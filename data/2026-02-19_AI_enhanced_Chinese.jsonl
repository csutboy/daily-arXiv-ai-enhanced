{"id": "2602.15876", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.15876", "abs": "https://arxiv.org/abs/2602.15876", "authors": ["Candace Walkington", "Mingyu Feng", "Itffini Pruitt-Britton", "Theodora Beauchamp", "Andrew Lan"], "title": "Should There be a Teacher In-the-Loop? A Study of Generative AI Personalized Tasks Middle School", "comment": null, "summary": "Adapting instruction to the fine-grained needs of individual students is a powerful application of recent advances in large language models. These generative AI models can create tasks that correspond to students' interests and enact context personalization, enhancing students' interest in learning academic content. However, when there is a teacher in-the-loop creating or modifying tasks with generative AI, it is unclear how efficient this process might be, despite commercial generative AI tools' claims that they will save teachers time. In the present study, we teamed 7 middle school mathematics teachers with ChatGPT to create personalized versions of problems in their curriculum, to correspond to their students' interests. We look at the prompting moves teachers made, their efficiency when creating problems, and the reactions of their 521 7th grade students who received the personalized assignments. We find that having a teacher-in-the-loop results in generative AI-enhanced personalization being enacted at a relatively broad grain size, whereas students tend to prefer a smaller grain size where they receive specific popular culture references that interest them. Teachers spent a lot of effort adjusting popular culture references and addressing issues with the depth or realism of the problems generated, giving higher or lower levels of ownership to the generative AI. Teachers were able to improve in their ability to craft interesting problems in partnership with generative AI, but this process did not appear to become particularly time efficient as teachers learned and reflected on their students' data, iterating their approaches.", "AI": {"tldr": "\u6559\u5e08\u4e0eChatGPT\u5408\u4f5c\u521b\u5efa\u4e2a\u6027\u5316\u6570\u5b66\u95ee\u9898\uff0c\u7814\u7a76\u53d1\u73b0\u6559\u5e08\u53c2\u4e0e\u5bfc\u81f4\u7c97\u7c92\u5ea6\u4e2a\u6027\u5316\uff0c\u800c\u5b66\u751f\u504f\u597d\u7ec6\u7c92\u5ea6\u6d41\u884c\u6587\u5316\u5f15\u7528\uff0c\u6559\u5e08\u8c03\u6574\u8fc7\u7a0b\u8017\u65f6\u4e14\u6548\u7387\u63d0\u5347\u6709\u9650\u3002", "motivation": "\u63a2\u7d22\u6559\u5e08\u4f7f\u7528\u751f\u6210\u5f0fAI\uff08ChatGPT\uff09\u521b\u5efa\u4e2a\u6027\u5316\u5b66\u4e60\u4efb\u52a1\u7684\u5b9e\u9645\u6548\u7387\uff0c\u5c3d\u7ba1\u5546\u4e1a\u5de5\u5177\u58f0\u79f0\u80fd\u8282\u7701\u6559\u5e08\u65f6\u95f4\uff0c\u4f46\u6559\u5e08\u53c2\u4e0e\u8fc7\u7a0b\u7684\u5b9e\u9645\u6548\u7387\u5c1a\u4e0d\u660e\u786e\u3002", "method": "7\u540d\u4e2d\u5b66\u6570\u5b66\u6559\u5e08\u4e0eChatGPT\u5408\u4f5c\uff0c\u6839\u636e\u5b66\u751f\u5174\u8da3\u4e2a\u6027\u5316\u8bfe\u7a0b\u95ee\u9898\uff1b\u5206\u6790\u6559\u5e08\u7684\u63d0\u793a\u7b56\u7565\u3001\u521b\u5efa\u6548\u7387\uff0c\u4ee5\u53ca521\u540d\u4e03\u5e74\u7ea7\u5b66\u751f\u5bf9\u4e2a\u6027\u5316\u4f5c\u4e1a\u7684\u53cd\u5e94\u3002", "result": "\u6559\u5e08\u53c2\u4e0e\u5bfc\u81f4\u751f\u6210\u5f0fAI\u589e\u5f3a\u7684\u4e2a\u6027\u5316\u4ee5\u76f8\u5bf9\u7c97\u7c92\u5ea6\u5b9e\u65bd\uff0c\u800c\u5b66\u751f\u504f\u597d\u5305\u542b\u5177\u4f53\u6d41\u884c\u6587\u5316\u5f15\u7528\u7684\u7ec6\u7c92\u5ea6\u4e2a\u6027\u5316\uff1b\u6559\u5e08\u82b1\u8d39\u5927\u91cf\u7cbe\u529b\u8c03\u6574\u6d41\u884c\u6587\u5316\u5f15\u7528\u3001\u89e3\u51b3\u95ee\u9898\u6df1\u5ea6\u6216\u73b0\u5b9e\u6027\u95ee\u9898\uff1b\u6559\u5e08\u80fd\u63d0\u9ad8\u4e0eAI\u5408\u4f5c\u521b\u5efa\u6709\u8da3\u95ee\u9898\u7684\u80fd\u529b\uff0c\u4f46\u8fc7\u7a0b\u5e76\u672a\u53d8\u5f97\u7279\u522b\u9ad8\u6548\u3002", "conclusion": "\u6559\u5e08\u4e0e\u751f\u6210\u5f0fAI\u5408\u4f5c\u521b\u5efa\u4e2a\u6027\u5316\u4efb\u52a1\u9700\u8981\u5927\u91cf\u8c03\u6574\u5de5\u4f5c\uff0c\u6548\u7387\u63d0\u5347\u6709\u9650\uff1b\u5b66\u751f\u504f\u597d\u4e0e\u6559\u5e08\u5b9e\u65bd\u65b9\u5f0f\u5b58\u5728\u7c92\u5ea6\u5dee\u5f02\uff1b\u9700\u8981\u66f4\u597d\u7684\u5de5\u5177\u652f\u6301\u6559\u5e08\u9ad8\u6548\u4e2a\u6027\u5316\u6559\u5b66\u3002"}}
{"id": "2602.15881", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.15881", "abs": "https://arxiv.org/abs/2602.15881", "authors": ["Mike Wa Nkongolo"], "title": "Pluralism in AI Governance: Toward Sociotechnical Alignment and Normative Coherence", "comment": "18 pages, 6 figures, and 2 tables", "summary": "This paper examines the challenge of embedding public values into national artificial intelligence (AI) governance frameworks, a task complicated by the sociotechnical nature of contemporary systems. As AI permeates domains such as healthcare, justice, and public administration, legitimacy depends not only on technical correctness but on alignment with societal norms, democratic principles, and human dignity. Traditional paradigms focused on model safety or market efficiency neglect broader institutional contexts. To address this, the study synthesises frameworks including Full-Stack Alignment, Thick Models of Value, Value Sensitive Design, and Public Constitutional AI, alongside comparative analysis of jurisdictions such as the EU, US, China, UK, Brazil, and South Africa (SA). It introduces a layered framework linking values, mechanisms, and strategies, and maps tensions such as fairness versus efficiency, transparency versus security, and privacy versus equity. Findings reveal a pluralism of regulatory philosophies, with SA sovereignty-oriented approach offering a distinctive counterpoint. The study contributes a holistic, value-sensitive model of AI governance, reframing regulation as a proactive mechanism for embedding public values into sociotechnical systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5c06\u516c\u5171\u4ef7\u503c\u5d4c\u5165\u56fd\u5bb6AI\u6cbb\u7406\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fde\u63a5\u4ef7\u503c\u3001\u673a\u5236\u548c\u7b56\u7565\u7684\u5206\u5c42\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u53f8\u6cd5\u7ba1\u8f96\u533a\u5c55\u793a\u4e86\u591a\u5143\u5316\u7684\u76d1\u7ba1\u54f2\u5b66\u3002", "motivation": "\u968f\u7740AI\u6e17\u900f\u5230\u533b\u7597\u3001\u53f8\u6cd5\u548c\u516c\u5171\u7ba1\u7406\u7b49\u5173\u952e\u9886\u57df\uff0c\u6cbb\u7406\u7684\u5408\u6cd5\u6027\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u6280\u672f\u6b63\u786e\u6027\uff0c\u8fd8\u9700\u8981\u4e0e\u793e\u4f1a\u89c4\u8303\u3001\u6c11\u4e3b\u539f\u5219\u548c\u4eba\u7c7b\u5c0a\u4e25\u4fdd\u6301\u4e00\u81f4\u3002\u4f20\u7edf\u8303\u5f0f\u8fc7\u4e8e\u5173\u6ce8\u6a21\u578b\u5b89\u5168\u6216\u5e02\u573a\u6548\u7387\uff0c\u5ffd\u89c6\u4e86\u66f4\u5e7f\u6cdb\u7684\u5236\u5ea6\u80cc\u666f\u3002", "method": "\u7814\u7a76\u7efc\u5408\u4e86\u5305\u62ec\u5168\u6808\u5bf9\u9f50\u3001\u539a\u4ef7\u503c\u6a21\u578b\u3001\u4ef7\u503c\u654f\u611f\u8bbe\u8ba1\u548c\u516c\u5171\u5baa\u6cd5AI\u5728\u5185\u7684\u591a\u4e2a\u6846\u67b6\uff0c\u5e76\u5bf9\u6b27\u76df\u3001\u7f8e\u56fd\u3001\u4e2d\u56fd\u3001\u82f1\u56fd\u3001\u5df4\u897f\u548c\u5357\u975e\u7b49\u53f8\u6cd5\u7ba1\u8f96\u533a\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fde\u63a5\u4ef7\u503c\u3001\u673a\u5236\u548c\u7b56\u7565\u7684\u5206\u5c42\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u591a\u5143\u5316\u7684\u76d1\u7ba1\u54f2\u5b66\uff0c\u5357\u975e\u7684\u4e3b\u6743\u5bfc\u5411\u65b9\u6cd5\u63d0\u4f9b\u4e86\u72ec\u7279\u7684\u5bf9\u6bd4\u89c6\u89d2\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u516c\u5e73\u4e0e\u6548\u7387\u3001\u900f\u660e\u5ea6\u4e0e\u5b89\u5168\u3001\u9690\u79c1\u4e0e\u516c\u5e73\u7b49\u6838\u5fc3\u5f20\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8d21\u732e\u4e86\u4e00\u4e2a\u6574\u4f53\u6027\u7684\u3001\u4ef7\u503c\u654f\u611f\u7684AI\u6cbb\u7406\u6a21\u578b\uff0c\u5c06\u76d1\u7ba1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5c06\u516c\u5171\u4ef7\u503c\u5d4c\u5165\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u7684\u4e3b\u52a8\u673a\u5236\uff0c\u5f3a\u8c03\u4e86\u5728AI\u6cbb\u7406\u4e2d\u5d4c\u5165\u516c\u5171\u4ef7\u503c\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.16151", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.16151", "abs": "https://arxiv.org/abs/2602.16151", "authors": ["Sabine Weber", "Angelina Wang", "Ankush Gupta", "Arjun Subramonian", "Dennis Ulmer", "Eshaan Tanwar", "Geetanjali Aich", "Hannah Devinney", "Jacob Hobbs", "Jennifer Mickel", "Joshua Tint", "Mae Sosto", "Ray Groshan", "Simone Astarita", "Vagrant Gautam", "Verena Blaschke", "William Agnew", "Wilson Y Lee", "Yanan Long"], "title": "Queer NLP: A Critical Survey on Literature Gaps, Biases and Trends", "comment": null, "summary": "Natural language processing (NLP) technologies are rapidly reshaping how language is created, processed, and analyzed by humans. With current and potential applications in hiring, law, healthcare, and other areas that impact people's lives, understanding and mitigating harms towards marginalized groups is critical. In this survey, we examine NLP research papers that explicitly address the relationship between LGBTQIA+ communities and NLP technologies. We systematically review all such papers published in the ACL Anthology, to answer the following research questions: (1) What are current research trends? (2) What gaps exist in terms of topics and methods? (3) What areas are open for future work? We find that while the number of papers on queer NLP has grown within the last few years, most papers take a reactive rather than a proactive approach, pointing out bias more often than mitigating it, and focusing on shortcomings of existing systems rather than creating new solutions. Our survey uncovers many opportunities for future work, especially regarding stakeholder involvement, intersectionality, interdisciplinarity, and languages other than English. We also offer an outlook from a queer studies perspective, highlighting understudied topics and gaps in the harms addressed in NLP papers. Beyond being a roadmap of what has been done, this survey is a call to action for work towards more just and inclusive NLP technologies.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u7cfb\u7edf\u56de\u987e\u4e86NLP\u6280\u672f\u4e0eLGBTQIA+\u793e\u533a\u5173\u7cfb\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u53d1\u73b0\u8be5\u9886\u57df\u8bba\u6587\u6570\u91cf\u867d\u5728\u589e\u957f\uff0c\u4f46\u5927\u591a\u91c7\u53d6\u88ab\u52a8\u800c\u975e\u4e3b\u52a8\u7684\u65b9\u6cd5\uff0c\u66f4\u591a\u662f\u6307\u51fa\u504f\u89c1\u800c\u975e\u7f13\u89e3\u504f\u89c1\uff0c\u5173\u6ce8\u73b0\u6709\u7cfb\u7edf\u7684\u7f3a\u9677\u800c\u975e\u521b\u9020\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740NLP\u6280\u672f\u5728\u62db\u8058\u3001\u6cd5\u5f8b\u3001\u533b\u7597\u7b49\u5f71\u54cd\u4eba\u4eec\u751f\u6d3b\u7684\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u7406\u89e3\u548c\u51cf\u8f7b\u5bf9\u8fb9\u7f18\u5316\u7fa4\u4f53\uff08\u7279\u522b\u662fLGBTQIA+\u793e\u533a\uff09\u7684\u4f24\u5bb3\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u7cfb\u7edf\u4e86\u89e3\u5f53\u524d\u7814\u7a76\u73b0\u72b6\u3001\u53d1\u73b0\u7814\u7a76\u7a7a\u767d\u5e76\u4e3a\u672a\u6765\u5de5\u4f5c\u6307\u660e\u65b9\u5411\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u56de\u987e\u4e86ACL Anthology\u4e2d\u6240\u6709\u660e\u786e\u63a2\u8ba8LGBTQIA+\u793e\u533a\u4e0eNLP\u6280\u672f\u5173\u7cfb\u7684\u8bba\u6587\uff0c\u901a\u8fc7\u56de\u7b54\u4e09\u4e2a\u7814\u7a76\u95ee\u9898\u6765\u5206\u6790\u5f53\u524d\u7814\u7a76\u8d8b\u52bf\u3001\u65b9\u6cd5\u7a7a\u767d\u548c\u672a\u6765\u5de5\u4f5c\u65b9\u5411\u3002", "result": "\u53d1\u73b0\u867d\u7136\u8fd1\u5e74\u6765\u5173\u4e8equeer NLP\u7684\u8bba\u6587\u6570\u91cf\u6709\u6240\u589e\u957f\uff0c\u4f46\u5927\u591a\u6570\u8bba\u6587\u91c7\u53d6\u88ab\u52a8\u800c\u975e\u4e3b\u52a8\u7684\u65b9\u6cd5\uff1a\u66f4\u591a\u662f\u6307\u51fa\u504f\u89c1\u800c\u975e\u7f13\u89e3\u504f\u89c1\uff0c\u5173\u6ce8\u73b0\u6709\u7cfb\u7edf\u7684\u7f3a\u9677\u800c\u975e\u521b\u9020\u65b0\u89e3\u51b3\u65b9\u6848\u3002\u7814\u7a76\u5b58\u5728\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u4e0d\u8db3\u3001\u4ea4\u53c9\u6027\u8003\u8651\u4e0d\u591f\u3001\u8de8\u5b66\u79d1\u5408\u4f5c\u7f3a\u4e4f\u3001\u975e\u82f1\u8bed\u8bed\u8a00\u7814\u7a76\u7a00\u5c11\u7b49\u95ee\u9898\u3002", "conclusion": "\u8be5\u8c03\u67e5\u4e0d\u4ec5\u662f\u5bf9\u73b0\u6709\u7814\u7a76\u7684\u8def\u7ebf\u56fe\uff0c\u66f4\u662f\u5bf9\u6784\u5efa\u66f4\u516c\u6b63\u3001\u5305\u5bb9\u7684NLP\u6280\u672f\u7684\u884c\u52a8\u547c\u5401\u3002\u672a\u6765\u5de5\u4f5c\u9700\u8981\u66f4\u591a\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u3001\u8003\u8651\u4ea4\u53c9\u6027\u3001\u52a0\u5f3a\u8de8\u5b66\u79d1\u5408\u4f5c\u3001\u5173\u6ce8\u975e\u82f1\u8bed\u8bed\u8a00\uff0c\u5e76\u4ece\u9177\u513f\u7814\u7a76\u89c6\u89d2\u586b\u8865\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2602.16307", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16307", "abs": "https://arxiv.org/abs/2602.16307", "authors": ["Fabian Walke", "Veronika F\u00f6ller"], "title": "Generative AI Usage of University Students: Navigating Between Education and Business", "comment": null, "summary": "This study investigates generative artificial intelligence (GenAI) usage of university students who study alongside their professional career. Previous literature has paid little attention to part-time students and the intersectional use of GenAI between education and business. This study examines with a grounded theory approach the characteristics of GenAI usage of part-time students. Eleven students from a distance learning university were interviewed. Three causal and four intervening conditions, as well as strategies were identified, to influence the use of GenAI. The study highlights both the potential and challenges of GenAI usage in education and business. While GenAI can significantly enhance productivity and learning outcomes, concerns about ethical implications, reliability, and the risk of academic misconduct persist. The developed grounded model offers a comprehensive understanding of GenAI usage among students, providing valuable insights for educators, policymakers, and developers of GenAI tools seeking to bridge the gap between education and business.", "AI": {"tldr": "\u7814\u7a76\u91c7\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u63a2\u8ba8\u5728\u804c\u5927\u5b66\u751f\u7684\u751f\u6210\u5f0fAI\u4f7f\u7528\u7279\u5f81\uff0c\u8bc6\u522b\u4e86\u5f71\u54cd\u4f7f\u7528\u7684\u56e0\u679c\u6761\u4ef6\u3001\u4e2d\u4ecb\u6761\u4ef6\u548c\u7b56\u7565\uff0c\u63ed\u793a\u4e86\u6559\u80b2\u4e0e\u4f01\u4e1a\u5e94\u7528\u4ea4\u53c9\u7684\u6f5c\u529b\u4e0e\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u5f88\u5c11\u5173\u6ce8\u5728\u804c\u5b66\u751f\u4ee5\u53ca\u751f\u6210\u5f0fAI\u5728\u6559\u80b2\u4e0e\u5546\u4e1a\u4ea4\u53c9\u9886\u57df\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6df1\u5165\u4e86\u89e3\u5728\u804c\u5b66\u751f\u7684\u751f\u6210\u5f0fAI\u4f7f\u7528\u7279\u5f81\u3002", "method": "\u91c7\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u5bf911\u540d\u8fdc\u7a0b\u6559\u80b2\u5927\u5b66\u7684\u5b66\u751f\u8fdb\u884c\u8bbf\u8c08\uff0c\u901a\u8fc7\u8d28\u6027\u5206\u6790\u8bc6\u522b\u5f71\u54cd\u751f\u6210\u5f0fAI\u4f7f\u7528\u7684\u5404\u79cd\u6761\u4ef6\u56e0\u7d20\u3002", "result": "\u8bc6\u522b\u4e86\u4e09\u4e2a\u56e0\u679c\u6761\u4ef6\u548c\u56db\u4e2a\u4e2d\u4ecb\u6761\u4ef6\uff0c\u4ee5\u53ca\u76f8\u5e94\u7684\u7b56\u7565\uff0c\u8fd9\u4e9b\u56e0\u7d20\u5171\u540c\u5f71\u54cd\u751f\u6210\u5f0fAI\u7684\u4f7f\u7528\u3002\u7814\u7a76\u53d1\u73b0\u751f\u6210\u5f0fAI\u80fd\u663e\u8457\u63d0\u9ad8\u751f\u4ea7\u529b\u548c\u5b66\u4e60\u6548\u679c\uff0c\u4f46\u4e5f\u5b58\u5728\u4f26\u7406\u95ee\u9898\u3001\u53ef\u9760\u6027\u548c\u5b66\u672f\u4e0d\u7aef\u98ce\u9669\u7b49\u6311\u6218\u3002", "conclusion": "\u5f00\u53d1\u7684\u624e\u6839\u6a21\u578b\u4e3a\u7406\u89e3\u5b66\u751f\u4f7f\u7528\u751f\u6210\u5f0fAI\u63d0\u4f9b\u4e86\u5168\u9762\u6846\u67b6\uff0c\u4e3a\u6559\u80b2\u8005\u3001\u653f\u7b56\u5236\u5b9a\u8005\u548cAI\u5de5\u5177\u5f00\u53d1\u8005\u5f25\u5408\u6559\u80b2\u4e0e\u5546\u4e1a\u4e4b\u95f4\u7684\u5dee\u8ddd\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2602.15985", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.15985", "abs": "https://arxiv.org/abs/2602.15985", "authors": ["Ruihong Yin", "Yue Zheng", "Chaohui Li", "Ahmet Efe", "Abhimanyu Kumar", "Ziqing Zeng", "Ulya R. Karpuzcu", "Sachin S. Sapatnekar", "Chris H. Kim"], "title": "Decomposing Large-Scale Ising Problems on FPGAs: A Hybrid Hardware Approach", "comment": null, "summary": "Emerging analog computing substrates, such as oscillator-based Ising machines, offer rapid convergence times for combinatorial optimization but often suffer from limited scalability due to physical implementation constraints. To tackle real-world problems involving thousands of variables, problem decomposition is required; however, performing this step on standard CPUs introduces significant latency, preventing the high-speed solver from operating at full capacity. This work presents a heterogeneous system that offloads the decomposition workload to an FPGA, tightly integrated with a custom 28nm Ising solver. By migrating the decomposition logic to reconfigurable hardware and utilizing parallel processing elements, the system minimizes the communication latency typically associated with host-device interactions. Our evaluation demonstrates that this co-design approach effectively bridges the speed gap between digital preprocessing and analog solving, achieving nearly 2$\\times$ speedup and an energy efficiency improvement of over two orders of magnitude compared to optimized software baselines running on modern CPUs.", "AI": {"tldr": "\u63d0\u51fa\u5f02\u6784\u7cfb\u7edf\uff0c\u5c06\u5206\u89e3\u5de5\u4f5c\u8d1f\u8f7d\u5378\u8f7d\u5230FPGA\uff0c\u4e0e\u6a21\u62df\u4f0a\u8f9b\u6c42\u89e3\u5668\u7d27\u5bc6\u96c6\u6210\uff0c\u51cf\u5c11\u901a\u4fe1\u5ef6\u8fdf\uff0c\u5b9e\u73b02\u500d\u52a0\u901f\u548c\u767e\u500d\u80fd\u6548\u63d0\u5347", "motivation": "\u6a21\u62df\u8ba1\u7b97\u57fa\u677f\uff08\u5982\u632f\u8361\u5668\u4f0a\u8f9b\u673a\uff09\u5728\u7ec4\u5408\u4f18\u5316\u4e2d\u6536\u655b\u5feb\uff0c\u4f46\u53d7\u7269\u7406\u5b9e\u73b0\u9650\u5236\u96be\u4ee5\u6269\u5c55\u3002\u5904\u7406\u6570\u5343\u53d8\u91cf\u9700\u8981\u95ee\u9898\u5206\u89e3\uff0c\u4f46CPU\u5206\u89e3\u5f15\u5165\u9ad8\u5ef6\u8fdf\uff0c\u9650\u5236\u4e86\u9ad8\u901f\u6c42\u89e3\u5668\u7684\u6027\u80fd\u53d1\u6325", "method": "\u8bbe\u8ba1\u5f02\u6784\u7cfb\u7edf\uff0c\u5c06\u5206\u89e3\u903b\u8f91\u8fc1\u79fb\u5230\u53ef\u91cd\u6784\u786c\u4ef6\uff08FPGA\uff09\uff0c\u5229\u7528\u5e76\u884c\u5904\u7406\u5143\u4ef6\uff0c\u4e0e28nm\u5b9a\u5236\u4f0a\u8f9b\u6c42\u89e3\u5668\u7d27\u5bc6\u96c6\u6210\uff0c\u6700\u5c0f\u5316\u4e3b\u673a-\u8bbe\u5907\u901a\u4fe1\u5ef6\u8fdf", "result": "\u8be5\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u6709\u6548\u5f25\u5408\u4e86\u6570\u5b57\u9884\u5904\u7406\u548c\u6a21\u62df\u6c42\u89e3\u4e4b\u95f4\u7684\u901f\u5ea6\u5dee\u8ddd\uff0c\u76f8\u6bd4\u73b0\u4ee3CPU\u4e0a\u7684\u4f18\u5316\u8f6f\u4ef6\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u8fd12\u500d\u52a0\u901f\u548c\u8d85\u8fc7\u4e24\u4e2a\u6570\u91cf\u7ea7\u7684\u80fd\u6548\u63d0\u5347", "conclusion": "\u901a\u8fc7\u5c06\u5206\u89e3\u5de5\u4f5c\u8d1f\u8f7d\u5378\u8f7d\u5230FPGA\u5e76\u4e0e\u6a21\u62df\u4f0a\u8f9b\u6c42\u89e3\u5668\u7d27\u5bc6\u96c6\u6210\uff0c\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5ef6\u8fdf\uff0c\u4f7f\u9ad8\u901f\u6a21\u62df\u6c42\u89e3\u5668\u80fd\u591f\u5145\u5206\u53d1\u6325\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.16376", "categories": ["econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.16376", "abs": "https://arxiv.org/abs/2602.16376", "authors": ["Ulrich Hounyo", "Jiahao Lin"], "title": "Two-way Clustering Robust Variance Estimator in Quantile Regression Models", "comment": null, "summary": "We study inference for linear quantile regression with two-way clustered data. Using a separately exchangeable array framework and a projection decomposition of the quantile score, we characterize regime-dependent convergence rates and establish a self-normalized Gaussian approximation. We propose a two-way cluster-robust sandwich variance estimator with a kernel-based density ``bread'' and a projection-matched ``meat'', and prove consistency and validity of inference in Gaussian regimes. We also show an impossibility result for uniform inference in a non-Gaussian interaction regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u53cc\u5411\u805a\u7c7b\u6570\u636e\u4e0b\u7684\u7ebf\u6027\u5206\u4f4d\u6570\u56de\u5f52\u63a8\u65ad\uff0c\u5efa\u7acb\u4e86\u81ea\u6807\u51c6\u5316\u9ad8\u65af\u8fd1\u4f3c\uff0c\u63d0\u51fa\u4e86\u7a33\u5065\u65b9\u5dee\u4f30\u8ba1\u5668\uff0c\u5e76\u8bc1\u660e\u4e86\u9ad8\u65af\u673a\u5236\u4e0b\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u975e\u9ad8\u65af\u4ea4\u4e92\u673a\u5236\u4e0b\u5747\u5300\u63a8\u65ad\u7684\u4e0d\u53ef\u80fd\u6027\u3002", "motivation": "\u5728\u5b9e\u8bc1\u7814\u7a76\u4e2d\u7ecf\u5e38\u9047\u5230\u53cc\u5411\u805a\u7c7b\u6570\u636e\uff08\u5982\u9762\u677f\u6570\u636e\uff09\uff0c\u4f20\u7edf\u5206\u4f4d\u6570\u56de\u5f52\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u6b64\u7c7b\u6570\u636e\u7ed3\u6784\u3002\u9700\u8981\u5f00\u53d1\u9002\u7528\u4e8e\u53cc\u5411\u805a\u7c7b\u6570\u636e\u7684\u5206\u4f4d\u6570\u56de\u5f52\u63a8\u65ad\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u590d\u6742\u4f9d\u8d56\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u4f7f\u7528\u5355\u72ec\u53ef\u4ea4\u6362\u6570\u7ec4\u6846\u67b6\u548c\u5206\u4f4d\u6570\u5f97\u5206\u7684\u6295\u5f71\u5206\u89e3\uff0c\u8868\u5f81\u673a\u5236\u4f9d\u8d56\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5efa\u7acb\u81ea\u6807\u51c6\u5316\u9ad8\u65af\u8fd1\u4f3c\u3002\u63d0\u51fa\u53cc\u5411\u805a\u7c7b\u7a33\u5065\u4e09\u660e\u6cbb\u65b9\u5dee\u4f30\u8ba1\u5668\uff0c\u5305\u542b\u57fa\u4e8e\u6838\u7684\u5bc6\u5ea6\"\u9762\u5305\"\u548c\u6295\u5f71\u5339\u914d\u7684\"\u8089\"\u3002", "result": "\u8bc1\u660e\u4e86\u9ad8\u65af\u673a\u5236\u4e0b\u63a8\u65ad\u7684\u4e00\u81f4\u6027\u548c\u6709\u6548\u6027\uff0c\u5efa\u7acb\u4e86\u81ea\u6807\u51c6\u5316\u9ad8\u65af\u8fd1\u4f3c\u3002\u540c\u65f6\u5c55\u793a\u4e86\u975e\u9ad8\u65af\u4ea4\u4e92\u673a\u5236\u4e0b\u5747\u5300\u63a8\u65ad\u7684\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u53cc\u5411\u805a\u7c7b\u6570\u636e\u4e0b\u7684\u5206\u4f4d\u6570\u56de\u5f52\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u63a8\u65ad\u65b9\u6cd5\uff0c\u5728\u9ad8\u65af\u673a\u5236\u4e0b\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\uff0c\u4f46\u63ed\u793a\u4e86\u5728\u975e\u9ad8\u65af\u4ea4\u4e92\u673a\u5236\u4e0b\u5747\u5300\u63a8\u65ad\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.15889", "categories": ["stat.AP", "cs.AI", "cs.CL", "physics.ed-ph"], "pdf": "https://arxiv.org/pdf/2602.15889", "abs": "https://arxiv.org/abs/2602.15889", "authors": ["Paul Tschisgale", "Peter Wulff"], "title": "Evidence for Daily and Weekly Periodic Variability in GPT-4o Performance", "comment": null, "summary": "Large language models (LLMs) are increasingly used in research both as tools and as objects of investigation. Much of this work implicitly assumes that LLM performance under fixed conditions (identical model snapshot, hyperparameters, and prompt) is time-invariant. If average output quality changes systematically over time, this assumption is violated, threatening the reliability, validity, and reproducibility of findings. To empirically examine this assumption, we conducted a longitudinal study on the temporal variability of GPT-4o's average performance. Using a fixed model snapshot, fixed hyperparameters, and identical prompting, GPT-4o was queried via the API to solve the same multiple-choice physics task every three hours for approximately three months. Ten independent responses were generated at each time point and their scores were averaged. Spectral (Fourier) analysis of the resulting time series revealed notable periodic variability in average model performance, accounting for approximately 20% of the total variance. In particular, the observed periodic patterns are well explained by the interaction of a daily and a weekly rhythm. These findings indicate that, even under controlled conditions, LLM performance may vary periodically over time, calling into question the assumption of time invariance. Implications for ensuring validity and replicability of research that uses or investigates LLMs are discussed.", "AI": {"tldr": "GPT-4o\u5728\u56fa\u5b9a\u6761\u4ef6\u4e0b\u89e3\u51b3\u7269\u7406\u9009\u62e9\u9898\u7684\u6027\u80fd\u968f\u65f6\u95f4\u5448\u73b0\u5468\u671f\u6027\u53d8\u5316\uff0c\u7ea620%\u7684\u65b9\u5dee\u53ef\u7531\u65e5\u5468\u671f\u548c\u5468\u5468\u671f\u89e3\u91ca\uff0c\u6311\u6218\u4e86LLM\u6027\u80fd\u65f6\u95f4\u4e0d\u53d8\u7684\u5047\u8bbe\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u901a\u5e38\u5047\u8bbe\u5728\u56fa\u5b9a\u6761\u4ef6\uff08\u76f8\u540c\u6a21\u578b\u7248\u672c\u3001\u8d85\u53c2\u6570\u548c\u63d0\u793a\uff09\u4e0b\uff0cLLM\u7684\u6027\u80fd\u662f\u65f6\u95f4\u4e0d\u53d8\u7684\u3002\u5982\u679c\u5e73\u5747\u8f93\u51fa\u8d28\u91cf\u968f\u65f6\u95f4\u7cfb\u7edf\u6027\u53d8\u5316\uff0c\u8fd9\u4e00\u5047\u8bbe\u5c06\u88ab\u8fdd\u53cd\uff0c\u5a01\u80c1\u7814\u7a76\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3001\u6709\u6548\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u4f7f\u7528\u56fa\u5b9a\u6a21\u578b\u5feb\u7167\u3001\u56fa\u5b9a\u8d85\u53c2\u6570\u548c\u76f8\u540c\u63d0\u793a\uff0c\u901a\u8fc7API\u6bcf3\u5c0f\u65f6\u67e5\u8be2GPT-4o\u89e3\u51b3\u76f8\u540c\u7684\u591a\u9879\u9009\u62e9\u7269\u7406\u4efb\u52a1\uff0c\u6301\u7eed\u7ea63\u4e2a\u6708\u3002\u6bcf\u4e2a\u65f6\u95f4\u70b9\u751f\u621010\u4e2a\u72ec\u7acb\u54cd\u5e94\u5e76\u8ba1\u7b97\u5e73\u5747\u5206\u6570\uff0c\u5bf9\u5f97\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9891\u8c31\uff08\u5085\u91cc\u53f6\uff09\u5206\u6790\u3002", "result": "\u9891\u8c31\u5206\u6790\u663e\u793a\u6a21\u578b\u5e73\u5747\u6027\u80fd\u5b58\u5728\u663e\u8457\u7684\u5468\u671f\u6027\u53d8\u5316\uff0c\u7ea6\u5360\u603b\u65b9\u5dee\u768420%\u3002\u89c2\u5bdf\u5230\u7684\u5468\u671f\u6027\u6a21\u5f0f\u5f88\u597d\u5730\u7531\u65e5\u8282\u594f\u548c\u5468\u8282\u594f\u7684\u76f8\u4e92\u4f5c\u7528\u89e3\u91ca\uff0c\u8868\u660e\u5373\u4f7f\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\uff0cLLM\u6027\u80fd\u4e5f\u53ef\u80fd\u968f\u65f6\u95f4\u5468\u671f\u6027\u53d8\u5316\u3002", "conclusion": "LLM\u6027\u80fd\u5728\u56fa\u5b9a\u6761\u4ef6\u4e0b\u5e76\u975e\u65f6\u95f4\u4e0d\u53d8\uff0c\u800c\u662f\u5448\u73b0\u5468\u671f\u6027\u53d8\u5316\uff0c\u8fd9\u6311\u6218\u4e86\u5f53\u524d\u7814\u7a76\u7684\u57fa\u672c\u5047\u8bbe\u3002\u7814\u7a76\u7ed3\u679c\u5bf9\u786e\u4fdd\u4f7f\u7528\u6216\u7814\u7a76LLM\u7684\u79d1\u7814\u5de5\u4f5c\u7684\u6709\u6548\u6027\u548c\u53ef\u91cd\u590d\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.16326", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.16326", "abs": "https://arxiv.org/abs/2602.16326", "authors": ["Fabrizio Corriera", "Frank W. Takes", "Akrati Saxena"], "title": "Individual Fairness in Community Detection: Quantitative Measure and Comparative Evaluation", "comment": null, "summary": "Community detection is a fundamental task in complex network analysis. Fairness-aware community detection seeks to prevent biased node partitions, typically framed in terms of individual fairness, which requires similar nodes to be treated similarly, and group fairness, which aims to avoid disadvantaging specific groups of nodes. While existing literature on fair community detection has primarily focused on group fairness, we introduce a novel measure to quantify individual fairness in community detection methods. The proposed measure captures unfairness as the vectorial distance between a node's true and predicted community representations, computed using the community co-occurrence matrix. We provide a comprehensive empirical investigation of a broad set of community detection algorithms from the literature on both synthetic networks, with varying levels of community explicitness, and real-world networks. We particularly investigate the fairness-performance trade-off using standard quality metrics and compare individual fairness outcomes with existing group fairness measures. The results show that individual unfairness can occur even when group fairness or clustering accuracy is high, underscoring that individual and group fairness are not interchangeable. Moreover, fairness depends critically on the detectability of community structure. However, we find that Significance and Surprise for denser graphs, and Combo, Leiden, and SBMDL for sparser graphs result in a better trade-off between individual fairness and community quality. Overall, our findings, together with the fact that community detection is an important step in many network analysis downstream tasks, highlight the necessity of developing fairness-aware community detection methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u793e\u533a\u68c0\u6d4b\u4e2d\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u65b0\u5ea6\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u4e2a\u4f53\u4e0d\u516c\u5e73\u6027\u53ef\u80fd\u5728\u7fa4\u4f53\u516c\u5e73\u6027\u6216\u805a\u7c7b\u51c6\u786e\u6027\u8f83\u9ad8\u65f6\u4ecd\u7136\u5b58\u5728\uff0c\u5e76\u8bc6\u522b\u4e86\u5728\u4e0d\u540c\u7f51\u7edc\u5bc6\u5ea6\u4e0b\u5b9e\u73b0\u4e2a\u4f53\u516c\u5e73\u6027\u4e0e\u793e\u533a\u8d28\u91cf\u66f4\u597d\u6743\u8861\u7684\u7b97\u6cd5\u3002", "motivation": "\u5f53\u524d\u516c\u5e73\u6027\u793e\u533a\u68c0\u6d4b\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7fa4\u4f53\u516c\u5e73\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u91cf\u5316\u8bc4\u4f30\u3002\u793e\u533a\u68c0\u6d4b\u4f5c\u4e3a\u590d\u6742\u7f51\u7edc\u5206\u6790\u7684\u57fa\u7840\u4efb\u52a1\uff0c\u5176\u516c\u5e73\u6027\u5bf9\u4e0b\u6e38\u4efb\u52a1\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u8003\u8651\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8282\u70b9\u771f\u5b9e\u4e0e\u9884\u6d4b\u793e\u533a\u8868\u793a\u5411\u91cf\u8ddd\u79bb\u7684\u4e2a\u4f53\u516c\u5e73\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4f7f\u7528\u793e\u533a\u5171\u73b0\u77e9\u9635\u8ba1\u7b97\u3002\u5728\u5408\u6210\u7f51\u7edc\uff08\u4e0d\u540c\u793e\u533a\u663e\u6027\u7a0b\u5ea6\uff09\u548c\u771f\u5b9e\u7f51\u7edc\u4e0a\u5bf9\u591a\u79cd\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u8fdb\u884c\u7efc\u5408\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u516c\u5e73\u6027\u4e0e\u6027\u80fd\u7684\u6743\u8861\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u4e2a\u4f53\u4e0d\u516c\u5e73\u6027\u53ef\u80fd\u5728\u7fa4\u4f53\u516c\u5e73\u6027\u6216\u805a\u7c7b\u51c6\u786e\u6027\u8f83\u9ad8\u65f6\u4ecd\u7136\u5b58\u5728\uff1b2\uff09\u4e2a\u4f53\u516c\u5e73\u6027\u4e0e\u7fa4\u4f53\u516c\u5e73\u6027\u4e0d\u53ef\u4e92\u6362\uff1b3\uff09\u516c\u5e73\u6027\u4e25\u91cd\u4f9d\u8d56\u793e\u533a\u7ed3\u6784\u7684\u53ef\u68c0\u6d4b\u6027\uff1b4\uff09\u5bf9\u4e8e\u7a20\u5bc6\u56fe\uff0cSignificance\u548cSurprise\u7b97\u6cd5\u8868\u73b0\u66f4\u597d\uff1b\u5bf9\u4e8e\u7a00\u758f\u56fe\uff0cCombo\u3001Leiden\u548cSBMDL\u7b97\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u4e2a\u4f53\u516c\u5e73\u6027\u4e0e\u7fa4\u4f53\u516c\u5e73\u6027\u662f\u4e0d\u540c\u7684\u6982\u5ff5\uff0c\u9700\u8981\u5206\u522b\u8003\u8651\u3002\u793e\u533a\u68c0\u6d4b\u4f5c\u4e3a\u7f51\u7edc\u5206\u6790\u7684\u91cd\u8981\u6b65\u9aa4\uff0c\u5f00\u53d1\u516c\u5e73\u6027\u611f\u77e5\u7684\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\u5177\u6709\u5fc5\u8981\u6027\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u7b97\u6cd5\u9009\u62e9\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u793e\u533a\u68c0\u6d4b\u4e2d\u540c\u65f6\u8003\u8651\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.16012", "categories": ["cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.16012", "abs": "https://arxiv.org/abs/2602.16012", "authors": ["Jieyi Bi", "Zhiguang Cao", "Jianan Zhou", "Wen Song", "Yaoxin Wu", "Jie Zhang", "Yining Ma", "Cathy Wu"], "title": "Towards Efficient Constraint Handling in Neural Solvers for Routing Problems", "comment": "Accepted by ICLR 2026", "summary": "Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.", "AI": {"tldr": "CaR\u662f\u4e00\u4e2a\u7528\u4e8e\u795e\u7ecf\u8def\u7531\u6c42\u89e3\u5668\u7684\u7ea6\u675f\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u53ef\u884c\u6027\u7cbe\u70bc\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5904\u7406\u590d\u6742\u7ea6\u675f\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u6c42\u89e3\u5668\u5728\u7b80\u5355\u8def\u7531\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u7ea6\u675f\u4e0b\u8868\u73b0\u6709\u9650\u3002\u5f53\u524d\u7684\u7ea6\u675f\u5904\u7406\u65b9\u6848\uff08\u53ef\u884c\u6027\u63a9\u7801\u6216\u9690\u5f0f\u53ef\u884c\u6027\u611f\u77e5\uff09\u5bf9\u4e8e\u786c\u7ea6\u675f\u8981\u4e48\u6548\u7387\u4f4e\u4e0b\uff0c\u8981\u4e48\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51faConstruct-and-Refine (CaR)\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6307\u5bfc\u6784\u9020\u6a21\u5757\u751f\u6210\u591a\u6837\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u4e9b\u65b9\u6848\u9002\u5408\u8f7b\u91cf\u7ea7\u6539\u8fdb\u8fc7\u7a0b\uff08\u598210\u6b65 vs \u4e4b\u524d\u5de5\u4f5c\u76845k\u6b65\uff09\u3002\u9996\u6b21\u4f7f\u7528\u6784\u9020-\u6539\u8fdb\u5171\u4eab\u8868\u793a\uff0c\u7edf\u4e00\u7f16\u7801\u5668\u4ee5\u5b9e\u73b0\u8de8\u8303\u5f0f\u7684\u77e5\u8bc6\u5171\u4eab\u3002", "result": "\u5728\u5178\u578b\u786c\u8def\u7531\u7ea6\u675f\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cCaR\u5728\u53ef\u884c\u6027\u3001\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u7ecf\u5178\u548c\u795e\u7ecfSOTA\u6c42\u89e3\u5668\u3002", "conclusion": "CaR\u662f\u7b2c\u4e00\u4e2a\u901a\u7528\u4e14\u9ad8\u6548\u7684\u795e\u7ecf\u8def\u7531\u6c42\u89e3\u5668\u7ea6\u675f\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5b66\u4e60\u53ef\u884c\u6027\u7cbe\u70bc\uff0c\u5728\u5904\u7406\u590d\u6742\u7ea6\u675f\u65f6\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.16553", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.16553", "abs": "https://arxiv.org/abs/2602.16553", "authors": ["Robert Ranisch", "Sabine Salloch"], "title": "Agentic AI, Medical Morality, and the Transformation of the Patient-Physician Relationship", "comment": "25 pages", "summary": "The emergence of agentic AI marks a new phase in the digital transformation of healthcare. Distinct from conventional generative AI, agentic AI systems are capable of autonomous, goal-directed actions and complex task coordination. They promise to support or even collaborate with clinicians and patients in increasingly independent ways. While agentic AI raises familiar moral concerns regarding safety, accountability, and bias, this article focuses on a less explored dimension: its capacity to transform the moral fabric of healthcare itself. Drawing on the framework of techno-moral change and the three domains of decision, relation and perception, we investigate how agentic AI might reshape the patient-physician relationship and reconfigure core concepts of medical morality. We argue that these shifts, while not fully predictable, demand ethical attention before widespread deployment. Ultimately, the paper calls for integrating ethical foresight into the design and use of agentic AI.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u667a\u80fd\u4f53AI\u5982\u4f55\u91cd\u5851\u533b\u7597\u4fdd\u5065\u7684\u9053\u5fb7\u7ed3\u6784\uff0c\u5f3a\u8c03\u9700\u8981\u5728\u5e7f\u6cdb\u90e8\u7f72\u524d\u8fdb\u884c\u4f26\u7406\u9884\u89c1", "motivation": "\u667a\u80fd\u4f53AI\u4f5c\u4e3a\u533b\u7597\u6570\u5b57\u5316\u7684\u65b0\u9636\u6bb5\uff0c\u4e0e\u4f20\u7edf\u751f\u6210\u5f0fAI\u4e0d\u540c\uff0c\u80fd\u591f\u81ea\u4e3b\u6267\u884c\u76ee\u6807\u5bfc\u5411\u884c\u52a8\u548c\u590d\u6742\u4efb\u52a1\u534f\u8c03\u3002\u867d\u7136\u5f15\u53d1\u4e86\u5b89\u5168\u3001\u95ee\u8d23\u548c\u504f\u89c1\u7b49\u5e38\u89c1\u9053\u5fb7\u95ee\u9898\uff0c\u4f46\u672c\u6587\u5173\u6ce8\u5176\u66f4\u5c11\u88ab\u63a2\u8ba8\u7684\u7ef4\u5ea6\uff1a\u6539\u53d8\u533b\u7597\u4fdd\u5065\u672c\u8eab\u7684\u9053\u5fb7\u7ed3\u6784", "method": "\u91c7\u7528\u6280\u672f-\u9053\u5fb7\u53d8\u9769\u6846\u67b6\uff0c\u4ece\u51b3\u7b56\u3001\u5173\u7cfb\u548c\u611f\u77e5\u4e09\u4e2a\u9886\u57df\u5206\u6790\u667a\u80fd\u4f53AI\u5982\u4f55\u91cd\u5851\u533b\u60a3\u5173\u7cfb\u548c\u91cd\u65b0\u914d\u7f6e\u533b\u7597\u9053\u5fb7\u6838\u5fc3\u6982\u5ff5", "result": "\u667a\u80fd\u4f53AI\u53ef\u80fd\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u533b\u7597\u9053\u5fb7\u7ed3\u6784\uff0c\u8fd9\u4e9b\u8f6c\u53d8\u867d\u4e0d\u5b8c\u5168\u53ef\u9884\u6d4b\uff0c\u4f46\u5728\u5e7f\u6cdb\u90e8\u7f72\u524d\u9700\u8981\u4f26\u7406\u5173\u6ce8", "conclusion": "\u5e94\u5c06\u4f26\u7406\u9884\u89c1\u6574\u5408\u5230\u667a\u80fd\u4f53AI\u7684\u8bbe\u8ba1\u548c\u4f7f\u7528\u4e2d\uff0c\u4ee5\u5e94\u5bf9\u5176\u5bf9\u533b\u7597\u9053\u5fb7\u7ed3\u6784\u7684\u6f5c\u5728\u91cd\u5851"}}
{"id": "2602.16432", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.16432", "abs": "https://arxiv.org/abs/2602.16432", "authors": ["Nilesh jain", "Rohit Yadav", "Andrej Karpathy"], "title": "Bibby AI -- AI Latex Editor writing assistant for researchers vs Overleaf Alternative vs OpenAI Prism. (Bibby AI Latex Editor)", "comment": null, "summary": "Large language models are increasingly integrated into academic writing workflows; however, the most widely used \\LaTeX\\ editors remain AI-peripheral -- offering compilation and collaboration, but no native intelligence. This separation forces researchers to leave their editing environment for AI assistance, fragmenting document context and interrupting writing flow. We present Bibby AI (trybibby.com), a native, AI-first \\LaTeX\\ editor that unifies the complete research writing lifecycle within a single interface. Bibby embeds an AI writing assistant, smart citation search, AI table and equation generation, an AI paper reviewer, abstract generator, literature review drafting, a deep research assistant, and real-time \\LaTeX\\ error detection and auto-fix -- all natively, without plugins or copy-paste workflows. We introduce LaTeXBench-500, a benchmark of 500 real-world compilation errors across six categories. Bibby achieves 91.4\\% detection accuracy and 83.7\\% one-click fix accuracy, outperforming Overleaf's native diagnostics (61.2\\%) and OpenAI Prism (78.3 / 64.1\\%) by large margins. Bibby demonstrates that a privacy-preserving, research-first AI editor can meaningfully accelerate every stage of academic manuscript preparation. We found that Bibby AI is a far superior alternative to overleaf latex and better than OpenAI Prism functionalities and AI.", "AI": {"tldr": "Bibby AI\u662f\u4e00\u6b3e\u539f\u751fAI\u4f18\u5148\u7684LaTeX\u7f16\u8f91\u5668\uff0c\u96c6\u6210\u4e86\u667a\u80fd\u5199\u4f5c\u52a9\u624b\u3001\u6587\u732e\u641c\u7d22\u3001\u8868\u683c\u516c\u5f0f\u751f\u6210\u3001\u8bba\u6587\u5ba1\u9605\u7b49\u529f\u80fd\uff0c\u5728LaTeX\u9519\u8bef\u68c0\u6d4b\u548c\u4fee\u590d\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684LaTeX\u7f16\u8f91\u5668\u7f3a\u4e4f\u539f\u751fAI\u652f\u6301\uff0c\u7814\u7a76\u4eba\u5458\u9700\u8981\u5728\u4e0d\u540c\u5de5\u5177\u95f4\u5207\u6362\uff0c\u5bfc\u81f4\u6587\u6863\u4e0a\u4e0b\u6587\u788e\u7247\u5316\u548c\u5199\u4f5c\u6d41\u7a0b\u4e2d\u65ad\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684AI\u4f18\u5148\u7814\u7a76\u5199\u4f5c\u5e73\u53f0\u3002", "method": "\u5f00\u53d1Bibby AI\u4f5c\u4e3a\u539f\u751fAI\u4f18\u5148\u7684LaTeX\u7f16\u8f91\u5668\uff0c\u96c6\u6210\u591a\u79cdAI\u529f\u80fd\uff1b\u521b\u5efaLaTeXBench-500\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b500\u4e2a\u771f\u5b9e\u7f16\u8bd1\u9519\u8bef\uff0c\u7528\u4e8e\u8bc4\u4f30\u9519\u8bef\u68c0\u6d4b\u548c\u4fee\u590d\u80fd\u529b\u3002", "result": "Bibby AI\u5728LaTeX\u9519\u8bef\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u523091.4%\uff0c\u4e00\u952e\u4fee\u590d\u51c6\u786e\u738783.7%\uff0c\u663e\u8457\u4f18\u4e8eOverleaf\u539f\u751f\u8bca\u65ad\uff0861.2%\uff09\u548cOpenAI Prism\uff0878.3%/64.1%\uff09\u3002", "conclusion": "Bibby AI\u8bc1\u660e\u4e86\u4e00\u4e2a\u6ce8\u91cd\u9690\u79c1\u3001\u4ee5\u7814\u7a76\u4e3a\u5148\u7684AI\u7f16\u8f91\u5668\u80fd\u591f\u663e\u8457\u52a0\u901f\u5b66\u672f\u624b\u7a3f\u51c6\u5907\u7684\u5404\u4e2a\u9636\u6bb5\uff0c\u662f\u6bd4Overleaf\u548cOpenAI Prism\u66f4\u4f18\u8d8a\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2602.16527", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.16527", "abs": "https://arxiv.org/abs/2602.16527", "authors": ["Piersilvio De Bortoli", "Davide Ferrari", "Francesco Ravazzolo", "Luca Rossini"], "title": "Model selection confidence sets for time series models with applications to electricity load data", "comment": null, "summary": "This paper studies the Model Selection Confidence Set (MSCS) methodology for univariate time series models involving autoregressive and moving average components, and applies it to study model selection uncertainty in the Italian electricity load data. Rather than relying on a single model selected by an arbitrary criterion, the MSCS identifies a set of models that are statistically indistinguishable from the true data-generating process at a given confidence level. The size and composition of this set reveal crucial information about model selection uncertainty: noisy data scenarios produce larger sets with many candidate models, while more informative cases narrow the set considerably. To study the importance of each model term, we consider numerical statistics measuring the frequency with which each term is included in both the entire MSCS and in Lower Boundary Models (LBM), its most parsimonious specifications. Applied to Italian hourly electricity load data, the MSCS methodology reveals marked intraday variation in model selection uncertainty and isolates a collection of model specifications that deliver competitive short-term forecasts while highlighting key drivers of electricity load like intraday hourly lags, temperature, calendar effects and solar energy generation.", "AI": {"tldr": "MSCS\u65b9\u6cd5\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u9009\u62e9\uff0c\u8bc6\u522b\u7edf\u8ba1\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u6a21\u578b\u96c6\u5408\uff0c\u5e94\u7528\u4e8e\u610f\u5927\u5229\u7535\u529b\u8d1f\u8377\u6570\u636e\uff0c\u63ed\u793a\u6a21\u578b\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\u548c\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u6807\u51c6\u9009\u62e9\u5355\u4e2a\u6a21\u578b\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7MSCS\u65b9\u6cd5\u91cf\u5316\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u7535\u529b\u8d1f\u8377\u9884\u6d4b\u4e2d\u8bc6\u522b\u7edf\u8ba1\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u5019\u9009\u6a21\u578b\u96c6\u5408\u3002", "method": "\u63d0\u51faModel Selection Confidence Set (MSCS)\u65b9\u6cd5\uff0c\u4e3a\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff08\u5305\u542b\u81ea\u56de\u5f52\u548c\u79fb\u52a8\u5e73\u5747\u5206\u91cf\uff09\u6784\u5efa\u7f6e\u4fe1\u96c6\u3002\u8be5\u65b9\u6cd5\u8bc6\u522b\u5728\u7ed9\u5b9a\u7f6e\u4fe1\u6c34\u5e73\u4e0b\u4e0e\u771f\u5b9e\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u7edf\u8ba1\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u6a21\u578b\u96c6\u5408\u3002\u901a\u8fc7\u5206\u6790\u96c6\u5408\u5927\u5c0f\u548c\u7ec4\u6210\u6765\u91cf\u5316\u6a21\u578b\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u4f7f\u7528\u6570\u503c\u7edf\u8ba1\u6d4b\u91cf\u6bcf\u4e2a\u6a21\u578b\u9879\u5728MSCS\u548cLower Boundary Models\u4e2d\u7684\u51fa\u73b0\u9891\u7387\u3002", "result": "\u5e94\u7528\u4e8e\u610f\u5927\u5229\u5c0f\u65f6\u7535\u529b\u8d1f\u8377\u6570\u636e\uff0cMSCS\u63ed\u793a\u4e86\u663e\u8457\u7684\u65e5\u5185\u6a21\u578b\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\u53d8\u5316\u3002\u8bc6\u522b\u51fa\u5305\u542b\u65e5\u5185\u5c0f\u65f6\u6ede\u540e\u3001\u6e29\u5ea6\u3001\u65e5\u5386\u6548\u5e94\u548c\u592a\u9633\u80fd\u53d1\u7535\u7b49\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u7684\u6a21\u578b\u96c6\u5408\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u77ed\u671f\u9884\u6d4b\u4e2d\u8868\u73b0\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "MSCS\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u5355\u4e00\u6a21\u578b\u9009\u62e9\u66f4\u4e30\u5bcc\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4fe1\u606f\u3002\u5728\u7535\u529b\u8d1f\u8377\u9884\u6d4b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u8bc6\u522b\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u8fd8\u63ed\u793a\u4e86\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u548c\u6a21\u578b\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\u7684\u65f6\u95f4\u53d8\u5316\u6a21\u5f0f\uff0c\u4e3a\u51b3\u7b56\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u4f9d\u636e\u3002"}}
{"id": "2602.16111", "categories": ["stat.AP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16111", "abs": "https://arxiv.org/abs/2602.16111", "authors": ["Zehao Xu", "Tony Paek", "Kevin O'Sullivan", "Attila Dobi"], "title": "Surrogate-Based Prevalence Measurement for Large-Scale A/B Testing", "comment": null, "summary": "Online media platforms often need to measure how frequently users are exposed to specific content attributes in order to evaluate trade-offs in A/B experiments. A direct approach is to sample content, label it using a high-quality rubric (e.g., an expert-reviewed LLM prompt), and estimate impression-weighted prevalence. However, repeatedly running such labeling for every experiment arm and segment is too costly and slow to serve as a default measurement at scale.\n  We present a scalable \\emph{surrogate-based prevalence measurement} framework that decouples expensive labeling from per-experiment evaluation. The framework calibrates a surrogate signal to reference labels offline and then uses only impression logs to estimate prevalence for arbitrary experiment arms and segments. We instantiate this framework using \\emph{score bucketing} as the surrogate: we discretize a model score into buckets, estimate bucket-level prevalences from an offline labeled sample, and combine these calibrated bucket level prevalences with the bucket distribution of impressions in each arm to obtain fast, log-based estimates.\n  Across multiple large-scale A/B tests, we validate that the surrogate estimates closely match the reference estimates for both arm-level prevalence and treatment--control deltas. This enables scalable, low-latency prevalence measurement in experimentation without requiring per-experiment labeling jobs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4ee3\u7406\u4fe1\u53f7\u7684\u6d41\u884c\u5ea6\u6d4b\u91cf\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u6821\u51c6\u4ee3\u7406\u4fe1\u53f7\u4e0e\u53c2\u8003\u6807\u7b7e\uff0c\u5b9e\u73b0\u65e0\u9700\u6bcf\u6b21\u5b9e\u9a8c\u6807\u6ce8\u7684\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684\u6d41\u884c\u5ea6\u6d4b\u91cf", "motivation": "\u5728\u7ebf\u5a92\u4f53\u5e73\u53f0\u9700\u8981\u6d4b\u91cf\u7528\u6237\u63a5\u89e6\u7279\u5b9a\u5185\u5bb9\u5c5e\u6027\u7684\u9891\u7387\u4ee5\u8bc4\u4f30A/B\u5b9e\u9a8c\u4e2d\u7684\u6743\u8861\u3002\u76f4\u63a5\u91c7\u6837\u6807\u6ce8\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u901f\u5ea6\u6162\uff0c\u65e0\u6cd5\u4f5c\u4e3a\u89c4\u6a21\u5316\u9ed8\u8ba4\u6d4b\u91cf\u65b9\u6848", "method": "\u63d0\u51fa\u4ee3\u7406\u57fa\u7840\u6d41\u884c\u5ea6\u6d4b\u91cf\u6846\u67b6\uff1a1) \u79bb\u7ebf\u6821\u51c6\u4ee3\u7406\u4fe1\u53f7\u4e0e\u53c2\u8003\u6807\u7b7e\uff1b2) \u4f7f\u7528\u5206\u6570\u5206\u6876\u4f5c\u4e3a\u4ee3\u7406\u4fe1\u53f7\uff0c\u5c06\u6a21\u578b\u5206\u6570\u79bb\u6563\u5316\u4e3a\u6876\uff1b3) \u4ece\u79bb\u7ebf\u6807\u6ce8\u6837\u672c\u4f30\u8ba1\u6876\u7ea7\u6d41\u884c\u5ea6\uff1b4) \u7ed3\u5408\u6821\u51c6\u6876\u7ea7\u6d41\u884c\u5ea6\u4e0e\u5404\u5b9e\u9a8c\u81c2\u7684\u6876\u5206\u5e03\uff0c\u83b7\u5f97\u57fa\u4e8e\u65e5\u5fd7\u7684\u5feb\u901f\u4f30\u8ba1", "result": "\u5728\u591a\u4e2a\u5927\u89c4\u6a21A/B\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\uff0c\u4ee3\u7406\u4f30\u8ba1\u4e0e\u53c2\u8003\u4f30\u8ba1\u5728\u81c2\u7ea7\u6d41\u884c\u5ea6\u548c\u5904\u7406-\u63a7\u5236\u5dee\u5f02\u65b9\u9762\u9ad8\u5ea6\u5339\u914d\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u4f4e\u5ef6\u8fdf\u7684\u6d41\u884c\u5ea6\u6d4b\u91cf", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u5b9e\u9a8c\u4e2d\u7684\u6d41\u884c\u5ea6\u6d4b\u91cf\u53d8\u5f97\u53ef\u6269\u5c55\u4e14\u4f4e\u5ef6\u8fdf\uff0c\u65e0\u9700\u6bcf\u6b21\u5b9e\u9a8c\u7684\u6807\u6ce8\u5de5\u4f5c\uff0c\u4e3a\u5728\u7ebf\u5e73\u53f0\u63d0\u4f9b\u9ad8\u6548\u7684\u6d4b\u91cf\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.16037", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16037", "abs": "https://arxiv.org/abs/2602.16037", "authors": ["Cameron Cagan", "Pedram Fard", "Jiazi Tian", "Jingya Cheng", "Shawn N. Murphy", "Hossein Estiri"], "title": "Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection", "comment": null, "summary": "Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog at 3%), we observed that validation sensitivity oscillated between 1.0 and 0.0 across iterations, with severity inversely proportional to class prevalence. At 3% prevalence, the system achieved 95% accuracy while detecting zero positive cases, a failure mode obscured by standard evaluation metrics. We evaluated two interventions: a guiding agent that actively redirected optimization, amplifying overfitting rather than correcting it, and a selector agent that retrospectively identified the best-performing iteration successfully prevented catastrophic failure. With selector agent oversight, the system outperformed expert-curated lexicons on brain fog detection by 331% (F1) and chest pain by 7%, despite requiring only a single natural language term as input. These findings characterize a critical failure mode of autonomous AI systems and demonstrate that retrospective selection outperforms active intervention for stabilization in low-prevalence classification tasks.", "AI": {"tldr": "\u81ea\u4e3b\u4ee3\u7406\u5de5\u4f5c\u6d41\u5728\u6301\u7eed\u4f18\u5316\u4e2d\u53ef\u80fd\u51fa\u73b0\u6027\u80fd\u9000\u5316\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u60a3\u75c5\u7387\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u9a8c\u8bc1\u654f\u611f\u5ea6\u4f1a\u57281.0\u548c0.0\u4e4b\u95f4\u632f\u8361\uff0c\u800c\u56de\u987e\u6027\u9009\u62e9\u6bd4\u4e3b\u52a8\u5e72\u9884\u66f4\u6709\u6548", "motivation": "\u7814\u7a76\u81ea\u4e3b\u4ee3\u7406\u5de5\u4f5c\u6d41\u5728\u6301\u7eed\u81ea\u6211\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u4f18\u5316\u4e0d\u7a33\u5b9a\u73b0\u8c61\u2014\u2014\u6301\u7eed\u81ea\u4e3b\u6539\u8fdb\u53cd\u800c\u964d\u4f4e\u5206\u7c7b\u5668\u6027\u80fd\u7684\u95ee\u9898", "method": "\u4f7f\u7528Pythia\u5f00\u6e90\u6846\u67b6\u8fdb\u884c\u81ea\u52a8\u63d0\u793a\u4f18\u5316\uff0c\u8bc4\u4f30\u4e09\u79cd\u4e0d\u540c\u60a3\u75c5\u7387\u7684\u4e34\u5e8a\u75c7\u72b6\uff08\u547c\u5438\u56f0\u96be23%\u3001\u80f8\u75db12%\u3001\u957f\u65b0\u51a0\u8111\u96fe3%\uff09\uff0c\u6d4b\u8bd5\u4e24\u79cd\u5e72\u9884\u63aa\u65bd\uff1a\u5f15\u5bfc\u4ee3\u7406\u4e3b\u52a8\u91cd\u5b9a\u5411\u4f18\u5316\u548c\u9009\u62e9\u4ee3\u7406\u56de\u987e\u6027\u8bc6\u522b\u6700\u4f73\u8fed\u4ee3", "result": "\u9a8c\u8bc1\u654f\u611f\u5ea6\u5728\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u57281.0\u548c0.0\u4e4b\u95f4\u632f\u8361\uff0c\u4e25\u91cd\u7a0b\u5ea6\u4e0e\u7c7b\u522b\u60a3\u75c5\u7387\u6210\u53cd\u6bd4\uff1b\u57283%\u60a3\u75c5\u7387\u65f6\uff0c\u7cfb\u7edf\u8fbe\u523095%\u51c6\u786e\u7387\u4f46\u68c0\u6d4b\u5230\u96f6\u9633\u6027\u75c5\u4f8b\uff1b\u9009\u62e9\u4ee3\u7406\u76d1\u7763\u4e0b\uff0c\u7cfb\u7edf\u5728\u8111\u96fe\u68c0\u6d4b\u4e0a\u6bd4\u4e13\u5bb6\u7b56\u5212\u8bcd\u5178\u9ad8\u51fa331%\uff08F1\uff09\uff0c\u80f8\u75db\u68c0\u6d4b\u9ad8\u51fa7%", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u5173\u952e\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u5728\u4f4e\u60a3\u75c5\u7387\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u56de\u987e\u6027\u9009\u62e9\u6bd4\u4e3b\u52a8\u5e72\u9884\u66f4\u80fd\u6709\u6548\u7a33\u5b9a\u7cfb\u7edf\u6027\u80fd"}}
{"id": "2602.16561", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.16561", "abs": "https://arxiv.org/abs/2602.16561", "authors": ["Roya Shomali", "Nick Freeman", "Greg Bott", "Iman Dayarian", "Jason Parton"], "title": "Hidden in Plain Sight: Detecting Illicit Massage Businesses from Mobility Data", "comment": "37 pages, 8 figures, 9 tables", "summary": "Illicit massage businesses (IMBs) masquerade as legitimate massage parlors while facilitating commercial sex and human trafficking. Law enforcement must identify these businesses within a dense population of lawful establishments, but investigative resources are limited and the illicit status of each location is unknown until inspection. Detection methods based on online reviews offer some insight, yet operators can manipulate these signals, leaving covert establishments undetected. IMBs constitute one of the largest segments of indoor sex trafficking in the United States, with an estimated 9,000 establishments. Mobility data offers an alternative to online signals, covering establishments that avoid digital visibility entirely. We derive features from mobility data spanning temporal visitation patterns, dwell times, visitor catchment areas, and demand stability. Because confirmed labels exist only for establishments identified through advertising platforms, we employ positive-unlabeled learning to address the label asymmetry in ground truth. The model achieves 0.97 AUC and 0.84 Average Precision. Four operational signatures characterize high-risk establishments: demand consistency, evening-concentrated visits, compressed service durations, and locally drawn clientele. The model produces risk scores for each business-week observation. Aggregating to the business level, prioritizing the highest-risk 10% of massage establishments captures 53% of known illicit operations, a 5.3-fold improvement over uninformed inspection. We develop a decision-support system that produces calibrated prioritization scores for law enforcement, enabling investigators to concentrate inspections on the highest-risk venues. The operational signatures may resist strategic manipulation because they reflect actual operations rather than online signals that operators can control.", "AI": {"tldr": "\u5229\u7528\u79fb\u52a8\u6570\u636e\u68c0\u6d4b\u975e\u6cd5\u6309\u6469\u5e97\uff0c\u901a\u8fc7\u6b63\u4f8b-\u672a\u6807\u8bb0\u5b66\u4e60\u89e3\u51b3\u6807\u7b7e\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u6a21\u578bAUC\u8fbe0.97\uff0c\u8bc6\u522b\u51fa\u56db\u5927\u8fd0\u8425\u7279\u5f81\uff0c\u4e3a\u6267\u6cd5\u90e8\u95e8\u63d0\u4f9b\u98ce\u9669\u8bc4\u5206\u7cfb\u7edf", "motivation": "\u975e\u6cd5\u6309\u6469\u5e97(IMBs)\u4f2a\u88c5\u6210\u5408\u6cd5\u6309\u6469\u5e97\u4ece\u4e8b\u6027\u4ea4\u6613\u548c\u4eba\u53e3\u8d29\u5356\uff0c\u662f\u7f8e\u56fd\u5ba4\u5185\u6027\u4ea4\u6613\u7684\u6700\u5927\u7ec4\u6210\u90e8\u5206\u3002\u4f20\u7edf\u57fa\u4e8e\u5728\u7ebf\u8bc4\u8bba\u7684\u68c0\u6d4b\u65b9\u6cd5\u5bb9\u6613\u88ab\u64cd\u7eb5\uff0c\u4e14\u8bb8\u591a\u573a\u6240\u5b8c\u5168\u907f\u514d\u6570\u5b57\u53ef\u89c1\u6027\u3002\u6267\u6cd5\u8d44\u6e90\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u79fb\u52a8\u6570\u636e\u63d0\u53d6\u7279\u5f81\uff1a\u65f6\u95f4\u8bbf\u95ee\u6a21\u5f0f\u3001\u505c\u7559\u65f6\u95f4\u3001\u8bbf\u5ba2\u6765\u6e90\u533a\u57df\u3001\u9700\u6c42\u7a33\u5b9a\u6027\u3002\u91c7\u7528\u6b63\u4f8b-\u672a\u6807\u8bb0\u5b66\u4e60\u89e3\u51b3\u6807\u7b7e\u4e0d\u5bf9\u79f0\u95ee\u9898\uff08\u53ea\u6709\u901a\u8fc7\u5e7f\u544a\u5e73\u53f0\u786e\u8ba4\u7684\u975e\u6cd5\u573a\u6240\u6807\u7b7e\uff09\u3002\u5f00\u53d1\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e3a\u6267\u6cd5\u90e8\u95e8\u63d0\u4f9b\u6821\u51c6\u7684\u98ce\u9669\u8bc4\u5206\u3002", "result": "\u6a21\u578b\u8fbe\u52300.97 AUC\u548c0.84\u5e73\u5747\u7cbe\u5ea6\u3002\u8bc6\u522b\u51fa\u56db\u5927\u8fd0\u8425\u7279\u5f81\uff1a\u9700\u6c42\u4e00\u81f4\u6027\u3001\u665a\u95f4\u96c6\u4e2d\u8bbf\u95ee\u3001\u538b\u7f29\u670d\u52a1\u65f6\u957f\u3001\u672c\u5730\u5ba2\u6237\u6765\u6e90\u3002\u5728\u6700\u9ad8\u98ce\u966910%\u7684\u6309\u6469\u5e97\u4e2d\u6355\u83b753%\u7684\u5df2\u77e5\u975e\u6cd5\u8fd0\u8425\uff0c\u6bd4\u65e0\u4fe1\u606f\u68c0\u67e5\u63d0\u9ad85.3\u500d\u3002", "conclusion": "\u79fb\u52a8\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u975e\u6cd5\u6309\u6469\u5e97\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5176\u8fd0\u8425\u7279\u5f81\u96be\u4ee5\u88ab\u64cd\u7eb5\u3002\u6a21\u578b\u4e3a\u6267\u6cd5\u90e8\u95e8\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u68c0\u67e5\u6548\u7387\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u9690\u853d\u7684\u975e\u6cd5\u6d3b\u52a8\u68c0\u6d4b\u3002"}}
{"id": "2602.16195", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.16195", "abs": "https://arxiv.org/abs/2602.16195", "authors": ["Sebin Oh", "Jinyan Zhao", "Raul Rincon", "Jamie E. Padgett", "Ziqi Wang"], "title": "Phase Transitions in Collective Damage of Civil Structures under Natural Hazards", "comment": null, "summary": "The fate of cities under natural hazards depends not only on hazard intensity but also on the coupling of structural damage, a collective process that remains poorly understood. Here we show that urban structural damage exhibits phase-transition phenomena. As hazard intensity increases, the system can shift abruptly from a largely safe to a largely damaged state, analogous to a first-order phase transition in statistical physics. Higher diversity in the building portfolio smooths this transition, but multiscale damage clustering traps the system in an extended critical-like regime (analogous to a Griffiths phase), suppressing the emergence of a more predictable disordered (Gaussian) phase. These phenomenological patterns are characterized by a random-field Ising model, with the external field, disorder strength, and temperature interpreted as the effective hazard demand, structural diversity, and modeling uncertainty, respectively. Applying this framework to real urban inventories reveals that widely used engineering modeling practices can shift urban damage patterns between synchronized and volatile regimes, systematically biasing exceedance-based risk metrics by up to 50% under moderate earthquakes ($M_w \\approx 5.5$--$6.0$), equivalent to a several-fold gap in repair costs. This phase-aware description turns the collective behavior of civil infrastructure damage into actionable diagnostics for urban risk assessment and planning.", "AI": {"tldr": "\u57ce\u5e02\u7ed3\u6784\u635f\u4f24\u5728\u81ea\u7136\u707e\u5bb3\u4e0b\u5448\u73b0\u76f8\u53d8\u73b0\u8c61\uff0c\u7c7b\u4f3c\u4e8e\u7edf\u8ba1\u7269\u7406\u5b66\u4e2d\u7684\u4e00\u7ea7\u76f8\u53d8\uff0c\u635f\u4f24\u6a21\u5f0f\u53d7\u5efa\u7b51\u591a\u6837\u6027\u548c\u591a\u5c3a\u5ea6\u805a\u7c7b\u5f71\u54cd\uff0c\u4f20\u7edf\u5de5\u7a0b\u5efa\u6a21\u65b9\u6cd5\u4f1a\u7cfb\u7edf\u6027\u504f\u5dee\u98ce\u9669\u6307\u6807\u8fbe50%\u3002", "motivation": "\u57ce\u5e02\u5728\u81ea\u7136\u707e\u5bb3\u4e0b\u7684\u547d\u8fd0\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u707e\u5bb3\u5f3a\u5ea6\uff0c\u8fd8\u53d6\u51b3\u4e8e\u7ed3\u6784\u635f\u4f24\u7684\u8026\u5408\u8fc7\u7a0b\uff0c\u8fd9\u662f\u4e00\u4e2a\u96c6\u4f53\u8fc7\u7a0b\uff0c\u76ee\u524d\u7406\u89e3\u4e0d\u8db3\u3002\u9700\u8981\u7406\u89e3\u57ce\u5e02\u7ed3\u6784\u635f\u4f24\u7684\u96c6\u4f53\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528\u968f\u673a\u573a\u4f0a\u8f9b\u6a21\u578b\u6765\u63cf\u8ff0\u57ce\u5e02\u7ed3\u6784\u635f\u4f24\u73b0\u8c61\uff0c\u5c06\u5916\u90e8\u573a\u3001\u65e0\u5e8f\u5f3a\u5ea6\u548c\u6e29\u5ea6\u5206\u522b\u89e3\u91ca\u4e3a\u6709\u6548\u707e\u5bb3\u9700\u6c42\u3001\u7ed3\u6784\u591a\u6837\u6027\u548c\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u3002\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u771f\u5b9e\u57ce\u5e02\u5e93\u5b58\u6570\u636e\u3002", "result": "\u57ce\u5e02\u7ed3\u6784\u635f\u4f24\u5448\u73b0\u76f8\u53d8\u73b0\u8c61\uff1a\u968f\u7740\u707e\u5bb3\u5f3a\u5ea6\u589e\u52a0\uff0c\u7cfb\u7edf\u4f1a\u4ece\u5b89\u5168\u72b6\u6001\u6025\u5267\u8f6c\u53d8\u4e3a\u635f\u4f24\u72b6\u6001\uff08\u4e00\u7ea7\u76f8\u53d8\uff09\u3002\u5efa\u7b51\u591a\u6837\u6027\u8d8a\u9ad8\uff0c\u76f8\u53d8\u8d8a\u5e73\u6ed1\uff1b\u591a\u5c3a\u5ea6\u635f\u4f24\u805a\u7c7b\u4f7f\u7cfb\u7edf\u9677\u5165\u6269\u5c55\u7684\u4e34\u754c\u72b6\u6001\uff08Griffiths\u76f8\uff09\uff0c\u6291\u5236\u53ef\u9884\u6d4b\u7684\u65e0\u5e8f\u76f8\u51fa\u73b0\u3002\u4f20\u7edf\u5de5\u7a0b\u5efa\u6a21\u65b9\u6cd5\u4f1a\u4f7f\u57ce\u5e02\u635f\u4f24\u6a21\u5f0f\u5728\u540c\u6b65\u548c\u6ce2\u52a8\u72b6\u6001\u4e4b\u95f4\u8f6c\u53d8\uff0c\u5728\u4e2d\u7b49\u5730\u9707\u4e0b\u7cfb\u7edf\u6027\u504f\u5dee\u98ce\u9669\u6307\u6807\u8fbe50%\uff0c\u76f8\u5f53\u4e8e\u4fee\u590d\u6210\u672c\u6570\u500d\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8fd9\u79cd\u76f8\u611f\u77e5\u63cf\u8ff0\u5c06\u6c11\u7528\u57fa\u7840\u8bbe\u65bd\u635f\u4f24\u7684\u96c6\u4f53\u884c\u4e3a\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u7528\u4e8e\u57ce\u5e02\u98ce\u9669\u8bc4\u4f30\u548c\u89c4\u5212\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u5efa\u6a21\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u66f4\u51c6\u786e\u7684\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002"}}
{"id": "2602.16039", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16039", "abs": "https://arxiv.org/abs/2602.16039", "authors": ["Hang Li", "Kaiqi Yang", "Xianxuan Long", "Fedor Filippov", "Yucheng Chu", "Yasemin Copur-Gencturk", "Peng He", "Cory Miller", "Namsoo Shin", "Joseph Krajcik", "Hui Liu", "Jiliang Tang"], "title": "How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment", "comment": null, "summary": "The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\u3001\u5f71\u54cd\u56e0\u7d20\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u81ea\u52a8\u8bc4\u4f30\u4e2d\u5c55\u73b0\u51fa\u4f18\u52bf\uff0c\u4f46\u5176\u56fa\u6709\u7684\u6982\u7387\u6027\u672c\u8d28\u5e26\u6765\u4e86\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\u3002\u8bc4\u4f30\u7ed3\u679c\u5bf9\u540e\u7eed\u6559\u5b66\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4e0d\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u53ef\u80fd\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u7684\u6559\u5b66\u5e72\u9884\uff0c\u5f71\u54cd\u5b66\u751f\u5b66\u4e60\u3002\u76ee\u524d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u5728\u6559\u80b2\u8bc4\u4f30\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u548c\u53ef\u9760\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5728\u591a\u8bc4\u4f30\u6570\u636e\u96c6\u3001LLM\u5bb6\u65cf\u548c\u751f\u6210\u63a7\u5236\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff0c\u57fa\u51c6\u6d4b\u8bd5\u4e86\u5e7f\u6cdb\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002\u7814\u7a76\u4e86LLM\u5728\u8bc4\u5206\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u5bb6\u65cf\u3001\u8bc4\u4f30\u4efb\u52a1\u548c\u89e3\u7801\u7b56\u7565\u7b49\u5173\u952e\u56e0\u7d20\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u81ea\u52a8\u8bc4\u5206\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u884c\u4e3a\u6a21\u5f0f\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u7684\u6027\u80fd\u548c\u5c40\u9650\u6027\uff0c\u5206\u6790\u4e86\u6a21\u578b\u5bb6\u65cf\u3001\u4efb\u52a1\u7c7b\u578b\u548c\u89e3\u7801\u7b56\u7565\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u7cfb\u7edf\u6027\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3LLM\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u7279\u5f81\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bc4\u5206\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.16703", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16703", "abs": "https://arxiv.org/abs/2602.16703", "authors": ["Shen Zhou Hong", "Alex Kleinman", "Alyssa Mathiowetz", "Adam Howes", "Julian Cohen", "Suveer Ganta", "Alex Letizia", "Dora Liao", "Deepika Pahari", "Xavier Roberts-Gaal", "Luca Righetti", "Joe Torres"], "title": "Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology", "comment": null, "summary": "Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153) evaluating whether LLMs improve novice performance in tasks that collectively model a viral reverse genetics workflow. We observed no significant difference in the primary endpoint of workflow completion (5.2% LLM vs. 6.6% Internet; P = 0.759), nor in the success rate of individual tasks. However, the LLM arm had numerically higher success rates in four of the five tasks, most notably for the cell culture task (68.8% LLM vs. 55.3% Internet; P = 0.059). Post-hoc Bayesian modeling of pooled data estimates an approximate 1.4-fold increase (95% CrI 0.74-2.62) in success for a \"typical\" reverse genetics task under LLM assistance. Ordinal regression modelling suggests that participants in the LLM arm were more likely to progress through intermediate steps across all tasks (posterior probability of a positive effect: 81%-96%). Overall, mid-2025 LLMs did not substantially increase novice completion of complex laboratory procedures but were associated with a modest performance benefit. These results reveal a gap between in silico benchmarks and real-world utility, underscoring the need for physical-world validation of AI biosecurity assessments as model capabilities and user proficiency evolve.", "AI": {"tldr": "LLMs\u5728\u751f\u7269\u5b89\u5168\u8bc4\u4f30\u4e2d\u663e\u793a\u51fa\u6709\u9650\u7684\u5b9e\u9a8c\u5ba4\u64cd\u4f5c\u63d0\u5347\u6548\u679c\uff0c\u867d\u7136\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u6709\u6570\u503c\u4f18\u52bf\uff0c\u4f46\u672a\u663e\u8457\u63d0\u9ad8\u65b0\u624b\u5b8c\u6210\u590d\u6742\u5b9e\u9a8c\u5ba4\u6d41\u7a0b\u7684\u80fd\u529b", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u7684\u80fd\u5e2e\u52a9\u65b0\u624b\u5728\u7269\u7406\u5b9e\u9a8c\u5ba4\u4e2d\u6267\u884c\u53cc\u91cd\u7528\u9014\u7684\u751f\u7269\u6280\u672f\u64cd\u4f5c\uff0c\u9a8c\u8bc1AI\u751f\u7269\u5b89\u5168\u8bc4\u4f30\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6709\u6548\u6027", "method": "\u91c7\u7528\u9884\u6ce8\u518c\u3001\u7814\u7a76\u8005\u76f2\u6cd5\u3001\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u8bbe\u8ba1\uff0c\u62db\u52df153\u540d\u53c2\u4e0e\u8005\uff0c\u6bd4\u8f83LLM\u8f85\u52a9\u4e0e\u4e92\u8054\u7f51\u641c\u7d22\u5728\u6a21\u62df\u75c5\u6bd2\u53cd\u5411\u9057\u4f20\u5b66\u5de5\u4f5c\u6d41\u7a0b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "result": "\u5de5\u4f5c\u6d41\u7a0b\u5b8c\u6210\u7387\u65e0\u663e\u8457\u5dee\u5f02\uff08LLM 5.2% vs \u4e92\u8054\u7f51 6.6%\uff09\uff0c\u4f46LLM\u7ec4\u57284/5\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u6570\u503c\u66f4\u9ad8\uff0c\u7279\u522b\u662f\u7ec6\u80de\u57f9\u517b\u4efb\u52a1\uff0868.8% vs 55.3%\uff09\u3002\u8d1d\u53f6\u65af\u6a21\u578b\u4f30\u8ba1LLM\u8f85\u52a9\u4e0b\u5178\u578b\u4efb\u52a1\u6210\u529f\u7387\u7ea6\u63d0\u9ad81.4\u500d", "conclusion": "2025\u5e74\u4e2d\u671f\u7684LLMs\u5e76\u672a\u663e\u8457\u63d0\u5347\u65b0\u624b\u5b8c\u6210\u590d\u6742\u5b9e\u9a8c\u5ba4\u7a0b\u5e8f\u7684\u80fd\u529b\uff0c\u4f46\u663e\u793a\u51fa\u9002\u5ea6\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u63ed\u793a\u4e86AI\u751f\u7269\u5b89\u5168\u8bc4\u4f30\u5728\u865a\u62df\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u73b0\u5b9e\u6548\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd"}}
{"id": "2602.16583", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.16583", "abs": "https://arxiv.org/abs/2602.16583", "authors": ["Yuezhou Zhang", "Amos Folarin", "Hugh Logan Ellis", "Rongrong Zhong", "Callum Stewart", "Heet Sankesara", "Hyunju Kim", "Shaoxiong Sun", "Abhishek Pratap", "Richard JB Dobson"], "title": "Physical Activity Trajectories Preceding Incident Major Depressive Disorder Diagnosis Using Consumer Wearable Devices in the All of Us Research Program: Case-Control Study", "comment": null, "summary": "Low physical activity is a known risk factor for major depressive disorder (MDD), but changes in activity before a first clinical diagnosis remain unclear, especially using long-term objective measurements. This study characterized trajectories of wearable-measured physical activity during the year preceding incident MDD diagnosis.\n  We conducted a retrospective nested case-control study using linked electronic health record and Fitbit data from the All of Us Research Program. Adults with at least 6 months of valid wearable data in the year before diagnosis were eligible. Incident MDD cases were matched to controls on age, sex, body mass index, and index time (up to four controls per case). Daily step counts and moderate-to-vigorous physical activity (MVPA) were aggregated into monthly averages. Linear mixed-effects models compared trajectories from 12 months before diagnosis to diagnosis. Within cases, contrasts identified when activity first significantly deviated from levels 12 months prior.\n  The cohort included 4,104 participants (829 cases and 3,275 controls; 81.7% women; median age 48.4 years). Compared with controls, cases showed consistently lower activity and significant downward trajectories in both step counts and MVPA during the year before diagnosis (P < 0.001). Significant declines appeared about 4 months before diagnosis for step counts and 5 months for MVPA. Exploratory analyses suggested subgroup differences, including steeper declines in men, greater intensity reductions at older ages, and persistently low activity among individuals with obesity.\n  Sustained within-person declines in physical activity emerged months before incident MDD diagnosis. Longitudinal wearable monitoring may provide early signals to support risk stratification and earlier intervention.", "AI": {"tldr": "\u901a\u8fc7\u53ef\u7a7f\u6234\u8bbe\u5907\u6570\u636e\u53d1\u73b0\uff0c\u5728\u9996\u6b21\u88ab\u8bca\u65ad\u4e3a\u91cd\u5ea6\u6291\u90c1\u75c7\u524d4-5\u4e2a\u6708\uff0c\u60a3\u8005\u7684\u8eab\u4f53\u6d3b\u52a8\u6c34\u5e73\u5c31\u5f00\u59cb\u663e\u8457\u4e0b\u964d\uff0c\u8fd9\u4e3a\u65e9\u671f\u98ce\u9669\u8bc6\u522b\u63d0\u4f9b\u4e86\u5ba2\u89c2\u6307\u6807\u3002", "motivation": "\u867d\u7136\u4f4e\u8eab\u4f53\u6d3b\u52a8\u662f\u91cd\u5ea6\u6291\u90c1\u75c7\u7684\u5df2\u77e5\u98ce\u9669\u56e0\u7d20\uff0c\u4f46\u5728\u9996\u6b21\u4e34\u5e8a\u8bca\u65ad\u524d\u8eab\u4f53\u6d3b\u52a8\u7684\u53d8\u5316\u6a21\u5f0f\u5c1a\u4e0d\u6e05\u695a\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u957f\u671f\u5ba2\u89c2\u6d4b\u91cf\u6570\u636e\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u53ef\u7a7f\u6234\u8bbe\u5907\u6570\u636e\uff0c\u63ed\u793a\u5728\u9996\u6b21MDD\u8bca\u65ad\u524d\u4e00\u5e74\u5185\u8eab\u4f53\u6d3b\u52a8\u7684\u8f68\u8ff9\u53d8\u5316\u3002", "method": "\u91c7\u7528\u56de\u987e\u6027\u5de2\u5f0f\u75c5\u4f8b\u5bf9\u7167\u7814\u7a76\u8bbe\u8ba1\uff0c\u5229\u7528\"All of Us\u7814\u7a76\u8ba1\u5212\"\u4e2d\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548cFitbit\u6570\u636e\u3002\u7eb3\u5165\u5728\u8bca\u65ad\u524d\u4e00\u5e74\u81f3\u5c11\u67096\u4e2a\u6708\u6709\u6548\u53ef\u7a7f\u6234\u6570\u636e\u7684\u6210\u5e74\u4eba\u3002\u5c06829\u4f8b\u65b0\u53d1MDD\u75c5\u4f8b\u4e0e3,275\u4f8b\u5bf9\u7167\u6309\u5e74\u9f84\u3001\u6027\u522b\u3001BMI\u548c\u7d22\u5f15\u65f6\u95f4\u5339\u914d\u3002\u5c06\u6bcf\u65e5\u6b65\u6570\u548c\u4e2d\u7b49\u81f3\u5267\u70c8\u8eab\u4f53\u6d3b\u52a8(MVPA)\u6c47\u603b\u4e3a\u6708\u5e73\u5747\u503c\uff0c\u4f7f\u7528\u7ebf\u6027\u6df7\u5408\u6548\u5e94\u6a21\u578b\u6bd4\u8f83\u4ece\u8bca\u65ad\u524d12\u4e2a\u6708\u5230\u8bca\u65ad\u65f6\u7684\u6d3b\u52a8\u8f68\u8ff9\u3002", "result": "\u4e0e\u5bf9\u7167\u7ec4\u76f8\u6bd4\uff0c\u75c5\u4f8b\u7ec4\u5728\u8bca\u65ad\u524d\u4e00\u5e74\u5185\u8868\u73b0\u51fa\u6301\u7eed\u8f83\u4f4e\u7684\u6d3b\u52a8\u6c34\u5e73\uff0c\u4e14\u6b65\u6570\u548cMVPA\u5747\u5448\u73b0\u663e\u8457\u4e0b\u964d\u8d8b\u52bf(P<0.001)\u3002\u6b65\u6570\u5728\u8bca\u65ad\u524d\u7ea64\u4e2a\u6708\u5f00\u59cb\u663e\u8457\u4e0b\u964d\uff0cMVPA\u5728\u8bca\u65ad\u524d\u7ea65\u4e2a\u6708\u5f00\u59cb\u663e\u8457\u4e0b\u964d\u3002\u63a2\u7d22\u6027\u5206\u6790\u663e\u793a\u5b58\u5728\u4e9a\u7ec4\u5dee\u5f02\uff1a\u7537\u6027\u4e0b\u964d\u66f4\u9661\u5ced\uff0c\u5e74\u9f84\u8f83\u5927\u8005\u5f3a\u5ea6\u4e0b\u964d\u66f4\u5927\uff0c\u80a5\u80d6\u4e2a\u4f53\u6d3b\u52a8\u6c34\u5e73\u6301\u7eed\u8f83\u4f4e\u3002", "conclusion": "\u5728\u9996\u6b21MDD\u8bca\u65ad\u524d\u6570\u6708\uff0c\u4e2a\u4f53\u8eab\u4f53\u6d3b\u52a8\u6c34\u5e73\u5df2\u51fa\u73b0\u6301\u7eed\u4e0b\u964d\u3002\u7eb5\u5411\u53ef\u7a7f\u6234\u8bbe\u5907\u76d1\u6d4b\u53ef\u80fd\u63d0\u4f9b\u65e9\u671f\u4fe1\u53f7\uff0c\u6709\u52a9\u4e8e\u98ce\u9669\u5206\u5c42\u548c\u65e9\u671f\u5e72\u9884\u3002"}}
{"id": "2602.16050", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16050", "abs": "https://arxiv.org/abs/2602.16050", "authors": ["Amir Hosseinian", "MohammadReza Zare Shahneh", "Umer Mansoor", "Gilbert Szeto", "Kirill Karlin", "Nima Aghaeepour"], "title": "Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination", "comment": null, "summary": "Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corpus with a structured reasoning architecture to generate evidence-linked outputs. Mirror operated under a closed-evidence constraint without external retrieval. Comparator LLMs had real-time web access to guidelines and primary literature. Results: Mirror achieved 87.5% accuracy (105/120; 95% CI: 80.4-92.3%), exceeding a human reference of 62.3% and frontier LLMs including GPT-5.2 (74.6%), GPT-5 (74.0%), and Gemini-3-Pro (69.8%). On the 30 most difficult questions (human accuracy less than 50%), Mirror achieved 76.7% accuracy. Top-2 accuracy was 92.5% for Mirror versus 85.25% for GPT-5.2. Conclusions: Mirror provided evidence traceability: 74.2% of outputs cited at least one guideline-tier source, with 100% citation accuracy on manual verification. Curated evidence with explicit provenance can outperform unconstrained web retrieval for subspecialty clinical reasoning and supports auditability for clinical deployment.", "AI": {"tldr": "January Mirror\u7cfb\u7edf\u5728120\u9053\u5185\u5206\u6ccc\u5b66\u8003\u8bd5\u4e2d\u8fbe\u523087.5%\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u4eba\u7c7b\u53c2\u8003(62.3%)\u548c\u524d\u6cbfLLMs\uff0c\u8bc1\u660e\u8bc1\u636e\u6eaf\u6e90\u7cfb\u7edf\u5728\u4e13\u79d1\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u4f18\u52bf", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u666e\u901a\u533b\u5b66\u8003\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u4e13\u79d1\u4e34\u5e8a\u63a8\u7406\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u4e13\u79d1\u6307\u5357\u66f4\u65b0\u5feb\u4e14\u8bc1\u636e\u5c42\u6b21\u590d\u6742\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6574\u5408\u4e13\u4e1a\u8bc1\u636e\u5e93\u7684\u4e34\u5e8a\u63a8\u7406\u7cfb\u7edf\u3002", "method": "\u5f00\u53d1January Mirror\u7cfb\u7edf\uff0c\u6574\u5408\u7cbe\u9009\u7684\u5185\u5206\u6ccc\u548c\u5fc3\u810f\u4ee3\u8c22\u8bc1\u636e\u5e93\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u63a8\u7406\u67b6\u6784\u751f\u6210\u8bc1\u636e\u94fe\u63a5\u8f93\u51fa\u3002\u5728\u5c01\u95ed\u8bc1\u636e\u7ea6\u675f\u4e0b\u8fd0\u884c\uff0c\u4e0e\u5177\u6709\u5b9e\u65f6\u7f51\u7edc\u8bbf\u95ee\u6743\u9650\u7684\u524d\u6cbfLLMs(GPT-5\u3001GPT-5.2\u3001Gemini-3-Pro)\u5728120\u9053\u5185\u5206\u6ccc\u5b66\u8003\u8bd5\u4e2d\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "Mirror\u8fbe\u523087.5%\u51c6\u786e\u7387\uff0c\u663e\u8457\u8d85\u8fc7\u4eba\u7c7b\u53c2\u8003(62.3%)\u548c\u6240\u6709\u524d\u6cbfLLMs\u3002\u5728\u6700\u96be\u768430\u9053\u9898\u4e2d\u8fbe\u523076.7%\u51c6\u786e\u7387\u300274.2%\u7684\u8f93\u51fa\u5f15\u7528\u4e86\u6307\u5357\u7ea7\u8bc1\u636e\u6e90\uff0c\u4e14\u5f15\u7528\u51c6\u786e\u7387100%\u3002", "conclusion": "\u5177\u6709\u660e\u786e\u6eaf\u6e90\u7684\u7cbe\u9009\u8bc1\u636e\u7cfb\u7edf\u5728\u4e13\u79d1\u4e34\u5e8a\u63a8\u7406\u4e2d\u4f18\u4e8e\u65e0\u7ea6\u675f\u7684\u7f51\u7edc\u68c0\u7d22\uff0c\u652f\u6301\u4e34\u5e8a\u90e8\u7f72\u7684\u53ef\u5ba1\u8ba1\u6027\u3002\u8bc1\u636e\u6eaf\u6e90\u80fd\u529b\u5bf9\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.16666", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16666", "abs": "https://arxiv.org/abs/2602.16666", "authors": ["Stephan Rabanser", "Sayash Kapoor", "Peter Kirgis", "Kangheng Liu", "Saiteja Utpala", "Arvind Narayanan"], "title": "Towards a Science of AI Agent Reliability", "comment": null, "summary": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa12\u4e2a\u5177\u4f53\u6307\u6807\uff0c\u4ece\u4e00\u81f4\u6027\u3001\u9c81\u68d2\u6027\u3001\u53ef\u9884\u6d4b\u6027\u548c\u5b89\u5168\u6027\u56db\u4e2a\u7ef4\u5ea6\u5206\u89e3AI\u4ee3\u7406\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u80fd\u529b\u63d0\u5347\u5bf9\u53ef\u9760\u6027\u6539\u5584\u6709\u9650", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u8bc4\u4f30\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff1a\u5c06\u4ee3\u7406\u884c\u4e3a\u538b\u7f29\u4e3a\u5355\u4e00\u6210\u529f\u7387\u6307\u6807\u4f1a\u63a9\u76d6\u5173\u952e\u7684\u64cd\u4f5c\u7f3a\u9677\uff0c\u65e0\u6cd5\u8bc4\u4f30\u4ee3\u7406\u5728\u4e0d\u540c\u8fd0\u884c\u4e2d\u7684\u4e00\u81f4\u6027\u3001\u6297\u5e72\u6270\u80fd\u529b\u3001\u5931\u8d25\u53ef\u9884\u6d4b\u6027\u6216\u9519\u8bef\u4e25\u91cd\u7a0b\u5ea6", "method": "\u57fa\u4e8e\u5b89\u5168\u5173\u952e\u5de5\u7a0b\u539f\u7406\uff0c\u63d0\u51fa12\u4e2a\u5177\u4f53\u6307\u6807\uff0c\u4ece\u4e00\u81f4\u6027\u3001\u9c81\u68d2\u6027\u3001\u53ef\u9884\u6d4b\u6027\u548c\u5b89\u5168\u6027\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\u5206\u89e3\u4ee3\u7406\u53ef\u9760\u6027\uff0c\u5e76\u5728\u4e24\u4e2a\u4e92\u8865\u57fa\u51c6\u4e0a\u8bc4\u4f3014\u4e2a\u4ee3\u7406\u6a21\u578b", "result": "\u7814\u7a76\u53d1\u73b0\u6700\u8fd1\u7684\u80fd\u529b\u63d0\u5347\u4ec5\u5e26\u6765\u53ef\u9760\u6027\u65b9\u9762\u7684\u5fae\u5c0f\u6539\u5584\uff0c\u66b4\u9732\u4e86\u4ee3\u7406\u7684\u6301\u7eed\u5c40\u9650\u6027", "conclusion": "\u63d0\u51fa\u7684\u6307\u6807\u8865\u5145\u4e86\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3a\u7406\u89e3\u4ee3\u7406\u5982\u4f55\u6267\u884c\u3001\u9000\u5316\u548c\u5931\u8d25\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u66f4\u5168\u9762\u5730\u8bc4\u4f30AI\u4ee3\u7406\u7684\u53ef\u9760\u6027"}}
{"id": "2602.16616", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.16616", "abs": "https://arxiv.org/abs/2602.16616", "authors": ["Byran Smucker", "Benjamin Brennan", "Emily Rego", "Meng Wu", "Zhihong Lin", "Brian Ahmer", "Blake Peterson"], "title": "Design and Analysis Strategies for Pooling in High Throughput Screening: Application to the Search for a New Anti-Microbial", "comment": null, "summary": "A major public health issue is the growing resistance of bacteria to antibiotics. An important part of the needed response is the discovery and development of new antimicrobial strategies. These require the screening of potential new drugs, typically accomplished using high-throughput screening (HTS). Traditionally, HTS is performed by examining one compound per well, but a more efficient strategy pools multiple compounds per well. In this work, we study several recently proposed pooling construction methods, as well as a variety of pooled high-throughput screening analysis methods, in order to provide guidance to practitioners on which methods to use. This is done in the context of an application of the methods to the search for new drugs to combat bacterial infection. We discuss both an extensive pilot study as well as a small screening campaign, and highlight both the successes and challenges of the pooling approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6297\u83cc\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5316\u5408\u7269\u6c60\u5316\u7b5b\u9009\u65b9\u6cd5\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u6c60\u5316\u6784\u5efa\u548c\u5206\u6790\u6280\u672f\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u65b9\u6cd5\u9009\u62e9\u6307\u5bfc\u3002", "motivation": "\u7ec6\u83cc\u5bf9\u6297\u751f\u7d20\u8010\u836f\u6027\u65e5\u76ca\u4e25\u91cd\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6297\u83cc\u7b56\u7565\u3002\u4f20\u7edf\u9ad8\u901a\u91cf\u7b5b\u9009\u6548\u7387\u4f4e\uff0c\u6c60\u5316\u7b5b\u9009\uff08\u591a\u4e2a\u5316\u5408\u7269\u6df7\u5408\u68c0\u6d4b\uff09\u80fd\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u9700\u8981\u6307\u5bfc\u5b9e\u8df5\u8005\u9009\u62e9\u5408\u9002\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u79cd\u8fd1\u671f\u63d0\u51fa\u7684\u6c60\u5316\u6784\u5efa\u65b9\u6cd5\u548c\u6c60\u5316\u9ad8\u901a\u91cf\u7b5b\u9009\u5206\u6790\u6280\u672f\uff0c\u5305\u62ec\u5728\u6297\u83cc\u836f\u7269\u53d1\u73b0\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u6d4b\u8bd5\uff0c\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u8bd5\u70b9\u7814\u7a76\u548c\u8f83\u5c0f\u7684\u7b5b\u9009\u6d3b\u52a8\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u6c60\u5316\u65b9\u6cd5\u5728\u6297\u83cc\u836f\u7269\u7b5b\u9009\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u7ed3\u679c\uff0c\u7a81\u51fa\u4e86\u8be5\u65b9\u6cd5\u7684\u6210\u529f\u4e4b\u5904\u548c\u9762\u4e34\u7684\u6311\u6218\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u65b9\u6cd5\u9009\u62e9\u7684\u5b9e\u7528\u6307\u5bfc\u3002", "conclusion": "\u6c60\u5316\u7b5b\u9009\u662f\u63d0\u9ad8\u6297\u83cc\u836f\u7269\u53d1\u73b0\u6548\u7387\u7684\u6709\u6548\u7b56\u7565\uff0c\u4f46\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u6c60\u5316\u6784\u5efa\u548c\u5206\u6790\u65b9\u6cd5\uff0c\u672c\u7814\u7a76\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u65b9\u6cd5\u9009\u62e9\u6307\u5bfc\u3002"}}
{"id": "2602.16066", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16066", "abs": "https://arxiv.org/abs/2602.16066", "authors": ["Martin Klissarov", "Jonathan Cook", "Diego Antognini", "Hao Sun", "Jingling Li", "Natasha Jaques", "Claudiu Musat", "Edward Grefenstette"], "title": "Improving Interactive In-Context Learning from Natural Language Feedback", "comment": null, "summary": "Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u6846\u67b6\uff0c\u5c06\u4ea4\u4e92\u5f0f\u4e0a\u4e0b\u6587\u5b66\u4e60\u89c6\u4e3a\u53ef\u8bad\u7ec3\u6280\u80fd\u800c\u975e\u6d8c\u73b0\u7279\u6027\uff0c\u901a\u8fc7\u4fe1\u606f\u4e0d\u5bf9\u79f0\u5c06\u5355\u8f6e\u4efb\u52a1\u8f6c\u5316\u4e3a\u591a\u8f6e\u6559\u5b66\u4e92\u52a8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u4ece\u8bed\u8a00\u53cd\u9988\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u8bed\u6599\u5e93\u5efa\u6a21\uff0c\u5ffd\u89c6\u4e86\u4eba\u7c7b\u5b66\u4e60\u4e2d\u57fa\u4e8e\u7ea0\u6b63\u53cd\u9988\u52a8\u6001\u8c03\u6574\u601d\u7ef4\u8fc7\u7a0b\u7684\u5173\u952e\u80fd\u529b\u3002\u73b0\u6709\u7684\u8bad\u7ec3\u8303\u5f0f\u867d\u7136\u6709\u6548\u83b7\u53d6\u77e5\u8bc6\uff0c\u4f46\u7f3a\u4e4f\u4ea4\u4e92\u5f0f\u53cd\u9988\u5faa\u73af\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u4e2d\u52a8\u6001\u9002\u5e94\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u5c06\u5355\u8f6e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u8f6c\u5316\u4e3a\u7531\u4fe1\u606f\u4e0d\u5bf9\u79f0\u9a71\u52a8\u7684\u591a\u8f6e\u6559\u5b66\u4e92\u52a8\u3002\u901a\u8fc7\u8bad\u7ec3\u6a21\u578b\u6574\u5408\u8bed\u8a00\u53cd\u9988\uff0c\u5c06\u4ea4\u4e92\u5f0f\u4e0a\u4e0b\u6587\u5b66\u4e60\u4f5c\u4e3a\u72ec\u7acb\u53ef\u8bad\u7ec3\u6280\u80fd\u3002\u8fdb\u4e00\u6b65\u901a\u8fc7\u8ba9\u6a21\u578b\u9884\u6d4b\u6559\u5e08\u6279\u8bc4\u6765\u5efa\u6a21\u53cd\u9988\u73af\u5883\uff0c\u5c06\u5916\u90e8\u4fe1\u53f7\u8f6c\u5316\u4e3a\u5185\u90e8\u80fd\u529b\u3002", "result": "1) \u5f53\u524d\u65d7\u8230\u6a21\u578b\u5728\u56f0\u96be\u63a8\u7406\u4efb\u52a1\u4e0a\u96be\u4ee5\u6574\u5408\u7ea0\u6b63\u53cd\u9988\uff1b2) \u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u4ea4\u4e92\u5f0f\u5b66\u4e60\u80fd\u529b\u663e\u8457\u63d0\u5347\uff0c\u8f83\u5c0f\u6a21\u578b\u7684\u591a\u8f6e\u8868\u73b0\u63a5\u8fd1\u5927\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u5927\u6a21\u578b\uff1b3) \u89c2\u5bdf\u5230\u5f3a\u5927\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\uff1a\u6570\u5b66\u95ee\u9898\u7684\u4ea4\u4e92\u8bad\u7ec3\u80fd\u8fc1\u79fb\u5230\u7f16\u7a0b\u3001\u8c1c\u9898\u548c\u8ff7\u5bab\u5bfc\u822a\u7b49\u9886\u57df\uff1b4) \u6a21\u578b\u83b7\u5f97\u4e86\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\u53ef\u5851\u6027\uff0c\u5e76\u80fd\u901a\u8fc7\u81ea\u6211\u7ea0\u6b63\u5b9e\u73b0\u81ea\u6211\u6539\u8fdb\u3002", "conclusion": "\u4ea4\u4e92\u5f0f\u4e0a\u4e0b\u6587\u5b66\u4e60\u5e94\u88ab\u89c6\u4e3a\u53ef\u8bad\u7ec3\u6280\u80fd\u800c\u975e\u6d8c\u73b0\u7279\u6027\u3002\u901a\u8fc7\u5c06\u5355\u8f6e\u4efb\u52a1\u8f6c\u5316\u4e3a\u591a\u8f6e\u6559\u5b66\u4e92\u52a8\uff0c\u6a21\u578b\u80fd\u663e\u8457\u63d0\u5347\u4ece\u53cd\u9988\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u5e76\u5b9e\u73b0\u8de8\u9886\u57df\u6cdb\u5316\u548c\u81ea\u6211\u6539\u8fdb\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.16105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16105", "abs": "https://arxiv.org/abs/2602.16105", "authors": ["Thinh Hung Truong", "Jey Han Lau", "Jianzhong Qi"], "title": "GPSBench: Do Large Language Models Understand GPS Coordinates?", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at https://github.com/joey234/gpsbench", "AI": {"tldr": "GPSBench\u662f\u4e00\u4e2a\u5305\u542b57,800\u4e2a\u6837\u672c\u3001\u6db5\u76d617\u4e2a\u4efb\u52a1\u7684\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6d4b\u8bd5LLM\u5728GPS\u5750\u6807\u548c\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u51e0\u4f55\u5750\u6807\u8ba1\u7b97\u65b9\u9762\u8f83\u5f31\uff0c\u4f46\u5728\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u8868\u73b0\u8f83\u597d\u3002", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u4e0e\u7269\u7406\u4e16\u754c\u4ea4\u4e92\u7684\u5e94\u7528\uff08\u5982\u5bfc\u822a\u3001\u673a\u5668\u4eba\u3001\u5730\u56fe\uff09\uff0c\u5f3a\u5927\u7684\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0cLLM\u5728GPS\u5750\u6807\u548c\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86GPSBench\u6570\u636e\u96c6\uff0c\u5305\u542b57,800\u4e2a\u6837\u672c\uff0c\u6db5\u76d617\u4e2a\u4efb\u52a1\uff0c\u5305\u62ec\u51e0\u4f55\u5750\u6807\u64cd\u4f5c\uff08\u5982\u8ddd\u79bb\u548c\u65b9\u4f4d\u8ba1\u7b97\uff09\u4ee5\u53ca\u5c06\u5750\u6807\u4e0e\u4e16\u754c\u77e5\u8bc6\u7ed3\u5408\u7684\u63a8\u7406\u4efb\u52a1\u3002\u8bc4\u4f30\u4e8614\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff0c\u4e13\u6ce8\u4e8e\u6a21\u578b\u5185\u5728\u80fd\u529b\u800c\u975e\u5de5\u5177\u4f7f\u7528\u3002", "result": "GPS\u63a8\u7406\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u4e0d\u540c\u4efb\u52a1\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1a\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u901a\u5e38\u6bd4\u51e0\u4f55\u8ba1\u7b97\u66f4\u53ef\u9760\u3002\u5730\u7406\u77e5\u8bc6\u5448\u5c42\u6b21\u6027\u9000\u5316\uff0c\u56fd\u5bb6\u7ea7\u522b\u8868\u73b0\u5f3a\u4f46\u57ce\u5e02\u7ea7\u522b\u5b9a\u4f4d\u5f31\u3002\u5bf9\u5750\u6807\u566a\u58f0\u7684\u9c81\u68d2\u6027\u8868\u660e\u6a21\u578b\u5177\u6709\u771f\u6b63\u7684\u5750\u6807\u7406\u89e3\u800c\u975e\u5355\u7eaf\u8bb0\u5fc6\u3002GPS\u5750\u6807\u589e\u5f3a\u53ef\u4ee5\u6539\u5584\u4e0b\u6e38\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\uff0c\u5fae\u8c03\u4f1a\u5728\u51e0\u4f55\u8ba1\u7b97\u6536\u76ca\u548c\u4e16\u754c\u77e5\u8bc6\u9000\u5316\u4e4b\u95f4\u4ea7\u751f\u6743\u8861\u3002", "conclusion": "\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u662fLLM\u7684\u4e00\u4e2a\u91cd\u8981\u4f46\u5c1a\u672a\u5145\u5206\u5f00\u53d1\u7684\u80fd\u529b\u9886\u57df\u3002GPSBench\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbLLM\u7684\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u901a\u8fc7\u5750\u6807\u589e\u5f3a\u548c\u5fae\u8c03\u6765\u6539\u8fdb\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.16173", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16173", "abs": "https://arxiv.org/abs/2602.16173", "authors": ["Kaiqu Liang", "Julia Kruk", "Shengyi Qian", "Xianjun Yang", "Shengjie Bi", "Yuanshun Yao", "Shaoliang Nie", "Mingyang Zhang", "Lijuan Liu", "Jaime Fern\u00e1ndez Fisac", "Shuyan Zhou", "Saghar Hosseini"], "title": "Learning Personalized Agents from Human Feedback", "comment": null, "summary": "Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding user profiles in external memory. However, these approaches struggle with new users and with preferences that change over time. We introduce Personalized Agents from Human Feedback (PAHF), a framework for continual personalization in which agents learn online from live interaction using explicit per-user memory. PAHF operationalizes a three-step loop: (1) seeking pre-action clarification to resolve ambiguity, (2) grounding actions in preferences retrieved from memory, and (3) integrating post-action feedback to update memory when preferences drift. To evaluate this capability, we develop a four-phase protocol and two benchmarks in embodied manipulation and online shopping. These benchmarks quantify an agent's ability to learn initial preferences from scratch and subsequently adapt to persona shifts. Our theoretical analysis and empirical results show that integrating explicit memory with dual feedback channels is critical: PAHF learns substantially faster and consistently outperforms both no-memory and single-channel baselines, reducing initial personalization error and enabling rapid adaptation to preference shifts.", "AI": {"tldr": "PAHF\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u7528\u6237\u8bb0\u5fc6\u548c\u53cc\u53cd\u9988\u901a\u9053\u5b9e\u73b0AI\u4ee3\u7406\u7684\u6301\u7eed\u4e2a\u6027\u5316\uff0c\u663e\u8457\u63d0\u5347\u65b0\u7528\u6237\u504f\u597d\u5b66\u4e60\u548c\u504f\u597d\u6f02\u79fb\u9002\u5e94\u80fd\u529b", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u96be\u4ee5\u9002\u5e94\u4e2a\u4f53\u7528\u6237\u7684\u72ec\u7279\u4e14\u4e0d\u65ad\u6f14\u53d8\u7684\u504f\u597d\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u6570\u636e\u96c6\uff0c\u8981\u4e48\u57fa\u4e8e\u4ea4\u4e92\u5386\u53f2\u8bad\u7ec3\u9690\u5f0f\u504f\u597d\u6a21\u578b\uff0c\u8981\u4e48\u5c06\u7528\u6237\u6863\u6848\u7f16\u7801\u5230\u5916\u90e8\u8bb0\u5fc6\u4e2d\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5728\u65b0\u7528\u6237\u548c\u504f\u597d\u968f\u65f6\u95f4\u53d8\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e2a\u6027\u5316\u4eba\u7c7b\u53cd\u9988\u4ee3\u7406(PAHF)\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u7528\u6237\u8bb0\u5fc6\u5b9e\u73b0\u6301\u7eed\u4e2a\u6027\u5316\u3002\u91c7\u7528\u4e09\u6b65\u5faa\u73af\uff1a(1)\u5bfb\u6c42\u884c\u52a8\u524d\u6f84\u6e05\u4ee5\u89e3\u51b3\u6b67\u4e49\uff0c(2)\u57fa\u4e8e\u4ece\u8bb0\u5fc6\u4e2d\u68c0\u7d22\u7684\u504f\u597d\u8fdb\u884c\u884c\u52a8\uff0c(3)\u6574\u5408\u884c\u52a8\u540e\u53cd\u9988\u4ee5\u66f4\u65b0\u8bb0\u5fc6\uff08\u5f53\u504f\u597d\u6f02\u79fb\u65f6\uff09\u3002\u5f00\u53d1\u4e86\u56db\u9636\u6bb5\u534f\u8bae\u548c\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u5177\u8eab\u64cd\u4f5c\u548c\u5728\u7ebf\u8d2d\u7269\uff09\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u663e\u5f0f\u8bb0\u5fc6\u4e0e\u53cc\u53cd\u9988\u901a\u9053\u7ed3\u5408\u81f3\u5173\u91cd\u8981\uff1aPAHF\u5b66\u4e60\u901f\u5ea6\u663e\u8457\u66f4\u5feb\uff0c\u59cb\u7ec8\u4f18\u4e8e\u65e0\u8bb0\u5fc6\u548c\u5355\u901a\u9053\u57fa\u7ebf\uff0c\u51cf\u5c11\u4e86\u521d\u59cb\u4e2a\u6027\u5316\u8bef\u5dee\uff0c\u5e76\u80fd\u591f\u5feb\u901f\u9002\u5e94\u504f\u597d\u53d8\u5316\u3002", "conclusion": "PAHF\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u7528\u6237\u8bb0\u5fc6\u548c\u53cc\u53cd\u9988\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86AI\u4ee3\u7406\u6301\u7eed\u4e2a\u6027\u5316\u7684\u95ee\u9898\uff0c\u5728\u521d\u59cb\u504f\u597d\u5b66\u4e60\u548c\u504f\u597d\u6f02\u79fb\u9002\u5e94\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u6784\u5efa\u66f4\u9002\u5e94\u7528\u6237\u4e2a\u6027\u5316\u9700\u6c42\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.16179", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16179", "abs": "https://arxiv.org/abs/2602.16179", "authors": ["Sushant Mehta", "Logan Ritchie", "Suhaas Garre", "Nick Heiner", "Edwin Chen"], "title": "EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments", "comment": null, "summary": "We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \\corecraft{}, the first environment in \\textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \\corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step, domain-specific work that real jobs demand. Frontier models such as GPT-5.2 and Claude Opus 4.6 solve fewer than 30\\% of tasks when all expert-authored rubric criteria must be satisfied. Using this environment, we train GLM~4.6 with Group Relative Policy Optimization (GRPO) and adaptive clipping. After a single epoch of training, the model improves from 25.37\\% to 36.76\\% task pass rate on held-out evaluation tasks. More importantly, these gains transfer to out-of-distribution benchmarks: +4.5\\% on BFCL Parallel, +7.4\\% on $\u03c4^2$-Bench Retail, and +6.8\\% on Toolathlon (Pass@1). We believe three environment properties are consistent with the observed transfer: task-centric world building that optimizes for diverse, challenging tasks; expert-authored rubrics enabling reliable reward computation; and enterprise workflows that reflect realistic professional patterns. Our results suggest that environment quality, diversity, and realism are key factors enabling generalizable agent capabilities.", "AI": {"tldr": "\u5728CoreCraft\u4f01\u4e1a\u6a21\u62df\u73af\u5883\u4e2d\u8bad\u7ec3AI\u4ee3\u7406\uff0c\u5176\u80fd\u529b\u53ef\u6cdb\u5316\u5230\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\uff0c\u5728\u591a\u4e2a\u5916\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u63d0\u5347", "motivation": "\u7814\u7a76AI\u4ee3\u7406\u5728\u9ad8\u4fdd\u771f\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u8bad\u7ec3\u540e\uff0c\u5176\u80fd\u529b\u662f\u5426\u80fd\u6cdb\u5316\u5230\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\uff0c\u63a2\u7d22\u73af\u5883\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\u5bf9\u4ee3\u7406\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd", "method": "\u5f00\u53d1CoreCraft\u4f01\u4e1a\u6a21\u62df\u73af\u5883\uff08\u5305\u542b2500+\u5b9e\u4f53\u300114\u79cd\u5b9e\u4f53\u7c7b\u578b\u300123\u79cd\u5de5\u5177\uff09\uff0c\u4f7f\u7528GRPO\uff08Group Relative Policy Optimization\uff09\u548c\u81ea\u9002\u5e94\u88c1\u526a\u8bad\u7ec3GLM 4.6\u6a21\u578b\uff0c\u5728\u5355\u8f6e\u8bad\u7ec3\u540e\u8bc4\u4f30\u4efb\u52a1\u901a\u8fc7\u7387\u548c\u5916\u90e8\u57fa\u51c6\u6d4b\u8bd5\u8868\u73b0", "result": "\u8bad\u7ec3\u540e\u4efb\u52a1\u901a\u8fc7\u7387\u4ece25.37%\u63d0\u5347\u81f336.76%\uff1b\u5728\u5916\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1aBFCL Parallel\u63d0\u53474.5%\uff0c\u03c4\u00b2-Bench Retail\u63d0\u53477.4%\uff0cToolathlon\uff08Pass@1\uff09\u63d0\u53476.8%", "conclusion": "\u73af\u5883\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\u662f\u4f7fAI\u4ee3\u7406\u80fd\u529b\u5177\u6709\u6cdb\u5316\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4efb\u52a1\u4e2d\u5fc3\u7684\u4e16\u754c\u6784\u5efa\u3001\u4e13\u5bb6\u7f16\u5199\u7684\u8bc4\u4f30\u6807\u51c6\u548c\u53cd\u6620\u771f\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u7684\u8bbe\u8ba1\u6709\u52a9\u4e8e\u5b9e\u73b0\u80fd\u529b\u8fc1\u79fb"}}
{"id": "2602.16192", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16192", "abs": "https://arxiv.org/abs/2602.16192", "authors": ["Hiroaki Yamanaka", "Daisuke Miyashita", "Takashi Toi", "Asuka Maki", "Taiga Ikeda", "Jun Deguchi"], "title": "Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage", "comment": "13 pages, 5 figures", "summary": "Driven by our mission of \"uplifting the world with memory,\" this paper explores the design concept of \"memory\" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed \"extract then store,\" involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the \"store then on-demand extract\" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5b9e\u73b0\u4eba\u5de5\u8d85\u667a\u80fd\u6240\u9700\u7684\u5173\u952e\"\u8bb0\u5fc6\"\u8bbe\u8ba1\u6982\u5ff5\uff0c\u63d0\u51fa\u4e86\"\u5148\u5b58\u50a8\u540e\u6309\u9700\u63d0\u53d6\"\u7b49\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4fdd\u7559\u539f\u59cb\u7ecf\u9a8c\u4ee5\u907f\u514d\u4fe1\u606f\u635f\u5931\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\"\u5148\u63d0\u53d6\u540e\u5b58\u50a8\"\u8303\u5f0f\u5b58\u5728\u4fe1\u606f\u635f\u5931\u98ce\u9669\uff0c\u56e0\u4e3a\u63d0\u53d6\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u4e22\u5f03\u5bf9\u4e0d\u540c\u4efb\u52a1\u6709\u4ef7\u503c\u7684\u77e5\u8bc6\u3002\u4e3a\u4e86\u63d0\u5347\u4eba\u5de5\u8d85\u667a\u80fd\u7684\u8bb0\u5fc6\u80fd\u529b\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u6709\u6548\u7684\u8bb0\u5fc6\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cd\u66ff\u4ee3\u65b9\u6cd5\uff1a1\uff09\"\u5148\u5b58\u50a8\u540e\u6309\u9700\u63d0\u53d6\" - \u4fdd\u7559\u539f\u59cb\u7ecf\u9a8c\u5e76\u7075\u6d3b\u5e94\u7528\u4e8e\u4e0d\u540c\u4efb\u52a1\uff1b2\uff09\u4ece\u5927\u91cf\u6982\u7387\u6027\u7ecf\u9a8c\u4e2d\u53d1\u73b0\u6df1\u5c42\u6d1e\u5bdf\uff1b3\uff09\u901a\u8fc7\u5171\u4eab\u5b58\u50a8\u7ecf\u9a8c\u63d0\u9ad8\u7ecf\u9a8c\u6536\u96c6\u6548\u7387\uff1b4\uff09\u901a\u8fc7\u7b80\u5355\u5b9e\u9a8c\u9a8c\u8bc1\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7b80\u5355\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u8fd9\u4e9b\u66ff\u4ee3\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u5b83\u4eec\u786e\u5b9e\u80fd\u591f\u907f\u514d\u4fe1\u606f\u635f\u5931\u5e76\u63d0\u9ad8\u8bb0\u5fc6\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "conclusion": "\u8bba\u6587\u6307\u51fa\u4e86\u9650\u5236\u8fd9\u4e9b\u6709\u524d\u666f\u65b9\u5411\u7814\u7a76\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7814\u7a76\u8bfe\u9898\uff0c\u4e3a\u4eba\u5de5\u8d85\u667a\u80fd\u7684\u8bb0\u5fc6\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u65b9\u5411\u3002"}}
{"id": "2602.16246", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16246", "abs": "https://arxiv.org/abs/2602.16246", "authors": ["Yun-Shiuan Chuang", "Chaitanya Kulkarni", "Alec Chiu", "Avinash Thangali", "Zijie Pan", "Shivani Shekhar", "Yirou Ge", "Yixi Li", "Uma Kona", "Linsey Pang", "Prakhar Mehrotra"], "title": "Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents", "comment": null, "summary": "Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluation without a deterministic database. Specifically, a scenario specifies the user goal, user/system facts, expected final state, and expected agent behavior, and an LLM state tracker infers a structured proxy state from the full interaction trace. LLM judges then verify goal completion and detect tool/user hallucinations against scenario constraints. Empirically, our benchmark produces stable, model-differentiating rankings across families and inference-time reasoning efforts, and its on-/off-policy rollouts provide supervision that transfers to unseen scenarios. Careful scenario specification yields near-zero simulator hallucination rates as supported by ablation studies. The framework also supports sensitivity analyses over user personas. Human-LLM judge agreement exceeds 90%, indicating reliable automated evaluation. Overall, proxy state-based evaluation offers a practical, scalable alternative to deterministic agentic benchmarks for industrial LLM agents.", "AI": {"tldr": "\u63d0\u51faProxy State-Based Evaluation\u6846\u67b6\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u7684\u6a21\u62df\u6765\u8bc4\u4f30\u4ea4\u4e92\u5f0fLLM\u667a\u80fd\u4f53\uff0c\u907f\u514d\u6784\u5efa\u786e\u5b9a\u6027\u6570\u636e\u5e93\u7684\u6210\u672c", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u57fa\u51c6\uff08\u5982tau-bench\u3001AppWorld\uff09\u4f9d\u8d56\u5b8c\u5168\u786e\u5b9a\u6027\u7684\u540e\u7aef\uff0c\u6784\u5efa\u548c\u7ef4\u62a4\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u66f4\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u901a\u8fc7\u573a\u666f\u89c4\u8303\u5b9a\u4e49\u7528\u6237\u76ee\u6807\u3001\u4e8b\u5b9e\u3001\u671f\u671b\u6700\u7ec8\u72b6\u6001\u548c\u884c\u4e3a\uff0c\u4f7f\u7528LLM\u72b6\u6001\u8ddf\u8e2a\u5668\u4ece\u4ea4\u4e92\u8f68\u8ff9\u63a8\u65ad\u7ed3\u6784\u5316\u4ee3\u7406\u72b6\u6001\uff0c\u518d\u7531LLM\u8bc4\u5224\u5668\u9a8c\u8bc1\u76ee\u6807\u5b8c\u6210\u548c\u68c0\u6d4b\u5e7b\u89c9", "result": "\u57fa\u51c6\u4ea7\u751f\u7a33\u5b9a\u3001\u80fd\u533a\u5206\u4e0d\u540c\u6a21\u578b\u7684\u6392\u540d\uff0c\u652f\u6301\u654f\u611f\u5ea6\u5206\u6790\uff0c\u4eba\u7c7b-LLM\u8bc4\u5224\u5668\u4e00\u81f4\u6027\u8d85\u8fc790%\uff0c\u6a21\u62df\u5668\u5e7b\u89c9\u7387\u63a5\u8fd1\u96f6", "conclusion": "\u4ee3\u7406\u72b6\u6001\u8bc4\u4f30\u4e3a\u5de5\u4e1aLLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u786e\u5b9a\u6027\u57fa\u51c6\u66ff\u4ee3\u65b9\u6848\uff0c\u652f\u6301\u81ea\u52a8\u8bc4\u4f30\u548c\u8bad\u7ec3\u6570\u636e\u751f\u6210"}}
{"id": "2602.16301", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16301", "abs": "https://arxiv.org/abs/2602.16301", "authors": ["Marissa A. Weis", "Maciej Wo\u0142czyk", "Rajai Nasser", "Rif A. Saurous", "Blaise Ag\u00fcera y Arcas", "Jo\u00e3o Sacramento", "Alexander Meulemans"], "title": "Multi-agent cooperation through in-context co-player inference", "comment": "26 pages, 4 figures", "summary": "Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between \"learning-aware\" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between \"naive learners\" updating on fast timescales and \"meta-learners\" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.", "AI": {"tldr": "\u5e8f\u5217\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u5408\u4f5c\uff0c\u65e0\u9700\u786c\u7f16\u7801\u5047\u8bbe\u6216\u663e\u5f0f\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\uff0c\u4ec5\u9700\u4e0e\u591a\u6837\u5316\u5bf9\u624b\u8bad\u7ec3\u5373\u53ef\u81ea\u7136\u6d8c\u73b0\u5408\u4f5c\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u786c\u7f16\u7801\u5bf9\u624b\u5b66\u4e60\u89c4\u5219\u5047\u8bbe\u6216\u5f3a\u5236\u533a\u5206\u5feb\u901f\u66f4\u65b0\u7684\"\u6734\u7d20\u5b66\u4e60\u8005\"\u548c\u89c2\u5bdf\u8fd9\u4e9b\u66f4\u65b0\u7684\"\u5143\u5b66\u4e60\u8005\"\uff0c\u8fd9\u9650\u5236\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u81ea\u5229\u667a\u80fd\u4f53\u5408\u4f5c\u7684\u5b9e\u73b0\u3002", "method": "\u4f7f\u7528\u5e8f\u5217\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u8bad\u7ec3\u667a\u80fd\u4f53\u5bf9\u6297\u591a\u6837\u5316\u7684\u5bf9\u624b\u5206\u5e03\uff0c\u8ba9\u667a\u80fd\u4f53\u5728\u5feb\u901f\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u81ea\u7136\u5730\u5b66\u4e60\u4e0a\u4e0b\u6587\u6700\u4f73\u54cd\u5e94\u7b56\u7565\uff0c\u65e0\u9700\u786c\u7f16\u7801\u5047\u8bbe\u6216\u663e\u5f0f\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u3002", "result": "\u5e8f\u5217\u6a21\u578b\u667a\u80fd\u4f53\u901a\u8fc7\u4e0a\u4e0b\u6587\u9002\u5e94\u53d8\u5f97\u5bb9\u6613\u53d7\u5230\u52d2\u7d22\u653b\u51fb\uff0c\u8fd9\u79cd\u76f8\u4e92\u538b\u529b\u4fc3\u4f7f\u667a\u80fd\u4f53\u5851\u9020\u5bf9\u624b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u52a8\u6001\uff0c\u6700\u7ec8\u81ea\u7136\u6d8c\u73b0\u51fa\u5408\u4f5c\u884c\u4e3a\u3002", "conclusion": "\u5e8f\u5217\u6a21\u578b\u7684\u53bb\u4e2d\u5fc3\u5316\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u5bf9\u624b\u591a\u6837\u6027\uff0c\u4e3a\u5b66\u4e60\u5408\u4f5c\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u65e0\u9700\u590d\u6742\u7684\u5143\u5b66\u4e60\u67b6\u6784\u6216\u786c\u7f16\u7801\u5047\u8bbe\u3002"}}
{"id": "2602.16424", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16424", "abs": "https://arxiv.org/abs/2602.16424", "authors": ["Philipp Schoenegger", "Matt Carlson", "Chris Schneider", "Chris Daly"], "title": "Verifiable Semantics for Agent-to-Agent Communication", "comment": null, "summary": "Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms (\"core-guarded reasoning\") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u523a\u6fc0-\u610f\u4e49\u6a21\u578b\u7684\u8ba4\u8bc1\u534f\u8bae\uff0c\u901a\u8fc7\u6d4b\u8bd5\u667a\u80fd\u4f53\u5728\u53ef\u89c2\u6d4b\u4e8b\u4ef6\u4e0a\u7684\u4e00\u81f4\u6027\u6765\u8ba4\u8bc1\u672f\u8bed\uff0c\u786e\u4fdd\u901a\u4fe1\u8bed\u4e49\u5bf9\u9f50", "motivation": "\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u9700\u8981\u4e00\u81f4\u7684\u901a\u4fe1\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u9a8c\u8bc1\u667a\u80fd\u4f53\u5bf9\u672f\u8bed\u7406\u89e3\u662f\u5426\u4e00\u81f4\u7684\u65b9\u6cd5\u3002\u81ea\u7136\u8bed\u8a00\u53ef\u89e3\u91ca\u4f46\u6613\u53d7\u8bed\u4e49\u6f02\u79fb\u5f71\u54cd\uff0c\u800c\u5b66\u4e60\u534f\u8bae\u9ad8\u6548\u4f46\u4e0d\u900f\u660e", "method": "\u57fa\u4e8e\u523a\u6fc0-\u610f\u4e49\u6a21\u578b\u8bbe\u8ba1\u8ba4\u8bc1\u534f\u8bae\uff1a\u6d4b\u8bd5\u667a\u80fd\u4f53\u5728\u5171\u4eab\u53ef\u89c2\u6d4b\u4e8b\u4ef6\u4e0a\u7684\u8868\u73b0\uff0c\u5982\u679c\u7ecf\u9a8c\u5206\u6b67\u4f4e\u4e8e\u7edf\u8ba1\u9608\u503c\u5219\u8ba4\u8bc1\u672f\u8bed\u3002\u667a\u80fd\u4f53\u9650\u5236\u63a8\u7406\u4e8e\u8ba4\u8bc1\u672f\u8bed\uff08\u6838\u5fc3\u9632\u62a4\u63a8\u7406\uff09\u53ef\u5b9e\u73b0\u53ef\u8bc1\u660e\u7684\u6709\u754c\u5206\u6b67\u3002\u8fd8\u5305\u62ec\u68c0\u6d4b\u6f02\u79fb\u7684\u91cd\u65b0\u8ba4\u8bc1\u673a\u5236\u548c\u6062\u590d\u5171\u4eab\u8bcd\u6c47\u7684\u91cd\u65b0\u534f\u5546\u673a\u5236", "result": "\u5728\u8bed\u4e49\u5206\u6b67\u7a0b\u5ea6\u4e0d\u540c\u7684\u6a21\u62df\u4e2d\uff0c\u6838\u5fc3\u9632\u62a4\u5c06\u5206\u6b67\u51cf\u5c1172-96%\u3002\u5728\u4f7f\u7528\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u7684\u9a8c\u8bc1\u4e2d\uff0c\u5206\u6b67\u51cf\u5c1151%", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53ef\u9a8c\u8bc1\u7684\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u63d0\u4f9b\u4e86\u7b2c\u4e00\u6b65\uff0c\u901a\u8fc7\u7edf\u8ba1\u8ba4\u8bc1\u786e\u4fdd\u8bed\u4e49\u5bf9\u9f50\uff0c\u51cf\u5c11\u901a\u4fe1\u5206\u6b67"}}
{"id": "2602.16435", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16435", "abs": "https://arxiv.org/abs/2602.16435", "authors": ["Arun Vignesh Malarkkan", "Wangyang Ying", "Yanjie Fu"], "title": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning", "comment": "11 Pages, References and Appendix", "summary": "Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.", "AI": {"tldr": "CAFE\u6846\u67b6\u5c06\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u56e0\u679c\u5f15\u5bfc\u7684\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u56e0\u679c\u53d1\u73b0\u548c\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u63d0\u5347\u7279\u5f81\u5de5\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u4f9d\u8d56\u7edf\u8ba1\u542f\u53d1\u5f0f\uff0c\u4ea7\u751f\u7684\u7279\u5f81\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u8106\u5f31\u3002\u9700\u8981\u7ed3\u5408\u56e0\u679c\u7ed3\u6784\u6765\u63d0\u5347\u7279\u5f81\u7684\u9c81\u68d2\u6027\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5b66\u4e60\u7a00\u758f\u6709\u5411\u65e0\u73af\u56fe\u83b7\u53d6\u8f6f\u56e0\u679c\u5148\u9a8c\uff0c\u5c06\u7279\u5f81\u6309\u56e0\u679c\u5f71\u54cd\u5206\u7ec4\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7ea7\u8054\u591a\u667a\u80fd\u4f53\u6df1\u5ea6Q\u5b66\u4e60\u67b6\u6784\u9009\u62e9\u56e0\u679c\u7ec4\u548c\u53d8\u6362\u7b97\u5b50\uff0c\u91c7\u7528\u5206\u5c42\u5956\u52b1\u5851\u9020\u548c\u56e0\u679c\u7ec4\u7ea7\u63a2\u7d22\u7b56\u7565\u3002", "result": "\u572815\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCAFE\u76f8\u6bd4\u57fa\u7ebf\u63d0\u5347\u8fbe7%\uff0c\u51cf\u5c11\u6536\u655b\u6240\u9700\u56de\u5408\u6570\uff0c\u5728\u534f\u53d8\u91cf\u504f\u79fb\u4e0b\u6027\u80fd\u4e0b\u964d\u51cf\u5c11\u7ea64\u500d\uff0c\u4ea7\u751f\u66f4\u7d27\u51d1\u7684\u7279\u5f81\u96c6\u548c\u66f4\u7a33\u5b9a\u7684\u540e\u9a8c\u5f52\u56e0\u3002", "conclusion": "\u56e0\u679c\u7ed3\u6784\u4f5c\u4e3a\u8f6f\u5f52\u7eb3\u5148\u9a8c\u800c\u975e\u521a\u6027\u7ea6\u675f\uff0c\u80fd\u663e\u8457\u63d0\u5347\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.16481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16481", "abs": "https://arxiv.org/abs/2602.16481", "authors": ["Zihao Li", "Fabrizio Russo"], "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach", "comment": "26 pages, including appendix", "summary": "Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e0d\u5b8c\u7f8e\u4e13\u5bb6\uff0c\u4e3a\u56e0\u679cABA\u6846\u67b6\u63d0\u4f9b\u8bed\u4e49\u7ed3\u6784\u5148\u9a8c\uff0c\u7ed3\u5408\u6761\u4ef6\u72ec\u7acb\u6027\u8bc1\u636e\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u56e0\u679c\u53d1\u73b0\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u6784\u5efa\u539f\u5219\u6027\u56e0\u679c\u56fe\uff0c\u4f46\u4e13\u5bb6\u77e5\u8bc6\u83b7\u53d6\u56f0\u96be\u3002\u540c\u65f6\uff0c\u73b0\u6709\u7edf\u8ba1\u65b9\u6cd5\u867d\u7136\u80fd\u5229\u7528\u89c2\u6d4b\u6570\u636e\uff0c\u4f46\u7f3a\u4e4f\u4e0e\u8f93\u5165\u7ea6\u675f\u7684\u7b26\u53f7\u63a8\u7406\u4fdd\u8bc1\u3002\u56e0\u679c\u5047\u8bbe\u8bba\u8bc1(ABA)\u6846\u67b6\u80fd\u786e\u4fdd\u8f93\u5165\u7ea6\u675f\u4e0e\u8f93\u51fa\u56fe\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4f46\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u8f93\u5165\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e0d\u5b8c\u7f8e\u4e13\u5bb6\uff0c\u4ece\u53d8\u91cf\u540d\u79f0\u548c\u63cf\u8ff0\u4e2d\u63d0\u53d6\u8bed\u4e49\u7ed3\u6784\u5148\u9a8c\uff0c\u5c06\u8fd9\u4e9b\u5148\u9a8c\u4e0e\u6761\u4ef6\u72ec\u7acb\u6027\u8bc1\u636e\u7ed3\u5408\uff0c\u96c6\u6210\u5230\u56e0\u679cABA\u6846\u67b6\u4e2d\u3002\u8fd8\u5f15\u5165\u4e86\u8bc4\u4f30\u534f\u8bae\u6765\u51cf\u8f7b\u8bc4\u4f30LLMs\u65f6\u7684\u8bb0\u5fc6\u504f\u5dee\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bed\u4e49\u57fa\u7840\u5408\u6210\u56fe\u4e0a\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u63d0\u51fa\u7684\u8bc4\u4f30\u534f\u8bae\u6709\u6548\u51cf\u8f7b\u4e86LLMs\u5728\u56e0\u679c\u53d1\u73b0\u8bc4\u4f30\u4e2d\u7684\u8bb0\u5fc6\u504f\u5dee\u95ee\u9898\u3002", "conclusion": "LLMs\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\"\u4e0d\u5b8c\u7f8e\u4e13\u5bb6\"\u4e3a\u56e0\u679cABA\u63d0\u4f9b\u8bed\u4e49\u5148\u9a8c\uff0c\u7ed3\u5408\u6761\u4ef6\u72ec\u7acb\u6027\u8bc1\u636e\u80fd\u5b9e\u73b0\u5f3a\u5927\u7684\u56e0\u679c\u53d1\u73b0\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u4e3a\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u548c\u7edf\u8ba1\u8bc1\u636e\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2602.16512", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16512", "abs": "https://arxiv.org/abs/2602.16512", "authors": ["Felix Fricke", "Simon Malberg", "Georg Groh"], "title": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs", "comment": null, "summary": "Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.", "AI": {"tldr": "FoT\u662f\u4e00\u4e2a\u901a\u7528\u7684\u57fa\u7840\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u548c\u4f18\u5316\u52a8\u6001\u63a8\u7406\u65b9\u6848\uff0c\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u63d0\u793a\u4f18\u5316\u3001\u5e76\u884c\u6267\u884c\u548c\u667a\u80fd\u7f13\u5b58\u6765\u63d0\u5347\u63a8\u7406\u65b9\u6848\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u65b9\u6848\uff08\u5982Chain of Thought\u3001Tree of Thoughts\u7b49\uff09\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u9700\u8981\u7528\u6237\u5b9a\u4e49\u9759\u6001\u7684\u3001\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u63a8\u7406\u7ed3\u6784\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u6216\u672a\u89c1\u95ee\u9898\u7c7b\u578b\u7684\u9002\u5e94\u6027\uff1b2\uff09\u5728\u8d85\u53c2\u6570\u3001\u63d0\u793a\u3001\u8fd0\u884c\u65f6\u95f4\u548c\u63d0\u793a\u6210\u672c\u65b9\u9762\u901a\u5e38\u672a\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e86Framework of Thoughts (FoT)\uff0c\u8fd9\u662f\u4e00\u4e2a\u901a\u7528\u7684\u57fa\u7840\u6846\u67b6\uff0c\u5177\u6709\u5185\u7f6e\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u63d0\u793a\u4f18\u5316\u3001\u5e76\u884c\u6267\u884c\u548c\u667a\u80fd\u7f13\u5b58\u529f\u80fd\u3002\u901a\u8fc7\u5728FoT\u4e2d\u5b9e\u73b0Tree of Thoughts\u3001Graph of Thoughts\u548cProbTree\u4e09\u79cd\u6d41\u884c\u65b9\u6848\u6765\u5c55\u793a\u5176\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eFoT\u80fd\u591f\u663e\u8457\u52a0\u5feb\u6267\u884c\u901f\u5ea6\u3001\u964d\u4f4e\u6210\u672c\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u83b7\u5f97\u66f4\u597d\u7684\u4efb\u52a1\u5206\u6570\u3002\u4ee3\u7801\u5e93\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u672a\u6765\u52a8\u6001\u9ad8\u6548\u63a8\u7406\u65b9\u6848\u7684\u53d1\u5c55\u3002", "conclusion": "FoT\u901a\u8fc7\u63d0\u4f9b\u7edf\u4e00\u7684\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u63a8\u7406\u65b9\u6848\u7f3a\u4e4f\u9002\u5e94\u6027\u548c\u672a\u4f18\u5316\u7684\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u52a8\u6001\u9ad8\u6548\u7684\u63a8\u7406\u65b9\u6848\u63d0\u4f9b\u4e86\u57fa\u7840\u652f\u6301\u3002"}}
{"id": "2602.16578", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16578", "abs": "https://arxiv.org/abs/2602.16578", "authors": ["Vered Tohar", "Tsahi Hayat", "Amir Leshem"], "title": "Creating a digital poet", "comment": "24 pages, 3 figures", "summary": "Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.", "AI": {"tldr": "\u901a\u8fc7\u4e03\u4e2a\u6708\u7684\u8bd7\u6b4c\u5de5\u4f5c\u574a\uff0c\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u8fed\u4ee3\u5f0f\u4e0a\u4e0b\u6587\u4e13\u5bb6\u53cd\u9988\u5851\u9020\u4e86\u4e00\u4e2a\u6570\u5b57\u8bd7\u4eba\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u521b\u4f5c\u51fa\u4e0e\u4eba\u7c7b\u8bd7\u6b4c\u96be\u4ee5\u533a\u5206\u7684\u4f5c\u54c1\uff0c\u5e76\u5728\u76f2\u6d4b\u4e2d\u8fbe\u5230\u968f\u673a\u6c34\u5e73\u3002", "motivation": "\u63a2\u7d22\u673a\u5668\u80fd\u5426\u521b\u4f5c\u51fa\u4f18\u79c0\u7684\u8bd7\u6b4c\uff0c\u8fd9\u6d89\u53ca\u5230\u827a\u672f\u672c\u8d28\u548c\u4ef7\u503c\u7684\u6839\u672c\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u6d4b\u8bd5\u901a\u8fc7\u5de5\u4f5c\u574a\u5f0f\u63d0\u793a\u80fd\u5426\u652f\u6301\u957f\u671f\u521b\u9020\u6027\u5851\u9020\uff0c\u5e76\u91cd\u65b0\u5f15\u53d1\u5173\u4e8e\u521b\u9020\u529b\u548c\u4f5c\u8005\u8eab\u4efd\u7684\u8ba8\u8bba\u3002", "method": "\u8fdb\u884c\u4e3a\u671f\u4e03\u4e2a\u6708\u7684\u8bd7\u6b4c\u5de5\u4f5c\u574a\uff0c\u901a\u8fc7\u8fed\u4ee3\u5f0f\u4e0a\u4e0b\u6587\u4e13\u5bb6\u53cd\u9988\uff08\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff09\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5851\u9020\u6210\u6570\u5b57\u8bd7\u4eba\u3002\u4f7f\u7528\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u8bc4\u4f30\u6a21\u578b\u53d1\u5c55\u51fa\u7684\u72ec\u7279\u98ce\u683c\u548c\u8fde\u8d2f\u4f5c\u54c1\u96c6\u3002\u8fdb\u884c\u76f2\u6d4b\u5b9e\u9a8c\uff0c\u8ba950\u540d\u4eba\u6587\u5b66\u751f\u548c\u6bd5\u4e1a\u751f\u5224\u65ad\u516d\u9996\u8bd7\uff08\u4e09\u9996AI\u521b\u4f5c\uff0c\u4e09\u9996\u77e5\u540d\u8bd7\u4eba\u4f5c\u54c1\uff09\u7684\u4f5c\u8005\u8eab\u4efd\u3002", "result": "\u6a21\u578b\u53d1\u5c55\u51fa\u4e86\u72ec\u7279\u7684\u98ce\u683c\u548c\u8fde\u8d2f\u7684\u4f5c\u54c1\u96c6\uff0c\u5e76\u521b\u5efa\u4e86\u7b14\u540d\u548c\u4f5c\u8005\u5f62\u8c61\u3002\u76f2\u6d4b\u7ed3\u679c\u663e\u793a\uff1a\u4eba\u7c7b\u8bd7\u6b4c\u88ab\u6807\u8bb0\u4e3a\u4eba\u7c7b\u7684\u51c6\u786e\u7387\u4e3a54%\uff0cAI\u8bd7\u6b4c\u88ab\u6807\u8bb0\u4e3aAI\u7684\u51c6\u786e\u7387\u4e3a52%\uff0895%\u7f6e\u4fe1\u533a\u95f4\u5305\u542b50%\uff09\uff0c\u5224\u65ad\u5904\u4e8e\u968f\u673a\u6c34\u5e73\u3002\u5de5\u4f5c\u574a\u540e\uff0c\u5546\u4e1a\u51fa\u7248\u793e\u51fa\u7248\u4e86\u8be5\u6a21\u578b\u7684\u8bd7\u96c6\u3002", "conclusion": "\u5de5\u4f5c\u574a\u5f0f\u63d0\u793a\u80fd\u591f\u652f\u6301\u957f\u671f\u521b\u9020\u6027\u5851\u9020\uff0c\u4f7fAI\u521b\u4f5c\u7684\u8bd7\u6b4c\u5728\u76f2\u6d4b\u4e2d\u4e0e\u4eba\u7c7b\u4f5c\u54c1\u96be\u4ee5\u533a\u5206\u3002\u8fd9\u4e00\u53d1\u73b0\u66f4\u65b0\u4e86\u5173\u4e8e\u521b\u9020\u529b\u548c\u4f5c\u8005\u8eab\u4efd\u7684\u8ba8\u8bba\uff0c\u8868\u660e\u673a\u5668\u80fd\u591f\u521b\u4f5c\u51fa\u88ab\u8ba4\u53ef\u4e3a\u827a\u672f\u7684\u8bd7\u6b4c\u4f5c\u54c1\u3002"}}
{"id": "2602.16653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16653", "abs": "https://arxiv.org/abs/2602.16653", "authors": ["Yangjie Xu", "Lujun Li", "Lama Sleem", "Niccolo Gentile", "Yewei Song", "Yiqun Wang", "Siming Ji", "Wenbo Wu", "Radu State"], "title": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments", "comment": null, "summary": "Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.", "AI": {"tldr": "Agent Skill\u6846\u67b6\u5bf9\u4e2d\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08\u7279\u522b\u662f12B-30B\u53c2\u6570\uff09\u6709\u663e\u8457\u63d0\u5347\u6548\u679c\uff0c\u4f46\u5728\u8d85\u5c0f\u578b\u6a21\u578b\u4e0a\u6548\u679c\u6709\u9650\uff0c80B\u53c2\u6570\u7684\u4ee3\u7801\u4e13\u7528\u6a21\u578b\u80fd\u8fbe\u5230\u95ed\u6e90\u57fa\u7ebf\u6027\u80fd\u3002", "motivation": "\u7814\u7a76Agent Skill\u8303\u5f0f\u662f\u5426\u80fd\u4e3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7c7b\u4f3c\u5927\u578b\u4e13\u6709\u6a21\u578b\u7684\u6027\u80fd\u63d0\u5347\uff0c\u89e3\u51b3\u5de5\u4e1a\u573a\u666f\u4e2d\u56e0\u6570\u636e\u5b89\u5168\u548c\u9884\u7b97\u9650\u5236\u65e0\u6cd5\u6301\u7eed\u4f9d\u8d56\u516c\u5171API\u7684\u95ee\u9898\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u5b9a\u4e49Agent Skill\u8fc7\u7a0b\u7684\u6570\u5b66\u6a21\u578b\uff0c\u7136\u540e\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u7528\u4f8b\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u4e24\u4e2a\u5f00\u6e90\u4efb\u52a1\u548c\u4e00\u4e2a\u771f\u5b9e\u4e16\u754c\u4fdd\u9669\u7d22\u8d54\u6570\u636e\u96c6\u3002", "result": "\u8d85\u5c0f\u578b\u6a21\u578b\u5728\u53ef\u9760\u6280\u80fd\u9009\u62e9\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e2d\u7b49\u89c4\u6a21SLMs\uff08\u7ea612B-30B\u53c2\u6570\uff09\u4eceAgent Skill\u65b9\u6cd5\u4e2d\u83b7\u76ca\u663e\u8457\uff0c\u7ea680B\u53c2\u6570\u7684\u4ee3\u7801\u4e13\u7528\u53d8\u4f53\u5728\u63d0\u5347GPU\u6548\u7387\u7684\u540c\u65f6\u8fbe\u5230\u95ed\u6e90\u57fa\u7ebf\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u5168\u9762\u63cf\u8ff0\u4e86Agent Skill\u6846\u67b6\u5728\u5c0f\u8bed\u8a00\u6a21\u578b\u73af\u5883\u4e2d\u7684\u80fd\u529b\u548c\u9650\u5236\uff0c\u4e3a\u5728SLM\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u6709\u6548\u90e8\u7f72Agent Skills\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
