<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.SI](#cs.SI) [Total: 4]
- [econ.GN](#econ.GN) [Total: 8]
- [cs.ET](#cs.ET) [Total: 3]
- [eess.SY](#eess.SY) [Total: 24]
- [econ.EM](#econ.EM) [Total: 1]
- [econ.TH](#econ.TH) [Total: 1]
- [stat.AP](#stat.AP) [Total: 5]
- [cs.CY](#cs.CY) [Total: 9]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Practical and Performant Enhancements for Maximization of Algebraic Connectivity](https://arxiv.org/abs/2511.08694)
*Leonard Jung,Alan Papalia,Kevin Doherty,Michael Everett*

Main category: cs.RO

TL;DR: 本文改进了图稀疏化算法MAC，通过开发专用求解器、优化步长策略和自动连通性保证方案，使其更适合实时估计应用。


<details>
  <summary>Details</summary>
Motivation: 当前图估计方法在大型长期图上扩展性差，MAC算法虽然能保持估计性能但计算成本高且需要手动指定连通边集，限制了其在线使用。

Method: 开发了专用代数连通性求解器（2倍加速）、优化MAC优化过程的步长策略、提出自动连通性保证方案。

Result: 这些改进使MAC算法更加可扩展、可靠，适合实时估计应用。

Conclusion: 通过三方面的互补改进，解决了MAC算法的计算瓶颈和手动配置问题，使其成为更实用的实时图估计工具。

Abstract: Long-term state estimation over graphs remains challenging as current graph estimation methods scale poorly on large, long-term graphs. To address this, our work advances a current state-of-the-art graph sparsification algorithm, maximizing algebraic connectivity (MAC). MAC is a sparsification method that preserves estimation performance by maximizing the algebraic connectivity, a spectral graph property that is directly connected to the estimation error. Unfortunately, MAC remains computationally prohibitive for online use and requires users to manually pre-specify a connectivity-preserving edge set. Our contributions close these gaps along three complementary fronts: we develop a specialized solver for algebraic connectivity that yields an average 2x runtime speedup; we investigate advanced step size strategies for MAC's optimization procedure to enhance both convergence speed and solution quality; and we propose automatic schemes that guarantee graph connectivity without requiring manual specification of edges. Together, these contributions make MAC more scalable, reliable, and suitable for real-time estimation applications.

</details>


### [2] [Intuitive Programming, Adaptive Task Planning, and Dynamic Role Allocation in Human-Robot Collaboration](https://arxiv.org/abs/2511.08732)
*Marta Lagomarsino,Elena Merlo,Andrea Pupa,Timo Birr,Franziska Krebs,Cristian Secchi,Tamim Asfour,Arash Ajoudani*

Main category: cs.RO

TL;DR: 这篇综述论文探讨了实现人机协同合作的关键组件，重点关注直觉信息交换和技能转移，涵盖从多模态输入到机器人可理解表示的转换、自适应规划和角色分配，以及控制层和反馈机制。


<details>
  <summary>Details</summary>
Motivation: 当前机器人和AI在复杂任务和环境方面取得了显著能力，但人类往往只是被动观察者。机器人要在人类环境中发挥全部潜力，需要有效建模人类状态和意图并调整行为，实现协同的人机协作。

Method: 通过建立连续信息流：人类直觉地传达指令、分享专业知识和表达需求，同时机器人清晰传达内部状态和即将采取的行动。论文审查了完整的交互流程，包括人机通信桥梁、自适应规划和角色分配、控制层和反馈机制。

Result: 识别并连接了实现人机间直觉信息交换和技能转移的关键组件，建立了完整的人机协作交互管道。

Conclusion: 论文指出了实现更自适应、可访问的人机协作的趋势和有前景的方向，强调了建立双向信息流对于实现真正协同人机合作的重要性。

Abstract: Remarkable capabilities have been achieved by robotics and AI, mastering complex tasks and environments. Yet, humans often remain passive observers, fascinated but uncertain how to engage. Robots, in turn, cannot reach their full potential in human-populated environments without effectively modeling human states and intentions and adapting their behavior. To achieve a synergistic human-robot collaboration (HRC), a continuous information flow should be established: humans must intuitively communicate instructions, share expertise, and express needs. In parallel, robots must clearly convey their internal state and forthcoming actions to keep users informed, comfortable, and in control. This review identifies and connects key components enabling intuitive information exchange and skill transfer between humans and robots. We examine the full interaction pipeline: from the human-to-robot communication bridge translating multimodal inputs into robot-understandable representations, through adaptive planning and role allocation, to the control layer and feedback mechanisms to close the loop. Finally, we highlight trends and promising directions toward more adaptive, accessible HRC.

</details>


### [3] [ATOM-CBF: Adaptive Safe Perception-Based Control under Out-of-Distribution Measurements](https://arxiv.org/abs/2511.08741)
*Kai S. Yun,Navid Azizan*

Main category: cs.RO

TL;DR: ATOM-CBF是一个新颖的安全控制框架，通过显式计算和适应分布外测量中的认知不确定性来确保系统安全，无需真实标签或分布偏移信息。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统依赖学习感知模块从高维传感器数据推断系统状态，但这些模块容易受到认知不确定性的影响，在遇到训练时未见过的分布外测量时会失效，从而威胁系统安全。

Method: 提出ATOM-CBF框架，包含两个关键组件：(1) 分布外感知的自适应感知误差边界；(2) 集成此自适应误差边界的安全过滤器，使其能够实时调整保守程度。

Result: 在仿真中进行了实证验证，证明ATOM-CBF能够确保配备LiDAR扫描的F1Tenth车辆和配备RGB图像的四足机器人的安全性。

Conclusion: ATOM-CBF框架通过显式处理分布外测量中的认知不确定性，有效解决了学习感知模块在现实世界系统中的安全问题，无需依赖真实标签或分布偏移信息。

Abstract: Ensuring the safety of real-world systems is challenging, especially when they rely on learned perception modules to infer the system state from high-dimensional sensor data. These perception modules are vulnerable to epistemic uncertainty, often failing when encountering out-of-distribution (OoD) measurements not seen during training. To address this gap, we introduce ATOM-CBF (Adaptive-To-OoD-Measurement Control Barrier Function), a novel safe control framework that explicitly computes and adapts to the epistemic uncertainty from OoD measurements, without the need for ground-truth labels or information on distribution shifts. Our approach features two key components: (1) an OoD-aware adaptive perception error margin and (2) a safety filter that integrates this adaptive error margin, enabling the filter to adjust its conservatism in real-time. We provide empirical validation in simulations, demonstrating that ATOM-CBF maintains safety for an F1Tenth vehicle with LiDAR scans and a quadruped robot with RGB images.

</details>


### [4] [CENIC: Convex Error-controlled Numerical Integration for Contact](https://arxiv.org/abs/2511.08771)
*Vince Kurtz,Alejandro Castro*

Main category: cs.RO

TL;DR: CENIC是一种新的连续时间积分器，结合了凸时间步进和误差控制积分的优势，能够在保持实时速率的同时提供精度和收敛性保证。


<details>
  <summary>Details</summary>
Motivation: 现有机器人模拟器使用离散时间步长，需要用户选择时间步长，这既关键又具有挑战性：大步长会产生非物理伪影，而小步长会降低模拟速度。误差控制连续时间积分可以避免这些问题，但现有方法难以处理接触的刚性动力学，无法满足现代机器人工作流程的速度和可扩展性要求。

Method: CENIC结合了凸时间步进和误差控制积分的最新进展，继承了连续积分和离散时间步进的优点。

Result: CENIC能够以与MuJoCo、Drake和Isaac Sim等离散时间机器人模拟器相当的快速实时速率运行，同时提供精度和收敛性保证。

Conclusion: CENIC成功地将连续时间积分的精度优势与离散时间模拟器的速度优势相结合，为机器人模拟提供了更好的解决方案。

Abstract: State-of-the-art robotics simulators operate in discrete time. This requires users to choose a time step, which is both critical and challenging: large steps can produce non-physical artifacts, while small steps force the simulation to run slowly. Continuous-time error-controlled integration avoids such issues by automatically adjusting the time step to achieve a desired accuracy. But existing error-controlled integrators struggle with the stiff dynamics of contact, and cannot meet the speed and scalability requirements of modern robotics workflows. We introduce CENIC, a new continuous-time integrator that brings together recent advances in convex time-stepping and error-controlled integration, inheriting benefits from both continuous integration and discrete time-stepping. CENIC runs at fast real-time rates comparable to discrete-time robotics simulators like MuJoCo, Drake and Isaac Sim, while also providing guarantees on accuracy and convergence.

</details>


### [5] [Dual-Arm Whole-Body Motion Planning: Leveraging Overlapping Kinematic Chains](https://arxiv.org/abs/2511.08778)
*Richard Cheng,Peter Werner,Carolyn Matl*

Main category: cs.RO

TL;DR: 提出一种针对双机械臂机器人的高效运动规划方法，通过利用共享关节结构构建动态路标图，在19自由度移动操作机器人上实现0.4秒平均规划时间和99.9%成功率


<details>
  <summary>Details</summary>
Motivation: 解决高自由度双机械臂机器人在未知动态环境中实时运动规划的挑战，克服配置空间高维度和复杂避障约束带来的维度灾难问题

Method: 为每个运动链（左臂+躯干、右臂+躯干）构建具有共享关节结构的动态路标图，并利用这种结构高效搜索两个路标图的组合

Result: 在真实超市环境中进行杂货配送任务测试，超过2000次运动规划的平均规划时间为0.4秒，成功率达到99.9%

Conclusion: 通过利用双机械臂机器人共享关节的结构特性，可以有效缓解维度灾难问题，实现高效的实时运动规划

Abstract: High degree-of-freedom dual-arm robots are becoming increasingly common due to their morphology enabling them to operate effectively in human environments. However, motion planning in real-time within unknown, changing environments remains a challenge for such robots due to the high dimensionality of the configuration space and the complex collision-avoidance constraints that must be obeyed. In this work, we propose a novel way to alleviate the curse of dimensionality by leveraging the structure imposed by shared joints (e.g. torso joints) in a dual-arm robot. First, we build two dynamic roadmaps (DRM) for each kinematic chain (i.e. left arm + torso, right arm + torso) with specific structure induced by the shared joints. Then, we show that we can leverage this structure to efficiently search through the composition of the two roadmaps and largely sidestep the curse of dimensionality. Finally, we run several experiments in a real-world grocery store with this motion planner on a 19 DoF mobile manipulation robot executing a grocery fulfillment task, achieving 0.4s average planning times with 99.9% success rate across more than 2000 motion plans.

</details>


### [6] [Low-cost Multi-agent Fleet for Acoustic Cooperative Localization Research](https://arxiv.org/abs/2511.08822)
*Nelson Durrant,Braden Meyers,Matthew McMurray,Clayton Smith,Brighton Anderson,Tristan Hodgins,Kalliyan Velasco,Joshua G. Mangelson*

Main category: cs.RO

TL;DR: 开发了低成本、可配置的CoUGARs自主水下机器人平台，用于多智能体自主性研究，成本低于3000美元，支持声学协同定位研究。


<details>
  <summary>Details</summary>
Motivation: 现实世界水下多智能体自主性测试面临高昂的财务和工程挑战，需要低成本的测试平台。

Method: 基于商用和3D打印部件设计CoUGARs平台，配备DVL和USBL声学阵列，使用容器化软件栈进行状态估计、导航和声学通信。

Result: 系统在仿真和犹他州湖泊水库的实地试验中进行了测试验证。

Conclusion: CoUGARs为多智能体自主性研究提供了经济实惠且可配置的解决方案。

Abstract: Real-world underwater testing for multi-agent autonomy presents substantial financial and engineering challenges. In this work, we introduce the Configurable Underwater Group of Autonomous Robots (CoUGARs) as a low-cost, configurable autonomous-underwater-vehicle (AUV) platform for multi-agent autonomy research. The base design costs less than $3,000 USD (as of May 2025) and is based on commercially-available and 3D-printed parts, enabling quick customization for various sensor payloads and configurations. Our current expanded model is equipped with a doppler velocity log (DVL) and ultra-short-baseline (USBL) acoustic array/transducer to support research on acoustic-based cooperative localization. State estimation, navigation, and acoustic communications software has been developed and deployed using a containerized software stack and is tightly integrated with the HoloOcean simulator. The system was tested both in simulation and via in-situ field trials in Utah lakes and reservoirs.

</details>


### [7] [XPRESS: X-Band Radar Place Recognition via Elliptical Scan Shaping](https://arxiv.org/abs/2511.08863)
*Hyesu Jang,Wooseong Yang,Ayoung Kim,Dongje Lee,Hanguen Kim*

Main category: cs.RO

TL;DR: 提出了一种专为X波段雷达设计的场所识别算法，通过基于物体密度的候选选择规则和故意降低雷达检测分辨率来实现稳健的检索性能。


<details>
  <summary>Details</summary>
Motivation: X波段雷达作为海上船只的主要传感器，但由于传感器分辨率低和信息内容不足，在自主导航中的应用受到限制。

Method: 采用基于物体密度的规则进行高效候选选择，并故意降低雷达检测分辨率以实现稳健检索性能。

Result: 在公共海事雷达数据集和自收集数据集上进行了评估，并与最先进的雷达场所识别方法进行了性能比较。

Conclusion: 通过消融研究评估了算法对关键参数的敏感性，证明了该算法在X波段雷达自主导航中的有效性。

Abstract: X-band radar serves as the primary sensor on maritime vessels, however, its application in autonomous navigation has been limited due to low sensor resolution and insufficient information content. To enable X-band radar-only autonomous navigation in maritime environments, this paper proposes a place recognition algorithm specifically tailored for X-band radar, incorporating an object density-based rule for efficient candidate selection and intentional degradation of radar detections to achieve robust retrieval performance. The proposed algorithm was evaluated on both public maritime radar datasets and our own collected dataset, and its performance was compared against state-of-the-art radar place recognition methods. An ablation study was conducted to assess the algorithm's performance sensitivity with respect to key parameters.

</details>


### [8] [MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror](https://arxiv.org/abs/2511.08865)
*Cong Tai,Hansheng Wu,Haixu Long,Zhengbin Long,Zhaoyu Zheng,Haodong Xiang,Tao Shen*

Main category: cs.RO

TL;DR: 提出基于PICO的机器人远程操作框架，实现低成本实时手部运动捕捉，兼容RealMirror生态系统，支持机器人轨迹记录和实时遥操作


<details>
  <summary>Details</summary>
Motivation: 降低上肢机器人操作研究的技术门槛，加速VLA相关研究发展

Method: 开发PICO-based机器人远程操作框架，实现低成本实时手部运动姿态数据采集，兼容RealMirror生态系统和Isaac仿真环境

Result: 框架在成本效益上优于主流视觉跟踪和动作捕捉方案，支持稳定精确的机器人轨迹记录和各种末端执行器的实时遥操作

Conclusion: 该工作为构建VLA数据集提供了便捷工具，有效促进了上肢机器人操作和VLA相关研究的发展

Abstract: In this work, we present a PICO-based robot remote operating framework that enables low-cost, real-time acquisition of hand motion and pose data, outperforming mainstream visual tracking and motion capture solutions in terms of cost-effectiveness. The framework is natively compatible with the RealMirror ecosystem, offering ready-to-use functionality for stable and precise robotic trajectory recording within the Isaac simulation environment, thereby facilitating the construction of Vision-Language-Action (VLA) datasets. Additionally, the system supports real-time teleoperation of a variety of end-effector-equipped robots, including dexterous hands and robotic grippers. This work aims to lower the technical barriers in the study of upper-limb robotic manipulation, thereby accelerating advancements in VLA-related research.

</details>


### [9] [A Shared Control Framework for Mobile Robots with Planning-Level Intention Prediction](https://arxiv.org/abs/2511.08912)
*Jinyu Zhang,Lijun Han,Feng Jian,Lingxi Zhang,Hesheng Wang*

Main category: cs.RO

TL;DR: 提出了一种基于规划级意图预测的移动机器人共享控制框架，通过意图域表示未来运动意图，结合深度强化学习进行路径重规划，显著降低操作员工作负荷并提高安全性。


<details>
  <summary>Details</summary>
Motivation: 在移动机器人共享控制中，准确理解人类运动意图对于实现无缝人机协作至关重要，现有方法在意图预测和路径规划方面存在局限。

Method: 引入意图域概念表示未来运动意图，将意图域预测和路径重规划问题建模为马尔可夫决策过程，通过深度强化学习求解，并开发基于Voronoi图的人类轨迹生成算法实现无监督训练。

Result: 大量仿真和真实用户研究表明，该方法相比现有辅助遥操作方法显著降低了操作员工作负荷，提高了安全性，同时保持了任务效率。

Conclusion: 所提出的共享控制框架通过规划级意图预测和深度强化学习路径重规划，有效提升了人机协作的性能和安全性，为移动机器人共享控制提供了新的解决方案。

Abstract: In mobile robot shared control, effectively understanding human motion intention is critical for seamless human-robot collaboration. This paper presents a novel shared control framework featuring planning-level intention prediction. A path replanning algorithm is designed to adjust the robot's desired trajectory according to inferred human intentions. To represent future motion intentions, we introduce the concept of an intention domain, which serves as a constraint for path replanning. The intention-domain prediction and path replanning problems are jointly formulated as a Markov Decision Process and solved through deep reinforcement learning. In addition, a Voronoi-based human trajectory generation algorithm is developed, allowing the model to be trained entirely in simulation without human participation or demonstration data. Extensive simulations and real-world user studies demonstrate that the proposed method significantly reduces operator workload and enhances safety, without compromising task efficiency compared with existing assistive teleoperation approaches.

</details>


### [10] [Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation](https://arxiv.org/abs/2511.08935)
*Ningnan Wang,Weihuang Chen,Liming Chen,Haoxuan Ji,Zhongyu Guo,Xuchong Zhang,Hongbin Sun*

Main category: cs.RO

TL;DR: SCOPE是一个零样本视觉导航框架，通过显式利用边界信息驱动基于潜力的探索，结合时空潜力图捕获边界动态，并引入自我重新考虑机制来提升决策可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有零样本研究忽略了视觉边界对轨迹和观测的根本影响，且未能推断部分视觉观察与导航目标之间的关系，导致长时程规划性能受限。

Method: 使用视觉语言模型估计探索潜力，构建时空潜力图捕获边界动态，并引入自我重新考虑机制重新评估和优化先前决策。

Result: 在两个不同的具身导航任务中，SCOPE比最先进基线方法准确率提升4.6%，核心组件带来更好的校准、更强的泛化能力和更高的决策质量。

Conclusion: SCOPE通过显式利用边界信息和自我重新考虑机制，有效提升了零样本视觉导航的性能和可靠性。

Abstract: Embodied visual navigation remains a challenging task, as agents must explore unknown environments with limited knowledge. Existing zero-shot studies have shown that incorporating memory mechanisms to support goal-directed behavior can improve long-horizon planning performance. However, they overlook visual frontier boundaries, which fundamentally dictate future trajectories and observations, and fall short of inferring the relationship between partial visual observations and navigation goals. In this paper, we propose Semantic Cognition Over Potential-based Exploration (SCOPE), a zero-shot framework that explicitly leverages frontier information to drive potential-based exploration, enabling more informed and goal-relevant decisions. SCOPE estimates exploration potential with a Vision-Language Model and organizes it into a spatio-temporal potential graph, capturing boundary dynamics to support long-horizon planning. In addition, SCOPE incorporates a self-reconsideration mechanism that revisits and refines prior decisions, enhancing reliability and reducing overconfident errors. Experimental results on two diverse embodied navigation tasks show that SCOPE outperforms state-of-the-art baselines by 4.6\% in accuracy. Further analysis demonstrates that its core components lead to improved calibration, stronger generalization, and higher decision quality.

</details>


### [11] [Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning](https://arxiv.org/abs/2511.08942)
*Mobin Habibpour,Fatemeh Afghah*

Main category: cs.RO

TL;DR: 该论文提出了一种新框架，将视觉语言模型（VLM）从被动观察者转变为主动策略制定者，通过结构化思维链提示、动态动作历史集成和障碍地图理解来指导前沿探索代理，显著提升了导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用VLM在机器人导航中的推理能力，需要将其角色从被动观察者转变为主动策略制定者，以释放VLM在机器人领域的全部潜力。

Method: 采用结构化思维链提示激发逻辑推理，动态集成代理的近期动作历史防止陷入循环，以及新颖的障碍地图与第一人称视图联合理解能力增强空间感知。

Result: 在HM3D、Gibson和MP3D等挑战性基准测试中，该方法产生了极其直接和逻辑的轨迹，导航效率相比现有方法有显著提升。

Conclusion: 该方法为开发更具能力的具身智能体开辟了新路径，展示了VLM作为主动策略制定者在机器人导航中的巨大潜力。

Abstract: While Vision-Language Models (VLMs) are set to transform robotic navigation, existing methods often underutilize their reasoning capabilities. To unlock the full potential of VLMs in robotics, we shift their role from passive observers to active strategists in the navigation process. Our framework outsources high-level planning to a VLM, which leverages its contextual understanding to guide a frontier-based exploration agent. This intelligent guidance is achieved through a trio of techniques: structured chain-of-thought prompting that elicits logical, step-by-step reasoning; dynamic inclusion of the agent's recent action history to prevent getting stuck in loops; and a novel capability that enables the VLM to interpret top-down obstacle maps alongside first-person views, thereby enhancing spatial awareness. When tested on challenging benchmarks like HM3D, Gibson, and MP3D, this method produces exceptionally direct and logical trajectories, marking a substantial improvement in navigation efficiency over existing approaches and charting a path toward more capable embodied agents.

</details>


### [12] [UniMM-V2X: MoE-Enhanced Multi-Level Fusion for End-to-End Cooperative Autonomous Driving](https://arxiv.org/abs/2511.09013)
*Ziyi Song,Chen Xia,Chenbing Wang,Haibao Yu,Sheng Zhou,Zhisheng Niu*

Main category: cs.RO

TL;DR: UniMM-V2X是一个端到端多智能体框架，通过多层次融合策略实现感知、预测和规划的层次化协作，采用MoE架构动态增强BEV表示，在DAIR-V2X数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统存在感知有限和孤立决策的问题，现有多智能体方法大多只关注感知层面协作，忽视了与下游规划控制的协调，未能充分利用端到端自动驾驶的潜力。

Method: 提出多层次融合策略统一感知和预测协作，采用MoE架构动态增强BEV表示，并将MoE扩展到解码器以更好捕捉多样化运动模式。

Result: 在DAIR-V2X数据集上，感知精度提升39.7%，预测误差降低7.2%，规划性能提升33.2%，相比UniV2X表现优异。

Conclusion: MoE增强的多层次协作范式展现了强大性能，证明了端到端多智能体框架在自动驾驶中的有效性。

Abstract: Autonomous driving holds transformative potential but remains fundamentally constrained by the limited perception and isolated decision-making with standalone intelligence. While recent multi-agent approaches introduce cooperation, they often focus merely on perception-level tasks, overlooking the alignment with downstream planning and control, or fall short in leveraging the full capacity of the recent emerging end-to-end autonomous driving. In this paper, we present UniMM-V2X, a novel end-to-end multi-agent framework that enables hierarchical cooperation across perception, prediction, and planning. At the core of our framework is a multi-level fusion strategy that unifies perception and prediction cooperation, allowing agents to share queries and reason cooperatively for consistent and safe decision-making. To adapt to diverse downstream tasks and further enhance the quality of multi-level fusion, we incorporate a Mixture-of-Experts (MoE) architecture to dynamically enhance the BEV representations. We further extend MoE into the decoder to better capture diverse motion patterns. Extensive experiments on the DAIR-V2X dataset demonstrate our approach achieves state-of-the-art (SOTA) performance with a 39.7% improvement in perception accuracy, a 7.2% reduction in prediction error, and a 33.2% improvement in planning performance compared with UniV2X, showcasing the strength of our MoE-enhanced multi-level cooperative paradigm.

</details>


### [13] [A Quantum Tunneling and Bio-Phototactic Driven Enhanced Dwarf Mongoose Optimizer for UAV Trajectory Planning and Engineering Problem](https://arxiv.org/abs/2511.09020)
*Mingyang Yu,Haorui Yang,Kangning An,Xinjian Wei,Xiaoxuan Xu,Jing Xu*

Main category: cs.RO

TL;DR: 提出增强型多策略矮獴优化算法(EDMO)用于无人机三维轨迹规划，通过三种新策略解决局部最优和多样性不足问题，在标准测试和实际应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式算法在复杂无人机路径规划中存在早熟收敛和解决方案多样性不足的问题，需要改进算法性能。

Method: 集成三种新策略：动态量子隧穿优化策略(DQTOS)用于逃离局部最优；生物趋光动态聚焦搜索策略(BDFSS)用于自适应局部优化；正交透镜对立学习策略(OLOBL)用于增强全局探索。

Result: 在CEC2017和CEC2020的39个标准测试函数上优于14种先进算法，在收敛速度、鲁棒性和优化精度方面表现突出，并在实际无人机路径规划和工程设计中验证了有效性。

Conclusion: EDMO算法在复杂动态环境中具有优异的路径规划能力，为需要智能、自适应和高效规划的现场机器人任务提供了实用解决方案。

Abstract: With the widespread adoption of unmanned aerial vehicles (UAV), effective path planning has become increasingly important. Although traditional search methods have been extensively applied, metaheuristic algorithms have gained popularity due to their efficiency and problem-specific heuristics. However, challenges such as premature convergence and lack of solution diversity still hinder their performance in complex scenarios. To address these issues, this paper proposes an Enhanced Multi-Strategy Dwarf Mongoose Optimization (EDMO) algorithm, tailored for three-dimensional UAV trajectory planning in dynamic and obstacle-rich environments. EDMO integrates three novel strategies: (1) a Dynamic Quantum Tunneling Optimization Strategy (DQTOS) to enable particles to probabilistically escape local optima; (2) a Bio-phototactic Dynamic Focusing Search Strategy (BDFSS) inspired by microbial phototaxis for adaptive local refinement; and (3) an Orthogonal Lens Opposition-Based Learning (OLOBL) strategy to enhance global exploration through structured dimensional recombination. EDMO is benchmarked on 39 standard test functions from CEC2017 and CEC2020, outperforming 14 advanced algorithms in convergence speed, robustness, and optimization accuracy. Furthermore, real-world validations on UAV three-dimensional path planning and three engineering design tasks confirm its practical applicability and effectiveness in field robotics missions requiring intelligent, adaptive, and time-efficient planning.

</details>


### [14] [SMF-VO: Direct Ego-Motion Estimation via Sparse Motion Fields](https://arxiv.org/abs/2511.09072)
*Sangheon Yang,Yeongin Yoon,Hong Mo Jung,Jongwoo Lim*

Main category: cs.RO

TL;DR: SMF-VO是一种轻量级的视觉里程计方法，通过稀疏光流直接估计瞬时线速度和角速度，绕过了传统方法中昂贵的姿态估计和地标跟踪，在树莓派5上仅使用CPU即可实现超过100 FPS的性能。


<details>
  <summary>Details</summary>
Motivation: 传统视觉里程计和视觉惯性里程计方法依赖于'姿态中心'范式，需要大规模地标维护和连续地图优化，计算成本高，限制了在资源受限设备上的实时性能。

Method: 提出稀疏运动场视觉里程计(SMF-VO)，采用'运动中心'框架，直接从稀疏光流估计瞬时线速度和角速度，使用通用的3D射线运动场公式，适用于各种相机模型包括广角镜头。

Result: 在基准数据集上展示了优越的效率和竞争性的精度，在树莓派5上仅使用CPU即可实现超过100 FPS的性能。

Conclusion: 为传统方法建立了一个可扩展且高效的替代方案，非常适合移动机器人和可穿戴设备。

Abstract: Traditional Visual Odometry (VO) and Visual Inertial Odometry (VIO) methods rely on a 'pose-centric' paradigm, which computes absolute camera poses from the local map thus requires large-scale landmark maintenance and continuous map optimization. This approach is computationally expensive, limiting their real-time performance on resource-constrained devices. To overcome these limitations, we introduce Sparse Motion Field Visual Odometry (SMF-VO), a lightweight, 'motion-centric' framework. Our approach directly estimates instantaneous linear and angular velocity from sparse optical flow, bypassing the need for explicit pose estimation or expensive landmark tracking. We also employed a generalized 3D ray-based motion field formulation that works accurately with various camera models, including wide-field-of-view lenses. SMF-VO demonstrates superior efficiency and competitive accuracy on benchmark datasets, achieving over 100 FPS on a Raspberry Pi 5 using only a CPU. Our work establishes a scalable and efficient alternative to conventional methods, making it highly suitable for mobile robotics and wearable devices.

</details>


### [15] [D-AWSIM: Distributed Autonomous Driving Simulator for Dynamic Map Generation Framework](https://arxiv.org/abs/2511.09080)
*Shunsuke Ito,Chaoran Zhao,Ryo Okamura,Takuya Azumi*

Main category: cs.RO

TL;DR: D-AWSIM是一个分布式模拟器，通过在多台机器间分配工作负载来支持大规模传感器部署和密集交通环境的仿真，为自动驾驶研究提供动态地图生成框架。


<details>
  <summary>Details</summary>
Motivation: 现实世界基础设施传感器实验成本高昂且面临监管挑战，传统单机模拟器无法处理大规模城市交通场景，需要分布式解决方案来支持信息共享策略研究。

Method: 提出D-AWSIM分布式模拟器，将工作负载分配到多台机器上，支持大规模传感器部署和密集交通环境仿真，并集成动态地图生成框架。

Result: 评估显示，与单机设置相比，D-AWSIM在车辆数量和LiDAR传感器处理方面的吞吐量显著提高，并与Autoware集成验证了其在自动驾驶研究中的适用性。

Conclusion: D-AWSIM为研究人员提供了无需依赖物理测试平台的信息共享策略探索能力，是自动驾驶系统大规模仿真研究的有效工具。

Abstract: Autonomous driving systems have achieved significant advances, and full autonomy within defined operational design domains near practical deployment. Expanding these domains requires addressing safety assurance under diverse conditions. Information sharing through vehicle-to-vehicle and vehicle-to-infrastructure communication, enabled by a Dynamic Map platform built from vehicle and roadside sensor data, offers a promising solution. Real-world experiments with numerous infrastructure sensors incur high costs and regulatory challenges. Conventional single-host simulators lack the capacity for large-scale urban traffic scenarios. This paper proposes D-AWSIM, a distributed simulator that partitions its workload across multiple machines to support the simulation of extensive sensor deployment and dense traffic environments. A Dynamic Map generation framework on D-AWSIM enables researchers to explore information-sharing strategies without relying on physical testbeds. The evaluation shows that D-AWSIM increases throughput for vehicle count and LiDAR sensor processing substantially compared to a single-machine setup. Integration with Autoware demonstrates applicability for autonomous driving research.

</details>


### [16] [APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots](https://arxiv.org/abs/2511.09091)
*Shivam Sood,Laukik Nakhwa,Sun Ge,Yuhong Cao,Jin Cheng,Fatemah Zargarbashi,Taerim Yoon,Sungjoon Choi,Stelian Coros,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: APEX是一种即插即用的强化学习扩展方法，通过整合专家演示的动作先验来提高四足机器人的运动学习效率和泛化能力，无需在部署时依赖参考数据。


<details>
  <summary>Details</summary>
Motivation: 现有的运动跟踪方法需要大量调参且在部署时依赖参考数据，限制了机器人的适应性。需要一种能够提高样本效率、减少调参工作并消除部署时对参考数据依赖的方法。

Method: APEX结合了衰减动作先验和多批评器框架。动作先验在训练初期偏向专家演示，随后逐渐允许策略独立探索；多批评器平衡任务性能与运动风格。

Result: 在仿真和Unitree Go2机器人上的实验表明，APEX能够学习多样化的运动，在不同地形和速度下转移参考风格，且对奖励设计变化具有鲁棒性。

Conclusion: APEX通过演示引导强化学习探索，提高了学习稳定性、效率和泛化能力，为从运动到操作等各种机器人任务的自然技能获取开辟了新途径。

Abstract: Learning natural, animal-like locomotion from demonstrations has become a core paradigm in legged robotics. Despite the recent advancements in motion tracking, most existing methods demand extensive tuning and rely on reference data during deployment, limiting adaptability. We present APEX (Action Priors enable Efficient Exploration), a plug-and-play extension to state-of-the-art motion tracking algorithms that eliminates any dependence on reference data during deployment, improves sample efficiency, and reduces parameter tuning effort. APEX integrates expert demonstrations directly into reinforcement learning (RL) by incorporating decaying action priors, which initially bias exploration toward expert demonstrations but gradually allow the policy to explore independently. This is combined with a multi-critic framework that balances task performance with motion style. Moreover, APEX enables a single policy to learn diverse motions and transfer reference-like styles across different terrains and velocities, while remaining robust to variations in reward design. We validate the effectiveness of our method through extensive experiments in both simulation and on a Unitree Go2 robot. By leveraging demonstrations to guide exploration during RL training, without imposing explicit bias toward them, APEX enables legged robots to learn with greater stability, efficiency, and generalization. We believe this approach paves the way for guidance-driven RL to boost natural skill acquisition in a wide array of robotic tasks, from locomotion to manipulation. Website and code: https://marmotlab.github.io/APEX/.

</details>


### [17] [Decoupling Torque and Stiffness: A Unified Modeling and Control Framework for Antagonistic Artificial Muscles](https://arxiv.org/abs/2511.09104)
*Amirhossein Kazemipour,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出了一个统一框架，实现软肌肉执行器的实时独立扭矩和刚度控制，通过级联控制器和分析逆动力学保持解耦，在接触实验中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有软肌肉控制器难以在动态接触瞬态中维持独立控制，需要实现类似生物阻抗策略的扭矩-刚度解耦控制。

Method: 使用统一力律捕捉多种软肌肉物理特性，采用级联控制器和分析逆动力学，通过共收缩/偏置坐标独立调制扭矩和刚度。

Result: 在接触实验中保持独立性：软表面200倍更快稳定，刚性表面81%力减少，稳定交互对比固定策略的22-54%稳定性。

Conclusion: 该框架为肌肉骨骼拮抗系统实现自适应阻抗控制提供了基础，支持安全的人机交互。

Abstract: Antagonistic soft actuators built from artificial muscles (PAMs, HASELs, DEAs) promise plant-level torque-stiffness decoupling, yet existing controllers for soft muscles struggle to maintain independent control through dynamic contact transients. We present a unified framework enabling independent torque and stiffness commands in real-time for diverse soft actuator types. Our unified force law captures diverse soft muscle physics in a single model with sub-ms computation, while our cascaded controller with analytical inverse dynamics maintains decoupling despite model errors and disturbances. Using co-contraction/bias coordinates, the controller independently modulates torque via bias and stiffness via co-contraction-replicating biological impedance strategies. Simulation-based validation through contact experiments demonstrates maintained independence: 200x faster settling on soft surfaces, 81% force reduction on rigid surfaces, and stable interaction vs 22-54% stability for fixed policies. This framework provides a foundation for enabling musculoskeletal antagonistic systems to execute adaptive impedance control for safe human-robot interaction.

</details>


### [18] [Data Assessment for Embodied Intelligence](https://arxiv.org/abs/2511.09119)
*Jiahao Xiao,Bowen Yan,Jianbo Zhang,Jia Wang,Chunyi Li,Zhengxue Cheng,Guangtao Zhai*

Main category: cs.RO

TL;DR: 本文提出了两个数据驱动的工具来评估具身智能数据集：多样性熵（衡量数据集信息量）和可学习性量化算法（无需训练即可评估数据集的学习难度），解决了现有方法在评估多模态数据集时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集评估方法主要关注多样性（通过统计任务和场景数量），但无法全面衡量多模态数据的多样性；同时，数据集的可学习性评估通常需要通过模型训练这种昂贵且缺乏解释性的方法，无法为数据集改进提供指导。

Method: 1. 为每个数据样本构建统一的多模态表示，基于此提出多样性熵作为连续度量指标；2. 提出首个可解释的数据驱动算法，无需训练即可量化数据集的可学习性。

Result: 在模拟和真实世界具身数据集上的验证表明，该算法能够提供可靠且可操作的见解，使研究人员能够同时改进数据集的多样性和可学习性。

Conclusion: 这项工作为设计更高质量的具身智能数据集奠定了基础，有望推动具身智能的发展。

Abstract: In embodied intelligence, datasets play a pivotal role, serving as both a knowledge repository and a conduit for information transfer. The two most critical attributes of a dataset are the amount of information it provides and how easily this information can be learned by models. However, the multimodal nature of embodied data makes evaluating these properties particularly challenging. Prior work has largely focused on diversity, typically counting tasks and scenes or evaluating isolated modalities, which fails to provide a comprehensive picture of dataset diversity. On the other hand, the learnability of datasets has received little attention and is usually assessed post-hoc through model training, an expensive, time-consuming process that also lacks interpretability, offering little guidance on how to improve a dataset. In this work, we address both challenges by introducing two principled, data-driven tools. First, we construct a unified multimodal representation for each data sample and, based on it, propose diversity entropy, a continuous measure that characterizes the amount of information contained in a dataset. Second, we introduce the first interpretable, data-driven algorithm to efficiently quantify dataset learnability without training, enabling researchers to assess a dataset's learnability immediately upon its release. We validate our algorithm on both simulated and real-world embodied datasets, demonstrating that it yields faithful, actionable insights that enable researchers to jointly improve diversity and learnability. We hope this work provides a foundation for designing higher-quality datasets that advance the development of embodied intelligence.

</details>


### [19] [RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation](https://arxiv.org/abs/2511.09141)
*Xuetao Li,Wenke Huang,Nengyuan Pan,Kaiyan Zhao,Songhua Yang,Yiming Wang,Mengde Li,Mang Ye,Jifeng Xuan,Miao Li*

Main category: cs.RO

TL;DR: RGMP是一个端到端框架，通过几何先验技能选择器和自适应递归高斯网络，统一了几何语义技能推理与数据高效的视觉运动控制，在泛化测试中达到87%任务成功率，数据效率比最先进模型高5倍。


<details>
  <summary>Details</summary>
Motivation: 当前基于数据驱动的方法需要大量训练数据来实现鲁棒的多模态决策和可泛化的视觉运动控制，但忽视了未见场景中的几何推理，且对机器人-目标关系的建模效率低下，造成训练资源浪费。

Method: 提出RGMP框架：1) 几何先验技能选择器，将几何归纳偏置注入视觉语言模型，为未见场景生成自适应技能序列；2) 自适应递归高斯网络，将机器人-物体交互参数化为高斯过程层次结构，递归编码多尺度空间关系。

Result: 在类人机器人和桌面双臂机器人上评估，RGMP在泛化测试中达到87%任务成功率，数据效率比最先进模型高5倍，展现出优越的跨域泛化能力。

Conclusion: RGMP通过几何语义推理和递归高斯自适应，实现了数据高效的运动合成和强大的跨域泛化能力，为机器人技能学习提供了新的解决方案。

Abstract: Humanoid robots exhibit significant potential in executing diverse human-level skills. However, current research predominantly relies on data-driven approaches that necessitate extensive training datasets to achieve robust multimodal decision-making capabilities and generalizable visuomotor control. These methods raise concerns due to the neglect of geometric reasoning in unseen scenarios and the inefficient modeling of robot-target relationships within the training data, resulting in significant waste of training resources. To address these limitations, we present the Recurrent Geometric-prior Multimodal Policy (RGMP), an end-to-end framework that unifies geometric-semantic skill reasoning with data-efficient visuomotor control. For perception capabilities, we propose the Geometric-prior Skill Selector, which infuses geometric inductive biases into a vision language model, producing adaptive skill sequences for unseen scenes with minimal spatial common sense tuning. To achieve data-efficient robotic motion synthesis, we introduce the Adaptive Recursive Gaussian Network, which parameterizes robot-object interactions as a compact hierarchy of Gaussian processes that recursively encode multi-scale spatial relationships, yielding dexterous, data-efficient motion synthesis even from sparse demonstrations. Evaluated on both our humanoid robot and desktop dual-arm robot, the RGMP framework achieves 87% task success in generalization tests and exhibits 5x greater data efficiency than the state-of-the-art model. This performance underscores its superior cross-domain generalization, enabled by geometric-semantic reasoning and recursive-Gaussion adaptation.

</details>


### [20] [LODESTAR: Degeneracy-Aware LiDAR-Inertial Odometry with Adaptive Schmidt-Kalman Filter and Data Exploitation](https://arxiv.org/abs/2511.09142)
*Eungchang Mason Lee,Kevin Christiansen Marsim,Hyun Myung*

Main category: cs.RO

TL;DR: LODESTAR是一种新颖的LiDAR-惯性里程计方法，通过退化感知自适应Schmidt-Kalman滤波器和退化感知数据利用模块，解决在退化环境（如长走廊、高空飞行）中LiDAR测量不平衡或稀疏导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR-惯性里程计在退化环境中性能下降，因为LiDAR测量不平衡或稀疏会导致状态估计不准确。需要一种能够适应不同退化程度的方法来提高鲁棒性。

Method: 采用两个关键模块：DA-ASKF（退化感知自适应Schmidt-Kalman滤波器）使用滑动窗口和退化感知滑动模式，将状态分类为活动或固定；DA-DE（退化感知数据利用）基于局部化贡献和雅可比矩阵条件数，修剪非信息性测量并选择性利用固定状态的测量。

Result: 实验结果表明，LODESTAR在各种退化条件下，在准确性和鲁棒性方面优于现有的基于LiDAR的里程计方法和退化感知模块。

Conclusion: LODESTAR通过退化感知约束优化和测量稀疏性缓解，有效解决了LiDAR-惯性里程计在退化环境中的性能问题，提高了系统的准确性和鲁棒性。

Abstract: LiDAR-inertial odometry (LIO) has been widely used in robotics due to its high accuracy. However, its performance degrades in degenerate environments, such as long corridors and high-altitude flights, where LiDAR measurements are imbalanced or sparse, leading to ill-posed state estimation. In this letter, we present LODESTAR, a novel LIO method that addresses these degeneracies through two key modules: degeneracy-aware adaptive Schmidt-Kalman filter (DA-ASKF) and degeneracy-aware data exploitation (DA-DE). DA-ASKF employs a sliding window to utilize past states and measurements as additional constraints. Specifically, it introduces degeneracy-aware sliding modes that adaptively classify states as active or fixed based on their degeneracy level. Using Schmidt-Kalman update, it partially optimizes active states while preserving fixed states. These fixed states influence the update of active states via their covariances, serving as reference anchors--akin to a lodestar. Additionally, DA-DE prunes less-informative measurements from active states and selectively exploits measurements from fixed states, based on their localizability contribution and the condition number of the Jacobian matrix. Consequently, DA-ASKF enables degeneracy-aware constrained optimization and mitigates measurement sparsity, while DA-DE addresses measurement imbalance. Experimental results show that LODESTAR outperforms existing LiDAR-based odometry methods and degeneracy-aware modules in terms of accuracy and robustness under various degenerate conditions.

</details>


### [21] [Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots](https://arxiv.org/abs/2511.09241)
*Yuxi Wei,Zirui Wang,Kangning Yin,Yue Hu,Jingbo Wang,Siheng Chen*

Main category: cs.RO

TL;DR: Humanoid-Union是一个通过自主流水线生成的大规模人形机器人运动数据集，包含260多小时多样化高质量运动数据，并基于此提出SCHUR可扩展学习框架，在数据扩展下显著提升运动生成质量和文本对齐能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学习中数据扩展的瓶颈，利用丰富的人类视频和运动数据作为免费的大规模数据源，挖掘原始视频中的机器人可学习表示。

Method: 通过自主流水线生成Humanoid-Union大规模数据集，并基于此提出SCHUR可扩展学习框架，探索大规模数据对人形机器人高级控制的影响。

Result: SCHUR在数据扩展下实现了高质量机器人运动生成和强文本-运动对齐，MPJPE重建改进37%，FID对齐改进25%，并在真实人形机器人上验证了有效性。

Conclusion: Humanoid-Union数据集和SCHUR框架有效解决了机器人学习中的数据扩展问题，证明了大规模数据对提升人形机器人高级控制能力的重要性。

Abstract: Data scaling has long remained a critical bottleneck in robot learning. For humanoid robots, human videos and motion data are abundant and widely available, offering a free and large-scale data source. Besides, the semantics related to the motions enable modality alignment and high-level robot control learning. However, how to effectively mine raw video, extract robot-learnable representations, and leverage them for scalable learning remains an open problem. To address this, we introduce Humanoid-Union, a large-scale dataset generated through an autonomous pipeline, comprising over 260 hours of diverse, high-quality humanoid robot motion data with semantic annotations derived from human motion videos. The dataset can be further expanded via the same pipeline. Building on this data resource, we propose SCHUR, a scalable learning framework designed to explore the impact of large-scale data on high-level control in humanoid robots. Experimental results demonstrate that SCHUR achieves high robot motion generation quality and strong text-motion alignment under data and model scaling, with 37\% reconstruction improvement under MPJPE and 25\% alignment improvement under FID comparing with previous methods. Its effectiveness is further validated through deployment in real-world humanoid robot.

</details>


### [22] [UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning](https://arxiv.org/abs/2511.09302)
*Yan Huang,Shoujie Li,Xingting Li,Wenbo Ding*

Main category: cs.RO

TL;DR: UMIGen是一个统一框架，通过手持设备Cloud-UMI采集点云观测-动作对，结合可见性感知优化机制，实现高效的数据生成和跨机器人具身的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决数据驱动机器人学习面临的数据采集难题：高质量演示数据需求大但采集成本高、依赖专用硬件、空间泛化能力有限。UMI方法放宽了硬件要求但缺乏3D几何信息。

Method: 包含两个关键组件：(1) Cloud-UMI手持数据采集设备，无需视觉SLAM，同时记录点云观测-动作对；(2) 可见性感知优化机制，扩展DemoGen流程到自我中心3D观测，仅生成相机视野内的点。

Result: 在模拟和真实环境中的实验表明，UMIGen支持强大的跨具身泛化能力，并在多种操作任务中加速数据收集。

Conclusion: UMIGen框架实现了高效的数据生成，与真实自我中心观测对齐，可直接在不同机器人具身间迁移而无需后处理。

Abstract: Data-driven robotic learning faces an obvious dilemma: robust policies demand large-scale, high-quality demonstration data, yet collecting such data remains a major challenge owing to high operational costs, dependence on specialized hardware, and the limited spatial generalization capability of current methods. The Universal Manipulation Interface (UMI) relaxes the strict hardware requirements for data collection, but it is restricted to capturing only RGB images of a scene and omits the 3D geometric information on which many tasks rely. Inspired by DemoGen, we propose UMIGen, a unified framework that consists of two key components: (1) Cloud-UMI, a handheld data collection device that requires no visual SLAM and simultaneously records point cloud observation-action pairs; and (2) a visibility-aware optimization mechanism that extends the DemoGen pipeline to egocentric 3D observations by generating only points within the camera's field of view. These two components enable efficient data generation that aligns with real egocentric observations and can be directly transferred across different robot embodiments without any post-processing. Experiments in both simulated and real-world settings demonstrate that UMIGen supports strong cross-embodiment generalization and accelerates data collection in diverse manipulation tasks.

</details>


### [23] [CoRL-MPPI: Enhancing MPPI With Learnable Behaviours For Efficient And Provably-Safe Multi-Robot Collision Avoidance](https://arxiv.org/abs/2511.09331)
*Stepan Dergachev,Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik,Konstantin Yakovlev*

Main category: cs.RO

TL;DR: CoRL-MPPI结合了合作强化学习和MPPI，通过训练深度神经网络学习局部合作避碰行为，并将其嵌入MPPI框架来引导采样分布，从而在多机器人导航中显著提高效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决分散式避碰问题，MPPI在实际中可能因依赖无信息的随机采样而提供次优轨迹，需要改进其采样策略。

Method: 将合作强化学习训练的动作策略（深度神经网络）嵌入MPPI框架，引导其采样分布偏向更智能和合作的动作。

Result: 在密集动态仿真环境中，相比ORCA、BVC和多智能体MPPI等基线方法，CoRL-MPPI显著提高了导航效率（成功率、完成时间）和安全性。

Conclusion: CoRL-MPPI在保持MPPI理论保证的同时，实现了更敏捷和鲁棒的多机器人导航。

Abstract: Decentralized collision avoidance remains a core challenge for scalable multi-robot systems. One of the promising approaches to tackle this problem is Model Predictive Path Integral (MPPI) -- a framework that is naturally suited to handle any robot motion model and provides strong theoretical guarantees. Still, in practice MPPI-based controller may provide suboptimal trajectories as its performance relies heavily on uninformed random sampling. In this work, we introduce CoRL-MPPI, a novel fusion of Cooperative Reinforcement Learning and MPPI to address this limitation. We train an action policy (approximated as deep neural network) in simulation that learns local cooperative collision avoidance behaviors. This learned policy is then embedded into the MPPI framework to guide its sampling distribution, biasing it towards more intelligent and cooperative actions. Notably, CoRL-MPPI preserves all the theoretical guarantees of regular MPPI. We evaluate our approach in dense, dynamic simulation environments against state-of-the-art baselines, including ORCA, BVC, and a multi-agent MPPI implementation. Our results demonstrate that CoRL-MPPI significantly improves navigation efficiency (measured by success rate and makespan) and safety, enabling agile and robust multi-robot navigation.

</details>


### [24] [SPIDER: Scalable Physics-Informed Dexterous Retargeting](https://arxiv.org/abs/2511.09484)
*Chaoyi Pan,Changhao Wang,Haozhi Qi,Zixi Liu,Homanga Bharadhwaj,Akash Sharma,Tingfan Wu,Guanya Shi,Jitendra Malik,Francois Hogan*

Main category: cs.RO

TL;DR: SPIDER是一个基于物理的重新定位框架，可将人类运动演示转换为机器人可执行的动态可行轨迹，解决数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 人类运动数据丰富但机器人数据稀缺，且由于身体差异和动态信息缺失，人类演示无法直接在机器人上执行

Method: 使用基于物理的大规模采样和课程式虚拟接触指导，将人类演示提供任务结构，通过物理采样确保动态可行性和正确接触序列

Result: 在9种人形/灵巧手实体和6个数据集上，成功率比标准采样提高18%，比强化学习基线快10倍，生成了240万帧动态可行机器人数据集

Conclusion: SPIDER作为通用物理重定位方法，能处理不同质量数据并生成高质量数据，有效支持强化学习等策略学习方法

Abstract: Learning dexterous and agile policy for humanoid and dexterous hand control requires large-scale demonstrations, but collecting robot-specific data is prohibitively expensive. In contrast, abundant human motion data is readily available from motion capture, videos, and virtual reality, which could help address the data scarcity problem. However, due to the embodiment gap and missing dynamic information like force and torque, these demonstrations cannot be directly executed on robots. To bridge this gap, we propose Scalable Physics-Informed DExterous Retargeting (SPIDER), a physics-based retargeting framework to transform and augment kinematic-only human demonstrations to dynamically feasible robot trajectories at scale. Our key insight is that human demonstrations should provide global task structure and objective, while large-scale physics-based sampling with curriculum-style virtual contact guidance should refine trajectories to ensure dynamical feasibility and correct contact sequences. SPIDER scales across diverse 9 humanoid/dexterous hand embodiments and 6 datasets, improving success rates by 18% compared to standard sampling, while being 10X faster than reinforcement learning (RL) baselines, and enabling the generation of a 2.4M frames dynamic-feasible robot dataset for policy learning. As a universal physics-based retargeting method, SPIDER can work with diverse quality data and generate diverse and high-quality data to enable efficient policy learning with methods like RL.

</details>


### [25] [WMPO: World Model-based Policy Optimization for Vision-Language-Action Models](https://arxiv.org/abs/2511.09515)
*Fangqi Zhu,Zhengyang Yan,Zicong Hong,Quanxin Shou,Xiao Ma,Song Guo*

Main category: cs.RO

TL;DR: WMPO是一个基于世界模型的策略优化框架，通过像素级预测将VLA特征与想象轨迹对齐，实现了无需真实环境交互的在线强化学习，显著提升了样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: VLA模型依赖专家演示，无法从失败中学习；强化学习样本效率低。需要结合两者优势，实现高效的自学习能力。

Method: 提出WMPO框架，使用像素级预测的世界模型，将VLA预训练特征与想象轨迹对齐，支持在线GRPO策略优化。

Result: 在仿真和真实机器人实验中，WMPO显著提升样本效率、整体性能，并涌现出自校正、泛化和终身学习能力。

Conclusion: WMPO成功结合了VLA模型和强化学习的优势，为机器人操作提供了高效的自学习框架。

Abstract: Vision-Language-Action (VLA) models have shown strong potential for general-purpose robotic manipulation, but their reliance on expert demonstrations limits their ability to learn from failures and perform self-corrections. Reinforcement learning (RL) addresses these through self-improving interactions with the physical environment, but suffers from high sample complexity on real robots. We introduce World-Model-based Policy Optimization (WMPO), a principled framework for on-policy VLA RL without interacting with the real environment. In contrast to widely used latent world models, WMPO focuses on pixel-based predictions that align the "imagined" trajectories with the VLA features pretrained with web-scale images. Crucially, WMPO enables the policy to perform on-policy GRPO that provides stronger performance than the often-used off-policy methods. Extensive experiments in both simulation and real-robot settings demonstrate that WMPO (i) substantially improves sample efficiency, (ii) achieves stronger overall performance, (iii) exhibits emergent behaviors such as self-correction, and (iv) demonstrates robust generalization and lifelong learning capabilities.

</details>


### [26] [MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation](https://arxiv.org/abs/2511.09516)
*Runhao Li,Wenkai Guo,Zhenyu Wu,Changyuan Wang,Haoyuan Deng,Zhenyu Weng,Yap-Peng Tan,Ziwei Wang*

Main category: cs.RO

TL;DR: MAP-VLA是一个增强预训练视觉-语言-动作模型的长时程任务处理能力的框架，通过从历史演示构建记忆库，并在执行任务时检索相关记忆提示来增强动作生成。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练VLA模型在处理长时程任务时表现不佳，因为它们缺乏记忆机制，仅依赖即时感官输入。

Method: 构建基于历史演示的记忆库，每个记忆单元捕获任务特定阶段的信息，通过轨迹相似性匹配检索相关记忆，并动态集成到冻结的VLA模型中。

Result: 在仿真基准测试中实现7.0%的绝对性能提升，在真实机器人评估中实现25.0%的性能提升，超越现有最先进方法。

Conclusion: MAP-VLA为预训练VLA模型提供了一个轻量级、灵活的即插即用模块，显著提升了长时程机器人操作任务的性能。

Abstract: Pre-trained Vision-Language-Action (VLA) models have achieved remarkable success in improving robustness and generalization for end-to-end robotic manipulation. However, these models struggle with long-horizon tasks due to their lack of memory and reliance solely on immediate sensory inputs. To address this limitation, we propose Memory-Augmented Prompting for Vision-Language-Action model (MAP-VLA), a novel framework that empowers pre-trained VLA models with demonstration-derived memory prompts to augment action generation for long-horizon robotic manipulation tasks. To achieve this, MAP-VLA first constructs a memory library from historical demonstrations, where each memory unit captures information about a specific stage of a task. These memory units are implemented as learnable soft prompts optimized through prompt tuning. Then, during real-time task execution, MAP-VLA retrieves relevant memory through trajectory similarity matching and dynamically integrates it into the VLA model for augmented action generation. Importantly, this prompt tuning and retrieval augmentation approach operates as a plug-and-play module for a frozen VLA model, offering a lightweight and flexible solution to improve task performance. Experimental results show that MAP-VLA delivers up to 7.0% absolute performance gains in the simulation benchmark and 25.0% on real robot evaluations for long-horizon tasks, surpassing the current state-of-the-art methods.

</details>


### [27] [SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation](https://arxiv.org/abs/2511.09555)
*Hao Shi,Bin Xie,Yingfei Liu,Yang Yue,Tiancai Wang,Haoqiang Fan,Xiangyu Zhang,Gao Huang*

Main category: cs.RO

TL;DR: 提出了SpatialActor框架，通过解耦语义和几何信息来解决机器人操作中的空间理解问题，在噪声环境下表现出强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在稀疏采样导致语义丢失、语义和几何纠缠对深度噪声敏感、忽略低级空间线索等问题，需要更鲁棒的机器人操作框架。

Method: 使用解耦框架明确分离语义和几何信息，包含语义引导的几何模块自适应融合噪声深度和语义先验，以及利用低级空间线索的空间变换器。

Result: 在50多个任务中达到最先进性能，RLBench上达到87.4%，在噪声条件下提升13.9%-19.4%，显著增强少样本泛化能力。

Conclusion: SpatialActor通过解耦语义和几何信息，在机器人操作中实现了鲁棒的空间理解和精确交互。

Abstract: Robotic manipulation requires precise spatial understanding to interact with objects in the real world. Point-based methods suffer from sparse sampling, leading to the loss of fine-grained semantics. Image-based methods typically feed RGB and depth into 2D backbones pre-trained on 3D auxiliary tasks, but their entangled semantics and geometry are sensitive to inherent depth noise in real-world that disrupts semantic understanding. Moreover, these methods focus on high-level geometry while overlooking low-level spatial cues essential for precise interaction. We propose SpatialActor, a disentangled framework for robust robotic manipulation that explicitly decouples semantics and geometry. The Semantic-guided Geometric Module adaptively fuses two complementary geometry from noisy depth and semantic-guided expert priors. Also, a Spatial Transformer leverages low-level spatial cues for accurate 2D-3D mapping and enables interaction among spatial features. We evaluate SpatialActor on multiple simulation and real-world scenarios across 50+ tasks. It achieves state-of-the-art performance with 87.4% on RLBench and improves by 13.9% to 19.4% under varying noisy conditions, showing strong robustness. Moreover, it significantly enhances few-shot generalization to new tasks and maintains robustness under various spatial perturbations. Project Page: https://shihao1895.github.io/SpatialActor

</details>


### [28] [IFG: Internet-Scale Guidance for Functional Grasping Generation](https://arxiv.org/abs/2511.09558)
*Ray Muxin Liu,Mingxuan Li,Kenneth Shaw,Deepak Pathak*

Main category: cs.RO

TL;DR: 该论文提出了一种结合互联网规模视觉模型的语义理解与基于仿真的局部几何感知力闭合方法，实现高性能语义抓取，无需手动收集训练数据。


<details>
  <summary>Details</summary>
Motivation: 大型视觉模型虽然能在杂乱场景中分割和理解物体部件，但缺乏精确控制灵巧机器人手进行3D抓取所需的几何理解能力。

Method: 利用仿真和力闭合抓取生成管道理解手和物体的局部几何，然后将生成的数据蒸馏到在相机点云上实时运行的扩散模型中。

Result: 通过结合互联网规模模型的全局语义理解和基于仿真的局部感知力闭合，实现了高性能语义抓取。

Conclusion: 该方法成功地将语义理解与几何精度相结合，为灵巧机器人抓取提供了有效的解决方案。

Abstract: Large Vision Models trained on internet-scale data have demonstrated strong capabilities in segmenting and semantically understanding object parts, even in cluttered, crowded scenes. However, while these models can direct a robot toward the general region of an object, they lack the geometric understanding required to precisely control dexterous robotic hands for 3D grasping. To overcome this, our key insight is to leverage simulation with a force-closure grasping generation pipeline that understands local geometries of the hand and object in the scene. Because this pipeline is slow and requires ground-truth observations, the resulting data is distilled into a diffusion model that operates in real-time on camera point clouds. By combining the global semantic understanding of internet-scale models with the geometric precision of a simulation-based locally-aware force-closure, \our achieves high-performance semantic grasping without any manually collected training data. For visualizations of this please visit our website at https://ifgrasping.github.io/

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [Bridging Natural Language and ASP: A Hybrid Approach Using LLMs and AMR Parsing](https://arxiv.org/abs/2511.08715)
*Connar Hite,Sean Saud,Raef Taha,Nayim Rahman,Tanvir Atahary,Scott Douglass,Tarek Taha*

Main category: cs.AI

TL;DR: 提出了一种使用LLM和AMR图将英语自然语言转换为ASP程序的方法，用于解决逻辑谜题，减少对LLM的依赖，创建轻量级可解释系统。


<details>
  <summary>Details</summary>
Motivation: ASP是一种强大的组合问题求解工具，但需要学习语法。随着非编程人员与代码交互的需求增加，需要一种方法让不熟悉编程语言的人也能使用ASP。

Method: 使用LLM简化自然语言句子、识别关键词和生成简单事实，然后通过AMR图解析简化后的语言，系统性地生成ASP约束，最终创建完整的ASP程序。

Result: 系统成功创建了完整的ASP程序来解决组合逻辑问题，展示了处理逻辑谜题的能力。

Conclusion: 这是创建轻量级、可解释的自然语言到复杂逻辑问题求解系统的重大第一步，最小化了LLM的作用，提高了系统的可控性和可解释性。

Abstract: Answer Set Programming (ASP) is a declarative programming paradigm based on logic programming and non-monotonic reasoning. It is a tremendously powerful tool for describing and solving combinatorial problems. Like any other language, ASP requires users to learn how it works and the syntax involved. It is becoming increasingly required for those unfamiliar with programming languages to interact with code. This paper proposes a novel method of translating unconstrained English into ASP programs for logic puzzles using an LLM and Abstract Meaning Representation (AMR) graphs. Everything from ASP rules, facts, and constraints is generated to fully represent and solve the desired problem. Example logic puzzles are used to demonstrate the capabilities of the system. While most current methods rely entirely on an LLM, our system minimizes the role of the LLM only to complete straightforward tasks. The LLM is used to simplify natural language sentences, identify keywords, and generate simple facts. The AMR graphs are then parsed from simplified language and used to generate ASP constraints systematically. The system successfully creates an entire ASP program that solves a combinatorial logic problem. This approach is a significant first step in creating a lighter-weight, explainable system that converts natural language to solve complex logic problems.

</details>


### [30] [Vector Symbolic Algebras for the Abstraction and Reasoning Corpus](https://arxiv.org/abs/2511.08747)
*Isaac Joffe,Chris Eliasmith*

Main category: cs.AI

TL;DR: 提出了一种基于向量符号代数(VSA)的神经符号方法，用于解决ARC-AGI基准测试，结合系统1直觉和系统2推理，实现高效可解释的认知合理求解器。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI是人类能轻松解决但AI系统极难应对的流体智力基准，受神经科学和心理学中人类智能建模方法的启发，旨在开发认知合理的求解器。

Method: 使用向量符号代数(VSA)的神经符号方法，通过面向对象的程序合成，利用VSA表示抽象对象、指导解决方案搜索，并实现样本高效的神经学习。

Result: 在ARC-AGI-1-Train上得分10.8%，在ARC-AGI-1-Eval上得分3.0%；在Sort-of-ARC上得分94.5%，在1D-ARC上得分83.1%，后者以极低计算成本超越GPT-4。

Conclusion: 这是首个将VSA应用于ARC-AGI的研究，开发了迄今为止最认知合理的ARC-AGI求解器，方法独特且有效。

Abstract: The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) is a generative, few-shot fluid intelligence benchmark. Although humans effortlessly solve ARC-AGI, it remains extremely difficult for even the most advanced artificial intelligence systems. Inspired by methods for modelling human intelligence spanning neuroscience to psychology, we propose a cognitively plausible ARC-AGI solver. Our solver integrates System 1 intuitions with System 2 reasoning in an efficient and interpretable process using neurosymbolic methods based on Vector Symbolic Algebras (VSAs). Our solver works by object-centric program synthesis, leveraging VSAs to represent abstract objects, guide solution search, and enable sample-efficient neural learning. Preliminary results indicate success, with our solver scoring 10.8% on ARC-AGI-1-Train and 3.0% on ARC-AGI-1-Eval. Additionally, our solver performs well on simpler benchmarks, scoring 94.5% on Sort-of-ARC and 83.1% on 1D-ARC -- the latter outperforming GPT-4 at a tiny fraction of the computational cost. Importantly, our approach is unique; we believe we are the first to apply VSAs to ARC-AGI and have developed the most cognitively plausible ARC-AGI solver yet. Our code is available at: https://github.com/ijoffe/ARC-VSA-2025.

</details>


### [31] [Interpretable by Design: Query-Specific Neural Modules for Explainable Reinforcement Learning](https://arxiv.org/abs/2511.08749)
*Mehrdad Zakershahrak*

Main category: cs.AI

TL;DR: 本文提出了QDIN架构，将强化学习系统重新设计为可回答多种环境查询的推理引擎，而非仅专注于奖励最大化。研究发现推理准确性与控制性能存在根本性解耦。


<details>
  <summary>Details</summary>
Motivation: 挑战传统强化学习单一目标范式，探索将RL系统设计为能够回答环境多样性查询的推理引擎，以暴露智能体隐含的环境知识。

Method: 引入查询条件确定性推理网络(QDIN)，为不同查询类型（策略、可达性、路径、比较）设计专门的神经模块，统一架构处理多种推理模式。

Result: 推理准确性可达近乎完美水平（99%可达性IoU），而控制性能仍保持次优（31%回报），表明世界知识表示与控制所需表示存在差异。专门化架构在推理任务上优于统一模型和后验提取方法。

Conclusion: 为RL系统作为可查询知识库的设计建立了研究议程，对可解释性、验证和人机协作具有重要影响。

Abstract: Reinforcement learning has traditionally focused on a singular objective: learning policies that select actions to maximize reward. We challenge this paradigm by asking: what if we explicitly architected RL systems as inference engines that can answer diverse queries about their environment? In deterministic settings, trained agents implicitly encode rich knowledge about reachability, distances, values, and dynamics - yet current architectures are not designed to expose this information efficiently. We introduce Query Conditioned Deterministic Inference Networks (QDIN), a unified architecture that treats different types of queries (policy, reachability, paths, comparisons) as first-class citizens, with specialized neural modules optimized for each inference pattern. Our key empirical finding reveals a fundamental decoupling: inference accuracy can reach near-perfect levels (99% reachability IoU) even when control performance remains suboptimal (31% return), suggesting that the representations needed for accurate world knowledge differ from those required for optimal control. Experiments demonstrate that query specialized architectures outperform both unified models and post-hoc extraction methods, while maintaining competitive control performance. This work establishes a research agenda for RL systems designed from inception as queryable knowledge bases, with implications for interpretability, verification, and human-AI collaboration.

</details>


### [32] [Neural Value Iteration](https://arxiv.org/abs/2511.08825)
*Yang You,Ufuk Çakır,Alex Schutz,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 该论文提出了一种新的POMDP规划算法——神经价值迭代，用神经网络替代传统的α向量来表示价值函数，解决了大规模POMDP问题中传统方法计算成本过高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统POMDP求解器使用α向量表示价值函数，每个α向量是|S|维的，在大规模问题中Bellman备份的计算成本过高，导致方法不可行。

Method: 利用PWLC特性，将POMDP价值函数表示为有限个神经网络的集合，结合神经网络的泛化能力和经典价值迭代框架，提出神经价值迭代算法。

Result: 该方法在现有离线求解器无法处理的大规模POMDP中仍能获得接近最优的解。

Conclusion: 神经网络表示为大规模POMDP规划提供了可行的替代方案，结合了神经网络的泛化优势和传统价值迭代的理论基础。

Abstract: The value function of a POMDP exhibits the piecewise-linear-convex (PWLC) property and can be represented as a finite set of hyperplanes, known as $α$-vectors. Most state-of-the-art POMDP solvers (offline planners) follow the point-based value iteration scheme, which performs Bellman backups on $α$-vectors at reachable belief points until convergence. However, since each $α$-vector is $|S|$-dimensional, these methods quickly become intractable for large-scale problems due to the prohibitive computational cost of Bellman backups. In this work, we demonstrate that the PWLC property allows a POMDP's value function to be alternatively represented as a finite set of neural networks. This insight enables a novel POMDP planning algorithm called \emph{Neural Value Iteration}, which combines the generalization capability of neural networks with the classical value iteration framework. Our approach achieves near-optimal solutions even in extremely large POMDPs that are intractable for existing offline solvers.

</details>


### [33] [UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models](https://arxiv.org/abs/2511.08873)
*Shouang Wei,Min Zhang,Xin Lin,Bo Jiang,Kun Kuang,Zhongxiang Dai*

Main category: cs.AI

TL;DR: 提出了单向认知优化(UCO)方法，通过多轮交互强化学习解决LLM作为智能导师时的动态适应问题，包含认知进步奖励和支架奖励两个协同奖励函数。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在教育中从答案提供者转向智能导师，但现有监督微调方法只能学习表面教学模式，缺乏动态适应能力。强化学习方法面临两个关键挑战：无法区分学生是否真正理解还是简单重复答案，以及无法实时感知学生认知状态来动态调整教学策略。

Method: UCO方法采用多轮交互强化学习范式，包含两个协同奖励函数：进步奖励捕捉学生认知进步，评估学生是否从困惑真正转向理解；支架奖励动态识别每个学生的最近发展区，鼓励教师在该区域内保持高效教学。

Result: 在BigMath和MathTutorBench基准测试中，UCO模型优于所有同等规模的基线模型，性能与先进的闭源模型相当。

Conclusion: UCO方法通过认知进步奖励和支架奖励有效解决了LLM作为智能导师时的动态适应问题，显著提升了教学效果。

Abstract: Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at https://github.com/Mind-Lab-ECNU/UCO.

</details>


### [34] [Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds](https://arxiv.org/abs/2511.08892)
*Weihao Tan,Xiangyang Li,Yunhao Fang,Heyuan Yao,Shi Yan,Hao Luo,Tenglong Ao,Huihui Li,Hongbin Ren,Bairen Yi,Yujia Qin,Bo An,Libin Liu,Guang Shi*

Main category: cs.AI

TL;DR: Lumine是首个能够实时完成数小时复杂任务的通用智能体，在3D开放世界中采用类人交互范式，统一感知、推理和行动，基于视觉语言模型处理原始像素并产生精确键盘鼠标操作。


<details>
  <summary>Details</summary>
Motivation: 开发能够在复杂3D开放世界环境中完成长时间任务的通用智能体，实现类人的实时交互能力。

Method: 采用端到端的视觉语言模型，以5Hz处理原始像素，产生30Hz的键盘鼠标动作，仅在必要时进行推理。在《原神》中训练，统一感知、推理和行动。

Result: 成功完成《原神》5小时蒙德主线剧情，效率与人类相当；在《鸣潮》中完成100分钟任务，在《崩坏：星穹铁道》中完成5小时第一章，展现强大的零样本跨游戏泛化能力。

Conclusion: Lumine在不同世界和交互动态中表现出色，标志着在开放环境中开发通用智能体的重要进展。

Abstract: We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts a human-like interaction paradigm that unifies perception, reasoning, and action in an end-to-end manner, powered by a vision-language model. It processes raw pixels at 5 Hz to produce precise 30 Hz keyboard-mouse actions and adaptively invokes reasoning only when necessary. Trained in Genshin Impact, Lumine successfully completes the entire five-hour Mondstadt main storyline on par with human-level efficiency and follows natural language instructions to perform a broad spectrum of tasks in both 3D open-world exploration and 2D GUI manipulation across collection, combat, puzzle-solving, and NPC interaction. In addition to its in-domain performance, Lumine demonstrates strong zero-shot cross-game generalization. Without any fine-tuning, it accomplishes 100-minute missions in Wuthering Waves and the full five-hour first chapter of Honkai: Star Rail. These promising results highlight Lumine's effectiveness across distinct worlds and interaction dynamics, marking a concrete step toward generalist agents in open-ended environments.

</details>


### [35] [The Double Contingency Problem: AI Recursion and the Limits of Interspecies Understanding](https://arxiv.org/abs/2511.08927)
*Graham L. Bishop*

Main category: cs.AI

TL;DR: 本文探讨了生物声学AI系统与其他物种递归通信过程相遇时的双重偶然性问题，主张将AI重新概念化为不同递归认知形式之间的外交相遇。


<details>
  <summary>Details</summary>
Motivation: 当前生物声学AI系统虽然取得了跨物种的优异表现，但忽视了AI自身的递归认知过程可能系统性地模糊或扭曲其他物种的通信结构这一根本问题。

Method: 基于哲学家Yuk Hui关于递归性和偶然性的理论框架，分析AI系统作为递归认知代理与其他物种通信之间的双重偶然性关系。

Result: 揭示了AI系统并非中立的模式检测器，而是具有自身偶然性架构和训练条件的递归认知代理，其信息处理可能系统性地影响对其他物种通信结构的理解。

Conclusion: 需要将生物声学AI从通用模式识别重新概念化为不同递归认知形式之间的外交相遇，这对模型设计、评估框架和研究方法都有重要影响。

Abstract: Current bioacoustic AI systems achieve impressive cross-species performance by processing animal communication through transformer architectures, foundation model paradigms, and other computational approaches. However, these approaches overlook a fundamental question: what happens when one form of recursive cognition--AI systems with their attention mechanisms, iterative processing, and feedback loops--encounters the recursive communicative processes of other species? Drawing on philosopher Yuk Hui's work on recursivity and contingency, I argue that AI systems are not neutral pattern detectors but recursive cognitive agents whose own information processing may systematically obscure or distort other species' communicative structures. This creates a double contingency problem: each species' communication emerges through contingent ecological and evolutionary conditions, while AI systems process these signals through their own contingent architectural and training conditions. I propose that addressing this challenge requires reconceptualizing bioacoustic AI from universal pattern recognition toward diplomatic encounter between different forms of recursive cognition, with implications for model design, evaluation frameworks, and research methodologies.

</details>


### [36] [From Model Training to Model Raising -- A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development](https://arxiv.org/abs/2511.09287)
*Roland Aydin,Christian Cyron,Steve Bachelor,Ashton Anderson,Robert West*

Main category: cs.AI

TL;DR: 提出从"模型训练"到"模型培育"的范式转变，将价值观对齐融入模型开发全过程，通过重新设计训练语料库实现知识与价值观的内在融合


<details>
  <summary>Details</summary>
Motivation: 当前AI训练方法只在核心能力建立后才进行价值观对齐，导致模型容易失准且缺乏深层次价值体系。在大模型能力开始超越人类的背景下，需要从根本上改变训练范式

Method: 重新设计训练语料库：采用第一人称视角重构训练数据、将信息重新情境化为生活经验、模拟社会互动、对训练数据进行支架式排序

Result: 预期这种训练语料库的重新设计将实现从第一个训练标记开始的早期价值观承诺，使知识、技能和价值观内在难以分离

Conclusion: 在大型语言模型能力开始超越人类能力的生态系统中，这种从模型训练到模型培育的范式转变是至关重要的需求

Abstract: Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from "model training" to "model raising", in which alignment is woven into a model's development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.

</details>


### [37] [A Research on Business Process Optimisation Model Integrating AI and Big Data Analytics](https://arxiv.org/abs/2511.08934)
*Di Liao,Ruijia Liang,Ziyi Ye*

Main category: cs.AI

TL;DR: 构建了融合人工智能与大数据的业务流程优化模型，采用三层架构实现流程全生命周期智能管理，实验验证可缩短处理时间42%、提升资源利用率28%、降低运营成本35%。


<details>
  <summary>Details</summary>
Motivation: 随着数字化转型深化，业务流程优化成为提升企业竞争力的关键，需要实现流程全生命周期的智能化管理。

Method: 采用包含数据处理、AI算法和业务逻辑的三层架构模型，结合分布式计算和深度学习技术，实现实时流程监控与优化。

Result: 多企业场景验证显示：流程处理时间缩短42%，资源利用率提升28%，运营成本降低35%，高并发负载下保持99.9%可用性。

Conclusion: 研究成果对企业数字化转型具有重要理论与实践价值，为提升企业运营效率提供了新思路。

Abstract: With the deepening of digital transformation, business process optimisation has become the key to improve the competitiveness of enterprises. This study constructs a business process optimisation model integrating artificial intelligence and big data to achieve intelligent management of the whole life cycle of processes. The model adopts a three-layer architecture incorporating data processing, AI algorithms, and business logic to enable real-time process monitoring and optimization. Through distributed computing and deep learning techniques, the system can handle complex business scenarios while maintaining high performance and reliability. Experimental validation across multiple enterprise scenarios shows that the model shortens process processing time by 42%, improves resource utilisation by 28%, and reduces operating costs by 35%. The system maintained 99.9% availability under high concurrent loads. The research results have important theoretical and practical value for promoting the digital transformation of enterprises, and provide new ideas for improving the operational efficiency of enterprises.

</details>


### [38] [AlphaCast: A Human Wisdom-LLM Intelligence Co-Reasoning Framework for Interactive Time Series Forecasting](https://arxiv.org/abs/2511.08947)
*Xiaohan Zhang,Tian Gao,Mingyue Cheng,Bokai Pan,Ze Guo,Yaguo Liu,Xiaoyu Tao*

Main category: cs.AI

TL;DR: AlphaCast是一个人类智慧与大型语言模型协同推理的时序预测框架，将预测重新定义为交互过程，通过两阶段协作实现更准确的预测。


<details>
  <summary>Details</summary>
Motivation: 现有时序预测方法缺乏人类专家的交互、推理和适应性，限制了在复杂现实环境中的实用性。

Method: 采用两阶段框架：自动预测准备（构建多源认知基础）和生成推理与反思优化（触发元推理循环进行持续自校正）。

Result: 在短期和长期数据集上的广泛实验表明，AlphaCast在预测准确性方面始终优于最先进的基线方法。

Conclusion: AlphaCast通过人类智慧与LLM智能的协同推理，显著提升了时序预测的性能和实用性。

Abstract: Time series forecasting plays a critical role in high-stakes domains such as energy, healthcare, and climate. Although recent advances have improved accuracy, most approaches still treat forecasting as a static one-time mapping task, lacking the interaction, reasoning, and adaptability of human experts. This gap limits their usefulness in complex real-world environments. To address this, we propose AlphaCast, a human wisdom-large language model (LLM) intelligence co-reasoning framework that redefines forecasting as an interactive process. The key idea is to enable step-by-step collaboration between human wisdom and LLM intelligence to jointly prepare, generate, and verify forecasts. The framework consists of two stages: (1) automated prediction preparation, where AlphaCast builds a multi-source cognitive foundation comprising a feature set that captures key statistics and time patterns, a domain knowledge base distilled from corpora and historical series, a contextual repository that stores rich information for each time window, and a case base that retrieves optimal strategies via pattern clustering and matching; and (2) generative reasoning and reflective optimization, where AlphaCast integrates statistical temporal features, prior knowledge, contextual information, and forecasting strategies, triggering a meta-reasoning loop for continuous self-correction and strategy refinement. Extensive experiments on short- and long-term datasets show that AlphaCast consistently outperforms state-of-the-art baselines in predictive accuracy. Code is available at this repository: https://github.com/SkyeGT/AlphaCast_Official .

</details>


### [39] [Heterogeneous Graph Neural Networks for Assumption-Based Argumentation](https://arxiv.org/abs/2511.08982)
*Preesha Gehlot,Anna Rapberger,Fabrizio Russo,Francesca Toni*

Main category: cs.AI

TL;DR: 提出了首个基于图神经网络的方法来近似计算ABA框架中的可信接受问题，通过依赖图表示和两种GNN架构，在ICCMA基准上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 基于假设的论证(ABA)是强大的结构化论证形式，但在稳定语义下精确计算扩展对于大型框架是难解的，需要可扩展的近似推理方法。

Method: 将ABA框架建模为依赖图，编码假设、声明和规则作为节点，使用异质边标签区分支持、推导和攻击关系。提出了ABAGCN和ABAGAT两种GNN架构，分别使用残差异质卷积层和注意力层来学习节点嵌入。

Result: ABAGCN和ABAGAT在ICCMA基准上优于最先进的GNN基线，节点级F1分数最高达0.71。扩展重构算法在小ABA框架上F1超过0.85，在大型框架上保持约0.58的F1。

Conclusion: 这项工作为结构化论证中的可扩展近似推理开辟了新途径，证明了GNN在ABA框架近似计算中的有效性。

Abstract: Assumption-Based Argumentation (ABA) is a powerful structured argumentation formalism, but exact computation of extensions under stable semantics is intractable for large frameworks. We present the first Graph Neural Network (GNN) approach to approximate credulous acceptance in ABA. To leverage GNNs, we model ABA frameworks via a dependency graph representation encoding assumptions, claims and rules as nodes, with heterogeneous edge labels distinguishing support, derive and attack relations. We propose two GNN architectures - ABAGCN and ABAGAT - that stack residual heterogeneous convolution or attention layers, respectively, to learn node embeddings. Our models are trained on the ICCMA 2023 benchmark, augmented with synthetic ABAFs, with hyperparameters optimised via Bayesian search. Empirically, both ABAGCN and ABAGAT outperform a state-of-the-art GNN baseline that we adapt from the abstract argumentation literature, achieving a node-level F1 score of up to 0.71 on the ICCMA instances. Finally, we develop a sound polynomial time extension-reconstruction algorithm driven by our predictor: it reconstructs stable extensions with F1 above 0.85 on small ABAFs and maintains an F1 of about 0.58 on large frameworks. Our work opens new avenues for scalable approximate reasoning in structured argumentation.

</details>


### [40] [AI Founding Fathers: A Case Study of GIS Search in Multi-Agent Pipelines](https://arxiv.org/abs/2511.09005)
*Alvin Chauhan*

Main category: cs.AI

TL;DR: 本文提出了一个系统框架来增强LLM的推理能力，认为高质量推理是受控的增量搜索，并通过多智能体管道实现逐步、增量、顺序的搜索空间遍历。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型表现出卓越的流畅性，但研究人员仍在努力提取其更强的推理能力。本文基于搜索导向的LLM计算解释，推进对LLM推理和优化的系统理解。

Method: 采用递归精炼作为实现GIS搜索的实用方法，设计了简单线性管道与复杂结构化管道的对比实验，后者包含递归精炼层。构建了反映美国开国元勋历史人物的多智能体模型，使用RAG增强语料库，针对三个当代政治议题生成回应。

Result: 复杂模型在所有九个测试案例中始终优于简单模型，平均仲裁得分为88.3对71.7。复杂模型的论证在分析深度、结构细微差别和战略框架方面更优越。

Conclusion: 递归精炼是通过GIS搜索增强LLM推理的强大架构特征，结构化多智能体管道能显著提升推理质量。

Abstract: Although Large Language Models (LLMs) show exceptional fluency, efforts persist to extract stronger reasoning capabilities from them. Drawing on search-based interpretations of LLM computation, this paper advances a systematic framework for understanding LLM reasoning and optimization. Namely, that enhancing reasoning is best achieved by structuring a multi-agent pipeline to ensure a traversal of the search space in a gradual, incremental, and sequential (GIS) manner. Stated succinctly, high-quality reasoning is a controlled, incremental search. To test this framework, we investigate the efficacy of recursive refinement (RR)--an iterative process of self-criticism, adversarial stress-testing, and integrating critical feedback--as a practical method for implementing GIS search. We designed an experiment comparing a simple, linear pipeline against a complex, explicitly structured pipeline leveraging a recursive refinement layer. The multi-agent models were constructed to reflect the historical personas of three US Founding Fathers (Hamilton, Jefferson, and Madison) using RAG-powered corpora and were prompted to generate responses to three contemporary political issues. Model performance was evaluated using a two-tiered approach: a quantitative score from an LLM arbiter agent and qualitative human judgment. Our results revealed that the complex model consistently outperformed the simple model across all nine test cases with an average arbiter-outputted score of 88.3 versus 71.7. The complex model's arguments were superior in analytical depth, structural nuance, and strategic framing. We conclude that recursive refinement is a robust architectural feature for enhancing LLM reasoning via GIS search.

</details>


### [41] [Solving a Million-Step LLM Task with Zero Errors](https://arxiv.org/abs/2511.09030)
*Elliot Meyerson,Giuseppe Paolo,Roberto Dailey,Hormoz Shahrzad,Olivier Francon,Conor F. Hayes,Xin Qiu,Babak Hodjat,Risto Miikkulainen*

Main category: cs.AI

TL;DR: MAKER系统首次实现了超过100万步LLM推理的零错误任务完成，通过极端任务分解和微代理投票机制解决了LLM在长程任务中的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在推理、洞察和工具使用方面取得突破，但在扩展到人类、组织和社会规模的复杂过程时，由于持续的错误率而无法实现。现有LLM研究主要关注依赖步骤较少的任务，但长程任务执行能力日益受到关注。

Method: 采用极端任务分解方法，将任务分解为可由专注微代理处理的子任务。通过高度模块化设计，在每个步骤应用高效的多代理投票机制进行错误校正。

Result: MAKER系统成功解决了超过100万步LLM推理的任务且零错误，理论上可扩展到更高水平。

Conclusion: 相比持续改进现有LLMs，大规模分解的代理过程(MDAPs)可能为组织和社会层面的问题提供高效解决方案。

Abstract: LLMs have achieved remarkable breakthroughs in reasoning, insights, and tool use, but chaining these abilities into extended processes at the scale of those routinely executed by humans, organizations, and societies has remained out of reach. The models have a persistent error rate that prevents scale-up: for instance, recent experiments in the Towers of Hanoi benchmark domain showed that the process inevitably becomes derailed after at most a few hundred steps. Thus, although LLM research is often still benchmarked on tasks with relatively few dependent logical steps, there is increasing attention on the ability (or inability) of LLMs to perform long range tasks. This paper describes MAKER, the first system that successfully solves a task with over one million LLM steps with zero errors, and, in principle, scales far beyond this level. The approach relies on an extreme decomposition of a task into subtasks, each of which can be tackled by focused microagents. The high level of modularity resulting from the decomposition allows error correction to be applied at each step through an efficient multi-agent voting scheme. This combination of extreme decomposition and error correction makes scaling possible. Thus, the results suggest that instead of relying on continual improvement of current LLMs, massively decomposed agentic processes (MDAPs) may provide a way to efficiently solve problems at the level of organizations and societies.

</details>


### [42] [Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs](https://arxiv.org/abs/2511.09032)
*Dingji Wang,You Lu,Bihuan Chen,Shuo Hao,Haowen Jiang,Yifan Tian,Xin Peng*

Main category: cs.AI

TL;DR: 提出了Argus框架，用于增强端到端自动驾驶系统的韧性，通过持续监控轨迹和危险缓解机制来防止安全违规。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在公共道路上部署时面临各种驾驶危险，需要具备持续监控和自适应响应能力来维持稳健驾驶行为。

Method: 开发了运行时韧性导向框架Argus，包含轨迹监控和危险缓解器，当EGO车辆被认为不安全时接管控制。

Result: 与TCP、UniAD和VAD三个先进ADS集成测试，驾驶评分平均提升150.30%，阻止了64.38%的违规行为，时间开销很小。

Conclusion: Argus能有效高效地增强自动驾驶系统的韧性，显著改善驾驶性能并预防安全违规。

Abstract: End-to-end autonomous driving systems (ADSs), with their strong capabilities in environmental perception and generalizable driving decisions, are attracting growing attention from both academia and industry. However, once deployed on public roads, ADSs are inevitably exposed to diverse driving hazards that may compromise safety and degrade system performance. This raises a strong demand for resilience of ADSs, particularly the capability to continuously monitor driving hazards and adaptively respond to potential safety violations, which is crucial for maintaining robust driving behaviors in complex driving scenarios.
  To bridge this gap, we propose a runtime resilience-oriented framework, Argus, to mitigate the driving hazards, thus preventing potential safety violations and improving the driving performance of an ADS. Argus continuously monitors the trajectories generated by the ADS for potential hazards and, whenever the EGO vehicle is deemed unsafe, seamlessly takes control through a hazard mitigator. We integrate Argus with three state-of-the-art end-to-end ADSs, i.e., TCP, UniAD and VAD. Our evaluation has demonstrated that Argus effectively and efficiently enhances the resilience of ADSs, improving the driving score of the ADS by up to 150.30% on average, and preventing up to 64.38% of the violations, with little additional time overhead.

</details>


### [43] [Advancing Autonomous Emergency Response Systems: A Generative AI Perspective](https://arxiv.org/abs/2511.09044)
*Yousef Emami,Radha Reddy,Azadeh Pourkabirian,Miguel Gutierrez Gaitan*

Main category: cs.AI

TL;DR: 本文综述了自动驾驶车辆在紧急服务中的优化策略，重点分析了从传统强化学习转向扩散模型增强强化学习和大型语言模型辅助上下文学习的新范式。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在自动驾驶紧急响应中存在样本效率低和动态场景适应性差的问题，需要更先进的AI方法来提升自动驾驶车辆在紧急情况下的决策能力。

Method: 分析了扩散模型增强强化学习（通过合成数据生成增强策略鲁棒性）和大型语言模型辅助上下文学习（提供轻量级、可解释的实时适应能力）两种新兴方法。

Result: 扩散模型增强强化学习提高了策略鲁棒性但计算成本增加，而LLM辅助上下文学习提供了无需重新训练的快速适应能力。

Conclusion: 从生成式AI视角为下一代自主紧急响应系统提供了关键框架，展示了DM增强RL和LLM辅助ICL在提升自动驾驶车辆紧急服务性能方面的潜力。

Abstract: Autonomous Vehicles (AVs) are poised to revolutionize emergency services by enabling faster, safer, and more efficient responses. This transformation is driven by advances in Artificial Intelligence (AI), particularly Reinforcement Learning (RL), which allows AVs to navigate complex environments and make critical decisions in real time. However, conventional RL paradigms often suffer from poor sample efficiency and lack adaptability in dynamic emergency scenarios. This paper reviews next-generation AV optimization strategies to address these limitations. We analyze the shift from conventional RL to Diffusion Model (DM)-augmented RL, which enhances policy robustness through synthetic data generation, albeit with increased computational cost. Additionally, we explore the emerging paradigm of Large Language Model (LLM)-assisted In-Context Learning (ICL), which offers a lightweight and interpretable alternative by enabling rapid, on-the-fly adaptation without retraining. By reviewing the state of the art in AV intelligence, DM-augmented RL, and LLM-assisted ICL, this paper provides a critical framework for understanding the next generation of autonomous emergency response systems from a Generative AI perspective.

</details>


### [44] [OR-R1: Automating Modeling and Solving of Operations Research Optimization Problem via Test-Time Reinforcement Learning](https://arxiv.org/abs/2511.09092)
*Zezhen Ding,Zhen Tan,Jiheng Zhang,Tianlong Chen*

Main category: cs.AI

TL;DR: OR-R1是一个数据高效的训练框架，用于自动化优化建模和求解，仅需1/10的合成数据即可达到67.7%的平均求解准确率，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的优化建模方法需要大量标注或合成数据，导致成本高且可扩展性差，需要开发数据效率更高的自动化解决方案。

Method: 采用两阶段训练：首先使用监督微调从有限标注数据学习问题建模和代码生成模式，然后通过测试时组相对策略优化提升能力和一致性。

Result: OR-R1在仅使用100个合成样本的情况下超越ORLM 2.4%，平均求解准确率达67.7%，比ORLM高出4.2%。TGRPO带来额外3.1%-6.4%的准确率提升。

Conclusion: OR-R1为自动化运筹优化问题建模和求解提供了稳健、可扩展且成本效益高的解决方案，降低了工业应用的专业知识和数据门槛。

Abstract: Optimization modeling and solving are fundamental to the application of Operations Research (OR) in real-world decision making, yet the process of translating natural language problem descriptions into formal models and solver code remains highly expertise intensive. While recent advances in large language models (LLMs) have opened new opportunities for automation, the generalization ability and data efficiency of existing LLM-based methods are still limited, asmost require vast amounts of annotated or synthetic data, resulting in high costs and scalability barriers. In this work, we present OR-R1, a data-efficient training framework for automated optimization modeling and solving. OR-R1 first employs supervised fine-tuning (SFT) to help the model acquire the essential reasoning patterns for problem formulation and code generation from limited labeled data. In addition, it improves the capability and consistency through Test-Time Group Relative Policy Optimization (TGRPO). This two-stage design enables OR-R1 to leverage both scarce labeled and abundant unlabeled data for effective learning. Experiments show that OR-R1 achieves state-of-the-art performance with an average solving accuracy of $67.7\%$, using only $1/10$ the synthetic data required by prior methods such as ORLM, exceeding ORLM's solving accuracy by up to $4.2\%$. Remarkably, OR-R1 outperforms ORLM by over $2.4\%$ with just $100$ synthetic samples. Furthermore, TGRPO contributes an additional $3.1\%-6.4\%$ improvement in accuracy, significantly narrowing the gap between single-attempt (Pass@1) and multi-attempt (Pass@8) performance from $13\%$ to $7\%$. Extensive evaluations across diverse real-world benchmarks demonstrate that OR-R1 provides a robust, scalable, and cost-effective solution for automated OR optimization problem modeling and solving, lowering the expertise and data barriers for industrial OR applications.

</details>


### [45] [History-Aware Reasoning for GUI Agents](https://arxiv.org/abs/2511.09127)
*Ziwei Wang,Leyang Yang,Xiaoxuan Tang,Sheng Zhou,Dajun Chen,Wei Jiang,Yong Li*

Main category: cs.AI

TL;DR: 提出了历史感知推理框架HAR，解决GUI代理在长时程任务中历史交互记忆弱的问题，通过反思错误和获取情节推理知识来增强短期记忆。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理在显式推理中短期记忆较弱，将链式交互视为离散屏幕理解，缺乏对历史交互的感知，这影响了GUI自动化的性能。

Method: 提出HAR框架，包括构建反思学习场景、合成定制校正指南和设计混合RL奖励函数，开发了端到端模型HAR-GUI-3B。

Result: 在多个GUI相关基准测试中的综合评估证明了该方法的有效性和泛化能力。

Conclusion: HAR框架成功将GUI代理的推理模式从历史无关转变为历史感知，赋予了稳定的短期记忆和可靠的屏幕细节感知能力。

Abstract: Advances in Multimodal Large Language Models have significantly enhanced Graphical User Interface (GUI) automation. Equipping GUI agents with reliable episodic reasoning capabilities is essential for bridging the gap between users' concise task descriptions and the complexities of real-world execution. Current methods integrate Reinforcement Learning (RL) with System-2 Chain-of-Thought, yielding notable gains in reasoning enhancement. For long-horizon GUI tasks, historical interactions connect each screen to the goal-oriented episode chain, and effectively leveraging these clues is crucial for the current decision. However, existing native GUI agents exhibit weak short-term memory in their explicit reasoning, interpreting the chained interactions as discrete screen understanding, i.e., unawareness of the historical interactions within the episode. This history-agnostic reasoning challenges their performance in GUI automation. To alleviate this weakness, we propose a History-Aware Reasoning (HAR) framework, which encourages an agent to reflect on its own errors and acquire episodic reasoning knowledge from them via tailored strategies that enhance short-term memory in long-horizon interaction. The framework mainly comprises constructing a reflective learning scenario, synthesizing tailored correction guidelines, and designing a hybrid RL reward function. Using the HAR framework, we develop a native end-to-end model, HAR-GUI-3B, which alters the inherent reasoning mode from history-agnostic to history-aware, equipping the GUI agent with stable short-term memory and reliable perception of screen details. Comprehensive evaluations across a range of GUI-related benchmarks demonstrate the effectiveness and generalization of our method.

</details>


### [46] [ProBench: Benchmarking GUI Agents with Accurate Process Information](https://arxiv.org/abs/2511.09157)
*Leyang Yang,Ziwei Wang,Xiaoxuan Tang,Sheng Zhou,Dajun Chen,Wei Jiang,Yong Li*

Main category: cs.AI

TL;DR: ProBench是一个全面的移动GUI代理基准测试，包含200多个挑战性任务，通过引入过程相关任务和专门的评估方法来解决现有基准仅关注最终状态的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理基准测试仅通过检查最终屏幕状态来评估任务完成情况，但GUI操作任务包含多个链式步骤，且关键信息不一定呈现在最终页面中，需要准确捕捉过程信息。

Method: 在保留传统状态相关任务评估的基础上，扩展数据集包含过程相关任务，并设计专门的评估方法。引入过程提供器自动提供准确的过程信息，实现精确的代理性能评估。

Result: 对先进GUI代理的评估揭示了它们在真实世界GUI场景中的显著局限性，这些缺陷普遍存在于不同模型中，包括大规模通用模型和较小的GUI专用模型。

Conclusion: 详细的错误分析揭示了几个普遍问题，为未来改进指明了具体方向，过程相关的评估方法对于全面评估GUI代理能力至关重要。

Abstract: With the deep integration of artificial intelligence and interactive technology, Graphical User Interface (GUI) Agent, as the carrier connecting goal-oriented natural language and real-world devices, has received widespread attention from the community. Contemporary benchmarks aim to evaluate the comprehensive capabilities of GUI agents in GUI operation tasks, generally determining task completion solely by inspecting the final screen state. However, GUI operation tasks consist of multiple chained steps while not all critical information is presented in the final few pages. Although a few research has begun to incorporate intermediate steps into evaluation, accurately and automatically capturing this process information still remains an open challenge. To address this weakness, we introduce ProBench, a comprehensive mobile benchmark with over 200 challenging GUI tasks covering widely-used scenarios. Remaining the traditional State-related Task evaluation, we extend our dataset to include Process-related Task and design a specialized evaluation method. A newly introduced Process Provider automatically supplies accurate process information, enabling presice assessment of agent's performance. Our evaluation of advanced GUI agents reveals significant limitations for real-world GUI scenarios. These shortcomings are prevalent across diverse models, including both large-scale generalist models and smaller, GUI-specific models. A detailed error analysis further exposes several universal problems, outlining concrete directions for future improvements.

</details>


### [47] [Efficient Reasoning via Reward Model](https://arxiv.org/abs/2511.09158)
*Yuhao Wang,Xiaopeng Li,Cheng Gong,Ziru Liu,Suiyun Zhang,Rui Liu,Xiangyu Zhao*

Main category: cs.AI

TL;DR: 提出了一种训练简洁性奖励模型（CRM）的方法，通过新颖的奖励函数（CRF）解决大型推理模型中的过度思考问题，在提高准确率的同时显著减少推理长度。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（如DeepSeek-R1和OpenAI o1）经常产生冗长的推理过程，包含冗余或不相关的步骤（过度思考现象），这大大增加了计算成本。现有的长度惩罚方法存在长度崩溃和训练崩溃问题。

Method: 提出了训练简洁性奖励模型（CRM）的流程，用于评估推理路径的简洁性；并引入了新颖的简洁性奖励函数（CRF），明确建立结果奖励与简洁性分数之间的依赖关系。

Result: 在五个数学基准数据集上的实验表明，该方法在Qwen2.5-7B上实现了8.1%的准确率提升和19.9%的响应token长度减少，并且在Llama和Mistral等其他LLM上也有良好的泛化能力。

Conclusion: 该方法通过理论证明和实践验证，能够有效促进更高效和更有效的推理，同时减少计算成本，为大型推理模型的优化提供了有效解决方案。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has been shown to enhance the reasoning capabilities of large language models (LLMs), enabling the development of large reasoning models (LRMs). However, LRMs such as DeepSeek-R1 and OpenAI o1 often generate verbose responses containing redundant or irrelevant reasoning step-a phenomenon known as overthinking-which substantially increases computational costs. Prior efforts to mitigate this issue commonly incorporate length penalties into the reward function, but we find they frequently suffer from two critical issues: length collapse and training collapse, resulting in sub-optimal performance. To address them, we propose a pipeline for training a Conciseness Reward Model (CRM) that scores the conciseness of reasoning path. Additionally, we introduce a novel reward formulation named Conciseness Reward Function (CRF) with explicit dependency between the outcome reward and conciseness score, thereby fostering both more effective and more efficient reasoning. From a theoretical standpoint, we demonstrate the superiority of the new reward from the perspective of variance reduction and improved convergence properties. Besides, on the practical side, extensive experiments on five mathematical benchmark datasets demonstrate the method's effectiveness and token efficiency, which achieves an 8.1% accuracy improvement and a 19.9% reduction in response token length on Qwen2.5-7B. Furthermore, the method generalizes well to other LLMs including Llama and Mistral. The implementation code and datasets are publicly available for reproduction: https://anonymous.4open.science/r/CRM.

</details>


### [48] [Perspectives on a Reliability Monitoring Framework for Agentic AI Systems](https://arxiv.org/abs/2511.09178)
*Niclas Flehmig,Mary Ann Lundteigen,Shen Yin*

Main category: cs.AI

TL;DR: 提出了一个用于智能AI系统的双层可靠性监控框架，包括分布外检测层和AI透明度层，以解决系统在运行期间可靠性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 智能AI系统在医疗和过程工业等高风险领域应用时，由于可靠性不足可能导致意外行为，需要开发缓解技术来降低风险。

Method: 基于智能AI系统特性推导主要可靠性挑战，提出包含分布外检测（处理新输入）和AI透明度（揭示内部操作）的双层监控框架。

Result: 该框架为开发缓解技术提供了基础，能够支持人类操作员判断输出是否可能不可靠并进行干预。

Conclusion: 双层可靠性监控框架是减少智能AI系统在运行期间可靠性不确定性的有效方法，为高风险应用提供了决策支持。

Abstract: The implementation of agentic AI systems has the potential of providing more helpful AI systems in a variety of applications. These systems work autonomously towards a defined goal with reduced external control. Despite their potential, one of their flaws is the insufficient reliability which makes them especially unsuitable for high-risk domains such as healthcare or process industry. Unreliable systems pose a risk in terms of unexpected behavior during operation and mitigation techniques are needed. In this work, we derive the main reliability challenges of agentic AI systems during operation based on their characteristics. We draw the connection to traditional AI systems and formulate a fundamental reliability challenge during operation which is inherent to traditional and agentic AI systems. As our main contribution, we propose a two-layered reliability monitoring framework for agentic AI systems which consists of a out-of-distribution detection layer for novel inputs and AI transparency layer to reveal internal operations. This two-layered monitoring approach gives a human operator the decision support which is needed to decide whether an output is potential unreliable or not and intervene. This framework provides a foundation for developing mitigation techniques to reduce risk stemming from uncertain reliability during operation.

</details>


### [49] [MedFuse: Multiplicative Embedding Fusion For Irregular Clinical Time Series](https://arxiv.org/abs/2511.09247)
*Yi-Hsien Hsieh,Ta-Jung Chien,Chun-Kai Huang,Shao-Hua Sun,Che Lin*

Main category: cs.AI

TL;DR: MedFuse是一个用于不规则临床时间序列的框架，通过乘法融合模块MuFuse将特征值和特征身份嵌入相结合，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中的临床时间序列具有不规则性、异步采样、缺失值和异质特征动态等问题。现有嵌入策略通常通过加法操作结合特征身份和值嵌入，限制了捕捉值依赖特征交互的能力。

Method: 提出MedFuse框架，核心是MuFuse模块，通过乘法调制融合值和特征嵌入，保留特征特定信息的同时建模跨特征的高阶依赖关系。

Result: 在三个真实世界数据集上的实验表明，MedFuse在关键预测任务上始终优于最先进的基线方法。学习表示的分析进一步证明乘法融合增强了表达能力并支持跨数据集预训练。

Conclusion: MedFuse为建模不规则临床时间序列提供了一个可推广的方法，乘法融合机制显著提升了模型性能。

Abstract: Clinical time series derived from electronic health records (EHRs) are inherently irregular, with asynchronous sampling, missing values, and heterogeneous feature dynamics. While numerical laboratory measurements are highly informative, existing embedding strategies usually combine feature identity and value embeddings through additive operations, which constrains their ability to capture value-dependent feature interactions. We propose MedFuse, a framework for irregular clinical time series centered on the MuFuse (Multiplicative Embedding Fusion) module. MuFuse fuses value and feature embeddings through multiplicative modulation, preserving feature-specific information while modeling higher-order dependencies across features. Experiments on three real-world datasets covering both intensive and chronic care show that MedFuse consistently outperforms state-of-the-art baselines on key predictive tasks. Analysis of the learned representations further demonstrates that multiplicative fusion enhances expressiveness and supports cross-dataset pretraining. These results establish MedFuse as a generalizable approach for modeling irregular clinical time series.

</details>


### [50] [HyperD: Hybrid Periodicity Decoupling Framework for Traffic Forecasting](https://arxiv.org/abs/2511.09275)
*Minlan Shao,Zijian Zhang,Yili Wang,Yiwei Dai,Xu Shen,Xin Wang*

Main category: cs.AI

TL;DR: 提出HyperD框架，通过解耦交通数据的周期性和残差分量来提升交通预测精度，结合混合周期表示和频率感知残差建模，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 交通预测面临复杂空间依赖性和多尺度周期模式与不规则波动共存的挑战，需要同时处理周期性规律和突发事件影响。

Method: HyperD框架将交通数据解耦为周期性和残差分量：周期性分量使用混合周期表示模块，残差分量使用频率感知残差表示模块，并引入双视图对齐损失确保语义分离。

Result: 在四个真实交通数据集上的实验表明，HyperD实现了最先进的预测精度，在扰动下具有更好的鲁棒性和计算效率。

Conclusion: HyperD通过解耦周期性和非周期性模式，有效提升了交通预测性能，为智能交通系统提供了可靠的解决方案。

Abstract: Accurate traffic forecasting plays a vital role in intelligent transportation systems, enabling applications such as congestion control, route planning, and urban mobility optimization.However, traffic forecasting remains challenging due to two key factors: (1) complex spatial dependencies arising from dynamic interactions between road segments and traffic sensors across the network, and (2) the coexistence of multi-scale periodic patterns (e.g., daily and weekly periodic patterns driven by human routines) with irregular fluctuations caused by unpredictable events (e.g., accidents, weather, or construction). To tackle these challenges, we propose HyperD (Hybrid Periodic Decoupling), a novel framework that decouples traffic data into periodic and residual components. The periodic component is handled by the Hybrid Periodic Representation Module, which extracts fine-grained daily and weekly patterns using learnable periodic embeddings and spatial-temporal attention. The residual component, which captures non-periodic, high-frequency fluctuations, is modeled by the Frequency-Aware Residual Representation Module, leveraging complex-valued MLP in frequency domain. To enforce semantic separation between the two components, we further introduce a Dual-View Alignment Loss, which aligns low-frequency information with the periodic branch and high-frequency information with the residual branch. Extensive experiments on four real-world traffic datasets demonstrate that HyperD achieves state-of-the-art prediction accuracy, while offering superior robustness under disturbances and improved computational efficiency compared to existing methods.

</details>


### [51] [Not Everything That Counts Can Be Counted: A Case for Safe Qualitative AI](https://arxiv.org/abs/2511.09325)
*Stine Beltoft,Lukas Galke*

Main category: cs.AI

TL;DR: 本文主张开发专门针对定性研究的AI系统，以弥补当前AI在定性研究方法中的不足，这些系统需要具备透明、可重现和隐私友好的特性。


<details>
  <summary>Details</summary>
Motivation: 当前AI主要推动了定量方法的发展，但定性研究领域被忽视。定性研究者对使用AI持保留态度，只能依赖通用工具如ChatGPT，但这些工具存在偏见、不透明、不可重现和隐私问题。

Method: 通过文献回顾，分析现有自动化发现流程如何通过增强定性能力来改进，并识别安全定性AI在多学科和混合方法研究中的关键机会。

Result: 识别了AI在定性研究中的关键应用领域，包括访谈解释、数据标注和主题建模，并提出了开发专门定性AI系统的必要性。

Conclusion: 需要从零开始构建专门用于解释性研究的定性AI系统，这些系统必须透明、可重现且隐私友好，以促进多学科和混合方法研究的进步。

Abstract: Artificial intelligence (AI) and large language models (LLM) are reshaping science, with most recent advances culminating in fully-automated scientific discovery pipelines. But qualitative research has been left behind. Researchers in qualitative methods are hesitant about AI adoption. Yet when they are willing to use AI at all, they have little choice but to rely on general-purpose tools like ChatGPT to assist with interview interpretation, data annotation, and topic modeling - while simultaneously acknowledging these system's well-known limitations of being biased, opaque, irreproducible, and privacy-compromising. This creates a critical gap: while AI has substantially advanced quantitative methods, the qualitative dimensions essential for meaning-making and comprehensive scientific understanding remain poorly integrated. We argue for developing dedicated qualitative AI systems built from the ground up for interpretive research. Such systems must be transparent, reproducible, and privacy-friendly. We review recent literature to show how existing automated discovery pipelines could be enhanced by robust qualitative capabilities, and identify key opportunities where safe qualitative AI could advance multidisciplinary and mixed-methods research.

</details>


### [52] [BarrierBench : Evaluating Large Language Models for Safety Verification in Dynamical Systems](https://arxiv.org/abs/2511.09363)
*Ali Taheri,Alireza Taban,Sadegh Soudjani,Ashutosh Trivedi*

Main category: cs.AI

TL;DR: 提出基于LLM的智能体框架用于屏障证书合成，通过自然语言推理来提出、优化和验证候选证书，在100个动力系统基准测试中达到90%以上的成功率。


<details>
  <summary>Details</summary>
Motivation: 传统屏障证书合成方法存在可扩展性差、依赖精心设计的模板、需要大量手动专业知识等问题，需要探索是否能通过语言模型捕捉专家推理过程。

Method: 使用LLM驱动的智能体框架，结合自然语言推理进行模板发现和SMT验证，支持屏障-控制器协同合成以确保安全证书与控制器的兼容性。

Result: 在BarrierBench基准测试中，该框架在生成有效证书方面达到90%以上的成功率，验证了检索增强生成和智能体协调策略的有效性。

Conclusion: 成功展示了语言模型能够捕捉专家推理过程，为形式验证与语言推理在动力系统中的集成提供了可行路径。

Abstract: Safety verification of dynamical systems via barrier certificates is essential for ensuring correctness in autonomous applications. Synthesizing these certificates involves discovering mathematical functions with current methods suffering from poor scalability, dependence on carefully designed templates, and exhaustive or incremental function-space searches. They also demand substantial manual expertise--selecting templates, solvers, and hyperparameters, and designing sampling strategies--requiring both theoretical and practical knowledge traditionally shared through linguistic reasoning rather than formalized methods.
  This motivates a key question: can such expert reasoning be captured and operationalized by language models? We address this by introducing an LLM-based agentic framework for barrier certificate synthesis. The framework uses natural language reasoning to propose, refine, and validate candidate certificates, integrating LLM-driven template discovery with SMT-based verification, and supporting barrier-controller co-synthesis to ensure consistency between safety certificates and controllers.
  To evaluate this capability, we introduce BarrierBench, a benchmark of 100 dynamical systems spanning linear, nonlinear, discrete-time, and continuous-time settings. Our experiments assess not only the effectiveness of LLM-guided barrier synthesis but also the utility of retrieval-augmented generation and agentic coordination strategies in improving its reliability and performance. Across these tasks, the framework achieves more than 90% success in generating valid certificates. By releasing BarrierBench and the accompanying toolchain, we aim to establish a community testbed for advancing the integration of language-based reasoning with formal verification in dynamical systems.
  The benchmark is publicly available at https://hycodev.com/dataset/barrierbench

</details>


### [53] [The 2025 Planning Performance of Frontier Large Language Models](https://arxiv.org/abs/2511.09378)
*Augusto B. Corrêa,André G. Pereira,Jendrik Seipp*

Main category: cs.AI

TL;DR: 2025年对DeepSeek R1、Gemini 2.5 Pro、GPT-5和LAMA规划器在PDDL领域的端到端规划性能评估，显示GPT-5在标准PDDL任务上与LAMA竞争，但在混淆测试中所有LLM性能下降但优于前代模型。


<details>
  <summary>Details</summary>
Motivation: 评估前沿大语言模型在推理能力方面的进展，特别是端到端规划性能，并与传统规划器进行比较。

Method: 使用国际规划竞赛学习赛道中的PDDL领域子集，评估模型从PDDL领域和任务描述生成计划的能力，包括标准PDDL和混淆PDDL测试。

Result: GPT-5在标准PDDL任务上解决的任务数量与LAMA规划器相当；所有LLM在混淆PDDL测试中性能下降但降幅小于之前报告的其他模型。

Conclusion: 前沿LLM在规划能力方面相比前代模型有显著改进，在具有挑战性的基准测试中缩小了与传统规划器的性能差距。

Abstract: The capacity of Large Language Models (LLMs) for reasoning remains an active area of research, with the capabilities of frontier models continually advancing. We provide an updated evaluation of the end-to-end planning performance of three frontier LLMs as of 2025, where models are prompted to generate a plan from PDDL domain and task descriptions. We evaluate DeepSeek R1, Gemini 2.5 Pro, GPT-5 and as reference the planner LAMA on a subset of domains from the most recent Learning Track of the International Planning Competition. Our results show that on standard PDDL domains, the performance of GPT-5 in terms of solved tasks is competitive with LAMA. When the PDDL domains and tasks are obfuscated to test for pure reasoning, the performance of all LLMs degrades, though less severely than previously reported for other models. These results show substantial improvements over prior generations of LLMs, reducing the performance gap to planners on a challenging benchmark.

</details>


### [54] [What We Don't C: Representations for scientific discovery beyond VAEs](https://arxiv.org/abs/2511.09433)
*Brian Rogers,Micah Bowles,Chris J. Lintott,Steve Croft*

Main category: cs.AI

TL;DR: 提出了一种基于潜在流匹配和分类器自由引导的新方法，通过显式分离条件信息与残差表示来解缠潜在子空间，在多个实验中展示了访问高维数据有意义特征的能力。


<details>
  <summary>Details</summary>
Motivation: 在高维领域进行科学发现需要访问学习表示中的信息，但目前缺乏有效的方法来分析、控制和重新利用潜在表示。

Method: 基于潜在流匹配与分类器自由引导，显式分离条件信息与残差表示，实现潜在子空间的解缠。

Result: 在合成2D高斯问题、彩色MNIST和Galaxy10天文数据集三个实验中，该方法成功访问了高维数据的有意义特征。

Conclusion: 该方法为分析、控制和重新利用潜在表示提供了简单而强大的机制，为使用生成模型进行科学探索开辟了途径。

Abstract: Accessing information in learned representations is critical for scientific discovery in high-dimensional domains. We introduce a novel method based on latent flow matching with classifier-free guidance that disentangles latent subspaces by explicitly separating information included in conditioning from information that remains in the residual representation. Across three experiments -- a synthetic 2D Gaussian toy problem, colored MNIST, and the Galaxy10 astronomy dataset -- we show that our method enables access to meaningful features of high dimensional data. Our results highlight a simple yet powerful mechanism for analyzing, controlling, and repurposing latent representations, providing a pathway toward using generative models for scientific exploration of what we don't capture, consider, or catalog.

</details>


### [55] [CrochetBench: Can Vision-Language Models Move from Describing to Doing in Crochet Domain?](https://arxiv.org/abs/2511.09483)
*Peiyu Li,Xiaobao Huang,Nitesh V. Chawla*

Main category: cs.AI

TL;DR: CrochetBench是一个评估多模态大语言模型在钩针编织领域进行细粒度、低层次程序推理能力的基准测试，强调从描述转向实际操作，包括识别针法、选择结构适当的指令和生成可编译的钩针程序。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要关注高层次描述或视觉问答，缺乏对实际执行能力的评估。CrochetBench旨在填补这一空白，通过评估模型在真实创造性领域中的程序能力。

Method: 采用CrochetPARADE DSL作为中间表示，支持结构验证和通过执行进行功能评估。基准测试涵盖针法分类、指令接地以及自然语言和图像到DSL的翻译任务。

Result: 在所有任务中，当评估从表面相似性转向可执行正确性时，性能急剧下降，暴露了长距离符号推理和3D感知程序合成的局限性。

Conclusion: CrochetBench为评估多模态模型的程序能力提供了新视角，并突显了在真实创造性领域中表面理解与可执行精度之间的差距。

Abstract: We present CrochetBench, a benchmark for evaluating the ability of multimodal large language models to perform fine-grained, low-level procedural reasoning in the domain of crochet. Unlike prior benchmarks that focus on high-level description or visual question answering, CrochetBench shifts the emphasis from describing to doing: models are required to recognize stitches, select structurally appropriate instructions, and generate compilable crochet procedures. We adopt the CrochetPARADE DSL as our intermediate representation, enabling structural validation and functional evaluation via execution. The benchmark covers tasks including stitch classification, instruction grounding, and both natural language and image-to-DSL translation. Across all tasks, performance sharply declines as the evaluation shifts from surface-level similarity to executable correctness, exposing limitations in long-range symbolic reasoning and 3D-aware procedural synthesis. CrochetBench offers a new lens for assessing procedural competence in multimodal models and highlights the gap between surface-level understanding and executable precision in real-world creative domains. Code is available at https://github.com/Peiyu-Georgia-Li/crochetBench.

</details>


### [56] [Consensus Sampling for Safer Generative AI](https://arxiv.org/abs/2511.09493)
*Adam Tauman Kalai,Yael Tauman Kalai,Or Zamir*

Main category: cs.AI

TL;DR: 提出一种基于多模型聚合的AI安全方法，通过共识采样算法选择最安全的模型子集来增强安全性。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全方法依赖模型输出或激活检查，但某些风险无法通过检查检测，需要架构无关的补充方法。

Method: 使用共识采样算法，给定k个模型和提示，选择最安全的s个模型子集，当模型间缺乏足够共识时弃权。算法利用模型计算输出概率的能力。

Result: 算法能够实现与最安全s个模型平均风险相当的风险水平，并在足够多模型安全且达成共识时限制弃权概率。

Conclusion: 该方法提供了一种新的模型无关AI安全方法，通过放大集合中未知安全模型子集的安全保证来创建可靠模型。

Abstract: Many approaches to AI safety rely on inspecting model outputs or activations, yet certain risks are inherently undetectable by inspection alone. We propose a complementary, architecture-agnostic approach that enhances safety through the aggregation of multiple generative models, with the aggregated model inheriting its safety from the safest subset of a given size among them. Specifically, we present a consensus sampling algorithm that, given $k$ models and a prompt, achieves risk competitive with the average risk of the safest $s$ of the $k$ models, where $s$ is a chosen parameter, while abstaining when there is insufficient agreement between them. The approach leverages the models' ability to compute output probabilities, and we bound the probability of abstention when sufficiently many models are safe and exhibit adequate agreement. The algorithm is inspired by the provable copyright protection algorithm of Vyas et al. (2023). It requires some overlap among safe models, offers no protection when all models are unsafe, and may accumulate risk over repeated use. Nonetheless, our results provide a new, model-agnostic approach for AI safety by amplifying safety guarantees from an unknown subset of models within a collection to that of a single reliable model.

</details>


### [57] [Fundamentals of Physical AI](https://arxiv.org/abs/2511.09497)
*Vahid Salehi*

Main category: cs.AI

TL;DR: 本文从科学和系统角度阐述了物理人工智能的基本原理，提出了包含具身化、感官感知、运动行动、学习、自主性和上下文敏感性的六个基本原则，这些原则构成一个封闭的控制循环，将智能理解为身体、环境和经验真实互动的涌现现象。


<details>
  <summary>Details</summary>
Motivation: 建立物理人工智能的理论基础，描述智能系统的物理具身化、感官感知、行动能力、学习过程和上下文敏感性，将智能理解为物理具身过程而非符号处理。

Method: 提出六个基本原则（具身化、感官感知、运动行动、学习、自主性、上下文敏感性）作为概念框架，并通过康复诊所中自适应辅助机器人的实际场景来说明理论模型。

Result: 建立了物理人工智能的理论框架，展示了六个原则如何作为封闭控制循环相互作用，使系统能够从物理经验而非数据库中生成意义。

Conclusion: 物理人工智能将智能理解为物理具身过程，学习是智能体与环境之间结构耦合的变化，而非参数调整，这代表了从抽象计算到具身体验的范式转变。

Abstract: This work will elaborate the fundamental principles of physical artificial intelligence (Physical AI) from a scientific and systemic perspective. The aim is to create a theoretical foundation that describes the physical embodiment, sensory perception, ability to act, learning processes, and context sensitivity of intelligent systems within a coherent framework. While classical AI approaches rely on symbolic processing and data driven models, Physical AI understands intelligence as an emergent phenomenon of real interaction between body, environment, and experience. The six fundamentals presented here are embodiment, sensory perception, motor action, learning, autonomy, and context sensitivity, and form the conceptual basis for designing and evaluating physically intelligent systems. Theoretically, it is shown that these six principles do not represent loose functional modules but rather act as a closed control loop in which energy, information, control, and context are in constant interaction. This circular interaction enables a system to generate meaning not from databases, but from physical experience, a paradigm shift that understands intelligence as an physical embodied process. Physical AI understands learning not as parameter adjustment, but as a change in the structural coupling between agents and the environment. To illustrate this, the theoretical model is explained using a practical scenario: An adaptive assistant robot supports patients in a rehabilitation clinic. This example illustrates that physical intelligence does not arise from abstract calculation, but from immediate, embodied experience. It shows how the six fundamentals interact in a real system: embodiment as a prerequisite, perception as input, movement as expression, learning as adaptation, autonomy as regulation, and context as orientation.

</details>


### [58] [Robust and Diverse Multi-Agent Learning via Rational Policy Gradient](https://arxiv.org/abs/2511.09535)
*Niklas Lauffer,Ameesh Shah,Micah Carroll,Sanjit A. Seshia,Stuart Russell,Michael Dennis*

Main category: cs.AI

TL;DR: 提出了Rationality-preserving Policy Optimization (RPO)框架和Rational Policy Gradient (RPG)算法，通过在修改后的游戏环境中使用对手塑造技术，避免对抗性优化在合作设置中导致的自毁行为问题。


<details>
  <summary>Details</summary>
Motivation: 对抗性优化算法在多智能体环境中能有效发现鲁棒和多样化的策略，但在合作设置中会导致智能体非理性地自毁，阻碍任务完成和学习进程。

Method: 开发了RPG算法，在修改后的游戏环境中训练智能体最大化自身奖励，使用对手塑造技术优化对抗性目标，确保智能体保持理性（即策略对某些可能的伙伴策略是最优的）。

Result: RPG能够扩展多种现有的对抗性优化算法，不再受自毁限制，能够发现对抗性示例、提高鲁棒性和适应性、学习多样化策略，在多个合作和一般和环境中表现出色。

Conclusion: RPO框架和RPG算法成功解决了对抗性优化在合作设置中的自毁问题，为在多智能体环境中应用对抗性优化提供了有效解决方案。

Abstract: Adversarial optimization algorithms that explicitly search for flaws in agents' policies have been successfully applied to finding robust and diverse policies in multi-agent settings. However, the success of adversarial optimization has been largely limited to zero-sum settings because its naive application in cooperative settings leads to a critical failure mode: agents are irrationally incentivized to self-sabotage, blocking the completion of tasks and halting further learning. To address this, we introduce Rationality-preserving Policy Optimization (RPO), a formalism for adversarial optimization that avoids self-sabotage by ensuring agents remain rational--that is, their policies are optimal with respect to some possible partner policy. To solve RPO, we develop Rational Policy Gradient (RPG), which trains agents to maximize their own reward in a modified version of the original game in which we use opponent shaping techniques to optimize the adversarial objective. RPG enables us to extend a variety of existing adversarial optimization algorithms that, no longer subject to the limitations of self-sabotage, can find adversarial examples, improve robustness and adaptability, and learn diverse policies. We empirically validate that our approach achieves strong performance in several popular cooperative and general-sum environments. Our project page can be found at https://rational-policy-gradient.github.io.

</details>


### [59] [Breadth-First Search vs. Restarting Random Walks for Escaping Uninformed Heuristic Regions](https://arxiv.org/abs/2511.09549)
*Daniel Platnick,Dawson Tomasz,Eamon Earl,Sourena Khanzadeh,Richard Valenzano*

Main category: cs.AI

TL;DR: 比较了广度优先搜索(BrFS)和重启随机游走(RRW)两种逃离无信息启发式区域(UHR)的方法，推导了它们的期望运行时间，并开发了使用RRW的EHC-RRW变体，在PDDL规划基准测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 贪婪搜索方法如GBFS和EHC在遇到启发式局部极小值或平台等无信息启发式区域(UHR)时表现不佳，需要有效的逃离机制。

Method: 理论推导BrFS和RRW逃离UHR的期望运行时间，开发EHC-RRW变体使用RRW替代BrFS，并在PDDL规划基准上进行实验比较。

Result: 确定了RRW比BrFS更快的条件，EHC-RRW在EHC有效的场景下具有强期望运行时间保证，实验验证了RRW在逃离UHR方面的相对有效性。

Conclusion: 重启随机游走(RRW)是逃离无信息启发式区域的有效方法，EHC-RRW变体在理论保证和实际性能上都表现出色。

Abstract: Greedy search methods like Greedy Best-First Search (GBFS) and Enforced Hill-Climbing (EHC) often struggle when faced with Uninformed Heuristic Regions (UHRs) like heuristic local minima or plateaus. In this work, we theoretically and empirically compare two popular methods for escaping UHRs in breadth-first search (BrFS) and restarting random walks (RRWs). We first derive the expected runtime of escaping a UHR using BrFS and RRWs, based on properties of the UHR and the random walk procedure, and then use these results to identify when RRWs will be faster in expectation than BrFS. We then evaluate these methods for escaping UHRs by comparing standard EHC, which uses BrFS to escape UHRs, to variants of EHC called EHC-RRW, which use RRWs for that purpose. EHC-RRW is shown to have strong expected runtime guarantees in cases where EHC has previously been shown to be effective. We also run experiments with these approaches on PDDL planning benchmarks to better understand their relative effectiveness for escaping UHRs.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [60] [Conformal Prediction for Multi-Source Detection on a Network](https://arxiv.org/abs/2511.08867)
*Xingchao Jian,Purui Zhang,Lan Tian,Feng Ji,Wenfei Liang,Wee Peng Tay,Bihan Wen,Felix Krahmer*

Main category: cs.SI

TL;DR: 提出了一种基于共形预测的多源检测框架，为网络信息传播源检测提供统计保证的召回率，适用于各种扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏统计保证或局限于特定扩散模型，需要一种独立于底层扩散过程且具有统计有效性的多源检测方法。

Method: 引入原则性评分函数量化预测概率与真实源的匹配度，利用校准集构建具有用户指定召回率和覆盖水平的预测集。

Result: 实证结果表明该方法实现了严格的覆盖保证和竞争性准确度，在可靠性和可扩展性方面优于现有基线方法。

Conclusion: 该共形预测框架为多源检测问题提供了统计有效的解决方案，适用于单源和多源场景，支持通用网络扩散动态，计算效率高。

Abstract: Detecting the origin of information or infection spread in networks is a fundamental challenge with applications in misinformation tracking, epidemiology, and beyond. We study the multi-source detection problem: given snapshot observations of node infection status on a graph, estimate the set of source nodes that initiated the propagation. Existing methods either lack statistical guarantees or are limited to specific diffusion models and assumptions. We propose a novel conformal prediction framework that provides statistically valid recall guarantees for source set detection, independent of the underlying diffusion process or data distribution. Our approach introduces principled score functions to quantify the alignment between predicted probabilities and true sources, and leverages a calibration set to construct prediction sets with user-specified recall and coverage levels. The method is applicable to both single- and multi-source scenarios, supports general network diffusion dynamics, and is computationally efficient for large graphs. Empirical results demonstrate that our method achieves rigorous coverage with competitive accuracy, outperforming existing baselines in both reliability and scalability.The code is available online.

</details>


### [61] [Iterative Ricci-Foster Curvature Flow with GMM-Based Edge Pruning: A Novel Approach to Community Detection](https://arxiv.org/abs/2511.08919)
*Arsenii Onuchin,Konstantin Sorokin,Maxim Beketov,Liubov Tupikina*

Main category: cs.SI

TL;DR: 提出基于Foster-Ricci曲率流的图社区检测新方法，通过迭代更新边权重并结合高斯混合模型分类，显著优于Ollivier-Ricci几何流方法。


<details>
  <summary>Details</summary>
Motivation: 复杂网络中的社区检测是一个基础性问题，需要新的方法来解决。现有基于Ollivier-Ricci几何流的方法计算效率较低，需要更高效的替代方案。

Method: 使用Foster-Ricci曲率流迭代更新边权重（基于有效电阻距离计算），然后通过高斯混合模型将边分为'强'（社区内）和'弱'（社区间）两类，最后系统性地修剪弱边来分离社区。

Result: 在随机块模型生成的合成网络上测试，使用调整兰德指数评估，结果表明该方法能稳健地恢复植入的社区结构，计算时间显著优于Ollivier-Ricci流方法。

Conclusion: Foster-Ricci流与GMM聚类相结合提供了一个原理性强、计算效率高的网络分析新工具，在社区检测任务上表现优异。

Abstract: Community detection in complex networks is a fundamental problem, open to new approaches in various scientific settings. We introduce a novel community detection method, based on Ricci flow on graphs. Our technique iteratively updates edge weights (their metric lengths) according to their (combinatorial) Foster version of Ricci curvature computed from effective resistance distance between the nodes. The latter computation is known to be done by pseudo-inverting the graph Laplacian matrix. At that, our approach is alternative to one based on Ollivier-Ricci geometric flow for community detection on graphs, significantly outperforming it in terms of computation time. In our proposed method, iterations of Foster-Ricci flow that highlight network regions of different curvature -- are followed by a Gaussian Mixture Model (GMM) separation heuristic. That allows to classify edges into ''strong'' (intra-community) and ''weak'' (inter-community) groups, followed by a systematic pruning of the former to isolate communities. We benchmark our algorithm on synthetic networks generated from the Stochastic Block Model (SBM), evaluating performance with the Adjusted Rand Index (ARI). Our results demonstrate that proposed framework robustly recovers the planted community structure of SBM-s, establishing Ricci-Foster Flow with GMM-clustering as a principled and computationally effective new tool for network analysis, tested against alternative Ricci-Ollivier flow coupled with spectral clustering.

</details>


### [62] [A Spanning-Tree-Based Algorithm for Planar Graph Dismantling](https://arxiv.org/abs/2511.09132)
*Fangchen You*

Main category: cs.SI

TL;DR: 提出了一种基于生成树骨架的双路径框架，用于在边预算约束下高效拆解平面图，分析网络鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在空间嵌入网络（如交通和电网）中，理解边移除如何影响连通性对于鲁棒性分析至关重要。

Method: 使用生成树骨架双路径框架：先采样多个均匀生成树捕捉网络骨干，然后根据预算自适应选择两条互补路径——小预算路径使用对数密度特征估计可拆分子图比例，大预算路径通过基于斜率的模型预测最优分区数。

Result: 在随机平面图上的实验显示：接近线性的运行时间扩展、最大连通分量比的一致减小、清晰的预算-碎片化趋势。

Conclusion: 该方法为平面网络鲁棒性分析提供了一种可解释且高效的方法。

Abstract: In spatially embedded networks such as transportation and power grids, understanding how edge removals affect connectivity is crucial for robustness analysis. This paper studies a planar graph dismantling problem under an edge-budget constraint. We propose a spanning-tree-skeleton dual-path framework that first samples multiple uniform spanning trees to capture network backbones and then adaptively selects between two complementary paths according to the budget. The small-budget path estimates a dismantlable subgraph fraction using a logarithmic density feature, while the large-budget path predicts the optimal partition count through a slope-based model. Experiments on random planar graphs demonstrate near-linear runtime scaling, consistent reductions in the largest connected component ratio, and clear budget-fragmentation trends. The method provides an interpretable and efficient approach for planar-network robustness analysis.

</details>


### [63] [A Phase Transition for Opinion Dynamics with Competing Biases](https://arxiv.org/abs/2511.09434)
*Federico Capannoli,Emilio Cruciani,Hlafo Alfie Mimun,Matteo Quattropani*

Main category: cs.SI

TL;DR: 本文研究有向网络中二元意见的非线性动态，发现存在相变：当外部偏见p超过临界阈值pc时，系统快速达成共识；当p<pc时，系统进入亚稳态，只有部分代理人接受新意见。


<details>
  <summary>Details</summary>
Motivation: 研究网络中代理人意见动态，探索外部偏见与代理人固执性之间的竞争，理解网络意见动态的临界点。

Method: 使用有向随机图模型，代理人根据邻居状态和外部偏见p非线性更新意见，通过分支、合并和消亡粒子系统进行等价分析。

Result: 发现临界阈值pc和亚稳态比例q*(p)仅取决于度序列的简单统计量，明确刻画了代理人度、固执性和外部偏见的相互作用。

Conclusion: 系统动态展现出相变行为，揭示了网络意见动态的临界点，为理解外部干预如何改变集体意见提供了理论框架。

Abstract: We study a nonlinear dynamics of binary opinions in a population of agents connected by a directed network, influenced by two competing forces. On the one hand, agents are stubborn, i.e., have a tendency for one of the two opinions; on the other hand, there is a disruptive bias, $p\in[0,1]$, that drives the agents toward the other opinion. The disruptive bias models external factors, such as market innovations or social controllers, aiming to challenge the status quo, while agents' stubbornness reinforces the initial opinion making it harder for the external bias to drive the process toward change. Each agent updates its opinion according to a nonlinear function of the states of its neighbors and of the bias $p$. We consider the case of random directed graphs with prescribed in- and out-degree sequences and we prove that the dynamics exhibits a phase transition: when the disruptive bias $p$ is larger than a critical threshold $p_c$, the population converges in constant time to a consensus on the disruptive opinion. Conversely, when the bias $p$ is less than $p_c$, the system enters a metastable state in which only a fraction of agents $q_\star(p)<1$ will share the new opinion for a long time. We characterize $p_c$ and $q_\star(p)$ explicitly, showing that they only depend on few simple statistics of the degree sequences. Our analysis relies on a dual system of branching, coalescing, and dying particles, which we show exhibits equivalent behavior and allows a rigorous characterization of the system's dynamics. Our results characterize the interplay between the degree of the agents, their stubbornness, and the external bias, shedding light on the tipping points of opinion dynamics in networks.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [64] [What Benefits Drive Membership in Medicare Advantage Plans?](https://arxiv.org/abs/2511.08603)
*Xiyue Liao,Ian Duncan*

Main category: econ.GN

TL;DR: 该研究通过多分类Lasso模型分析Medicare Advantage健康计划中影响市场份额的关键因素，发现品牌、PPO计划和处方药覆盖是主要驱动因素，而附加福利影响较小。


<details>
  <summary>Details</summary>
Motivation: 识别Medicare Advantage健康计划中真正驱动会员数量和市场份额的关键福利因素，为保险公司制定更有效的市场策略提供依据。

Method: 使用2018-2023年新泽西州单个县的公开数据，构建数据集并应用方差膨胀因子消除多重共线性。将市场份额分为三个类别，采用多分类Lasso模型和5折交叉验证来调整惩罚参数。

Result: 不同市场份额类别的重要变量各不相同。品牌、PPO计划和处方药覆盖是主要驱动因素，附加福利影响较小，而免赔额、共付额和自付上限等财务条款与较高市场份额相关。模型测试集准确率为0.76。

Conclusion: Medicare Advantage计划的市场份额主要由品牌声誉、PPO计划类型和处方药覆盖等核心因素驱动，而非附加福利。财务条款对市场份额有显著影响，这为保险公司优化产品设计提供了重要参考。

Abstract: We seek to identify the most relevant benefits offered by Medicare Advantage Health Plans that drive membership and market share. As an example, we explore plans operating in a single county in New Jersey between 2018 and 2023. A dataset of benefits from publicly available data sources was created and the variance inflation factor was applied to identify the correlation between the extracted features, to avoid multicollinearity and overparameterization problems. We categorized the variable Market Share and used it as a multinomial response variable with three categories: less than 0.3\%, 0.3\% to 1.5\%, and over 1.5\%. Categories were chosen to achieve approximately uniform distribution of plans (47, 60, and 65 respectively). We built a multinomial Lasso model using 5-fold cross-validation to tune the penalty parameter. Lasso forced some features to be dropped from the model, which reduces the risk of overfitting and increases the interpretability of the results. For each category, important variables are different. Certain brands drive market share, as do PPO plans and prescription drug coverage. Benefits, particularly ancillary benefits that are not part of CMS's required benefits, appear to have little influence, while financial terms such as deductibles, copays, and out-of-pocket limits are associated with higher market share. Finally, we evaluated the predictive accuracy of the Lasso model with the test set. The accuracy is 0.76.

</details>


### [65] [Generative Agents and Expectations: Do LLMs Align with Heterogeneous Agent Models?](https://arxiv.org/abs/2511.08604)
*Filippo Gusella,Eugenio Vicario*

Main category: econ.GN

TL;DR: 使用大型语言模型构建生成式代理来模拟金融市场中基本面分析者和趋势跟随者的策略选择概率，并与传统异质代理模型结果进行比较。


<details>
  <summary>Details</summary>
Motivation: 传统HAM文献中基本面分析者和趋势跟随者的比例随时期变化，需要验证AI代理能否产生类似的策略选择概率。

Method: 使用LLM构建生成式代理，基于当前信息决定采用两种策略的概率，并与1990-2020年S&P 500指数的HAM文献结果进行比较，同时在人工市场数据中扩展分析。

Result: AI代理的期望与HAM文献报告的结果一致，在人工市场中确认了期望异质性，但显示出向基本面分析行为的系统性不对称。

Conclusion: LLM构建的生成式代理能够有效模拟金融市场参与者的策略选择行为，验证了HAM模型的合理性，同时揭示了AI决策过程中的系统性偏好。

Abstract: Results in the Heterogeneous Agent Model (HAM) literature determine the proportion of fundamentalists and trend followers in the financial market. This proportion varies according to the periods analyzed. In this paper, we use a large language model (LLM) to construct a generative agent (GA) that determines the probability of adopting one of the two strategies based on current information. The probabilities of strategy adoption are compared with those in the HAM literature for the S\&P 500 index between 1990 and 2020. Our findings suggest that the resulting artificial intelligence (AI) expectations align with those reported in the HAM literature. At the same time, extending the analysis to artificial market data helps us to filter the decision-making process of the AI agent. In the artificial market, results confirm the heterogeneity in expectations but reveal systematic asymmetry toward the fundamentalist behavior.

</details>


### [66] [The effects of International Monetary Fund programs: a systematic review with narrative synthesis on poverty, inequality, and social indicators](https://arxiv.org/abs/2511.08617)
*Ricardo Alonzo Fernández Salguero*

Main category: econ.GN

TL;DR: IMF项目的社会影响系统综述：使用准实验设计的研究显示，IMF条件性会加剧收入不平等、恶化健康状况并促进非正规经济发展，而少数使用倾向得分匹配等偏高风险方法的研究未发现系统性负面社会影响。


<details>
  <summary>Details</summary>
Motivation: 系统评估国际货币基金组织（IMF）项目的社会影响，特别关注研究方法的质量和对内生性、选择偏倚等问题的处理，以提供更可靠的证据基础。

Method: 采用PRISMA指南进行系统综述和叙述性综合，检索5个学术数据库和灰色文献，纳入53项符合预定义标准的实证研究，评估每项研究的偏倚风险。

Result: 大多数使用更强准实验设计（特别是工具变量策略）的研究发现IMF条件性与更高的收入不平等、更差的健康结果（尤其是结核病和儿童死亡率）以及非正规经济增长相关。少数使用偏高风险方法的研究未发现系统性负面社会影响。

Conclusion: 现有最佳证据表明IMF项目（特别是以财政紧缩和结构改革为中心的项目）会造成显著社会成本，需要重新设计条件性以保护社会支出并推进可持续发展目标。

Abstract: This systematic review with narrative synthesis examines the social impacts of International Monetary Fund (IMF) programs. We systematically searched five academic databases and grey literature following PRISMA guidelines and included 53 empirical studies that met predefined eligibility criteria. For each study we assessed risk of bias, with particular attention to how endogeneity, selection bias, and confounding were handled. Because of substantial heterogeneity in outcomes and research designs, results were synthesized narratively rather than through meta analysis. We find that a minority of studies, often using methods with higher risk of bias such as propensity score matching, report no systematic adverse social effects. By contrast, a large body of work using stronger quasi experimental designs, especially instrumental variable strategies, links IMF conditionality to higher income inequality, worse health outcomes (notably tuberculosis and child mortality), and growth of the informal economy. Overall, the best available evidence indicates that IMF programs, particularly those centered on fiscal austerity and structural reforms, impose significant social costs and that a redesign of conditionality is needed to protect social spending and advance the Sustainable Development Goals.

</details>


### [67] [Pattern Recognition of Scrap Plastic Misclassification in Global Trade Data](https://arxiv.org/abs/2511.08638)
*Muhammad Sukri Bin Ramli*

Main category: econ.GN

TL;DR: 提出可解释机器学习框架检测贸易数据异常，发现价格与成交量反向变化模式，准确率达93.75%，为海关提供透明数据驱动方法支持环境政策。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以检测贸易数据差异，需要开发可解释的机器学习工具来识别异常模式，支持海关从传统检查转向基于优先级的检查协议。

Method: 分析贸易数据寻找新型的反向价格-成交量特征模式，即报告成交量增加而平均单价下降的模式，通过比较联合国大规模数据与企业级详细数据进行验证。

Result: 模型准确率达到0.9375，风险特征在大规模UN数据与企业级数据对比中得到确认，证明风险特征的一致性。

Conclusion: 该可扩展工具为海关当局提供透明、数据驱动的方法，将复杂数据转化为可操作情报，支持国际环境政策的实施。

Abstract: We propose an interpretable machine learning framework to help identify trade data discrepancies that are challenging to detect with traditional methods. Our system analyzes trade data to find a novel inverse price-volume signature, a pattern where reported volumes increase as average unit prices decrease.
  The model achieves 0.9375 accuracy and was validated by comparing large-scale UN data with detailed firm-level data, confirming that the risk signatures are consistent. This scalable tool provides customs authorities with a transparent, data-driven method to shift from conventional to priority-based inspection protocols, translating complex data into actionable intelligence to support international environmental policies.

</details>


### [68] [A Risk-Based Equilibrium Analysis of Energy Imbalance Reserve in Day-Ahead Electricity Markets](https://arxiv.org/abs/2511.08736)
*Ryan Ent,Golbon Zakeri,Jinye Zhao,Tongxin Zheng*

Main category: econ.GN

TL;DR: 分析了新英格兰ISO引入的能源不平衡储备(EIR)产品，这是一种以实时能源价格结算的新型实物期权产品，研究发现风险中性环境下EIR影响不大，但在风险规避环境下能促进提前燃料采购。


<details>
  <summary>Details</summary>
Motivation: EIR是一种新型的实物期权产品，以实时能源价格而非储备价格结算，目前研究文献尚未分析其影响效果。

Method: 开发了一个包含发电商和需求方风险偏好的随机长期均衡模型，涵盖日前和实时市场的能源与储备市场参与。

Result: 风险中性环境下EIR产品对市场结果影响不大；在风险规避的发电商和需求方环境下，引入EIR产品后观察到提前燃料采购增加。

Conclusion: EIR产品在风险规避环境下能有效激励发电资源进行更好的燃料采购规划，为电力市场提供了新的风险管理工具。

Abstract: Energy imbalance reserve (EIR) product is introduced into the Independent System Operator (ISO) of New England's day-ahead wholesale electricity market to provide a better fuel procurement incentive for generating resources. Different from existing forward reserve products, EIR is a novel real option product, which is settled against real-time energy price rather than reserve prices. This novel product has not been analyzed in the research literature in terms of its effects. In this paper, we develop a stochastic long-run equilibrium model that incorporates the risk preference of generator and demand agents participating in the energy and reserve market in both day-ahead and real-time time frame. In a risk neutral environment, we find that the presence of the EIR product makes little difference on market outcomes. We also conduct a series of numerical simulations with risk-averse generators and demand, and observed increased advanced fuel procurement when the EIR product is present.

</details>


### [69] [Making Talk Cheap: Generative AI and Labor Market Signaling](https://arxiv.org/abs/2511.08785)
*Anais Galdin,Jesse Silbert*

Main category: econ.GN

TL;DR: 研究大型语言模型（LLMs）如何通过降低写作成本，破坏传统依赖写作作为质量信号的市场（如求职申请、大学论文），并量化其对劳动力市场均衡结果的影响。


<details>
  <summary>Details</summary>
Motivation: LLMs大幅降低了写作成本，这可能破坏传统依赖写作作为质量信号的市场机制，特别是在劳动力市场中，求职申请作为能力信号的作用可能被削弱。

Method: 使用Freelancer.com数据，开发基于LLM的指标量化申请信与职位匹配程度，并构建结构模型模拟LLMs破坏信号机制后的均衡结果。

Result: 雇主在LLMs引入前愿意为定制化申请支付高价，但引入后不再如此。模拟显示，没有成本信号机制时，雇主难以识别高能力工作者，市场变得不公正：能力前20%工作者被雇佣率下降19%，后20%上升14%。

Conclusion: LLMs通过降低写作成本破坏了劳动力市场的信号机制，导致市场效率下降和分配不公，高能力工作者更难被识别和雇佣。

Abstract: Large language models (LLMs) like ChatGPT have significantly lowered the cost of producing written content. This paper studies how LLMs, through lowering writing costs, disrupt markets that traditionally relied on writing as a costly signal of quality (e.g., job applications, college essays). Using data from Freelancer.com, a major digital labor platform, we explore the effects of LLMs' disruption of labor market signaling on equilibrium market outcomes. We develop a novel LLM-based measure to quantify the extent to which an application is tailored to a given job posting. Taking the measure to the data, we find that employers have a high willingness to pay for workers with more customized applications in the period before LLMs are introduced, but not after. To isolate and quantify the effect of LLMs' disruption of signaling on equilibrium outcomes, we develop and estimate a structural model of labor market signaling, in which workers invest costly effort to produce noisy signals that predict their ability in equilibrium. We use the estimated model to simulate a counterfactual equilibrium in which LLMs render written applications useless in signaling workers' ability. Without costly signaling, employers are less able to identify high-ability workers, causing the market to become significantly less meritocratic: compared to the pre-LLM equilibrium, workers in the top quintile of the ability distribution are hired 19% less often, workers in the bottom quintile are hired 14% more often.

</details>


### [70] [Not-so-Cleansing Recessions](https://arxiv.org/abs/2511.09162)
*Igli Bajo,Frederik H. Bennhoff,Alessandro Ferrari*

Main category: econ.GN

TL;DR: 本文研究了经济衰退的长期福利效应，分析了企业退出带来的生产率提升与品种减少之间的权衡关系，发现如果经济具有比CES更强的品种偏好，衰退的长期效应是负面的。


<details>
  <summary>Details</summary>
Motivation: 研究经济衰退对长期福利的影响，探讨企业退出带来的生产率提升（净化效应）与品种减少之间的权衡关系。

Method: 使用模型和需求的外生变化来估计品种偏好，分析不同聚合函数下的福利效应，并定量描述最优政策响应。

Result: 研究发现品种偏好显著高于CES聚合所隐含的水平，表明即使从长期来看，衰退的影响也是负面的。

Conclusion: 经济衰退的长期福利效应取决于品种偏好和替代弹性，当经济具有比CES更强的品种偏好时，衰退的长期效应是负面的，最优政策应在衰退期间补贴经济活动以避免企业退出。

Abstract: Recessions are periods in which the least productive firms in the economy exit, and as the economy recovers, they are replaced by new and more productive entrants. These cleansing effects improve the average firm productivity. At the same time, recessions induce a loss of varieties. We show that the long-run welfare effects trade off these two forces. This trade-off is governed by love-of-variety and the elasticity of substitution in aggregate production. If industry output is aggregated with the standard CES aggregator, recessions do not bring about any improvement in GDP and welfare. If the economy features more love-of-variety than CES, the social planner optimally subsidizes economic activity both in steady state and even more so in recessions to avoid firm exit. We use the model and quasi-exogenous variation in demand to estimate love-of-variety. We find it to be significantly higher than implied by CES aggregation, suggesting that even the long-run effects of recessions are negative. Finally, we quantitatively characterize the optimal policy response both along the transition and in the steady state.

</details>


### [71] [Self-Selection, University Courses and Returns to Advanced Degrees](https://arxiv.org/abs/2511.09260)
*Eleonora Brandimarti*

Main category: econ.GN

TL;DR: 研究意大利毕业生学位组合对劳动力市场回报的影响，发现学士和硕士学位的组合选择对经济结果有显著影响，跨学科组合表现更好，而定量课程本身不能解释更高回报。


<details>
  <summary>Details</summary>
Motivation: 高等教育需要选择学士和硕士学位，但这些组合选择的回报以及不同学科课程的作用尚未得到充分研究。

Method: 使用意大利毕业生和大学项目的详细数据，利用入学要求的外生变化来因果估计43种学位组合的回报，通过政策模拟分析偏好特征，并将估计回报与学位课程特征相关联。

Result: 学位组合的回报存在显著差异，即使是同一学士学位的不同组合；跨学科组合对经济结果有积极影响，而同领域组合表现较差；成功的组合在学士阶段包含更多非定量教育。

Conclusion: 需要考虑学士和硕士两种学位类型，跨学科组合表现更好，定量课程本身不能解释更高回报，课程设置的时间安排和内容结构对劳动力市场结果有重要影响。

Abstract: Higher education often requires choosing a bachelor's and a master's degree, yet the returns of these combined choices and the role of courses in different disciplines remain understudied. This paper addresses this gap using detailed data on Italian graduates and university programs. I study the labor market returns to combinations of bachelor's and master's degrees and investigate how curriculum characteristics affect outcomes. I exploit exogenous variation in access to bachelor's and master's degrees to causally estimate the returns to 43 combinations of degrees. I organize the data in a nested model with exogenous variation in admission requirements and explore the preference profile of the sample through policy simulations that shift these requirements. I then relate the estimated returns to the academic curriculum of degrees, focusing on the role of quantitative education and timing of courses. I contribute to the literature on returns to advanced degrees by incorporating master's degrees in the discussion on how higher education affects outcomes and providing evidence on the characteristics of curricula that are positively related to labor market returns. The findings reveal substantial variation in returns to degree combinations, even among combinations with the same bachelor's degree, indicating the need to consider both types of programs. Combinations of degrees in different disciplines positively impact economic outcomes, while those in the same field perform worse. Successful combinations feature more non-quantitative education in the bachelor's, and quantitative courses alone do not explain higher returns.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [72] [Reservoir Computing-Based Detection for Molecular Communications](https://arxiv.org/abs/2511.08762)
*Abdulkadir Bilge,Eren Akyol,Murat Kuscu*

Main category: cs.ET

TL;DR: 提出了一种基于储层计算（RC）的低复杂度分子通信检测器，用于解决移动场景中严重ISI问题，相比传统检测器和复杂ML方法具有更少参数和超低延迟。


<details>
  <summary>Details</summary>
Motivation: 分子通信在移动场景中面临严重ISI，传统模型检测需要准确CSI但难以获取，深度学习虽具适应性但复杂度高，不适合资源受限的微/纳设备。

Method: 使用固定、循环非线性储层将时变接收信号投影到高维状态空间，将复杂时序检测问题转化为简单线性分类任务，无需显式信道建模或复杂重训练。

Result: 在3D移动MC仿真环境中，RC检测器显著优于传统检测器，在严重ISI下性能优于复杂ML方法（LSTM、CNN、MLP），且参数更少（300 vs 264k），推理延迟极低（约1μs/符号）。

Conclusion: RC检测器为移动分子通信提供了一种高效、低复杂度的解决方案，在严重ISI环境下表现出色，适合资源受限设备。

Abstract: Diffusion-based Molecular Communication (MC) is inherently challenged by severe inter-symbol interference (ISI). This is significantly amplified in mobile scenarios, where the channel impulse response (CIR) becomes time-varying and stochastic. Obtaining accurate Channel State Information (CSI) for traditional model-based detection is intractable in such dynamic environments. While deep learning (DL) offers adaptability, its complexity is unsuitable for resource-constrained micro/nanodevices. This paper proposes a low-complexity Reservoir Computing (RC) based detector. The RC architecture utilizes a fixed, recurrent non-linear reservoir to project the time-varying received signal into a high-dimensional state space. This effectively transforms the complex temporal detection problem into a simple linear classification task, capturing ISI dynamics without explicit channel modeling or complex retraining. Evaluated in a realistic 3D mobile MC simulation environment (Smoldyn), our RC detector significantly outperforms classical detectors and achieves superior performance compared to complex ML methods (LSTM, CNN, MLP) under severe ISI. Importantly, RC achieves this with significantly fewer trainable parameters (e.g., 300 vs. up to 264k for MLP) and ultra-low latency inference (approx. 1 $μ$s per symbol).

</details>


### [73] [Modeling Closed-loop Analog Matrix Computing Circuits with Interconnect Resistance](https://arxiv.org/abs/2511.09151)
*Mu Zhou,Junbin Long,Yubiao Luo,Zhong Sun*

Main category: cs.ET

TL;DR: 提出了针对基于RRAM的模拟矩阵计算电路中互连电阻问题的快速求解算法，相比传统SPICE仿真器实现了几个数量级的加速，并开发了基于偏置的补偿策略显著降低互连引起的误差。


<details>
  <summary>Details</summary>
Motivation: 随着矩阵尺寸增大，互连电阻会降低计算精度并限制电路可扩展性，而传统SPICE仿真器由于节点和反馈连接的二次增长，在大规模AMC电路中变得极其缓慢。

Method: 针对矩阵求逆和特征向量计算两种关键操作，提出了利用雅可比矩阵稀疏性的快速求解算法，并将其扩展到开环矩阵向量乘法电路。

Result: 相比SPICE实现了几个数量级的加速，同时保持高精度；开发的偏置补偿策略将互连引起的误差降低了50%以上（矩阵求逆）和70%以上（特征向量计算）。

Conclusion: 提出的快速算法能够高效准确地模拟大规模AMC电路，偏置补偿策略有效缓解了互连电阻问题，并揭示了最优偏置随矩阵尺寸和互连电阻的缩放规律。

Abstract: Analog matrix computing (AMC) circuits based on resistive random-access memory (RRAM) have shown strong potential for accelerating matrix operations. However, as matrix size grows, interconnect resistance increasingly degrades computational accuracy and limits circuit scalability. Modeling and evaluating these effects are therefore critical for developing effective mitigation strategies. Traditional SPICE (Simulation Program with Integrated Circuit Emphasis) simulators, which rely on modified nodal analysis, become prohibitively slow for large-scale AMC circuits due to the quadratic growth of nodes and feedback connections. In this work, we model AMC circuits with interconnect resistance for two key operations-matrix inversion (INV) and eigenvector computation (EGV), and propose fast solving algorithms tailored for each case. The algorithms exploit the sparsity of the Jacobian matrix, enabling rapid and accurate solutions. Compared to SPICE, they achieve several orders of magnitude acceleration while maintaining high accuracy. We further extend the approach to open-loop matrix-vector multiplication (MVM) circuits, demonstrating similar efficiency gains. Finally, leveraging these fast solvers, we develop a bias-based compensation strategy that reduces interconnect-induced errors by over 50% for INV and 70% for EGV circuits. It also reveals the scaling behavior of the optimal bias with respect to matrix size and interconnect resistance.

</details>


### [74] [RIoT Digital Twin: Modeling, Deployment, and Optimization of Reconfigurable IoT System with Optical-Radio Wireless Integration](https://arxiv.org/abs/2511.09303)
*Alaa Awad Abdellatif,Sergio Silva,Eduardo Baltazar,Bruno Oliveira,Senhui Qiu,Mohammud J. Bocus,Kerstin Eder,Robert J. Piechocki,Nuno T. Almeida,Helder Fontes*

Main category: cs.ET

TL;DR: 提出优化的可重构物联网(RIoT)框架，集成光无线和射频技术，通过数字孪生和跨层优化策略提升6G物联网网络的能效、可扩展性和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决混合光-射频环境的复杂性，提升物联网网络的能效、可扩展性和适应性，为6G物联网网络提供更可持续的解决方案。

Method: 在NS-3平台开发高保真数字孪生，建模RIoT架构子系统；采用主动跨层优化策略，动态调整传输速率、唤醒/睡眠调度和接入技术选择；结合实时能量测量确保物理行为准确性。

Result: 所提框架显著提升了6G物联网网络的性能、弹性和可持续性，通过数字孪生技术、混合光-射频集成和数据驱动的能量建模实现了实质性改进。

Conclusion: 结合数字孪生、混合光-射频集成和数据驱动能量建模的优化RIoT框架，为6G物联网网络提供了增强性能、弹性和可持续性的有效解决方案。

Abstract: This paper proposes an optimized Reconfigurable Internet of Things (RIoT) framework that integrates optical and radio wireless technologies with a focus on energy efficiency, scalability, and adaptability. To address the inherent complexity of hybrid optical-radio environments, a high-fidelity Digital Twin (DT) is developed within the Network Simulator 3 (NS-3) platform. The DT models deploy subsystems of the RIoT architecture, including radio frequency (RF) communication, optical wireless communication (OWC), and energy harvesting and consumption mechanisms that enable autonomous operation. Real-time energy and power measurements from target hardware platforms are also incorporated to ensure accurate representation of physical behavior and enable runtime analysis and optimization. Building on this foundation, a proactive cross-layer optimization strategy is devised to balance energy efficiency and quality of service (QoS). The strategy dynamically reconfigures RIoT nodes by adapting transmission rates, wake/sleep scheduling, and access technology selection. Results demonstrate that the proposed framework, combining digital twin technology, hybrid optical-radio integration, and data-driven energy modeling, substantially enhances the performance, resilience, and sustainability of 6G IoT networks.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [75] [MoE-GraphSAGE-Based Integrated Evaluation of Transient Rotor Angle and Voltage Stability in Power Systems](https://arxiv.org/abs/2511.08610)
*Kunyu Zhang,Guang Yang,Fashun Shi,Shaoying He,Yuchi Zhang*

Main category: eess.SY

TL;DR: 提出MoE-GraphSAGE图神经网络框架，用于统一暂态角稳定性和暂态电压稳定性评估，在复杂电力系统中实现高精度高效的在线多任务评估。


<details>
  <summary>Details</summary>
Motivation: 可再生能源和电力电子设备的大规模集成增加了电力系统稳定性复杂性，传统方法在精度和计算效率方面存在局限。

Method: 使用GraphSAGE捕捉电网时空拓扑特征，采用多专家网络和门控机制联合建模不同失稳模式。

Result: 在IEEE 39节点系统上的实验结果表明，MoE-GraphSAGE实现了优越的精度和效率。

Conclusion: 该框架为复杂电力系统中的在线多任务暂态稳定评估提供了有效解决方案。

Abstract: The large-scale integration of renewable energy and power electronic devices has increased the complexity of power system stability, making transient stability assessment more challenging. Conventional methods are limited in both accuracy and computational efficiency. To address these challenges, this paper proposes MoE-GraphSAGE, a graph neural network framework based on the MoE for unified TAS and TVS assessment. The framework leverages GraphSAGE to capture the power grid's spatiotemporal topological features and employs multi-expert networks with a gating mechanism to model distinct instability modes jointly. Experimental results on the IEEE 39-bus system demonstrate that MoE-GraphSAGE achieves superior accuracy and efficiency, offering an effective solution for online multi-task transient stability assessment in complex power systems.

</details>


### [76] [Learning based Modelling of Throttleable Engine Dynamics for Lunar Landing Mission](https://arxiv.org/abs/2511.08612)
*Suraj Kumar,Aditya Rallapalli,Bharat Kumar GVP*

Main category: eess.SY

TL;DR: 提出基于学习的系统辨识方法，用于建模月球着陆任务中的可调节发动机动力学，使用高保真推进模型数据进行训练，并通过实验验证和闭环制导控制仿真。


<details>
  <summary>Details</summary>
Motivation: 月球着陆任务涉及多阶段制动以实现软着陆，推进系统配置包含可调节发动机，涉及复杂的非线性动态特性，准确建模推进动力学对分析闭环制导控制方案至关重要。

Method: 采用基于学习的系统辨识方法，利用高保真推进模型获取的数据来建模可调节发动机动力学。

Result: 开发的模型通过实验结果验证，并成功应用于闭环制导控制仿真。

Conclusion: 学习型系统辨识方法能够有效建模复杂推进系统动力学，为月球着陆任务的制导控制分析提供可靠工具。

Abstract: Typical lunar landing missions involve multiple phases of braking to achieve soft-landing. The propulsion system configuration for these missions consists of throttleable engines. This configuration involves complex interconnected hydraulic, mechanical, and pneumatic components each exhibiting non-linear dynamic characteristics. Accurate modelling of the propulsion dynamics is essential for analyzing closed-loop guidance and control schemes during descent. This paper presents a learning-based system identification approach for modelling of throttleable engine dynamics using data obtained from high-fidelity propulsion model. The developed model is validated with experimental results and used for closed-loop guidance and control simulations.

</details>


### [77] [Energy-Workload Coupled Migration Optimization Strategy for Virtual Power Plants with Data Centers Considering Fuzzy Chance Constraints](https://arxiv.org/abs/2511.08619)
*Jia-Kai Wu,Zhi-Wei Liu,Yong Zhao,Yan-Wu Wang,Fan-Rong Qu,Chaojie Li*

Main category: eess.SY

TL;DR: 提出了一种虚拟电厂与数据中心耦合迁移优化策略，通过博弈框架和模糊机会约束处理，提升需求响应曲线跟踪精度并降低运营成本。


<details>
  <summary>Details</summary>
Motivation: 解决虚拟电厂与数据中心协同调度中的资源分配问题，克服数据中心工作负载数据稀疏性对传统概率建模的挑战，实现精确的需求响应曲线跟踪。

Method: 建立基于反对称矩阵的博弈耦合迁移框架，采用模糊集理论进行确定性等价变换，提出改进的Shapley值利润分配方法，并使用交替方向乘子法求解高维非凸优化问题。

Result: 基于谷歌多个数据中心的真实数据仿真表明，该方法能有效提高需求响应曲线跟踪精度并降低运营成本。

Conclusion: 所提出的能量-工作负载耦合迁移优化策略能够有效协调跨区域资源分配，在保证理论公平性的同时实现计算可行性，为虚拟电厂与数据中心的协同运营提供了有效解决方案。

Abstract: This paper proposes an energy-workload coupled migration optimization strategy for virtual power plants (VPPs) with data centers (DCs) to enhance resource scheduling flexibility and achieve precise demand response (DR) curve tracking. A game-based coupled migration framework characterized by antisymmetric matrices is first established to facilitate the coordination of cross-regional resource allocation between VPPs. To address the challenge posed to conventional probabilistic modeling by the inherent data sparsity of DC workloads, deterministic equivalent transformations of fuzzy chance constraints are derived based on fuzzy set theory, and non-convex stochastic problems are transformed into a solvable second-order cone program. To address the multi-player interest coordination problem in cooperative games, an improved Shapley value profit allocation method with the VPP operator as intermediary is proposed to achieve a balance between theoretical fairness and computational feasibility. In addition, the alternating direction method of multipliers with consensus-based variable splitting is introduced to solve the high-dimensional non-convex optimization problem, transforming coupled antisymmetric constraints into separable subproblems with analytical solutions. Simulations based on real data from Google's multiple DCs demonstrate the effectiveness of the proposed method in improving DR curve tracking precision and reducing operational costs.

</details>


### [78] [Dynamic Modeling and Control of Phosphate-Pebble Drying Systems -- A Comprehensive Approach](https://arxiv.org/abs/2511.08623)
*Jose M. Campos-Salazar,Felipe Santander,Eduardo Keim*

Main category: eess.SY

TL;DR: 本文提出了磷酸盐球团旋转干燥过程的非线性动态模型，基于第一性原理构建，用于解决该多变量非线性系统的建模和控制挑战。


<details>
  <summary>Details</summary>
Motivation: 磷酸盐干燥器在矿石处理中起关键作用，但由于系统的非线性多变量特性，精确建模和控制仍是工业难题。

Method: 基于第一性原理构建综合非线性动态模型，捕捉耦合的热质传递、蒸发动力学和子系统相互作用。

Result: 开发了能够准确描述磷酸盐球团旋转干燥过程的动态模型。

Conclusion: 该模型为解决磷酸盐干燥过程的工业控制挑战提供了理论基础。

Abstract: Dryers play a central role in the processing of phosphate rock, where moisture removal is essential for downstream handling and energy efficiency. Due to the inherently nonlinear and multivariable nature of these systems, accurate modeling and control remain industrial challenges. This article presents a comprehensive nonlinear dynamic model of a phosphate-pebble rotary drying process, built from first principles to capture coupled heat and mass transfer, evaporation kinetics, and subsystem interactions.

</details>


### [79] [Recursive Binary Identification under Data Tampering and Non-Persistent Excitation with Application to Emission Control](https://arxiv.org/abs/2511.08629)
*Jian Guo,Lihong Pei,Wenchao Xue,Yanlong Zhao,Ji-Feng Zhang*

Main category: eess.SY

TL;DR: 本文提出了针对二进制输出网络物理系统的在线参数估计方法，包括一阶梯度算法和二阶拟牛顿算法，能够处理已知和未知的数据篡改攻击，并证明了参数估计的几乎必然收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要是离线的，不适合实时学习，且持续激励条件在反馈控制场景中难以满足。需要开发能够在数据篡改情况下进行在线参数估计的鲁棒算法。

Method: 开发了一阶梯度算法和二阶拟牛顿算法，分别处理已知和未知的数据篡改策略。二阶算法不需要持续激励条件，并扩展到自适应控制框架中。

Result: 两种算法的参数估计都被证明几乎必然收敛。二阶算法在匹配经典最小二乘估计所需最小激励的信号条件下确保收敛。数值仿真验证了方法的有效性，并在车辆排放控制问题中提高了过量排放事件的检测精度。

Conclusion: 提出的在线参数估计方法对数据篡改具有鲁棒性，能够有效应用于网络物理系统的实时学习和控制问题。

Abstract: This paper studies the problem of online parameter estimation for cyber-physical systems with binary outputs that may be subject to adversarial data tampering. Existing methods are primarily offline and unsuitable for real-time learning. To address this issue, we first develop a first-order gradient-based algorithm that updates parameter estimates recursively using incoming data. Considering that persistent excitation (PE) conditions are difficult to satisfy in feedback control scenarios, a second-order quasi-Newton algorithm is proposed to achieve faster convergence without requiring the PE condition. For both algorithms, corresponding versions are developed to handle known and unknown tampering strategies, and their parameter estimates are proven to converge almost surely over time. In particular, the second-order algorithm ensures convergence under a signal condition that matches the minimal excitation required by classical least-squares estimation in stochastic regression models. The second-order algorithm is also extended to an adaptive control framework, providing an explicit upper bound on the tracking error for binary-output FIR systems under unknown tampering. Three numerical simulations verify the theoretical results and show that the proposed methods are robust against data tampering. Finally, the approach is validated via a vehicle emission control problem, where it effectively improves the detection accuracy of excess-emission events.

</details>


### [80] [Bus Type Switching to Reduce Bound Violations in AC Power Flow](https://arxiv.org/abs/2511.08643)
*Anna Van Boven,Kyri Baker*

Main category: eess.SY

TL;DR: 提出一种增强的交流潮流计算方法，通过引入两种新的母线类型(PQV和P)来解决传统方法中的电压边界违规问题，在发电机和负荷母线之间重新分配自由度以寻找可行的电力系统设定点。


<details>
  <summary>Details</summary>
Motivation: 批发电力市场通常使用电力系统约束的线性近似，但交流潮流可行性后处理不考虑不等式约束，可能导致无功功率、电压幅值或热极限的边界违规，需要一种能保证交流可行性并遵守变量边界的分析方法。

Method: 提出增强的交流潮流实现方法，使用额外的两种母线类型(PQV和P)，通过牺牲发电机的电压设定点来修复负荷母线的电压，从而在网络中重新分配自由度。

Result: 在IEEE 14母线、57母线和300母线测试案例上的结果表明，切换母线类型可以减少整体网络违规，帮助找到可行的电力系统设定点。

Conclusion: 所提出的增强交流潮流方法通过重新分配网络自由度，能够有效解决电压边界违规问题，为电力系统提供可行的运行设定点。

Abstract: Wholesale power markets often use linear approximations of power system constraints. Because it does not consider inequality constraints, using AC power flow for feasibility post-processing can violate bounds on reactive power, voltage magnitudes, or thermal limits. There remains a need for a streamlined analytical approach that can guarantee AC feasibility while adhering to variable bounds. This paper suggests an augmented implementation of AC power flow that uses an additional two bus types (PQV and P) to help resolve voltage bound violations present in the traditional approach. The proposed method sacrifices the voltage setpoint at a generator in exchange for fixing the voltage at a load bus, thereby moving a degree of freedom around the network. Results on the IEEE 14-bus, 57-bus, and 300-bus test cases demonstrate how switching bus types can reduce overall network violations and help find feasible power system setpoints.

</details>


### [81] [Data-driven Control of Hypergraphs: Leveraging THIS to Damp Noise in Diffusive Hypergraphs](https://arxiv.org/abs/2511.08647)
*Robin Delabays,Yuanzhao Zhang,Florian Dörfler,Giulia De Pasquale*

Main category: eess.SY

TL;DR: 提出了一种基于超图推断的系统辨识与控制框架，通过推断多体耦合结构来设计简约控制器，指导系统达到期望配置。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统存在高阶相互作用，无法用简单图表示，且代理间的相互作用方式通常未知，需要从部分观测中推断。

Method: 结合超图表示和超图推断算法THIS推断多体耦合结构，基于推断结构设计简约控制器，使用最小可控节点集引导系统。

Result: 在超图上的Kuramoto振荡器网络上验证了所提出的系统辨识与控制框架。

Conclusion: 该框架成功实现了从部分观测推断系统结构并设计有效控制策略的闭环过程。

Abstract: Controllability determines whether a system's state can be guided toward any desired configuration, making it a fundamental prerequisite for designing effective control strategies. In the context of networked systems, controllability is a well-established concept. However, many real-world systems, from biological collectives to engineered infrastructures, exhibit higher-order interactions that cannot be captured by simple graphs. Moreover, the way in which agents interact and influence one another is often unknown and must be inferred from partial observations of the system. Here, we close the loop between a hypergraph representation and our recently developed hypergraph inference algorithm, THIS, to infer the underlying multibody couplings. Building on the inferred structure, we design a parsimonious controller that, given a minimal set of controllable nodes, steers the system toward a desired configuration. We validate the proposed system identification and control framework on a network of Kuramoto oscillators evolving over a hypergraph.

</details>


### [82] [Hierarchical Strategic Decision-Making in Layered Mobility Systems](https://arxiv.org/abs/2511.08734)
*Mingjia He,Zhiyu He,Jan Ghadamian,Florian Dörfler,Emilio Frazzoli,Gioele Zardini*

Main category: eess.SY

TL;DR: 该论文提出了一种将分层博弈论建模与在线反馈优化相结合的方法，将城市交通系统建模为三层Stackelberg博弈（出行者、运营商、市政当局），通过反馈循环进行优化控制。


<details>
  <summary>Details</summary>
Motivation: 交通系统是复杂的社会技术环境，受多个利益相关者的分层决策影响，使得有效控制和政策设计具有挑战性。需要一种能够处理这种复杂性的方法。

Method: 使用三层Stackelberg博弈模型，市政当局通过投影两点（无梯度）方案迭代更新税收、补贴和运营约束，下层通过均衡计算（Frank-Wolfe算法计算出行者均衡；运营商最佳响应）进行响应。

Result: 在苏黎世真实多模式网络上，该方法比贝叶斯优化和遗传算法获得更好的市政目标，识别出能够增加多模式使用并改善运营商目标的整合激励措施。

Conclusion: 基于反馈的监管可以将竞争引导向合作结果，在复杂、数据丰富的交通生态系统中实现切实的福利收益。

Abstract: Mobility systems are complex socio-technical environments influenced by multiple stakeholders with hierarchically interdependent decisions, rendering effective control and policy design inherently challenging. We bridge hierarchical game-theoretic modeling with online feedback optimization by casting urban mobility as a tri-level Stackelberg game (travelers, operators, municipality) closed in a feedback loop. The municipality iteratively updates taxes, subsidies, and operational constraints using a projected two-point (gradient-free) scheme, while lower levels respond through equilibrium computations (Frank-Wolfe for traveler equilibrium; operator best responses). This model-free pipeline enforces constraints, accommodates heterogeneous users and modes, and scales to higher-dimensional policy vectors without differentiating through equilibrium maps.
  On a real multimodal network for Zurich, Switzerland, our method attains substantially better municipal objectives than Bayesian optimization and Genetic algorithms, and identifies integration incentives that increase multimodal usage while improving both operator objectives. The results show that feedback-based regulation can steer competition toward cooperative outcomes and deliver tangible welfare gains in complex, data-rich mobility ecosystems.

</details>


### [83] [ADMM Penalty Parameter Evaluation for Networked Microgrid Energy Management](https://arxiv.org/abs/2511.08750)
*Jesus Silva-Rodriguez,Xingpeng Li*

Main category: eess.SY

TL;DR: 本文评估了三种不同的ADMM公式来解决网络微电网能源管理问题，重点关注如何确定合适的停止点以获得高质量解。研究发现基于目标的OB-ADMM方法对惩罚参数ρ的选择更鲁棒，能产生更接近集中式最优解的解决方案。


<details>
  <summary>Details</summary>
Motivation: ADMM算法在解决去中心化优化问题时性能高度依赖于惩罚参数ρ的选择，不当的参数会导致收敛缓慢、次优解甚至算法发散。

Method: 比较了三种不同的ADMM公式，并融入了自适应惩罚启发式方法，在不同规模的网络案例研究中进行分析。

Result: 基于目标的OB-ADMM方法对惩罚参数ρ的选择显著更鲁棒，能持续产生更接近集中式最优基准的解决方案，防止算法过早停止。

Conclusion: OB-ADMM方法在解决网络微电网能源管理问题时表现出更好的鲁棒性和解质量，是更可靠的ADMM变体。

Abstract: The alternating direction method of multipliers (ADMM) is a powerful algorithm for solving decentralized optimization problems including networked microgrid energy management (NetMEM). However, its performance is highly sensitive to the selection of its penalty parameter \r{ho}, which can lead to slow convergence, suboptimal solutions, or even algorithm divergence. This paper evaluates and compares three district ADMM formulations to solve the NetMEM problem, which explore different methods to determine appropriate stopping points, aiming to yield high-quality solutions. Furthermore, an adaptive penalty heuristic is also incorporated into each method to analyze its potential impact on ADMM performance. Different case studies on networks of varying sizes demonstrate that an objective-based ADMM approach, denominated as OB-ADMM, is significantly more robust to the choice of \r{ho}, consistently yielding solutions closer to the centralized optimal benchmark by preventing premature algorithm stopping.

</details>


### [84] [Information-Driven Fault Detection and Identification for Multi-Agent Spacecraft Systems: Collaborative On-Orbit Inspection Mission](https://arxiv.org/abs/2511.08752)
*Akshita Gupta,Arna Bhardwaj,Yashwanth Kumar Nakka,Changrak Choi,Amir Rahmani*

Main category: eess.SY

TL;DR: 提出了一个用于多航天器系统的全局到局部、任务感知的故障检测与识别框架，通过信息驱动的成本函数将制导、控制和故障检测识别统一起来。


<details>
  <summary>Details</summary>
Motivation: 多航天器在低地球轨道执行协同检查任务时，需要可靠的故障检测与识别机制来确保任务成功，传统方法往往将制导、控制和故障检测分离处理。

Method: 使用全局信息驱动的成本函数整合传感器模型、航天器姿态和任务级信息增益目标，通过比较预期和观测的任务指标进行故障检测，利用高阶成本梯度度量识别传感器、执行器和状态估计器的故障。

Result: 仿真结果表明，在代表性多航天器检查场景下，该方法能够在不确定性条件下可靠地进行故障定位和分类。

Conclusion: 该框架为弹性自主检查架构提供了统一的信息驱动基础，将任务级目标与故障检测识别紧密结合。

Abstract: This work presents a global-to-local, task-aware fault detection and identification (FDI) framework for multi-spacecraft systems conducting collaborative inspection missions in low Earth orbit. The inspection task is represented by a global information-driven cost functional that integrates the sensor model, spacecraft poses, and mission-level information-gain objectives. This formulation links guidance, control, and FDI by using the same cost function to drive both global task allocation and local sensing or motion decisions. Fault detection is achieved through comparisons between expected and observed task metrics, while higher-order cost-gradient measures enable the identification of faults among sensors, actuators, and state estimators. An adaptive thresholding mechanism captures the time-varying inspection geometry and dynamic mission conditions. Simulation results for representative multi-spacecraft inspection scenarios demonstrate the reliability of fault localization and classification under uncertainty, providing a unified, information-driven foundation for resilient autonomous inspection architectures.

</details>


### [85] [Grid Operational Benefit Analysis of Data Center Spatial Flexibility: Congestion Relief, Renewable Energy Curtailment Reduction, and Cost Saving](https://arxiv.org/abs/2511.08759)
*Haoxiang Wan,Linhan Fang,Xingpeng Li*

Main category: eess.SY

TL;DR: 数据中心的时空灵活性可作为电网资源，通过地理迁移计算负载来缓解输电拥堵、减少太阳能弃光，并推迟输电升级需求。


<details>
  <summary>Details</summary>
Motivation: 人工智能快速发展导致数据中心电力需求激增，给电网带来拥堵和可靠性挑战，同时太阳能和风能的间歇性需要灵活资源来维持电网稳定。

Method: 开发最优潮流模型，协同优化发电调度、安全备用和灵活数据中心负载，并在改进的IEEE 73节点系统上进行案例研究。

Result: 不灵活的数据中心布局导致输电违规严重（线路过载达30.1%），时空灵活性可消除这些违规并恢复系统可行性，同时将太阳能弃光减少高达61.0%。

Conclusion: 数据中心时空灵活性是推迟输电升级和提升可再生能源利用率的可行方法。

Abstract: Data centers are facilities housing computing infrastructure for processing and storing digital information. The rapid expansion of artificial intelligence is driving unprecedented growth in data center capacity, with global electricity demand from data centers projected to double by 2026. This growth creates substantial challenges for power transmission networks, as large concentrated loads can cause congestion and threaten grid reliability. Meanwhile, the intermittent nature of solar and wind generation requires flexible resources to maintain grid reliability and minimize curtailment. This paper assesses whether data center spatial flexibility-the ability to migrate computational workloads geographically-can serve as a grid resource to address these challenges. An optimal power flow model is developed to co-optimize generation dispatch, security reserves, and flexible data center loads. Case studies on a modified IEEE 73-bus system show that inflexible data center placement can lead to severe transmission violations, with line overloads reaching 30.1%. Enabling spatial flexibility mitigates these violations in the studied scenarios and restores system feasibility. This flexibility also reduces solar curtailment by up to 61.0% by strategically reallocating load to solar-rich areas. The results suggest that spatial flexibility offers a viable approach to defer transmission upgrades and enhance renewable utilization.

</details>


### [86] [Discovering and exploiting active sensing motifs for estimation](https://arxiv.org/abs/2511.08766)
*Benjamin Cellini,Burak Boyacioglu,Austin Lopez,Floris van Breugel*

Main category: eess.SY

TL;DR: 提出了BOUNDS方法和pybounds工具包，用于量化非线性系统中传感器运动对状态估计的影响，并开发了AI-KF框架来结合数据驱动和模型驱动的估计方法。


<details>
  <summary>Details</summary>
Motivation: 需要数学严谨的工具来量化传感器运动如何提升非线性系统的估计性能，并利用这些知识改进状态估计，特别是在部分可观测的非线性系统中。

Method: 开发了BOUNDS方法和Python包pybounds，能够发现增强单个状态变量信息的传感器运动模式；提出了AI-KF框架，结合人工神经网络的数据驱动状态和可观测性估计与模型驱动的估计方法。

Result: 通过飞行代理案例研究展示了主动感知如何估计关键变量；在室外四旋翼飞行中验证了AI-KF框架在GPS缺失情况下的高度估计性能。

Conclusion: 该工作有助于解码主动感知策略，并为感觉运动系统中估计算法的设计提供信息。

Abstract: From organisms to machines, autonomous systems rely on measured sensory cues to estimate unknown information about themselves or their environment. For nonlinear systems, carefully selected sensor motion can be exploited to extract information that is otherwise unavailable, i.e. active sensing. Empirical, yet mathematically rigorous, tools are needed to (1) quantify how sensor movement can contribute to estimation performance, and (2) leverage this knowledge to improve state estimates. Here, we introduce "BOUNDS: Bounding Observability for Uncertain Nonlinear Dynamic Systems", and Python package pybounds, which can discover patterns of sensor motion that increase information for individual state variables. Crucially, it is suitable for partially observable nonlinear systems, accounts for sensor noise, and can be applied to either simulated or observed trajectories. We demonstrate BOUNDS through a case study on a flying agent with limited sensors, showing how active sensing can be leveraged to estimate key variables such as ground speed, altitude, and ambient wind direction. Finally, we present a framework to refine sporadic estimates from bouts of active sensing that combines data-driven state and observability estimation from artificial neural networks with model-based estimation, which we call the Augmented Information Kalman Filter (AI-KF). We validate our framework using altitude estimation given GPS-denied data from an outdoor quadcopter flight. Collectively, our work will help decode active sensing strategies and inform the design of estimation algorithms in sensorimotor systems.

</details>


### [87] [Incorporating the nonlinearity index into adaptive-mesh sequential convex optimization for minimum-fuel low-thrust trajectory design](https://arxiv.org/abs/2511.08837)
*Saeid Tafazzol,Ehsan Taheri*

Main category: eess.SY

TL;DR: 提出一种结合非线性指数信任域策略的自适应网格细化方法，用于提高SCP框架下航天器轨迹设计的稳定性。


<details>
  <summary>Details</summary>
Motivation: 直接优化方法中的网格细化是提高解精度的关键步骤，但现有方法在自适应网格细化稳定性方面存在不足，特别是在航天器轨迹设计这类复杂非线性问题中。

Method: 在连续凸规划(SCP)框架中，将自适应网格细化与基于非线性指数的信任域策略相结合，通过策略性分布和放置网格点来提升离散化技术的精度和质量。

Result: 该方法在最小燃料、低推力任务中表现有效，成功解决了地球-小行星交会基准问题和地球-月球L2 Halo轨道转移问题。

Conclusion: 提出的非线性指数信任域策略显著增强了自适应网格细化的稳定性，为航天器轨迹设计提供了一种高效可靠的优化方法。

Abstract: Successive convex programming (SCP) is a powerful class of direct optimization methods, known for its polynomial complexity and computational efficiency, making it particularly suitable for autonomous applications. Direct methods are also referred to as ``discretize-then-optimize'' with discretization being a fundamental solution step. A key step in all practical direct methods is mesh refinement, which aims to refine the solution resolution by enhancing the precision and quality of discretization techniques through strategic distribution and placement of mesh/grid points. We propose a novel method to enhance adaptive mesh refinement stability by integrating it with a nonlinearity-index-based trust-region strategy within the SCP framework for spacecraft trajectory design. The effectiveness of the proposed method is demonstrated through solving minimum-fuel, low-thrust missions, including a benchmark Earth-to-Asteroid rendezvous and an Earth-Moon L2 Halo-to-Halo transfer using the Circular Restricted Three-Body (CR3BP) model.

</details>


### [88] [An Improved Dual-Attention Transformer-LSTM for Small-Sample Prediction of Modal Frequency and Actual Anchor Radius in Micro Hemispherical Resonator Design](https://arxiv.org/abs/2511.08900)
*Yuyi Yao,Gongliu Yang,Runzhuo Xu,Yongqiang Tu,Haozhou Mo*

Main category: eess.SY

TL;DR: 提出了一种基于改进Transformer-LSTM模型的微半球谐振器模态频率和实际锚点半径快速预测方法，显著提高MEMS器件设计效率。


<details>
  <summary>Details</summary>
Motivation: 微半球谐振器设计需要评估多种配置组合，传统有限元仿真耗时极长，需要快速预测方法来解决设计效率问题。

Method: 使用改进的Transformer-LSTM模型，用双多头自注意力机制替换标准前馈网络，通过有限元玻璃吹制仿真获取模态频率和实际锚点半径数据。

Result: 预测准确率达到96.35%，计算时间减少到传统有限元方法的1/48,000，显著提升设计效率。

Conclusion: 该方法为复杂工艺条件下的智能MEMS器件设计提供了新范式，有效支持微半球谐振器的快速设计。

Abstract: The high-temperature glassblowing-fabricated micro hemispherical resonator (MHR) exhibits high symmetry and high Q-value for precision inertial navigation. However, MHR design entails a comprehensive evaluation of multiple possible configurations and demands extremely time-consuming simulation of key parameters combination. To address this problem, this paper proposed a rapid prediction method of modal frequency and actual anchor radius of designed MHR using an improved Transformer-LSTM (Long Short-Term Memory) model for rapid design sizing. High-temperature-induced softening deformation at the anchor point reduces the actual anchor radius below the designed value. By varying key parameters such as resonator height, anchor radius and edge thickness, finite element glassblowing simulation and modal analyse were conducted to obtain the first six modal frequencies and actual anchor radius. To address regression prediction challenges with limited data, dual multi-head self-attention (MHSA) mechanisms replaced the transformer's standard Feed Forward Network, to improve hidden information capture for high-accuracy predictions of modal frequencies and anchor radius. By checking fabricating feasibility of anchor radius and allowing rapid modal characteristics evaluation without interference, ablation and comparative experiments validated the method's superiority, as an effective support of MHR design. Design optimization experiments demonstrate a prediction accuracy of 96.35%, with computational time reduced to 1/48,000 of traditional finite element methods, significantly improving design efficiency. This study offers a new paradigm for intelligent Micro-Electro-Mechanical System (MEMS) device design under complex process conditions.

</details>


### [89] [Validating Warehouse Picking Strategies Using Simulation: Case Study of a Plumbing Equipment Firm](https://arxiv.org/abs/2511.08928)
*Phattara Khumprom,Wanatchapong Kongkaew,Antoun Yaacoub,Nattakit Thanawitsatien*

Main category: eess.SY

TL;DR: 通过仿真分析优化仓库拣选周期时间，使用ABC分析优化存储策略，测试三种存储政策以确定最有效的拣选路线


<details>
  <summary>Details</summary>
Motivation: 在竞争激烈的商业环境中，高效的物流至关重要，特别是在及时交付至关重要的行业。本研究旨在通过基于仿真的分析来改进仓库拣选周期时间

Method: 使用泰国领先的管道设备分销商作为案例研究，采用ABC分析优化存储方法，测试固定、随机和组合（固定区域）三种存储政策，通过区域拣选策略进行仿真

Result: 研究发现了存储混乱和高频物品放置不当等低效问题，通过优化存储布局可以显著提高拣选效率

Conclusion: 研究结果为改进仓库布局和库存放置提供了见解，有助于提升整体性能

Abstract: In today competitive business environment, efficient logistics are essential, especially in industries where timely delivery matters. This research aims to improve warehouse picking cycle time through simulation-based analysis, using a leading plumbing equipment distributor in Thailand as a case study. The study identifies inefficiencies such as disorganized storage and poor placement of high-frequency items that slow down picking. To address this, an optimized storage approach using ABC analysis is proposed, prioritizing high-demand items near the entrance. Three storage policies-Fixed, Random, and Combination (Fixed Zone)-are tested with a Zone Picking strategy through simulation to identify the most efficient picking routes. The findings provide insights for improving warehouse layout and inventory placement to enhance overall performance.

</details>


### [90] [Assumed Density Filtering and Smoothing with Neural Network Surrogate Models](https://arxiv.org/abs/2511.09016)
*Simon Kuang,Xinfan Lin*

Main category: eess.SY

TL;DR: 提出了一种基于深度神经网络高斯输入均值协方差分析公式的非线性系统状态估计方法，在随机Lorenz系统和Wiener系统上验证了其优越性


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统中状态转移和输出函数的不确定性传播问题，特别是针对神经网络模型的状态估计

Method: 使用最新的深度神经网络高斯输入均值协方差分析公式，结合卡尔曼滤波和RTS平滑器进行状态估计

Result: 在随机Lorenz系统和Wiener系统上表现出优越的状态估计性能，能够实现更优的线性二次调节控制

Conclusion: 该方法能够准确传播神经网络模型中的不确定性，在非线性系统状态估计中表现优异，并提升反馈控制性能

Abstract: The Kalman filter and Rauch-Tung-Striebel (RTS) smoother are optimal for state estimation in linear dynamic systems. With nonlinear systems, the challenge consists in how to propagate uncertainty through the state transitions and output function. For the case of a neural network model, we enable accurate uncertainty propagation using a recent state-of-the-art analytic formula for computing the mean and covariance of a deep neural network with Gaussian input. We argue that cross entropy is a more appropriate performance metric than RMSE for evaluating the accuracy of filters and smoothers. We demonstrate the superiority of our method for state estimation on a stochastic Lorenz system and a Wiener system, and find that our method enables more optimal linear quadratic regulation when the state estimate is used for feedback.

</details>


### [91] [RIS-based Communication Enhancement and Location Privacy Protection in UAV Networks](https://arxiv.org/abs/2511.09094)
*Ziqi Chen,Jun Du,Chunxiao Jiang,Tony Q. S. Quek,Zhu Han*

Main category: eess.SY

TL;DR: 提出一种基于主动可重构智能表面(ARIS)的隐蔽通信方案，通过虚拟分区和人工噪声保护无人机位置隐私，在保证合法通信的同时干扰恶意无人机的定位。


<details>
  <summary>Details</summary>
Motivation: 由于无人机通信环境的开放性，恶意无人机可以通过分析接收信号推断源无人机位置，从而威胁位置隐私安全。需要在不影响合法通信的前提下保护源无人机位置隐私。

Method: 设计新型ARIS架构，将反射元件动态划分为多个子区域：一部分优化SU与RU之间的通信速率，另一部分生成人工噪声干扰MU对SU的定位。建立联合优化框架，推导最优分区和功率分配策略。

Result: 仿真结果表明，相比基线方案，所提方案显著增加了恶意无人机对源无人机的定位误差，同时保持了源无人机与合法接收无人机之间的高效通信。

Conclusion: 该方案能有效保护源无人机位置隐私，在保证通信效率的同时干扰恶意定位。

Abstract: With the explosive advancement of unmanned aerial vehicles (UAVs), the security of efficient UAV networks has become increasingly critical. Owing to the open nature of its communication environment, illegitimate malicious UAVs (MUs) can infer the position of the source UAV (SU) by analyzing received signals, thus compromising the SU location privacy. To protect the SU location privacy while ensuring efficient communication with legitimate receiving UAVs (RUs), we propose an Active Reconfigurable Intelligent Surface (ARIS)-assisted covert communication scheme based on virtual partitioning and artificial noise (AN). Specifically, we design a novel ARIS architecture integrated with an AN module. This architecture dynamically partitions its reflecting elements into multiple sub-regions: one subset is optimized to enhance the communication rate between the SU and RUs, while the other subset generates AN to interfere with the localization of the SU by MUs. We first derive the Cramér-Rao Lower Bound (CRLB) for the localization with received signal strength (RSS), based on which, we establish a joint optimization framework for communication enhancement and localization interference. Subsequently, we derive and validate the optimal ARIS partitioning and power allocation under average channel conditions. Finally, tailored optimization methods are proposed for the reflection precoding and AN design of the two partitions. Simulation results validate that, compared to baseline schemes, the proposed scheme significantly increases the localization error of the SU by MUs while maintaining efficient communication between the SU and RUs, thereby effectively protecting the SU location privacy.

</details>


### [92] [Unifying Sequential Quadratic Programming and Linear-Parameter-Varying Algorithms for Real-Time Model Predictive Control](https://arxiv.org/abs/2511.09106)
*Kristóf Floch,Amon Lahr,Roland Tóth,Melanie N. Zeilinger*

Main category: eess.SY

TL;DR: 本文提出了一个统一框架，将序列二次规划(SQP)与迭代线性参数变化模型预测控制(LPV-MPC)技术连接起来，通过特定的调度变量选择和FTC嵌入技术统一两种方法，并比较其收敛特性。


<details>
  <summary>Details</summary>
Motivation: 为了统一SQP的零阶方法与LPV-MPC调度技术，提高随机和鲁棒MPC问题的计算效率。

Method: 使用LPV-MPC的微分公式，通过特定的调度变量选择和2nd Fundamental Theorem of Calculus (FTC)嵌入技术统一SQP和LPV-MPC，并比较它们的收敛特性。

Result: 成功统一了SQP和LPV-MPC方法，在仿真示例中比较了两种方案，并通过真实世界实验展示了零阶LPV-MPC方法在基于高斯过程的自主赛车MPC中的实时可行性和性能。

Conclusion: 提出的统一框架能够有效连接SQP和LPV-MPC，为随机和鲁棒MPC问题提供了计算效率更高的解决方案，并在实际应用中验证了其有效性。

Abstract: This paper presents a unified framework that connects sequential quadratic programming (SQP) and the iterative linear-parameter-varying model predictive control (LPV-MPC) technique. Using the differential formulation of the LPV-MPC, we demonstrate how SQP and LPV-MPC can be unified through a specific choice of scheduling variable and the 2nd Fundamental Theorem of Calculus (FTC) embedding technique and compare their convergence properties. This enables the unification of the zero-order approach of SQP with the LPV-MPC scheduling technique to enhance the computational efficiency of stochastic and robust MPC problems. To demonstrate our findings, we compare the two schemes in a simulation example. Finally, we present real-time feasibility and performance of the zeroorder LPV-MPC approach by applying it to Gaussian process (GP)-based MPC for autonomous racing with real-world experiments.

</details>


### [93] [Context-Aware Management of IoT Nodes: Balancing Informational Value with Energy Usage](https://arxiv.org/abs/2511.09111)
*Nihal Ahmad,Talha Manzoor,Ijaz Haider Naqvi*

Main category: eess.SY

TL;DR: 提出了一种基于价值信息(VoI)和能量状态(SoE)的情境感知能量管理策略，使用模型预测控制(MPC)来平衡及时数据收集与能量节约的冲突目标。


<details>
  <summary>Details</summary>
Motivation: 能量收集无线传感器节点的运行寿命受限于能源可用性和能量缓冲容量，传统降低占空比的方法在时间关键应用中不可取，需要在及时数据收集与能量节约之间找到平衡。

Method: 将能量管理策略建模为模型预测控制(MPC)问题，通过定义的价值信息(VoI)和能量状态(SoE)来计算设备采样和传输频率，最大化有限时间范围内的效用标准。

Result: 使用真实世界山洪事件数据评估了该决策框架在多种能量可用性场景下的表现。

Conclusion: 该框架能够有效平衡及时数据收集与能量节约的冲突目标，为能量受限的无线传感器网络提供了实用的能量管理解决方案。

Abstract: The operational lifetime of energy-harvesting wireless sensor nodes is limited by availability of the energy source and the capacity of the installed energy buffer. When a sensor node depletes its energy reserves, manual intervention is often required to resume node operation. While lowering the duty cycle would help extend the network lifetime, this is often undesirable, especially in time-critical applications, where rapid collection and dissemination of information is vital. In this paper, we propose a context-aware energy management policy that helps balance the two opposing objectives of timely data collection and dissemination with energy conservation. We capture these objectives through the Value of Information (VoI) of observations made by a sensor node and the State of Energy (SoE) of the energy buffer. We formulate the energy management policy as a Model Predictive Control (MPC) problem which computes device sampling and transmission frequencies to maximize a defined utility criterion over a finite, receding, time-horizon. In the process, we also develop a unique mathematical representation for VoI, that adequately captures aspects related to continuity in monitoring, urgency of dissemination, and representation of the phenomena being observed. In the end, we use data collected from a real-world flash flood event, to evaluate our decision framework across multiple scenarios of energy availability.

</details>


### [94] [Steering Opinion Dynamics in Signed Time-Varying Networks via External Control Input](https://arxiv.org/abs/2511.09152)
*Swati Priya,Twinkle Tripathy*

Main category: eess.SY

TL;DR: 本文研究了在有符号时变有向图上的多智能体系统中目标意见形成问题，提出了一种控制器设计方法，使集体意见能够收敛到任意期望的稳态配置，超越自然涌现的聚类或极化行为。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体系统中意见形成的控制问题，旨在克服由结构平衡的有影响力根节点导致的自然聚类或极化现象，实现任意期望的稳态意见配置。

Method: 采用拉普拉斯基更新规则，结合合作和对抗性交互，利用外部控制输入作为外生因素，通过上Dini导数分析和Grönwall型不等式建立指数收敛性。

Result: 在具有均匀准强δ连通性的网络上，建立了意见幅度向期望稳态配置的指数收敛性，并通过数值模拟验证了理论结果。

Conclusion: 提出的控制器设计方法能够有效引导多智能体系统的集体意见收敛到任意期望的稳态配置，超越了自然涌现的聚类或极化行为。

Abstract: This paper studies targeted opinion formation in multi-agent systems evolving over signed, time-varying directed graphs. The dynamics of each agent's state follow a Laplacian-based update rule driven by both cooperative and antagonistic interactions in the presence of exogenous factors. We formulate these exogenous factors as external control inputs and establish a suitable controller design methodology enabling collective opinion to converge to any desired steady-state configuration, superseding the natural emergent clustering or polarization behavior imposed by persistently structurally balanced influential root nodes. Our approach leverages upper Dini derivative analysis and Grönwall-type inequalities to establish exponential convergence for opinion magnitude towards the desired steady state configuration on networks with uniform quasi-strong $δ$-connectivity. Finally, the theoretical results are validated through extensive numerical simulations.

</details>


### [95] [Runtime Safety and Reach-avoid Prediction of Stochastic Systems via Observation-aware Barrier Functions](https://arxiv.org/abs/2511.09192)
*Shenghua Feng,Jie An,Fanjiang Xu*

Main category: eess.SY

TL;DR: 提出了一种结合实时观测的动态随机系统安全性和可达性概率预测框架，通过观测感知屏障函数在线更新概率边界。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖离线模型，无法利用实时观测动态修正概率估计，需要开发能结合在线观测的安全性和可达性概率预测方法。

Method: 引入观测感知屏障函数，结合离线高效计算和在线反向迭代，动态更新安全性和可达性事件的概率边界。

Result: 实验结果表明该方法在基准系统上具有实际有效性，能够提供严格且响应迅速的概率预测。

Conclusion: 该框架为不确定环境下的随机系统提供了理论保证的运行时安全性和可达性概率预测能力。

Abstract: Stochastic dynamical systems have emerged as fundamental models across numerous application domains, providing powerful mathematical representations for capturing uncertain system behavior. In this paper, we address the problem of runtime safety and reach-avoid probability prediction for discrete-time stochastic systems with online observations, i.e., estimating the probability that the system satisfies a given safety or reach-avoid specification. Unlike traditional approaches that rely solely on offline models, we propose a framework that incorporates real-time observations to dynamically refine probability estimates for safety and reach-avoid events. By introducing observation-aware barrier functions, our method adaptively updates probability bounds as new observations are collected, combining efficient offline computation with online backward iteration. This approach enables rigorous and responsive prediction of safety and reach-avoid probabilities under uncertainty. In addition to the theoretical guarantees, experimental results on benchmark systems demonstrate the practical effectiveness of the proposed method.

</details>


### [96] [Investigation of resonance between HVDC-MMC link and AC network](https://arxiv.org/abs/2511.09235)
*Iva Radecic,Bozidar Filipovic-Grcic,Paul Akiki,Alain Xemard,Bruno Jurisic*

Main category: eess.SY

TL;DR: 该研究通过数值EMT仿真分析了HVDC站的电谐振现象，发现弱电网和长电缆中谐振最为显著，并在时域中成功模拟了两个实际案例。


<details>
  <summary>Details</summary>
Motivation: HVDC网络在长距离输电和可再生能源整合方面具有优势，但也增加了振荡风险，需要研究相关的电谐振现象。

Method: 使用数值EMT仿真和奈奎斯特准则分析频率响应，通过在时域中引入网络变化（如临时故障和功率强度变化）来激活谐振。

Result: 发现弱电网和长电缆中电谐振最为显著；强电网和短电缆中谐振与换流器保护系统相互作用；谐振谐波振幅快速衰减，表明网络配置具有足够阻尼。

Conclusion: 研究确认了网络对换流器参数变化的敏感性，并验证了EMT仿真在分析HVDC谐振现象中的有效性。

Abstract: HVDC networks offer several advantages over traditional HVAC systems, particularly for long-distance power transmission and integration of renewable energy sources, such as reduced losses and enhanced stability and control, but also increase the risk of oscillations. This study investigates electrical resonant phenomena associated with HVDC stations through numerical EMT simulations. The findings indicate that electrical resonance is primarily pronounced in weak networks with long cables, as confirmed by the Nyquist criterion applied to frequency responses. Two real cases were successfully simulated in the time domain by introducing network changes, such as temporary faults and alterations in network's power strength, to activate the identified resonances. Notably, in a strong network with short cables, electrical resonance occurred alongside interactions between the network and the converter's protection system. The analysis of voltage waveforms revealed that the amplitude of the induced resonant harmonic dissipates quickly, indicating sufficient damping in the network configuration. Furthermore, the study confirmed the network's sensitivity to changes in converter parameters modeled using available MMC model.

</details>


### [97] [Robust Estimation and Control for Heterogeneous Multi-agent Systems Based on Decentralized k-hop Prescribed Performance Observers](https://arxiv.org/abs/2511.09269)
*Tommaso Zaccherini,Siyuan Liu,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: 提出了一种去中心化的k跳规定性能状态和输入观测器，用于受有界外部干扰的异构多智能体系统，通过局部信息交换估计多跳邻居的状态和输入，并保证估计误差满足预设性能边界。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中需要估计多跳邻居状态和输入的问题，同时保证估计误差的瞬态性能满足预定要求，减少通信负担。

Method: 设计去中心化k跳规定性能状态和输入观测器，每个智能体仅与1跳邻居交换信息来估计2跳或更远邻居的状态和输入，建立条件使输入观测器可省略。

Result: 理论分析表明，如果具有完整状态知识的闭环控制器能实现控制目标，且基于估计的闭环系统对目标集是集合输入状态稳定的，则使用估计状态可实现系统目标，误差由状态估计精度决定。

Conclusion: 仿真结果验证了所提方法的有效性，该方法能够在保证性能边界的前提下，通过局部信息交换实现多跳邻居状态和输入的准确估计。

Abstract: We propose decentralized k-hop Prescribed Performance State and Input Observers for heterogeneous multi-agent systems subject to bounded external disturbances. In the proposed input/state observer, each agent estimates the state and input of agents located two or more hops away using only local information exchanged with 1-hop neighbors, while guaranteeing that transient estimation errors satisfy predefined performance bounds. Conditions are established under which the input observer can be omitted, allowing the state observer convergence to be independent of the input estimates. Theoretical analysis demonstrates that if a closed-loop controller with full state knowledge achieves the control objective and the estimation-based closed-loop system is set-Input to State Stable (set-ISS) with respect to the goal set, then the estimated states can be used to achieve the system objective with an arbitrarily small worst-case error governed by the accuracy of the states estimates. Simulation results are provided to validate the proposed approach.

</details>


### [98] [Security Index from Input/Output Data: Theory and Computation](https://arxiv.org/abs/2511.09524)
*Takumi Shinohara,Karl H. Johansson,Henrik Sandberg*

Main category: eess.SY

TL;DR: 提出了一种仅从输入/输出数据计算安全指数的数据驱动方法，无需系统模型，并提供了计算算法和多项式时间可计算的上界。


<details>
  <summary>Details</summary>
Motivation: 安全指数可以量化组件被攻击的风险，但传统方法需要系统模型。本文旨在开发仅从数据就能计算安全指数的方法，适用于模型未知的场景。

Method: 引入数据驱动的安全指数定义，证明在特定条件下与基于模型的安全指数一致，提供计算算法和多项式时间上界。

Result: 在车辆编队控制案例中验证了所提指数和算法的有效性，但也揭示了其局限性。

Conclusion: 数据驱动安全指数可以在模型未知时有效评估组件安全风险，为实际系统安全分析提供了实用工具。

Abstract: The concept of a security index quantifies the minimum number of components that must be compromised to carry out an undetectable attack. This metric enables system operators to quantify each component's security risk and implement countermeasures. In this paper, we introduce a data-driven security index that can be computed solely from input/output data when the system model is unknown. We show a sufficient condition under which the data-driven security index coincides with the model-based security index, which implies that the exact risk level of each component can be identified solely from the data. We provide an algorithm for computing the data-driven security index. Although computing this index is NP-hard, we derive a polynomial-time computable upper bound. Numerical examples on vehicle platooning illustrate the efficacy and limitations of the proposed index and algorithms.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [99] [Robust Cauchy-Based Methods for Predictive Regressions](https://arxiv.org/abs/2511.09249)
*Rustam Ibragimov,Jihyun Kim,Anton Skrobotov*

Main category: econ.EM

TL;DR: 提出了两种稳健的预测回归推断方法，基于柯西估计框架，解决内生持久性、重尾回归变量和持久波动率带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 标准推断方法在内生性、接近非平稳性、重尾和持久波动率条件下存在严重的尺寸扭曲问题，需要开发更稳健的推断方法。

Method: 基于柯西估计框架，提出了t统计量组推断和结合柯西与OLS估计的混合方法两种新检验。

Result: 模拟实验显示在多种现实设置下具有良好的有限样本性能，实证应用发现股息价格比具有预测能力而盈利价格比没有。

Conclusion: 所提出的方法能有效缓解标准推断程序的尺寸扭曲，简单易用且适用于连续和离散时间模型。

Abstract: This paper develops robust inference methods for predictive regressions that address key challenges posed by endogenously persistent or heavy-tailed regressors, as well as persistent volatility in errors. Building on the Cauchy estimation framework, we propose two novel tests: one based on $t$-statistic group inference and the other employing a hybrid approach that combines Cauchy and OLS estimation. These methods effectively mitigate size distortions that commonly arise in standard inference procedures under endogeneity, near nonstationarity, heavy tails, and persistent volatility. The proposed tests are simple to implement and applicable to both continuous- and discrete-time models. Extensive simulation experiments demonstrate favorable finite-sample performance across a range of realistic settings. An empirical application examines the predictability of excess stock returns using the dividend-price and earnings-price ratios as predictors. The results suggest that the dividend-price ratio possesses predictive power, whereas the earnings-price ratio does not significantly forecast returns.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [100] [Posterior-Separable Costs and Menu Preferences](https://arxiv.org/abs/2511.09424)
*Henrique de Oliveira,Jeffrey Mensch*

Main category: econ.TH

TL;DR: 该论文研究了具有理性不关注偏好的代理人的决策问题，提出了两个公理（无关替代独立性、无知等价性）作为后验可分离成本函数的充要条件，并在贝叶斯说服框架下分析了这些公理的含义。


<details>
  <summary>Details</summary>
Motivation: 研究理性不关注偏好下的决策者行为，探索能够保证后验可分离成本函数存在的公理条件，为理解信息获取和决策过程提供理论框架。

Method: 采用公理化方法，提出两个关键公理（无关替代独立性、无知等价性），分析这些公理与后验可分离成本函数的关系，并在贝叶斯说服问题中验证其适用性。

Result: 证明了两个公理是保证代理人具有联合方向可微后验可分离成本函数的充要条件，且在贝叶斯说服问题中对应唯一超平面可解性。当成本函数对先验不变时，这些公理意味着均匀后验可分离且可微的成本函数。

Conclusion: 无关替代独立性和无知等价性公理为理性不关注偏好下的后验可分离成本函数提供了完整的特征化，深化了对信息获取决策过程的理论理解。

Abstract: We consider an agent with a rationally inattentive preference over menus of acts, as in de Oliveira et al (2017). We show that two axioms, Independence of Irrelevant Alternatives and Ignorance Equivalence, are necessary and sufficient for this agent to have a posterior-separable cost satisfying a mild smoothness condition, called joint-directional differentiability. Viewing the decision-maker's problem as a Bayesian persuasion problem, we also show that these axioms are necessary and sufficient for solvability by a unique hyperplane. When the cost function remains invariant for different priors, we show that these axioms imply uniformly posterior separable costs that are differentiable.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [101] [Backcasting biodiversity at high spatiotemporal resolution using flexible site-occupancy models for opportunistically sampled citizen science data](https://arxiv.org/abs/2511.08802)
*Maxime Fajgenblat,Marc Herremans,Pieter Vanormelingen,Kristijn Swinnen,Dirk Maes,Robby Stoks,Luc De Meester,Christel Faes,Thomas Neyens*

Main category: stat.AP

TL;DR: 提出了一种灵活的贝叶斯时空站点占用模型，用于分析公民科学数据集，能够进行高分辨率的时空回溯预测和丰富的生物学推断。


<details>
  <summary>Details</summary>
Motivation: 现有的站点占用模型往往忽略检测过程的重要方面，未能充分利用公民科学数据集中的信息，无法进行精细的时空回溯分析。

Method: 开发了一个灵活的贝叶斯时空站点占用模型，模拟公民科学数据生成过程，应用于比利时超过300万条蝴蝶记录的数据集。

Result: 该方法能够进行高分辨率的时空回溯预测，推断年度分布趋势、范围动态、栖息地偏好、物候模式、检测模式和观察者异质性。

Conclusion: 该模型可以提高机会性收集数据的价值，帮助理解缺乏严格收集数据的物种的时空动态。

Abstract: For many taxonomic groups, online biodiversity portals used by naturalists and citizen scientists constitute the primary source of distributional information. Over the last decade, site-occupancy models have been advanced as a promising framework to analyse such loosely structured, opportunistically collected datasets. Current approaches often ignore important aspects of the detection process and do not fully capitalise on the information present in these datasets, leaving opportunities for fine-grained spatiotemporal backcasting untouched. We propose a flexible Bayesian spatiotemporal site-occupancy model that aims to mimic the data-generating process that underlies common citizen science datasets sourced from public biodiversity portals, and yields rich biological output. We illustrate the use of the model to a dataset containing over 3M butterfly records in Belgium, collected through the citizen science data portal Observations.be. We show that the proposed approach enables retrospective predictions on the occupancy of species through time and space at high resolution, as well as inference on inter-annual distributional trends, range dynamics, habitat preferences, phenological patterns, detection patterns and observer heterogeneity. The proposed model can be used to increase the value of opportunistically collected data by naturalists and citizen scientists, and can aid the understanding of spatiotemporal dynamics of species for which rigorously collected data are absent or too costly to collect.

</details>


### [102] [Generalisable prediction model of surgical case duration: multicentre development and temporal validation](https://arxiv.org/abs/2511.08994)
*Daijiro Kabata,Mari Ito,Tokito Koga,Kazuma Yunoki*

Main category: stat.AP

TL;DR: 开发了一个仅使用广泛可得的术前变量的堆叠机器学习模型，用于预测手术持续时间，并在多中心研究中进行了外部验证，显示出良好的准确性和校准性能。


<details>
  <summary>Details</summary>
Motivation: 现有手术持续时间预测模型通常依赖特定医院或外科医生的输入，且很少进行外部验证，限制了模型的通用性和可移植性。

Method: 采用回顾性多中心研究，使用日本两家综合医院的围手术期数据。纳入四个机器学习模型（弹性网络、广义可加模型、随机森林、梯度提升树），通过内部-外部交叉验证进行调优，并使用堆叠泛化方法组合模型来预测对数转换后的手术持续时间。

Result: 分析了63,206例手术，在2024年时间测试队列中校准良好（截距0.423，斜率0.921），在不同中心和年份间表现一致。

Conclusion: 仅使用广泛可得的术前变量的堆叠机器学习模型在时间外部验证中实现了准确、良好校准的预测，支持跨站点和时间的可移植性，可能改善手术室调度而不依赖特定输入。

Abstract: Background: Accurate prediction of surgical case duration underpins operating room (OR) scheduling, yet existing models often depend on site- or surgeon-specific inputs and rarely undergo external validation, limiting generalisability.
  Methods: We undertook a retrospective multicentre study using routinely collected perioperative data from two general hospitals in Japan (development: 1 January 2021-31 December 2023; temporal test: 1 January-31 December 2024). Elective weekday procedures with American Society of Anesthesiologists (ASA) Physical Status 1-4 were included. Pre-specified preoperative predictors comprised surgical context (year, month, weekday, scheduled duration, general anaesthesia indicator, body position) and patient factors (sex, age, body mass index, allergy, infection, comorbidity, ASA). Missing data were addressed by multiple imputation by chained equations. Four learners (elastic-net, generalised additive models, random forest, gradient-boosted trees) were tuned within internal-external cross-validation (IECV; leave-one-cluster-out by centre-year) and combined by stacked generalisation to predict log-transformed duration.
  Results: We analysed 63,206 procedures (development 45,647; temporal test 17,559). Cluster-specific and pooled errors and calibrations from IECV are provided with consistent performance across centres and years. In the 2024 temporal test cohort, calibration was good (intercept 0.423, 95%CI 0.372 to 0.474; slope 0.921, 95%CI 0.911 to 0.932).
  Conclusions: A stacked machine-learning model using only widely available preoperative variables achieved accurate, well-calibrated predictions in temporal external validation, supporting transportability across sites and over time. Such general-purpose tools may improve OR scheduling without relying on idiosyncratic inputs.

</details>


### [103] [Second-order spatial analysis of shapes of tumor cell nuclei](https://arxiv.org/abs/2511.09023)
*Ye Jin Choi,Sebastian Kurtek,Simeng Zhu,Karthik Bharath*

Main category: stat.AP

TL;DR: 提出了一个基于标记点过程的框架，用于量化细胞核形状之间的空间相关性，通过标记加权K函数来评估平面闭合曲线形状的空间依赖性。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏能够量化细胞和细胞核形状空间相关性（包括不确定性）的工具，现有方法基于低维数值摘要，无法充分编码形状信息。

Method: 使用标记点过程框架，将细胞核轮廓表示为平面闭合曲线，通过标记加权K函数（二阶空间统计量）来捕捉形状变化，并开发局部和全局假设检验来评估标记间的空间依赖性。

Result: 将该框架应用于乳腺癌组织病理学图像中的细胞核，发现了与临床预期一致的不同相关性模式。

Conclusion: 所提出的框架能够有效量化细胞核形状的空间相关性，为理解肿瘤异质性提供了新的分析工具。

Abstract: Intra-tumor heterogeneity driving disease progression is characterized by distinct growth and spatial proliferation patterns of cells and their nuclei within tumor and non-tumor tissues. A widely accepted hypothesis is that these spatial patterns are correlated with morphology of the cells and their nuclei. Nevertheless, tools to quantify the correlation, with uncertainty, are scarce, and the state-of-the-art is based on low-dimensional numerical summaries of the shapes that are inadequate to fully encode shape information. To this end, we propose a marked point process framework to assess spatial correlation among shapes of planar closed curves, which represent cell or nuclei outlines. With shapes of curves as marks, the framework is based on a mark-weighted $K$ function, a second-order spatial statistic that accounts for the marks' variation by using test functions that capture only the shapes of cells and their nuclei. We then develop local and global hypothesis tests for spatial dependence between the marks using the $K$ function. The framework is brought to bear on the cell nuclei extracted from histopathology images of breast cancer, where we uncover distinct correlation patterns that are consistent with clinical expectations.

</details>


### [104] [Scaling behavioral incentives for low-carbon mobility through digital platforms](https://arxiv.org/abs/2511.09237)
*Bing Liu,Yuan Liao,Sonia Yeh,Oded Cats,Kristian S. Nielsen,Zhenning Dong,Yong Wang,Yi Li,Yanli Liu,Zirui Ni,Xiaolei Ma*

Main category: stat.AP

TL;DR: 在北京MaaS平台中嵌入碳激励计划，通过3.9百万参与者和48亿次多模式出行数据评估，该计划每月增加20.3%的公共交通和自行车出行，每日减少1.8%的汽油车使用，年碳减排约94,000吨。


<details>
  <summary>Details</summary>
Motivation: 实现全球碳减排目标需要大规模日常出行行为转变，但关于如何激励这种大规模行为改变的现实证据仍然稀缺。

Method: 在北京MaaS平台中嵌入碳激励计划，使用3.9百万参与者和48亿次多模式出行数据，进行395天的评估。

Result: 计划每月增加20.3%的公共交通和自行车出行，每日减少1.8%的汽油车使用，年碳减排约94,000吨，相当于北京碳市场认证减排量的5.7%。虽然效果随时间减弱，但8个月后参与者每月仍多进行12.8%的绿色出行。

Conclusion: 这为MaaS中的碳激励提供了首个大规模实证证据，突显了其潜力，可为针对性的城市特定干预措施提供信息，支持全球低碳交通转型。

Abstract: Meeting global carbon reduction targets requires large-scale behavioral shifts in everyday travel. Yet, real-world evidence on how to motivate such large-scale behavioral change remains scarce. We evaluate a carbon incentive program embedded in a MaaS platform in Beijing, China, using data from 3.9 million participants and 4.8 billion multimodal trips over 395 days. The program increased reported public transport and bike travel by 20.3% per month and reduced gasoline car use by 1.8% per day, yielding an annual carbon reduction of ~94,000 tons, or 5.7% of certified reductions in Beijing's carbon market. Although effects diminished over time, participants still made 12.8% more green trips per month after eight months, indicating persistence. These results provide the first large-scale empirical evidence of carbon incentives in MaaS and highlight their potential to inform targeted, city-specific interventions that can scale to support global low-carbon mobility transitions.

</details>


### [105] [The trade-off between model flexibility and accuracy of the Expected Threat model in football](https://arxiv.org/abs/2511.09457)
*Koen W. van Arem,Jakob Söhl,Mirjam Bruinsma,Geurt Jongbloed*

Main category: stat.AP

TL;DR: 本文分析了足球数据中的预期威胁模型，研究了网格大小选择对模型灵活性和准确性的权衡，提出了理论误差上限和实用选择指南。


<details>
  <summary>Details</summary>
Motivation: 足球比赛数据丰富但难以有效利用，预期威胁模型因其可解释性而受推崇，但网格大小选择面临灵活性与准确性的权衡难题。

Method: 从理论角度分析预期威胁模型，基于模型的马尔可夫链进行模拟实验，建立误差上限并改进理论边界。

Result: 理论分析建立了不同灵活性下模型误差的上界，模拟实验提供了更准确的误差特征描述，改进了理论边界。

Conclusion: 将研究结果转化为实用经验法则，帮助从业者在模型灵活性和期望精度之间选择合适的平衡点。

Abstract: With an average football (soccer) match recording over 3,000 on-ball events, effective use of this event data is essential for practitioners at football clubs to obtain meaningful insights. Models can extract more information from this data, and explainable methods can make them more accessible to practitioners. The Expected Threat model has been praised for its explainability and offers an accessible option. However, selecting the grid size is a challenging key design choice that has to be made when applying the Expected Threat model. Using a finer grid leads to a more flexible model that can better distinguish between different situations, but the accuracy of the estimates deteriorates with a more flexible model. Consequently, practitioners face challenges in balancing the trade-off between model flexibility and model accuracy. In this study, the Expected Threat model is analyzed from a theoretical perspective and simulations are performed based on the Markov chain of the model to examine its behavior in practice. Our theoretical results establish an upper bound on the error of the Expected Threat model for different flexibilities. Based on the simulations, a more accurate characterization of the model's error is provided, improving over the theoretical bound. Finally, these insights are converted into a practical rule of thumb to help practitioners choose the right balance between the model flexibility and the desired accuracy of the Expected Threat model.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [106] [Conversational Agents for Building Energy Efficiency -- Advising Housing Cooperatives in Stockholm on Reducing Energy Consumption](https://arxiv.org/abs/2511.08587)
*Shadaab Ghani,Anne Håkansson,Oleksii Pasichnyi,Hossein Shahrokni*

Main category: cs.CY

TL;DR: SPARA是一个基于检索增强生成框架的对话代理系统，旨在为瑞典住房合作社提供能源效率建议，其准确率可达80%，与市政能源专家相当。


<details>
  <summary>Details</summary>
Motivation: 瑞典住房合作社的董事会成员通常缺乏管理物业和能源消耗的专业知识，而欧盟指令要求在2033年前禁止F和G级能效建筑，这给合作社带来了挑战。

Method: 采用检索增强生成框架，利用语言模型基于专业能源顾问与斯德哥尔摩合作社代表之间的电子邮件通信知识库生成针对性建议。

Result: 初步结果显示SPARA能提供准确率达80%的能源效率建议，目前正在进行试点实施，由市政能源专家评估其性能。

Conclusion: 语言模型能显著改善能源转型中的利益相关者支持，但需要进一步研究评估该技术，特别是其能源效率建议的稳定性和可信度限制。

Abstract: Housing cooperative is a common type of multifamily building ownership in Sweden. Although this ownership structure grants decision-making autonomy, it places a burden of responsibility on cooperative's board members. Most board members lack the resources or expertise to manage properties and their energy consumption. This ignorance presents a unique challenge, especially given the EU directives that prohibit buildings rated as energy classes F and G by 2033. Conversational agents (CAs) enable human-like interactions with computer systems, facilitating human-computer interaction across various domains. In our case, CAs can be implemented to support cooperative members in making informed energy retrofitting and usage decisions. This paper introduces a Conversational agent system, called SPARA, designed to advise cooperatives on energy efficiency. SPARA functions as an energy efficiency advisor by leveraging the Retrieval-Augmented Generation (RAG) framework with a Language Model(LM). The LM generates targeted recommendations based on a knowledge base composed of email communications between professional energy advisors and cooperatives' representatives in Stockholm. The preliminary results indicate that SPARA can provide energy efficiency advice with precision 80\%, comparable to that of municipal energy efficiency (EE) experts. A pilot implementation is currently underway, where municipal EE experts are evaluating SPARA performance based on questions posed to EE experts by BRF members. Our findings suggest that LMs can significantly improve outreach by supporting stakeholders in their energy transition. For future work, more research is needed to evaluate this technology, particularly limitations to the stability and trustworthiness of its energy efficiency advice.

</details>


### [107] [Hope, Aspirations, and the Impact of LLMs on Female Programming Learners in Afghanistan](https://arxiv.org/abs/2511.08630)
*Hamayoon Behmanush,Freshta Akhtari,Roghieh Nooripour,Ingmar Weber,Vikram Kamath Cannanure*

Main category: cs.CY

TL;DR: 该研究在阿富汗社会政治不稳定背景下，将斯奈德的希望量表改编为衡量女性在线学习编程者教育抱负的工具，验证了其可靠性和相关性，并发现使用LLM的参与者有更广泛的实现教育抱负途径认知。


<details>
  <summary>Details</summary>
Motivation: 在社会政治不稳定背景下设计有影响力的教育技术需要理解教育抱负，但目前缺乏可扩展的衡量指标，特别是在阿富汗教育受限时期。

Method: 研究对斯奈德的希望量表进行改编、翻译和评估，对136名在线学习编程的阿富汗女性进行调查，检验量表的可靠性和相关性，并分析LLM访问与抱负得分的关系。

Result: 改编后的量表显示出良好的信度（Cronbach's α = 0.78），参与者认为其易于理解和相关。虽然总体抱负得分在LLM访问组间无显著差异，但使用LLM的参与者在途径子量表上得分略高（p = .056）。

Conclusion: 改编后的量表可作为社会政治不稳定背景下衡量抱负的有效指标，并可用于评估基于抱负驱动的教育技术设计的影响。

Abstract: Designing impactful educational technologies in contexts of socio-political instability requires a nuanced understanding of educational aspirations. Currently, scalable metrics for measuring aspirations are limited. This study adapts, translates, and evaluates Snyder's Hope Scale as a metric for measuring aspirations among 136 women learning programming online during a period of systemic educational restrictions in Afghanistan. The adapted scale demonstrated good reliability (Cronbach's α = 0.78) and participants rated it as understandable and relevant. While overall aspiration-related scores did not differ significantly by access to Large Language Models (LLMs), those with access reported marginally higher scores on the Avenues subscale (p = .056), suggesting broader perceived pathways to achieving educational aspirations. These findings support the use of the adapted scale as a metric for aspirations in contexts of socio-political instability. More broadly, the adapted scale can be used to evaluate the impact of aspiration-driven design of educational technologies.

</details>


### [108] [Enabling Frontier Lab Collaboration to Mitigate AI Safety Risks](https://arxiv.org/abs/2511.08631)
*Nicholas Felstead*

Main category: cs.CY

TL;DR: 本文探讨如何调整美国反垄断政策以允许AI实验室之间的安全合作，同时不放弃核心竞争原则，以降低AI发展带来的灾难性风险。


<details>
  <summary>Details</summary>
Motivation: 前沿AI实验室面临激烈的商业竞争压力，可能导致在安全标准上竞相降低，增加灾难性和生存性风险。实验室间的自愿协调（如联合安全测试、信息共享和资源整合）可以降低这些风险，但反垄断审查的担忧可能阻碍此类合作。

Method: 分析无约束AI发展的风险及实验室间协调的益处，评估潜在的反垄断问题（包括产出限制、市场分配和信息共享），并调查一系列立法和监管改革方案。

Result: 提出了可以为负责任合作提供法律明确性和安全港的立法和监管改革方案，使AI安全合作能够在反垄断框架内得到允许。

Conclusion: 美国反垄断政策需要演进，以容纳AI安全合作，在不放弃核心竞争原则的前提下，通过提供法律明确性和安全港来鼓励负责任的协作，从而降低AI发展的灾难性风险。

Abstract: Frontier AI labs face intense commercial competitive pressure to develop increasingly powerful systems, raising the risk of a race to the bottom on safety. Voluntary coordination among labs - including by way of joint safety testing, information sharing, and resource pooling - could reduce catastrophic and existential risks. But the risk of antitrust scrutiny may deter such collaboration, even when it is demonstrably beneficial. This paper explores how U.S. antitrust policy can evolve to accommodate AI safety cooperation without abandoning core competition principles. After outlining the risks of unconstrained AI development and the benefits of lab-lab coordination, the paper analyses potential antitrust concerns, including output restrictions, market allocation, and information sharing. It then surveys a range of legislative and regulatory reforms that could provide legal clarity and safe harbours that will encourage responsible collaboration.

</details>


### [109] [How do data owners say no? A case study of data consent mechanisms in web-scraped vision-language AI training datasets](https://arxiv.org/abs/2511.08637)
*Chung Peng Lee,Rachel Hong,Harry Jiang,Aster Plotnik,William Agnew,Jamie Morgenstern*

Main category: cs.CY

TL;DR: 该研究分析了DataComp数据集中128亿文本-图像对的数据所有者同意情况，发现当前AI数据收集实践未能充分尊重数据所有者的意愿，存在大量版权声明、禁止抓取的网站服务条款和水印等问题。


<details>
  <summary>Details</summary>
Motivation: 互联网已成为训练现代文本到图像或视觉语言模型的主要数据来源，但网络规模的数据收集实践是否充分尊重数据所有者的意愿尚不明确。忽视数据所有者关于数据使用的同意表示不仅引发伦理问题，还升级为版权侵权诉讼。

Method: 研究检查了DataComp数据集中的样本级信息（包括版权声明、水印和元数据）和网站级信息（如服务条款和机器人排除协议），使用统计方法估计了存在版权声明和水印的样本比例。

Result: 估计CommonPool中至少有1.22亿样本显示版权声明；前50个域中60%的样本来自禁止抓取的网站；9-13%的样本包含水印，现有水印检测方法无法高保真地捕获这些水印。

Conclusion: 数据所有者依赖多种渠道传达数据同意，而当前的AI数据收集管道未能完全尊重这些意愿。这些发现凸显了当前数据集策划/发布实践的局限性，以及需要建立考虑AI目的的统一数据同意框架。

Abstract: The internet has become the main source of data to train modern text-to-image or vision-language models, yet it is increasingly unclear whether web-scale data collection practices for training AI systems adequately respect data owners' wishes. Ignoring the owner's indication of consent around data usage not only raises ethical concerns but also has recently been elevated into lawsuits around copyright infringement cases. In this work, we aim to reveal information about data owners' consent to AI scraping and training, and study how it's expressed in DataComp, a popular dataset of 12.8 billion text-image pairs. We examine both the sample-level information, including the copyright notice, watermarking, and metadata, and the web-domain-level information, such as a site's Terms of Service (ToS) and Robots Exclusion Protocol. We estimate at least 122M of samples exhibit some indication of copyright notice in CommonPool, and find that 60\% of the samples in the top 50 domains come from websites with ToS that prohibit scraping. Furthermore, we estimate 9-13\% with 95\% confidence interval of samples from CommonPool to contain watermarks, where existing watermark detection methods fail to capture them in high fidelity. Our holistic methods and findings show that data owners rely on various channels to convey data consent, of which current AI data collection pipelines do not entirely respect. These findings highlight the limitations of the current dataset curation/release practice and the need for a unified data consent framework taking AI purposes into consideration.

</details>


### [110] [The Journal of Prompt-Engineered Philosophy Or: How I Started to Track AI Assistance and Stopped Worrying About Slop](https://arxiv.org/abs/2511.08639)
*Michele Loi*

Main category: cs.CY

TL;DR: 本文分析了学术出版中AI辅助披露的结构性矛盾：要求披露但惩罚实质性AI使用，传统出版体系无法解决此问题。作者提出替代性出版基础设施，强制披露、支持可复现评审，并以自身AI辅助论文为例展示该框架。


<details>
  <summary>Details</summary>
Motivation: 学术出版要求作者披露AI辅助，但对实质性AI使用施加声誉成本，这种结构性矛盾阻碍透明度。传统出版体系基于声望经济奖励不透明，无法通过政策调整解决此问题。

Method: 提出替代性出版基础设施：在声望体系外的出版平台，强制披露AI使用，采用基于复现的评审机制，通过详细文档支持生态有效性。以自身AI辅助论文为例，包含代表性提示日志和修改记录。

Result: 建立了AI辅助学术工作评估框架：通过透明文档、验证导向评审和方法论承诺学者的参与，使AI辅助研究能够基于自身条件被评估。

Conclusion: 该框架不仅针对AI辅助学术，更涉及学术系统如何处理方法论创新的更广泛问题。通过建立透明、可验证的评估机制，为方法论创新提供可行的评价路径。

Abstract: Academic publishing increasingly requires authors to disclose AI assistance, yet imposes reputational costs for doing so--especially when such assistance is substantial. This article analyzes that structural contradiction, showing how incentives discourage transparency in precisely the work where it matters most. Traditional venues cannot resolve this tension through policy tweaks alone, as the underlying prestige economy rewards opacity. To address this, the article proposes an alternative publishing infrastructure: a venue outside prestige systems that enforces mandatory disclosure, enables reproduction-based review, and supports ecological validity through detailed documentation. As a demonstration of this approach, the article itself is presented as an example of AI-assisted scholarship under reasonably detailed disclosure, with representative prompt logs and modification records included. Rather than taking a position for or against AI-assisted scholarship, the article outlines conditions under which such work can be evaluated on its own terms: through transparent documentation, verification-oriented review, and participation by methodologically committed scholars. While focused on AI, the framework speaks to broader questions about how academic systems handle methodological innovation.

</details>


### [111] [AI-generated podcasts: Synthetic Intimacy and Cultural Translation in NotebookLM's Audio Overviews](https://arxiv.org/abs/2511.08654)
*Jill Walker Rettberg*

Main category: cs.CY

TL;DR: 分析Google NotebookLM生成的AI播客，发现其采用固定模板结构，并将不同文本和文化背景标准化为美国中西部白人、中产阶级、受过教育的文化默认，这改变了传统播客构建多元公共领域的方式。


<details>
  <summary>Details</summary>
Motivation: AI生成的播客虽然作为工具被讨论，但尚未被作为媒体进行分析。本研究旨在分析AI播客如何构建内容和塑造公众。

Method: 通过上传不同类型的文本到Google NotebookLM，分析生成的播客输出内容、结构和文化特征。

Result: 发现播客结构基于固定模板，不仅将其他语言文本转换为标准化的美国中西部口音，还将文化背景转化为白人、中产阶级、受过教育的美国文化默认。

Conclusion: 这标志着媒体塑造公众方式的显著发展，从传统播客的多元公共领域转向播客类型的抽象化。

Abstract: This paper analyses AI-generated podcasts produced by Google's NotebookLM, which generates audio podcasts with two chatty AI hosts discussing whichever documents a user uploads. While AI-generated podcasts have been discussed as tools, for instance in medical education, they have not yet been analysed as media. By uploading different types of text and analysing the generated outputs I show how the podcasts' structure is built around a fixed template. I also find that NotebookLM not only translates texts from other languages into a perky standardised Mid-Western American accent, it also translates cultural contexts to a white, educated, middle-class American default. This is a distinct development in how publics are shaped by media, marking a departure from the multiple public spheres that scholars have described in human podcasting from the early 2000s until today, where hosts spoke to specific communities and responded to listener comments, to an abstraction of the podcast genre.

</details>


### [112] [Operationalizing Justice: Towards the Development of a Principle Based Design Framework for Human Services AI](https://arxiv.org/abs/2511.08844)
*Maria Y. Rodriguez,Seventy Hall,Pranav Sankhe,Melanie Sage,Winnie Chen,Atri Rudra,Kenny Joseph*

Main category: cs.CY

TL;DR: 该研究通过混合方法分析纽约州儿童福利政策，发现了多种功能性正义定义，强调在开发高风险AI系统前需要先理解接收系统的正义执行方式。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索儿童福利系统中正义如何被操作化，为开发伦理AI提供指导，特别是在高风险决策环境中。

Method: 采用混合方法分析纽约州儿童福利政策，进行价值源分析，识别政策中的功能性正义定义。

Result: 发现了从公平、平等到父母和孩子专有权利等多种正义原则，反映了跨情境的细致正义理解。

Conclusion: 强调AI与政策互动的重要性，操作化价值对于制定高风险决策环境中的伦理设计要求至关重要。

Abstract: Scholars investigating ethical AI, especially in high stakes settings like child welfare, have arguably been seeking ways to embed notions of justice into the design of these critical technologies. These efforts often operationalize justice at the upper and lower bounds of its continuum, defining it in terms of progressiveness or reform. Before characterizing the type of justice an AI tool should have baked in, we argue for a systematic discovery of how justice is executed by the recipient system: a method the Value Sensitive Design (VSD) framework terms Value Source analysis. The present work asks: how is justice operationalized within current child welfare administrative policy and what does it teach us about how to develop AI? We conduct a mixed-methods analysis of child welfare policy in the state of New York and find a range of functional definitions of justice (which we term principles). These principles reflect more nuanced understandings of justice across a spectrum of contexts: from established concepts like fairness and equity to less common foci like the proprietary rights of parents and children. Our work contributes to a deeper understanding of the interplay between AI and policy, highlighting the importance of operationalized values in adjudicating our development of ethical design requirements for high stakes decision settings.

</details>


### [113] [From Everyday to Existential -- The ethics of shifting the boundaries of health and data with multimodal digital biomarkers](https://arxiv.org/abs/2511.09238)
*Joschka Haltaufderheide,Florian Funer,Esther Braun,Hans-Jörg Ehni,Urban Wiesing,Robert Ranisch*

Main category: cs.CY

TL;DR: 多模态数字生物标志物通过整合多种生理、行为和情境数据来连续表征健康状态，引发了健康数据化和健康相关性重新定义的本体论和认识论转变，并带来知识、责任和治理方面的伦理影响。


<details>
  <summary>Details</summary>
Motivation: 探讨多模态数字生物标志物如何扩展数字生物标志物的概念，以及这种扩展带来的本体论和认识论转变及其伦理影响。

Method: 通过分析多模态数字生物标志物在变异性、复杂性和抽象性三个维度上的扩展，论证其引发的健康数据化本体论转变和健康相关性重新定义的认识论转变。

Result: 多模态数字生物标志物导致了健康概念的数据化转变和健康相关性标准的重新定义，这些转变在知识生产、责任分配和治理机制方面产生了重要的伦理影响。

Conclusion: 多模态数字生物标志物的发展不仅扩展了数字生物标志物的技术能力，更重要的是引发了健康概念的根本性转变，需要在知识、责任和治理层面进行深入的伦理考量。

Abstract: Multimodal digital biomarkers (MDBs) integrate diverse physiological, behavioral, and contextual data to provide continuous representations of health. This paper argues that MDBs expand the concept of digital biomarkers along the dimensions of variability, complexity and abstraction, producing an ontological shift that datafies health and an epistemic shift that redefines health relevance. These transformations entail ethical implications for knowledge, responsibility, and governance in data-driven, preventive medicine.

</details>


### [114] [Slaying the Dragon: The Quest for Democracy in Decentralized Autonomous Organizations (DAOs)](https://arxiv.org/abs/2511.09263)
*Stefano Balietti,Pietro Saggese,Stefan Kitzler,Bernhard Haslhofer*

Main category: cs.CY

TL;DR: 本章探讨了基于区块链技术的去中心化自治组织(DAOs)如何挑战传统中心化治理结构，分析了其机遇与挑战，并讨论了DAOs与人工智能的交叉领域。


<details>
  <summary>Details</summary>
Motivation: 研究DAOs这一新型组织形式如何通过可编程、透明和参与式机制重新分配决策权，以及它们是否能够实现民主承诺还是复制现有的权力不对称。

Method: 通过分析DAOs在金融、科学和数字社区等领域的治理实践，识别其机会和挑战，并探讨DAOs与人工智能的融合潜力。

Result: DAOs提供了激励协调、快速协调和抗审查等机会，但也面临代币集中、参与度低和事实上的中心化等挑战。与AI结合可能增加自动化，但也带来人类监督减少和算法不透明的风险。

Conclusion: DAOs在特定条件下可能实现民主承诺，但也可能复制它们试图克服的权力不对称，需要仔细评估其治理机制的有效性。

Abstract: This chapter explores how Decentralized Autonomous Organizations (DAOs), a novel institutional form based on blockchain technology, challenge traditional centralized governance structures. DAOs govern projects ranging from finance to science and digital communities. They aim to redistribute decision-making power through programmable, transparent, and participatory mechanisms. This chapter outlines both the opportunities DAOs present, such as incentive alignment, rapid coordination, and censorship resistance, and the challenges they face, including token concentration, low participation, and the risk of de facto centralization. It further discusses the emerging intersection of DAOs and artificial intelligence, highlighting the potential for increased automation alongside the dangers of diminished human oversight and algorithmic opacity. Ultimately, we discuss under what circumstances DAOs can fulfill their democratic promise or risk replicating the very power asymmetries they seek to overcome.

</details>
