<div id=toc></div>

# Table of Contents

- [cs.SI](#cs.SI) [Total: 4]
- [cs.ET](#cs.ET) [Total: 5]
- [cs.CY](#cs.CY) [Total: 17]
- [econ.TH](#econ.TH) [Total: 2]
- [cs.AI](#cs.AI) [Total: 48]
- [econ.EM](#econ.EM) [Total: 2]
- [stat.AP](#stat.AP) [Total: 4]
- [eess.SY](#eess.SY) [Total: 22]
- [cs.RO](#cs.RO) [Total: 55]
- [econ.GN](#econ.GN) [Total: 2]


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [1] [Homophily in Complex Networks: Measures, Models, and Applications](https://arxiv.org/abs/2509.18289)
*Akrati Saxena,Gaurav Kumar,Chandrakala Meena*

Main category: cs.SI

TL;DR: 本教程全面概述了同质性（homophily）现象，涵盖其定义、性质、度量方法的局限性，以及在超图和高阶网络结构中的应用，同时介绍了可调节同质性水平的网络生成模型和现实应用。


<details>
  <summary>Details</summary>
Motivation: 理解同质性对于揭示社会网络演化动态和结构不平等现象的出现至关重要，因为同质性是社交网络的一个决定性特征。

Method: 教程采用综述方法，系统梳理同质性的各种定义、关键属性和常用度量的局限性，并扩展到高阶网络结构（如超图和单纯复形）中的同质性分析，同时介绍能够产生不同类型同质性网络的生成模型。

Result: 提供了同质性研究的全面框架，包括传统成对交互和高阶结构中的同质性分析，以及可调节同质性水平的网络模型，强调了在现实世界背景中的相关性。

Conclusion: 教程最后讨论了该领域的开放挑战、新兴方向和未来研究机会，为同质性研究的进一步发展提供了指导。

Abstract: Homophily, the tendency of individuals to connect with others who share
similar attributes, is a defining feature of social networks. Understanding how
groups interact, both within and across, is crucial for uncovering the dynamics
of network evolution and the emergence of structural inequalities in these
network. This tutorial offers a comprehensive overview of homophily, covering
its various definitions, key properties, and the limitations of widely used
metrics. Extending beyond traditional pairwise interactions, we will discuss
homophily in higher-order network structures such as hypergraphs and simplicial
complexes. We will further discuss network generating models capable of
producing different types of homophilic networks with tunable levels of
homophily and highlight their relevance in real-world contexts. The tutorial
concludes with a discussion of open challenges, emerging directions, and
opportunities for further research in this area.

</details>


### [2] [Identifying Constructive Conflict in Online Discussions through Controversial yet Toxicity Resilient Posts](https://arxiv.org/abs/2509.18303)
*Ozgur Can Seckin,Bao Tran Truong,Alessandro Flammini,Filippo Menczer*

Main category: cs.SI

TL;DR: 该论文提出通过算法筛选具有争议性但能抵抗毒性的内容，以促进社交媒体上的建设性政治讨论。研究发现使用礼貌提示的帖子即使在争议话题中也能保持文明对话。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的对立观点交流往往被回音室和有毒言论淹没，缺乏建设性对话。研究者希望通过算法识别能够引发建设性冲突的内容。

Method: 开发高精度模型来识别两个维度：争议性（识别挑战性对话）和毒性抵抗力（识别尊重性对话）。基于这些模型进行分析。

Result: 政治帖子通常具有争议性且容易引发毒性回应，但部分帖子即使高度争议也能保持文明对话。使用礼貌提示（如表达感谢、使用缓和语气）的帖子更具毒性抵抗力。

Conclusion: 通过调整帖子语气框架，有潜力鼓励建设性政治讨论。算法可以考虑争议性和毒性抵抗力作为筛选标准，促进社交媒体上的文明对话。

Abstract: Bridging content that brings together individuals with opposing viewpoints on
social media remains elusive, overshadowed by echo chambers and toxic
exchanges. We propose that algorithmic curation could surface such content by
considering constructive conflicts as a foundational criterion. We
operationalize this criterion through controversiality to identify challenging
dialogues and toxicity resilience to capture respectful conversations. We
develop high-accuracy models to capture these dimensions. Analyses based on
these models demonstrate that assessing resilience to toxic responses is not
the same as identifying low-toxicity posts. We also find that political posts
are often controversial and tend to attract more toxic responses. However, some
posts, even the political ones, are resilient to toxicity despite being highly
controversial, potentially sparking civil engagement. Toxicity resilient posts
tend to use politeness cues, such as showing gratitude and hedging. These
findings suggest the potential for framing the tone of posts to encourage
constructive political discussions.

</details>


### [3] [A Graph-Neural-Network-Entropy model of vital node identification on network attack and propagation](https://arxiv.org/abs/2509.18325)
*Huaizhi Liao,Tian Qiu,Guang Chen*

Main category: cs.SI

TL;DR: 本文提出了一种基于图神经网络和信息熵的新方法GNNE，用于识别复杂网络中的关键节点。该方法结合GCN和GAT的优势，通过节点熵量化节点重要性，在多种真实数据集上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分整合节点特征、交互和状态信息，而关键节点在网络遭受攻击时具有重要作用，需要更有效的识别方法。

Method: 使用图卷积网络(GCN)学习节点特征，输入图注意力网络(GAT)获取节点影响因子，然后计算节点熵来评估节点重要性。

Result: 在六个真实数据集上的测试表明，GNNE在网络攻击和传播视角下优于八种传统拓扑方法和四种图机器学习方法。

Conclusion: GNNE方法通过结合GCN和GAT的优势，有效识别关键节点，在网络保护和传播控制方面具有实用价值。

Abstract: Vital nodes usually play a key role in complex networks. Uncovering these
nodes is an important task in protecting the network, especially when the
network suffers intentional attack. Many existing methods have not fully
integrated the node feature, interaction and state. In this article, we propose
a novel method (GNNE) based on graph neural networks and information entropy.
The method employs a Graph Convolutional Network (GCN) to learn the nodes'
features, which are input into a Graph Attention Network (GAT) to obtain the
influence factor of nodes, and the node influence factors are used to calculate
the nodes' entropy to evaluate the node importance. The GNNE takes advantage of
the GCN and GAT, with the GCN well extracting the nodes' features and the GAT
aggregating the features of the nodes' neighbors by using the attention
mechanism to assign different weights to the neighbors with different
importance, and the nodes' entropy quantifies the nodes' state in the network.
The proposed method is trained on a synthetic Barabasi-Albert network, and
tested on six real datasets. Compared with eight traditional topology-based
methods and four graph-machine-learning-based methods, the GNNE shows an
advantage for the vital node identification in the perspectives of network
attack and propagation.

</details>


### [4] [Simulating Online Social Media Conversations on Controversial Topics Using AI Agents Calibrated on Real-World Data](https://arxiv.org/abs/2509.18985)
*Elisa Composta,Nicolo' Fontana,Francesco Corso,Francesco Pierri*

Main category: cs.SI

TL;DR: 本文研究了基于LLM的智能体在模拟微博社交网络中的行为，通过真实世界政治对话数据初始化智能体，发现LLM能生成连贯内容并构建现实社交网络结构，但生成内容在语气和毒性方面异质性不足，且意见动态与传统数学模型相似。


<details>
  <summary>Details</summary>
Motivation: 在线社交网络为分析个体和集体现象提供了宝贵视角，通过将LLM集成到模拟器中可以使模拟更加真实，让智能体能够理解和生成自然语言内容。

Method: 使用基于真实世界意大利2022年政治选举在线对话的配置文件初始化LLM智能体，扩展现有模拟器引入意见建模机制，在不同场景下研究LLM智能体的对话模拟、互动和意见演化。

Result: LLM智能体生成连贯内容、形成连接并构建现实社交网络结构，但生成内容在语气和毒性方面的异质性低于真实数据，LLM意见动态与传统数学模型演化方式相似，参数变化未产生显著影响。

Conclusion: LLM在模拟社交环境中用户行为方面具有潜力，但在捕捉异质性和复杂动态方面仍面临挑战，需要更精细的认知建模来更准确地复制人类行为。

Abstract: Online social networks offer a valuable lens to analyze both individual and
collective phenomena. Researchers often use simulators to explore controlled
scenarios, and the integration of Large Language Models (LLMs) makes these
simulations more realistic by enabling agents to understand and generate
natural language content. In this work, we investigate the behavior of
LLM-based agents in a simulated microblogging social network. We initialize
agents with realistic profiles calibrated on real-world online conversations
from the 2022 Italian political election and extend an existing simulator by
introducing mechanisms for opinion modeling. We examine how LLM agents simulate
online conversations, interact with others, and evolve their opinions under
different scenarios. Our results show that LLM agents generate coherent
content, form connections, and build a realistic social network structure.
However, their generated content displays less heterogeneity in tone and
toxicity compared to real data. We also find that LLM-based opinion dynamics
evolve over time in ways similar to traditional mathematical models. Varying
parameter configurations produces no significant changes, indicating that
simulations require more careful cognitive modeling at initialization to
replicate human behavior more faithfully. Overall, we demonstrate the potential
of LLMs for simulating user behavior in social environments, while also
identifying key challenges in capturing heterogeneity and complex dynamics.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [5] [Energy-convergence trade off for the training of neural networks on bio-inspired hardware](https://arxiv.org/abs/2509.18121)
*Nikhil Garg,Paul Uriarte Vicandi,Yanming Zhang,Alexandre Baigol,Donato Francesco Falcone,Saketh Ram Mamidala,Bert Jan Offrein,Laura Bégon-Lours*

Main category: cs.ET

TL;DR: 本文研究了基于HfO2/ZrO2超晶格的铁电突触器件，通过硬件感知神经网络模拟分析其性能。研究发现短脉冲编程结合定制化训练可以显著提高片上学习效率，在准确率、收敛速度和能耗之间实现优化平衡。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴传感器和植入式设备的部署增加，AI处理需求向极端边缘转移，需要超低功耗的连续操作。受大脑启发，新兴的忆阻器件有望通过消除计算和内存之间的昂贵数据传输来加速神经网络训练，但平衡性能和能效仍然是一个挑战。

Method: 研究铁电突触器件基于HfO2/ZrO2超晶格，将实验测量的权重更新输入硬件感知神经网络模拟。分析不同脉冲宽度（20 ns至0.2 ms）下的性能，比较普通随机梯度下降（SGD）和混合精度SGD，并提出"对称点偏移"技术来解决不对称更新问题。

Result: 短脉冲降低了每次更新的能量但需要更多训练周期，总体上仍能减少总能量而不牺牲准确率。普通SGD的分类准确率低于混合精度SGD。通过对称点偏移技术成功恢复了准确率。

Conclusion: 研究结果突出了准确率、收敛速度和能耗之间的权衡关系，表明短脉冲编程结合定制化训练可以显著提高片上学习效率，为超低功耗边缘AI处理提供了有效解决方案。

Abstract: The increasing deployment of wearable sensors and implantable devices is
shifting AI processing demands to the extreme edge, necessitating ultra-low
power for continuous operation. Inspired by the brain, emerging memristive
devices promise to accelerate neural network training by eliminating costly
data transfers between compute and memory. Though, balancing performance and
energy efficiency remains a challenge. We investigate ferroelectric synaptic
devices based on HfO2/ZrO2 superlattices and feed their experimentally measured
weight updates into hardware-aware neural network simulations. Across pulse
widths from 20 ns to 0.2 ms, shorter pulses lower per-update energy but require
more training epochs while still reducing total energy without sacrificing
accuracy. Classification accuracy using plain stochastic gradient descent (SGD)
is diminished compared to mixed-precision SGD. We analyze the causes and
propose a ``symmetry point shifting'' technique, addressing asymmetric updates
and restoring accuracy. These results highlight a trade-off among accuracy,
convergence speed, and energy use, showing that short-pulse programming with
tailored training significantly enhances on-chip learning efficiency.

</details>


### [6] [Weight Mapping Properties of a Dual Tree Single Clock Adiabatic Capacitive Neuron](https://arxiv.org/abs/2509.18143)
*Mike Smart,Sachin Maheshwari,Himadri Singh Raghav,Alexander Serb*

Main category: cs.ET

TL;DR: 本文研究了将人工神经网络权重映射到双树单时钟绝热电容神经元电路电容值的方法，提出了优化映射策略以提高芯片面积效率和分类精度。


<details>
  <summary>Details</summary>
Motivation: 虽然DTSC ACN电路具有高能效优势，但如何将软件训练得到的人工神经元权重有效映射到物理ACN电容值尚未得到充分研究，这限制了其实际应用。

Method: 使用TensorFlow和Larq框架训练三种不同ANN网络，提出最优的AN到ACN映射方法，并分析权重量化对ACN性能的影响。

Result: 实现了100%功能等效性，证明了所提方法能够减小芯片尺寸并提高整体分类精度。

Conclusion: 该研究为IC设计者提供了实用的映射方法，解决了权重映射中的复杂性和挑战，促进了DTSC ACN电路的实际部署。

Abstract: Dual Tree Single Clock (DTSC) Adiabatic Capacitive Neuron (ACN) circuits
offer the potential for highly energy-efficient Artificial Neural Network (ANN)
computation in full custom analog IC designs. The efficient mapping of
Artificial Neuron (AN) abstract weights, extracted from the software-trained
ANNs, onto physical ACN capacitance values has, however, yet to be fully
researched. In this paper, we explore the unexpected hidden complexities,
challenges and properties of the mapping, as well as, the ramifications for IC
designers in terms accuracy, design and implementation. We propose an optimal,
AN to ACN methodology, that promotes smaller chip sizes and improved overall
classification accuracy, necessary for successful practical deployment. Using
TensorFlow and Larq software frameworks, we train three different ANN networks
and map their weights into the energy-efficient DTSC ACN capacitance value
domain to demonstrate 100% functional equivalency. Finally, we delve into the
impact of weight quantization on ACN performance using novel metrics related to
practical IC considerations, such as IC floor space and comparator
decision-making efficacy.

</details>


### [7] [Lightweight Targeted Estimation of Layout Noise in a Quantum Computer using Quality Indicator Circuits](https://arxiv.org/abs/2509.18679)
*Shikhar Srivastava,Ritajit Majumdar,Padmanabha Venkatagiri Seshadri,Anupama Ray,Yogesh Simmhan*

Main category: cs.ET

TL;DR: 本文提出了一种轻量级的实时布局质量评估方法——质量指示电路（QICs），用于在量子硬件上选择最优的电路映射布局，以降低噪声影响并提高电路执行可靠性。


<details>
  <summary>Details</summary>
Motivation: 在量子计算中，将抽象量子电路映射到物理硬件布局对电路性能有重要影响。现有解决方案如Mapomatic和JIT Transpilation存在校准数据过时或硬件使用率高等局限性，需要一种更高效的实时布局评估方法。

Method: 提出质量指示电路（QICs）方法：设计小型探测电路，保留用户电路的基本结构，已知其理想无噪声结果。通过执行QIC来评估量子硬件不同区域对目标电路的适用性。包括基础方法（为每个同构布局执行QIC）、无重叠的Union QIC方法以及允许部分重叠的Distortion Threshold方法。

Result: 实验结果显示，与JIT相比平均减少79%的硬件开销，同时在布局选择质量上优于Mapomatic。

Conclusion: QICs方法轻量、可靠，是近期量子设备中布局选择的可行技术，能够在保证布局质量的同时显著降低硬件开销。

Abstract: In the current era of quantum computing, minimizing noise is essential for
reliably executing quantum circuits on hardware. A key factor affecting circuit
performance is the mapping of the abstract quantum circuit to the physical
layout of the quantum hardware. This mapping can significantly influence output
quality, especially since hardware noise profiles are non-uniform and dynamic.
Existing solutions such as Mapomatic and Just-In-Time (JIT) Transpilation
attempt to address this issue but are limited either by relying on stale
calibration data or high hardware usage, respectively. In this article, we
propose Quality Indicator Circuits (QICs) as a lightweight, real-time method
for assessing layout quality. A QIC is a small probe circuit that is designed
to retain the basic structure of the user's circuit and whose ideal noiseless
outcome is known. It is used to evaluate which region of the quantum hardware
is best suited for executing the circuit of interest. We first propose a basic
method where a QIC is executed for each isomorphic layout to detect the best
among them. Although this requires several targeted circuit executions, we show
that it still, in most cases, reduces the execution overheads as compared with
JIT. To reduce the overheads further, we propose the union of multiple layouts
with a Union QIC approach that has no overlaps, and a Distortion Threshold
based approach allowing some overlap. Our results show that these outperform
Mapomatic in the quality of layout selection while reducing the hardware
overhead of JIT by 79 percent on average. This makes our proposed method
lightweight and reliable, and a viable technique for layout selection in
near-term quantum devices.

</details>


### [8] [Integrating Stacked Intelligent Metasurfaces and Power Control for Dynamic Edge Inference via Over-The-Air Neural Networks](https://arxiv.org/abs/2509.18906)
*Kyriakos Stylianopoulos,George C. Alexandropoulos*

Main category: cs.ET

TL;DR: 本文提出了一种新颖的边缘推理框架，利用堆叠智能超表面控制无线传播，使信道本身能够执行空中计算，从而避免接收端的符号估计，显著降低计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 传统的边缘推理方法将无线信道视为噪声，存在计算和通信开销大的问题。本文旨在通过利用智能超表面技术，让无线信道直接参与计算过程，提高能效。

Method: 将发射器-信道-接收器系统建模为端到端深度神经网络，其中超表面元件的响应作为可训练参数。还引入专门的DNN模块根据用户位置信息动态调整传输功率以应对信道变化。

Result: 性能评估表明，所提出的集成超表面的DNN框架能够在不同场景下平衡分类精度和功耗，提供显著的能效改进。

Conclusion: 基于智能超表面的边缘推理框架能够有效利用无线信道进行计算，显著降低系统开销，为边缘计算提供了新的能效优化方案。

Abstract: This paper introduces a novel framework for Edge Inference (EI) that bypasses
the conventional practice of treating the wireless channel as noise. We utilize
Stacked Intelligent Metasurfaces (SIMs) to control wireless propagation,
enabling the channel itself to perform over-the-air computation. This
eliminates the need for symbol estimation at the receiver, significantly
reducing computational and communication overhead. Our approach models the
transmitter-channel-receiver system as an end-to-end Deep Neural Network (DNN)
where the response of the SIM elements are trainable parameters. To address
channel variability, we incorporate a dedicated DNN module responsible for
dynamically adjusting transmission power leveraging user location information.
Our performance evaluations showcase that the proposed metasurfaces-integrated
DNN framework with deep SIM architectures are capable of balancing
classification accuracy and power consumption under diverse scenarios, offering
significant energy efficiency improvements.

</details>


### [9] [A Stateless Transparent Voting Machine](https://arxiv.org/abs/2509.19257)
*Juan E. Gilbert,Jean D. Louis*

Main category: cs.ET

TL;DR: 本文实现了一种无状态、透明的投票机（STVM），该设备使用透明的交互式打印界面，让选民在填写选票时可以验证纸质选票。系统从只读媒体启动，不存储任何信息，提高了安全性。


<details>
  <summary>Details</summary>
Motivation: 投票系统的透明性和安全性至关重要，需要解决传统投票方法中存在的安全隐患和可访问性问题。

Method: 使用BD-R光盘启动无状态投票软件，通过透明的交互式打印界面将纸质选票转变为交互界面，采用开源投票系统实现通用设计。

Result: 该设计结合了高可用性、可访问性和安全性，能够有效防止投票翻转问题，并使黑客攻击难以持续或不被发现。

Conclusion: STVM设计是目前最安全的投票标记设备，能够为所有选民提供安全、透明的投票体验。

Abstract: Transparency and security are essential in our voting system, and voting
machines. This paper describes an implementation of a stateless, transparent
voting machine (STVM). The STVM is a ballot marking device (BMD) that uses a
transparent, interactive printing interface where voters can verify their paper
ballots as they fill out the ballot. The transparent interface turns the paper
ballot into an interactive interface. In this architecture, stateless describes
the machine's boot sequence, where no information is stored or passed forward
between reboots. The machine does not have a hard drive. Instead, it boots and
runs from read-only media. This STVM design utilizes a Blu-ray Disc ROM (BD-R)
to boot the voting software. This system's statelessness and the transparent
interactive printing interface make this design the most secure BMD for voting.
Unlike other voting methods, this system incorporates high usability,
accessibility, and security for all voters. The STVM uses an open-source voting
system that has a universally designed interface, making the system accessible
for all voters independent of their ability or disability. This system can make
voting safer by simultaneously addressing the issue of voters noticing a vote
flip and making it difficult for a hack to persist or go unmitigated.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [10] [Learning Progression-Guided AI Evaluation of Scientific Models To Support Diverse Multi-Modal Understanding in NGSS Classroom](https://arxiv.org/abs/2509.18157)
*Leonora Kaldaras,Tingting Li,Prudence Djagba,Kevin Haudek,Joseph Krajcik*

Main category: cs.CY

TL;DR: 本文提出使用机器学习方法评估基于学习进阶的多模态科学模型和解释，为高中生电学互动理解提供个性化反馈。


<details>
  <summary>Details</summary>
Motivation: 支持文化和语言多样化的学生发展建模技能，为公平的科学评估提供替代沟通模式，同时解决传统评分耗时的问题。

Method: 利用经验证的NGSS对齐多模态学习进阶和评估工具，应用机器学习技术自动评分开放式的建模任务和简短文本解释。

Result: 展示了学习进阶如何指导基于学生思维多样性的个性化机器学习反馈设计，有效评估多模态科学理解。

Conclusion: 机器学习驱动的多模态评估方法能够支持学生的科学建模实践，促进深度科学理解，并为教育公平提供技术支撑。

Abstract: Learning Progressions (LPs) can help adjust instruction to individual
learners needs if the LPs reflect diverse ways of thinking about a construct
being measured, and if the LP-aligned assessments meaningfully measure this
diversity. The process of doing science is inherently multi-modal with
scientists utilizing drawings, writing and other modalities to explain
phenomena. Thus, fostering deep science understanding requires supporting
students in using multiple modalities when explaining phenomena. We build on a
validated NGSS-aligned multi-modal LP reflecting diverse ways of modeling and
explaining electrostatic phenomena and associated assessments. We focus on
students modeling, an essential practice for building a deep science
understanding. Supporting culturally and linguistically diverse students in
building modeling skills provides them with an alternative mode of
communicating their understanding, essential for equitable science assessment.
Machine learning (ML) has been used to score open-ended modeling tasks (e.g.,
drawings), and short text-based constructed scientific explanations, both of
which are time- consuming to score. We use ML to evaluate LP-aligned scientific
models and the accompanying short text-based explanations reflecting
multi-modal understanding of electrical interactions in high school Physical
Science. We show how LP guides the design of personalized ML-driven feedback
grounded in the diversity of student thinking on both assessment modes.

</details>


### [11] [Deleuze's "Postscript on the Societies of Control" Updated for Big Data and Predictive Analytics](https://arxiv.org/abs/2509.18194)
*James Brusseau*

Main category: cs.CY

TL;DR: 本文是对德勒兹《控制社会后记》的30年更新，分析了控制社会如何从广泛推测发展为围绕个人信息、大数据、预测分析和营销的具体经济机制。


<details>
  <summary>Details</summary>
Motivation: 探讨德勒兹控制社会概念在30年后的发展变化，特别是控制机制如何通过愉悦的激励而非禁止来实现强制。

Method: 通过理论分析和当代经济机制研究，详细描述控制社会的具体运作方式。

Result: 发现现代控制社会通过个人信息驱动的愉悦激励实现强制，而非传统的禁止手段。

Conclusion: 提出了两种与控制系统本身同样未被探索的生活策略，这些策略由特定的压迫方法所揭示和促成。

Abstract: In 1990, Gilles Deleuze published Postscript on the Societies of Control, an
introduction to the potentially suffocating reality of the nascent control
society. This thirty-year update details how Deleuze's conception has developed
from a broad speculative vision into specific economic mechanisms clustering
around personal information, big data, predictive analytics, and marketing. The
central claim is that today's advancing control society coerces without
prohibitions, and through incentives that are not grim but enjoyable, even
euphoric because they compel individuals to obey their own personal
information. The article concludes by delineating two strategies for living
that are as unexplored as control society itself because they are revealed and
then enabled by the particular method of oppression that is control.

</details>


### [12] [Algorithmic A-Legality: Shorting the Human Future through AI](https://arxiv.org/abs/2509.18195)
*Scott Veitch*

Main category: cs.CY

TL;DR: 本文纠正了当前法律和政治概念及制度能够有效监管新兴AI技术权力的错误认知，指出AI发展依赖于经济与法律权力的结合，但其技术形态已超出最严格法律政治制度的监管能力，形成"非法性"状态。


<details>
  <summary>Details</summary>
Motivation: 纠正对现有法律政治制度监管AI能力的过度乐观看法，揭示AI技术发展已超越传统监管框架的现实问题。

Method: 基于法理学分析，论证AI发展依赖经济与法律权力结合，但技术形态超出监管能力。

Result: 识别出"非法性"现象，即AI产生危害的潜力无法被传统法律政治制度约束。

Conclusion: 当前法律政治概念和制度不足以应对AI技术带来的监管挑战，需要新的监管框架。

Abstract: This article provides a necessary corrective to the belief that current legal
and political concepts and institutions are capable of holding to account the
power of new AI technologies. Drawing on jurisprudential analysis, it argues
that while the current development of AI is dependent on the combination of
economic and legal power, the technological forms that result increasingly
exceed the capacity of even the most rigorous legal and political regimes. A
situation of "a-legality" is emerging whereby the potential of AI to produce
harms cannot be restrained by conventional legal or political institutions.

</details>


### [13] [Dark and Bright Patterns in Cookie Consent Requests](https://arxiv.org/abs/2509.18210)
*Paul Graßl,Hanna Schraffenberger,Frederik Zuiderveen Borgesius,Moniek Buijzen*

Main category: cs.CY

TL;DR: 该研究通过两个在线实验探讨了暗模式（dark patterns）和亮模式（bright patterns）对用户cookie同意决策的影响，发现当前cookie同意请求的实现方式无法让用户做出有意义的选择，不符合欧盟政策制定者的意图。


<details>
  <summary>Details</summary>
Motivation: 暗模式（邪恶的设计推动）通过有说服力的界面设计引导用户行为，在cookie同意请求中越来越常见，可能破坏欧盟隐私法的原则。研究旨在调查常见设计推动对用户同意决策和感知控制的影响。

Method: 采用两个预先注册的在线实验：实验1（N=228）探索暗模式（默认设置、美学操纵、阻碍）对隐私不友好选项的影响；实验2（N=255）将设计推动方向反转至隐私友好选项（亮模式）。

Result: 实验1显示大多数参与者同意所有请求，阻碍隐私友好选项反而增加了感知控制；实验2中阻碍和默认推动有效引导用户选择隐私友好选项，但感知控制结果与实验1相同。

Conclusion: 当前cookie同意请求的实现无法让互联网用户做出有意义的选择，不符合欧盟政策制定者的意图。研究还探讨了政策制定者如何解决这一问题。

Abstract: Dark patterns are (evil) design nudges that steer people's behaviour through
persuasive interface design. Increasingly found in cookie consent requests,
they possibly undermine principles of EU privacy law. In two preregistered
online experiments we investigated the effects of three common design nudges
(default, aesthetic manipulation, obstruction) on users' consent decisions and
their perception of control over their personal data in these situations. In
the first experiment (N = 228) we explored the effects of design nudges towards
the privacy-unfriendly option (dark patterns). The experiment revealed that
most participants agreed to all consent requests regardless of dark design
nudges. Unexpectedly, despite generally low levels of perceived control,
obstructing the privacy-friendly option led to more rather than less perceived
control. In the second experiment (N = 255) we reversed the direction of the
design nudges towards the privacy-friendly option, which we title "bright
patterns". This time the obstruction and default nudges swayed people
effectively towards the privacy-friendly option, while the result regarding
perceived control stayed the same compared to Experiment 1. Overall, our
findings suggest that many current implementations of cookie consent requests
do not enable meaningful choices by internet users, and are thus not in line
with the intention of the EU policymakers. We also explore how policymakers
could address the problem.

</details>


### [14] [Microtargeted propaganda by foreign actors: An interdisciplinary exploration](https://arxiv.org/abs/2509.18211)
*Ronan Ó Fathaigh,Tom Dobber,Frederik Zuiderveen Borgesius,James Shires*

Main category: cs.CY

TL;DR: 本文探讨了外国行为体进行微观定向宣传的问题，分析了其与传统宣传的区别，并提出了欧洲立法者的应对措施。


<details>
  <summary>Details</summary>
Motivation: 研究外国行为体利用微观定向技术进行政治宣传的新现象，这种技术能够针对特定人群投放精准广告，可能对民主选举产生威胁。

Method: 通过分析俄罗斯在美国的微观定向宣传案例，比较微观定向宣传与传统宣传的区别，探讨立法应对措施。

Result: 发现微观定向宣传具有更高的精准性和隐蔽性，传统法律框架难以有效监管，需要新的立法手段。

Conclusion: 欧洲立法者需要制定专门法规来应对微观定向宣传的威胁，保护民主进程不受外国干预。

Abstract: This article discusses a problem that has received scant attention in
literature: microtargeted propaganda by foreign actors. Microtargeting involves
collecting information about people, and using that information to show them
targeted political advertisements. Such microtargeting enables advertisers to
target ads to specific groups of people, for instance people who visit certain
websites, forums, or Facebook groups. This article focuses on one type of
microtargeting: microtargeting by foreign actors. For example, Russia has
targeted certain groups in the US with ads, aiming to sow discord. Foreign
actors could also try to influence European elections, for instance by
advertising in favour of a certain political party. Foreign propaganda
possibilities existed before microtargeting. This article explores two
questions. In what ways, if any, is microtargeted propaganda by foreign actors
different from other foreign propaganda? What could lawmakers in Europe do to
mitigate the risks of microtargeted propaganda?

</details>


### [15] [A Mega-Study of Digital Twins Reveals Strengths, Weaknesses and Opportunities for Further Improvement](https://arxiv.org/abs/2509.19088)
*Tiany Peng,George Gui,Daniel J. Merlau,Grace Jiarui Fan,Malek Ben Sliman,Melanie Brucks,Eric J. Johnson,Vicki Morwitz,Abdullah Althenayyan,Silvia Bellezza,Dante Donati,Hortense Fong,Elizabeth Friedman,Ariana Guevara,Mohamed Hussein,Kinshuk Jerath,Bruce Kogut,Kristen Lane,Hannah Li,Patryk Perkowski,Oded Netzer,Olivier Toubia*

Main category: cs.CY

TL;DR: 该研究通过19项预注册研究比较了基于LLM的数字孪生与真实人类在调查和实验中的回答差异，发现数字孪生与人类回答的相关性仅为约0.2，且数字孪生的回答变异性较低。


<details>
  <summary>Details</summary>
Motivation: 验证当前基于LLM的数字孪生技术是否能准确捕捉个体在调查和实验中的真实反应，评估其在社会科学研究中的实用性。

Method: 在美国全国面板上运行19项预注册研究，基于先前收集的广泛个体数据构建LLM驱动的数字孪生，比较孪生与人类在164个结果上的回答。

Result: 数字孪生与人类回答的相关性中等（约0.2），回答变异性低于人类。虽然基于丰富个体数据构建的数字孪生能更好地捕捉参与者间的异质性，但无法准确预测特定参与者的确切回答或提高对总体均值的预测能力。

Conclusion: 当前数字孪生技术能捕捉一定程度的相对差异，但在个体层面预测和样本均值方差估计方面不可靠，使用前需要谨慎验证。

Abstract: Do "digital twins" capture individual responses in surveys and experiments?
We run 19 pre-registered studies on a national U.S. panel and their LLM-powered
digital twins (constructed based on previously-collected extensive
individual-level data) and compare twin and human answers across 164 outcomes.
The correlation between twin and human answers is modest (approximately 0.2 on
average) and twin responses are less variable than human responses. While
constructing digital twins based on rich individual-level data improves our
ability to capture heterogeneity across participants and predict relative
differences between them, it does not substantially improve our ability to
predict the exact answers given by specific participants or enhance predictions
of population means. Twin performance varies by domain and is higher among more
educated, higher-income, and ideologically moderate participants. These results
suggest current digital twins can capture some degree of relative differences
but are unreliable for individual-level predictions and sample mean and
variance estimation, underscoring the need for careful validation before use.
Our data and code are publicly available for researchers and practitioners
interested in optimizing digital twin pipelines.

</details>


### [16] [Generative Propaganda](https://arxiv.org/abs/2509.19147)
*Madeleine I. G. Daepp,Alejandro Cuevas,Robert Osazuwa Ness,Vickie Yu-Ping Wang,Bharat Kumar Nayak,Dibyendu Mishra,Ti-Chung Cheng,Shaily Desai,Joyojeet Pal*

Main category: cs.CY

TL;DR: 该研究通过访谈台湾和印度的相关从业者，分析了生成式AI在宣传中的实际应用，发现'深度伪造'概念过度影响了防御者对滥用的预期，并提出了区分明显/隐藏、推广/贬低用途的分类法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在了解生成式AI在真实世界宣传中的使用情况，特别是在台湾和印度这两个网络宣传高发地区，以更准确地描述生成式宣传的特征。

Method: 通过对台湾的防御者（事实核查员、记者、官员）和创作者（影响者、政治顾问、广告商）以及印度的防御者进行访谈，收集第一手资料。

Result: 研究发现欺骗并非AI使用的主要驱动力或影响途径，印度创作者更倾向于说服而非欺骗，台湾防御者则将欺骗视为更广泛的战略叙事扭曲的一部分。AI主要用于跨语言沟通和规避检测的效率提升。

Conclusion: 安全研究人员应重新考虑威胁模型，明确区分深度伪造与推广性明显用途，补充约束内部行为者滥用的社会因素，并应对全球范围内的效率提升挑战。

Abstract: Generative propaganda is the use of generative artificial intelligence (AI)
to shape public opinion. To characterize its use in real-world settings, we
conducted interviews with defenders (e.g., factcheckers, journalists,
officials) in Taiwan and creators (e.g., influencers, political consultants,
advertisers) as well as defenders in India, centering two places characterized
by high levels of online propaganda. The term "deepfakes", we find, exerts
outsized discursive power in shaping defenders' expectations of misuse and, in
turn, the interventions that are prioritized. To better characterize the space
of generative propaganda, we develop a taxonomy that distinguishes between
obvious versus hidden and promotional versus derogatory use. Deception was
neither the main driver nor the main impact vector of AI's use; instead, Indian
creators sought to persuade rather than to deceive, often making AI's use
obvious in order to reduce legal and reputational risks, while Taiwan's
defenders saw deception as a subset of broader efforts to distort the
prevalence of strategic narratives online. AI was useful and used, however, in
producing efficiency gains in communicating across languages and modes, and in
evading human and algorithmic detection. Security researchers should reconsider
threat models to clearly differentiate deepfakes from promotional and obvious
uses, to complement and bolster the social factors that constrain misuse by
internal actors, and to counter efficiency gains globally.

</details>


### [17] [Personalised Pricing: The Demise of the Fixed Price?](https://arxiv.org/abs/2509.18212)
*Joost Poort,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文探讨了在线价格歧视的经济理论基础、消费者态度以及GDPR法规的适用性。调查显示消费者普遍反对在线价格歧视，认为其不公平，并支持禁令。GDPR要求企业披露价格歧视行为并获得用户同意，但行业实践尚未遵循这些原则。


<details>
  <summary>Details</summary>
Motivation: 研究在线价格歧视的道德公平性问题及其监管需求，分析消费者对价格歧视的态度以及现有法规（如GDPR）的适用性。

Method: 通过经济理论分析价格歧视的基础，结合消费者调查数据评估公众对在线价格歧视的接受度，并探讨GDPR法规在价格歧视场景下的法律适用性。

Result: 消费者对在线价格歧视持批判态度，多数认为其不可接受且不公平，支持禁令并要求企业透明披露。GDPR适用于有争议的价格歧视形式，但行业实践尚未遵守披露和同意要求。

Conclusion: 在线价格歧视引发严重的公平性和道德担忧，需要监管干预。GDPR提供了法律框架，但实际执行存在差距，企业应提高透明度并获得用户同意。

Abstract: An online seller or platform is technically able to offer every consumer a
different price for the same product, based on information it has about the
customers. Such online price discrimination exacerbates concerns regarding the
fairness and morality of price discrimination, and the possible need for
regulation. In this chapter, we discuss the underlying basis of price
discrimination in economic theory, and its popular perception. Our surveys show
that consumers are critical and suspicious of online price discrimination. A
majority consider it unacceptable and unfair, and are in favour of a ban. When
stores apply online price discrimination, most consumers think they should be
informed about it. We argue that the General Data Protection Regulation (GDPR)
applies to the most controversial forms of online price discrimination, and not
only requires companies to disclose their use of price discrimination, but also
requires companies to ask customers for their prior consent. Industry practice,
however, does not show any adoption of these two principles.

</details>


### [18] [Enhanced Interpretable Knowledge Tracing for Students Performance Prediction with Human understandable Feature Space](https://arxiv.org/abs/2509.18231)
*Sein Minn,Roger Nkambou*

Main category: cs.CY

TL;DR: 本文提出通过引入人类可理解的特征来增强可解释的知识追踪模型，在保持与认知理论一致性的同时提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的知识追踪模型虽然预测准确率高，但复杂性和不透明性阻碍了提供心理学上有意义的解释，限制了在教育应用中的可信度。

Method: 探索从学生交互数据中提取人类可理解的特征，特别是反映学生学习能力的特征，并将其整合到可解释的知识追踪模型中。

Result: 增强后的方法在保持与认知理论一致性的同时提高了预测准确性。

Conclusion: 该方法在预测能力和可解释性之间取得了平衡，推动了自适应学习系统的实用性。

Abstract: Knowledge Tracing (KT) plays a central role in assessing students skill
mastery and predicting their future performance. While deep learning based KT
models achieve superior predictive accuracy compared to traditional methods,
their complexity and opacity hinder their ability to provide psychologically
meaningful explanations. This disconnect between model parameters and cognitive
theory poses challenges for understanding and enhancing the learning process,
limiting their trustworthiness in educational applications. To address these
challenges, we enhance interpretable KT models by exploring
human-understandable features derived from students interaction data. By
incorporating additional features, particularly those reflecting students
learning abilities, our enhanced approach improves predictive accuracy while
maintaining alignment with cognitive theory. Our contributions aim to balance
predictive power with interpretability, advancing the utility of adaptive
learning systems.

</details>


### [19] [Perceptions of AI Across Sectors: A Comparative Review of Public Attitudes](https://arxiv.org/abs/2509.18233)
*Filip Bialy,Mark Elliot,Robert Meckin*

Main category: cs.CY

TL;DR: 本文对2011-2025年间251项关于公众对AI态度的研究进行了跨领域比较分析，探讨了不同因素如何影响公众对AI的接受度或抵制。


<details>
  <summary>Details</summary>
Motivation: 理解公众对AI的态度在不同领域和用例中的差异，为制定更精准的负责任AI治理策略提供基础。

Method: 采用系统性文献综述方法，分析251项研究，考察感知利益、风险、制度信任、公平性和伦理关切等因素。

Result: 发现公众对AI的认知不仅受技术设计和性能影响，还受领域特定考量、文化叙事和历史遗产等因素塑造。

Conclusion: 比较方法为开发更具针对性和情境敏感性的负责任AI治理策略奠定了基础。

Abstract: This paper offers a domain-mediated comparative review of 251 studies on
public attitudes toward AI, published between 2011 and 2025. Drawing on a
systematic literature review, we analyse how different factors including
perceived benefits and concerns (or risks) shape public acceptance of - or
resistance to - artificial intelligence across domains and use-cases, including
healthcare, education, security, public administration, generative AI, and
autonomous vehicles. The analysis highlights recurring patterns in individual,
contextual, and technical factors influencing perception, while also tracing
variations in institutional trust, perceived fairness, and ethical concerns. We
show that the public perception in AI is shaped not only by technical design or
performance but also by sector-specific considerations as well as imaginaries,
cultural narratives, and historical legacies. This comparative approach offers
a foundation for developing more tailored and context-sensitive strategies for
responsible AI governance.

</details>


### [20] [An Artificial Intelligence Value at Risk Approach: Metrics and Models](https://arxiv.org/abs/2509.18394)
*Luis Enriquez Alvarez*

Main category: cs.CY

TL;DR: 本文分析了人工智能风险管理的多维性，指出当前AI风险管理方法不成熟，缺乏具有实际实施价值的指南，并强调需要为特定AI风险场景定制风险指标和模型。


<details>
  <summary>Details</summary>
Motivation: 随着新AI法规的出现，AI风险管理现状高度不成熟。财务、法律和合规部门对AI系统的技术方面了解不足，而数据科学家和AI工程师是最合适的实施者。需要从数据保护、公平性、准确性、鲁棒性和信息安全等多个维度分解AI风险问题。

Method: 本文旨在为AI利益相关者提供AI风险管理的深度指导，虽然不极其技术性，但需要风险管理、量化不确定性、FAIR模型、机器学习、大语言模型和AI上下文工程的基本知识。通过基本易懂的示例提供可在特定AI定制环境中发展的简单思路。

Result: 本文提出了AI风险管理的整体概述，展示了AI风险之间的相互依赖性，以及如何在风险场景中共同建模这些风险。

Conclusion: AI风险管理的主要任务是开发适当的指标和风险模型，以减少决策过程中的不确定性，从而就AI系统的风险管理做出明智决策。本文提供了解决AI风险管理中许多问题的框架和方法。

Abstract: Artificial intelligence risks are multidimensional in nature, as the same
risk scenarios may have legal, operational, and financial risk dimensions. With
the emergence of new AI regulations, the state of the art of artificial
intelligence risk management seems to be highly immature due to upcoming AI
regulations. Despite the appearance of several methodologies and generic
criteria, it is rare to find guidelines with real implementation value,
considering that the most important issue is customizing artificial
intelligence risk metrics and risk models for specific AI risk scenarios.
Furthermore, the financial departments, legal departments and Government Risk
Compliance teams seem to remain unaware of many technical aspects of AI
systems, in which data scientists and AI engineers emerge as the most
appropriate implementers. It is crucial to decompose the problem of artificial
intelligence risk in several dimensions: data protection, fairness, accuracy,
robustness, and information security. Consequently, the main task is developing
adequate metrics and risk models that manage to reduce uncertainty for
decision-making in order to take informed decisions concerning the risk
management of AI systems.
  The purpose of this paper is to orientate AI stakeholders about the depths of
AI risk management. Although it is not extremely technical, it requires a basic
knowledge of risk management, quantifying uncertainty, the FAIR model, machine
learning, large language models and AI context engineering. The examples
presented pretend to be very basic and understandable, providing simple ideas
that can be developed regarding specific AI customized environments. There are
many issues to solve in AI risk management, and this paper will present a
holistic overview of the inter-dependencies of AI risks, and how to model them
together, within risk scenarios.

</details>


### [21] [Large-Scale, Longitudinal Study of Large Language Models During the 2024 US Election Season](https://arxiv.org/abs/2509.18446)
*Sarah H. Cen,Andrew Ilyas,Hedi Driss,Charlotte Park,Aspen Hopkins,Chara Podimata,Aleksander Mądry*

Main category: cs.CY

TL;DR: 本文对12个大语言模型在2024年美国总统选举期间的行为进行了大规模纵向研究，分析了模型对选举相关问题的响应变化、人口统计引导敏感性、候选人属性认知以及选举结果的隐含预测。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及，2024年美国总统选举成为首个面临LLM影响的主要政治竞赛。研究旨在了解LLM如何塑造信息生态系统和影响政治话语，以及平台选举保护措施的实际效果。

Method: 采用结构化调查问卷，在2024年7月至11月期间以近每日频率对12个模型进行超过12,000个问题的查询，系统性地变化内容和格式，创建丰富数据集用于分析模型行为随时间的变化。

Result: 研究揭示了模型在选举季节的行为变化、对人口统计引导的敏感性、对候选人属性的认知以及隐含的选举结果预测，为评估LLM在选举环境中的影响提供了实证基础。

Conclusion: 该研究为未来评估LLM在选举背景下的影响提供了方法论框架和公开数据集，强调了持续监控LLM在政治话语中作用的重要性。

Abstract: The 2024 US presidential election is the first major contest to occur in the
US since the popularization of large language models (LLMs). Building on
lessons from earlier shifts in media (most notably social media's well studied
role in targeted messaging and political polarization) this moment raises
urgent questions about how LLMs may shape the information ecosystem and
influence political discourse. While platforms have announced some election
safeguards, how well they work in practice remains unclear. Against this
backdrop, we conduct a large-scale, longitudinal study of 12 models, queried
using a structured survey with over 12,000 questions on a near-daily cadence
from July through November 2024. Our design systematically varies content and
format, resulting in a rich dataset that enables analyses of the models'
behavior over time (e.g., across model updates), sensitivity to steering,
responsiveness to instructions, and election-related knowledge and "beliefs."
In the latter half of our work, we perform four analyses of the dataset that
(i) study the longitudinal variation of model behavior during election season,
(ii) illustrate the sensitivity of election-related responses to demographic
steering, (iii) interrogate the models' beliefs about candidates' attributes,
and (iv) reveal the models' implicit predictions of the election outcome. To
facilitate future evaluations of LLMs in electoral contexts, we detail our
methodology, from question generation to the querying pipeline and third-party
tooling. We also publicly release our dataset at
https://huggingface.co/datasets/sarahcen/llm-election-data-2024

</details>


### [22] [Developing a Decolonial Mindset for Indigenising Computing Education (CE)](https://arxiv.org/abs/2509.18509)
*Jianhua Li,Yin Paradies,Trina Myers,Robin Doss,Armita Zarnegar,Jack Reis*

Main category: cs.CY

TL;DR: 本文提出了一个七层框架——去殖民思维堆栈（DMS），用于教育者转型，旨在解决计算教育中第一民族代表性不足的问题，通过识别、反思、重构、重新嵌入、互惠、重新主张和复兴等步骤，促进计算教育的去殖民化。


<details>
  <summary>Details</summary>
Motivation: 计算教育中第一民族的代表性不足反映了课程、教学法和数字基础设施中根深蒂固的殖民遗留问题，需要通过去殖民化的方法进行系统性变革。

Method: 基于Freire的批判性教学法和土著方法论，DMS框架包含七个层次：识别、反思、重构、重新嵌入、互惠、重新主张和复兴，并与“关于我”、“我们之间”和“由我们”的关系视角对齐。

Result: DMS框架为教育者提供了自我反思、关系责任和土著主权在计算教育中的实践路径，将代表性不足重新定义为系统性排斥。

Conclusion: DMS不仅提供了理论基础和实践路径，还将土著化定位为对变革性正义和与第一民族共同创建计算教育的持续伦理承诺，而非终点。

Abstract: The underrepresentation of First Peoples in computing education reflects
colonial legacies embedded in curricula, pedagogies, and digital
infrastructures. This paper introduces the \textbf{Decolonial Mindset Stack
(DMS)}, a seven-layer framework for educator transformation:
\textbf{Recognition, Reflection, Reframing, Reembedding, Reciprocity,
Reclamation}, and \textbf{Resurgence}. Grounded in Freirean critical pedagogy
and Indigenous methodologies, the DMS aligns with relational lenses of ``About
Me,'' ``Between Us,'' and ``By Us.'' It fosters self-reflexivity, relational
accountability, and Indigenous sovereignty in computing education, reframing
underrepresentation as systemic exclusion. The DMS provides both theoretical
grounding and pathways for practice, positioning indigenisation not as an
endpoint but as a sustained ethical commitment to transformative justice and
the co-creation of computing education with First Peoples.

</details>


### [23] [Automatic coherence-driven inference on arguments](https://arxiv.org/abs/2509.18523)
*Steve Huntsman*

Main category: cs.CY

TL;DR: 使用大型语言模型提取法律论证中的命题，通过组合优化进行一致性驱动推理，为法律和政策分析提供技术解决方案


<details>
  <summary>Details</summary>
Motivation: 法律、行政和法理学中普遍存在不一致性问题，需要技术手段来解决这些不一致性

Method: 利用LLMs从论证中提取命题并编译成自然数据结构，通过组合优化实现一致性驱动推理的神经符号架构

Result: 该方法能够自然分离关注点，并对论证的一致性做出有意义的判断

Conclusion: 该神经符号架构可以为立法和政策分析以及法律推理提供信息支持

Abstract: Inconsistencies are ubiquitous in law, administration, and jurisprudence.
Though a cure is too much to hope for, we propose a technological remedy. Large
language models (LLMs) can accurately extract propositions from arguments and
compile them into natural data structures that enable coherence-driven
inference (CDI) via combinatorial optimization. This neurosymbolic architecture
naturally separates concerns and enables meaningful judgments about the
coherence of arguments that can inform legislative and policy analysis and
legal reasoning.

</details>


### [24] [Judging Data: Critical Discourse and the Rise of Data Intellectual Property Rights in Chinese Courts](https://arxiv.org/abs/2509.18605)
*Chanhou Lou*

Main category: cs.CY

TL;DR: 本文通过批判性话语分析展示了中国司法能动主义如何塑造数据知识产权。研究发现地方法院和最高法院采用两种互补的司法话语，形成双向概念耦合机制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示中国数据知识产权领域司法能动主义的作用机制，探讨司法系统如何在数字治理中平衡统一市场标准与防止平台垄断的关系。

Method: 采用批判性话语分析方法，分析浙江省高级人民法院和最高人民法院的司法案例，如淘宝诉美景案和反不正当竞争司法解释。

Result: 识别出两种互补的司法话语：地方法院的司法延续话语和最高法院的司法联动话语，它们形成双向概念耦合机制，既合法化又约束法院和政策制定者。

Conclusion: 数据知识产权成为中国数字治理中法律创新和制度协调的试验场，展示了司法系统在平衡市场统一与反垄断方面的独特作用。

Abstract: This paper uses Critical Discourse Analysis (CDA) to show how Sino-judicial
activism shapes Data Intellectual Property Rights (DIPR) in China. We identify
two complementary judicial discourses. Local courts (exemplified by the
Zhejiang High People's Court, HCZJ) use a judicial continuation discourse that
extends intellectual property norms to data disputes. The Supreme People's
Court (SPC) deploys a judicial linkage discourse that aligns adjudication with
state policy and administrative governance. Their interaction forms a
bidirectional conceptual coupling (BCC): an inside-out projection of local
reasoning and an outside-in translation of policy into doctrine. The coupling
both legitimizes and constrains courts and policymakers, balancing pressure for
unified market standards with safeguards against platform monopolization.
Through cases such as HCZJ's Taobao v. Meijing and the SPC's Anti-Unfair
Competition Interpretation, the study presents DIPR as a testbed for doctrinal
innovation and institutional coordination in China's evolving digital
governance.

</details>


### [25] [Purer than pure: how purity reshapes the upstream materiality of the semiconductor industry](https://arxiv.org/abs/2509.18768)
*Gauthier Roussilhe,Thibault Pirson,David Bol,Srinjoy Mitra*

Main category: cs.CY

TL;DR: 本文探讨了数字部门的环境影响，特别是半导体行业对多种元素及其纯度要求的影响，揭示了数字部门对大规模生产工业部门的依赖。


<details>
  <summary>Details</summary>
Motivation: 数字部门的环境影响日益受到关注，但现有研究往往局限于少数矿物（如钴、锂）。本文旨在通过半导体行业的元素多样性和纯度要求，进一步探索数字部门的物质性。

Method: 采用基于元素多样性和纯度要求的方法，研究半导体行业中的关键公司，分析其在复杂供应链中的角色。

Result: 研究发现半导体行业对超高纯度材料的需求非常特殊，揭示了数字部门对其他大规模生产工业部门的强依赖关系，特别是与化学工业的互动需要进一步研究。

Conclusion: 数字部门的物质性不仅限于采矿活动，还需深入探讨其与化学工业等部门的互动，以全面理解其环境影响。

Abstract: Growing attention is given to the environmental impacts of the digital
sector, exacerbated by the increase of digital products and services in our
globalized societies. The materiality of the digital sector is often presented
through the environmental impacts of mining activities to point out that
digitization does not mean dematerialization. Despite its importance, such a
narrative is often restricted to a few minerals (e.g., cobalt, lithium) that
have become the symbols of extractive industries. In this paper, we further
explore the materiality of the digital sector with an approach based on the
diversity of elements and their purity requirements in the semiconductor
industry. Semiconductors are responsible for manufacturing the key building
blocks of the digital sector, i.e., microchips. Given that the need for
ultra-high purity materials is very specific to the semiconductor industry, a
few companies around the world have been studied, revealing new critical actors
in complex supply chains. This highlights strong dependencies towards other
industrial sectors with mass production and the need for a deeper investigation
of interactions with the chemical industry, complementary to the mining
industry.

</details>


### [26] [The AI Literacy Heptagon: A Structured Approach to AI Literacy in Higher Education](https://arxiv.org/abs/2509.18900)
*Veronika Hackl,Alexandra Mueller,Maximilian Sailer*

Main category: cs.CY

TL;DR: 该论文通过整合性文献综述，探讨了高等教育中AI素养的概念化和实施，提出了AI素养七边形模型，包含七个核心维度，旨在弥合理论概念与实践应用之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前AI素养在高等教育中的概念定义模糊且缺乏统一框架，需要系统梳理现有研究，建立清晰的概念边界和实用实施指南。

Method: 采用整合性文献综述方法，分析2021-2024年的相关研究文献，系统梳理AI素养的定义、概念化及其与相关素养概念的区分。

Result: 识别出AI素养的七个核心维度（技术、应用、批判性思维、伦理、社会、整合、法律），并构建了AI素养七边形模型。

Conclusion: 研究为高等教育中的AI素养教育提供了理论框架和实践指导，有助于系统化地开发和实施AI素养课程。

Abstract: The integrative literature review addresses the conceptualization and
implementation of AI Literacy (AIL) in Higher Education (HE) by examining
recent research literature. Through an analysis of publications (2021-2024), we
explore (1) how AIL is defined and conceptualized in current research,
particularly in HE, and how it can be delineated from related concepts such as
Data Literacy, Media Literacy, and Computational Literacy; (2) how various
definitions can be synthesized into a comprehensive working definition, and (3)
how scientific insights can be effectively translated into educational
practice. Our analysis identifies seven central dimensions of AIL: technical,
applicational, critical thinking, ethical, social, integrational, and legal.
These are synthesized in the AI Literacy Heptagon, deepening conceptual
understanding and supporting the structured development of AIL in HE. The study
aims to bridge the gap between theoretical AIL conceptualizations and the
practical implementation in academic curricula.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [27] [An Advection-Difusion Model Incorporating Investor Inertia for the Dynamics of Financial Asset Prices](https://arxiv.org/abs/2509.18488)
*Diego,Gustavo*

Main category: econ.TH

TL;DR: 本文提出了一个包含投资者惯性的股票价格动态模型，将资产对数价格建模为三状态离散随机游走，推导出对流-扩散偏微分方程，证明了对数价格服从正态分布。


<details>
  <summary>Details</summary>
Motivation: 标准资产价格动态模型（如几何布朗运动）未正式纳入投资者惯性概念，本文旨在填补这一空白。

Method: 采用受扩散保留模型启发的三状态离散随机游走框架，允许价格向上、向下或中性移动，推导出包含漂移项的对流-扩散偏微分方程。

Result: 模型显示对数价格服从正态分布，具有分析易处理性，通过巴西PETR4.SA数据的模拟和实证应用验证了模型适用性。

Conclusion: 该框架成功将投资者惯性纳入价格动态模型，为资产定价提供了新的理论工具，具有重要的实际应用价值。

Abstract: Standard models of asset price dynamics, such as geometric Brownian motion
(Osborne, 1959, Samuelson, 2016), do not formally incorporate investor inertia.
This paper introduces a novel framework for modelling stock price dynamics that
incorporates the concept of investor inertia, inspired by diffusion with
retention models (Bevilacqua, 2011). The asset's log-price is modelled as a
three-state discrete random walk, allowing for movements in any of three
directions: up, down, or neutral. We demonstrate that this framework naturally
leads to an advection-diffusion partial differential equation, in which the
advection (drift) term arises directly from the asymmetry between buying,
selling, and holding decisions. Remarkably, the model implies that log-prices
follow a normal distribution a finding of great practical interest due to its
analytical tractability. The applicability of the model is confirmed through
simulation and an empirical application using Brazilian PETR4.SA data.

</details>


### [28] [Existence and Calculation of Optimal Equilibria on Overlapping Generations Economies](https://arxiv.org/abs/2509.19019)
*Leandro Lyra Braga Dognini*

Main category: econ.TH

TL;DR: 本文开发了一种算法，通过嵌套紧集逼近非平稳消费贷款重叠世代经济中的均衡，证明了有效均衡的存在性。


<details>
  <summary>Details</summary>
Motivation: 重叠世代经济中第一福利定理失效，均衡可能无效。Cass准则提供了效率的必要充分条件，但未解决有效均衡存在性问题，且存在不存在有效均衡的例子。

Method: 基于有限寿命异质代理人的非平稳消费贷款经济的连续逼近算法，通过均衡方程的后向计算，从表现良好的尾部经济的帕累托最优均衡出发，找到均衡集的元素作为嵌套紧集的极限。

Result: 通过该算法计算的均衡满足Cass准则，并用于推导有效均衡的存在性结果。

Conclusion: 该算法为重叠世代经济中有效均衡的存在性提供了理论支持，解决了Cass等人提出的不存在性问题。

Abstract: A well-known feature of overlapping generations economies is that the First
Welfare Theorem fails and equilibrium may be inefficient. The Cass (1972)
criterion furnishes a necessary and sufficient condition for efficiency, but
does not address the matter of existence of efficient equilibria, and Cass,
Okuno, and Zilcha (1979) provide nonexistence examples. I develop an algorithm
based on successive approximations of a nonstationary, consumption-loan, prone
to savings, overlapping generations economy with finite-lived heterogeneous
agents to find elements of its set of equilibria as the limit of nested compact
sets. These compact sets are the result of a backward calculation through
equilibrium equations that departs from the set of Pareto optimal equilibria of
well-behaved tail economies. The equilibria calculated through this algorithm
satisfy the Cass (1972) criterion and are used to derive the existence results
on efficient equilibria.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services](https://arxiv.org/abs/2509.18101)
*Guanzhong Pan,Haibo Wang*

Main category: cs.AI

TL;DR: 本文提出了一个成本效益分析框架，帮助组织评估本地部署开源LLM与商业订阅服务的经济可行性


<details>
  <summary>Details</summary>
Motivation: 组织在使用AI时面临选择商业LLM服务还是本地部署的决策难题，需要考虑数据隐私、供应商锁定和长期运营成本等因素

Method: 通过分析硬件需求、运营费用和开源模型性能基准，将本地部署总成本与主要云服务商的订阅费用进行比较

Result: 研究提供了基于使用水平和性能需求的盈亏平衡点估计

Conclusion: 结果为组织制定LLM战略提供了实用的决策框架

Abstract: Large language models (LLMs) are becoming increasingly widespread.
Organizations that want to use AI for productivity now face an important
decision. They can subscribe to commercial LLM services or deploy models on
their own infrastructure. Cloud services from providers such as OpenAI,
Anthropic, and Google are attractive because they provide easy access to
state-of-the-art models and are easy to scale. However, concerns about data
privacy, the difficulty of switching service providers, and long-term operating
costs have driven interest in local deployment of open-source models. This
paper presents a cost-benefit analysis framework to help organizations
determine when on-premise LLM deployment becomes economically viable compared
to commercial subscription services. We consider the hardware requirements,
operational expenses, and performance benchmarks of the latest open-source
models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost
of deploying these models locally with the major cloud providers subscription
fee. Our findings provide an estimated breakeven point based on usage levels
and performance needs. These results give organizations a practical framework
for planning their LLM strategies.

</details>


### [30] [SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture](https://arxiv.org/abs/2509.18123)
*Yeonju Lee,Rui Qi Chen,Joseph Oboamah,Po Nien Su,Wei-zhen Liang,Yeyin Shi,Lu Gan,Yongsheng Chen,Xin Qiao,Jing Li*

Main category: cs.AI

TL;DR: SPADE是一个基于大语言模型的土壤水分时间序列分析框架，能够零样本检测灌溉模式和异常，无需特定任务标注或微调。


<details>
  <summary>Details</summary>
Motivation: 现有土壤水分时间序列分析方法依赖基于阈值的规则或数据密集型机器学习模型，存在适应性差和可解释性弱的问题。

Method: 利用ChatGPT-4.1的推理能力，将时间序列数据转换为文本表示，通过领域知识设计的提示模板进行零样本分析，检测灌溉事件、估计灌溉增益、分类异常。

Result: 在真实农场数据上，SPADE在异常检测方面优于现有方法，召回率和F1分数更高，灌溉事件检测精度和召回率也很高。

Conclusion: LLMs可作为精准农业的可扩展、适应性强的工具，整合定性知识和数据驱动推理，为土壤水分监测和灌溉调度提供可操作见解。

Abstract: Accurate interpretation of soil moisture patterns is critical for irrigation
scheduling and crop management, yet existing approaches for soil moisture
time-series analysis either rely on threshold-based rules or data-hungry
machine learning or deep learning models that are limited in adaptability and
interpretability. In this study, we introduce SPADE (Soil moisture Pattern and
Anomaly DEtection), an integrated framework that leverages large language
models (LLMs) to jointly detect irrigation patterns and anomalies in soil
moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced
reasoning and instruction-following capabilities, enabling zero-shot analysis
without requiring task-specific annotation or fine-tuning. By converting
time-series data into a textual representation and designing domain-informed
prompt templates, SPADE identifies irrigation events, estimates net irrigation
gains, detects, classifies anomalies, and produces structured, interpretable
reports. Experiments were conducted on real-world soil moisture sensor data
from commercial and experimental farms cultivating multiple crops across the
United States. Results demonstrate that SPADE outperforms the existing method
in anomaly detection, achieving higher recall and F1 scores and accurately
classifying anomaly types. Furthermore, SPADE achieved high precision and
recall in detecting irrigation events, indicating its strong capability to
capture irrigation patterns accurately. SPADE's reports provide
interpretability and usability of soil moisture analytics. This study
highlights the potential of LLMs as scalable, adaptable tools for precision
agriculture, which is capable of integrating qualitative knowledge and
data-driven reasoning to produce actionable insights for accurate soil moisture
monitoring and improved irrigation scheduling from soil moisture time-series
data.

</details>


### [31] [Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI](https://arxiv.org/abs/2509.18132)
*Xiuyi Fan*

Main category: cs.AI

TL;DR: 该论文提出了可解释不确定性估计（XUE）框架，将可解释性与不确定性量化相结合，以解决医疗AI中不确定性沟通不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI系统未能以符合临床推理的方式明确量化或沟通不确定性，现有可解释AI方法缺乏对预测置信度的捕捉，而不确定性估计技术又缺乏直观解释，这种脱节限制了AI在医学中的应用。

Method: 提出XUE框架，系统地将医学不确定性映射到AI不确定性概念，识别XUE实施的关键挑战，并规划技术方向包括多模态不确定性量化、模型无关可视化技术和不确定性感知决策支持系统。

Result: 建立了将可解释性与不确定性量化整合的理论框架，为开发更可信的医疗AI系统提供了指导原则和技术路径。

Conclusion: 这项工作通过桥接可解释性和不确定性，为开发与真实世界临床复杂性相一致的AI系统铺平了道路，有助于构建可信赖的医疗AI。

Abstract: Uncertainty is a fundamental challenge in medical practice, but current
medical AI systems fail to explicitly quantify or communicate uncertainty in a
way that aligns with clinical reasoning. Existing XAI works focus on
interpreting model predictions but do not capture the confidence or reliability
of these predictions. Conversely, uncertainty estimation (UE) techniques
provide confidence measures but lack intuitive explanations. The disconnect
between these two areas limits AI adoption in medicine. To address this gap, we
propose Explainable Uncertainty Estimation (XUE) that integrates explainability
with uncertainty quantification to enhance trust and usability in medical AI.
We systematically map medical uncertainty to AI uncertainty concepts and
identify key challenges in implementing XUE. We outline technical directions
for advancing XUE, including multimodal uncertainty quantification,
model-agnostic visualization techniques, and uncertainty-aware decision support
systems. Lastly, we propose guiding principles to ensure effective XUE
realisation. Our analysis highlights the need for AI systems that not only
generate reliable predictions but also articulate confidence levels in a
clinically meaningful way. This work contributes to the development of
trustworthy medical AI by bridging explainability and uncertainty, paving the
way for AI systems that are aligned with real-world clinical complexities.

</details>


### [32] [HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics](https://arxiv.org/abs/2509.18168)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: HSGM是一种分层段图记忆框架，通过将长文档分解为有意义的段，构建局部语义图并提取摘要节点来降低语义解析的计算复杂度和内存需求。


<details>
  <summary>Details</summary>
Motivation: 长文档语义解析面临二次复杂度增长和内存需求过高的挑战，需要一种可扩展的解决方案来支持超长文本的实时处理。

Method: 将输入文档分解为M个段，在每个段上构建局部语义图，提取摘要节点形成全局图记忆，支持增量更新和分层查询处理。

Result: 在三个基准测试中，HSGM实现了2-4倍推理加速，峰值内存减少>60%，准确率保持基线95%以上。

Conclusion: HSGM为超长文本提供了可扩展、准确的语义建模方法，支持实时和资源受限的NLP应用。

Abstract: Semantic parsing of long documents remains challenging due to quadratic
growth in pairwise composition and memory requirements. We introduce
\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that
decomposes an input of length $N$ into $M$ meaningful segments, constructs
\emph{Local Semantic Graphs} on each segment, and extracts compact
\emph{summary nodes} to form a \emph{Global Graph Memory}. HSGM supports
\emph{incremental updates} -- only newly arrived segments incur local graph
construction and summary-node integration -- while \emph{Hierarchical Query
Processing} locates relevant segments via top-$K$ retrieval over summary nodes
and then performs fine-grained reasoning within their local graphs.
  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to
$O\!\left(N\,k + (N/k)^2\right)$, with segment size $k \ll N$, and we derive
Frobenius-norm bounds on the approximation error introduced by node
summarization and sparsification thresholds. Empirically, on three benchmarks
-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),
and legal event extraction -- HSGM achieves \emph{2--4$\times$ inference
speedup}, \emph{$>60\%$ reduction} in peak memory, and \emph{$\ge 95\%$} of
baseline accuracy. Our approach unlocks scalable, accurate semantic modeling
for ultra-long texts, enabling real-time and resource-constrained NLP
applications.

</details>


### [33] [Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](https://arxiv.org/abs/2509.18178)
*Ling Yue,Nithin Somasekharan,Tingwen Zhang,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent是一个基于多智能体框架的端到端OpenFOAM工作流自动化系统，能够通过自然语言提示自动完成CFD仿真的预处理、网格生成、HPC脚本生成和后处理可视化等全流程。


<details>
  <summary>Details</summary>
Motivation: 传统CFD仿真工具学习曲线陡峭且设置复杂，存在较高的使用门槛。为了解决这些问题，作者开发了Foam-Agent来降低CFD仿真的专业知识要求。

Method: 采用多智能体框架，使用Model Context Protocol（MCP）将核心功能暴露为可调用工具，通过层次化多索引RAG实现高精度上下文检索，并采用依赖感知的生成过程确保配置一致性。

Result: 在110个仿真任务的基准测试中，Foam-Agent使用Claude 3.5 Sonnet达到了88.2%的成功率，显著优于现有框架（MetaOpenFOAM为55.5%）。

Conclusion: Foam-Agent显著降低了CFD仿真的专业门槛，展示了专用多智能体系统如何使复杂的科学计算民主化。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in
engineering, yet its steep learning curve and complex manual setup create
significant barriers. To address these challenges, we introduce Foam-Agent, a
multi-agent framework that automates the entire end-to-end OpenFOAM workflow
from a single natural language prompt. Our key innovations address critical
gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:
Foam-Agent is the first system to manage the full simulation pipeline,
including advanced pre-processing with a versatile Meshing Agent capable of
handling external mesh files and generating new geometries via Gmsh, automatic
generation of HPC submission scripts, and post-simulation visualization via
ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,
the framework uses Model Context Protocol (MCP) to expose its core functions as
discrete, callable tools. This allows for flexible integration and use by other
agentic systems, such as Claude-code, for more exploratory workflows. 3.
High-Fidelity Configuration Generation: We achieve superior accuracy through a
Hierarchical Multi-Index RAG for precise context retrieval and a
dependency-aware generation process that ensures configuration consistency.
Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%
success rate with Claude 3.5 Sonnet, significantly outperforming existing
frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the
expertise barrier for CFD, demonstrating how specialized multi-agent systems
can democratize complex scientific computing. The code is public at
https://github.com/csml-rpi/Foam-Agent.

</details>


### [34] [Large Language Models and Operations Research: A Structured Survey](https://arxiv.org/abs/2509.18180)
*Yang Wang,Kai Li*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型（LLMs）在运筹学（OR）领域的应用进展，主要涵盖自动建模、辅助优化和直接求解三个方向，并讨论了当前挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学方法依赖专家建模和手动参数调整，难以处理大规模、动态、多约束问题。LLMs通过语义理解、结构化生成和推理控制，有望解决这些局限性。

Method: 将LLMs与OR集成的方法分为三类：自动建模（将自然语言描述转换为数学模型或可执行代码）、辅助优化（生成启发式算法、进化算法）和直接求解优化任务。

Result: LLMs在OR领域显示出巨大潜力，能够提高问题求解效率，但面临语义到结构映射不稳定、研究进展碎片化、泛化能力有限和评估体系不足等挑战。

Conclusion: LLMs为OR领域带来新的机遇，未来需要解决现有挑战，探索更有效的集成方法，推动LLMs在复杂系统决策中的更广泛应用。

Abstract: Operations research (OR) provides fundamental methodologies for complex
system decision-making, with established applications in transportation, supply
chain management, and production scheduling. Traditional approaches, which
depend on expert-based modeling and manual parameter adjustment, often face
challenges in handling large-scale, dynamic, and multi-constraint problems.
Recently, large language models (LLMs) have shown potential to address these
limitations through semantic understanding, structured generation, and
reasoning control. LLMs can translate natural language descriptions into
mathematical models or executable code, generate heuristics, evolve algorithms,
and directly tackle optimization tasks. This paper surveys recent progress on
the integration of LLMs into OR, organizing methods into three main directions:
automatic modeling, auxiliary optimization, and direct solving. It further
reviews evaluation benchmarks and domain-specific applications, and summarizes
key open issues such as unstable semantic-to-structure mapping, fragmented
research progress, limited generalization, and insufficient evaluation systems.
Finally, the survey outlines possible research avenues for advancing the role
of LLMs in OR.

</details>


### [35] [Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling](https://arxiv.org/abs/2509.18181)
*Mustafa Sameen,Xiaojian Zhang,Xilei Zhao*

Main category: cs.AI

TL;DR: 本文提出了SAPA框架，利用大语言模型合成理论驱动的潜在态度来预测网约车选择，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有网约车选择预测模型因无法捕捉关键心理因素而预测精度有限，且面临严重的类别不平衡问题（网约车出行仅占日常出行的一小部分）。

Method: SAPA框架采用分层方法：首先用LLM从原始出行调查数据生成定性旅行者画像，然后训练倾向得分模型，再用LLM为理论驱动的潜在变量分配定量分数，最后通过分类器整合倾向得分、潜在变量分数和可观测出行属性来预测网约车选择。

Result: 在大规模多年出行调查上的实验表明，SAPA显著优于最先进的基线方法，在测试集上的PR-AUC指标提升了高达75.9%。

Conclusion: 该研究为准确预测网约车选择提供了强大工具，其方法论可轻松迁移到各种应用中。

Abstract: Accurate modeling of ridesourcing mode choices is essential for designing and
implementing effective traffic management policies for reducing congestion,
improving mobility, and allocating resources more efficiently. Existing models
for predicting ridesourcing mode choices often suffer from limited predictive
accuracy due to their inability to capture key psychological factors, and are
further challenged by severe class imbalance, as ridesourcing trips comprise
only a small fraction of individuals' daily travel. To address these
limitations, this paper introduces the Synthesizing Attitudes, Predicting
Actions (SAPA) framework, a hierarchical approach that uses Large Language
Models (LLMs) to synthesize theory-grounded latent attitudes to predict
ridesourcing choices. SAPA first uses an LLM to generate qualitative traveler
personas from raw travel survey data and then trains a propensity-score model
on demographic and behavioral features, enriched by those personas, to produce
an individual-level score. Next, the LLM assigns quantitative scores to
theory-driven latent variables (e.g., time and cost sensitivity), and a final
classifier integrates the propensity score, latent-variable scores (with their
interaction terms), and observable trip attributes to predict ridesourcing mode
choice. Experiments on a large-scale, multi-year travel survey show that SAPA
significantly outperforms state-of-the-art baselines, improving ridesourcing
choice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.
This study provides a powerful tool for accurately predicting ridesourcing mode
choices, and provides a methodology that is readily transferable to various
applications.

</details>


### [36] [An Outcome-Based Educational Recommender System](https://arxiv.org/abs/2509.18186)
*Nursultan Askarbekuly,Timur Fayzrakhmanov,Sladjan Babarogić,Ivan Luković*

Main category: cs.AI

TL;DR: OBER是一个基于学习成果的教育推荐系统，通过将学习成果和评估项目嵌入数据模式，使任何推荐算法都能根据其促进的学习掌握程度进行评估。


<details>
  <summary>Details</summary>
Motivation: 大多数教育推荐系统仅基于点击或评分相关性进行调优和评估，无法衡量其真实的教学影响。需要一种能够直接评估推荐系统对学习成果影响的方法。

Method: OBER采用简约的实体关系模型、基于日志的掌握度公式和插件架构，在非正式学习领域的电子学习系统中进行了为期两周的随机分组测试，比较了固定专家路径、协同过滤和基于知识的过滤三种方法。

Result: 协同过滤方法最大化了用户留存率，但固定路径方法实现了最高的学习掌握度。OBER可以从相同的日志数据中导出业务、相关性和学习指标。

Conclusion: OBER框架是方法无关的，允许从业者在相关性、参与度和学习成果掌握度之间进行权衡，无需额外的测试开销，并且易于扩展到未来的自适应或情境感知推荐系统。

Abstract: Most educational recommender systems are tuned and judged on click- or
rating-based relevance, leaving their true pedagogical impact unclear. We
introduce OBER-an Outcome-Based Educational Recommender that embeds learning
outcomes and assessment items directly into the data schema, so any algorithm
can be evaluated on the mastery it fosters. OBER uses a minimalist
entity-relation model, a log-driven mastery formula, and a plug-in
architecture. Integrated into an e-learning system in non-formal domain, it was
evaluated trough a two-week randomized split test with over 5 700 learners
across three methods: fixed expert trajectory, collaborative filtering (CF),
and knowledge-based (KB) filtering. CF maximized retention, but the fixed path
achieved the highest mastery. Because OBER derives business, relevance, and
learning metrics from the same logs, it lets practitioners weigh relevance and
engagement against outcome mastery with no extra testing overhead. The
framework is method-agnostic and readily extensible to future adaptive or
context-aware recommenders.

</details>


### [37] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 提出了MMCD框架，通过多模态协作决策和跨模态知识蒸馏，解决自动驾驶中传感器故障或连接车辆缺失时的鲁棒决策问题


<details>
  <summary>Details</summary>
Motivation: 现有方法假设训练和测试时所有数据模态和连接车辆都可用，这在传感器故障或连接车辆缺失时不现实，需要更鲁棒的决策框架

Method: MMCD框架融合自车和协作车辆的多模态观测数据，采用教师-学生模型的跨模态知识蒸馏方法，教师模型使用多模态数据训练，学生模型在模态减少时仍能有效运行

Result: 在连接自动驾驶和空地车辆协作实验中，该方法将驾驶安全性提高了20.7%，在潜在事故检测和安全驾驶决策方面优于现有最佳基线

Conclusion: MMCD框架通过多模态协作和知识蒸馏有效提升了自动驾驶系统在挑战性环境中的鲁棒性和安全性

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


### [38] [Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations](https://arxiv.org/abs/2509.18215)
*Timotheus Kampik,Kristijonas Čyras,José Ruiz Alarcón*

Main category: cs.AI

TL;DR: 本文提出了一种形式化方法来解释定量双极论证框架（QBAF）中推理变化的原因，通过追踪论证强度部分顺序的变化来识别强度不一致性，并提供基于启发式的解释搜索方法。


<details>
  <summary>Details</summary>
Motivation: 在QBAF中进行推理并更新框架后，论证强度的部分顺序可能发生变化，这种强度不一致性需要被解释。本文旨在开发一种系统方法来追踪和解释这些变化。

Method: 通过追踪主题论证强度部分顺序的变化来识别强度不一致性，将原因追溯到特定论证，定义充分、必要和反事实解释，并开发基于启发式的解释搜索算法。

Result: 证明了强度不一致性解释存在的充要条件是更新导致强度不一致性，并提供了相应的实现。

Conclusion: 该方法能够有效解释QBAF中推理变化的原因，为理解论证框架的动态演化提供了理论工具。

Abstract: This paper presents a formal approach to explaining change of inference in
Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions
from a QBAF and updating the QBAF to then again draw conclusions (and so on),
our approach traces changes -- which we call strength inconsistencies -- in the
partial order over argument strengths that a semantics establishes on some
arguments of interest, called topic arguments. We trace the causes of strength
inconsistencies to specific arguments, which then serve as explanations. We
identify sufficient, necessary, and counterfactual explanations for strength
inconsistencies and show that strength inconsistency explanations exist if and
only if an update leads to strength inconsistency. We define a heuristic-based
approach to facilitate the search for strength inconsistency explanations, for
which we also provide an implementation.

</details>


### [39] [nDNA -- the Semantic Helix of Artificial Cognition](https://arxiv.org/abs/2509.18216)
*Amitava Das*

Main category: cs.AI

TL;DR: 该论文提出了神经DNA（nDNA）作为捕捉AI基础模型潜在认知身份的语义-基因型表示，通过三个几何维度来量化模型的内在信念几何结构。


<details>
  <summary>Details</summary>
Motivation: 随着AI基础模型能力的增长，需要超越行为基准来理解模型的内在认知身份，揭示模型潜在几何结构中的"灵魂"。

Method: 提出nDNA表示方法，基于三个几何维度：谱曲率（揭示概念流动的曲率）、热力学长度（量化语义转换的努力）、信念向量场（描述信念方向导向的语义扭转场）。

Result: nDNA能够稳定地捕捉模型的语义流动特征，实现模型谱系追踪、继承关系测量、漂移检测等功能。

Conclusion: 这项工作开启了神经基因组学新领域，将AI模型视为具有可追溯内在认知的数字语义有机体，为模型比较、风险诊断和演化研究提供了新方法。

Abstract: As AI foundation models grow in capability, a deeper question emerges: What
shapes their internal cognitive identity -- beyond fluency and output?
Benchmarks measure behavior, but the soul of a model resides in its latent
geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic
representation that captures this latent identity through the intrinsic
geometry of belief. At its core, nDNA is synthesized from three principled and
indispensable dimensions of latent geometry: spectral curvature, which reveals
the curvature of conceptual flow across layers; thermodynamic length, which
quantifies the semantic effort required to traverse representational
transitions through layers; and belief vector field, which delineates the
semantic torsion fields that guide a model's belief directional orientations.
Like biological DNA, it encodes ancestry, mutation, and semantic inheritance,
found in finetuning and alignment scars, cultural imprints, and architectural
drift. In naming it, we open a new field: Neural Genomics, where models are not
just tools, but digital semantic organisms with traceable inner cognition.
  Modeling statement. We read AI foundation models as semantic fluid--dynamics:
meaning is transported through layers like fluid in a shaped conduit; nDNA is
the physics-grade readout of that flow -- a geometry-first measure of how
meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free
neural DNA fingerprint tied to on-input behavior; with this fingerprint we
cross into biology: tracing lineages across pretraining, fine-tuning,
alignment, pruning, distillation, and merges; measuring inheritance between
checkpoints; detecting drift as traits shift under new data or objectives; and,
ultimately, studying the evolution of artificial cognition to compare models,
diagnose risks, and govern change over time.

</details>


### [40] [Similarity Field Theory: A Mathematical Framework for Intelligence](https://arxiv.org/abs/2509.18218)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 本文提出了相似性场理论，这是一个数学框架，用于形式化实体间相似性关系及其演化的原则。该理论定义了相似性场、系统演化、概念纤维和生成算子，并基于此形式化地定义了智能的概念。


<details>
  <summary>Details</summary>
Motivation: 作者认为持久化和转换相似性关系构成了任何可理解动态系统的结构基础。需要建立一个数学框架来形式化相似性值的原则及其演化，为描述、比较和构建智能系统提供基础语言。

Method: 定义了相似性场S: U×U→[0,1]，满足自反性但允许不对称性和非传递性；系统演化序列Z_p=(X_p,S^(p))；概念K诱导的纤维F_α(K)；生成算子G。基于此框架形式化智能的定义。

Result: 证明了两个定理：(i)不对称性阻碍相互包含；(ii)稳定性需要锚坐标或最终限制在f的水平集内。这些结果确保相似性场演化既受约束又可解释。

Conclusion: 相似性场理论为描述智能系统提供了基础框架，并展示了如何用该框架解释大语言模型，将其作为社会认知的实验探针。

Abstract: We posit that persisting and transforming similarity relations form the
structural basis of any comprehensible dynamic system. This paper introduces
Similarity Field Theory, a mathematical framework that formalizes the
principles governing similarity values among entities and their evolution. We
define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of
entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed
relational field (asymmetry and non-transitivity are allowed); (2) the
evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by
$p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers
$F_{\alpha}(K) = { E \in U \mid S(E,K) \ge \alpha }$, i.e., superlevel sets of
the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that
produces new entities. Within this framework, we formalize a generative
definition of intelligence: an operator $G$ is intelligent with respect to a
concept $K$ if, given a system containing entities belonging to the fiber of
$K$, it generates new entities that also belong to that fiber. Similarity Field
Theory thus offers a foundational language for characterizing, comparing, and
constructing intelligent systems. We prove two theorems: (i) asymmetry blocks
mutual inclusion; and (ii) stability requires either an anchor coordinate or
eventual confinement within a level set of $f$. These results ensure that the
evolution of similarity fields is both constrained and interpretable,
culminating in an exploration of how the framework allows us to interpret large
language models and use them as experimental probes into societal cognition.

</details>


### [41] [Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models](https://arxiv.org/abs/2509.18221)
*Dingxin Lu,Shurui Wu,Xinyi Huang*

Main category: cs.AI

TL;DR: VL-RiskFormer是一个用于预测个体健康风险的多模态AI框架，结合视觉和语言信息，在MIMIC-IV数据集上取得了0.90的AUROC。


<details>
  <summary>Details</summary>
Motivation: 随着慢性疾病负担增加和多模态临床数据的涌现，需要统一的AI框架来主动预测个体健康风险。

Method: 采用分层堆叠的视觉-语言多模态Transformer架构，包含四个关键创新：跨模态预训练、时间融合块、疾病本体图适配器和LLM推理头。

Result: 在MIMIC-IV纵向队列中，平均AUROC达到0.90，预期校准误差为2.7%。

Conclusion: VL-RiskFormer展示了在多模态医疗数据上进行健康风险预测的有效性，为个性化医疗提供了有力工具。

Abstract: With the rising global burden of chronic diseases and the multimodal and
heterogeneous clinical data (medical imaging, free-text recordings, wearable
sensor streams, etc.), there is an urgent need for a unified multimodal AI
framework that can proactively predict individual health risks. We propose
VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer
with a large language model (LLM) inference head embedded in its top layer. The
system builds on the dual-stream architecture of existing visual-linguistic
models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with
cross-modal comparison and fine-grained alignment of radiological images,
fundus maps, and wearable device photos with corresponding clinical narratives
using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion
block that integrates irregular visit sequences into the causal Transformer
decoder through adaptive time interval position coding; (iii) a disease
ontology map adapter that injects ICD-10 codes into visual and textual channels
in layers and infers comorbid patterns with the help of a graph attention
mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an
average AUROC of 0.90 with an expected calibration error of 2.7 percent.

</details>


### [42] [From "What to Eat?" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation](https://arxiv.org/abs/2509.18226)
*Yu Fu,Linyue Cai,Ruoyu Wu,Yong Zhao*

Main category: cs.AI

TL;DR: ChefMind是一个结合了探索链、知识图谱、检索增强生成和大语言模型的混合架构，用于解决个性化食谱推荐中的模糊用户意图、语义准确性和细节覆盖问题。


<details>
  <summary>Details</summary>
Motivation: 个性化食谱推荐面临处理模糊用户意图、确保语义准确性和提供足够细节覆盖的挑战。

Method: 提出ChefMind混合架构：探索链(CoE)将模糊查询精炼为结构化条件，知识图谱(KG)提供语义推理和可解释性，检索增强生成(RAG)补充上下文烹饪细节，大语言模型(LLM)将输出整合为连贯推荐。

Result: 在Xiachufang数据集和手动标注查询上的评估显示，ChefMind在准确性、相关性、完整性和清晰度方面表现优异，平均得分8.7，而消融模型为6.4-6.7。未处理查询降至1.6%，证明其在处理模糊需求方面的鲁棒性。

Conclusion: ChefMind通过混合架构有效解决了食谱推荐中的关键挑战，显著提升了推荐质量和对模糊用户意图的处理能力。

Abstract: Personalized recipe recommendation faces challenges in handling fuzzy user
intent, ensuring semantic accuracy, and providing sufficient detail coverage.
We propose ChefMind, a hybrid architecture combining Chain of Exploration
(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large
Language Model (LLM). CoE refines ambiguous queries into structured conditions,
KG offers semantic reasoning and interpretability, RAG supplements contextual
culinary details, and LLM integrates outputs into coherent recommendations. We
evaluate ChefMind on the Xiachufang dataset and manually annotated queries,
comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that
ChefMind achieves superior performance in accuracy, relevance, completeness,
and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.
Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in
handling fuzzy demands.

</details>


### [43] [An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems](https://arxiv.org/abs/2509.18229)
*Anthony Patera,Rohan Abeyaratne*

Main category: cs.AI

TL;DR: 本文提出了一种"N-Plus-1"GPT代理框架，通过多个独立求解代理和比较代理来提高机械工程问题分析的可靠性，解决了单一GPT模型85%成功率的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: GPT在机械工程分析中虽然能产生出色解决方案，但成功率仅为85%，这种不可靠性使其无法直接应用于教育或工程实践。需要一种机制来提高解决方案的可靠性。

Method: 采用N+1代理框架：首先启动N个独立求解代理生成N个解决方案，然后通过比较代理汇总比较这些方案并推荐最优解。基于孔多塞陪审团定理，当每个求解代理的成功概率大于1/2且N足够大时，多数解决方案将正确。

Result: 与商业多代理模型Grok Heavy相比，该框架在设计和性能上具有相似性，但更注重透明度和教学价值。通过多数投票机制显著提高了解决方案的可靠性。

Conclusion: N-Plus-1代理框架有效解决了GPT在机械工程分析中的不可靠性问题，为教育和技术实践提供了更可靠的AI辅助工具，特别强调透明度和教学价值。

Abstract: Generative AI, and specifically GPT, can produce a remarkable solution to a
mechanical engineering analysis problem - but also, on occasion, a flawed
solution. For example, an elementary mechanics problem is solved flawlessly in
one GPT instance and incorrectly in a subsequent GPT instance, with a success
probability of only 85%. This unreliability renders "out-of-the-box" GPT
unsuitable for deployment in education or engineering practice. We introduce an
"N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering
Problem Statements. Agency first launches N instantiations of Agent Solve to
yield N independent Proposed Problem Solution Realizations; Agency then invokes
Agent Compare to summarize and compare the N Proposed Problem Solution
Realizations and to provide a Recommended Problem Solution. We argue from
Condorcet's Jury Theorem that, for a Problem Statement characterized by
per-Solve success probability greater than 1/2 (and N sufficiently large), the
Predominant (Agent Compare) Proposed Problem Solution will, with high
probability, correspond to a Correct Proposed Problem Solution. Furthermore,
Agent Compare can also incorporate aspects of Secondary (Agent Compare)
Proposed Problem Solutions, in particular when the latter represent alternative
Problem Statement interpretations - different Mathematical Models - or
alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a
commercial multi-agent model, show similarities in design and performance, but
also important differences in emphasis: our Agency focuses on transparency and
pedagogical value.

</details>


### [44] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: 本文提出了一种轻量级分层强化学习框架ComputerAgent，用于桌面应用控制，相比现有多模态大语言模型方法，在保持性能的同时大幅减小模型规模和推理时间。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的桌面应用控制方法存在推理延迟高、样本效率低、无法在设备上部署等问题，需要更实用的解决方案。

Method: 采用分层强化学习框架，将操作系统控制建模为两级选项过程（管理器和子策略），使用三模态状态编码器处理视觉和上下文多样性，集成元动作和早停机制减少无效交互，使用紧凑视觉骨干网络和小型策略网络实现设备端推理。

Result: 在135个真实世界桌面任务测试中，简单任务成功率92.1%，困难任务成功率58.8%，性能匹配或超越200B参数大模型基线，同时模型规模减少四个数量级，推理时间减半。

Conclusion: 分层强化学习为计算机控制提供了一种实用、可扩展的替代方案，优于单一的大语言模型自动化方法。

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>


### [45] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 论文指出当前医疗AI基准测试存在严重问题，大型模型虽然在基准测试中得分很高，但实际上是通过应试技巧而非真正的医学理解来获得分数，存在脆弱性和捷径学习的问题。


<details>
  <summary>Details</summary>
Motivation: 揭示当前医疗AI基准测试的局限性，证明高分数并不等同于真实的医疗能力，呼吁需要更严格的评估标准来确保AI在医疗领域的可靠应用。

Method: 对六个旗舰模型在六个广泛使用的医疗基准上进行压力测试，包括移除关键输入、改变提示词等方法，并通过临床医生指导的评分标准进行评估。

Result: 发现领先系统在关键输入被移除时仍能猜对答案，在简单提示词变化下会改变答案，并生成有说服力但有缺陷的推理，基准测试分数不能真实反映模型的实际医疗能力。

Conclusion: 医疗基准测试分数不能直接反映AI在现实世界中的准备程度，需要要求系统具备鲁棒性、合理推理能力，并与真实医疗需求保持一致，而不仅仅是追求排行榜胜利。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [46] [Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints](https://arxiv.org/abs/2509.18382)
*Adarsha Balaji,Le Chen,Rajeev Thakur,Franck Cappello,Sandeep Madireddy*

Main category: cs.AI

TL;DR: 本文研究两种计算约束策略（推理长度约束和模型量化）来降低推理模型的计算需求，并分析它们对模型安全性能的影响。


<details>
  <summary>Details</summary>
Motivation: 测试时计算扩展虽然能通过生成长链思维序列提高推理语言模型性能，但计算成本显著增加。需要找到在保持性能的同时降低计算需求的方法。

Method: 1）使用基于长度控制策略优化的强化学习方法微调推理模型，满足用户定义的推理长度；2）应用量化技术，在用户定义的计算约束内最大化生成链式思维序列。

Result: 研究了计算效率与模型安全性之间的权衡关系。

Conclusion: 计算约束策略可以有效降低推理模型的计算需求，但需要在计算效率和安全性之间找到平衡点。

Abstract: Test-time compute scaling has demonstrated the ability to improve the
performance of reasoning language models by generating longer chain-of-thought
(CoT) sequences. However, this increase in performance comes with a significant
increase in computational cost. In this work, we investigate two compute
constraint strategies: (1) reasoning length constraint and (2) model
quantization, as methods to reduce the compute demand of reasoning models and
study their impact on their safety performance. Specifically, we explore two
approaches to apply compute constraints to reasoning models: (1) fine-tuning
reasoning models using a length controlled policy optimization (LCPO) based
reinforcement learning method to satisfy a user-defined CoT reasoning length,
and (2) applying quantization to maximize the generation of CoT sequences
within a user-defined compute constraint. Furthermore, we study the trade-off
between the computational efficiency and the safety of the model.

</details>


### [47] [Gödel Test: Can Large Language Models Solve Easy Conjectures?](https://arxiv.org/abs/2509.18383)
*Moran Feldman,Amin Karbasi*

Main category: cs.AI

TL;DR: 论文提出Gödel测试，评估GPT-5在组合优化中解决未解简单猜想的能力。结果显示GPT-5在常规推理上有进步，偶尔展现原创性，但在跨论文综合推理方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型在数学竞赛中表现优异，但能否在更高级数学领域解决新的简单猜想仍不明确。作者希望通过Gödel测试来评估大语言模型在这方面的能力。

Method: 选取组合优化中的五个未解猜想，提供相关源论文但隐藏作者自己的猜想，详细评估GPT-5的推理过程。

Result: GPT-5在三个较简单问题上产生接近正确的解，在问题2中甚至推导出不同的近似保证并反驳了作者的猜想。在需要跨论文综合的问题4上失败，在更复杂的问题5上算法正确但分析失败。

Conclusion: GPT-5在常规推理方面取得有意义进展，偶尔展现原创性，但在需要综合多篇论文知识时存在明显局限，可能代表了前沿模型通过Gödel测试的早期步骤。

Abstract: Recent announcements from frontier AI model labs have highlighted strong
results on high-school and undergraduate math competitions. Yet it remains
unclear whether large language models can solve new, simple conjectures in more
advanced areas of mathematics. We propose the G\"odel Test: evaluating whether
a model can produce correct proofs for very simple, previously unsolved
conjectures. To this end, we study the performance of GPT-5 on five conjectures
in combinatorial optimization. For each problem, we provided one or two source
papers from which the conjecture arose, withheld our own conjecture, and then
assessed the model's reasoning in detail. On the three easier problems, GPT-5
produced nearly correct solutions; for Problem 2 it even derived a different
approximation guarantee that, upon checking, refuted our conjecture while
providing a valid solution. The model failed on Problem 4, which required
combining results from two papers. On Problem 5, a harder case without a
validated conjecture, GPT-5 proposed the same algorithm we had in mind but
failed in the analysis, suggesting the proof is more challenging than expected.
Although our sample is small, the results point to meaningful progress on
routine reasoning, occasional flashes of originality, and clear limitations
when cross-paper synthesis is required. GPT-5 may represent an early step
toward frontier models eventually passing the G\"odel Test.

</details>


### [48] [ATLAS: Benchmarking and Adapting LLMs for Global Trade via Harmonized Tariff Code Classification](https://arxiv.org/abs/2509.18400)
*Pritish Yuvraj,Siva Devarakonda*

Main category: cs.AI

TL;DR: 该论文提出了首个基于美国海关裁决在线搜索系统的HTS代码分类基准，并开发了Atlas模型（基于LLaMA-3.3-70B微调），在10位数分类上达到40%准确率，比GPT-5和Gemini-2.5分别提升15和27.5个百分点，且成本显著降低。


<details>
  <summary>Details</summary>
Motivation: HTS代码分类是全球贸易中的关键瓶颈，但机器学习社区对此关注不足。错误分类可能导致货物运输完全停滞，主要邮政运营商因海关文件不完整而暂停向美国发货。

Method: 基于美国海关裁决在线搜索系统创建基准数据集，对领先的LLM进行评估，并微调LLaMA-3.3-70B模型（Atlas）进行HTS代码分类。

Result: Atlas模型在10位数分类上达到40%准确率，6位数分类达到57.5%准确率，比GPT-5-Thinking和Gemini-2.5-Pro-Thinking分别提升15和27.5个百分点，成本降低5-8倍，且可自托管保证数据隐私。

Conclusion: Atlas为HTS分类设立了强基线，但该任务仍极具挑战性。通过发布数据集和模型，旨在将HTS分类定位为新的社区基准任务，并促进检索、推理和对齐方面的未来研究。

Abstract: Accurate classification of products under the Harmonized Tariff Schedule
(HTS) is a critical bottleneck in global trade, yet it has received little
attention from the machine learning community. Misclassification can halt
shipments entirely, with major postal operators suspending deliveries to the
U.S. due to incomplete customs documentation. We introduce the first benchmark
for HTS code classification, derived from the U.S. Customs Rulings Online
Search System (CROSS). Evaluating leading LLMs, we find that our fine-tuned
Atlas model (LLaMA-3.3-70B) achieves 40 percent fully correct 10-digit
classifications and 57.5 percent correct 6-digit classifications, improvements
of 15 points over GPT-5-Thinking and 27.5 points over Gemini-2.5-Pro-Thinking.
Beyond accuracy, Atlas is roughly five times cheaper than GPT-5-Thinking and
eight times cheaper than Gemini-2.5-Pro-Thinking, and can be self-hosted to
guarantee data privacy in high-stakes trade and compliance workflows. While
Atlas sets a strong baseline, the benchmark remains highly challenging, with
only 40 percent 10-digit accuracy. By releasing both dataset and model, we aim
to position HTS classification as a new community benchmark task and invite
future work in retrieval, reasoning, and alignment.

</details>


### [49] [Instruction-Following Evaluation in Function Calling for Large Language Models](https://arxiv.org/abs/2509.18420)
*Nikolai Skripko*

Main category: cs.AI

TL;DR: IFEval-FC是一个新的函数调用基准测试，专门评估大语言模型在函数调用中对参数描述中格式指令的遵循能力，填补了现有基准测试只关注参数正确性而忽略格式要求的空白。


<details>
  <summary>Details</summary>
Motivation: 现有函数调用基准测试（如BFCL、tau^2-Bench、ACEBench）只评估参数正确性，不测试格式指令遵循能力，而现实应用中格式要求（如引号、日期格式）对AI代理系统至关重要。

Method: 基于IFEval设计，将可验证的格式要求直接编码到JSON schema描述中，包含750个测试用例，每个用例包含带有格式要求的函数和对应用户查询，采用全算法评估确保客观性和可复现性。

Result: 即使是GPT-5和Claude 4.1 Opus等最先进的专有模型也经常无法遵循基本格式规则，揭示了现实世界代理系统的实际局限性。

Conclusion: IFEval-FC揭示了当前大语言模型在精确遵循格式指令方面的不足，为改进函数调用能力提供了重要基准，代码和数据已开源。

Abstract: Function calling is a core capability of large language models, essential for
AI agents. Existing benchmarks such as the Berkeley Function Calling
Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench
(arXiv:2501.12851) evaluate argument correctness but do not test adherence to
format instructions embedded in parameter descriptions, such as enclosing
values in double quotes or using ISO date formats.
  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911)
that assesses precise instruction following in function calling. IFEval-FC
encodes verifiable formats directly within JSON schema descriptions, for
example specifying that a value must not contain punctuation. It includes 750
test cases, each consisting of a function with an embedded format for one of
its input parameters and a corresponding user query. Evaluation is fully
algorithmic, ensuring objectivity, reproducibility, and scalability.
  Our results show that even state-of-the-art proprietary models, including
GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules,
highlighting a practical limitation for real-world agent systems. The complete
codebase and data are publicly available at
https://github.com/Skripkon/IFEval-FC.

</details>


### [50] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: Memory-QA是一个新颖的真实世界任务，旨在回答关于先前存储的多模态记忆的视觉内容回忆问题。作者提出了Pensieve管道来解决该任务的挑战，并在多模态基准测试中表现出优于现有解决方案的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉问答系统主要关注即时感知，缺乏对长期记忆的利用。现实世界中需要能够从存储的记忆中回答回忆问题的能力，这涉及到任务导向的记忆创建、时空信息的有效利用以及多记忆推理等独特挑战。

Method: 提出了Pensieve综合管道，包含三个关键组件：1）记忆特定的数据增强；2）时间和位置感知的多信号检索；3）多记忆问答微调。该方法专门针对记忆检索和利用的挑战进行设计。

Result: 在多模态基准测试中，Pensieve相比最先进的解决方案在问答准确率上提升了高达14%，证明了该方法在记忆问答任务上的有效性。

Conclusion: Memory-QA任务揭示了现实世界记忆问答的重要挑战，Pensieve管道通过整合记忆增强、时空感知检索和多记忆推理，为解决这些挑战提供了有效的解决方案，为长期记忆在视觉问答中的应用开辟了新方向。

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [51] [FERA: Foil Fencing Referee Assistant Using Pose-Based Multi-Label Move Recognition and Rule Reasoning](https://arxiv.org/abs/2509.18527)
*Ziwen Chen,Zhong Wang*

Main category: cs.AI

TL;DR: FERA是一个用于击剑裁判辅助的AI系统原型，通过姿态动作识别和规则推理来解决击剑裁判中的主观判断、人为错误等问题。


<details>
  <summary>Details</summary>
Motivation: 击剑运动面临裁判主观判断、人为错误、偏见以及在训练环境中裁判资源有限等挑战。

Method: 系统从视频中提取2D关节位置，进行归一化处理后计算101维运动学特征，使用Transformer进行多标签动作和剑尖分类，并结合基于规则的推理来确定优先权和得分。

Result: 在有限的手动标注数据下，5折交叉验证的平均macro-F1得分为0.549，优于Temporal Convolutional Network、BiLSTM和普通Transformer等基线模型。

Conclusion: 虽然尚未达到部署水平，但结果表明在击剑自动化裁判辅助方面具有前景，并为AI在击剑领域的应用（如教练辅助）开辟了新机会。

Abstract: The sport of fencing, like many other sports, faces challenges in refereeing:
subjective calls, human errors, bias, and limited availability in practice
environments. We present FERA (Fencing Referee Assistant), a prototype AI
referee for foil fencing which integrates pose-based multi-label action
recognition and rule-based reasoning. FERA extracts 2D joint positions from
video, normalizes them, computes a 101-dimensional kinematic feature set, and
applies a Transformer for multi-label move and blade classification. To
determine priority and scoring, FERA applies a distilled language model with
encoded right-of-way rules, producing both a decision and an explanation for
each exchange. With limited hand-labeled data, a 5-fold cross-validation
achieves an average macro-F1 score of 0.549, outperforming multiple baselines,
including a Temporal Convolutional Network (TCN), BiLSTM, and a vanilla
Transformer. While not ready for deployment, these results demonstrate a
promising path towards automated referee assistance in foil fencing and new
opportunities for AI applications, such as coaching in the field of fencing.

</details>


### [52] [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](https://arxiv.org/abs/2509.18557)
*Tom Pawelek,Raj Patel,Charlotte Crowell,Noorbakhsh Amiri,Sudip Mittal,Shahram Rahimi,Andy Perkins*

Main category: cs.AI

TL;DR: LLMZ+是一种基于提示白名单的新型防御机制，通过仅允许上下文相关的安全消息与代理式LLM交互，提供对越狱攻击的强大防护。


<details>
  <summary>Details</summary>
Motivation: 代理式AI相比传统模型具有更高的安全风险，因为它们拥有对数据源和API工具的特权访问，且依赖AI的非确定性行为，这给操作安全和信息安全带来重大威胁。

Method: 采用提示白名单方法，仅允许符合预定义用例和操作边界的上下文适当消息与代理式LLM交互，超越传统的基于检测的防御方法。

Result: 实证评估显示LLMZ+对最常见的越狱提示具有强大抵抗力，同时不干扰合法的业务通信，在实验环境中假阳性和假阴性率均可降至0。

Conclusion: LLMZ+方法简化了安全框架，增强了长期韧性，减少了维持LLM信息安全所需的资源，为代理式AI提供了有效的安全防护方案。

Abstract: Compared to traditional models, agentic AI represents a highly valuable
target for potential attackers as they possess privileged access to data
sources and API tools, which are traditionally not incorporated into classical
agents. Unlike a typical software application residing in a Demilitarized Zone
(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI
(only defining a final goal, leaving the path selection to LLM). This
characteristic introduces substantial security risk to both operational
security and information security. Most common existing defense mechanism rely
on detection of malicious intent and preventing it from reaching the LLM agent,
thus protecting against jailbreak attacks such as prompt injection. In this
paper, we present an alternative approach, LLMZ+, which moves beyond
traditional detection-based approaches by implementing prompt whitelisting.
Through this method, only contextually appropriate and safe messages are
permitted to interact with the agentic LLM. By leveraging the specificity of
context, LLMZ+ guarantees that all exchanges between external users and the LLM
conform to predefined use cases and operational boundaries. Our approach
streamlines the security framework, enhances its long-term resilience, and
reduces the resources required for sustaining LLM information security. Our
empirical evaluation demonstrates that LLMZ+ provides strong resilience against
the most common jailbreak prompts. At the same time, legitimate business
communications are not disrupted, and authorized traffic flows seamlessly
between users and the agentic LLM. We measure the effectiveness of approach
using false positive and false negative rates, both of which can be reduced to
0 in our experimental setting.

</details>


### [53] [Solving Math Word Problems Using Estimation Verification and Equation Generation](https://arxiv.org/abs/2509.18565)
*Mitchell Piehl,Dillon Wilson,Ananya Kalita,Jugal Kalita*

Main category: cs.AI

TL;DR: 提出了一种结合LLM和外部符号方程求解器的新方法，通过问题分解、方程生成、答案验证和迭代修正来解决数学应用题，在多个数据集上达到新的最优结果。


<details>
  <summary>Details</summary>
Motivation: LLM在解决数学应用题时面临挑战，因为需要复杂的推理和数学能力。现有方法在复杂MWPs上仍有改进空间。

Method: 首先提示LLM从问题分解中创建方程，然后使用外部符号方程求解器生成答案。通过让LLM第二次估计答案来验证准确性，如果验证失败则进行迭代修正。

Result: 在数值和代数MWPs数据集上比之前最优结果平均提升近2%，在三角函数MWPs上也取得了满意结果，并引入了两个新数据集SVAMPClean和Trig300。

Conclusion: 该方法有效提升了LLM解决数学应用题的能力，特别是在复杂推理任务上表现优异，为LLM的数学推理能力测试提供了新基准。

Abstract: Large Language Models (LLMs) excel at various tasks, including
problem-solving and question-answering. However, LLMs often find Math Word
Problems (MWPs) challenging because solving them requires a range of reasoning
and mathematical abilities with which LLMs seem to struggle. Recent efforts
have helped LLMs solve more complex MWPs with improved prompts. This study
proposes a novel method that initially prompts an LLM to create equations from
a decomposition of the question, followed by using an external symbolic
equation solver to produce an answer. To ensure the accuracy of the obtained
answer, inspired by an established recommendation of math teachers, the LLM is
instructed to solve the MWP a second time, but this time with the objective of
estimating the correct answer instead of solving it exactly. The estimation is
then compared to the generated answer to verify. If verification fails, an
iterative rectification process is employed to ensure the correct answer is
eventually found. This approach achieves new state-of-the-art results on
datasets used by prior published research on numeric and algebraic MWPs,
improving the previous best results by nearly two percent on average. In
addition, the approach obtains satisfactory results on trigonometric MWPs, a
task not previously attempted to the authors' best knowledge. This study also
introduces two new datasets, SVAMPClean and Trig300, to further advance the
testing of LLMs' reasoning abilities.

</details>


### [54] [Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents](https://arxiv.org/abs/2509.18633)
*Yara Mohajerani*

Main category: cs.AI

TL;DR: 提出了一个结合地理空间代理模型和进化学习的气候风险评估框架，用于模拟气候灾害与经济系统的复杂相互作用。


<details>
  <summary>Details</summary>
Motivation: 气候风险评估需要建模空间异质性灾害与适应性经济系统之间的复杂相互作用，传统方法难以捕捉这些动态过程。

Method: 开发了基于Mesa的地理空间代理模型，集成CLIMADA气候影响评估，引入进化学习机制让企业通过适应性选择演化预算分配、定价、工资和风险适应策略。

Result: 使用RCP8.5情景下的河流洪水预测到2100年，显示进化适应使企业能在几十年气候压力后恢复到基准生产水平；未直接暴露于洪水的代理也面临供应链中断影响，世纪末商品平均价格比基准高5.6%。

Conclusion: 该开源框架为金融机构和公司提供了量化直接和级联气候风险的工具，同时评估成本效益适应策略。

Abstract: Climate risk assessment requires modelling complex interactions between
spatially heterogeneous hazards and adaptive economic systems. We present a
novel geospatial agent-based model that integrates climate hazard data with
evolutionary learning for economic agents. Our framework combines Mesa-based
spatial modelling with CLIMADA climate impact assessment, introducing adaptive
learning behaviours that allow firms to evolve strategies for budget
allocation, pricing, wages, and risk adaptation through fitness-based selection
and mutation. We demonstrate the framework using riverine flood projections
under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to
converge with baseline (no hazard) production levels after decades of
disruption due to climate stress. Our results reveal systemic risks where even
agents that are not directly exposed to floods face impacts through supply
chain disruptions, with the end-of-century average price of goods 5.6% higher
under RCP8.5 compared to the baseline. This open-source framework provides
financial institutions and companies with tools to quantify both direct and
cascading climate risks while evaluating cost-effective adaptation strategies.

</details>


### [55] [TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2509.18667)
*Qiao Xiao,Hong Ting Tsang,Jiaxin Bai*

Main category: cs.AI

TL;DR: TERAG是一个低成本图基检索增强生成框架，通过个性化PageRank在检索阶段实现高效图构建，仅用3%-11%的输出token就能达到现有方法80%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有图基RAG系统在构建图时LLM token使用成本过高，阻碍了大规模应用，需要开发更经济的解决方案。

Method: 受HippoRAG启发，在检索阶段引入个性化PageRank(PPR)来构建信息丰富的图结构，显著降低token消耗。

Result: TERAG在保持准确性的同时，将输出token使用量大幅减少到现有方法的3%-11%，达到至少80%的准确率。

Conclusion: TERAG证明了通过优化检索策略可以显著降低图基RAG的成本，为实现大规模应用提供了可行方案。

Abstract: Graph-based Retrieval-augmented generation (RAG) has become a widely studied
approach for improving the reasoning, accuracy, and factuality of Large
Language Models. However, many existing graph-based RAG systems overlook the
high cost associated with LLM token usage during graph construction, hindering
large-scale adoption. To address this, we propose TERAG, a simple yet effective
framework designed to build informative graphs at a significantly lower cost.
Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the
retrieval phase, and we achieve at least 80% of the accuracy of widely used
graph-based RAG methods while consuming only 3%-11% of the output tokens.

</details>


### [56] [Implementation of airborne ML models with semantics preservation](https://arxiv.org/abs/2509.18681)
*Nicolas Valot,Louis Fabre,Benjamin Lesage,Ammar Mechouche,Claire Pagetti*

Main category: cs.AI

TL;DR: 本文探讨了机器学习模型在航空系统中的安全合规性，重点区分了ML模型与其明确描述（MLMD），并提出了语义保持的概念以确保模型准确复制。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在航空系统中的应用增加，需要确保这些系统的安全运行并符合监管要求。EASA和EUROCAE/SAE等机构已发布相关指导文件，但需要更具体的方法来验证ML模型的性能。

Method: 通过区分ML模型和MLMD，并细化语义保持的概念，确保模型在目标环境中准确复制其训练性能。方法应用于多个工业用例来构建和比较目标模型。

Result: 研究提出了明确的MLMD概念和语义保持框架，通过工业用例验证了方法的有效性，能够帮助确保ML模型在航空系统中的安全合规性。

Conclusion: MLMD和语义保持概念为ML模型在安全关键系统中的合规验证提供了重要理论基础，有助于推动机器学习在航空领域的可靠应用。

Abstract: Machine Learning (ML) may offer new capabilities in airborne systems.
However, as any piece of airborne systems, ML-based systems will be required to
guarantee their safe operation. Thus, their development will have to be
demonstrated to be compliant with the adequate guidance. So far, the European
Union Aviation Safety Agency (EASA) has published a concept paper and an
EUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level
objectives to confirm the ML model achieves its intended function and maintains
training performance in the target environment. The paper aims to clarify the
difference between an ML model and its corresponding unambiguous description,
referred to as the Machine Learning Model Description (MLMD). It then refines
the essential notion of semantics preservation to ensure the accurate
replication of the model. We apply our contributions to several industrial use
cases to build and compare several target models.

</details>


### [57] [Advances in Large Language Models for Medicine](https://arxiv.org/abs/2509.18690)
*Zhiyu Kan,Wensheng Gan,Zhenlian Qi,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文系统综述了大型语言模型在医学领域的最新研究进展，包括医学大模型的训练技术、医疗场景适配、应用情况、优势与局限性，并对医学LLMs进行了创新性分类，提出了现有挑战的解决方案和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，大型语言模型在医学领域展现出巨大应用潜力，需要系统梳理当前研究进展，为医学LLMs的发展提供指导和参考。

Method: 采用系统性文献综述方法，对医学LLMs的训练方法、应用场景、评估方法等进行深入分析，并基于训练方法将医学LLMs分为三类，评估方法分为两类。

Result: 全面梳理了医学LLMs的研究现状，提出了分类框架，识别了当前挑战，并为后续研究提供了明确指导。

Conclusion: 医学LLMs具有重要应用价值，未来发展需要在技术优化、应用拓展和伦理规范等方面持续探索，本研究为相关研究提供了系统性参考。

Abstract: Artificial intelligence (AI) technology has advanced rapidly in recent years,
with large language models (LLMs) emerging as a significant breakthrough. LLMs
are increasingly making an impact across various industries, with the medical
field standing out as the most prominent application area. This paper
systematically reviews the up-to-date research progress of LLMs in the medical
field, providing an in-depth analysis of training techniques for large medical
models, their adaptation in healthcare settings, related applications, as well
as their strengths and limitations. Furthermore, it innovatively categorizes
medical LLMs into three distinct types based on their training methodologies
and classifies their evaluation approaches into two categories. Finally, the
study proposes solutions to existing challenges and outlines future research
directions based on identified issues in the field of medical LLMs. By
systematically reviewing previous and advanced research findings, we aim to
highlight the necessity of developing medical LLMs, provide a deeper
understanding of their current state of development, and offer clear guidance
for subsequent research.

</details>


### [58] [Autonomous Data Agents: A New Opportunity for Smart Data](https://arxiv.org/abs/2509.18710)
*Yanjie Fu,Dongjie Wang,Wangyang Ying,Xiangliang Zhang,Huan Liu,Jian Pei*

Main category: cs.AI

TL;DR: 本文提出自主数据代理(DataAgents)的概念，通过集成LLM推理与任务分解、行动推理和工具调用，实现数据到知识的自动化转换，代表了数据管理向自主知识系统的范式转变。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模和复杂性的增长，数据准备、转换和分析工作仍然劳动密集、重复且难以扩展。数据与AI之间的对齐至关重要，但现有数据结构往往不适合AI利用。

Method: DataAgents整合LLM推理能力，能够自主解释数据任务描述、分解任务为子任务、推理行动、将行动转化为Python代码或工具调用，并执行操作。与传统工具不同，DataAgents能动态规划工作流、调用强大工具并适应各种数据任务。

Result: DataAgents能够处理数据收集、集成、预处理、选择、转换、重加权、增强、重编程、修复和检索等任务，将复杂非结构化数据转化为连贯可操作的知识。

Conclusion: DataAgents代表了数据到知识系统的范式转变，需要推进行动工作流优化、建立开放数据集和基准生态系统、保护隐私、平衡效率与可扩展性，并开发可信赖的防护机制。

Abstract: As data continues to grow in scale and complexity, preparing, transforming,
and analyzing it remains labor-intensive, repetitive, and difficult to scale.
Since data contains knowledge and AI learns knowledge from it, the alignment
between AI and data is essential. However, data is often not structured in ways
that are optimal for AI utilization. Moreover, an important question arises:
how much knowledge can we pack into data through intensive data operations?
Autonomous data agents (DataAgents), which integrate LLM reasoning with task
decomposition, action reasoning and grounding, and tool calling, can
autonomously interpret data task descriptions, decompose tasks into subtasks,
reason over actions, ground actions into python code or tool calling, and
execute operations. Unlike traditional data management and engineering tools,
DataAgents dynamically plan workflows, call powerful tools, and adapt to
diverse data tasks at scale. This report argues that DataAgents represent a
paradigm shift toward autonomous data-to-knowledge systems. DataAgents are
capable of handling collection, integration, preprocessing, selection,
transformation, reweighing, augmentation, reprogramming, repairs, and
retrieval. Through these capabilities, DataAgents transform complex and
unstructured data into coherent and actionable knowledge. We first examine why
the convergence of agentic AI and data-to-knowledge systems has emerged as a
critical trend. We then define the concept of DataAgents and discuss their
architectural design, training strategies, as well as the new skills and
capabilities they enable. Finally, we call for concerted efforts to advance
action workflow optimization, establish open datasets and benchmark ecosystems,
safeguard privacy, balance efficiency with scalability, and develop trustworthy
DataAgent guardrails to prevent malicious actions.

</details>


### [59] [Experience Scaling: Post-Deployment Evolution For Large Language Models](https://arxiv.org/abs/2509.18771)
*Xingkun Yin,Kaibin Huang,Dong In Kim,Hongyang Du*

Main category: cs.AI

TL;DR: 本文提出经验扩展框架，通过自主环境交互和协作经验共享实现LLM的持续进化，突破静态人类生成数据的限制


<details>
  <summary>Details</summary>
Motivation: 传统通过扩大模型规模、训练数据和计算能力的方法已接近饱和，人类生成文本资源耗尽，进一步增益递减

Method: 经验扩展框架：捕获原始交互，提炼为紧凑可重用知识，定期优化存储内容以保持相关性和效率

Result: 在模拟真实场景中验证，包括泛化到未见但相关任务、重复查询和过饱和知识存储，经验扩展提高了准确性，维持了长期性能，并在新情境中保持增益

Conclusion: 结构化部署后学习可以扩展LLM能力超越静态人类生成数据的限制，为持续智能进步提供可扩展路径

Abstract: Scaling model size, training data, and compute power have driven advances in
large language models (LLMs), but these approaches are reaching saturation as
human-generated text is exhausted and further gains diminish. We propose
experience scaling, a framework for continuous post-deployment evolution for
LLMs through autonomous interaction with the environment and collaborative
sharing of accumulated experience. The framework captures raw interactions,
distills them into compact, reusable knowledge, and periodically refines stored
content to preserve relevance and efficiency. We validate the framework in
simulated real-world scenarios involving generalization to previously unseen
but related tasks, repetitive queries, and over-saturated knowledge stores.
Across all settings, experience scaling improves accuracy, sustains performance
over time, and maintains gains when applied to novel situations. These results
demonstrate that structured post-deployment learning can extend LLM
capabilities beyond the limits of static human-generated data, offering a
scalable path for continued intelligence progress.

</details>


### [60] [The AGNTCY Agent Directory Service: Architecture and Implementation](https://arxiv.org/abs/2509.18787)
*Luca Muscariello,Vijoy Pandey,Ramiz Polic*

Main category: cs.AI

TL;DR: ADS是一个分布式目录服务，用于发现AI代理的能力、元数据和来源。它利用内容寻址存储、分层分类法和加密签名，在异构多代理系统中实现高效、可验证的多维发现。


<details>
  <summary>Details</summary>
Motivation: 为了解决多代理系统中代理能力发现和互操作性的挑战，需要一种能够处理异构代理系统、支持可验证发现和扩展性的目录服务。

Method: 基于Open Agentic Schema Framework构建，采用两级映射架构（通过Kademlia DHT实现），重用OCI/ORAS基础设施进行工件分发，集成Sigstore用于来源验证，支持模式驱动的可扩展性。

Result: ADS提供了一个正式的架构模型，包括存储和发现层，具有明确的安全和性能特性，能够支持新兴代理模式（如LLM提示代理、MCP服务器等）。

Conclusion: ADS在新兴代理注册和互操作性倡议的广泛背景下定位，为多代理系统的能力发现和互操作提供了系统化的解决方案。

Abstract: The Agent Directory Service (ADS) is a distributed directory for the
discovery of AI agent capabilities, metadata, and provenance. It leverages
content-addressed storage, hierarchical taxonomies, and cryptographic signing
to enable efficient, verifiable, and multi-dimensional discovery across
heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema
Framework (OASF), ADS decouples capability indexing from content location
through a two-level mapping realized over a Kademlia-based Distributed Hash
Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact
distribution, integrates Sigstore for provenance, and supports schema-driven
extensibility for emerging agent modalities (LLM prompt agents, MCP servers,
A2A-enabled components). This paper formalizes the architectural model,
describes storage and discovery layers, explains security and performance
properties, and positions ADS within the broader landscape of emerging agent
registry and interoperability initiatives.

</details>


### [61] [Bounded PCTL Model Checking of Large Language Model Outputs](https://arxiv.org/abs/2509.18836)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: LLMCHECKER是一个基于模型检查的验证方法，用于验证LLM文本生成过程的概率计算树逻辑(PCTL)属性。该方法通过α-k有界文本生成来限制验证范围，重点关注每个生成步骤中top-k令牌的累积概率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本生成过程缺乏形式化验证方法，无法保证生成文本的一致性和可靠性。作者发现文本生成过程中只有有限数量的令牌被选择，且这些选择并不总是相同，这促使开发形式化验证方法。

Method: 提出α-k有界文本生成方法，在每个文本生成步骤中只考虑累积概率超过阈值α的top-k令牌。LLMCHECKER利用模型检查技术验证PCTL属性，支持多种文本量化方法如质量评估和偏见检测。

Result: 该方法在多个LLM模型（包括Llama、Gemma、Mistral、Genstruct和BERT）上进行了验证，证明了其适用性。这是首次将PCTL模型检查应用于LLM文本生成过程的一致性验证。

Conclusion: LLMCHECKER为LLM文本生成过程提供了首个基于PCTL的形式化验证框架，能够有效验证生成文本的可靠性和一致性，为LLM的安全可信应用提供了重要工具。

Abstract: In this paper, we introduce LLMCHECKER, a model-checking-based verification
method to verify the probabilistic computation tree logic (PCTL) properties of
an LLM text generation process. We empirically show that only a limited number
of tokens are typically chosen during text generation, which are not always the
same. This insight drives the creation of $\alpha$-$k$-bounded text generation,
narrowing the focus to the $\alpha$ maximal cumulative probability on the
top-$k$ tokens at every step of the text generation process. Our verification
method considers an initial string and the subsequent top-$k$ tokens while
accommodating diverse text quantification methods, such as evaluating text
quality and biases. The threshold $\alpha$ further reduces the selected tokens,
only choosing those that exceed or meet it in cumulative probability.
LLMCHECKER then allows us to formally verify the PCTL properties of
$\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in
several LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our
knowledge, this is the first time PCTL-based model checking has been used to
check the consistency of the LLM text generation process.

</details>


### [62] [Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning](https://arxiv.org/abs/2509.18846)
*Hong-Jie Dai,Zheng-Hao Li,An-Tai Lu,Bo-Tsz Shain,Ming-Ta Li,Tatheer Hussain Mir,Kuang-Te Wang,Min-I Su,Pei-Kang Liu,Ming-Ju Tsai*

Main category: cs.AI

TL;DR: 提出一个模块化框架用于ICD-10-CM编码预测，通过系统化模型选择、冗余感知数据采样和结构化输入设计，提升大型语言模型在医疗编码任务中的性能。


<details>
  <summary>Details</summary>
Motivation: ICD编码对临床文档、计费和分析至关重要，但目前仍是劳动密集型且易出错的任务。现有LLMs在自动编码中存在模型选择、输入上下文化和训练数据冗余等挑战。

Method: 采用LLM-as-judge评估协议和Plackett-Luce聚合来评估开源LLMs对ICD-10-CM定义的理解；引入嵌入相似性度量和冗余感知采样策略；利用台湾医院的结构化出院摘要评估上下文效果。

Result: 在两个机构数据集上的实验表明，经过微调的选定基础模型在内部和外部评估中始终优于基线LLMs；纳入更多临床部分持续提升预测性能。

Conclusion: 该框架为ICD-10-CM编码预测提供了一个实用且原则性的方法，结合了明智的模型选择、高效数据精炼和上下文感知提示，为自动化医疗编码系统的实际部署提供了可扩展的机构就绪解决方案。

Abstract: Accurate International Classification of Diseases (ICD) coding is critical
for clinical documentation, billing, and healthcare analytics, yet it remains a
labour-intensive and error-prone task. Although large language models (LLMs)
show promise in automating ICD coding, their challenges in base model
selection, input contextualization, and training data redundancy limit their
effectiveness. We propose a modular framework for ICD-10 Clinical Modification
(ICD-10-CM) code prediction that addresses these challenges through principled
model selection, redundancy-aware data sampling, and structured input design.
The framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce
aggregation to assess and rank open-source LLMs based on their intrinsic
comprehension of ICD-10-CM code definitions. We introduced embedding-based
similarity measures, a redundancy-aware sampling strategy to remove
semantically duplicated discharge summaries. We leverage structured discharge
summaries from Taiwanese hospitals to evaluate contextual effects and examine
section-wise content inclusion under universal and section-specific modelling
paradigms. Experiments across two institutional datasets demonstrate that the
selected base model after fine-tuning consistently outperforms baseline LLMs in
internal and external evaluations. Incorporating more clinical sections
consistently improves prediction performance. This study uses open-source LLMs
to establish a practical and principled approach to ICD-10-CM code prediction.
The proposed framework provides a scalable, institution-ready solution for
real-world deployment of automated medical coding systems by combining informed
model selection, efficient data refinement, and context-aware prompting.

</details>


### [63] [MAPO: Mixed Advantage Policy Optimization](https://arxiv.org/abs/2509.18849)
*Wenke Huang,Quan Zhang,Yiyang Fang,Jian Liang,Xuankun Rong,Huanjin Yao,Guancheng Wan,Ke Liang,Wenwen He,Mingjun Li,Leszek Rutkowski,Mang Ye,Bo Du,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文提出了一种名为混合优势策略优化（MAPO）的新方法，解决了GRPO中存在的优势反转和优势镜像问题，通过动态重新加权优势函数来适应不同轨迹确定性的样本。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO方法在优势函数分配上存在优势反转和优势镜像问题，阻碍了不同查询样本间的合理优势分配。

Method: 提出MAPO策略，引入优势百分比偏差来处理高确定性轨迹样本，并动态重新加权优势函数以适应不同轨迹确定性的样本。

Result: 与相关最先进方法的比较以及不同优势变体的消融研究验证了该方法的有效性。

Conclusion: MAPO是一种简单但有效的GRPO策略，能够更好地处理轨迹确定性差异，提升基础模型在推理任务上的性能。

Abstract: Recent advances in reinforcement learning for foundation models, such as
Group Relative Policy Optimization (GRPO), have significantly improved the
performance of foundation models on reasoning tasks. Notably, the advantage
function serves as a central mechanism in GRPO for ranking the trajectory
importance. However, existing explorations encounter both advantage reversion
and advantage mirror problems, which hinder the reasonable advantage allocation
across different query samples. In this work, we propose an easy but effective
GRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the
trajectory appears with different certainty and propose the advantage percent
deviation for samples with high-certainty trajectories. Furthermore, we
dynamically reweight the advantage function for samples with varying trajectory
certainty, thereby adaptively configuring the advantage function to account for
sample-specific characteristics. Comparison with related state-of-the-art
methods, along with ablation studies on different advantage variants, validates
the effectiveness of our approach.

</details>


### [64] [Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling](https://arxiv.org/abs/2509.18864)
*Yingxin Li,Jianbo Zhao,Xueyu Ren,Jie Tang,Wangjie You,Xu Chen,Kan Zhou,Chao Feng,Jiao Ran,Yuan Meng,Zhi Wang*

Main category: cs.AI

TL;DR: 本文提出了ProfileBench基准和Conf-Profile框架，用于解决用户画像任务中标签稀缺和异构数据噪声问题，通过置信度驱动的两阶段方法显著提升LLM在用户画像任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 用户画像作为用户理解的核心技术面临两大挑战：缺乏全面的基准测试，以及难以获取大规模真实标签。异构和噪声用户信息会降低LLM的可靠性。

Method: 提出Conf-Profile框架，采用两阶段范式：1）利用高级LLM合成高质量标签，进行置信度加权投票和校准；2）通过置信度引导的无监督强化学习增强推理能力，包括难度过滤、准真实标签投票和奖励加权。

Result: 实验结果表明，Conf-Profile通过两阶段训练显著提升性能，在Qwen3-8B模型上F1分数提高了13.97。

Conclusion: 该研究为解决标签稀缺的用户画像问题提供了有效方案，置信度驱动的框架能够显著提升LLM在真实工业场景中的表现。

Abstract: User profiling, as a core technique for user understanding, aims to infer
structural attributes from user information. Large Language Models (LLMs)
provide a promising avenue for user profiling, yet the progress is hindered by
the lack of comprehensive benchmarks. To bridge this gap, we propose
ProfileBench, an industrial benchmark derived from a real-world video platform,
encompassing heterogeneous user data and a well-structured profiling taxonomy.
However, the profiling task remains challenging due to the difficulty of
collecting large-scale ground-truth labels, and the heterogeneous and noisy
user information can compromise the reliability of LLMs. To approach label-free
and reliable user profiling, we propose a Confidence-driven Profile reasoning
framework Conf-Profile, featuring a two-stage paradigm. We first synthesize
high-quality labels by leveraging advanced LLMs with confidence hints, followed
by confidence-weighted voting for accuracy improvement and confidence
calibration for a balanced distribution. The multiple profile results,
rationales, and confidence scores are aggregated and distilled into a
lightweight LLM. We further enhance the reasoning ability via confidence-guided
unsupervised reinforcement learning, which exploits confidence for difficulty
filtering, quasi-ground truth voting, and reward weighting. Experimental
results demonstrate that Conf-Profile delivers substantial performance through
the two-stage training, improving F1 by 13.97 on Qwen3-8B.

</details>


### [65] [Memory in Large Language Models: Mechanisms, Evaluation and Evolution](https://arxiv.org/abs/2509.18868)
*Dianxing Zhang,Wendong Li,Kani Song,Jiaye Lu,Gang Li,Liuchun Yang,Sheng Li*

Main category: cs.AI

TL;DR: 提出一个统一的LLM记忆定义和四部分分类法（参数化、上下文、外部、程序性/情景性），建立记忆四元组框架，通过三设置协议实现可比较评估，并开发分层评估方法和DMM Gov治理框架。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM记忆研究中的定义不一致、评估方法不可比、缺乏治理框架等问题，构建一个可重现、可比较、可治理的坐标系统。

Method: 采用统一的记忆定义和四部分分类法，提出记忆四元组（位置、持久性、写入/访问路径、可控性），使用三设置评估协议（仅参数化、离线检索、在线检索），开发分层评估体系和DMM Gov治理框架。

Result: 建立了一个完整的LLM记忆分析框架，包括定义、分类、评估协议、治理机制和四个可测试命题，为研究和部署提供了系统化的方法论。

Conclusion: 该框架为LLM记忆研究提供了可重现、可比较和可治理的坐标系统，有助于推动该领域的标准化发展和实际应用。

Abstract: Under a unified operational definition, we define LLM memory as a persistent
state written during pretraining, finetuning, or inference that can later be
addressed and that stably influences outputs. We propose a four-part taxonomy
(parametric, contextual, external, procedural/episodic) and a memory quadruple
(location, persistence, write/access path, controllability). We link mechanism,
evaluation, and governance via the chain write -> read -> inhibit/update. To
avoid distorted comparisons across heterogeneous setups, we adopt a
three-setting protocol (parametric only, offline retrieval, online retrieval)
that decouples capability from information availability on the same data and
timeline. On this basis we build a layered evaluation: parametric (closed-book
recall, edit differential, memorization/privacy), contextual (position curves
and the mid-sequence drop), external (answer correctness vs snippet
attribution/faithfulness), and procedural/episodic (cross-session consistency
and timeline replay, E MARS+). The framework integrates temporal governance and
leakage auditing (freshness hits, outdated answers, refusal slices) and
uncertainty reporting via inter-rater agreement plus paired tests with
multiple-comparison correction. For updating and forgetting, we present DMM
Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),
and RAG to form an auditable loop covering admission thresholds, rollout,
monitoring, rollback, and change audits, with specs for timeliness, conflict
handling, and long-horizon consistency. Finally, we give four testable
propositions: minimum identifiability; a minimal evaluation card; causally
constrained editing with verifiable forgetting; and when retrieval with
small-window replay outperforms ultra-long-context reading. This yields a
reproducible, comparable, and governable coordinate system for research and
deployment.

</details>


### [66] [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chengcheng Han,Chenhui Yang,Chi Zhang,Chong Peng,Chuyu Zhang,Cong Chen,Fengcun Li,Gang Xu,Guoyuan Lin,Hao Jiang,Hao Liang,Haomin Fu,Haoxiang Ma,Hong Liu,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiahao Liu,Jiahuan Li,Jialin Liu,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiaqi Sun,Jiaqi Zhang,Jiarong Shi,Jiawei Yang,Jingang Wang,Jinrui Ding,Jun Kuang,Jun Xu,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Li Wei,Liang Shi,Lin Qiu,Lingbin Kong,Lingchuan Liu,Linsen Guo,Longfei An,Mai Xia,Meng Zhou,Mengshen Zhu,Peng Pei,Pengcheng Jia,Qi Gu,Qi Guo,Qiong Huang,Quan Chen,Quanchi Weng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shanglin Lei,Shuai Du,Shuaikang Liu,Shuang Zhou,Shuhao Hu,Siyu Xu,Songshan Gong,Tao Liang,Tianhao Hu,Wei He,Wei Shi,Wei Wang,Wei Wu,Wei Zhuo,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Xi Su,Xiangcheng Liu,Xiangyu Xi,Xiangzhou Huang,Xiao Liu,Xiaochen Jiang,Xiaowei Shi,Xiaowen Shi,Xiaoyu Li,Xin Chen,Xinyue Zhao,Xuan Huang,Xuemiao Zhang,Xuezhi Cao,Xunliang Cai,Yajie Zhang,Yang Chen,Yang Liu,Yang Liu,Yang Zheng,Yaoming Wang,Yaqi Huo,Yerui Sun,Yifan Lu,Yiyang Li,Youshao Xiao,Yuanzhe Lei,Yuchen Xie,Yueqing Sun,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunke Zhao,Yuqing Ding,Yuwei Jiang,Zhaohua Yang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhongda Su,Ziran Li,Ziwen Wang,Ziyuan Zhuang,Zongyu Wang,Zunyuan Yang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking是一个5600亿参数的开放源代码混合专家推理模型，通过精心设计的训练流程实现高效推理能力，包括长链思维数据冷启动和大规模强化学习。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够高效处理复杂推理任务的开放源代码模型，特别是在STEM、代码和智能体推理等领域实现最先进的性能。

Method: 采用冷启动训练策略增强推理潜力，然后通过领域并行训练方案将不同领域的专家模型融合成一个近乎帕累托最优的单一模型，使用DORA系统进行大规模RL训练。

Result: 在复杂推理任务上达到开源模型的最先进性能，在AIME-25上智能体推理的平均token消耗减少64.5%，从19,653降至6,965，且任务准确率不下降。

Conclusion: LongCat-Flash-Thinking展示了在推理系统和智能体AI研究方面的显著进展，模型已公开发布以促进该领域的进一步发展。

Abstract: We present LongCat-Flash-Thinking, an efficient 560-billion-parameter
open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities
are cultivated through a meticulously crafted training process, beginning with
long Chain-of-Thought (CoT) data cold-start and culminating in large-scale
Reinforcement Learning (RL). We first employ a well-designed cold-start
training strategy, which significantly enhances the reasoning potential and
equips the model with specialized skills in both formal and agentic reasoning.
Then, a core innovation is our domain-parallel training scheme, which decouples
optimization across distinct domains (e.g., STEM, Code, Agentic) and
subsequently fuses the resulting expert models into a single, nearly
Pareto-optimal model. This entire process is powered by our Dynamic
ORchestration for Asynchronous rollout (DORA) system, a large-scale RL
framework that delivers a greater than threefold training speedup over
synchronous methods on tens of thousands of accelerators. As a result,
LongCat-Flash-Thinking achieves state-of-the-art performance among open-source
models on a suite of complex reasoning tasks. The model exhibits exceptional
efficiency in agentic reasoning, reducing average token consumption by 64.5%
(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We
release LongCat-Flash-Thinking to promote further advances in reasoning systems
and agentic AI research.

</details>


### [67] [How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective](https://arxiv.org/abs/2509.18905)
*Songsong Yu,Yuxin Chen,Hao Ju,Lianjie Jia,Fuxi Zhang,Shaofei Huang,Yuhan Wu,Rundi Cui,Binghao Ran,Zaibin Zhang,Zhedong Zheng,Zhipeng Zhang,Yifan Wang,Lin Song,Lijun Wang,Yanwei Li,Ying Shan,Huchuan Lu*

Main category: cs.AI

TL;DR: 本文对视觉空间推理（VSR）进行了系统性研究，提出了空间智能的三级能力分类，并创建了SIBench基准测试，发现当前视觉语言模型在感知任务上表现良好，但在理解和规划任务上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 视觉空间推理是人类核心认知能力，对推进具身智能和自主系统至关重要。尽管视觉语言模型取得进展，但由于三维空间表示和推理的复杂性，实现人类水平的VSR仍极具挑战。

Method: 系统调查VSR在VLMs中的应用，包括输入模态、模型架构、训练策略和推理机制的综述；将空间智能分为基础感知、空间理解和空间规划三个能力级别；构建SIBench基准，涵盖23个任务设置的近20个开源数据集。

Result: 实验表明最先进的VLMs在感知和推理之间存在明显差距：模型在基础感知任务上有能力，但在理解和规划任务上持续表现不佳，特别是在数值估计、多视图推理、时间动态和空间想象方面。

Conclusion: 这些发现强调了实现空间智能仍面临的重大挑战，同时为未来研究提供了系统性路线图和全面基准。

Abstract: Visual Spatial Reasoning (VSR) is a core human cognitive ability and a
critical requirement for advancing embodied intelligence and autonomous
systems. Despite recent progress in Vision-Language Models (VLMs), achieving
human-level VSR remains highly challenging due to the complexity of
representing and reasoning over three-dimensional space. In this paper, we
present a systematic investigation of VSR in VLMs, encompassing a review of
existing methodologies across input modalities, model architectures, training
strategies, and reasoning mechanisms. Furthermore, we categorize spatial
intelligence into three levels of capability, ie, basic perception, spatial
understanding, spatial planning, and curate SIBench, a spatial intelligence
benchmark encompassing nearly 20 open-source datasets across 23 task settings.
Experiments with state-of-the-art VLMs reveal a pronounced gap between
perception and reasoning, as models show competence in basic perceptual tasks
but consistently underperform in understanding and planning tasks, particularly
in numerical estimation, multi-view reasoning, temporal dynamics, and spatial
imagination. These findings underscore the substantial challenges that remain
in achieving spatial intelligence, while providing both a systematic roadmap
and a comprehensive benchmark to drive future research in the field. The
related resources of this study are accessible at
https://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.

</details>


### [68] [Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning](https://arxiv.org/abs/2509.18942)
*Xiao Han,Zimo Zhao,Wanyu Wang,Maolin Wang,Zitao Liu,Yi Chang,Xiangyu Zhao*

Main category: cs.AI

TL;DR: DEAL是一个结合低秩适应(LoRA)和持续微调策略的新框架，通过知识保留和自适应参数更新模块解决传统微调方法的灾难性遗忘和数据效率低下的问题


<details>
  <summary>Details</summary>
Motivation: 传统微调方法存在灾难性遗忘和数据效率低下的问题，限制了在实际应用中的适用性，特别是在从头训练计算不可行的情况下

Method: 提出DEAL框架，集成低秩适应(LoRA)与持续微调策略，包含知识保留和自适应参数更新模块，在隐私保护设置下保持效率

Result: 在15个不同数据集上的实验表明，DEAL持续优于基线方法，在任务准确性和资源效率方面取得显著提升

Conclusion: 该方法有潜力通过增强任务性能同时提高资源效率来推进LLMs的持续适应

Abstract: Recent advancements in Large Language Models (LLMs) have emphasized the
critical role of fine-tuning (FT) techniques in adapting LLMs to specific
tasks, especially when retraining from scratch is computationally infeasible.
Fine-tuning enables LLMs to leverage task- or domain-specific data, producing
models that more effectively meet the requirements of targeted applications.
However, con- ventional FT approaches often suffer from catastrophic forgetting
and suboptimal data efficiency, limiting their real-world applicability. To
address these challenges, this paper proposes DEAL, a novel framework that
integrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.
By incorporating knowledge retention and adaptive parameter update modules, the
framework mitigates the lim- itations of existing FT methods while maintaining
efficiency in privacy-preserving settings. Experiments on 15 diverse datasets
show that DEAL consistently outper- forms baseline methods, yielding
substantial gains in task accuracy and resource efficiency. These findings
demonstrate the potential of our approach to advance continual adaptation in
LLMs by enhancing task performance while improving resource efficiency.

</details>


### [69] [LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions](https://arxiv.org/abs/2509.18970)
*Xixun Lin,Yucheng Ning,Jingwen Zhang,Yan Dong,Yilong Liu,Yongxuan Wu,Xiaohua Qi,Nan Sun,Yanmin Shang,Pengfei Cao,Lixin Zou,Xu Chen,Chuan Zhou,Jia Wu,Shirui Pan,Bin Wang,Yanan Cao,Kai Chen,Songlin Hu,Li Guo*

Main category: cs.AI

TL;DR: 本文是第一篇关于LLM-based agents幻觉问题的全面综述，提出了新的分类法识别不同阶段的幻觉类型，深入分析了18种触发原因，并总结了幻觉缓解和检测方法。


<details>
  <summary>Details</summary>
Motivation: LLM-based agents在现实应用中存在幻觉问题，可能导致错误任务执行和系统可靠性下降，需要系统性地理解和整合相关研究进展。

Method: 通过仔细分析agents的完整工作流程，提出新的分类法识别不同阶段的幻觉类型，深入分析18种触发原因，并综述大量现有研究的幻觉缓解和检测方法。

Result: 建立了全面的LLM-based agents幻觉分类体系，识别了多种幻觉类型和触发机制，总结了有效的缓解和检测策略。

Conclusion: 该综述为LLM-based agents的幻觉问题研究提供了系统框架，有助于开发更鲁棒可靠的agent系统，并指出了未来研究方向。

Abstract: Driven by the rapid advancements of Large Language Models (LLMs), LLM-based
agents have emerged as powerful intelligent systems capable of human-like
cognition, reasoning, and interaction. These agents are increasingly being
deployed across diverse real-world applications, including student education,
scientific research, and financial analysis. However, despite their remarkable
potential, LLM-based agents remain vulnerable to hallucination issues, which
can result in erroneous task execution and undermine the reliability of the
overall system design. Addressing this critical challenge requires a deep
understanding and a systematic consolidation of recent advances on LLM-based
agents. To this end, we present the first comprehensive survey of
hallucinations in LLM-based agents. By carefully analyzing the complete
workflow of agents, we propose a new taxonomy that identifies different types
of agent hallucinations occurring at different stages. Furthermore, we conduct
an in-depth examination of eighteen triggering causes underlying the emergence
of agent hallucinations. Through a detailed review of a large number of
existing studies, we summarize approaches for hallucination mitigation and
detection, and highlight promising directions for future research. We hope this
survey will inspire further efforts toward addressing hallucinations in
LLM-based agents, ultimately contributing to the development of more robust and
reliable agent systems.

</details>


### [70] [From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system](https://arxiv.org/abs/2509.18980)
*Maxime Manderlier,Fabian Lecron,Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.AI

TL;DR: 研究大型语言模型能否从数学可解释的推荐模型中生成有效的用户导向解释，通过用户研究评估不同解释策略的质量。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI研究多依赖自动评估指标，但这些指标往往无法捕捉用户的实际需求和感知，因此需要采用用户中心的方法来评估解释质量。

Method: 使用基于约束矩阵分解的可解释推荐模型，通过精心设计的LLM提示将模型结构转化为自然语言解释，并对326名参与者进行用户研究，评估五种关键维度的解释质量。

Result: 所有解释类型都普遍受到好评，不同策略之间存在适度的统计差异，用户评论提供了定量结果之外的补充见解。

Conclusion: LLM能够从数学可解释的推荐模型中生成有效的用户导向解释，用户中心评估方法为解释质量提供了更全面的理解。

Abstract: We investigate whether large language models (LLMs) can generate effective,
user-facing explanations from a mathematically interpretable recommendation
model. The model is based on constrained matrix factorization, where user types
are explicitly represented and predicted item scores share the same scale as
observed ratings, making the model's internal representations and predicted
scores directly interpretable. This structure is translated into natural
language explanations using carefully designed LLM prompts. Many works in
explainable AI rely on automatic evaluation metrics, which often fail to
capture users' actual needs and perceptions. In contrast, we adopt a
user-centered approach: we conduct a study with 326 participants who assessed
the quality of the explanations across five key dimensions-transparency,
effectiveness, persuasion, trust, and satisfaction-as well as the
recommendations themselves.To evaluate how different explanation strategies are
perceived, we generate multiple explanation types from the same underlying
model, varying the input information provided to the LLM. Our analysis reveals
that all explanation types are generally well received, with moderate
statistical differences between strategies. User comments further underscore
how participants react to each type of explanation, offering complementary
insights beyond the quantitative results.

</details>


### [71] [Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)](https://arxiv.org/abs/2509.18986)
*Erik Penther,Michael Grohs,Jana-Rebecca Rehse*

Main category: cs.AI

TL;DR: 本文比较了四种剩余时间预测方法在物流公司出库仓库流程中的性能，发现深度学习模型准确率最高，但浅层方法如传统提升技术在计算资源需求上更高效且具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 预测性流程监控旨在预测正在进行的流程执行的未来，其中剩余时间预测是一个常见目标。本文旨在在真实物流公司出库仓库流程中比较不同剩余时间预测方法的性能。

Method: 在物流公司提供的包含169,523条轨迹的原始事件日志上，比较了四种剩余时间预测方法，包括深度学习模型和浅层方法如传统提升技术。

Result: 深度学习模型达到最高准确率，但浅层方法如传统提升技术具有竞争力的准确率，且需要显著更少的计算资源。

Conclusion: 虽然深度学习在剩余时间预测上表现最佳，但浅层方法在准确率和计算效率之间提供了更好的平衡，特别是在资源受限的环境中更具实用性。

Abstract: Predictive process monitoring is a sub-domain of process mining which aims to
forecast the future of ongoing process executions. One common prediction target
is the remaining time, meaning the time that will elapse until a process
execution is completed. In this paper, we compare four different remaining time
prediction approaches in a real-life outbound warehouse process of a logistics
company in the aviation business. For this process, the company provided us
with a novel and original event log with 169,523 traces, which we can make
publicly available. Unsurprisingly, we find that deep learning models achieve
the highest accuracy, but shallow methods like conventional boosting techniques
achieve competitive accuracy and require significantly fewer computational
resources.

</details>


### [72] [Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action](https://arxiv.org/abs/2509.19030)
*Victoire Hervé,Henrik Warpefelt,Christoph Salge*

Main category: cs.AI

TL;DR: 提出基于玩家视角的Landmarks、Monuments和Beacons概念，用于自动分解和评估程序生成内容的子组件，以改善算法评估与人类体验的一致性。


<details>
  <summary>Details</summary>
Motivation: 算法评估程序生成内容时难以找到与人类体验一致的指标，特别是对于复合产物。需要满足多种属性的概念来实现自动分解。

Method: 引入基于可感知性、唤起性和行动召唤的Landmarks、Monuments和Beacons概念，这些概念具有游戏通用性，可利用现有技术进行识别和评估。

Result: 这些概念为完全自动化的PCG分解和显著子组件评估开辟了路径，连接了人文学科和技术游戏研究。

Conclusion: 该方法不仅适用于混合主动PCG和组合PCG，还可应用于更广泛的领域，实现更好的计算PCG评估。

Abstract: Algorithmic evaluation of procedurally generated content struggles to find
metrics that align with human experience, particularly for composite artefacts.
Automatic decomposition as a possible solution requires concepts that meet a
range of properties. To this end, drawing on Games Studies and Game AI
research, we introduce the nested concepts of \textit{Landmarks},
\textit{Monuments}, and \textit{Beacons}. These concepts are based on the
artefact's perceivability, evocativeness, and Call to Action, all from a
player-centric perspective. These terms are generic to games and usable across
genres. We argue that these entities can be found and evaluated with techniques
currently used in both research and industry, opening a path towards a fully
automated decomposition of PCG, and evaluation of the salient sub-components.
Although the work presented here emphasises mixed-initiative PCG and
compositional PCG, we believe it applies beyond those domains. With this
approach, we intend to create a connection between humanities and technical
game research and allow for better computational PCG evaluation

</details>


### [73] [Towards Causal Representation Learning with Observable Sources as Auxiliaries](https://arxiv.org/abs/2509.19058)
*Kwonho Kim,Heejeong Nam,Inwoo Hwang,Sanghack Lee*

Main category: cs.AI

TL;DR: 本文提出了一个使用可观察源作为辅助变量的因果表示学习框架，能够在已知潜因果图的情况下识别潜变量，并通过实验验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有因果表示学习框架通常将辅助变量限制为混合函数外部变量，但实际中系统驱动的潜因子可能容易从数据中观察或提取，这有助于识别潜变量。

Method: 引入可观察源作为辅助变量的框架，使用保体积编码器实现潜变量的子空间变换和排列识别，并提供变量选择方案来最大化潜因子可恢复性。

Result: 实验在合成图和图像数据上验证了框架的有效性，能够识别整个潜变量。

Conclusion: 该框架扩展了当前方法的边界，通过利用可观察源作为辅助变量改进了因果表示学习的识别能力。

Abstract: Causal representation learning seeks to recover latent factors that generate
observational data through a mixing function. Needing assumptions on latent
structures or relationships to achieve identifiability in general, prior works
often build upon conditional independence given known auxiliary variables.
However, prior frameworks limit the scope of auxiliary variables to be external
to the mixing function. Yet, in some cases, system-driving latent factors can
be easily observed or extracted from data, possibly facilitating
identification. In this paper, we introduce a framework of observable sources
being auxiliaries, serving as effective conditioning variables. Our main
results show that one can identify entire latent variables up to subspace-wise
transformations and permutations using volume-preserving encoders. Moreover,
when multiple known auxiliary variables are available, we offer a
variable-selection scheme to choose those that maximize recoverability of the
latent factors given knowledge of the latent causal graph. Finally, we
demonstrate the effectiveness of our framework through experiments on synthetic
graph and image data, thereby extending the boundaries of current approaches.

</details>


### [74] [Code Driven Planning with Domain-Adaptive Critic](https://arxiv.org/abs/2509.19077)
*Zikang Tian,Shaohui Peng,Du Huang,Jiaming Guo,Ruizhi Chen,Rui Zhang,Xishan Zhang,Yuxuan Guo,Zidong Du,Qi Guo,Ling Li,Yewen Pu,Xing Hu,Yunji Chen*

Main category: cs.AI

TL;DR: CoPiC提出了一种基于代码驱动规划和领域自适应批评器的LLM任务规划方法，通过生成多样化高级规划程序并利用训练好的批评器评估候选计划，显著减少LLM查询次数并提高长期奖励对齐。


<details>
  <summary>Details</summary>
Motivation: 现有LLM任务规划方法依赖频繁查询进行迭代优化，导致高查询成本且难以对齐长期奖励。需要一种既能减少查询次数又能优化长期规划性能的方法。

Method: CoPiC使用LLM生成多样化高级规划程序，这些程序迭代产生和优化候选计划。然后通过训练好的领域自适应批评器评估候选计划，选择最符合长期奖励的方案执行。

Result: 在ALFWorld、NetHack和StarCraft II Unit Building三个环境中，CoPiC相比AdaPlanner和Reflexion等先进基线方法，平均成功率提升23.33%，查询成本降低91.27%。

Conclusion: CoPiC通过代码驱动规划和领域自适应批评器的结合，有效解决了LLM在任务规划中的查询成本高和长期奖励对齐问题，为AI代理的序列决策提供了更高效的解决方案。

Abstract: Large Language Models (LLMs) have been widely adopted as task planners for AI
agents in sequential decision-making problems, leveraging their extensive world
knowledge. However, the gap between their general knowledge and
environment-specific requirements often leads to inaccurate plans. To address
this, existing approaches rely on frequent LLM queries to iteratively refine
plans based on immediate environmental feedback, which incurs substantial query
costs. However, this refinement is typically guided by short-term environmental
feedback, limiting LLMs from developing plans aligned with long-term rewards.
We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of
relying on frequent queries, CoPiC employs LLMs to generate a diverse set of
high-level planning programs, which iteratively produce and refine candidate
plans. A trained domain-adaptive critic then evaluates these candidates and
selects the one most aligned with long-term rewards for execution. Using
high-level planning programs as planner and domain-adaptive critic as
estimator, CoPiC improves planning while significantly reducing query costs.
Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC
outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving
an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in
query costs.

</details>


### [75] [AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration](https://arxiv.org/abs/2509.19236)
*Chunhao Tian,Yutong Wang,Xuebo Liu,Zhexuan Wang,Liang Ding,Miao Zhang,Min Zhang*

Main category: cs.AI

TL;DR: AgentInit是一种多智能体系统初始化方法，通过优化智能体团队结构来提升系统性能，结合自然语言格式化机制和帕累托平衡选择策略，在多种任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MAS初始化方法未能充分考虑后续阶段生成智能体的协作需求，需要一种能够优化智能体团队结构的方法来提升系统效率和效果。

Method: 提出AgentInit方法，包含多轮智能体交互反思、自然语言到格式的转换机制确保一致性，以及基于帕累托原则的平衡团队选择策略，综合考虑团队多样性和任务相关性。

Result: 实验显示AgentInit在各种框架和任务中均优于最先进的初始化方法和预定义策略，整体性能提升分别达到1.2和1.6倍，同时显著减少token消耗。

Conclusion: AgentInit具有良好的可迁移性，关键组件有效性得到验证，证明其作为可靠MAS初始化方法的能力和适应性。

Abstract: Proper initialization is crucial for any system, particularly in multi-agent
systems (MAS), where it plays a pivotal role in determining both the system's
efficiency and effectiveness. However, existing MAS initialization methods do
not fully account for the collaborative needs of the generated agents in
subsequent stages. Inspired by the principles of effective team composition, we
propose AgentInit, which aims to optimize the structure of agent teams.
Specifically, in addition to multi-round interactions and reflections between
agents during agent generation, AgentInit incorporates a Natural Language to
Format mechanism to ensure consistency and standardization. Balanced team
selection strategies using Pareto principles are subsequently applied to
jointly consider agent team diversity and task relevance to promote effective
and efficient collaboration and enhance overall system performance. Experiments
show that AgentInit consistently outperforms state-of-the-art initialization
methods and pre-defined strategies across various frameworks and tasks,
achieving an overall performance improvement of up to 1.2 and 1.6,
respectively, while also significantly reducing token consumption. Further
analysis confirms its strong transferability to similar tasks and verifies the
effectiveness of its key components, demonstrating its capability and
adaptability as a reliable MAS initialization method. Source code and models
are available at https://github.com/1737423697/AgentInit.

</details>


### [76] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型在阿拉伯世界的跨文化常识推理迁移，发现仅需少量文化特定示例即可显著提升模型在其他文化背景下的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在西方中心偏见，限制了其在多元文化环境中的有效性。虽然已有研究探索文化对齐，但跨文化迁移潜力（利用一种文化的对齐来改善其他文化的性能）仍未被充分探索。

Method: 使用覆盖13个阿拉伯国家的文化基础常识推理数据集，评估轻量级对齐方法（如上下文学习、演示强化DITTO）以及基线方法（监督微调、直接偏好优化）。

Result: 仅需来自一个国家的12个文化特定示例，即可在多语言模型中平均提升其他文化10%的性能。来自印尼和美国的跨文化演示在MCQ推理中能够匹配甚至超越文化内对齐效果。

Conclusion: 高效的跨文化对齐是可行的，这为将LLM适配到低资源文化环境提供了一种有前景的方法。

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [77] [Optimal estimation for regression discontinuity design with binary outcomes](https://arxiv.org/abs/2509.18857)
*Takuya Ishihara,Masayuki Sawada,Kohei Yata*

Main category: econ.EM

TL;DR: 本文开发了一种有限样本最优估计器，用于处理结果变量有界（包括二元结果）的断点回归设计。该估计器在回归函数属于Lipschitz类时，在线性收缩估计器中达到精确的极小极大均方误差。


<details>
  <summary>Details</summary>
Motivation: 传统的大样本方法在小样本情况下可能不可靠，特别是在有效样本量较小时。本文旨在解决小样本断点回归估计的挑战，特别是当结果变量有界时。

Method: 通过求解凸优化问题获得有限样本最优估计器，仅需Lipschitz常数作为调优参数。同时提出了无需大样本近似的统一有效推断程序。

Result: 在小样本模拟中，该估计器比传统大样本技术具有更小的均方误差和更短的置信区间。在实际应用中，即使在每个断点样本量较小的情况下，也能产生信息丰富的置信区间。

Conclusion: 该方法为小样本断点回归设计提供了可靠且高效的估计和推断工具，特别适用于结果变量有界的情况，解决了传统大样本方法在小样本场景下的局限性。

Abstract: We develop a finite-sample optimal estimator for regression discontinuity
designs when the outcomes are bounded, including binary outcomes as the leading
case. Our finite-sample optimal estimator achieves the exact minimax mean
squared error among linear shrinkage estimators with nonnegative weights when
the regression function of a bounded outcome lies in a Lipschitz class.
Although the original minimax problem involves an iterating (n+1)-dimensional
non-convex optimization problem where n is the sample size, we show that our
estimator is obtained by solving a convex optimization problem. A key advantage
of our estimator is that the Lipschitz constant is the only tuning parameter.
We also propose a uniformly valid inference procedure without a large-sample
approximation. In a simulation exercise for small samples, our estimator
exhibits smaller mean squared errors and shorter confidence intervals than
conventional large-sample techniques which may be unreliable when the effective
sample size is small. We apply our method to an empirical multi-cutoff design
where the sample size for each cutoff is small. In the application, our method
yields informative confidence intervals, in contrast to the leading
large-sample approach.

</details>


### [78] [Driver Identification and PCA Augmented Selection Shrinkage Framework for Nordic System Price Forecasting](https://arxiv.org/abs/2509.18887)
*Yousef Adeli Sadabad,Mohammad Reza Hesamzadeh,Gyorgy Dan,Matin Bagherpour,Darryl R. Biggar*

Main category: econ.EM

TL;DR: 本文提出了一个结合可解释驱动因素分析和稳健预测方法的系统框架，用于预测北欧电力市场的系统价格。该方法通过特征工程识别主要驱动因素，应用PCA处理多重共线性，并提出多预测选择-收缩算法来优化预测组合。


<details>
  <summary>Details</summary>
Motivation: 北欧电力市场的系统价格是金融对冲合约的关键参考，准确预测系统价格对市场参与者设计有效对冲策略至关重要。

Method: 提出可解释特征工程算法（结合K-means聚类、MSTD分解和SARIMA模型）识别驱动因素，应用PCA处理数据，开发多预测选择-收缩算法进行价格预测。

Result: 使用北欧电力市场历史数据验证，该方法在保持可比计算成本的同时，显著优于单个输入模型和最先进的TFT方法，也超越了多个成熟的预测组合方法。

Conclusion: 所提出的系统框架能够产生优越的预测结果，使用简单的输入模型即可超越现有先进方法，为电力市场价格预测提供了有效的解决方案。

Abstract: The System Price (SP) of the Nordic electricity market serves as a key
reference for financial hedge contracts such as Electricity Price Area
Differentials (EPADs) and other risk management instruments. Therefore, the
identification of drivers and the accurate forecasting of SP are essential for
market participants to design effective hedging strategies. This paper develops
a systematic framework that combines interpretable drivers analysis with robust
forecasting methods. It proposes an interpretable feature engineering algorithm
to identify the main drivers of the Nordic SP based on a novel combination of
K-means clustering, Multiple Seasonal-Trend Decomposition (MSTD), and Seasonal
Autoregressive Integrated Moving Average (SARIMA) model. Then, it applies
principal component analysis (PCA) to the identified data matrix, which is
adapted to the downstream task of price forecasting to mitigate the issue of
imperfect multicollinearity in the data. Finally, we propose a multi-forecast
selection-shrinkage algorithm for Nordic SP forecasting, which selects a subset
of complementary forecast models based on their bias-variance tradeoff at the
ensemble level and then computes the optimal weights for the retained forecast
models to minimize the error variance of the combined forecast. Using
historical data from the Nordic electricity market, we demonstrate that the
proposed approach outperforms individual input models uniformly, robustly, and
significantly, while maintaining a comparable computational cost. Notably, our
systematic framework produces superior results using simple input models,
outperforming the state-of-the-art Temporal Fusion Transformer (TFT).
Furthermore, we show that our approach also exceeds the performance of several
well-established practical forecast combination methods.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [79] [Sequential Design for the Efficient Estimation of Offshore Structure Failure Probability](https://arxiv.org/abs/2509.18319)
*Matthew Speers,Jonathan Angus Tawn,Philip Jonathan*

Main category: stat.AP

TL;DR: 该论文提出了两种估计海上结构失效概率的方法：IS-PT（结合并行退火MCMC和重要性采样）和AGE（结合自适应高斯仿真与贝叶斯积分），并在合成结构和单桩结构上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 估计海上结构在极端海洋环境下的失效概率对其安全设计和运行至关重要，需要开发高效可靠的计算方法。

Method: IS-PT方法结合并行退火MCMC进行条件密度估计和重要性采样进行失效概率计算；AGE方法使用自适应高斯仿真和贝叶斯积分，需要平衡探索与利用的参数lambda。

Result: IS-PT在两个应用案例中都提供了可靠结果，计算成本低于朴素积分；当lambda参数已知时，AGE能进一步降低计算成本，但当lambda未知时，IS-PT更可靠。

Conclusion: IS-PT方法在计算成本和可靠性方面表现良好，特别是当AGE方法的关键参数未知时，IS-PT是更可靠的选择。

Abstract: Estimation of the failure probability of offshore structures exposed to
extreme ocean environments is critical to their safe design and operation. The
conditional density of the environment (CDE) quantifies regions of the space of
long term environment responsible for extreme structural response. Moreover,
the probability of structural failure is obtained by simply integrating the CDE
over the environment space. In this work, two methodologies for estimation of
the CDE and failure probability are considered. The first (IS-PT) combines
parallel tempering MCMC (for CDE estimation) with important sampling (for
eventual estimation of failure probability). The second (AGE) combines adaptive
Gaussian emulation with Bayesian quadrature. We evaluate IS-PT and two variants
of the AGE procedure in application to a simple synthetic structure with
multimodal CDE, and a monopile structure exhibiting non-linear resonant
response. IS-PT provides reliable results for both applications for lesser
compute cost than naive integration. The AGE procedures require balancing
exploration and exploitation of the environment space, using a
typically-unknown weight parameter, lambda. When lambda is known, perhaps from
prior engineering knowledge, AGE provides a further reduction in computational
cost over IS-PT. However, when unknown, IS-PT is more reliable.

</details>


### [80] [Hierarchical Semi-Markov Models with Duration-Aware Dynamics for Activity Sequences](https://arxiv.org/abs/2509.18414)
*Rohit Dube,Natarajan Gautam,Amarnath Banerjee,Harsha Nagarajan*

Main category: stat.AP

TL;DR: 本文开发了一个分层半马尔可夫框架来生成人类活动序列，用于预测住宅电力需求。该模型通过马尔可夫路由器和半马尔可夫风险组件分别建模活动顺序和持续时间，在测试集上显示出比纯马尔可夫模型显著更好的性能。


<details>
  <summary>Details</summary>
Motivation: 准确预测住宅电力需求需要能够生成真实日常活动序列的生成模型，捕捉人类行为的时间和持续时间模式，以支持微电网管理和需求响应等应用。

Method: 提出分层半马尔可夫框架：1）时间非齐次马尔可夫路由器学习"下一个活动是什么"的模式；2）半马尔可夫风险组件显式建模活动持续时间；3）通过跨人口统计组和时间块的信息共享确保统计稳定性；4）使用调查设计权重确保结果具有美国人口代表性。

Result: 显式建模持续时间的风险组件相比纯马尔可夫模型提供了显著改进；人口统计因素重要性排序：性别、日期类型和家庭规模预测增益最大，而地区和季节对活动序列本身预测贡献较小。

Conclusion: 该方法产生可解释且稳健的合成活动轨迹生成器，为下游能源系统建模提供了高保真基础。

Abstract: Residential electricity demand at granular scales is driven by what people do
and for how long. Accurately forecasting this demand for applications like
microgrid management and demand response therefore requires generative models
that can produce realistic daily activity sequences, capturing both the timing
and duration of human behavior. This paper develops a generative model of human
activity sequences using nationally representative time-use diaries at a
10-minute resolution. We use this model to quantify which demographic factors
are most critical for improving predictive performance.
  We propose a hierarchical semi-Markov framework that addresses two key
modeling challenges. First, a time-inhomogeneous Markov \emph{router} learns
the patterns of ``which activity comes next." Second, a semi-Markov
\emph{hazard} component explicitly models activity durations, capturing ``how
long" activities realistically last. To ensure statistical stability when data
are sparse, the model pools information across related demographic groups and
time blocks. The entire framework is trained and evaluated using survey design
weights to ensure our findings are representative of the U.S. population.
  On a held-out test set, we demonstrate that explicitly modeling durations
with the hazard component provides a substantial and statistically significant
improvement over purely Markovian models. Furthermore, our analysis reveals a
clear hierarchy of demographic factors: Sex, Day-Type, and Household Size
provide the largest predictive gains, while Region and Season, though important
for energy calculations, contribute little to predicting the activity sequence
itself. The result is an interpretable and robust generator of synthetic
activity traces, providing a high-fidelity foundation for downstream energy
systems modeling.

</details>


### [81] [Evaluating Bias Reduction Methods in Binary Emax Model for Reliable Dose-Response Estimation](https://arxiv.org/abs/2509.18459)
*Jiangshan Zhang,Vivek Pradhan,Yuxi Zhao*

Main category: stat.AP

TL;DR: 本文研究了三种偏差减少方法（Cox-Snell偏差校正、Firth-score修正和Jeffreys先验的最大惩罚似然估计器）在二元Emax模型中的应用，通过模拟研究和TURANDOT研究数据验证了MPLE方法在稳定性和方差控制方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 二元Emax模型在II期临床试验中广泛用于剂量反应分析，但最大似然估计在小样本或模型假设违反时存在问题，需要更可靠的偏差减少方法。

Method: 通过全面的模拟研究评估三种偏差减少方法（Cox-Snell、Firth和MPLE）在减少偏差和控制方差方面的性能，特别是在模型假设违反的情况下。

Result: Firth和MPLE方法都能提供稳健的估计，但MPLE在稳定性和方差控制方面表现更优，特别是在剂量反应关系偏离单调性时。

Conclusion: 使用Jeffreys先验的MPLE方法为Firth方法提供了有效可靠的替代方案，特别适用于剂量反应关系偏离单调性的情况，对剂量范围研究中的稳健参数估计具有重要价值。

Abstract: The Binary Emax model is widely employed in dose-response analysis during
Phase II clinical studies to identify the optimal dose for subsequence
confirmatory trials. The parameter estimation and inference heavily rely on the
asymptotic properties of Maximum Likelihood (ML) estimators; however, this
approach may be questionable under small or moderate sample sizes and is not
robust to violation of model assumptions. To provide a reliable solution, this
paper examines three bias-reduction methods: the Cox-Snell bias correction,
Firth-score modification, and a maximum penalized likelihood estimator (MPLE)
using Jeffreys prior. Through comprehensive simulation studies, we evaluate the
performance of these methods in reducing bias and controlling variance,
especially when model assumptions are violated. The results demonstrate that
both Firth and MPLE methods provide robust estimates, with MPLE outperforming
in terms of stability and lower variance. We further illustrate the practical
application of these methods using data from the TURANDOT study, a Phase II
clinical trial. Our findings suggest that MPLE with Jeffreys prior offers an
effective and reliable alternative to the Firth method, particularly for
dose-response relationships that deviate from monotonicity, making it valuable
for robust parameter estimation in dose-ranging studies.

</details>


### [82] [The information flow among Green Bonds exchange traded funds](https://arxiv.org/abs/2509.19285)
*Wenderson Gomes Barbosa,Kerolly Kedma Felix do Nascimento,Fabio Sandro dos Santos,Tiago A. E. Ferreira*

Main category: stat.AP

TL;DR: 本文研究了2021-2022年间美国、加拿大和欧洲三个全球市场中13只绿色债券ETF之间的信息流动，发现美国市场在信息传递中占据主导地位。


<details>
  <summary>Details</summary>
Motivation: 了解全球绿色债券ETF市场之间的信息流动方向和维度，识别各市场中的主导ETF和信息传递模式。

Method: 使用转移熵和有效转移熵方法来建模和分析绿色债券价格信息在不同全球市场之间的流动。

Result: 美国市场在三个市场中表现主导地位；FLMB ETF是信息传递最活跃的ETF；欧洲市场的FLRG和GRON.MI债券在欧洲内部信息传递中起主要作用；KLMH.F是最大的信息接收者。

Conclusion: 通过研究明确了绿色债券ETF市场间信息流动的方向和维度，为理解全球绿色债券市场的联动性提供了重要见解。

Abstract: This article investigates the information flow between 13 Green Bond ETFs
(Exchange Traded Funds) from three global markets: the USA, Canada,and Europe,
between 2021 and 2022. We used the transfer entropy and effective transfer
entropy methods to model and investigate the Green Bond price information flow
between these global markets. The American market demonstrated market dominance
among the other two markets (Canadian and European). The FLMB Green Bond of the
American ETF presented the greatest flow of information transfer among the ETFs
analyzed, being considered the dominant ETF among the three Green Bond ETF
markets investigated. The HGGB ETF has emerged as a major information
transmitter in Europe and in the Canadian market, but it has had a strong
influence from the American ETF FLMB. In the European market, the FLRG and
GRON.MI bonds played a major role in the flow of information sent to other ETFs
in Europe. The KLMH.F in Europe is highlighted as the largest receiver of
information. Thus, through this article, it was possible to understand the
direction of the flow of information between the Green Bond ETF markets and
their dimensionality.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [83] [Stochastic Economic Dispatch with Battery Energy Storage considering Wind and Load Uncertainty](https://arxiv.org/abs/2509.18100)
*Shishir Lamichhane,Anamika Dubey*

Main category: eess.SY

TL;DR: 本文提出了一种随机动态经济调度与储能（SDED-S）框架，用于评估电池储能系统（BESS）在管理不确定性方面的作用，通过考虑风能和负荷不确定性的时间相关性，在改进的IEEE 39总线系统上验证了BESS部署对减少可再生能源弃电和调度成本的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源在电力系统中的集成，如何在最小化运营成本的同时管理运行灵活性和可靠性变得日益困难。电池储能系统（BESS）为解决这些问题提供了有前景的解决方案。

Method: 采用基于分层和重要性采样的方法生成场景，捕捉风能和负荷不确定性的时间相关性，并在改进的IEEE 39总线系统上进行案例研究，其中部分常规发电机被转换为风电场。

Result: 案例研究表明，战略性BESS部署显著提高了系统灵活性，减少了可再生能源弃电和调度成本。BESS规模增大时弃电减少，且在高风电渗透率下成本节约更明显。

Conclusion: 随着可再生能源渗透率的增加，对灵活性的需求日益增长，BESS部署在高风电渗透率下能有效减少弃电并带来更大的成本节约。

Abstract: With the integration of renewable energy resources in power systems, managing
operational flexibility and reliability while minimizing operational costs has
become increasingly challenging. Battery energy storage system (BESS) offers a
promising solution to address these issues. This paper presents a stochastic
dynamic economic dispatch with storage (SDED-S) framework to assess the impact
of BESS in managing uncertainty. The temporal correlation between wind and load
uncertainties is captured, with scenarios generated using a method inspired by
stratified and importance sampling. The proposed approach is demonstrated on a
modified IEEE 39-bus system, where selected conventional generators are
converted to wind power plants. Case studies show that strategic BESS
deployment significantly improves system flexibility by reducing renewable
curtailments and dispatch costs. Renewable energy curtailments decrease upon
increasing BESS size and approach zero depending on wind penetration level.
Higher wind penetrations result in greater curtailments without storage and
yield larger cost savings when BESS is deployed, highlighting the growing need
for flexibility as renewable energy penetrations increase.

</details>


### [84] [Reversible Kalman Filter for state estimation with Manifold](https://arxiv.org/abs/2509.18224)
*Svyatoslav Covanov,Cedric Pradalier*

Main category: eess.SY

TL;DR: 本文提出了一种在流形上进行状态估计的卡尔曼滤波算法，旨在评估现有卡尔曼滤波器变体在合成数据上的精度，并修正先前变体的发散问题。


<details>
  <summary>Details</summary>
Motivation: 现有卡尔曼滤波器变体在合成数据上的精度评估方法尚未得到充分研究，且存在数值发散问题。本文旨在提供一种能够准确评估滤波器精度的方法，并改进滤波器的数值稳定性。

Method: 开发了一种新的卡尔曼滤波器，具有更好的数值特性，不再受小速度假设的限制，精度仅由传感器噪声决定。滤波器假设传感器具有高精度，并通过启发式检测步骤扩展至实际场景，适用于9轴IMU或组合传感器配置。

Result: 新滤波器修正了先前变体的发散问题，提高了数值稳定性，并在水下环境轨迹重建等实际场景中表现出良好的适用性。

Conclusion: 本文提出的滤波器在流形状态估计中实现了更高的精度和稳定性，为合成数据评估和实际应用提供了有效工具。

Abstract: This work introduces an algorithm for state estimation on manifolds within
the framework of the Kalman filter. Its primary objective is to provide a
methodology enabling the evaluation of the precision of existing Kalman filter
variants with arbitrary accuracy on synthetic data, something that, to the best
of our knowledge, has not been addressed in prior work. To this end, we develop
a new filter that exhibits favorable numerical properties, thereby correcting
the divergences observed in previous Kalman filter variants. In this
formulation, the achievable precision is no longer constrained by the
small-velocity assumption and is determined solely by sensor noise. In
addition, this new filter assumes high precision on the sensors, which, in real
scenarios require a detection step that we define heuristically, allowing one
to extend this approach to scenarios, using either a 9-axis IMU or a
combination of odometry, accelerometer, and pressure sensors. The latter
configuration is designed for the reconstruction of trajectories in underwater
environments.

</details>


### [85] [Watts and Drops: Co-Scheduling Power and Water in Desalination Plants](https://arxiv.org/abs/2509.19243)
*Ahmed S. Alahmed,Audun Botterud,Saurabh Amin,Ali T. Al-Awami*

Main category: eess.SY

TL;DR: 本文开发了一个数学框架来联合调度水电，优化可再生能源共址海水淡化厂的利润，该厂整合了热法和膜法技术。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时优化水生产和电力交易的调度策略，使可再生能源海水淡化厂能够根据内部发电情况和电网电价实现利润最大化。

Method: 建立数学优化框架，考虑热法和膜法两种海水淡化技术的特性，允许双向电力交易（购买或出售电力），并基于可再生能源输出制定阈值调度策略。

Result: 最优调度策略具有简单的阈值结构：热法水产量随可再生能源输出单调递减，而膜法水产量随可再生能源输出单调递增。

Conclusion: 该研究为可再生能源海水淡化厂提供了一种有效的联合调度方法，通过阈值策略实现了水电资源的优化配置和利润最大化。

Abstract: We develop a mathematical framework to jointly schedule water and electricity
in a profit-maximizing renewable colocated water desalination plant that
integrates both thermal and membrane based technologies. The price-taking
desalination plant sells desalinated water to a water utility at a given price
and engages in bidirectional electricity transactions with the grid, purchasing
or selling power based on its net electricity demand. We show that the optimal
scheduling policy depends on the plant's internal renewable generation and
follows a simple threshold structure. Under the optimal policy, thermal based
water output decreases monotonically with renewable output, while membrane
based water output increases monotonically. We characterize the structure and
intuition behind the threshold policy and examine key special properties.

</details>


### [86] [Fully Distributed State Estimation for Multi-agent Systems and its Application in Cooperative Localization](https://arxiv.org/abs/2509.18292)
*Shuaiting Huang,Haodong Jiang,Chengcheng Zhao,Peng Cheng,Junfeng Wu*

Main category: eess.SY

TL;DR: 本文研究了连续时间线性多智能体系统的分布式状态估计问题，提出了一种分布式观测器，使每个智能体能够重构整个系统的状态。通过领导-跟随一致性规则和Luenberger类估计规则，在节点级可观测性和拓扑排序一致性的假设下，证明了估计误差动态可稳定的充要条件是通信图强连通。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中每个智能体需要估计整个系统状态的问题，特别是在智能体只能获得局部信息的情况下，实现完全分布式的状态估计。

Method: 提出分布式观测器，每个智能体使用领导-跟随一致性规则跟踪其他智能体的状态估计，结合Luenberger类估计规则。设计了完全分布式方案，智能体仅需知道基本配置信息（如同质性和最大允许智能体数）。

Result: 证明了估计误差动态可稳定的充要条件是通信图强连通。开发了两种完全分布式定位算法，使智能体能够跟踪自身和其他智能体的位置和速度。仿真验证了理论结果的有效性。

Conclusion: 所提出的分布式观测器在强连通通信图条件下能够有效实现多智能体系统的状态估计，完全分布式设计保证了系统的可扩展性和鲁棒性，适用于智能体动态加入或退出的场景。

Abstract: In this paper, we investigate the distributed state estimation problem for a
continuous-time linear multi-agent system (MAS) composed of $\mathit{m}$ agents
and monitored by the agents themselves. To address this problem, we propose a
distributed observer that enables each agent to reconstruct the state of the
MAS. The main idea is to let each agent $\mathit{i}$ recover the state of agent
$\mathit{j}$ by using leader-follower consensus rules to track agent
$\mathit{j}$'s state estimate, which is generated by agent $\mathit{j}$ itself
using a Luenberger-like estimation rule. Under the assumptions of node-level
observability and topological ordering consistency, we show that the estimation
error dynamics are stabilizable if and only if the communication graph is
strongly connected. Moreover, we discuss the fully distributed design of the
proposed observer, assuming that the agents only know basic MAS configuration
information, such as the homogeneity and the maximum number of allowable
agents. This design ensures that the proposed observer functions correctly when
agents are added or removed. Building on this, we consider cooperative
localization as a distributed estimation problem and develop two fully
distributed localization algorithms that allow agents to track their own and
other agents' positions (and velocities) within the MAS. Finally, we conduct
simulations to demonstrate the effectiveness of our proposed theoretical
results.

</details>


### [87] [On the Dynamics of Acceleration in First order Gradient Methods](https://arxiv.org/abs/2509.18346)
*M Parimi,Rachit Mehra,S. R. Wagh,Amol Yerudkar,Navdeep Singh*

Main category: eess.SY

TL;DR: 本文从动力系统视角重新审视Nesterov加速算法，使用控制理论和几何奇异摄动理论来解释加速现象的本质，揭示了算法中各项的物理意义，并解释了Heavy-Ball方法不收敛的原因。


<details>
  <summary>Details</summary>
Motivation: 传统上通过ODE反向推导算法的方法掩盖了高阶原理，无法真正解释Nesterov算法的加速机制。本文旨在从动力系统角度重新构建理论框架，揭示算法背后的数学严谨性。

Method: 采用新近发展的控制范式（无源性和浸入方法）以及几何奇异摄动理论，构建能够解释加速现象的动力系统模型，而不是从离散算法反向推导ODE。

Result: 该框架成功解释了Nesterov加速算法中各项的物理意义和步骤序列，可扩展到三动量方法，并为Heavy-Ball方法不收敛提供了理论依据。

Conclusion: 从动力系统视角出发的新方法为理解优化算法的加速现象提供了更深刻的数学洞察，揭示了传统ODE方法所掩盖的高阶原理。

Abstract: Ever since the original algorithm by Nesterov (1983), the true nature of the
acceleration phenomenon has remained elusive, with various interpretations of
why the method is actually faster. The diagnosis of the algorithm through the
lens of Ordinary Differential Equations (ODEs) and the corresponding dynamical
system formulation to explain the underlying dynamics has a rich history. In
the literature, the ODEs that explain algorithms are typically derived by
considering the limiting case of the algorithm maps themselves, that is, an ODE
formulation follows the development of an algorithm. This obfuscates the
underlying higher order principles and thus provides little evidence of the
working of the algorithm. Such has been the case with Nesterov algorithm and
the various analogies used to describe the acceleration phenomena, viz,
momentum associated with the rolling of a Heavy-Ball down a slope, Hessian
damping etc. The main focus of our work is to ideate the genesis of the
Nesterov algorithm from the viewpoint of dynamical systems leading to
demystifying the mathematical rigour behind the algorithm. Instead of reverse
engineering ODEs from discrete algorithms, this work explores tools from the
recently developed control paradigm titled Passivity and Immersion approach and
the Geometric Singular Perturbation theory which are applied to arrive at the
formulation of a dynamical system that explains and models the acceleration
phenomena. This perspective helps to gain insights into the various terms
present and the sequence of steps used in Nesterovs accelerated algorithm for
the smooth strongly convex and the convex case. The framework can also be
extended to derive the acceleration achieved using the triple momentum method
and provides justifications for the non-convergence to the optimal solution in
the Heavy-Ball method.

</details>


### [88] [Optimal Service Mode Assignment in a Simple Computation Offloading System: Extended Version](https://arxiv.org/abs/2509.18356)
*Darin Jeff,Eytan Modiano*

Main category: eess.SY

TL;DR: 本文研究计算卸载策略，提出在云服务器空闲时直接分配任务到云端，繁忙时采用阈值策略将任务分配到本地服务器。


<details>
  <summary>Details</summary>
Motivation: 设计基于系统状态的任务分配策略，以最小化系统延迟，解决计算卸载中的任务调度问题。

Method: 建立简单的计算卸载模型，分析云服务器空闲和繁忙两种状态下的最优策略，通过阈值策略进行任务分配。

Result: 云服务器空闲时最优策略是直接分配任务到云端；繁忙时最优策略是当系统队列超过阈值时将任务分配到本地服务器。

Conclusion: 提出的阈值策略能有效优化系统延迟，仿真验证了该策略结构的有效性。

Abstract: We consider a simple computation offloading model where jobs can either be
fully processed in the cloud or be partially processed at a local server before
being sent to the cloud to complete processing. Our goal is to design a policy
for assigning jobs to service modes, i.e., full offloading or partial
offloading, based on the state of the system, in order to minimize delay in the
system. We show that when the cloud server is idle, the optimal policy is to
assign the next job in the system queue to the cloud for processing. However,
when the cloud server is busy, we show that, under mild assumptions, the
optimal policy is of a threshold type, that sends the next job in the system
queue to the local server if the queue exceeds a certain threshold. Finally, we
demonstrate this policy structure through simulations.

</details>


### [89] [Policy Gradient with Self-Attention for Model-Free Distributed Nonlinear Multi-Agent Games](https://arxiv.org/abs/2509.18371)
*Eduardo Sebastián,Maitrayee Keskar,Eeman Iqbal,Eduardo Montijano,Carlos Sagüés,Nikolay Atanasov*

Main category: eess.SY

TL;DR: 本文提出了一种基于策略梯度的分布式学习方法，用于解决动态非线性多智能体游戏中的非平稳纳什均衡问题，该方法利用自注意力层建模非线性反馈增益，并在多种场景下验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 动态非线性多智能体游戏中的挑战在于智能体间时变交互和纳什均衡的非平稳性，特别是在模型未知的情况下，需要开发能够适应通信结构的分布式策略学习方法。

Method: 采用策略梯度方法学习分布式策略，利用自注意力层参数化非线性反馈增益，以处理时变多智能体通信拓扑结构，该方法受到线性二次游戏中分布式策略结构的启发。

Result: 该方法在分布式线性和非线性调节、模拟和真实多机器人追逃游戏等多种设置中表现出色，验证了其有效性。

Conclusion: 所提出的分布式策略梯度方法能够有效处理多团队游戏中的复杂交互和非平稳性，为动态非线性多智能体系统提供了实用的学习框架。

Abstract: Multi-agent games in dynamic nonlinear settings are challenging due to the
time-varying interactions among the agents and the non-stationarity of the
(potential) Nash equilibria. In this paper we consider model-free games, where
agent transitions and costs are observed without knowledge of the transition
and cost functions that generate them. We propose a policy gradient approach to
learn distributed policies that follow the communication structure in
multi-team games, with multiple agents per team. Our formulation is inspired by
the structure of distributed policies in linear quadratic games, which take the
form of time-varying linear feedback gains. In the nonlinear case, we model the
policies as nonlinear feedback gains, parameterized by self-attention layers to
account for the time-varying multi-agent communication topology. We demonstrate
that our distributed policy gradient approach achieves strong performance in
several settings, including distributed linear and nonlinear regulation, and
simulated and real multi-robot pursuit-and-evasion games.

</details>


### [90] [Compositional System Dynamics: The Higher Mathematics Underlying System Dynamics Diagrams & Practice](https://arxiv.org/abs/2509.18475)
*Xiaoyan Li,Evan Patterson,Patricia L. Mabry,Nathaniel D. Osgood*

Main category: eess.SY

TL;DR: 该研究建立了系统动力学组合建模的数学基础，利用范畴论形式化系统模型的表示、分析和组合，支持模块化建模和语义映射。


<details>
  <summary>Details</summary>
Motivation: 为系统动力学建模提供坚实的数学基础，解决传统方法在可扩展性、透明度和系统化推理方面的不足。

Method: 将系统动力学图表示为范畴构造，使用属性C-集编码数据，应用结构化余跨度、推出、拉回等范畴工具。

Result: 框架支持模块化组合、分层、语法语义映射，能够识别反馈环路、检测模式、发现图间共同结构。

Conclusion: 该框架为复杂系统建模提供了清晰、可扩展和严谨的方法，未来可扩展到时序推理和混合建模范式。

Abstract: This work establishes a robust mathematical foundation for compositional
System Dynamics modeling, leveraging category theory to formalize and enhance
the representation, analysis, and composition of system models. Here, System
Dynamics diagrams, such as stock & flow diagrams, system structure diagrams,
and causal loop diagrams, are formulated as categorical constructs, enabling
scalable, transparent, and systematic reasoning. By encoding these diagrams as
data using attributed C-sets and utilizing advanced categorical tools like
structured cospans, pushouts, pullbacks, and functor mappings, the framework
supports modular composition, stratification, and seamless mapping between
syntax and semantics.
  The approach underwrites traditional practice with firm mathematical
structure, facilitates the identification of certain forms of pathways and
feedback loops, the detection of simple patterns within complex diagrams,
common structure between diagrams, and structure-preserving mappings between
diverse diagram types. Additionally, this framework supports alternative
semantics, such as stochastic transition dynamics, extending beyond traditional
ordinary differential equation (ODE) representations. Applications in
compositional modeling, modularity, and team-based collaboration demonstrate
the practical advantages of this advanced framework.
  Future directions include integrating dimensional annotations, supporting
hybrid and agent-based modeling paradigms, and expanding the framework's
applicability to global and local temporal reasoning through temporal sheaves.
By revealing and formalizing the hidden mathematical structure of System
Dynamics diagrams, this work empowers practitioners to tackle complex systems
with clarity, scalability, and rigor.

</details>


### [91] [Refined Barrier Conditions for Finite-Time Safety and Reach-Avoid Guarantees in Stochastic Systems](https://arxiv.org/abs/2509.18518)
*Bai Xue,Luke Ong,Dominik Wagner,Peixin Wang*

Main category: eess.SY

TL;DR: 本文提出了改进的屏障证书条件，消除了对辅助函数有界性的限制，为离散时间系统提供有限时间安全概率上界，为连续时间系统提供有限时间可达-规避概率下界。


<details>
  <summary>Details</summary>
Motivation: 现有屏障证书方法依赖于辅助函数的有界性假设，这限制了其在安全关键随机系统中的应用范围。本文旨在消除这一限制，扩展可验证系统的类别。

Method: 建立改进的屏障类条件，通过松弛有界性要求，使方法适用于无界状态空间系统，并支持半定规划等优化技术的应用。

Result: 该方法显著扩展了可验证系统的范围，特别是在无界状态空间系统上表现良好，并通过数值示例验证了有效性。

Conclusion: 提出的改进屏障条件成功消除了传统方法的有界性限制，为更广泛的安全关键随机系统提供了有效的有限时间概率安全保证。

Abstract: Providing finite-time probabilistic safety and reach-avoid guarantees is
crucial for safety-critical stochastic systems. Existing barrier certificate
methods often rely on a restrictive boundedness assumption for auxiliary
functions, limiting their applicability. This paper presents refined
barrier-like conditions that remove this assumption. Specifically, we establish
conditions for deriving upper bounds on finite-time safety probabilities in
discrete-time systems and lower bounds on finite-time reach-avoid probabilities
in continuous-time systems. This key relaxation significantly expands the class
of verifiable systems, especially those with unbounded state spaces, and
facilitates the application of advanced optimization techniques, such as
semi-definite programming with polynomial functions. The efficacy of our
approach is validated through numerical examples.

</details>


### [92] [AI Agent Access (A\^3) Network: An Embodied, Communication-Aware Multi-Agent Framework for 6G Coverage](https://arxiv.org/abs/2509.18526)
*Han Zeng,Haibo Wang,Luhao Fan,Bingcheng Zhu,Xiaohu You,Zaichen Zhang*

Main category: eess.SY

TL;DR: 提出A^3网络框架，将多智能体网络转变为动态、去中心化的端到端系统，集成探索、用户接入和回程维护于单一学习过程，支持运行时按需添加智能体。


<details>
  <summary>Details</summary>
Motivation: 6G通信需要在没有固定基础设施的环境下实现自主和弹性网络，但现有MARL方法局限于静态部署和集中控制下的孤立阶段，缺乏适应性。

Method: 采用去中心化策略和actor-critic学习，将链路级通信指标嵌入学习过程，实现拓扑形成与鲁棒决策的耦合。

Result: 数值模拟显示A^3网络不仅平衡了探索和通信效率，还提供了现有MARL框架缺乏的系统级适应性。

Conclusion: A^3网络为6G多智能体网络提供了新范式，通过统一框架实现动态、去中心化的端到端系统。

Abstract: The vision of 6G communication demands autonomous and resilient networking in
environments without fixed infrastructure. Yet most multi-agent reinforcement
learning (MARL) approaches focus on isolated stages - exploration, relay
formation, or access - under static deployments and centralized control,
limiting adaptability. We propose the AI Agent Access (A\^3) Network, a
unified, embodied intelligence-driven framework that transforms multi-agent
networking into a dynamic, decentralized, and end-to-end system. Unlike prior
schemes, the A\^3 Network integrates exploration, target user access, and
backhaul maintenance within a single learning process, while supporting
on-demand agent addition during runtime. Its decentralized policies ensure that
even a single agent can operate independently with limited observations, while
coordinated agents achieve scalable, communication-optimized coverage. By
embedding link-level communication metrics into actor-critic learning, the A\^3
Network couples topology formation with robust decision-making. Numerical
simulations demonstrate that the A\^3 Network not only balances exploration and
communication efficiency but also delivers system-level adaptability absent in
existing MARL frameworks, offering a new paradigm for 6G multi-agent networks.

</details>


### [93] [Interaction-aware Lane-Changing Early Warning System in Congested Traffic](https://arxiv.org/abs/2509.18624)
*Yue Zhang,Xinzhi Zhong,Soyoung Ahn,Yajie Zou,Zhengbing He*

Main category: eess.SY

TL;DR: 本文提出了一种基于交互感知的车道变换早期预警系统，通过多车辆轨迹预测来识别直接和间接风险，提高交通安全和效率。


<details>
  <summary>Details</summary>
Motivation: 解决拥堵交通中车道变换带来的安全风险，通过早期预警帮助驾驶员做出更明智的决策，提升驾驶辅助系统的主动性。

Method: 使用基于互信息的社会时空图卷积神经网络框架预测多车辆轨迹，通过定向边界框检测识别潜在碰撞风险，生成预警信号。

Result: 在SUMO交通模拟实验中，该系统提高了车辆级安全性和整体交通效率，促进了更自然的行为适应。

Conclusion: 交互感知的车道变换早期预警系统能够有效提升交通安全和效率，为智能驾驶辅助系统提供了可靠的技术支持。

Abstract: Lane changes (LCs) in congested traffic are complex, multi-vehicle
interactive events that pose significant safety concerns. Providing early
warnings can enable more proactive driver assistance system and support more
informed decision-making for drivers under LCs. This paper presents an
interaction-aware Lane-Changing Early Warning (LCEW) system designed to issue
reliable early warning signals based on future trajectory predictions. We first
investigate the stochastic nature of LCs, characterized by (i) variable-size
multi-vehicle interactions and (ii) the direct and indirect risks resulting
from these interactions. To model these stochastic interactions, a Social
Spatio-Temporal Graph Convolutional Neural Network framework informed by mutual
information (STGCNN-MI) is introduced to predict multi-vehicle trajectories. By
leveraging a MI-based adjacency matrix, the framework enhances trajectory
prediction accuracy while providing interpretable representations of vehicle
interactions. Then, potential collisions between the LC vehicle and adjacent
vehicles (direct risks) or among the non-adjacent vehicles (indirect risks) are
identified using oriented bounding box detection applied to the predicted
trajectories. Finally, a warning signal is generated to inform the LC driver of
location of potential collisions within the predicted time window. Traffic
simulation experiments conducted in SUMO demonstrate that the proposed
interaction-aware LCEW improves both vehicle-level safety and overall traffic
efficiency, while also promoting more natural behavioral adaptation.

</details>


### [94] [Dual Iterative Learning Control for Multiple-Input Multiple-Output Dynamics with Validation in Robotic Systems](https://arxiv.org/abs/2509.18723)
*Jan-Hendrik Ewering,Alessandro Papa,Simon F. G. Ehlers,Thomas Seel,Michael Meindl*

Main category: eess.SY

TL;DR: 提出MIMO双迭代学习控制(DILC)方法，实现无需先验系统知识和手动参数调优的同时跟踪控制与模型学习


<details>
  <summary>Details</summary>
Motivation: 解决复杂多输入多输出系统中未知动态和手动参数调优的挑战，实现真正自主的运动任务控制

Method: 设计数据驱动的迭代学习方案，集成现有迭代学习控制方法，为线性时不变系统提供单调收敛条件

Result: 在高保真工业机器人仿真和多个非线性真实MIMO系统中快速自主解决各种运动任务，多数任务在10-20次试验内完成，复杂运动在100次迭代内学习

Conclusion: DILC因其快速自主学习能力，有潜力作为复杂学习框架的高效构建模块，用于智能真实世界系统

Abstract: Solving motion tasks autonomously and accurately is a core ability for
intelligent real-world systems. To achieve genuine autonomy across multiple
systems and tasks, key challenges include coping with unknown dynamics and
overcoming the need for manual parameter tuning, which is especially crucial in
complex Multiple-Input Multiple-Output (MIMO) systems.
  This paper presents MIMO Dual Iterative Learning Control (DILC), a novel
data-driven iterative learning scheme for simultaneous tracking control and
model learning, without requiring any prior system knowledge or manual
parameter tuning. The method is designed for repetitive MIMO systems and
integrates seamlessly with established iterative learning control methods. We
provide monotonic convergence conditions for both reference tracking error and
model error in linear time-invariant systems.
  The DILC scheme -- rapidly and autonomously -- solves various motion tasks in
high-fidelity simulations of an industrial robot and in multiple nonlinear
real-world MIMO systems, without requiring model knowledge or manually tuning
the algorithm. In our experiments, many reference tracking tasks are solved
within 10-20 trials, and even complex motions are learned in less than 100
iterations. We believe that, because of its rapid and autonomous learning
capabilities, DILC has the potential to serve as an efficient building block
within complex learning frameworks for intelligent real-world systems.

</details>


### [95] [An Extended Kalman Filter for Systems with Infinite-Dimensional Measurements](https://arxiv.org/abs/2509.18749)
*Maxwell M. Varley,Timothy L. Molloy,Girish N. Nair*

Main category: eess.SY

TL;DR: 本文研究离散时间非线性随机系统的状态估计问题，针对有限维状态和无限维测量的情况，开发了扩展卡尔曼滤波器（EKF），在视觉定位应用中证明了图像梯度作为测量雅可比矩阵的理论合理性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于现实应用中的视觉定位和跟踪问题，特别是处理有限维状态和无限维测量的非线性随机系统状态估计需求。

Method: 开发了扩展卡尔曼滤波器（EKF），将测量噪声建模为无限维随机场，在视觉状态估计中证明了测量雅可比矩阵对应于图像梯度。

Result: 在无人机视觉定位实验中，EKF方法相比VINS-MONO算法在某些情况下实现了均方误差降低一个数量级的性能提升。

Conclusion: 本文为图像梯度在视觉状态估计中的使用提供了系统理论依据，证明了EKF在无限维测量场景下的有效性。

Abstract: This article examines state estimation in discrete-time nonlinear stochastic
systems with finite-dimensional states and infinite-dimensional measurements,
motivated by real-world applications such as vision-based localization and
tracking. We develop an extended Kalman filter (EKF) for real-time state
estimation, with the measurement noise modeled as an infinite-dimensional
random field. When applied to vision-based state estimation, the measurement
Jacobians required to implement the EKF are shown to correspond to image
gradients. This result provides a novel system-theoretic justification for the
use of image gradients as features for vision-based state estimation,
contrasting with their (often heuristic) introduction in many computer-vision
pipelines. We demonstrate the practical utility of the EKF on a public
real-world dataset involving the localization of an aerial drone using video
from a downward-facing monocular camera. The EKF is shown to outperform
VINS-MONO, an established visual-inertial odometry algorithm, in some cases
achieving mean squared error reductions of up to an order of magnitude.

</details>


### [96] [Integration of Concentrated Solar Power Plants in Renewable-Only VPP with Electrical and Thermal Demands: A Two-Stage Robust Bidding Approach](https://arxiv.org/abs/2509.18769)
*Hadi Nemati,Pedro Sánchez-Martín,Álvaro Ortega,Lukas Sigrist,Luis Rouco*

Main category: eess.SY

TL;DR: 该论文提出将聚光太阳能发电厂（CSP）整合到纯可再生能源虚拟电厂（RVPP）中，用于电力日前市场和二次备用市场的投标，以及通过热力购买协议进行热能交易。采用改进的两阶段鲁棒优化方法来处理多种不确定性。


<details>
  <summary>Details</summary>
Motivation: 提高RVPP在电力和热能交易中的灵活性，增加RVPP的盈利能力，通过整合CSP来应对电力价格、可再生能源发电、CSP热能生产以及电力和热需求消费等多种不确定性。

Method: 引入改进的两阶段鲁棒优化方法，采用可调整的方法对CSP热储能的能量和备用提供进行建模，根据RVPP的盈利能力分配上下备用能量的份额。

Result: 仿真结果表明，将CSP整合到RVPP中增强了RVPP在电力和热能交易方面的灵活性。当考虑所有交易选项时，无论RVPP运营商对不确定参数采取何种保守程度，RVPP的盈利能力都会增加。

Conclusion: CSP与RVPP的整合是有效的，提出的方法在不同交易策略和不确定参数下都表现出良好的计算效率和性能，能够显著提升RVPP的经济效益和运行灵活性。

Abstract: This paper proposes the integration of Concentrated Solar Power Plant (CSP)
in the Renewable-only virtual power plant (RVPP) for bidding in the electricity
day-ahead and secondary reserve markets, as well as trading thermal energy
through a heat purchase agreement. A reformulated two-stage robust optimization
approach is introduced to account for multiple uncertainties, including
electricity prices, non-dispatchable renewable energy sources electrical
production, CSP thermal production, and uncertainties in electrical and thermal
demand consumption. The provision of energy and reserve by the thermal storage
of CSP is modeled using an adjustable approach, which allocates a share of
energy for up and down reserves based on the profitability of the RVPP.
Simulations are conducted for several case studies to demonstrate the
effectiveness and computational efficiency of the proposed approach under
different RVPP operator decisions against uncertain parameters and various
trading strategies for electricity and thermal energy. The simulation results
show that integrating CSP into RVPP enhances RVPP flexibility for both
electrical and thermal trading. Furthermore, the results indicate that the
profitability of the RVPP increases when all trading options are considered,
across different levels of conservatism adopted by the RVPP operator in
response to uncertain parameters.

</details>


### [97] [Frequency-Varying Optimization: A Control Framework for New Dynamic Frequency Response Services](https://arxiv.org/abs/2509.18935)
*Yiqiao Xu,Quan Wan,Alessandra Parisio*

Main category: eess.SY

TL;DR: 该论文提出了一种用于聚合响应单元（ARU）的频率变化优化（FVO）框架，通过将FVO问题转化为最优轨迹跟踪（TOT）问题，实现在线优化和分布式协调。


<details>
  <summary>Details</summary>
Motivation: 为了解决可再生能源发电的波动性，需要提供更快更有效的频率响应服务。英国国家能源系统运营商（NESO）引入了新的动态服务，其中资产聚合起着关键作用。

Method: 将频率变化优化（FVO）问题重新表述为最优轨迹跟踪（TOT）问题，提出了两种场景的算法：资产动态可忽略和必须考虑资产动态的情况。

Result: 在合理条件下，ARU能在固定时间内收敛到最优轨迹，并在NESO要求的最长交付时间内完成响应。数值结果验证了控制框架的有效性和可扩展性。

Conclusion: 所提出的框架可以轻松分布式协调大量资产，为可再生能源集成提供有效的频率响应解决方案。

Abstract: To address the variability of renewable generation, initiatives have been
launched globally to provide faster and more effective frequency responses. In
the UK, the National Energy System Operator (NESO) has introduced a suite of
three new dynamic services, where aggregation of assets is expected to play a
key role. For an Aggregated Response Unit (ARU), the required level of
frequency response varies with grid frequency, resulting in a frequency-varying
equality constraint that assets should meet collectively. We show that the
optimal coordination of an ARU constitutes a Frequency-Varying Optimization
(FVO) problem, in which the optimal trajectory for each asset evolves
dynamically. To facilitate online optimization, we reformulate the FVO problem
into Tracking of the Optimal Trajectory (TOT) problems, with algorithms
proposed for two scenarios: one where the asset dynamics are negligible, and
another where they must be accounted for. Under reasonable conditions, the ARU
converges to the optimal trajectory within a fixed time, and within the maximum
delivery time requested by NESO. The proposed framework can be readily
distributed to coordinate a large number of assets. Numerical results verify
the effectiveness and scalability of the proposed control framework.

</details>


### [98] [Adaptive Override Control under High-Relative-Degree Nonovershooting Constraints](https://arxiv.org/abs/2509.18988)
*Ziliang Lyu,Miroslav Krstic,Kaixin Lu,Yiguang Hong,Lihua Xie*

Main category: eess.SY

TL;DR: 本文提出了一种自适应覆盖不安全动作的方法，通过模块化设计处理高相对度非超调约束和参数不确定性，确保闭环安全违规有界且参数估计收敛到真实值。


<details>
  <summary>Details</summary>
Motivation: 解决在存在高相对度非超调约束和参数不确定性的情况下，自适应覆盖名义控制器不安全动作的问题，避免设计过程中与参数估计误差的高阶导数耦合。

Method: 采用模块化设计方法，将控制器和参数标识器分开设计。控制器模块确保由参数不确定性引起的安全违规有界，参数标识器模块保证参数估计误差及其一阶导数有界或平方可积。

Result: 理论分析和仿真结果表明，闭环安全违规受初始估计误差的可调函数限制，随着时间推移，参数估计收敛到真实值，安全违规相应减少。

Conclusion: 所提出的模块化设计方法有效解决了高相对度约束下的自适应安全控制问题，实现了有界的安全违规和参数估计的渐近收敛。

Abstract: This paper considers the problem of adaptively overriding unsafe actions of a
nominal controller in the presence of high-relative-degree nonovershooting
constraints and parametric uncertainties. To prevent the design from being
coupled with high-order derivatives of the parameter estimation error, we adopt
a modular design approach in which the controller and the parameter identifier
are designed separately. The controller module ensures that any safety
violations caused by parametric uncertainties remain bounded, provided that the
parameter estimation error and its first-order derivative are either bounded or
square-integrable. The identifier module, in turn, guarantees that these
requirements on the parameter estimation error are satisfied. Both theoretical
analysis and simulation results demonstrate that the closed-loop safety
violation is bounded by a tunable function of the initial estimation error.
Moreover, as time increases, the parameter estimate converges to the true
value, and the amount of safety violation decreases accordingly.

</details>


### [99] [A Weighted Least Squares Error Hetero-functional Graph State Estimator of the American Multi-modal Energy System](https://arxiv.org/abs/2509.19045)
*Dakota Thompson,Amro M. Farid*

Main category: eess.SY

TL;DR: 本文提出了一个加权最小二乘误差异质图状态估计（WLSEHFGSE）方法，用于分析美国多模态能源系统（AMES）中质量和能量的最优流动，首次将状态估计方法与异质图理论（HFGT）相结合。


<details>
  <summary>Details</summary>
Motivation: 应对21世纪全球气候变化挑战，需要理解美国多模态能源系统（电网、天然气系统、石油系统、煤炭系统）之间的相互依赖关系，以制定有效政策。

Method: 采用数据驱动和基于模型的系统工程方法，结合异质图理论（HFGT），开发了WLSEHFGSE优化程序来估计AMES中的质量和能量流动。

Result: 该方法能够在系统级系统中以资产级粒度恢复质量和能量流动，首次将状态估计扩展到异构的AMES环境中。

Conclusion: 这项工作为分析复杂能源系统的行为提供了新方法，展示了HFGT与状态估计方法结合在系统级系统分析中的有效性。

Abstract: As one of the most pressing challenges of the 21st century, global climate
change demands a host of changes across at least four critical energy
infrastructures: the electric grid, the natural gas system, the oil system, and
the coal system. In the context of the United States, this paper refers to this
system-of-systems as ``The American Multi-Modal Energy System (AMES)". These
combined changes necessitate an understanding of the AMES interdependencies,
both structurally and behaviorally, to develop and enact effective policies.
This work focuses on behavioral analysis methods to provide examples of how to
analyze system behavior and the critical matter and energy flows through the
system. Building upon past works, two regions of the AMES are modeled, and
their behavior is analyzed using Hetero-functional Graph Theory (HFGT). More
specifically, the work presents a weighted least square error state estimation
model of the AMES. State estimation has played a major role in the operation
and development of the American Electric Power System. This work extends the
state estimation analysis beyond the single-operand electric grid environment
into the heterogeneous environment of the AMES. Employing a data-driven and
model-based systems engineering approach in combination with HFGT, a Weighted
Least Squares Error Hetero-functional Graph State Estimation (WLSEHFGSE)
optimization program is developed to estimate the optimal flows of mass and
energy through the AMES. This work is the first to integrate state estimation
methods with HFGT. Furthermore, it demonstrates how such a WLSEHFGSE recovers
the mass and energy flows in a system-of-systems like the AMES with asset-level
granularity.

</details>


### [100] [MAPPO for Edge Server Monitoring](https://arxiv.org/abs/2509.19079)
*Samuel Chamoun,Christian McDowell,Robin Buchanan,Kevin Chan,Eric Graves,Yin Sun*

Main category: eess.SY

TL;DR: 该论文提出了一种基于多智能体近端策略优化（MAPPO）的算法，用于解决边缘服务器监控中的目标导向通信问题，通过联合优化查询调度来平衡吞吐量和通信开销。


<details>
  <summary>Details</summary>
Motivation: 边缘服务器监控中，作业间歇性到达多个调度器并需要分配到具有有限队列和时变可用性的共享边缘服务器。在动态工作负载和部分可观测性下，准确了解服务器状态对于维持高吞吐量至关重要但具有挑战性。

Method: 每个调度器通过两种互补机制维护服务器知识：主动状态查询和作业执行反馈。提出基于MAPPO的算法，利用集中训练分散执行（CTDE）来学习在部分和过时观测下的分布式查询和调度策略。

Result: 数值评估显示，MAPPO实现了优越的吞吐量-成本权衡，显著优于基线策略，平均比最接近的基线提高了30%的性能。

Conclusion: 所提出的MAPPO算法能够有效解决边缘服务器监控中的分布式决策问题，在部分可观测环境下实现了通信开销和系统吞吐量的良好平衡。

Abstract: In this paper, we consider a goal-oriented communication problem for edge
server monitoring, where jobs arrive intermittently at multiple dispatchers and
must be assigned to shared edge servers with finite queues and time-varying
availability. Accurate knowledge of server status is critical for sustaining
high throughput, yet remains challenging under dynamic workloads and partial
observability. To address this challenge, each dispatcher maintains server
knowledge through two complementary mechanisms: (i) active status queries that
provide instantaneous updates at a communication cost, and (ii) job execution
feedback that reveals server conditions opportunistically. We formulate a
cooperative multi-agent distributed decision-making problem in which
dispatchers jointly optimize query scheduling to balance throughput against
communication overhead. To solve this problem, we propose a Multi-Agent
Proximal Policy Optimization (MAPPO)-based algorithm that leverages centralized
training with decentralized execution (CTDE) to learn distributed
query-and-dispatch policies under partial and stale observations. Numerical
evaluations show that MAPPO achieves superior throughput-cost tradeoffs and
significantly outperforms baseline strategies, achieving on average a 30%
improvement over the closest baseline.

</details>


### [101] [AI-Enabled Smart Hygiene System for Real-Time Glucose Detection](https://arxiv.org/abs/2509.19107)
*Khan Masood Parvez,Sk Md Abidar Rahaman,Ali Shiri Sichani,Hadi AliAkbarpour*

Main category: eess.SY

TL;DR: 本研究提出了一种智能尿液健康监测系统，采用共面波导馈电槽环天线生物传感器分析尿液样本，通过频率偏移检测尿液健康状况，并讨论AI框架提高检测精度，最终实现无需用户操作的智能马桶系统。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需用户行为改变的智能尿液监测系统，通过非侵入式方法实时检测尿液生物标志物，为日常健康监测提供便利解决方案。

Method: 使用共面波导馈电槽环天线作为微波传感器，检测五种尿液条件下的谐振频率偏移；提出基于CNN-LSTM的AI框架处理重叠频率响应问题。

Result: 天线在1.42GHz基准频率下对五种尿液条件表现出可测量的频率偏移，证明其作为尿液生物标志物检测微波传感器的有效性。

Conclusion: 该系统成功展示了智能马桶实时健康监测的可行性，为无创尿液分析提供了新的技术途径，具有临床应用潜力。

Abstract: This research presents a smart urinary health monitoring system incorporating
a coplanar waveguide (CPW)-fed slot-loop antenna biosensor designed to analyse
various urine samples. The antenna demonstrates distinct resonant frequency
shifts when exposed to five specific urine conditions, deviating from its
baseline 1.42 GHz operation. These measurable frequency variations enable the
antenna to function as an effective microwave sensor for urinary biomarker
detection. A potential artificial intelligence-based Convolutional Neural
Networks Long Short-Term Memory (CNN-LSTM) framework is also discussed to
overcome the limitations of overlapping frequency responses, aiming to improve
the accuracy of health condition detection. These components contribute to the
development of a smart toilet system that displays real-time health information
on a wall-mounted urinal screen, without requiring any user effort or
behavioural change.

</details>


### [102] [A Fast Initialization Method for Neural Network Controllers: A Case Study of Image-based Visual Servoing Control for the multicopter Interception](https://arxiv.org/abs/2509.19110)
*Chenxu Ke,Congling Tian,Kaichen Xu,Ye Li,Lingcong Bao*

Main category: eess.SY

TL;DR: 本文提出了一种神经网络快速初始化方法，通过构建符合稳定性条件的数据集来实现神经网络控制策略的初始训练，解决了强化学习控制器训练初期需要大量数据、收敛慢的问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习控制器设计需要大量初始训练数据且收敛缓慢，而基于Lyapunov稳定性的方法需要初始稳定的神经网络控制策略。传统控制理论设计稳定控制器需要专业知识，因此需要一种快速初始化方法。

Method: 基于系统模型构建符合稳定性条件的数据集，实现神经网络控制策略的初始训练。以多旋翼飞行器拦截的图像视觉伺服控制为案例进行研究。

Result: 实验验证了方法的有效性，训练的控制策略达到了15 m/s的最终拦截速度。

Conclusion: 该方法能够快速获得稳定的初始神经网络控制器，为后续强化学习训练提供良好起点，提高了训练效率和性能。

Abstract: Reinforcement learning-based controller design methods often require
substantial data in the initial training phase. Moreover, the training process
tends to exhibit strong randomness and slow convergence. It often requires
considerable time or high computational resources. Another class of
learning-based method incorporates Lyapunov stability theory to obtain a
control policy with stability guarantees. However, these methods generally
require an initially stable neural network control policy at the beginning of
training. Evidently, a stable neural network controller can not only serve as
an initial policy for reinforcement learning, allowing the training to focus on
improving controller performance, but also act as an initial state for
learning-based Lyapunov control methods. Although stable controllers can be
designed using traditional control theory, designers still need to have a great
deal of control design knowledge to address increasingly complicated control
problems. The proposed neural network rapid initialization method in this paper
achieves the initial training of the neural network control policy by
constructing datasets that conform to the stability conditions based on the
system model. Furthermore, using the image-based visual servoing control for
multicopter interception as a case study, simulations and experiments were
conducted to validate the effectiveness and practical performance of the
proposed method. In the experiment, the trained control policy attains a final
interception velocity of 15 m/s.

</details>


### [103] [Robust Synchronous Reference Frame Phase-Looked Loop (PLL) with Feed-Forward Frequency Estimation](https://arxiv.org/abs/2509.19111)
*Michael Ruderman,Elia Brescia,Paolo Roberto Massenio,Giuseppe Leonardo Cascella,David Naso*

Main category: eess.SY

TL;DR: 本文提出了一种改进的同步参考坐标系锁相环（SRF-PLL）方案，通过结合鲁棒前馈频率估计器和反馈控制，提高了对噪声和时变谐波信号的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统的SRF-PLL在频率斜坡跟踪和瞬态响应方面存在不足，且对输入幅值变化敏感。需要一种更鲁棒的设计来改善这些性能问题。

Method: 采用比例积分（PI）控制反馈，结合模型无关的鲁棒前馈频率估计器，并使用归一化方案使环路对输入幅值变化不敏感。

Result: 实验评估表明，该方案在PMSM驱动器的三相谐波电流跟踪中，显著改善了瞬态行为和频率斜坡跟踪性能。

Conclusion: 提出的前馈-反馈SRF-PLL方案有效提升了同步性能，适用于噪声大且时变的谐波信号环境。

Abstract: Synchronous reference frame phase-looked loop (SRF-PLL) techniques are widely
used for interfacing and control applications in the power systems and energy
conversion at large. Since a PLL system synchronizes its output with an
exogenous harmonic signal, often 3-phases voltage or current, the locking of
the frequency and phase angle depends on the performance of the feedback loop
with at least two integrator terms, and on the distortions of the measured
input quantities. For the conventional SRF-PLL with a proportional-integral
(PI) control in feedback, we are providing a robust design which maximizes the
phase margin and uses the normalization scheme for yielding the loop
insensitive to the input amplitude variations. The main improvement in the
transient behavior and also in tracking of frequency ramps is achieved by using
the robust feed-forward frequency estimator, which is model-free and suitable
for the noisy and time-varying harmonic signals. The proposed
feed-forward-feedback SRF-PLL scheme is experimentally evaluated on the
3-phases harmonic currents from standard PMSM drives with varying angular
speeds and loads. Both, the tracked angular frequency and locked phase angle
are assessed as performance metrics of the robust SRF-PLL scheme with
feedforwarding.

</details>


### [104] [Policy Gradient Bounds in Multitask LQR](https://arxiv.org/abs/2509.19266)
*Charis Stamouli,Leonardo F. Toso,Anastasios Tsiamis,George J. Pappas,James Anderson*

Main category: eess.SY

TL;DR: 本文分析了多任务线性二次调节（LQR）中策略梯度的性能，提出了基于互模拟的任务异质性度量方法，以捕捉闭环任务相似性，并推导了多任务最优控制器和渐进策略梯度控制器的次优性界。


<details>
  <summary>Details</summary>
Motivation: 多任务LQR的主要目标是找到一个在所有任务上都具有满意性能的控制器。先前分析未能捕捉闭环任务相似性，导致性能保证过于保守。

Method: 提出基于互模拟的任务异质性度量方法，使用新的互模拟函数来约束在共同稳定控制器下闭环运行的一对任务的成本梯度距离。

Result: 对于多个随机任务集，观察到基于互模拟的度量方法相比基线任务异质性度量有显著改进。

Conclusion: 该方法能够更好地捕捉任务间的相似性，为多任务LQR控制提供了更准确的性能保证。

Abstract: We analyze the performance of policy gradient in multitask linear quadratic
regulation (LQR), where the system and cost parameters differ across tasks. The
main goal of multitask LQR is to find a controller with satisfactory
performance on every task. Prior analyses on relevant contexts fail to capture
closed-loop task similarities, resulting in conservative performance
guarantees. To account for such similarities, we propose bisimulation-based
measures of task heterogeneity. Our measures employ new bisimulation functions
to bound the cost gradient distance between a pair of tasks in closed loop with
a common stabilizing controller. Employing these measures, we derive
suboptimality bounds for both the multitask optimal controller and the
asymptotic policy gradient controller with respect to each of the tasks. We
further provide conditions under which the policy gradient iterates remain
stabilizing for every system. For multiple random sets of certain tasks, we
observe that our bisimulation-based measures improve upon baseline measures of
task heterogeneity dramatically.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [105] [PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies](https://arxiv.org/abs/2509.18282)
*Jesse Zhang,Marius Memmel,Kevin Kim,Dieter Fox,Jesse Thomason,Fabio Ramos,Erdem Bıyık,Abhishek Gupta,Anqi Li*

Main category: cs.RO

TL;DR: PEEK通过微调视觉语言模型生成统一的点基中间表示，将高层推理与底层动作执行分离，显著提升机器人操作策略的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人操作策略泛化能力差，因为需要同时学习关注位置、动作类型和执行方式。PEEK旨在将高层推理任务卸载给视觉语言模型，让策略专注于动作执行。

Method: 1. 微调VLMs预测统一的点基中间表示：末端执行器路径和任务相关掩码；2. 开发自动标注流水线，在20+机器人数据集上生成标注数据；3. 将标注直接叠加到机器人观察上，实现策略无关的表示。

Result: 1. 仅在仿真训练的3D策略在真实世界中提升41.4倍；2. 大型VLA和小型操作策略分别获得2-3.5倍性能提升；3. 在9种不同机器人平台上验证了有效性。

Conclusion: 通过让VLMs处理语义和视觉复杂性，PEEK为操作策略提供了所需的最小提示（位置、内容和方式），显著提升了零样本泛化能力。

Abstract: Robotic manipulation policies often fail to generalize because they must
simultaneously learn where to attend, what actions to take, and how to execute
them. We argue that high-level reasoning about where and what can be offloaded
to vision-language models (VLMs), leaving policies to specialize in how to act.
We present PEEK (Policy-agnostic Extraction of Essential Keypoints), which
fine-tunes VLMs to predict a unified point-based intermediate representation:
1. end-effector paths specifying what actions to take, and 2. task-relevant
masks indicating where to focus. These annotations are directly overlaid onto
robot observations, making the representation policy-agnostic and transferable
across architectures. To enable scalable training, we introduce an automatic
annotation pipeline, generating labeled data across 20+ robot datasets spanning
9 embodiments. In real-world evaluations, PEEK consistently boosts zero-shot
generalization, including a 41.4x real-world improvement for a 3D policy
trained only in simulation, and 2-3.5x gains for both large VLAs and small
manipulation policies. By letting VLMs absorb semantic and visual complexity,
PEEK equips manipulation policies with the minimal cues they need--where, what,
and how. Website at https://peek-robot.github.io/.

</details>


### [106] [Fine-Tuning Robot Policies While Maintaining User Privacy](https://arxiv.org/abs/2509.18311)
*Benjamin A. Christie,Sagar Parekh,Dylan P. Losey*

Main category: cs.RO

TL;DR: PRoP是一个模型无关的框架，用于实现个性化且私密的机器人策略，通过为每个用户分配唯一密钥来保护用户偏好数据不被外部代理窃取。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略需要根据用户偏好进行微调，但在此过程中用户的个人数据（如饮食习惯）容易泄露。需要开发既能个性化又能保护隐私的机器人策略。

Method: 为每个用户分配唯一密钥，用该密钥对机器人网络权重进行数学变换。只有使用正确密钥时，机器人策略才会切换到该用户的个性化行为。

Result: PRoP在模仿学习、强化学习和分类任务中均表现良好，优于现有的基于编码器的方法，同时保持了原始策略的架构和行为。

Conclusion: PRoP框架有效解决了机器人个性化过程中的隐私保护问题，具有实际应用价值。

Abstract: Recent works introduce general-purpose robot policies. These policies provide
a strong prior over how robots should behave -- e.g., how a robot arm should
manipulate food items. But in order for robots to match an individual person's
needs, users typically fine-tune these generalized policies -- e.g., showing
the robot arm how to make their own preferred dinners. Importantly, during the
process of personalizing robots, end-users leak data about their preferences,
habits, and styles (e.g., the foods they prefer to eat). Other agents can
simply roll-out the fine-tuned policy and see these personally-trained
behaviors. This leads to a fundamental challenge: how can we develop robots
that personalize actions while keeping learning private from external agents?
We here explore this emerging topic in human-robot interaction and develop
PRoP, a model-agnostic framework for personalized and private robot policies.
Our core idea is to equip each user with a unique key; this key is then used to
mathematically transform the weights of the robot's network. With the correct
key, the robot's policy switches to match that user's preferences -- but with
incorrect keys, the robot reverts to its baseline behaviors. We show the
general applicability of our method across multiple model types in imitation
learning, reinforcement learning, and classification tasks. PRoP is practically
advantageous because it retains the architecture and behaviors of the original
policy, and experimentally outperforms existing encoder-based approaches. See
videos and code here: https://prop-icra26.github.io.

</details>


### [107] [Haptic Communication in Human-Human and Human-Robot Co-Manipulation](https://arxiv.org/abs/2509.18327)
*Katherine H. Allen,Chris Rogers,Elaine S. Short*

Main category: cs.RO

TL;DR: 该研究比较了人-人和人-机器人协作操纵物体时的运动特征差异，发现人-人协作更加流畅，并建议未来机器人应具备发送和接收类人触觉信号的能力


<details>
  <summary>Details</summary>
Motivation: 研究人类在协作操纵物体时通过物体运动进行的触觉通信，并比较人-人协作与人-机器人协作的差异，以改进机器人协作能力

Method: 使用低成本IMU跟踪人-人协作和人-机器人协作中共享物体的运动，通过问卷收集参与者反馈，分析运动数据差异

Result: 人-人协作显著更流畅，IMU数据捕捉到了不同条件下的运动特征差异，主观和客观指标都显示人-人协作优于人-机器人协作

Conclusion: 研究结果支持未来开发能够发送和接收类人触觉信号的机器人助手，以改善物理任务中的协作效果

Abstract: When a human dyad jointly manipulates an object, they must communicate about
their intended motion plans. Some of that collaboration is achieved through the
motion of the manipulated object itself, which we call "haptic communication."
In this work, we captured the motion of human-human dyads moving an object
together with one participant leading a motion plan about which the follower is
uninformed. We then captured the same human participants manipulating the same
object with a robot collaborator. By tracking the motion of the shared object
using a low-cost IMU, we can directly compare human-human shared manipulation
to the motion of those same participants interacting with the robot.
Intra-study and post-study questionnaires provided participant feedback on the
collaborations, indicating that the human-human collaborations are
significantly more fluent, and analysis of the IMU data indicates that it
captures objective differences in the motion profiles of the conditions. The
differences in objective and subjective measures of accuracy and fluency
between the human-human and human-robot trials motivate future research into
improving robot assistants for physical tasks by enabling them to send and
receive anthropomorphic haptic signals.

</details>


### [108] [The Landform Contextual Mesh: Automatically Fusing Surface and Orbital Terrain for Mars 2020](https://arxiv.org/abs/2509.18330)
*Marsette Vona*

Main category: cs.RO

TL;DR: 该论文介绍了Landform上下文网格技术，该技术融合了火星2020探测车拍摄的数千张2D和3D图像数据，以及火星勘测轨道飞行器的轨道高程和彩色地图，创建交互式3D地形可视化。


<details>
  <summary>Details</summary>
Motivation: 为火星任务科学家提供战术和战略规划工具，同时向公众提供火星探索的可视化体验。

Method: 通过自动处理探测车每个位置的2D和3D图像数据，结合轨道高程和彩色地图，构建上下文网格。

Result: 成功开发了自动化的上下文网格生成系统，该系统已集成到ASTTRO工具中供科学家使用，部分网格也在公共网站上发布。

Conclusion: Landform上下文网格技术有效支持了火星探测任务的科学规划和公众参与，展示了多源数据融合在行星探索中的实用价值。

Abstract: The Landform contextual mesh fuses 2D and 3D data from up to thousands of
Mars 2020 rover images, along with orbital elevation and color maps from Mars
Reconnaissance Orbiter, into an interactive 3D terrain visualization.
Contextual meshes are built automatically for each rover location during
mission ground data system processing, and are made available to mission
scientists for tactical and strategic planning in the Advanced Science
Targeting Tool for Robotic Operations (ASTTRO). A subset of them are also
deployed to the "Explore with Perseverance" public access website.

</details>


### [109] [Semantic-Aware Particle Filter for Reliable Vineyard Robot Localisation](https://arxiv.org/abs/2509.18342)
*Rajitha de Silva,Jonathan Cox,James R. Heselden,Marija Popovic,Cesar Cadena,Riccardo Polvara*

Main category: cs.RO

TL;DR: 提出了一种用于葡萄园环境的语义粒子滤波器，通过融合LiDAR扫描和语义地标（葡萄藤树干和支撑杆）来解决重复行几何结构导致的定位问题，使用语义墙和自适应GPS先验来提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 在结构化的户外环境中，特别是葡萄园这种具有重复行几何结构的环境，传统的LiDAR定位方法由于感知混叠而经常失效，需要一种能够利用稳定物体级检测的定位方法。

Method: 开发了语义粒子滤波器，将检测到的地标（葡萄藤树干和支撑杆）投影到鸟瞰图并与LiDAR扫描融合生成语义观测。关键创新是使用语义墙连接相邻地标形成伪结构约束，并在语义稀疏的头地区域引入自适应GPS先验来保持全局一致性。

Result: 在真实葡萄园中的实验表明，该方法能够在正确的行内保持定位，在AMCL失败的情况下从偏差中恢复，并且优于基于视觉的SLAM方法如RTAB-Map。

Conclusion: 所提出的语义粒子滤波器通过结合语义地标和自适应GPS先验，有效解决了葡萄园环境中的定位挑战，为在具有重复几何结构的农业环境中实现鲁棒定位提供了可行方案。

Abstract: Accurate localisation is critical for mobile robots in structured outdoor
environments, yet LiDAR-based methods often fail in vineyards due to repetitive
row geometry and perceptual aliasing. We propose a semantic particle filter
that incorporates stable object-level detections, specifically vine trunks and
support poles into the likelihood estimation process. Detected landmarks are
projected into a birds eye view and fused with LiDAR scans to generate semantic
observations. A key innovation is the use of semantic walls, which connect
adjacent landmarks into pseudo-structural constraints that mitigate row
aliasing. To maintain global consistency in headland regions where semantics
are sparse, we introduce a noisy GPS prior that adaptively supports the filter.
Experiments in a real vineyard demonstrate that our approach maintains
localisation within the correct row, recovers from deviations where AMCL fails,
and outperforms vision-based SLAM methods such as RTAB-Map.

</details>


### [110] [AD-VF: LLM-Automatic Differentiation Enables Fine-Tuning-Free Robot Planning from Formal Methods Feedback](https://arxiv.org/abs/2509.18384)
*Yunhao Yang,Junyuan Hong,Gabriel Jacob Perin,Zhiwen Fan,Li Yin,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: LAD-VF是一个无需微调的框架，利用形式化验证反馈进行自动提示工程，通过文本损失函数迭代优化提示而非模型参数，显著提升LLM驱动规划系统的规范合规性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的规划系统在物理世界部署时经常违反安全和监管约束，传统的数据驱动对齐方法需要昂贵的人工标注，而现有的形式化反馈方法仍需资源密集的微调。

Method: 提出LAD-VF框架，结合形式化验证反馈的文本损失函数与LLM-AutoDiff，迭代优化提示而非模型参数，实现无需微调的自动化提示工程。

Result: 在机器人导航和操作任务中，LAD-VF将规范合规的成功率从60%提升到90%以上。

Conclusion: LAD-VF为可信赖、形式化验证的LLM驱动控制系统提供了一条可扩展且可解释的路径。

Abstract: Large language models (LLMs) can translate natural language instructions into
executable action plans for robotics, autonomous driving, and other domains.
Yet, deploying LLM-driven planning in the physical world demands strict
adherence to safety and regulatory constraints, which current models often
violate due to hallucination or weak alignment. Traditional data-driven
alignment methods, such as Direct Preference Optimization (DPO), require costly
human labeling, while recent formal-feedback approaches still depend on
resource-intensive fine-tuning. In this paper, we propose LAD-VF, a
fine-tuning-free framework that leverages formal verification feedback for
automated prompt engineering. By introducing a formal-verification-informed
text loss integrated with LLM-AutoDiff, LAD-VF iteratively refines prompts
rather than model parameters. This yields three key benefits: (i) scalable
adaptation without fine-tuning; (ii) compatibility with modular LLM
architectures; and (iii) interpretable refinement via auditable prompts.
Experiments in robot navigation and manipulation tasks demonstrate that LAD-VF
substantially enhances specification compliance, improving success rates from
60% to over 90%. Our method thus presents a scalable and interpretable pathway
toward trustworthy, formally-verified LLM-driven control systems.

</details>


### [111] [Assistive Decision-Making for Right of Way Navigation at Uncontrolled Intersections](https://arxiv.org/abs/2509.18407)
*Navya Tiwari,Joseph Vazhaeparampil,Victoria Preston*

Main category: cs.RO

TL;DR: 本文提出了一种基于部分可观测马尔可夫决策过程（POMDP）的驾驶员辅助框架，用于无控制交叉口的通行权推理，通过概率规划器显著提高了安全性能。


<details>
  <summary>Details</summary>
Motivation: 无控制交叉口由于通行权规则模糊、遮挡和驾驶员行为不可预测等因素导致大量交通事故，而现有研究很少关注为人工驾驶车辆提供辅助导航支持。

Method: 开发了驾驶员辅助框架，采用POMDP建模，在自定义仿真环境中比较了确定性有限状态机和三种概率规划器（QMDP、POMCP、DESPOT）的性能。

Result: 概率规划器优于基于规则的基线方法，在部分可观测条件下实现了高达97.5%的无碰撞导航率，其中POMCP注重安全性，DESPOT平衡效率与运行时可行性。

Conclusion: 不确定性感知规划对驾驶员辅助系统至关重要，未来需要集成传感器融合和环境感知模块以实现真实交通环境中的实时部署。

Abstract: Uncontrolled intersections account for a significant fraction of roadway
crashes due to ambiguous right-of-way rules, occlusions, and unpredictable
driver behavior. While autonomous vehicle research has explored
uncertainty-aware decision making, few systems exist to retrofit human-operated
vehicles with assistive navigation support. We present a driver-assist
framework for right-of-way reasoning at uncontrolled intersections, formulated
as a Partially Observable Markov Decision Process (POMDP). Using a custom
simulation testbed with stochastic traffic agents, pedestrians, occlusions, and
adversarial scenarios, we evaluate four decision-making approaches: a
deterministic finite state machine (FSM), and three probabilistic planners:
QMDP, POMCP, and DESPOT. Results show that probabilistic planners outperform
the rule-based baseline, achieving up to 97.5 percent collision-free navigation
under partial observability, with POMCP prioritizing safety and DESPOT
balancing efficiency and runtime feasibility. Our findings highlight the
importance of uncertainty-aware planning for driver assistance and motivate
future integration of sensor fusion and environment perception modules for
real-time deployment in realistic traffic environments.

</details>


### [112] [Latent Action Pretraining Through World Modeling](https://arxiv.org/abs/2509.18428)
*Bahey Tharwat,Yara Nasser,Ali Abouzeid,Ian Reid*

Main category: cs.RO

TL;DR: LAWM是一个模型无关的框架，通过世界建模从无标签视频数据中学习潜在动作表示，用于自监督预训练模仿学习模型，在效率和实用性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型依赖大规模人工标注的动作数据集，模型体积大，在真实世界部署困难。需要更高效实用的预训练方法。

Method: 提出LAWM框架，通过世界建模从无标签视频（机器人记录或人类日常动作视频）中学习潜在动作表示，支持跨任务、环境和体现的迁移。

Result: 在LIBERO基准测试和真实世界设置中，LAWM优于使用真实机器人动作训练的模型和类似预训练方法。

Conclusion: LAWM框架在保持高性能的同时，显著提高了效率，更适合真实世界部署。

Abstract: Vision-Language-Action (VLA) models have gained popularity for learning
robotic manipulation tasks that follow language instructions. State-of-the-art
VLAs, such as OpenVLA and $\pi_{0}$, were trained on large-scale, manually
labeled action datasets collected through teleoperation. More recent
approaches, including LAPA and villa-X, introduce latent action representations
that enable unsupervised pretraining on unlabeled datasets by modeling abstract
visual changes between frames. Although these methods have shown strong
results, their large model sizes make deployment in real-world settings
challenging. In this work, we propose LAWM, a model-agnostic framework to
pretrain imitation learning models in a self-supervised way, by learning latent
action representations from unlabeled video data through world modeling. These
videos can be sourced from robot recordings or videos of humans performing
actions with everyday objects. Our framework is designed to be effective for
transferring across tasks, environments, and embodiments. It outperforms models
trained with ground-truth robotics actions and similar pretraining methods on
the LIBERO benchmark and real-world setup, while being significantly more
efficient and practical for real-world settings.

</details>


### [113] [PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction](https://arxiv.org/abs/2509.18447)
*Rishabh Madan,Jiawei Lin,Mahika Goel,Angchen Xie,Xiaoyu Liang,Marcus Lee,Justin Guo,Pranav N. Thakkar,Rohan Banerjee,Jose Barreiros,Kate Tsui,Tom Silver,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: PrioriTouch是一个用于在物理人机交互中优先处理多接触控制目标的框架，通过学习和排序方法解决不同身体部位接触力冲突的问题。


<details>
  <summary>Details</summary>
Motivation: 在护理等需要多接触交互的任务中，不同身体部位对接触力的偏好可能存在冲突，需要优先处理机制来平衡各种控制目标。

Method: 结合学习排序方法和分层操作空间控制，利用仿真循环展开进行数据高效安全探索，整合个性化舒适阈值。

Result: 通过仿真和真实实验验证，PrioriTouch能够适应用户接触偏好，保持任务性能，提高安全性和舒适度。

Conclusion: 该框架为多接触物理人机交互提供了一种有效的优先级控制方法，特别适用于护理场景。

Abstract: Physical human-robot interaction (pHRI) requires robots to adapt to
individual contact preferences, such as where and how much force is applied.
Identifying preferences is difficult for a single contact; with whole-arm
interaction involving multiple simultaneous contacts between the robot and
human, the challenge is greater because different body parts can impose
incompatible force requirements. In caregiving tasks, where contact is frequent
and varied, such conflicts are unavoidable. With multiple preferences across
multiple contacts, no single solution can satisfy all objectives--trade-offs
are inherent, making prioritization essential. We present PrioriTouch, a
framework for ranking and executing control objectives across multiple
contacts. PrioriTouch can prioritize from a general collection of controllers,
making it applicable not only to caregiving scenarios such as bed bathing and
dressing but also to broader multi-contact settings. Our method combines a
novel learning-to-rank approach with hierarchical operational space control,
leveraging simulation-in-the-loop rollouts for data-efficient and safe
exploration. We conduct a user study on physical assistance preferences, derive
personalized comfort thresholds, and incorporate them into PrioriTouch. We
evaluate PrioriTouch through extensive simulation and real-world experiments,
demonstrating its ability to adapt to user contact preferences, maintain task
performance, and enhance safety and comfort. Website:
https://emprise.cs.cornell.edu/prioritouch.

</details>


### [114] [Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands](https://arxiv.org/abs/2509.18455)
*Yunshuang Li,Yiyang Ling,Gaurav S. Sukhatme,Daniel Seita*

Main category: cs.RO

TL;DR: 本文提出了一种基于几何感知的多指灵巧手推拉操作（GD2P）方法，用于非抓取式操作。通过接触引导采样生成多样化的手部姿态，利用物理模拟进行筛选，并训练扩散模型来预测可行的手部姿态。实验表明该方法在真实机器人上具有良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有的非抓取式操作主要依赖平行夹爪或工具，而多指灵巧手能提供更丰富的接触模式和稳定性，但非抓取操作的动力学建模困难。因此需要开发专门针对灵巧手的非抓取操作方法。

Method: 1. 通过接触引导采样生成多样化的预接触手部姿态；2. 使用物理模拟筛选可行姿态；3. 训练基于物体几何条件的扩散模型来预测可行手部姿态；4. 在测试时采样手部姿态并使用标准运动规划器执行推拉动作。

Result: 在Allegro Hand上进行了840次真实世界实验，结果表明GD2P为训练灵巧非抓取操作策略提供了可扩展的途径。在LEAP Hand上的进一步演示验证了该方法对不同手部形态的适用性。

Conclusion: GD2P方法有效解决了多指灵巧手非抓取操作的挑战，提供了包含130万手部姿态和2300个物体的开源数据集和预训练模型，将促进相关领域的研究发展。

Abstract: Nonprehensile manipulation, such as pushing and pulling, enables robots to
move, align, or reposition objects that may be difficult to grasp due to their
geometry, size, or relationship to the robot or the environment. Much of the
existing work in nonprehensile manipulation relies on parallel-jaw grippers or
tools such as rods and spatulas. In contrast, multi-fingered dexterous hands
offer richer contact modes and versatility for handling diverse objects to
provide stable support over the objects, which compensates for the difficulty
of modeling the dynamics of nonprehensile manipulation. Therefore, we propose
Geometry-aware Dexterous Pushing and Pulling (GD2P) for nonprehensile
manipulation with dexterous robotic hands. We study pushing and pulling by
framing the problem as synthesizing and learning pre-contact dexterous hand
poses that lead to effective manipulation. We generate diverse hand poses via
contact-guided sampling, filter them using physics simulation, and train a
diffusion model conditioned on object geometry to predict viable poses. At test
time, we sample hand poses and use standard motion planners to select and
execute pushing and pulling actions. We perform 840 real-world experiments with
an Allegro Hand, comparing our method to baselines. The results indicate that
GD2P offers a scalable route for training dexterous nonprehensile manipulation
policies. We further demonstrate GD2P on a LEAP Hand, highlighting its
applicability to different hand morphologies. Our pre-trained models and
dataset, including 1.3 million hand poses across 2.3k objects, will be
open-source to facilitate further research. Our project website is available
at: geodex2p.github.io.

</details>


### [115] [A Counterfactual Reasoning Framework for Fault Diagnosis in Robot Perception Systems](https://arxiv.org/abs/2509.18460)
*Haeyoon Han,Mahdi Taheri,Soon-Jo Chung,Fred Y. Hadaegh*

Main category: cs.RO

TL;DR: 本文提出了一种基于反事实推理的感知系统故障检测与隔离框架，通过分析冗余而非物理冗余来构建感知可靠性测试，采用被动和主动两种FDI方法，并在机器人探索场景中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 感知系统为自主系统提供环境理解，其故障会影响下游模块决策。感知系统故障具有特殊性：与感知环境上下文相关，且多阶段流水线中的错误会在模块间传播。需要解决这些挑战来确保系统可靠性。

Method: 采用反事实推理方法构建感知可靠性测试作为因果结果。被动FDI通过信念更新实现，主动FDI定义为因果多臂赌博机问题，使用蒙特卡洛树搜索和上置信界算法寻找最大化有效信息的控制输入。

Result: 在机器人探索场景中验证，空间机器人通过主动调整姿态增加有效信息，成功隔离了由传感器损坏、动态场景和感知退化引起的故障。

Conclusion: 反事实推理框架有效解决了感知系统故障检测与隔离问题，主动FDI方法通过优化控制输入提高了故障诊断能力，为自主系统的可靠性提供了重要保障。

Abstract: Perception systems provide a rich understanding of the environment for
autonomous systems, shaping decisions in all downstream modules. Hence,
accurate detection and isolation of faults in perception systems is important.
Faults in perception systems pose particular challenges: faults are often tied
to the perceptual context of the environment, and errors in their multi-stage
pipelines can propagate across modules. To address this, we adopt a
counterfactual reasoning approach to propose a framework for fault detection
and isolation (FDI) in perception systems. As opposed to relying on physical
redundancy (i.e., having extra sensors), our approach utilizes analytical
redundancy with counterfactual reasoning to construct perception reliability
tests as causal outcomes influenced by system states and fault scenarios.
Counterfactual reasoning generates reliability test results under hypothesized
faults to update the belief over fault hypotheses. We derive both passive and
active FDI methods. While the passive FDI can be achieved by belief updates,
the active FDI approach is defined as a causal bandit problem, where we utilize
Monte Carlo Tree Search (MCTS) with upper confidence bound (UCB) to find
control inputs that maximize a detection and isolation metric, designated as
Effective Information (EI). The mentioned metric quantifies the informativeness
of control inputs for FDI. We demonstrate the approach in a robot exploration
scenario, where a space robot performing vision-based navigation actively
adjusts its attitude to increase EI and correctly isolate faults caused by
sensor damage, dynamic scenes, and perceptual degradation.

</details>


### [116] [Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task](https://arxiv.org/abs/2509.18463)
*Jannick van Buuren,Roberto Giglio,Loris Roveda,Luka Peternel*

Main category: cs.RO

TL;DR: 本文提出了一种基于奖励函数变异的新框架，通过在奖励函数的不同项上应用高斯噪声来产生多样化的机器人操作技能，以液体倾倒任务为例展示了该方法能生成从原始任务变体到意外新技能（如容器边缘清洁、液体混合和浇水）的广泛行为。


<details>
  <summary>Details</summary>
Motivation: 受人类运动控制中成本-收益权衡模型的启发，研究旨在探索如何通过故意变异奖励函数来产生机器人操作任务的多样化技能变化，使机器人系统能够学习特定任务的多样化执行方式，并可能为未来任务衍生有意义的技能。

Method: 开发了基于高斯噪声的奖励函数变异框架，奖励函数包含准确性、时间和努力三个关键项；在NVIDIA Isaac Sim仿真环境中使用Franka Emika Panda机械臂进行液体倾倒任务，采用近端策略优化强化学习算法，系统探索不同权重变异配置对学习策略的影响。

Result: 生成的策略展现出广泛的行为范围：从原始倾倒任务执行的变化到意外任务的新技能，如容器边缘清洁、液体混合和浇水。

Conclusion: 该方法为机器人系统执行特定任务的多样化学习提供了有前景的方向，同时可能为未来任务衍生有意义的技能。

Abstract: This paper explores how deliberate mutations of reward function in
reinforcement learning can produce diversified skill variations in robotic
manipulation tasks, examined with a liquid pouring use case. To this end, we
developed a new reward function mutation framework that is based on applying
Gaussian noise to the weights of the different terms in the reward function.
Inspired by the cost-benefit tradeoff model from human motor control, we
designed the reward function with the following key terms: accuracy, time, and
effort. The study was performed in a simulation environment created in NVIDIA
Isaac Sim, and the setup included Franka Emika Panda robotic arm holding a
glass with a liquid that needed to be poured into a container. The
reinforcement learning algorithm was based on Proximal Policy Optimization. We
systematically explored how different configurations of mutated weights in the
rewards function would affect the learned policy. The resulting policies
exhibit a wide range of behaviours: from variations in execution of the
originally intended pouring task to novel skills useful for unexpected tasks,
such as container rim cleaning, liquid mixing, and watering. This approach
offers promising directions for robotic systems to perform diversified learning
of specific tasks, while also potentially deriving meaningful skills for future
tasks.

</details>


### [117] [RL-augmented Adaptive Model Predictive Control for Bipedal Locomotion over Challenging Terrain](https://arxiv.org/abs/2509.18466)
*Junnosuke Kamohara,Feiyang Wu,Chinmayee Wamorkar,Seth Hutchinson,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种用于双足机器人在粗糙和湿滑地形上行走的RL增强MPC框架，通过参数化MPC的三个关键组件来结合MPC和RL的优势。


<details>
  <summary>Details</summary>
Motivation: MPC在双足行走方面有效但难以建模复杂地形交互，RL能训练出鲁棒策略但缺乏约束保证且需要大量奖励设计。现有MPC+RL方法主要限于平坦地形或四足机器人。

Method: 参数化基于单刚体动力学的MPC的三个关键组件：系统动力学、摆动腿控制器和步态频率，在NVIDIA IsaacLab中进行双足机器人仿真验证。

Result: 在楼梯、踏脚石和低摩擦表面等多种地形上的实验表明，RL增强MPC框架比基线MPC和RL产生显著更自适应和鲁棒的行为。

Conclusion: RL增强MPC框架成功结合了MPC的约束保证和RL的适应性，为双足机器人在复杂地形上的鲁棒行走提供了有效解决方案。

Abstract: Model predictive control (MPC) has demonstrated effectiveness for humanoid
bipedal locomotion; however, its applicability in challenging environments,
such as rough and slippery terrain, is limited by the difficulty of modeling
terrain interactions. In contrast, reinforcement learning (RL) has achieved
notable success in training robust locomotion policies over diverse terrain,
yet it lacks guarantees of constraint satisfaction and often requires
substantial reward shaping. Recent efforts in combining MPC and RL have shown
promise of taking the best of both worlds, but they are primarily restricted to
flat terrain or quadrupedal robots. In this work, we propose an RL-augmented
MPC framework tailored for bipedal locomotion over rough and slippery terrain.
Our method parametrizes three key components of
single-rigid-body-dynamics-based MPC: system dynamics, swing leg controller,
and gait frequency. We validate our approach through bipedal robot simulations
in NVIDIA IsaacLab across various terrains, including stairs, stepping stones,
and low-friction surfaces. Experimental results demonstrate that our
RL-augmented MPC framework produces significantly more adaptive and robust
behaviors compared to baseline MPC and RL.

</details>


### [118] [Spatial Envelope MPC: High Performance Driving without a Reference](https://arxiv.org/abs/2509.18506)
*Siyuan Yu,Congkai Shen,Yufei Xi,James Dallas,Michael Thompson,John Subosits,Hiroshi Yasuda,Tulga Ersal*

Main category: cs.RO

TL;DR: 提出了一种基于包络线的模型预测控制框架，使自动驾驶车辆无需预定义参考轨迹即可处理高性能驾驶场景


<details>
  <summary>Details</summary>
Motivation: 现有基于参考轨迹的规划控制框架在车辆达到动态极限时性能受限，需要能够直接整合动态可行性和安全约束的统一框架

Method: 开发了计算高效的车辆动力学模型和连续可微的数学公式来捕捉整个可行驶包络线，结合强化学习和优化技术解决包络规划问题

Result: 通过仿真和真实实验验证，该框架在赛车、紧急避障和越野导航等多种任务中表现出高性能

Conclusion: 该框架具有可扩展性和广泛适用性，能够处理多样化的自动驾驶场景

Abstract: This paper presents a novel envelope based model predictive control (MPC)
framework designed to enable autonomous vehicles to handle high performance
driving across a wide range of scenarios without a predefined reference. In
high performance autonomous driving, safe operation at the vehicle's dynamic
limits requires a real time planning and control framework capable of
accounting for key vehicle dynamics and environmental constraints when
following a predefined reference trajectory is suboptimal or even infeasible.
State of the art planning and control frameworks, however, are predominantly
reference based, which limits their performance in such situations. To address
this gap, this work first introduces a computationally efficient vehicle
dynamics model tailored for optimization based control and a continuously
differentiable mathematical formulation that accurately captures the entire
drivable envelope. This novel model and formulation allow for the direct
integration of dynamic feasibility and safety constraints into a unified
planning and control framework, thereby removing the necessity for predefined
references. The challenge of envelope planning, which refers to maximally
approximating the safe drivable area, is tackled by combining reinforcement
learning with optimization techniques. The framework is validated through both
simulations and real world experiments, demonstrating its high performance
across a variety of tasks, including racing, emergency collision avoidance and
off road navigation. These results highlight the framework's scalability and
broad applicability across a diverse set of scenarios.

</details>


### [119] [LCMF: Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA](https://arxiv.org/abs/2509.18576)
*Zeyi Kang,Liang He,Yanxin Zhang,Zuheng Ming,Kaixing Zhao*

Main category: cs.RO

TL;DR: 该论文提出轻量级LCMF级联注意力框架，通过多级跨模态参数共享机制实现异构模态的高效融合和语义互补对齐，在资源受限环境下显著提升多模态语义学习性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态语义学习中的异构数据有效融合和资源受限环境下的计算效率挑战，为具身智能中的人机交互应用提供高效解决方案。

Method: 提出LCMF框架，将多级跨模态参数共享机制集成到Mamba模块中，结合交叉注意力和选择性参数共享状态空间模型的优势。

Result: 在VQA任务中达到74.29%准确率，在EQA视频任务中达到LLM智能体中游水平，FLOPs比同类基线平均减少4.35倍，参数量仅166.51M（图像-文本）和219M（视频-文本）。

Conclusion: LCMF框架为资源受限场景下的人机交互应用提供了具有强大多模态决策泛化能力的高效解决方案。

Abstract: Multimodal semantic learning plays a critical role in embodied intelligence,
especially when robots perceive their surroundings, understand human
instructions, and make intelligent decisions. However, the field faces
technical challenges such as effective fusion of heterogeneous data and
computational efficiency in resource-constrained environments. To address these
challenges, this study proposes the lightweight LCMF cascaded attention
framework, introducing a multi-level cross-modal parameter sharing mechanism
into the Mamba module. By integrating the advantages of Cross-Attention and
Selective parameter-sharing State Space Models (SSMs), the framework achieves
efficient fusion of heterogeneous modalities and semantic complementary
alignment. Experimental results show that LCMF surpasses existing multimodal
baselines with an accuracy of 74.29% in VQA tasks and achieves competitive
mid-tier performance within the distribution cluster of Large Language Model
Agents (LLM Agents) in EQA video tasks. Its lightweight design achieves a
4.35-fold reduction in FLOPs relative to the average of comparable baselines
while using only 166.51M parameters (image-text) and 219M parameters
(video-text), providing an efficient solution for Human-Robot Interaction (HRI)
applications in resource-constrained scenarios with strong multimodal decision
generalization capabilities.

</details>


### [120] [VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation](https://arxiv.org/abs/2509.18592)
*Neel P. Bhatt,Yunhao Yang,Rohan Siva,Pranay Samineni,Daniel Milan,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: VLN-Zero是一个两阶段的视觉语言导航框架，利用视觉语言模型构建符号场景图，实现零样本神经符号导航，在未见环境中实现快速适应和高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言导航方法在未见环境中适应性差、计算效率低的问题，实现可扩展的自主导航。

Method: 采用两阶段框架：探索阶段使用结构化提示引导VLM搜索构建紧凑场景图；部署阶段使用神经符号规划器在场景图上推理生成可执行计划，并通过缓存机制加速适应。

Result: 在多样化环境中，VLN-Zero相比最先进的零样本模型成功率提高2倍，超越大多数微调基线，到达目标位置时间减半，VLM调用减少55%。

Conclusion: VLN-Zero通过快速探索、符号推理和缓存执行相结合，克服了现有方法的计算低效和泛化能力差的问题，实现了在未见环境中鲁棒且可扩展的决策制定。

Abstract: Rapid adaptation in unseen environments is essential for scalable real-world
autonomy, yet existing approaches rely on exhaustive exploration or rigid
navigation policies that fail to generalize. We present VLN-Zero, a two-phase
vision-language navigation framework that leverages vision-language models to
efficiently construct symbolic scene graphs and enable zero-shot neurosymbolic
navigation. In the exploration phase, structured prompts guide VLM-based search
toward informative and diverse trajectories, yielding compact scene graph
representations. In the deployment phase, a neurosymbolic planner reasons over
the scene graph and environmental observations to generate executable plans,
while a cache-enabled execution module accelerates adaptation by reusing
previously computed task-location trajectories. By combining rapid exploration,
symbolic reasoning, and cache-enabled execution, the proposed framework
overcomes the computational inefficiency and poor generalization of prior
vision-language navigation methods, enabling robust and scalable
decision-making in unseen environments. VLN-Zero achieves 2x higher success
rate compared to state-of-the-art zero-shot models, outperforms most fine-tuned
baselines, and reaches goal locations in half the time with 55% fewer VLM calls
on average compared to state-of-the-art models across diverse environments.
Codebase, datasets, and videos for VLN-Zero are available at:
https://vln-zero.github.io/.

</details>


### [121] [Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills](https://arxiv.org/abs/2509.18597)
*Yuan Meng,Zhenguo Sun,Max Fest,Xukun Li,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 提出了一种基于大语言模型的人机协同框架，用于机器人操作任务，通过将人类修正编码为可重用技能，结合外部记忆和检索增强生成技术，显著提升了长时程任务的执行成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的机器人代码生成方法存在噪声大、受限于固定原语、上下文窗口有限、难以处理长时程任务等问题，且闭环反馈中的修正知识存储格式不当，限制了泛化能力并导致灾难性遗忘。

Method: 采用人在回路框架，将人类修正编码为可重用技能，使用外部记忆和带有提示机制的检索增强生成技术实现动态重用。

Result: 在Ravens、Franka Kitchen和MetaWorld等基准测试以及真实场景中，框架实现了0.93的成功率（比基线提升高达27%），修正轮次效率提升42%，能够稳健解决需要规划超过20个原语的"建造房屋"等极端长时程任务。

Conclusion: 该人机协同框架通过将修正知识编码为可重用技能，有效解决了LLM在机器人领域的长时程任务规划难题，显著提升了任务成功率和效率。

Abstract: Large language models (LLMs)-based code generation for robotic manipulation
has recently shown promise by directly translating human instructions into
executable code, but existing methods remain noisy, constrained by fixed
primitives and limited context windows, and struggle with long-horizon tasks.
While closed-loop feedback has been explored, corrected knowledge is often
stored in improper formats, restricting generalization and causing catastrophic
forgetting, which highlights the need for learning reusable skills. Moreover,
approaches that rely solely on LLM guidance frequently fail in extremely
long-horizon scenarios due to LLMs' limited reasoning capability in the robotic
domain, where such issues are often straightforward for humans to identify. To
address these challenges, we propose a human-in-the-loop framework that encodes
corrections into reusable skills, supported by external memory and
Retrieval-Augmented Generation with a hint mechanism for dynamic reuse.
Experiments on Ravens, Franka Kitchen, and MetaWorld, as well as real-world
settings, show that our framework achieves a 0.93 success rate (up to 27%
higher than baselines) and a 42% efficiency improvement in correction rounds.
It can robustly solve extremely long-horizon tasks such as "build a house",
which requires planning over 20 primitives.

</details>


### [122] [End-to-End Crop Row Navigation via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2509.18608)
*Ana Luiza Mineiro,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出了一种基于端到端学习的导航系统，使用深度强化学习策略将原始3D LiDAR数据直接映射到控制命令，解决农业冠层下环境中的可靠导航问题。


<details>
  <summary>Details</summary>
Motivation: 解决冠层下农业环境中GNSS不可靠、行间杂乱和光照变化等挑战，实现可靠导航。

Method: 采用基于体素的下采样策略将LiDAR输入尺寸减少95.83%，使用深度强化学习策略在仿真环境中训练，无需标记数据集或手动设计的控制接口。

Result: 在仿真验证中，直线种植园中达到100%成功率，随着行曲率增加性能逐渐下降，在不同正弦频率和幅度下进行了测试。

Conclusion: 该方法展示了在仿真环境中训练的学习策略能够有效处理农业导航挑战，为实际应用提供了可行方案。

Abstract: Reliable navigation in under-canopy agricultural environments remains a
challenge due to GNSS unreliability, cluttered rows, and variable lighting. To
address these limitations, we present an end-to-end learning-based navigation
system that maps raw 3D LiDAR data directly to control commands using a deep
reinforcement learning policy trained entirely in simulation. Our method
includes a voxel-based downsampling strategy that reduces LiDAR input size by
95.83%, enabling efficient policy learning without relying on labeled datasets
or manually designed control interfaces. The policy was validated in
simulation, achieving a 100% success rate in straight-row plantations and
showing a gradual decline in performance as row curvature increased, tested
across varying sinusoidal frequencies and amplitudes.

</details>


### [123] [PIE: Perception and Interaction Enhanced End-to-End Motion Planning for Autonomous Driving](https://arxiv.org/abs/2509.18609)
*Chengran Yuan,Zijian Lu,Zhanqi Zhang,Yimin Zhao,Zefan Huang,Shuo Sun,Jiawei Sun,Jiahui Li,Christina Dao Wen Lee,Dongen Li,Marcelo H. Ang Jr*

Main category: cs.RO

TL;DR: PIE是一个端到端的运动规划框架，通过集成先进感知、推理和意图建模来动态捕捉自车与周围智能体之间的交互，在NAVSIM基准测试中超越了现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 端到端运动规划虽然有望简化复杂的自动驾驶流程，但在场景理解和有效预测决策方面仍面临重大挑战，阻碍了其大规模部署。

Method: 采用双向Mamba融合解决相机和LiDAR多模态融合中的数据压缩损失，结合推理增强解码器（集成Mamba和Mixture-of-Experts）进行场景兼容的锚点选择和自适应轨迹推断优化，使用动作-运动交互模块利用周围智能体状态预测来优化自车规划。

Result: 在NAVSIM基准测试中，PIE在不使用任何集成和数据增强技术的情况下，获得了88.9 PDM分数和85.6 EPDM分数，超越了现有最优方法。

Conclusion: 综合定量和定性分析表明，PIE能够可靠地生成可行且高质量的自车轨迹。

Abstract: End-to-end motion planning is promising for simplifying complex autonomous
driving pipelines. However, challenges such as scene understanding and
effective prediction for decision-making continue to present substantial
obstacles to its large-scale deployment. In this paper, we present PIE, a
pioneering framework that integrates advanced perception, reasoning, and
intention modeling to dynamically capture interactions between the ego vehicle
and surrounding agents. It incorporates a bidirectional Mamba fusion that
addresses data compression losses in multimodal fusion of camera and LiDAR
inputs, alongside a novel reasoning-enhanced decoder integrating Mamba and
Mixture-of-Experts to facilitate scene-compliant anchor selection and optimize
adaptive trajectory inference. PIE adopts an action-motion interaction module
to effectively utilize state predictions of surrounding agents to refine ego
planning. The proposed framework is thoroughly validated on the NAVSIM
benchmark. PIE, without using any ensemble and data augmentation techniques,
achieves an 88.9 PDM score and 85.6 EPDM score, surpassing the performance of
prior state-of-the-art methods. Comprehensive quantitative and qualitative
analyses demonstrate that PIE is capable of reliably generating feasible and
high-quality ego trajectories.

</details>


### [124] [SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones](https://arxiv.org/abs/2509.18610)
*Maximilian Adang,JunEn Low,Ola Shorinwa,Mac Schwager*

Main category: cs.RO

TL;DR: SINGER是一个基于语言引导的自主无人机导航系统，仅使用机载传感和计算，通过高斯泼溅模拟器生成数据，结合RRT多轨迹专家和轻量级端到端视觉运动策略，实现零样本模拟到现实的转移。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇自主无人机导航的挑战，包括大规模演示数据稀缺、无人机实时控制需求以及缺乏可靠的外部姿态估计模块。

Method: 使用高斯泼溅构建逼真的语言嵌入飞行模拟器，采用RRT启发的多轨迹生成专家进行无碰撞导航演示，训练轻量级端到端视觉运动策略。

Result: 在硬件飞行实验中，SINGER在未见环境和未见语言条件目标物体上表现出优越的零样本模拟到现实转移性能，平均到达查询目标率提高23.33%，视野保持率提高16.67%，碰撞减少10%。

Conclusion: SINGER成功实现了仅使用机载传感和计算的语言引导自主无人机导航，展示了强大的开放词汇导航能力。

Abstract: Large vision-language models have driven remarkable progress in
open-vocabulary robot policies, e.g., generalist robot manipulation policies,
that enable robots to complete complex tasks specified in natural language.
Despite these successes, open-vocabulary autonomous drone navigation remains an
unsolved challenge due to the scarcity of large-scale demonstrations, real-time
control demands of drones for stabilization, and lack of reliable external pose
estimation modules. In this work, we present SINGER for language-guided
autonomous drone navigation in the open world using only onboard sensing and
compute. To train robust, open-vocabulary navigation policies, SINGER leverages
three central components: (i) a photorealistic language-embedded flight
simulator with minimal sim-to-real gap using Gaussian Splatting for efficient
data generation, (ii) an RRT-inspired multi-trajectory generation expert for
collision-free navigation demonstrations, and these are used to train (iii) a
lightweight end-to-end visuomotor policy for real-time closed-loop control.
Through extensive hardware flight experiments, we demonstrate superior
zero-shot sim-to-real transfer of our policy to unseen environments and unseen
language-conditioned goal objects. When trained on ~700k-1M observation action
pairs of language conditioned visuomotor data and deployed on hardware, SINGER
outperforms a velocity-controlled semantic guidance baseline by reaching the
query 23.33% more on average, and maintains the query in the field of view
16.67% more on average, with 10% fewer collisions.

</details>


### [125] [The Case for Negative Data: From Crash Reports to Counterfactuals for Reasonable Driving](https://arxiv.org/abs/2509.18626)
*Jay Patrikar,Apoorva Sharma,Sushant Veer,Boyi Li,Sebastian Scherer,Marco Pavone*

Main category: cs.RO

TL;DR: 该论文提出了一种利用真实事故报告来改进自动驾驶决策系统的方法，通过将事故叙述转换为自我中心语言和统一的场景-动作表示，在决策时检索相关先例来评估提议动作，并通过反事实推理来改进风险边界附近的决策。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的自动驾驶系统主要在无事故数据上训练，缺乏对安全性能边界附近的指导。真实事故报告包含所需的对比证据，但难以使用，因为叙述是非结构化的、第三人称的，且与传感器视图关联性差。

Method: 将事故叙述标准化为自我中心语言，并将日志和事故转换为统一的场景-动作表示。在决策时，通过检索统一索引中的相关先例来评估提议动作；反事实扩展提出合理替代方案，为每个方案检索结果，并在决策前跨结果进行推理。

Result: 在nuScenes基准测试中，先例检索显著提高了校准度，上下文偏好动作的召回率从24%提高到53%。反事实变体在保持这些收益的同时，在风险边界附近使决策更加敏锐。

Conclusion: 该方法有效利用了事故报告来改进自动驾驶系统的决策质量，特别是在安全边界附近，通过检索先例和反事实推理提高了系统的校准度和决策准确性。

Abstract: Learning-based autonomous driving systems are trained mostly on incident-free
data, offering little guidance near safety-performance boundaries. Real crash
reports contain precisely the contrastive evidence needed, but they are hard to
use: narratives are unstructured, third-person, and poorly grounded to sensor
views. We address these challenges by normalizing crash narratives to
ego-centric language and converting both logs and crashes into a unified
scene-action representation suitable for retrieval. At decision time, our
system adjudicates proposed actions by retrieving relevant precedents from this
unified index; an agentic counterfactual extension proposes plausible
alternatives, retrieves for each, and reasons across outcomes before deciding.
On a nuScenes benchmark, precedent retrieval substantially improves
calibration, with recall on contextually preferred actions rising from 24% to
53%. The counterfactual variant preserves these gains while sharpening
decisions near risk.

</details>


### [126] [Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training](https://arxiv.org/abs/2509.18631)
*Shuo Cheng,Liqian Ma,Zhenyang Chen,Ajay Mandlekar,Caelan Garrett,Danfei Xu*

Main category: cs.RO

TL;DR: 提出了一种统一的仿真与真实世界协同训练框架，利用少量真实演示和大量仿真数据学习可泛化的机器人操作策略，通过最优传输损失实现跨域特征对齐。


<details>
  <summary>Details</summary>
Motivation: 行为克隆在机器人操作中表现出潜力，但真实世界演示成本高昂。仿真数据虽可扩展，但存在领域差距导致策略迁移困难。

Method: 采用仿真与真实世界协同训练框架，学习领域不变的任务相关特征空间。通过最优传输损失对齐观测和动作的联合分布，并使用非平衡最优传输处理数据不平衡问题。

Result: 在挑战性操作任务上验证，利用丰富仿真数据可将真实世界成功率提升高达30%，并能泛化到仅在仿真中见过的场景。

Conclusion: 该方法有效解决了仿真到真实世界的迁移问题，通过联合分布对齐实现了更好的领域适应性能。

Abstract: Behavior cloning has shown promise for robot manipulation, but real-world
demonstrations are costly to acquire at scale. While simulated data offers a
scalable alternative, particularly with advances in automated demonstration
generation, transferring policies to the real world is hampered by various
simulation and real domain gaps. In this work, we propose a unified
sim-and-real co-training framework for learning generalizable manipulation
policies that primarily leverages simulation and only requires a few real-world
demonstrations. Central to our approach is learning a domain-invariant,
task-relevant feature space. Our key insight is that aligning the joint
distributions of observations and their corresponding actions across domains
provides a richer signal than aligning observations (marginals) alone. We
achieve this by embedding an Optimal Transport (OT)-inspired loss within the
co-training framework, and extend this to an Unbalanced OT framework to handle
the imbalance between abundant simulation data and limited real-world examples.
We validate our method on challenging manipulation tasks, showing it can
leverage abundant simulation data to achieve up to a 30% improvement in the
real-world success rate and even generalize to scenarios seen only in
simulation.

</details>


### [127] [Number Adaptive Formation Flight Planning via Affine Deformable Guidance in Narrow Environments](https://arxiv.org/abs/2509.18636)
*Yuan Zhou,Jialiang Hou,Guangtong Xu,Fei Gao*

Main category: cs.RO

TL;DR: 提出了一种基于可变形虚拟结构（DVS）的无人机编队规划方法，能够在狭窄环境中处理无人机数量变化的编队维护问题


<details>
  <summary>Details</summary>
Motivation: 狭窄环境中无人机数量变化会阻碍编队规划收敛到期望配置，需要解决编队形状完整性和安全距离维护的挑战

Method: 使用Lloyd算法进行均匀分区和匈牙利算法进行分配（PAAS）来保证编队形状完整性；通过基于基元的路径搜索和非线性轨迹优化规划DVS的时空轨迹；每个智能体在DVS指导下进行分布式轨迹规划

Result: 在模拟环境中支持多达15%的无人机加入或离开编队，同时快速恢复期望编队形状；相比前沿编队规划方法，展示了更快的编队恢复能力和环境适应性

Conclusion: 真实世界实验验证了该编队规划方法的有效性和鲁棒性，能够实现自适应过渡并确保对狭窄环境的适应性

Abstract: Formation maintenance with varying number of drones in narrow environments
hinders the convergence of planning to the desired configurations. To address
this challenge, this paper proposes a formation planning method guided by
Deformable Virtual Structures (DVS) with continuous spatiotemporal
transformation. Firstly, to satisfy swarm safety distance and preserve
formation shape filling integrity for irregular formation geometries, we employ
Lloyd algorithm for uniform $\underline{PA}$rtitioning and Hungarian algorithm
for $\underline{AS}$signment (PAAS) in DVS. Subsequently, a spatiotemporal
trajectory involving DVS is planned using primitive-based path search and
nonlinear trajectory optimization. The DVS trajectory achieves adaptive
transitions with respect to a varying number of drones while ensuring
adaptability to narrow environments through affine transformation. Finally,
each agent conducts distributed trajectory planning guided by desired
spatiotemporal positions within the DVS, while incorporating collision
avoidance and dynamic feasibility requirements. Our method enables up to 15\%
of swarm numbers to join or leave in cluttered environments while rapidly
restoring the desired formation shape in simulation. Compared to cutting-edge
formation planning method, we demonstrate rapid formation recovery capacity and
environmental adaptability. Real-world experiments validate the effectiveness
and resilience of our formation planning method.

</details>


### [128] [Do You Need Proprioceptive States in Visuomotor Policies?](https://arxiv.org/abs/2509.18644)
*Juntu Zhao,Wenbo Lu,Di Zhang,Yufeng Liu,Yushen Liang,Tianluo Zhang,Yifeng Cao,Junyuan Xie,Yingdong Hu,Shengjie Wang,Junliang Guo,Dequan Wang,Yang Gao*

Main category: cs.RO

TL;DR: 提出状态无关策略，仅基于视觉观测预测动作，相比传统结合视觉和本体感知的方法，显著提升了空间泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习方法同时使用视觉观测和本体感知状态，导致策略过度依赖本体感知输入，产生对训练轨迹的过拟合和较差的空间泛化能力

Method: 构建状态无关策略，移除本体感知状态输入，仅在相对末端执行器动作空间中基于视觉观测预测动作，使用双广角腕部摄像头提供完整的任务相关视觉信息

Result: 状态无关策略在空间泛化方面显著优于基于状态的方法：在高度泛化中成功率从0%提升至85%，在水平泛化中从6%提升至64%，同时在数据效率和跨平台适应性方面也表现出优势

Conclusion: 状态无关策略通过减少对本体感知状态的依赖，有效解决了空间泛化问题，提高了实际部署的实用性

Abstract: Imitation-learning-based visuomotor policies have been widely used in robot
manipulation, where both visual observations and proprioceptive states are
typically adopted together for precise control. However, in this study, we find
that this common practice makes the policy overly reliant on the proprioceptive
state input, which causes overfitting to the training trajectories and results
in poor spatial generalization. On the contrary, we propose the State-free
Policy, removing the proprioceptive state input and predicting actions only
conditioned on visual observations. The State-free Policy is built in the
relative end-effector action space, and should ensure the full task-relevant
visual observations, here provided by dual wide-angle wrist cameras. Empirical
results demonstrate that the State-free policy achieves significantly stronger
spatial generalization than the state-based policy: in real-world tasks such as
pick-and-place, challenging shirt-folding, and complex whole-body manipulation,
spanning multiple robot embodiments, the average success rate improves from 0\%
to 85\% in height generalization and from 6\% to 64\% in horizontal
generalization. Furthermore, they also show advantages in data efficiency and
cross-embodiment adaptation, enhancing their practicality for real-world
deployment.

</details>


### [129] [SPiDR: A Simple Approach for Zero-Shot Safety in Sim-to-Real Transfer](https://arxiv.org/abs/2509.18648)
*Yarden As,Chengrui Qu,Benjamin Unger,Dongho Kang,Max van der Hart,Laixi Shi,Stelian Coros,Adam Wierman,Andreas Krause*

Main category: cs.RO

TL;DR: SPiDR是一种通过悲观域随机化实现安全sim-to-real迁移的可扩展算法，能够在存在sim-to-real差距的情况下有效保证安全性


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在现实世界部署中的安全问题，特别是sim-to-real差距带来的安全约束挑战

Method: 使用域随机化将sim-to-real差距的不确定性纳入安全约束，与现有训练管道高度兼容

Result: 在sim-to-sim基准测试和两个不同的真实机器人平台上，SPiDR在保持强性能的同时有效确保安全

Conclusion: SPiDR提供了一个具有可证明保证的安全sim-to-real迁移解决方案，解决了传统方法的局限性

Abstract: Safety remains a major concern for deploying reinforcement learning (RL) in
real-world applications. Simulators provide safe, scalable training
environments, but the inevitable sim-to-real gap introduces additional safety
concerns, as policies must satisfy constraints in real-world conditions that
differ from simulation. To address this challenge, robust safe RL techniques
offer principled methods, but are often incompatible with standard scalable
training pipelines. In contrast, domain randomization, a simple and popular
sim-to-real technique, stands out as a promising alternative, although it often
results in unsafe behaviors in practice. We present SPiDR, short for
Sim-to-real via Pessimistic Domain Randomization -- a scalable algorithm with
provable guarantees for safe sim-to-real transfer. SPiDR uses domain
randomization to incorporate the uncertainty about the sim-to-real gap into the
safety constraints, making it versatile and highly compatible with existing
training pipelines. Through extensive experiments on sim-to-sim benchmarks and
two distinct real-world robotic platforms, we demonstrate that SPiDR
effectively ensures safety despite the sim-to-real gap while maintaining strong
performance.

</details>


### [130] [Distributionally Robust Safe Motion Planning with Contextual Information](https://arxiv.org/abs/2509.18666)
*Kaizer Rahaman,Simran Kumari,Ashish R. Hota*

Main category: cs.RO

TL;DR: 提出一种基于分布鲁棒优化的碰撞避免方法，通过条件核均值嵌入在RKHS中建模障碍物未来轨迹的条件分布，构建包含上下文信息的分布不确定性集合，并将其集成到模型预测控制框架中。


<details>
  <summary>Details</summary>
Motivation: 传统碰撞避免方法往往忽略上下文信息或对分布不确定性考虑不足，导致在复杂场景中避障效果不佳。需要一种能够结合上下文信息并处理分布不确定性的鲁棒方法。

Method: 使用条件核均值嵌入将障碍物轨迹的条件分布映射到RKHS空间，构建基于经验估计的分布模糊集，在模型预测控制框架中引入分布鲁棒碰撞避免约束。

Result: 仿真结果表明，该方法在多个挑战性场景中比不考虑上下文信息和分布鲁棒性的方法具有更好的碰撞避免效果。

Conclusion: 提出的分布鲁棒方法通过有效利用上下文信息和处理分布不确定性，显著提升了碰撞避免性能，为自动驾驶等领域的运动规划提供了更可靠的解决方案。

Abstract: We present a distributionally robust approach for collision avoidance by
incorporating contextual information. Specifically, we embed the conditional
distribution of future trajectory of the obstacle conditioned on the motion of
the ego agent in a reproducing kernel Hilbert space (RKHS) via the conditional
kernel mean embedding operator. Then, we define an ambiguity set containing all
distributions whose embedding in the RKHS is within a certain distance from the
empirical estimate of conditional mean embedding learnt from past data.
Consequently, a distributionally robust collision avoidance constraint is
formulated, and included in the receding horizon based motion planning
formulation of the ego agent. Simulation results show that the proposed
approach is more successful in avoiding collision compared to approaches that
do not include contextual information and/or distributional robustness in their
formulation in several challenging scenarios.

</details>


### [131] [3D Flow Diffusion Policy: Visuomotor Policy Learning via Generating Flow in 3D Space](https://arxiv.org/abs/2509.18676)
*Sangjun Noh,Dongwoo Nam,Kangmin Kim,Geonhyup Lee,Yeonguk Yu,Raeyoung Kang,Kyoobin Lee*

Main category: cs.RO

TL;DR: 3D Flow Diffusion Policy (3D FDP) 是一个利用场景级3D流作为结构化中间表示的新框架，通过捕捉细粒度局部运动线索来学习鲁棒的视觉运动策略，在接触丰富的操作任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作方法通常依赖直接观察到动作的映射或将感知输入压缩为全局或物体中心特征，往往忽略了精确和接触丰富操作所需的局部运动线索。

Method: 提出3D FDP框架，预测采样查询点的时间轨迹，并在统一的扩散架构中基于这些交互感知流来生成动作，使操作基于局部动力学同时考虑动作的广泛场景级后果。

Result: 在MetaWorld基准测试中，3D FDP在50个任务上达到最先进性能，特别是在中等和困难设置中表现出色。在8个真实机器人任务中，在接触丰富和非抓取场景中持续优于现有基线。

Conclusion: 3D流作为学习可泛化视觉运动策略的强大结构化先验，支持开发更鲁棒和通用的机器人操作能力。

Abstract: Learning robust visuomotor policies that generalize across diverse objects
and interaction dynamics remains a central challenge in robotic manipulation.
Most existing approaches rely on direct observation-to-action mappings or
compress perceptual inputs into global or object-centric features, which often
overlook localized motion cues critical for precise and contact-rich
manipulation. We present 3D Flow Diffusion Policy (3D FDP), a novel framework
that leverages scene-level 3D flow as a structured intermediate representation
to capture fine-grained local motion cues. Our approach predicts the temporal
trajectories of sampled query points and conditions action generation on these
interaction-aware flows, implemented jointly within a unified diffusion
architecture. This design grounds manipulation in localized dynamics while
enabling the policy to reason about broader scene-level consequences of
actions. Extensive experiments on the MetaWorld benchmark show that 3D FDP
achieves state-of-the-art performance across 50 tasks, particularly excelling
on medium and hard settings. Beyond simulation, we validate our method on eight
real-robot tasks, where it consistently outperforms prior baselines in
contact-rich and non-prehensile scenarios. These results highlight 3D flow as a
powerful structural prior for learning generalizable visuomotor policies,
supporting the development of more robust and versatile robotic manipulation.
Robot demonstrations, additional results, and code can be found at
https://sites.google.com/view/3dfdp/home.

</details>


### [132] [N2M: Bridging Navigation and Manipulation by Learning Pose Preference from Rollout](https://arxiv.org/abs/2509.18671)
*Kaixin Chai,Hyunjun Lee,Joseph J. Lim*

Main category: cs.RO

TL;DR: N2M是一个过渡模块，在机器人到达任务区域后引导其到更优的初始位姿，显著提高移动操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 移动操作中，导航模块只关注到达任务区域，而不考虑下游操作策略偏好的初始位姿，导致任务成功率低。

Method: N2M模块仅依赖自我中心观测，无需全局或历史信息，具有实时环境适应能力和高视角鲁棒性。

Result: 在PnPCounterToCab任务中，成功率从基线3%提升到54%；在Toybox Handover任务中，仅用15个数据样本就能在未见环境中提供可靠预测。

Conclusion: N2M具有广泛适用性、数据效率高和泛化能力强等五大优势，显著提升了移动操作系统的性能。

Abstract: In mobile manipulation, the manipulation policy has strong preferences for
initial poses where it is executed. However, the navigation module focuses
solely on reaching the task area, without considering which initial pose is
preferable for downstream manipulation. To address this misalignment, we
introduce N2M, a transition module that guides the robot to a preferable
initial pose after reaching the task area, thereby substantially improving task
success rates. N2M features five key advantages: (1) reliance solely on
ego-centric observation without requiring global or historical information; (2)
real-time adaptation to environmental changes; (3) reliable prediction with
high viewpoint robustness; (4) broad applicability across diverse tasks,
manipulation policies, and robot hardware; and (5) remarkable data efficiency
and generalizability. We demonstrate the effectiveness of N2M through extensive
simulation and real-world experiments. In the PnPCounterToCab task, N2M
improves the averaged success rate from 3% with the reachability-based baseline
to 54%. Furthermore, in the Toybox Handover task, N2M provides reliable
predictions even in unseen environments with only 15 data samples, showing
remarkable data efficiency and generalizability.

</details>


### [133] [Proactive-reactive detection and mitigation of intermittent faults in robot swarms](https://arxiv.org/abs/2509.19246)
*Sinan Oğuz,Emanuele Garone,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: 本文提出了一种针对机器人群体中间歇性故障的主动-被动检测与缓解策略，利用自组织备份层和多路网络中的分布式共识来解决间歇性故障检测难题。


<details>
  <summary>Details</summary>
Motivation: 间歇性故障在机器人群体中频繁出现和消失，对可靠性和协调性构成重大挑战，但现有研究主要关注永久性故障。由于机器人群体网络拓扑的瞬态性和不可预测性，间歇性故障检测极为困难。

Method: 采用主动-被动策略：主动阶段，机器人在故障发生前自组织动态备份路径；被动阶段，使用单次似然比检验比较多路网络中不同路径的信息，实现早期故障检测。检测到故障后，通信以自组织方式临时重路由。

Result: 在形成控制过程中出现故障位置数据的代表性场景中验证了该方法，证明间歇性故障不会破坏期望形成的收敛，具有高故障检测准确率和低误报率。

Conclusion: 该方法首次在具有持久网络的机器人群体中有效解决了间歇性故障问题，通过自组织备份层和分布式共识实现了可靠的故障检测和缓解。

Abstract: Intermittent faults are transient errors that sporadically appear and
disappear. Although intermittent faults pose substantial challenges to
reliability and coordination, existing studies of fault tolerance in robot
swarms focus instead on permanent faults. One reason for this is that
intermittent faults are prohibitively difficult to detect in the fully
self-organized ad-hoc networks typical of robot swarms, as their network
topologies are transient and often unpredictable. However, in the recently
introduced self-organizing nervous systems (SoNS) approach, robot swarms are
able to self-organize persistent network structures for the first time, easing
the problem of detecting intermittent faults. To address intermittent faults in
robot swarms that have persistent networks, we propose a novel
proactive-reactive strategy to detection and mitigation, based on
self-organized backup layers and distributed consensus in a multiplex network.
Proactively, the robots self-organize dynamic backup paths before faults occur,
adapting to changes in the primary network topology and the robots' relative
positions. Reactively, robots use one-shot likelihood ratio tests to compare
information received along different paths in the multiplex network, enabling
early fault detection. Upon detection, communication is temporarily rerouted in
a self-organized way, until the detected fault resolves. We validate the
approach in representative scenarios of faulty positional data occurring during
formation control, demonstrating that intermittent faults are prevented from
disrupting convergence to desired formations, with high fault detection
accuracy and low rates of false positives.

</details>


### [134] [Query-Centric Diffusion Policy for Generalizable Robotic Assembly](https://arxiv.org/abs/2509.18686)
*Ziyi Xu,Haohong Lin,Shiqi Liu,Ding Zhao*

Main category: cs.RO

TL;DR: 提出Query-centric Diffusion Policy (QDP)分层框架，通过查询机制连接高层规划和底层控制，提升机器人装配任务的性能


<details>
  <summary>Details</summary>
Motivation: 机器人装配任务因零件交互复杂性和接触丰富环境中的噪声敏感性而具有挑战性，传统分层策略存在高层技能查询与底层执行不匹配的问题

Method: QDP框架使用包含物体、接触点和技能信息的查询来识别任务相关组件并指导底层策略，利用点云观测提高策略鲁棒性

Result: 在FurnitureBench仿真和真实环境实验中，QDP在技能精度和长时程成功率方面表现优异，在插入和拧螺丝任务中比无结构化查询的基线方法提升超过50%的技能成功率

Conclusion: QDP通过查询中心机制有效解决了分层策略中的不匹配问题，为构建通用机器人提供了有前景的解决方案

Abstract: The robotic assembly task poses a key challenge in building generalist robots
due to the intrinsic complexity of part interactions and the sensitivity to
noise perturbations in contact-rich settings. The assembly agent is typically
designed in a hierarchical manner: high-level multi-part reasoning and
low-level precise control. However, implementing such a hierarchical policy is
challenging in practice due to the mismatch between high-level skill queries
and low-level execution. To address this, we propose the Query-centric
Diffusion Policy (QDP), a hierarchical framework that bridges high-level
planning and low-level control by utilizing queries comprising objects, contact
points, and skill information. QDP introduces a query-centric mechanism that
identifies task-relevant components and uses them to guide low-level policies,
leveraging point cloud observations to improve the policy's robustness. We
conduct comprehensive experiments on the FurnitureBench in both simulation and
real-world settings, demonstrating improved performance in skill precision and
long-horizon success rate. In the challenging insertion and screwing tasks, QDP
improves the skill-wise success rate by over 50% compared to baselines without
structured queries.

</details>


### [135] [Learning Obstacle Avoidance using Double DQN for Quadcopter Navigation](https://arxiv.org/abs/2509.18734)
*Nishant Doshi,Amey Sutvani,Sanket Gujar*

Main category: cs.RO

TL;DR: 使用强化学习训练配备深度相机的虚拟四旋翼无人机在模拟城市环境中导航


<details>
  <summary>Details</summary>
Motivation: 自主飞行器在城市环境中面临GPS精度下降、狭窄空间和动态障碍物等挑战，需要开发可靠的避障能力

Method: 采用强化学习方法，让配备深度相机的虚拟四旋翼无人机在模拟城市环境中学习导航

Result: 论文提出了一个基于强化学习的导航框架，但具体实验结果未在摘要中提及

Conclusion: 强化学习是解决无人机在城市环境中导航挑战的有效方法

Abstract: One of the challenges faced by Autonomous Aerial Vehicles is reliable
navigation through urban environments. Factors like reduction in precision of
Global Positioning System (GPS), narrow spaces and dynamically moving obstacles
make the path planning of an aerial robot a complicated task. One of the skills
required for the agent to effectively navigate through such an environment is
to develop an ability to avoid collisions using information from onboard depth
sensors. In this paper, we propose Reinforcement Learning of a virtual
quadcopter robot agent equipped with a Depth Camera to navigate through a
simulated urban environment.

</details>


### [136] [MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning](https://arxiv.org/abs/2509.18757)
*Omar Rayyan,John Abanes,Mahmoud Hafez,Anthony Tzes,Fares Abu-Dakka*

Main category: cs.RO

TL;DR: MV-UMI框架通过整合第三人称视角与第一人称视角相机，解决了手持抓取器在模仿学习中场景上下文捕捉不足的问题，提高了机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 手持抓取器作为数据收集工具虽然直观且可扩展，但仅依赖第一人称视角手腕摄像头难以捕捉足够的场景上下文，限制了机器人操作任务的学习范围。

Method: 提出MV-UMI框架，整合第三人称视角与第一人称视角相机，减轻人类演示与机器人部署之间的领域偏移，同时保持手持数据收集设备的跨体现优势。

Result: 实验结果显示，MV-UMI框架在需要广泛场景理解的子任务中性能提升约47%（在3个任务中），证实了该方法的有效性。

Conclusion: MV-UMI框架扩展了使用手持抓取器系统可学习的可行操作任务范围，同时不损害此类系统固有的跨体现优势。

Abstract: Recent advances in imitation learning have shown great promise for developing
robust robot manipulation policies from demonstrations. However, this promise
is contingent on the availability of diverse, high-quality datasets, which are
not only challenging and costly to collect but are often constrained to a
specific robot embodiment. Portable handheld grippers have recently emerged as
intuitive and scalable alternatives to traditional robotic teleoperation
methods for data collection. However, their reliance solely on first-person
view wrist-mounted cameras often creates limitations in capturing sufficient
scene contexts. In this paper, we present MV-UMI (Multi-View Universal
Manipulation Interface), a framework that integrates a third-person perspective
with the egocentric camera to overcome this limitation. This integration
mitigates domain shifts between human demonstration and robot deployment,
preserving the cross-embodiment advantages of handheld data-collection devices.
Our experimental results, including an ablation study, demonstrate that our
MV-UMI framework improves performance in sub-tasks requiring broad scene
understanding by approximately 47% across 3 tasks, confirming the effectiveness
of our approach in expanding the range of feasible manipulation tasks that can
be learned using handheld gripper systems, without compromising the
cross-embodiment advantages inherent to such systems.

</details>


### [137] [VGGT-DP: Generalizable Robot Control via Vision Foundation Models](https://arxiv.org/abs/2509.18778)
*Shijia Ge,Yinxin Zhang,Shuzhao Xie,Weixiang Zhang,Mingcai Zhou,Zhi Wang*

Main category: cs.RO

TL;DR: VGGT-DP是一个视觉模仿学习框架，通过整合预训练3D感知模型的几何先验和本体感觉反馈，提升机器人的空间理解和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模仿学习方法主要关注策略设计，但忽视了视觉编码器的结构和能力，限制了空间理解和泛化性能。受生物视觉系统启发，需要结合视觉和本体感觉线索来实现鲁棒控制。

Method: 采用视觉几何基础Transformer作为视觉编码器，引入本体感觉引导的视觉学习策略来对齐感知与机器人内部状态。设计了帧级token重用机制来减少推理延迟，并应用随机token剪枝来增强策略鲁棒性。

Result: 在具有挑战性的MetaWorld任务上的实验表明，VGGT-DP显著优于DP和DP3等强基线方法，特别是在精度要求高和长时程场景中表现突出。

Conclusion: VGGT-DP通过整合几何先验和本体感觉反馈，有效提升了视觉模仿学习的空间理解和控制性能，为机器人操作技能学习提供了更有效的解决方案。

Abstract: Visual imitation learning frameworks allow robots to learn manipulation
skills from expert demonstrations. While existing approaches mainly focus on
policy design, they often neglect the structure and capacity of visual
encoders, limiting spatial understanding and generalization. Inspired by
biological vision systems, which rely on both visual and proprioceptive cues
for robust control, we propose VGGT-DP, a visuomotor policy framework that
integrates geometric priors from a pretrained 3D perception model with
proprioceptive feedback. We adopt the Visual Geometry Grounded Transformer
(VGGT) as the visual encoder and introduce a proprioception-guided visual
learning strategy to align perception with internal robot states, improving
spatial grounding and closed-loop control. To reduce inference latency, we
design a frame-wise token reuse mechanism that compacts multi-view tokens into
an efficient spatial representation. We further apply random token pruning to
enhance policy robustness and reduce overfitting. Experiments on challenging
MetaWorld tasks show that VGGT-DP significantly outperforms strong baselines
such as DP and DP3, particularly in precision-critical and long-horizon
scenarios.

</details>


### [138] [Human-Interpretable Uncertainty Explanations for Point Cloud Registration](https://arxiv.org/abs/2509.18786)
*Johannes A. Gaus,Loris Schneider,Yitian Shi,Jongseok Lee,Rania Rayyes,Rudolph Triebel*

Main category: cs.RO

TL;DR: 提出GP-CA方法解决点云配准中的不确定性，通过主动学习量化并解释配准误差来源，在多个数据集和真实机器人实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法如ICP在传感器噪声、位姿估计误差和部分重叠等不确定性条件下容易失败，需要一种能量化并解释配准不确定性的方法。

Method: 开发高斯过程概念归因(GP-CA)方法，利用主动学习发现新的不确定性来源，通过查询信息丰富的实例来改进配准性能。

Result: 在三个公开数据集和真实机器人实验中验证，GP-CA在运行时间、样本效率和准确性方面优于现有方法，并能实现有效的故障恢复行为。

Conclusion: GP-CA方法能够提供鲁棒的点云配准，通过解释不确定性来源增强机器人感知的可靠性，具有实际应用价值。

Abstract: In this paper, we address the point cloud registration problem, where
well-known methods like ICP fail under uncertainty arising from sensor noise,
pose-estimation errors, and partial overlap due to occlusion. We develop a
novel approach, Gaussian Process Concept Attribution (GP-CA), which not only
quantifies registration uncertainty but also explains it by attributing
uncertainty to well-known sources of errors in registration problems. Our
approach leverages active learning to discover new uncertainty sources in the
wild by querying informative instances. We validate GP-CA on three publicly
available datasets and in our real-world robot experiment. Extensive ablations
substantiate our design choices. Our approach outperforms other
state-of-the-art methods in terms of runtime, high sample-efficiency with
active learning, and high accuracy. Our real-world experiment clearly
demonstrates its applicability. Our video also demonstrates that GP-CA enables
effective failure-recovery behaviors, yielding more robust robotic perception.

</details>


### [139] [Application Management in C-ITS: Orchestrating Demand-Driven Deployments and Reconfigurations](https://arxiv.org/abs/2509.18793)
*Lukas Zanger,Bastian Lampe,Lennart Reiher,Lutz Eckstein*

Main category: cs.RO

TL;DR: 本文提出了一种基于Kubernetes的需求驱动应用管理方法，用于解决大规模协作智能交通系统中动态环境下的应用编排挑战。


<details>
  <summary>Details</summary>
Motivation: 随着车辆自动化和互联程度的提高，协作智能交通系统需要高效的云原生技术来管理动态环境中的应用，但现有方法在资源利用效率方面存在不足。

Method: 开发了一个基于Kubernetes和ROS 2的应用管理框架，通过需求驱动的自动化流程（部署、重配置、更新、升级和扩展微服务）来动态协调不同的服务需求。

Result: 该方法在集体环境感知用例中得到验证，能够有效减少计算资源消耗和网络流量，并支持动态处理变化和新需求。

Conclusion: 提出的需求驱动应用管理框架为大规模C-ITS提供了可行的解决方案，通过云原生技术实现了高效的应用编排和资源优化。

Abstract: Vehicles are becoming increasingly automated and interconnected, enabling the
formation of cooperative intelligent transport systems (C-ITS) and the use of
offboard services. As a result, cloud-native techniques, such as microservices
and container orchestration, play an increasingly important role in their
operation. However, orchestrating applications in a large-scale C-ITS poses
unique challenges due to the dynamic nature of the environment and the need for
efficient resource utilization. In this paper, we present a demand-driven
application management approach that leverages cloud-native techniques -
specifically Kubernetes - to address these challenges. Taking into account the
demands originating from different entities within the C-ITS, the approach
enables the automation of processes, such as deployment, reconfiguration,
update, upgrade, and scaling of microservices. Executing these processes on
demand can, for example, reduce computing resource consumption and network
traffic. A demand may include a request for provisioning an external supporting
service, such as a collective environment model. The approach handles changing
and new demands by dynamically reconciling them through our proposed
application management framework built on Kubernetes and the Robot Operating
System (ROS 2). We demonstrate the operation of our framework in the C-ITS use
case of collective environment perception and make the source code of the
prototypical framework publicly available at
https://github.com/ika-rwth-aachen/application_manager .

</details>


### [140] [DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation](https://arxiv.org/abs/2509.18830)
*Suzannah Wistreich,Baiyu Shi,Stephen Tian,Samuel Clarke,Michael Nath,Chengyi Xu,Zhenan Bao,Jiajun Wu*

Main category: cs.RO

TL;DR: DexSkin是一种柔软、可适应的电容式电子皮肤，能够实现敏感、局部化和可校准的触觉感知，可用于机器人灵巧操作任务的学习。


<details>
  <summary>Details</summary>
Motivation: 人类皮肤提供丰富的触觉感知流，能够在大的曲面区域定位有意和无意的接触事件。为灵巧机器人操作系统复制这些触觉感知能力仍然是一个长期挑战。

Method: 开发DexSkin软性电容电子皮肤，可定制到不同几何形状，并在平行夹爪手指上实现几乎整个手指表面的触觉覆盖，通过示范学习和在线强化学习框架进行评估。

Result: DexSkin在需要整个手指表面感知覆盖的挑战性操作任务中表现有效，如手中重新定向物体和将弹性带缠绕在盒子上，并且能够实现传感器实例间的模型迁移。

Conclusion: DexSkin适用于学习现实世界中接触丰富的操作任务，具有实用性和适用性。

Abstract: Human skin provides a rich tactile sensing stream, localizing intentional and
unintentional contact events over a large and contoured region. Replicating
these tactile sensing capabilities for dexterous robotic manipulation systems
remains a longstanding challenge. In this work, we take a step towards this
goal by introducing DexSkin. DexSkin is a soft, conformable capacitive
electronic skin that enables sensitive, localized, and calibratable tactile
sensing, and can be tailored to varying geometries. We demonstrate its efficacy
for learning downstream robotic manipulation by sensorizing a pair of parallel
jaw gripper fingers, providing tactile coverage across almost the entire finger
surfaces. We empirically evaluate DexSkin's capabilities in learning
challenging manipulation tasks that require sensing coverage across the entire
surface of the fingers, such as reorienting objects in hand and wrapping
elastic bands around boxes, in a learning-from-demonstration framework. We then
show that, critically for data-driven approaches, DexSkin can be calibrated to
enable model transfer across sensor instances, and demonstrate its
applicability to online reinforcement learning on real robots. Our results
highlight DexSkin's suitability and practicality for learning real-world,
contact-rich manipulation. Please see our project webpage for videos and
visualizations: https://dex-skin.github.io/.

</details>


### [141] [Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation](https://arxiv.org/abs/2509.18865)
*Masato Kobayashi,Thanpimon Buamanee*

Main category: cs.RO

TL;DR: Bi-VLA是一个基于双边控制的模仿学习框架，通过视觉-语言融合实现多任务动作生成，解决了传统双边控制方法只能处理单一任务的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统双边控制方法虽然利用关节角度、速度、扭矩和视觉信息实现精确操作，但需要为每个任务构建特定模型，限制了通用性。Bi-VLA旨在克服这一限制，实现单一模型处理多个任务。

Method: Bi-VLA结合了领导者-跟随者双边控制的机器人关节角度、速度和扭矩数据，通过SigLIP和FiLM-based融合技术整合视觉特征和自然语言指令。

Result: 真实机器人实验表明，Bi-VLA能够成功解读视觉-语言组合，相比传统双边控制模仿学习方法显著提高了任务成功率。

Conclusion: Bi-VLA解决了先前双边方法只能处理单一任务的限制，实证表明视觉和语言的结合显著增强了系统的通用性，在真实世界任务中表现出有效性。

Abstract: We propose Bilateral Control-Based Imitation Learning via Vision-Language
Fusion for Action Generation (Bi-VLA), a novel framework that extends bilateral
control-based imitation learning to handle more than one task within a single
model. Conventional bilateral control methods exploit joint angle, velocity,
torque, and vision for precise manipulation but require task-specific models,
limiting their generality. Bi-VLA overcomes this limitation by utilizing robot
joint angle, velocity, and torque data from leader-follower bilateral control
with visual features and natural language instructions through SigLIP and
FiLM-based fusion. We validated Bi-VLA on two task types: one requiring
supplementary language cues and another distinguishable solely by vision.
Real-robot experiments showed that Bi-VLA successfully interprets
vision-language combinations and improves task success rates compared to
conventional bilateral control-based imitation learning. Our Bi-VLA addresses
the single-task limitation of prior bilateral approaches and provides empirical
evidence that combining vision and language significantly enhances versatility.
Experimental results validate the effectiveness of Bi-VLA in real-world tasks.
For additional material, please visit the website:
https://mertcookimg.github.io/bi-vla/

</details>


### [142] [Lang2Morph: Language-Driven Morphological Design of Robotic Hands](https://arxiv.org/abs/2509.18937)
*Yanyuan Qiao,Kieran Gilday,Yutong Xie,Josie Hughes*

Main category: cs.RO

TL;DR: Lang2Morph是一个基于大语言模型的机器人手形态设计框架，能够将自然语言任务描述转化为可3D打印的特定任务形态结构。


<details>
  <summary>Details</summary>
Motivation: 传统机器人手设计依赖专家启发式和手动调参，自动化方法计算密集且依赖仿真。大语言模型具有广泛的人类-物体交互知识和强大生成能力，为零样本设计推理提供了新途径。

Method: Lang2Morph包含两个主要模块：(i)形态设计：将任务映射为语义标签、结构语法和OPH兼容参数；(ii)选择与优化：基于语义对齐和尺寸兼容性评估设计候选，并在需要时应用LLM引导的优化。

Result: 在不同任务上的评估表明，该方法能够生成多样化且与任务相关的形态结构。

Conclusion: 这是首个基于LLM的任务条件化机器人手设计框架，展示了语言驱动设计方法的可行性。

Abstract: Designing robotic hand morphologies for diverse manipulation tasks requires
balancing dexterity, manufacturability, and task-specific functionality. While
open-source frameworks and parametric tools support reproducible design, they
still rely on expert heuristics and manual tuning. Automated methods using
optimization are often compute-intensive, simulation-dependent, and rarely
target dexterous hands. Large language models (LLMs), with their broad
knowledge of human-object interactions and strong generative capabilities,
offer a promising alternative for zero-shot design reasoning. In this paper, we
present Lang2Morph, a language-driven pipeline for robotic hand design. It uses
LLMs to translate natural-language task descriptions into symbolic structures
and OPH-compatible parameters, enabling 3D-printable task-specific
morphologies. The pipeline consists of: (i) Morphology Design, which maps tasks
into semantic tags, structural grammars, and OPH-compatible parameters; and
(ii) Selection and Refinement, which evaluates design candidates based on
semantic alignment and size compatibility, and optionally applies LLM-guided
refinement when needed. We evaluate Lang2Morph across varied tasks, and results
show that our approach can generate diverse, task-relevant morphologies. To our
knowledge, this is the first attempt to develop an LLM-based framework for
task-conditioned robotic hand design.

</details>


### [143] [Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations](https://arxiv.org/abs/2509.18953)
*Hanqing Liu,Jiahuan Long,Junqi Wu,Jiacheng Hou,Huili Tang,Tingsong Jiang,Weien Zhou,Wen Yao*

Main category: cs.RO

TL;DR: Eva-VLA是首个系统评估视觉-语言-动作模型在物理变化下鲁棒性的统一框架，将离散物理变化转化为连续优化问题，发现现有模型在真实世界部署中存在严重脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作中表现出潜力，但其对真实世界物理变化的鲁棒性尚未得到充分探索，需要系统评估框架来弥合实验室成功与部署准备之间的差距。

Method: 将真实世界变化分解为三个关键领域：物体3D变换、光照变化和对抗性补丁；引入连续黑盒优化框架将离散物理变化转化为参数优化问题，系统探索最坏情况场景。

Result: 在多个基准测试中对最先进的OpenVLA模型进行广泛实验，发现所有变化类型都导致超过60%的失败率，物体变换在长时域任务中导致高达97.8%的失败率。

Conclusion: 研究结果揭示了受控实验室成功与不可预测部署准备之间的关键差距，Eva-VLA框架为增强VLA基机器人操作模型对抗真实世界部署挑战提供了实用途径。

Abstract: Vision-Language-Action (VLA) models have emerged as promising solutions for
robotic manipulation, yet their robustness to real-world physical variations
remains critically underexplored. To bridge this gap, we propose Eva-VLA, the
first unified framework that systematically evaluates the robustness of VLA
models by transforming discrete physical variations into continuous
optimization problems. However, comprehensively assessing VLA robustness
presents two key challenges: (1) how to systematically characterize diverse
physical variations encountered in real-world deployments while maintaining
evaluation reproducibility, and (2) how to discover worst-case scenarios
without prohibitive real-world data collection costs efficiently. To address
the first challenge, we decompose real-world variations into three critical
domains: object 3D transformations that affect spatial reasoning, illumination
variations that challenge visual perception, and adversarial patches that
disrupt scene understanding. For the second challenge, we introduce a
continuous black-box optimization framework that transforms discrete physical
variations into parameter optimization, enabling systematic exploration of
worst-case scenarios. Extensive experiments on state-of-the-art OpenVLA models
across multiple benchmarks reveal alarming vulnerabilities: all variation types
trigger failure rates exceeding 60%, with object transformations causing up to
97.8% failure in long-horizon tasks. Our findings expose critical gaps between
controlled laboratory success and unpredictable deployment readiness, while the
Eva-VLA framework provides a practical pathway for hardening VLA-based robotic
manipulation models against real-world deployment challenges.

</details>


### [144] [Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation](https://arxiv.org/abs/2509.18954)
*Minoo Dolatabadi,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.RO

TL;DR: 提出了一种基于深度学习的框架，用于在ICP匹配前估计注册误差协方差，无需参考地图即可提供可靠的6自由度误差协方差估计，从而提升LiDAR定位和SLAM的精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统ICP算法在特征缺失环境和动态场景中容易产生误差，现有方法要么依赖预建地图，要么只能进行二元分类，无法准确建模不确定性。

Method: 采用数据驱动的深度学习框架，在ICP匹配前预测注册误差协方差，将每个LiDAR扫描与6自由度误差协方差估计关联，实现与卡尔曼滤波的无缝集成。

Result: 在KITTI数据集上的大量实验表明，该方法能准确预测协方差，应用于预建地图定位或SLAM时，能减少定位误差并提高鲁棒性。

Conclusion: 该框架为ICP提供了可靠的误差协方差估计，显著提升了LiDAR定位系统的性能和可靠性。

Abstract: LiDAR-based localization and SLAM often rely on iterative matching
algorithms, particularly the Iterative Closest Point (ICP) algorithm, to align
sensor data with pre-existing maps or previous scans. However, ICP is prone to
errors in featureless environments and dynamic scenes, leading to inaccurate
pose estimation. Accurately predicting the uncertainty associated with ICP is
crucial for robust state estimation but remains challenging, as existing
approaches often rely on handcrafted models or simplified assumptions.
Moreover, a few deep learning-based methods for localizability estimation
either depend on a pre-built map, which may not always be available, or provide
a binary classification of localizable versus non-localizable, which fails to
properly model uncertainty. In this work, we propose a data-driven framework
that leverages deep learning to estimate the registration error covariance of
ICP before matching, even in the absence of a reference map. By associating
each LiDAR scan with a reliable 6-DoF error covariance estimate, our method
enables seamless integration of ICP within Kalman filtering, enhancing
localization accuracy and robustness. Extensive experiments on the KITTI
dataset demonstrate the effectiveness of our approach, showing that it
accurately predicts covariance and, when applied to localization using a
pre-built map or SLAM, reduces localization errors and improves robustness.

</details>


### [145] [Category-Level Object Shape and Pose Estimation in Less Than a Millisecond](https://arxiv.org/abs/2509.18979)
*Lorenzo Shaikewitz,Tim Nguyen,Luca Carlone*

Main category: cs.RO

TL;DR: 提出一种快速的物体形状和姿态估计局部求解器，仅需类别级先验知识，并能提供全局最优性证明。通过RGB-D图像检测语义关键点，使用线性主动形状模型表示未知形状，通过最大后验优化同时求解位置、方向和形状。


<details>
  <summary>Details</summary>
Motivation: 物体形状和姿态估计是机器人学的基础问题，支持从操作到场景理解和导航等任务。需要开发快速且能保证全局最优性的求解方法。

Method: 使用学习前端检测类别级语义关键点，用线性主动形状模型表示物体形状，构建最大后验优化问题，通过自洽场迭代求解特征值问题，每次迭代仅需计算4×4矩阵的最小特征值-特征向量对。

Result: 求解器每次迭代约需100微秒，能快速剔除异常值。在合成数据、真实场景、公开数据集和无人机跟踪场景中进行了测试验证。

Conclusion: 该方法实现了高效的形状和姿态估计，提供了简单的全局最优性证明，在多种应用场景中表现良好。

Abstract: Object shape and pose estimation is a foundational robotics problem,
supporting tasks from manipulation to scene understanding and navigation. We
present a fast local solver for shape and pose estimation which requires only
category-level object priors and admits an efficient certificate of global
optimality. Given an RGB-D image of an object, we use a learned front-end to
detect sparse, category-level semantic keypoints on the target object. We
represent the target object's unknown shape using a linear active shape model
and pose a maximum a posteriori optimization problem to solve for position,
orientation, and shape simultaneously. Expressed in unit quaternions, this
problem admits first-order optimality conditions in the form of an eigenvalue
problem with eigenvector nonlinearities. Our primary contribution is to solve
this problem efficiently with self-consistent field iteration, which only
requires computing a 4-by-4 matrix and finding its minimum eigenvalue-vector
pair at each iterate. Solving a linear system for the corresponding Lagrange
multipliers gives a simple global optimality certificate. One iteration of our
solver runs in about 100 microseconds, enabling fast outlier rejection. We test
our method on synthetic data and a variety of real-world settings, including
two public datasets and a drone tracking scenario. Code is released at
https://github.com/MIT-SPARK/Fast-ShapeAndPose.

</details>


### [146] [Pure Vision Language Action (VLA) Models: A Comprehensive Survey](https://arxiv.org/abs/2509.19012)
*Dapeng Zhang,Jin Sun,Chenghui Hu,Xiaoyan Wu,Zhenlong Yuan,Rui Zhou,Fei Shen,Qingguo Zhou*

Main category: cs.RO

TL;DR: 这篇综述论文系统性地回顾了视觉语言动作（VLA）模型的研究进展，提供了分类框架并分析了300多项相关研究，探讨了VLA在通用机器人领域的应用前景和挑战。


<details>
  <summary>Details</summary>
Motivation: VLA模型的出现标志着从传统策略控制向通用机器人的范式转变，将视觉语言模型从被动序列生成器转变为复杂动态环境中主动决策和操作的智能体。

Method: 论文采用系统综述方法，将VLA方法分类为自回归、扩散、强化学习、混合和专门方法等范式，并详细分析其动机、核心策略和实现方式。

Result: 提供了VLA领域的全面分析，包括基础数据集、基准测试和仿真平台的介绍，为研究者提供了该领域的系统认知框架。

Conclusion: 论文指出了VLA模型发展的关键挑战和未来方向，强调了构建可扩展、通用VLA方法的机会和挑战，将推动通用机器人研究的发展。

Abstract: The emergence of Vision Language Action (VLA) models marks a paradigm shift
from traditional policy-based control to generalized robotics, reframing Vision
Language Models (VLMs) from passive sequence generators into active agents for
manipulation and decision-making in complex, dynamic environments. This survey
delves into advanced VLA methods, aiming to provide a clear taxonomy and a
systematic, comprehensive review of existing research. It presents a
comprehensive analysis of VLA applications across different scenarios and
classifies VLA approaches into several paradigms: autoregression-based,
diffusion-based, reinforcement-based, hybrid, and specialized methods; while
examining their motivations, core strategies, and implementations in detail. In
addition, foundational datasets, benchmarks, and simulation platforms are
introduced. Building on the current VLA landscape, the review further proposes
perspectives on key challenges and future directions to advance research in VLA
models and generalizable robotics. By synthesizing insights from over three
hundred recent studies, this survey maps the contours of this rapidly evolving
field and highlights the opportunities and challenges that will shape the
development of scalable, general-purpose VLA methods.

</details>


### [147] [Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion](https://arxiv.org/abs/2509.19023)
*Shuai Liu,Meng Cheng Lau*

Main category: cs.RO

TL;DR: ROM-GRL是一个两阶段强化学习框架，用于人形机器人行走，无需运动捕捉数据或复杂奖励设计。通过简化模型引导高维策略训练，实现稳定自然的步态。


<details>
  <summary>Details</summary>
Motivation: 解决传统人形机器人行走方法需要大量运动捕捉数据或复杂奖励设计的问题，探索一种无需人类示范就能生成自然步态的方法。

Method: 第一阶段：使用PPO训练4自由度简化模型生成能量高效步态模板；第二阶段：使用SAC加对抗判别器训练全身策略，确保步态特征分布与简化模型一致。

Result: 在1m/s和4m/s速度下，ROM-GRL产生稳定对称的步态，跟踪误差显著低于纯奖励基线方法。

Conclusion: ROM-GRL通过简化模型引导填补了纯奖励方法和模仿学习方法之间的空白，实现了无需人类示范的多样化、自然化人形行为。

Abstract: We introduce Reduced-Order Model-Guided Reinforcement Learning (ROM-GRL), a
two-stage reinforcement learning framework for humanoid walking that requires
no motion capture data or elaborate reward shaping. In the first stage, a
compact 4-DOF (four-degree-of-freedom) reduced-order model (ROM) is trained via
Proximal Policy Optimization. This generates energy-efficient gait templates.
In the second stage, those dynamically consistent trajectories guide a
full-body policy trained with Soft Actor--Critic augmented by an adversarial
discriminator, ensuring the student's five-dimensional gait feature
distribution matches the ROM's demonstrations. Experiments at 1
meter-per-second and 4 meter-per-second show that ROM-GRL produces stable,
symmetric gaits with substantially lower tracking error than a pure-reward
baseline. By distilling lightweight ROM guidance into high-dimensional
policies, ROM-GRL bridges the gap between reward-only and imitation-based
locomotion methods, enabling versatile, naturalistic humanoid behaviors without
any human demonstrations.

</details>


### [148] [TacEva: A Performance Evaluation Framework For Vision-Based Tactile Sensors](https://arxiv.org/abs/2509.19037)
*Qingzheng Cong,Steven Oh,Wen Fan,Shan Luo,Kaspar Althoefer,Dandan Zhang*

Main category: cs.RO

TL;DR: 本文提出了TacEva框架，用于对视觉触觉传感器进行标准化性能评估，解决了现有VBTS因参数差异导致的性能比较困难问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉触觉传感器在传感机制、结构尺寸等参数上存在差异，导致性能差异显著，缺乏标准化评估指标，难以针对特定任务进行选择和优化。

Method: 开发了TacEva评估框架，定义了一套性能指标来捕捉典型应用场景中的关键特征，并为每个指标设计了结构化的实验流程以确保一致性和可重复性。

Result: 该框架应用于多种不同传感机制的VBTS，结果表明能够对每种设计进行全面评估，并为每个性能维度提供定量指标。

Conclusion: TacEva框架使研究人员能够基于任务需求预先选择最合适的VBTS，同时为VBTS设计的优化提供性能指导见解。

Abstract: Vision-Based Tactile Sensors (VBTSs) are widely used in robotic tasks because
of the high spatial resolution they offer and their relatively low
manufacturing costs. However, variations in their sensing mechanisms,
structural dimension, and other parameters lead to significant performance
disparities between existing VBTSs. This makes it challenging to optimize them
for specific tasks, as both the initial choice and subsequent fine-tuning are
hindered by the lack of standardized metrics. To address this issue, TacEva is
introduced as a comprehensive evaluation framework for the quantitative
analysis of VBTS performance. The framework defines a set of performance
metrics that capture key characteristics in typical application scenarios. For
each metric, a structured experimental pipeline is designed to ensure
consistent and repeatable quantification. The framework is applied to multiple
VBTSs with distinct sensing mechanisms, and the results demonstrate its ability
to provide a thorough evaluation of each design and quantitative indicators for
each performance dimension. This enables researchers to pre-select the most
appropriate VBTS on a task by task basis, while also offering
performance-guided insights into the optimization of VBTS design. A list of
existing VBTS evaluation methods and additional evaluations can be found on our
website: https://stevenoh2003.github.io/TacEva/

</details>


### [149] [ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation](https://arxiv.org/abs/2509.19047)
*Geonhyup Lee,Yeongjin Lee,Kangmin Kim,Seongju Lee,Sangjun Noh,Seunghyeok Back,Kyoobin Lee*

Main category: cs.RO

TL;DR: 提出了ManipForce手持系统来采集高频力扭矩和RGB数据，并开发了频率感知多模态变换器(FMT)用于接触丰富的操作任务，在六个真实任务中达到83%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 接触丰富的操作任务需要精确控制交互力，但现有的模仿学习方法主要依赖视觉演示，缺乏力扭矩数据。

Method: 使用ManipForce系统采集多模态数据，开发FMT模型通过频率感知嵌入和双向交叉注意力融合异步RGB和力扭矩信号，基于变换器扩散策略。

Result: 在齿轮装配、盒子翻转、电池插入等六个任务中，FMT达到83%的平均成功率，显著优于仅RGB的基线方法。

Conclusion: 高频力扭矩数据和跨模态集成能显著提升策略性能，特别是在需要高精度和稳定接触的任务中。

Abstract: Contact-rich manipulation tasks such as precision assembly require precise
control of interaction forces, yet existing imitation learning methods rely
mainly on vision-only demonstrations. We propose ManipForce, a handheld system
designed to capture high-frequency force-torque (F/T) and RGB data during
natural human demonstrations for contact-rich manipulation. Building on these
demonstrations, we introduce the Frequency-Aware Multimodal Transformer (FMT).
FMT encodes asynchronous RGB and F/T signals using frequency- and
modality-aware embeddings and fuses them via bi-directional cross-attention
within a transformer diffusion policy. Through extensive experiments on six
real-world contact-rich manipulation tasks - such as gear assembly, box
flipping, and battery insertion - FMT trained on ManipForce demonstrations
achieves robust performance with an average success rate of 83% across all
tasks, substantially outperforming RGB-only baselines. Ablation and
sampling-frequency analyses further confirm that incorporating high-frequency
F/T data and cross-modal integration improves policy performance, especially in
tasks demanding high precision and stable contact.

</details>


### [150] [SlicerROS2: A Research and Development Module for Image-Guided Robotic Interventions](https://arxiv.org/abs/2509.19076)
*Laura Connolly,Aravind S. Kumar,Kapi Ketan Mehta,Lidia Al-Zogbi,Peter Kazanzides,Parvin Mousavi,Gabor Fichtinger,Axel Krieger,Junichi Tokuda,Russell H. Taylor,Simon Leonard,Anton Deguet*

Main category: cs.RO

TL;DR: SlicerROS2是一个结合3D Slicer和ROS的软件模块，用于医学机器人研究的标准集成方法。本文介绍了其重新设计后的新架构以及四个应用案例。


<details>
  <summary>Details</summary>
Motivation: 为医学机器人研究提供一个标准化的集成方法，将3D Slicer的医学影像功能与ROS的机器人控制能力相结合。

Method: 重新设计和重写SlicerROS2模块，提高模块化程度，提供对底层功能的访问，支持3D Slicer的Python API，并改进数据传输协议。

Result: 开发了四个应用案例，在真实的图像引导机器人场景中展示了SlicerROS2的核心功能。

Conclusion: SlicerROS2的新设计为医学机器人研究提供了更强大和灵活的工具，成功展示了在图像引导机器人干预中的实际应用价值。

Abstract: Image-guided robotic interventions involve the use of medical imaging in
tandem with robotics. SlicerROS2 is a software module that combines 3D Slicer
and robot operating system (ROS) in pursuit of a standard integration approach
for medical robotics research. The first release of SlicerROS2 demonstrated the
feasibility of using the C++ API from 3D Slicer and ROS to load and visualize
robots in real time. Since this initial release, we've rewritten and redesigned
the module to offer greater modularity, access to low-level features, access to
3D Slicer's Python API, and better data transfer protocols. In this paper, we
introduce this new design as well as four applications that leverage the core
functionalities of SlicerROS2 in realistic image-guided robotics scenarios.

</details>


### [151] [World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation](https://arxiv.org/abs/2509.19080)
*Zhennan Jiang,Kai Liu,Yuxin Qin,Shuai Tian,Yupeng Zheng,Mingcai Zhou,Chao Yu,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: World4RL是一个利用扩散模型作为高保真模拟器的框架，用于在想象环境中优化预训练的机器人操作策略，避免真实世界交互的成本和风险。


<details>
  <summary>Details</summary>
Motivation: 机器人操作策略通常通过模仿学习初始化，但受限于专家数据的稀缺性和覆盖范围。强化学习可以优化策略，但真实机器人训练成本高且不安全，而模拟器训练存在仿真到现实的差距。

Method: 提出World4RL框架，预训练扩散世界模型捕捉多任务数据集中的多样化动态，在冻结的世界模型中完全优化策略。设计了针对机器人操作的双热动作编码方案，并采用扩散骨干网络提高建模保真度。

Result: 广泛的仿真和真实世界实验表明，World4RL提供高保真环境建模，实现一致的策略优化，相比模仿学习和其他基线方法显著提高成功率。

Conclusion: World4RL框架成功地将扩散模型世界模型与策略优化相结合，为机器人操作提供了一种高效且安全的策略优化方法。

Abstract: Robotic manipulation policies are commonly initialized through imitation
learning, but their performance is limited by the scarcity and narrow coverage
of expert data. Reinforcement learning can refine polices to alleviate this
limitation, yet real-robot training is costly and unsafe, while training in
simulators suffers from the sim-to-real gap. Recent advances in generative
models have demonstrated remarkable capabilities in real-world simulation, with
diffusion models in particular excelling at generation. This raises the
question of how diffusion model-based world models can be combined to enhance
pre-trained policies in robotic manipulation. In this work, we propose
World4RL, a framework that employs diffusion-based world models as
high-fidelity simulators to refine pre-trained policies entirely in imagined
environments for robotic manipulation. Unlike prior works that primarily employ
world models for planning, our framework enables direct end-to-end policy
optimization. World4RL is designed around two principles: pre-training a
diffusion world model that captures diverse dynamics on multi-task datasets and
refining policies entirely within a frozen world model to avoid online
real-world interactions. We further design a two-hot action encoding scheme
tailored for robotic manipulation and adopt diffusion backbones to improve
modeling fidelity. Extensive simulation and real-world experiments demonstrate
that World4RL provides high-fidelity environment modeling and enables
consistent policy refinement, yielding significantly higher success rates
compared to imitation learning and other baselines. More visualization results
are available at https://world4rl.github.io/.

</details>


### [152] [FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.19102)
*Hongli Xu,Lei Zhang,Xiaoyue Hu,Boyang Zhong,Kaixin Bai,Zoltán-Csaba Márton,Zhenshan Bing,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: FunCanon框架将长时程操作任务分解为动作块序列，通过功能对象规范化实现跨类别泛化和行为重用


<details>
  <summary>Details</summary>
Motivation: 解决端到端演示学习导致的任务特定策略泛化能力差的问题，实现可组合和可重用的机器人技能

Method: 将任务分解为动作块（执行者-动词-对象），通过大视觉语言模型进行功能对象规范化，使用FuncDiffuser扩散策略学习

Result: 在仿真和真实世界基准测试中展示了类别级泛化、跨任务行为重用和稳健的sim2real部署

Conclusion: 功能规范化为复杂操作领域的可扩展模仿学习提供了强归纳偏置

Abstract: General-purpose robotic skills from end-to-end demonstrations often leads to
task-specific policies that fail to generalize beyond the training
distribution. Therefore, we introduce FunCanon, a framework that converts
long-horizon manipulation tasks into sequences of action chunks, each defined
by an actor, verb, and object. These chunks focus policy learning on the
actions themselves, rather than isolated tasks, enabling compositionality and
reuse. To make policies pose-aware and category-general, we perform functional
object canonicalization for functional alignment and automatic manipulation
trajectory transfer, mapping objects into shared functional frames using
affordance cues from large vision language models. An object centric and action
centric diffusion policy FuncDiffuser trained on this aligned data naturally
respects object affordances and poses, simplifying learning and improving
generalization ability. Experiments on simulated and real-world benchmarks
demonstrate category-level generalization, cross-task behavior reuse, and
robust sim2real deployment, showing that functional canonicalization provides a
strong inductive bias for scalable imitation learning in complex manipulation
domains. Details of the demo and supplemental material are available on our
project website https://sites.google.com/view/funcanon.

</details>


### [153] [Spectral Signature Mapping from RGB Imagery for Terrain-Aware Navigation](https://arxiv.org/abs/2509.19105)
*Sarvesh Prajapati,Ananya Trivedi,Nathaniel Hanson,Bruce Maxwell,Taskin Padir*

Main category: cs.RO

TL;DR: RS-Net是一个深度神经网络，能够从RGB图像预测光谱特征，从而获取地形材质信息，用于机器人户外导航中的地形分类和摩擦系数估计。


<details>
  <summary>Details</summary>
Motivation: 户外导航需要准确预测机器人与地形的物理交互。现有方法依赖几何或语义标签，但无法区分视觉相似但材质不同的表面。光谱传感能提供材质信息，但受限于硬件成本和处理复杂度。

Method: 提出RS-Net神经网络，从RGB图像块预测光谱特征，映射到地形标签和摩擦系数。将地形分类集成到基于采样的运动规划器，摩擦估计集成到基于接触力的MPC控制器。

Result: 开发了一个框架，在训练时学习任务相关的物理属性，测试时仅需RGB传感。代码已开源。

Conclusion: RS-Net填补了RGB传感可访问性与光谱数据丰富材质信息之间的差距，为机器人户外导航提供了实用的材质感知解决方案。

Abstract: Successful navigation in outdoor environments requires accurate prediction of
the physical interactions between the robot and the terrain. To this end,
several methods rely on geometric or semantic labels to classify traversable
surfaces. However, such labels cannot distinguish visually similar surfaces
that differ in material properties. Spectral sensors enable inference of
material composition from surface reflectance measured across multiple
wavelength bands. Although spectral sensing is gaining traction in robotics,
widespread deployment remains constrained by the need for custom hardware
integration, high sensor costs, and compute-intensive processing pipelines. In
this paper, we present RGB Image to Spectral Signature Neural Network (RS-Net),
a deep neural network designed to bridge the gap between the accessibility of
RGB sensing and the rich material information provided by spectral data. RS-Net
predicts spectral signatures from RGB patches, which we map to terrain labels
and friction coefficients. The resulting terrain classifications are integrated
into a sampling-based motion planner for a wheeled robot operating in outdoor
environments. Likewise, the friction estimates are incorporated into a
contact-force-based MPC for a quadruped robot navigating slippery surfaces.
Thus, we introduce a framework that learns the task-relevant physical property
once during training and thereafter relies solely on RGB sensing at test time.
The code is available at https://github.com/prajapatisarvesh/RS-Net.

</details>


### [154] [BiGraspFormer: End-to-End Bimanual Grasp Transformer](https://arxiv.org/abs/2509.19142)
*Kangmin Kim,Seunghyeok Back,Geonhyup Lee,Sangbeom Lee,Sangjun Noh,Kyoobin Lee*

Main category: cs.RO

TL;DR: BiGraspFormer是一个统一的端到端Transformer框架，直接从物体点云生成协调的双臂抓取，解决了现有方法中协调性差、碰撞风险和力分布不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的双臂抓取方法要么只关注单臂抓取，要么采用分离的抓取生成和双臂评估阶段，导致协调性问题，包括碰撞风险和力分布不平衡。

Method: 提出单引导双臂（SGB）策略：首先使用Transformer解码器生成多样化的单抓取候选，然后通过专门的注意力机制利用其学习到的特征来联合预测双臂姿态和质量分数。

Result: 综合仿真实验和真实世界验证表明，BiGraspFormer始终优于现有方法，同时保持高效的推理速度（<0.05秒）。

Conclusion: BiGraspFormer框架在解决双臂抓取协调性问题方面具有有效性，代码和补充材料已公开。

Abstract: Bimanual grasping is essential for robots to handle large and complex
objects. However, existing methods either focus solely on single-arm grasping
or employ separate grasp generation and bimanual evaluation stages, leading to
coordination problems including collision risks and unbalanced force
distribution. To address these limitations, we propose BiGraspFormer, a unified
end-to-end transformer framework that directly generates coordinated bimanual
grasps from object point clouds. Our key idea is the Single-Guided Bimanual
(SGB) strategy, which first generates diverse single grasp candidates using a
transformer decoder, then leverages their learned features through specialized
attention mechanisms to jointly predict bimanual poses and quality scores. This
conditioning strategy reduces the complexity of the 12-DoF search space while
ensuring coordinated bimanual manipulation. Comprehensive simulation
experiments and real-world validation demonstrate that BiGraspFormer
consistently outperforms existing methods while maintaining efficient inference
speed (<0.05s), confirming the effectiveness of our framework. Code and
supplementary materials are available at https://sites.google.com/bigraspformer

</details>


### [155] [A Multimodal Stochastic Planning Approach for Navigation and Multi-Robot Coordination](https://arxiv.org/abs/2509.19168)
*Mark Gonzales,Ethan Oh,Joseph Moore*

Main category: cs.RO

TL;DR: 提出一种基于采样的重规划器，能够处理多模态策略分布，通过交叉熵方法优化多模态策略，提高对局部极小值的鲁棒性和解空间探索效率


<details>
  <summary>Details</summary>
Motivation: 解决传统规划方法容易陷入局部极小值的问题，提高多机器人系统中避碰和死锁避免的成功率

Method: 使用重规划视野和基于采样的规划方法，结合交叉熵方法优化多模态策略分布，在共同成本函数下进行优化

Result: 数值模拟显示多模态策略在陷阱环境和多机器人避碰中显著提高成功率，硬件实验验证了实时可行性

Conclusion: 该方法能够有效处理多模态策略，提高规划鲁棒性，适用于多机器人系统的分布式优化

Abstract: In this paper, we present a receding-horizon, sampling-based planner capable
of reasoning over multimodal policy distributions. By using the cross-entropy
method to optimize a multimodal policy under a common cost function, our
approach increases robustness against local minima and promotes effective
exploration of the solution space. We show that our approach naturally extends
to multi-robot collision-free planning, enables agents to share diverse
candidate policies to avoid deadlocks, and allows teams to minimize a global
objective without incurring the computational complexity of centralized
optimization. Numerical simulations demonstrate that employing multiple modes
significantly improves success rates in trap environments and in multi-robot
collision avoidance. Hardware experiments further validate the approach's
real-time feasibility and practical performance.

</details>


### [156] [MagiClaw: A Dual-Use, Vision-Based Soft Gripper for Bridging the Human Demonstration to Robotic Deployment Gap](https://arxiv.org/abs/2509.19169)
*Tianyu Wu,Xudong Han,Haoran Sun,Zishang Zhang,Bangchao Huang,Chaoyang Song,Fang Wan*

Main category: cs.RO

TL;DR: MagiClaw是一个多功能双指末端执行器，通过硬件一致性设计解决人机操作技能转移中的领域差距问题，集成了视觉力感知和环境感知能力。


<details>
  <summary>Details</summary>
Motivation: 解决人类演示与机器人执行之间的领域差距问题，特别是在感知和形态学方面的差异，降低接触丰富数据集收集的门槛。

Method: 设计MagiClaw末端执行器，兼具手持工具和机器人末端执行器功能，集成软多面体网络（SPN）和嵌入式摄像头进行6-DoF力估计，结合iPhone提供环境感知数据。

Result: 开发了统一的系统架构，能够实时流式传输同步多模态数据，支持遥操作、离线策略学习和混合现实界面控制。

Conclusion: MagiClaw系统降低了高保真接触丰富数据集收集的障碍，加速了可泛化操作策略的开发。

Abstract: The transfer of manipulation skills from human demonstration to robotic
execution is often hindered by a "domain gap" in sensing and morphology. This
paper introduces MagiClaw, a versatile two-finger end-effector designed to
bridge this gap. MagiClaw functions interchangeably as both a handheld tool for
intuitive data collection and a robotic end-effector for policy deployment,
ensuring hardware consistency and reliability. Each finger incorporates a Soft
Polyhedral Network (SPN) with an embedded camera, enabling vision-based
estimation of 6-DoF forces and contact deformation. This proprioceptive data is
fused with exteroceptive environmental sensing from an integrated iPhone, which
provides 6D pose, RGB video, and LiDAR-based depth maps. Through a custom iOS
application, MagiClaw streams synchronized, multi-modal data for real-time
teleoperation, offline policy learning, and immersive control via mixed-reality
interfaces. We demonstrate how this unified system architecture lowers the
barrier to collecting high-fidelity, contact-rich datasets and accelerates the
development of generalizable manipulation policies. Please refer to the iOS app
at https://apps.apple.com/cn/app/magiclaw/id6661033548 for further details.

</details>


### [157] [Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces](https://arxiv.org/abs/2509.19261)
*Kuanqi Cai,Chunfeng Wang,Zeqi Li,Haowen Yao,Weinan Chen,Luis Figueredo,Aude Billard,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出了一种模仿引导的双手机器人规划框架，通过稳定的抓取流形采样策略和分层运动架构，实现无缝抓取转换和优化的运动性能。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中机器人操作时不同抓取类型之间平滑转换的挑战，特别是在处理外部力和复杂运动约束时现有方法的不足。

Method: 采用模仿引导的双手机器人规划框架，包括稳定的抓取流形采样策略实现单双抓取无缝转换，以及分层双阶段运动架构结合模仿学习和二次规划进行实时运动规划。

Result: 在力密集型任务评估中显示出抓取转换效率和运动性能的显著提升。

Conclusion: 该方法有效提高了机器人操作的稳定性和灵巧性，为动态环境中的复杂操作任务提供了可行的解决方案。

Abstract: Robotic manipulation in dynamic environments often requires seamless
transitions between different grasp types to maintain stability and efficiency.
However, achieving smooth and adaptive grasp transitions remains a challenge,
particularly when dealing with external forces and complex motion constraints.
Existing grasp transition strategies often fail to account for varying external
forces and do not optimize motion performance effectively. In this work, we
propose an Imitation-Guided Bimanual Planning Framework that integrates
efficient grasp transition strategies and motion performance optimization to
enhance stability and dexterity in robotic manipulation. Our approach
introduces Strategies for Sampling Stable Intersections in Grasp Manifolds for
seamless transitions between uni-manual and bi-manual grasps, reducing
computational costs and regrasping inefficiencies. Additionally, a Hierarchical
Dual-Stage Motion Architecture combines an Imitation Learning-based Global Path
Generator with a Quadratic Programming-driven Local Planner to ensure real-time
motion feasibility, obstacle avoidance, and superior manipulability. The
proposed method is evaluated through a series of force-intensive tasks,
demonstrating significant improvements in grasp transition efficiency and
motion performance. A video demonstrating our simulation results can be viewed
at
\href{https://youtu.be/3DhbUsv4eDo}{\textcolor{blue}{https://youtu.be/3DhbUsv4eDo}}.

</details>


### [158] [SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration](https://arxiv.org/abs/2509.19292)
*Yang Jin,Jun Lv,Han Xue,Wendi Chen,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: SOE是一个通过流形约束探索来增强机器人策略自我改进的框架，解决了传统随机扰动方法的安全性和稳定性问题


<details>
  <summary>Details</summary>
Motivation: 机器人策略由于动作模式坍塌而缺乏足够的探索能力，现有基于随机扰动的方法不安全且行为不稳定，限制了其有效性

Method: 学习任务相关因素的紧凑潜在表示，将探索约束在有效动作的流形上，可作为插件模块与任意策略模型集成

Result: 在仿真和真实世界任务中，SOE持续优于现有方法，获得更高的任务成功率、更平滑安全的探索和更好的样本效率

Conclusion: 流形约束探索为样本高效的策略自我改进提供了原则性方法

Abstract: Intelligent agents progress by continually refining their capabilities
through actively exploring environments. Yet robot policies often lack
sufficient exploration capability due to action mode collapse. Existing methods
that encourage exploration typically rely on random perturbations, which are
unsafe and induce unstable, erratic behaviors, thereby limiting their
effectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a
framework that enhances policy exploration and improvement in robotic
manipulation. SOE learns a compact latent representation of task-relevant
factors and constrains exploration to the manifold of valid actions, ensuring
safety, diversity, and effectiveness. It can be seamlessly integrated with
arbitrary policy models as a plug-in module, augmenting exploration without
degrading the base policy performance. Moreover, the structured latent space
enables human-guided exploration, further improving efficiency and
controllability. Extensive experiments in both simulation and real-world tasks
demonstrate that SOE consistently outperforms prior methods, achieving higher
task success rates, smoother and safer exploration, and superior sample
efficiency. These results establish on-manifold exploration as a principled
approach to sample-efficient policy self-improvement. Project website:
https://ericjin2002.github.io/SOE

</details>


### [159] [Residual Off-Policy RL for Finetuning Behavior Cloning Policies](https://arxiv.org/abs/2509.19301)
*Lars Ankile,Zhenyu Jiang,Rocky Duan,Guanya Shi,Pieter Abbeel,Anusha Nagabandi*

Main category: cs.RO

TL;DR: 提出了一种结合行为克隆和强化学习的残差学习框架，利用BC策略作为基础，通过样本高效的离策略RL学习轻量级逐步残差修正，实现了在真实世界人形机器人上的成功RL训练。


<details>
  <summary>Details</summary>
Motivation: 行为克隆方法受限于人类演示质量、数据收集成本以及离线数据收益递减问题，而强化学习虽然能通过自主环境交互训练智能体，但在真实机器人上训练面临样本效率低、安全性问题和稀疏奖励学习困难等挑战。

Method: 采用残差学习框架，将BC策略作为黑盒基础，通过样本高效的离策略RL学习轻量级的逐步残差修正，仅需稀疏二元奖励信号。

Result: 在高自由度系统上有效改进了操作策略，在仿真和真实世界中都取得了成功，特别是在人形机器人灵巧手上实现了首个成功的真实世界RL训练，在各种视觉任务中达到了最先进的性能。

Conclusion: 该方法为在真实世界中部署RL提供了一条实用路径，成功结合了BC和RL的优势，解决了各自方法的局限性。

Abstract: Recent advances in behavior cloning (BC) have enabled impressive visuomotor
control policies. However, these approaches are limited by the quality of human
demonstrations, the manual effort required for data collection, and the
diminishing returns from increasing offline data. In comparison, reinforcement
learning (RL) trains an agent through autonomous interaction with the
environment and has shown remarkable success in various domains. Still,
training RL policies directly on real-world robots remains challenging due to
sample inefficiency, safety concerns, and the difficulty of learning from
sparse rewards for long-horizon tasks, especially for high-degree-of-freedom
(DoF) systems. We present a recipe that combines the benefits of BC and RL
through a residual learning framework. Our approach leverages BC policies as
black-box bases and learns lightweight per-step residual corrections via
sample-efficient off-policy RL. We demonstrate that our method requires only
sparse binary reward signals and can effectively improve manipulation policies
on high-degree-of-freedom (DoF) systems in both simulation and the real world.
In particular, we demonstrate, to the best of our knowledge, the first
successful real-world RL training on a humanoid robot with dexterous hands. Our
results demonstrate state-of-the-art performance in various vision-based tasks,
pointing towards a practical pathway for deploying RL in the real world.
Project website: https://residual-offpolicy-rl.github.io

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [160] [The Role of Informal Care in Cognitive Outcome and Healthcare Utilization Among Older Adults with Dementia](https://arxiv.org/abs/2509.18468)
*Mohammad Abdullah Al Faisal*

Main category: econ.GN

TL;DR: 本文使用工具变量方法研究非正式照护对老年痴呆患者认知功能和医疗资源使用的影响，发现非正式照护对认知功能无显著因果效应，但能显著减少养老院使用和机构化护理。


<details>
  <summary>Details</summary>
Motivation: 探讨非正式照护在老年痴呆患者长期照护中的作用，特别是其对认知功能和医疗资源使用的因果影响，为长期照护政策提供实证依据。

Method: 使用HRS调查数据（2010-2022年），采用OLS和工具变量方法，以子女数量作为非正式照护强度的工具变量，控制人口、社会经济和滞后认知变量。

Result: IV估计显示非正式照护对认知功能无显著因果效应，但显著降低养老院使用概率、机构夜数和机构化概率；对医院使用、医生就诊和门诊手术无稳健因果效应。

Conclusion: 非正式照护在替代机构照护方面发挥重要作用，对痴呆患者的长期照护政策具有重要意义。

Abstract: This paper examines the relationship between informal caregiving and both
cognitive functioning and healthcare utilization among older adults with
dementia. Using data from the RAND version of the Health and Retirement Study
(HRS), a nationally representative longitudinal panel of U.S. adults over age
50, covering the years 2010 to 2022, I estimate Ordinary Least Squares (OLS)
and Instrumental Variables (IV) models to address potential endogeneity in
caregiving decisions. The number of children is employed as an instrument for
informal care intensity. While OLS estimates suggest a negative association
between informal caregiving and cognition, IV estimates show no significant
causal effect after controlling for demographic, socioeconomic, and lagged
cognition variables. In contrast, IV results indicate that informal care
significantly reduces the likelihood of nursing home use, the number of
institutional nights, and the probability of institutionalization. No robust
causal effects are found for hospital use, doctor visits, or outpatient
surgery, although there is some suggestive evidence of a complementary
relationship between informal care and home health services. These findings
highlight the role of informal caregiving in substituting for institutional
care and underscore its importance in long-term care policy for dementia
patients. Keywords: Informal Caregiving; Cognitive Decline; Instrumental
Variables; Healthcare Utilization: Dementia Patients.

</details>


### [161] [Predicting Credit Spreads and Ratings with Machine Learning: The Role of Non-Financial Data](https://arxiv.org/abs/2509.19042)
*Yanran Wu,Xinlei Zhang,Quanyi Xu,Qianxin Yang,Chao Zhang*

Main category: econ.GN

TL;DR: 构建包含167个指标的信用风险指标体系，首次纳入30个大规模企业非财务指标，使用7种机器学习模型预测债券信用利差，验证其评级预测效果，发现模型优于中国信用评级机构，非财务指标重要性远超传统指标。


<details>
  <summary>Details</summary>
Motivation: 传统信用风险模型主要依赖财务指标，缺乏对企业非财务特征的考量。本文旨在通过整合宏观、财务、债券特征及大规模非财务指标，构建更全面的信用风险预测模型，提升债券违约预警和信用评级准确性。

Method: 建立167个指标的信用风险指标集，包含宏观、企业财务、债券特征及30个非财务指标。采用7种机器学习模型构建信用利差预测模型，并进行机制分析和信用评级预测验证。

Result: 模型在解释信用利差方面优于中国信用评级机构，非财务指标的加入使样本外预测性能提升一倍以上。非财务指标重要性显著高于传统指标，前10大重要指标中有7个是非财务指标。基于预测利差的信用评级模型准确率超过75%。

Conclusion: 非财务指标在信用风险预测中具有关键作用，本文提出的模型为债券违约预警、信用评级和金融稳定提供了有价值的指导，证明了机器学习模型在信用风险评估中的优越性。

Abstract: We build a 167-indicator comprehensive credit risk indicator set, integrating
macro, corporate financial, bond-specific indicators, and for the first time,
30 large-scale corporate non-financial indicators. We use seven machine
learning models to construct a bond credit spread prediction model, test their
spread predictive power and economic mechanisms, and verify their credit rating
prediction effectiveness. Results show these models outperform Chinese credit
rating agencies in explaining credit spreads. Specially, adding non-financial
indicators more than doubles their out-of-sample performance vs. traditional
feature-driven models. Mechanism analysis finds non-financial indicators far
more important than traditional ones (macro-level, financial, bond
features)-seven of the top 10 are non-financial (e.g., corporate governance,
property rights nature, information disclosure evaluation), the most stable
predictors. Models identify high-risk traits (deteriorating operations,
short-term debt, higher financing constraints) via these indicators for spread
prediction and risk identification. Finally, we pioneer a credit rating model
using predicted spreads (predicted implied rating model), with
full/sub-industry models achieving over 75% accuracy, recall, F1. This paper
provides valuable guidance for bond default early warning, credit rating, and
financial stability.

</details>
