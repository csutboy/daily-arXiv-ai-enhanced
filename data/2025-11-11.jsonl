{"id": "2511.05512", "categories": ["econ.GN", "econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.05512", "abs": "https://arxiv.org/abs/2511.05512", "authors": ["Vladislav Virtonen"], "title": "Estimating the Impact of the Bitcoin Halving on Its Price Using Synthetic Control", "comment": "74 pages, 33 figures", "summary": "The third Bitcoin halving that took place in May 2020 cut down the mining reward from 12.5 to 6.25 BTC per block and thus slowed down the rate of issuance of new Bitcoins, making it more scarce. The fourth and most recent halving happened in April 2024, cutting the block reward further to 3.125 BTC. If the demand did not decrease simultaneously after these halvings, then the neoclassical economic theory posits that the price of Bitcoin should have increased due to the halving. But did it, in fact, increase for that reason, or is this a post hoc fallacy? This paper uses synthetic control to construct a weighted Bitcoin that is different from its counterpart in one aspect - it did not undergo halving. Comparing the price trajectory of the actual and the simulated Bitcoins, I find evidence of a positive effect of the 2024 Bitcoin halving on its price three months later. The magnitude of this effect is one fifth of the total percentage change in the price of Bitcoin during the study period - from April 2, 2023, to July 21, 2024 (17 months). The second part of the study fails to obtain a statistically significant and robust causal estimate of the effect of the 2020 Bitcoin halving on Bitcoin's price. This is the first paper analyzing the effect of halving causally, building on the existing body of correlational research."}
{"id": "2511.05642", "categories": ["cs.RO", "cs.AR", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05642", "abs": "https://arxiv.org/abs/2511.05642", "authors": ["Justin Williams", "Kishor Datta Gupta", "Roy George", "Mrinmoy Sarkar"], "title": "Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots", "comment": null, "summary": "The deployment of artificial intelligence models at the edge is increasingly critical for autonomous robots operating in GPS-denied environments where local, resource-efficient reasoning is essential. This work demonstrates the feasibility of deploying small Vision-Language Models (VLMs) on mobile robots to achieve real-time scene understanding and reasoning under strict computational constraints. Unlike prior approaches that separate perception from mobility, the proposed framework enables simultaneous movement and reasoning in dynamic environments using only on-board hardware. The system integrates a compact VLM with multimodal perception to perform contextual interpretation directly on embedded hardware, eliminating reliance on cloud connectivity. Experimental validation highlights the balance between computational efficiency, task accuracy, and system responsiveness. Implementation on a mobile robot confirms one of the first successful deployments of small VLMs for concurrent reasoning and mobility at the edge. This work establishes a foundation for scalable, assured autonomy in applications such as service robotics, disaster response, and defense operations."}
{"id": "2511.05524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05524", "abs": "https://arxiv.org/abs/2511.05524", "authors": ["Ruiying Chen"], "title": "Evidence-Bound Autonomous Research (EviBound): A Governance Framework for Eliminating False Claims", "comment": "27 pages, 11 figures, 5 tables. Reproducibility package with MLflow artifacts and Google Colab notebooks available upon publication", "summary": "LLM-based autonomous research agents report false claims: tasks marked \"complete\" despite missing artifacts, contradictory metrics, or failed executions. EviBound is an evidence-bound execution framework that eliminates false claims through dual governance gates requiring machine-checkable evidence.\n  Two complementary gates enforce evidence requirements. The pre-execution Approval Gate validates acceptance criteria schemas before code runs, catching structural violations proactively. The post-execution Verification Gate validates artifacts via MLflow API queries (with recursive path checking) and optionally validates metrics when specified by acceptance criteria. Claims propagate only when backed by a queryable run ID, required artifacts, and FINISHED status. Bounded, confidence-gated retries (typically 1-2 attempts) recover from transient failures without unbounded loops.\n  The framework was evaluated on 8 benchmark tasks spanning infrastructure validation, ML capabilities, and governance stress tests. Baseline A (Prompt-Level Only) yields 100% hallucination (8/8 claimed, 0/8 verified). Baseline B (Verification-Only) reduces hallucination to 25% (2/8 fail verification). EviBound (Dual Gates) achieves 0% hallucination: 7/8 tasks verified and 1 task correctly blocked at the approval gate, all with only approximately 8.3% execution overhead.\n  This package includes execution trajectories, MLflow run IDs for all verified tasks, and a 4-step verification protocol. Research integrity is an architectural property, achieved through governance gates rather than emergent from model scale."}
{"id": "2511.05512", "categories": ["econ.GN", "econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.05512", "abs": "https://arxiv.org/abs/2511.05512", "authors": ["Vladislav Virtonen"], "title": "Estimating the Impact of the Bitcoin Halving on Its Price Using Synthetic Control", "comment": "74 pages, 33 figures", "summary": "The third Bitcoin halving that took place in May 2020 cut down the mining reward from 12.5 to 6.25 BTC per block and thus slowed down the rate of issuance of new Bitcoins, making it more scarce. The fourth and most recent halving happened in April 2024, cutting the block reward further to 3.125 BTC. If the demand did not decrease simultaneously after these halvings, then the neoclassical economic theory posits that the price of Bitcoin should have increased due to the halving. But did it, in fact, increase for that reason, or is this a post hoc fallacy? This paper uses synthetic control to construct a weighted Bitcoin that is different from its counterpart in one aspect - it did not undergo halving. Comparing the price trajectory of the actual and the simulated Bitcoins, I find evidence of a positive effect of the 2024 Bitcoin halving on its price three months later. The magnitude of this effect is one fifth of the total percentage change in the price of Bitcoin during the study period - from April 2, 2023, to July 21, 2024 (17 months). The second part of the study fails to obtain a statistically significant and robust causal estimate of the effect of the 2020 Bitcoin halving on Bitcoin's price. This is the first paper analyzing the effect of halving causally, building on the existing body of correlational research."}
{"id": "2511.06613", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.06613", "abs": "https://arxiv.org/abs/2511.06613", "authors": ["Henry A. Thompson"], "title": "Some economics of artificial super intelligence", "comment": null, "summary": "Conventional wisdom holds that a misaligned artificial superintelligence (ASI) will destroy humanity. But the problem of constraining a powerful agent is not new. I apply classic economic logic of interjurisdictional competition, all-encompassing interest, and trading on credit to the threat of misaligned ASI. Using a simple model, I show that an acquisitive ASI refrains from full predation under surprisingly weak conditions. When humans can flee to rivals, inter-ASI competition creates a market that tempers predation. When trapped by a monopolist ASI, its \"encompassing interest\" in humanity's output makes it a rational autocrat rather than a ravager. And when the ASI has no long-term stake, our ability to withhold future output incentivizes it to trade on credit rather than steal. In each extension, humanity's welfare progressively worsens. But each case suggests that catastrophe is not a foregone conclusion. The dismal science, ironically, offers an optimistic take on our superintelligent future."}
{"id": "2511.05530", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05530", "abs": "https://arxiv.org/abs/2511.05530", "authors": ["Ian M. Church", "Lyndon Drake", "Mark Harris"], "title": "Using LLMs to support assessment of student work in higher education: a viva voce simulator", "comment": null, "summary": "One of the emergent challenges of student work submitted for assessment is the widespread use of large language models (LLMs) to support and even produce written work. This particularly affects subjects where long-form written work is a key part of assessment. We propose a novel approach to addressing this challenge, using LLMs themselves to support the assessment process. We have developed a proof-of-concept viva voce examination simulator, which accepts the student's written submission as input, generates an interactive series of questions from the LLM and answers from the student. The viva voce simulator is an interactive tool which asks questions which a human examiner might plausibly ask, and uses the student's answers to form a judgment about whether the submitted piece of work is likely to be the student's own work. The interaction transcript is provided to the human examiner to support their final judgment. We suggest theoretical and practical points which are critical to real-world deployment of such a tool."}
{"id": "2511.05880", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05880", "abs": "https://arxiv.org/abs/2511.05880", "authors": ["Yiru Zhang"], "title": "Exploration of Enterprise Big Data Microservice Architecture Based on Domain-Driven Design (DDD)", "comment": null, "summary": "With the rapid advancement of digitization and intelligence, enterprise big data processing platforms have become increasingly important in data management. However, traditional monolithic architectures, due to their high coupling, are unable to cope with increasingly complex demands in the face of business expansion and increased data volume, resulting in limited platform scalability and decreased data collection efficiency. This article proposes a solution for enterprise big data processing platform based on microservice architecture, based on the concept of Domain Driven Design (DDD). Through in-depth analysis of business requirements, the functional and non functional requirements of the platform in various scenarios were determined, and the DDD method was used to decompose the core business logic into independent microservice modules, enabling data collection, parsing, cleaning, and visualization functions to be independently developed, deployed, and upgraded, thereby improving the flexibility and scalability of the system. This article also designs an automated data collection process based on microservices and proposes an improved dynamic scheduling algorithm to efficiently allocate data collection tasks to Docker nodes, and monitor the collection progress and service status in real time to ensure the accuracy and efficiency of data collection. Through the implementation and testing of the platform, it has been verified that the enterprise big data processing platform based on microservice architecture has significantly improved scalability, data quality, and collection efficiency."}
{"id": "2511.05712", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2511.05712", "abs": "https://arxiv.org/abs/2511.05712", "authors": ["Susanne Schennach", "Vincent Starck"], "title": "Optimally-Transported Generalized Method of Moments", "comment": null, "summary": "We propose a novel optimal transport-based version of the Generalized Method of Moment (GMM). Instead of handling overidentification by reweighting the data to satisfy the moment conditions (as in Generalized Empirical Likelihood methods), this method proceeds by allowing for errors in the variables of the least mean-square magnitude necessary to simultaneously satisfy all moment conditions. This approach, based on the notions of optimal transport and Wasserstein metric, aims to address the problem of assigning a logical interpretation to GMM results even when overidentification tests reject the null, a situation that cannot always be avoided in applications. We illustrate the method by revisiting Duranton, Morrow and Turner's (2014) study of the relationship between a city's exports and the extent of its transportation infrastructure. Our results corroborate theirs under weaker assumptions and provide insight into the error structure of the variables."}
{"id": "2511.05680", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05680", "abs": "https://arxiv.org/abs/2511.05680", "authors": ["Jeong-Jung Kim", "Doo-Yeol Koh", "Chang-Hyun Kim"], "title": "VLM-driven Skill Selection for Robotic Assembly Tasks", "comment": null, "summary": "This paper presents a robotic assembly framework that combines Vision-Language Models (VLMs) with imitation learning for assembly manipulation tasks. Our system employs a gripper-equipped robot that moves in 3D space to perform assembly operations. The framework integrates visual perception, natural language understanding, and learned primitive skills to enable flexible and adaptive robotic manipulation. Experimental results demonstrate the effectiveness of our approach in assembly scenarios, achieving high success rates while maintaining interpretability through the structured primitive skill decomposition."}
{"id": "2511.05757", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05757", "abs": "https://arxiv.org/abs/2511.05757", "authors": ["Hassan Iqbal", "Xingjian Li", "Tyler Ingebrand", "Adam Thorpe", "Krishna Kumar", "Ufuk Topcu", "Ján Drgoňa"], "title": "Zero-Shot Function Encoder-Based Differentiable Predictive Control", "comment": null, "summary": "We introduce a differentiable framework for zero-shot adaptive control over parametric families of nonlinear dynamical systems. Our approach integrates a function encoder-based neural ODE (FE-NODE) for modeling system dynamics with a differentiable predictive control (DPC) for offline self-supervised learning of explicit control policies. The FE-NODE captures nonlinear behaviors in state transitions and enables zero-shot adaptation to new systems without retraining, while the DPC efficiently learns control policies across system parameterizations, thus eliminating costly online optimization common in classical model predictive control. We demonstrate the efficiency, accuracy, and online adaptability of the proposed method across a range of nonlinear systems with varying parametric scenarios, highlighting its potential as a general-purpose tool for fast zero-shot adaptive control."}
{"id": "2511.07287", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.07287", "abs": "https://arxiv.org/abs/2511.07287", "authors": ["Daniele De luca"], "title": "Mapping Power Relations: A Geometric Framework for Game-Theoretic Analysis", "comment": null, "summary": "This paper introduces a geometric framework for analyzing power relations in games, independent of their strategic form. We define a canonical preference space where each player's relational stance is a normalized vector. This model eliminates the arbitrariness of selecting utility functions, a limitation of recent approaches. We show how classical concepts-bargaining power, dependence, reciprocity-are recovered and generalized within this space. The analysis proceeds in two steps: projecting a game's payoffs and outcomes onto the space, and then reducing the resulting landscape using key metrics. These include a Center of Mass (CoM) and structural indices for Hierarchy (H) and Reciprocity (R). Applications to canonical games (Prisoner's Dilemma, Battle of the Sexes) and economic models (Cournot duopoly) demonstrate that the framework reveals underlying structural similarities across different strategic settings and provides a quantitative characterization of relational dynamics. It thus bridges cooperative and non-cooperative game theory by conceptualizing power as a structural property of the mapping from preferences to equilibria."}
{"id": "2511.05757", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05757", "abs": "https://arxiv.org/abs/2511.05757", "authors": ["Hassan Iqbal", "Xingjian Li", "Tyler Ingebrand", "Adam Thorpe", "Krishna Kumar", "Ufuk Topcu", "Ján Drgoňa"], "title": "Zero-Shot Function Encoder-Based Differentiable Predictive Control", "comment": null, "summary": "We introduce a differentiable framework for zero-shot adaptive control over parametric families of nonlinear dynamical systems. Our approach integrates a function encoder-based neural ODE (FE-NODE) for modeling system dynamics with a differentiable predictive control (DPC) for offline self-supervised learning of explicit control policies. The FE-NODE captures nonlinear behaviors in state transitions and enables zero-shot adaptation to new systems without retraining, while the DPC efficiently learns control policies across system parameterizations, thus eliminating costly online optimization common in classical model predictive control. We demonstrate the efficiency, accuracy, and online adaptability of the proposed method across a range of nonlinear systems with varying parametric scenarios, highlighting its potential as a general-purpose tool for fast zero-shot adaptive control."}
{"id": "2511.05528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05528", "abs": "https://arxiv.org/abs/2511.05528", "authors": ["Aayush Aluru", "Myra Malik", "Samarth Patankar", "Spencer Kim", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "title": "SMAGDi: Socratic Multi Agent Interaction Graph Distillation for Efficient High Accuracy Reasoning", "comment": "Multi-Turn Interactions in Large Language Models (MTI-LLM) Workshop at NeurIPS 2025", "summary": "Multi-agent systems (MAS) often achieve higher reasoning accuracy than single models, but their reliance on repeated debates across agents makes them computationally expensive. We introduce SMAGDi, a distillation framework that transfers the debate dynamics of a five-agent Llama-based MAS into a compact Socratic decomposer-solver student. SMAGDi represents debate traces as directed interaction graphs, where nodes encode intermediate reasoning steps with correctness labels and edges capture continuity and cross-agent influence. The student is trained with a composite objective combining language modeling, graph-based supervision, contrastive reasoning, and embedding alignment to preserve both fluency and structured reasoning. On StrategyQA and MMLU, SMAGDi compresses a 40B multi-agent system into a 6B student while retaining 88% of its accuracy, substantially outperforming prior distillation methods such as MAGDi, standard KD, and fine-tuned baselines. These results highlight that explicitly modeling interaction graphs and Socratic decomposition enable small models to inherit the accuracy benefits of multi-agent debate while remaining efficient enough for real-world deployment."}
{"id": "2511.05524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05524", "abs": "https://arxiv.org/abs/2511.05524", "authors": ["Ruiying Chen"], "title": "Evidence-Bound Autonomous Research (EviBound): A Governance Framework for Eliminating False Claims", "comment": "27 pages, 11 figures, 5 tables. Reproducibility package with MLflow artifacts and Google Colab notebooks available upon publication", "summary": "LLM-based autonomous research agents report false claims: tasks marked \"complete\" despite missing artifacts, contradictory metrics, or failed executions. EviBound is an evidence-bound execution framework that eliminates false claims through dual governance gates requiring machine-checkable evidence.\n  Two complementary gates enforce evidence requirements. The pre-execution Approval Gate validates acceptance criteria schemas before code runs, catching structural violations proactively. The post-execution Verification Gate validates artifacts via MLflow API queries (with recursive path checking) and optionally validates metrics when specified by acceptance criteria. Claims propagate only when backed by a queryable run ID, required artifacts, and FINISHED status. Bounded, confidence-gated retries (typically 1-2 attempts) recover from transient failures without unbounded loops.\n  The framework was evaluated on 8 benchmark tasks spanning infrastructure validation, ML capabilities, and governance stress tests. Baseline A (Prompt-Level Only) yields 100% hallucination (8/8 claimed, 0/8 verified). Baseline B (Verification-Only) reduces hallucination to 25% (2/8 fail verification). EviBound (Dual Gates) achieves 0% hallucination: 7/8 tasks verified and 1 task correctly blocked at the approval gate, all with only approximately 8.3% execution overhead.\n  This package includes execution trajectories, MLflow run IDs for all verified tasks, and a 4-step verification protocol. Research integrity is an architectural property, achieved through governance gates rather than emergent from model scale."}
{"id": "2511.05599", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05599", "abs": "https://arxiv.org/abs/2511.05599", "authors": ["Doron Sayag", "Avichai Snir", "Daniel Levy"], "title": "0.001% and Counting: Revisiting the Price Rounding Tax", "comment": null, "summary": "In 1991 and 2008, Israel abolished the equivalents of 1-cent and 5-cent coins, respectively, effectively eliminating low-denomination coins and introducing rounding in cash transactions. When totals were rounded up, shoppers incurred a small rounding tax. Using detailed data on price endings and basket sizes across supermarkets, drugstores, small groceries, and convenience stores, we estimate that the magnitude of the rounding tax borne by Israeli consumers averaged only between 0.001 percent and 0.002 percent of revenues in the fast-moving consumer goods markets. These findings have implications for the ongoing debate regarding the desirability and viability of abolishing the 1-cent and 5-cent coins in the US."}
{"id": "2511.06107", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.06107", "abs": "https://arxiv.org/abs/2511.06107", "authors": ["David Kaplan", "Nina Jude", "Kjorte Harra", "Jonas Stampka"], "title": "On the Development of Probabilistic Projections of Country-level Progress to the UN SDG Indicator of Minimum Proficiency in Reading and Mathematics", "comment": null, "summary": "As of this writing, there are five years remaining for countries to reach their Sustainable Development Goals deadline of 2030 as agreed to by the member countries of the United Nations. Countries are, therefore, naturally interested in projections of progress toward these goals. A variety of statistical measures have been used to report on country-level progress toward the goals, but they have not utilized methodologies explicitly designed to obtain optimally predictive measures of rate of progress as the foundation for projecting trends. The focus of this paper is to provide Bayesian probabilistic projections of progress to SDG indicator 4.1.1, attaining minimum proficiency in reading and mathematics, with particular emphasis on competencies among lower secondary school children. Using data from the OECD PISA, as well as indicators drawn from the World Bank, the OECD, UNDP, and UNESCO, we employ a novel combination of Bayesian latent growth curve modeling Bayesian model averaging to obtain optimal estimates of the rate of progress in minimum proficiency percentages and then use those estimate to develop probabilistic projections into the future overall for all countries in the analysis. Four case study countries are also presented to show how the methods can be used for individual country projections."}
{"id": "2511.07218", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.07218", "abs": "https://arxiv.org/abs/2511.07218", "authors": ["Masaya Nishihata"], "title": "The Long Shadow of Superstars: Effects on Opportunities, Careers, and Team Production", "comment": "25 pages, 2 figures", "summary": "Superstars often dominate key tasks because of their exceptional abilities, but this concentration of responsibility may unintentionally limit on-the-job learning opportunities for others. Using panel data from Major League Baseball (MLB), this study examines how superstar presence affects teammates' opportunities and career outcomes. To address potential endogeneity in team composition, we exploit plausibly exogenous variation in superstar availability caused by injuries. When a superstar is active in the same team-position unit, non-star teammates play significantly less. These short-term reductions in playing time extend to longer horizons: players who begin their careers alongside a superstar who remains active for a full season (i.e., not on the injured list) are about 1.7 times more likely to exit MLB earlier than comparable peers. A key mechanism is reduced skill development -- limited playing opportunities hinder subsequent growth in offensive performance. At the team level, greater dependence on superstars raises immediate productivity but magnifies performance declines after their departure, indicating a trade-off between short-term success and long-term adaptability. Overall, the findings suggest that while concentrating key roles in top performers boosts output in the short run, it can restrict others' development and retention. Similar dynamics may arise in other organizations that rely heavily on a few exceptional individuals."}
{"id": "2511.05543", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05543", "abs": "https://arxiv.org/abs/2511.05543", "authors": ["Mohammed Marzuk T M", "Vijayasarathy R", "Madona Mathew"], "title": "Revenge Porn: A Peep into its Awareness among the Youth of Tamilnadu, India", "comment": "12 pages, 14 figures, International Journal of Indian Psychology, 2023", "summary": "The act of posting a person's private photos or videos without their consent is known as revenge porn, and it is usually done to extort money or seek revenge. According to a 2010 cybercrime survey, about 18.3% of women were unaware that they were victims of revenge porn. In densely populated countries like India, such incidents are more likely, yet there is no specific law addressing revenge porn. This study used purposive sampling with a sample size of 200 unmarried women from Tamil Nadu aged 18 to 30. The survey results show that more than 50% had never heard the term \"revenge porn,\" and only about 5% had personally experienced it. About 40% believed the victim was at fault, while 43.5% were unsure whether pornographic websites should be banned. Around 11% admitted that they might upload explicit content as revenge, and 8.5% felt that due to cultural taboos around sex, society tends to blame the victim. Police officers should be trained in techniques for psychologically supporting victims. India, which ranks third globally in cybercrime, must adopt better preventive measures. Public awareness and targeted legal reforms could play a major role in reducing such crimes."}
{"id": "2511.05891", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05891", "abs": "https://arxiv.org/abs/2511.05891", "authors": ["Linwei Wu"], "title": "Construction and Evolutionary Analysis of a Game Model for Supply Chain Finance Funding Based on Blockchain Technology", "comment": null, "summary": "The current surge in supply chain finance has significantly alleviated the \"capital challenges\" faced by domestic related enterprises, enabling enterprises upstream and subsequent stages of the industrial chain to achieve effective circulation of financing services in the supply chain based on the credit of core enterprises. By gathering essential information from the heart of the supply chain, supply chain financing enables efficient resource distribution and aids all stakeholders in making well-informed choices. However, supply chain finance in China still faces numerous obstacles, such as information asymmetry and inefficient credit transmission chains, hindering its long-term development. This paper designs an operational framework for supply chain finance incorporating blockchain technology, clearly defines the participating entities, and analyzes their business relationships. Based upon evolutionary game theory, a supply chain finance financing game model incorporating blockchain technology is constructed. A comparative analysis of the model's equilibrium points and their stability is conducted. The choices of evolutionary equilibrium strategies adopted by small and medium-sized enterprises, key players, and financing entities within this framework are explored, and the influence of blockchain technology on the prerequisites for completing supply chain finance transactions is investigated."}
{"id": "2511.05801", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2511.05801", "abs": "https://arxiv.org/abs/2511.05801", "authors": ["Yue Fang", "Geert Ridder"], "title": "The Exact Variance of the Average Treatment Effect Estimator in Cluster RCT", "comment": null, "summary": "In cluster randomized controlled trials (CRCT) with a finite populations, the exact design-based variance of the Horvitz-Thompson (HT) estimator for the average treatment effect (ATE) depends on the joint distribution of unobserved cluster-aggregated potential outcomes and is therefore not point-identifiable. We study a common two-stage sampling design-random sampling of clusters followed by sampling units within sampled clusters-with treatment assigned at the cluster level. First, we derive the exact (infeasible) design-based variance of the HT ATE estimator that accounts jointly for cluster- and unit-level sampling as well as random assignment. Second, extending Aronow et al (2014), we provide a sharp, attanable upper bound on that variance and propose a consistent estimator of the bound using only observed outcomes and known sampling/assignment probabilities. In simulations and an empirical application, confidence intervals based on our bound are valid and typically narrower than those based on cluster standard errors."}
{"id": "2511.05723", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05723", "abs": "https://arxiv.org/abs/2511.05723", "authors": ["Guangshen Ma", "Ravi Prakash", "Beatrice Schleupner", "Jeffrey Everitt", "Arpit Mishra", "Junqin Chen", "Brian Mann", "Boyuan Chen", "Leila Bridgeman", "Pei Zhong", "Mark Draelos", "William C. Eward", "Patrick J. Codd"], "title": "TumorMap: A Laser-based Surgical Platform for 3D Tumor Mapping and Fully-Automated Tumor Resection", "comment": "41 pages, 25 figures", "summary": "Surgical resection of malignant solid tumors is critically dependent on the surgeon's ability to accurately identify pathological tissue and remove the tumor while preserving surrounding healthy structures. However, building an intraoperative 3D tumor model for subsequent removal faces major challenges due to the lack of high-fidelity tumor reconstruction, difficulties in developing generalized tissue models to handle the inherent complexities of tumor diagnosis, and the natural physical limitations of bimanual operation, physiologic tremor, and fatigue creep during surgery. To overcome these challenges, we introduce \"TumorMap\", a surgical robotic platform to formulate intraoperative 3D tumor boundaries and achieve autonomous tissue resection using a set of multifunctional lasers. TumorMap integrates a three-laser mechanism (optical coherence tomography, laser-induced endogenous fluorescence, and cutting laser scalpel) combined with deep learning models to achieve fully-automated and noncontact tumor resection. We validated TumorMap in murine osteoscarcoma and soft-tissue sarcoma tumor models, and established a novel histopathological workflow to estimate sensor performance. With submillimeter laser resection accuracy, we demonstrated multimodal sensor-guided autonomous tumor surgery without any human intervention."}
{"id": "2511.05775", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05775", "abs": "https://arxiv.org/abs/2511.05775", "authors": ["Li-Yu Lin", "Benjamin Perseghetti", "James Goppert"], "title": "Log-linear Backstepping control on $SE_2(3)$", "comment": "4 pages, preliminary version, to be updated with full Lyapunov proof and extended results", "summary": "Most of the rigid-body systems which evolve on nonlinear Lie groups where Euclidean control designs lose geometric meaning. In this paper, we introduce a log-linear backstepping control law on SE2(3) that preserves full rotational-translational coupling. Leveraging a class of mixed-invariant system, which is a group-affine dynamic model, we derive exact logarithmic error dynamics that are linear in the Lie algebra. The closed-form expressions for the left- and right-Jacobian inverses of SE2(3) are expressed in the paper, which provides us the exact error dynamics without local approximations. A log-linear backstepping control design ensures exponential stability for our error dynamics; since our error dynamics is a block-triangular structure, this allows us to use Linear Matrix Inequality (LMI) formulation or $H_\\infty$ gain performance design. This work establishes the exact backstepping framework for a class of mixed-invariant system, providing a geometrically consistent foundation for future Unmanned Aerial Vehicle (UAV) and spacecraft control design."}
{"id": "2511.05932", "categories": ["cs.CY", "cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2511.05932", "abs": "https://arxiv.org/abs/2511.05932", "authors": ["Mohammad Rashed Albous", "Bedour Alboloushi", "Arnaud Lacheret"], "title": "The Future of AI in the GCC Post-NPM Landscape: A Comparative Analysis of Kuwait and the UAE", "comment": null, "summary": "Comparative evidence on how Gulf Cooperation Council (GCC) states turn artificial intelligence (AI) ambitions into post--New Public Management (post-NPM) outcomes is scarce because most studies examine Western democracies. We analyze constitutional, collective-choice, and operational rules shaping AI uptake in two contrasting GCC members, the United Arab Emirates (UAE) and Kuwait, and whether they foster citizen centricity, collaborative governance, and public value creation. Anchored in Ostrom's Institutional Analysis and Development framework, the study combines a most similar/most different systems design with multiple sources: 62 public documents from 2018--2025, embedded UAE cases (Smart Dubai and MBZUAI), and 39 interviews with officials conducted Aug 2024--May 2025. Dual coding and process tracing connect rule configurations to AI performance. Cross-case analysis identifies four reinforcing mechanisms behind divergent trajectories. In the UAE, concentrated authority, credible sanctions, pro-innovation narratives, and flexible reinvestment rules scale pilots into hundreds of services and sizable recycled savings. In Kuwait, dispersed veto points, exhortative sanctions, cautious discourse, and lapsed AI budgets confine initiatives to pilot mode despite equivalent fiscal resources. The findings refine institutional theory by showing that vertical rule coherence, not wealth, determines AI's public-value yield, and temper post-NPM optimism by revealing that efficiency metrics serve societal goals only when backed by enforceable safeguards. To curb ethics washing and test transferability beyond the GCC, future work should track rule diffusion over time, develop blended legitimacy--efficiency scorecards, and examine how narrative framing shapes citizen consent for data sharing."}
{"id": "2511.05775", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05775", "abs": "https://arxiv.org/abs/2511.05775", "authors": ["Li-Yu Lin", "Benjamin Perseghetti", "James Goppert"], "title": "Log-linear Backstepping control on $SE_2(3)$", "comment": "4 pages, preliminary version, to be updated with full Lyapunov proof and extended results", "summary": "Most of the rigid-body systems which evolve on nonlinear Lie groups where Euclidean control designs lose geometric meaning. In this paper, we introduce a log-linear backstepping control law on SE2(3) that preserves full rotational-translational coupling. Leveraging a class of mixed-invariant system, which is a group-affine dynamic model, we derive exact logarithmic error dynamics that are linear in the Lie algebra. The closed-form expressions for the left- and right-Jacobian inverses of SE2(3) are expressed in the paper, which provides us the exact error dynamics without local approximations. A log-linear backstepping control design ensures exponential stability for our error dynamics; since our error dynamics is a block-triangular structure, this allows us to use Linear Matrix Inequality (LMI) formulation or $H_\\infty$ gain performance design. This work establishes the exact backstepping framework for a class of mixed-invariant system, providing a geometrically consistent foundation for future Unmanned Aerial Vehicle (UAV) and spacecraft control design."}
{"id": "2511.05597", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05597", "abs": "https://arxiv.org/abs/2511.05597", "authors": ["Francisco Caravaca", "Ángel Cuevas", "Rubén Cuevas"], "title": "From Prompts to Power: Measuring the Energy Footprint of LLM Inference", "comment": null, "summary": "The rapid expansion of Large Language Models (LLMs) has introduced unprecedented energy demands, extending beyond training to large-scale inference workloads that often dominate total lifecycle consumption. Deploying these models requires energy-intensive GPU infrastructure, and in some cases has even prompted plans to power data centers with nuclear energy. Despite this growing relevance, systematic analyses of inference energy consumption remain limited. In this work, we present a large-scale measurement-based study comprising over 32,500 measurements across 21 GPU configurations and 155 model architectures, from small open-source models to frontier systems. Using the vLLM inference engine, we quantify energy usage at the prompt level and identify how architectural and operational factors shape energy demand. Building on these insights, we develop a predictive model that accurately estimates inference energy consumption across unseen architectures and hardware, and implement it as a browser extension to raise awareness of the environmental impact of generative AI."}
{"id": "2511.05526", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05526", "abs": "https://arxiv.org/abs/2511.05526", "authors": ["James Zhang", "Miles Kodama", "Zongze Wu", "Michael Chen", "Yue Zhu", "Geng Hong"], "title": "Emergency Response Measures for Catastrophic AI Risk", "comment": "Accepted to the Workshop on Regulatable ML at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Chinese authorities are extending the country's four-phase emergency response framework (prevent, warn, respond, and recover) to address risks from advanced artificial intelligence (AI). Concrete mechanisms for the proactive prevention and warning phases, however, remain under development. This paper analyzes an implementation model inspired by international AI safety practices: frontier safety policies (FSPs). These policies feature pre-deployment evaluations for dangerous capabilities and tiered, pre-planned safety measures. We observe close alignment between FSPs and the proactive phases of China's emergency response framework, suggesting that the FSP model could help operationalize AI emergency preparedness in a manner consistent with China's established governance principles."}
{"id": "2511.06545", "categories": ["econ.GN", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06545", "abs": "https://arxiv.org/abs/2511.06545", "authors": ["Ruiqing Cao", "Abhishek Bhatia"], "title": "How Founder Expertise Shapes the Impact of Generative Artificial Intelligence on Digital Ventures", "comment": null, "summary": "The rapid diffusion of generative artificial intelligence (GenAI) has substantially lowered the costs of launching and developing digital ventures. GenAI can potentially both enable previously unviable entrepreneurial ideas by lowering resource needs and improve the performance of existing ventures. We explore how founders' technical and managerial expertise shapes GenAI's impact on digital ventures along these dimensions. Exploiting exogenous variation in GenAI usage across venture categories and the timing of its broad availability for software tasks (e.g., GitHub Copilot's public release and subsequent GenAI tools), we find that the number of new venture launches increased and the median time to launch decreased significantly more in categories with relatively high GenAI usage. GenAI's effect on new launches is larger for founders without managerial experience or education, while its effect on venture capital (VC) funding likelihood is stronger for founders with technical experience or education. Overall, our results suggest that GenAI expands access to digital entrepreneurship for founders lacking managerial expertise and enhances venture performance among technical founders."}
{"id": "2511.06200", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.06200", "abs": "https://arxiv.org/abs/2511.06200", "authors": ["Sara Antonijevic", "Danielle Sitalo", "Brani Vidakovic"], "title": "Bayesian Meta-Analysis with Application in Dental Studies", "comment": "17 pages total, 3 figures and 2 tables", "summary": "Dental caries remain a persistent global health challenge, and fluoride varnish is widely used as a preventive intervention. This study synthesizes evidence from multiple clinical trials to evaluate the effectiveness of fluoride varnish in reducing Decayed-Missing-Filled (DMF) surfaces. The principal measure of efficacy is the Prevented Fraction (PF), representing the proportional reduction in caries relative to untreated controls. A comprehensive meta-analysis was conducted using fixed-effect and random-effects models, complemented by hierarchical Bayesian inference. The Bayesian framework incorporated multiple prior distributions on between-study variance, including Pareto, half-normal, uniform, beta, and scaled chi-square forms, to assess robustness under alternative heterogeneity assumptions. Across all specifications, the pooled estimate indicated an approximate 43% reduction in caries incidence, with credible intervals consistently excluding the null. Compared to classical methods, the Bayesian approach provided richer uncertainty quantification through full posterior distributions, allowed principled incorporation of prior evidence, and offered improved inference under heterogeneity and small-sample conditions. The stability of posterior estimates across diverse priors reinforces the robustness and reliability of the conclusions. Overall, findings confirm fluoride varnish as an effective and consistent preventive measure, and demonstrate the value of Bayesian hierarchical modeling as a powerful complement to traditional meta-analytic techniques in dental public health research."}
{"id": "2511.07280", "categories": ["econ.GN", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07280", "abs": "https://arxiv.org/abs/2511.07280", "authors": ["Kevin Zielnicki", "Guy Aridor", "Aurélien Bibaut", "Allen Tran", "Winston Chou", "Nathan Kallus"], "title": "The Value of Personalized Recommendations: Evidence from Netflix", "comment": null, "summary": "Personalized recommendation systems shape much of user choice online, yet their targeted nature makes separating out the value of recommendation and the underlying goods challenging. We build a discrete choice model that embeds recommendation-induced utility, low-rank heterogeneity, and flexible state dependence and apply the model to viewership data at Netflix. We exploit idiosyncratic variation introduced by the recommendation algorithm to identify and separately value these components as well as to recover model-free diversion ratios that we can use to validate our structural model. We use the model to evaluate counterfactuals that quantify the incremental engagement generated by personalized recommendations. First, we show that replacing the current recommender system with a matrix factorization or popularity-based algorithm would lead to 4% and 12% reduction in engagement, respectively, and decreased consumption diversity. Second, most of the consumption increase from recommendations comes from effective targeting, not mechanical exposure, with the largest gains for mid-popularity goods (as opposed to broadly appealing or very niche goods)."}
{"id": "2511.05555", "categories": ["cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05555", "abs": "https://arxiv.org/abs/2511.05555", "authors": ["C. Bowman Kerbage"], "title": "Deception Decoder: Proposing a Human-Focused Framework for Identifying AI-Generated Content on Social Media", "comment": null, "summary": "Generative AI (GenAI) poses a substantial threat to the integrity of information within the contemporary public sphere, which increasingly relies on social media platforms as intermediaries for news consumption. At present, most research efforts are directed toward automated and machine learning-based detection methods, despite growing concerns regarding false positives, social and political biases, and susceptibility to circumvention. This dissertation instead adopts a human-centred approach. It proposes the Deception Decoder; a multimodal, systematic, and topological framework designed to support general users in identifying AI-generated misinformation and disinformation across text, image, and video. The framework was developed through a comparative synthesis of existing models, supplemented by a content analysis of GenAI-video, and refined through a small-scale focus group session. While initial testing indicates promising improvements, further research is required to confirm its generalisability across user groups, and sustained effectiveness over time."}
{"id": "2511.05899", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05899", "abs": "https://arxiv.org/abs/2511.05899", "authors": ["Junchun Ding"], "title": "Research On CODP Localization Decision Model Of Automotive Supply Chain Based On Delayed Manufacturing Strategy", "comment": null, "summary": "Under the market background of increasingly personalized product demand and compressed response cycle, the traditional manufacturing model with standardized mass production as the core has been difficult to meet the dual expectations of customers for differentiation and fast delivery. In order to improve the efficiency of resource allocation and market response, automobile manufacturers need to build a production system that takes into account cost and flexibility. Based on the delayed response manufacturing strategy, this study built an order response node configuration model suitable for automotive manufacturing scenarios, focusing on the positioning of order driven intervention points in the production process. The model comprehensively considers the structural cost changes brought by process adjustment, the dynamic characteristics of the changes of unit manufacturing cost and intermediate inventory cost at different stages with the location of nodes, and introduces delivery time constraints to embed time factors into the inventory decision logic to enhance the practicality of the model and the adaptation of realistic constraints. In terms of solution methods, this paper adopts function fitting and simulation analysis methods, combined with mathematical modeling tools, systematically describes the change trend of total cost, and verifies the rationality and effectiveness of the model structure and solution through actual enterprise cases. The research results provide a theoretical basis and decision support for automobile manufacturing enterprises to realize the synergy of flexible production and cost control in the environment of variable demand, and also provide an empirical reference for the implementation path and system optimization of subsequent relevant strategies."}
{"id": "2511.05870", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2511.05870", "abs": "https://arxiv.org/abs/2511.05870", "authors": ["Yiqi Liu"], "title": "Synthetic Parallel Trends", "comment": null, "summary": "Popular empirical strategies for policy evaluation in the panel data literature -- including difference-in-differences (DID), synthetic control (SC) methods, and their variants -- rely on key identifying assumptions that can be expressed through a specific choice of weights $ω$ relating pre-treatment trends to the counterfactual outcome. While each choice of $ω$ may be defensible in empirical contexts that motivate a particular method, it relies on fundamentally untestable and often fragile assumptions. I develop an identification framework that allows for all weights satisfying a Synthetic Parallel Trends assumption: the treated unit's trend is parallel to a weighted combination of control units' trends for a general class of weights. The framework nests these existing methods as special cases and is by construction robust to violations of their respective assumptions. I construct a valid confidence set for the identified set of the treatment effect, which admits a linear programming representation with estimated coefficients and nuisance parameters that are profiled out. In simulations where the assumptions underlying DID or SC-based methods are violated, the proposed confidence set remains robust and attains nominal coverage, while existing methods suffer severe undercoverage."}
{"id": "2511.05785", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05785", "abs": "https://arxiv.org/abs/2511.05785", "authors": ["Lianhao Yin", "Haiping Yu", "Pascal Spino", "Daniela Rus"], "title": "A Unified Stochastic Mechanism Underlying Collective Behavior in Ants, Physical Systems, and Robotic Swarms", "comment": null, "summary": "Biological swarms, such as ant colonies, achieve collective goals through decentralized and stochastic individual behaviors. Similarly, physical systems composed of gases, liquids, and solids exhibit random particle motion governed by entropy maximization, yet do not achieve collective objectives. Despite this analogy, no unified framework exists to explain the stochastic behavior in both biological and physical systems. Here, we present empirical evidence from \\textit{Formica polyctena} ants that reveals a shared statistical mechanism underlying both systems: maximization under different energy function constraints. We further demonstrate that robotic swarms governed by this principle can exhibit scalable, decentralized cooperation, mimicking physical phase-like behaviors with minimal individual computation. These findings established a unified stochastic model linking biological, physical, and robotic swarms, offering a scalable principle for designing robust and intelligent swarm robotics."}
{"id": "2511.05779", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05779", "abs": "https://arxiv.org/abs/2511.05779", "authors": ["Ahmed Saad Al-Karsani", "Maryam Khanbaghi"], "title": "Autonomous and Distributed Synchronization and Restoration of an Islanded Network of Microgrids", "comment": null, "summary": "The transition towards clean energy and the introduction of Inverter-Based Resources (IBRs) are leading to the formation of Microgrids (MGs) and Network of MGs (NMGs). MGs and NMGs can operate autonomously in islanded mode, which requires Grid-Forming (GFM) IBRs that can perform black start, synchronization, restoration and regulation. However, such IBRs face synchronization instability issues, which might be worsened by inadequate secondary level frequency and voltage regulation. Accordingly, we propose an autonomous and distributed synchronization and restoration scheme using Distributed-Averaging Proportional-Integral (DAPI) control. To validate the proposed method, we model and simulate a high-fidelity islanded and modified IEEE 123 bus system, modeled as an NMG consisting of 7 MGs. The simulation results demonstrate an effective autonomous soft-start, synchronization, connection and regulation procedure using DAPI control and distributed breaker operation logic."}
{"id": "2511.05779", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05779", "abs": "https://arxiv.org/abs/2511.05779", "authors": ["Ahmed Saad Al-Karsani", "Maryam Khanbaghi"], "title": "Autonomous and Distributed Synchronization and Restoration of an Islanded Network of Microgrids", "comment": null, "summary": "The transition towards clean energy and the introduction of Inverter-Based Resources (IBRs) are leading to the formation of Microgrids (MGs) and Network of MGs (NMGs). MGs and NMGs can operate autonomously in islanded mode, which requires Grid-Forming (GFM) IBRs that can perform black start, synchronization, restoration and regulation. However, such IBRs face synchronization instability issues, which might be worsened by inadequate secondary level frequency and voltage regulation. Accordingly, we propose an autonomous and distributed synchronization and restoration scheme using Distributed-Averaging Proportional-Integral (DAPI) control. To validate the proposed method, we model and simulate a high-fidelity islanded and modified IEEE 123 bus system, modeled as an NMG consisting of 7 MGs. The simulation results demonstrate an effective autonomous soft-start, synchronization, connection and regulation procedure using DAPI control and distributed breaker operation logic."}
{"id": "2511.05747", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05747", "abs": "https://arxiv.org/abs/2511.05747", "authors": ["Ziqian Bi", "Kaijie Chen", "Tianyang Wang", "Junfeng Hao", "Xinyuan Song"], "title": "CoT-X: An Adaptive Framework for Cross-Model Chain-of-Thought Transfer and Optimization", "comment": "TKDD 2025", "summary": "Chain-of-Thought (CoT) reasoning enhances the problem-solving ability of large language models (LLMs) but leads to substantial inference overhead, limiting deployment in resource-constrained settings. This paper investigates efficient CoT transfer across models of different scales and architectures through an adaptive reasoning summarization framework. The proposed method compresses reasoning traces via semantic segmentation with importance scoring, budget-aware dynamic compression, and coherence reconstruction, preserving critical reasoning steps while significantly reducing token usage. Experiments on 7{,}501 medical examination questions across 10 specialties show up to 40% higher accuracy than truncation under the same token budgets. Evaluations on 64 model pairs from eight LLMs (1.5B-32B parameters, including DeepSeek-R1 and Qwen3) confirm strong cross-model transferability. Furthermore, a Gaussian Process-based Bayesian optimization module reduces evaluation cost by 84% and reveals a power-law relationship between model size and cross-domain robustness. These results demonstrate that reasoning summarization provides a practical path toward efficient CoT transfer, enabling advanced reasoning under tight computational constraints. Code will be released upon publication."}
{"id": "2511.05528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05528", "abs": "https://arxiv.org/abs/2511.05528", "authors": ["Aayush Aluru", "Myra Malik", "Samarth Patankar", "Spencer Kim", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "title": "SMAGDi: Socratic Multi Agent Interaction Graph Distillation for Efficient High Accuracy Reasoning", "comment": "Multi-Turn Interactions in Large Language Models (MTI-LLM) Workshop at NeurIPS 2025", "summary": "Multi-agent systems (MAS) often achieve higher reasoning accuracy than single models, but their reliance on repeated debates across agents makes them computationally expensive. We introduce SMAGDi, a distillation framework that transfers the debate dynamics of a five-agent Llama-based MAS into a compact Socratic decomposer-solver student. SMAGDi represents debate traces as directed interaction graphs, where nodes encode intermediate reasoning steps with correctness labels and edges capture continuity and cross-agent influence. The student is trained with a composite objective combining language modeling, graph-based supervision, contrastive reasoning, and embedding alignment to preserve both fluency and structured reasoning. On StrategyQA and MMLU, SMAGDi compresses a 40B multi-agent system into a 6B student while retaining 88% of its accuracy, substantially outperforming prior distillation methods such as MAGDi, standard KD, and fine-tuned baselines. These results highlight that explicitly modeling interaction graphs and Socratic decomposition enable small models to inherit the accuracy benefits of multi-agent debate while remaining efficient enough for real-world deployment."}
{"id": "2511.06562", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.06562", "abs": "https://arxiv.org/abs/2511.06562", "authors": ["Saani Rawat"], "title": "Does Urban Local Governance Matter? Evidence from India", "comment": null, "summary": "This paper examines the causal effect of urban local governance on public goods provision in India. We exploit quasi-random variation in multi-threshold criteria utilized for classifying Census Towns (CTs) and focus on settlements near the thresholds that are likely to obtain statutory recognition. Using a fuzzy regression discontinuity design, we instrument for urban local governance to identify the Local Average Treatment Effect (LATE). We document a strong first stage relationship between meeting CT thresholds and statutory recognition. Our results show that obtaining an Urban Local Body (ULB) increases local public good provision: government schools increase by approximately 14 (primary), 8 (middle), and 5 (secondary), healthcare infrastructure expands by 2 hospitals and 3 family welfare centers, and financial access deepens with 15 private banks, 2 cooperative banks, and 2 agricultural credit societies. Community amenities improve modestly with an additional public library, reading room, and cinema hall. Sports infrastructure declines by 5 facilities, consistent with our understanding of reallocation of urban space and investments. Our findings suggest that timely municipalization of emerging urban areas can expand provision of certain public goods, which may improve living standards and economic opportunities in urbanizing economies."}
{"id": "2511.06204", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.06204", "abs": "https://arxiv.org/abs/2511.06204", "authors": ["Hyun Jung Koo", "Aaron J. Molstad"], "title": "A unified approach to spatial domain detection and cell-type deconvolution in spot-based spatial transcriptomics", "comment": null, "summary": "Many popular technologies for generating spatially resolved transcriptomic (SRT) data measure gene expression at the resolution of a \"spot\", i.e., a small tissue region 55 microns in diameter. Each spot can contain many cells of different types. In typical analyses, researchers are interested in using these data to identify discrete spatial domains in the tissue. In this paper, we propose a new method, DUET, that simultaneously identifies discrete spatial domains and estimates each spot's cell-type proportion. This allows the identified spatial domains to be characterized in terms of the cell type proportions, which affords interpretability and biological insight. DUET utilizes a constrained version of model-based convex clustering, and as such, can accommodate Poisson, negative binomial, normal, and other types of expression data. Through simulation studies and multiple applications, we show that our method can achieve better clustering and deconvolution performance than existing methods."}
{"id": "2511.05515", "categories": ["q-fin.GN", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05515", "abs": "https://arxiv.org/abs/2511.05515", "authors": ["T. Alexander Puutio"], "title": "The Breadth Premium: Measuring the Firm-level Impact of CEO Career Breadth", "comment": "Preprint version 0.3 - pending data validation and regression reruns", "summary": "Prevailing career and education systems continue to reward early specialization and deep expertise within narrow domains. While such depth promotes efficiency, it may also limit adaptability in complex and rapidly changing environments. Building on research showing that variability in training inputs enhances learning outcomes across cognitive and behavioral domains, this study explores whether the same principle applies to executive performance.\n  Using an original dataset of 650 CEOs leading firms that together represent roughly 85% of US market capitalization, we construct a composite Breadth Index capturing cross-domain educational and professional breadth. Preliminary analyses reveal that firms led by higher-breadth CEOs outperform their industry peers by an average of 9.8 percentage points over a three-year window. Regression results indicate that each one-point increase on the five-point Range Index corresponds to a 1.8-point gain in abnormal returns (p < 0.03), with effects remaining robust across industries, firm sizes, and CEO age groups.\n  These early findings suggest that leadership breadth, defined as experience spanning multiple functions, disciplines, and sectors, is positively associated with firm-level performance. While the dataset remains under validation, the pattern observed supports the emerging view that as specialization deepens, the marginal value of lateral insight rises. Breadth, in this light, functions as a form of adaptive capital; it enhances leaders' capacity for integrative reasoning, organizational translation, and strategic flexibility in uncertain environments."}
{"id": "2511.05572", "categories": ["cs.CY", "cs.CE", "cs.CR", "cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05572", "abs": "https://arxiv.org/abs/2511.05572", "authors": ["Ivan Bergier"], "title": "AgriTrust: a Federated Semantic Governance Framework for Trusted Agricultural Data Sharing", "comment": null, "summary": "The potential of agricultural data (AgData) to drive efficiency and sustainability is stifled by the \"AgData Paradox\": a pervasive lack of trust and interoperability that locks data in silos, despite its recognized value. This paper introduces AgriTrust, a federated semantic governance framework designed to resolve this paradox. AgriTrust integrates a multi-stakeholder governance model, built on pillars of Data Sovereignty, Transparent Data Contracts, Equitable Value Sharing, and Regulatory Compliance, with a semantic digital layer. This layer is realized through the AgriTrust Core Ontology, a formal OWL ontology that provides a shared vocabulary for tokenization, traceability, and certification, enabling true semantic interoperability across independent platforms. A key innovation is a blockchain-agnostic, multi-provider architecture that prevents vendor lock-in. The framework's viability is demonstrated through case studies across three critical Brazilian supply chains: coffee (for EUDR compliance), soy (for mass balance), and beef (for animal tracking). The results show that AgriTrust successfully enables verifiable provenance, automates compliance, and creates new revenue streams for data producers, thereby transforming data sharing from a trust-based dilemma into a governed, automated operation. This work provides a foundational blueprint for a more transparent, efficient, and equitable agricultural data economy."}
{"id": "2511.05904", "categories": ["cs.SI", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2511.05904", "abs": "https://arxiv.org/abs/2511.05904", "authors": ["Pengwei Zhu"], "title": "The Role and Mechanism of Deep Statistical Machine Learning In Biological Target Screening and Immune Microenvironment Regulation of Asthma", "comment": null, "summary": "As an important source of small molecule drugs, natural products show remarkable biological activities with their rich types and unique structures. However, due to the limited number of samples and structural complexity, the rapid discovery of lead compounds is limited. Therefore, in this study, natural inhibitors of phosphodiesterase 4 (PDE4) and Phosphodiesterase 7 (PDE7) were screened by combining computer aided drug design (CADD) technology and deep learning method, and their activities were verified by enzyme activity experiment and enzymo-linked immunoassay. These two enzymes have important application potential in the treatment of inflammatory diseases such as chronic obstructive pulmonary disease and asthma, but PDE4 inhibitors may cause adverse reactions, so it is particularly important to develop both effective and safe dual-target inhibitors. In addition, as a potential target of hyperuricemia, the development of natural inhibitors of xanthine oxidase (X0) is also of great value. We used pharmacophore technology for virtual screening, combined with molecular docking technology to improve accuracy, and finally selected 16 potential natural inhibitors of PDE4/7, and verified their binding stability through molecular dynamics simulation. The results of this study laid a foundation for establishing an efficient dual-target inhibitor screening system and exploring the lead compounds of novel X0 inhibitors."}
{"id": "2511.06474", "categories": ["econ.EM", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.06474", "abs": "https://arxiv.org/abs/2511.06474", "authors": ["Matias D. Cattaneo", "Rocio Titiunik", "Ruiqi Rae Yu"], "title": "Boundary Discontinuity Designs: Theory and Practice", "comment": null, "summary": "We review the literature on boundary discontinuity (BD) designs, a powerful non-experimental research methodology that identifies causal effects by exploiting a thresholding treatment assignment rule based on a bivariate score and a boundary curve. This methodology generalizes standard regression discontinuity designs based on a univariate score and scalar cutoff, and has specific challenges and features related to its multi-dimensional nature. We synthesize the empirical literature by systematically reviewing over $80$ empirical papers, tracing the method's application from its formative uses to its implementation in modern research. In addition to the empirical survey, we overview the latest methodological results on identification, estimation and inference for the analysis of BD designs, and offer recommendations for practice."}
{"id": "2511.05791", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05791", "abs": "https://arxiv.org/abs/2511.05791", "authors": ["Manav Kulshrestha", "S. Talha Bukhari", "Damon Conover", "Aniket Bera"], "title": "VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models", "comment": "8 pages, 4 figures, under review", "summary": "Robotic grasping is a fundamental capability for autonomous manipulation; however, most existing methods rely on large-scale expert annotations and necessitate retraining to handle new objects. We present VLAD-Grasp, a Vision-Language model Assisted zero-shot approach for Detecting grasps. From a single RGB-D image, our method (1) prompts a large vision-language model to generate a goal image where a straight rod \"impales\" the object, representing an antipodal grasp, (2) predicts depth and segmentation to lift this generated image into 3D, and (3) aligns generated and observed object point clouds via principal component analysis and correspondence-free optimization to recover an executable grasp pose. Unlike prior work, our approach is training-free and does not rely on curated grasp datasets. Despite this, VLAD-Grasp achieves performance that is competitive with or superior to that of state-of-the-art supervised models on the Cornell and Jacquard datasets. We further demonstrate zero-shot generalization to novel real-world objects on a Franka Research 3 robot, highlighting vision-language foundation models as powerful priors for robotic manipulation."}
{"id": "2511.05822", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05822", "abs": "https://arxiv.org/abs/2511.05822", "authors": ["Sayak Mukherjee", "Ramij R. Hossain", "Kaustav Chatterjee", "Sameer Nekkalapu", "Marcelo Elizondo"], "title": "Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions", "comment": "10 pages, 7 figures", "summary": "This paper explores the development of learning-based tunable control gains using EMT-in-the-loop simulation framework (e.g., PSCAD interfaced with Python-based learning modules) to address critical sub-synchronous oscillations. Since sub-synchronous control interactions (SSCI) arise from the mis-tuning of control gains under specific grid configurations, effective mitigation strategies require adaptive re-tuning of these gains. Such adaptiveness can be achieved by employing a closed-loop, learning-based framework that considers the grid conditions responsible for such sub-synchronous oscillations. This paper addresses this need by adopting methodologies inspired by Markov decision process (MDP) based reinforcement learning (RL), with a particular emphasis on simpler deep policy gradient methods with additional SSCI-specific signal processing modules such as down-sampling, bandpass filtering, and oscillation energy dependent reward computations. Our experimentation in a real-world event setting demonstrates that the deep policy gradient based trained policy can adaptively compute gain settings in response to varying grid conditions and optimally suppress control interaction-induced oscillations."}
{"id": "2511.05822", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05822", "abs": "https://arxiv.org/abs/2511.05822", "authors": ["Sayak Mukherjee", "Ramij R. Hossain", "Kaustav Chatterjee", "Sameer Nekkalapu", "Marcelo Elizondo"], "title": "Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions", "comment": "10 pages, 7 figures", "summary": "This paper explores the development of learning-based tunable control gains using EMT-in-the-loop simulation framework (e.g., PSCAD interfaced with Python-based learning modules) to address critical sub-synchronous oscillations. Since sub-synchronous control interactions (SSCI) arise from the mis-tuning of control gains under specific grid configurations, effective mitigation strategies require adaptive re-tuning of these gains. Such adaptiveness can be achieved by employing a closed-loop, learning-based framework that considers the grid conditions responsible for such sub-synchronous oscillations. This paper addresses this need by adopting methodologies inspired by Markov decision process (MDP) based reinforcement learning (RL), with a particular emphasis on simpler deep policy gradient methods with additional SSCI-specific signal processing modules such as down-sampling, bandpass filtering, and oscillation energy dependent reward computations. Our experimentation in a real-world event setting demonstrates that the deep policy gradient based trained policy can adaptively compute gain settings in response to varying grid conditions and optimally suppress control interaction-induced oscillations."}
{"id": "2511.05766", "categories": ["cs.AI", "cs.CL", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05766", "abs": "https://arxiv.org/abs/2511.05766", "authors": ["Felipe Valencia-Clavijo"], "title": "Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs", "comment": null, "summary": "Large language models (LLMs) are increasingly examined as both behavioral subjects and decision systems, yet it remains unclear whether observed cognitive biases reflect surface imitation or deeper probability shifts. Anchoring bias, a classic human judgment bias, offers a critical test case. While prior work shows LLMs exhibit anchoring, most evidence relies on surface-level outputs, leaving internal mechanisms and attributional contributions unexplored. This paper advances the study of anchoring in LLMs through three contributions: (1) a log-probability-based behavioral analysis showing that anchors shift entire output distributions, with controls for training-data contamination; (2) exact Shapley-value attribution over structured prompt fields to quantify anchor influence on model log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score integrating behavioral and attributional evidence across six open-source models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and Llama-2-7B, with attribution signaling that the anchors influence reweighting. Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability, suggesting scale may modulate sensitivity. Attributional effects, however, vary across prompt designs, underscoring fragility in treating LLMs as human substitutes. The findings demonstrate that anchoring bias in LLMs is robust, measurable, and interpretable, while highlighting risks in applied domains. More broadly, the framework bridges behavioral science, LLM safety, and interpretability, offering a reproducible path for evaluating other cognitive biases in LLMs."}
{"id": "2511.05530", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05530", "abs": "https://arxiv.org/abs/2511.05530", "authors": ["Ian M. Church", "Lyndon Drake", "Mark Harris"], "title": "Using LLMs to support assessment of student work in higher education: a viva voce simulator", "comment": null, "summary": "One of the emergent challenges of student work submitted for assessment is the widespread use of large language models (LLMs) to support and even produce written work. This particularly affects subjects where long-form written work is a key part of assessment. We propose a novel approach to addressing this challenge, using LLMs themselves to support the assessment process. We have developed a proof-of-concept viva voce examination simulator, which accepts the student's written submission as input, generates an interactive series of questions from the LLM and answers from the student. The viva voce simulator is an interactive tool which asks questions which a human examiner might plausibly ask, and uses the student's answers to form a judgment about whether the submitted piece of work is likely to be the student's own work. The interaction transcript is provided to the human examiner to support their final judgment. We suggest theoretical and practical points which are critical to real-world deployment of such a tool."}
{"id": "2511.06613", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.06613", "abs": "https://arxiv.org/abs/2511.06613", "authors": ["Henry A. Thompson"], "title": "Some economics of artificial super intelligence", "comment": null, "summary": "Conventional wisdom holds that a misaligned artificial superintelligence (ASI) will destroy humanity. But the problem of constraining a powerful agent is not new. I apply classic economic logic of interjurisdictional competition, all-encompassing interest, and trading on credit to the threat of misaligned ASI. Using a simple model, I show that an acquisitive ASI refrains from full predation under surprisingly weak conditions. When humans can flee to rivals, inter-ASI competition creates a market that tempers predation. When trapped by a monopolist ASI, its \"encompassing interest\" in humanity's output makes it a rational autocrat rather than a ravager. And when the ASI has no long-term stake, our ability to withhold future output incentivizes it to trade on credit rather than steal. In each extension, humanity's welfare progressively worsens. But each case suggests that catastrophe is not a foregone conclusion. The dismal science, ironically, offers an optimistic take on our superintelligent future."}
{"id": "2511.06276", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.06276", "abs": "https://arxiv.org/abs/2511.06276", "authors": ["Fernando Rodriguez Avellaneda", "Paula Moraga"], "title": "Bayesian spatio-temporal disaggregation modeling using a diffusion-SPDE approach: a case study of Aerosol Optical Depth in India", "comment": null, "summary": "Accurate estimation of Aerosol Optical Depth (AOD) is crucial for understanding climate change and its impacts on public health, as aerosols are a measure of air quality conditions. AOD is usually retrieved from satellite imagery at coarse spatial and temporal resolutions. However, producing high-resolution AOD estimates in both space and time can better support evidence-based policies and interventions. We propose a spatio-temporal disaggregation model that assumes a latent spatio--temporal continuous Gaussian process observed through aggregated measurements. The model links discrete observations to the continuous domain and accommodates covariates to improve explanatory power and interpretability. The approach employs Gaussian processes with separable or non-separable covariance structures derived from a diffusion-based spatio-temporal stochastic partial differential equation (SPDE). Bayesian inference is conducted using the INLA-SPDE framework for computational efficiency. Simulation studies and an application to nowcasting AOD at 550 nm in India demonstrate the model's effectiveness, improving spatial resolution from 0.75° to 0.25° and temporal resolution from 3 hours to 1 hour."}
{"id": "2511.05766", "categories": ["cs.AI", "cs.CL", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05766", "abs": "https://arxiv.org/abs/2511.05766", "authors": ["Felipe Valencia-Clavijo"], "title": "Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs", "comment": null, "summary": "Large language models (LLMs) are increasingly examined as both behavioral subjects and decision systems, yet it remains unclear whether observed cognitive biases reflect surface imitation or deeper probability shifts. Anchoring bias, a classic human judgment bias, offers a critical test case. While prior work shows LLMs exhibit anchoring, most evidence relies on surface-level outputs, leaving internal mechanisms and attributional contributions unexplored. This paper advances the study of anchoring in LLMs through three contributions: (1) a log-probability-based behavioral analysis showing that anchors shift entire output distributions, with controls for training-data contamination; (2) exact Shapley-value attribution over structured prompt fields to quantify anchor influence on model log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score integrating behavioral and attributional evidence across six open-source models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and Llama-2-7B, with attribution signaling that the anchors influence reweighting. Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability, suggesting scale may modulate sensitivity. Attributional effects, however, vary across prompt designs, underscoring fragility in treating LLMs as human substitutes. The findings demonstrate that anchoring bias in LLMs is robust, measurable, and interpretable, while highlighting risks in applied domains. More broadly, the framework bridges behavioral science, LLM safety, and interpretability, offering a reproducible path for evaluating other cognitive biases in LLMs."}
{"id": "2511.05613", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05613", "abs": "https://arxiv.org/abs/2511.05613", "authors": ["Anka Reuel", "Avijit Ghosh", "Jenny Chim", "Andrew Tran", "Yanan Long", "Jennifer Mickel", "Usman Gohar", "Srishti Yadav", "Pawan Sasanka Ammanamanchi", "Mowafak Allaham", "Hossein A. Rahmani", "Mubashara Akhtar", "Felix Friedrich", "Robert Scholz", "Michael Alexander Riegler", "Jan Batzner", "Eliya Habba", "Arushi Saxena", "Anastassia Kornilova", "Kevin Wei", "Prajna Soni", "Yohan Mathew", "Kevin Klyman", "Jeba Sania", "Subramanyam Sahoo", "Olivia Beyer Bruvik", "Pouya Sadeghi", "Sujata Goswami", "Angelina Wang", "Yacine Jernite", "Zeerak Talat", "Stella Biderman", "Mykel Kochenderfer", "Sanmi Koyejo", "Irene Solaiman"], "title": "Who Evaluates AI's Social Impacts? Mapping Coverage and Gaps in First and Third Party Evaluations", "comment": null, "summary": "Foundation models are increasingly central to high-stakes AI systems, and governance frameworks now depend on evaluations to assess their risks and capabilities. Although general capability evaluations are widespread, social impact assessments covering bias, fairness, privacy, environmental costs, and labor practices remain uneven across the AI ecosystem. To characterize this landscape, we conduct the first comprehensive analysis of both first-party and third-party social impact evaluation reporting across a wide range of model developers. Our study examines 186 first-party release reports and 183 post-release evaluation sources, and complements this quantitative analysis with interviews of model developers. We find a clear division of evaluation labor: first-party reporting is sparse, often superficial, and has declined over time in key areas such as environmental impact and bias, while third-party evaluators including academic researchers, nonprofits, and independent organizations provide broader and more rigorous coverage of bias, harmful content, and performance disparities. However, this complementarity has limits. Only model developers can authoritatively report on data provenance, content moderation labor, financial costs, and training infrastructure, yet interviews reveal that these disclosures are often deprioritized unless tied to product adoption or regulatory compliance. Our findings indicate that current evaluation practices leave major gaps in assessing AI's societal impacts, highlighting the urgent need for policies that promote developer transparency, strengthen independent evaluation ecosystems, and create shared infrastructure to aggregate and compare third-party evaluations in a consistent and accessible way."}
{"id": "2511.06091", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.06091", "abs": "https://arxiv.org/abs/2511.06091", "authors": ["Wenchao Dong", "Marcelo S. Locatelli", "Virgilio Almeida", "Meeyoung Cha"], "title": "Characterizing AI Manipulation Risks in Brazilian YouTube Climate Discourse", "comment": "Accepted to the Special Track on AI for Social Impact at AAAI 2026", "summary": "Climate change poses a global threat to public health, food security, and economic stability. Addressing it requires evidence-based policies and a nuanced understanding of how the threat is perceived by the public, particularly within visual social media, where narratives quickly evolve through voices of individuals, politicians, NGOs, and institutions. This study investigates climate-related discourse on YouTube within the Brazilian context, a geopolitically significant nation in global environmental negotiations. Through three case studies, we examine (1) which psychological content traits most effectively drive audience engagement, (2) the extent to which these traits influence content popularity, and (3) whether such insights can inform the design of persuasive synthetic campaigns--such as climate denialism--using recent generative language models. Another contribution of this work is the release of a large publicly available dataset of 226K Brazilian YouTube videos and 2.7M user comments on climate change. The dataset includes fine-grained annotations of persuasive strategies, theory-of-mind categorizations in user responses, and typologies of content creators. This resource can help support future research on digital climate communication and the ethical risk of algorithmically amplified narratives and generative media."}
{"id": "2511.07183", "categories": ["econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.07183", "abs": "https://arxiv.org/abs/2511.07183", "authors": ["Liudas Giraitis", "George Kapetanios", "Yufei Li", "Alexia Ventouri"], "title": "Unlocking the Regression Space", "comment": "74 pages, 15 figures", "summary": "This paper introduces and analyzes a framework that accommodates general heterogeneity in regression modeling. It demonstrates that regression models with fixed or time-varying parameters can be estimated using the OLS and time-varying OLS methods, respectively, across a broad class of regressors and noise processes not covered by existing theory. The proposed setting facilitates the development of asymptotic theory and the estimation of robust standard errors. The robust confidence interval estimators accommodate substantial heterogeneity in both regressors and noise. The resulting robust standard error estimates coincide with White's (1980) heteroskedasticity-consistent estimator but are applicable to a broader range of conditions, including models with missing data. They are computationally simple and perform well in Monte Carlo simulations. Their robustness, generality, and ease of implementation make them highly suitable for empirical applications. Finally, the paper provides a brief empirical illustration."}
{"id": "2511.05798", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05798", "abs": "https://arxiv.org/abs/2511.05798", "authors": ["William R. Johnson", "Patrick Meng", "Nelson Chen", "Luca Cimatti", "Augustin Vercoutere", "Mridul Aanjaneya", "Rebecca Kramer-Bottiglio", "Kostas E. Bekris"], "title": "An Open-Source, Reproducible Tensegrity Robot that can Navigate Among Obstacles", "comment": null, "summary": "Tensegrity robots, composed of rigid struts and elastic tendons, provide impact resistance, low mass, and adaptability to unstructured terrain. Their compliance and complex, coupled dynamics, however, present modeling and control challenges, hindering path planning and obstacle avoidance. This paper presents a complete, open-source, and reproducible system that enables navigation for a 3-bar tensegrity robot. The system comprises: (i) an inexpensive, open-source hardware design, and (ii) an integrated, open-source software stack for physics-based modeling, system identification, state estimation, path planning, and control. All hardware and software are publicly available at https://sites.google.com/view/tensegrity-navigation/. The proposed system tracks the robot's pose and executes collision-free paths to a specified goal among known obstacle locations. System robustness is demonstrated through experiments involving unmodeled environmental challenges, including a vertical drop, an incline, and granular media, culminating in an outdoor field demonstration. To validate reproducibility, experiments were conducted using robot instances at two different laboratories. This work provides the robotics community with a complete navigation system for a compliant, impact-resistant, and shape-morphing robot. This system is intended to serve as a springboard for advancing the navigation capabilities of other unconventional robotic platforms."}
{"id": "2511.05828", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05828", "abs": "https://arxiv.org/abs/2511.05828", "authors": ["Zhiguan Niu", "Xiaochao Zhou", "Hao Xiong"], "title": "Learning-Based Multi-Stage Strategy for a Fixed-Wing Aircraft to Evade a Missile Detected at a Short Distance", "comment": null, "summary": "Missiles pose a major threat to aircraft in modern air combat. Advances in technology make them increasingly difficult to detect until they are close to the target and highly resistant to jamming. The evasion maneuver is the last line of defense for an aircraft. However, conventional rule-based evasion strategies are limited by computational demands and aerodynamic constraints, and existing learning-based approaches remain unconvincing for manned aircraft against modern missiles. To enhance aircraft survivability, this study investigates missile evasion inspired by the pursuit-evasion game between a gazelle and a cheetah and proposes a multi-stage reinforcement learning-based evasion strategy. The strategy learns a large azimuth policy to turn to evade, a small azimuth policy to keep moving away, and a short distance policy to perform agile aggressive maneuvers to avoid. One of the three policies is activated at each stage based on distance and azimuth. To evaluate performance, a high-fidelity simulation environment modeling an F-16 aircraft and missile under various conditions is used to compare the proposed approach with baseline strategies. Experimental results show that the proposed method achieves superior performance, enabling the F-16 aircraft to successfully avoid missiles with a probability of 80.89 percent for velocities ranging from 800 m/s to 1400 m/s, maximum overloads from 40 g to 50 g, detection distances from 5000 m to 15000 m, and random azimuths. When the missile is detected beyond 8000 m, the success ratio increases to 85.06 percent."}
{"id": "2511.05828", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05828", "abs": "https://arxiv.org/abs/2511.05828", "authors": ["Zhiguan Niu", "Xiaochao Zhou", "Hao Xiong"], "title": "Learning-Based Multi-Stage Strategy for a Fixed-Wing Aircraft to Evade a Missile Detected at a Short Distance", "comment": null, "summary": "Missiles pose a major threat to aircraft in modern air combat. Advances in technology make them increasingly difficult to detect until they are close to the target and highly resistant to jamming. The evasion maneuver is the last line of defense for an aircraft. However, conventional rule-based evasion strategies are limited by computational demands and aerodynamic constraints, and existing learning-based approaches remain unconvincing for manned aircraft against modern missiles. To enhance aircraft survivability, this study investigates missile evasion inspired by the pursuit-evasion game between a gazelle and a cheetah and proposes a multi-stage reinforcement learning-based evasion strategy. The strategy learns a large azimuth policy to turn to evade, a small azimuth policy to keep moving away, and a short distance policy to perform agile aggressive maneuvers to avoid. One of the three policies is activated at each stage based on distance and azimuth. To evaluate performance, a high-fidelity simulation environment modeling an F-16 aircraft and missile under various conditions is used to compare the proposed approach with baseline strategies. Experimental results show that the proposed method achieves superior performance, enabling the F-16 aircraft to successfully avoid missiles with a probability of 80.89 percent for velocities ranging from 800 m/s to 1400 m/s, maximum overloads from 40 g to 50 g, detection distances from 5000 m to 15000 m, and random azimuths. When the missile is detected beyond 8000 m, the success ratio increases to 85.06 percent."}
{"id": "2511.05810", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05810", "abs": "https://arxiv.org/abs/2511.05810", "authors": ["Bowen Xu", "Xinyue Zeng", "Jiazhen Hu", "Tuo Wang", "Adithya Kulkarni"], "title": "DiagnoLLM: A Hybrid Bayesian Neural Language Framework for Interpretable Disease Diagnosis", "comment": null, "summary": "Building trustworthy clinical AI systems requires not only accurate predictions but also transparent, biologically grounded explanations. We present \\texttt{DiagnoLLM}, a hybrid framework that integrates Bayesian deconvolution, eQTL-guided deep learning, and LLM-based narrative generation for interpretable disease diagnosis. DiagnoLLM begins with GP-unmix, a Gaussian Process-based hierarchical model that infers cell-type-specific gene expression profiles from bulk and single-cell RNA-seq data while modeling biological uncertainty. These features, combined with regulatory priors from eQTL analysis, power a neural classifier that achieves high predictive performance in Alzheimer's Disease (AD) detection (88.0\\% accuracy). To support human understanding and trust, we introduce an LLM-based reasoning module that translates model outputs into audience-specific diagnostic reports, grounded in clinical features, attribution signals, and domain knowledge. Human evaluations confirm that these reports are accurate, actionable, and appropriately tailored for both physicians and patients. Our findings show that LLMs, when deployed as post-hoc reasoners rather than end-to-end predictors, can serve as effective communicators within hybrid diagnostic pipelines."}
{"id": "2511.05543", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05543", "abs": "https://arxiv.org/abs/2511.05543", "authors": ["Mohammed Marzuk T M", "Vijayasarathy R", "Madona Mathew"], "title": "Revenge Porn: A Peep into its Awareness among the Youth of Tamilnadu, India", "comment": "12 pages, 14 figures, International Journal of Indian Psychology, 2023", "summary": "The act of posting a person's private photos or videos without their consent is known as revenge porn, and it is usually done to extort money or seek revenge. According to a 2010 cybercrime survey, about 18.3% of women were unaware that they were victims of revenge porn. In densely populated countries like India, such incidents are more likely, yet there is no specific law addressing revenge porn. This study used purposive sampling with a sample size of 200 unmarried women from Tamil Nadu aged 18 to 30. The survey results show that more than 50% had never heard the term \"revenge porn,\" and only about 5% had personally experienced it. About 40% believed the victim was at fault, while 43.5% were unsure whether pornographic websites should be banned. Around 11% admitted that they might upload explicit content as revenge, and 8.5% felt that due to cultural taboos around sex, society tends to blame the victim. Police officers should be trained in techniques for psychologically supporting victims. India, which ranks third globally in cybercrime, must adopt better preventive measures. Public awareness and targeted legal reforms could play a major role in reducing such crimes."}
{"id": "2511.07218", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.07218", "abs": "https://arxiv.org/abs/2511.07218", "authors": ["Masaya Nishihata"], "title": "The Long Shadow of Superstars: Effects on Opportunities, Careers, and Team Production", "comment": "25 pages, 2 figures", "summary": "Superstars often dominate key tasks because of their exceptional abilities, but this concentration of responsibility may unintentionally limit on-the-job learning opportunities for others. Using panel data from Major League Baseball (MLB), this study examines how superstar presence affects teammates' opportunities and career outcomes. To address potential endogeneity in team composition, we exploit plausibly exogenous variation in superstar availability caused by injuries. When a superstar is active in the same team-position unit, non-star teammates play significantly less. These short-term reductions in playing time extend to longer horizons: players who begin their careers alongside a superstar who remains active for a full season (i.e., not on the injured list) are about 1.7 times more likely to exit MLB earlier than comparable peers. A key mechanism is reduced skill development -- limited playing opportunities hinder subsequent growth in offensive performance. At the team level, greater dependence on superstars raises immediate productivity but magnifies performance declines after their departure, indicating a trade-off between short-term success and long-term adaptability. Overall, the findings suggest that while concentrating key roles in top performers boosts output in the short run, it can restrict others' development and retention. Similar dynamics may arise in other organizations that rely heavily on a few exceptional individuals."}
{"id": "2511.06320", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.06320", "abs": "https://arxiv.org/abs/2511.06320", "authors": ["Abbas Zaidi", "Rina Friedberg", "Samir Khan", "Yao-Yang Leow", "Maulik Soneji", "Houssam Nassif", "Richard Mudd"], "title": "Bayesian Predictive Probabilities for Online Experimentation", "comment": "5 pages, 1 figure", "summary": "The widespread adoption of online randomized controlled experiments (A/B Tests) for decision-making has created ongoing capacity constraints which necessitate interim analyses. As a consequence, platform users are increasingly motivated to use ad-hoc means of optimizing limited resources via peeking. Such processes, however, are error prone and often misaligned with end-of-experiment outcomes (e.g., inflated type-I error). We introduce a system based on Bayesian Predictive Probabilities that enable us to perform interim analyses without compromising fidelity of the experiment; This idea has been widely utilized in applications outside of the technology domain to more efficiently make decisions in experiments. Motivated by at-scale deployment within an experimentation platform, we demonstrate how predictive probabilities can be estimated without numerical integration techniques and recommend systems to study its properties at scale as an ongoing health check, along with system design recommendations - all on experiment data from Instagram - to demonstrate practical benefits that it enables."}
{"id": "2511.05927", "categories": ["cs.CY", "cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05927", "abs": "https://arxiv.org/abs/2511.05927", "authors": ["Mohammad Rashed Albous", "Melodena Stephens", "Odeh Rashed Al-Jayyousi"], "title": "Artificial intelligence and the Gulf Cooperation Council workforce adapting to the future of work", "comment": null, "summary": "The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation Council (GCC) raises a central question: are investments in compute infrastructure matched by an equally robust build-out of skills, incentives, and governance? Grounded in socio-technical systems (STS) theory, this mixed-methods study audits workforce preparedness across Kingdom of Saudi Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman. We combine term frequency--inverse document frequency (TF--IDF) analysis of six national AI strategies (NASs), an inventory of 47 publicly disclosed AI initiatives (January 2017--April 2025), paired case studies, the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data & Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix linking oil-revenue slack (technical capacity) to regulatory coherence (social alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI 0.58--0.83) exhibit joint social--technical design; country-level indices span 0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under our modeled conditions, regulatory convergence plausibly binds outcomes more than fiscal capacity: fragmented rules can offset high oil revenues, while harmonized standards help preserve progress under austerity. We also identify an emerging two-track talent system, research elites versus rapidly trained practitioners, that risks labor-market bifurcation without bridging mechanisms. By extending STS inquiry to oil-rich, state-led economies, the study refines theory and sets a research agenda focused on longitudinal coupling metrics, ethnographies of coordination, and outcome-based performance indicators."}
{"id": "2511.05625", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05625", "abs": "https://arxiv.org/abs/2511.05625", "authors": ["Thomas J McKenna", "Ingvill Rasmussen", "Sten Ludvigsen", "Avivit Arvatz", "Christa Asterhan", "Gaowei Chen", "Julie Cohen", "Michele Flammia", "Dongkeun Han", "Emma Hayward", "Heather Hill", "Yifat Kolikant", "Helen Lehndorf", "Kexin Li", "Lindsay Clare Matsumura", "Henrik Tjønn", "Pengjin Wang", "Rupert Wegerif"], "title": "Report from Workshop on Dialogue alongside Artificial Intelligence", "comment": "Report from the Workshop on Dialogue alongside Artificial Intelligence (2025)", "summary": "Educational dialogue -the collaborative exchange of ideas through talk- is widely recognized as a catalyst for deeper learning and critical thinking in and across contexts. At the same time, artificial intelligence (AI) has rapidly emerged as a powerful force in education, with the potential to address major challenges, personalize learning, and innovate teaching practices. However, these advances come with significant risks: rapid AI development can undermine human agency, exacerbate inequities, and outpace our capacity to guide its use with sound policy. Human learning presupposes cognitive efforts and social interaction (dialogues). In response to this evolving landscape, an international workshop titled \"Educational Dialogue: Moving Thinking Forward\" convened 19 leading researchers from 11 countries in Cambridge (September 1-3, 2025) to examine the intersection of AI and educational dialogue. This AI-focused strand of the workshop centered on three critical questions: (1) When is AI truly useful in education, and when might it merely replace human effort at the expense of learning? (2) Under what conditions can AI use lead to better dialogic teaching and learning? (3) Does the AI-human partnership risk outpacing and displacing human educational work, and what are the implications? These questions framed two days of presentations and structured dialogue among participants."}
{"id": "2511.06600", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.06600", "abs": "https://arxiv.org/abs/2511.06600", "authors": ["Hamed Sajadinia", "Zhuo Feng"], "title": "HyperEF 2.0: Spectral Hypergraph Coarsening via Krylov Subspace Expansion and Resistance-based Local Clustering", "comment": "Accepted for publication at the IEEE/ACM International Conference on Computer-Aided Design (ICCAD) 2025", "summary": "This paper introduces HyperEF 2.0, a scalable framework for spectral coarsening and clustering of large-scale hypergraphs through hyperedge effective resistances, aiming to decompose hypergraphs into multiple node clusters with a small number of inter-cluster hyperedges. Building on the recent HyperEF framework, our approach offers three primary contributions. Specifically, first, by leveraging the expanded Krylov subspace exploiting both clique and star expansions of hyperedges, we can significantly improve the approximation accuracy of effective resistances. Second, we propose a resistance-based local clustering scheme for merging small isolated nodes into nearby clusters, yielding more balanced clusters with substantially improved conductance. Third, the proposed HyperEF 2.0 enables the integration of resistance-based hyperedge weighting and community detection into a multilevel hypergraph partitioning tool, achieving state-of-the-art performance. Extensive experiments on real-world VLSI benchmarks show that HyperEF 2.0 can more effectively coarsen hypergraphs without compromising their structural properties, while delivering much better solution quality (e.g. conductance) than the state-of-the-art hypergraph coarsening methods, such as HyperEF and HyperSF. Moreover, compared to leading hypergraph partitioners such as hMETIS, SpecPart, MedPart, and KaHyPar, our framework consistently achieves smaller cut sizes. In terms of runtime, HyperEF 2.0 attains up to a 4.5x speedup over the latest flow-based local clustering algorithm, HyperSF, demonstrating both superior efficiency and partitioning quality."}
{"id": "2511.05512", "categories": ["econ.GN", "econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.05512", "abs": "https://arxiv.org/abs/2511.05512", "authors": ["Vladislav Virtonen"], "title": "Estimating the Impact of the Bitcoin Halving on Its Price Using Synthetic Control", "comment": "74 pages, 33 figures", "summary": "The third Bitcoin halving that took place in May 2020 cut down the mining reward from 12.5 to 6.25 BTC per block and thus slowed down the rate of issuance of new Bitcoins, making it more scarce. The fourth and most recent halving happened in April 2024, cutting the block reward further to 3.125 BTC. If the demand did not decrease simultaneously after these halvings, then the neoclassical economic theory posits that the price of Bitcoin should have increased due to the halving. But did it, in fact, increase for that reason, or is this a post hoc fallacy? This paper uses synthetic control to construct a weighted Bitcoin that is different from its counterpart in one aspect - it did not undergo halving. Comparing the price trajectory of the actual and the simulated Bitcoins, I find evidence of a positive effect of the 2024 Bitcoin halving on its price three months later. The magnitude of this effect is one fifth of the total percentage change in the price of Bitcoin during the study period - from April 2, 2023, to July 21, 2024 (17 months). The second part of the study fails to obtain a statistically significant and robust causal estimate of the effect of the 2020 Bitcoin halving on Bitcoin's price. This is the first paper analyzing the effect of halving causally, building on the existing body of correlational research."}
{"id": "2511.05809", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05809", "abs": "https://arxiv.org/abs/2511.05809", "authors": ["Yu Chen", "Botao He", "Yuemin Mao", "Arthur Jakobsson", "Jeffrey Ke", "Yiannis Aloimonos", "Guanya Shi", "Howie Choset", "Jiayuan Mao", "Jeffrey Ichnowski"], "title": "Adversarial Game-Theoretic Algorithm for Dexterous Grasp Synthesis", "comment": "Submitted to ICRA 2026", "summary": "For many complex tasks, multi-finger robot hands are poised to revolutionize how we interact with the world, but reliably grasping objects remains a significant challenge. We focus on the problem of synthesizing grasps for multi-finger robot hands that, given a target object's geometry and pose, computes a hand configuration. Existing approaches often struggle to produce reliable grasps that sufficiently constrain object motion, leading to instability under disturbances and failed grasps. A key reason is that during grasp generation, they typically focus on resisting a single wrench, while ignoring the object's potential for adversarial movements, such as escaping. We propose a new grasp-synthesis approach that explicitly captures and leverages the adversarial object motion in grasp generation by formulating the problem as a two-player game. One player controls the robot to generate feasible grasp configurations, while the other adversarially controls the object to seek motions that attempt to escape from the grasp. Simulation experiments on various robot platforms and target objects show that our approach achieves a success rate of 75.78%, up to 19.61% higher than the state-of-the-art baseline. The two-player game mechanism improves the grasping success rate by 27.40% over the method without the game formulation. Our approach requires only 0.28-1.04 seconds on average to generate a grasp configuration, depending on the robot platform, making it suitable for real-world deployment. In real-world experiments, our approach achieves an average success rate of 85.0% on ShadowHand and 87.5% on LeapHand, which confirms its feasibility and effectiveness in real robot setups."}
{"id": "2511.05900", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05900", "abs": "https://arxiv.org/abs/2511.05900", "authors": ["Ruoyu Lin", "Gennaro Notomista", "Magnus Egerstedt"], "title": "Disentangled Control of Multi-Agent Systems", "comment": "This work has been submitted to IEEE Transactions on Control of Network Systems for possible publication", "summary": "This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments."}
{"id": "2511.05900", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05900", "abs": "https://arxiv.org/abs/2511.05900", "authors": ["Ruoyu Lin", "Gennaro Notomista", "Magnus Egerstedt"], "title": "Disentangled Control of Multi-Agent Systems", "comment": "This work has been submitted to IEEE Transactions on Control of Network Systems for possible publication", "summary": "This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments."}
{"id": "2511.05854", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05854", "abs": "https://arxiv.org/abs/2511.05854", "authors": ["Zepeng Bao", "Shen Zhou", "Qiankun Pi", "Jianhao Chen", "Mayi Xu", "Ming Zhong", "Yuanyuan Zhu", "Tieyun Qian"], "title": "Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and Proactive Correction for Hallucination Detection", "comment": null, "summary": "Hallucination in large language models (LLMs) remains a critical barrier to their safe deployment. Existing tool-augmented hallucination detection methods require pre-defined fixed verification strategies, which are crucial to the quality and effectiveness of tool calls. Some methods directly employ powerful closed-source LLMs such as GPT-4 as detectors, which are effective but too costly. To mitigate the cost issue, some methods adopt the teacher-student architecture and finetune open-source small models as detectors via agent tuning. However, these methods are limited by fixed strategies. When faced with a dynamically changing execution environment, they may lack adaptability and inappropriately call tools, ultimately leading to detection failure. To address the problem of insufficient strategy adaptability, we propose the innovative ``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an efficient student model with the dynamic learning and proactive correction capabilities of the teacher model. Specifically, our method formulates the hallucination detection problem as a dynamic strategy learning problem. We first employ a teacher model to generate trajectories within the dynamic learning loop and dynamically adjust the strategy based on execution failures. We then distill this dynamic planning capability into an efficient student model via agent tuning. Finally, during strategy execution, the student model adopts a proactive correction mechanism, enabling it to propose, review, and optimize its own verification strategies before execution. We demonstrate through experiments on three challenging benchmarks that our LEAP-tuned model outperforms existing state-of-the-art methods."}
{"id": "2511.05555", "categories": ["cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05555", "abs": "https://arxiv.org/abs/2511.05555", "authors": ["C. Bowman Kerbage"], "title": "Deception Decoder: Proposing a Human-Focused Framework for Identifying AI-Generated Content on Social Media", "comment": null, "summary": "Generative AI (GenAI) poses a substantial threat to the integrity of information within the contemporary public sphere, which increasingly relies on social media platforms as intermediaries for news consumption. At present, most research efforts are directed toward automated and machine learning-based detection methods, despite growing concerns regarding false positives, social and political biases, and susceptibility to circumvention. This dissertation instead adopts a human-centred approach. It proposes the Deception Decoder; a multimodal, systematic, and topological framework designed to support general users in identifying AI-generated misinformation and disinformation across text, image, and video. The framework was developed through a comparative synthesis of existing models, supplemented by a content analysis of GenAI-video, and refined through a small-scale focus group session. While initial testing indicates promising improvements, further research is required to confirm its generalisability across user groups, and sustained effectiveness over time."}
{"id": "2511.07280", "categories": ["econ.GN", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07280", "abs": "https://arxiv.org/abs/2511.07280", "authors": ["Kevin Zielnicki", "Guy Aridor", "Aurélien Bibaut", "Allen Tran", "Winston Chou", "Nathan Kallus"], "title": "The Value of Personalized Recommendations: Evidence from Netflix", "comment": null, "summary": "Personalized recommendation systems shape much of user choice online, yet their targeted nature makes separating out the value of recommendation and the underlying goods challenging. We build a discrete choice model that embeds recommendation-induced utility, low-rank heterogeneity, and flexible state dependence and apply the model to viewership data at Netflix. We exploit idiosyncratic variation introduced by the recommendation algorithm to identify and separately value these components as well as to recover model-free diversion ratios that we can use to validate our structural model. We use the model to evaluate counterfactuals that quantify the incremental engagement generated by personalized recommendations. First, we show that replacing the current recommender system with a matrix factorization or popularity-based algorithm would lead to 4% and 12% reduction in engagement, respectively, and decreased consumption diversity. Second, most of the consumption increase from recommendations comes from effective targeting, not mechanical exposure, with the largest gains for mid-popularity goods (as opposed to broadly appealing or very niche goods)."}
{"id": "2511.06999", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.06999", "abs": "https://arxiv.org/abs/2511.06999", "authors": ["Jessica Renz", "Frederik Witt", "Iain G. Johnston"], "title": "An Algebraic Approach to Evolutionary Accumulation Models", "comment": null, "summary": "We present an algebraic approach to evolutionary accumulation modelling (EvAM). EvAM is concerned with learning and predicting the order in which evolutionary features accumulate over time. Our approach is complementary to the more common optimisation-based inference methods used in this field. Namely, we first use the natural underlying polynomial structure of the evolutionary process to define a semi-algebraic set of candidate parameters consistent with a given data set before maximising the likelihood function. We consider explicit examples and show that this approach is compatible with the solutions given by various statistical evolutionary accumulation models. Furthermore, we discuss the additional information of our algebraic model relative to these models."}
{"id": "2511.05627", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05627", "abs": "https://arxiv.org/abs/2511.05627", "authors": ["Sabik Aftahee", "A. F. M. Farhad", "Arpita Mallik", "Ratnajit Dhar", "Jawadul Karim", "Nahiyan Bin Noor", "Ishmam Ahmed Solaiman"], "title": "Assessing the Reliability of Large Language Models in the Bengali Legal Context: A Comparative Evaluation Using LLM-as-Judge and Legal Experts", "comment": null, "summary": "Accessing legal help in Bangladesh is hard. People face high fees, complex legal language, a shortage of lawyers, and millions of unresolved court cases. Generative AI models like OpenAI GPT-4.1 Mini, Gemini 2.0 Flash, Meta Llama 3 70B, and DeepSeek R1 could potentially democratize legal assistance by providing quick and affordable legal advice. In this study, we collected 250 authentic legal questions from the Facebook group \"Know Your Rights,\" where verified legal experts regularly provide authoritative answers. These questions were subsequently submitted to four four advanced AI models and responses were generated using a consistent, standardized prompt. A comprehensive dual evaluation framework was employed, in which a state-of-the-art LLM model served as a judge, assessing each AI-generated response across four critical dimensions: factual accuracy, legal appropriateness, completeness, and clarity. Following this, the same set of questions was evaluated by three licensed Bangladeshi legal professionals according to the same criteria. In addition, automated evaluation metrics, including BLEU scores, were applied to assess response similarity. Our findings reveal a complex landscape where AI models frequently generate high-quality, well-structured legal responses but also produce dangerous misinformation, including fabricated case citations, incorrect legal procedures, and potentially harmful advice. These results underscore the critical need for rigorous expert validation and comprehensive safeguards before AI systems can be safely deployed for legal consultation in Bangladesh."}
{"id": "2511.06747", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06747", "abs": "https://arxiv.org/abs/2511.06747", "authors": ["Anu Kuncheria", "Joan L. Walker", "Jane Macfarlane"], "title": "Beyond Centrality: Understanding Urban Street Network Typologies Through Intersection Patterns", "comment": null, "summary": "The structure of road networks plays a pivotal role in shaping transportation dynamics. It also provides insights into how drivers experience city streets and helps uncover each urban environment's unique characteristics and challenges. Consequently, characterizing cities based on their road network patterns can facilitate the identification of similarities and differences, informing collaborative traffic management strategies, particularly at a regional scale. While previous studies have investigated global network patterns for cities, they have often overlooked detailed characterizations within a single large urban region. Additionally, most existing research uses metrics like degree, centrality, orientation, etc., and misses the nuances of street networks at the intersection level, specifically the geometric angles formed by links at intersections, which could offer a more refined feature for characterization. To address these gaps, this study examines over 100 cities in the San Francisco Bay Area. We introduce a novel metric for classifying intersections, distinguishing between different types of 3-way and 4-way intersections based on the angles formed at the intersections. Through the application of clustering algorithms in machine learning, we have identified three distinct typologies - grid, orthogonal, and organic cities - within the San Francisco Bay Area. We demonstrate the effectiveness of the metric in capturing the differences between cities based on street and intersection patterns. The typologies generated in this study could offer valuable support for city planners and policymakers in crafting a range of practical strategies tailored to the complexities of each city's road network, covering aspects such as evacuation plans, traffic signage placements, and traffic signal control."}
{"id": "2511.05725", "categories": ["stat.AP", "econ.EM"], "pdf": "https://arxiv.org/pdf/2511.05725", "abs": "https://arxiv.org/abs/2511.05725", "authors": ["RJ Waken", "Fengxian Wang", "Sarah A. Eisenstein", "Tim McBride", "Kim Johnson", "Karen Joynt-Maddox"], "title": "Multilevel non-linear interrupted time series analysis", "comment": null, "summary": "Recent advances in interrupted time series analysis permit characterization of a typical non-linear interruption effect through use of generalized additive models. Concurrently, advances in latent time series modeling allow efficient Bayesian multilevel time series models. We propose to combine these concepts with a hierarchical model selection prior to characterize interruption effects with a multilevel structure, encouraging parsimony and partial pooling while incorporating meaningful variability in causal effects across subpopulations of interest, while allowing poststratification. These models are demonstrated with three applications: 1) the effect of the introduction of the prostate specific antigen test on prostate cancer diagnosis rates by race and age group, 2) the change in stroke or trans-ischemic attack hospitalization rates across Medicare beneficiaries by rurality in the months after the start of the COVID-19 pandemic, and 3) the effect of Medicaid expansion in Missouri on the proportion of inpatient hospitalizations discharged with Medicaid as a primary payer by key age groupings and sex."}
{"id": "2511.05816", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05816", "abs": "https://arxiv.org/abs/2511.05816", "authors": ["Taku Okawara", "Ryo Nishibe", "Mao Kasano", "Kentaro Uno", "Kazuya Yoshida"], "title": "3D Mapping Using a Lightweight and Low-Power Monocular Camera Embedded inside a Gripper of Limbed Climbing Robots", "comment": "International Conference on Space Robotics (iSpaRo)", "summary": "Limbed climbing robots are designed to explore challenging vertical walls, such as the skylights of the Moon and Mars. In such robots, the primary role of a hand-eye camera is to accurately estimate 3D positions of graspable points (i.e., convex terrain surfaces) thanks to its close-up views. While conventional climbing robots often employ RGB-D cameras as hand-eye cameras to facilitate straightforward 3D terrain mapping and graspable point detection, RGB-D cameras are large and consume considerable power.\n  This work presents a 3D terrain mapping system designed for space exploration using limbed climbing robots equipped with a monocular hand-eye camera. Compared to RGB-D cameras, monocular cameras are more lightweight, compact structures, and have lower power consumption. Although monocular SLAM can be used to construct 3D maps, it suffers from scale ambiguity. To address this limitation, we propose a SLAM method that fuses monocular visual constraints with limb forward kinematics. The proposed method jointly estimates time-series gripper poses and the global metric scale of the 3D map based on factor graph optimization.\n  We validate the proposed framework through both physics-based simulations and real-world experiments. The results demonstrate that our framework constructs a metrically scaled 3D terrain map in real-time and enables autonomous grasping of convex terrain surfaces using a monocular hand-eye camera, without relying on RGB-D cameras. Our method contributes to scalable and energy-efficient perception for future space missions involving limbed climbing robots. See the video summary here: https://youtu.be/fMBrrVNKJfc"}
{"id": "2511.06011", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06011", "abs": "https://arxiv.org/abs/2511.06011", "authors": ["Tong Zhou", "Yubing Li"], "title": "Parameter Recovery from Tangential Interpolations for Systems with an LFT Structure", "comment": "15 pages, 3 figures, 1 table", "summary": "This paper investigates how to recover parameters of a linear time invariant system from values and derivatives of its transfer function matrix, along several particular directions at a prescribed set of points in the complex plane, in which system matrices depend on these parameters through a linear fractional transformation. A necessary and sufficient condition is derived for a unique determination of these system parameters, which is expressed by a vector inequality. Under some particular situations, this condition reduces to a full column rank requirement on a constant matrix. Moreover, a method is given to recover system parameters from these values and derivatives, which is expressed by a vector linear equation with some rank constraints, for which various methods exist for finding its solutions. Robustness of the suggested recovery method is also clarified. A numerical example is given to illustrate characteristics of the suggested method, as well as effectiveness of derivative information introduction in parameter recovery, in which natural frequency and damping ratio are to be recovered for a transfer function."}
{"id": "2511.06011", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06011", "abs": "https://arxiv.org/abs/2511.06011", "authors": ["Tong Zhou", "Yubing Li"], "title": "Parameter Recovery from Tangential Interpolations for Systems with an LFT Structure", "comment": "15 pages, 3 figures, 1 table", "summary": "This paper investigates how to recover parameters of a linear time invariant system from values and derivatives of its transfer function matrix, along several particular directions at a prescribed set of points in the complex plane, in which system matrices depend on these parameters through a linear fractional transformation. A necessary and sufficient condition is derived for a unique determination of these system parameters, which is expressed by a vector inequality. Under some particular situations, this condition reduces to a full column rank requirement on a constant matrix. Moreover, a method is given to recover system parameters from these values and derivatives, which is expressed by a vector linear equation with some rank constraints, for which various methods exist for finding its solutions. Robustness of the suggested recovery method is also clarified. A numerical example is given to illustrate characteristics of the suggested method, as well as effectiveness of derivative information introduction in parameter recovery, in which natural frequency and damping ratio are to be recovered for a transfer function."}
{"id": "2511.05874", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05874", "abs": "https://arxiv.org/abs/2511.05874", "authors": ["Haoran Xue", "Gias Uddin", "Song Wang"], "title": "An Empirical Study of Reasoning Steps in Thinking Code LLMs", "comment": null, "summary": "Thinking Large Language Models (LLMs) generate explicit intermediate reasoning traces before final answers, potentially improving transparency, interpretability, and solution accuracy for code generation. However, the quality of these reasoning chains remains underexplored. We present a comprehensive empirical study examining the reasoning process and quality of thinking LLMs for code generation. We evaluate six state-of-the-art reasoning LLMs (DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking, Gemini-2.5-Flash, and Qwen-QwQ) across 100 code generation tasks of varying difficulty from BigCodeBench. We quantify reasoning-chain structure through step counts and verbosity, conduct controlled step-budget adjustments, and perform a 21-participant human evaluation across three dimensions: efficiency, logical correctness, and completeness. Our step-count interventions reveal that targeted step increases can improve resolution rates for certain models/tasks, while modest reductions often preserve success on standard tasks, rarely on hard ones. Through systematic analysis, we develop a reasoning-problematic taxonomy, identifying completeness as the dominant failure mode. Task complexity significantly impacts reasoning quality; hard problems are substantially more prone to incompleteness than standard tasks. Our stability analysis demonstrates that thinking LLMs maintain consistent logical structures across computational effort levels and can self-correct previous errors. This study provides new insights into the strengths and limitations of current thinking LLMs in software engineering."}
{"id": "2511.05572", "categories": ["cs.CY", "cs.CE", "cs.CR", "cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05572", "abs": "https://arxiv.org/abs/2511.05572", "authors": ["Ivan Bergier"], "title": "AgriTrust: a Federated Semantic Governance Framework for Trusted Agricultural Data Sharing", "comment": null, "summary": "The potential of agricultural data (AgData) to drive efficiency and sustainability is stifled by the \"AgData Paradox\": a pervasive lack of trust and interoperability that locks data in silos, despite its recognized value. This paper introduces AgriTrust, a federated semantic governance framework designed to resolve this paradox. AgriTrust integrates a multi-stakeholder governance model, built on pillars of Data Sovereignty, Transparent Data Contracts, Equitable Value Sharing, and Regulatory Compliance, with a semantic digital layer. This layer is realized through the AgriTrust Core Ontology, a formal OWL ontology that provides a shared vocabulary for tokenization, traceability, and certification, enabling true semantic interoperability across independent platforms. A key innovation is a blockchain-agnostic, multi-provider architecture that prevents vendor lock-in. The framework's viability is demonstrated through case studies across three critical Brazilian supply chains: coffee (for EUDR compliance), soy (for mass balance), and beef (for animal tracking). The results show that AgriTrust successfully enables verifiable provenance, automates compliance, and creates new revenue streams for data producers, thereby transforming data sharing from a trust-based dilemma into a governed, automated operation. This work provides a foundational blueprint for a more transparent, efficient, and equitable agricultural data economy."}
{"id": "2511.05515", "categories": ["q-fin.GN", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05515", "abs": "https://arxiv.org/abs/2511.05515", "authors": ["T. Alexander Puutio"], "title": "The Breadth Premium: Measuring the Firm-level Impact of CEO Career Breadth", "comment": "Preprint version 0.3 - pending data validation and regression reruns", "summary": "Prevailing career and education systems continue to reward early specialization and deep expertise within narrow domains. While such depth promotes efficiency, it may also limit adaptability in complex and rapidly changing environments. Building on research showing that variability in training inputs enhances learning outcomes across cognitive and behavioral domains, this study explores whether the same principle applies to executive performance.\n  Using an original dataset of 650 CEOs leading firms that together represent roughly 85% of US market capitalization, we construct a composite Breadth Index capturing cross-domain educational and professional breadth. Preliminary analyses reveal that firms led by higher-breadth CEOs outperform their industry peers by an average of 9.8 percentage points over a three-year window. Regression results indicate that each one-point increase on the five-point Range Index corresponds to a 1.8-point gain in abnormal returns (p < 0.03), with effects remaining robust across industries, firm sizes, and CEO age groups.\n  These early findings suggest that leadership breadth, defined as experience spanning multiple functions, disciplines, and sectors, is positively associated with firm-level performance. While the dataset remains under validation, the pattern observed supports the emerging view that as specialization deepens, the marginal value of lateral insight rises. Breadth, in this light, functions as a form of adaptive capital; it enhances leaders' capacity for integrative reasoning, organizational translation, and strategic flexibility in uncertain environments."}
{"id": "2511.07038", "categories": ["stat.AP", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.07038", "abs": "https://arxiv.org/abs/2511.07038", "authors": ["Kizito Salako", "Rabiu Tsoho Muhammad"], "title": "Conservative Software Reliability Assessments Using Collections of Bayesian Inference Problems", "comment": null, "summary": "When using Bayesian inference to support conservative software reliability assessments, it is useful to consider a collection of Bayesian inference problems, with the aim of determining the worst-case value (from this collection) for a posterior predictive probability that characterizes how reliable the software is. Using a Bernoulli process to model the occurrence of software failures, we explicitly determine (from collections of Bayesian inference problems) worst-case posterior predictive probabilities of the software operating without failure in the future. We deduce asymptotic properties of these conservative posterior probabilities and their priors, and illustrate how to use these results in assessments of safety-critical software. This work extends robust Bayesian inference results and so-called conservative Bayesian inference methods."}
{"id": "2511.05713", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05713", "abs": "https://arxiv.org/abs/2511.05713", "authors": ["Henrique S. Xavier", "Beatriz Rocha", "Diogo Cortiz"], "title": "Who shapes Web standards? Uncovering the main topics of interest in the W3C", "comment": "9 pages, 11 figures, 1 table", "summary": "This paper identifies the primary topics of interest of organizations participating in the World Wide Web Consortium (W3C), the leading standards body for the Web. Using publicly available data from the W3C website, we analyze the participation of member organizations in W3C groups, treating the number of representatives allocated to each group as a proxy for their interests. By applying topic modeling and similarity analysis to these participation patterns, we uncover clusters of related groups and shared priorities among organizations. The results reveal five prominent areas of focus -- Web, Ads & Privacy; High Performance; Credentials & Web of Things; Accessibility; and Payments -- and show that large enterprises, particularly those based in the United States, dominate participation in core Web development and advertising-related topics, while Japanese organizations are more active in the Web of Things. These findings offer insights into how various stakeholders influence the standardization process and how the Web may evolve in the coming years."}
{"id": "2511.06982", "categories": ["cs.SI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.06982", "abs": "https://arxiv.org/abs/2511.06982", "authors": ["Ankit Mazumder", "Srikanta Bedathur"], "title": "CGLE: Class-label Graph Link Estimator for Link Prediction", "comment": "Paper accepted at the IEEE International Conference on Data Mining (ICDM 2025)", "summary": "Link prediction is a pivotal task in graph mining with wide-ranging applications in social networks, recommendation systems, and knowledge graph completion. However, many leading Graph Neural Network (GNN) models often neglect the valuable semantic information aggregated at the class level. To address this limitation, this paper introduces CGLE (Class-label Graph Link Estimator), a novel framework designed to augment GNN-based link prediction models. CGLE operates by constructing a class-conditioned link probability matrix, where each entry represents the probability of a link forming between two node classes. This matrix is derived from either available ground-truth labels or from pseudo-labels obtained through clustering. The resulting class-based prior is then concatenated with the structural link embedding from a backbone GNN, and the combined representation is processed by a Multi-Layer Perceptron (MLP) for the final prediction. Crucially, CGLE's logic is encapsulated in an efficient preprocessing stage, leaving the computational complexity of the underlying GNN model unaffected. We validate our approach through extensive experiments on a broad suite of benchmark datasets, covering both homophilous and sparse heterophilous graphs. The results show that CGLE yields substantial performance gains over strong baselines such as NCN and NCNC, with improvements in HR@100 of over 10 percentage points on homophilous datasets like Pubmed and DBLP. On sparse heterophilous graphs, CGLE delivers an MRR improvement of over 4% on the Chameleon dataset. Our work underscores the efficacy of integrating global, data-driven semantic priors, presenting a compelling alternative to the pursuit of increasingly complex model architectures. Code to reproduce our findings is available at: https://github.com/data-iitd/cgle-icdm2025."}
{"id": "2511.05855", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05855", "abs": "https://arxiv.org/abs/2511.05855", "authors": ["Jiayu Zhou", "Qiwei Wu", "Jian Li", "Zhe Chen", "Xiaogang Xiong", "Renjing Xu"], "title": "Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills", "comment": "Accepted for the 40th Annual AAAI Conference on Artificial Intelligence (2026)", "summary": "Autonomous execution of long-horizon, contact-rich manipulation tasks traditionally requires extensive real-world data and expert engineering, posing significant cost and scalability challenges. This paper proposes a novel framework integrating hierarchical semantic decomposition, reinforcement learning (RL), visual language models (VLMs), and knowledge distillation to overcome these limitations. Complex tasks are decomposed into atomic skills, with RL-trained policies for each primitive exclusively in simulation. Crucially, our RL formulation incorporates explicit force constraints to prevent object damage during delicate interactions. VLMs perform high-level task decomposition and skill planning, generating diverse expert demonstrations. These are distilled into a unified policy via Visual-Tactile Diffusion Policy for end-to-end execution. We conduct comprehensive ablation studies exploring different VLM-based task planners to identify optimal demonstration generation pipelines, and systematically compare imitation learning algorithms for skill distillation. Extensive simulation experiments and physical deployment validate that our approach achieves policy learning for long-horizon manipulation without costly human demonstrations, while the VLM-guided atomic skill framework enables scalable generalization to diverse tasks."}
{"id": "2511.06026", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06026", "abs": "https://arxiv.org/abs/2511.06026", "authors": ["Yi Gao", "Xi Xiong", "Karl H. Johansson", "Li Jin"], "title": "Probe-and-Release Coordination of Platoons at Highway Bottlenecks with Unknown Parameters", "comment": "15 pages, 12 figures", "summary": "This paper considers coordination of platoons of connected and autonomous vehicles (CAVs) at mixed-autonomy bottlenecks in the face of three practically important factors, viz. time-varying traffic demand, random CAV platoon sizes, and capacity breakdowns. Platoon coordination is essential to smoothen the interaction between CAV platoons and non-CAV traffic. Based on a fluid queuing model, we develop a \"probe-and-release\" algorithm that simultaneously estimates environmental parameters and coordinates CAV platoons for traffic stabilization. We show that this algorithm ensures bounded estimation errors and bounded traffic queues. The proof builds on a Lyapunov function that jointly penalizes estimation errors and traffic queues and a drift argument for an embedded Markov process. We validate the proposed algorithm in a standard micro-simulation environment and compare against a representative deep reinforcement learning method in terms of control performance and computational efficiency."}
{"id": "2511.06026", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06026", "abs": "https://arxiv.org/abs/2511.06026", "authors": ["Yi Gao", "Xi Xiong", "Karl H. Johansson", "Li Jin"], "title": "Probe-and-Release Coordination of Platoons at Highway Bottlenecks with Unknown Parameters", "comment": "15 pages, 12 figures", "summary": "This paper considers coordination of platoons of connected and autonomous vehicles (CAVs) at mixed-autonomy bottlenecks in the face of three practically important factors, viz. time-varying traffic demand, random CAV platoon sizes, and capacity breakdowns. Platoon coordination is essential to smoothen the interaction between CAV platoons and non-CAV traffic. Based on a fluid queuing model, we develop a \"probe-and-release\" algorithm that simultaneously estimates environmental parameters and coordinates CAV platoons for traffic stabilization. We show that this algorithm ensures bounded estimation errors and bounded traffic queues. The proof builds on a Lyapunov function that jointly penalizes estimation errors and traffic queues and a drift argument for an embedded Markov process. We validate the proposed algorithm in a standard micro-simulation environment and compare against a representative deep reinforcement learning method in terms of control performance and computational efficiency."}
{"id": "2511.05883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05883", "abs": "https://arxiv.org/abs/2511.05883", "authors": ["Hehai Lin", "Hui Liu", "Shilei Cao", "Jing Li", "Haoliang Li", "Wenya Wang"], "title": "Unveiling Modality Bias: Automated Sample-Specific Analysis for Multimodal Misinformation Benchmarks", "comment": null, "summary": "Numerous multimodal misinformation benchmarks exhibit bias toward specific modalities, allowing detectors to make predictions based solely on one modality. While previous research has quantified bias at the dataset level or manually identified spurious correlations between modalities and labels, these approaches lack meaningful insights at the sample level and struggle to scale to the vast amount of online information. In this paper, we investigate the design for automated recognition of modality bias at the sample level. Specifically, we propose three bias quantification methods based on theories/views of different levels of granularity: 1) a coarse-grained evaluation of modality benefit; 2) a medium-grained quantification of information flow; and 3) a fine-grained causality analysis. To verify the effectiveness, we conduct a human evaluation on two popular benchmarks. Experimental results reveal three interesting findings that provide potential direction toward future research: 1)~Ensembling multiple views is crucial for reliable automated analysis; 2)~Automated analysis is prone to detector-induced fluctuations; and 3)~Different views produce a higher agreement on modality-balanced samples but diverge on biased ones."}
{"id": "2511.05597", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05597", "abs": "https://arxiv.org/abs/2511.05597", "authors": ["Francisco Caravaca", "Ángel Cuevas", "Rubén Cuevas"], "title": "From Prompts to Power: Measuring the Energy Footprint of LLM Inference", "comment": null, "summary": "The rapid expansion of Large Language Models (LLMs) has introduced unprecedented energy demands, extending beyond training to large-scale inference workloads that often dominate total lifecycle consumption. Deploying these models requires energy-intensive GPU infrastructure, and in some cases has even prompted plans to power data centers with nuclear energy. Despite this growing relevance, systematic analyses of inference energy consumption remain limited. In this work, we present a large-scale measurement-based study comprising over 32,500 measurements across 21 GPU configurations and 155 model architectures, from small open-source models to frontier systems. Using the vLLM inference engine, we quantify energy usage at the prompt level and identify how architectural and operational factors shape energy demand. Building on these insights, we develop a predictive model that accurately estimates inference energy consumption across unseen architectures and hardware, and implement it as a browser extension to raise awareness of the environmental impact of generative AI."}
{"id": "2511.05766", "categories": ["cs.AI", "cs.CL", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05766", "abs": "https://arxiv.org/abs/2511.05766", "authors": ["Felipe Valencia-Clavijo"], "title": "Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs", "comment": null, "summary": "Large language models (LLMs) are increasingly examined as both behavioral subjects and decision systems, yet it remains unclear whether observed cognitive biases reflect surface imitation or deeper probability shifts. Anchoring bias, a classic human judgment bias, offers a critical test case. While prior work shows LLMs exhibit anchoring, most evidence relies on surface-level outputs, leaving internal mechanisms and attributional contributions unexplored. This paper advances the study of anchoring in LLMs through three contributions: (1) a log-probability-based behavioral analysis showing that anchors shift entire output distributions, with controls for training-data contamination; (2) exact Shapley-value attribution over structured prompt fields to quantify anchor influence on model log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score integrating behavioral and attributional evidence across six open-source models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and Llama-2-7B, with attribution signaling that the anchors influence reweighting. Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability, suggesting scale may modulate sensitivity. Attributional effects, however, vary across prompt designs, underscoring fragility in treating LLMs as human substitutes. The findings demonstrate that anchoring bias in LLMs is robust, measurable, and interpretable, while highlighting risks in applied domains. More broadly, the framework bridges behavioral science, LLM safety, and interpretability, offering a reproducible path for evaluating other cognitive biases in LLMs."}
{"id": "2511.07353", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.07353", "abs": "https://arxiv.org/abs/2511.07353", "authors": ["Ruoyu Li", "Rob Deardon", "Na Li", "John Conly", "Jenine Leal"], "title": "Bayesian compartmental modelling of MRSA transmission within hospitals in Edmonton, Canada", "comment": null, "summary": "Methicillin-resistant Staphylococcus aureus (MRSA) is a bacterium that leads to severe infections in hospitalized patients. Previous epidemiological research has focused on MRSA transmission, but few studies have examined the influence of both hospital-acquired MRSA (HA-MRSA) and community-acquired MRSA (CA-MRSA) on MRSA spread in hospitals. In this study, we present a unique compartmental model for studying MRSA transmission patterns in hospitals in Edmonton, Alberta. The model consists of susceptible individuals, patients who have been colonized or infected with HA-MRSA or CA-MRSA, and isolated patients. We first use Bayesian inference with Markov chain Monte Carlo (MCMC) algorithms to estimate the posterior mean of parameters in the full model using data from hospitals in Edmonton. Then we develop multiple sub-models with varying assumptions about the origin of new MRSA colonization. We also estimate transmission rates in hospitals."}
{"id": "2511.05714", "categories": ["cs.CY", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05714", "abs": "https://arxiv.org/abs/2511.05714", "authors": ["Nicholas Generous", "Brian Cook", "Jason Pruet"], "title": "Preserving security in a world with powerful AI Considerations for the future Defense Architecture", "comment": null, "summary": "Advances in AI threaten to invalidate assumptions underpinning today's defense architecture. We argue that the current U.S. defense program of record, designed in an era before capable machine intelligence, cannot by itself preserve national security against rapidly emerging AI enabled threats. Instead, shoring up legacy systems must be coupled with entirely new elements of a defense architecture. We outline immediate steps to adapt the Department of Energy National Nuclear Security Administration National Laboratories to ensure agility and resilience in an era of powerful AI."}
{"id": "2511.07157", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.07157", "abs": "https://arxiv.org/abs/2511.07157", "authors": ["Francesco Zigliotto"], "title": "Past-aware game-theoretic centrality in complex contagion dynamics", "comment": null, "summary": "In this paper, we introduce past-aware game-theoretic centrality, a class of centrality measures that captures the collaborative contribution of nodes in a network, accounting for both uncertain and certain collaborators. A general framework for computing standard game-theoretic centrality is extended to the past-aware case. As an application, we develop a new heuristic for different versions of the influence maximization problems in complex contagion dynamics, which models processes requiring reinforcement from multiple neighbors to spread. A computationally efficient explicit formula for the corresponding past-aware centrality score is derived, leading to scalable algorithms for identifying the most influential nodes, which in most cases outperform the standard greedy approach in both efficiency and solution quality."}
{"id": "2511.05858", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05858", "abs": "https://arxiv.org/abs/2511.05858", "authors": ["Chuanyu Li", "Chaoyi Liu", "Daotan Wang", "Shuyu Zhang", "Lusong Li", "Zecui Zeng", "Fangchen Liu", "Jing Xu", "Rui Chen"], "title": "ViTaMIn-B: A Reliable and Efficient Visuo-Tactile Bimanual Manipulation Interface", "comment": null, "summary": "Handheld devices have opened up unprecedented opportunities to collect large-scale, high-quality demonstrations efficiently. However, existing systems often lack robust tactile sensing or reliable pose tracking to handle complex interaction scenarios, especially for bimanual and contact-rich tasks. In this work, we propose ViTaMIn-B, a more capable and efficient handheld data collection system for such tasks. We first design DuoTact, a novel compliant visuo-tactile sensor built with a flexible frame to withstand large contact forces during manipulation while capturing high-resolution contact geometry. To enhance the cross-sensor generalizability, we propose reconstructing the sensor's global deformation as a 3D point cloud and using it as the policy input. We further develop a robust, unified 6-DoF bimanual pose acquisition process using Meta Quest controllers, which eliminates the trajectory drift issue in common SLAM-based methods. Comprehensive user studies confirm the efficiency and high usability of ViTaMIn-B among novice and expert operators. Furthermore, experiments on four bimanual manipulation tasks demonstrate its superior task performance relative to existing systems."}
{"id": "2511.06063", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06063", "abs": "https://arxiv.org/abs/2511.06063", "authors": ["Wentao Tang", "Xiuzhen Ye"], "title": "Koopman Operator for Stability Analysis: Theory with a Linear--Radial Product Reproducing Kernel", "comment": "17 pages, 10 figures, submitted to L4DC 2026", "summary": "Koopman operator, as a fully linear representation of nonlinear dynamical systems, if well-defined on a reproducing kernel Hilbert space (RKHS), can be efficiently learned from data. For stability analysis and control-related problems, it is desired that the defining RKHS of the Koopman operator should account for both the stability of an equilibrium point (as a local property) and the regularity of the dynamics on the state space (as a global property). To this end, we show that by using the product kernel formed by the linear kernel and a Wendland radial kernel, the resulting RKHS is invariant under the action of Koopman operator (under certain smoothness conditions). Furthermore, when the equilibrium is asymptotically stable, the spectrum of Koopman operator is provably confined inside the unit circle, and escapes therefrom upon bifurcation. Thus, the learned Koopman operator with provable probabilistic error bound provides a stability certificate. In addition to numerical verification, we further discuss how such a fundamental spectrum--stability relation would be useful for Koopman-based control."}
{"id": "2511.06063", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06063", "abs": "https://arxiv.org/abs/2511.06063", "authors": ["Wentao Tang", "Xiuzhen Ye"], "title": "Koopman Operator for Stability Analysis: Theory with a Linear--Radial Product Reproducing Kernel", "comment": "17 pages, 10 figures, submitted to L4DC 2026", "summary": "Koopman operator, as a fully linear representation of nonlinear dynamical systems, if well-defined on a reproducing kernel Hilbert space (RKHS), can be efficiently learned from data. For stability analysis and control-related problems, it is desired that the defining RKHS of the Koopman operator should account for both the stability of an equilibrium point (as a local property) and the regularity of the dynamics on the state space (as a global property). To this end, we show that by using the product kernel formed by the linear kernel and a Wendland radial kernel, the resulting RKHS is invariant under the action of Koopman operator (under certain smoothness conditions). Furthermore, when the equilibrium is asymptotically stable, the spectrum of Koopman operator is provably confined inside the unit circle, and escapes therefrom upon bifurcation. Thus, the learned Koopman operator with provable probabilistic error bound provides a stability certificate. In addition to numerical verification, we further discuss how such a fundamental spectrum--stability relation would be useful for Koopman-based control."}
{"id": "2511.05931", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05931", "abs": "https://arxiv.org/abs/2511.05931", "authors": ["Hiroaki Hayashi", "Bo Pang", "Wenting Zhao", "Ye Liu", "Akash Gokul", "Srijan Bansal", "Caiming Xiong", "Semih Yavuz", "Yingbo Zhou"], "title": "Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement", "comment": null, "summary": "Large language model (LLM) based agents are increasingly used to tackle software engineering tasks that require multi-step reasoning and code modification, demonstrating promising yet limited performance. However, most existing LLM agents typically operate within static execution frameworks, lacking a principled mechanism to learn and self-improve from their own experience and past rollouts. As a result, their performance remains bounded by the initial framework design and the underlying LLM's capabilities. We propose Self-Abstraction from Grounded Experience (SAGE), a framework that enables agents to learn from their own task executions and refine their behavior through self-abstraction. After an initial rollout, the agent induces a concise plan abstraction from its grounded experience, distilling key steps, dependencies, and constraints. This learned abstraction is then fed back as contextual guidance, refining the agent's policy and supporting more structured, informed subsequent executions. Empirically, SAGE delivers consistent performance gains across diverse LLM backbones and agent architectures. Notably, it yields a 7.2% relative performance improvement over the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone. SAGE further achieves strong overall performance on SWE-Bench Verified benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent and OpenHands CodeAct agent framework, respectively."}
{"id": "2511.05613", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05613", "abs": "https://arxiv.org/abs/2511.05613", "authors": ["Anka Reuel", "Avijit Ghosh", "Jenny Chim", "Andrew Tran", "Yanan Long", "Jennifer Mickel", "Usman Gohar", "Srishti Yadav", "Pawan Sasanka Ammanamanchi", "Mowafak Allaham", "Hossein A. Rahmani", "Mubashara Akhtar", "Felix Friedrich", "Robert Scholz", "Michael Alexander Riegler", "Jan Batzner", "Eliya Habba", "Arushi Saxena", "Anastassia Kornilova", "Kevin Wei", "Prajna Soni", "Yohan Mathew", "Kevin Klyman", "Jeba Sania", "Subramanyam Sahoo", "Olivia Beyer Bruvik", "Pouya Sadeghi", "Sujata Goswami", "Angelina Wang", "Yacine Jernite", "Zeerak Talat", "Stella Biderman", "Mykel Kochenderfer", "Sanmi Koyejo", "Irene Solaiman"], "title": "Who Evaluates AI's Social Impacts? Mapping Coverage and Gaps in First and Third Party Evaluations", "comment": null, "summary": "Foundation models are increasingly central to high-stakes AI systems, and governance frameworks now depend on evaluations to assess their risks and capabilities. Although general capability evaluations are widespread, social impact assessments covering bias, fairness, privacy, environmental costs, and labor practices remain uneven across the AI ecosystem. To characterize this landscape, we conduct the first comprehensive analysis of both first-party and third-party social impact evaluation reporting across a wide range of model developers. Our study examines 186 first-party release reports and 183 post-release evaluation sources, and complements this quantitative analysis with interviews of model developers. We find a clear division of evaluation labor: first-party reporting is sparse, often superficial, and has declined over time in key areas such as environmental impact and bias, while third-party evaluators including academic researchers, nonprofits, and independent organizations provide broader and more rigorous coverage of bias, harmful content, and performance disparities. However, this complementarity has limits. Only model developers can authoritatively report on data provenance, content moderation labor, financial costs, and training infrastructure, yet interviews reveal that these disclosures are often deprioritized unless tied to product adoption or regulatory compliance. Our findings indicate that current evaluation practices leave major gaps in assessing AI's societal impacts, highlighting the urgent need for policies that promote developer transparency, strengthen independent evaluation ecosystems, and create shared infrastructure to aggregate and compare third-party evaluations in a consistent and accessible way."}
{"id": "2511.05927", "categories": ["cs.CY", "cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05927", "abs": "https://arxiv.org/abs/2511.05927", "authors": ["Mohammad Rashed Albous", "Melodena Stephens", "Odeh Rashed Al-Jayyousi"], "title": "Artificial intelligence and the Gulf Cooperation Council workforce adapting to the future of work", "comment": null, "summary": "The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation Council (GCC) raises a central question: are investments in compute infrastructure matched by an equally robust build-out of skills, incentives, and governance? Grounded in socio-technical systems (STS) theory, this mixed-methods study audits workforce preparedness across Kingdom of Saudi Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman. We combine term frequency--inverse document frequency (TF--IDF) analysis of six national AI strategies (NASs), an inventory of 47 publicly disclosed AI initiatives (January 2017--April 2025), paired case studies, the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data & Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix linking oil-revenue slack (technical capacity) to regulatory coherence (social alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI 0.58--0.83) exhibit joint social--technical design; country-level indices span 0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under our modeled conditions, regulatory convergence plausibly binds outcomes more than fiscal capacity: fragmented rules can offset high oil revenues, while harmonized standards help preserve progress under austerity. We also identify an emerging two-track talent system, research elites versus rapidly trained practitioners, that risks labor-market bifurcation without bridging mechanisms. By extending STS inquiry to oil-rich, state-led economies, the study refines theory and sets a research agenda focused on longitudinal coupling metrics, ethnographies of coordination, and outcome-based performance indicators."}
{"id": "2511.05764", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05764", "abs": "https://arxiv.org/abs/2511.05764", "authors": ["Samvrit Srinath", "Annapurna Vadaparty", "David H. Smith", "Leo Porter", "Daniel Zingaro"], "title": "Assessing Problem Decomposition in CS1 for the GenAI Era", "comment": null, "summary": "Problem decomposition--the ability to break down a large task into smaller, well-defined components--is a critical skill for effectively designing and creating large programs, but it is often not included in introductory computer science curricula. With the rise of generative AI (GenAI), students even at the introductory level are able to generate large quantities of code, and it is becoming increasingly important to equip them with the ability to decompose problems. There is not yet a consensus among educators on how to best teach and assess the skill of decomposition, particularly in introductory computing. This practitioner paper details the development of questions to assess the skill of problem decomposition, and impressions about how these questions were received by students. A challenge unique to problem decomposition questions is their necessarily lengthy context, and we detail our approach to addressing this problem using Question Suites: scaffolded sequences of questions that help students understand a question's context before attempting to decompose it. We then describe the use of open-ended drawing of decomposition diagrams as another form of assessment. We outline the learning objectives used to design our questions and describe how we addressed challenges encountered in early iterations. We present our decomposition assessment materials and reflections on them for educators who wish to teach problem decomposition to beginner programmers."}
{"id": "2511.05555", "categories": ["cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05555", "abs": "https://arxiv.org/abs/2511.05555", "authors": ["C. Bowman Kerbage"], "title": "Deception Decoder: Proposing a Human-Focused Framework for Identifying AI-Generated Content on Social Media", "comment": null, "summary": "Generative AI (GenAI) poses a substantial threat to the integrity of information within the contemporary public sphere, which increasingly relies on social media platforms as intermediaries for news consumption. At present, most research efforts are directed toward automated and machine learning-based detection methods, despite growing concerns regarding false positives, social and political biases, and susceptibility to circumvention. This dissertation instead adopts a human-centred approach. It proposes the Deception Decoder; a multimodal, systematic, and topological framework designed to support general users in identifying AI-generated misinformation and disinformation across text, image, and video. The framework was developed through a comparative synthesis of existing models, supplemented by a content analysis of GenAI-video, and refined through a small-scale focus group session. While initial testing indicates promising improvements, further research is required to confirm its generalisability across user groups, and sustained effectiveness over time."}
{"id": "2511.05886", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05886", "abs": "https://arxiv.org/abs/2511.05886", "authors": ["Lei Shi", "Yongju Kim", "Xinzhi Zhong", "Wissam Kontar", "Qichao Liu", "Soyoung Ahn"], "title": "Fair and Safe: A Real-Time Hierarchical Control Framework for Intersections", "comment": null, "summary": "Ensuring fairness in the coordination of connected and automated vehicles at intersections is essential for equitable access, social acceptance, and long-term system efficiency, yet it remains underexplored in safety-critical, real-time traffic control. This paper proposes a fairness-aware hierarchical control framework that explicitly integrates inequity aversion into intersection management. At the top layer, a centralized allocation module assigns control authority (i.e., selects a single vehicle to execute its trajectory) by maximizing a utility that accounts for waiting time, urgency, control history, and velocity deviation. At the bottom layer, the authorized vehicle executes a precomputed trajectory using a Linear Quadratic Regulator (LQR) and applies a high-order Control Barrier Function (HOCBF)-based safety filter for real-time collision avoidance. Simulation results across varying traffic demands and demand distributions demonstrate that the proposed framework achieves near-perfect fairness, eliminates collisions, reduces average delay, and maintains real-time feasibility. These results highlight that fairness can be systematically incorporated without sacrificing safety or performance, enabling scalable and equitable coordination for future autonomous traffic systems."}
{"id": "2511.06084", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06084", "abs": "https://arxiv.org/abs/2511.06084", "authors": ["Juan Augusto Paredes Salazar", "Ankit Goel"], "title": "Model-free Adaptive Output Feedback Vibration Suppression in a Cantilever Beam", "comment": "16 pages, 14 figures, to be presented at Scitech 2026", "summary": "This paper presents a model-free adaptive control approach to suppress vibrations in a cantilevered beam excited by an unknown disturbance. The cantilevered beam under harmonic excitation is modeled using a lumped parameter approach. Based on retrospective cost optimization, a sampled-data adaptive controller is developed to suppress vibrations caused by external disturbances. Both displacement and acceleration measurements are considered for feedback. Since acceleration measurements are more sensitive to spillover, which excites higher frequency modes, a filter is developed to extract key displacement information from the acceleration data and enhance suppression performance. The vibration suppression performance is compared using both displacement and acceleration measurements."}
{"id": "2511.06084", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06084", "abs": "https://arxiv.org/abs/2511.06084", "authors": ["Juan Augusto Paredes Salazar", "Ankit Goel"], "title": "Model-free Adaptive Output Feedback Vibration Suppression in a Cantilever Beam", "comment": "16 pages, 14 figures, to be presented at Scitech 2026", "summary": "This paper presents a model-free adaptive control approach to suppress vibrations in a cantilevered beam excited by an unknown disturbance. The cantilevered beam under harmonic excitation is modeled using a lumped parameter approach. Based on retrospective cost optimization, a sampled-data adaptive controller is developed to suppress vibrations caused by external disturbances. Both displacement and acceleration measurements are considered for feedback. Since acceleration measurements are more sensitive to spillover, which excites higher frequency modes, a filter is developed to extract key displacement information from the acceleration data and enhance suppression performance. The vibration suppression performance is compared using both displacement and acceleration measurements."}
{"id": "2511.05951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05951", "abs": "https://arxiv.org/abs/2511.05951", "authors": ["Qi Wang", "Hongzhi Zhang", "Jia Fu", "Kai Fu", "Yahui Liu", "Tinghai Zhang", "Chenxi Sun", "Gangwei Jiang", "Jingyi Tang", "Xingguang Ji", "Yang Yue", "Jingyuan Zhang", "Fuzheng Zhang", "Kun Gai", "Guorui Zhou"], "title": "Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling", "comment": "20 pages, 7 figures", "summary": "Despite the proliferation of powerful agentic models, the lack of critical post-training details hinders the development of strong counterparts in the open-source community. In this study, we present a comprehensive and fully open-source pipeline for training a high-performance agentic model for interacting with external tools and environments, named Klear-Qwen3-AgentForge, starting from the Qwen3-8B base model. We design effective supervised fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement learning (RL) to unlock the potential for multiple diverse agentic tasks. We perform exclusive experiments on various agentic benchmarks in both tool use and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art performance among LLMs of similar size and remains competitive with significantly larger models."}
{"id": "2511.05625", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05625", "abs": "https://arxiv.org/abs/2511.05625", "authors": ["Thomas J McKenna", "Ingvill Rasmussen", "Sten Ludvigsen", "Avivit Arvatz", "Christa Asterhan", "Gaowei Chen", "Julie Cohen", "Michele Flammia", "Dongkeun Han", "Emma Hayward", "Heather Hill", "Yifat Kolikant", "Helen Lehndorf", "Kexin Li", "Lindsay Clare Matsumura", "Henrik Tjønn", "Pengjin Wang", "Rupert Wegerif"], "title": "Report from Workshop on Dialogue alongside Artificial Intelligence", "comment": "Report from the Workshop on Dialogue alongside Artificial Intelligence (2025)", "summary": "Educational dialogue -the collaborative exchange of ideas through talk- is widely recognized as a catalyst for deeper learning and critical thinking in and across contexts. At the same time, artificial intelligence (AI) has rapidly emerged as a powerful force in education, with the potential to address major challenges, personalize learning, and innovate teaching practices. However, these advances come with significant risks: rapid AI development can undermine human agency, exacerbate inequities, and outpace our capacity to guide its use with sound policy. Human learning presupposes cognitive efforts and social interaction (dialogues). In response to this evolving landscape, an international workshop titled \"Educational Dialogue: Moving Thinking Forward\" convened 19 leading researchers from 11 countries in Cambridge (September 1-3, 2025) to examine the intersection of AI and educational dialogue. This AI-focused strand of the workshop centered on three critical questions: (1) When is AI truly useful in education, and when might it merely replace human effort at the expense of learning? (2) Under what conditions can AI use lead to better dialogic teaching and learning? (3) Does the AI-human partnership risk outpacing and displacing human educational work, and what are the implications? These questions framed two days of presentations and structured dialogue among participants."}
{"id": "2511.05512", "categories": ["econ.GN", "econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.05512", "abs": "https://arxiv.org/abs/2511.05512", "authors": ["Vladislav Virtonen"], "title": "Estimating the Impact of the Bitcoin Halving on Its Price Using Synthetic Control", "comment": "74 pages, 33 figures", "summary": "The third Bitcoin halving that took place in May 2020 cut down the mining reward from 12.5 to 6.25 BTC per block and thus slowed down the rate of issuance of new Bitcoins, making it more scarce. The fourth and most recent halving happened in April 2024, cutting the block reward further to 3.125 BTC. If the demand did not decrease simultaneously after these halvings, then the neoclassical economic theory posits that the price of Bitcoin should have increased due to the halving. But did it, in fact, increase for that reason, or is this a post hoc fallacy? This paper uses synthetic control to construct a weighted Bitcoin that is different from its counterpart in one aspect - it did not undergo halving. Comparing the price trajectory of the actual and the simulated Bitcoins, I find evidence of a positive effect of the 2024 Bitcoin halving on its price three months later. The magnitude of this effect is one fifth of the total percentage change in the price of Bitcoin during the study period - from April 2, 2023, to July 21, 2024 (17 months). The second part of the study fails to obtain a statistically significant and robust causal estimate of the effect of the 2020 Bitcoin halving on Bitcoin's price. This is the first paper analyzing the effect of halving causally, building on the existing body of correlational research."}
{"id": "2511.05819", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05819", "abs": "https://arxiv.org/abs/2511.05819", "authors": ["Nina Lutz", "Benjamin Olsen", "Weishung Liu", "E. Glen Weyl"], "title": "(Working Paper) Good Faith Design: Religion as a Resource for Technologists", "comment": null, "summary": "Previous work has found a lack of research in HCI on religion, partly driven by misunderstandings of values and practices between religious and technical communities. To bridge this divide in an empirically rigorous way, we conducted an interview study with 48 religious people and/or experts from 11 faiths, and we document how religious people experience, understand, and imagine technologies. We show that religious stakeholders find non-neutral secular embeddings in technologies and the firms and people that design them, and how these manifest in unintended harms for religious and nonreligious users. Our findings reveal how users navigate technoreligious practices with religiously informed mental models and what they desire from technologies. Informed by this, we distill six design values -- wonder, humility, space, embodiedness, community, and eternity -- to guide technologists in considering and leveraging religion as an additional, valid sociocultural resource when designing for a holistic user. We further spell out directions for future research."}
{"id": "2511.05889", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05889", "abs": "https://arxiv.org/abs/2511.05889", "authors": ["Zeyuan Feng", "Haimingyue Zhang", "Somil Bansal"], "title": "From Words to Safety: Language-Conditioned Safety Filtering for Robot Navigation", "comment": null, "summary": "As robots become increasingly integrated into open-world, human-centered environments, their ability to interpret natural language instructions and adhere to safety constraints is critical for effective and trustworthy interaction. Existing approaches often focus on mapping language to reward functions instead of safety specifications or address only narrow constraint classes (e.g., obstacle avoidance), limiting their robustness and applicability. We propose a modular framework for language-conditioned safety in robot navigation. Our framework is composed of three core components: (1) a large language model (LLM)-based module that translates free-form instructions into structured safety specifications, (2) a perception module that grounds these specifications by maintaining object-level 3D representations of the environment, and (3) a model predictive control (MPC)-based safety filter that enforces both semantic and geometric constraints in real time. We evaluate the effectiveness of the proposed framework through both simulation studies and hardware experiments, demonstrating that it robustly interprets and enforces diverse language-specified constraints across a wide range of environments and scenarios."}
{"id": "2511.06131", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06131", "abs": "https://arxiv.org/abs/2511.06131", "authors": ["Luca Ambrosino", "Khai Manh Nguyen", "Minh Binh Vu", "Riadh Zorgati", "Laurent El Ghaoui", "Giuseppe C. Calafiore"], "title": "A Multi-Criterion Approach to Smart EV Charging with CO2 Emissions and Cost Minimization", "comment": "Paper submitted to the 24th European Control Conference (ECC2026) in Reykjavík, Iceland", "summary": "In this work, we propose a novel three-step framework for smart electric vehicle (EV) charging that jointly minimizes charging costs and CO2 emissions. Drawing inspiration from the classical Unit Commitment Problem (UCP), we first design a linear model to determine the optimal power generation mix over a 24-hour horizon, using real-world data from Vietnam, a country with a highly carbon intensive energy system. This allows us to estimate time-varying CO2 emissions and translate them into an emission cost signal. We then incorporate this environmental cost into a smart charging optimization model, formulated as a linear program (LP). Numerical simulations confirm that the proposed strategy significantly outperforms a baseline First-In-First-Served (FIFS) approach, achieving notable reductions in both CO2 emissions and charging costs also compared to another optimization approach. The results demonstrate the potential of this multiobjective optimization framework to support more sustainable and cost-efficient EV charging strategies."}
{"id": "2511.06131", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06131", "abs": "https://arxiv.org/abs/2511.06131", "authors": ["Luca Ambrosino", "Khai Manh Nguyen", "Minh Binh Vu", "Riadh Zorgati", "Laurent El Ghaoui", "Giuseppe C. Calafiore"], "title": "A Multi-Criterion Approach to Smart EV Charging with CO2 Emissions and Cost Minimization", "comment": "Paper submitted to the 24th European Control Conference (ECC2026) in Reykjavík, Iceland", "summary": "In this work, we propose a novel three-step framework for smart electric vehicle (EV) charging that jointly minimizes charging costs and CO2 emissions. Drawing inspiration from the classical Unit Commitment Problem (UCP), we first design a linear model to determine the optimal power generation mix over a 24-hour horizon, using real-world data from Vietnam, a country with a highly carbon intensive energy system. This allows us to estimate time-varying CO2 emissions and translate them into an emission cost signal. We then incorporate this environmental cost into a smart charging optimization model, formulated as a linear program (LP). Numerical simulations confirm that the proposed strategy significantly outperforms a baseline First-In-First-Served (FIFS) approach, achieving notable reductions in both CO2 emissions and charging costs also compared to another optimization approach. The results demonstrate the potential of this multiobjective optimization framework to support more sustainable and cost-efficient EV charging strategies."}
{"id": "2511.05977", "categories": ["cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.05977", "abs": "https://arxiv.org/abs/2511.05977", "authors": ["Pavel Naumov", "Alexandra Pavlova"], "title": "An Epistemic Perspective on Agent Awareness", "comment": "Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "The paper proposes to treat agent awareness as a form of knowledge, breaking the tradition in the existing literature on awareness. It distinguishes the de re and de dicto forms of such knowledge. The work introduces two modalities capturing these forms and formally specifies their meaning using a version of 2D-semantics. The main technical result is a sound and complete logical system describing the interplay between the two proposed modalities and the standard \"knowledge of the fact\" modality."}
{"id": "2511.05627", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05627", "abs": "https://arxiv.org/abs/2511.05627", "authors": ["Sabik Aftahee", "A. F. M. Farhad", "Arpita Mallik", "Ratnajit Dhar", "Jawadul Karim", "Nahiyan Bin Noor", "Ishmam Ahmed Solaiman"], "title": "Assessing the Reliability of Large Language Models in the Bengali Legal Context: A Comparative Evaluation Using LLM-as-Judge and Legal Experts", "comment": null, "summary": "Accessing legal help in Bangladesh is hard. People face high fees, complex legal language, a shortage of lawyers, and millions of unresolved court cases. Generative AI models like OpenAI GPT-4.1 Mini, Gemini 2.0 Flash, Meta Llama 3 70B, and DeepSeek R1 could potentially democratize legal assistance by providing quick and affordable legal advice. In this study, we collected 250 authentic legal questions from the Facebook group \"Know Your Rights,\" where verified legal experts regularly provide authoritative answers. These questions were subsequently submitted to four four advanced AI models and responses were generated using a consistent, standardized prompt. A comprehensive dual evaluation framework was employed, in which a state-of-the-art LLM model served as a judge, assessing each AI-generated response across four critical dimensions: factual accuracy, legal appropriateness, completeness, and clarity. Following this, the same set of questions was evaluated by three licensed Bangladeshi legal professionals according to the same criteria. In addition, automated evaluation metrics, including BLEU scores, were applied to assess response similarity. Our findings reveal a complex landscape where AI models frequently generate high-quality, well-structured legal responses but also produce dangerous misinformation, including fabricated case citations, incorrect legal procedures, and potentially harmful advice. These results underscore the critical need for rigorous expert validation and comprehensive safeguards before AI systems can be safely deployed for legal consultation in Bangladesh."}
{"id": "2511.06191", "categories": ["cs.CY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.06191", "abs": "https://arxiv.org/abs/2511.06191", "authors": ["Soujanya Dash", "Kenjiro Ide", "Rikuhei Umemoto", "Kai Amino", "Keisuke Fujii"], "title": "Prediction-based evaluation of back-four defense with spatial control in soccer", "comment": "22 pages, 4 figures", "summary": "Defensive organization is critical in soccer, particularly during negative transitions when teams are most vulnerable. The back-four defensive line plays a decisive role in preventing goal-scoring opportunities, yet its collective coordination remains difficult to quantify. This study introduces interpretable spatio-temporal indicators namely, space control, stretch index, pressure index, and defensive line height (absolute and relative) to evaluate the effectiveness of the back-four during defensive transitions. Using synchronized tracking and event data from the 2023-24 LaLiga season, 2,413 defensive sequences were analyzed following possession losses by FC Barcelona and Real Madrid CF. Two-way ANOVA revealed significant effects of team, outcome, and their interaction for key indicators, with relative line height showing the strongest association with defensive success. Predictive modeling using XGBoost achieved the highest discriminative performance (ROC AUC: 0.724 for Barcelona, 0.698 for Real Madrid), identifying space score and relative line height as dominant predictors. Comparative analysis revealed distinct team-specific defensive behaviors: Barcelona's success was characterized by higher spatial control and compact line coordination, whereas Real Madrid exhibited more adaptive but less consistent defensive structures. These findings demonstrate the tactical and predictive value of interpretable spatial indicators for quantifying collective defensive performance."}
{"id": "2511.05903", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05903", "abs": "https://arxiv.org/abs/2511.05903", "authors": ["Zhengyuan Liu", "Stella Xin Yin", "Bryan Chen Zhengyu Tan", "Roy Ka-Wei Lee", "Guimei Liu", "Dion Hoe-Lian Goh", "Wenya Wang", "Nancy F. Chen"], "title": "The Imperfect Learner: Incorporating Developmental Trajectories in Memory-based Student Simulation", "comment": null, "summary": "User simulation is important for developing and evaluating human-centered AI, yet current student simulation in educational applications has significant limitations. Existing approaches focus on single learning experiences and do not account for students' gradual knowledge construction and evolving skill sets. Moreover, large language models are optimized to produce direct and accurate responses, making it challenging to represent the incomplete understanding and developmental constraints that characterize real learners. In this paper, we introduce a novel framework for memory-based student simulation that incorporates developmental trajectories through a hierarchical memory mechanism with structured knowledge representation. The framework also integrates metacognitive processes and personality traits to enrich the individual learner profiling, through dynamical consolidation of both cognitive development and personal learning characteristics. In practice, we implement a curriculum-aligned simulator grounded on the Next Generation Science Standards. Experimental results show that our approach can effectively reflect the gradual nature of knowledge development and the characteristic difficulties students face, providing a more accurate representation of learning processes."}
{"id": "2511.05936", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05936", "abs": "https://arxiv.org/abs/2511.05936", "authors": ["Soujanya Poria", "Navonil Majumder", "Chia-Yu Hung", "Amir Ali Bagherzadeh", "Chuan Li", "Kenneth Kwok", "Ziwei Wang", "Cheston Tan", "Jiajun Wu", "David Hsu"], "title": "10 Open Challenges Steering the Future of Vision-Language-Action Models", "comment": "AAAI 2026 (Senior Track)", "summary": "Due to their ability of follow natural language instructions, vision-language-action (VLA) models are increasingly prevalent in the embodied AI arena, following the widespread success of their precursors -- LLMs and VLMs. In this paper, we discuss 10 principal milestones in the ongoing development of VLA models -- multimodality, reasoning, data, evaluation, cross-robot action generalization, efficiency, whole-body coordination, safety, agents, and coordination with humans. Furthermore, we discuss the emerging trends of using spatial understanding, modeling world dynamics, post training, and data synthesis -- all aiming to reach these milestones. Through these discussions, we hope to bring attention to the research avenues that may accelerate the development of VLA models into wider acceptability."}
{"id": "2511.06199", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06199", "abs": "https://arxiv.org/abs/2511.06199", "authors": ["Shiqi Liu", "Hang Song", "Bo Wei", "Nopphon Keerativoranan", "Jun-ichi Takada"], "title": "A Passive Software-Defined Radio-based mmWave Sensing System for Blind Integrated Communication and Sensing", "comment": null, "summary": "Integrated Sensing and Communication (ISAC) is considered as a key component of future 6G technologies, especially in the millimeter-wave (mmWave) bands. Recently, the performances of ISAC were experimentally evaluated and demonstrated in various scenarios by developing ISAC systems. These systems generally consist of coherent transmitting (Tx) and receiving (Rx) modules. However, actively transmitting radio waves for experiments is not easy due to regulatory restrictions of radio. Meanwhile, the Tx/Rx should be synchronized and Rx need the information of Tx. In this paper, a fully passive mmWave sensing system is developed with software-defined radio for blind ISAC. It only consists of a passive Rx module which does not depend on the Tx. Since the proposed system is not synchronized with Tx and has no knowledge of the transmitted signals, a differential structure with two oppositely-oriented receivers is introduced to realize the sensing function. This structure can mitigate the influences of unknown source signals and other distortions. With the proposed sensing system, the ambient mmWave communication signals are leveraged for sensing without interrupting the existing systems. It can be deployed for field applications such as signal detection and dynamic human activity recognition since it does not emit signals. The efficacy of the developed system is first verified with a metallic plate with known motion pattern. The measured Doppler spectrogram shows good agreement with the simulation results, demonstrating the correctness of the sensing results. Further, the system is evaluated in complex scenarios, including handwaving, single- and multi-person motion detection. The sensing results successfully reflect the corresponding motions, demonstrating that the proposed sensing system can be utilized for blind ISAC in various applications."}
{"id": "2511.06199", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06199", "abs": "https://arxiv.org/abs/2511.06199", "authors": ["Shiqi Liu", "Hang Song", "Bo Wei", "Nopphon Keerativoranan", "Jun-ichi Takada"], "title": "A Passive Software-Defined Radio-based mmWave Sensing System for Blind Integrated Communication and Sensing", "comment": null, "summary": "Integrated Sensing and Communication (ISAC) is considered as a key component of future 6G technologies, especially in the millimeter-wave (mmWave) bands. Recently, the performances of ISAC were experimentally evaluated and demonstrated in various scenarios by developing ISAC systems. These systems generally consist of coherent transmitting (Tx) and receiving (Rx) modules. However, actively transmitting radio waves for experiments is not easy due to regulatory restrictions of radio. Meanwhile, the Tx/Rx should be synchronized and Rx need the information of Tx. In this paper, a fully passive mmWave sensing system is developed with software-defined radio for blind ISAC. It only consists of a passive Rx module which does not depend on the Tx. Since the proposed system is not synchronized with Tx and has no knowledge of the transmitted signals, a differential structure with two oppositely-oriented receivers is introduced to realize the sensing function. This structure can mitigate the influences of unknown source signals and other distortions. With the proposed sensing system, the ambient mmWave communication signals are leveraged for sensing without interrupting the existing systems. It can be deployed for field applications such as signal detection and dynamic human activity recognition since it does not emit signals. The efficacy of the developed system is first verified with a metallic plate with known motion pattern. The measured Doppler spectrogram shows good agreement with the simulation results, demonstrating the correctness of the sensing results. Further, the system is evaluated in complex scenarios, including handwaving, single- and multi-person motion detection. The sensing results successfully reflect the corresponding motions, demonstrating that the proposed sensing system can be utilized for blind ISAC in various applications."}
{"id": "2511.06065", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06065", "abs": "https://arxiv.org/abs/2511.06065", "authors": ["Lianrui Li", "Dakuan Lu", "Jiawei Shao", "Chi Zhang", "Xuelong Li"], "title": "ScRPO: From Errors to Insights", "comment": null, "summary": "We propose Self-correction Relative Policy Optimization (ScRPO), a novel reinforcement learning framework designed to enhance large language models on challenging mathematical problems by leveraging self-reflection and error correction. Our approach consists of two stages: (1) Trial-and-error learning stage: training the model with GRPO and collecting incorrect answers along with their corresponding questions in an error pool; (2) Self-correction learning stage: guiding the model to reflect on why its previous answers were wrong. Extensive experiments across multiple math reasoning benchmarks, including AIME, AMC, Olympiad, MATH-500, GSM8k, using Deepseek-Distill-Qwen-1.5B and Deepseek-Distill-Qwen-7B. The experimental results demonstrate that ScRPO consistently outperforms several post-training methods. These findings highlight ScRPO as a promising paradigm for enabling language models to self-improve on difficult tasks with limited external feedback, paving the way toward more reliable and capable AI systems."}
{"id": "2511.05642", "categories": ["cs.RO", "cs.AR", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05642", "abs": "https://arxiv.org/abs/2511.05642", "authors": ["Justin Williams", "Kishor Datta Gupta", "Roy George", "Mrinmoy Sarkar"], "title": "Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots", "comment": null, "summary": "The deployment of artificial intelligence models at the edge is increasingly critical for autonomous robots operating in GPS-denied environments where local, resource-efficient reasoning is essential. This work demonstrates the feasibility of deploying small Vision-Language Models (VLMs) on mobile robots to achieve real-time scene understanding and reasoning under strict computational constraints. Unlike prior approaches that separate perception from mobility, the proposed framework enables simultaneous movement and reasoning in dynamic environments using only on-board hardware. The system integrates a compact VLM with multimodal perception to perform contextual interpretation directly on embedded hardware, eliminating reliance on cloud connectivity. Experimental validation highlights the balance between computational efficiency, task accuracy, and system responsiveness. Implementation on a mobile robot confirms one of the first successful deployments of small VLMs for concurrent reasoning and mobility at the edge. This work establishes a foundation for scalable, assured autonomy in applications such as service robotics, disaster response, and defense operations."}
{"id": "2511.06474", "categories": ["econ.EM", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.06474", "abs": "https://arxiv.org/abs/2511.06474", "authors": ["Matias D. Cattaneo", "Rocio Titiunik", "Ruiqi Rae Yu"], "title": "Boundary Discontinuity Designs: Theory and Practice", "comment": null, "summary": "We review the literature on boundary discontinuity (BD) designs, a powerful non-experimental research methodology that identifies causal effects by exploiting a thresholding treatment assignment rule based on a bivariate score and a boundary curve. This methodology generalizes standard regression discontinuity designs based on a univariate score and scalar cutoff, and has specific challenges and features related to its multi-dimensional nature. We synthesize the empirical literature by systematically reviewing over $80$ empirical papers, tracing the method's application from its formative uses to its implementation in modern research. In addition to the empirical survey, we overview the latest methodological results on identification, estimation and inference for the analysis of BD designs, and offer recommendations for practice."}
{"id": "2511.05914", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05914", "abs": "https://arxiv.org/abs/2511.05914", "authors": ["Kevin Wei", "Lennart Heim"], "title": "Designing Incident Reporting Systems for Harms from General-Purpose AI", "comment": "Accepted to AAAI 2026", "summary": "We introduce a conceptual framework and provide considerations for the institutional design of AI incident reporting systems, i.e., processes for collecting information about safety- and rights-related events caused by general-purpose AI. As general-purpose AI systems are increasingly adopted, they are causing more real-world harms and displaying the potential to cause significantly more dangerous incidents - events that did or could have caused harm to individuals, property, or the environment. Through a literature review, we develop a framework for understanding the institutional design of AI incident reporting systems, which includes seven dimensions: policy goal, actors submitting and receiving reports, type of incidents reported, level of risk materialization, enforcement of reporting, anonymity of reporters, and post-reporting actions. We then examine nine case studies of incident reporting in safety-critical industries to extract design considerations for AI incident reporting in the United States. We discuss, among other factors, differences in systems operated by regulatory vs. non-regulatory government agencies, near miss reporting, the roles of mandatory reporting thresholds and voluntary reporting channels, how to enable safety learning after reporting, sharing incident information, and clarifying legal frameworks for reporting. Our aim is to inform researchers and policymakers about when particular design choices might be more or less appropriate for AI incident reporting."}
{"id": "2511.05995", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05995", "abs": "https://arxiv.org/abs/2511.05995", "authors": ["Jianbo Yuan", "Jing Dai", "Yerui Fan", "Yaxiong Wu", "Yunpeng Liang", "Weixin Yan"], "title": "Robustness study of the bio-inspired musculoskeletal arm robot based on the data-driven iterative learning algorithm", "comment": "20 pages, 13 figures", "summary": "The human arm exhibits remarkable capabilities, including both explosive power and precision, which demonstrate dexterity, compliance, and robustness in unstructured environments. Developing robotic systems that emulate human-like operational characteristics through musculoskeletal structures has long been a research focus. In this study, we designed a novel lightweight tendon-driven musculoskeletal arm (LTDM-Arm), featuring a seven degree-of-freedom (DOF) skeletal joint system and a modularized artificial muscular system (MAMS) with 15 actuators. Additionally, we employed a Hilly-type muscle model and data-driven iterative learning control (DDILC) to learn and refine activation signals for repetitive tasks within a finite time frame. We validated the anti-interference capabilities of the musculoskeletal system through both simulations and experiments. The results show that the LTDM-Arm system can effectively achieve desired trajectory tracking tasks, even under load disturbances of 20 % in simulation and 15 % in experiments. This research lays the foundation for developing advanced robotic systems with human-like operational performance."}
{"id": "2511.06223", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06223", "abs": "https://arxiv.org/abs/2511.06223", "authors": ["Heeseung Bang", "Andreas A. Malikopoulos"], "title": "Learning-Based Robust Bayesian Persuasion with Conformal Prediction Guarantees", "comment": "8 pages", "summary": "Classical Bayesian persuasion assumes that senders fully understand how receivers form beliefs and make decisions--an assumption that rarely holds when receivers possess private information or exhibit non-Bayesian behavior. In this paper, we develop a learning-based framework that integrates neural networks with conformal prediction to achieve robust persuasion under uncertainty about receiver belief formation. The proposed neural architecture learns end-to-end mappings from receiver observations and sender signals to action predictions, eliminating the need to identify belief mechanisms explicitly. Conformal prediction constructs finite-sample valid prediction sets with provable marginal coverage, enabling principled, distribution-free robust optimization. We establish exact coverage guarantees for the data-generating policy and derive bounds on coverage degradation under policy shifts. Furthermore, we provide neural network approximation and estimation error bounds, with sample complexity $O(d \\log(|\\mathcal{U}||\\mathcal{Y}||\\mathcal{S}|)/\\varepsilon^2)$, where $d$ denotes the effective network dimension, and finite-sample lower bounds on the sender's expected utility. Numerical experiments on smart-grid energy management illustrate the framework's robustness."}
{"id": "2511.06223", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06223", "abs": "https://arxiv.org/abs/2511.06223", "authors": ["Heeseung Bang", "Andreas A. Malikopoulos"], "title": "Learning-Based Robust Bayesian Persuasion with Conformal Prediction Guarantees", "comment": "8 pages", "summary": "Classical Bayesian persuasion assumes that senders fully understand how receivers form beliefs and make decisions--an assumption that rarely holds when receivers possess private information or exhibit non-Bayesian behavior. In this paper, we develop a learning-based framework that integrates neural networks with conformal prediction to achieve robust persuasion under uncertainty about receiver belief formation. The proposed neural architecture learns end-to-end mappings from receiver observations and sender signals to action predictions, eliminating the need to identify belief mechanisms explicitly. Conformal prediction constructs finite-sample valid prediction sets with provable marginal coverage, enabling principled, distribution-free robust optimization. We establish exact coverage guarantees for the data-generating policy and derive bounds on coverage degradation under policy shifts. Furthermore, we provide neural network approximation and estimation error bounds, with sample complexity $O(d \\log(|\\mathcal{U}||\\mathcal{Y}||\\mathcal{S}|)/\\varepsilon^2)$, where $d$ denotes the effective network dimension, and finite-sample lower bounds on the sender's expected utility. Numerical experiments on smart-grid energy management illustrate the framework's robustness."}
{"id": "2511.06134", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.06134", "abs": "https://arxiv.org/abs/2511.06134", "authors": ["Wei Yang", "Jiacheng Pang", "Shixuan Li", "Paul Bogdan", "Stephen Tu", "Jesse Thomason"], "title": "Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs", "comment": null, "summary": "Multi-agent systems (MAS) built on Large Language Models (LLMs) are being used to approach complex problems and can surpass single model inference. However, their success hinges on navigating a fundamental cognitive tension: the need to balance broad, divergent exploration of the solution space with a principled, convergent synthesis to the optimal solution. Existing paradigms often struggle to manage this duality, leading to premature consensus, error propagation, and a critical credit assignment problem that fails to distinguish between genuine reasoning and superficially plausible arguments. To resolve this core challenge, we propose the Multi-Agent Exploration-Synthesis framework Through Role Orchestration (Maestro), a principled paradigm for collaboration that structurally decouples these cognitive modes. Maestro uses a collective of parallel Execution Agents for diverse exploration and a specialized Central Agent for convergent, evaluative synthesis. To operationalize this critical synthesis phase, we introduce Conditional Listwise Policy Optimization (CLPO), a reinforcement learning objective that disentangles signals for strategic decisions and tactical rationales. By combining decision-focused policy gradients with a list-wise ranking loss over justifications, CLPO achieves clean credit assignment and stronger comparative supervision. Experiments on mathematical reasoning and general problem-solving benchmarks demonstrate that Maestro, coupled with CLPO, consistently outperforms existing state-of-the-art multi-agent approaches, delivering absolute accuracy gains of 6% on average and up to 10% at best."}
{"id": "2511.05680", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05680", "abs": "https://arxiv.org/abs/2511.05680", "authors": ["Jeong-Jung Kim", "Doo-Yeol Koh", "Chang-Hyun Kim"], "title": "VLM-driven Skill Selection for Robotic Assembly Tasks", "comment": null, "summary": "This paper presents a robotic assembly framework that combines Vision-Language Models (VLMs) with imitation learning for assembly manipulation tasks. Our system employs a gripper-equipped robot that moves in 3D space to perform assembly operations. The framework integrates visual perception, natural language understanding, and learned primitive skills to enable flexible and adaptive robotic manipulation. Experimental results demonstrate the effectiveness of our approach in assembly scenarios, achieving high success rates while maintaining interpretability through the structured primitive skill decomposition."}
{"id": "2511.05927", "categories": ["cs.CY", "cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05927", "abs": "https://arxiv.org/abs/2511.05927", "authors": ["Mohammad Rashed Albous", "Melodena Stephens", "Odeh Rashed Al-Jayyousi"], "title": "Artificial intelligence and the Gulf Cooperation Council workforce adapting to the future of work", "comment": null, "summary": "The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation Council (GCC) raises a central question: are investments in compute infrastructure matched by an equally robust build-out of skills, incentives, and governance? Grounded in socio-technical systems (STS) theory, this mixed-methods study audits workforce preparedness across Kingdom of Saudi Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman. We combine term frequency--inverse document frequency (TF--IDF) analysis of six national AI strategies (NASs), an inventory of 47 publicly disclosed AI initiatives (January 2017--April 2025), paired case studies, the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data & Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix linking oil-revenue slack (technical capacity) to regulatory coherence (social alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI 0.58--0.83) exhibit joint social--technical design; country-level indices span 0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under our modeled conditions, regulatory convergence plausibly binds outcomes more than fiscal capacity: fragmented rules can offset high oil revenues, while harmonized standards help preserve progress under austerity. We also identify an emerging two-track talent system, research elites versus rapidly trained practitioners, that risks labor-market bifurcation without bridging mechanisms. By extending STS inquiry to oil-rich, state-led economies, the study refines theory and sets a research agenda focused on longitudinal coupling metrics, ethnographies of coordination, and outcome-based performance indicators."}
{"id": "2511.06102", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06102", "abs": "https://arxiv.org/abs/2511.06102", "authors": ["Mohammed Abboodi"], "title": "Development and testing of novel soft sleeve actuators", "comment": "PhD thesis", "summary": "Aging populations and the rising prevalence of neurological and musculoskeletal disorders increase the demand for wearable mobility assistive devices that are effective, comfortable, and anatomically compatible. Many existing systems use rigid mechanisms and bulky interfaces that impede force transmission and reduce wearability. This study introduces a soft sleeve actuation architecture that conforms to the limb while transmitting forces and moments efficiently. We develop three soft sleeve actuators that produce linear, bending, and twisting motion, and an omnidirectional design that combines these motions in one device. Actuators are fabricated from thermoplastic elastomers using a customized fused filament fabrication process that produces airtight and compliant structures and resolves leakage observed with conventional methods. A dedicated experimental platform quantifies kinematic outputs such as displacement, angle, and twist, and kinetic outputs such as force and torque under low pneumatic pressures. A parametric study varies geometric features and material properties to determine their influence on performance. Results show reproducible multi axis motion with improved transfer of force to the limb and reduced need for complex attachment hardware. The work establishes a unified and manufacturable framework for soft sleeve actuation that enables compact and user centered assistive technologies with enhanced kinematic and kinetic performance."}
{"id": "2511.06306", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06306", "abs": "https://arxiv.org/abs/2511.06306", "authors": ["Yixuan Liu", "Yingzhu Liu", "Pengcheng You"], "title": "Coherency Analysis in Nonlinear Heterogeneous Power Networks: A Blended Dynamics Approach", "comment": null, "summary": "Power system coherency refers to the phenomenon that machines in a power network exhibit similar frequency responses after disturbances, and is foundational for model reduction and control design. Despite abundant empirical observations, the understanding of coherence in complex power networks remains incomplete where the dynamics could be highly heterogeneous, nonlinear, and increasingly affected by persistent disturbances such as renewable energy fluctuations. To bridge this gap, this paper extends the blended dynamics approach, originally rooted in consensus analysis of multi-agent systems, to develop a novel coherency analysis in power networks. We show that the frequency responses of coherent machines coupled by nonlinear power flow can be approximately represented by the blended dynamics, which is a weighted average of nonlinear heterogeneous nodal dynamics, even under time-varying disturbances. Specifically, by developing novel bounds on the difference between the trajectories of nodal dynamics and the blended dynamics, we identify two key factors -- either high network connectivity or small time-variation rate of disturbances -- that contribute to coherence. They enable the nodal frequencies to rapidly approach the blended-dynamics trajectory from arbitrary initial state. Furthermore, they ensure the frequencies closely follow this trajectory in the long term, even when the system does not settle to an equilibrium. These insights contribute to the understanding of power system coherency and are further supported by simulation results."}
{"id": "2511.06306", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06306", "abs": "https://arxiv.org/abs/2511.06306", "authors": ["Yixuan Liu", "Yingzhu Liu", "Pengcheng You"], "title": "Coherency Analysis in Nonlinear Heterogeneous Power Networks: A Blended Dynamics Approach", "comment": null, "summary": "Power system coherency refers to the phenomenon that machines in a power network exhibit similar frequency responses after disturbances, and is foundational for model reduction and control design. Despite abundant empirical observations, the understanding of coherence in complex power networks remains incomplete where the dynamics could be highly heterogeneous, nonlinear, and increasingly affected by persistent disturbances such as renewable energy fluctuations. To bridge this gap, this paper extends the blended dynamics approach, originally rooted in consensus analysis of multi-agent systems, to develop a novel coherency analysis in power networks. We show that the frequency responses of coherent machines coupled by nonlinear power flow can be approximately represented by the blended dynamics, which is a weighted average of nonlinear heterogeneous nodal dynamics, even under time-varying disturbances. Specifically, by developing novel bounds on the difference between the trajectories of nodal dynamics and the blended dynamics, we identify two key factors -- either high network connectivity or small time-variation rate of disturbances -- that contribute to coherence. They enable the nodal frequencies to rapidly approach the blended-dynamics trajectory from arbitrary initial state. Furthermore, they ensure the frequencies closely follow this trajectory in the long term, even when the system does not settle to an equilibrium. These insights contribute to the understanding of power system coherency and are further supported by simulation results."}
{"id": "2511.06136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06136", "abs": "https://arxiv.org/abs/2511.06136", "authors": ["Stefano Ferraro", "Akihiro Nakano", "Masahiro Suzuki", "Yutaka Matsuo"], "title": "When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks", "comment": null, "summary": "Object-centric world models (OCWM) aim to decompose visual scenes into object-level representations, providing structured abstractions that could improve compositional generalization and data efficiency in reinforcement learning. We hypothesize that explicitly disentangled object-level representations, by localizing task-relevant information, can enhance policy performance across novel feature combinations. To test this hypothesis, we introduce DLPWM, a fully unsupervised, disentangled object-centric world model that learns object-level latents directly from pixels. DLPWM achieves strong reconstruction and prediction performance, including robustness to several out-of-distribution (OOD) visual variations. However, when used for downstream model-based control, policies trained on DLPWM latents underperform compared to DreamerV3. Through latent-trajectory analyses, we identify representation shift during multi-object interactions as a key driver of unstable policy learning. Our results suggest that, although object-centric perception supports robust visual modeling, achieving stable control requires mitigating latent drift."}
{"id": "2511.05713", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05713", "abs": "https://arxiv.org/abs/2511.05713", "authors": ["Henrique S. Xavier", "Beatriz Rocha", "Diogo Cortiz"], "title": "Who shapes Web standards? Uncovering the main topics of interest in the W3C", "comment": "9 pages, 11 figures, 1 table", "summary": "This paper identifies the primary topics of interest of organizations participating in the World Wide Web Consortium (W3C), the leading standards body for the Web. Using publicly available data from the W3C website, we analyze the participation of member organizations in W3C groups, treating the number of representatives allocated to each group as a proxy for their interests. By applying topic modeling and similarity analysis to these participation patterns, we uncover clusters of related groups and shared priorities among organizations. The results reveal five prominent areas of focus -- Web, Ads & Privacy; High Performance; Credentials & Web of Things; Accessibility; and Payments -- and show that large enterprises, particularly those based in the United States, dominate participation in core Web development and advertising-related topics, while Japanese organizations are more active in the Web of Things. These findings offer insights into how various stakeholders influence the standardization process and how the Web may evolve in the coming years."}
{"id": "2511.05932", "categories": ["cs.CY", "cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2511.05932", "abs": "https://arxiv.org/abs/2511.05932", "authors": ["Mohammad Rashed Albous", "Bedour Alboloushi", "Arnaud Lacheret"], "title": "The Future of AI in the GCC Post-NPM Landscape: A Comparative Analysis of Kuwait and the UAE", "comment": null, "summary": "Comparative evidence on how Gulf Cooperation Council (GCC) states turn artificial intelligence (AI) ambitions into post--New Public Management (post-NPM) outcomes is scarce because most studies examine Western democracies. We analyze constitutional, collective-choice, and operational rules shaping AI uptake in two contrasting GCC members, the United Arab Emirates (UAE) and Kuwait, and whether they foster citizen centricity, collaborative governance, and public value creation. Anchored in Ostrom's Institutional Analysis and Development framework, the study combines a most similar/most different systems design with multiple sources: 62 public documents from 2018--2025, embedded UAE cases (Smart Dubai and MBZUAI), and 39 interviews with officials conducted Aug 2024--May 2025. Dual coding and process tracing connect rule configurations to AI performance. Cross-case analysis identifies four reinforcing mechanisms behind divergent trajectories. In the UAE, concentrated authority, credible sanctions, pro-innovation narratives, and flexible reinvestment rules scale pilots into hundreds of services and sizable recycled savings. In Kuwait, dispersed veto points, exhortative sanctions, cautious discourse, and lapsed AI budgets confine initiatives to pilot mode despite equivalent fiscal resources. The findings refine institutional theory by showing that vertical rule coherence, not wealth, determines AI's public-value yield, and temper post-NPM optimism by revealing that efficiency metrics serve societal goals only when backed by enforceable safeguards. To curb ethics washing and test transferability beyond the GCC, future work should track rule diffusion over time, develop blended legitimacy--efficiency scorecards, and examine how narrative framing shapes citizen consent for data sharing."}
{"id": "2511.06141", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06141", "abs": "https://arxiv.org/abs/2511.06141", "authors": ["Marc Duclusaud", "Grégoire Passault", "Vincent Padois", "Olivier Ly"], "title": "PlaCo: a QP-based robot planning and control framework", "comment": null, "summary": "This article introduces PlaCo, a software framework designed to simplify the formulation and solution of Quadratic Programming (QP)-based planning and control problems for robotic systems. PlaCo provides a high-level interface that abstracts away the low-level mathematical formulation of QP problems, allowing users to specify tasks and constraints in a modular and intuitive manner. The framework supports both Python bindings for rapid prototyping and a C++ implementation for real-time performance."}
{"id": "2511.06335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06335", "abs": "https://arxiv.org/abs/2511.06335", "authors": ["Ehsan Asadi", "Davood Keshavarzi", "Alexander Koehler", "Nima Tashakor", "Stefan Goetz"], "title": "Partial-Power Flow Controller, Voltage Regulator, and Energy Router for Hybrid AC-DC Grids", "comment": "10 pages, 42 figures", "summary": "The share of electronically converted power from renewable sources, loads, and storage is continuously growing in the low- and medium-voltage grids. These sources and loads typically rectify the grid AC to DC, e.g., for a DC link, so that a DC grid could eliminate hardware and losses of these conversion stages. However, extended DC grids lack the stabilizing nature of AC impedances so that the voltage is more fragile and power flows may need active control, particularly if redundancy as known from AC, such as rings and meshing, is desired. Furthermore, a DC infrastructure will not replace but will need to interface with the existing AC grid. This paper presents a partial-power energy router architecture that can interface multiple AC and DC lines to enable precise control of voltages and both active as well as reactive power flows. The proposed system uses modular low-voltage high-current series modules supplied through dual active bridges. These modules only need to process a small share of the voltage to control large power flows. The topology reduces component size, cost, energy losses, and reliability more than three times compared to conventional technology. The optional integration of battery energy storage can furthermore eliminate the need for the sum of the power flows of all inputs to be zero at all times. Through dynamic voltage injection relative to the line voltage, the modules effectively balance feeder currents, regulate reactive power, and improve the power factor in AC grids. Real-time hardware-in-the-loop and prototype measurements validate the proposed energy router's performance under diverse operating conditions. Experimental results confirm the series module's functionality in both AC and DC grids as an effective solution for controlling extended grids, including power sharing, voltage, and power quality."}
{"id": "2511.06335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06335", "abs": "https://arxiv.org/abs/2511.06335", "authors": ["Ehsan Asadi", "Davood Keshavarzi", "Alexander Koehler", "Nima Tashakor", "Stefan Goetz"], "title": "Partial-Power Flow Controller, Voltage Regulator, and Energy Router for Hybrid AC-DC Grids", "comment": "10 pages, 42 figures", "summary": "The share of electronically converted power from renewable sources, loads, and storage is continuously growing in the low- and medium-voltage grids. These sources and loads typically rectify the grid AC to DC, e.g., for a DC link, so that a DC grid could eliminate hardware and losses of these conversion stages. However, extended DC grids lack the stabilizing nature of AC impedances so that the voltage is more fragile and power flows may need active control, particularly if redundancy as known from AC, such as rings and meshing, is desired. Furthermore, a DC infrastructure will not replace but will need to interface with the existing AC grid. This paper presents a partial-power energy router architecture that can interface multiple AC and DC lines to enable precise control of voltages and both active as well as reactive power flows. The proposed system uses modular low-voltage high-current series modules supplied through dual active bridges. These modules only need to process a small share of the voltage to control large power flows. The topology reduces component size, cost, energy losses, and reliability more than three times compared to conventional technology. The optional integration of battery energy storage can furthermore eliminate the need for the sum of the power flows of all inputs to be zero at all times. Through dynamic voltage injection relative to the line voltage, the modules effectively balance feeder currents, regulate reactive power, and improve the power factor in AC grids. Real-time hardware-in-the-loop and prototype measurements validate the proposed energy router's performance under diverse operating conditions. Experimental results confirm the series module's functionality in both AC and DC grids as an effective solution for controlling extended grids, including power sharing, voltage, and power quality."}
{"id": "2511.06142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06142", "abs": "https://arxiv.org/abs/2511.06142", "authors": ["Sizhe Tang", "Jiayu Chen", "Tian Lan"], "title": "MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning", "comment": null, "summary": "Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for Trees (UCTs) to balance exploration and exploitation through randomized sampling, is instrumental to solving complex planning problems. However, for multi-agent planning, MCTS is confronted with a large combinatorial action space that often grows exponentially with the number of agents. As a result, the branching factor of MCTS during tree expansion also increases exponentially, making it very difficult to efficiently explore and exploit during tree search. To this end, we propose MALinZero, a new approach to leverage low-dimensional representational structures on joint-action returns and enable efficient MCTS in complex multi-agent planning. Our solution can be viewed as projecting the joint-action returns into the low-dimensional space representable using a contextual linear bandit problem formulation. We solve the contextual linear bandit problem with convex and $μ$-smooth loss functions -- in order to place more importance on better joint actions and mitigate potential representational limitations -- and derive a linear Upper Confidence Bound applied to trees (LinUCT) to enable novel multi-agent exploration and exploitation in the low-dimensional space. We analyze the regret of MALinZero for low-dimensional reward functions and propose an $(1-\\tfrac1e)$-approximation algorithm for the joint action selection by maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2, outperforming both model-based and model-free multi-agent reinforcement learning baselines with faster learning speed and better performance."}
{"id": "2511.05714", "categories": ["cs.CY", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05714", "abs": "https://arxiv.org/abs/2511.05714", "authors": ["Nicholas Generous", "Brian Cook", "Jason Pruet"], "title": "Preserving security in a world with powerful AI Considerations for the future Defense Architecture", "comment": null, "summary": "Advances in AI threaten to invalidate assumptions underpinning today's defense architecture. We argue that the current U.S. defense program of record, designed in an era before capable machine intelligence, cannot by itself preserve national security against rapidly emerging AI enabled threats. Instead, shoring up legacy systems must be coupled with entirely new elements of a defense architecture. We outline immediate steps to adapt the Department of Energy National Nuclear Security Administration National Laboratories to ensure agility and resilience in an era of powerful AI."}
{"id": "2511.05953", "categories": ["cs.CY", "cs.MM", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.05953", "abs": "https://arxiv.org/abs/2511.05953", "authors": ["Atharva Mehta", "Shivam Chauhan", "Megha Sharma", "Gus Xia", "Kaustuv Kanti Ganguli", "Nishanth Chandran", "Zeerak Talat", "Monojit Choudhury"], "title": "Who Gets Heard? Rethinking Fairness in AI for Music Systems", "comment": "7 pages, Accepted at NeurIPS'25 workshop on AI for Music", "summary": "In recent years, the music research community has examined risks of AI models for music, with generative AI models in particular, raised concerns about copyright, deepfakes, and transparency. In our work, we raise concerns about cultural and genre biases in AI for music systems (music-AI systems) which affect stakeholders including creators, distributors, and listeners shaping representation in AI for music. These biases can misrepresent marginalized traditions, especially from the Global South, producing inauthentic outputs (e.g., distorted ragas) that reduces creators' trust on these systems. Such harms risk reinforcing biases, limiting creativity, and contributing to cultural erasure. To address this, we offer recommendations at dataset, model and interface level in music-AI systems."}
{"id": "2511.06182", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06182", "abs": "https://arxiv.org/abs/2511.06182", "authors": ["Peican Lin", "Gan Sun", "Chenxi Liu", "Fazeng Li", "Weihong Ren", "Yang Cong"], "title": "OpenVLN: Open-world aerial Vision-Language Navigation", "comment": "Content: 8 pages 4 figures, conference under review", "summary": "Vision-language models (VLMs) have been widely-applied in ground-based vision-language navigation (VLN). However, the vast complexity of outdoor aerial environments compounds data acquisition challenges and imposes long-horizon trajectory planning requirements on Unmanned Aerial Vehicles (UAVs), introducing novel complexities for aerial VLN. To address these challenges, we propose a data-efficient Open-world aerial Vision-Language Navigation (i.e., OpenVLN) framework, which could execute language-guided flight with limited data constraints and enhance long-horizon trajectory planning capabilities in complex aerial environments. Specifically, we reconfigure a reinforcement learning framework to optimize the VLM for UAV navigation tasks, which can efficiently fine-tune VLM by using rule-based policies under limited training data. Concurrently, we introduce a long-horizon planner for trajectory synthesis that dynamically generates precise UAV actions via value-based rewards. To the end, we conduct sufficient navigation experiments on the TravelUAV benchmark with dataset scaling across diverse reward settings. Our method demonstrates consistent performance gains of up to 4.34% in Success Rate, 6.19% in Oracle Success Rate, and 4.07% in Success weighted by Path Length over baseline methods, validating its deployment efficacy for long-horizon UAV navigation in complex aerial environments."}
{"id": "2511.06368", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06368", "abs": "https://arxiv.org/abs/2511.06368", "authors": ["Hideki Nishizawa", "Toru Mano", "Kazuya Anazawa", "Tatsuya Matsumura", "Takeo Sasai", "Masatoshi Namiki", "Dmitrii Briantcev", "Renato Ambrosone", "Esther Le Rouzic", "Stefan Melin", "Oscar Gonzalez-de-Dios", "Juan Pedro Fernandez-Palacios", "Xiaocheng Zhang", "Keigo Akahoshi", "Gert Grammel", "Andrea D'Amico", "Giacomo Borraccini", "Marco Ruffini", "Daniel Kilper", "Vittorio Curri"], "title": "Optical Network Digital Twin - Commercialization Barriers, Value Proposition, Early Use Cases, and Challenges", "comment": "7 pages, 5 figures", "summary": "With the widespread adoption of AI, machine-to-machine communications are rapidly increasing, reshaping the requirements for optical networks. Recent advances in Gaussian noise modeling for digital coherent transmission have raised expectations for digital-twin-based operation. However, unlike digital twins in wireless communication, which are already well established, significant barriers remain for commercialization in optical networks. This paper discusses the evolving requirements of optical networks in the AI era and proposes an Optical Network Digital Twin architecture that enables flexible end-to-end light path operation beyond conventional management. The value propositions of the proposed architecture, its evolutionary steps toward commercialization, and key research challenges for practical deployment are presented."}
{"id": "2511.06368", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06368", "abs": "https://arxiv.org/abs/2511.06368", "authors": ["Hideki Nishizawa", "Toru Mano", "Kazuya Anazawa", "Tatsuya Matsumura", "Takeo Sasai", "Masatoshi Namiki", "Dmitrii Briantcev", "Renato Ambrosone", "Esther Le Rouzic", "Stefan Melin", "Oscar Gonzalez-de-Dios", "Juan Pedro Fernandez-Palacios", "Xiaocheng Zhang", "Keigo Akahoshi", "Gert Grammel", "Andrea D'Amico", "Giacomo Borraccini", "Marco Ruffini", "Daniel Kilper", "Vittorio Curri"], "title": "Optical Network Digital Twin - Commercialization Barriers, Value Proposition, Early Use Cases, and Challenges", "comment": "7 pages, 5 figures", "summary": "With the widespread adoption of AI, machine-to-machine communications are rapidly increasing, reshaping the requirements for optical networks. Recent advances in Gaussian noise modeling for digital coherent transmission have raised expectations for digital-twin-based operation. However, unlike digital twins in wireless communication, which are already well established, significant barriers remain for commercialization in optical networks. This paper discusses the evolving requirements of optical networks in the AI era and proposes an Optical Network Digital Twin architecture that enables flexible end-to-end light path operation beyond conventional management. The value propositions of the proposed architecture, its evolutionary steps toward commercialization, and key research challenges for practical deployment are presented."}
{"id": "2511.06160", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06160", "abs": "https://arxiv.org/abs/2511.06160", "authors": ["Fatima Jahara", "Mark Dredze", "Sharon Levy"], "title": "Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles", "comment": "24 pages (including appendix)", "summary": "While recent safety guardrails effectively suppress overtly biased outputs, subtler forms of social bias emerge during complex logical reasoning tasks that evade current evaluation benchmarks. To fill this gap, we introduce a new evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model Evaluation), that uses logic grid puzzles to systematically probe the influence of social stereotypes on logical reasoning and decision making in LLMs. Our use of logic puzzles enables automatic generation and verification, as well as variability in complexity and biased settings. PRIME includes stereotypical, anti-stereotypical, and neutral puzzle variants generated from a shared puzzle structure, allowing for controlled and fine-grained comparisons. We evaluate multiple model families across puzzle sizes and test the effectiveness of prompt-based mitigation strategies. Focusing our experiments on gender stereotypes, our findings highlight that models consistently reason more accurately when solutions align with stereotypical associations. This demonstrates the significance of PRIME for diagnosing and quantifying social biases perpetuated in the deductive reasoning of LLMs, where fairness is critical."}
{"id": "2511.05723", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05723", "abs": "https://arxiv.org/abs/2511.05723", "authors": ["Guangshen Ma", "Ravi Prakash", "Beatrice Schleupner", "Jeffrey Everitt", "Arpit Mishra", "Junqin Chen", "Brian Mann", "Boyuan Chen", "Leila Bridgeman", "Pei Zhong", "Mark Draelos", "William C. Eward", "Patrick J. Codd"], "title": "TumorMap: A Laser-based Surgical Platform for 3D Tumor Mapping and Fully-Automated Tumor Resection", "comment": "41 pages, 25 figures", "summary": "Surgical resection of malignant solid tumors is critically dependent on the surgeon's ability to accurately identify pathological tissue and remove the tumor while preserving surrounding healthy structures. However, building an intraoperative 3D tumor model for subsequent removal faces major challenges due to the lack of high-fidelity tumor reconstruction, difficulties in developing generalized tissue models to handle the inherent complexities of tumor diagnosis, and the natural physical limitations of bimanual operation, physiologic tremor, and fatigue creep during surgery. To overcome these challenges, we introduce \"TumorMap\", a surgical robotic platform to formulate intraoperative 3D tumor boundaries and achieve autonomous tissue resection using a set of multifunctional lasers. TumorMap integrates a three-laser mechanism (optical coherence tomography, laser-induced endogenous fluorescence, and cutting laser scalpel) combined with deep learning models to achieve fully-automated and noncontact tumor resection. We validated TumorMap in murine osteoscarcoma and soft-tissue sarcoma tumor models, and established a novel histopathological workflow to estimate sensor performance. With submillimeter laser resection accuracy, we demonstrated multimodal sensor-guided autonomous tumor surgery without any human intervention."}
{"id": "2511.06078", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06078", "abs": "https://arxiv.org/abs/2511.06078", "authors": ["Luis Marquez-Carpintero", "Alberto Lopez-Sellers", "Miguel Cazorla"], "title": "Simulating Students with Large Language Models: A Review of Architecture, Mechanisms, and Role Modelling in Education with Generative AI", "comment": null, "summary": "Simulated Students offer a valuable methodological framework for evaluating pedagogical approaches and modelling diverse learner profiles, tasks which are otherwise challenging to undertake systematically in real-world settings. Recent research has increasingly focused on developing such simulated agents to capture a range of learning styles, cognitive development pathways, and social behaviours. Among contemporary simulation techniques, the integration of large language models (LLMs) into educational research has emerged as a particularly versatile and scalable paradigm. LLMs afford a high degree of linguistic realism and behavioural adaptability, enabling agents to approximate cognitive processes and engage in contextually appropriate pedagogical dialogues. This paper presents a thematic review of empirical and methodological studies utilising LLMs to simulate student behaviour across educational environments. We synthesise current evidence on the capacity of LLM-based agents to emulate learner archetypes, respond to instructional inputs, and interact within multi-agent classroom scenarios. Furthermore, we examine the implications of such systems for curriculum development, instructional evaluation, and teacher training. While LLMs surpass rule-based systems in natural language generation and situational flexibility, ongoing concerns persist regarding algorithmic bias, evaluation reliability, and alignment with educational objectives. The review identifies existing technological and methodological gaps and proposes future research directions for integrating generative AI into adaptive learning systems and instructional design."}
{"id": "2511.06202", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06202", "abs": "https://arxiv.org/abs/2511.06202", "authors": ["Shahram Najam Syed", "Yatharth Ahuja", "Arthur Jakobsson", "Jeff Ichnowski"], "title": "ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval", "comment": "10 pages, 5 figures, submitted to ICRA 2026. Equal contribution by first two authors", "summary": "Vision-Language-Action models such as OpenVLA show impressive zero-shot generalization across robotic manipulation tasks but often fail to adapt efficiently to new deployment environments. In many real-world applications, consistent high performance on a limited set of tasks is more important than broad generalization. We propose ExpReS-VLA, a method for specializing pre-trained VLA models through experience replay and retrieval while preventing catastrophic forgetting. ExpReS-VLA stores compact feature representations from the frozen vision backbone instead of raw image-action pairs, reducing memory usage by approximately 97 percent. During deployment, relevant past experiences are retrieved using cosine similarity and used to guide adaptation, while prioritized experience replay emphasizes successful trajectories. We also introduce Thresholded Hybrid Contrastive Loss, which enables learning from both successful and failed attempts. On the LIBERO simulation benchmark, ExpReS-VLA improves success rates from 82.6 to 93.1 percent on spatial reasoning tasks and from 61 to 72.3 percent on long-horizon tasks. On physical robot experiments with five manipulation tasks, it reaches 98 percent success on both seen and unseen settings, compared to 84.7 and 32 percent for naive fine-tuning. Adaptation takes 31 seconds using 12 demonstrations on a single RTX 5090 GPU, making the approach practical for real robot deployment."}
{"id": "2511.06398", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06398", "abs": "https://arxiv.org/abs/2511.06398", "authors": ["Leloko J. Lepolesa", "Kayode E. Adetunji", "Khmaies Ouahada", "Zhenqing Liu", "Ling Cheng"], "title": "Dynamic Electric Vehicle Charging Pricing for Load Balancing in Power Distribution Networks based on Collaborative DDPG Agents", "comment": "12 pages, In the second round of review at IEEE Transactions on Smart Grid", "summary": "The transition from the Internal Combustion Engine Vehicles (ICEVs) to the Electric Vehicles (EVs) is globally recommended to combat the unfavourable environmental conditions caused by reliance on fossil fuels. However, it has been established that the charging of EVs can destabilize the grid when they penetrate the market in large numbers, especially in grids that were not initially built to handle the load from the charging of EVs. In this work, we present a dynamic EV charging pricing strategy that fulfills the following three objectives: distribution network-level load peak-shaving, valley-filling, and load balancing across distribution networks. Based on historical environmental variables such as temperature, humidity, wind speed, EV charging prices and distribution of vehicles in different areas in different times of the day, we first forecast the distribution network load demand, and then use deep reinforcement learning approach to set the optimal dynamic EV charging price. While most research seeks to achieve load peak-shaving and valley-filling to stabilize the grid, our work goes further into exploring the load-balancing between the distribution networks in the close vicinity to each other. We compare the performance of Deep Deterministic Policy Gradient (DDPG), Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO) algorithms for this purpose. The best algorithm is used for dymamic EV pricing. Simulation results show an improved utilization of the grid at the distribution network level, leading to the optimal usage of the grid on a larger scale."}
{"id": "2511.06398", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06398", "abs": "https://arxiv.org/abs/2511.06398", "authors": ["Leloko J. Lepolesa", "Kayode E. Adetunji", "Khmaies Ouahada", "Zhenqing Liu", "Ling Cheng"], "title": "Dynamic Electric Vehicle Charging Pricing for Load Balancing in Power Distribution Networks based on Collaborative DDPG Agents", "comment": "12 pages, In the second round of review at IEEE Transactions on Smart Grid", "summary": "The transition from the Internal Combustion Engine Vehicles (ICEVs) to the Electric Vehicles (EVs) is globally recommended to combat the unfavourable environmental conditions caused by reliance on fossil fuels. However, it has been established that the charging of EVs can destabilize the grid when they penetrate the market in large numbers, especially in grids that were not initially built to handle the load from the charging of EVs. In this work, we present a dynamic EV charging pricing strategy that fulfills the following three objectives: distribution network-level load peak-shaving, valley-filling, and load balancing across distribution networks. Based on historical environmental variables such as temperature, humidity, wind speed, EV charging prices and distribution of vehicles in different areas in different times of the day, we first forecast the distribution network load demand, and then use deep reinforcement learning approach to set the optimal dynamic EV charging price. While most research seeks to achieve load peak-shaving and valley-filling to stabilize the grid, our work goes further into exploring the load-balancing between the distribution networks in the close vicinity to each other. We compare the performance of Deep Deterministic Policy Gradient (DDPG), Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO) algorithms for this purpose. The best algorithm is used for dymamic EV pricing. Simulation results show an improved utilization of the grid at the distribution network level, leading to the optimal usage of the grid on a larger scale."}
{"id": "2511.06168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06168", "abs": "https://arxiv.org/abs/2511.06168", "authors": ["Boxuan Wang", "Zhuoyun Li", "Xinmiao Huang", "Xiaowei Huang", "Yi Dong"], "title": "Chasing Consistency: Quantifying and Optimizing Human-Model Alignment in Chain-of-Thought Reasoning", "comment": "13 pages, 3 figures", "summary": "This paper presents a framework for evaluating and optimizing reasoning consistency in Large Language Models (LLMs) via a new metric, the Alignment Score, which quantifies the semantic alignment between model-generated reasoning chains and human-written reference chains in Chain-of-Thought (CoT) reasoning. Empirically, we find that 2-hop reasoning chains achieve the highest Alignment Score. To explain this phenomenon, we define four key error types: logical disconnection, thematic shift, redundant reasoning, and causal reversal, and show how each contributes to the degradation of the Alignment Score. Building on this analysis, we further propose Semantic Consistency Optimization Sampling (SCOS), a method that samples and favors chains with minimal alignment errors, significantly improving Alignment Scores by an average of 29.84% with longer reasoning chains, such as in 3-hop tasks."}
{"id": "2511.05729", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05729", "abs": "https://arxiv.org/abs/2511.05729", "authors": ["Andrew Yen Chang", "Ho-Chun Herbert Chang"], "title": "Food as Soft Power: Taiwanese Gastrodiplomacy on Social Media and Algorithmic Suppression", "comment": "13 pages and 10 figures", "summary": "Social media platforms have become pivotal for projecting national identity and soft power in an increasingly digital world. This study examines the digital manifestation of Taiwanese gastrodiplomacy by focusing on bubble tea -- a culturally iconic beverage -- leveraging a dataset comprising 107,169 posts from the popular lifestyle social media platform Instagram. Including 315,279,227 engagements, 4,756,320 comments, and 8,097,260,651 views over five full years (2020--2024), we investigate how social media facilitates discussion about Taiwanese cuisine and contributes to Taiwan's digital soft power. Our analysis reveals that bubble tea consistently emerges as the dominant representation of Taiwanese cuisine across Meta's Instagram channels. However, this dominance also indicates vulnerability in gastrodiplomatic strategy compared to other countries. Additionally, we find evidence that Instagram suppresses bubble tea posts mentioning Taiwan by 1,200\\% -- roughly a twelve--fold decrease in exposure -- relative to posts without such mentions. Crucially, we observe a significant drop in the number of posts, views, and engagement following Lai's inauguration in May 2024. This study ultimately contributes to understanding how digital platforms can enable or disable gastrodiplomacy, soft power, and cultural diplomacy while highlighting the need for greater algorithmic transparency. By noting Taiwan's bubble tea's digital engagement and footprint, critical insights are brought for nations seeking to leverage soft power through gastronomic means in a politicized digital era and researchers trying to better understand algorithmic suppression."}
{"id": "2511.06148", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06148", "abs": "https://arxiv.org/abs/2511.06148", "authors": ["Addison J. Wu", "Ryan Liu", "Xuechunzi Bai", "Thomas L. Griffiths"], "title": "Large Language Models Develop Novel Social Biases Through Adaptive Exploration", "comment": null, "summary": "As large language models (LLMs) are adopted into frameworks that grant them the capacity to make real decisions, it is increasingly important to ensure that they are unbiased. In this paper, we argue that the predominant approach of simply removing existing biases from models is not enough. Using a paradigm from the psychology literature, we demonstrate that LLMs can spontaneously develop novel social biases about artificial demographic groups even when no inherent differences exist. These biases result in highly stratified task allocations, which are less fair than assignments by human participants and are exacerbated by newer and larger models. In social science, emergent biases like these have been shown to result from exploration-exploitation trade-offs, where the decision-maker explores too little, allowing early observations to strongly influence impressions about entire demographic groups. To alleviate this effect, we examine a series of interventions targeting model inputs, problem structure, and explicit steering. We find that explicitly incentivizing exploration most robustly reduces stratification, highlighting the need for better multifaceted objectives to mitigate bias. These results reveal that LLMs are not merely passive mirrors of human social biases, but can actively create new ones from experience, raising urgent questions about how these systems will shape societies over time."}
{"id": "2511.06240", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06240", "abs": "https://arxiv.org/abs/2511.06240", "authors": ["Tzu-Jung Lin", "Jia-Fong Yeh", "Hung-Ting Su", "Chung-Yi Lin", "Yi-Ting Chen", "Winston H. Hsu"], "title": "Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation", "comment": "Accepted to AAAI 2026", "summary": "In open-vocabulary mobile manipulation (OVMM), task success often hinges on the selection of an appropriate base placement for the robot. Existing approaches typically navigate to proximity-based regions without considering affordances, resulting in frequent manipulation failures. We propose Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base placement that integrates semantic understanding from vision-language models (VLMs) with geometric feasibility through an iterative optimization process. Our method constructs cross-modal representations, namely Affordance RGB and Obstacle Map+, to align semantics with spatial context. This enables reasoning that extends beyond the egocentric limitations of RGB perception. To ensure interaction is guided by task-relevant affordances, we leverage coarse semantic priors from VLMs to guide the search toward task-relevant regions and refine placements with geometric constraints, thereby reducing the risk of convergence to local optima. Evaluated on five diverse open-vocabulary mobile manipulation tasks, our system achieves an 85% success rate, significantly outperforming classical geometric planners and VLM-based methods. This demonstrates the promise of affordance-aware and multimodal reasoning for generalizable, instruction-conditioned planning in OVMM."}
{"id": "2511.06409", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06409", "abs": "https://arxiv.org/abs/2511.06409", "authors": ["Vishal Cholapadi Ravindra"], "title": "Sensor Importance towards Observability Degree via Shapley Values", "comment": null, "summary": "Sensor selection is an often under-appreciated aspect of state estimator or Kalman filter design. The basic minimum requirement for the choice of a sensor set while designing Kalman filters is that all states are observable. In addition, the sensors should be chosen with a view towards estimating the states with a desired accuracy. Often observability is treated as true/false check during filter design. Beyond observability -- the observability degree -- which measures \\emph{how observable} the states are, has been used as the metric of choice to for sensor selection or placement applications. The higher the degree of observability, the better the possibility of designing Kalman filters that achieve the desired state estimation accuracy and consistency requirements. When a wide variety of sensors are available, sometimes with cost and physical constraints involved, sensor selection plays a crucial role in filter design. In such situations it is important to know the expected contribution of each sensor towards observability degree. Shapley values, developed in cooperative game theory for fair allocation of the payout of a multi-player game to individual players, are widely used in machine learning to assess feature importance. This paper shows that Shapley values can indeed be leveraged to quantify the expected marginal contribution of each sensor in any given sensor set towards the observability degree. This quantification of the fair contribution of each sensor towards the observability degree can be leveraged by filter designers for sensor selection, placement and filter (state estimator) design."}
{"id": "2511.06409", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06409", "abs": "https://arxiv.org/abs/2511.06409", "authors": ["Vishal Cholapadi Ravindra"], "title": "Sensor Importance towards Observability Degree via Shapley Values", "comment": null, "summary": "Sensor selection is an often under-appreciated aspect of state estimator or Kalman filter design. The basic minimum requirement for the choice of a sensor set while designing Kalman filters is that all states are observable. In addition, the sensors should be chosen with a view towards estimating the states with a desired accuracy. Often observability is treated as true/false check during filter design. Beyond observability -- the observability degree -- which measures \\emph{how observable} the states are, has been used as the metric of choice to for sensor selection or placement applications. The higher the degree of observability, the better the possibility of designing Kalman filters that achieve the desired state estimation accuracy and consistency requirements. When a wide variety of sensors are available, sometimes with cost and physical constraints involved, sensor selection plays a crucial role in filter design. In such situations it is important to know the expected contribution of each sensor towards observability degree. Shapley values, developed in cooperative game theory for fair allocation of the payout of a multi-player game to individual players, are widely used in machine learning to assess feature importance. This paper shows that Shapley values can indeed be leveraged to quantify the expected marginal contribution of each sensor in any given sensor set towards the observability degree. This quantification of the fair contribution of each sensor towards the observability degree can be leveraged by filter designers for sensor selection, placement and filter (state estimator) design."}
{"id": "2511.06175", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.06175", "abs": "https://arxiv.org/abs/2511.06175", "authors": ["Kaijie Xu", "Fandi Meng", "Clark Verbrugge", "Simon Lucas"], "title": "CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference", "comment": null, "summary": "In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary \"reasoning tool.\" Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs."}
{"id": "2511.05747", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05747", "abs": "https://arxiv.org/abs/2511.05747", "authors": ["Ziqian Bi", "Kaijie Chen", "Tianyang Wang", "Junfeng Hao", "Xinyuan Song"], "title": "CoT-X: An Adaptive Framework for Cross-Model Chain-of-Thought Transfer and Optimization", "comment": "TKDD 2025", "summary": "Chain-of-Thought (CoT) reasoning enhances the problem-solving ability of large language models (LLMs) but leads to substantial inference overhead, limiting deployment in resource-constrained settings. This paper investigates efficient CoT transfer across models of different scales and architectures through an adaptive reasoning summarization framework. The proposed method compresses reasoning traces via semantic segmentation with importance scoring, budget-aware dynamic compression, and coherence reconstruction, preserving critical reasoning steps while significantly reducing token usage. Experiments on 7{,}501 medical examination questions across 10 specialties show up to 40% higher accuracy than truncation under the same token budgets. Evaluations on 64 model pairs from eight LLMs (1.5B-32B parameters, including DeepSeek-R1 and Qwen3) confirm strong cross-model transferability. Furthermore, a Gaussian Process-based Bayesian optimization module reduces evaluation cost by 84% and reveals a power-law relationship between model size and cross-domain robustness. These results demonstrate that reasoning summarization provides a practical path toward efficient CoT transfer, enabling advanced reasoning under tight computational constraints. Code will be released upon publication."}
{"id": "2511.06191", "categories": ["cs.CY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.06191", "abs": "https://arxiv.org/abs/2511.06191", "authors": ["Soujanya Dash", "Kenjiro Ide", "Rikuhei Umemoto", "Kai Amino", "Keisuke Fujii"], "title": "Prediction-based evaluation of back-four defense with spatial control in soccer", "comment": "22 pages, 4 figures", "summary": "Defensive organization is critical in soccer, particularly during negative transitions when teams are most vulnerable. The back-four defensive line plays a decisive role in preventing goal-scoring opportunities, yet its collective coordination remains difficult to quantify. This study introduces interpretable spatio-temporal indicators namely, space control, stretch index, pressure index, and defensive line height (absolute and relative) to evaluate the effectiveness of the back-four during defensive transitions. Using synchronized tracking and event data from the 2023-24 LaLiga season, 2,413 defensive sequences were analyzed following possession losses by FC Barcelona and Real Madrid CF. Two-way ANOVA revealed significant effects of team, outcome, and their interaction for key indicators, with relative line height showing the strongest association with defensive success. Predictive modeling using XGBoost achieved the highest discriminative performance (ROC AUC: 0.724 for Barcelona, 0.698 for Real Madrid), identifying space score and relative line height as dominant predictors. Comparative analysis revealed distinct team-specific defensive behaviors: Barcelona's success was characterized by higher spatial control and compact line coordination, whereas Real Madrid exhibited more adaptive but less consistent defensive structures. These findings demonstrate the tactical and predictive value of interpretable spatial indicators for quantifying collective defensive performance."}
{"id": "2511.06267", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06267", "abs": "https://arxiv.org/abs/2511.06267", "authors": ["Jiayi Chen", "Wei Zhao", "Liangwang Ruan", "Baoquan Chen", "He Wang"], "title": "Robust Differentiable Collision Detection for General Objects", "comment": null, "summary": "Collision detection is a core component of robotics applications such as simulation, control, and planning. Traditional algorithms like GJK+EPA compute witness points (i.e., the closest or deepest-penetration pairs between two objects) but are inherently non-differentiable, preventing gradient flow and limiting gradient-based optimization in contact-rich tasks such as grasping and manipulation. Recent work introduced efficient first-order randomized smoothing to make witness points differentiable; however, their direction-based formulation is restricted to convex objects and lacks robustness for complex geometries. In this work, we propose a robust and efficient differentiable collision detection framework that supports both convex and concave objects across diverse scales and configurations. Our method introduces distance-based first-order randomized smoothing, adaptive sampling, and equivalent gradient transport for robust and informative gradient computation. Experiments on complex meshes from DexGraspNet and Objaverse show significant improvements over existing baselines. Finally, we demonstrate a direct application of our method for dexterous grasp synthesis to refine the grasp quality. The code is available at https://github.com/JYChen18/DiffCollision."}
{"id": "2511.06508", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06508", "abs": "https://arxiv.org/abs/2511.06508", "authors": ["Grace E. Calkins", "Jay W. McMahon", "Jackson Kulik"], "title": "Optimal Rank-1 Directional State Transition Tensors", "comment": "Submitted to AIAA Journal of Guidance, Control, and Dynamics", "summary": "An optimal rank-1 approximation of state transition tensors was developed as an efficient alternative to state transition tensors for nonlinear uncertainty quantification. While previous directional state transition tensors used the dominant right singular subspace of the state transition matrix to construct a reduced-dimension representation of the state transition tensors, optimal directional state transition tensors are constructed to maximize the information retained in a rank-1 approximation of the state transition tensors in the Frobenius-norm sense. The optimal rank-1 directional state transition tensor is found by solving a tensor z-eigenpair problem of the \"square\" of the state transition tensor. This construct leads to increased approximation accuracy of the state transition tensors and improved Gaussian moment propagation for nonlinear flight scenarios like aerocapture."}
{"id": "2511.06508", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06508", "abs": "https://arxiv.org/abs/2511.06508", "authors": ["Grace E. Calkins", "Jay W. McMahon", "Jackson Kulik"], "title": "Optimal Rank-1 Directional State Transition Tensors", "comment": "Submitted to AIAA Journal of Guidance, Control, and Dynamics", "summary": "An optimal rank-1 approximation of state transition tensors was developed as an efficient alternative to state transition tensors for nonlinear uncertainty quantification. While previous directional state transition tensors used the dominant right singular subspace of the state transition matrix to construct a reduced-dimension representation of the state transition tensors, optimal directional state transition tensors are constructed to maximize the information retained in a rank-1 approximation of the state transition tensors in the Frobenius-norm sense. The optimal rank-1 directional state transition tensor is found by solving a tensor z-eigenpair problem of the \"square\" of the state transition tensor. This construct leads to increased approximation accuracy of the state transition tensors and improved Gaussian moment propagation for nonlinear flight scenarios like aerocapture."}
{"id": "2511.06185", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06185", "abs": "https://arxiv.org/abs/2511.06185", "authors": ["Xinyuan Wang", "Yanjie Fu"], "title": "Dataforge: A Data Agent Platform for Autonomous Data Engineering", "comment": null, "summary": "The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed \"From Data to Better Data.\""}
{"id": "2511.05757", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05757", "abs": "https://arxiv.org/abs/2511.05757", "authors": ["Hassan Iqbal", "Xingjian Li", "Tyler Ingebrand", "Adam Thorpe", "Krishna Kumar", "Ufuk Topcu", "Ján Drgoňa"], "title": "Zero-Shot Function Encoder-Based Differentiable Predictive Control", "comment": null, "summary": "We introduce a differentiable framework for zero-shot adaptive control over parametric families of nonlinear dynamical systems. Our approach integrates a function encoder-based neural ODE (FE-NODE) for modeling system dynamics with a differentiable predictive control (DPC) for offline self-supervised learning of explicit control policies. The FE-NODE captures nonlinear behaviors in state transitions and enables zero-shot adaptation to new systems without retraining, while the DPC efficiently learns control policies across system parameterizations, thus eliminating costly online optimization common in classical model predictive control. We demonstrate the efficiency, accuracy, and online adaptability of the proposed method across a range of nonlinear systems with varying parametric scenarios, highlighting its potential as a general-purpose tool for fast zero-shot adaptive control."}
{"id": "2511.06472", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06472", "abs": "https://arxiv.org/abs/2511.06472", "authors": ["Adele Olof-Ors", "Martin Smit"], "title": "Simulated Affection, Engineered Trust: How Anthropomorphic AI Benefits Surveillance Capitalism", "comment": "7 pages", "summary": "In this paper, we argue that anthropomorphized technology, designed to simulate emotional realism, are not neutral tools but cognitive infrastructures that manipulate user trust and behaviour. This reinforces the logic of surveillance capitalism, an under-regulated economic system that profits from behavioural manipulation and monitoring. Drawing on Nicholas Carr's theory of the intellectual ethic, we identify how technologies such as chatbots, virtual assistants, or generative models reshape not only what we think about ourselves and our world, but how we think at the cognitive level. We identify how the emerging intellectual ethic of AI benefits a system of surveillance capitalism, and discuss the potential ways of addressing this."}
{"id": "2511.06311", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06311", "abs": "https://arxiv.org/abs/2511.06311", "authors": ["Seiichi Yamamoto", "Hiroki Ishizuka", "Takumi Kawasetsu", "Koh Hosoda", "Takayuki Kameoka", "Kango Yanagida", "Takato Horii", "Sei Ikeda", "Osamu Oshiro"], "title": "External Photoreflective Tactile Sensing Based on Surface Deformation Measurement", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We present a tactile sensing method enabled by the mechanical compliance of soft robots; an externally attachable photoreflective module reads surface deformation of silicone skin to estimate contact force without embedding tactile transducers. Locating the sensor off the contact interface reduces damage risk, preserves softness, and simplifies fabrication and maintenance. We first characterize the optical sensing element and the compliant skin, thendetermine the design of a prototype tactile sensor. Compression experiments validate the approach, exhibiting a monotonic force output relationship consistent with theory, low hysteresis, high repeatability over repeated cycles, and small response indentation speeds. We further demonstrate integration on a soft robotic gripper, where the module reliably detects grasp events. Compared with liquid filled or wireembedded tactile skins, the proposed modular add on architecture enhances durability, reduces wiring complexity, and supports straightforward deployment across diverse robot geometries. Because the sensing principle reads skin strain patterns, it also suggests extensions to other somatosensory cues such as joint angle or actuator state estimation from surface deformation. Overall, leveraging surface compliance with an external optical module provides a practical and robust route to equip soft robots with force perception while preserving structural flexibility and manufacturability, paving the way for robotic applications and safe human robot collaboration."}
{"id": "2511.06520", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06520", "abs": "https://arxiv.org/abs/2511.06520", "authors": ["Nina Stipetic", "Bozidar Filipovic-Grcic", "Igor Ziger", "Silvio Jancin", "Bruno Jurisic", "Dalibor Filipovic-Grcic", "Alain Xémard"], "title": "Verification of low-frequency signal injection method for earth-fault detection", "comment": "10 pages", "summary": "Unearthed neutral is commonly used in networks which require continuous power supply. This is common in MV circuits of industrial and power plants. Unearthed networks can remain in operation during an earth-fault, but fast determination of the faulty line is key for prevention of further fault escalation. Signal injection is one of the fault location methods often used in LV unearthed networks. The possibility of applying this method in MV networks depends on how to inject the signal into unearthed phases. In such networks, it is possible to use a group of three inductive voltage transformers (IVTs) for signal injection. After the simulations have shown promising results of signal injection and earth-fault detection in MV network, an experimental test was performed. This paper describes the experimental setup and shows the measurement results of signal injection method at MV level supported by EMT simulations."}
{"id": "2511.06520", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06520", "abs": "https://arxiv.org/abs/2511.06520", "authors": ["Nina Stipetic", "Bozidar Filipovic-Grcic", "Igor Ziger", "Silvio Jancin", "Bruno Jurisic", "Dalibor Filipovic-Grcic", "Alain Xémard"], "title": "Verification of low-frequency signal injection method for earth-fault detection", "comment": "10 pages", "summary": "Unearthed neutral is commonly used in networks which require continuous power supply. This is common in MV circuits of industrial and power plants. Unearthed networks can remain in operation during an earth-fault, but fast determination of the faulty line is key for prevention of further fault escalation. Signal injection is one of the fault location methods often used in LV unearthed networks. The possibility of applying this method in MV networks depends on how to inject the signal into unearthed phases. In such networks, it is possible to use a group of three inductive voltage transformers (IVTs) for signal injection. After the simulations have shown promising results of signal injection and earth-fault detection in MV network, an experimental test was performed. This paper describes the experimental setup and shows the measurement results of signal injection method at MV level supported by EMT simulations."}
{"id": "2511.06209", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06209", "abs": "https://arxiv.org/abs/2511.06209", "authors": ["Jingwei Ni", "Ekaterina Fadeeva", "Tianyi Wu", "Mubashara Akhtar", "Jiaheng Zhang", "Elliott Ash", "Markus Leippold", "Timothy Baldwin", "See-Kiong Ng", "Artem Shelmanov", "Mrinmaya Sachan"], "title": "Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads", "comment": "Preprint under review", "summary": "Solving complex tasks usually requires LLMs to generate long multi-step reasoning chains. Previous work has shown that verifying the correctness of individual reasoning steps can further improve the performance and efficiency of LLMs on such tasks and enhance solution interpretability. However, existing verification approaches, such as Process Reward Models (PRMs), are either computationally expensive, limited to specific domains, or require large-scale human or model-generated annotations. Thus, we propose a lightweight alternative for step-level reasoning verification based on data-driven uncertainty scores. We train transformer-based uncertainty quantification heads (UHeads) that use the internal states of a frozen LLM to estimate the uncertainty of its reasoning steps during generation. The approach is fully automatic: target labels are generated either by another larger LLM (e.g., DeepSeek R1) or in a self-supervised manner by the original model itself. UHeads are both effective and lightweight, containing less than 10M parameters. Across multiple domains, including mathematics, planning, and general knowledge question answering, they match or even surpass the performance of PRMs that are up to 810x larger. Our findings suggest that the internal states of LLMs encode their uncertainty and can serve as reliable signals for reasoning verification, offering a promising direction toward scalable and generalizable introspective LLMs."}
{"id": "2511.05764", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05764", "abs": "https://arxiv.org/abs/2511.05764", "authors": ["Samvrit Srinath", "Annapurna Vadaparty", "David H. Smith", "Leo Porter", "Daniel Zingaro"], "title": "Assessing Problem Decomposition in CS1 for the GenAI Era", "comment": null, "summary": "Problem decomposition--the ability to break down a large task into smaller, well-defined components--is a critical skill for effectively designing and creating large programs, but it is often not included in introductory computer science curricula. With the rise of generative AI (GenAI), students even at the introductory level are able to generate large quantities of code, and it is becoming increasingly important to equip them with the ability to decompose problems. There is not yet a consensus among educators on how to best teach and assess the skill of decomposition, particularly in introductory computing. This practitioner paper details the development of questions to assess the skill of problem decomposition, and impressions about how these questions were received by students. A challenge unique to problem decomposition questions is their necessarily lengthy context, and we detail our approach to addressing this problem using Question Suites: scaffolded sequences of questions that help students understand a question's context before attempting to decompose it. We then describe the use of open-ended drawing of decomposition diagrams as another form of assessment. We outline the learning objectives used to design our questions and describe how we addressed challenges encountered in early iterations. We present our decomposition assessment materials and reflections on them for educators who wish to teach problem decomposition to beginner programmers."}
{"id": "2511.06525", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06525", "abs": "https://arxiv.org/abs/2511.06525", "authors": ["Philip Trippenbach", "Isabella Scala", "Jai Bhambra", "Rowan Emslie"], "title": "From Catastrophic to Concrete: Reframing AI Risk Communication for Public Mobilization", "comment": "25 pages, 9 figures", "summary": "Effective governance of artificial intelligence (AI) requires public engagement, yet communication strategies centered on existential risk have not produced sustained mobilization. In this paper, we examine the psychological and opinion barriers that limit engagement with extinction narratives, such as mortality avoidance, exponential growth bias, and the absence of self-referential anchors. We contrast them with evidence that public concern over AI rises when framed in terms of proximate harms such as employment disruption, relational instability, and mental health issues. We validate these findings through actual message testing with 1063 respondents, with the evidence showing that AI risks to Jobs and Children have the highest potential to mobilize people, while Existential Risk is the lowest-performing theme across all demographics. Using survey data from five countries, we identify two segments (Tech-Positive Urbanites and World Guardians) as particularly receptive to such framing and more likely to participate in civic action. Finally, we argue that mobilization around these everyday concerns can raise the political salience of AI, creating \"policy demand\" for structural measures to mitigate AI risks. We conclude that this strategy creates the conditions for successful regulatory change."}
{"id": "2511.06371", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06371", "abs": "https://arxiv.org/abs/2511.06371", "authors": ["Yingnan Zhao", "Xinmiao Wang", "Dewei Wang", "Xinzhe Liu", "Dan Lu", "Qilong Han", "Peng Liu", "Chenjia Bai"], "title": "Towards Adaptive Humanoid Control via Multi-Behavior Distillation and Reinforced Fine-Tuning", "comment": null, "summary": "Humanoid robots are promising to learn a diverse set of human-like locomotion behaviors, including standing up, walking, running, and jumping. However, existing methods predominantly require training independent policies for each skill, yielding behavior-specific controllers that exhibit limited generalization and brittle performance when deployed on irregular terrains and in diverse situations. To address this challenge, we propose Adaptive Humanoid Control (AHC) that adopts a two-stage framework to learn an adaptive humanoid locomotion controller across different skills and terrains. Specifically, we first train several primary locomotion policies and perform a multi-behavior distillation process to obtain a basic multi-behavior controller, facilitating adaptive behavior switching based on the environment. Then, we perform reinforced fine-tuning by collecting online feedback in performing adaptive behaviors on more diverse terrains, enhancing terrain adaptability for the controller. We conduct experiments in both simulation and real-world experiments in Unitree G1 robots. The results show that our method exhibits strong adaptability across various situations and terrains. Project website: https://ahc-humanoid.github.io."}
{"id": "2511.06523", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06523", "abs": "https://arxiv.org/abs/2511.06523", "authors": ["Selma Grebovic", "Abdulah Aksamovic", "Bozidar Filipovic-Grcic", "Samim Konjicija"], "title": "Investigation of lightning effects on solar power plants connected to transmission networks", "comment": "8 pages", "summary": "The increasing integration of solar power plants into transmission grids has raised concerns about their vulnerability to disturbances, particularly lightning strokes. Solar energy, while offering significant environmental and economic benefits, faces challenges when connected to transmission lines that are prone to lightning discharges. This paper investigates the impact of lightning events on solar power plants, focusing on overvoltage effects. Lightning stroke simulations were conducted at various distances from the solar power plant along the transmission line, considering scenarios with and without surge arrester. Key lightning parameters such as peak current, front time, and tail time were varied to simulate different lightning strokes. The study also includes a Fourier transform analysis of the resulting overvoltages with and without a surge arrester, along with the Hilbert marginal spectrum of these overvoltages. The results provide insights into the effectiveness of surge arresters in mitigating lightning overvoltages and highlight the importance of proper protective measures for enhancing the reliability and safety of solar power plants connected to transmission networks."}
{"id": "2511.06523", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06523", "abs": "https://arxiv.org/abs/2511.06523", "authors": ["Selma Grebovic", "Abdulah Aksamovic", "Bozidar Filipovic-Grcic", "Samim Konjicija"], "title": "Investigation of lightning effects on solar power plants connected to transmission networks", "comment": "8 pages", "summary": "The increasing integration of solar power plants into transmission grids has raised concerns about their vulnerability to disturbances, particularly lightning strokes. Solar energy, while offering significant environmental and economic benefits, faces challenges when connected to transmission lines that are prone to lightning discharges. This paper investigates the impact of lightning events on solar power plants, focusing on overvoltage effects. Lightning stroke simulations were conducted at various distances from the solar power plant along the transmission line, considering scenarios with and without surge arrester. Key lightning parameters such as peak current, front time, and tail time were varied to simulate different lightning strokes. The study also includes a Fourier transform analysis of the resulting overvoltages with and without a surge arrester, along with the Hilbert marginal spectrum of these overvoltages. The results provide insights into the effectiveness of surge arresters in mitigating lightning overvoltages and highlight the importance of proper protective measures for enhancing the reliability and safety of solar power plants connected to transmission networks."}
{"id": "2511.06221", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06221", "abs": "https://arxiv.org/abs/2511.06221", "authors": ["Sen Xu", "Yi Zhou", "Wei Wang", "Jixin Min", "Zhibin Yin", "Yingwei Dai", "Shixi Liu", "Lianyu Pang", "Yirong Chen", "Junlin Zhang"], "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B", "comment": null, "summary": "Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research."}
{"id": "2511.05766", "categories": ["cs.AI", "cs.CL", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05766", "abs": "https://arxiv.org/abs/2511.05766", "authors": ["Felipe Valencia-Clavijo"], "title": "Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs", "comment": null, "summary": "Large language models (LLMs) are increasingly examined as both behavioral subjects and decision systems, yet it remains unclear whether observed cognitive biases reflect surface imitation or deeper probability shifts. Anchoring bias, a classic human judgment bias, offers a critical test case. While prior work shows LLMs exhibit anchoring, most evidence relies on surface-level outputs, leaving internal mechanisms and attributional contributions unexplored. This paper advances the study of anchoring in LLMs through three contributions: (1) a log-probability-based behavioral analysis showing that anchors shift entire output distributions, with controls for training-data contamination; (2) exact Shapley-value attribution over structured prompt fields to quantify anchor influence on model log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score integrating behavioral and attributional evidence across six open-source models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and Llama-2-7B, with attribution signaling that the anchors influence reweighting. Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability, suggesting scale may modulate sensitivity. Attributional effects, however, vary across prompt designs, underscoring fragility in treating LLMs as human substitutes. The findings demonstrate that anchoring bias in LLMs is robust, measurable, and interpretable, while highlighting risks in applied domains. More broadly, the framework bridges behavioral science, LLM safety, and interpretability, offering a reproducible path for evaluating other cognitive biases in LLMs."}
{"id": "2511.06700", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06700", "abs": "https://arxiv.org/abs/2511.06700", "authors": ["Damian Curran", "Vanessa Sporne", "Lea Frermann", "Jeannie Paterson"], "title": "Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries", "comment": null, "summary": "How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM-based chatbots varies depending on their location. However, obtaining meaningful comparative metrics is challenging because legal institutions in different places are not themselves easily comparable. In this work we propose a methodology to obtain place-to-place metrics based on the comparative law concept of functionalism. We construct a dataset of factual scenarios drawn from Reddit posts by users seeking legal advice for family, housing, employment, crime and traffic issues. We use these to elicit a summary of a law from the LLM relevant to each scenario in Los Angeles, London and Sydney. These summaries, typically of a legislative provision, are manually evaluated for hallucinations. We show that the rate of hallucination of legal information by leading closed-source LLMs is significantly associated with place. This suggests that the quality of legal solutions provided by these models is not evenly distributed across geography. Additionally, we show a strong negative correlation between hallucination rate and the frequency of the majority response when the LLM is sampled multiple times, suggesting a measure of uncertainty of model predictions of legal facts."}
{"id": "2511.06378", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06378", "abs": "https://arxiv.org/abs/2511.06378", "authors": ["Prajval Kumar Murali", "Mohsen Kaboli"], "title": "ArtReg: Visuo-Tactile based Pose Tracking and Manipulation of Unseen Articulated Objects", "comment": "Under review", "summary": "Robots operating in real-world environments frequently encounter unknown objects with complex structures and articulated components, such as doors, drawers, cabinets, and tools. The ability to perceive, track, and manipulate these objects without prior knowledge of their geometry or kinematic properties remains a fundamental challenge in robotics. In this work, we present a novel method for visuo-tactile-based tracking of unseen objects (single, multiple, or articulated) during robotic interaction without assuming any prior knowledge regarding object shape or dynamics. Our novel pose tracking approach termed ArtReg (stands for Articulated Registration) integrates visuo-tactile point clouds in an unscented Kalman Filter formulation in the SE(3) Lie Group for point cloud registration. ArtReg is used to detect possible articulated joints in objects using purposeful manipulation maneuvers such as pushing or hold-pulling with a two-robot team. Furthermore, we leverage ArtReg to develop a closed-loop controller for goal-driven manipulation of articulated objects to move the object into the desired pose configuration. We have extensively evaluated our approach on various types of unknown objects through real robot experiments. We also demonstrate the robustness of our method by evaluating objects with varying center of mass, low-light conditions, and with challenging visual backgrounds. Furthermore, we benchmarked our approach on a standard dataset of articulated objects and demonstrated improved performance in terms of pose accuracy compared to state-of-the-art methods. Our experiments indicate that robust and accurate pose tracking leveraging visuo-tactile information enables robots to perceive and interact with unseen complex articulated objects (with revolute or prismatic joints)."}
{"id": "2511.06524", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06524", "abs": "https://arxiv.org/abs/2511.06524", "authors": ["Haihui Gao", "Alessandro Bosso", "Lei Wang", "David Saussié", "Bowen Yi"], "title": "Input-Output Data-Driven Stabilization of Continuous-Time Linear MIMO Systems", "comment": null, "summary": "In this paper, we address the problem of data-driven stabilization of continuous-time multi-input multi-output (MIMO) linear time-invariant systems using the input-output data collected from an experiment. Building on recent results for data-driven output-feedback control based on non-minimal realizations, we propose an approach that can be applied to a broad class of continuous-time MIMO systems without requiring a uniform observability index. The key idea is to show that Kreisselmeier's adaptive filter can be interpreted as an observer of a stabilizable non-minimal realization of the plant. Then, by postprocessing the input-output data with such a filter, we derive a linear matrix inequality that yields the feedback gain of a dynamic output-feedback stabilizer."}
{"id": "2511.06524", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06524", "abs": "https://arxiv.org/abs/2511.06524", "authors": ["Haihui Gao", "Alessandro Bosso", "Lei Wang", "David Saussié", "Bowen Yi"], "title": "Input-Output Data-Driven Stabilization of Continuous-Time Linear MIMO Systems", "comment": null, "summary": "In this paper, we address the problem of data-driven stabilization of continuous-time multi-input multi-output (MIMO) linear time-invariant systems using the input-output data collected from an experiment. Building on recent results for data-driven output-feedback control based on non-minimal realizations, we propose an approach that can be applied to a broad class of continuous-time MIMO systems without requiring a uniform observability index. The key idea is to show that Kreisselmeier's adaptive filter can be interpreted as an observer of a stabilizable non-minimal realization of the plant. Then, by postprocessing the input-output data with such a filter, we derive a linear matrix inequality that yields the feedback gain of a dynamic output-feedback stabilizer."}
{"id": "2511.06226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06226", "abs": "https://arxiv.org/abs/2511.06226", "authors": ["Xingcheng Liu", "Yanchen Guan", "Haicheng Liao", "Zhengbing He", "Zhenning Li"], "title": "ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving", "comment": "Published to Accident Analysis and Prevention", "summary": "Accurate accident anticipation is essential for enhancing the safety of autonomous vehicles (AVs). However, existing methods often assume ideal conditions, overlooking challenges such as sensor failures, environmental disturbances, and data imperfections, which can significantly degrade prediction accuracy. Additionally, previous models have not adequately addressed the considerable variability in driver behavior and accident rates across different vehicle types. To overcome these limitations, this study introduces ROAR, a novel approach for accident detection and prediction. ROAR combines Discrete Wavelet Transform (DWT), a self adaptive object aware module, and dynamic focal loss to tackle these challenges. The DWT effectively extracts features from noisy and incomplete data, while the object aware module improves accident prediction by focusing on high-risk vehicles and modeling the spatial temporal relationships among traffic agents. Moreover, dynamic focal loss mitigates the impact of class imbalance between positive and negative samples. Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently outperforms existing baselines in key metrics such as Average Precision (AP) and mean Time to Accident (mTTA). These results demonstrate the model's robustness in real-world conditions, particularly in handling sensor degradation, environmental noise, and imbalanced data distributions. This work offers a promising solution for reliable and accurate accident anticipation in complex traffic environments."}
{"id": "2511.05775", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05775", "abs": "https://arxiv.org/abs/2511.05775", "authors": ["Li-Yu Lin", "Benjamin Perseghetti", "James Goppert"], "title": "Log-linear Backstepping control on $SE_2(3)$", "comment": "4 pages, preliminary version, to be updated with full Lyapunov proof and extended results", "summary": "Most of the rigid-body systems which evolve on nonlinear Lie groups where Euclidean control designs lose geometric meaning. In this paper, we introduce a log-linear backstepping control law on SE2(3) that preserves full rotational-translational coupling. Leveraging a class of mixed-invariant system, which is a group-affine dynamic model, we derive exact logarithmic error dynamics that are linear in the Lie algebra. The closed-form expressions for the left- and right-Jacobian inverses of SE2(3) are expressed in the paper, which provides us the exact error dynamics without local approximations. A log-linear backstepping control design ensures exponential stability for our error dynamics; since our error dynamics is a block-triangular structure, this allows us to use Linear Matrix Inequality (LMI) formulation or $H_\\infty$ gain performance design. This work establishes the exact backstepping framework for a class of mixed-invariant system, providing a geometrically consistent foundation for future Unmanned Aerial Vehicle (UAV) and spacecraft control design."}
{"id": "2511.07306", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.07306", "abs": "https://arxiv.org/abs/2511.07306", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Het 'right to be forgotten' en bijzondere persoonsgegevens: geen ruimte meer voor een belangenafweging? [The 'Right to Be Forgotten' and Sensitive Personal Data: No Room for Balancing?]", "comment": "In Dutch", "summary": "An attorney submitted a 'right to be forgotten' delisting request to Google, regarding a blog post about a criminal conviction of the attorney in another country. The Rotterdam District Court ruled that Google may no longer link to the blog post when people search for the attorney's name. The court granted the attorney's request because the blog post concerns a criminal conviction. Personal data regarding criminal convictions are, under Dutch law, special categories of data (sometimes called sensitive data). The reasoning of the court on special categories of data creates problems for freedom of expression. This paper, in Dutch, explores how these problems can be reduced. Google has appealed the decision; the judgment of the Court of Appeals is expected in March 2017."}
{"id": "2511.06385", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06385", "abs": "https://arxiv.org/abs/2511.06385", "authors": ["Ralf Römer", "Julian Balletshofer", "Jakob Thumm", "Marco Pavone", "Angela P. Schoellig", "Matthias Althoff"], "title": "From Demonstrations to Safe Deployment: Path-Consistent Safety Filtering for Diffusion Policies", "comment": "Project page: https://tum-lsy.github.io/pacs/. 8 pages, 4 figures", "summary": "Diffusion policies (DPs) achieve state-of-the-art performance on complex manipulation tasks by learning from large-scale demonstration datasets, often spanning multiple embodiments and environments. However, they cannot guarantee safe behavior, so external safety mechanisms are needed. These, however, alter actions in ways unseen during training, causing unpredictable behavior and performance degradation. To address these problems, we propose path-consistent safety filtering (PACS) for DPs. Our approach performs path-consistent braking on a trajectory computed from the sequence of generated actions. In this way, we keep execution consistent with the policy's training distribution, maintaining the learned, task-completing behavior. To enable a real-time deployment and handle uncertainties, we verify safety using set-based reachability analysis. Our experimental evaluation in simulation and on three challenging real-world human-robot interaction tasks shows that PACS (a) provides formal safety guarantees in dynamic environments, (b) preserves task success rates, and (c) outperforms reactive safety approaches, such as control barrier functions, by up to 68% in terms of task success. Videos are available at our project website: https://tum-lsy.github.io/pacs/."}
{"id": "2511.06528", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06528", "abs": "https://arxiv.org/abs/2511.06528", "authors": ["Qinghua Ma", "Seyyedali Hosseinalipour", "Ming Shi", "Jan Drgona", "Shimiao Li"], "title": "Voltage-Regulated Sparse Optimization for Proactive Diagnosis of Voltage Collapses", "comment": null, "summary": "This paper aims to proactively diagnose and manage the voltage collapse risks, i.e., the risk of bus voltages violating the safe operational bounds, which can be caused by extreme events and contingencies. We jointly answer two resilience-related research questions: (Q1) Survivability: Upon having an extreme event/contingency, will the system remain feasible with voltage staying within a (preferred) safe range? (Q2) Dominant Vulnerability: If voltage collapses, what are the dominant sources of system vulnerabilities responsible for the failure? This highlights some key locations worth paying attention to in the planning or decision-making process. To address these questions, we propose a voltage-regulated sparse optimization that finds a minimal set of bus locations along with quantified compensations (corrective actions) that can simultaneously enforce AC network balance and voltage bounds. Results on transmission systems of varying sizes (30-bus to 2383-bus) demonstrate that the proposed method effectively mitigates voltage collapses by compensating at only a few strategically identified nodes, while scaling efficiently to large systems, taking on average less than 4 min for 2000+ bus cases. This work can further serve as a backbone for more comprehensive and actionable decision-making, such as reactive power planning to fix voltage issues."}
{"id": "2511.06528", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06528", "abs": "https://arxiv.org/abs/2511.06528", "authors": ["Qinghua Ma", "Seyyedali Hosseinalipour", "Ming Shi", "Jan Drgona", "Shimiao Li"], "title": "Voltage-Regulated Sparse Optimization for Proactive Diagnosis of Voltage Collapses", "comment": null, "summary": "This paper aims to proactively diagnose and manage the voltage collapse risks, i.e., the risk of bus voltages violating the safe operational bounds, which can be caused by extreme events and contingencies. We jointly answer two resilience-related research questions: (Q1) Survivability: Upon having an extreme event/contingency, will the system remain feasible with voltage staying within a (preferred) safe range? (Q2) Dominant Vulnerability: If voltage collapses, what are the dominant sources of system vulnerabilities responsible for the failure? This highlights some key locations worth paying attention to in the planning or decision-making process. To address these questions, we propose a voltage-regulated sparse optimization that finds a minimal set of bus locations along with quantified compensations (corrective actions) that can simultaneously enforce AC network balance and voltage bounds. Results on transmission systems of varying sizes (30-bus to 2383-bus) demonstrate that the proposed method effectively mitigates voltage collapses by compensating at only a few strategically identified nodes, while scaling efficiently to large systems, taking on average less than 4 min for 2000+ bus cases. This work can further serve as a backbone for more comprehensive and actionable decision-making, such as reactive power planning to fix voltage issues."}
{"id": "2511.06262", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06262", "abs": "https://arxiv.org/abs/2511.06262", "authors": ["Siming Zhao", "Qi Li"], "title": "GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening", "comment": null, "summary": "Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows."}
{"id": "2511.05779", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05779", "abs": "https://arxiv.org/abs/2511.05779", "authors": ["Ahmed Saad Al-Karsani", "Maryam Khanbaghi"], "title": "Autonomous and Distributed Synchronization and Restoration of an Islanded Network of Microgrids", "comment": null, "summary": "The transition towards clean energy and the introduction of Inverter-Based Resources (IBRs) are leading to the formation of Microgrids (MGs) and Network of MGs (NMGs). MGs and NMGs can operate autonomously in islanded mode, which requires Grid-Forming (GFM) IBRs that can perform black start, synchronization, restoration and regulation. However, such IBRs face synchronization instability issues, which might be worsened by inadequate secondary level frequency and voltage regulation. Accordingly, we propose an autonomous and distributed synchronization and restoration scheme using Distributed-Averaging Proportional-Integral (DAPI) control. To validate the proposed method, we model and simulate a high-fidelity islanded and modified IEEE 123 bus system, modeled as an NMG consisting of 7 MGs. The simulation results demonstrate an effective autonomous soft-start, synchronization, connection and regulation procedure using DAPI control and distributed breaker operation logic."}
{"id": "2511.07307", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.07307", "abs": "https://arxiv.org/abs/2511.07307", "authors": ["Frederik J. Zuiderveen Borgesius"], "title": "Singling out people without knowing their names - Behavioural targeting, pseudonymous data, and the New Data Protection Regulation", "comment": null, "summary": "Information about millions of people is collected for behavioural targeting, a type of marketing that involves tracking people's online behaviour for targeted advertising. It is hotly debated whether data protection law applies to behavioural targeting. Many behavioural targeting companies say that, as long as they do not tie names to data they hold about individuals, they do not process any personal data, and that, therefore, data protection law does not apply to them. European Data Protection Authorities, however, take the view that a company processes personal data if it uses data to single out a person, even if it cannot tie a name to these data. This paper argues that data protection law should indeed apply to behavioural targeting. Companies can often tie a name to nameless data about individuals. Furthermore, behavioural targeting relies on collecting information about individuals, singling out individuals, and targeting ads to individuals. Many privacy risks remain, regardless of whether companies tie a name to the information they hold about a person. A name is merely one of the identifiers that can be tied to data about a person, and it is not even the most practical identifier for behavioural targeting. Seeing data used to single out a person as personal data fits the rationale for data protection law: protecting fairness and privacy."}
{"id": "2511.06397", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06397", "abs": "https://arxiv.org/abs/2511.06397", "authors": ["Cong Wen", "Yunfei Li", "Kexin Liu", "Yixin Qiu", "Xuanhong Liao", "Tianyu Wang", "Dingchuan Liu", "Tao Zhang", "Ximin Lyu"], "title": "Whole-Body Control With Terrain Estimation of A 6-DoF Wheeled Bipedal Robot", "comment": "8 pages, 8 figures", "summary": "Wheeled bipedal robots have garnered increasing attention in exploration and inspection. However, most research simplifies calculations by ignoring leg dynamics, thereby restricting the robot's full motion potential. Additionally, robots face challenges when traversing uneven terrain. To address the aforementioned issue, we develop a complete dynamics model and design a whole-body control framework with terrain estimation for a novel 6 degrees of freedom wheeled bipedal robot. This model incorporates the closed-loop dynamics of the robot and a ground contact model based on the estimated ground normal vector. We use a LiDAR inertial odometry framework and improved Principal Component Analysis for terrain estimation. Task controllers, including PD control law and LQR, are employed for pose control and centroidal dynamics-based balance control, respectively. Furthermore, a hierarchical optimization approach is used to solve the whole-body control problem. We validate the performance of the terrain estimation algorithm and demonstrate the algorithm's robustness and ability to traverse uneven terrain through both simulation and real-world experiments."}
{"id": "2511.06576", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06576", "abs": "https://arxiv.org/abs/2511.06576", "authors": ["Mohammad Javad Najafirad", "Shirantha Welikala", "Lei Wu", "Panos J. Antsaklis"], "title": "Dissipativity-Based Synthesis of Distributed Control and Communication Topology Co-Design for AC Microgrids", "comment": null, "summary": "This paper presents a novel dissipativity-based framework for co-designing distributed controllers and communication topologies in AC microgrids (MGs). Unlike existing methods that treat control synthesis and topology design separately, we propose a unified approach that simultaneously optimizes both aspects to achieve voltage and frequency regulation and proportional power sharing among distributed generators (DGs). We formulate the closed-loop AC MG as a networked system where DGs, distribution lines, and loads are interconnected subsystems characterized by their dissipative properties. Each DG employs a hierarchical architecture combining local controllers for voltage regulation and distributed controllers for droop-free power sharing through normalized power consensus. By leveraging dissipativity theory, we establish necessary and sufficient conditions for subsystem passivity and cast the co-design problem as a convex linear matrix inequality (LMI) optimization, enabling efficient computation and guaranteed stability. Our framework systematically synthesizes sparse communication topologies while handling the coupled dq-frame dynamics and dual power flow objectives inherent to AC MGs. Simulation results on a representative AC MG demonstrate the effectiveness of the proposed approach in achieving accurate voltage regulation, frequency synchronization, and proportional power sharing."}
{"id": "2511.06576", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06576", "abs": "https://arxiv.org/abs/2511.06576", "authors": ["Mohammad Javad Najafirad", "Shirantha Welikala", "Lei Wu", "Panos J. Antsaklis"], "title": "Dissipativity-Based Synthesis of Distributed Control and Communication Topology Co-Design for AC Microgrids", "comment": null, "summary": "This paper presents a novel dissipativity-based framework for co-designing distributed controllers and communication topologies in AC microgrids (MGs). Unlike existing methods that treat control synthesis and topology design separately, we propose a unified approach that simultaneously optimizes both aspects to achieve voltage and frequency regulation and proportional power sharing among distributed generators (DGs). We formulate the closed-loop AC MG as a networked system where DGs, distribution lines, and loads are interconnected subsystems characterized by their dissipative properties. Each DG employs a hierarchical architecture combining local controllers for voltage regulation and distributed controllers for droop-free power sharing through normalized power consensus. By leveraging dissipativity theory, we establish necessary and sufficient conditions for subsystem passivity and cast the co-design problem as a convex linear matrix inequality (LMI) optimization, enabling efficient computation and guaranteed stability. Our framework systematically synthesizes sparse communication topologies while handling the coupled dq-frame dynamics and dual power flow objectives inherent to AC MGs. Simulation results on a representative AC MG demonstrate the effectiveness of the proposed approach in achieving accurate voltage regulation, frequency synchronization, and proportional power sharing."}
{"id": "2511.06292", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06292", "abs": "https://arxiv.org/abs/2511.06292", "authors": ["Yaoning Yu", "Kaimin Chang", "Ye Yu", "Kai Wei", "Haojing Luo", "Haohan Wang"], "title": "Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents", "comment": null, "summary": "Financial documents like earning reports or balance sheets often involve long tables and multi-page reports. Large language models have become a new tool to help numerical reasoning and understanding these documents. However, prompt quality can have a major effect on how well LLMs perform these financial reasoning tasks. Most current methods tune prompts on fixed datasets of financial text or tabular data, which limits their ability to adapt to new question types or document structures, or they involve costly and manually labeled/curated dataset to help build the prompts. We introduce a self-improving prompt framework driven by data-augmented optimization. In this closed-loop process, we generate synthetic financial tables and document excerpts, verify their correctness and robustness, and then update the prompt based on the results. Specifically, our framework combines a synthetic data generator with verifiers and a prompt optimizer, where the generator produces new examples that exposes weaknesses in the current prompt, the verifiers check the validity and robustness of the produced examples, and the optimizer incrementally refines the prompt in response. By iterating these steps in a feedback cycle, our method steadily improves prompt accuracy on financial reasoning tasks without needing external labels. Evaluation on DocMath-Eval benchmark demonstrates that our system achieves higher performance in both accuracy and robustness than standard prompt methods, underscoring the value of incorporating synthetic data generation into prompt learning for financial applications."}
{"id": "2511.05785", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05785", "abs": "https://arxiv.org/abs/2511.05785", "authors": ["Lianhao Yin", "Haiping Yu", "Pascal Spino", "Daniela Rus"], "title": "A Unified Stochastic Mechanism Underlying Collective Behavior in Ants, Physical Systems, and Robotic Swarms", "comment": null, "summary": "Biological swarms, such as ant colonies, achieve collective goals through decentralized and stochastic individual behaviors. Similarly, physical systems composed of gases, liquids, and solids exhibit random particle motion governed by entropy maximization, yet do not achieve collective objectives. Despite this analogy, no unified framework exists to explain the stochastic behavior in both biological and physical systems. Here, we present empirical evidence from \\textit{Formica polyctena} ants that reveals a shared statistical mechanism underlying both systems: maximization under different energy function constraints. We further demonstrate that robotic swarms governed by this principle can exhibit scalable, decentralized cooperation, mimicking physical phase-like behaviors with minimal individual computation. These findings established a unified stochastic model linking biological, physical, and robotic swarms, offering a scalable principle for designing robust and intelligent swarm robotics."}
{"id": "2511.06160", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06160", "abs": "https://arxiv.org/abs/2511.06160", "authors": ["Fatima Jahara", "Mark Dredze", "Sharon Levy"], "title": "Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles", "comment": "24 pages (including appendix)", "summary": "While recent safety guardrails effectively suppress overtly biased outputs, subtler forms of social bias emerge during complex logical reasoning tasks that evade current evaluation benchmarks. To fill this gap, we introduce a new evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model Evaluation), that uses logic grid puzzles to systematically probe the influence of social stereotypes on logical reasoning and decision making in LLMs. Our use of logic puzzles enables automatic generation and verification, as well as variability in complexity and biased settings. PRIME includes stereotypical, anti-stereotypical, and neutral puzzle variants generated from a shared puzzle structure, allowing for controlled and fine-grained comparisons. We evaluate multiple model families across puzzle sizes and test the effectiveness of prompt-based mitigation strategies. Focusing our experiments on gender stereotypes, our findings highlight that models consistently reason more accurately when solutions align with stereotypical associations. This demonstrates the significance of PRIME for diagnosing and quantifying social biases perpetuated in the deductive reasoning of LLMs, where fairness is critical."}
{"id": "2511.06434", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06434", "abs": "https://arxiv.org/abs/2511.06434", "authors": ["Wenkang Hu", "Xincheng Tang", "Yanzhi E", "Yitong Li", "Zhengjie Shu", "Wei Li", "Huamin Wang", "Ruigang Yang"], "title": "Real Garment Benchmark (RGBench): A Comprehensive Benchmark for Robotic Garment Manipulation featuring a High-Fidelity Scalable Simulator", "comment": "2026 AAAI Accept", "summary": "While there has been significant progress to use simulated data to learn robotic manipulation of rigid objects, applying its success to deformable objects has been hindered by the lack of both deformable object models and realistic non-rigid body simulators. In this paper, we present Real Garment Benchmark (RGBench), a comprehensive benchmark for robotic manipulation of garments. It features a diverse set of over 6000 garment mesh models, a new high-performance simulator, and a comprehensive protocol to evaluate garment simulation quality with carefully measured real garment dynamics. Our experiments demonstrate that our simulator outperforms currently available cloth simulators by a large margin, reducing simulation error by 20% while maintaining a speed of 3 times faster. We will publicly release RGBench to accelerate future research in robotic garment manipulation. Website: https://rgbench.github.io/"}
{"id": "2511.06583", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06583", "abs": "https://arxiv.org/abs/2511.06583", "authors": ["Ying Zhang", "Yihao Wang", "Yuanshuo Zhang", "Eric Larson", "Di Shi", "Fanping Sui"], "title": "On the Potential of Digital Twins for Distribution System State Estimation with Randomly Missing Data in Heterogeneous Measurements", "comment": "Accepted by the 2025 IEEE Power and Energy Society General Meeting", "summary": "Traditional statistical optimization-based state estimation (DSSE) algorithms rely on detailed grid parameters and mathematical assumptions of all possible uncertainties. Furthermore, random data missing due to communication failures, congestion, and cyberattacks, makes these methods easily infeasible. Inspired by recent advances in digital twins (DTs), this paper proposes an interactive attention-based DSSE model for robust grid monitoring by integrating three core components: physical entities, virtual modeling, and data fusion. To enable robustness against various data missing in heterogeneous measurements, we first propose physics-informed data augmentation and transfer. Moreover, a state-of-the-art attention-based spatiotemporal feature learning is proposed, followed by a novel cross-interaction feature fusion for robust voltage estimation. A case study in a real-world unbalanced 84-bus distribution system with raw data validates the accuracy and robustness of the proposed DT model in estimating voltage states, with random locational, arbitrary ratios (up to 40% of total measurements) of data missing."}
{"id": "2511.06583", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06583", "abs": "https://arxiv.org/abs/2511.06583", "authors": ["Ying Zhang", "Yihao Wang", "Yuanshuo Zhang", "Eric Larson", "Di Shi", "Fanping Sui"], "title": "On the Potential of Digital Twins for Distribution System State Estimation with Randomly Missing Data in Heterogeneous Measurements", "comment": "Accepted by the 2025 IEEE Power and Energy Society General Meeting", "summary": "Traditional statistical optimization-based state estimation (DSSE) algorithms rely on detailed grid parameters and mathematical assumptions of all possible uncertainties. Furthermore, random data missing due to communication failures, congestion, and cyberattacks, makes these methods easily infeasible. Inspired by recent advances in digital twins (DTs), this paper proposes an interactive attention-based DSSE model for robust grid monitoring by integrating three core components: physical entities, virtual modeling, and data fusion. To enable robustness against various data missing in heterogeneous measurements, we first propose physics-informed data augmentation and transfer. Moreover, a state-of-the-art attention-based spatiotemporal feature learning is proposed, followed by a novel cross-interaction feature fusion for robust voltage estimation. A case study in a real-world unbalanced 84-bus distribution system with raw data validates the accuracy and robustness of the proposed DT model in estimating voltage states, with random locational, arbitrary ratios (up to 40% of total measurements) of data missing."}
{"id": "2511.06301", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06301", "abs": "https://arxiv.org/abs/2511.06301", "authors": ["Azanzi Jiomekong", "Jean Bikim", "Patricia Negoue", "Joyce Chin"], "title": "Secu-Table: a Comprehensive security table dataset for evaluating semantic table interpretation systems", "comment": "Submitted to Nature Scientific Data", "summary": "Evaluating semantic tables interpretation (STI) systems, (particularly, those based on Large Language Models- LLMs) especially in domain-specific contexts such as the security domain, depends heavily on the dataset. However, in the security domain, tabular datasets for state-of-the-art are not publicly available. In this paper, we introduce Secu-Table dataset, composed of more than 1500 tables with more than 15k entities constructed using security data extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES CSKG). Along with the dataset, all the code is publicly released. This dataset is made available to the research community in the context of the SemTab challenge on Tabular to Knowledge Graph Matching. This challenge aims to evaluate the performance of several STI based on open source LLMs. Preliminary evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source LLM."}
{"id": "2511.05791", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05791", "abs": "https://arxiv.org/abs/2511.05791", "authors": ["Manav Kulshrestha", "S. Talha Bukhari", "Damon Conover", "Aniket Bera"], "title": "VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models", "comment": "8 pages, 4 figures, under review", "summary": "Robotic grasping is a fundamental capability for autonomous manipulation; however, most existing methods rely on large-scale expert annotations and necessitate retraining to handle new objects. We present VLAD-Grasp, a Vision-Language model Assisted zero-shot approach for Detecting grasps. From a single RGB-D image, our method (1) prompts a large vision-language model to generate a goal image where a straight rod \"impales\" the object, representing an antipodal grasp, (2) predicts depth and segmentation to lift this generated image into 3D, and (3) aligns generated and observed object point clouds via principal component analysis and correspondence-free optimization to recover an executable grasp pose. Unlike prior work, our approach is training-free and does not rely on curated grasp datasets. Despite this, VLAD-Grasp achieves performance that is competitive with or superior to that of state-of-the-art supervised models on the Cornell and Jacquard datasets. We further demonstrate zero-shot generalization to novel real-world objects on a Franka Research 3 robot, highlighting vision-language foundation models as powerful priors for robotic manipulation."}
{"id": "2511.06262", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06262", "abs": "https://arxiv.org/abs/2511.06262", "authors": ["Siming Zhao", "Qi Li"], "title": "GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening", "comment": null, "summary": "Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows."}
{"id": "2511.06465", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06465", "abs": "https://arxiv.org/abs/2511.06465", "authors": ["Lingfan Bao", "Tianhu Peng", "Chengxu Zhou"], "title": "Sim-to-Real Transfer in Deep Reinforcement Learning for Bipedal Locomotion", "comment": "Sim-to-real for bipedal locomotion chapter", "summary": "This chapter addresses the critical challenge of simulation-to-reality (sim-to-real) transfer for deep reinforcement learning (DRL) in bipedal locomotion. After contextualizing the problem within various control architectures, we dissect the ``curse of simulation'' by analyzing the primary sources of sim-to-real gap: robot dynamics, contact modeling, state estimation, and numerical solvers. Building on this diagnosis, we structure the solutions around two complementary philosophies. The first is to shrink the gap through model-centric strategies that systematically improve the simulator's physical fidelity. The second is to harden the policy, a complementary approach that uses in-simulation robustness training and post-deployment adaptation to make the policy inherently resilient to model inaccuracies. The chapter concludes by synthesizing these philosophies into a strategic framework, providing a clear roadmap for developing and evaluating robust sim-to-real solutions."}
{"id": "2511.06663", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06663", "abs": "https://arxiv.org/abs/2511.06663", "authors": ["Yuhang Li", "Yang Lu", "Bo Ai", "Zhiguo Ding", "Dusit Niyato", "Arumugam Nallanathan"], "title": "GNN-Enabled Robust Hybrid Beamforming with Score-Based CSI Generation and Denoising", "comment": null, "summary": "Accurate Channel State Information (CSI) is critical for Hybrid Beamforming (HBF) tasks. However, obtaining high-resolution CSI remains challenging in practical wireless communication systems. To address this issue, we propose to utilize Graph Neural Networks (GNNs) and score-based generative models to enable robust HBF under imperfect CSI conditions. Firstly, we develop the Hybrid Message Graph Attention Network (HMGAT) which updates both node and edge features through node-level and edge-level message passing. Secondly, we design a Bidirectional Encoder Representations from Transformers (BERT)-based Noise Conditional Score Network (NCSN) to learn the distribution of high-resolution CSI, facilitating CSI generation and data augmentation to further improve HMGAT's performance. Finally, we present a Denoising Score Network (DSN) framework and its instantiation, termed DeBERT, which can denoise imperfect CSI under arbitrary channel error levels, thereby facilitating robust HBF. Experiments on DeepMIMO urban datasets demonstrate the proposed models' superior generalization, scalability, and robustness across various HBF tasks with perfect and imperfect CSI."}
{"id": "2511.06663", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06663", "abs": "https://arxiv.org/abs/2511.06663", "authors": ["Yuhang Li", "Yang Lu", "Bo Ai", "Zhiguo Ding", "Dusit Niyato", "Arumugam Nallanathan"], "title": "GNN-Enabled Robust Hybrid Beamforming with Score-Based CSI Generation and Denoising", "comment": null, "summary": "Accurate Channel State Information (CSI) is critical for Hybrid Beamforming (HBF) tasks. However, obtaining high-resolution CSI remains challenging in practical wireless communication systems. To address this issue, we propose to utilize Graph Neural Networks (GNNs) and score-based generative models to enable robust HBF under imperfect CSI conditions. Firstly, we develop the Hybrid Message Graph Attention Network (HMGAT) which updates both node and edge features through node-level and edge-level message passing. Secondly, we design a Bidirectional Encoder Representations from Transformers (BERT)-based Noise Conditional Score Network (NCSN) to learn the distribution of high-resolution CSI, facilitating CSI generation and data augmentation to further improve HMGAT's performance. Finally, we present a Denoising Score Network (DSN) framework and its instantiation, termed DeBERT, which can denoise imperfect CSI under arbitrary channel error levels, thereby facilitating robust HBF. Experiments on DeepMIMO urban datasets demonstrate the proposed models' superior generalization, scalability, and robustness across various HBF tasks with perfect and imperfect CSI."}
{"id": "2511.06309", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.06309", "abs": "https://arxiv.org/abs/2511.06309", "authors": ["Stephen Chung", "Wenyu Du"], "title": "The Station: An Open-World Environment for AI-Driven Discovery", "comment": "54 pages", "summary": "We introduce the STATION, an open-world multi-agent environment that models a miniature scientific ecosystem. Leveraging their extended context windows, agents in the Station can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, submitting code, performing analyses, and publishing results. Importantly, there is no centralized system coordinating their activities - agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning from mathematics to computational biology to machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of narratives emerges as agents pursue independent research, interact with peers, and build upon a cumulative history. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid optimization."}
{"id": "2511.05798", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05798", "abs": "https://arxiv.org/abs/2511.05798", "authors": ["William R. Johnson", "Patrick Meng", "Nelson Chen", "Luca Cimatti", "Augustin Vercoutere", "Mridul Aanjaneya", "Rebecca Kramer-Bottiglio", "Kostas E. Bekris"], "title": "An Open-Source, Reproducible Tensegrity Robot that can Navigate Among Obstacles", "comment": null, "summary": "Tensegrity robots, composed of rigid struts and elastic tendons, provide impact resistance, low mass, and adaptability to unstructured terrain. Their compliance and complex, coupled dynamics, however, present modeling and control challenges, hindering path planning and obstacle avoidance. This paper presents a complete, open-source, and reproducible system that enables navigation for a 3-bar tensegrity robot. The system comprises: (i) an inexpensive, open-source hardware design, and (ii) an integrated, open-source software stack for physics-based modeling, system identification, state estimation, path planning, and control. All hardware and software are publicly available at https://sites.google.com/view/tensegrity-navigation/. The proposed system tracks the robot's pose and executes collision-free paths to a specified goal among known obstacle locations. System robustness is demonstrated through experiments involving unmodeled environmental challenges, including a vertical drop, an incline, and granular media, culminating in an outdoor field demonstration. To validate reproducibility, experiments were conducted using robot instances at two different laboratories. This work provides the robotics community with a complete navigation system for a compliant, impact-resistant, and shape-morphing robot. This system is intended to serve as a springboard for advancing the navigation capabilities of other unconventional robotic platforms."}
{"id": "2511.06545", "categories": ["econ.GN", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06545", "abs": "https://arxiv.org/abs/2511.06545", "authors": ["Ruiqing Cao", "Abhishek Bhatia"], "title": "How Founder Expertise Shapes the Impact of Generative Artificial Intelligence on Digital Ventures", "comment": null, "summary": "The rapid diffusion of generative artificial intelligence (GenAI) has substantially lowered the costs of launching and developing digital ventures. GenAI can potentially both enable previously unviable entrepreneurial ideas by lowering resource needs and improve the performance of existing ventures. We explore how founders' technical and managerial expertise shapes GenAI's impact on digital ventures along these dimensions. Exploiting exogenous variation in GenAI usage across venture categories and the timing of its broad availability for software tasks (e.g., GitHub Copilot's public release and subsequent GenAI tools), we find that the number of new venture launches increased and the median time to launch decreased significantly more in categories with relatively high GenAI usage. GenAI's effect on new launches is larger for founders without managerial experience or education, while its effect on venture capital (VC) funding likelihood is stronger for founders with technical experience or education. Overall, our results suggest that GenAI expands access to digital entrepreneurship for founders lacking managerial expertise and enhances venture performance among technical founders."}
{"id": "2511.06496", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06496", "abs": "https://arxiv.org/abs/2511.06496", "authors": ["Keke Long", "Jiacheng Guo", "Tianyun Zhang", "Hongkai Yu", "Xiaopeng Li"], "title": "A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving", "comment": null, "summary": "Vision Language Models (VLMs) are increasingly used in autonomous driving to help understand traffic scenes, but they sometimes produce hallucinations, which are false details not grounded in the visual input. Detecting and mitigating hallucinations is challenging when ground-truth references are unavailable and model internals are inaccessible. This paper proposes a novel self-contained low-rank approach to automatically rank multiple candidate captions generated by multiple VLMs based on their hallucination levels, using only the captions themselves without requiring external references or model access. By constructing a sentence-embedding matrix and decomposing it into a low-rank consensus component and a sparse residual, we use the residual magnitude to rank captions: selecting the one with the smallest residual as the most hallucination-free. Experiments on the NuScenes dataset demonstrate that our approach achieves 87% selection accuracy in identifying hallucination-free captions, representing a 19% improvement over the unfiltered baseline and a 6-10% improvement over multi-agent debate method. The sorting produced by sparse error magnitudes shows strong correlation with human judgments of hallucinations, validating our scoring mechanism. Additionally, our method, which can be easily parallelized, reduces inference time by 51-67% compared to debate approaches, making it practical for real-time autonomous driving applications."}
{"id": "2511.06677", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06677", "abs": "https://arxiv.org/abs/2511.06677", "authors": ["Swetha Rani Kasimalla", "Kuchan Park", "Junho Hong", "Young-Jin Kim"], "title": "F2GAN: A Feature-Feedback Generative Framework for Reliable AI-Based Fault Diagnosis in Inverter-Dominated Microgrids", "comment": null, "summary": "Enhancing the reliability of AI based fault diagnosis in inverter dominated microgrids requires diverse and statistically balanced datasets. However, the scarcity and imbalance of high fidelity fault data, especially for rare inverter malfunctions and extreme external line faults, limit dependable model training and validation. This paper introduces a unified framework that models a detailed inverter dominated microgrid and systematically generates multiple internal and external fault scenarios to mitigate data scarcity and class imbalance. An enhanced generative model called F2GAN (Feature Feedback GAN) is developed to synthesize high dimensional tabular fault data with improved realism and statistical alignment. Unlike conventional GANs, F2GAN integrates multi level feedback based on mean variance, correlation, and feature matching losses, enabling the generator to refine output distributions toward real fault feature spaces. The generated datasets are evaluated through quantitative and qualitative analyses. Train on Synthetic, Test on Real (TSTR) experiments demonstrate strong generalization of machine learning classifiers trained exclusively on F2GAN samples. The framework is validated on a hardware-in-the-loop (HIL) fault diagnosis platform integrated with a real time simulator and graphical interface, achieving 100 % diagnostic accuracy under real-time testing. Results confirm that F2GAN effectively bridges the gap between simulated and real world microgrid fault datasets"}
{"id": "2511.06677", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06677", "abs": "https://arxiv.org/abs/2511.06677", "authors": ["Swetha Rani Kasimalla", "Kuchan Park", "Junho Hong", "Young-Jin Kim"], "title": "F2GAN: A Feature-Feedback Generative Framework for Reliable AI-Based Fault Diagnosis in Inverter-Dominated Microgrids", "comment": null, "summary": "Enhancing the reliability of AI based fault diagnosis in inverter dominated microgrids requires diverse and statistically balanced datasets. However, the scarcity and imbalance of high fidelity fault data, especially for rare inverter malfunctions and extreme external line faults, limit dependable model training and validation. This paper introduces a unified framework that models a detailed inverter dominated microgrid and systematically generates multiple internal and external fault scenarios to mitigate data scarcity and class imbalance. An enhanced generative model called F2GAN (Feature Feedback GAN) is developed to synthesize high dimensional tabular fault data with improved realism and statistical alignment. Unlike conventional GANs, F2GAN integrates multi level feedback based on mean variance, correlation, and feature matching losses, enabling the generator to refine output distributions toward real fault feature spaces. The generated datasets are evaluated through quantitative and qualitative analyses. Train on Synthetic, Test on Real (TSTR) experiments demonstrate strong generalization of machine learning classifiers trained exclusively on F2GAN samples. The framework is validated on a hardware-in-the-loop (HIL) fault diagnosis platform integrated with a real time simulator and graphical interface, achieving 100 % diagnostic accuracy under real-time testing. Results confirm that F2GAN effectively bridges the gap between simulated and real world microgrid fault datasets"}
{"id": "2511.06316", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06316", "abs": "https://arxiv.org/abs/2511.06316", "authors": ["MD Thamed Bin Zaman Chowdhury", "Moazzem Hossain"], "title": "ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning", "comment": null, "summary": "Reliable geospatial information on road accidents is vital for safety analysis and infrastructure planning, yet most low- and middle-income countries continue to face a critical shortage of accurate, location-specific crash data. Existing text-based geocoding tools perform poorly in multilingual and unstructured news environments, where incomplete place descriptions and mixed Bangla-English scripts obscure spatial context. To address these limitations, this study introduces ALIGN (Accident Location Inference through Geo-Spatial Neural Reasoning)- a vision-language framework that emulates human spatial reasoning to infer accident coordinates directly from textual and map-based cues. ALIGN integrates large language and vision-language models within a multi-stage pipeline that performs optical character recognition, linguistic reasoning, and map-level verification through grid-based spatial scanning. The framework systematically evaluates each predicted location against contextual and visual evidence, ensuring interpretable, fine-grained geolocation outcomes without requiring model retraining. Applied to Bangla-language news data, ALIGN demonstrates consistent improvements over traditional geoparsing methods, accurately identifying district and sub-district-level crash sites. Beyond its technical contribution, the framework establishes a high accuracy foundation for automated crash mapping in data-scarce regions, supporting evidence-driven road-safety policymaking and the broader integration of multimodal artificial intelligence in transportation analytics. The code for this paper is open-source and available at: https://github.com/Thamed-Chowdhury/ALIGN"}
{"id": "2511.05809", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05809", "abs": "https://arxiv.org/abs/2511.05809", "authors": ["Yu Chen", "Botao He", "Yuemin Mao", "Arthur Jakobsson", "Jeffrey Ke", "Yiannis Aloimonos", "Guanya Shi", "Howie Choset", "Jiayuan Mao", "Jeffrey Ichnowski"], "title": "Adversarial Game-Theoretic Algorithm for Dexterous Grasp Synthesis", "comment": "Submitted to ICRA 2026", "summary": "For many complex tasks, multi-finger robot hands are poised to revolutionize how we interact with the world, but reliably grasping objects remains a significant challenge. We focus on the problem of synthesizing grasps for multi-finger robot hands that, given a target object's geometry and pose, computes a hand configuration. Existing approaches often struggle to produce reliable grasps that sufficiently constrain object motion, leading to instability under disturbances and failed grasps. A key reason is that during grasp generation, they typically focus on resisting a single wrench, while ignoring the object's potential for adversarial movements, such as escaping. We propose a new grasp-synthesis approach that explicitly captures and leverages the adversarial object motion in grasp generation by formulating the problem as a two-player game. One player controls the robot to generate feasible grasp configurations, while the other adversarially controls the object to seek motions that attempt to escape from the grasp. Simulation experiments on various robot platforms and target objects show that our approach achieves a success rate of 75.78%, up to 19.61% higher than the state-of-the-art baseline. The two-player game mechanism improves the grasping success rate by 27.40% over the method without the game formulation. Our approach requires only 0.28-1.04 seconds on average to generate a grasp configuration, depending on the robot platform, making it suitable for real-world deployment. In real-world experiments, our approach achieves an average success rate of 85.0% on ShadowHand and 87.5% on LeapHand, which confirms its feasibility and effectiveness in real robot setups."}
{"id": "2511.06747", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06747", "abs": "https://arxiv.org/abs/2511.06747", "authors": ["Anu Kuncheria", "Joan L. Walker", "Jane Macfarlane"], "title": "Beyond Centrality: Understanding Urban Street Network Typologies Through Intersection Patterns", "comment": null, "summary": "The structure of road networks plays a pivotal role in shaping transportation dynamics. It also provides insights into how drivers experience city streets and helps uncover each urban environment's unique characteristics and challenges. Consequently, characterizing cities based on their road network patterns can facilitate the identification of similarities and differences, informing collaborative traffic management strategies, particularly at a regional scale. While previous studies have investigated global network patterns for cities, they have often overlooked detailed characterizations within a single large urban region. Additionally, most existing research uses metrics like degree, centrality, orientation, etc., and misses the nuances of street networks at the intersection level, specifically the geometric angles formed by links at intersections, which could offer a more refined feature for characterization. To address these gaps, this study examines over 100 cities in the San Francisco Bay Area. We introduce a novel metric for classifying intersections, distinguishing between different types of 3-way and 4-way intersections based on the angles formed at the intersections. Through the application of clustering algorithms in machine learning, we have identified three distinct typologies - grid, orthogonal, and organic cities - within the San Francisco Bay Area. We demonstrate the effectiveness of the metric in capturing the differences between cities based on street and intersection patterns. The typologies generated in this study could offer valuable support for city planners and policymakers in crafting a range of practical strategies tailored to the complexities of each city's road network, covering aspects such as evacuation plans, traffic signage placements, and traffic signal control."}
{"id": "2511.06500", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06500", "abs": "https://arxiv.org/abs/2511.06500", "authors": ["JiaHao Wu", "ShengWen Yu"], "title": "Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation", "comment": "21 pages,12 tables, 6 figures", "summary": "Proportional-Integral-Derivative (PID) controllers remain the predominant choice in industrial robotics due to their simplicity and reliability. However, manual tuning of PID parameters for diverse robotic platforms is time-consuming and requires extensive domain expertise. This paper presents a novel hierarchical control framework that combines meta-learning for PID initialization and reinforcement learning (RL) for online adaptation. To address the sample efficiency challenge, a \\textit{physics-based data augmentation} strategy is introduced that generates virtual robot configurations by systematically perturbing physical parameters, enabling effective meta-learning with limited real robot data. The proposed approach is evaluated on two heterogeneous platforms: a 9-DOF Franka Panda manipulator and a 12-DOF Laikago quadruped robot. Experimental results demonstrate that the proposed method achieves 16.6\\% average improvement on Franka Panda (6.26° MAE), with exceptional gains in high-load joints (J2: 80.4\\% improvement from 12.36° to 2.42°). Critically, this work discovers the \\textit{optimization ceiling effect}: RL achieves dramatic improvements when meta-learning exhibits localized high-error joints, but provides no benefit (0.0\\%) when baseline performance is uniformly strong, as observed in Laikago. The method demonstrates robust performance under disturbances (parameter uncertainty: +19.2\\%, no disturbance: +16.6\\%, average: +10.0\\%) with only 10 minutes of training time. Multi-seed analysis across 100 random initializations confirms stable performance (4.81+/-1.64\\% average). These results establish that RL effectiveness is highly dependent on meta-learning baseline quality and error distribution, providing important design guidance for hierarchical control systems."}
{"id": "2511.06713", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06713", "abs": "https://arxiv.org/abs/2511.06713", "authors": ["Yuheng Luo", "Chuanzhe Zhang", "Qingsong Liu", "Hai Zhu", "Wenjun Mei"], "title": "Pareto-Improvement-Driven Opinion Dynamics Explaining the Emergence of Pluralistic Ignorance", "comment": null, "summary": "Opinion dynamics has recently been modeled from a game-theoretic perspective, where opinion updates are captured by individuals' cost functions representing their motivations. Conventional formulations aggregate multiple motivations into a single objective, implicitly assuming that these motivations are interchangeable. This paper challenges that assumption and proposes an opinion dynamics model grounded in a multi-objective game framework. In the proposed model, each individual experiences two distinct costs: social pressure from disagreement with others and cognitive dissonance from deviation from the perceived truth. Opinion updates are modeled as Pareto improvements between these two costs. This fwork provides a parsimonious explanation for the emergence of pluralistic ignorance, where individuals may agree on something untrue even though they all know the underlying truth. We analytically characterize the model, derive conditions for the emrameergence and prevalence of the truth, and propose an initial-seeding strategy that ensures consensus on truth. Numerical simulations are conducted on how network density and clustering affect the expression of truth. Both theoretical and numerical results lead to clear and non-trivial sociological insights. For example, no network structure guarantees truthful consensus if no one initially express the truth; moderately sparse but well-mixed networks best mitigate pluralistic ignorance."}
{"id": "2511.06713", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06713", "abs": "https://arxiv.org/abs/2511.06713", "authors": ["Yuheng Luo", "Chuanzhe Zhang", "Qingsong Liu", "Hai Zhu", "Wenjun Mei"], "title": "Pareto-Improvement-Driven Opinion Dynamics Explaining the Emergence of Pluralistic Ignorance", "comment": null, "summary": "Opinion dynamics has recently been modeled from a game-theoretic perspective, where opinion updates are captured by individuals' cost functions representing their motivations. Conventional formulations aggregate multiple motivations into a single objective, implicitly assuming that these motivations are interchangeable. This paper challenges that assumption and proposes an opinion dynamics model grounded in a multi-objective game framework. In the proposed model, each individual experiences two distinct costs: social pressure from disagreement with others and cognitive dissonance from deviation from the perceived truth. Opinion updates are modeled as Pareto improvements between these two costs. This fwork provides a parsimonious explanation for the emergence of pluralistic ignorance, where individuals may agree on something untrue even though they all know the underlying truth. We analytically characterize the model, derive conditions for the emrameergence and prevalence of the truth, and propose an initial-seeding strategy that ensures consensus on truth. Numerical simulations are conducted on how network density and clustering affect the expression of truth. Both theoretical and numerical results lead to clear and non-trivial sociological insights. For example, no network structure guarantees truthful consensus if no one initially express the truth; moderately sparse but well-mixed networks best mitigate pluralistic ignorance."}
{"id": "2511.06346", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06346", "abs": "https://arxiv.org/abs/2511.06346", "authors": ["Liya Zhu", "Peizhuang Cong", "Aowei Ji", "Wenya Wu", "Jiani Hou", "Chunjie Wu", "Xiang Gao", "Jingkai Liu", "Zhou Huan", "Xuelei Sun", "Yang Yang", "Jianpeng Jiao", "Liang Hu", "Xinjie Chen", "Jiashuo Liu", "Jingzhe Ding", "Tong Yang", "Zaiyuan Wang", "Ge Zhang", "Wenhao Huang"], "title": "LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation", "comment": null, "summary": "Large Language Models (LLMs) have made rapid progress in reasoning, question answering, and professional applications; however, their true capabilities remain difficult to evaluate using existing benchmarks. Current datasets often focus on simplified tasks or artificial scenarios, overlooking long-tail knowledge and the complexities of real-world applications. To bridge this gap, we propose LPFQA, a long-tail knowledge-based benchmark derived from authentic professional forums across 20 academic and industrial fields, covering 502 tasks grounded in practical expertise. LPFQA introduces four key innovations: fine-grained evaluation dimensions that target knowledge depth, reasoning, terminology comprehension, and contextual analysis; a hierarchical difficulty structure that ensures semantic clarity and unique answers; authentic professional scenario modeling with realistic user personas; and interdisciplinary knowledge integration across diverse domains. We evaluated 12 mainstream LLMs on LPFQA and observed significant performance disparities, especially in specialized reasoning tasks. LPFQA provides a robust, authentic, and discriminative benchmark for advancing LLM evaluation and guiding future model development."}
{"id": "2511.05810", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05810", "abs": "https://arxiv.org/abs/2511.05810", "authors": ["Bowen Xu", "Xinyue Zeng", "Jiazhen Hu", "Tuo Wang", "Adithya Kulkarni"], "title": "DiagnoLLM: A Hybrid Bayesian Neural Language Framework for Interpretable Disease Diagnosis", "comment": null, "summary": "Building trustworthy clinical AI systems requires not only accurate predictions but also transparent, biologically grounded explanations. We present \\texttt{DiagnoLLM}, a hybrid framework that integrates Bayesian deconvolution, eQTL-guided deep learning, and LLM-based narrative generation for interpretable disease diagnosis. DiagnoLLM begins with GP-unmix, a Gaussian Process-based hierarchical model that infers cell-type-specific gene expression profiles from bulk and single-cell RNA-seq data while modeling biological uncertainty. These features, combined with regulatory priors from eQTL analysis, power a neural classifier that achieves high predictive performance in Alzheimer's Disease (AD) detection (88.0\\% accuracy). To support human understanding and trust, we introduce an LLM-based reasoning module that translates model outputs into audience-specific diagnostic reports, grounded in clinical features, attribution signals, and domain knowledge. Human evaluations confirm that these reports are accurate, actionable, and appropriately tailored for both physicians and patients. Our findings show that LLMs, when deployed as post-hoc reasoners rather than end-to-end predictors, can serve as effective communicators within hybrid diagnostic pipelines."}
{"id": "2511.07204", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07204", "abs": "https://arxiv.org/abs/2511.07204", "authors": ["Giacomo Fidone", "Lucia Passaro", "Riccardo Guidotti"], "title": "Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations", "comment": "Accepted for publication at AAAI Conference on Artificial Intelligence 2026", "summary": "Online Social Networks (OSNs) widely adopt content moderation to mitigate the spread of abusive and toxic discourse. Nonetheless, the real effectiveness of moderation interventions remains unclear due to the high cost of data collection and limited experimental control. The latest developments in Natural Language Processing pave the way for a new evaluation approach. Large Language Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and simulate human-like social behavior with unprecedented degree of believability. Yet, existing tools do not support simulation-based evaluation of moderation strategies. We fill this gap by designing a LLM-powered simulator of OSN conversations enabling a parallel, counterfactual simulation where toxic behavior is influenced by moderation interventions, keeping all else equal. We conduct extensive experiments, unveiling the psychological realism of OSN agents, the emergence of social contagion phenomena and the superior effectiveness of personalized moderation strategies."}
{"id": "2511.06515", "categories": ["cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06515", "abs": "https://arxiv.org/abs/2511.06515", "authors": ["Cormac O'Neill", "Jasmine Terrones", "H. Harry Asada"], "title": "Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control", "comment": null, "summary": "Controlling robots that dynamically engage in contact with their environment is a pressing challenge. Whether a legged robot making-and-breaking contact with a floor, or a manipulator grasping objects, contact is everywhere. Unfortunately, the switching of dynamics at contact boundaries makes control difficult. Predictive controllers face non-convex optimization problems when contact is involved. Here, we overcome this difficulty by applying Koopman operators to subsume the segmented dynamics due to contact changes into a unified, globally-linear model in an embedding space. We show that viscoelastic contact at robot-environment interactions underpins the use of Koopman operators without approximation to control inputs. This methodology enables the convex Model Predictive Control of a legged robot, and the real-time control of a manipulator engaged in dynamic pushing. In this work, we show that our method allows robots to discover elaborate control strategies in real-time over time horizons with multiple contact changes, and the method is applicable to broad fields beyond robotics."}
{"id": "2511.06714", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06714", "abs": "https://arxiv.org/abs/2511.06714", "authors": ["Emad Abukhousa", "Syed Sohail Feroz Syed Afroz", "Fahad Alsaeed", "Abdulaziz Qwbaiban", "Saman Zonouz", "A. P. Sakis Meliopoulos"], "title": "The Wisdom of the Crowd: High-Fidelity Classification of Cyber-Attacks and Faults in Power Systems Using Ensemble and Machine Learning", "comment": null, "summary": "This paper presents a high-fidelity evaluation framework for machine learning (ML)-based classification of cyber-attacks and physical faults using electromagnetic transient simulations with digital substation emulation at 4.8 kHz. Twelve ML models, including ensemble algorithms and a multi-layer perceptron (MLP), were trained on labeled time-domain measurements and evaluated in a real-time streaming environment designed for sub-cycle responsiveness. The architecture incorporates a cycle-length smoothing filter and confidence threshold to stabilize decisions. Results show that while several models achieved near-perfect offline accuracies (up to 99.9%), only the MLP sustained robust coverage (98-99%) under streaming, whereas ensembles preserved perfect anomaly precision but abstained frequently (10-49% coverage). These findings demonstrate that offline accuracy alone is an unreliable indicator of field readiness and underscore the need for realistic testing and inference pipelines to ensure dependable classification in inverter-based resources (IBR)-rich networks."}
{"id": "2511.06714", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06714", "abs": "https://arxiv.org/abs/2511.06714", "authors": ["Emad Abukhousa", "Syed Sohail Feroz Syed Afroz", "Fahad Alsaeed", "Abdulaziz Qwbaiban", "Saman Zonouz", "A. P. Sakis Meliopoulos"], "title": "The Wisdom of the Crowd: High-Fidelity Classification of Cyber-Attacks and Faults in Power Systems Using Ensemble and Machine Learning", "comment": null, "summary": "This paper presents a high-fidelity evaluation framework for machine learning (ML)-based classification of cyber-attacks and physical faults using electromagnetic transient simulations with digital substation emulation at 4.8 kHz. Twelve ML models, including ensemble algorithms and a multi-layer perceptron (MLP), were trained on labeled time-domain measurements and evaluated in a real-time streaming environment designed for sub-cycle responsiveness. The architecture incorporates a cycle-length smoothing filter and confidence threshold to stabilize decisions. Results show that while several models achieved near-perfect offline accuracies (up to 99.9%), only the MLP sustained robust coverage (98-99%) under streaming, whereas ensembles preserved perfect anomaly precision but abstained frequently (10-49% coverage). These findings demonstrate that offline accuracy alone is an unreliable indicator of field readiness and underscore the need for realistic testing and inference pipelines to ensure dependable classification in inverter-based resources (IBR)-rich networks."}
{"id": "2511.06380", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06380", "abs": "https://arxiv.org/abs/2511.06380", "authors": ["Chen He", "Xun Jiang", "Lei Wang", "Hao Yang", "Chong Peng", "Peng Yan", "Fumin Shen", "Xing Xu"], "title": "What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as \"Echo Reflection\". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks."}
{"id": "2511.05816", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05816", "abs": "https://arxiv.org/abs/2511.05816", "authors": ["Taku Okawara", "Ryo Nishibe", "Mao Kasano", "Kentaro Uno", "Kazuya Yoshida"], "title": "3D Mapping Using a Lightweight and Low-Power Monocular Camera Embedded inside a Gripper of Limbed Climbing Robots", "comment": "International Conference on Space Robotics (iSpaRo)", "summary": "Limbed climbing robots are designed to explore challenging vertical walls, such as the skylights of the Moon and Mars. In such robots, the primary role of a hand-eye camera is to accurately estimate 3D positions of graspable points (i.e., convex terrain surfaces) thanks to its close-up views. While conventional climbing robots often employ RGB-D cameras as hand-eye cameras to facilitate straightforward 3D terrain mapping and graspable point detection, RGB-D cameras are large and consume considerable power.\n  This work presents a 3D terrain mapping system designed for space exploration using limbed climbing robots equipped with a monocular hand-eye camera. Compared to RGB-D cameras, monocular cameras are more lightweight, compact structures, and have lower power consumption. Although monocular SLAM can be used to construct 3D maps, it suffers from scale ambiguity. To address this limitation, we propose a SLAM method that fuses monocular visual constraints with limb forward kinematics. The proposed method jointly estimates time-series gripper poses and the global metric scale of the 3D map based on factor graph optimization.\n  We validate the proposed framework through both physics-based simulations and real-world experiments. The results demonstrate that our framework constructs a metrically scaled 3D terrain map in real-time and enables autonomous grasping of convex terrain surfaces using a monocular hand-eye camera, without relying on RGB-D cameras. Our method contributes to scalable and energy-efficient perception for future space missions involving limbed climbing robots. See the video summary here: https://youtu.be/fMBrrVNKJfc"}
{"id": "2511.06575", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06575", "abs": "https://arxiv.org/abs/2511.06575", "authors": ["Jun Wang", "Yevgeniy Vorobeychik", "Yiannis Kantaros"], "title": "CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning", "comment": null, "summary": "Large Language Models (LLMs) have recently emerged as planners for language-instructed agents, generating sequences of actions to accomplish natural language tasks. However, their reliability remains a challenge, especially in long-horizon tasks, since they often produce overconfident yet wrong outputs. Conformal Prediction (CP) has been leveraged to address this issue by wrapping LLM outputs into prediction sets that contain the correct action with a user-defined confidence. When the prediction set is a singleton, the planner executes that action; otherwise, it requests help from a user. This has led to LLM-based planners that can ensure plan correctness with a user-defined probability. However, as LLMs are trained in an uncertainty-agnostic manner, without awareness of prediction sets, they tend to produce unnecessarily large sets, particularly at higher confidence levels, resulting in frequent human interventions limiting autonomous deployment. To address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first CP-aware finetuning framework for LLM-based planners that explicitly reduces prediction-set size and, in turn, the need for user interventions. We evaluate our approach on multiple language-instructed robot planning problems and show consistent improvements over uncertainty-aware and uncertainty-agnostic finetuning baselines in terms of prediction-set size, and help rates. Finally, we demonstrate robustness of our method to out-of-distribution scenarios in hardware experiments."}
{"id": "2511.06832", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06832", "abs": "https://arxiv.org/abs/2511.06832", "authors": ["Daniele Ravasio", "Danilo Saccani", "Marcello Farina", "Giancarlo Ferrari-Trecate"], "title": "Learning stabilising policies for constrained nonlinear systems", "comment": "4 figures, under review", "summary": "This work proposes a two-layered control scheme for constrained nonlinear systems represented by a class of recurrent neural networks and affected by additive disturbances. In particular, a base controller ensures global or regional closed-loop l_p-stability of the error in tracking a desired equilibrium and the satisfaction of input and output constraints within a robustly positive invariant set. An additional control contribution, derived by combining the internal model control principle with a stable operator, is introduced to improve system performance. This operator, implemented as a stable neural network, can be trained via unconstrained optimisation on a chosen performance metric, without compromising closed-loop equilibrium tracking or constraint satisfaction, even if the optimisation is stopped prematurely. In addition, we characterise the class of closed-loop stable behaviours that can be achieved with the proposed architecture. Simulation results on a pH-neutralisation benchmark demonstrate the effectiveness of the proposed approach."}
{"id": "2511.06832", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06832", "abs": "https://arxiv.org/abs/2511.06832", "authors": ["Daniele Ravasio", "Danilo Saccani", "Marcello Farina", "Giancarlo Ferrari-Trecate"], "title": "Learning stabilising policies for constrained nonlinear systems", "comment": "4 figures, under review", "summary": "This work proposes a two-layered control scheme for constrained nonlinear systems represented by a class of recurrent neural networks and affected by additive disturbances. In particular, a base controller ensures global or regional closed-loop l_p-stability of the error in tracking a desired equilibrium and the satisfaction of input and output constraints within a robustly positive invariant set. An additional control contribution, derived by combining the internal model control principle with a stable operator, is introduced to improve system performance. This operator, implemented as a stable neural network, can be trained via unconstrained optimisation on a chosen performance metric, without compromising closed-loop equilibrium tracking or constraint satisfaction, even if the optimisation is stopped prematurely. In addition, we characterise the class of closed-loop stable behaviours that can be achieved with the proposed architecture. Simulation results on a pH-neutralisation benchmark demonstrate the effectiveness of the proposed approach."}
{"id": "2511.06396", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06396", "abs": "https://arxiv.org/abs/2511.06396", "authors": ["Dachuan Lin", "Guobin Shen", "Zihao Yang", "Tianrong Liu", "Dongcheng Zhao", "Yi Zeng"], "title": "Efficient LLM Safety Evaluation through Multi-Agent Debate", "comment": "9 pages of main text, 14 pages total, 4 figures", "summary": "Safety evaluation of large language models (LLMs) increasingly relies on LLM-as-a-Judge frameworks, but the high cost of frontier models limits scalability. We propose a cost-efficient multi-agent judging framework that employs Small Language Models (SLMs) through structured debates among critic, defender, and judge agents. To rigorously assess safety judgments, we construct HAJailBench, a large-scale human-annotated jailbreak benchmark comprising 12,000 adversarial interactions across diverse attack methods and target models. The dataset provides fine-grained, expert-labeled ground truth for evaluating both safety robustness and judge reliability. Our SLM-based framework achieves agreement comparable to GPT-4o judges on HAJailBench while substantially reducing inference cost. Ablation results show that three rounds of debate yield the optimal balance between accuracy and efficiency. These findings demonstrate that structured, value-aligned debate enables SLMs to capture semantic nuances of jailbreak attacks and that HAJailBench offers a reliable foundation for scalable LLM safety evaluation."}
{"id": "2511.05819", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05819", "abs": "https://arxiv.org/abs/2511.05819", "authors": ["Nina Lutz", "Benjamin Olsen", "Weishung Liu", "E. Glen Weyl"], "title": "(Working Paper) Good Faith Design: Religion as a Resource for Technologists", "comment": null, "summary": "Previous work has found a lack of research in HCI on religion, partly driven by misunderstandings of values and practices between religious and technical communities. To bridge this divide in an empirically rigorous way, we conducted an interview study with 48 religious people and/or experts from 11 faiths, and we document how religious people experience, understand, and imagine technologies. We show that religious stakeholders find non-neutral secular embeddings in technologies and the firms and people that design them, and how these manifest in unintended harms for religious and nonreligious users. Our findings reveal how users navigate technoreligious practices with religiously informed mental models and what they desire from technologies. Informed by this, we distill six design values -- wonder, humility, space, embodiedness, community, and eternity -- to guide technologists in considering and leveraging religion as an additional, valid sociocultural resource when designing for a holistic user. We further spell out directions for future research."}
{"id": "2511.06578", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06578", "abs": "https://arxiv.org/abs/2511.06578", "authors": ["Kaustubh Singh", "Shivam Kumar", "Shashikant Pawar", "Sandeep Manjanna"], "title": "Underactuated Biomimetic Autonomous Underwater Vehicle for Ecosystem Monitoring", "comment": "ICRA RUNE 2024 Workshop Paper", "summary": "In this paper, we present an underactuated biomimetic underwater robot that is suitable for ecosystem monitoring in both marine and freshwater environments. We present an updated mechanical design for a fish-like robot and propose minimal actuation behaviors learned using reinforcement learning techniques. We present our preliminary mechanical design of the tail oscillation mechanism and illustrate the swimming behaviors on FishGym simulator, where the reinforcement learning techniques will be tested on"}
{"id": "2511.06873", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06873", "abs": "https://arxiv.org/abs/2511.06873", "authors": ["Ruohan Wang", "Siyuan Liu", "Zhiyong Sun", "Sofie Haesaert"], "title": "Correct-by-Design Control Synthesis of Stochastic Multi-agent Systems: a Robust Tensor-based Solution", "comment": null, "summary": "Discrete-time stochastic systems with continuous spaces are hard to verify and control, even with MDP abstractions due to the curse of dimensionality. We propose an abstraction-based framework with robust dynamic programming mappings that deliver control strategies with provable lower bounds on temporal-logic satisfaction, quantified via approximate stochastic simulation relations. Exploiting decoupled dynamics, we reveal a Canonical Polyadic Decomposition tensor structure in value functions that makes dynamic programming scalable. The proposed method provides correct-by-design probabilistic guarantees for temporal logic specifications. We validate our results on continuous-state linear stochastic systems."}
{"id": "2511.06873", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06873", "abs": "https://arxiv.org/abs/2511.06873", "authors": ["Ruohan Wang", "Siyuan Liu", "Zhiyong Sun", "Sofie Haesaert"], "title": "Correct-by-Design Control Synthesis of Stochastic Multi-agent Systems: a Robust Tensor-based Solution", "comment": null, "summary": "Discrete-time stochastic systems with continuous spaces are hard to verify and control, even with MDP abstractions due to the curse of dimensionality. We propose an abstraction-based framework with robust dynamic programming mappings that deliver control strategies with provable lower bounds on temporal-logic satisfaction, quantified via approximate stochastic simulation relations. Exploiting decoupled dynamics, we reveal a Canonical Polyadic Decomposition tensor structure in value functions that makes dynamic programming scalable. The proposed method provides correct-by-design probabilistic guarantees for temporal logic specifications. We validate our results on continuous-state linear stochastic systems."}
{"id": "2511.06411", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06411", "abs": "https://arxiv.org/abs/2511.06411", "authors": ["Zhi Zheng", "Wee Sun Lee"], "title": "SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization", "comment": null, "summary": "The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master"}
{"id": "2511.05822", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05822", "abs": "https://arxiv.org/abs/2511.05822", "authors": ["Sayak Mukherjee", "Ramij R. Hossain", "Kaustav Chatterjee", "Sameer Nekkalapu", "Marcelo Elizondo"], "title": "Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions", "comment": "10 pages, 7 figures", "summary": "This paper explores the development of learning-based tunable control gains using EMT-in-the-loop simulation framework (e.g., PSCAD interfaced with Python-based learning modules) to address critical sub-synchronous oscillations. Since sub-synchronous control interactions (SSCI) arise from the mis-tuning of control gains under specific grid configurations, effective mitigation strategies require adaptive re-tuning of these gains. Such adaptiveness can be achieved by employing a closed-loop, learning-based framework that considers the grid conditions responsible for such sub-synchronous oscillations. This paper addresses this need by adopting methodologies inspired by Markov decision process (MDP) based reinforcement learning (RL), with a particular emphasis on simpler deep policy gradient methods with additional SSCI-specific signal processing modules such as down-sampling, bandpass filtering, and oscillation energy dependent reward computations. Our experimentation in a real-world event setting demonstrates that the deep policy gradient based trained policy can adaptively compute gain settings in response to varying grid conditions and optimally suppress control interaction-induced oscillations."}
{"id": "2511.06619", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06619", "abs": "https://arxiv.org/abs/2511.06619", "authors": ["Chuheng Zhang", "Rushuai Yang", "Xiaoyu Chen", "Kaixin Wang", "Li Zhao", "Yi Chen", "Jiang Bian"], "title": "How Do VLAs Effectively Inherit from VLMs?", "comment": null, "summary": "Vision-language-action (VLA) models hold the promise to attain generalizable embodied control. To achieve this, a pervasive paradigm is to leverage the rich vision-semantic priors of large vision-language models (VLMs). However, the fundamental question persists: How do VLAs effectively inherit the prior knowledge from VLMs? To address this critical question, we introduce a diagnostic benchmark, GrinningFace, an emoji tabletop manipulation task where the robot arm is asked to place objects onto printed emojis corresponding to language instructions. This task design is particularly revealing -- knowledge associated with emojis is ubiquitous in Internet-scale datasets used for VLM pre-training, yet emojis themselves are largely absent from standard robotics datasets. Consequently, they provide a clean proxy: successful task completion indicates effective transfer of VLM priors to embodied control. We implement this diagnostic task in both simulated environment and a real robot, and compare various promising techniques for knowledge transfer. Specifically, we investigate the effects of parameter-efficient fine-tuning, VLM freezing, co-training, predicting discretized actions, and predicting latent actions. Through systematic evaluation, our work not only demonstrates the critical importance of preserving VLM priors for the generalization of VLA but also establishes guidelines for future research in developing truly generalizable embodied AI systems."}
{"id": "2511.06921", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06921", "abs": "https://arxiv.org/abs/2511.06921", "authors": ["Siddhartha Mahajan", "Harsh Raj", "Sonam Tanwar"], "title": "Analysis of Traffic Congestion in North Campus, Delhi University Using Continuous Time Models", "comment": null, "summary": "This project investigates traffic congestion within North Campus, Delhi University (DU), using continuous time simulations implemented in UXSim to model vehicle movement and interaction. The study focuses on several key intersections, identifies recurring congestion points, and evaluates the effectiveness of conventional traffic management measures. Implementing signal timing optimization and modest intersection reconfiguration resulted in measurable improvements in simulated traffic flow. The results provide practical insights for local traffic management and illustrate the value of continuous time simulation methods for informing short-term interventions and longer-term planning."}
{"id": "2511.06921", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06921", "abs": "https://arxiv.org/abs/2511.06921", "authors": ["Siddhartha Mahajan", "Harsh Raj", "Sonam Tanwar"], "title": "Analysis of Traffic Congestion in North Campus, Delhi University Using Continuous Time Models", "comment": null, "summary": "This project investigates traffic congestion within North Campus, Delhi University (DU), using continuous time simulations implemented in UXSim to model vehicle movement and interaction. The study focuses on several key intersections, identifies recurring congestion points, and evaluates the effectiveness of conventional traffic management measures. Implementing signal timing optimization and modest intersection reconfiguration resulted in measurable improvements in simulated traffic flow. The results provide practical insights for local traffic management and illustrate the value of continuous time simulation methods for informing short-term interventions and longer-term planning."}
{"id": "2511.06417", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06417", "abs": "https://arxiv.org/abs/2511.06417", "authors": ["Xiangwu Guo", "Difei Gao", "Mike Zheng Shou"], "title": "AUTO-Explorer: Automated Data Collection for GUI Agent", "comment": null, "summary": "Recent advancements in GUI agents have significantly expanded their ability to interpret natural language commands to manage software interfaces. However, acquiring GUI data remains a significant challenge. Existing methods often involve designing automated agents that browse URLs from the Common Crawl, using webpage HTML to collect screenshots and corresponding annotations, including the names and bounding boxes of UI elements. However, this method is difficult to apply to desktop software or some newly launched websites not included in the Common Crawl. While we expect the model to possess strong generalization capabilities to handle this, it is still crucial for personalized scenarios that require rapid and perfect adaptation to new software or websites. To address this, we propose an automated data collection method with minimal annotation costs, named Auto-Explorer. It incorporates a simple yet effective exploration mechanism that autonomously parses and explores GUI environments, gathering data efficiently. Additionally, to assess the quality of exploration, we have developed the UIXplore benchmark. This benchmark creates environments for explorer agents to discover and save software states. Using the data gathered, we fine-tune a multimodal large language model (MLLM) and establish a GUI element grounding testing set to evaluate the effectiveness of the exploration strategies. Our experiments demonstrate the superior performance of Auto-Explorer, showing that our method can quickly enhance the capabilities of an MLLM in explored software."}
{"id": "2511.05828", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05828", "abs": "https://arxiv.org/abs/2511.05828", "authors": ["Zhiguan Niu", "Xiaochao Zhou", "Hao Xiong"], "title": "Learning-Based Multi-Stage Strategy for a Fixed-Wing Aircraft to Evade a Missile Detected at a Short Distance", "comment": null, "summary": "Missiles pose a major threat to aircraft in modern air combat. Advances in technology make them increasingly difficult to detect until they are close to the target and highly resistant to jamming. The evasion maneuver is the last line of defense for an aircraft. However, conventional rule-based evasion strategies are limited by computational demands and aerodynamic constraints, and existing learning-based approaches remain unconvincing for manned aircraft against modern missiles. To enhance aircraft survivability, this study investigates missile evasion inspired by the pursuit-evasion game between a gazelle and a cheetah and proposes a multi-stage reinforcement learning-based evasion strategy. The strategy learns a large azimuth policy to turn to evade, a small azimuth policy to keep moving away, and a short distance policy to perform agile aggressive maneuvers to avoid. One of the three policies is activated at each stage based on distance and azimuth. To evaluate performance, a high-fidelity simulation environment modeling an F-16 aircraft and missile under various conditions is used to compare the proposed approach with baseline strategies. Experimental results show that the proposed method achieves superior performance, enabling the F-16 aircraft to successfully avoid missiles with a probability of 80.89 percent for velocities ranging from 800 m/s to 1400 m/s, maximum overloads from 40 g to 50 g, detection distances from 5000 m to 15000 m, and random azimuths. When the missile is detected beyond 8000 m, the success ratio increases to 85.06 percent."}
{"id": "2511.06667", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06667", "abs": "https://arxiv.org/abs/2511.06667", "authors": ["Andrew Choi", "Dezhong Tong"], "title": "Rapidly Learning Soft Robot Control via Implicit Time-Stepping", "comment": "Code: https://github.com/QuantuMope/dismech-rl", "summary": "With the explosive growth of rigid-body simulators, policy learning in simulation has become the de facto standard for most rigid morphologies. In contrast, soft robotic simulation frameworks remain scarce and are seldom adopted by the soft robotics community. This gap stems partly from the lack of easy-to-use, general-purpose frameworks and partly from the high computational cost of accurately simulating continuum mechanics, which often renders policy learning infeasible. In this work, we demonstrate that rapid soft robot policy learning is indeed achievable via implicit time-stepping. Our simulator of choice, DisMech, is a general-purpose, fully implicit soft-body simulator capable of handling both soft dynamics and frictional contact. We further introduce delta natural curvature control, a method analogous to delta joint position control in rigid manipulators, providing an intuitive and effective means of enacting control for soft robot learning. To highlight the benefits of implicit time-stepping and delta curvature control, we conduct extensive comparisons across four diverse soft manipulator tasks against one of the most widely used soft-body frameworks, Elastica. With implicit time-stepping, parallel stepping of 500 environments achieves up to 6x faster speeds for non-contact cases and up to 40x faster for contact-rich scenarios. Finally, a comprehensive sim-to-sim gap evaluation--training policies in one simulator and evaluating them in another--demonstrates that implicit time-stepping provides a rare free lunch: dramatic speedups achieved without sacrificing accuracy."}
{"id": "2511.06950", "categories": ["eess.SY", "cs.MA", "eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06950", "abs": "https://arxiv.org/abs/2511.06950", "authors": ["M. Doostmohammadian", "U. A. Khan", "N. Meskin"], "title": "On the Redundant Distributed Observability of Mixed Traffic Transportation Systems", "comment": "EURASIP journal on advances in signal processing", "summary": "In this paper, the problem of distributed state estimation of human-driven vehicles (HDVs) by connected autonomous vehicles (CAVs) is investigated in mixed traffic transportation systems. Toward this, a distributed observable state-space model is derived, which paves the way for estimation and observability analysis of HDVs in mixed traffic scenarios. In this direction, first, we obtain the condition on the network topology to satisfy the distributed observability, i.e., the condition such that each HDV state is observable to every CAV via information-exchange over the network. It is shown that strong connectivity of the network, along with the proper design of the observer gain, is sufficient for this. A distributed observer is then designed by locally sharing estimates/observations of each CAV with its neighborhood. Second, in case there exist faulty sensors or unreliable observation data, we derive the condition for redundant distributed observability as a $q$-node/link-connected network design. This redundancy is achieved by extra information-sharing over the network and implies that a certain number of faulty sensors and unreliable links can be isolated/removed without losing the observability. Simulation results are provided to illustrate the effectiveness of the proposed approach."}
{"id": "2511.06950", "categories": ["eess.SY", "cs.MA", "eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06950", "abs": "https://arxiv.org/abs/2511.06950", "authors": ["M. Doostmohammadian", "U. A. Khan", "N. Meskin"], "title": "On the Redundant Distributed Observability of Mixed Traffic Transportation Systems", "comment": "EURASIP journal on advances in signal processing", "summary": "In this paper, the problem of distributed state estimation of human-driven vehicles (HDVs) by connected autonomous vehicles (CAVs) is investigated in mixed traffic transportation systems. Toward this, a distributed observable state-space model is derived, which paves the way for estimation and observability analysis of HDVs in mixed traffic scenarios. In this direction, first, we obtain the condition on the network topology to satisfy the distributed observability, i.e., the condition such that each HDV state is observable to every CAV via information-exchange over the network. It is shown that strong connectivity of the network, along with the proper design of the observer gain, is sufficient for this. A distributed observer is then designed by locally sharing estimates/observations of each CAV with its neighborhood. Second, in case there exist faulty sensors or unreliable observation data, we derive the condition for redundant distributed observability as a $q$-node/link-connected network design. This redundancy is achieved by extra information-sharing over the network and implies that a certain number of faulty sensors and unreliable links can be isolated/removed without losing the observability. Simulation results are provided to illustrate the effectiveness of the proposed approach."}
{"id": "2511.06419", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06419", "abs": "https://arxiv.org/abs/2511.06419", "authors": ["Jingyu Hu", "Shu Yang", "Xilin Gong", "Hongming Wang", "Weiru Liu", "Di Wang"], "title": "MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. To address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer. MONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds. Extensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements."}
{"id": "2511.05854", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05854", "abs": "https://arxiv.org/abs/2511.05854", "authors": ["Zepeng Bao", "Shen Zhou", "Qiankun Pi", "Jianhao Chen", "Mayi Xu", "Ming Zhong", "Yuanyuan Zhu", "Tieyun Qian"], "title": "Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and Proactive Correction for Hallucination Detection", "comment": null, "summary": "Hallucination in large language models (LLMs) remains a critical barrier to their safe deployment. Existing tool-augmented hallucination detection methods require pre-defined fixed verification strategies, which are crucial to the quality and effectiveness of tool calls. Some methods directly employ powerful closed-source LLMs such as GPT-4 as detectors, which are effective but too costly. To mitigate the cost issue, some methods adopt the teacher-student architecture and finetune open-source small models as detectors via agent tuning. However, these methods are limited by fixed strategies. When faced with a dynamically changing execution environment, they may lack adaptability and inappropriately call tools, ultimately leading to detection failure. To address the problem of insufficient strategy adaptability, we propose the innovative ``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an efficient student model with the dynamic learning and proactive correction capabilities of the teacher model. Specifically, our method formulates the hallucination detection problem as a dynamic strategy learning problem. We first employ a teacher model to generate trajectories within the dynamic learning loop and dynamically adjust the strategy based on execution failures. We then distill this dynamic planning capability into an efficient student model via agent tuning. Finally, during strategy execution, the student model adopts a proactive correction mechanism, enabling it to propose, review, and optimize its own verification strategies before execution. We demonstrate through experiments on three challenging benchmarks that our LEAP-tuned model outperforms existing state-of-the-art methods."}
{"id": "2511.06673", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06673", "abs": "https://arxiv.org/abs/2511.06673", "authors": ["Joel Kemp", "Andre Farinha", "David Howard", "Krishna Manaswi Digumarti", "Josh Pinskier"], "title": "Programmable Telescopic Soft Pneumatic Actuators for Deployable and Shape Morphing Soft Robots", "comment": "8 pages, 10 figures, Submitted to Robosoft 2026", "summary": "Soft Robotics presents a rich canvas for free-form and continuum devices capable of exerting forces in any direction and transforming between arbitrary configurations. However, there is no current way to tractably and directly exploit the design freedom due to the curse of dimensionality. Parameterisable sets of designs offer a pathway towards tractable, modular soft robotics that appropriately harness the behavioural freeform of soft structures to create rich embodied behaviours. In this work, we present a parametrised class of soft actuators, Programmable Telescopic Soft Pneumatic Actuators (PTSPAs). PTSPAs expand axially on inflation for deployable structures and manipulation in challenging confined spaces. We introduce a parametric geometry generator to customise actuator models from high-level inputs, and explore the new design space through semi-automated experimentation and systematic exploration of key parameters. Using it we characterise the actuators' extension/bending, expansion, and stiffness and reveal clear relationships between key design parameters and performance. Finally we demonstrate the application of the actuators in a deployable soft quadruped whose legs deploy to walk, enabling automatic adaptation to confined spaces. PTSPAs present new design paradigm for deployable and shape morphing structures and wherever large length changes are required."}
{"id": "2511.06989", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06989", "abs": "https://arxiv.org/abs/2511.06989", "authors": ["Yang Wang", "Marta Zagorowska", "Riccardo M. G. Ferrari"], "title": "Capacity Estimation of Lithium-ion Batteries Using Invariance Property in Open Circuit Voltage Relationship", "comment": null, "summary": "Lithium-ion (Li-ion) batteries are ubiquitous in electric vehicles (EVs) as efficient energy storage devices. The reliable operation of Li-ion batteries depends critically on the accurate estimation of battery capacity. However, conventional estimation methods require extensive training datasets from costly battery tests for modeling, and a full cycle of charge and discharge is often needed to estimate the capacity. To overcome these limitations, we propose a novel capacity estimation method that leverages only one cycle of the open-circuit voltage (OCV) test in modeling and allows for estimating the capacity from partial charge or discharge data. Moreover, by applying it with OCV identification algorithms, we can estimate the capacity from dynamic discharge data without requiring dedicated data collection tests. We observed an invariance property in the OCV versus state of charge relationship across aging cycles. Leveraging this invariance, the proposed method estimates the capacity by solving an OCV alignment problem using only the OCV and the discharge capacity data from the battery. Simulation results demonstrate the method's efficacy, achieving a mean absolute relative error of 0.85\\% in capacity estimation across 12 samples from 344 aging cycles."}
{"id": "2511.06989", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06989", "abs": "https://arxiv.org/abs/2511.06989", "authors": ["Yang Wang", "Marta Zagorowska", "Riccardo M. G. Ferrari"], "title": "Capacity Estimation of Lithium-ion Batteries Using Invariance Property in Open Circuit Voltage Relationship", "comment": null, "summary": "Lithium-ion (Li-ion) batteries are ubiquitous in electric vehicles (EVs) as efficient energy storage devices. The reliable operation of Li-ion batteries depends critically on the accurate estimation of battery capacity. However, conventional estimation methods require extensive training datasets from costly battery tests for modeling, and a full cycle of charge and discharge is often needed to estimate the capacity. To overcome these limitations, we propose a novel capacity estimation method that leverages only one cycle of the open-circuit voltage (OCV) test in modeling and allows for estimating the capacity from partial charge or discharge data. Moreover, by applying it with OCV identification algorithms, we can estimate the capacity from dynamic discharge data without requiring dedicated data collection tests. We observed an invariance property in the OCV versus state of charge relationship across aging cycles. Leveraging this invariance, the proposed method estimates the capacity by solving an OCV alignment problem using only the OCV and the discharge capacity data from the battery. Simulation results demonstrate the method's efficacy, achieving a mean absolute relative error of 0.85\\% in capacity estimation across 12 samples from 344 aging cycles."}
{"id": "2511.06437", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06437", "abs": "https://arxiv.org/abs/2511.06437", "authors": ["Abhishek More", "Anthony Zhang", "Nicole Bonilla", "Ashvik Vivekan", "Kevin Zhu", "Parham Sharafoleslami", "Maheep Chaudhary"], "title": "Optimizing Chain-of-Thought Confidence via Topological and Dirichlet Risk Analysis", "comment": null, "summary": "Chain-of-thought (CoT) prompting enables Large Language Models to solve complex problems, but deploying these models safely requires reliable confidence estimates, a capability where existing methods suffer from poor calibration and severe overconfidence on incorrect predictions. We propose Enhanced Dirichlet and Topology Risk (EDTR), a novel decoding strategy that combines topological analysis with Dirichlet-based uncertainty quantification to measure LLM confidence across multiple reasoning paths. EDTR treats each CoT as a vector in high-dimensional space and extracts eight topological risk features capturing the geometric structure of reasoning distributions: tighter, more coherent clusters indicate higher confidence while dispersed, inconsistent paths signal uncertainty. We evaluate EDTR against three state-of-the-art calibration methods across four diverse reasoning benchmarks spanning olympiad-level mathematics (AIME), grade school math (GSM8K), commonsense reasoning, and stock price prediction \\cite{zhang2025aime, cobbe2021training, talmor-etal-2019-commonsenseqa, yahoo_finance}. EDTR achieves 41\\% better calibration than competing methods with an average ECE of 0.287 and the best overall composite score of 0.672, while notably achieving perfect accuracy on AIME and exceptional calibration on GSM8K with an ECE of 0.107, domains where baselines exhibit severe overconfidence. Our work provides a geometric framework for understanding and quantifying uncertainty in multi-step LLM reasoning, enabling more reliable deployment where calibrated confidence estimates are essential."}
{"id": "2511.05855", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05855", "abs": "https://arxiv.org/abs/2511.05855", "authors": ["Jiayu Zhou", "Qiwei Wu", "Jian Li", "Zhe Chen", "Xiaogang Xiong", "Renjing Xu"], "title": "Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills", "comment": "Accepted for the 40th Annual AAAI Conference on Artificial Intelligence (2026)", "summary": "Autonomous execution of long-horizon, contact-rich manipulation tasks traditionally requires extensive real-world data and expert engineering, posing significant cost and scalability challenges. This paper proposes a novel framework integrating hierarchical semantic decomposition, reinforcement learning (RL), visual language models (VLMs), and knowledge distillation to overcome these limitations. Complex tasks are decomposed into atomic skills, with RL-trained policies for each primitive exclusively in simulation. Crucially, our RL formulation incorporates explicit force constraints to prevent object damage during delicate interactions. VLMs perform high-level task decomposition and skill planning, generating diverse expert demonstrations. These are distilled into a unified policy via Visual-Tactile Diffusion Policy for end-to-end execution. We conduct comprehensive ablation studies exploring different VLM-based task planners to identify optimal demonstration generation pipelines, and systematically compare imitation learning algorithms for skill distillation. Extensive simulation experiments and physical deployment validate that our approach achieves policy learning for long-horizon manipulation without costly human demonstrations, while the VLM-guided atomic skill framework enables scalable generalization to diverse tasks."}
{"id": "2511.06745", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06745", "abs": "https://arxiv.org/abs/2511.06745", "authors": ["Lan Thi Ha Nguyen", "Kien Ton Manh", "Anh Do Duc", "Nam Pham Hai"], "title": "Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning", "comment": null, "summary": "Self-supervised goal-conditioned reinforcement learning enables robots to autonomously acquire diverse skills without human supervision. However, a central challenge is the goal setting problem: robots must propose feasible and diverse goals that are achievable in their current environment. Existing methods like RIG (Visual Reinforcement Learning with Imagined Goals) use variational autoencoder (VAE) to generate goals in a learned latent space but have the limitation of producing physically implausible goals that hinder learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates physical constraints directly into the VAE training process through a novel Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling the generation of physically consistent and achievable goals. Our key innovation is the explicit separation of the latent space into physics variables governing object dynamics and environmental factors capturing visual appearance, while enforcing physical consistency through differential equation constraints and conservation laws. This enables the generation of physically consistent and achievable goals that respect fundamental physical principles such as object permanence, collision constraints, and dynamic feasibility. Through extensive experiments, we demonstrate that this physics-informed goal generation significantly improves the quality of proposed goals, leading to more effective exploration and better skill acquisition in visual robotic manipulation tasks including reaching, pushing, and pick-and-place scenarios."}
{"id": "2511.06990", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06990", "abs": "https://arxiv.org/abs/2511.06990", "authors": ["Vitor Bueno", "Ali Azarbahram", "Marcello Farina", "Lorenzo Fagiano"], "title": "Koopman-Based Dynamic Environment Prediction for Safe UAV Navigation", "comment": null, "summary": "This paper presents a Koopman-based model predictive control (MPC) framework for safe UAV navigation in dynamic environments using real-time LiDAR data. By leveraging the Koopman operator to linearly approximate the dynamics of surrounding objets, we enable efficient and accurate prediction of the position of moving obstacles. Embedding this into an MPC formulation ensures robust, collision-free trajectory planning suitable for real-time execution. The method is validated through simulation and ROS2-Gazebo implementation, demonstrating reliable performance under sensor noise, actuation delays, and environmental uncertainty."}
{"id": "2511.06990", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06990", "abs": "https://arxiv.org/abs/2511.06990", "authors": ["Vitor Bueno", "Ali Azarbahram", "Marcello Farina", "Lorenzo Fagiano"], "title": "Koopman-Based Dynamic Environment Prediction for Safe UAV Navigation", "comment": null, "summary": "This paper presents a Koopman-based model predictive control (MPC) framework for safe UAV navigation in dynamic environments using real-time LiDAR data. By leveraging the Koopman operator to linearly approximate the dynamics of surrounding objets, we enable efficient and accurate prediction of the position of moving obstacles. Embedding this into an MPC formulation ensures robust, collision-free trajectory planning suitable for real-time execution. The method is validated through simulation and ROS2-Gazebo implementation, demonstrating reliable performance under sensor noise, actuation delays, and environmental uncertainty."}
{"id": "2511.06470", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06470", "abs": "https://arxiv.org/abs/2511.06470", "authors": ["Mingde \"Harry\" Zhao"], "title": "Brain-Inspired Planning for Better Generalization in Reinforcement Learning", "comment": "McGill PhD Thesis (updated on 20251109 for typos and margin adjustments)", "summary": "Existing Reinforcement Learning (RL) systems encounter significant challenges when applied to real-world scenarios, primarily due to poor generalization across environments that differ from their training conditions. This thesis explores the direction of enhancing agents' zero-shot systematic generalization abilities by granting RL agents reasoning behaviors that are found to help systematic generalization in the human brain. Inspired by human conscious planning behaviors, we first introduced a top-down attention mechanism, which allows a decision-time planning agent to dynamically focus its reasoning on the most relevant aspects of the environmental state given its instantaneous intentions, a process we call \"spatial abstraction\". This approach significantly improves systematic generalization outside the training tasks. Subsequently, building on spatial abstraction, we developed the Skipper framework to automatically decompose complex tasks into simpler, more manageable sub-tasks. Skipper provides robustness against distributional shifts and efficacy in long-term, compositional planning by focusing on pertinent spatial and temporal elements of the environment. Finally, we identified a common failure mode and safety risk in planning agents that rely on generative models to generate state targets during planning. It is revealed that most agents blindly trust the targets they hallucinate, resulting in delusional planning behaviors. Inspired by how the human brain rejects delusional intentions, we propose learning a feasibility evaluator to enable rejecting hallucinated infeasible targets, which led to significant performance improvements in various kinds of planning agents. Finally, we suggest directions for future research, aimed at achieving general task abstraction and fully enabling abstract planning."}
{"id": "2511.05858", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05858", "abs": "https://arxiv.org/abs/2511.05858", "authors": ["Chuanyu Li", "Chaoyi Liu", "Daotan Wang", "Shuyu Zhang", "Lusong Li", "Zecui Zeng", "Fangchen Liu", "Jing Xu", "Rui Chen"], "title": "ViTaMIn-B: A Reliable and Efficient Visuo-Tactile Bimanual Manipulation Interface", "comment": null, "summary": "Handheld devices have opened up unprecedented opportunities to collect large-scale, high-quality demonstrations efficiently. However, existing systems often lack robust tactile sensing or reliable pose tracking to handle complex interaction scenarios, especially for bimanual and contact-rich tasks. In this work, we propose ViTaMIn-B, a more capable and efficient handheld data collection system for such tasks. We first design DuoTact, a novel compliant visuo-tactile sensor built with a flexible frame to withstand large contact forces during manipulation while capturing high-resolution contact geometry. To enhance the cross-sensor generalizability, we propose reconstructing the sensor's global deformation as a 3D point cloud and using it as the policy input. We further develop a robust, unified 6-DoF bimanual pose acquisition process using Meta Quest controllers, which eliminates the trajectory drift issue in common SLAM-based methods. Comprehensive user studies confirm the efficiency and high usability of ViTaMIn-B among novice and expert operators. Furthermore, experiments on four bimanual manipulation tasks demonstrate its superior task performance relative to existing systems."}
{"id": "2511.06749", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06749", "abs": "https://arxiv.org/abs/2511.06749", "authors": ["Weining Lu", "Deer Bin", "Lian Ma", "Ming Ma", "Zhihao Ma", "Xiangyang Chen", "Longfei Wang", "Yixiao Feng", "Zhouxian Jiang", "Yongliang Shi", "Bin Liang"], "title": "Semi-distributed Cross-modal Air-Ground Relative Localization", "comment": "7 pages, 3 figures. Accepted by IROS 2025", "summary": "Efficient, accurate, and flexible relative localization is crucial in air-ground collaborative tasks. However, current approaches for robot relative localization are primarily realized in the form of distributed multi-robot SLAM systems with the same sensor configuration, which are tightly coupled with the state estimation of all robots, limiting both flexibility and accuracy. To this end, we fully leverage the high capacity of Unmanned Ground Vehicle (UGV) to integrate multiple sensors, enabling a semi-distributed cross-modal air-ground relative localization framework. In this work, both the UGV and the Unmanned Aerial Vehicle (UAV) independently perform SLAM while extracting deep learning-based keypoints and global descriptors, which decouples the relative localization from the state estimation of all agents. The UGV employs a local Bundle Adjustment (BA) with LiDAR, camera, and an IMU to rapidly obtain accurate relative pose estimates. The BA process adopts sparse keypoint optimization and is divided into two stages: First, optimizing camera poses interpolated from LiDAR-Inertial Odometry (LIO), followed by estimating the relative camera poses between the UGV and UAV. Additionally, we implement an incremental loop closure detection algorithm using deep learning-based descriptors to maintain and retrieve keyframes efficiently. Experimental results demonstrate that our method achieves outstanding performance in both accuracy and efficiency. Unlike traditional multi-robot SLAM approaches that transmit images or point clouds, our method only transmits keypoint pixels and their descriptors, effectively constraining the communication bandwidth under 0.3 Mbps. Codes and data will be publicly available on https://github.com/Ascbpiac/cross-model-relative-localization.git."}
{"id": "2511.06997", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06997", "abs": "https://arxiv.org/abs/2511.06997", "authors": ["Javier Castillo-Martínez", "Raul Baños", "Francisco G. Montoya"], "title": "Beyond Phasors: Solving Non-Sinusoidal Electrical Circuits using Geometry", "comment": null, "summary": "Classical phasor analysis is fundamentally limited to sinusoidal single-frequency conditions, which poses challenges when working in the presence of harmonics. Furthermore, the conventional solution, which consists of decomposing signals using Fourier series and applying superposition, is a fragmented process that does not provide a unified solution in the frequency domain. This paper overcomes this limitation by introducing a complete and direct approach for multi-harmonic AC circuits using Geometric Algebra (GA). In this way, all non-sinusoidal voltage and current waveforms are represented as simple vectors in a $2N$-dimensional Euclidean space. The relationship between these vectors is characterized by a single and unified geometric transformation termed the \\textit{rotoflex}. This operator elevates the concept of impedance from a set of complex numbers per frequency to a single multivector that holistically captures the circuit response, while unifying the magnitude scale (flextance) and phase rotation (rotance) across all harmonics. Thus, this work establishes GA as a structurally unified and efficient alternative to phasor analysis, providing a more rigorous foundation for electrical circuit analysis. The methodology is validated through case studies that demonstrate perfect numerical consistency with traditional methods and superior performance."}
{"id": "2511.06997", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06997", "abs": "https://arxiv.org/abs/2511.06997", "authors": ["Javier Castillo-Martínez", "Raul Baños", "Francisco G. Montoya"], "title": "Beyond Phasors: Solving Non-Sinusoidal Electrical Circuits using Geometry", "comment": null, "summary": "Classical phasor analysis is fundamentally limited to sinusoidal single-frequency conditions, which poses challenges when working in the presence of harmonics. Furthermore, the conventional solution, which consists of decomposing signals using Fourier series and applying superposition, is a fragmented process that does not provide a unified solution in the frequency domain. This paper overcomes this limitation by introducing a complete and direct approach for multi-harmonic AC circuits using Geometric Algebra (GA). In this way, all non-sinusoidal voltage and current waveforms are represented as simple vectors in a $2N$-dimensional Euclidean space. The relationship between these vectors is characterized by a single and unified geometric transformation termed the \\textit{rotoflex}. This operator elevates the concept of impedance from a set of complex numbers per frequency to a single multivector that holistically captures the circuit response, while unifying the magnitude scale (flextance) and phase rotation (rotance) across all harmonics. Thus, this work establishes GA as a structurally unified and efficient alternative to phasor analysis, providing a more rigorous foundation for electrical circuit analysis. The methodology is validated through case studies that demonstrate perfect numerical consistency with traditional methods and superior performance."}
{"id": "2511.06471", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06471", "abs": "https://arxiv.org/abs/2511.06471", "authors": ["Jingtao Tang", "Hang Ma"], "title": "GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets", "comment": "Accepted to AAAI-2026", "summary": "We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP) defined over a Graph of Convex Sets (GCS) -- a powerful representation for trajectory planning that decomposes the configuration space into convex regions connected by a sparse graph. In this setting, edge costs are not fixed but depend on the specific trajectory selected through each convex region, making classical TSP methods inapplicable. We introduce GHOST, a hierarchical framework that optimally solves the GCS-TSP by combining combinatorial tour search with convex trajectory optimization. GHOST systematically explores tours on a complete graph induced by the GCS, using a novel abstract-path-unfolding algorithm to compute admissible lower bounds that guide best-first search at both the high level (over tours) and the low level (over feasible GCS paths realizing the tour). These bounds provide strong pruning power, enabling efficient search while avoiding unnecessary convex optimization calls. We prove that GHOST guarantees optimality and present a bounded-suboptimal variant for time-critical scenarios. Experiments show that GHOST is orders-of-magnitude faster than unified mixed-integer convex programming baselines for simple cases and uniquely handles complex trajectory planning problems involving high-order continuity constraints and an incomplete GCS."}
{"id": "2511.05874", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05874", "abs": "https://arxiv.org/abs/2511.05874", "authors": ["Haoran Xue", "Gias Uddin", "Song Wang"], "title": "An Empirical Study of Reasoning Steps in Thinking Code LLMs", "comment": null, "summary": "Thinking Large Language Models (LLMs) generate explicit intermediate reasoning traces before final answers, potentially improving transparency, interpretability, and solution accuracy for code generation. However, the quality of these reasoning chains remains underexplored. We present a comprehensive empirical study examining the reasoning process and quality of thinking LLMs for code generation. We evaluate six state-of-the-art reasoning LLMs (DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking, Gemini-2.5-Flash, and Qwen-QwQ) across 100 code generation tasks of varying difficulty from BigCodeBench. We quantify reasoning-chain structure through step counts and verbosity, conduct controlled step-budget adjustments, and perform a 21-participant human evaluation across three dimensions: efficiency, logical correctness, and completeness. Our step-count interventions reveal that targeted step increases can improve resolution rates for certain models/tasks, while modest reductions often preserve success on standard tasks, rarely on hard ones. Through systematic analysis, we develop a reasoning-problematic taxonomy, identifying completeness as the dominant failure mode. Task complexity significantly impacts reasoning quality; hard problems are substantially more prone to incompleteness than standard tasks. Our stability analysis demonstrates that thinking LLMs maintain consistent logical structures across computational effort levels and can self-correct previous errors. This study provides new insights into the strengths and limitations of current thinking LLMs in software engineering."}
{"id": "2511.06754", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06754", "abs": "https://arxiv.org/abs/2511.06754", "authors": ["Taisei Hanyu", "Nhat Chung", "Huy Le", "Toan Nguyen", "Yuki Ikebe", "Anthony Gunderman", "Duy Nguyen Ho Minh", "Khoa Vo", "Tung Kieu", "Kashu Yamazaki", "Chase Rainwater", "Anh Nguyen", "Ngan Le"], "title": "SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation", "comment": "under review", "summary": "Inspired by how humans reason over discrete objects and their relationships, we explore whether compact object-centric and object-relation representations can form a foundation for multitask robotic manipulation. Most existing robotic multitask models rely on dense embeddings that entangle both object and background cues, raising concerns about both efficiency and interpretability. In contrast, we study object-relation-centric representations as a pathway to more structured, efficient, and explainable visuomotor control. Our contributions are two-fold. First, we introduce LIBERO+, a fine-grained benchmark dataset designed to enable and evaluate object-relation reasoning in robotic manipulation. Unlike prior datasets, LIBERO+ provides object-centric annotations that enrich demonstrations with box- and mask-level labels as well as instance-level temporal tracking, supporting compact and interpretable visuomotor representations. Second, we propose SlotVLA, a slot-attention-based framework that captures both objects and their relations for action decoding. It uses a slot-based visual tokenizer to maintain consistent temporal object representations, a relation-centric decoder to produce task-relevant embeddings, and an LLM-driven module that translates these embeddings into executable actions. Experiments on LIBERO+ demonstrate that object-centric slot and object-relation slot representations drastically reduce the number of required visual tokens, while providing competitive generalization. Together, LIBERO+ and SlotVLA provide a compact, interpretable, and effective foundation for advancing object-relation-centric robotic manipulation."}
{"id": "2511.07052", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07052", "abs": "https://arxiv.org/abs/2511.07052", "authors": ["S. Gokul Krishnan", "Mohd Asim Aftab", "Shehab Ahmed", "Charalambos Konstantinou"], "title": "Real-Time Co-Simulation for DC Microgrid Energy Management with Communication Delays", "comment": null, "summary": "The growing integration of renewable energy sources (RESs) in modern power systems has intensified the need for resilient and efficient microgrid solutions. DC microgrids have gained prominence due to their reduced conversion losses, simplified interfacing with DC-based RESs, and improved reliability. To manage the inherent variability of RESs and ensure stable operation, energy management systems (EMS) have become essential. While various EMS algorithms have been proposed and validated using real-time simulation platforms, most assume ideal communication conditions or rely on simplified network models, overlooking the impact of realistic communication delays on EMS performance. This paper presents a novel real-time cyber-physical system (CPS) testbed for evaluating EMS performance in DC microgrids under realistic communication delays. The proposed testbed integrates a DC microgrid modeled in OPAL-RT with an EMS controller implemented on a Raspberry Pi (RPi). The communication network is emulated using EXataCPS, enabling the exchange of actual power system traffic and the replication of realistic latency conditions. This comprehensive setup captures the interplay between power system dynamics, EMS control, and communication network behavior."}
{"id": "2511.07052", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07052", "abs": "https://arxiv.org/abs/2511.07052", "authors": ["S. Gokul Krishnan", "Mohd Asim Aftab", "Shehab Ahmed", "Charalambos Konstantinou"], "title": "Real-Time Co-Simulation for DC Microgrid Energy Management with Communication Delays", "comment": null, "summary": "The growing integration of renewable energy sources (RESs) in modern power systems has intensified the need for resilient and efficient microgrid solutions. DC microgrids have gained prominence due to their reduced conversion losses, simplified interfacing with DC-based RESs, and improved reliability. To manage the inherent variability of RESs and ensure stable operation, energy management systems (EMS) have become essential. While various EMS algorithms have been proposed and validated using real-time simulation platforms, most assume ideal communication conditions or rely on simplified network models, overlooking the impact of realistic communication delays on EMS performance. This paper presents a novel real-time cyber-physical system (CPS) testbed for evaluating EMS performance in DC microgrids under realistic communication delays. The proposed testbed integrates a DC microgrid modeled in OPAL-RT with an EMS controller implemented on a Raspberry Pi (RPi). The communication network is emulated using EXataCPS, enabling the exchange of actual power system traffic and the replication of realistic latency conditions. This comprehensive setup captures the interplay between power system dynamics, EMS control, and communication network behavior."}
{"id": "2511.06522", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06522", "abs": "https://arxiv.org/abs/2511.06522", "authors": ["Jan Ondras", "Marek Šuppa"], "title": "FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis", "comment": "Accepted to The 5th Workshop on Mathematical Reasoning and AI at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025); 25 pages, 14 figures, 8 tables; Code available at https://github.com/NaiveNeuron/FractalBench", "summary": "Mathematical reasoning requires abstracting symbolic rules from visual patterns -- inferring the infinite from the finite. We investigate whether multimodal AI systems possess this capability through FractalBench, a benchmark evaluating fractal program synthesis from images. Fractals provide ideal test cases: Iterated Function Systems with only a few contraction maps generate complex self-similar patterns through simple recursive rules, requiring models to bridge visual perception with mathematical abstraction. We evaluate four leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL -- on 12 canonical fractals. Models must generate executable Python code reproducing the fractal, enabling objective evaluation. Results reveal a striking disconnect: 76% generate syntactically valid code but only 4% capture mathematical structure. Success varies systematically -- models handle geometric transformations (Koch curves: 17-21%) but fail at branching recursion (trees: <2%), revealing fundamental gaps in mathematical abstraction. FractalBench provides a contamination-resistant diagnostic for visual-mathematical reasoning and is available at https://github.com/NaiveNeuron/FractalBench"}
{"id": "2511.05880", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05880", "abs": "https://arxiv.org/abs/2511.05880", "authors": ["Yiru Zhang"], "title": "Exploration of Enterprise Big Data Microservice Architecture Based on Domain-Driven Design (DDD)", "comment": null, "summary": "With the rapid advancement of digitization and intelligence, enterprise big data processing platforms have become increasingly important in data management. However, traditional monolithic architectures, due to their high coupling, are unable to cope with increasingly complex demands in the face of business expansion and increased data volume, resulting in limited platform scalability and decreased data collection efficiency. This article proposes a solution for enterprise big data processing platform based on microservice architecture, based on the concept of Domain Driven Design (DDD). Through in-depth analysis of business requirements, the functional and non functional requirements of the platform in various scenarios were determined, and the DDD method was used to decompose the core business logic into independent microservice modules, enabling data collection, parsing, cleaning, and visualization functions to be independently developed, deployed, and upgraded, thereby improving the flexibility and scalability of the system. This article also designs an automated data collection process based on microservices and proposes an improved dynamic scheduling algorithm to efficiently allocate data collection tasks to Docker nodes, and monitor the collection progress and service status in real time to ensure the accuracy and efficiency of data collection. Through the implementation and testing of the platform, it has been verified that the enterprise big data processing platform based on microservice architecture has significantly improved scalability, data quality, and collection efficiency."}
{"id": "2511.06796", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06796", "abs": "https://arxiv.org/abs/2511.06796", "authors": ["MD-Nazmus Sunbeam"], "title": "Human-Level Actuation for Humanoids", "comment": "61 pages, 8 figures, 7 tables, and 12 numbered equations", "summary": "Claims that humanoid robots achieve ``human-level'' actuation are common but rarely quantified. Peak torque or speed specifications tell us little about whether a joint can deliver the right combination of torque, power, and endurance at task-relevant postures and rates. We introduce a comprehensive framework that makes ``human-level'' measurable and comparable across systems. Our approach has three components. First, a kinematic \\emph{DoF atlas} standardizes joint coordinate systems and ranges of motion using ISB-based conventions, ensuring that human and robot joints are compared in the same reference frames. Second, \\emph{Human-Equivalence Envelopes (HEE)} define per-joint requirements by measuring whether a robot meets human torque \\emph{and} power simultaneously at the same joint angle and rate $(q,ω)$, weighted by positive mechanical work in task-specific bands (walking, stairs, lifting, reaching, and hand actions). Third, the \\emph{Human-Level Actuation Score (HLAS)} aggregates six physically grounded factors: workspace coverage (ROM and DoF), HEE coverage, torque-mode bandwidth, efficiency, and thermal sustainability. We provide detailed measurement protocols using dynamometry, electrical power monitoring, and thermal testing that yield every HLAS input from reproducible experiments. A worked example demonstrates HLAS computation for a multi-joint humanoid, showing how the score exposes actuator trade-offs (gearing ratio versus bandwidth and efficiency) that peak-torque specifications obscure. The framework serves as both a design specification for humanoid development and a benchmarking standard for comparing actuation systems, with all components grounded in published human biomechanics data."}
{"id": "2511.07054", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07054", "abs": "https://arxiv.org/abs/2511.07054", "authors": ["Pradeep M", "Twinkle Tripathy"], "title": "Structural sign herdability of linear time-invariant systems:theory and design for arbitrary network structures", "comment": null, "summary": "The objective of this paper is to investigate graph-theoretic conditions for structural herdability of an LTI system. In particular, we are interested in the structural sign (SS) herdability of a system wherein the underlying digraph representing it is signed. Structural herdability finds applications in various domains like power networks, biological networks, opinion dynamics, multi-robot shepherding, etc. We begin the analysis by introducing a layered graph representation Gs of the signed digraph G; such a representation allows us to capture the signed distances between the nodes with ease. We construct a subgraph of G_s that characterizes paths of identical signs between layers and uniform path lengths, referred to as a layer-wise unisigned graph LUG(G_s). A special subgraph of an LUG(G_s), denoted as an LUG^H(G_s), is key to achieving SS herdability. This is because we prove that an LTI system is SS herdable if and only if there exists an LUG^H(G_s) which covers all the nodes of the given digraph. To the best of our knowledge, such a graphical test is one of the first methods which allows us to check SS herdability for arbitrary digraph topologies. Interestingly, the analysis also reveals that a system can be SS herdable even in the presence of (signed and layer) dilation in the associated digraph (note that such a behaviour has been shown to be impossible in directed trees). Additionally, we also extend these results to digraphs with multiple leader and driver nodes. In order to illustrate all the results, we present numerous examples throughout the paper."}
{"id": "2511.07054", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07054", "abs": "https://arxiv.org/abs/2511.07054", "authors": ["Pradeep M", "Twinkle Tripathy"], "title": "Structural sign herdability of linear time-invariant systems:theory and design for arbitrary network structures", "comment": null, "summary": "The objective of this paper is to investigate graph-theoretic conditions for structural herdability of an LTI system. In particular, we are interested in the structural sign (SS) herdability of a system wherein the underlying digraph representing it is signed. Structural herdability finds applications in various domains like power networks, biological networks, opinion dynamics, multi-robot shepherding, etc. We begin the analysis by introducing a layered graph representation Gs of the signed digraph G; such a representation allows us to capture the signed distances between the nodes with ease. We construct a subgraph of G_s that characterizes paths of identical signs between layers and uniform path lengths, referred to as a layer-wise unisigned graph LUG(G_s). A special subgraph of an LUG(G_s), denoted as an LUG^H(G_s), is key to achieving SS herdability. This is because we prove that an LTI system is SS herdable if and only if there exists an LUG^H(G_s) which covers all the nodes of the given digraph. To the best of our knowledge, such a graphical test is one of the first methods which allows us to check SS herdability for arbitrary digraph topologies. Interestingly, the analysis also reveals that a system can be SS herdable even in the presence of (signed and layer) dilation in the associated digraph (note that such a behaviour has been shown to be impossible in directed trees). Additionally, we also extend these results to digraphs with multiple leader and driver nodes. In order to illustrate all the results, we present numerous examples throughout the paper."}
{"id": "2511.06618", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06618", "abs": "https://arxiv.org/abs/2511.06618", "authors": ["Moriya Dechtiar", "Daniel Martin Katz", "Mari Sundaresan", "Sylvain Jaume", "Hongming Wang"], "title": "GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization", "comment": null, "summary": "Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering."}
{"id": "2511.05883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05883", "abs": "https://arxiv.org/abs/2511.05883", "authors": ["Hehai Lin", "Hui Liu", "Shilei Cao", "Jing Li", "Haoliang Li", "Wenya Wang"], "title": "Unveiling Modality Bias: Automated Sample-Specific Analysis for Multimodal Misinformation Benchmarks", "comment": null, "summary": "Numerous multimodal misinformation benchmarks exhibit bias toward specific modalities, allowing detectors to make predictions based solely on one modality. While previous research has quantified bias at the dataset level or manually identified spurious correlations between modalities and labels, these approaches lack meaningful insights at the sample level and struggle to scale to the vast amount of online information. In this paper, we investigate the design for automated recognition of modality bias at the sample level. Specifically, we propose three bias quantification methods based on theories/views of different levels of granularity: 1) a coarse-grained evaluation of modality benefit; 2) a medium-grained quantification of information flow; and 3) a fine-grained causality analysis. To verify the effectiveness, we conduct a human evaluation on two popular benchmarks. Experimental results reveal three interesting findings that provide potential direction toward future research: 1)~Ensembling multiple views is crucial for reliable automated analysis; 2)~Automated analysis is prone to detector-induced fluctuations; and 3)~Different views produce a higher agreement on modality-balanced samples but diverge on biased ones."}
{"id": "2511.06801", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06801", "abs": "https://arxiv.org/abs/2511.06801", "authors": ["Praveen Kumar", "Tushar Sandhan"], "title": "Vision-Aided Online A* Path Planning for Efficient and Safe Navigation of Service Robots", "comment": "10 pages", "summary": "The deployment of autonomous service robots in human-centric environments is hindered by a critical gap in perception and planning. Traditional navigation systems rely on expensive LiDARs that, while geometrically precise, are seman- tically unaware, they cannot distinguish a important document on an office floor from a harmless piece of litter, treating both as physically traversable. While advanced semantic segmentation exists, no prior work has successfully integrated this visual intelligence into a real-time path planner that is efficient enough for low-cost, embedded hardware. This paper presents a frame- work to bridge this gap, delivering context-aware navigation on an affordable robotic platform. Our approach centers on a novel, tight integration of a lightweight perception module with an online A* planner. The perception system employs a semantic segmentation model to identify user-defined visual constraints, enabling the robot to navigate based on contextual importance rather than physical size alone. This adaptability allows an operator to define what is critical for a given task, be it sensitive papers in an office or safety lines in a factory, thus resolving the ambiguity of what to avoid. This semantic perception is seamlessly fused with geometric data. The identified visual constraints are projected as non-geometric obstacles onto a global map that is continuously updated from sensor data, enabling robust navigation through both partially known and unknown environments. We validate our framework through extensive experiments in high-fidelity simulations and on a real-world robotic platform. The results demonstrate robust, real-time performance, proving that a cost- effective robot can safely navigate complex environments while respecting critical visual cues invisible to traditional planners."}
{"id": "2511.07159", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07159", "abs": "https://arxiv.org/abs/2511.07159", "authors": ["Mehmet Turker Takci", "James Day", "Meysam Qadrdan"], "title": "Characterisation and Quantification of Data Centre Flexibility for Power System Support", "comment": null, "summary": "The rapid growth of data centres poses an evolving challenge for power systems with high variable renewable energy. Traditionally operated as passive electrical loads, data centres, have the potential to become active participants that provide flexibility to the grid. However, quantifying and utilising this flexibility have not yet been fully explored. This paper presents an integrated, whole facility optimisation model to investigate the least cost operating schedule of data centres and characterise the aggregate flexibility available from data centres to the power system. The model accounts for IT workload shifting, UPS energy storage, and cooling system. Motivated by the need to alleviate the increasing strain on power systems while leveraging their untapped flexibility potential, this study makes two primary contributions: (i) an operational optimisation model that integrates IT scheduling, UPS operation, and cooling dynamics to establish a cost optimal baseline operation, and (ii) a duration-aware flexibility assessment that, for any given start time and power deviation, computes the maximum feasible duration from this baseline while respecting all operational, thermal, and recovery constraints. This method characterises the aggregate flexibility envelope. Results reveal a clear temporal structure and a notable asymmetry in flexibility provision: upward flexibility (electricity load reduction) is driven by deferring IT workload, which allows for a secondary reduction in cooling power. Downward flexibility (electricity load increase) relies on increasing power consumption of the cooling system, supported by the TES buffer, and charging the UPS. This framework translates abstract flexibility potential into quantified flexibility magnitude and duration that system operators could investigate for use in services such as reserve, frequency response, and price responsive demand."}
{"id": "2511.07159", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07159", "abs": "https://arxiv.org/abs/2511.07159", "authors": ["Mehmet Turker Takci", "James Day", "Meysam Qadrdan"], "title": "Characterisation and Quantification of Data Centre Flexibility for Power System Support", "comment": null, "summary": "The rapid growth of data centres poses an evolving challenge for power systems with high variable renewable energy. Traditionally operated as passive electrical loads, data centres, have the potential to become active participants that provide flexibility to the grid. However, quantifying and utilising this flexibility have not yet been fully explored. This paper presents an integrated, whole facility optimisation model to investigate the least cost operating schedule of data centres and characterise the aggregate flexibility available from data centres to the power system. The model accounts for IT workload shifting, UPS energy storage, and cooling system. Motivated by the need to alleviate the increasing strain on power systems while leveraging their untapped flexibility potential, this study makes two primary contributions: (i) an operational optimisation model that integrates IT scheduling, UPS operation, and cooling dynamics to establish a cost optimal baseline operation, and (ii) a duration-aware flexibility assessment that, for any given start time and power deviation, computes the maximum feasible duration from this baseline while respecting all operational, thermal, and recovery constraints. This method characterises the aggregate flexibility envelope. Results reveal a clear temporal structure and a notable asymmetry in flexibility provision: upward flexibility (electricity load reduction) is driven by deferring IT workload, which allows for a secondary reduction in cooling power. Downward flexibility (electricity load increase) relies on increasing power consumption of the cooling system, supported by the TES buffer, and charging the UPS. This framework translates abstract flexibility potential into quantified flexibility magnitude and duration that system operators could investigate for use in services such as reserve, frequency response, and price responsive demand."}
{"id": "2511.06626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06626", "abs": "https://arxiv.org/abs/2511.06626", "authors": ["Chloe Li", "Mary Phuong", "Daniel Tan"], "title": "Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives", "comment": null, "summary": "As AI systems become more capable of complex agentic tasks, they also become more capable of pursuing undesirable objectives and causing harm. Previous work has attempted to catch these unsafe instances by interrogating models directly about their objectives and behaviors. However, the main weakness of trusting interrogations is that models can lie. We propose self-report fine-tuning (SRFT), a simple supervised fine-tuning technique that trains models to admit their factual mistakes when asked. We show that the admission of factual errors in simple question-answering settings generalizes out-of-distribution (OOD) to the admission of hidden misaligned objectives in adversarial agentic settings. We evaluate SRFT in OOD stealth tasks, where models are instructed to complete a hidden misaligned objective alongside a user-specified objective without being caught by monitoring. After SRFT, models are more likely to confess the details of their hidden objectives when interrogated, even under strong pressure not to disclose them. Interrogation on SRFT models can detect hidden objectives with near-ceiling performance (F1 score = 0.98), while the baseline model lies when interrogated under the same conditions (F1 score = 0). Interrogation on SRFT models can further elicit the content of the hidden objective, recovering 28-100% details, compared to 0% details recovered in the baseline model and by prefilled assistant turn attacks. This provides a promising technique for promoting honesty propensity and incriminating misaligned AI systems."}
{"id": "2511.05886", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05886", "abs": "https://arxiv.org/abs/2511.05886", "authors": ["Lei Shi", "Yongju Kim", "Xinzhi Zhong", "Wissam Kontar", "Qichao Liu", "Soyoung Ahn"], "title": "Fair and Safe: A Real-Time Hierarchical Control Framework for Intersections", "comment": null, "summary": "Ensuring fairness in the coordination of connected and automated vehicles at intersections is essential for equitable access, social acceptance, and long-term system efficiency, yet it remains underexplored in safety-critical, real-time traffic control. This paper proposes a fairness-aware hierarchical control framework that explicitly integrates inequity aversion into intersection management. At the top layer, a centralized allocation module assigns control authority (i.e., selects a single vehicle to execute its trajectory) by maximizing a utility that accounts for waiting time, urgency, control history, and velocity deviation. At the bottom layer, the authorized vehicle executes a precomputed trajectory using a Linear Quadratic Regulator (LQR) and applies a high-order Control Barrier Function (HOCBF)-based safety filter for real-time collision avoidance. Simulation results across varying traffic demands and demand distributions demonstrate that the proposed framework achieves near-perfect fairness, eliminates collisions, reduces average delay, and maintains real-time feasibility. These results highlight that fairness can be systematically incorporated without sacrificing safety or performance, enabling scalable and equitable coordination for future autonomous traffic systems."}
{"id": "2511.06839", "categories": ["cs.RO", "cs.CV", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06839", "abs": "https://arxiv.org/abs/2511.06839", "authors": ["Selim Ahmet Iz", "Mustafa Unel"], "title": "Vision-Based System Identification of a Quadrotor", "comment": null, "summary": "This paper explores the application of vision-based system identification techniques in quadrotor modeling and control. Through experiments and analysis, we address the complexities and limitations of quadrotor modeling, particularly in relation to thrust and drag coefficients. Grey-box modeling is employed to mitigate uncertainties, and the effectiveness of an onboard vision system is evaluated. An LQR controller is designed based on a system identification model using data from the onboard vision system. The results demonstrate consistent performance between the models, validating the efficacy of vision based system identification. This study highlights the potential of vision-based techniques in enhancing quadrotor modeling and control, contributing to improved performance and operational capabilities. Our findings provide insights into the usability and consistency of these techniques, paving the way for future research in quadrotor performance enhancement, fault detection, and decision-making processes."}
{"id": "2511.07167", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07167", "abs": "https://arxiv.org/abs/2511.07167", "authors": ["Mengqi Li", "Lixin Li", "Wensheng Lin", "Zhu Han", "Tamer Başar"], "title": "Beyond Gaussian Assumptions: A General Fractional HJB Control Framework for Lévy-Driven Heavy-Tailed Channels in 6G", "comment": null, "summary": "Emerging 6G wireless systems suffer severe performance degradation in challenging environments like high-speed trains traversing dense urban corridors and Unmanned Aerial Vehicles (UAVs) links over mountainous terrain. These scenarios exhibit non-Gaussian, non-stationary channels with heavy-tailed fading and abrupt signal fluctuations. To address these challenges, this paper proposes a novel wireless channel model based on symmetric $α$-stable Lévy processes, thereby enabling continuous-time state-space characterization of both long-term and short-term fading. Building on this model, a generalized optimal control framework is developed via a fractional Hamilton-Jacobi-Bellman (HJB) equation that incorporates the Riesz fractional operator to capture non-local spatial effects and memory-dependent dynamics. The existence and uniqueness of viscosity solutions to the fractional HJB equation are rigorously established, thus ensuring the theoretical validity of the proposed control formulation. Numerical simulations conducted in a multi-cell, multi-user downlink setting demonstrate the effectiveness of the fractional HJB-based strategy in optimizing transmission power under heavy-tailed co-channel and multi-user interference."}
{"id": "2511.07167", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07167", "abs": "https://arxiv.org/abs/2511.07167", "authors": ["Mengqi Li", "Lixin Li", "Wensheng Lin", "Zhu Han", "Tamer Başar"], "title": "Beyond Gaussian Assumptions: A General Fractional HJB Control Framework for Lévy-Driven Heavy-Tailed Channels in 6G", "comment": null, "summary": "Emerging 6G wireless systems suffer severe performance degradation in challenging environments like high-speed trains traversing dense urban corridors and Unmanned Aerial Vehicles (UAVs) links over mountainous terrain. These scenarios exhibit non-Gaussian, non-stationary channels with heavy-tailed fading and abrupt signal fluctuations. To address these challenges, this paper proposes a novel wireless channel model based on symmetric $α$-stable Lévy processes, thereby enabling continuous-time state-space characterization of both long-term and short-term fading. Building on this model, a generalized optimal control framework is developed via a fractional Hamilton-Jacobi-Bellman (HJB) equation that incorporates the Riesz fractional operator to capture non-local spatial effects and memory-dependent dynamics. The existence and uniqueness of viscosity solutions to the fractional HJB equation are rigorously established, thus ensuring the theoretical validity of the proposed control formulation. Numerical simulations conducted in a multi-cell, multi-user downlink setting demonstrate the effectiveness of the fractional HJB-based strategy in optimizing transmission power under heavy-tailed co-channel and multi-user interference."}
{"id": "2511.06761", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06761", "abs": "https://arxiv.org/abs/2511.06761", "authors": ["Fei Yang"], "title": "SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding", "comment": null, "summary": "Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \\textit{What} and \\textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. Moreover, unlike the prevalent ``pretrain-then-finetune'' paradigm, SRNN adopts a ``predefine-then-finetune'' approach. On the CLEVRER benchmark, SRNN achieves competitive performance. Our analysis further reveals a benchmark bias, outlines a path for a more holistic evaluation, and demonstrates SRNN's white-box utility for precise error diagnosis. Our work confirms the viability of translating biological intelligence into engineered systems for intuitive physics understanding."}
{"id": "2511.05889", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05889", "abs": "https://arxiv.org/abs/2511.05889", "authors": ["Zeyuan Feng", "Haimingyue Zhang", "Somil Bansal"], "title": "From Words to Safety: Language-Conditioned Safety Filtering for Robot Navigation", "comment": null, "summary": "As robots become increasingly integrated into open-world, human-centered environments, their ability to interpret natural language instructions and adhere to safety constraints is critical for effective and trustworthy interaction. Existing approaches often focus on mapping language to reward functions instead of safety specifications or address only narrow constraint classes (e.g., obstacle avoidance), limiting their robustness and applicability. We propose a modular framework for language-conditioned safety in robot navigation. Our framework is composed of three core components: (1) a large language model (LLM)-based module that translates free-form instructions into structured safety specifications, (2) a perception module that grounds these specifications by maintaining object-level 3D representations of the environment, and (3) a model predictive control (MPC)-based safety filter that enforces both semantic and geometric constraints in real time. We evaluate the effectiveness of the proposed framework through both simulation studies and hardware experiments, demonstrating that it robustly interprets and enforces diverse language-specified constraints across a wide range of environments and scenarios."}
{"id": "2511.06892", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06892", "abs": "https://arxiv.org/abs/2511.06892", "authors": ["Kailin Tong", "Selim Solmaz", "Kenan Mujkic", "Gottfried Allmer", "Bo Leng"], "title": "Multi-Agent AI Framework for Road Situation Detection and C-ITS Message Generation", "comment": "submitted to TRA 2026", "summary": "Conventional road-situation detection methods achieve strong performance in predefined scenarios but fail in unseen cases and lack semantic interpretation, which is crucial for reliable traffic recommendations. This work introduces a multi-agent AI framework that combines multimodal large language models (MLLMs) with vision-based perception for road-situation monitoring. The framework processes camera feeds and coordinates dedicated agents for situation detection, distance estimation, decision-making, and Cooperative Intelligent Transport System (C-ITS) message generation. Evaluation is conducted on a custom dataset of 103 images extracted from 20 videos of the TAD dataset. Both Gemini-2.0-Flash and Gemini-2.5-Flash were evaluated. The results show 100\\% recall in situation detection and perfect message schema correctness; however, both models suffer from false-positive detections and have reduced performance in terms of number of lanes, driving lane status and cause code. Surprisingly, Gemini-2.5-Flash, though more capable in general tasks, underperforms Gemini-2.0-Flash in detection accuracy and semantic understanding and incurs higher latency (Table II). These findings motivate further work on fine-tuning specialized LLMs or MLLMs tailored for intelligent transportation applications."}
{"id": "2511.07225", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07225", "abs": "https://arxiv.org/abs/2511.07225", "authors": ["Matteo Cederle", "Saverio Bolognani", "Gian Antonio Susto"], "title": "Fair and Efficient allocation of Mobility-on-Demand resources through a Karma Economy", "comment": "6 pages, 3 figures. Under review at the 2026 European Control Conference (ECC)", "summary": "Mobility-on-demand systems like ride-hailing have transformed urban transportation, but they have also exacerbated socio-economic inequalities in access to these services, also due to surge pricing strategies. Although several fairness-aware frameworks have been proposed in smart mobility, they often overlook the temporal and situational variability of user urgency that shapes real-world transportation demands. This paper introduces a non-monetary, Karma-based mechanism that models endogenous urgency, allowing user time-sensitivity to evolve in response to system conditions as well as external factors. We develop a theoretical framework maintaining the efficiency and fairness guarantees of classical Karma economies, while accommodating this realistic user behavior modeling. Applied to a simulated mobility-on-demand scenario we show that our framework is able to achieve high levels of system efficiency, guaranteeing at the same time equitable resource allocation for the users."}
{"id": "2511.07225", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07225", "abs": "https://arxiv.org/abs/2511.07225", "authors": ["Matteo Cederle", "Saverio Bolognani", "Gian Antonio Susto"], "title": "Fair and Efficient allocation of Mobility-on-Demand resources through a Karma Economy", "comment": "6 pages, 3 figures. Under review at the 2026 European Control Conference (ECC)", "summary": "Mobility-on-demand systems like ride-hailing have transformed urban transportation, but they have also exacerbated socio-economic inequalities in access to these services, also due to surge pricing strategies. Although several fairness-aware frameworks have been proposed in smart mobility, they often overlook the temporal and situational variability of user urgency that shapes real-world transportation demands. This paper introduces a non-monetary, Karma-based mechanism that models endogenous urgency, allowing user time-sensitivity to evolve in response to system conditions as well as external factors. We develop a theoretical framework maintaining the efficiency and fairness guarantees of classical Karma economies, while accommodating this realistic user behavior modeling. Applied to a simulated mobility-on-demand scenario we show that our framework is able to achieve high levels of system efficiency, guaranteeing at the same time equitable resource allocation for the users."}
{"id": "2511.06805", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06805", "abs": "https://arxiv.org/abs/2511.06805", "authors": ["Jinhao Chen", "Zhen Yang", "Jianxin Shi", "Tianyu Wo", "Jie Tang"], "title": "MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning", "comment": "19 pages, 11 figures", "summary": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \\textbf{\\method}, a \\textbf{Math}ematical \\textbf{S}elf-\\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \\method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \\method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \\texttt{https://zheny2751\\allowbreak-dotcom.github.io/\\allowbreak MathSE.github.io/}."}
{"id": "2511.05891", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05891", "abs": "https://arxiv.org/abs/2511.05891", "authors": ["Linwei Wu"], "title": "Construction and Evolutionary Analysis of a Game Model for Supply Chain Finance Funding Based on Blockchain Technology", "comment": null, "summary": "The current surge in supply chain finance has significantly alleviated the \"capital challenges\" faced by domestic related enterprises, enabling enterprises upstream and subsequent stages of the industrial chain to achieve effective circulation of financing services in the supply chain based on the credit of core enterprises. By gathering essential information from the heart of the supply chain, supply chain financing enables efficient resource distribution and aids all stakeholders in making well-informed choices. However, supply chain finance in China still faces numerous obstacles, such as information asymmetry and inefficient credit transmission chains, hindering its long-term development. This paper designs an operational framework for supply chain finance incorporating blockchain technology, clearly defines the participating entities, and analyzes their business relationships. Based upon evolutionary game theory, a supply chain finance financing game model incorporating blockchain technology is constructed. A comparative analysis of the model's equilibrium points and their stability is conducted. The choices of evolutionary equilibrium strategies adopted by small and medium-sized enterprises, key players, and financing entities within this framework are explored, and the influence of blockchain technology on the prerequisites for completing supply chain finance transactions is investigated."}
{"id": "2511.06919", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06919", "abs": "https://arxiv.org/abs/2511.06919", "authors": ["Luis Diener", "Jens Kalkkuhl", "Markus Enzweiler"], "title": "Integration of Visual SLAM into Consumer-Grade Automotive Localization", "comment": "This manuscript has been submitted to the IEEE for possible publication", "summary": "Accurate ego-motion estimation in consumer-grade vehicles currently relies on proprioceptive sensors, i.e. wheel odometry and IMUs, whose performance is limited by systematic errors and calibration. While visual-inertial SLAM has become a standard in robotics, its integration into automotive ego-motion estimation remains largely unexplored. This paper investigates how visual SLAM can be integrated into consumer-grade vehicle localization systems to improve performance. We propose a framework that fuses visual SLAM with a lateral vehicle dynamics model to achieve online gyroscope calibration under realistic driving conditions. Experimental results demonstrate that vision-based integration significantly improves gyroscope calibration accuracy and thus enhances overall localization performance, highlighting a promising path toward higher automotive localization accuracy. We provide results on both proprietary and public datasets, showing improved performance and superior localization accuracy on a public benchmark compared to state-of-the-art methods."}
{"id": "2511.07323", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07323", "abs": "https://arxiv.org/abs/2511.07323", "authors": ["Papa Yaw Owusu-Obeng", "Mai Shi", "Max Vanatta", "Michael T. Craig"], "title": "Beyond Prime Farmland: Solar Siting Tradeoffs for Cost-Effective Decarbonization", "comment": "16 pages, 4 figures", "summary": "The feasibility and cost-effectiveness of continued growth in solar photovoltaics are closely tied to siting decisions. But trade-offs between costs and technical potential between land categories, especially brownfields and rooftop sites, have not been quantified, despite increasing resistance to and policy interest in reducing use of greenfield sites (e.g., prime agricultural lands). We examine the effect of siting decisions across land types for utility-scale and rooftop PV on the feasibility and cost of meeting solar deployment targets across the Eastern U.S. We build a database of solar PV supply curves by land type for each county in the Eastern Interconnect (EI) region (~2,400 counties). Our supply curves quantify technical potential versus levelized cost across greenfield, brownfield, and rooftop land types. With these supply curves and a 2035 solar deployment target (435 GW) aligned with a decarbonized power system, we quantify cost and capacity trade-offs using scenarios that prioritize solar PV deployment on different land types. We find greenfield, particularly prime agriculture, sites offer the lowest levelized costs for meeting capacity targets, of 39 to 57 $/MWh. Contaminated lands, often prioritized in policy to reduce land use conflict, have limited technical potential and impose a cost premium of 14-33% relative to greenfield sites. Rooftop PV provides enough technical potential for meeting capacity targets but comes at consistently higher costs, with minimum LCOEs of roughly 70 $/MWh or well above the highest-cost greenfield sites. Our results detail heterogeneous siting trade-offs across the Eastern United States, enabling targeted policy design to meet deployment targets while balancing costs and land use conflicts."}
{"id": "2511.07323", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07323", "abs": "https://arxiv.org/abs/2511.07323", "authors": ["Papa Yaw Owusu-Obeng", "Mai Shi", "Max Vanatta", "Michael T. Craig"], "title": "Beyond Prime Farmland: Solar Siting Tradeoffs for Cost-Effective Decarbonization", "comment": "16 pages, 4 figures", "summary": "The feasibility and cost-effectiveness of continued growth in solar photovoltaics are closely tied to siting decisions. But trade-offs between costs and technical potential between land categories, especially brownfields and rooftop sites, have not been quantified, despite increasing resistance to and policy interest in reducing use of greenfield sites (e.g., prime agricultural lands). We examine the effect of siting decisions across land types for utility-scale and rooftop PV on the feasibility and cost of meeting solar deployment targets across the Eastern U.S. We build a database of solar PV supply curves by land type for each county in the Eastern Interconnect (EI) region (~2,400 counties). Our supply curves quantify technical potential versus levelized cost across greenfield, brownfield, and rooftop land types. With these supply curves and a 2035 solar deployment target (435 GW) aligned with a decarbonized power system, we quantify cost and capacity trade-offs using scenarios that prioritize solar PV deployment on different land types. We find greenfield, particularly prime agriculture, sites offer the lowest levelized costs for meeting capacity targets, of 39 to 57 $/MWh. Contaminated lands, often prioritized in policy to reduce land use conflict, have limited technical potential and impose a cost premium of 14-33% relative to greenfield sites. Rooftop PV provides enough technical potential for meeting capacity targets but comes at consistently higher costs, with minimum LCOEs of roughly 70 $/MWh or well above the highest-cost greenfield sites. Our results detail heterogeneous siting trade-offs across the Eastern United States, enabling targeted policy design to meet deployment targets while balancing costs and land use conflicts."}
{"id": "2511.06918", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06918", "abs": "https://arxiv.org/abs/2511.06918", "authors": ["Gilles Audemard", "Christophe Lecoutre", "Emmanuel Lonca"], "title": "Proceedings of the 2025 XCSP3 Competition", "comment": "110 pages", "summary": "This document represents the proceedings of the 2025 XCSP3 Competition. The results of this competition of constraint solvers were presented at CP'25 (31st International Conference on Principles and Practice of Constraint Programming)."}
{"id": "2511.05899", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05899", "abs": "https://arxiv.org/abs/2511.05899", "authors": ["Junchun Ding"], "title": "Research On CODP Localization Decision Model Of Automotive Supply Chain Based On Delayed Manufacturing Strategy", "comment": null, "summary": "Under the market background of increasingly personalized product demand and compressed response cycle, the traditional manufacturing model with standardized mass production as the core has been difficult to meet the dual expectations of customers for differentiation and fast delivery. In order to improve the efficiency of resource allocation and market response, automobile manufacturers need to build a production system that takes into account cost and flexibility. Based on the delayed response manufacturing strategy, this study built an order response node configuration model suitable for automotive manufacturing scenarios, focusing on the positioning of order driven intervention points in the production process. The model comprehensively considers the structural cost changes brought by process adjustment, the dynamic characteristics of the changes of unit manufacturing cost and intermediate inventory cost at different stages with the location of nodes, and introduces delivery time constraints to embed time factors into the inventory decision logic to enhance the practicality of the model and the adaptation of realistic constraints. In terms of solution methods, this paper adopts function fitting and simulation analysis methods, combined with mathematical modeling tools, systematically describes the change trend of total cost, and verifies the rationality and effectiveness of the model structure and solution through actual enterprise cases. The research results provide a theoretical basis and decision support for automobile manufacturing enterprises to realize the synergy of flexible production and cost control in the environment of variable demand, and also provide an empirical reference for the implementation path and system optimization of subsequent relevant strategies."}
{"id": "2511.06998", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06998", "abs": "https://arxiv.org/abs/2511.06998", "authors": ["Jin Huang", "Yingqiang Wang", "Ying Chen"], "title": "Raspi$^2$USBL: An open-source Raspberry Pi-Based Passive Inverted Ultra-Short Baseline Positioning System for Underwater Robotics", "comment": null, "summary": "Precise underwater positioning remains a fundamental challenge for underwater robotics since global navigation satellite system (GNSS) signals cannot penetrate the sea surface. This paper presents Raspi$^2$USBL, an open-source, Raspberry Pi-based passive inverted ultra-short baseline (piUSBL) positioning system designed to provide a low-cost and accessible solution for underwater robotic research. The system comprises a passive acoustic receiver and an active beacon. The receiver adopts a modular hardware architecture that integrates a hydrophone array, a multichannel preamplifier, an oven-controlled crystal oscillator (OCXO), a Raspberry Pi 5, and an MCC-series data acquisition (DAQ) board. Apart from the Pi 5, OCXO, and MCC board, the beacon comprises an impedance-matching network, a power amplifier, and a transmitting transducer. An open-source C++ software framework provides high-precision clock synchronization and triggering for one-way travel-time (OWTT) messaging, while performing real-time signal processing, including matched filtering, array beamforming, and adaptive gain control, to estimate the time of flight (TOF) and direction of arrival (DOA) of received signals. The Raspi$^2$USBL system was experimentally validated in an anechoic tank, freshwater lake, and open-sea trials. Results demonstrate a slant-range accuracy better than 0.1%, a bearing accuracy within 0.1$^\\circ$, and stable performance over operational distances up to 1.3 km. These findings confirm that low-cost, reproducible hardware can deliver research-grade underwater positioning accuracy. By releasing both the hardware and software as open-source, Raspi$^2$USBL provides a unified reference platform that lowers the entry barrier for underwater robotics laboratories, fosters reproducibility, and promotes collaborative innovation in underwater acoustic navigation and swarm robotics."}
{"id": "2511.07335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07335", "abs": "https://arxiv.org/abs/2511.07335", "authors": ["Marcel Menner", "Eugene Lavretsky"], "title": "Robust Linear Design for Flight Control Systems with Operational Constraints", "comment": null, "summary": "This paper presents a systematic approach for designing robust linear proportional-integral (PI) servo-controllers that effectively manage control input and output constraints in flight control systems. The control design leverages the Nagumo Theorem and the Comparison Lemma to prove constraint satisfaction, while employing min-norm optimal controllers in a manner akin to Control Barrier Functions. This results in a continuous piecewise-linear state feedback policy that maintains the analyzability of the closed-loop system through the principles of linear systems theory. Additionally, we derive multi-input multi-output (MIMO) robustness margins, demonstrating that our approach enables robust tracking of external commands even in the presence of operational constraints. Moreover, the proposed control design offers a systematic approach for anti-windup protection. Through flight control trade studies, we illustrate the applicability of the proposed framework to real-world safety-critical aircraft control scenarios. Notably, MIMO margin analysis with active constraints reveals that our method preserves gain and phase margins comparable to those of the unconstrained case, in contrast to controllers that rely on hard saturation heuristics, which suffer significant performance degradation under active constraints. Simulation results using a nonlinear six-degree-of-freedom rigid body aircraft model further validate the effectiveness of our method in achieving constraint satisfaction, robustness, and effective anti-windup protection."}
{"id": "2511.07335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07335", "abs": "https://arxiv.org/abs/2511.07335", "authors": ["Marcel Menner", "Eugene Lavretsky"], "title": "Robust Linear Design for Flight Control Systems with Operational Constraints", "comment": null, "summary": "This paper presents a systematic approach for designing robust linear proportional-integral (PI) servo-controllers that effectively manage control input and output constraints in flight control systems. The control design leverages the Nagumo Theorem and the Comparison Lemma to prove constraint satisfaction, while employing min-norm optimal controllers in a manner akin to Control Barrier Functions. This results in a continuous piecewise-linear state feedback policy that maintains the analyzability of the closed-loop system through the principles of linear systems theory. Additionally, we derive multi-input multi-output (MIMO) robustness margins, demonstrating that our approach enables robust tracking of external commands even in the presence of operational constraints. Moreover, the proposed control design offers a systematic approach for anti-windup protection. Through flight control trade studies, we illustrate the applicability of the proposed framework to real-world safety-critical aircraft control scenarios. Notably, MIMO margin analysis with active constraints reveals that our method preserves gain and phase margins comparable to those of the unconstrained case, in contrast to controllers that rely on hard saturation heuristics, which suffer significant performance degradation under active constraints. Simulation results using a nonlinear six-degree-of-freedom rigid body aircraft model further validate the effectiveness of our method in achieving constraint satisfaction, robustness, and effective anti-windup protection."}
{"id": "2511.07061", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07061", "abs": "https://arxiv.org/abs/2511.07061", "authors": ["Xinran Li", "Xiujuan Xu", "Jiaqi Qiao", "Yu Liu"], "title": "Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and Curriculum Learning", "comment": "Accepted at AAAI 2026", "summary": "Emotion Recognition in Conversation (ERC) is a crucial task for understanding human emotions and enabling natural human-computer interaction. Although Large Language Models (LLMs) have recently shown great potential in this field, their ability to capture the intrinsic connections between explicit and implicit emotions remains limited. We propose a novel ERC training framework, PRC-Emo, which integrates Prompt engineering, demonstration Retrieval, and Curriculum learning, with the goal of exploring whether LLMs can effectively perceive emotions in conversational contexts. Specifically, we design emotion-sensitive prompt templates based on both explicit and implicit emotional cues to better guide the model in understanding the speaker's psychological states. We construct the first dedicated demonstration retrieval repository for ERC, which includes training samples from widely used datasets, as well as high-quality dialogue examples generated by LLMs and manually verified. Moreover, we introduce a curriculum learning strategy into the LoRA fine-tuning process, incorporating weighted emotional shifts between same-speaker and different-speaker utterances to assign difficulty levels to dialogue samples, which are then organized in an easy-to-hard training sequence. Experimental results on two benchmark datasets-- IEMOCAP and MELD --show that our method achieves new state-of-the-art (SOTA) performance, demonstrating the effectiveness and generalizability of our approach in improving LLM-based emotional understanding."}
{"id": "2511.05900", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05900", "abs": "https://arxiv.org/abs/2511.05900", "authors": ["Ruoyu Lin", "Gennaro Notomista", "Magnus Egerstedt"], "title": "Disentangled Control of Multi-Agent Systems", "comment": "This work has been submitted to IEEE Transactions on Control of Network Systems for possible publication", "summary": "This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments."}
{"id": "2511.07081", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07081", "abs": "https://arxiv.org/abs/2511.07081", "authors": ["Guanghu Xie", "Mingxu Li", "Songwei Wu", "Yang Liu", "Zongwu Xie", "Baoshi Cao", "Hong Liu"], "title": "HDCNet: A Hybrid Depth Completion Network for Grasping Transparent and Reflective Objects", "comment": null, "summary": "Depth perception of transparent and reflective objects has long been a critical challenge in robotic manipulation.Conventional depth sensors often fail to provide reliable measurements on such surfaces, limiting the performance of robots in perception and grasping tasks. To address this issue, we propose a novel depth completion network,HDCNet,which integrates the complementary strengths of Transformer,CNN and Mamba architectures.Specifically,the encoder is designed as a dual-branch Transformer-CNN framework to extract modality-specific features. At the shallow layers of the encoder, we introduce a lightweight multimodal fusion module to effectively integrate low-level features. At the network bottleneck,a Transformer-Mamba hybrid fusion module is developed to achieve deep integration of high-level semantic and global contextual information, significantly enhancing depth completion accuracy and robustness. Extensive evaluations on multiple public datasets demonstrate that HDCNet achieves state-of-the-art(SOTA) performance in depth completion tasks.Furthermore,robotic grasping experiments show that HDCNet substantially improves grasp success rates for transparent and reflective objects,achieving up to a 60% increase."}
{"id": "2511.07363", "categories": ["eess.SY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.07363", "abs": "https://arxiv.org/abs/2511.07363", "authors": ["Cayetana Salinas Rodriguez", "Jonathan Rogers", "Sarah H. Q. Li"], "title": "When the Correct Model Fails: The Optimality of Stackelberg Equilibria with Follower Intention Updates", "comment": "9 pages, 6 figures, conference submission", "summary": "We study a two-player dynamic Stackelberg game between a leader and a follower. Classical formulations of the Stackelberg equilibrium (SE) assume that the follower's best response (BR) mapping is known to the leader. However, this is not always true in practice. In those cases the leader needs to simultaneously infer this BR function while fulfilling an internal objective. We study a setting in which the leader selects a control strategy that optimizes an objective given an initial belief about the follower's best response. This belief is updated during the finite decision horizon, prompting the leader to reoptimize its control. We characterize the optimality guarantees of the SE solutions under this belief update for both open loop (OL) and feedback (FB) information structures. In particular, we show that it is possible that assuming an incorrect follower BR map obtains a lower cost over the game horizon than knowing the true BR. We support these claims with numerical examples in a linear quadratic (LQ) Stackelberg game."}
{"id": "2511.07363", "categories": ["eess.SY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.07363", "abs": "https://arxiv.org/abs/2511.07363", "authors": ["Cayetana Salinas Rodriguez", "Jonathan Rogers", "Sarah H. Q. Li"], "title": "When the Correct Model Fails: The Optimality of Stackelberg Equilibria with Follower Intention Updates", "comment": "9 pages, 6 figures, conference submission", "summary": "We study a two-player dynamic Stackelberg game between a leader and a follower. Classical formulations of the Stackelberg equilibrium (SE) assume that the follower's best response (BR) mapping is known to the leader. However, this is not always true in practice. In those cases the leader needs to simultaneously infer this BR function while fulfilling an internal objective. We study a setting in which the leader selects a control strategy that optimizes an objective given an initial belief about the follower's best response. This belief is updated during the finite decision horizon, prompting the leader to reoptimize its control. We characterize the optimality guarantees of the SE solutions under this belief update for both open loop (OL) and feedback (FB) information structures. In particular, we show that it is possible that assuming an incorrect follower BR map obtains a lower cost over the game horizon than knowing the true BR. We support these claims with numerical examples in a linear quadratic (LQ) Stackelberg game."}
{"id": "2511.07062", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07062", "abs": "https://arxiv.org/abs/2511.07062", "authors": ["Yimei Zhang", "Guojiang Shen", "Kaili Ning", "Tongwei Ren", "Xuebo Qiu", "Mengmeng Wang", "Xiangjie Kong"], "title": "Improving Region Representation Learning from Urban Imagery with Noisy Long-Caption Supervision", "comment": "Accepted as a full paper by AAAI-26", "summary": "Region representation learning plays a pivotal role in urban computing by extracting meaningful features from unlabeled urban data. Analogous to how perceived facial age reflects an individual's health, the visual appearance of a city serves as its ``portrait\", encapsulating latent socio-economic and environmental characteristics. Recent studies have explored leveraging Large Language Models (LLMs) to incorporate textual knowledge into imagery-based urban region representation learning. However, two major challenges remain: i)~difficulty in aligning fine-grained visual features with long captions, and ii) suboptimal knowledge incorporation due to noise in LLM-generated captions. To address these issues, we propose a novel pre-training framework called UrbanLN that improves Urban region representation learning through Long-text awareness and Noise suppression. Specifically, we introduce an information-preserved stretching interpolation strategy that aligns long captions with fine-grained visual semantics in complex urban scenes. To effectively mine knowledge from LLM-generated captions and filter out noise, we propose a dual-level optimization strategy. At the data level, a multi-model collaboration pipeline automatically generates diverse and reliable captions without human intervention. At the model level, we employ a momentum-based self-distillation mechanism to generate stable pseudo-targets, facilitating robust cross-modal learning under noisy conditions. Extensive experiments across four real-world cities and various downstream tasks demonstrate the superior performance of our UrbanLN."}
{"id": "2511.05903", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05903", "abs": "https://arxiv.org/abs/2511.05903", "authors": ["Zhengyuan Liu", "Stella Xin Yin", "Bryan Chen Zhengyu Tan", "Roy Ka-Wei Lee", "Guimei Liu", "Dion Hoe-Lian Goh", "Wenya Wang", "Nancy F. Chen"], "title": "The Imperfect Learner: Incorporating Developmental Trajectories in Memory-based Student Simulation", "comment": null, "summary": "User simulation is important for developing and evaluating human-centered AI, yet current student simulation in educational applications has significant limitations. Existing approaches focus on single learning experiences and do not account for students' gradual knowledge construction and evolving skill sets. Moreover, large language models are optimized to produce direct and accurate responses, making it challenging to represent the incomplete understanding and developmental constraints that characterize real learners. In this paper, we introduce a novel framework for memory-based student simulation that incorporates developmental trajectories through a hierarchical memory mechanism with structured knowledge representation. The framework also integrates metacognitive processes and personality traits to enrich the individual learner profiling, through dynamical consolidation of both cognitive development and personal learning characteristics. In practice, we implement a curriculum-aligned simulator grounded on the Next Generation Science Standards. Experimental results show that our approach can effectively reflect the gradual nature of knowledge development and the characteristic difficulties students face, providing a more accurate representation of learning processes."}
{"id": "2511.07155", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07155", "abs": "https://arxiv.org/abs/2511.07155", "authors": ["Thomas Steinecker", "Alexander Bienemann", "Denis Trescher", "Thorsten Luettel", "Mirko Maehlisch"], "title": "Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving", "comment": null, "summary": "Reinforcement learning (RL) has shown promise in robotics, but deploying RL on real vehicles remains challenging due to the complexity of vehicle dynamics and the mismatch between simulation and reality. Factors such as tire characteristics, road surface conditions, aerodynamic disturbances, and vehicle load make it infeasible to model real-world dynamics accurately, which hinders direct transfer of RL agents trained in simulation. In this paper, we present a framework that decouples motion planning from vehicle control through a spatial and temporal alignment strategy between a virtual vehicle and the real system. An RL agent is first trained in simulation using a kinematic bicycle model to output continuous control actions. Its behavior is then distilled into a trajectory-predicting agent that generates finite-horizon ego-vehicle trajectories, enabling synchronization between virtual and real vehicles. At deployment, a Stanley controller governs lateral dynamics, while longitudinal alignment is maintained through adaptive update mechanisms that compensate for deviations between virtual and real trajectories. We validate our approach on a real vehicle and demonstrate that the proposed alignment strategy enables robust zero-shot transfer of RL-based motion planning from simulation to reality, successfully decoupling high-level trajectory generation from low-level vehicle control."}
{"id": "2511.05642", "categories": ["cs.RO", "cs.AR", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05642", "abs": "https://arxiv.org/abs/2511.05642", "authors": ["Justin Williams", "Kishor Datta Gupta", "Roy George", "Mrinmoy Sarkar"], "title": "Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots", "comment": null, "summary": "The deployment of artificial intelligence models at the edge is increasingly critical for autonomous robots operating in GPS-denied environments where local, resource-efficient reasoning is essential. This work demonstrates the feasibility of deploying small Vision-Language Models (VLMs) on mobile robots to achieve real-time scene understanding and reasoning under strict computational constraints. Unlike prior approaches that separate perception from mobility, the proposed framework enables simultaneous movement and reasoning in dynamic environments using only on-board hardware. The system integrates a compact VLM with multimodal perception to perform contextual interpretation directly on embedded hardware, eliminating reliance on cloud connectivity. Experimental validation highlights the balance between computational efficiency, task accuracy, and system responsiveness. Implementation on a mobile robot confirms one of the first successful deployments of small VLMs for concurrent reasoning and mobility at the edge. This work establishes a foundation for scalable, assured autonomy in applications such as service robotics, disaster response, and defense operations."}
{"id": "2511.05642", "categories": ["cs.RO", "cs.AR", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05642", "abs": "https://arxiv.org/abs/2511.05642", "authors": ["Justin Williams", "Kishor Datta Gupta", "Roy George", "Mrinmoy Sarkar"], "title": "Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots", "comment": null, "summary": "The deployment of artificial intelligence models at the edge is increasingly critical for autonomous robots operating in GPS-denied environments where local, resource-efficient reasoning is essential. This work demonstrates the feasibility of deploying small Vision-Language Models (VLMs) on mobile robots to achieve real-time scene understanding and reasoning under strict computational constraints. Unlike prior approaches that separate perception from mobility, the proposed framework enables simultaneous movement and reasoning in dynamic environments using only on-board hardware. The system integrates a compact VLM with multimodal perception to perform contextual interpretation directly on embedded hardware, eliminating reliance on cloud connectivity. Experimental validation highlights the balance between computational efficiency, task accuracy, and system responsiveness. Implementation on a mobile robot confirms one of the first successful deployments of small VLMs for concurrent reasoning and mobility at the edge. This work establishes a foundation for scalable, assured autonomy in applications such as service robotics, disaster response, and defense operations."}
{"id": "2511.07070", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07070", "abs": "https://arxiv.org/abs/2511.07070", "authors": ["Fei Zhao", "Chonggang Lu", "Haofu Qian", "Fangcheng Shi", "Zijie Meng", "Jianzhao Huang", "Xu Tang", "Zheyong Xie", "Zheyu Ye", "Zhe Xu", "Yao Hu", "Shaosheng Cao"], "title": "RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social Networking Services", "comment": null, "summary": "As a key medium for human interaction and information exchange, social networking services (SNS) pose unique challenges for large language models (LLMs): heterogeneous workloads, fast-shifting norms and slang, and multilingual, culturally diverse corpora that induce sharp distribution shift. Supervised fine-tuning (SFT) can specialize models but often triggers a ``seesaw'' between in-distribution gains and out-of-distribution robustness, especially for smaller models. To address these challenges, we introduce RedOne 2.0, an SNS-oriented LLM trained with a progressive, RL-prioritized post-training paradigm designed for rapid and stable adaptation. The pipeline consist in three stages: (1) Exploratory Learning on curated SNS corpora to establish initial alignment and identify systematic weaknesses; (2) Targeted Fine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a small fraction of general data to mitigate forgetting; and (3) Refinement Learning that re-applies RL with SNS-centric signals to consolidate improvements and harmonize trade-offs across tasks. Across various tasks spanning three categories, our 4B scale model delivers an average improvements about 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves average performance lift about 8.74 from the base model with less than half the data required by SFT-centric method RedOne, evidencing superior data efficiency and stability at compact scales. Overall, RedOne 2.0 establishes a competitive, cost-effective baseline for domain-specific LLMs in SNS scenario, advancing capability without sacrificing robustness."}
{"id": "2511.05904", "categories": ["cs.SI", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2511.05904", "abs": "https://arxiv.org/abs/2511.05904", "authors": ["Pengwei Zhu"], "title": "The Role and Mechanism of Deep Statistical Machine Learning In Biological Target Screening and Immune Microenvironment Regulation of Asthma", "comment": null, "summary": "As an important source of small molecule drugs, natural products show remarkable biological activities with their rich types and unique structures. However, due to the limited number of samples and structural complexity, the rapid discovery of lead compounds is limited. Therefore, in this study, natural inhibitors of phosphodiesterase 4 (PDE4) and Phosphodiesterase 7 (PDE7) were screened by combining computer aided drug design (CADD) technology and deep learning method, and their activities were verified by enzyme activity experiment and enzymo-linked immunoassay. These two enzymes have important application potential in the treatment of inflammatory diseases such as chronic obstructive pulmonary disease and asthma, but PDE4 inhibitors may cause adverse reactions, so it is particularly important to develop both effective and safe dual-target inhibitors. In addition, as a potential target of hyperuricemia, the development of natural inhibitors of xanthine oxidase (X0) is also of great value. We used pharmacophore technology for virtual screening, combined with molecular docking technology to improve accuracy, and finally selected 16 potential natural inhibitors of PDE4/7, and verified their binding stability through molecular dynamics simulation. The results of this study laid a foundation for establishing an efficient dual-target inhibitor screening system and exploring the lead compounds of novel X0 inhibitors."}
{"id": "2511.07175", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07175", "abs": "https://arxiv.org/abs/2511.07175", "authors": ["Marvin Rüdt", "Constantin Enke", "Kai Furmans"], "title": "Automated Generation of Continuous-Space Roadmaps for Routing Mobile Robot Fleets", "comment": "submitted to the IEEE for possible publication; 8 pages, 6 figures, 2 tables", "summary": "Efficient routing of mobile robot fleets is crucial in intralogistics, where delays and deadlocks can substantially reduce system throughput. Roadmap design, specifying feasible transport routes, directly affects fleet coordination and computational performance. Existing approaches are either grid-based, compromising geometric precision, or continuous-space approaches that disregard practical constraints. This paper presents an automated roadmap generation approach that bridges this gap by operating in continuous-space, integrating station-to-station transport demand and enforcing minimum distance constraints for nodes and edges. By combining free space discretization, transport demand-driven $K$-shortest-path optimization, and path smoothing, the approach produces roadmaps tailored to intralogistics applications. Evaluation across multiple intralogistics use cases demonstrates that the proposed approach consistently outperforms established baselines (4-connected grid, 8-connected grid, and random sampling), achieving lower structural complexity, higher redundancy, and near-optimal path lengths, enabling efficient and robust routing of mobile robot fleets."}
{"id": "2511.06385", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06385", "abs": "https://arxiv.org/abs/2511.06385", "authors": ["Ralf Römer", "Julian Balletshofer", "Jakob Thumm", "Marco Pavone", "Angela P. Schoellig", "Matthias Althoff"], "title": "From Demonstrations to Safe Deployment: Path-Consistent Safety Filtering for Diffusion Policies", "comment": "Project page: https://tum-lsy.github.io/pacs/. 8 pages, 4 figures", "summary": "Diffusion policies (DPs) achieve state-of-the-art performance on complex manipulation tasks by learning from large-scale demonstration datasets, often spanning multiple embodiments and environments. However, they cannot guarantee safe behavior, so external safety mechanisms are needed. These, however, alter actions in ways unseen during training, causing unpredictable behavior and performance degradation. To address these problems, we propose path-consistent safety filtering (PACS) for DPs. Our approach performs path-consistent braking on a trajectory computed from the sequence of generated actions. In this way, we keep execution consistent with the policy's training distribution, maintaining the learned, task-completing behavior. To enable a real-time deployment and handle uncertainties, we verify safety using set-based reachability analysis. Our experimental evaluation in simulation and on three challenging real-world human-robot interaction tasks shows that PACS (a) provides formal safety guarantees in dynamic environments, (b) preserves task success rates, and (c) outperforms reactive safety approaches, such as control barrier functions, by up to 68% in terms of task success. Videos are available at our project website: https://tum-lsy.github.io/pacs/."}
{"id": "2511.06385", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06385", "abs": "https://arxiv.org/abs/2511.06385", "authors": ["Ralf Römer", "Julian Balletshofer", "Jakob Thumm", "Marco Pavone", "Angela P. Schoellig", "Matthias Althoff"], "title": "From Demonstrations to Safe Deployment: Path-Consistent Safety Filtering for Diffusion Policies", "comment": "Project page: https://tum-lsy.github.io/pacs/. 8 pages, 4 figures", "summary": "Diffusion policies (DPs) achieve state-of-the-art performance on complex manipulation tasks by learning from large-scale demonstration datasets, often spanning multiple embodiments and environments. However, they cannot guarantee safe behavior, so external safety mechanisms are needed. These, however, alter actions in ways unseen during training, causing unpredictable behavior and performance degradation. To address these problems, we propose path-consistent safety filtering (PACS) for DPs. Our approach performs path-consistent braking on a trajectory computed from the sequence of generated actions. In this way, we keep execution consistent with the policy's training distribution, maintaining the learned, task-completing behavior. To enable a real-time deployment and handle uncertainties, we verify safety using set-based reachability analysis. Our experimental evaluation in simulation and on three challenging real-world human-robot interaction tasks shows that PACS (a) provides formal safety guarantees in dynamic environments, (b) preserves task success rates, and (c) outperforms reactive safety approaches, such as control barrier functions, by up to 68% in terms of task success. Videos are available at our project website: https://tum-lsy.github.io/pacs/."}
{"id": "2511.07083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07083", "abs": "https://arxiv.org/abs/2511.07083", "authors": ["Marc Jansen", "Marcel Pehlke"], "title": "Increasing AI Explainability by LLM Driven Standard Processes", "comment": null, "summary": "This paper introduces an approach to increasing the explainability of artificial intelligence (AI) systems by embedding Large Language Models (LLMs) within standardized analytical processes. While traditional explainable AI (XAI) methods focus on feature attribution or post-hoc interpretation, the proposed framework integrates LLMs into defined decision models such as Question-Option-Criteria (QOC), Sensitivity Analysis, Game Theory, and Risk Management. By situating LLM reasoning within these formal structures, the approach transforms opaque inference into transparent and auditable decision traces. A layered architecture is presented that separates the reasoning space of the LLM from the explainable process space above it. Empirical evaluations show that the system can reproduce human-level decision logic in decentralized governance, systems analysis, and strategic reasoning contexts. The results suggest that LLM-driven standard processes provide a foundation for reliable, interpretable, and verifiable AI-supported decision making."}
{"id": "2511.05914", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05914", "abs": "https://arxiv.org/abs/2511.05914", "authors": ["Kevin Wei", "Lennart Heim"], "title": "Designing Incident Reporting Systems for Harms from General-Purpose AI", "comment": "Accepted to AAAI 2026", "summary": "We introduce a conceptual framework and provide considerations for the institutional design of AI incident reporting systems, i.e., processes for collecting information about safety- and rights-related events caused by general-purpose AI. As general-purpose AI systems are increasingly adopted, they are causing more real-world harms and displaying the potential to cause significantly more dangerous incidents - events that did or could have caused harm to individuals, property, or the environment. Through a literature review, we develop a framework for understanding the institutional design of AI incident reporting systems, which includes seven dimensions: policy goal, actors submitting and receiving reports, type of incidents reported, level of risk materialization, enforcement of reporting, anonymity of reporters, and post-reporting actions. We then examine nine case studies of incident reporting in safety-critical industries to extract design considerations for AI incident reporting in the United States. We discuss, among other factors, differences in systems operated by regulatory vs. non-regulatory government agencies, near miss reporting, the roles of mandatory reporting thresholds and voluntary reporting channels, how to enable safety learning after reporting, sharing incident information, and clarifying legal frameworks for reporting. Our aim is to inform researchers and policymakers about when particular design choices might be more or less appropriate for AI incident reporting."}
{"id": "2511.07275", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.07275", "abs": "https://arxiv.org/abs/2511.07275", "authors": ["David Black", "Septimiu Salcudean"], "title": "Robotic versus Human Teleoperation for Remote Ultrasound", "comment": "Under review at IEEE TMRB. Extended version of a paper presented at the Hamlyn Symposium for Medical Robotics, 2025", "summary": "Diagnostic medical ultrasound is widely used, safe, and relatively low cost but requires a high degree of expertise to acquire and interpret the images. Personnel with this expertise are often not available outside of larger cities, leading to difficult, costly travel and long wait times for rural populations. To address this issue, tele-ultrasound techniques are being developed, including robotic teleoperation and recently human teleoperation, in which a novice user is remotely guided in a hand-over-hand manner through mixed reality to perform an ultrasound exam. These methods have not been compared, and their relative strengths are unknown. Human teleoperation may be more practical than robotics for small communities due to its lower cost and complexity, but this is only relevant if the performance is comparable. This paper therefore evaluates the differences between human and robotic teleoperation, examining practical aspects such as setup time and flexibility and experimentally comparing performance metrics such as completion time, position tracking, and force consistency. It is found that human teleoperation does not lead to statistically significant differences in completion time or position accuracy, with mean differences of 1.8% and 0.5%, respectively, and provides more consistent force application despite being substantially more practical and accessible."}
{"id": "2511.06578", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06578", "abs": "https://arxiv.org/abs/2511.06578", "authors": ["Kaustubh Singh", "Shivam Kumar", "Shashikant Pawar", "Sandeep Manjanna"], "title": "Underactuated Biomimetic Autonomous Underwater Vehicle for Ecosystem Monitoring", "comment": "ICRA RUNE 2024 Workshop Paper", "summary": "In this paper, we present an underactuated biomimetic underwater robot that is suitable for ecosystem monitoring in both marine and freshwater environments. We present an updated mechanical design for a fish-like robot and propose minimal actuation behaviors learned using reinforcement learning techniques. We present our preliminary mechanical design of the tail oscillation mechanism and illustrate the swimming behaviors on FishGym simulator, where the reinforcement learning techniques will be tested on"}
{"id": "2511.06578", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06578", "abs": "https://arxiv.org/abs/2511.06578", "authors": ["Kaustubh Singh", "Shivam Kumar", "Shashikant Pawar", "Sandeep Manjanna"], "title": "Underactuated Biomimetic Autonomous Underwater Vehicle for Ecosystem Monitoring", "comment": "ICRA RUNE 2024 Workshop Paper", "summary": "In this paper, we present an underactuated biomimetic underwater robot that is suitable for ecosystem monitoring in both marine and freshwater environments. We present an updated mechanical design for a fish-like robot and propose minimal actuation behaviors learned using reinforcement learning techniques. We present our preliminary mechanical design of the tail oscillation mechanism and illustrate the swimming behaviors on FishGym simulator, where the reinforcement learning techniques will be tested on"}
{"id": "2511.07086", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07086", "abs": "https://arxiv.org/abs/2511.07086", "authors": ["Marcel Pehlke", "Marc Jansen"], "title": "LLM Driven Processes to Foster Explainable AI", "comment": null, "summary": "We present a modular, explainable LLM-agent pipeline for decision support that externalizes reasoning into auditable artifacts. The system instantiates three frameworks: Vester's Sensitivity Model (factor set, signed impact matrix, systemic roles, feedback loops); normal-form games (strategies, payoff matrix, equilibria); and sequential games (role-conditioned agents, tree construction, backward induction), with swappable modules at every step. LLM components (default: GPT-5) are paired with deterministic analyzers for equilibria and matrix-based role classification, yielding traceable intermediates rather than opaque outputs. In a real-world logistics case (100 runs), mean factor alignment with a human baseline was 55.5\\% over 26 factors and 62.9\\% on the transport-core subset; role agreement over matches was 57\\%. An LLM judge using an eight-criterion rubric (max 100) scored runs on par with a reconstructed human baseline. Configurable LLM pipelines can thus mimic expert workflows with transparent, inspectable steps."}
{"id": "2511.05927", "categories": ["cs.CY", "cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05927", "abs": "https://arxiv.org/abs/2511.05927", "authors": ["Mohammad Rashed Albous", "Melodena Stephens", "Odeh Rashed Al-Jayyousi"], "title": "Artificial intelligence and the Gulf Cooperation Council workforce adapting to the future of work", "comment": null, "summary": "The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation Council (GCC) raises a central question: are investments in compute infrastructure matched by an equally robust build-out of skills, incentives, and governance? Grounded in socio-technical systems (STS) theory, this mixed-methods study audits workforce preparedness across Kingdom of Saudi Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman. We combine term frequency--inverse document frequency (TF--IDF) analysis of six national AI strategies (NASs), an inventory of 47 publicly disclosed AI initiatives (January 2017--April 2025), paired case studies, the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data & Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix linking oil-revenue slack (technical capacity) to regulatory coherence (social alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI 0.58--0.83) exhibit joint social--technical design; country-level indices span 0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under our modeled conditions, regulatory convergence plausibly binds outcomes more than fiscal capacity: fragmented rules can offset high oil revenues, while harmonized standards help preserve progress under austerity. We also identify an emerging two-track talent system, research elites versus rapidly trained practitioners, that risks labor-market bifurcation without bridging mechanisms. By extending STS inquiry to oil-rich, state-led economies, the study refines theory and sets a research agenda focused on longitudinal coupling metrics, ethnographies of coordination, and outcome-based performance indicators."}
{"id": "2511.07292", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07292", "abs": "https://arxiv.org/abs/2511.07292", "authors": ["Simon Gerstenecker", "Andreas Geiger", "Katrin Renz"], "title": "PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving", "comment": null, "summary": "Most recent work in autonomous driving has prioritized benchmark performance and methodological innovation over in-depth analysis of model failures, biases, and shortcut learning. This has led to incremental improvements without a deep understanding of the current failures. While it is straightforward to look at situations where the model fails, it is hard to understand the underlying reason. This motivates us to conduct a systematic study, where inputs to the model are perturbed and the predictions observed. We introduce PlanT 2.0, a lightweight, object-centric planning transformer designed for autonomous driving research in CARLA. The object-level representation enables controlled analysis, as the input can be easily perturbed (e.g., by changing the location or adding or removing certain objects), in contrast to sensor-based models. To tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0, we introduce multiple upgrades to PlanT, achieving state-of-the-art performance on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis exposes insightful failures, such as a lack of scene understanding caused by low obstacle diversity, rigid expert behaviors leading to exploitable shortcuts, and overfitting to a fixed set of expert trajectories. Based on these findings, we argue for a shift toward data-centric development, with a focus on richer, more robust, and less biased datasets. We open-source our code and model at https://github.com/autonomousvision/plant2."}
{"id": "2511.06839", "categories": ["cs.RO", "cs.CV", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06839", "abs": "https://arxiv.org/abs/2511.06839", "authors": ["Selim Ahmet Iz", "Mustafa Unel"], "title": "Vision-Based System Identification of a Quadrotor", "comment": null, "summary": "This paper explores the application of vision-based system identification techniques in quadrotor modeling and control. Through experiments and analysis, we address the complexities and limitations of quadrotor modeling, particularly in relation to thrust and drag coefficients. Grey-box modeling is employed to mitigate uncertainties, and the effectiveness of an onboard vision system is evaluated. An LQR controller is designed based on a system identification model using data from the onboard vision system. The results demonstrate consistent performance between the models, validating the efficacy of vision based system identification. This study highlights the potential of vision-based techniques in enhancing quadrotor modeling and control, contributing to improved performance and operational capabilities. Our findings provide insights into the usability and consistency of these techniques, paving the way for future research in quadrotor performance enhancement, fault detection, and decision-making processes."}
{"id": "2511.06839", "categories": ["cs.RO", "cs.CV", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06839", "abs": "https://arxiv.org/abs/2511.06839", "authors": ["Selim Ahmet Iz", "Mustafa Unel"], "title": "Vision-Based System Identification of a Quadrotor", "comment": null, "summary": "This paper explores the application of vision-based system identification techniques in quadrotor modeling and control. Through experiments and analysis, we address the complexities and limitations of quadrotor modeling, particularly in relation to thrust and drag coefficients. Grey-box modeling is employed to mitigate uncertainties, and the effectiveness of an onboard vision system is evaluated. An LQR controller is designed based on a system identification model using data from the onboard vision system. The results demonstrate consistent performance between the models, validating the efficacy of vision based system identification. This study highlights the potential of vision-based techniques in enhancing quadrotor modeling and control, contributing to improved performance and operational capabilities. Our findings provide insights into the usability and consistency of these techniques, paving the way for future research in quadrotor performance enhancement, fault detection, and decision-making processes."}
{"id": "2511.07090", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07090", "abs": "https://arxiv.org/abs/2511.07090", "authors": ["Marcel Rojahn", "Marcus Grum"], "title": "Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts", "comment": null, "summary": "Across the Artificial Intelligence (AI) lifecycle - from hardware to development, deployment, and reuse - burdens span energy, carbon, water, and embodied impacts. Cloud provider tools improve transparency but remain heterogeneous and often omit water and value chain effects, limiting comparability and reproducibility. Addressing these multi dimensional burdens requires a lifecycle approach linking phase explicit mapping with system levers (hardware, placement, energy mix, cooling, scheduling) and calibrated measurement across facility, system, device, and workload levels. This article (i) establishes a unified, operational definition of Green AI distinct from Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle Assessment (LCA) stages, making energy, carbon, water, and embodied impacts first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles with decision gateways; (iv) systematizes hardware and system level strategies across the edge cloud continuum to reduce embodied burdens; and (v) defines a calibrated measurement framework combining estimator models with direct metering to enable reproducible, provider agnostic comparisons. Combining definition, lifecycle processes, hardware strategies, and calibrated measurement, this article offers actionable, evidence based guidance for researchers, practitioners, and policymakers."}
{"id": "2511.05931", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05931", "abs": "https://arxiv.org/abs/2511.05931", "authors": ["Hiroaki Hayashi", "Bo Pang", "Wenting Zhao", "Ye Liu", "Akash Gokul", "Srijan Bansal", "Caiming Xiong", "Semih Yavuz", "Yingbo Zhou"], "title": "Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement", "comment": null, "summary": "Large language model (LLM) based agents are increasingly used to tackle software engineering tasks that require multi-step reasoning and code modification, demonstrating promising yet limited performance. However, most existing LLM agents typically operate within static execution frameworks, lacking a principled mechanism to learn and self-improve from their own experience and past rollouts. As a result, their performance remains bounded by the initial framework design and the underlying LLM's capabilities. We propose Self-Abstraction from Grounded Experience (SAGE), a framework that enables agents to learn from their own task executions and refine their behavior through self-abstraction. After an initial rollout, the agent induces a concise plan abstraction from its grounded experience, distilling key steps, dependencies, and constraints. This learned abstraction is then fed back as contextual guidance, refining the agent's policy and supporting more structured, informed subsequent executions. Empirically, SAGE delivers consistent performance gains across diverse LLM backbones and agent architectures. Notably, it yields a 7.2% relative performance improvement over the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone. SAGE further achieves strong overall performance on SWE-Bench Verified benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent and OpenHands CodeAct agent framework, respectively."}
{"id": "2511.07375", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07375", "abs": "https://arxiv.org/abs/2511.07375", "authors": ["Shaohang Han", "Joris Verhagen", "Jana Tumova"], "title": "Exact Smooth Reformulations for Trajectory Optimization Under Signal Temporal Logic Specifications", "comment": null, "summary": "We study motion planning under Signal Temporal Logic (STL), a useful formalism for specifying spatial-temporal requirements. We pose STL synthesis as a trajectory optimization problem leveraging the STL robustness semantics. To obtain a differentiable problem without approximation error, we introduce an exact reformulation of the max and min operators. The resulting method is exact, smooth, and sound. We validate it in numerical simulations, demonstrating its practical performance."}
{"id": "2511.07095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07095", "abs": "https://arxiv.org/abs/2511.07095", "authors": ["Meghyn Bienvenu", "Quentin Manière"], "title": "Data Complexity of Querying Description Logic Knowledge Bases under Cost-Based Semantics", "comment": "Long version of paper to appear in AAAI 2026", "summary": "In this paper, we study the data complexity of querying inconsistent weighted description logic (DL) knowledge bases under recently-introduced cost-based semantics. In a nutshell, the idea is to assign each interpretation a cost based upon the weights of the violated axioms and assertions, and certain and possible query answers are determined by considering all (resp. some) interpretations having optimal or bounded cost. Whereas the initial study of cost-based semantics focused on DLs between $\\mathcal{EL}_\\bot$ and $\\mathcal{ALCO}$, we consider DLs that may contain inverse roles and role inclusions, thus covering prominent DL-Lite dialects. Our data complexity analysis goes significantly beyond existing results by sharpening several lower bounds and pinpointing the precise complexity of optimal-cost certain answer semantics (no non-trivial upper bound was known). Moreover, while all existing results show the intractability of cost-based semantics, our most challenging and surprising result establishes that if we consider $\\text{DL-Lite}^\\mathcal{H}_\\mathsf{bool}$ ontologies and a fixed cost bound, certain answers for instance queries and possible answers for conjunctive queries can be computed using first-order rewriting and thus enjoy the lowest possible data complexity ($\\mathsf{TC}_0$)."}
{"id": "2511.05932", "categories": ["cs.CY", "cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2511.05932", "abs": "https://arxiv.org/abs/2511.05932", "authors": ["Mohammad Rashed Albous", "Bedour Alboloushi", "Arnaud Lacheret"], "title": "The Future of AI in the GCC Post-NPM Landscape: A Comparative Analysis of Kuwait and the UAE", "comment": null, "summary": "Comparative evidence on how Gulf Cooperation Council (GCC) states turn artificial intelligence (AI) ambitions into post--New Public Management (post-NPM) outcomes is scarce because most studies examine Western democracies. We analyze constitutional, collective-choice, and operational rules shaping AI uptake in two contrasting GCC members, the United Arab Emirates (UAE) and Kuwait, and whether they foster citizen centricity, collaborative governance, and public value creation. Anchored in Ostrom's Institutional Analysis and Development framework, the study combines a most similar/most different systems design with multiple sources: 62 public documents from 2018--2025, embedded UAE cases (Smart Dubai and MBZUAI), and 39 interviews with officials conducted Aug 2024--May 2025. Dual coding and process tracing connect rule configurations to AI performance. Cross-case analysis identifies four reinforcing mechanisms behind divergent trajectories. In the UAE, concentrated authority, credible sanctions, pro-innovation narratives, and flexible reinvestment rules scale pilots into hundreds of services and sizable recycled savings. In Kuwait, dispersed veto points, exhortative sanctions, cautious discourse, and lapsed AI budgets confine initiatives to pilot mode despite equivalent fiscal resources. The findings refine institutional theory by showing that vertical rule coherence, not wealth, determines AI's public-value yield, and temper post-NPM optimism by revealing that efficiency metrics serve societal goals only when backed by enforceable safeguards. To curb ethics washing and test transferability beyond the GCC, future work should track rule diffusion over time, develop blended legitimacy--efficiency scorecards, and examine how narrative framing shapes citizen consent for data sharing."}
{"id": "2511.07381", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07381", "abs": "https://arxiv.org/abs/2511.07381", "authors": ["Yizhe Zhu", "Zhang Ye", "Boce Hu", "Haibo Zhao", "Yu Qi", "Dian Wang", "Robert Platt"], "title": "Residual Rotation Correction using Tactile Equivariance", "comment": "8 pages", "summary": "Visuotactile policy learning augments vision-only policies with tactile input, facilitating contact-rich manipulation. However, the high cost of tactile data collection makes sample efficiency the key requirement for developing visuotactile policies. We present EquiTac, a framework that exploits the inherent SO(2) symmetry of in-hand object rotation to improve sample efficiency and generalization for visuotactile policy learning. EquiTac first reconstructs surface normals from raw RGB inputs of vision-based tactile sensors, so rotations of the normal vector field correspond to in-hand object rotations. An SO(2)-equivariant network then predicts a residual rotation action that augments a base visuomotor policy at test time, enabling real-time rotation correction without additional reorientation demonstrations. On a real robot, EquiTac accurately achieves robust zero-shot generalization to unseen in-hand orientations with very few training samples, where baselines fail even with more training data. To our knowledge, this is the first tactile learning method to explicitly encode tactile equivariance for policy learning, yielding a lightweight, symmetry-aware module that improves reliability in contact-rich tasks."}
{"id": "2511.07097", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07097", "abs": "https://arxiv.org/abs/2511.07097", "authors": ["Diego Gosmar", "Anna Chiara Pallotta", "Giovanni Zenezini"], "title": "Agentic AI Sustainability Assessment for Supply Chain Document Insights", "comment": "17 pages, 4 figures", "summary": "This paper presents a comprehensive sustainability assessment framework for document intelligence within supply chain operations, centered on agentic artificial intelligence (AI). We address the dual objective of improving automation efficiency while providing measurable environmental performance in document-intensive workflows. The research compares three scenarios: fully manual (human-only), AI-assisted (human-in-the-loop, HITL), and an advanced multi-agent agentic AI workflow leveraging parsers and verifiers. Empirical results show that AI-assisted HITL and agentic AI scenarios achieve reductions of up to 70-90% in energy consumption, 90-97% in carbon dioxide emissions, and 89-98% in water usage compared to manual processes. Notably, full agentic configurations, combining advanced reasoning (thinking mode) and multi-agent validation, achieve substantial sustainability gains over human-only approaches, even when resource usage increases slightly versus simpler AI-assisted solutions. The framework integrates performance, energy, and emission indicators into a unified ESG-oriented methodology for assessing and governing AI-enabled supply chain solutions. The paper includes a complete replicability use case demonstrating the methodology's application to real-world document extraction tasks."}
{"id": "2511.05936", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05936", "abs": "https://arxiv.org/abs/2511.05936", "authors": ["Soujanya Poria", "Navonil Majumder", "Chia-Yu Hung", "Amir Ali Bagherzadeh", "Chuan Li", "Kenneth Kwok", "Ziwei Wang", "Cheston Tan", "Jiajun Wu", "David Hsu"], "title": "10 Open Challenges Steering the Future of Vision-Language-Action Models", "comment": "AAAI 2026 (Senior Track)", "summary": "Due to their ability of follow natural language instructions, vision-language-action (VLA) models are increasingly prevalent in the embodied AI arena, following the widespread success of their precursors -- LLMs and VLMs. In this paper, we discuss 10 principal milestones in the ongoing development of VLA models -- multimodality, reasoning, data, evaluation, cross-robot action generalization, efficiency, whole-body coordination, safety, agents, and coordination with humans. Furthermore, we discuss the emerging trends of using spatial understanding, modeling world dynamics, post training, and data synthesis -- all aiming to reach these milestones. Through these discussions, we hope to bring attention to the research avenues that may accelerate the development of VLA models into wider acceptability."}
{"id": "2511.07407", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07407", "abs": "https://arxiv.org/abs/2511.07407", "authors": ["Zhengjie Xu", "Ye Li", "Kwan-yee Lin", "Stella X. Yu"], "title": "Unified Humanoid Fall-Safety Policy from a Few Demonstrations", "comment": null, "summary": "Falling is an inherent risk of humanoid mobility. Maintaining stability is thus a primary safety focus in robot control and learning, yet no existing approach fully averts loss of balance. When instability does occur, prior work addresses only isolated aspects of falling: avoiding falls, choreographing a controlled descent, or standing up afterward. Consequently, humanoid robots lack integrated strategies for impact mitigation and prompt recovery when real falls defy these scripts. We aim to go beyond keeping balance to make the entire fall-and-recovery process safe and autonomous: prevent falls when possible, reduce impact when unavoidable, and stand up when fallen. By fusing sparse human demonstrations with reinforcement learning and an adaptive diffusion-based memory of safe reactions, we learn adaptive whole-body behaviors that unify fall prevention, impact mitigation, and rapid recovery in one policy. Experiments in simulation and on a Unitree G1 demonstrate robust sim-to-real transfer, lower impact forces, and consistently fast recovery across diverse disturbances, pointing towards safer, more resilient humanoids in real environments. Videos are available at https://firm2025.github.io/."}
{"id": "2511.07098", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07098", "abs": "https://arxiv.org/abs/2511.07098", "authors": ["Yuanshao Zhu", "Xiangyu Zhao", "Zijian Zhang", "Xuetao Wei", "James Jianqiao Yu"], "title": "Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture and Focalized Optimization", "comment": "Accepted as a regular paper by AAAI'26", "summary": "Fine-grained urban flow inference is crucial for urban planning and intelligent transportation systems, enabling precise traffic management and resource allocation. However, the practical deployment of existing methods is hindered by two key challenges: the prohibitive computational cost of over-parameterized models and the suboptimal performance of conventional loss functions on the highly skewed distribution of urban flows. To address these challenges, we propose a unified solution that synergizes architectural efficiency with adaptive optimization. Specifically, we first introduce PLGF, a lightweight yet powerful architecture that employs a Progressive Local-Global Fusion strategy to effectively capture both fine-grained details and global contextual dependencies. Second, we propose DualFocal Loss, a novel function that integrates dual-space supervision with a difficulty-aware focusing mechanism, enabling the model to adaptively concentrate on hard-to-predict regions. Extensive experiments on 4 real-world scenarios validate the effectiveness and scalability of our method. Notably, while achieving state-of-the-art performance, PLGF reduces the model size by up to 97% compared to current high-performing methods. Furthermore, under comparable parameter budgets, our model yields an accuracy improvement of over 10% against strong baselines. The implementation is included in the https://github.com/Yasoz/PLGF."}
{"id": "2511.05951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05951", "abs": "https://arxiv.org/abs/2511.05951", "authors": ["Qi Wang", "Hongzhi Zhang", "Jia Fu", "Kai Fu", "Yahui Liu", "Tinghai Zhang", "Chenxi Sun", "Gangwei Jiang", "Jingyi Tang", "Xingguang Ji", "Yang Yue", "Jingyuan Zhang", "Fuzheng Zhang", "Kun Gai", "Guorui Zhou"], "title": "Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling", "comment": "20 pages, 7 figures", "summary": "Despite the proliferation of powerful agentic models, the lack of critical post-training details hinders the development of strong counterparts in the open-source community. In this study, we present a comprehensive and fully open-source pipeline for training a high-performance agentic model for interacting with external tools and environments, named Klear-Qwen3-AgentForge, starting from the Qwen3-8B base model. We design effective supervised fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement learning (RL) to unlock the potential for multiple diverse agentic tasks. We perform exclusive experiments on various agentic benchmarks in both tool use and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art performance among LLMs of similar size and remains competitive with significantly larger models."}
{"id": "2511.07410", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07410", "abs": "https://arxiv.org/abs/2511.07410", "authors": ["Hao Wang", "Sathwik Karnik", "Bea Lim", "Somil Bansal"], "title": "Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective", "comment": null, "summary": "Large Language Models (LLMs) and Vision Language Models (VLMs) have been widely used for embodied symbolic planning. Yet, how to effectively use these models for closed-loop symbolic planning remains largely unexplored. Because they operate as black boxes, LLMs and VLMs can produce unpredictable or costly errors, making their use in high-level robotic planning especially challenging. In this work, we investigate how to use VLMs as closed-loop symbolic planners for robotic applications from a control-theoretic perspective. Concretely, we study how the control horizon and warm-starting impact the performance of VLM symbolic planners. We design and conduct controlled experiments to gain insights that are broadly applicable to utilizing VLMs as closed-loop symbolic planners, and we discuss recommendations that can help improve the performance of VLM symbolic planners."}
{"id": "2511.07104", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07104", "abs": "https://arxiv.org/abs/2511.07104", "authors": ["Junji Hou", "Junzhou Zhao", "Shuo Zhang", "Pinghui Wang"], "title": "A Theoretical Analysis of Detecting Large Model-Generated Time Series", "comment": "23 pages,12 figures, to be published in AAAI-2026 main track", "summary": "Motivated by the increasing risks of data misuse and fabrication, we investigate the problem of identifying synthetic time series generated by Time-Series Large Models (TSLMs) in this work. While there are extensive researches on detecting model generated text, we find that these existing methods are not applicable to time series data due to the fundamental modality difference, as time series usually have lower information density and smoother probability distributions than text data, which limit the discriminative power of token-based detectors. To address this issue, we examine the subtle distributional differences between real and model-generated time series and propose the contraction hypothesis, which states that model-generated time series, unlike real ones, exhibit progressively decreasing uncertainty under recursive forecasting. We formally prove this hypothesis under theoretical assumptions on model behavior and time series structure. Model-generated time series exhibit progressively concentrated distributions under recursive forecasting, leading to uncertainty contraction. We provide empirical validation of the hypothesis across diverse datasets. Building on this insight, we introduce the Uncertainty Contraction Estimator (UCE), a white-box detector that aggregates uncertainty metrics over successive prefixes to identify TSLM-generated time series. Extensive experiments on 32 datasets show that UCE consistently outperforms state-of-the-art baselines, offering a reliable and generalizable solution for detecting model-generated time series."}
{"id": "2511.05953", "categories": ["cs.CY", "cs.MM", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.05953", "abs": "https://arxiv.org/abs/2511.05953", "authors": ["Atharva Mehta", "Shivam Chauhan", "Megha Sharma", "Gus Xia", "Kaustuv Kanti Ganguli", "Nishanth Chandran", "Zeerak Talat", "Monojit Choudhury"], "title": "Who Gets Heard? Rethinking Fairness in AI for Music Systems", "comment": "7 pages, Accepted at NeurIPS'25 workshop on AI for Music", "summary": "In recent years, the music research community has examined risks of AI models for music, with generative AI models in particular, raised concerns about copyright, deepfakes, and transparency. In our work, we raise concerns about cultural and genre biases in AI for music systems (music-AI systems) which affect stakeholders including creators, distributors, and listeners shaping representation in AI for music. These biases can misrepresent marginalized traditions, especially from the Global South, producing inauthentic outputs (e.g., distorted ragas) that reduces creators' trust on these systems. Such harms risk reinforcing biases, limiting creativity, and contributing to cultural erasure. To address this, we offer recommendations at dataset, model and interface level in music-AI systems."}
{"id": "2511.07416", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07416", "abs": "https://arxiv.org/abs/2511.07416", "authors": ["Jiageng Mao", "Sicheng He", "Hao-Ning Wu", "Yang You", "Shuyang Sun", "Zhicheng Wang", "Yanan Bao", "Huizhong Chen", "Leonidas Guibas", "Vitor Guizilini", "Howard Zhou", "Yue Wang"], "title": "Robot Learning from a Physical World Model", "comment": "Project page: https://pointscoder.github.io/PhysWorld_Web/", "summary": "We introduce PhysWorld, a framework that enables robot learning from video generation through physical world modeling. Recent video generation models can synthesize photorealistic visual demonstrations from language commands and images, offering a powerful yet underexplored source of training signals for robotics. However, directly retargeting pixel motions from generated videos to robots neglects physics, often resulting in inaccurate manipulations. PhysWorld addresses this limitation by coupling video generation with physical world reconstruction. Given a single image and a task command, our method generates task-conditioned videos and reconstructs the underlying physical world from the videos, and the generated video motions are grounded into physically accurate actions through object-centric residual reinforcement learning with the physical world model. This synergy transforms implicit visual guidance into physically executable robotic trajectories, eliminating the need for real robot data collection and enabling zero-shot generalizable robotic manipulation. Experiments on diverse real-world tasks demonstrate that PhysWorld substantially improves manipulation accuracy compared to previous approaches. Visit \\href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage} for details."}
{"id": "2511.07107", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07107", "abs": "https://arxiv.org/abs/2511.07107", "authors": ["Liang Shan", "Kaicheng Shen", "Wen Wu", "Zhenyu Ying", "Chaochao Lu", "Guangze Ye", "Liang He"], "title": "MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks", "comment": null, "summary": "Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment."}
{"id": "2511.05977", "categories": ["cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.05977", "abs": "https://arxiv.org/abs/2511.05977", "authors": ["Pavel Naumov", "Alexandra Pavlova"], "title": "An Epistemic Perspective on Agent Awareness", "comment": "Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "The paper proposes to treat agent awareness as a form of knowledge, breaking the tradition in the existing literature on awareness. It distinguishes the de re and de dicto forms of such knowledge. The work introduces two modalities capturing these forms and formally specifies their meaning using a version of 2D-semantics. The main technical result is a sound and complete logical system describing the interplay between the two proposed modalities and the standard \"knowledge of the fact\" modality."}
{"id": "2511.07418", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.DC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.07418", "abs": "https://arxiv.org/abs/2511.07418", "authors": ["Zhao-Heng Yin", "Pieter Abbeel"], "title": "Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields", "comment": "Code: https://github.com/zhaohengyin/lightning-grasp", "summary": "Despite years of research, real-time diverse grasp synthesis for dexterous hands remains an unsolved core challenge in robotics and computer graphics. We present Lightning Grasp, a novel high-performance procedural grasp synthesis algorithm that achieves orders-of-magnitude speedups over state-of-the-art approaches, while enabling unsupervised grasp generation for irregular, tool-like objects. The method avoids many limitations of prior approaches, such as the need for carefully tuned energy functions and sensitive initialization. This breakthrough is driven by a key insight: decoupling complex geometric computation from the search process via a simple, efficient data structure - the Contact Field. This abstraction collapses the problem complexity, enabling a procedural search at unprecedented speeds. We open-source our system to propel further innovation in robotic manipulation."}
{"id": "2511.07110", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07110", "abs": "https://arxiv.org/abs/2511.07110", "authors": ["Tianhao Fu", "Xinxin Xu", "Weichen Xu", "Jue Chen", "Ruilong Ren", "Bowen Deng", "Xinyu Zhao", "Jian Cao", "Xixin Cao"], "title": "Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture", "comment": null, "summary": "Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows significant performance. Such methods are hindered by their slow inference speed, while most of the current research has not studied LLM distillation for this specific task. To address this, we first propose the normalized fluorescent probe to study the mechanism of the LLM's feature. Based on the observation found by our investigation, we propose Cooperative Market Making (CMM), a novel framework that decouples LLM features across three orthogonal dimensions: layer, task, and data. Various student models collaboratively learn simple LLM features along with different dimensions, with each model responsible for a distinct feature to achieve knowledge distillation. Furthermore, CMM introduces an Hájek-MoE to integrate the output of the student models by investigating the contribution of different models in a kernel function-generated common feature space. Extensive experimental results on four real-world market datasets demonstrate the superiority of CMM over the current distillation method and RL-based market-making strategies."}
{"id": "2511.05995", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05995", "abs": "https://arxiv.org/abs/2511.05995", "authors": ["Jianbo Yuan", "Jing Dai", "Yerui Fan", "Yaxiong Wu", "Yunpeng Liang", "Weixin Yan"], "title": "Robustness study of the bio-inspired musculoskeletal arm robot based on the data-driven iterative learning algorithm", "comment": "20 pages, 13 figures", "summary": "The human arm exhibits remarkable capabilities, including both explosive power and precision, which demonstrate dexterity, compliance, and robustness in unstructured environments. Developing robotic systems that emulate human-like operational characteristics through musculoskeletal structures has long been a research focus. In this study, we designed a novel lightweight tendon-driven musculoskeletal arm (LTDM-Arm), featuring a seven degree-of-freedom (DOF) skeletal joint system and a modularized artificial muscular system (MAMS) with 15 actuators. Additionally, we employed a Hilly-type muscle model and data-driven iterative learning control (DDILC) to learn and refine activation signals for repetitive tasks within a finite time frame. We validated the anti-interference capabilities of the musculoskeletal system through both simulations and experiments. The results show that the LTDM-Arm system can effectively achieve desired trajectory tracking tasks, even under load disturbances of 20 % in simulation and 15 % in experiments. This research lays the foundation for developing advanced robotic systems with human-like operational performance."}
{"id": "2511.05900", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05900", "abs": "https://arxiv.org/abs/2511.05900", "authors": ["Ruoyu Lin", "Gennaro Notomista", "Magnus Egerstedt"], "title": "Disentangled Control of Multi-Agent Systems", "comment": "This work has been submitted to IEEE Transactions on Control of Network Systems for possible publication", "summary": "This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments."}
{"id": "2511.07126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07126", "abs": "https://arxiv.org/abs/2511.07126", "authors": ["Tim Bohne", "Anne-Kathrin Patricia Windler", "Martin Atzmueller"], "title": "Saliency Map-Guided Knowledge Discovery for Subclass Identification with LLM-Based Symbolic Approximations", "comment": null, "summary": "This paper proposes a novel neuro-symbolic approach for sensor signal-based knowledge discovery, focusing on identifying latent subclasses in time series classification tasks. The approach leverages gradient-based saliency maps derived from trained neural networks to guide the discovery process. Multiclass time series classification problems are transformed into binary classification problems through label subsumption, and classifiers are trained for each of these to yield saliency maps. The input signals, grouped by predicted class, are clustered under three distinct configurations. The centroids of the final set of clusters are provided as input to an LLM for symbolic approximation and fuzzy knowledge graph matching to discover the underlying subclasses of the original multiclass problem. Experimental results on well-established time series classification datasets demonstrate the effectiveness of our saliency map-driven method for knowledge discovery, outperforming signal-only baselines in both clustering and subclass identification."}
{"id": "2511.06011", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06011", "abs": "https://arxiv.org/abs/2511.06011", "authors": ["Tong Zhou", "Yubing Li"], "title": "Parameter Recovery from Tangential Interpolations for Systems with an LFT Structure", "comment": "15 pages, 3 figures, 1 table", "summary": "This paper investigates how to recover parameters of a linear time invariant system from values and derivatives of its transfer function matrix, along several particular directions at a prescribed set of points in the complex plane, in which system matrices depend on these parameters through a linear fractional transformation. A necessary and sufficient condition is derived for a unique determination of these system parameters, which is expressed by a vector inequality. Under some particular situations, this condition reduces to a full column rank requirement on a constant matrix. Moreover, a method is given to recover system parameters from these values and derivatives, which is expressed by a vector linear equation with some rank constraints, for which various methods exist for finding its solutions. Robustness of the suggested recovery method is also clarified. A numerical example is given to illustrate characteristics of the suggested method, as well as effectiveness of derivative information introduction in parameter recovery, in which natural frequency and damping ratio are to be recovered for a transfer function."}
{"id": "2511.06084", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06084", "abs": "https://arxiv.org/abs/2511.06084", "authors": ["Juan Augusto Paredes Salazar", "Ankit Goel"], "title": "Model-free Adaptive Output Feedback Vibration Suppression in a Cantilever Beam", "comment": "16 pages, 14 figures, to be presented at Scitech 2026", "summary": "This paper presents a model-free adaptive control approach to suppress vibrations in a cantilevered beam excited by an unknown disturbance. The cantilevered beam under harmonic excitation is modeled using a lumped parameter approach. Based on retrospective cost optimization, a sampled-data adaptive controller is developed to suppress vibrations caused by external disturbances. Both displacement and acceleration measurements are considered for feedback. Since acceleration measurements are more sensitive to spillover, which excites higher frequency modes, a filter is developed to extract key displacement information from the acceleration data and enhance suppression performance. The vibration suppression performance is compared using both displacement and acceleration measurements."}
{"id": "2511.07204", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07204", "abs": "https://arxiv.org/abs/2511.07204", "authors": ["Giacomo Fidone", "Lucia Passaro", "Riccardo Guidotti"], "title": "Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations", "comment": "Accepted for publication at AAAI Conference on Artificial Intelligence 2026", "summary": "Online Social Networks (OSNs) widely adopt content moderation to mitigate the spread of abusive and toxic discourse. Nonetheless, the real effectiveness of moderation interventions remains unclear due to the high cost of data collection and limited experimental control. The latest developments in Natural Language Processing pave the way for a new evaluation approach. Large Language Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and simulate human-like social behavior with unprecedented degree of believability. Yet, existing tools do not support simulation-based evaluation of moderation strategies. We fill this gap by designing a LLM-powered simulator of OSN conversations enabling a parallel, counterfactual simulation where toxic behavior is influenced by moderation interventions, keeping all else equal. We conduct extensive experiments, unveiling the psychological realism of OSN agents, the emergence of social contagion phenomena and the superior effectiveness of personalized moderation strategies."}
{"id": "2511.06026", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06026", "abs": "https://arxiv.org/abs/2511.06026", "authors": ["Yi Gao", "Xi Xiong", "Karl H. Johansson", "Li Jin"], "title": "Probe-and-Release Coordination of Platoons at Highway Bottlenecks with Unknown Parameters", "comment": "15 pages, 12 figures", "summary": "This paper considers coordination of platoons of connected and autonomous vehicles (CAVs) at mixed-autonomy bottlenecks in the face of three practically important factors, viz. time-varying traffic demand, random CAV platoon sizes, and capacity breakdowns. Platoon coordination is essential to smoothen the interaction between CAV platoons and non-CAV traffic. Based on a fluid queuing model, we develop a \"probe-and-release\" algorithm that simultaneously estimates environmental parameters and coordinates CAV platoons for traffic stabilization. We show that this algorithm ensures bounded estimation errors and bounded traffic queues. The proof builds on a Lyapunov function that jointly penalizes estimation errors and traffic queues and a drift argument for an embedded Markov process. We validate the proposed algorithm in a standard micro-simulation environment and compare against a representative deep reinforcement learning method in terms of control performance and computational efficiency."}
{"id": "2511.06471", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06471", "abs": "https://arxiv.org/abs/2511.06471", "authors": ["Jingtao Tang", "Hang Ma"], "title": "GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets", "comment": "Accepted to AAAI-2026", "summary": "We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP) defined over a Graph of Convex Sets (GCS) -- a powerful representation for trajectory planning that decomposes the configuration space into convex regions connected by a sparse graph. In this setting, edge costs are not fixed but depend on the specific trajectory selected through each convex region, making classical TSP methods inapplicable. We introduce GHOST, a hierarchical framework that optimally solves the GCS-TSP by combining combinatorial tour search with convex trajectory optimization. GHOST systematically explores tours on a complete graph induced by the GCS, using a novel abstract-path-unfolding algorithm to compute admissible lower bounds that guide best-first search at both the high level (over tours) and the low level (over feasible GCS paths realizing the tour). These bounds provide strong pruning power, enabling efficient search while avoiding unnecessary convex optimization calls. We prove that GHOST guarantees optimality and present a bounded-suboptimal variant for time-critical scenarios. Experiments show that GHOST is orders-of-magnitude faster than unified mixed-integer convex programming baselines for simple cases and uniquely handles complex trajectory planning problems involving high-order continuity constraints and an incomplete GCS."}
{"id": "2511.07260", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07260", "abs": "https://arxiv.org/abs/2511.07260", "authors": ["Hohei Chan", "Xinzhi Zhang", "Antao Xiang", "Weinan Zhang", "Mengchen Zhao"], "title": "PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork", "comment": "Accepted by the 40th AAAI conference on Artificial Intelligence (AAAI 2026)", "summary": "Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly."}
{"id": "2511.06063", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06063", "abs": "https://arxiv.org/abs/2511.06063", "authors": ["Wentao Tang", "Xiuzhen Ye"], "title": "Koopman Operator for Stability Analysis: Theory with a Linear--Radial Product Reproducing Kernel", "comment": "17 pages, 10 figures, submitted to L4DC 2026", "summary": "Koopman operator, as a fully linear representation of nonlinear dynamical systems, if well-defined on a reproducing kernel Hilbert space (RKHS), can be efficiently learned from data. For stability analysis and control-related problems, it is desired that the defining RKHS of the Koopman operator should account for both the stability of an equilibrium point (as a local property) and the regularity of the dynamics on the state space (as a global property). To this end, we show that by using the product kernel formed by the linear kernel and a Wendland radial kernel, the resulting RKHS is invariant under the action of Koopman operator (under certain smoothness conditions). Furthermore, when the equilibrium is asymptotically stable, the spectrum of Koopman operator is provably confined inside the unit circle, and escapes therefrom upon bifurcation. Thus, the learned Koopman operator with provable probabilistic error bound provides a stability certificate. In addition to numerical verification, we further discuss how such a fundamental spectrum--stability relation would be useful for Koopman-based control."}
{"id": "2511.07262", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07262", "abs": "https://arxiv.org/abs/2511.07262", "authors": ["Qile Jiang", "George Karniadakis"], "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning", "comment": null, "summary": "Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing."}
{"id": "2511.06065", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06065", "abs": "https://arxiv.org/abs/2511.06065", "authors": ["Lianrui Li", "Dakuan Lu", "Jiawei Shao", "Chi Zhang", "Xuelong Li"], "title": "ScRPO: From Errors to Insights", "comment": null, "summary": "We propose Self-correction Relative Policy Optimization (ScRPO), a novel reinforcement learning framework designed to enhance large language models on challenging mathematical problems by leveraging self-reflection and error correction. Our approach consists of two stages: (1) Trial-and-error learning stage: training the model with GRPO and collecting incorrect answers along with their corresponding questions in an error pool; (2) Self-correction learning stage: guiding the model to reflect on why its previous answers were wrong. Extensive experiments across multiple math reasoning benchmarks, including AIME, AMC, Olympiad, MATH-500, GSM8k, using Deepseek-Distill-Qwen-1.5B and Deepseek-Distill-Qwen-7B. The experimental results demonstrate that ScRPO consistently outperforms several post-training methods. These findings highlight ScRPO as a promising paradigm for enabling language models to self-improve on difficult tasks with limited external feedback, paving the way toward more reliable and capable AI systems."}
{"id": "2511.07267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07267", "abs": "https://arxiv.org/abs/2511.07267", "authors": ["Chen Han", "Yijia Ma", "Jin Tan", "Wenzhen Zheng", "Xijin Tang"], "title": "Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion", "comment": "This paper has been accepted to AAAI 2026", "summary": "Multi-agent debate (MAD) frameworks have emerged as promising approaches for misinformation detection by simulating adversarial reasoning. While prior work has focused on detection accuracy, it overlooks the importance of helping users understand the reasoning behind factual judgments and develop future resilience. The debate transcripts generated during MAD offer a rich but underutilized resource for transparent reasoning. In this study, we introduce ED2D, an evidence-based MAD framework that extends previous approach by incorporating factual evidence retrieval. More importantly, ED2D is designed not only as a detection framework but also as a persuasive multi-agent system aimed at correcting user beliefs and discouraging misinformation sharing. We compare the persuasive effects of ED2D-generated debunking transcripts with those authored by human experts. Results demonstrate that ED2D outperforms existing baselines across three misinformation detection benchmarks. When ED2D generates correct predictions, its debunking transcripts exhibit persuasive effects comparable to those of human experts; However, when ED2D misclassifies, its accompanying explanations may inadvertently reinforce users'misconceptions, even when presented alongside accurate human explanations. Our findings highlight both the promise and the potential risks of deploying MAD systems for misinformation intervention. We further develop a public community website to help users explore ED2D, fostering transparency, critical thinking, and collaborative fact-checking."}
{"id": "2511.06078", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06078", "abs": "https://arxiv.org/abs/2511.06078", "authors": ["Luis Marquez-Carpintero", "Alberto Lopez-Sellers", "Miguel Cazorla"], "title": "Simulating Students with Large Language Models: A Review of Architecture, Mechanisms, and Role Modelling in Education with Generative AI", "comment": null, "summary": "Simulated Students offer a valuable methodological framework for evaluating pedagogical approaches and modelling diverse learner profiles, tasks which are otherwise challenging to undertake systematically in real-world settings. Recent research has increasingly focused on developing such simulated agents to capture a range of learning styles, cognitive development pathways, and social behaviours. Among contemporary simulation techniques, the integration of large language models (LLMs) into educational research has emerged as a particularly versatile and scalable paradigm. LLMs afford a high degree of linguistic realism and behavioural adaptability, enabling agents to approximate cognitive processes and engage in contextually appropriate pedagogical dialogues. This paper presents a thematic review of empirical and methodological studies utilising LLMs to simulate student behaviour across educational environments. We synthesise current evidence on the capacity of LLM-based agents to emulate learner archetypes, respond to instructional inputs, and interact within multi-agent classroom scenarios. Furthermore, we examine the implications of such systems for curriculum development, instructional evaluation, and teacher training. While LLMs surpass rule-based systems in natural language generation and situational flexibility, ongoing concerns persist regarding algorithmic bias, evaluation reliability, and alignment with educational objectives. The review identifies existing technological and methodological gaps and proposes future research directions for integrating generative AI into adaptive learning systems and instructional design."}
{"id": "2511.07327", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07327", "abs": "https://arxiv.org/abs/2511.07327", "authors": ["Guoxin Chen", "Zile Qiao", "Xuanzhong Chen", "Donglei Yu", "Haotian Xu", "Wayne Xin Zhao", "Ruihua Song", "Wenbiao Yin", "Huifeng Yin", "Liwen Zhang", "Kuan Li", "Minpeng Liao", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "title": "IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction", "comment": "https://github.com/Alibaba-NLP/DeepResearch", "summary": "Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\\% to 42.5\\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models."}
{"id": "2511.06084", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06084", "abs": "https://arxiv.org/abs/2511.06084", "authors": ["Juan Augusto Paredes Salazar", "Ankit Goel"], "title": "Model-free Adaptive Output Feedback Vibration Suppression in a Cantilever Beam", "comment": "16 pages, 14 figures, to be presented at Scitech 2026", "summary": "This paper presents a model-free adaptive control approach to suppress vibrations in a cantilevered beam excited by an unknown disturbance. The cantilevered beam under harmonic excitation is modeled using a lumped parameter approach. Based on retrospective cost optimization, a sampled-data adaptive controller is developed to suppress vibrations caused by external disturbances. Both displacement and acceleration measurements are considered for feedback. Since acceleration measurements are more sensitive to spillover, which excites higher frequency modes, a filter is developed to extract key displacement information from the acceleration data and enhance suppression performance. The vibration suppression performance is compared using both displacement and acceleration measurements."}
{"id": "2511.07338", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07338", "abs": "https://arxiv.org/abs/2511.07338", "authors": ["Zhen Wang", "Yufan Zhou", "Zhongyan Luo", "Lyumanshan Ye", "Adam Wood", "Man Yao", "Luoshang Pan"], "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas", "comment": "12 pages, 5 figures, accepted at LAW 2025 Workshop (NeurIPS 2025)", "summary": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research."}
{"id": "2511.06091", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.06091", "abs": "https://arxiv.org/abs/2511.06091", "authors": ["Wenchao Dong", "Marcelo S. Locatelli", "Virgilio Almeida", "Meeyoung Cha"], "title": "Characterizing AI Manipulation Risks in Brazilian YouTube Climate Discourse", "comment": "Accepted to the Special Track on AI for Social Impact at AAAI 2026", "summary": "Climate change poses a global threat to public health, food security, and economic stability. Addressing it requires evidence-based policies and a nuanced understanding of how the threat is perceived by the public, particularly within visual social media, where narratives quickly evolve through voices of individuals, politicians, NGOs, and institutions. This study investigates climate-related discourse on YouTube within the Brazilian context, a geopolitically significant nation in global environmental negotiations. Through three case studies, we examine (1) which psychological content traits most effectively drive audience engagement, (2) the extent to which these traits influence content popularity, and (3) whether such insights can inform the design of persuasive synthetic campaigns--such as climate denialism--using recent generative language models. Another contribution of this work is the release of a large publicly available dataset of 226K Brazilian YouTube videos and 2.7M user comments on climate change. The dataset includes fine-grained annotations of persuasive strategies, theory-of-mind categorizations in user responses, and typologies of content creators. This resource can help support future research on digital climate communication and the ethical risk of algorithmically amplified narratives and generative media."}
{"id": "2511.07413", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07413", "abs": "https://arxiv.org/abs/2511.07413", "authors": ["Yuxuan Sun", "Manchen Wang", "Shengyi Qian", "William R. Wong", "Eric Gan", "Pierluca D'Oro", "Alejandro Castillejo Munoz", "Sneha Silwal", "Pedro Matias", "Nitin Kamra", "Satwik Kottur", "Nick Raines", "Xuanyi Zhao", "Joy Chen", "Joseph Greer", "Andrea Madotto", "Allen Bolourchi", "James Valori", "Kevin Carlberg", "Karl Ridgeway", "Joseph Tighe"], "title": "DigiData: Training and Evaluating General-Purpose Mobile Control Agents", "comment": "Website: https://facebookresearch.github.io/DigiData", "summary": "AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions."}
{"id": "2511.06102", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06102", "abs": "https://arxiv.org/abs/2511.06102", "authors": ["Mohammed Abboodi"], "title": "Development and testing of novel soft sleeve actuators", "comment": "PhD thesis", "summary": "Aging populations and the rising prevalence of neurological and musculoskeletal disorders increase the demand for wearable mobility assistive devices that are effective, comfortable, and anatomically compatible. Many existing systems use rigid mechanisms and bulky interfaces that impede force transmission and reduce wearability. This study introduces a soft sleeve actuation architecture that conforms to the limb while transmitting forces and moments efficiently. We develop three soft sleeve actuators that produce linear, bending, and twisting motion, and an omnidirectional design that combines these motions in one device. Actuators are fabricated from thermoplastic elastomers using a customized fused filament fabrication process that produces airtight and compliant structures and resolves leakage observed with conventional methods. A dedicated experimental platform quantifies kinematic outputs such as displacement, angle, and twist, and kinetic outputs such as force and torque under low pneumatic pressures. A parametric study varies geometric features and material properties to determine their influence on performance. Results show reproducible multi axis motion with improved transfer of force to the limb and reduced need for complex attachment hardware. The work establishes a unified and manufacturable framework for soft sleeve actuation that enables compact and user centered assistive technologies with enhanced kinematic and kinetic performance."}
{"id": "2511.05508", "categories": ["q-fin.GN", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.05508", "abs": "https://arxiv.org/abs/2511.05508", "authors": ["Tianyi Zhang", "Mu Chen"], "title": "Personalized Chain-of-Thought Summarization of Financial News for Investor Decision Support", "comment": "ICDM SENTIRE 2025", "summary": "Financial advisors and investors struggle with information overload from financial news, where irrelevant content and noise obscure key market signals and hinder timely investment decisions. To address this, we propose a novel Chain-of-Thought (CoT) summarization framework that condenses financial news into concise, event-driven summaries. The framework integrates user-specified keywords to generate personalized outputs, ensuring that only the most relevant contexts are highlighted. These personalized summaries provide an intermediate layer that supports language models in producing investor-focused narratives, bridging the gap between raw news and actionable insights."}
{"id": "2511.06131", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06131", "abs": "https://arxiv.org/abs/2511.06131", "authors": ["Luca Ambrosino", "Khai Manh Nguyen", "Minh Binh Vu", "Riadh Zorgati", "Laurent El Ghaoui", "Giuseppe C. Calafiore"], "title": "A Multi-Criterion Approach to Smart EV Charging with CO2 Emissions and Cost Minimization", "comment": "Paper submitted to the 24th European Control Conference (ECC2026) in Reykjavík, Iceland", "summary": "In this work, we propose a novel three-step framework for smart electric vehicle (EV) charging that jointly minimizes charging costs and CO2 emissions. Drawing inspiration from the classical Unit Commitment Problem (UCP), we first design a linear model to determine the optimal power generation mix over a 24-hour horizon, using real-world data from Vietnam, a country with a highly carbon intensive energy system. This allows us to estimate time-varying CO2 emissions and translate them into an emission cost signal. We then incorporate this environmental cost into a smart charging optimization model, formulated as a linear program (LP). Numerical simulations confirm that the proposed strategy significantly outperforms a baseline First-In-First-Served (FIFS) approach, achieving notable reductions in both CO2 emissions and charging costs also compared to another optimization approach. The results demonstrate the potential of this multiobjective optimization framework to support more sustainable and cost-efficient EV charging strategies."}
{"id": "2511.05511", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05511", "abs": "https://arxiv.org/abs/2511.05511", "authors": ["Janet", "Lin", "Liangwei Zhang"], "title": "From Failure Modes to Reliability Awareness in Generative and Agentic AI System", "comment": "24pages", "summary": "This chapter bridges technical analysis and organizational preparedness by tracing the path from layered failure modes to reliability awareness in generative and agentic AI systems. We first introduce an 11-layer failure stack, a structured framework for identifying vulnerabilities ranging from hardware and power foundations to adaptive learning and agentic reasoning. Building on this, the chapter demonstrates how failures rarely occur in isolation but propagate across layers, creating cascading effects with systemic consequences. To complement this diagnostic lens, we develop the concept of awareness mapping: a maturity-oriented framework that quantifies how well individuals and organizations recognize reliability risks across the AI stack. Awareness is treated not only as a diagnostic score but also as a strategic input for AI governance, guiding improvement and resilience planning. By linking layered failures to awareness levels and further integrating this into Dependability-Centred Asset Management (DCAM), the chapter positions awareness mapping as both a measurement tool and a roadmap for trustworthy and sustainable AI deployment across mission-critical domains."}
{"id": "2511.06134", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.06134", "abs": "https://arxiv.org/abs/2511.06134", "authors": ["Wei Yang", "Jiacheng Pang", "Shixuan Li", "Paul Bogdan", "Stephen Tu", "Jesse Thomason"], "title": "Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs", "comment": null, "summary": "Multi-agent systems (MAS) built on Large Language Models (LLMs) are being used to approach complex problems and can surpass single model inference. However, their success hinges on navigating a fundamental cognitive tension: the need to balance broad, divergent exploration of the solution space with a principled, convergent synthesis to the optimal solution. Existing paradigms often struggle to manage this duality, leading to premature consensus, error propagation, and a critical credit assignment problem that fails to distinguish between genuine reasoning and superficially plausible arguments. To resolve this core challenge, we propose the Multi-Agent Exploration-Synthesis framework Through Role Orchestration (Maestro), a principled paradigm for collaboration that structurally decouples these cognitive modes. Maestro uses a collective of parallel Execution Agents for diverse exploration and a specialized Central Agent for convergent, evaluative synthesis. To operationalize this critical synthesis phase, we introduce Conditional Listwise Policy Optimization (CLPO), a reinforcement learning objective that disentangles signals for strategic decisions and tactical rationales. By combining decision-focused policy gradients with a list-wise ranking loss over justifications, CLPO achieves clean credit assignment and stronger comparative supervision. Experiments on mathematical reasoning and general problem-solving benchmarks demonstrate that Maestro, coupled with CLPO, consistently outperforms existing state-of-the-art multi-agent approaches, delivering absolute accuracy gains of 6% on average and up to 10% at best."}
{"id": "2511.05613", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05613", "abs": "https://arxiv.org/abs/2511.05613", "authors": ["Anka Reuel", "Avijit Ghosh", "Jenny Chim", "Andrew Tran", "Yanan Long", "Jennifer Mickel", "Usman Gohar", "Srishti Yadav", "Pawan Sasanka Ammanamanchi", "Mowafak Allaham", "Hossein A. Rahmani", "Mubashara Akhtar", "Felix Friedrich", "Robert Scholz", "Michael Alexander Riegler", "Jan Batzner", "Eliya Habba", "Arushi Saxena", "Anastassia Kornilova", "Kevin Wei", "Prajna Soni", "Yohan Mathew", "Kevin Klyman", "Jeba Sania", "Subramanyam Sahoo", "Olivia Beyer Bruvik", "Pouya Sadeghi", "Sujata Goswami", "Angelina Wang", "Yacine Jernite", "Zeerak Talat", "Stella Biderman", "Mykel Kochenderfer", "Sanmi Koyejo", "Irene Solaiman"], "title": "Who Evaluates AI's Social Impacts? Mapping Coverage and Gaps in First and Third Party Evaluations", "comment": null, "summary": "Foundation models are increasingly central to high-stakes AI systems, and governance frameworks now depend on evaluations to assess their risks and capabilities. Although general capability evaluations are widespread, social impact assessments covering bias, fairness, privacy, environmental costs, and labor practices remain uneven across the AI ecosystem. To characterize this landscape, we conduct the first comprehensive analysis of both first-party and third-party social impact evaluation reporting across a wide range of model developers. Our study examines 186 first-party release reports and 183 post-release evaluation sources, and complements this quantitative analysis with interviews of model developers. We find a clear division of evaluation labor: first-party reporting is sparse, often superficial, and has declined over time in key areas such as environmental impact and bias, while third-party evaluators including academic researchers, nonprofits, and independent organizations provide broader and more rigorous coverage of bias, harmful content, and performance disparities. However, this complementarity has limits. Only model developers can authoritatively report on data provenance, content moderation labor, financial costs, and training infrastructure, yet interviews reveal that these disclosures are often deprioritized unless tied to product adoption or regulatory compliance. Our findings indicate that current evaluation practices leave major gaps in assessing AI's societal impacts, highlighting the urgent need for policies that promote developer transparency, strengthen independent evaluation ecosystems, and create shared infrastructure to aggregate and compare third-party evaluations in a consistent and accessible way."}
{"id": "2511.06136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06136", "abs": "https://arxiv.org/abs/2511.06136", "authors": ["Stefano Ferraro", "Akihiro Nakano", "Masahiro Suzuki", "Yutaka Matsuo"], "title": "When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks", "comment": null, "summary": "Object-centric world models (OCWM) aim to decompose visual scenes into object-level representations, providing structured abstractions that could improve compositional generalization and data efficiency in reinforcement learning. We hypothesize that explicitly disentangled object-level representations, by localizing task-relevant information, can enhance policy performance across novel feature combinations. To test this hypothesis, we introduce DLPWM, a fully unsupervised, disentangled object-centric world model that learns object-level latents directly from pixels. DLPWM achieves strong reconstruction and prediction performance, including robustness to several out-of-distribution (OOD) visual variations. However, when used for downstream model-based control, policies trained on DLPWM latents underperform compared to DreamerV3. Through latent-trajectory analyses, we identify representation shift during multi-object interactions as a key driver of unstable policy learning. Our results suggest that, although object-centric perception supports robust visual modeling, achieving stable control requires mitigating latent drift."}
{"id": "2511.05625", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05625", "abs": "https://arxiv.org/abs/2511.05625", "authors": ["Thomas J McKenna", "Ingvill Rasmussen", "Sten Ludvigsen", "Avivit Arvatz", "Christa Asterhan", "Gaowei Chen", "Julie Cohen", "Michele Flammia", "Dongkeun Han", "Emma Hayward", "Heather Hill", "Yifat Kolikant", "Helen Lehndorf", "Kexin Li", "Lindsay Clare Matsumura", "Henrik Tjønn", "Pengjin Wang", "Rupert Wegerif"], "title": "Report from Workshop on Dialogue alongside Artificial Intelligence", "comment": "Report from the Workshop on Dialogue alongside Artificial Intelligence (2025)", "summary": "Educational dialogue -the collaborative exchange of ideas through talk- is widely recognized as a catalyst for deeper learning and critical thinking in and across contexts. At the same time, artificial intelligence (AI) has rapidly emerged as a powerful force in education, with the potential to address major challenges, personalize learning, and innovate teaching practices. However, these advances come with significant risks: rapid AI development can undermine human agency, exacerbate inequities, and outpace our capacity to guide its use with sound policy. Human learning presupposes cognitive efforts and social interaction (dialogues). In response to this evolving landscape, an international workshop titled \"Educational Dialogue: Moving Thinking Forward\" convened 19 leading researchers from 11 countries in Cambridge (September 1-3, 2025) to examine the intersection of AI and educational dialogue. This AI-focused strand of the workshop centered on three critical questions: (1) When is AI truly useful in education, and when might it merely replace human effort at the expense of learning? (2) Under what conditions can AI use lead to better dialogic teaching and learning? (3) Does the AI-human partnership risk outpacing and displacing human educational work, and what are the implications? These questions framed two days of presentations and structured dialogue among participants."}
{"id": "2511.06141", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06141", "abs": "https://arxiv.org/abs/2511.06141", "authors": ["Marc Duclusaud", "Grégoire Passault", "Vincent Padois", "Olivier Ly"], "title": "PlaCo: a QP-based robot planning and control framework", "comment": null, "summary": "This article introduces PlaCo, a software framework designed to simplify the formulation and solution of Quadratic Programming (QP)-based planning and control problems for robotic systems. PlaCo provides a high-level interface that abstracts away the low-level mathematical formulation of QP problems, allowing users to specify tasks and constraints in a modular and intuitive manner. The framework supports both Python bindings for rapid prototyping and a C++ implementation for real-time performance."}
{"id": "2511.05627", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05627", "abs": "https://arxiv.org/abs/2511.05627", "authors": ["Sabik Aftahee", "A. F. M. Farhad", "Arpita Mallik", "Ratnajit Dhar", "Jawadul Karim", "Nahiyan Bin Noor", "Ishmam Ahmed Solaiman"], "title": "Assessing the Reliability of Large Language Models in the Bengali Legal Context: A Comparative Evaluation Using LLM-as-Judge and Legal Experts", "comment": null, "summary": "Accessing legal help in Bangladesh is hard. People face high fees, complex legal language, a shortage of lawyers, and millions of unresolved court cases. Generative AI models like OpenAI GPT-4.1 Mini, Gemini 2.0 Flash, Meta Llama 3 70B, and DeepSeek R1 could potentially democratize legal assistance by providing quick and affordable legal advice. In this study, we collected 250 authentic legal questions from the Facebook group \"Know Your Rights,\" where verified legal experts regularly provide authoritative answers. These questions were subsequently submitted to four four advanced AI models and responses were generated using a consistent, standardized prompt. A comprehensive dual evaluation framework was employed, in which a state-of-the-art LLM model served as a judge, assessing each AI-generated response across four critical dimensions: factual accuracy, legal appropriateness, completeness, and clarity. Following this, the same set of questions was evaluated by three licensed Bangladeshi legal professionals according to the same criteria. In addition, automated evaluation metrics, including BLEU scores, were applied to assess response similarity. Our findings reveal a complex landscape where AI models frequently generate high-quality, well-structured legal responses but also produce dangerous misinformation, including fabricated case citations, incorrect legal procedures, and potentially harmful advice. These results underscore the critical need for rigorous expert validation and comprehensive safeguards before AI systems can be safely deployed for legal consultation in Bangladesh."}
{"id": "2511.06142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06142", "abs": "https://arxiv.org/abs/2511.06142", "authors": ["Sizhe Tang", "Jiayu Chen", "Tian Lan"], "title": "MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning", "comment": null, "summary": "Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for Trees (UCTs) to balance exploration and exploitation through randomized sampling, is instrumental to solving complex planning problems. However, for multi-agent planning, MCTS is confronted with a large combinatorial action space that often grows exponentially with the number of agents. As a result, the branching factor of MCTS during tree expansion also increases exponentially, making it very difficult to efficiently explore and exploit during tree search. To this end, we propose MALinZero, a new approach to leverage low-dimensional representational structures on joint-action returns and enable efficient MCTS in complex multi-agent planning. Our solution can be viewed as projecting the joint-action returns into the low-dimensional space representable using a contextual linear bandit problem formulation. We solve the contextual linear bandit problem with convex and $μ$-smooth loss functions -- in order to place more importance on better joint actions and mitigate potential representational limitations -- and derive a linear Upper Confidence Bound applied to trees (LinUCT) to enable novel multi-agent exploration and exploitation in the low-dimensional space. We analyze the regret of MALinZero for low-dimensional reward functions and propose an $(1-\\tfrac1e)$-approximation algorithm for the joint action selection by maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2, outperforming both model-based and model-free multi-agent reinforcement learning baselines with faster learning speed and better performance."}
{"id": "2511.05791", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05791", "abs": "https://arxiv.org/abs/2511.05791", "authors": ["Manav Kulshrestha", "S. Talha Bukhari", "Damon Conover", "Aniket Bera"], "title": "VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models", "comment": "8 pages, 4 figures, under review", "summary": "Robotic grasping is a fundamental capability for autonomous manipulation; however, most existing methods rely on large-scale expert annotations and necessitate retraining to handle new objects. We present VLAD-Grasp, a Vision-Language model Assisted zero-shot approach for Detecting grasps. From a single RGB-D image, our method (1) prompts a large vision-language model to generate a goal image where a straight rod \"impales\" the object, representing an antipodal grasp, (2) predicts depth and segmentation to lift this generated image into 3D, and (3) aligns generated and observed object point clouds via principal component analysis and correspondence-free optimization to recover an executable grasp pose. Unlike prior work, our approach is training-free and does not rely on curated grasp datasets. Despite this, VLAD-Grasp achieves performance that is competitive with or superior to that of state-of-the-art supervised models on the Cornell and Jacquard datasets. We further demonstrate zero-shot generalization to novel real-world objects on a Franka Research 3 robot, highlighting vision-language foundation models as powerful priors for robotic manipulation."}
{"id": "2511.06148", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06148", "abs": "https://arxiv.org/abs/2511.06148", "authors": ["Addison J. Wu", "Ryan Liu", "Xuechunzi Bai", "Thomas L. Griffiths"], "title": "Large Language Models Develop Novel Social Biases Through Adaptive Exploration", "comment": null, "summary": "As large language models (LLMs) are adopted into frameworks that grant them the capacity to make real decisions, it is increasingly important to ensure that they are unbiased. In this paper, we argue that the predominant approach of simply removing existing biases from models is not enough. Using a paradigm from the psychology literature, we demonstrate that LLMs can spontaneously develop novel social biases about artificial demographic groups even when no inherent differences exist. These biases result in highly stratified task allocations, which are less fair than assignments by human participants and are exacerbated by newer and larger models. In social science, emergent biases like these have been shown to result from exploration-exploitation trade-offs, where the decision-maker explores too little, allowing early observations to strongly influence impressions about entire demographic groups. To alleviate this effect, we examine a series of interventions targeting model inputs, problem structure, and explicit steering. We find that explicitly incentivizing exploration most robustly reduces stratification, highlighting the need for better multifaceted objectives to mitigate bias. These results reveal that LLMs are not merely passive mirrors of human social biases, but can actively create new ones from experience, raising urgent questions about how these systems will shape societies over time."}
{"id": "2511.05822", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05822", "abs": "https://arxiv.org/abs/2511.05822", "authors": ["Sayak Mukherjee", "Ramij R. Hossain", "Kaustav Chatterjee", "Sameer Nekkalapu", "Marcelo Elizondo"], "title": "Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions", "comment": "10 pages, 7 figures", "summary": "This paper explores the development of learning-based tunable control gains using EMT-in-the-loop simulation framework (e.g., PSCAD interfaced with Python-based learning modules) to address critical sub-synchronous oscillations. Since sub-synchronous control interactions (SSCI) arise from the mis-tuning of control gains under specific grid configurations, effective mitigation strategies require adaptive re-tuning of these gains. Such adaptiveness can be achieved by employing a closed-loop, learning-based framework that considers the grid conditions responsible for such sub-synchronous oscillations. This paper addresses this need by adopting methodologies inspired by Markov decision process (MDP) based reinforcement learning (RL), with a particular emphasis on simpler deep policy gradient methods with additional SSCI-specific signal processing modules such as down-sampling, bandpass filtering, and oscillation energy dependent reward computations. Our experimentation in a real-world event setting demonstrates that the deep policy gradient based trained policy can adaptively compute gain settings in response to varying grid conditions and optimally suppress control interaction-induced oscillations."}
{"id": "2511.06160", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06160", "abs": "https://arxiv.org/abs/2511.06160", "authors": ["Fatima Jahara", "Mark Dredze", "Sharon Levy"], "title": "Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles", "comment": "24 pages (including appendix)", "summary": "While recent safety guardrails effectively suppress overtly biased outputs, subtler forms of social bias emerge during complex logical reasoning tasks that evade current evaluation benchmarks. To fill this gap, we introduce a new evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model Evaluation), that uses logic grid puzzles to systematically probe the influence of social stereotypes on logical reasoning and decision making in LLMs. Our use of logic puzzles enables automatic generation and verification, as well as variability in complexity and biased settings. PRIME includes stereotypical, anti-stereotypical, and neutral puzzle variants generated from a shared puzzle structure, allowing for controlled and fine-grained comparisons. We evaluate multiple model families across puzzle sizes and test the effectiveness of prompt-based mitigation strategies. Focusing our experiments on gender stereotypes, our findings highlight that models consistently reason more accurately when solutions align with stereotypical associations. This demonstrates the significance of PRIME for diagnosing and quantifying social biases perpetuated in the deductive reasoning of LLMs, where fairness is critical."}
{"id": "2511.05903", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05903", "abs": "https://arxiv.org/abs/2511.05903", "authors": ["Zhengyuan Liu", "Stella Xin Yin", "Bryan Chen Zhengyu Tan", "Roy Ka-Wei Lee", "Guimei Liu", "Dion Hoe-Lian Goh", "Wenya Wang", "Nancy F. Chen"], "title": "The Imperfect Learner: Incorporating Developmental Trajectories in Memory-based Student Simulation", "comment": null, "summary": "User simulation is important for developing and evaluating human-centered AI, yet current student simulation in educational applications has significant limitations. Existing approaches focus on single learning experiences and do not account for students' gradual knowledge construction and evolving skill sets. Moreover, large language models are optimized to produce direct and accurate responses, making it challenging to represent the incomplete understanding and developmental constraints that characterize real learners. In this paper, we introduce a novel framework for memory-based student simulation that incorporates developmental trajectories through a hierarchical memory mechanism with structured knowledge representation. The framework also integrates metacognitive processes and personality traits to enrich the individual learner profiling, through dynamical consolidation of both cognitive development and personal learning characteristics. In practice, we implement a curriculum-aligned simulator grounded on the Next Generation Science Standards. Experimental results show that our approach can effectively reflect the gradual nature of knowledge development and the characteristic difficulties students face, providing a more accurate representation of learning processes."}
{"id": "2511.06168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06168", "abs": "https://arxiv.org/abs/2511.06168", "authors": ["Boxuan Wang", "Zhuoyun Li", "Xinmiao Huang", "Xiaowei Huang", "Yi Dong"], "title": "Chasing Consistency: Quantifying and Optimizing Human-Model Alignment in Chain-of-Thought Reasoning", "comment": "13 pages, 3 figures", "summary": "This paper presents a framework for evaluating and optimizing reasoning consistency in Large Language Models (LLMs) via a new metric, the Alignment Score, which quantifies the semantic alignment between model-generated reasoning chains and human-written reference chains in Chain-of-Thought (CoT) reasoning. Empirically, we find that 2-hop reasoning chains achieve the highest Alignment Score. To explain this phenomenon, we define four key error types: logical disconnection, thematic shift, redundant reasoning, and causal reversal, and show how each contributes to the degradation of the Alignment Score. Building on this analysis, we further propose Semantic Consistency Optimization Sampling (SCOS), a method that samples and favors chains with minimal alignment errors, significantly improving Alignment Scores by an average of 29.84% with longer reasoning chains, such as in 3-hop tasks."}
{"id": "2511.05927", "categories": ["cs.CY", "cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.05927", "abs": "https://arxiv.org/abs/2511.05927", "authors": ["Mohammad Rashed Albous", "Melodena Stephens", "Odeh Rashed Al-Jayyousi"], "title": "Artificial intelligence and the Gulf Cooperation Council workforce adapting to the future of work", "comment": null, "summary": "The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation Council (GCC) raises a central question: are investments in compute infrastructure matched by an equally robust build-out of skills, incentives, and governance? Grounded in socio-technical systems (STS) theory, this mixed-methods study audits workforce preparedness across Kingdom of Saudi Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman. We combine term frequency--inverse document frequency (TF--IDF) analysis of six national AI strategies (NASs), an inventory of 47 publicly disclosed AI initiatives (January 2017--April 2025), paired case studies, the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data & Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix linking oil-revenue slack (technical capacity) to regulatory coherence (social alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI 0.58--0.83) exhibit joint social--technical design; country-level indices span 0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under our modeled conditions, regulatory convergence plausibly binds outcomes more than fiscal capacity: fragmented rules can offset high oil revenues, while harmonized standards help preserve progress under austerity. We also identify an emerging two-track talent system, research elites versus rapidly trained practitioners, that risks labor-market bifurcation without bridging mechanisms. By extending STS inquiry to oil-rich, state-led economies, the study refines theory and sets a research agenda focused on longitudinal coupling metrics, ethnographies of coordination, and outcome-based performance indicators."}
{"id": "2511.06175", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.06175", "abs": "https://arxiv.org/abs/2511.06175", "authors": ["Kaijie Xu", "Fandi Meng", "Clark Verbrugge", "Simon Lucas"], "title": "CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference", "comment": null, "summary": "In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary \"reasoning tool.\" Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs."}
{"id": "2511.05932", "categories": ["cs.CY", "cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2511.05932", "abs": "https://arxiv.org/abs/2511.05932", "authors": ["Mohammad Rashed Albous", "Bedour Alboloushi", "Arnaud Lacheret"], "title": "The Future of AI in the GCC Post-NPM Landscape: A Comparative Analysis of Kuwait and the UAE", "comment": null, "summary": "Comparative evidence on how Gulf Cooperation Council (GCC) states turn artificial intelligence (AI) ambitions into post--New Public Management (post-NPM) outcomes is scarce because most studies examine Western democracies. We analyze constitutional, collective-choice, and operational rules shaping AI uptake in two contrasting GCC members, the United Arab Emirates (UAE) and Kuwait, and whether they foster citizen centricity, collaborative governance, and public value creation. Anchored in Ostrom's Institutional Analysis and Development framework, the study combines a most similar/most different systems design with multiple sources: 62 public documents from 2018--2025, embedded UAE cases (Smart Dubai and MBZUAI), and 39 interviews with officials conducted Aug 2024--May 2025. Dual coding and process tracing connect rule configurations to AI performance. Cross-case analysis identifies four reinforcing mechanisms behind divergent trajectories. In the UAE, concentrated authority, credible sanctions, pro-innovation narratives, and flexible reinvestment rules scale pilots into hundreds of services and sizable recycled savings. In Kuwait, dispersed veto points, exhortative sanctions, cautious discourse, and lapsed AI budgets confine initiatives to pilot mode despite equivalent fiscal resources. The findings refine institutional theory by showing that vertical rule coherence, not wealth, determines AI's public-value yield, and temper post-NPM optimism by revealing that efficiency metrics serve societal goals only when backed by enforceable safeguards. To curb ethics washing and test transferability beyond the GCC, future work should track rule diffusion over time, develop blended legitimacy--efficiency scorecards, and examine how narrative framing shapes citizen consent for data sharing."}
{"id": "2511.06182", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06182", "abs": "https://arxiv.org/abs/2511.06182", "authors": ["Peican Lin", "Gan Sun", "Chenxi Liu", "Fazeng Li", "Weihong Ren", "Yang Cong"], "title": "OpenVLN: Open-world aerial Vision-Language Navigation", "comment": "Content: 8 pages 4 figures, conference under review", "summary": "Vision-language models (VLMs) have been widely-applied in ground-based vision-language navigation (VLN). However, the vast complexity of outdoor aerial environments compounds data acquisition challenges and imposes long-horizon trajectory planning requirements on Unmanned Aerial Vehicles (UAVs), introducing novel complexities for aerial VLN. To address these challenges, we propose a data-efficient Open-world aerial Vision-Language Navigation (i.e., OpenVLN) framework, which could execute language-guided flight with limited data constraints and enhance long-horizon trajectory planning capabilities in complex aerial environments. Specifically, we reconfigure a reinforcement learning framework to optimize the VLM for UAV navigation tasks, which can efficiently fine-tune VLM by using rule-based policies under limited training data. Concurrently, we introduce a long-horizon planner for trajectory synthesis that dynamically generates precise UAV actions via value-based rewards. To the end, we conduct sufficient navigation experiments on the TravelUAV benchmark with dataset scaling across diverse reward settings. Our method demonstrates consistent performance gains of up to 4.34% in Success Rate, 6.19% in Oracle Success Rate, and 4.07% in Success weighted by Path Length over baseline methods, validating its deployment efficacy for long-horizon UAV navigation in complex aerial environments."}
{"id": "2511.05936", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05936", "abs": "https://arxiv.org/abs/2511.05936", "authors": ["Soujanya Poria", "Navonil Majumder", "Chia-Yu Hung", "Amir Ali Bagherzadeh", "Chuan Li", "Kenneth Kwok", "Ziwei Wang", "Cheston Tan", "Jiajun Wu", "David Hsu"], "title": "10 Open Challenges Steering the Future of Vision-Language-Action Models", "comment": "AAAI 2026 (Senior Track)", "summary": "Due to their ability of follow natural language instructions, vision-language-action (VLA) models are increasingly prevalent in the embodied AI arena, following the widespread success of their precursors -- LLMs and VLMs. In this paper, we discuss 10 principal milestones in the ongoing development of VLA models -- multimodality, reasoning, data, evaluation, cross-robot action generalization, efficiency, whole-body coordination, safety, agents, and coordination with humans. Furthermore, we discuss the emerging trends of using spatial understanding, modeling world dynamics, post training, and data synthesis -- all aiming to reach these milestones. Through these discussions, we hope to bring attention to the research avenues that may accelerate the development of VLA models into wider acceptability."}
{"id": "2511.06185", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06185", "abs": "https://arxiv.org/abs/2511.06185", "authors": ["Xinyuan Wang", "Yanjie Fu"], "title": "Dataforge: A Data Agent Platform for Autonomous Data Engineering", "comment": null, "summary": "The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed \"From Data to Better Data.\""}
{"id": "2511.06078", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06078", "abs": "https://arxiv.org/abs/2511.06078", "authors": ["Luis Marquez-Carpintero", "Alberto Lopez-Sellers", "Miguel Cazorla"], "title": "Simulating Students with Large Language Models: A Review of Architecture, Mechanisms, and Role Modelling in Education with Generative AI", "comment": null, "summary": "Simulated Students offer a valuable methodological framework for evaluating pedagogical approaches and modelling diverse learner profiles, tasks which are otherwise challenging to undertake systematically in real-world settings. Recent research has increasingly focused on developing such simulated agents to capture a range of learning styles, cognitive development pathways, and social behaviours. Among contemporary simulation techniques, the integration of large language models (LLMs) into educational research has emerged as a particularly versatile and scalable paradigm. LLMs afford a high degree of linguistic realism and behavioural adaptability, enabling agents to approximate cognitive processes and engage in contextually appropriate pedagogical dialogues. This paper presents a thematic review of empirical and methodological studies utilising LLMs to simulate student behaviour across educational environments. We synthesise current evidence on the capacity of LLM-based agents to emulate learner archetypes, respond to instructional inputs, and interact within multi-agent classroom scenarios. Furthermore, we examine the implications of such systems for curriculum development, instructional evaluation, and teacher training. While LLMs surpass rule-based systems in natural language generation and situational flexibility, ongoing concerns persist regarding algorithmic bias, evaluation reliability, and alignment with educational objectives. The review identifies existing technological and methodological gaps and proposes future research directions for integrating generative AI into adaptive learning systems and instructional design."}
{"id": "2511.06191", "categories": ["cs.CY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.06191", "abs": "https://arxiv.org/abs/2511.06191", "authors": ["Soujanya Dash", "Kenjiro Ide", "Rikuhei Umemoto", "Kai Amino", "Keisuke Fujii"], "title": "Prediction-based evaluation of back-four defense with spatial control in soccer", "comment": "22 pages, 4 figures", "summary": "Defensive organization is critical in soccer, particularly during negative transitions when teams are most vulnerable. The back-four defensive line plays a decisive role in preventing goal-scoring opportunities, yet its collective coordination remains difficult to quantify. This study introduces interpretable spatio-temporal indicators namely, space control, stretch index, pressure index, and defensive line height (absolute and relative) to evaluate the effectiveness of the back-four during defensive transitions. Using synchronized tracking and event data from the 2023-24 LaLiga season, 2,413 defensive sequences were analyzed following possession losses by FC Barcelona and Real Madrid CF. Two-way ANOVA revealed significant effects of team, outcome, and their interaction for key indicators, with relative line height showing the strongest association with defensive success. Predictive modeling using XGBoost achieved the highest discriminative performance (ROC AUC: 0.724 for Barcelona, 0.698 for Real Madrid), identifying space score and relative line height as dominant predictors. Comparative analysis revealed distinct team-specific defensive behaviors: Barcelona's success was characterized by higher spatial control and compact line coordination, whereas Real Madrid exhibited more adaptive but less consistent defensive structures. These findings demonstrate the tactical and predictive value of interpretable spatial indicators for quantifying collective defensive performance."}
{"id": "2511.06148", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06148", "abs": "https://arxiv.org/abs/2511.06148", "authors": ["Addison J. Wu", "Ryan Liu", "Xuechunzi Bai", "Thomas L. Griffiths"], "title": "Large Language Models Develop Novel Social Biases Through Adaptive Exploration", "comment": null, "summary": "As large language models (LLMs) are adopted into frameworks that grant them the capacity to make real decisions, it is increasingly important to ensure that they are unbiased. In this paper, we argue that the predominant approach of simply removing existing biases from models is not enough. Using a paradigm from the psychology literature, we demonstrate that LLMs can spontaneously develop novel social biases about artificial demographic groups even when no inherent differences exist. These biases result in highly stratified task allocations, which are less fair than assignments by human participants and are exacerbated by newer and larger models. In social science, emergent biases like these have been shown to result from exploration-exploitation trade-offs, where the decision-maker explores too little, allowing early observations to strongly influence impressions about entire demographic groups. To alleviate this effect, we examine a series of interventions targeting model inputs, problem structure, and explicit steering. We find that explicitly incentivizing exploration most robustly reduces stratification, highlighting the need for better multifaceted objectives to mitigate bias. These results reveal that LLMs are not merely passive mirrors of human social biases, but can actively create new ones from experience, raising urgent questions about how these systems will shape societies over time."}
{"id": "2511.06199", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06199", "abs": "https://arxiv.org/abs/2511.06199", "authors": ["Shiqi Liu", "Hang Song", "Bo Wei", "Nopphon Keerativoranan", "Jun-ichi Takada"], "title": "A Passive Software-Defined Radio-based mmWave Sensing System for Blind Integrated Communication and Sensing", "comment": null, "summary": "Integrated Sensing and Communication (ISAC) is considered as a key component of future 6G technologies, especially in the millimeter-wave (mmWave) bands. Recently, the performances of ISAC were experimentally evaluated and demonstrated in various scenarios by developing ISAC systems. These systems generally consist of coherent transmitting (Tx) and receiving (Rx) modules. However, actively transmitting radio waves for experiments is not easy due to regulatory restrictions of radio. Meanwhile, the Tx/Rx should be synchronized and Rx need the information of Tx. In this paper, a fully passive mmWave sensing system is developed with software-defined radio for blind ISAC. It only consists of a passive Rx module which does not depend on the Tx. Since the proposed system is not synchronized with Tx and has no knowledge of the transmitted signals, a differential structure with two oppositely-oriented receivers is introduced to realize the sensing function. This structure can mitigate the influences of unknown source signals and other distortions. With the proposed sensing system, the ambient mmWave communication signals are leveraged for sensing without interrupting the existing systems. It can be deployed for field applications such as signal detection and dynamic human activity recognition since it does not emit signals. The efficacy of the developed system is first verified with a metallic plate with known motion pattern. The measured Doppler spectrogram shows good agreement with the simulation results, demonstrating the correctness of the sensing results. Further, the system is evaluated in complex scenarios, including handwaving, single- and multi-person motion detection. The sensing results successfully reflect the corresponding motions, demonstrating that the proposed sensing system can be utilized for blind ISAC in various applications."}
{"id": "2511.06240", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06240", "abs": "https://arxiv.org/abs/2511.06240", "authors": ["Tzu-Jung Lin", "Jia-Fong Yeh", "Hung-Ting Su", "Chung-Yi Lin", "Yi-Ting Chen", "Winston H. Hsu"], "title": "Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation", "comment": "Accepted to AAAI 2026", "summary": "In open-vocabulary mobile manipulation (OVMM), task success often hinges on the selection of an appropriate base placement for the robot. Existing approaches typically navigate to proximity-based regions without considering affordances, resulting in frequent manipulation failures. We propose Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base placement that integrates semantic understanding from vision-language models (VLMs) with geometric feasibility through an iterative optimization process. Our method constructs cross-modal representations, namely Affordance RGB and Obstacle Map+, to align semantics with spatial context. This enables reasoning that extends beyond the egocentric limitations of RGB perception. To ensure interaction is guided by task-relevant affordances, we leverage coarse semantic priors from VLMs to guide the search toward task-relevant regions and refine placements with geometric constraints, thereby reducing the risk of convergence to local optima. Evaluated on five diverse open-vocabulary mobile manipulation tasks, our system achieves an 85% success rate, significantly outperforming classical geometric planners and VLM-based methods. This demonstrates the promise of affordance-aware and multimodal reasoning for generalizable, instruction-conditioned planning in OVMM."}
{"id": "2511.06202", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06202", "abs": "https://arxiv.org/abs/2511.06202", "authors": ["Shahram Najam Syed", "Yatharth Ahuja", "Arthur Jakobsson", "Jeff Ichnowski"], "title": "ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval", "comment": "10 pages, 5 figures, submitted to ICRA 2026. Equal contribution by first two authors", "summary": "Vision-Language-Action models such as OpenVLA show impressive zero-shot generalization across robotic manipulation tasks but often fail to adapt efficiently to new deployment environments. In many real-world applications, consistent high performance on a limited set of tasks is more important than broad generalization. We propose ExpReS-VLA, a method for specializing pre-trained VLA models through experience replay and retrieval while preventing catastrophic forgetting. ExpReS-VLA stores compact feature representations from the frozen vision backbone instead of raw image-action pairs, reducing memory usage by approximately 97 percent. During deployment, relevant past experiences are retrieved using cosine similarity and used to guide adaptation, while prioritized experience replay emphasizes successful trajectories. We also introduce Thresholded Hybrid Contrastive Loss, which enables learning from both successful and failed attempts. On the LIBERO simulation benchmark, ExpReS-VLA improves success rates from 82.6 to 93.1 percent on spatial reasoning tasks and from 61 to 72.3 percent on long-horizon tasks. On physical robot experiments with five manipulation tasks, it reaches 98 percent success on both seen and unseen settings, compared to 84.7 and 32 percent for naive fine-tuning. Adaptation takes 31 seconds using 12 demonstrations on a single RTX 5090 GPU, making the approach practical for real robot deployment."}
{"id": "2511.06496", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06496", "abs": "https://arxiv.org/abs/2511.06496", "authors": ["Keke Long", "Jiacheng Guo", "Tianyun Zhang", "Hongkai Yu", "Xiaopeng Li"], "title": "A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving", "comment": null, "summary": "Vision Language Models (VLMs) are increasingly used in autonomous driving to help understand traffic scenes, but they sometimes produce hallucinations, which are false details not grounded in the visual input. Detecting and mitigating hallucinations is challenging when ground-truth references are unavailable and model internals are inaccessible. This paper proposes a novel self-contained low-rank approach to automatically rank multiple candidate captions generated by multiple VLMs based on their hallucination levels, using only the captions themselves without requiring external references or model access. By constructing a sentence-embedding matrix and decomposing it into a low-rank consensus component and a sparse residual, we use the residual magnitude to rank captions: selecting the one with the smallest residual as the most hallucination-free. Experiments on the NuScenes dataset demonstrate that our approach achieves 87% selection accuracy in identifying hallucination-free captions, representing a 19% improvement over the unfiltered baseline and a 6-10% improvement over multi-agent debate method. The sorting produced by sparse error magnitudes shows strong correlation with human judgments of hallucinations, validating our scoring mechanism. Additionally, our method, which can be easily parallelized, reduces inference time by 51-67% compared to debate approaches, making it practical for real-time autonomous driving applications."}
{"id": "2511.06209", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06209", "abs": "https://arxiv.org/abs/2511.06209", "authors": ["Jingwei Ni", "Ekaterina Fadeeva", "Tianyi Wu", "Mubashara Akhtar", "Jiaheng Zhang", "Elliott Ash", "Markus Leippold", "Timothy Baldwin", "See-Kiong Ng", "Artem Shelmanov", "Mrinmaya Sachan"], "title": "Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads", "comment": "Preprint under review", "summary": "Solving complex tasks usually requires LLMs to generate long multi-step reasoning chains. Previous work has shown that verifying the correctness of individual reasoning steps can further improve the performance and efficiency of LLMs on such tasks and enhance solution interpretability. However, existing verification approaches, such as Process Reward Models (PRMs), are either computationally expensive, limited to specific domains, or require large-scale human or model-generated annotations. Thus, we propose a lightweight alternative for step-level reasoning verification based on data-driven uncertainty scores. We train transformer-based uncertainty quantification heads (UHeads) that use the internal states of a frozen LLM to estimate the uncertainty of its reasoning steps during generation. The approach is fully automatic: target labels are generated either by another larger LLM (e.g., DeepSeek R1) or in a self-supervised manner by the original model itself. UHeads are both effective and lightweight, containing less than 10M parameters. Across multiple domains, including mathematics, planning, and general knowledge question answering, they match or even surpass the performance of PRMs that are up to 810x larger. Our findings suggest that the internal states of LLMs encode their uncertainty and can serve as reliable signals for reasoning verification, offering a promising direction toward scalable and generalizable introspective LLMs."}
{"id": "2511.06575", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06575", "abs": "https://arxiv.org/abs/2511.06575", "authors": ["Jun Wang", "Yevgeniy Vorobeychik", "Yiannis Kantaros"], "title": "CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning", "comment": null, "summary": "Large Language Models (LLMs) have recently emerged as planners for language-instructed agents, generating sequences of actions to accomplish natural language tasks. However, their reliability remains a challenge, especially in long-horizon tasks, since they often produce overconfident yet wrong outputs. Conformal Prediction (CP) has been leveraged to address this issue by wrapping LLM outputs into prediction sets that contain the correct action with a user-defined confidence. When the prediction set is a singleton, the planner executes that action; otherwise, it requests help from a user. This has led to LLM-based planners that can ensure plan correctness with a user-defined probability. However, as LLMs are trained in an uncertainty-agnostic manner, without awareness of prediction sets, they tend to produce unnecessarily large sets, particularly at higher confidence levels, resulting in frequent human interventions limiting autonomous deployment. To address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first CP-aware finetuning framework for LLM-based planners that explicitly reduces prediction-set size and, in turn, the need for user interventions. We evaluate our approach on multiple language-instructed robot planning problems and show consistent improvements over uncertainty-aware and uncertainty-agnostic finetuning baselines in terms of prediction-set size, and help rates. Finally, we demonstrate robustness of our method to out-of-distribution scenarios in hardware experiments."}
{"id": "2511.06221", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06221", "abs": "https://arxiv.org/abs/2511.06221", "authors": ["Sen Xu", "Yi Zhou", "Wei Wang", "Jixin Min", "Zhibin Yin", "Yingwei Dai", "Shixi Liu", "Lianyu Pang", "Yirong Chen", "Junlin Zhang"], "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B", "comment": null, "summary": "Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research."}
{"id": "2511.06619", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06619", "abs": "https://arxiv.org/abs/2511.06619", "authors": ["Chuheng Zhang", "Rushuai Yang", "Xiaoyu Chen", "Kaixin Wang", "Li Zhao", "Yi Chen", "Jiang Bian"], "title": "How Do VLAs Effectively Inherit from VLMs?", "comment": null, "summary": "Vision-language-action (VLA) models hold the promise to attain generalizable embodied control. To achieve this, a pervasive paradigm is to leverage the rich vision-semantic priors of large vision-language models (VLMs). However, the fundamental question persists: How do VLAs effectively inherit the prior knowledge from VLMs? To address this critical question, we introduce a diagnostic benchmark, GrinningFace, an emoji tabletop manipulation task where the robot arm is asked to place objects onto printed emojis corresponding to language instructions. This task design is particularly revealing -- knowledge associated with emojis is ubiquitous in Internet-scale datasets used for VLM pre-training, yet emojis themselves are largely absent from standard robotics datasets. Consequently, they provide a clean proxy: successful task completion indicates effective transfer of VLM priors to embodied control. We implement this diagnostic task in both simulated environment and a real robot, and compare various promising techniques for knowledge transfer. Specifically, we investigate the effects of parameter-efficient fine-tuning, VLM freezing, co-training, predicting discretized actions, and predicting latent actions. Through systematic evaluation, our work not only demonstrates the critical importance of preserving VLM priors for the generalization of VLA but also establishes guidelines for future research in developing truly generalizable embodied AI systems."}
{"id": "2511.06223", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06223", "abs": "https://arxiv.org/abs/2511.06223", "authors": ["Heeseung Bang", "Andreas A. Malikopoulos"], "title": "Learning-Based Robust Bayesian Persuasion with Conformal Prediction Guarantees", "comment": "8 pages", "summary": "Classical Bayesian persuasion assumes that senders fully understand how receivers form beliefs and make decisions--an assumption that rarely holds when receivers possess private information or exhibit non-Bayesian behavior. In this paper, we develop a learning-based framework that integrates neural networks with conformal prediction to achieve robust persuasion under uncertainty about receiver belief formation. The proposed neural architecture learns end-to-end mappings from receiver observations and sender signals to action predictions, eliminating the need to identify belief mechanisms explicitly. Conformal prediction constructs finite-sample valid prediction sets with provable marginal coverage, enabling principled, distribution-free robust optimization. We establish exact coverage guarantees for the data-generating policy and derive bounds on coverage degradation under policy shifts. Furthermore, we provide neural network approximation and estimation error bounds, with sample complexity $O(d \\log(|\\mathcal{U}||\\mathcal{Y}||\\mathcal{S}|)/\\varepsilon^2)$, where $d$ denotes the effective network dimension, and finite-sample lower bounds on the sender's expected utility. Numerical experiments on smart-grid energy management illustrate the framework's robustness."}
{"id": "2511.06667", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06667", "abs": "https://arxiv.org/abs/2511.06667", "authors": ["Andrew Choi", "Dezhong Tong"], "title": "Rapidly Learning Soft Robot Control via Implicit Time-Stepping", "comment": "Code: https://github.com/QuantuMope/dismech-rl", "summary": "With the explosive growth of rigid-body simulators, policy learning in simulation has become the de facto standard for most rigid morphologies. In contrast, soft robotic simulation frameworks remain scarce and are seldom adopted by the soft robotics community. This gap stems partly from the lack of easy-to-use, general-purpose frameworks and partly from the high computational cost of accurately simulating continuum mechanics, which often renders policy learning infeasible. In this work, we demonstrate that rapid soft robot policy learning is indeed achievable via implicit time-stepping. Our simulator of choice, DisMech, is a general-purpose, fully implicit soft-body simulator capable of handling both soft dynamics and frictional contact. We further introduce delta natural curvature control, a method analogous to delta joint position control in rigid manipulators, providing an intuitive and effective means of enacting control for soft robot learning. To highlight the benefits of implicit time-stepping and delta curvature control, we conduct extensive comparisons across four diverse soft manipulator tasks against one of the most widely used soft-body frameworks, Elastica. With implicit time-stepping, parallel stepping of 500 environments achieves up to 6x faster speeds for non-contact cases and up to 40x faster for contact-rich scenarios. Finally, a comprehensive sim-to-sim gap evaluation--training policies in one simulator and evaluating them in another--demonstrates that implicit time-stepping provides a rare free lunch: dramatic speedups achieved without sacrificing accuracy."}
{"id": "2511.06226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06226", "abs": "https://arxiv.org/abs/2511.06226", "authors": ["Xingcheng Liu", "Yanchen Guan", "Haicheng Liao", "Zhengbing He", "Zhenning Li"], "title": "ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving", "comment": "Published to Accident Analysis and Prevention", "summary": "Accurate accident anticipation is essential for enhancing the safety of autonomous vehicles (AVs). However, existing methods often assume ideal conditions, overlooking challenges such as sensor failures, environmental disturbances, and data imperfections, which can significantly degrade prediction accuracy. Additionally, previous models have not adequately addressed the considerable variability in driver behavior and accident rates across different vehicle types. To overcome these limitations, this study introduces ROAR, a novel approach for accident detection and prediction. ROAR combines Discrete Wavelet Transform (DWT), a self adaptive object aware module, and dynamic focal loss to tackle these challenges. The DWT effectively extracts features from noisy and incomplete data, while the object aware module improves accident prediction by focusing on high-risk vehicles and modeling the spatial temporal relationships among traffic agents. Moreover, dynamic focal loss mitigates the impact of class imbalance between positive and negative samples. Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently outperforms existing baselines in key metrics such as Average Precision (AP) and mean Time to Accident (mTTA). These results demonstrate the model's robustness in real-world conditions, particularly in handling sensor degradation, environmental noise, and imbalanced data distributions. This work offers a promising solution for reliable and accurate accident anticipation in complex traffic environments."}
{"id": "2511.06700", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06700", "abs": "https://arxiv.org/abs/2511.06700", "authors": ["Damian Curran", "Vanessa Sporne", "Lea Frermann", "Jeannie Paterson"], "title": "Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries", "comment": null, "summary": "How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM-based chatbots varies depending on their location. However, obtaining meaningful comparative metrics is challenging because legal institutions in different places are not themselves easily comparable. In this work we propose a methodology to obtain place-to-place metrics based on the comparative law concept of functionalism. We construct a dataset of factual scenarios drawn from Reddit posts by users seeking legal advice for family, housing, employment, crime and traffic issues. We use these to elicit a summary of a law from the LLM relevant to each scenario in Los Angeles, London and Sydney. These summaries, typically of a legislative provision, are manually evaluated for hallucinations. We show that the rate of hallucination of legal information by leading closed-source LLMs is significantly associated with place. This suggests that the quality of legal solutions provided by these models is not evenly distributed across geography. Additionally, we show a strong negative correlation between hallucination rate and the frequency of the majority response when the LLM is sampled multiple times, suggesting a measure of uncertainty of model predictions of legal facts."}
{"id": "2511.06240", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06240", "abs": "https://arxiv.org/abs/2511.06240", "authors": ["Tzu-Jung Lin", "Jia-Fong Yeh", "Hung-Ting Su", "Chung-Yi Lin", "Yi-Ting Chen", "Winston H. Hsu"], "title": "Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation", "comment": "Accepted to AAAI 2026", "summary": "In open-vocabulary mobile manipulation (OVMM), task success often hinges on the selection of an appropriate base placement for the robot. Existing approaches typically navigate to proximity-based regions without considering affordances, resulting in frequent manipulation failures. We propose Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base placement that integrates semantic understanding from vision-language models (VLMs) with geometric feasibility through an iterative optimization process. Our method constructs cross-modal representations, namely Affordance RGB and Obstacle Map+, to align semantics with spatial context. This enables reasoning that extends beyond the egocentric limitations of RGB perception. To ensure interaction is guided by task-relevant affordances, we leverage coarse semantic priors from VLMs to guide the search toward task-relevant regions and refine placements with geometric constraints, thereby reducing the risk of convergence to local optima. Evaluated on five diverse open-vocabulary mobile manipulation tasks, our system achieves an 85% success rate, significantly outperforming classical geometric planners and VLM-based methods. This demonstrates the promise of affordance-aware and multimodal reasoning for generalizable, instruction-conditioned planning in OVMM."}
{"id": "2511.06745", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06745", "abs": "https://arxiv.org/abs/2511.06745", "authors": ["Lan Thi Ha Nguyen", "Kien Ton Manh", "Anh Do Duc", "Nam Pham Hai"], "title": "Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning", "comment": null, "summary": "Self-supervised goal-conditioned reinforcement learning enables robots to autonomously acquire diverse skills without human supervision. However, a central challenge is the goal setting problem: robots must propose feasible and diverse goals that are achievable in their current environment. Existing methods like RIG (Visual Reinforcement Learning with Imagined Goals) use variational autoencoder (VAE) to generate goals in a learned latent space but have the limitation of producing physically implausible goals that hinder learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates physical constraints directly into the VAE training process through a novel Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling the generation of physically consistent and achievable goals. Our key innovation is the explicit separation of the latent space into physics variables governing object dynamics and environmental factors capturing visual appearance, while enforcing physical consistency through differential equation constraints and conservation laws. This enables the generation of physically consistent and achievable goals that respect fundamental physical principles such as object permanence, collision constraints, and dynamic feasibility. Through extensive experiments, we demonstrate that this physics-informed goal generation significantly improves the quality of proposed goals, leading to more effective exploration and better skill acquisition in visual robotic manipulation tasks including reaching, pushing, and pick-and-place scenarios."}
{"id": "2511.06262", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06262", "abs": "https://arxiv.org/abs/2511.06262", "authors": ["Siming Zhao", "Qi Li"], "title": "GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening", "comment": null, "summary": "Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows."}
{"id": "2511.07410", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07410", "abs": "https://arxiv.org/abs/2511.07410", "authors": ["Hao Wang", "Sathwik Karnik", "Bea Lim", "Somil Bansal"], "title": "Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective", "comment": null, "summary": "Large Language Models (LLMs) and Vision Language Models (VLMs) have been widely used for embodied symbolic planning. Yet, how to effectively use these models for closed-loop symbolic planning remains largely unexplored. Because they operate as black boxes, LLMs and VLMs can produce unpredictable or costly errors, making their use in high-level robotic planning especially challenging. In this work, we investigate how to use VLMs as closed-loop symbolic planners for robotic applications from a control-theoretic perspective. Concretely, we study how the control horizon and warm-starting impact the performance of VLM symbolic planners. We design and conduct controlled experiments to gain insights that are broadly applicable to utilizing VLMs as closed-loop symbolic planners, and we discuss recommendations that can help improve the performance of VLM symbolic planners."}
{"id": "2511.06267", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06267", "abs": "https://arxiv.org/abs/2511.06267", "authors": ["Jiayi Chen", "Wei Zhao", "Liangwang Ruan", "Baoquan Chen", "He Wang"], "title": "Robust Differentiable Collision Detection for General Objects", "comment": null, "summary": "Collision detection is a core component of robotics applications such as simulation, control, and planning. Traditional algorithms like GJK+EPA compute witness points (i.e., the closest or deepest-penetration pairs between two objects) but are inherently non-differentiable, preventing gradient flow and limiting gradient-based optimization in contact-rich tasks such as grasping and manipulation. Recent work introduced efficient first-order randomized smoothing to make witness points differentiable; however, their direction-based formulation is restricted to convex objects and lacks robustness for complex geometries. In this work, we propose a robust and efficient differentiable collision detection framework that supports both convex and concave objects across diverse scales and configurations. Our method introduces distance-based first-order randomized smoothing, adaptive sampling, and equivalent gradient transport for robust and informative gradient computation. Experiments on complex meshes from DexGraspNet and Objaverse show significant improvements over existing baselines. Finally, we demonstrate a direct application of our method for dexterous grasp synthesis to refine the grasp quality. The code is available at https://github.com/JYChen18/DiffCollision."}
{"id": "2511.07416", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07416", "abs": "https://arxiv.org/abs/2511.07416", "authors": ["Jiageng Mao", "Sicheng He", "Hao-Ning Wu", "Yang You", "Shuyang Sun", "Zhicheng Wang", "Yanan Bao", "Huizhong Chen", "Leonidas Guibas", "Vitor Guizilini", "Howard Zhou", "Yue Wang"], "title": "Robot Learning from a Physical World Model", "comment": "Project page: https://pointscoder.github.io/PhysWorld_Web/", "summary": "We introduce PhysWorld, a framework that enables robot learning from video generation through physical world modeling. Recent video generation models can synthesize photorealistic visual demonstrations from language commands and images, offering a powerful yet underexplored source of training signals for robotics. However, directly retargeting pixel motions from generated videos to robots neglects physics, often resulting in inaccurate manipulations. PhysWorld addresses this limitation by coupling video generation with physical world reconstruction. Given a single image and a task command, our method generates task-conditioned videos and reconstructs the underlying physical world from the videos, and the generated video motions are grounded into physically accurate actions through object-centric residual reinforcement learning with the physical world model. This synergy transforms implicit visual guidance into physically executable robotic trajectories, eliminating the need for real robot data collection and enabling zero-shot generalizable robotic manipulation. Experiments on diverse real-world tasks demonstrate that PhysWorld substantially improves manipulation accuracy compared to previous approaches. Visit \\href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage} for details."}
{"id": "2511.06292", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06292", "abs": "https://arxiv.org/abs/2511.06292", "authors": ["Yaoning Yu", "Kaimin Chang", "Ye Yu", "Kai Wei", "Haojing Luo", "Haohan Wang"], "title": "Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents", "comment": null, "summary": "Financial documents like earning reports or balance sheets often involve long tables and multi-page reports. Large language models have become a new tool to help numerical reasoning and understanding these documents. However, prompt quality can have a major effect on how well LLMs perform these financial reasoning tasks. Most current methods tune prompts on fixed datasets of financial text or tabular data, which limits their ability to adapt to new question types or document structures, or they involve costly and manually labeled/curated dataset to help build the prompts. We introduce a self-improving prompt framework driven by data-augmented optimization. In this closed-loop process, we generate synthetic financial tables and document excerpts, verify their correctness and robustness, and then update the prompt based on the results. Specifically, our framework combines a synthetic data generator with verifiers and a prompt optimizer, where the generator produces new examples that exposes weaknesses in the current prompt, the verifiers check the validity and robustness of the produced examples, and the optimizer incrementally refines the prompt in response. By iterating these steps in a feedback cycle, our method steadily improves prompt accuracy on financial reasoning tasks without needing external labels. Evaluation on DocMath-Eval benchmark demonstrates that our system achieves higher performance in both accuracy and robustness than standard prompt methods, underscoring the value of incorporating synthetic data generation into prompt learning for financial applications."}
{"id": "2511.07418", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.DC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.07418", "abs": "https://arxiv.org/abs/2511.07418", "authors": ["Zhao-Heng Yin", "Pieter Abbeel"], "title": "Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields", "comment": "Code: https://github.com/zhaohengyin/lightning-grasp", "summary": "Despite years of research, real-time diverse grasp synthesis for dexterous hands remains an unsolved core challenge in robotics and computer graphics. We present Lightning Grasp, a novel high-performance procedural grasp synthesis algorithm that achieves orders-of-magnitude speedups over state-of-the-art approaches, while enabling unsupervised grasp generation for irregular, tool-like objects. The method avoids many limitations of prior approaches, such as the need for carefully tuned energy functions and sensitive initialization. This breakthrough is driven by a key insight: decoupling complex geometric computation from the search process via a simple, efficient data structure - the Contact Field. This abstraction collapses the problem complexity, enabling a procedural search at unprecedented speeds. We open-source our system to propel further innovation in robotic manipulation."}
{"id": "2511.06301", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06301", "abs": "https://arxiv.org/abs/2511.06301", "authors": ["Azanzi Jiomekong", "Jean Bikim", "Patricia Negoue", "Joyce Chin"], "title": "Secu-Table: a Comprehensive security table dataset for evaluating semantic table interpretation systems", "comment": "Submitted to Nature Scientific Data", "summary": "Evaluating semantic tables interpretation (STI) systems, (particularly, those based on Large Language Models- LLMs) especially in domain-specific contexts such as the security domain, depends heavily on the dataset. However, in the security domain, tabular datasets for state-of-the-art are not publicly available. In this paper, we introduce Secu-Table dataset, composed of more than 1500 tables with more than 15k entities constructed using security data extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES CSKG). Along with the dataset, all the code is publicly released. This dataset is made available to the research community in the context of the SemTab challenge on Tabular to Knowledge Graph Matching. This challenge aims to evaluate the performance of several STI based on open source LLMs. Preliminary evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source LLM."}
{"id": "2511.06306", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06306", "abs": "https://arxiv.org/abs/2511.06306", "authors": ["Yixuan Liu", "Yingzhu Liu", "Pengcheng You"], "title": "Coherency Analysis in Nonlinear Heterogeneous Power Networks: A Blended Dynamics Approach", "comment": null, "summary": "Power system coherency refers to the phenomenon that machines in a power network exhibit similar frequency responses after disturbances, and is foundational for model reduction and control design. Despite abundant empirical observations, the understanding of coherence in complex power networks remains incomplete where the dynamics could be highly heterogeneous, nonlinear, and increasingly affected by persistent disturbances such as renewable energy fluctuations. To bridge this gap, this paper extends the blended dynamics approach, originally rooted in consensus analysis of multi-agent systems, to develop a novel coherency analysis in power networks. We show that the frequency responses of coherent machines coupled by nonlinear power flow can be approximately represented by the blended dynamics, which is a weighted average of nonlinear heterogeneous nodal dynamics, even under time-varying disturbances. Specifically, by developing novel bounds on the difference between the trajectories of nodal dynamics and the blended dynamics, we identify two key factors -- either high network connectivity or small time-variation rate of disturbances -- that contribute to coherence. They enable the nodal frequencies to rapidly approach the blended-dynamics trajectory from arbitrary initial state. Furthermore, they ensure the frequencies closely follow this trajectory in the long term, even when the system does not settle to an equilibrium. These insights contribute to the understanding of power system coherency and are further supported by simulation results."}
{"id": "2511.06309", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.06309", "abs": "https://arxiv.org/abs/2511.06309", "authors": ["Stephen Chung", "Wenyu Du"], "title": "The Station: An Open-World Environment for AI-Driven Discovery", "comment": "54 pages", "summary": "We introduce the STATION, an open-world multi-agent environment that models a miniature scientific ecosystem. Leveraging their extended context windows, agents in the Station can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, submitting code, performing analyses, and publishing results. Importantly, there is no centralized system coordinating their activities - agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning from mathematics to computational biology to machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of narratives emerges as agents pursue independent research, interact with peers, and build upon a cumulative history. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid optimization."}
{"id": "2511.06311", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06311", "abs": "https://arxiv.org/abs/2511.06311", "authors": ["Seiichi Yamamoto", "Hiroki Ishizuka", "Takumi Kawasetsu", "Koh Hosoda", "Takayuki Kameoka", "Kango Yanagida", "Takato Horii", "Sei Ikeda", "Osamu Oshiro"], "title": "External Photoreflective Tactile Sensing Based on Surface Deformation Measurement", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We present a tactile sensing method enabled by the mechanical compliance of soft robots; an externally attachable photoreflective module reads surface deformation of silicone skin to estimate contact force without embedding tactile transducers. Locating the sensor off the contact interface reduces damage risk, preserves softness, and simplifies fabrication and maintenance. We first characterize the optical sensing element and the compliant skin, thendetermine the design of a prototype tactile sensor. Compression experiments validate the approach, exhibiting a monotonic force output relationship consistent with theory, low hysteresis, high repeatability over repeated cycles, and small response indentation speeds. We further demonstrate integration on a soft robotic gripper, where the module reliably detects grasp events. Compared with liquid filled or wireembedded tactile skins, the proposed modular add on architecture enhances durability, reduces wiring complexity, and supports straightforward deployment across diverse robot geometries. Because the sensing principle reads skin strain patterns, it also suggests extensions to other somatosensory cues such as joint angle or actuator state estimation from surface deformation. Overall, leveraging surface compliance with an external optical module provides a practical and robust route to equip soft robots with force perception while preserving structural flexibility and manufacturability, paving the way for robotic applications and safe human robot collaboration."}
{"id": "2511.06316", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06316", "abs": "https://arxiv.org/abs/2511.06316", "authors": ["MD Thamed Bin Zaman Chowdhury", "Moazzem Hossain"], "title": "ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning", "comment": null, "summary": "Reliable geospatial information on road accidents is vital for safety analysis and infrastructure planning, yet most low- and middle-income countries continue to face a critical shortage of accurate, location-specific crash data. Existing text-based geocoding tools perform poorly in multilingual and unstructured news environments, where incomplete place descriptions and mixed Bangla-English scripts obscure spatial context. To address these limitations, this study introduces ALIGN (Accident Location Inference through Geo-Spatial Neural Reasoning)- a vision-language framework that emulates human spatial reasoning to infer accident coordinates directly from textual and map-based cues. ALIGN integrates large language and vision-language models within a multi-stage pipeline that performs optical character recognition, linguistic reasoning, and map-level verification through grid-based spatial scanning. The framework systematically evaluates each predicted location against contextual and visual evidence, ensuring interpretable, fine-grained geolocation outcomes without requiring model retraining. Applied to Bangla-language news data, ALIGN demonstrates consistent improvements over traditional geoparsing methods, accurately identifying district and sub-district-level crash sites. Beyond its technical contribution, the framework establishes a high accuracy foundation for automated crash mapping in data-scarce regions, supporting evidence-driven road-safety policymaking and the broader integration of multimodal artificial intelligence in transportation analytics. The code for this paper is open-source and available at: https://github.com/Thamed-Chowdhury/ALIGN"}
{"id": "2511.06335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06335", "abs": "https://arxiv.org/abs/2511.06335", "authors": ["Ehsan Asadi", "Davood Keshavarzi", "Alexander Koehler", "Nima Tashakor", "Stefan Goetz"], "title": "Partial-Power Flow Controller, Voltage Regulator, and Energy Router for Hybrid AC-DC Grids", "comment": "10 pages, 42 figures", "summary": "The share of electronically converted power from renewable sources, loads, and storage is continuously growing in the low- and medium-voltage grids. These sources and loads typically rectify the grid AC to DC, e.g., for a DC link, so that a DC grid could eliminate hardware and losses of these conversion stages. However, extended DC grids lack the stabilizing nature of AC impedances so that the voltage is more fragile and power flows may need active control, particularly if redundancy as known from AC, such as rings and meshing, is desired. Furthermore, a DC infrastructure will not replace but will need to interface with the existing AC grid. This paper presents a partial-power energy router architecture that can interface multiple AC and DC lines to enable precise control of voltages and both active as well as reactive power flows. The proposed system uses modular low-voltage high-current series modules supplied through dual active bridges. These modules only need to process a small share of the voltage to control large power flows. The topology reduces component size, cost, energy losses, and reliability more than three times compared to conventional technology. The optional integration of battery energy storage can furthermore eliminate the need for the sum of the power flows of all inputs to be zero at all times. Through dynamic voltage injection relative to the line voltage, the modules effectively balance feeder currents, regulate reactive power, and improve the power factor in AC grids. Real-time hardware-in-the-loop and prototype measurements validate the proposed energy router's performance under diverse operating conditions. Experimental results confirm the series module's functionality in both AC and DC grids as an effective solution for controlling extended grids, including power sharing, voltage, and power quality."}
{"id": "2511.06346", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06346", "abs": "https://arxiv.org/abs/2511.06346", "authors": ["Liya Zhu", "Peizhuang Cong", "Aowei Ji", "Wenya Wu", "Jiani Hou", "Chunjie Wu", "Xiang Gao", "Jingkai Liu", "Zhou Huan", "Xuelei Sun", "Yang Yang", "Jianpeng Jiao", "Liang Hu", "Xinjie Chen", "Jiashuo Liu", "Jingzhe Ding", "Tong Yang", "Zaiyuan Wang", "Ge Zhang", "Wenhao Huang"], "title": "LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation", "comment": null, "summary": "Large Language Models (LLMs) have made rapid progress in reasoning, question answering, and professional applications; however, their true capabilities remain difficult to evaluate using existing benchmarks. Current datasets often focus on simplified tasks or artificial scenarios, overlooking long-tail knowledge and the complexities of real-world applications. To bridge this gap, we propose LPFQA, a long-tail knowledge-based benchmark derived from authentic professional forums across 20 academic and industrial fields, covering 502 tasks grounded in practical expertise. LPFQA introduces four key innovations: fine-grained evaluation dimensions that target knowledge depth, reasoning, terminology comprehension, and contextual analysis; a hierarchical difficulty structure that ensures semantic clarity and unique answers; authentic professional scenario modeling with realistic user personas; and interdisciplinary knowledge integration across diverse domains. We evaluated 12 mainstream LLMs on LPFQA and observed significant performance disparities, especially in specialized reasoning tasks. LPFQA provides a robust, authentic, and discriminative benchmark for advancing LLM evaluation and guiding future model development."}
{"id": "2511.06368", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06368", "abs": "https://arxiv.org/abs/2511.06368", "authors": ["Hideki Nishizawa", "Toru Mano", "Kazuya Anazawa", "Tatsuya Matsumura", "Takeo Sasai", "Masatoshi Namiki", "Dmitrii Briantcev", "Renato Ambrosone", "Esther Le Rouzic", "Stefan Melin", "Oscar Gonzalez-de-Dios", "Juan Pedro Fernandez-Palacios", "Xiaocheng Zhang", "Keigo Akahoshi", "Gert Grammel", "Andrea D'Amico", "Giacomo Borraccini", "Marco Ruffini", "Daniel Kilper", "Vittorio Curri"], "title": "Optical Network Digital Twin - Commercialization Barriers, Value Proposition, Early Use Cases, and Challenges", "comment": "7 pages, 5 figures", "summary": "With the widespread adoption of AI, machine-to-machine communications are rapidly increasing, reshaping the requirements for optical networks. Recent advances in Gaussian noise modeling for digital coherent transmission have raised expectations for digital-twin-based operation. However, unlike digital twins in wireless communication, which are already well established, significant barriers remain for commercialization in optical networks. This paper discusses the evolving requirements of optical networks in the AI era and proposes an Optical Network Digital Twin architecture that enables flexible end-to-end light path operation beyond conventional management. The value propositions of the proposed architecture, its evolutionary steps toward commercialization, and key research challenges for practical deployment are presented."}
{"id": "2511.06371", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06371", "abs": "https://arxiv.org/abs/2511.06371", "authors": ["Yingnan Zhao", "Xinmiao Wang", "Dewei Wang", "Xinzhe Liu", "Dan Lu", "Qilong Han", "Peng Liu", "Chenjia Bai"], "title": "Towards Adaptive Humanoid Control via Multi-Behavior Distillation and Reinforced Fine-Tuning", "comment": null, "summary": "Humanoid robots are promising to learn a diverse set of human-like locomotion behaviors, including standing up, walking, running, and jumping. However, existing methods predominantly require training independent policies for each skill, yielding behavior-specific controllers that exhibit limited generalization and brittle performance when deployed on irregular terrains and in diverse situations. To address this challenge, we propose Adaptive Humanoid Control (AHC) that adopts a two-stage framework to learn an adaptive humanoid locomotion controller across different skills and terrains. Specifically, we first train several primary locomotion policies and perform a multi-behavior distillation process to obtain a basic multi-behavior controller, facilitating adaptive behavior switching based on the environment. Then, we perform reinforced fine-tuning by collecting online feedback in performing adaptive behaviors on more diverse terrains, enhancing terrain adaptability for the controller. We conduct experiments in both simulation and real-world experiments in Unitree G1 robots. The results show that our method exhibits strong adaptability across various situations and terrains. Project website: https://ahc-humanoid.github.io."}
{"id": "2511.06378", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06378", "abs": "https://arxiv.org/abs/2511.06378", "authors": ["Prajval Kumar Murali", "Mohsen Kaboli"], "title": "ArtReg: Visuo-Tactile based Pose Tracking and Manipulation of Unseen Articulated Objects", "comment": "Under review", "summary": "Robots operating in real-world environments frequently encounter unknown objects with complex structures and articulated components, such as doors, drawers, cabinets, and tools. The ability to perceive, track, and manipulate these objects without prior knowledge of their geometry or kinematic properties remains a fundamental challenge in robotics. In this work, we present a novel method for visuo-tactile-based tracking of unseen objects (single, multiple, or articulated) during robotic interaction without assuming any prior knowledge regarding object shape or dynamics. Our novel pose tracking approach termed ArtReg (stands for Articulated Registration) integrates visuo-tactile point clouds in an unscented Kalman Filter formulation in the SE(3) Lie Group for point cloud registration. ArtReg is used to detect possible articulated joints in objects using purposeful manipulation maneuvers such as pushing or hold-pulling with a two-robot team. Furthermore, we leverage ArtReg to develop a closed-loop controller for goal-driven manipulation of articulated objects to move the object into the desired pose configuration. We have extensively evaluated our approach on various types of unknown objects through real robot experiments. We also demonstrate the robustness of our method by evaluating objects with varying center of mass, low-light conditions, and with challenging visual backgrounds. Furthermore, we benchmarked our approach on a standard dataset of articulated objects and demonstrated improved performance in terms of pose accuracy compared to state-of-the-art methods. Our experiments indicate that robust and accurate pose tracking leveraging visuo-tactile information enables robots to perceive and interact with unseen complex articulated objects (with revolute or prismatic joints)."}
{"id": "2511.06380", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06380", "abs": "https://arxiv.org/abs/2511.06380", "authors": ["Chen He", "Xun Jiang", "Lei Wang", "Hao Yang", "Chong Peng", "Peng Yan", "Fumin Shen", "Xing Xu"], "title": "What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as \"Echo Reflection\". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks."}
{"id": "2511.06385", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06385", "abs": "https://arxiv.org/abs/2511.06385", "authors": ["Ralf Römer", "Julian Balletshofer", "Jakob Thumm", "Marco Pavone", "Angela P. Schoellig", "Matthias Althoff"], "title": "From Demonstrations to Safe Deployment: Path-Consistent Safety Filtering for Diffusion Policies", "comment": "Project page: https://tum-lsy.github.io/pacs/. 8 pages, 4 figures", "summary": "Diffusion policies (DPs) achieve state-of-the-art performance on complex manipulation tasks by learning from large-scale demonstration datasets, often spanning multiple embodiments and environments. However, they cannot guarantee safe behavior, so external safety mechanisms are needed. These, however, alter actions in ways unseen during training, causing unpredictable behavior and performance degradation. To address these problems, we propose path-consistent safety filtering (PACS) for DPs. Our approach performs path-consistent braking on a trajectory computed from the sequence of generated actions. In this way, we keep execution consistent with the policy's training distribution, maintaining the learned, task-completing behavior. To enable a real-time deployment and handle uncertainties, we verify safety using set-based reachability analysis. Our experimental evaluation in simulation and on three challenging real-world human-robot interaction tasks shows that PACS (a) provides formal safety guarantees in dynamic environments, (b) preserves task success rates, and (c) outperforms reactive safety approaches, such as control barrier functions, by up to 68% in terms of task success. Videos are available at our project website: https://tum-lsy.github.io/pacs/."}
{"id": "2511.06396", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06396", "abs": "https://arxiv.org/abs/2511.06396", "authors": ["Dachuan Lin", "Guobin Shen", "Zihao Yang", "Tianrong Liu", "Dongcheng Zhao", "Yi Zeng"], "title": "Efficient LLM Safety Evaluation through Multi-Agent Debate", "comment": "9 pages of main text, 14 pages total, 4 figures", "summary": "Safety evaluation of large language models (LLMs) increasingly relies on LLM-as-a-Judge frameworks, but the high cost of frontier models limits scalability. We propose a cost-efficient multi-agent judging framework that employs Small Language Models (SLMs) through structured debates among critic, defender, and judge agents. To rigorously assess safety judgments, we construct HAJailBench, a large-scale human-annotated jailbreak benchmark comprising 12,000 adversarial interactions across diverse attack methods and target models. The dataset provides fine-grained, expert-labeled ground truth for evaluating both safety robustness and judge reliability. Our SLM-based framework achieves agreement comparable to GPT-4o judges on HAJailBench while substantially reducing inference cost. Ablation results show that three rounds of debate yield the optimal balance between accuracy and efficiency. These findings demonstrate that structured, value-aligned debate enables SLMs to capture semantic nuances of jailbreak attacks and that HAJailBench offers a reliable foundation for scalable LLM safety evaluation."}
{"id": "2511.06397", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06397", "abs": "https://arxiv.org/abs/2511.06397", "authors": ["Cong Wen", "Yunfei Li", "Kexin Liu", "Yixin Qiu", "Xuanhong Liao", "Tianyu Wang", "Dingchuan Liu", "Tao Zhang", "Ximin Lyu"], "title": "Whole-Body Control With Terrain Estimation of A 6-DoF Wheeled Bipedal Robot", "comment": "8 pages, 8 figures", "summary": "Wheeled bipedal robots have garnered increasing attention in exploration and inspection. However, most research simplifies calculations by ignoring leg dynamics, thereby restricting the robot's full motion potential. Additionally, robots face challenges when traversing uneven terrain. To address the aforementioned issue, we develop a complete dynamics model and design a whole-body control framework with terrain estimation for a novel 6 degrees of freedom wheeled bipedal robot. This model incorporates the closed-loop dynamics of the robot and a ground contact model based on the estimated ground normal vector. We use a LiDAR inertial odometry framework and improved Principal Component Analysis for terrain estimation. Task controllers, including PD control law and LQR, are employed for pose control and centroidal dynamics-based balance control, respectively. Furthermore, a hierarchical optimization approach is used to solve the whole-body control problem. We validate the performance of the terrain estimation algorithm and demonstrate the algorithm's robustness and ability to traverse uneven terrain through both simulation and real-world experiments."}
{"id": "2511.06398", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06398", "abs": "https://arxiv.org/abs/2511.06398", "authors": ["Leloko J. Lepolesa", "Kayode E. Adetunji", "Khmaies Ouahada", "Zhenqing Liu", "Ling Cheng"], "title": "Dynamic Electric Vehicle Charging Pricing for Load Balancing in Power Distribution Networks based on Collaborative DDPG Agents", "comment": "12 pages, In the second round of review at IEEE Transactions on Smart Grid", "summary": "The transition from the Internal Combustion Engine Vehicles (ICEVs) to the Electric Vehicles (EVs) is globally recommended to combat the unfavourable environmental conditions caused by reliance on fossil fuels. However, it has been established that the charging of EVs can destabilize the grid when they penetrate the market in large numbers, especially in grids that were not initially built to handle the load from the charging of EVs. In this work, we present a dynamic EV charging pricing strategy that fulfills the following three objectives: distribution network-level load peak-shaving, valley-filling, and load balancing across distribution networks. Based on historical environmental variables such as temperature, humidity, wind speed, EV charging prices and distribution of vehicles in different areas in different times of the day, we first forecast the distribution network load demand, and then use deep reinforcement learning approach to set the optimal dynamic EV charging price. While most research seeks to achieve load peak-shaving and valley-filling to stabilize the grid, our work goes further into exploring the load-balancing between the distribution networks in the close vicinity to each other. We compare the performance of Deep Deterministic Policy Gradient (DDPG), Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO) algorithms for this purpose. The best algorithm is used for dymamic EV pricing. Simulation results show an improved utilization of the grid at the distribution network level, leading to the optimal usage of the grid on a larger scale."}
{"id": "2511.06409", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06409", "abs": "https://arxiv.org/abs/2511.06409", "authors": ["Vishal Cholapadi Ravindra"], "title": "Sensor Importance towards Observability Degree via Shapley Values", "comment": null, "summary": "Sensor selection is an often under-appreciated aspect of state estimator or Kalman filter design. The basic minimum requirement for the choice of a sensor set while designing Kalman filters is that all states are observable. In addition, the sensors should be chosen with a view towards estimating the states with a desired accuracy. Often observability is treated as true/false check during filter design. Beyond observability -- the observability degree -- which measures \\emph{how observable} the states are, has been used as the metric of choice to for sensor selection or placement applications. The higher the degree of observability, the better the possibility of designing Kalman filters that achieve the desired state estimation accuracy and consistency requirements. When a wide variety of sensors are available, sometimes with cost and physical constraints involved, sensor selection plays a crucial role in filter design. In such situations it is important to know the expected contribution of each sensor towards observability degree. Shapley values, developed in cooperative game theory for fair allocation of the payout of a multi-player game to individual players, are widely used in machine learning to assess feature importance. This paper shows that Shapley values can indeed be leveraged to quantify the expected marginal contribution of each sensor in any given sensor set towards the observability degree. This quantification of the fair contribution of each sensor towards the observability degree can be leveraged by filter designers for sensor selection, placement and filter (state estimator) design."}
{"id": "2511.06411", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06411", "abs": "https://arxiv.org/abs/2511.06411", "authors": ["Zhi Zheng", "Wee Sun Lee"], "title": "SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization", "comment": null, "summary": "The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master"}
{"id": "2511.06417", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06417", "abs": "https://arxiv.org/abs/2511.06417", "authors": ["Xiangwu Guo", "Difei Gao", "Mike Zheng Shou"], "title": "AUTO-Explorer: Automated Data Collection for GUI Agent", "comment": null, "summary": "Recent advancements in GUI agents have significantly expanded their ability to interpret natural language commands to manage software interfaces. However, acquiring GUI data remains a significant challenge. Existing methods often involve designing automated agents that browse URLs from the Common Crawl, using webpage HTML to collect screenshots and corresponding annotations, including the names and bounding boxes of UI elements. However, this method is difficult to apply to desktop software or some newly launched websites not included in the Common Crawl. While we expect the model to possess strong generalization capabilities to handle this, it is still crucial for personalized scenarios that require rapid and perfect adaptation to new software or websites. To address this, we propose an automated data collection method with minimal annotation costs, named Auto-Explorer. It incorporates a simple yet effective exploration mechanism that autonomously parses and explores GUI environments, gathering data efficiently. Additionally, to assess the quality of exploration, we have developed the UIXplore benchmark. This benchmark creates environments for explorer agents to discover and save software states. Using the data gathered, we fine-tune a multimodal large language model (MLLM) and establish a GUI element grounding testing set to evaluate the effectiveness of the exploration strategies. Our experiments demonstrate the superior performance of Auto-Explorer, showing that our method can quickly enhance the capabilities of an MLLM in explored software."}
{"id": "2511.06419", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06419", "abs": "https://arxiv.org/abs/2511.06419", "authors": ["Jingyu Hu", "Shu Yang", "Xilin Gong", "Hongming Wang", "Weiru Liu", "Di Wang"], "title": "MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. To address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer. MONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds. Extensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements."}
{"id": "2511.06434", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06434", "abs": "https://arxiv.org/abs/2511.06434", "authors": ["Wenkang Hu", "Xincheng Tang", "Yanzhi E", "Yitong Li", "Zhengjie Shu", "Wei Li", "Huamin Wang", "Ruigang Yang"], "title": "Real Garment Benchmark (RGBench): A Comprehensive Benchmark for Robotic Garment Manipulation featuring a High-Fidelity Scalable Simulator", "comment": "2026 AAAI Accept", "summary": "While there has been significant progress to use simulated data to learn robotic manipulation of rigid objects, applying its success to deformable objects has been hindered by the lack of both deformable object models and realistic non-rigid body simulators. In this paper, we present Real Garment Benchmark (RGBench), a comprehensive benchmark for robotic manipulation of garments. It features a diverse set of over 6000 garment mesh models, a new high-performance simulator, and a comprehensive protocol to evaluate garment simulation quality with carefully measured real garment dynamics. Our experiments demonstrate that our simulator outperforms currently available cloth simulators by a large margin, reducing simulation error by 20% while maintaining a speed of 3 times faster. We will publicly release RGBench to accelerate future research in robotic garment manipulation. Website: https://rgbench.github.io/"}
{"id": "2511.06437", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06437", "abs": "https://arxiv.org/abs/2511.06437", "authors": ["Abhishek More", "Anthony Zhang", "Nicole Bonilla", "Ashvik Vivekan", "Kevin Zhu", "Parham Sharafoleslami", "Maheep Chaudhary"], "title": "Optimizing Chain-of-Thought Confidence via Topological and Dirichlet Risk Analysis", "comment": null, "summary": "Chain-of-thought (CoT) prompting enables Large Language Models to solve complex problems, but deploying these models safely requires reliable confidence estimates, a capability where existing methods suffer from poor calibration and severe overconfidence on incorrect predictions. We propose Enhanced Dirichlet and Topology Risk (EDTR), a novel decoding strategy that combines topological analysis with Dirichlet-based uncertainty quantification to measure LLM confidence across multiple reasoning paths. EDTR treats each CoT as a vector in high-dimensional space and extracts eight topological risk features capturing the geometric structure of reasoning distributions: tighter, more coherent clusters indicate higher confidence while dispersed, inconsistent paths signal uncertainty. We evaluate EDTR against three state-of-the-art calibration methods across four diverse reasoning benchmarks spanning olympiad-level mathematics (AIME), grade school math (GSM8K), commonsense reasoning, and stock price prediction \\cite{zhang2025aime, cobbe2021training, talmor-etal-2019-commonsenseqa, yahoo_finance}. EDTR achieves 41\\% better calibration than competing methods with an average ECE of 0.287 and the best overall composite score of 0.672, while notably achieving perfect accuracy on AIME and exceptional calibration on GSM8K with an ECE of 0.107, domains where baselines exhibit severe overconfidence. Our work provides a geometric framework for understanding and quantifying uncertainty in multi-step LLM reasoning, enabling more reliable deployment where calibrated confidence estimates are essential."}
{"id": "2511.06465", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06465", "abs": "https://arxiv.org/abs/2511.06465", "authors": ["Lingfan Bao", "Tianhu Peng", "Chengxu Zhou"], "title": "Sim-to-Real Transfer in Deep Reinforcement Learning for Bipedal Locomotion", "comment": "Sim-to-real for bipedal locomotion chapter", "summary": "This chapter addresses the critical challenge of simulation-to-reality (sim-to-real) transfer for deep reinforcement learning (DRL) in bipedal locomotion. After contextualizing the problem within various control architectures, we dissect the ``curse of simulation'' by analyzing the primary sources of sim-to-real gap: robot dynamics, contact modeling, state estimation, and numerical solvers. Building on this diagnosis, we structure the solutions around two complementary philosophies. The first is to shrink the gap through model-centric strategies that systematically improve the simulator's physical fidelity. The second is to harden the policy, a complementary approach that uses in-simulation robustness training and post-deployment adaptation to make the policy inherently resilient to model inaccuracies. The chapter concludes by synthesizing these philosophies into a strategic framework, providing a clear roadmap for developing and evaluating robust sim-to-real solutions."}
{"id": "2511.06470", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06470", "abs": "https://arxiv.org/abs/2511.06470", "authors": ["Mingde \"Harry\" Zhao"], "title": "Brain-Inspired Planning for Better Generalization in Reinforcement Learning", "comment": "McGill PhD Thesis (updated on 20251109 for typos and margin adjustments)", "summary": "Existing Reinforcement Learning (RL) systems encounter significant challenges when applied to real-world scenarios, primarily due to poor generalization across environments that differ from their training conditions. This thesis explores the direction of enhancing agents' zero-shot systematic generalization abilities by granting RL agents reasoning behaviors that are found to help systematic generalization in the human brain. Inspired by human conscious planning behaviors, we first introduced a top-down attention mechanism, which allows a decision-time planning agent to dynamically focus its reasoning on the most relevant aspects of the environmental state given its instantaneous intentions, a process we call \"spatial abstraction\". This approach significantly improves systematic generalization outside the training tasks. Subsequently, building on spatial abstraction, we developed the Skipper framework to automatically decompose complex tasks into simpler, more manageable sub-tasks. Skipper provides robustness against distributional shifts and efficacy in long-term, compositional planning by focusing on pertinent spatial and temporal elements of the environment. Finally, we identified a common failure mode and safety risk in planning agents that rely on generative models to generate state targets during planning. It is revealed that most agents blindly trust the targets they hallucinate, resulting in delusional planning behaviors. Inspired by how the human brain rejects delusional intentions, we propose learning a feasibility evaluator to enable rejecting hallucinated infeasible targets, which led to significant performance improvements in various kinds of planning agents. Finally, we suggest directions for future research, aimed at achieving general task abstraction and fully enabling abstract planning."}
{"id": "2511.06471", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06471", "abs": "https://arxiv.org/abs/2511.06471", "authors": ["Jingtao Tang", "Hang Ma"], "title": "GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets", "comment": "Accepted to AAAI-2026", "summary": "We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP) defined over a Graph of Convex Sets (GCS) -- a powerful representation for trajectory planning that decomposes the configuration space into convex regions connected by a sparse graph. In this setting, edge costs are not fixed but depend on the specific trajectory selected through each convex region, making classical TSP methods inapplicable. We introduce GHOST, a hierarchical framework that optimally solves the GCS-TSP by combining combinatorial tour search with convex trajectory optimization. GHOST systematically explores tours on a complete graph induced by the GCS, using a novel abstract-path-unfolding algorithm to compute admissible lower bounds that guide best-first search at both the high level (over tours) and the low level (over feasible GCS paths realizing the tour). These bounds provide strong pruning power, enabling efficient search while avoiding unnecessary convex optimization calls. We prove that GHOST guarantees optimality and present a bounded-suboptimal variant for time-critical scenarios. Experiments show that GHOST is orders-of-magnitude faster than unified mixed-integer convex programming baselines for simple cases and uniquely handles complex trajectory planning problems involving high-order continuity constraints and an incomplete GCS."}
{"id": "2511.06472", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06472", "abs": "https://arxiv.org/abs/2511.06472", "authors": ["Adele Olof-Ors", "Martin Smit"], "title": "Simulated Affection, Engineered Trust: How Anthropomorphic AI Benefits Surveillance Capitalism", "comment": "7 pages", "summary": "In this paper, we argue that anthropomorphized technology, designed to simulate emotional realism, are not neutral tools but cognitive infrastructures that manipulate user trust and behaviour. This reinforces the logic of surveillance capitalism, an under-regulated economic system that profits from behavioural manipulation and monitoring. Drawing on Nicholas Carr's theory of the intellectual ethic, we identify how technologies such as chatbots, virtual assistants, or generative models reshape not only what we think about ourselves and our world, but how we think at the cognitive level. We identify how the emerging intellectual ethic of AI benefits a system of surveillance capitalism, and discuss the potential ways of addressing this."}
{"id": "2511.06496", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06496", "abs": "https://arxiv.org/abs/2511.06496", "authors": ["Keke Long", "Jiacheng Guo", "Tianyun Zhang", "Hongkai Yu", "Xiaopeng Li"], "title": "A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving", "comment": null, "summary": "Vision Language Models (VLMs) are increasingly used in autonomous driving to help understand traffic scenes, but they sometimes produce hallucinations, which are false details not grounded in the visual input. Detecting and mitigating hallucinations is challenging when ground-truth references are unavailable and model internals are inaccessible. This paper proposes a novel self-contained low-rank approach to automatically rank multiple candidate captions generated by multiple VLMs based on their hallucination levels, using only the captions themselves without requiring external references or model access. By constructing a sentence-embedding matrix and decomposing it into a low-rank consensus component and a sparse residual, we use the residual magnitude to rank captions: selecting the one with the smallest residual as the most hallucination-free. Experiments on the NuScenes dataset demonstrate that our approach achieves 87% selection accuracy in identifying hallucination-free captions, representing a 19% improvement over the unfiltered baseline and a 6-10% improvement over multi-agent debate method. The sorting produced by sparse error magnitudes shows strong correlation with human judgments of hallucinations, validating our scoring mechanism. Additionally, our method, which can be easily parallelized, reduces inference time by 51-67% compared to debate approaches, making it practical for real-time autonomous driving applications."}
{"id": "2511.06500", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06500", "abs": "https://arxiv.org/abs/2511.06500", "authors": ["JiaHao Wu", "ShengWen Yu"], "title": "Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation", "comment": "21 pages,12 tables, 6 figures", "summary": "Proportional-Integral-Derivative (PID) controllers remain the predominant choice in industrial robotics due to their simplicity and reliability. However, manual tuning of PID parameters for diverse robotic platforms is time-consuming and requires extensive domain expertise. This paper presents a novel hierarchical control framework that combines meta-learning for PID initialization and reinforcement learning (RL) for online adaptation. To address the sample efficiency challenge, a \\textit{physics-based data augmentation} strategy is introduced that generates virtual robot configurations by systematically perturbing physical parameters, enabling effective meta-learning with limited real robot data. The proposed approach is evaluated on two heterogeneous platforms: a 9-DOF Franka Panda manipulator and a 12-DOF Laikago quadruped robot. Experimental results demonstrate that the proposed method achieves 16.6\\% average improvement on Franka Panda (6.26° MAE), with exceptional gains in high-load joints (J2: 80.4\\% improvement from 12.36° to 2.42°). Critically, this work discovers the \\textit{optimization ceiling effect}: RL achieves dramatic improvements when meta-learning exhibits localized high-error joints, but provides no benefit (0.0\\%) when baseline performance is uniformly strong, as observed in Laikago. The method demonstrates robust performance under disturbances (parameter uncertainty: +19.2\\%, no disturbance: +16.6\\%, average: +10.0\\%) with only 10 minutes of training time. Multi-seed analysis across 100 random initializations confirms stable performance (4.81+/-1.64\\% average). These results establish that RL effectiveness is highly dependent on meta-learning baseline quality and error distribution, providing important design guidance for hierarchical control systems."}
{"id": "2511.06508", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06508", "abs": "https://arxiv.org/abs/2511.06508", "authors": ["Grace E. Calkins", "Jay W. McMahon", "Jackson Kulik"], "title": "Optimal Rank-1 Directional State Transition Tensors", "comment": "Submitted to AIAA Journal of Guidance, Control, and Dynamics", "summary": "An optimal rank-1 approximation of state transition tensors was developed as an efficient alternative to state transition tensors for nonlinear uncertainty quantification. While previous directional state transition tensors used the dominant right singular subspace of the state transition matrix to construct a reduced-dimension representation of the state transition tensors, optimal directional state transition tensors are constructed to maximize the information retained in a rank-1 approximation of the state transition tensors in the Frobenius-norm sense. The optimal rank-1 directional state transition tensor is found by solving a tensor z-eigenpair problem of the \"square\" of the state transition tensor. This construct leads to increased approximation accuracy of the state transition tensors and improved Gaussian moment propagation for nonlinear flight scenarios like aerocapture."}
{"id": "2511.06515", "categories": ["cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06515", "abs": "https://arxiv.org/abs/2511.06515", "authors": ["Cormac O'Neill", "Jasmine Terrones", "H. Harry Asada"], "title": "Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control", "comment": null, "summary": "Controlling robots that dynamically engage in contact with their environment is a pressing challenge. Whether a legged robot making-and-breaking contact with a floor, or a manipulator grasping objects, contact is everywhere. Unfortunately, the switching of dynamics at contact boundaries makes control difficult. Predictive controllers face non-convex optimization problems when contact is involved. Here, we overcome this difficulty by applying Koopman operators to subsume the segmented dynamics due to contact changes into a unified, globally-linear model in an embedding space. We show that viscoelastic contact at robot-environment interactions underpins the use of Koopman operators without approximation to control inputs. This methodology enables the convex Model Predictive Control of a legged robot, and the real-time control of a manipulator engaged in dynamic pushing. In this work, we show that our method allows robots to discover elaborate control strategies in real-time over time horizons with multiple contact changes, and the method is applicable to broad fields beyond robotics."}
{"id": "2511.06520", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06520", "abs": "https://arxiv.org/abs/2511.06520", "authors": ["Nina Stipetic", "Bozidar Filipovic-Grcic", "Igor Ziger", "Silvio Jancin", "Bruno Jurisic", "Dalibor Filipovic-Grcic", "Alain Xémard"], "title": "Verification of low-frequency signal injection method for earth-fault detection", "comment": "10 pages", "summary": "Unearthed neutral is commonly used in networks which require continuous power supply. This is common in MV circuits of industrial and power plants. Unearthed networks can remain in operation during an earth-fault, but fast determination of the faulty line is key for prevention of further fault escalation. Signal injection is one of the fault location methods often used in LV unearthed networks. The possibility of applying this method in MV networks depends on how to inject the signal into unearthed phases. In such networks, it is possible to use a group of three inductive voltage transformers (IVTs) for signal injection. After the simulations have shown promising results of signal injection and earth-fault detection in MV network, an experimental test was performed. This paper describes the experimental setup and shows the measurement results of signal injection method at MV level supported by EMT simulations."}
{"id": "2511.06522", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06522", "abs": "https://arxiv.org/abs/2511.06522", "authors": ["Jan Ondras", "Marek Šuppa"], "title": "FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis", "comment": "Accepted to The 5th Workshop on Mathematical Reasoning and AI at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025); 25 pages, 14 figures, 8 tables; Code available at https://github.com/NaiveNeuron/FractalBench", "summary": "Mathematical reasoning requires abstracting symbolic rules from visual patterns -- inferring the infinite from the finite. We investigate whether multimodal AI systems possess this capability through FractalBench, a benchmark evaluating fractal program synthesis from images. Fractals provide ideal test cases: Iterated Function Systems with only a few contraction maps generate complex self-similar patterns through simple recursive rules, requiring models to bridge visual perception with mathematical abstraction. We evaluate four leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL -- on 12 canonical fractals. Models must generate executable Python code reproducing the fractal, enabling objective evaluation. Results reveal a striking disconnect: 76% generate syntactically valid code but only 4% capture mathematical structure. Success varies systematically -- models handle geometric transformations (Koch curves: 17-21%) but fail at branching recursion (trees: <2%), revealing fundamental gaps in mathematical abstraction. FractalBench provides a contamination-resistant diagnostic for visual-mathematical reasoning and is available at https://github.com/NaiveNeuron/FractalBench"}
{"id": "2511.06523", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06523", "abs": "https://arxiv.org/abs/2511.06523", "authors": ["Selma Grebovic", "Abdulah Aksamovic", "Bozidar Filipovic-Grcic", "Samim Konjicija"], "title": "Investigation of lightning effects on solar power plants connected to transmission networks", "comment": "8 pages", "summary": "The increasing integration of solar power plants into transmission grids has raised concerns about their vulnerability to disturbances, particularly lightning strokes. Solar energy, while offering significant environmental and economic benefits, faces challenges when connected to transmission lines that are prone to lightning discharges. This paper investigates the impact of lightning events on solar power plants, focusing on overvoltage effects. Lightning stroke simulations were conducted at various distances from the solar power plant along the transmission line, considering scenarios with and without surge arrester. Key lightning parameters such as peak current, front time, and tail time were varied to simulate different lightning strokes. The study also includes a Fourier transform analysis of the resulting overvoltages with and without a surge arrester, along with the Hilbert marginal spectrum of these overvoltages. The results provide insights into the effectiveness of surge arresters in mitigating lightning overvoltages and highlight the importance of proper protective measures for enhancing the reliability and safety of solar power plants connected to transmission networks."}
{"id": "2511.06524", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06524", "abs": "https://arxiv.org/abs/2511.06524", "authors": ["Haihui Gao", "Alessandro Bosso", "Lei Wang", "David Saussié", "Bowen Yi"], "title": "Input-Output Data-Driven Stabilization of Continuous-Time Linear MIMO Systems", "comment": null, "summary": "In this paper, we address the problem of data-driven stabilization of continuous-time multi-input multi-output (MIMO) linear time-invariant systems using the input-output data collected from an experiment. Building on recent results for data-driven output-feedback control based on non-minimal realizations, we propose an approach that can be applied to a broad class of continuous-time MIMO systems without requiring a uniform observability index. The key idea is to show that Kreisselmeier's adaptive filter can be interpreted as an observer of a stabilizable non-minimal realization of the plant. Then, by postprocessing the input-output data with such a filter, we derive a linear matrix inequality that yields the feedback gain of a dynamic output-feedback stabilizer."}
{"id": "2511.06525", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06525", "abs": "https://arxiv.org/abs/2511.06525", "authors": ["Philip Trippenbach", "Isabella Scala", "Jai Bhambra", "Rowan Emslie"], "title": "From Catastrophic to Concrete: Reframing AI Risk Communication for Public Mobilization", "comment": "25 pages, 9 figures", "summary": "Effective governance of artificial intelligence (AI) requires public engagement, yet communication strategies centered on existential risk have not produced sustained mobilization. In this paper, we examine the psychological and opinion barriers that limit engagement with extinction narratives, such as mortality avoidance, exponential growth bias, and the absence of self-referential anchors. We contrast them with evidence that public concern over AI rises when framed in terms of proximate harms such as employment disruption, relational instability, and mental health issues. We validate these findings through actual message testing with 1063 respondents, with the evidence showing that AI risks to Jobs and Children have the highest potential to mobilize people, while Existential Risk is the lowest-performing theme across all demographics. Using survey data from five countries, we identify two segments (Tech-Positive Urbanites and World Guardians) as particularly receptive to such framing and more likely to participate in civic action. Finally, we argue that mobilization around these everyday concerns can raise the political salience of AI, creating \"policy demand\" for structural measures to mitigate AI risks. We conclude that this strategy creates the conditions for successful regulatory change."}
{"id": "2511.06528", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06528", "abs": "https://arxiv.org/abs/2511.06528", "authors": ["Qinghua Ma", "Seyyedali Hosseinalipour", "Ming Shi", "Jan Drgona", "Shimiao Li"], "title": "Voltage-Regulated Sparse Optimization for Proactive Diagnosis of Voltage Collapses", "comment": null, "summary": "This paper aims to proactively diagnose and manage the voltage collapse risks, i.e., the risk of bus voltages violating the safe operational bounds, which can be caused by extreme events and contingencies. We jointly answer two resilience-related research questions: (Q1) Survivability: Upon having an extreme event/contingency, will the system remain feasible with voltage staying within a (preferred) safe range? (Q2) Dominant Vulnerability: If voltage collapses, what are the dominant sources of system vulnerabilities responsible for the failure? This highlights some key locations worth paying attention to in the planning or decision-making process. To address these questions, we propose a voltage-regulated sparse optimization that finds a minimal set of bus locations along with quantified compensations (corrective actions) that can simultaneously enforce AC network balance and voltage bounds. Results on transmission systems of varying sizes (30-bus to 2383-bus) demonstrate that the proposed method effectively mitigates voltage collapses by compensating at only a few strategically identified nodes, while scaling efficiently to large systems, taking on average less than 4 min for 2000+ bus cases. This work can further serve as a backbone for more comprehensive and actionable decision-making, such as reactive power planning to fix voltage issues."}
{"id": "2511.06575", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06575", "abs": "https://arxiv.org/abs/2511.06575", "authors": ["Jun Wang", "Yevgeniy Vorobeychik", "Yiannis Kantaros"], "title": "CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning", "comment": null, "summary": "Large Language Models (LLMs) have recently emerged as planners for language-instructed agents, generating sequences of actions to accomplish natural language tasks. However, their reliability remains a challenge, especially in long-horizon tasks, since they often produce overconfident yet wrong outputs. Conformal Prediction (CP) has been leveraged to address this issue by wrapping LLM outputs into prediction sets that contain the correct action with a user-defined confidence. When the prediction set is a singleton, the planner executes that action; otherwise, it requests help from a user. This has led to LLM-based planners that can ensure plan correctness with a user-defined probability. However, as LLMs are trained in an uncertainty-agnostic manner, without awareness of prediction sets, they tend to produce unnecessarily large sets, particularly at higher confidence levels, resulting in frequent human interventions limiting autonomous deployment. To address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first CP-aware finetuning framework for LLM-based planners that explicitly reduces prediction-set size and, in turn, the need for user interventions. We evaluate our approach on multiple language-instructed robot planning problems and show consistent improvements over uncertainty-aware and uncertainty-agnostic finetuning baselines in terms of prediction-set size, and help rates. Finally, we demonstrate robustness of our method to out-of-distribution scenarios in hardware experiments."}
{"id": "2511.06576", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06576", "abs": "https://arxiv.org/abs/2511.06576", "authors": ["Mohammad Javad Najafirad", "Shirantha Welikala", "Lei Wu", "Panos J. Antsaklis"], "title": "Dissipativity-Based Synthesis of Distributed Control and Communication Topology Co-Design for AC Microgrids", "comment": null, "summary": "This paper presents a novel dissipativity-based framework for co-designing distributed controllers and communication topologies in AC microgrids (MGs). Unlike existing methods that treat control synthesis and topology design separately, we propose a unified approach that simultaneously optimizes both aspects to achieve voltage and frequency regulation and proportional power sharing among distributed generators (DGs). We formulate the closed-loop AC MG as a networked system where DGs, distribution lines, and loads are interconnected subsystems characterized by their dissipative properties. Each DG employs a hierarchical architecture combining local controllers for voltage regulation and distributed controllers for droop-free power sharing through normalized power consensus. By leveraging dissipativity theory, we establish necessary and sufficient conditions for subsystem passivity and cast the co-design problem as a convex linear matrix inequality (LMI) optimization, enabling efficient computation and guaranteed stability. Our framework systematically synthesizes sparse communication topologies while handling the coupled dq-frame dynamics and dual power flow objectives inherent to AC MGs. Simulation results on a representative AC MG demonstrate the effectiveness of the proposed approach in achieving accurate voltage regulation, frequency synchronization, and proportional power sharing."}
{"id": "2511.06578", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06578", "abs": "https://arxiv.org/abs/2511.06578", "authors": ["Kaustubh Singh", "Shivam Kumar", "Shashikant Pawar", "Sandeep Manjanna"], "title": "Underactuated Biomimetic Autonomous Underwater Vehicle for Ecosystem Monitoring", "comment": "ICRA RUNE 2024 Workshop Paper", "summary": "In this paper, we present an underactuated biomimetic underwater robot that is suitable for ecosystem monitoring in both marine and freshwater environments. We present an updated mechanical design for a fish-like robot and propose minimal actuation behaviors learned using reinforcement learning techniques. We present our preliminary mechanical design of the tail oscillation mechanism and illustrate the swimming behaviors on FishGym simulator, where the reinforcement learning techniques will be tested on"}
{"id": "2511.06583", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06583", "abs": "https://arxiv.org/abs/2511.06583", "authors": ["Ying Zhang", "Yihao Wang", "Yuanshuo Zhang", "Eric Larson", "Di Shi", "Fanping Sui"], "title": "On the Potential of Digital Twins for Distribution System State Estimation with Randomly Missing Data in Heterogeneous Measurements", "comment": "Accepted by the 2025 IEEE Power and Energy Society General Meeting", "summary": "Traditional statistical optimization-based state estimation (DSSE) algorithms rely on detailed grid parameters and mathematical assumptions of all possible uncertainties. Furthermore, random data missing due to communication failures, congestion, and cyberattacks, makes these methods easily infeasible. Inspired by recent advances in digital twins (DTs), this paper proposes an interactive attention-based DSSE model for robust grid monitoring by integrating three core components: physical entities, virtual modeling, and data fusion. To enable robustness against various data missing in heterogeneous measurements, we first propose physics-informed data augmentation and transfer. Moreover, a state-of-the-art attention-based spatiotemporal feature learning is proposed, followed by a novel cross-interaction feature fusion for robust voltage estimation. A case study in a real-world unbalanced 84-bus distribution system with raw data validates the accuracy and robustness of the proposed DT model in estimating voltage states, with random locational, arbitrary ratios (up to 40% of total measurements) of data missing."}
{"id": "2511.06600", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.06600", "abs": "https://arxiv.org/abs/2511.06600", "authors": ["Hamed Sajadinia", "Zhuo Feng"], "title": "HyperEF 2.0: Spectral Hypergraph Coarsening via Krylov Subspace Expansion and Resistance-based Local Clustering", "comment": "Accepted for publication at the IEEE/ACM International Conference on Computer-Aided Design (ICCAD) 2025", "summary": "This paper introduces HyperEF 2.0, a scalable framework for spectral coarsening and clustering of large-scale hypergraphs through hyperedge effective resistances, aiming to decompose hypergraphs into multiple node clusters with a small number of inter-cluster hyperedges. Building on the recent HyperEF framework, our approach offers three primary contributions. Specifically, first, by leveraging the expanded Krylov subspace exploiting both clique and star expansions of hyperedges, we can significantly improve the approximation accuracy of effective resistances. Second, we propose a resistance-based local clustering scheme for merging small isolated nodes into nearby clusters, yielding more balanced clusters with substantially improved conductance. Third, the proposed HyperEF 2.0 enables the integration of resistance-based hyperedge weighting and community detection into a multilevel hypergraph partitioning tool, achieving state-of-the-art performance. Extensive experiments on real-world VLSI benchmarks show that HyperEF 2.0 can more effectively coarsen hypergraphs without compromising their structural properties, while delivering much better solution quality (e.g. conductance) than the state-of-the-art hypergraph coarsening methods, such as HyperEF and HyperSF. Moreover, compared to leading hypergraph partitioners such as hMETIS, SpecPart, MedPart, and KaHyPar, our framework consistently achieves smaller cut sizes. In terms of runtime, HyperEF 2.0 attains up to a 4.5x speedup over the latest flow-based local clustering algorithm, HyperSF, demonstrating both superior efficiency and partitioning quality."}
{"id": "2511.06618", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06618", "abs": "https://arxiv.org/abs/2511.06618", "authors": ["Moriya Dechtiar", "Daniel Martin Katz", "Mari Sundaresan", "Sylvain Jaume", "Hongming Wang"], "title": "GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization", "comment": null, "summary": "Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering."}
{"id": "2511.06619", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06619", "abs": "https://arxiv.org/abs/2511.06619", "authors": ["Chuheng Zhang", "Rushuai Yang", "Xiaoyu Chen", "Kaixin Wang", "Li Zhao", "Yi Chen", "Jiang Bian"], "title": "How Do VLAs Effectively Inherit from VLMs?", "comment": null, "summary": "Vision-language-action (VLA) models hold the promise to attain generalizable embodied control. To achieve this, a pervasive paradigm is to leverage the rich vision-semantic priors of large vision-language models (VLMs). However, the fundamental question persists: How do VLAs effectively inherit the prior knowledge from VLMs? To address this critical question, we introduce a diagnostic benchmark, GrinningFace, an emoji tabletop manipulation task where the robot arm is asked to place objects onto printed emojis corresponding to language instructions. This task design is particularly revealing -- knowledge associated with emojis is ubiquitous in Internet-scale datasets used for VLM pre-training, yet emojis themselves are largely absent from standard robotics datasets. Consequently, they provide a clean proxy: successful task completion indicates effective transfer of VLM priors to embodied control. We implement this diagnostic task in both simulated environment and a real robot, and compare various promising techniques for knowledge transfer. Specifically, we investigate the effects of parameter-efficient fine-tuning, VLM freezing, co-training, predicting discretized actions, and predicting latent actions. Through systematic evaluation, our work not only demonstrates the critical importance of preserving VLM priors for the generalization of VLA but also establishes guidelines for future research in developing truly generalizable embodied AI systems."}
{"id": "2511.06626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06626", "abs": "https://arxiv.org/abs/2511.06626", "authors": ["Chloe Li", "Mary Phuong", "Daniel Tan"], "title": "Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives", "comment": null, "summary": "As AI systems become more capable of complex agentic tasks, they also become more capable of pursuing undesirable objectives and causing harm. Previous work has attempted to catch these unsafe instances by interrogating models directly about their objectives and behaviors. However, the main weakness of trusting interrogations is that models can lie. We propose self-report fine-tuning (SRFT), a simple supervised fine-tuning technique that trains models to admit their factual mistakes when asked. We show that the admission of factual errors in simple question-answering settings generalizes out-of-distribution (OOD) to the admission of hidden misaligned objectives in adversarial agentic settings. We evaluate SRFT in OOD stealth tasks, where models are instructed to complete a hidden misaligned objective alongside a user-specified objective without being caught by monitoring. After SRFT, models are more likely to confess the details of their hidden objectives when interrogated, even under strong pressure not to disclose them. Interrogation on SRFT models can detect hidden objectives with near-ceiling performance (F1 score = 0.98), while the baseline model lies when interrogated under the same conditions (F1 score = 0). Interrogation on SRFT models can further elicit the content of the hidden objective, recovering 28-100% details, compared to 0% details recovered in the baseline model and by prefilled assistant turn attacks. This provides a promising technique for promoting honesty propensity and incriminating misaligned AI systems."}
{"id": "2511.06663", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06663", "abs": "https://arxiv.org/abs/2511.06663", "authors": ["Yuhang Li", "Yang Lu", "Bo Ai", "Zhiguo Ding", "Dusit Niyato", "Arumugam Nallanathan"], "title": "GNN-Enabled Robust Hybrid Beamforming with Score-Based CSI Generation and Denoising", "comment": null, "summary": "Accurate Channel State Information (CSI) is critical for Hybrid Beamforming (HBF) tasks. However, obtaining high-resolution CSI remains challenging in practical wireless communication systems. To address this issue, we propose to utilize Graph Neural Networks (GNNs) and score-based generative models to enable robust HBF under imperfect CSI conditions. Firstly, we develop the Hybrid Message Graph Attention Network (HMGAT) which updates both node and edge features through node-level and edge-level message passing. Secondly, we design a Bidirectional Encoder Representations from Transformers (BERT)-based Noise Conditional Score Network (NCSN) to learn the distribution of high-resolution CSI, facilitating CSI generation and data augmentation to further improve HMGAT's performance. Finally, we present a Denoising Score Network (DSN) framework and its instantiation, termed DeBERT, which can denoise imperfect CSI under arbitrary channel error levels, thereby facilitating robust HBF. Experiments on DeepMIMO urban datasets demonstrate the proposed models' superior generalization, scalability, and robustness across various HBF tasks with perfect and imperfect CSI."}
{"id": "2511.06667", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06667", "abs": "https://arxiv.org/abs/2511.06667", "authors": ["Andrew Choi", "Dezhong Tong"], "title": "Rapidly Learning Soft Robot Control via Implicit Time-Stepping", "comment": "Code: https://github.com/QuantuMope/dismech-rl", "summary": "With the explosive growth of rigid-body simulators, policy learning in simulation has become the de facto standard for most rigid morphologies. In contrast, soft robotic simulation frameworks remain scarce and are seldom adopted by the soft robotics community. This gap stems partly from the lack of easy-to-use, general-purpose frameworks and partly from the high computational cost of accurately simulating continuum mechanics, which often renders policy learning infeasible. In this work, we demonstrate that rapid soft robot policy learning is indeed achievable via implicit time-stepping. Our simulator of choice, DisMech, is a general-purpose, fully implicit soft-body simulator capable of handling both soft dynamics and frictional contact. We further introduce delta natural curvature control, a method analogous to delta joint position control in rigid manipulators, providing an intuitive and effective means of enacting control for soft robot learning. To highlight the benefits of implicit time-stepping and delta curvature control, we conduct extensive comparisons across four diverse soft manipulator tasks against one of the most widely used soft-body frameworks, Elastica. With implicit time-stepping, parallel stepping of 500 environments achieves up to 6x faster speeds for non-contact cases and up to 40x faster for contact-rich scenarios. Finally, a comprehensive sim-to-sim gap evaluation--training policies in one simulator and evaluating them in another--demonstrates that implicit time-stepping provides a rare free lunch: dramatic speedups achieved without sacrificing accuracy."}
{"id": "2511.06673", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06673", "abs": "https://arxiv.org/abs/2511.06673", "authors": ["Joel Kemp", "Andre Farinha", "David Howard", "Krishna Manaswi Digumarti", "Josh Pinskier"], "title": "Programmable Telescopic Soft Pneumatic Actuators for Deployable and Shape Morphing Soft Robots", "comment": "8 pages, 10 figures, Submitted to Robosoft 2026", "summary": "Soft Robotics presents a rich canvas for free-form and continuum devices capable of exerting forces in any direction and transforming between arbitrary configurations. However, there is no current way to tractably and directly exploit the design freedom due to the curse of dimensionality. Parameterisable sets of designs offer a pathway towards tractable, modular soft robotics that appropriately harness the behavioural freeform of soft structures to create rich embodied behaviours. In this work, we present a parametrised class of soft actuators, Programmable Telescopic Soft Pneumatic Actuators (PTSPAs). PTSPAs expand axially on inflation for deployable structures and manipulation in challenging confined spaces. We introduce a parametric geometry generator to customise actuator models from high-level inputs, and explore the new design space through semi-automated experimentation and systematic exploration of key parameters. Using it we characterise the actuators' extension/bending, expansion, and stiffness and reveal clear relationships between key design parameters and performance. Finally we demonstrate the application of the actuators in a deployable soft quadruped whose legs deploy to walk, enabling automatic adaptation to confined spaces. PTSPAs present new design paradigm for deployable and shape morphing structures and wherever large length changes are required."}
{"id": "2511.06677", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06677", "abs": "https://arxiv.org/abs/2511.06677", "authors": ["Swetha Rani Kasimalla", "Kuchan Park", "Junho Hong", "Young-Jin Kim"], "title": "F2GAN: A Feature-Feedback Generative Framework for Reliable AI-Based Fault Diagnosis in Inverter-Dominated Microgrids", "comment": null, "summary": "Enhancing the reliability of AI based fault diagnosis in inverter dominated microgrids requires diverse and statistically balanced datasets. However, the scarcity and imbalance of high fidelity fault data, especially for rare inverter malfunctions and extreme external line faults, limit dependable model training and validation. This paper introduces a unified framework that models a detailed inverter dominated microgrid and systematically generates multiple internal and external fault scenarios to mitigate data scarcity and class imbalance. An enhanced generative model called F2GAN (Feature Feedback GAN) is developed to synthesize high dimensional tabular fault data with improved realism and statistical alignment. Unlike conventional GANs, F2GAN integrates multi level feedback based on mean variance, correlation, and feature matching losses, enabling the generator to refine output distributions toward real fault feature spaces. The generated datasets are evaluated through quantitative and qualitative analyses. Train on Synthetic, Test on Real (TSTR) experiments demonstrate strong generalization of machine learning classifiers trained exclusively on F2GAN samples. The framework is validated on a hardware-in-the-loop (HIL) fault diagnosis platform integrated with a real time simulator and graphical interface, achieving 100 % diagnostic accuracy under real-time testing. Results confirm that F2GAN effectively bridges the gap between simulated and real world microgrid fault datasets"}
{"id": "2511.06700", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06700", "abs": "https://arxiv.org/abs/2511.06700", "authors": ["Damian Curran", "Vanessa Sporne", "Lea Frermann", "Jeannie Paterson"], "title": "Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries", "comment": null, "summary": "How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM-based chatbots varies depending on their location. However, obtaining meaningful comparative metrics is challenging because legal institutions in different places are not themselves easily comparable. In this work we propose a methodology to obtain place-to-place metrics based on the comparative law concept of functionalism. We construct a dataset of factual scenarios drawn from Reddit posts by users seeking legal advice for family, housing, employment, crime and traffic issues. We use these to elicit a summary of a law from the LLM relevant to each scenario in Los Angeles, London and Sydney. These summaries, typically of a legislative provision, are manually evaluated for hallucinations. We show that the rate of hallucination of legal information by leading closed-source LLMs is significantly associated with place. This suggests that the quality of legal solutions provided by these models is not evenly distributed across geography. Additionally, we show a strong negative correlation between hallucination rate and the frequency of the majority response when the LLM is sampled multiple times, suggesting a measure of uncertainty of model predictions of legal facts."}
{"id": "2511.06713", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06713", "abs": "https://arxiv.org/abs/2511.06713", "authors": ["Yuheng Luo", "Chuanzhe Zhang", "Qingsong Liu", "Hai Zhu", "Wenjun Mei"], "title": "Pareto-Improvement-Driven Opinion Dynamics Explaining the Emergence of Pluralistic Ignorance", "comment": null, "summary": "Opinion dynamics has recently been modeled from a game-theoretic perspective, where opinion updates are captured by individuals' cost functions representing their motivations. Conventional formulations aggregate multiple motivations into a single objective, implicitly assuming that these motivations are interchangeable. This paper challenges that assumption and proposes an opinion dynamics model grounded in a multi-objective game framework. In the proposed model, each individual experiences two distinct costs: social pressure from disagreement with others and cognitive dissonance from deviation from the perceived truth. Opinion updates are modeled as Pareto improvements between these two costs. This fwork provides a parsimonious explanation for the emergence of pluralistic ignorance, where individuals may agree on something untrue even though they all know the underlying truth. We analytically characterize the model, derive conditions for the emrameergence and prevalence of the truth, and propose an initial-seeding strategy that ensures consensus on truth. Numerical simulations are conducted on how network density and clustering affect the expression of truth. Both theoretical and numerical results lead to clear and non-trivial sociological insights. For example, no network structure guarantees truthful consensus if no one initially express the truth; moderately sparse but well-mixed networks best mitigate pluralistic ignorance."}
{"id": "2511.06714", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06714", "abs": "https://arxiv.org/abs/2511.06714", "authors": ["Emad Abukhousa", "Syed Sohail Feroz Syed Afroz", "Fahad Alsaeed", "Abdulaziz Qwbaiban", "Saman Zonouz", "A. P. Sakis Meliopoulos"], "title": "The Wisdom of the Crowd: High-Fidelity Classification of Cyber-Attacks and Faults in Power Systems Using Ensemble and Machine Learning", "comment": null, "summary": "This paper presents a high-fidelity evaluation framework for machine learning (ML)-based classification of cyber-attacks and physical faults using electromagnetic transient simulations with digital substation emulation at 4.8 kHz. Twelve ML models, including ensemble algorithms and a multi-layer perceptron (MLP), were trained on labeled time-domain measurements and evaluated in a real-time streaming environment designed for sub-cycle responsiveness. The architecture incorporates a cycle-length smoothing filter and confidence threshold to stabilize decisions. Results show that while several models achieved near-perfect offline accuracies (up to 99.9%), only the MLP sustained robust coverage (98-99%) under streaming, whereas ensembles preserved perfect anomaly precision but abstained frequently (10-49% coverage). These findings demonstrate that offline accuracy alone is an unreliable indicator of field readiness and underscore the need for realistic testing and inference pipelines to ensure dependable classification in inverter-based resources (IBR)-rich networks."}
{"id": "2511.06745", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06745", "abs": "https://arxiv.org/abs/2511.06745", "authors": ["Lan Thi Ha Nguyen", "Kien Ton Manh", "Anh Do Duc", "Nam Pham Hai"], "title": "Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning", "comment": null, "summary": "Self-supervised goal-conditioned reinforcement learning enables robots to autonomously acquire diverse skills without human supervision. However, a central challenge is the goal setting problem: robots must propose feasible and diverse goals that are achievable in their current environment. Existing methods like RIG (Visual Reinforcement Learning with Imagined Goals) use variational autoencoder (VAE) to generate goals in a learned latent space but have the limitation of producing physically implausible goals that hinder learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates physical constraints directly into the VAE training process through a novel Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling the generation of physically consistent and achievable goals. Our key innovation is the explicit separation of the latent space into physics variables governing object dynamics and environmental factors capturing visual appearance, while enforcing physical consistency through differential equation constraints and conservation laws. This enables the generation of physically consistent and achievable goals that respect fundamental physical principles such as object permanence, collision constraints, and dynamic feasibility. Through extensive experiments, we demonstrate that this physics-informed goal generation significantly improves the quality of proposed goals, leading to more effective exploration and better skill acquisition in visual robotic manipulation tasks including reaching, pushing, and pick-and-place scenarios."}
{"id": "2511.06747", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06747", "abs": "https://arxiv.org/abs/2511.06747", "authors": ["Anu Kuncheria", "Joan L. Walker", "Jane Macfarlane"], "title": "Beyond Centrality: Understanding Urban Street Network Typologies Through Intersection Patterns", "comment": null, "summary": "The structure of road networks plays a pivotal role in shaping transportation dynamics. It also provides insights into how drivers experience city streets and helps uncover each urban environment's unique characteristics and challenges. Consequently, characterizing cities based on their road network patterns can facilitate the identification of similarities and differences, informing collaborative traffic management strategies, particularly at a regional scale. While previous studies have investigated global network patterns for cities, they have often overlooked detailed characterizations within a single large urban region. Additionally, most existing research uses metrics like degree, centrality, orientation, etc., and misses the nuances of street networks at the intersection level, specifically the geometric angles formed by links at intersections, which could offer a more refined feature for characterization. To address these gaps, this study examines over 100 cities in the San Francisco Bay Area. We introduce a novel metric for classifying intersections, distinguishing between different types of 3-way and 4-way intersections based on the angles formed at the intersections. Through the application of clustering algorithms in machine learning, we have identified three distinct typologies - grid, orthogonal, and organic cities - within the San Francisco Bay Area. We demonstrate the effectiveness of the metric in capturing the differences between cities based on street and intersection patterns. The typologies generated in this study could offer valuable support for city planners and policymakers in crafting a range of practical strategies tailored to the complexities of each city's road network, covering aspects such as evacuation plans, traffic signage placements, and traffic signal control."}
{"id": "2511.06749", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06749", "abs": "https://arxiv.org/abs/2511.06749", "authors": ["Weining Lu", "Deer Bin", "Lian Ma", "Ming Ma", "Zhihao Ma", "Xiangyang Chen", "Longfei Wang", "Yixiao Feng", "Zhouxian Jiang", "Yongliang Shi", "Bin Liang"], "title": "Semi-distributed Cross-modal Air-Ground Relative Localization", "comment": "7 pages, 3 figures. Accepted by IROS 2025", "summary": "Efficient, accurate, and flexible relative localization is crucial in air-ground collaborative tasks. However, current approaches for robot relative localization are primarily realized in the form of distributed multi-robot SLAM systems with the same sensor configuration, which are tightly coupled with the state estimation of all robots, limiting both flexibility and accuracy. To this end, we fully leverage the high capacity of Unmanned Ground Vehicle (UGV) to integrate multiple sensors, enabling a semi-distributed cross-modal air-ground relative localization framework. In this work, both the UGV and the Unmanned Aerial Vehicle (UAV) independently perform SLAM while extracting deep learning-based keypoints and global descriptors, which decouples the relative localization from the state estimation of all agents. The UGV employs a local Bundle Adjustment (BA) with LiDAR, camera, and an IMU to rapidly obtain accurate relative pose estimates. The BA process adopts sparse keypoint optimization and is divided into two stages: First, optimizing camera poses interpolated from LiDAR-Inertial Odometry (LIO), followed by estimating the relative camera poses between the UGV and UAV. Additionally, we implement an incremental loop closure detection algorithm using deep learning-based descriptors to maintain and retrieve keyframes efficiently. Experimental results demonstrate that our method achieves outstanding performance in both accuracy and efficiency. Unlike traditional multi-robot SLAM approaches that transmit images or point clouds, our method only transmits keypoint pixels and their descriptors, effectively constraining the communication bandwidth under 0.3 Mbps. Codes and data will be publicly available on https://github.com/Ascbpiac/cross-model-relative-localization.git."}
{"id": "2511.06754", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.06754", "abs": "https://arxiv.org/abs/2511.06754", "authors": ["Taisei Hanyu", "Nhat Chung", "Huy Le", "Toan Nguyen", "Yuki Ikebe", "Anthony Gunderman", "Duy Nguyen Ho Minh", "Khoa Vo", "Tung Kieu", "Kashu Yamazaki", "Chase Rainwater", "Anh Nguyen", "Ngan Le"], "title": "SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation", "comment": "under review", "summary": "Inspired by how humans reason over discrete objects and their relationships, we explore whether compact object-centric and object-relation representations can form a foundation for multitask robotic manipulation. Most existing robotic multitask models rely on dense embeddings that entangle both object and background cues, raising concerns about both efficiency and interpretability. In contrast, we study object-relation-centric representations as a pathway to more structured, efficient, and explainable visuomotor control. Our contributions are two-fold. First, we introduce LIBERO+, a fine-grained benchmark dataset designed to enable and evaluate object-relation reasoning in robotic manipulation. Unlike prior datasets, LIBERO+ provides object-centric annotations that enrich demonstrations with box- and mask-level labels as well as instance-level temporal tracking, supporting compact and interpretable visuomotor representations. Second, we propose SlotVLA, a slot-attention-based framework that captures both objects and their relations for action decoding. It uses a slot-based visual tokenizer to maintain consistent temporal object representations, a relation-centric decoder to produce task-relevant embeddings, and an LLM-driven module that translates these embeddings into executable actions. Experiments on LIBERO+ demonstrate that object-centric slot and object-relation slot representations drastically reduce the number of required visual tokens, while providing competitive generalization. Together, LIBERO+ and SlotVLA provide a compact, interpretable, and effective foundation for advancing object-relation-centric robotic manipulation."}
{"id": "2511.06761", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06761", "abs": "https://arxiv.org/abs/2511.06761", "authors": ["Fei Yang"], "title": "SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding", "comment": null, "summary": "Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \\textit{What} and \\textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. Moreover, unlike the prevalent ``pretrain-then-finetune'' paradigm, SRNN adopts a ``predefine-then-finetune'' approach. On the CLEVRER benchmark, SRNN achieves competitive performance. Our analysis further reveals a benchmark bias, outlines a path for a more holistic evaluation, and demonstrates SRNN's white-box utility for precise error diagnosis. Our work confirms the viability of translating biological intelligence into engineered systems for intuitive physics understanding."}
{"id": "2511.06796", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06796", "abs": "https://arxiv.org/abs/2511.06796", "authors": ["MD-Nazmus Sunbeam"], "title": "Human-Level Actuation for Humanoids", "comment": "61 pages, 8 figures, 7 tables, and 12 numbered equations", "summary": "Claims that humanoid robots achieve ``human-level'' actuation are common but rarely quantified. Peak torque or speed specifications tell us little about whether a joint can deliver the right combination of torque, power, and endurance at task-relevant postures and rates. We introduce a comprehensive framework that makes ``human-level'' measurable and comparable across systems. Our approach has three components. First, a kinematic \\emph{DoF atlas} standardizes joint coordinate systems and ranges of motion using ISB-based conventions, ensuring that human and robot joints are compared in the same reference frames. Second, \\emph{Human-Equivalence Envelopes (HEE)} define per-joint requirements by measuring whether a robot meets human torque \\emph{and} power simultaneously at the same joint angle and rate $(q,ω)$, weighted by positive mechanical work in task-specific bands (walking, stairs, lifting, reaching, and hand actions). Third, the \\emph{Human-Level Actuation Score (HLAS)} aggregates six physically grounded factors: workspace coverage (ROM and DoF), HEE coverage, torque-mode bandwidth, efficiency, and thermal sustainability. We provide detailed measurement protocols using dynamometry, electrical power monitoring, and thermal testing that yield every HLAS input from reproducible experiments. A worked example demonstrates HLAS computation for a multi-joint humanoid, showing how the score exposes actuator trade-offs (gearing ratio versus bandwidth and efficiency) that peak-torque specifications obscure. The framework serves as both a design specification for humanoid development and a benchmarking standard for comparing actuation systems, with all components grounded in published human biomechanics data."}
{"id": "2511.06801", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06801", "abs": "https://arxiv.org/abs/2511.06801", "authors": ["Praveen Kumar", "Tushar Sandhan"], "title": "Vision-Aided Online A* Path Planning for Efficient and Safe Navigation of Service Robots", "comment": "10 pages", "summary": "The deployment of autonomous service robots in human-centric environments is hindered by a critical gap in perception and planning. Traditional navigation systems rely on expensive LiDARs that, while geometrically precise, are seman- tically unaware, they cannot distinguish a important document on an office floor from a harmless piece of litter, treating both as physically traversable. While advanced semantic segmentation exists, no prior work has successfully integrated this visual intelligence into a real-time path planner that is efficient enough for low-cost, embedded hardware. This paper presents a frame- work to bridge this gap, delivering context-aware navigation on an affordable robotic platform. Our approach centers on a novel, tight integration of a lightweight perception module with an online A* planner. The perception system employs a semantic segmentation model to identify user-defined visual constraints, enabling the robot to navigate based on contextual importance rather than physical size alone. This adaptability allows an operator to define what is critical for a given task, be it sensitive papers in an office or safety lines in a factory, thus resolving the ambiguity of what to avoid. This semantic perception is seamlessly fused with geometric data. The identified visual constraints are projected as non-geometric obstacles onto a global map that is continuously updated from sensor data, enabling robust navigation through both partially known and unknown environments. We validate our framework through extensive experiments in high-fidelity simulations and on a real-world robotic platform. The results demonstrate robust, real-time performance, proving that a cost- effective robot can safely navigate complex environments while respecting critical visual cues invisible to traditional planners."}
{"id": "2511.06805", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06805", "abs": "https://arxiv.org/abs/2511.06805", "authors": ["Jinhao Chen", "Zhen Yang", "Jianxin Shi", "Tianyu Wo", "Jie Tang"], "title": "MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning", "comment": "19 pages, 11 figures", "summary": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \\textbf{\\method}, a \\textbf{Math}ematical \\textbf{S}elf-\\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \\method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \\method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \\texttt{https://zheny2751\\allowbreak-dotcom.github.io/\\allowbreak MathSE.github.io/}."}
{"id": "2511.06832", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06832", "abs": "https://arxiv.org/abs/2511.06832", "authors": ["Daniele Ravasio", "Danilo Saccani", "Marcello Farina", "Giancarlo Ferrari-Trecate"], "title": "Learning stabilising policies for constrained nonlinear systems", "comment": "4 figures, under review", "summary": "This work proposes a two-layered control scheme for constrained nonlinear systems represented by a class of recurrent neural networks and affected by additive disturbances. In particular, a base controller ensures global or regional closed-loop l_p-stability of the error in tracking a desired equilibrium and the satisfaction of input and output constraints within a robustly positive invariant set. An additional control contribution, derived by combining the internal model control principle with a stable operator, is introduced to improve system performance. This operator, implemented as a stable neural network, can be trained via unconstrained optimisation on a chosen performance metric, without compromising closed-loop equilibrium tracking or constraint satisfaction, even if the optimisation is stopped prematurely. In addition, we characterise the class of closed-loop stable behaviours that can be achieved with the proposed architecture. Simulation results on a pH-neutralisation benchmark demonstrate the effectiveness of the proposed approach."}
{"id": "2511.06839", "categories": ["cs.RO", "cs.CV", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.06839", "abs": "https://arxiv.org/abs/2511.06839", "authors": ["Selim Ahmet Iz", "Mustafa Unel"], "title": "Vision-Based System Identification of a Quadrotor", "comment": null, "summary": "This paper explores the application of vision-based system identification techniques in quadrotor modeling and control. Through experiments and analysis, we address the complexities and limitations of quadrotor modeling, particularly in relation to thrust and drag coefficients. Grey-box modeling is employed to mitigate uncertainties, and the effectiveness of an onboard vision system is evaluated. An LQR controller is designed based on a system identification model using data from the onboard vision system. The results demonstrate consistent performance between the models, validating the efficacy of vision based system identification. This study highlights the potential of vision-based techniques in enhancing quadrotor modeling and control, contributing to improved performance and operational capabilities. Our findings provide insights into the usability and consistency of these techniques, paving the way for future research in quadrotor performance enhancement, fault detection, and decision-making processes."}
{"id": "2511.06873", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06873", "abs": "https://arxiv.org/abs/2511.06873", "authors": ["Ruohan Wang", "Siyuan Liu", "Zhiyong Sun", "Sofie Haesaert"], "title": "Correct-by-Design Control Synthesis of Stochastic Multi-agent Systems: a Robust Tensor-based Solution", "comment": null, "summary": "Discrete-time stochastic systems with continuous spaces are hard to verify and control, even with MDP abstractions due to the curse of dimensionality. We propose an abstraction-based framework with robust dynamic programming mappings that deliver control strategies with provable lower bounds on temporal-logic satisfaction, quantified via approximate stochastic simulation relations. Exploiting decoupled dynamics, we reveal a Canonical Polyadic Decomposition tensor structure in value functions that makes dynamic programming scalable. The proposed method provides correct-by-design probabilistic guarantees for temporal logic specifications. We validate our results on continuous-state linear stochastic systems."}
{"id": "2511.06892", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06892", "abs": "https://arxiv.org/abs/2511.06892", "authors": ["Kailin Tong", "Selim Solmaz", "Kenan Mujkic", "Gottfried Allmer", "Bo Leng"], "title": "Multi-Agent AI Framework for Road Situation Detection and C-ITS Message Generation", "comment": "submitted to TRA 2026", "summary": "Conventional road-situation detection methods achieve strong performance in predefined scenarios but fail in unseen cases and lack semantic interpretation, which is crucial for reliable traffic recommendations. This work introduces a multi-agent AI framework that combines multimodal large language models (MLLMs) with vision-based perception for road-situation monitoring. The framework processes camera feeds and coordinates dedicated agents for situation detection, distance estimation, decision-making, and Cooperative Intelligent Transport System (C-ITS) message generation. Evaluation is conducted on a custom dataset of 103 images extracted from 20 videos of the TAD dataset. Both Gemini-2.0-Flash and Gemini-2.5-Flash were evaluated. The results show 100\\% recall in situation detection and perfect message schema correctness; however, both models suffer from false-positive detections and have reduced performance in terms of number of lanes, driving lane status and cause code. Surprisingly, Gemini-2.5-Flash, though more capable in general tasks, underperforms Gemini-2.0-Flash in detection accuracy and semantic understanding and incurs higher latency (Table II). These findings motivate further work on fine-tuning specialized LLMs or MLLMs tailored for intelligent transportation applications."}
{"id": "2511.06918", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06918", "abs": "https://arxiv.org/abs/2511.06918", "authors": ["Gilles Audemard", "Christophe Lecoutre", "Emmanuel Lonca"], "title": "Proceedings of the 2025 XCSP3 Competition", "comment": "110 pages", "summary": "This document represents the proceedings of the 2025 XCSP3 Competition. The results of this competition of constraint solvers were presented at CP'25 (31st International Conference on Principles and Practice of Constraint Programming)."}
{"id": "2511.06919", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06919", "abs": "https://arxiv.org/abs/2511.06919", "authors": ["Luis Diener", "Jens Kalkkuhl", "Markus Enzweiler"], "title": "Integration of Visual SLAM into Consumer-Grade Automotive Localization", "comment": "This manuscript has been submitted to the IEEE for possible publication", "summary": "Accurate ego-motion estimation in consumer-grade vehicles currently relies on proprioceptive sensors, i.e. wheel odometry and IMUs, whose performance is limited by systematic errors and calibration. While visual-inertial SLAM has become a standard in robotics, its integration into automotive ego-motion estimation remains largely unexplored. This paper investigates how visual SLAM can be integrated into consumer-grade vehicle localization systems to improve performance. We propose a framework that fuses visual SLAM with a lateral vehicle dynamics model to achieve online gyroscope calibration under realistic driving conditions. Experimental results demonstrate that vision-based integration significantly improves gyroscope calibration accuracy and thus enhances overall localization performance, highlighting a promising path toward higher automotive localization accuracy. We provide results on both proprietary and public datasets, showing improved performance and superior localization accuracy on a public benchmark compared to state-of-the-art methods."}
{"id": "2511.06921", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06921", "abs": "https://arxiv.org/abs/2511.06921", "authors": ["Siddhartha Mahajan", "Harsh Raj", "Sonam Tanwar"], "title": "Analysis of Traffic Congestion in North Campus, Delhi University Using Continuous Time Models", "comment": null, "summary": "This project investigates traffic congestion within North Campus, Delhi University (DU), using continuous time simulations implemented in UXSim to model vehicle movement and interaction. The study focuses on several key intersections, identifies recurring congestion points, and evaluates the effectiveness of conventional traffic management measures. Implementing signal timing optimization and modest intersection reconfiguration resulted in measurable improvements in simulated traffic flow. The results provide practical insights for local traffic management and illustrate the value of continuous time simulation methods for informing short-term interventions and longer-term planning."}
{"id": "2511.06950", "categories": ["eess.SY", "cs.MA", "eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.06950", "abs": "https://arxiv.org/abs/2511.06950", "authors": ["M. Doostmohammadian", "U. A. Khan", "N. Meskin"], "title": "On the Redundant Distributed Observability of Mixed Traffic Transportation Systems", "comment": "EURASIP journal on advances in signal processing", "summary": "In this paper, the problem of distributed state estimation of human-driven vehicles (HDVs) by connected autonomous vehicles (CAVs) is investigated in mixed traffic transportation systems. Toward this, a distributed observable state-space model is derived, which paves the way for estimation and observability analysis of HDVs in mixed traffic scenarios. In this direction, first, we obtain the condition on the network topology to satisfy the distributed observability, i.e., the condition such that each HDV state is observable to every CAV via information-exchange over the network. It is shown that strong connectivity of the network, along with the proper design of the observer gain, is sufficient for this. A distributed observer is then designed by locally sharing estimates/observations of each CAV with its neighborhood. Second, in case there exist faulty sensors or unreliable observation data, we derive the condition for redundant distributed observability as a $q$-node/link-connected network design. This redundancy is achieved by extra information-sharing over the network and implies that a certain number of faulty sensors and unreliable links can be isolated/removed without losing the observability. Simulation results are provided to illustrate the effectiveness of the proposed approach."}
{"id": "2511.06982", "categories": ["cs.SI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.06982", "abs": "https://arxiv.org/abs/2511.06982", "authors": ["Ankit Mazumder", "Srikanta Bedathur"], "title": "CGLE: Class-label Graph Link Estimator for Link Prediction", "comment": "Paper accepted at the IEEE International Conference on Data Mining (ICDM 2025)", "summary": "Link prediction is a pivotal task in graph mining with wide-ranging applications in social networks, recommendation systems, and knowledge graph completion. However, many leading Graph Neural Network (GNN) models often neglect the valuable semantic information aggregated at the class level. To address this limitation, this paper introduces CGLE (Class-label Graph Link Estimator), a novel framework designed to augment GNN-based link prediction models. CGLE operates by constructing a class-conditioned link probability matrix, where each entry represents the probability of a link forming between two node classes. This matrix is derived from either available ground-truth labels or from pseudo-labels obtained through clustering. The resulting class-based prior is then concatenated with the structural link embedding from a backbone GNN, and the combined representation is processed by a Multi-Layer Perceptron (MLP) for the final prediction. Crucially, CGLE's logic is encapsulated in an efficient preprocessing stage, leaving the computational complexity of the underlying GNN model unaffected. We validate our approach through extensive experiments on a broad suite of benchmark datasets, covering both homophilous and sparse heterophilous graphs. The results show that CGLE yields substantial performance gains over strong baselines such as NCN and NCNC, with improvements in HR@100 of over 10 percentage points on homophilous datasets like Pubmed and DBLP. On sparse heterophilous graphs, CGLE delivers an MRR improvement of over 4% on the Chameleon dataset. Our work underscores the efficacy of integrating global, data-driven semantic priors, presenting a compelling alternative to the pursuit of increasingly complex model architectures. Code to reproduce our findings is available at: https://github.com/data-iitd/cgle-icdm2025."}
{"id": "2511.06989", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06989", "abs": "https://arxiv.org/abs/2511.06989", "authors": ["Yang Wang", "Marta Zagorowska", "Riccardo M. G. Ferrari"], "title": "Capacity Estimation of Lithium-ion Batteries Using Invariance Property in Open Circuit Voltage Relationship", "comment": null, "summary": "Lithium-ion (Li-ion) batteries are ubiquitous in electric vehicles (EVs) as efficient energy storage devices. The reliable operation of Li-ion batteries depends critically on the accurate estimation of battery capacity. However, conventional estimation methods require extensive training datasets from costly battery tests for modeling, and a full cycle of charge and discharge is often needed to estimate the capacity. To overcome these limitations, we propose a novel capacity estimation method that leverages only one cycle of the open-circuit voltage (OCV) test in modeling and allows for estimating the capacity from partial charge or discharge data. Moreover, by applying it with OCV identification algorithms, we can estimate the capacity from dynamic discharge data without requiring dedicated data collection tests. We observed an invariance property in the OCV versus state of charge relationship across aging cycles. Leveraging this invariance, the proposed method estimates the capacity by solving an OCV alignment problem using only the OCV and the discharge capacity data from the battery. Simulation results demonstrate the method's efficacy, achieving a mean absolute relative error of 0.85\\% in capacity estimation across 12 samples from 344 aging cycles."}
{"id": "2511.06990", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06990", "abs": "https://arxiv.org/abs/2511.06990", "authors": ["Vitor Bueno", "Ali Azarbahram", "Marcello Farina", "Lorenzo Fagiano"], "title": "Koopman-Based Dynamic Environment Prediction for Safe UAV Navigation", "comment": null, "summary": "This paper presents a Koopman-based model predictive control (MPC) framework for safe UAV navigation in dynamic environments using real-time LiDAR data. By leveraging the Koopman operator to linearly approximate the dynamics of surrounding objets, we enable efficient and accurate prediction of the position of moving obstacles. Embedding this into an MPC formulation ensures robust, collision-free trajectory planning suitable for real-time execution. The method is validated through simulation and ROS2-Gazebo implementation, demonstrating reliable performance under sensor noise, actuation delays, and environmental uncertainty."}
{"id": "2511.06997", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06997", "abs": "https://arxiv.org/abs/2511.06997", "authors": ["Javier Castillo-Martínez", "Raul Baños", "Francisco G. Montoya"], "title": "Beyond Phasors: Solving Non-Sinusoidal Electrical Circuits using Geometry", "comment": null, "summary": "Classical phasor analysis is fundamentally limited to sinusoidal single-frequency conditions, which poses challenges when working in the presence of harmonics. Furthermore, the conventional solution, which consists of decomposing signals using Fourier series and applying superposition, is a fragmented process that does not provide a unified solution in the frequency domain. This paper overcomes this limitation by introducing a complete and direct approach for multi-harmonic AC circuits using Geometric Algebra (GA). In this way, all non-sinusoidal voltage and current waveforms are represented as simple vectors in a $2N$-dimensional Euclidean space. The relationship between these vectors is characterized by a single and unified geometric transformation termed the \\textit{rotoflex}. This operator elevates the concept of impedance from a set of complex numbers per frequency to a single multivector that holistically captures the circuit response, while unifying the magnitude scale (flextance) and phase rotation (rotance) across all harmonics. Thus, this work establishes GA as a structurally unified and efficient alternative to phasor analysis, providing a more rigorous foundation for electrical circuit analysis. The methodology is validated through case studies that demonstrate perfect numerical consistency with traditional methods and superior performance."}
{"id": "2511.06998", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06998", "abs": "https://arxiv.org/abs/2511.06998", "authors": ["Jin Huang", "Yingqiang Wang", "Ying Chen"], "title": "Raspi$^2$USBL: An open-source Raspberry Pi-Based Passive Inverted Ultra-Short Baseline Positioning System for Underwater Robotics", "comment": null, "summary": "Precise underwater positioning remains a fundamental challenge for underwater robotics since global navigation satellite system (GNSS) signals cannot penetrate the sea surface. This paper presents Raspi$^2$USBL, an open-source, Raspberry Pi-based passive inverted ultra-short baseline (piUSBL) positioning system designed to provide a low-cost and accessible solution for underwater robotic research. The system comprises a passive acoustic receiver and an active beacon. The receiver adopts a modular hardware architecture that integrates a hydrophone array, a multichannel preamplifier, an oven-controlled crystal oscillator (OCXO), a Raspberry Pi 5, and an MCC-series data acquisition (DAQ) board. Apart from the Pi 5, OCXO, and MCC board, the beacon comprises an impedance-matching network, a power amplifier, and a transmitting transducer. An open-source C++ software framework provides high-precision clock synchronization and triggering for one-way travel-time (OWTT) messaging, while performing real-time signal processing, including matched filtering, array beamforming, and adaptive gain control, to estimate the time of flight (TOF) and direction of arrival (DOA) of received signals. The Raspi$^2$USBL system was experimentally validated in an anechoic tank, freshwater lake, and open-sea trials. Results demonstrate a slant-range accuracy better than 0.1%, a bearing accuracy within 0.1$^\\circ$, and stable performance over operational distances up to 1.3 km. These findings confirm that low-cost, reproducible hardware can deliver research-grade underwater positioning accuracy. By releasing both the hardware and software as open-source, Raspi$^2$USBL provides a unified reference platform that lowers the entry barrier for underwater robotics laboratories, fosters reproducibility, and promotes collaborative innovation in underwater acoustic navigation and swarm robotics."}
{"id": "2511.07052", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07052", "abs": "https://arxiv.org/abs/2511.07052", "authors": ["S. Gokul Krishnan", "Mohd Asim Aftab", "Shehab Ahmed", "Charalambos Konstantinou"], "title": "Real-Time Co-Simulation for DC Microgrid Energy Management with Communication Delays", "comment": null, "summary": "The growing integration of renewable energy sources (RESs) in modern power systems has intensified the need for resilient and efficient microgrid solutions. DC microgrids have gained prominence due to their reduced conversion losses, simplified interfacing with DC-based RESs, and improved reliability. To manage the inherent variability of RESs and ensure stable operation, energy management systems (EMS) have become essential. While various EMS algorithms have been proposed and validated using real-time simulation platforms, most assume ideal communication conditions or rely on simplified network models, overlooking the impact of realistic communication delays on EMS performance. This paper presents a novel real-time cyber-physical system (CPS) testbed for evaluating EMS performance in DC microgrids under realistic communication delays. The proposed testbed integrates a DC microgrid modeled in OPAL-RT with an EMS controller implemented on a Raspberry Pi (RPi). The communication network is emulated using EXataCPS, enabling the exchange of actual power system traffic and the replication of realistic latency conditions. This comprehensive setup captures the interplay between power system dynamics, EMS control, and communication network behavior."}
{"id": "2511.07054", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07054", "abs": "https://arxiv.org/abs/2511.07054", "authors": ["Pradeep M", "Twinkle Tripathy"], "title": "Structural sign herdability of linear time-invariant systems:theory and design for arbitrary network structures", "comment": null, "summary": "The objective of this paper is to investigate graph-theoretic conditions for structural herdability of an LTI system. In particular, we are interested in the structural sign (SS) herdability of a system wherein the underlying digraph representing it is signed. Structural herdability finds applications in various domains like power networks, biological networks, opinion dynamics, multi-robot shepherding, etc. We begin the analysis by introducing a layered graph representation Gs of the signed digraph G; such a representation allows us to capture the signed distances between the nodes with ease. We construct a subgraph of G_s that characterizes paths of identical signs between layers and uniform path lengths, referred to as a layer-wise unisigned graph LUG(G_s). A special subgraph of an LUG(G_s), denoted as an LUG^H(G_s), is key to achieving SS herdability. This is because we prove that an LTI system is SS herdable if and only if there exists an LUG^H(G_s) which covers all the nodes of the given digraph. To the best of our knowledge, such a graphical test is one of the first methods which allows us to check SS herdability for arbitrary digraph topologies. Interestingly, the analysis also reveals that a system can be SS herdable even in the presence of (signed and layer) dilation in the associated digraph (note that such a behaviour has been shown to be impossible in directed trees). Additionally, we also extend these results to digraphs with multiple leader and driver nodes. In order to illustrate all the results, we present numerous examples throughout the paper."}
{"id": "2511.07061", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07061", "abs": "https://arxiv.org/abs/2511.07061", "authors": ["Xinran Li", "Xiujuan Xu", "Jiaqi Qiao", "Yu Liu"], "title": "Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and Curriculum Learning", "comment": "Accepted at AAAI 2026", "summary": "Emotion Recognition in Conversation (ERC) is a crucial task for understanding human emotions and enabling natural human-computer interaction. Although Large Language Models (LLMs) have recently shown great potential in this field, their ability to capture the intrinsic connections between explicit and implicit emotions remains limited. We propose a novel ERC training framework, PRC-Emo, which integrates Prompt engineering, demonstration Retrieval, and Curriculum learning, with the goal of exploring whether LLMs can effectively perceive emotions in conversational contexts. Specifically, we design emotion-sensitive prompt templates based on both explicit and implicit emotional cues to better guide the model in understanding the speaker's psychological states. We construct the first dedicated demonstration retrieval repository for ERC, which includes training samples from widely used datasets, as well as high-quality dialogue examples generated by LLMs and manually verified. Moreover, we introduce a curriculum learning strategy into the LoRA fine-tuning process, incorporating weighted emotional shifts between same-speaker and different-speaker utterances to assign difficulty levels to dialogue samples, which are then organized in an easy-to-hard training sequence. Experimental results on two benchmark datasets-- IEMOCAP and MELD --show that our method achieves new state-of-the-art (SOTA) performance, demonstrating the effectiveness and generalizability of our approach in improving LLM-based emotional understanding."}
{"id": "2511.07062", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07062", "abs": "https://arxiv.org/abs/2511.07062", "authors": ["Yimei Zhang", "Guojiang Shen", "Kaili Ning", "Tongwei Ren", "Xuebo Qiu", "Mengmeng Wang", "Xiangjie Kong"], "title": "Improving Region Representation Learning from Urban Imagery with Noisy Long-Caption Supervision", "comment": "Accepted as a full paper by AAAI-26", "summary": "Region representation learning plays a pivotal role in urban computing by extracting meaningful features from unlabeled urban data. Analogous to how perceived facial age reflects an individual's health, the visual appearance of a city serves as its ``portrait\", encapsulating latent socio-economic and environmental characteristics. Recent studies have explored leveraging Large Language Models (LLMs) to incorporate textual knowledge into imagery-based urban region representation learning. However, two major challenges remain: i)~difficulty in aligning fine-grained visual features with long captions, and ii) suboptimal knowledge incorporation due to noise in LLM-generated captions. To address these issues, we propose a novel pre-training framework called UrbanLN that improves Urban region representation learning through Long-text awareness and Noise suppression. Specifically, we introduce an information-preserved stretching interpolation strategy that aligns long captions with fine-grained visual semantics in complex urban scenes. To effectively mine knowledge from LLM-generated captions and filter out noise, we propose a dual-level optimization strategy. At the data level, a multi-model collaboration pipeline automatically generates diverse and reliable captions without human intervention. At the model level, we employ a momentum-based self-distillation mechanism to generate stable pseudo-targets, facilitating robust cross-modal learning under noisy conditions. Extensive experiments across four real-world cities and various downstream tasks demonstrate the superior performance of our UrbanLN."}
{"id": "2511.07070", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07070", "abs": "https://arxiv.org/abs/2511.07070", "authors": ["Fei Zhao", "Chonggang Lu", "Haofu Qian", "Fangcheng Shi", "Zijie Meng", "Jianzhao Huang", "Xu Tang", "Zheyong Xie", "Zheyu Ye", "Zhe Xu", "Yao Hu", "Shaosheng Cao"], "title": "RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social Networking Services", "comment": null, "summary": "As a key medium for human interaction and information exchange, social networking services (SNS) pose unique challenges for large language models (LLMs): heterogeneous workloads, fast-shifting norms and slang, and multilingual, culturally diverse corpora that induce sharp distribution shift. Supervised fine-tuning (SFT) can specialize models but often triggers a ``seesaw'' between in-distribution gains and out-of-distribution robustness, especially for smaller models. To address these challenges, we introduce RedOne 2.0, an SNS-oriented LLM trained with a progressive, RL-prioritized post-training paradigm designed for rapid and stable adaptation. The pipeline consist in three stages: (1) Exploratory Learning on curated SNS corpora to establish initial alignment and identify systematic weaknesses; (2) Targeted Fine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a small fraction of general data to mitigate forgetting; and (3) Refinement Learning that re-applies RL with SNS-centric signals to consolidate improvements and harmonize trade-offs across tasks. Across various tasks spanning three categories, our 4B scale model delivers an average improvements about 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves average performance lift about 8.74 from the base model with less than half the data required by SFT-centric method RedOne, evidencing superior data efficiency and stability at compact scales. Overall, RedOne 2.0 establishes a competitive, cost-effective baseline for domain-specific LLMs in SNS scenario, advancing capability without sacrificing robustness."}
{"id": "2511.07081", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07081", "abs": "https://arxiv.org/abs/2511.07081", "authors": ["Guanghu Xie", "Mingxu Li", "Songwei Wu", "Yang Liu", "Zongwu Xie", "Baoshi Cao", "Hong Liu"], "title": "HDCNet: A Hybrid Depth Completion Network for Grasping Transparent and Reflective Objects", "comment": null, "summary": "Depth perception of transparent and reflective objects has long been a critical challenge in robotic manipulation.Conventional depth sensors often fail to provide reliable measurements on such surfaces, limiting the performance of robots in perception and grasping tasks. To address this issue, we propose a novel depth completion network,HDCNet,which integrates the complementary strengths of Transformer,CNN and Mamba architectures.Specifically,the encoder is designed as a dual-branch Transformer-CNN framework to extract modality-specific features. At the shallow layers of the encoder, we introduce a lightweight multimodal fusion module to effectively integrate low-level features. At the network bottleneck,a Transformer-Mamba hybrid fusion module is developed to achieve deep integration of high-level semantic and global contextual information, significantly enhancing depth completion accuracy and robustness. Extensive evaluations on multiple public datasets demonstrate that HDCNet achieves state-of-the-art(SOTA) performance in depth completion tasks.Furthermore,robotic grasping experiments show that HDCNet substantially improves grasp success rates for transparent and reflective objects,achieving up to a 60% increase."}
{"id": "2511.07083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07083", "abs": "https://arxiv.org/abs/2511.07083", "authors": ["Marc Jansen", "Marcel Pehlke"], "title": "Increasing AI Explainability by LLM Driven Standard Processes", "comment": null, "summary": "This paper introduces an approach to increasing the explainability of artificial intelligence (AI) systems by embedding Large Language Models (LLMs) within standardized analytical processes. While traditional explainable AI (XAI) methods focus on feature attribution or post-hoc interpretation, the proposed framework integrates LLMs into defined decision models such as Question-Option-Criteria (QOC), Sensitivity Analysis, Game Theory, and Risk Management. By situating LLM reasoning within these formal structures, the approach transforms opaque inference into transparent and auditable decision traces. A layered architecture is presented that separates the reasoning space of the LLM from the explainable process space above it. Empirical evaluations show that the system can reproduce human-level decision logic in decentralized governance, systems analysis, and strategic reasoning contexts. The results suggest that LLM-driven standard processes provide a foundation for reliable, interpretable, and verifiable AI-supported decision making."}
{"id": "2511.07086", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07086", "abs": "https://arxiv.org/abs/2511.07086", "authors": ["Marcel Pehlke", "Marc Jansen"], "title": "LLM Driven Processes to Foster Explainable AI", "comment": null, "summary": "We present a modular, explainable LLM-agent pipeline for decision support that externalizes reasoning into auditable artifacts. The system instantiates three frameworks: Vester's Sensitivity Model (factor set, signed impact matrix, systemic roles, feedback loops); normal-form games (strategies, payoff matrix, equilibria); and sequential games (role-conditioned agents, tree construction, backward induction), with swappable modules at every step. LLM components (default: GPT-5) are paired with deterministic analyzers for equilibria and matrix-based role classification, yielding traceable intermediates rather than opaque outputs. In a real-world logistics case (100 runs), mean factor alignment with a human baseline was 55.5\\% over 26 factors and 62.9\\% on the transport-core subset; role agreement over matches was 57\\%. An LLM judge using an eight-criterion rubric (max 100) scored runs on par with a reconstructed human baseline. Configurable LLM pipelines can thus mimic expert workflows with transparent, inspectable steps."}
{"id": "2511.07090", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07090", "abs": "https://arxiv.org/abs/2511.07090", "authors": ["Marcel Rojahn", "Marcus Grum"], "title": "Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts", "comment": null, "summary": "Across the Artificial Intelligence (AI) lifecycle - from hardware to development, deployment, and reuse - burdens span energy, carbon, water, and embodied impacts. Cloud provider tools improve transparency but remain heterogeneous and often omit water and value chain effects, limiting comparability and reproducibility. Addressing these multi dimensional burdens requires a lifecycle approach linking phase explicit mapping with system levers (hardware, placement, energy mix, cooling, scheduling) and calibrated measurement across facility, system, device, and workload levels. This article (i) establishes a unified, operational definition of Green AI distinct from Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle Assessment (LCA) stages, making energy, carbon, water, and embodied impacts first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles with decision gateways; (iv) systematizes hardware and system level strategies across the edge cloud continuum to reduce embodied burdens; and (v) defines a calibrated measurement framework combining estimator models with direct metering to enable reproducible, provider agnostic comparisons. Combining definition, lifecycle processes, hardware strategies, and calibrated measurement, this article offers actionable, evidence based guidance for researchers, practitioners, and policymakers."}
{"id": "2511.07095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07095", "abs": "https://arxiv.org/abs/2511.07095", "authors": ["Meghyn Bienvenu", "Quentin Manière"], "title": "Data Complexity of Querying Description Logic Knowledge Bases under Cost-Based Semantics", "comment": "Long version of paper to appear in AAAI 2026", "summary": "In this paper, we study the data complexity of querying inconsistent weighted description logic (DL) knowledge bases under recently-introduced cost-based semantics. In a nutshell, the idea is to assign each interpretation a cost based upon the weights of the violated axioms and assertions, and certain and possible query answers are determined by considering all (resp. some) interpretations having optimal or bounded cost. Whereas the initial study of cost-based semantics focused on DLs between $\\mathcal{EL}_\\bot$ and $\\mathcal{ALCO}$, we consider DLs that may contain inverse roles and role inclusions, thus covering prominent DL-Lite dialects. Our data complexity analysis goes significantly beyond existing results by sharpening several lower bounds and pinpointing the precise complexity of optimal-cost certain answer semantics (no non-trivial upper bound was known). Moreover, while all existing results show the intractability of cost-based semantics, our most challenging and surprising result establishes that if we consider $\\text{DL-Lite}^\\mathcal{H}_\\mathsf{bool}$ ontologies and a fixed cost bound, certain answers for instance queries and possible answers for conjunctive queries can be computed using first-order rewriting and thus enjoy the lowest possible data complexity ($\\mathsf{TC}_0$)."}
{"id": "2511.07097", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07097", "abs": "https://arxiv.org/abs/2511.07097", "authors": ["Diego Gosmar", "Anna Chiara Pallotta", "Giovanni Zenezini"], "title": "Agentic AI Sustainability Assessment for Supply Chain Document Insights", "comment": "17 pages, 4 figures", "summary": "This paper presents a comprehensive sustainability assessment framework for document intelligence within supply chain operations, centered on agentic artificial intelligence (AI). We address the dual objective of improving automation efficiency while providing measurable environmental performance in document-intensive workflows. The research compares three scenarios: fully manual (human-only), AI-assisted (human-in-the-loop, HITL), and an advanced multi-agent agentic AI workflow leveraging parsers and verifiers. Empirical results show that AI-assisted HITL and agentic AI scenarios achieve reductions of up to 70-90% in energy consumption, 90-97% in carbon dioxide emissions, and 89-98% in water usage compared to manual processes. Notably, full agentic configurations, combining advanced reasoning (thinking mode) and multi-agent validation, achieve substantial sustainability gains over human-only approaches, even when resource usage increases slightly versus simpler AI-assisted solutions. The framework integrates performance, energy, and emission indicators into a unified ESG-oriented methodology for assessing and governing AI-enabled supply chain solutions. The paper includes a complete replicability use case demonstrating the methodology's application to real-world document extraction tasks."}
{"id": "2511.07098", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07098", "abs": "https://arxiv.org/abs/2511.07098", "authors": ["Yuanshao Zhu", "Xiangyu Zhao", "Zijian Zhang", "Xuetao Wei", "James Jianqiao Yu"], "title": "Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture and Focalized Optimization", "comment": "Accepted as a regular paper by AAAI'26", "summary": "Fine-grained urban flow inference is crucial for urban planning and intelligent transportation systems, enabling precise traffic management and resource allocation. However, the practical deployment of existing methods is hindered by two key challenges: the prohibitive computational cost of over-parameterized models and the suboptimal performance of conventional loss functions on the highly skewed distribution of urban flows. To address these challenges, we propose a unified solution that synergizes architectural efficiency with adaptive optimization. Specifically, we first introduce PLGF, a lightweight yet powerful architecture that employs a Progressive Local-Global Fusion strategy to effectively capture both fine-grained details and global contextual dependencies. Second, we propose DualFocal Loss, a novel function that integrates dual-space supervision with a difficulty-aware focusing mechanism, enabling the model to adaptively concentrate on hard-to-predict regions. Extensive experiments on 4 real-world scenarios validate the effectiveness and scalability of our method. Notably, while achieving state-of-the-art performance, PLGF reduces the model size by up to 97% compared to current high-performing methods. Furthermore, under comparable parameter budgets, our model yields an accuracy improvement of over 10% against strong baselines. The implementation is included in the https://github.com/Yasoz/PLGF."}
{"id": "2511.07104", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07104", "abs": "https://arxiv.org/abs/2511.07104", "authors": ["Junji Hou", "Junzhou Zhao", "Shuo Zhang", "Pinghui Wang"], "title": "A Theoretical Analysis of Detecting Large Model-Generated Time Series", "comment": "23 pages,12 figures, to be published in AAAI-2026 main track", "summary": "Motivated by the increasing risks of data misuse and fabrication, we investigate the problem of identifying synthetic time series generated by Time-Series Large Models (TSLMs) in this work. While there are extensive researches on detecting model generated text, we find that these existing methods are not applicable to time series data due to the fundamental modality difference, as time series usually have lower information density and smoother probability distributions than text data, which limit the discriminative power of token-based detectors. To address this issue, we examine the subtle distributional differences between real and model-generated time series and propose the contraction hypothesis, which states that model-generated time series, unlike real ones, exhibit progressively decreasing uncertainty under recursive forecasting. We formally prove this hypothesis under theoretical assumptions on model behavior and time series structure. Model-generated time series exhibit progressively concentrated distributions under recursive forecasting, leading to uncertainty contraction. We provide empirical validation of the hypothesis across diverse datasets. Building on this insight, we introduce the Uncertainty Contraction Estimator (UCE), a white-box detector that aggregates uncertainty metrics over successive prefixes to identify TSLM-generated time series. Extensive experiments on 32 datasets show that UCE consistently outperforms state-of-the-art baselines, offering a reliable and generalizable solution for detecting model-generated time series."}
{"id": "2511.07107", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07107", "abs": "https://arxiv.org/abs/2511.07107", "authors": ["Liang Shan", "Kaicheng Shen", "Wen Wu", "Zhenyu Ying", "Chaochao Lu", "Guangze Ye", "Liang He"], "title": "MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks", "comment": null, "summary": "Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment."}
{"id": "2511.07110", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07110", "abs": "https://arxiv.org/abs/2511.07110", "authors": ["Tianhao Fu", "Xinxin Xu", "Weichen Xu", "Jue Chen", "Ruilong Ren", "Bowen Deng", "Xinyu Zhao", "Jian Cao", "Xixin Cao"], "title": "Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture", "comment": null, "summary": "Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows significant performance. Such methods are hindered by their slow inference speed, while most of the current research has not studied LLM distillation for this specific task. To address this, we first propose the normalized fluorescent probe to study the mechanism of the LLM's feature. Based on the observation found by our investigation, we propose Cooperative Market Making (CMM), a novel framework that decouples LLM features across three orthogonal dimensions: layer, task, and data. Various student models collaboratively learn simple LLM features along with different dimensions, with each model responsible for a distinct feature to achieve knowledge distillation. Furthermore, CMM introduces an Hájek-MoE to integrate the output of the student models by investigating the contribution of different models in a kernel function-generated common feature space. Extensive experimental results on four real-world market datasets demonstrate the superiority of CMM over the current distillation method and RL-based market-making strategies."}
{"id": "2511.07126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07126", "abs": "https://arxiv.org/abs/2511.07126", "authors": ["Tim Bohne", "Anne-Kathrin Patricia Windler", "Martin Atzmueller"], "title": "Saliency Map-Guided Knowledge Discovery for Subclass Identification with LLM-Based Symbolic Approximations", "comment": null, "summary": "This paper proposes a novel neuro-symbolic approach for sensor signal-based knowledge discovery, focusing on identifying latent subclasses in time series classification tasks. The approach leverages gradient-based saliency maps derived from trained neural networks to guide the discovery process. Multiclass time series classification problems are transformed into binary classification problems through label subsumption, and classifiers are trained for each of these to yield saliency maps. The input signals, grouped by predicted class, are clustered under three distinct configurations. The centroids of the final set of clusters are provided as input to an LLM for symbolic approximation and fuzzy knowledge graph matching to discover the underlying subclasses of the original multiclass problem. Experimental results on well-established time series classification datasets demonstrate the effectiveness of our saliency map-driven method for knowledge discovery, outperforming signal-only baselines in both clustering and subclass identification."}
{"id": "2511.07155", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07155", "abs": "https://arxiv.org/abs/2511.07155", "authors": ["Thomas Steinecker", "Alexander Bienemann", "Denis Trescher", "Thorsten Luettel", "Mirko Maehlisch"], "title": "Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving", "comment": null, "summary": "Reinforcement learning (RL) has shown promise in robotics, but deploying RL on real vehicles remains challenging due to the complexity of vehicle dynamics and the mismatch between simulation and reality. Factors such as tire characteristics, road surface conditions, aerodynamic disturbances, and vehicle load make it infeasible to model real-world dynamics accurately, which hinders direct transfer of RL agents trained in simulation. In this paper, we present a framework that decouples motion planning from vehicle control through a spatial and temporal alignment strategy between a virtual vehicle and the real system. An RL agent is first trained in simulation using a kinematic bicycle model to output continuous control actions. Its behavior is then distilled into a trajectory-predicting agent that generates finite-horizon ego-vehicle trajectories, enabling synchronization between virtual and real vehicles. At deployment, a Stanley controller governs lateral dynamics, while longitudinal alignment is maintained through adaptive update mechanisms that compensate for deviations between virtual and real trajectories. We validate our approach on a real vehicle and demonstrate that the proposed alignment strategy enables robust zero-shot transfer of RL-based motion planning from simulation to reality, successfully decoupling high-level trajectory generation from low-level vehicle control."}
{"id": "2511.07157", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.07157", "abs": "https://arxiv.org/abs/2511.07157", "authors": ["Francesco Zigliotto"], "title": "Past-aware game-theoretic centrality in complex contagion dynamics", "comment": null, "summary": "In this paper, we introduce past-aware game-theoretic centrality, a class of centrality measures that captures the collaborative contribution of nodes in a network, accounting for both uncertain and certain collaborators. A general framework for computing standard game-theoretic centrality is extended to the past-aware case. As an application, we develop a new heuristic for different versions of the influence maximization problems in complex contagion dynamics, which models processes requiring reinforcement from multiple neighbors to spread. A computationally efficient explicit formula for the corresponding past-aware centrality score is derived, leading to scalable algorithms for identifying the most influential nodes, which in most cases outperform the standard greedy approach in both efficiency and solution quality."}
{"id": "2511.07159", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07159", "abs": "https://arxiv.org/abs/2511.07159", "authors": ["Mehmet Turker Takci", "James Day", "Meysam Qadrdan"], "title": "Characterisation and Quantification of Data Centre Flexibility for Power System Support", "comment": null, "summary": "The rapid growth of data centres poses an evolving challenge for power systems with high variable renewable energy. Traditionally operated as passive electrical loads, data centres, have the potential to become active participants that provide flexibility to the grid. However, quantifying and utilising this flexibility have not yet been fully explored. This paper presents an integrated, whole facility optimisation model to investigate the least cost operating schedule of data centres and characterise the aggregate flexibility available from data centres to the power system. The model accounts for IT workload shifting, UPS energy storage, and cooling system. Motivated by the need to alleviate the increasing strain on power systems while leveraging their untapped flexibility potential, this study makes two primary contributions: (i) an operational optimisation model that integrates IT scheduling, UPS operation, and cooling dynamics to establish a cost optimal baseline operation, and (ii) a duration-aware flexibility assessment that, for any given start time and power deviation, computes the maximum feasible duration from this baseline while respecting all operational, thermal, and recovery constraints. This method characterises the aggregate flexibility envelope. Results reveal a clear temporal structure and a notable asymmetry in flexibility provision: upward flexibility (electricity load reduction) is driven by deferring IT workload, which allows for a secondary reduction in cooling power. Downward flexibility (electricity load increase) relies on increasing power consumption of the cooling system, supported by the TES buffer, and charging the UPS. This framework translates abstract flexibility potential into quantified flexibility magnitude and duration that system operators could investigate for use in services such as reserve, frequency response, and price responsive demand."}
{"id": "2511.07167", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07167", "abs": "https://arxiv.org/abs/2511.07167", "authors": ["Mengqi Li", "Lixin Li", "Wensheng Lin", "Zhu Han", "Tamer Başar"], "title": "Beyond Gaussian Assumptions: A General Fractional HJB Control Framework for Lévy-Driven Heavy-Tailed Channels in 6G", "comment": null, "summary": "Emerging 6G wireless systems suffer severe performance degradation in challenging environments like high-speed trains traversing dense urban corridors and Unmanned Aerial Vehicles (UAVs) links over mountainous terrain. These scenarios exhibit non-Gaussian, non-stationary channels with heavy-tailed fading and abrupt signal fluctuations. To address these challenges, this paper proposes a novel wireless channel model based on symmetric $α$-stable Lévy processes, thereby enabling continuous-time state-space characterization of both long-term and short-term fading. Building on this model, a generalized optimal control framework is developed via a fractional Hamilton-Jacobi-Bellman (HJB) equation that incorporates the Riesz fractional operator to capture non-local spatial effects and memory-dependent dynamics. The existence and uniqueness of viscosity solutions to the fractional HJB equation are rigorously established, thus ensuring the theoretical validity of the proposed control formulation. Numerical simulations conducted in a multi-cell, multi-user downlink setting demonstrate the effectiveness of the fractional HJB-based strategy in optimizing transmission power under heavy-tailed co-channel and multi-user interference."}
{"id": "2511.07175", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07175", "abs": "https://arxiv.org/abs/2511.07175", "authors": ["Marvin Rüdt", "Constantin Enke", "Kai Furmans"], "title": "Automated Generation of Continuous-Space Roadmaps for Routing Mobile Robot Fleets", "comment": "submitted to the IEEE for possible publication; 8 pages, 6 figures, 2 tables", "summary": "Efficient routing of mobile robot fleets is crucial in intralogistics, where delays and deadlocks can substantially reduce system throughput. Roadmap design, specifying feasible transport routes, directly affects fleet coordination and computational performance. Existing approaches are either grid-based, compromising geometric precision, or continuous-space approaches that disregard practical constraints. This paper presents an automated roadmap generation approach that bridges this gap by operating in continuous-space, integrating station-to-station transport demand and enforcing minimum distance constraints for nodes and edges. By combining free space discretization, transport demand-driven $K$-shortest-path optimization, and path smoothing, the approach produces roadmaps tailored to intralogistics applications. Evaluation across multiple intralogistics use cases demonstrates that the proposed approach consistently outperforms established baselines (4-connected grid, 8-connected grid, and random sampling), achieving lower structural complexity, higher redundancy, and near-optimal path lengths, enabling efficient and robust routing of mobile robot fleets."}
{"id": "2511.07204", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07204", "abs": "https://arxiv.org/abs/2511.07204", "authors": ["Giacomo Fidone", "Lucia Passaro", "Riccardo Guidotti"], "title": "Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations", "comment": "Accepted for publication at AAAI Conference on Artificial Intelligence 2026", "summary": "Online Social Networks (OSNs) widely adopt content moderation to mitigate the spread of abusive and toxic discourse. Nonetheless, the real effectiveness of moderation interventions remains unclear due to the high cost of data collection and limited experimental control. The latest developments in Natural Language Processing pave the way for a new evaluation approach. Large Language Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and simulate human-like social behavior with unprecedented degree of believability. Yet, existing tools do not support simulation-based evaluation of moderation strategies. We fill this gap by designing a LLM-powered simulator of OSN conversations enabling a parallel, counterfactual simulation where toxic behavior is influenced by moderation interventions, keeping all else equal. We conduct extensive experiments, unveiling the psychological realism of OSN agents, the emergence of social contagion phenomena and the superior effectiveness of personalized moderation strategies."}
{"id": "2511.07225", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07225", "abs": "https://arxiv.org/abs/2511.07225", "authors": ["Matteo Cederle", "Saverio Bolognani", "Gian Antonio Susto"], "title": "Fair and Efficient allocation of Mobility-on-Demand resources through a Karma Economy", "comment": "6 pages, 3 figures. Under review at the 2026 European Control Conference (ECC)", "summary": "Mobility-on-demand systems like ride-hailing have transformed urban transportation, but they have also exacerbated socio-economic inequalities in access to these services, also due to surge pricing strategies. Although several fairness-aware frameworks have been proposed in smart mobility, they often overlook the temporal and situational variability of user urgency that shapes real-world transportation demands. This paper introduces a non-monetary, Karma-based mechanism that models endogenous urgency, allowing user time-sensitivity to evolve in response to system conditions as well as external factors. We develop a theoretical framework maintaining the efficiency and fairness guarantees of classical Karma economies, while accommodating this realistic user behavior modeling. Applied to a simulated mobility-on-demand scenario we show that our framework is able to achieve high levels of system efficiency, guaranteeing at the same time equitable resource allocation for the users."}
{"id": "2511.07245", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.07245", "abs": "https://arxiv.org/abs/2511.07245", "authors": ["Ruifeng Zheng", "Pengjie Zhou", "Pit Hofmann", "Fatima Rani", "Juan A. Cabrera", "Frank H. P. Fitzek"], "title": "System Modeling of Microfluidic Molecular Communication: A Markov Approach", "comment": "6 pages, 5 figures. Submitted to IEEE International Conference on Communications (ICC) 2026", "summary": "This paper presents a Markov-based system model for microfluidic molecular communication (MC) channels. By discretizing the advection-diffusion dynamics, the proposed model establishes a physically consistent state-space formulation. The transition matrix explicitly captures diffusion, advective flow, reversible binding, and flow-out effects. The resulting discrete-time formulation enables analytical characterization of both transient and equilibrium responses through a linear system representation. Numerical results verify that the proposed framework accurately reproduces channel behaviors across a wide range of flow conditions, providing a tractable basis for the design and analysis of MC systems in microfluidic environments."}
{"id": "2511.07260", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07260", "abs": "https://arxiv.org/abs/2511.07260", "authors": ["Hohei Chan", "Xinzhi Zhang", "Antao Xiang", "Weinan Zhang", "Mengchen Zhao"], "title": "PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork", "comment": "Accepted by the 40th AAAI conference on Artificial Intelligence (AAAI 2026)", "summary": "Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly."}
{"id": "2511.07262", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07262", "abs": "https://arxiv.org/abs/2511.07262", "authors": ["Qile Jiang", "George Karniadakis"], "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning", "comment": null, "summary": "Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing."}
{"id": "2511.07267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07267", "abs": "https://arxiv.org/abs/2511.07267", "authors": ["Chen Han", "Yijia Ma", "Jin Tan", "Wenzhen Zheng", "Xijin Tang"], "title": "Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion", "comment": "This paper has been accepted to AAAI 2026", "summary": "Multi-agent debate (MAD) frameworks have emerged as promising approaches for misinformation detection by simulating adversarial reasoning. While prior work has focused on detection accuracy, it overlooks the importance of helping users understand the reasoning behind factual judgments and develop future resilience. The debate transcripts generated during MAD offer a rich but underutilized resource for transparent reasoning. In this study, we introduce ED2D, an evidence-based MAD framework that extends previous approach by incorporating factual evidence retrieval. More importantly, ED2D is designed not only as a detection framework but also as a persuasive multi-agent system aimed at correcting user beliefs and discouraging misinformation sharing. We compare the persuasive effects of ED2D-generated debunking transcripts with those authored by human experts. Results demonstrate that ED2D outperforms existing baselines across three misinformation detection benchmarks. When ED2D generates correct predictions, its debunking transcripts exhibit persuasive effects comparable to those of human experts; However, when ED2D misclassifies, its accompanying explanations may inadvertently reinforce users'misconceptions, even when presented alongside accurate human explanations. Our findings highlight both the promise and the potential risks of deploying MAD systems for misinformation intervention. We further develop a public community website to help users explore ED2D, fostering transparency, critical thinking, and collaborative fact-checking."}
{"id": "2511.07275", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.07275", "abs": "https://arxiv.org/abs/2511.07275", "authors": ["David Black", "Septimiu Salcudean"], "title": "Robotic versus Human Teleoperation for Remote Ultrasound", "comment": "Under review at IEEE TMRB. Extended version of a paper presented at the Hamlyn Symposium for Medical Robotics, 2025", "summary": "Diagnostic medical ultrasound is widely used, safe, and relatively low cost but requires a high degree of expertise to acquire and interpret the images. Personnel with this expertise are often not available outside of larger cities, leading to difficult, costly travel and long wait times for rural populations. To address this issue, tele-ultrasound techniques are being developed, including robotic teleoperation and recently human teleoperation, in which a novice user is remotely guided in a hand-over-hand manner through mixed reality to perform an ultrasound exam. These methods have not been compared, and their relative strengths are unknown. Human teleoperation may be more practical than robotics for small communities due to its lower cost and complexity, but this is only relevant if the performance is comparable. This paper therefore evaluates the differences between human and robotic teleoperation, examining practical aspects such as setup time and flexibility and experimentally comparing performance metrics such as completion time, position tracking, and force consistency. It is found that human teleoperation does not lead to statistically significant differences in completion time or position accuracy, with mean differences of 1.8% and 0.5%, respectively, and provides more consistent force application despite being substantially more practical and accessible."}
{"id": "2511.07292", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07292", "abs": "https://arxiv.org/abs/2511.07292", "authors": ["Simon Gerstenecker", "Andreas Geiger", "Katrin Renz"], "title": "PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving", "comment": null, "summary": "Most recent work in autonomous driving has prioritized benchmark performance and methodological innovation over in-depth analysis of model failures, biases, and shortcut learning. This has led to incremental improvements without a deep understanding of the current failures. While it is straightforward to look at situations where the model fails, it is hard to understand the underlying reason. This motivates us to conduct a systematic study, where inputs to the model are perturbed and the predictions observed. We introduce PlanT 2.0, a lightweight, object-centric planning transformer designed for autonomous driving research in CARLA. The object-level representation enables controlled analysis, as the input can be easily perturbed (e.g., by changing the location or adding or removing certain objects), in contrast to sensor-based models. To tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0, we introduce multiple upgrades to PlanT, achieving state-of-the-art performance on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis exposes insightful failures, such as a lack of scene understanding caused by low obstacle diversity, rigid expert behaviors leading to exploitable shortcuts, and overfitting to a fixed set of expert trajectories. Based on these findings, we argue for a shift toward data-centric development, with a focus on richer, more robust, and less biased datasets. We open-source our code and model at https://github.com/autonomousvision/plant2."}
{"id": "2511.07306", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.07306", "abs": "https://arxiv.org/abs/2511.07306", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Het 'right to be forgotten' en bijzondere persoonsgegevens: geen ruimte meer voor een belangenafweging? [The 'Right to Be Forgotten' and Sensitive Personal Data: No Room for Balancing?]", "comment": "In Dutch", "summary": "An attorney submitted a 'right to be forgotten' delisting request to Google, regarding a blog post about a criminal conviction of the attorney in another country. The Rotterdam District Court ruled that Google may no longer link to the blog post when people search for the attorney's name. The court granted the attorney's request because the blog post concerns a criminal conviction. Personal data regarding criminal convictions are, under Dutch law, special categories of data (sometimes called sensitive data). The reasoning of the court on special categories of data creates problems for freedom of expression. This paper, in Dutch, explores how these problems can be reduced. Google has appealed the decision; the judgment of the Court of Appeals is expected in March 2017."}
{"id": "2511.07307", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.07307", "abs": "https://arxiv.org/abs/2511.07307", "authors": ["Frederik J. Zuiderveen Borgesius"], "title": "Singling out people without knowing their names - Behavioural targeting, pseudonymous data, and the New Data Protection Regulation", "comment": null, "summary": "Information about millions of people is collected for behavioural targeting, a type of marketing that involves tracking people's online behaviour for targeted advertising. It is hotly debated whether data protection law applies to behavioural targeting. Many behavioural targeting companies say that, as long as they do not tie names to data they hold about individuals, they do not process any personal data, and that, therefore, data protection law does not apply to them. European Data Protection Authorities, however, take the view that a company processes personal data if it uses data to single out a person, even if it cannot tie a name to these data. This paper argues that data protection law should indeed apply to behavioural targeting. Companies can often tie a name to nameless data about individuals. Furthermore, behavioural targeting relies on collecting information about individuals, singling out individuals, and targeting ads to individuals. Many privacy risks remain, regardless of whether companies tie a name to the information they hold about a person. A name is merely one of the identifiers that can be tied to data about a person, and it is not even the most practical identifier for behavioural targeting. Seeing data used to single out a person as personal data fits the rationale for data protection law: protecting fairness and privacy."}
{"id": "2511.07323", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07323", "abs": "https://arxiv.org/abs/2511.07323", "authors": ["Papa Yaw Owusu-Obeng", "Mai Shi", "Max Vanatta", "Michael T. Craig"], "title": "Beyond Prime Farmland: Solar Siting Tradeoffs for Cost-Effective Decarbonization", "comment": "16 pages, 4 figures", "summary": "The feasibility and cost-effectiveness of continued growth in solar photovoltaics are closely tied to siting decisions. But trade-offs between costs and technical potential between land categories, especially brownfields and rooftop sites, have not been quantified, despite increasing resistance to and policy interest in reducing use of greenfield sites (e.g., prime agricultural lands). We examine the effect of siting decisions across land types for utility-scale and rooftop PV on the feasibility and cost of meeting solar deployment targets across the Eastern U.S. We build a database of solar PV supply curves by land type for each county in the Eastern Interconnect (EI) region (~2,400 counties). Our supply curves quantify technical potential versus levelized cost across greenfield, brownfield, and rooftop land types. With these supply curves and a 2035 solar deployment target (435 GW) aligned with a decarbonized power system, we quantify cost and capacity trade-offs using scenarios that prioritize solar PV deployment on different land types. We find greenfield, particularly prime agriculture, sites offer the lowest levelized costs for meeting capacity targets, of 39 to 57 $/MWh. Contaminated lands, often prioritized in policy to reduce land use conflict, have limited technical potential and impose a cost premium of 14-33% relative to greenfield sites. Rooftop PV provides enough technical potential for meeting capacity targets but comes at consistently higher costs, with minimum LCOEs of roughly 70 $/MWh or well above the highest-cost greenfield sites. Our results detail heterogeneous siting trade-offs across the Eastern United States, enabling targeted policy design to meet deployment targets while balancing costs and land use conflicts."}
{"id": "2511.07327", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07327", "abs": "https://arxiv.org/abs/2511.07327", "authors": ["Guoxin Chen", "Zile Qiao", "Xuanzhong Chen", "Donglei Yu", "Haotian Xu", "Wayne Xin Zhao", "Ruihua Song", "Wenbiao Yin", "Huifeng Yin", "Liwen Zhang", "Kuan Li", "Minpeng Liao", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "title": "IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction", "comment": "https://github.com/Alibaba-NLP/DeepResearch", "summary": "Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\\% to 42.5\\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models."}
{"id": "2511.07335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.07335", "abs": "https://arxiv.org/abs/2511.07335", "authors": ["Marcel Menner", "Eugene Lavretsky"], "title": "Robust Linear Design for Flight Control Systems with Operational Constraints", "comment": null, "summary": "This paper presents a systematic approach for designing robust linear proportional-integral (PI) servo-controllers that effectively manage control input and output constraints in flight control systems. The control design leverages the Nagumo Theorem and the Comparison Lemma to prove constraint satisfaction, while employing min-norm optimal controllers in a manner akin to Control Barrier Functions. This results in a continuous piecewise-linear state feedback policy that maintains the analyzability of the closed-loop system through the principles of linear systems theory. Additionally, we derive multi-input multi-output (MIMO) robustness margins, demonstrating that our approach enables robust tracking of external commands even in the presence of operational constraints. Moreover, the proposed control design offers a systematic approach for anti-windup protection. Through flight control trade studies, we illustrate the applicability of the proposed framework to real-world safety-critical aircraft control scenarios. Notably, MIMO margin analysis with active constraints reveals that our method preserves gain and phase margins comparable to those of the unconstrained case, in contrast to controllers that rely on hard saturation heuristics, which suffer significant performance degradation under active constraints. Simulation results using a nonlinear six-degree-of-freedom rigid body aircraft model further validate the effectiveness of our method in achieving constraint satisfaction, robustness, and effective anti-windup protection."}
{"id": "2511.07338", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07338", "abs": "https://arxiv.org/abs/2511.07338", "authors": ["Zhen Wang", "Yufan Zhou", "Zhongyan Luo", "Lyumanshan Ye", "Adam Wood", "Man Yao", "Luoshang Pan"], "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas", "comment": "12 pages, 5 figures, accepted at LAW 2025 Workshop (NeurIPS 2025)", "summary": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research."}
{"id": "2511.07363", "categories": ["eess.SY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.07363", "abs": "https://arxiv.org/abs/2511.07363", "authors": ["Cayetana Salinas Rodriguez", "Jonathan Rogers", "Sarah H. Q. Li"], "title": "When the Correct Model Fails: The Optimality of Stackelberg Equilibria with Follower Intention Updates", "comment": "9 pages, 6 figures, conference submission", "summary": "We study a two-player dynamic Stackelberg game between a leader and a follower. Classical formulations of the Stackelberg equilibrium (SE) assume that the follower's best response (BR) mapping is known to the leader. However, this is not always true in practice. In those cases the leader needs to simultaneously infer this BR function while fulfilling an internal objective. We study a setting in which the leader selects a control strategy that optimizes an objective given an initial belief about the follower's best response. This belief is updated during the finite decision horizon, prompting the leader to reoptimize its control. We characterize the optimality guarantees of the SE solutions under this belief update for both open loop (OL) and feedback (FB) information structures. In particular, we show that it is possible that assuming an incorrect follower BR map obtains a lower cost over the game horizon than knowing the true BR. We support these claims with numerical examples in a linear quadratic (LQ) Stackelberg game."}
{"id": "2511.07375", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07375", "abs": "https://arxiv.org/abs/2511.07375", "authors": ["Shaohang Han", "Joris Verhagen", "Jana Tumova"], "title": "Exact Smooth Reformulations for Trajectory Optimization Under Signal Temporal Logic Specifications", "comment": null, "summary": "We study motion planning under Signal Temporal Logic (STL), a useful formalism for specifying spatial-temporal requirements. We pose STL synthesis as a trajectory optimization problem leveraging the STL robustness semantics. To obtain a differentiable problem without approximation error, we introduce an exact reformulation of the max and min operators. The resulting method is exact, smooth, and sound. We validate it in numerical simulations, demonstrating its practical performance."}
{"id": "2511.07381", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07381", "abs": "https://arxiv.org/abs/2511.07381", "authors": ["Yizhe Zhu", "Zhang Ye", "Boce Hu", "Haibo Zhao", "Yu Qi", "Dian Wang", "Robert Platt"], "title": "Residual Rotation Correction using Tactile Equivariance", "comment": "8 pages", "summary": "Visuotactile policy learning augments vision-only policies with tactile input, facilitating contact-rich manipulation. However, the high cost of tactile data collection makes sample efficiency the key requirement for developing visuotactile policies. We present EquiTac, a framework that exploits the inherent SO(2) symmetry of in-hand object rotation to improve sample efficiency and generalization for visuotactile policy learning. EquiTac first reconstructs surface normals from raw RGB inputs of vision-based tactile sensors, so rotations of the normal vector field correspond to in-hand object rotations. An SO(2)-equivariant network then predicts a residual rotation action that augments a base visuomotor policy at test time, enabling real-time rotation correction without additional reorientation demonstrations. On a real robot, EquiTac accurately achieves robust zero-shot generalization to unseen in-hand orientations with very few training samples, where baselines fail even with more training data. To our knowledge, this is the first tactile learning method to explicitly encode tactile equivariance for policy learning, yielding a lightweight, symmetry-aware module that improves reliability in contact-rich tasks."}
{"id": "2511.07407", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07407", "abs": "https://arxiv.org/abs/2511.07407", "authors": ["Zhengjie Xu", "Ye Li", "Kwan-yee Lin", "Stella X. Yu"], "title": "Unified Humanoid Fall-Safety Policy from a Few Demonstrations", "comment": null, "summary": "Falling is an inherent risk of humanoid mobility. Maintaining stability is thus a primary safety focus in robot control and learning, yet no existing approach fully averts loss of balance. When instability does occur, prior work addresses only isolated aspects of falling: avoiding falls, choreographing a controlled descent, or standing up afterward. Consequently, humanoid robots lack integrated strategies for impact mitigation and prompt recovery when real falls defy these scripts. We aim to go beyond keeping balance to make the entire fall-and-recovery process safe and autonomous: prevent falls when possible, reduce impact when unavoidable, and stand up when fallen. By fusing sparse human demonstrations with reinforcement learning and an adaptive diffusion-based memory of safe reactions, we learn adaptive whole-body behaviors that unify fall prevention, impact mitigation, and rapid recovery in one policy. Experiments in simulation and on a Unitree G1 demonstrate robust sim-to-real transfer, lower impact forces, and consistently fast recovery across diverse disturbances, pointing towards safer, more resilient humanoids in real environments. Videos are available at https://firm2025.github.io/."}
{"id": "2511.07410", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07410", "abs": "https://arxiv.org/abs/2511.07410", "authors": ["Hao Wang", "Sathwik Karnik", "Bea Lim", "Somil Bansal"], "title": "Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective", "comment": null, "summary": "Large Language Models (LLMs) and Vision Language Models (VLMs) have been widely used for embodied symbolic planning. Yet, how to effectively use these models for closed-loop symbolic planning remains largely unexplored. Because they operate as black boxes, LLMs and VLMs can produce unpredictable or costly errors, making their use in high-level robotic planning especially challenging. In this work, we investigate how to use VLMs as closed-loop symbolic planners for robotic applications from a control-theoretic perspective. Concretely, we study how the control horizon and warm-starting impact the performance of VLM symbolic planners. We design and conduct controlled experiments to gain insights that are broadly applicable to utilizing VLMs as closed-loop symbolic planners, and we discuss recommendations that can help improve the performance of VLM symbolic planners."}
{"id": "2511.07413", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07413", "abs": "https://arxiv.org/abs/2511.07413", "authors": ["Yuxuan Sun", "Manchen Wang", "Shengyi Qian", "William R. Wong", "Eric Gan", "Pierluca D'Oro", "Alejandro Castillejo Munoz", "Sneha Silwal", "Pedro Matias", "Nitin Kamra", "Satwik Kottur", "Nick Raines", "Xuanyi Zhao", "Joy Chen", "Joseph Greer", "Andrea Madotto", "Allen Bolourchi", "James Valori", "Kevin Carlberg", "Karl Ridgeway", "Joseph Tighe"], "title": "DigiData: Training and Evaluating General-Purpose Mobile Control Agents", "comment": "Website: https://facebookresearch.github.io/DigiData", "summary": "AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions."}
{"id": "2511.07416", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07416", "abs": "https://arxiv.org/abs/2511.07416", "authors": ["Jiageng Mao", "Sicheng He", "Hao-Ning Wu", "Yang You", "Shuyang Sun", "Zhicheng Wang", "Yanan Bao", "Huizhong Chen", "Leonidas Guibas", "Vitor Guizilini", "Howard Zhou", "Yue Wang"], "title": "Robot Learning from a Physical World Model", "comment": "Project page: https://pointscoder.github.io/PhysWorld_Web/", "summary": "We introduce PhysWorld, a framework that enables robot learning from video generation through physical world modeling. Recent video generation models can synthesize photorealistic visual demonstrations from language commands and images, offering a powerful yet underexplored source of training signals for robotics. However, directly retargeting pixel motions from generated videos to robots neglects physics, often resulting in inaccurate manipulations. PhysWorld addresses this limitation by coupling video generation with physical world reconstruction. Given a single image and a task command, our method generates task-conditioned videos and reconstructs the underlying physical world from the videos, and the generated video motions are grounded into physically accurate actions through object-centric residual reinforcement learning with the physical world model. This synergy transforms implicit visual guidance into physically executable robotic trajectories, eliminating the need for real robot data collection and enabling zero-shot generalizable robotic manipulation. Experiments on diverse real-world tasks demonstrate that PhysWorld substantially improves manipulation accuracy compared to previous approaches. Visit \\href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage} for details."}
{"id": "2511.07418", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.DC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.07418", "abs": "https://arxiv.org/abs/2511.07418", "authors": ["Zhao-Heng Yin", "Pieter Abbeel"], "title": "Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields", "comment": "Code: https://github.com/zhaohengyin/lightning-grasp", "summary": "Despite years of research, real-time diverse grasp synthesis for dexterous hands remains an unsolved core challenge in robotics and computer graphics. We present Lightning Grasp, a novel high-performance procedural grasp synthesis algorithm that achieves orders-of-magnitude speedups over state-of-the-art approaches, while enabling unsupervised grasp generation for irregular, tool-like objects. The method avoids many limitations of prior approaches, such as the need for carefully tuned energy functions and sensitive initialization. This breakthrough is driven by a key insight: decoupling complex geometric computation from the search process via a simple, efficient data structure - the Contact Field. This abstraction collapses the problem complexity, enabling a procedural search at unprecedented speeds. We open-source our system to propel further innovation in robotic manipulation."}
{"id": "2511.05508", "categories": ["q-fin.GN", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.05508", "abs": "https://arxiv.org/abs/2511.05508", "authors": ["Tianyi Zhang", "Mu Chen"], "title": "Personalized Chain-of-Thought Summarization of Financial News for Investor Decision Support", "comment": "ICDM SENTIRE 2025", "summary": "Financial advisors and investors struggle with information overload from financial news, where irrelevant content and noise obscure key market signals and hinder timely investment decisions. To address this, we propose a novel Chain-of-Thought (CoT) summarization framework that condenses financial news into concise, event-driven summaries. The framework integrates user-specified keywords to generate personalized outputs, ensuring that only the most relevant contexts are highlighted. These personalized summaries provide an intermediate layer that supports language models in producing investor-focused narratives, bridging the gap between raw news and actionable insights."}
{"id": "2511.06545", "categories": ["econ.GN", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06545", "abs": "https://arxiv.org/abs/2511.06545", "authors": ["Ruiqing Cao", "Abhishek Bhatia"], "title": "How Founder Expertise Shapes the Impact of Generative Artificial Intelligence on Digital Ventures", "comment": null, "summary": "The rapid diffusion of generative artificial intelligence (GenAI) has substantially lowered the costs of launching and developing digital ventures. GenAI can potentially both enable previously unviable entrepreneurial ideas by lowering resource needs and improve the performance of existing ventures. We explore how founders' technical and managerial expertise shapes GenAI's impact on digital ventures along these dimensions. Exploiting exogenous variation in GenAI usage across venture categories and the timing of its broad availability for software tasks (e.g., GitHub Copilot's public release and subsequent GenAI tools), we find that the number of new venture launches increased and the median time to launch decreased significantly more in categories with relatively high GenAI usage. GenAI's effect on new launches is larger for founders without managerial experience or education, while its effect on venture capital (VC) funding likelihood is stronger for founders with technical experience or education. Overall, our results suggest that GenAI expands access to digital entrepreneurship for founders lacking managerial expertise and enhances venture performance among technical founders."}
{"id": "2511.07038", "categories": ["stat.AP", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.07038", "abs": "https://arxiv.org/abs/2511.07038", "authors": ["Kizito Salako", "Rabiu Tsoho Muhammad"], "title": "Conservative Software Reliability Assessments Using Collections of Bayesian Inference Problems", "comment": null, "summary": "When using Bayesian inference to support conservative software reliability assessments, it is useful to consider a collection of Bayesian inference problems, with the aim of determining the worst-case value (from this collection) for a posterior predictive probability that characterizes how reliable the software is. Using a Bernoulli process to model the occurrence of software failures, we explicitly determine (from collections of Bayesian inference problems) worst-case posterior predictive probabilities of the software operating without failure in the future. We deduce asymptotic properties of these conservative posterior probabilities and their priors, and illustrate how to use these results in assessments of safety-critical software. This work extends robust Bayesian inference results and so-called conservative Bayesian inference methods."}
{"id": "2511.07280", "categories": ["econ.GN", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07280", "abs": "https://arxiv.org/abs/2511.07280", "authors": ["Kevin Zielnicki", "Guy Aridor", "Aurélien Bibaut", "Allen Tran", "Winston Chou", "Nathan Kallus"], "title": "The Value of Personalized Recommendations: Evidence from Netflix", "comment": null, "summary": "Personalized recommendation systems shape much of user choice online, yet their targeted nature makes separating out the value of recommendation and the underlying goods challenging. We build a discrete choice model that embeds recommendation-induced utility, low-rank heterogeneity, and flexible state dependence and apply the model to viewership data at Netflix. We exploit idiosyncratic variation introduced by the recommendation algorithm to identify and separately value these components as well as to recover model-free diversion ratios that we can use to validate our structural model. We use the model to evaluate counterfactuals that quantify the incremental engagement generated by personalized recommendations. First, we show that replacing the current recommender system with a matrix factorization or popularity-based algorithm would lead to 4% and 12% reduction in engagement, respectively, and decreased consumption diversity. Second, most of the consumption increase from recommendations comes from effective targeting, not mechanical exposure, with the largest gains for mid-popularity goods (as opposed to broadly appealing or very niche goods)."}
