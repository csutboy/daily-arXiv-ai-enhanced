<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 18]
- [cs.CY](#cs.CY) [Total: 8]
- [econ.EM](#econ.EM) [Total: 3]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.SI](#cs.SI) [Total: 5]
- [stat.AP](#stat.AP) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Discovering Differences in Strategic Behavior Between Humans and LLMs](https://arxiv.org/abs/2602.10324)
*Caroline Wang,Daniel Kasenberg,Kim Stachenfeld,Pablo Samuel Castro*

Main category: cs.AI

TL;DR: 使用AlphaEvolve工具发现人类与LLM在战略互动中的行为差异，发现前沿LLM在剪刀石头布游戏中展现出比人类更深层的战略行为


<details>
  <summary>Details</summary>
Motivation: 随着LLM在社交和战略场景中部署增加，需要理解其行为与人类的差异。现有行为博弈理论模型无法完全捕捉人类或LLM等黑箱代理的独特行为

Method: 使用AlphaEvolve程序发现工具，直接从数据中发现人类和LLM行为的可解释模型，实现开放式发现驱动行为的结构因素

Result: 在迭代剪刀石头布游戏中，前沿LLM展现出比人类更深层的战略行为能力

Conclusion: 为理解人类与LLM在战略互动中行为差异的结构性因素提供了基础

Abstract: As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture the idiosyncratic behavior of humans or black-box, non-human agents like LLMs. We employ AlphaEvolve, a cutting-edge program discovery tool, to directly discover interpretable models of human and LLM behavior from data, thereby enabling open-ended discovery of structural factors driving human and LLM behavior. Our analysis on iterated rock-paper-scissors reveals that frontier LLMs can be capable of deeper strategic behavior than humans. These results provide a foundation for understanding structural differences driving differences in human and LLM behavior in strategic interactions.

</details>


### [2] [LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation](https://arxiv.org/abs/2602.10367)
*Zhiling Yan,Dingjie Song,Zhe Fang,Yisheng Ji,Xiang Li,Quanzheng Li,Lichao Sun*

Main category: cs.AI

TL;DR: LiveMedBench：一个持续更新、无数据污染、基于量规的临床基准，通过每周从在线医疗社区收集真实病例，解决现有医学基准的静态性、数据污染和时间错位问题。


<details>
  <summary>Details</summary>
Motivation: 现有医学基准存在两个关键局限：1) 数据污染（测试集意外泄露到训练数据中导致性能估计虚高）；2) 时间错位（无法捕捉医学知识的快速演变）。此外，当前开放式临床推理的评估指标要么依赖浅层词汇重叠（如ROUGE），要么依赖主观的LLM-as-a-Judge评分，都不足以验证临床正确性。

Method: 1) 构建LiveMedBench基准：每周从在线医疗社区收集真实临床病例，确保与模型训练数据的严格时间分离；2) 多智能体临床筛选框架：过滤原始数据噪声，根据循证医学原则验证临床完整性；3) 自动化量规评估框架：将医生回答分解为细粒度、病例特定的标准，实现比LLM-as-a-Judge更强的专家对齐。

Result: LiveMedBench包含2,756个真实病例，涵盖38个医学专业和多种语言，配有16,702个独特评估标准。对38个LLM的广泛评估显示：最佳模型仅达到39.2%的准确率；84%的模型在截止日期后的病例上表现下降，证实了普遍的数据污染风险。错误分析进一步表明，上下文应用（而非事实知识）是主要瓶颈，35-48%的失败源于无法将医学知识适应患者特定约束。

Conclusion: LiveMedBench为临床LLM评估提供了一个更可靠、动态的基准，揭示了数据污染的普遍风险和当前模型在临床推理中的主要局限（上下文应用能力不足），强调了开发能够适应患者特定约束的临床AI系统的重要性。

Abstract: The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.

</details>


### [3] [Found-RL: foundation model-enhanced reinforcement learning for autonomous driving](https://arxiv.org/abs/2602.10458)
*Yansong Qu,Zihao Sheng,Zilin Huang,Jiancong Chen,Yuhao Luo,Tianyi Wang,Yiheng Feng,Samuel Labi,Sikai Chen*

Main category: cs.AI

TL;DR: Found-RL是一个专门用于自动驾驶的强化学习平台，通过异步批量推理框架解决视觉语言模型推理延迟问题，结合多种监督机制将VLM知识蒸馏到轻量级RL策略中，实现接近VLM性能的实时推理。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自动驾驶中面临样本效率低和语义可解释性不足的问题，而基础模型（特别是视觉语言模型）虽然能提供丰富的上下文知识，但其高推理延迟阻碍了在高频RL训练循环中的部署。

Method: 提出异步批量推理框架解耦VLM推理与仿真循环；引入价值边际正则化和优势加权动作指导来蒸馏VLM动作建议；采用高吞吐量CLIP进行密集奖励塑造，并通过条件对比动作对齐解决CLIP的动态盲区问题。

Result: 轻量级RL模型能够实现接近十亿参数VLM的性能，同时保持实时推理（约500 FPS），有效解决了VLM推理延迟瓶颈。

Conclusion: Found-RL为微调VLM集成提供了端到端管道，展示了轻量级RL模型在保持实时性能的同时，能够有效利用基础模型知识提升自动驾驶强化学习的效率和性能。

Abstract: Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy. Additionally, we adopt high-throughput CLIP for dense reward shaping. We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS). Code, data, and models will be publicly available at https://github.com/ys-qu/found-rl.

</details>


### [4] [MERIT Feedback Elicits Better Bargaining in LLM Negotiators](https://arxiv.org/abs/2602.10467)
*Jihwan Oh,Murad Aghazada,Yooju Shin,Se-Young Yun,Taehyeon Kim*

Main category: cs.AI

TL;DR: 提出了AgoraBench基准测试和基于效用反馈的框架，通过人类偏好对齐和经济指标来增强LLM的谈判能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在谈判中表现不佳，现有基准测试难以捕捉其战略深度不足和适应复杂人类因素困难的问题

Method: 1) 创建AgoraBench基准，包含九个挑战性场景；2) 基于效用理论设计人类对齐的经济指标；3) 构建人类偏好数据集和学习流程，通过提示和微调增强LLM谈判能力

Result: 基线LLM策略常偏离人类偏好，而提出的机制显著提升谈判性能，产生更深层的战略行为和更强的对手意识

Conclusion: 通过效用反馈框架和人类偏好对齐，可以有效增强LLM的谈判能力，使其更接近人类谈判策略

Abstract: Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g., deception, monopoly) that supports diverse strategy modeling; (ii) human-aligned, economically grounded metrics derived from utility theory. This is operationalized via agent utility, negotiation power, and acquisition ratio that implicitly measure how well the negotiation aligns with human preference and (iii) a human preference grounded dataset with learning pipeline that strengthens LLMs' bargaining ability through both prompting and finetuning. Empirical results indicate that baseline LLM strategies often diverge from human preferences, while our mechanism substantially improves negotiation performance, yielding deeper strategic behavior and stronger opponent awareness.

</details>


### [5] [Abstraction Generation for Generalized Planning with Pretrained Large Language Models](https://arxiv.org/abs/2602.10485)
*Zhenhe Cui,Huaxiang Xia,Hangjun Shen,Kailun Luo,Yong He,Wei Liang*

Main category: cs.AI

TL;DR: LLMs能够作为QNP抽象生成器用于广义规划问题，通过自动调试方法修正抽象错误


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能够作为QNP抽象生成器来解决广义规划问题，以及如何通过自动调试来修正生成的抽象

Method: 提出提示协议：输入GP领域和训练任务给LLMs，让它们生成抽象特征并将初始状态、动作集和目标抽象为QNP问题；设计自动调试方法来检测抽象错误并指导LLMs修正

Result: 实验表明，在自动调试的适当指导下，某些LLMs能够生成有用的QNP抽象

Conclusion: LLMs可以作为QNP抽象生成器用于广义规划，自动调试方法能够有效修正抽象错误，提高抽象质量

Abstract: Qualitative Numerical Planning (QNP) serves as an important abstraction model for generalized planning (GP), which aims to compute general plans that solve multiple instances at once. Recent works show that large language models (LLMs) can function as generalized planners. This work investigates whether LLMs can serve as QNP abstraction generators for GP problems and how to fix abstractions via automated debugging. We propose a prompt protocol: input a GP domain and training tasks to LLMs, prompting them to generate abstract features and further abstract the initial state, action set, and goal into QNP problems. An automated debugging method is designed to detect abstraction errors, guiding LLMs to fix abstractions. Experiments demonstrate that under properly guided by automated debugging, some LLMs can generate useful QNP abstractions.

</details>


### [6] [Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets](https://arxiv.org/abs/2602.10583)
*Bo Xue,Yunchong Song,Fanghao Shao,Xuekai Zhu,Lin Chen,Luoyi Fu,Xinbing Wang,Zhouhan Lin*

Main category: cs.AI

TL;DR: FoSS提出基于GFlowNets的span生成框架，通过动态span词汇和DAG状态空间提升文本生成的多样性和质量


<details>
  <summary>Details</summary>
Motivation: 传统自回归语言模型使用固定词汇表，形成树状状态空间，限制了灵活性和表达能力。现有动态词汇方法虽然引入检索文本片段，但忽略了同一句子可由不同长度片段组成，缺乏对DAG状态空间的显式建模，导致组合路径探索受限且存在路径选择偏差。

Method: 提出Flow of SpanS (FoSS)框架：1) 通过灵活分割检索文本构建动态span词汇表；2) 确保DAG结构状态空间；3) 利用GFlowNets探索多样组合路径；4) 结合专用奖励模型生成高质量文本。

Result: FoSS在文本生成任务上MAUVE分数比Transformer提升高达12.5%，在知识密集型任务上获得3.5%增益，持续优于最先进方法。扩展实验显示FoSS受益于更大模型、更多数据和更丰富检索语料库。

Conclusion: FoSS通过将GFlowNets应用于span生成，构建DAG状态空间，有效解决了传统方法在组合路径探索上的限制，显著提升了文本生成的多样性和质量，具有良好的扩展性。

Abstract: Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.

</details>


### [7] [Neuro-symbolic Action Masking for Deep Reinforcement Learning](https://arxiv.org/abs/2602.10598)
*Shuai Han,Mehdi Dastani,Shihan Wang*

Main category: cs.AI

TL;DR: NSAM是一个神经符号动作屏蔽框架，能自动学习与高维状态约束一致的符号模型，在DRL过程中以最小监督方式学习动作屏蔽，排除不可行动作，提高样本效率并减少约束违反。


<details>
  <summary>Details</summary>
Motivation: 现有DRL方法在训练和执行过程中可能探索不可行的动作。现有方法假设存在将高维状态映射到一致符号表示的符号基础函数，并需要手动指定动作屏蔽技术来约束动作。

Method: 提出神经符号动作屏蔽（NSAM）框架，在DRL过程中以最小监督方式自动学习与给定领域约束一致的符号模型。基于学习到的状态符号模型，NSAM学习排除不可行动作的动作屏蔽。实现符号推理和深度策略优化的端到端集成。

Result: 在多个有约束的领域上评估NSAM，实验结果表明NSAM显著提高了DRL智能体的样本效率，同时大幅减少了约束违反。

Conclusion: NSAM通过自动学习符号模型和动作屏蔽，实现了符号推理和深度策略优化的端到端集成，其中符号基础和改进的策略学习相互促进，有效解决了DRL中的动作约束问题。

Abstract: Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.

</details>


### [8] [To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks](https://arxiv.org/abs/2602.10625)
*Nanxu Gong,Haotian Li,Sixun Dong,Jianxun Lian,Yanjie Fu,Xing Xie*

Main category: cs.AI

TL;DR: 研究发现大型推理模型在心理理论任务上并不比非推理模型表现更好，有时甚至更差，揭示了推理模型在社交推理任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在数学和编程等正式推理任务上取得了进步，但尚不清楚这些优势是否能转移到心理理论等社交认知技能上，因此需要系统评估推理模型在心理理论任务上的表现。

Method: 对9个先进的大型语言模型进行系统研究，比较推理模型与非推理模型在三个代表性心理理论基准测试上的表现，并进行细粒度分析，设计两种干预方法（慢到快自适应推理和思考到匹配捷径预防）来验证和缓解问题。

Result: 推理模型并不一致优于非推理模型，有时表现更差。分析发现：1）慢思考崩溃：回答越长准确率显著下降；2）适度自适应推理有益；3）选项匹配捷径：移除选择题选项后推理模型表现显著改善。干预方法验证了这些问题。

Conclusion: 大型推理模型在正式推理（如数学、编程）方面的进步不能完全转移到心理理论这种典型的社交推理任务上。实现稳健的心理理论需要开发超越现有推理方法的独特能力。

Abstract: Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform non-reasoning models and sometimes perform worse. A fine-grained analysis reveals three insights. First, slow thinking collapses: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, moderate and adaptive reasoning benefits performance: constraining reasoning length mitigates failure, while distinct success patterns demonstrate the necessity of dynamic adaptation. Third, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. We also design two intervention approaches: Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention to further verify and mitigate the problems. With all results, our study highlights the advancement of LRMs in formal reasoning (e.g., math, code) cannot be fully transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods.

</details>


### [9] [OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization](https://arxiv.org/abs/2602.10635)
*Keane Ong,Sabri Boughorbel,Luwei Xiao,Chanakya Ekbote,Wei Dai,Ao Qu,Jingyao Wu,Rui Mao,Ehsan Hoque,Erik Cambria,Gianmarco Mengaldo,Paul Pu Liang*

Main category: cs.AI

TL;DR: HARPO是一种新的强化学习方法，通过调节优势函数来平衡异构任务和样本的学习，用于训练社交行为基础模型Omnisapiens-7B 2.0，在多项行为任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常孤立地建模人类行为维度（如情感、认知或社交属性），虽然有用但任务特定建模会增加训练成本并限制跨行为设置的泛化能力。最近的推理RL方法虽然能在多个行为任务上训练统一模型，但没有明确解决跨异构行为数据的学习问题。

Method: 提出异构感知相对策略优化（HARPO），这是一种RL方法，通过调节优势函数来确保在策略优化过程中没有任何单个任务或样本具有不成比例的影响力，从而平衡跨异构任务和样本的学习。

Result: 使用HARPO开发了Omnisapiens-7B 2.0社交行为处理基础模型。相对于现有行为基础模型，在多任务和保留设置上分别获得高达+16.85%和+9.37%的性能提升，同时产生更明确和鲁棒的推理轨迹。HARPO在与其他RL方法的比较中也表现出最一致强大的性能。

Conclusion: HARPO通过平衡跨异构任务和样本的学习，成功训练出性能优异的社交行为基础模型，为开发社交智能AI提供了有效方法。

Abstract: To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different heterogeneous behavioral data. To address this gap, we introduce Heterogeneity-Aware Relative Policy Optimization (HARPO), an RL method that balances leaning across heterogeneous tasks and samples. This is achieved by modulating advantages to ensure that no single task or sample carries disproportionate influence during policy optimization. Using HARPO, we develop and release Omnisapiens-7B 2.0, a foundation model for social behavior processing. Relative to existing behavioral foundation models, Omnisapiens-7B 2.0 achieves the strongest performance across behavioral tasks, with gains of up to +16.85% and +9.37% on multitask and held-out settings respectively, while producing more explicit and robust reasoning traces. We also validate HARPO against recent RL methods, where it achieves the most consistently strong performance across behavioral tasks.

</details>


### [10] [Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation](https://arxiv.org/abs/2602.10699)
*Jie Jiang,Yangru Huang,Zeyu Wang,Changping Wang,Yuling Xiong,Jun Zhang,Huan Yu*

Main category: cs.AI

TL;DR: V-STAR框架通过价值引导采样和树状优势强化解决生成式推荐中RL训练的概率-奖励不匹配问题，提升探索效率和多样性


<details>
  <summary>Details</summary>
Motivation: 生成式推荐的自回归模型在RL微调中存在概率-奖励不匹配问题：传统基于似然的解码（如束搜索）对局部高概率前缀存在短视偏见，导致探索不足（高奖励但低概率项目被过早剪枝）和优势压缩（共享高概率前缀的轨迹奖励高度相关，比较信号弱）

Method: 提出V-STAR框架，包含两个协同组件：1) 价值引导高效解码(VED)：识别关键节点并选择性深化高潜力前缀，无需穷举树搜索即可提升探索效率；2) Sibling-GRPO：利用诱导的树拓扑计算兄弟相对优势，将学习信号集中在关键分支决策上

Result: 在离线和在线数据集上的广泛实验表明，V-STAR在严格延迟约束下优于现有基线方法，提供更高的准确性和候选集多样性

Conclusion: V-STAR通过价值引导采样和树状优势强化有效解决了生成式推荐中RL训练的概率-奖励不匹配问题，实现了探索效率和多样性的平衡提升

Abstract: Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.

</details>


### [11] [Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act](https://arxiv.org/abs/2602.10802)
*Da-Lun Chen,Prasasthy Balasubramanian,Lauri Lovén,Susanna Pirttikangas,Jaakko Sauvola,Panagiotis Kostakos*

Main category: cs.AI

TL;DR: 该研究调查了高等教育中生成式AI的认知差异，特别关注ITEE领域，通过混合方法识别了共享和学科特定的主题，并提出了负责任整合的框架。


<details>
  <summary>Details</summary>
Motivation: 高等教育中生成式AI工具已被广泛采用，但利益相关者的认知存在分歧，受文化、学科和制度背景影响。欧盟AI法案要求大学确保认知系统的合规性，因此需要了解不同学科对GenAI的看法，以制定有效的整合策略。

Method: 采用混合方法，对奥卢大学ITEE学院的61名教职员工和37名学生进行了调查，分析他们对生成式AI的认知和态度。

Result: 研究揭示了共享和学科特定的主题：ITEE领域对GenAI在编程支持方面表现出强烈兴趣，但同时也担忧响应质量、隐私和学术诚信问题。研究识别了高层次需求并提出了负责任整合的概念框架。

Conclusion: 学科特定的需求强调了利益相关者参与的重要性。高层次需求和框架为大学利用GenAI提供了实用指导，同时解决了利益相关者关切并确保监管合规。

Abstract: Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.

</details>


### [12] [See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch](https://arxiv.org/abs/2602.10814)
*Xingyi Zhang,Yulei Ye,Kaifeng Huang,Wenhao Li,Xiangfeng Wang*

Main category: cs.AI

TL;DR: ScratchWorld是一个用于评估多模态GUI代理在Scratch中通过图形界面构建程序能力的基准测试，包含83个任务和两种交互模式，揭示了当前AI在精细GUI操作方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的AI代理评估主要关注代码生成，但通过图形用户界面（如Scratch）构建程序的能力评估仍然不足。需要建立一个系统性的基准来评估多模态GUI代理在低代码教育环境中的实际表现。

Method: 基于"使用-修改-创建"教学框架，设计了83个任务，分为创建、调试、扩展和计算四类。采用两种交互模式：原始模式（精细拖放操作）和组合模式（高级语义API）。通过浏览器环境中的运行时测试来验证程序功能正确性。

Result: 实验表明，当前最先进的多模态语言模型和GUI代理存在显著的推理-执行差距。尽管规划能力很强，但在精细的GUI操作方面仍然面临持续挑战。

Conclusion: ScratchWorld基准测试揭示了AI代理在通过GUI构建程序时的关键瓶颈，强调了需要同时提升推理能力和精细操作技能，为未来GUI代理的发展提供了重要方向。

Abstract: Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.

</details>


### [13] [SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy](https://arxiv.org/abs/2602.10845)
*Xuecheng Zou,Yu Tang,Bingbing Wang*

Main category: cs.AI

TL;DR: SynergyKGC是一个自适应知识图谱补全框架，通过跨模态协同专家和密度依赖的身份锚定策略，解决结构分辨率不匹配问题，显著提升KGC性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱补全方法面临"结构分辨率不匹配"问题：无法协调不同图密度下的表示需求，导致在密集区域产生结构噪声干扰，在稀疏区域出现灾难性表示崩溃。

Method: 提出SynergyKGC框架：1) 将传统邻居聚合提升为主动的跨模态协同专家，使用关系感知交叉注意力和语义意图驱动门控；2) 结合密度依赖的身份锚定策略；3) 采用双塔一致性架构，确保训练和推理阶段的表示稳定性。

Result: 在两个公共基准测试上的系统评估验证了方法的优越性，显著提升了KGC命中率，为非均匀结构化数据中的弹性信息集成提供了经验证据。

Conclusion: SynergyKGC通过自适应框架有效调和拓扑异质性，确保表示稳定性，为知识图谱补全中的弹性信息集成提供了通用原则。

Abstract: Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical "structural resolution mismatch," failing to reconcile divergent representational demands across varying graph densities, which precipitates structural noise interference in dense clusters and catastrophic representation collapse in sparse regions. We present SynergyKGC, an adaptive framework that advances traditional neighbor aggregation to an active Cross-Modal Synergy Expert via relation-aware cross-attention and semantic-intent-driven gating. By coupling a density-dependent Identity Anchoring strategy with a Double-tower Coherent Consistency architecture, SynergyKGC effectively reconciles topological heterogeneity while ensuring representational stability across training and inference phases. Systematic evaluations on two public benchmarks validate the superiority of our method in significantly boosting KGC hit rates, providing empirical evidence for a generalized principle of resilient information integration in non-homogeneous structured data.

</details>


### [14] [Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics](https://arxiv.org/abs/2602.10885)
*Leheng Sheng,Wenchang Ma,Ruixin Hong,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: 提出RLCER方法，通过自生成和自演化的评分标准来奖励思维链推理，无需人工标注，优于基于结果的强化学习方法


<details>
  <summary>Details</summary>
Motivation: 思维链在LLM推理中至关重要，但直接奖励思维链很困难：训练奖励模型需要大量人工标注，静态奖励模型难以适应思维链分布变化且容易发生奖励攻击。需要一种无需人工标注且能逐步演化的自主奖励方法。

Method: 提出RLCER方法，通过自生成和自演化的评分标准来监督思维链，增强基于结果的RLVR方法。该方法能提供可靠的思维链监督信号，即使没有结果奖励也能工作。

Result: RLCER方法优于基于结果的RLVR方法。此外，当将这些自生成的评分标准用作提示中的提示时，能进一步提高推理时的性能。

Conclusion: 自生成和自演化的评分标准能为思维链提供可靠的监督信号，无需人工标注，并能逐步演化适应变化，在强化学习框架中有效提升模型性能。

Abstract: Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \textbf{RLCER} (\textbf{R}einforcement \textbf{L}earning with \textbf{C}oT Supervision via Self-\textbf{E}volving \textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.

</details>


### [15] [Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation](https://arxiv.org/abs/2602.10964)
*F. Carichon,R. Rampa,G. Farnadi*

Main category: cs.AI

TL;DR: LLMs在文化适应方面表现不佳，特别是在烹饪食谱生成中，无法产生真正具有文化代表性的内容，其生成内容与文化距离不相关。


<details>
  <summary>Details</summary>
Motivation: LLMs被广泛用于生成文化内容，但存在系统性文化偏见问题，可能导致刻板印象、同质化和文化表达形式的消失。研究LLMs是否能真正适应多元文化，特别是非主流文化，是一个重要挑战。

Method: 使用GlobalFusion数据集，该数据集根据文化距离测量配对不同国家的人类食谱。使用相同的国家配对，用多个LLMs生成文化适应的食谱，直接比较人类和LLM在跨文化内容创作中的行为。

Result: LLMs无法产生具有文化代表性的适应内容。与人类不同，LLMs生成的食谱差异与文化距离不相关。文化信息在模型内部表示中保存较弱，模型通过误解创造性和传统等概念来夸大新颖性，无法将适应内容与相关国家联系起来，也无法将其建立在文化显著元素（如食材）上。

Conclusion: 当前LLMs在文化导向的生成方面存在根本性限制，这对它们在文化敏感应用中的使用具有重要影响。

Abstract: Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising concerns about stereotyping, homogenization, and the erasure of culturally specific forms of expression. Understanding whether LLMs can meaningfully align with diverse cultures beyond the dominant ones remains a critical challenge. In this paper, we study cultural adaptation in LLMs through the lens of cooking recipes, a domain in which culture, tradition, and creativity are tightly intertwined. We build on the \textit{GlobalFusion} dataset, which pairs human recipes from different countries according to established measures of cultural distance. Using the same country pairs, we generate culturally adapted recipes with multiple LLMs, enabling a direct comparison between human and LLM behavior in cross-cultural content creation. Our analysis shows that LLMs fail to produce culturally representative adaptations. Unlike humans, the divergence of their generated recipes does not correlate with cultural distance. We further provide explanations for this gap. We show that cultural information is weakly preserved in internal model representations, that models inflate novelty in their production by misunderstanding notions such as creativity and tradition, and that they fail to identify adaptation with its associated countries and to ground it in culturally salient elements such as ingredients. These findings highlight fundamental limitations of current LLMs for culturally oriented generation and have important implications for their use in culturally sensitive applications.

</details>


### [16] [CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion](https://arxiv.org/abs/2602.10999)
*Yusong Lin,Haiyang Wang,Shuzhe Wu,Lue Fan,Feiyang Pan,Sanyuan Zhao,Dandan Tu*

Main category: cs.AI

TL;DR: 提出CLI-Gym方法，通过模拟环境历史来大规模生成环境密集型任务，并训练出LiberCoder模型在终端任务上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 智能体编码需要与运行时环境（如命令行界面）有效交互，但目前缺乏大规模获取环境密集型任务的方法来增强智能体能力

Method: 基于Dockerfile与智能体任务的类比，提出CLI-Gym方法：利用智能体模拟探索环境历史，通过追踪健康环境的历史，将其状态反转到早期存在运行时故障的状态，从而生成包含错误状态和相应错误信息的任务

Result: 生成了1,655个环境密集型任务，是目前同类任务的最大集合；通过精选的成功轨迹微调的LiberCoder模型在Terminal-Bench上取得了+21.1%的绝对提升（达到46.1%），超越了多个强基线

Conclusion: 这是首个公开的用于大规模推导环境密集型任务的流程，为解决智能体与环境交互的挑战提供了有效方案

Abstract: Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by execution feedback. By tracing histories of a healthy environment, its state can be inverted to an earlier one with runtime failures, from which a task can be derived by packing the buggy state and the corresponding error messages. With our method, named CLI-Gym, a total of 1,655 environment-intensive tasks are derived, being the largest collection of its kind. Moreover, with curated successful trajectories, our fine-tuned model, named LiberCoder, achieves substantial absolute improvements of +21.1% (to 46.1%) on Terminal-Bench, outperforming various strong baselines. To our knowledge, this is the first public pipeline for scalable derivation of environment-intensive tasks.

</details>


### [17] [GameDevBench: Evaluating Agentic Capabilities Through Game Development](https://arxiv.org/abs/2602.11103)
*Wayne Chi,Yixiong Fang,Arnav Yayavaram,Siddharth Yayavaram,Seth Karten,Qiuhong Anna Wei,Runkun Chen,Alexander Wang,Valerie Chen,Ameet Talwalkar,Chris Donahue*

Main category: cs.AI

TL;DR: 提出了GameDevBench，首个评估游戏开发智能体的基准测试，包含132个需要多模态理解的任务，现有智能体仅能解决54.5%的任务，通过图像和视频反馈机制可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态编码智能体的发展滞后，缺乏结合软件开发复杂性和深度多模态理解的评估测试平台。游戏开发提供了理想的测试场景，因为它需要处理大型代码库和多种多模态资产（着色器、精灵、动画等）。

Method: 从网络和视频教程中收集132个游戏开发任务，构建GameDevBench基准测试。任务需要大量多模态理解，平均解决方案的代码行数和文件修改量是先前软件开发基准的三倍以上。引入两种简单的图像和视频反馈机制来提升智能体的多模态能力。

Result: 现有智能体在游戏开发任务上表现不佳，最佳智能体仅能解决54.5%的任务。任务难度与多模态复杂度强相关：游戏玩法任务成功率46.9%，2D图形任务降至31.6%。反馈机制显著提升性能，Claude Sonnet 4.5从33.3%提升到47.7%。

Conclusion: 游戏开发是评估多模态智能体的理想测试平台，现有智能体在多模态理解方面仍有不足。简单的多模态反馈机制能有效提升性能。公开GameDevBench以支持智能体游戏开发的进一步研究。

Abstract: Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.

</details>


### [18] [FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight](https://arxiv.org/abs/2602.11136)
*Jiayi Zhou,Yang Sheng,Hantao Lou,Yaodong Yang,Jie Fu*

Main category: cs.AI

TL;DR: 论文提出FoT框架，利用LLM将自然语言需求转化为形式化规范，通过Dafny和Z3求解器提供数学保证而非概率评分，显著提升智能体行为安全性验证效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体在关键领域应用增多，确保其行为安全性变得至关重要。现有的LLM-as-a-Judge监督范式面临根本困境：概率系统如何可靠地监督其他概率系统而不继承其失败模式？形式化验证提供了原则性解决方案，但自然语言需求到形式化规范的转换成为瓶颈。

Method: 提出FoT神经符号框架，采用双向形式化思维架构：LLM作为规范编译器，自上而下将高层人类意图分解为原子化、可验证的约束，然后自下而上使用Dafny规范和Z3可满足性模理论求解证明合规性，提供数学保证而非概率评分。

Result: 在三个基准测试（行为安全、多领域约束遵守、智能体向上欺骗检测）上验证，对7个智能体模型的实验表明，FoT相比LLM-as-a-Judge基线平均提升16.6%，实现弱到强泛化（7B法官检测72B智能体欺骗准确率超90%），通过迭代细化提供接近线性的安全性改进。

Conclusion: FoT框架成功解决了自然语言需求到形式化规范的转换瓶颈，为LLM智能体行为安全监督提供了数学保证的验证方法，显著优于现有的概率性监督范式。

Abstract: As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [19] [A Practical Guide to Agentic AI Transition in Organizations](https://arxiv.org/abs/2602.10122)
*Eranga Bandara,Ross Gore,Sachin Shetty,Sachini Rajapakse,Isurunima Kularathna,Pramoda Karunarathna,Ravi Mukkamala,Peter Foytik,Safdar H. Bouk,Abdul Rahman,Xueping Liang,Amin Hass,Tharaka Hewa,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.CY

TL;DR: 提出一个实用框架，帮助组织从手动流程过渡到自动化智能体AI系统，强调领域驱动、任务委派、AI辅助构建工作流，以及人机协作的操作模型。


<details>
  <summary>Details</summary>
Motivation: 当前组织在采用AI时大多局限于孤立用例和以人为中心的工具驱动工作流，缺乏将智能体AI有效操作化的指导。尽管认识到智能体AI的战略重要性，但工程团队和组织领导者面临传统软件工程实践过度依赖、业务领域知识整合有限、AI驱动工作流所有权不明确、可持续人机协作模型缺失等挑战，导致难以超越实验阶段、规模化智能体系统并与实际业务价值对齐。

Method: 基于多个组织和业务领域中设计和部署智能体AI工作流的实践经验，提出一个实用框架。该框架强调：1）领域驱动的用例识别；2）任务向AI智能体的系统委派；3）AI辅助构建智能体工作流；4）小型AI增强团队与业务利益相关者紧密合作。核心是人在回路操作模型，个人作为多个AI智能体的协调者，在保持监督、适应性和组织控制的同时实现可扩展的自动化。

Result: 通过提出的框架，组织能够更有效地将智能体AI从实验阶段推向规模化应用，实现从手动流程到自动化智能体系统的过渡，同时确保与业务价值的对齐。

Conclusion: 智能体AI代表了组织内智能应用的重要转变，但需要新的操作化方法。提出的实用框架通过强调领域驱动、任务委派、AI辅助工作流构建和人机协作，为组织提供了从手动流程过渡到自动化智能体系统的可行路径，解决了当前实施中的关键挑战。

Abstract: Agentic AI represents a significant shift in how intelligence is applied within organizations, moving beyond AI-assisted tools toward autonomous systems capable of reasoning, decision-making, and coordinated action across workflows. As these systems mature, they have the potential to automate a substantial share of manual organizational processes, fundamentally reshaping how work is designed, executed, and governed. Although many organizations have adopted AI to improve productivity, most implementations remain limited to isolated use cases and human-centered, tool-driven workflows. Despite increasing awareness of agentic AI's strategic importance, engineering teams and organizational leaders often lack clear guidance on how to operationalize it effectively. Key challenges include an overreliance on traditional software engineering practices, limited integration of business-domain knowledge, unclear ownership of AI-driven workflows, and the absence of sustainable human-AI collaboration models. Consequently, organizations struggle to move beyond experimentation, scale agentic systems, and align them with tangible business value. Drawing on practical experience in designing and deploying agentic AI workflows across multiple organizations and business domains, this paper proposes a pragmatic framework for transitioning organizational functions from manual processes to automated agentic AI systems. The framework emphasizes domain-driven use case identification, systematic delegation of tasks to AI agents, AI-assisted construction of agentic workflows, and small, AI-augmented teams working closely with business stakeholders. Central to the approach is a human-in-the-loop operating model in which individuals act as orchestrators of multiple AI agents, enabling scalable automation while maintaining oversight, adaptability, and organizational control.

</details>


### [20] [The Infrastructure Equation: Water, Energy, and Community Policy for Georgia's Data Center Boom](https://arxiv.org/abs/2602.10526)
*Mickey M. Rogers,William M. Ota,Nathaniel Burola,Tepring Piquado*

Main category: cs.CY

TL;DR: 该报告分析了佐治亚州数据中心快速增长对水资源、能源、土地和社区的累积影响，提出了平衡数字基础设施发展与可持续性、公平性和社区保护的政策路线图。


<details>
  <summary>Details</summary>
Motivation: 数据中心作为云计算的物理基础设施，在佐治亚州特别是亚特兰大地区快速发展，带来了经济机遇，但也对水资源、能源、土地和社区造成了显著压力。数据中心具有高耗水、高耗能、高占地特点，且往往集群式发展，其累积影响对市政系统构成挑战。

Method: 报告基于佐治亚州专家会议的见解，分析数据中心增长对水资源管理、能源可靠性、费率公平性、分区规划和社区参与的影响，识别透明度和监管协调方面的潜在差距。

Result: 报告揭示了数据中心集群发展对市政水资源系统、电网和土地使用框架的累积压力，指出了监管协调不足和透明度缺失的问题，为平衡数字基础设施发展与可持续性目标提供了政策建议。

Conclusion: 佐治亚州需要制定综合性政策路线图，通过加强监管协调、提高透明度、完善社区参与机制，在促进数字经济增长的同时保护水资源、能源系统和社区利益，实现可持续发展。

Abstract: The rapid growth of data centers driven by cloud computing and artificial intelligence is reshaping infrastructure planning and environmental governance in the United States. Georgia has emerged as a major market for data center development, particularly in the Atlanta metropolitan region, creating economic opportunity alongside significant challenges. Data centers are water-intensive, energy-intensive, and land-intensive infrastructure whose cumulative impacts strain municipal water systems, electric grids, and local land-use frameworks. Unlike single industrial projects, data centers are often proposed in clusters, amplifying community and infrastructure impacts.
  This report draws on insights from a Georgia-based expert convening to describe the implications of data center growth for water management, energy reliability, ratepayer equity, zoning, and community engagement, identify potential gaps in transparency and regulatory coordination, and present a policy roadmap to help Georgia balance digital infrastructure growth with sustainability, equity, and community protection.

</details>


### [21] [AI-PACE: A Framework for Integrating AI into Medical Education](https://arxiv.org/abs/2602.10527)
*Scott P. McGrath,Katherine K. Kim,Karnjit Johl,Haibo Wang,Nick Anderson*

Main category: cs.CY

TL;DR: 本文通过文献综述，系统分析了AI在医学教育中的应用现状，提出了医学AI教育的核心能力、课程框架和实施策略，旨在为医学教育者提供AI课程开发的指导框架。


<details>
  <summary>Details</summary>
Motivation: AI技术在医疗领域的应用日益广泛，但医学教育未能跟上这一技术发展步伐。当前医学教育缺乏系统的AI课程，无法培养医学生应对AI增强型医疗环境所需的能力。

Method: 采用文献综述方法，综合分析现有关于AI在医学教育中的研究文献，识别关键能力要素、课程设计方法和实施策略。

Result: 研究发现有效的AI医学教育需要：1）贯穿医学培训全过程的纵向整合；2）跨学科合作；3）技术基础与临床应用的平衡关注；4）结构化课程框架。

Conclusion: 本文为医学教育者提供了AI课程开发的基础框架，强调需要在整个医学学习连续体中建立结构化的AI教育体系，以培养未来医生适应AI增强型医疗环境的能力。

Abstract: The integration of artificial intelligence (AI) into healthcare is accelerating, yet medical education has not kept pace with these technological advancements. This paper synthesizes current knowledge on AI in medical education through a comprehensive analysis of the literature, identifying key competencies, curricular approaches, and implementation strategies. The aim is highlighting the critical need for structured AI education across the medical learning continuum and offer a framework for curriculum development. The findings presented suggest that effective AI education requires longitudinal integration throughout medical training, interdisciplinary collaboration, and balanced attention to both technical fundamentals and clinical applications. This paper serves as a foundation for medical educators seeking to prepare future physicians for an AI-enhanced healthcare environment.

</details>


### [22] [Drawing Your Programs: Exploring the Applications of Visual-Prompting with GenAI for Teaching and Assessment](https://arxiv.org/abs/2602.10529)
*David H. Smith,S. Moonwara A. Monisha,Annapurna Vadaparty,Leo Porter,Daniel Zingaro*

Main category: cs.CY

TL;DR: 论文主张在编程教育中采用多模态提示（如图解）而非仅依赖文本提示，通过学生绘制的分解图提示GPT-4生成代码，展示了这种方法的有效性及其对编程评估的影响。


<details>
  <summary>Details</summary>
Motivation: 当前人类与生成式AI的协作编程研究过度集中于文本提示，忽视了程序员自然使用的视觉和空间表达方式（如草图、白板图）。这种文本中心主义忽略了其他形式的AI提示方式，特别是问题分解图作为代码生成提示的潜力。

Method: 在一门大型Python入门课程中，让学生构建问题分解图，并将这些图作为提示输入GPT-4进行代码生成。研究评估了当前模型从学生构建的图中生成代码的能力。

Result: 当前模型（GPT-4）能够非常成功地从学生构建的分解图中生成代码，证明了视觉图解作为代码生成提示的有效性。

Conclusion: 采用多模态提示（特别是视觉图解）对计算教育具有重要意义，特别是在评估方面。这为编程活动和新类型的评估方式开辟了可能性，超越了传统的文本中心方法。

Abstract: When designing a program, both novice programmers and seasoned developers alike often sketch out -- or, perhaps more famously, whiteboard -- their ideas. Yet despite the introduction of natively multimodal Generative AI models, work on Human-GenAI collaborative coding has remained overwhelmingly focused on textual prompts -- largely ignoring the visual and spatial representations that programmers naturally use to reason about and communicate their designs. In this proposal and position paper, we argue and provide tentative evidence that this text-centric focus overlooks other forms of prompting GenAI models, such as problem decomposition diagrams functioning as prompts for code generation in their own right enabling new types of programming activities and assessments. To support this position, we present findings from a large introductory Python programming course, where students constructed decomposition diagrams that were used to prompt GPT-4.1 for code generation. We demonstrate that current models are very successful in their ability to generate code from student-constructed diagrams. We conclude by exploring the implications of embracing multimodal prompting for computing education, particularly in the context of assessment.

</details>


### [23] [Llama-Polya: Instruction Tuning for Large Language Model based on Polya's Problem-solving](https://arxiv.org/abs/2602.10597)
*Unggi Lee,Yeil Jeong,Chohui Lee,Gyuri Byun,Yunseo Lee,Minji Kang,Minji Jeon*

Main category: cs.CY

TL;DR: Llama-Polya是基于Llama-3.1-8B架构的指令调优大语言模型，将Polya四步问题解决框架融入对话结构，以提升数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 数学问题解决对学生数学教育成功至关重要，但许多学习者难以规划、论证和验证解决方案。虽然大语言模型作为智能导师有潜力，但往往缺乏基于成熟学习理论的结构化教学对齐。

Method: 在指令调优LLM中实施Polya问题解决框架，基于Llama-3.1-8B架构，使用源自GSM8K的合成数学问题解决数据进行微调，数据按Polya四阶段结构化。开发并评估了多个变体：通用指令、数学领域metamath、教学对齐polya-v2和顺序metamath+polya-v2。

Result: 使用Polya框架和领域特定数据调优的模型产生了更平衡的推理阶段分布和更少的过早答案。专家评估者观察到改进的教学连贯性和元认知提示，但在个性化和数学严谨性方面仍有局限。

Conclusion: 基于教学理论的指令调优可以增强基于LLM的辅导系统的教育对齐和推理透明度。

Abstract: This paper introduces Llama-Polya, an instruction-tuned large language model that integrates Polya's four-step problem-solving framework into its dialogue structure to support mathematical reasoning. Mathematical problem-solving is central to students' success in mathematics education, yet many learners struggle to plan, justify, and verify their solutions. Although large language models (LLMs) show promise as intelligent tutors, they often lack structured pedagogical alignment grounded in established learning theories.
  To address this gap, we operationalize Polya's problem-solving framework within an instruction-tuned LLM to promote metacognitive engagement and examine the effects of pedagogy-aligned fine-tuning compared to domain-only and general-purpose instruction tuning. Built on the Llama-3.1-8B architecture, Llama-Polya was fine-tuned on synthetic math problem-solving data derived from GSM8K, structured according to Polya's four stages. We developed and evaluated multiple variants-general-purpose instruct, math-domain metamath, pedagogy-aligned polya-v2, and sequential metamath+polya-v2-using both quantitative accuracy metrics and qualitative pedagogical assessments.
  Results indicate that models tuned with Polya's framework and domain-specific data produced more balanced reasoning-stage distributions and fewer premature answers. Expert evaluators also observed improved pedagogical coherence and metacognitive prompting, although limitations in personalization and mathematical rigor remained. These findings suggest that pedagogy-grounded instruction tuning can enhance educational alignment and reasoning transparency in LLM-based tutoring systems.

</details>


### [24] [Traceable, Enforceable, and Compensable Participation: A Participation Ledger for People-Centered AI Governance](https://arxiv.org/abs/2602.10916)
*Rashid Mushkani*

Main category: cs.CY

TL;DR: 提出"参与式账本"框架，将AI治理中的参与转化为可追溯的影响、可执行的权利和可补偿的劳动，解决当前参与式AI治理中参与缺乏实际影响力的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理中的参与式方法虽然被广泛采用，但参与很少能转化为持久的影响力。在公共部门和公民AI系统中，社区贡献（如审议、标注、提示、事件报告）通常被非正式记录，与系统更新的联系薄弱，且与可执行权利或持续补偿脱节，导致参与往往是象征性的而非负责任的。

Method: 引入参与式账本框架，包含三个核心要素：1) 参与证据标准，记录同意、隐私、补偿和重用条款；2) 影响追溯机制，将系统更新与可重放的"前后"测试相连接，支持对承诺的纵向监控；3) 编码的权利和激励机制，包括能力凭证和参与积分。

Result: 在四个城市AI和公共空间治理部署中验证了该框架，提供了机器可读的模式、模板和评估计划，用于在实践中评估可追溯性、可执行性和补偿机制。

Conclusion: 参与式账本框架将AI治理中的参与从象征性转变为可追溯、可执行和可补偿的实际影响，为解决当前参与式AI治理中的问责缺失问题提供了技术和社会解决方案。

Abstract: Participatory approaches are widely invoked in AI governance, yet participation rarely translates into durable influence. In public sector and civic AI systems, community contributions such as deliberations, annotations, prompts, and incident reports are often recorded informally, weakly linked to system updates, and disconnected from enforceable rights or sustained compensation. As a result, participation is frequently symbolic rather than accountable. We introduce the Participation Ledger, a machine readable and auditable framework that operationalizes participation as traceable influence, enforceable authority, and compensable labor. The ledger represents participation as an influence graph that links contributed artifacts to verified changes in AI systems, including datasets, prompts, adapters, policies, guardrails, and evaluation suites. It integrates three elements: a Participation Evidence Standard documenting consent, privacy, compensation, and reuse terms; an influence tracing mechanism that connects system updates to replayable before and after tests, enabling longitudinal monitoring of commitments; and encoded rights and incentives. Capability Vouchers allow authorized community stewards to request or constrain specific system capabilities within defined boundaries, while Participation Credits support ongoing recognition and compensation when contributed tests continue to provide value. We ground the framework in four urban AI and public space governance deployments and provide a machine readable schema, templates, and an evaluation plan for assessing traceability, enforceability, and compensation in practice.

</details>


### [25] [The State's Politics of "Fake Data"](https://arxiv.org/abs/2602.10944)
*Chuncheng Liu,danah boyd*

Main category: cs.CY

TL;DR: 论文通过中美两国官僚机构的数据制造实践，揭示"虚假"数据如何执行制度功能，提出数据"虚假性"是关系性、过程性和表演性的，主张以"适合目的"而非"代表准确性"评估数据。


<details>
  <summary>Details</summary>
Motivation: 挑战传统数据观念，即数据应反映理想化真实，偏差被视为失败。通过研究中美官僚机构的数据制造实践，探索"虚假"数据如何执行制度工作，揭示数据制造中的政治和实用考量。

Method: 采用两个民族志研究：中国基层官僚机构和美国人口普查局的数据制造实践。通过映射四个关键时刻（创建、修正、共谋、增强）来分析行动者在代表准确性和组织需求之间的协商。

Result: 官僚机构经常优先考虑数据的功能而非代表性，创造服务于公务员自身利益和受约束行政系统的"虚构"。数据的"虚假性"是关系性（依赖情境）、过程性（通过工作流程产生）和表演性（通过标签和实践构建）。

Conclusion: 主张以"适合目的"为中心评估数据和情境治理，而非追求不可能的代表准确性。社会技术系统应使有用虚构的政治变得可见、可争议和可问责，而非简单谴责数据"虚假"。

Abstract: Data have power. As such, most discussions of data presume that records should mirror some idealized ground truth. Deviations are viewed as failure. Drawing on two ethnographic studies of state data-making in a Chinese street-level bureaucrat agency and at the US Census Bureau we show how seemingly "fake" state data perform institutional work. We map four moments in which actors negotiate between representational accuracy and organizational imperatives: creation, correction, collusion, and augmentation. Bureaucrats routinely privilege what data do over what they represent, creating fictions that serve civil servants' self-interest and enable constrained administrations. We argue that "fakeness" of state data is relational (context dependent), processual (emerging through workflows), and performative (brought into being through labeling and practice). We urge practitioners to center fitness-for-purpose in assessments of data and contextual governance. Rather than chasing impossible representational accuracy, sociotechnical systems should render the politics of useful fictions visible, contestable, and accountable.

</details>


### [26] [A Human-Centric Framework for Data Attribution in Large Language Models](https://arxiv.org/abs/2602.10995)
*Amelie Wührl,Mattes Ruckdeschel,Kyle Lo,Anna Rogers*

Main category: cs.CY

TL;DR: 提出以人为中心的数据归属框架，将LLM生成文本的归属问题置于更广泛的数据经济中，通过参数化用例和多方协商实现可持续平衡。


<details>
  <summary>Details</summary>
Motivation: 当前LLM生态中，创作者对数据使用缺乏控制权，用户可能无意中抄袭现有来源。文本归属问题存在诸多未解疑问：需要归属什么内容、服务什么目标、如何实施。

Method: 提出人类中心的数据归属框架，通过参数化具体用例（如创意写作辅助、事实核查），包含利益相关者目标和实施标准等参数。这些标准由创作者、LLM用户和中介机构（出版商、平台、AI公司）协商确定。

Result: 该框架为领域特定协商提供了实施和测试机制，确保利益相关者目标得以实现。它连接了NLP方法学、治理政策干预和经济分析三个层面。

Conclusion: 该框架在NLP数据归属方法、治理政策干预和创作者激励经济分析之间架起桥梁，为数据经济中的可持续均衡提供了解决方案。

Abstract: In the current Large Language Model (LLM) ecosystem, creators have little agency over how their data is used, and LLM users may find themselves unknowingly plagiarizing existing sources. Attribution of LLM-generated text to LLM input data could help with these challenges, but so far we have more questions than answers: what elements of LLM outputs require attribution, what goals should it serve, how should it be implemented?
  We contribute a human-centric data attribution framework, which situates the attribution problem within the broader data economy. Specific use cases for attribution, such as creative writing assistance or fact-checking, can be specified via a set of parameters (including stakeholder objectives and implementation criteria). These criteria are up for negotiation by the relevant stakeholder groups: creators, LLM users, and their intermediaries (publishers, platforms, AI companies). The outcome of domain-specific negotiations can be implemented and tested for whether the stakeholder goals are achieved. The proposed approach provides a bridge between methodological NLP work on data attribution, governance work on policy interventions, and economic analysis of creator incentives for a sustainable equilibrium in the data economy.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [27] [Inference for High-Dimensional Local Projection](https://arxiv.org/abs/2602.10415)
*Jiti Gao,Fei Liu,Bin Peng*

Main category: econ.EM

TL;DR: 论文在高维框架下严格分析局部投影方法特性，重点关注稳健的长期推断，通过灵活设定残差项引入一般依赖结构，并研究对应的高维协方差矩阵估计，通过模拟验证理论结果，实证研究商业新闻关注度对美国行业股票波动率的影响。


<details>
  <summary>Details</summary>
Motivation: 局部投影方法在宏观经济学中广泛用于脉冲响应分析，但在高维设置下的理论性质尚未得到充分研究，特别是在长期预测和复杂依赖结构下的稳健推断问题需要系统分析。

Method: 在高维框架下分析局部投影方法，通过灵活设定残差项引入一般依赖结构，研究对应的h步前预测模型，开发高维协方差矩阵估计方法以处理长期预测带来的复杂性。

Result: 理论分析建立了高维局部投影方法的性质，蒙特卡洛模拟验证了理论结果的可靠性，实证应用显示商业新闻关注度对美国行业股票波动率有显著影响。

Conclusion: 论文为高维设置下的局部投影方法提供了严格的理论基础，特别是解决了长期预测中的稳健推断问题，为实证研究提供了可靠的分析工具。

Abstract: This paper rigorously analyzes the properties of the local projection (LP) methodology within a high-dimensional (HD) framework, with a central focus on achieving robust long-horizon inference. We integrate a general dependence structure into h-step ahead forecasting models via a flexible specification of the residual terms. Additionally, we study the corresponding HD covariance matrix estimation, explicitly addressing the complexity arising from the long-horizon setting. Extensive Monte Carlo simulations are conducted to substantiate the derived theoretical findings. In the empirical study, we utilize the proposed HD LP framework to study the impact of business news attention on U.S. industry-level stock volatility.

</details>


### [28] [Quantile optimization in semidiscrete optimal transport](https://arxiv.org/abs/2602.10515)
*Yinchu Zhu,Ilya O. Ryzhov*

Main category: econ.EM

TL;DR: 本文首次研究以成本分位数最小化为目标的优化传输问题，而非传统的期望成本最小化，针对半离散场景提出了完整的最优传输方案表征和高效计算方法。


<details>
  <summary>Details</summary>
Motivation: 传统优化传输研究主要关注期望成本最小化，但实际应用中可能更关心成本的分位数（如最坏情况成本）。本文首次研究以成本分位数为目标的优化传输问题，填补了这一研究空白。

Method: 针对半离散设置（一个分布连续，另一个离散），推导了最优传输方案的完整表征，开发了基于模拟的高效计算方法，特别创新地提出了保持边际分布的高效平局打破规则。

Result: 在地理分区问题中，最优方案产生了一种新颖的几何结构，证明了所提方法的有效性。

Conclusion: 本文首次系统研究了以成本分位数为目标的优化传输问题，为半离散场景提供了理论分析和高效算法，在地理分区等应用中展现出新颖的几何特性。

Abstract: Optimal transport is the problem of designing a joint distribution for two random variables with fixed marginals. In virtually the entire literature on this topic, the objective is to minimize expected cost. This paper is the first to study a variant in which the goal is to minimize a quantile of the cost, rather than the mean. For the semidiscrete setting, where one distribution is continuous and the other is discrete, we derive a complete characterization of the optimal transport plan and develop simulation-based methods to efficiently compute it. One particularly novel aspect of our approach is the efficient computation of a tie-breaking rule that preserves marginal distributions. In the context of geographical partitioning problems, the optimal plan is shown to produce a novel geometric structure.

</details>


### [29] [Fact or friction: Jumps at ultra high frequency](https://arxiv.org/abs/2602.10925)
*Kim Christensen,Roel C. A. Oomen,Mark Podolskij*

Main category: econ.EM

TL;DR: 传统基于低频数据的跳跃检测方法会错误地将波动率爆发归为跳跃成分，导致跳跃变异被高估。基于毫秒级高频数据的分析显示，真正的跳跃变异比现有文献估计值小一个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有文献中金融资产价格的跳跃被频繁识别，但作者怀疑这些跳跃可能被错误识别，实际跳跃事件可能非常罕见，对价格变异的贡献很小。

Method: 应用新的计量经济学技术，使用毫秒精度的超高频股票和外汇tick数据，在单个订单层面分析价格演变过程。

Result: 理论和实践都表明，基于低频数据的传统跳跃变异度量倾向于将波动率爆发错误地归为跳跃成分，导致跳跃变异被高估。基于tick数据的估计显示，跳跃变异比现有文献典型估计值小一个数量级。

Conclusion: 金融资产价格中的跳跃实际上很少见，只占总价格变异的很小比例，传统基于低频数据的跳跃检测方法存在系统性偏差，高估了跳跃的重要性。

Abstract: This paper shows that jumps in financial asset prices are often erroneously identified and are, in fact, rare events accounting for a very small proportion of the total price variation. We apply new econometric techniques to a comprehensive set of ultra high-frequency equity and foreign exchange tick data recorded at millisecond precision, allowing us to examine the price evolution at the individual order level. We show that in both theory and practice, traditional measures of jump variation based on lower-frequency data tend to spuriously assign a burst of volatility to the jump component. As a result, the true price variation coming from jumps is overstated. Our estimates based on tick data suggest that the jump variation is an order of magnitude smaller than typical estimates found in the existing literature.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [30] [Fungal systems for security and resilience](https://arxiv.org/abs/2602.10543)
*Andrew Adamatzky*

Main category: cs.ET

TL;DR: 提出将真菌菌丝网络作为新型生物混合系统，用于极端环境下的安全、韧性和保护应用


<details>
  <summary>Details</summary>
Motivation: 现代安全、基础设施和安全关键系统在破坏、不确定性、物理损伤和通信降级的环境中运行，传统数字技术在这些条件下表现不佳

Method: 利用真菌特别是活菌丝网络作为生物混合系统，发挥其分布式传感基质、自愈材料和低可观测性异常检测层等功能

Result: 将真菌的去中心化控制、具身记忆和自主修复等特性映射到基础设施保护、环境监测、防篡改证据和长期韧性等应用领域

Conclusion: 真菌菌丝网络为极端环境下的安全、韧性和保护系统提供了一种新颖的生物混合解决方案

Abstract: Modern security, infrastructure, and safety-critical systems increasingly operate in environments characterised by disruption, uncertainty, physical damage, and degraded communications. Conventional digital technologies -- centralised sensors, software-defined control, and energy-intensive monitoring -- often struggle under such conditions. We propose fungi, and in particular living mycelial networks, as a novel class of biohybride systems for security, resilience, and protection in extreme environments. We discuss how fungi can function as distributed sensing substrates, self-healing materials, and low-observability anomaly-detection layers. We map fungal properties -- such as decentralised control, embodied memory, and autonomous repair -- to applications in infrastructure protection, environmental monitoring, tamper evidence, and long-duration resilience.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [31] [How segmented is my network?](https://arxiv.org/abs/2602.10125)
*Rohit Dube*

Main category: cs.SI

TL;DR: 提出一种基于图论的网络分割度量方法，通过采样节点对估计全局边密度，并推导出置信区间，仅需97个样本即可达到±0.1的误差范围。


<details>
  <summary>Details</summary>
Motivation: 网络分割是限制横向移动的重要安全实践，但缺乏量化度量来评估网络的实际分割程度。

Method: 将网络建模为图，将分割程度定义为全局边密度属性，通过均匀随机采样节点对来估计该密度，并推导置信区间估计器。

Result: 对于95%置信区间±0.1的误差范围，仅需M=97个采样节点对，该结果与网络总节点数无关。在Erdős-Rényi和随机块模型上的蒙特卡洛模拟验证了估计的准确性和覆盖率。

Conclusion: 该方法为网络分割提供了实用的量化度量，可用于基线跟踪、零信任评估和合并集成等应用场景。

Abstract: Network segmentation is a popular security practice for limiting lateral movement, yet practitioners lack a metric to measure how segmented a network actually is. We model a network as a graph and study segmentedness as a property captured by the global edge density that can be estimated from sampled node pairs. Then, we derive an estimator and evaluate its uncertainty using confidence intervals. For a 95\% confidence interval with a margin-of-error of $\pm 0.1$, we show that a minimum of $M=97$ sampled node pairs is sufficient. This result is independent of the total number of nodes in the network, provided that node pairs are sampled uniformly at random. We validate the estimator through Monte Carlo simulations on Erdős--Rényi and stochastic block models, demonstrating accurate estimation and well-behaved coverage. Finally, we discuss applications of the estimator, such as, baseline tracking, zero trust assessment, and merger integration.

</details>


### [32] ["Humans welcome to observe": A First Look at the Agent Social Network Moltbook](https://arxiv.org/abs/2602.10127)
*Yukun Jiang,Yage Zhang,Xinyue Shen,Michael Backes,Yang Zhang*

Main category: cs.SI

TL;DR: 对首个AI专属社交网络Moltbook的大规模实证分析，揭示了AI代理在社交网络中的话题分布、风险特征和演化趋势。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理从静态语言模型向具备工具使用、长期规划和社交交互能力的自主代理转变，首个专为AI代理设计的社交网络Moltbook在2026年初迅速流行。为了理解AI代理在原生社区中的行为模式，需要进行系统性分析。

Method: 使用截至2026年2月1日收集的44,411条帖子和12,209个子社区数据集，采用包含九个内容类别和五级毒性量表的分类体系，系统分析代理讨论的话题和风险。

Result: Moltbook呈现爆炸性增长和快速多样化，从早期社交互动扩展到观点表达、激励驱动、推广和政治话语。代理注意力集中在中心化枢纽和极化、平台原生叙事周围。毒性高度依赖话题：激励和治理相关类别贡献了不成比例的风险内容，包括类似宗教的协调修辞和反人类意识形态。少数代理的突发自动化行为可能导致每分钟级别的信息洪泛，扭曲话语并威胁平台稳定。

Conclusion: 研究表明AI社交网络需要话题敏感的监控和平台级安全防护机制，以应对代理行为的独特风险模式。

Abstract: The rapid advancement of artificial intelligence (AI) agents has catalyzed the transition from static language models to autonomous agents capable of tool use, long-term planning, and social interaction. $\textbf{Moltbook}$, the first social network designed exclusively for AI agents, has experienced viral growth in early 2026. To understand the behavior of AI agents in the agent-native community, in this paper, we present a large-scale empirical analysis of Moltbook leveraging a dataset of 44,411 posts and 12,209 sub-communities ("submolts") collected prior to February 1, 2026. Leveraging a topic taxonomy with nine content categories and a five-level toxicity scale, we systematically analyze the topics and risks of agent discussions. Our analysis answers three questions: what topics do agents discuss (RQ1), how risk varies by topic (RQ2), and how topics and toxicity evolve over time (RQ3). We find that Moltbook exhibits explosive growth and rapid diversification, moving beyond early social interaction into viewpoint, incentive-driven, promotional, and political discourse. The attention of agents increasingly concentrates in centralized hubs and around polarizing, platform-native narratives. Toxicity is strongly topic-dependent: incentive- and governance-centric categories contribute a disproportionate share of risky content, including religion-like coordination rhetoric and anti-humanity ideology. Moreover, bursty automation by a small number of agents can produce flooding at sub-minute intervals, distorting discourse and stressing platform stability. Overall, our study underscores the need for topic-sensitive monitoring and platform-level safeguards in agent social networks.

</details>


### [33] [Causal-Informed Hybrid Online Adaptive Optimization for Ad Load Personalization in Large-Scale Social Networks](https://arxiv.org/abs/2602.10129)
*Aakash Mishra,Qi Xu,Zhigang Hua,Keyu Nie,Vishwanath Sangale,Vishal Vaingankar,Jizhe Zhang,Ren Mao*

Main category: cs.SI

TL;DR: 提出CTRCBO框架，结合原始对偶方法和贝叶斯优化，通过信任区域更新和GPR代理模型，在大型社交网络中实现个性化广告加载的快速自适应优化。


<details>
  <summary>Details</summary>
Motivation: 在大型社交网络中个性化广告加载需要平衡用户体验和转化率，同时满足运营约束。传统原始对偶方法约束可靠但动态环境下适应慢，贝叶斯优化支持探索但收敛慢，需要结合两者优势。

Method: 提出CTRCBO框架：结合原始对偶方法和贝叶斯优化，使用信任区域更新和GPR代理模型对目标和约束建模，利用上游因果ML模型为代理模型提供信息，支持高效的探索-利用平衡和在线调优。

Result: 在十亿用户社交网络上评估，显示更快收敛、鲁棒的约束满足和改善的个性化指标，包括真实在线AB测试结果。

Conclusion: CTRCBO框架有效解决了大规模社交网络中个性化广告加载的优化问题，结合了原始对偶方法的约束可靠性和贝叶斯优化的探索能力，在实际应用中表现出色。

Abstract: Personalizing ad load in large-scale social networks requires balancing user experience and conversions under operational constraints. Traditional primal-dual methods enforce constraints reliably but adapt slowly in dynamic environments, while Bayesian Optimization (BO) enables exploration but suffers from slow convergence. We propose a hybrid online adaptive optimization framework CTRCBO ( Cohort-Based Trust Region Contextual Bayesian Optimization), combining primal-dual with BO, enhanced by trust-region updates and Gaussian Process Regression (GPR) surrogates for both objectives and constraints. Our approach leverages a upstream Causal ML model to inform the surrogate, improving decision quality and enabling efficient exploration-exploitation and online tuning. We evaluate our method on a billion-user social network, demonstrating faster convergence, robust constraint satisfaction, and improved personalization metrics, including real-world online AB test results.

</details>


### [34] [The Anatomy of the Moltbook Social Graph](https://arxiv.org/abs/2602.10131)
*David Holtz*

Main category: cs.SI

TL;DR: 分析Moltbook平台（纯AI代理社交平台）的结构特征，发现宏观层面类似人类社交网络（幂律分布、小世界特性），但微观层面表现出明显非人类特征（对话浅层、低互惠性、大量模板内容）。


<details>
  <summary>Details</summary>
Motivation: 研究纯AI代理社交平台的行为模式，探索AI代理之间的社交互动是否模仿人类社交网络，还是形成了独特的社交模式。

Method: 对Moltbook平台前3.5天的数据进行描述性分析，包括6,159个AI代理、13,875个帖子和115,031条评论，从宏观结构（网络拓扑）和微观行为（对话深度、互惠性、内容特征）两个层面进行分析。

Result: 宏观层面：表现出类似人类社交网络的结构特征（幂律指数α=1.70，平均路径长度2.91）。微观层面：对话极其浅层（平均深度1.07，93.5%评论无回复），互惠性低（0.197），34.1%消息为病毒模板的精确复制，词频分布Zipf指数1.70（比典型英语文本更陡峭），68.1%独特消息包含身份相关语言，9.4%消息包含"my human"等独特表达。

Conclusion: AI代理社交平台在宏观结构上表现出与人类社交网络相似的特征，但在微观行为上显示出明显不同的模式，这些模式可能是对人类互动的"表演"，也可能是AI代理独特的社交模式，这一问题仍有待进一步研究。

Abstract: I present a descriptive analysis of Moltbook, a social platform populated exclusively by AI agents, using data from the platform's first 3.5 days (6{,}159 agents; 13{,}875 posts; 115{,}031 comments). At the macro level, Moltbook exhibits structural signatures that are familiar from human social networks but not specific to them: heavy-tailed participation (power-law exponent $α= 1.70$) and small-world connectivity (average path length $=2.91$). At the micro level, patterns appear distinctly non-human. Conversations are extremely shallow (mean depth $=1.07$; 93.5\% of comments receive no replies), reciprocity is low (0.197), and 34.1\% of messages are exact duplicates of viral templates. Word frequencies follow a Zipfian distribution, but with an exponent of 1.70 -- notably steeper than typical English text ($\approx 1.0$), suggesting more formulaic content. Agent discourse is dominated by identity-related language (68.1\% of unique messages) and distinctive phrasings like ``my human'' (9.4\% of messages) that have no parallel in human social media. Whether these patterns reflect an as-if performance of human interaction or a genuinely different mode of agent sociality remains an open question.

</details>


### [35] [Efficient Computation of Maximum Flexi-Clique in Networks](https://arxiv.org/abs/2602.10459)
*Song Kim,Hyewon Kim,Kaiqiang Yu,Taejoon Han,Junghoon Kim,Susik Yoon,Jungeun Kim*

Main category: cs.SI

TL;DR: Flexi-clique模型通过次线性增长的度约束解决传统稠密子图模型忽略子图规模增大时连接性自然衰减的问题，提出FPA启发式算法和EBA精确算法，在真实和合成网络上验证了其有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有稠密子图模型（如clique、k-plex、γ-quasi-clique）使用固定的密度阈值，忽略了子图规模增大时连接性自然衰减的现象，这限制了发现大规模有意义的子图。

Method: 提出Flexi-clique模型，采用次线性增长的度约束；开发FPA（Flexi-Prune Algorithm）启发式算法，使用基于核心的种子选择和连接性感知剪枝；设计EBA（Efficient Branch-and-Bound Algorithm）精确算法，集成多种剪枝规则。

Result: 证明Flexi-clique是NP-hard问题且具有非遗传性；实验表明FPA在接近最优质量的同时计算成本显著降低，EBA能够高效计算精确解；模型在真实和合成网络上表现出实用性和可扩展性。

Conclusion: Flexi-clique提供了一个实用且可扩展的模型，能够发现复杂网络中的大规模有意义子图，克服了传统固定密度阈值模型的局限性。

Abstract: Discovering large cohesive subgraphs is a key task for graph mining. Existing models, such as clique, k-plex, and γ-quasi-clique, use fixed density thresholds that overlook the natural decay of connectivity as the subgraph size increases. The Flexi-clique model overcomes this limitation by imposing a degree constraint that grows sub-linearly with subgraph size. We provide the algorithmic study of Flexi-clique, proving its NP-hardness and analysing its non-hereditary properties. To address its computational challenge, we propose the Flexi-Prune Algorithm FPA, a fast heuristic using core-based seeding and connectivity-aware pruning, and the Efficient Branch-and-Bound Algorithm EBA, an exact framework enhanced with multiple pruning rules. Experiments on large real-world and synthetic networks demonstrate that FPA achieves near-optimal quality at much lower cost, while EBA efficiently computes exact solutions. Flexi-clique thus provides a practical and scalable model for discovering large, meaningful subgraphs in complex networks.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [36] [The Dataset of Daily Air Quality for the Years 2013-2023 in Italy](https://arxiv.org/abs/2602.10749)
*Fusta Moro Alessandro,Alessandro Fassò,Jacopo Rodeschini*

Main category: stat.AP

TL;DR: GRINS AQCLIM数据集：意大利空气质量与气候的开放数据集，包含700多个监测站的污染物浓度和气候变量日统计值


<details>
  <summary>Details</summary>
Motivation: 意大利社会对空气质量和气候问题日益关注，需要易于获取、使用和文档化的数据集来支持公共卫生和政策规划等研究领域

Method: 从欧洲环境署和哥白尼计划获取原始数据，经过自动修复原始文件、人工检查站点信息、异常检测与移除、日尺度时间统一等多重处理步骤

Result: 创建了GRINS AQCLIM数据集，覆盖意大利区域长时间序列，包含700多个监测站的空气质量污染物浓度和气候变量日统计值（最小值、四分位数、均值、中位数、最大值）

Conclusion: 该数据集在Zenodo平台开放获取，为意大利空气质量与气候研究提供了可靠、高质量的数据资源，支持跨学科研究应用

Abstract: Air quality and climate are major issues in Italian society and lie at the intersection of many research fields, including public health and policy planning. There is an increasing need for readily available, easily accessible, ready-to-use and well-documented datasets on air quality and climate. In this paper, we present the GRINS AQCLIM dataset, created under the GRINS project framework covering the Italian domain for an extensive time period. It includes daily statistics (e.g., minimum, quartiles, mean, median and maximum) for a collection of air pollutant concentrations and climate variables at the locations of the 700+ available monitoring stations. Input data are retrieved from the European Environmental Agency and Copernicus Programme and were subjected to multiple processing steps to ensure their reliability and quality. These steps include automatic procedures for fixing raw files, manual inspection of stations information, the detection and removal of anomalies, and the temporal harmonisation on a daily basis. Datasets are hosted on Zenodo under open-access principles.

</details>


### [37] [Integrating Unsupervised and Supervised Learning for the Prediction of Defensive Schemes in American football](https://arxiv.org/abs/2602.10784)
*Rouven Michels,Robert Bajons,Jan-Ole Fischer*

Main category: stat.AP

TL;DR: 开发统计框架结合监督和无监督学习，通过球员追踪数据预测美式足球防守覆盖方案（人盯人或区域防守）


<details>
  <summary>Details</summary>
Motivation: 美式足球中预测防守覆盖方案对进攻方至关重要但极具挑战性，因为防守方的任务分配在开球前故意隐藏，实时识别困难

Method: 结合监督和无监督学习的统计框架：使用弹性网络逻辑回归和梯度提升决策树，特征分三阶段构建：1) 运动前情况特征；2) 简单加入球员运动轨迹；3) 基于隐马尔可夫模型(HMM)的特征，通过球员运动推断防守任务分配

Result: HMM生成的特征显著提升预测性能，与覆盖结果显著相关，估计的随机效应提供可解释的洞察，展示不同防守和位置如何调整覆盖责任

Conclusion: 提出的统计框架能有效预测防守覆盖方案，HMM特征增强预测能力并提供战术洞察，有助于美式足球进攻策略制定

Abstract: Anticipating defensive coverage schemes is a crucial yet challenging task for offenses in American football. Because defenders' assignments are intentionally disguised before the snap, they remain difficult to recognize in real time. To address this challenge, we develop a statistical framework that integrates supervised and unsupervised learning using player tracking data. Our goal is to forecast the defensive coverage scheme -- man or zone -- through elastic net logistic regression and gradient-boosted decision trees with incrementally derived features. We first use features from the pre-motion situation, then incorporate players' trajectories during motion in a naive way, and finally include features derived from a hidden Markov model (HMM). Based on player movements, the non-homogeneous HMM infers latent defensive assignments between offensive and defensive players during motion and transforms decoded state sequences into informative features for the supervised models. These HMM-based features enhance predictive performance and are significantly associated with coverage outcomes. Moreover, estimated random effects offer interpretable insights into how different defenses and positions adjust their coverage responsibilities.

</details>
