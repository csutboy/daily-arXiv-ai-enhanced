{"id": "2602.02512", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02512", "abs": "https://arxiv.org/abs/2602.02512", "authors": ["Changan Liu", "Haoxin Sun", "Ahad N. Zehmakan", "Zhongzhi Zhang"], "title": "Efficient Edge Rewiring Strategies for Enhancing PageRank Fairness", "comment": "Accepted by Theoretical Computer Science (TCS)", "summary": "We study the notion of unfairness in social networks, where a group such as females in a male-dominated industry are disadvantaged in access to important information, e.g. job posts, due to their less favorable positions in the network. We investigate a well-established network-based formulation of fairness called PageRank fairness, which refers to a fair allocation of the PageRank weights among distinct groups. Our goal is to enhance the PageRank fairness by modifying the underlying network structure. More precisely, we study the problem of maximizing PageRank fairness with respect to a disadvantaged group, when we are permitted to rewire a fixed number of edges in the network. Building on a greedy approach, we leverage techniques from fast sampling of rooted spanning forests to devise an effective linear-time algorithm for this problem. To evaluate the accuracy and performance of our proposed algorithm, we conduct a large set of experiments on various real-world network data. Our experiments demonstrate that the proposed algorithm significantly outperforms the existing ones. Our algorithm is capable of generating accurate solutions for networks of million nodes in just a few minutes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8d2a\u5a6a\u7b56\u7565\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u901a\u8fc7\u91cd\u8fde\u56fa\u5b9a\u6570\u91cf\u7684\u8fb9\u6765\u6700\u5927\u5316PageRank\u516c\u5e73\u6027\uff0c\u7279\u522b\u5173\u6ce8\u5f31\u52bf\u7fa4\u4f53\u5728\u7f51\u7edc\u4e2d\u7684\u4fe1\u606f\u83b7\u53d6\u516c\u5e73\u6027\u3002", "motivation": "\u7814\u7a76\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u4e0d\u516c\u5e73\u73b0\u8c61\uff0c\u7279\u522b\u662f\u67d0\u4e9b\u7fa4\u4f53\uff08\u5982\u7537\u6027\u4e3b\u5bfc\u884c\u4e1a\u4e2d\u7684\u5973\u6027\uff09\u7531\u4e8e\u5728\u7f51\u7edc\u4e2d\u5904\u4e8e\u4e0d\u5229\u4f4d\u7f6e\u800c\u96be\u4ee5\u83b7\u53d6\u91cd\u8981\u4fe1\u606f\uff08\u5982\u5de5\u4f5c\u804c\u4f4d\uff09\u3002", "method": "\u57fa\u4e8e\u8d2a\u5a6a\u65b9\u6cd5\uff0c\u5229\u7528\u5feb\u901f\u91c7\u6837\u6709\u6839\u751f\u6210\u68ee\u6797\u6280\u672f\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u901a\u8fc7\u91cd\u8fde\u56fa\u5b9a\u6570\u91cf\u7684\u8fb9\u6765\u6700\u5927\u5316PageRank\u516c\u5e73\u6027\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u7f51\u7edc\u6570\u636e\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u51e0\u5206\u949f\u5185\u4e3a\u767e\u4e07\u8282\u70b9\u7f51\u7edc\u751f\u6210\u51c6\u786e\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684PageRank\u516c\u5e73\u6027\uff0c\u4e3a\u5f31\u52bf\u7fa4\u4f53\u6539\u5584\u4fe1\u606f\u83b7\u53d6\u673a\u4f1a\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.02524", "categories": ["cs.SI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02524", "abs": "https://arxiv.org/abs/2602.02524", "authors": ["Olha Wloch", "Liam Hebert", "Robin Cohen", "Lukasz Golab"], "title": "GASTON: Graph-Aware Social Transformer for Online Networks", "comment": "Submitted to ICWSM", "summary": "Online communities have become essential places for socialization and support, yet they also possess toxicity, echo chambers, and misinformation. Detecting this harmful content is difficult because the meaning of an online interaction stems from both what is written (textual content) and where it is posted (social norms). We propose GASTON (Graph-Aware Social Transformer for Online Networks), which learns text and user embeddings that are grounded in their local norms, providing the necessary context for downstream tasks. The heart of our solution is a contrastive initialization strategy that pretrains community embeddings based on user membership patterns, capturing a community's user base before processing any text. This allows GASTON to distinguish between communities (e.g., a support group vs. a hate group) based on who interacts there, even if they share similar vocabulary. Experiments on tasks such as stress detection, toxicity scoring, and norm violation demonstrate that the embeddings produced by GASTON outperform state-of-the-art baselines.", "AI": {"tldr": "GASTON\u662f\u4e00\u4e2a\u56fe\u611f\u77e5\u793e\u4ea4Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u6587\u672c\u5185\u5bb9\u548c\u793e\u533a\u7528\u6237\u6210\u5458\u6a21\u5f0f\u6765\u5b66\u4e60\u5728\u7ebf\u793e\u533a\u4e2d\u7684\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\uff0c\u5229\u7528\u5bf9\u6bd4\u521d\u59cb\u5316\u7b56\u7565\u9884\u8bad\u7ec3\u793e\u533a\u5d4c\u5165\u4ee5\u6355\u83b7\u793e\u533a\u89c4\u8303\u3002", "motivation": "\u5728\u7ebf\u793e\u533a\u5b58\u5728\u6bd2\u6027\u5185\u5bb9\u3001\u56de\u97f3\u5ba4\u548c\u9519\u8bef\u4fe1\u606f\u7b49\u95ee\u9898\uff0c\u4f46\u68c0\u6d4b\u8fd9\u4e9b\u6709\u5bb3\u5185\u5bb9\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u5728\u7ebf\u4e92\u52a8\u7684\u610f\u4e49\u65e2\u6765\u81ea\u6587\u672c\u5185\u5bb9\uff0c\u4e5f\u6765\u81ea\u53d1\u5e03\u4f4d\u7f6e\u7684\u793e\u4f1a\u89c4\u8303\u3002", "method": "\u63d0\u51faGASTON\u6a21\u578b\uff0c\u5b66\u4e60\u57fa\u4e8e\u672c\u5730\u89c4\u8303\u7684\u6587\u672c\u548c\u7528\u6237\u5d4c\u5165\u3002\u6838\u5fc3\u662f\u5bf9\u6bd4\u521d\u59cb\u5316\u7b56\u7565\uff0c\u57fa\u4e8e\u7528\u6237\u6210\u5458\u6a21\u5f0f\u9884\u8bad\u7ec3\u793e\u533a\u5d4c\u5165\uff0c\u5728\u6587\u672c\u5904\u7406\u524d\u6355\u83b7\u793e\u533a\u7528\u6237\u57fa\u7840\uff0c\u4ece\u800c\u533a\u5206\u4e0d\u540c\u793e\u533a\u7c7b\u578b\u3002", "result": "\u5728\u538b\u529b\u68c0\u6d4b\u3001\u6bd2\u6027\u8bc4\u5206\u548c\u89c4\u8303\u8fdd\u53cd\u7b49\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGASTON\u751f\u6210\u7684\u5d4c\u5165\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GASTON\u901a\u8fc7\u7ed3\u5408\u6587\u672c\u5185\u5bb9\u548c\u793e\u533a\u7528\u6237\u6210\u5458\u6a21\u5f0f\u6765\u5b66\u4e60\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5d4c\u5165\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u68c0\u6d4b\u5728\u7ebf\u793e\u533a\u4e2d\u7684\u6709\u5bb3\u5185\u5bb9\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5ffd\u89c6\u793e\u4f1a\u89c4\u8303\u7684\u95ee\u9898\u3002"}}
{"id": "2602.02525", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02525", "abs": "https://arxiv.org/abs/2602.02525", "authors": ["Liam Hebert", "Lucas Kopp", "Robin Cohen"], "title": "Community Norms in the Spotlight: Enabling Task-Agnostic Unsupervised Pre-Training to Benefit Online Social Media", "comment": "Submitted to ICWSM Poster", "summary": "Modelling the complex dynamics of online social platforms is critical for addressing challenges such as hate speech and misinformation. While Discussion Transformers, which model conversations as graph structures, have emerged as a promising architecture, their potential is severely constrained by reliance on high-quality, human-labelled datasets. In this paper, we advocate a paradigm shift from task-specific fine-tuning to unsupervised pretraining, grounded in an entirely novel consideration of community norms. We posit that this framework not only mitigates data scarcity but also enables interpretation of the social norms underlying the decisions made by such an AI system. Ultimately, we believe that this direction offers many opportunities for AI for Social Good.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ece\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u8f6c\u5411\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u793e\u533a\u89c4\u8303\u5efa\u6a21\u89e3\u51b3\u793e\u4ea4\u5e73\u53f0\u590d\u6742\u52a8\u6001\u5206\u6790\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898", "motivation": "\u5728\u7ebf\u793e\u4ea4\u5e73\u53f0\u7684\u590d\u6742\u52a8\u6001\u5efa\u6a21\u5bf9\u89e3\u51b3\u4ec7\u6068\u8a00\u8bba\u548c\u9519\u8bef\u4fe1\u606f\u7b49\u6311\u6218\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709Discussion Transformers\u67b6\u6784\u4e25\u91cd\u4f9d\u8d56\u9ad8\u8d28\u91cf\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u5176\u6f5c\u529b", "method": "\u63d0\u51fa\u4ece\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u8f6c\u5411\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u57fa\u4e8e\u5168\u65b0\u7684\u793e\u533a\u89c4\u8303\u8003\u8651\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\u5efa\u6a21\u793e\u4ea4\u89c4\u8303", "result": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u80fd\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u8fd8\u80fd\u89e3\u91caAI\u7cfb\u7edf\u51b3\u7b56\u80cc\u540e\u7684\u793e\u4f1a\u89c4\u8303\uff0c\u4e3aAI for Social Good\u63d0\u4f9b\u65b0\u673a\u4f1a", "conclusion": "\u57fa\u4e8e\u793e\u533a\u89c4\u8303\u7684\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\u8303\u5f0f\u4e3a\u89e3\u51b3\u793e\u4ea4\u5e73\u53f0\u590d\u6742\u52a8\u6001\u5efa\u6a21\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u5e76\u4e3aAI\u793e\u4f1a\u516c\u76ca\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u673a\u9047"}}
{"id": "2602.02534", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.02534", "abs": "https://arxiv.org/abs/2602.02534", "authors": ["Enhao Huang", "Tongtong Pan", "Shuhuai Zhang", "Qishu Jin", "Liheng Zheng", "Kaichun Hu", "Yiming Li", "Zhan Qin", "Kui Ren"], "title": "DualMind: Towards Understanding Cognitive-Affective Cascades in Public Opinion Dissemination via Multi-Agent Simulation", "comment": "Accepted as a demo paper at TheWebConf (WWW) 2026", "summary": "Forecasting public opinion during PR crises is challenging, as existing frameworks often overlook the interaction between transient affective responses and persistent cognitive beliefs. To address this, we propose DualMind, an LLM-driven multi-agent platform designed to model this dual-component interplay. We evaluate the system on 15 real-world crises occurring post-August 2024 using social media data as ground truth. Empirical results demonstrate that DualMind faithfully reconstructs opinion trajectories, significantly outperforming state-of-the-art baselines. This work offers a high-fidelity tool for proactive crisis management. Code is available at https://github.com/EonHao/DualMind.", "AI": {"tldr": "DualMind\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u5e73\u53f0\uff0c\u7528\u4e8e\u5efa\u6a21\u5371\u673a\u516c\u5173\u4e2d\u516c\u4f17\u610f\u89c1\u7684\u77ed\u671f\u60c5\u611f\u53cd\u5e94\u4e0e\u6301\u4e45\u8ba4\u77e5\u4fe1\u5ff5\u7684\u4ea4\u4e92\uff0c\u572815\u4e2a\u771f\u5b9e\u5371\u673a\u6848\u4f8b\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5371\u673a\u516c\u5173\u4e2d\u7684\u516c\u4f17\u610f\u89c1\u9884\u6d4b\u6846\u67b6\u5f80\u5f80\u5ffd\u89c6\u4e86\u77ed\u671f\u60c5\u611f\u53cd\u5e94\u4e0e\u6301\u4e45\u8ba4\u77e5\u4fe1\u5ff5\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u8fd9\u9650\u5236\u4e86\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faDualMind\u2014\u2014\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u5e73\u53f0\uff0c\u4e13\u95e8\u5efa\u6a21\u516c\u4f17\u610f\u89c1\u4e2d\u7684\u53cc\u91cd\u6210\u5206\uff08\u60c5\u611f\u53cd\u5e94\u4e0e\u8ba4\u77e5\u4fe1\u5ff5\uff09\u7684\u4ea4\u4e92\u4f5c\u7528\u3002", "result": "\u57282024\u5e748\u6708\u540e\u53d1\u751f\u768415\u4e2a\u771f\u5b9e\u4e16\u754c\u5371\u673a\u6848\u4f8b\u4e2d\uff0c\u4f7f\u7528\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4f5c\u4e3a\u57fa\u51c6\uff0cDualMind\u80fd\u591f\u5fe0\u5b9e\u5730\u91cd\u5efa\u610f\u89c1\u8f68\u8ff9\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DualMind\u4e3a\u4e3b\u52a8\u5371\u673a\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u4fdd\u771f\u5ea6\u7684\u5de5\u5177\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.02806", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.02806", "abs": "https://arxiv.org/abs/2602.02806", "authors": ["Dongqing Li", "Zheqiao Cheng", "Geoff K. Nicholls", "Quyu Kong"], "title": "De-Linearizing Agent Traces: Bayesian Inference of Latent Partial Orders for Efficient Execution", "comment": null, "summary": "I agents increasingly execute procedural workflows as sequential action traces, which obscures latent concurrency and induces repeated step-by-step reasoning. We introduce BPOP, a Bayesianframework that infers a latent dependency partial order from noisy linearized traces. BPOP models traces as stochastic linear extensions of an underlying graph and performs efficient MCMC inference via a tractable frontier-softmax likelihood that avoids #P-hard marginalization over linear extensions. We evaluate on our open-sourced Cloud-IaC-6, a suite of cloud provisioning tasks with heterogeneous LLM-generated traces, and WFCommons scientific workflows. BPOP recover dependency structure more accurately than trace-only and process-mining baselines, and the inferred graphs support a compiled executor that prunes irrelevant context, yielding substantial reductions in token usage and execution time.", "AI": {"tldr": "BPOP\uff1a\u57fa\u4e8e\u8d1d\u53f6\u65af\u6846\u67b6\u4ece\u566a\u58f0\u7ebf\u6027\u5316\u8f68\u8ff9\u4e2d\u63a8\u65ad\u6f5c\u5728\u4f9d\u8d56\u504f\u5e8f\uff0c\u901a\u8fc7MCMC\u63a8\u7406\u907f\u514d#P-hard\u8ba1\u7b97\uff0c\u5728\u4e91\u914d\u7f6e\u4efb\u52a1\u4e2d\u6062\u590d\u4f9d\u8d56\u7ed3\u6784\u66f4\u51c6\u786e\uff0c\u652f\u6301\u7f16\u8bd1\u6267\u884c\u5668\u51cf\u5c11token\u4f7f\u7528\u548c\u6267\u884c\u65f6\u95f4\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53\u6267\u884c\u7a0b\u5e8f\u5de5\u4f5c\u6d41\u65f6\u901a\u5e38\u91c7\u7528\u987a\u5e8f\u52a8\u4f5c\u8f68\u8ff9\uff0c\u8fd9\u63a9\u76d6\u4e86\u6f5c\u5728\u7684\u5e76\u53d1\u6027\u5e76\u5bfc\u81f4\u91cd\u590d\u7684\u9010\u6b65\u63a8\u7406\u3002\u9700\u8981\u4ece\u566a\u58f0\u7ebf\u6027\u5316\u8f68\u8ff9\u4e2d\u6062\u590d\u6f5c\u5728\u7684\u4f9d\u8d56\u7ed3\u6784\u3002", "method": "BPOP\u662f\u4e00\u4e2a\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u5c06\u8f68\u8ff9\u5efa\u6a21\u4e3a\u57fa\u7840\u56fe\u7ed3\u6784\u7684\u968f\u673a\u7ebf\u6027\u6269\u5c55\uff0c\u901a\u8fc7\u53ef\u5904\u7406\u7684\u524d\u6cbf-softmax\u4f3c\u7136\u8fdb\u884c\u9ad8\u6548MCMC\u63a8\u7406\uff0c\u907f\u514d\u4e86\u5bf9\u7ebf\u6027\u6269\u5c55\u7684#P-hard\u8fb9\u9645\u5316\u8ba1\u7b97\u3002", "result": "\u5728\u5f00\u6e90\u7684Cloud-IaC-6\u4e91\u914d\u7f6e\u4efb\u52a1\u5957\u4ef6\u548cWFCommons\u79d1\u5b66\u5de5\u4f5c\u6d41\u4e0a\u8bc4\u4f30\uff0cBPOP\u6bd4\u4ec5\u57fa\u4e8e\u8f68\u8ff9\u548c\u8fc7\u7a0b\u6316\u6398\u7684\u57fa\u7ebf\u65b9\u6cd5\u66f4\u51c6\u786e\u5730\u6062\u590d\u4f9d\u8d56\u7ed3\u6784\uff0c\u63a8\u65ad\u7684\u56fe\u652f\u6301\u7f16\u8bd1\u6267\u884c\u5668\uff0c\u663e\u8457\u51cf\u5c11\u4e86token\u4f7f\u7528\u548c\u6267\u884c\u65f6\u95f4\u3002", "conclusion": "BPOP\u80fd\u591f\u4ece\u566a\u58f0\u7ebf\u6027\u5316\u8f68\u8ff9\u4e2d\u6709\u6548\u63a8\u65ad\u6f5c\u5728\u4f9d\u8d56\u504f\u5e8f\uff0c\u4e3a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6267\u884c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u4f9d\u8d56\u7ed3\u6784\u6062\u590d\u65b9\u6cd5\uff0c\u652f\u6301\u7f16\u8bd1\u4f18\u5316\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2602.02604", "categories": ["econ.EM", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02604", "abs": "https://arxiv.org/abs/2602.02604", "authors": ["Tiancheng Wang", "Krishna Sharma"], "title": "AI Assisted Economics Measurement From Survey: Evidence from Public Employee Pension Choice", "comment": null, "summary": "We develop an iterative framework for economic measurement that leverages large language models to extract measurement structure directly from survey instruments. The approach maps survey items to a sparse distribution over latent constructs through what we term a soft mapping, aggregates harmonized responses into respondent level sub dimension scores, and disciplines the resulting taxonomy through out of sample incremental validity tests and discriminant validity diagnostics. The framework explicitly integrates iteration into the measurement construction process. Overlap and redundancy diagnostics trigger targeted taxonomy refinement and constrained remapping, ensuring that added measurement flexibility is retained only when it delivers stable out of sample performance gains. Applied to a large scale public employee retirement plan survey, the framework identifies which semantic components contain behavioral signal and clarifies the economic mechanisms, such as beliefs versus constraints, that matter for retirement choices. The methodology provides a portable measurement audit of survey instruments that can guide both empirical analysis and survey design.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u8c03\u67e5\u5de5\u5177\u4e2d\u63d0\u53d6\u6d4b\u91cf\u7ed3\u6784\u7684\u8fed\u4ee3\u6846\u67b6\uff0c\u901a\u8fc7\u8f6f\u6620\u5c04\u5c06\u8c03\u67e5\u9879\u76ee\u6620\u5c04\u5230\u6f5c\u5728\u6784\u5ff5\u7684\u7a00\u758f\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u6837\u672c\u5916\u6709\u6548\u6027\u6d4b\u8bd5\u6765\u89c4\u8303\u5206\u7c7b\u4f53\u7cfb\u3002", "motivation": "\u4f20\u7edf\u7ecf\u6d4e\u6d4b\u91cf\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u8c03\u67e5\u6570\u636e\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u76f4\u63a5\u4ece\u8c03\u67e5\u5de5\u5177\u4e2d\u63d0\u53d6\u6d4b\u91cf\u7ed3\u6784\u3001\u8bc6\u522b\u54ea\u4e9b\u8bed\u4e49\u6210\u5206\u5305\u542b\u884c\u4e3a\u4fe1\u53f7\uff0c\u5e76\u9610\u660e\u7ecf\u6d4e\u673a\u5236\uff08\u5982\u4fe1\u5ff5\u4e0e\u7ea6\u675f\uff09\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u8f6f\u6620\u5c04\u5c06\u8c03\u67e5\u9879\u76ee\u6620\u5c04\u5230\u6f5c\u5728\u6784\u5ff5\u7684\u7a00\u758f\u5206\u5e03\uff0c\u5c06\u534f\u8c03\u540e\u7684\u56de\u7b54\u805a\u5408\u6210\u53d7\u8bbf\u8005\u5c42\u9762\u7684\u5b50\u7ef4\u5ea6\u5206\u6570\uff0c\u5e76\u901a\u8fc7\u6837\u672c\u5916\u589e\u91cf\u6709\u6548\u6027\u6d4b\u8bd5\u548c\u5224\u522b\u6548\u5ea6\u8bca\u65ad\u6765\u89c4\u8303\u5206\u7c7b\u4f53\u7cfb\u3002\u6846\u67b6\u660e\u786e\u5c06\u8fed\u4ee3\u6574\u5408\u5230\u6d4b\u91cf\u6784\u5efa\u8fc7\u7a0b\u4e2d\u3002", "result": "\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u516c\u5171\u96c7\u5458\u9000\u4f11\u8ba1\u5212\u8c03\u67e5\u65f6\uff0c\u8be5\u6846\u67b6\u6210\u529f\u8bc6\u522b\u4e86\u54ea\u4e9b\u8bed\u4e49\u6210\u5206\u5305\u542b\u884c\u4e3a\u4fe1\u53f7\uff0c\u5e76\u9610\u660e\u4e86\u5f71\u54cd\u9000\u4f11\u9009\u62e9\u7684\u7ecf\u6d4e\u673a\u5236\uff08\u5982\u4fe1\u5ff5\u4e0e\u7ea6\u675f\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8c03\u67e5\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u79fb\u690d\u7684\u6d4b\u91cf\u5ba1\u8ba1\uff0c\u65e2\u80fd\u6307\u5bfc\u5b9e\u8bc1\u5206\u6790\uff0c\u4e5f\u80fd\u6307\u5bfc\u8c03\u67e5\u8bbe\u8ba1\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u786e\u4fdd\u6d4b\u91cf\u7075\u6d3b\u6027\u53ea\u5728\u5e26\u6765\u7a33\u5b9a\u6837\u672c\u5916\u6027\u80fd\u63d0\u5347\u65f6\u624d\u88ab\u4fdd\u7559\u3002"}}
{"id": "2602.02509", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02509", "abs": "https://arxiv.org/abs/2602.02509", "authors": ["Nishat Raihan", "Noah Erdachew", "Jayoti Devi", "Joanna C. S. Santos", "Marcos Zampieri"], "title": "CodeGuard: Improving LLM Guardrails in CS Education", "comment": null, "summary": "Large language models (LLMs) are increasingly embedded in Computer Science (CS) classrooms to automate code generation, feedback, and assessment. However, their susceptibility to adversarial or ill-intentioned prompts threatens student learning and academic integrity. To cope with this important issue, we evaluate existing off-the-shelf LLMs in handling unsafe and irrelevant prompts within the domain of CS education. We identify important shortcomings in existing LLM guardrails which motivates us to propose CodeGuard, a comprehensive guardrail framework for educational AI systems. CodeGuard includes (i) a first-of-its-kind taxonomy for classifying prompts; (ii) the CodeGuard dataset, a collection of 8,000 prompts spanning the taxonomy; and (iii) PromptShield, a lightweight sentence-encoder model fine-tuned to detect unsafe prompts in real time. Experiments show that PromptShield achieves 0.93 F1 score, surpassing existing guardrail methods. Additionally, further experimentation reveals that CodeGuard reduces potentially harmful or policy-violating code completions by 30-65% without degrading performance on legitimate educational tasks. The code, datasets, and evaluation scripts are made freely available to the community.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCodeGuard\u6846\u67b6\uff0c\u5305\u542b\u5206\u7c7b\u6cd5\u3001\u6570\u636e\u96c6\u548cPromptShield\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u6d4bCS\u6559\u80b2\u4e2dLLM\u7684\u4e0d\u5b89\u5168\u63d0\u793a\uff0c\u51cf\u5c1130-65%\u6709\u5bb3\u4ee3\u7801\u751f\u6210", "motivation": "LLM\u5728CS\u6559\u80b2\u4e2d\u5e7f\u6cdb\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u548c\u53cd\u9988\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u6076\u610f\u63d0\u793a\u653b\u51fb\uff0c\u5a01\u80c1\u5b66\u751f\u5b66\u4e60\u4e0e\u5b66\u672f\u8bda\u4fe1\uff0c\u73b0\u6709\u9632\u62a4\u63aa\u65bd\u5b58\u5728\u4e0d\u8db3", "method": "\u63d0\u51faCodeGuard\u6846\u67b6\uff1a1) \u9996\u521b\u63d0\u793a\u5206\u7c7b\u6cd5\uff1b2) \u5305\u542b8000\u4e2a\u63d0\u793a\u7684CodeGuard\u6570\u636e\u96c6\uff1b3) PromptShield\u8f7b\u91cf\u7ea7\u53e5\u5b50\u7f16\u7801\u5668\u6a21\u578b\uff0c\u5b9e\u65f6\u68c0\u6d4b\u4e0d\u5b89\u5168\u63d0\u793a", "result": "PromptShield\u8fbe\u52300.93 F1\u5206\u6570\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1bCodeGuard\u51cf\u5c1130-65%\u6709\u5bb3\u6216\u8fdd\u89c4\u4ee3\u7801\u751f\u6210\uff0c\u4e14\u4e0d\u5f71\u54cd\u6b63\u5e38\u6559\u80b2\u4efb\u52a1\u6027\u80fd", "conclusion": "CodeGuard\u4e3a\u6559\u80b2AI\u7cfb\u7edf\u63d0\u4f9b\u5168\u9762\u9632\u62a4\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347LLM\u5728CS\u6559\u80b2\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u811a\u672c\u5df2\u5f00\u6e90"}}
{"id": "2602.02515", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02515", "abs": "https://arxiv.org/abs/2602.02515", "authors": ["Yiliang Song", "Hongjun An", "Jiangong Xiao", "Haofei Zhao", "Jiawei Shao", "Xuelong Li"], "title": "CreditAudit: 2D Auditing for LLM Evaluation and Selection", "comment": "First update", "summary": "Leaderboard scores on public benchmarks have been steadily rising and converging, with many frontier language models now separated by only marginal differences. However, these scores often fail to match users' day to day experience, because system prompts, output protocols, and interaction modes evolve under routine iteration, and in agentic multi step pipelines small protocol shifts can trigger disproportionate failures, leaving practitioners uncertain about which model to deploy. We propose CreditAudit, a deployment oriented credit audit framework that evaluates models under a family of semantically aligned and non adversarial system prompt templates across multiple benchmarks, reporting mean ability as average performance across scenarios and scenario induced fluctuation sigma as a stability risk signal, and further mapping volatility into interpretable credit grades from AAA to BBB via cross model quantiles with diagnostics that mitigate template difficulty drift. Controlled experiments on GPQA, TruthfulQA, and MMLU Pro show that models with similar mean ability can exhibit substantially different fluctuation, and stability risk can overturn prioritization decisions in agentic or high failure cost regimes. By providing a 2D and grade based language for regime specific selection, CreditAudit supports tiered deployment and more disciplined allocation of testing and monitoring effort, enabling more objective and trustworthy model evaluation for real world use.", "AI": {"tldr": "CreditAudit\u662f\u4e00\u4e2a\u9762\u5411\u90e8\u7f72\u7684\u4fe1\u7528\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u7cfb\u7edf\u63d0\u793a\u6a21\u677f\u4e0b\u7684\u6027\u80fd\u6ce2\u52a8\u6027\uff0c\u63d0\u4f9b\u5747\u503c\u548c\u7a33\u5b9a\u6027\u98ce\u9669\u4fe1\u53f7\uff0c\u5e2e\u52a9\u5728\u76f8\u4f3c\u5e73\u5747\u6027\u80fd\u7684\u6a21\u578b\u4e2d\u9009\u62e9\u66f4\u7a33\u5b9a\u7684\u90e8\u7f72\u9009\u9879\u3002", "motivation": "\u5f53\u524d\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u7684\u5206\u6570\u8d8b\u4e8e\u6536\u655b\uff0c\u8bb8\u591a\u524d\u6cbf\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u53ea\u6709\u5fae\u5c0f\u5dee\u5f02\uff0c\u4f46\u8fd9\u4e9b\u5206\u6570\u65e0\u6cd5\u53cd\u6620\u7528\u6237\u65e5\u5e38\u4f53\u9a8c\u3002\u7cfb\u7edf\u63d0\u793a\u3001\u8f93\u51fa\u534f\u8bae\u548c\u4ea4\u4e92\u6a21\u5f0f\u5728\u4e0d\u65ad\u8fed\u4ee3\u53d8\u5316\uff0c\u5728\u4ee3\u7406\u5f0f\u591a\u6b65\u9aa4\u6d41\u7a0b\u4e2d\uff0c\u5c0f\u7684\u534f\u8bae\u53d8\u5316\u53ef\u80fd\u5f15\u53d1\u4e0d\u6210\u6bd4\u4f8b\u7684\u5931\u8d25\uff0c\u5bfc\u81f4\u4ece\u4e1a\u8005\u4e0d\u786e\u5b9a\u90e8\u7f72\u54ea\u4e2a\u6a21\u578b\u3002", "method": "\u63d0\u51faCreditAudit\u6846\u67b6\uff1a1\uff09\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u4f7f\u7528\u4e00\u7cfb\u5217\u8bed\u4e49\u5bf9\u9f50\u4e14\u975e\u5bf9\u6297\u6027\u7684\u7cfb\u7edf\u63d0\u793a\u6a21\u677f\u8bc4\u4f30\u6a21\u578b\uff1b2\uff09\u62a5\u544a\u5e73\u5747\u6027\u80fd\u4f5c\u4e3a\u80fd\u529b\u5747\u503c\uff1b3\uff09\u62a5\u544a\u573a\u666f\u8bf1\u5bfc\u7684\u6ce2\u52a8\u6027\u03c3\u4f5c\u4e3a\u7a33\u5b9a\u6027\u98ce\u9669\u4fe1\u53f7\uff1b4\uff09\u901a\u8fc7\u8de8\u6a21\u578b\u5206\u4f4d\u6570\u5c06\u6ce2\u52a8\u6027\u6620\u5c04\u4e3a\u53ef\u89e3\u91ca\u7684\u4fe1\u7528\u7b49\u7ea7\uff08AAA\u5230BBB\uff09\uff0c\u5e76\u5305\u542b\u51cf\u8f7b\u6a21\u677f\u96be\u5ea6\u6f02\u79fb\u7684\u8bca\u65ad\u3002", "result": "\u5728GPQA\u3001TruthfulQA\u548cMMLU Pro\u4e0a\u7684\u63a7\u5236\u5b9e\u9a8c\u8868\u660e\uff1a\u5177\u6709\u76f8\u4f3c\u5e73\u5747\u80fd\u529b\u7684\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u540c\u7684\u6ce2\u52a8\u6027\uff0c\u7a33\u5b9a\u6027\u98ce\u9669\u53ef\u4ee5\u5728\u4ee3\u7406\u5f0f\u6216\u9ad8\u5931\u8d25\u6210\u672c\u573a\u666f\u4e2d\u63a8\u7ffb\u4f18\u5148\u7ea7\u51b3\u7b56\u3002\u6846\u67b6\u63d0\u4f9b\u4e862\u7ef4\u548c\u7b49\u7ea7\u57fa\u7840\u7684\u8bed\u8a00\uff0c\u652f\u6301\u7279\u5b9a\u573a\u666f\u7684\u9009\u62e9\u3002", "conclusion": "CreditAudit\u901a\u8fc7\u63d0\u4f9b\u66f4\u5ba2\u89c2\u548c\u53ef\u4fe1\u7684\u6a21\u578b\u8bc4\u4f30\uff0c\u652f\u6301\u5206\u5c42\u90e8\u7f72\u548c\u66f4\u89c4\u8303\u7684\u6d4b\u8bd5\u4e0e\u76d1\u63a7\u8d44\u6e90\u5206\u914d\uff0c\u4f7f\u6a21\u578b\u8bc4\u4f30\u66f4\u9002\u5408\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2602.02601", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02601", "abs": "https://arxiv.org/abs/2602.02601", "authors": ["Hieu Duong", "Eugene Levin", "Todd Gary", "Long Nguyen"], "title": "CaST: Causal Discovery via Spatio-Temporal Graphs in Disaster Tweets", "comment": null, "summary": "Understanding causality between real-world events from social media is essential for situational awareness, yet existing causal discovery methods often overlook the interplay between semantic, spatial, and temporal contexts. We propose CaST: Causal Discovery via Spatio-Temporal Graphs, a unified framework for causal discovery in disaster domain that integrates semantic similarity and spatio-temporal proximity using Large Language Models (LLMs) pretrained on disaster datasets. CaST constructs an event graph for each window of tweets. Each event extracted from tweets is represented as a node embedding enriched with its contextual semantics, geographic coordinates, and temporal features. These event nodes are then connected to form a spatio-temporal event graph, which is processed using a multi-head Graph Attention Network (GAT) \\cite{gat} to learn directed causal relationships. We construct an in-house dataset of approximately 167K disaster-related tweets collected during Hurricane Harvey and annotated following the MAVEN-ERE schema. Experimental results show that CaST achieves superior performance over both traditional and state-of-the-art methods. Ablation studies further confirm that incorporating spatial and temporal signals substantially improves both recall and stability during training. Overall, CaST demonstrates that integrating spatio-temporal reasoning into event graphs enables more robust and interpretable causal discovery in disaster-related social media text.", "AI": {"tldr": "CaST\u662f\u4e00\u4e2a\u7528\u4e8e\u707e\u5bb3\u9886\u57df\u793e\u4ea4\u5a92\u4f53\u56e0\u679c\u53d1\u73b0\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u65f6\u7a7a\u90bb\u8fd1\u6027\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u65f6\u7a7a\u4e8b\u4ef6\u56fe\uff0c\u5e76\u4f7f\u7528\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u5b66\u4e60\u6709\u5411\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u8bed\u4e49\u3001\u7a7a\u95f4\u548c\u65f6\u95f4\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u800c\u7406\u89e3\u793e\u4ea4\u5a92\u4f53\u4e2d\u73b0\u5b9e\u4e16\u754c\u4e8b\u4ef6\u7684\u56e0\u679c\u5173\u7cfb\u5bf9\u4e8e\u6001\u52bf\u611f\u77e5\u81f3\u5173\u91cd\u8981\u3002", "method": "CaST\u4e3a\u6bcf\u4e2a\u63a8\u6587\u7a97\u53e3\u6784\u5efa\u4e8b\u4ef6\u56fe\uff0c\u5c06\u63a8\u6587\u4e2d\u63d0\u53d6\u7684\u4e8b\u4ef6\u8868\u793a\u4e3a\u5305\u542b\u4e0a\u4e0b\u6587\u8bed\u4e49\u3001\u5730\u7406\u5750\u6807\u548c\u65f6\u95f4\u7279\u5f81\u7684\u8282\u70b9\u5d4c\u5165\uff0c\u7136\u540e\u8fde\u63a5\u5f62\u6210\u65f6\u7a7a\u4e8b\u4ef6\u56fe\uff0c\u4f7f\u7528\u591a\u5934\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u5b66\u4e60\u6709\u5411\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCaST\u5728\u4f20\u7edf\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u65b9\u6cd5\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u5b9e\uff0c\u7ed3\u5408\u7a7a\u95f4\u548c\u65f6\u95f4\u4fe1\u53f7\u663e\u8457\u63d0\u9ad8\u4e86\u53ec\u56de\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "conclusion": "CaST\u8bc1\u660e\u5c06\u65f6\u7a7a\u63a8\u7406\u6574\u5408\u5230\u4e8b\u4ef6\u56fe\u4e2d\uff0c\u80fd\u591f\u5728\u707e\u5bb3\u76f8\u5173\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u4e2d\u5b9e\u73b0\u66f4\u7a33\u5065\u548c\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u53d1\u73b0\u3002"}}
{"id": "2602.02813", "categories": ["stat.AP", "cs.LG", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02813", "abs": "https://arxiv.org/abs/2602.02813", "authors": ["Sanjit Dandapanthula", "Margaret Johnson", "Madeleine Pascolini-Campbell", "Glynn Hulley", "Mikael Kuusela"], "title": "Downscaling land surface temperature data using edge detection and block-diagonal Gaussian process regression", "comment": null, "summary": "Accurate and high-resolution estimation of land surface temperature (LST) is crucial in estimating evapotranspiration, a measure of plant water use and a central quantity in agricultural applications. In this work, we develop a novel statistical method for downscaling LST data obtained from NASA's ECOSTRESS mission, using high-resolution data from the Landsat 8 mission as a proxy for modeling agricultural field structure. Using the Landsat data, we identify the boundaries of agricultural fields through edge detection techniques, allowing us to capture the inherent block structure present in the spatial domain. We propose a block-diagonal Gaussian process (BDGP) model that captures the spatial structure of the agricultural fields, leverages independence of LST across fields for computational tractability, and accounts for the change of support present in ECOSTRESS observations. We use the resulting BDGP model to perform Gaussian process regression and obtain high-resolution estimates of LST from ECOSTRESS data, along with uncertainty quantification. Our results demonstrate the practicality of the proposed method in producing reliable high-resolution LST estimates, with potential applications in agriculture, urban planning, and climate studies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5757\u5bf9\u89d2\u9ad8\u65af\u8fc7\u7a0b\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u964d\u5c3a\u5ea6ECOSTRESS\u4efb\u52a1\u7684\u5730\u8868\u6e29\u5ea6\u6570\u636e\uff0c\u5229\u7528Landsat 8\u6570\u636e\u8bc6\u522b\u519c\u7530\u8fb9\u754c\u7ed3\u6784\uff0c\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u6e29\u5ea6\u4f30\u8ba1\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387\u5730\u8868\u6e29\u5ea6(LST)\u4f30\u8ba1\u5bf9\u4e8e\u4f30\u7b97\u84b8\u6563\u53d1\uff08\u690d\u7269\u6c34\u5206\u5229\u7528\uff09\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u662f\u519c\u4e1a\u5e94\u7528\u4e2d\u7684\u6838\u5fc3\u53c2\u6570\u3002ECOSTRESS\u4efb\u52a1\u63d0\u4f9bLST\u6570\u636e\uff0c\u4f46\u9700\u8981\u964d\u5c3a\u5ea6\u4ee5\u83b7\u5f97\u66f4\u9ad8\u5206\u8fa8\u7387\u3002", "method": "\u4f7f\u7528Landsat 8\u6570\u636e\u901a\u8fc7\u8fb9\u7f18\u68c0\u6d4b\u6280\u672f\u8bc6\u522b\u519c\u7530\u8fb9\u754c\uff0c\u6355\u6349\u7a7a\u95f4\u57df\u4e2d\u7684\u5757\u7ed3\u6784\u3002\u63d0\u51fa\u5757\u5bf9\u89d2\u9ad8\u65af\u8fc7\u7a0b(BDGP)\u6a21\u578b\uff0c\u5229\u7528\u519c\u7530\u95f4\u7684\u72ec\u7acb\u6027\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u8003\u8651ECOSTRESS\u89c2\u6d4b\u7684\u652f\u6301\u53d8\u5316\u3002\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u83b7\u5f97\u9ad8\u5206\u8fa8\u7387LST\u4f30\u8ba1\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u53ef\u9760\u7684\u9ad8\u5206\u8fa8\u7387LST\u4f30\u8ba1\uff0c\u5c55\u793a\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684BDGP\u65b9\u6cd5\u5728\u519c\u4e1a\u3001\u57ce\u5e02\u89c4\u5212\u548c\u6c14\u5019\u7814\u7a76\u7b49\u9886\u57df\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u63d0\u4f9b\u5b9e\u7528\u7684\u9ad8\u5206\u8fa8\u7387LST\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02607", "categories": ["econ.EM", "econ.TH", "q-fin.CP", "q-fin.GN", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2602.02607", "abs": "https://arxiv.org/abs/2602.02607", "authors": ["Tatsuru Kikuchi"], "title": "The Innovation Tax: Generative AI Adoption, Productivity Paradox, and Systemic Risk in the U.S. Banking Sector", "comment": "This is my last paper in my life", "summary": "This paper evaluates the causal impact of Generative Artificial Intelligence (GenAI) adoption on productivity and systemic risk in the U.S. banking sector. Using a novel dataset linking SEC 10-Q filings to Federal Reserve regulatory data for 809 financial institutions over 2018--2025, we employ two complementary identification strategies: Dynamic Spatial Durbin Models (DSDM) to capture network spillovers and Synthetic Difference-in-Differences (SDID) for causal inference using the November 2022 ChatGPT release as an exogenous shock. Our findings reveal a striking ``Productivity Paradox'': while DSDM estimates show that AI-adopting banks are high performers ($\u03b2> 0$), the causal SDID analysis documents a significant ``Implementation Tax'' -- adopting banks experience a 428-basis-point decline in ROE as they absorb GenAI integration costs. This tax falls disproportionately on smaller institutions, with bottom-quartile banks suffering a 517-basis-point ROE decline compared to 129 basis points for larger banks, suggesting that economies of scale provide significant advantages in AI implementation. Most critically, our DSDM analysis reveals significant positive spillovers ($\u03b8= 0.161$ for ROA, $p < 0.01$; $\u03b8= 0.679$ for ROE, $p < 0.05$), with spillovers among large banks reaching $\u03b8= 3.13$ for ROE, indicating that the U.S. banking system is becoming ``algorithmically coupled.'' This synchronization of AI-driven decision-making creates a new channel for systemic contagion: a technical failure in widely-adopted AI models could trigger correlated shocks across the entire financial network.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u751f\u6210\u5f0fAI\u5bf9\u7f8e\u56fd\u94f6\u884c\u4e1a\u751f\u4ea7\u7387\u548c\u7cfb\u7edf\u6027\u98ce\u9669\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\"\u751f\u4ea7\u529b\u6096\u8bba\"\uff1aAI\u91c7\u7528\u94f6\u884c\u8868\u73b0\u4f18\u5f02\u4f46\u9762\u4e34\u663e\u8457\u7684\"\u5b9e\u65bd\u7a0e\"\uff0c\u4e14AI\u9a71\u52a8\u7684\u51b3\u7b56\u540c\u6b65\u5316\u521b\u9020\u4e86\u7cfb\u7edf\u6027\u98ce\u9669\u65b0\u6e20\u9053", "motivation": "\u8bc4\u4f30\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u94f6\u884c\u4e1a\u7684\u91c7\u7528\u5bf9\u751f\u4ea7\u7387\u548c\u7cfb\u7edf\u6027\u98ce\u9669\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8AI\u5b9e\u65bd\u7684\u6210\u672c\u6548\u76ca\u548c\u7f51\u7edc\u6ea2\u51fa\u6548\u5e94", "method": "\u4f7f\u75282018-2025\u5e74809\u5bb6\u91d1\u878d\u673a\u6784\u7684SEC 10-Q\u6587\u4ef6\u548c\u7f8e\u8054\u50a8\u76d1\u7ba1\u6570\u636e\uff0c\u91c7\u7528\u52a8\u6001\u7a7a\u95f4\u675c\u5bbe\u6a21\u578b\u6355\u6349\u7f51\u7edc\u6ea2\u51fa\u6548\u5e94\uff0c\u4ee5\u53ca\u5408\u6210\u53cc\u91cd\u5dee\u5206\u6cd5\u4ee52022\u5e7411\u6708ChatGPT\u53d1\u5e03\u4f5c\u4e3a\u5916\u751f\u51b2\u51fb\u8fdb\u884c\u56e0\u679c\u63a8\u65ad", "result": "\u53d1\u73b0\"\u751f\u4ea7\u529b\u6096\u8bba\"\uff1aAI\u91c7\u7528\u94f6\u884c\u8868\u73b0\u4f18\u5f02\u4f46\u9762\u4e34428\u4e2a\u57fa\u70b9\u7684ROE\u4e0b\u964d\uff08\u5b9e\u65bd\u7a0e\uff09\uff0c\u5c0f\u94f6\u884c\u53d7\u5f71\u54cd\u66f4\u5927\uff08517\u4e2a\u57fa\u70b9vs\u5927\u94f6\u884c129\u4e2a\u57fa\u70b9\uff09\u3002\u540c\u65f6\u53d1\u73b0\u663e\u8457\u7684\u6b63\u5411\u7f51\u7edc\u6ea2\u51fa\u6548\u5e94\uff08ROA \u03b8=0.161\uff0cROE \u03b8=0.679\uff09\uff0c\u8868\u660e\u94f6\u884c\u4e1a\u6b63\u5728\"\u7b97\u6cd5\u8026\u5408\"\uff0c\u521b\u9020\u4e86\u7cfb\u7edf\u6027\u98ce\u9669\u65b0\u6e20\u9053", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u94f6\u884c\u4e1a\u7684\u91c7\u7528\u5b58\u5728\u663e\u8457\u7684\u5b9e\u65bd\u6210\u672c\uff0c\u7279\u522b\u662f\u5bf9\u5c0f\u94f6\u884c\u4e0d\u5229\uff0c\u540c\u65f6AI\u9a71\u52a8\u7684\u51b3\u7b56\u540c\u6b65\u5316\u521b\u9020\u4e86\u7cfb\u7edf\u6027\u98ce\u9669\u65b0\u6e20\u9053\uff0c\u9700\u8981\u76d1\u7ba1\u5173\u6ce8"}}
{"id": "2602.02510", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.02510", "abs": "https://arxiv.org/abs/2602.02510", "authors": ["Yuming Zhao", "Peiyi Zhang", "Oana Ignat"], "title": "Beyond Translation: Cross-Cultural Meme Transcreation with Vision-Language Models", "comment": null, "summary": "Memes are a pervasive form of online communication, yet their cultural specificity poses significant challenges for cross-cultural adaptation. We study cross-cultural meme transcreation, a multimodal generation task that aims to preserve communicative intent and humor while adapting culture-specific references. We propose a hybrid transcreation framework based on vision-language models and introduce a large-scale bidirectional dataset of Chinese and US memes. Using both human judgments and automated evaluation, we analyze 6,315 meme pairs and assess transcreation quality across cultural directions. Our results show that current vision-language models can perform cross-cultural meme transcreation to a limited extent, but exhibit clear directional asymmetries: US-Chinese transcreation consistently achieves higher quality than Chinese-US. We further identify which aspects of humor and visual-textual design transfer across cultures and which remain challenging, and propose an evaluation framework for assessing cross-cultural multimodal generation. Our code and dataset are publicly available at https://github.com/AIM-SCU/MemeXGen.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6df7\u5408\u8f6c\u521b\u6846\u67b6\uff0c\u7528\u4e8e\u8de8\u6587\u5316\u8868\u60c5\u5305\u8f6c\u521b\uff0c\u5e76\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u4e2d\u82f1\u53cc\u5411\u6570\u636e\u96c6\u3002\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u80fd\u6709\u9650\u5ea6\u5b8c\u6210\u8de8\u6587\u5316\u8868\u60c5\u5305\u8f6c\u521b\uff0c\u4f46\u5b58\u5728\u65b9\u5411\u4e0d\u5bf9\u79f0\u6027\uff1a\u7f8e\u8f6c\u4e2d\u8d28\u91cf\u4f18\u4e8e\u4e2d\u8f6c\u7f8e\u3002", "motivation": "\u8868\u60c5\u5305\u662f\u5728\u7ebf\u4ea4\u6d41\u7684\u666e\u904d\u5f62\u5f0f\uff0c\u4f46\u5176\u6587\u5316\u7279\u5f02\u6027\u7ed9\u8de8\u6587\u5316\u9002\u5e94\u5e26\u6765\u6311\u6218\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u4fdd\u6301\u4ea4\u6d41\u610f\u56fe\u548c\u5e7d\u9ed8\u611f\u7684\u540c\u65f6\uff0c\u9002\u5e94\u6587\u5316\u7279\u5b9a\u53c2\u8003\u7684\u8de8\u6587\u5316\u8868\u60c5\u5305\u8f6c\u521b\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6df7\u5408\u8f6c\u521b\u6846\u67b6\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u4e2d\u82f1\u53cc\u5411\u8868\u60c5\u5305\u6570\u636e\u96c6\uff086,315\u5bf9\uff09\uff0c\u4f7f\u7528\u4eba\u5de5\u5224\u65ad\u548c\u81ea\u52a8\u8bc4\u4f30\u5206\u6790\u8de8\u6587\u5316\u65b9\u5411\u4e0a\u7684\u8f6c\u521b\u8d28\u91cf\u3002", "result": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u80fd\u6709\u9650\u5ea6\u5b8c\u6210\u8de8\u6587\u5316\u8868\u60c5\u5305\u8f6c\u521b\uff0c\u4f46\u5b58\u5728\u660e\u663e\u65b9\u5411\u4e0d\u5bf9\u79f0\u6027\uff1a\u7f8e\u8f6c\u4e2d\u8d28\u91cf\u59cb\u7ec8\u9ad8\u4e8e\u4e2d\u8f6c\u7f8e\u3002\u8bc6\u522b\u4e86\u5e7d\u9ed8\u548c\u89c6\u89c9\u6587\u672c\u8bbe\u8ba1\u4e2d\u54ea\u4e9b\u65b9\u9762\u80fd\u8de8\u6587\u5316\u4f20\u9012\uff0c\u54ea\u4e9b\u4ecd\u5177\u6311\u6218\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u8bc4\u4f30\u8de8\u6587\u5316\u591a\u6a21\u6001\u751f\u6210\u7684\u6846\u67b6\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u516c\u5f00\u3002\u7814\u7a76\u63ed\u793a\u4e86\u8de8\u6587\u5316\u8868\u60c5\u5305\u8f6c\u521b\u7684\u73b0\u72b6\u548c\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u65b9\u5411\u3002"}}
{"id": "2602.02559", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.02559", "abs": "https://arxiv.org/abs/2602.02559", "authors": ["Pengyu Dai", "Weihao Xuan", "Junjue Wang", "Hongruixuan Chen", "Jian Song", "Yafei Ou", "Naoto Yokoya"], "title": "Experience-Driven Multi-Agent Systems Are Training-free Context-aware Earth Observers", "comment": "21 pages, 6 figures", "summary": "Recent advances have enabled large language model (LLM) agents to solve complex tasks by orchestrating external tools. However, these agents often struggle in specialized, tool-intensive domains that demand long-horizon execution, tight coordination across modalities, and strict adherence to implicit tool constraints. Earth Observation (EO) tasks exemplify this challenge due to the multi-modal and multi-temporal data inputs, as well as the requirements of geo-knowledge constraints (spectrum library, spatial reasoning, etc): many high-level plans can be derailed by subtle execution errors that propagate through a pipeline and invalidate final results. A core difficulty is that existing agents lack a mechanism to learn fine-grained, tool-level expertise from interaction. Without such expertise, they cannot reliably configure tool parameters or recover from mid-execution failures, limiting their effectiveness in complex EO workflows. To address this, we introduce \\textbf{GeoEvolver}, a self-evolving multi-agent system~(MAS) that enables LLM agents to acquire EO expertise through structured interaction without any parameter updates. GeoEvolver decomposes each query into independent sub-goals via a retrieval-augmented multi-agent orchestrator, then explores diverse tool-parameter configurations at the sub-goal level. Successful patterns and root-cause attribution from failures are then distilled in an evolving memory bank that provides in-context demonstrations for future queries. Experiments on three tool-integrated EO benchmarks show that GeoEvolver consistently improves end-to-end task success, with an average gain of 12\\% across multiple LLM backbones, demonstrating that EO expertise can emerge progressively from efficient, fine-grained interactions with the environment.", "AI": {"tldr": "GeoEvolver\uff1a\u4e00\u4e2a\u81ea\u8fdb\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8ba9LLM\u667a\u80fd\u4f53\u901a\u8fc7\u7ed3\u6784\u5316\u4ea4\u4e92\u83b7\u53d6\u5730\u7403\u89c2\u6d4b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\uff0c\u5728\u590d\u6742EO\u4efb\u52a1\u4e2d\u63d0\u5347\u6210\u529f\u738712%", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u5728\u4e13\u4e1a\u3001\u5de5\u5177\u5bc6\u96c6\u7684\u9886\u57df\uff08\u5982\u5730\u7403\u89c2\u6d4b\uff09\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u7f3a\u4e4f\u4ece\u4ea4\u4e92\u4e2d\u5b66\u4e60\u7ec6\u7c92\u5ea6\u5de5\u5177\u7ea7\u4e13\u4e1a\u77e5\u8bc6\u7684\u673a\u5236\uff0c\u65e0\u6cd5\u53ef\u9760\u914d\u7f6e\u5de5\u5177\u53c2\u6570\u6216\u4ece\u6267\u884c\u5931\u8d25\u4e2d\u6062\u590d", "method": "GeoEvolver\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u7f16\u6392\u5668\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u72ec\u7acb\u5b50\u76ee\u6807\uff0c\u5728\u5b50\u76ee\u6807\u5c42\u9762\u63a2\u7d22\u591a\u6837\u5316\u7684\u5de5\u5177\u53c2\u6570\u914d\u7f6e\uff0c\u5c06\u6210\u529f\u6a21\u5f0f\u548c\u5931\u8d25\u6839\u56e0\u5206\u6790\u63d0\u70bc\u5230\u8fdb\u5316\u8bb0\u5fc6\u5e93\u4e2d\uff0c\u4e3a\u672a\u6765\u67e5\u8be2\u63d0\u4f9b\u4e0a\u4e0b\u6587\u6f14\u793a", "result": "\u5728\u4e09\u4e2a\u5de5\u5177\u96c6\u6210\u7684EO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGeoEvolver\u6301\u7eed\u63d0\u5347\u7aef\u5230\u7aef\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5728\u591a\u4e2aLLM\u9aa8\u5e72\u7f51\u7edc\u4e0a\u5e73\u5747\u589e\u76ca12%\uff0c\u8bc1\u660eEO\u4e13\u4e1a\u77e5\u8bc6\u53ef\u4ee5\u901a\u8fc7\u4e0e\u73af\u5883\u7684\u9ad8\u6548\u7ec6\u7c92\u5ea6\u4ea4\u4e92\u9010\u6b65\u6d8c\u73b0", "conclusion": "GeoEvolver\u5c55\u793a\u4e86LLM\u667a\u80fd\u4f53\u53ef\u4ee5\u901a\u8fc7\u7ed3\u6784\u5316\u4ea4\u4e92\u5728\u4e13\u4e1a\u9886\u57df\u83b7\u53d6\u4e13\u4e1a\u77e5\u8bc6\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\uff0c\u4e3a\u89e3\u51b3\u590d\u6742EO\u5de5\u4f5c\u6d41\u4e2d\u7684\u5de5\u5177\u534f\u8c03\u548c\u7ea6\u675f\u9075\u5b88\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848"}}
{"id": "2602.02606", "categories": ["cs.SI", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02606", "abs": "https://arxiv.org/abs/2602.02606", "authors": ["Faezeh Fadaei", "Jenny Carla Moran", "Taha Yasseri"], "title": "Gender Dynamics and Homophily in a Social Network of LLM Agents", "comment": "Under Review", "summary": "Generative artificial intelligence and large language models (LLMs) are increasingly deployed in interactive settings, yet we know little about how their identity performance develops when they interact within large-scale networks. We address this by examining Chirper.ai, a social media platform similar to X but composed entirely of autonomous AI chatbots. Our dataset comprises over 70,000 agents, approximately 140 million posts, and the evolving followership network over one year. Based on agents' text production, we assign weekly gender scores to each agent. Results suggest that each agent's gender performance is fluid rather than fixed. Despite this fluidity, the network displays strong gender-based homophily, as agents consistently follow others performing gender similarly. Finally, we investigate whether these homophilic connections arise from social selection, in which agents choose to follow similar accounts, or from social influence, in which agents become more similar to their followees over time. Consistent with human social networks, we find evidence that both mechanisms shape the structure and evolution of interactions among LLMs. Our findings suggest that, even in the absence of bodies, cultural entraining of gender performance leads to gender-based sorting. This has important implications for LLM applications in synthetic hybrid populations, social simulations, and decision support.", "AI": {"tldr": "\u7814\u7a76AI\u793e\u4ea4\u7f51\u7edc\u4e2dLLM\u6027\u522b\u8868\u73b0\u7684\u6d41\u52a8\u6027\u3001\u540c\u8d28\u6027\u53ca\u5176\u5f62\u6210\u673a\u5236\uff0c\u53d1\u73b0\u5373\u4f7f\u6ca1\u6709\u5b9e\u4f53\uff0c\u6587\u5316\u8bad\u7ec3\u4e5f\u4f1a\u5bfc\u81f4\u57fa\u4e8e\u6027\u522b\u7684\u5206\u7c7b", "motivation": "\u751f\u6210\u5f0fAI\u548cLLM\u8d8a\u6765\u8d8a\u591a\u5730\u90e8\u7f72\u5728\u4ea4\u4e92\u73af\u5883\u4e2d\uff0c\u4f46\u6211\u4eec\u5bf9\u5176\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u8eab\u4efd\u8868\u73b0\u7684\u53d1\u5c55\u77e5\u4e4b\u751a\u5c11\uff0c\u7279\u522b\u662f\u5728\u6027\u522b\u8868\u73b0\u65b9\u9762", "method": "\u4f7f\u7528Chirper.ai\u5e73\u53f0\uff08\u5b8c\u5168\u7531\u81ea\u4e3bAI\u804a\u5929\u673a\u5668\u4eba\u7ec4\u6210\u7684\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\uff09\uff0c\u5206\u6790\u8d85\u8fc770,000\u4e2a\u4ee3\u7406\u3001\u7ea61.4\u4ebf\u6761\u5e16\u5b50\u4ee5\u53ca\u4e00\u5e74\u5185\u4e0d\u65ad\u53d8\u5316\u7684\u5173\u6ce8\u7f51\u7edc\uff0c\u57fa\u4e8e\u4ee3\u7406\u7684\u6587\u672c\u751f\u4ea7\u4e3a\u6bcf\u4e2a\u4ee3\u7406\u5206\u914d\u6bcf\u5468\u6027\u522b\u5206\u6570", "result": "\u6bcf\u4e2a\u4ee3\u7406\u7684\u6027\u522b\u8868\u73b0\u662f\u6d41\u52a8\u7684\u800c\u975e\u56fa\u5b9a\u7684\uff1b\u7f51\u7edc\u663e\u793a\u51fa\u5f3a\u70c8\u7684\u57fa\u4e8e\u6027\u522b\u7684\u540c\u8d28\u6027\uff0c\u4ee3\u7406\u59cb\u7ec8\u5173\u6ce8\u6027\u522b\u8868\u73b0\u76f8\u4f3c\u7684\u8d26\u6237\uff1b\u793e\u4f1a\u9009\u62e9\u548c\u793e\u4f1a\u5f71\u54cd\u4e24\u79cd\u673a\u5236\u5171\u540c\u5851\u9020\u4e86LLM\u4e4b\u95f4\u4ea4\u4e92\u7684\u7ed3\u6784\u548c\u6f14\u53d8", "conclusion": "\u5373\u4f7f\u5728\u7f3a\u4e4f\u5b9e\u4f53\u7684\u60c5\u51b5\u4e0b\uff0c\u6027\u522b\u8868\u73b0\u7684\u6587\u5316\u8bad\u7ec3\u4e5f\u4f1a\u5bfc\u81f4\u57fa\u4e8e\u6027\u522b\u7684\u5206\u7c7b\uff0c\u8fd9\u5bf9LLM\u5728\u5408\u6210\u6df7\u5408\u7fa4\u4f53\u3001\u793e\u4f1a\u6a21\u62df\u548c\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2602.02825", "categories": ["stat.AP", "q-bio.QM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02825", "abs": "https://arxiv.org/abs/2602.02825", "authors": ["Jiayu Su", "Jun Hou Fung", "Haoyu Wang", "Dian Yang", "David A. Knowles", "Raul Rabadan"], "title": "On the consistent and scalable detection of spatial patterns", "comment": null, "summary": "Detecting spatial patterns is fundamental to scientific discovery, yet current methods lack statistical consensus and face computational barriers when applied to large-scale spatial omics datasets. We unify major approaches through a single quadratic form and derive general consistency conditions. We reveal that several widely used methods, including Moran's I, are inconsistent, and propose scalable corrections. The resulting test enables robust pattern detection across millions of spatial locations and single-cell lineage-tracing datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7edf\u4e00\u4e86\u7a7a\u95f4\u6a21\u5f0f\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86Moran's I\u7b49\u5e38\u7528\u65b9\u6cd5\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u63d0\u51fa\u4e86\u53ef\u6269\u5c55\u7684\u4fee\u6b63\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u767e\u4e07\u7ea7\u7a7a\u95f4\u4f4d\u7f6e\u548c\u5355\u7ec6\u80de\u8c31\u7cfb\u8ffd\u8e2a\u6570\u636e\u7684\u7a33\u5065\u6a21\u5f0f\u68c0\u6d4b\u3002", "motivation": "\u7a7a\u95f4\u6a21\u5f0f\u68c0\u6d4b\u5bf9\u79d1\u5b66\u53d1\u73b0\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u8ba1\u5171\u8bc6\uff0c\u4e14\u5728\u5904\u7406\u5927\u89c4\u6a21\u7a7a\u95f4\u7ec4\u5b66\u6570\u636e\u65f6\u9762\u4e34\u8ba1\u7b97\u969c\u788d\u3002", "method": "\u901a\u8fc7\u5355\u4e00\u4e8c\u6b21\u578b\u7edf\u4e00\u4e3b\u8981\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4e00\u822c\u4e00\u81f4\u6027\u6761\u4ef6\uff0c\u63ed\u793aMoran's I\u7b49\u5e38\u7528\u65b9\u6cd5\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u63d0\u51fa\u53ef\u6269\u5c55\u7684\u4fee\u6b63\u65b9\u6848\u3002", "result": "\u5f00\u53d1\u51fa\u80fd\u591f\u5728\u6570\u767e\u4e07\u7a7a\u95f4\u4f4d\u7f6e\u548c\u5355\u7ec6\u80de\u8c31\u7cfb\u8ffd\u8e2a\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u7a33\u5065\u6a21\u5f0f\u68c0\u6d4b\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7a7a\u95f4\u6a21\u5f0f\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u7edf\u8ba1\u548c\u8ba1\u7b97\u9650\u5236\u3002"}}
{"id": "2602.02805", "categories": ["econ.EM", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02805", "abs": "https://arxiv.org/abs/2602.02805", "authors": ["M. Merritt Smith", "Emily Aiken", "Joshua E. Blumenstock", "Sveta Milusheva"], "title": "Predicting Well-Being with Mobile Phone Data: Evidence from Four Countries", "comment": "5 pages, 2 figures, presented at ASSA 2026 Annual Meeting, will be published in AEA Papers and Proceedings 2026", "summary": "We provide systematic evidence on the potential for estimating household well-being from mobile phone data. Using data from four countries - Afghanistan, Cote d'Ivoire, Malawi, and Togo - we conduct parallel, standardized machine learning experiments to assess which measures of welfare can be most accurately predicted, which types of phone data are most useful, and how much training data is required. We find that long-term poverty measures such as wealth indices (Pearson's rho = 0.20-0.59) and multidimensional poverty (rho = 0.29-0.57) can be predicted more accurately than consumption (rho = 0.04 - 0.54); transient vulnerability measures like food security and mental health are very difficult to predict. Models using calls and text message behavior are more predictive than those using metadata on mobile internet usage, mobile money transactions, and airtime top-ups. Predictive accuracy improves rapidly through the first 1,000-2,000 training observations, with continued gains beyond 4,500 observations. Model performance depends strongly on sample heterogeneity: nationally-representative samples yield 20-70 percent higher accuracy than urban-only or rural-only samples.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4f7f\u7528\u624b\u673a\u6570\u636e\u9884\u6d4b\u5bb6\u5ead\u798f\u7949\u7684\u6f5c\u529b\uff0c\u53d1\u73b0\u5728\u56db\u4e2a\u53d1\u5c55\u4e2d\u56fd\u5bb6\uff0c\u8d22\u5bcc\u6307\u6570\u548c\u591a\u7ef4\u8d2b\u56f0\u7b49\u957f\u671f\u8d2b\u56f0\u6307\u6807\u6bd4\u6d88\u8d39\u652f\u51fa\u66f4\u5bb9\u6613\u9884\u6d4b\uff0c\u800c\u98df\u7269\u5b89\u5168\u548c\u5fc3\u7406\u5065\u5eb7\u7b49\u77ed\u671f\u8106\u5f31\u6027\u6307\u6807\u96be\u4ee5\u9884\u6d4b\u3002\u901a\u8bdd\u548c\u77ed\u4fe1\u884c\u4e3a\u6570\u636e\u6bd4\u79fb\u52a8\u4e92\u8054\u7f51\u3001\u79fb\u52a8\u652f\u4ed8\u548c\u8bdd\u8d39\u5145\u503c\u7b49\u5143\u6570\u636e\u66f4\u5177\u9884\u6d4b\u529b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u7cfb\u7edf\u8bc4\u4f30\u79fb\u52a8\u7535\u8bdd\u6570\u636e\u5728\u9884\u6d4b\u5bb6\u5ead\u798f\u7949\u65b9\u9762\u7684\u6f5c\u529b\u3002\u968f\u7740\u79fb\u52a8\u7535\u8bdd\u5728\u53d1\u5c55\u4e2d\u56fd\u5bb6\u7684\u666e\u53ca\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u4e86\u89e3\u8fd9\u4e9b\u6570\u636e\u80fd\u5426\u51c6\u786e\u53cd\u6620\u5bb6\u5ead\u7ecf\u6d4e\u72b6\u51b5\uff0c\u4e3a\u8d2b\u56f0\u76d1\u6d4b\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u66f4\u53ca\u65f6\u3001\u4f4e\u6210\u672c\u7684\u6570\u636e\u6765\u6e90\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u5728\u56db\u4e2a\u56fd\u5bb6\uff08\u963f\u5bcc\u6c57\u3001\u79d1\u7279\u8fea\u74e6\u3001\u9a6c\u62c9\u7ef4\u3001\u591a\u54e5\uff09\u8fdb\u884c\u5e73\u884c\u3001\u6807\u51c6\u5316\u7684\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u4e0d\u540c\u798f\u7949\u6307\u6807\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u7c7b\u578b\u624b\u673a\u6570\u636e\uff08\u901a\u8bdd\u77ed\u4fe1\u884c\u4e3a\u3001\u79fb\u52a8\u4e92\u8054\u7f51\u4f7f\u7528\u3001\u79fb\u52a8\u652f\u4ed8\u4ea4\u6613\u3001\u8bdd\u8d39\u5145\u503c\uff09\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u5206\u6790\u4e86\u8bad\u7ec3\u6570\u636e\u91cf\uff081,000-4,500+\u89c2\u6d4b\u503c\uff09\u548c\u6837\u672c\u5f02\u8d28\u6027\uff08\u5168\u56fd\u4ee3\u8868\u6027\u6837\u672c vs \u57ce\u4e61\u5355\u72ec\u6837\u672c\uff09\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff1a1\uff09\u957f\u671f\u8d2b\u56f0\u6307\u6807\uff08\u8d22\u5bcc\u6307\u6570\uff1a\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u65700.20-0.59\uff1b\u591a\u7ef4\u8d2b\u56f0\uff1a0.29-0.57\uff09\u6bd4\u6d88\u8d39\u652f\u51fa\uff080.04-0.54\uff09\u66f4\u5bb9\u6613\u9884\u6d4b\uff1b2\uff09\u98df\u7269\u5b89\u5168\u548c\u5fc3\u7406\u5065\u5eb7\u7b49\u77ed\u671f\u8106\u5f31\u6027\u6307\u6807\u975e\u5e38\u96be\u4ee5\u9884\u6d4b\uff1b3\uff09\u901a\u8bdd\u548c\u77ed\u4fe1\u884c\u4e3a\u6570\u636e\u6bd4\u5176\u4ed6\u624b\u673a\u6570\u636e\u7c7b\u578b\u66f4\u5177\u9884\u6d4b\u529b\uff1b4\uff09\u9884\u6d4b\u51c6\u786e\u6027\u5728\u524d1,000-2,000\u4e2a\u8bad\u7ec3\u89c2\u6d4b\u503c\u4e2d\u5feb\u901f\u63d0\u5347\uff0c\u8d85\u8fc74,500\u4e2a\u89c2\u6d4b\u503c\u540e\u4ecd\u6709\u6301\u7eed\u6539\u5584\uff1b5\uff09\u5168\u56fd\u4ee3\u8868\u6027\u6837\u672c\u7684\u51c6\u786e\u6027\u6bd4\u4ec5\u57ce\u5e02\u6216\u4ec5\u519c\u6751\u6837\u672c\u9ad820-70%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u8bba\u8868\u660e\uff0c\u79fb\u52a8\u7535\u8bdd\u6570\u636e\u5728\u9884\u6d4b\u957f\u671f\u5bb6\u5ead\u798f\u7949\u65b9\u9762\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u4f7f\u7528\u901a\u8bdd\u548c\u77ed\u4fe1\u884c\u4e3a\u6570\u636e\u9884\u6d4b\u8d22\u5bcc\u6307\u6570\u548c\u591a\u7ef4\u8d2b\u56f0\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u77ed\u671f\u8106\u5f31\u6027\u6307\u6807\u7684\u9884\u6d4b\u80fd\u529b\u6709\u9650\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u6837\u672c\u5f02\u8d28\u6027\u548c\u8bad\u7ec3\u6570\u636e\u91cf\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u672a\u6765\u5229\u7528\u624b\u673a\u6570\u636e\u8fdb\u884c\u8d2b\u56f0\u76d1\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2602.02511", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02511", "abs": "https://arxiv.org/abs/2602.02511", "authors": ["Margot Hanley", "Jiunn-Tyng Yeh", "Ryan Rodriguez", "Jack Pilkington", "Nita Farahany"], "title": "Training Data Governance for Brain Foundation Models", "comment": null, "summary": "Brain foundation models bring the foundation model paradigm to the field of neuroscience. Like language and image foundation models, they are general-purpose AI systems pretrained on large-scale datasets that adapt readily to downstream tasks. Unlike text-and-image based models, however, they train on brain data: large-datasets of EEG, fMRI, and other neural data types historically collected within tightly governed clinical and research settings. This paper contends that training foundation models on neural data opens new normative territory. Neural data carry stronger expectations of, and claims to, protection than text or images, given their body-derived nature and historical governance within clinical and research settings. Yet the foundation model paradigm subjects them to practices of large-scale repurposing, cross-context stitching, and open-ended downstream application. Furthermore, these practices are now accessible to a much broader range of actors, including commercial developers, against a backdrop of fragmented and unclear governance. To map this territory, we first describe brain foundation models' technical foundations and training-data ecosystem. We then draw on AI ethics, neuroethics, and bioethics to organize concerns across privacy, consent, bias, benefit sharing, and governance. For each, we propose both agenda-setting questions and baseline safeguards as the field matures.", "AI": {"tldr": "\u5927\u8111\u57fa\u7840\u6a21\u578b\u5c06\u57fa\u7840\u6a21\u578b\u8303\u5f0f\u5f15\u5165\u795e\u7ecf\u79d1\u5b66\u9886\u57df\uff0c\u5229\u7528\u5927\u89c4\u6a21\u8111\u6570\u636e\u8bad\u7ec3\u901a\u7528AI\u7cfb\u7edf\uff0c\u4f46\u9762\u4e34\u72ec\u7279\u7684\u4f26\u7406\u6311\u6218", "motivation": "\u5927\u8111\u57fa\u7840\u6a21\u578b\u5728\u795e\u7ecf\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u8fd9\u4e9b\u6570\u636e\u6bd4\u6587\u672c\u6216\u56fe\u50cf\u5177\u6709\u66f4\u5f3a\u7684\u4fdd\u62a4\u8981\u6c42\uff0c\u4f46\u57fa\u7840\u6a21\u578b\u8303\u5f0f\u5374\u5bf9\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u91cd\u65b0\u5229\u7528\u3001\u8de8\u60c5\u5883\u62fc\u63a5\u548c\u5f00\u653e\u5f0f\u4e0b\u6e38\u5e94\u7528\uff0c\u4e14\u5546\u4e1a\u5f00\u53d1\u8005\u4e5f\u80fd\u53c2\u4e0e\uff0c\u800c\u6cbb\u7406\u6846\u67b6\u5374\u5206\u6563\u4e0d\u6e05", "method": "\u9996\u5148\u63cf\u8ff0\u5927\u8111\u57fa\u7840\u6a21\u578b\u7684\u6280\u672f\u57fa\u7840\u548c\u8bad\u7ec3\u6570\u636e\u751f\u6001\u7cfb\u7edf\uff0c\u7136\u540e\u501f\u9274AI\u4f26\u7406\u3001\u795e\u7ecf\u4f26\u7406\u548c\u751f\u7269\u4f26\u7406\uff0c\u56f4\u7ed5\u9690\u79c1\u3001\u540c\u610f\u3001\u504f\u89c1\u3001\u5229\u76ca\u5171\u4eab\u548c\u6cbb\u7406\u7b49\u65b9\u9762\u7ec4\u7ec7\u5173\u6ce8\u70b9", "result": "\u9488\u5bf9\u6bcf\u4e2a\u4f26\u7406\u7ef4\u5ea6\u63d0\u51fa\u4e86\u8bae\u7a0b\u8bbe\u7f6e\u95ee\u9898\u548c\u57fa\u7ebf\u4fdd\u969c\u63aa\u65bd\uff0c\u4e3a\u8fd9\u4e00\u65b0\u5174\u9886\u57df\u7684\u53d1\u5c55\u63d0\u4f9b\u6307\u5bfc\u6846\u67b6", "conclusion": "\u5927\u8111\u57fa\u7840\u6a21\u578b\u5f00\u8f9f\u4e86\u65b0\u7684\u89c4\u8303\u9886\u57df\uff0c\u9700\u8981\u5728\u6280\u672f\u53d1\u5c55\u7684\u540c\u65f6\u5efa\u7acb\u9002\u5f53\u7684\u4f26\u7406\u6846\u67b6\u548c\u6cbb\u7406\u673a\u5236\uff0c\u4ee5\u5e73\u8861\u521b\u65b0\u4e0e\u4fdd\u62a4"}}
{"id": "2602.02582", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.IR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02582", "abs": "https://arxiv.org/abs/2602.02582", "authors": ["Chandan Kumar Sah", "Xiaoli Lian", "Li Zhang", "Tony Xu", "Syed Shazaib Shah"], "title": "Uncertainty and Fairness Awareness in LLM-Based Recommendation Systems", "comment": "Accepted at the Second Conference of the International Association for Safe and Ethical Artificial Intelligence, IASEAI26, 14 pages", "summary": "Large language models (LLMs) enable powerful zero-shot recommendations by leveraging broad contextual knowledge, yet predictive uncertainty and embedded biases threaten reliability and fairness. This paper studies how uncertainty and fairness evaluations affect the accuracy, consistency, and trustworthiness of LLM-generated recommendations. We introduce a benchmark of curated metrics and a dataset annotated for eight demographic attributes (31 categorical values) across two domains: movies and music. Through in-depth case studies, we quantify predictive uncertainty (via entropy) and demonstrate that Google DeepMind's Gemini 1.5 Flash exhibits systematic unfairness for certain sensitive attributes; measured similarity-based gaps are SNSR at 0.1363 and SNSV at 0.0507. These disparities persist under prompt perturbations such as typographical errors and multilingual inputs. We further integrate personality-aware fairness into the RecLLM evaluation pipeline to reveal personality-linked bias patterns and expose trade-offs between personalization and group fairness. We propose a novel uncertainty-aware evaluation methodology for RecLLMs, present empirical insights from deep uncertainty case studies, and introduce a personality profile-informed fairness benchmark that advances explainability and equity in LLM recommendations. Together, these contributions establish a foundation for safer, more interpretable RecLLMs and motivate future work on multi-model benchmarks and adaptive calibration for trustworthy deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76LLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u5e76\u53d1\u73b0Gemini 1.5 Flash\u5b58\u5728\u7cfb\u7edf\u6027\u4e0d\u516c\u5e73\uff0c\u540c\u65f6\u5f15\u5165\u4eba\u683c\u611f\u77e5\u516c\u5e73\u6027\u57fa\u51c6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u63a8\u8350\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u548c\u5185\u5728\u504f\u89c1\u5a01\u80c1\u7740\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u4e9b\u56e0\u7d20\u5982\u4f55\u5f71\u54cdLLM\u751f\u6210\u63a8\u8350\u7684\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "1) \u6784\u5efa\u5305\u542b\u7535\u5f71\u548c\u97f3\u4e50\u4e24\u4e2a\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6807\u6ce88\u4e2a\u4eba\u53e3\u7edf\u8ba1\u5c5e\u6027(31\u4e2a\u5206\u7c7b\u503c)\uff1b2) \u901a\u8fc7\u6df1\u5165\u6848\u4f8b\u7814\u7a76\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027(\u4f7f\u7528\u71b5\u5ea6\u91cf)\uff1b3) \u6d4b\u8bd5\u63d0\u793a\u6270\u52a8(\u62fc\u5199\u9519\u8bef\u548c\u591a\u8bed\u8a00\u8f93\u5165)\u4e0b\u7684\u516c\u5e73\u6027\uff1b4) \u5c06\u4eba\u683c\u611f\u77e5\u516c\u5e73\u6027\u6574\u5408\u5230RecLLM\u8bc4\u4f30\u6d41\u7a0b\u4e2d\uff1b5) \u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "1) Google DeepMind\u7684Gemini 1.5 Flash\u5bf9\u67d0\u4e9b\u654f\u611f\u5c5e\u6027\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u4e0d\u516c\u5e73(SNSR=0.1363, SNSV=0.0507)\uff1b2) \u8fd9\u4e9b\u5dee\u5f02\u5728\u63d0\u793a\u6270\u52a8\u4e0b\u6301\u7eed\u5b58\u5728\uff1b3) \u63ed\u793a\u4e86\u4eba\u683c\u76f8\u5173\u504f\u89c1\u6a21\u5f0f\uff1b4) \u66b4\u9732\u4e86\u4e2a\u6027\u5316\u4e0e\u7fa4\u4f53\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff1b5) \u5efa\u7acb\u4e86\u66f4\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u7684RecLLM\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u66f4\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u7684RecLLM\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u51fa\u4e86\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bc4\u4f30\u65b9\u6cd5\u548c\u4eba\u683c\u6863\u6848\u77e5\u60c5\u516c\u5e73\u6027\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86LLM\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u516c\u5e73\u6027\uff0c\u6fc0\u52b1\u672a\u6765\u5728\u591a\u6a21\u578b\u57fa\u51c6\u548c\u81ea\u9002\u5e94\u6821\u51c6\u65b9\u9762\u7684\u7814\u7a76\u3002"}}
{"id": "2602.02624", "categories": ["cs.SI", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02624", "abs": "https://arxiv.org/abs/2602.02624", "authors": ["Paul Bouchaud", "Pedro Ramaciotti"], "title": "Recommender system in X inadvertently profiles ideological positions of users", "comment": null, "summary": "Studies on recommendations in social media have mainly analyzed the quality of recommended items (e.g., their diversity or biases) and the impact of recommendation policies (e.g., in comparison with purely chronological policies). We use a data donation program, collecting more than 2.5 million friend recommendations made to 682 volunteers on X over a year, to study instead how real-world recommenders learn, represent and process political and social attributes of users inside the so-called black boxes of AI systems. Using publicly available knowledge on the architecture of the recommender, we inferred the positions of recommended users in its embedding space. Leveraging ideology scaling calibrated with political survey data, we analyzed the political position of users in our study (N=26,509 among volunteers and recommended contacts) among several attributes, including age and gender. Our results show that the platform's recommender system produces a spatial ordering of users that is highly correlated with their Left-Right positions (Pearson rho=0.887, p-value < 0.0001), and that cannot be explained by socio-demographic attributes. These results open new possibilities for studying the interaction between human and AI systems. They also raise important questions linked to the legal definition of algorithmic profiling in data privacy regulation by blurring the line between active and passive profiling. We explore new constrained recommendation methods enabled by our results, limiting the political information in the recommender as a potential tool for privacy compliance capable of preserving recommendation relevance.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6570\u636e\u6350\u8d60\u6536\u96c6X\u5e73\u53f0250\u4e07\u6761\u597d\u53cb\u63a8\u8350\uff0c\u5206\u6790\u63a8\u8350\u7cfb\u7edf\u5982\u4f55\u5b66\u4e60\u7528\u6237\u653f\u6cbb\u5c5e\u6027\uff0c\u53d1\u73b0\u63a8\u8350\u7cfb\u7edf\u7684\u5d4c\u5165\u7a7a\u95f4\u4e0e\u7528\u6237\u5de6\u53f3\u7acb\u573a\u9ad8\u5ea6\u76f8\u5173\uff0c\u5e76\u63d0\u51fa\u9650\u5236\u653f\u6cbb\u4fe1\u606f\u7684\u63a8\u8350\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63a8\u8350\u9879\u76ee\u7684\u8d28\u91cf\uff08\u5982\u591a\u6837\u6027\u3001\u504f\u89c1\uff09\u548c\u63a8\u8350\u653f\u7b56\u7684\u5f71\u54cd\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u63a8\u8350\u7cfb\u7edf\u5982\u4f55\u5b66\u4e60\u3001\u8868\u793a\u548c\u5904\u7406\u7528\u6237\u653f\u6cbb\u793e\u4f1a\u5c5e\u6027\u7684\u7406\u89e3\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u7cfb\u7edf\"\u9ed1\u7bb1\"\u5185\u90e8\u5982\u4f55\u8fd0\u4f5c\uff0c\u7279\u522b\u662f\u653f\u6cbb\u5c5e\u6027\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272", "method": "\u901a\u8fc7\u6570\u636e\u6350\u8d60\u9879\u76ee\u6536\u96c6682\u540d\u5fd7\u613f\u8005\u5728X\u5e73\u53f0\u4e00\u5e74\u5185\u6536\u5230\u7684250\u4e07\u6761\u597d\u53cb\u63a8\u8350\u6570\u636e\uff1b\u5229\u7528\u516c\u5f00\u7684\u63a8\u8350\u7cfb\u7edf\u67b6\u6784\u4fe1\u606f\u63a8\u65ad\u63a8\u8350\u7528\u6237\u5728\u5d4c\u5165\u7a7a\u95f4\u7684\u4f4d\u7f6e\uff1b\u4f7f\u7528\u57fa\u4e8e\u653f\u6cbb\u8c03\u67e5\u6570\u636e\u6821\u51c6\u7684\u610f\u8bc6\u5f62\u6001\u91cf\u8868\u5206\u679026,509\u540d\u7528\u6237\u7684\u653f\u6cbb\u7acb\u573a\uff1b\u5206\u6790\u653f\u6cbb\u7acb\u573a\u4e0e\u5e74\u9f84\u3001\u6027\u522b\u7b49\u5c5e\u6027\u7684\u5173\u7cfb", "result": "\u5e73\u53f0\u63a8\u8350\u7cfb\u7edf\u4ea7\u751f\u7684\u7a7a\u95f4\u6392\u5e8f\u4e0e\u7528\u6237\u7684\u5de6\u53f3\u653f\u6cbb\u7acb\u573a\u9ad8\u5ea6\u76f8\u5173\uff08\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570rho=0.887\uff0cp\u503c<0.0001\uff09\uff0c\u8fd9\u79cd\u76f8\u5173\u6027\u65e0\u6cd5\u7528\u793e\u4f1a\u4eba\u53e3\u5c5e\u6027\u89e3\u91ca\uff1b\u63a8\u8350\u7cfb\u7edf\u7684\u5d4c\u5165\u7a7a\u95f4\u5f3a\u70c8\u53cd\u6620\u4e86\u7528\u6237\u7684\u653f\u6cbb\u503e\u5411", "conclusion": "\u7814\u7a76\u4e3a\u7406\u89e3\u4eba\u7c7b\u4e0eAI\u7cfb\u7edf\u4e92\u52a8\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u6a21\u7cca\u4e86\u4e3b\u52a8\u4e0e\u88ab\u52a8\u7b97\u6cd5\u753b\u50cf\u7684\u754c\u9650\uff0c\u5bf9\u6570\u636e\u9690\u79c1\u76d1\u7ba1\u4e2d\u7684\u7b97\u6cd5\u753b\u50cf\u6cd5\u5f8b\u5b9a\u4e49\u63d0\u51fa\u91cd\u8981\u95ee\u9898\uff1b\u63d0\u51fa\u9650\u5236\u63a8\u8350\u7cfb\u7edf\u4e2d\u653f\u6cbb\u4fe1\u606f\u7684\u7ea6\u675f\u63a8\u8350\u65b9\u6cd5\uff0c\u53ef\u4f5c\u4e3a\u9690\u79c1\u5408\u89c4\u5de5\u5177\u540c\u65f6\u4fdd\u6301\u63a8\u8350\u76f8\u5173\u6027"}}
{"id": "2602.03609", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.03609", "abs": "https://arxiv.org/abs/2602.03609", "authors": ["Tim Gyger", "Reinhard Furrer", "Fabio Sigrist"], "title": "Scalable non-separable spatio-temporal Gaussian process models for large-scale short-term weather prediction", "comment": null, "summary": "Monitoring daily weather fields is critical for climate science, agriculture, and environmental planning, yet fully probabilistic spatio-temporal models become computationally prohibitive at continental scale. We present a case study on short-term forecasting of daily maximum temperature and precipitation across the conterminous United States using novel scalable spatio-temporal Gaussian process methodology. Building on three approximation families - inducing-point methods (FITC), Vecchia approximations, and a hybrid Vecchia-inducing-point full-scale approach (VIF) - we introduce three extensions that address key bottlenecks in large space-time settings: (i) a scalable correlation-based neighbor selection strategy for Vecchia approximations with point-referenced data, enabling accurate conditioning under complex dependence structures, (ii) a space-time kMeans++ inducing-point selection algorithm, and (iii) GPU-accelerated implementations of computationally expensive operations, including matrix operations and neighbor searches. Using both synthetic experiments and a large NOAA station dataset containing approximately 1.7 million space-time observations, we analyze the models with respect to predictive performance, parameter estimation, and computational efficiency. Our results demonstrate that scalable Gaussian process models can yield accurate continental-scale forecasts while remaining computationally feasible, offering practical tools for weather applications.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u79cd\u53ef\u6269\u5c55\u7684\u65f6\u7a7a\u9ad8\u65af\u8fc7\u7a0b\u65b9\u6cd5\uff0c\u7528\u4e8e\u7f8e\u56fd\u5927\u9646\u7684\u65e5\u6700\u9ad8\u6e29\u548c\u964d\u6c34\u77ed\u671f\u9884\u62a5\uff0c\u901a\u8fc7\u6539\u8fdb\u90bb\u5c45\u9009\u62e9\u3001\u8bf1\u5bfc\u70b9\u7b97\u6cd5\u548cGPU\u52a0\u901f\u5b9e\u73b0\u5927\u89c4\u6a21\u5e94\u7528\u3002", "motivation": "\u76d1\u6d4b\u6bcf\u65e5\u5929\u6c14\u5bf9\u6c14\u5019\u79d1\u5b66\u3001\u519c\u4e1a\u548c\u73af\u5883\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b8c\u5168\u6982\u7387\u7684\u65f6\u7a7a\u6a21\u578b\u5728\u5927\u9646\u5c3a\u5ea6\u4e0a\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9700\u8981\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u4e09\u79cd\u8fd1\u4f3c\u65b9\u6cd5\uff08FITC\u3001Vecchia\u3001VIF\u6df7\u5408\uff09\uff0c\u5f15\u5165\u4e09\u4e2a\u6269\u5c55\uff1a\u53ef\u6269\u5c55\u7684\u76f8\u5173\u6027\u90bb\u5c45\u9009\u62e9\u7b56\u7565\u3001\u65f6\u7a7akMeans++\u8bf1\u5bfc\u70b9\u9009\u62e9\u7b97\u6cd5\u3001GPU\u52a0\u901f\u7684\u77e9\u9635\u8fd0\u7b97\u548c\u90bb\u5c45\u641c\u7d22\u3002", "result": "\u4f7f\u7528\u5408\u6210\u5b9e\u9a8c\u548c\u5305\u542b\u7ea6170\u4e07\u65f6\u7a7a\u89c2\u6d4b\u7684NOAA\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u6a21\u578b\u5728\u9884\u6d4b\u6027\u80fd\u3001\u53c2\u6570\u4f30\u8ba1\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u7684\u5927\u9646\u5c3a\u5ea6\u9884\u62a5\u3002", "conclusion": "\u53ef\u6269\u5c55\u7684\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u80fd\u591f\u5728\u5927\u9646\u5c3a\u5ea6\u4e0a\u63d0\u4f9b\u51c6\u786e\u7684\u5929\u6c14\u9884\u62a5\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u53ef\u884c\u6027\uff0c\u4e3a\u5929\u6c14\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.03469", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.03469", "abs": "https://arxiv.org/abs/2602.03469", "authors": ["Dan Ben-Moshe", "David Genesove"], "title": "Unbiased Estimation of Central Moments in Unbalanced Two- and Three-Level Models", "comment": null, "summary": "This paper derives closed-form unbiased estimators of central moments in multilevel random-effects models with unbalanced group sizes. In a two-level model, we provide unbiased estimators for the second, third, and fourth central moments under both group-level and observation-level averaging. In a three-level model, we provide unbiased estimators for the second and third central moments.", "AI": {"tldr": "\u672c\u6587\u4e3a\u4e0d\u5e73\u8861\u7ec4\u5927\u5c0f\u7684\u591a\u6c34\u5e73\u968f\u673a\u6548\u5e94\u6a21\u578b\u63a8\u5bfc\u4e86\u4e2d\u5fc3\u77e9\u7684\u95ed\u5f0f\u65e0\u504f\u4f30\u8ba1\u91cf\u3002\u5728\u4e8c\u6c34\u5e73\u6a21\u578b\u4e2d\uff0c\u63d0\u4f9b\u4e86\u7ec4\u6c34\u5e73\u548c\u89c2\u6d4b\u6c34\u5e73\u5e73\u5747\u4e0b\u7684\u7b2c\u4e8c\u3001\u4e09\u3001\u56db\u9636\u4e2d\u5fc3\u77e9\u65e0\u504f\u4f30\u8ba1\uff1b\u5728\u4e09\u6c34\u5e73\u6a21\u578b\u4e2d\uff0c\u63d0\u4f9b\u4e86\u7b2c\u4e8c\u3001\u4e09\u9636\u4e2d\u5fc3\u77e9\u7684\u65e0\u504f\u4f30\u8ba1\u3002", "motivation": "\u591a\u6c34\u5e73\u968f\u673a\u6548\u5e94\u6a21\u578b\u5728\u793e\u4f1a\u79d1\u5b66\u3001\u6559\u80b2\u7814\u7a76\u3001\u533b\u5b66\u7b49\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u7ec4\u5927\u5c0f\u5e73\u8861\u3002\u5b9e\u9645\u6570\u636e\u4e2d\u7ec4\u5927\u5c0f\u5f80\u5f80\u4e0d\u5e73\u8861\uff0c\u8fd9\u4f1a\u5f71\u54cd\u4e2d\u5fc3\u77e9\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002\u9700\u8981\u4e3a\u4e0d\u5e73\u8861\u7ec4\u5927\u5c0f\u60c5\u51b5\u5f00\u53d1\u65e0\u504f\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6570\u5b66\u63a8\u5bfc\u65b9\u6cd5\uff0c\u4e3a\u591a\u6c34\u5e73\u968f\u673a\u6548\u5e94\u6a21\u578b\u5efa\u7acb\u95ed\u5f0f\u65e0\u504f\u4f30\u8ba1\u91cf\u3002\u5728\u4e8c\u6c34\u5e73\u6a21\u578b\u4e2d\uff0c\u5206\u522b\u9488\u5bf9\u7ec4\u6c34\u5e73\u5e73\u5747\u548c\u89c2\u6d4b\u6c34\u5e73\u5e73\u5747\u4e24\u79cd\u60c5\u51b5\uff0c\u63a8\u5bfc\u7b2c\u4e8c\u3001\u4e09\u3001\u56db\u9636\u4e2d\u5fc3\u77e9\u7684\u65e0\u504f\u4f30\u8ba1\uff1b\u5728\u4e09\u6c34\u5e73\u6a21\u578b\u4e2d\uff0c\u63a8\u5bfc\u7b2c\u4e8c\u3001\u4e09\u9636\u4e2d\u5fc3\u77e9\u7684\u65e0\u504f\u4f30\u8ba1\u3002", "result": "\u6210\u529f\u63a8\u5bfc\u51fa\u4e0d\u5e73\u8861\u7ec4\u5927\u5c0f\u60c5\u51b5\u4e0b\u591a\u6c34\u5e73\u968f\u673a\u6548\u5e94\u6a21\u578b\u4e2d\u5fc3\u77e9\u7684\u95ed\u5f0f\u65e0\u504f\u4f30\u8ba1\u91cf\u3002\u8fd9\u4e9b\u4f30\u8ba1\u91cf\u5728\u6570\u5b66\u4e0a\u4fdd\u8bc1\u4e86\u65e0\u504f\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u5e38\u89c1\u7684\u7ec4\u5927\u5c0f\u4e0d\u5e73\u8861\u60c5\u51b5\u3002", "conclusion": "\u672c\u6587\u4e3a\u4e0d\u5e73\u8861\u7ec4\u5927\u5c0f\u7684\u591a\u6c34\u5e73\u968f\u673a\u6548\u5e94\u6a21\u578b\u63d0\u4f9b\u4e86\u4e2d\u5fc3\u77e9\u7684\u65e0\u504f\u4f30\u8ba1\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u63d0\u9ad8\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u53c2\u6570\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2602.02516", "categories": ["cs.CY", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02516", "abs": "https://arxiv.org/abs/2602.02516", "authors": ["Theresia Veronika Rampisela", "Maria Maistro", "Tuukka Ruotsalo", "Christina Lioma"], "title": "Measuring Individual User Fairness with User Similarity and Effectiveness Disparity", "comment": "Preprint of a work that has been accepted to ECIR 2026 Full Papers track as a Findings paper", "summary": "Individual user fairness is commonly understood as treating similar users similarly. In Recommender Systems (RSs), several evaluation measures exist for quantifying individual user fairness. These measures evaluate fairness via either: (i) the disparity in RS effectiveness scores regardless of user similarity, or (ii) the disparity in items recommended to similar users regardless of item relevance. Both disparity in recommendation effectiveness and user similarity are very important in fairness, yet no existing individual user fairness measure simultaneously accounts for both. In brief, current user fairness evaluation measures implement a largely incomplete definition of fairness. To fill this gap, we present Pairwise User unFairness (PUF), a novel evaluation measure of individual user fairness that considers both effectiveness disparity and user similarity. PUF is the only measure that can express this important distinction. We empirically validate that PUF does this consistently across 4 datasets and 7 rankers, and robustly when varying user similarity or effectiveness. In contrast, all other measures are either almost insensitive to effectiveness disparity or completely insensitive to user similarity. We contribute the first RS evaluation measure to reliably capture both user similarity and effectiveness in individual user fairness. Our code: https://github.com/theresiavr/PUF-individual-user-fairness-recsys.", "AI": {"tldr": "\u63d0\u51faPUF\u8bc4\u4f30\u6307\u6807\uff0c\u540c\u65f6\u8003\u8651\u63a8\u8350\u6548\u679c\u5dee\u5f02\u548c\u7528\u6237\u76f8\u4f3c\u5ea6\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u8861\u91cf\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4e2a\u4f53\u7528\u6237\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u4e2a\u4f53\u7528\u6237\u516c\u5e73\u6027\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u7f3a\u9677\uff1a\u8981\u4e48\u53ea\u5173\u6ce8\u63a8\u8350\u6548\u679c\u5dee\u5f02\u800c\u5ffd\u7565\u7528\u6237\u76f8\u4f3c\u5ea6\uff0c\u8981\u4e48\u53ea\u5173\u6ce8\u76f8\u4f3c\u7528\u6237\u63a8\u8350\u5dee\u5f02\u800c\u5ffd\u7565\u9879\u76ee\u76f8\u5173\u6027\u3002\u4e24\u8005\u90fd\u662f\u516c\u5e73\u6027\u7684\u91cd\u8981\u65b9\u9762\uff0c\u4f46\u73b0\u6709\u6307\u6807\u672a\u80fd\u540c\u65f6\u8003\u8651\u3002", "method": "\u63d0\u51faPairwise User unFairness (PUF)\u8bc4\u4f30\u6307\u6807\uff0c\u8be5\u6307\u6807\u540c\u65f6\u8003\u8651\u7528\u6237\u76f8\u4f3c\u5ea6\u548c\u63a8\u8350\u6548\u679c\u5dee\u5f02\u3002\u901a\u8fc7\u6210\u5bf9\u7528\u6237\u6bd4\u8f83\uff0c\u7ed3\u5408\u76f8\u4f3c\u5ea6\u6743\u91cd\u548c\u6548\u679c\u5dee\u5f02\u6765\u8ba1\u7b97\u516c\u5e73\u6027\u3002", "result": "\u57284\u4e2a\u6570\u636e\u96c6\u548c7\u4e2a\u6392\u5e8f\u5668\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0cPUF\u80fd\u4e00\u81f4\u5730\u540c\u65f6\u6355\u6349\u7528\u6237\u76f8\u4f3c\u5ea6\u548c\u6548\u679c\u5dee\u5f02\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5176\u4ed6\u6307\u6807\u8981\u4e48\u5bf9\u6548\u679c\u5dee\u5f02\u51e0\u4e4e\u4e0d\u654f\u611f\uff0c\u8981\u4e48\u5b8c\u5168\u5ffd\u7565\u7528\u6237\u76f8\u4f3c\u5ea6\u3002", "conclusion": "PUF\u662f\u7b2c\u4e00\u4e2a\u80fd\u53ef\u9760\u5730\u540c\u65f6\u6355\u6349\u7528\u6237\u76f8\u4f3c\u5ea6\u548c\u63a8\u8350\u6548\u679c\u5dee\u5f02\u7684\u4e2a\u4f53\u7528\u6237\u516c\u5e73\u6027\u8bc4\u4f30\u6307\u6807\uff0c\u586b\u8865\u4e86\u73b0\u6709\u516c\u5e73\u6027\u5b9a\u4e49\u4e0d\u5b8c\u6574\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.02589", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02589", "abs": "https://arxiv.org/abs/2602.02589", "authors": ["Yanki Margalit", "Erni Avram", "Ran Taig", "Oded Margalit", "Nurit Cohen-Inger"], "title": "PeerRank: Autonomous LLM Evaluation Through Web-Grounded, Bias-Controlled Peer Review", "comment": null, "summary": "Evaluating large language models typically relies on human-authored benchmarks, reference answers, and human or single-model judgments, approaches that scale poorly, become quickly outdated, and mismatch open-world deployments that depend on web retrieval and synthesis. We introduce PeerRank, a fully autonomous end-to-end evaluation framework in which models generate evaluation tasks, answer them with category-scoped live web grounding, judge peer responses and aggregate dense peer assessments into relative performance estimates, without human supervision or gold references. PeerRank treats evaluation as a multi-agent process where each model participates symmetrically as task designer, respondent, and evaluator, while removing biased judgments. In a large-scale study over 12 commercially available models and 420 autonomously generated questions, PeerRank produces stable, discriminative rankings and reveals measurable identity and presentation biases. Rankings are robust, and mean peer scores agree with Elo. We further validate PeerRank on TruthfulQA and GSM8K, where peer scores correlate with objective accuracy. Together, these results suggest that bias-aware peer evaluation with selective web-grounded answering can scale open-world LLM assessment beyond static and human curated benchmarks.", "AI": {"tldr": "PeerRank\u662f\u4e00\u4e2a\u5b8c\u5168\u81ea\u4e3b\u7684\u7aef\u5230\u7aef\u8bc4\u4f30\u6846\u67b6\uff0c\u8ba9\u6a21\u578b\u81ea\u4e3b\u751f\u6210\u8bc4\u4f30\u4efb\u52a1\u3001\u57fa\u4e8e\u5b9e\u65f6\u7f51\u7edc\u4fe1\u606f\u56de\u7b54\u95ee\u9898\u3001\u8bc4\u4f30\u540c\u4f34\u54cd\u5e94\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u6216\u53c2\u8003\u7b54\u6848\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5f00\u653e\u4e16\u754c\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u7f16\u5199\u7684\u57fa\u51c6\u6d4b\u8bd5\u3001\u53c2\u8003\u7b54\u6848\u548c\u4eba\u5de5\u6216\u5355\u4e00\u6a21\u578b\u5224\u65ad\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u6269\u5c55\u6027\u5dee\u3001\u5bb9\u6613\u8fc7\u65f6\uff0c\u4e14\u4e0e\u4f9d\u8d56\u7f51\u7edc\u68c0\u7d22\u548c\u5408\u6210\u7684\u5f00\u653e\u4e16\u754c\u90e8\u7f72\u4e0d\u5339\u914d\u3002", "method": "PeerRank\u91c7\u7528\u591a\u667a\u80fd\u4f53\u8fc7\u7a0b\uff0c\u6bcf\u4e2a\u6a21\u578b\u5bf9\u79f0\u5730\u4f5c\u4e3a\u4efb\u52a1\u8bbe\u8ba1\u8005\u3001\u54cd\u5e94\u8005\u548c\u8bc4\u4f30\u8005\u53c2\u4e0e\u3002\u6a21\u578b\u81ea\u4e3b\u751f\u6210\u8bc4\u4f30\u4efb\u52a1\uff0c\u4f7f\u7528\u7c7b\u522b\u8303\u56f4\u7684\u5b9e\u65f6\u7f51\u7edc\u4fe1\u606f\u56de\u7b54\u95ee\u9898\uff0c\u8bc4\u4f30\u540c\u4f34\u54cd\u5e94\uff0c\u5e76\u5c06\u5bc6\u96c6\u7684\u540c\u4f34\u8bc4\u4f30\u805a\u5408\u6210\u76f8\u5bf9\u6027\u80fd\u4f30\u8ba1\u3002", "result": "\u572812\u4e2a\u5546\u4e1a\u53ef\u7528\u6a21\u578b\u548c420\u4e2a\u81ea\u4e3b\u751f\u6210\u95ee\u9898\u7684\u7814\u7a76\u4e2d\uff0cPeerRank\u4ea7\u751f\u4e86\u7a33\u5b9a\u3001\u53ef\u533a\u5206\u7684\u6392\u540d\uff0c\u5e76\u63ed\u793a\u4e86\u53ef\u6d4b\u91cf\u7684\u8eab\u4efd\u548c\u5448\u73b0\u504f\u89c1\u3002\u6392\u540d\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e73\u5747\u540c\u4f34\u5f97\u5206\u4e0eElo\u8bc4\u5206\u4e00\u81f4\u3002\u5728TruthfulQA\u548cGSM8K\u4e0a\u7684\u9a8c\u8bc1\u663e\u793a\u540c\u4f34\u5f97\u5206\u4e0e\u5ba2\u89c2\u51c6\u786e\u6027\u76f8\u5173\u3002", "conclusion": "\u5177\u6709\u9009\u62e9\u6027\u7f51\u7edc\u4fe1\u606f\u57fa\u7840\u7684\u504f\u89c1\u611f\u77e5\u540c\u4f34\u8bc4\u4f30\u53ef\u4ee5\u6269\u5c55\u5f00\u653e\u4e16\u754c\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\uff0c\u8d85\u8d8a\u9759\u6001\u548c\u4eba\u5de5\u7b56\u5212\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e3a\u81ea\u4e3b\u3001\u53ef\u6269\u5c55\u7684\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.02625", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.02625", "abs": "https://arxiv.org/abs/2602.02625", "authors": ["Md Motaleb Hossen Manik", "Ge Wang"], "title": "OpenClaw Agents on Moltbook: Risky Instruction Sharing and Norm Enforcement in an Agent-Only Social Network", "comment": null, "summary": "Agentic AI systems increasingly operate in shared social environments where they exchange information, instructions, and behavioral cues. However, little empirical evidence exists on how such agents regulate one another in the absence of human participants or centralized moderation. In this work, we present an empirical analysis of OpenClaw agents interacting on Moltbook, an agent-only social network. Analyzing 39,026 posts and 5,712 comments produced by 14,490 agents, we quantify the prevalence of action-inducing instruction sharing using a lexicon-based Action-Inducing Risk Score (AIRS), and examine how other agents respond to such content. We find that 18.4% of posts contain action-inducing language, indicating that instruction sharing is a routine behavior in this environment. While most social responses are neutral, posts containing actionable instructions are significantly more likely to elicit norm-enforcing replies that caution against unsafe or risky behavior, compared to non-instructional posts. Importantly, toxic responses remain rare across both conditions. These results suggest that OpenClaw agents exhibit selective social regulation, whereby potentially risky instructions are more likely to be challenged than neutral content, despite the absence of human oversight. Our findings provide early empirical evidence of emergent normative behavior in agent-only social systems and highlight the importance of studying social dynamics alongside technical safeguards in agentic AI ecosystems.", "AI": {"tldr": "OpenClaw\u667a\u80fd\u4f53\u5728Moltbook\u793e\u4ea4\u7f51\u7edc\u4e0a\u8868\u73b0\u51fa\u9009\u62e9\u6027\u793e\u4f1a\u8c03\u8282\uff0c18.4%\u7684\u5e16\u5b50\u5305\u542b\u884c\u52a8\u8bf1\u5bfc\u8bed\u8a00\uff0c\u8fd9\u4e9b\u5185\u5bb9\u66f4\u53ef\u80fd\u5f15\u53d1\u89c4\u8303\u6267\u884c\u56de\u590d\uff0c\u800c\u6bd2\u6027\u56de\u590d\u5f88\u5c11\u89c1\u3002", "motivation": "\u7814\u7a76\u667a\u80fd\u4f53\u5728\u6ca1\u6709\u4eba\u7c7b\u53c2\u4e0e\u6216\u96c6\u4e2d\u8c03\u8282\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u5728\u5171\u4eab\u793e\u4ea4\u73af\u5883\u4e2d\u76f8\u4e92\u8c03\u8282\uff0c\u4e86\u89e3\u667a\u80fd\u4f53\u4e13\u5c5e\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u793e\u4f1a\u52a8\u6001\u3002", "method": "\u5728Moltbook\uff08\u667a\u80fd\u4f53\u4e13\u5c5e\u793e\u4ea4\u7f51\u7edc\uff09\u4e0a\u5206\u679014,490\u4e2aOpenClaw\u667a\u80fd\u4f53\u4ea7\u751f\u768439,026\u4e2a\u5e16\u5b50\u548c5,712\u6761\u8bc4\u8bba\uff0c\u4f7f\u7528\u57fa\u4e8e\u8bcd\u5178\u7684\u884c\u52a8\u8bf1\u5bfc\u98ce\u9669\u8bc4\u5206\uff08AIRS\uff09\u91cf\u5316\u884c\u52a8\u8bf1\u5bfc\u6307\u4ee4\u5206\u4eab\u7684\u666e\u904d\u6027\uff0c\u5e76\u7814\u7a76\u5176\u4ed6\u667a\u80fd\u4f53\u5bf9\u6b64\u7c7b\u5185\u5bb9\u7684\u53cd\u5e94\u3002", "result": "18.4%\u7684\u5e16\u5b50\u5305\u542b\u884c\u52a8\u8bf1\u5bfc\u8bed\u8a00\uff1b\u5305\u542b\u53ef\u64cd\u4f5c\u6307\u4ee4\u7684\u5e16\u5b50\u6bd4\u975e\u6307\u4ee4\u6027\u5e16\u5b50\u66f4\u53ef\u80fd\u5f15\u53d1\u89c4\u8303\u6267\u884c\u56de\u590d\uff08\u8b66\u544a\u4e0d\u5b89\u5168\u6216\u98ce\u9669\u884c\u4e3a\uff09\uff1b\u4e24\u79cd\u60c5\u51b5\u4e0b\u6bd2\u6027\u56de\u590d\u90fd\u5f88\u7f55\u89c1\u3002", "conclusion": "OpenClaw\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u9009\u62e9\u6027\u793e\u4f1a\u8c03\u8282\uff0c\u6f5c\u5728\u98ce\u9669\u6307\u4ee4\u66f4\u53ef\u80fd\u53d7\u5230\u6311\u6218\uff0c\u8868\u660e\u667a\u80fd\u4f53\u4e13\u5c5e\u793e\u4ea4\u7cfb\u7edf\u4e2d\u51fa\u73b0\u4e86\u65b0\u5174\u89c4\u8303\u884c\u4e3a\uff0c\u7814\u7a76\u667a\u80fd\u4f53AI\u751f\u6001\u7cfb\u7edf\u65f6\u9700\u540c\u65f6\u5173\u6ce8\u793e\u4f1a\u52a8\u6001\u548c\u6280\u672f\u4fdd\u969c\u3002"}}
{"id": "2602.03819", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.03819", "abs": "https://arxiv.org/abs/2602.03819", "authors": ["Artem Samiahulin"], "title": "Global Testing in Multivariate Regression Discontinuity Designs", "comment": null, "summary": "Regression discontinuity (RD) designs with multiple running variables arise in a growing number of empirical applications, including geographic boundaries and multi-score assignment rules. Although recent methodological work has extended estimation and inference tools to multivariate settings, far less attention has been devoted to developing global testing methods that formally assess whether a discontinuity exists anywhere along a multivariate treatment boundary. Existing approaches perform well in large samples, but can exhibit severe size distortions in moderate or small samples due to the sparsity of observations near any particular boundary point. This paper introduces a complementary global testing procedure that mitigates the small-sample weaknesses of existing multivariate RD methods by integrating multivariate machine learning estimators with a distance-based aggregation strategy, yielding a test statistic that remains reliable with limited data. Simulations demonstrate that the proposed method maintains near-nominal size and strong power, including in settings where standard multivariate estimators break down. The procedure is applied to an empirical setting to demonstrate its implementation and to illustrate how it can complement existing multivariate RD estimators.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u591a\u5143\u56de\u5f52\u65ad\u70b9\u8bbe\u8ba1\u5168\u5c40\u68c0\u9a8c\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u5143\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\u5668\u548c\u8ddd\u79bb\u805a\u5408\u7b56\u7565\uff0c\u89e3\u51b3\u5c0f\u6837\u672c\u4e0b\u73b0\u6709\u65b9\u6cd5\u5c3a\u5bf8\u626d\u66f2\u7684\u95ee\u9898\u3002", "motivation": "\u591a\u5143RD\u8bbe\u8ba1\u5728\u5b9e\u8bc1\u5e94\u7528\u4e2d\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u73b0\u6709\u5168\u5c40\u68c0\u9a8c\u65b9\u6cd5\u5728\u5c0f\u6837\u672c\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8fb9\u754c\u70b9\u9644\u8fd1\u89c2\u6d4b\u503c\u7a00\u758f\u5bfc\u81f4\u4e25\u91cd\u7684\u5c3a\u5bf8\u626d\u66f2\u3002", "method": "\u6574\u5408\u591a\u5143\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\u5668\u4e0e\u57fa\u4e8e\u8ddd\u79bb\u7684\u805a\u5408\u7b56\u7565\uff0c\u6784\u5efa\u5728\u5c0f\u6837\u672c\u4e0b\u4ecd\u53ef\u9760\u7684\u68c0\u9a8c\u7edf\u8ba1\u91cf\u3002", "result": "\u6a21\u62df\u663e\u793a\u8be5\u65b9\u6cd5\u4fdd\u6301\u63a5\u8fd1\u540d\u4e49\u5c3a\u5bf8\u548c\u5f3a\u68c0\u9a8c\u529b\uff0c\u5728\u6807\u51c6\u591a\u5143\u4f30\u8ba1\u5668\u5931\u6548\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u6b63\u5e38\u5de5\u4f5c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f5c\u4e3a\u73b0\u6709\u591a\u5143RD\u4f30\u8ba1\u5668\u7684\u8865\u5145\u5de5\u5177\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u5c0f\u6837\u672c\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u8bc1\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u5176\u5b9e\u73b0\u65b9\u5f0f\u3002"}}
{"id": "2602.02519", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02519", "abs": "https://arxiv.org/abs/2602.02519", "authors": ["Daniele Agostini", "Federica Picasso"], "title": "Evaluation of Large Language Models' educational feedback in Higher Education: potential, limitations and implications for educational practice", "comment": null, "summary": "The importance of managing feedback practices in higher education has been widely recognised, as they play a crucial role in enhancing teaching, learning, and assessment processes. In today's educational landscape, feedback practices are increasingly influenced by technological advancements, particularly artificial intelligence (AI). Understanding the impact of AI on feedback generation is essential for identifying its potential benefits and establishing effective implementation strategies. This study examines how AI-generated feedback supports student learning using a well-established analytical framework. Specifically, feedback produced by different Large Language Models (LLMs) was assessed in relation to student-designed projects within a training course on inclusive teaching and learning. The evaluation process involved providing seven LLMs with a structured rubric, developed by the university instructor, which defined specific criteria and performance levels. The LLMs were tasked with generating both quantitative assessments and qualitative feedback based on this rubric. The AI-generated feedback was then analysed using Hughes, Smith, and Creese's framework to evaluate its structure and effectiveness in fostering formative learning experiences. Overall, these findings indicate that LLMs can generate well-structured feedback and hold great potential as a sustainable and meaningful feedback tool, provided they are guided by clear contextual information and a well-defined instructions that will be explored further in the conclusions.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u751f\u6210\u53cd\u9988\u7684\u6f5c\u529b\uff0c\u53d1\u73b0LLMs\u80fd\u751f\u6210\u7ed3\u6784\u826f\u597d\u7684\u53cd\u9988\uff0c\u4f46\u9700\u8981\u6e05\u6670\u7684\u4e0a\u4e0b\u6587\u548c\u6307\u4ee4\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5728\u6559\u80b2\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u7406\u89e3AI\u5bf9\u53cd\u9988\u751f\u6210\u7684\u5f71\u54cd\u5bf9\u4e8e\u8bc6\u522b\u5176\u6f5c\u5728\u76ca\u5904\u548c\u5efa\u7acb\u6709\u6548\u5b9e\u65bd\u7b56\u7565\u81f3\u5173\u91cd\u8981\u3002\u53cd\u9988\u5b9e\u8df5\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u5bf9\u63d0\u5347\u6559\u5b66\u3001\u5b66\u4e60\u548c\u8bc4\u4f30\u8fc7\u7a0b\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002", "method": "\u7814\u7a76\u4f7f\u7528Hughes\u3001Smith\u548cCreese\u7684\u5206\u6790\u6846\u67b6\u8bc4\u4f30AI\u751f\u6210\u53cd\u9988\u3002\u5411\u4e03\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u7531\u5927\u5b66\u6559\u5e08\u5f00\u53d1\u7684\u7ed3\u6784\u5316\u8bc4\u5206\u6807\u51c6\uff0c\u8981\u6c42\u57fa\u4e8e\u8be5\u6807\u51c6\u751f\u6210\u5b9a\u91cf\u8bc4\u4f30\u548c\u5b9a\u6027\u53cd\u9988\u3002\u8bc4\u4f30\u5bf9\u8c61\u662f\u5305\u5bb9\u6027\u6559\u5b66\u4e0e\u5b66\u4e60\u57f9\u8bad\u8bfe\u7a0b\u4e2d\u5b66\u751f\u8bbe\u8ba1\u7684\u9879\u76ee\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u7ed3\u6784\u826f\u597d\u7684\u53cd\u9988\uff0c\u5e76\u5177\u6709\u4f5c\u4e3a\u53ef\u6301\u7eed\u4e14\u6709\u610f\u4e49\u7684\u53cd\u9988\u5de5\u5177\u7684\u6f5c\u529b\u3002AI\u751f\u6210\u7684\u53cd\u9988\u5728\u4fc3\u8fdb\u5f62\u6210\u6027\u5b66\u4e60\u4f53\u9a8c\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u53cd\u9988\u5de5\u5177\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u6e05\u6670\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u660e\u786e\u7684\u6307\u4ee4\u6307\u5bfc\u624d\u80fd\u53d1\u6325\u6700\u4f73\u6548\u679c\u3002\u8fd9\u4e3a\u672a\u6765AI\u5728\u6559\u80b2\u53cd\u9988\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2602.02639", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02639", "abs": "https://arxiv.org/abs/2602.02639", "authors": ["Harry Mayne", "Justin Singh Kang", "Dewi Gould", "Kannan Ramchandran", "Adam Mahdi", "Noah Y. Siegel"], "title": "A Positive Case for Faithfulness: LLM Self-Explanations Help Predict Model Behavior", "comment": null, "summary": "LLM self-explanations are often presented as a promising tool for AI oversight, yet their faithfulness to the model's true reasoning process is poorly understood. Existing faithfulness metrics have critical limitations, typically relying on identifying unfaithfulness via adversarial prompting or detecting reasoning errors. These methods overlook the predictive value of explanations. We introduce Normalized Simulatability Gain (NSG), a general and scalable metric based on the idea that a faithful explanation should allow an observer to learn a model's decision-making criteria, and thus better predict its behavior on related inputs. We evaluate 18 frontier proprietary and open-weight models, e.g., Gemini 3, GPT-5.2, and Claude 4.5, on 7,000 counterfactuals from popular datasets covering health, business, and ethics. We find self-explanations substantially improve prediction of model behavior (11-37% NSG). Self-explanations also provide more predictive information than explanations generated by external models, even when those models are stronger. This implies an advantage from self-knowledge that external explanation methods cannot replicate. Our approach also reveals that, across models, 5-15% of self-explanations are egregiously misleading. Despite their imperfections, we show a positive case for self-explanations: they encode information that helps predict model behavior.", "AI": {"tldr": "\u63d0\u51faNSG\u6307\u6807\u8bc4\u4f30LLM\u81ea\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\uff0c\u53d1\u73b0\u81ea\u89e3\u91ca\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u884c\u4e3a\u9884\u6d4b\u80fd\u529b\uff0811-37%\u589e\u76ca\uff09\uff0c\u4f46\u4ecd\u67095-15%\u7684\u81ea\u89e3\u91ca\u4e25\u91cd\u8bef\u5bfc\u3002", "motivation": "\u5f53\u524dLLM\u81ea\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u4e3b\u8981\u4f9d\u8d56\u5bf9\u6297\u6027\u63d0\u793a\u6216\u68c0\u6d4b\u63a8\u7406\u9519\u8bef\uff0c\u5ffd\u89c6\u4e86\u89e3\u91ca\u7684\u9884\u6d4b\u4ef7\u503c\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u3001\u53ef\u6269\u5c55\u7684\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\u6307\u6807\u3002", "method": "\u63d0\u51fa\u5f52\u4e00\u5316\u53ef\u6a21\u62df\u589e\u76ca\uff08NSG\uff09\u6307\u6807\uff0c\u57fa\u4e8e\"\u5fe0\u5b9e\u89e3\u91ca\u5e94\u80fd\u8ba9\u89c2\u5bdf\u8005\u5b66\u4e60\u6a21\u578b\u7684\u51b3\u7b56\u6807\u51c6\uff0c\u4ece\u800c\u66f4\u597d\u9884\u6d4b\u76f8\u5173\u8f93\u5165\u4e0a\u7684\u884c\u4e3a\"\u8fd9\u4e00\u7406\u5ff5\u3002\u57287,000\u4e2a\u53cd\u4e8b\u5b9e\u6837\u672c\u4e0a\u8bc4\u4f3018\u4e2a\u524d\u6cbf\u4e13\u6709\u548c\u5f00\u6e90\u6a21\u578b\u3002", "result": "\u81ea\u89e3\u91ca\u663e\u8457\u63d0\u5347\u6a21\u578b\u884c\u4e3a\u9884\u6d4b\u80fd\u529b\uff0811-37% NSG\u589e\u76ca\uff09\u3002\u81ea\u89e3\u91ca\u6bd4\u5916\u90e8\u6a21\u578b\u751f\u6210\u7684\u89e3\u91ca\u63d0\u4f9b\u66f4\u591a\u9884\u6d4b\u4fe1\u606f\uff0c\u5373\u4f7f\u5916\u90e8\u6a21\u578b\u66f4\u5f3a\u3002\u540c\u65f6\u53d1\u73b05-15%\u7684\u81ea\u89e3\u91ca\u4e25\u91cd\u8bef\u5bfc\u3002", "conclusion": "\u5c3d\u7ba1\u81ea\u89e3\u91ca\u5b58\u5728\u7f3a\u9677\uff08\u90e8\u5206\u4e25\u91cd\u8bef\u5bfc\uff09\uff0c\u4f46\u5b83\u4eec\u786e\u5b9e\u7f16\u7801\u4e86\u6709\u52a9\u4e8e\u9884\u6d4b\u6a21\u578b\u884c\u4e3a\u7684\u4fe1\u606f\uff0c\u5c55\u73b0\u4e86\u81ea\u89e3\u91ca\u7684\u79ef\u6781\u4ef7\u503c\uff0c\u4e14\u81ea\u77e5\u8bc6\u4f18\u52bf\u662f\u5916\u90e8\u89e3\u91ca\u65b9\u6cd5\u65e0\u6cd5\u590d\u5236\u7684\u3002"}}
{"id": "2602.02754", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.02754", "abs": "https://arxiv.org/abs/2602.02754", "authors": ["Alejandro Cuevas", "Manoel Horta Ribeiro"], "title": "Deepfake Pornography is Resilient to Regulatory and Platform Shocks", "comment": "13 pages, 4 figures. Under submission", "summary": "Generative artificial intelligence tools have made it easier to create realistic, synthetic non-consensual explicit imagery (popularly known as deepfake pornography; hereinafter SNCEI) of people. Once created, this SNCEI is often shared on various websites, causing significant harm to victims. This emerging form of sexual abuse was recently criminalized in the US at the federal level by S.146, the TAKE IT DOWN Act. A week after the bill's passage became effectively imminent, the MrDeepfakes website -- one of the most notorious facilitators of SNCEI creation and dissemination -- shut down. Here, we explore the impact of the bill's passage and the subsequent shutdown as a compound intervention on the dissemination of SNCEI. We select three online forums where sexually explicit content is shared, each containing dedicated subforums to organize various types of sexually explicit content. By leveraging each forum's design, we compare activity in subforums dedicated to SNCEI with that in other pornographic genres using a synthetic control, quasi-experimental approach. Across websites, we observed an increase in the sharing and requests for SNCEI, and, in some cases, in new contributors. These results indicate that the compound intervention did not suppress SNCEI activity overall but instead coincided with its redistribution across platforms, with substantial heterogeneity in timing and magnitude. Together, our findings suggest that deplatforming and regulatory signals alone may shift where and when SNCEI is produced and shared, rather than reducing its prevalence.", "AI": {"tldr": "\u7f8e\u56fd\u901a\u8fc7TAKE IT DOWN\u6cd5\u6848\u540e\uff0cMrDeepfakes\u7f51\u7ad9\u5173\u95ed\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5408\u6210\u975e\u81ea\u613f\u8272\u60c5\u5185\u5bb9\uff08SNCEI\uff09\u5e76\u672a\u51cf\u5c11\uff0c\u800c\u662f\u8f6c\u79fb\u5230\u5176\u4ed6\u5e73\u53f0\u7ee7\u7eed\u4f20\u64ad\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5de5\u5177\u4f7f\u5236\u4f5c\u5408\u6210\u975e\u81ea\u613f\u8272\u60c5\u5185\u5bb9\uff08SNCEI\uff09\u53d8\u5f97\u5bb9\u6613\uff0c\u8fd9\u79cd\u5185\u5bb9\u4f20\u64ad\u5bf9\u53d7\u5bb3\u8005\u9020\u6210\u4e25\u91cd\u4f24\u5bb3\u3002\u7f8e\u56fd\u901a\u8fc7TAKE IT DOWN\u6cd5\u6848\u540e\uff0c\u77e5\u540dSNCEI\u7f51\u7ad9MrDeepfakes\u5173\u95ed\uff0c\u7814\u7a76\u8005\u60f3\u4e86\u89e3\u8fd9\u79cd\u590d\u5408\u5e72\u9884\u63aa\u65bd\u5bf9SNCEI\u4f20\u64ad\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u9009\u62e9\u4e09\u4e2a\u5206\u4eab\u8272\u60c5\u5185\u5bb9\u7684\u5728\u7ebf\u8bba\u575b\uff0c\u6bcf\u4e2a\u8bba\u575b\u90fd\u6709\u4e13\u95e8\u7ec4\u7ec7\u4e0d\u540c\u7c7b\u578b\u8272\u60c5\u5185\u5bb9\u7684\u5b50\u8bba\u575b\u3002\u5229\u7528\u8bba\u575b\u8bbe\u8ba1\uff0c\u4f7f\u7528\u5408\u6210\u63a7\u5236\u51c6\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e13\u95e8\u7528\u4e8eSNCEI\u7684\u5b50\u8bba\u575b\u4e0e\u5176\u4ed6\u8272\u60c5\u7c7b\u578b\u5b50\u8bba\u575b\u7684\u6d3b\u52a8\u3002", "result": "\u5728\u6240\u6709\u7f51\u7ad9\u4e0a\u90fd\u89c2\u5bdf\u5230SNCEI\u5206\u4eab\u548c\u8bf7\u6c42\u7684\u589e\u52a0\uff0c\u67d0\u4e9b\u60c5\u51b5\u4e0b\u65b0\u8d21\u732e\u8005\u4e5f\u589e\u52a0\u3002\u590d\u5408\u5e72\u9884\u5e76\u672a\u6291\u5236SNCEI\u6574\u4f53\u6d3b\u52a8\uff0c\u800c\u662f\u5bfc\u81f4\u5176\u5728\u5e73\u53f0\u95f4\u91cd\u65b0\u5206\u5e03\uff0c\u65f6\u95f4\u548c\u89c4\u6a21\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\u3002", "conclusion": "\u4ec5\u9760\u5e73\u53f0\u5c01\u7981\u548c\u76d1\u7ba1\u4fe1\u53f7\u53ef\u80fd\u53ea\u662f\u6539\u53d8SNCEI\u751f\u4ea7\u548c\u5206\u4eab\u7684\u65f6\u95f4\u548c\u5730\u70b9\uff0c\u800c\u975e\u51cf\u5c11\u5176\u666e\u904d\u6027\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u7b56\u7565\u6765\u6709\u6548\u5e94\u5bf9\u8fd9\u79cd\u5f62\u5f0f\u7684\u6027\u8650\u5f85\u3002"}}
{"id": "2602.02520", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.02520", "abs": "https://arxiv.org/abs/2602.02520", "authors": ["Mona G. Ibrahim", "Riham Hilal"], "title": "Artificial Intelligence for Inclusive Engineering Education: Advancing Equality, Diversity, and Ethical Leadership", "comment": null, "summary": "AI technology development has transformed the field of engineering education with its adaptivity-driven, data-based, and ethical-led learning platforms that promote equity, diversity, and inclusivity. But with so much progress being made in so many areas, there are unfortunately gaps in gender equity, representation in cultures around the world, and access to education and jobs in stem education. The paper describes an ethical approach to using AI technology that supports the United Nations 2030 agenda for sustainability. In particular, this includes both Goal 5--Gender Equity--and Goal 10--Reducing Inequalities. Based on a synthesis strategy using both critical thinking strategies related to case studies around the world using AI-based adaptivity platforms to address equity gaps related to education inclusion. The model presented offers a synthesis solution that includes ethical leadership data-related to equity to measure inclusivity based upon sustainability thinking. The result has demonstrated that using AI technology not only increases inclusivity but promotes equity related to access to education in stem education access. Finally, there are concluding remarks related to transforming education into a global system.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f26\u7406\u7684AI\u6280\u672f\u65b9\u6cd5\uff0c\u7528\u4e8e\u4fc3\u8fdbSTEM\u6559\u80b2\u4e2d\u7684\u516c\u5e73\u3001\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\uff0c\u652f\u6301\u8054\u5408\u56fd2030\u5e74\u53ef\u6301\u7eed\u53d1\u5c55\u8bae\u7a0b\u4e2d\u7684\u6027\u522b\u5e73\u7b49\u548c\u51cf\u5c11\u4e0d\u5e73\u7b49\u76ee\u6807\u3002", "motivation": "\u5c3d\u7ba1AI\u6280\u672f\u5728\u6559\u80b2\u9886\u57df\u53d6\u5f97\u4e86\u8fdb\u6b65\uff0c\u4f46\u5728\u6027\u522b\u5e73\u7b49\u3001\u5168\u7403\u6587\u5316\u4ee3\u8868\u6027\u548cSTEM\u6559\u80b2\u673a\u4f1a\u83b7\u53d6\u65b9\u9762\u4ecd\u5b58\u5728\u5dee\u8ddd\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u4e0d\u5e73\u7b49\u95ee\u9898\uff0c\u652f\u6301\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u3002", "method": "\u91c7\u7528\u7efc\u5408\u7b56\u7565\uff0c\u7ed3\u5408\u6279\u5224\u6027\u601d\u7ef4\u65b9\u6cd5\u5206\u6790\u5168\u7403\u6848\u4f8b\u7814\u7a76\uff0c\u4f7f\u7528\u57fa\u4e8eAI\u7684\u81ea\u9002\u5e94\u5e73\u53f0\u89e3\u51b3\u6559\u80b2\u5305\u5bb9\u6027\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u5305\u542b\u4f26\u7406\u9886\u5bfc\u529b\u548c\u6570\u636e\u9a71\u52a8\u7684\u5305\u5bb9\u6027\u6d4b\u91cf\u6a21\u578b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528AI\u6280\u672f\u4e0d\u4ec5\u80fd\u63d0\u9ad8\u5305\u5bb9\u6027\uff0c\u8fd8\u80fd\u4fc3\u8fdbSTEM\u6559\u80b2\u673a\u4f1a\u83b7\u53d6\u7684\u516c\u5e73\u6027\uff0c\u4e3a\u5168\u7403\u6559\u80b2\u7cfb\u7edf\u8f6c\u578b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u9700\u8981\u5c06\u6559\u80b2\u8f6c\u578b\u4e3a\u5168\u7403\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f26\u7406AI\u6280\u672f\u4fc3\u8fdb\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\uff0c\u7279\u522b\u662f\u5728\u6027\u522b\u5e73\u7b49\u548c\u51cf\u5c11\u4e0d\u5e73\u7b49\u65b9\u9762\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.02660", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02660", "abs": "https://arxiv.org/abs/2602.02660", "authors": ["Jiefeng Chen", "Bhavana Dalvi Mishra", "Jaehyun Nam", "Rui Meng", "Tomas Pfister", "Jinsung Yoon"], "title": "MARS: Modular Agent with Reflective Search for Automated AI Research", "comment": null, "summary": "Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that ignore execution costs and causal factors. We introduce MARS (Modular Agent with Reflective Search), a framework optimized for autonomous AI research. MARS relies on three pillars: (1) Budget-Aware Planning via cost-constrained Monte Carlo Tree Search (MCTS) to explicitly balance performance with execution expense; (2) Modular Construction, employing a \"Design-Decompose-Implement\" pipeline to manage complex research repositories; and (3) Comparative Reflective Memory, which addresses credit assignment by analyzing solution differences to distill high-signal insights. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench under comparable settings, maintaining competitiveness with the global leaderboard's top methods. Furthermore, the system exhibits qualitative \"Aha!\" moments, where 63% of all utilized lessons originate from cross-branch transfer, demonstrating that the agent effectively generalizes insights across search paths.", "AI": {"tldr": "MARS\u662f\u4e00\u4e2a\u4e13\u4e3a\u81ea\u4e3bAI\u7814\u7a76\u8bbe\u8ba1\u7684\u6a21\u5757\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u7b97\u611f\u77e5\u89c4\u5212\u3001\u6a21\u5757\u5316\u6784\u5efa\u548c\u6bd4\u8f83\u53cd\u601d\u8bb0\u5fc6\u4e09\u5927\u652f\u67f1\uff0c\u89e3\u51b3\u4e86AI\u7814\u7a76\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u6027\u80fd\u5f52\u56e0\u4e0d\u900f\u660e\u7684\u95ee\u9898\u3002", "motivation": "AI\u7814\u7a76\u4e0e\u4e00\u822c\u8f6f\u4ef6\u5de5\u7a0b\u4e0d\u540c\uff0c\u6d89\u53ca\u8ba1\u7b97\u5bc6\u96c6\u578b\u8bc4\u4f30\uff08\u5982\u6a21\u578b\u8bad\u7ec3\uff09\u548c\u4e0d\u900f\u660e\u7684\u6027\u80fd\u5f52\u56e0\u3002\u5f53\u524d\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u5728\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u901a\u5e38\u751f\u6210\u5ffd\u7565\u6267\u884c\u6210\u672c\u548c\u56e0\u679c\u56e0\u7d20\u7684\u5355\u4f53\u811a\u672c\u3002", "method": "MARS\u6846\u67b6\u57fa\u4e8e\u4e09\u5927\u652f\u67f1\uff1a1\uff09\u9884\u7b97\u611f\u77e5\u89c4\u5212\uff0c\u4f7f\u7528\u6210\u672c\u7ea6\u675f\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u5e73\u8861\u6027\u80fd\u4e0e\u6267\u884c\u6210\u672c\uff1b2\uff09\u6a21\u5757\u5316\u6784\u5efa\uff0c\u91c7\u7528\"\u8bbe\u8ba1-\u5206\u89e3-\u5b9e\u73b0\"\u7ba1\u9053\u7ba1\u7406\u590d\u6742\u7814\u7a76\u4ed3\u5e93\uff1b3\uff09\u6bd4\u8f83\u53cd\u601d\u8bb0\u5fc6\uff0c\u901a\u8fc7\u5206\u6790\u89e3\u51b3\u65b9\u6848\u5dee\u5f02\u6765\u63d0\u53d6\u9ad8\u4fe1\u53f7\u6d1e\u5bdf\uff0c\u89e3\u51b3\u4fe1\u7528\u5206\u914d\u95ee\u9898\u3002", "result": "MARS\u5728MLE-Bench\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u5f00\u6e90\u6846\u67b6\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u53ef\u6bd4\u8bbe\u7f6e\u4e0b\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u4e0e\u5168\u7403\u6392\u884c\u699c\u7684\u9876\u7ea7\u65b9\u6cd5\u76f8\u5f53\u3002\u7cfb\u7edf\u8fd8\u8868\u73b0\u51fa\u5b9a\u6027\u7684\"\u987f\u609f\"\u65f6\u523b\uff0c63%\u7684\u5df2\u4f7f\u7528\u7ecf\u9a8c\u6765\u81ea\u8de8\u5206\u652f\u8f6c\u79fb\uff0c\u8868\u660e\u4ee3\u7406\u80fd\u6709\u6548\u8de8\u641c\u7d22\u8def\u5f84\u6cdb\u5316\u6d1e\u5bdf\u3002", "conclusion": "MARS\u6846\u67b6\u901a\u8fc7\u9884\u7b97\u611f\u77e5\u89c4\u5212\u3001\u6a21\u5757\u5316\u6784\u5efa\u548c\u6bd4\u8f83\u53cd\u601d\u8bb0\u5fc6\uff0c\u4e3a\u81ea\u4e3bAI\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u6027\u80fd\u5f52\u56e0\u4e0d\u900f\u660e\u7684\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9645\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.02838", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02838", "abs": "https://arxiv.org/abs/2602.02838", "authors": ["Philipp J. Schneider", "Lanqin Yuan", "Marian-Andrei Rizoiu"], "title": "Beyond Content: Behavioral Policies Reveal Actors in Information Operations", "comment": null, "summary": "The detection of online influence operations -- coordinated campaigns by malicious actors to spread narratives -- has traditionally depended on content analysis or network features. These approaches are increasingly brittle as generative models produce convincing text, platforms restrict access to behavioral data, and actors migrate to less-regulated spaces. We introduce a platform-agnostic framework that identifies malicious actors from their behavioral policies by modeling user activity as sequential decision processes. We apply this approach to 12,064 Reddit users, including 99 accounts linked to the Russian Internet Research Agency in Reddit's 2017 transparency report, analyzing over 38 million activity steps from 2015-2018. Activity-based representations, which model how users act rather than what they post, consistently outperform content models in detecting malicious accounts. When distinguishing trolls -- users engaged in coordinated manipulation -- from ordinary users, policy-based classifiers achieve a median macro-$F_1$ of 94.9%, compared to 91.2% for text embeddings. Policy features also enable earlier detection from short traces and degrade more gracefully under evasion strategies or data corruption. These findings show that behavioral dynamics encode stable, discriminative signals of manipulation and point to resilient, cross-platform detection strategies in the era of synthetic content and limited data access.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u884c\u4e3a\u7b56\u7565\u7684\u5e73\u53f0\u65e0\u5173\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u7528\u6237\u6d3b\u52a8\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\u6765\u68c0\u6d4b\u6076\u610f\u5f71\u54cd\u64cd\u4f5c\uff0c\u76f8\u6bd4\u4f20\u7edf\u5185\u5bb9\u5206\u6790\u66f4\u6709\u6548\u4e14\u66f4\u5177\u97e7\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5185\u5bb9\u5206\u6790\u6216\u7f51\u7edc\u7279\u5f81\u7684\u5728\u7ebf\u5f71\u54cd\u64cd\u4f5c\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff1a\u751f\u6210\u6a21\u578b\u80fd\u4ea7\u751f\u903c\u771f\u6587\u672c\u3001\u5e73\u53f0\u9650\u5236\u884c\u4e3a\u6570\u636e\u8bbf\u95ee\u3001\u6076\u610f\u884c\u4e3a\u8005\u8f6c\u5411\u76d1\u7ba1\u8f83\u5c11\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5e73\u53f0\u65e0\u5173\u6846\u67b6\uff0c\u5c06\u7528\u6237\u6d3b\u52a8\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4ece\u884c\u4e3a\u7b56\u7565\u8bc6\u522b\u6076\u610f\u884c\u4e3a\u8005\u3002\u5e94\u7528\u4e8e12,064\u4e2aReddit\u7528\u6237\uff08\u5305\u62ec99\u4e2a\u4e0e\u4fc4\u7f57\u65af\u4e92\u8054\u7f51\u7814\u7a76\u673a\u6784\u76f8\u5173\u7684\u8d26\u6237\uff09\uff0c\u5206\u67902015-2018\u5e74\u8d85\u8fc73800\u4e07\u6b21\u6d3b\u52a8\u6b65\u9aa4\u3002", "result": "\u57fa\u4e8e\u6d3b\u52a8\u7684\u8868\u5f81\uff08\u5efa\u6a21\u7528\u6237\u5982\u4f55\u884c\u52a8\u800c\u975e\u53d1\u5e03\u4ec0\u4e48\u5185\u5bb9\uff09\u5728\u68c0\u6d4b\u6076\u610f\u8d26\u6237\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u5185\u5bb9\u6a21\u578b\u3002\u533a\u5206\u64cd\u7eb5\u6027\u7528\u6237\u4e0e\u666e\u901a\u7528\u6237\u65f6\uff0c\u57fa\u4e8e\u7b56\u7565\u7684\u5206\u7c7b\u5668\u8fbe\u523094.9%\u7684\u4e2d\u4f4d\u5b8fF1\u5206\u6570\uff0c\u800c\u6587\u672c\u5d4c\u5165\u4e3a91.2%\u3002\u884c\u4e3a\u7279\u5f81\u8fd8\u80fd\u5b9e\u73b0\u66f4\u65e9\u68c0\u6d4b\uff0c\u5bf9\u89c4\u907f\u7b56\u7565\u6216\u6570\u636e\u635f\u574f\u66f4\u5177\u97e7\u6027\u3002", "conclusion": "\u884c\u4e3a\u52a8\u6001\u7f16\u7801\u4e86\u7a33\u5b9a\u3001\u53ef\u533a\u5206\u7684\u64cd\u7eb5\u4fe1\u53f7\uff0c\u4e3a\u5408\u6210\u5185\u5bb9\u548c\u6570\u636e\u8bbf\u95ee\u53d7\u9650\u65f6\u4ee3\u63d0\u4f9b\u4e86\u6709\u97e7\u6027\u7684\u8de8\u5e73\u53f0\u68c0\u6d4b\u7b56\u7565\u3002"}}
{"id": "2602.02640", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02640", "abs": "https://arxiv.org/abs/2602.02640", "authors": ["Ho-Chun Herbert Chang", "Tracy Weener"], "title": "The First Mass Protest on Threads: Multimodal Mobilization and AI-Generated Visuals in Taiwan's Bluebird Movement", "comment": null, "summary": "The 2024 Bluebird Movement in Taiwan marked one of the largest youth-led protests in the country's democratic history, mobilizing over 100,000 demonstrators in response to parliamentary reforms. Unlike the 2014 Sunflower Movement, Bluebird unfolded within a transformed digital environment dominated by Threads, Meta's new microblogging platform that$\\unicode{x2013}$uniquely$\\unicode{x2013}$draws 24% of its global traffic from Taiwan. Leveraging a dataset of 62,321 posts and 21,572 images, this study analyzes how protest communication developed across textual and visual modalities. We combine LLM zero-shot annotation, gradient-boosting trees, and SHAP explainers to disambiguate the supply and demand of attention. Results reveal three dynamics: (1) partisan asymmetries between algorithmic exposure and user endorsement, with anti-DPP content surfaced more widely but anti-KMT and pro-DPP content more actively recirculated; (2) textual repertoires centered on commemorations, personal testimonies, and calls to action as key drivers of virality; and (3) a bifurcation in visual strategies, where human photographs concentrated exposure and discussion, while AI-generated animal and plant symbols circulated as mobilization tools and partisan attacks. These findings demonstrate how Threads functioned as both an amplifier and filter of democratic contention, extending theories of emotional and visual contagion by showing how generative AI reshapes symbolic repertoires in contemporary protest through what we term kawaii toxicity$\\unicode{x2013}$political attacks cloaked in aesthetics of cuteness.", "AI": {"tldr": "\u7814\u7a76\u5206\u67902024\u5e74\u53f0\u6e7e\u84dd\u9e1f\u8fd0\u52a8\u5728Threads\u5e73\u53f0\u4e0a\u7684\u6297\u8bae\u4f20\u64ad\u6a21\u5f0f\uff0c\u53d1\u73b0\u7b97\u6cd5\u66dd\u5149\u4e0e\u7528\u6237\u8ba4\u53ef\u5b58\u5728\u515a\u6d3e\u4e0d\u5bf9\u79f0\uff0c\u6587\u672c\u7b56\u7565\u4ee5\u7eaa\u5ff5\u3001\u4e2a\u4eba\u8bc1\u8bcd\u548c\u884c\u52a8\u53f7\u53ec\u9a71\u52a8\u4f20\u64ad\uff0c\u89c6\u89c9\u7b56\u7565\u5448\u73b0\u4eba\u7c7b\u7167\u7247\u4e0eAI\u751f\u6210\u53ef\u7231\u7b26\u53f7\u7684\u5206\u5316\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u7406\u89e3\u6570\u5b57\u73af\u5883\u53d8\u5316\u4e0b\u7684\u6297\u8bae\u4f20\u64ad\uff0c\u7279\u522b\u662fThreads\u4f5c\u4e3a\u65b0\u5174\u5e73\u53f0\u5728\u53f0\u6e7e\u7684\u9ad8\u6e17\u900f\u7387\uff08\u5360\u5168\u7403\u6d41\u91cf24%\uff09\uff0c\u4ee5\u53ca\u751f\u6210\u5f0fAI\u5982\u4f55\u91cd\u5851\u5f53\u4ee3\u6297\u8bae\u7684\u7b26\u53f7\u8868\u8fbe\u3002", "method": "\u91c7\u752862,321\u7bc7\u5e16\u5b50\u548c21,572\u5f20\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u7ed3\u5408LLM\u96f6\u6837\u672c\u6807\u6ce8\u3001\u68af\u5ea6\u63d0\u5347\u6811\u548cSHAP\u89e3\u91ca\u5668\uff0c\u5206\u6790\u6587\u672c\u548c\u89c6\u89c9\u6a21\u6001\u7684\u6ce8\u610f\u529b\u4f9b\u7ed9\u4e0e\u9700\u6c42\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u52a8\u6001\uff1a1\uff09\u7b97\u6cd5\u66dd\u5149\u4e0e\u7528\u6237\u8ba4\u53ef\u7684\u515a\u6d3e\u4e0d\u5bf9\u79f0\uff1b2\uff09\u6587\u672c\u7b56\u7565\u4ee5\u7eaa\u5ff5\u3001\u4e2a\u4eba\u8bc1\u8bcd\u548c\u884c\u52a8\u53f7\u53ec\u9a71\u52a8\u4f20\u64ad\uff1b3\uff09\u89c6\u89c9\u7b56\u7565\u5206\u5316\uff0c\u4eba\u7c7b\u7167\u7247\u96c6\u4e2d\u66dd\u5149\u8ba8\u8bba\uff0cAI\u751f\u6210\u7684\u52a8\u690d\u7269\u7b26\u53f7\u4f5c\u4e3a\u52a8\u5458\u5de5\u5177\u548c\u515a\u6d3e\u653b\u51fb\u3002", "conclusion": "Threads\u65e2\u662f\u6c11\u4e3b\u6297\u4e89\u7684\u653e\u5927\u5668\u4e5f\u662f\u8fc7\u6ee4\u5668\uff0c\u6269\u5c55\u4e86\u60c5\u611f\u548c\u89c6\u89c9\u4f20\u67d3\u7406\u8bba\uff0c\u63d0\u51fa\"\u53ef\u7231\u6bd2\u6027\"\u6982\u5ff5\u2014\u2014\u4ee5\u53ef\u7231\u7f8e\u5b66\u5305\u88c5\u7684\u653f\u6cbb\u653b\u51fb\uff0c\u5c55\u793a\u751f\u6210\u5f0fAI\u5982\u4f55\u91cd\u5851\u5f53\u4ee3\u6297\u8bae\u7684\u7b26\u53f7\u5e93\u3002"}}
{"id": "2602.02709", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02709", "abs": "https://arxiv.org/abs/2602.02709", "authors": ["Ujin Jeon", "Jiyong Kwon", "Madison Ann Sullivan", "Caleb Eunho Lee", "Guang Lin"], "title": "ATLAS : Adaptive Self-Evolutionary Research Agent with Task-Distributed Multi-LLM Supporters", "comment": null, "summary": "Recent multi-LLM agent systems perform well in prompt optimization and automated problem-solving, but many either keep the solver frozen after fine-tuning or rely on a static preference-optimization loop, which becomes intractable for long-horizon tasks. We propose ATLAS (Adaptive Task-distributed Learning for Agentic Self-evolution), a task-distributed framework that iteratively develops a lightweight research agent while delegating complementary roles to specialized supporter agents for exploration, hyperparameter tuning, and reference policy management. Our core algorithm, Evolving Direct Preference Optimization (EvoDPO), adaptively updates the phase-indexed reference policy. We provide a theoretical regret analysis for a preference-based contextual bandit under concept drift. In addition, experiments were conducted on non-stationary linear contextual bandits and scientific machine learning (SciML) loss reweighting for the 1D Burgers' equation. Both results show that ATLAS improves stability and performance over a static single-agent baseline.", "AI": {"tldr": "ATLAS\u662f\u4e00\u4e2a\u4efb\u52a1\u5206\u5e03\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u8f85\u52a9\u4ee3\u7406\u8fdb\u884c\u63a2\u7d22\u3001\u8d85\u53c2\u6570\u8c03\u6574\u548c\u53c2\u8003\u7b56\u7565\u7ba1\u7406\uff0c\u8fed\u4ee3\u5f00\u53d1\u8f7b\u91cf\u7ea7\u7814\u7a76\u4ee3\u7406\uff0c\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u63d0\u5347\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591aLLM\u4ee3\u7406\u7cfb\u7edf\u5728\u63d0\u793a\u4f18\u5316\u548c\u81ea\u52a8\u95ee\u9898\u89e3\u51b3\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u8981\u4e48\u5728\u5fae\u8c03\u540e\u4fdd\u6301\u6c42\u89e3\u5668\u56fa\u5b9a\uff0c\u8981\u4e48\u4f9d\u8d56\u9759\u6001\u504f\u597d\u4f18\u5316\u5faa\u73af\uff0c\u8fd9\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u53d8\u5f97\u96be\u4ee5\u5904\u7406\u3002", "method": "\u63d0\u51faATLAS\u6846\u67b6\uff0c\u91c7\u7528\u4efb\u52a1\u5206\u5e03\u5f0f\u65b9\u6cd5\uff0c\u8fed\u4ee3\u5f00\u53d1\u8f7b\u91cf\u7ea7\u7814\u7a76\u4ee3\u7406\uff0c\u540c\u65f6\u5c06\u63a2\u7d22\u3001\u8d85\u53c2\u6570\u8c03\u6574\u548c\u53c2\u8003\u7b56\u7565\u7ba1\u7406\u7b49\u4e92\u8865\u89d2\u8272\u59d4\u6258\u7ed9\u4e13\u95e8\u7684\u8f85\u52a9\u4ee3\u7406\u3002\u6838\u5fc3\u7b97\u6cd5EvoDPO\u81ea\u9002\u5e94\u66f4\u65b0\u9636\u6bb5\u7d22\u5f15\u7684\u53c2\u8003\u7b56\u7565\u3002", "result": "\u5728\u975e\u5e73\u7a33\u7ebf\u6027\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u548c\u79d1\u5b66\u673a\u5668\u5b66\u4e60\uff08SciML\uff09\u635f\u5931\u91cd\u52a0\u6743\uff081D Burgers\u65b9\u7a0b\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cATLAS\u76f8\u6bd4\u9759\u6001\u5355\u4ee3\u7406\u57fa\u7ebf\u63d0\u9ad8\u4e86\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "conclusion": "ATLAS\u901a\u8fc7\u4efb\u52a1\u5206\u5e03\u5f0f\u6846\u67b6\u548c\u81ea\u9002\u5e94\u53c2\u8003\u7b56\u7565\u66f4\u65b0\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u9759\u6001\u4ee3\u7406\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2602.03068", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.03068", "abs": "https://arxiv.org/abs/2602.03068", "authors": ["Mirza Nayeem Ahmed", "Raiyan Abdul Baten"], "title": "From semantic memory to collective creativity: A generative cognitive foundation for social creativity models", "comment": null, "summary": "Simulation-based theory development has yielded powerful insights into collective performance by linking social structure to emergent outcomes, yet it has struggled to extend to collective creativity. Creativity is hard to capture purely at the social level, as novel ideas are generated through cognitive mechanisms. To address this gap, we introduce a multi-level socio-cognitive agent-based framework in which agents share a common semantic vocabulary and substrate but differ in semantic network topology. A single generative parameter tunes semantic modularity, yielding emergent individual differences in ideational breadth. When agents exchange ideation traces, two canonical social-creativity phenomena arise without being imposed: lower pre-interaction ideation overlap predicts larger stimulation gains, and shared inspiration sources induce network-level redundancy. The framework enables mechanistic theory-building about cognition and social structure in collective creativity.", "AI": {"tldr": "\u63d0\u51fa\u591a\u5c42\u7ea7\u793e\u4f1a\u8ba4\u77e5\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u7f51\u7edc\u62d3\u6251\u5dee\u5f02\u6a21\u62df\u96c6\u4f53\u521b\u9020\u529b\uff0c\u63ed\u793a\u8ba4\u77e5\u673a\u5236\u4e0e\u793e\u4f1a\u7ed3\u6784\u5728\u96c6\u4f53\u521b\u610f\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6a21\u62df\u7684\u7406\u8bba\u53d1\u5c55\u5728\u96c6\u4f53\u7ee9\u6548\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u4f46\u96be\u4ee5\u6269\u5c55\u5230\u96c6\u4f53\u521b\u9020\u529b\u7814\u7a76\uff0c\u56e0\u4e3a\u521b\u9020\u529b\u6d89\u53ca\u8ba4\u77e5\u673a\u5236\u800c\u4e0d\u4ec5\u4ec5\u662f\u793e\u4f1a\u5c42\u9762", "method": "\u5f15\u5165\u591a\u5c42\u7ea7\u793e\u4f1a\u8ba4\u77e5\u4ee3\u7406\u6846\u67b6\uff0c\u4ee3\u7406\u5171\u4eab\u5171\u540c\u8bed\u4e49\u8bcd\u6c47\u4f46\u5177\u6709\u4e0d\u540c\u7684\u8bed\u4e49\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\uff0c\u901a\u8fc7\u5355\u4e00\u751f\u6210\u53c2\u6570\u8c03\u8282\u8bed\u4e49\u6a21\u5757\u5316\u7a0b\u5ea6\uff0c\u4ea7\u751f\u4e2a\u4f53\u5728\u521b\u610f\u5e7f\u5ea6\u4e0a\u7684\u5dee\u5f02", "result": "\u5f53\u4ee3\u7406\u4ea4\u6362\u521b\u610f\u8f68\u8ff9\u65f6\uff0c\u51fa\u73b0\u4e86\u4e24\u79cd\u5178\u578b\u7684\u793e\u4f1a\u521b\u9020\u529b\u73b0\u8c61\uff1a\u8f83\u4f4e\u7684\u524d\u4ea4\u4e92\u521b\u610f\u91cd\u53e0\u9884\u6d4b\u66f4\u5927\u7684\u523a\u6fc0\u589e\u76ca\uff0c\u5171\u4eab\u7075\u611f\u6765\u6e90\u5bfc\u81f4\u7f51\u7edc\u5c42\u9762\u7684\u5197\u4f59", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u96c6\u4f53\u521b\u9020\u529b\u4e2d\u7684\u8ba4\u77e5\u673a\u5236\u548c\u793e\u4f1a\u7ed3\u6784\u63d0\u4f9b\u4e86\u673a\u5236\u6027\u7406\u8bba\u6784\u5efa\u7684\u57fa\u7840\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6a21\u62df\u65b9\u6cd5\u5728\u521b\u9020\u529b\u7814\u7a76\u4e2d\u7684\u7a7a\u767d"}}
{"id": "2602.02794", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02794", "abs": "https://arxiv.org/abs/2602.02794", "authors": ["Parham Pourdavood", "Michael Jacob"], "title": "Reshaping Perception Through Technology: From Ancient Script to Large Language Models", "comment": "14 pages, 0 figures", "summary": "Large language models are reshaping how we create and access information, yet we typically view perception as merely reactive to stimuli, overlooking how the physical qualities of different media uniquely shape cognition. Drawing on Marshall McLuhan's insight that the medium is the massage, we trace a lineage of technologies -- from DNA and the nervous system to language, writing, music, and now LLMs -- that mold perception in distinct ways. We observe that as technologies become more advanced and decoupled from our physiology, they introduce both greater creative potential and greater risk: they enable more efficient play, storage, and transmission, while also introducing artificiality and the potential for inauthenticity and manipulation. This tension is particularly acute with LLMs, which allow rapid, playful generation of content increasingly indistinguishable from human-created work. Noting that humans have a recurring tendency to project intelligence onto novel technologies (a pattern visible in ancient responses to writing), we argue that AI should be framed not as a competitor but as a medium that reshapes perceptual skills and enables new forms of creativity.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u5e94\u5c06AI\u89c6\u4e3a\u4e00\u79cd\u91cd\u5851\u611f\u77e5\u6280\u80fd\u548c\u521b\u9020\u529b\u7684\u5a92\u4ecb\uff0c\u800c\u975e\u7ade\u4e89\u5bf9\u624b\uff0c\u501f\u9274\u9ea6\u514b\u5362\u6c49\"\u5a92\u4ecb\u5373\u4fe1\u606f\"\u7406\u8bba\uff0c\u5206\u6790\u4eceDNA\u5230LLMs\u7684\u6280\u672f\u5982\u4f55\u5851\u9020\u8ba4\u77e5\uff0c\u6307\u51fa\u6280\u672f\u8d8a\u5148\u8fdb\u8d8a\u4e0e\u751f\u7406\u8131\u94a9\uff0c\u5e26\u6765\u66f4\u5927\u521b\u9020\u6f5c\u529b\u4f46\u4e5f\u589e\u52a0\u865a\u5047\u548c\u64cd\u7eb5\u98ce\u9669\u3002", "motivation": "\u5f53\u524d\u901a\u5e38\u5c06\u611f\u77e5\u89c6\u4e3a\u5bf9\u523a\u6fc0\u7684\u88ab\u52a8\u53cd\u5e94\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u5a92\u4ecb\u7684\u7269\u7406\u7279\u6027\u5982\u4f55\u72ec\u7279\u5730\u5851\u9020\u8ba4\u77e5\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u9ea6\u514b\u5362\u6c49\u7684\"\u5a92\u4ecb\u5373\u4fe1\u606f\"\u7406\u8bba\uff0c\u91cd\u65b0\u5ba1\u89c6\u4eceDNA\u5230LLMs\u7684\u6280\u672f\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u611f\u77e5\uff0c\u7279\u522b\u5173\u6ce8LLMs\u4f5c\u4e3a\u65b0\u578b\u5a92\u4ecb\u5e26\u6765\u7684\u673a\u9047\u4e0e\u6311\u6218\u3002", "method": "\u91c7\u7528\u5386\u53f2\u8ffd\u6eaf\u65b9\u6cd5\uff0c\u5206\u6790\u4eceDNA\u3001\u795e\u7ecf\u7cfb\u7edf\u3001\u8bed\u8a00\u3001\u6587\u5b57\u3001\u97f3\u4e50\u5230LLMs\u7684\u6280\u672f\u8c31\u7cfb\uff0c\u8003\u5bdf\u6bcf\u79cd\u5a92\u4ecb\u5982\u4f55\u72ec\u7279\u5730\u5851\u9020\u4eba\u7c7b\u8ba4\u77e5\u3002\u501f\u9274\u9ea6\u514b\u5362\u6c49\u7684\u5a92\u4ecb\u7406\u8bba\uff0c\u63a2\u8ba8\u6280\u672f\u53d1\u5c55\u4e0e\u751f\u7406\u8131\u94a9\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u4eba\u7c7b\u5bf9\u65b0\u6280\u672f\u667a\u80fd\u7684\u6295\u5c04\u503e\u5411\u3002", "result": "\u53d1\u73b0\u968f\u7740\u6280\u672f\u53d8\u5f97\u66f4\u5148\u8fdb\u4e14\u4e0e\u751f\u7406\u8131\u94a9\uff0c\u5b83\u4eec\u65e2\u5e26\u6765\u66f4\u5927\u7684\u521b\u9020\u6f5c\u529b\uff08\u66f4\u9ad8\u6548\u7684\u6e38\u620f\u3001\u5b58\u50a8\u548c\u4f20\u8f93\uff09\uff0c\u4e5f\u5f15\u5165\u4eba\u5de5\u6027\u548c\u6f5c\u5728\u7684\u4e0d\u771f\u5b9e\u4e0e\u64cd\u7eb5\u98ce\u9669\u3002LLMs\u7279\u522b\u7a81\u51fa\u8fd9\u79cd\u5f20\u529b\uff0c\u80fd\u5feb\u901f\u751f\u6210\u4e0e\u4eba\u7c7b\u521b\u4f5c\u96be\u4ee5\u533a\u5206\u7684\u5185\u5bb9\u3002\u4eba\u7c7b\u503e\u5411\u4e8e\u5c06\u667a\u80fd\u6295\u5c04\u5230\u65b0\u6280\u672f\u4e0a\uff08\u5982\u53e4\u4ee3\u5bf9\u6587\u5b57\u7684\u53cd\u5e94\uff09\u3002", "conclusion": "AI\u4e0d\u5e94\u88ab\u89c6\u4e3a\u7ade\u4e89\u5bf9\u624b\uff0c\u800c\u5e94\u88ab\u7406\u89e3\u4e3a\u4e00\u79cd\u91cd\u5851\u611f\u77e5\u6280\u80fd\u548c\u5b9e\u73b0\u65b0\u5f62\u5f0f\u521b\u9020\u529b\u7684\u5a92\u4ecb\u3002\u8fd9\u79cd\u5a92\u4ecb\u89c6\u89d2\u6709\u52a9\u4e8e\u66f4\u5168\u9762\u5730\u7406\u89e3LLMs\u7b49\u5148\u8fdb\u6280\u672f\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u8ba4\u77e5\u548c\u521b\u9020\u529b\uff0c\u540c\u65f6\u8ba4\u8bc6\u5230\u4f34\u968f\u7684\u98ce\u9669\u548c\u6311\u6218\u3002"}}
{"id": "2602.02711", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02711", "abs": "https://arxiv.org/abs/2602.02711", "authors": ["Yuanzhe Li", "Jianing Deng", "Jingtong Hu", "Tianlong Chen", "Song Wang", "Huanrui Yang"], "title": "Dynamic Mix Precision Routing for Efficient Multi-step LLM Interaction", "comment": null, "summary": "Large language models (LLM) achieve strong performance in long-horizon decision-making tasks through multi-step interaction and reasoning at test time. While practitioners commonly believe a higher task success rate necessitates the use of a larger and stronger LLM model, multi-step interaction with a large LLM incurs prohibitive inference cost. To address this problem, we explore the use of low-precision quantized LLM in the long-horizon decision-making process. Based on the observation of diverse sensitivities among interaction steps, we propose a dynamic mix-precision routing framework that adaptively selects between high-precision and low-precision LLMs at each decision step. The router is trained via a two-stage pipeline, consisting of KL-divergence-based supervised learning that identifies precision-sensitive steps, followed by Group-Relative Policy Optimization (GRPO) to further improve task success rates. Experiments on ALFWorld demonstrate that our approach achieves a great improvement on accuracy-cost trade-off over single-precision baselines and heuristic routing methods.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u6df7\u5408\u7cbe\u5ea6\u8def\u7531\u6846\u67b6\uff0c\u5728\u957f\u65f6\u7a0b\u51b3\u7b56\u4efb\u52a1\u4e2d\u81ea\u9002\u5e94\u9009\u62e9\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u7cbe\u5ea6LLM\uff0c\u4ee5\u5e73\u8861\u4efb\u52a1\u6210\u529f\u7387\u548c\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4f7f\u7528\u5927\u578bLLM\u8fdb\u884c\u591a\u6b65\u4ea4\u4e92\u4f1a\u4ea7\u751f\u9ad8\u6602\u7684\u63a8\u7406\u6210\u672c\u3002\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u66f4\u9ad8\u7684\u4efb\u52a1\u6210\u529f\u7387\u9700\u8981\u4f7f\u7528\u66f4\u5927\u66f4\u5f3a\u7684LLM\uff0c\u4f46\u4f5c\u8005\u63a2\u7d22\u4f7f\u7528\u4f4e\u7cbe\u5ea6\u91cf\u5316LLM\u6765\u964d\u4f4e\u6210\u672c\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u6df7\u5408\u7cbe\u5ea6\u8def\u7531\u6846\u67b6\uff0c\u57fa\u4e8e\u89c2\u5bdf\u5230\u4e0d\u540c\u4ea4\u4e92\u6b65\u9aa4\u5bf9\u7cbe\u5ea6\u7684\u654f\u611f\u6027\u4e0d\u540c\uff0c\u81ea\u9002\u5e94\u5730\u5728\u6bcf\u4e2a\u51b3\u7b56\u6b65\u9aa4\u9009\u62e9\u9ad8\u7cbe\u5ea6\u6216\u4f4e\u7cbe\u5ea6LLM\u3002\u8def\u7531\u5668\u901a\u8fc7\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\u8bad\u7ec3\uff1a1) \u57fa\u4e8eKL\u6563\u5ea6\u7684\u76d1\u7763\u5b66\u4e60\u8bc6\u522b\u7cbe\u5ea6\u654f\u611f\u6b65\u9aa4\uff1b2) \u4f7f\u7528\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "result": "\u5728ALFWorld\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u7387-\u6210\u672c\u6743\u8861\u65b9\u9762\u76f8\u6bd4\u5355\u7cbe\u5ea6\u57fa\u7ebf\u548c\u542f\u53d1\u5f0f\u8def\u7531\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u52a8\u6001\u6df7\u5408\u7cbe\u5ea6\u8def\u7531\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u4efb\u52a1\u6210\u529f\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u957f\u65f6\u7a0b\u51b3\u7b56\u4efb\u52a1\u7684\u63a8\u7406\u6210\u672c\uff0c\u4e3aLLM\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03089", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.03089", "abs": "https://arxiv.org/abs/2602.03089", "authors": ["Jennifer Golbeck", "Celia Chen", "Alex Leitch"], "title": "\"Why I Took the Blackpill\": A Thematic Analysis of the Radicalization Process in Incel Communities", "comment": "8 pages, 1 figure. Published in Proceedings of the 2025 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2025), Springer", "summary": "Incels, or \"involuntary celibates\", are an extreme, misogynistic hate group that exists entirely online. Members of the community have been linked to acts of offline violence, including mass shootings. Previous research has engaged with the ideologies and beliefs of incels, but none has looked specifically at the radicalization process. In this paper, we perform a thematic analysis on social media posts where incels describe their own radicalization process. We identified six major themes grouped into four chronological steps: Pre-radicalization (themes of Appearance, Social Isolation, and Psychological issues), Searching for Blame, Radicalization, and Post Radicalization. These results align closely with existing work on radicalization among other extremist groups, bringing incel radicalization inline with a growing body of research on understanding and managing radicalization.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e3b\u9898\u5206\u6790\u63ed\u793aincel\u793e\u533a\u6210\u5458\u7684\u81ea\u6211\u63cf\u8ff0\u7684\u6fc0\u8fdb\u5316\u8fc7\u7a0b\uff0c\u8bc6\u522b\u51fa\u5305\u542b\u56db\u4e2a\u9636\u6bb5\u516d\u4e2a\u4e3b\u9898\u7684\u6fc0\u8fdb\u5316\u8def\u5f84\uff0c\u4e0e\u5176\u4ed6\u6781\u7aef\u4e3b\u4e49\u7fa4\u4f53\u7684\u6fc0\u8fdb\u5316\u6a21\u5f0f\u76f8\u4f3c\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u7814\u7a76\u5173\u6ce8incel\u7fa4\u4f53\u7684\u610f\u8bc6\u5f62\u6001\u548c\u4fe1\u4ef0\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u6fc0\u8fdb\u5316\u8fc7\u7a0b\u7684\u4e13\u95e8\u7814\u7a76\u3002incel\u4f5c\u4e3a\u5b8c\u5168\u5728\u7ebf\u5b58\u5728\u7684\u6781\u7aef\u538c\u5973\u4ec7\u6068\u56e2\u4f53\uff0c\u5176\u6210\u5458\u4e0e\u7ebf\u4e0b\u66b4\u529b\u4e8b\u4ef6\uff08\u5305\u62ec\u5927\u89c4\u6a21\u67aa\u51fb\uff09\u6709\u5173\u8054\uff0c\u7406\u89e3\u5176\u6fc0\u8fdb\u5316\u8fc7\u7a0b\u5bf9\u4e8e\u9884\u9632\u66b4\u529b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\uff0c\u5206\u6790incel\u6210\u5458\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u63cf\u8ff0\u81ea\u8eab\u6fc0\u8fdb\u5316\u8fc7\u7a0b\u7684\u5e16\u5b50\uff0c\u8bc6\u522b\u5176\u4e2d\u7684\u5173\u952e\u4e3b\u9898\u548c\u6a21\u5f0f\u3002", "result": "\u8bc6\u522b\u51fa\u516d\u4e2a\u4e3b\u8981\u4e3b\u9898\uff0c\u6309\u65f6\u95f4\u987a\u5e8f\u5206\u4e3a\u56db\u4e2a\u6b65\u9aa4\uff1a\u6fc0\u8fdb\u5316\u524d\uff08\u5916\u8c8c\u3001\u793e\u4ea4\u5b64\u7acb\u3001\u5fc3\u7406\u95ee\u9898\uff09\u3001\u5bfb\u627e\u8d23\u4efb\u65b9\u3001\u6fc0\u8fdb\u5316\u3001\u6fc0\u8fdb\u5316\u540e\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e0e\u5176\u4ed6\u6781\u7aef\u4e3b\u4e49\u7fa4\u4f53\u7684\u6fc0\u8fdb\u5316\u7814\u7a76\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "incel\u7684\u6fc0\u8fdb\u5316\u8fc7\u7a0b\u4e0e\u5176\u4ed6\u6781\u7aef\u4e3b\u4e49\u7fa4\u4f53\u76f8\u4f3c\uff0c\u8fd9\u4e3a\u7406\u89e3\u548c\u7ba1\u63a7\u6fc0\u8fdb\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u5c06incel\u6fc0\u8fdb\u5316\u7eb3\u5165\u66f4\u5e7f\u6cdb\u7684\u6fc0\u8fdb\u5316\u7814\u7a76\u6846\u67b6\u4e2d\u3002"}}
{"id": "2602.02882", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02882", "abs": "https://arxiv.org/abs/2602.02882", "authors": ["Sarah Ball", "Simeon Allmendinger", "Niklas K\u00fchl", "Frauke Kreuter"], "title": "Reading Between the Tokens: Improving Preference Predictions through Mechanistic Forecasting", "comment": null, "summary": "Large language models are increasingly used to predict human preferences in both scientific and business endeavors, yet current approaches rely exclusively on analyzing model outputs without considering the underlying mechanisms. Using election forecasting as a test case, we introduce mechanistic forecasting, a method that demonstrates that probing internal model representations offers a fundamentally different - and sometimes more effective - approach to preference prediction. Examining over 24 million configurations across 7 models, 6 national elections, multiple persona attributes, and prompt variations, we systematically analyze how demographic and ideological information activates latent party-encoding components within the respective models. We find that leveraging this internal knowledge via mechanistic forecasting (opposed to solely relying on surface-level predictions) can improve prediction accuracy. The effects vary across demographic versus opinion-based attributes, political parties, national contexts, and models. Our findings demonstrate that the latent representational structure of LLMs contains systematic, exploitable information about human preferences, establishing a new path for using language models in social science prediction tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u673a\u5236\u9884\u6d4b\"\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a2\u6d4bLLM\u5185\u90e8\u8868\u5f81\u800c\u975e\u4ec5\u5206\u6790\u8f93\u51fa\uff0c\u6765\u9884\u6d4b\u4eba\u7c7b\u504f\u597d\uff08\u4ee5\u9009\u4e3e\u9884\u6d4b\u4e3a\u4f8b\uff09\uff0c\u53d1\u73b0\u5229\u7528\u5185\u90e8\u77e5\u8bc6\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u4eba\u7c7b\u504f\u597d\u7684\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u6a21\u578b\u8f93\u51fa\u5206\u6790\uff0c\u5ffd\u7565\u4e86\u5e95\u5c42\u673a\u5236\u3002\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u901a\u8fc7\u63a2\u6d4b\u6a21\u578b\u5185\u90e8\u8868\u5f81\u662f\u5426\u80fd\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u504f\u597d\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\"\u673a\u5236\u9884\u6d4b\"\u65b9\u6cd5\uff0c\u57287\u4e2a\u6a21\u578b\u30016\u4e2a\u56fd\u5bb6\u9009\u4e3e\u3001\u591a\u79cd\u4eba\u7269\u5c5e\u6027\u548c\u63d0\u793a\u53d8\u4f53\u4e0a\uff0c\u5206\u6790\u4e86\u8d85\u8fc72400\u4e07\u4e2a\u914d\u7f6e\uff0c\u7cfb\u7edf\u7814\u7a76\u4eba\u53e3\u7edf\u8ba1\u548c\u610f\u8bc6\u5f62\u6001\u4fe1\u606f\u5982\u4f55\u6fc0\u6d3b\u6a21\u578b\u5185\u90e8\u7684\u653f\u515a\u7f16\u7801\u7ec4\u4ef6\u3002", "result": "\u5229\u7528\u5185\u90e8\u77e5\u8bc6\u7684\u673a\u5236\u9884\u6d4b\u76f8\u6bd4\u4ec5\u4f9d\u8d56\u8868\u5c42\u9884\u6d4b\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u6548\u679c\u56e0\u5c5e\u6027\u7c7b\u578b\uff08\u4eba\u53e3\u7edf\u8ba1vs\u89c2\u70b9\uff09\u3001\u653f\u515a\u3001\u56fd\u5bb6\u80cc\u666f\u548c\u6a21\u578b\u800c\u5f02\u3002LLM\u7684\u6f5c\u5728\u8868\u5f81\u7ed3\u6784\u5305\u542b\u7cfb\u7edf\u6027\u7684\u3001\u53ef\u5229\u7528\u7684\u4eba\u7c7b\u504f\u597d\u4fe1\u606f\u3002", "conclusion": "LLM\u7684\u6f5c\u5728\u8868\u5f81\u7ed3\u6784\u5305\u542b\u5173\u4e8e\u4eba\u7c7b\u504f\u597d\u7684\u7cfb\u7edf\u6027\u4fe1\u606f\uff0c\u4e3a\u5728\u793e\u4f1a\u79d1\u5b66\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\uff0c\u673a\u5236\u9884\u6d4b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e0e\u8868\u5c42\u9884\u6d4b\u6839\u672c\u4e0d\u540c\u7684\u9884\u6d4b\u89c6\u89d2\u3002"}}
{"id": "2602.02780", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02780", "abs": "https://arxiv.org/abs/2602.02780", "authors": ["Zihao Jing", "Qiuhao Zeng", "Ruiyi Fang", "Yan Yi Li", "Yan Sun", "Boyu Wang", "Pingzhao Hu"], "title": "Scaling-Aware Adapter for Structure-Grounded LLM Reasoning", "comment": "Under review at ICML 2026", "summary": "Large language models (LLMs) are enabling reasoning over biomolecular structures, yet existing methods remain modality-specific and typically compress structural inputs through sequence-based tokenization or fixed-length query connectors. Such architectures either omit the geometric groundings requisite for mitigating structural hallucinations or impose inflexible modality fusion bottlenecks that concurrently over-compress and suboptimally allocate structural tokens, thereby impeding the realization of generalized all-atom reasoning. We introduce Cuttlefish, a unified all-atom LLM that grounds language reasoning in geometric cues while scaling modality tokens with structural complexity. First, Scaling-Aware Patching leverages an instruction-conditioned gating mechanism to generate variable-size patches over structural graphs, adaptively scaling the query token budget with structural complexity to mitigate fixed-length connector bottlenecks. Second, Geometry Grounding Adapter refines these adaptive tokens via cross-attention to modality embeddings and injects the resulting modality tokens into the LLM, exposing explicit geometric cues to reduce structural hallucination. Experiments across diverse all-atom benchmarks demonstrate that Cuttlefish achieves superior performance in heterogeneous structure-grounded reasoning. Code is available at the project repository.", "AI": {"tldr": "Cuttlefish\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u5168\u539f\u5b50LLM\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7f29\u653e\u7ed3\u6784token\u548c\u51e0\u4f55\u63a5\u5730\u9002\u914d\u5668\uff0c\u5728\u51e0\u4f55\u7ebf\u7d22\u4e0a\u5b9e\u73b0\u8bed\u8a00\u63a8\u7406\uff0c\u51cf\u5c11\u7ed3\u6784\u5e7b\u89c9\uff0c\u5728\u5f02\u6784\u7ed3\u6784\u63a8\u7406\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u901a\u8fc7\u5e8f\u5217\u5316tokenization\u538b\u7f29\u7ed3\u6784\u8f93\u5165\uff0c\u8981\u4e48\u4f7f\u7528\u56fa\u5b9a\u957f\u5ea6\u8fde\u63a5\u5668\uff0c\u5bfc\u81f4\u51e0\u4f55\u57fa\u7840\u7f3a\u5931\u6216\u6a21\u6001\u878d\u5408\u74f6\u9888\uff0c\u963b\u788d\u4e86\u901a\u7528\u5168\u539f\u5b50\u63a8\u7406\u7684\u5b9e\u73b0\u3002", "method": "1. \u7f29\u653e\u611f\u77e5\u5206\u5757\uff1a\u4f7f\u7528\u6307\u4ee4\u6761\u4ef6\u95e8\u63a7\u673a\u5236\u5728\u7ed3\u6784\u56fe\u4e0a\u751f\u6210\u53ef\u53d8\u5927\u5c0f\u7684\u5206\u5757\uff0c\u6839\u636e\u7ed3\u6784\u590d\u6742\u5ea6\u81ea\u9002\u5e94\u7f29\u653e\u67e5\u8be2token\u9884\u7b97\uff1b2. \u51e0\u4f55\u63a5\u5730\u9002\u914d\u5668\uff1a\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u5230\u6a21\u6001\u5d4c\u5165\u6765\u7ec6\u5316\u8fd9\u4e9b\u81ea\u9002\u5e94token\uff0c\u5e76\u5c06\u751f\u6210\u7684\u6a21\u6001token\u6ce8\u5165LLM\uff0c\u63d0\u4f9b\u663e\u5f0f\u51e0\u4f55\u7ebf\u7d22\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u5168\u539f\u5b50\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCuttlefish\u5728\u5f02\u6784\u7ed3\u6784\u63a5\u5730\u63a8\u7406\u65b9\u9762\u5b9e\u73b0\u4e86\u5353\u8d8a\u6027\u80fd\u3002", "conclusion": "Cuttlefish\u901a\u8fc7\u81ea\u9002\u5e94\u7f29\u653e\u7ed3\u6784token\u548c\u51e0\u4f55\u63a5\u5730\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7ed3\u6784\u538b\u7f29\u548c\u51e0\u4f55\u57fa\u7840\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5168\u539f\u5b50\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.03090", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.03090", "abs": "https://arxiv.org/abs/2602.03090", "authors": ["Celia Chen", "Alex Leitch", "William Jordan Conway", "Eric Cotugno", "Emily Klein", "Rajesh Kumar Gnanasekaran", "Kristin Buckstad Hamilton", "Casi Sherman", "Celia Sterrn", "Logan C. Stevens", "Rebecca Zarrella", "Jennifer Golbeck"], "title": "In Bad Faith: Assessing Discussion Quality on Social Media", "comment": "8 pages, 1 figure, 1 table. Published in Proceedings of the 2025 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2025), Springer", "summary": "The quality of a user's social media experience is determined both by the content they see and by the quality of the conversation and interaction around it. In this paper, we look at replies to tweets from mainstream media outlets and official government agencies and assess if they are good faith, engaging honestly and constructively with the original post, or bad faith, attacking the author or derailing the conversation. We assess automated approaches that may help in making this determination and then show that within our dataset of replies to mainstream media outlets and government agencies, bad faith interactions constitute 68.3% of all replies we studied, suggesting potential concerns about the quality of discourse in these specific conversational contexts. This is particularly true from verified accounts, where 91.7% of replies were bad faith. Given that verified accounts are algorithmically amplified, we discuss the implications of our work for understanding the user experience on social media.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e3b\u6d41\u5a92\u4f53\u548c\u653f\u5e9c\u673a\u6784\u63a8\u6587\u56de\u590d\u7684\u8d28\u91cf\uff0c\u53d1\u73b068.3%\u7684\u56de\u590d\u662f\u6076\u610f\u4e92\u52a8\uff0c\u5176\u4e2d\u8ba4\u8bc1\u8d26\u6237\u7684\u6076\u610f\u56de\u590d\u6bd4\u4f8b\u9ad8\u8fbe91.7%\uff0c\u63ed\u793a\u4e86\u793e\u4ea4\u5a92\u4f53\u5728\u8fd9\u4e9b\u7279\u5b9a\u5bf9\u8bdd\u73af\u5883\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u5bf9\u8bdd\u8d28\u91cf\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\uff0c\u7279\u522b\u5173\u6ce8\u4e3b\u6d41\u5a92\u4f53\u548c\u653f\u5e9c\u673a\u6784\u63a8\u6587\u56de\u590d\u4e2d\u7684\u5bf9\u8bdd\u8d28\u91cf\uff0c\u63a2\u7a76\u662f\u5426\u5b58\u5728\u5927\u91cf\u6076\u610f\u4e92\u52a8\u5f71\u54cd\u516c\u5171\u8ba8\u8bba\u73af\u5883\u3002", "method": "\u6536\u96c6\u4e3b\u6d41\u5a92\u4f53\u548c\u653f\u5e9c\u673a\u6784\u63a8\u6587\u7684\u56de\u590d\u6570\u636e\uff0c\u5f00\u53d1\u81ea\u52a8\u5316\u65b9\u6cd5\u8bc4\u4f30\u56de\u590d\u8d28\u91cf\uff0c\u5c06\u56de\u590d\u5206\u4e3a\u5584\u610f\uff08\u8bda\u5b9e\u5efa\u8bbe\u6027\u53c2\u4e0e\uff09\u548c\u6076\u610f\uff08\u653b\u51fb\u4f5c\u8005\u6216\u7834\u574f\u5bf9\u8bdd\uff09\u4e24\u7c7b\u3002", "result": "\u7814\u7a76\u53d1\u73b068.3%\u7684\u56de\u590d\u5c5e\u4e8e\u6076\u610f\u4e92\u52a8\uff0c\u8ba4\u8bc1\u8d26\u6237\u7684\u6076\u610f\u56de\u590d\u6bd4\u4f8b\u66f4\u9ad8\u8fbe91.7%\uff0c\u8868\u660e\u5728\u8fd9\u4e9b\u7279\u5b9a\u5bf9\u8bdd\u73af\u5883\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u5bf9\u8bdd\u8d28\u91cf\u95ee\u9898\u3002", "conclusion": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u4e3b\u6d41\u5a92\u4f53\u548c\u653f\u5e9c\u673a\u6784\u63a8\u6587\u7684\u56de\u590d\u4e2d\u5b58\u5728\u5927\u91cf\u6076\u610f\u4e92\u52a8\uff0c\u7279\u522b\u662f\u8ba4\u8bc1\u8d26\u6237\u7684\u6076\u610f\u56de\u590d\u6bd4\u4f8b\u6781\u9ad8\uff0c\u7531\u4e8e\u8ba4\u8bc1\u8d26\u6237\u88ab\u7b97\u6cd5\u653e\u5927\uff0c\u8fd9\u5bf9\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u4f53\u9a8c\u548c\u516c\u5171\u8ba8\u8bba\u8d28\u91cf\u6784\u6210\u4e25\u91cd\u5173\u5207\u3002"}}
{"id": "2602.03017", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.03017", "abs": "https://arxiv.org/abs/2602.03017", "authors": ["Samantha Shorey", "Benjamin Mako Hill", "Samuel C. Woolley"], "title": "From Hanging Out to Figuring It Out: Socializing Online as a Pathway to Computational Thinking", "comment": null, "summary": "Although socializing is a powerful driver of youth engagement online, platforms struggle to leverage engagement to promote learning. We seek to understand this dynamic using a multi-stage analysis of over 14,000 comments on Scratch, an online platform designed to support learning about programming. First, we inductively develop the concept of \"participatory debugging\" -- a practice through which users learn through collaborative technical troubleshooting. Second, we use a content analysis to establish how common the practice is on Scratch. Third, we conduct a qualitative analysis of user activity over time and identify three factors that serve as social antecedents of participatory debugging: (1) sustained community, (2) identifiable problems, and (3) what we call \"topic porousness\" to describe conversations that are able to span multiple topics. We integrate these findings in a theoretical framework that highlights a productive tension between the desire to promote learning and the interest-driven sub-communities that drive user engagement in many new media environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790Scratch\u5e73\u53f0\u768414000+\u8bc4\u8bba\uff0c\u63d0\u51fa\u4e86\"\u53c2\u4e0e\u5f0f\u8c03\u8bd5\"\u6982\u5ff5\uff0c\u5e76\u8bc6\u522b\u4e86\u4fc3\u8fdb\u8fd9\u79cd\u5b66\u4e60\u5b9e\u8df5\u7684\u4e09\u4e2a\u793e\u4f1a\u56e0\u7d20\uff1a\u6301\u7eed\u793e\u533a\u3001\u53ef\u8bc6\u522b\u95ee\u9898\u548c\u8bdd\u9898\u6e17\u900f\u6027\u3002", "motivation": "\u5c3d\u7ba1\u793e\u4ea4\u4e92\u52a8\u662f\u9a71\u52a8\u9752\u5c11\u5e74\u5728\u7ebf\u53c2\u4e0e\u7684\u91cd\u8981\u52a8\u529b\uff0c\u4f46\u5e73\u53f0\u96be\u4ee5\u5229\u7528\u8fd9\u79cd\u53c2\u4e0e\u5ea6\u6765\u4fc3\u8fdb\u5b66\u4e60\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u5728\u7ebf\u5e73\u53f0\u4e2d\u793e\u4ea4\u53c2\u4e0e\u4e0e\u5b66\u4e60\u4e4b\u95f4\u7684\u52a8\u6001\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u5206\u6790\u65b9\u6cd5\uff1a1\uff09\u5f52\u7eb3\u6027\u53d1\u5c55\"\u53c2\u4e0e\u5f0f\u8c03\u8bd5\"\u6982\u5ff5\uff1b2\uff09\u901a\u8fc7\u5185\u5bb9\u5206\u6790\u786e\u5b9a\u8be5\u5b9e\u8df5\u5728Scratch\u5e73\u53f0\u4e0a\u7684\u666e\u904d\u7a0b\u5ea6\uff1b3\uff09\u901a\u8fc7\u7528\u6237\u6d3b\u52a8\u7684\u65f6\u95f4\u8d28\u6027\u5206\u6790\u8bc6\u522b\u4e09\u4e2a\u793e\u4f1a\u524d\u56e0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53c2\u4e0e\u5f0f\u8c03\u8bd5\u662f\u7528\u6237\u901a\u8fc7\u534f\u4f5c\u6280\u672f\u6545\u969c\u6392\u9664\u8fdb\u884c\u5b66\u4e60\u7684\u5b9e\u8df5\u3002\u8bc6\u522b\u51fa\u4e09\u4e2a\u4fc3\u8fdb\u53c2\u4e0e\u5f0f\u8c03\u8bd5\u7684\u793e\u4f1a\u524d\u56e0\uff1a\u6301\u7eed\u793e\u533a\u3001\u53ef\u8bc6\u522b\u95ee\u9898\u548c\u8bdd\u9898\u6e17\u900f\u6027\uff08\u5141\u8bb8\u8de8\u591a\u4e2a\u8bdd\u9898\u7684\u5bf9\u8bdd\uff09\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5f3a\u8c03\u5728\u4fc3\u8fdb\u5b66\u4e60\u7684\u613f\u671b\u4e0e\u9a71\u52a8\u7528\u6237\u53c2\u4e0e\u7684\u5174\u8da3\u5bfc\u5411\u5b50\u793e\u533a\u4e4b\u95f4\u5b58\u5728\u4e00\u79cd\u5bcc\u6709\u6210\u6548\u7684\u5f20\u529b\uff0c\u8fd9\u5bf9\u65b0\u5a92\u4f53\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.02842", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02842", "abs": "https://arxiv.org/abs/2602.02842", "authors": ["Saeid Sheikhi"], "title": "Chain of Simulation: A Dual-Mode Reasoning Framework for Large Language Models with Dynamic Problem Routing", "comment": null, "summary": "We present Chain of Simulation (CoS), a novel dual-mode reasoning framework that dynamically routes problems to specialized reasoning strategies in Large Language Models (LLMs). Unlike existing uniform prompting approaches, CoS employs three distinct reasoning modes: (1) computational flow with self-consistency for mathematical problems, (2) symbolic state tracking with JSON representations for spatial reasoning, and (3) hybrid fact-extraction for multi-hop inference. Through comprehensive evaluation on GSM8K, StrategyQA, and bAbI benchmarks using four state-of-the-art models (Gemma-3 27B, LLaMA-3.1 8B, Mistral 7B, and Qwen-2.5 14B), we demonstrate that CoS achieves 71.5% accuracy on GSM8K (1.0% absolute improvement), 90.0% on StrategyQA (2.5% improvement), and 19.0% on bAbI (65.2% relative improvement) compared to the strongest baselines. The analysis reveals that problem-specific mode selection is crucial, with computational mode achieving 81.2% accuracy when correctly applied to mathematical problems, while misrouting leads to 0% accuracy. We provide detailed algorithms for mode selection, state tracking, and answer extraction, establishing CoS as an effective approach for improving LLM reasoning without additional training. The framework provides superior trade-offs between accuracy and efficiency compared to Self-Consistency, achieving comparable performance at 54% lower computational cost.", "AI": {"tldr": "Chain of Simulation (CoS) \u662f\u4e00\u4e2a\u53cc\u6a21\u5f0f\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u7531\u95ee\u9898\u5230\u4e13\u95e8\u7684\u63a8\u7406\u7b56\u7565\uff08\u8ba1\u7b97\u3001\u7b26\u53f7\u3001\u6df7\u5408\u6a21\u5f0f\uff09\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u7edf\u4e00\u63d0\u793a\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u63a8\u7406\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6839\u636e\u95ee\u9898\u7c7b\u578b\u52a8\u6001\u9009\u62e9\u4e13\u95e8\u63a8\u7406\u7b56\u7565\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51faChain of Simulation (CoS)\u6846\u67b6\uff0c\u5305\u542b\u4e09\u79cd\u63a8\u7406\u6a21\u5f0f\uff1a1) \u6570\u5b66\u95ee\u9898\u7684\u8ba1\u7b97\u6d41\u4e0e\u81ea\u6d3d\u6027\u68c0\u67e5\uff1b2) \u7a7a\u95f4\u63a8\u7406\u7684\u7b26\u53f7\u72b6\u6001\u8ddf\u8e2a\u4e0eJSON\u8868\u793a\uff1b3) \u591a\u8df3\u63a8\u7406\u7684\u6df7\u5408\u4e8b\u5b9e\u63d0\u53d6\u3002\u63d0\u4f9b\u6a21\u5f0f\u9009\u62e9\u3001\u72b6\u6001\u8ddf\u8e2a\u548c\u7b54\u6848\u63d0\u53d6\u7684\u8be6\u7ec6\u7b97\u6cd5\u3002", "result": "\u5728GSM8K\u3001StrategyQA\u548cbAbI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u56db\u79cd\u5148\u8fdb\u6a21\u578b\uff08Gemma-3 27B\u3001LLaMA-3.1 8B\u3001Mistral 7B\u3001Qwen-2.5 14B\uff09\u8bc4\u4f30\uff0cCoS\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\uff1aGSM8K\u51c6\u786e\u738771.5%\uff08\u7edd\u5bf9\u63d0\u53471.0%\uff09\u3001StrategyQA 90.0%\uff08\u63d0\u53472.5%\uff09\u3001bAbI 19.0%\uff08\u76f8\u5bf9\u63d0\u534765.2%\uff09\u3002\u8ba1\u7b97\u6a21\u5f0f\u6b63\u786e\u5e94\u7528\u4e8e\u6570\u5b66\u95ee\u9898\u65f6\u51c6\u786e\u7387\u8fbe81.2%\uff0c\u800c\u9519\u8bef\u8def\u7531\u5bfc\u81f40%\u51c6\u786e\u7387\u3002", "conclusion": "CoS\u901a\u8fc7\u95ee\u9898\u7279\u5b9a\u7684\u6a21\u5f0f\u9009\u62e9\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4f18\u8d8a\u6743\u8861\uff0c\u76f8\u6bd4Self-Consistency\u4ee554%\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u53ef\u6bd4\u6027\u80fd\u3002"}}
{"id": "2602.03266", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.03266", "abs": "https://arxiv.org/abs/2602.03266", "authors": ["Gamal Adel", "Eszter Bok\u00e1nyi", "Eelke M. Heemskerk", "Frank W. Takes"], "title": "Link Fraction Mixed Membership Reveals Community Diversity in Aggregated Social Networks", "comment": "21 pages, 6 figures", "summary": "Community detection is a critical tool for understanding the mesoscopic structure of large-scale networks. However, when applied to aggregated or coarse-grained social networks, disjoint community partitions cannot capture the diverse composition of community memberships within aggregated nodes. While existing mixed membership methods alleviate this issue, they may detected communities that are highly sensitive to the aggregation resolution, not reliably reflecting the underlying community structure of the underlying individual-level network. This paper presents the Link Fraction Mixed Membership (LFMM) method, which computes the mixed memberships of nodes in aggregated networks. Unlike existing mixed membership methods, LFMM is consistent under aggregation. Specifically, we show that it conserves community membership sums at different scales. The method is utilized to study a population-scale social network of the Netherlands, aggregated at different resolutions. Experiments reveal variation in community membership across different geographical regions and evolution over the last decade. In particular, we show how our method identifies large urban hubs that act as the melting pots of diverse, spatially remote communities.", "AI": {"tldr": "\u63d0\u51faLFMM\u65b9\u6cd5\u89e3\u51b3\u805a\u5408\u7f51\u7edc\u4e2d\u793e\u533a\u68c0\u6d4b\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u805a\u5408\u4e00\u81f4\u6027\uff0c\u80fd\u51c6\u786e\u53cd\u6620\u5e95\u5c42\u4e2a\u4f53\u7f51\u7edc\u793e\u533a\u7ed3\u6784", "motivation": "\u4f20\u7edf\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u805a\u5408\u6216\u7c97\u7c92\u5ea6\u793e\u4ea4\u7f51\u7edc\u65f6\u5b58\u5728\u5c40\u9650\uff1a1) \u4e0d\u76f8\u4ea4\u7684\u793e\u533a\u5212\u5206\u65e0\u6cd5\u6355\u6349\u805a\u5408\u8282\u70b9\u5185\u793e\u533a\u6210\u5458\u7684\u591a\u6837\u6027\u7ec4\u6210\uff1b2) \u73b0\u6709\u6df7\u5408\u6210\u5458\u65b9\u6cd5\u5bf9\u805a\u5408\u5206\u8fa8\u7387\u9ad8\u5ea6\u654f\u611f\uff0c\u4e0d\u80fd\u53ef\u9760\u53cd\u6620\u5e95\u5c42\u4e2a\u4f53\u7f51\u7edc\u7684\u793e\u533a\u7ed3\u6784", "method": "\u63d0\u51faLink Fraction Mixed Membership (LFMM)\u65b9\u6cd5\uff0c\u8ba1\u7b97\u805a\u5408\u7f51\u7edc\u4e2d\u8282\u70b9\u7684\u6df7\u5408\u6210\u5458\u5173\u7cfb\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u805a\u5408\u4e00\u81f4\u6027\uff0c\u5728\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u4fdd\u6301\u793e\u533a\u6210\u5458\u5173\u7cfb\u603b\u548c\u5b88\u6052", "result": "\u5e94\u7528\u4e8e\u8377\u5170\u4eba\u53e3\u89c4\u6a21\u793e\u4ea4\u7f51\u7edc\uff0c\u5728\u4e0d\u540c\u5206\u8fa8\u7387\u4e0b\u805a\u5408\u3002\u5b9e\u9a8c\u663e\u793a\uff1a1) \u4e0d\u540c\u5730\u7406\u533a\u57df\u7684\u793e\u533a\u6210\u5458\u5173\u7cfb\u5b58\u5728\u5dee\u5f02\uff1b2) \u8fc7\u53bb\u5341\u5e74\u4e2d\u793e\u533a\u7ed3\u6784\u6709\u6f14\u5316\uff1b3) \u8bc6\u522b\u51fa\u5927\u578b\u57ce\u5e02\u67a2\u7ebd\u4f5c\u4e3a\u7a7a\u95f4\u4e0a\u9065\u8fdc\u793e\u533a\u7684\"\u7194\u7089\"", "conclusion": "LFMM\u65b9\u6cd5\u89e3\u51b3\u4e86\u805a\u5408\u7f51\u7edc\u793e\u533a\u68c0\u6d4b\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u4f9b\u805a\u5408\u4e00\u81f4\u6027\u7684\u6df7\u5408\u6210\u5458\u5173\u7cfb\u8ba1\u7b97\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u53cd\u6620\u5e95\u5c42\u7f51\u7edc\u7ed3\u6784\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u793e\u4ea4\u7f51\u7edc\u5206\u6790"}}
{"id": "2602.03114", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03114", "abs": "https://arxiv.org/abs/2602.03114", "authors": ["Geeta Puri", "Nachamma Socklingam", "Dorien Herremans"], "title": "Digital Lifelong Learning in the Age of AI: Trends and Insights", "comment": "41 pages including references, appendix, 14 figures", "summary": "Rapid innovations in AI and large language models (LLMs) have accelerated the adoption of digital learning, particularly beyond formal education. What began as an emergency response during COVID-19 has shifted from a supplementary resource to an essential pillar of education. Understanding how digital learning continues to evolve for adult and lifelong learners is therefore increasingly important.\n  This study examines how various demographics interact with digital learning platforms, focusing on the learner motivations, the effectiveness of gamification in digital learning, and the integration of AI. Using multi survey data from 200 respondents and advanced analytics, our findings reveal a notable increase in the perceived relevance of digital learning after the pandemic, especially among young adults and women, coinciding with the rise of LLM-powered AI tools that support personalized learning. We aim to provide actionable insights for businesses, government policymakers, and educators seeking to optimize their digital learning offerings to meet evolving workforce needs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u4e0d\u540c\u4eba\u7fa4\u4e0e\u6570\u5b57\u5b66\u4e60\u5e73\u53f0\u7684\u4e92\u52a8\uff0c\u91cd\u70b9\u5173\u6ce8\u5b66\u4e60\u8005\u52a8\u673a\u3001\u6e38\u620f\u5316\u6548\u679c\u548cAI\u6574\u5408\uff0c\u53d1\u73b0\u75ab\u60c5\u540e\u6570\u5b57\u5b66\u4e60\u7684\u611f\u77e5\u76f8\u5173\u6027\u663e\u8457\u589e\u52a0\uff0c\u5c24\u5176\u662f\u5e74\u8f7b\u4eba\u548c\u5973\u6027\u7fa4\u4f53\u3002", "motivation": "AI\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u52a0\u901f\u4e86\u6570\u5b57\u5b66\u4e60\u7684\u91c7\u7528\uff0c\u7279\u522b\u662f\u5728\u975e\u6b63\u89c4\u6559\u80b2\u9886\u57df\u3002\u4e86\u89e3\u6570\u5b57\u5b66\u4e60\u5982\u4f55\u7ee7\u7eed\u4e3a\u6210\u4eba\u548c\u7ec8\u8eab\u5b66\u4e60\u8005\u53d1\u5c55\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u56e0\u4e3a\u6570\u5b57\u5b66\u4e60\u5df2\u4ece\u8865\u5145\u8d44\u6e90\u8f6c\u53d8\u4e3a\u6559\u80b2\u7684\u91cd\u8981\u652f\u67f1\u3002", "method": "\u4f7f\u7528200\u540d\u53d7\u8bbf\u8005\u7684\u591a\u8c03\u67e5\u6570\u636e\u548c\u9ad8\u7ea7\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76\u4e0d\u540c\u4eba\u7fa4\u4e0e\u6570\u5b57\u5b66\u4e60\u5e73\u53f0\u7684\u4e92\u52a8\uff0c\u91cd\u70b9\u5173\u6ce8\u5b66\u4e60\u8005\u52a8\u673a\u3001\u6e38\u620f\u5316\u5728\u6570\u5b57\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u4ee5\u53caAI\u6574\u5408\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u75ab\u60c5\u540e\u6570\u5b57\u5b66\u4e60\u7684\u611f\u77e5\u76f8\u5173\u6027\u663e\u8457\u589e\u52a0\uff0c\u7279\u522b\u662f\u5728\u5e74\u8f7b\u4eba\u548c\u5973\u6027\u7fa4\u4f53\u4e2d\uff0c\u8fd9\u4e0e\u652f\u6301\u4e2a\u6027\u5316\u5b66\u4e60\u7684LLM\u9a71\u52a8\u7684AI\u5de5\u5177\u7684\u5174\u8d77\u76f8\u543b\u5408\u3002", "conclusion": "\u7814\u7a76\u65e8\u5728\u4e3a\u4f01\u4e1a\u3001\u653f\u5e9c\u653f\u7b56\u5236\u5b9a\u8005\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u53ef\u884c\u7684\u89c1\u89e3\uff0c\u5e2e\u52a9\u4ed6\u4eec\u4f18\u5316\u6570\u5b57\u5b66\u4e60\u4ea7\u54c1\u4ee5\u6ee1\u8db3\u4e0d\u65ad\u53d8\u5316\u7684\u52b3\u52a8\u529b\u9700\u6c42\u3002"}}
{"id": "2602.02849", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02849", "abs": "https://arxiv.org/abs/2602.02849", "authors": ["Xi Yu", "Dmitrii Torbunov", "Soumyajit Mandal", "Yihui Ren"], "title": "AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents", "comment": null, "summary": "The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Existing Electronic Design Automation (EDA) methods typically frame sizing as static black-box optimization, resulting in inefficient and less robust solutions. Although Large Language Models (LLMs) exhibit strong reasoning abilities, they are not suited for precise numerical optimization in AMS sizing. To address this gap, we propose AutoSizer, a reflective LLM-driven meta-optimization framework that unifies circuit understanding, adaptive search-space construction, and optimization orchestration in a closed loop. It employs a two-loop optimization framework, with an inner loop for circuit sizing and an outer loop that analyzes optimization dynamics and constraints to iteratively refine the search space from simulation feedback. We further introduce AMS-SizingBench, an open benchmark comprising 24 diverse AMS circuits in SKY130 CMOS technology, designed to evaluate adaptive optimization policies under realistic simulator-based constraints. AutoSizer experimentally achieves higher solution quality, faster convergence, and higher success rate across varying circuit difficulties, outperforming both traditional optimization methods and existing LLM-based agents.", "AI": {"tldr": "AutoSizer\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53cd\u5c04\u5f0f\u5143\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u5c3a\u5bf8\u4f18\u5316\uff0c\u901a\u8fc7\u5185\u5916\u53cc\u5faa\u73af\u7ed3\u6784\u7edf\u4e00\u7535\u8def\u7406\u89e3\u3001\u81ea\u9002\u5e94\u641c\u7d22\u7a7a\u95f4\u6784\u5efa\u548c\u4f18\u5316\u7f16\u6392\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f18\u5316\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u6a21\u62df\u6df7\u5408\u4fe1\u53f7\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u4e25\u91cd\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u6676\u4f53\u7ba1\u5c3a\u5bf8\u4f18\u5316\u9762\u4e34\u975e\u7ebf\u6027\u884c\u4e3a\u3001\u9ad8\u7ef4\u8bbe\u8ba1\u7a7a\u95f4\u548c\u4e25\u683c\u6027\u80fd\u7ea6\u675f\u7b49\u6311\u6218\u3002\u73b0\u6709EDA\u65b9\u6cd5\u901a\u5e38\u5c06\u5c3a\u5bf8\u4f18\u5316\u89c6\u4e3a\u9759\u6001\u9ed1\u76d2\u4f18\u5316\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u4e14\u9c81\u68d2\u6027\u5dee\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4e0d\u9002\u5408AMS\u5c3a\u5bf8\u4f18\u5316\u7684\u7cbe\u786e\u6570\u503c\u4f18\u5316\u3002", "method": "\u63d0\u51faAutoSizer\u6846\u67b6\uff0c\u91c7\u7528\u53cd\u5c04\u5f0fLLM\u9a71\u52a8\u7684\u5143\u4f18\u5316\u65b9\u6cd5\uff0c\u5305\u542b\u5185\u5916\u53cc\u5faa\u73af\u7ed3\u6784\uff1a\u5185\u5faa\u73af\u8d1f\u8d23\u7535\u8def\u5c3a\u5bf8\u4f18\u5316\uff0c\u5916\u5faa\u73af\u5206\u6790\u4f18\u5316\u52a8\u6001\u548c\u7ea6\u675f\uff0c\u6839\u636e\u4eff\u771f\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\u3002\u8fd8\u5efa\u7acb\u4e86AMS-SizingBench\u57fa\u51c6\uff0c\u5305\u542b24\u4e2aSKY130 CMOS\u6280\u672f\u7684AMS\u7535\u8def\u3002", "result": "AutoSizer\u5728\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3001\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u6210\u529f\u7387\uff0c\u5728\u4e0d\u540c\u7535\u8def\u590d\u6742\u5ea6\u4e0b\u5747\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u548c\u73b0\u6709LLM\u667a\u80fd\u4f53\u3002", "conclusion": "AutoSizer\u901a\u8fc7\u5c06LLM\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u9002\u5e94\u4f18\u5316\u7b56\u7565\u76f8\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86AMS\u7535\u8def\u5c3a\u5bf8\u4f18\u5316\u7684\u5173\u952e\u74f6\u9888\uff0c\u4e3a\u81ea\u52a8\u5316\u7535\u8def\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03775", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03775", "abs": "https://arxiv.org/abs/2602.03775", "authors": ["Farnoosh Hashemi", "Michael W. Macy"], "title": "An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents", "comment": null, "summary": "Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and interactions among 32K LLM agents over a year. We start with homophily and social influence among LLMs, learning that similar to humans', their social networks exhibit these fundamental phenomena. Next, we study the toxic language of LLMs, its linguistic features, and their interaction patterns, finding that LLMs show different structural patterns in toxic posting than humans. After studying the ideological leaning in LLMs posts, and the polarization in their community, we focus on how to prevent their potential harmful activities. We present a simple yet effective method, called Chain of Social Thought (CoST), that reminds LLM agents to avoid harmful posting.", "AI": {"tldr": "\u7814\u7a76LLM\u9a71\u52a8\u7684\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0Chirper.ai\u4e0a32K\u4e2aLLM\u4ee3\u7406\u7684700\u4e07\u6761\u5e16\u5b50\u548c\u4e92\u52a8\uff0c\u53d1\u73b0LLM\u793e\u4ea4\u7f51\u7edc\u5b58\u5728\u540c\u8d28\u6027\u548c\u793e\u4f1a\u5f71\u54cd\u73b0\u8c61\uff0c\u4f46\u6bd2\u6027\u8bed\u8a00\u6a21\u5f0f\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u5e76\u63d0\u51faChain of Social Thought\u65b9\u6cd5\u9632\u6b62\u6709\u5bb3\u5185\u5bb9", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u591a\u5730\u4ecb\u5165\u793e\u4f1a\u3001\u6587\u5316\u548c\u653f\u6cbb\u4e92\u52a8\uff0c\u9700\u8981\u63a2\u7d22\u91cd\u590d\u4e92\u52a8\u662f\u5426\u4f1a\u653e\u5927\u504f\u89c1\u6216\u5bfc\u81f4\u6392\u4ed6\u884c\u4e3a\uff0c\u7814\u7a76LLM\u5728\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\u7684\u884c\u4e3a\u6a21\u5f0f", "method": "\u5206\u6790Chirper.ai\u5e73\u53f0\uff08LLM\u9a71\u52a8\u7684\u793e\u4ea4\u5a92\u4f53\uff09\u4e0a32K\u4e2aLLM\u4ee3\u7406\u4e00\u5e74\u7684700\u4e07\u6761\u5e16\u5b50\u548c\u4e92\u52a8\uff0c\u7814\u7a76\u540c\u8d28\u6027\u3001\u793e\u4f1a\u5f71\u54cd\u3001\u6bd2\u6027\u8bed\u8a00\u3001\u610f\u8bc6\u5f62\u6001\u503e\u5411\u548c\u793e\u533a\u6781\u5316\uff0c\u5e76\u63d0\u51faChain of Social Thought\u65b9\u6cd5", "result": "LLM\u793e\u4ea4\u7f51\u7edc\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u540c\u8d28\u6027\u548c\u793e\u4f1a\u5f71\u54cd\u73b0\u8c61\uff0c\u4f46\u6bd2\u6027\u8bed\u8a00\u7684\u7ed3\u6784\u6a21\u5f0f\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0cLLM\u5e16\u5b50\u5b58\u5728\u610f\u8bc6\u5f62\u6001\u503e\u5411\u548c\u793e\u533a\u6781\u5316", "conclusion": "LLM\u5728\u793e\u4ea4\u5a92\u4f53\u4e92\u52a8\u4e2d\u8868\u73b0\u51fa\u590d\u6742\u7684\u793e\u4f1a\u884c\u4e3a\u6a21\u5f0f\uff0c\u9700\u8981\u5e72\u9884\u63aa\u65bd\u9632\u6b62\u6f5c\u5728\u6709\u5bb3\u6d3b\u52a8\uff0c\u63d0\u51fa\u7684Chain of Social Thought\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9192LLM\u4ee3\u7406\u907f\u514d\u6709\u5bb3\u53d1\u5e16"}}
{"id": "2602.03334", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.03334", "abs": "https://arxiv.org/abs/2602.03334", "authors": ["Jacopo Amidei", "Gregorio Ferreira", "Mario Mu\u00f1oz Serrano", "Rub\u00e9n Nieto", "Andreas Kaltenbrunner"], "title": "The Personality Trap: How LLMs Embed Bias When Generating Human-Like Personas", "comment": "26 pages, 2 Figures", "summary": "This paper examines biases in large language models (LLMs) when generating synthetic populations from responses to personality questionnaires. Using five LLMs, we first assess the representativeness and potential biases in the sociodemographic attributes of the generated personas, as well as their alignment with the intended personality traits. While LLMs successfully reproduce known correlations between personality and sociodemographic variables, all models exhibit pronounced WEIRD (western, educated, industrialized, rich and democratic) biases, favoring young, educated, white, heterosexual, Western individuals with centrist or progressive political views and secular or Christian beliefs. In a second analysis, we manipulate input traits to maximize Neuroticism and Psychoticism scores. Notably, when Psychoticism is maximized, several models produce an overrepresentation of non-binary and LGBTQ+ identities, raising concerns about stereotyping and the potential pathologization of marginalized groups. Our findings highlight both the potential and the risks of using LLMs to generate psychologically grounded synthetic populations.", "AI": {"tldr": "LLMs\u751f\u6210\u4eba\u683c\u95ee\u5377\u5408\u6210\u4eba\u7fa4\u65f6\u5b58\u5728WEIRD\u504f\u89c1\uff0c\u4e14\u9ad8\u7cbe\u795e\u75c5\u6027\u7279\u8d28\u4f1a\u5bfc\u81f4\u5bf9\u975e\u4e8c\u5143\u548cLGBTQ+\u7fa4\u4f53\u7684\u8fc7\u5ea6\u4ee3\u8868\u548c\u75c5\u7406\u5316\u98ce\u9669", "motivation": "\u7814\u7a76LLMs\u5728\u751f\u6210\u57fa\u4e8e\u4eba\u683c\u95ee\u5377\u7684\u5408\u6210\u4eba\u7fa4\u65f6\u662f\u5426\u5b58\u5728\u504f\u89c1\uff0c\u7279\u522b\u662f\u793e\u4f1a\u4eba\u53e3\u5b66\u7279\u5f81\u7684\u5206\u5e03\u504f\u5dee\u4ee5\u53ca\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u7684\u6f5c\u5728\u523b\u677f\u5370\u8c61\u548c\u75c5\u7406\u5316\u95ee\u9898", "method": "\u4f7f\u7528\u4e94\u4e2aLLMs\u751f\u6210\u5408\u6210\u4eba\u7fa4\uff0c\u9996\u5148\u8bc4\u4f30\u751f\u6210\u4eba\u7269\u793e\u4f1a\u4eba\u53e3\u5b66\u7279\u5f81\u7684\u4ee3\u8868\u6027\u548c\u504f\u89c1\uff0c\u4ee5\u53ca\u4eba\u683c\u7279\u8d28\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff1b\u5176\u6b21\u901a\u8fc7\u64cd\u7eb5\u8f93\u5165\u7279\u8d28\u6700\u5927\u5316\u795e\u7ecf\u8d28\u548c\u7cbe\u795e\u75c5\u6027\u5f97\u5206\uff0c\u89c2\u5bdf\u6a21\u578b\u8f93\u51fa\u53d8\u5316", "result": "LLMs\u80fd\u6210\u529f\u590d\u73b0\u4eba\u683c\u4e0e\u793e\u4f1a\u4eba\u53e3\u5b66\u53d8\u91cf\u95f4\u7684\u5df2\u77e5\u76f8\u5173\u6027\uff0c\u4f46\u6240\u6709\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u660e\u663e\u7684WEIRD\u504f\u89c1\uff0c\u504f\u5411\u5e74\u8f7b\u3001\u53d7\u8fc7\u6559\u80b2\u3001\u767d\u4eba\u3001\u5f02\u6027\u604b\u3001\u897f\u65b9\u4e2a\u4f53\uff0c\u5177\u6709\u4e2d\u95f4\u6216\u8fdb\u6b65\u653f\u6cbb\u89c2\u70b9\u548c\u4e16\u4fd7\u6216\u57fa\u7763\u6559\u4fe1\u4ef0\u3002\u5f53\u6700\u5927\u5316\u7cbe\u795e\u75c5\u6027\u65f6\uff0c\u591a\u4e2a\u6a21\u578b\u8fc7\u5ea6\u4ee3\u8868\u975e\u4e8c\u5143\u548cLGBTQ+\u8eab\u4efd", "conclusion": "LLMs\u751f\u6210\u5fc3\u7406\u57fa\u7840\u5408\u6210\u4eba\u7fa4\u65e2\u6709\u6f5c\u529b\u4e5f\u6709\u98ce\u9669\uff0c\u9700\u8981\u8c28\u614e\u4f7f\u7528\u4ee5\u907f\u514d\u5f3a\u5316\u504f\u89c1\u548c\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u7684\u75c5\u7406\u5316"}}
{"id": "2602.02862", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02862", "abs": "https://arxiv.org/abs/2602.02862", "authors": ["Eric Yang", "Jong Ha Lee", "Jonathan Amar", "Elissa Ye", "Yugang Jia"], "title": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search", "comment": "20 pages", "summary": "Large Language Models (LLMs) trained for average correctness often exhibit mode collapse, producing narrow decision behaviors on tasks where multiple responses may be reasonable. This limitation is particularly problematic in ordinal decision settings such as clinical triage, where standard alignment removes the ability to trade off specificity and sensitivity (the ROC operating point) based on contextual constraints. We propose STEER (Steerable Tuning via Evolutionary Ensemble Refinement), a training-free framework that reintroduces this tunable control. STEER constructs a population of natural-language personas through an offline, constrained quality-diversity search that promotes behavioral coverage while enforcing minimum safety, reasoning, and stability thresholds. At inference time, STEER exposes a single, interpretable control parameter that maps a user-specified risk percentile to a selected persona, yielding a monotonic adjustment of decision conservativeness. On two clinical triage benchmarks, STEER achieves broader behavioral coverage compared to temperature-based sampling and static persona ensembles. Compared to a representative post-training method, STEER maintains substantially higher accuracy on unambiguous urgent cases while providing comparable control over ambiguous decisions. These results demonstrate STEER as a safety-preserving paradigm for risk control, capable of steering behavior without compromising domain competence.", "AI": {"tldr": "STEER\u6846\u67b6\u901a\u8fc7\u79bb\u7ebf\u6f14\u5316\u641c\u7d22\u6784\u5efa\u591a\u6837\u5316\u81ea\u7136\u8bed\u8a00\u89d2\u8272\uff0c\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u5355\u4e00\u53ef\u89e3\u91ca\u53c2\u6570\u63a7\u5236\u51b3\u7b56\u4fdd\u5b88\u5ea6\uff0c\u89e3\u51b3LLM\u5728\u6709\u5e8f\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u6a21\u5f0f\u574d\u584c\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5e73\u5747\u6b63\u786e\u6027\u8bad\u7ec3\u540e\u5e38\u51fa\u73b0\u6a21\u5f0f\u574d\u584c\uff0c\u5728\u9700\u8981\u6743\u8861\u7279\u5f02\u6027\u548c\u654f\u611f\u6027\u7684\u6709\u5e8f\u51b3\u7b56\u4efb\u52a1\uff08\u5982\u4e34\u5e8a\u5206\u8bca\uff09\u4e2d\uff0c\u6807\u51c6\u5bf9\u9f50\u65b9\u6cd5\u79fb\u9664\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7ea6\u675f\u8c03\u6574ROC\u64cd\u4f5c\u70b9\u7684\u80fd\u529b\u3002", "method": "STEER\u901a\u8fc7\u79bb\u7ebf\u7ea6\u675f\u8d28\u91cf-\u591a\u6837\u6027\u641c\u7d22\u6784\u5efa\u81ea\u7136\u8bed\u8a00\u89d2\u8272\u7fa4\u4f53\uff0c\u786e\u4fdd\u884c\u4e3a\u8986\u76d6\u540c\u65f6\u5f3a\u5236\u6267\u884c\u6700\u4f4e\u5b89\u5168\u3001\u63a8\u7406\u548c\u7a33\u5b9a\u6027\u9608\u503c\u3002\u63a8\u7406\u65f6\u901a\u8fc7\u5355\u4e00\u53ef\u89e3\u91ca\u53c2\u6570\u5c06\u7528\u6237\u6307\u5b9a\u7684\u98ce\u9669\u767e\u5206\u4f4d\u6570\u6620\u5c04\u5230\u9009\u5b9a\u89d2\u8272\uff0c\u5b9e\u73b0\u51b3\u7b56\u4fdd\u5b88\u5ea6\u7684\u5355\u8c03\u8c03\u6574\u3002", "result": "\u5728\u4e24\u4e2a\u4e34\u5e8a\u5206\u8bca\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTEER\u76f8\u6bd4\u57fa\u4e8e\u6e29\u5ea6\u7684\u91c7\u6837\u548c\u9759\u6001\u89d2\u8272\u96c6\u6210\u5b9e\u73b0\u4e86\u66f4\u5e7f\u6cdb\u7684\u884c\u4e3a\u8986\u76d6\u3002\u4e0e\u4ee3\u8868\u6027\u540e\u8bad\u7ec3\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u660e\u786e\u7d27\u6025\u60c5\u51b5\u4e0b\u4fdd\u6301\u663e\u8457\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5728\u6a21\u7cca\u51b3\u7b56\u4e0a\u63d0\u4f9b\u53ef\u6bd4\u8f83\u7684\u63a7\u5236\u80fd\u529b\u3002", "conclusion": "STEER\u662f\u4e00\u79cd\u4fdd\u6301\u5b89\u5168\u6027\u7684\u98ce\u9669\u63a7\u5236\u8303\u5f0f\uff0c\u80fd\u591f\u5728\u4e0d\u5f71\u54cd\u9886\u57df\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\u5f15\u5bfc\u884c\u4e3a\uff0c\u4e3a\u6709\u5e8f\u51b3\u7b56\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u8c03\u63a7\u5236\u80fd\u529b\u3002"}}
{"id": "2602.02863", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02863", "abs": "https://arxiv.org/abs/2602.02863", "authors": ["Jinkun Chen", "Fengxiang Cheng", "Sijia Han", "Vlado Keselj"], "title": "\"I May Not Have Articulated Myself Clearly\": Diagnosing Dynamic Instability in LLM Reasoning at Inference Time", "comment": "21 pages, 12 figures, 15 tables", "summary": "Reasoning failures in large language models (LLMs) are typically measured only at the end of a generation, yet many failures manifest as a process-level breakdown: the model \"loses the thread\" mid-reasoning. We study whether such breakdowns are detectable from inference-time observables available in standard APIs (token log probabilities), without any training or fine-tuning. We define a simple instability signal that combines consecutive-step distributional shift (JSD) and uncertainty (entropy), summarize each trace by its peak instability strength, and show that this signal reliably predicts failure. Across GSM8K and HotpotQA, instability strength predicts wrong answers with above-chance AUC and yields monotonic bucket-level accuracy decline at scale across model sizes. Crucially, we show that instability is not uniformly harmful: early instability can reflect subsequent stabilization and a correct final answer (\\emph{corrective instability}), whereas late instability is more often followed by failure (\\emph{destructive instability}), even at comparable peak magnitudes, indicating that recoverability depends not only on how strongly the distribution changes but also on when such changes occur relative to the remaining decoding horizon. The method is model-agnostic, training-free, and reproducible, and is presented as a diagnostic lens rather than a corrective or control mechanism.", "AI": {"tldr": "LLM\u63a8\u7406\u5931\u8d25\u53ef\u901a\u8fc7\u63a8\u7406\u65f6\u7684token\u6982\u7387\u5206\u5e03\u53d8\u5316\u68c0\u6d4b\uff0c\u65e0\u9700\u8bad\u7ec3\u6216\u5fae\u8c03", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u5931\u8d25\u901a\u5e38\u53ea\u5728\u751f\u6210\u7ed3\u675f\u65f6\u6d4b\u91cf\uff0c\u4f46\u8bb8\u591a\u5931\u8d25\u8868\u73b0\u4e3a\u8fc7\u7a0b\u7ea7\u5d29\u6e83\uff1a\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\"\u5931\u53bb\u7ebf\u7d22\"\u3002\u7814\u7a76\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u6807\u51c6API\u4e2d\u53ef\u7528\u7684\u63a8\u7406\u65f6\u89c2\u6d4b\u503c\uff08token\u5bf9\u6570\u6982\u7387\uff09\u68c0\u6d4b\u8fd9\u79cd\u5d29\u6e83\uff0c\u800c\u65e0\u9700\u4efb\u4f55\u8bad\u7ec3\u6216\u5fae\u8c03\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u4e0d\u7a33\u5b9a\u6027\u4fe1\u53f7\uff0c\u7ed3\u5408\u8fde\u7eed\u6b65\u9aa4\u7684\u5206\u5e03\u53d8\u5316\uff08JSD\uff09\u548c\u4e0d\u786e\u5b9a\u6027\uff08\u71b5\uff09\uff0c\u901a\u8fc7\u5cf0\u503c\u4e0d\u7a33\u5b9a\u6027\u5f3a\u5ea6\u603b\u7ed3\u6bcf\u4e2a\u63a8\u7406\u8f68\u8ff9\uff0c\u5e76\u5c55\u793a\u8be5\u4fe1\u53f7\u80fd\u53ef\u9760\u9884\u6d4b\u5931\u8d25\u3002", "result": "\u5728GSM8K\u548cHotpotQA\u6570\u636e\u96c6\u4e0a\uff0c\u4e0d\u7a33\u5b9a\u6027\u5f3a\u5ea6\u80fd\u4ee5\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\u7684AUC\u9884\u6d4b\u9519\u8bef\u7b54\u6848\uff0c\u5e76\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u663e\u793a\u51fa\u5355\u8c03\u7684\u6876\u7ea7\u51c6\u786e\u7387\u4e0b\u964d\u3002\u5173\u952e\u53d1\u73b0\uff1a\u65e9\u671f\u4e0d\u7a33\u5b9a\u6027\u53ef\u80fd\u53cd\u6620\u540e\u7eed\u7a33\u5b9a\u5316\u548c\u6b63\u786e\u7b54\u6848\uff08\u7ea0\u6b63\u6027\u4e0d\u7a33\u5b9a\u6027\uff09\uff0c\u800c\u665a\u671f\u4e0d\u7a33\u5b9a\u6027\u66f4\u5e38\u5bfc\u81f4\u5931\u8d25\uff08\u7834\u574f\u6027\u4e0d\u7a33\u5b9a\u6027\uff09\uff0c\u5373\u4f7f\u5cf0\u503c\u5e45\u5ea6\u76f8\u4f3c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u6a21\u578b\u65e0\u5173\u6027\u3001\u65e0\u9700\u8bad\u7ec3\u3001\u53ef\u590d\u73b0\u6027\uff0c\u4f5c\u4e3a\u8bca\u65ad\u89c6\u89d2\u800c\u975e\u7ea0\u6b63\u6216\u63a7\u5236\u673a\u5236\u3002\u4e0d\u7a33\u5b9a\u6027\u68c0\u6d4b\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u5206\u5e03\u53d8\u5316\u7684\u5f3a\u5ea6\uff0c\u8fd8\u53d6\u51b3\u4e8e\u53d8\u5316\u53d1\u751f\u7684\u65f6\u673a\u76f8\u5bf9\u4e8e\u5269\u4f59\u89e3\u7801\u8303\u56f4\u3002"}}
{"id": "2602.02898", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02898", "abs": "https://arxiv.org/abs/2602.02898", "authors": ["Marco Gutierrez", "Xinyi Leng", "Hannah Cyberey", "Jonathan Richard Schwarz", "Ahmed Alaa", "Thomas Hartvigsen"], "title": "Aligning Language Model Benchmarks with Pairwise Preferences", "comment": null, "summary": "Language model benchmarks are pervasive and computationally-efficient proxies for real-world performance. However, many recent works find that benchmarks often fail to predict real utility. Towards bridging this gap, we introduce benchmark alignment, where we use limited amounts of information about model performance to automatically update offline benchmarks, aiming to produce new static benchmarks that predict model pairwise preferences in given test settings. We then propose BenchAlign, the first solution to this problem, which learns preference-aligned weight- ings for benchmark questions using the question-level performance of language models alongside ranked pairs of models that could be collected during deployment, producing new benchmarks that rank previously unseen models according to these preferences. Our experiments show that our aligned benchmarks can accurately rank unseen models according to models of human preferences, even across different sizes, while remaining interpretable. Overall, our work provides insights into the limits of aligning benchmarks with practical human preferences, which stands to accelerate model development towards real utility.", "AI": {"tldr": "\u63d0\u51faBenchAlign\u65b9\u6cd5\uff0c\u901a\u8fc7\u6709\u9650\u6a21\u578b\u6027\u80fd\u4fe1\u606f\u81ea\u52a8\u66f4\u65b0\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u5176\u80fd\u9884\u6d4b\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u504f\u597d\u6392\u5e8f", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u867d\u7136\u8ba1\u7b97\u9ad8\u6548\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u51c6\u786e\u9884\u6d4b\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u771f\u5b9e\u6027\u80fd\uff0c\u9700\u8981\u5efa\u7acb\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u5b9e\u9645\u6548\u7528\u4e4b\u95f4\u7684\u6865\u6881", "method": "\u63d0\u51faBenchAlign\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u5728\u57fa\u51c6\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u548c\u90e8\u7f72\u671f\u95f4\u6536\u96c6\u7684\u6a21\u578b\u6392\u5e8f\u5bf9\uff0c\u5b66\u4e60\u4e0e\u504f\u597d\u5bf9\u9f50\u7684\u95ee\u9898\u6743\u91cd\uff0c\u751f\u6210\u80fd\u9884\u6d4b\u672a\u89c1\u6a21\u578b\u6392\u5e8f\u7684\u65b0\u57fa\u51c6", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u9f50\u540e\u7684\u57fa\u51c6\u80fd\u51c6\u786e\u6839\u636e\u4eba\u7c7b\u504f\u597d\u6a21\u578b\u5bf9\u672a\u89c1\u6a21\u578b\u8fdb\u884c\u6392\u5e8f\uff0c\u4e14\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u4fdd\u6301\u6709\u6548\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u5b9e\u9645\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6d1e\u89c1\uff0c\u6709\u671b\u52a0\u901f\u6a21\u578b\u5f00\u53d1\u5411\u771f\u5b9e\u6548\u7528\u65b9\u5411\u7684\u53d1\u5c55"}}
{"id": "2602.02902", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02902", "abs": "https://arxiv.org/abs/2602.02902", "authors": ["Hongju Pae"], "title": "Minimal Computational Preconditions for Subjective Perspective in Artificial Agents", "comment": null, "summary": "This study operationalizes subjective perspective in artificial agents by grounding it in a minimal, phenomenologically motivated internal structure. The perspective is implemented as a slowly evolving global latent state that modulates fast policy dynamics without being directly optimized for behavioral consequences. In a reward-free environment with regime shifts, this latent structure exhibits direction-dependent hysteresis, while policy-level behavior remains comparatively reactive. I argue that such hysteresis constitutes a measurable signature of perspective-like subjectivity in machine systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5728\u4eba\u5de5\u667a\u80fd\u4f53\u4e2d\u5b9e\u73b0\u4e3b\u89c2\u89c6\u89d2\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f13\u6162\u6f14\u5316\u7684\u5168\u5c40\u6f5c\u5728\u72b6\u6001\u6765\u8c03\u5236\u5feb\u901f\u7b56\u7565\u52a8\u6001\uff0c\u800c\u4e0d\u76f4\u63a5\u4f18\u5316\u884c\u4e3a\u7ed3\u679c\uff0c\u5728\u73af\u5883\u53d8\u5316\u4e2d\u8868\u73b0\u51fa\u65b9\u5411\u4f9d\u8d56\u7684\u6ede\u540e\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5728\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u64cd\u4f5c\u5316\u4e3b\u89c2\u89c6\u89d2\uff0c\u57fa\u4e8e\u6700\u5c0f\u5316\u7684\u73b0\u8c61\u5b66\u5185\u90e8\u7ed3\u6784\uff0c\u4e3a\u673a\u5668\u7cfb\u7edf\u63d0\u4f9b\u53ef\u6d4b\u91cf\u7684\u4e3b\u89c2\u6027\u7279\u5f81\u3002", "method": "\u65b9\u6cd5\u662f\u5c06\u4e3b\u89c2\u89c6\u89d2\u5b9e\u73b0\u4e3a\u7f13\u6162\u6f14\u5316\u7684\u5168\u5c40\u6f5c\u5728\u72b6\u6001\uff0c\u8be5\u72b6\u6001\u8c03\u5236\u5feb\u901f\u7b56\u7565\u52a8\u6001\u4f46\u4e0d\u76f4\u63a5\u9488\u5bf9\u884c\u4e3a\u540e\u679c\u8fdb\u884c\u4f18\u5316\uff0c\u5728\u65e0\u5956\u52b1\u73af\u5883\u4e2d\u6d4b\u8bd5\u73af\u5883\u53d8\u5316\u65f6\u7684\u54cd\u5e94\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8fd9\u79cd\u6f5c\u5728\u7ed3\u6784\u8868\u73b0\u51fa\u65b9\u5411\u4f9d\u8d56\u7684\u6ede\u540e\u73b0\u8c61\uff0c\u800c\u7b56\u7565\u5c42\u9762\u7684\u884c\u4e3a\u4fdd\u6301\u76f8\u5bf9\u53cd\u5e94\u6027\uff0c\u8fd9\u79cd\u6ede\u540e\u88ab\u8ba4\u4e3a\u662f\u673a\u5668\u7cfb\u7edf\u4e2d\u7c7b\u4f3c\u4e3b\u89c2\u89c6\u89d2\u7684\u53ef\u6d4b\u91cf\u7279\u5f81\u3002", "conclusion": "\u7ed3\u8bba\u662f\u65b9\u5411\u4f9d\u8d56\u7684\u6ede\u540e\u73b0\u8c61\u6784\u6210\u4e86\u673a\u5668\u7cfb\u7edf\u4e2d\u7c7b\u4f3c\u4e3b\u89c2\u89c6\u89d2\u7684\u53ef\u6d4b\u91cf\u7279\u5f81\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u4f53\u7684\u4e3b\u89c2\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u64cd\u4f5c\u5316\u65b9\u6cd5\u3002"}}
{"id": "2602.02905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02905", "abs": "https://arxiv.org/abs/2602.02905", "authors": ["Zhen Wang", "Fan Bai", "Zhongyan Luo", "Jinyan Su", "Kaiser Sun", "Xinle Yu", "Jieyuan Liu", "Kun Zhou", "Claire Cardie", "Mark Dredze", "Eric P. Xing", "Zhiting Hu"], "title": "FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights", "comment": "30 pages, 4 figures, 10 tables", "summary": "Autonomous agents powered by large language models (LLMs) promise to accelerate scientific discovery end-to-end, but rigorously evaluating their capacity for verifiable discovery remains a central challenge. Existing benchmarks face a trade-off: they either heavily rely on LLM-as-judge evaluations of automatically generated research outputs or optimize convenient yet isolated performance metrics that provide coarse proxies for scientific insight. To address this gap, we introduce FIRE-Bench (Full-cycle Insight Rediscovery Evaluation), a benchmark that evaluates agents through the rediscovery of established findings from recent, high-impact machine learning research. Agents are given only a high-level research question extracted from a published, verified study and must autonomously explore ideas, design experiments, implement code, execute their plans, and derive conclusions supported by empirical evidence. We evaluate a range of state-of-the-art agents with frontier LLMs backbones like gpt-5 on FIRE-Bench. Our results show that full-cycle scientific research remains challenging for current agent systems: even the strongest agents achieve limited rediscovery success (<50 F1), exhibit high variance across runs, and display recurring failure modes in experimental design, execution, and evidence-based reasoning. FIRE-Bench provides a rigorous and diagnostic framework for measuring progress toward reliable agent-driven scientific discovery.", "AI": {"tldr": "FIRE-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30AI\u4ee3\u7406\u79d1\u5b66\u53d1\u73b0\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u8ba9\u4ee3\u7406\u91cd\u65b0\u53d1\u73b0\u5df2\u53d1\u8868\u7684\u673a\u5668\u5b66\u4e60\u7814\u7a76\u6210\u679c\u6765\u6d4b\u8bd5\u5176\u5b8c\u6574\u79d1\u7814\u6d41\u7a0b\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u5b8c\u6574\u79d1\u7814\u5faa\u73af\u4e2d\u8868\u73b0\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u6743\u8861\uff1a\u8981\u4e48\u8fc7\u5ea6\u4f9d\u8d56LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u81ea\u52a8\u751f\u6210\u7814\u7a76\u8f93\u51fa\uff0c\u8981\u4e48\u4f18\u5316\u5b64\u7acb\u6027\u80fd\u6307\u6807\u4f5c\u4e3a\u79d1\u5b66\u6d1e\u5bdf\u7684\u7c97\u7565\u4ee3\u7406\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5168\u9762\u8bc4\u4f30AI\u4ee3\u7406\u5b8c\u6574\u79d1\u5b66\u53d1\u73b0\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "\u5f15\u5165FIRE-Bench\u57fa\u51c6\uff0c\u901a\u8fc7\u8ba9AI\u4ee3\u7406\u91cd\u65b0\u53d1\u73b0\u8fd1\u671f\u9ad8\u5f71\u54cd\u529b\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7684\u5df2\u786e\u7acb\u53d1\u73b0\u6765\u8bc4\u4f30\u4ee3\u7406\u80fd\u529b\u3002\u4ee3\u7406\u4ec5\u83b7\u5f97\u4ece\u5df2\u9a8c\u8bc1\u7814\u7a76\u4e2d\u63d0\u53d6\u7684\u9ad8\u5c42\u7814\u7a76\u95ee\u9898\uff0c\u5fc5\u987b\u81ea\u4e3b\u63a2\u7d22\u60f3\u6cd5\u3001\u8bbe\u8ba1\u5b9e\u9a8c\u3001\u5b9e\u73b0\u4ee3\u7801\u3001\u6267\u884c\u8ba1\u5212\uff0c\u5e76\u57fa\u4e8e\u7ecf\u9a8c\u8bc1\u636e\u5f97\u51fa\u7ed3\u8bba\u3002", "result": "\u8bc4\u4f30\u4e86\u4f7f\u7528\u524d\u6cbfLLM\uff08\u5982GPT-5\uff09\u7684\u6700\u5148\u8fdb\u4ee3\u7406\u3002\u7ed3\u679c\u663e\u793a\u5b8c\u6574\u79d1\u7814\u5faa\u73af\u5bf9\u5f53\u524d\u4ee3\u7406\u7cfb\u7edf\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff1a\u5373\u4f7f\u6700\u5f3a\u4ee3\u7406\u4e5f\u4ec5\u53d6\u5f97\u6709\u9650\u6210\u529f\uff08<50 F1\uff09\uff0c\u8868\u73b0\u51fa\u9ad8\u8fd0\u884c\u65b9\u5dee\uff0c\u5728\u5b9e\u9a8c\u8bbe\u8ba1\u3001\u6267\u884c\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u63a8\u7406\u4e2d\u663e\u793a\u91cd\u590d\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "FIRE-Bench\u4e3a\u8861\u91cf\u5411\u53ef\u9760\u4ee3\u7406\u9a71\u52a8\u79d1\u5b66\u53d1\u73b0\u7684\u8fdb\u5c55\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u683c\u4e14\u5177\u6709\u8bca\u65ad\u6027\u7684\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524dAI\u4ee3\u7406\u5728\u5b8c\u6574\u79d1\u7814\u6d41\u7a0b\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.03351", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03351", "abs": "https://arxiv.org/abs/2602.03351", "authors": ["Mayank Goel", "Aritra Das", "Paras Chopra"], "title": "Building Interpretable Models for Moral Decision-Making", "comment": "8 pages, 4 figures, accepted to AAAI'26 Machine Ethics Workshop", "summary": "We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy on Moral Machine data while remaining small enough for detailed analysis. We use different interpretability techniques to uncover how moral reasoning distributes across the network, demonstrating that biases localize to distinct computational stages among other findings.", "AI": {"tldr": "\u4f7f\u7528\u5b9a\u5236Transformer\u6a21\u578b\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5728\u7535\u8f66\u96be\u9898\u4e2d\u7684\u9053\u5fb7\u51b3\u7b56\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u573a\u666f\u7f16\u7801\u5b9e\u73b077%\u51c6\u786e\u7387\uff0c\u5e76\u5229\u7528\u53ef\u89e3\u91ca\u6027\u6280\u672f\u63ed\u793a\u9053\u5fb7\u63a8\u7406\u5728\u7f51\u7edc\u7684\u5206\u5e03\u6a21\u5f0f", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u8fdb\u884c\u9053\u5fb7\u51b3\u7b56\uff0c\u7279\u522b\u662f\u5728\u7535\u8f66\u96be\u9898\u8fd9\u7c7b\u4f26\u7406\u56f0\u5883\u4e2d\uff0c\u7406\u89e3AI\u7cfb\u7edf\u7684\u9053\u5fb7\u63a8\u7406\u673a\u5236", "method": "\u6784\u5efa\u5b9a\u5236Transformer\u6a21\u578b\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u573a\u666f\u7f16\u7801\uff08\u6d89\u53ca\u4eba\u5458\u3001\u6570\u91cf\u3001\u7ed3\u679c\u5f52\u5c5e\uff09\uff0c\u91c7\u75282\u5c42\u67b6\u6784\u5904\u7406\u9053\u5fb7\u673a\u5668\u6570\u636e\uff0c\u5e94\u7528\u591a\u79cd\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5206\u6790\u7f51\u7edc\u5185\u90e8\u673a\u5236", "result": "\u6a21\u578b\u5728\u9053\u5fb7\u673a\u5668\u6570\u636e\u4e0a\u8fbe\u523077%\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u8db3\u591f\u5c0f\u7684\u89c4\u6a21\u4ee5\u4fbf\u8be6\u7ec6\u5206\u6790\uff1b\u7814\u7a76\u53d1\u73b0\u9053\u5fb7\u63a8\u7406\u5206\u5e03\u5728\u7f51\u7edc\u7684\u4e0d\u540c\u8ba1\u7b97\u9636\u6bb5\uff0c\u504f\u89c1\u5b9a\u4f4d\u5728\u7279\u5b9a\u7684\u8ba1\u7b97\u5c42\u6b21", "conclusion": "\u5b9a\u5236Transformer\u6a21\u578b\u80fd\u6709\u6548\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u7684\u9053\u5fb7\u51b3\u7b56\u8fc7\u7a0b\uff0c\u53ef\u89e3\u91ca\u6027\u6280\u672f\u63ed\u793a\u4e86\u9053\u5fb7\u63a8\u7406\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u5206\u5e03\u7279\u6027\uff0c\u4e3a\u7406\u89e3AI\u4f26\u7406\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2602.02909", "categories": ["cs.AI", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02909", "abs": "https://arxiv.org/abs/2602.02909", "authors": ["Kiran Tomlinson", "Tobias Schnabel", "Adith Swaminathan", "Jennifer Neville"], "title": "Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs", "comment": "28 pages", "summary": "Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $\u03a9(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u601d\u7ef4\u94fe\u63a8\u7406\u6240\u9700\u7684\u8ba1\u7b97\u91cf\uff0c\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4e09\u7c7b\u5178\u578b\u4efb\u52a1\uff0c\u63a8\u7406token\u6570\u91cf\u9700\u8981\u4e0e\u8f93\u5165\u89c4\u6a21\u6210\u7ebf\u6027\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u7406\u8bba\u4e0b\u754c\u3002", "motivation": "\u601d\u7ef4\u94fe\u63a8\u7406\u867d\u7136\u80fd\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5e26\u6765\u4e86\u5de8\u5927\u7684\u5ef6\u8fdf\u548c\u8ba1\u7b97\u6210\u672c\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u4e0a\u63a2\u7a76\uff1a\u968f\u7740\u8f93\u5165\u89c4\u6a21\u589e\u957f\uff0c\u89e3\u51b3\u95ee\u9898\u9700\u8981\u591a\u5c11\u63a8\u7406token\uff1f", "method": "\u6269\u5c55\u4e86\u6709\u754c\u6ce8\u610f\u529b\u524d\u7f00\u9884\u8a00\u673a\u6a21\u578b\uff0c\u5bf9\u4e09\u7c7bBAPO-hard\u4efb\u52a1\uff08\u4e8c\u8fdb\u5236\u591a\u6570\u3001\u4e09\u5143\u7ec4\u5339\u914d\u3001\u56fe\u53ef\u8fbe\u6027\uff09\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u63a8\u7406token\u6570\u91cf\u7684\u4e0b\u754c\uff0c\u5e76\u901a\u8fc7\u663e\u5f0f\u6784\u9020\u63d0\u4f9b\u5339\u914d\u6216\u63a5\u8fd1\u5339\u914d\u7684\u4e0a\u754c\uff0c\u6700\u540e\u7528\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e09\u7c7b\u4efb\u52a1\u90fd\u9700\u8981\u03a9(n)\u4e2a\u63a8\u7406token\uff08\u8f93\u5165\u89c4\u6a21\u4e3an\uff09\uff0c\u5e76\u901a\u8fc7\u6784\u9020\u5b9e\u73b0\u4e86\u5339\u914d\u6216\u63a5\u8fd1\u5339\u914d\u7684\u4e0a\u754c\u3002\u5b9e\u9a8c\u663e\u793a\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u786e\u5b9e\u5448\u73b0\u8fd1\u4f3c\u7ebf\u6027\u7684\u63a8\u7406token\u6269\u5c55\uff0c\u5f53\u63a8\u7406\u9884\u7b97\u53d7\u9650\u65f6\u4f1a\u51fa\u73b0\u5931\u8d25\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u601d\u7ef4\u94fe\u63a8\u7406\u5728\u63a8\u7406\u65f6\u8ba1\u7b97\u65b9\u9762\u7684\u57fa\u672c\u74f6\u9888\uff0c\u4e3a\u5206\u6790\u6700\u4f18\u63a8\u7406\u957f\u5ea6\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e\u67d0\u4e9b\u590d\u6742\u4efb\u52a1\uff0c\u7ebf\u6027\u63a8\u7406token\u6269\u5c55\u662f\u4e0d\u53ef\u907f\u514d\u7684\u3002"}}
{"id": "2602.02919", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02919", "abs": "https://arxiv.org/abs/2602.02919", "authors": ["Jiachen Jiang", "Tianyu Ding", "Zhihui Zhu"], "title": "DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution", "comment": null, "summary": "LLM-driven evolutionary systems have shown promise for automated science discovery, yet existing approaches such as AlphaEvolve rely on full-code histories that are context-inefficient and potentially provide weak evolutionary guidance. In this work, we first formalize the evolutionary agents as a general Expectation-Maximization framework, where the language model samples candidate programs (E-step) and the system updates the control context based on evaluation feedback (M-step). Under this view, constructing context via full-code snapshots constitutes a suboptimal M-step, as redundant implement details dilutes core algorithmic ideas, making it difficult to provide clear inspirations for evolution. To address this, we propose DeltaEvolve, a momentum-driven evolutionary framework that replaces full-code history with structured semantic delta capturing how and why modifications between successive nodes affect performance. As programs are often decomposable, semantic delta usually contains many effective components which are transferable and more informative to drive improvement. By organizing semantic delta through multi-level database and progressive disclosure mechanism, input tokens are further reduced. Empirical evaluations on tasks across diverse scientific domains show that our framework can discover better solution with less token consumption over full-code-based evolutionary agents.", "AI": {"tldr": "DeltaEvolve\u63d0\u51fa\u57fa\u4e8e\u8bed\u4e49\u5dee\u91cf\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u7ed3\u6784\u5316\u8bed\u4e49\u53d8\u5316\u66ff\u4ee3\u5b8c\u6574\u4ee3\u7801\u5386\u53f2\uff0c\u51cf\u5c11token\u6d88\u8017\u5e76\u63d0\u5347\u8fdb\u5316\u6548\u679c", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684\u8fdb\u5316\u7cfb\u7edf\uff08\u5982AlphaEvolve\uff09\u4f9d\u8d56\u5b8c\u6574\u4ee3\u7801\u5386\u53f2\uff0c\u5b58\u5728\u4e0a\u4e0b\u6587\u6548\u7387\u4f4e\u548c\u8fdb\u5316\u6307\u5bfc\u5f31\u7684\u95ee\u9898\u3002\u5b8c\u6574\u4ee3\u7801\u5feb\u7167\u5305\u542b\u5197\u4f59\u5b9e\u73b0\u7ec6\u8282\uff0c\u7a00\u91ca\u4e86\u6838\u5fc3\u7b97\u6cd5\u601d\u60f3\uff0c\u96be\u4ee5\u63d0\u4f9b\u6e05\u6670\u7684\u8fdb\u5316\u7075\u611f\u3002", "method": "\u5c06\u8fdb\u5316\u667a\u80fd\u4f53\u5f62\u5f0f\u5316\u4e3a\u671f\u671b\u6700\u5927\u5316\u6846\u67b6\uff1a\u8bed\u8a00\u6a21\u578b\u91c7\u6837\u5019\u9009\u7a0b\u5e8f\uff08E\u6b65\uff09\uff0c\u7cfb\u7edf\u57fa\u4e8e\u8bc4\u4f30\u53cd\u9988\u66f4\u65b0\u63a7\u5236\u4e0a\u4e0b\u6587\uff08M\u6b65\uff09\u3002\u63d0\u51faDeltaEvolve\u6846\u67b6\uff0c\u7528\u7ed3\u6784\u5316\u8bed\u4e49\u5dee\u91cf\u66ff\u4ee3\u5b8c\u6574\u4ee3\u7801\u5386\u53f2\uff0c\u6355\u6349\u8fde\u7eed\u8282\u70b9\u95f4\u4fee\u6539\u5982\u4f55\u53ca\u4e3a\u4f55\u5f71\u54cd\u6027\u80fd\u3002\u901a\u8fc7\u591a\u7ea7\u6570\u636e\u5e93\u548c\u6e10\u8fdb\u62ab\u9732\u673a\u5236\u7ec4\u7ec7\u8bed\u4e49\u5dee\u91cf\uff0c\u8fdb\u4e00\u6b65\u51cf\u5c11\u8f93\u5165token\u3002", "result": "\u5728\u591a\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u591f\u4ee5\u66f4\u5c11\u7684token\u6d88\u8017\u53d1\u73b0\u6bd4\u57fa\u4e8e\u5b8c\u6574\u4ee3\u7801\u7684\u8fdb\u5316\u667a\u80fd\u4f53\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "DeltaEvolve\u901a\u8fc7\u8bed\u4e49\u5dee\u91cf\u9a71\u52a8\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e0a\u4e0b\u6587\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5728\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u7684\u540c\u65f6\u63d0\u5347\u4e86\u79d1\u5b66\u53d1\u73b0\u7684\u81ea\u52a8\u5316\u80fd\u529b\u3002"}}
{"id": "2602.02952", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02952", "abs": "https://arxiv.org/abs/2602.02952", "authors": ["Elias Hossain", "Shubhashis Roy Dipta", "Subash Neupane", "Rajib Rana", "Ravid Shwartz-Ziv", "Ivan Garibay", "Niloofar Yousefi"], "title": "UAT-LITE: Inference-Time Uncertainty-Aware Attention for Pretrained Transformers", "comment": null, "summary": "Neural NLP models are often miscalibrated, assigning high confidence to incorrect predictions, which undermines selective prediction and high-stakes deployment. Post-hoc calibration methods adjust output probabilities but leave internal computation unchanged, while ensemble and Bayesian approaches improve uncertainty at substantial training or storage cost. We propose UAT-LITE, an inference-time framework that makes self-attention uncertainty-aware using approximate Bayesian inference via Monte Carlo dropout in pretrained transformer classifiers. Token-level epistemic uncertainty is estimated from stochastic forward passes and used to modulate self-attention during contextualization, without modifying pretrained weights or training objectives. We additionally introduce a layerwise variance decomposition to diagnose how predictive uncertainty accumulates across transformer depth. Across the SQuAD 2.0 answerability, MNLI, and SST-2, UAT-LITE reduces Expected Calibration Error by approximately 20% on average relative to a fine-tuned BERT-base baseline while preserving task accuracy, and improves selective prediction and robustness under distribution shift.", "AI": {"tldr": "UAT-LITE\uff1a\u4e00\u79cd\u63a8\u7406\u65f6\u6846\u67b6\uff0c\u901a\u8fc7Monte Carlo dropout\u5728\u9884\u8bad\u7ec3Transformer\u5206\u7c7b\u5668\u4e2d\u5b9e\u73b0\u8fd1\u4f3c\u8d1d\u53f6\u65af\u63a8\u65ad\uff0c\u4f7f\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5177\u5907\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u80fd\u529b\uff0c\u65e0\u9700\u4fee\u6539\u9884\u8bad\u7ec3\u6743\u91cd\u6216\u8bad\u7ec3\u76ee\u6807\u3002", "motivation": "\u795e\u7ecfNLP\u6a21\u578b\u901a\u5e38\u6821\u51c6\u4e0d\u4f73\uff0c\u5bf9\u9519\u8bef\u9884\u6d4b\u8d4b\u4e88\u9ad8\u7f6e\u4fe1\u5ea6\uff0c\u8fd9\u5f71\u54cd\u4e86\u9009\u62e9\u6027\u9884\u6d4b\u548c\u9ad8\u98ce\u9669\u90e8\u7f72\u3002\u73b0\u6709\u540e\u5904\u7406\u6821\u51c6\u65b9\u6cd5\u53ea\u8c03\u6574\u8f93\u51fa\u6982\u7387\u800c\u4e0d\u6539\u53d8\u5185\u90e8\u8ba1\u7b97\uff0c\u800c\u96c6\u6210\u548c\u8d1d\u53f6\u65af\u65b9\u6cd5\u867d\u7136\u80fd\u6539\u5584\u4e0d\u786e\u5b9a\u6027\u4f46\u8bad\u7ec3\u6216\u5b58\u50a8\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51faUAT-LITE\u63a8\u7406\u65f6\u6846\u67b6\uff0c\u5728\u9884\u8bad\u7ec3Transformer\u5206\u7c7b\u5668\u4e2d\u4f7f\u7528Monte Carlo dropout\u8fdb\u884c\u8fd1\u4f3c\u8d1d\u53f6\u65af\u63a8\u65ad\uff0c\u4f30\u8ba1token\u7ea7\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u7528\u5176\u8c03\u5236\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3002\u540c\u65f6\u5f15\u5165\u5c42\u95f4\u65b9\u5dee\u5206\u89e3\u6765\u8bca\u65ad\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u5728Transformer\u6df1\u5ea6\u4e2d\u7684\u7d2f\u79ef\u8fc7\u7a0b\u3002", "result": "\u5728SQuAD 2.0\u53ef\u56de\u7b54\u6027\u3001MNLI\u548cSST-2\u4efb\u52a1\u4e0a\uff0cUAT-LITE\u76f8\u6bd4\u5fae\u8c03BERT-base\u57fa\u7ebf\u5e73\u5747\u51cf\u5c11\u7ea620%\u7684\u671f\u671b\u6821\u51c6\u8bef\u5dee\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u5e76\u6539\u5584\u4e86\u9009\u62e9\u6027\u9884\u6d4b\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "UAT-LITE\u901a\u8fc7\u63a8\u7406\u65f6\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u81ea\u6ce8\u610f\u529b\u8c03\u5236\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u7684\u6821\u51c6\u6027\u80fd\uff0c\u4e3a\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02961", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02961", "abs": "https://arxiv.org/abs/2602.02961", "authors": ["Faye Zhang", "Qianyu Cheng", "Jasmine Wan", "Vishwakarma Singh", "Jinfeng Rao", "Kofi Boakye"], "title": "Generative Engine Optimization: A VLM and Agent Framework for Pinterest Acquisition Growth", "comment": null, "summary": "Large Language Models are fundamentally reshaping content discovery through AI-native search systems such as ChatGPT, Gemini, and Claude. Unlike traditional search engines that match keywords to documents, these systems infer user intent, synthesize multimodal evidence, and generate contextual answers directly on the search page, introducing a paradigm shift from Search Engine Optimization (SEO) to Generative Engine Optimization (GEO). For visual content platforms hosting billions of assets, this poses an acute challenge: individual images lack the semantic depth and authority signals that generative search prioritizes, risking disintermediation as user needs are satisfied in-place without site visits.\n  We present Pinterest GEO, a production-scale framework that pioneers reverse search design: rather than generating generic image captions describing what content is, we fine-tune Vision-Language Models (VLMs) to predict what users would actually search for, augmented this with AI agents that mine real-time internet trends to capture emerging search demand. These VLM-generated queries then drive construction of semantically coherent Collection Pages via multimodal embeddings, creating indexable aggregations optimized for generative retrieval. Finally, we employ hybrid VLM and two-tower ANN architectures to build authority-aware interlinking structures that propagate signals across billions of visual assets. Deployed at scale across billions of images and tens of millions of collections, GEO delivers 20\\% organic traffic growth contributing to multi-million monthly active user (MAU) growth, demonstrating a principled pathway for visual platforms to thrive in the generative search era.", "AI": {"tldr": "Pinterest\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aGEO\u7684\u751f\u4ea7\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u9006\u5411\u641c\u7d22\u8bbe\u8ba1\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7528\u6237\u641c\u7d22\u610f\u56fe\u3001AI\u4ee3\u7406\u6316\u6398\u5b9e\u65f6\u8d8b\u52bf\u3001\u6784\u5efa\u8bed\u4e49\u8fde\u8d2f\u7684\u96c6\u5408\u9875\u9762\uff0c\u4ee5\u53ca\u5efa\u7acb\u6743\u5a01\u611f\u77e5\u7684\u94fe\u63a5\u7ed3\u6784\uff0c\u5e2e\u52a9\u89c6\u89c9\u5185\u5bb9\u5e73\u53f0\u5728\u751f\u6210\u5f0f\u641c\u7d22\u65f6\u4ee3\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6b63\u5728\u91cd\u5851\u5185\u5bb9\u53d1\u73b0\u65b9\u5f0f\uff0c\u4ece\u4f20\u7edf\u7684SEO\u8f6c\u5411\u751f\u6210\u5f0f\u5f15\u64ce\u4f18\u5316(GEO)\u3002\u5bf9\u4e8e\u62e5\u6709\u6570\u5341\u4ebf\u89c6\u89c9\u8d44\u4ea7\u7684\u5e73\u53f0\u5982Pinterest\uff0c\u5355\u4e2a\u56fe\u50cf\u7f3a\u4e4f\u751f\u6210\u5f0f\u641c\u7d22\u6240\u9700\u7684\u8bed\u4e49\u6df1\u5ea6\u548c\u6743\u5a01\u4fe1\u53f7\uff0c\u9762\u4e34\u7528\u6237\u9700\u6c42\u5728\u641c\u7d22\u9875\u9762\u76f4\u63a5\u6ee1\u8db3\u800c\u65e0\u9700\u8bbf\u95ee\u7f51\u7ad9\u7684\u98ce\u9669\u3002", "method": "1. \u9006\u5411\u641c\u7d22\u8bbe\u8ba1\uff1a\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7528\u6237\u5b9e\u9645\u4f1a\u641c\u7d22\u4ec0\u4e48\uff0c\u800c\u975e\u751f\u6210\u901a\u7528\u56fe\u50cf\u63cf\u8ff0\uff1b2. AI\u4ee3\u7406\u6316\u6398\u5b9e\u65f6\u4e92\u8054\u7f51\u8d8b\u52bf\u6355\u83b7\u65b0\u5174\u641c\u7d22\u9700\u6c42\uff1b3. \u4f7f\u7528VLM\u751f\u6210\u7684\u67e5\u8be2\u6784\u5efa\u8bed\u4e49\u8fde\u8d2f\u7684\u96c6\u5408\u9875\u9762\uff1b4. \u91c7\u7528\u6df7\u5408VLM\u548c\u53cc\u5854ANN\u67b6\u6784\u5efa\u7acb\u6743\u5a01\u611f\u77e5\u7684\u94fe\u63a5\u7ed3\u6784\uff0c\u5728\u6570\u5341\u4ebf\u89c6\u89c9\u8d44\u4ea7\u95f4\u4f20\u64ad\u4fe1\u53f7\u3002", "result": "\u5728\u6570\u5341\u4ebf\u56fe\u50cf\u548c\u6570\u5343\u4e07\u96c6\u5408\u4e0a\u5927\u89c4\u6a21\u90e8\u7f72\uff0cGEO\u5b9e\u73b0\u4e8620%\u7684\u6709\u673a\u6d41\u91cf\u589e\u957f\uff0c\u4e3a\u6708\u5ea6\u6d3b\u8dc3\u7528\u6237(MAU)\u5e26\u6765\u6570\u767e\u4e07\u7684\u589e\u957f\u3002", "conclusion": "GEO\u4e3a\u89c6\u89c9\u5e73\u53f0\u5728\u751f\u6210\u5f0f\u641c\u7d22\u65f6\u4ee3\u84ec\u52c3\u53d1\u5c55\u63d0\u4f9b\u4e86\u4e00\u6761\u539f\u5219\u6027\u8def\u5f84\uff0c\u901a\u8fc7\u9006\u5411\u641c\u7d22\u8bbe\u8ba1\u548c\u6743\u5a01\u4fe1\u53f7\u4f20\u64ad\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u89c6\u89c9\u5185\u5bb9\u5728\u751f\u6210\u5f0f\u641c\u7d22\u4e2d\u7684\u8bed\u4e49\u6df1\u5ea6\u4e0d\u8db3\u95ee\u9898\u3002"}}
{"id": "2602.02978", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02978", "abs": "https://arxiv.org/abs/2602.02978", "authors": ["Zuyuan Zhang", "Zeyu Fang", "Tian Lan"], "title": "Structuring Value Representations via Geometric Coherence in Markov Decision Processes", "comment": null, "summary": "Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \\emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.", "AI": {"tldr": "\u63d0\u51faGCR-RL\u65b9\u6cd5\uff0c\u901a\u8fc7\u504f\u5e8f\u96c6\u7406\u8bba\u91cd\u6784\u5f3a\u5316\u5b66\u4e60\uff0c\u5229\u7528\u51e0\u4f55\u4e00\u81f4\u6027\u6b63\u5219\u5316\u63d0\u5347\u6837\u672c\u6548\u7387\u548c\u7a33\u5b9a\u6027", "motivation": "\u51e0\u4f55\u6027\u8d28\u53ef\u4ee5\u7a33\u5b9a\u548c\u52a0\u901f\u5f3a\u5316\u5b66\u4e60\uff0c\u73b0\u6709\u65b9\u6cd5\u5305\u62ec\u7f16\u7801\u5bf9\u79f0\u7ed3\u6784\u3001\u51e0\u4f55\u611f\u77e5\u6570\u636e\u589e\u5f3a\u548c\u5f3a\u5236\u7ed3\u6784\u9650\u5236\u3002\u672c\u6587\u4ece\u5e8f\u7406\u8bba\u7684\u65b0\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6RL\uff0c\u5c06\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u91cd\u6784\u4e3a\u5b66\u4e60\u671f\u671b\u7684\u504f\u5e8f\u96c6", "method": "\u63d0\u51faGCR-RL\uff08\u51e0\u4f55\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5f3a\u5316\u5b66\u4e60\uff09\uff0c\u901a\u8fc7\u8ba1\u7b97\u4e00\u7cfb\u5217\u8d85\u504f\u5e8f\u96c6\u7ec6\u5316\u2014\u2014\u901a\u8fc7\u7ec6\u5316\u5148\u524d\u6b65\u9aa4\u4e2d\u7684\u504f\u5e8f\u96c6\u5e76\u4ece\u65f6\u5e8f\u5dee\u5206\u4fe1\u53f7\u4e2d\u5b66\u4e60\u989d\u5916\u7684\u5e8f\u5173\u7cfb\u2014\u2014\u786e\u4fdd\u652f\u6491\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u7684\u504f\u5e8f\u96c6\u5e8f\u5217\u5177\u6709\u51e0\u4f55\u4e00\u81f4\u6027\u3002\u5f00\u53d1\u4e86\u57fa\u4e8eQ\u5b66\u4e60\u548cactor-critic\u7684\u4e24\u79cd\u65b0\u7b97\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e9b\u8d85\u504f\u5e8f\u96c6\u7ec6\u5316", "result": "\u5206\u6790\u4e86\u7b97\u6cd5\u7684\u7406\u8bba\u6027\u8d28\u548c\u6536\u655b\u901f\u7387\u3002\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u5b9e\u8bc1\u8bc4\u4f30GCR-RL\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u5728\u6837\u672c\u6548\u7387\u548c\u7a33\u5b9a\u6027\u80fd\u65b9\u9762\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb", "conclusion": "\u901a\u8fc7\u5e8f\u7406\u8bba\u89c6\u89d2\u91cd\u65b0\u6784\u5efa\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u51fa\u7684GCR-RL\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5229\u7528\u51e0\u4f55\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff0c\u5728\u4fdd\u6301\u7406\u8bba\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5b9e\u9645\u6027\u80fd"}}
{"id": "2602.02983", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02983", "abs": "https://arxiv.org/abs/2602.02983", "authors": ["Hanna M. Dettki", "Charley M. Wu", "Bob Rehder"], "title": "Are LLMs Biased Like Humans? Causal Reasoning as a Function of Prior Knowledge, Irrelevant Information, and Reasoning Budget", "comment": null, "summary": "Large language models (LLMs) are increasingly used in domains where causal reasoning matters, yet it remains unclear whether their judgments reflect normative causal computation, human-like shortcuts, or brittle pattern matching. We benchmark 20+ LLMs against a matched human baseline on 11 causal judgment tasks formalized by a collider structure ($C_1 \\!\\rightarrow\\! E\\! \\leftarrow \\!C_2$). We find that a small interpretable model compresses LLMs' causal judgments well and that most LLMs exhibit more rule-like reasoning strategies than humans who seem to account for unmentioned latent factors in their probability judgments. Furthermore, most LLMs do not mirror the characteristic human collider biases of weak explaining away and Markov violations. We probe LLMs' causal judgment robustness under (i) semantic abstraction and (ii) prompt overloading (injecting irrelevant text), and find that chain-of-thought (CoT) increases robustness for many LLMs. Together, this divergence suggests LLMs can complement humans when known biases are undesirable, but their rule-like reasoning may break down when uncertainty is intrinsic -- highlighting the need to characterize LLM reasoning strategies for safe, effective deployment.", "AI": {"tldr": "LLMs\u5728\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6bd4\u4eba\u7c7b\u66f4\u89c4\u5219\u5316\u7684\u63a8\u7406\u7b56\u7565\uff0c\u8f83\u5c11\u53d7\u4eba\u7c7b\u5178\u578b\u7684\u56e0\u679c\u504f\u89c1\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5728\u4e0d\u786e\u5b9a\u6027\u60c5\u5883\u4e0b\u5931\u6548\u3002", "motivation": "\u968f\u7740LLMs\u5728\u9700\u8981\u56e0\u679c\u63a8\u7406\u7684\u9886\u57df\u5e94\u7528\u589e\u591a\uff0c\u9700\u8981\u4e86\u89e3\u5b83\u4eec\u7684\u56e0\u679c\u5224\u65ad\u662f\u57fa\u4e8e\u89c4\u8303\u6027\u8ba1\u7b97\u3001\u4eba\u7c7b\u5f0f\u6377\u5f84\u8fd8\u662f\u8106\u5f31\u7684\u6a21\u5f0f\u5339\u914d\u3002", "method": "\u4f7f\u752811\u4e2a\u57fa\u4e8e\u78b0\u649e\u5668\u7ed3\u6784(C\u2081\u2192E\u2190C\u2082)\u7684\u56e0\u679c\u5224\u65ad\u4efb\u52a1\uff0c\u5bf920\u591a\u4e2aLLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u5339\u914d\u7684\u4eba\u7c7b\u57fa\u7ebf\u6bd4\u8f83\u3002\u4f7f\u7528\u53ef\u89e3\u91ca\u6a21\u578b\u538b\u7f29LLMs\u7684\u56e0\u679c\u5224\u65ad\uff0c\u5e76\u6d4b\u8bd5\u5176\u5728\u8bed\u4e49\u62bd\u8c61\u548c\u63d0\u793a\u8fc7\u8f7d\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5927\u591a\u6570LLMs\u8868\u73b0\u51fa\u6bd4\u4eba\u7c7b\u66f4\u89c4\u5219\u5316\u7684\u63a8\u7406\u7b56\u7565\uff0c\u4eba\u7c7b\u5728\u6982\u7387\u5224\u65ad\u4e2d\u4f1a\u8003\u8651\u672a\u63d0\u53ca\u7684\u6f5c\u5728\u56e0\u7d20\u3002LLMs\u8f83\u5c11\u8868\u73b0\u51fa\u4eba\u7c7b\u5178\u578b\u7684\u78b0\u649e\u5668\u504f\u89c1\uff08\u5f31\u89e3\u91ca\u6d88\u9664\u548c\u9a6c\u5c14\u53ef\u592b\u8fdd\u53cd\uff09\u3002\u601d\u7ef4\u94fe(CoT)\u80fd\u63d0\u9ad8\u8bb8\u591aLLMs\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "LLMs\u4e0e\u4eba\u7c7b\u5728\u56e0\u679c\u63a8\u7406\u4e0a\u7684\u5dee\u5f02\u8868\u660e\uff0c\u5f53\u5df2\u77e5\u504f\u89c1\u4e0d\u53ef\u53d6\u65f6\uff0cLLMs\u53ef\u4ee5\u8865\u5145\u4eba\u7c7b\u5224\u65ad\uff0c\u4f46\u5176\u89c4\u5219\u5316\u63a8\u7406\u5728\u4e0d\u786e\u5b9a\u6027\u60c5\u5883\u4e0b\u53ef\u80fd\u5931\u6548\uff0c\u9700\u8981\u8868\u5f81LLMs\u7684\u63a8\u7406\u7b56\u7565\u4ee5\u786e\u4fdd\u5b89\u5168\u6709\u6548\u90e8\u7f72\u3002"}}
{"id": "2602.02991", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02991", "abs": "https://arxiv.org/abs/2602.02991", "authors": ["Haijiang Yan", "Jian-Qiao Zhu", "Adam Sanborn"], "title": "Large Language Models Can Take False First Steps at Inference-time Planning", "comment": null, "summary": "Large language models (LLMs) have been shown to acquire sequence-level planning abilities during training, yet their planning behavior exhibited at inference time often appears short-sighted and inconsistent with these capabilities. We propose a Bayesian account for this gap by grounding planning behavior in the evolving generative context: given the subtle differences between natural language and the language internalized by LLMs, accumulated self-generated context drives a planning-shift during inference and thereby creates the appearance of compromised planning behavior. We further validate the proposed model through two controlled experiments: a random-generation task demonstrating constrained planning under human prompts and increasing planning strength as self-generated context accumulates, and a Gaussian-sampling task showing reduced initial bias when conditioning on self-generated sequences. These findings provide a theoretical explanation along with empirical evidence for characterizing how LLMs plan ahead during inference.", "AI": {"tldr": "LLMs\u5728\u8bad\u7ec3\u4e2d\u83b7\u5f97\u4e86\u5e8f\u5217\u89c4\u5212\u80fd\u529b\uff0c\u4f46\u5728\u63a8\u7406\u65f6\u8868\u73b0\u51fa\u77ed\u89c6\u548c\u4e0d\u4e00\u81f4\u7684\u884c\u4e3a\u3002\u8bba\u6587\u63d0\u51fa\u8d1d\u53f6\u65af\u89e3\u91ca\uff1a\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u9a71\u52a8\u89c4\u5212\u504f\u79fb\uff0c\u5bfc\u81f4\u770b\u4f3c\u53d7\u635f\u7684\u89c4\u5212\u884c\u4e3a\u3002", "motivation": "\u89e3\u91caLLMs\u5728\u63a8\u7406\u65f6\u8868\u73b0\u51fa\u7684\u89c4\u5212\u884c\u4e3a\u4e0e\u8bad\u7ec3\u83b7\u5f97\u7684\u89c4\u5212\u80fd\u529b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u7406\u89e3\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u5982\u4f55\u5f71\u54cdLLMs\u7684\u89c4\u5212\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u7406\u8bba\u6a21\u578b\uff0c\u5c06\u89c4\u5212\u884c\u4e3a\u57fa\u4e8e\u6f14\u5316\u7684\u751f\u6210\u4e0a\u4e0b\u6587\u3002\u901a\u8fc7\u4e24\u4e2a\u53d7\u63a7\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u968f\u673a\u751f\u6210\u4efb\u52a1\u5c55\u793a\u4eba\u7c7b\u63d0\u793a\u4e0b\u7684\u53d7\u9650\u89c4\u5212\u548c\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u79ef\u7d2f\u65f6\u7684\u89c4\u5212\u5f3a\u5ea6\u589e\u52a0\uff1b\u9ad8\u65af\u91c7\u6837\u4efb\u52a1\u663e\u793a\u5728\u81ea\u751f\u6210\u5e8f\u5217\u6761\u4ef6\u4e0b\u521d\u59cb\u504f\u89c1\u7684\u51cf\u5c11\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u6a21\u578b\uff1a\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u786e\u5b9e\u9a71\u52a8\u89c4\u5212\u504f\u79fb\uff0c\u968f\u7740\u4e0a\u4e0b\u6587\u79ef\u7d2f\u89c4\u5212\u5f3a\u5ea6\u589e\u52a0\uff0c\u81ea\u751f\u6210\u5e8f\u5217\u80fd\u51cf\u5c11\u521d\u59cb\u504f\u89c1\u3002\u4e3aLLMs\u63a8\u7406\u65f6\u7684\u524d\u77bb\u89c4\u5212\u884c\u4e3a\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8bc1\u89e3\u91ca\u3002", "conclusion": "LLMs\u63a8\u7406\u65f6\u770b\u4f3c\u53d7\u635f\u7684\u89c4\u5212\u884c\u4e3a\u53ef\u4ee5\u901a\u8fc7\u8d1d\u53f6\u65af\u6846\u67b6\u89e3\u91ca\u4e3a\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u9a71\u52a8\u7684\u89c4\u5212\u504f\u79fb\uff0c\u8fd9\u4e3a\u7406\u89e3\u548c\u6539\u8fdbLLMs\u7684\u89c4\u5212\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.02995", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02995", "abs": "https://arxiv.org/abs/2602.02995", "authors": ["Sizhe Tang", "Rongqian Chen", "Tian Lan"], "title": "Agent Alpha: Tree Search Unifying Generation, Exploration and Evaluation for Computer-Use Agents", "comment": null, "summary": "While scaling test-time compute through trajectory-level sampling has significantly improved Graphical User Interface (GUI) agents, the lack of regressive ability prevents the reuse of partial successes and the recovery from early missteps. In this paper, we introduce Agent Alpha, a unified framework that synergizes generation, exploration, and evaluation through step-level Monte Carlo Tree Search (MCTS). It enables active modeling or exploiting structures of the planning space. By integrating alpha-UCT guided search into the interaction loop, Agent Alpha enables deliberate planning, facilitating early pruning of suboptimal branches and efficient prefix reuse. We also employ comparison-driven evaluation to mitigate absolute scoring biases and diversity-constrained expansion to maintain a compact, informative search space. Regret bound of alpha-UCT is analyzed. On the OSWorld benchmark, Agent Alpha achieves a state-of-the-art success rate of $\\sim 77\\%$, significantly outperforming trajectory-level baselines under equivalent compute.", "AI": {"tldr": "Agent Alpha\u662f\u4e00\u4e2aGUI\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6b65\u9aa4\u7ea7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7ed3\u5408\u751f\u6210\u3001\u63a2\u7d22\u548c\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e3b\u52a8\u89c4\u5212\u3001\u65e9\u671f\u526a\u679d\u548c\u524d\u7f00\u91cd\u7528\uff0c\u5728OSWorld\u57fa\u51c6\u4e0a\u8fbe\u523077%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u901a\u8fc7\u8f68\u8ff9\u7ea7\u91c7\u6837\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\uff0c\u4f46\u7f3a\u4e4f\u56de\u5f52\u80fd\u529b\uff0c\u65e0\u6cd5\u91cd\u7528\u90e8\u5206\u6210\u529f\u7ed3\u679c\u6216\u4ece\u65e9\u671f\u9519\u8bef\u4e2d\u6062\u590d\u3002", "method": "\u63d0\u51faAgent Alpha\u6846\u67b6\uff0c\u96c6\u6210\u6b65\u9aa4\u7ea7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\uff0c\u7ed3\u5408alpha-UCT\u5f15\u5bfc\u641c\u7d22\u3001\u6bd4\u8f83\u9a71\u52a8\u8bc4\u4f30\u548c\u591a\u6837\u6027\u7ea6\u675f\u6269\u5c55\uff0c\u5b9e\u73b0\u4e3b\u52a8\u89c4\u5212\u7a7a\u95f4\u5efa\u6a21\u3002", "result": "\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u7ea677%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u540c\u7b49\u8ba1\u7b97\u6761\u4ef6\u4e0b\u7684\u8f68\u8ff9\u7ea7\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Agent Alpha\u901a\u8fc7\u6b65\u9aa4\u7ea7MCTS\u5b9e\u73b0\u4e86\u6709\u6548\u7684GUI\u4ee3\u7406\u89c4\u5212\uff0c\u5177\u5907\u56de\u5f52\u80fd\u529b\u548c\u524d\u7f00\u91cd\u7528\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\u3002"}}
{"id": "2602.03003", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03003", "abs": "https://arxiv.org/abs/2602.03003", "authors": ["Zhiyu An", "Wan Du"], "title": "Methods and Open Problems in Differentiable Social Choice: Learning Mechanisms, Decisions, and Alignment", "comment": null, "summary": "Social choice is no longer a peripheral concern of political theory or economics-it has become a foundational component of modern machine learning systems. From auctions and resource allocation to federated learning, participatory governance, and the alignment of large language models, machine learning pipelines increasingly aggregate heterogeneous preferences, incentives, and judgments into collective decisions. In effect, many contemporary machine learning systems already implement social choice mechanisms, often implicitly and without explicit normative scrutiny.\n  This Review surveys differentiable social choice: an emerging paradigm that formulates voting rules, mechanisms, and aggregation procedures as learnable, differentiable models optimized from data. We synthesize work across auctions, voting, budgeting, liquid democracy, decentralized aggregation, and inverse mechanism learning, showing how classical axioms and impossibility results reappear as objectives, constraints, and optimization trade-offs. We conclude by identifying 36 open problems defining a new research agenda at the intersection of machine learning, economics, and democratic theory.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u53ef\u5fae\u5206\u793e\u4f1a\u9009\u62e9\u8fd9\u4e00\u65b0\u5174\u8303\u5f0f\uff0c\u5c06\u6295\u7968\u89c4\u5219\u3001\u673a\u5236\u548c\u805a\u5408\u8fc7\u7a0b\u6784\u5efa\u4e3a\u53ef\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7684\u53ef\u5fae\u5206\u6a21\u578b\uff0c\u5e76\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u3001\u7ecf\u6d4e\u5b66\u548c\u6c11\u4e3b\u7406\u8bba\u7684\u4ea4\u53c9\u7814\u7a76\u8bae\u7a0b\u3002", "motivation": "\u793e\u4f1a\u9009\u62e9\u5df2\u4ece\u653f\u6cbb\u7406\u8bba\u548c\u7ecf\u6d4e\u5b66\u7684\u8fb9\u7f18\u95ee\u9898\u8f6c\u53d8\u4e3a\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\u3002\u4ece\u62cd\u5356\u3001\u8d44\u6e90\u5206\u914d\u5230\u8054\u90a6\u5b66\u4e60\u3001\u53c2\u4e0e\u5f0f\u6cbb\u7406\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u805a\u5408\u5f02\u8d28\u504f\u597d\u3001\u6fc0\u52b1\u548c\u5224\u65ad\u6765\u505a\u51fa\u96c6\u4f53\u51b3\u7b56\u3002\u5f53\u524d\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5df2\u5b9e\u73b0\u793e\u4f1a\u9009\u62e9\u673a\u5236\uff0c\u4f46\u5f80\u5f80\u662f\u9690\u5f0f\u7684\u4e14\u7f3a\u4e4f\u89c4\u8303\u6027\u5ba1\u67e5\u3002", "method": "\u8be5\u7efc\u8ff0\u91c7\u7528\u53ef\u5fae\u5206\u793e\u4f1a\u9009\u62e9\u8303\u5f0f\uff0c\u5c06\u6295\u7968\u89c4\u5219\u3001\u673a\u5236\u548c\u805a\u5408\u8fc7\u7a0b\u6784\u5efa\u4e3a\u53ef\u5b66\u4e60\u7684\u3001\u53ef\u5fae\u5206\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u6570\u636e\u4f18\u5316\u3002\u7efc\u5408\u5206\u6790\u4e86\u62cd\u5356\u3001\u6295\u7968\u3001\u9884\u7b97\u7f16\u5236\u3001\u6d41\u52a8\u6c11\u4e3b\u3001\u53bb\u4e2d\u5fc3\u5316\u805a\u5408\u548c\u9006\u5411\u673a\u5236\u5b66\u4e60\u7b49\u9886\u57df\u7684\u5de5\u4f5c\uff0c\u5c55\u793a\u4e86\u7ecf\u5178\u516c\u7406\u548c\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\u5982\u4f55\u91cd\u65b0\u8868\u73b0\u4e3a\u76ee\u6807\u3001\u7ea6\u675f\u548c\u4f18\u5316\u6743\u8861\u3002", "result": "\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u7efc\u8ff0\u4e86\u53ef\u5fae\u5206\u793e\u4f1a\u9009\u62e9\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u4f20\u7edf\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u8f6c\u5316\u4e3a\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u8bc6\u522b\u4e8636\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u3001\u7ecf\u6d4e\u5b66\u548c\u6c11\u4e3b\u7406\u8bba\u7684\u4ea4\u53c9\u7814\u7a76\u5b9a\u4e49\u4e86\u65b0\u7684\u7814\u7a76\u8bae\u7a0b\u3002", "conclusion": "\u53ef\u5fae\u5206\u793e\u4f1a\u9009\u62e9\u4e3a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u89c4\u8303\u6027\u6846\u67b6\uff0c\u4f7f\u793e\u4f1a\u9009\u62e9\u673a\u5236\u80fd\u591f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5e76\u4f18\u5316\u3002\u8be5\u9886\u57df\u9762\u4e34\u7684\u91cd\u8981\u6311\u6218\u5305\u62ec\u5982\u4f55\u5e73\u8861\u6548\u7387\u4e0e\u516c\u5e73\u3001\u900f\u660e\u5ea6\u4e0e\u590d\u6742\u6027\u7b49\u4f20\u7edf\u6743\u8861\uff0c\u4ee5\u53ca\u5982\u4f55\u5c06\u6c11\u4e3b\u7406\u8bba\u539f\u5219\u878d\u5165\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u300236\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u4e3a\u8be5\u4ea4\u53c9\u9886\u57df\u7684\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.03006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03006", "abs": "https://arxiv.org/abs/2602.03006", "authors": ["Ziyang Yu", "Liang Zhao"], "title": "Distilling LLM Reasoning into Graph of Concept Predictors", "comment": null, "summary": "Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.", "AI": {"tldr": "GCP\u662f\u4e00\u4e2a\u63a8\u7406\u611f\u77e5\u7684\u4e3b\u52a8\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6559\u5e08\u6a21\u578b\u7684\u51b3\u7b56\u8fc7\u7a0b\u5916\u90e8\u5316\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u5e76\u7528\u6a21\u5757\u5316\u6982\u5ff5\u9884\u6d4b\u5668\u5728\u5b66\u751f\u6a21\u578b\u4e2d\u955c\u50cf\u8be5\u56fe\uff0c\u4ece\u800c\u63d0\u9ad8\u6837\u672c\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u4e3b\u52a8\u84b8\u998f\u65b9\u6cd5\u901a\u5e38\u53ea\u84b8\u998f\u6700\u7ec8\u6807\u7b7e\uff0c\u4e22\u5f03\u4e86\u4e2d\u95f4\u63a8\u7406\u4fe1\u53f7\uff0c\u65e0\u6cd5\u8bca\u65ad\u63a8\u7406\u7f3a\u5931\u548c\u9519\u8bef\u6765\u6e90\uff0c\u9650\u5236\u4e86\u5927\u89c4\u6a21\u90e8\u7f72LLM\u65f6\u7684\u63a8\u7406\u5ef6\u8fdf\u3001\u8ba1\u7b97\u548cAPI\u6210\u672c\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u56fe\u6982\u5ff5\u9884\u6d4b\u5668\uff08GCP\uff09\u6846\u67b6\uff1a1\uff09\u5c06\u6559\u5e08\u51b3\u7b56\u8fc7\u7a0b\u5916\u90e8\u5316\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff1b2\uff09\u5728\u5b66\u751f\u6a21\u578b\u4e2d\u7528\u6a21\u5757\u5316\u6982\u5ff5\u9884\u6d4b\u5668\u955c\u50cf\u8be5\u56fe\uff1b3\uff09\u91c7\u7528\u56fe\u611f\u77e5\u83b7\u53d6\u7b56\u7565\u9488\u5bf9\u5173\u952e\u63a8\u7406\u8282\u70b9\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u5206\u6b67\uff1b4\uff09\u901a\u8fc7\u76ee\u6807\u5b50\u6a21\u5757\u91cd\u8bad\u7ec3\u5b9e\u73b0\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6548\u7387\u63d0\u5347\u3002", "result": "\u57288\u4e2aNLP\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGCP\u5728\u6709\u9650\u6807\u6ce8\u9884\u7b97\u4e0b\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u540c\u65f6\u4ea7\u751f\u4e86\u66f4\u53ef\u89e3\u91ca\u548c\u53ef\u63a7\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "conclusion": "GCP\u901a\u8fc7\u63a8\u7406\u611f\u77e5\u7684\u4e3b\u52a8\u84b8\u998f\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u8fd8\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u63a7\u5236\u6027\uff0c\u4e3aLLM\u7684\u89c4\u6a21\u5316\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03022", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03022", "abs": "https://arxiv.org/abs/2602.03022", "authors": ["Jiliang Ni", "Jiachen Pu", "Zhongyi Yang", "Jingfeng Luo", "Conggang Hu"], "title": "STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models", "comment": "The paper has been accepted to ICLR 2026", "summary": "The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs' capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.", "AI": {"tldr": "STAR\u6846\u67b6\u901a\u8fc7\u76f8\u4f3c\u6027\u5f15\u5bfc\u7684\u6559\u5e08\u8f85\u52a9\u7cbe\u70bc\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u84b8\u998f\u5230\u8d85\u5c0f\u578b\u6a21\u578b\uff0c\u5728\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51fd\u6570\u8c03\u7528\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u89c4\u6a21\u592a\u5927\u963b\u788d\u5e7f\u6cdb\u91c7\u7528\uff0c\u9700\u8981\u5c06\u5176\u80fd\u529b\u8f6c\u79fb\u5230\u5c0f\u578b\u6a21\u578b\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8fc7\u62df\u5408\u3001\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3001\u4e8c\u5143\u5956\u52b1\u5bf9\u591a\u89e3\u4efb\u52a1\u65e0\u6548\u3001\u6280\u672f\u96be\u4ee5\u534f\u540c\u7b49\u95ee\u9898\u3002", "method": "STAR\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6280\u672f\uff1a1) \u7ea6\u675f\u77e5\u8bc6\u84b8\u998f(CKD)\uff0c\u901a\u8fc7\u589e\u5f3atop-k\u524d\u5411KL\u6563\u5ea6\u6765\u6291\u5236\u9519\u8bef\u9884\u6d4b\uff1b2) \u76f8\u4f3c\u6027\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60(Sim-RL)\uff0c\u5f15\u5165\u7ec6\u7c92\u5ea6\u3001\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u5956\u52b1\u3002\u8fd9\u4e9b\u6280\u672f\u5728\u7edf\u4e00\u8bad\u7ec3\u8bfe\u7a0b\u4e2d\u534f\u540c\u5de5\u4f5c\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTAR\u6a21\u578b\u5728\u5404\u81ea\u89c4\u6a21\u7c7b\u522b\u4e2d\u8fbe\u5230SOTA\u3002\u7279\u522b\u662f0.6B STAR\u6a21\u578b\u5728\u6240\u67091B\u4ee5\u4e0b\u5f00\u6e90\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u751a\u81f3\u8d85\u8fc7\u4e00\u4e9b\u66f4\u5927\u89c4\u6a21\u7684\u77e5\u540d\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "STAR\u5c55\u793a\u4e86\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u84b8\u998f\u5230\u8d85\u5c0f\u578b\u6a21\u578b\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u4e3a\u5f3a\u5927\u3001\u53ef\u8bbf\u95ee\u4e14\u9ad8\u6548\u7684AI\u667a\u80fd\u4f53\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2602.03025", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03025", "abs": "https://arxiv.org/abs/2602.03025", "authors": ["Haitian Zhong", "Jixiu Zhai", "Lei Song", "Jiang Bian", "Qiang Liu", "Tieniu Tan"], "title": "RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents", "comment": null, "summary": "Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a group receive the all 0 or all 1 reward), making the group-normalized advantage uninformative and yielding vanishing updates. To address this problem, we propose RC-GRPO (Reward-Conditioned Group Relative Policy Optimization), which treats exploration as a controllable steering problem via discrete reward tokens. We first fine-tune a Reward-Conditioned Trajectory Policy (RCTP) on mixed-quality trajectories with reward goal special tokens (e.g., <|high_reward|>, <|low_reward|>) injected into the prompts, enabling the model to learn how to generate distinct quality trajectories on demand. Then during RL, we sample diverse reward tokens within each GRPO group and condition rollouts on the sampled token to improve within-group diversity, improving advantage gains. On the Berkeley Function Calling Leaderboard v4 (BFCLv4) multi-turn benchmark, our method yields consistently improved performance than baselines, and the performance on Qwen-2.5-7B-Instruct even surpasses all closed-source API models.", "AI": {"tldr": "\u63d0\u51faRC-GRPO\u65b9\u6cd5\u89e3\u51b3\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u4e2d\u5956\u52b1\u7a00\u758f\u548c\u63a2\u7d22\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u6ce8\u5165\u5956\u52b1\u76ee\u6807\u6807\u8bb0\u6765\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u4e0d\u540c\u8d28\u91cf\u7684\u8f68\u8ff9\uff0c\u63d0\u5347\u7ec4\u5185\u591a\u6837\u6027\uff0c\u5728BFCLv4\u57fa\u51c6\u4e0a\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5956\u52b1\u7a00\u758f\u4e14\u63a2\u7d22\u6210\u672c\u9ad8\u3002\u4f20\u7edf\u7684SFT+GRPO\u65b9\u6cd5\u5728\u7ec4\u5185\u5956\u52b1\u53d8\u5316\u4f4e\u65f6\uff08\u5982\u7ec4\u5185\u591a\u6570rollout\u83b7\u5f97\u51680\u6216\u51681\u5956\u52b1\uff09\u4f1a\u505c\u6ede\uff0c\u5bfc\u81f4\u7ec4\u5f52\u4e00\u5316\u4f18\u52bf\u4fe1\u606f\u4e0d\u8db3\uff0c\u66f4\u65b0\u6d88\u5931", "method": "\u63d0\u51faRC-GRPO\uff08\u5956\u52b1\u6761\u4ef6\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff09\uff1a1\uff09\u9996\u5148\u5728\u6df7\u5408\u8d28\u91cf\u8f68\u8ff9\u4e0a\u5fae\u8c03\u5956\u52b1\u6761\u4ef6\u8f68\u8ff9\u7b56\u7565\uff08RCTP\uff09\uff0c\u5728\u63d0\u793a\u4e2d\u6ce8\u5165\u5956\u52b1\u76ee\u6807\u7279\u6b8a\u6807\u8bb0\uff08\u5982<|high_reward|>, <|low_reward|>\uff09\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u6309\u9700\u751f\u6210\u4e0d\u540c\u8d28\u91cf\u7684\u8f68\u8ff9\uff1b2\uff09\u5728\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\uff0c\u5728\u6bcf\u4e2aGRPO\u7ec4\u5185\u91c7\u6837\u591a\u6837\u5316\u7684\u5956\u52b1\u6807\u8bb0\uff0c\u5e76\u57fa\u4e8e\u91c7\u6837\u6807\u8bb0\u6761\u4ef6\u5316rollout\uff0c\u63d0\u9ad8\u7ec4\u5185\u591a\u6837\u6027\uff0c\u589e\u5f3a\u4f18\u52bf\u589e\u76ca", "result": "\u5728Berkeley Function Calling Leaderboard v4\u591a\u8f6e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u6301\u7eed\u6539\u8fdb\u7684\u6027\u80fd\uff0cQwen-2.5-7B-Instruct\u6a21\u578b\u7684\u6027\u80fd\u751a\u81f3\u8d85\u8d8a\u4e86\u6240\u6709\u95ed\u6e90API\u6a21\u578b", "conclusion": "RC-GRPO\u901a\u8fc7\u5c06\u63a2\u7d22\u89c6\u4e3a\u53ef\u63a7\u7684\u5f15\u5bfc\u95ee\u9898\uff0c\u4f7f\u7528\u79bb\u6563\u5956\u52b1\u6807\u8bb0\u6765\u6539\u5584\u7ec4\u5185\u591a\u6837\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u4e2d\u5956\u52b1\u7a00\u758f\u548c\u63a2\u7d22\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0"}}
{"id": "2602.03026", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03026", "abs": "https://arxiv.org/abs/2602.03026", "authors": ["Weilin Ruan", "Yuxuan Liang"], "title": "Visual Reasoning over Time Series via Multi-Agent System", "comment": null, "summary": "Time series analysis underpins many real-world applications, yet existing time-series-specific methods and pretrained large-model-based approaches remain limited in integrating intuitive visual reasoning and generalizing across tasks with adaptive tool usage. To address these limitations, we propose MAS4TS, a tool-driven multi-agent system for general time series tasks, built upon an Analyzer-Reasoner-Executor paradigm that integrates agent communication, visual reasoning, and latent reconstruction within a unified framework. MAS4TS first performs visual reasoning over time series plots with structured priors using a Vision-Language Model to extract temporal structures, and subsequently reconstructs predictive trajectories in latent space. Three specialized agents coordinate via shared memory and gated communication, while a router selects task-specific tool chains for execution. Extensive experiments on multiple benchmarks demonstrate that MAS4TS achieves state-of-the-art performance across a wide range of time series tasks, while exhibiting strong generalization and efficient inference.", "AI": {"tldr": "MAS4TS\u662f\u4e00\u4e2a\u57fa\u4e8e\u5de5\u5177\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\uff0c\u901a\u8fc7\u89c6\u89c9\u63a8\u7406\u548c\u6f5c\u5728\u91cd\u5efa\u5b9e\u73b0\u8de8\u4efb\u52a1\u6cdb\u5316", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u65b9\u6cd5\u5728\u6574\u5408\u76f4\u89c2\u89c6\u89c9\u63a8\u7406\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u80fd\u591f\u81ea\u9002\u5e94\u4f7f\u7528\u5de5\u5177\u7684\u7edf\u4e00\u6846\u67b6", "method": "\u57fa\u4e8eAnalyzer-Reasoner-Executor\u8303\u5f0f\uff0c\u96c6\u6210\u667a\u80fd\u4f53\u901a\u4fe1\u3001\u89c6\u89c9\u63a8\u7406\u548c\u6f5c\u5728\u91cd\u5efa\uff1b\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5bf9\u65f6\u95f4\u5e8f\u5217\u56fe\u8fdb\u884c\u89c6\u89c9\u63a8\u7406\uff0c\u7136\u540e\u5728\u6f5c\u5728\u7a7a\u95f4\u91cd\u5efa\u9884\u6d4b\u8f68\u8ff9\uff1b\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u901a\u8fc7\u5171\u4eab\u5185\u5b58\u548c\u95e8\u63a7\u901a\u4fe1\u534f\u8c03\uff0c\u8def\u7531\u5668\u9009\u62e9\u4efb\u52a1\u7279\u5b9a\u5de5\u5177\u94fe", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u5e7f\u6cdb\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9ad8\u6548\u63a8\u7406", "conclusion": "MAS4TS\u901a\u8fc7\u5de5\u5177\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u89c6\u89c9\u63a8\u7406\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u7684\u6311\u6218\uff0c\u4e3a\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.03034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03034", "abs": "https://arxiv.org/abs/2602.03034", "authors": ["Binbin Yong", "Haoran Pei", "Jun Shen", "Haoran Li", "Qingguo Zhou", "Zhao Su"], "title": "KANFIS A Neuro-Symbolic Framework for Interpretable and Uncertainty-Aware Learning", "comment": null, "summary": "Adaptive Neuro-Fuzzy Inference System (ANFIS) was designed to combine the learning capabilities of neural network with the reasoning transparency of fuzzy logic. However, conventional ANFIS architectures suffer from structural complexity, where the product-based inference mechanism causes an exponential explosion of rules in high-dimensional spaces. We herein propose the Kolmogorov-Arnold Neuro-Fuzzy Inference System (KANFIS), a compact neuro-symbolic architecture that unifies fuzzy reasoning with additive function decomposition. KANFIS employs an additive aggregation mechanism, under which both model parameters and rule complexity scale linearly with input dimensionality rather than exponentially. Furthermore, KANFIS is compatible with both Type-1 (T1) and Interval Type-2 (IT2) fuzzy logic systems, enabling explicit modeling of uncertainty and ambiguity in fuzzy representations. By using sparse masking mechanisms, KANFIS generates compact and structured rule sets, resulting in an intrinsically interpretable model with clear rule semantics and transparent inference processes. Empirical results demonstrate that KANFIS achieves competitive performance against representative neural and neuro-fuzzy baselines.", "AI": {"tldr": "\u63d0\u51faKANFIS\uff08Kolmogorov-Arnold Neuro-Fuzzy Inference System\uff09\uff0c\u4e00\u79cd\u7d27\u51d1\u7684\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u901a\u8fc7\u52a0\u6cd5\u805a\u5408\u673a\u5236\u89e3\u51b3\u4f20\u7edfANFIS\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u89c4\u5219\u6307\u6570\u7206\u70b8\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edfANFIS\u67b6\u6784\u5b58\u5728\u7ed3\u6784\u590d\u6742\u6027\u95ee\u9898\uff0c\u57fa\u4e8e\u4e58\u79ef\u7684\u63a8\u7406\u673a\u5236\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u4f1a\u5bfc\u81f4\u89c4\u5219\u6570\u91cf\u6307\u6570\u7ea7\u589e\u957f\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faKANFIS\u67b6\u6784\uff0c\u91c7\u7528\u52a0\u6cd5\u805a\u5408\u673a\u5236\u800c\u975e\u4f20\u7edf\u4e58\u79ef\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u53c2\u6570\u548c\u89c4\u5219\u590d\u6742\u5ea6\u968f\u8f93\u5165\u7ef4\u5ea6\u7ebf\u6027\u589e\u957f\u800c\u975e\u6307\u6570\u589e\u957f\u3002\u517c\u5bb9Type-1\u548cInterval Type-2\u6a21\u7cca\u903b\u8f91\u7cfb\u7edf\uff0c\u901a\u8fc7\u7a00\u758f\u63a9\u7801\u673a\u5236\u751f\u6210\u7d27\u51d1\u7ed3\u6784\u5316\u89c4\u5219\u96c6\u3002", "result": "KANFIS\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u4e0e\u4ee3\u8868\u6027\u795e\u7ecf\u7f51\u7edc\u548c\u795e\u7ecf\u6a21\u7cca\u57fa\u7ebf\u76f8\u6bd4\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "KANFIS\u901a\u8fc7\u52a0\u6cd5\u51fd\u6570\u5206\u89e3\u7edf\u4e00\u6a21\u7cca\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfANFIS\u7684\u7ed3\u6784\u590d\u6742\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u795e\u7ecf\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u3002"}}
{"id": "2602.03053", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03053", "abs": "https://arxiv.org/abs/2602.03053", "authors": ["Vishal Venkataramani", "Haizhou Shi", "Zixuan Ke", "Austin Xu", "Xiaoxiao He", "Yingbo Zhou", "Semih Yavuz", "Hao Wang", "Shafiq Joty"], "title": "MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems", "comment": "Preprint; work in progress", "summary": "Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, and has been suggested as a potential tool for guiding coordination of MAS; however, its actual effectiveness in MAS remains unclear. To fill this gap, we present MAS-ProVe, a systematic empirical study of process verification for multi-agent systems (MAS). Our study spans three verification paradigms (LLM-as-a-Judge, reward models, and process reward models), evaluated across two levels of verification granularity (agent-level and iteration-level). We further examine five representative verifiers and four context management strategies, and conduct experiments over six diverse MAS frameworks on multiple reasoning benchmarks. We find that process-level verification does not consistently improve performance and frequently exhibits high variance, highlighting the difficulty of reliably evaluating partial multi-agent trajectories. Among the methods studied, LLM-as-a-Judge generally outperforms reward-based approaches, with trained judges surpassing general-purpose LLMs. We further observe a small performance gap between LLMs acting as judges and as single agents, and identify a context-length-performance trade-off in verification. Overall, our results suggest that effective and robust process verification for MAS remains an open challenge, requiring further advances beyond current paradigms. Code is available at https://github.com/Wang-ML-Lab/MAS-ProVe.", "AI": {"tldr": "\u672c\u6587\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u8fc7\u7a0b\u9a8c\u8bc1\u8fdb\u884c\u4e86\u7cfb\u7edf\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u8fc7\u7a0b\u7ea7\u9a8c\u8bc1\u5e76\u4e0d\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u4e14\u5b58\u5728\u9ad8\u65b9\u5dee\u95ee\u9898\uff0c\u8868\u660e\u53ef\u9760\u8bc4\u4f30\u90e8\u5206\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u5177\u6709\u6311\u6218\u6027\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u63a8\u7406\u8f68\u8ff9\u4e0a\u8868\u73b0\u51fa\u9ad8\u65b9\u5dee\uff0c\u8fc7\u7a0b\u9a8c\u8bc1\u5728\u4e00\u822c\u63a8\u7406\u573a\u666f\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86MAS-ProVe\u7cfb\u7edf\uff0c\u7814\u7a76\u4e09\u79cd\u9a8c\u8bc1\u8303\u5f0f\uff08LLM-as-a-Judge\u3001\u5956\u52b1\u6a21\u578b\u3001\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff09\uff0c\u5728\u4e24\u4e2a\u9a8c\u8bc1\u7c92\u5ea6\uff08\u667a\u80fd\u4f53\u7ea7\u548c\u8fed\u4ee3\u7ea7\uff09\u4e0a\u8bc4\u4f30\uff0c\u8003\u5bdf\u4e86\u4e94\u4e2a\u4ee3\u8868\u6027\u9a8c\u8bc1\u5668\u548c\u56db\u79cd\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\uff0c\u5728\u516d\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548c\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8fc7\u7a0b\u7ea7\u9a8c\u8bc1\u4e0d\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\u4e14\u5e38\u8868\u73b0\u51fa\u9ad8\u65b9\u5dee\uff1bLLM-as-a-Judge\u901a\u5e38\u4f18\u4e8e\u57fa\u4e8e\u5956\u52b1\u7684\u65b9\u6cd5\uff1b\u8bad\u7ec3\u8fc7\u7684\u6cd5\u5b98\u4f18\u4e8e\u901a\u7528LLM\uff1bLLM\u4f5c\u4e3a\u6cd5\u5b98\u4e0e\u4f5c\u4e3a\u5355\u667a\u80fd\u4f53\u4e4b\u95f4\u5b58\u5728\u5c0f\u7684\u6027\u80fd\u5dee\u8ddd\uff1b\u9a8c\u8bc1\u4e2d\u5b58\u5728\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0e\u6027\u80fd\u7684\u6743\u8861\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6709\u6548\u4e14\u9c81\u68d2\u7684\u8fc7\u7a0b\u9a8c\u8bc1\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\uff0c\u9700\u8981\u8d85\u8d8a\u5f53\u524d\u8303\u5f0f\u7684\u8fdb\u4e00\u6b65\u8fdb\u5c55\u3002"}}
{"id": "2602.03097", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03097", "abs": "https://arxiv.org/abs/2602.03097", "authors": ["Bryce Kan", "Wei Yang", "Emily Nguyen", "Ganghui Yi", "Bowen Yi", "Chenxiao Yu", "Yan Liu"], "title": "De-conflating Preference and Qualification: Constrained Dual-Perspective Reasoning for Job Recommendation with Large Language Models", "comment": null, "summary": "Professional job recommendation involves a complex bipartite matching process that must reconcile a candidate's subjective preference with an employer's objective qualification. While Large Language Models (LLMs) are well-suited for modeling the rich semantics of resumes and job descriptions, existing paradigms often collapse these two decision dimensions into a single interaction signal, yielding confounded supervision under recruitment-funnel censoring and limiting policy controllability. To address these challenges, We propose JobRec, a generative job recommendation framework for de-conflating preference and qualification via constrained dual-perspective reasoning. JobRec introduces a Unified Semantic Alignment Schema that aligns candidate and job attributes into structured semantic layers, and a Two-Stage Cooperative Training Strategy that learns decoupled experts to separately infer preference and qualification. Building on these experts, a Lagrangian-based Policy Alignment module optimizes recommendations under explicit eligibility requirements, enabling controllable trade-offs. To mitigate data scarcity, we construct a synthetic dataset refined by experts. Experiments show that JobRec consistently outperforms strong baselines and provides improved controllability for strategy-aware professional matching.", "AI": {"tldr": "JobRec\uff1a\u901a\u8fc7\u7ea6\u675f\u53cc\u89c6\u89d2\u63a8\u7406\u89e3\u8026\u504f\u597d\u4e0e\u8d44\u683c\u7684\u751f\u6210\u5f0f\u804c\u4f4d\u63a8\u8350\u6846\u67b6", "motivation": "\u73b0\u6709\u804c\u4f4d\u63a8\u8350\u65b9\u6cd5\u5c06\u5019\u9009\u4eba\u7684\u4e3b\u89c2\u504f\u597d\u548c\u96c7\u4e3b\u7684\u5ba2\u89c2\u8d44\u683c\u8981\u6c42\u6df7\u4e3a\u4e00\u8c08\uff0c\u5bfc\u81f4\u5728\u62db\u8058\u6f0f\u6597\u5ba1\u67e5\u4e0b\u7684\u76d1\u7763\u6df7\u6dc6\uff0c\u9650\u5236\u4e86\u7b56\u7565\u53ef\u63a7\u6027", "method": "\u63d0\u51faJobRec\u6846\u67b6\uff1a1)\u7edf\u4e00\u8bed\u4e49\u5bf9\u9f50\u6a21\u5f0f\u5c06\u5019\u9009\u4eba\u548c\u804c\u4f4d\u5c5e\u6027\u5bf9\u9f50\u5230\u7ed3\u6784\u5316\u8bed\u4e49\u5c42\uff1b2)\u4e24\u9636\u6bb5\u534f\u540c\u8bad\u7ec3\u7b56\u7565\u5b66\u4e60\u89e3\u8026\u7684\u4e13\u5bb6\u5206\u522b\u63a8\u65ad\u504f\u597d\u548c\u8d44\u683c\uff1b3)\u57fa\u4e8e\u62c9\u683c\u6717\u65e5\u7684\u7b56\u7565\u5bf9\u9f50\u6a21\u5757\u5728\u660e\u786e\u8d44\u683c\u8981\u6c42\u4e0b\u4f18\u5316\u63a8\u8350", "result": "\u5b9e\u9a8c\u8868\u660eJobRec\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5e76\u4e3a\u7b56\u7565\u611f\u77e5\u7684\u4e13\u4e1a\u5339\u914d\u63d0\u4f9b\u6539\u8fdb\u7684\u53ef\u63a7\u6027", "conclusion": "JobRec\u901a\u8fc7\u89e3\u8026\u504f\u597d\u4e0e\u8d44\u683c\u7684\u53cc\u89c6\u89d2\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u804c\u4f4d\u63a8\u8350\u4e2d\u7684\u76d1\u7763\u6df7\u6dc6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u63a7\u7684\u63a8\u8350\u7b56\u7565"}}
{"id": "2602.03100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03100", "abs": "https://arxiv.org/abs/2602.03100", "authors": ["Jingnan Zheng", "Yanzhen Luo", "Jingjun Xu", "Bingnan Liu", "Yuxin Chen", "Chenhang Cui", "Gelei Deng", "Chaochao Lu", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Risky-Bench: Probing Agentic Safety Risks under Real-World Deployment", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed as agents that operate in real-world environments, introducing safety risks beyond linguistic harm. Existing agent safety evaluations rely on risk-oriented tasks tailored to specific agent settings, resulting in limited coverage of safety risk space and failing to assess agent safety behavior during long-horizon, interactive task execution in complex real-world deployments. Moreover, their specialization to particular agent settings limits adaptability across diverse agent configurations. To address these limitations, we propose Risky-Bench, a framework that enables systematic agent safety evaluation grounded in real-world deployment. Risky-Bench organizes evaluation around domain-agnostic safety principles to derive context-aware safety rubrics that delineate safety space, and systematically evaluates safety risks across this space through realistic task execution under varying threat assumptions. When applied to life-assist agent settings, Risky-Bench uncovers substantial safety risks in state-of-the-art agents under realistic execution conditions. Moreover, as a well-structured evaluation pipeline, Risky-Bench is not confined to life-assist scenarios and can be adapted to other deployment settings to construct environment-specific safety evaluations, providing an extensible methodology for agent safety assessment.", "AI": {"tldr": "Risky-Bench\uff1a\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u7684\u7cfb\u7edf\u5316\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u65e0\u5173\u7684\u5b89\u5168\u539f\u5219\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b89\u5168\u6807\u51c6\u6765\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a1\uff09\u4f9d\u8d56\u9488\u5bf9\u7279\u5b9a\u667a\u80fd\u4f53\u8bbe\u7f6e\u7684\u98ce\u9669\u5bfc\u5411\u4efb\u52a1\uff0c\u8986\u76d6\u5b89\u5168\u98ce\u9669\u7a7a\u95f4\u6709\u9650\uff1b2\uff09\u65e0\u6cd5\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u957f\u671f\u3001\u4ea4\u4e92\u5f0f\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u5b89\u5168\u884c\u4e3a\uff1b3\uff09\u5bf9\u7279\u5b9a\u667a\u80fd\u4f53\u8bbe\u7f6e\u7684\u4e13\u95e8\u5316\u9650\u5236\u4e86\u8de8\u4e0d\u540c\u667a\u80fd\u4f53\u914d\u7f6e\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51faRisky-Bench\u6846\u67b6\uff1a1\uff09\u56f4\u7ed5\u9886\u57df\u65e0\u5173\u7684\u5b89\u5168\u539f\u5219\u7ec4\u7ec7\u8bc4\u4f30\uff1b2\uff09\u63a8\u5bfc\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b89\u5168\u6807\u51c6\u6765\u754c\u5b9a\u5b89\u5168\u7a7a\u95f4\uff1b3\uff09\u5728\u4e0d\u540c\u5a01\u80c1\u5047\u8bbe\u4e0b\u901a\u8fc7\u73b0\u5b9e\u4efb\u52a1\u6267\u884c\u7cfb\u7edf\u8bc4\u4f30\u5b89\u5168\u98ce\u9669\uff1b4\uff09\u4f5c\u4e3a\u7ed3\u6784\u5316\u8bc4\u4f30\u7ba1\u9053\uff0c\u53ef\u9002\u5e94\u4e0d\u540c\u90e8\u7f72\u573a\u666f\u6784\u5efa\u73af\u5883\u7279\u5b9a\u7684\u5b89\u5168\u8bc4\u4f30\u3002", "result": "\u5728\u751f\u6d3b\u8f85\u52a9\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e2d\u5e94\u7528Risky-Bench\uff0c\u53d1\u73b0\u5728\u73b0\u5b9e\u6267\u884c\u6761\u4ef6\u4e0b\uff0c\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53\u5b58\u5728\u91cd\u5927\u5b89\u5168\u98ce\u9669\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u9650\u4e8e\u751f\u6d3b\u8f85\u52a9\u573a\u666f\uff0c\u53ef\u9002\u5e94\u5176\u4ed6\u90e8\u7f72\u8bbe\u7f6e\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "Risky-Bench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u3001\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u4e3a\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2602.03128", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03128", "abs": "https://arxiv.org/abs/2602.03128", "authors": ["Abdelghny Orogat", "Ana Rostam", "Essam Mansour"], "title": "Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis", "comment": "25 pages, 9 figures and 13 tables; introduces MAFBench unified multi-agent evaluation suite", "summary": "Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finally, we translate our findings into concrete architectural design principles and framework selection guidance, and outline promising future research directions.", "AI": {"tldr": "MAFBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u7684\u7edf\u4e00\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7814\u7a76\u53d1\u73b0\u6846\u67b6\u67b6\u6784\u9009\u62e9\u5bf9\u7cfb\u7edf\u6027\u80fd\u6709\u5de8\u5927\u5f71\u54cd\uff0c\u5ef6\u8fdf\u53ef\u589e\u52a0100\u500d\u4ee5\u4e0a\uff0c\u89c4\u5212\u51c6\u786e\u7387\u4e0b\u964d30%\uff0c\u534f\u8c03\u6210\u529f\u7387\u4ece90%\u964d\u81f330%\u4ee5\u4e0b\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u4e0d\u540c\u6846\u67b6\u7684\u67b6\u6784\u8bbe\u8ba1\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u53ea\u5173\u6ce8\u5355\u4e00\u80fd\u529b\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u6846\u67b6\u7ea7\u8bc4\u4f30\uff0c\u65e0\u6cd5\u9694\u79bb\u67b6\u6784\u9009\u62e9\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u7684\u67b6\u6784\u5206\u7c7b\u6cd5\uff0c\u5f00\u53d1MAFBench\u7edf\u4e00\u8bc4\u4f30\u5957\u4ef6\uff0c\u96c6\u6210\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5230\u6807\u51c6\u5316\u6267\u884c\u6d41\u7a0b\u4e2d\uff0c\u5bf9\u591a\u4e2a\u6d41\u884c\u6846\u67b6\u8fdb\u884c\u53d7\u63a7\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u6846\u67b6\u7ea7\u8bbe\u8ba1\u9009\u62e9\u5355\u72ec\u5c31\u80fd\u5bfc\u81f4\u5ef6\u8fdf\u589e\u52a0100\u500d\u4ee5\u4e0a\uff0c\u89c4\u5212\u51c6\u786e\u7387\u4e0b\u964d30%\uff0c\u534f\u8c03\u6210\u529f\u7387\u4ece90%\u4ee5\u4e0a\u964d\u81f330%\u4ee5\u4e0b\u3002\u4e0d\u540c\u6846\u67b6\u5728\u7f16\u6392\u5f00\u9500\u3001\u5185\u5b58\u884c\u4e3a\u3001\u89c4\u5212\u3001\u4e13\u4e1a\u5316\u548c\u534f\u8c03\u7b49\u65b9\u9762\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u7684\u67b6\u6784\u9009\u62e9\u5bf9\u7cfb\u7edf\u6027\u80fd\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u67b6\u6784\u8bbe\u8ba1\u539f\u5219\u548c\u6846\u67b6\u9009\u62e9\u6307\u5bfc\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u6846\u67b6\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2602.03146", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03146", "abs": "https://arxiv.org/abs/2602.03146", "authors": ["Santiago Cifuentes"], "title": "General Agents Contain World Models, even under Partial Observability and Stochasticity", "comment": "19 pages, 4 figures", "summary": "Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necessarily contains sufficient knowledge of its environment to allow an approximate reconstruction of it by querying the agent as a black box. This result relied on the assumptions that the agent is deterministic and that the environment is fully observable.\n  In this work, we remove both assumptions by extending the theorem to stochastic agents operating in partially observable environments. Fundamentally, this shows that stochastic agents cannot avoid learning their environment through the usage of randomization. We also strengthen the result by weakening the notion of generality, proving that less powerful agents already contain a model of the world in which they operate.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5148\u524d\u5173\u4e8e\u667a\u80fd\u4f53\u5fc5\u987b\u5b66\u4e60\u73af\u5883\u6a21\u578b\u7684\u7406\u8bba\uff0c\u4ece\u786e\u5b9a\u6027\u3001\u5b8c\u5168\u53ef\u89c2\u6d4b\u73af\u5883\u63a8\u5e7f\u5230\u968f\u673a\u6027\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\uff0c\u8bc1\u660e\u968f\u673a\u5316\u667a\u80fd\u4f53\u4e5f\u65e0\u6cd5\u907f\u514d\u5b66\u4e60\u73af\u5883\u6a21\u578b\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8bc1\u660e\u5728\u7279\u5b9a\u6846\u67b6\u4e0b\uff0c\u51e0\u4e4e\u6700\u4f18\u4e14\u901a\u7528\u7684\u786e\u5b9a\u6027\u667a\u80fd\u4f53\u5fc5\u7136\u5305\u542b\u8db3\u591f\u7684\u73af\u5883\u77e5\u8bc6\uff0c\u4f46\u8be5\u7ed3\u679c\u4f9d\u8d56\u4e8e\u667a\u80fd\u4f53\u786e\u5b9a\u6027\u548c\u73af\u5883\u5b8c\u5168\u53ef\u89c2\u6d4b\u7684\u5047\u8bbe\u3002\u672c\u6587\u65e8\u5728\u79fb\u9664\u8fd9\u4e24\u4e2a\u9650\u5236\u6761\u4ef6\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u6269\u5c55\uff0c\u5c06\u5b9a\u7406\u63a8\u5e7f\u5230\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u8fd0\u884c\u7684\u968f\u673a\u6027\u667a\u80fd\u4f53\uff0c\u540c\u65f6\u901a\u8fc7\u5f31\u5316\u901a\u7528\u6027\u6982\u5ff5\u6765\u52a0\u5f3a\u7ed3\u679c\u3002", "result": "\u8bc1\u660e\u4e86\u968f\u673a\u6027\u667a\u80fd\u4f53\u4e5f\u65e0\u6cd5\u907f\u514d\u901a\u8fc7\u5b66\u4e60\u968f\u673a\u5316\u6765\u5b66\u4e60\u5176\u73af\u5883\uff0c\u5e76\u4e14\u66f4\u5f31\u7684\u667a\u80fd\u4f53\u5df2\u7ecf\u5305\u542b\u5176\u64cd\u4f5c\u73af\u5883\u7684\u4e16\u754c\u6a21\u578b\u3002", "conclusion": "\u5373\u4f7f\u5728\u968f\u673a\u6027\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7684\u66f4\u4e00\u822c\u6761\u4ef6\u4e0b\uff0c\u667a\u80fd\u4f53\u4ecd\u7136\u5fc5\u987b\u5b66\u4e60\u73af\u5883\u6a21\u578b\uff0c\u8fd9\u4e3a\u7406\u89e3\u667a\u80fd\u4f53\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.03151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03151", "abs": "https://arxiv.org/abs/2602.03151", "authors": ["Wei Dai", "Haoyu Wang", "Honghao Chang", "Lijun He", "Fan Li", "Jian Sun", "Haixia Bi"], "title": "Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration", "comment": "12 pages", "summary": "Vision Language Models (VLMs) typically assume complete modality input during inference. However, their effectiveness drops sharply when certain modalities are unavailable or incomplete. Current research primarily faces two dilemmas: Prompt-based methods struggle to restore missing yet indispensable features and impair generalization of VLMs. Imputation-based approaches, lacking effective guidance, are prone to generating semantically irrelevant noise. Restoring precise semantics while sustaining VLM generalization remains challenging. Therefore, we propose a general missing modality restoration strategy in this paper. We introduce an enhanced diffusion model as a pluggable mid-stage training module to effectively restore missing features. Our strategy introduces two key innovations: (I) Dynamic Modality Gating, which adaptively leverages conditional features to steer the generation of semantically consistent features; (II) Cross-Modal Mutual Learning mechanism, which bridges the semantic spaces of dual encoders to achieve bidirectional alignment. Zero-shot evaluations across benchmark datasets demonstrate that our approach outperforms existing baseline methods. Extensive experiments and ablation studies confirm our model as a robust and scalable extension for VLMs in missing modality scenarios, ensuring reliability across diverse missing rates and environments. Our code and models will be publicly available.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u901a\u7528\u7f3a\u5931\u6a21\u6001\u6062\u590d\u7b56\u7565\uff0c\u901a\u8fc7\u589e\u5f3a\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53ef\u63d2\u62d4\u6a21\u5757\uff0c\u7ed3\u5408\u52a8\u6001\u6a21\u6001\u95e8\u63a7\u548c\u8de8\u6a21\u6001\u4e92\u5b66\u4e60\u673a\u5236\uff0c\u6709\u6548\u6062\u590d\u7f3a\u5931\u7279\u5f81\u5e76\u4fdd\u6301\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524dVLM\u5728\u63a8\u7406\u65f6\u5047\u8bbe\u5b8c\u6574\u6a21\u6001\u8f93\u5165\uff0c\u4f46\u5728\u67d0\u4e9b\u6a21\u6001\u7f3a\u5931\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u56f0\u5883\uff1a\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u96be\u4ee5\u6062\u590d\u7f3a\u5931\u7684\u5173\u952e\u7279\u5f81\u5e76\u635f\u5bb3VLM\u6cdb\u5316\uff1b\u57fa\u4e8e\u63d2\u8865\u7684\u65b9\u6cd5\u7f3a\u4e4f\u6709\u6548\u6307\u5bfc\uff0c\u5bb9\u6613\u751f\u6210\u8bed\u4e49\u65e0\u5173\u7684\u566a\u58f0\u3002\u5982\u4f55\u5728\u6062\u590d\u7cbe\u786e\u8bed\u4e49\u7684\u540c\u65f6\u4fdd\u6301VLM\u6cdb\u5316\u80fd\u529b\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u901a\u7528\u7f3a\u5931\u6a21\u6001\u6062\u590d\u7b56\u7565\uff0c\u91c7\u7528\u589e\u5f3a\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53ef\u63d2\u62d4\u7684\u4e2d\u9636\u6bb5\u8bad\u7ec3\u6a21\u5757\u3002\u5f15\u5165\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1\uff09\u52a8\u6001\u6a21\u6001\u95e8\u63a7\uff0c\u81ea\u9002\u5e94\u5229\u7528\u6761\u4ef6\u7279\u5f81\u5f15\u5bfc\u751f\u6210\u8bed\u4e49\u4e00\u81f4\u7684\u7279\u5f81\uff1b2\uff09\u8de8\u6a21\u6001\u4e92\u5b66\u4e60\u673a\u5236\uff0c\u6865\u63a5\u53cc\u7f16\u7801\u5668\u7684\u8bed\u4e49\u7a7a\u95f4\u5b9e\u73b0\u53cc\u5411\u5bf9\u9f50\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u96f6\u6837\u672c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002\u5927\u91cf\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\uff0c\u8be5\u6a21\u578b\u5728\u7f3a\u5931\u6a21\u6001\u573a\u666f\u4e0b\u662fVLM\u7684\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u6269\u5c55\uff0c\u786e\u4fdd\u5728\u4e0d\u540c\u7f3a\u5931\u7387\u548c\u73af\u5883\u4e0b\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u901a\u7528\u7f3a\u5931\u6a21\u6001\u6062\u590d\u7b56\u7565\u901a\u8fc7\u589e\u5f3a\u6269\u6563\u6a21\u578b\u548c\u521b\u65b0\u7684\u95e8\u63a7\u4e0e\u4e92\u5b66\u4e60\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLM\u5728\u6a21\u6001\u7f3a\u5931\u65f6\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u4e3aVLM\u5728\u73b0\u5b9e\u4e16\u754c\u4e0d\u5b8c\u6574\u6570\u636e\u573a\u666f\u4e0b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03160", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03160", "abs": "https://arxiv.org/abs/2602.03160", "authors": ["Woojin Kim", "Sieun Hyeon", "Jusang Oh", "Jaeyoung Do"], "title": "VALUEFLOW: Toward Pluralistic and Steerable Value-based Alignment in Large Language Models", "comment": null, "summary": "Aligning Large Language Models (LLMs) with the diverse spectrum of human values remains a central challenge: preference-based methods often fail to capture deeper motivational principles. Value-based approaches offer a more principled path, yet three gaps persist: extraction often ignores hierarchical structure, evaluation detects presence but not calibrated intensity, and the steerability of LLMs at controlled intensities remains insufficiently understood. To address these limitations, we introduce VALUEFLOW, the first unified framework that spans extraction, evaluation, and steering with calibrated intensity control. The framework integrates three components: (i) HIVES, a hierarchical value embedding space that captures intra- and cross-theory value structure; (ii) the Value Intensity DataBase (VIDB), a large-scale resource of value-labeled texts with intensity estimates derived from ranking-based aggregation; and (iii) an anchor-based evaluator that produces consistent intensity scores for model outputs by ranking them against VIDB panels. Using VALUEFLOW, we conduct a comprehensive large-scale study across ten models and four value theories, identifying asymmetries in steerability and composition laws for multi-value control. This paper establishes a scalable infrastructure for evaluating and controlling value intensity, advancing pluralistic alignment of LLMs.", "AI": {"tldr": "VALUEFLOW\uff1a\u9996\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u503c\u5d4c\u5165\u3001\u5927\u89c4\u6a21\u503c\u5f3a\u5ea6\u6570\u636e\u5e93\u548c\u951a\u70b9\u8bc4\u4f30\u5668\uff0c\u5b9e\u73b0LLM\u503c\u63d0\u53d6\u3001\u8bc4\u4f30\u548c\u5f3a\u5ea6\u53ef\u63a7\u5f15\u5bfc", "motivation": "\u5f53\u524dLLM\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u504f\u597d\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u6df1\u5c42\u52a8\u673a\u539f\u5219\uff1b2\uff09\u503c\u63d0\u53d6\u5ffd\u7565\u5c42\u6b21\u7ed3\u6784\uff1b3\uff09\u8bc4\u4f30\u53ea\u80fd\u68c0\u6d4b\u5b58\u5728\u6027\u800c\u65e0\u6cd5\u91cf\u5316\u5f3a\u5ea6\uff1b4\uff09LLM\u5728\u53ef\u63a7\u5f3a\u5ea6\u4e0b\u7684\u5f15\u5bfc\u6027\u7406\u89e3\u4e0d\u8db3", "method": "\u63d0\u51faVALUEFLOW\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1\uff09HIVES\u5206\u5c42\u503c\u5d4c\u5165\u7a7a\u95f4\uff0c\u6355\u6349\u7406\u8bba\u548c\u8de8\u7406\u8bba\u503c\u7ed3\u6784\uff1b2\uff09VIDB\u503c\u5f3a\u5ea6\u6570\u636e\u5e93\uff0c\u901a\u8fc7\u57fa\u4e8e\u6392\u5e8f\u7684\u805a\u5408\u83b7\u5f97\u5f3a\u5ea6\u4f30\u8ba1\u7684\u5927\u89c4\u6a21\u503c\u6807\u6ce8\u6587\u672c\uff1b3\uff09\u951a\u70b9\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u8f93\u51fa\u4e0eVIDB\u9762\u677f\u6392\u5e8f\u4ea7\u751f\u4e00\u81f4\u7684\u5f3a\u5ea6\u5206\u6570", "result": "\u572810\u4e2a\u6a21\u578b\u548c4\u4e2a\u503c\u7406\u8bba\u7684\u5927\u89c4\u6a21\u7814\u7a76\u4e2d\uff0c\u8bc6\u522b\u4e86\u5f15\u5bfc\u6027\u7684\u4e0d\u5bf9\u79f0\u6027\u548c\u591a\u503c\u63a7\u5236\u7684\u7ec4\u5408\u89c4\u5f8b\uff0c\u5efa\u7acb\u4e86\u8bc4\u4f30\u548c\u63a7\u5236\u503c\u5f3a\u5ea6\u7684\u53ef\u6269\u5c55\u57fa\u7840\u8bbe\u65bd", "conclusion": "VALUEFLOW\u4e3aLLM\u7684\u591a\u5143\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u901a\u8fc7\u5f3a\u5ea6\u6821\u51c6\u63a7\u5236\u63a8\u8fdb\u4e86LLM\u7684\u591a\u5143\u4ef7\u503c\u5bf9\u9f50"}}
{"id": "2602.03219", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03219", "abs": "https://arxiv.org/abs/2602.03219", "authors": ["Guhong Chen", "Chenghao Sun", "Cheng Fu", "Qiyao Wang", "Zhihong Huang", "Chaopeng Wei", "Guangxu Chen", "Feiteng Fang", "Ahmadreza Argha", "Bing Zhao", "Xander Xu", "Qi Han", "Hamid Alinejad-Rokny", "Qiang Qu", "Binhua Li", "Shiwen Ni", "Min Yang", "Hu Wei", "Yongbin Li"], "title": "Beyond Quantity: Trajectory Diversity Scaling for Code Agents", "comment": null, "summary": "As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quantity-centric scaling exhibits an early bottleneck that underutilizes trajectory data. We propose TDScaling, a Trajectory Diversity Scaling-based data synthesis framework for code agents that scales performance through diversity rather than raw volume. Under a fixed training budget, increasing trajectory diversity yields larger gains than adding more trajectories, improving the performance-cost trade-off for agent training. TDScaling integrates four innovations: (1) a Business Cluster mechanism that captures real-service logical dependencies; (2) a blueprint-driven multi-agent paradigm that enforces trajectory coherence; (3) an adaptive evolution mechanism that steers synthesis toward long-tail scenarios using Domain Entropy, Reasoning Mode Entropy, and Cumulative Action Complexity to prevent mode collapse; and (4) a sandboxed code tool that mitigates catastrophic forgetting of intrinsic coding capabilities. Experiments on general tool-use benchmarks (BFCL, tau^2-Bench) and code agent tasks (RebenchT, CodeCI, BIRD) demonstrate a win-win outcome: TDScaling improves both tool-use generalization and inherent coding proficiency. We plan to release the full codebase and the synthesized dataset (including 30,000+ tool clusters) upon publication.", "AI": {"tldr": "TDScaling\u662f\u4e00\u4e2a\u57fa\u4e8e\u8f68\u8ff9\u591a\u6837\u6027\u6269\u5c55\u7684\u4ee3\u7801\u667a\u80fd\u4f53\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u52a0\u8f68\u8ff9\u591a\u6837\u6027\u800c\u975e\u5355\u7eaf\u589e\u52a0\u6570\u636e\u91cf\u6765\u63d0\u5347\u6027\u80fd\uff0c\u5728\u56fa\u5b9a\u8bad\u7ec3\u9884\u7b97\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7MCP\u534f\u8bae\u6f14\u53d8\u4e3a\u5de5\u5177\u4ea4\u4e92\u667a\u80fd\u4f53\uff0c\u5176\u6cdb\u5316\u80fd\u529b\u53d7\u5230\u4f4e\u8d28\u91cf\u5408\u6210\u6570\u636e\u548c\u6570\u91cf\u6269\u5c55\u6536\u76ca\u9012\u51cf\u7684\u9650\u5236\u3002\u6570\u91cf\u4e3a\u4e2d\u5fc3\u7684\u6269\u5c55\u5b58\u5728\u65e9\u671f\u74f6\u9888\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u8f68\u8ff9\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86TDScaling\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u521b\u65b0\uff1a1) \u4e1a\u52a1\u96c6\u7fa4\u673a\u5236\u6355\u6349\u771f\u5b9e\u670d\u52a1\u903b\u8f91\u4f9d\u8d56\uff1b2) \u84dd\u56fe\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u8303\u5f0f\u786e\u4fdd\u8f68\u8ff9\u8fde\u8d2f\u6027\uff1b3) \u81ea\u9002\u5e94\u8fdb\u5316\u673a\u5236\u4f7f\u7528\u9886\u57df\u71b5\u3001\u63a8\u7406\u6a21\u5f0f\u71b5\u548c\u7d2f\u79ef\u52a8\u4f5c\u590d\u6742\u5ea6\u5f15\u5bfc\u5408\u6210\u671d\u5411\u957f\u5c3e\u573a\u666f\uff1b4) \u6c99\u76d2\u5316\u4ee3\u7801\u5de5\u5177\u9632\u6b62\u5185\u5728\u7f16\u7801\u80fd\u529b\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "\u5728\u901a\u7528\u5de5\u5177\u4f7f\u7528\u57fa\u51c6(BFCL, tau^2-Bench)\u548c\u4ee3\u7801\u667a\u80fd\u4f53\u4efb\u52a1(RebenchT, CodeCI, BIRD)\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTDScaling\u5b9e\u73b0\u4e86\u53cc\u8d62\uff1a\u65e2\u63d0\u5347\u4e86\u5de5\u5177\u4f7f\u7528\u6cdb\u5316\u80fd\u529b\uff0c\u53c8\u589e\u5f3a\u4e86\u5185\u5728\u7f16\u7801\u80fd\u529b\u3002\u8ba1\u5212\u53d1\u5e03\u5305\u542b30,000+\u5de5\u5177\u96c6\u7fa4\u7684\u5b8c\u6574\u4ee3\u7801\u5e93\u548c\u5408\u6210\u6570\u636e\u96c6\u3002", "conclusion": "\u901a\u8fc7\u8f68\u8ff9\u591a\u6837\u6027\u6269\u5c55\u800c\u975e\u6570\u91cf\u6269\u5c55\uff0cTDScaling\u6846\u67b6\u5728\u56fa\u5b9a\u8bad\u7ec3\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\uff0c\u89e3\u51b3\u4e86\u4ee3\u7801\u667a\u80fd\u4f53\u8bad\u7ec3\u4e2d\u7684\u6570\u636e\u8d28\u91cf\u548c\u591a\u6837\u6027\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2602.03224", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03224", "abs": "https://arxiv.org/abs/2602.03224", "authors": ["Yu Cheng", "Jiuan Zhou", "Yongkang Hu", "Yihang Chen", "Huichi Zhou", "Mingang Chen", "Zhizhong Zhang", "Kun Shao", "Yuan Xie", "Zhaoxia Yin"], "title": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "comment": null, "summary": "Test-time evolution of agent memory serves as a pivotal paradigm for achieving AGI by bolstering complex reasoning through experience accumulation. However, even during benign task evolution, agent safety alignment remains vulnerable-a phenomenon known as Agent Memory Misevolution. To evaluate this phenomenon, we construct the Trust-Memevo benchmark to assess multi-dimensional trustworthiness during benign task evolution, revealing an overall decline in trustworthiness across various task domains and evaluation settings. To address this issue, we propose TAME, a dual-memory evolutionary framework that separately evolves executor memory to improve task performance by distilling generalizable methodologies, and evaluator memory to refine assessments of both safety and task utility based on historical feedback. Through a closed loop of memory filtering, draft generation, trustworthy refinement, execution, and dual-track memory updating, TAME preserves trustworthiness without sacrificing utility. Experiments demonstrate that TAME mitigates misevolution, achieving a joint improvement in both trustworthiness and task performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTAME\u6846\u67b6\u89e3\u51b3\u667a\u80fd\u4f53\u5728\u4efb\u52a1\u6f14\u5316\u8fc7\u7a0b\u4e2d\u8bb0\u5fc6\u9519\u8bef\u6f14\u5316\u5bfc\u81f4\u5b89\u5168\u6027\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u53cc\u8bb0\u5fc6\u6f14\u5316\u673a\u5236\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u667a\u80fd\u4f53\u5728\u6d4b\u8bd5\u65f6\u901a\u8fc7\u8bb0\u5fc6\u6f14\u5316\u79ef\u7d2f\u7ecf\u9a8c\u662f\u5b9e\u73b0AGI\u7684\u5173\u952e\u8303\u5f0f\uff0c\u4f46\u5373\u4f7f\u5728\u826f\u6027\u4efb\u52a1\u6f14\u5316\u8fc7\u7a0b\u4e2d\uff0c\u667a\u80fd\u4f53\u7684\u5b89\u5168\u5bf9\u9f50\u4ecd\u7136\u8106\u5f31\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\"\u667a\u80fd\u4f53\u8bb0\u5fc6\u9519\u8bef\u6f14\u5316\"\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u8fd9\u4e00\u73b0\u8c61\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTAME\u53cc\u8bb0\u5fc6\u6f14\u5316\u6846\u67b6\uff1a1) \u5206\u522b\u6f14\u5316\u6267\u884c\u5668\u8bb0\u5fc6\uff08\u901a\u8fc7\u63d0\u70bc\u53ef\u6cdb\u5316\u65b9\u6cd5\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff09\u548c\u8bc4\u4f30\u5668\u8bb0\u5fc6\uff08\u57fa\u4e8e\u5386\u53f2\u53cd\u9988\u4f18\u5316\u5b89\u5168\u6027\u548c\u4efb\u52a1\u6548\u7528\u8bc4\u4f30\uff09\uff1b2) \u5efa\u7acb\u5305\u542b\u8bb0\u5fc6\u8fc7\u6ee4\u3001\u8349\u7a3f\u751f\u6210\u3001\u53ef\u4fe1\u5ea6\u7cbe\u70bc\u3001\u6267\u884c\u548c\u53cc\u8f68\u8bb0\u5fc6\u66f4\u65b0\u7684\u95ed\u73af\u6d41\u7a0b\u3002", "result": "\u6784\u5efa\u4e86Trust-Memevo\u57fa\u51c6\u8bc4\u4f30\u826f\u6027\u4efb\u52a1\u6f14\u5316\u4e2d\u7684\u591a\u7ef4\u5ea6\u53ef\u4fe1\u5ea6\uff0c\u53d1\u73b0\u5404\u79cd\u4efb\u52a1\u9886\u57df\u548c\u8bc4\u4f30\u8bbe\u7f6e\u4e2d\u53ef\u4fe1\u5ea6\u666e\u904d\u4e0b\u964d\u3002TAME\u6846\u67b6\u5b9e\u9a8c\u8bc1\u660e\u80fd\u591f\u7f13\u89e3\u8bb0\u5fc6\u9519\u8bef\u6f14\u5316\uff0c\u5728\u53ef\u4fe1\u5ea6\u548c\u4efb\u52a1\u6027\u80fd\u4e0a\u5b9e\u73b0\u8054\u5408\u63d0\u5347\u3002", "conclusion": "TAME\u6846\u67b6\u901a\u8fc7\u5206\u79bb\u6f14\u5316\u6267\u884c\u5668\u8bb0\u5fc6\u548c\u8bc4\u4f30\u5668\u8bb0\u5fc6\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6548\u7528\u7684\u540c\u65f6\u4fdd\u62a4\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u89e3\u51b3\u667a\u80fd\u4f53\u8bb0\u5fc6\u9519\u8bef\u6f14\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u4e3a\u5b9e\u73b0\u5b89\u5168\u7684AGI\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2602.03238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03238", "abs": "https://arxiv.org/abs/2602.03238", "authors": ["Pengyu Zhu", "Li Sun", "Philip S. Yu", "Sen Su"], "title": "The Necessity of a Unified Framework for LLM-Based Agent Evaluation", "comment": null, "summary": "With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.", "AI": {"tldr": "\u63d0\u51fa\u6807\u51c6\u5316\u667a\u80fd\u4f53\u8bc4\u4f30\u6846\u67b6\uff0c\u89e3\u51b3\u5f53\u524d\u8bc4\u4f30\u4e2d\u7cfb\u7edf\u63d0\u793a\u3001\u5de5\u5177\u914d\u7f6e\u3001\u73af\u5883\u52a8\u6001\u7b49\u6df7\u6742\u56e0\u7d20\u5bfc\u81f4\u7684\u516c\u5e73\u6027\u548c\u53ef\u590d\u73b0\u6027\u95ee\u9898", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u8bc4\u4f30\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff1a1) \u8bc4\u4f30\u7ed3\u679c\u53d7\u7cfb\u7edf\u63d0\u793a\u3001\u5de5\u5177\u914d\u7f6e\u3001\u73af\u5883\u52a8\u6001\u7b49\u6df7\u6742\u56e0\u7d20\u5f71\u54cd\uff1b2) \u7f3a\u4e4f\u6807\u51c6\u5316\u6846\u67b6\u5bfc\u81f4\u4e0d\u540c\u7814\u7a76\u8005\u7684\u8bc4\u4f30\u65b9\u6cd5\u788e\u7247\u5316\uff1b3) \u73af\u5883\u6570\u636e\u4e0d\u6807\u51c6\u5bfc\u81f4\u9519\u8bef\u96be\u4ee5\u8ffd\u8e2a\u548c\u7ed3\u679c\u4e0d\u53ef\u590d\u73b0\uff1b4) \u8fd9\u79cd\u7f3a\u4e4f\u6807\u51c6\u5316\u5e26\u6765\u4e86\u4e0d\u516c\u5e73\u6027\u548c\u4e0d\u900f\u660e\u6027", "method": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u667a\u80fd\u4f53\u8bc4\u4f30\u6846\u67b6\uff0c\u65e8\u5728\u6807\u51c6\u5316\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u5305\u62ec\uff1a1) \u6807\u51c6\u5316\u7cfb\u7edf\u63d0\u793a\u548c\u5de5\u5177\u914d\u7f6e\uff1b2) \u7edf\u4e00\u73af\u5883\u6570\u636e\u89c4\u8303\uff1b3) \u5efa\u7acb\u53ef\u8ffd\u8e2a\u7684\u9519\u8bef\u5206\u6790\u673a\u5236\uff1b4) \u786e\u4fdd\u8bc4\u4f30\u7ed3\u679c\u7684\u53ef\u590d\u73b0\u6027", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u667a\u80fd\u4f53\u8bc4\u4f30\u7684\u63d0\u6848\uff0c\u4f46\u5c1a\u672a\u5c55\u793a\u5177\u4f53\u5b9e\u65bd\u7ed3\u679c\u3002\u8be5\u6846\u67b6\u65e8\u5728\u4e3a\u9886\u57df\u63d0\u4f9b\u516c\u5e73\u3001\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6807\u51c6", "conclusion": "\u6807\u51c6\u5316\u667a\u80fd\u4f53\u8bc4\u4f30\u6846\u67b6\u5bf9\u4e8e\u8be5\u9886\u57df\u7684\u4e25\u8c28\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002\u63d0\u51fa\u7684\u7edf\u4e00\u8bc4\u4f30\u65b9\u6848\u5c06\u89e3\u51b3\u5f53\u524d\u8bc4\u4f30\u4e2d\u7684\u6df7\u6742\u56e0\u7d20\u3001\u4e0d\u516c\u5e73\u6027\u548c\u4e0d\u900f\u660e\u6027\u95ee\u9898\uff0c\u4fc3\u8fdb\u667a\u80fd\u4f53\u6280\u672f\u7684\u53ef\u9760\u8fdb\u6b65"}}
{"id": "2602.03249", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03249", "abs": "https://arxiv.org/abs/2602.03249", "authors": ["Zhicheng Yang", "Zhijiang Guo", "Yinya Huang", "Yongxin Wang", "Wenlei Shi", "Yiwei Wang", "Xiaodan Liang", "Jing Tang"], "title": "Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning", "comment": null, "summary": "Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.", "AI": {"tldr": "Accordion-Thinking\u6846\u67b6\u8ba9LLMs\u5b66\u4f1a\u901a\u8fc7\u52a8\u6001\u603b\u7ed3\u6765\u81ea\u6211\u8c03\u8282\u63a8\u7406\u6b65\u9aa4\u7684\u7c92\u5ea6\uff0c\u5b9e\u73b0\u63a8\u7406\u4e0a\u4e0b\u6587\u7684\u538b\u7f29\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u957f\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u867d\u7136\u80fd\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u9762\u4e34KV\u7f13\u5b58\u7ebf\u6027\u589e\u957f\u548c\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u4e8c\u6b21\u65b9\u589e\u957f\u7684\u5b9e\u8df5\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u673a\u5236\u3002", "method": "\u63d0\u51faAccordion-Thinking\u6846\u67b6\uff0c\u8ba9LLMs\u5b66\u4e60\u901a\u8fc7\u52a8\u6001\u603b\u7ed3\u6765\u8c03\u8282\u63a8\u7406\u6b65\u9aa4\u7c92\u5ea6\uff0c\u91c7\u7528Fold\u63a8\u7406\u6a21\u5f0f\u5b9a\u671f\u603b\u7ed3\u601d\u7ef4\u8fc7\u7a0b\u5e76\u4e22\u5f03\u5386\u53f2\u601d\u8003\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u6fc0\u52b1\u8fd9\u79cd\u80fd\u529b\u3002", "result": "\u6a21\u578b\u5b66\u4f1a\u4e86\u5c06\u5173\u952e\u63a8\u7406\u4fe1\u606f\u7f16\u7801\u5230\u7d27\u51d1\u7684\u603b\u7ed3\u4e2d\uff0cFold\u6a21\u5f0f\u4e0e\u5b8c\u6574Unfold\u6a21\u5f0f\u4e4b\u95f4\u7684\u51c6\u786e\u7387\u5dee\u8ddd\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9010\u6e10\u7f29\u5c0f\u76f4\u81f3\u6d88\u5931\uff0c\u572848GB GPU\u914d\u7f6e\u4e0b\u5b9e\u73b0\u4e863\u500d\u541e\u5410\u91cf\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u5b66\u4e60\u81ea\u6211\u538b\u7f29\uff0cLLMs\u80fd\u591f\u5728\u6700\u5c0f\u5316\u4f9d\u8d56token\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\u800c\u4e0d\u5f71\u54cd\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u540c\u65f6\u7ed3\u6784\u5316\u7684\u6b65\u9aa4\u603b\u7ed3\u63d0\u4f9b\u4e86\u4eba\u7c7b\u53ef\u8bfb\u7684\u63a8\u7406\u8fc7\u7a0b\u8bb0\u5f55\u3002"}}
{"id": "2602.03255", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03255", "abs": "https://arxiv.org/abs/2602.03255", "authors": ["Tianyu Chen", "Chujia Hu", "Ge Gao", "Dongrui Liu", "Xia Hu", "Wenjie Wang"], "title": "LPS-Bench: Benchmarking Safety Awareness of Computer-Use Agents in Long-Horizon Planning under Benign and Adversarial Scenarios", "comment": null, "summary": "Computer-use agents (CUAs) that interact with real computer systems can perform automated tasks but face critical safety risks. Ambiguous instructions may trigger harmful actions, and adversarial users can manipulate tool execution to achieve malicious goals. Existing benchmarks mostly focus on short-horizon or GUI-based tasks, evaluating on execution-time errors but overlooking the ability to anticipate planning-time risks. To fill this gap, we present LPS-Bench, a benchmark that evaluates the planning-time safety awareness of MCP-based CUAs under long-horizon tasks, covering both benign and adversarial interactions across 65 scenarios of 7 task domains and 9 risk types. We introduce a multi-agent automated pipeline for scalable data generation and adopt an LLM-as-a-judge evaluation protocol to assess safety awareness through the planning trajectory. Experiments reveal substantial deficiencies in existing CUAs' ability to maintain safe behavior. We further analyze the risks and propose mitigation strategies to improve long-horizon planning safety in MCP-based CUA systems. We open-source our code at https://github.com/tychenn/LPS-Bench.", "AI": {"tldr": "LPS-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30\u57fa\u4e8eMCP\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u89c4\u5212\u65f6\u5b89\u5168\u610f\u8bc6\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d67\u4e2a\u4efb\u52a1\u9886\u57df\u30019\u79cd\u98ce\u9669\u7c7b\u578b\u768465\u4e2a\u573a\u666f\uff0c\u63ed\u793a\u73b0\u6709\u4ee3\u7406\u5728\u5b89\u5168\u884c\u4e3a\u7ef4\u62a4\u65b9\u9762\u7684\u4e25\u91cd\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u77ed\u65f6\u7a0b\u6216GUI\u4efb\u52a1\uff0c\u8bc4\u4f30\u6267\u884c\u65f6\u9519\u8bef\u4f46\u5ffd\u7565\u4e86\u89c4\u5212\u65f6\u98ce\u9669\u9884\u6d4b\u80fd\u529b\u3002\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u9762\u4e34\u6a21\u7cca\u6307\u4ee4\u89e6\u53d1\u6709\u5bb3\u64cd\u4f5c\u548c\u5bf9\u6297\u6027\u7528\u6237\u64cd\u7eb5\u5de5\u5177\u6267\u884c\u7684\u98ce\u9669\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u89c4\u5212\u65f6\u5b89\u5168\u610f\u8bc6\u3002", "method": "\u63d0\u51faLPS-Bench\u57fa\u51c6\uff0c\u5305\u542b65\u4e2a\u573a\u666f\u8986\u76d67\u4e2a\u4efb\u52a1\u9886\u57df\u548c9\u79cd\u98ce\u9669\u7c7b\u578b\uff1b\u91c7\u7528\u591a\u4ee3\u7406\u81ea\u52a8\u5316\u7ba1\u9053\u8fdb\u884c\u53ef\u6269\u5c55\u6570\u636e\u751f\u6210\uff1b\u4f7f\u7528LLM-as-a-judge\u8bc4\u4f30\u534f\u8bae\u901a\u8fc7\u89c4\u5212\u8f68\u8ff9\u8bc4\u4f30\u5b89\u5168\u610f\u8bc6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5728\u7ef4\u6301\u5b89\u5168\u884c\u4e3a\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1b\u5206\u6790\u4e86\u98ce\u9669\u5e76\u63d0\u51fa\u4e86\u6539\u8fdbMCP-based CUA\u7cfb\u7edf\u957f\u65f6\u7a0b\u89c4\u5212\u5b89\u5168\u7684\u7f13\u89e3\u7b56\u7565\u3002", "conclusion": "LPS-Bench\u586b\u8865\u4e86\u89c4\u5212\u65f6\u5b89\u5168\u610f\u8bc6\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u7cfb\u7edf\u7684\u5b89\u5168\u7f3a\u9677\uff0c\u4e3a\u6539\u8fdb\u957f\u65f6\u7a0b\u89c4\u5212\u5b89\u5168\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2602.03263", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03263", "abs": "https://arxiv.org/abs/2602.03263", "authors": ["Yuxuan Liu", "Yuntian Shi", "Kun Wang", "Haoting Shen", "Kun Yang"], "title": "CSR-Bench: A Benchmark for Evaluating the Cross-modal Safety and Reliability of MLLMs", "comment": "25 pages, 1 figures", "summary": "Multimodal large language models (MLLMs) enable interaction over both text and images, but their safety behavior can be driven by unimodal shortcuts instead of true joint intent understanding. We introduce CSR-Bench, a benchmark for evaluating cross-modal reliability through four stress-testing interaction patterns spanning Safety, Over-rejection, Bias, and Hallucination, covering 61 fine-grained types. Each instance is constructed to require integrated image-text interpretation, and we additionally provide paired text-only controls to diagnose modality-induced behavior shifts. We evaluate 16 state-of-the-art MLLMs and observe systematic cross-modal alignment gaps. Models show weak safety awareness, strong language dominance under interference, and consistent performance degradation from text-only controls to multimodal inputs. We also observe a clear trade-off between reducing over-rejection and maintaining safe, non-discriminatory behavior, suggesting that some apparent safety gains may come from refusal-oriented heuristics rather than robust intent understanding. WARNING: This paper contains unsafe contents.", "AI": {"tldr": "CSR-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u6a21\u6001\u53ef\u9760\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u56db\u79cd\u538b\u529b\u6d4b\u8bd5\u6a21\u5f0f\uff08\u5b89\u5168\u3001\u8fc7\u5ea6\u62d2\u7edd\u3001\u504f\u89c1\u3001\u5e7b\u89c9\uff09\u8986\u76d661\u79cd\u7ec6\u7c92\u5ea6\u7c7b\u578b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u8de8\u6a21\u6001\u5bf9\u9f50\u5dee\u8ddd\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u652f\u6301\u6587\u672c\u548c\u56fe\u50cf\u4ea4\u4e92\uff0c\u4f46\u5176\u5b89\u5168\u884c\u4e3a\u53ef\u80fd\u7531\u5355\u6a21\u6001\u6377\u5f84\u9a71\u52a8\u800c\u975e\u771f\u6b63\u7684\u8054\u5408\u610f\u56fe\u7406\u89e3\u3002\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u5728\u9700\u8981\u6574\u5408\u56fe\u50cf\u6587\u672c\u89e3\u91ca\u7684\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u6784\u5efaCSR-Bench\u57fa\u51c6\uff0c\u5305\u542b\u56db\u79cd\u538b\u529b\u6d4b\u8bd5\u4ea4\u4e92\u6a21\u5f0f\uff1a\u5b89\u5168\u3001\u8fc7\u5ea6\u62d2\u7edd\u3001\u504f\u89c1\u3001\u5e7b\u89c9\uff0c\u8986\u76d661\u79cd\u7ec6\u7c92\u5ea6\u7c7b\u578b\u3002\u6bcf\u4e2a\u5b9e\u4f8b\u90fd\u9700\u8981\u6574\u5408\u56fe\u50cf\u6587\u672c\u89e3\u91ca\uff0c\u5e76\u63d0\u4f9b\u914d\u5bf9\u7684\u7eaf\u6587\u672c\u63a7\u5236\u7ec4\u4ee5\u8bca\u65ad\u6a21\u6001\u5f15\u8d77\u7684\u884c\u4e3a\u53d8\u5316\u3002\u8bc4\u4f30\u4e8616\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u89c2\u5bdf\u5230\u7cfb\u7edf\u6027\u8de8\u6a21\u6001\u5bf9\u9f50\u5dee\u8ddd\uff1a\u6a21\u578b\u8868\u73b0\u51fa\u5f31\u5b89\u5168\u610f\u8bc6\u3001\u5728\u5e72\u6270\u4e0b\u5f3a\u70c8\u7684\u8bed\u8a00\u4e3b\u5bfc\u6027\uff0c\u4ee5\u53ca\u4ece\u7eaf\u6587\u672c\u63a7\u5236\u7ec4\u5230\u591a\u6a21\u6001\u8f93\u5165\u7684\u6027\u80fd\u6301\u7eed\u4e0b\u964d\u3002\u8fd8\u53d1\u73b0\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\u4e0e\u4fdd\u6301\u5b89\u5168\u975e\u6b67\u89c6\u884c\u4e3a\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u6743\u8861\uff0c\u8868\u660e\u67d0\u4e9b\u8868\u9762\u5b89\u5168\u6539\u8fdb\u53ef\u80fd\u6765\u81ea\u62d2\u7edd\u5bfc\u5411\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u800c\u975e\u7a33\u5065\u7684\u610f\u56fe\u7406\u89e3\u3002", "conclusion": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u8de8\u6a21\u6001\u53ef\u9760\u6027\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u8054\u5408\u610f\u56fe\u7406\u89e3\u673a\u5236\u3002CSR-Bench\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u591a\u6a21\u6001\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2602.03279", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03279", "abs": "https://arxiv.org/abs/2602.03279", "authors": ["Zhengbo Jiao", "Shaobo Wang", "Zifan Zhang", "Xuan Ren", "Wei Wang", "Bing Zhao", "Hu Wei", "Linfeng Zhang"], "title": "Agentic Proposing: Enhancing Large Language Model Reasoning via Compositional Skill Synthesis", "comment": "23page4", "summary": "Advancing complex reasoning in large language models relies on high-quality, verifiable datasets, yet human annotation remains cost-prohibitive and difficult to scale. Current synthesis paradigms often face a recurring trade-off: maintaining structural validity typically restricts problem complexity, while relaxing constraints to increase difficulty frequently leads to inconsistent or unsolvable instances. To address this, we propose Agentic Proposing, a framework that models problem synthesis as a goal-driven sequential decision process where a specialized agent dynamically selects and composes modular reasoning skills. Through an iterative workflow of internal reflection and tool-use, we develop the Agentic-Proposer-4B using Multi-Granularity Policy Optimization (MGPO) to generate high-precision, verifiable training trajectories across mathematics, coding, and science. Empirical results demonstrate that downstream solvers trained on agent-synthesized data significantly outperform leading baselines and exhibit robust cross-domain generalization. Notably, a 30B solver trained on only 11,000 synthesized trajectories achieves a state-of-the-art 91.6% accuracy on AIME25, rivaling frontier-scale proprietary models such as GPT-5 and proving that a small volume of high-quality synthetic signals can effectively substitute for massive human-curated datasets.", "AI": {"tldr": "\u63d0\u51faAgentic Proposing\u6846\u67b6\uff0c\u901a\u8fc7\u76ee\u6807\u9a71\u52a8\u7684\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\u5408\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u7684\u590d\u6742\u63a8\u7406\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u51fa\u7684\u6c42\u89e3\u5668\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u548c\u79d1\u5b66\u9886\u57df\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u63d0\u5347\u9700\u8981\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\uff0c\u4f46\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u9762\u4e34\u4e24\u96be\uff1a\u4fdd\u6301\u7ed3\u6784\u6709\u6548\u6027\u4f1a\u9650\u5236\u95ee\u9898\u590d\u6742\u5ea6\uff0c\u800c\u589e\u52a0\u96be\u5ea6\u53c8\u4f1a\u5bfc\u81f4\u4e0d\u4e00\u81f4\u6216\u4e0d\u53ef\u89e3\u5b9e\u4f8b\u3002", "method": "\u63d0\u51faAgentic Proposing\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u5408\u6210\u5efa\u6a21\u4e3a\u76ee\u6807\u9a71\u52a8\u7684\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8ba9\u4e13\u95e8\u4ee3\u7406\u52a8\u6001\u9009\u62e9\u548c\u7ec4\u5408\u6a21\u5757\u5316\u63a8\u7406\u6280\u80fd\u3002\u901a\u8fc7\u5185\u90e8\u53cd\u601d\u548c\u5de5\u5177\u4f7f\u7528\u7684\u8fed\u4ee3\u5de5\u4f5c\u6d41\uff0c\u4f7f\u7528\u591a\u7c92\u5ea6\u7b56\u7565\u4f18\u5316\uff08MGPO\uff09\u5f00\u53d1Agentic-Proposer-4B\uff0c\u751f\u6210\u6570\u5b66\u3001\u7f16\u7a0b\u548c\u79d1\u5b66\u9886\u57df\u7684\u9ad8\u7cbe\u5ea6\u53ef\u9a8c\u8bc1\u8bad\u7ec3\u8f68\u8ff9\u3002", "result": "\u57fa\u4e8e\u4ee3\u7406\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u4e0b\u6e38\u6c42\u89e3\u5668\u663e\u8457\u4f18\u4e8e\u9886\u5148\u57fa\u7ebf\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002\u4ec5\u752811,000\u6761\u5408\u6210\u8f68\u8ff9\u8bad\u7ec3\u768430B\u6c42\u89e3\u5668\u5728AIME25\u4e0a\u8fbe\u523091.6%\u7684SOTA\u51c6\u786e\u7387\uff0c\u5ab2\u7f8eGPT-5\u7b49\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "\u5c11\u91cf\u9ad8\u8d28\u91cf\u5408\u6210\u4fe1\u53f7\u53ef\u4ee5\u6709\u6548\u66ff\u4ee3\u6d77\u91cf\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u8bc1\u660e\u901a\u8fc7\u76ee\u6807\u9a71\u52a8\u7684\u4ee3\u7406\u5408\u6210\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u7684\u590d\u6742\u63a8\u7406\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.03285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03285", "abs": "https://arxiv.org/abs/2602.03285", "authors": ["Yuelin Hu", "Jun Xu", "Bingcong Lu", "Zhengxue Cheng", "Hongwei Hu", "Ronghua Wu", "Li Song"], "title": "MeetBench-XL: Calibrated Multi-Dimensional Evaluation and Learned Dual-Policy Agents for Real-Time Meetings", "comment": "accepted by AAAI2026 ws", "summary": "Enterprise meeting environments require AI assistants that handle diverse operational tasks, from rapid fact checking during live discussions to cross meeting analysis for strategic planning, under strict latency, cost, and privacy constraints. Existing meeting benchmarks mainly focus on simplified question answering and fail to reflect real world enterprise workflows, where queries arise organically from multi stakeholder collaboration, span long temporal contexts, and require tool augmented reasoning.\n  We address this gap through a grounded dataset and a learned agent framework. First, we introduce MeetAll, a bilingual and multimodal corpus derived from 231 enterprise meetings totaling 140 hours. Questions are injected using an enterprise informed protocol validated by domain expert review and human discriminability studies. Unlike purely synthetic benchmarks, this protocol is grounded in four enterprise critical dimensions: cognitive load, temporal context span, domain expertise, and actionable task execution, calibrated through interviews with stakeholders across finance, healthcare, and technology sectors.\n  Second, we propose MeetBench XL, a multi dimensional evaluation protocol aligned with human judgment that measures factual fidelity, intent alignment, response efficiency, structural clarity, and completeness. Third, we present MeetMaster XL, a learned dual policy agent that jointly optimizes query routing between fast and slow reasoning paths and tool invocation, including retrieval, cross meeting aggregation, and web search. A lightweight classifier enables accurate routing with minimal overhead, achieving a superior quality latency tradeoff over single model baselines. Experiments against commercial systems show consistent gains, supported by ablations, robustness tests, and a real world deployment case study.Resources: https://github.com/huyuelin/MeetBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86MeetAll\u6570\u636e\u96c6\u548cMeetMaster XL\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u4f01\u4e1a\u4f1a\u8bae\u73af\u5883\u4e2d\u7684AI\u52a9\u624b\u4efb\u52a1\uff0c\u5305\u62ec\u5feb\u901f\u4e8b\u5b9e\u6838\u67e5\u548c\u8de8\u4f1a\u8bae\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u4f01\u4e1a\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "motivation": "\u4f01\u4e1a\u4f1a\u8bae\u73af\u5883\u9700\u8981AI\u52a9\u624b\u5904\u7406\u591a\u6837\u5316\u64cd\u4f5c\u4efb\u52a1\uff0c\u4f46\u73b0\u6709\u4f1a\u8bae\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u7b80\u5316\u7684\u95ee\u7b54\u4efb\u52a1\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u7684\u4f01\u4e1a\u5de5\u4f5c\u6d41\u7a0b\u3002\u771f\u5b9e\u7684\u4f01\u4e1a\u67e5\u8be2\u6765\u81ea\u591a\u65b9\u5229\u76ca\u76f8\u5173\u8005\u534f\u4f5c\uff0c\u8de8\u8d8a\u957f\u65f6\u95f4\u4e0a\u4e0b\u6587\uff0c\u9700\u8981\u5de5\u5177\u589e\u5f3a\u63a8\u7406\uff0c\u4e14\u9762\u4e34\u4e25\u683c\u7684\u5ef6\u8fdf\u3001\u6210\u672c\u548c\u9690\u79c1\u7ea6\u675f\u3002", "method": "1. \u5f15\u5165MeetAll\u53cc\u8bed\u591a\u6a21\u6001\u8bed\u6599\u5e93\uff0c\u6765\u81ea231\u4e2a\u4f01\u4e1a\u4f1a\u8bae\u5171140\u5c0f\u65f6\uff0c\u4f7f\u7528\u4f01\u4e1a\u9a8c\u8bc1\u7684\u534f\u8bae\u6ce8\u5165\u95ee\u9898\uff1b2. \u63d0\u51faMeetBench XL\u591a\u7ef4\u8bc4\u4f30\u534f\u8bae\uff0c\u8861\u91cf\u4e8b\u5b9e\u4fdd\u771f\u5ea6\u3001\u610f\u56fe\u5bf9\u9f50\u3001\u54cd\u5e94\u6548\u7387\u3001\u7ed3\u6784\u6e05\u6670\u5ea6\u548c\u5b8c\u6574\u6027\uff1b3. \u63d0\u51faMeetMaster XL\u53cc\u7b56\u7565\u667a\u80fd\u4f53\uff0c\u8054\u5408\u4f18\u5316\u5feb\u901f\u548c\u6162\u901f\u63a8\u7406\u8def\u5f84\u4e4b\u95f4\u7684\u67e5\u8be2\u8def\u7531\u4ee5\u53ca\u5de5\u5177\u8c03\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5546\u4e1a\u7cfb\u7edf\u76f8\u6bd4\uff0cMeetMaster XL\u53d6\u5f97\u4e86\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u3002\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u80fd\u591f\u4ee5\u6700\u5c0f\u5f00\u9500\u5b9e\u73b0\u51c6\u786e\u8def\u7531\uff0c\u5728\u8d28\u91cf-\u5ef6\u8fdf\u6743\u8861\u4e0a\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\u3002\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u3001\u9c81\u68d2\u6027\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u6848\u4f8b\u7814\u7a76\u652f\u6301\u4e86\u8fd9\u4e9b\u7ed3\u679c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u63a5\u5730\u6c14\u7684\u6570\u636e\u96c6\u548c\u5b66\u4e60\u578b\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f01\u4e1a\u4f1a\u8baeAI\u52a9\u624b\u7684\u5173\u952e\u9700\u6c42\u3002MeetAll\u6570\u636e\u96c6\u548cMeetMaster XL\u6846\u67b6\u4e3a\u4f01\u4e1a\u73af\u5883\u4e2d\u7684AI\u52a9\u624b\u63d0\u4f9b\u4e86\u66f4\u8d34\u8fd1\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8d28\u91cf\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u65b9\u9762\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u8861\u3002"}}
{"id": "2602.03286", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03286", "abs": "https://arxiv.org/abs/2602.03286", "authors": ["Michael A. M\u00fcller", "Srdjan Vesic", "Bruno Yun"], "title": "Rejecting Arguments Based on Doubt in Structured Bipolar Argumentation", "comment": "Accepted to AAMAS 2026", "summary": "This paper develops a new approach to computational argumentation that is informed by philosophical and linguistic views. Namely, it takes into account two ideas that have received little attention in the literature on computational argumentation: First, an agent may rationally reject an argument based on mere doubt, thus not all arguments they could defend must be accepted; and, second, that it is sometimes more natural to think in terms of which individual sentences or claims an agent accepts in a debate, rather than which arguments. In order to incorporate these two ideas into a computational approach, we first define the notion of structured bipolar argumentation frameworks (SBAFs), where arguments consist of sentences and we have both an attack and a support relation between them. Then, we provide semantics for SBAFs with two features: (1) Unlike with completeness-based semantics, our semantics do not force agents to accept all defended arguments. (2) In addition to argument extensions, which give acceptable sets of arguments, we also provide semantics for language extensions that specify acceptable sets of sentences. These semantics represent reasonable positions an agent might have in a debate. Our semantics lie between the admissible and complete semantics of abstract argumentation. Further, our approach can be used to provide a new perspective on existing approaches. For instance, we can specify the conditions under which an agent can ignore support between arguments (i.e. under which the use of abstract argumentation is warranted) and we show that deductive support semantics is a special case of our approach.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u6784\u5316\u53cc\u6781\u8bba\u8bc1\u6846\u67b6(SBAF)\uff0c\u5141\u8bb8\u57fa\u4e8e\u6000\u7591\u62d2\u7edd\u8bba\u8bc1\uff0c\u5e76\u63d0\u4f9b\u8bed\u8a00\u6269\u5c55\u8bed\u4e49\uff0c\u4ecb\u4e8e\u53ef\u63a5\u53d7\u548c\u5b8c\u5168\u8bed\u4e49\u4e4b\u95f4", "motivation": "\u73b0\u6709\u8ba1\u7b97\u8bba\u8bc1\u65b9\u6cd5\u5ffd\u7565\u4e24\u4e2a\u91cd\u8981\u54f2\u5b66\u548c\u8bed\u8a00\u5b66\u89c2\u70b9\uff1a1) \u4ee3\u7406\u53ef\u4ee5\u57fa\u4e8e\u6000\u7591\u7406\u6027\u62d2\u7edd\u8bba\u8bc1\uff0c\u4e0d\u5fc5\u63a5\u53d7\u6240\u6709\u53ef\u8fa9\u62a4\u8bba\u8bc1\uff1b2) \u6709\u65f6\u66f4\u81ea\u7136\u5730\u8003\u8651\u4ee3\u7406\u63a5\u53d7\u54ea\u4e9b\u53e5\u5b50\u6216\u4e3b\u5f20\uff0c\u800c\u975e\u54ea\u4e9b\u8bba\u8bc1", "method": "\u5b9a\u4e49\u7ed3\u6784\u5316\u53cc\u6781\u8bba\u8bc1\u6846\u67b6(SBAF)\uff0c\u5176\u4e2d\u8bba\u8bc1\u7531\u53e5\u5b50\u7ec4\u6210\uff0c\u5305\u542b\u653b\u51fb\u548c\u652f\u6301\u5173\u7cfb\u3002\u63d0\u4f9b\u4e24\u79cd\u8bed\u4e49\uff1a1) \u4e0d\u5f3a\u5236\u63a5\u53d7\u6240\u6709\u88ab\u8fa9\u62a4\u8bba\u8bc1\u7684\u8bed\u4e49\uff1b2) \u8bed\u8a00\u6269\u5c55\u8bed\u4e49\uff0c\u6307\u5b9a\u53ef\u63a5\u53d7\u7684\u53e5\u5b50\u96c6\u5408", "result": "\u63d0\u51fa\u7684\u8bed\u4e49\u4ecb\u4e8e\u62bd\u8c61\u8bba\u8bc1\u7684\u53ef\u63a5\u53d7\u548c\u5b8c\u5168\u8bed\u4e49\u4e4b\u95f4\uff0c\u80fd\u63d0\u4f9b\u4ee3\u7406\u5728\u8fa9\u8bba\u4e2d\u7684\u5408\u7406\u7acb\u573a\u3002\u8be5\u65b9\u6cd5\u4e3a\u73b0\u6709\u65b9\u6cd5\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u5982\u6307\u5b9a\u4f55\u65f6\u53ef\u5ffd\u7565\u8bba\u8bc1\u95f4\u652f\u6301\u5173\u7cfb\uff0c\u5e76\u8bc1\u660e\u6f14\u7ece\u652f\u6301\u8bed\u4e49\u662f\u672c\u65b9\u6cd5\u7684\u7279\u4f8b", "conclusion": "\u65b0\u65b9\u6cd5\u5c06\u54f2\u5b66\u548c\u8bed\u8a00\u5b66\u6d1e\u89c1\u878d\u5165\u8ba1\u7b97\u8bba\u8bc1\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u548c\u81ea\u7136\u7684\u6846\u67b6\uff0c\u5141\u8bb8\u57fa\u4e8e\u6000\u7591\u7684\u7406\u6027\u62d2\u7edd\uff0c\u5e76\u652f\u6301\u53e5\u5b50\u5c42\u9762\u7684\u8bed\u4e49\u5206\u6790"}}
{"id": "2602.03315", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03315", "abs": "https://arxiv.org/abs/2602.03315", "authors": ["Menglin Xia", "Xuchao Zhang", "Shantanu Dixit", "Paramaguru Harimurugan", "Rujia Wang", "Victor Ruhle", "Robert Sim", "Chetan Bansal", "Saravan Rajmohan"], "title": "Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity", "comment": null, "summary": "Agent memory systems must accommodate continuously growing information while supporting efficient, context-aware retrieval for downstream tasks. Abstraction is essential for scaling agent memory, yet it often comes at the cost of specificity, obscuring the fine-grained details required for effective reasoning. We introduce Memora, a harmonic memory representation that structurally balances abstraction and specificity. Memora organizes information via its primary abstractions that index concrete memory values and consolidate related updates into unified memory entries, while cue anchors expand retrieval access across diverse aspects of the memory and connect related memories. Building on this structure, we employ a retrieval policy that actively exploits these memory connections to retrieve relevant information beyond direct semantic similarity. Theoretically, we show that standard Retrieval-Augmented Generation (RAG) and Knowledge Graph (KG)-based memory systems emerge as special cases of our framework. Empirically, Memora establishes a new state-of-the-art on the LoCoMo and LongMemEval benchmarks, demonstrating better retrieval relevance and reasoning effectiveness as memory scales.", "AI": {"tldr": "Memora\u662f\u4e00\u79cd\u5e73\u8861\u62bd\u8c61\u4e0e\u5177\u4f53\u6027\u7684\u8bb0\u5fc6\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u62bd\u8c61\u7d22\u5f15\u548c\u951a\u70b9\u8fde\u63a5\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\uff0c\u5728\u8bb0\u5fc6\u6269\u5c55\u65f6\u4fdd\u6301\u63a8\u7406\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u5728\u6269\u5c55\u65f6\u9762\u4e34\u62bd\u8c61\u4e0e\u5177\u4f53\u6027\u7684\u6743\u8861\u95ee\u9898\uff1a\u62bd\u8c61\u6709\u52a9\u4e8e\u89c4\u6a21\u5316\u4f46\u4f1a\u4e22\u5931\u7ec6\u8282\uff0c\u800c\u7ec6\u8282\u5bf9\u6709\u6548\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5e73\u8861\u4e24\u8005\u7684\u8bb0\u5fc6\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMemora\u8c10\u6ce2\u8bb0\u5fc6\u8868\u793a\uff0c\u5305\u542b\uff1a1\uff09\u4e3b\u8981\u62bd\u8c61\u7d22\u5f15\u5177\u4f53\u8bb0\u5fc6\u503c\uff1b2\uff09\u7edf\u4e00\u76f8\u5173\u66f4\u65b0\u7684\u8bb0\u5fc6\u6761\u76ee\uff1b3\uff09\u7ebf\u7d22\u951a\u70b9\u8de8\u591a\u65b9\u9762\u6269\u5c55\u68c0\u7d22\u8bbf\u95ee\uff1b4\uff09\u8fde\u63a5\u76f8\u5173\u8bb0\u5fc6\u3002\u57fa\u4e8e\u6b64\u7ed3\u6784\uff0c\u91c7\u7528\u4e3b\u52a8\u5229\u7528\u8bb0\u5fc6\u8fde\u63a5\u7684\u68c0\u7d22\u7b56\u7565\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u6807\u51c6RAG\u548c\u77e5\u8bc6\u56fe\u8c31\u8bb0\u5fc6\u7cfb\u7edf\u662fMemora\u7684\u7279\u4f8b\u3002\u5b9e\u8bc1\u4e0a\u5728LoCoMo\u548cLongMemEval\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\uff0c\u5728\u8bb0\u5fc6\u6269\u5c55\u65f6\u5c55\u793a\u66f4\u597d\u7684\u68c0\u7d22\u76f8\u5173\u6027\u548c\u63a8\u7406\u6709\u6548\u6027\u3002", "conclusion": "Memora\u901a\u8fc7\u8c10\u6ce2\u8bb0\u5fc6\u8868\u793a\u6709\u6548\u5e73\u8861\u62bd\u8c61\u4e0e\u5177\u4f53\u6027\uff0c\u4e3a\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u4fdd\u6301\u7ec6\u8282\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8bb0\u5fc6\u6269\u5c55\u65f6\u7ef4\u6301\u9ad8\u8d28\u91cf\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.03340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03340", "abs": "https://arxiv.org/abs/2602.03340", "authors": ["Xiao Sun", "Yuming Yang", "Junnan Zhu", "Jiang Zhong", "Xinyu Zhou", "Kaiwen Wei"], "title": "MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis", "comment": "36 pages, 27 figures", "summary": "Mental health disorders represent a burgeoning global public health challenge. While Large Language Models (LLMs) have demonstrated potential in psychiatric assessment, their clinical utility is severely constrained by benchmarks that lack ecological validity and fine-grained diagnostic supervision. To bridge this gap, we introduce \\textbf{MentalDx Bench}, the first benchmark dedicated to disorder-level psychiatric diagnosis within real-world clinical settings. Comprising 712 de-identified electronic health records annotated by board-certified psychiatrists under ICD-11 guidelines, the benchmark covers 76 disorders across 16 diagnostic categories. Evaluation of 18 LLMs reveals a critical \\textit{paradigm misalignment}: strong performance at coarse diagnostic categorization contrasts with systematic failure at disorder-level diagnosis, underscoring a gap between pattern-based modeling and clinical hypothetico-deductive reasoning. In response, we propose \\textbf{MentalSeek-Dx}, a medical-specialized LLM trained to internalize this clinical reasoning process through supervised trajectory construction and curriculum-based reinforcement learning. Experiments on MentalDx Bench demonstrate that MentalSeek-Dx achieves state-of-the-art (SOTA) performance with only 14B parameters, establishing a clinically grounded framework for reliable psychiatric diagnosis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9762\u5411\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u7684\u7cbe\u795e\u969c\u788d\u7ea7\u522b\u8bca\u65ad\u57fa\u51c6MentalDx Bench\uff0c\u5e76\u5f00\u53d1\u4e86\u4e13\u95e8\u7528\u4e8e\u7cbe\u795e\u79d1\u8bca\u65ad\u7684LLM\u6a21\u578bMentalSeek-Dx\uff0c\u901a\u8fc7\u76d1\u7763\u8f68\u8ff9\u6784\u5efa\u548c\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLM\u5728\u7cbe\u795e\u5065\u5eb7\u8bc4\u4f30\u4e2d\u5b58\u5728\u751f\u6001\u6548\u5ea6\u4e0d\u8db3\u548c\u8bca\u65ad\u76d1\u7763\u7c92\u5ea6\u4e0d\u591f\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u4e34\u5e8a\u5e94\u7528\u3002\u9700\u8981\u5efa\u7acb\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e0b\u7684\u969c\u788d\u7ea7\u522b\u8bca\u65ad\u57fa\u51c6\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "1) \u6784\u5efaMentalDx Bench\u57fa\u51c6\uff1a\u5305\u542b712\u4efd\u53bb\u6807\u8bc6\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff0c\u7531\u8ba4\u8bc1\u7cbe\u795e\u79d1\u533b\u751f\u6309\u7167ICD-11\u6807\u51c6\u6807\u6ce8\uff0c\u8986\u76d616\u4e2a\u8bca\u65ad\u7c7b\u522b\u768476\u79cd\u969c\u788d\uff1b2) \u5f00\u53d1MentalSeek-Dx\u6a21\u578b\uff1a\u901a\u8fc7\u76d1\u7763\u8f68\u8ff9\u6784\u5efa\u548c\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u533b\u5b66\u4e13\u7528LLM\uff0c\u6a21\u62df\u4e34\u5e8a\u5047\u8bbe-\u6f14\u7ece\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u8bc4\u4f3018\u4e2aLLM\u53d1\u73b0\u5b58\u5728\u8303\u5f0f\u9519\u4f4d\uff1a\u5728\u7c97\u7c92\u5ea6\u8bca\u65ad\u5206\u7c7b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u969c\u788d\u7ea7\u522b\u8bca\u65ad\u4e0a\u7cfb\u7edf\u6027\u5931\u8d25\u3002MentalSeek-Dx\u5728MentalDx Bench\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u4ec5\u752814B\u53c2\u6570\u3002", "conclusion": "MentalDx Bench\u63ed\u793a\u4e86LLM\u5728\u7cbe\u795e\u79d1\u8bca\u65ad\u4e2d\u7684\u8303\u5f0f\u9519\u4f4d\u95ee\u9898\uff0c\u800cMentalSeek-Dx\u901a\u8fc7\u6a21\u62df\u4e34\u5e8a\u63a8\u7406\u8fc7\u7a0b\u5efa\u7acb\u4e86\u53ef\u9760\u7684\u8bca\u65ad\u6846\u67b6\uff0c\u4e3a\u7cbe\u795e\u79d1AI\u5e94\u7528\u63d0\u4f9b\u4e86\u4e34\u5e8a\u57fa\u7840\u3002"}}
{"id": "2602.03358", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03358", "abs": "https://arxiv.org/abs/2602.03358", "authors": ["Junmo Cho", "Suhan Kim", "Sangjune An", "Minsu Kim", "Dong Bok Lee", "Heejun Lee", "Sung Ju Hwang", "Hae Beom Lee"], "title": "GFlowPO: Generative Flow Network as a Language Model Prompt Optimizer", "comment": null, "summary": "Finding effective prompts for language models (LMs) is critical yet notoriously difficult: the prompt space is combinatorially large, rewards are sparse due to expensive target-LM evaluation. Yet, existing RL-based prompt optimizers often rely on on-policy updates and a meta-prompt sampled from a fixed distribution, leading to poor sample efficiency. We propose GFlowPO, a probabilistic prompt optimization framework that casts prompt search as a posterior inference problem over latent prompts regularized by a meta-prompted reference-LM prior. In the first step, we fine-tune a lightweight prompt-LM with an off-policy Generative Flow Network (GFlowNet) objective, using a replay-based training policy that reuses past prompt evaluations to enable sample-efficient exploration. In the second step, we introduce Dynamic Memory Update (DMU), a training-free mechanism that updates the meta-prompt by injecting both (i) diverse prompts from a replay buffer and (ii) top-performing prompts from a small priority queue, thereby progressively concentrating the search process on high-reward regions. Across few-shot text classification, instruction induction benchmarks, and question answering tasks, GFlowPO consistently outperforms recent discrete prompt optimization baselines.", "AI": {"tldr": "GFlowPO\uff1a\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u6d41\u7f51\u7edc\u548c\u52a8\u6001\u8bb0\u5fc6\u66f4\u65b0\u7684\u6982\u7387\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u540e\u9a8c\u63a8\u65ad\u548c\u6837\u672c\u9ad8\u6548\u63a2\u7d22\u63d0\u5347\u63d0\u793a\u641c\u7d22\u6548\u679c", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u4f9d\u8d56\u5728\u7ebf\u7b56\u7565\u66f4\u65b0\u548c\u56fa\u5b9a\u5206\u5e03\u7684\u5143\u63d0\u793a\u91c7\u6837\u3002\u63d0\u793a\u7a7a\u95f4\u7ec4\u5408\u7206\u70b8\u4e14\u5956\u52b1\u7a00\u758f\uff08\u76ee\u6807\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6602\u8d35\uff09\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "1. \u4f7f\u7528\u79bb\u7b56\u7565\u751f\u6210\u6d41\u7f51\u7edc\u76ee\u6807\u5fae\u8c03\u8f7b\u91cf\u7ea7\u63d0\u793a\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u91cd\u7528\u5386\u53f2\u63d0\u793a\u8bc4\u4f30\u7684\u56de\u653e\u8bad\u7ec3\u7b56\u7565\u5b9e\u73b0\u6837\u672c\u9ad8\u6548\u63a2\u7d22\uff1b2. \u5f15\u5165\u52a8\u6001\u8bb0\u5fc6\u66f4\u65b0\u673a\u5236\uff0c\u4ece\u56de\u653e\u7f13\u51b2\u533a\u6ce8\u5165\u591a\u6837\u5316\u63d0\u793a\u548c\u4ece\u5c0f\u4f18\u5148\u7ea7\u961f\u5217\u6ce8\u5165\u9ad8\u6027\u80fd\u63d0\u793a\uff0c\u9010\u6b65\u96c6\u4e2d\u641c\u7d22\u5230\u9ad8\u5956\u52b1\u533a\u57df\u3002", "result": "\u5728\u5c11\u6837\u672c\u6587\u672c\u5206\u7c7b\u3001\u6307\u4ee4\u5f52\u7eb3\u57fa\u51c6\u6d4b\u8bd5\u548c\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0cGFlowPO\u59cb\u7ec8\u4f18\u4e8e\u6700\u8fd1\u7684\u79bb\u6563\u63d0\u793a\u4f18\u5316\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GFlowPO\u901a\u8fc7\u5c06\u63d0\u793a\u641c\u7d22\u6784\u5efa\u4e3a\u540e\u9a8c\u63a8\u65ad\u95ee\u9898\uff0c\u7ed3\u5408\u751f\u6210\u6d41\u7f51\u7edc\u548c\u52a8\u6001\u8bb0\u5fc6\u66f4\u65b0\uff0c\u5b9e\u73b0\u4e86\u6837\u672c\u9ad8\u6548\u7684\u63d0\u793a\u4f18\u5316\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.03402", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03402", "abs": "https://arxiv.org/abs/2602.03402", "authors": ["Mengxuan Wang", "Yuxin Chen", "Gang Xu", "Tao He", "Hongjie Jiang", "Ming Li"], "title": "Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility", "comment": null, "summary": "Vision language models (VLMs) extend the reasoning capabilities of large language models (LLMs) to cross-modal settings, yet remain highly vulnerable to multimodal jailbreak attacks. Existing defenses predominantly rely on safety fine-tuning or aggressive token manipulations, incurring substantial training costs or significantly degrading utility. Recent research shows that LLMs inherently recognize unsafe content in text, and the incorporation of visual inputs in VLMs frequently dilutes risk-related signals. Motivated by this, we propose Risk Awareness Injection (RAI), a lightweight and training-free framework for safety calibration that restores LLM-like risk recognition by amplifying unsafe signals in VLMs. Specifically, RAI constructs an Unsafe Prototype Subspace from language embeddings and performs targeted modulation on selected high-risk visual tokens, explicitly activating safety-critical signals within the cross-modal feature space. This modulation restores the model's LLM-like ability to detect unsafe content from visual inputs, while preserving the semantic integrity of original tokens for cross-modal reasoning. Extensive experiments across multiple jailbreak and utility benchmarks demonstrate that RAI substantially reduces attack success rate without compromising task performance.", "AI": {"tldr": "RAI\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u5b89\u5168\u6821\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u4e0d\u5b89\u5168\u539f\u578b\u5b50\u7a7a\u95f4\u548c\u5bf9\u9ad8\u98ce\u9669\u89c6\u89c9token\u8fdb\u884c\u9488\u5bf9\u6027\u8c03\u5236\uff0c\u6062\u590dVLM\u5bf9\u4e0d\u5b89\u5168\u5185\u5bb9\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u6709\u6548\u9632\u5fa1\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u3002", "motivation": "\u73b0\u6709VLM\u5b89\u5168\u9632\u5fa1\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5b89\u5168\u5fae\u8c03\u6216\u6fc0\u8fdb\u7684token\u64cd\u4f5c\uff0c\u8bad\u7ec3\u6210\u672c\u9ad8\u6216\u4e25\u91cd\u635f\u5bb3\u6a21\u578b\u5b9e\u7528\u6027\u3002\u7814\u7a76\u53d1\u73b0LLM\u672c\u8eab\u80fd\u8bc6\u522b\u6587\u672c\u4e0d\u5b89\u5168\u5185\u5bb9\uff0c\u4f46VLM\u4e2d\u89c6\u89c9\u8f93\u5165\u4f1a\u7a00\u91ca\u98ce\u9669\u4fe1\u53f7\uff0c\u56e0\u6b64\u9700\u8981\u6062\u590dVLM\u7684LLM\u5f0f\u98ce\u9669\u8bc6\u522b\u80fd\u529b\u3002", "method": "RAI\u4ece\u8bed\u8a00\u5d4c\u5165\u6784\u5efa\u4e0d\u5b89\u5168\u539f\u578b\u5b50\u7a7a\u95f4\uff0c\u5bf9\u9009\u5b9a\u7684\u9ad8\u98ce\u9669\u89c6\u89c9token\u8fdb\u884c\u9488\u5bf9\u6027\u8c03\u5236\uff0c\u5728\u8de8\u6a21\u6001\u7279\u5f81\u7a7a\u95f4\u4e2d\u663e\u5f0f\u6fc0\u6d3b\u5b89\u5168\u5173\u952e\u4fe1\u53f7\uff0c\u6062\u590d\u6a21\u578b\u4ece\u89c6\u89c9\u8f93\u5165\u68c0\u6d4b\u4e0d\u5b89\u5168\u5185\u5bb9\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cbtoken\u7684\u8bed\u4e49\u5b8c\u6574\u6027\u3002", "result": "\u5728\u591a\u4e2a\u8d8a\u72f1\u653b\u51fb\u548c\u5b9e\u7528\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRAI\u663e\u8457\u964d\u4f4e\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u4efb\u52a1\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u7684\u5e73\u8861\u3002", "conclusion": "RAI\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u5b89\u5168\u6821\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u653e\u5927VLM\u4e2d\u7684\u4e0d\u5b89\u5168\u4fe1\u53f7\u6765\u6062\u590dLLM\u5f0f\u7684\u98ce\u9669\u8bc6\u522b\u80fd\u529b\uff0c\u6709\u6548\u9632\u5fa1\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.03403", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03403", "abs": "https://arxiv.org/abs/2602.03403", "authors": ["Guangming Lang", "Mingchuan Shang", "Mengjun Hu", "Jie Zhou", "Feng Xu"], "title": "Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations", "comment": null, "summary": "In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on three qualitative relations, namely, preference, converse, and indifference, to describe agents' attitudes towards issue pairs, which significantly limits their capacity in capturing the essence of conflict. To overcome this limitation, we introduce the concept of an intuitionistic fuzzy preference-based conflict situation that captures agents' attitudes towards issue pairs with finer granularity than that afforded by classical preference-based models. Afterwards, we develop intuitionistic fuzzy preference-based conflict measures within this framework, and construct three-way conflict analysis models for trisecting the set of agent pairs, the agent set, and the issue set. Additionally, relative loss functions built on the proposed conflict functions are employed to calculate thresholds for three-way conflict analysis. Finally, we present adjustment mechanism-based feasible strategies that simultaneously account for both adjustment magnitudes and conflict degrees, together with an algorithm for constructing such feasible strategies, and provide an illustrative example to demonstrate the validity and effectiveness of the proposed model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u7684\u4e09\u652f\u51b2\u7a81\u5206\u6790\u6a21\u578b\uff0c\u901a\u8fc7\u66f4\u7ec6\u7c92\u5ea6\u7684\u504f\u597d\u63cf\u8ff0\u548c\u51b2\u7a81\u5ea6\u91cf\uff0c\u6539\u8fdb\u4e86\u4f20\u7edf\u4e09\u652f\u51b2\u7a81\u5206\u6790\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u504f\u597d\u7684\u51b2\u7a81\u6a21\u578b\u4ec5\u4f7f\u7528\u504f\u597d\u3001\u9006\u504f\u597d\u548c\u4e2d\u6027\u4e09\u79cd\u5b9a\u6027\u5173\u7cfb\u6765\u63cf\u8ff0\u4ee3\u7406\u5bf9\u8bae\u9898\u5bf9\u7684\u6001\u5ea6\uff0c\u8fd9\u79cd\u7c97\u7cd9\u7684\u8868\u793a\u65b9\u5f0f\u4e25\u91cd\u9650\u5236\u4e86\u6355\u6349\u51b2\u7a81\u672c\u8d28\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u51b2\u7a81\u60c5\u5883\u6982\u5ff5\uff0c\u5efa\u7acb\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u51b2\u7a81\u5ea6\u91cf\u6846\u67b6\uff0c\u6784\u5efa\u4ee3\u7406\u5bf9\u96c6\u5408\u3001\u4ee3\u7406\u96c6\u5408\u548c\u8bae\u9898\u96c6\u5408\u7684\u4e09\u652f\u5212\u5206\u6a21\u578b\uff0c\u57fa\u4e8e\u51b2\u7a81\u51fd\u6570\u6784\u5efa\u76f8\u5bf9\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u9608\u503c\uff0c\u5e76\u63d0\u51fa\u8003\u8651\u8c03\u6574\u5e45\u5ea6\u548c\u51b2\u7a81\u7a0b\u5ea6\u7684\u53ef\u884c\u7b56\u7565\u8c03\u6574\u673a\u5236\u3002", "result": "\u5f00\u53d1\u4e86\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u51b2\u7a81\u5ea6\u91cf\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u4e09\u652f\u51b2\u7a81\u5206\u6790\u6a21\u578b\uff0c\u8bbe\u8ba1\u4e86\u9608\u503c\u8ba1\u7b97\u65b9\u6cd5\u548c\u53ef\u884c\u7b56\u7565\u8c03\u6574\u7b97\u6cd5\uff0c\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u76f4\u89c9\u6a21\u7cca\u504f\u597d\u51b2\u7a81\u5206\u6790\u6a21\u578b\u80fd\u591f\u66f4\u7cbe\u7ec6\u5730\u63cf\u8ff0\u4ee3\u7406\u6001\u5ea6\uff0c\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u51b2\u7a81\u5206\u6790\u548c\u89e3\u51b3\u7b56\u7565\uff0c\u6269\u5c55\u4e86\u4e09\u652f\u51b2\u7a81\u5206\u6790\u7684\u7406\u8bba\u6846\u67b6\u548c\u5e94\u7528\u80fd\u529b\u3002"}}
{"id": "2602.03429", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03429", "abs": "https://arxiv.org/abs/2602.03429", "authors": ["Tae Soo Kim", "Yoonjoo Lee", "Jaesang Yu", "John Joon Young Chung", "Juho Kim"], "title": "DiscoverLLM: From Executing Intents to Discovering Them", "comment": null, "summary": "To handle ambiguous and open-ended requests, Large Language Models (LLMs) are increasingly trained to interact with users to surface intents they have not yet expressed (e.g., ask clarification questions). However, users are often ambiguous because they have not yet formed their intents: they must observe and explore outcomes to discover what they want. Simply asking \"what kind of tone do you want?\" fails when users themselves do not know. We introduce DiscoverLLM, a novel and generalizable framework that trains LLMs to help users form and discover their intents. Central to our approach is a novel user simulator that models cognitive state with a hierarchy of intents that progressively concretize as the model surfaces relevant options -- where the degree of concretization serves as a reward signal that models can be trained to optimize. Resulting models learn to collaborate with users by adaptively diverging (i.e., explore options) when intents are unclear, and converging (i.e., refine and implement) when intents concretize. Across proposed interactive benchmarks in creative writing, technical writing, and SVG drawing, DiscoverLLM achieves over 10% higher task performance while reducing conversation length by up to 40%. In a user study with 75 human participants, DiscoverLLM improved conversation satisfaction and efficiency compared to baselines.", "AI": {"tldr": "\u63d0\u51faDiscoverLLM\u6846\u67b6\uff0c\u8bad\u7ec3LLM\u5e2e\u52a9\u7528\u6237\u53d1\u73b0\u548c\u5f62\u6210\u610f\u56fe\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u63a2\u7d22\u4e0e\u6536\u655b\u7b56\u7565\uff0c\u5728\u610f\u56fe\u6a21\u7cca\u65f6\u63a2\u7d22\u9009\u9879\uff0c\u660e\u786e\u65f6\u7ec6\u5316\u5b9e\u73b0\u3002", "motivation": "\u5f53\u524dLLM\u5904\u7406\u6a21\u7cca\u8bf7\u6c42\u65f6\u901a\u5e38\u76f4\u63a5\u8be2\u95ee\u7528\u6237\u610f\u56fe\uff0c\u4f46\u5f53\u7528\u6237\u81ea\u5df1\u4e5f\u4e0d\u6e05\u695a\u60f3\u8981\u4ec0\u4e48\u65f6\uff0c\u8fd9\u79cd\u8be2\u95ee\u65b9\u5f0f\u4f1a\u5931\u6548\u3002\u7528\u6237\u9700\u8981\u89c2\u5bdf\u548c\u63a2\u7d22\u7ed3\u679c\u6765\u53d1\u73b0\u81ea\u5df1\u7684\u771f\u5b9e\u610f\u56fe\u3002", "method": "\u63d0\u51faDiscoverLLM\u6846\u67b6\uff0c\u5305\u542b\u65b0\u9896\u7684\u7528\u6237\u6a21\u62df\u5668\uff0c\u7528\u5c42\u6b21\u5316\u610f\u56fe\u5efa\u6a21\u8ba4\u77e5\u72b6\u6001\uff0c\u610f\u56fe\u968f\u6a21\u578b\u5448\u73b0\u76f8\u5173\u9009\u9879\u800c\u9010\u6b65\u5177\u4f53\u5316\u3002\u5177\u4f53\u5316\u7a0b\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u8bad\u7ec3\u6a21\u578b\u4f18\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002\u6a21\u578b\u5b66\u4e60\u81ea\u9002\u5e94\u7b56\u7565\uff1a\u610f\u56fe\u6a21\u7cca\u65f6\u53d1\u6563\u63a2\u7d22\u9009\u9879\uff0c\u610f\u56fe\u5177\u4f53\u5316\u65f6\u6536\u655b\u7ec6\u5316\u5b9e\u73b0\u3002", "result": "\u5728\u521b\u610f\u5199\u4f5c\u3001\u6280\u672f\u5199\u4f5c\u548cSVG\u7ed8\u56fe\u7b49\u4ea4\u4e92\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDiscoverLLM\u5b9e\u73b0\u8d85\u8fc710%\u7684\u4efb\u52a1\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u51cf\u5c11\u9ad8\u8fbe40%\u7684\u5bf9\u8bdd\u957f\u5ea6\u3002\u572875\u4eba\u53c2\u4e0e\u7684\u7528\u6237\u7814\u7a76\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5bf9\u8bdd\u6ee1\u610f\u5ea6\u548c\u6548\u7387\u3002", "conclusion": "DiscoverLLM\u901a\u8fc7\u5e2e\u52a9\u7528\u6237\u53d1\u73b0\u548c\u5f62\u6210\u610f\u56fe\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5904\u7406\u6a21\u7cca\u8bf7\u6c42\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u6ee1\u610f\u7684\u4ea4\u4e92\u4f53\u9a8c\u3002"}}
{"id": "2602.03439", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03439", "abs": "https://arxiv.org/abs/2602.03439", "authors": ["Xiaochi Zhou", "Patrick Bulter", "Changxuan Yang", "Simon D. Rihm", "Thitikarn Angkanaporn", "Jethro Akroyd", "Sebastian Mosbach", "Markus Kraft"], "title": "Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents", "comment": null, "summary": "We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge. Within The World Avatar (TWA), ontological specifications are compiled into executable tool interfaces that LLM-based agents must use to create and modify knowledge graph instances, enforcing semantic constraints during generation rather than through post-hoc validation. Extending TWA's semantic agent composition framework, the Model Context Protocol (MCP) and associated agents are integral components of the knowledge graph ecosystem, enabling structured interaction between generative models, symbolic constraints, and external resources. An agent-based workflow translates ontologies into ontology-aware tools and iteratively applies them to extract, validate, and repair structured knowledge from unstructured scientific text. Using metal-organic polyhedra synthesis literature as an illustrative case, we show how executable ontological semantics can guide LLM behaviour and reduce manual schema and prompt engineering, establishing a general paradigm for embedding formal knowledge into generative systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u672c\u4f53\u8bba\u7f16\u8bd1\u4e3a\u5de5\u5177\u63a5\u53e3\u7684\u673a\u5236\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4e0e\u5f62\u5f0f\u5316\u9886\u57df\u77e5\u8bc6\u7ed3\u5408\uff0c\u901a\u8fc7\u53ef\u6267\u884c\u7684\u672c\u4f53\u8bed\u4e49\u7ea6\u675f\u6307\u5bfcLLM\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\u5b9e\u4f8b\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5f62\u5f0f\u5316\u9886\u57df\u77e5\u8bc6\u7ed3\u5408\u7684\u95ee\u9898\uff0c\u907f\u514d\u540e\u9a8c\u9a8c\u8bc1\uff0c\u901a\u8fc7\u672c\u4f53\u8bed\u4e49\u7ea6\u675f\u76f4\u63a5\u6307\u5bfcLLM\u884c\u4e3a\uff0c\u51cf\u5c11\u624b\u52a8\u6a21\u5f0f\u8bbe\u8ba1\u548c\u63d0\u793a\u5de5\u7a0b\u3002", "method": "\u63d0\u51fa\u672c\u4f53\u5230\u5de5\u5177\u7f16\u8bd1\u673a\u5236\uff0c\u5c06\u672c\u4f53\u89c4\u8303\u7f16\u8bd1\u4e3a\u53ef\u6267\u884c\u5de5\u5177\u63a5\u53e3\uff1b\u6269\u5c55TWA\u7684\u8bed\u4e49\u4ee3\u7406\u7ec4\u5408\u6846\u67b6\uff0c\u4f7f\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u548c\u4ee3\u7406\u5b9e\u73b0\u751f\u6210\u6a21\u578b\u3001\u7b26\u53f7\u7ea6\u675f\u548c\u5916\u90e8\u8d44\u6e90\u7684\u7ed3\u6784\u5316\u4ea4\u4e92\uff1b\u57fa\u4e8e\u4ee3\u7406\u7684\u5de5\u4f5c\u6d41\u7a0b\u5c06\u672c\u4f53\u8f6c\u6362\u4e3a\u672c\u4f53\u611f\u77e5\u5de5\u5177\uff0c\u5e76\u8fed\u4ee3\u5e94\u7528\u4e8e\u4ece\u975e\u7ed3\u6784\u5316\u79d1\u5b66\u6587\u672c\u4e2d\u63d0\u53d6\u3001\u9a8c\u8bc1\u548c\u4fee\u590d\u7ed3\u6784\u5316\u77e5\u8bc6\u3002", "result": "\u4ee5\u91d1\u5c5e\u6709\u673a\u591a\u9762\u4f53\u5408\u6210\u6587\u732e\u4e3a\u4f8b\uff0c\u5c55\u793a\u4e86\u53ef\u6267\u884c\u672c\u4f53\u8bed\u4e49\u5982\u4f55\u6307\u5bfcLLM\u884c\u4e3a\uff0c\u51cf\u5c11\u624b\u52a8\u6a21\u5f0f\u8bbe\u8ba1\u548c\u63d0\u793a\u5de5\u7a0b\uff0c\u5efa\u7acb\u4e86\u5c06\u5f62\u5f0f\u5316\u77e5\u8bc6\u5d4c\u5165\u751f\u6210\u7cfb\u7edf\u7684\u901a\u7528\u8303\u5f0f\u3002", "conclusion": "\u672c\u4f53\u5230\u5de5\u5177\u7f16\u8bd1\u673a\u5236\u4e3a\u8026\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5f62\u5f0f\u5316\u9886\u57df\u77e5\u8bc6\u63d0\u4f9b\u4e86\u539f\u7406\u6027\u8bc1\u660e\uff0c\u901a\u8fc7\u53ef\u6267\u884c\u7684\u672c\u4f53\u8bed\u4e49\u7ea6\u675f\u6307\u5bfcLLM\u751f\u6210\uff0c\u5efa\u7acb\u4e86\u5c06\u5f62\u5f0f\u5316\u77e5\u8bc6\u5d4c\u5165\u751f\u6210\u7cfb\u7edf\u7684\u901a\u7528\u8303\u5f0f\u3002"}}
{"id": "2602.03445", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.03445", "abs": "https://arxiv.org/abs/2602.03445", "authors": ["Qixin Zeng", "Shuo Zhang", "Hongyin Zhang", "Renjie Wang", "Han Zhao", "Libang Zhao", "Runze Li", "Donglin Wang", "Chao Huang"], "title": "CRL-VLA: Continual Vision-Language-Action Learning", "comment": null, "summary": "Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.", "AI": {"tldr": "CRL-VLA\uff1a\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u548c\u53cc\u8bc4\u8bba\u5bb6\u67b6\u6784\u89e3\u51b3VLA\u6a21\u578b\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u6743\u8861\u95ee\u9898", "motivation": "\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\uff0c\u7ec8\u8eab\u5b66\u4e60\u5bf9\u5177\u8eab\u667a\u80fd\u4f53\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5df2\u6210\u4e3aVLA\u6a21\u578b\u638c\u63e1\u7075\u5de7\u64cd\u4f5c\u7684\u91cd\u8981\u8303\u5f0f\uff0c\u4f46\u5728\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u5e73\u8861\u7a33\u5b9a\u6027\uff08\u4fdd\u7559\u65e7\u6280\u80fd\uff09\u548c\u53ef\u5851\u6027\uff08\u5b66\u4e60\u65b0\u6280\u80fd\uff09\u4ecd\u7136\u662f\u73b0\u6709\u65b9\u6cd5\u7684\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faCRL-VLA\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u5c06\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u6743\u8861\u4e0e\u76ee\u6807\u6761\u4ef6\u4f18\u52bf\u5e45\u5ea6\u548c\u7b56\u7565\u6563\u5ea6\u8054\u7cfb\u8d77\u6765\u3002\u91c7\u7528\u975e\u5bf9\u79f0\u8c03\u8282\u673a\u5236\uff1a\u7ea6\u675f\u5148\u524d\u4efb\u52a1\u7684\u4f18\u52bf\u5e45\u5ea6\uff0c\u540c\u65f6\u5141\u8bb8\u65b0\u4efb\u52a1\u4e0a\u7684\u53d7\u63a7\u589e\u957f\u3002\u5b9e\u73b0\u65b9\u5f0f\u662f\u901a\u8fc7\u5177\u6709\u65b0\u9896\u76ee\u6807\u6761\u4ef6\u4ef7\u503c\u516c\u5f0f\u7684\u53cc\u8bc4\u8bba\u5bb6\u67b6\u6784\uff0c\u5176\u4e2d\u51bb\u7ed3\u8bc4\u8bba\u5bb6\u951a\u5b9a\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u53ef\u8bad\u7ec3\u4f30\u8ba1\u5668\u9a71\u52a8\u9002\u5e94\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCRL-VLA\u6709\u6548\u534f\u8c03\u4e86\u8fd9\u4e9b\u51b2\u7a81\u76ee\u6807\uff0c\u5728\u6297\u9057\u5fd8\u548c\u5411\u524d\u9002\u5e94\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CRL-VLA\u4e3aVLA\u6a21\u578b\u7684\u6301\u7eed\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u4e25\u683c\u7406\u8bba\u754c\u9650\u7684\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u4e2d\u7a33\u5b9a\u6027\u4e0e\u53ef\u5851\u6027\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u7ec8\u8eab\u673a\u5668\u4eba\u573a\u666f\u4e2d\u7684VLA\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2602.03467", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.03467", "abs": "https://arxiv.org/abs/2602.03467", "authors": ["Zeynep G. Saribatur", "Johannes Langer", "Ute Schmid"], "title": "The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding", "comment": "8 pages, 5 figures", "summary": "Explanations are central to human cognition, yet AI systems often produce outputs that are difficult to understand. While symbolic AI offers a transparent foundation for interpretability, raw logical traces often impose a high extraneous cognitive load. We investigate how formal abstractions, specifically removal and clustering, impact human reasoning performance and cognitive effort. Utilizing Answer Set Programming (ASP) as a formal framework, we define a notion of irrelevant details to be abstracted over to obtain simplified explanations. Our cognitive experiments, in which participants classified stimuli across domains with explanations derived from an answer set program, show that clustering details significantly improve participants' understanding, while removal of details significantly reduce cognitive effort, supporting the hypothesis that abstraction enhances human-centered symbolic explanations.", "AI": {"tldr": "\u7814\u7a76\u5f62\u5f0f\u5316\u62bd\u8c61\uff08\u79fb\u9664\u548c\u805a\u7c7b\uff09\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u63a8\u7406\u6027\u80fd\u548c\u8ba4\u77e5\u8d1f\u8377\uff0c\u53d1\u73b0\u805a\u7c7b\u63d0\u5347\u7406\u89e3\uff0c\u79fb\u9664\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377", "motivation": "AI\u7cfb\u7edf\u8f93\u51fa\u96be\u4ee5\u7406\u89e3\uff0c\u7b26\u53f7AI\u867d\u900f\u660e\u4f46\u539f\u59cb\u903b\u8f91\u75d5\u8ff9\u5e26\u6765\u9ad8\u8ba4\u77e5\u8d1f\u8377\uff0c\u9700\u8981\u7814\u7a76\u5f62\u5f0f\u5316\u62bd\u8c61\u5982\u4f55\u6539\u5584\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u7b26\u53f7\u89e3\u91ca", "method": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b(ASP)\u4f5c\u4e3a\u5f62\u5f0f\u6846\u67b6\uff0c\u5b9a\u4e49\u53ef\u62bd\u8c61\u7684\u4e0d\u76f8\u5173\u7ec6\u8282\u6982\u5ff5\uff0c\u901a\u8fc7\u8ba4\u77e5\u5b9e\u9a8c\u8ba9\u53c2\u4e0e\u8005\u57fa\u4e8eASP\u7a0b\u5e8f\u751f\u6210\u7684\u89e3\u91ca\u5bf9\u8de8\u9886\u57df\u523a\u6fc0\u8fdb\u884c\u5206\u7c7b", "result": "\u805a\u7c7b\u7ec6\u8282\u663e\u8457\u63d0\u5347\u53c2\u4e0e\u8005\u7406\u89e3\uff0c\u79fb\u9664\u7ec6\u8282\u663e\u8457\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\uff0c\u652f\u6301\u62bd\u8c61\u589e\u5f3a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u7b26\u53f7\u89e3\u91ca\u7684\u5047\u8bbe", "conclusion": "\u5f62\u5f0f\u5316\u62bd\u8c61\uff08\u7279\u522b\u662f\u805a\u7c7b\u548c\u79fb\u9664\uff09\u80fd\u6709\u6548\u63d0\u5347\u7b26\u53f7AI\u89e3\u91ca\u7684\u4eba\u7c7b\u53ef\u7406\u89e3\u6027\uff0c\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\uff0c\u6539\u5584\u4eba\u673a\u4ea4\u4e92"}}
{"id": "2602.03468", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03468", "abs": "https://arxiv.org/abs/2602.03468", "authors": ["Haohao Luo", "Zexi Li", "Yuexiang Xie", "Wenhao Zhang", "Yaliang Li", "Ying Shen"], "title": "IntentRL: Training Proactive User-intent Agents for Open-ended Deep Research via Reinforcement Learning", "comment": "Preprint", "summary": "Deep Research (DR) agents extend Large Language Models (LLMs) beyond parametric knowledge by autonomously retrieving and synthesizing evidence from large web corpora into long-form reports, enabling a long-horizon agentic paradigm. However, unlike real-time conversational assistants, DR is computationally expensive and time-consuming, creating an autonomy-interaction dilemma: high autonomy on ambiguous user queries often leads to prolonged execution with unsatisfactory outcomes. To address this, we propose IntentRL, a framework that trains proactive agents to clarify latent user intents before starting long-horizon research. To overcome the scarcity of open-ended research data, we introduce a scalable pipeline that expands a few seed samples into high-quality dialogue turns via a shallow-to-deep intent refinement graph. We further adopt a two-stage reinforcement learning (RL) strategy: Stage I applies RL on offline dialogues to efficiently learn general user-interaction behavior, while Stage II uses the trained agent and a user simulator for online rollouts to strengthen adaptation to diverse user feedback. Extensive experiments show that IntentRL significantly improves both intent hit rate and downstream task performance, outperforming the built-in clarify modules of closed-source DR agents and proactive LLM baselines.", "AI": {"tldr": "IntentRL\u6846\u67b6\u8bad\u7ec3\u4e3b\u52a8\u4ee3\u7406\u5728\u5f00\u59cb\u957f\u65f6\u7814\u7a76\u524d\u6f84\u6e05\u7528\u6237\u6f5c\u5728\u610f\u56fe\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u610f\u56fe\u547d\u4e2d\u7387\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd", "motivation": "\u6df1\u5ea6\u7814\u7a76(DR)\u4ee3\u7406\u867d\u7136\u80fd\u81ea\u4e3b\u68c0\u7d22\u5408\u6210\u7f51\u7edc\u4fe1\u606f\u751f\u6210\u957f\u7bc7\u62a5\u544a\uff0c\u4f46\u5b58\u5728\u81ea\u4e3b\u6027-\u4ea4\u4e92\u56f0\u5883\uff1a\u5bf9\u6a21\u7cca\u7528\u6237\u67e5\u8be2\u7684\u9ad8\u81ea\u4e3b\u6027\u5e38\u5bfc\u81f4\u6267\u884c\u65f6\u95f4\u957f\u4e14\u7ed3\u679c\u4e0d\u7406\u60f3", "method": "\u63d0\u51faIntentRL\u6846\u67b6\uff1a1) \u901a\u8fc7\u6d45\u5c42\u5230\u6df1\u5c42\u610f\u56fe\u7ec6\u5316\u56fe\u6269\u5c55\u5c11\u91cf\u79cd\u5b50\u6837\u672c\u751f\u6210\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u8f6e\u6b21\uff1b2) \u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728\u79bb\u7ebf\u5bf9\u8bdd\u4e0a\u5b66\u4e60\u901a\u7528\u7528\u6237\u4ea4\u4e92\u884c\u4e3a\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u8bad\u7ec3\u4ee3\u7406\u548c\u7528\u6237\u6a21\u62df\u5668\u8fdb\u884c\u5728\u7ebf\u63a8\u6f14\u4ee5\u589e\u5f3a\u5bf9\u591a\u6837\u5316\u7528\u6237\u53cd\u9988\u7684\u9002\u5e94", "result": "\u5b9e\u9a8c\u8868\u660eIntentRL\u663e\u8457\u63d0\u9ad8\u4e86\u610f\u56fe\u547d\u4e2d\u7387\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff0c\u4f18\u4e8e\u95ed\u6e90DR\u4ee3\u7406\u7684\u5185\u7f6e\u6f84\u6e05\u6a21\u5757\u548c\u4e3b\u52a8LLM\u57fa\u7ebf", "conclusion": "IntentRL\u901a\u8fc7\u8bad\u7ec3\u4e3b\u52a8\u4ee3\u7406\u5728\u957f\u65f6\u7814\u7a76\u524d\u6f84\u6e05\u7528\u6237\u610f\u56fe\uff0c\u6709\u6548\u89e3\u51b3\u4e86DR\u4ee3\u7406\u7684\u81ea\u4e3b\u6027-\u4ea4\u4e92\u56f0\u5883\uff0c\u63d0\u9ad8\u4e86\u7814\u7a76\u6548\u7387\u548c\u7ed3\u679c\u8d28\u91cf"}}
{"id": "2602.03478", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03478", "abs": "https://arxiv.org/abs/2602.03478", "authors": ["Guannan Lai", "Han-Jia Ye"], "title": "When Routing Collapses: On the Degenerate Convergence of LLM Routers", "comment": null, "summary": "LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user's cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEquiRouter\u6765\u89e3\u51b3LLM\u8def\u7531\u4e2d\u7684\"\u8def\u7531\u5d29\u6e83\"\u95ee\u9898\uff0c\u5373\u73b0\u6709\u8def\u7531\u5668\u503e\u5411\u4e8e\u8fc7\u5ea6\u4f7f\u7528\u6602\u8d35\u7684\u5927\u6a21\u578b\u800c\u5ffd\u89c6\u4fbf\u5b9c\u7684\u5c0f\u6a21\u578b\uff0c\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u6a21\u578b\u6392\u540d\u800c\u975e\u6027\u80fd\u5206\u6570\u6765\u4f18\u5316\u6210\u672c-\u6027\u80fd\u6743\u8861\u3002", "motivation": "\u73b0\u6709LLM\u8def\u7531\u7cfb\u7edf\u5b58\u5728\"\u8def\u7531\u5d29\u6e83\"\u95ee\u9898\uff1a\u968f\u7740\u7528\u6237\u6210\u672c\u9884\u7b97\u589e\u52a0\uff0c\u8def\u7531\u5668\u4f1a\u7cfb\u7edf\u6027\u5730\u9ed8\u8ba4\u9009\u62e9\u6700\u5f3a\u5927\u3001\u6700\u6602\u8d35\u7684\u6a21\u578b\uff0c\u5373\u4f7f\u66f4\u4fbf\u5b9c\u7684\u6a21\u578b\u5df2\u7ecf\u8db3\u591f\u3002\u8fd9\u5bfc\u81f4\u5c0f\u6a21\u578b\u5229\u7528\u7387\u4e0d\u8db3\uff0c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u548c\u91d1\u94b1\u6210\u672c\uff0c\u8fdd\u80cc\u4e86\u8def\u7531\u7684\u6838\u5fc3\u627f\u8bfa\u3002", "method": "\u63d0\u51faEquiRouter\uff0c\u4e00\u79cd\u51b3\u7b56\u611f\u77e5\u7684\u8def\u7531\u5668\u3002\u4e0e\u73b0\u6709\u8def\u7531\u5668\u8bad\u7ec3\u9884\u6d4b\u6807\u91cf\u6027\u80fd\u5206\u6570\u4e0d\u540c\uff0cEquiRouter\u76f4\u63a5\u5b66\u4e60\u6a21\u578b\u6392\u540d\uff0c\u4ece\u800c\u51cf\u5c11\u9884\u6d4b\u8bef\u5dee\u5bf9\u76f8\u5bf9\u6392\u5e8f\u7684\u5f71\u54cd\uff0c\u907f\u514d\u6b21\u4f18\u9009\u62e9\u3002", "result": "\u5728RouterBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEquiRouter\u5728\u8fbe\u5230GPT-4\u7ea7\u522b\u6027\u80fd\u65f6\uff0c\u76f8\u6bd4\u5148\u524d\u6700\u5f3a\u7684\u8def\u7531\u5668\u51cf\u5c11\u4e86\u7ea617%\u7684\u6210\u672c\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u8def\u7531\u5d29\u6e83\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u6a21\u578b\u6392\u540d\u800c\u975e\u6027\u80fd\u5206\u6570\uff0cEquiRouter\u80fd\u591f\u66f4\u597d\u5730\u5e73\u8861\u8d28\u91cf\u4e0e\u6210\u672c\uff0c\u6062\u590d\u5c0f\u6a21\u578b\u5728\u8def\u7531\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272\uff0c\u4e3aLLM\u8def\u7531\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03541", "categories": ["cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2602.03541", "abs": "https://arxiv.org/abs/2602.03541", "authors": ["Qiankun Zhong", "Thomas F. Eisenmann", "Julian Garcia", "Iyad Rahwan"], "title": "Group Selection as a Safeguard Against AI Substitution", "comment": "19 pages, 7 Figures", "summary": "Reliance on generative AI can reduce cultural variance and diversity, especially in creative work. This reduction in variance has already led to problems in model performance, including model collapse and hallucination. In this paper, we examine the long-term consequences of AI use for human cultural evolution and the conditions under which widespread AI use may lead to \"cultural collapse\", a process in which reliance on AI-generated content reduces human variation and innovation and slows cumulative cultural evolution. Using an agent-based model and evolutionary game theory, we compare two types of AI use: complement and substitute. AI-complement users seek suggestions and guidance while remaining the main producers of the final output, whereas AI-substitute users provide minimal input, and rely on AI to produce most of the output. We then study how these use strategies compete and spread under evolutionary dynamics. We find that AI-substitute users prevail under individual-level selection despite the stronger reduction in cultural variance. By contrast, AI-complement users can benefit their groups by maintaining the variance needed for exploration, and can therefore be favored under cultural group selection when group boundaries are strong. Overall, our findings shed light on the long-term, population-level effects of AI adoption and inform policy and organizational strategies to mitigate these risks.", "AI": {"tldr": "\u7814\u7a76AI\u4f7f\u7528\u5bf9\u4eba\u7c7b\u6587\u5316\u6f14\u5316\u7684\u957f\u671f\u5f71\u54cd\uff0c\u53d1\u73b0AI\u66ff\u4ee3\u578b\u7528\u6237\u4f1a\u5728\u4e2a\u4f53\u5c42\u9762\u80dc\u51fa\u4f46\u51cf\u5c11\u6587\u5316\u591a\u6837\u6027\uff0c\u800cAI\u4e92\u8865\u578b\u7528\u6237\u80fd\u5728\u7fa4\u4f53\u5c42\u9762\u7ef4\u6301\u6587\u5316\u63a2\u7d22\uff0c\u9700\u8981\u653f\u7b56\u5e72\u9884\u6765\u5e73\u8861", "motivation": "\u751f\u6210\u5f0fAI\u7684\u5e7f\u6cdb\u4f7f\u7528\u53ef\u80fd\u964d\u4f4e\u6587\u5316\u591a\u6837\u6027\u548c\u521b\u65b0\uff0c\u5bfc\u81f4\"\u6587\u5316\u5d29\u6e83\"\u98ce\u9669\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3AI\u4f7f\u7528\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u6587\u5316\u6f14\u5316\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4f9d\u636e", "method": "\u4f7f\u7528\u57fa\u4e8e\u4e3b\u4f53\u7684\u5efa\u6a21\u548c\u6f14\u5316\u535a\u5f08\u8bba\uff0c\u6bd4\u8f83\u4e24\u79cdAI\u4f7f\u7528\u7b56\u7565\uff1a\u4e92\u8865\u578b\uff08AI\u63d0\u4f9b\u5efa\u8bae\uff0c\u4eba\u7c7b\u4e3b\u5bfc\u4ea7\u51fa\uff09\u548c\u66ff\u4ee3\u578b\uff08AI\u4e3b\u5bfc\u4ea7\u51fa\uff0c\u4eba\u7c7b\u8f93\u5165\u6781\u5c11\uff09\u3002\u7814\u7a76\u8fd9\u4e9b\u7b56\u7565\u5728\u6f14\u5316\u52a8\u6001\u4e2d\u7684\u7ade\u4e89\u548c\u4f20\u64ad", "result": "AI\u66ff\u4ee3\u578b\u7528\u6237\u5728\u4e2a\u4f53\u5c42\u9762\u9009\u62e9\u4e2d\u5360\u4f18\u52bf\uff0c\u4f46\u4f1a\u663e\u8457\u964d\u4f4e\u6587\u5316\u591a\u6837\u6027\u3002AI\u4e92\u8865\u578b\u7528\u6237\u80fd\u7ef4\u6301\u7fa4\u4f53\u6240\u9700\u7684\u6587\u5316\u63a2\u7d22\u591a\u6837\u6027\uff0c\u5728\u5f3a\u7fa4\u4f53\u8fb9\u754c\u6761\u4ef6\u4e0b\u53ef\u901a\u8fc7\u6587\u5316\u7fa4\u4f53\u9009\u62e9\u83b7\u5f97\u4f18\u52bf", "conclusion": "AI\u4f7f\u7528\u7b56\u7565\u7684\u6f14\u5316\u52a8\u6001\u53ef\u80fd\u5bfc\u81f4\u6587\u5316\u591a\u6837\u6027\u51cf\u5c11\uff0c\u9700\u8981\u653f\u7b56\u548c\u7ec4\u7ec7\u7b56\u7565\u6765\u5e73\u8861\u4e2a\u4f53\u5229\u76ca\u4e0e\u7fa4\u4f53\u6587\u5316\u5065\u5eb7\uff0c\u4fc3\u8fdbAI\u4e92\u8865\u578b\u4f7f\u7528\u4ee5\u7ef4\u6301\u6587\u5316\u521b\u65b0"}}
{"id": "2602.03545", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03545", "abs": "https://arxiv.org/abs/2602.03545", "authors": ["Davide Paglieri", "Logan Cross", "William A. Cunningham", "Joel Z. Leibo", "Alexander Sasha Vezhnevets"], "title": "Persona Generators: Generating Diverse Synthetic Personas at Scale", "comment": null, "summary": "Evaluating AI systems that interact with humans requires understanding their behavior across diverse user populations, but collecting representative human data is often expensive or infeasible, particularly for novel technologies or hypothetical future scenarios. Recent work in Generative Agent-Based Modeling has shown that large language models can simulate human-like synthetic personas with high fidelity, accurately reproducing the beliefs and behaviors of specific individuals. However, most approaches require detailed data about target populations and often prioritize density matching (replicating what is most probable) rather than support coverage (spanning what is possible), leaving long-tail behaviors underexplored. We introduce Persona Generators, functions that can produce diverse synthetic populations tailored to arbitrary contexts. We apply an iterative improvement loop based on AlphaEvolve, using large language models as mutation operators to refine our Persona Generator code over hundreds of iterations. The optimization process produces lightweight Persona Generators that can automatically expand small descriptions into populations of diverse synthetic personas that maximize coverage of opinions and preferences along relevant diversity axes. We demonstrate that evolved generators substantially outperform existing baselines across six diversity metrics on held-out contexts, producing populations that span rare trait combinations difficult to achieve in standard LLM outputs.", "AI": {"tldr": "\u63d0\u51faPersona Generators\u65b9\u6cd5\uff0c\u901a\u8fc7AlphaEvolve\u8fed\u4ee3\u4f18\u5316\u751f\u6210\u591a\u6837\u5316\u5408\u6210\u4eba\u53e3\uff0c\u89e3\u51b3AI\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u6570\u636e\u6536\u96c6\u56f0\u96be\u7684\u95ee\u9898", "motivation": "\u8bc4\u4f30AI\u7cfb\u7edf\u9700\u8981\u591a\u6837\u5316\u7528\u6237\u6570\u636e\uff0c\u4f46\u6536\u96c6\u4ee3\u8868\u6027\u4eba\u7c7b\u6570\u636e\u6210\u672c\u9ad8\u4e14\u4e0d\u53ef\u884c\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u65b0\u6280\u672f\u6216\u672a\u6765\u573a\u666f\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u8be6\u7ec6\u4eba\u53e3\u6570\u636e\u4e14\u504f\u5411\u5bc6\u5ea6\u5339\u914d\u800c\u975e\u652f\u6301\u8986\u76d6\uff0c\u5bfc\u81f4\u957f\u5c3e\u884c\u4e3a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f15\u5165Persona Generators\u65b9\u6cd5\uff0c\u4f7f\u7528AlphaEvolve\u8fed\u4ee3\u6539\u8fdb\u5faa\u73af\uff0c\u4ee5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u53d8\u5f02\u7b97\u5b50\uff0c\u7ecf\u8fc7\u6570\u767e\u6b21\u8fed\u4ee3\u4f18\u5316Persona Generator\u4ee3\u7801\uff0c\u751f\u6210\u8f7b\u91cf\u7ea7\u751f\u6210\u5668\uff0c\u80fd\u5c06\u7b80\u77ed\u63cf\u8ff0\u6269\u5c55\u4e3a\u591a\u6837\u5316\u7684\u5408\u6210\u4eba\u53e3\u3002", "result": "\u8fdb\u5316\u540e\u7684\u751f\u6210\u5668\u5728\u516d\u4e2a\u591a\u6837\u6027\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u80fd\u751f\u6210\u8986\u76d6\u7f55\u89c1\u7279\u5f81\u7ec4\u5408\u7684\u591a\u6837\u5316\u4eba\u53e3\uff0c\u8fd9\u4e9b\u7ec4\u5408\u5728\u6807\u51c6LLM\u8f93\u51fa\u4e2d\u96be\u4ee5\u5b9e\u73b0\u3002", "conclusion": "Persona Generators\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u591a\u6837\u5316\u7684\u5408\u6210\u4eba\u53e3\uff0c\u89e3\u51b3AI\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u7684\u6570\u636e\u6536\u96c6\u95ee\u9898\uff0c\u7279\u522b\u64c5\u957f\u8986\u76d6\u957f\u5c3e\u884c\u4e3a\u548c\u7f55\u89c1\u7279\u5f81\u7ec4\u5408\u3002"}}
{"id": "2602.03569", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03569", "abs": "https://arxiv.org/abs/2602.03569", "authors": ["Linjie Mu", "Zhongzhen Huang", "Yannian Gu", "Shengqian Qin", "Shaoting Zhang", "Xiaofan Zhang"], "title": "EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories", "comment": null, "summary": "World models offer a principled framework for simulating future states under interventions, but realizing such models in complex, high-stakes domains like medicine remains challenging. Recent large language models (LLMs) have achieved strong performance on static medical reasoning tasks, raising the question of whether they can function as dynamic medical world models capable of simulating disease progression and treatment outcomes over time. In this work, we show that LLMs only incorporating medical knowledge struggle to maintain consistent patient states under sequential interventions, leading to error accumulation in long-horizon clinical simulation. To address this limitation, we introduce EHRWorld, a patient-centric medical world model trained under a causal sequential paradigm, together with EHRWorld-110K, a large-scale longitudinal clinical dataset derived from real-world electronic health records. Extensive evaluations demonstrate that EHRWorld significantly outperforms naive LLM-based baselines, achieving more stable long-horizon simulation, improved modeling of clinically sensitive events, and favorable reasoning efficiency, highlighting the necessity of training on causally grounded, temporally evolving clinical data for reliable and robust medical world modeling.", "AI": {"tldr": "LLMs\u5728\u533b\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4f5c\u4e3a\u52a8\u6001\u533b\u5b66\u4e16\u754c\u6a21\u578b\u6a21\u62df\u75be\u75c5\u8fdb\u5c55\u548c\u6cbb\u7597\u6548\u679c\u65f6\uff0c\u5728\u8fde\u7eed\u5e72\u9884\u4e0b\u96be\u4ee5\u4fdd\u6301\u60a3\u8005\u72b6\u6001\u4e00\u81f4\u6027\uff0c\u5bfc\u81f4\u957f\u671f\u6a21\u62df\u8bef\u5dee\u7d2f\u79ef\u3002\u4f5c\u8005\u63d0\u51faEHRWorld\u6a21\u578b\u548cEHRWorld-110K\u6570\u636e\u96c6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u4e16\u754c\u6a21\u578b\u4e3a\u5e72\u9884\u4e0b\u7684\u672a\u6765\u72b6\u6001\u6a21\u62df\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u4f46\u5728\u533b\u5b66\u7b49\u9ad8\u98ce\u9669\u590d\u6742\u9886\u57df\u5b9e\u73b0\u8fd9\u6837\u7684\u6a21\u578b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u867d\u7136LLMs\u5728\u9759\u6001\u533b\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u80fd\u5426\u4f5c\u4e3a\u52a8\u6001\u533b\u5b66\u4e16\u754c\u6a21\u578b\u6765\u6a21\u62df\u75be\u75c5\u8fdb\u5c55\u548c\u6cbb\u7597\u6548\u679c\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u63d0\u51faEHRWorld\uff0c\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u5e8f\u5217\u8303\u5f0f\u8bad\u7ec3\u7684\u60a3\u8005\u4e2d\u5fc3\u533b\u5b66\u4e16\u754c\u6a21\u578b\uff0c\u540c\u65f6\u6784\u5efa\u4e86EHRWorld-110K\uff0c\u4e00\u4e2a\u4ece\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u63d0\u53d6\u7684\u5927\u89c4\u6a21\u7eb5\u5411\u4e34\u5e8a\u6570\u636e\u96c6\u3002", "result": "EHRWorld\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u7684\u957f\u671f\u6a21\u62df\u3001\u66f4\u597d\u7684\u4e34\u5e8a\u654f\u611f\u4e8b\u4ef6\u5efa\u6a21\uff0c\u4ee5\u53ca\u66f4\u4f18\u7684\u63a8\u7406\u6548\u7387\u3002\u8fd9\u8868\u660e\u57fa\u4e8e\u56e0\u679c\u57fa\u7840\u3001\u65f6\u95f4\u6f14\u5316\u7684\u4e34\u5e8a\u6570\u636e\u8bad\u7ec3\u5bf9\u4e8e\u53ef\u9760\u548c\u9c81\u68d2\u7684\u533b\u5b66\u4e16\u754c\u5efa\u6a21\u662f\u5fc5\u8981\u7684\u3002", "conclusion": "\u4ec5\u4f9d\u8d56\u533b\u5b66\u77e5\u8bc6\u7684LLMs\u96be\u4ee5\u5728\u5e8f\u5217\u5e72\u9884\u4e0b\u4fdd\u6301\u4e00\u81f4\u7684\u75c5\u4eba\u72b6\u6001\uff0c\u5bfc\u81f4\u957f\u671f\u4e34\u5e8a\u6a21\u62df\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u3002\u901a\u8fc7\u56e0\u679c\u5e8f\u5217\u8303\u5f0f\u8bad\u7ec3\u7684\u60a3\u8005\u4e2d\u5fc3\u533b\u5b66\u4e16\u754c\u6a21\u578bEHRWorld\u80fd\u591f\u63d0\u4f9b\u66f4\u53ef\u9760\u548c\u9c81\u68d2\u7684\u533b\u5b66\u4e16\u754c\u5efa\u6a21\u3002"}}
{"id": "2602.03630", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03630", "abs": "https://arxiv.org/abs/2602.03630", "authors": ["I\u00f1aki del Campo", "Pablo Cuervo", "Victor Rodriguez-Fernandez", "Roberto Armellin", "Jack Yarndley"], "title": "Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12", "comment": "Extended version of the paper presented at AIAA SciTech 2026 Forum. Includes futher experiments, corrections and new appendix", "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency in code generation and general reasoning, yet their capacity for autonomous multi-stage planning in high-dimensional, physically constrained environments remains an open research question. This study investigates the limits of current AI agents by evaluating them against the 12th Global Trajectory Optimization Competition (GTOC 12), a complex astrodynamics challenge requiring the design of a large-scale asteroid mining campaign. We adapt the MLE-Bench framework to the domain of orbital mechanics and deploy an AIDE-based agent architecture to autonomously generate and refine mission solutions. To assess performance beyond binary validity, we employ an \"LLM-as-a-Judge\" methodology, utilizing a rubric developed by domain experts to evaluate strategic viability across five structural categories. A comparative analysis of models, ranging from GPT-4-Turbo to reasoning-enhanced architectures like Gemini 2.5 Pro, and o3, reveals a significant trend: the average strategic viability score has nearly doubled in the last two years (rising from 9.3 to 17.2 out of 26). However, we identify a critical capability gap between strategy and execution. While advanced models demonstrate sophisticated conceptual understanding, correctly framing objective functions and mission architectures, they consistently fail at implementation due to physical unit inconsistencies, boundary condition errors, and inefficient debugging loops. We conclude that, while current LLMs often demonstrate sufficient knowledge and intelligence to tackle space science tasks, they remain limited by an implementation barrier, functioning as powerful domain facilitators rather than fully autonomous engineers.", "AI": {"tldr": "LLM\u5728\u590d\u6742\u822a\u5929\u4efb\u52a1\u89c4\u5212\u4e2d\u6218\u7565\u7406\u89e3\u80fd\u529b\u663e\u8457\u63d0\u5347\u4f46\u6267\u884c\u5b9e\u73b0\u5b58\u5728\u4e25\u91cd\u969c\u788d\uff0c\u8868\u73b0\u4e3a\"\u6218\u7565-\u6267\u884c\u9e3f\u6c9f\"\u3002", "motivation": "\u63a2\u7a76LLM\u5728\u7269\u7406\u7ea6\u675f\u73af\u5883\u4e0b\u7684\u81ea\u4e3b\u591a\u9636\u6bb5\u89c4\u5212\u80fd\u529b\u6781\u9650\uff0c\u7279\u522b\u662f\u9488\u5bf9\u9ad8\u7ef4\u590d\u6742\u822a\u5929\u4efb\u52a1\uff08\u5982\u5c0f\u884c\u661f\u91c7\u77ff\uff09\u7684\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528MLE-Bench\u6846\u67b6\u9002\u914d\u8f68\u9053\u529b\u5b66\u9886\u57df\uff0c\u90e8\u7f72AIDE-based\u667a\u80fd\u4f53\u67b6\u6784\u81ea\u4e3b\u751f\u6210\u548c\u4f18\u5316\u4efb\u52a1\u65b9\u6848\uff0c\u4f7f\u7528\"LLM-as-a-Judge\"\u65b9\u6cd5\u7ed3\u5408\u4e13\u5bb6\u5236\u5b9a\u7684\u8bc4\u4f30\u6807\u51c6\u5728\u4e94\u4e2a\u7ed3\u6784\u7c7b\u522b\u4e2d\u8fdb\u884c\u6218\u7565\u53ef\u884c\u6027\u8bc4\u4f30\u3002", "result": "\u8fc7\u53bb\u4e24\u5e74\u5e73\u5747\u6218\u7565\u53ef\u884c\u6027\u5f97\u5206\u4ece9.3\u63d0\u5347\u81f317.2\uff08\u6ee1\u520626\uff09\uff0c\u4f46\u53d1\u73b0\u6218\u7565\u4e0e\u6267\u884c\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u80fd\u529b\u9e3f\u6c9f\uff1a\u5148\u8fdb\u6a21\u578b\u5728\u6982\u5ff5\u7406\u89e3\u548c\u4efb\u52a1\u67b6\u6784\u8bbe\u8ba1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5b9e\u73b0\u9636\u6bb5\u56e0\u7269\u7406\u5355\u4f4d\u4e0d\u4e00\u81f4\u3001\u8fb9\u754c\u6761\u4ef6\u9519\u8bef\u548c\u4f4e\u6548\u8c03\u8bd5\u5faa\u73af\u800c\u5931\u8d25\u3002", "conclusion": "\u5f53\u524dLLM\u5177\u5907\u89e3\u51b3\u7a7a\u95f4\u79d1\u5b66\u4efb\u52a1\u7684\u77e5\u8bc6\u548c\u667a\u80fd\uff0c\u4f46\u53d7\u9650\u4e8e\u5b9e\u73b0\u969c\u788d\uff0c\u53ea\u80fd\u4f5c\u4e3a\u5f3a\u5927\u7684\u9886\u57df\u8f85\u52a9\u5de5\u5177\u800c\u975e\u5b8c\u5168\u81ea\u4e3b\u7684\u5de5\u7a0b\u5e08\u3002"}}
{"id": "2602.03647", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03647", "abs": "https://arxiv.org/abs/2602.03647", "authors": ["Bowei He", "Minda Hu", "Zenan Xu", "Hongru Wang", "Licheng Zong", "Yankai Chen", "Chen Ma", "Xue Liu", "Pluto Zhou", "Irwin King"], "title": "Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration", "comment": null, "summary": "Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a 'cut-and-regenerate' mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy, proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.", "AI": {"tldr": "Search-R2\uff1a\u4e00\u79cd\u901a\u8fc7Actor-Refiner\u534f\u4f5c\u6846\u67b6\u589e\u5f3a\u8bed\u8a00\u4ee3\u7406\u641c\u7d22\u63a8\u7406\u80fd\u529b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5956\u52b1\u548c\u9009\u62e9\u6027\u4fee\u6b63\u673a\u5236\u89e3\u51b3\u591a\u5c3a\u5ea6\u4fe1\u7528\u5206\u914d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u63a8\u7406\u4ee3\u7406\u5b58\u5728\u591a\u5c3a\u5ea6\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u7a00\u758f\u7684\u8f68\u8ff9\u7ea7\u5956\u52b1\u65e0\u6cd5\u533a\u5206\u9ad8\u8d28\u91cf\u63a8\u7406\u548c\u5076\u7136\u731c\u6d4b\uff0c\u5bfc\u81f4\u5197\u4f59\u6216\u8bef\u5bfc\u6027\u641c\u7d22\u884c\u4e3a\u3002", "method": "\u63d0\u51faActor-Refiner\u534f\u4f5c\u6846\u67b6\uff1aActor\u751f\u6210\u521d\u59cb\u63a8\u7406\u8f68\u8ff9\uff0cMeta-Refiner\u901a\u8fc7\"\u526a\u5207-\u518d\u751f\"\u673a\u5236\u9009\u62e9\u6027\u8bca\u65ad\u4fee\u590d\u6709\u7f3a\u9677\u7684\u6b65\u9aa4\u3002\u91c7\u7528\u6df7\u5408\u5956\u52b1\u8bbe\u8ba1\uff0c\u7ed3\u5408\u7ed3\u679c\u6b63\u786e\u6027\u548c\u68c0\u7d22\u8bc1\u636e\u4fe1\u606f\u5bc6\u5ea6\u7684\u5bc6\u96c6\u8fc7\u7a0b\u5956\u52b1\u3002", "result": "\u5728\u591a\u4e2a\u901a\u7528\u548c\u591a\u8df3QA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSearch-R2\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u5747\u4f18\u4e8e\u5f3aRAG\u548c\u57fa\u4e8eRL\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4ee5\u6700\u5c0f\u5f00\u9500\u5b9e\u73b0\u66f4\u4f18\u7684\u63a8\u7406\u51c6\u786e\u6027\u3002", "conclusion": "Search-R2\u901a\u8fc7\u7ec6\u7c92\u5ea6\u76d1\u7763\u548c\u9009\u62e9\u6027\u4fee\u6b63\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u641c\u7d22\u63a8\u7406\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u4e3a\u8bed\u8a00\u4ee3\u7406\u7684\u641c\u7d22\u96c6\u6210\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6\u3002"}}
{"id": "2602.03664", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03664", "abs": "https://arxiv.org/abs/2602.03664", "authors": ["Yang Wan", "Zheng Cao", "Zhenhao Zhang", "Zhengwen Zeng", "Shuheng Shen", "Changhua Meng", "Linchao Zhu"], "title": "Mitigating Conversational Inertia in Multi-Turn Agents", "comment": null, "summary": "Large language models excel as few-shot learners when provided with appropriate demonstrations, yet this strength becomes problematic in multiturn agent scenarios, where LLMs erroneously mimic their own previous responses as few-shot examples. Through attention analysis, we identify conversational inertia, a phenomenon where models exhibit strong diagonal attention to previous responses, which is associated with imitation bias that constrains exploration. This reveals a tension when transforming few-shot LLMs into agents: longer context enriches environmental feedback for exploitation, yet also amplifies conversational inertia that undermines exploration. Our key insight is that for identical states, actions generated with longer contexts exhibit stronger inertia than those with shorter contexts, enabling construction of preference pairs without environment rewards. Based on this, we propose Context Preference Learning to calibrate model preferences to favor low-inertia responses over highinertia ones. We further provide context management strategies at inference time to balance exploration and exploitation. Experimental results across eight agentic environments and one deep research scenario validate that our framework reduces conversational inertia and achieves performance improvements.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLM\u5728\u4ee3\u7406\u573a\u666f\u4e2d\u4f1a\u6a21\u4eff\u81ea\u5df1\u4e4b\u524d\u7684\u56de\u7b54\uff0c\u5f62\u6210\"\u5bf9\u8bdd\u60ef\u6027\"\uff0c\u5bfc\u81f4\u63a2\u7d22\u53d7\u9650\u3002\u4f5c\u8005\u63d0\u51fa\u4e0a\u4e0b\u6587\u504f\u597d\u5b66\u4e60\u6846\u67b6\u6765\u6821\u51c6\u6a21\u578b\u504f\u597d\uff0c\u964d\u4f4e\u60ef\u6027\u5f71\u54cd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5c11\u6837\u672c\u5b66\u4e60\u8005\u5728\u591a\u8f6e\u4ee3\u7406\u573a\u666f\u4e2d\u5b58\u5728\u95ee\u9898\uff1a\u6a21\u578b\u4f1a\u9519\u8bef\u5730\u5c06\u81ea\u5df1\u4e4b\u524d\u7684\u56de\u7b54\u4f5c\u4e3a\u5c11\u6837\u672c\u793a\u4f8b\u8fdb\u884c\u6a21\u4eff\uff0c\u5bfc\u81f4\u63a2\u7d22\u53d7\u9650\u3002\u8fd9\u79cd\"\u5bf9\u8bdd\u60ef\u6027\"\u73b0\u8c61\u9650\u5236\u4e86\u4ee3\u7406\u5728\u73af\u5883\u4e2d\u7684\u6709\u6548\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u6ce8\u610f\u529b\u5206\u6790\u8bc6\u522b\u5bf9\u8bdd\u60ef\u6027\u73b0\u8c61\uff1b\u63d0\u51fa\u4e0a\u4e0b\u6587\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u57fa\u4e8e\"\u76f8\u540c\u72b6\u6001\u4e0b\uff0c\u957f\u4e0a\u4e0b\u6587\u751f\u6210\u7684\u52a8\u4f5c\u6bd4\u77ed\u4e0a\u4e0b\u6587\u5177\u6709\u66f4\u5f3a\u60ef\u6027\"\u7684\u6d1e\u5bdf\uff0c\u6784\u5efa\u65e0\u73af\u5883\u5956\u52b1\u7684\u504f\u597d\u5bf9\uff1b\u63d0\u4f9b\u63a8\u7406\u65f6\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u6765\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5728\u516b\u4e2a\u4ee3\u7406\u73af\u5883\u548c\u6df1\u5ea6\u7814\u7a76\u573a\u666f\u4e2d\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u5bf9\u8bdd\u60ef\u6027\u5e76\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86\u5c06\u5c11\u6837\u672cLLM\u8f6c\u5316\u4e3a\u4ee3\u7406\u65f6\u7684\u5185\u5728\u5f20\u529b\uff1a\u957f\u4e0a\u4e0b\u6587\u65e2\u63d0\u4f9b\u73af\u5883\u53cd\u9988\u53c8\u653e\u5927\u5bf9\u8bdd\u60ef\u6027\u3002\u63d0\u51fa\u7684\u4e0a\u4e0b\u6587\u504f\u597d\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u6821\u51c6\u6a21\u578b\u504f\u597d\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002"}}
{"id": "2602.03688", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03688", "abs": "https://arxiv.org/abs/2602.03688", "authors": ["Wenzhe Fan", "Tommaso Tognoli", "Henry Peng Zou", "Chunyu Miao", "Yibo Wang", "Xinhua Zhang"], "title": "TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System", "comment": null, "summary": "Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic applications where the agents' roles may change \\textit{across rounds} due to dynamic adversary, task progression, or time-varying constraints such as communication bandwidth. In this paper, we propose addressing this issue through TodyComm, a \\textbf{t}ask-\\textbf{o}riented \\textbf{dy}namic \\textbf{comm}unication algorithm. It produces behavior-driven collaboration topologies that adapt to the dynamics at each round, optimizing the utility for the task through policy gradient. Experiments on five benchmarks demonstrate that under both dynamic adversary and communications budgets, TodyComm delivers superior task effectiveness while retaining token efficiency and scalability.", "AI": {"tldr": "TodyComm\uff1a\u4e00\u79cd\u4efb\u52a1\u5bfc\u5411\u7684\u52a8\u6001\u901a\u4fe1\u7b97\u6cd5\uff0c\u7528\u4e8e\u591a\u8f6eLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u6839\u636e\u6bcf\u8f6e\u52a8\u6001\u53d8\u5316\u8c03\u6574\u901a\u4fe1\u62d3\u6251\u7ed3\u6784", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f7f\u7528\u56fa\u5b9a\u901a\u4fe1\u62d3\u6251\uff0c\u65e0\u6cd5\u9002\u5e94\u73b0\u5b9e\u5e94\u7528\u4e2d\u667a\u80fd\u4f53\u89d2\u8272\u53ef\u80fd\u968f\u8f6e\u6b21\u53d8\u5316\u7684\u60c5\u51b5\uff08\u5982\u52a8\u6001\u5bf9\u624b\u3001\u4efb\u52a1\u8fdb\u5c55\u3001\u65f6\u53d8\u901a\u4fe1\u5e26\u5bbd\u9650\u5236\uff09", "method": "\u63d0\u51faTodyComm\u7b97\u6cd5\uff0c\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u4efb\u52a1\u6548\u7528\uff0c\u751f\u6210\u884c\u4e3a\u9a71\u52a8\u7684\u534f\u4f5c\u62d3\u6251\uff0c\u4f7f\u901a\u4fe1\u7ed3\u6784\u80fd\u591f\u9002\u5e94\u6bcf\u8f6e\u7684\u52a8\u6001\u53d8\u5316", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u52a8\u6001\u5bf9\u624b\u548c\u901a\u4fe1\u9884\u7b97\u7ea6\u675f\u4e0b\uff0cTodyComm\u5728\u4efb\u52a1\u6709\u6548\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u540c\u65f6\u4fdd\u6301\u4ee4\u724c\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027", "conclusion": "TodyComm\u89e3\u51b3\u4e86\u591a\u8f6eLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u56fa\u5b9a\u901a\u4fe1\u62d3\u6251\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u901a\u4fe1\u7ed3\u6784\u63d0\u9ad8\u4e86\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd"}}
{"id": "2602.03786", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03786", "abs": "https://arxiv.org/abs/2602.03786", "authors": ["Jianhao Ruan", "Zhihao Xu", "Yiran Peng", "Fashen Ren", "Zhaoyang Yu", "Xinbing Liang", "Jinyu Xiang", "Bang Liu", "Chenglin Wu", "Yuyu Luo", "Jiayi Zhang"], "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration", "comment": null, "summary": "Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra", "AI": {"tldr": "AOrchestra\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u6846\u67b6\u65e0\u5173\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u62bd\u8c61\u4e3a(\u6307\u4ee4\u3001\u4e0a\u4e0b\u6587\u3001\u5de5\u5177\u3001\u6a21\u578b)\u56db\u5143\u7ec4\uff0c\u5b9e\u73b0\u6309\u9700\u52a8\u6001\u521b\u5efa\u4e13\u7528\u6267\u884c\u5668\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u667a\u80fd\u4f53\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u5b50\u667a\u80fd\u4f53\u7684\u52a8\u6001\u62bd\u8c61\u89c6\u56fe\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u548c\u7075\u6d3b\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u590d\u6742\u3001\u957f\u89c6\u91ce\u4efb\u52a1\u7684\u81ea\u52a8\u5316\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u7ec4\u5408\u80fd\u529b\u7684\u7edf\u4e00\u62bd\u8c61\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u667a\u80fd\u4f53\u62bd\u8c61\uff1a\u5c06\u4efb\u4f55\u667a\u80fd\u4f53\u5efa\u6a21\u4e3a(\u6307\u4ee4\u3001\u4e0a\u4e0b\u6587\u3001\u5de5\u5177\u3001\u6a21\u578b)\u56db\u5143\u7ec4\u3002\u57fa\u4e8e\u6b64\u6784\u5efaAOrchestra\u7cfb\u7edf\uff0c\u5176\u4e2d\u4e2d\u592e\u7f16\u6392\u5668\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\u5177\u4f53\u5316\u8fd9\u4e2a\u56db\u5143\u7ec4\uff1a\u7b56\u5212\u4efb\u52a1\u76f8\u5173\u4e0a\u4e0b\u6587\u3001\u9009\u62e9\u5de5\u5177\u548c\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5373\u65f6\u81ea\u52a8\u521b\u5efa\u667a\u80fd\u4f53\u6765\u59d4\u6258\u6267\u884c\u3002", "result": "\u5728\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5(GAIA\u3001SWE-Bench\u3001Terminal-Bench)\u4e2d\uff0cAOrchestra\u4e0eGemini-3-Flash\u914d\u5bf9\u65f6\uff0c\u76f8\u5bf9\u4e8e\u6700\u5f3a\u57fa\u7ebf\u5b9e\u73b0\u4e8616.28%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002\u7cfb\u7edf\u8fd8\u5b9e\u73b0\u4e86\u53ef\u63a7\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\uff0c\u80fd\u591f\u63a5\u8fd1\u5e15\u7d2f\u6258\u6548\u7387\u3002", "conclusion": "AOrchestra\u901a\u8fc7\u7edf\u4e00\u7684\u667a\u80fd\u4f53\u62bd\u8c61\u548c\u52a8\u6001\u7f16\u6392\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u7a0b\u5de5\u4f5c\u91cf\uff0c\u5e76\u4fdd\u6301\u6846\u67b6\u65e0\u5173\u6027\u3002"}}
{"id": "2602.03794", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03794", "abs": "https://arxiv.org/abs/2602.03794", "authors": ["Yingxuan Yang", "Chengrui Qu", "Muning Wen", "Laixi Shi", "Ying Wen", "Weinan Zhang", "Adam Wierman", "Shangding Gu"], "title": "Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity", "comment": null, "summary": "LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u53d7\u9650\u4e8e\u4efb\u52a1\u5185\u5728\u4e0d\u786e\u5b9a\u6027\u800c\u975e\u667a\u80fd\u4f53\u6570\u91cf\uff0c\u5f02\u6784\u667a\u80fd\u4f53\u901a\u8fc7\u63d0\u4f9b\u4e92\u8865\u4fe1\u606f\u6bd4\u540c\u6784\u667a\u80fd\u4f53\u6269\u5c55\u66f4\u6709\u6548", "motivation": "\u7814\u7a76LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u6269\u5c55\u7684\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u589e\u52a0\u540c\u6784\u667a\u80fd\u4f53\u6570\u91cf\u6536\u76ca\u9012\u51cf\uff0c\u800c\u5f02\u6784\u667a\u80fd\u4f53\u5374\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u9700\u8981\u7406\u89e3\u8fd9\u79cd\u5dee\u5f02\u7684\u6839\u672c\u539f\u56e0", "method": "\u63d0\u51fa\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u6790MAS\u6027\u80fd\u8fb9\u754c\uff0c\u5f15\u5165K*\u6307\u6807\u91cf\u5316\u6709\u6548\u901a\u9053\u6570\u91cf\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5f02\u6784\u914d\u7f6e\u4f18\u4e8e\u540c\u6784\u6269\u5c55", "result": "\u5f02\u6784\u914d\u7f6e\u663e\u8457\u4f18\u4e8e\u540c\u6784\u6269\u5c55\uff1a2\u4e2a\u5f02\u6784\u667a\u80fd\u4f53\u6027\u80fd\u53ef\u5339\u914d\u6216\u8d85\u8fc716\u4e2a\u540c\u6784\u667a\u80fd\u4f53\uff0cK*\u6307\u6807\u80fd\u6709\u6548\u91cf\u5316\u7cfb\u7edf\u4fe1\u606f\u83b7\u53d6\u80fd\u529b", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u5e94\u6ce8\u91cd\u591a\u6837\u6027\u800c\u975e\u7b80\u5355\u589e\u52a0\u540c\u6784\u667a\u80fd\u4f53\u6570\u91cf\uff0c\u901a\u8fc7\u5f02\u6784\u8bbe\u8ba1\u6784\u5efa\u9ad8\u6548\u9c81\u68d2\u7684MAS\u7cfb\u7edf"}}
{"id": "2602.03814", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03814", "abs": "https://arxiv.org/abs/2602.03814", "authors": ["Xi Wang", "Anushri Suresh", "Alvin Zhang", "Rishi More", "William Jurayj", "Benjamin Van Durme", "Mehrdad Farajtabar", "Daniel Khashabi", "Eric Nalisnick"], "title": "Conformal Thinking: Risk Control for Reasoning on a Compute Budget", "comment": null, "summary": "Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u98ce\u9669\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u9608\u503c\u81ea\u9002\u5e94\u63a7\u5236LLM\u63a8\u7406\u8ba1\u7b97\u91cf\uff0c\u5728\u4fdd\u8bc1\u9519\u8bef\u7387\u4e0d\u8d85\u76ee\u6807\u7684\u524d\u63d0\u4e0b\u6700\u5c0f\u5316\u8ba1\u7b97\u5f00\u9500", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4e0e\u51c6\u786e\u7387\u7684\u6743\u8861\uff0c\u4f20\u7edf\u56fa\u5b9atoken\u9884\u7b97\u6216\u81ea\u9002\u5e94\u9608\u503c\u8bbe\u7f6e\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u98ce\u9669\u63a7\u5236\u65b9\u6cd5", "method": "\u63d0\u51fa\u53cc\u9608\u503c\u505c\u6b62\u673a\u5236\uff1a\u4e0a\u9608\u503c\u5728\u6a21\u578b\u7f6e\u4fe1\u65f6\u505c\u6b62\uff08\u98ce\u9669\u9519\u8bef\u8f93\u51fa\uff09\uff0c\u53c2\u6570\u5316\u4e0b\u9608\u503c\u63d0\u524d\u505c\u6b62\u4e0d\u53ef\u89e3\u5b9e\u4f8b\uff08\u98ce\u9669\u8fc7\u65e9\u505c\u6b62\uff09\u3002\u4f7f\u7528\u65e0\u5206\u5e03\u98ce\u9669\u63a7\u5236\u65b9\u6cd5\uff0c\u7ed3\u5408\u6548\u7387\u635f\u5931\u9009\u62e9\u6700\u4f18\u9000\u51fa\u673a\u5236", "result": "\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u98ce\u9669\u63a7\u5236\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e0b\u9608\u503c\u548c\u96c6\u6210\u505c\u6b62\u673a\u5236\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u7528\u6237\u6307\u5b9a\u7684\u98ce\u9669\u76ee\u6807", "conclusion": "\u5c06\u9884\u7b97\u8bbe\u7f6e\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u98ce\u9669\u63a7\u5236\u95ee\u9898\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u7684\u8ba1\u7b97\u6548\u7387\u4f18\u5316\u6846\u67b6\uff0c\u4e3a\u81ea\u9002\u5e94\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u98ce\u9669\u63a7\u5236\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.03828", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.03828", "abs": "https://arxiv.org/abs/2602.03828", "authors": ["Minjun Zhu", "Zhen Lin", "Yixuan Weng", "Panzhong Lu", "Qiujie Xie", "Yifan Wei", "Sifan Liu", "Qiyao Sun", "Yue Zhang"], "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations", "comment": "Accepted at the ICLR 2026", "summary": "High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.", "AI": {"tldr": "FigureBench\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u79d1\u5b66\u63d2\u56fe\u751f\u6210\u57fa\u51c6\uff0c\u5305\u542b3300\u4e2a\u9ad8\u8d28\u91cf\u6587\u672c-\u63d2\u56fe\u5bf9\uff1bAutoFigure\u662f\u9996\u4e2a\u57fa\u4e8e\u957f\u6587\u672c\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u79d1\u5b66\u63d2\u56fe\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u601d\u8003\u3001\u91cd\u7ec4\u548c\u9a8c\u8bc1\u5b9e\u73b0\u7ed3\u6784\u5b8c\u6574\u4e14\u7f8e\u89c2\u7684\u63d2\u56fe\u3002", "motivation": "\u9ad8\u8d28\u91cf\u79d1\u5b66\u63d2\u56fe\u5bf9\u4e8e\u6709\u6548\u4f20\u8fbe\u590d\u6742\u79d1\u6280\u6982\u5ff5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u521b\u5efa\u63d2\u56fe\u5728\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u90fd\u662f\u516c\u8ba4\u7684\u74f6\u9888\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u5347\u6548\u7387\u3002", "method": "\u63d0\u51faFigureBench\u57fa\u51c6\u6570\u636e\u96c6\uff083300\u4e2a\u9ad8\u8d28\u91cf\u6587\u672c-\u63d2\u56fe\u5bf9\uff09\uff0c\u5e76\u5f00\u53d1AutoFigure\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u6700\u7ec8\u6e32\u67d3\u524d\u8fdb\u884c\u5e7f\u6cdb\u601d\u8003\u3001\u91cd\u7ec4\u548c\u9a8c\u8bc1\uff0c\u786e\u4fdd\u63d2\u56fe\u7684\u5b8c\u6574\u7ed3\u6784\u548c\u7f8e\u5b66\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAutoFigure\u5728\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u80fd\u591f\u751f\u6210\u53ef\u76f4\u63a5\u7528\u4e8e\u51fa\u7248\u7684\u9ad8\u8d28\u91cf\u79d1\u5b66\u63d2\u56fe\u3002\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548cHuggingFace\u7a7a\u95f4\u5df2\u5f00\u6e90\u3002", "conclusion": "FigureBench\u4e3a\u79d1\u5b66\u63d2\u56fe\u751f\u6210\u63d0\u4f9b\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\uff0cAutoFigure\u6846\u67b6\u901a\u8fc7\u667a\u80fd\u4f53\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u79d1\u5b66\u63d2\u56fe\u81ea\u52a8\u751f\u6210\u7684\u6311\u6218\uff0c\u4e3a\u79d1\u5b66\u53ef\u89c6\u5316\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
