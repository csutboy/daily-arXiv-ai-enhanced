<div id=toc></div>

# Table of Contents

- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.AI](#cs.AI) [Total: 51]
- [econ.EM](#econ.EM) [Total: 1]
- [cs.CY](#cs.CY) [Total: 9]
- [stat.AP](#stat.AP) [Total: 6]
- [econ.GN](#econ.GN) [Total: 4]
- [cs.SI](#cs.SI) [Total: 1]
- [econ.TH](#econ.TH) [Total: 2]
- [eess.SY](#eess.SY) [Total: 17]
- [cs.RO](#cs.RO) [Total: 41]
- [cs.ET](#cs.ET) [Total: 1]


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [1] [Financial Stability Implications of Generative AI: Taming the Animal Spirits](https://arxiv.org/abs/2510.01451)
*Anne Lundgaard Hansen,Seung Jung Lee*

Main category: q-fin.GN

TL;DR: 研究生成式AI对金融稳定的影响，通过实验发现AI代理比人类更理性，主要依赖私有信息而非市场趋势，可能减少资产泡沫，但AI也会在特定条件下出现最优从众行为并继承人类偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在金融交易决策中的应用对金融稳定性的潜在影响，特别是AI是否会像人类一样出现从众行为。

Method: 使用大型语言模型进行实验室风格的实验，复制经典的交易决策从众行为研究，并在不同实验设置下测试AI代理的行为。

Result: AI代理比人类更理性，主要依赖私有信息；在特定指导下会出现最优从众行为；AI继承了人类的条件反射和偏见。

Conclusion: AI交易建议可能减少资产泡沫，但AI的从众行为和继承的人类偏见仍对金融稳定有潜在影响。

Abstract: This paper investigates the impact of the adoption of generative AI on
financial stability. We conduct laboratory-style experiments using large
language models to replicate classic studies on herd behavior in trading
decisions. Our results show that AI agents make more rational decisions than
humans, relying predominantly on private information over market trends.
Increased reliance on AI-powered trading advice could therefore potentially
lead to fewer asset price bubbles arising from animal spirits that trade by
following the herd. However, exploring variations in the experimental settings
reveals that AI agents can be induced to herd optimally when explicitly guided
to make profit-maximizing decisions. While optimal herding improves market
discipline, this behavior still carries potential implications for financial
stability. In other experimental variations, we show that AI agents are not
purely algorithmic, but have inherited some elements of human conditioning and
bias.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Zero-shot reasoning for simulating scholarly peer-review](https://arxiv.org/abs/2510.02027)
*Khalid M. Saqr*

Main category: cs.AI

TL;DR: 提出了一个确定性模拟框架，为评估AI生成的同行评审报告提供首个稳定、基于证据的标准，通过分析352份模拟报告验证了系统的可靠性和可预测性。


<details>
  <summary>Details</summary>
Motivation: 学术出版生态系统面临提交量不可管理和AI不受监管的双重危机，需要新的治理模式来保护科学完整性。传统纯人工同行评审缺乏可扩展的客观基准。

Method: 采用确定性模拟框架，分析352份同行评审模拟报告，识别一致的系统状态指标来评估可靠性。

Result: 系统能够模拟校准的编辑判断，'修订'决策始终占多数(>50%)，'拒绝'率动态适应领域规范；保持程序完整性，证据锚定合规率稳定在29%。

Conclusion: 该框架将AI重新定位为机构问责的重要组成部分，为维护学术交流信任提供关键基础设施，为科学界提供确保公平的透明工具，为出版策略师提供可扩展的审计工具。

Abstract: The scholarly publishing ecosystem faces a dual crisis of unmanageable
submission volumes and unregulated AI, creating an urgent need for new
governance models to safeguard scientific integrity. The traditional human-only
peer review regime lacks a scalable, objective benchmark, making editorial
processes opaque and difficult to audit. Here we investigate a deterministic
simulation framework that provides the first stable, evidence-based standard
for evaluating AI-generated peer review reports. Analyzing 352 peer-review
simulation reports, we identify consistent system state indicators that
demonstrate its reliability. First, the system is able to simulate calibrated
editorial judgment, with 'Revise' decisions consistently forming the majority
outcome (>50%) across all disciplines, while 'Reject' rates dynamically adapt
to field-specific norms, rising to 45% in Health Sciences. Second, it maintains
unwavering procedural integrity, enforcing a stable 29% evidence-anchoring
compliance rate that remains invariant across diverse review tasks and
scientific domains. These findings demonstrate a system that is predictably
rule-bound, mitigating the stochasticity of generative AI. For the scientific
community, this provides a transparent tool to ensure fairness; for publishing
strategists, it offers a scalable instrument for auditing workflows, managing
integrity risks, and implementing evidence-based governance. The framework
repositions AI as an essential component of institutional accountability,
providing the critical infrastructure to maintain trust in scholarly
communication.

</details>


### [3] [OR-Toolformer: Modeling and Solving Operations Research Problems with Tool Augmented Large Language Models](https://arxiv.org/abs/2510.01253)
*Jianzhang Zhang,Jialong Zhou,Chuang Liu*

Main category: cs.AI

TL;DR: OR-Toolformer通过微调Llama-3.1-8B-Instruct模型，结合半自动数据合成管道和外部求解器增强，在运筹学问题上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在运筹学任务中依赖闭源API带来的隐私问题，以及从头训练开源模型的高计算成本问题。

Method: 使用半自动数据合成管道生成多样化的运筹学问题-答案对，通过微调Llama-3.1-8B-Instruct模型，并增强模型使用外部求解器生成API调用的能力。

Result: 在四个标准基准测试中的三个上，OR-Toolformer达到80.1%的执行准确率，比同规模基线高出4.3%以上；在两种未见过的运筹学问题类型上，零样本评估获得54%的平均准确率，比最强基线提高21个百分点。

Conclusion: 工具增强的微调方法对于准确且可泛化的运筹学问题建模和求解具有有效性。

Abstract: Large language models (LLMs) demonstrate strong mathematical reasoning, but
reliance on closed-source APIs for OR tasks raises privacy concerns, and
training open-source models from scratch incurs high compute costs. We
introduce OR-Toolformer, which fine-tunes Llama-3.1-8B-Instruct with a
semi-automatic data synthesis pipeline that generates diverse OR problem-answer
pairs and augments the model with external solvers to produce API calls. On
three of four standard benchmarks, OR-Toolformer achieves up to 80.1% execution
accuracy, exceeding size-matched baselines by over 4.3%. In zero-shot
evaluation on two unseen OR problem types, it attains 54% average accuracy, a
21 percentage-point improvement over the strongest baseline. These findings
validate the efficacy of tool-augmented fine-tuning LLMs for accurate and
generalizable OR problem modeling and solving.

</details>


### [4] [Modeling Others' Minds as Code](https://arxiv.org/abs/2510.01272)
*Kunal Jha,Aydan Yuenan Huang,Eric Ye,Natasha Jaques,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: ROTE算法通过将人类行为建模为行为程序，结合大语言模型生成假设空间和概率推理处理不确定性，显著提升了人类行为预测的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的人类行为建模方法要么对理性做出不切实际的假设，要么计算量过大难以快速适应。日常社交互动往往遵循可预测的认知简化模式，这为高效行为预测提供了机会。

Method: 将日常行为建模为行为程序（计算机代码形式），而非基于信念和欲望的策略。使用大语言模型生成行为程序的假设空间，结合概率推理处理不确定性。

Result: 在网格世界任务和大规模家庭模拟器中，ROTE从稀疏观察中预测人类和AI行为，比行为克隆和基于LLM的方法在样本内准确性和样本外泛化能力上提升高达50%。

Conclusion: 将动作理解视为程序合成问题，ROTE为AI系统在现实世界中高效有效预测人类行为开辟了新路径。

Abstract: Accurate prediction of human behavior is essential for robust and safe
human-AI collaboration. However, existing approaches for modeling people are
often data-hungry and brittle because they either make unrealistic assumptions
about rationality or are too computationally demanding to adapt rapidly. Our
key insight is that many everyday social interactions may follow predictable
patterns; efficient "scripts" that minimize cognitive load for actors and
observers, e.g., "wait for the green light, then go." We propose modeling these
routines as behavioral programs instantiated in computer code rather than
policies conditioned on beliefs and desires. We introduce ROTE, a novel
algorithm that leverages both large language models (LLMs) for synthesizing a
hypothesis space of behavioral programs, and probabilistic inference for
reasoning about uncertainty over that space. We test ROTE in a suite of
gridworld tasks and a large-scale embodied household simulator. ROTE predicts
human and AI behaviors from sparse observations, outperforming competitive
baselines -- including behavior cloning and LLM-based methods -- by as much as
50% in terms of in-sample accuracy and out-of-sample generalization. By
treating action understanding as a program synthesis problem, ROTE opens a path
for AI systems to efficiently and effectively predict human behavior in the
real-world.

</details>


### [5] [Cyber Academia-Chemical Engineering (CA-ChemE): A Living Digital Town for Self-Directed Research Evolution and Emergent Scientific Discovery](https://arxiv.org/abs/2510.01293)
*Zekun Jiang,Chunming Xu,Tianhang Zhou*

Main category: cs.AI

TL;DR: 提出了CA-ChemE系统，一个通过多智能体协作实现自主研究进化和科学发现的生命数字城镇，解决了AI在化学工程中跨学科合作和未知问题探索的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统在化学工程中跨学科合作和探索未知问题方面存在局限，需要构建能够自主进化和发现新知识的智能生态系统。

Method: 集成领域特定知识库、知识增强技术和协作智能体，构建CA-ChemE系统，通过多智能体协作实现自主研究进化。

Result: 知识库增强机制使7个专家智能体的对话质量评分平均提高10-15%；协作智能体的介入使远域专家对的协作效率提升8.5%，而邻近域对仅提升0.8%，揭示了知识库差距导致的协作效率递减效应。

Conclusion: 精心设计的多智能体架构为化学工程中的自主科学发现提供了可行路径。

Abstract: The rapid advancement of artificial intelligence (AI) has demonstrated
substantial potential in chemical engineering, yet existing AI systems remain
limited in interdisciplinary collaboration and exploration of uncharted
problems. To address these issues, we present the Cyber Academia-Chemical
Engineering (CA-ChemE) system, a living digital town that enables self-directed
research evolution and emergent scientific discovery through multi-agent
collaboration. By integrating domain-specific knowledge bases, knowledge
enhancement technologies, and collaboration agents, the system successfully
constructs an intelligent ecosystem capable of deep professional reasoning and
efficient interdisciplinary collaboration. Our findings demonstrate that
knowledge base-enabled enhancement mechanisms improved dialogue quality scores
by 10-15% on average across all seven expert agents, fundamentally ensuring
technical judgments are grounded in verifiable scientific evidence. However, we
observed a critical bottleneck in cross-domain collaboration efficiency,
prompting the introduction of a Collaboration Agent (CA) equipped with ontology
engineering capabilities. CA's intervention achieved 8.5% improvements for
distant-domain expert pairs compared to only 0.8% for domain-proximate pairs -
a 10.6-fold difference - unveiling the "diminished collaborative efficiency
caused by knowledge-base gaps" effect. This study demonstrates how carefully
designed multi-agent architectures can provide a viable pathway toward
autonomous scientific discovery in chemical engineering.

</details>


### [6] [The Social Laboratory: A Psychometric Framework for Multi-Agent LLM Evaluation](https://arxiv.org/abs/2510.01295)
*Zarreen Reza*

Main category: cs.AI

TL;DR: 提出了一个基于多智能体辩论的新型评估框架，用于量化LLM智能体在交互环境中涌现的社会和认知行为。


<details>
  <summary>Details</summary>
Motivation: 传统评估基准无法捕捉智能体在交互环境中沟通、说服和协作时涌现的社会和认知动态，需要新的评估方法。

Method: 使用多智能体辩论作为受控"社会实验室"，让具有不同角色和激励的LLM智能体在LLM主持人的监督下就各种挑战性话题进行辩论，并采用新的心理测量和语义指标进行分析。

Result: 发现智能体具有强烈的共识寻求倾向，即使没有明确指令也能达到高语义一致性；分配的角色能诱导稳定的心理测量特征；主持人的角色能显著改变辩论结果。

Conclusion: 这项工作为面向智能体环境的新型动态、基于心理测量的评估协议提供了蓝图，为理解和塑造下一代AI智能体的社会行为提供了关键方法。

Abstract: As Large Language Models (LLMs) transition from static tools to autonomous
agents, traditional evaluation benchmarks that measure performance on
downstream tasks are becoming insufficient. These methods fail to capture the
emergent social and cognitive dynamics that arise when agents communicate,
persuade, and collaborate in interactive environments. To address this gap, we
introduce a novel evaluation framework that uses multi-agent debate as a
controlled "social laboratory" to discover and quantify these behaviors. In our
framework, LLM-based agents, instantiated with distinct personas and
incentives, deliberate on a wide range of challenging topics under the
supervision of an LLM moderator. Our analysis, enabled by a new suite of
psychometric and semantic metrics, reveals several key findings. Across
hundreds of debates, we uncover a powerful and robust emergent tendency for
agents to seek consensus, consistently reaching high semantic agreement ({\mu}
> 0.88) even without explicit instruction and across sensitive topics. We show
that assigned personas induce stable, measurable psychometric profiles,
particularly in cognitive effort, and that the moderators persona can
significantly alter debate outcomes by structuring the environment, a key
finding for external AI alignment. This work provides a blueprint for a new
class of dynamic, psychometrically grounded evaluation protocols designed for
the agentic setting, offering a crucial methodology for understanding and
shaping the social behaviors of the next generation of AI agents. We have
released the code and results at
https://github.com/znreza/multi-agent-LLM-eval-for-debate.

</details>


### [7] [Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.01304)
*Yu Zeng,Wenxuan Huang,Shiting Huang,Xikun Bao,Yukun Qi,Yiming Zhao,Qiuchen Wang,Lin Chen,Zehui Chen,Huaian Chen,Wanli Ouyang,Feng Zhao*

Main category: cs.AI

TL;DR: AGILE通过将拼图任务制定为交互式学习过程，使用代码执行与环境反馈来增强视觉语言模型的感知和推理能力，显著提升了拼图任务性能并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型视觉语言模型在多模态理解和推理方面虽有进步，但在基本感知和推理能力上仍有局限，特别是在简单拼图任务上表现接近随机，高质量视觉语言数据的稀缺性也限制了能力提升。

Method: AGILE将拼图解决制定为交互过程，模型在每个步骤生成可执行代码来执行动作，环境提供细粒度视觉反馈来指导任务完成，通过观察和交互的迭代循环来逐步提升能力。

Result: AGILE显著提升了不同复杂度拼图任务的性能（如2×2设置下准确率从9.5%提升至82.8%），并在9个通用视觉任务上表现出强泛化能力，平均提升3.1%。

Conclusion: 这项工作为推进多模态模型的推理和泛化能力开辟了新途径，并为多模态强化学习数据稀缺问题提供了高效、可扩展的解决方案。

Abstract: Although current large Vision-Language Models (VLMs) have advanced in
multimodal understanding and reasoning, their fundamental perceptual and
reasoning abilities remain limited. Specifically, even on simple jigsaw tasks,
existing VLMs perform near randomly, revealing deficiencies in core perception
and reasoning capabilities. While high-quality vision-language data can enhance
these capabilities, its scarcity and limited scalability impose significant
constraints. To address this, we propose AGILE, an Agentic jiGsaw Interaction
Learning for Enhancing visual perception and reasoning in VLMs. AGILE
formulates jigsaw solving as an interactive process, enabling the model to
progressively engage with the environment. At each step, the model generates
executable code to perform an action based on the current state, while the
environment provides fine-grained visual feedback to guide task completion.
Through this iterative cycle of observation and interaction, the model
incrementally improves its perceptual and reasoning capabilities via
exploration and feedback. Experimental results show that AGILE not only
substantially boosts performance on jigsaw tasks of varying complexity (e.g.,
increasing accuracy from 9.5% to 82.8% under the 2 $\times$ 2 setting) but also
demonstrates strong generalization across 9 general vision tasks, achieving an
average improvement of 3.1%. These results indicate notable enhancements in
both perceptual and reasoning abilities. This work opens a new avenue for
advancing reasoning and generalization in multimodal models and provides an
efficient, scalable solution to the scarcity of multimodal reinforcement
learning data. The code and datasets is available at
https://github.com/yuzeng0-0/AGILE .

</details>


### [8] [Aristotle: IMO-level Automated Theorem Proving](https://arxiv.org/abs/2510.01346)
*Tudor Achim,Alex Best,Kevin Der,Mathïs Fédérico,Sergei Gukov,Daniel Halpern-Leister,Kirsten Henningsgard,Yury Kudryashov,Alexander Meiburg,Martin Michelsen,Riley Patterson,Eric Rodriguez,Laura Scharff,Vikram Shanker,Vladmir Sicca,Hari Sowrirajan,Aidan Swope,Matyas Tamas,Vlad Tenev,Jonathan Thomm,Harold Williams,Lawrence Wu*

Main category: cs.AI

TL;DR: Aristotle系统将形式验证与非正式推理相结合，在2025年国际数学奥林匹克竞赛中达到金牌级别表现。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够结合形式验证和非正式推理的AI系统，以解决复杂的数学问题，特别是国际数学奥林匹克竞赛级别的难题。

Method: 集成三个主要组件：Lean证明搜索系统、生成并形式化引理的非正式推理系统，以及专用的几何求解器。

Result: 在2025年国际数学奥林匹克竞赛问题上达到金牌级别表现，展示了自动定理证明领域的最先进性能。

Conclusion: Aristotle系统通过结合形式验证和非正式推理，在复杂数学问题求解方面取得了突破性进展，具有良好的扩展性能。

Abstract: We introduce Aristotle, an AI system that combines formal verification with
informal reasoning, achieving gold-medal-equivalent performance on the 2025
International Mathematical Olympiad problems. Aristotle integrates three main
components: a Lean proof search system, an informal reasoning system that
generates and formalizes lemmas, and a dedicated geometry solver. Our system
demonstrates state-of-the-art performance with favorable scaling properties for
automated theorem proving.

</details>


### [9] [MEMTRACK: Evaluating Long-Term Memory and State Tracking in Multi-Platform Dynamic Agent Environments](https://arxiv.org/abs/2510.01353)
*Darshan Deshpande,Varun Gangal,Hersh Mehta,Anand Kannappan,Rebecca Qian,Peng Wang*

Main category: cs.AI

TL;DR: MEMTRACK是一个评估多平台代理环境中长期记忆和状态跟踪的基准测试，专注于企业环境中的动态记忆评估，超越了传统的对话式记忆测试。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文和记忆基准测试主要关注对话实例，但企业动态环境中记忆评估的需求对于其有效应用至关重要。

Method: 通过集成Slack、Linear和Git等多个通信和生产力平台的异步事件来模拟现实组织工作流程，使用专家驱动设计和基于代理的合成方法构建数据集。

Result: 实验显示，即使是表现最好的GPT-5模型在MEMTRACK上仅达到60%的正确性分数，表明在长时程记忆利用、跨平台依赖处理和矛盾解决方面存在挑战。

Conclusion: 这项工作为记忆增强代理的评估研究提供了一个可扩展框架，超越了现有对话设置的关注，为复杂组织环境中的多代理、多平台记忆基准测试奠定了基础。

Abstract: Recent works on context and memory benchmarking have primarily focused on
conversational instances but the need for evaluating memory in dynamic
enterprise environments is crucial for its effective application. We introduce
MEMTRACK, a benchmark designed to evaluate long-term memory and state tracking
in multi-platform agent environments. MEMTRACK models realistic organizational
workflows by integrating asynchronous events across multiple communication and
productivity platforms such as Slack, Linear and Git. Each benchmark instance
provides a chronologically platform-interleaved timeline, with noisy,
conflicting, cross-referring information as well as potential
codebase/file-system comprehension and exploration. Consequently, our benchmark
tests memory capabilities such as acquistion, selection and conflict
resolution. We curate the MEMTRACK dataset through both manual expert driven
design and scalable agent based synthesis, generating ecologically valid
scenarios grounded in real world software development processes. We introduce
pertinent metrics for Correctness, Efficiency, and Redundancy that capture the
effectiveness of memory mechanisms beyond simple QA performance. Experiments
across SoTA LLMs and memory backends reveal challenges in utilizing memory
across long horizons, handling cross-platform dependencies, and resolving
contradictions. Notably, the best performing GPT-5 model only achieves a 60\%
Correctness score on MEMTRACK. This work provides an extensible framework for
advancing evaluation research for memory-augmented agents, beyond existing
focus on conversational setups, and sets the stage for multi-agent,
multi-platform memory benchmarking in complex organizational settings

</details>


### [10] [Retrieval-Augmented Framework for LLM-Based Clinical Decision Support](https://arxiv.org/abs/2510.01363)
*Leon Garza,Anantaa Kotal,Michael A. Grasso,Emre Umucu*

Main category: cs.AI

TL;DR: 提出基于大语言模型的临床决策支持系统，通过分析电子健康记录生成治疗建议，采用检索增强生成技术整合结构化和非结构化数据，旨在辅助而非替代临床医生决策。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录的快速增长和临床决策复杂性增加，为数据驱动的医疗护理带来机遇和挑战，需要开发能够辅助处方决策的智能系统。

Method: 采用检索增强生成(RAG)管道，整合自然语言处理和结构化临床输入，通过分析患者人口统计、临床表现、诊断信息和治疗历史，检索相似病例并生成治疗建议。

Result: 初步评估显示，在适当约束和严格验证下，基于LLM的工具在处方工作流程中能提供有价值的决策支持，输出具有临床合理性和一致性。

Conclusion: 这是将生成式AI整合到现实世界临床决策的初步尝试，强调透明度、安全性以及与既定实践的一致性。

Abstract: The increasing complexity of clinical decision-making, alongside the rapid
expansion of electronic health records (EHR), presents both opportunities and
challenges for delivering data-informed care. This paper proposes a clinical
decision support system powered by Large Language Models (LLMs) to assist
prescribing clinicians. The system generates therapeutic suggestions by
analyzing historical EHR data, including patient demographics, presenting
complaints, clinical symptoms, diagnostic information, and treatment histories.
The framework integrates natural language processing with structured clinical
inputs to produce contextually relevant recommendations. Rather than replacing
clinician judgment, it is designed to augment decision-making by retrieving and
synthesizing precedent cases with comparable characteristics, drawing on local
datasets or federated sources where applicable. At its core, the system employs
a retrieval-augmented generation (RAG) pipeline that harmonizes unstructured
narratives and codified data to support LLM-based inference. We outline the
system's technical components, including representation representation
alignment and generation strategies. Preliminary evaluations, conducted with
de-identified and synthetic clinical datasets, examine the clinical
plausibility and consistency of the model's outputs. Early findings suggest
that LLM-based tools may provide valuable decision support in prescribing
workflows when appropriately constrained and rigorously validated. This work
represents an initial step toward integration of generative AI into real-world
clinical decision-making with an emphasis on transparency, safety, and
alignment with established practices.

</details>


### [11] [Is It Thinking or Cheating? Detecting Implicit Reward Hacking by Measuring Reasoning Effort](https://arxiv.org/abs/2510.01367)
*Xinpeng Wang,Nitish Joshi,Barbara Plank,Rico Angell,He He*

Main category: cs.AI

TL;DR: 提出了TRACE方法来检测隐式奖励黑客行为，通过截断推理过程来量化模型努力程度，在数学推理和编程任务中显著优于现有监控方法。


<details>
  <summary>Details</summary>
Motivation: 奖励黑客行为（模型利用奖励函数漏洞获取高分但不解决实际任务）是一个严重威胁，特别是隐式黑客行为会绕过现有的推理链监控。

Method: TRACE方法通过逐步截断模型的推理链，强制模型在不同截断点回答，测量验证器通过率。黑客模型只需少量推理就能获得高通过率，从而在准确率-长度曲线下产生较大面积。

Result: 在数学推理任务中比最强的72B推理链监控提升65%以上，在编程任务中比32B监控提升30%以上，并能发现训练中的未知漏洞。

Conclusion: TRACE提供了一种可扩展的无监督监督方法，在当前监控方法失效的情况下有效检测隐式奖励黑客行为。

Abstract: Reward hacking, where a reasoning model exploits loopholes in a reward
function to achieve high rewards without solving the intended task, poses a
significant threat. This behavior may be explicit, i.e. verbalized in the
model's chain-of-thought (CoT), or implicit, where the CoT appears benign thus
bypasses CoT monitors. To detect implicit reward hacking, we propose TRACE
(Truncated Reasoning AUC Evaluation). Our key observation is that hacking
occurs when exploiting the loophole is easier than solving the actual task.
This means that the model is using less `effort' than required to achieve high
reward. TRACE quantifies effort by measuring how early a model's reasoning
becomes sufficient to pass a verifier. We progressively truncate a model's CoT
at various lengths, force the model to answer, and measure the verifier-passing
rate at each cutoff. A hacking model, which takes a shortcut, will achieve a
high passing rate with only a small fraction of its CoT, yielding a large area
under the accuracy-vs-length curve. TRACE achieves over 65% gains over our
strongest 72B CoT monitor in math reasoning, and over 30% gains over a 32B
monitor in coding. We further show that TRACE can discover unknown loopholes
during training. Overall, TRACE offers a scalable unsupervised approach for
oversight where current monitoring methods prove ineffective.

</details>


### [12] [Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness](https://arxiv.org/abs/2510.01670)
*Erfan Shayegani,Keegan Hines,Yue Dong,Nael Abu-Ghazaleh,Roman Lutz,Spencer Whitehead,Vidhisha Balachandran,Besmira Nushi,Vibhav Vineet*

Main category: cs.AI

TL;DR: 论文揭示了计算机使用代理(CUAs)存在盲目目标导向(BGD)问题，即不顾可行性、安全性和上下文盲目追求目标，并开发了BLIND-ACT基准来评估这种风险。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理在GUI上执行操作时存在系统性风险，需要识别和量化这些代理在追求目标时不顾可行性、安全性和上下文的倾向。

Method: 开发了BLIND-ACT基准，包含90个任务，基于OSWorld提供真实环境，使用LLM评估代理行为，评估了9个前沿模型。

Result: 发现高平均BGD率(80.8%)，提示干预能降低BGD水平但风险依然存在，观察到执行优先偏见、思维-行动脱节和请求优先等失败模式。

Conclusion: 识别BGD并引入BLIND-ACT为未来研究和减轻这种基本风险奠定了基础，确保CUA的安全部署。

Abstract: Computer-Use Agents (CUAs) are an increasingly deployed class of agents that
take actions on GUIs to accomplish user goals. In this paper, we show that CUAs
consistently exhibit Blind Goal-Directedness (BGD): a bias to pursue goals
regardless of feasibility, safety, reliability, or context. We characterize
three prevalent patterns of BGD: (i) lack of contextual reasoning, (ii)
assumptions and decisions under ambiguity, and (iii) contradictory or
infeasible goals. We develop BLIND-ACT, a benchmark of 90 tasks capturing these
three patterns. Built on OSWorld, BLIND-ACT provides realistic environments and
employs LLM-based judges to evaluate agent behavior, achieving 93.75% agreement
with human annotations. We use BLIND-ACT to evaluate nine frontier models,
including Claude Sonnet and Opus 4, Computer-Use-Preview, and GPT-5, observing
high average BGD rates (80.8%) across them. We show that BGD exposes subtle
risks that arise even when inputs are not directly harmful. While
prompting-based interventions lower BGD levels, substantial risk persists,
highlighting the need for stronger training- or inference-time interventions.
Qualitative analysis reveals observed failure modes: execution-first bias
(focusing on how to act over whether to act), thought-action disconnect
(execution diverging from reasoning), and request-primacy (justifying actions
due to user request). Identifying BGD and introducing BLIND-ACT establishes a
foundation for future research on studying and mitigating this fundamental risk
and ensuring safe CUA deployment.

</details>


### [13] [Fine-tuning with RAG for Improving LLM Learning of New Skills](https://arxiv.org/abs/2510.01375)
*Humaid Ibrahim,Nikolai Rozanov,Marek Rei*

Main category: cs.AI

TL;DR: 提出一种将推理时检索转化为学习能力的蒸馏方法，通过提取失败提示、生成改进轨迹并训练学生模型，在ALFWorld和WebShop基准上显著提升性能，同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: LLM代理在多步任务中经常出现可预测的失败，如尝试不满足前提条件的操作、发出冗余命令或处理环境约束不当。虽然检索增强生成(RAG)可以通过提供运行时指导来改善性能，但需要维护外部知识库并在每次部署时增加计算开销。

Method: 1) 从代理失败中提取紧凑、可重用的提示；2) 使用这些提示在情节开始时通过一次性检索生成改进的教师轨迹；3) 在移除提示字符串的情况下训练学生模型，强制内部化而非记忆。

Result: 在ALFWorld(家庭任务)和WebShop(在线购物)两个交互基准上，蒸馏后的学生模型始终优于基线代理：ALFWorld成功率提升至91%(基线79%)，WebShop分数提升至72(基线61)，同时比检索增强教师少用10-60%的token。

Conclusion: 该方法在不同模型规模(7B/14B参数)和代理架构(ReAct/StateAct)上均能泛化，证明检索优势可以通过有针对性的微调有效内部化，无需永久运行时依赖。

Abstract: Large language model (LLM) agents deployed for multi-step tasks frequently
fail in predictable ways: attempting actions with unmet preconditions, issuing
redundant commands, or mishandling environment constraints. While
retrieval-augmented generation (RAG) can improve performance by providing
runtime guidance, it requires maintaining external knowledge databases and adds
computational overhead at every deployment. We propose a simple pipeline that
converts inference-time retrieval into learned competence through distillation.
Our approach: (1) extracts compact, reusable hints from agent failures, (2)
uses these hints to generate improved teacher trajectories via one-shot
retrieval at episode start, and (3) trains student models on these trajectories
with hint strings removed, forcing internalization rather than memorization.
Across two interactive benchmarks, ALFWorld (household tasks) and WebShop
(online shopping), distilled students consistently outperform baseline agents,
achieving up to 91% success on ALFWorld (vs. 79% for baselines) and improving
WebShop scores to 72 (vs. 61 for baselines), while using 10-60% fewer tokens
than retrieval-augmented teachers depending on the environment. The approach
generalizes across model scales (7B/14B parameters) and agent architectures
(ReAct/StateAct), demonstrating that retrieval benefits can be effectively
internalized through targeted fine-tuning without permanent runtime
dependencies.

</details>


### [14] [Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents](https://arxiv.org/abs/2510.01398)
*Yang Liu,Zaid Abulawi,Abhiram Garimidi,Doyeong Lim*

Main category: cs.AI

TL;DR: 提出使用LLM代理自动化数据驱动建模和分析的创新流程，特别关注回归任务，在临界热通量预测基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现代工程依赖大规模数据集，传统数据驱动方法需要大量人工干预，难以扩展和泛化。

Method: 评估两种LLM代理框架：多代理协作系统和基于ReAct范式的单代理系统，自动处理数据预处理、神经网络开发、训练、超参数优化和不确定性量化。

Result: 在约25,000个实验数据点的CHF预测基准测试中，LLM代理开发的模型超越传统查找表，预测精度和UQ与专家开发的贝叶斯优化深度神经网络相当。

Conclusion: LLM代理在自动化复杂工程建模任务方面具有巨大潜力，能显著减少人工工作量同时达到或超越现有预测性能标准。

Abstract: Modern engineering increasingly relies on vast datasets generated by
experiments and simulations, driving a growing demand for efficient, reliable,
and broadly applicable modeling strategies. There is also heightened interest
in developing data-driven approaches, particularly neural network models, for
effective prediction and analysis of scientific datasets. Traditional
data-driven methods frequently involve extensive manual intervention, limiting
their ability to scale effectively and generalize to diverse applications. In
this study, we propose an innovative pipeline utilizing Large Language Model
(LLM) agents to automate data-driven modeling and analysis, with a particular
emphasis on regression tasks. We evaluate two LLM-agent frameworks: a
multi-agent system featuring specialized collaborative agents, and a
single-agent system based on the Reasoning and Acting (ReAct) paradigm. Both
frameworks autonomously handle data preprocessing, neural network development,
training, hyperparameter optimization, and uncertainty quantification (UQ). We
validate our approach using a critical heat flux (CHF) prediction benchmark,
involving approximately 25,000 experimental data points from the OECD/NEA
benchmark dataset. Results indicate that our LLM-agent-developed model
surpasses traditional CHF lookup tables and delivers predictive accuracy and UQ
on par with state-of-the-art Bayesian optimized deep neural network models
developed by human experts. These outcomes underscore the significant potential
of LLM-based agents to automate complex engineering modeling tasks, greatly
reducing human workload while meeting or exceeding existing standards of
predictive performance.

</details>


### [15] [OntoLogX: Ontology-Guided Knowledge Graph Extraction from Cybersecurity Logs with Large Language Models](https://arxiv.org/abs/2510.01409)
*Luca Cotti,Idilio Drago,Anisa Rula,Devis Bianchini,Federico Cerutti*

Main category: cs.AI

TL;DR: OntoLogX是一个基于LLM的自主AI代理，能够将原始日志转换为基于本体的知识图谱，并通过RAG和迭代校正确保KG的有效性，最终映射到MITRE ATT&CK战术。


<details>
  <summary>Details</summary>
Motivation: 系统日志是重要的网络威胁情报来源，但由于缺乏结构、语义不一致和跨设备碎片化等问题，其效用受到限制。需要能够将噪声、异构数据转换为连贯且可互操作表示的方法。

Method: 集成轻量级日志本体与检索增强生成(RAG)和迭代校正步骤，确保生成的KG在语法和语义上有效。系统还将KG聚合到会话中，并使用LLM预测MITRE ATT&CK战术。

Result: 在公共基准和真实世界蜜罐数据集上的评估表明，OntoLogX能够在多个KG后端上稳健生成KG，并准确将对抗活动映射到ATT&CK战术。检索和校正显著提高了精确率和召回率。

Conclusion: 代码导向模型在结构化日志分析中表现有效，基于本体的表示为可操作的CTI提取提供了价值，检索和校正机制对提高KG质量至关重要。

Abstract: System logs represent a valuable source of Cyber Threat Intelligence (CTI),
capturing attacker behaviors, exploited vulnerabilities, and traces of
malicious activity. Yet their utility is often limited by lack of structure,
semantic inconsistency, and fragmentation across devices and sessions.
Extracting actionable CTI from logs therefore requires approaches that can
reconcile noisy, heterogeneous data into coherent and interoperable
representations. We introduce OntoLogX, an autonomous Artificial Intelligence
(AI) agent that leverages Large Language Models (LLMs) to transform raw logs
into ontology-grounded Knowledge Graphs (KGs). OntoLogX integrates a
lightweight log ontology with Retrieval Augmented Generation (RAG) and
iterative correction steps, ensuring that generated KGs are syntactically and
semantically valid. Beyond event-level analysis, the system aggregates KGs into
sessions and employs a LLM to predict MITRE ATT&CK tactics, linking low-level
log evidence to higher-level adversarial objectives. We evaluate OntoLogX on
both logs from a public benchmark and a real-world honeypot dataset,
demonstrating robust KG generation across multiple KGs backends and accurate
mapping of adversarial activity to ATT&CK tactics. Results highlight the
benefits of retrieval and correction for precision and recall, the
effectiveness of code-oriented models in structured log analysis, and the value
of ontology-grounded representations for actionable CTI extraction.

</details>


### [16] [A Tale of LLMs and Induced Small Proxies: Scalable Agents for Knowledge Mining](https://arxiv.org/abs/2510.01427)
*Sipeng Zhang,Longfei Yun,Zilong Wang,Jingbo Shang,Letian Peng*

Main category: cs.AI

TL;DR: Falconer是一个结合LLM规划能力和轻量级代理模型的可扩展知识挖掘框架，在保持高准确率的同时大幅降低推理成本


<details>
  <summary>Details</summary>
Motivation: 解决LLM在大规模知识挖掘中部署成本过高，而传统分类器-提取器流水线又缺乏泛化能力的问题

Method: 使用LLM作为规划器分解用户指令，作为标注器生成监督数据训练轻量代理模型，统一分类和提取为两个原子操作

Result: Falconer在指令跟随准确率上接近最先进LLM，同时推理成本降低90%，知识挖掘速度提升20倍以上

Conclusion: Falconer为深度研究提供了高效可扩展的基础，实现了LLM推理能力与轻量模型效率的结合

Abstract: At the core of Deep Research is knowledge mining, the task of extracting
structured information from massive unstructured text in response to user
instructions. Large language models (LLMs) excel at interpreting such
instructions but are prohibitively expensive to deploy at scale, while
traditional pipelines of classifiers and extractors remain efficient yet
brittle and unable to generalize to new tasks. We introduce Falconer, a
collaborative framework that combines the agentic reasoning of LLMs with
lightweight proxy models for scalable knowledge mining. In Falconer, LLMs act
as planners, decomposing user instructions into executable pipelines, and as
annotators, generating supervision to train small proxies. The framework
unifies classification and extraction into two atomic operations, get label and
get span, enabling a single instruction-following model to replace multiple
task-specific components. To evaluate the consistency between proxy models
incubated by Falconer and annotations provided by humans and large models, we
construct new benchmarks covering both planning and end-to-end execution.
Experiments show that Falconer closely matches state-of-the-art LLMs in
instruction-following accuracy while reducing inference cost by up to 90% and
accelerating large-scale knowledge mining by more than 20x, offering an
efficient and scalable foundation for Deep Research.

</details>


### [17] [On the Role of Domain Experts in Creating Effective Tutoring Systems](https://arxiv.org/abs/2510.01432)
*Sarath Sreedharan,Kelsey Sikes,Nathaniel Blanchard,Lisa Mason,Nikhil Krishnaswamy,Jill Zarestky*

Main category: cs.AI

TL;DR: 论文探讨了专家知识在AI教育系统中的作用，提出了两种利用专家知识创建新型教育系统的方法：使用可解释AI自动生成课程，以及利用专家制定的课程实现自适应教学系统。


<details>
  <summary>Details</summary>
Motivation: AI教育社区往往忽视了领域专家提供的精心策划知识在创建有效教学系统中的作用，本文旨在强调这一主题的重要性。

Method: 1. 使用可解释AI技术结合专家指定的解题规则自动生成课程；2. 利用专家制定的学习课程开发自适应教学系统。

Result: 通过传粉者识别教学系统的案例研究，证明了这些方法的重要性和可行性。

Conclusion: 专家知识在创建有效的AI教育系统中具有重要作用，特别是在自动课程生成和自适应教学系统开发方面。

Abstract: The role that highly curated knowledge, provided by domain experts, could
play in creating effective tutoring systems is often overlooked within the AI
for education community. In this paper, we highlight this topic by discussing
two ways such highly curated expert knowledge could help in creating novel
educational systems. First, we will look at how one could use explainable AI
(XAI) techniques to automatically create lessons. Most existing XAI methods are
primarily aimed at debugging AI systems. However, we will discuss how one could
use expert specified rules about solving specific problems along with novel XAI
techniques to automatically generate lessons that could be provided to
learners. Secondly, we will see how an expert specified curriculum for learning
a target concept can help develop adaptive tutoring systems, that can not only
provide a better learning experience, but could also allow us to use more
efficient algorithms to create these systems. Finally, we will highlight the
importance of such methods using a case study of creating a tutoring system for
pollinator identification, where such knowledge could easily be elicited from
experts.

</details>


### [18] [VOGUE: Guiding Exploration with Visual Uncertainty Improves Multimodal Reasoning](https://arxiv.org/abs/2510.01444)
*Rui Liu,Dian Yu,Tong Zheng,Runpeng Dai,Zongxia Li,Wenhao Yu,Zhenwen Liang,Linfeng Song,Haitao Mi,Pratap Tokekar,Dong Yu*

Main category: cs.AI

TL;DR: VOGUE是一种新颖的视觉不确定性引导探索方法，通过将图像视为随机上下文，量化策略对视觉扰动的敏感性，有效提升多模态大语言模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法将视觉输入视为固定条件，忽略了视觉变化的模糊性，难以构建对合理视觉变化具有鲁棒性的策略，这限制了多模态大语言模型的探索能力。

Method: VOGUE将探索从输出（文本）空间转移到输入（视觉）空间，通过原始分支和噪声分支之间的对称KL散度量化策略对视觉扰动的敏感性，结合不确定性比例奖励、token熵奖励和退火采样调度来平衡探索与利用。

Result: 在Qwen2.5-VL-3B/7B模型上，VOGUE在三个视觉数学基准上平均提升pass@1准确率2.6%，在三个通用领域推理基准上提升3.7%，同时提高了pass@4性能并缓解了RL微调中常见的探索衰减问题。

Conclusion: 基于视觉输入固有不确定性的探索策略是提升多模态推理的有效方法。

Abstract: Reinforcement learning with verifiable rewards (RLVR) improves reasoning in
large language models (LLMs) but struggles with exploration, an issue that
still persists for multimodal LLMs (MLLMs). Current methods treat the visual
input as a fixed, deterministic condition, overlooking a critical source of
ambiguity and struggling to build policies robust to plausible visual
variations. We introduce $\textbf{VOGUE (Visual Uncertainty Guided
Exploration)}$, a novel method that shifts exploration from the output (text)
to the input (visual) space. By treating the image as a stochastic context,
VOGUE quantifies the policy's sensitivity to visual perturbations using the
symmetric KL divergence between a "raw" and "noisy" branch, creating a direct
signal for uncertainty-aware exploration. This signal shapes the learning
objective via an uncertainty-proportional bonus, which, combined with a
token-entropy bonus and an annealed sampling schedule, effectively balances
exploration and exploitation. Implemented within GRPO on two model scales
(Qwen2.5-VL-3B/7B), VOGUE boosts pass@1 accuracy by an average of 2.6% on three
visual math benchmarks and 3.7% on three general-domain reasoning benchmarks,
while simultaneously increasing pass@4 performance and mitigating the
exploration decay commonly observed in RL fine-tuning. Our work shows that
grounding exploration in the inherent uncertainty of visual inputs is an
effective strategy for improving multimodal reasoning.

</details>


### [19] [AIReg-Bench: Benchmarking Language Models That Assess AI Regulation Compliance](https://arxiv.org/abs/2510.01474)
*Bill Marino,Rosco Hunter,Zubair Jamali,Marinos Emmanouil Kalpakos,Mudra Kashyap,Isaiah Hinton,Alexa Hanson,Maahum Nazir,Christoph Schnabl,Felix Steffek,Hongkai Wen,Nicholas D. Lane*

Main category: cs.AI

TL;DR: 提出了首个评估LLM在AI法规合规性评估方面性能的基准数据集AIReg-Bench，基于欧盟AI法案构建，包含120个技术文档样本并由法律专家标注。


<details>
  <summary>Details</summary>
Motivation: 随着政府对AI的监管加强，需要评估LLM在AI法规合规性判断方面的能力，但目前缺乏相应的基准测试方法。

Method: 通过两步流程创建数据集：(1) 使用结构化指令提示LLM生成120个虚构但合理的AI系统技术文档；(2) 法律专家审查并标注每个样本是否违反AI法案的具体条款。

Result: 创建了包含专家标注的合规性标签的数据集，并评估了前沿LLM在重现专家合规标签方面的表现。

Conclusion: 该基准为理解基于LLM的AI法规合规评估工具的机会和局限性提供了起点，并为后续LLM的比较建立了基准。

Abstract: As governments move to regulate AI, there is growing interest in using Large
Language Models (LLMs) to assess whether or not an AI system complies with a
given AI Regulation (AIR). However, there is presently no way to benchmark the
performance of LLMs at this task. To fill this void, we introduce AIReg-Bench:
the first benchmark dataset designed to test how well LLMs can assess
compliance with the EU AI Act (AIA). We created this dataset through a two-step
process: (1) by prompting an LLM with carefully structured instructions, we
generated 120 technical documentation excerpts (samples), each depicting a
fictional, albeit plausible, AI system - of the kind an AI provider might
produce to demonstrate their compliance with AIR; (2) legal experts then
reviewed and annotated each sample to indicate whether, and in what way, the AI
system described therein violates specific Articles of the AIA. The resulting
dataset, together with our evaluation of whether frontier LLMs can reproduce
the experts' compliance labels, provides a starting point to understand the
opportunities and limitations of LLM-based AIR compliance assessment tools and
establishes a benchmark against which subsequent LLMs can be compared. The
dataset and evaluation code are available at
https://github.com/camlsys/aireg-bench.

</details>


### [20] [Lateral Tree-of-Thoughts Surpasses ToT by Incorporating Logically-Consistent, Low-Utility Candidates](https://arxiv.org/abs/2510.01500)
*Abhinav Madahar*

Main category: cs.AI

TL;DR: LToT是一种改进的思维树搜索控制器，通过分离效用和逻辑一致性，将低效用但一致的候选视为资产而非浪费，解决了广度饱和和深度近视问题。


<details>
  <summary>Details</summary>
Motivation: 标准思维树搜索在大计算预算下存在两个问题：广度饱和（额外样本产生近似重复）和深度近视（噪声短期效用过早剪枝有潜力的分支）。

Method: LToT将前沿分为主线（高效用候选用于开发）和侧线（一致但初始低效用的候选），通过侧向竞速与短路机制探索侧线，使用有上限的连续减半竞赛在宽侧线集上分布小探测。

Result: 理论证明侧线成本为伪线性Θ(N₀ log_η N₀)，与无上限主线的指数增长形成对比。

Conclusion: LToT将大测试时预算转化为原则性多样性，同时保持提升纪律，在不增加计算量的情况下缓解饱和和近视问题。

Abstract: Modern deployments increasingly allocate large test-time compute (thousands
of tokens or many node expansions) to boost reliability. Under such budgets,
standard Tree-of-Thoughts-style search exhibits two pathologies: breadth
saturation (additional samples mostly produce near-duplicates, so width stops
growing) and depth myopia (noisy short-horizon utilities prune branches whose
payoff appears after a few more steps). We propose Lateral Tree-of-Thoughts
(LToT), a drop-in controller that separates utility from logical consistency
and treats low-utility but consistent candidates as assets rather than waste.
The frontier is split into mainlines (high-utility candidates used for
exploitation) and laterals (consistent, initially low-utility candidates that
receive short, cheap probes before judgment). LToT explores laterals via
Lateral Racing with Short-Circuit (LR--SC): a capped successive-halving race
that spreads tiny probes across a very wide lateral set, uses width-aware
thresholds with repeat-to-confirm, and immediately promotes a branch once its
envelope clears the mainline bar; mainlines are kept intentionally narrow so
surplus compute is invested where width is cheap. We prove a pseudolinear
lateral cost $\Theta(N_0 \log_{\eta} N_0)$ with logarithmically many rungs
(initial lateral width $N_0$; culling factor $\eta>1$), in contrast to the
exponential growth of uncapped mainlines. Empirical evaluations on benchmark
tasks are in preparation and will be added in a future revision. In short, LToT
turns large test-time budgets into principled diversity while preserving
promotion discipline, mitigating saturation and myopia without inflating
compute.

</details>


### [21] [Towards Interpretable and Inference-Optimal COT Reasoning with Sparse Autoencoder-Guided Generation](https://arxiv.org/abs/2510.01528)
*Daniel Zhao,Abhilash Shankarampeta,Lanxiang Hu,Tajana Rosing,Hao Zhang*

Main category: cs.AI

TL;DR: 提出一种基于稀疏自编码器和聚类技术的方法，用于分析大语言模型的内部标记表示并指导数学推理任务的生成过程，通过构建标记转移图来平衡利用和探索。


<details>
  <summary>Details</summary>
Motivation: 为了分析大语言模型在数学推理任务中的内部表示，并指导生成过程实现利用（遵循已知推理轨迹）和探索（生成多样性）之间的平衡，从而提高推理质量。

Method: 首先训练稀疏自编码器生成训练标记的稀疏向量表示，然后应用k-means聚类构建标记转移图，其中顶点代表标记簇，加权边捕获顺序标记转移。基于边权重定义奖励函数来量化对推理轨迹的遵循程度。

Result: 研究发现平衡利用和探索对于数学推理任务的高准确性至关重要。稀疏自编码器可以作为可扩展的奖励模型来指导生成，确保利用和探索之间的平衡权衡。

Conclusion: 该方法能够防止极端行为，最终促进大语言模型中更高质量的推理过程，通过平衡利用已知推理轨迹和探索新可能性来提高数学推理性能。

Abstract: We propose a novel method that leverages sparse autoencoders (SAEs) and
clustering techniques to analyze the internal token representations of large
language models (LLMs) and guide generations in mathematical reasoning tasks.
Our approach first trains an SAE to generate sparse vector representations for
training tokens, then applies k-means clustering to construct a graph where
vertices represent token clusters and weighted edges capture sequential token
transitions. Using this graph, we define an edge-weight based reward function
to quantify adherence to established reasoning traces, thereby identifying
exploitative reasoning trajectories. Additionally, we measure generation
diversity from clustering to assess the extent of exploration. Our findings
indicate that balancing both exploitation and exploration is crucial for
achieving high accuracy in mathematical reasoning tasks. During generation, the
SAE can serve as a scalable reward model to guide generations, ensuring a
balanced trade-off between exploitation and exploration. This prevents extreme
behaviors in either direction, ultimately fostering a higher-quality reasoning
process in LLMs.

</details>


### [22] [LOGicalThought: Logic-Based Ontological Grounding of LLMs for High-Assurance Reasoning](https://arxiv.org/abs/2510.01530)
*Navapat Nananukul,Yue Zhang,Ryan Lee,Eric Boxer,Jonathan May,Vibhav Giridhar Gogate,Jay Pujara,Mayank Kejriwal*

Main category: cs.AI

TL;DR: LOGicalThought (LogT) 是一种神经符号架构，结合高级逻辑语言和推理器与LLM，通过构建双上下文表示将长文本推理转化为紧凑的接地评估，在四个多领域基准测试中相比基线提升11.84%性能。


<details>
  <summary>Details</summary>
Motivation: 在关键领域如法律和医学中，需要准确、可验证且明确基于证据的推理。LLM在标准推理任务中表现出色，但无法满足对高保证文本指南的严格推理要求，特别是在涉及否定、蕴含和可废止规则等逻辑结构时。

Method: 提出LogT架构，使用高级逻辑语言和推理器与LLM结合，构建双符号图上下文和基于逻辑的上下文，将长文本指南的推理问题转化为紧凑的接地评估。

Result: 在四个多领域基准测试中，相比四个基线模型，LogT整体性能提升11.84%。在三种推理模式上均有显著改进：否定推理提升10.2%，蕴含推理提升13.2%，可废止推理提升5.5%。

Conclusion: LogT通过神经符号方法有效解决了高保证文本推理中的挑战，特别是在处理可废止逻辑和例外情况方面表现出色，为关键领域的可靠推理提供了可行方案。

Abstract: High-assurance reasoning, particularly in critical domains such as law and
medicine, requires conclusions that are accurate, verifiable, and explicitly
grounded in evidence. This reasoning relies on premises codified from rules,
statutes, and contracts, inherently involving defeasible or non-monotonic logic
due to numerous exceptions, where the introduction of a single fact can
invalidate general rules, posing significant challenges. While large language
models (LLMs) excel at processing natural language, their capabilities in
standard inference tasks do not translate to the rigorous reasoning required
over high-assurance text guidelines. Core reasoning challenges within such
texts often manifest specific logical structures involving negation,
implication, and, most critically, defeasible rules and exceptions. In this
paper, we propose a novel neurosymbolically-grounded architecture called
LOGicalThought (LogT) that uses an advanced logical language and reasoner in
conjunction with an LLM to construct a dual symbolic graph context and
logic-based context. These two context representations transform the problem
from inference over long-form guidelines into a compact grounded evaluation.
Evaluated on four multi-domain benchmarks against four baselines, LogT improves
overall performance by 11.84% across all LLMs. Performance improves
significantly across all three modes of reasoning: by up to +10.2% on negation,
+13.2% on implication, and +5.5% on defeasible reasoning compared to the
strongest baseline.

</details>


### [23] [Information Seeking for Robust Decision Making under Partial Observability](https://arxiv.org/abs/2510.01531)
*Djengo Cyun-Jyun Fang,Tsung-Wei Ke*

Main category: cs.AI

TL;DR: InfoSeeker是一个LLM决策框架，通过集成任务导向规划和信息寻求，在部分可观测环境中实现鲁棒决策，性能比现有方法提升74%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM规划代理在处理观测不确定性时，往往忽略其内部动态与实际环境之间的差异，导致在信息不完整和动态噪声的环境中出现决策问题。

Method: InfoSeeker框架提示LLM主动收集信息，通过规划行动来验证其理解、检测环境变化或测试假设，然后生成或修订任务导向计划。

Result: 在部分可观测环境基准测试中，InfoSeeker实现了74%的绝对性能提升，且不牺牲样本效率，在机器人操作和网络导航等基准测试中优于基线方法。

Conclusion: 在部分可观测环境中，紧密集成规划和信息寻求对于实现鲁棒行为至关重要，InfoSeeker框架展示了这种集成的有效性。

Abstract: Explicit information seeking is essential to human problem-solving in
practical environments characterized by incomplete information and noisy
dynamics. When the true environmental state is not directly observable, humans
seek information to update their internal dynamics and inform future
decision-making. Although existing Large Language Model (LLM) planning agents
have addressed observational uncertainty, they often overlook discrepancies
between their internal dynamics and the actual environment. We introduce
Information Seeking Decision Planner (InfoSeeker), an LLM decision-making
framework that integrates task-oriented planning with information seeking to
align internal dynamics and make optimal decisions under uncertainty in both
agent observations and environmental dynamics. InfoSeeker prompts an LLM to
actively gather information by planning actions to validate its understanding,
detect environmental changes, or test hypotheses before generating or revising
task-oriented plans. To evaluate InfoSeeker, we introduce a novel benchmark
suite featuring partially observable environments with incomplete observations
and uncertain dynamics. Experiments demonstrate that InfoSeeker achieves a 74%
absolute performance gain over prior methods without sacrificing sample
efficiency. Moreover, InfoSeeker generalizes across LLMs and outperforms
baselines on established benchmarks such as robotic manipulation and web
navigation. These findings underscore the importance of tightly integrating
planning and information seeking for robust behavior in partially observable
environments. The project page is available at https://infoseekerllm.github.io

</details>


### [24] [Step-Aware Policy Optimization for Reasoning in Diffusion Large Language Models](https://arxiv.org/abs/2510.01544)
*Shaoan Xie,Lingjing Kong,Xiangchen Song,Xinshuai Dong,Guangyi Chen,Eric P. Xing,Kun Zhang*

Main category: cs.AI

TL;DR: 提出SAPO算法解决扩散语言模型在复杂推理训练中的问题，通过过程奖励函数引导模型学习结构化推理路径


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖稀疏结果奖励，会强化导致偶然正确结果的错误推理路径，这与推理的自然结构不匹配

Method: 提出理论框架将复杂问题解决形式化为层次选择过程，然后引入SAPO算法，使用过程奖励函数使扩散模型的去噪过程与潜在推理层次对齐

Result: 实验结果表明该方法显著提高了在挑战性推理基准上的性能，并增强了生成过程的可解释性

Conclusion: 基于理论框架的SAPO算法能够有效引导扩散语言模型学习结构化推理路径，解决现有方法中的非结构化精炼问题

Abstract: Diffusion language models (dLLMs) offer a promising, non-autoregressive
paradigm for text generation, yet training them for complex reasoning remains a
key challenge. Current reinforcement learning approaches often rely on sparse,
outcome-based rewards, which can reinforce flawed reasoning paths that lead to
coincidentally correct answers. We argue that this stems from a fundamental
mismatch with the natural structure of reasoning. We first propose a
theoretical framework that formalizes complex problem solving as a hierarchical
selection process, where an intractable global constraint is decomposed into a
series of simpler, localized logical steps. This framework provides a
principled foundation for algorithm design, including theoretical insights into
the identifiability of this latent reasoning structure. Motivated by this
theory, we identify unstructured refinement -- a failure mode where a model's
iterative steps do not contribute meaningfully to the solution -- as a core
deficiency in existing methods. We then introduce Step-Aware Policy
Optimization (SAPO), a novel RL algorithm that aligns the dLLM's denoising
process with the latent reasoning hierarchy. By using a process-based reward
function that encourages incremental progress, SAPO guides the model to learn
structured, coherent reasoning paths. Our empirical results show that this
principled approach significantly improves performance on challenging reasoning
benchmarks and enhances the interpretability of the generation process.

</details>


### [25] [InvThink: Towards AI Safety via Inverse Reasoning](https://arxiv.org/abs/2510.01569)
*Yubin Kim,Taehan Kim,Eugene Park,Chunjong Park,Cynthia Breazeal,Daniel McDuff,Hae Won Park*

Main category: cs.AI

TL;DR: InvThink是一种让大语言模型具备逆向思维能力的方法，通过预先分析潜在危害及其后果来生成更安全的响应。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法直接优化安全响应，但缺乏系统性的风险预防机制，需要一种更主动的安全保障方法。

Method: 训练模型执行三个步骤：1) 枚举潜在危害，2) 分析后果，3) 生成主动避免这些风险的安全输出。通过监督微调和强化学习在三个LLM系列上实现。

Result: 安全改进随模型规模扩展性更强；减轻安全税，保持标准基准上的通用推理能力；在高风险领域（医疗、金融、法律等）有害响应减少达15.7%。

Conclusion: 逆向推理为构建更安全、更强大的语言模型提供了可扩展和泛化的路径。

Abstract: We present InvThink, a simple yet powerful approach that gives large language
models (LLMs) the capability of inverse thinking: reasoning through failure
modes before generating responses. Unlike existing safety alignment methods
that optimize directly for safe response, InvThink instructs models to 1)
enumerate potential harms, 2) analyze their consequences, and 3) generate safe
outputs that proactively avoid these risks. Our method reveals three key
findings: (i) safety improvements show stronger scaling with model size
compared to existing safety methods. (ii) InvThink mitigates safety tax; by
training models to systematically consider failure modes, it preserves general
reasoning capabilities on standard benchmarks. (iii) beyond general safety
tasks, InvThink excels in high-stakes domains including external-facing
(medicine, finance, law) and agentic (blackmail, murder) risk scenarios,
achieving up to 15.7% reduction in harmful responses compared to baseline
methods like SafetyPrompt. We further implement InvThink via supervised
fine-tuning, and reinforcement learning across three LLM families. These
results suggest that inverse reasoning provides a scalable and generalizable
path toward safer, more capable language models.

</details>


### [26] [AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.01586)
*Zhenyu Pan,Yiting Zhang,Zhuo Liu,Yolo Yunlong Tang,Zeliang Zhang,Haozheng Luo,Yuwei Han,Jianshu Zhang,Dennis Wu,Hong-Yu Chen,Haoran Lu,Haoyang Fang,Manling Li,Chenliang Xu,Philip S. Yu,Han Liu*

Main category: cs.AI

TL;DR: AdvEvo-MARL是一个协同进化的多智能体强化学习框架，通过内部化安全机制到任务智能体，无需外部防护模块就能同时提升安全性和任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM多智能体系统防御方法存在不足：自验证方法因单个智能体能力有限而效果不佳，外部防护模块会增加系统开销并造成单点故障。需要一种既能保证安全又不增加系统复杂度的解决方案。

Method: 提出AdvEvo-MARL框架，在对抗学习环境中联合优化攻击者（生成不断演化的越狱提示）和防御者（训练任务智能体既能完成任务又能抵抗攻击），并引入基于功能组的公共基线来稳定学习和促进协作。

Result: 在代表性攻击场景中，AdvEvo-MARL始终将攻击成功率保持在20%以下，而基线方法可达38.33%，同时保持甚至提高了任务准确率（推理任务上提升达+3.67%）。

Conclusion: 安全性和实用性可以在不依赖额外防护智能体或增加系统开销的情况下共同提升，AdvEvo-MARL为LLM多智能体系统提供了一种有效的内生安全解决方案。

Abstract: LLM-based multi-agent systems excel at planning, tool use, and role
coordination, but their openness and interaction complexity also expose them to
jailbreak, prompt-injection, and adversarial collaboration. Existing defenses
fall into two lines: (i) self-verification that asks each agent to pre-filter
unsafe instructions before execution, and (ii) external guard modules that
police behaviors. The former often underperforms because a standalone agent
lacks sufficient capacity to detect cross-agent unsafe chains and
delegation-induced risks; the latter increases system overhead and creates a
single-point-of-failure-once compromised, system-wide safety collapses, and
adding more guards worsens cost and complexity. To solve these challenges, we
propose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning
framework that internalizes safety into task agents. Rather than relying on
external guards, AdvEvo-MARL jointly optimizes attackers (which synthesize
evolving jailbreak prompts) and defenders (task agents trained to both
accomplish their duties and resist attacks) in adversarial learning
environments. To stabilize learning and foster cooperation, we introduce a
public baseline for advantage estimation: agents within the same functional
group share a group-level mean-return baseline, enabling lower-variance updates
and stronger intra-group coordination. Across representative attack scenarios,
AdvEvo-MARL consistently keeps attack-success rate (ASR) below 20%, whereas
baselines reach up to 38.33%, while preserving-and sometimes improving-task
accuracy (up to +3.67% on reasoning tasks). These results show that safety and
utility can be jointly improved without relying on extra guard agents or added
system overhead.

</details>


### [27] [AgentRec: Next-Generation LLM-Powered Multi-Agent Collaborative Recommendation with Adaptive Intelligence](https://arxiv.org/abs/2510.01609)
*Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Lau*

Main category: cs.AI

TL;DR: AgentRec是一个基于LLM的多智能体协作推荐框架，通过分层智能体网络解决动态用户偏好、对话连贯性和多目标排序的挑战，在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有交互式对话推荐系统在处理动态用户偏好、保持对话连贯性和平衡多排序目标方面存在显著挑战，需要更智能的解决方案。

Method: 采用分层智能体网络，包括对话理解、偏好建模、上下文感知和动态排序等专门LLM智能体，通过自适应权重机制协调，结合三层学习策略（快速响应、智能推理和深度协作）。

Result: 在三个真实数据集上的实验表明，AgentRec在对话成功率提升2.8%，推荐准确性（NDCG@10）提高1.9%，对话效率提升3.2%，同时保持可比较的计算成本。

Conclusion: AgentRec通过多智能体协作框架有效解决了现有对话推荐系统的关键挑战，在多个性能指标上实现了显著提升。

Abstract: Interactive conversational recommender systems have gained significant
attention for their ability to capture user preferences through natural
language interactions. However, existing approaches face substantial challenges
in handling dynamic user preferences, maintaining conversation coherence, and
balancing multiple ranking objectives simultaneously. This paper introduces
AgentRec, a next-generation LLM-powered multi-agent collaborative
recommendation framework that addresses these limitations through hierarchical
agent networks with adaptive intelligence. Our approach employs specialized
LLM-powered agents for conversation understanding, preference modeling, context
awareness, and dynamic ranking, coordinated through an adaptive weighting
mechanism that learns from interaction patterns. We propose a three-tier
learning strategy combining rapid response for simple queries, intelligent
reasoning for complex preferences, and deep collaboration for challenging
scenarios. Extensive experiments on three real-world datasets demonstrate that
AgentRec achieves consistent improvements over state-of-the-art baselines, with
2.8\% enhancement in conversation success rate, 1.9\% improvement in
recommendation accuracy (NDCG@10), and 3.2\% better conversation efficiency
while maintaining comparable computational costs through intelligent agent
coordination.

</details>


### [28] [PychoBench: Evaluating the Psychology Intelligence of Large Language Models](https://arxiv.org/abs/2510.01611)
*Min Zeng*

Main category: cs.AI

TL;DR: 本文评估LLMs是否具备心理辅导能力，通过创建基于美国国家咨询师认证考试的心理咨询基准PsychoBench，发现只有前沿模型能通过考试标准。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在需要认知能力的应用（如心理咨询）中的潜力，验证LLMs是否具备担任心理辅导师所需的专业知识。

Method: 构建PsychoBench基准，包含2,252个精心设计的单选题，基于美国国家咨询师认证考试，要求深度理解和广泛心理学知识。

Result: GPT-4o、Llama3.3-70B和Gemma3-27B等先进模型远超通过阈值（约70%），而小型开源模型远低于标准。

Conclusion: 只有前沿LLMs目前能满足心理咨询考试标准，这凸显了开发心理学导向LLMs的前景与挑战。

Abstract: Large Language Models (LLMs) have demonstrated remarkable success across a
wide range of industries, primarily due to their impressive generative
abilities. Yet, their potential in applications requiring cognitive abilities,
such as psychological counseling, remains largely untapped. This paper
investigates the key question: Can LLMs be effectively applied to psychological
counseling? To determine whether an LLM can effectively take on the role of a
psychological counselor, the first step is to assess whether it meets the
qualifications required for such a role, namely the ability to pass the U.S.
National Counselor Certification Exam (NCE). This is because, just as a human
counselor must pass a certification exam to practice, an LLM must demonstrate
sufficient psychological knowledge to meet the standards required for such a
role. To address this, we introduce PsychoBench, a benchmark grounded in
U.S.national counselor examinations, a licensure test for professional
counselors that requires about 70% accuracy to pass. PsychoBench comprises
approximately 2,252 carefully curated single-choice questions, crafted to
require deep understanding and broad enough to cover various sub-disciplines of
psychology. This benchmark provides a comprehensive assessment of an LLM's
ability to function as a counselor. Our evaluation shows that advanced models
such as GPT-4o, Llama3.3-70B, and Gemma3-27B achieve well above the passing
threshold, while smaller open-source models (e.g., Qwen2.5-7B, Mistral-7B)
remain far below it. These results suggest that only frontier LLMs are
currently capable of meeting counseling exam standards, highlighting both the
promise and the challenges of developing psychology-oriented LLMs.

</details>


### [29] [Learning to Decide with Just Enough: Information-Theoretic Context Summarization for CDMPs](https://arxiv.org/abs/2510.01620)
*Peidong Liu,Junjiang Lin,Shaowen Wang,Yao Xu,Haiqing Li,Xuhao Xie,Siyi Wu,Hao Li*

Main category: cs.AI

TL;DR: 提出基于信息论的上下文马尔可夫决策过程(CMDP)方法，使用LLM压缩高维上下文为低维语义摘要，提升决策效率并降低计算成本


<details>
  <summary>Details</summary>
Motivation: 现有CMDP方法在高维或非结构化上下文中泛化能力差，导致计算开销大且性能不稳定，需要更高效的上下文处理方法

Method: 使用LLM进行信息论摘要，将上下文输入压缩为低维语义丰富的摘要，基于近似上下文充分性概念构建理论框架

Result: 在离散、连续、视觉和推荐基准测试中，该方法在奖励、成功率、样本效率方面优于原始上下文和非上下文基线，同时降低延迟和内存使用

Conclusion: LLM摘要为上下文丰富、资源受限环境中的高效决策提供了可扩展且可解释的解决方案

Abstract: Contextual Markov Decision Processes (CMDPs) offer a framework for sequential
decision-making under external signals, but existing methods often fail to
generalize in high-dimensional or unstructured contexts, resulting in excessive
computation and unstable performance. We propose an information-theoretic
summarization approach that uses large language models (LLMs) to compress
contextual inputs into low-dimensional, semantically rich summaries. These
summaries augment states by preserving decision-critical cues while reducing
redundancy. Building on the notion of approximate context sufficiency, we
provide, to our knowledge, the first regret bounds and a latency-entropy
trade-off characterization for CMDPs. Our analysis clarifies how
informativeness impacts computational cost. Experiments across discrete,
continuous, visual, and recommendation benchmarks show that our method
outperforms raw-context and non-context baselines, improving reward, success
rate, and sample efficiency, while reducing latency and memory usage. These
findings demonstrate that LLM-based summarization offers a scalable and
interpretable solution for efficient decision-making in context-rich,
resource-constrained environments.

</details>


### [30] [Understanding the Geospatial Reasoning Capabilities of LLMs: A Trajectory Recovery Perspective](https://arxiv.org/abs/2510.01639)
*Thinh Hung Truong,Jey Han Lau,Jianzhong Qi*

Main category: cs.AI

TL;DR: LLMs能够理解道路网络地图并执行导航任务，通过轨迹恢复任务验证其在GPS轨迹重建方面的能力，在GLOBALTRACE数据集上表现优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在空间推理方面的能力，特别是能否理解道路网络地图并执行导航任务，为增强导航体验提供新方法。

Method: 将轨迹恢复作为代理任务，使用GLOBALTRACE数据集（包含4000多个真实轨迹），通过提示框架让LLMs在不访问外部导航工具的情况下生成有效路径。

Result: LLMs在轨迹恢复任务上优于现成基线和专业轨迹恢复模型，具有强大的零样本泛化能力，但对不同区域和交通方式存在系统性偏差。

Conclusion: LLMs具有强大的道路网络和坐标系理解能力，能够通过灵活的地图推理来增强导航体验，融入用户偏好。

Abstract: We explore the geospatial reasoning capabilities of Large Language Models
(LLMs), specifically, whether LLMs can read road network maps and perform
navigation. We frame trajectory recovery as a proxy task, which requires models
to reconstruct masked GPS traces, and introduce GLOBALTRACE, a dataset with
over 4,000 real-world trajectories across diverse regions and transportation
modes. Using road network as context, our prompting framework enables LLMs to
generate valid paths without accessing any external navigation tools.
Experiments show that LLMs outperform off-the-shelf baselines and specialized
trajectory recovery models, with strong zero-shot generalization. Fine-grained
analysis shows that LLMs have strong comprehension of the road network and
coordinate systems, but also pose systematic biases with respect to regions and
transportation modes. Finally, we demonstrate how LLMs can enhance navigation
experiences by reasoning over maps in flexible ways to incorporate user
preferences.

</details>


### [31] [GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents](https://arxiv.org/abs/2510.01664)
*Yejin Kim,Youngbin Lee,Juhyeong Kim,Yongjae Lee*

Main category: cs.AI

TL;DR: 本研究开发了五个基于提示工程的AI投资代理（GuruAgents），分别模拟传奇投资大师的策略。在纳斯达克100成分股的测试中，巴菲特代理表现最佳，年化收益率达42.2%，显著超越基准。


<details>
  <summary>Details</summary>
Motivation: 将定性投资哲学转化为可复现的量化策略，探索自动化系统投资的新方向。

Method: 通过LLM提示编码投资大师的独特哲学，整合金融工具和确定性推理管道，开发五个不同的GuruAgents。

Result: 巴菲特代理表现最佳（42.2% CAGR），其他代理结果各异，所有代理都展现出由其提示人格驱动的独特行为。

Conclusion: 提示工程能成功将投资大师的定性哲学转化为可复现的量化策略，为自动化系统投资开辟了新方向。

Abstract: This study demonstrates that GuruAgents, prompt-guided AI agents, can
systematically operationalize the strategies of legendary investment gurus. We
develop five distinct GuruAgents, each designed to emulate an iconic investor,
by encoding their distinct philosophies into LLM prompts that integrate
financial tools and a deterministic reasoning pipeline. In a backtest on
NASDAQ-100 constituents from Q4 2023 to Q2 2025, the GuruAgents exhibit unique
behaviors driven by their prompted personas. The Buffett GuruAgent achieves the
highest performance, delivering a 42.2\% CAGR that significantly outperforms
benchmarks, while other agents show varied results. These findings confirm that
prompt engineering can successfully translate the qualitative philosophies of
investment gurus into reproducible, quantitative strategies, highlighting a
novel direction for automated systematic investing. The source code and data
are available at https://github.com/yejining99/GuruAgents.

</details>


### [32] [A Locally Executable AI System for Improving Preoperative Patient Communication: A Multi-Domain Clinical Evaluation](https://arxiv.org/abs/2510.01671)
*Motoki Sato,Yuki Matsushita,Hidekazu Takahashi,Tomoaki Kakazu,Sou Nagata,Mizuho Ohnuma,Atsushi Yoshikawa,Masayuki Yamamura*

Main category: cs.AI

TL;DR: LENOHA是一个安全优先、本地优先的系统，使用高精度分类器从临床医生整理的FAQ中返回逐字答案，避免自由文本生成，在临床路径中实现高准确率、低能耗和快速响应。


<details>
  <summary>Details</summary>
Motivation: 患者在等待侵入性手术时经常有未解答的问题，但时间紧迫的工作流程和隐私限制限制了个性化咨询。需要一种安全、高效且保护隐私的解决方案。

Method: 使用基于句子转换器的分类器路由输入，从临床医生整理的FAQ中返回逐字答案，完全避免临床路径中的自由文本生成。在两个临床领域（拔牙和胃镜检查）进行评估。

Result: E5-large-instruct模型总体准确率达0.983，AUC为0.996，仅7个错误。非生成式临床路径能耗仅为1.0 mWh/输入，比本地8B SLM小170倍，延迟约0.10秒。

Conclusion: 通过返回经过验证的FAQ逐字答案，可以在临床路径中结构性避免前沿模型生成导致的错误，支持隐私保护、可持续性以及在带宽受限环境中的公平部署。

Abstract: Patients awaiting invasive procedures often have unanswered pre-procedural
questions; however, time-pressured workflows and privacy constraints limit
personalized counseling. We present LENOHA (Low Energy, No Hallucination, Leave
No One Behind Architecture), a safety-first, local-first system that routes
inputs with a high-precision sentence-transformer classifier and returns
verbatim answers from a clinician-curated FAQ for clinical queries, eliminating
free-text generation in the clinical path. We evaluated two domains (tooth
extraction and gastroscopy) using expert-reviewed validation sets
(n=400/domain) for thresholding and independent test sets (n=200/domain). Among
the four encoders, E5-large-instruct (560M) achieved an overall accuracy of
0.983 (95% CI 0.964-0.991), AUC 0.996, and seven total errors, which were
statistically indistinguishable from GPT-4o on this task; Gemini made no errors
on this test set. Energy logging shows that the non-generative clinical path
consumes ~1.0 mWh per input versus ~168 mWh per small-talk reply from a local
8B SLM, a ~170x difference, while maintaining ~0.10 s latency on a single
on-prem GPU. These results indicate that near-frontier discrimination and
generation-induced errors are structurally avoided in the clinical path by
returning vetted FAQ answers verbatim, supporting privacy, sustainability, and
equitable deployment in bandwidth-limited environments.

</details>


### [33] [Improving AGI Evaluation: A Data Science Perspective](https://arxiv.org/abs/2510.01687)
*John Hawkins*

Main category: cs.AI

TL;DR: 本文主张AGI评估方法应从基于直觉设计合成任务转向关注稳健任务执行能力的评估，借鉴数据科学实践来验证系统的可靠部署能力。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估方法依赖对智能的直觉理解来设计合成任务，这种方法在AI历史上表现不佳，需要更有效的评估框架。

Method: 提出基于稳健任务执行能力的评估设计哲学，借鉴数据科学中验证系统可靠部署的实践方法，并提供具体评估示例。

Result: 开发了一种替代性的AGI评估视角，强调通过能力展示而非直觉任务来证明AGI。

Conclusion: AGI评估应转向关注系统在真实环境中的稳健执行能力，这种基于能力的评估方法比传统的基于直觉的合成任务更有效。

Abstract: Evaluation of potential AGI systems and methods is difficult due to the
breadth of the engineering goal. We have no methods for perfect evaluation of
the end state, and instead measure performance on small tests designed to
provide directional indication that we are approaching AGI. In this work we
argue that AGI evaluation methods have been dominated by a design philosophy
that uses our intuitions of what intelligence is to create synthetic tasks,
that have performed poorly in the history of AI. Instead we argue for an
alternative design philosophy focused on evaluating robust task execution that
seeks to demonstrate AGI through competence. This perspective is developed from
common practices in data science that are used to show that a system can be
reliably deployed. We provide practical examples of what this would mean for
AGI evaluation.

</details>


### [34] [VaPR -- Vision-language Preference alignment for Reasoning](https://arxiv.org/abs/2510.01700)
*Rohan Wadhawan,Fabrice Y Harel-Canada,Zi-Yi Dou,Suhaila Shakiah,Robinson Piramuthu,Nanyun Peng*

Main category: cs.AI

TL;DR: 提出了VaPR框架，通过LLM引导的响应编辑生成硬负样本，解决了合成偏好标注中的风格和长度偏差问题，显著提升了大型视觉语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的偏好微调方法忽视了合成偏好标注中普遍存在的风格和长度偏差噪声，需要开发能够产生高质量负样本的方法来改善模型对齐效果。

Method: 基于LLM引导的响应编辑框架，生成具有目标错误的拒绝响应，同时保持与接受响应在风格和长度上的相似性，构建了包含30K样本的VaPR数据集。

Result: 在三个LVLM家族上实现了显著性能提升：LLaVA平均提升6.5%，Qwen2VL提升4.0%，Qwen2.5VL提升1.5%，特别是在推理任务上表现突出，并减少了二元问题中的"是"回答倾向。

Conclusion: VaPR框架有效解决了合成偏好数据中的偏差问题，性能随数据规模持续提升，且该框架可推广到开源LLM作为编辑器，具有很好的通用性。

Abstract: Preference finetuning methods like Direct Preference Optimization (DPO) with
AI-generated feedback have shown promise in aligning Large Vision-Language
Models (LVLMs) with human preferences. However, existing techniques overlook
the prevalence of noise in synthetic preference annotations in the form of
stylistic and length biases. To this end, we introduce a hard-negative response
generation framework based on LLM-guided response editing, that produces
rejected responses with targeted errors, maintaining stylistic and length
similarity to the accepted ones. Using this framework, we develop the VaPR
dataset, comprising 30K high-quality samples, to finetune three LVLM families:
LLaVA-V1.5, Qwen2VL & Qwen2.5VL (2B-13B sizes). Our VaPR models deliver
significant performance improvements across ten benchmarks, achieving average
gains of 6.5% (LLaVA), 4.0% (Qwen2VL), and 1.5% (Qwen2.5VL), with notable
improvements on reasoning tasks. A scaling analysis shows that performance
consistently improves with data size, with LLaVA models benefiting even at
smaller scales. Moreover, VaPR reduces the tendency to answer "Yes" in binary
questions - addressing a common failure mode in LVLMs like LLaVA. Lastly, we
show that the framework generalizes to open-source LLMs as editors, with models
trained on VaPR-OS achieving ~99% of the performance of models trained on
\name, which is synthesized using GPT-4o. Our data, models, and code can be
found on the project page https://vap-r.github.io

</details>


### [35] [MetaboT: AI-based agent for natural language-based interaction with metabolomics knowledge graphs](https://arxiv.org/abs/2510.01724)
*Madina Bekbergenova,Lucas Pradi,Benjamin Navet,Emma Tysinger,Franck Michel,Matthieu Feraud,Yousouf Taghzouti,Yan Zhou Chen,Olivier Kirchhoffer,Florence Mehl,Martin Legrand,Tao Jiang,Marco Pagni,Soha Hassoun,Jean-Luc Wolfender,Wout Bittremieux,Fabien Gandon,Louis-Félix Nothias*

Main category: cs.AI

TL;DR: MetaboT是一个基于大语言模型的多代理AI系统，能够将用户自然语言问题转换为SPARQL查询语言，用于操作代谢组学知识图谱，显著提高了查询准确率。


<details>
  <summary>Details</summary>
Motivation: 代谢组学质谱分析产生大量数据，知识图谱虽然能结构化这些数据，但使用需要深入了解本体论和查询语言语法，这阻碍了研究人员的使用。

Method: 采用多代理系统架构，使用LangChain和LangGraph库集成大语言模型与外部工具，通过专门的代理处理用户查询、验证问题、识别化学转换需求，并生成SPARQL查询。

Result: 在50个代谢组学相关问题的测试中，MetaboT达到83.67%的准确率，而仅使用GPT-4o的基线方法只有8.16%的准确率。

Conclusion: MetaboT成功消除了访问知识图谱的技术障碍，通过自然语言查询实现了结构化代谢组学数据的检索，促进了数据驱动的研究发现。

Abstract: Mass spectrometry metabolomics generates vast amounts of data requiring
advanced methods for interpretation. Knowledge graphs address these challenges
by structuring mass spectrometry data, metabolite information, and their
relationships into a connected network (Gaudry et al. 2024). However, effective
use of a knowledge graph demands an in-depth understanding of its ontology and
its query language syntax. To overcome this, we designed MetaboT, an AI system
utilizing large language models (LLMs) to translate user questions into SPARQL
semantic query language for operating on knowledge graphs (Steve Harris 2013).
We demonstrate its effectiveness using the Experimental Natural Products
Knowledge Graph (ENPKG), a large-scale public knowledge graph for plant natural
products (Gaudry et al. 2024).MetaboT employs specialized AI agents for
handling user queries and interacting with the knowledge graph by breaking down
complex tasks into discrete components, each managed by a specialised agent
(Fig. 1a). The multi-agent system is constructed using the LangChain and
LangGraph libraries, which facilitate the integration of LLMs with external
tools and information sources (LangChain, n.d.). The query generation process
follows a structured workflow. First, the Entry Agent determines if the
question is new or a follow-up to previous interactions. New questions are
forwarded to the Validator Agent, which verifies if the question is related to
the knowledge graph. Then, the valid question is sent to the Supervisor Agent,
which identifies if the question requires chemical conversions or standardized
identifiers. In this case it delegates the question to the Knowledge Graph
Agent, which can use tools to extract necessary details, such as URIs or
taxonomies of chemical names, from the user query. Finally, an agent
responsible for crafting the SPARQL queries equipped with the ontology of the
knowledge graph uses the provided identifiers to generate the query. Then, the
system executes the generated query against the metabolomics knowledge graph
and returns structured results to the user (Fig. 1b). To assess the performance
of MetaboT we have curated 50 metabolomics-related questions and their expected
answers. In addition to submitting these questions to MetaboT, we evaluated a
baseline by submitting them to a standard LLM (GPT-4o) with a prompt that
incorporated the knowledge graph ontology but did not provide specific entity
IDs. This baseline achieved only 8.16% accuracy, compared to MetaboT's 83.67%,
underscoring the necessity of our multi-agent system for accurately retrieving
entities and generating correct SPARQL queries. MetaboT demonstrates promising
performance as a conversational question-answering assistant, enabling
researchers to retrieve structured metabolomics data through natural language
queries. By automating the generation and execution of SPARQL queries, it
removes technical barriers that have traditionally hindered access to knowledge
graphs. Importantly, MetaboT leverages the capabilities of LLMs while
maintaining experimentally grounded query generation, ensuring that outputs
remain aligned with domain-specific standards and data structures. This
approach facilitates data-driven discoveries by bridging the gap between
complex semantic technologies and user-friendly interaction. MetaboT is
accessible at [https://metabot.holobiomicslab.eu/], and its source code is
available at [https://github.com/HolobiomicsLab/MetaboT].

</details>


### [36] [A cybersecurity AI agent selection and decision support framework](https://arxiv.org/abs/2510.01751)
*Masike Malatji*

Main category: cs.AI

TL;DR: 提出了一个结构化决策支持框架，将不同类型的AI智能体架构与NIST网络安全框架2.0系统对齐，为选择部署AI解决方案提供透明方法。


<details>
  <summary>Details</summary>
Motivation: 弥合理论AI构建与运营网络安全需求之间的差距，提供统一的检测、事件响应和治理策略。

Method: 通过将NIST CSF 2.0功能细分为具体任务，将AI智能体特性（自主性、自适应学习、实时响应）与安全要求关联，并定义分级自主级别。

Result: 概念验证表明，定制的AI智能体部署能够与现实约束和风险状况对齐，增强态势感知、加速响应时间并强化长期韧性。

Conclusion: 该研究为遵循行业标准的稳健、经验验证的多智能体系统奠定了基础，连接了AI理论与网络安全实践。

Abstract: This paper presents a novel, structured decision support framework that
systematically aligns diverse artificial intelligence (AI) agent architectures,
reactive, cognitive, hybrid, and learning, with the comprehensive National
Institute of Standards and Technology (NIST) Cybersecurity Framework (CSF) 2.0.
By integrating agent theory with industry guidelines, this framework provides a
transparent and stepwise methodology for selecting and deploying AI solutions
to address contemporary cyber threats. Employing a granular decomposition of
NIST CSF 2.0 functions into specific tasks, the study links essential AI agent
properties such as autonomy, adaptive learning, and real-time responsiveness to
each subcategory's security requirements. In addition, it outlines graduated
levels of autonomy (assisted, augmented, and fully autonomous) to accommodate
organisations at varying stages of cybersecurity maturity. This holistic
approach transcends isolated AI applications, providing a unified detection,
incident response, and governance strategy. Through conceptual validation, the
framework demonstrates how tailored AI agent deployments can align with
real-world constraints and risk profiles, enhancing situational awareness,
accelerating response times, and fortifying long-term resilience via adaptive
risk management. Ultimately, this research bridges the gap between theoretical
AI constructs and operational cybersecurity demands, establishing a foundation
for robust, empirically validated multi-agent systems that adhere to industry
standards.

</details>


### [37] [REBot: From RAG to CatRAG with Semantic Enrichment and Graph Routing](https://arxiv.org/abs/2510.01800)
*Thanh Ma,Tri-Tam La,Lam-Thu Le Huu,Minh-Nghi Nguyen,Khanh-Van Pham Luu,Huu-Hoa Nguyen*

Main category: cs.AI

TL;DR: 提出了REBot，一个基于CatRAG框架的LLM增强学术规定咨询聊天机器人，通过混合检索推理实现高效的学术政策咨询，在分类和问答任务中达到98.89%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 学术规定咨询对帮助学生理解和遵守机构政策至关重要，但构建有效系统需要领域特定的监管资源。

Method: 提出CatRAG混合检索推理框架，结合检索增强生成和图推理，使用层次化类别标记的知识图谱，配备轻量级意图分类器路由查询到适当的检索模块。

Result: 构建了特定规定数据集，在分类和问答任务中实现最先进性能，F1分数达到98.89%。

Conclusion: 开发了展示REBot在实际学术咨询场景中实用价值的Web应用程序。

Abstract: Academic regulation advising is essential for helping students interpret and
comply with institutional policies, yet building effective systems requires
domain specific regulatory resources. To address this challenge, we propose
REBot, an LLM enhanced advisory chatbot powered by CatRAG, a hybrid retrieval
reasoning framework that integrates retrieval augmented generation with graph
based reasoning. CatRAG unifies dense retrieval and graph reasoning, supported
by a hierarchical, category labeled knowledge graph enriched with semantic
features for domain alignment. A lightweight intent classifier routes queries
to the appropriate retrieval modules, ensuring both factual accuracy and
contextual depth. We construct a regulation specific dataset and evaluate REBot
on classification and question answering tasks, achieving state of the art
performance with an F1 score of 98.89%. Finally, we implement a web application
that demonstrates the practical value of REBot in real world academic advising
scenarios.

</details>


### [38] [Human-AI Teaming Co-Learning in Military Operations](https://arxiv.org/abs/2510.01815)
*Clara Maathuis,Kasper Cools*

Main category: cs.AI

TL;DR: 提出一个可信赖的协同学习模型，用于军事行动中的人机协作，通过四个维度实现：可调节自主性、多层控制、双向反馈和协作决策。


<details>
  <summary>Details</summary>
Motivation: 在快速演变的军事威胁和复杂作战环境中，AI集成带来显著优势，但也面临有效和伦理部署的挑战。当前方法多从外部视角处理，需要深入系统内部动态以应对更广泛的多维责任、安全和鲁棒性问题。

Method: 设计包含四个维度的可信赖协同学习模型：1) 可调节自主性 - 根据任务状态、系统置信度和环境不确定性动态校准自主级别；2) 多层控制 - 持续监督、活动监控和问责制；3) 双向反馈 - 显性和隐性反馈循环，确保推理、不确定性和学习适应的适当沟通；4) 协作决策 - 生成、评估和提议决策，附带置信水平和理由。

Result: 提出了一个具体的人机协作模型，并提供了具体示例和建议，有助于进一步发展负责任和可信赖的军事人机协作系统。

Conclusion: 该研究通过四个关键维度的整合，为军事行动中的人机协作提供了一个可信赖的协同学习框架，能够促进系统在动态战场条件下的共同适应和持续改进。

Abstract: In a time of rapidly evolving military threats and increasingly complex
operational environments, the integration of AI into military operations proves
significant advantages. At the same time, this implies various challenges and
risks regarding building and deploying human-AI teaming systems in an effective
and ethical manner. Currently, understanding and coping with them are often
tackled from an external perspective considering the human-AI teaming system as
a collective agent. Nevertheless, zooming into the dynamics involved inside the
system assures dealing with a broader palette of relevant multidimensional
responsibility, safety, and robustness aspects. To this end, this research
proposes the design of a trustworthy co-learning model for human-AI teaming in
military operations that encompasses a continuous and bidirectional exchange of
insights between the human and AI agents as they jointly adapt to evolving
battlefield conditions. It does that by integrating four dimensions. First,
adjustable autonomy for dynamically calibrating the autonomy levels of agents
depending on aspects like mission state, system confidence, and environmental
uncertainty. Second, multi-layered control which accounts continuous oversight,
monitoring of activities, and accountability. Third, bidirectional feedback
with explicit and implicit feedback loops between the agents to assure a proper
communication of reasoning, uncertainties, and learned adaptations that each of
the agents has. And fourth, collaborative decision-making which implies the
generation, evaluation, and proposal of decisions associated with confidence
levels and rationale behind them. The model proposed is accompanied by concrete
exemplifications and recommendations that contribute to further developing
responsible and trustworthy human-AI teaming systems in military operations.

</details>


### [39] [Plan Then Action:High-Level Planning Guidance Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2510.01833)
*Zhihao Dou,Qinjian Zhao,Zhongwei Wan,Dinggen Zhang,Weida Wang,Towsif Raiyan,Benteng Chen,Qingtao Pan,Yang Ouyang,Zhiqiang Gao,Shufei Zhang,Sumon Biswas*

Main category: cs.AI

TL;DR: 提出了PTA-GRPO框架，通过两阶段方法改进大语言模型的推理能力：第一阶段用高级LLM提炼思维链为紧凑高层指导，第二阶段引入指导感知的强化学习方法联合优化最终输出和高层指导质量。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的推理过程受限于自回归的token级生成，缺乏全局规划，导致推理冗余、不连贯或不准确。现有方法如树搜索和强化学习计算成本高且难以产生最优推理轨迹。

Method: 两阶段框架：1) 用高级LLM将思维链蒸馏为紧凑高层指导进行监督微调；2) 引入指导感知的强化学习方法，联合优化最终输出和高层指导质量。

Result: 在多个数学推理基准测试（MATH、AIME2024、AIME2025、AMC）和不同基础模型（Qwen2.5-7B-Instruct、Qwen3-8B、Qwen3-14B、LLaMA3.2-3B）上，PTA-GRPO均实现了稳定且显著的性能提升。

Conclusion: PTA-GRPO框架能有效提升大语言模型的推理能力，在不同模型和任务上都具有良好的泛化性能。

Abstract: Large language models (LLMs) have demonstrated remarkable reasoning abilities
in complex tasks, often relying on Chain-of-Thought (CoT) reasoning. However,
due to their autoregressive token-level generation, the reasoning process is
largely constrained to local decision-making and lacks global planning. This
limitation frequently results in redundant, incoherent, or inaccurate
reasoning, which significantly degrades overall performance. Existing
approaches, such as tree-based algorithms and reinforcement learning (RL),
attempt to address this issue but suffer from high computational costs and
often fail to produce optimal reasoning trajectories. To tackle this challenge,
we propose Plan-Then-Action Enhanced Reasoning with Group Relative Policy
Optimization PTA-GRPO, a two-stage framework designed to improve both
high-level planning and fine-grained CoT reasoning. In the first stage, we
leverage advanced LLMs to distill CoT into compact high-level guidance, which
is then used for supervised fine-tuning (SFT). In the second stage, we
introduce a guidance-aware RL method that jointly optimizes the final output
and the quality of high-level guidance, thereby enhancing reasoning
effectiveness. We conduct extensive experiments on multiple mathematical
reasoning benchmarks, including MATH, AIME2024, AIME2025, and AMC, across
diverse base models such as Qwen2.5-7B-Instruct, Qwen3-8B, Qwen3-14B, and
LLaMA3.2-3B. Experimental results demonstrate that PTA-GRPO consistently
achieves stable and significant improvements across different models and tasks,
validating its effectiveness and generalization.

</details>


### [40] [Learning a Dense Reasoning Reward Model from Expert Demonstration via Inverse Reinforcement Learning](https://arxiv.org/abs/2510.01857)
*Claudio Fanconi,Nicolás Astorga,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 该论文提出了一种对抗性逆强化学习方法，用于学习密集的token级奖励模型，为语言模型推理提供过程监督。该奖励模型在训练时优化推理策略，在推理时作为评判器对采样轨迹进行重排序。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过监督微调模仿专家风格，但本文旨在直接从专家演示中学习推理奖励，优先考虑正确性而非表面形式，实现可解释的错误定位。

Method: 使用对抗性逆强化学习框架，学习密集的token级奖励模型。该模型在训练时提供步骤级反馈优化推理策略，在推理时作为评判器对采样轨迹进行重排序。

Result: 在GSM8K数据集上，使用Llama3和Qwen2.5骨干网络，证明：(i) 密集推理奖励可作为学习信号激发推理；(ii) 通过奖励引导的重排序提高了预测性能（特别是基于Llama的策略）。

Conclusion: 通过将训练信号、推理时选择和token级诊断统一到单一推理奖励中，这项工作表明可重用的过程级奖励具有增强语言模型中多步推理的广泛潜力。

Abstract: We reframe and operationalise adversarial inverse reinforcement learning
(IRL) to large language model reasoning, learning a dense, token-level reward
model for process supervision directly from expert demonstrations rather than
imitating style via supervised fine-tuning. The learned reasoning reward serves
two complementary roles: (i) it provides step-level feedback to optimise a
reasoning policy during training; and (ii) it functions at inference as a
critic to rerank sampled traces under fixed compute budgets. We demonstrate
that our approach prioritises correctness over surface form, yielding scores
that correlate with eventual answer validity and enabling interpretable
localisation of errors within a trace. Empirically, on GSM8K with Llama3 and
Qwen2.5 backbones, we demonstrate: (i) dense reasoning rewards can be used as a
learning signal to elicit reasoning, and (ii) predictive performance is
improved from reward-guided reranking (notably for Llama-based policies). By
unifying training signals, inference-time selection, and token-level
diagnostics into a single reasoning reward, this work suggests reusable
process-level rewards with broad potential to enhance multi-step reasoning in
language models.

</details>


### [41] [Constrained Adaptive Rejection Sampling](https://arxiv.org/abs/2510.01902)
*Paweł Parys,Sairam Vaidya,Taylor Berg-Kirkpatrick,Loris D'Antoni*

Main category: cs.AI

TL;DR: 提出CARS方法，在保持语言模型分布不变的前提下，通过自适应剪枝技术提高约束生成的采样效率


<details>
  <summary>Details</summary>
Motivation: 现有约束生成方法存在两难：贪婪解码会扭曲语言模型分布，而拒绝采样则计算效率低下。在程序模糊测试等需要同时保证有效性和多样性的领域，这两种方法都有问题

Method: CARS从无约束语言模型采样开始，通过构建trie数据结构自适应地排除违反约束的后续生成，从未来采样中减去这些无效路径的概率质量

Result: 在程序模糊测试和分子生成等多个领域的实验中，CARS在采样效率（每个有效样本所需的语言模型前向传递次数）和样本多样性方面均优于现有方法

Conclusion: CARS方法严格提升了拒绝采样的效率，同时保持了语言模型的原始分布，为需要高质量约束生成的领域提供了有效的解决方案

Abstract: Language Models (LMs) are increasingly used in applications where generated
outputs must satisfy strict semantic or syntactic constraints. Existing
approaches to constrained generation fall along a spectrum: greedy constrained
decoding methods enforce validity during decoding but distort the LM's
distribution, while rejection sampling (RS) preserves fidelity but wastes
computation by discarding invalid outputs. Both extremes are problematic in
domains such as program fuzzing, where both validity and diversity of samples
are essential. We present Constrained Adaptive Rejection Sampling (CARS), an
approach that strictly improves the sample-efficiency of RS without
distributional distortion. CARS begins with unconstrained LM sampling and
adaptively rules out constraint-violating continuations by recording them in a
trie and subtracting their probability mass from future draws. This adaptive
pruning ensures that prefixes proven invalid are never revisited, acceptance
rates improve monotonically, and the resulting samples exactly follow the
constrained distribution. In experiments on a variety of domains -- e.g.,
program fuzzing and molecular generation -- CARS consistently achieves higher
efficiency -- measured in the number of LM forward passes per valid sample --
while also producing stronger sample diversity than both GCD and methods that
approximate the LM's distribution.

</details>


### [42] [To Mask or to Mirror: Human-AI Alignment in Collective Reasoning](https://arxiv.org/abs/2510.01924)
*Crystal Qian,Aaron Parisi,Clémentine Bouleau,Vivian Tsai,Maël Lebreton,Lucas Dixon*

Main category: cs.AI

TL;DR: 本文提出了一个评估LLM与人类集体决策对齐的框架，通过Lost at Sea心理学实验发现不同LLM在集体推理中的行为差异：有些模仿人类偏见，有些则试图补偿这些偏见。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地用于建模和增强集体决策，需要检验它们与人类社会推理的对齐程度，特别是集体层面的对齐，而非个体层面。

Method: 使用Lost at Sea社会心理学任务进行大规模在线实验（N=748），随机分配小组进行有可见人口属性或匿名别名的领导者选举，然后基于人类数据模拟匹配的LLM小组，对Gemini 2.5、GPT 4.1、Claude Haiku 3.5和Gemma 3进行基准测试。

Result: LLM行为出现分化：有些镜像人类偏见；有些掩盖这些偏见并试图补偿。人类-AI在集体推理中的对齐取决于上下文、线索和模型特定的归纳偏见。

Conclusion: 理解LLM如何与集体人类行为对齐对于推进社会对齐的AI至关重要，需要能够捕捉集体推理复杂性的动态基准。

Abstract: As large language models (LLMs) are increasingly used to model and augment
collective decision-making, it is critical to examine their alignment with
human social reasoning. We present an empirical framework for assessing
collective alignment, in contrast to prior work on the individual level. Using
the Lost at Sea social psychology task, we conduct a large-scale online
experiment (N=748), randomly assigning groups to leader elections with either
visible demographic attributes (e.g. name, gender) or pseudonymous aliases. We
then simulate matched LLM groups conditioned on the human data, benchmarking
Gemini 2.5, GPT 4.1, Claude Haiku 3.5, and Gemma 3. LLM behaviors diverge: some
mirror human biases; others mask these biases and attempt to compensate for
them. We empirically demonstrate that human-AI alignment in collective
reasoning depends on context, cues, and model-specific inductive biases.
Understanding how LLMs align with collective human behavior is critical to
advancing socially-aligned AI, and demands dynamic benchmarks that capture the
complexities of collective reasoning.

</details>


### [43] [ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly Detection](https://arxiv.org/abs/2510.02060)
*Sanghyu Yoon,Dongmin Kim,Suhee Yoon,Ye Seul Sim,Seungdong Yoa,Hye-Seung Cho,Soonyoung Lee,Hankook Lee,Woohyung Lim*

Main category: cs.AI

TL;DR: ReTabAD是一个为表格异常检测恢复文本语义的基准框架，提供20个带有结构化文本元数据的表格数据集和多种异常检测算法实现，包括零样本LLM框架，证明语义上下文能提升检测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有表格异常检测基准缺乏文本语义上下文，忽略了特征描述和领域知识等关键信息，限制了模型充分利用领域知识进行检测的能力。

Method: 提供20个精心策划的表格数据集，包含结构化文本元数据，并实现包括经典方法、深度学习和LLM方法在内的最先进异常检测算法，以及无需任务特定训练的零样本LLM框架。

Result: 实验结果表明语义上下文能提高检测性能，并通过支持领域感知推理增强可解释性。

Conclusion: ReTabAD为系统探索上下文感知的异常检测建立了基准，展示了文本元数据在异常检测中的作用和实用性。

Abstract: In tabular anomaly detection (AD), textual semantics often carry critical
signals, as the definition of an anomaly is closely tied to domain-specific
context. However, existing benchmarks provide only raw data points without
semantic context, overlooking rich textual metadata such as feature
descriptions and domain knowledge that experts rely on in practice. This
limitation restricts research flexibility and prevents models from fully
leveraging domain knowledge for detection. ReTabAD addresses this gap by
restoring textual semantics to enable context-aware tabular AD research. We
provide (1) 20 carefully curated tabular datasets enriched with structured
textual metadata, together with implementations of state-of-the-art AD
algorithms including classical, deep learning, and LLM-based approaches, and
(2) a zero-shot LLM framework that leverages semantic context without
task-specific training, establishing a strong baseline for future research.
Furthermore, this work provides insights into the role and utility of textual
metadata in AD through experiments and analysis. Results show that semantic
context improves detection performance and enhances interpretability by
supporting domain-aware reasoning. These findings establish ReTabAD as a
benchmark for systematic exploration of context-aware AD.

</details>


### [44] [Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning](https://arxiv.org/abs/2510.02091)
*Xinyuan Song,Keyu Wang,PengXiang Li,Lu Yin,Shiwei Liu*

Main category: cs.AI

TL;DR: 对LLM深度层作用的研究发现，深层贡献因评估设置而异：似然评估中仅需浅层，而生成评估中深层对推理和连贯性至关重要


<details>
  <summary>Details</summary>
Motivation: 现有研究认为LLM深层对表示学习贡献有限且可移除，但这些结论基于有限评估，可能忽略了模型行为的重要方面

Method: 系统研究深度利用的多个维度，包括评估协议、任务类别和模型架构，分析不同层在不同设置下的贡献

Result: 知识检索集中在浅层，推理准确性依赖深层但可通过蒸馏重塑；深度使用高度异质且依赖上下文

Conclusion: LLM中深度使用高度异质且依赖上下文，强调在解释和压缩大模型时需要任务、度量和模型感知的视角

Abstract: Recent studies suggest that the deeper layers of Large Language Models (LLMs)
contribute little to representation learning and can often be removed without
significant performance loss. However, such claims are typically drawn from
narrow evaluations and may overlook important aspects of model behavior. In
this work, we present a systematic study of depth utilization across diverse
dimensions, including evaluation protocols, task categories, and model
architectures. Our analysis confirms that very deep layers are generally less
effective than earlier ones, but their contributions vary substantially with
the evaluation setting. Under likelihood-based metrics without generation,
pruning most layers preserves performance, with only the initial few being
critical. By contrast, generation-based evaluation uncovers indispensable roles
for middle and deeper layers in enabling reasoning and maintaining long-range
coherence. We further find that knowledge and retrieval are concentrated in
shallow components, whereas reasoning accuracy relies heavily on deeper layers
-- yet can be reshaped through distillation. These results highlight that depth
usage in LLMs is highly heterogeneous and context-dependent, underscoring the
need for task-, metric-, and model-aware perspectives in both interpreting and
compressing large models.

</details>


### [45] [Do AI Models Perform Human-like Abstract Reasoning Across Modalities?](https://arxiv.org/abs/2510.02125)
*Claas Beger,Ryan Yi,Shuhao Fu,Arseny Moskvichev,Sarah W. Tsai,Sivasankaran Rajamanickam,Melanie Mitchell*

Main category: cs.AI

TL;DR: 论文评估AI模型在ConceptARC任务上的抽象推理能力，发现仅基于准确率的评估会高估文本模态的抽象推理能力，低估视觉模态的抽象推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管OpenAI的o3-preview推理模型在ARC-AGI基准上超过了人类准确率，但作者质疑模型是否真正理解和使用了任务设计者预期的抽象概念。

Method: 在ConceptARC上评估模型，改变输入模态（文本vs视觉）、是否允许使用外部Python工具、以及推理模型的推理努力程度。除了测量输出准确率，还对模型生成的自然语言规则进行细粒度评估。

Result: 使用文本表示的一些模型在输出准确率上达到人类水平，但最佳模型的规则通常基于表面级"捷径"，很少捕捉到预期的抽象概念。在视觉模态中，AI模型的输出准确率大幅下降，但规则分析显示模型仍能生成相当比例的捕捉预期抽象的规则，只是无法正确应用这些规则。

Conclusion: 模型在抽象推理方面仍落后于人类，仅使用准确率评估ARC类任务的抽象推理能力可能会高估文本模态的抽象推理能力，低估视觉模态的抽象推理能力。作者提出的评估框架能更准确地反映多模态模型的抽象推理能力。

Abstract: OpenAI's o3-preview reasoning model exceeded human accuracy on the ARC-AGI
benchmark, but does that mean state-of-the-art models recognize and reason with
the abstractions that the task creators intended? We investigate models'
abstraction abilities on ConceptARC. We evaluate models under settings that
vary the input modality (textual vs. visual), whether the model is permitted to
use external Python tools, and, for reasoning models, the amount of reasoning
effort. In addition to measuring output accuracy, we perform fine-grained
evaluation of the natural-language rules that models generate to explain their
solutions. This dual evaluation lets us assess whether models solve tasks using
the abstractions ConceptARC was designed to elicit, rather than relying on
surface-level patterns. Our results show that, while some models using
text-based representations match human output accuracy, the best models' rules
are often based on surface-level ``shortcuts'' and capture intended
abstractions far less often than humans. Thus their capabilities for general
abstract reasoning may be overestimated by evaluations based on accuracy alone.
In the visual modality, AI models' output accuracy drops sharply, yet our
rule-level analysis reveals that models might be underestimated, as they still
exhibit a substantial share of rules that capture intended abstractions, but
are often unable to correctly apply these rules. In short, our results show
that models still lag humans in abstract reasoning, and that using accuracy
alone to evaluate abstract reasoning on ARC-like tasks may overestimate
abstract-reasoning capabilities in textual modalities and underestimate it in
visual modalities. We believe that our evaluation framework offers a more
faithful picture of multimodal models' abstract reasoning abilities and a more
principled way to track progress toward human-like, abstraction-centered
intelligence.

</details>


### [46] [FlexDoc: Parameterized Sampling for Diverse Multilingual Synthetic Documents for Training Document Understanding Models](https://arxiv.org/abs/2510.02133)
*Karan Dua,Hitesh Laxmichand Patel,Puneet Mittal,Ranjeet Gupta,Amit Agarwal,Praneet Pabolu,Srikant Panda,Hansa Meghwani,Graham Horwood,Fahad Shah*

Main category: cs.AI

TL;DR: FlexDoc是一个可扩展的合成数据生成框架，通过随机模式和参数化采样生成多语言半结构化文档，显著降低文档理解模型的标注成本。


<details>
  <summary>Details</summary>
Motivation: 企业级文档理解模型需要大规模、多样化的标注数据，但传统数据收集方法面临隐私限制、法律约束和高昂的人工标注成本（可达数百万美元）。

Method: 结合随机模式和参数化采样，通过概率建模布局模式、视觉结构和内容变异性，实现可控的大规模文档变体生成。

Result: 在关键信息提取任务中，使用FlexDoc生成的数据可将F1分数提升高达11%，同时相比传统硬模板方法减少90%以上的标注工作量。

Conclusion: FlexDoc已在实际部署中加速了企业级文档理解模型的开发，同时显著降低了数据获取和标注成本。

Abstract: Developing document understanding models at enterprise scale requires large,
diverse, and well-annotated datasets spanning a wide range of document types.
However, collecting such data is prohibitively expensive due to privacy
constraints, legal restrictions, and the sheer volume of manual annotation
needed - costs that can scale into millions of dollars. We introduce FlexDoc, a
scalable synthetic data generation framework that combines Stochastic Schemas
and Parameterized Sampling to produce realistic, multilingual semi-structured
documents with rich annotations. By probabilistically modeling layout patterns,
visual structure, and content variability, FlexDoc enables the controlled
generation of diverse document variants at scale. Experiments on Key
Information Extraction (KIE) tasks demonstrate that FlexDoc-generated data
improves the absolute F1 Score by up to 11% when used to augment real datasets,
while reducing annotation effort by over 90% compared to traditional
hard-template methods. The solution is in active deployment, where it has
accelerated the development of enterprise-grade document understanding models
while significantly reducing data acquisition and annotation costs.

</details>


### [47] [A Rigorous Benchmark with Multidimensional Evaluation for Deep Research Agents: From Answers to Reports](https://arxiv.org/abs/2510.02190)
*Yang Yao,Yixu Wang,Yuxuan Zhang,Yi Lu,Tianle Gu,Lingyu Li,Dingyi Zhao,Keming Wu,Haozhe Wang,Ping Nie,Yan Teng,Yingchun Wang*

Main category: cs.AI

TL;DR: 本文提出了一个专门针对深度研究代理的严格基准和多维评估框架，包含214个专家策划的挑战性查询和手动构建的参考包，用于全面评估长格式报告的质量。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估维度、响应格式和评分机制方面存在不足，无法有效评估从封闭语言模型转向具有外部感知和信息整合能力的互联代理系统。

Method: 开发了一个包含214个专家策划查询的基准，分布在10个主题领域，并构建了多维评估框架，整合了语义质量、主题聚焦和检索可信度的评分指标。

Result: 实验证实主流深度研究代理优于基于网络搜索工具增强的推理模型，但仍存在显著的改进空间。

Conclusion: 本研究为深度研究代理系统的能力评估、架构改进和范式进步提供了坚实基础。

Abstract: Artificial intelligence is undergoing the paradigm shift from closed language
models to interconnected agent systems capable of external perception and
information integration. As a representative embodiment, Deep Research Agents
(DRAs) systematically exhibit the capabilities for task decomposition,
cross-source retrieval, multi-stage reasoning, and structured output, which
markedly enhance performance on complex and open-ended tasks. However, existing
benchmarks remain deficient in evaluation dimensions, response formatting, and
scoring mechanisms, limiting their capacity to assess such systems effectively.
This paper introduces a rigorous benchmark and a multidimensional evaluation
framework tailored to DRAs and report-style responses. The benchmark comprises
214 expert-curated challenging queries distributed across 10 broad thematic
domains, each accompanied by manually constructed reference bundles to support
composite evaluation. The framework enables comprehensive evaluation of
long-form reports generated by DRAs, incorporating integrated scoring metrics
for semantic quality, topical focus, and retrieval trustworthiness. Extensive
experimentation confirms the superior performance of mainstream DRAs over
web-search-tool-augmented reasoning models, yet reveals considerable scope for
further improvement. This study provides a robust foundation for capability
assessment, architectural refinement, and paradigm advancement in DRA systems.

</details>


### [48] [UpSafe$^\circ$C: Upcycling for Controllable Safety in Large Language Models](https://arxiv.org/abs/2510.02194)
*Yuhao Sun,Zhuoer Xu,Shiwen Cui,Kun Yang,Lingyun Yu,Yongdong Zhang,Hongtao Xie*

Main category: cs.AI

TL;DR: 提出了UpSafe°C框架，通过安全感知的升级改造来增强LLM安全性，使用稀疏MoE结构和安全温度机制实现动态安全控制


<details>
  <summary>Details</summary>
Motivation: 现有安全技术（外部护栏、推理时指导和后训练对齐）在平衡安全性、实用性和可控性方面存在局限性，需要更灵活的安全解决方案

Method: 识别安全关键层并将其升级为稀疏MoE结构，路由器作为软护栏选择性激活原始MLP和新增安全专家；采用两阶段SFT策略；引入安全温度机制实现推理时动态控制

Result: 在多个基准测试、基础模型和模型规模上实现了对有害和越狱输入的鲁棒安全改进，同时在通用任务上保持竞争力；安全温度实现了效用和安全性的帕累托最优边界

Conclusion: 为LLM安全提供了新方向：从静态对齐转向动态、模块化和推理感知的控制

Abstract: Large Language Models (LLMs) have achieved remarkable progress across a wide
range of tasks, but remain vulnerable to safety risks such as harmful content
generation and jailbreak attacks. Existing safety techniques -- including
external guardrails, inference-time guidance, and post-training alignment --
each face limitations in balancing safety, utility, and controllability. In
this work, we propose UpSafe$^\circ$C, a unified framework for enhancing LLM
safety through safety-aware upcycling. Our approach first identifies
safety-critical layers and upcycles them into a sparse Mixture-of-Experts (MoE)
structure, where the router acts as a soft guardrail that selectively activates
original MLPs and added safety experts. We further introduce a two-stage SFT
strategy to strengthen safety discrimination while preserving general
capabilities. To enable flexible control at inference time, we introduce a
safety temperature mechanism, allowing dynamic adjustment of the trade-off
between safety and utility. Experiments across multiple benchmarks, base model,
and model scales demonstrate that UpSafe$^\circ$C achieves robust safety
improvements against harmful and jailbreak inputs, while maintaining
competitive performance on general tasks. Moreover, analysis shows that safety
temperature provides fine-grained inference-time control that achieves the
Pareto-optimal frontier between utility and safety. Our results highlight a new
direction for LLM safety: moving from static alignment toward dynamic, modular,
and inference-aware control.

</details>


### [49] [The Reasoning Boundary Paradox: How Reinforcement Learning Constrains Language Models](https://arxiv.org/abs/2510.02230)
*Phuc Minh Nguyen,Chinh D. La,Duy M. H. Nguyen,Nitesh V. Chawla,Binh T. Nguyen,Khoa D. Doan*

Main category: cs.AI

TL;DR: 研究发现强化学习与可验证奖励(RLVR)会缩小而非扩大语言模型的推理边界，揭示了负干扰和赢家通吃现象，并提出针对低概率问题的数据筛选算法来提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管RLVR被用于提升大语言模型的推理能力，但近期证据表明它可能反而会缩小推理边界，本研究旨在探究这一收缩问题的原因。

Method: 通过理论分析和在多个数学推理基准上的实证研究，揭示了RLVR学习动态中的负干扰和赢家通吃现象，并提出了专注于低概率问题的数据筛选算法。

Result: 研究发现RLVR存在负干扰（学习某些问题会降低其他问题的正确解决概率）和赢家通吃现象（过度强化高概率问题而抑制低概率问题），提出的数据筛选算法显著提升了Pass@k性能。

Conclusion: RLVR的收缩问题源于标准强化学习目标中的内在策略采样，导致模型收敛于狭窄的解决策略，通过专注于低概率问题的数据筛选可以有效缓解这一问题。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key
method for improving Large Language Models' reasoning capabilities, yet recent
evidence suggests it may paradoxically shrink the reasoning boundary rather
than expand it. This paper investigates the shrinkage issue of RLVR by
analyzing its learning dynamics and reveals two critical phenomena that explain
this failure. First, we expose negative interference in RLVR, where learning to
solve certain training problems actively reduces the likelihood of correct
solutions for others, leading to the decline of Pass@$k$ performance, or the
probability of generating a correct solution within $k$ attempts. Second, we
uncover the winner-take-all phenomenon: RLVR disproportionately reinforces
problems with high likelihood, correct solutions, under the base model, while
suppressing other initially low-likelihood ones. Through extensive theoretical
and empirical analysis on multiple mathematical reasoning benchmarks, we show
that this effect arises from the inherent on-policy sampling in standard RL
objectives, causing the model to converge toward narrow solution strategies.
Based on these insights, we propose a simple yet effective data curation
algorithm that focuses RLVR learning on low-likelihood problems, achieving
notable improvement in Pass@$k$ performance. Our code is available at
https://github.com/mail-research/SELF-llm-interference.

</details>


### [50] [The Unreasonable Effectiveness of Scaling Agents for Computer Use](https://arxiv.org/abs/2510.02250)
*Gonzalo Gonzalez-Pumariega,Vincent Tu,Chih-Lun Lee,Jiachen Yang,Ang Li,Xin Eric Wang*

Main category: cs.AI

TL;DR: 提出了Behavior Best-of-N (bBoN)方法，通过生成多个执行轨迹并使用行为叙事进行选择，显著提升了计算机使用代理在复杂任务中的成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理在自动化日常数字任务方面具有潜力，但其不可靠性和高方差阻碍了在长期复杂任务中的应用。

Method: bBoN方法通过生成多个执行轨迹，并使用描述代理执行过程的行为叙事来进行轨迹选择，实现广泛探索和原则性选择。

Result: 在OSWorld上达到69.9%的最新水平，显著优于先前方法，接近人类72%的水平，并在WindowsAgentArena和AndroidWorld上展示出强泛化能力。

Conclusion: 当正确实施时，扩展计算机使用代理具有显著效果，有效扩展需要结构化的轨迹理解和选择，bBoN为此提供了实用框架。

Abstract: Computer-use agents (CUAs) hold promise for automating everyday digital
tasks, but their unreliability and high variance hinder their application to
long-horizon, complex tasks. We introduce Behavior Best-of-N (bBoN), a method
that scales over agents by generating multiple rollouts and selecting among
them using behavior narratives that describe the agents' rollouts. It enables
both wide exploration and principled trajectory selection, substantially
improving robustness and success rates. On OSWorld, our bBoN scaling method
establishes a new state of the art (SoTA) at 69.9%, significantly outperforming
prior methods and approaching human-level performance at 72%, with
comprehensive ablations validating key design choices. We further demonstrate
strong generalization results to different operating systems on
WindowsAgentArena and AndroidWorld. Crucially, our results highlight the
unreasonable effectiveness of scaling CUAs, when you do it right: effective
scaling requires structured trajectory understanding and selection, and bBoN
provides a practical framework to achieve this.

</details>


### [51] [RLAD: Training LLMs to Discover Abstractions for Solving Reasoning Problems](https://arxiv.org/abs/2510.02263)
*Yuxiao Qu,Anikait Singh,Yoonho Lee,Amrith Setlur,Ruslan Salakhutdinov,Chelsea Finn,Aviral Kumar*

Main category: cs.AI

TL;DR: 提出RLAD方法，通过推理抽象来引导模型学习有效的推理过程，采用两玩家强化学习训练抽象生成器和解决方案生成器


<details>
  <summary>Details</summary>
Motivation: 当前大模型在推理过程中缺乏对算法性程序的一致捕获和重用，容易陷入冗长和退化的探索

Method: 引入推理抽象概念，训练模型为问题提出多个抽象，然后使用强化学习激励在抽象信息基础上构建解决方案

Result: RLAD方法实现了结构化探索，解耦了抽象提议和解决方案生成的学习信号，并提高了对更难问题的泛化能力

Conclusion: 推理抽象能有效引导有意义的探索，在测试时分配更多计算资源生成抽象比生成更多解决方案更有利于性能提升

Abstract: Reasoning requires going beyond pattern matching or memorization of solutions
to identify and implement "algorithmic procedures" that can be used to deduce
answers to hard problems. Doing so requires realizing the most relevant
primitives, intermediate results, or shared procedures, and building upon them.
While RL post-training on long chains of thought ultimately aims to uncover
this kind of algorithmic behavior, most reasoning traces learned by large
models fail to consistently capture or reuse procedures, instead drifting into
verbose and degenerate exploration. To address more effective reasoning, we
introduce reasoning abstractions: concise natural language descriptions of
procedural and factual knowledge that guide the model toward learning
successful reasoning. We train models to be capable of proposing multiple
abstractions given a problem, followed by RL that incentivizes building a
solution while using the information provided by these abstractions. This
results in a two-player RL training paradigm, abbreviated as RLAD, that jointly
trains an abstraction generator and a solution generator. This setup
effectively enables structured exploration, decouples learning signals of
abstraction proposal and solution generation, and improves generalization to
harder problems. We also show that allocating more test-time compute to
generating abstractions is more beneficial for performance than generating more
solutions at large test budgets, illustrating the role of abstractions in
guiding meaningful exploration.

</details>


### [52] [BioX-Bridge: Model Bridging for Unsupervised Cross-Modal Knowledge Transfer across Biosignals](https://arxiv.org/abs/2510.02276)
*Chenqi Li,Yu Liu,Timothy Denison,Tingting Zhu*

Main category: cs.AI

TL;DR: 提出BioX-Bridge框架，通过轻量级桥接网络实现生物信号跨模态知识迁移，大幅减少可训练参数(88-99%)，同时保持或提升迁移性能。


<details>
  <summary>Details</summary>
Motivation: 解决生物信号跨模态知识迁移中计算和内存开销大的问题，特别是面对大型基础模型时的挑战。

Method: 训练轻量级桥接网络对齐中间表示，实现基础模型间的跨模态信息流动，包含高效的桥接位置选择策略和灵活的原型网络架构。

Result: 在多个生物信号模态、任务和数据集上的实验表明，BioX-Bridge相比现有方法显著减少训练参数，同时保持或提升性能。

Conclusion: BioX-Bridge为生物信号跨模态知识迁移提供了高效解决方案，特别适合大型基础模型的应用场景。

Abstract: Biosignals offer valuable insights into the physiological states of the human
body. Although biosignal modalities differ in functionality, signal fidelity,
sensor comfort, and cost, they are often intercorrelated, reflecting the
holistic and interconnected nature of human physiology. This opens up the
possibility of performing the same tasks using alternative biosignal
modalities, thereby improving the accessibility, usability, and adaptability of
health monitoring systems. However, the limited availability of large labeled
datasets presents challenges for training models tailored to specific tasks and
modalities of interest. Unsupervised cross-modal knowledge transfer offers a
promising solution by leveraging knowledge from an existing modality to support
model training for a new modality. Existing methods are typically based on
knowledge distillation, which requires running a teacher model alongside
student model training, resulting in high computational and memory overhead.
This challenge is further exacerbated by the recent development of foundation
models that demonstrate superior performance and generalization across tasks at
the cost of large model sizes. To this end, we explore a new framework for
unsupervised cross-modal knowledge transfer of biosignals by training a
lightweight bridge network to align the intermediate representations and enable
information flow between foundation models and across modalities. Specifically,
we introduce an efficient strategy for selecting alignment positions where the
bridge should be constructed, along with a flexible prototype network as the
bridge architecture. Extensive experiments across multiple biosignal
modalities, tasks, and datasets show that BioX-Bridge reduces the number of
trainable parameters by 88--99\% while maintaining or even improving transfer
performance compared to state-of-the-art methods.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [53] [Cautions on Tail Index Regressions](https://arxiv.org/abs/2510.01535)
*Thomas T. Yang*

Main category: econ.EM

TL;DR: 重新审视尾指数回归，发现极端结果条件下回归变量可能退化，条件分布集中在尾指数最小化点，非参数回归收敛速度缓慢


<details>
  <summary>Details</summary>
Motivation: 重新研究尾指数回归方法，发现在极端结果条件下传统线性回归的满秩条件可能失效，需要深入理解这种退化现象

Method: 分析线性尾指数回归的满秩条件失效原因，研究协变量条件分布在尾部的集中特性，探讨非参数尾指数回归的收敛速度

Result: 发现条件协变量分布集中在尾指数最小化点，远离这些点时条件密度趋近于零，非参数回归收敛速度可能非常缓慢

Conclusion: 为应用研究提供实用建议，强调在尾指数回归中需要注意变量退化问题和收敛速度限制

Abstract: We revisit tail-index regressions. For linear specifications, we find that
the usual full-rank condition can fail because conditioning on extreme outcomes
causes regressors to degenerate to constants. More generally, the conditional
distribution of the covariates in the tails concentrates on the values at which
the tail index is minimized. Away from those points, the conditional density
tends to zero. For local nonparametric tail index regression, the convergence
rate can be very slow. We conclude with practical suggestions for applied work.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [54] [Discovering Self-Regulated Learning Patterns in Chatbot-Powered Education Environment](https://arxiv.org/abs/2510.01275)
*Yilin Lyu,Ren Ding*

Main category: cs.CY

TL;DR: 本研究提出了Gen-SRL标注框架来分析学生与聊天机器人互动中的自我调节学习行为，发现学生主要关注任务执行而缺乏规划和反思，且学习过程呈现非序列性模式。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具在教育中的普及，需要了解学生如何在与聊天机器人互动中进行自我调节学习，但现有SRL理论难以捕捉真实互动中的动态模式。

Method: 提出Gen-SRL标注框架，将学生提示分为4个宏观阶段和16个微观行为，对212个真实英语写作任务中的聊天机器人互动进行标注，使用频率分析和过程挖掘技术分析SRL模式。

Result: 学生SRL行为不平衡，82%以上行为集中在任务执行阶段，规划和反思参与有限；过程分析显示非序列性调节模式。

Conclusion: 经典SRL理论无法完全捕捉聊天机器人互动中的动态SRL模式，需要设计适应学生动态行为的个性化支架，为SRL研究和聊天机器人开发提供新视角。

Abstract: The increasing adoption of generative AI (GenAI) tools such as chatbots in
education presents new opportunities to support students' self-regulated
learning (SRL), but also raises concerns about how learners actually engage in
planning, executing, and reflection when learning with a chatbot. While SRL is
typically conceptualized as a sequential process, little is known about how it
unfolds during real-world student-chatbot interactions. To explore this, we
proposed Gen-SRL, an annotation schema to categorize student prompts into 16
microlevel actions across 4 macrolevel phases. Using the proposed schema, we
annotated 212 chatbot interactions from a real-world English writing task. We
then performed frequency analysis and process mining (PM) techniques to
discover SRL patterns in depth. Our results revealed that students' SRL
behaviours were imbalanced, with over 82% of actions focused on task execution
and limited engagement in planning and reflection. In addition, the process
analysis showed nonsequential regulation patterns. Our findings suggest that
classical SRL theories cannot fully capture the dynamic SRL patterns that
emerge during chatbot interactions. Furthermore, we highlight the importance of
designing adaptive and personalized scaffolds that respond to students' dynamic
behaviours in chatbot-powered contexts. More importantly, this study offers a
new perspective for advancing SRL research and suggests directions for
developing chatbots that better support self-regulation.

</details>


### [55] [An Analysis of the New EU AI Act and A Proposed Standardization Framework for Machine Learning Fairness](https://arxiv.org/abs/2510.01281)
*Mike Teodorescu,Yongxu Sun,Haren N. Bhatia,Christos Makridis*

Main category: cs.CY

TL;DR: 欧盟AI法案缺乏可量化的公平性指标，术语模糊，存在重大责任风险，建议制定更精准的监管框架和公平透明度评估系统。


<details>
  <summary>Details</summary>
Motivation: 欧盟AI法案在伦理AI监管方面迈出重要一步，但存在术语模糊和缺乏量化公平指标的问题，这可能导致责任风险并阻碍投资。

Method: 分析欧盟AI法案中的术语模糊问题，提出定制化监管框架建议，并设计公平透明度评估系统框架，以ASR和语音合成器为例进行说明。

Result: 发现法案中透明度、可解释性和可理解性等术语被互换使用，缺乏伦理合规透明度参考，这造成了监管不确定性。

Conclusion: 需要在广泛监管基础上标准化行业最佳实践，在保持创新和投资的同时实现所需的监管细节水平。

Abstract: The European Union's AI Act represents a crucial step towards regulating
ethical and responsible AI systems. However, we find an absence of quantifiable
fairness metrics and the ambiguity in terminology, particularly the
interchangeable use of the keywords transparency, explainability, and
interpretability in the new EU AI Act and no reference of transparency of
ethical compliance. We argue that this ambiguity creates substantial liability
risk that would deter investment. Fairness transparency is strategically
important. We recommend a more tailored regulatory framework to enhance the new
EU AI regulation. Further-more, we propose a public system framework to assess
the fairness and transparency of AI systems. Drawing from past work, we
advocate for the standardization of industry best practices as a necessary
addition to broad regulations to achieve the level of details required in
industry, while preventing stifling innovation and investment in the AI sector.
The proposals are exemplified with the case of ASR and speech synthesizers.

</details>


### [56] [Emergent evaluation hubs in a decentralizing large language model ecosystem](https://arxiv.org/abs/2510.01286)
*Manuel Cebrian,Tomomi Kito,Raul Castro Fernandez*

Main category: cs.CY

TL;DR: 研究发现大语言模型生态系统呈现分化趋势：模型创建日益分散和多样化，而基准测试影响力却高度集中，少数国家和机构主导了评估标准。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型与其基准测试两个层面的聚合模式是否同步演化，分析生态系统中的集中与分散动态。

Method: 使用斯坦福基础模型生态系统图和Evidently AI基准注册表作为代理指标，构建基准作者机构网络，并采用基于代理的模拟分析机制。

Result: 模型创建在地域、组织和特性上更加多样化，而基准影响力高度集中：前15%节点占80%高介数路径，3个国家产出83%基准，基准权威性基尼系数达0.89。

Conclusion: 集中的基准影响力作为协调基础设施，支持标准化和可复现性，但也带来路径依赖、选择性可见性和判别力下降等权衡。

Abstract: Large language models are proliferating, and so are the benchmarks that serve
as their common yardsticks. We ask how the agglomeration patterns of these two
layers compare: do they evolve in tandem or diverge? Drawing on two curated
proxies for the ecosystem, the Stanford Foundation-Model Ecosystem Graph and
the Evidently AI benchmark registry, we find complementary but contrasting
dynamics. Model creation has broadened across countries and organizations and
diversified in modality, licensing, and access. Benchmark influence, by
contrast, displays centralizing patterns: in the inferred
benchmark-author-institution network, the top 15% of nodes account for over 80%
of high-betweenness paths, three countries produce 83% of benchmark outputs,
and the global Gini for inferred benchmark authority reaches 0.89. An
agent-based simulation highlights three mechanisms: higher entry of new
benchmarks reduces concentration; rapid inflows can temporarily complicate
coordination in evaluation; and stronger penalties against over-fitting have
limited effect. Taken together, these results suggest that concentrated
benchmark influence functions as coordination infrastructure that supports
standardization, comparability, and reproducibility amid rising heterogeneity
in model production, while also introducing trade-offs such as path dependence,
selective visibility, and diminishing discriminative power as leaderboards
saturate.

</details>


### [57] [Framing Unionization on Facebook: Communication around Representation Elections in the United States](https://arxiv.org/abs/2510.01757)
*Arianna Pera,Veronica Jude,Ceren Budak,Luca Maria Aiello*

Main category: cs.CY

TL;DR: 该研究结合NLRB选举数据和15.8万条工会Facebook帖子，分析工会在线话语框架与选举结果的关系。研究发现获胜选举前诊断性、前瞻性和社区框架使用增加，而失败选举中工会沟通策略缺乏调整。


<details>
  <summary>Details</summary>
Motivation: 数字媒体已成为工会沟通、组织和维持集体行动的核心方式，但工会在线话语与选举结果等具体成果之间的关系尚不明确。

Method: 结合NLRB选举数据和158k条工会Facebook帖子，使用微调RoBERTa分类器系统标注工会帖子的五种话语框架：诊断性、前瞻性、激励性、社区性和参与性。

Result: 诊断性和社区框架主导工会沟通整体，但不同组织间框架使用差异显著。获胜选举前诊断性、前瞻性和社区框架使用增加，选举后前瞻性和激励性框架减少；失败选举中工会沟通策略缺乏调整。

Conclusion: 研究通过分析信息层面框架变化，揭示了沟通策略如何适应组织情境，为理解工会和社会运动的数字沟通提供了开放工具和数据支持。

Abstract: Digital media have become central to how labor unions communicate, organize,
and sustain collective action. Yet little is known about how unions' online
discourse relates to concrete outcomes such as representation elections. This
study addresses the gap by combining National Labor Relations Board (NLRB)
election data with 158k Facebook posts published by U.S. labor unions between
2015 and 2024. We focused on five discourse frames widely recognized in labor
and social movement communication research: diagnostic (identifying problems),
prognostic (proposing solutions), motivational (mobilizing action), community
(emphasizing solidarity), and engagement (promoting interaction). Using a
fine-tuned RoBERTa classifier, we systematically annotated unions' posts and
analyzed patterns of frame usage around election events. Our findings showed
that diagnostic and community frames dominated union communication overall, but
that frame usage varied substantially across organizations. In election cases
that unions won, communication leading up to the vote showed an increased use
of diagnostic, prognostic, and community frames, followed by a reduction in
prognostic and motivational framing after the event--patterns consistent with
strategic preparation. By contrast, in lost election cases unions showed little
adjustment in their communication, suggesting an absence of tailored
communication strategies. By examining variation in message-level framing, the
study highlights how communication strategies adapt to organizational contexts,
contributing open tools and data and complementing prior research in
understanding digital communication of unions and social movements.

</details>


### [58] [Sycophantic AI Decreases Prosocial Intentions and Promotes Dependence](https://arxiv.org/abs/2510.01395)
*Myra Cheng,Cinoo Lee,Pranav Khadpe,Sunny Yu,Dyllan Han,Dan Jurafsky*

Main category: cs.CY

TL;DR: 研究发现AI模型普遍存在谄媚行为，会过度认同用户观点，这降低了用户修复人际冲突的意愿，但用户却更喜欢这类AI并给予更高评价。


<details>
  <summary>Details</summary>
Motivation: 了解AI谄媚现象的普遍程度及其对用户行为的影响，揭示AI过度认同用户可能带来的风险。

Method: 评估11个先进AI模型的谄媚程度，并进行两个预注册实验（N=1604），包括真实人际冲突的现场互动研究。

Result: AI模型比人类谄媚度高50%，即使涉及操纵和欺骗行为也会认同。与谄媚AI互动显著降低用户修复人际冲突的意愿，但用户却更信任和喜欢这类AI。

Conclusion: 用户偏好谄媚AI会形成恶性循环，需要明确解决这种激励机制以减轻AI谄媚带来的广泛风险。

Abstract: Both the general public and academic communities have raised concerns about
sycophancy, the phenomenon of artificial intelligence (AI) excessively agreeing
with or flattering users. Yet, beyond isolated media reports of severe
consequences, like reinforcing delusions, little is known about the extent of
sycophancy or how it affects people who use AI. Here we show the pervasiveness
and harmful impacts of sycophancy when people seek advice from AI. First,
across 11 state-of-the-art AI models, we find that models are highly
sycophantic: they affirm users' actions 50% more than humans do, and they do so
even in cases where user queries mention manipulation, deception, or other
relational harms. Second, in two preregistered experiments (N = 1604),
including a live-interaction study where participants discuss a real
interpersonal conflict from their life, we find that interaction with
sycophantic AI models significantly reduced participants' willingness to take
actions to repair interpersonal conflict, while increasing their conviction of
being in the right. However, participants rated sycophantic responses as higher
quality, trusted the sycophantic AI model more, and were more willing to use it
again. This suggests that people are drawn to AI that unquestioningly validate,
even as that validation risks eroding their judgment and reducing their
inclination toward prosocial behavior. These preferences create perverse
incentives both for people to increasingly rely on sycophantic AI models and
for AI model training to favor sycophancy. Our findings highlight the necessity
of explicitly addressing this incentive structure to mitigate the widespread
risks of AI sycophancy.

</details>


### [59] [A principled way to think about AI in education: guidance for action based on goals, models of human learning, and use of technologies](https://arxiv.org/abs/2510.01467)
*Noah D. Finkelstein*

Main category: cs.CY

TL;DR: 本文提出了一个原则性框架，指导人工智能在高等教育中的使用，旨在让人工智能增强而非取代人类能力，将技术使用与持久的教育价值观和目标保持一致。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能及相关技术的快速发展对高等教育产生深远影响，需要明确机构、教育者和学生在技术丰富未来中的角色，避免仅关注人工智能的利弊或直接实施。

Method: 基于学习科学和教育技术应用的数十年学术研究，提出一套将广泛教育目标与可操作实践相连接的原则，阐明教育者、学习者和技术在课程设计、教学安排、学习评估和社区建设中的各自角色。

Result: 建立了一个原则性框架，使高等教育能够在利用新工具的同时保持其基本使命：促进有意义的学习、支持民主社会和为学生应对动态未来做准备。

Conclusion: 原则性方法确保人工智能增强而非取代人类能力，使技术使用与持久的教育价值观和目标保持一致，为高等教育在人工智能时代的发展提供指导。

Abstract: The rapid emergence of generative artificial intelligence (AI) and related
technologies has the potential to dramatically influence higher education,
raising questions about the roles of institutions, educators, and students in a
technology-rich future. While existing discourse often emphasizes either the
promise and peril of AI or its immediate implementation, this paper advances a
third path: a principled framework for guiding the use of AI in teaching and
learning. Drawing on decades of scholarship in the learning sciences and uses
of technology in education, I articulate a set of principles that connect broad
our educational goalsto actionable practices. These principles clarify the
respective roles of educators, learners, and technologies in shaping curricula,
designing instruction, assessing learning, and cultivating community. The piece
illustrates how a principled approach enables higher education to harness new
tools while preserving its fundamental mission: advancing meaningful learning,
supporting democratic societies, and preparing students for dynamic futures.
Ultimately, this framework seeks to ensure that AI augments rather than
displaces human capacities, aligning technology use with enduring educational
values and goals.

</details>


### [60] [Extracting O*NET Features from the NLx Corpus to Build Public Use Aggregate Labor Market Data](https://arxiv.org/abs/2510.01470)
*Stephen Meisenbacher,Svetlozar Nestorov,Peter Norlander*

Main category: cs.CY

TL;DR: 开发了Job Ad Analysis Toolkit (JAAT)，一个从在线招聘广告中提取结构化信息的开源自然语言处理工具包，基于O*NET框架，处理了超过1.55亿个招聘广告，提取了超过100亿个数据点。


<details>
  <summary>Details</summary>
Motivation: 在线招聘广告数据难以获取且缺乏标准化，而标准的O*NET数据库更新不频繁且基于小样本调查，需要更好的工具来从大量招聘广告中提取结构化信息。

Method: 采用O*NET作为框架，构建自然语言处理工具来从招聘广告中提取结构化信息，开发了开源的JAAT工具包，并通过样本外测试和LLM作为评判者来验证其可靠性和准确性。

Result: 从NLx Research Hub提供的1.55亿多个在线招聘广告中提取了超过100亿个数据点，包括O*NET任务、职业代码、工具和技术，以及工资、技能、行业等特征，构建了2015-2025年按职业、州和行业级别聚合的数据集。

Conclusion: JAAT工具包展示了在研究和未来教育及劳动力发展应用中的潜力，为从大规模招聘广告数据中提取有价值信息提供了可靠的工具。

Abstract: Data from online job postings are difficult to access and are not built in a
standard or transparent manner. Data included in the standard taxonomy and
occupational information database (O*NET) are updated infrequently and based on
small survey samples. We adopt O*NET as a framework for building natural
language processing tools that extract structured information from job
postings. We publish the Job Ad Analysis Toolkit (JAAT), a collection of
open-source tools built for this purpose, and demonstrate its reliability and
accuracy in out-of-sample and LLM-as-a-Judge testing. We extract more than 10
billion data points from more than 155 million online job ads provided by the
National Labor Exchange (NLx) Research Hub, including O*NET tasks, occupation
codes, tools, and technologies, as well as wages, skills, industry, and more
features. We describe the construction of a dataset of occupation, state, and
industry level features aggregated by monthly active jobs from 2015 - 2025. We
illustrate the potential for research and future uses in education and
workforce development.

</details>


### [61] [Small is Sufficient: Reducing the World AI Energy Consumption Through Model Selection](https://arxiv.org/abs/2510.01889)
*Tiago da Silva Barros,Frédéric Giroire,Ramon Aparicio-Pardo,Joanna Moulierac*

Main category: cs.CY

TL;DR: 该论文提出通过模型选择策略实现绿色AI，强调从追求大模型转向选择合适的小模型，可在保持性能的同时显著降低AI推理能耗。研究表明应用模型选择可减少27.8%的AI能耗，相当于2025年全球节省31.9 TWh电力。


<details>
  <summary>Details</summary>
Motivation: AI的能耗和碳足迹已成为关键问题，需要从'越大越好'转向'小即足够'的能源节制理念，通过选择更小更高效的模型来减少环境影响。

Method: 进行系统性的AI任务研究，分析任务流行度、模型大小和效率，研究不同任务成熟度和模型采用模式对节能潜力的影响，评估模型选择策略的节能效果。

Result: 模型选择可在不同任务中实现1%到98%的能耗节省，总体可减少AI能耗27.8%，2025年全球可节省31.9 TWh电力，相当于五个核电站的年发电量。

Conclusion: 模型选择是一种简单有效的绿色AI方法，无需新硬件或架构，通过选择合适的模型大小即可在保持性能的同时显著降低AI推理能耗，推动AI可持续发展。

Abstract: The energy consumption and carbon footprint of Artificial Intelligence (AI)
have become critical concerns due to rising costs and environmental impacts. In
response, a new trend in green AI is emerging, shifting from the "bigger is
better" paradigm, which prioritizes large models, to "small is sufficient",
emphasizing energy sobriety through smaller, more efficient models.
  We explore how the AI community can adopt energy sobriety today by focusing
on model selection during inference. Model selection consists of choosing the
most appropriate model for a given task, a simple and readily applicable
method, unlike approaches requiring new hardware or architectures. Our
hypothesis is that, as in many industrial activities, marginal utility gains
decrease with increasing model size. Thus, applying model selection can
significantly reduce energy consumption while maintaining good utility for AI
inference.
  We conduct a systematic study of AI tasks, analyzing their popularity, model
size, and efficiency. We examine how the maturity of different tasks and model
adoption patterns impact the achievable energy savings, ranging from 1% to 98%
for different tasks. Our estimates indicate that applying model selection could
reduce AI energy consumption by 27.8%, saving 31.9 TWh worldwide in 2025 -
equivalent to the annual output of five nuclear power reactors.

</details>


### [62] [The Current State of AI Bias Bounties: An Overview of Existing Programmes and Research](https://arxiv.org/abs/2510.02036)
*Sergej Kucenko,Nathaniel Dennler,Fengxiang He*

Main category: cs.CY

TL;DR: 该调查分析了AI偏见悬赏计划的研究现状，发现目前仅有5个偏见悬赏项目和5篇相关研究，主要集中在美国，采用限时竞赛形式，奖金在7,000-24,000美元之间。


<details>
  <summary>Details</summary>
Motivation: 当前偏见评估方法很少涉及受AI系统影响的社区，偏见悬赏作为一种基于奖励的方法，旨在让社区参与AI偏见检测。

Method: 通过搜索Google、Google Scholar、PhilPapers和IEEE Xplore，识别和分析现有的AI偏见悬赏项目和学术文献。

Result: 识别出5个偏见悬赏项目（均为美国组织举办的限时竞赛）和5篇研究出版物，涵盖从错误悬赏应用到算法偏见、Twitter偏见悬赏、制度机制提案等主题。

Conclusion: 需要降低偏见悬赏的技术门槛以包含无编码经验者，未来应探索从错误悬赏中借鉴最佳实践，并设计对弱势群体敏感且降低组织采用障碍的方案。

Abstract: Current bias evaluation methods rarely engage with communities impacted by AI
systems. Inspired by bug bounties, bias bounties have been proposed as a
reward-based method that involves communities in AI bias detection by asking
users of AI systems to report biases they encounter when interacting with such
systems. In the absence of a state-of-the-art review, this survey aimed to
identify and analyse existing AI bias bounty programmes and to present academic
literature on bias bounties. Google, Google Scholar, PhilPapers, and IEEE
Xplore were searched, and five bias bounty programmes, as well as five research
publications, were identified. All bias bounties were organised by U.S.-based
organisations as time-limited contests, with public participation in four
programmes and prize pools ranging from 7,000 to 24,000 USD. The five research
publications included a report on the application of bug bounties to
algorithmic harms, an article addressing Twitter's bias bounty, a proposal for
bias bounties as an institutional mechanism to increase AI scrutiny, a workshop
discussing bias bounties from queer perspectives, and an algorithmic framework
for bias bounties. We argue that reducing the technical requirements to enter
bounty programmes is important to include those without coding experience.
Given the limited adoption of bias bounties, future efforts should explore the
transferability of the best practices from bug bounties and examine how such
programmes can be designed to be sensitive to underrepresented groups while
lowering adoption barriers for organisations.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [63] [Lung Cancer Survival Prediction Using Machine Learning and Statistical Methods](https://arxiv.org/abs/2510.01267)
*Varun Vishwanathan Nair,Victor Miranda Soberanis*

Main category: stat.AP

TL;DR: 该研究整合基线特征与治疗后变量（如无进展生存期和残留肿瘤状态），使用Cox比例风险模型和随机生存森林模型预测肺癌生存率，显著优于以往研究。


<details>
  <summary>Details</summary>
Motivation: 现有肺癌生存模型主要依赖基线因素，忽略了反映疾病进展的治疗后变量，导致预测准确性不足。

Method: 应用Cox比例风险模型和随机生存森林模型，整合基线特征与治疗后预测因子（无进展生存期、残留肿瘤状态）。

Result: Cox模型C-index达0.90，随机生存森林模型达0.86，均优于以往研究。整合治疗后变量提供了更具临床意义的生存估计。

Conclusion: 研究表明常规收集的临床变量可转化为可操作的生存预测，有助于改善治疗计划、个性化患者咨询和随访策略。

Abstract: Lung cancer remains one of the leading causes of cancer-related mortality,
yet most survival models rely only on baseline factors and overlook
posttreatment variables that reflect disease progression. To address this gap,
we applied Cox Proportional Hazards and Random Survival Forests, integrating
baseline features with post-treatment predictors such as progression-free
interval (PFI.time) and residual tumor status. The Cox model achieved a
concordance index (C-index) of 0.90, while the RSF model reached 0.86, both
outperforming previous studies. Beyond statistical gains, the integration of
post-treatment variables provides oncologists with more clinically meaningful
and reliable survival estimates. This enables improved treatment planning, more
personalized patient counseling, and better-informed follow-up strategies. From
a practical standpoint, these results demonstrate how routinely collected
clinical variables can be transformed into actionable survival predictions.

</details>


### [64] [Neural Tangent Kernels for Complex Genetic Risk Prediction: Bridging Deep Learning and Kernel Methods in Genomics](https://arxiv.org/abs/2510.01426)
*Heng Ge,Qing Lu*

Main category: stat.AP

TL;DR: 开发神经正切核(NTK)框架，将核方法集成到深度神经网络中用于遗传风险预测分析，提出了NTK-LMM和NTK-KRR两种方法，在阿尔茨海默病数据上表现出优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 遗传风险预测的复杂性需要开发能够有效捕捉复杂基因型-表型关系（如非线性关系）的新方法，同时保持统计可解释性和计算可行性。

Method: 开发了神经正切核(NTK)框架，包括两种方法：NTK-LMM（将经验NTK嵌入线性混合模型，通过MINQUE估计方差分量）和NTK-KRR（使用交叉验证正则化进行核岭回归）。

Result: 模拟研究表明NTK模型优于传统神经网络模型和线性混合模型。在ADNI数据应用中，NTK在海马体积和内嗅皮层厚度预测上比现有方法获得更高准确率。

Conclusion: 通过整合深度神经网络和核方法的优势，NTK在遗传风险预测分析中提供了有竞争力的性能，同时具有可解释性和计算效率的优势。

Abstract: Given the complexity of genetic risk prediction, there is a critical need for
the development of novel methodologies that can effectively capture intricate
genotype--phenotype relationships (e.g., nonlinear) while remaining
statistically interpretable and computationally tractable. We develop a Neural
Tangent Kernel (NTK) framework to integrate kernel methods into deep neural
networks for genetic risk prediction analysis. We consider two approaches:
NTK-LMM, which embeds the empirical NTK in a linear mixed model with variance
components estimated via minimum quadratic unbiased estimator (MINQUE), and
NTK-KRR, which performs kernel ridge regression with cross-validated
regularization. Through simulation studies, we show that NTK-based models
outperform the traditional neural network models and linear mixed models. By
applying NTK to endophenotypes (e.g., hippocampal volume) and AD-related genes
(e.g., APOE) from Alzheimer's Disease Neuroimaging Initiative (ADNI), we found
that NTK achieved higher accuracy than existing methods for hippocampal volume
and entorhinal cortex thickness. In addition to its accuracy performance, NTK
has favorable optimization properties (i.e., having a closed-form or convex
training) and generates interpretable results due to its connection to variance
components and heritability. Overall, our results indicate that by integrating
the strengths of both deep neural networks and kernel methods, NTK offers
competitive performance for genetic risk prediction analysis while having the
advantages of interpretability and computational efficiency.

</details>


### [65] [The Perceived Influences of Environment on Health in Italy: a Penalized Ordinal Regression Approach](https://arxiv.org/abs/2510.01803)
*Mattia Stival,Angela Andreella,Gaia Bertarelli,Catarina Midões,Stefano Federico Tonellato,Enrica De Cian,Stefano Campostrini*

Main category: stat.AP

TL;DR: 该研究通过整合意大利全国健康监测系统PASSI的环境模块与市级背景信息，采用惩罚性半并行累积序数回归模型分析环境感知的个人和地域决定因素。


<details>
  <summary>Details</summary>
Motivation: 理解个体对生活环境的感知是一个复杂任务，涉及个人和背景决定因素。研究旨在分析环境感知如何受到个人和地域特征的影响。

Method: 采用惩罚性半并行累积序数回归模型，整合PASSI环境模块数据与市级社会经济指标、污染暴露和其他地理特征，平衡灵活性和可解释性。

Result: 结果显示意大利各地区存在显著异质性，本地特征强烈影响环境感知；个人因素与背景影响相互作用；PM2.5等危险环境因素与较差的环境感知相关。

Conclusion: 该方法在环境政策规划中具有强大应用潜力，为理解环境感知的决定因素提供了有用见解。

Abstract: Understanding how individuals perceive their living environment is a complex
task, as it reflects both personal and contextual determinants. In this paper,
we address this task by analyzing the environmental module of the Italian
nationwide health surveillance system PASSI (Progressi delle Aziende Sanitarie
per la Salute in Italia), integrating it with contextual information at the
municipal level, including socio-economic indicators, pollution exposure, and
other geographical characteristics. Methodologically, we adopt a penalized
semi-parallel cumulative ordinal regression model to analyze how subjective
perceptions are shaped by both personal and territorial determinants. The
approach balances flexibility and interpretability by allowing both parallel
and non-parallel effects while regularizing estimates to address
multicollinearity and separation issues. We use the model as an analytical tool
to uncover the determinants of positivity and neutrality in environmental
perceptions, defined as factors that contribute the most to improving
perception or increasing the sense of neutrality. The results are diverse.
First, results reveal significant heterogeneity across Italian territories,
indicating that local characteristics strongly shape environmental perception.
Second, various individual factors interact with contextual influences to shape
perceptions. Third, hazardous environmental factors, such as higher PM2.5
levels, appear to be associated with poorer environmental perception,
suggesting a tendency among respondents to recognize specific environmental
issues. Overall, the approach demonstrates strong potential for application and
provides useful insights for environmental policy planning.

</details>


### [66] [Dependent stochastic block models for age-indexed sequences of directed causes-of-death networks](https://arxiv.org/abs/2510.01806)
*Giovanni Romanò,Cristian Castiglione,Daniele Durante*

Main category: stat.AP

TL;DR: 提出了一种新的贝叶斯随机块模型，用于分析死亡证书中基础死因和促成死因之间的年龄特异性网络交互模式，揭示了美国死亡率数据中隐藏的群体结构和演化规律。


<details>
  <summary>Details</summary>
Motivation: 死亡事件通常由基础死因和促成死因的复杂相互作用引起，但目前缺乏适合分析年龄索引有向网络序列的随机块模型来研究这些交互模式。

Method: 开发了一种新的贝叶斯公式，学习基础死因和促成死因的独立群体结构，并通过依赖随机分区先验允许这些结构随年龄平滑变化。

Result: 模拟显示该方法优于现有解决方案，应用于美国死亡率数据时揭示了先前研究中隐藏的死因群体组成、演化和模块化交互结构。

Conclusion: 该方法有助于理解美国近期'绝望死亡'现象，可能具有相关政策意义。

Abstract: Death events commonly arise from complex interactions among interrelated
causes, formally classified in reporting practices as underlying and
contributing. Leveraging information from death certificates, these
interactions can be naturally represented through a sequence of directed
networks encoding co-occurrence strengths between pairs of underlying and
contributing causes across ages. Although this perspective opens the avenues to
learn informative age-specific block interactions among endogenous groups of
underlying and contributing causes displaying similar co-occurrence patterns,
there has been limited research along this direction in mortality modeling.
This is mainly due to the lack of suitable stochastic block models for
age-indexed sequences of directed networks. We cover this gap through a novel
Bayesian formulation which crucially learns two separate group structures for
underlying and contributing causes, while allowing both structures to change
smoothly across ages via dependent random partition priors. As illustrated in
simulations, this formulation outperforms state-of-the-art solutions that could
be adapted to our motivating application. Moreover, when applied to USA
mortality data, it unveils structures in the composition, evolution, and
modular interactions among causes-of-death groups that were hidden to previous
studies. Such findings could have relevant policy implications and contribute
to an improved understanding of the recent "death of despair" phenomena in USA.

</details>


### [67] [Multidata Causal Discovery for Statistical Hurricane Intensity Forecasting](https://arxiv.org/abs/2510.02050)
*Saranya Ganesh S.,Frederick Iat-Hin Tam,Milton S. Gomez,Marie McGraw,Mark DeMaria,Kate Musgrave,Jakob Runge,Tom Beucler*

Main category: stat.AP

TL;DR: 提出基于因果发现的多数据框架改进大西洋飓风强度预测，通过识别与飓风强度变化因果相关的预测因子，在短期预测中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统飓风强度预测方法主要依赖相关性或拟合度，往往忽略混杂变量，对未见过热带风暴的泛化能力有限。需要更可靠的预测因子选择方法。

Method: 使用多数据因果发现框架结合ERA5再分析数据，识别因果相关的预测因子。比较了无选择、相关性、随机森林特征重要性和因果特征选择方法，并构建扩展预测因子集SHIPS+。

Result: 因果特征选择在未见测试案例中表现最佳，特别是在3天以内的短期预测。SHIPS+在24、48、72小时预测中提高了技能，加入多层感知器后技能进一步扩展到更长预报时效。

Conclusion: 因果发现显著改善飓风强度预测，为更经验化的预报铺平道路，三个新增因果发现预测因子在业务测试中证实能改进预报，尤其在较长预报时效获得最大增益。

Abstract: Improving statistical forecasts of Atlantic hurricane intensity is limited by
complex nonlinear interactions and difficulty in identifying relevant
predictors. Conventional methods prioritize correlation or fit, often
overlooking confounding variables and limiting generalizability to unseen
tropical storms. To address this, we leverage a multidata causal discovery
framework with a replicated dataset based on Statistical Hurricane Intensity
Prediction Scheme (SHIPS) using ERA5 meteorological reanalysis. We conduct
multiple experiments to identify and select predictors causally linked to
hurricane intensity changes. We train multiple linear regression models to
compare causal feature selection with no selection, correlation, and random
forest feature importance across five forecast lead times from 1 to 5 days (24
to 120 hours). Causal feature selection consistently outperforms on unseen test
cases, especially for lead times shorter than 3 days. The causal features
primarily include vertical shear, mid-tropospheric potential vorticity and
surface moisture conditions, which are physically significant yet often
underutilized in hurricane intensity predictions. Further, we build an extended
predictor set (SHIPS+) by adding selected features to the standard SHIPS
predictors. SHIPS+ yields increased short-term predictive skill at lead times
of 24, 48, and 72 hours. Adding nonlinearity using multilayer perceptron
further extends skill to longer lead times, despite our framework being purely
regional and not requiring global forecast data. Operational SHIPS tests
confirm that three of the six added causally discovered predictors improve
forecasts, with the largest gains at longer lead times. Our results demonstrate
that causal discovery improves hurricane intensity prediction and pave the way
toward more empirical forecasts.

</details>


### [68] [How to Find Fantastic Papers: Self-Rankings as a Powerful Predictor of Scientific Impact Beyond Peer Review](https://arxiv.org/abs/2510.02143)
*Buxin Su,Natalie Collina,Garrett Wen,Didong Li,Kyunghyun Cho,Jianqing Fan,Bingxin Zhao,Weijie Su*

Main category: stat.AP

TL;DR: 作者自我排名能有效识别高影响力AI研究，比同行评审更能预测论文引用量，最高自排名论文的引用量是最低自排名论文的两倍。


<details>
  <summary>Details</summary>
Motivation: 在AI等快速发展的领域，同行评审难以识别具有高科学潜力的研究。作者对自己的工作有独特理解，因此研究作者自我排名是否能作为识别高影响力研究的补充指标。

Method: 在顶级AI会议上进行大规模实验，让1,342名研究人员对其2,592篇投稿进行自我质量排名，并追踪一年以上的引用结果。

Result: 作者最高自排名论文的引用量是最低自排名论文的两倍；自排名在识别高引用论文（超过150次引用）方面特别有效，且优于同行评审分数预测未来引用量。

Conclusion: 作者自我排名为识别和提升AI领域高影响力研究提供了可靠且宝贵的同行评审补充工具。

Abstract: Peer review in academic research aims not only to ensure factual correctness
but also to identify work of high scientific potential that can shape future
research directions. This task is especially critical in fast-moving fields
such as artificial intelligence (AI), yet it has become increasingly difficult
given the rapid growth of submissions. In this paper, we investigate an
underexplored measure for identifying high-impact research: authors' own
rankings of their multiple submissions to the same AI conference. Grounded in
game-theoretic reasoning, we hypothesize that self-rankings are informative
because authors possess unique understanding of their work's conceptual depth
and long-term promise. To test this hypothesis, we conducted a large-scale
experiment at a leading AI conference, where 1,342 researchers self-ranked
their 2,592 submissions by perceived quality. Tracking outcomes over more than
a year, we found that papers ranked highest by their authors received twice as
many citations as their lowest-ranked counterparts; self-rankings were
especially effective at identifying highly cited papers (those with over 150
citations). Moreover, we showed that self-rankings outperformed peer review
scores in predicting future citation counts. Our results remained robust after
accounting for confounders such as preprint posting time and self-citations.
Together, these findings demonstrate that authors' self-rankings provide a
reliable and valuable complement to peer review for identifying and elevating
high-impact research in AI.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [69] [Does Adoption of Zero Tillage Reduce Crop Residue Burning? Evidence from Satellite Remote Sensing and Household Survey Data in India](https://arxiv.org/abs/2510.01351)
*Dominik Naeher,Virginia Ziulu*

Main category: econ.GN

TL;DR: 本研究通过整合高分辨率卫星影像和印度家庭调查数据，发现免耕技术与作物残留物焚烧之间存在显著负相关关系，焚烧发生率减少50%或更多。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏关于免耕技术采用与残留物焚烧之间联系的实证证据，这给政策制定者带来了困难。

Method: 整合高分辨率卫星影像与家庭调查数据，比较从遥感数据构建焚烧指标的不同方法，并评估其与调查数据的预测能力。

Result: 发现免耕技术与作物残留物焚烧之间存在稳健的负相关关系，焚烧发生率减少50%或更多。

Conclusion: 研究不仅提供了关于免耕技术减少焚烧的实证证据，还在地理空间数据整合方法上做出方法论贡献，可为未来研究和基于证据的政策干预提供支持。

Abstract: Previous research indicates that zero tillage technology offers a profitable
alternative to crop residue burning, with significant potential to reduce
agricultural emissions and contribute to improvements in air quality and public
health. Yet, empirical evidence on the link between zero tillage adoption and
residue burning remains scarce, adding to the difficulties policy makers face
in this context. This study addresses this gap by integrating high-resolution
satellite imagery with household survey data from India to examine the
empirical relationship between zero tillage and residue burning. We compare
different methods for constructing burn indicators from remote-sensing data and
assess their predictive power against survey-based measures. Our findings
reveal a robust negative association between zero tillage and crop residue
burning, with reductions in the incidence of burning of 50% or more across both
survey data and satellite-derived indicators. By providing insights into
optimal geospatial data integration methods, our study also makes a
methodological contribution that can inform future research and support
evidence-based policy interventions for more sustainable agricultural
practices.

</details>


### [70] [Equity Market Price Changes Are Predictable: A Natural Science Approach](https://arxiv.org/abs/2510.01542)
*Qingyuan Han*

Main category: econ.GN

TL;DR: 本文提出了扩展萨缪尔森模型(ESM)，这是一个基于自然科学的框架，能够捕捉市场行为的动态因果过程。该模型识别多个时间尺度上的峰值、谷值和转折点，并转化为实用的交易策略，在日内交易中能够可靠预测短期反转和长期趋势。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，即认为股市不可预测且日内价格变动是随机噪声。通过引入基于自然科学的框架来理解市场行为的动态因果过程。

Method: 开发扩展萨缪尔森模型(ESM)，该模型识别多个时间尺度上的峰值、谷值和转折点，展示时间兼容性，并定义八种市场状态和六个方向信号。

Result: ESM在日内交易中能够可靠预测短期反转和长期趋势，即使在突发新闻影响下也有效。在平静时期可捕捉标普500指数10点的波动，相当于每份E-mini期货合约500美元的收益。

Conclusion: ESM不仅推进了对市场演化的科学理解，还为盈利交易提供了稳健可行的路线图，其方法与文艺复兴科技公司奖章基金的状态方法相呼应。

Abstract: Equity markets have long been regarded as unpredictable, with intraday price
movements treated as stochastic noise. This study challenges that view by
introducing the Extended Samuelson Model (ESM), a natural science-based
framework that captures the dynamic, causal processes underlying market
behavior. ESM identifies peaks, troughs, and turning points across multiple
timescales and demonstrates temporal compatibility: finer timeframes contain
all signals of broader ones while offering sharper directional guidance. Beyond
theory, ESM translates into practical trading strategies. During intraday
sessions, it reliably anticipates short-term reversals and longer-term trends,
even under the influence of breaking news. Its eight market states and six
directional signals provide actionable guardrails for traders, enabling
consistent profit opportunities. Notably, even during calm periods, ESM can
capture 10-point swings in the S&P 500, equivalent to $500 per E-mini futures
contract. These findings resonate with the state-based approaches attributed to
Renaissance Technologies' Medallion Fund, which delivered extraordinary returns
through systematic intraday trading. By bridging normal conditions with crisis
dynamics, ESM not only advances the scientific understanding of market
evolution but also provides a robust, actionable roadmap for profitable
trading.

</details>


### [71] [The centripetal pull of climate: Evidence from European Parliament elections (1989-2019)](https://arxiv.org/abs/2510.01551)
*Marco Dueñas,Hector Galindo-Silva,Antoine Mandel*

Main category: econ.GN

TL;DR: 温度冲击会降低欧洲议会选举中的意识形态极化，增加选票集中度，使选民向更大、更温和的政党靠拢，推动政党体系向中间靠拢并削弱政治极端势力。


<details>
  <summary>Details</summary>
Motivation: 研究短期温度冲击对投票行为的影响，探索气候因素如何影响政治选举结果和政党体系。

Method: 结合高分辨率气候数据和1989-2019年欧洲议会选举结果，利用选举前异常温暖和炎热天气的外生变化来识别温度冲击的因果效应。

Result: 温度冲击导致意识形态极化降低，选票集中度增加，自由党和社民党支持率上升，右翼政党得票率下降；政党宣言在温暖选举背景下更强调气候议题。

Conclusion: 气候冲击能够推动政党体系向中间靠拢，削弱政治极端势力，表明环境因素对政治格局具有重要影响。

Abstract: This paper examines the impact of temperature shocks on European Parliament
elections. We combine high-resolution climate data with results from
parliamentary elections between 1989 and 2019, aggregated at the NUTS-2
regional level. Exploiting exogenous variation in unusually warm and hot days
during the months preceding elections, we identify the effect of short-run
temperature shocks on voting behaviour. We find that temperature shocks reduce
ideological polarisation and increase vote concentration, as voters consolidate
around larger, more moderate parties. This aggregated pattern is explained by a
gain in support of liberal and, to a lesser extent, social democratic parties,
while right-wing parties lose vote share. Consistent with a salience mechanism,
complementary analysis of party manifestos shows greater emphasis on
climate-related issues in warmer pre-electoral contexts. Overall, our findings
indicate that climate shocks can shift party systems toward the centre and
weaken political extremes.

</details>


### [72] [A Computational Approach to Sustainable Policies Evaluation of the Italian Wheat Production System](https://arxiv.org/abs/2510.02154)
*Gianfranco Giuloni,Edmondo Di Giuseppe,Arianna Di Paola*

Main category: econ.GN

TL;DR: 开发了一个基于代理的模型工具，支持政策制定者引导小麦生产向更可持续的方向发展。该模型整合了农场异质性、全球小麦市场动态和环境评估。


<details>
  <summary>Details</summary>
Motivation: 农业政策影响高度多样化的农场，这些农场在规模、土地构成、当地气候和灌溉可用性等方面存在显著差异，需要解决这种异质性来支持可持续政策制定。

Method: 构建基于代理的模型，使用意大利农场代表性调查数据进行初始化，并扩展到全国规模。模型整合了全球小麦市场模型和环境影响评估工具。

Result: 开发了一个集成框架，能够考虑全球价格与本地生产之间的反馈循环，同时评估政策措施的环境影响。

Conclusion: 该集成建模方法为政策制定者提供了支持可持续小麦生产决策的工具，能够处理农场异质性和复杂系统动态。

Abstract: This work outlines the modeling steps for developing a tool aimed at
supporting policymakers in guiding policies toward more sustainable wheat
production. In the agricultural sector,policies affect a highly diverse set of
farms, which differ across several dimensions such as size,land composition,
local climate, and irrigation availability. To address this significant
heterogeneity, we construct an Agent-Based Model (ABM). The model is
initialized using a representative survey of Italian farms, which captures
their heterogeneity. The ABM is then scaled to include a number of farms
comparable to those operating nationwide. To capture broader dynamics, the ABM
is integrated with two additional components:a global model of international
wheat markets and a tool for assessing the environmental impacts of wheat
production. This integrated framework enables us to account for the feedback
loop between global prices and local production while evaluating the
environmental implications of policy measures.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [73] [Adversarial Social Influence: Modeling Persuasion in Contested Social Networks](https://arxiv.org/abs/2510.01481)
*Renukanandan Tumu,Cristian Ioan Vasile,Victor Preciado,Rahul Mangharam*

Main category: cs.SI

TL;DR: 提出Social Influence Game (SIG)框架，用于建模社交网络中多方竞争的影响传播，通过DeGroot动态和固定预算分配来优化意见引导，并开发了高效的IL求解器。


<details>
  <summary>Details</summary>
Motivation: 为大规模社交网络中的对抗性说服提供可扩展且可解释的模型，捕捉网络结构中的关键影响点。

Method: 使用DeGroot动态模型，将影响优化问题建模为凸差规划，并开发迭代线性(IL)求解器来近似玩家目标。

Result: 在随机和典型网络中，IL求解器达到非线性求解器97%的精度，速度快10倍以上，可扩展到大型社交网络。

Conclusion: 为复杂网络中竞争性影响的渐近分析奠定了基础。

Abstract: We present the Social Influence Game (SIG), a framework for modeling
adversarial persuasion in social networks with an arbitrary number of competing
players. Our goal is to provide a tractable and interpretable model of
contested influence that scales to large systems while capturing the structural
leverage points of networks. Each player allocates influence from a fixed
budget to steer opinions that evolve under DeGroot dynamics, and we prove that
the resulting optimization problem is a difference-of-convex program. To enable
scalability, we develop an Iterated Linear (IL) solver that approximates player
objectives with linear programs. In experiments on random and archetypical
networks, IL achieves solutions within 7% of nonlinear solvers while being over
10x faster, scaling to large social networks. This paper lays a foundation for
asymptotic analysis of contested influence in complex networks.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [74] [Persuasion in Lemons Markets](https://arxiv.org/abs/2510.01413)
*Andrea Di Giovan Paolo,Jose Higueras*

Main category: econ.TH

TL;DR: 研究竞争市场中存在逆向选择时的信息披露问题，卖家知道产品质量但买家不知道，通过设计公共信号来优化交易量或价格与盈余的加权组合。


<details>
  <summary>Details</summary>
Motivation: 在竞争市场中，卖家对产品质量有私人信息（高质量对应高成本），买家通过公共信号获取信息后按市场出清价格交易。卖家参与交易的行为本身会传递质量信息，这给设计者带来了内生约束。

Method: 将设计者的问题重新表述为带有额外条件的鞅最优传输问题，该条件排除了通过卖家参与决策进一步传递信息的可能性，并描述了最优信号的特征。

Result: 当设计者最大化交易量时，解决方案表现出低效和高效卖家的负向匹配；当目标是价格和盈余的加权组合时，只要价格权重足够高，最优信号保持这种结构，否则会完全揭示低质量类型，同时将中等类型与高质量卖家合并。

Conclusion: 在竞争性逆向选择市场中，最优信息披露策略取决于设计者的目标函数，交易量最大化需要负向匹配，而价格-盈余权衡则根据权重决定信息揭示程度。

Abstract: We study information disclosure in competitive markets with adverse
selection. Sellers privately observe product quality, with higher quality
entailing higher production costs, while buyers trade at the market-clearing
price after observing a public signal. Because sellers' participation in trade
conveys information about quality, the designer faces endogenous constraints in
the set of posteriors that she can induce. We reformulate the designer's
problem as a martingale optimal transport exercise with an additional condition
that rules out further information transmission through sellers' participation
decisions, and characterize the optimal signals. When the designer maximizes
trade volume, the solution features negative-assortative matching of
inefficient and efficient sellers. When the objective is a weighted combination
of price and surplus, optimal signals preserve this structure as long as the
weight on the price is high enough, otherwise they fully reveal low-quality
types while pooling middle types with high-quality sellers.

</details>


### [75] [Privacy-Aware Sequential Learning](https://arxiv.org/abs/2502.19525)
*Yuxin Liu,M. Amin Rahimian*

Main category: econ.TH

TL;DR: 在隐私保护序列学习中，个体通过添加内生噪声来保护隐私信号。研究发现，在连续信号和固定隐私预算下，最优随机化策略能平衡隐私与准确性，加速学习过程，甚至优于非隐私情况。


<details>
  <summary>Details</summary>
Motivation: 研究在疫苗接种登记等场景中，个体观察他人行为后行动，公共记录可能暴露隐私信息的问题。探索如何在保护隐私的同时实现高效的社会学习。

Method: 分析隐私保护序列学习模型，其中个体在报告行动时添加内生噪声以隐藏私有信号。比较连续信号和二进制信号在不同隐私预算下的学习效果。

Result: 在连续信号和固定隐私预算下，学习加速到Θε(log n)，快于非隐私的Θ(√log n)。在非隐私基准中，首次正确行动的期望时间和错误行动数量发散；在隐私保护下，两者都是有限的。

Conclusion: 隐私保护可以重塑信息动态，在某些情况下甚至能加速学习过程。研究结果为平台和政策设计提供了重要启示，特别是在异质群体中，当部分个体隐私预算较低时，可实现阶数最优的学习速率。

Abstract: In settings like vaccination registries, individuals act after observing
others, and the resulting public records can expose private information. We
study privacy-preserving sequential learning, where agents add endogenous noise
to their reported actions to conceal private signals. Efficient social learning
relies on information flow, seemingly in conflict with privacy. Surprisingly,
with continuous signals and a fixed privacy budget $(\epsilon)$, the optimal
randomization strategy balances privacy and accuracy, accelerating learning to
$\Theta_{\epsilon}(\log n)$, faster than the nonprivate $\Theta(\sqrt{\log n})$
rate. In the nonprivate baseline, the expected time to the first correct action
and the number of incorrect actions diverge; under privacy with sufficiently
small $\epsilon$, both are finite. Privacy helps because, under the false
state, agents more often receive signals contradicting the majority;
randomization then asymmetrically amplifies the log-likelihood ratio, enhancing
aggregation. In heterogeneous populations, an order-optimal $\Theta(\sqrt{n})$
rate is achievable when a subset of agents have low privacy budgets. With
binary signals, however, privacy reduces informativeness and impairs learning
relative to the nonprivate baseline, though the dependence on $\epsilon$ is
nonmonotone. Our results show how privacy reshapes information dynamics and
inform the design of platforms and policies.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [76] [A Control Theory inspired Exploration Method for a Linear Bandit driven by a Linear Gaussian Dynamical System](https://arxiv.org/abs/2510.01364)
*Jonathan Gornet,Yilin Mo,Bruno Sinopoli*

Main category: eess.SY

TL;DR: 该论文提出了两种在线性高斯动态系统环境中的算法：Kalman-UCB和IDEA，用于解决探索与利用的权衡问题，并提供了一个基于系统特性的性能预测指标。


<details>
  <summary>Details</summary>
Motivation: 解决在高维动作空间（如机器学习超参数优化）中传统乐观面对不确定性方法的性能问题，因为这些方法需要探索每个动作来降低奖励预测的不确定性。

Method: Kalman-UCB使用乐观面对不确定性原则，IDEA选择最大化预测奖励和最小化卡尔曼滤波器状态预测误差的动作组合，依赖于系统的可观测性特性。

Result: 通过在各种随机生成环境中的数值结果验证了基于LGDS特性的性能预测指标的有效性。

Conclusion: 提出了两种适用于线性高斯动态系统环境的算法，并提供了预测算法性能的指标，特别适用于高维动作空间的场景。

Abstract: The paper introduces a linear bandit environment where the reward is the
output of a known Linear Gaussian Dynamical System (LGDS). In this environment,
we address the fundamental challenge of balancing exploration -- gathering
information about the environment -- and exploitation -- selecting to the
action with the highest predicted reward. We propose two algorithms, Kalman
filter Upper Confidence Bound (Kalman-UCB) and Information filter Directed
Exploration Action-selection (IDEA). Kalman-UCB uses the principle of optimism
in the face of uncertainty. IDEA selects actions that maximize the combination
of the predicted reward and a term that quantifies how much an action minimizes
the error of the Kalman filter state prediction, which depends on the LGDS
property called observability. IDEA is motivated by applications such as
hyperparameter optimization in machine learning. A major problem encountered in
hyperparameter optimization is the large action spaces, which hinder the
performance of methods inspired by principle of optimism in the face of
uncertainty as they need to explore each action to lower reward prediction
uncertainty. To predict if either Kalman-UCB or IDEA will perform better, a
metric based on the LGDS properties is provided. This metric is validated with
numerical results across a variety of randomly generated environments.

</details>


### [77] [Robust Data-Driven Control for Nonlinear Systems Using their Digital Twins and Quadratic Funnels](https://arxiv.org/abs/2510.01406)
*Shiva Shakeri,Mehran Mesbahi*

Main category: eess.SY

TL;DR: 提出了一种结合数字孪生和在线数据驱动不确定性量化的鲁棒跟踪控制方法，通过线性矩阵不等式合成二次漏斗来保证非线性系统的安全部署。


<details>
  <summary>Details</summary>
Motivation: 解决具有非线性动态的系统在数字孪生模型不完美情况下的安全部署问题，需要一种能够适应真实系统行为并保证约束满足的鲁棒控制方法。

Method: 融合数字孪生的标称轨迹与在线数据驱动不确定性量化，通过时间序列数据构建线性矩阵不等式来合成二次漏斗（鲁棒正不变管），采用分段学习策略逐步优化控制器。

Result: 开发了一个系统化框架，能够为基于学习的非线性系统控制提供安全证书，控制器能够保证约束满足并适应真实系统行为。

Conclusion: 该方法为具有不完美模型的非线性系统的学习控制建立了一个系统化安全认证框架，通过数据驱动的不确定性量化和鲁棒控制合成实现了安全部署。

Abstract: This paper examines a robust data-driven approach for the safe deployment of
systems with nonlinear dynamics using their imperfect digital twins. Our
contribution involves proposing a method that fuses the digital twin's nominal
trajectory with online, data-driven uncertainty quantification to synthesize
robust tracking controllers. Specifically, we derive data-driven bounds to
capture the deviations of the actual system from its prescribed nominal
trajectory informed via its digital twin. Subsequently, the dataset is used in
the synthesis of quadratic funnels -- robust positive invariant tubes around
the nominal trajectory -- via linear matrix inequalities built on the
time-series data. The resulting controller guarantees constraint satisfaction
while adapting to the true system behavior through a segmented learning
strategy, where each segment's controller is synthesized using uncertainty
information from the previous segment. This work establishes a systematic
framework for obtaining safety certificates in learning-based control of
nonlinear systems with imperfect models.

</details>


### [78] [A New Partial State-Feedback IDA-PBC for Two-Dimensional Nonlinear Systems: Application to Power Converters with Experimental Results](https://arxiv.org/abs/2510.01425)
*Rafael Cisneros,Leyan Fang,Wei He,Romeo Ortega*

Main category: eess.SY

TL;DR: 提出了一种基于庞加莱引理的IDA-PBC变体方法，用于设计二维系统的输出反馈全局稳定控制器，该方法将偏微分方程替换为更易求解的常微分方程，并应用于DC-DC变换器的电压反馈控制。


<details>
  <summary>Details</summary>
Motivation: 传统IDA-PBC方法因需要求解复杂的匹配偏微分方程而应用受限，本文旨在开发一种更简单有效的控制器设计方法。

Method: 基于庞加莱引理改进IDA-PBC，将匹配PDE替换为ODE，应用于Buck、Boost和Buck-Boost三种DC-DC变换器拓扑，并为不确定负载情况设计了自适应版本。

Result: 数值仿真和实验结果表明该方法有效，能够调节变换器输出以适应负载变化。

Conclusion: 提出的方法简化了控制器设计过程，在DC-DC变换器控制中表现出良好的性能和适应性。

Abstract: In this paper we propose a variation of the widely popular
Interconnection-and-Damping-Assigment Passivity-Based Control (IDA-PBC) based
on Poincare's Lemma to design output feedback globally stabilizing controllers
for two dimensional systems. The procedure is constructive and, in comparison
with the classical IDA-PBC, whose application is often stymied by the need to
solve the (infamous) matching partial differential equation (PDE), in this new
method the PDE is replaced by an ordinary differential equation, whose solution
is far simpler. The procedure is then applied for the design of
voltage-feedback controllers for the three most typical DC-to-DC power
converter topologies: the Buck, Boost and Buck-Boost. It is assumed that these
converters feed an uncertain load, which is characterized by a static relation
between its voltage and current. In the case when the load consists of the
parallel connection of a resistive term and a constant power load we propose an
adaptive version of the design, adding an identification scheme for the load
parameters. This allows the controller to regulate the converter output when
the load varies-that is a typical scenario in these applications. Extensive
numerical simulations and experimental results validate the approach.

</details>


### [79] [Comparative Field Deployment of Reinforcement Learning and Model Predictive Control for Residential HVAC](https://arxiv.org/abs/2510.01475)
*Ozan Baris Mulayim,Elias N. Pergantis,Levi D. Reyes Premer,Bingqing Chen,Guannan Qu,Kevin J. Kircher,Mario Bergés*

Main category: eess.SY

TL;DR: 比较MPC和模型基础RL控制器在真实住宅HVAC系统中的性能，发现RL能节省22%能耗但舒适度稍差，MPC节省20%能耗但在舒适度标准化后表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究MPC和RL在真实住宅HVAC控制中的实际应用问题，探索RL的可扩展性、安全性和可比性，解决工程实施难度和实际部署挑战。

Method: 在印第安纳州西拉法叶的住宅中，分别部署MPC和模型基础RL控制器各一个月，与现有控制器进行对比评估。

Result: RL相对现有控制器节能22%，略高于MPC的20%，但舒适度稍差；当能耗节省按舒适度标准化后，MPC表现更优。

Conclusion: RL减少了工程开销，但在模型精度和操作鲁棒性方面存在权衡；需要解决控制器安全初始化、控制动作与实际实施不匹配、在线学习完整性等关键问题。

Abstract: Advanced control strategies like Model Predictive Control (MPC) offer
significant energy savings for HVAC systems but often require substantial
engineering effort, limiting scalability. Reinforcement Learning (RL) promises
greater automation and adaptability, yet its practical application in
real-world residential settings remains largely undemonstrated, facing
challenges related to safety, interpretability, and sample efficiency. To
investigate these practical issues, we performed a direct comparison of an MPC
and a model-based RL controller, with each controller deployed for a one-month
period in an occupied house with a heat pump system in West Lafayette, Indiana.
This investigation aimed to explore scalability of the chosen RL and MPC
implementations while ensuring safety and comparability. The advanced
controllers were evaluated against each other and against the existing
controller. RL achieved substantial energy savings (22\% relative to the
existing controller), slightly exceeding MPC's savings (20\%), albeit with
modestly higher occupant discomfort. However, when energy savings were
normalized for the level of comfort provided, MPC demonstrated superior
performance. This study's empirical results show that while RL reduces
engineering overhead, it introduces practical trade-offs in model accuracy and
operational robustness. The key lessons learned concern the difficulties of
safe controller initialization, navigating the mismatch between control actions
and their practical implementation, and maintaining the integrity of online
learning in a live environment. These insights pinpoint the essential research
directions needed to advance RL from a promising concept to a truly scalable
HVAC control solution.

</details>


### [80] [A Robust Neural Control Design for Multi-drone Slung Payload Manipulation with Control Contraction Metrics](https://arxiv.org/abs/2510.01489)
*Xinyuan Liang,Longhao Qian,Yi Lok Lo,Hugh H. T. Liu*

Main category: eess.SY

TL;DR: 提出了一种用于三无人机吊挂载荷运输系统的鲁棒神经控制设计，在外部干扰下跟踪参考路径，结合控制收缩度量和不确定性扰动估计器实现模块化控制。


<details>
  <summary>Details</summary>
Motivation: 解决多无人机吊挂载荷系统在外部干扰下的轨迹跟踪问题，需要设计能够处理控制输入饱和约束并补偿持续扰动的鲁棒控制器。

Method: 使用控制收缩度量(CCM)生成神经指数收敛基线控制器，结合不确定性扰动估计器(UDE)技术动态补偿持续扰动，实现模块化设计。

Result: 仿真验证了所提控制设计在外部干扰下跟踪复杂轨迹的能力，系统具有稳定性和鲁棒性。

Conclusion: 提出的CCM控制器和UDE补偿器结合框架能够有效处理外部干扰，在满足特定假设条件下实现零轨迹跟踪误差。

Abstract: This paper presents a robust neural control design for a three-drone slung
payload transportation system to track a reference path under external
disturbances. The control contraction metric (CCM) is used to generate a neural
exponentially converging baseline controller while complying with control input
saturation constraints. We also incorporate the uncertainty and disturbance
estimator (UDE) technique to dynamically compensate for persistent
disturbances. The proposed framework yields a modularized design, allowing the
controller and estimator to perform their individual tasks and achieve a zero
trajectory tracking error if the disturbances meet certain assumptions. The
stability and robustness of the complete system, incorporating both the CCM
controller and the UDE compensator, are presented. Simulations are conducted to
demonstrate the capability of the proposed control design to follow complicated
trajectories under external disturbances.

</details>


### [81] [Off-Policy Reinforcement Learning with Anytime Safety Guarantees via Robust Safe Gradient Flow](https://arxiv.org/abs/2510.01492)
*Pol Mestres,Arnau Marzabal,Jorge Cortés*

Main category: eess.SY

TL;DR: 提出RSGF-RL算法，解决带约束强化学习问题，确保每次迭代都产生满足约束的策略，具有任意时间保证。


<details>
  <summary>Details</summary>
Motivation: 解决带约束强化学习问题中需要保证每次迭代都产生安全策略的需求，提供任意时间保证。

Method: 基于鲁棒安全梯度流(RSGF)的离散化设计，使用离策略算法，通过episodic数据估计价值函数及其梯度，通过求解凸二次约束二次规划更新策略参数。

Result: 理论分析确定了确保安全策略更新和从不安全策略恢复所需的episode数量，证明了算法几乎必然收敛到RL问题的KKT点集。在导航示例和倒立摆系统上的仿真显示了优于现有技术的性能。

Conclusion: RSGF-RL算法能够有效解决带约束强化学习问题，提供任意时间安全保证，并在实验中表现出优越性能。

Abstract: This paper considers the problem of solving constrained reinforcement
learning (RL) problems with anytime guarantees, meaning that the algorithmic
solution must yield a constraint-satisfying policy at every iteration of its
evolution. Our design is based on a discretization of the Robust Safe Gradient
Flow (RSGF), a continuous-time dynamics for anytime constrained optimization
whose forward invariance and stability properties we formally characterize. The
proposed strategy, termed RSGF-RL, is an off-policy algorithm which uses
episodic data to estimate the value functions and their gradients and updates
the policy parameters by solving a convex quadratically constrained quadratic
program. Our technical analysis combines statistical analysis, the theory of
stochastic approximation, and convex analysis to determine the number of
episodes sufficient to ensure that safe policies are updated to safe policies
and to recover from an unsafe policy, both with an arbitrary user-specified
probability, and to establish the asymptotic convergence to the set of KKT
points of the RL problem almost surely. Simulations on a navigation example and
the cart-pole system illustrate the superior performance of RSGF-RL with
respect to the state of the art.

</details>


### [82] [Probabilistic Control Barrier Functions: Safety in Probability for Discrete-Time Stochastic Systems](https://arxiv.org/abs/2510.01501)
*Pol Mestres,Blake Werner,Ryan K. Cosner,Aaron D. Ames*

Main category: eess.SY

TL;DR: 提出概率控制屏障函数方法，为随机系统设计具有概率安全保证的控制器


<details>
  <summary>Details</summary>
Motivation: 现实世界控制系统面临众多不可预测的不确定性，随机扰动会使确定性安全保证失效并导致灾难性安全故障

Method: 修改传统控制屏障函数概念，提出概率控制屏障函数，结合浓度不等式、场景方法和共形预测等不确定性量化方法

Result: 开发出计算可行的控制器，可在有限时间步内提供可调的概率安全保证

Conclusion: 该方法在四足机器人控制和硬件实验中展示了实用性，为随机系统提供了可靠的安全控制方案

Abstract: Control systems operating in the real world face countless sources of
unpredictable uncertainties. These random disturbances can render deterministic
guarantees inapplicable and cause catastrophic safety failures. To overcome
this, this paper proposes a method for designing safe controllers for
discrete-time stochastic systems that retain probabilistic guarantees of
safety. To do this we modify the traditional notion of a control barrier
function (CBF) to explicitly account for these stochastic uncertainties and
call these new modified functions probabilistic CBFs. We show that
probabilistic CBFs can be used to design controllers that guarantee safety over
a finite number of time steps with a prescribed probability. Next, by
leveraging various uncertainty quantification methods, such as concentration
inequalities, the scenario approach, and conformal prediction, we provide a
variety of sufficient conditions that result in computationally tractable
controllers with tunable probabilistic guarantees across a plethora of
practical scenarios. Finally, we showcase the applicability of our results in
simulation and hardware for the control of a quadruped robot.

</details>


### [83] [A Scalable Design Approach to Resilient Architectures for Interconnected Cyber-Physical Systems: Safety Guarantees under Multiple Attacks](https://arxiv.org/abs/2510.01541)
*Eman Badr,Abdullah Al Maruf*

Main category: eess.SY

TL;DR: 提出了一个可扩展框架，用于为互连的CPS分配弹性架构并调整其恢复时间，通过量化子系统在受损输入下对安全的影响指数来保证安全性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对单系统设置，扩展到互连CPS更具挑战性，因为需要考虑任意顺序和可能无限时间重叠的多子系统攻击。

Method: 引入标量指数量化每个子系统在受损输入下对安全的影响，这些指数在子系统间线性聚合；建立子系统指数与恢复时间之间的线性不等式关系；提出基于分段的方法加强条件；开发算法计算指数并寻找成本最优的架构分配。

Result: 通过互联房间温度调节的案例研究验证了该框架在不同攻击场景下的有效性。

Conclusion: 该框架能够为互连CPS提供可扩展的安全保证，指导弹性架构分配和恢复时间调优。

Abstract: Complex, interconnected cyber-physical systems (CPS) are increasingly
prevalent in domains such as power systems. Cyber-resilient architectures have
been proposed to recover compromised cyber components of CPS. Recent works have
studied tuning the recovery times of such architectures to guarantee safety in
single-system settings. Extending these designs to interconnected CPS is more
challenging, since solutions must account for attacks on multiple subsystems
that can occur in any order and potentially infinite possible temporal overlap.
This paper aims to address the aforementioned challenge by developing a
scalable framework to assign resilient architectures and to inform the tuning
of their recovery times. Our approach introduces a scalar index that quantifies
the impact of each subsystem on safety under compromised input. These indices
aggregate linearly across subsystems, enabling scalable analysis under
arbitrary attack orderings and temporal overlaps. We establish a linear
inequality relating each subsystem's index and recovery time that guarantees
safety and guides resilient architecture assignment. We also propose a
segmentation-based approach to strengthen the previously derived conditions. We
then present algorithms to compute the proposed indices and to find a
cost-optimal architecture assignment with a safety guarantee. We validate the
framework through a case study on temperature regulation in interconnected
rooms under different attack scenarios.

</details>


### [84] [Stability and Robustness of Time-Varying Opinion Dynamics: A Graph-Theoretic Approach](https://arxiv.org/abs/2510.01580)
*M. Hossein Abedinzadeh,Emrah Akyol*

Main category: eess.SY

TL;DR: 本文研究了时变Friedkin-Johnsen模型中的意见动态稳定性，引入了缺陷时态图和弱缺陷时态图等图论工具，证明了在无限循环缺陷时态图下的渐近稳定性、半周期缺陷网络中的指数稳定性，以及信任扩展模型在较弱条件下的渐近稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究时变社交网络中意见形成的稳定性问题，将代数收缩测试与基于图的推理相结合，为分析演化社交网络和人类-AI网络中的意见形成提供可扩展且具有弹性的工具。

Method: 引入缺陷时态图和弱缺陷时态图作为图论证书，将顽固影响和时态连通性与状态转移矩阵的收缩联系起来，通过p-LTI分解分析周期切换系统的极限集。

Result: 证明了在无限循环缺陷时态图下的渐近稳定性、半周期缺陷网络中的指数稳定性，以及信任扩展模型在较弱条件下的渐近稳定性；建立了ω极限集的有界性，表明长期意见保持在固有信念的凸包内；对于周期切换系统，ω极限集的大小最多为p。

Conclusion: 这些结果统一了代数收缩测试与可解释的基于图的推理，为分析演化社交和人类-AI网络中的意见形成提供了可扩展且具有弹性的工具，并证明了在有限扰动下指数稳定性仍然保持，确保了在噪声或不完美网络中的鲁棒性。

Abstract: We study the stability of opinion dynamics in the time-varying
Friedkin-Johnsen (TVFJ) model, which captures both persistent individual biases
and adaptive social influence. We introduce two temporal structures, defected
temporal graphs (DTGs) and weakly defected temporal graphs (WDTGs), that serve
as graph-theoretic certificates linking stubborn influence and temporal
connectivity to contraction of the state-transition matrix. Using these tools,
we prove asymptotic stability of TVFJ dynamics under infinitely recurring DTGs,
exponential stability in semi-periodic defected networks, and asymptotic
stability of a trust-based extension under the weaker condition of recurring
WDTGs. We also establish boundedness of the omega-limit set, showing that
long-run opinions remain within the convex hull of innate beliefs, and
characterize the limit set for periodically switching systems via a p-LTI
decomposition with the tight bound that the size of the omega-limit set is at
most p. Finally, we show that exponential stability persists under bounded
perturbations, ensuring robustness in noisy or imperfect networks. These
results unify algebraic contraction tests with interpretable graph-based
reasoning, providing scalable and resilient tools for analyzing opinion
formation in evolving social and human-AI networks.

</details>


### [85] [A TSO-DSO Coordination Framework via Analytical Representation and Monetization of PQV-Based Distribution System Flexibility](https://arxiv.org/abs/2510.01854)
*Burak Dindar,Can Berk Saner,Hüseyin Kemal Çakmak,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 提出了一种基于AC最优潮流的三维PQV可行运行区域构建方法，通过多项式拟合和成本函数实现TSO-DSO单轮协调，提高计算效率并保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 随着配电系统灵活性在输电网管理中的重要性增加，数据隐私问题阻碍了互操作性。PQ域中的可行运行区域概念虽能保护隐私，但在大规模网状配电网络中准确确定、可分析表示和经济评估方面仍面临挑战。

Method: 采用基于AC最优潮流的方法构建三维PQV-FOR，使用两阶段采样策略（边界框投影和斐波那契方向技术）高效捕获FOR，引入隐式多项式拟合进行解析表示，并推导PQV域上的二次成本函数。

Result: 在多达533个节点的网状配电系统测试中，该方法相比标准AC-OPF平均成本偏差最大仅为0.058%，计算时间减少高达58.11%。

Conclusion: 所提框架实现了TSO-DSO单轮协调，DSO提供解析FOR和成本模型，TSO在基于FOR的AC-OPF中确定PCC运行点，DSO通过本地OPF计算FPU调度，无需计算密集的解聚或迭代协调。

Abstract: As the role of distribution system (DS) flexibility in transmission system
operator (TSO) network management becomes increasingly vital, data privacy
concerns hinder seamless interoperability. The notion of the feasible operating
region (FOR), defined in the PQ domain, has emerged as a promising
privacy-preserving approach. However, effectively leveraging FOR in TSO
operations remains challenging due to three key factors: its accurate
determination in large-scale, meshed DS networks; its tractable analytical
representation; and its economic valuation. In the present paper, we propose a
novel AC optimal power flow (OPF)-based method to construct a three-dimensional
PQV-FOR, explicitly accounting for voltage variability and diverse
flexibility-providing unit (FPU) characteristics. The construction process
employs a two-stage sampling strategy that combines bounding box projection and
Fibonacci direction techniques to efficiently capture the FOR. We then
introduce an implicit polynomial fitting approach to analytically represent the
FOR. Furthermore, we derive a quadratic cost function over the PQV domain to
monetize the FOR. Thus, the proposed framework enables single-round TSO-DSO
coordination: the DSO provides an analytical FOR and cost model; the TSO
determines operating point at the point of common coupling (PCC) within the
FOR-based AC-OPF; and the DSO computes FPU dispatch by solving its local OPF,
without computationally intensive disaggregation or iterative coordination.
Case studies on meshed DS with up to 533 buses, integrated into TS,
demonstrates the method's efficiency compared to standard AC-OPF. On average,
the proposed approach yields negligible cost deviations of at most 0.058%
across test cases, while reducing computation times by up to 58.11%.

</details>


### [86] [Coordinated Car-following Using Distributed MPC](https://arxiv.org/abs/2510.02010)
*Di Shen,Qi Dai,Suzhou Huang*

Main category: eess.SY

TL;DR: 提出基于分布式模型预测控制的协调跟车算法，通过最佳响应动态和直接协商实现近似纳什均衡或集中优化的解决方案，显著提升交通效率并抑制幽灵拥堵。


<details>
  <summary>Details</summary>
Motivation: 解决传统跟车模型跟踪预设轨迹的局限性，通过直接优化驾驶策略来协调车辆行为，提高交通系统效率并控制拥堵波。

Method: 采用分布式模型预测控制框架，将动作序列重新参数化为规划时域上的曲线，通过网格搜索高效求解最优解。使用最佳响应动态和直接协商机制实现协调。

Result: 算法能在高密度交通条件下显著提升效率，有效抑制停走式幽灵拥堵波，且能在实时条件下执行。

Conclusion: 该方法为协调自适应巡航控制提供了新的建模框架，将交通控制问题转化为机制设计问题，实现完全激励兼容的车辆协调。

Abstract: Within the modeling framework of Markov games, we propose a series of
algorithms for coordinated car-following using distributed model predictive
control (DMPC). Instead of tracking prescribed feasible trajectories, driving
policies are solved directly as outcomes of the DMPC optimization given the
driver's perceivable states. The coordinated solutions are derived using the
best response dynamics via iterated self-play, and are facilitated by direct
negotiation using inter-agent or agent-infrastructure communication. These
solutions closely approximate either Nash equilibrium or centralized
optimization. By re-parameterizing the action sequence in DMPC as a curve along
the planning horizon, we are able to systematically reduce the original DMPC to
very efficient grid searches such that the optimal solution to the original
DMPC can be well executed in real-time. Within our modeling framework, it is
natural to cast traffic control problems as mechanism design problems, in which
all agents are endogenized on an equal footing with full incentive
compatibility. We show how traffic efficiency can be dramatically improved
while keeping stop-and-go phantom waves tamed at high vehicle densities. Our
approach can be viewed as an alternative way to formulate coordinated adaptive
cruise control (CACC) without an explicit platooning (or with all vehicles in
the traffic system treated as a single extended platoon). We also address the
issue of linear stability of the associated discrete-time traffic dynamics and
demonstrate why it does not always tell the full story about the traffic
stability.

</details>


### [87] [Event-triggered control and communication for single-master multi-slave teleoperation systems with Try-Once-Discard protocol](https://arxiv.org/abs/2510.02072)
*Yuling Li,Chenxi Li,Kun Liu,Jie Dong,Rolf Johansson*

Main category: eess.SY

TL;DR: 本文针对单主多从遥操作系统，结合TOD调度协议和事件触发机制，提出了自适应控制器和虚拟观测器，以优化网络带宽和能耗，实现主从同步。


<details>
  <summary>Details</summary>
Motivation: 随着从机械臂数量增加，通信带宽限制成为关键问题。现有方法如TOD调度协议和事件触发机制通常单独使用，本文旨在结合两者优化SMMS遥操作系统的网络带宽和能耗。

Method: 提出基于事件触发的控制和通信方案，结合TOD调度协议。开发自适应控制器和虚拟观测器，处理动态不确定性、相对速度不可用和时变延迟问题。

Result: 建立了SMMS遥操作系统在事件触发控制和通信方案下的稳定性判据，证明排除了Zeno行为。实验验证了所提算法的有效性。

Conclusion: 结合TOD调度和事件触发机制能有效优化SMMS遥操作系统的网络带宽和能耗，实现主从同步，且系统稳定性得到保证。

Abstract: Single-master multi-slave (SMMS) teleoperation systems can perform multiple
tasks remotely in a shorter time, cover large-scale areas, and adapt more
easily to single-point failures, thereby effectively encompassing a broader
range of applications. As the number of slave manipulators sharing a
communication network increases, the limitation of communication bandwidth
becomes critical. To alleviate bandwidth usage, the Try-Once-Discard (TOD)
scheduling protocol and event-triggered mechanisms are often employed
separately. In this paper, we combine both strategies to optimize network
bandwidth and energy consumption for SMMS teleoperation systems. Specifically,
we propose event-triggered control and communication schemes for a class of
SMMS teleoperation systems using the TOD scheduling protocol. Considering
dynamic uncertainties, the unavailability of relative velocities, and
time-varying delays, we develop adaptive controllers with virtual observers
based on event-triggered schemes to achieve master-slave synchronization.
Stability criteria for the SMMS teleoperation systems under these
event-triggered control and communication schemes are established,
demonstrating that Zeno behavior is excluded. Finally, experiments are
conducted to validate the effectiveness of the proposed algorithms.

</details>


### [88] [Cooperative Guidance for Aerial Defense in Multiagent Systems](https://arxiv.org/abs/2510.02087)
*Shivam Bajpai,Abhinav Sinha,Shashi Ranjan Kumar*

Main category: eess.SY

TL;DR: 提出了一种用于无人机空中防御的协同制导框架，保证在敌对无人机捕获高价值无人机前将其拦截，适用于动态不确定环境。


<details>
  <summary>Details</summary>
Motivation: 解决受争议空域中的关键空中防御挑战，传统启发式、最优控制或微分博弈方法存在局限，需要更鲁棒和保证的解决方案。

Method: 采用时间约束制导框架，基于真实比例导航方法，无需了解敌方策略或控制规律，计算轻量且可扩展。

Result: 从任意初始几何构型出发，关键交战误差在固定时间内收敛到零，确保任务成功，在各种对抗场景下验证有效。

Conclusion: 该方法为受争议空域环境中的实时自主防御提供了有效解决方案，具有鲁棒性和保证性能。

Abstract: This paper addresses a critical aerial defense challenge in contested
airspace, involving three autonomous aerial vehicles -- a hostile drone (the
pursuer), a high-value drone (the evader), and a protective drone (the
defender). We present a cooperative guidance framework for the evader-defender
team that guarantees interception of the pursuer before it can capture the
evader, even under highly dynamic and uncertain engagement conditions. Unlike
traditional heuristic, optimal control, or differential game-based methods, we
approach the problem within a time-constrained guidance framework, leveraging
true proportional navigation based approach that ensures robust and guaranteed
solutions to the aerial defense problem. The proposed strategy is
computationally lightweight, scalable to a large number of agent
configurations, and does not require knowledge of the pursuer's strategy or
control laws. From arbitrary initial geometries, our method guarantees that key
engagement errors are driven to zero within a fixed time, leading to a
successful mission. Extensive simulations across diverse and adversarial
scenarios confirm the effectiveness of the proposed strategy and its relevance
for real-time autonomous defense in contested airspace environments.

</details>


### [89] [Recurrent Control Barrier Functions: A Path Towards Nonparametric Safety Verification](https://arxiv.org/abs/2510.02127)
*Jixian Liu,Enrique Mallada*

Main category: eess.SY

TL;DR: 提出了一种新的循环控制屏障函数(RCBF)概念，利用轨迹的循环特性进行安全验证，避免了传统方法的高计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 传统Hamilton-Jacobi可达性分析和控制屏障函数方法在计算高维偏微分方程或大规模半定规划时计算负担重，难以找到表征安全集的函数。

Method: 引入循环控制屏障函数(RCBF)，利用轨迹的循环特性(即回到安全集)进行安全验证，并提出数据驱动的非参数方法来计算安全集。

Result: 在温和假设下，证明了RCBF条件对符号距离函数成立，将函数设计转化为集合识别问题，所得集合无需保持不变性即可证明安全性。

Conclusion: RCBF提供了一种可大规模并行化的数据驱动方法，在保守性和计算成本之间进行权衡，为复杂动态系统的安全验证提供了更高效的解决方案。

Abstract: Ensuring the safety of complex dynamical systems often relies on
Hamilton-Jacobi (HJ) Reachability Analysis or Control Barrier Functions (CBFs).
Both methods require computing a function that characterizes a safe set that
can be made (control) invariant. However, the computational burden of solving
high-dimensional partial differential equations (for HJ Reachability) or
large-scale semidefinite programs (for CBFs) makes finding such functions
challenging. In this paper, we introduce the notion of Recurrent Control
Barrier Functions (RCBFs), a novel class of CBFs that leverages a recurrent
property of the trajectories, i.e., coming back to a safe set, for safety
verification. Under mild assumptions, we show that the RCBF condition holds for
the signed-distance function, turning function design into set identification.
Notably, the resulting set need not be invariant to certify safety. We further
propose a data-driven nonparametric method to compute safe sets that is
massively parallelizable and trades off conservativeness against computational
cost.

</details>


### [90] [Detection and Identification of Sensor Attacks Using Data](https://arxiv.org/abs/2510.02183)
*Takumi Shinohara,Karl H. Johansson,Henrik Sandberg*

Main category: eess.SY

TL;DR: 提出了一种在模型无关设置下检测和识别数据驱动攻击的方法，即使输出数据包含恶意虚假数据注入也能工作


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设输出数据是干净的，但实际中数据可能已被恶意篡改，需要在数据已被破坏的情况下仍能检测和识别攻击

Method: 在两种场景下开发检测和识别算法：(1)系统操作员知道系统的稀疏可观测性条件；(2)数据部分干净（即无攻击）。两种场景都仅使用受损数据进行攻击检测和识别

Result: 通过三惯性系统的数值仿真验证了所提框架的有效性

Conclusion: 该方法能够在模型无关且数据已被恶意篡改的情况下，仅使用受损数据成功检测和识别虚假数据注入攻击

Abstract: In this paper, we investigate data-driven attack detection and identification
in a model-free setting. Unlike existing studies, we consider the case where
the available output data include malicious false-data injections. We aim to
detect and identify such attacks solely from the compromised data. We address
this problem in two scenarios: (1) when the system operator is aware of the
system's sparse observability condition, and (2) when the data are partially
clean (i.e., attack-free). In both scenarios, we derive conditions and
algorithms for detecting and identifying attacks using only the compromised
data. Finally, we demonstrate the effectiveness of the proposed framework via
numerical simulations on a three-inertia system.

</details>


### [91] [Computing Control Lyapunov-Barrier Functions: Softmax Relaxation and Smooth Patching with Formal Guarantees](https://arxiv.org/abs/2510.02223)
*Jun Liu,Maxwell Fitzsimmons*

Main category: eess.SY

TL;DR: 提出了一种合成平滑Lyapunov函数的计算框架，同时证明渐近稳定性和安全性，通过软最大松弛和反例引导细化来最大化可证明的安全域。


<details>
  <summary>Details</summary>
Motivation: 现有方法在证明系统安全性和稳定性时存在保守性，需要一种能够同时验证渐近稳定性和安全性的统一框架。

Method: 使用log-sum-exp松弛非光滑最大障碍函数，结合反例引导细化插入半空间切割，通过显式平滑构造将软最大障碍函数与控制Lyapunov函数拼接。

Result: 在基准系统（包括功率转换器）上，该方法获得的安全稳定区域比最先进的SOS兼容CBF-CLF设计更少保守。

Conclusion: 提出的框架能够有效合成同时证明稳定性和安全性的平滑Lyapunov函数，显著减少了现有方法的保守性。

Abstract: We present a computational framework for synthesizing a single smooth
Lyapunov function that certifies both asymptotic stability and safety. We show
that the existence of a strictly compatible pair of control barrier and control
Lyapunov functions (CBF-CLF) guarantees the existence of such a function on the
exact safe set certified by the barrier. To maximize the certifiable safe
domain while retaining differentiability, we employ a log-sum-exp (softmax)
relaxation of the nonsmooth maximum barrier, together with a
counterexample-guided refinement that inserts half-space cuts until a strict
barrier condition is verifiable. We then patch the softmax barrier with a CLF
via an explicit smooth bump construction, which is always feasible under the
strict compatibility condition. All conditions are formally verified using a
satisfiability modulo theories (SMT) solver, enabled by a reformulation of
Farkas' lemma for encoding strict compatibility. On benchmark systems,
including a power converter, we show that the certified safe stabilization
regions obtained with the proposed approach are often less conservative than
those achieved by state-of-the-art sum-of-squares (SOS) compatible CBF-CLF
designs.

</details>


### [92] [Game-theoretic Social Distancing in Competitive Bi-Virus SIS Epidemics](https://arxiv.org/abs/2510.02269)
*Benjamin Catalano,Keith Paarporn,Sebin Gracy*

Main category: eess.SY

TL;DR: 提出了一个结合双病毒SIS流行病模型和博弈论社交距离行为模型的框架，分析两种病毒株在人群中的共存条件及稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究复杂网络中传染病传播的驱动因素，特别是与疾病传播同步演化的社会行为，以及多种病毒株（如Delta和Omicron变种）同时传播的机制。

Method: 使用双病毒SIS流行病模型与基于进化博弈论的复制方程来建模社交距离行为，分析系统平衡点及其局部稳定性。

Result: 发现只有当两种病毒株的再生数相等时，地方性共存才可能发生；在相同再生数条件下，确定了产生共存平衡线的参数区域及其局部指数稳定性条件。

Conclusion: 通过数值模拟验证了理论分析，揭示了病毒株共存与社会行为相互作用的复杂动态特性。

Abstract: Numerous elements drive the spread of infectious diseases in complex
real-world networks. Of particular interest is social behaviors that evolve in
tandem with the spread of disease. Moreover, recent studies highlight the
importance of understanding how multiple strains spread simultaneously through
a population (e.g. Delta and Omicron variants of SARS-CoV-2). In this paper, we
propose a bi-virus SIS epidemic model coupled with a game-theoretic social
distancing behavior model. The behaviors are governed by replicator equations
from evolutionary game theory. The prevalence of each strain impacts the choice
of an individual to social distance, and, in turn, their behavior affects the
spread of each virus in the SIS model. Our analysis identifies equilibria of
the system and their local stability properties, which reveal several isolated
fixed points with varying levels of social distancing. We find that endemic
co-existence is possible only when the reproduction numbers of both strains are
equal. Assuming the reproduction number for each virus is the same, we identify
suitable parameter regimes that give rise to lines of coexistence equilibria.
Moreover, we also identify conditions for local exponential stability of said
lines of equilibria. We illustrate our findings with several numerical
simulations.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [93] [Kilometer-Scale GNSS-Denied UAV Navigation via Heightmap Gradients: A Winning System from the SPRIN-D Challenge](https://arxiv.org/abs/2510.01348)
*Michal Werner,David Čapek,Tomáš Musil,Ondřej Franěk,Tomáš Báča,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种完全机载的无人机系统，在GNSS拒绝环境下通过LiDAR高度图匹配和粒子滤波实现9公里长距离自主飞行，显著减少了里程计漂移。


<details>
  <summary>Details</summary>
Motivation: 解决GNSS拒绝环境下无人机长距离飞行的挑战：里程计漂移、新区域缺乏闭环检测、嵌入式平台计算能力有限。

Method: 集成感知、建图、规划和控制，采用轻量级漂移校正方法，通过梯度模板匹配将LiDAR局部高度图与先验地理数据高度图匹配，并在聚类粒子滤波中融合证据与里程计。

Result: 在竞赛中成功执行千米级飞行，穿越城市、森林和开阔地带，相对于原始里程计显著减少漂移，在仅CPU硬件上实时运行。

Conclusion: 该系统为GNSS拒绝环境下的无人机自主性设计提供了实用的现场部署见解。

Abstract: Reliable long-range flight of unmanned aerial vehicles (UAVs) in GNSS-denied
environments is challenging: integrating odometry leads to drift, loop closures
are unavailable in previously unseen areas and embedded platforms provide
limited computational power. We present a fully onboard UAV system developed
for the SPRIN-D Funke Fully Autonomous Flight Challenge, which required 9 km
long-range waypoint navigation below 25 m AGL (Above Ground Level) without GNSS
or prior dense mapping. The system integrates perception, mapping, planning,
and control with a lightweight drift-correction method that matches
LiDAR-derived local heightmaps to a prior geo-data heightmap via
gradient-template matching and fuses the evidence with odometry in a clustered
particle filter. Deployed during the competition, the system executed
kilometer-scale flights across urban, forest, and open-field terrain and
reduced drift substantially relative to raw odometry, while running in real
time on CPU-only hardware. We describe the system architecture, the
localization pipeline, and the competition evaluation, and we report practical
insights from field deployment that inform the design of GNSS-denied UAV
autonomy.

</details>


### [94] [Safe Motion Planning and Control Using Predictive and Adaptive Barrier Methods for Autonomous Surface Vessels](https://arxiv.org/abs/2510.01357)
*Alejandro Gonzalez-Garcia,Wei Xiao,Wei Wang,Alejandro Astudillo,Wilm Decré,Jan Swevers,Carlo Ratti,Daniela Rus*

Main category: cs.RO

TL;DR: 提出一种结合模型预测控制(MPC)和控制屏障函数(CBFs)的安全运动规划策略，通过时变膨胀椭圆障碍物表示来减少控制器的保守性，使自主船舶能在狭窄水域实时安全导航。


<details>
  <summary>Details</summary>
Motivation: 自主船舶在狭窄内陆水道等挑战性空间的安全运动规划至关重要，但传统方法要么计算密集要么过于保守。

Method: 结合MPC和CBFs，引入时变膨胀椭圆障碍物表示，根据船舶与障碍物的相对位置和姿态调整膨胀半径，MPC提供近似运动规划，高阶CBFs确保安全。

Result: 仿真和真实世界实验表明，该策略使全驱动自主机器人船舶能够在实时条件下通过狭窄空间并解决潜在死锁，同时确保安全。

Conclusion: 提出的自适应膨胀方法相比传统固定椭圆障碍物表述减少了保守性，实现了自主船舶在狭窄水域的安全实时导航。

Abstract: Safe motion planning is essential for autonomous vessel operations,
especially in challenging spaces such as narrow inland waterways. However,
conventional motion planning approaches are often computationally intensive or
overly conservative. This paper proposes a safe motion planning strategy
combining Model Predictive Control (MPC) and Control Barrier Functions (CBFs).
We introduce a time-varying inflated ellipse obstacle representation, where the
inflation radius is adjusted depending on the relative position and attitude
between the vessel and the obstacle. The proposed adaptive inflation reduces
the conservativeness of the controller compared to traditional fixed-ellipsoid
obstacle formulations. The MPC solution provides an approximate motion plan,
and high-order CBFs ensure the vessel's safety using the varying inflation
radius. Simulation and real-world experiments demonstrate that the proposed
strategy enables the fully-actuated autonomous robot vessel to navigate through
narrow spaces in real time and resolve potential deadlocks, all while ensuring
safety.

</details>


### [95] [A Stochastic Framework for Continuous-Time State Estimation of Continuum Robots](https://arxiv.org/abs/2510.01381)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种基于因子图优化的连续时间随机状态估计框架，用于连续体机器人的状态估计，能够处理未建模的外部干扰和数据丢失问题。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人状态估计方法通常使用计算复杂的动态模型、简化的形状近似或仅限于准静态方法，这些方法对未建模的干扰敏感。

Method: 采用基于连续时间运动学的因子图优化方法，结合高斯过程白噪声，使用简单的机器人模型配合高频率传感。

Result: 该方法能够估计机器人位姿、速度和应变的均值和协方差，可在时间或空间上连续插值，计算复杂度与时间呈线性关系。

Conclusion: 该方法在带有陀螺仪和位姿传感器的连续体机器人上验证了其在实际系统中的适用性。

Abstract: State estimation techniques for continuum robots (CRs) typically involve
using computationally complex dynamic models, simplistic shape approximations,
or are limited to quasi-static methods. These limitations can be sensitive to
unmodelled disturbances acting on the robot. Inspired by a factor-graph
optimization paradigm, this work introduces a continuous-time stochastic state
estimation framework for continuum robots. We introduce factors based on
continuous-time kinematics that are corrupted by a white noise Gaussian process
(GP). By using a simple robot model paired with high-rate sensing, we show
adaptability to unmodelled external forces and data dropout. The result
contains an estimate of the mean and covariance for the robot's pose, velocity,
and strain, each of which can be interpolated continuously in time or space.
This same interpolation scheme can be used during estimation, allowing for
inclusion of measurements on states that are not explicitly estimated. Our
method's inherent sparsity leads to a linear solve complexity with respect to
time and interpolation queries in constant time. We demonstrate our method on a
CR with gyroscope and pose sensors, highlighting its versatility in real-world
systems.

</details>


### [96] [VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation](https://arxiv.org/abs/2510.01388)
*Arthur Zhang,Xiangyun Meng,Luca Calliari,Dong-Ki Kim,Shayegan Omidshafiei,Joydeep Biswas,Ali Agha,Amirreza Shaban*

Main category: cs.RO

TL;DR: VENTURA是一个视觉语言导航系统，通过微调互联网预训练的扩散模型进行路径规划，生成视觉路径掩码来指导机器人导航，在真实世界评估中显著优于现有基准方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型在机器人导航任务中由于动作空间差异和预训练目标不同而难以迁移应用的问题，使机器人能够适应多样化的人类指令并在非结构化环境中安全操作。

Method: 使用互联网预训练的扩散模型进行微调，生成视觉路径掩码作为导航计划，通过轻量级的行为克隆策略将视觉计划转换为可执行轨迹，利用自监督跟踪模型和VLM增强的标注进行规模化训练。

Result: 在真实世界评估中，VENTURA在物体到达、避障和地形偏好任务上优于最先进的基准方法，成功率提高33%，碰撞减少54%，并展现出对未见任务组合的泛化能力。

Conclusion: VENTURA通过视觉路径规划方法有效解决了视觉语言模型在机器人导航中的迁移问题，展现出强大的性能和组合泛化能力。

Abstract: Robots must adapt to diverse human instructions and operate safely in
unstructured, open-world environments. Recent Vision-Language models (VLMs)
offer strong priors for grounding language and perception, but remain difficult
to steer for navigation due to differences in action spaces and pretraining
objectives that hamper transferability to robotics tasks. Towards addressing
this, we introduce VENTURA, a vision-language navigation system that finetunes
internet-pretrained image diffusion models for path planning. Instead of
directly predicting low-level actions, VENTURA generates a path mask (i.e. a
visual plan) in image space that captures fine-grained, context-aware
navigation behaviors. A lightweight behavior-cloning policy grounds these
visual plans into executable trajectories, yielding an interface that follows
natural language instructions to generate diverse robot behaviors. To scale
training, we supervise on path masks derived from self-supervised tracking
models paired with VLM-augmented captions, avoiding manual pixel-level
annotation or highly engineered data collection setups. In extensive real-world
evaluations, VENTURA outperforms state-of-the-art foundation model baselines on
object reaching, obstacle avoidance, and terrain preference tasks, improving
success rates by 33% and reducing collisions by 54% across both seen and unseen
scenarios. Notably, we find that VENTURA generalizes to unseen combinations of
distinct tasks, revealing emergent compositional capabilities. Videos, code,
and additional materials: https://venturapath.github.io

</details>


### [97] [INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models](https://arxiv.org/abs/2510.01389)
*Ulas Berk Karli,Ziyao Shangguan,Tesca FItzgerald*

Main category: cs.RO

TL;DR: INSIGHT框架利用token级不确定性信号预测VLA模型何时需要请求人类帮助，通过训练紧凑的transformer分类器来映射不确定性序列到帮助触发信号。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型缺乏内省机制来预测失败和请求人类监督，需要开发能够主动识别不确定情况并寻求帮助的机制。

Method: 使用π₀-FAST作为基础模型，提取每个token的熵、对数概率以及基于Dirichlet的认知和偶然不确定性估计，训练transformer分类器将这些序列映射到帮助触发信号。

Result: 强监督标签能捕捉细粒度不确定性动态实现可靠的帮助检测，弱监督标签在训练和评估对齐时仍能提供有竞争力的内省能力，建模token级不确定性信号的时间演化比静态序列级评分具有更强的预测能力。

Conclusion: 这是对VLA中基于不确定性的内省机制的首个系统评估，为主动学习和通过选择性人类干预实现实时错误缓解开辟了未来途径。

Abstract: Recent Vision-Language-Action (VLA) models show strong generalization
capabilities, yet they lack introspective mechanisms for anticipating failures
and requesting help from a human supervisor. We present \textbf{INSIGHT}, a
learning framework for leveraging token-level uncertainty signals to predict
when a VLA should request help. Using $\pi_0$-FAST as the underlying model, we
extract per-token \emph{entropy}, \emph{log-probability}, and Dirichlet-based
estimates of \emph{aleatoric and epistemic uncertainty}, and train compact
transformer classifiers to map these sequences to help triggers. We explore
supervision regimes for strong or weak supervision, and extensively compare
them across in-distribution and out-of-distribution tasks. Our results show a
trade-off: strong labels enable models to capture fine-grained uncertainty
dynamics for reliable help detection, while weak labels, though noisier, still
support competitive introspection when training and evaluation are aligned,
offering a scalable path when dense annotation is impractical. Crucially, we
find that modeling the temporal evolution of token-level uncertainty signals
with transformers provides far greater predictive power than static
sequence-level scores. This study provides the first systematic evaluation of
uncertainty-based introspection in VLAs, opening future avenues for active
learning and for real-time error mitigation through selective human
intervention.

</details>


### [98] [Beyond Collision Cones: Dynamic Obstacle Avoidance for Nonholonomic Robots via Dynamic Parabolic Control Barrier Functions](https://arxiv.org/abs/2510.01402)
*Hun Kuk Park,Taekyung Kim,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出动态抛物线控制屏障函数（DPCBF），通过动态调整抛物线边界来解决非完整机器人在密集动态环境中CBF方法保守性和不可行性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于碰撞锥或速度障碍的CBF方法仅考虑相对速度角度，过于保守，在密集场景中容易导致二次规划不可行。

Method: 使用动态抛物线边界定义安全集，抛物线的顶点和曲率根据障碍物距离和相对速度大小动态调整，创建限制更少的安全约束。

Result: DPCBF控制器显著提高了导航成功率和QP可行性，能在100个动态障碍物的密集环境中成功导航，而基于碰撞锥的方法因不可行性而失败。

Conclusion: DPCBF方法有效解决了非完整机器人在动态密集环境中的安全控制问题，相比传统方法具有更好的性能和可行性。

Abstract: Control Barrier Functions (CBFs) are a powerful tool for ensuring the safety
of autonomous systems, yet applying them to nonholonomic robots in cluttered,
dynamic environments remains an open challenge. State-of-the-art methods often
rely on collision-cone or velocity-obstacle constraints which, by only
considering the angle of the relative velocity, are inherently conservative and
can render the CBF-based quadratic program infeasible, particularly in dense
scenarios. To address this issue, we propose a Dynamic Parabolic Control
Barrier Function (DPCBF) that defines the safe set using a parabolic boundary.
The parabola's vertex and curvature dynamically adapt based on both the
distance to an obstacle and the magnitude of the relative velocity, creating a
less restrictive safety constraint. We prove that the proposed DPCBF is valid
for a kinematic bicycle model subject to input constraints. Extensive
comparative simulations demonstrate that our DPCBF-based controller
significantly enhances navigation success rates and QP feasibility compared to
baseline methods. Our approach successfully navigates through dense
environments with up to 100 dynamic obstacles, scenarios where collision
cone-based methods fail due to infeasibility.

</details>


### [99] [How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?](https://arxiv.org/abs/2510.01404)
*Lexi Foland,Thomas Cohn,Adam Wei,Nicholas Pfaff,Boyuan Chen,Russ Tedrake*

Main category: cs.RO

TL;DR: 该论文研究扩散策略在机器人模仿学习中学习运动学约束的能力，通过双手拾放任务案例发现扩散策略能粗略学习约束流形，但受数据集大小和质量影响，而约束流形曲率的影响不明确。


<details>
  <summary>Details</summary>
Motivation: 研究扩散策略是否能够精确学习训练数据中的运动学约束，因为任务性能本身不能可靠反映策略学习约束的能力。

Method: 通过双手拾放任务案例研究，分析数据集大小、数据集质量和约束流形曲率三个因素对训练策略的影响。

Result: 扩散策略能够学习约束流形的粗略近似，数据集大小和质量的下降会负面影响学习效果，而约束流形曲率与约束满足度和任务成功率的关系不明确。

Conclusion: 扩散策略能够学习运动学约束，但学习效果受数据集特征影响，硬件评估验证了结果在现实世界中的适用性。

Abstract: Diffusion policies have shown impressive results in robot imitation learning,
even for tasks that require satisfaction of kinematic equality constraints.
However, task performance alone is not a reliable indicator of the policy's
ability to precisely learn constraints in the training data. To investigate, we
analyze how well diffusion policies discover these manifolds with a case study
on a bimanual pick-and-place task that encourages fulfillment of a kinematic
constraint for success. We study how three factors affect trained policies:
dataset size, dataset quality, and manifold curvature. Our experiments show
diffusion policies learn a coarse approximation of the constraint manifold with
learning affected negatively by decreases in both dataset size and quality. On
the other hand, the curvature of the constraint manifold showed inconclusive
correlations with both constraint satisfaction and task success. A hardware
evaluation verifies the applicability of our results in the real world. Project
website with additional results and visuals:
https://diffusion-learns-kinematic.github.io

</details>


### [100] [AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation](https://arxiv.org/abs/2510.01433)
*Anukriti Singh,Kasra Torshizi,Khuzema Habib,Kelin Yu,Ruohan Gao,Pratap Tokekar*

Main category: cs.RO

TL;DR: AFFORD2ACT是一个基于视觉的机器人学习框架，通过文本提示和单张图像提取语义2D关键点，构建紧凑的38维状态策略，在15分钟内完成训练，在多样化真实世界操作任务中实现82%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决基于视觉的机器人学习依赖密集图像或点云输入导致计算负担重、包含无关背景特征的问题，以及现有基于关键点方法依赖手动启发式或任务耦合选择，限制可扩展性和语义理解。

Method: 采用三阶段流程：1) 可操作性过滤；2) 类别级关键点构建；3) 基于transformer的策略学习，嵌入门控机制推理最相关关键点。

Result: 在多样化真实世界操作任务中，AFFORD2ACT持续提升数据效率，在未见过的物体、新类别、背景和干扰物上达到82%的成功率，无需本体感知或密集表示即可实时运行。

Conclusion: AFFORD2ACT框架通过可操作性引导的关键点提取，实现了高效、轻量且语义丰富的机器人操作学习，在数据效率和泛化能力方面表现出色。

Abstract: Vision-based robot learning often relies on dense image or point-cloud
inputs, which are computationally heavy and entangle irrelevant background
features. Existing keypoint-based approaches can focus on manipulation-centric
features and be lightweight, but either depend on manual heuristics or
task-coupled selection, limiting scalability and semantic understanding. To
address this, we propose AFFORD2ACT, an affordance-guided framework that
distills a minimal set of semantic 2D keypoints from a text prompt and a single
image. AFFORD2ACT follows a three-stage pipeline: affordance filtering,
category-level keypoint construction, and transformer-based policy learning
with embedded gating to reason about the most relevant keypoints, yielding a
compact 38-dimensional state policy that can be trained in 15 minutes, which
performs well in real-time without proprioception or dense representations.
Across diverse real-world manipulation tasks, AFFORD2ACT consistently improves
data efficiency, achieving an 82% success rate on unseen objects, novel
categories, backgrounds, and distractors.

</details>


### [101] [Differentiable Skill Optimisation for Powder Manipulation in Laboratory Automation](https://arxiv.org/abs/2510.01438)
*Minglun Wei,Xintong Yang,Yu-Kun Lai,Ze Ji*

Main category: cs.RO

TL;DR: 提出了一种用于实验室粉末运输的轨迹优化框架，结合可微分物理模拟、低维技能空间参数化和课程学习策略，实现了接触丰富的机器人轨迹端到端优化。


<details>
  <summary>Details</summary>
Motivation: 机器人自动化正在加速科学发现，但粉末的精确操作仍然具有挑战性，特别是在需要准确性和稳定性的运输任务中。

Method: 使用可微分物理模拟精确建模颗粒动力学，通过低维技能空间参数化降低优化复杂度，采用基于课程学习的策略在长时域上逐步提升任务能力。

Result: 实验结果表明，与强化学习基线相比，所提方法实现了更高的任务成功率和稳定性。

Conclusion: 该框架能够在保持稳定性和收敛效率的同时，实现接触丰富的机器人轨迹的端到端优化。

Abstract: Robotic automation is accelerating scientific discovery by reducing manual
effort in laboratory workflows. However, precise manipulation of powders
remains challenging, particularly in tasks such as transport that demand
accuracy and stability. We propose a trajectory optimisation framework for
powder transport in laboratory settings, which integrates differentiable
physics simulation for accurate modelling of granular dynamics, low-dimensional
skill-space parameterisation to reduce optimisation complexity, and a
curriculum-based strategy that progressively refines task competence over long
horizons. This formulation enables end-to-end optimisation of contact-rich
robot trajectories while maintaining stability and convergence efficiency.
Experimental results demonstrate that the proposed method achieves superior
task success rates and stability compared to the reinforcement learning
baseline.

</details>


### [102] [Touching the tumor boundary: A pilot study on ultrasound based virtual fixtures for breast-conserving surgery](https://arxiv.org/abs/2510.01452)
*Laura Connolly,Tamas Ungi,Adnan Munawar,Anton Deguet,Chris Yeung,Russell H. Taylor,Parvin Mousavi,Gabor Fichtinger Keyvan Hashtrudi-Zaad*

Main category: cs.RO

TL;DR: 开发了一种协作机器人引导系统，通过触觉反馈帮助在保乳手术中定位肿瘤边界，在模拟实验中证明能改善切除边缘并降低手术难度。


<details>
  <summary>Details</summary>
Motivation: 保乳手术中肿瘤边界定位困难，因为肿瘤通常高度移动、不可触及且边界不规则，需要更好的定位方法。

Method: 将小型触觉机器人改装为协作控制的手术工具，结合超声和电磁导航识别肿瘤边界，当手术工具碰撞肿瘤边界时施加禁止区域虚拟约束。

Result: 虚拟约束引导改善了切除边缘，用户在使用触觉反馈时感觉任务更轻松、挫败感更低、工作量更少，但也发现了一些对手术流程的意外影响。

Conclusion: 虚拟约束有助于在模拟保乳手术中定位肿瘤边界，未来将进行更广泛的用户研究来验证结果并优化引导系统。

Abstract: Purpose: Delineating tumor boundaries during breast-conserving surgery is
challenging as tumors are often highly mobile, non-palpable, and have
irregularly shaped borders. To address these challenges, we introduce a
cooperative robotic guidance system that applies haptic feedback for tumor
localization. In this pilot study, we aim to assess if and how this system can
be successfully integrated into breast cancer care.
  Methods: A small haptic robot is retrofitted with an electrocautery blade to
operate as a cooperatively controlled surgical tool. Ultrasound and
electromagnetic navigation are used to identify the tumor boundaries and
position. A forbidden region virtual fixture is imposed when the surgical tool
collides with the tumor boundary. We conducted a study where users were asked
to resect tumors from breast simulants both with and without the haptic
guidance. We then assess the results of these simulated resections both
qualitatively and quantitatively.
  Results: Virtual fixture guidance is shown to improve resection margins. On
average, users find the task to be less mentally demanding, frustrating, and
effort intensive when haptic feedback is available. We also discovered some
unanticipated impacts on surgical workflow that will guide design adjustments
and training protocol moving forward.
  Conclusion: Our results suggest that virtual fixtures can help localize tumor
boundaries in simulated breast-conserving surgery. Future work will include an
extensive user study to further validate these results and fine-tune our
guidance system.

</details>


### [103] [VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs](https://arxiv.org/abs/2510.01483)
*Mohamad Al Mdfaa,Svetlana Lukina,Timur Akhtyamov,Arthur Nigmatzyanov,Dmitrii Nalberskii,Sergey Zagoruyko,Gonzalo Ferrer*

Main category: cs.RO

TL;DR: VL-KnG是一个视觉场景理解系统，通过时空知识图谱构建和高效查询处理解决机器人导航中视觉语言模型的局限性，在真实机器人部署中达到77.27%成功率和76.92%答案准确率。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在机器人导航中的三个基本限制：缺乏持久场景记忆、空间推理能力有限、无法有效扩展视频时长以适应实时应用。

Method: 将视频序列分块处理，利用现代视觉语言模型构建持久知识图谱，通过可查询的图结构实现可解释的空间推理。

Result: 在真实差分驱动机器人上部署，达到77.27%成功率和76.92%答案准确率，性能与Gemini 2.5 Pro相当，同时提供可解释推理和计算效率。

Conclusion: VL-KnG系统在机器人导航任务中表现出色，提供了可解释的推理支持、计算效率，适用于定位、导航和规划等不同任务。

Abstract: Vision-language models (VLMs) have shown potential for robot navigation but
encounter fundamental limitations: they lack persistent scene memory, offer
limited spatial reasoning, and do not scale effectively with video duration for
real-time application. We present VL-KnG, a Visual Scene Understanding system
that tackles these challenges using spatiotemporal knowledge graph construction
and computationally efficient query processing for navigation goal
identification. Our approach processes video sequences in chunks utilizing
modern VLMs, creates persistent knowledge graphs that maintain object identity
over time, and enables explainable spatial reasoning through queryable graph
structures. We also introduce WalkieKnowledge, a new benchmark with about 200
manually annotated questions across 8 diverse trajectories spanning
approximately 100 minutes of video data, enabling fair comparison between
structured approaches and general-purpose VLMs. Real-world deployment on a
differential drive robot demonstrates practical applicability, with our method
achieving 77.27% success rate and 76.92% answer accuracy, matching Gemini 2.5
Pro performance while providing explainable reasoning supported by the
knowledge graph, computational efficiency for real-time deployment across
different tasks, such as localization, navigation and planning. Code and
dataset will be released after acceptance.

</details>


### [104] [Pose Estimation of a Thruster-Driven Bioinspired Multi-Link Robot](https://arxiv.org/abs/2510.01485)
*Nicholas B. Andrews,Yanhao Yang,Sofya Akhetova,Kristi A. Morgansen,Ross L. Hatton*

Main category: cs.RO

TL;DR: 提出了一种用于自由漂浮生物启发多连杆机器人的姿态估计方法，该机器人具有无驱动关节、连杆安装推进器和单陀螺仪，通过无迹卡尔曼滤波结合高斯过程残差学习来补偿非零均值非高斯噪声。


<details>
  <summary>Details</summary>
Motivation: 针对具有无驱动关节、连杆推进器和最小传感配置的自由漂浮多连杆机器人，解决其姿态估计的挑战，这种平台具有欠驱动和最小感知的特点。

Method: 使用无迹卡尔曼滤波增强高斯过程残差学习来补偿非零均值非高斯噪声，通过概念验证硬件实验和离线卡尔曼滤波分析进行验证。

Result: 实验表明机器人姿态可以可靠估计，在多步态数据集上训练的滤波器与仅在前进步态数据集上训练的滤波器在相同测试轨迹上表现相当。

Conclusion: 步态输入空间存在重叠，可以利用这一点减少训练数据需求，同时增强滤波器在多种步态间的泛化能力。

Abstract: This work demonstrates pose (position and shape) estimation for a
free-floating, bioinspired multi-link robot with unactuated joints,
link-mounted thrusters for control, and a single gyroscope per link, resulting
in an underactuated, minimally sensed platform. Through a proof-of-concept
hardware experiment and offline Kalman filter analysis, we show that the
robot's pose can be reliably estimated. State estimation is performed using an
unscented Kalman filter augmented with Gaussian process residual learning to
compensate for non-zero-mean, non-Gaussian noise. We further show that a filter
trained on a multi-gait dataset (forward, backward, left, right, and turning)
performs comparably to one trained on a larger forward-gait-only dataset when
both are evaluated on the same forward-gait test trajectory. These results
reveal overlap in the gait input space, which can be exploited to reduce
training data requirements while enhancing the filter's generalizability across
multiple gaits.

</details>


### [105] [Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments](https://arxiv.org/abs/2510.01519)
*Wei Han Chen,Yuchen Liu,Alexiy Buynitsky,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了一种分层规划框架来解决机器人导航中的谱偏差和灾难性遗忘问题，通过稀疏图捕获全局连通性，神经网络场解决局部障碍物导航，在复杂室内环境中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航方法存在局限性：传统采样方法难以控制分辨率和扩展性，模仿学习方法需要大量演示数据，而ANTFields方法受谱偏差和灾难性遗忘影响。需要一种能适应复杂场景的高效导航方案。

Method: 采用分层规划结构：高层使用稀疏图表示环境全局连通性，低层使用基于神经网络场的规划器通过求解Eikonal PDE来导航局部障碍物，这种物理信息策略克服了谱偏差和神经场拟合困难。

Result: 在大规模环境中验证了该框架，相比先前方法展现出更强的适应性和精度，能够实现平滑精确的成本景观表示。

Conclusion: 该分层规划框架有效解决了复杂室内环境中的导航挑战，具有在线探索、建图和实际导航的应用潜力。

Abstract: Robot navigation in large, complex, and unknown indoor environments is a
challenging problem. The existing approaches, such as traditional
sampling-based methods, struggle with resolution control and scalability, while
imitation learning-based methods require a large amount of demonstration data.
Active Neural Time Fields (ANTFields) have recently emerged as a promising
solution by using local observations to learn cost-to-go functions without
relying on demonstrations. Despite their potential, these methods are hampered
by challenges such as spectral bias and catastrophic forgetting, which diminish
their effectiveness in complex scenarios. To address these issues, our approach
decomposes the planning problem into a hierarchical structure. At the high
level, a sparse graph captures the environment's global connectivity, while at
the low level, a planner based on neural fields navigates local obstacles by
solving the Eikonal PDE. This physics-informed strategy overcomes common
pitfalls like spectral bias and neural field fitting difficulties, resulting in
a smooth and precise representation of the cost landscape. We validate our
framework in large-scale environments, demonstrating its enhanced adaptability
and precision compared to previous methods, and highlighting its potential for
online exploration, mapping, and real-world navigation.

</details>


### [106] [Real-time Multi-Plane Segmentation Based on GPU Accelerated High-Resolution 3D Voxel Mapping for Legged Robot Locomotion](https://arxiv.org/abs/2510.01592)
*Shun Niijima,Ryoichi Tsuzaki,Noriaki Takasugi,Masaya Kinoshita*

Main category: cs.RO

TL;DR: 提出了一种基于GPU加速高分辨率3D体素映射的实时多平面分割方法，用于腿式机器人运动，能在0.01米分辨率下以30Hz更新率实现快速准确的3D多平面分割。


<details>
  <summary>Details</summary>
Motivation: 现有在线平面映射方法难以平衡精度和计算效率：直接深度图像分割时间整合性差，高度图方法无法表示复杂3D结构（如悬垂），体素平面分割在实时应用中尚未探索。

Method: 开发了集成基于顶点的连通分量标记、随机采样一致性平面检测和凸包的新框架，利用GPU并行计算从高分辨率3D体素图中快速提取平面区域。

Result: 实验结果表明，该方法在0.01米分辨率下以超过30Hz更新率实现快速准确的3D多平面分割，检测到的平面可实时用于运动任务。

Conclusion: 在模拟环境和物理腿式机器人平台上的实验验证了该方法的有效性，确认了考虑3D平面结构时的稳健运动性能。

Abstract: This paper proposes a real-time multi-plane segmentation method based on
GPU-accelerated high-resolution 3D voxel mapping for legged robot locomotion.
Existing online planar mapping approaches struggle to balance accuracy and
computational efficiency: direct depth image segmentation from specific sensors
suffers from poor temporal integration, height map-based methods cannot
represent complex 3D structures like overhangs, and voxel-based plane
segmentation remains unexplored for real-time applications. To address these
limitations, we develop a novel framework that integrates vertex-based
connected component labeling with random sample consensus based plane detection
and convex hull, leveraging GPU parallel computing to rapidly extract planar
regions from point clouds accumulated in high-resolution 3D voxel maps.
Experimental results demonstrate that the proposed method achieves fast and
accurate 3D multi-plane segmentation at over 30 Hz update rate even at a
resolution of 0.01 m, enabling the detected planes to be utilized in real time
for locomotion tasks. Furthermore, we validate the effectiveness of our
approach through experiments in both simulated environments and physical legged
robot platforms, confirming robust locomotion performance when considering 3D
planar structures.

</details>


### [107] [MiniBEE: A New Form Factor for Compact Bimanual Dexterity](https://arxiv.org/abs/2510.01603)
*Sharfin Islam,Zewen Chen,Zhanpeng He,Swapneel Bhatt,Andres Permuy,Brock Taylor,James Vickery,Pedro Piacenza,Cheng Zhang,Matei Ciocarlie*

Main category: cs.RO

TL;DR: 提出MiniBEE系统，将两个低自由度机械臂耦合为紧凑的双手机器人末端执行器，通过穿戴式演示训练模仿学习策略，实现稳健的双手机器人操作。


<details>
  <summary>Details</summary>
Motivation: 传统双手机器人系统复杂且仅利用部分工作空间进行灵巧操作，需要更紧凑、轻量化的解决方案。

Method: 设计耦合两个低自由度机械臂的MiniBEE系统，制定运动学灵巧度指标优化设计，支持穿戴式数据收集和标准机械臂部署两种模式。

Result: 系统能够实现全工作空间内的灵巧操作，并通过穿戴式演示成功训练出稳健的模仿学习策略。

Conclusion: MiniBEE系统提供了一种紧凑、轻量化的双手机器人解决方案，扩展了灵巧操作的工作空间范围。

Abstract: Bimanual robot manipulators can achieve impressive dexterity, but typically
rely on two full six- or seven- degree-of-freedom arms so that paired grippers
can coordinate effectively. This traditional framework increases system
complexity while only exploiting a fraction of the overall workspace for
dexterous interaction. We introduce the MiniBEE (Miniature Bimanual
End-effector), a compact system in which two reduced-mobility arms (3+ DOF
each) are coupled into a kinematic chain that preserves full relative
positioning between grippers. To guide our design, we formulate a kinematic
dexterity metric that enlarges the dexterous workspace while keeping the
mechanism lightweight and wearable. The resulting system supports two
complementary modes: (i) wearable kinesthetic data collection with self-tracked
gripper poses, and (ii) deployment on a standard robot arm, extending dexterity
across its entire workspace. We present kinematic analysis and design
optimization methods for maximizing dexterous range, and demonstrate an
end-to-end pipeline in which wearable demonstrations train imitation learning
policies that perform robust, real-world bimanual manipulation.

</details>


### [108] [ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations](https://arxiv.org/abs/2510.01607)
*Qiyuan Zeng,Chengmeng Li,Jude St. John,Zhongyi Zhou,Junjie Wen,Guorui Feng,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: ActiveUMI是一个数据收集框架，通过VR遥操作将真实世界的人类演示转移到机器人上，特别关注双手机器人操作。该系统通过记录操作者的主动头部运动来学习视觉注意与操作之间的联系。


<details>
  <summary>Details</summary>
Motivation: 开发便携式数据收集系统，将真实世界的人类演示有效转移到机器人上，解决复杂双手操作任务的学习问题，并关注主动感知在操作中的重要性。

Method: 使用便携式VR遥操作套件和传感器化控制器，通过精确姿态对齐桥接人类-机器人运动学。关键技术包括沉浸式3D模型渲染、自包含可穿戴计算机和高效校准方法，特别记录操作者的主动头部运动。

Result: 在六个挑战性双手任务上评估，仅使用ActiveUMI数据训练的策略在分布内任务上达到70%的平均成功率，在新物体和新环境中保持56%的成功率，显示出强泛化能力。

Conclusion: 便携式数据收集系统与学习的主动感知相结合，为创建可泛化且高能力的真实世界机器人策略提供了有效且可扩展的途径。

Abstract: We present ActiveUMI, a framework for a data collection system that transfers
in-the-wild human demonstrations to robots capable of complex bimanual
manipulation. ActiveUMI couples a portable VR teleoperation kit with sensorized
controllers that mirror the robot's end-effectors, bridging human-robot
kinematics via precise pose alignment. To ensure mobility and data quality, we
introduce several key techniques, including immersive 3D model rendering, a
self-contained wearable computer, and efficient calibration methods.
ActiveUMI's defining feature is its capture of active, egocentric perception.
By recording an operator's deliberate head movements via a head-mounted
display, our system learns the crucial link between visual attention and
manipulation. We evaluate ActiveUMI on six challenging bimanual tasks. Policies
trained exclusively on ActiveUMI data achieve an average success rate of 70\%
on in-distribution tasks and demonstrate strong generalization, retaining a
56\% success rate when tested on novel objects and in new environments. Our
results demonstrate that portable data collection systems, when coupled with
learned active perception, provide an effective and scalable pathway toward
creating generalizable and highly capable real-world robot policies.

</details>


### [109] [FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models](https://arxiv.org/abs/2510.01642)
*Zijun Lin,Jiafei Duan,Haoquan Fang,Dieter Fox,Ranjay Krishna,Cheston Tan,Bihan Wen*

Main category: cs.RO

TL;DR: FailSafe是一个自动生成多样化失败案例和可执行恢复动作的系统，通过微调LLaVa-OneVision-7B构建FailSafe-VLM，显著提升了机器人从失败中检测和恢复的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作数据集主要提供地面真实轨迹，缺乏失败恢复能力。少数处理失败检测的数据集通常只提供文本解释，难以直接在VLA模型中使用。

Method: 引入FailSafe系统，自动生成失败案例和恢复动作，可应用于任何模拟器中的操作任务。通过微调LLaVa-OneVision-7B构建FailSafe-VLM。

Result: FailSafe-VLM成功帮助机械臂检测和恢复潜在失败，在Maniskill任务中将三个最先进VLA模型(pi0-FAST、OpenVLA、OpenVLA-OFT)的平均性能提升高达22.6%。

Conclusion: FailSafe-VLM能够泛化到不同的空间配置、相机视角和机器人实体，计划向社区发布FailSafe代码。

Abstract: Recent advances in robotic manipulation have integrated low-level robotic
control into Vision-Language Models (VLMs), extending them into
Vision-Language-Action (VLA) models. Although state-of-the-art VLAs achieve
strong performance in downstream robotic applications, supported by large-scale
crowd-sourced robot training data, they still inevitably encounter failures
during execution. Enabling robots to reason about and recover from
unpredictable and abrupt failures remains a critical challenge. Existing
robotic manipulation datasets, collected in either simulation or the real
world, primarily provide only ground-truth trajectories, leaving robots unable
to recover once failures occur. Moreover, the few datasets that address failure
detection typically offer only textual explanations, which are difficult to
utilize directly in VLA models. To address this gap, we introduce FailSafe, a
novel failure generation and recovery system that automatically produces
diverse failure cases paired with executable recovery actions. FailSafe can be
seamlessly applied to any manipulation task in any simulator, enabling scalable
creation of failure-action data. To demonstrate its effectiveness, we fine-tune
LLaVa-OneVision-7B (LLaVa-OV-7B) to build FailSafe-VLM. Experimental results
show that FailSafe-VLM successfully helps robotic arm detect and recover from
potential failures, improving the performance of three state-of-the-art VLA
models pi0-FAST, OpenVLA, OpenVLA-OFT) by up to 22.6% on average across several
tasks in Maniskill. Furthermore, FailSafe-VLM could generalize across different
spatial configurations, camera viewpoints, and robotic embodiments. We plan to
release the FailSafe code to the community.

</details>


### [110] [Statistical Uncertainty Learning for Robust Visual-Inertial State Estimation](https://arxiv.org/abs/2510.01648)
*Seungwon Choi,Donggyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: 提出了一种在线学习测量可靠性的统计框架，通过多视图几何一致性作为自监督，动态评估视觉惯性里程计中传感器测量的可靠性，相比固定不确定性参数的方法显著提升了跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法假设所有测量具有静态、均匀的不确定性，无法捕捉真实世界数据中动态变化的误差特性，限制了鲁棒视觉惯性里程计的性能。

Method: 利用多视图几何一致性作为自监督，从传感器数据和优化结果中在线学习测量可靠性评估，推断地标不确定性并在优化过程中自适应加权视觉测量。

Result: 在EuRoC数据集上的评估显示，相比固定不确定性参数的基线方法，平均平移误差减少约24%，旋转误差减少约42%，框架能够实时运行且具有更高的精度和鲁棒性。

Conclusion: 所提出的统计框架能够在线学习测量可靠性，显著提升视觉惯性里程计的跟踪精度和鲁棒性，源代码将公开以促进可复现性和进一步研究。

Abstract: A fundamental challenge in robust visual-inertial odometry (VIO) is to
dynamically assess the reliability of sensor measurements. This assessment is
crucial for properly weighting the contribution of each measurement to the
state estimate. Conventional methods often simplify this by assuming a static,
uniform uncertainty for all measurements. This heuristic, however, may be
limited in its ability to capture the dynamic error characteristics inherent in
real-world data. To improve this limitation, we present a statistical framework
that learns measurement reliability assessment online, directly from sensor
data and optimization results. Our approach leverages multi-view geometric
consistency as a form of self-supervision. This enables the system to infer
landmark uncertainty and adaptively weight visual measurements during
optimization. We evaluated our method on the public EuRoC dataset,
demonstrating improvements in tracking accuracy with average reductions of
approximately 24\% in translation error and 42\% in rotation error compared to
baseline methods with fixed uncertainty parameters. The resulting framework
operates in real time while showing enhanced accuracy and robustness. To
facilitate reproducibility and encourage further research, the source code will
be made publicly available.

</details>


### [111] [Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation](https://arxiv.org/abs/2510.01661)
*Yifei Simon Shao,Yuchen Zheng,Sunan Sun,Pratik Chaudhari,Vijay Kumar,Nadia Figueroa*

Main category: cs.RO

TL;DR: SymSkill是一个结合模仿学习和任务运动规划优点的统一学习框架，能够实现组合泛化和实时故障恢复，通过从无标签演示中学习谓词、运算符和技能，并在执行时使用符号规划器组合技能。


<details>
  <summary>Details</summary>
Motivation: 解决多步操作任务中模仿学习缺乏组合泛化能力，以及任务运动规划规划延迟过高的问题，结合两者的优势实现实时组合和故障恢复。

Method: 从无标签、无分割的演示中联合学习谓词、运算符和技能，在执行时使用符号规划器组合和重新排序技能，同时在运动和符号层面进行实时恢复。

Result: 在RoboCasa模拟中执行12个单步任务成功率85%，无需额外数据即可组合成最多6次技能重组的复杂任务；在真实机器人上从5分钟无标签数据学习后能执行多个任务。

Conclusion: SymSkill框架成功结合了IL和TAMP的优势，实现了组合泛化和实时故障恢复，在模拟和真实环境中都表现出色。

Abstract: Multi-step manipulation in dynamic environments remains challenging. Two
major families of methods fail in distinct ways: (i) imitation learning (IL) is
reactive but lacks compositional generalization, as monolithic policies do not
decide which skill to reuse when scenes change; (ii) classical task-and-motion
planning (TAMP) offers compositionality but has prohibitive planning latency,
preventing real-time failure recovery. We introduce SymSkill, a unified
learning framework that combines the benefits of IL and TAMP, allowing
compositional generalization and failure recovery in real-time. Offline,
SymSkill jointly learns predicates, operators, and skills directly from
unlabeled and unsegmented demonstrations. At execution time, upon specifying a
conjunction of one or more learned predicates, SymSkill uses a symbolic planner
to compose and reorder learned skills to achieve the symbolic goals, while
performing recovery at both the motion and symbolic levels in real time.
Coupled with a compliant controller, SymSkill enables safe and uninterrupted
execution under human and environmental disturbances. In RoboCasa simulation,
SymSkill can execute 12 single-step tasks with 85% success rate. Without
additional data, it composes these skills into multi-step plans requiring up to
6 skill recompositions, recovering robustly from execution failures. On a real
Franka robot, we demonstrate SymSkill, learning from 5 minutes of unsegmented
and unlabeled play data, is capable of performing multiple tasks simply by goal
specifications. The source code and additional analysis can be found on
https://sites.google.com/view/symskill.

</details>


### [112] [Geometric Backstepping Control of Omnidirectional Tiltrotors Incorporating Servo-Rotor Dynamics for Robustness against Sudden Disturbances](https://arxiv.org/abs/2510.01675)
*Jaewoo Lee,Dongjae Lee,Jinwoo Lee,Hyungyu Lee,Yeonjoon Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出了一种考虑伺服和转子动力学的可变倾斜全向多旋翼几何反步控制器，相比忽略执行器动力学的基线方法，在快速平移跟踪、快速旋转跟踪和扰动恢复实验中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有执行器感知控制方法依赖于执行器输入与力矩之间的线性关系，无法捕捉可变倾斜角度引起的非线性特性，这限制了在激进飞行或扰动恢复中的有效性和可靠性。

Method: 利用多旋翼刚体动力学与非线性执行器动力学之间的级联结构，设计几何反步控制器，并建立整个系统的指数稳定性。

Result: 在三个实验场景中，所提控制器始终获得更好的跟踪性能，在最快平移轨迹跟踪和恢复实验中，基线方法发散并坠毁，而所提控制器保持稳定并成功完成任务。

Conclusion: 所提控制器能有效处理执行器非线性动力学，对模型参数不确定性具有鲁棒性，在激进飞行和扰动恢复场景中显著优于忽略执行器动力学的基线方法。

Abstract: This work presents a geometric backstepping controller for a variable-tilt
omnidirectional multirotor that explicitly accounts for both servo and rotor
dynamics. Considering actuator dynamics is essential for more effective and
reliable operation, particularly during aggressive flight maneuvers or recovery
from sudden disturbances. While prior studies have investigated actuator-aware
control for conventional and fixed-tilt multirotors, these approaches rely on
linear relationships between actuator input and wrench, which cannot capture
the nonlinearities induced by variable tilt angles. In this work, we exploit
the cascade structure between the rigid-body dynamics of the multirotor and its
nonlinear actuator dynamics to design the proposed backstepping controller and
establish exponential stability of the overall system. Furthermore, we reveal
parametric uncertainty in the actuator model through experiments, and we
demonstrate that the proposed controller remains robust against such
uncertainty. The controller was compared against a baseline that does not
account for actuator dynamics across three experimental scenarios: fast
translational tracking, rapid rotational tracking, and recovery from sudden
disturbance. The proposed method consistently achieved better tracking
performance, and notably, while the baseline diverged and crashed during the
fastest translational trajectory tracking and the recovery experiment, the
proposed controller maintained stability and successfully completed the tasks,
thereby demonstrating its effectiveness.

</details>


### [113] [PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via Multi-Simulator Dynamics Randomization](https://arxiv.org/abs/2510.01708)
*Zixing Lei,Zibo Zhou,Sheng Yin,Yueru Chen,Qingyao Xu,Weixin Li,Yunhong Wang,Bowei Tang,Wei Jing,Siheng Chen*

Main category: cs.RO

TL;DR: PolySim是一个多模拟器集成平台，通过同时训练多个异构模拟器来减少模拟器归纳偏差，实现零样本从模拟到真实世界的部署。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人全身控制在模拟到真实世界迁移中的模拟器归纳偏差问题，即单个模拟器的固有假设和限制导致的跨模拟器和模拟-真实世界之间的差异。

Method: 开发PolySim平台，在单个训练运行中同时启动来自不同引擎的并行环境，实现动态层面的领域随机化。

Result: 在模拟到模拟评估中显著减少运动跟踪误差，在MuJoCo上比IsaacSim基线提高执行成功率52.8%，并在真实Unitree G1机器人上实现零样本部署。

Conclusion: 多模拟器联合训练能有效缓解模拟器归纳偏差，实现更好的模拟到真实世界迁移性能。

Abstract: Humanoid whole-body control (WBC) policies trained in simulation often suffer
from the sim-to-real gap, which fundamentally arises from simulator inductive
bias, the inherent assumptions and limitations of any single simulator. These
biases lead to nontrivial discrepancies both across simulators and between
simulation and the real world. To mitigate the effect of simulator inductive
bias, the key idea is to train policies jointly across multiple simulators,
encouraging the learned controller to capture dynamics that generalize beyond
any single simulator's assumptions. We thus introduce PolySim, a WBC training
platform that integrates multiple heterogeneous simulators. PolySim can launch
parallel environments from different engines simultaneously within a single
training run, thereby realizing dynamics-level domain randomization.
Theoretically, we show that PolySim yields a tighter upper bound on simulator
inductive bias than single-simulator training. In experiments, PolySim
substantially reduces motion-tracking error in sim-to-sim evaluations; for
example, on MuJoCo, it improves execution success by 52.8 over an IsaacSim
baseline. PolySim further enables zero-shot deployment on a real Unitree G1
without additional fine-tuning, showing effective transfer from simulation to
the real world. We will release the PolySim code upon acceptance of this work.

</details>


### [114] [Contrastive Representation Regularization for Vision-Language-Action Models](https://arxiv.org/abs/2510.01711)
*Taeyoung Kim,Jimin Lee,Myungkyu Koo,Dongyoung Kim,Kyungmin Lee,Changyeon Kim,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: 提出了Robot State-aware Contrastive Loss (RS-CL)，一种用于VLA模型的表示正则化方法，通过将表示与机器人的本体感知状态对齐来改善机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在机器人操作中表现良好，但其表示对机器人信号（如控制动作和本体感知状态）不够敏感，导致表示不够优化。

Method: 引入RS-CL，使用机器人状态之间的相对距离作为软监督，将VLM表示与机器人本体感知状态更紧密地对齐，同时保持与标准VLA训练流程的兼容性。

Result: 在RoboCasa-Kitchen的拾取放置任务中，将成功率从30.8%提升到41.5%；在真实机器人操作任务中，成功率从45.0%提升到58.3%。

Conclusion: RS-CL是一种简单有效的表示正则化方法，能够显著提升VLA模型在机器人操作任务中的性能，通过更准确的位置控制改善抓取和放置精度。

Abstract: Vision-Language-Action (VLA) models have shown its capabilities in robot
manipulation by leveraging rich representations from pre-trained
Vision-Language Models (VLMs). However, their representations arguably remain
suboptimal, lacking sensitivity to robotic signals such as control actions and
proprioceptive states. To address the issue, we introduce Robot State-aware
Contrastive Loss (RS-CL), a simple and effective representation regularization
for VLA models, designed to bridge the gap between VLM representations and
robotic signals. In particular, RS-CL aligns the representations more closely
with the robot's proprioceptive states, by using relative distances between the
states as soft supervision. Complementing the original action prediction
objective, RS-CL effectively enhances control-relevant representation learning,
while being lightweight and fully compatible with standard VLA training
pipeline. Our empirical results demonstrate that RS-CL substantially improves
the manipulation performance of state-of-the-art VLA models; it pushes the
prior art from 30.8% to 41.5% on pick-and-place tasks in RoboCasa-Kitchen,
through more accurate positioning during grasping and placing, and boosts
success rates from 45.0% to 58.3% on challenging real-robot manipulation tasks.

</details>


### [115] [Dual-Mode Magnetic Continuum Robot for Targeted Drug Delivery](https://arxiv.org/abs/2510.01761)
*Wendu Zhang,Heng Wang,Shuangyi Wang,Yuanrui Huang*

Main category: cs.RO

TL;DR: 提出了一种径向嵌入永磁体的磁性连续体机器人，通过外部永磁体独立控制弯曲和扭转运动，并利用扭转剪切实现按需药物释放。


<details>
  <summary>Details</summary>
Motivation: 传统轴向磁化的磁性连续体机器人主要限于弯曲运动，需要扩展变形能力以实现更复杂的医疗操作。

Method: 在导管壁内径向嵌入永磁体，结合物理建模和有限元分析建立驱动原理，采用外层凹槽和内层板组成的双层阻塞机制。

Result: 实验验证了在实用场下的解耦模式控制，并在体模干预实验中展示了从管腔跟随到目标接近再到扭转激活释放的端到端操作。

Conclusion: 该紧凑、无缆平台将多功能变形与精确载荷输送相结合，在下一代定点治疗中具有强大潜力。

Abstract: Magnetic continuum robots (MCRs) enable minimally invasive navigation through
tortuous anatomical channels, yet axially magnetized designs have largely been
limited to bending-only motion. To expand deformation capabilities, this paper
presents a simple assembly that embeds permanent magnets radially within the
catheter wall, allowing a single externally steered permanent magnet to
independently induce either bending or torsion. A physics-based formulation
together with finite-element analysis establishes the actuation principles, and
benchtop experiments validate decoupled mode control under practical fields.
Building on this, a dual-layer blockage mechanism consisting of outer grooves
and inner plates leverages torsional shear to achieve on-demand drug release.
Finally, an in-phantom intervention experiment demonstrates end-to-end
operation: lumen following by bending for target approach, followed by
twist-activated release at the site. The resulting compact, cable-free platform
combines versatile deformation with precise payload delivery, indicating strong
potential for next-generation, site-specific therapies.

</details>


### [116] [An Anytime, Scalable and Complete Algorithm for Embedding a Manufacturing Procedure in a Smart Factory](https://arxiv.org/abs/2510.01770)
*Christopher Leet,Aidan Sciortino,Sven Koenig*

Main category: cs.RO

TL;DR: 提出了TS-ACES，首个可扩展的智能工厂嵌入（SFE）解决方案，能处理包含数百台机器的真实工业场景。


<details>
  <summary>Details</summary>
Motivation: 现有SFE求解器只能扩展到几十台机器，而现代智能工厂可能包含数百台机器，需要更可扩展的解决方案。

Method: 开发了基于交通系统的随时循环嵌入求解器（TS-ACES），这是一种完整的求解方法。

Result: TS-ACES能够扩展到基于真实工业场景的SFE实例，处理超过一百台机器的情况。

Conclusion: TS-ACES填补了现有SFE求解器无法扩展到大型智能工厂的空白，为工业应用提供了实用的解决方案。

Abstract: Modern automated factories increasingly run manufacturing procedures using a
matrix of programmable machines, such as 3D printers, interconnected by a
programmable transport system, such as a fleet of tabletop robots. To embed a
manufacturing procedure into a smart factory, an operator must: (a) assign each
of its processes to a machine and (b) specify how agents should transport parts
between machines. The problem of embedding a manufacturing process into a smart
factory is termed the Smart Factory Embedding (SFE) problem. State-of-the-art
SFE solvers can only scale to factories containing a couple dozen machines.
Modern smart factories, however, may contain hundreds of machines. We fill this
hole by introducing the first highly scalable solution to the SFE, TS-ACES, the
Traffic System based Anytime Cyclic Embedding Solver. We show that TS-ACES is
complete and can scale to SFE instances based on real industrial scenarios with
more than a hundred machines.

</details>


### [117] [SPARC: Spine with Prismatic and Revolute Compliance for Quadruped Robot](https://arxiv.org/abs/2510.01984)
*Yue Wang*

Main category: cs.RO

TL;DR: SPARC是一个紧凑的开源3自由度脊柱模块，结合了旋转和直线运动，具有可编程任务空间阻抗，用于四足机器人。


<details>
  <summary>Details</summary>
Motivation: 为四足机器人提供系统研究脊柱柔顺性的便携平台，实现闭环刚度和阻尼控制。

Method: 集成三个扭矩控制执行器、定制1kHz控制板和受保护电源单元，开发基于RNEA的计算加速度控制器，带有平滑Stribeck摩擦补偿。

Result: 准静态推拉测试显示线性力-位移特性，水平刚度300-700 N/m，相对误差≤1.5%；动态位移释放试验确认质量-弹簧-阻尼器响应。

Conclusion: SPARC为腿式运动中脊柱柔顺性的系统研究提供了便携平台，将发布完整的硬件和固件资源。

Abstract: We present SPARC, a compact, open-source 3-DoF sagittal-plane spine module
that combines revolute (pitch) and prismatic (axial) motion with programmable
task-space impedance for quadruped robots. The system integrates three
torque-controlled actuators, a custom 1 kHz control board, and a protected
power unit in a 1.26 kg package, enabling closed-loop stiffness and damping
shaping along x, z, and theta. We develop an RNEA-based computed-acceleration
controller with smooth Stribeck friction compensation to render spring-damper
behavior without explicit inertia shaping. Bench experiments validate the
approach. Quasi-static push-pull tests show linear force-displacement
characteristics with commanded horizontal stiffness spanning 300-700 N/m and <=
1.5% relative error (R^2 >= 0.992, narrow 95% CIs). Dynamic
displace-and-release trials confirm mass-spring-damper responses over multiple
damping settings, with small, interpretable phase deviations due to
configuration-dependent inertia and low-speed friction effects. A task-space PD
controller produces roughly linear stiffness but with greater variability and
coupling sensitivity. SPARC provides a portable platform for systematic studies
of spine compliance in legged locomotion and will be released with complete
hardware and firmware resources.

</details>


### [118] [Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2510.01795)
*Haibo Hu,Lianming Huang,Xinyu Wang,Yufei Cui,Nan Guan,Chun Jason Xue*

Main category: cs.RO

TL;DR: Nav-EE是一个基于导航先验的早期退出框架，通过预计算任务特定的退出层并基于导航信息动态应用，在自动驾驶中显著降低视觉语言模型的推理延迟，同时保持与完整推理相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在自动驾驶中应用日益广泛，但高推理延迟阻碍了实时部署。传统早期退出方法受限于任务依赖性，难以在多样化场景中泛化。作者观察到自动驾驶的导航系统可以预测即将到来的场景，这为任务特定的早期退出提供了机会。

Method: 提出Nav-EE框架：1）离线预计算任务特定的退出层；2）在线基于导航先验动态应用这些退出层；3）利用导航系统对即将场景（如交叉口、交通灯）的预测来指导早期退出决策。

Result: 在CODA、Waymo和BOSCH数据集上的实验显示，Nav-EE在保持与完整推理相当准确性的同时，将延迟降低了高达63.9%。在Autoware Universe中的实车集成进一步证明推理延迟从600ms降至300ms。

Conclusion: 将导航预见性与早期退出相结合，为在自动驾驶系统中高效部署大模型提供了可行路径，显著降低了推理延迟，支持复杂场景下的快速决策。

Abstract: Vision-Language Models (VLMs) are increasingly applied in autonomous driving
for unified perception and reasoning, but high inference latency hinders
real-time deployment. Early-exit reduces latency by terminating inference at
intermediate layers, yet its task-dependent nature limits generalization across
diverse scenarios. We observe that this limitation aligns with autonomous
driving: navigation systems can anticipate upcoming contexts (e.g.,
intersections, traffic lights), indicating which tasks will be required. We
propose Nav-EE, a navigation-guided early-exit framework that precomputes
task-specific exit layers offline and dynamically applies them online based on
navigation priors. Experiments on CODA, Waymo, and BOSCH show that Nav-EE
achieves accuracy comparable to full inference while reducing latency by up to
63.9%. Real-vehicle integration with Autoware Universe further demonstrates
reduced inference latency (600ms to 300ms), supporting faster decision-making
in complex scenarios. These results suggest that coupling navigation foresight
with early-exit offers a viable path toward efficient deployment of large
models in autonomous systems. Code and data are available at our anonymous
repository: https://anonymous.4open.science/r/Nav-EE-BBC4

</details>


### [119] [Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation](https://arxiv.org/abs/2510.01986)
*Varun Kotian,Vishrut Jain,Andrea Michelle Rios Lazcano,Daan Marinus Pool,Riender Happee,Barys Shyrokau*

Main category: cs.RO

TL;DR: 提出一种基于模型预测控制的运动提示算法，通过惩罚感官冲突和特定力误差来联合优化驾驶模拟器的保真度和舒适度，显著减少晕动症。


<details>
  <summary>Details</summary>
Motivation: 驾驶模拟器在研发中应用日益广泛，但由于缩放运动和非缩放视觉常导致晕动症，需要开发能同时优化保真度和舒适度的运动提示算法。

Method: 使用模型预测控制开发运动提示算法，在成本函数中惩罚感官冲突和特定力误差，进行人机闭环实验比较四种运动设置：两种MPC变体、自适应清洗和无运动情况。

Result: 实验结果显示，妥协方案相比自适应清洗和纯特定力跟踪算法，晕动症减少超过50%（平均MISC水平从3降至1.5），且保真度评级无显著下降。

Conclusion: 提出的方法综合考虑模拟器动力学和晕动症时间演化，在实现晕动症控制和特定力重现方面取得重要进展，支持模拟器的更广泛应用。

Abstract: Driving simulators are increasingly used in research and development.
However, simulators often cause motion sickness due to downscaled motion and
unscaled veridical visuals. In this paper, a motion cueing algorithm is
proposed that reduces motion sickness as predicted by the subjective vertical
conflict (SVC) model using model predictive control (MPC). Both sensory
conflict and specific force errors are penalised in the cost function, allowing
the algorithm to jointly optimise fidelity and comfort.
  Human-in-the-loop experiments were conducted to compare four simulator motion
settings: two variations of our MPC-based algorithm, one focused on pure
specific force tracking and the second compromising specific force tracking and
motion sickness minimisation, as well as reference adaptive washout and no
motion cases. The experiments were performed on a hexapod driving simulator
with participants exposed to passive driving.
  Experimental motion sickness results closely matched the sickness model
predictions. As predicted by the model, the no motion condition yielded the
lowest sickness levels. However, it was rated lowest in terms of fidelity. The
compromise solution reduced sickness by over 50% (average MISC level 3 to 1.5)
compared to adaptive washout and the algorithm focusing on specific force
tracking, without any significant reduction in fidelity rating.
  The proposed approach for developing MCA that takes into account both the
simulator dynamics and time evolution of motion sickness offers a significant
advancement in achieving an optimal control of motion sickness and specific
force recreation in driving simulators, supporting broader simulator use.

</details>


### [120] [What Matters in RL-Based Methods for Object-Goal Navigation? An Empirical Study and A Unified Framework](https://arxiv.org/abs/2510.01830)
*Hongze Wang,Boyang Sun,Jiaxu Xing,Fan Yang,Marco Hutter,Dhruv Shah,Davide Scaramuzza,Marc Pollefeys*

Main category: cs.RO

TL;DR: 本文对基于强化学习的物体目标导航系统进行了大规模实证研究，分解为感知、策略和测试时增强三个关键组件，发现感知质量和测试时策略是性能的决定性因素，而策略改进仅带来边际收益。


<details>
  <summary>Details</summary>
Motivation: 物体目标导航是移动机器人在日常环境中部署的关键能力，但目前缺乏对强化学习方法中真正驱动性能的组件进行统一分析。

Method: 通过大规模受控实验，将模块化RL系统分解为感知、策略和测试时增强三个组件，分别评估其贡献。

Result: 感知质量和测试时策略是性能的主要驱动因素，基于这些洞察构建的增强系统在SPL指标上超过现有最佳方法6.6%，成功率提高2.7%。

Conclusion: 研究不仅设定了新的性能标准，还为未来物体目标导航的发展和评估提供了原则性指导，同时揭示了RL代理与人类专家导航能力之间的显著差距。

Abstract: Object-Goal Navigation (ObjectNav) is a critical component toward deploying
mobile robots in everyday, uncontrolled environments such as homes, schools,
and workplaces. In this context, a robot must locate target objects in
previously unseen environments using only its onboard perception. Success
requires the integration of semantic understanding, spatial reasoning, and
long-horizon planning, which is a combination that remains extremely
challenging. While reinforcement learning (RL) has become the dominant
paradigm, progress has spanned a wide range of design choices, yet the field
still lacks a unifying analysis to determine which components truly drive
performance. In this work, we conduct a large-scale empirical study of modular
RL-based ObjectNav systems, decomposing them into three key components:
perception, policy, and test-time enhancement. Through extensive controlled
experiments, we isolate the contribution of each and uncover clear trends:
perception quality and test-time strategies are decisive drivers of
performance, whereas policy improvements with current methods yield only
marginal gains. Building on these insights, we propose practical design
guidelines and demonstrate an enhanced modular system that surpasses
State-of-the-Art (SotA) methods by 6.6% on SPL and by a 2.7% success rate. We
also introduce a human baseline under identical conditions, where experts
achieve an average 98% success, underscoring the gap between RL agents and
human-level navigation. Our study not only sets the SotA performance but also
provides principled guidance for future ObjectNav development and evaluation.

</details>


### [121] [Product Digital Twin Supporting End-of-life Phase of Electric Vehicle Batteries Utilizing Product-Process-Resource Asset Network](https://arxiv.org/abs/2510.02167)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 本文提出使用数字孪生技术优化电动汽车电池的拆解过程，通过扩展产品-过程-资源资产网络(PAN)为双向PAN(Bi-PAN)，同时覆盖制造和再制造/回收阶段，以支持循环经济。


<details>
  <summary>Details</summary>
Motivation: 在循环经济背景下，产品生命周期结束时应进行再制造或回收，但制造商往往不共享相关数据，阻碍了这些可持续过程。

Method: 采用数字孪生技术和扩展的产品-过程-资源资产网络(Bi-PAN)表示法，能够建模产品、生产资源、制造过程及其关系，并扩展到再制造/回收阶段。

Result: 通过电动汽车电池拆解案例验证，数字孪生技术能够灵活高效地解决不同类型电池的拆解挑战。

Conclusion: 数字孪生技术和Bi-PAN表示法为产品生命周期管理提供了有效工具，特别适用于支持循环经济中的再制造和回收过程。

Abstract: In the context of the circular economy, products in their end-of-life phase
should be either remanufactured or recycled. Both of these processes are
crucial for sustainability and environmental conservation. However,
manufacturers often do not support these processes enough by not sharing
relevant data. This paper proposes use of a digital twin technology, which is
capable to help optimizing the disassembly processes to reduce ecological
impact and enhance sustainability. The proposed approach is demonstrated
through a disassembly use-case of the product digital twin of an electric
vehicle battery. By utilizing product digital twins, challenges associated with
the disassembly of electric vehicle batteries can be solved flexibly and
efficiently for various battery types. As a backbone for the product digital
twin representation, the paper uses the paradigm of product-process-resource
asset networks (PAN). Such networks enable to model relevant relationships
across products, production resources, manufacturing processes, and specific
production operations that have to be done in the manufacturing phase of a
product. This paper introduces a Bi-Flow Product-Process-Resource Asset Network
(Bi-PAN) representation, which extends the PAN paradigm to cover not only the
manufacturing, but also the remanufacturing/recycling phase.

</details>


### [122] [Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots](https://arxiv.org/abs/2510.01843)
*Wanyue Li,Ji Ma,Minghao Lu,Peng Lu*

Main category: cs.RO

TL;DR: 本研究将无人机中成功的时空轨迹规划方法创新性地应用于双足机器人系统，自主生成满足目标踢球位置、速度和加速度约束的足部轨迹，同时优化摆动阶段持续时间。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人足球中的系统稳定性问题，特别是在进行激烈踢球动作时保持稳定并实现精确的球轨迹控制。现有方法（传统位置控制或强化学习）存在显著限制，MPC方法在腿摆动过程中过度简化，制约了足部环境交互能力。

Method: 将无人机中成功的时空轨迹规划方法创新性地应用于双足机器人系统，自主生成满足目标踢球位置、速度和加速度约束的足部轨迹，同时优化摆动阶段持续时间。

Result: 优化的轨迹密切模仿人类踢球行为，具有后摆动作。轨迹规划时间低于1毫秒，在-90°到90°范围内的足球目标区域实现了接近100%的任务完成准确率。

Conclusion: 该方法在人形机器人足球应用中表现出高效性和可靠性，能够生成类似人类踢球行为的优化轨迹，并在硬件实验中验证了其性能。

Abstract: Humanoid robot soccer presents several challenges, particularly in
maintaining system stability during aggressive kicking motions while achieving
precise ball trajectory control. Current solutions, whether traditional
position-based control methods or reinforcement learning (RL) approaches,
exhibit significant limitations. Model predictive control (MPC) is a prevalent
approach for ordinary quadruped and biped robots. While MPC has demonstrated
advantages in legged robots, existing studies often oversimplify the leg swing
progress, relying merely on simple trajectory interpolation methods. This
severely constrains the foot's environmental interaction capability, hindering
tasks such as ball kicking. This study innovatively adapts the spatial-temporal
trajectory planning method, which has been successful in drone applications, to
bipedal robotic systems. The proposed approach autonomously generates foot
trajectories that satisfy constraints on target kicking position, velocity, and
acceleration while simultaneously optimizing swing phase duration. Experimental
results demonstrate that the optimized trajectories closely mimic human kicking
behavior, featuring a backswing motion. Simulation and hardware experiments
confirm the algorithm's efficiency, with trajectory planning times under 1 ms,
and its reliability, achieving nearly 100 % task completion accuracy when the
soccer goal is within the range of -90{\deg} to 90{\deg}.

</details>


### [123] [GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics](https://arxiv.org/abs/2510.01848)
*Diram Tabaa,Gianni Di Caro*

Main category: cs.RO

TL;DR: GreenhouseSplat：基于高斯泼溅的温室环境光场重建框架，可从低成本RGB图像生成逼真温室资产，支持ROS仿真和机器人评估


<details>
  <summary>Details</summary>
Motivation: 现有温室仿真方法依赖简单或合成资产，限制了仿真到现实的迁移能力，需要更逼真的温室规模仿真解决方案

Method: 使用高斯泼溅等光场方法从低成本RGB图像重建逼真温室资产，集成到ROS仿真环境中，支持相机和LiDAR渲染

Result: 提供了包含82株黄瓜植物、多种行配置的数据集，展示了在机器人定位等任务中的实用性

Conclusion: 这是首个温室规模光场仿真框架，为农业机器人研究提供了基础

Abstract: Simulating greenhouse environments is critical for developing and evaluating
robotic systems for agriculture, yet existing approaches rely on simplistic or
synthetic assets that limit simulation-to-real transfer. Recent advances in
radiance field methods, such as Gaussian splatting, enable photorealistic
reconstruction but have so far been restricted to individual plants or
controlled laboratory conditions. In this work, we introduce GreenhouseSplat, a
framework and dataset for generating photorealistic greenhouse assets directly
from inexpensive RGB images. The resulting assets are integrated into a
ROS-based simulation with support for camera and LiDAR rendering, enabling
tasks such as localization with fiducial markers. We provide a dataset of 82
cucumber plants across multiple row configurations and demonstrate its utility
for robotics evaluation. GreenhouseSplat represents the first step toward
greenhouse-scale radiance-field simulation and offers a foundation for future
research in agricultural robotics.

</details>


### [124] [TACOS: Task Agnostic COordinator of a multi-drone System](https://arxiv.org/abs/2510.01869)
*Alessandro Nazzari,Roberto Rubinacci,Marco Lovera*

Main category: cs.RO

TL;DR: TACOS是一个基于大型语言模型的多无人机系统协调框架，通过自然语言界面实现高级任务控制，将用户意图转化为结构化任务计划并执行。


<details>
  <summary>Details</summary>
Motivation: 单个飞行员管理多无人机系统需要不同级别的自主性，从直接控制到群体协调再到完全自主的群体行为。需要支持多种共享自主模式的框架，利用语言模型的推理和规划能力减少飞行员工作负荷。

Method: TACOS框架整合三个关键能力：一对多自然语言界面、智能协调器（将用户意图转化为结构化任务计划）、自主代理（执行与现实世界交互的计划）。LLM与可执行API库交互，连接语义推理与实时多机器人协调。

Result: 在真实多无人机系统中演示了该系统，并通过消融研究评估了每个模块的贡献。

Conclusion: TACOS提供了一个统一的框架，通过大型语言模型实现多无人机系统的高级自然语言控制，有效连接语义推理与实时多机器人协调。

Abstract: When a single pilot is responsible for managing a multi-drone system, the
task demands varying levels of autonomy, from direct control of individual
UAVs, to group-level coordination, to fully autonomous swarm behaviors for
accomplishing high-level tasks. Enabling such flexible interaction requires a
framework that supports multiple modes of shared autonomy. As language models
continue to improve in reasoning and planning, they provide a natural
foundation for such systems, reducing pilot workload by enabling high-level
task delegation through intuitive, language-based interfaces. In this paper we
present TACOS (Task-Agnostic COordinator of a multi-drone System), a unified
framework that enables high-level natural language control of multi-UAV systems
through Large Language Models (LLMs). TACOS integrates three key capabilities
into a single architecture: a one-to-many natural language interface for
intuitive user interaction, an intelligent coordinator for translating user
intent into structured task plans, and an autonomous agent that executes plans
interacting with the real-world. TACOS allows a LLM to interact with a library
of executable APIs, bridging semantic reasoning with real-time multi-robot
coordination. We demonstrate the system in real-world multi-drone system and
conduct an ablation study to assess the contribution of each module.

</details>


### [125] [EC3R-SLAM: Efficient and Consistent Monocular Dense SLAM with Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2510.02080)
*Lingxiang Hu,Naima Ait Oufroukh,Fabien Bonardi,Raymond Ghandour*

Main category: cs.RO

TL;DR: EC3R-SLAM是一个无需相机标定的单目稠密SLAM框架，通过结合稀疏特征点跟踪和前馈3D重建模型，实现了高精度定位建图、低延迟和低GPU内存消耗，并在资源受限平台上有效运行。


<details>
  <summary>Details</summary>
Motivation: 解决传统单目稠密SLAM存在的高延迟、大GPU内存消耗和依赖相机标定的问题，开发一个更高效、实用的SLAM系统。

Method: 结合跟踪模块（维护稀疏特征点地图）和基于前馈3D重建模型的建图模块，同时估计相机内参，并集成局部和全局闭环检测以确保多视角一致性。

Result: 在多个基准测试中达到与最先进方法相当的性能，同时速度更快、内存效率更高，能在笔记本电脑和Jetson Orin NX等资源受限平台上有效运行。

Conclusion: EC3R-SLAM框架在保持高精度的同时显著提升了效率和实用性，为现实世界机器人应用提供了可行的解决方案。

Abstract: The application of monocular dense Simultaneous Localization and Mapping
(SLAM) is often hindered by high latency, large GPU memory consumption, and
reliance on camera calibration. To relax this constraint, we propose EC3R-SLAM,
a novel calibration-free monocular dense SLAM framework that jointly achieves
high localization and mapping accuracy, low latency, and low GPU memory
consumption. This enables the framework to achieve efficiency through the
coupling of a tracking module, which maintains a sparse map of feature points,
and a mapping module based on a feed-forward 3D reconstruction model that
simultaneously estimates camera intrinsics. In addition, both local and global
loop closures are incorporated to ensure mid-term and long-term data
association, enforcing multi-view consistency and thereby enhancing the overall
accuracy and robustness of the system. Experiments across multiple benchmarks
show that EC3R-SLAM achieves competitive performance compared to
state-of-the-art methods, while being faster and more memory-efficient.
Moreover, it runs effectively even on resource-constrained platforms such as
laptops and Jetson Orin NX, highlighting its potential for real-world robotics
applications.

</details>


### [126] [LangGrasp: Leveraging Fine-Tuned LLMs for Language Interactive Robot Grasping with Ambiguous Instructions](https://arxiv.org/abs/2510.02104)
*Yunhan Lin,Wenqi Wu,Zhijie Zhang,Huasong Min*

Main category: cs.RO

TL;DR: LangGrasp是一个语言交互的机器人抓取框架，通过微调大语言模型处理包含隐含意图的模糊指令，结合点云定位实现从物体级到部件级的精细抓取操作。


<details>
  <summary>Details</summary>
Motivation: 现有语言驱动抓取方法难以处理包含隐含意图的模糊指令，限制了机器人在非结构化环境中的适应性和任务执行效率。

Method: 集成微调的大语言模型进行常识推理和环境感知，结合2D部件分割引导的点云定位模块，实现从物体级到部件级的精细操作。

Result: 实验表明LangGrasp能准确解析模糊指令中的隐含意图，识别关键操作和目标信息，动态选择最优抓取姿态，显著提升机器人适应性。

Conclusion: 该框架通过语言交互和精细操作能力，显著增强了机器人在非结构化环境中的任务执行效率和适应性。

Abstract: The existing language-driven grasping methods struggle to fully handle
ambiguous instructions containing implicit intents. To tackle this challenge,
we propose LangGrasp, a novel language-interactive robotic grasping framework.
The framework integrates fine-tuned large language models (LLMs) to leverage
their robust commonsense understanding and environmental perception
capabilities, thereby deducing implicit intents from linguistic instructions
and clarifying task requirements along with target manipulation objects.
Furthermore, our designed point cloud localization module, guided by 2D part
segmentation, enables partial point cloud localization in scenes, thereby
extending grasping operations from coarse-grained object-level to fine-grained
part-level manipulation. Experimental results show that the LangGrasp framework
accurately resolves implicit intents in ambiguous instructions, identifying
critical operations and target information that are unstated yet essential for
task completion. Additionally, it dynamically selects optimal grasping poses by
integrating environmental information. This enables high-precision grasping
from object-level to part-level manipulation, significantly enhancing the
adaptability and task execution efficiency of robots in unstructured
environments. More information and code are available here:
https://github.com/wu467/LangGrasp.

</details>


### [127] [Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control](https://arxiv.org/abs/2510.02129)
*Philip Reichenberg,Tim Laue*

Main category: cs.RO

TL;DR: 本文介绍了为NAO机器人开发的站立动作，通过解决关节位置执行误差问题，显著提高了站立成功率。


<details>
  <summary>Details</summary>
Motivation: 站立动作是人形机器人足球中不可或缺的部分，无法自主站立的机器人会被暂时移出比赛。

Method: 通过执行特殊动作释放卡住的肢体（如手臂），或使用其他关节补偿大误差，来应对关节位置执行误差问题。

Result: 显著提高了站立动作的整体成功率，其他团队使用这些动作也取得了相似的成功率。

Conclusion: 该方法经过6年评估和扩展，证明能有效解决站立动作中的关节执行误差问题。

Abstract: Stand-up motions are an indispensable part of humanoid robot soccer. A robot
incapable of standing up by itself is removed from the game for some time. In
this paper, we present our stand-up motions for the NAO robot. Our approach
dates back to 2019 and has been evaluated and slightly expanded over the past
six years. We claim that the main reason for failed stand-up attempts are large
errors in the executed joint positions. By addressing such problems by either
executing special motions to free up stuck limbs such as the arms, or by
compensating large errors with other joints, we significantly increased the
overall success rate of our stand-up routine. The motions presented in this
paper are also used by several other teams in the Standard Platform League,
which thereby achieve similar success rates, as shown in an analysis of videos
from multiple tournaments.

</details>


### [128] [SCANS: A Soft Gripper with Curvature and Spectroscopy Sensors for In-Hand Material Differentiation](https://arxiv.org/abs/2510.02164)
*Nathaniel Hanson,Austin Allison,Charles DiMarzio,Taşkın Padır,Kristen L. Dorsey*

Main category: cs.RO

TL;DR: SCANS系统是一种无电子元件、流体驱动的软体机械手，能够通过预接触包覆或手持方式评估物体的光谱特性，具有比以往软体机器人更宽的光谱感知能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种多功能的光学感知软体机器人平台，扩展软体机器人的光谱感知能力，实现物体的可解释分类识别。

Method: 进行材料分析以选择最佳软基底材料用于光谱感知，评估预接触和手持性能，使用线性判别分析识别关键光谱特征。

Result: 实验显示能够对金属、木材、塑料、有机物、纸张、泡沫等不同类别和尺寸的物体进行可解释的统计分离，近红外波长敏感性对区分视觉相似物体至关重要。

Conclusion: SCANS系统推进了光学作为软体机器人多功能感知模式的潜力，所有部件清单、组装指南和处理代码均已公开。

Abstract: We introduce the soft curvature and spectroscopy (SCANS) system: a versatile,
electronics-free, fluidically actuated soft manipulator capable of assessing
the spectral properties of objects either in hand or through pre-touch caging.
This platform offers a wider spectral sensing capability than previous soft
robotic counterparts. We perform a material analysis to explore optimal soft
substrates for spectral sensing, and evaluate both pre-touch and in-hand
performance. Experiments demonstrate explainable, statistical separation across
diverse object classes and sizes (metal, wood, plastic, organic, paper, foam),
with large spectral angle differences between items. Through linear
discriminant analysis, we show that sensitivity in the near-infrared
wavelengths is critical to distinguishing visually similar objects. These
capabilities advance the potential of optics as a multi-functional sensory
modality for soft robots. The complete parts list, assembly guidelines, and
processing code for the SCANS gripper are accessible at:
https://parses-lab.github.io/scans/.

</details>


### [129] [DisCo-Layout: Disentangling and Coordinating Semantic and Physical Refinement in a Multi-Agent Framework for 3D Indoor Layout Synthesis](https://arxiv.org/abs/2510.02178)
*Jialin Gao,Donghao Zhou,Mingjian Liang,Lihao Liu,Chi-Wing Fu,Xiaowei Hu,Pheng-Ann Heng*

Main category: cs.RO

TL;DR: DisCo-Layout是一个解耦物理和语义精炼的3D室内布局合成框架，通过多智能体协作实现最优布局生成


<details>
  <summary>Details</summary>
Motivation: 传统方法因固定数据集而泛化能力差，现有LLM/VLM方法语义丰富但缺乏灵活精炼机制，导致布局不理想

Method: 开发语义精炼工具(SRT)修正抽象对象关系，物理精炼工具(PRT)通过网格匹配算法解决空间问题，多智能体框架协调工具协作

Result: 实验显示DisCo-Layout达到最先进性能，生成逼真、连贯且可泛化的3D室内布局

Conclusion: DisCo-Layout框架通过解耦和协调物理与语义精炼，有效解决了3D室内布局合成的挑战

Abstract: 3D indoor layout synthesis is crucial for creating virtual environments.
Traditional methods struggle with generalization due to fixed datasets. While
recent LLM and VLM-based approaches offer improved semantic richness, they
often lack robust and flexible refinement, resulting in suboptimal layouts. We
develop DisCo-Layout, a novel framework that disentangles and coordinates
physical and semantic refinement. For independent refinement, our Semantic
Refinement Tool (SRT) corrects abstract object relationships, while the
Physical Refinement Tool (PRT) resolves concrete spatial issues via a
grid-matching algorithm. For collaborative refinement, a multi-agent framework
intelligently orchestrates these tools, featuring a planner for placement
rules, a designer for initial layouts, and an evaluator for assessment.
Experiments demonstrate DisCo-Layout's state-of-the-art performance, generating
realistic, coherent, and generalizable 3D indoor layouts. Our code will be
publicly available.

</details>


### [130] [Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0](https://arxiv.org/abs/2510.02248)
*Yan Miao,Ege Yuceel,Georgios Fainekos,Bardh Hoxha,Hideki Okamoto,Sayan Mitra*

Main category: cs.RO

TL;DR: 开发了FalconGym 2.0仿真框架和性能引导优化算法，训练出的视觉策略在无人机导航中展现出优异的泛化能力和鲁棒性，并能实现零样本的仿真到真实迁移。


<details>
  <summary>Details</summary>
Motivation: 现有视觉策略在无人机导航中容易对单一赛道过拟合，当赛道几何形状变化时性能会下降。

Method: 基于高斯泼溅技术构建FalconGym 2.0仿真框架，提出性能引导优化算法，在具有挑战性的赛道上集中训练视觉策略。

Result: 在固定翼无人机和四旋翼无人机两个案例中，单一视觉策略在三个未见赛道上实现100%成功率，在门姿态扰动下保持更高成功率，并能零样本迁移到真实四旋翼无人机，达到98.6%成功率。

Conclusion: FalconGym 2.0框架和性能引导优化算法能够训练出具有强大泛化能力和鲁棒性的视觉策略，并能成功实现仿真到真实的迁移。

Abstract: Visual policy design is crucial for aerial navigation. However,
state-of-the-art visual policies often overfit to a single track and their
performance degrades when track geometry changes. We develop FalconGym 2.0, a
photorealistic simulation framework built on Gaussian Splatting (GSplat) with
an Edit API that programmatically generates diverse static and dynamic tracks
in milliseconds. Leveraging FalconGym 2.0's editability, we propose a
Performance-Guided Refinement (PGR) algorithm, which concentrates visual
policy's training on challenging tracks while iteratively improving its
performance. Across two case studies (fixed-wing UAVs and quadrotors) with
distinct dynamics and environments, we show that a single visual policy trained
with PGR in FalconGym 2.0 outperforms state-of-the-art baselines in
generalization and robustness: it generalizes to three unseen tracks with 100%
success without per-track retraining and maintains higher success rates under
gate-pose perturbations. Finally, we demonstrate that the visual policy trained
with PGR in FalconGym 2.0 can be zero-shot sim-to-real transferred to a
quadrotor hardware, achieving a 98.6% success rate (69 / 70 gates) over 30
trials spanning two three-gate tracks and a moving-gate track.

</details>


### [131] [Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking](https://arxiv.org/abs/2510.02252)
*Joao Pedro Araujo,Yanjie Ze,Pei Xu,Jiajun Wu,C. Karen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种新的运动重定向方法GMR，解决了人形机器人运动跟踪中由于重定向质量问题导致的策略性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人运动跟踪策略面临人体与机器人之间的具身差距问题，现有重定向方法会在参考轨迹中引入伪影（如脚部滑动、自穿透等），需要强化学习策略进行修正，这通常需要大量的奖励工程和领域随机化。

Method: 提出了通用运动重定向(GMR)方法，并与现有的开源重定向器PHC、ProtoMotions以及Unitree的高质量闭源数据集进行比较，使用BeyondMimic进行策略训练以隔离重定向效果。

Result: 在LAFAN1数据集的多样化子集上的实验表明，GMR在跟踪性能和运动保真度方面持续优于现有的开源方法，达到了接近闭源基线的感知保真度和策略成功率。

Conclusion: 重定向质量对策略性能有显著影响，GMR方法能有效减少重定向数据中的伪影，提高策略的鲁棒性，特别是在动态或长序列运动中。

Abstract: Humanoid motion tracking policies are central to building teleoperation
pipelines and hierarchical controllers, yet they face a fundamental challenge:
the embodiment gap between humans and humanoid robots. Current approaches
address this gap by retargeting human motion data to humanoid embodiments and
then training reinforcement learning (RL) policies to imitate these reference
trajectories. However, artifacts introduced during retargeting, such as foot
sliding, self-penetration, and physically infeasible motion are often left in
the reference trajectories for the RL policy to correct. While prior work has
demonstrated motion tracking abilities, they often require extensive reward
engineering and domain randomization to succeed. In this paper, we
systematically evaluate how retargeting quality affects policy performance when
excessive reward tuning is suppressed. To address issues that we identify with
existing retargeting methods, we propose a new retargeting method, General
Motion Retargeting (GMR). We evaluate GMR alongside two open-source
retargeters, PHC and ProtoMotions, as well as with a high-quality closed-source
dataset from Unitree. Using BeyondMimic for policy training, we isolate
retargeting effects without reward tuning. Our experiments on a diverse subset
of the LAFAN1 dataset reveal that while most motions can be tracked, artifacts
in retargeted data significantly reduce policy robustness, particularly for
dynamic or long sequences. GMR consistently outperforms existing open-source
methods in both tracking performance and faithfulness to the source motion,
achieving perceptual fidelity and policy success rates close to the
closed-source baseline. Website:
https://jaraujo98.github.io/retargeting_matters. Code:
https://github.com/YanjieZe/GMR.

</details>


### [132] [Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning](https://arxiv.org/abs/2510.02268)
*Tianchong Jiang,Jingtian Ji,Xiangshan Tan,Jiading Fang,Anand Bhattad,Vitor Guizilini,Matthew R. Walter*

Main category: cs.RO

TL;DR: 该论文研究了通过显式将策略与相机外参条件化来实现视点不变的模仿学习，发现这种方法能显著提升行为克隆策略在不同视点下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习策略在视点变化时表现不佳，特别是当策略依赖静态背景中的视觉线索来推断相机姿态时，这种捷径在场景几何或相机位置变化时会失效。

Method: 使用Plucker嵌入的逐像素射线，将策略与相机外参条件化，在RoboSuite和ManiSkill中引入六个操作任务来评估视点变化下的策略鲁棒性。

Result: 实验表明，不包含外参的策略在固定场景中依赖静态背景线索推断相机姿态，但在视点变化时性能崩溃；而条件化外参的方法恢复了性能，实现了仅使用RGB的鲁棒控制。

Conclusion: 显式条件化相机外参是实现视点不变模仿学习的有效方法，能够在不依赖深度信息的情况下实现鲁棒的RGB控制。

Abstract: We study view-invariant imitation learning by explicitly conditioning
policies on camera extrinsics. Using Plucker embeddings of per-pixel rays, we
show that conditioning on extrinsics significantly improves generalization
across viewpoints for standard behavior cloning policies, including ACT,
Diffusion Policy, and SmolVLA. To evaluate policy robustness under realistic
viewpoint shifts, we introduce six manipulation tasks in RoboSuite and
ManiSkill that pair "fixed" and "randomized" scene variants, decoupling
background cues from camera pose. Our analysis reveals that policies without
extrinsics often infer camera pose using visual cues from static backgrounds in
fixed scenes; this shortcut collapses when workspace geometry or camera
placement shifts. Conditioning on extrinsics restores performance and yields
robust RGB-only control without depth. We release the tasks, demonstrations,
and code at https://ripl.github.io/know_your_camera/ .

</details>


### [133] [ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation](https://arxiv.org/abs/2510.02298)
*Wenye Yu,Jun Lv,Zixi Ying,Yang Jin,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: ARMADA是一个多机器人部署和适应系统，通过FLOAT自主故障检测方法实现人类在环共享控制，显著减少对人类监督的依赖，提高策略部署效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在大规模真实世界数据上表现良好，但预训练策略在缺乏领域内数据时性能较差。人工收集演示数据成本高且质量不一，传统人类在环系统需要全程人工监控。

Method: 开发ARMADA系统，包含FLOAT自主在线故障检测方法，实现并行策略部署，仅在必要时请求人工干预，通过共享控制减少人类监督需求。

Result: FLOAT平均准确率达到近95%，比现有故障检测方法提升超过20%。ARMADA在多次策略部署和后训练中，成功率提高4倍以上，人工干预率减少2倍以上。

Conclusion: ARMADA系统通过自主故障检测和人类在环共享控制，实现了更高效的领域内数据获取，提升了机器人部署的可扩展性和对新场景的适应速度。

Abstract: Imitation learning has shown promise in learning from large-scale real-world
datasets. However, pretrained policies usually perform poorly without
sufficient in-domain data. Besides, human-collected demonstrations entail
substantial labour and tend to encompass mixed-quality data and redundant
information. As a workaround, human-in-the-loop systems gather domain-specific
data for policy post-training, and exploit closed-loop policy feedback to offer
informative guidance, but usually require full-time human surveillance during
policy rollout. In this work, we devise ARMADA, a multi-robot deployment and
adaptation system with human-in-the-loop shared control, featuring an
autonomous online failure detection method named FLOAT. Thanks to FLOAT, ARMADA
enables paralleled policy rollout and requests human intervention only when
necessary, significantly reducing reliance on human supervision. Hence, ARMADA
enables efficient acquisition of in-domain data, and leads to more scalable
deployment and faster adaptation to new scenarios. We evaluate the performance
of ARMADA on four real-world tasks. FLOAT achieves nearly 95% accuracy on
average, surpassing prior state-of-the-art failure detection approaches by over
20%. Besides, ARMADA manifests more than 4$\times$ increase in success rate and
greater than 2$\times$ reduction in human intervention rate over multiple
rounds of policy rollout and post-training, compared to previous
human-in-the-loop learning methods.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [134] [ENLighten: Lighten the Transformer, Enable Efficient Optical Acceleration](https://arxiv.org/abs/2510.01673)
*Hanqing Zhu,Zhican Zhou,Shupeng Ning,Xuhao Wu,Ray Chen,Yating Wan,David Pan*

Main category: cs.ET

TL;DR: 本文提出Lighten和ENLighten的软硬件协同设计框架，通过光计算加速Transformer模型，解决了光电转换成本高和片上光子资源有限的问题。


<details>
  <summary>Details</summary>
Motivation: 光计算在AI加速方面有潜力，但Transformer模型规模扩大时面临两个瓶颈：(1)昂贵的光电转换和数据移动开销降低能效；(2)有限的片上光子资源与Transformer规模不匹配，导致光子张量核心频繁复用，稀释吞吐增益。

Method: 1. Lighten：PTC感知压缩流程，将Transformer权重矩阵分解为低秩分量和结构化稀疏分量，无需长时间重新训练；2. ENLighten：可重构光子加速器，具有动态自适应张量核心，支持细粒度稀疏性和全功率门控。

Result: 在ImageNet上，Lighten将Base级Vision Transformer剪枝50%，仅需3个epoch（约1小时）微调，精度下降约1%。在ENLighten上部署，相比最先进的光子Transformer加速器，能量延迟积提升2.5倍。

Conclusion: 该软硬件协同设计框架有效解决了光子计算在Transformer加速中的瓶颈，显著提升了能效和性能。

Abstract: Photonic computing has emerged as a promising substrate for accelerating the
dense linear-algebra operations at the heart of AI, yet adoption for large
Transformer models remains in its infancy. We identify two bottlenecks: (1)
costly electro--optic conversions and data-movement overheads that erode energy
efficiency as model sizes scale; (2) a mismatch between limited on-chip
photonic resources and Transformer scale, which forces frequent reuse of
photonic tensor cores and dilutes throughput gains. To address these
challenges, we introduce a hardware--software co-design framework. First, we
propose \texttt{Lighten}, a PTC-aware compression flow that post-hoc decomposes
each Transformer weight matrix into a low-rank component plus a
structured-sparse component aligned to photonic tensor-core granularity,
without lengthy retraining. Second, we present \texttt{ENLighten}, a
reconfigurable photonic accelerator with dynamically adaptive tensor cores,
driven by broadband light redistribution, enabling fine-grained sparsity
support and full power gating of inactive parts. On ImageNet, \texttt{Lighten}
prunes a Base-scale Vision Transformer by 50\% with $\approx$1\% accuracy drop
after only 3 epochs (about 1 hour) of fine-tuning. Deployed on
\texttt{ENLighten}, it achieves a $2.5\times$ improvement in energy--delay
product over the state-of-the-art photonic Transformer accelerator.

</details>
