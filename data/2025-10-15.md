<div id=toc></div>

# Table of Contents

- [cs.CY](#cs.CY) [Total: 6]
- [econ.TH](#econ.TH) [Total: 4]
- [cs.SI](#cs.SI) [Total: 7]
- [eess.SY](#eess.SY) [Total: 11]
- [cs.AI](#cs.AI) [Total: 46]
- [cs.RO](#cs.RO) [Total: 26]
- [econ.GN](#econ.GN) [Total: 2]
- [econ.EM](#econ.EM) [Total: 4]
- [stat.AP](#stat.AP) [Total: 2]
- [cs.ET](#cs.ET) [Total: 3]


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [1] [Scaling Law in LLM Simulated Personality: More Detailed and Realistic Persona Profile Is All You Need](https://arxiv.org/abs/2510.11734)
*Yuqi Bai,Tianyu Huang,Kun Sun,Yuting Chen*

Main category: cs.CY

TL;DR: 提出一个评估大语言模型虚拟人格模拟的系统框架，包括个体和群体层面的分析，并发现人格模拟中的缩放定律效应。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在模拟人类人格方面的能力，为社会科学实验应用提供理论基础和操作指标。

Method: 开发端到端评估框架，包括个体层面的稳定性和可识别性分析，以及群体层面的渐进人格曲线分析；改进传统心理测量方法以适应LLM的低水平模拟特性。

Result: 实证证明了人物细节在人格模拟质量中的关键作用；识别了人物配置的边际效用效应，特别是LLM人格模拟中的缩放定律。

Conclusion: 提出了系统性的LLM虚拟人格评估框架，为大语言模型在社会科学实验中的应用提供了操作评估指标和理论基础。

Abstract: This research focuses on using large language models (LLMs) to simulate
social experiments, exploring their ability to emulate human personality in
virtual persona role-playing. The research develops an end-to-end evaluation
framework, including individual-level analysis of stability and
identifiability, as well as population-level analysis called progressive
personality curves to examine the veracity and consistency of LLMs in
simulating human personality. Methodologically, this research proposes
important modifications to traditional psychometric approaches (CFA and
construct validity) which are unable to capture improvement trends in LLMs at
their current low-level simulation, potentially leading to remature rejection
or methodological misalignment. The main contributions of this research are:
proposing a systematic framework for LLM virtual personality evaluation;
empirically demonstrating the critical role of persona detail in personality
simulation quality; and identifying marginal utility effects of persona
profiles, especially a Scaling Law in LLM personality simulation, offering
operational evaluation metrics and a theoretical foundation for applying large
language models in social science experiments.

</details>


### [2] [The Ethics Engine: A Modular Pipeline for Accessible Psychometric Assessment of Large Language Models](https://arxiv.org/abs/2510.11742)
*Jake Van Clief,Constantine Kyritsopoulos*

Main category: cs.CY

TL;DR: 提出了Ethics Engine，一个模块化的Python管道，将LLM的心理测量评估从技术复杂的工作转变为可访问的研究工具，使跨学科研究人员能够系统测量语言模型中的价值表达。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地介导人类沟通和决策，理解它们的价值表达对于跨学科研究变得至关重要。缺乏系统测量这些价值表达会导致部署其道德影响未知的系统。

Method: 开发了一个模块化的Python管道Ethics Engine，通过降低技术障碍来扩展AI研究的参与度，使认知科学、政治心理学、教育等领域的研究人员能够研究语言模型中的价值表达。

Result: 该管道已被爱丁堡大学研究人员用于研究威权主义，处理了超过10,000个AI响应，验证了其研究实用性。

Conclusion: 此类工具通过降低技术障碍同时保持科学严谨性，从根本上改变了AI研究的格局，为这些有影响力技术的知情治理提供了必要的严格评估。

Abstract: As Large Language Models increasingly mediate human communication and
decision-making, understanding their value expression becomes critical for
research across disciplines. This work presents the Ethics Engine, a modular
Python pipeline that transforms psychometric assessment of LLMs from a
technically complex endeavor into an accessible research tool. The pipeline
demonstrates how thoughtful infrastructure design can expand participation in
AI research, enabling investigators across cognitive science, political
psychology, education, and other fields to study value expression in language
models. Recent adoption by University of Edinburgh researchers studying
authoritarianism validates its research utility, processing over 10,000 AI
responses across multiple models and contexts. We argue that such tools
fundamentally change the landscape of AI research by lowering technical
barriers while maintaining scientific rigor. As LLMs increasingly serve as
cognitive infrastructure, their embedded values shape millions of daily
interactions. Without systematic measurement of these value expressions, we
deploy systems whose moral influence remains uncharted. The Ethics Engine
enables the rigorous assessment necessary for informed governance of these
influential technologies.

</details>


### [3] [Benefits and Limitations of Using GenAI for Political Education and Municipal Elections](https://arxiv.org/abs/2510.11749)
*Raphael Fischer,Youssef Abdelrahim,Katharina Poitz*

Main category: cs.CY

TL;DR: 该研究探索使用生成式AI（GenAI）让政治纲领更易于理解，通过语言模型分析政治纲领内容并生成可视化图像，促进政治教育。


<details>
  <summary>Details</summary>
Motivation: 面对北莱茵-威斯特法伦州的市政选举，研究者希望探索GenAI是否能让政治纲领更易于理解，从而促进政治教育。

Method: 结合不同GenAI方法进行实验研究：使用语言模型自动翻译和分析政治纲领内容，基于分析结果用扩散模型生成图像，并将所有结果发布为交互式网页。所有模型都在本地计算集群上部署。

Result: 成功生成了五个潜在的城市外观变化可视化，创建了交互式网页展示结果，并能够调查环境影响。

Conclusion: 该项目深入探讨了GenAI在教育领域的潜力与局限，通过透明讨论GenAI在教育中的优缺点，促进了可持续发展目标中的优质教育（SDG 4）。

Abstract: Generative artificial intelligence (GenAI) presents both challenges and
opportunities across all areas of education. Facing the municipal elections in
North Rhine-Westphalia, the Young AI Leaders in Dortmund asked themselves:
Could GenAI be used to make political programs more accessible, in order to
facilitate political education? To explore respective potentials and
limitations, we therefore performed an experimental study that combines
different GenAI approaches. Language models were used to automatically
translate and analyze the contents of each program, deriving five potential
visual appearance changes to the city of Dortmund. Based on each analysis, we
then generated images with diffusion models and published all results as an
interactive webpage. All GenAI models were locally deployed on a Dortmund-based
computing cluster, allowing us to also investigate environmental impacts. This
manuscript explores the project in full depth, discussing technical details and
critically reflecting on the results. As part of the global Young AI Leaders
Community, our work promotes the Sustainable Development Goal Quality Education
(SDG 4) by transparently discussing the pros and cons of using GenAI for
education and political agendas.

</details>


### [4] [Artificial Intelligence for Optimal Learning: A Comparative Approach towards AI-Enhanced Learning Environments](https://arxiv.org/abs/2510.11755)
*Ananth Hariharan*

Main category: cs.CY

TL;DR: 本研究比较了三种教育环境：传统非技术教育、非AI技术增强教育和AI驱动教育，旨在整合各自优势创建更全面的混合教育模式。


<details>
  <summary>Details</summary>
Motivation: 随着技术在教育中的重要性日益增长，特别是人工智能的出现，需要评估不同教育环境对教育成果、参与度、教学方法和资源公平性的影响。

Method: 通过批判性评估和比较三种教育设置：传统教育方法、非AI技术增强教育和AI驱动技术教育。

Result: 研究发现每种教育环境都有独特优势：传统教育提供人际互动和成熟教学方法，非AI技术增强可访问性和协作工具，AI技术实现个性化和自适应学习。

Conclusion: 通过整合三种教育模式的优点，可以创建更丰富有效的混合教育环境，提升教育成果、参与度和包容性，同时解决各模式的局限性。

Abstract: In the rapidly evolving educational landscape, the integration of technology
has shifted from an enhancement to a cornerstone of educational strategy
worldwide. This transition is propelled by advancements in digital technology,
especially the emergence of artificial intelligence as a crucial tool in
learning environments. This research project critically evaluates the impact of
three distinct educational settings: traditional educational methods without
technological integration, those enhanced by non-AI technology, and those
utilising AI-driven technologies. This comparison aims to assess how each
environment influences educational outcomes, engagement, pedagogical methods,
and equity in access to learning resources, and how each contributes uniquely
to the learning experience. The ultimate goal of this research is to synthesise
the strengths of each model to create a more holistic educational approach. By
integrating the personal interaction and tested pedagogical techniques of
traditional classrooms, the enhanced accessibility and collaborative tools
offered by non-AI technology, and the personalised, adaptive learning
strategies enabled by AI-driven technologies, education systems can develop
richer, more effective learning environments. This hybrid approach aims to
leverage the best elements of each setting, thereby enhancing educational
outcomes, engagement, and inclusiveness, while also addressing the distinct
challenges and limitations inherent in each model. The intention is to create
an educational framework deeply attentive to the diverse needs of students,
ensuring equitable access to high-quality education for all.

</details>


### [5] [The Adoption Paradox: A Comparative Analysis of Veterinary AI Adoption in China and the North America](https://arxiv.org/abs/2510.11758)
*Shumin Li,Xiaoyun Lai*

Main category: cs.CY

TL;DR: 本研究比较了中国和北美兽医专业人士对AI的认知、采用和应用情况，发现中国兽医虽然对AI熟悉度较低但采用率较高，主要用于临床诊断；而北美兽医熟悉度高但采用率低，主要用于行政工作。


<details>
  <summary>Details</summary>
Motivation: 验证AI采用模式是否受区域市场和人口因素影响，比较不同地区兽医专业人士对AI的态度和使用差异。

Method: 采用描述性横断面调查，在中国调查455名兽医专业人士（2025年5-7月），并与北美2024年调查的3,968名兽医数据进行比较。

Result: 中国兽医AI采用率71.0%（熟悉度55.4%），主要用于疾病诊断和处方计算；北美兽医AI采用率39.2%（熟悉度83.8%），主要用于影像分析和记录保存。

Conclusion: 存在"采用悖论"：中国市场是自下而上的临床导向采用模式，北美市场是自上而下的行政导向整合模式，需要针对不同地区制定定制化AI整合策略。

Abstract: This study compares the perception, adoption, and application of artificial
intelligence (AI) among veterinary professionals in China and North America
(NA), testing the hypothesis that adoption patterns are shaped by regional
market and demographic factors. A descriptive, cross-sectional survey was
conducted with 455 veterinary professionals in China between May and July 2025.
The results were compared with published data from a 2024 survey of 3,968
veterinary professionals in the United States and Canada. The Chinese cohort,
primarily composed of clinicians (81.5%), showed a high AI adoption rate
(71.0%) despite low familiarity (55.4%). Their AI use was focused on clinical
tasks, such as disease diagnosis (50.1%) and prescription calculation (44.8%).
In contrast, the NA cohort reported high familiarity (83.8%) but a lower
adoption rate (39.2%). Their priorities were administrative, including imaging
analysis (39.0%) and record-keeping (39.0%). Concerns about AI reliability and
accuracy were the top barrier in both groups. Our findings reveal an "adoption
paradox" where the Chinese market demonstrates a practitioner-driven, bottom-up
adoption model focused on augmenting clinical efficacy, while the NA market
shows a more cautious, structured, top-down integration aimed at improving
administrative efficiency. This suggests that a one-size-fits-all approach to
AI development and integration is insufficient, and tailored, region-specific
strategies are necessary to responsibly incorporate AI into global veterinary
practice.

</details>


### [6] [From Delegates to Trustees: How Optimizing for Long-Term Interests Shapes Bias and Alignment in LLM](https://arxiv.org/abs/2510.12689)
*Suyash Fulay,Jocelyn Zhu,Michiel Bakker*

Main category: cs.CY

TL;DR: 该研究探讨了AI系统在代表人类利益时的设计权衡：是作为代表（直接反映用户表达偏好）还是作为受托人（基于用户长期利益做出判断）。通过模拟美国政策投票实验，发现受托人模型在明确问题上更符合专家共识，但在主观议题上会偏向模型默认立场。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs如何复制个体表达偏好（行为克隆），但忽视了政治代表理论中的关键权衡：AI系统应该作为代表反映用户表达偏好，还是作为受托人基于用户长期利益行使判断权。这与LLM奉承问题密切相关。

Method: 通过一系列模拟美国政策议题投票的实验，应用时间效用框架权衡短期和长期利益（模拟受托人角色），并与行为克隆模型（模拟代表角色）的投票结果进行比较。

Result: 受托人式预测（侧重长期利益）在明确理解的政策问题上产生更符合专家共识的决策，但在缺乏明确共识的话题上表现出更大的偏向模型默认立场的偏见。

Conclusion: AI系统代表人类利益存在根本性权衡：代表模型更好地保护用户自主性但可能偏离有充分支持的政策立场；受托人模型在明确问题上能促进福利，但在主观议题上存在家长式作风和偏见风险。

Abstract: Large language models (LLMs) have shown promising accuracy in predicting
survey responses and policy preferences, which has increased interest in their
potential to represent human interests in various domains. Most existing
research has focused on behavioral cloning, effectively evaluating how well
models reproduce individuals' expressed preferences. Drawing on theories of
political representation, we highlight an underexplored design trade-off:
whether AI systems should act as delegates, mirroring expressed preferences, or
as trustees, exercising judgment about what best serves an individual's
interests. This trade-off is closely related to issues of LLM sycophancy, where
models can encourage behavior or validate beliefs that may be aligned with a
user's short-term preferences, but is detrimental to their long-term interests.
Through a series of experiments simulating votes on various policy issues in
the U.S. context, we apply a temporal utility framework that weighs short and
long-term interests (simulating a trustee role) and compare voting outcomes to
behavior-cloning models (simulating a delegate). We find that trustee-style
predictions weighted toward long-term interests produce policy decisions that
align more closely with expert consensus on well-understood issues, but also
show greater bias toward models' default stances on topics lacking clear
agreement. These findings reveal a fundamental trade-off in designing AI
systems to represent human interests. Delegate models better preserve user
autonomy but may diverge from well-supported policy positions, while trustee
models can promote welfare on well-understood issues yet risk paternalism and
bias on subjective topics.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [7] [Perceived Fairness in Networks](https://arxiv.org/abs/2510.12028)
*Arthur Charpentier*

Main category: econ.TH

TL;DR: 论文提出了一个感知公平网络的理论模型，指出即使决策规则满足传统公平标准，在存在同质性或分类混合的情况下，感知歧视仍可能持续甚至加剧。


<details>
  <summary>Details</summary>
Motivation: 传统算法公平性定义关注人口层面的统计，但在社会或经济背景下，公平性通常是通过个体的同伴网络和比较在本地感知的，而非全局感知。

Method: 提出了感知公平网络的理论模型，将网络结构、本地观察和社会感知联系起来，通过分析和模拟研究网络拓扑如何影响客观公平与感知公平之间的差异。

Result: 研究表明，即使决策规则满足标准公平标准，在同质性或分类混合存在的情况下，感知歧视可能持续或增加，网络拓扑显著影响客观公平与感知公平之间的分歧。

Conclusion: 网络结构对公平感知有重要影响，这对算法治理以及在金融和协作保险等领域的应用具有重要意义。

Abstract: The usual definitions of algorithmic fairness focus on population-level
statistics, such as demographic parity or equal opportunity. However, in many
social or economic contexts, fairness is not perceived globally, but locally,
through an individual's peer network and comparisons. We propose a theoretical
model of perceived fairness networks, in which each individual's sense of
discrimination depends on the local topology of interactions. We show that even
if a decision rule satisfies standard criteria of fairness, perceived
discrimination can persist or even increase in the presence of homophily or
assortative mixing. We propose a formalism for the concept of fairness
perception, linking network structure, local observation, and social
perception. Analytical and simulation results highlight how network topology
affects the divergence between objective fairness and perceived fairness, with
implications for algorithmic governance and applications in finance and
collaborative insurance.

</details>


### [8] [Game Theory Analysis of Third-Party Regulation in Organic Supply Chains](https://arxiv.org/abs/2510.12420)
*João Zambujal-Oliveira,André Silva,Rui Vasconcelos*

Main category: econ.TH

TL;DR: 该论文通过博弈论分析证明需要第三方监管来确保有机食品市场的公平性和信任度


<details>
  <summary>Details</summary>
Motivation: 随着人们对健康和环境意识的提高，有机食品需求增加，但区分有机产品和传统产品存在困难，生产者可能将传统产品标为有机以高价销售

Method: 采用博弈论分析方法，研究生产者和消费者之间的战略互动

Result: 分析表明需要第三方机构来平衡市场并促进有机供应链中的信任

Conclusion: 政府监管（包括定期和随机监控以及认证要求）对于实现供应链参与者之间的信任和信息交换至关重要，这最终决定了该行业的发展轨迹

Abstract: As people become more conscious of their health and the environment, the
demand for organic food is expected to increase. However, distinguishing
organic products from conventionally produced ones can be hard, creating a
problem where producers may have the incentive to label their conventional
products as organic to sell them at a higher price. Game theory can help to
analyze the strategic interactions between producers and consumers in order to
help consumers verifying these claims. Through a game theory analysis approach,
this paper provides evidence of the need for a third party to equalize markets
and foster trust in organic supply chains. Therefore, government regulation,
including regular and random monitoring and certification requirements, plays a
crucial role in achieving the desired level of trust and information exchange
among supply chain agents, which ultimately determines the growth trajectory of
the sector.

</details>


### [9] [When Can Communication Lead to Efficiency?](https://arxiv.org/abs/2510.12508)
*Itai Arieli,Yakov Babichenko,Atulya Jain,Rann Smorodinsky*

Main category: econ.TH

TL;DR: 该论文研究了不完全信息博弈中的帕累托效率，发现过度随机化的结果通常是低效的，效率要求行动总数少于玩家数和状态数之和。在通信模型中，廉价磋商结果只有在纯策略时才是高效的。


<details>
  <summary>Details</summary>
Motivation: 研究不完全信息博弈中帕累托效率的特征，特别关注随机化行动和通信模型对效率的影响。

Method: 通过理论分析，推导出不完全信息博弈中帕累托效率的必要条件，并应用于通信模型和机制设计问题。

Result: 发现过度随机化会导致低效；廉价磋商结果只有在纯策略时才高效；在自然买卖方设置中，贝叶斯说服结果在广泛的先验和偏好下都是低效的。

Conclusion: 论文建立了不完全信息博弈中效率的通用特征，这些结果适用于多玩家机制设计问题，为理解信息传递和策略互动中的效率提供了重要洞见。

Abstract: We study games with incomplete information and characterize when a feasible
outcome is Pareto efficient. We show that any outcome with excessive
randomization over actions is inefficient. Generically, efficiency requires
that the total number of actions taken across states be strictly less than the
sum of the number of players and states. We then examine the efficiency of
equilibrium outcomes in communication models. Generically, a cheap talk outcome
is efficient only if it is pure. When the sender's payoff is state-independent,
it is efficient if and only if the sender's most preferred action is chosen
with certainty. In natural buyer-seller settings, Bayesian persuasion outcomes
are inefficient across a wide range of priors and preferences. Finally, we show
that our results apply to mechanism design problems with many players.

</details>


### [10] [Selection Procedures in Competitive Admission](https://arxiv.org/abs/2510.12653)
*Nathan Hancart*

Main category: econ.TH

TL;DR: 两个相同企业在候选人生产力未知的情况下竞争招聘。企业同时发布包含测试和接受概率的选择程序，候选人选择申请。研究发现竞争导致企业选择最准确但难度最低的测试，形成精确但无用的知识。


<details>
  <summary>Details</summary>
Motivation: 研究企业在招聘竞争中的选择策略，特别是测试统计特性和候选人自选择对均衡的影响。

Method: 构建博弈论模型，企业同时选择测试程序，候选人随后选择申请。引入测试准确度和难度两个偏序关系来分析均衡。

Result: 在对称均衡中，企业选择的测试必须在准确度上最大、难度上最小。竞争导致企业获得精确但无用的知识。

Conclusion: 招聘竞争促使企业采用高准确度但低难度的测试策略，这种策略虽然提供精确信息但对收益无实际帮助。

Abstract: Two identical firms compete to attract and hire from a pool of candidates of
unknown productivity. Firms simultaneously post a selection procedure which
consists of a test and an acceptance probability for each test outcome. After
observing the firms' selection procedures, each candidate can apply to one of
them. Both firms have access to a limited set of feasible tests. The firms face
two key considerations when choosing their selection procedure: the statistical
properties of their test and the selection into the procedure by the
candidates. I identify two partial orders on tests that are useful to
characterise the equilibrium of this game: the test's accuracy (Lehmann, 1988)
and difficulty. I show that in any symmetric equilibrium, the test chosen must
be maximal in the accuracy order and minimal in the difficulty order.
Intuitively, competition leads to maximal but misguided learning: firms end up
having precise knowledge that is not payoff relevant. I also consider the cases
where firms face capacity constraints, have the possibility of making a wage
offer and the existence of asymmetric equilibria where one firm is more
selective than another.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [11] [Modeling Hypergraph Using Large Language Models](https://arxiv.org/abs/2510.11728)
*Bingqiao Gu,Jiale Zeng,Xingqin Qi,Dong Li*

Main category: cs.SI

TL;DR: HyperLLM：一种基于大语言模型的多智能体协作框架，用于生成符合真实网络特性的大规模超图数据


<details>
  <summary>Details</summary>
Motivation: 由于真实超图数据集在规模和多样性上的稀缺，限制了超图学习算法的发展与评估，需要一种能快速生成符合真实网络特性的大规模超图的方法

Method: 利用大语言模型的语义推理、结构化生成和模拟人类行为能力，通过多智能体协作模拟超图的形成与演化过程，结合提示和结构反馈机制确保生成超图反映真实世界模式

Result: 在多个数据集上的广泛实验表明，HyperLLM在结构性和时序性超图模式上实现了卓越的保真度，且仅需最少的统计先验

Conclusion: 基于大语言模型的框架为超图建模提供了一个有前景的新方向

Abstract: Due to the advantages of hypergraphs in modeling high-order relationships in
complex systems, they have been applied to higher-order clustering, hypergraph
neural networks and computer vision. These applications rely heavily on access
to high-quality, large-scale real-world hypergraph data. Yet, compared to
traditional pairwise graphs, real hypergraph datasets remain scarce in both
scale and diversity. This shortage significantly limits the development and
evaluation of advanced hypergraph learning algorithms. Therefore, how to
quickly generate large-scale hypergraphs that conform to the characteristics of
real networks is a crucial task that has not received sufficient attention.
Motivated by recent advances in large language models (LLMs), particularly
their capabilities in semantic reasoning, structured generation, and simulating
human behavior, we investigate whether LLMs can facilitate hypergraph
generation from a fundamentally new perspective. We introduce HyperLLM, a novel
LLM-driven hypergraph generator that simulates the formation and evolution of
hypergraphs through a multi-agent collaboration. The framework integrates
prompts and structural feedback mechanisms to ensure that the generated
hypergraphs reflect key real-world patterns. Extensive experiments across
diverse datasets demonstrate that HyperLLM achieves superior fidelity to
structural and temporal hypergraph patterns, while requiring minimal
statistical priors. Our findings suggest that LLM-based frameworks offer a
promising new direction for hypergraph modeling.

</details>


### [12] [Celebrity Profiling on Short Urdu Text using Twitter Followers' Feed](https://arxiv.org/abs/2510.11739)
*Muhammad Hamza,Rizwan Jafar*

Main category: cs.SI

TL;DR: 该研究应用机器学习和深度学习技术，通过分析乌尔都语名人粉丝的推文来预测名人的人口统计特征，填补了乌尔都语这一低资源语言在该领域的研究空白。


<details>
  <summary>Details</summary>
Motivation: 社交媒体已成为数字时代的重要组成部分，名人通过在线帖子展示个人和职业生活。现有研究主要集中在英语等高资源语言，乌尔都语领域研究较少，因此需要探索如何利用粉丝的语言特征来预测名人人口统计信息。

Method: 收集了南亚名人粉丝的乌尔都语推文数据集，使用多种算法进行训练和比较，包括逻辑回归、支持向量机、随机森林、卷积神经网络和长短期记忆网络。

Result: 性别预测表现最佳，cRank和准确率均为0.65；年龄、职业和知名度预测结果中等。

Conclusion: 研究表明，利用机器学习和神经网络方法，可以有效地基于粉丝的语言特征进行乌尔都语的人口统计预测，为低资源语言的研究提供了可行方案。

Abstract: Social media has become an essential part of the digital age, serving as a
platform for communication, interaction, and information sharing. Celebrities
are among the most active users and often reveal aspects of their personal and
professional lives through online posts. Platforms such as Twitter provide an
opportunity to analyze language and behavior for understanding demographic and
social patterns. Since followers frequently share linguistic traits and
interests with the celebrities they follow, textual data from followers can be
used to predict celebrity demographics. However, most existing research in this
field has focused on English and other high-resource languages, leaving Urdu
largely unexplored.
  This study applies modern machine learning and deep learning techniques to
the problem of celebrity profiling in Urdu. A dataset of short Urdu tweets from
followers of subcontinent celebrities was collected and preprocessed. Multiple
algorithms were trained and compared, including Logistic Regression, Support
Vector Machines, Random Forests, Convolutional Neural Networks, and Long
Short-Term Memory networks. The models were evaluated using accuracy,
precision, recall, F1-score, and cumulative rank (cRank). The best performance
was achieved for gender prediction with a cRank of 0.65 and an accuracy of
0.65, followed by moderate results for age, profession, and fame prediction.
These results demonstrate that follower-based linguistic features can be
effectively leveraged using machine learning and neural approaches for
demographic prediction in Urdu, a low-resource language.

</details>


### [13] [Evolution of wartime discourse on Telegram: A comparative study of Ukrainian and Russian policymakers' communication before and after Russia's full-scale invasion of Ukraine](https://arxiv.org/abs/2510.11746)
*Mykola Makhortykh,Aytalina Kulichkina,Kateryna Maikovska*

Main category: cs.SI

TL;DR: 该研究分析了俄乌战争期间乌克兰和俄罗斯政策制定者在Telegram上的精英驱动政治传播，发现入侵后活动量激增，两国政策制定者采用不同的传播策略应对战时挑战。


<details>
  <summary>Details</summary>
Motivation: 研究俄乌战争期间政策制定者如何利用Telegram进行政治传播，这是社交媒体时代欧洲首次大规模战争，为理解战时在线政治话语动态提供重要视角。

Method: 使用2019-2024年乌克兰和俄罗斯政策制定者Telegram公开帖文的独特数据集，分析传播量、主题内容和参与者参与度的变化。

Result: 入侵后Telegram活动激增，乌克兰政策制定者初期关注战争话题但随时间减少，俄罗斯政策制定者则避免战争讨论，转而强调西方危机等无关话题分散公众注意力。

Conclusion: 研究揭示了政策制定者如何适应战时传播挑战，为理解战争时期在线政治话语动态提供了重要见解，并发现了不同政党和个人政策制定者之间的传播策略差异。

Abstract: This study examines elite-driven political communication on Telegram during
the ongoing Russo-Ukrainian war, the first large-scale European war in the
social media era. Using a unique dataset of Telegram public posts from
Ukrainian and Russian policymakers (2019-2024), we analyze changes in
communication volume, thematic content, and actor engagement following Russia's
2022 full-scale invasion. Our findings show a sharp increase in Telegram
activity after the invasion, particularly among ruling-party policymakers.
Ukrainian policymakers initially focused on war-related topics, but this
emphasis declined over time In contrast, Russian policymakers largely avoided
war-related discussions, instead emphasizing unrelated topics, such as Western
crises, to distract public attention. We also identify differences in
communication strategies between large and small parties, as well as individual
policymakers. Our findings shed light on how policymakers adapt to wartime
communication challenges and offer critical insights into the dynamics of
online political discourse during times of war.

</details>


### [14] [Structure-aware Propagation Generation with Large Language Models for Fake News Detection](https://arxiv.org/abs/2510.12125)
*Mengyang Chen,Lingwei Wei,Wei Zhou,Songlin Hu*

Main category: cs.SI

TL;DR: 提出StruSP框架，通过结构感知的合成传播增强来改进假新闻检测，解决现有方法忽略真实传播结构模式的问题。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的假新闻传播严重威胁公众信任和社会稳定。现有基于传播的方法因不完整的传播数据而受限，且LLM生成的合成传播通常忽略真实讨论的结构模式。

Method: 提出StruSP框架，在语义和结构维度上对齐合成传播与真实传播，设计双向进化传播学习策略，通过结构感知混合采样和掩码传播建模目标来对齐LLM与真实传播结构模式。

Result: 在三个公共数据集上的实验表明，StruSP在各种实际检测场景中显著提高了假新闻检测性能。

Conclusion: BEP策略使LLM能够在语义和结构上生成更真实和多样化的传播，StruSP框架有效提升了假新闻检测能力。

Abstract: The spread of fake news on social media poses a serious threat to public
trust and societal stability. While propagation-based methods improve fake news
detection by modeling how information spreads, they often suffer from
incomplete propagation data. Recent work leverages large language models (LLMs)
to generate synthetic propagation, but typically overlooks the structural
patterns of real-world discussions. In this paper, we propose a novel
structure-aware synthetic propagation enhanced detection (StruSP) framework to
fully capture structural dynamics from real propagation. It enables LLMs to
generate realistic and structurally consistent propagation for better
detection. StruSP explicitly aligns synthetic propagation with real-world
propagation in both semantic and structural dimensions. Besides, we also design
a new bidirectional evolutionary propagation (BEP) learning strategy to better
align LLMs with structural patterns of propagation in the real world via
structure-aware hybrid sampling and masked propagation modeling objective.
Experiments on three public datasets demonstrate that StruSP significantly
improves fake news detection performance in various practical detection
scenarios. Further analysis indicates that BEP enables the LLM to generate more
realistic and diverse propagation semantically and structurally.

</details>


### [15] [CrisisNews: A Dataset Mapping Two Decades of News Articles on Online Problematic Behavior at Scale](https://arxiv.org/abs/2510.12243)
*Jeanne Choi,DongJae Kang,Yubin Choi,Juhoon Lee,Joseph Seering*

Main category: cs.SI

TL;DR: 该研究提出'社交媒体危机'概念，通过分析20年来的93,250篇新闻报道，从事件视角而非内容视角来理解社交媒体上的问题行为演变模式。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体普及，在线问题行为日益升级为大规模危机，需要新的缓解策略。现有研究多关注用户生成内容，缺乏对离散事件演变过程的关注。

Method: 使用全球新闻报道构建包含93,250篇文章的数据集，分析代表性样本来分类利益相关者角色、行为类型和结果，识别社交媒体危机的模式。

Result: 揭示了超越内容描述的社交媒体危机分类模式，为更细致的危机分类提供了信息。

Conclusion: 通过采用更广泛的视角，这项研究旨在为设计更安全的平台提供信息，使平台能够采取主动措施缓解危机，培育更可信的在线环境。

Abstract: As social media adoption grows globally, online problematic behaviors
increasingly escalate into large-scale crises, requiring an evolving set of
mitigation strategies. While HCI research often analyzes problematic behaviors
with pieces of user-generated content as the unit of analysis, less attention
has been given to event-focused perspectives that track how discrete events
evolve. In this paper, we examine 'social media crises': discrete patterns of
problematic behaviors originating and evolving within social media that cause
larger-scale harms. Using global news coverage, we present a dataset of 93,250
news articles covering social media-endemic crises from the past 20 years. We
analyze a representative subset to classify stakeholder roles, behavior types,
and outcomes, uncovering patterns that inform more nuanced classification of
social media crises beyond content-based descriptions. By adopting a wider
perspective, this research seeks to inform the design of safer platforms,
enabling proactive measures to mitigate crises and foster more trustworthy
online environments.

</details>


### [16] [MOUFLON: Multi-group Modularity-based Fairness-aware Community Detection](https://arxiv.org/abs/2510.12348)
*Georgios Panayiotou,Anand Mathew Muthukulam Simon,Matteo Magnani,Ece Calikus*

Main category: cs.SI

TL;DR: MOUFLON是一种公平感知的模块化社区检测方法，允许调整分区质量与公平结果之间的重要性平衡。


<details>
  <summary>Details</summary>
Motivation: 解决社区检测中存在的结构性偏见问题，这些偏见可能导致人口统计群体与网络结构之间的强对齐，影响公平性。

Method: 使用新颖的比例平衡公平度量，在模块化社区检测中融入公平约束，支持多群体和不平衡网络设置。

Result: 在合成和真实网络数据集上的评估展示了模块化与公平性之间的权衡关系，以及网络特征对公平结果的影响。

Conclusion: 研究揭示了将公平约束纳入模块化社区检测的效果，为设计和基准测试公平感知的社交网络分析方法提供了关键考虑因素。

Abstract: In this paper, we propose MOUFLON, a fairness-aware, modularity-based
community detection method that allows adjusting the importance of partition
quality over fairness outcomes. MOUFLON uses a novel proportional balance
fairness metric, providing consistent and comparable fairness scores across
multi-group and imbalanced network settings. We evaluate our method under both
synthetic and real network datasets, focusing on performance and the trade-off
between modularity and fairness in the resulting communities, along with the
impact of network characteristics such as size, density, and group
distribution. As structural biases can lead to strong alignment between
demographic groups and network structure, we also examine scenarios with highly
clustered homogeneous groups, to understand how such structures influence
fairness outcomes. Our findings showcase the effects of incorporating fairness
constraints into modularity-based community detection, and highlight key
considerations for designing and benchmarking fairness-aware social network
analysis methods.

</details>


### [17] [Timeliness, Consensus, and Composition of the Crowd: Community Notes on X](https://arxiv.org/abs/2510.12559)
*Olesya Razuvayevskaya,Adel Tayebi,Ulrikke Dybdal Sørensen,Kalina Bontcheva,Richard Rogers*

Main category: cs.SI

TL;DR: 对X平台Community Notes系统的首次大规模量化分析显示，该系统存在显著的参与不平等、共识形成困难和时效性问题，揭示了这一众包审核系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究Community Notes这一众包审核系统的实际运行效率，考察其在参与平等性、共识形成和时效性三个关键维度的表现。

Method: 基于超过180万条笔记数据，采用定量分析方法，考察参与不平等性（基尼系数）、共识形成率（笔记发布率）和时效性（笔记发布延迟时间）。

Result: 发现严重的参与不平等（前10%贡献者产生58%笔记，基尼系数0.68）、低共识率（仅11.5%笔记达成发布共识）、高冲突率（69%帖子收到矛盾分类），以及平均65.7小时的发布延迟。

Conclusion: Community Notes是一个分层化、审议性的系统，由少数精英主导，存在持续分歧和时效约束，需要设计策略来促进公平、快速共识和认知可靠性。

Abstract: This study presents the first large-scale quantitative analysis of the
efficiency of X's Community Notes, a crowdsourced moderation system for
identifying and contextualising potentially misleading content. Drawing on over
1.8 million notes, we examine three key dimensions of crowdsourced moderation:
participation inequality, consensus formation, and timeliness. Despite the
system's goal of collective moderation, we find substantial concentration
effect, with the top 10% of contributors producing 58% of all notes (Gini
Coefficient = 0.68). The observed consensus is rare-only 11.5% of notes reach
agreement on publication, while 69% of posts receive conflicting
classifications. A majority of noted posts (approximately 68%) are annotated as
"Note Not Needed", reflecting the repurposing of the platform for debate rather
than moderation. We found that such posts are paradoxically more likely to
yield published notes (OR = 3.12). Temporal analyses show that the notes, on
average, are published 65.7 hours after the original post, with longer delays
significantly reducing the likelihood of consensus. These results portray
Community Notes as a stratified, deliberative system dominated by a small
contributor elite, marked by persistent dissensus, and constrained by
timeliness. We conclude this study by outlining design strategies to promote
equity, faster consensus, and epistemic reliability in community-based
moderation.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [18] [Quantum Deception: Honey-X Deception using Quantum Games](https://arxiv.org/abs/2510.11848)
*Efstratios Reppas,Ali Wadi,Brendan Gould,Kyriakos G. Vamvoudakis*

Main category: eess.SY

TL;DR: 将经典博弈中的Honey-X欺骗范式扩展到量子领域，通过控制扰动收益哈密顿量来形式化量子欺骗，并证明知情受害者与天真受害者的均衡策略相同，从而将量子欺骗转化为双层优化问题。


<details>
  <summary>Details</summary>
Motivation: 将经典博弈中的欺骗概念扩展到量子领域，研究量子策略空间和非经典收益如何增强欺骗效果。

Method: 将量子欺骗形式化为对收益哈密顿量的受控扰动，建立欺骗预算约束，并将其转化为双层优化问题和双线性半定规划。

Result: 发现知情受害者和天真受害者的均衡策略相同，通过量子便士翻转游戏的模拟展示了量子欺骗相对于经典欺骗的放大效应。

Conclusion: 量子欺骗框架成功扩展了经典欺骗概念，量子策略空间和非经典收益确实能增强欺骗效果，为量子博弈中的欺骗行为提供了理论基础。

Abstract: In this paper, we develop a framework for deception in quantum games,
extending the Honey-X paradigm from classical zero-sum settings into the
quantum domain. Building on a view of deception in classical games as
manipulation of a player's perception of the payoff matrix, we formalize
quantum deception as controlled perturbations of the payoff Hamiltonian subject
to a deception budget. We show that when victims are aware of possible
deception, their equilibrium strategies surprisingly coincide with those of
naive victims who fully trust the deceptive Hamiltonian. This equivalence
allows us to cast quantum deception as a bilevel optimization problem, which
can be reformulated into a bilinear semidefinite program. To illustrate the
framework, we present simulations on quantum versions of the Penny Flip game,
demonstrating how quantum strategy spaces and non-classical payoffs can amplify
the impact of deception relative to classical formulations.

</details>


### [19] [Sleepy Chauffeur Detection and Alert Techniques for Road Safety](https://arxiv.org/abs/2510.12205)
*Himel Ghosh,Sayak Chatterjee,Antik Ganguly,Shreetama Karmakar,Koushik Sarkar*

Main category: eess.SY

TL;DR: 本文综述了现有驾驶员疲劳检测系统，并提出了一种使用传感器和Arduino的简单廉价系统，能够检测困倦并发出警报。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是导致交通事故的主要原因之一，预防这些事故对避免生命损失和严重伤害至关重要。

Method: 使用传感器和Arduino构建检测系统，通过警报和发送预警消息来提醒疲劳驾驶员。

Result: 提出的系统能够有效检测驾驶员疲劳状态并发出警报。

Conclusion: 该系统提供了一种简单且成本效益高的解决方案来预防疲劳驾驶事故。

Abstract: The most startling of the contemporary problems is the sleepiness of
chauffeur which causes lots of car accidents. Prevention of those impending
accidents by detecting and alerting the sleepy chauffeur is vital, otherwise
that would lead to loss of lives and various traumas along with severe
injuries. The slumber or sleep may be caused by huge stress, pressure,
relentless work load or alcoholism, for which sleep deprivation occurs and the
chauffeur while driving gets drowsy. So far, considerable amount of systems has
been developed to detect drowsiness of drivers, most of which mainly depend on
image processing algorithms using cameras. Some of them also incorporate
artificial intelligence and machine learning based algorithms. This paper
presents a review of the existing systems and also proposes an easy and cheap
system using sensors and Arduino, capable of detecting sleepiness and generates
siren alarm and send alert message to take precautionary measures.

</details>


### [20] [Empowering Prosumers: Incentive Design for Local Electricity Markets Under Generalized Uncertainty and Grid Constraints](https://arxiv.org/abs/2510.12318)
*Pål Forr Austnes,Matthieu Jacobs,Lu Wang,Mario Paolone*

Main category: eess.SY

TL;DR: 提出基于概率节点边际定价的本地电力市场框架，有效处理发电、用电和电网变量的不确定性，通过两阶段凸模型计算价格概率分布，激励终端产消者参与市场同时确保电网安全运行。


<details>
  <summary>Details</summary>
Motivation: 当前中央电力市场未直接纳入不确定性，也未考虑配电网物理约束。可再生能源的随机性需要灵活备用电源，终端产消者的灵活性被视为大规模可再生能源整合的关键推动因素。

Method: 使用lindistflow方程表示电网，采用广义多项式混沌(gPC)处理不确定性传播。提出两阶段凸模型：日前阶段计算各时段价格概率分布，实时阶段基于已实现的不确定性计算实时价格。

Result: 通过四个案例研究证明该方法能有效激励终端产消者参与市场，同时确保其行为不会对电网运行产生不利影响。

Conclusion: 提出的本地电力市场框架能够有效处理不确定性，促进可再生能源整合，同时保障电网安全稳定运行。

Abstract: Since the 1990s, widespread introduction of central (wholesale) electricity
markets has been seen across multiple continents, driven by the search for
efficient operation of the power grid through competition. The increase of
renewables has made significant impacts both on central electricity markets and
distribution-level grids as renewable power generation is often connected to
the latter. These stochastic renewable technologies have both advantages and
disadvantages. On one hand they offer very low marginal cost and carbon
emissions, while on the other hand, their output is uncertain, requiring
flexible backup power with high marginal cost. Flexibility from end-prosumers
or smaller market participants is therefore seen as a key enabler of
large-scale integration of renewables. However, current central electricity
markets do not directly include uncertainty into the market clearing and do not
account for physical constraints of distribution grids. In this paper we
propose a local electricity market framework based on probabilistic locational
marginal pricing, effectively accounting for uncertainties in production,
consumption and grid variables. The model includes a representation of the grid
using the lindistflow equations and accounts for the propagation of uncertainty
using general Polynomial Chaos (gPC). A two-stage convex model is proposed; in
the day-ahead stage, probability distributions of prices are calculated for
every timestep, where the expected values represent the day-ahead (spot)
prices. In the real-time stage, uncertainties are realized (measured) and a
trivial calculation reveals the real-time price. Through four instructive
case-studies we highlight the effectiveness of the method to incentivize
end-prosumers' participation in the market, while ensuring that their behavior
does not have an adverse impact on the operation of the grid.

</details>


### [21] [Pooling Probabilistic Forecasts for Cooperative Wind Power Offering](https://arxiv.org/abs/2510.12382)
*Honglin Wen,Pierre Pinson*

Main category: eess.SY

TL;DR: 提出了一个“协调后优化”框架，用于风电商合作参与电力市场，通过协调个体预测信息来制定市场报价和利润分配规则。


<details>
  <summary>Details</summary>
Motivation: 现有风电商合作方法忽视了预测信息不一致的问题，这可能导致报价和分配的不确定性。

Method: 采用两阶段随机规划方法，先协调个体预测为联合预测，再基于场景对偶值构建预算平衡且稳定的利润分配规则。

Result: 通过实证案例验证了该方法的实际有效性和理论合理性。

Conclusion: 所提框架能够有效解决风电商合作中的预测不一致问题，确保合作稳定性和利润公平分配。

Abstract: Wind power producers can benefit from forming coalitions to participate
cooperatively in electricity markets. To support such collaboration, various
profit allocation rules rooted in cooperative game theory have been proposed.
However, existing approaches overlook the lack of coherence among producers
regarding forecast information, which may lead to ambiguity in offering and
allocations. In this paper, we introduce a ``reconcile-then-optimize''
framework for cooperative market offerings. This framework first aligns the
individual forecasts into a coherent joint forecast before determining market
offers. With such forecasts, we formulate and solve a two-stage stochastic
programming problem to derive both the aggregate offer and the corresponding
scenario-based dual values for each trading hour. Based on these dual values,
we construct a profit allocation rule that is budget-balanced and stable.
Finally, we validate the proposed method through empirical case studies,
demonstrating its practical effectiveness and theoretical soundness.

</details>


### [22] [Physics-Informed Reinforcement Learning for Large-Scale EV Smart Charging Considering Distribution Network Voltage Constraints](https://arxiv.org/abs/2510.12335)
*Stavros Orfanoudakis,Frans Oliehoek,Peter Palesnky,Pedro P. Vergara*

Main category: eess.SY

TL;DR: 提出了一种物理信息强化学习算法PI-TD3，用于电动汽车智能充电管理，通过集成可微分潮流模型和基于电压的奖励设计，在满足用户需求的同时提供实时电压支持。


<details>
  <summary>Details</summary>
Motivation: 大规模无序的电动汽车充电可能威胁配电网电压稳定性，现有强化学习方法往往忽视物理电网约束或在复杂大规模任务中性能有限，限制了其可扩展性和实际应用性。

Method: 将可微分潮流模型和基于电压的奖励设计集成到TD3算法中，形成物理信息强化学习算法PI-TD3，使电动汽车能够在满足用户需求的同时提供实时电压支持。

Result: 在IEEE 34总线和123总线网络上测试表明，PI-TD3在电网约束管理、用户满意度和经济指标方面优于无模型强化学习和基于优化的基线方法，即使系统扩展到数百辆电动汽车。

Conclusion: PI-TD3算法实现了更快的收敛速度、改进的样本效率和可靠的电压幅值调节，为增强电网韧性和支持配电网运行提供了稳健、可扩展且实用的电动汽车充电策略。

Abstract: Electric Vehicles (EVs) offer substantial flexibility for grid services, yet
large-scale, uncoordinated charging can threaten voltage stability in
distribution networks. Existing Reinforcement Learning (RL) approaches for
smart charging often disregard physical grid constraints or have limited
performance for complex large-scale tasks, limiting their scalability and
real-world applicability. This paper introduces a physics-informed (PI) RL
algorithm that integrates a differentiable power flow model and voltage-based
reward design into the Twin Delayed Deep Deterministic Policy Gradient (TD3)
algorithm, enabling EVs to deliver real-time voltage support while meeting user
demands. The resulting PI-TD3 algorithm achieves faster convergence, improved
sample efficiency, and reliable voltage magnitude regulation under uncertain
and overloaded conditions. Benchmarks on the IEEE 34-bus and 123-bus networks
show that the proposed PI-TD3 outperforms both model-free RL and
optimization-based baselines in grid constraint management, user satisfaction,
and economic metrics, even as the system scales to hundreds of EVs. These
advances enable robust, scalable, and practical EV charging strategies that
enhance grid resilience and support distribution networks operation.

</details>


### [23] [Ultrafast Grid Impedance Identification in $dq$-Asymmetric Three-Phase Power Systems](https://arxiv.org/abs/2510.12338)
*Mohamed Abdalmoaty,Verena Häberle,Xiuqiang He,Florian Dörfler*

Main category: eess.SY

TL;DR: 提出一种非参数频域方法，使用并网变流器在宽频带内识别小信号dq不对称电网阻抗，实现超快速（<1秒）识别，无需专用激励信号或硬件。


<details>
  <summary>Details</summary>
Motivation: 现有识别方法面临显著权衡：被动方法依赖环境谐波和罕见电网事件，只能提供少数频率的估计；主动方法需要长时间序列测量和专用设备。时间域方法虽然减少测量时间，但需要简化假设或繁琐的模型阶数调整。

Method: 非参数频域方法，利用并网变流器进行电网阻抗识别，无需专用激励信号或硬件，在频域内进行操作。

Result: 通过详细电磁暂态仿真验证了该方法，证明其相对于现有替代方案的明显优越性，实现超快速（<1秒）识别。

Conclusion: 该方法有效解决了现有电网阻抗识别方法的挑战，实现了快速、无需专用设备的宽频带阻抗识别。

Abstract: We propose a non-parametric frequency-domain method to identify small-signal
$dq$-asymmetric grid impedances, over a wide frequency band, using
grid-connected converters. Existing identification methods are faced with
significant trade-offs: e.g., passive approaches rely on ambient harmonics and
rare grid events and thus can only provide estimates at a few frequencies,
while many active approaches that intentionally perturb grid operation require
long time series measurement and specialized equipment. Although active
time-domain methods reduce the measurement time, they either make crude
simplifying assumptions or require laborious model order tuning. Our approach
effectively addresses these challenges: it does not require specialized
excitation signals or hardware and achieves ultrafast ($<1$ s) identification,
drastically reducing measurement time. Being non-parametric, our approach also
makes no assumptions on the grid structure. A detailed electromagnetic
transient simulation is used to validate the method and demonstrate its clear
superiority over existing alternatives.

</details>


### [24] [High-Parallel FPGA-Based Discrete Simulated Bifurcation for Large-Scale Optimization](https://arxiv.org/abs/2510.12407)
*Fabrizio Orlando,Deborah Volpe,Giacomo Orlandi,Mariagrazia Graziano,Fabrizio Riente,Marco Vacca*

Main category: eess.SY

TL;DR: 该论文分析了模拟绝热分岔算法的三种变体(dSB、bSB、HbSB)，评估了定点表示的可行性，并提出了一个开源的FPGA硬件架构来实现dSB算法，成功在低端FPGA上解决了256变量的问题。


<details>
  <summary>Details</summary>
Motivation: 组合优化问题具有指数级复杂度，难以求解。模拟绝热分岔算法是一种量子启发算法，能够通过模拟非线性参量振荡器的绝热演化来近似求解大规模组合优化问题，特别适合硬件实现。

Method: 使用专用软件模型全面分析dSB、bSB和HbSB算法变体，评估定点表示的硬件实现可行性，然后设计并实现了一个开源的FPGA硬件架构来实现dSB算法，支持用户根据需求调整算法并行化程度。

Result: 在AMD Kria KV260 SoM（低端FPGA）上成功实现了概念验证，能够解决256变量的最大割和背包问题。

Conclusion: 提出的dSB算法FPGA实现方案在低端硬件上有效解决了大规模组合优化问题，证明了该方法的可行性和实用性。

Abstract: Combinatorial Optimization (CO) problems exhibit exponential complexity,
making their resolution challenging. Simulated Adiabatic Bifurcation (aSB) is a
quantum-inspired algorithm to obtain approximate solutions to largescale CO
problems written in the Ising form. It explores the solution space by emulating
the adiabatic evolution of a network of Kerr-nonlinear parametric oscillators
(KPOs), where each oscillator represents a variable in the problem. The optimal
solution corresponds to the ground state of this system. A key advantage of
this approach is the possibility of updating multiple variables simultaneously,
making it particularly suited for hardware implementation. To enhance solution
quality and convergence speed, variations of the algorithm have been proposed
in the literature, including ballistic (bSB), discrete (dSB), and thermal
(HbSB) versions. In this work, we have comprehensively analyzed dSB, bSB, and
HbSB using dedicated software models, evaluating the feasibility of using a
fixed-point representation for hardware implementation. We then present an
opensource hardware architecture implementing the dSB algorithm for
Field-Programmable Gate Arrays (FPGAs). The design allows users to adjust the
degree of algorithmic parallelization based on their specific requirements. A
proof-of-concept implementation that solves 256-variable problems was achieved
on an AMD Kria KV260 SoM, a low-tier FPGA, validated using well-known max-cut
and knapsack problems.

</details>


### [25] [A Unidirectionally Connected FAS Approach for 6-DOF Quadrotor Control](https://arxiv.org/abs/2510.12360)
*Weijie Ren,Haowen Liu,Guang-Ren Duan*

Main category: eess.SY

TL;DR: 提出单向连接全驱动系统(UC-FAS)方法，用于6自由度四旋翼的亚稳定和跟踪控制，通过消除高阶导数估计简化控制器设计。


<details>
  <summary>Details</summary>
Motivation: 解决现有状态空间和FAS框架在四旋翼控制中的局限性，统一不同的FAS变换方法，简化控制器设计。

Method: 将欠驱动四旋翼动力学转换为UC-FAS模型，消除控制输入高阶导数估计，实现闭环动力学的直接特征结构分配。

Result: 仿真显示实现了精确的6自由度跟踪性能。

Conclusion: 该工作将理论FAS方法进展与实际实现需求连接起来，为非线性四旋翼控制提供了标准化范式。

Abstract: This paper proposes a unidirectionally connected fully actuated system
(UC-FAS) approach for the sub-stabilization and tracking control of 6-DOF
quadrotors, tackling limitations both in state-space and FAS framework to some
extent. The framework systematically converts underactuated quadrotor dynamics
into a UC-FAS model, unifying the existing different FAS transformation ways.
By eliminating estimation of the high-order derivatives of control inputs, a
drawback of current methods, the UC-FAS model simplifies controller design and
enables direct eigenstructure assignment for closed-loop dynamics. Simulations
demonstrate precise 6-DOF tracking performance. This work bridges theoretical
FAS approach advancements with practical implementation needs, offering a
standardized paradigm for nonlinear quadrotor control.

</details>


### [26] [Optimising Communication Control Factors for Energy Consumption in Rural LOS V2X](https://arxiv.org/abs/2510.12539)
*Zhanle Zhao,Son Dinh-Van,Yuen Kwan Mo,Siddartha Khastgir,Matthew D. Higgins*

Main category: eess.SY

TL;DR: 研究5G NR V2X通信中如何配置子载波间距、调制编码方案和发射功率，在乡村LOS场景下平衡安全性和能耗。重交通下需提高发射功率和低速率MCS，轻交通下可降低功率同时保持低MCS，实现可靠性-能耗的良好权衡。


<details>
  <summary>Details</summary>
Motivation: 乡村地区路边单元稀疏且功率受限，需要在保证车辆安全的同时考虑能量效率。

Method: 研究三个通信控制因素（子载波间距、调制编码方案、发射功率）在不同交通密度下的配置策略，以包接收率作为安全指标，分析其对最小通信距离的影响。

Result: 重交通场景下，提高发射功率和选择低速率MCS在30kHz SCS下能维持高PRR，但能耗较高；轻交通场景下，保持较低发射功率和低MCS水平能在可接受的PRR下实现良好的可靠性-能耗权衡。

Conclusion: 需要采用自适应、能量感知的策略来保证乡村V2X系统的安全性和能量效率。

Abstract: Connected braking can reduce fatal collisions in connected and autonomous
vehicles (CAVs) by using reliable, low-latency 5G New Radio (NR) links,
especially NR Sidelink Vehicle-to-Everything (V2X). In rural areas, road side
units are sparse and power-constrained or off-grid, so energy efficiency must
be considered alongside safety. This paper studies how three communication
control factors including subcarrier spacing ($\mathrm{SCS}$), modulation and
coding scheme ($\mathrm{MCS}$), and transmit power ($P_{\mathrm{t}}$) should be
configured to balance safety and energy consumption in rural line-of-sight
(LOS) scenarios in light and heavy traffic scenarios. Safety is quantified by
the packet receive ratio ($\mathrm{PRR}$) against the minimum communication
distance $D_{\mathrm{comm}}$, defined as the distance that the vehicle travels
during the transmission of the safety message. Results show that, under heavy
traffic, increasing $P_{\mathrm{t}}$ and selecting a low-rate $\mathrm{MCS}$ at
$\mathrm{SCS} = 30$ kHz sustains high $\mathrm{PRR}$ at $D_{\mathrm{comm}}$,
albeit with higher energy cost. In light traffic, maintaining lower
$P_\mathrm{t}$ with low $\mathrm{MCS}$ levels achieves a favorable
reliability-energy trade-off while preserving acceptable $\mathrm{PRR}$ at
$D_{\mathrm{comm}}$. These findings demonstrate the necessity of adaptive,
energy-aware strategy to guarantee both safety and energy efficiency in rural
V2X systems.

</details>


### [27] [Privacy-Preserving Distributed Estimation with Limited Data Rate](https://arxiv.org/abs/2510.12549)
*Jieming Ke,Jimin Wang,Ji-Feng Zhang*

Main category: eess.SY

TL;DR: 提出了一种基于二值量化器的隐私保护分布式估计算法，在保护观测数据隐私的同时降低通信成本，每个传感器每步仅传输1比特信息，且估计值几乎必然收敛到真实参数值。


<details>
  <summary>Details</summary>
Motivation: 解决分布式估计中观测数据隐私保护和有限数据率通信的问题，需要在保护敏感信息的同时降低通信成本。

Method: 开发基于二值量化器的隐私保护分布式估计算法，通过设计时变隐私噪声和步长的协同设计准则，确保估计收敛性。

Result: 算法隐私保护能力（用Fisher信息矩阵衡量）随时间动态增强，以多项式速率收敛到零；每个传感器每步仅传输1比特信息；估计值几乎必然收敛到真实参数值，并获得多项式收敛速率。

Conclusion: 成功实现了隐私保护与通信成本降低的双重目标，建立了隐私保护与收敛速率之间的权衡关系，数值实验验证了主要结果。

Abstract: This paper focuses on the privacy-preserving distributed estimation problem
with a limited data rate, where the observations are the sensitive information.
Specifically, a binary-valued quantizer-based privacy-preserving distributed
estimation algorithm is developed, which improves the algorithm's
privacy-preserving capability and simultaneously reduces the communication
costs. The algorithm's privacy-preserving capability, measured by the Fisher
information matrix, is dynamically enhanced over time. Notably, the Fisher
information matrix of the output signals with respect to the sensitive
information converges to zero at a polynomial rate, and the improvement in
privacy brought by the quantizers is quantitatively characterized as a
multiplicative effect. Regarding the communication costs, each sensor transmits
only 1 bit of information to its neighbours at each time step. Additionally,
the assumption on the negligible quantization error for real-valued messages is
not required. While achieving the requirements of privacy preservation and
reducing communication costs, the algorithm ensures that its estimates converge
almost surely to the true value of the unknown parameter by establishing a
co-design guideline for the time-varying privacy noises and step-sizes. A
polynomial almost sure convergence rate is obtained, and then the trade-off
between privacy and convergence rate is established. Numerical examples
demonstrate the main results.

</details>


### [28] [Enhancing Robust Multi-Market Participation of Renewable-Based VPPs through Flexible Resources](https://arxiv.org/abs/2510.12589)
*Hadi Nemati,Álvaro Ortega,Pedro Sánchez-Martín,Lukas Sigrist,Luis Rouco,Ignacio Egido*

Main category: eess.SY

TL;DR: 本文分析了不同灵活资源对可再生能源虚拟电厂在能源和备用市场中参与的影响，采用两阶段鲁棒优化处理不确定性，并通过边际贡献法评估各技术对利润的贡献。


<details>
  <summary>Details</summary>
Motivation: 在向可持续电力系统转型过程中，可再生能源虚拟电厂面临有效市场参与策略和不确定性管理的挑战，其可行性依赖于灵活资源的利用。

Method: 使用两阶段鲁棒优化方法处理发电、消费和电价的多重不确定性，并通过边际贡献法公平分配各技术在不同市场中的利润。

Result: 对西班牙南部虚拟电厂的模拟显示，战略决策和灵活资源的可用性显著影响可行性、市场参与和机组调度。

Conclusion: 灵活资源对可再生能源虚拟电厂的市场参与和盈利能力具有重要影响，合理的资源组合和利润分配策略是确保其可行性的关键。

Abstract: In the transition toward a sustainable power system, renewable-based Virtual
Power Plants (RVPPs) have emerged as a promising solution to the challenges of
integrating renewable energy sources into electricity markets. Their viability,
however, depends on effective market participation strategies and the ability
to manage uncertainties while leveraging flexible resources. This paper
analyzes the impact of different flexible resources - such as concentrated
solar power plants, hydro plants, biomass plants, and flexible demand - on the
participation of RVPPs in energy and reserve markets. Multiple sources of
uncertainty in generation, consumption, and electricity prices are addressed
using a two-stage robust optimization approach. The contribution of different
technologies to RVPP profitability is evaluated through a marginal contribution
method, ensuring fair allocation of profits among them according to their
actual role in energy and reserve provision across markets. Simulations for an
RVPP in southern Spain demonstrate how strategic decisions and the availability
of flexible resources influence viability, market participation, and unit
scheduling.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [AI Agents for the Dhumbal Card Game: A Comparative Study](https://arxiv.org/abs/2510.11736)
*Sahaj Raj Malla*

Main category: cs.AI

TL;DR: 本研究系统评估了AI代理在Dhumbal文化纸牌游戏中的表现，比较了基于规则、搜索和学习的方法，发现基于规则的激进策略在1024轮模拟中获胜率最高（88.3%），优于ISMCTS和PPO方法。


<details>
  <summary>Details</summary>
Motivation: 评估AI代理在具有文化意义的不完全信息多人纸牌游戏Dhumbal中的表现，为AI研究提供可复现框架，并支持文化游戏的数字保护。

Method: 形式化Dhumbal游戏机制，实现多种AI代理：基于启发式（激进、保守、平衡、机会主义）、基于搜索（MCTS、ISMCTS）和强化学习（DQN、PPO）方法，通过类别内锦标赛和跨类别冠军赛进行评估。

Result: 在1024轮模拟中，基于规则的激进代理获得最高胜率（88.3%，95% CI: [86.3, 90.3]），通过有效利用Jhyap声明优于ISMCTS（9.0%）和PPO（1.5%）。

Conclusion: 研究贡献了可复现的AI框架，揭示了不完全信息下启发式方法的有效性，提供了开源代码，推动了AI研究并支持文化游戏的数字保护。

Abstract: This study evaluates Artificial Intelligence (AI) agents for Dhumbal, a
culturally significant multiplayer card game with imperfect information,
through a systematic comparison of rule-based, search-based, and learning-based
strategies. We formalize Dhumbal's mechanics and implement diverse agents,
including heuristic approaches (Aggressive, Conservative, Balanced,
Opportunistic), search-based methods such as Monte Carlo Tree Search (MCTS) and
Information Set Monte Carlo Tree Search (ISMCTS), and reinforcement learning
approaches including Deep Q-Network (DQN) and Proximal Policy Optimization
(PPO), and a random baseline. Evaluation involves within-category tournaments
followed by a cross-category championship. Performance is measured via win
rate, economic outcome, Jhyap success, cards discarded per round, risk
assessment, and decision efficiency. Statistical significance is assessed using
Welch's t-test with Bonferroni correction, effect sizes via Cohen's d, and 95%
confidence intervals (CI). Across 1024 simulated rounds, the rule-based
Aggressive agent achieves the highest win rate (88.3%, 95% CI: [86.3, 90.3]),
outperforming ISMCTS (9.0%) and PPO (1.5%) through effective exploitation of
Jhyap declarations. The study contributes a reproducible AI framework, insights
into heuristic efficacy under partial information, and open-source code,
thereby advancing AI research and supporting digital preservation of cultural
games.

</details>


### [30] [Beyond Consensus: Mitigating the Agreeableness Bias in LLM Judge Evaluations](https://arxiv.org/abs/2510.11822)
*Suryaansh Jain,Umair Z. Ahmed,Shubham Sahai,Ben Leong*

Main category: cs.AI

TL;DR: LLM作为评估器存在强烈的正向偏见，能准确识别有效输出但难以识别无效输出。论文提出了少数否决策略和基于回归的框架来缓解这种偏见，在代码反馈任务上显著提升了评估准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法存在系统性正向偏见问题，虽然能高精度识别有效输出，但对无效输出的识别准确率很低。这种偏见加上类别不平衡问题导致可靠性评分被夸大，需要更有效的解决方案。

Method: 提出了两种方法：1）最优少数否决策略，对缺失数据具有鲁棒性；2）基于回归的框架，使用少量人工标注数据直接建模验证器偏见。

Result: 在366个高中Python程序的代码反馈任务中，回归方法将最大绝对误差降至仅1.2%，比14个最先进LLM的最佳集成性能提升2倍。

Conclusion: LLM评估器存在系统性正向偏见，通过少数否决策略和回归框架可以有效缓解这一问题，显著提升评估的准确性和可靠性。

Abstract: New Large Language Models (LLMs) become available every few weeks, and modern
application developers confronted with the unenviable task of having to decide
if they should switch to a new model. While human evaluation remains the gold
standard, it is costly and unscalable. The state-of-the-art approach is to use
LLMs as evaluators ( LLM-as-a-judge), but this suffers from a critical flaw:
LLMs exhibit a strong positive bias. We provide empirical evidence showing that
while LLMs can identify valid outputs with high accuracy (i.e., True Positive
Rate 96%), they are remarkably poor at identifying invalid ones (i.e., True
Negative Rate <25%). This systematic bias, coupled with class imbalance, often
leads to inflated reliability scores.
  While ensemble-based methods like majority voting can help, we show that they
are not good enough. We introduce an optimal minority-veto strategy that is
resilient to missing data and mitigates this bias to a large extent. For
scenarios requiring even higher precision, we propose a novel regression-based
framework that directly models the validator bias using a small set of
human-annotated ground truth data. On a challenging code feedback task over 366
high-school Python programs, our regression approach reduces the maximum
absolute error to just 1.2%, achieving a 2x improvement over the
best-performing ensemble of 14 state-of-the-art LLMs.

</details>


### [31] [Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation](https://arxiv.org/abs/2510.11977)
*Sayash Kapoor,Benedikt Stroebl,Peter Kirgis,Nitya Nadgir,Zachary S Siegel,Boyi Wei,Tianci Xue,Ziru Chen,Felix Chen,Saiteja Utpala,Franck Ndzomga,Dheeraj Oruganty,Sophie Luskin,Kangheng Liu,Botao Yu,Amit Arora,Dongyoon Hahm,Harsh Trivedi,Huan Sun,Juyong Lee,Tengjun Jin,Yifan Mai,Yifei Zhou,Yuxuan Zhu,Rishi Bommasani,Daniel Kang,Dawn Song,Peter Henderson,Yu Su,Percy Liang,Arvind Narayanan*

Main category: cs.AI

TL;DR: 提出了HAL（整体智能体排行榜）来解决AI智能体评估中的挑战，包括标准化评估框架、三维分析和LLM辅助日志检查，旨在推动从基准测试表现转向现实世界可靠性。


<details>
  <summary>Details</summary>
Motivation: AI智能体在复杂任务中应用广泛，但现有评估存在诸多问题，阻碍了对智能体真实性能的理解。

Method: 1) 开发标准化评估框架，在数百个VM上并行评估；2) 进行模型、支架和基准的三维分析；3) 使用LLM辅助日志检查发现未报告行为。

Result: 验证了框架的有效性，进行了21,730次智能体运行，覆盖9个模型和9个基准，发现意外洞察如更高推理努力反而降低准确性，并揭示了智能体的异常行为。

Conclusion: 通过标准化评估方法和解决常见陷阱，HAL有助于推动AI智能体从基准测试表现向现实世界可靠性的转变。

Abstract: AI agents have been developed for complex real-world tasks from coding to
customer service. But AI agent evaluations suffer from many challenges that
undermine our understanding of how well agents really work. We introduce the
Holistic Agent Leaderboard (HAL) to address these challenges. We make three
main contributions. First, we provide a standardized evaluation harness that
orchestrates parallel evaluations across hundreds of VMs, reducing evaluation
time from weeks to hours while eliminating common implementation bugs. Second,
we conduct three-dimensional analysis spanning models, scaffolds, and
benchmarks. We validate the harness by conducting 21,730 agent rollouts across
9 models and 9 benchmarks in coding, web navigation, science, and customer
service with a total cost of about $40,000. Our analysis reveals surprising
insights, such as higher reasoning effort reducing accuracy in the majority of
runs. Third, we use LLM-aided log inspection to uncover previously unreported
behaviors, such as searching for the benchmark on HuggingFace instead of
solving a task, or misusing credit cards in flight booking tasks. We share all
agent logs, comprising 2.5B tokens of language model calls, to incentivize
further research into agent behavior. By standardizing how the field evaluates
agents and addressing common pitfalls in agent evaluation, we hope to shift the
focus from agents that ace benchmarks to agents that work reliably in the real
world.

</details>


### [32] [CGBench: Benchmarking Language Model Scientific Reasoning for Clinical Genetics Research](https://arxiv.org/abs/2510.11985)
*Owen Queen,Harrison G. Zhang,James Zou*

Main category: cs.AI

TL;DR: CGBench是一个用于评估语言模型在科学文献解释能力的基准测试，基于临床遗传学专家标注数据构建，测试模型在提取实验结果、评估证据强度、分类实验成果等方面的表现。


<details>
  <summary>Details</summary>
Motivation: 传统变异和基因解释方法耗时耗力，生成式语言模型可以加速这一过程，但现有基准测试任务过于狭窄，无法反映真实研究需求。

Method: 从ClinGen专家标注的临床遗传学文献中构建CGBench基准，测试8种不同语言模型在三个关键任务上的表现：精确提取实验结果、判断证据强度、分类和描述实验成果。

Result: 模型在文献解释方面表现出潜力但存在明显差距，推理模型在细粒度任务上表现更好，非推理模型在高层次解释上更优。模型经常产生幻觉或误解结果，即使正确分类证据时也是如此。

Conclusion: CGBench揭示了语言模型在科学文献精确解释方面的优势和局限，为AI在临床遗传学和更广泛科学领域的未来研究开辟了道路。

Abstract: Variant and gene interpretation are fundamental to personalized medicine and
translational biomedicine. However, traditional approaches are manual and
labor-intensive. Generative language models (LMs) can facilitate this process,
accelerating the translation of fundamental research into clinically-actionable
insights. While existing benchmarks have attempted to quantify the capabilities
of LMs for interpreting scientific data, these studies focus on narrow tasks
that do not translate to real-world research. To meet these challenges, we
introduce CGBench, a robust benchmark that tests reasoning capabilities of LMs
on scientific publications. CGBench is built from ClinGen, a resource of
expert-curated literature interpretations in clinical genetics. CGBench
measures the ability to 1) extract relevant experimental results following
precise protocols and guidelines, 2) judge the strength of evidence, and 3)
categorize and describe the relevant outcome of experiments. We test 8
different LMs and find that while models show promise, substantial gaps exist
in literature interpretation, especially on fine-grained instructions.
Reasoning models excel in fine-grained tasks but non-reasoning models are
better at high-level interpretations. Finally, we measure LM explanations
against human explanations with an LM judge approach, revealing that models
often hallucinate or misinterpret results even when correctly classifying
evidence. CGBench reveals strengths and weaknesses of LMs for precise
interpretation of scientific publications, opening avenues for future research
in AI for clinical genetics and science more broadly.

</details>


### [33] [Asking Clarifying Questions for Preference Elicitation With Large Language Models](https://arxiv.org/abs/2510.12015)
*Ali Montazeralghaem,Guy Tennenholtz,Craig Boutilier,Ofer Meshi*

Main category: cs.AI

TL;DR: 提出一种基于扩散模型思想的两阶段方法，训练LLMs生成有效的顺序澄清问题来揭示用户偏好，显著提升了提问能力和偏好获取效果。


<details>
  <summary>Details</summary>
Motivation: 在用户历史有限的情况下，个性化LLM响应需要有效获取用户偏好，而生成跨领域的顺序澄清问题仍具挑战。

Method: 采用两阶段过程：前向过程从用户档案生成澄清问题并逐步移除答案作为"噪声"；反向过程训练模型通过提问"去噪"用户档案。

Result: 该方法显著提高了LLM提出漏斗式问题和有效获取用户偏好的能力。

Conclusion: 基于扩散模型思想的训练方法能有效提升LLMs在生成顺序澄清问题和获取用户偏好方面的表现。

Abstract: Large Language Models (LLMs) have made it possible for recommendation systems
to interact with users in open-ended conversational interfaces. In order to
personalize LLM responses, it is crucial to elicit user preferences, especially
when there is limited user history. One way to get more information is to
present clarifying questions to the user. However, generating effective
sequential clarifying questions across various domains remains a challenge. To
address this, we introduce a novel approach for training LLMs to ask sequential
questions that reveal user preferences. Our method follows a two-stage process
inspired by diffusion models. Starting from a user profile, the forward process
generates clarifying questions to obtain answers and then removes those answers
step by step, serving as a way to add ``noise'' to the user profile. The
reverse process involves training a model to ``denoise'' the user profile by
learning to ask effective clarifying questions. Our results show that our
method significantly improves the LLM's proficiency in asking funnel questions
and eliciting user preferences effectively.

</details>


### [34] [CausalTrace: A Neurosymbolic Causal Analysis Agent for Smart Manufacturing](https://arxiv.org/abs/2510.12033)
*Chathurangi Shyalika,Aryaman Sharma,Fadi El Kalach,Utkarshani Jaimini,Cory Henson,Ramy Harik,Amit Sheth*

Main category: cs.AI

TL;DR: CausalTrace是一个集成到工业CoPilot中的神经符号因果分析模块，通过数据驱动因果分析和工业知识图谱，提供因果发现、反事实推理和根本原因分析等功能，实现透明可解释的决策支持。


<details>
  <summary>Details</summary>
Motivation: 现代制造环境需要准确预测和可解释的异常分析，现有AI系统作为孤立黑盒缺乏预测、解释和因果推理的集成，限制了在高风险工业环境中的可信度和实用性。

Method: 开发CausalTrace神经符号因果分析模块，集成数据驱动因果分析和工业本体知识图谱，支持因果发现、反事实推理和根本原因分析，实现实时操作员交互。

Result: 在火箭组装测试中，与领域专家达成高度一致（ROUGE-1: 0.91），RCA性能优异（MAP@3: 94%, PR@2: 97%, MRR: 0.92, Jaccard: 0.92），C3AN评估得分4.59/5。

Conclusion: CausalTrace通过神经符号因果分析为工业环境提供了透明可解释的决策支持，在准确性和可靠性方面表现出色，适合实际部署。

Abstract: Modern manufacturing environments demand not only accurate predictions but
also interpretable insights to process anomalies, root causes, and potential
interventions. Existing AI systems often function as isolated black boxes,
lacking the seamless integration of prediction, explanation, and causal
reasoning required for a unified decision-support solution. This fragmentation
limits their trustworthiness and practical utility in high-stakes industrial
environments. In this work, we present CausalTrace, a neurosymbolic causal
analysis module integrated into the SmartPilot industrial CoPilot. CausalTrace
performs data-driven causal analysis enriched by industrial ontologies and
knowledge graphs, including advanced functions such as causal discovery,
counterfactual reasoning, and root cause analysis (RCA). It supports real-time
operator interaction and is designed to complement existing agents by offering
transparent, explainable decision support. We conducted a comprehensive
evaluation of CausalTrace using multiple causal assessment methods and the C3AN
framework (i.e. Custom, Compact, Composite AI with Neurosymbolic Integration),
which spans principles of robustness, intelligence, and trustworthiness. In an
academic rocket assembly testbed, CausalTrace achieved substantial agreement
with domain experts (ROUGE-1: 0.91 in ontology QA) and strong RCA performance
(MAP@3: 94%, PR@2: 97%, MRR: 0.92, Jaccard: 0.92). It also attained 4.59/5 in
the C3AN evaluation, demonstrating precision and reliability for live
deployment.

</details>


### [35] [Do Large Language Models Respect Contracts? Evaluating and Enforcing Contract-Adherence in Code Generation](https://arxiv.org/abs/2510.12047)
*Soohan Lim,Joonghyuk Hahn,Hyunwoo Park,Sang-Ki Ko,Yo-Sub Han*

Main category: cs.AI

TL;DR: PACT是一个评估LLM生成代码合约遵从性的框架，通过扩展HumanEval+和MBPP+基准，提供合约违反测试用例，并引入新指标来量化合约遵从性。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准主要评估功能正确性，但忽略了真实软件中合约遵从性这一关键方面，即如何处理不符合前提条件和约束的输入。

Method: PACT通过提供专注于合约违反的测试套件语料库，扩展现有基准，并系统分析不同提示条件下代码生成能力，特别是使用合约违反测试用例增强提示的效果。

Result: 分析表明，在提示中增加合约违反测试用例相比仅使用合约描述，能显著提升模型对合约的遵从能力。

Conclusion: PACT通过揭示传统基准忽略的关键错误，为评估LLM生成代码的功能性和合约遵从性提供了严格且可解释的指标。

Abstract: Prevailing code generation benchmarks, such as HumanEval+ and MBPP+,
primarily evaluate large language models (LLMs) with pass@k on functional
correctness using well-formed inputs. However, they ignore a crucial aspect of
real-world software: adherence to contracts-the preconditions and validity
constraints that dictate how ill-formed inputs must be rejected. This critical
oversight means that existing benchmarks fail to measure, and models
consequently fail to generate, truly robust and reliable code snippets. We
introduce PACT, a program assessment and contract-adherence evaluation
framework, to bridge this gap. PACT is the first framework designed to
systematically evaluate and enhance contract-adherence in LLM-generated code
snippets alongside functional correctness. PACT's contributions are threefold:
First, it provides a comprehensive test-suite corpus focused on contract
violations, extending HumanEval+ and MBPP+. Second, it enables a systematic
analysis of code generation under varied prompting conditions. This analysis
demonstrates that augmenting prompts with contract-violating test cases
significantly enhance a model's ability to respect contracts compared to using
contract description alone. Finally, it introduces novel metrics to rigorously
quantify contract adherence in both test generation and code generation. By
revealing critical errors that conventional benchmarks overlook, PACT provides
the rigorous and interpretable metrics to evaluate the robustness of
LLM-generated code snippets in both functionality and contract-adherence.Our
code and data are available at https://github.com/suhanmen/PACT.

</details>


### [36] [Empowering LLM Agents with Geospatial Awareness: Toward Grounded Reasoning for Wildfire Response](https://arxiv.org/abs/2510.12061)
*Yiheng Chen,Lingyao Li,Zihui Ma,Qikai Hu,Yilun Zhu,Min Deng,Runlong Yu*

Main category: cs.AI

TL;DR: 提出了一种地理空间感知层(GAL)，通过整合地理数据增强LLM在灾害响应中的能力，在真实野火场景中验证了有效性


<details>
  <summary>Details</summary>
Motivation: 现有统计方法缺乏语义上下文、跨事件泛化能力差且可解释性有限，LLM虽然具有少样本泛化能力但受限于文本且缺乏地理感知

Method: 引入GAL层，从原始野火检测出发，自动检索并整合基础设施、人口统计、地形和天气等地理数据，生成带单位标注的感知脚本

Result: 在多个LLM模型上评估真实野火场景，显示地理空间接地的智能体能够超越基线方法

Conclusion: 该框架能够推广到洪水、飓风等其他灾害类型，为灾害响应提供了基于证据的资源分配建议

Abstract: Effective disaster response is essential for safeguarding lives and property.
Existing statistical approaches often lack semantic context, generalize poorly
across events, and offer limited interpretability. While Large language models
(LLMs) provide few-shot generalization, they remain text-bound and blind to
geography. To bridge this gap, we introduce a Geospatial Awareness Layer (GAL)
that grounds LLM agents in structured earth data. Starting from raw wildfire
detections, GAL automatically retrieves and integrates infrastructure,
demographic, terrain, and weather information from external geodatabases,
assembling them into a concise, unit-annotated perception script. This enriched
context enables agents to produce evidence-based resource-allocation
recommendations (e.g., personnel assignments, budget allocations), further
reinforced by historical analogs and daily change signals for incremental
updates. We evaluate the framework in real wildfire scenarios across multiple
LLM models, showing that geospatially grounded agents can outperform baselines.
The proposed framework can generalize to other hazards such as floods and
hurricanes.

</details>


### [37] [Inclusive Fitness as a Key Step Towards More Advanced Social Behaviors in Multi-Agent Reinforcement Learning Settings](https://arxiv.org/abs/2510.12555)
*Andries Rosseau,Raphaël Avalos,Ann Nowé*

Main category: cs.AI

TL;DR: 提出基于包容性适应度的多智能体强化学习框架，通过基因型分配和基因共享机制模拟自然选择过程，在囚徒困境网络游戏中验证了与汉密尔顿法则等生物学原理的一致性。


<details>
  <summary>Details</summary>
Motivation: 受自然选择中竞争与合作力量驱动智能进化的启发，旨在创建能够模拟生物进化过程中社会动态的多智能体系统，超越传统的二元团队结构。

Method: 为每个智能体分配基因型，基于包容性适应度设计奖励函数，允许基因共享，在囚徒困境网络游戏中研究社会动态。

Result: 实验结果与汉密尔顿法则等生物学原理一致，展示了基于基因相似性的合作谱系，能够产生独特的非团队型社会动态。

Conclusion: 基于包容性适应度的奖励机制为更先进战略和社会智能智能体的涌现提供了基础，有望产生类似于生物进化的多智能体自动课程。

Abstract: The competitive and cooperative forces of natural selection have driven the
evolution of intelligence for millions of years, culminating in nature's vast
biodiversity and the complexity of human minds. Inspired by this process, we
propose a novel multi-agent reinforcement learning framework where each agent
is assigned a genotype and where reward functions are modelled after the
concept of inclusive fitness. An agent's genetic material may be shared with
other agents, and our inclusive reward function naturally accounts for this. We
study the resulting social dynamics in two types of network games with
prisoner's dilemmas and find that our results align with well-established
principles from biology, such as Hamilton's rule. Furthermore, we outline how
this framework can extend to more open-ended environments with spatial and
temporal structure, finite resources, and evolving populations. We hypothesize
the emergence of an arms race of strategies, where each new strategy is a
gradual improvement over earlier adaptations of other agents, effectively
producing a multi-agent autocurriculum analogous to biological evolution. In
contrast to the binary team-based structures prevalent in earlier research, our
gene-based reward structure introduces a spectrum of cooperation ranging from
full adversity to full cooperativeness based on genetic similarity, enabling
unique non team-based social dynamics. For example, one agent having a mutual
cooperative relationship with two other agents, while the two other agents
behave adversarially towards each other. We argue that incorporating inclusive
fitness in agents provides a foundation for the emergence of more strategically
advanced and socially intelligent agents.

</details>


### [38] [ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization](https://arxiv.org/abs/2510.12063)
*Sunzhu Li,Zhiyu Lin,Shuling Yang,Jiale Zhao,Wei Chen*

Main category: cs.AI

TL;DR: ThinkPilot是一个无需训练即可自动优化大型推理模型推理过程的框架，通过进化过程生成think-prefixes来引导模型实现更优性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽然强大，但仍存在推理效率低下和目标不准确的问题。现有的免训练方法要么局限于僵化的启发式规则，要么只提供描述性但不可操作的分析。

Method: 使用进化过程生成think-prefixes，这些前缀指令在推理行为分类学的驱动下演化，引导模型朝着更优性能发展。

Result: ThinkPilot显著改善了准确性与推理长度的权衡，大幅提升了安全性（如将DeepSeek-R1-Distill-Qwen-32B的StrongREJECT分数从27.0%降至0.7），增强了指令跟随能力，并能与现有的基于训练的方法协同工作。

Conclusion: think-prefixes能够可靠地控制大型推理模型的推理行为，不同任务对特定行为分布有强烈偏好。通过自动识别和激发这些行为，ThinkPilot提供了一个可泛化的框架来使模型推理与任务需求对齐。

Abstract: Large Reasoning Models (LRMs) are powerful, but they still suffer from
inefficient and off-target reasoning. Currently, training-free methods are
limited to either rigid heuristics or descriptive, non-actionable analyses. In
this paper, we introduce ThinkPilot, a training-free framework that
automatically optimizes LRMs reasoning. It uses an evolutionary process to
generate think-prefixes, which are instructions that evolve driven by a
taxonomy of reasoning behaviors to guide models toward superior performance.
Extensive experiments demonstrate ThinkPilot's broad effectiveness: it
significantly improves the accuracy-length trade-off for efficient reasoning,
drastically improves safety (for example, cutting the StrongREJECT score of
DeepSeek-R1-Distill-Qwen-32B from 27.0% to 0.7), and enhances instruction
following. It also synergizes with existing training-based methods. Our
analysis reveals that think-prefixes can reliably control LRMs' reasoning
behaviors, and that different tasks have strong preferences for specific
behavioral distributions. By automatically identifying and eliciting these
behaviors, ThinkPilot provides a generalizable framework for aligning LRMs
reasoning with task demands. Data and code are available at
https://github.com/teqkilla/ThinkPilot

</details>


### [39] [AI Agents as Universal Task Solvers](https://arxiv.org/abs/2510.12066)
*Alessandro Achille,Stefano Soatto*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: AI reasoning agents are already able to solve a variety of tasks by deploying
tools, simulating outcomes of multiple hypotheses and reflecting on them. In
doing so, they perform computation, although not in the classical sense --
there is no program being executed. Still, if they perform computation, can AI
agents be universal? Can chain-of-thought reasoning solve any computable task?
How does an AI Agent learn to reason? Is it a matter of model size? Or training
dataset size?
  In this work, we reinterpret the role of learning in the context of AI
Agents, viewing them as compute-capable stochastic dynamical systems, and
highlight the role of time in a foundational principle for learning to reason.
In doing so, we propose a shift from classical inductive learning to
transductive learning -- where the objective is not to approximate the
distribution of past data, but to capture their algorithmic structure to reduce
the time needed to find solutions to new tasks.
  Transductive learning suggests that, counter to Shannon's theory, a key role
of information in learning is about reduction of time rather than
reconstruction error. In particular, we show that the optimal speed-up that a
universal solver can achieve using past data is tightly related to their
algorithmic information. Using this, we show a theoretical derivation for the
observed power-law scaling of inference time versus training time. We then show
that scaling model size can lead to behaviors that, while improving accuracy on
benchmarks, fail any reasonable test of intelligence, let alone
super-intelligence: In the limit of infinite space and time, large models can
behave as savants, able to brute-force through any task without any insight.
Instead, we argue that the key quantity to optimize when scaling reasoning
models is time, whose critical role in learning has so far only been indirectly
considered.

</details>


### [40] [HiCoTraj:Zero-Shot Demographic Reasoning via Hierarchical Chain-of-Thought Prompting from Trajectory](https://arxiv.org/abs/2510.12067)
*Junyi Xie,Yuankun Jiao,Jina Kim,Yao-Yi Chiang,Lingyi Zhao,Khurram Shafique*

Main category: cs.AI

TL;DR: HiCoTraj是一个基于大语言模型的零样本人口属性推理框架，通过分层思维链提示从轨迹数据中推断年龄、性别、收入等人口属性，无需标注训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于移动轨迹的人口属性推断方法依赖大规模标注数据、可解释性差、跨数据集泛化能力弱的问题。

Method: 将轨迹转化为语义丰富的自然语言表示（详细活动记录和多尺度访问摘要），使用分层思维链推理（事实特征提取、行为模式分析、结构化输出的人口属性推断）来指导大语言模型。

Result: 在真实世界轨迹数据上的实验表明，HiCoTraj在零样本场景下对多个人口属性实现了有竞争力的性能。

Conclusion: HiCoTraj解决了标注人口数据稀缺的问题，同时提供了透明的推理链，为人口属性推断提供了新的解决方案。

Abstract: Inferring demographic attributes such as age, sex, or income level from human
mobility patterns enables critical applications such as targeted public health
interventions, equitable urban planning, and personalized transportation
services. Existing mobility-based demographic inference studies heavily rely on
large-scale trajectory data with demographic labels, leading to limited
interpretability and poor generalizability across different datasets and user
groups. We propose HiCoTraj (Zero-Shot Demographic Reasoning via Hierarchical
Chain-of-Thought Prompting from Trajectory), a framework that leverages LLMs'
zero-shot learning and semantic understanding capabilities to perform
demographic inference without labeled training data. HiCoTraj transforms
trajectories into semantically rich, natural language representations by
creating detailed activity chronicles and multi-scale visiting summaries. Then
HiCoTraj uses a novel hierarchical chain of thought reasoning to systematically
guide LLMs through three cognitive stages: factual feature extraction,
behavioral pattern analysis, and demographic inference with structured output.
This approach addresses the scarcity challenge of labeled demographic data
while providing transparent reasoning chains. Experimental evaluation on
real-world trajectory data demonstrates that HiCoTraj achieves competitive
performance across multiple demographic attributes in zero-shot scenarios.

</details>


### [41] [EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making](https://arxiv.org/abs/2510.12072)
*Zixing Lei,Sheng Yin,Yichen Xiong,Yuanzhuo Ding,Wenhao Huang,Yuxi Wei,Qingyao Xu,Yiming Li,Weixin Li,Yunhong Wang,Siheng Chen*

Main category: cs.AI

TL;DR: EmboMatrix是首个为LLM提供真实物理环境交互的训练平台，通过大规模任务模拟和精确奖励机制，成功训练出在具身决策任务上超越大型模型的EmboBrain-7B模型。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在纯语言训练下缺乏物理环境暴露的问题，使其获得真正的具身决策能力，实现通用具身智能。

Method: 构建EmboMatrix训练平台，包含多智能体数据引擎生成大规模任务场景、分布式异构硬件系统实现可扩展模拟、多级奖励架构提供精确监督。

Result: EmboBrain-7B在具身决策基准测试中超越671B的DeepSeek-R1基线9.5%，证明了交互式环境学习的力量。

Conclusion: 通过环境交互训练能够有效培养LLM的具身决策能力，EmboMatrix为构建真正智能的具身代理提供了可行的技术路径。

Abstract: Embodied decision-making enables agents to translate high-level goals into
executable actions through continuous interactions within the physical world,
forming a cornerstone of general-purpose embodied intelligence. Large language
models (LLMs), with their general decision-making capabilities, offer a
promising path to realize this potential; however, LLMs trained solely on
language lack exposure to physical environments, limiting their true embodied
understanding. To bridge this gap, we propose the concept of a training ground:
a comprehensive infrastructure that provides task and scene simulation,
embodied interaction, and feedback signals, offering a one-stop solution for
LLM acquire genuine embodied decision-making skills. In this work, we present
EmboMatrix, the first training ground of its kind, providing massive and
diverse tasks with efficient simulation and precise rewards. EmboMatrix
incorporates a series of novel techniques: a multi-agent data engine for
large-scale task and scene generation, a distributed heterogeneous-hardware
system for scalable simulation, and a multi-level reward architecture for
precise supervision. Leveraging EmboMatrix, we cultivate EmboBrain, an LLM
whose embodied decision-making abilities emerge from extensive embodied
interactions. Experiments show that EmboBrain-7B surpasses the 671B DeepSeek-R1
baseline by 9.5\% on two challenging embodied decision-making benchmarks,
demonstrating the power of interactive, environment-grounded learning for
building truly intelligent embodied agents.

</details>


### [42] [BeSTAD: Behavior-Aware Spatio-Temporal Anomaly Detection for Human Mobility Data](https://arxiv.org/abs/2510.12076)
*Junyi Xie,Jina Kim,Yao-Yi Chiang,Lingyi Zhao,Khurram Shafique*

Main category: cs.AI

TL;DR: BeSTAD是一个无监督框架，通过联合建模空间上下文和时间动态来检测人类移动数据中的个体级异常，能够在大规模人群中捕捉个性化行为特征并发现细粒度异常。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测主要关注轨迹级分析，但在大规模数据集中检测个体相对于自身历史模式的异常行为仍具挑战性。

Method: 学习语义丰富的移动表示，整合位置意义和时间模式；采用行为聚类感知建模机制，从正常活动构建个性化行为档案，并通过跨时期行为比较识别异常。

Result: 能够检测行为转变和常规偏离，并在大规模移动数据集中识别表现出此类变化的个体。

Conclusion: BeSTAD通过直接从无标签数据学习个体行为，将异常检测推向个性化和可解释的移动分析。

Abstract: Traditional anomaly detection in human mobility has primarily focused on
trajectory-level analysis, identifying statistical outliers or spatiotemporal
inconsistencies across aggregated movement traces. However, detecting
individual-level anomalies, i.e., unusual deviations in a person's mobility
behavior relative to their own historical patterns, within datasets
encompassing large populations remains a significant challenge. In this paper,
we present BeSTAD (Behavior-aware Spatio-Temporal Anomaly Detection for Human
Mobility Data), an unsupervised framework that captures individualized
behavioral signatures across large populations and uncovers fine-grained
anomalies by jointly modeling spatial context and temporal dynamics. BeSTAD
learns semantically enriched mobility representations that integrate location
meaning and temporal patterns, enabling the detection of subtle deviations in
individual movement behavior. BeSTAD further employs a behavior-cluster-aware
modeling mechanism that builds personalized behavioral profiles from normal
activity and identifies anomalies through cross-period behavioral comparison
with consistent semantic alignment. Building on prior work in mobility behavior
clustering, this approach enables not only the detection of behavioral shifts
and deviations from established routines but also the identification of
individuals exhibiting such changes within large-scale mobility datasets. By
learning individual behaviors directly from unlabeled data, BeSTAD advances
anomaly detection toward personalized and interpretable mobility analysis.

</details>


### [43] [Evaluating the Quality of Randomness and Entropy in Tasks Supported by Large Language Models](https://arxiv.org/abs/2510.12080)
*Rabimba Karanjai,Yang Lu,Ranjith Chodavarapu,Lei Xu,Weidong Shi*

Main category: cs.AI

TL;DR: 该论文研究了大语言模型处理随机性任务的能力，发现虽然LLM能生成具有一定随机性的输出，但表现不一致且与预期行为存在显著偏差。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型技术的快速发展，许多应用需要随机性（如随机决策、游戏、调度等），但LLM处理随机性的能力尚不明确。

Method: 设计了一系列实验，考虑外部工具可访问性、任务类型、模型状态（新鲜vs非新鲜）和提示策略等因素，涵盖生成随机数、随机字符串、洗牌和随机性质量评估等任务。

Result: LLM生成的输出虽然具有一定随机性，但表现不稳定，且与预期行为存在显著偏差。

Conclusion: LLM在处理涉及随机性的任务时存在关键局限性，需要改进才能有效处理这类任务。

Abstract: The rapid advancement of large language model (LLM) technology has led to
diverse applications, many of which inherently require randomness, such as
stochastic decision-making, gaming, scheduling, AI agents, and
cryptography-related tasks. However, the capabilities of LLMs in handling
randomness, particularly in generating and utilizing random numbers
effectively, remain unclear. This paper investigates the capacity of LLMs for
handling tasks that involve randomness through a series of experiments. We
designed a set of experiments that consider various factors that can influence
an LLM's performance in tasks involving randomness, such as accessibility to
external tools, types of tasks, model states (fresh vs. non-fresh), and
prompting strategies. The experiments cover a range of tasks, including
generating random numbers, generating random strings such as passwords,
shuffling items, and evaluating the quality of randomness using entropy and the
NIST randomness test-suite. Our findings reveal that while LLMs can generate
outputs that exhibit some degree of randomness, their performance is
inconsistent and often deviates significantly from the expected behavior. The
analysis of the experimental results highlights key limitations and areas where
improvement is needed for the LLMs to effectively handle tasks involving
randomness

</details>


### [44] [One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration](https://arxiv.org/abs/2510.12088)
*Zaid Khan,Archiki Prasad,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal*

Main category: cs.AI

TL;DR: OneLife框架通过条件激活的程序化法则在概率编程框架中建模世界动态，能够在复杂随机环境中从有限的无人指导交互中学习关键环境动态。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂、随机环境中，代理只有"一次生命"探索敌对环境且无人指导的挑战性场景下的符号世界建模问题。

Method: 使用条件激活的程序化法则，每个法则通过前提-效果结构在相关世界状态中激活，创建动态计算图，仅通过相关法则路由推理和优化。

Result: 在Crafter-OO环境中测试，OneLife在23个测试场景中的16个上优于强基线，能够从最少、无指导的交互中成功学习关键环境动态。

Conclusion: 为自主构建未知复杂环境的程序化世界模型奠定了基础。

Abstract: Symbolic world modeling requires inferring and representing an environment's
transitional dynamics as an executable program. Prior work has focused on
largely deterministic environments with abundant interaction data, simple
mechanics, and human guidance. We address a more realistic and challenging
setting, learning in a complex, stochastic environment where the agent has only
"one life" to explore a hostile environment without human guidance. We
introduce OneLife, a framework that models world dynamics through
conditionally-activated programmatic laws within a probabilistic programming
framework. Each law operates through a precondition-effect structure,
activating in relevant world states. This creates a dynamic computation graph
that routes inference and optimization only through relevant laws, avoiding
scaling challenges when all laws contribute to predictions about a complex,
hierarchical state, and enabling the learning of stochastic dynamics even with
sparse rule activation. To evaluate our approach under these demanding
constraints, we introduce a new evaluation protocol that measures (a) state
ranking, the ability to distinguish plausible future states from implausible
ones, and (b) state fidelity, the ability to generate future states that
closely resemble reality. We develop and evaluate our framework on Crafter-OO,
our reimplementation of the Crafter environment that exposes a structured,
object-oriented symbolic state and a pure transition function that operates on
that state alone. OneLife can successfully learn key environment dynamics from
minimal, unguided interaction, outperforming a strong baseline on 16 out of 23
scenarios tested. We also test OneLife's planning ability, with simulated
rollouts successfully identifying superior strategies. Our work establishes a
foundation for autonomously constructing programmatic world models of unknown,
complex environments.

</details>


### [45] [ToPolyAgent: AI Agents for Coarse-Grained Topological Polymer Simulations](https://arxiv.org/abs/2510.12091)
*Lijie Ding,Jan-Michael Carrillo,Changwoo Do*

Main category: cs.AI

TL;DR: ToPolyAgent是一个多智能体AI框架，通过自然语言指令执行拓扑聚合物的粗粒度分子动力学模拟。它集成了大语言模型和领域特定计算工具，支持线形、环形、刷状、星形聚合物及树枝状聚合物的交互式和自主模拟工作流。


<details>
  <summary>Details</summary>
Motivation: 降低复杂计算工作流的门槛，推动聚合物科学中AI驱动的材料发现，为自主可扩展的多智能体科学研究生态系统奠定基础。

Method: 系统包含四个LLM驱动的智能体：配置智能体生成初始聚合物-溶剂配置，模拟智能体执行LAMMPS分子动力学模拟和构象分析，报告智能体编译markdown报告，工作流智能体实现流线化自主操作。支持交互式（含用户反馈循环）和自主式两种模式。

Result: 通过案例研究展示了系统在不同聚合物架构、溶剂条件、恒温器和模拟时长下的多功能性。成功指导系统研究相互作用参数对线形聚合物构象的影响，以及接枝密度对刷状聚合物持续长度的影响。

Conclusion: 通过将自然语言界面与严格的模拟工具相结合，ToPolyAgent降低了复杂计算工作流的门槛，推动了聚合物科学中AI驱动的材料发现，为自主可扩展的多智能体科学研究生态系统奠定了基础。

Abstract: We introduce ToPolyAgent, a multi-agent AI framework for performing
coarse-grained molecular dynamics (MD) simulations of topological polymers
through natural language instructions. By integrating large language models
(LLMs) with domain-specific computational tools, ToPolyAgent supports both
interactive and autonomous simulation workflows across diverse polymer
architectures, including linear, ring, brush, and star polymers, as well as
dendrimers. The system consists of four LLM-powered agents: a Config Agent for
generating initial polymer-solvent configurations, a Simulation Agent for
executing LAMMPS-based MD simulations and conformational analyses, a Report
Agent for compiling markdown reports, and a Workflow Agent for streamlined
autonomous operations. Interactive mode incorporates user feedback loops for
iterative refinements, while autonomous mode enables end-to-end task execution
from detailed prompts. We demonstrate ToPolyAgent's versatility through case
studies involving diverse polymer architectures under varying solvent
condition, thermostats, and simulation lengths. Furthermore, we highlight its
potential as a research assistant by directing it to investigate the effect of
interaction parameters on the linear polymer conformation, and the influence of
grafting density on the persistence length of the brush polymer. By coupling
natural language interfaces with rigorous simulation tools, ToPolyAgent lowers
barriers to complex computational workflows and advances AI-driven materials
discovery in polymer science. It lays the foundation for autonomous and
extensible multi-agent scientific research ecosystems.

</details>


### [46] [Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing](https://arxiv.org/abs/2510.12121)
*Rongzhi Zhang,Liqin Ye,Yuzhao Heng,Xiang Chen,Tong Yu,Lingkai Kong,Sudheer Chava,Chao Zhang*

Main category: cs.AI

TL;DR: 提出了一种精确控制LLM输出属性强度的方法，通过目标达成问题重新定义、训练轻量级价值函数和基于梯度的隐藏表示干预，实现了对属性强度的细粒度连续控制。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐方法通常只能提供方向性或开放式指导，无法可靠地实现精确的属性强度控制，这限制了AI系统适应不同用户期望的能力。

Method: 1) 将精确属性强度控制重新定义为目标达成问题；2) 通过时序差分学习训练轻量级价值函数，从部分生成预测最终属性强度；3) 使用基于梯度的隐藏表示干预来精确导航模型达到特定属性强度目标。

Result: 在LLaMA-3.2-3b和Phi-4-mini上的实验证实了该方法能够以高精度引导文本生成达到用户指定的属性强度。

Conclusion: 该方法实现了对属性强度的细粒度连续控制，超越了简单的方向性对齐，并在偏好数据合成、帕累托前沿近似和优化以及对齐行为蒸馏等下游任务中展示了效率提升。

Abstract: Precise attribute intensity control--generating Large Language Model (LLM)
outputs with specific, user-defined attribute intensities--is crucial for AI
systems adaptable to diverse user expectations. Current LLM alignment methods,
however, typically provide only directional or open-ended guidance, failing to
reliably achieve exact attribute intensities. We address this limitation with
three key designs: (1) reformulating precise attribute intensity control as a
target-reaching problem, rather than simple maximization; (2) training a
lightweight value function via temporal-difference learning to predict final
attribute intensity scores from partial generations, thereby steering LLM
outputs; and (3) employing gradient-based interventions on hidden
representations to navigate the model precisely towards specific attribute
intensity targets. Our method enables fine-grained, continuous control over
attribute intensities, moving beyond simple directional alignment. Experiments
on LLaMA-3.2-3b and Phi-4-mini confirm our method's ability to steer text
generation to user-specified attribute intensities with high accuracy. Finally,
we demonstrate efficiency enhancements across three downstream tasks:
preference data synthesis, Pareto frontier approximation and optimization, and
distillation of aligned behaviors for intervention-free inference. Our code is
available on https://github.com/Pre-Control/pre-control

</details>


### [47] [MatSciBench: Benchmarking the Reasoning Ability of Large Language Models in Materials Science](https://arxiv.org/abs/2510.12171)
*Junkai Zhang,Jingru Gan,Xiaoxuan Wang,Zian Jia,Changquan Gu,Jianpeng Chen,Yanqiao Zhu,Mingyu Derek Ma,Dawei Zhou,Ling Li,Wei Wang*

Main category: cs.AI

TL;DR: MatSciBench是一个包含1340个大学水平材料科学问题的综合基准，涵盖6个主要领域和31个子领域，具有三级难度分类和多模态推理能力。评估显示即使是表现最好的模型在材料科学问题上准确率也低于80%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学推理方面表现出色，但在材料科学领域的推理能力尚未充分探索，需要建立专门的基准来评估和推动改进。

Method: 创建了MatSciBench基准，包含1340个结构化问题，采用三级难度分类，提供详细参考解决方案，并整合多模态推理。评估了多种推理策略：基础思维链、工具增强和自校正。

Result: 即使是表现最好的Gemini-2.5-Pro模型在材料科学问题上准确率也低于80%。不同推理策略在不同场景下表现不一，没有单一方法在所有情况下都表现优异。

Conclusion: MatSciBench为评估和提升LLMs在材料科学领域的科学推理能力建立了全面而坚实的基准，揭示了当前模型在该领域的局限性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable abilities in
scientific reasoning, yet their reasoning capabilities in materials science
remain underexplored. To fill this gap, we introduce MatSciBench, a
comprehensive college-level benchmark comprising 1,340 problems that span the
essential subdisciplines of materials science. MatSciBench features a
structured and fine-grained taxonomy that categorizes materials science
questions into 6 primary fields and 31 sub-fields, and includes a three-tier
difficulty classification based on the reasoning length required to solve each
question. MatSciBench provides detailed reference solutions enabling precise
error analysis and incorporates multimodal reasoning through visual contexts in
numerous questions. Evaluations of leading models reveal that even the
highest-performing model, Gemini-2.5-Pro, achieves under 80% accuracy on
college-level materials science questions, highlighting the complexity of
MatSciBench. Our systematic analysis of different reasoning strategie--basic
chain-of-thought, tool augmentation, and self-correction--demonstrates that no
single method consistently excels across all scenarios. We further analyze
performance by difficulty level, examine trade-offs between efficiency and
accuracy, highlight the challenges inherent in multimodal reasoning tasks,
analyze failure modes across LLMs and reasoning methods, and evaluate the
influence of retrieval-augmented generation. MatSciBench thus establishes a
comprehensive and solid benchmark for assessing and driving improvements in the
scientific reasoning capabilities of LLMs within the materials science domain.

</details>


### [48] [Evolution of meta's llama models and parameter-efficient fine-tuning of large language models: a survey](https://arxiv.org/abs/2510.12178)
*Abdulhady Abas Abdullah,Arkaitz Zubiaga,Seyedali Mirjalili,Amir H. Gandomi,Fatemeh Daneshfar,Mohammadsadra Amini,Alan Salam Mohammed,Hadi Veisi*

Main category: cs.AI

TL;DR: 本文综述了Meta AI的LLaMA系列模型（从LLaMA 1到LLaMA 4）的快速发展，以及为这些模型开发的参数高效微调（PEFT）方法，包括模型架构、性能特征和实际应用案例。


<details>
  <summary>Details</summary>
Motivation: 随着LLaMA系列模型的快速演进和广泛应用，需要系统梳理这些基础模型及其高效微调方法，为研究者和实践者提供一站式资源。

Method: 首先描述LLaMA系列基础模型（7B-65B到288B参数）及其架构，然后介绍PEFT概念，并详细回顾五种应用于LLaMA的PEFT方法：LoRA、LLaMA-Adapter V1和V2、LLaMA-Excitor、QLoRA。

Result: 提供了模型和适配器架构、参数数量和基准测试结果的结构化分析，展示了微调后LLaMA模型在某些情况下优于更大基线模型的实例，并探讨了在法律、医疗等领域的成功应用案例。

Conclusion: LLaMA模型和PEFT方法在实际应用中表现出色，但仍面临扩展到更大上下文和提升鲁棒性等挑战，为未来研究指明了方向。

Abstract: This review surveys the rapid evolution of Meta AI's LLaMA (Large Language
Model Meta AI) series - from LLaMA 1 through LLaMA 4 and the specialized
parameter-efficient fine-tuning (PEFT) methods developed for these models. We
first describe the LLaMA family of foundation models (7B-65B to 288B
parameters), their architectures (including native multimodal and
Mixtureof-Experts variants), and key performance characteristics. We then
describe and discuss the concept of PEFT, which adapts large pre-trained models
by updating only a small subset of parameters, and review five PEFT methods
that have been applied to LLaMA: LoRA (Low-Rank Adaptation), LLaMA-Adapter V1
and V2, LLaMA-Excitor, and QLoRA (Quantized LoRA). We discuss each method's
mechanism, parameter savings, and example application to LLaMA (e.g.,
instruction tuning, multimodal tasks). We provide structured discussion and
analysis of model and adapter architectures, parameter counts, and benchmark
results (including examples where fine-tuned LLaMA models outperform larger
baselines). Finally, we examine real-world use cases where LLaMA-based models
and PEFT have been successfully applied (e.g., legal and medical domains), and
we discuss ongoing challenges and future research directions (such as scaling
to even larger contexts and improving robustness). This survey paper provides a
one-stop resource for ML researchers and practitioners interested in LLaMA
models and efficient fine-tuning strategies.

</details>


### [49] [ResearStudio: A Human-Intervenable Framework for Building Controllable Deep-Research Agents](https://arxiv.org/abs/2510.12194)
*Linyi Yang,Yixuan Weng*

Main category: cs.AI

TL;DR: ResearStudio是一个开源框架，将实时人工控制置于核心，通过协作工作坊设计实现AI主导、人工辅助和人工主导、AI辅助模式之间的平滑切换。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理运行在'发射后不管'模式下，用户无法在执行过程中修复错误或添加专家知识。

Method: 采用分层规划器-执行器架构，将每个步骤写入实时'计划即文档'，通过快速通信层将每个动作、文件变更和工具调用流式传输到Web界面。

Result: 在完全自主模式下，ResearStudio在GAIA基准测试中达到最先进结果，超越了OpenAI的DeepResearch和Manus等系统。

Conclusion: 强大的自动化性能和细粒度人工控制可以共存，为安全可控的研究代理开发提供了新方向。

Abstract: Current deep-research agents run in a ''fire-and-forget'' mode: once started,
they give users no way to fix errors or add expert knowledge during execution.
We present ResearStudio, the first open-source framework that places real-time
human control at its core. The system follows a Collaborative Workshop design.
A hierarchical Planner-Executor writes every step to a live
''plan-as-document,'' a fast communication layer streams each action, file
change, and tool call to a web interface. At any moment, the user can pause the
run, edit the plan or code, run custom commands, and resume -- switching
smoothly between AI-led, human-assisted and human-led, AI-assisted modes. In
fully autonomous mode, ResearStudio achieves state-of-the-art results on the
GAIA benchmark, surpassing systems like OpenAI's DeepResearch and Manus. These
results show that strong automated performance and fine-grained human control
can coexist. The full code, protocol, and evaluation scripts are available at
https://github.com/ResearAI/ResearStudio. We will continue to update the
repository to encourage further work on safe and controllable research agents.
Our live demo is publicly accessible at http://ai-researcher.net:3000/. We
support the development of DeepScientist, which can be accessed at
https://github.com/ResearAI/DeepScientist.

</details>


### [50] [On the Design and Evaluation of Human-centered Explainable AI Systems: A Systematic Review and Taxonomy](https://arxiv.org/abs/2510.12201)
*Aline Mangold,Juliane Zietz,Susanne Weinhold,Sebastian Pannasch*

Main category: cs.AI

TL;DR: 这篇论文对65个评估可解释AI(XAI)系统的用户研究进行了全面综述，提出了以人为中心的XAI系统设计目标和评估框架，并针对不同AI专业水平的用户(新手和专家)提供了差异化的设计指南。


<details>
  <summary>Details</summary>
Motivation: 随着AI在日常生活中的普及，对既高性能又可理解的智能系统需求日益增长。目前XAI系统的评估过程过于技术化，未能充分关注人类用户的实际需求，因此需要开展以人为中心的用户研究来指导XAI系统的开发。

Method: 通过对65个XAI用户研究的全面综述，分析XAI系统特性和评估指标，提出了以人为中心的设计目标框架，并根据用户AI专业水平(AI新手和数据专家)进行差异化设计。

Result: 研究发现XAI系统由核心系统和解释组件共同构成；评估指标可分为对系统的情感、认知、可用性、可解释性和解释指标；针对AI新手的设计目标包括负责任使用、接受度和可用性，针对数据专家的设计目标则更注重性能导向，包括人机协作和系统任务性能。

Conclusion: 论文扩展了现有的XAI评估和设计框架，为XAI开发者提供了以人为中心的系统特性和评估指标的综合概述，以及针对不同用户群体的差异化设计目标，有助于开发更符合人类用户需求的XAI系统。

Abstract: As AI becomes more common in everyday living, there is an increasing demand
for intelligent systems that are both performant and understandable.
Explainable AI (XAI) systems aim to provide comprehensible explanations of
decisions and predictions. At present, however, evaluation processes are rather
technical and not sufficiently focused on the needs of human users.
Consequently, evaluation studies involving human users can serve as a valuable
guide for conducting user studies. This paper presents a comprehensive review
of 65 user studies evaluating XAI systems across different domains and
application contexts. As a guideline for XAI developers, we provide a holistic
overview of the properties of XAI systems and evaluation metrics focused on
human users (human-centered). We propose objectives for the human-centered
design (design goals) of XAI systems. To incorporate users' specific
characteristics, design goals are adapted to users with different levels of AI
expertise (AI novices and data experts). In this regard, we provide an
extension to existing XAI evaluation and design frameworks. The first part of
our results includes the analysis of XAI system characteristics. An important
finding is the distinction between the core system and the XAI explanation,
which together form the whole system. Further results include the distinction
of evaluation metrics into affection towards the system, cognition, usability,
interpretability, and explanation metrics. Furthermore, the users, along with
their specific characteristics and behavior, can be assessed. For AI novices,
the relevant extended design goals include responsible use, acceptance, and
usability. For data experts, the focus is performance-oriented and includes
human-AI collaboration and system and user task performance.

</details>


### [51] [GOAT: A Training Framework for Goal-Oriented Agent with Tools](https://arxiv.org/abs/2510.12218)
*Hyunji Min,Sangwon Jung,Junyoung Sung,Dosung Lee,Leekyeung Han,Paul Hongsuck Seo*

Main category: cs.AI

TL;DR: GOAT是一个无需人工标注的训练框架，能够从API文档自动构建合成数据集，用于微调LLM代理以处理目标导向的API执行任务。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在处理需要分解高级目标为多个相互依赖API调用的目标导向查询时能力有限，且缺乏训练数据，开源模型表现不佳。

Method: 提出GOAT框架，从API文档自动生成合成数据集，训练LLM代理进行推理和连贯响应生成。

Result: GOAT训练的代理在多个现有目标导向基准测试中达到最先进性能，并在新基准GOATBench上也表现出色。

Conclusion: GOAT为构建能够进行复杂推理和工具使用的稳健开源LLM代理提供了实用路径。

Abstract: Large language models (LLMs) have recently been extended beyond traditional
text generation to serve as interactive agents capable of using external tools
based on user intent. However, current LLM agents still show limited ability to
handle goal-oriented queries, which require decomposing a high-level objective
into multiple interdependent API calls with correct planning and execution.
Current approaches mainly rely on zero-shot evaluation due to the absence of
training data. While proprietary closed-source models such as GPT-4 demonstrate
strong reasoning abilities, smaller open-source models struggle to perform
complex tool use effectively. Thus, we propose a novel training framework GOAT,
which enables fine-tuning of LLM agents in a human annotation-free setting.
GOAT automatically constructs synthetic datasets of goal-oriented API execution
tasks directly from given API documents, equipping models with the ability to
reason over interdependent calls and generate coherent responses. Through
extensive experiments, we show that GOAT-trained agents achieve
state-of-the-art performance across multiple existing goal-oriented benchmarks.
In addition, we introduce GOATBench, a new goal-oriented API execution
benchmark, and demonstrate that agents trained with GOAT also excel in this
setting. These results highlight GOAT as a practical path toward building
robust open-source LLM agents capable of complex reasoning and tool use.

</details>


### [52] [MedKGEval: A Knowledge Graph-Based Multi-Turn Evaluation Framework for Open-Ended Patient Interactions with Clinical LLMs](https://arxiv.org/abs/2510.12224)
*Yuechun Yu,Han Ying,Haoan Jin,Wenjian Jiang,Dong Xian,Binghao Wang,Zhou Yang,Mengyue Wu*

Main category: cs.AI

TL;DR: 提出了MedKGEval框架，这是一个基于结构化医学知识的多轮临床LLM评估方法，通过知识图谱驱动的患者模拟和实时评估来改进医疗对话系统的评估。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型医学评估方法主要依赖对话转录的事后审查，忽略了医疗对话的动态性和患者不断变化的信息需求，无法捕捉真实临床环境中复杂的医患多轮互动。

Method: 1. 知识图谱驱动的患者模拟机制，从精心构建的知识图谱中检索相关医学事实；2. 实时轮级评估框架，由法官代理在对话过程中评估每个模型响应的临床适当性、事实准确性和安全性；3. 构建包含8个最先进LLM的全面多轮基准测试。

Result: MedKGEval能够识别传统评估流程经常忽略的细微行为缺陷和安全风险，展示了其在医疗LLM评估中的有效性。

Conclusion: 该框架虽然最初设计用于中英文医疗应用，但通过切换输入知识图谱可以轻松扩展到其他语言，确保无缝的双语支持和领域特定适用性。

Abstract: The reliable evaluation of large language models (LLMs) in medical
applications remains an open challenge, particularly in capturing the
complexity of multi-turn doctor-patient interactions that unfold in real
clinical environments. Existing evaluation methods typically rely on post hoc
review of full conversation transcripts, thereby neglecting the dynamic,
context-sensitive nature of medical dialogues and the evolving informational
needs of patients. In this work, we present MedKGEval, a novel multi-turn
evaluation framework for clinical LLMs grounded in structured medical
knowledge. Our approach introduces three key contributions: (1) a knowledge
graph-driven patient simulation mechanism, where a dedicated control module
retrieves relevant medical facts from a curated knowledge graph, thereby
endowing the patient agent with human-like and realistic conversational
behavior. This knowledge graph is constructed by integrating open-source
resources with additional triples extracted from expert-annotated datasets; (2)
an in-situ, turn-level evaluation framework, where each model response is
assessed by a Judge Agent for clinical appropriateness, factual correctness,
and safety as the dialogue progresses using a suite of fine-grained,
task-specific metrics; (3) a comprehensive multi-turn benchmark of eight
state-of-the-art LLMs, demonstrating MedKGEval's ability to identify subtle
behavioral flaws and safety risks that are often overlooked by conventional
evaluation pipelines. Although initially designed for Chinese and English
medical applications, our framework can be readily extended to additional
languages by switching the input knowledge graphs, ensuring seamless bilingual
support and domain-specific applicability.

</details>


### [53] [PromptFlow: Training Prompts Like Neural Networks](https://arxiv.org/abs/2510.12246)
*Jingyi Wang,Hongyuan Zhu,Ye Niu,Yunhui Deng*

Main category: cs.AI

TL;DR: 提出了PromptFlow框架，通过元学习自动优化提示工程，减少人工设计负担，并在多个数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在特定领域部署时手动提示设计费时费力、现有自动方法缺乏动态策略选择和细粒度编辑的问题。

Method: 提出模块化训练框架PromptFlow，集成元提示、操作符、优化器和评估器，采用基于梯度的元学习和强化学习来回收经验。

Result: 在多个数据集上的实验表明，PromptFlow能够有效优化提示工程，提升模型性能。

Conclusion: PromptFlow为自动提示工程提供了高效灵活的解决方案，能够适应不同NLP任务需求，减少对专业知识和大量训练数据的依赖。

Abstract: Large Language Models (LLMs) have demonstrated profound impact on Natural
Language Processing (NLP) tasks. However, their effective deployment across
diverse domains often require domain-specific adaptation strategies, as generic
models may underperform when faced with specialized data distributions. Recent
advances in prompt engineering (PE) offer a promising alternative to extensive
retraining by refining input instructions to align LLM outputs with task
objectives. This paradigm has emerged as a rapid and versatile approach for
model fine-tuning. Despite its potential, manual prompt design remains
labor-intensive and heavily depends on specialized expertise, often requiring
iterative human effort to achieve optimal formulations. To address this
limitation, automated prompt engineering methodologies have been developed to
systematically generate task-specific prompts. However, current implementations
predominantly employ static update rules and lack mechanisms for dynamic
strategy selection, resulting in suboptimal adaptation to varying NLP task
requirements. Furthermore, most methods treat and update the whole prompts at
each step, without considering editing prompt sections at a finer granularity.
At last, in particular, the problem of how to recycle experience in LLM is
still underexplored. To this end, we propose the PromptFlow, a modular training
framework inspired by TensorFlow, which integrates meta-prompts, operators,
optimization, and evaluator. Our framework can be equipped with the latest
optimization methods and autonomously explores optimal prompt refinement
trajectories through gradient-based meta-learning, requiring minimal
task-specific training data. Specifically, we devise a reinforcement learning
method to recycle experience for LLM in the PE process. Finally, we conduct
extensive experiments on various datasets, and demonstrate the effectiveness of
PromptFlow.

</details>


### [54] [$\mathbf{T^3}$: Reducing Belief Deviation in Reinforcement Learning for Active Reasoning](https://arxiv.org/abs/2510.12264)
*Deyu Zou,Yongqiang Chen,Jianxiang Wang,Haochen Yang,Mufei Li,James Cheng,Pan Li,Yu Gong*

Main category: cs.AI

TL;DR: 提出T³方法，通过检测信念偏差并截断训练轨迹，解决LLM智能体在主动推理中的信念偏差问题，提升策略优化效果。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在主动推理中容易产生信念偏差，导致无法正确建模信念、丢失问题状态跟踪，陷入无信息或重复动作，影响强化学习训练效果。

Method: 开发T³方法，跟踪模型信念偏差，检测过度偏差并在训练时截断轨迹，移除无信息尾部，保留信息前缀的信用分配。

Result: 在5个挑战性任务中，T³持续提升训练稳定性、令牌效率和最终性能，获得高达30%的性能增益，同时减少约25%的令牌使用。

Conclusion: 信念控制是开发稳健且可泛化的基于LLM的主动推理器的关键原则。

Abstract: Active reasoning requires large language models (LLMs) to interact with
external sources and strategically gather information to solve problems.
Central to this process is belief tracking: maintaining a coherent
understanding of the problem state and the missing information toward the
solution. However, due to limited reasoning capabilities, LLM-based agents
often suffer from belief deviation: they struggle to correctly model beliefs,
lose track of problem states, and fall into uninformative or repetitive
actions. Once this happens, errors compound and reinforcement learning (RL)
training fails to properly credit the crucial exploratory steps. To address
this issue, we propose to track the deviation of model beliefs and develop
$\mathbf{T^3}$, a simple yet effective method that detects excessive belief
deviation and truncates trajectories during training to remove uninformative
tails. By preserving credit for informative prefixes, $\mathbf{T^3}$
systematically improves policy optimization. Across 5 challenging tasks,
$\mathbf{T^3}$ consistently enhances training stability, token efficiency, and
final performance, achieving up to 30% gains while cutting rollout tokens by
roughly 25%. These results highlight belief control as a key principle for
developing robust and generalizable LLM-based active reasoners.

</details>


### [55] [Tensor Logic: The Language of AI](https://arxiv.org/abs/2510.12269)
*Pedro Domingos*

Main category: cs.AI

TL;DR: 提出张量逻辑语言，统一神经和符号AI，通过张量方程实现逻辑规则与爱因斯坦求和的统一，支持transformers、形式推理、核机器和概率图模型等AI方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI编程语言存在缺陷：PyTorch和TensorFlow缺乏自动推理和知识获取支持，而LISP和Prolog缺乏可扩展性和学习支持，阻碍AI发展。

Method: 设计张量逻辑语言，核心构造是张量方程，将逻辑规则和爱因斯坦求和视为相同操作，其他功能都可还原为此基础。

Result: 优雅实现了神经、符号和统计AI的关键形式，包括transformers、形式推理、核机器和概率图模型，并支持嵌入空间中的可靠推理。

Conclusion: 张量逻辑结合了神经网络的可扩展性和学习能力与符号推理的可靠性和透明度，为AI的广泛采用提供了潜在基础。

Abstract: Progress in AI is hindered by the lack of a programming language with all the
requisite features. Libraries like PyTorch and TensorFlow provide automatic
differentiation and efficient GPU implementation, but are additions to Python,
which was never intended for AI. Their lack of support for automated reasoning
and knowledge acquisition has led to a long and costly series of hacky attempts
to tack them on. On the other hand, AI languages like LISP an Prolog lack
scalability and support for learning. This paper proposes tensor logic, a
language that solves these problems by unifying neural and symbolic AI at a
fundamental level. The sole construct in tensor logic is the tensor equation,
based on the observation that logical rules and Einstein summation are
essentially the same operation, and all else can be reduced to them. I show how
to elegantly implement key forms of neural, symbolic and statistical AI in
tensor logic, including transformers, formal reasoning, kernel machines and
graphical models. Most importantly, tensor logic makes new directions possible,
such as sound reasoning in embedding space. This combines the scalability and
learnability of neural networks with the reliability and transparency of
symbolic reasoning, and is potentially a basis for the wider adoption of AI.

</details>


### [56] [RAG-Anything: All-in-One RAG Framework](https://arxiv.org/abs/2510.12323)
*Zirui Guo,Xubin Ren,Lingrui Xu,Jiahao Zhang,Chao Huang*

Main category: cs.AI

TL;DR: RAG-Anything是一个统一的多模态检索增强生成框架，能够处理文本、图像、表格和数学表达式等多种模态内容，解决了现有RAG系统仅限于文本处理的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统与真实世界信息环境存在严重不匹配，现实知识库本质上是多模态的，包含文本、视觉元素、结构化表格和数学表达式的丰富组合，但现有RAG框架仅限于文本内容，在处理多模态文档时存在根本性差距。

Method: 将多模态内容重新概念化为相互连接的知识实体而非孤立数据类型；引入双图构建来捕获跨模态关系和文本语义的统一表示；开发跨模态混合检索，结合结构知识导航和语义匹配。

Result: 在具有挑战性的多模态基准测试中表现出优越性能，相比最先进方法取得显著改进；在传统方法失败的长文档处理上性能提升尤为明显。

Conclusion: 该框架为多模态知识访问建立了新范式，消除了限制当前系统的架构碎片化问题。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a fundamental paradigm
for expanding Large Language Models beyond their static training limitations.
However, a critical misalignment exists between current RAG capabilities and
real-world information environments. Modern knowledge repositories are
inherently multimodal, containing rich combinations of textual content, visual
elements, structured tables, and mathematical expressions. Yet existing RAG
frameworks are limited to textual content, creating fundamental gaps when
processing multimodal documents. We present RAG-Anything, a unified framework
that enables comprehensive knowledge retrieval across all modalities. Our
approach reconceptualizes multimodal content as interconnected knowledge
entities rather than isolated data types. The framework introduces dual-graph
construction to capture both cross-modal relationships and textual semantics
within a unified representation. We develop cross-modal hybrid retrieval that
combines structural knowledge navigation with semantic matching. This enables
effective reasoning over heterogeneous content where relevant evidence spans
multiple modalities. RAG-Anything demonstrates superior performance on
challenging multimodal benchmarks, achieving significant improvements over
state-of-the-art methods. Performance gains become particularly pronounced on
long documents where traditional approaches fail. Our framework establishes a
new paradigm for multimodal knowledge access, eliminating the architectural
fragmentation that constrains current systems. Our framework is open-sourced
at: https://github.com/HKUDS/RAG-Anything.

</details>


### [57] [O-Forge: An LLM + Computer Algebra Framework for Asymptotic Analysis](https://arxiv.org/abs/2510.12350)
*Ayush Khaitan,Vijay Ganesh*

Main category: cs.AI

TL;DR: 提出LLM+CAS框架和O-Forge工具，将前沿LLM与计算机代数系统结合，通过符号反馈循环生成既具创造性又经过符号验证的证明，特别针对渐近不等式问题。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在数学研究中验证困难的问题，回答Terence Tao提出的关于LLM与验证器结合能否帮助证明复杂渐近不等式的问题，推动AI从竞赛数学向研究级数学工具发展。

Method: 使用LLM+CAS框架，通过上下文符号反馈循环：LLM建议域分解，CAS对每个部分进行公理化验证，形成LLM与CAS的协同工作模式。

Result: 该框架在提出适当域分解方面表现出显著效果，能够处理研究级的渐近分析问题，证明了AI在专业数学研究中的潜力。

Conclusion: LLM+CAS框架成功展示了AI如何超越竞赛数学，成为专业数学家的研究工具，为复杂渐近不等式的证明提供了有效解决方案。

Abstract: Large language models have recently demonstrated advanced capabilities in
solving IMO and Putnam problems; yet their role in research mathematics has
remained fairly limited. The key difficulty is verification: suggested proofs
may look plausible, but cannot be trusted without rigorous checking. We present
a framework, called LLM+CAS, and an associated tool, O-Forge, that couples
frontier LLMs with a computer algebra systems (CAS) in an In-Context Symbolic
Feedback loop to produce proofs that are both creative and symbolically
verified. Our focus is on asymptotic inequalities, a topic that often involves
difficult proofs and appropriate decomposition of the domain into the "right"
subdomains. Many mathematicians, including Terry Tao, have suggested that using
AI tools to find the right decompositions can be very useful for research-level
asymptotic analysis. In this paper, we show that our framework LLM+CAS turns
out to be remarkably effective at proposing such decompositions via a
combination of a frontier LLM and a CAS. More precisely, we use an LLM to
suggest domain decomposition, and a CAS (such as Mathematica) that provides a
verification of each piece axiomatically. Using this loop, we answer a question
posed by Terence Tao: whether LLMs coupled with a verifier can be used to help
prove intricate asymptotic inequalities. More broadly, we show how AI can move
beyond contest math towards research-level tools for professional
mathematicians.

</details>


### [58] [A Survey of Vibe Coding with Large Language Models](https://arxiv.org/abs/2510.12399)
*Yuyao Ge,Lingrui Mei,Zenghao Duan,Tianhao Li,Yujia Zheng,Yiwei Wang,Lexin Wang,Jiayu Yao,Tianyu Liu,Yujun Cai,Baolong Bi,Fangda Guo,Jiafeng Guo,Shenghua Liu,Xueqi Cheng*

Main category: cs.AI

TL;DR: 这篇论文对基于大语言模型的Vibe Coding范式进行了首次系统性综述，建立了理论框架并分析了五种开发模型，揭示了成功Vibe Coding的关键因素。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，从代码生成辅助转向自主编码代理，催生了"Vibe Coding"新方法，但该范式的有效性缺乏系统研究，实证显示存在生产力损失和协作挑战。

Method: 通过分析1000多篇研究论文，建立了约束马尔可夫决策过程理论框架，并综合现有实践归纳出五种开发模型：无约束自动化、迭代对话协作、规划驱动、测试驱动和上下文增强模型。

Result: 成功实现Vibe Coding不仅依赖代理能力，更需要系统上下文工程、完善的开发环境和人机协作开发模型。

Conclusion: Vibe Coding作为正式学科需要理论框架支撑，成功实施依赖于系统化的上下文工程、开发环境和协作模型，而非单纯依赖代理能力。

Abstract: The advancement of large language models (LLMs) has catalyzed a paradigm
shift from code generation assistance to autonomous coding agents, enabling a
novel development methodology termed "Vibe Coding" where developers validate
AI-generated implementations through outcome observation rather than
line-by-line code comprehension. Despite its transformative potential, the
effectiveness of this emergent paradigm remains under-explored, with empirical
evidence revealing unexpected productivity losses and fundamental challenges in
human-AI collaboration. To address this gap, this survey provides the first
comprehensive and systematic review of Vibe Coding with large language models,
establishing both theoretical foundations and practical frameworks for this
transformative development approach. Drawing from systematic analysis of over
1000 research papers, we survey the entire vibe coding ecosystem, examining
critical infrastructure components including LLMs for coding, LLM-based coding
agent, development environment of coding agent, and feedback mechanisms. We
first introduce Vibe Coding as a formal discipline by formalizing it through a
Constrained Markov Decision Process that captures the dynamic triadic
relationship among human developers, software projects, and coding agents.
Building upon this theoretical foundation, we then synthesize existing
practices into five distinct development models: Unconstrained Automation,
Iterative Conversational Collaboration, Planning-Driven, Test-Driven, and
Context-Enhanced Models, thus providing the first comprehensive taxonomy in
this domain. Critically, our analysis reveals that successful Vibe Coding
depends not merely on agent capabilities but on systematic context engineering,
well-established development environments, and human-agent collaborative
development models.

</details>


### [59] [PricingLogic: Evaluating LLMs Reasoning on Complex Tourism Pricing Tasks](https://arxiv.org/abs/2510.12409)
*Yunuo Liu,Dawei Zhu,Zena Al-Khalili,Dai Cheng,Yanjun Chen,Dietrich Klakow,Wei Zhang,Xiaoyu Shen*

Main category: cs.AI

TL;DR: PricingLogic是首个评估大语言模型在旅游定价场景中可靠性的基准测试，包含300个基于真实定价政策的问题，测试显示LLMs在复杂定价规则下存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 旅游机构希望将易出错的定价任务自动化给AI系统，但未经验证的LLM部署可能导致重大财务损失和客户信任危机。

Method: 构建包含300个自然语言问题的基准测试，基于42个真实定价政策，分为两个难度级别：基础客户类型定价和涉及交互折扣的捆绑旅游计算。

Result: 对一系列LLMs的评估显示，在更难层级上性能急剧下降，暴露了规则解释和算术推理的系统性失败。

Conclusion: 尽管具备通用能力，但当前LLMs在收入关键应用中仍不可靠，需要进一步的保障措施或领域适应。

Abstract: We present PricingLogic, the first benchmark that probes whether Large
Language Models(LLMs) can reliably automate tourism-related prices when
multiple, overlapping fare rules apply. Travel agencies are eager to offload
this error-prone task onto AI systems; however, deploying LLMs without verified
reliability could result in significant financial losses and erode customer
trust. PricingLogic comprises 300 natural-language questions based on booking
requests derived from 42 real-world pricing policies, spanning two levels of
difficulty: (i) basic customer-type pricing and (ii)bundled-tour calculations
involving interacting discounts. Evaluations of a line of LLMs reveal a steep
performance drop on the harder tier,exposing systematic failures in rule
interpretation and arithmetic reasoning.These results highlight that, despite
their general capabilities, today's LLMs remain unreliable in revenue-critical
applications without further safeguards or domain adaptation. Our code and
dataset are available at https://github.com/EIT-NLP/PricingLogic.

</details>


### [60] [MTOS: A LLM-Driven Multi-topic Opinion Simulation Framework for Exploring Echo Chamber Dynamics](https://arxiv.org/abs/2510.12423)
*Dingyi Zuo,Hongjie Zhang,Jie Ou,Chaosheng Feng,Shuwan Liu*

Main category: cs.AI

TL;DR: 提出了MTOS框架，将多主题上下文与LLM结合进行社会模拟，解决了现有研究在跨领域多主题认知转移方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现实网络中信息常涉及多个相关主题，现有基于LLM的研究多聚焦单一主题，传统数值模型则简化了复杂语言态度，缺乏解释性和多主题整合能力。

Method: MTOS框架结合LLM与短期/长期记忆，采用多种用户选择交互机制、动态主题选择策略和信念衰减机制，实现跨主题视角更新。

Result: 多主题设置显著改变极化趋势：正相关主题放大回音室效应，负相关主题抑制回音室，无关主题通过资源竞争缓解回音室效应。相比数值模型，LLM智能体能更真实模拟动态观点变化。

Conclusion: LLM智能体能够真实模拟动态观点变化，再现新闻文本的语言特征，捕捉复杂的人类推理，提高了模拟的解释性和系统稳定性。

Abstract: The polarization of opinions, information segregation, and cognitive biases
on social media have attracted significant academic attention. In real-world
networks, information often spans multiple interrelated topics, posing
challenges for opinion evolution and highlighting the need for frameworks that
simulate interactions among topics. Existing studies based on large language
models (LLMs) focus largely on single topics, limiting the capture of cognitive
transfer in multi-topic, cross-domain contexts. Traditional numerical models,
meanwhile, simplify complex linguistic attitudes into discrete values, lacking
interpretability, behavioral consistency, and the ability to integrate multiple
topics. To address these issues, we propose Multi-topic Opinion Simulation
(MTOS), a social simulation framework integrating multi-topic contexts with
LLMs. MTOS leverages LLMs alongside short-term and long-term memory,
incorporates multiple user-selection interaction mechanisms and dynamic
topic-selection strategies, and employs a belief decay mechanism to enable
perspective updates across topics. We conduct extensive experiments on MTOS,
varying topic numbers, correlation types, and performing ablation studies to
assess features such as group polarization and local consistency. Results show
that multi-topic settings significantly alter polarization trends: positively
correlated topics amplify echo chambers, negatively correlated topics inhibit
them, and irrelevant topics also mitigate echo chamber effects through resource
competition. Compared with numerical models, LLM-based agents realistically
simulate dynamic opinion changes, reproduce linguistic features of news texts,
and capture complex human reasoning, improving simulation interpretability and
system stability.

</details>


### [61] [Biased-Attention Guided Risk Prediction for Safe Decision-Making at Unsignalized Intersections](https://arxiv.org/abs/2510.12428)
*Chengyang Dong,Nan Guo*

Main category: cs.AI

TL;DR: 提出了一种基于深度强化学习和偏置注意力机制的无信号交叉口自动驾驶决策框架，通过风险预测器评估碰撞风险并转化为密集奖励信号，提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 无信号交叉口自动驾驶决策面临复杂动态交互和高冲突风险的挑战，需要实现主动安全控制。

Method: 基于Soft Actor-Critic算法，使用偏置注意力机制构建交通风险预测器，评估车辆进入交叉口的长期碰撞风险，并将其转化为密集奖励信号指导决策。

Result: 仿真结果表明该方法有效提高了交叉口的交通效率和车辆安全性。

Conclusion: 该智能决策框架在复杂场景中具有有效性，证明了基于风险预测的强化学习方法在自动驾驶决策中的优势。

Abstract: Autonomous driving decision-making at unsignalized intersections is highly
challenging due to complex dynamic interactions and high conflict risks. To
achieve proactive safety control, this paper proposes a deep reinforcement
learning (DRL) decision-making framework integrated with a biased attention
mechanism. The framework is built upon the Soft Actor-Critic (SAC) algorithm.
Its core innovation lies in the use of biased attention to construct a traffic
risk predictor. This predictor assesses the long-term risk of collision for a
vehicle entering the intersection and transforms this risk into a dense reward
signal to guide the SAC agent in making safe and efficient driving decisions.
Finally, the simulation results demonstrate that the proposed method
effectively improves both traffic efficiency and vehicle safety at the
intersection, thereby proving the effectiveness of the intelligent
decision-making framework in complex scenarios. The code of our work is
available at https://github.com/hank111525/SAC-RWB.

</details>


### [62] [Evaluating and Mitigating LLM-as-a-judge Bias in Communication Systems](https://arxiv.org/abs/2510.12462)
*Jiaxin Gao,Chen Chen,Yanwen Jia,Xueluan Gong,Kwok-Yan Lam,Qian Wang*

Main category: cs.AI

TL;DR: 本文系统研究了LLM作为评判者时的偏见问题，发现现有模型对偏见输入具有鲁棒性，但微调会显著降低性能，并提出四种缓解策略。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被广泛用于自主评估通信系统内容质量，其评判的公正性无法保证，偏见可能影响结果并损害用户信任。

Method: 在点式评分设置下系统调查两种LLM评判模型的11种偏见类型，包括隐性和显性形式，并分析微调、评分标准、任务难度等因素的影响。

Result: 最先进的LLM评判者对偏见输入具有鲁棒性，通常给予较低分数；提供详细评分标准能增强鲁棒性；微调会显著降低性能；评判分数与任务难度相关。

Conclusion: LLM评判者存在偏见风险，需要采取缓解策略来确保实际通信场景中AI评判的公平性和可靠性。

Abstract: Large Language Models (LLMs) are increasingly being used to autonomously
evaluate the quality of content in communication systems, e.g., to assess
responses in telecom customer support chatbots. However, the impartiality of
these AI "judges" is not guaranteed, and any biases in their evaluation
criteria could skew outcomes and undermine user trust. In this paper, we
systematically investigate judgment biases in two LLM-as-a-judge models (i.e.,
GPT-Judge and JudgeLM) under the point-wise scoring setting, encompassing 11
types of biases that cover both implicit and explicit forms. We observed that
state-of-the-art LLM judges demonstrate robustness to biased inputs, generally
assigning them lower scores than the corresponding clean samples. Providing a
detailed scoring rubric further enhances this robustness. We further found that
fine-tuning an LLM on high-scoring yet biased responses can significantly
degrade its performance, highlighting the risk of training on biased data. We
also discovered that the judged scores correlate with task difficulty: a
challenging dataset like GPQA yields lower average scores, whereas an
open-ended reasoning dataset (e.g., JudgeLM-val) sees higher average scores.
Finally, we proposed four potential mitigation strategies to ensure fair and
reliable AI judging in practical communication scenarios.

</details>


### [63] [Using Medical Algorithms for Task-Oriented Dialogue in LLM-Based Medical Interviews](https://arxiv.org/abs/2510.12490)
*Rui Reis,Pedro Rangel Henriques,João Ferreira-Coimbra,Eva Oliveira,Nuno F. Rodrigues*

Main category: cs.AI

TL;DR: 开发了基于有向无环图的医疗对话框架，包含问题转换、冷启动、自适应分支、终止逻辑和报告生成等功能模块，在初步评估中表现出良好的用户体验和临床工作流程集成。


<details>
  <summary>Details</summary>
Motivation: 为医疗领域开发一个任务导向的对话系统，能够将医疗算法和指南转化为结构化的临床问题，支持高效的医患交互和报告生成。

Method: 采用有向无环图结构，集成系统化的问题转换管道、基于层次聚类的冷启动机制、扩展剪枝的自适应分支机制、终止逻辑以及自动化报告生成。

Result: 患者应用认知负荷低(15.6)、可用性高(86)、满意度强(8.1/9)；医生应用认知负荷中等(26)、可用性优秀(88.5)、满意度高(8.3/9)。系统能有效集成到临床工作流程中。

Conclusion: 该医疗对话框架在初步评估中表现出良好的性能和用户体验，但存在系统延迟和小样本评估的局限性，未来需要扩大评估规模和优化性能。

Abstract: We developed a task-oriented dialogue framework structured as a Directed
Acyclic Graph (DAG) of medical questions. The system integrates: (1) a
systematic pipeline for transforming medical algorithms and guidelines into a
clinical question corpus; (2) a cold-start mechanism based on hierarchical
clustering to generate efficient initial questioning without prior patient
information; (3) an expand-and-prune mechanism enabling adaptive branching and
backtracking based on patient responses; (4) a termination logic to ensure
interviews end once sufficient information is gathered; and (5) automated
synthesis of doctor-friendly structured reports aligned with clinical
workflows. Human-computer interaction principles guided the design of both the
patient and physician applications. Preliminary evaluation involved five
physicians using standardized instruments: NASA-TLX (cognitive workload), the
System Usability Scale (SUS), and the Questionnaire for User Interface
Satisfaction (QUIS). The patient application achieved low workload scores
(NASA-TLX = 15.6), high usability (SUS = 86), and strong satisfaction (QUIS =
8.1/9), with particularly high ratings for ease of learning and interface
design. The physician application yielded moderate workload (NASA-TLX = 26) and
excellent usability (SUS = 88.5), with satisfaction scores of 8.3/9. Both
applications demonstrated effective integration into clinical workflows,
reducing cognitive demand and supporting efficient report generation.
Limitations included occasional system latency and a small, non-diverse
evaluation sample.

</details>


### [64] [Artificial Intelligence Virtual Cells: From Measurements to Decisions across Modality, Scale, Dynamics, and Evaluation](https://arxiv.org/abs/2510.12498)
*Chengpeng Hu,Calvin Yu-Chian Chen*

Main category: cs.AI

TL;DR: 提出细胞状态潜在(CSL)视角，通过操作符语法组织学习过程，强调决策对齐的评估框架，以解决当前AI虚拟细胞模型在跨实验室、跨平台迁移性、数据泄漏和跨尺度耦合方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前AI虚拟细胞模型虽然在单数据集验证中表现良好，但在跨实验室和平台迁移性、数据泄漏、剂量时间效应处理以及跨尺度耦合方面存在局限，需要更系统化的评估和建模方法。

Method: 提出模型无关的CSL视角，使用操作符语法组织学习：测量、跨尺度耦合的lift/project操作、以及剂量和调度的干预操作。强调决策对齐的评估蓝图，涵盖模态、尺度、上下文和干预。

Result: 构建了系统化的评估框架，强调功能空间读出如通路活性、空间邻域和临床相关终点，推荐操作符感知的数据设计、抗泄漏分区和透明校准报告方法。

Conclusion: 通过CSL视角和操作符语法，能够实现可重复的类对类比较，促进AI虚拟细胞模型在跨尺度、跨平台环境中的可靠应用和发展。

Abstract: Artificial Intelligence Virtual Cells (AIVCs) aim to learn executable,
decision-relevant models of cell state from multimodal, multiscale
measurements. Recent studies have introduced single-cell and spatial foundation
models, improved cross-modality alignment, scaled perturbation atlases, and
explored pathway-level readouts. Nevertheless, although held-out validation is
standard practice, evaluations remain predominantly within single datasets and
settings; evidence indicates that transport across laboratories and platforms
is often limited, that some data splits are vulnerable to leakage and coverage
bias, and that dose, time and combination effects are not yet systematically
handled. Cross-scale coupling also remains constrained, as anchors linking
molecular, cellular and tissue levels are sparse, and alignment to scientific
or clinical readouts varies across studies. We propose a model-agnostic
Cell-State Latent (CSL) perspective that organizes learning via an operator
grammar: measurement, lift/project for cross-scale coupling, and intervention
for dosing and scheduling. This view motivates a decision-aligned evaluation
blueprint across modality, scale, context and intervention, and emphasizes
function-space readouts such as pathway activity, spatial neighborhoods and
clinically relevant endpoints. We recommend operator-aware data design,
leakage-resistant partitions, and transparent calibration and reporting to
enable reproducible, like-for-like comparisons.

</details>


### [65] [ProtoSiTex: Learning Semi-Interpretable Prototypes for Multi-label Text Classification](https://arxiv.org/abs/2510.12534)
*Utsav Kumar Nareti,Suraj Kumar,Soumya Pandey,Soumi Chattopadhyay,Chandranath Adak*

Main category: cs.AI

TL;DR: ProtoSiTex是一个半可解释的多标签文本分类框架，通过双阶段交替训练和分层损失函数，在子句、句子和文档级别提供细粒度解释，并在多标签分类任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 用户生成评论的激增需要可解释模型提供细粒度洞察。现有基于原型的模型通常只在粗粒度（句子或文档级别）运行，无法处理现实世界文本分类的多标签特性。

Method: 采用双阶段交替训练策略：无监督原型发现阶段学习语义连贯且多样化的原型，监督分类阶段将这些原型映射到类别标签。使用分层损失函数在子句、句子和文档级别强制一致性。通过自适应原型和多头注意力捕获重叠和冲突语义。

Result: 在酒店评论基准数据集和两个公共基准测试（二分类和多分类）上的实验表明，ProtoSiTex实现了最先进的性能，同时提供忠实、与人类对齐的解释。

Conclusion: ProtoSiTex为半可解释多标签文本分类提供了一个强大的解决方案，能够处理细粒度多标签分类任务并提供有意义的解释。

Abstract: The surge in user-generated reviews has amplified the need for interpretable
models that can provide fine-grained insights. Existing prototype-based models
offer intuitive explanations but typically operate at coarse granularity
(sentence or document level) and fail to address the multi-label nature of
real-world text classification. We propose ProtoSiTex, a semi-interpretable
framework designed for fine-grained multi-label text classification. ProtoSiTex
employs a dual-phase alternating training strategy: an unsupervised prototype
discovery phase that learns semantically coherent and diverse prototypes, and a
supervised classification phase that maps these prototypes to class labels. A
hierarchical loss function enforces consistency across sub-sentence, sentence,
and document levels, enhancing interpretability and alignment. Unlike prior
approaches, ProtoSiTex captures overlapping and conflicting semantics using
adaptive prototypes and multi-head attention. We also introduce a benchmark
dataset of hotel reviews annotated at the sub-sentence level with multiple
labels. Experiments on this dataset and two public benchmarks (binary and
multi-class) show that ProtoSiTex achieves state-of-the-art performance while
delivering faithful, human-aligned explanations, establishing it as a robust
solution for semi-interpretable multi-label text classification.

</details>


### [66] [HardcoreLogic: Challenging Large Reasoning Models with Long-tail Logic Puzzle Games](https://arxiv.org/abs/2510.12563)
*Jingcong Liang,Shijun Wan,Xuehai Wu,Siyuan Wang,Yitong Li,Qianglong Chen,Duyu Tang,Zhongyu Wei*

Main category: cs.AI

TL;DR: 提出了HardcoreLogic基准测试，包含5000多个谜题，通过增加复杂性、非典型元素和不可解谜题三个维度来评估大型推理模型的逻辑推理鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注标准格式的谜题（如9x9数独），可能导致模型过拟合和记忆解决方案模式，无法真正测试其处理非典型规则变体的能力。

Method: 设计包含10种游戏的HardcoreLogic基准，通过三个维度系统性地变换标准谜题：增加复杂性(IC)、非典型元素(UE)和不可解谜题(UP)，减少对捷径记忆的依赖。

Result: 评估显示即使在其他基准测试中表现优异的模型在HardcoreLogic上性能显著下降，表明它们严重依赖记忆的刻板模式。增加复杂性是主要困难来源，但模型在细微规则变化上也表现不佳。

Conclusion: HardcoreLogic揭示了当前大型推理模型的局限性，为推进高水平逻辑推理建立了基准测试框架。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance on
complex tasks, including logical puzzle games that require deriving solutions
satisfying all constraints. However, whether they can flexibly apply
appropriate rules to varying conditions, particularly when faced with
non-canonical game variants, remains an open question. Existing corpora focus
on popular puzzles like 9x9 Sudoku, risking overfitting to canonical formats
and memorization of solution patterns, which can mask deficiencies in
understanding novel rules or adapting strategies to new variants. To address
this, we introduce HardcoreLogic, a challenging benchmark of over 5,000 puzzles
across 10 games, designed to test the robustness of LRMs on the "long-tail" of
logical games. HardcoreLogic systematically transforms canonical puzzles
through three dimensions: Increased Complexity (IC), Uncommon Elements (UE),
and Unsolvable Puzzles (UP), reducing reliance on shortcut memorization.
Evaluations on a diverse set of LRMs reveal significant performance drops, even
for models achieving top scores on existing benchmarks, indicating heavy
reliance on memorized stereotypes. While increased complexity is the dominant
source of difficulty, models also struggle with subtle rule variations that do
not necessarily increase puzzle difficulty. Our systematic error analysis on
solvable and unsolvable puzzles further highlights gaps in genuine reasoning.
Overall, HardcoreLogic exposes the limitations of current LRMs and establishes
a benchmark for advancing high-level logical reasoning.

</details>


### [67] [Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks](https://arxiv.org/abs/2510.12635)
*Yuxiang Zhang,Jiangming Shu,Ye Ma,Xueyuan Lin,Shangxi Wu,Jitao Sang*

Main category: cs.AI

TL;DR: 提出Memory-as-Action框架，将工作内存管理重构为可学习的内在能力，通过强化学习联合优化任务推理和内存管理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长视野智能体任务中面临内存限制，现有方法依赖与核心策略解耦的外部启发式机制。

Method: 提出Memory-as-Action框架，智能体通过执行显式编辑操作主动管理工作内存；为解决轨迹断裂问题，提出动态上下文策略优化算法。

Result: 端到端联合优化不仅减少了计算消耗，还通过自适应上下文管理策略提高了任务性能。

Conclusion: 将内存管理作为可学习的内在能力，通过统一策略联合优化任务推理和内存管理，能够提升智能体在资源约束下的长期任务表现。

Abstract: Large Language Models face challenges in long-horizon agentic tasks as their
constrained memory is easily overwhelmed by distracting or irrelevant context.
Existing working memory methods typically rely on external, heuristic
mechanisms that are decoupled from the agent's core policy. In this work, we
reframe working memory management as a learnable, intrinsic capability. We
propose a novel framework, Memory-as-Action, where an agent actively manages
its working memory by executing explicit editing operations as part of a
unified policy. This formulation allows an agent, trained via reinforcement
learning, to balance memory curation against long-term task objectives under
given resource constraints. However, such memory editing actions break the
standard assumption of a continuously growing prefix in LLM interactions,
leading to what we call trajectory fractures. These non-prefix changes disrupt
the causal continuity required by standard policy gradient methods, making
those methods inapplicable. To address this, we propose a new algorithm,
Dynamic Context Policy Optimization, which enables stable end-to-end
reinforcement learning by segmenting trajectories at memory action points and
applying trajectory-level advantages to the resulting action segments. Our
results demonstrate that jointly optimizing for task reasoning and memory
management in an end-to-end fashion not only reduces overall computational
consumption but also improves task performance, driven by adaptive context
curation strategies tailored to the model's intrinsic capabilities.

</details>


### [68] [ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning](https://arxiv.org/abs/2510.12693)
*Hanyang Chen,Mark Zhao,Rui Yang,Qinwei Ma,Ke Yang,Jiarui Yao,Kangrui Wang,Hao Bai,Zhenhailong Wang,Rui Pan,Mengchao Zhang,Jose Barreiros,Aykut Onol,ChengXiang Zhai,Heng Ji,Manling Li,Huan Zhang,Tong Zhang*

Main category: cs.AI

TL;DR: ERA是一个两阶段框架，通过先验知识学习和在线强化学习，使小型视觉语言模型在具身AI任务中超越大型模型。


<details>
  <summary>Details</summary>
Motivation: 解决高性能具身AI系统依赖昂贵大模型，而小模型缺乏必要知识和技能的问题。

Method: 第一阶段进行具身先验学习，从轨迹增强先验、环境锚定先验和外部知识先验中提取知识；第二阶段通过自总结、密集奖励塑造和回合级策略优化进行在线强化学习。

Result: ERA-3B在EB-ALFRED任务上比GPT-4o提升8.4%，在EB-Manipulation任务上提升19.4%，并在未见任务上表现出强泛化能力。

Conclusion: ERA为可扩展具身智能提供了实用路径，为未来具身AI系统提供了方法论见解。

Abstract: Recent advances in embodied AI highlight the potential of vision language
models (VLMs) as agents capable of perception, reasoning, and interaction in
complex environments. However, top-performing systems rely on large-scale
models that are costly to deploy, while smaller VLMs lack the necessary
knowledge and skills to succeed. To bridge this gap, we present
\textit{Embodied Reasoning Agent (ERA)}, a two-stage framework that integrates
prior knowledge learning and online reinforcement learning (RL). The first
stage, \textit{Embodied Prior Learning}, distills foundational knowledge from
three types of data: (1) Trajectory-Augmented Priors, which enrich existing
trajectory data with structured reasoning generated by stronger models; (2)
Environment-Anchored Priors, which provide in-environment knowledge and
grounding supervision; and (3) External Knowledge Priors, which transfer
general knowledge from out-of-environment datasets. In the second stage, we
develop an online RL pipeline that builds on these priors to further enhance
agent performance. To overcome the inherent challenges in agent RL, including
long horizons, sparse rewards, and training instability, we introduce three key
designs: self-summarization for context management, dense reward shaping, and
turn-level policy optimization. Extensive experiments on both high-level
planning (EB-ALFRED) and low-level control (EB-Manipulation) tasks demonstrate
that ERA-3B surpasses both prompting-based large models and previous
training-based baselines. Specifically, it achieves overall improvements of
8.4\% on EB-ALFRED and 19.4\% on EB-Manipulation over GPT-4o, and exhibits
strong generalization to unseen tasks. Overall, ERA offers a practical path
toward scalable embodied intelligence, providing methodological insights for
future embodied AI systems.

</details>


### [69] [Multi-Agent Debate for LLM Judges with Adaptive Stability Detection](https://arxiv.org/abs/2510.12697)
*Tianyu Hu,Zhen Tan,Song Wang,Huaizhi Qu,Tianlong Chen*

Main category: cs.AI

TL;DR: 提出了一个多智能体辩论评判框架，通过智能体协作推理和迭代优化响应来提升大型语言模型在自动评判任务中的准确性，相比简单多数投票方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为评判者的方法通常依赖简单的聚合方法（如多数投票），即使在个体智能体提供正确答案的情况下也可能失败，需要更有效的协作推理机制。

Method: 多智能体辩论评判框架，智能体协作推理并迭代优化响应；引入稳定性检测机制，通过时变Beta-Binomial混合模型建模评判者共识动态，基于分布相似性（Kolmogorov-Smirnov检验）的自适应停止准则。

Result: 在多个基准测试和模型上的实验表明，该框架相比多数投票提高了评判准确性，同时保持了计算效率。

Conclusion: 多智能体辩论框架能够有效提升LLM在自动评判任务中的性能，通过协作推理和自适应停止机制实现准确性和效率的平衡。

Abstract: With advancements in reasoning capabilities, Large Language Models (LLMs) are
increasingly employed for automated judgment tasks. While LLMs-as-Judges offer
promise in automating evaluations, current approaches often rely on simplistic
aggregation methods (e.g., majority voting), which can fail even when
individual agents provide correct answers. To address this, we propose a
multi-agent debate judge framework where agents collaboratively reason and
iteratively refine their responses. We formalize the debate process
mathematically, analyzing agent interactions and proving that debate amplifies
correctness compared to static ensembles. To enhance efficiency, we introduce a
stability detection mechanism that models judge consensus dynamics via a
time-varying Beta-Binomial mixture, with adaptive stopping based on
distributional similarity (Kolmogorov-Smirnov test). This mechanism models the
judges' collective correct rate dynamics using a time-varying mixture of
Beta-Binomial distributions and employs an adaptive stopping criterion based on
distributional similarity (Kolmogorov-Smirnov statistic). Experiments across
multiple benchmarks and models demonstrate that our framework improves judgment
accuracy over majority voting while maintaining computational efficiency.

</details>


### [70] [CAMNet: Leveraging Cooperative Awareness Messages for Vehicle Trajectory Prediction](https://arxiv.org/abs/2510.12703)
*Mattia Grasselli,Angelo Porrello,Carlo Augusto Grazia*

Main category: cs.AI

TL;DR: 本文研究了使用协作感知消息(CAM)数据进行车辆轨迹预测，开发了CAMNet神经网络模型，并在两个数据集上验证了CAM数据在轨迹预测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶面临安全挑战，现有传感器存在视野受限和遮挡问题。车辆间通信能够共享信息，提高情境感知能力，特别是通过协作感知消息(CAM)来克服传感器限制。

Method: 设计并训练了基于协作感知消息的图神经网络(CAMNet)，在一个广泛使用的运动预测数据集上进行训练，并在新创建的CAM数据集上进行评估。

Result: 方法显示出有希望的结果，证明CAM数据确实可以支持车辆轨迹预测，但同时也存在一些局限性。

Conclusion: CAM数据在车辆轨迹预测中具有应用潜力，但存在局限性，为未来研究提供了机会。

Abstract: Autonomous driving remains a challenging task, particularly due to safety
concerns. Modern vehicles are typically equipped with expensive sensors such as
LiDAR, cameras, and radars to reduce the risk of accidents. However, these
sensors face inherent limitations: their field of view and line of sight can be
obstructed by other vehicles, thereby reducing situational awareness. In this
context, vehicle-to-vehicle communication plays a crucial role, as it enables
cars to share information and remain aware of each other even when sensors are
occluded. One way to achieve this is through the use of Cooperative Awareness
Messages (CAMs). In this paper, we investigate the use of CAM data for vehicle
trajectory prediction. Specifically, we design and train a neural network,
Cooperative Awareness Message-based Graph Neural Network (CAMNet), on a widely
used motion forecasting dataset. We then evaluate the model on a second dataset
that we created from scratch using Cooperative Awareness Messages, in order to
assess whether this type of data can be effectively exploited. Our approach
demonstrates promising results, showing that CAMs can indeed support vehicle
trajectory prediction. At the same time, we discuss several limitations of the
approach, which highlight opportunities for future research.

</details>


### [71] [Towards Robust Artificial Intelligence: Self-Supervised Learning Approach for Out-of-Distribution Detection](https://arxiv.org/abs/2510.12713)
*Wissam Salhab,Darine Ameyed,Hamid Mcheick,Fehmi Jaafar*

Main category: cs.AI

TL;DR: 提出了一种无需标记数据的OOD检测方法，通过自监督学习和图论技术提高AI系统的鲁棒性，在AUROC指标上达到0.99。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶、医疗等安全关键系统中，AI系统需要具备在OOD样本、对抗攻击等条件下保持可靠性能的鲁棒性。

Method: 结合自监督学习和图论技术，从无标签数据中学习有用表征，实现更高效的OOD样本识别和分类。

Result: 与现有最先进方法相比，该方法在AUROC指标上达到0.99的优异表现。

Conclusion: 该方法有效提升了AI系统在无标签数据条件下的OOD检测能力，增强了系统鲁棒性。

Abstract: Robustness in AI systems refers to their ability to maintain reliable and
accurate performance under various conditions, including out-of-distribution
(OOD) samples, adversarial attacks, and environmental changes. This is crucial
in safety-critical systems, such as autonomous vehicles, transportation, or
healthcare, where malfunctions could have severe consequences. This paper
proposes an approach to improve OOD detection without the need of labeled data,
thereby increasing the AI systems' robustness. The proposed approach leverages
the principles of self-supervised learning, allowing the model to learn useful
representations from unlabeled data. Combined with graph-theoretical
techniques, this enables the more efficient identification and categorization
of OOD samples. Compared to existing state-of-the-art methods, this approach
achieved an Area Under the Receiver Operating Characteristic Curve (AUROC) =
0.99.

</details>


### [72] [Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing](https://arxiv.org/abs/2510.12732)
*Myles Foley,Sergio Maffeis,Muhammad Fakhrur Rozi,Takeshi Takahashi*

Main category: cs.AI

TL;DR: CLUTCH是一种基于深度组合多臂赌博机的新型JavaScript模糊测试方法，通过注意力机制和Concrete Dropout动态选择变异目标，显著提高了测试效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有JavaScript引擎模糊测试技术使用随机选择变异位置的方法，存在效率问题。作者认为选择更好的变异目标适合使用组合多臂赌博机方法来解决。

Method: 提出CLUTCH方法：使用注意力机制的深度组合多臂赌博机观察变长JavaScript测试用例表示，并通过Concrete Dropout动态调整探索策略。

Result: 相比三种最先进解决方案，CLUTCH将有效测试用例数量平均提高20.3%，每个测试用例的覆盖率平均提高8.9%。在波动和组合设置中，后悔值分别减少至少78.1%和4.1%。

Conclusion: CLUTCH在JavaScript模糊测试中显著提高了效率，证明了深度组合多臂赌博机方法在解决变异目标选择问题上的有效性。

Abstract: JavaScript engines are widely used in web browsers, PDF readers, and
server-side applications. The rise in concern over their security has led to
the development of several targeted fuzzing techniques. However, existing
approaches use random selection to determine where to perform mutations in
JavaScript code. We postulate that the problem of selecting better mutation
targets is suitable for combinatorial bandits with a volatile number of arms.
Thus, we propose CLUTCH, a novel deep combinatorial bandit that can observe
variable length JavaScript test case representations, using an attention
mechanism from deep learning. Furthermore, using Concrete Dropout, CLUTCH can
dynamically adapt its exploration. We show that CLUTCH increases efficiency in
JavaScript fuzzing compared to three state-of-the-art solutions by increasing
the number of valid test cases and coverage-per-testcase by, respectively,
20.3% and 8.9% on average. In volatile and combinatorial settings we show that
CLUTCH outperforms state-of-the-art bandits, achieving at least 78.1% and 4.1%
less regret in volatile and combinatorial settings, respectively.

</details>


### [73] [CTRL-Rec: Controlling Recommender Systems With Natural Language](https://arxiv.org/abs/2510.12742)
*Micah Carroll,Adeline Foote,Kevin Feng,Marcus Williams,Anca Dragan,W. Bradley Knox,Smitha Milli*

Main category: cs.AI

TL;DR: CTRL-Rec是一种让用户通过自然语言实时控制推荐系统的方法，使用LLM模拟用户对物品的批准判断，训练嵌入模型来近似这些判断，并将预测集成到传统推荐系统的信号加权中。


<details>
  <summary>Details</summary>
Motivation: 当用户对推荐系统不满意时，他们通常缺乏细粒度的控制手段来改变推荐结果。大语言模型（LLMs）提供了解决方案，允许用户通过自然语言请求来指导推荐。

Method: 在训练时，使用LLM模拟用户基于语言请求是否批准物品，训练嵌入模型来近似这些模拟判断。然后将基于用户请求的预测集成到传统推荐系统优化的标准信号加权中。在部署时，每个用户请求只需要一次LLM嵌入计算，实现实时推荐控制。

Result: 在MovieLens数据集上的实验表明，该方法在各种请求下都能实现细粒度控制。在19名Letterboxd用户的研究中，CTRL-Rec受到用户积极评价，与传统控制相比显著增强了用户的控制感和推荐满意度。

Conclusion: CTRL-Rec方法成功实现了通过自然语言对传统推荐系统的实时控制，计算效率高，用户接受度好，显著提升了用户体验。

Abstract: When users are dissatisfied with recommendations from a recommender system,
they often lack fine-grained controls for changing them. Large language models
(LLMs) offer a solution by allowing users to guide their recommendations
through natural language requests (e.g., "I want to see respectful posts with a
different perspective than mine"). We propose a method, CTRL-Rec, that allows
for natural language control of traditional recommender systems in real-time
with computational efficiency. Specifically, at training time, we use an LLM to
simulate whether users would approve of items based on their language requests,
and we train embedding models that approximate such simulated judgments. We
then integrate these user-request-based predictions into the standard weighting
of signals that traditional recommender systems optimize. At deployment time,
we require only a single LLM embedding computation per user request, allowing
for real-time control of recommendations. In experiments with the MovieLens
dataset, our method consistently allows for fine-grained control across a
diversity of requests. In a study with 19 Letterboxd users, we find that
CTRL-Rec was positively received by users and significantly enhanced users'
sense of control and satisfaction with recommendations compared to traditional
controls.

</details>


### [74] [Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics](https://arxiv.org/abs/2510.12787)
*Marco Del Tredici,Jacob McCarran,Benjamin Breen,Javier Aspuru Mijares,Weichen Winston Yin,Jacob M. Taylor,Frank Koppens,Dirk Englund*

Main category: cs.AI

TL;DR: Ax-Prover是一个基于多智能体系统的自动定理证明器，能够在Lean中解决跨科学领域的问题，既可以自主运行，也可以与人类专家协作。


<details>
  <summary>Details</summary>
Motivation: 解决科学问题需要结合创造性推理和严格的形式化验证，现有专门化证明系统难以泛化到不同领域。

Method: 通过Model Context Protocol (MCP)为大型语言模型配备Lean工具，将LLM的知识推理能力与形式化正确性保证相结合。

Result: 在公共数学基准测试中与最先进证明器竞争，在新引入的抽象代数和量子理论基准上显著优于其他方法，并成功协助专家数学家形式化复杂密码学定理证明。

Conclusion: 基于工具的多智能体定理证明方法为跨科学领域的形式化验证提供了可泛化的方法论。

Abstract: We present Ax-Prover, a multi-agent system for automated theorem proving in
Lean that can solve problems across diverse scientific domains and operate
either autonomously or collaboratively with human experts. To achieve this,
Ax-Prover approaches scientific problem solving through formal proof
generation, a process that demands both creative reasoning and strict syntactic
rigor. Ax-Prover meets this challenge by equipping Large Language Models
(LLMs), which provide knowledge and reasoning, with Lean tools via the Model
Context Protocol (MCP), which ensure formal correctness. To evaluate its
performance as an autonomous prover, we benchmark our approach against frontier
LLMs and specialized prover models on two public math benchmarks and on two
Lean benchmarks we introduce in the fields of abstract algebra and quantum
theory. On public datasets, Ax-Prover is competitive with state-of-the-art
provers, while it largely outperform them on the new benchmarks. This shows
that, unlike specialized systems that struggle to generalize, our tool-based
agentic theorem prover approach offers a generalizable methodology for formal
verification across diverse scientific domains. Furthermore, we demonstrate
Ax-Prover's assistant capabilities in a practical use case, showing how it
enabled an expert mathematician to formalize the proof of a complex
cryptography theorem.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [75] [Translating Milli/Microrobots with A Value-Centered Readiness Framework](https://arxiv.org/abs/2510.12090)
*Hakan Ceylan,Edoardo Sinibaldi,Sanjay Misra,Pankaj J. Pasricha,Dietmar W. Hutmacher*

Main category: cs.RO

TL;DR: 本文回顾了无绳移动毫米/微米机器人在介入医学中的转化挑战，提出了技术就绪水平框架（mTRL）来加速从实验室到临床的转化。


<details>
  <summary>Details</summary>
Motivation: 尽管毫米/微米机器人在实验室中取得了显著进展，但大多数仍停留在概念验证阶段，缺乏临床应用的可行性。需要弥合技术创新与实际应用之间的差距。

Method: 引入战略性的毫米/微米机器人技术就绪水平框架（mTRL），通过明确定义的里程碑和逐步活动，将系统开发从概念化映射到临床采用。

Result: mTRL模型提供了技术成熟度的结构化衡量标准，为跨学科合作提供共同语言，并为加速转化发展提供可操作的指导。

Conclusion: 该领域的长期影响和可持续性取决于将开发与未满足的医疗需求对齐，确保应用可行性，并无缝集成到现有临床工作流程中。

Abstract: Untethered mobile milli/microrobots hold transformative potential for
interventional medicine by enabling more precise and entirely non-invasive
diagnosis and therapy. Realizing this promise requires bridging the gap between
groundbreaking laboratory demonstrations and successful clinical integration.
Despite remarkable technical progress over the past two decades, most
millirobots and microrobots remain confined to laboratory proof-of-concept
demonstrations, with limited real-world feasibility. In this Review, we
identify key factors that slow translation from bench to bedside, focusing on
the disconnect between technical innovation and real-world application. We
argue that the long-term impact and sustainability of the field depend on
aligning development with unmet medical needs, ensuring applied feasibility,
and integrating seamlessly into existing clinical workflows, which are
essential pillars for delivering meaningful patient outcomes. To support this
shift, we introduce a strategic milli/microrobot Technology Readiness Level
framework (mTRL), which maps system development from initial conceptualization
to clinical adoption through clearly defined milestones and their associated
stepwise activities. The mTRL model provides a structured gauge of
technological maturity, a common language for cross-disciplinary collaboration
and actionable guidance to accelerate translational development toward new,
safer and more efficient interventions.

</details>


### [76] [Gaussian Semantic Field for One-shot LiDAR Global Localization](https://arxiv.org/abs/2510.12101)
*Pengyu Yin,Shenghai Yuan,Haozhi Cao,Xingyu Ji,Ruofei Bai,Siyu Chen,Lihua Xie*

Main category: cs.RO

TL;DR: 提出了一种基于轻量级三层场景图的单次LiDAR全局定位算法，通过高斯过程学习语义分布的连续函数来解决地标重复性问题。


<details>
  <summary>Details</summary>
Motivation: 基于地标语义配准的方法在全局定位中表现优于纯几何方法，但地标可能重复且误导对应关系建立，需要解决这一问题。

Method: 使用高斯过程学习语义分布的连续函数，构建对象层-连续函数层-度量语义层的三层3D场景图，作为轻量级单次定位后端。

Result: 在公开数据集上的广泛实验验证了该方法相对于当前最先进方法的优越性能。

Conclusion: 提出的Outram-GSF全局定位管道通过连续语义函数有效解决了地标重复性问题，实现了高性能的单次LiDAR全局定位。

Abstract: We present a one-shot LiDAR global localization algorithm featuring semantic
disambiguation ability based on a lightweight tri-layered scene graph. While
landmark semantic registration-based methods have shown promising performance
improvements in global localization compared with geometric-only methods,
landmarks can be repetitive and misleading for correspondence establishment. We
propose to mitigate this problem by modeling semantic distributions with
continuous functions learned from a population of Gaussian processes. Compared
with discrete semantic labels, the continuous functions capture finer-grained
geo-semantic information and also provide more detailed metric information for
correspondence establishment. We insert this continuous function as the middle
layer between the object layer and the metric-semantic layer, forming a
tri-layered 3D scene graph, serving as a light-weight yet performant backend
for one-shot localization. We term our global localization pipeline Outram-GSF
(Gaussian semantic field) and conduct a wide range of experiments on publicly
available data sets, validating the superior performance against the current
state-of-the-art.

</details>


### [77] [Hybrid Terrain-Aware Path Planning: Integrating VD--RRT\(^{*}\) Exploration and VD--D\(^{*}\) Lite Repair](https://arxiv.org/abs/2510.12169)
*Akshay Naik,William R. Norris,Dustin Nottage,Ahmet Soylemezoglu*

Main category: cs.RO

TL;DR: 提出了一种结合土壤强度和坡度评估的连续状态-成本度量方法，用于越野车辆在可变形地形中的实时路径规划，支持毫秒级重规划。


<details>
  <summary>Details</summary>
Motivation: 越野车辆需要在考虑土壤强度和坡度等空间变化的地形危险因素的同时，规划出曲率可行的路径，并在实时环境中执行。

Method: 使用连续状态-成本度量结合Bekker压力-沉降模型和坡度惩罚，在格子上评估成本场，采用Vehicle-Dynamics RRT*进行全局探索，Vehicle-Dynamics D* Lite进行局部修复。

Result: 硬件试验表明，该方法能够在软土和坡度变化的地形中实现实时导航，支持非结构化环境中的可靠自主性。

Conclusion: 通过将地形-车辆模型与规划器分离，该框架为可变形地形中的确定性、基于采样或学习驱动的规划提供了可重用的基础。

Abstract: Autonomous ground vehicles operating off-road must plan curvature-feasible
paths while accounting for spatially varying soil strength and slope hazards in
real time. We present a continuous state--cost metric that combines a Bekker
pressure--sinkage model with elevation-derived slope and attitude penalties.
The resulting terrain cost field is analytic, bounded, and monotonic in soil
modulus and slope, ensuring well-posed discretization and stable updates under
sensor noise. This metric is evaluated on a lattice with exact steering
primitives: Dubins and Reeds--Shepp motions for differential drive and
time-parameterized bicycle arcs for Ackermann steering. Global exploration is
performed using Vehicle-Dynamics RRT\(^{*}\), while local repair is managed by
Vehicle-Dynamics D\(^{*}\) Lite, enabling millisecond-scale replanning without
heuristic smoothing. By separating the terrain--vehicle model from the planner,
the framework provides a reusable basis for deterministic, sampling-based, or
learning-driven planning in deformable terrain. Hardware trials on an off-road
platform demonstrate real-time navigation across soft soil and slope
transitions, supporting reliable autonomy in unstructured environments.

</details>


### [78] [Controllable Collision Scenario Generation via Collision Pattern Prediction](https://arxiv.org/abs/2510.12206)
*Pin-Lun Chen,Chi-Hsi Kung,Che-Han Chang,Wei-Chen Chiu,Yi-Ting Chen*

Main category: cs.RO

TL;DR: 提出了可控碰撞场景生成任务，通过COLLIDE数据集和预测碰撞模式的方法，自动生成指定碰撞类型和碰撞时间的场景，用于评估和改进自动驾驶车辆的安全性。


<details>
  <summary>Details</summary>
Motivation: 评估自动驾驶车辆安全性需要多样化的安全关键场景，特别是碰撞场景，但在现实中收集这些场景既罕见又不安全。现有方法难以精确控制碰撞类型和碰撞时间等属性。

Method: 构建COLLIDE大规模碰撞场景数据集，将真实驾驶日志转换为多样化碰撞；提出预测碰撞模式的框架，该模式是碰撞时自车与对抗车辆空间配置的紧凑可解释表示；然后展开完整的对抗轨迹。

Result: 实验表明该方法在碰撞率和可控性方面优于强基线；生成的场景能持续诱导更高的规划器失败率，揭示现有规划器的局限性；这些场景可用于微调规划器以提升鲁棒性。

Conclusion: 该方法能有效生成可控的碰撞场景，有助于在不同碰撞场景中实现更安全的自动驾驶部署，通过暴露规划器弱点并针对性改进来提升系统安全性。

Abstract: Evaluating the safety of autonomous vehicles (AVs) requires diverse,
safety-critical scenarios, with collisions being especially important yet rare
and unsafe to collect in the real world. Therefore, the community has been
focusing on generating safety-critical scenarios in simulation. However,
controlling attributes such as collision type and time-to-accident (TTA)
remains challenging. We introduce a new task called controllable collision
scenario generation, where the goal is to produce trajectories that realize a
user-specified collision type and TTA, to investigate the feasibility of
automatically generating desired collision scenarios. To support this task, we
present COLLIDE, a large-scale collision scenario dataset constructed by
transforming real-world driving logs into diverse collisions, balanced across
five representative collision types and different TTA intervals. We propose a
framework that predicts Collision Pattern, a compact and interpretable
representation that captures the spatial configuration of the ego and the
adversarial vehicles at impact, before rolling out full adversarial
trajectories. Experiments show that our approach outperforms strong baselines
in both collision rate and controllability. Furthermore, generated scenarios
consistently induce higher planner failure rates, revealing limitations of
existing planners. We demonstrate that these scenarios fine-tune planners for
robustness improvements, contributing to safer AV deployment in different
collision scenarios.

</details>


### [79] [Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications](https://arxiv.org/abs/2510.12215)
*Chanwoo Kim,Jihwan Yoon,Hyeonseong Kim,Taemoon Jeong,Changwoo Yoo,Seungbeen Lee,Soohwan Byeon,Hoon Chung,Matthew Pan,Jean Oh,Kyungjae Lee,Sungjoon Choi*

Main category: cs.RO

TL;DR: 提出了一种结合数据驱动奖励和规则目标的移动机器人导航框架，通过密度学习奖励函数，结合避障和到达目标的规则目标，使用采样前瞻控制器生成安全自适应动作，并蒸馏为适合实时操作的紧凑策略。


<details>
  <summary>Details</summary>
Motivation: 在动态人类环境中，机器人导航需要平衡适应性和安全性。假设将数据驱动奖励与基于规则的目标结合，能更有效地实现这种平衡。

Method: 开发了一个框架：从正负演示中学习基于密度的奖励，用规则目标增强（避障和到达目标），使用采样前瞻控制器生成监督动作，最后蒸馏为紧凑的学生策略。

Result: 在合成和电梯共乘模拟中，相比基线方法在成功率和时间效率上都有稳定提升，真实世界演示证实了部署的实用性。

Conclusion: 该框架成功平衡了导航策略的适应性和安全性，在模拟和真实环境中都表现出色，验证了数据驱动奖励与规则目标结合的有效性。

Abstract: Mobile robot navigation in dynamic human environments requires policies that
balance adaptability to diverse behaviors with compliance to safety
constraints. We hypothesize that integrating data-driven rewards with
rule-based objectives enables navigation policies to achieve a more effective
balance of adaptability and safety. To this end, we develop a framework that
learns a density-based reward from positive and negative demonstrations and
augments it with rule-based objectives for obstacle avoidance and goal
reaching. A sampling-based lookahead controller produces supervisory actions
that are both safe and adaptive, which are subsequently distilled into a
compact student policy suitable for real-time operation with uncertainty
estimates. Experiments in synthetic and elevator co-boarding simulations show
consistent gains in success rate and time efficiency over baselines, and
real-world demonstrations with human participants confirm the practicality of
deployment. A video illustrating this work can be found on our project page
https://chanwookim971024.github.io/PioneeR/.

</details>


### [80] [Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model](https://arxiv.org/abs/2510.12276)
*Fuhao Li,Wenxuan Song,Han Zhao,Jingbo Wang,Pengxiang Ding,Donglin Wang,Long Zeng,Haoang Li*

Main category: cs.RO

TL;DR: 提出了一种名为Spatial Forcing (SF)的简单有效对齐策略，通过将VLA模型的中间视觉嵌入与预训练3D基础模型生成的几何表示对齐，隐式地增强VLA模型的空间理解能力，无需依赖显式3D输入或深度估计器。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型大多基于仅在2D数据上预训练的视觉语言模型，缺乏准确的空间感知能力，限制了其在3D物理世界中的操作能力。现有解决方案要么依赖有噪声的3D传感器输入，要么受限于深度估计器的性能。

Method: SF策略在中间层将VLA的视觉嵌入与预训练3D基础模型的几何表示进行对齐，引导VLA编码更丰富的空间表示，从而提升动作精度。

Result: 在仿真和真实环境中的广泛实验表明，SF实现了最先进的性能，超越了基于2D和3D的VLA模型。SF还加速了训练达3.8倍，并在多样化机器人任务中提高了数据效率。

Conclusion: SF是一种简单而有效的策略，能够隐式地增强VLA模型的空间理解能力，无需依赖显式3D输入，在机器人任务中表现出色且高效。

Abstract: Vision-language-action (VLA) models have recently shown strong potential in
enabling robots to follow language instructions and execute precise actions.
However, most VLAs are built upon vision-language models pretrained solely on
2D data, which lack accurate spatial awareness and hinder their ability to
operate in the 3D physical world. Existing solutions attempt to incorporate
explicit 3D sensor inputs such as depth maps or point clouds, but these
approaches face challenges due to sensor noise, hardware heterogeneity, and
incomplete depth coverage in existing datasets. Alternative methods that
estimate 3D cues from 2D images also suffer from the limited performance of
depth estimators.We propose Spatial Forcing (SF), a simple yet effective
alignment strategy that implicitly forces VLA models to develop spatial
comprehension capabilities without relying on explicit 3D inputs or depth
estimators. SF aligns intermediate visual embeddings of VLAs with geometric
representations produced by pretrained 3D foundation models. By enforcing
alignment at intermediate layers, SF guides VLAs to encode richer spatial
representations that enhance action precision.Extensive experiments in
simulation and real-world environments demonstrate that SF achieves
state-of-the-art results, surpassing both 2D- and 3D-based VLAs. SF further
accelerates training by up to 3.8x and improves data efficiency across diverse
robotic tasks. Project page is at https://spatial-forcing.github.io/

</details>


### [81] [Shape-Aware Whole-Body Control for Continuum Robots with Application in Endoluminal Surgical Robotics](https://arxiv.org/abs/2510.12332)
*Mohammadreza Kasaei,Mostafa Ghobadi,Mohsen Khadem*

Main category: cs.RO

TL;DR: 提出了一个形状感知的全身控制框架，用于肌腱驱动连续体机器人的腔内手术导航，通过物理信息骨架模型和增强神经ODE实现精确形状估计和高效雅可比计算，结合MPPI控制器优化尖端跟踪、骨架顺应性和障碍物避让。


<details>
  <summary>Details</summary>
Motivation: 解决传统仅尖端控制在腔内手术中容易导致壁接触、组织创伤或无法到达远端目标的问题，需要在曲折的患者特定解剖结构中实现精确安全导航。

Method: 结合物理信息骨架模型与增强神经ODE进行残差学习，使用基于采样的MPPI控制器联合优化尖端跟踪、骨架顺应性和障碍物避让，任务管理器支持实时调整目标。

Result: 仿真研究显示毫米级精度，在支气管镜体模上的真实机器人实验验证了框架有效性，相比仅操纵杆导航和现有基线，提高了管腔跟随精度、减少壁接触并增强适应性。

Conclusion: 该框架有潜力提高微创腔内手术的安全性、可靠性和操作效率，并适用于其他受限和安全关键环境。

Abstract: This paper presents a shape-aware whole-body control framework for
tendon-driven continuum robots with direct application to endoluminal surgical
navigation. Endoluminal procedures, such as bronchoscopy, demand precise and
safe navigation through tortuous, patient-specific anatomy where conventional
tip-only control often leads to wall contact, tissue trauma, or failure to
reach distal targets. To address these challenges, our approach combines a
physics-informed backbone model with residual learning through an Augmented
Neural ODE, enabling accurate shape estimation and efficient Jacobian
computation. A sampling-based Model Predictive Path Integral (MPPI) controller
leverages this representation to jointly optimize tip tracking, backbone
conformance, and obstacle avoidance under actuation constraints. A task manager
further enhances adaptability by allowing real-time adjustment of objectives,
such as wall clearance or direct advancement, during tele-operation. Extensive
simulation studies demonstrate millimeter-level accuracy across diverse
scenarios, including trajectory tracking, dynamic obstacle avoidance, and
shape-constrained reaching. Real-robot experiments on a bronchoscopy phantom
validate the framework, showing improved lumen-following accuracy, reduced wall
contacts, and enhanced adaptability compared to joystick-only navigation and
existing baselines. These results highlight the potential of the proposed
framework to increase safety, reliability, and operator efficiency in minimally
invasive endoluminal surgery, with broader applicability to other confined and
safety-critical environments.

</details>


### [82] [Achieving Meaningful Collaboration: Worker-centered Design of a Physical Human-Robot Collaborative Blending Task](https://arxiv.org/abs/2510.12340)
*Nicky Mol,Luka Peternel,Alessandro Ianniello,Denis Zatyagov,Auke Nachenius,Stephan Balvert,J. Micah Prendergast,Sara Muscolo,Olger Siebinga,Eva Verhoef,Deborah Forster,David A. Abbink*

Main category: cs.RO

TL;DR: 本文提倡并展示了一种跨学科方法，将机器人技术应用于工作场所，特别关注飞机发动机维修和维护操作中的协作机器人潜力。


<details>
  <summary>Details</summary>
Motivation: 工业机器人应用增长迅速，旨在解决劳动力短缺、人口老龄化和生产需求增加等复杂社会挑战，同时关注工人福祉和工作吸引力。

Method: 采用跨学科方法，整合学术研究、实用专业知识和具体实践经验，开展多方面的协作机器人应用探索。

Result: 正在进行中的研究表明协作机器人在飞机发动机维修维护操作中具有应用潜力。

Conclusion: 跨学科方法对于在工作场所成功应用机器人技术至关重要，能够平衡技术效率与人文关怀。

Abstract: The use of robots in industrial settings continues to grow, driven by the
need to address complex societal challenges such as labor shortages, aging
populations, and ever-increasing production demands. In this abstract, we
advocate for (and demonstrate) a transdisciplinary approach when considering
robotics in the workplace. Transdisciplinarity emphasizes the integration of
academic research with pragmatic expertise and embodied experiential knowledge,
that prioritize values such as worker wellbeing and job attractiveness. In the
following, we describe an ongoing multi-pronged effort to explore the potential
of collaborative robots in the context of airplane engine repair and
maintenance operations.

</details>


### [83] [PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing](https://arxiv.org/abs/2510.12346)
*Bingquan Li,Ning Wang,Tianwei Zhang,Zhicheng He,Yucong Wu*

Main category: cs.RO

TL;DR: 提出了PolyMap框架，基于感知的人形机器人楼梯攀爬规划系统，通过多传感器融合构建实时多边形楼梯平面语义地图，实现20-30Hz全身运动规划。


<details>
  <summary>Details</summary>
Motivation: 为了让人形机器人能够像人类一样在未知空间中准确踩踏位置，特别是在楼梯攀爬场景中，需要开发基于感知的定位规划方法。

Method: 使用多传感器融合（LiDAR、RGB-D相机和IMU）进行平面分割和视觉里程计，构建实时多边形楼梯平面语义地图，并基于这些多边形平面段进行脚步规划。

Result: 在NVIDIA Orin上部署，实现了20-30Hz的全身运动规划输出，室内外真实场景实验表明该方法对人形机器人楼梯攀爬高效且鲁棒。

Conclusion: PolyMap框架通过实时多边形平面语义地图和脚步规划，成功实现了人形机器人的高效楼梯攀爬能力。

Abstract: Recently, biped robot walking technology has been significantly developed,
mainly in the context of a bland walking scheme. To emulate human walking,
robots need to step on the positions they see in unknown spaces accurately. In
this paper, we present PolyMap, a perception-based locomotion planning
framework for humanoid robots to climb stairs. Our core idea is to build a
real-time polygonal staircase plane semantic map, followed by a footstep planar
using these polygonal plane segments. These plane segmentation and visual
odometry are done by multi-sensor fusion(LiDAR, RGB-D camera and IMUs). The
proposed framework is deployed on a NVIDIA Orin, which performs 20-30 Hz
whole-body motion planning output. Both indoor and outdoor real-scene
experiments indicate that our method is efficient and robust for humanoid robot
stair climbing.

</details>


### [84] [Pretraining in Actor-Critic Reinforcement Learning for Robot Motion Control](https://arxiv.org/abs/2510.12363)
*Jiale Fan,Andrei Cramariuc,Tifanny Portela,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种用于机器人运动控制的预训练-微调范式，通过探索性数据收集训练逆动力学模型，然后将其权重用于初始化PPO算法的actor和critic网络，显著提升了样本效率和任务性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人强化学习中，每个技能通常从头开始学习，但同一机器人实体中的任务特定策略很可能共享可泛化的知识。本文旨在定义一种预训练范式来封装这种知识，为经典actor-critic算法提供热启动基础。

Method: 1）使用任务无关的探索性数据收集算法获取多样化的动态转换数据；2）通过监督学习训练本体感觉逆动力学模型（PIDM）；3）将预训练权重加载到actor和critic网络中，热启动实际任务的策略优化。

Result: 在7个不同的机器人运动控制任务上系统验证，相比随机初始化，平均样本效率提升40.1%，任务性能提升7.5%。

Conclusion: 提出的预训练初始化策略在机器人强化学习中具有显著优势，通过逆动力学模型预训练为策略优化提供了有效的热启动机制。

Abstract: The pretraining-finetuning paradigm has facilitated numerous transformative
advancements in artificial intelligence research in recent years. However, in
the domain of reinforcement learning (RL) for robot motion control, individual
skills are often learned from scratch despite the high likelihood that some
generalizable knowledge is shared across all task-specific policies belonging
to a single robot embodiment. This work aims to define a paradigm for
pretraining neural network models that encapsulate such knowledge and can
subsequently serve as a basis for warm-starting the RL process in classic
actor-critic algorithms, such as Proximal Policy Optimization (PPO). We begin
with a task-agnostic exploration-based data collection algorithm to gather
diverse, dynamic transition data, which is then used to train a Proprioceptive
Inverse Dynamics Model (PIDM) through supervised learning. The pretrained
weights are loaded into both the actor and critic networks to warm-start the
policy optimization of actual tasks. We systematically validated our proposed
method on seven distinct robot motion control tasks, showing significant
benefits to this initialization strategy. Our proposed approach on average
improves sample efficiency by 40.1% and task performance by 7.5%, compared to
random initialization. We further present key ablation studies and empirical
analyses that shed light on the mechanisms behind the effectiveness of our
method.

</details>


### [85] [Controlling Intent Expressiveness in Robot Motion with Diffusion Models](https://arxiv.org/abs/2510.12370)
*Wenli Shi,Clemence Grislain,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 提出了一种可控的机器人运动生成框架，能够在从高度可读性到高度模糊性的全谱系中调节运动意图表达，通过信息势场建模和两阶段扩散框架实现。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹生成方法通常优先考虑效率，但未能清晰传达机器人意图；现有可读性运动方法只产生单一"最可读"轨迹，忽视了在不同情境下调节意图表达的需求。

Method: 基于信息势场建模为轨迹分配连续可读性评分，采用两阶段扩散框架：首先生成指定可读性水平的路径，然后将其转换为可执行的机器人动作。

Result: 在2D和3D到达任务中的实验表明，该方法能产生具有不同可读性程度的多样化可控运动，同时达到与最先进方法相当的性能。

Conclusion: 提出的框架成功实现了机器人运动可读性的连续可控调节，为人类-机器人交互中的意图表达提供了灵活解决方案。

Abstract: Legibility of robot motion is critical in human-robot interaction, as it
allows humans to quickly infer a robot's intended goal. Although traditional
trajectory generation methods typically prioritize efficiency, they often fail
to make the robot's intentions clear to humans. Meanwhile, existing approaches
to legible motion usually produce only a single "most legible" trajectory,
overlooking the need to modulate intent expressiveness in different contexts.
In this work, we propose a novel motion generation framework that enables
controllable legibility across the full spectrum, from highly legible to highly
ambiguous motions. We introduce a modeling approach based on an Information
Potential Field to assign continuous legibility scores to trajectories, and
build upon it with a two-stage diffusion framework that first generates paths
at specified legibility levels and then translates them into executable robot
actions. Experiments in both 2D and 3D reaching tasks demonstrate that our
approach produces diverse and controllable motions with varying degrees of
legibility, while achieving performance comparable to SOTA. Code and project
page: https://legibility-modulator.github.io.

</details>


### [86] [Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking](https://arxiv.org/abs/2510.12392)
*Junhyuk So,Chiwoong Lee,Shinyoung Lee,Jungseul Ok,Eunhyeok Park*

Main category: cs.RO

TL;DR: 提出了两种新技术来增强扩散策略的一致性和反应性：自我引导和自适应分块，显著提高了生成行为克隆在机器人操作任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生成行为克隆方法使用开环控制，其固有的随机性可能导致错误动作采样和意外任务失败，且在噪声或动态环境中存在延迟响应问题。

Method: 1. 自我引导：利用过去观察并隐式促进未来感知行为来提高动作保真度；2. 自适应分块：当反应性收益超过时间一致性需求时，选择性更新动作序列。

Result: 在广泛的模拟和真实世界机器人操作任务中，该方法显著提高了生成行为克隆的性能。

Conclusion: 所提出的自我引导和自适应分块技术有效解决了扩散策略的随机性和延迟响应问题，提升了生成行为克隆的可靠性和实用性。

Abstract: Generative Behavior Cloning (GBC) is a simple yet effective framework for
robot learning, particularly in multi-task settings. Recent GBC methods often
employ diffusion policies with open-loop (OL) control, where actions are
generated via a diffusion process and executed in multi-step chunks without
replanning. While this approach has demonstrated strong success rates and
generalization, its inherent stochasticity can result in erroneous action
sampling, occasionally leading to unexpected task failures. Moreover, OL
control suffers from delayed responses, which can degrade performance in noisy
or dynamic environments. To address these limitations, we propose two novel
techniques to enhance the consistency and reactivity of diffusion policies: (1)
self-guidance, which improves action fidelity by leveraging past observations
and implicitly promoting future-aware behavior; and (2) adaptive chunking,
which selectively updates action sequences when the benefits of reactivity
outweigh the need for temporal consistency. Extensive experiments show that our
approach substantially improves GBC performance across a wide range of
simulated and real-world robotic manipulation tasks. Our code is available at
https://github.com/junhyukso/SGAC

</details>


### [87] [Learning Robust Agile Flight Control with Stability Guarantees](https://arxiv.org/abs/2510.12611)
*Lukas Pries,Markus Ryll*

Main category: cs.RO

TL;DR: 提出了一种用于敏捷飞行控制的神经增强反馈控制器，结合现有控制范式的优势，提供稳定性保证和高计算效率。


<details>
  <summary>Details</summary>
Motivation: 在高速敏捷四旋翼飞行中，需要在平台操作极限下实现精确轨迹跟踪，控制器必须处理执行器约束、抗干扰且计算高效。

Method: 采用神经增强反馈控制器，统一现有控制范式的优势，具有非线性反馈结构和高计算效率。

Result: 控制器能够准确跟踪超出执行器可行性的高攻击性轨迹，在强干扰环境下保持鲁棒性和跟踪性能，无需训练增强或微调即可直接部署到真实平台。

Conclusion: 该控制器在仿真中学习快速稳定，具有通用稳定性保证，能够有效应对敏捷飞行控制中的挑战。

Abstract: In the evolving landscape of high-speed agile quadrotor flight, achieving
precise trajectory tracking at the platform's operational limits is paramount.
Controllers must handle actuator constraints, exhibit robustness to
disturbances, and remain computationally efficient for safety-critical
applications. In this work, we present a novel neural-augmented feedback
controller for agile flight control. The controller addresses individual
limitations of existing state-of-the-art control paradigms and unifies their
strengths. We demonstrate the controller's capabilities, including the accurate
tracking of highly aggressive trajectories that surpass the feasibility of the
actuators. Notably, the controller provides universal stability guarantees,
enhancing its robustness and tracking performance even in exceedingly
disturbance-prone settings. Its nonlinear feedback structure is highly
efficient enabling fast computation at high update rates. Moreover, the
learning process in simulation is both fast and stable, and the controller's
inherent robustness allows direct deployment to real-world platforms without
the need for training augmentations or fine-tuning.

</details>


### [88] [Robot Learning: A Tutorial](https://arxiv.org/abs/2510.12403)
*Francesco Capuano,Caroline Pascal,Adil Zouitine,Thomas Wolf,Michel Aractingi*

Main category: cs.RO

TL;DR: 本教程全面介绍现代机器人学习，从强化学习和行为克隆基础到通用语言条件模型，提供概念理解和实用工具。


<details>
  <summary>Details</summary>
Motivation: 机器人学习正处于转折点，机器学习快速发展和大规模机器人数据的可用性推动了从传统模型方法向数据驱动学习范式的转变。

Method: 通过强化学习、行为克隆等基础方法，发展到能够跨任务和机器人形态操作的通用语言条件模型，使用lerobot实现示例。

Result: 为研究人员和从业者提供导航现代机器人学习领域的指南，解锁自主系统的前所未有的能力。

Conclusion: 本教程旨在为读者提供必要的概念理解和实用工具，以促进机器人学习的发展，并配有现成的实现示例。

Abstract: Robot learning is at an inflection point, driven by rapid advancements in
machine learning and the growing availability of large-scale robotics data.
This shift from classical, model-based methods to data-driven, learning-based
paradigms is unlocking unprecedented capabilities in autonomous systems. This
tutorial navigates the landscape of modern robot learning, charting a course
from the foundational principles of Reinforcement Learning and Behavioral
Cloning to generalist, language-conditioned models capable of operating across
diverse tasks and even robot embodiments. This work is intended as a guide for
researchers and practitioners, and our goal is to equip the reader with the
conceptual understanding and practical tools necessary to contribute to
developments in robot learning, with ready-to-use examples implemented in
$\texttt{lerobot}$.

</details>


### [89] [Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning](https://arxiv.org/abs/2510.12684)
*Alvaro Belmonte-Baeza,Miguel Cazorla,Gabriel J. García,Carlos J. Pérez-Del-Pulgar,Jorge Pomares*

Main category: cs.RO

TL;DR: 提出用于月球环境的四足移动机械臂约束强化学习框架，集成全身运动与操作能力，满足碰撞避免、动态稳定性和能效等安全约束，在月球重力条件下实现精确6D末端执行器姿态跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统轮式机器人在非结构化和陡峭地形中的局限性促使采用腿式机器人，其具有更好的移动性和适应性，适合在月球恶劣环境中建立永久基地的需求。

Method: 采用约束强化学习框架，集成全身运动与操作能力，明确处理碰撞避免、动态稳定性和功率效率等关键安全约束，适应月球特定条件如低重力和不规则地形。

Result: 实现了精确的6D任务空间末端执行器姿态跟踪，平均位置精度4厘米，方向精度8.1度，系统始终遵守软硬约束，在月球重力条件下表现出自适应行为。

Conclusion: 该工作有效桥接了自适应学习与关键任务安全需求，为未来月球任务的先进自主机器人探索者铺平了道路。

Abstract: Robotics plays a pivotal role in planetary science and exploration, where
autonomous and reliable systems are crucial due to the risks and challenges
inherent to space environments. The establishment of permanent lunar bases
demands robotic platforms capable of navigating and manipulating in the harsh
lunar terrain. While wheeled rovers have been the mainstay for planetary
exploration, their limitations in unstructured and steep terrains motivate the
adoption of legged robots, which offer superior mobility and adaptability. This
paper introduces a constrained reinforcement learning framework designed for
autonomous quadrupedal mobile manipulators operating in lunar environments. The
proposed framework integrates whole-body locomotion and manipulation
capabilities while explicitly addressing critical safety constraints, including
collision avoidance, dynamic stability, and power efficiency, in order to
ensure robust performance under lunar-specific conditions, such as reduced
gravity and irregular terrain. Experimental results demonstrate the framework's
effectiveness in achieving precise 6D task-space end-effector pose tracking,
achieving an average positional accuracy of 4 cm and orientation accuracy of
8.1 degrees. The system consistently respects both soft and hard constraints,
exhibiting adaptive behaviors optimized for lunar gravity conditions. This work
effectively bridges adaptive learning with essential mission-critical safety
requirements, paving the way for advanced autonomous robotic explorers for
future lunar missions.

</details>


### [90] [M3D-skin: Multi-material 3D-printed Tactile Sensor with Hierarchical Infill Structures for Pressure Sensing](https://arxiv.org/abs/2510.12419)
*Shunnosuke Yoshimura,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 提出了一种名为M3D-skin的触觉传感器，利用多材料FDM 3D打印机的填充图案作为传感原理，易于制造且具有高通用性。


<details>
  <summary>Details</summary>
Motivation: 如果触觉传感器能够更容易地制造和集成，其应用范围将进一步扩大。

Method: 使用导电和非导电柔性长丝创建具有特定填充图案的分层结构，柔性分层结构在压力下变形导致电阻变化，从而获取触觉信息。

Result: 测量了分层结构修改对传感器特性的影响，展示了多瓦片传感器的制造和使用，并在足底运动模式测量、机器人手集成和触觉机器人操作等应用中验证了有效性。

Conclusion: 通过实验验证了所提出的触觉传感器的有效性。

Abstract: Tactile sensors have a wide range of applications, from utilization in
robotic grippers to human motion measurement. If tactile sensors could be
fabricated and integrated more easily, their applicability would further
expand. In this study, we propose a tactile sensor-M3D-skin-that can be easily
fabricated with high versatility by leveraging the infill patterns of a
multi-material fused deposition modeling (FDM) 3D printer as the sensing
principle. This method employs conductive and non-conductive flexible filaments
to create a hierarchical structure with a specific infill pattern. The flexible
hierarchical structure deforms under pressure, leading to a change in
electrical resistance, enabling the acquisition of tactile information. We
measure the changes in characteristics of the proposed tactile sensor caused by
modifications to the hierarchical structure. Additionally, we demonstrate the
fabrication and use of a multi-tile sensor. Furthermore, as applications, we
implement motion pattern measurement on the sole of a foot, integration with a
robotic hand, and tactile-based robotic operations. Through these experiments,
we validate the effectiveness of the proposed tactile sensor.

</details>


### [91] [A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation](https://arxiv.org/abs/2510.12477)
*Gaoyuan Liu,Joris de Winter,Kelly Merckaert,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 提出一种混合强化学习规划框架，结合交互式运动规划器和RL任务规划器，在HRC环境中平衡安全性和效率


<details>
  <summary>Details</summary>
Motivation: 在HRC环境中，安全机制通常阻碍任务效率，人类干预会导致机器人备份运动和目标失败，频繁的运动重规划会增加计算负载和失败几率

Method: 使用RL任务规划器选择统计上安全高效的任务序列，结合运动规划器通过检测人体手臂运动来保持任务执行过程无碰撞

Result: 框架在仿真和真实机器人上验证，相比硬编码方法，能响应不确定人体运动、减少失败目标命令重复次数、降低重规划请求总数

Conclusion: 所提规划框架能有效平衡HRC环境中的安全性和效率问题

Abstract: In a Human-Robot Cooperation (HRC) environment, safety and efficiency are the
two core properties to evaluate robot performance. However, safety mechanisms
usually hinder task efficiency since human intervention will cause backup
motions and goal failures of the robot. Frequent motion replanning will
increase the computational load and the chance of failure. In this paper, we
present a hybrid Reinforcement Learning (RL) planning framework which is
comprised of an interactive motion planner and a RL task planner. The RL task
planner attempts to choose statistically safe and efficient task sequences
based on the feedback from the motion planner, while the motion planner keeps
the task execution process collision-free by detecting human arm motions and
deploying new paths when the previous path is not valid anymore. Intuitively,
the RL agent will learn to avoid dangerous tasks, while the motion planner
ensures that the chosen tasks are safe. The proposed framework is validated on
the cobot in both simulation and the real world, we compare the planner with
hard-coded task motion planning methods. The results show that our planning
framework can 1) react to uncertain human motions at both joint and task
levels; 2) reduce the times of repeating failed goal commands; 3) reduce the
total number of replanning requests.

</details>


### [92] [Fast Visuomotor Policy for Robotic Manipulation](https://arxiv.org/abs/2510.12483)
*Jingkai Jia,Tong Yang,Xueyao Chen,Chenhuan Liu,Wenqiang Zhang*

Main category: cs.RO

TL;DR: 提出了一种名为Energy Policy的快速有效机器人操作策略框架，专为高频任务和资源受限系统设计，能够单次前向传播预测多模态动作，实现高速高精度操作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人策略在处理高频任务和资源受限系统时存在效率问题，需要一种能够同时实现高速推理和多模态动作预测的解决方案。

Method: 基于两个核心组件：1) 采用能量分数作为学习目标以促进多模态动作建模；2) 引入能量MLP来实现该目标，同时保持架构简单高效。

Result: 在仿真环境和真实机器人任务中的实验表明，Energy Policy在达到或超越最先进操作方法性能的同时，显著降低了计算开销。在MimicGen基准测试中，以更快的推理速度实现了更优性能。

Conclusion: Energy Policy是一个高效的多模态动作预测框架，特别适合高频机器人操作任务，在保持高性能的同时大幅提升了计算效率。

Abstract: We present a fast and effective policy framework for robotic manipulation,
named Energy Policy, designed for high-frequency robotic tasks and
resource-constrained systems. Unlike existing robotic policies, Energy Policy
natively predicts multimodal actions in a single forward pass, enabling
high-precision manipulation at high speed. The framework is built upon two core
components. First, we adopt the energy score as the learning objective to
facilitate multimodal action modeling. Second, we introduce an energy MLP to
implement the proposed objective while keeping the architecture simple and
efficient. We conduct comprehensive experiments in both simulated environments
and real-world robotic tasks to evaluate the effectiveness of Energy Policy.
The results show that Energy Policy matches or surpasses the performance of
state-of-the-art manipulation methods while significantly reducing
computational overhead. Notably, on the MimicGen benchmark, Energy Policy
achieves superior performance with at a faster inference compared to existing
approaches.

</details>


### [93] [Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge](https://arxiv.org/abs/2510.12509)
*Gaoyuan Liu,Bas Boom,Naftali Slob,Yuri Durodié,Ann Nowé,Bram Vanderborght*

Main category: cs.RO

TL;DR: 本文提出了一种用于果园修剪的机器人行为规划方法，解决了在复杂碰撞环境中高维机械臂的多层次规划问题。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究主要关注感知挑战，但修剪操作中的复杂规划和控制问题往往被忽视，特别是在关节空间和笛卡尔空间中引导末端执行器穿过复杂树枝的规划。

Method: 提出了一个综合的修剪工作流程，包括感知、建模和整体规划，研究了系统的内在冗余性，并制定了修剪场景下的高维机械臂规划问题。

Result: 实验表明，更全面的规划方法能显著提高机器人操纵器的性能，并在真实机器人上实现了所提出的工作流程。

Conclusion: 这项工作补充了先前关于机器人修剪的研究，并为修剪应用中的规划研究和发展提供了动力。

Abstract: Pruning is an essential agricultural practice for orchards. Proper pruning
can promote healthier growth and optimize fruit production throughout the
orchard's lifespan. Robot manipulators have been developed as an automated
solution for this repetitive task, which typically requires seasonal labor with
specialized skills. While previous research has primarily focused on the
challenges of perception, the complexities of manipulation are often
overlooked. These challenges involve planning and control in both joint and
Cartesian spaces to guide the end-effector through intricate, obstructive
branches. Our work addresses the behavior planning challenge for a robotic
pruning system, which entails a multi-level planning problem in environments
with complex collisions. In this paper, we formulate the planning problem for a
high-dimensional robotic arm in a pruning scenario, investigate the system's
intrinsic redundancies, and propose a comprehensive pruning workflow that
integrates perception, modeling, and holistic planning. In our experiments, we
demonstrate that more comprehensive planning methods can significantly enhance
the performance of the robotic manipulator. Finally, we implement the proposed
workflow on a real-world robot. As a result, this work complements previous
efforts on robotic pruning and motivates future research and development in
planning for pruning applications.

</details>


### [94] [Two-stream network-driven vision-based tactile sensor for object feature extraction and fusion perception](https://arxiv.org/abs/2510.12528)
*Muxing Huang,Zibin Chen,Weiliang Xu,Zilan Li,Yuanzhi Zhou,Guoyuan Zhou,Wenjing Chen,Xinming Li*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的触觉系统双流网络特征提取与融合感知策略，通过分布式方法提取物体内外特征，结合深度图和接触力数据，使用CNN提取特征后进行加权融合，显著提升了物体识别精度。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉传感器在提取物体物理属性时会产生大量冗余信息，单维特征提取缺乏有效融合，无法充分表征物体属性，限制了识别精度的提升。

Method: 采用双流网络特征提取和融合策略：一路通过三维重建获取深度图信息，另一路通过测量接触力数据获取硬度信息；使用CNN提取特征后进行加权融合。

Result: 力预测误差0.06N（12N范围内），硬度识别准确率98.0%，形状识别准确率93.75%；融合算法在实际抓取场景中物体识别准确率超过98.5%。

Conclusion: 该方法专注于物体物理属性感知，增强了人工触觉系统从感知到认知的能力，使其能够在具身感知应用中使用。

Abstract: Tactile perception is crucial for embodied intelligent robots to recognize
objects. Vision-based tactile sensors extract object physical attributes
multidimensionally using high spatial resolution; however, this process
generates abundant redundant information. Furthermore, single-dimensional
extraction, lacking effective fusion, fails to fully characterize object
attributes. These challenges hinder the improvement of recognition accuracy. To
address this issue, this study introduces a two-stream network feature
extraction and fusion perception strategy for vision-based tactile systems.
This strategy employs a distributed approach to extract internal and external
object features. It obtains depth map information through three-dimensional
reconstruction while simultaneously acquiring hardness information by measuring
contact force data. After extracting features with a convolutional neural
network (CNN), weighted fusion is applied to create a more informative and
effective feature representation. In standard tests on objects of varying
shapes and hardness, the force prediction error is 0.06 N (within a 12 N
range). Hardness recognition accuracy reaches 98.0%, and shape recognition
accuracy reaches 93.75%. With fusion algorithms, object recognition accuracy in
actual grasping scenarios exceeds 98.5%. Focused on object physical attributes
perception, this method enhances the artificial tactile system ability to
transition from perception to cognition, enabling its use in embodied
perception applications.

</details>


### [95] [Designing Tools with Control Confidence](https://arxiv.org/abs/2510.12630)
*Ajith Anil Meera,Abian Torres,Pablo Lanillos*

Main category: cs.RO

TL;DR: 本文提出了一种考虑控制置信度的自主工具设计框架，通过引入神经启发的控制置信度项来优化工具设计，使机器人设计的工具在环境不确定性下具有更高的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前自主工具设计框架仅依赖性能优化，未考虑代理在重复使用工具时的置信度，而史前人类设计石器工具时会增加对工具的置信度以获得更好的鲁棒性。

Method: 定义任务条件自主手工工具设计优化框架，引入神经启发的控制置信度项到优化过程中，使用基于CMAES的进化优化策略进行工具设计。

Result: 通过机器人臂的严格模拟显示，以控制置信度为目标函数设计的工具在环境不确定性下比纯精度驱动目标具有更高鲁棒性，且在控制扰动下在鲁棒性和目标精度之间提供平衡。

Conclusion: CMAES进化优化策略在自主工具设计中优于其他最先进优化器，能够以最少的迭代次数设计出最优工具。

Abstract: Prehistoric humans invented stone tools for specialized tasks by not just
maximizing the tool's immediate goal-completion accuracy, but also increasing
their confidence in the tool for later use under similar settings. This factor
contributed to the increased robustness of the tool, i.e., the least
performance deviations under environmental uncertainties. However, the current
autonomous tool design frameworks solely rely on performance optimization,
without considering the agent's confidence in tool use for repeated use. Here,
we take a step towards filling this gap by i) defining an optimization
framework for task-conditioned autonomous hand tool design for robots, where
ii) we introduce a neuro-inspired control confidence term into the optimization
routine that helps the agent to design tools with higher robustness. Through
rigorous simulations using a robotic arm, we show that tools designed with
control confidence as the objective function are more robust to environmental
uncertainties during tool use than a pure accuracy-driven objective. We further
show that adding control confidence to the objective function for tool design
provides a balance between the robustness and goal accuracy of the designed
tools under control perturbations. Finally, we show that our CMAES-based
evolutionary optimization strategy for autonomous tool design outperforms other
state-of-the-art optimizers by designing the optimal tool within the fewest
iterations. Code: https://github.com/ajitham123/Tool_design_control_confidence.

</details>


### [96] [Maximal Adaptation, Minimal Guidance: Permissive Reactive Robot Task Planning with Humans in the Loop](https://arxiv.org/abs/2510.12662)
*Oz Gitelson,Satya Prakash Nayak,Ritam Raha,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 提出了一种人机逻辑交互框架，使机器人能够可靠满足时序逻辑任务，同时与追求独立未知任务的人类有效协作。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中机器人需要满足长期任务要求，同时尊重人类自主性并最小化干扰的问题。

Method: 结合最大适应性和最小可调反馈两种能力：最大适应性让机器人在线调整策略以利用人类行为进行合作；最小可调反馈仅在必要时请求人类合作以保证任务进展。

Result: 在真实世界块操作任务和Overcooked-AI基准测试中验证，该方法产生了超越现有方法的丰富涌现合作行为，同时保持强大的形式化保证。

Conclusion: 该框架能够在冲突的人类目标下实现持久机器人任务满足，同时最小化人机干扰并保持人类自主性。

Abstract: We present a novel framework for human-robot \emph{logical} interaction that
enables robots to reliably satisfy (infinite horizon) temporal logic tasks
while effectively collaborating with humans who pursue independent and unknown
tasks. The framework combines two key capabilities: (i) \emph{maximal
adaptation} enables the robot to adjust its strategy \emph{online} to exploit
human behavior for cooperation whenever possible, and (ii) \emph{minimal
tunable feedback} enables the robot to request cooperation by the human online
only when necessary to guarantee progress. This balance minimizes human-robot
interference, preserves human autonomy, and ensures persistent robot task
satisfaction even under conflicting human goals. We validate the approach in a
real-world block-manipulation task with a Franka Emika Panda robotic arm and in
the Overcooked-AI benchmark, demonstrating that our method produces rich,
\emph{emergent} cooperative behaviors beyond the reach of existing approaches,
while maintaining strong formal guarantees.

</details>


### [97] [Reflection-Based Task Adaptation for Self-Improving VLA](https://arxiv.org/abs/2510.12710)
*Baicheng Li,Dong Wu,Zike Yan,Xinchen Liu,Zecui Zeng,Lusong Li,Hongbin Zha*

Main category: cs.RO

TL;DR: 提出Reflective Self-Adaptation框架，通过双路径架构实现VLA模型的快速自主任务适应，包含失败驱动的反思RL和成功驱动的质量引导SFT，在挑战性操作任务中实现更快收敛和更高成功率。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言-动作模型在通用机器人方面取得重大进展，但在现场适应新特定任务时效率低下。虽然强化学习是适应的重要途径，但过程效率低，阻碍快速任务掌握。

Method: 采用双路径架构：1) 失败驱动的反思RL路径，利用VLM因果推理从失败分析自动合成密集奖励函数；2) 成功驱动的质量引导SFT路径，识别并选择性模仿高质量成功轨迹，确保与最终任务目标对齐。

Result: 在挑战性操作任务实验中，该框架相比代表性基线方法实现了更快收敛和更高最终成功率。

Conclusion: 该工作为创建能够高效可靠适应新环境的自改进智能体提供了稳健解决方案。

Abstract: Pre-trained Vision-Language-Action (VLA) models represent a major leap
towards general-purpose robots, yet efficiently adapting them to novel,
specific tasks in-situ remains a significant hurdle. While reinforcement
learning (RL) is a promising avenue for such adaptation, the process often
suffers from low efficiency, hindering rapid task mastery. We introduce
Reflective Self-Adaptation, a framework for rapid, autonomous task adaptation
without human intervention. Our framework establishes a self-improving loop
where the agent learns from its own experience to enhance both strategy and
execution.
  The core of our framework is a dual-pathway architecture that addresses the
full adaptation lifecycle. First, a Failure-Driven Reflective RL pathway
enables rapid learning by using the VLM's causal reasoning to automatically
synthesize a targeted, dense reward function from failure analysis. This
provides a focused learning signal that significantly accelerates policy
exploration. However, optimizing such proxy rewards introduces a potential risk
of "reward hacking," where the agent masters the reward function but fails the
actual task. To counteract this, our second pathway, Success-Driven
Quality-Guided SFT, grounds the policy in holistic success. It identifies and
selectively imitates high-quality successful trajectories, ensuring the agent
remains aligned with the ultimate task goal. This pathway is strengthened by a
conditional curriculum mechanism to aid initial exploration.
  We conduct experiments in challenging manipulation tasks. The results
demonstrate that our framework achieves faster convergence and higher final
success rates compared to representative baselines. Our work presents a robust
solution for creating self-improving agents that can efficiently and reliably
adapt to new environments.

</details>


### [98] [Residual MPC: Blending Reinforcement Learning with GPU-Parallelized Model Predictive Control](https://arxiv.org/abs/2510.12717)
*Se Hwan Jeon,Ho Jae Lee,Seungwoo Hong,Sangbae Kim*

Main category: cs.RO

TL;DR: 提出了一种GPU并行化的残差架构，将MPC和RL在力矩控制层面紧密集成，结合了基于模型控制的解释性和约束处理能力与RL的适应性。


<details>
  <summary>Details</summary>
Motivation: MPC提供可解释、可调的运动控制器，但鲁棒性受限于模型失配和实时计算约束；RL能产生高度鲁棒行为但缺乏可解释性且需要大量奖励工程。

Method: 开发了动力学全身MPC公式，在100Hz频率下并行评估数千个智能体进行RL训练。残差策略学习对MPC输出进行针对性修正。

Result: 相比独立MPC或端到端RL，该方法实现了更高的样本效率、更大的渐近奖励、更广的可跟踪速度命令范围，并能零样本适应未见步态和不平地形。

Conclusion: 基于模型的控制先验作为强偏差，用简单奖励集初始化和引导策略朝向理想行为，成功结合了MPC和RL的优势。

Abstract: Model Predictive Control (MPC) provides interpretable, tunable locomotion
controllers grounded in physical models, but its robustness depends on frequent
replanning and is limited by model mismatch and real-time computational
constraints. Reinforcement Learning (RL), by contrast, can produce highly
robust behaviors through stochastic training but often lacks interpretability,
suffers from out-of-distribution failures, and requires intensive reward
engineering. This work presents a GPU-parallelized residual architecture that
tightly integrates MPC and RL by blending their outputs at the torque-control
level. We develop a kinodynamic whole-body MPC formulation evaluated across
thousands of agents in parallel at 100 Hz for RL training. The residual policy
learns to make targeted corrections to the MPC outputs, combining the
interpretability and constraint handling of model-based control with the
adaptability of RL. The model-based control prior acts as a strong bias,
initializing and guiding the policy towards desirable behavior with a simple
set of rewards. Compared to standalone MPC or end-to-end RL, our approach
achieves higher sample efficiency, converges to greater asymptotic rewards,
expands the range of trackable velocity commands, and enables zero-shot
adaptation to unseen gaits and uneven terrain.

</details>


### [99] [T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping](https://arxiv.org/abs/2510.12724)
*Xin Fei,Zhixuan Xu,Huaicong Fang,Tianrui Zhang,Lin Shao*

Main category: cs.RO

TL;DR: T(R,O) Grasp是一个基于扩散模型的灵巧抓取框架，通过统一的图表示和高效的逆运动学求解器，实现了快速、多样化的多机器人手抓取生成。


<details>
  <summary>Details</summary>
Motivation: 灵巧抓取在机器人学中面临高维状态和动作空间的复杂性挑战，需要开发能够高效生成准确且多样化抓取的方法。

Method: 提出T(R,O)图表示法统一建模机器人手与物体间的空间变换关系，结合图扩散模型和高效逆运动学求解器，支持无条件和条件抓取合成。

Result: 在多种灵巧手上平均成功率94.83%，推理速度0.21秒，在NVIDIA A100 GPU上每秒生成41个抓取，显著优于现有基线方法，且内存消耗大幅降低。

Conclusion: 该方法具有鲁棒性和跨具身泛化能力，高推理速度支持闭环灵巧操作，有望成为灵巧抓取的基础模型。

Abstract: Dexterous grasping remains a central challenge in robotics due to the
complexity of its high-dimensional state and action space. We introduce T(R,O)
Grasp, a diffusion-based framework that efficiently generates accurate and
diverse grasps across multiple robotic hands. At its core is the T(R,O) Graph,
a unified representation that models spatial transformations between robotic
hands and objects while encoding their geometric properties. A graph diffusion
model, coupled with an efficient inverse kinematics solver, supports both
unconditioned and conditioned grasp synthesis. Extensive experiments on a
diverse set of dexterous hands show that T(R,O) Grasp achieves average success
rate of 94.83%, inference speed of 0.21s, and throughput of 41 grasps per
second on an NVIDIA A100 40GB GPU, substantially outperforming existing
baselines. In addition, our approach is robust and generalizable across
embodiments while significantly reducing memory consumption. More importantly,
the high inference speed enables closed-loop dexterous manipulation,
underscoring the potential of T(R,O) Grasp to scale into a foundation model for
dexterous grasping.

</details>


### [100] [HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions](https://arxiv.org/abs/2510.12733)
*Hang Yu,Julian Jordan,Julian Schmidt,Silvan Lindner,Alessandro Canevaro,Wilhelm Stork*

Main category: cs.RO

TL;DR: HYPE是一种混合运动规划器，通过将学习到的多模态轨迹提案作为启发式先验集成到蒙特卡洛树搜索中，简化了成本函数设计，实现了复杂城市环境中安全可解释的双向多智能体交互规划。


<details>
  <summary>Details</summary>
Motivation: 复杂城市环境中的运动规划需要处理双向多智能体交互，现有方法依赖精心设计的成本函数来编码期望的车辆行为，这在考虑广泛复杂场景时极具挑战性。

Method: 提出HYPE混合规划器：1）使用学习到的提案模型生成多模态轨迹提案作为启发式先验；2）集成到蒙特卡洛树搜索中进行细化；3）引入自我条件占用预测模型来建模双向交互。

Result: 在nuPlan和DeepUrban大规模真实世界基准测试中，HYPE实现了最先进的性能，特别是在安全性和适应性方面表现优异。

Conclusion: HYPE通过提案驱动的引导显著简化了细化过程中的成本函数设计，仅需最小化的基于网格的成本项，就能在复杂城市环境中实现安全可解释的运动规划。

Abstract: Safe and interpretable motion planning in complex urban environments needs to
reason about bidirectional multi-agent interactions. This reasoning requires to
estimate the costs of potential ego driving maneuvers. Many existing planners
generate initial trajectories with sampling-based methods and refine them by
optimizing on learned predictions of future environment states, which requires
a cost function that encodes the desired vehicle behavior. Designing such a
cost function can be very challenging, especially if a wide range of complex
urban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego
proposal-conditioned predictions, a planner that integrates multimodal
trajectory proposals from a learned proposal model as heuristic priors into a
Monte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions,
we introduce an ego-conditioned occupancy prediction model, enabling
consistent, scene-aware reasoning. Our design significantly simplifies cost
function design in refinement by considering proposal-driven guidance,
requiring only minimalistic grid-based cost terms. Evaluations on large-scale
real-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves
state-of-the-art performance, especially in safety and adaptability.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [101] [Beyond Test Scores: How Academic Rank Shapes Long-Term Outcomes](https://arxiv.org/abs/2510.11973)
*Emilia Del Bono,Angus Holford,Tommaso Sartori*

Main category: econ.GN

TL;DR: 使用1962年苏格兰阿伯丁所有小学生的数据，研究发现学业排名对学术表现、非认知发展、父母投资和长期结果有显著因果影响。


<details>
  <summary>Details</summary>
Motivation: 探究学业排名对学生发展的因果影响，特别是在学术表现、非认知技能和长期人生结果方面。

Method: 利用同伴群体构成的准随机变异，估计排名对高风险的11+考试表现、非认知发展、父母投资和40年后长期结果的因果影响。

Result: 较高排名显著提高11+考试成绩，增强内化技能（自我概念和信心相关特质），40年后调查显示排名提高教育程度（尤其女孩），但收入增长仅出现在男孩中。

Conclusion: 排名效应主要通过学生自我认知运作，长期效应存在性别差异，反映了当时女性在高等教育和技能就业方面的历史障碍。

Abstract: We study the effects of academic rank using data on the entire population of
children enrolled in primary schools in Aberdeen, Scotland, in 1962. Exploiting
quasi-random variation in peer group composition, we estimate the causal impact
of rank on academic performance, noncognitive development, parental investment,
and long-term outcomes. Higher rank improves achievement on the high-stakes
eleven-plus examination and strengthens internalizing skills (traits related to
self-concept and confidence), suggesting that rank effects operate primarily
through students' self-perception. Using a follow-up survey conducted forty
years later, we find that rank raises educational attainment, particularly for
girls, while long-term income gains emerge only among boys. The gender gap in
long-run effects likely reflects historical barriers to women's access to
higher education and skilled employment during this period.

</details>


### [102] [Generative AI and Firm Productivity: Field Experiments in Online Retail](https://arxiv.org/abs/2510.12049)
*Lu Fang,Zhe Yuan,Kaifu Zhang,Dante Donati,Miklos Sarvary*

Main category: econ.GN

TL;DR: 通过大规模随机实验发现，生成式AI在跨境电商平台能显著提升销售和全要素生产率，特别是对小型卖家和新用户效果更明显。


<details>
  <summary>Details</summary>
Motivation: 量化生成式AI对企业生产力的实际影响，填补大规模因果证据的空白。

Method: 在领先跨境电商平台进行大规模随机现场实验，涉及数百万用户和产品，将GenAI集成到7个面向消费者的业务流程中。

Result: GenAI采用显著增加销售额（效果从0%到16.3%），四个有效应用的年增量价值约为每人5美元，主要通过提高转化率实现。

Conclusion: 生成式AI在在线零售中具有显著的生产力效应，展现了其即时价值和更广泛潜力。

Abstract: We quantify the impact of Generative Artificial Intelligence (GenAI) on firm
productivity through a series of large-scale randomized field experiments
involving millions of users and products at a leading cross-border online
retail platform. Over six months in 2023-2024, GenAI-based enhancements were
integrated into seven consumer-facing business workflows. We find that GenAI
adoption significantly increases sales, with treatment effects ranging from 0\%
to 16.3\%, depending on GenAI's marginal contribution relative to existing firm
practices. Because inputs and prices were held constant across experimental
arms, these gains map directly into total factor productivity improvements.
Across the four GenAI applications with positive effects, the implied annual
incremental value is approximately \$5 per consumer-an economically meaningful
impact given the retailer's scale and the early stage of GenAI adoption. The
primary mechanism operates through higher conversion rates, consistent with
GenAI reducing frictions in the marketplace and improving consumer experience.
We also document substantial heterogeneity: smaller and newer sellers, as well
as less experienced consumers, exhibit disproportionately larger gains. Our
findings provide novel, large-scale causal evidence on the productivity effects
of GenAI in online retail, highlighting both its immediate value and broader
potential.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [103] [Estimating Variances for Causal Panel Data Estimators](https://arxiv.org/abs/2510.11841)
*Alexander Almeida,Susan Athey,Guido Imbens,Eva Lestant,Alexia Olaizola*

Main category: econ.EM

TL;DR: 本文研究了面板数据中的方差估计器，提出了一个比较框架，发现现有估计器在平均上有效但统计功效差异显著，并开发了一个新的能灵活处理双维度异方差性的方差估计器。


<details>
  <summary>Details</summary>
Motivation: 面板数据模型研究激增，但对其估计器精度的量化关注不足，现有方差估计器的相对优劣尚不明确。

Method: 建立了一个通用框架来比较不同方差估计器，将三种常用方法重新解释为在可交换性假设下针对不同条件方差，并提出新的能灵活处理单位和时间维度异方差性的方差估计器。

Result: 发现所考虑的估计器在平均上都是有效的，但其统计功效根据数据的异方差结构差异显著，新提出的估计器在现实面板数据设置中提供了更优的统计功效。

Conclusion: 面板数据方差估计器的性能高度依赖于异方差结构，新提出的双维度异方差调整估计器在实际应用中表现更优。

Abstract: This paper studies variance estimators in panel data settings. There has been
a recent surge in research on panel data models with a number of new estimators
proposed. However, there has been less attention paid to the quantification of
the precision of these estimators. Of the variance estimators that have been
proposed, their relative merits are not well understood. In this paper we
develop a common framework for comparing some of the proposed variance
estimators for generic point estimators. We reinterpret three commonly used
approaches as targeting different conditional variances under an
exchangeability assumption. We find that the estimators we consider are all
valid on average, but that their performance in terms of power differs
substantially depending on the heteroskedasticity structure of the data.
Building on these insights, we propose a new variance estimator that flexibly
accounts for heteroskedasticity in both the unit and time dimensions, and
delivers superior statistical power in realistic panel data settings.

</details>


### [104] [L2-relaxation for Economic Prediction](https://arxiv.org/abs/2510.12183)
*Zhentao Shi,Yishu Wang*

Main category: econ.EM

TL;DR: 提出L2松弛方法，使用超过样本量的回归器集合进行经济预测和政策评估，在面板数据框架下建立平均处理效应的推断，并扩展到多处理单元场景。


<details>
  <summary>Details</summary>
Motivation: 解决高维密集回归模型中高度相关协变量的问题，改进传统面板数据方法在短后处理期和多处理单元情况下的局限性。

Method: L2松弛方法估计回归系数和外推样本外结果，基于潜在因子结构构建密集回归模型，扩展面板数据方法支持多处理单元。

Result: 蒙特卡洛模拟显示该方法在样本外预测和政策评估方面具有优异的有限样本性能，两个实证案例验证了方法的有效性。

Conclusion: L2松弛方法为高维经济预测和政策评估提供了有效工具，特别适用于多处理单元和短后处理期的复杂场景。

Abstract: We leverage an ensemble of many regressors, the number of which can exceed
the sample size, for economic prediction. An underlying latent factor structure
implies a dense regression model with highly correlated covariates. We propose
the L2-relaxation method for estimating the regression coefficients and
extrapolating the out-of-sample (OOS) outcomes. This framework can be applied
to policy evaluation using the panel data approach (PDA), where we further
establish inference for the average treatment effect. In addition, we extend
the traditional single unit setting in PDA to allow for many treated units with
a short post-treatment period. Monte Carlo simulations demonstrate that our
approach exhibits excellent finite sample performance for both OOS prediction
and policy evaluation. We illustrate our method with two empirical examples:
(i) predicting China's producer price index growth rate and evaluating the
effect of real estate regulations, and (ii) estimating the impact of Brexit on
the stock returns of British and European companies.

</details>


### [105] [Optimal break tests for large linear time series models](https://arxiv.org/abs/2510.12262)
*Abhimanyu Gupta,Myung Hwan Seo*

Main category: econ.EM

TL;DR: 开发了一类针对无限阶和增长阶时间序列回归模型中未知断点结构变化的最优检验方法，适用于AR(∞)、多变量线性回归和非参数回归等场景。


<details>
  <summary>Details</summary>
Motivation: 现有结构断点检验方法主要针对固定维度模型，无法处理无限阶或增长阶时间序列回归模型中的断点检测问题，特别是在零假设下存在识别失败的情况。

Method: 在辅助i.i.d.高斯误差假设下推导平均功效最优检验，建立增长维度下的指数检验；放宽假设后建立随机过程的功能中心极限定理，并针对高阶序列依赖项和有限样本偏差进行稳健化处理。

Result: 蒙特卡洛研究和实际数据实证示例表明该方法具有优异的性能和实际相关性。

Conclusion: 成功开发了能够处理无限和增长阶时间序列回归模型中未知断点结构变化的最优检验方法，在理论和实证层面均表现出色。

Abstract: We develop a class of optimal tests for a structural break occurring at an
unknown date in infinite and growing-order time series regression models, such
as AR($\infty$), linear regression with increasingly many covariates, and
nonparametric regression. Under an auxiliary i.i.d. Gaussian error assumption,
we derive an average power optimal test, establishing a growing-dimensional
analog of the exponential tests of Andrews and Ploberger (1994) to handle
identification failure under the null hypothesis of no break. Relaxing the
i.i.d. Gaussian assumption to a more general dependence structure, we establish
a functional central limit theorem for the underlying stochastic processes,
which features an extra high-order serial dependence term due to the growing
dimension. We robustify our test both against this term and finite sample bias
and illustrate its excellent performance and practical relevance in a Monte
Carlo study and a real data empirical example.

</details>


### [106] [Nonparametric Identification and Estimation of Spatial Treatment Effect Boundaries: Evidence from 42 Million Pollution Observations](https://arxiv.org/abs/2510.12289)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 开发了一个非参数框架来识别和估计地理溢出效应中的空间边界，使用4200万卫星观测数据发现非参数核回归比参数化指数衰减假设平均减少1.0个百分点预测误差。


<details>
  <summary>Details</summary>
Motivation: 大气扩散理论预测的理想化指数衰减假设（稳定风、均匀大气、平坦地形）在实践中系统性地被违反，需要更灵活的方法来准确估计污染物的空间边界。

Method: 建立弱平滑性和单调性条件下的非参数空间边界识别，提出基于核的估计器与数据驱动带宽选择，并推导渐近理论进行推断。

Result: 非参数核回归比参数化指数衰减假设平均减少1.0个百分点预测误差，在政策相关距离上改善最大：10公里处2.8个百分点（近源影响），100公里处3.7个百分点（长距离传输）。参数方法系统性地低估近源浓度而高估长距离衰减。

Conclusion: 灵活的数据驱动空间方法在环境政策应用中显著优于限制性参数假设，COVID-19自然实验验证了框架的时间敏感性。

Abstract: This paper develops a nonparametric framework for identifying and estimating
spatial boundaries of treatment effects in settings with geographic spillovers.
While atmospheric dispersion theory predicts exponential decay of pollution
under idealized assumptions, these assumptions -- steady winds, homogeneous
atmospheres, flat terrain -- are systematically violated in practice. I
establish nonparametric identification of spatial boundaries under weak
smoothness and monotonicity conditions, propose a kernel-based estimator with
data-driven bandwidth selection, and derive asymptotic theory for inference.
Using 42 million satellite observations of NO$_2$ concentrations near coal
plants (2019-2021), I find that nonparametric kernel regression reduces
prediction errors by 1.0 percentage point on average compared to parametric
exponential decay assumptions, with largest improvements at policy-relevant
distances: 2.8 percentage points at 10 km (near-source impacts) and 3.7
percentage points at 100 km (long-range transport). Parametric methods
systematically underestimate near-source concentrations while overestimating
long-range decay. The COVID-19 pandemic provides a natural experiment
validating the framework's temporal sensitivity: NO$_2$ concentrations dropped
4.6\% in 2020, then recovered 5.7\% in 2021. These results demonstrate that
flexible, data-driven spatial methods substantially outperform restrictive
parametric assumptions in environmental policy applications.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [107] [Multi-objective Bayesian optimization for blocking in extreme value analysis and its application in additive manufacturing](https://arxiv.org/abs/2510.11960)
*Shehzaib Irfan,Nabeel Ahmad,Alexander Vinel,Daniel F. Silva,Shuai Shao,Nima Shamsaei,Jia Liu*

Main category: stat.AP

TL;DR: 提出了一种新的贝叶斯框架MOBO-D*，用于自动选择极值理论中的块大小，以优化极端事件的建模和预测。


<details>
  <summary>Details</summary>
Motivation: 极值理论中块大小的自动选择（无需专家输入）仍然是一个开放挑战，这对于系统可靠性评估和风险管理至关重要。

Method: 使用多目标贝叶斯优化（MOBO-D*）框架，优化两个目标：极端事件分布的拟合优度和极端事件的准确预测，构建帕累托前沿来选择最优块大小。

Result: 在增材制造领域的真实案例研究和合成数据集上，MOBO-D*优于多个基准方法，并能自然扩展到高维情况。

Conclusion: MOBO-D*在需要重复自动选择块大小的应用中（如优化或同时分析多个数据集）是一个有前景的方法。

Abstract: Extreme value theory (EVT) is well suited to model extreme events, such as
floods, heatwaves, or mechanical failures, which is required for reliability
assessment of systems across multiple domains for risk management and loss
prevention. The block maxima (BM) method, a particular approach within EVT,
starts by dividing the historical observations into blocks. Then the sample of
the maxima for each block can be shown, under some assumptions, to converge to
a known class of distributions, which can then be used for analysis. The
question of automatic (i.e., without explicit expert input) selection of the
block size remains an open challenge. This work proposes a novel Bayesian
framework, namely, multi-objective Bayesian optimization (MOBO-D*), to optimize
BM blocking for accurate modeling and prediction of extremes in EVT. MOBO-D*
formulates two objectives: goodness-of-fit of the distribution of extreme
events and the accurate prediction of extreme events to construct an estimated
Pareto front for optimal blocking choices. The efficacy of the proposed
framework is illustrated by applying it to a real-world case study from the
domain of additive manufacturing as well as a synthetic dataset. MOBO-D*
outperforms a number of benchmarks and can be naturally extended to
high-dimensional cases. The computational experiments show that it can be a
promising approach in applications that require repeated automated block size
selection, such as optimization or analysis of many datasets at once.

</details>


### [108] [The Living Forecast: Evolving Day-Ahead Predictions into Intraday Reality](https://arxiv.org/abs/2510.12271)
*Kutay Bölat,Peter Palensky,Simon Tindemans*

Main category: stat.AP

TL;DR: 提出一种贝叶斯更新机制，将全概率日前预测转换为日内预测，无需重新训练或推理，通过观测数据更新高斯混合分布，提高预测精度达25%。


<details>
  <summary>Details</summary>
Motivation: 准确的日内预测对电力系统运行至关重要，能够补充逐渐失效的日前预测，需要一种无需重新训练的高效实时预测方法。

Method: 使用贝叶斯更新机制，基于条件变分自编码器的预测器输出高斯混合分布，通过观测测量值进行条件更新，保持概率结构完整性。

Result: 在家庭用电和光伏发电数据集上的实验表明，该方法在似然、样本、分位数和点预测指标上提高精度达25%，在时间相关性强的时段效果最佳。

Conclusion: 该方法为现代电力系统提供了一个理论基础的日内预测框架，计算高效且适合实时应用。

Abstract: Accurate intraday forecasts are essential for power system operations,
complementing day-ahead forecasts that gradually lose relevance as new
information becomes available. This paper introduces a Bayesian updating
mechanism that converts fully probabilistic day-ahead forecasts into intraday
forecasts without retraining or re-inference. The approach conditions the
Gaussian mixture output of a conditional variational autoencoder-based
forecaster on observed measurements, yielding an updated distribution for the
remaining horizon that preserves its probabilistic structure. This enables
consistent point, quantile, and ensemble forecasts while remaining
computationally efficient and suitable for real-time applications. Experiments
on household electricity consumption and photovoltaic generation datasets
demonstrate that the proposed method improves forecast accuracy up to 25%
across likelihood-, sample-, quantile-, and point-based metrics. The largest
gains occur in time steps with strong temporal correlation to observed data,
and the use of pattern dictionary-based covariance structures further enhances
performance. The results highlight a theoretically grounded framework for
intraday forecasting in modern power systems.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [109] [Multi-objective Bayesian Optimization with Human-in-the-Loop for Flexible Neuromorphic Electronics Fabrication](https://arxiv.org/abs/2510.11727)
*Benius Dunn,Javier Meza-Arroyo,Armi Tiihonen,Mark Lee,Julia W. P. Hsu*

Main category: cs.ET

TL;DR: 使用多目标贝叶斯优化和人在回路框架优化光子固化工艺，制备用于神经形态计算的柔性金属氧化物电容器


<details>
  <summary>Details</summary>
Motivation: 金属氧化物材料在柔性神经形态电子器件中具有潜力，但氧化物与聚合物基板之间的不相容性导致加工困难。传统网格搜索方法无法有效优化光子固化工艺参数。

Method: 应用多目标贝叶斯优化(MOBO)确定光子固化条件，优化电容-频率色散和低漏电流之间的权衡。开发人在回路(HITL)框架将失败实验纳入机器学习工作流。

Result: 该框架通过减少所需实验轮次加速优化过程。通过Shapley加性解释分析不同输入参数的重要性，获得帕累托最优条件以调控介电性能。

Conclusion: 结合MOBO和HITL反馈的框架可适应各种多目标实验问题，特别是具有相互关联输入和高实验失败率的情况，为机器学习模型生成可用结果。

Abstract: Neuromorphic computing hardware enables edge computing and can be implemented
in flexible electronics for novel applications. Metal oxide materials are
promising candidates for fabricating flexible neuromorphic electronics, but
suffer from processing constraints due to the incompatibilities between oxides
and polymer substrates. In this work, we use photonic curing to fabricate
flexible metal-insulator-metal capacitors with solution-processible aluminum
oxide dielectric tailored for neuromorphic applications. Because photonic
curing outcomes depend on many input parameters, identifying an optimal
processing condition through a traditional grid-search approach is unfeasible.
Here, we apply multi-objective Bayesian optimization (MOBO) to determine
photonic curing conditions that optimize the trade-off between desired
electrical properties of large capacitance-frequency dispersion and low leakage
current. Furthermore, we develop a human-in-the-loop (HITL) framework for
incorporating failed experiments into the MOBO machine learning workflow,
demonstrating that this framework accelerates optimization by reducing the
number of experimental rounds required. Once optimization is concluded, we
analyze different Pareto-optimal conditions to tune the dielectrics properties
and provide insight into the importance of different inputs through Shapley
Additive exPlanations analysis. The demonstrated framework of combining MOBO
with HITL feedback can be adapted to a wide range of multi-objective
experimental problems that have interconnected inputs and high experimental
failure rates to generate usable results for machine learning models.

</details>


### [110] [Wireless Sensing of Temperature, Strain and Crack Growth in 3D-Printed Metal Structures via Magnetoelastic and Thermomagnetic Inclusions](https://arxiv.org/abs/2510.11730)
*Connor G. McMahan,Gavin Chang,Raymond Nguyen,Souren Soukiazian,David A. Smith,Tobias Schaedler,David Shahan*

Main category: cs.ET

TL;DR: 首次在3D打印金属结构中实现无线应变和温度传感，使用标准电磁检测硬件，为基于准确损伤评估的按需维护提供路径。


<details>
  <summary>Details</summary>
Motivation: 建立基于准确损伤评估的按需零件维护路径，替代定期维护拆解，延长在恶劣环境中运行结构的服务间隔。

Method: 将磁弹性和热磁性材料封装在微管中，在增材制造过程中嵌入传感元件。机械和热刺激影响嵌入材料的磁导率，从而调制放置在打印零件表面或附近的线圈阻抗。

Result: 应变传感精度达±27×10⁻⁶，应变范围至少6×10⁻⁴；温度传感精度±0.75°C，温度范围70°C，置信区间均为95%。成功检测塑性开始和疲劳裂纹增长，比临界失效提前数千个周期。

Conclusion: 将无损涡流损伤检测扩展到金属结构内准确、实时的应变和温度监测。

Abstract: In this study, we demonstrate the first realization of wireless strain and
temperature sensing within 3D-printed metallic structures using standard
electromagnetic inspection hardware. This establishes a path toward need-based
parts maintenance driven by accurate damage assessments instead of relying on
regularly scheduled maintenance teardowns, extending the service intervals of
structures operating in harsh environments. To this end, we encapsulate
magnetoelastic and thermomagnetic materials inside microtubes and embed the
sensing elements during additive manufacturing. Mechanical and thermal stimuli
affect the magnetic permeability of the embedded materials, which modulates the
impedance of a coil placed on or near the surface of the printed part. We
demonstrate strain sensing accurate to +/-27x10-6 over at least a 6x10-4 strain
range, and temperature sensing accurate to +/-0.75oC over a 70oC range, both to
a 95% confidence interval. We highlight these sensors' capabilities by
detecting the onset of plasticity and fatigue-driven crack growth thousands of
cycles before critical failure. This extends non-destructive eddy-current
damage detection to accurate, real-time strain and temperature monitoring
within metallic structures.

</details>


### [111] [Quantum Annealing for Staff Scheduling in Educational Environments](https://arxiv.org/abs/2510.12278)
*Alessia Ciacco,Francesca Guerriero,Eneko Osaba*

Main category: cs.ET

TL;DR: 本文针对意大利卡拉布里亚一所公立学校的教职工分配问题，开发了基于量子退火的优化模型，实现了在多重约束下快速生成平衡的教职工分配方案。


<details>
  <summary>Details</summary>
Motivation: 解决公立学校中教职工在幼儿园、小学和中学之间的分配问题，需要考虑可用性、能力和公平性等多重约束，这是一个现实中的复杂资源分配挑战。

Method: 开发优化模型并研究基于量子退火的解决方案方法，通过计算实验验证其在真实数据上的表现。

Result: 计算实验表明，量子退火能够在短时间内产生平衡的分配方案，运行时间短且效果良好。

Conclusion: 量子优化方法在教育调度和复杂资源分配任务中具有实际应用价值，证明了量子计算在解决现实问题中的潜力。

Abstract: We address a novel staff allocation problem that arises in the organization
of collaborators among multiple school sites and educational levels. The
problem emerges from a real case study in a public school in Calabria, Italy,
where staff members must be distributed across kindergartens, primary, and
secondary schools under constraints of availability, competencies, and
fairness. To tackle this problem, we develop an optimization model and
investigate a solution approach based on quantum annealing. Our computational
experiments on real-world data show that quantum annealing is capable of
producing balanced assignments in short runtimes. These results provide
evidence of the practical applicability of quantum optimization methods in
educational scheduling and, more broadly, in complex resource allocation tasks.

</details>
