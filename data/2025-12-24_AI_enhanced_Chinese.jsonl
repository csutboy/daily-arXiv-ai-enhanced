{"id": "2512.20317", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2512.20317", "abs": "https://arxiv.org/abs/2512.20317", "authors": ["Ashish Ranjan Kumar", "Sekhar Bhattacharyya"], "title": "Towards Energy Independence: Critical Minerals in the Indian Context", "comment": "This paper was presented at the International Seminar on Critical and Strategic Minerals for Viksit Bharat - 2047 on 9 November 2025 in Kolkata, India", "summary": "The global impetus for extracting rare earth elements (REEs) is shaping the future of green technologies. From high-efficiency magnets in wind turbines to advanced batteries and solar photovoltaics, REEs are indispensable for a greener world through the energy transition. However, supply chains remain a barrier for the majority of the global population. India is mainly dependent on imports for most REEs. Innovation and recycling efforts in most REEs are still in their early stages. For India, aspiring to Viksit Bharat by 2047, securing sustainable REE access is critical to national energy security and technological independence. This paper explores India's opportunities and challenges in the REE domain, high-lighting underutilized resources such as copper tailings, fly ash, and e-waste. We argue for circular economy pathways that can reduce environmental impacts and strengthen domestic supply. Hindustan Copper Limited (HCL), as India's sole vertically integrated copper producer, is uniquely positioned to pioneer co-recovery of REEs, advance research and development partnerships, and build a comprehensive supply chain. By embedding sustainability, ESG principles, and community trust in its strategy, HCL can evolve into a national champion in this domain.", "AI": {"tldr": "\u5370\u5ea6\u7a00\u571f\u5143\u7d20\u4f9b\u5e94\u9762\u4e34\u6311\u6218\uff0c\u9700\u901a\u8fc7\u5faa\u73af\u7ecf\u6d4e\u8def\u5f84\u5229\u7528\u94dc\u5c3e\u77ff\u3001\u7c89\u7164\u7070\u548c\u7535\u5b50\u5e9f\u5f03\u7269\u7b49\u672a\u5145\u5206\u5229\u7528\u8d44\u6e90\uff0cHCL\u53ef\u4f5c\u4e3a\u56fd\u5bb6\u51a0\u519b\u63a8\u52a8\u53ef\u6301\u7eed\u53d1\u5c55", "motivation": "\u7a00\u571f\u5143\u7d20\u5bf9\u7eff\u8272\u6280\u672f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5370\u5ea6\u4e3b\u8981\u4f9d\u8d56\u8fdb\u53e3\uff0c\u4f9b\u5e94\u94fe\u5b58\u5728\u969c\u788d\uff0c\u521b\u65b0\u548c\u56de\u6536\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\u3002\u4e3a\u5b9e\u73b02047\u5e74\u53d1\u8fbe\u5370\u5ea6\u613f\u666f\uff0c\u786e\u4fdd\u53ef\u6301\u7eed\u7a00\u571f\u4f9b\u5e94\u5bf9\u80fd\u6e90\u5b89\u5168\u548c\u6280\u672f\u72ec\u7acb\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63a2\u7d22\u5370\u5ea6\u5728\u7a00\u571f\u9886\u57df\u7684\u673a\u4f1a\u548c\u6311\u6218\uff0c\u91cd\u70b9\u5173\u6ce8\u94dc\u5c3e\u77ff\u3001\u7c89\u7164\u7070\u548c\u7535\u5b50\u5e9f\u5f03\u7269\u7b49\u672a\u5145\u5206\u5229\u7528\u8d44\u6e90\uff0c\u63d0\u51fa\u5faa\u73af\u7ecf\u6d4e\u8def\u5f84\uff0c\u5e76\u5206\u6790HCL\u4f5c\u4e3a\u5782\u76f4\u6574\u5408\u94dc\u751f\u4ea7\u5546\u7684\u72ec\u7279\u4f18\u52bf\u3002", "result": "\u8bc6\u522b\u51fa\u5370\u5ea6\u53ef\u901a\u8fc7\u5faa\u73af\u7ecf\u6d4e\u51cf\u5c11\u73af\u5883\u5f71\u54cd\u5e76\u52a0\u5f3a\u56fd\u5185\u4f9b\u5e94\u94fe\u7684\u673a\u4f1a\uff0cHCL\u53ef\u901a\u8fc7\u7a00\u571f\u534f\u540c\u56de\u6536\u3001\u7814\u53d1\u5408\u4f5c\u548c\u4f9b\u5e94\u94fe\u5efa\u8bbe\uff0c\u6210\u4e3a\u8be5\u9886\u57df\u7684\u56fd\u5bb6\u51a0\u519b\u3002", "conclusion": "\u5370\u5ea6\u9700\u8981\u91c7\u53d6\u5faa\u73af\u7ecf\u6d4e\u7b56\u7565\u786e\u4fdd\u7a00\u571f\u53ef\u6301\u7eed\u4f9b\u5e94\uff0cHCL\u901a\u8fc7\u6574\u5408\u53ef\u6301\u7eed\u53d1\u5c55\u3001ESG\u539f\u5219\u548c\u793e\u533a\u4fe1\u4efb\uff0c\u53ef\u5728\u7a00\u571f\u9886\u57df\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u652f\u6301\u56fd\u5bb6\u80fd\u6e90\u5b89\u5168\u548c\u6280\u672f\u72ec\u7acb\u76ee\u6807\u3002"}}
{"id": "2512.20408", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2512.20408", "abs": "https://arxiv.org/abs/2512.20408", "authors": ["Lorenzo Schiavon", "Mattia Stival", "Angela Andreella", "Stefano Campostrini"], "title": "Topic-informed dynamic mixture model for occupational heterogeneity in health risk behaviors", "comment": null, "summary": "Behavioral risk factors, i.e., smoking, poor nutrition, alcohol misuse, and physical inactivity (SNAP), are leading contributors to chronic diseases and healthcare costs worldwide. Their prevalence is shaped %not only by demographic characteristics %but and also by contextual ones such as socioeconomic and occupational environments. In this study, we leverage data from the Italian health and behavioral surveillance system PASSI to model SNAP behaviors through a Bayesian framework that integrates textual information on occupations. We use Structural Topic Modeling (STM) to cluster free-text job descriptions into latent occupational groups, which inform mixture weights in a multivariate ordered probit model. Covariate effects are allowed to vary across occupational clusters and evolve over time. To enhance interpretability and variable selection, we impose non-local spike-and-slab priors on regression coefficients. Finally, an online learning algorithm based on sequential Monte Carlo enables efficient updating as new data become available. This dynamic, scalable, and interpretable approach permits observing how occupational contexts modulate the impact of socio-demographic factors on health behaviors, providing valuable insights for targeted public health interventions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u4e3b\u9898\u5efa\u6a21\u5206\u6790\u804c\u4e1a\u6587\u672c\u63cf\u8ff0\uff0c\u5efa\u7acb\u804c\u4e1a\u96c6\u7fa4\u4e0eSNAP\u5065\u5eb7\u884c\u4e3a\uff08\u5438\u70df\u3001\u4e0d\u826f\u8425\u517b\u3001\u9152\u7cbe\u6ee5\u7528\u3001\u7f3a\u4e4f\u8fd0\u52a8\uff09\u7684\u5173\u8054\u6a21\u578b\uff0c\u5e76\u5b9e\u73b0\u52a8\u6001\u66f4\u65b0\u3002", "motivation": "SNAP\u884c\u4e3a\u98ce\u9669\u56e0\u7d20\u662f\u6162\u6027\u75c5\u548c\u533b\u7597\u6210\u672c\u7684\u4e3b\u8981\u8d21\u732e\u8005\uff0c\u5176\u6d41\u884c\u4e0d\u4ec5\u53d7\u4eba\u53e3\u7279\u5f81\u5f71\u54cd\uff0c\u8fd8\u53d7\u793e\u4f1a\u7ecf\u6d4e\u548c\u804c\u4e1a\u73af\u5883\u7b49\u60c5\u5883\u56e0\u7d20\u5f71\u54cd\u3002\u73b0\u6709\u7814\u7a76\u9700\u8981\u66f4\u7cbe\u7ec6\u5730\u7406\u89e3\u804c\u4e1a\u73af\u5883\u5982\u4f55\u8c03\u8282\u793e\u4f1a\u4eba\u53e3\u56e0\u7d20\u5bf9\u5065\u5eb7\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "1. \u4f7f\u7528\u610f\u5927\u5229PASSI\u5065\u5eb7\u76d1\u6d4b\u7cfb\u7edf\u6570\u636e\uff1b2. \u91c7\u7528\u7ed3\u6784\u4e3b\u9898\u5efa\u6a21\uff08STM\uff09\u5bf9\u81ea\u7531\u6587\u672c\u804c\u4e1a\u63cf\u8ff0\u8fdb\u884c\u805a\u7c7b\uff0c\u5f62\u6210\u6f5c\u5728\u804c\u4e1a\u7fa4\u4f53\uff1b3. \u5efa\u7acb\u591a\u5143\u6709\u5e8fprobit\u6a21\u578b\uff0c\u804c\u4e1a\u96c6\u7fa4\u4f5c\u4e3a\u6df7\u5408\u6743\u91cd\uff1b4. \u534f\u53d8\u91cf\u6548\u5e94\u5141\u8bb8\u8de8\u804c\u4e1a\u96c6\u7fa4\u53d8\u5316\u5e76\u968f\u65f6\u95f4\u6f14\u5316\uff1b5. \u4f7f\u7528\u975e\u5c40\u90e8spike-and-slab\u5148\u9a8c\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u548c\u53d8\u91cf\u9009\u62e9\uff1b6. \u57fa\u4e8e\u987a\u5e8f\u8499\u7279\u5361\u6d1b\u7684\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u5b9e\u73b0\u6570\u636e\u66f4\u65b0\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u52a8\u6001\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u5730\u89c2\u5bdf\u804c\u4e1a\u73af\u5883\u5982\u4f55\u8c03\u8282\u793e\u4f1a\u4eba\u53e3\u56e0\u7d20\u5bf9\u5065\u5eb7\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4e3a\u6709\u9488\u5bf9\u6027\u7684\u516c\u5171\u536b\u751f\u5e72\u9884\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u8d1d\u53f6\u65af\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u804c\u4e1a\u6587\u672c\u4fe1\u606f\uff0c\u80fd\u591f\u66f4\u7cbe\u7ec6\u5730\u5206\u6790\u804c\u4e1a\u73af\u5883\u5bf9\u5065\u5eb7\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4e3a\u516c\u5171\u536b\u751f\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177\u548c\u65b9\u6cd5\u8bba\u652f\u6301\u3002"}}
{"id": "2512.19700", "categories": ["cs.CY", "cs.DL"], "pdf": "https://arxiv.org/pdf/2512.19700", "abs": "https://arxiv.org/abs/2512.19700", "authors": ["Anton Alyakin"], "title": "\"All You Need\" is Not All You Need for a Paper Title: On the Origins of a Scientific Meme", "comment": null, "summary": "The 2017 paper ''Attention Is All You Need'' introduced the Transformer architecture-and inadvertently spawned one of machine learning's most persistent naming conventions. We analyze 717 arXiv preprints containing ''All You Need'' in their titles (2009-2025), finding exponential growth ($R^2$ > 0.994) following the original paper, with 200 titles in 2025 alone. Among papers following the canonical ''X [Is] All You Need'' structure, ''Attention'' remains the most frequently claimed necessity (28 occurrences). Situating this phenomenon within memetic theory, we argue the pattern's success reflects competitive pressures in scientific communication that increasingly favor memorability over precision. Whether this trend represents harmless academic whimsy or symptomatic sensationalism, we leave-with appropriate self-awareness-to the reader.", "AI": {"tldr": "\u5206\u67902017\u5e74Transformer\u8bba\u6587\u5f15\u53d1\u7684\"All You Need\"\u6807\u9898\u547d\u540d\u73b0\u8c61\uff0c\u7814\u7a76717\u7bc7arXiv\u9884\u5370\u672c\uff0c\u53d1\u73b0\u6307\u6570\u589e\u957f\u8d8b\u52bf\uff0c\u63a2\u8ba8\u5b66\u672f\u4f20\u64ad\u4e2d\u7684\u8bb0\u5fc6\u6027\u4f18\u5148\u4e8e\u7cbe\u786e\u6027\u7684\u8d8b\u52bf", "motivation": "\u5206\u67902017\u5e74\"Attention Is All You Need\"\u8bba\u6587\u5f15\u53d1\u7684\u5b66\u672f\u6807\u9898\u547d\u540d\u73b0\u8c61\uff0c\u7814\u7a76\u8fd9\u79cd\u547d\u540d\u6a21\u5f0f\u5728\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u4f20\u64ad\u548c\u5f71\u54cd\uff0c\u63a2\u8ba8\u5b66\u672f\u4f20\u64ad\u4e2d\u7684\u7ade\u4e89\u538b\u529b\u5982\u4f55\u5bfc\u81f4\u8bb0\u5fc6\u6027\u4f18\u5148\u4e8e\u7cbe\u786e\u6027\u7684\u8d8b\u52bf", "method": "\u6536\u96c62009-2025\u5e74\u95f4arXiv\u9884\u5370\u672c\u4e2d717\u7bc7\u5305\u542b\"All You Need\"\u7684\u8bba\u6587\u6807\u9898\uff0c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u5305\u62ec\u6570\u91cf\u589e\u957f\u8d8b\u52bf\u3001\u6700\u5e38\u89c1\u7684\"X\"\u8bcd\u6c47\u5206\u5e03\uff0c\u5e76\u5c06\u6b64\u73b0\u8c61\u7f6e\u4e8e\u6a21\u56e0\u7406\u8bba\u6846\u67b6\u4e0b\u5206\u6790", "result": "\u53d1\u73b0\"All You Need\"\u6807\u9898\u5448\u73b0\u6307\u6570\u589e\u957f\uff08R\u00b2 > 0.994\uff09\uff0c2025\u5e74\u8fbe\u5230200\u7bc7\uff1b\u5728\"X [Is] All You Need\"\u7ed3\u6784\u4e2d\uff0c\"Attention\"\u4ecd\u662f\u6700\u5e38\u89c1\u7684\u8bcd\u6c47\uff0828\u6b21\uff09\uff1b\u8be5\u547d\u540d\u6a21\u5f0f\u5df2\u6210\u4e3a\u673a\u5668\u5b66\u4e60\u9886\u57df\u6700\u6301\u4e45\u7684\u547d\u540d\u60ef\u4f8b\u4e4b\u4e00", "conclusion": "\u8fd9\u79cd\u547d\u540d\u73b0\u8c61\u7684\u6210\u529f\u53cd\u6620\u4e86\u79d1\u5b66\u4f20\u64ad\u4e2d\u65e5\u76ca\u589e\u957f\u7684\u7ade\u4e89\u538b\u529b\uff0c\u4f7f\u5f97\u8bb0\u5fc6\u6027\u9010\u6e10\u4f18\u5148\u4e8e\u7cbe\u786e\u6027\uff1b\u4f5c\u8005\u4ee5\u9002\u5f53\u7684\u81ea\u6211\u610f\u8bc6\uff0c\u5c06\u8fd9\u79cd\u8d8b\u52bf\u662f\u5426\u4ee3\u8868\u65e0\u5bb3\u7684\u5b66\u672f\u8da3\u5473\u6216\u75c7\u72b6\u6027\u8038\u4eba\u542c\u95fb\u7559\u7ed9\u8bfb\u8005\u5224\u65ad"}}
{"id": "2512.19799", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.19799", "abs": "https://arxiv.org/abs/2512.19799", "authors": ["Tingjia Miao", "Jiawen Dai", "Jingkun Liu", "Jinxin Tan", "Muhua Zhang", "Wenkai Jin", "Yuwen Du", "Tian Jin", "Xianghe Pang", "Zexi Liu", "Tu Guo", "Zhengliang Zhang", "Yunjie Huang", "Shuo Chen", "Rui Ye", "Yuzhi Zhang", "Linfeng Zhang", "Kun Chen", "Wei Wang", "Weinan E", "Siheng Chen"], "title": "PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research", "comment": "32 pages, 10 figures", "summary": "Advances in LLMs have produced agents with knowledge and operational capabilities comparable to human scientists, suggesting potential to assist, accelerate, and automate research. However, existing studies mainly evaluate such systems on well-defined benchmarks or general tasks like literature retrieval, limiting their end-to-end problem-solving ability in open scientific scenarios. This is particularly true in physics, which is abstract, mathematically intensive, and requires integrating analytical reasoning with code-based computation. To address this, we propose PhysMaster, an LLM-based agent functioning as an autonomous theoretical and computational physicist. PhysMaster couples absract reasoning with numerical computation and leverages LANDAU, the Layered Academic Data Universe, which preserves retrieved literature, curated prior knowledge, and validated methodological traces, enhancing decision reliability and stability. It also employs an adaptive exploration strategy balancing efficiency and open-ended exploration, enabling robust performance in ultra-long-horizon tasks. We evaluate PhysMaster on problems from high-energy theory, condensed matter theory to astrophysics, including: (i) acceleration, compressing labor-intensive research from months to hours; (ii) automation, autonomously executing hypothesis-driven loops ; and (iii) autonomous discovery, independently exploring open problems.", "AI": {"tldr": "PhysMaster\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u81ea\u4e3b\u7406\u8bba\u7269\u7406\u5b66\u5bb6\u4ee3\u7406\uff0c\u901a\u8fc7\u7ed3\u5408\u62bd\u8c61\u63a8\u7406\u4e0e\u6570\u503c\u8ba1\u7b97\uff0c\u5229\u7528LANDAU\u77e5\u8bc6\u5e93\u548c\u81ea\u9002\u5e94\u63a2\u7d22\u7b56\u7565\uff0c\u5728\u7269\u7406\u7814\u7a76\u4e2d\u5b9e\u73b0\u52a0\u901f\u3001\u81ea\u52a8\u5316\u548c\u81ea\u4e3b\u53d1\u73b0\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u4e3b\u8981\u5728\u5b9a\u4e49\u826f\u597d\u7684\u57fa\u51c6\u6d4b\u8bd5\u6216\u6587\u732e\u68c0\u7d22\u7b49\u901a\u7528\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u5728\u5f00\u653e\u79d1\u5b66\u573a\u666f\u4e2d\u7684\u7aef\u5230\u7aef\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002\u7269\u7406\u5b66\u5c24\u5176\u5177\u6709\u62bd\u8c61\u6027\u3001\u6570\u5b66\u5bc6\u96c6\u6027\uff0c\u9700\u8981\u6574\u5408\u5206\u6790\u63a8\u7406\u4e0e\u4ee3\u7801\u8ba1\u7b97\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u8fdb\u884c\u7269\u7406\u7814\u7a76\u7684\u667a\u80fd\u4ee3\u7406\u3002", "method": "PhysMaster\u5c06\u62bd\u8c61\u63a8\u7406\u4e0e\u6570\u503c\u8ba1\u7b97\u76f8\u7ed3\u5408\uff0c\u5229\u7528LANDAU\uff08\u5206\u5c42\u5b66\u672f\u6570\u636e\u5b87\u5b99\uff09\u77e5\u8bc6\u5e93\u4fdd\u5b58\u68c0\u7d22\u6587\u732e\u3001\u6574\u7406\u5148\u9a8c\u77e5\u8bc6\u548c\u9a8c\u8bc1\u65b9\u6cd5\u8f68\u8ff9\uff0c\u589e\u5f3a\u51b3\u7b56\u53ef\u9760\u6027\u548c\u7a33\u5b9a\u6027\u3002\u91c7\u7528\u81ea\u9002\u5e94\u63a2\u7d22\u7b56\u7565\u5e73\u8861\u6548\u7387\u4e0e\u5f00\u653e\u5f0f\u63a2\u7d22\uff0c\u652f\u6301\u8d85\u957f\u89c6\u91ce\u4efb\u52a1\u3002", "result": "\u5728\u9ad8\u80fd\u7406\u8bba\u3001\u51dd\u805a\u6001\u7406\u8bba\u548c\u5929\u4f53\u7269\u7406\u7b49\u591a\u4e2a\u7269\u7406\u9886\u57df\u95ee\u9898\u4e0a\u8bc4\u4f30\u663e\u793a\uff1a(1) \u52a0\u901f\uff1a\u5c06\u52b3\u52a8\u5bc6\u96c6\u578b\u7814\u7a76\u4ece\u6570\u6708\u538b\u7f29\u5230\u6570\u5c0f\u65f6\uff1b(2) \u81ea\u52a8\u5316\uff1a\u81ea\u4e3b\u6267\u884c\u5047\u8bbe\u9a71\u52a8\u5faa\u73af\uff1b(3) \u81ea\u4e3b\u53d1\u73b0\uff1a\u72ec\u7acb\u63a2\u7d22\u5f00\u653e\u95ee\u9898\u3002", "conclusion": "PhysMaster\u4f5c\u4e3a\u81ea\u4e3b\u7406\u8bba\u7269\u7406\u5b66\u5bb6\u4ee3\u7406\uff0c\u901a\u8fc7\u6574\u5408\u63a8\u7406\u3001\u8ba1\u7b97\u548c\u77e5\u8bc6\u7ba1\u7406\uff0c\u5728\u7269\u7406\u7814\u7a76\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u52a0\u901f\u3001\u81ea\u52a8\u5316\u548c\u81ea\u4e3b\u53d1\u73b0\u80fd\u529b\uff0c\u4e3a\u79d1\u5b66\u7814\u7a76\u7684\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2512.19824", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2512.19824", "abs": "https://arxiv.org/abs/2512.19824", "authors": ["Jeff Dominitz", "Charles F. Manski"], "title": "Limit Regret in Binary Treatment Choice with Misspecified Plug-In Predictors and Decision Thresholds", "comment": null, "summary": "We study the population limit maximum regret (MR) of plug-in prediction when the decision problem is to choose between two treatments for the members of a population with observed covariates x. In this setting, the optimal treatment for persons with covariate value x is B if the conditional probability P(y = 1|x) of a binary outcome y exceeds an x-specific known threshold and is A otherwise. This structure is common in medical decision making, as well as non-medical contexts. Plug-in prediction uses data to estimate P(y|x) and acts as if the estimate is accurate. We are concerned that the model used to estimate P(y|x) may be misspecified, with true conditional probabilities being outside the model space. In practice, plug-in prediction has been performed with a wide variety of prediction models that commonly are misspecified. Further, applications often use a conventional x-invariant threshold, whereas optimal treatment choice uses x-specific thresholds. The main contribution of this paper is to shed new light on limit MR when plug-in prediction is performed with misspecified models. We use a combination of algebraic and computational analysis to study limit MR, demonstrating how it depends on the limit estimate and on the thresholds used to choose treatments. We recommend that a planner who wants to use plug-in prediction to achieve satisfactory MR should jointly choose a predictive model, estimation method, and x-specific thresholds to accomplish this objective.", "AI": {"tldr": "\u7814\u7a76\u5728\u4e8c\u5143\u6cbb\u7597\u9009\u62e9\u95ee\u9898\u4e2d\uff0c\u5f53\u4f7f\u7528\u9519\u8bef\u6307\u5b9a\u7684\u6a21\u578b\u8fdb\u884c\u63d2\u4ef6\u9884\u6d4b\u65f6\uff0c\u5176\u6700\u5927\u9057\u61be\uff08MR\uff09\u7684\u6781\u9650\u884c\u4e3a\uff0c\u5e76\u5efa\u8bae\u901a\u8fc7\u8054\u5408\u9009\u62e9\u9884\u6d4b\u6a21\u578b\u3001\u4f30\u8ba1\u65b9\u6cd5\u548c\u534f\u53d8\u91cf\u7279\u5b9a\u9608\u503c\u6765\u4f18\u5316MR\u3002", "motivation": "\u5728\u533b\u7597\u51b3\u7b56\u7b49\u573a\u666f\u4e2d\uff0c\u63d2\u4ef6\u9884\u6d4b\u5e38\u7528\u4e8e\u4f30\u8ba1\u6761\u4ef6\u6982\u7387P(y|x)\u6765\u9009\u62e9\u6cbb\u7597\uff08A\u6216B\uff09\uff0c\u4f46\u5b9e\u9645\u4f7f\u7528\u7684\u9884\u6d4b\u6a21\u578b\u5e38\u88ab\u9519\u8bef\u6307\u5b9a\uff0c\u4e14\u901a\u5e38\u4f7f\u7528\u56fa\u5b9a\u9608\u503c\u800c\u975e\u534f\u53d8\u91cf\u7279\u5b9a\u9608\u503c\u3002\u9700\u8981\u7406\u89e3\u8fd9\u79cd\u9519\u8bef\u6307\u5b9a\u5bf9\u6700\u5927\u9057\u61be\uff08MR\uff09\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u4ee3\u6570\u5206\u6790\u548c\u8ba1\u7b97\u5206\u6790\uff0c\u7814\u7a76\u63d2\u4ef6\u9884\u6d4b\u5728\u6a21\u578b\u9519\u8bef\u6307\u5b9a\u60c5\u51b5\u4e0b\u7684\u6781\u9650\u6700\u5927\u9057\u61be\uff08MR\uff09\uff0c\u5206\u6790\u5176\u5982\u4f55\u4f9d\u8d56\u4e8e\u6781\u9650\u4f30\u8ba1\u503c\u548c\u6cbb\u7597\u9009\u62e9\u9608\u503c\u3002", "result": "\u63ed\u793a\u4e86\u6781\u9650MR\u5982\u4f55\u4f9d\u8d56\u4e8e\u6781\u9650\u4f30\u8ba1\u503c\u548c\u6cbb\u7597\u9009\u62e9\u9608\u503c\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u9519\u8bef\u6307\u5b9a\u5bf9MR\u7684\u5f71\u54cd\u673a\u5236\u3002", "conclusion": "\u5efa\u8bae\u8ba1\u5212\u8005\u5728\u4f7f\u7528\u63d2\u4ef6\u9884\u6d4b\u65f6\uff0c\u5e94\u8054\u5408\u9009\u62e9\u9884\u6d4b\u6a21\u578b\u3001\u4f30\u8ba1\u65b9\u6cd5\u548c\u534f\u53d8\u91cf\u7279\u5b9a\u9608\u503c\uff0c\u4ee5\u5b9e\u73b0\u6ee1\u610f\u7684\u6700\u5927\u9057\u61be\uff08MR\uff09\u6027\u80fd\u3002"}}
{"id": "2512.20103", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2512.20103", "abs": "https://arxiv.org/abs/2512.20103", "authors": ["Md Mahfuzur Rahman", "Nishith Tripathi", "Jeffrey H. Reed", "Lingjia Liu"], "title": "Developing an NTN Architecture for End-to-End Performance Evaluation", "comment": null, "summary": "Non-Terrestrial Networks (NTN) are emerging as critical enablers of global connectivity, particularly in remote, unserved, underserved, or maritime regions lacking traditional infrastructure. While much of the existing work on NTN focuses on theoretical or simulated evaluations, practical implementations remain limited. In this paper, we present SpaceNET, a transparent NTN testbed that leverages the Starlink Low Earth Orbit (LEO) satellite constellation in conjunction with Mininet-based emulation to perform end-to-end performance assessments across real-world maritime and terrestrial endpoints that can also be applied to 5th generation (5G). Specifically, we establish a bidirectional link between a ground terminal located in Blacksburg, Virginia, and a maritime terminal aboard a cruise ship near Key West, Florida. We report detailed transmission control protocol (TCP) throughput, user datagram protocol (UDP) throughput, and latency measurements using two different user terminals - a) Smartphone, and b) very small aperture terminal (VSAT), emphasizing the transparent nature of the NTN payload, where the satellite acts solely as a relay node. Our results provide new insights into the performance limits and reliability of commercial LEO-based NTN applications. The SpaceNET testbed offers a reproducible and extensible platform for future research in NTN routing, mobility support, and cross-layer optimization.", "AI": {"tldr": "SpaceNET\u662f\u4e00\u4e2a\u5229\u7528Starlink LEO\u536b\u661f\u661f\u5ea7\u7684\u900f\u660eNTN\u6d4b\u8bd5\u5e73\u53f0\uff0c\u901a\u8fc7Mininet\u4eff\u771f\u5728\u771f\u5b9e\u6d77\u4e8b\u548c\u5730\u9762\u7ec8\u7aef\u95f4\u8fdb\u884c\u7aef\u5230\u7aef\u6027\u80fd\u8bc4\u4f30\uff0c\u4e3a5G\u5e94\u7528\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u7814\u7a76\u5e73\u53f0\u3002", "motivation": "\u73b0\u6709NTN\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u7406\u8bba\u6216\u4eff\u771f\u8bc4\u4f30\uff0c\u5b9e\u9645\u5b9e\u73b0\u6709\u9650\u3002\u9700\u8981\u5efa\u7acb\u900f\u660eNTN\u6d4b\u8bd5\u5e73\u53f0\u6765\u8bc4\u4f30\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u7f3a\u4e4f\u4f20\u7edf\u57fa\u7840\u8bbe\u65bd\u7684\u504f\u8fdc\u3001\u672a\u670d\u52a1\u6216\u6d77\u4e8b\u533a\u57df\u3002", "method": "\u5229\u7528Starlink LEO\u536b\u661f\u661f\u5ea7\u4e0eMininet\u4eff\u771f\u7ed3\u5408\uff0c\u5efa\u7acb\u4ece\u5f17\u5409\u5c3c\u4e9a\u5dde\u5e03\u83b1\u514b\u65af\u5821\u5730\u9762\u7ec8\u7aef\u5230\u4f5b\u7f57\u91cc\u8fbe\u5dde\u57fa\u97e6\u65af\u7279\u9644\u8fd1\u6e38\u8f6e\u6d77\u4e8b\u7ec8\u7aef\u7684\u53cc\u5411\u94fe\u8def\u3002\u4f7f\u7528\u667a\u80fd\u624b\u673a\u548cVSAT\u4e24\u79cd\u7528\u6237\u7ec8\u7aef\u6d4b\u91cfTCP/UDP\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\uff0c\u536b\u661f\u4ec5\u4f5c\u4e3a\u4e2d\u7ee7\u8282\u70b9\u3002", "result": "\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684TCP\u541e\u5410\u91cf\u3001UDP\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u6d4b\u91cf\u7ed3\u679c\uff0c\u4e3a\u5546\u4e1aLEO-based NTN\u5e94\u7528\u7684\u6027\u80fd\u6781\u9650\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002\u6d4b\u8bd5\u5e73\u53f0\u5c55\u793a\u4e86\u900f\u660eNTN\u8f7d\u8377\u7684\u7279\u6027\u3002", "conclusion": "SpaceNET\u6d4b\u8bd5\u5e73\u53f0\u4e3a\u672a\u6765NTN\u8def\u7531\u3001\u79fb\u52a8\u6027\u652f\u6301\u548c\u8de8\u5c42\u4f18\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u548c\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8NTN\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.19947", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2512.19947", "abs": "https://arxiv.org/abs/2512.19947", "authors": ["Elizabeth Stewart", "Suryash Greenwold", "Timotius Marselo"], "title": "Community Notes: Crowd Participation and Dependence on Professional Fact-Checking Across Languages", "comment": null, "summary": "Crowd-sourced fact-checking provides social media platforms with a promising method of managing misinformation at scale. However, the success of fact-checking programs like X's Community Notes requires the participation of a critical mass of note-writers who have the time and epistemic resources necessary to write and rate high-quality notes. As X's Community Notes program was first established in English-speaking countries, much academic research has focused on English-language notes or notes writ large. Relatively little research has investigated how different linguistic communities utilise Community Notes. Thus, it is unclear whether Community Notes or similar crowd-sourced fact-checking initiatives represent a viable alternative to social media platforms' partnerships with professional fact-checking organisations across linguistic contexts. This research identifies how different linguistic communities participate in volunteer fact-checking efforts on X's Community Notes program and addresses volunteers' reliance on professional fact-checking resources differs across languages. We find that while the Community Notes program has had strong uptake in some linguistic communities, the program has failed to catch on in others. Additionally, we confirm findings that notes that cite professional fact-checkers are considered more helpful, but show that reliance on professional fact-checking overall remains minimal.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86X\u5e73\u53f0Community Notes\u9879\u76ee\u4e2d\u4e0d\u540c\u8bed\u8a00\u793e\u533a\u7684\u53c2\u4e0e\u60c5\u51b5\uff0c\u53d1\u73b0\u67d0\u4e9b\u8bed\u8a00\u793e\u533a\u53c2\u4e0e\u5ea6\u9ad8\uff0c\u800c\u5176\u4ed6\u793e\u533a\u53c2\u4e0e\u5ea6\u4f4e\uff0c\u4e14\u5bf9\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u8d44\u6e90\u7684\u4f9d\u8d56\u6574\u4f53\u8f83\u4f4e\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u82f1\u8bed\u793e\u533a\u6216\u6574\u4f53\u60c5\u51b5\uff0c\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u8bed\u8a00\u793e\u533a\u5728\u4f17\u5305\u4e8b\u5b9e\u6838\u67e5\u4e2d\u53c2\u4e0e\u5dee\u5f02\u7684\u7814\u7a76\uff0c\u9700\u8981\u4e86\u89e3Community Notes\u5728\u4e0d\u540c\u8bed\u8a00\u73af\u5883\u4e0b\u662f\u5426\u53ef\u884c\u3002", "method": "\u901a\u8fc7\u5206\u6790X\u5e73\u53f0Community Notes\u9879\u76ee\u4e2d\u4e0d\u540c\u8bed\u8a00\u793e\u533a\u7684\u53c2\u4e0e\u6570\u636e\uff0c\u7814\u7a76\u4e0d\u540c\u8bed\u8a00\u793e\u533a\u7684\u53c2\u4e0e\u6a21\u5f0f\u548c\u4ed6\u4eec\u5bf9\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u8d44\u6e90\u7684\u4f9d\u8d56\u7a0b\u5ea6\u3002", "result": "1. Community Notes\u5728\u67d0\u4e9b\u8bed\u8a00\u793e\u533a\u4e2d\u53c2\u4e0e\u5ea6\u9ad8\uff0c\u4f46\u5728\u5176\u4ed6\u793e\u533a\u4e2d\u672a\u80fd\u666e\u53ca\uff1b2. \u5f15\u7528\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u673a\u6784\u7684\u7b14\u8bb0\u88ab\u8ba4\u4e3a\u66f4\u6709\u5e2e\u52a9\uff1b3. \u6574\u4f53\u4e0a\u5bf9\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u7684\u4f9d\u8d56\u4ecd\u7136\u5f88\u4f4e\u3002", "conclusion": "\u4f17\u5305\u4e8b\u5b9e\u6838\u67e5\u5728\u4e0d\u540c\u8bed\u8a00\u793e\u533a\u4e2d\u7684\u9002\u7528\u6027\u5b58\u5728\u5dee\u5f02\uff0c\u867d\u7136\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u8d44\u6e90\u80fd\u63d0\u5347\u7b14\u8bb0\u8d28\u91cf\uff0c\u4f46\u6574\u4f53\u4f9d\u8d56\u5ea6\u4e0d\u9ad8\uff0c\u8868\u660eCommunity Notes\u4e0d\u80fd\u5b8c\u5168\u66ff\u4ee3\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u673a\u6784\u3002"}}
{"id": "2512.19882", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.19882", "abs": "https://arxiv.org/abs/2512.19882", "authors": ["Mahdi Mostajabdaveh", "F. Sibel Salman", "Walter J. Gutjahr"], "title": "A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution", "comment": null, "summary": "The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating limited relief supplies. To balance efficiency and equity, we formulate a bi-objective problem: minimizing a Gini-index-based measure of inequity in unsatisfied demand for fair distribution and minimizing total travel time for timely delivery. We propose a Mixed Integer Programming (MIP) model and use the $\u03b5$-constraint method to handle the bi-objective nature. By deriving mathematical properties of the optimal solution, we introduce valid inequalities and design an algorithm for optimal delivery allocations given feasible vehicle routes. A branch-and-price (B&P) algorithm is developed to solve the problem efficiently. Computational tests on realistic datasets from a past earthquake in Van, Turkey, and predicted data for Istanbul's Kartal region show that the B&P algorithm significantly outperforms commercial MIP solvers. Our bi-objective approach reduces aid distribution inequity by 34% without compromising efficiency. Results indicate that when time constraints are very loose or tight, lexicographic optimization prioritizing demand coverage over fairness is effective. For moderately restrictive time constraints, a balanced approach is essential to avoid inequitable outcomes.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u707e\u540e\u6551\u63f4\u7269\u8d44\u5206\u914d\uff0c\u540c\u65f6\u8003\u8651\u6548\u7387\uff08\u6700\u5c0f\u5316\u603b\u65c5\u884c\u65f6\u95f4\uff09\u548c\u516c\u5e73\u6027\uff08\u6700\u5c0f\u5316\u672a\u6ee1\u8db3\u9700\u6c42\u7684\u57fa\u5c3c\u7cfb\u6570\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u5206\u652f\u5b9a\u4ef7\u7b97\u6cd5\u8fdb\u884c\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u91cd\u5927\u707e\u5bb3\u4e2d\uff0c\u9884\u7f6e\u7684\u6551\u63f4\u7269\u8d44\u901a\u5e38\u65e0\u6cd5\u6ee1\u8db3\u6240\u6709\u9700\u6c42\uff0c\u9700\u8981\u5728\u591a\u4e2a\u907f\u96be\u6240\u4e4b\u95f4\u5408\u7406\u5206\u914d\u6709\u9650\u7269\u8d44\u3002\u4f20\u7edf\u65b9\u6cd5\u5f80\u5f80\u53ea\u5173\u6ce8\u6548\u7387\uff0c\u5ffd\u7565\u4e86\u5206\u914d\u7684\u516c\u5e73\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u67d0\u4e9b\u907f\u96be\u6240\u83b7\u5f97\u8fc7\u591a\u63f4\u52a9\u800c\u5176\u4ed6\u907f\u96be\u6240\u4e25\u91cd\u77ed\u7f3a\u3002", "method": "1. \u5efa\u7acb\u53cc\u76ee\u6807\u6df7\u5408\u6574\u6570\u89c4\u5212\u6a21\u578b\uff1a\u76ee\u6807\u4e00\u662f\u6700\u5c0f\u5316\u672a\u6ee1\u8db3\u9700\u6c42\u7684\u57fa\u5c3c\u7cfb\u6570\uff08\u516c\u5e73\u6027\uff09\uff0c\u76ee\u6807\u4e8c\u662f\u6700\u5c0f\u5316\u603b\u65c5\u884c\u65f6\u95f4\uff08\u6548\u7387\uff09\uff1b2. \u4f7f\u7528\u03b5-\u7ea6\u675f\u65b9\u6cd5\u5904\u7406\u53cc\u76ee\u6807\u4f18\u5316\uff1b3. \u63a8\u5bfc\u6700\u4f18\u89e3\u7684\u6570\u5b66\u6027\u8d28\uff0c\u5f15\u5165\u6709\u6548\u4e0d\u7b49\u5f0f\uff1b4. \u8bbe\u8ba1\u7ed9\u5b9a\u53ef\u884c\u8f66\u8f86\u8def\u5f84\u4e0b\u7684\u6700\u4f18\u914d\u9001\u5206\u914d\u7b97\u6cd5\uff1b5. \u5f00\u53d1\u5206\u652f\u5b9a\u4ef7\u7b97\u6cd5\u8fdb\u884c\u9ad8\u6548\u6c42\u89e3\u3002", "result": "1. \u5206\u652f\u5b9a\u4ef7\u7b97\u6cd5\u5728\u571f\u8033\u5176\u51e1\u57ce\u5730\u9707\u548c\u4f0a\u65af\u5766\u5e03\u5c14\u5361\u5c14\u5854\u5c14\u5730\u533a\u7684\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u5546\u4e1aMIP\u6c42\u89e3\u5668\uff1b2. \u53cc\u76ee\u6807\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u6548\u7387\u7684\u60c5\u51b5\u4e0b\u5c06\u63f4\u52a9\u5206\u914d\u4e0d\u516c\u5e73\u6027\u964d\u4f4e\u4e8634%\uff1b3. \u65f6\u95f4\u7ea6\u675f\u975e\u5e38\u5bbd\u677e\u6216\u7d27\u5f20\u65f6\uff0c\u4f18\u5148\u8003\u8651\u9700\u6c42\u8986\u76d6\u7684\u8bcd\u5178\u4f18\u5316\u6709\u6548\uff1b4. \u65f6\u95f4\u7ea6\u675f\u4e2d\u7b49\u4e25\u683c\u65f6\uff0c\u5e73\u8861\u65b9\u6cd5\u5bf9\u907f\u514d\u4e0d\u516c\u5e73\u7ed3\u679c\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u53cc\u76ee\u6807\u4f18\u5316\u6846\u67b6\u548c\u5206\u652f\u5b9a\u4ef7\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u707e\u540e\u6551\u63f4\u7269\u8d44\u5206\u914d\u7684\u6548\u7387\u548c\u516c\u5e73\u6027\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e0d\u540c\u65f6\u95f4\u7ea6\u675f\u6761\u4ef6\u4e0b\u9700\u8981\u91c7\u7528\u4e0d\u540c\u7684\u4f18\u5316\u7b56\u7565\uff1a\u6781\u7aef\u60c5\u51b5\u4e0b\u4f18\u5148\u6ee1\u8db3\u9700\u6c42\uff0c\u4e2d\u7b49\u7ea6\u675f\u65f6\u9700\u8981\u5e73\u8861\u8003\u8651\uff0c\u4ee5\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u6551\u63f4\u7269\u8d44\u5206\u914d\u3002"}}
{"id": "2512.19843", "categories": ["econ.EM", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.19843", "abs": "https://arxiv.org/abs/2512.19843", "authors": ["Philipp Ketz", "Adam McCloskey", "Jan Scherer"], "title": "Numerical Analysis of Test Optimality", "comment": null, "summary": "In nonstandard testing environments, researchers often derive ad hoc tests with correct (asymptotic) size, but their optimality properties are typically unknown a priori and difficult to assess. This paper develops a numerical framework for determining whether an ad hoc test is effectively optimal - approximately maximizing a weighted average power criterion for some weights over the alternative and attaining a power envelope generated by a single weighted average power-maximizing test. Our approach uses nested optimization algorithms to approximate the weight function that makes an ad hoc test's weighted average power as close as possible to that of a true weighted average power-maximizing test, and we show the surprising result that the rejection probabilities corresponding to the latter form an approximate power envelope for the former. We provide convergence guarantees, discuss practical implementation and apply the method to the weak instrument-robust conditional likelihood ratio test and a recently-proposed test for when a nuisance parameter may be on or near its boundary.", "AI": {"tldr": "\u63d0\u51fa\u6570\u503c\u6846\u67b6\u8bc4\u4f30\u4e34\u65f6\u68c0\u9a8c\u662f\u5426\u6709\u6548\u6700\u4f18\uff0c\u901a\u8fc7\u5bfb\u627e\u4f7f\u4e34\u65f6\u68c0\u9a8c\u52a0\u6743\u5e73\u5747\u529f\u7387\u63a5\u8fd1\u771f\u5b9e\u6700\u4f18\u68c0\u9a8c\u7684\u6743\u91cd\u51fd\u6570", "motivation": "\u5728\u975e\u6807\u51c6\u6d4b\u8bd5\u73af\u5883\u4e2d\uff0c\u7814\u7a76\u8005\u5e38\u4f7f\u7528\u4e34\u65f6\u68c0\u9a8c\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u867d\u7136\u5177\u6709\u6b63\u786e\u7684\u6e10\u8fd1\u89c4\u6a21\uff0c\u4f46\u5176\u6700\u4f18\u6027\u901a\u5e38\u672a\u77e5\u4e14\u96be\u4ee5\u8bc4\u4f30\uff0c\u9700\u8981\u7cfb\u7edf\u65b9\u6cd5\u6765\u8bc4\u4f30\u8fd9\u4e9b\u68c0\u9a8c\u7684\u6709\u6548\u6027", "method": "\u4f7f\u7528\u5d4c\u5957\u4f18\u5316\u7b97\u6cd5\u8fd1\u4f3c\u6743\u91cd\u51fd\u6570\uff0c\u4f7f\u4e34\u65f6\u68c0\u9a8c\u7684\u52a0\u6743\u5e73\u5747\u529f\u7387\u5c3d\u53ef\u80fd\u63a5\u8fd1\u771f\u5b9e\u52a0\u6743\u5e73\u5747\u529f\u7387\u6700\u5927\u5316\u68c0\u9a8c\uff0c\u5f62\u6210\u8fd1\u4f3c\u529f\u7387\u5305\u7edc", "result": "\u8bc1\u660e\u771f\u5b9e\u52a0\u6743\u5e73\u5747\u529f\u7387\u6700\u5927\u5316\u68c0\u9a8c\u7684\u62d2\u7edd\u6982\u7387\u5f62\u6210\u4e34\u65f6\u68c0\u9a8c\u7684\u8fd1\u4f3c\u529f\u7387\u5305\u7edc\uff0c\u63d0\u4f9b\u6536\u655b\u4fdd\u8bc1\uff0c\u5e76\u5e94\u7528\u4e8e\u5f31\u5de5\u5177\u7a33\u5065\u6761\u4ef6\u4f3c\u7136\u6bd4\u68c0\u9a8c\u548c\u8fb9\u754c\u53c2\u6570\u68c0\u9a8c", "conclusion": "\u8be5\u6570\u503c\u6846\u67b6\u4e3a\u8bc4\u4f30\u4e34\u65f6\u68c0\u9a8c\u7684\u6709\u6548\u6700\u4f18\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u975e\u6807\u51c6\u6d4b\u8bd5\u73af\u5883\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u68c0\u9a8c\u7684\u7edf\u8ba1\u6027\u80fd"}}
{"id": "2512.20302", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2512.20302", "abs": "https://arxiv.org/abs/2512.20302", "authors": ["Arka Chakraborty", "Franz M\u00fcller", "Thomas K\u00e4mpfe", "Shubham Sahay"], "title": "Ferroelectric FET-based Logic-in-Memory Encoder for Hyperdimensional Computing", "comment": "27 pages, 13 figures, 3 tables", "summary": "Hyperdimensional (HD) computing involves encoding of baseline information into large hypervectors and repeated Boolean operations to generate the output class hypervectors which are stored in an associative memory. The classification task is then performed through similarity search operation. While prior studies have focused mostly on accelerating HD search operation using TCAMs based on emerging non-volatile memories, considering the dominant contribution of the encoder module to the energy and latency landscape specifically for complex datasets such as language recognition, DNA sequencing, etc., in this work, we propose energy- and area-efficient single FDSOI ferroelectric (Fe)FET-based logic-in-memory implementations of XOR and 3-input majority gates for N-gram HD encoders. We utilize the proposed FeFET-based encoder in a HD spam filtering accelerator and show that it outperforms the prior emerging non-volatile memory-based implementations in terms of area and energy-efficiency while exhibiting a high classification accuracy of 91.38% on the SMS Spam Collection dataset.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eFDSOI\u94c1\u7535\u573a\u6548\u5e94\u6676\u4f53\u7ba1\u7684\u903b\u8f91\u5185\u5b58\u67b6\u6784\uff0c\u7528\u4e8e\u8d85\u7ef4\u8ba1\u7b97\u7f16\u7801\u5668\uff0c\u5728\u5783\u573e\u90ae\u4ef6\u8fc7\u6ee4\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u80fd\u6548\u548c\u9ad8\u7cbe\u5ea6", "motivation": "\u8d85\u7ef4\u8ba1\u7b97\u4e2d\u7f16\u7801\u5668\u6a21\u5757\u5bf9\u590d\u6742\u6570\u636e\u96c6\uff08\u5982\u8bed\u8a00\u8bc6\u522b\u3001DNA\u6d4b\u5e8f\uff09\u7684\u80fd\u8017\u548c\u5ef6\u8fdf\u8d21\u732e\u6700\u5927\uff0c\u800c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4f7f\u7528\u65b0\u5174\u975e\u6613\u5931\u6027\u5b58\u50a8\u5668\u52a0\u901f\u641c\u7d22\u64cd\u4f5c\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7f16\u7801\u5668\u5b9e\u73b0\u65b9\u6848", "method": "\u63d0\u51fa\u57fa\u4e8e\u5355FDSOI\u94c1\u7535\u573a\u6548\u5e94\u6676\u4f53\u7ba1\u7684\u903b\u8f91\u5185\u5b58\u67b6\u6784\uff0c\u5b9e\u73b0XOR\u548c3\u8f93\u5165\u591a\u6570\u95e8\uff0c\u7528\u4e8eN-gram\u8d85\u7ef4\u8ba1\u7b97\u7f16\u7801\u5668\uff0c\u5e76\u5728\u5783\u573e\u90ae\u4ef6\u8fc7\u6ee4\u52a0\u901f\u5668\u4e2d\u5e94\u7528", "result": "\u5728SMS\u5783\u573e\u90ae\u4ef6\u6536\u96c6\u6570\u636e\u96c6\u4e0a\u8fbe\u523091.38%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5728\u9762\u79ef\u548c\u80fd\u6548\u65b9\u9762\u4f18\u4e8e\u5148\u524d\u57fa\u4e8e\u65b0\u5174\u975e\u6613\u5931\u6027\u5b58\u50a8\u5668\u7684\u5b9e\u73b0\u65b9\u6848", "conclusion": "\u57fa\u4e8eFeFET\u7684\u903b\u8f91\u5185\u5b58\u7f16\u7801\u5668\u4e3a\u8d85\u7ef4\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9762\u79ef\u548c\u80fd\u6548\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u6570\u636e\u96c6\u5904\u7406\u4efb\u52a1"}}
{"id": "2512.20225", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2512.20225", "abs": "https://arxiv.org/abs/2512.20225", "authors": ["Letizia Milli", "Laura Pollacci", "Riccardo Guidotti"], "title": "Evaluating Moderation in Online Social Network", "comment": "Accepted and Presented at EDAI 2025 (Evolutionary Dynamics in social, cooperative and hybrid AI), 26.10, 2025, Bologna, Italy", "summary": "The spread of toxic content on online platforms presents complex challenges that call for both theoretical insight and practical tools to test intervention strategies. In this novel research paper, we introduce a simulation-based framework that extends the classical SEIZ (Susceptible-Exposed-Infected-Skeptic) epidemic model to capture the dynamics of toxic message propagation. Our simulator incorporates active moderation mechanisms through two distinct variants: a basic moderator, which implements uniform, non-personalized interventions, and smart moderator, which leverages user-specific psychological profiles based on Dark Triad traits to apply personalized, threshold-driven moderation. By varying parameter configurations, the simulator allows for systematic exploration of how different moderation strategies influence user state transitions over time. Simulation results demonstrate that while generic interventions can curb toxicity under certain conditions, profile-aware moderation proves significantly more effective in limiting both the spread and persistence of toxic behavior. This simulation framework offers a flexible and extensible tool for studying and designing adaptive moderation strategies in complex online social systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSEIZ\u4f20\u67d3\u75c5\u6a21\u578b\u7684\u6bd2\u6027\u5185\u5bb9\u4f20\u64ad\u4eff\u771f\u6846\u67b6\uff0c\u5305\u542b\u57fa\u7840\u7248\u548c\u667a\u80fd\u7248\u4e24\u79cd\u5ba1\u6838\u673a\u5236\uff0c\u667a\u80fd\u7248\u5229\u7528\u9ed1\u6697\u4e09\u4eba\u683c\u7279\u8d28\u8fdb\u884c\u4e2a\u6027\u5316\u9608\u503c\u9a71\u52a8\u5ba1\u6838\uff0c\u8bc1\u660e\u4e2a\u6027\u5316\u5ba1\u6838\u6bd4\u901a\u7528\u5e72\u9884\u66f4\u6709\u6548\u3002", "motivation": "\u5728\u7ebf\u5e73\u53f0\u6bd2\u6027\u5185\u5bb9\u4f20\u64ad\u5e26\u6765\u590d\u6742\u6311\u6218\uff0c\u9700\u8981\u7406\u8bba\u6d1e\u5bdf\u548c\u5b9e\u7528\u5de5\u5177\u6765\u6d4b\u8bd5\u5e72\u9884\u7b56\u7565\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7528\u6237\u5fc3\u7406\u7279\u5f81\u8003\u8651\u548c\u7cfb\u7edf\u5316\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6269\u5c55\u7ecf\u5178SEIZ\u4f20\u67d3\u75c5\u6a21\u578b\uff0c\u5f00\u53d1\u4eff\u771f\u6846\u67b6\u5305\u542b\u4e24\u79cd\u5ba1\u6838\u53d8\u4f53\uff1a\u57fa\u7840\u5ba1\u6838\u5668\uff08\u7edf\u4e00\u975e\u4e2a\u6027\u5316\u5e72\u9884\uff09\u548c\u667a\u80fd\u5ba1\u6838\u5668\uff08\u57fa\u4e8e\u9ed1\u6697\u4e09\u4eba\u683c\u7279\u8d28\u7684\u7528\u6237\u5fc3\u7406\u753b\u50cf\uff0c\u91c7\u7528\u4e2a\u6027\u5316\u9608\u503c\u9a71\u52a8\u5ba1\u6838\uff09\uff0c\u901a\u8fc7\u53c2\u6570\u914d\u7f6e\u7cfb\u7edf\u63a2\u7d22\u4e0d\u540c\u5ba1\u6838\u7b56\u7565\u5bf9\u7528\u6237\u72b6\u6001\u8f6c\u53d8\u7684\u5f71\u54cd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u901a\u7528\u5e72\u9884\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u4ee5\u6291\u5236\u6bd2\u6027\uff0c\u4f46\u57fa\u4e8e\u5fc3\u7406\u753b\u50cf\u7684\u4e2a\u6027\u5316\u5ba1\u6838\u5728\u9650\u5236\u6bd2\u6027\u884c\u4e3a\u4f20\u64ad\u548c\u6301\u4e45\u6027\u65b9\u9762\u663e\u8457\u66f4\u6709\u6548\u3002", "conclusion": "\u8be5\u4eff\u771f\u6846\u67b6\u4e3a\u7814\u7a76\u548c\u8bbe\u8ba1\u590d\u6742\u5728\u7ebf\u793e\u4ea4\u7cfb\u7edf\u4e2d\u7684\u81ea\u9002\u5e94\u5ba1\u6838\u7b56\u7565\u63d0\u4f9b\u4e86\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u4e2a\u6027\u5316\u5fc3\u7406\u7279\u5f81\u9a71\u52a8\u7684\u5ba1\u6838\u7b56\u7565\u4f18\u4e8e\u4f20\u7edf\u7edf\u4e00\u5e72\u9884\u3002"}}
{"id": "2512.19866", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2512.19866", "abs": "https://arxiv.org/abs/2512.19866", "authors": ["Samuel Jacob Chacko", "An-I Andy Wang", "Lara Perez-Felkner", "Sonia Haiduc", "David Whalley", "Xiuwen Liu"], "title": "CS-Guide: Leveraging LLMs and Student Reflections to Provide Frequent, Scalable Academic Monitoring Feedback to Computer Science Students", "comment": "10 pages, 2 figures", "summary": "Computer Science (CS) departments often serve large student populations, making timely academic monitoring and personalized feedback difficult. While the recommended counselor-to-student ratio is 250:1, it often exceeds 350:1 in practice, leading to delays in support and interventions. We present CS-Guide, which leverages Large Language Models (LLMs) to deliver scalable, frequent academic feedback. Weekly, students interact with CS-Guide through self-reported grades and reflective journal entries, from which CS-Guide extracts quantitative and qualitative features and triggers tailored interventions (e.g., academic support, health and wellness referrals). Thus, CS-Guide uniquely integrates learning analytics, LLMs, and actionable interventions using both structured and unstructured student-generated data.\n  We evaluated CS-Guide on a four-year, ~20K-entry longitudinal dataset, and it achieved up to a 97% F1 score in recommending interventions for first-year students. This shows that CS-Guide can enhance advising systems with scalable, consistent, timely, and domain-specific feedback.", "AI": {"tldr": "CS-Guide\uff1a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3aCS\u5b66\u751f\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u5b66\u672f\u76d1\u63a7\u548c\u4e2a\u6027\u5316\u53cd\u9988\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b66\u751f\u6bcf\u5468\u7684\u81ea\u8bc4\u548c\u53cd\u601d\u751f\u6210\u5e72\u9884\u5efa\u8bae", "motivation": "CS\u9662\u7cfb\u5b66\u751f\u6570\u91cf\u5e9e\u5927\uff0c\u5e08\u751f\u6bd4\u4f8b\u8fdc\u8d85\u63a8\u8350\u6807\u51c6\uff08350:1 vs 250:1\uff09\uff0c\u5bfc\u81f4\u5b66\u672f\u76d1\u63a7\u548c\u4e2a\u6027\u5316\u53cd\u9988\u96be\u4ee5\u53ca\u65f6\u63d0\u4f9b\uff0c\u9700\u8981\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5f00\u53d1CS-Guide\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u5b66\u751f\u6bcf\u5468\u63d0\u4ea4\u7684\u6210\u7ee9\u81ea\u8bc4\u548c\u53cd\u601d\u65e5\u8bb0\uff0c\u4ece\u4e2d\u63d0\u53d6\u5b9a\u91cf\u548c\u5b9a\u6027\u7279\u5f81\uff0c\u89e6\u53d1\u5b9a\u5236\u5316\u5e72\u9884\u63aa\u65bd\uff08\u5982\u5b66\u672f\u652f\u6301\u3001\u5065\u5eb7\u8f6c\u4ecb\uff09", "result": "\u5728\u56db\u5e74\u7ea62\u4e07\u6761\u7eb5\u5411\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cCS-Guide\u5728\u4e3a\u5927\u4e00\u5b66\u751f\u63a8\u8350\u5e72\u9884\u63aa\u65bd\u65b9\u9762\u8fbe\u523097%\u7684F1\u5206\u6570", "conclusion": "CS-Guide\u80fd\u591f\u901a\u8fc7\u6574\u5408\u5b66\u4e60\u5206\u6790\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u53ef\u64cd\u4f5c\u5e72\u9884\uff0c\u4e3a\u5b66\u672f\u6307\u5bfc\u7cfb\u7edf\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u4e00\u81f4\u3001\u53ca\u65f6\u4e14\u9886\u57df\u7279\u5b9a\u7684\u53cd\u9988"}}
{"id": "2512.19937", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.19937", "abs": "https://arxiv.org/abs/2512.19937", "authors": ["Eric Yeh", "John Cadigan", "Ran Chen", "Dick Crouch", "Melinda Gervasio", "Dayne Freitag"], "title": "Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs", "comment": "20 pages, 5 figures", "summary": "Recent research has explored using very large language models (LLMs) as proxies for humans in tasks such as simulation, surveys, and studies. While LLMs do not possess a human psychology, they often can emulate human behaviors with sufficiently high fidelity to drive simulations to test human behavioral hypotheses, exhibiting more nuance and range than the rule-based agents often employed in behavioral economics. One key area of interest is the effect of personality on decision making, but the requirement that a prompt must be created for every tested personality profile introduces experimental overhead and degrades replicability. To address this issue, we leverage interpolative decoding, representing each dimension of personality as a pair of opposed prompts and employing an interpolation parameter to simulate behavior along the dimension. We show that interpolative decoding reliably modulates scores along each of the Big Five dimensions. We then show how interpolative decoding causes LLMs to mimic human decision-making behavior in economic games, replicating results from human psychological research. Finally, we present preliminary results of our efforts to ``twin'' individual human players in a collaborative game through systematic search for points in interpolation space that cause the system to replicate actions taken by the human subject.", "AI": {"tldr": "\u4f7f\u7528\u63d2\u503c\u89e3\u7801\u65b9\u6cd5\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u4eba\u7c7b\u4eba\u683c\u7279\u8d28\uff0c\u5728\u7ecf\u6d4e\u5b66\u6e38\u620f\u4e2d\u590d\u73b0\u4eba\u7c7b\u51b3\u7b56\u884c\u4e3a", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u4eba\u7c7b\u4ee3\u7406\u8fdb\u884c\u884c\u4e3a\u6a21\u62df\uff0c\u4f46\u4e3a\u6bcf\u4e2a\u4eba\u683c\u7279\u5f81\u521b\u5efa\u63d0\u793a\u4f1a\u589e\u52a0\u5b9e\u9a8c\u8d1f\u62c5\u5e76\u964d\u4f4e\u53ef\u91cd\u590d\u6027\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u6a21\u62df\u4e0d\u540c\u4eba\u683c\u7279\u8d28\u5bf9\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u63d2\u503c\u89e3\u7801\u6280\u672f\uff0c\u5c06\u6bcf\u4e2a\u4eba\u683c\u7ef4\u5ea6\u8868\u793a\u4e3a\u4e00\u5bf9\u76f8\u53cd\u7684\u63d0\u793a\uff0c\u901a\u8fc7\u63d2\u503c\u53c2\u6570\u5728\u7ef4\u5ea6\u4e0a\u6a21\u62df\u884c\u4e3a\u3002\u4f7f\u7528\u5927\u4e94\u4eba\u683c\u6a21\u578b\u4f5c\u4e3a\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u641c\u7d22\u63d2\u503c\u7a7a\u95f4\u6765\u5339\u914d\u4eba\u7c7b\u73a9\u5bb6\u7684\u884c\u4e3a\u3002", "result": "\u63d2\u503c\u89e3\u7801\u80fd\u591f\u53ef\u9760\u5730\u8c03\u8282\u5927\u4e94\u4eba\u683c\u5404\u7ef4\u5ea6\u7684\u5f97\u5206\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ecf\u6d4e\u5b66\u6e38\u620f\u4e2d\u590d\u73b0\u4eba\u7c7b\u51b3\u7b56\u884c\u4e3a\uff0c\u6210\u529f\u5339\u914d\u4eba\u7c7b\u5fc3\u7406\u5b66\u7814\u7a76\u7ed3\u679c\u3002\u521d\u6b65\u5b9e\u73b0\u4e86\u5728\u534f\u4f5c\u6e38\u620f\u4e2d\u901a\u8fc7\u63d2\u503c\u7a7a\u95f4\u641c\u7d22\u6765\"\u590d\u5236\"\u4e2a\u4f53\u4eba\u7c7b\u73a9\u5bb6\u7684\u884c\u4e3a\u3002", "conclusion": "\u63d2\u503c\u89e3\u7801\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u91cd\u590d\u7684\u65b9\u6cd5\u6765\u6a21\u62df\u4eba\u683c\u7279\u8d28\u5bf9\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\uff0c\u4e3a\u884c\u4e3a\u7ecf\u6d4e\u5b66\u548c\u5fc3\u7406\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2512.20152", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2512.20152", "abs": "https://arxiv.org/abs/2512.20152", "authors": ["Pooyan Amir-Ahmadi", "Marko Mlikota", "Dalibor Stevanovi\u0107"], "title": "Origins and Nature of Macroeconomic Instability in Vector Autoregressions", "comment": null, "summary": "For a general class of dynamic and stochastic structural models, we show that (i) non-linearity in economic dynamics is a necessary and sufficient condition for time-varying parameters (TVPs) in the reduced-form VARMA process followed by observables, and (ii) all parameters' time-variation is driven by the same, typically few sources of stochasticity: the structural shocks. Our results call into question the common interpretation that TVPs are due to \"structural instabilities\". Motivated by our theoretical analysis, we model a set of macroeconomic and financial variables as a TVP-VAR with a factor-structure in TVPs. This reveals that most instabilities are driven by a few factors, which comove strongly with measures of macroeconomic uncertainty and the contribution of finance to real economic activity, commonly emphasized as important sources of non-linearities in macroeconomics. Furthermore, our model yields improved forecasts relative to the standard TVP-VAR where TVPs evolve as independent random walks.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u975e\u7ebf\u6027\u7ecf\u6d4e\u52a8\u6001\u662f\u65f6\u53d8\u53c2\u6570\u7684\u5fc5\u8981\u5145\u5206\u6761\u4ef6\uff0c\u4e14\u65f6\u53d8\u53c2\u6570\u7531\u5c11\u6570\u7ed3\u6784\u6027\u51b2\u51fb\u9a71\u52a8\uff0c\u6311\u6218\u4e86\"\u7ed3\u6784\u4e0d\u7a33\u5b9a\u6027\"\u7684\u4f20\u7edf\u89e3\u91ca\u3002\u5b9e\u8bc1\u663e\u793a\u5b8f\u89c2\u91d1\u878d\u53d8\u91cf\u7684\u65f6\u53d8\u53c2\u6570\u53ef\u7531\u5c11\u6570\u56e0\u5b50\u89e3\u91ca\uff0c\u8fd9\u4e9b\u56e0\u5b50\u4e0e\u5b8f\u89c2\u7ecf\u6d4e\u4e0d\u786e\u5b9a\u6027\u548c\u91d1\u878d\u5bf9\u5b9e\u4f53\u7ecf\u6d4e\u7684\u8d21\u732e\u5bc6\u5207\u76f8\u5173\uff0c\u4e14\u6a21\u578b\u9884\u6d4b\u4f18\u4e8e\u6807\u51c6\u65f6\u53d8\u53c2\u6570VAR\u3002", "motivation": "\u4f20\u7edf\u4e0a\uff0c\u65f6\u53d8\u53c2\u6570\u5e38\u88ab\u89e3\u91ca\u4e3a\"\u7ed3\u6784\u4e0d\u7a33\u5b9a\u6027\"\uff0c\u4f46\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e00\u89e3\u91ca\u3002\u4f5c\u8005\u5e0c\u671b\u8bc1\u660e\u65f6\u53d8\u53c2\u6570\u5b9e\u9645\u4e0a\u6e90\u4e8e\u7ecf\u6d4e\u52a8\u6001\u7684\u975e\u7ebf\u6027\u7279\u5f81\uff0c\u800c\u975e\u7ed3\u6784\u672c\u8eab\u7684\u4e0d\u7a33\u5b9a\uff0c\u5e76\u4e14\u8fd9\u4e9b\u65f6\u53d8\u53c2\u6570\u7531\u5c11\u6570\u7ed3\u6784\u6027\u51b2\u51fb\u9a71\u52a8\u3002", "method": "1. \u7406\u8bba\u5206\u6790\uff1a\u8bc1\u660e\u975e\u7ebf\u6027\u7ecf\u6d4e\u52a8\u6001\u662f\u65f6\u53d8\u53c2\u6570\u7684\u5fc5\u8981\u5145\u5206\u6761\u4ef6\uff0c\u4e14\u6240\u6709\u53c2\u6570\u7684\u65f6\u53d8\u6027\u90fd\u7531\u76f8\u540c\u7684\u5c11\u6570\u7ed3\u6784\u6027\u51b2\u51fb\u9a71\u52a8\u30022. \u5b9e\u8bc1\u5efa\u6a21\uff1a\u4f7f\u7528\u65f6\u53d8\u53c2\u6570VAR\u6a21\u578b\uff0c\u4f46\u5728\u65f6\u53d8\u53c2\u6570\u4e2d\u5f15\u5165\u56e0\u5b50\u7ed3\u6784\uff0c\u4ee5\u6355\u6349\u5c11\u6570\u5171\u540c\u9a71\u52a8\u56e0\u7d20\u3002", "result": "1. \u7406\u8bba\u7ed3\u679c\uff1a\u6311\u6218\u4e86\u65f6\u53d8\u53c2\u6570\u6e90\u4e8e\"\u7ed3\u6784\u4e0d\u7a33\u5b9a\u6027\"\u7684\u4f20\u7edf\u89c2\u70b9\uff0c\u8bc1\u660e\u5b83\u4eec\u5b9e\u9645\u4e0a\u53cd\u6620\u4e86\u7ecf\u6d4e\u52a8\u6001\u7684\u975e\u7ebf\u6027\u7279\u5f81\u30022. \u5b9e\u8bc1\u7ed3\u679c\uff1a\u5b8f\u89c2\u91d1\u878d\u53d8\u91cf\u7684\u65f6\u53d8\u53c2\u6570\u4e3b\u8981\u7531\u5c11\u6570\u56e0\u5b50\u9a71\u52a8\uff0c\u8fd9\u4e9b\u56e0\u5b50\u4e0e\u5b8f\u89c2\u7ecf\u6d4e\u4e0d\u786e\u5b9a\u6027\u548c\u91d1\u878d\u5bf9\u5b9e\u4f53\u7ecf\u6d4e\u7684\u8d21\u732e\u9ad8\u5ea6\u76f8\u5173\u30023. \u9884\u6d4b\u8868\u73b0\uff1a\u56e0\u5b50\u7ed3\u6784\u7684\u65f6\u53d8\u53c2\u6570VAR\u6a21\u578b\u9884\u6d4b\u4f18\u4e8e\u6807\u51c6\u7684\u72ec\u7acb\u968f\u673a\u6e38\u8d70\u65f6\u53d8\u53c2\u6570VAR\u6a21\u578b\u3002", "conclusion": "\u65f6\u53d8\u53c2\u6570\u4e0d\u5e94\u88ab\u7b80\u5355\u89e3\u91ca\u4e3a\u7ed3\u6784\u4e0d\u7a33\u5b9a\u6027\uff0c\u800c\u662f\u7ecf\u6d4e\u52a8\u6001\u975e\u7ebf\u6027\u7684\u4f53\u73b0\uff0c\u4e14\u7531\u5c11\u6570\u7ed3\u6784\u6027\u51b2\u51fb\u9a71\u52a8\u3002\u8fd9\u79cd\u7406\u89e3\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u5efa\u6a21\u548c\u9884\u6d4b\u5b8f\u89c2\u7ecf\u6d4e\u6ce2\u52a8\uff0c\u5e76\u4e3a\u653f\u7b56\u5206\u6790\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u57fa\u7840\u3002"}}
{"id": "2512.19976", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2512.19976", "abs": "https://arxiv.org/abs/2512.19976", "authors": ["C. Ram\u00edrez-Dolores", "J. C. Zamora-Luria", "J. A. Altamirano-Acosta", "L. Sarao-Cruz", "P. Jim\u00e9nez-Palma", "J. Moreno-Falconi"], "title": "Prediction Air Temperature in Geothermal Heat Exchangers Using Pseudorandom Numbers: The New DARL Model", "comment": "6 pages, 5 figures, 3 tables", "summary": "The use of Earth-Air-Water Heat Exchangers (EAWHE) for sustainable air conditioning has not been widely studied. Due to their experimental nature, methods of characterizing internal thermal air distribution impose high dependence on instrumentation by sensors and entail data acquisition and computational costs. This document presents an alternative method that estimates air temperature distribution while minimizing the need for a dense network of sensors in the experimental system. The proposed model, DARL (Data of Air and Random Length), can predict the temperature of air circulating inside EAWHEs. DARL is a significant methodological advance that integrates experimental data from boundary conditions with simulations based on pseudo-random numbers (PRNs). These PRNs are generated using Fermat's prime numbers as seeds to initialize the generator. Ordinary linear regressions and robust statistical validations, including the Shapiro-Wilk test and root mean square error, have demonstrated that the model can estimate the thermal distribution of air at different lengths with a relative error of less than 6.2%. These results demonstrate the model's efficiency, predictive capacity, and potential to reduce dependence on sensors.", "AI": {"tldr": "\u63d0\u51faDARL\u6a21\u578b\uff0c\u5229\u7528\u8fb9\u754c\u6761\u4ef6\u5b9e\u9a8c\u6570\u636e\u548c\u4f2a\u968f\u673a\u6570\u6a21\u62df\uff0c\u9884\u6d4b\u5730-\u7a7a-\u6c34\u70ed\u4ea4\u6362\u5668\u5185\u90e8\u7a7a\u6c14\u6e29\u5ea6\u5206\u5e03\uff0c\u51cf\u5c11\u5bf9\u5bc6\u96c6\u4f20\u611f\u5668\u7f51\u7edc\u7684\u4f9d\u8d56\uff0c\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e6.2%\u3002", "motivation": "\u5730-\u7a7a-\u6c34\u70ed\u4ea4\u6362\u5668\uff08EAWHE\uff09\u7528\u4e8e\u53ef\u6301\u7eed\u7a7a\u8c03\u7684\u7814\u7a76\u4e0d\u8db3\uff0c\u73b0\u6709\u8868\u5f81\u5185\u90e8\u70ed\u7a7a\u6c14\u5206\u5e03\u7684\u65b9\u6cd5\u4f9d\u8d56\u5bc6\u96c6\u4f20\u611f\u5668\u7f51\u7edc\uff0c\u5bfc\u81f4\u6570\u636e\u91c7\u96c6\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51faDARL\uff08\u7a7a\u6c14\u6570\u636e\u548c\u968f\u673a\u957f\u5ea6\uff09\u6a21\u578b\uff0c\u6574\u5408\u8fb9\u754c\u6761\u4ef6\u5b9e\u9a8c\u6570\u636e\u4e0e\u57fa\u4e8e\u4f2a\u968f\u673a\u6570\u7684\u6a21\u62df\u3002\u4f7f\u7528\u8d39\u9a6c\u7d20\u6570\u4f5c\u4e3a\u79cd\u5b50\u521d\u59cb\u5316\u968f\u673a\u6570\u751f\u6210\u5668\uff0c\u901a\u8fc7\u666e\u901a\u7ebf\u6027\u56de\u5f52\u548c\u7a33\u5065\u7edf\u8ba1\u9a8c\u8bc1\uff08Shapiro-Wilk\u68c0\u9a8c\u548c\u5747\u65b9\u6839\u8bef\u5dee\uff09\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6a21\u578b\u80fd\u591f\u4ee5\u4f4e\u4e8e6.2%\u7684\u76f8\u5bf9\u8bef\u5dee\u4f30\u8ba1\u4e0d\u540c\u957f\u5ea6\u5904\u7684\u7a7a\u6c14\u70ed\u5206\u5e03\uff0c\u8bc1\u660e\u4e86\u5176\u6548\u7387\u3001\u9884\u6d4b\u80fd\u529b\u4ee5\u53ca\u51cf\u5c11\u4f20\u611f\u5668\u4f9d\u8d56\u7684\u6f5c\u529b\u3002", "conclusion": "DARL\u6a21\u578b\u662f\u91cd\u8981\u7684\u65b9\u6cd5\u5b66\u8fdb\u6b65\uff0c\u80fd\u591f\u6709\u6548\u9884\u6d4bEAWHE\u5185\u90e8\u7a7a\u6c14\u6e29\u5ea6\u5206\u5e03\uff0c\u663e\u8457\u51cf\u5c11\u5bf9\u5bc6\u96c6\u4f20\u611f\u5668\u7f51\u7edc\u7684\u4f9d\u8d56\uff0c\u4e3a\u53ef\u6301\u7eed\u7a7a\u8c03\u7cfb\u7edf\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2512.19957", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.19957", "abs": "https://arxiv.org/abs/2512.19957", "authors": ["Luciano Araujo Dourado Filho", "Almir Moreira da Silva Neto", "Rodrigo Pereira David", "Rodrigo Tripodi Calumby"], "title": "Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification", "comment": null, "summary": "This paper presents an approach developed to address the PlantClef 2025 challenge, which consists of a fine-grained multi-label species identification, over high-resolution images. Our solution focused on employing class prototypes obtained from the training dataset as a proxy guidance for training a segmentation Vision Transformer (ViT) on the test set images. To obtain these representations, the proposed method extracts features from training dataset images and create clusters, by applying K-Means, with $K$ equals to the number of classes in the dataset. The segmentation model is a customized narrow ViT, built by replacing the patch embedding layer with a frozen DinoV2, pre-trained on the training dataset for individual species classification. This model is trained to reconstruct the class prototypes of the training dataset from the test dataset images. We then use this model to obtain attention scores that enable to identify and localize areas of interest and consequently guide the classification process. The proposed approach enabled a domain-adaptation from multi-class identification with individual species, into multi-label classification from high-resolution vegetation plots. Our method achieved fifth place in the PlantCLEF 2025 challenge on the private leaderboard, with an F1 score of 0.33331. Besides that, in absolute terms our method scored 0.03 lower than the top-performing submission, suggesting that it may achieved competitive performance in the benchmark task. Our code is available at \\href{https://github.com/ADAM-UEFS/PlantCLEF2025}{https://github.com/ADAM-UEFS/PlantCLEF2025}.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7c7b\u522b\u539f\u578b\u5f15\u5bfc\u7684\u89c6\u89c9Transformer\u5206\u5272\u65b9\u6cd5\uff0c\u7528\u4e8ePlantCLEF 2025\u6311\u6218\u8d5b\u4e2d\u7684\u7ec6\u7c92\u5ea6\u591a\u6807\u7b7e\u7269\u79cd\u8bc6\u522b\uff0c\u5728\u79c1\u6709\u6392\u884c\u699c\u4e0a\u83b7\u5f97\u7b2c\u4e94\u540d\u3002", "motivation": "\u89e3\u51b3PlantCLEF 2025\u6311\u6218\u8d5b\u4e2d\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u4e0a\u7684\u7ec6\u7c92\u5ea6\u591a\u6807\u7b7e\u7269\u79cd\u8bc6\u522b\u95ee\u9898\uff0c\u901a\u8fc7\u8bad\u7ec3\u96c6\u7c7b\u522b\u539f\u578b\u5f15\u5bfc\u6d4b\u8bd5\u96c6\u56fe\u50cf\u5206\u5272\uff0c\u5b9e\u73b0\u4ece\u5355\u7269\u79cd\u591a\u7c7b\u522b\u8bc6\u522b\u5230\u690d\u88ab\u5730\u5757\u591a\u6807\u7b7e\u5206\u7c7b\u7684\u9886\u57df\u9002\u5e94\u3002", "method": "\u4f7f\u7528K-Means\u805a\u7c7b\u4ece\u8bad\u7ec3\u96c6\u56fe\u50cf\u7279\u5f81\u4e2d\u63d0\u53d6\u7c7b\u522b\u539f\u578b\uff0c\u6784\u5efa\u5b9a\u5236\u5316\u7684\u7a84\u89c6\u89c9Transformer\uff0c\u7528\u51bb\u7ed3\u7684DinoV2\u9884\u8bad\u7ec3\u6a21\u578b\u66ff\u6362patch\u5d4c\u5165\u5c42\uff0c\u8bad\u7ec3\u6a21\u578b\u4ece\u6d4b\u8bd5\u96c6\u56fe\u50cf\u91cd\u5efa\u8bad\u7ec3\u96c6\u7c7b\u522b\u539f\u578b\uff0c\u5229\u7528\u6ce8\u610f\u529b\u5206\u6570\u8bc6\u522b\u611f\u5174\u8da3\u533a\u57df\u5e76\u6307\u5bfc\u5206\u7c7b\u3002", "result": "\u5728PlantCLEF 2025\u6311\u6218\u8d5b\u79c1\u6709\u6392\u884c\u699c\u4e0a\u83b7\u5f97\u7b2c\u4e94\u540d\uff0cF1\u5206\u6570\u4e3a0.33331\uff0c\u4e0e\u6700\u4f73\u63d0\u4ea4\u7ed3\u679c\u4ec5\u76f8\u5dee0.03\uff0c\u8868\u73b0\u51fa\u7ade\u4e89\u6027\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8e\u7c7b\u522b\u539f\u578b\u5f15\u5bfc\u7684\u89c6\u89c9Transformer\u5206\u5272\u65b9\u6cd5\u5728\u7ec6\u7c92\u5ea6\u591a\u6807\u7b7e\u7269\u79cd\u8bc6\u522b\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u5b9e\u73b0\u4e86\u4ece\u5355\u7269\u79cd\u5206\u7c7b\u5230\u690d\u88ab\u5730\u5757\u591a\u6807\u7b7e\u5206\u7c7b\u7684\u9886\u57df\u9002\u5e94\uff0c\u5177\u6709\u7ade\u4e89\u6027\u6027\u80fd\u3002"}}
{"id": "2512.20523", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.20523", "abs": "https://arxiv.org/abs/2512.20523", "authors": ["Masahiro Kato"], "title": "ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification", "comment": null, "summary": "This study proposes Riesz representer estimation methods based on score matching. The Riesz representer is a key component in debiased machine learning for constructing $\\sqrt{n}$-consistent and efficient estimators in causal inference and structural parameter estimation. To estimate the Riesz representer, direct approaches have garnered attention, such as Riesz regression and the covariate balancing propensity score. These approaches can also be interpreted as variants of direct density ratio estimation (DRE) in several applications such as average treatment effect estimation. In DRE, it is well known that flexible models can easily overfit the observed data due to the estimand and the form of the loss function. To address this issue, recent work has proposed modeling the density ratio as a product of multiple intermediate density ratios and estimating it using score-matching techniques, which are often used in the diffusion model literature. We extend score-matching-based DRE methods to Riesz representer estimation. Our proposed method not only mitigates overfitting but also provides insights for causal inference by bridging marginal effects and average policy effects through time score functions.", "AI": {"tldr": "\u5c06\u57fa\u4e8e\u5206\u6570\u5339\u914d\u7684\u76f4\u63a5\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u65b9\u6cd5\u6269\u5c55\u5230Riesz\u8868\u793a\u5668\u4f30\u8ba1\uff0c\u4ee5\u89e3\u51b3\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5e76\u4e3a\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u65b0\u89c6\u89d2", "motivation": "Riesz\u8868\u793a\u5668\u662f\u53bb\u504f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u7528\u4e8e\u6784\u5efa\u221an\u4e00\u81f4\u4e14\u9ad8\u6548\u7684\u56e0\u679c\u63a8\u65ad\u548c\u7ed3\u6784\u53c2\u6570\u4f30\u8ba1\u5668\u3002\u73b0\u6709\u7684\u76f4\u63a5\u4f30\u8ba1\u65b9\u6cd5\uff08\u5982Riesz\u56de\u5f52\u548c\u534f\u53d8\u91cf\u5e73\u8861\u503e\u5411\u5f97\u5206\uff09\u5bb9\u6613\u56e0\u7075\u6d3b\u6a21\u578b\u548c\u635f\u5931\u51fd\u6570\u5f62\u5f0f\u5bfc\u81f4\u8fc7\u62df\u5408\u95ee\u9898", "method": "\u5c06\u57fa\u4e8e\u5206\u6570\u5339\u914d\u7684\u76f4\u63a5\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u65b9\u6cd5\u6269\u5c55\u5230Riesz\u8868\u793a\u5668\u4f30\u8ba1\u3002\u8be5\u65b9\u6cd5\u5c06\u5bc6\u5ea6\u6bd4\u5efa\u6a21\u4e3a\u591a\u4e2a\u4e2d\u95f4\u5bc6\u5ea6\u6bd4\u7684\u4e58\u79ef\uff0c\u5e76\u5229\u7528\u6269\u6563\u6a21\u578b\u6587\u732e\u4e2d\u5e38\u7528\u7684\u5206\u6570\u5339\u914d\u6280\u672f\u8fdb\u884c\u4f30\u8ba1", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u7f13\u89e3\u4e86\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u8fd8\u901a\u8fc7\u65f6\u95f4\u5206\u6570\u51fd\u6570\u5c06\u8fb9\u9645\u6548\u5e94\u548c\u5e73\u5747\u653f\u7b56\u6548\u5e94\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c1\u89e3", "conclusion": "\u57fa\u4e8e\u5206\u6570\u5339\u914d\u7684Riesz\u8868\u793a\u5668\u4f30\u8ba1\u65b9\u6cd5\u4e3a\u89e3\u51b3\u53bb\u504f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u5e76\u5efa\u7acb\u4e86\u56e0\u679c\u63a8\u65ad\u4e2d\u4e0d\u540c\u6548\u5e94\u4f30\u8ba1\u4e4b\u95f4\u7684\u8054\u7cfb"}}
{"id": "2512.20589", "categories": ["cs.CY", "cs.AI", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.20589", "abs": "https://arxiv.org/abs/2512.20589", "authors": ["\u0130brahim O\u011fuz \u00c7etinkaya", "Sajad Khodadadian", "Taylan G. Top\u00e7u"], "title": "Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information", "comment": null, "summary": "As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME. To that end, this paper proposes an intelligent mission coordination methodology that integrates digital mission models with Reinforcement Learning (RL), that specifically addresses the need for adaptive task allocation and reconfiguration. More specifically, we are leveraging a Digital Engineering (DE) based infrastructure that is composed of a high-fidelity digital mission model and agent-based simulation; and then we formulate the mission tactics management problem as a Markov Decision Process (MDP), and employ an RL agent trained via Proximal Policy Optimization. By leveraging the simulation as a sandbox, we map the system states to actions, refining the policy based on realized mission outcomes. The utility of the RL-based intelligent mission coordinator is demonstrated through an aerial firefighting case study. Our findings indicate that the RL-based intelligent mission coordinator not only surpasses baseline performance but also significantly reduces the variability in mission performance. Thus, this study serves as a proof of concept demonstrating that DE-enabled mission simulations combined with advanced analytical tools offer a mission-agnostic framework for improving ME practice; which can be extended to more complicated fleet design and selection problems in the future from a mission-first perspective.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6570\u5b57\u5de5\u7a0b\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u7684\u667a\u80fd\u4efb\u52a1\u534f\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a7a\u4e2d\u706d\u706b\u6848\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u5e76\u964d\u4f4e\u6027\u80fd\u6ce2\u52a8\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u5de5\u7a0b\u76ee\u6807\u4ece\u5355\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u8f6c\u5411\u590d\u6742\u7cfb\u7edf\u4f53\u7cfb\uff0c\u4efb\u52a1\u5de5\u7a0b\u6210\u4e3a\u65b0\u601d\u8def\u3002\u4efb\u52a1\u73af\u5883\u4e0d\u786e\u5b9a\u4e14\u52a8\u6001\uff0c\u9759\u6001\u67b6\u6784\u8106\u5f31\uff0c\u9700\u8981\u5206\u6790\u65b9\u6cd5\u6765\u652f\u6301\u81ea\u9002\u5e94\u4efb\u52a1\u5206\u914d\u548c\u91cd\u6784\u3002", "method": "\u63d0\u51fa\u667a\u80fd\u4efb\u52a1\u534f\u8c03\u65b9\u6cd5\uff0c\u96c6\u6210\u6570\u5b57\u4efb\u52a1\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u3002\u5229\u7528\u6570\u5b57\u5de5\u7a0b\u57fa\u7840\u8bbe\u65bd\uff08\u9ad8\u4fdd\u771f\u6570\u5b57\u4efb\u52a1\u6a21\u578b\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u4eff\u771f\uff09\uff0c\u5c06\u4efb\u52a1\u6218\u672f\u7ba1\u7406\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u3002", "result": "\u901a\u8fc7\u7a7a\u4e2d\u706d\u706b\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u4efb\u52a1\u534f\u8c03\u5668\u4e0d\u4ec5\u8d85\u8d8a\u57fa\u7ebf\u6027\u80fd\uff0c\u8fd8\u663e\u8457\u964d\u4f4e\u4e86\u4efb\u52a1\u6027\u80fd\u7684\u53d8\u5f02\u6027\u3002", "conclusion": "\u6570\u5b57\u5de5\u7a0b\u652f\u6301\u7684\u4efb\u52a1\u4eff\u771f\u4e0e\u5148\u8fdb\u5206\u6790\u5de5\u5177\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4efb\u52a1\u65e0\u5173\u7684\u6846\u67b6\u6765\u6539\u8fdb\u4efb\u52a1\u5de5\u7a0b\u5b9e\u8df5\uff0c\u672a\u6765\u53ef\u4ece\u4efb\u52a1\u4f18\u5148\u89d2\u5ea6\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u7f16\u961f\u8bbe\u8ba1\u548c\u9009\u62e9\u95ee\u9898\u3002"}}
{"id": "2512.19960", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.19960", "abs": "https://arxiv.org/abs/2512.19960", "authors": ["Luciano Araujo Dourado Filho", "Rodrigo Tripodi Calumby"], "title": "FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification", "comment": null, "summary": "Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Categorization (FGVC) tasks. This paper proposes a novel method that aims at leveraging classification performance in FGVC tasks by learning fine-grained features via classification of class-wise cluster assignments. Our goal is to apply clustering over each class individually, which can allow to discover pseudo-labels that encodes a latent degree of similarity between images. In turn, those labels can be employed in a hierarchical classification process that allows to learn more fine-grained visual features and thereby mitigating intra-class variability issues. Initial experiments over the PlantNet300k enabled to shed light upon several key points in which future work will have to be developed in order to find more conclusive evidence regarding the effectiveness of our method. Our method still achieves state-of-the-art performance on the PlantNet300k dataset even though some of its components haven't been shown to be fully optimized. Our code is available at \\href{https://github.com/ADAM-UEFS/FGDCC}{https://github.com/ADAM-UEFS/FGDCC}.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u7c7b\u5185\u805a\u7c7b\u5b66\u4e60\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u7f13\u89e3\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4e2d\u7684\u7c7b\u5185\u53d8\u5f02\u95ee\u9898\uff0c\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u7c7b\u5185\u53d8\u5f02\uff08\u540c\u4e00\u7c7b\u522b\u5185\u56fe\u50cf\u7684\u5dee\u5f02\u7a0b\u5ea6\uff09\u4f1a\u963b\u788d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7279\u522b\u662f\u5f53\u8fd9\u4e9b\u7c7b\u522b\u6837\u672c\u4e0d\u8db3\u65f6\u3002\u9700\u8981\u89e3\u51b3\u7c7b\u5185\u53d8\u5f02\u5bf9\u5206\u7c7b\u6027\u80fd\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u65b9\u6cd5\uff1a\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u5355\u72ec\u8fdb\u884c\u805a\u7c7b\uff0c\u53d1\u73b0\u7f16\u7801\u56fe\u50cf\u95f4\u76f8\u4f3c\u5ea6\u7684\u4f2a\u6807\u7b7e\uff0c\u7136\u540e\u901a\u8fc7\u5206\u5c42\u5206\u7c7b\u8fc7\u7a0b\u5229\u7528\u8fd9\u4e9b\u6807\u7b7e\u5b66\u4e60\u66f4\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u7279\u5f81\uff0c\u4ece\u800c\u7f13\u89e3\u7c7b\u5185\u53d8\u5f02\u95ee\u9898\u3002", "result": "\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u521d\u6b65\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86\u672a\u6765\u5de5\u4f5c\u9700\u8981\u53d1\u5c55\u7684\u5173\u952e\u70b9\u3002\u5c3d\u7ba1\u90e8\u5206\u7ec4\u4ef6\u5c1a\u672a\u5b8c\u5168\u4f18\u5316\uff0c\u4f46\u8be5\u65b9\u6cd5\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u4ecd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u7c7b\u5185\u805a\u7c7b\u5b66\u4e60\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u7f13\u89e3\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4e2d\u7684\u7c7b\u5185\u53d8\u5f02\u95ee\u9898\uff0c\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u601d\u8def\u3002"}}
{"id": "2512.19992", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.19992", "abs": "https://arxiv.org/abs/2512.19992", "authors": ["Zhe Sun", "Xueyuan Yang", "Yujie Lu", "Zhenliang Zhang"], "title": "S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test", "comment": "10 pages, 9 figures", "summary": "The integration of embodied agents into human environments demands embodied social intelligence: reasoning over both social norms and physical constraints. However, existing evaluations fail to address this integration, as they are limited to either disembodied social reasoning (e.g., in text) or socially-agnostic physical tasks. Both approaches fail to assess an agent's ability to integrate and trade off both physical and social constraints within a realistic, embodied context. To address this challenge, we introduce Spatially Situated Social Intelligence Test (S$^{3}$IT), a benchmark specifically designed to evaluate embodied social intelligence. It is centered on a novel and challenging seat-ordering task, requiring an agent to arrange seating in a 3D environment for a group of large language model-driven (LLM-driven) NPCs with diverse identities, preferences, and intricate interpersonal relationships. Our procedurally extensible framework generates a vast and diverse scenario space with controllable difficulty, compelling the agent to acquire preferences through active dialogue, perceive the environment via autonomous exploration, and perform multi-objective optimization within a complex constraint network. We evaluate state-of-the-art LLMs on S$^{3}$IT and found that they still struggle with this problem, showing an obvious gap compared with the human baseline. Results imply that LLMs have deficiencies in spatial intelligence, yet simultaneously demonstrate their ability to achieve near human-level competence in resolving conflicts that possess explicit textual cues.", "AI": {"tldr": "S\u00b3IT\uff1a\u4e00\u4e2a\u8bc4\u4f30\u5177\u8eab\u793e\u4ea4\u667a\u80fd\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc73D\u73af\u5883\u4e2d\u7684\u5ea7\u4f4d\u5b89\u6392\u4efb\u52a1\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u7efc\u5408\u8003\u8651\u793e\u4ea4\u5173\u7cfb\u548c\u7269\u7406\u7ea6\u675f\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u8981\u4e48\u53ea\u5173\u6ce8\u975e\u5177\u8eab\u7684\u793e\u4ea4\u63a8\u7406\uff08\u5982\u6587\u672c\uff09\uff0c\u8981\u4e48\u53ea\u5173\u6ce8\u65e0\u793e\u4ea4\u610f\u8bc6\u7684\u7269\u7406\u4efb\u52a1\uff0c\u65e0\u6cd5\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u5177\u8eab\u73af\u5883\u4e2d\u6574\u5408\u7269\u7406\u548c\u793e\u4ea4\u7ea6\u675f\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faS\u00b3IT\u57fa\u51c6\uff0c\u6838\u5fc3\u662f\u65b0\u9896\u7684\u5ea7\u4f4d\u5b89\u6392\u4efb\u52a1\uff1a\u667a\u80fd\u4f53\u9700\u8981\u57283D\u73af\u5883\u4e2d\u4e3a\u4e00\u7ec4\u5177\u6709\u4e0d\u540c\u8eab\u4efd\u3001\u504f\u597d\u548c\u590d\u6742\u4eba\u9645\u5173\u7cfb\u7684LLM\u9a71\u52a8\u7684NPC\u5b89\u6392\u5ea7\u4f4d\u3002\u4f7f\u7528\u7a0b\u5e8f\u5316\u53ef\u6269\u5c55\u6846\u67b6\u751f\u6210\u5927\u91cf\u591a\u6837\u5316\u573a\u666f\uff0c\u667a\u80fd\u4f53\u9700\u8981\u901a\u8fc7\u4e3b\u52a8\u5bf9\u8bdd\u83b7\u53d6\u504f\u597d\u3001\u81ea\u4e3b\u63a2\u7d22\u611f\u77e5\u73af\u5883\uff0c\u5e76\u5728\u590d\u6742\u7ea6\u675f\u7f51\u7edc\u4e2d\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\u3002", "result": "\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728S\u00b3IT\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u4ecd\u7136\u96be\u4ee5\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u4e0e\u4eba\u7c7b\u57fa\u7ebf\u5b58\u5728\u660e\u663e\u5dee\u8ddd\u3002\u7ed3\u679c\u8868\u660eLLM\u5728\u7a7a\u95f4\u667a\u80fd\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4f46\u5728\u5904\u7406\u5177\u6709\u660e\u786e\u6587\u672c\u7ebf\u7d22\u7684\u51b2\u7a81\u65f6\u80fd\u8fbe\u5230\u63a5\u8fd1\u4eba\u7c7b\u7684\u6c34\u5e73\u3002", "conclusion": "S\u00b3IT\u57fa\u51c6\u586b\u8865\u4e86\u5177\u8eab\u793e\u4ea4\u667a\u80fd\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u6574\u5408\u7269\u7406\u548c\u793e\u4ea4\u7ea6\u675f\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u5177\u8eab\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2512.20043", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20043", "abs": "https://arxiv.org/abs/2512.20043", "authors": ["Jung Yeon Park", "Yuxuan Chen", "Floor Eijkelboom", "Jan-Willem van de Meent", "Lawson L. S. Wong", "Robin Walters"], "title": "Discovering Lie Groups with Flow Matching", "comment": null, "summary": "Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learning symmetries directly from data via flow matching on Lie groups. We formulate symmetry discovery as learning a distribution over a larger hypothesis group, such that the learned distribution matches the symmetries observed in data. Relative to previous works, our method, \\lieflow, is more flexible in terms of the types of groups it can discover and requires fewer assumptions. Experiments on 2D and 3D point clouds demonstrate the successful discovery of discrete groups, including reflections by flow matching over the complex domain. We identify a key challenge where the symmetric arrangement of the target modes causes ``last-minute convergence,'' where samples remain stationary until relatively late in the flow, and introduce a novel interpolation scheme for flow matching for symmetry discovery.", "AI": {"tldr": "\u63d0\u51faLieFlow\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u5728\u674e\u7fa4\u4e0a\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5bf9\u79f0\u6027\uff0c\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\uff0c\u80fd\u591f\u53d1\u73b0\u79bb\u6563\u7fa4\u548c\u53cd\u5c04\u7b49\u5bf9\u79f0\u6027\u3002", "motivation": "\u5bf9\u79f0\u6027\u5bf9\u7406\u89e3\u7269\u7406\u7cfb\u7edf\u548c\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u6027\u80fd\u90fd\u5f88\u91cd\u8981\uff0c\u4f46\u901a\u5e38\u9700\u8981\u5148\u9a8c\u77e5\u8bc6\u3002\u672c\u6587\u65e8\u5728\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u5bf9\u79f0\u6027\uff0c\u65e0\u9700\u5047\u8bbe\u3002", "method": "\u63d0\u51faLieFlow\u65b9\u6cd5\uff0c\u5c06\u5bf9\u79f0\u6027\u53d1\u73b0\u5efa\u6a21\u4e3a\u5728\u66f4\u5927\u7684\u5047\u8bbe\u7fa4\u4e0a\u5b66\u4e60\u5206\u5e03\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u5728\u674e\u7fa4\u4e0a\u5339\u914d\u6570\u636e\u4e2d\u89c2\u5bdf\u5230\u7684\u5bf9\u79f0\u6027\u3002\u5f15\u5165\u65b0\u7684\u63d2\u503c\u65b9\u6848\u89e3\u51b3\"\u6700\u540e\u4e00\u523b\u6536\u655b\"\u95ee\u9898\u3002", "result": "\u57282D\u548c3D\u70b9\u4e91\u6570\u636e\u4e0a\u6210\u529f\u53d1\u73b0\u4e86\u79bb\u6563\u7fa4\uff0c\u5305\u62ec\u901a\u8fc7\u590d\u57df\u6d41\u5339\u914d\u53d1\u73b0\u7684\u53cd\u5c04\u5bf9\u79f0\u6027\u3002\u89e3\u51b3\u4e86\u76ee\u6807\u6a21\u5f0f\u5bf9\u79f0\u6392\u5217\u5bfc\u81f4\u7684\"\u6700\u540e\u4e00\u523b\u6536\u655b\"\u6311\u6218\u3002", "conclusion": "LieFlow\u80fd\u591f\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u5bf9\u79f0\u6027\uff0c\u6bd4\u5148\u524d\u65b9\u6cd5\u66f4\u7075\u6d3b\u3001\u5047\u8bbe\u66f4\u5c11\uff0c\u4e3a\u5bf9\u79f0\u6027\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u6d41\u5339\u914d\u6846\u67b6\u3002"}}
{"id": "2512.20052", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.20052", "abs": "https://arxiv.org/abs/2512.20052", "authors": ["Hung-Chieh Fang", "Kuo-Han Hung", "Chu-Rong Chen", "Po-Jung Chou", "Chun-Kai Yang", "Po-Chen Ko", "Yu-Chiang Wang", "Yueh-Hua Wu", "Min-Hung Chen", "Shao-Hua Sun"], "title": "Learning Skills from Action-Free Videos", "comment": null, "summary": "Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.", "AI": {"tldr": "SOF\u6846\u67b6\u4ece\u65e0\u52a8\u4f5c\u89c6\u9891\u4e2d\u5b66\u4e60\u57fa\u4e8e\u5149\u6d41\u7684\u6f5c\u5728\u6280\u80fd\uff0c\u5b9e\u73b0\u9ad8\u5c42\u89c4\u5212\u5e76\u63d0\u5347\u591a\u4efb\u52a1\u548c\u957f\u65f6\u57df\u4efb\u52a1\u6027\u80fd", "motivation": "\u73b0\u6709\u89c6\u9891\u751f\u6210\u6a21\u578b\u96be\u4ee5\u8f6c\u5316\u4e3a\u4f4e\u7ea7\u52a8\u4f5c\uff0c\u800c\u6f5c\u5728\u52a8\u4f5c\u6a21\u578b\u7f3a\u4e4f\u9ad8\u5c42\u89c4\u5212\u80fd\u529b\uff0c\u9700\u8981\u5f25\u5408\u89c6\u9891\u5b66\u4e60\u4e0e\u673a\u5668\u4eba\u52a8\u4f5c\u6267\u884c\u4e4b\u95f4\u7684\u9e3f\u6c9f", "method": "\u63d0\u51faSOF\u6846\u67b6\uff0c\u901a\u8fc7\u5149\u6d41\u4e2d\u95f4\u8868\u793a\u5b66\u4e60\u6f5c\u5728\u6280\u80fd\u7a7a\u95f4\uff0c\u8be5\u7a7a\u95f4\u540c\u65f6\u6355\u83b7\u89c6\u9891\u52a8\u6001\u548c\u673a\u5668\u4eba\u52a8\u4f5c\u4fe1\u606f\uff0c\u5b9e\u73b0\u57fa\u4e8e\u89c6\u9891\u6280\u80fd\u7684\u9ad8\u5c42\u89c4\u5212", "result": "\u5b9e\u9a8c\u8868\u660eSOF\u5728\u591a\u4efb\u52a1\u548c\u957f\u65f6\u57df\u8bbe\u7f6e\u4e2d\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u80fd\u591f\u76f4\u63a5\u4ece\u539f\u59cb\u89c6\u89c9\u6570\u636e\u4e2d\u83b7\u53d6\u548c\u7ec4\u5408\u6280\u80fd", "conclusion": "SOF\u901a\u8fc7\u5149\u6d41\u4e2d\u95f4\u8868\u793a\u6709\u6548\u8fde\u63a5\u89c6\u9891\u5b66\u4e60\u4e0e\u673a\u5668\u4eba\u52a8\u4f5c\u6267\u884c\uff0c\u4e3a\u4ece\u89c6\u9891\u4e2d\u5b66\u4e60\u901a\u7528\u673a\u5668\u4eba\u6280\u80fd\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84"}}
{"id": "2512.20056", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.20056", "abs": "https://arxiv.org/abs/2512.20056", "authors": ["Hao Li", "Fabian Deuser", "Wenping Yin", "Steffen Knoblauch", "Wufan Zhao", "Filip Biljecki", "Yong Xue", "Wei Huang"], "title": "Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach", "comment": null, "summary": "As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC", "AI": {"tldr": "\u63d0\u51faProbGLC\u6982\u7387\u4ea4\u53c9\u89c6\u89d2\u5730\u7406\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u7ed3\u5408\u6982\u7387\u548c\u786e\u5b9a\u6027\u6a21\u578b\uff0c\u63d0\u5347\u707e\u5bb3\u54cd\u5e94\u4e2d\u7684\u5b9a\u4f4d\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u5bfc\u81f4\u707e\u5bb3\u9891\u53d1\uff0c\u5feb\u901f\u51c6\u786e\u7684\u707e\u5bb3\u4f4d\u7f6e\u8bc6\u522b\u5bf9\u5e94\u6025\u54cd\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u6027\u548c\u5b9a\u4f4d\u6027\u80fd\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faProbGLC\u7edf\u4e00\u6846\u67b6\uff0c\u7ed3\u5408\u6982\u7387\u548c\u786e\u5b9a\u6027\u5730\u7406\u5b9a\u4f4d\u6a21\u578b\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u5c40\u90e8\u5316\u8bc4\u5206\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u591a\u707e\u5bb3\u4e8b\u4ef6\u7684\u4ea4\u53c9\u89c6\u89d2\u5730\u7406\u5b9a\u4f4d\u3002", "result": "\u5728\u4e24\u4e2a\u707e\u5bb3\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cProbGLC\u57281\u516c\u91cc\u7cbe\u5ea6\u8fbe\u52300.86\uff0c25\u516c\u91cc\u7cbe\u5ea6\u8fbe\u52300.97\uff0c\u540c\u65f6\u901a\u8fc7\u6982\u7387\u5206\u5e03\u548c\u5c40\u90e8\u5316\u8bc4\u5206\u63d0\u4f9b\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "ProbGLC\u5c55\u793a\u4e86\u751f\u6210\u5f0f\u4ea4\u53c9\u89c6\u89d2\u65b9\u6cd5\u5728\u707e\u5bb3\u54cd\u5e94\u4e2d\u63d0\u5347\u4f4d\u7f6e\u611f\u77e5\u80fd\u529b\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u66f4\u5feb\u66f4\u597d\u7684\u707e\u5bb3\u54cd\u5e94\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.20061", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20061", "abs": "https://arxiv.org/abs/2512.20061", "authors": ["Hamed Firooz", "Rui Liu", "Yuchen Lu", "Zhenyu Hou", "Fangzhou Xiong", "Xiaoyang Zhang", "Changshu Jian", "Zhicheng Zhu", "Jiayuan Ma", "Jacob Tao", "Chaitali Gupta", "Xiaochang Peng", "Shike Mei", "Hang Cui", "Yang Qin", "Shuo Tang", "Jason Gaedtke", "Arpit Mittal"], "title": "Scaling Reinforcement Learning for Content Moderation with Large Language Models", "comment": null, "summary": "Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential for policy-grounded moderation, the practical challenges of training these systems to achieve expert-level accuracy in real-world settings remain largely unexplored, particularly in regimes characterized by label sparsity, evolving policy definitions, and the need for nuanced reasoning beyond shallow pattern matching. In this work, we present a comprehensive empirical investigation of scaling reinforcement learning (RL) for content classification, systematically evaluating multiple RL training recipes and reward-shaping strategies-including verifiable rewards and LLM-as-judge frameworks-to transform general-purpose language models into specialized, policy-aligned classifiers across three real-world content moderation tasks. Our findings provide actionable insights for industrial-scale moderation systems, demonstrating that RL exhibits sigmoid-like scaling behavior in which performance improves smoothly with increased training data, rollouts, and optimization steps before gradually saturating. Moreover, we show that RL substantially improves performance on tasks requiring complex policy-grounded reasoning while achieving up to 100x higher data efficiency than supervised fine-tuning, making it particularly effective in domains where expert annotations are scarce or costly.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5185\u5bb9\u5ba1\u6838\uff0c\u5728\u771f\u5b9e\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86RL\u7684sigmoid\u5f0f\u6269\u5c55\u884c\u4e3a\uff0c\u76f8\u6bd4\u76d1\u7763\u5fae\u8c03\u5b9e\u73b0\u4e86100\u500d\u6570\u636e\u6548\u7387\u63d0\u5347\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6807\u6ce8\u7a00\u7f3a\u7684\u590d\u6742\u653f\u7b56\u63a8\u7406\u573a\u666f\u3002", "motivation": "\u5927\u89c4\u6a21\u5185\u5bb9\u5ba1\u6838\u662f\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u7684\u7d27\u8feb\u6311\u6218\uff0c\u73b0\u6709LLM\u5728\u653f\u7b56\u5bfc\u5411\u5ba1\u6838\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u5b9e\u73b0\u4e13\u5bb6\u7ea7\u51c6\u786e\u6027\u7684\u5b9e\u9645\u6311\u6218\uff08\u6807\u7b7e\u7a00\u758f\u3001\u653f\u7b56\u6f14\u53d8\u3001\u9700\u8981\u8d85\u8d8a\u6d45\u5c42\u6a21\u5f0f\u5339\u914d\u7684\u7ec6\u81f4\u63a8\u7406\uff09\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5185\u5bb9\u5206\u7c7b\uff0c\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cdRL\u8bad\u7ec3\u65b9\u6848\u548c\u5956\u52b1\u5851\u9020\u7b56\u7565\uff0c\u5305\u62ec\u53ef\u9a8c\u8bc1\u5956\u52b1\u548cLLM\u4f5c\u4e3a\u88c1\u5224\u6846\u67b6\uff0c\u5c06\u901a\u7528\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u4e13\u95e8\u7684\u653f\u7b56\u5bf9\u9f50\u5206\u7c7b\u5668\uff0c\u5728\u4e09\u4e2a\u771f\u5b9e\u5185\u5bb9\u5ba1\u6838\u4efb\u52a1\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "RL\u8868\u73b0\u51fasigmoid\u5f0f\u6269\u5c55\u884c\u4e3a\uff0c\u6027\u80fd\u968f\u8bad\u7ec3\u6570\u636e\u3001rollouts\u548c\u4f18\u5316\u6b65\u9aa4\u589e\u52a0\u800c\u5e73\u6ed1\u63d0\u5347\u540e\u9010\u6e10\u9971\u548c\uff1bRL\u5728\u9700\u8981\u590d\u6742\u653f\u7b56\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u76f8\u6bd4\u76d1\u7763\u5fae\u8c03\u5b9e\u73b0\u9ad8\u8fbe100\u500d\u7684\u6570\u636e\u6548\u7387\u63d0\u5347\uff0c\u5728\u4e13\u5bb6\u6807\u6ce8\u7a00\u7f3a\u6216\u6602\u8d35\u7684\u9886\u57df\u7279\u522b\u6709\u6548\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4e3a\u5de5\u4e1a\u7ea7\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u548c\u653f\u7b56\u63a8\u7406\u590d\u6742\u7684\u573a\u666f\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.20074", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.20074", "abs": "https://arxiv.org/abs/2512.20074", "authors": ["H M Quamran Hasan", "Housam Khalifa Bashier", "Jiayi Dai", "Mi-Young Kim", "Randy Goebel"], "title": "Reason2Decide: Rationale-Driven Multi-Task Learning", "comment": null, "summary": "Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.", "AI": {"tldr": "Reason2Decide\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u89e3\u91ca\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u8bad\u7ec3\u51cf\u5c11\u66b4\u9732\u504f\u5dee\uff0c\u5728\u5c0f\u578b\u6a21\u578b\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u9884\u6d4b\u548c\u89e3\u91ca\u751f\u6210\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u9762\u4e34\u5173\u952e\u6311\u6218\uff1a\u5728\u5b9e\u73b0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u751f\u6210\u4e0e\u9884\u6d4b\u4e00\u81f4\u7684\u533b\u5b66\u89e3\u91ca\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u66b4\u9732\u504f\u5dee\u95ee\u9898\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0e\u9884\u6d4b\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51faReason2Decide\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u6a21\u578b\u751f\u6210\u89e3\u91ca\uff08rationale generation\uff09\uff0c\u7b2c\u4e8c\u9636\u6bb5\u8054\u5408\u8bad\u7ec3\u6807\u7b7e\u9884\u6d4b\u548c\u89e3\u91ca\u751f\u6210\uff0c\u91c7\u7528\u8ba1\u5212\u91c7\u6837\u9010\u6b65\u4ece\u57fa\u4e8e\u9ec4\u91d1\u6807\u7b7e\u8f6c\u5411\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5305\u62ec\u4e13\u6709\u5206\u8bca\u6570\u636e\u96c6\u548c\u516c\u5171\u751f\u7269\u533b\u5b66QA\u6570\u636e\u96c6\u3002Reason2Decide\u5728\u9884\u6d4b\uff08F1\uff09\u548c\u89e3\u91ca\u4fdd\u771f\u5ea6\uff08BERTScore\u3001BLEU\u3001LLM-as-a-Judge\uff09\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u5fae\u8c03\u57fa\u7ebf\u548c\u4e00\u4e9b\u96f6\u6837\u672cLLM\u3002\u5728\u5206\u8bca\u4efb\u52a1\u4e2d\uff0c\u5bf9LLM\u751f\u6210\u3001\u62a4\u58eb\u64b0\u5199\u548c\u62a4\u58eb\u540e\u5904\u7406\u7684\u89e3\u91ca\u90fd\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u3002", "conclusion": "Reason2Decide\u80fd\u591f\u4f7f\u7528\u6bd4\u5f53\u4ee3\u57fa\u7840\u6a21\u578b\u5c0f40\u500d\u7684\u6a21\u578b\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u4f7f\u4e34\u5e8a\u63a8\u7406\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u66f4\u6613\u90e8\u7f72\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u652f\u6301\u3002LLM\u751f\u6210\u7684\u89e3\u91ca\u9002\u5408\u7528\u4e8e\u6a21\u578b\u9884\u8bad\u7ec3\uff0c\u51cf\u5c11\u5bf9\u4eba\u7c7b\u6807\u6ce8\u7684\u4f9d\u8d56\u3002"}}
{"id": "2512.20082", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20082", "abs": "https://arxiv.org/abs/2512.20082", "authors": ["Chaithra", "Kamesh Kadimisetty", "Biju R Mohan"], "title": "Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches", "comment": "Accepted in CODS 2025", "summary": "Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5e02\u573a\u53cd\u9988\u7684\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u6307\u4ee4\u5fae\u8c03\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5370\u5ea6\u80a1\u5e02\u60c5\u611f\u5206\u6790\uff0c\u663e\u8457\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u6027\u548c\u5e02\u573a\u5bf9\u9f50\u5ea6\u3002", "motivation": "\u73b0\u6709\u91d1\u878d\u60c5\u611f\u5206\u6790\u7814\u7a76\u672a\u8003\u8651\u80a1\u4ef7\u6216\u5e02\u573a\u53cd\u9988\u7684\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u5e02\u573a\u52a8\u6001\u53d8\u5316\u7684\u6a21\u578b\u6765\u63d0\u5347\u60c5\u611f\u5206\u7c7b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "1) \u4f7f\u7528SentiFin\u6570\u636e\u96c6\u5bf9LLaMA 3.2 3B\u6a21\u578b\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\uff1b2) \u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7ba1\u9053\u52a8\u6001\u9009\u62e9\u591a\u6e90\u4e0a\u4e0b\u6587\u4fe1\u606f\uff1b3) \u5f15\u5165\u53cd\u9988\u9a71\u52a8\u6a21\u5757\uff0c\u901a\u8fc7\u6bd4\u8f83\u9884\u6d4b\u60c5\u611f\u4e0e\u5b9e\u9645\u6b21\u65e5\u80a1\u7968\u6536\u76ca\u8c03\u6574\u6e90\u53ef\u9760\u6027\uff1b4) \u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316(PPO)\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5b9e\u73b0\u8de8\u65f6\u95f4\u6570\u636e\u7684\u81ea\u9002\u5e94\u673a\u5236\u3002", "result": "\u57282024-2025\u5e74NIFTY 50\u65b0\u95fb\u6807\u9898\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u5206\u7c7b\u51c6\u786e\u7387\u3001F1\u5206\u6570\u548c\u5e02\u573a\u5bf9\u9f50\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u548c\u9759\u6001\u68c0\u7d22\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408\u6307\u4ee4\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3001\u52a8\u6001\u53cd\u9988\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u80fd\u591f\u5b9e\u73b0\u7a33\u5065\u3001\u5e02\u573a\u611f\u77e5\u7684\u91d1\u878d\u60c5\u611f\u5efa\u6a21\uff0c\u4e3a\u6295\u8d44\u51b3\u7b56\u548c\u5e02\u573a\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u4f9d\u636e\u3002"}}
{"id": "2512.20135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20135", "abs": "https://arxiv.org/abs/2512.20135", "authors": ["Zhuo Yang", "Yeyun chen", "Jiaqing Xie", "Ben Gao", "Shuaike Shen", "Wanhao Liu", "Liujia Yang", "Beilun Wang", "Tianfan Fu", "Yuqiang Li"], "title": "MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization", "comment": null, "summary": "Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed \"thinking\" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open \"thinking\" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed \"thinking\" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.", "AI": {"tldr": "MolAct\u662f\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u5206\u5b50\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08\u5148\u5b66\u7f16\u8f91\u80fd\u529b\uff0c\u518d\u5b66\u4f18\u5316\uff09\u5b9e\u73b0\u591a\u6b65\u5206\u5b50\u7f16\u8f91\u4e0e\u4f18\u5316\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5206\u5b50\u7f16\u8f91\u548c\u4f18\u5316\u662f\u591a\u6b65\u9aa4\u95ee\u9898\uff0c\u9700\u8981\u8fed\u4ee3\u6539\u8fdb\u6027\u8d28\u540c\u65f6\u4fdd\u6301\u5316\u5b66\u6709\u6548\u6027\u548c\u7ed3\u6784\u76f8\u4f3c\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5c06\u5206\u5b50\u8bbe\u8ba1\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u7684\u6846\u67b6\uff0c\u65e0\u6cd5\u6709\u6548\u7ed3\u5408\u63a8\u7406\u3001\u5de5\u5177\u4f7f\u7528\u548c\u5206\u5b50\u4f18\u5316\u3002", "method": "\u63d0\u51faMolAct\u6846\u67b6\uff0c\u5c06\u5206\u5b50\u8bbe\u8ba1\u5f62\u5f0f\u5316\u4e3a\u5e8f\u5217\u5316\u3001\u5de5\u5177\u6307\u5bfc\u7684\u51b3\u7b56\u95ee\u9898\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u7b2c\u4e00\u9636\u6bb5\u5b66\u4e60\u7f16\u8f91\u80fd\u529b\uff0c\u7b2c\u4e8c\u9636\u6bb5\u91cd\u7528\u7f16\u8f91\u884c\u4e3a\u4f18\u5316\u6027\u8d28\u3002\u667a\u80fd\u4f53\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u8c03\u7528\u5316\u5b66\u5de5\u5177\u8fdb\u884c\u6709\u6548\u6027\u68c0\u67e5\u3001\u6027\u8d28\u8bc4\u4f30\u548c\u76f8\u4f3c\u6027\u63a7\u5236\uff0c\u5e76\u6839\u636e\u53cd\u9988\u4f18\u5316\u540e\u7eed\u7f16\u8f91\u3002", "result": "\u5728\u5206\u5b50\u7f16\u8f91\u4efb\u52a1\u4e2d\uff0cMolEditAgent-7B\u5728\u6dfb\u52a0\u3001\u5220\u9664\u548c\u66ff\u6362\u7f16\u8f91\u4e0a\u5206\u522b\u8fbe\u5230100\u300195\u548c98\u7684\u6709\u6548\u6027\uff0c\u4f18\u4e8eDeepSeek-R1\u7b49\u57fa\u7ebf\uff1bMolEditAgent-3B\u6027\u80fd\u63a5\u8fd1Qwen3-32B-think\u3002\u5728\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\uff0cMolOptAgent-7B\u5728LogP\u6307\u6807\u4e0a\u8d85\u8d8aClaude 3.7\uff0c\u5728\u6eb6\u89e3\u5ea6\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u5e76\u5728\u5176\u4ed6\u76ee\u6807\u4e0a\u4fdd\u6301\u5e73\u8861\u6027\u80fd\u3002", "conclusion": "\u5c06\u5206\u5b50\u8bbe\u8ba1\u89c6\u4e3a\u591a\u6b65\u9aa4\u3001\u5de5\u5177\u589e\u5f3a\u7684\u8fc7\u7a0b\u662f\u5b9e\u73b0\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u6539\u8fdb\u7684\u5173\u952e\u3002MolAct\u6846\u67b6\u9996\u6b21\u5c06\u5206\u5b50\u8bbe\u8ba1\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u667a\u80fd\u4f53\u5b66\u4e60\u4ea4\u7ec7\u63a8\u7406\u3001\u5de5\u5177\u4f7f\u7528\u548c\u5206\u5b50\u4f18\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.20140", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20140", "abs": "https://arxiv.org/abs/2512.20140", "authors": ["Xingyou Yin", "Ceyao Zhang", "Min Hu", "Kai Chen"], "title": "Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection", "comment": "9 pages,3 figures", "summary": "Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.", "AI": {"tldr": "\u901a\u8fc7\u5411\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u6ce8\u5165\u566a\u58f0\u6765\u63d0\u5347\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5229\u7528\u5b8c\u5168\u51bb\u7ed3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65f6\uff0c\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u8f93\u5165\u6570\u636e\u7684\u6587\u672c\u8868\u793a\uff0c\u56e0\u4e3a\u6a21\u578b\u53c2\u6570\u65e0\u6cd5\u9002\u5e94\u5206\u5e03\u53d8\u5316\u3002\u9700\u8981\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u79cd\u8106\u5f31\u6027\u3002", "method": "\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636etokenization\u4e4b\u524d\u5411\u539f\u59cb\u6570\u636e\u6ce8\u5165\u566a\u58f0\uff0c\u4f5c\u4e3a\u4e00\u79cd\u63a8\u7406\u65f6\u589e\u5f3a\u7b56\u7565\uff0c\u8feb\u4f7f\u51bb\u7ed3\u7684LLM\u57fa\u4e8e\u7a33\u5065\u7684\u5e95\u5c42\u65f6\u95f4\u6a21\u5f0f\u800c\u975e\u8868\u9762\u6570\u503c\u4f2a\u5f71\u8fdb\u884c\u5916\u63a8\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002\u7279\u522b\u5730\uff0c\u5728\u4e13\u95e8\u8bbe\u8ba1\u7684\u4e24\u4e2a\u65b0\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\uff08\u786e\u4fdd\u4e0d\u5728LLM\u9884\u8bad\u7ec3\u8303\u56f4\u5185\uff09\uff0c\u4e00\u81f4\u89c2\u5bdf\u5230\u6027\u80fd\u63d0\u5347\uff0c\u6392\u9664\u4e86\u6570\u636e\u6c61\u67d3\u504f\u5dee\u3002", "conclusion": "\u566a\u58f0\u6ce8\u5165\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u7b56\u7565\uff0c\u80fd\u591f\u589e\u5f3a\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u76f4\u63a5\u5229\u7528\u73b0\u6210LLM\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u8fdb\u4e00\u6b65\u8fdb\u5c55\u3002"}}
{"id": "2512.20161", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20161", "abs": "https://arxiv.org/abs/2512.20161", "authors": ["Dhivya Dharshini Kannan", "Anupam Trivedi", "Dipti Srinivasan"], "title": "A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers", "comment": "2025 International Joint Conference on Neural Networks (IJCNN), Rome, Italy, 2025, https://ieeexplore.ieee.org/document/11227238", "summary": "Data centers account for significant global energy consumption and a carbon footprint. The recent increasing demand for edge computing and AI advancements drives the growth of data center storage capacity. Energy efficiency is a cost-effective way to combat climate change, cut energy costs, improve business competitiveness, and promote IT and environmental sustainability. Thus, optimizing data center energy management is the most important factor in the sustainability of the world. Power Usage Effectiveness (PUE) is used to represent the operational efficiency of the data center. Predicting PUE using Neural Networks provides an understanding of the effect of each feature on energy consumption, thus enabling targeted modifications of those key features to improve energy efficiency. In this paper, we have developed Bidirectional Gated Recurrent Unit (BiGRU) based PUE prediction model and compared the model performance with GRU. The data set comprises 52,560 samples with 117 features using EnergyPlus, simulating a DC in Singapore. Sets of the most relevant features are selected using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm for different parameter settings. These feature sets are used to find the optimal hyperparameter configuration and train the BiGRU model. The performance of the optimized BiGRU-based PUE prediction model is then compared with that of GRU using mean squared error (MSE), mean absolute error (MAE), and R-squared metrics.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8e\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08BiGRU\uff09\u7684\u6570\u636e\u4e2d\u5fc3\u80fd\u6548\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u548c\u8d85\u53c2\u6570\u4f18\u5316\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u4e0eGRU\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u5de8\u5927\u4e14\u78b3\u8db3\u8ff9\u663e\u8457\uff0c\u968f\u7740\u8fb9\u7f18\u8ba1\u7b97\u548cAI\u53d1\u5c55\uff0c\u5b58\u50a8\u5bb9\u91cf\u9700\u6c42\u589e\u957f\u3002\u63d0\u9ad8\u80fd\u6548\u662f\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3001\u964d\u4f4e\u6210\u672c\u3001\u589e\u5f3a\u7ade\u4e89\u529b\u7684\u5173\u952e\u3002\u9884\u6d4bPUE\uff08\u7535\u529b\u4f7f\u7528\u6548\u7387\uff09\u6709\u52a9\u4e8e\u7406\u89e3\u5404\u7279\u5f81\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u9488\u5bf9\u6027\u5730\u6539\u8fdb\u80fd\u6548\u3002", "method": "1. \u4f7f\u7528EnergyPlus\u6a21\u62df\u65b0\u52a0\u5761\u6570\u636e\u4e2d\u5fc3\uff0c\u751f\u621052,560\u4e2a\u6837\u672c\u548c117\u4e2a\u7279\u5f81\u7684\u6570\u636e\u96c6\uff1b2. \u91c7\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664\u4e0e\u4ea4\u53c9\u9a8c\u8bc1\uff08RFECV\uff09\u7b97\u6cd5\u9009\u62e9\u6700\u76f8\u5173\u7279\u5f81\u96c6\uff1b3. \u5f00\u53d1BiGRU\u6a21\u578b\u5e76\u8fdb\u884c\u8d85\u53c2\u6570\u4f18\u5316\uff1b4. \u4e0eGRU\u6a21\u578b\u5bf9\u6bd4\uff0c\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u3001\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u548cR\u5e73\u65b9\u6307\u6807\u8bc4\u4f30\u6027\u80fd\u3002", "result": "BiGRU\u6a21\u578b\u5728PUE\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edfGRU\u6a21\u578b\u7684\u6027\u80fd\u3002\u901a\u8fc7RFECV\u7279\u5f81\u9009\u62e9\u548c\u8d85\u53c2\u6570\u4f18\u5316\uff0cBiGRU\u6a21\u578b\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u53d6\u5f97\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u6570\u636e\u4e2d\u5fc3\u80fd\u6548\u3002", "conclusion": "BiGRU\u6a21\u578b\u5728\u6570\u636e\u4e2d\u5fc3PUE\u9884\u6d4b\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u4e3a\u6570\u636e\u4e2d\u5fc3\u80fd\u6548\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9884\u6d4b\u5de5\u5177\u3002\u901a\u8fc7\u7406\u89e3\u5404\u7279\u5f81\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\uff0c\u53ef\u4ee5\u9488\u5bf9\u6027\u5730\u6539\u8fdb\u6570\u636e\u4e2d\u5fc3\u8fd0\u8425\uff0c\u63d0\u9ad8\u80fd\u6e90\u6548\u7387\uff0c\u4fc3\u8fdb\u53ef\u6301\u7eed\u53d1\u5c55\u3002"}}
{"id": "2512.20162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20162", "abs": "https://arxiv.org/abs/2512.20162", "authors": ["Arghavan Bazigaran", "Hansem Sohn"], "title": "Concept Generalization in Humans and Large Language Models: Insights from the Number Game", "comment": null, "summary": "We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.", "AI": {"tldr": "\u6bd4\u8f83\u4eba\u7c7b\u4e0eLLM\u5728\u6570\u5b57\u6e38\u620f\u4e2d\u7684\u6982\u5ff5\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u4eba\u7c7b\u66f4\u7075\u6d3b\u5730\u7ed3\u5408\u89c4\u5219\u4e0e\u76f8\u4f3c\u6027\u63a8\u7406\uff0c\u800cLLM\u66f4\u4f9d\u8d56\u6570\u5b66\u89c4\u5219\uff0c\u4e14\u4eba\u7c7b\u80fd\u5355\u6837\u672c\u6cdb\u5316\u800cLLM\u9700\u8981\u66f4\u591a\u6837\u672c", "motivation": "\u7814\u7a76\u4eba\u7c7b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6982\u5ff5\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u5f02\uff0c\u63a2\u7a76\u4e24\u8005\u5728\u5f52\u7eb3\u504f\u7f6e\u548c\u63a8\u7406\u7b56\u7565\u4e0a\u7684\u6839\u672c\u533a\u522b", "method": "\u4f7f\u7528\u6570\u5b57\u6e38\u620f\u4f5c\u4e3a\u6982\u5ff5\u63a8\u7406\u4efb\u52a1\uff0c\u4ee5\u8d1d\u53f6\u65af\u6a21\u578b\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u6bd4\u8f83\u4eba\u7c7b\u548cLLM\u7684\u5f52\u7eb3\u504f\u7f6e\u548c\u63a8\u7406\u7b56\u7565", "result": "\u8d1d\u53f6\u65af\u6a21\u578b\u80fd\u66f4\u597d\u5730\u6355\u6349\u4eba\u7c7b\u884c\u4e3a\uff1a\u4eba\u7c7b\u7075\u6d3b\u63a8\u65ad\u57fa\u4e8e\u89c4\u5219\u548c\u76f8\u4f3c\u6027\u7684\u6982\u5ff5\uff0c\u800cLLM\u66f4\u4f9d\u8d56\u6570\u5b66\u89c4\u5219\uff1b\u4eba\u7c7b\u80fd\u4ece\u5355\u4e2a\u793a\u4f8b\u8fdb\u884c\u5c11\u6837\u672c\u6cdb\u5316\uff0c\u800cLLM\u9700\u8981\u66f4\u591a\u6837\u672c", "conclusion": "\u4eba\u7c7b\u4e0eLLM\u5728\u6570\u5b66\u6982\u5ff5\u63a8\u7406\u548c\u6cdb\u5316\u65b9\u9762\u5b58\u5728\u6839\u672c\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u80fd\u529b\u7684\u91cd\u8981\u533a\u522b"}}
{"id": "2512.20173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20173", "abs": "https://arxiv.org/abs/2512.20173", "authors": ["Ze Gong", "Pradeep Varakantham", "Akshat Kumar"], "title": "Offline Safe Policy Optimization From Heterogeneous Feedback", "comment": "Accepted at AAMAS 2026 (Extended Abstract)", "summary": "Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \\textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \\textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.", "AI": {"tldr": "\u63d0\u51faPreSa\u65b9\u6cd5\uff0c\u901a\u8fc7\u504f\u597d\u5b66\u4e60\u548c\u5b89\u5168\u5bf9\u9f50\u76f4\u63a5\u5b66\u4e60\u5b89\u5168\u7b56\u7565\uff0c\u907f\u514d\u663e\u5f0f\u5b66\u4e60\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u79bb\u7ebf\u504f\u597d\u5f3a\u5316\u5b66\u4e60(PbRL)\u907f\u514d\u4e86\u4eba\u5de5\u5956\u52b1\u5de5\u7a0b\u548c\u5b9e\u65f6\u4ea4\u4e92\uff0c\u4f46\u5b89\u5168\u6027\u4ecd\u662f\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5b89\u5168RL\u65b9\u6cd5\u5148\u5b66\u4e60\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b\uff0c\u518d\u7528\u7ea6\u675fRL\u4f18\u5316\u7b56\u7565\uff0c\u5728\u957f\u65f6\u57df\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u8bef\u5dee\u4f1a\u7d2f\u79ef\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d", "method": "\u63d0\u51faPreSa\u6846\u67b6\uff1a1) \u76f4\u63a5\u57fa\u4e8e\u884c\u4e3a\u504f\u597d\u548c\u8f68\u8ff9\u6bb5\u5b89\u5168\u6807\u7b7e\u5b66\u4e60\u7b56\u7565\uff1b2) \u7ed3\u5408\u504f\u597d\u5b66\u4e60\u6a21\u5757\u548c\u5b89\u5168\u5bf9\u9f50\u7684\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff1b3) \u5728\u62c9\u683c\u6717\u65e5\u6846\u67b6\u5185\u6c42\u89e3\uff0c\u76f4\u63a5\u5b66\u4e60\u5956\u52b1\u6700\u5927\u5316\u4e14\u5b89\u5168\u7684\u7b56\u7565\uff0c\u65e0\u9700\u663e\u5f0f\u5b66\u4e60\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b", "result": "\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\uff0c\u4f7f\u7528\u5408\u6210\u548c\u771f\u5b9e\u4eba\u7c7b\u53cd\u9988\u8fdb\u884c\u8bc4\u4f30\uff0cPreSa\u6210\u529f\u5b66\u4e60\u5230\u9ad8\u5956\u52b1\u7684\u5b89\u5168\u7b56\u7565\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u751a\u81f3\u4f18\u4e8e\u4f7f\u7528\u771f\u5b9e\u5956\u52b1\u548c\u6210\u672c\u7684\u79bb\u7ebf\u5b89\u5168RL\u65b9\u6cd5", "conclusion": "PreSa\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u5b89\u5168\u7b56\u7565\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b\u8bef\u5dee\u7d2f\u79ef\u7684\u95ee\u9898\uff0c\u5728\u79bb\u7ebf\u504f\u597d\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u5e73\u8861"}}
{"id": "2512.20206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20206", "abs": "https://arxiv.org/abs/2512.20206", "authors": ["Zhe Sun", "Kunlun Wu", "Chuanjian Fu", "Zeming Song", "Langyong Shi", "Zihe Xue", "Bohan Jing", "Ying Yang", "Xiaomeng Gao", "Aijia Li", "Tianyu Guo", "Huiying Li", "Xueyuan Yang", "Rongkai Liu", "Xinyi He", "Yuxi Wang", "Yue Li", "Mingyuan Liu", "Yujie Lu", "Hongzhao Xie", "Shiyun Zhao", "Bo Dai", "Wei Wang", "Tao Yuan", "Song-Chun Zhu", "Yujia Peng", "Zhenliang Zhang"], "title": "TongSIM: A General Platform for Simulating Intelligent Machines", "comment": null, "summary": "As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.", "AI": {"tldr": "TongSIM\u662f\u4e00\u4e2a\u9ad8\u4fdd\u771f\u3001\u901a\u7528\u578b\u5e73\u53f0\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u7684\u5ba4\u5185\u5916\u573a\u666f\u548c\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u968f\u7740AI\u5411\u591a\u6a21\u6001\u548c\u5177\u8eab\u667a\u80fd\u53d1\u5c55\uff0c\u73b0\u6709\u4eff\u771f\u5e73\u53f0\u5927\u591a\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u80fd\u591f\u652f\u6301\u4ece\u4f4e\u7ea7\u5bfc\u822a\u5230\u9ad8\u7ea7\u590d\u5408\u6d3b\u52a8\uff08\u5982\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u6a21\u62df\u548c\u4eba\u673a\u534f\u4f5c\uff09\u7684\u901a\u7528\u8bad\u7ec3\u73af\u5883\u3002", "method": "\u5f00\u53d1TongSIM\u5e73\u53f0\uff0c\u63d0\u4f9b100\u591a\u4e2a\u591a\u6837\u5316\u7684\u591a\u623f\u95f4\u5ba4\u5185\u573a\u666f\u548c\u5f00\u653e\u5f0f\u7684\u4ea4\u4e92\u4e30\u5bcc\u7684\u6237\u5916\u57ce\u9547\u6a21\u62df\uff0c\u652f\u6301\u5b9a\u5236\u5316\u573a\u666f\u3001\u4efb\u52a1\u81ea\u9002\u5e94\u4fdd\u771f\u5ea6\u3001\u591a\u6837\u667a\u80fd\u4f53\u7c7b\u578b\u548c\u52a8\u6001\u73af\u5883\u6a21\u62df\u3002", "result": "TongSIM\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u7edf\u4e00\u5e73\u53f0\uff0c\u80fd\u591f\u52a0\u901f\u5177\u8eab\u667a\u80fd\u7684\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u8fdb\u5c55\uff0c\u652f\u6301\u611f\u77e5\u3001\u8ba4\u77e5\u3001\u51b3\u7b56\u3001\u4eba\u673a\u534f\u4f5c\u3001\u7a7a\u95f4\u548c\u793e\u4f1a\u63a8\u7406\u7b49\u591a\u79cd\u80fd\u529b\u7684\u8bc4\u4f30\u3002", "conclusion": "TongSIM\u586b\u8865\u4e86\u901a\u7528\u5177\u8eab\u667a\u80fd\u8bad\u7ec3\u73af\u5883\u7684\u7a7a\u767d\uff0c\u4f5c\u4e3a\u4e00\u4e2a\u9ad8\u4fdd\u771f\u3001\u901a\u7528\u578b\u5e73\u53f0\uff0c\u6709\u671b\u63a8\u52a8\u4ece\u4f4e\u7ea7\u5177\u8eab\u5bfc\u822a\u5230\u9ad8\u7ea7\u590d\u5408\u6d3b\u52a8\u7684\u5177\u8eab\u667a\u80fd\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2512.20237", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20237", "abs": "https://arxiv.org/abs/2512.20237", "authors": ["Xingbo Du", "Loka Li", "Duzhen Zhang", "Le Song"], "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents", "comment": "16 pages, 6 figures", "summary": "Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents. However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval. From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. This design departs from the standard retrieve-then-answer pipeline by introducing a closed-loop control mechanism that enables autonomous decision-making. Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.", "AI": {"tldr": "MemR\u00b3\u662f\u4e00\u4e2a\u4e3aLLM\u4ee3\u7406\u8bbe\u8ba1\u7684\u8bb0\u5fc6\u68c0\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u95ed\u73af\u63a7\u5236\u673a\u5236\u4f18\u5316\u8bb0\u5fc6\u68c0\u7d22\u8fc7\u7a0b\uff0c\u5305\u542b\u8def\u7531\u5668\u548c\u5168\u5c40\u8bc1\u636e\u7f3a\u53e3\u8ffd\u8e2a\u5668\uff0c\u663e\u8457\u63d0\u5347RAG\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bb0\u5fc6\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u538b\u7f29\u548c\u5b58\u50a8\u4f18\u5316\uff0c\u4f46\u5bf9\u8bb0\u5fc6\u68c0\u7d22\u7684\u663e\u5f0f\u95ed\u73af\u63a7\u5236\u5173\u6ce8\u4e0d\u8db3\u3002\u4f5c\u8005\u5e0c\u671b\u6784\u5efa\u4e00\u4e2a\u81ea\u4e3b\u3001\u51c6\u786e\u3001\u517c\u5bb9\u7684\u8bb0\u5fc6\u68c0\u7d22\u7cfb\u7edf\uff0c\u6539\u8fdb\u6807\u51c6\u7684\u68c0\u7d22-\u56de\u7b54\u6d41\u7a0b\u3002", "method": "\u63d0\u51faMemR\u00b3\u7cfb\u7edf\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u673a\u5236\uff1a1\uff09\u8def\u7531\u5668\uff1a\u5728\u68c0\u7d22\u3001\u53cd\u601d\u548c\u56de\u7b54\u4e09\u4e2a\u52a8\u4f5c\u4e2d\u9009\u62e9\u4ee5\u4f18\u5316\u7b54\u6848\u8d28\u91cf\uff1b2\uff09\u5168\u5c40\u8bc1\u636e\u7f3a\u53e3\u8ffd\u8e2a\u5668\uff1a\u663e\u5f0f\u5448\u73b0\u56de\u7b54\u8fc7\u7a0b\u900f\u660e\u5ea6\u5e76\u8ffd\u8e2a\u8bc1\u636e\u6536\u96c6\u8fc7\u7a0b\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u95ed\u73af\u63a7\u5236\u673a\u5236\u5b9e\u73b0\u81ea\u4e3b\u51b3\u7b56\u3002", "result": "\u5728LoCoMo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMemR\u00b3\u8d85\u8d8a\u4e86\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5728LLM-as-a-Judge\u8bc4\u5206\u4e0a\u8868\u73b0\u4f18\u5f02\u3002\u7279\u522b\u5730\uff0c\u5b83\u6539\u8fdb\u4e86\u56db\u7c7b\u73b0\u6709\u68c0\u7d22\u5668\u7684\u6027\u80fd\uff0c\u4f7f\u7528GPT-4.1-mini\u540e\u7aef\u65f6\uff0cRAG\u63d0\u53477.29%\uff0cZep\u63d0\u53471.94%\u3002", "conclusion": "MemR\u00b3\u4e3a\u73b0\u6709\u8bb0\u5fc6\u5b58\u50a8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u95ed\u73af\u63a7\u5236\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u8bb0\u5fc6\u68c0\u7d22\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4e3aLLM\u4ee3\u7406\u7684\u8bb0\u5fc6\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.20275", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.20275", "abs": "https://arxiv.org/abs/2512.20275", "authors": ["Divya Vijay", "Vignesh Ethiraj"], "title": "Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks", "comment": "15 pages, 3 figures, 3 tables", "summary": "As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.", "AI": {"tldr": "G-SPEC\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u9a8c\u8bc1\u7ea6\u675f\u6982\u7387\u89c4\u5212\uff0c\u89e3\u51b35G/6G\u7f51\u7edc\u4e2dLLM\u4ee3\u7406\u7684\u968f\u673a\u98ce\u9669\u95ee\u9898\uff0c\u5728450\u8282\u70b95G\u6838\u5fc3\u7f51\u6a21\u62df\u4e2d\u5b9e\u73b0\u96f6\u5b89\u5168\u8fdd\u89c4\u548c94.1%\u7684\u4fee\u590d\u6210\u529f\u7387\u3002", "motivation": "5G\u72ec\u7acb\u7ec4\u7f51\u548c6G\u7f51\u7edc\u6f14\u8fdb\u4e2d\uff0c\u8fd0\u8425\u5546\u9762\u4e34\u8d85\u51fa\u9759\u6001\u81ea\u52a8\u5316\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u80fd\u529b\u7684\u7f16\u6392\u6311\u6218\u3002\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e3a\u5b9e\u73b0\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u4f46\u5b83\u4eec\u5f15\u5165\u4e86\u968f\u673a\u98ce\u9669\uff0c\u5305\u62ec\u62d3\u6251\u5e7b\u89c9\u548c\u653f\u7b56\u4e0d\u5408\u89c4\u95ee\u9898\u3002", "method": "\u63d0\u51faGraph-Symbolic Policy Enforcement and Control (G-SPEC)\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u9a8c\u8bc1\u7ea6\u675f\u6982\u7387\u89c4\u5212\u3002\u67b6\u6784\u57fa\u4e8e\u6cbb\u7406\u4e09\u5143\u7ec4\uff1a\u7535\u4fe1\u9002\u914d\u4ee3\u7406(TSLAM-4B)\u3001\u7f51\u7edc\u77e5\u8bc6\u56fe\u8c31(NKG)\u548cSHACL\u7ea6\u675f\u3002", "result": "\u5728450\u8282\u70b95G\u6838\u5fc3\u7f51\u6a21\u62df\u4e2d\uff0cG-SPEC\u5b9e\u73b0\u4e86\u96f6\u5b89\u5168\u8fdd\u89c4\u548c94.1%\u7684\u4fee\u590d\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e82.4%\u7684\u57fa\u7ebf\u3002\u6d88\u878d\u5206\u6790\u663e\u793aNKG\u9a8c\u8bc1\u8d21\u732e\u4e8668%\u7684\u5b89\u5168\u589e\u76ca\uff0cSHACL\u7b56\u7565\u8d21\u732e24%\u3002\u572810K\u5230100K\u8282\u70b9\u62d3\u6251\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u6d4b\u8bd5\u8868\u660e\u9a8c\u8bc1\u5ef6\u8fdf\u6309O(k^1.2)\u7f29\u653e\u3002", "conclusion": "G-SPEC\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86LLM\u4ee3\u7406\u5728\u7f51\u7edc\u7f16\u6392\u4e2d\u7684\u968f\u673a\u98ce\u9669\uff0c\u5904\u7406\u5f00\u9500142ms\uff0c\u9002\u5408SMO\u5c42\u64cd\u4f5c\uff0c\u4e3a5G/6G\u7f51\u7edc\u7684\u5b89\u5168\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.20276", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.20276", "abs": "https://arxiv.org/abs/2512.20276", "authors": ["Yuntao Dai", "Hang Gu", "Teng Wang", "Qianyu Cheng", "Yifei Zheng", "Zhiyong Qiu", "Lei Gong", "Wenqi Lou", "Xuehai Zhou"], "title": "ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge", "comment": null, "summary": "Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.", "AI": {"tldr": "ActionFlow\uff1a\u9488\u5bf9\u8fb9\u7f18\u8bbe\u5907\u4e0aVLA\u6a21\u578b\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\u7684\u7cfb\u7edf\u7ea7\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u8bf7\u6c42\u6d41\u6c34\u7ebf\u8c03\u5ea6\u548c\u5185\u5b58\u4f18\u5316\uff0c\u5b9e\u73b02.55\u500d\u6027\u80fd\u63d0\u5347", "motivation": "\u5f53\u524dVLA\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff08\u4ec53-5Hz\uff09\uff0c\u65e0\u6cd5\u6ee1\u8db3\u673a\u5668\u4eba\u5b9e\u65f6\u63a7\u5236\u9700\u6c42\uff0820-30Hz\uff09\uff0c\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u91cd\u8bad\u7ec3\u6216\u727a\u7272\u51c6\u786e\u6027", "method": "\u63d0\u51faActionFlow\u7cfb\u7edf\u7ea7\u63a8\u7406\u6846\u67b6\uff1a1\uff09\u8de8\u8bf7\u6c42\u6d41\u6c34\u7ebf\u7b56\u7565\uff0c\u5c06VLA\u63a8\u7406\u91cd\u6784\u4e3a\u5fae\u8bf7\u6c42\u7684\u5b8f\u6d41\u6c34\u7ebf\uff1b2\uff09\u8de8\u8bf7\u6c42\u72b6\u6001\u6253\u5305\u524d\u5411\u7b97\u5b50\uff1b3\uff09\u7edf\u4e00KV\u73af\u5f62\u7f13\u51b2\u533a\uff0c\u5c06\u788e\u7247\u5316\u5185\u5b58\u64cd\u4f5c\u878d\u5408\u4e3a\u5bc6\u96c6\u8ba1\u7b97", "result": "\u5728OpenVLA-7B\u6a21\u578b\u4e0a\u5b9e\u73b02.55\u500dFPS\u63d0\u5347\uff0c\u65e0\u9700\u91cd\u8bad\u7ec3\u5373\u53ef\u5728\u8fb9\u7f18\u786c\u4ef6\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u52a8\u6001\u64cd\u4f5c", "conclusion": "ActionFlow\u901a\u8fc7\u521b\u65b0\u7684\u8c03\u5ea6\u548c\u5185\u5b58\u4f18\u5316\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLA\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u4e3a\u5b9e\u65f6\u673a\u5668\u4eba\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2512.20278", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20278", "abs": "https://arxiv.org/abs/2512.20278", "authors": ["Nishant Gaurav", "Adit Akarsh", "Ankit Ranjan", "Manoj Bajaj"], "title": "Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation", "comment": "7 pages", "summary": "While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u79d1\u5b66\u65b9\u6cd5\u8bba\uff08\u5047\u8bbe\u3001\u63a2\u6d4b\u3001\u7f16\u7801\uff09\u8ba9LLM\u4ece\u88ab\u52a8\u5de5\u5177\u4f7f\u7528\u8005\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u5de5\u4f5c\u6d41\u67b6\u6784\u5e08\uff0c\u89e3\u51b3\u4ee3\u7801\u6280\u80fd\u81ea\u52a8\u751f\u6210\u4e2d\u7684\u56db\u4e2a\u7ed3\u6784\u74f6\u9888\uff0c\u5b9e\u73b0\u81ea\u4e3b\u7f16\u5199\u751f\u4ea7\u7ea7\u4ee3\u7801\u6280\u80fd\u3002", "motivation": "\u867d\u7136CodeMem\u786e\u7acb\u4e86\u53ef\u6267\u884c\u4ee3\u7801\u4f5c\u4e3a\u4ee3\u7406\u7a0b\u5e8f\u8bb0\u5fc6\u7684\u6700\u4f73\u8868\u793a\u5f62\u5f0f\uff0c\u4f46\u4ece\u7a7a\u767d\u72b6\u6001\u81ea\u4e3b\u5408\u6210\u8fd9\u79cd\u8bb0\u5fc6\u7684\u673a\u5236\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u88ab\u52a8\u5de5\u5177\u4f7f\u7528\u8005\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u5de5\u4f5c\u6d41\u67b6\u6784\u5e08\u3002", "method": "\u901a\u8fc7Outlook\u548cOneDrive\u8de8\u670d\u52a1\u7f16\u6392\u4efb\u52a1\u7684\u9ad8\u4fdd\u771f\u6848\u4f8b\u7814\u7a76\uff0c\u8bc6\u522b\u5e76\u89e3\u51b3\u81ea\u52a8\u5316\u6280\u80fd\u751f\u6210\u4e2d\u7684\u56db\u4e2a\u7ed3\u6784\u74f6\u9888\uff1a\u53d1\u73b0\u5dee\u8ddd\uff08\u5bfc\u822a\u5927\u578b\u5de5\u5177\u6ce8\u518c\u8868\uff09\u3001\u9a8c\u8bc1\u5dee\u8ddd\uff08\u57fa\u7840\u5de5\u5177\u54cd\u5e94\u7ed3\u6784\uff09\u3001\u5206\u89e3\u5dee\u8ddd\uff08\u7528\u7ebf\u6027\u72b6\u6001\u951a\u5b9a\u66ff\u4ee3\u4f4e\u6548\u641c\u7d22\uff09\u548c\u6269\u5c55\u5dee\u8ddd\uff08\u5e76\u53d1\u6027\u548c\u6301\u4e45\u6027\uff09\u3002\u91c7\u7528\u5047\u8bbe\u3001\u63a2\u6d4b\u3001\u7f16\u7801\u7684\u79d1\u5b66\u65b9\u6cd5\u8bba\u3002", "result": "\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u79d1\u5b66\u65b9\u6cd5\u8bba\uff0c\u4ee3\u7406\u80fd\u591f\u81ea\u4e3b\u7f16\u5199\u5065\u58ee\u7684\u751f\u4ea7\u7ea7\u4ee3\u7801\u6280\u80fd\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u6280\u80fd\u751f\u6210\u4e2d\u7684\u5173\u952e\u74f6\u9888\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u79d1\u5b66\u65b9\u6cd5\u8bba\u548c\u89e3\u51b3\u56db\u4e2a\u7ed3\u6784\u74f6\u9888\uff0c\u53ef\u4ee5\u5b9e\u73b0LLM\u4ece\u88ab\u52a8\u5de5\u5177\u4f7f\u7528\u8005\u5411\u4e3b\u52a8\u5de5\u4f5c\u6d41\u67b6\u6784\u5e08\u7684\u8f6c\u53d8\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u81ea\u4e3b\u5408\u6210\u751f\u4ea7\u7ea7\u4ee3\u7801\u6280\u80fd\uff0c\u586b\u8865\u4e86CodeMem\u6846\u67b6\u4e2d\u4ece\u7a7a\u767d\u72b6\u6001\u81ea\u4e3b\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u8bb0\u5fc6\u7684\u673a\u5236\u7a7a\u767d\u3002"}}
{"id": "2512.20333", "categories": ["cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.20333", "abs": "https://arxiv.org/abs/2512.20333", "authors": ["Junren Li", "Luhua Lai"], "title": "SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization", "comment": "28 pages, 4 figures, 1 table", "summary": "Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible. Current solutions, such as post-hoc filtering or projection-based methods, often compromise structural novelty or disrupt key pharmacophores by forcing molecules into pre-defined synthetic templates. Herein, we introduce SynCraft, a reasoning-based framework that reframes synthesizability optimization not as a sequence translation task, but as a precise structural editing problem. Leveraging the emergent reasoning capabilities of Large Language Models, SynCraft navigates the \"synthesis cliff\" where minimal structural modifications yield significant gains in synthetic feasibility. By predicting executable sequences of atom-level edits rather than generating SMILES strings directly, SynCraft circumvents the syntactic fragility of LLMs while harnessing their chemical intuition. Extensive benchmarks demonstrate that SynCraft outperforms state-of-the-art baselines in generating synthesizable analogs with high structural fidelity. Furthermore, through interaction-aware prompting, SynCraft successfully replicates expert medicinal chemistry intuition in editing PLK1 inhibitors and rescuing high-scoring but previously discarded RIPK1 candidates in previous molecular generation literatures.", "AI": {"tldr": "SynCraft\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u5206\u5b50\u53ef\u5408\u6210\u6027\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u539f\u5b50\u7ea7\u7f16\u8f91\u800c\u975eSMILES\u751f\u6210\uff0c\u89e3\u51b3\u751f\u6210\u5206\u5b50\u5408\u6210\u4e0d\u53ef\u8fbe\u95ee\u9898", "motivation": "\u751f\u6210\u5f0fAI\u5728\u5316\u5b66\u7a7a\u95f4\u63a2\u7d22\u4e2d\u9762\u4e34\u5173\u952e\u74f6\u9888\uff1a\u5927\u91cf\u751f\u6210\u5206\u5b50\u5408\u6210\u4e0d\u53ef\u8fbe\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u540e\u8fc7\u6ee4\u6216\u57fa\u4e8e\u6a21\u677f\u7684\u65b9\u6cd5\uff09\u4f1a\u635f\u5bb3\u7ed3\u6784\u65b0\u9896\u6027\u6216\u7834\u574f\u5173\u952e\u836f\u6548\u56e2", "method": "\u5c06\u53ef\u5408\u6210\u6027\u4f18\u5316\u91cd\u6784\u4e3a\u7cbe\u786e\u7684\u7ed3\u6784\u7f16\u8f91\u95ee\u9898\u800c\u975e\u5e8f\u5217\u7ffb\u8bd1\u4efb\u52a1\u3002\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u9884\u6d4b\u53ef\u6267\u884c\u7684\u539f\u5b50\u7ea7\u7f16\u8f91\u5e8f\u5217\uff0c\u907f\u514dSMILES\u751f\u6210\u7684\u8bed\u6cd5\u8106\u5f31\u6027", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u751f\u6210\u9ad8\u7ed3\u6784\u4fdd\u771f\u5ea6\u7684\u53ef\u5408\u6210\u7c7b\u4f3c\u7269\u3002\u901a\u8fc7\u4ea4\u4e92\u611f\u77e5\u63d0\u793a\u6210\u529f\u590d\u5236\u836f\u7269\u5316\u5b66\u4e13\u5bb6\u76f4\u89c9\uff0c\u7f16\u8f91PLK1\u6291\u5236\u5242\u5e76\u633d\u6551\u5148\u524d\u88ab\u4e22\u5f03\u7684RIPK1\u5019\u9009\u5206\u5b50", "conclusion": "SynCraft\u901a\u8fc7\u63a8\u7406\u9a71\u52a8\u7684\u7ed3\u6784\u7f16\u8f91\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u751f\u6210\u5206\u5b50\u7684\u53ef\u5408\u6210\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u7ed3\u6784\u65b0\u9896\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u5408\u6210\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e86LLMs\u5728\u5316\u5b66\u63a8\u7406\u4e2d\u7684\u6f5c\u529b"}}
{"id": "2512.20344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20344", "abs": "https://arxiv.org/abs/2512.20344", "authors": ["Yaowei Bai", "Ruiheng Zhang", "Yu Lei", "Xuhua Duan", "Jingfeng Yao", "Shuguang Ju", "Chaoyang Wang", "Wei Yao", "Yiwan Guo", "Guilin Zhang", "Chao Wan", "Qian Yuan", "Lei Chen", "Wenjuan Tang", "Biqiang Zhu", "Xinggang Wang", "Tao Sun", "Wei Zhou", "Dacheng Tao", "Yongchao Xu", "Chuansheng Zheng", "Huangxuan Zhao", "Bo Du"], "title": "A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.19493", "summary": "A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P < 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.", "AI": {"tldr": "Janus-Pro-CXR (1B)\u662f\u4e00\u4e2a\u57fa\u4e8eDeepSeek Janus-Pro\u7684\u80f8\u90e8X\u5149\u89e3\u8bfb\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u4e2d\u5fc3\u524d\u77bb\u6027\u8bd5\u9a8c\u9a8c\u8bc1\uff0c\u5728\u62a5\u544a\u751f\u6210\u8d28\u91cf\u548c\u4e34\u5e8a\u5173\u952e\u53d1\u73b0\u68c0\u6d4b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u653e\u5c04\u79d1\u533b\u751f\u5de5\u4f5c\u6548\u7387\u3002", "motivation": "\u5168\u7403\u653e\u5c04\u79d1\u533b\u751f\u77ed\u7f3a\uff0c\u80f8\u90e8X\u5149\u5de5\u4f5c\u91cf\u5de8\u5927\uff0c\u7279\u522b\u662f\u5728\u521d\u7ea7\u533b\u7597\u4e2d\u3002\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u81ea\u52a8\u5316\u6307\u6807\u6216\u56de\u987e\u6027\u5206\u6790\uff0c\u7f3a\u4e4f\u4e25\u683c\u7684\u524d\u77bb\u6027\u4e34\u5e8a\u9a8c\u8bc1\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eDeepSeek Janus-Pro\u6a21\u578b\u7684Janus-Pro-CXR (1B)\u80f8\u90e8X\u5149\u89e3\u8bfb\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u4e2d\u5fc3\u524d\u77bb\u6027\u4e34\u5e8a\u8bd5\u9a8c(NCT07117266)\u8fdb\u884c\u4e25\u683c\u9a8c\u8bc1\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u67b6\u6784\u548c\u9886\u57df\u7279\u5b9a\u4f18\u5316\u3002", "result": "\u7cfb\u7edf\u5728\u81ea\u52a8\u5316\u62a5\u544a\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684X\u5149\u62a5\u544a\u751f\u6210\u6a21\u578b\uff0c\u751a\u81f3\u8d85\u8fc7\u66f4\u5927\u89c4\u6a21\u7684ChatGPT 4o(200B\u53c2\u6570)\uff1b\u53ef\u9760\u68c0\u6d4b\u516d\u79cd\u4e34\u5e8a\u5173\u952e\u653e\u5c04\u5b66\u53d1\u73b0\uff1b\u524d\u77bb\u6027\u4e34\u5e8a\u90e8\u7f72\u4e2d\uff0cAI\u8f85\u52a9\u663e\u8457\u63d0\u9ad8\u62a5\u544a\u8d28\u91cf\u8bc4\u5206\uff0c\u51cf\u5c1118.3%\u7684\u89e3\u8bfb\u65f6\u95f4(P<0.001)\uff0c54.3%\u7684\u75c5\u4f8b\u4e2d\u4e13\u5bb6\u66f4\u504f\u597dAI\u8f85\u52a9\u62a5\u544a\u3002", "conclusion": "Janus-Pro-CXR\u901a\u8fc7\u8f7b\u91cf\u7ea7\u67b6\u6784\u548c\u9886\u57df\u7279\u5b9a\u4f18\u5316\uff0c\u63d0\u9ad8\u4e86\u8bca\u65ad\u53ef\u9760\u6027\u548c\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u3002\u6a21\u578b\u67b6\u6784\u548c\u5b9e\u65bd\u6846\u67b6\u5c06\u5f00\u6e90\uff0c\u4ee5\u4fc3\u8fdbAI\u8f85\u52a9\u653e\u5c04\u5b66\u89e3\u51b3\u65b9\u6848\u7684\u4e34\u5e8a\u8f6c\u5316\u3002"}}
{"id": "2512.20387", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.20387", "abs": "https://arxiv.org/abs/2512.20387", "authors": ["YuChe Hsu", "AnJui Wang", "TsaiChing Ni", "YuanFu Yang"], "title": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems", "comment": "10 pages, 9 figures", "summary": "We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.", "AI": {"tldr": "VLSM\u6a21\u578b\u901a\u8fc7\u7edf\u4e00\u89c6\u89c9\u548c\u6587\u672c\u7406\u89e3\uff0c\u4ece\u5e03\u5c40\u8349\u56fe\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u751f\u6210\u53ef\u6267\u884c\u7684FlexScript\uff0c\u4e3a\u5de5\u4e1a\u4eff\u771f\u7cfb\u7edf\u5b9e\u73b0\u8de8\u6a21\u6001\u63a8\u7406\u3002", "motivation": "\u5de5\u4e1a\u4eff\u771f\u7cfb\u7edf\u9700\u8981\u5c06\u89c6\u89c9\u5e03\u5c40\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002\u672c\u7814\u7a76\u65e8\u5728\u5efa\u7acb\u751f\u6210\u5f0f\u6570\u5b57\u5b6a\u751f\u7684\u57fa\u7840\uff0c\u5c06\u89c6\u89c9\u63a8\u7406\u548c\u8bed\u8a00\u7406\u89e3\u6574\u5408\u5230\u53ef\u6267\u884c\u7684\u5de5\u4e1a\u4eff\u771f\u7cfb\u7edf\u4e2d\u3002", "method": "\u63d0\u51fa\u89c6\u89c9-\u8bed\u8a00\u4eff\u771f\u6a21\u578b(VLSM)\uff0c\u6784\u5efa\u9996\u4e2a\u5927\u89c4\u6a21\u751f\u6210\u5f0f\u6570\u5b57\u5b6a\u751f\u6570\u636e\u96c6\uff0812\u4e07+\u4e2a\u63d0\u793a-\u8349\u56fe-\u4ee3\u7801\u4e09\u5143\u7ec4\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e09\u4e2a\u4e13\u95e8\u8bc4\u4f30\u6307\u6807\uff1a\u7ed3\u6784\u6709\u6548\u6027\u7387(SVR)\u3001\u53c2\u6570\u5339\u914d\u7387(PMR)\u548c\u6267\u884c\u6210\u529f\u7387(ESR)\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u6d88\u878d\u5b9e\u9a8c\uff0c\u6a21\u578b\u5728\u89c6\u89c9\u7f16\u7801\u5668\u3001\u8fde\u63a5\u5668\u548c\u4ee3\u7801\u9884\u8bad\u7ec3\u8bed\u8a00\u9aa8\u5e72\u65b9\u9762\u53d6\u5f97\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u7ed3\u6784\u51c6\u786e\u6027\u548c\u9ad8\u6267\u884c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u751f\u6210\u5f0f\u6570\u5b57\u5b6a\u751f\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c06\u89c6\u89c9\u63a8\u7406\u548c\u8bed\u8a00\u7406\u89e3\u6574\u5408\u5230\u53ef\u6267\u884c\u7684\u5de5\u4e1a\u4eff\u771f\u7cfb\u7edf\u4e2d\uff0c\u5b9e\u73b0\u4e86\u8de8\u6a21\u6001\u7684\u5de5\u4e1a\u4eff\u771f\u4ee3\u7801\u751f\u6210\u3002"}}
{"id": "2512.20469", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20469", "abs": "https://arxiv.org/abs/2512.20469", "authors": ["Linfeng Zhang", "Siheng Chen", "Yuzhu Cai", "Jingyi Chai", "Junhan Chang", "Kun Chen", "Zhi X. Chen", "Zhaohan Ding", "Yuwen Du", "Yuanpeng Gao", "Yuan Gao", "Jing Gao", "Zhifeng Gao", "Qiangqiang Gu", "Yanhui Hong", "Yuan Huang", "Xi Fang", "Xiaohong Ji", "Guolin Ke", "Zixing Lei", "Xinyu Li", "Yongge Li", "Ruoxue Liao", "Hang Lin", "Xiaolu Lin", "Yuxiang Liu", "Xinzijian Liu", "Zexi Liu", "Jintan Lu", "Tingjia Miao", "Haohui Que", "Weijie Sun", "Yanfeng Wang", "Bingyang Wu", "Tianju Xue", "Rui Ye", "Jinzhe Zeng", "Duo Zhang", "Jiahui Zhang", "Linfeng Zhang", "Tianhan Zhang", "Wenchang Zhang", "Yuzhi Zhang", "Zezhong Zhang", "Hang Zheng", "Hui Zhou", "Tong Zhu", "Xinyu Zhu", "Qingguo Zhou", "Weinan E"], "title": "Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale", "comment": null, "summary": "AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \\emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.\n  However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.\n  We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \\emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.\n  We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faBohrium+SciMaster\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u7840\u8bbe\u65bd\u548c\u751f\u6001\u7cfb\u7edf\u65b9\u6cd5\u89e3\u51b3\u89c4\u6a21\u5316\u667a\u80fd\u4f53\u79d1\u5b66\u9762\u4e34\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u53ef\u89c2\u6d4b\u3001\u53ef\u91cd\u73b0\u548c\u53ef\u6cbb\u7406\u3002", "motivation": "AI\u667a\u80fd\u4f53\u6b63\u5728\u6210\u4e3a\u8fd0\u884c\u591a\u6b65\u9aa4\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u5b9e\u7528\u65b9\u5f0f\uff0c\u4f46\u89c4\u6a21\u5316\u667a\u80fd\u4f53\u79d1\u5b66\u9762\u4e34\u56db\u5927\u6311\u6218\uff1a\u5de5\u4f5c\u6d41\u96be\u4ee5\u89c2\u6d4b\u548c\u91cd\u73b0\uff1b\u8bb8\u591a\u5de5\u5177\u548c\u5b9e\u9a8c\u5ba4\u7cfb\u7edf\u4e0d\u652f\u6301\u667a\u80fd\u4f53\uff1b\u6267\u884c\u96be\u4ee5\u8ffd\u8e2a\u548c\u6cbb\u7406\uff1b\u539f\u578bAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u901a\u5e38\u662f\u5b9a\u5236\u7684\uff0c\u9650\u5236\u4e86\u91cd\u7528\u548c\u7cfb\u7edf\u6027\u6539\u8fdb\u3002", "method": "\u63d0\u51faBohrium+SciMaster\u67b6\u6784\uff1aBohrium\u4f5c\u4e3aAI4S\u8d44\u4ea7\u7684\u6258\u7ba1\u53ef\u8ffd\u6eaf\u4e2d\u5fc3\uff0c\u5c06\u79d1\u5b66\u6570\u636e\u3001\u8f6f\u4ef6\u3001\u8ba1\u7b97\u548c\u5b9e\u9a8c\u5ba4\u7cfb\u7edf\u8f6c\u5316\u4e3a\u667a\u80fd\u4f53\u5c31\u7eea\u80fd\u529b\uff1bSciMaster\u5c06\u8fd9\u4e9b\u80fd\u529b\u7f16\u6392\u4e3a\u957f\u89c6\u91ce\u79d1\u5b66\u5de5\u4f5c\u6d41\uff1b\u4e2d\u95f4\u7684\u79d1\u5b66\u667a\u80fd\u57fa\u677f\u5c06\u53ef\u91cd\u7528\u6a21\u578b\u3001\u77e5\u8bc6\u548c\u7ec4\u4ef6\u7ec4\u7ec7\u6210\u53ef\u6267\u884c\u6784\u5efa\u5757\u3002", "result": "\u572811\u4e2a\u4ee3\u8868\u6027\u4e3b\u667a\u80fd\u4f53\u7684\u771f\u5b9e\u5de5\u4f5c\u6d41\u4e2d\u6f14\u793a\u4e86\u8be5\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u79d1\u5b66\u5468\u671f\u65f6\u95f4\u7684\u6570\u91cf\u7ea7\u51cf\u5c11\uff0c\u5e76\u4ece\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u751f\u6210\u4e86\u6570\u767e\u4e07\u89c4\u6a21\u7684\u6267\u884c\u57fa\u7840\u4fe1\u53f7\u3002", "conclusion": "\u89c4\u6a21\u5316\u667a\u80fd\u4f53\u79d1\u5b66\u9700\u8981\u57fa\u7840\u8bbe\u65bd\u548c\u751f\u6001\u7cfb\u7edf\u65b9\u6cd5\uff0cBohrium+SciMaster\u67b6\u6784\u901a\u8fc7\u63d0\u4f9b\u53ef\u8ffd\u6eaf\u3001\u53ef\u7ec4\u5408\u3001\u53ef\u5ba1\u8ba1\u7684\u5de5\u4f5c\u6d41\u6267\u884c\u73af\u5883\uff0c\u4e3a\u667a\u80fd\u4f53\u79d1\u5b66\u7684\u89c4\u6a21\u5316\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.20520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20520", "abs": "https://arxiv.org/abs/2512.20520", "authors": ["Chehak Malhotra", "Mehak Gopal", "Akshaya Devadiga", "Pradeep Singh", "Ridam Pal", "Ritwik Kashyap", "Tavpritesh Sethi"], "title": "Benchmarking LLMs for Predictive Applications in the Intensive Care Units", "comment": null, "summary": "With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay > 24 hours and shock index (SI) > 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u9884\u6d4b\u5371\u91cd\u60a3\u8005\u4f11\u514b\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5c3d\u7ba1GatorTron-Base\u83b7\u5f97\u6700\u9ad8\u52a0\u6743\u53ec\u56de\u738780.5%\uff0c\u4f46LLMs\u5728\u9884\u6d4b\u4e34\u5e8a\u4e8b\u4ef6\u65b9\u9762\u5e76\u4e0d\u5929\u7136\u4f18\u4e8eSLMs\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u9884\u6d4b\u6027\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u8f83\u5c11\u3002\u53ca\u65f6\u9884\u6d4b\u4f11\u514b\u53ef\u4ee5\u4fc3\u8fdb\u65e9\u671f\u5e72\u9884\uff0c\u6539\u5584\u60a3\u8005\u9884\u540e\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30LLMs\u5728\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528MIMIC III\u6570\u636e\u5e93\u4e2d17,294\u6b21ICU\u4f4f\u9662\u7684\u6587\u672c\u6570\u636e\uff0c\u7b5b\u9009\u51fa\u4f4f\u9662\u65f6\u95f4>24\u5c0f\u65f6\u4e14\u4f11\u514b\u6307\u6570>0.7\u7684\u60a3\u8005\uff08\u6b63\u5e38\u7ec4355\u4eba\uff0c\u5f02\u5e38\u7ec487\u4eba\uff09\u3002\u6bd4\u8f83\u4e86GatorTron-Base\uff08\u4e34\u5e8a\u6570\u636e\u8bad\u7ec3\uff09\u3001Llama 8B\u3001Mistral 7B\u7b49LLMs\u4e0eBioBERT\u3001DocBERT\u3001BioClinicalBERT\u3001Word2Vec\u3001Doc2Vec\u7b49SLMs\u3002\u5728\u5fae\u8c03\u65f6\u4f7f\u7528focal loss\u548c\u4ea4\u53c9\u71b5\u635f\u5931\u6765\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "GatorTron-Base\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u52a0\u6743\u53ec\u56de\u738780.5%\uff0c\u4f46LLMs\u548cSLMs\u7684\u6574\u4f53\u6027\u80fd\u6307\u6807\u76f8\u5f53\u3002\u8fd9\u8868\u660eLLMs\u5728\u9884\u6d4b\u672a\u6765\u4e34\u5e8a\u4e8b\u4ef6\u65b9\u9762\u5e76\u4e0d\u5929\u7136\u4f18\u4e8eSLMs\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5728\u6587\u672c\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u4e3a\u4e86\u83b7\u5f97\u6709\u610f\u4e49\u7684\u4e34\u5e8a\u7ed3\u679c\uff0c\u672a\u6765\u8bad\u7ec3LLMs\u7684\u52aa\u529b\u5e94\u4f18\u5148\u5f00\u53d1\u80fd\u591f\u9884\u6d4b\u4e34\u5e8a\u8f68\u8ff9\u7684\u6a21\u578b\uff0c\u800c\u4e0d\u662f\u4e13\u6ce8\u4e8e\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6216\u8868\u578b\u5206\u6790\u7b49\u8f83\u7b80\u5355\u7684\u4efb\u52a1\u3002"}}
{"id": "2512.20548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20548", "abs": "https://arxiv.org/abs/2512.20548", "authors": ["Zhiyi Duan", "Xiangren Wang", "Hongyu Yuan", "Qianli Xing"], "title": "Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model", "comment": null, "summary": "Teachers' emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers' emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process.The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information.Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA.AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u6559\u5e08\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6T-MED\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u975e\u5bf9\u79f0\u6ce8\u610f\u529b\u7684\u591a\u6a21\u6001\u6559\u5e08\u60c5\u611f\u5206\u6790\u6a21\u578bAAM-TSA\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6559\u5e08\u60c5\u611f\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6559\u5e08\u60c5\u611f\u72b6\u6001\u5bf9\u6559\u5b66\u6548\u679c\u3001\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u5b66\u4e60\u6210\u5c31\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u56e0\u6559\u5e08\u8868\u6f14\u6027\u8d28\u800c\u96be\u4ee5\u51c6\u786e\u6355\u6349\u60c5\u611f\uff0c\u4e14\u5ffd\u89c6\u4e86\u6559\u5b66\u4fe1\u606f\u5bf9\u60c5\u611f\u8868\u8fbe\u7684\u5173\u952e\u5f71\u54cd\u3002", "method": "1) \u6784\u5efaT-MED\u6570\u636e\u96c6\uff1a\u91c7\u7528\u4eba\u673a\u534f\u540c\u6807\u6ce8\u6d41\u7a0b\uff0c\u5305\u542b14,938\u4e2a\u6559\u5e08\u60c5\u611f\u5b9e\u4f8b\uff0c\u6db5\u76d6250\u4e2a\u771f\u5b9e\u8bfe\u5802\u7684\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u9891\u548c\u6559\u5b66\u4fe1\u606f\uff1b2) \u63d0\u51faAAM-TSA\u6a21\u578b\uff1a\u5f15\u5165\u975e\u5bf9\u79f0\u6ce8\u610f\u529b\u673a\u5236\u548c\u5206\u5c42\u95e8\u63a7\u5355\u5143\uff0c\u5b9e\u73b0\u5dee\u5f02\u5316\u8de8\u6a21\u6001\u7279\u5f81\u878d\u5408\u548c\u7cbe\u786e\u60c5\u611f\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAAM-TSA\u6a21\u578b\u5728T-MED\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6\u548c\u521b\u65b0\u6a21\u578b\uff0c\u7cfb\u7edf\u89e3\u51b3\u4e86\u6559\u5e08\u60c5\u611f\u5206\u6790\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u6559\u80b2\u573a\u666f\u4e2d\u7684\u6559\u5e08\u60c5\u611f\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.20586", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.20586", "abs": "https://arxiv.org/abs/2512.20586", "authors": ["Humza Nusrat", "Luke Francisco", "Bing Luo", "Hassan Bagher-Ebadian", "Joshua Kim", "Karen Chin-Snyder", "Salim Siddiqui", "Mira Shah", "Eric Mellon", "Mohammad Ghassemi", "Anthony Doemer", "Benjamin Movsas", "Kundan Thind"], "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "comment": null, "summary": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.", "AI": {"tldr": "SAGE LLM\u89c4\u5212\u4ee3\u7406\u901a\u8fc7\u94fe\u5f0f\u601d\u8003\u63a8\u7406\u5728\u7acb\u4f53\u5b9a\u5411\u653e\u5c04\u5916\u79d1\u8ba1\u5212\u4e2d\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u7684\u81ea\u52a8\u5316\u89c4\u5212\uff0c\u63a8\u7406\u6a21\u578b\u5728\u4fdd\u6301\u4e3b\u8981\u5242\u91cf\u6307\u6807\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8033\u8717\u5242\u91cf\uff0c\u5e76\u5c55\u73b0\u51fa\u7cfb\u7edf\u6027\u7684\u89c4\u5212\u884c\u4e3a\u3002", "motivation": "\u7acb\u4f53\u5b9a\u5411\u653e\u5c04\u5916\u79d1\u9700\u8981\u7cbe\u786e\u7684\u5242\u91cf\u5851\u9020\uff0c\u4f46\u9ed1\u76d2AI\u7cfb\u7edf\u56e0\u900f\u660e\u5ea6\u95ee\u9898\u4e34\u5e8a\u91c7\u7528\u6709\u9650\u3002\u7814\u7a76\u65e8\u5728\u6d4b\u8bd5\u94fe\u5f0f\u601d\u8003\u63a8\u7406\u662f\u5426\u80fd\u6539\u5584\u4ee3\u7406\u89c4\u5212\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u5ba1\u8ba1\u7684\u81ea\u52a8\u5316\u89c4\u5212\u65b9\u6848\u3002", "method": "\u5f00\u53d1SAGE LLM\u89c4\u5212\u4ee3\u7406\uff0c\u572841\u4f8b\u8111\u8f6c\u79fb\u7624\u60a3\u8005\u7684\u56de\u987e\u6027\u961f\u5217\u4e2d\u6d4b\u8bd5\u3002\u6bd4\u8f83\u63a8\u7406\u6a21\u578b\u4e0e\u975e\u63a8\u7406\u6a21\u578b\u751f\u6210\u7684\u8ba1\u5212\uff0c\u8bc4\u4f30\u5242\u91cf\u5b66\u6307\u6807\u548c\u89c4\u5212\u884c\u4e3a\u3002", "result": "\u63a8\u7406\u6a21\u578b\u5728\u4e3b\u8981\u7ec8\u70b9\uff08PTV\u8986\u76d6\u7387\u3001\u6700\u5927\u5242\u91cf\u3001\u9002\u5f62\u6307\u6570\u3001\u68af\u5ea6\u6307\u6570\uff09\u4e0a\u4e0e\u4eba\u7c7b\u89c4\u5212\u5e08\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8033\u8717\u5242\u91cf\u3002\u63a8\u7406\u6a21\u578b\u5c55\u73b0\u51fa\u524d\u77bb\u6027\u7ea6\u675f\u9a8c\u8bc1\u548c\u6743\u8861\u5ba1\u8bae\u7b49\u7cfb\u7edf\u6027\u89c4\u5212\u884c\u4e3a\uff0c\u800c\u975e\u63a8\u7406\u6a21\u578b\u51e0\u4e4e\u6ca1\u6709\u8fd9\u4e9b\u8fc7\u7a0b\u3002", "conclusion": "\u94fe\u5f0f\u601d\u8003\u63a8\u7406\u4f7fLLM\u89c4\u5212\u4ee3\u7406\u80fd\u591f\u4ea7\u751f\u900f\u660e\u3001\u53ef\u5ba1\u8ba1\u7684\u81ea\u52a8\u5316\u653e\u5c04\u5916\u79d1\u8ba1\u5212\uff0c\u5728\u4fdd\u6301\u4e34\u5e8a\u8d28\u91cf\u7684\u540c\u65f6\u63d0\u4f9b\u89e3\u91ca\u6027\uff0c\u4e3a\u4e34\u5e8a\u91c7\u7528\u63d0\u4f9b\u4e86\u8def\u5f84\u3002"}}
{"id": "2512.20618", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.20618", "abs": "https://arxiv.org/abs/2512.20618", "authors": ["Runtao Liu", "Ziyi Liu", "Jiaqi Tang", "Yue Ma", "Renjie Pi", "Jipeng Zhang", "Qifeng Chen"], "title": "LongVideoAgent: Multi-Agent Reasoning with Long Videos", "comment": null, "summary": "Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u4e3bLLM\u534f\u8c03\u5b9a\u4f4d\u667a\u80fd\u4f53\u548c\u89c6\u89c9\u667a\u80fd\u4f53\uff0c\u5728\u957f\u89c6\u9891QA\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u65f6\u95f4\u5b9a\u4f4d\u548c\u7ec6\u7c92\u5ea6\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u957f\u89c6\u9891QA\u4e2d\u901a\u5e38\u5c06\u5185\u5bb9\u538b\u7f29\u4e3a\u6709\u635f\u6458\u8981\u6216\u4f9d\u8d56\u6709\u9650\u5de5\u5177\u96c6\uff0c\u5bfc\u81f4\u65f6\u95f4\u5b9a\u4f4d\u80fd\u529b\u5f31\u4e14\u9519\u8fc7\u7ec6\u7c92\u5ea6\u7ebf\u7d22\u3002\u9700\u8981\u4e00\u79cd\u80fd\u66f4\u597d\u5730\u5904\u7406\u5c0f\u65f6\u7ea7\u89c6\u9891\u63a8\u7406\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u4e3bLLM\u534f\u8c03\u5b9a\u4f4d\u667a\u80fd\u4f53\uff08\u5b9a\u4f4d\u95ee\u9898\u76f8\u5173\u7247\u6bb5\uff09\u548c\u89c6\u89c9\u667a\u80fd\u4f53\uff08\u63d0\u53d6\u76ee\u6807\u6587\u672c\u89c2\u5bdf\uff09\u3002\u4e3b\u667a\u80fd\u4f53\u6709\u6b65\u9aa4\u9650\u5236\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4ee5\u5b9e\u73b0\u7b80\u6d01\u3001\u6b63\u786e\u3001\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3002", "result": "\u5728\u63d0\u51fa\u7684LongTVQA\u548cLongTVQA+\u6570\u636e\u96c6\u4e0a\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u663e\u8457\u4f18\u4e8e\u5f3a\u975e\u667a\u80fd\u4f53\u57fa\u7ebf\u3002\u5b9e\u9a8c\u663e\u793a\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u8bad\u7ec3\u667a\u80fd\u4f53\u7684\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u3002", "conclusion": "\u8be5\u591a\u667a\u80fd\u4f53\u6846\u67b6\u901a\u8fc7\u534f\u8c03\u5b9a\u4f4d\u548c\u89c6\u89c9\u667a\u80fd\u4f53\uff0c\u5728\u957f\u89c6\u9891QA\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u65f6\u95f4\u5b9a\u4f4d\u3001\u89c6\u89c9\u7ec6\u8282\u8865\u5145\u548c\u53ef\u89e3\u91ca\u8f68\u8ff9\uff0c\u4e3a\u5c0f\u65f6\u7ea7\u89c6\u9891\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
