{"id": "2511.16777", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16777", "abs": "https://arxiv.org/abs/2511.16777", "authors": ["Ali Tehranian", "Jordan Budhu", "Casey Perkowski", "Lance Sookdeo", "Kenneth H. Church", "Garrett Harris", "Carl Pfeiffer"], "title": "Design, Fabrication, and Measurement of a Hemispherical Multi-Layer Band-Pass Frequency Selective Surface", "comment": null, "summary": "A hemispherical multilayer wide-band (7-13 GHz) band-pass frequency selective surface (FSS) is reported. A new design technique based on a Goldberg discretization and unit cell scaling technique is introduced to accommodate the curved profile of the FSS. The FSS is additively manufactured by sequentially printing dielectric layers and metallic patterns until 3 patterned silver-ink surfaces are integrated within a 4.5 mm (${\u03bb_0}/6$ at 10 GHz) thick ABS hemispherical radome. The diameter and the height of the realized hemispherical FSS are around $5{\u03bb_0}$ and $3{\u03bb_0}$ respectively. Measurements demonstrate a roughly 1.7 dB insertion loss in the passband and 15-20 dB rejection in the stop-band. Additionally, a new postprocessing technique is used to suppress the effects of edge diffraction in the measured transmission spectrum. The design process, manufacturing technique, and measurement postprocessing represent novel advancements enabling future conformal frequency selective surfaces.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u7403\u5f62\u591a\u5c42\u5bbd\u5e26\uff087-13 GHz\uff09\u5e26\u901a\u9891\u7387\u9009\u62e9\u8868\u9762\uff08FSS\uff09\uff0c\u91c7\u7528\u57fa\u4e8eGoldberg\u79bb\u6563\u5316\u548c\u5355\u5143\u7f29\u653e\u7684\u65b0\u8bbe\u8ba1\u6280\u672f\uff0c\u901a\u8fc7\u589e\u6750\u5236\u9020\u5b9e\u73b0\uff0c\u6d4b\u91cf\u663e\u793a\u901a\u5e26\u63d2\u5165\u635f\u8017\u7ea61.7 dB\uff0c\u963b\u5e26\u6291\u523615-20 dB\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u66f2\u9762\u8f6e\u5ed3\u7684FSS\u8bbe\u8ba1\u6280\u672f\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u534a\u7403\u5f62\u9891\u7387\u9009\u62e9\u8868\u9762\uff0c\u4e3a\u672a\u6765\u5171\u5f62FSS\u63d0\u4f9b\u6280\u672f\u57fa\u7840\u3002", "method": "\u91c7\u7528Goldberg\u79bb\u6563\u5316\u548c\u5355\u5143\u7f29\u653e\u6280\u672f\u8bbe\u8ba1\u66f2\u9762FSS\uff0c\u901a\u8fc7\u987a\u5e8f\u6253\u5370\u4ecb\u7535\u5c42\u548c\u91d1\u5c5e\u56fe\u6848\u7684\u589e\u6750\u5236\u9020\u65b9\u6cd5\uff0c\u57284.5 mm\u539a\u7684ABS\u534a\u7403\u5f62\u5929\u7ebf\u7f69\u5185\u96c6\u62103\u5c42\u94f6\u58a8\u6c34\u56fe\u6848\u8868\u9762\u3002", "result": "\u5b9e\u73b0\u7684\u534a\u7403\u5f62FSS\u76f4\u5f84\u7ea65\u03bb0\uff0c\u9ad8\u5ea6\u7ea63\u03bb0\uff0c\u6d4b\u91cf\u663e\u793a\u901a\u5e26\u63d2\u5165\u635f\u8017\u7ea61.7 dB\uff0c\u963b\u5e26\u6291\u523615-20 dB\uff0c\u5e76\u91c7\u7528\u65b0\u7684\u540e\u5904\u7406\u6280\u672f\u6291\u5236\u8fb9\u7f18\u884d\u5c04\u6548\u5e94\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u8fc7\u7a0b\u3001\u5236\u9020\u6280\u672f\u548c\u6d4b\u91cf\u540e\u5904\u7406\u4ee3\u8868\u4e86\u65b0\u9896\u7684\u8fdb\u6b65\uff0c\u4e3a\u672a\u6765\u5171\u5f62\u9891\u7387\u9009\u62e9\u8868\u9762\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.16819", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16819", "abs": "https://arxiv.org/abs/2511.16819", "authors": ["Arash Omidi", "Tanmay Mishra", "Mads R. Almassalkhi"], "title": "Experimental Multi-site Testbed for Advanced Control and Optimization of Hybrid Energy Systems", "comment": null, "summary": "This paper presents a hybrid energy system (HES) experimental testbed developed at the University of Vermont to support prototyping and validation of advanced control and optimization strategies for grid services. The platform integrates hardware-in-the-loop (HIL) simulation with a reconfigurable set of kilowatt-scale assets, including solar photovoltaic (PV), battery storage, an electrolyzer as a controllable load, and grid-tied inverters. A unified monitoring and communication architecture supports real-time data acquisition, model validation, and control implementation. The testbed's capabilities are demonstrated through a controller hardware-in-the-loop (CHIL) experiment in which a battery system participates in PV power smoothing.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6df7\u5408\u80fd\u6e90\u7cfb\u7edf\u5b9e\u9a8c\u5e73\u53f0\uff0c\u7528\u4e8e\u9a8c\u8bc1\u7535\u7f51\u670d\u52a1\u7684\u5148\u8fdb\u63a7\u5236\u548c\u4f18\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u786c\u4ef6\u5728\u73af\u4eff\u771f\u548c\u53ef\u91cd\u6784\u5343\u74e6\u7ea7\u8bbe\u5907\u5b9e\u73b0\u3002", "motivation": "\u4e3a\u7535\u7f51\u670d\u52a1\u7684\u5148\u8fdb\u63a7\u5236\u548c\u4f18\u5316\u7b56\u7565\u63d0\u4f9b\u539f\u578b\u8bbe\u8ba1\u548c\u9a8c\u8bc1\u652f\u6301\uff0c\u89e3\u51b3\u53ef\u518d\u751f\u80fd\u6e90\u96c6\u6210\u548c\u7535\u7f51\u7a33\u5b9a\u6027\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u786c\u4ef6\u5728\u73af\u4eff\u771f\u6280\u672f\uff0c\u96c6\u6210\u592a\u9633\u80fd\u5149\u4f0f\u3001\u7535\u6c60\u5b58\u50a8\u3001\u7535\u89e3\u69fd\u548c\u5e76\u7f51\u9006\u53d8\u5668\u7b49\u53ef\u91cd\u6784\u5343\u74e6\u7ea7\u8bbe\u5907\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u76d1\u63a7\u548c\u901a\u4fe1\u67b6\u6784\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86\u63a7\u5236\u5668\u786c\u4ef6\u5728\u73af\u5b9e\u9a8c\uff0c\u5176\u4e2d\u7535\u6c60\u7cfb\u7edf\u53c2\u4e0e\u4e86\u5149\u4f0f\u529f\u7387\u5e73\u6ed1\u63a7\u5236\uff0c\u9a8c\u8bc1\u4e86\u5e73\u53f0\u7684\u5b9e\u65f6\u6570\u636e\u91c7\u96c6\u3001\u6a21\u578b\u9a8c\u8bc1\u548c\u63a7\u5236\u5b9e\u65bd\u80fd\u529b\u3002", "conclusion": "\u8be5\u6df7\u5408\u80fd\u6e90\u7cfb\u7edf\u5b9e\u9a8c\u5e73\u53f0\u4e3a\u7535\u7f51\u670d\u52a1\u63a7\u5236\u7b56\u7565\u7684\u5f00\u53d1\u548c\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u652f\u6301\u53ef\u518d\u751f\u80fd\u6e90\u7684\u9ad8\u6548\u96c6\u6210\u548c\u7535\u7f51\u7a33\u5b9a\u6027\u63d0\u5347\u3002"}}
{"id": "2511.16834", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16834", "abs": "https://arxiv.org/abs/2511.16834", "authors": ["Hugo FM Milan", "Aline Q Alves", "Thatiane AT Souza", "Juliana M Galo", "Alex SC Maia", "Mois\u00e9s AP Borges", "Ciro J Egoavil"], "title": "The PV performance ratio paradox: annual data from large-scale, real-world PV systems show negligible meteorological and technical impact and points to dominant human factors", "comment": "Paper and supplementary material in the same PDF", "summary": "Performance ratio (PR) is a established measure of efficiency of photovoltaic (PV) systems. While previous research demonstrated the effects of meteorological and technical variables on PR, a gap persists in the literature on which variables strongly influence PR in large-scale, real-world, heterogeneous PV systems. This paper aims to fill this gap, applying data-driven models to PV systems located in Rond\u00f4nia State, Brazil, to identify which variables strongly influence annual PR, and, hence, should be the target for optimization. Surprisingly, only negligible effects were found between meteorological and technical variables on annual PR, indicating that human-factors (such as installation, monitoring, and maintenance quality) might have a stronger effect. These findings indicates that, to improve performance of PV systems, policy makers could focus on creating educational programs to teach PV installers and technicians how to properly install, monitor, and maintain modern PV systems. Through estimating the probability density functions of PR, its peak value was found as 78.85% (mean 77.52%, 95% confidence interval of 76.12% to 78.84%, and 95% prediction interval of 58.83% to 92.70%). A map of annual final yield was developed for Rond\u00f4nia State and can be used by entrepreneurs to quickly and cheaply estimate energy production.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u5df4\u897f\u6717\u591a\u5c3c\u4e9a\u5dde\u5927\u578b\u5149\u4f0f\u7cfb\u7edf\u7684\u6027\u80fd\u6bd4\u5f71\u54cd\u56e0\u7d20\uff0c\u53d1\u73b0\u6c14\u8c61\u548c\u6280\u672f\u53d8\u91cf\u5bf9\u5e74\u6027\u80fd\u6bd4\u5f71\u54cd\u5fae\u5f31\uff0c\u4eba\u4e3a\u56e0\u7d20\u53ef\u80fd\u66f4\u5177\u51b3\u5b9a\u6027\u3002", "motivation": "\u586b\u8865\u73b0\u6709\u6587\u732e\u5728\u5927\u578b\u3001\u771f\u5b9e\u4e16\u754c\u3001\u5f02\u8d28\u5149\u4f0f\u7cfb\u7edf\u4e2d\u54ea\u4e9b\u53d8\u91cf\u5f3a\u70c8\u5f71\u54cd\u6027\u80fd\u6bd4\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5e94\u7528\u6570\u636e\u9a71\u52a8\u6a21\u578b\u5206\u6790\u5df4\u897f\u6717\u591a\u5c3c\u4e9a\u5dde\u7684\u5149\u4f0f\u7cfb\u7edf\u6570\u636e\uff0c\u8bc6\u522b\u5f71\u54cd\u5e74\u6027\u80fd\u6bd4\u7684\u5173\u952e\u53d8\u91cf\u3002", "result": "\u6c14\u8c61\u548c\u6280\u672f\u53d8\u91cf\u5bf9\u5e74\u6027\u80fd\u6bd4\u4ec5\u6709\u5fae\u5f31\u5f71\u54cd\uff0c\u4eba\u4e3a\u56e0\u7d20\uff08\u5b89\u88c5\u3001\u76d1\u6d4b\u548c\u7ef4\u62a4\u8d28\u91cf\uff09\u53ef\u80fd\u5f71\u54cd\u66f4\u5927\uff1b\u6027\u80fd\u6bd4\u5cf0\u503c\u4e3a78.85%\uff0c\u5e73\u574777.52%\u3002", "conclusion": "\u4e3a\u63d0\u9ad8\u5149\u4f0f\u7cfb\u7edf\u6027\u80fd\uff0c\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u5173\u6ce8\u521b\u5efa\u6559\u80b2\u9879\u76ee\uff0c\u57f9\u8bad\u5b89\u88c5\u4eba\u5458\u548c\u6280\u672f\u4eba\u5458\u6b63\u786e\u5b89\u88c5\u3001\u76d1\u6d4b\u548c\u7ef4\u62a4\u73b0\u4ee3\u5149\u4f0f\u7cfb\u7edf\u3002"}}
{"id": "2511.16900", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16900", "abs": "https://arxiv.org/abs/2511.16900", "authors": ["Jingzehua Xu", "Weiyi Liu", "Weihang Zhang", "Zhuofan Xi", "Guanwen Xie", "Shuai Zhang", "Yi Li"], "title": "When Motion Learns to Listen: Diffusion-Prior Lyapunov Actor-Critic Framework with LLM Guidance for Stable and Robust AUV Control in Underwater Tasks", "comment": "This paper is currently under review and does not represent the final version. Jingzehua Xu, Weiyi Liu and Weihang Zhang are co-first authors of this paper, with Zhuofan Xi as the second author", "summary": "Autonomous Underwater Vehicles (AUVs) are indispensable for marine exploration; yet, their control is hindered by nonlinear hydrodynamics, time-varying disturbances, and localization uncertainty. Traditional controllers provide only limited adaptability, while Reinforcement Learning (RL), though promising, suffers from sample inefficiency, weak long-term planning, and lacks stability guarantees, leading to unreliable behavior. To address these challenges, we propose a diffusion-prior Lyapunov actor-critic framework that unifies exploration, stability, and semantic adaptability. Specifically, a diffusion model generates smooth, multimodal, and disturbance-resilient candidate actions; a Lyapunov critic further imposes dual constraints that ensure stability; and a Large Language Model (LLM)-driven outer loop adaptively selects and refines Lyapunov functions based on task semantics and training feedback. This \"generation-filtering-optimization\" mechanism not only enhances sample efficiency and planning capability but also aligns stability guarantees with diverse mission requirements in the multi-objective optimization task. Extensive simulations under complex ocean dynamics demonstrate that the proposed framework achieves more accurate trajectory tracking, higher task completion rates, improved energy efficiency, faster convergence, and improved robustness compared with conventional RL and diffusion-augmented baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6269\u6563\u6a21\u578b\u3001Lyapunov\u7a33\u5b9a\u6027\u548cLLM\u7684AUV\u63a7\u5236\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRL\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u3001\u957f\u671f\u89c4\u5212\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "AUV\u63a7\u5236\u9762\u4e34\u975e\u7ebf\u6027\u6c34\u52a8\u529b\u5b66\u3001\u65f6\u53d8\u6270\u52a8\u548c\u5b9a\u4f4d\u4e0d\u786e\u5b9a\u6027\u7b49\u6311\u6218\uff0c\u4f20\u7edf\u63a7\u5236\u5668\u9002\u5e94\u6027\u6709\u9650\uff0c\u800cRL\u65b9\u6cd5\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u3001\u957f\u671f\u89c4\u5212\u80fd\u529b\u5f31\u548c\u7f3a\u4e4f\u7a33\u5b9a\u6027\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6269\u6563\u5148\u9a8cLyapunov actor-critic\u6846\u67b6\uff1a\u6269\u6563\u6a21\u578b\u751f\u6210\u5e73\u6ed1\u591a\u6a21\u6001\u7684\u6297\u6270\u52a8\u5019\u9009\u52a8\u4f5c\uff0cLyapunov\u6279\u8bc4\u5668\u65bd\u52a0\u7a33\u5b9a\u6027\u7ea6\u675f\uff0cLLM\u9a71\u52a8\u7684\u5916\u73af\u6839\u636e\u4efb\u52a1\u8bed\u4e49\u548c\u8bad\u7ec3\u53cd\u9988\u81ea\u9002\u5e94\u9009\u62e9\u548c\u4f18\u5316Lyapunov\u51fd\u6570\u3002", "result": "\u5728\u590d\u6742\u6d77\u6d0b\u52a8\u529b\u5b66\u4e0b\u7684\u5e7f\u6cdb\u4eff\u771f\u8868\u660e\uff0c\u8be5\u6846\u67b6\u76f8\u6bd4\u4f20\u7edfRL\u548c\u6269\u6563\u589e\u5f3a\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u8f68\u8ff9\u8ddf\u8e2a\u3001\u66f4\u9ad8\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u3001\u66f4\u597d\u7684\u80fd\u91cf\u6548\u7387\u3001\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u751f\u6210-\u8fc7\u6ee4-\u4f18\u5316\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u548c\u89c4\u5212\u80fd\u529b\uff0c\u540c\u65f6\u5c06\u7a33\u5b9a\u6027\u4fdd\u8bc1\u4e0e\u591a\u76ee\u6807\u4efb\u52a1\u4e2d\u7684\u591a\u6837\u5316\u4efb\u52a1\u9700\u6c42\u5bf9\u9f50\u3002"}}
{"id": "2511.17140", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.17140", "abs": "https://arxiv.org/abs/2511.17140", "authors": ["Ping Wu", "Dan Zhu"], "title": "U.S. Economy and Global Stock Markets: Insights from a Distributional Approach", "comment": null, "summary": "Financial markets are interconnected, with micro-currents propagating across global markets and shaping economic trends. This paper moves beyond traditional stock market indices to examine cross-sectional return distributions-15 in our empirical application, each representing a distinct global market. To facilitate this analysis, we develop a matrix functional VAR method with interpretable factors extracted from cross-sectional return distributions. Our approach extends the existing framework from modeling a single function to multiple functions, allowing for a richer representation of cross-sectional dependencies. By jointly modeling these distributions with U.S. macroeconomic indicators, we uncover the predictive power of financial market in forecasting macro-economic dynamics. Our findings reveal that U.S. contractionary monetary policy not only lowers global stock returns, as traditionally understood, but also dampens cross-sectional return kurtosis, highlighting an overlooked policy transmission. This framework enables conditional forecasting, equipping policymakers with a flexible tool to assess macro-financial linkages under different economic scenarios.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u77e9\u9635\u51fd\u6570VAR\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5168\u740315\u4e2a\u5e02\u573a\u7684\u6a2a\u622a\u9762\u6536\u76ca\u5206\u5e03\u6765\u9884\u6d4b\u5b8f\u89c2\u7ecf\u6d4e\u52a8\u6001\uff0c\u53d1\u73b0\u7f8e\u56fd\u7d27\u7f29\u8d27\u5e01\u653f\u7b56\u4e0d\u4ec5\u964d\u4f4e\u5168\u7403\u80a1\u7968\u6536\u76ca\uff0c\u8fd8\u6291\u5236\u6a2a\u622a\u9762\u6536\u76ca\u5cf0\u5ea6\u3002", "motivation": "\u8d85\u8d8a\u4f20\u7edf\u80a1\u7968\u5e02\u573a\u6307\u6570\uff0c\u7814\u7a76\u6a2a\u622a\u9762\u6536\u76ca\u5206\u5e03\u5982\u4f55\u76f8\u4e92\u5173\u8054\u5e76\u9884\u6d4b\u5b8f\u89c2\u7ecf\u6d4e\u52a8\u6001\uff0c\u7279\u522b\u662f\u63a2\u7d22\u91d1\u878d\u5e02\u573a\u7684\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u77e9\u9635\u51fd\u6570VAR\u65b9\u6cd5\uff0c\u4ece\u6a2a\u622a\u9762\u6536\u76ca\u5206\u5e03\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u56e0\u5b50\uff0c\u5c06\u5355\u51fd\u6570\u5efa\u6a21\u6269\u5c55\u5230\u591a\u51fd\u6570\u5efa\u6a21\uff0c\u5e76\u4e0e\u7f8e\u56fd\u5b8f\u89c2\u7ecf\u6d4e\u6307\u6807\u8054\u5408\u5efa\u6a21\u3002", "result": "\u53d1\u73b0\u7f8e\u56fd\u7d27\u7f29\u8d27\u5e01\u653f\u7b56\u4e0d\u4ec5\u964d\u4f4e\u5168\u7403\u80a1\u7968\u6536\u76ca\uff0c\u8fd8\u6291\u5236\u6a2a\u622a\u9762\u6536\u76ca\u5cf0\u5ea6\uff0c\u63ed\u793a\u4e86\u88ab\u5ffd\u89c6\u7684\u653f\u7b56\u4f20\u5bfc\u673a\u5236\u3002", "conclusion": "\u8be5\u6846\u67b6\u652f\u6301\u6761\u4ef6\u9884\u6d4b\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u5728\u4e0d\u540c\u7ecf\u6d4e\u60c5\u666f\u4e0b\u8bc4\u4f30\u5b8f\u89c2\u91d1\u878d\u8054\u7cfb\u7684\u7075\u6d3b\u5de5\u5177\u3002"}}
{"id": "2511.16925", "categories": ["econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.16925", "abs": "https://arxiv.org/abs/2511.16925", "authors": ["Andr\u00e9s Aradillas Fern\u00e1ndez", "Jos\u00e9 Blanchet", "Jos\u00e9 Luis Montiel Olea", "Chen Qiu", "J\u00f6rg Stoye", "Lezhi Tan"], "title": "Approximate Least-Favorable Distributions and Nearly Optimal Tests via Stochastic Mirror Descent", "comment": null, "summary": "We consider a class of hypothesis testing problems where the null hypothesis postulates $M$ distributions for the observed data, and there is only one possible distribution under the alternative. We show that one can use a stochastic mirror descent routine for convex optimization to provably obtain - after finitely many iterations - both an approximate least-favorable distribution and a nearly optimal test, in a sense we make precise. Our theoretical results yield concrete recommendations about the algorithm's implementation, including its initial condition, its step size, and the number of iterations. Importantly, our suggested algorithm can be viewed as a slight variation of the algorithm suggested by Elliott, M\u00fcller, and Watson (2015), whose theoretical performance guarantees are unknown.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u968f\u673a\u955c\u50cf\u4e0b\u964d\u7b97\u6cd5\u6765\u89e3\u51b3\u4e00\u7c7b\u5047\u8bbe\u68c0\u9a8c\u95ee\u9898\uff0c\u5176\u4e2d\u96f6\u5047\u8bbe\u6709M\u4e2a\u5206\u5e03\uff0c\u5907\u62e9\u5047\u8bbe\u53ea\u6709\u4e00\u4e2a\u5206\u5e03\u3002\u8be5\u7b97\u6cd5\u80fd\u5728\u6709\u9650\u8fed\u4ee3\u6b21\u6570\u5185\u83b7\u5f97\u8fd1\u4f3c\u6700\u4e0d\u5229\u5206\u5e03\u548c\u8fd1\u4f3c\u6700\u4f18\u68c0\u9a8c\u3002", "motivation": "\u89e3\u51b3\u4e00\u7c7b\u7279\u6b8a\u7684\u5047\u8bbe\u68c0\u9a8c\u95ee\u9898\uff0c\u5176\u4e2d\u96f6\u5047\u8bbe\u5305\u542b\u591a\u4e2a\u5206\u5e03\u800c\u5907\u62e9\u5047\u8bbe\u53ea\u6709\u4e00\u4e2a\u5206\u5e03\uff0c\u9700\u8981\u627e\u5230\u6709\u6548\u7684\u7b97\u6cd5\u6765\u83b7\u5f97\u6700\u4e0d\u5229\u5206\u5e03\u548c\u6700\u4f18\u68c0\u9a8c\u3002", "method": "\u4f7f\u7528\u968f\u673a\u955c\u50cf\u4e0b\u964d\uff08stochastic mirror descent\uff09\u8fd9\u4e00\u51f8\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u6709\u9650\u6b21\u8fed\u4ee3\u6765\u83b7\u5f97\u8fd1\u4f3c\u6700\u4e0d\u5229\u5206\u5e03\u548c\u8fd1\u4f3c\u6700\u4f18\u68c0\u9a8c\u3002", "result": "\u7b97\u6cd5\u80fd\u5728\u6709\u9650\u8fed\u4ee3\u6b21\u6570\u5185\u83b7\u5f97\u8fd1\u4f3c\u6700\u4e0d\u5229\u5206\u5e03\u548c\u8fd1\u4f3c\u6700\u4f18\u68c0\u9a8c\uff0c\u5e76\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u5b9e\u73b0\u5efa\u8bae\uff0c\u5305\u62ec\u521d\u59cb\u6761\u4ef6\u3001\u6b65\u957f\u548c\u8fed\u4ee3\u6b21\u6570\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u53ef\u89c6\u4e3aElliott\u7b49\u4eba(2015)\u63d0\u51fa\u7b97\u6cd5\u7684\u8f7b\u5fae\u53d8\u4f53\uff0c\u4f46\u672c\u6587\u63d0\u4f9b\u4e86\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\uff0c\u800c\u539f\u7b97\u6cd5\u7684\u7406\u8bba\u6027\u80fd\u672a\u77e5\u3002"}}
{"id": "2511.16816", "categories": ["stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.16816", "abs": "https://arxiv.org/abs/2511.16816", "authors": ["Lekha Patel", "Craig Ulmer", "Stephen J. Verzi", "Daniel J. Krofcheck", "Indu Manickam", "Asmeret Naugle", "Jaideep Ray"], "title": "Trust-Aware Multimodal Data Fusion for Yield Estimation: A Case Study of the 2020 Beirut Explosion", "comment": "19 pages, 4 figures, supplementary material, journal", "summary": "The estimation of explosive yield from heterogeneous observational data presents fundamental challenges in inverse problems, particularly when combining traditional physical measurements with modern artificial intelligence-interpreted modalities. We present a novel Bayesian fractional posterior framework that fuses seismic waves, crater dimensions, synthetic aperture radar imagery, and vision-language model interpreted ground-level images to estimate the yield of the 2020 Beirut explosion. Unlike conventional approaches that may treat data sources equally, our method learns trust weights for each modality through a Dirichlet prior, automatically calibrating the relative information content of disparate observations. Applied to the Beirut explosion, the framework yields an estimate of 0.34--0.48 kt TNT equivalent, representing 12 to 17 percent detonation efficiency relative to the 2.75 kt theoretical maximum from the blast's stored ammonium nitrate. The fractional posterior approach demonstrates superior uncertainty quantification compared to single-modality estimates while providing robustness against systematic biases. This work establishes a principled framework for integrating qualitative assessments with quantitative physical measurements, with applications to explosion monitoring, disaster response, and forensic analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8d1d\u53f6\u65af\u5206\u6570\u540e\u9a8c\u6846\u67b6\uff0c\u878d\u5408\u591a\u79cd\u89c2\u6d4b\u6570\u636e\u6765\u4f30\u8ba1\u7206\u70b8\u5f53\u91cf\uff0c\u5e94\u7528\u4e8e2020\u5e74\u8d1d\u9c81\u7279\u7206\u70b8\u4e8b\u4ef6\u3002", "motivation": "\u89e3\u51b3\u5f02\u8d28\u89c2\u6d4b\u6570\u636e\u878d\u5408\u5728\u53cd\u95ee\u9898\u4e2d\u7684\u6839\u672c\u6311\u6218\uff0c\u7279\u522b\u662f\u4f20\u7edf\u7269\u7406\u6d4b\u91cf\u4e0e\u73b0\u4ee3AI\u89e3\u91ca\u6a21\u6001\u7684\u7ed3\u5408\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u5206\u6570\u540e\u9a8c\u6846\u67b6\uff0c\u901a\u8fc7\u72c4\u5229\u514b\u96f7\u5148\u9a8c\u5b66\u4e60\u6bcf\u79cd\u6a21\u6001\u7684\u4fe1\u4efb\u6743\u91cd\uff0c\u81ea\u52a8\u6821\u51c6\u4e0d\u540c\u89c2\u6d4b\u7684\u76f8\u5bf9\u4fe1\u606f\u5185\u5bb9\u3002", "result": "\u4f30\u8ba1\u8d1d\u9c81\u7279\u7206\u70b8\u5f53\u91cf\u4e3a0.34-0.48\u5343\u5428TNT\u5f53\u91cf\uff0c\u76f8\u5bf9\u4e8e\u7206\u70b8\u50a8\u5b58\u76842.75\u5343\u5428\u785d\u9178\u94f5\uff0c\u7206\u70b8\u6548\u7387\u4e3a12-17%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u4f18\u4e8e\u5355\u6a21\u6001\u4f30\u8ba1\uff0c\u5bf9\u7cfb\u7edf\u504f\u5dee\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4e3a\u5b9a\u6027\u8bc4\u4f30\u4e0e\u5b9a\u91cf\u7269\u7406\u6d4b\u91cf\u7684\u6574\u5408\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\u3002"}}
{"id": "2511.16884", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16884", "abs": "https://arxiv.org/abs/2511.16884", "authors": ["AJ Alvero", "Dustin S. Stoltz", "Oscar Stuhler", "Marshall Taylor"], "title": "Generative AI in Sociological Research: State of the Discipline", "comment": null, "summary": "Generative artificial intelligence (GenAI) has garnered considerable attention for its potential utility in research and scholarship, even among those who typically do not rely on computational tools. Early commentators, however, have also articulated concerns about how GenAI usage comes with enormous environmental costs, serious social risks, and a tendency to produce low-quality content. In the midst of both excitement and skepticism, it is crucial to take stock of how GenAI is actually being used. Our study focuses on sociological research as our site, and here we present findings from a survey of 433 authors of articles published in 50 sociology journals in the last five years. The survey provides an overview of the state of the discipline with regard to the use of GenAI by providing answers to fundamental questions: how (much) do scholars use the technology for their research; what are their reasons for using it; and how concerned, trustful, and optimistic are they about the technology? Of the approximately one third ofrespondents who self-report using GenAI at least weekly, the primary uses are for writing assistance and comparatively less so in planning, data collection, or data analysis. In both use and attitudes, there are surprisingly few differences between self-identified computational and non-computational researchers. Generally, respondents are very concerned about the social and environmental consequences of GenAI. Trust in GenAI outputs is low, regardless of expertise or frequency of use. While optimism that GenAI will improve is high, scholars are divided on whether GenAI will have a positive impact on the field.", "AI": {"tldr": "\u5bf9433\u540d\u793e\u4f1a\u5b66\u5b66\u8005\u7684\u8c03\u67e5\u663e\u793a\uff0c\u7ea6\u4e09\u5206\u4e4b\u4e00\u6bcf\u5468\u4f7f\u7528\u751f\u6210\u5f0fAI\uff0c\u4e3b\u8981\u7528\u4e8e\u5199\u4f5c\u8f85\u52a9\uff0c\u4f46\u5bf9AI\u7684\u793e\u4f1a\u73af\u5883\u5f71\u54cd\u62c5\u5fe7\u5f3a\u70c8\uff0c\u4fe1\u4efb\u5ea6\u4f4e\uff0c\u5bf9AI\u80fd\u5426\u6539\u5584\u8be5\u9886\u57df\u6301\u5206\u6b67\u6001\u5ea6\u3002", "motivation": "\u5728\u751f\u6210\u5f0fAI\u65e2\u53d7\u5173\u6ce8\u53c8\u53d7\u8d28\u7591\u7684\u80cc\u666f\u4e0b\uff0c\u4e86\u89e3\u5b66\u8005\u4eec\u5b9e\u9645\u5982\u4f55\u4f7f\u7528\u8be5\u6280\u672f\u53ca\u5176\u6001\u5ea6\uff0c\u7279\u522b\u662f\u5728\u793e\u4f1a\u5b66\u7814\u7a76\u9886\u57df\u3002", "method": "\u5bf9\u8fc7\u53bb\u4e94\u5e74\u572850\u4e2a\u793e\u4f1a\u5b66\u671f\u520a\u53d1\u8868\u6587\u7ae0\u7684433\u540d\u4f5c\u8005\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff0c\u5206\u6790\u4f7f\u7528\u9891\u7387\u3001\u7528\u9014\u3001\u6001\u5ea6\u7b49\u3002", "result": "\u7ea633%\u5b66\u8005\u6bcf\u5468\u4f7f\u7528AI\uff0c\u4e3b\u8981\u7528\u4e8e\u5199\u4f5c\u8f85\u52a9\uff1b\u8ba1\u7b97\u4e0e\u975e\u8ba1\u7b97\u7814\u7a76\u8005\u5dee\u5f02\u4e0d\u5927\uff1b\u666e\u904d\u62c5\u5fe7\u793e\u4f1a\u73af\u5883\u5f71\u54cd\uff1b\u5bf9AI\u8f93\u51fa\u4fe1\u4efb\u5ea6\u4f4e\uff1b\u5bf9AI\u6539\u8fdb\u4e50\u89c2\u4f46\u5bf9\u5176\u5f71\u54cd\u793e\u4f1a\u5b66\u9886\u57df\u6301\u5206\u6b67\u3002", "conclusion": "\u793e\u4f1a\u5b66\u5b66\u8005\u5bf9\u751f\u6210\u5f0fAI\u6301\u8c28\u614e\u6001\u5ea6\uff0c\u4f7f\u7528\u6709\u9650\u4e14\u4e3b\u8981\u7528\u4e8e\u8f85\u52a9\u5199\u4f5c\uff0c\u5bf9\u5176\u793e\u4f1a\u5f71\u54cd\u62c5\u5fe7\u5f3a\u70c8\uff0c\u4fe1\u4efb\u5ea6\u6709\u5f85\u63d0\u9ad8\u3002"}}
{"id": "2511.16832", "categories": ["cs.SI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16832", "abs": "https://arxiv.org/abs/2511.16832", "authors": ["Nikesh Gyawali", "Doina Caragea", "Cornelia Caragea", "Saif M. Mohammad"], "title": "The Shifting Landscape of Vaccine Discourse: Insights From a Decade of Pre- to Post-COVID-19 Vaccine Posts on Social Media", "comment": null, "summary": "In this work, we study English-language vaccine discourse in social media posts, specifically posts on X (formerly Twitter), in seven years before the COVID-19 outbreak (2013 to 2019) and three years after the outbreak was first reported (2020 to 2022). Drawing on theories from social cognition and the stereotype content model in Social Psychology, we analyze how English speakers talk about vaccines on social media to understand the evolving narrative around vaccines in social media posts. To do that, we first introduce a novel dataset comprising 18.7 million curated posts on vaccine discourse from 2013 to 2022. This extensive collection-filtered down from an initial 129 million posts through rigorous preprocessing-captures both pre-COVID and COVID-19 periods, offering valuable insights into the evolution of English-speaking X users' perceptions related to vaccines. Our analysis shows that the COVID-19 pandemic led to complex shifts in X users' sentiment and discourse around vaccines. We observe that negative emotion word usage decreased during the pandemic, with notable rises in usage of surprise, and trust related emotion words. Furthermore, vaccine-related language tended to use more warmth-focused words associated with trustworthiness, along with positive, competence-focused words during the early days of the pandemic, with a marked rise in negative word usage towards the end of the pandemic, possibly reflecting a growing vaccine hesitancy and skepticism.", "AI": {"tldr": "\u5206\u67902013-2022\u5e74Twitter\u75ab\u82d7\u8bdd\u8bed\u6f14\u53d8\uff0c\u53d1\u73b0COVID-19\u5927\u6d41\u884c\u5bfc\u81f4\u7528\u6237\u60c5\u611f\u548c\u8bdd\u8bed\u590d\u6742\u53d8\u5316\uff1a\u8d1f\u9762\u60c5\u7eea\u51cf\u5c11\uff0c\u60ca\u8bb6\u548c\u4fe1\u4efb\u76f8\u5173\u8bcd\u6c47\u589e\u52a0\uff0c\u65e9\u671f\u4f7f\u7528\u66f4\u591a\u6e29\u6696\u548c\u79ef\u6781\u8bcd\u6c47\uff0c\u540e\u671f\u8d1f\u9762\u8bcd\u6c47\u663e\u8457\u4e0a\u5347\u3002", "motivation": "\u57fa\u4e8e\u793e\u4f1a\u8ba4\u77e5\u548c\u523b\u677f\u5370\u8c61\u5185\u5bb9\u6a21\u578b\u7406\u8bba\uff0c\u7814\u7a76\u82f1\u8bed\u4f7f\u7528\u8005\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u5173\u4e8e\u75ab\u82d7\u7684\u8ba8\u8bba\uff0c\u4e86\u89e3\u75ab\u82d7\u53d9\u4e8b\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u6f14\u53d8\u8fc7\u7a0b\u3002", "method": "\u6784\u5efa\u5305\u542b1870\u4e07\u6761\u75ab\u82d7\u76f8\u5173\u63a8\u6587\u7684\u65b0\u6570\u636e\u96c6\uff08\u4ece1.29\u4ebf\u6761\u539f\u59cb\u63a8\u6587\u7ecf\u4e25\u683c\u9884\u5904\u7406\u7b5b\u9009\uff09\uff0c\u6db5\u76d62013-2022\u5e74\uff0c\u5206\u6790COVID-19\u524d\u540e\u7684\u60c5\u611f\u548c\u8bed\u8a00\u53d8\u5316\u3002", "result": "\u75ab\u60c5\u5bfc\u81f4Twitter\u7528\u6237\u75ab\u82d7\u8bdd\u8bed\u590d\u6742\u53d8\u5316\uff1a\u8d1f\u9762\u60c5\u7eea\u8bcd\u6c47\u51cf\u5c11\uff0c\u60ca\u8bb6\u548c\u4fe1\u4efb\u76f8\u5173\u60c5\u7eea\u8bcd\u6c47\u589e\u52a0\uff1b\u65e9\u671f\u4f7f\u7528\u66f4\u591a\u6e29\u6696\u3001\u4fe1\u4efb\u76f8\u5173\u8bcd\u6c47\u548c\u79ef\u6781\u80fd\u529b\u8bcd\u6c47\uff0c\u540e\u671f\u8d1f\u9762\u8bcd\u6c47\u663e\u8457\u4e0a\u5347\u3002", "conclusion": "COVID-19\u5927\u6d41\u884c\u663e\u8457\u6539\u53d8\u4e86\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u75ab\u82d7\u8bdd\u8bed\u6a21\u5f0f\uff0c\u65e9\u671f\u4fe1\u4efb\u548c\u79ef\u6781\u8bcd\u6c47\u589e\u52a0\uff0c\u540e\u671f\u8d1f\u9762\u8bcd\u6c47\u4e0a\u5347\u53ef\u80fd\u53cd\u6620\u4e86\u75ab\u82d7\u72b9\u8c6b\u548c\u6000\u7591\u60c5\u7eea\u7684\u589e\u957f\u3002"}}
{"id": "2511.16844", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.16844", "abs": "https://arxiv.org/abs/2511.16844", "authors": ["Disha Kamale", "Xi Yu", "Cristian-Ioan Vasile"], "title": "A*-based Temporal Logic Path Planning with User Preferences on Relaxed Task Satisfaction", "comment": null, "summary": "In this work, we consider the problem of planning for temporal logic tasks in large robot environments. When full task compliance is unattainable, we aim to achieve the best possible task satisfaction by integrating user preferences for relaxation into the planning process. Utilizing the automata-based representations for temporal logic goals and user preferences, we propose an A*-based planning framework. This approach effectively tackles large-scale problems while generating near-optimal high-level trajectories. To facilitate this, we propose a simple, efficient heuristic that allows for planning over large robot environments in a fraction of time and search memory as compared to uninformed search algorithms. We present extensive case studies to demonstrate the scalability, runtime analysis as well as empirical bounds on the suboptimality of the proposed heuristic.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eA*\u7684\u89c4\u5212\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5927\u578b\u673a\u5668\u4eba\u73af\u5883\u4e2d\u5904\u7406\u65f6\u5e8f\u903b\u8f91\u4efb\u52a1\uff0c\u5f53\u65e0\u6cd5\u5b8c\u5168\u6ee1\u8db3\u4efb\u52a1\u8981\u6c42\u65f6\uff0c\u901a\u8fc7\u6574\u5408\u7528\u6237\u504f\u597d\u6765\u83b7\u5f97\u6700\u4f73\u4efb\u52a1\u6ee1\u610f\u5ea6\u3002", "motivation": "\u5728\u5927\u578b\u673a\u5668\u4eba\u73af\u5883\u4e2d\uff0c\u5b8c\u5168\u6ee1\u8db3\u65f6\u5e8f\u903b\u8f91\u4efb\u52a1\u8981\u6c42\u5f80\u5f80\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u4efb\u52a1\u677e\u5f1b\u5e76\u8003\u8651\u7528\u6237\u504f\u597d\u7684\u89c4\u5212\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u65f6\u5e8f\u903b\u8f91\u76ee\u6807\u548c\u7528\u6237\u504f\u597d\u7684\u81ea\u52a8\u673a\u8868\u793a\uff0c\u63d0\u51fa\u57fa\u4e8eA*\u7684\u89c4\u5212\u6846\u67b6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684\u53ef\u91c7\u7eb3\u542f\u53d1\u5f0f\u51fd\u6570\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5927\u578b\u73af\u5883\u4e2d\u5feb\u901f\u89c4\u5212\uff0c\u76f8\u6bd4\u65e0\u4fe1\u606f\u641c\u7d22\u7b97\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u65f6\u95f4\u548c\u5185\u5b58\u6d88\u8017\uff0c\u540c\u65f6\u751f\u6210\u63a5\u8fd1\u6700\u4f18\u7684\u9ad8\u5c42\u8f68\u8ff9\u3002", "conclusion": "\u63d0\u51fa\u7684\u542f\u53d1\u5f0f\u89c4\u5212\u65b9\u6cd5\u5177\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u65f6\u5e8f\u903b\u8f91\u4efb\u52a1\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\u3002"}}
{"id": "2511.16814", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.16814", "abs": "https://arxiv.org/abs/2511.16814", "authors": ["Silvia Rondini", "Claudia Alvarez-Martin", "Paula Angermair-Barkai", "Olivier Penacchio", "M. Paz", "Matthew Pelowski", "Dan Dediu", "Antoni Rodriguez-Fornells", "Xim Cerda-Company"], "title": "Stable diffusion models reveal a persisting human and AI gap in visual creativity", "comment": null, "summary": "While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u89c6\u89c9\u827a\u672f\u5bb6\u5728\u56fe\u50cf\u751f\u6210\u521b\u9020\u529b\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5176\u6b21\u662f\u666e\u901a\u4eba\uff0c\u800c\u751f\u6210\u5f0fAI\u7684\u521b\u9020\u529b\u6700\u4f4e\u3002\u589e\u52a0\u4eba\u7c7b\u6307\u5bfc\u80fd\u663e\u8457\u63d0\u5347AI\u7684\u521b\u9020\u529b\u8868\u73b0\uff0c\u4f7f\u5176\u63a5\u8fd1\u666e\u901a\u4eba\u6c34\u5e73\u3002\u4eba\u7c7b\u548cAI\u8bc4\u5206\u8005\u5728\u521b\u9020\u529b\u8bc4\u5224\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9\u521b\u9020\u529b\u9886\u57df\uff0c\u6bd4\u8f83\u4eba\u7c7b\uff08\u827a\u672f\u5bb6\u548c\u975e\u827a\u672f\u5bb6\uff09\u4e0e\u751f\u6210\u5f0fAI\u5728\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u521b\u9020\u529b\u8868\u73b0\uff0c\u586b\u8865\u8bed\u8a00\u521b\u9020\u529b\u7814\u7a76\u4e4b\u5916\u7684\u89c6\u89c9\u521b\u9020\u529b\u7a7a\u767d\u3002", "method": "\u6bd4\u8f83\u4eba\u7c7b\u53c2\u4e0e\u8005\uff08\u89c6\u89c9\u827a\u672f\u5bb6\u548c\u975e\u827a\u672f\u5bb6\uff09\u4e0e\u56fe\u50cf\u751f\u6210AI\u6a21\u578b\uff08\u4e24\u79cd\u63d0\u793a\u6761\u4ef6\uff1a\u9ad8\u4eba\u7c7b\u8f93\u5165\u7684\"\u4eba\u7c7b\u542f\u53d1\"\u548c\u4f4e\u4eba\u7c7b\u8f93\u5165\u7684\"\u81ea\u4e3b\u5f15\u5bfc\"\uff09\u7684\u56fe\u50cf\u751f\u6210\u80fd\u529b\u3002\u7531255\u540d\u4eba\u7c7b\u8bc4\u5206\u8005\u548cGPT4o\u8bc4\u4f30\u751f\u6210\u56fe\u50cf\u7684\u521b\u9020\u529b\u3002", "result": "\u53d1\u73b0\u6e05\u6670\u7684\u521b\u9020\u529b\u68af\u5ea6\uff1a\u89c6\u89c9\u827a\u672f\u5bb6\u6700\u5177\u521b\u9020\u529b\uff0c\u5176\u6b21\u662f\u975e\u827a\u672f\u5bb6\uff0c\u7136\u540e\u662f\"\u4eba\u7c7b\u542f\u53d1\"\u751f\u6210AI\uff0c\u6700\u540e\u662f\"\u81ea\u4e3b\u5f15\u5bfc\"\u751f\u6210AI\u3002\u589e\u52a0\u4eba\u7c7b\u6307\u5bfc\u80fd\u663e\u8457\u63d0\u5347\u751f\u6210AI\u7684\u521b\u9020\u529b\u8f93\u51fa\uff0c\u4f7f\u5176\u63a5\u8fd1\u975e\u827a\u672f\u5bb6\u7684\u6c34\u5e73\u3002\u4eba\u7c7b\u548cAI\u8bc4\u5206\u8005\u5728\u521b\u9020\u529b\u8bc4\u5224\u6a21\u5f0f\u4e0a\u5b58\u5728\u5de8\u5927\u5dee\u5f02\u3002", "conclusion": "\u4e0e\u8bed\u8a00\u4e2d\u5fc3\u4efb\u52a1\u4e0d\u540c\uff0c\u751f\u6210\u5f0fAI\u6a21\u578b\u5728\u89c6\u89c9\u9886\u57df\u53ef\u80fd\u9762\u4e34\u72ec\u7279\u6311\u6218\uff0c\u56e0\u4e3a\u89c6\u89c9\u521b\u9020\u529b\u4f9d\u8d56\u4e8e\u611f\u77e5\u7ec6\u5fae\u5dee\u522b\u548c\u4e0a\u4e0b\u6587\u654f\u611f\u6027\uff0c\u8fd9\u4e9b\u662f\u4eba\u7c7b\u7279\u6709\u7684\u80fd\u529b\uff0c\u53ef\u80fd\u4e0d\u5bb9\u6613\u4ece\u8bed\u8a00\u6a21\u578b\u8f6c\u79fb\u3002"}}
{"id": "2511.16974", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16974", "abs": "https://arxiv.org/abs/2511.16974", "authors": ["MST Rumi Akter", "Anamitra Pal", "Rajasekhar Anguluri"], "title": "State-Derivative Feedback Control for Damping Low-Frequency Oscillations in Bulk Power Systems", "comment": "5 pages, 6 figures, 1 table, Submitted to IEEE PES General Meeting 2026", "summary": "Low-frequency oscillations remain a major challenge in bulk power systems with high renewable penetration, long lines, and large loads. Existing damping strategies based on power modulation of high voltage DC (HVDC) or energy storage, are often limited by fixed control architectures, leaving some modes poorly damped. This paper introduces a state-derivative feedback (SDF) damping controller that uses both frequency and its rate of change as feedback signals. Incorporating state derivatives enhances modal damping and accelerates frequency recovery, enabling HVDC and energy storage to effectively stabilize the grid. We evaluate the SDF controller on two- and three-area systems and compare performance with a frequency difference-based damping scheme. Results show that the SDF control reproduces state-feedback performance while providing good damping of both inter- and intra-area oscillations compared to the frequency-difference method, highlighting its potential as a practical solution for stabilizing power-electronics-rich grids.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u72b6\u6001\u5bfc\u6570\u53cd\u9988\u7684\u963b\u5c3c\u63a7\u5236\u5668\uff0c\u4f7f\u7528\u9891\u7387\u53ca\u5176\u53d8\u5316\u7387\u4f5c\u4e3a\u53cd\u9988\u4fe1\u53f7\uff0c\u589e\u5f3a\u6a21\u6001\u963b\u5c3c\u5e76\u52a0\u901f\u9891\u7387\u6062\u590d\uff0c\u4f7fHVDC\u548c\u50a8\u80fd\u7cfb\u7edf\u80fd\u6709\u6548\u7a33\u5b9a\u7535\u7f51\u3002", "motivation": "\u4f4e\u9891\u632f\u8361\u662f\u542b\u9ad8\u6bd4\u4f8b\u53ef\u518d\u751f\u80fd\u6e90\u3001\u957f\u7ebf\u8def\u548c\u5927\u8d1f\u8377\u7684\u7535\u529b\u7cfb\u7edf\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8eHVDC\u529f\u7387\u8c03\u5236\u6216\u50a8\u80fd\u7684\u963b\u5c3c\u7b56\u7565\u53d7\u9650\u4e8e\u56fa\u5b9a\u63a7\u5236\u67b6\u6784\uff0c\u67d0\u4e9b\u6a21\u6001\u963b\u5c3c\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u72b6\u6001\u5bfc\u6570\u53cd\u9988\u963b\u5c3c\u63a7\u5236\u5668\uff0c\u540c\u65f6\u4f7f\u7528\u9891\u7387\u53ca\u5176\u53d8\u5316\u7387\u4f5c\u4e3a\u53cd\u9988\u4fe1\u53f7\uff0c\u901a\u8fc7\u7ed3\u5408\u72b6\u6001\u5bfc\u6570\u6765\u589e\u5f3a\u6a21\u6001\u963b\u5c3c\u548c\u52a0\u901f\u9891\u7387\u6062\u590d\u3002", "result": "\u5728\u4e24\u533a\u57df\u548c\u4e09\u533a\u57df\u7cfb\u7edf\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cSDF\u63a7\u5236\u5668\u80fd\u91cd\u73b0\u72b6\u6001\u53cd\u9988\u6027\u80fd\uff0c\u5728\u533a\u57df\u95f4\u548c\u533a\u57df\u5185\u632f\u8361\u65b9\u9762\u90fd\u63d0\u4f9b\u826f\u597d\u963b\u5c3c\uff0c\u4f18\u4e8e\u57fa\u4e8e\u9891\u7387\u5dee\u7684\u65b9\u6cd5\u3002", "conclusion": "SDF\u63a7\u5236\u6709\u6f5c\u529b\u6210\u4e3a\u7a33\u5b9a\u7535\u529b\u7535\u5b50\u4e30\u5bcc\u7535\u7f51\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u6709\u6548\u963b\u5c3c\u5404\u79cd\u632f\u8361\u6a21\u5f0f\u3002"}}
{"id": "2511.16932", "categories": ["stat.AP", "econ.EM", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.16932", "abs": "https://arxiv.org/abs/2511.16932", "authors": ["Chang Zhai", "Ping Chen", "Zhuo Jin", "David Pitt"], "title": "Optimising pandemic response through vaccination strategies using neural networks", "comment": null, "summary": "Epidemic risk assessment poses inherent challenges, with traditional approaches often failing to balance health outcomes and economic constraints. This paper presents a data-driven decision support tool that models epidemiological dynamics and optimises vaccination strategies to control disease spread whilst minimising economic losses. The proposed economic-epidemiological framework comprises three phases: modelling, optimising, and analysing. First, a stochastic compartmental model captures epidemic dynamics. Second, an optimal control problem is formulated to derive vaccination strategies that minimise pandemic-related expenditure. Given the analytical intractability of epidemiological models, neural networks are employed to calibrate parameters and solve the high-dimensional control problem. The framework is demonstrated using COVID-19 data from Victoria, Australia, empirically deriving optimal vaccination strategies that simultaneously minimise disease incidence and governmental expenditure. By employing this three-phase framework, policymakers can adjust input values to reflect evolving transmission dynamics and continuously update strategies, thereby minimising aggregate costs, aiding future pandemic preparedness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\uff0c\u901a\u8fc7\u5efa\u6a21\u6d41\u884c\u75c5\u5b66\u52a8\u6001\u548c\u4f18\u5316\u75ab\u82d7\u63a5\u79cd\u7b56\u7565\uff0c\u5728\u63a7\u5236\u75be\u75c5\u4f20\u64ad\u7684\u540c\u65f6\u6700\u5c0f\u5316\u7ecf\u6d4e\u635f\u5931\u3002", "motivation": "\u4f20\u7edf\u6d41\u884c\u75c5\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u5065\u5eb7\u7ed3\u679c\u548c\u7ecf\u6d4e\u7ea6\u675f\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u540c\u65f6\u8003\u8651\u6d41\u884c\u75c5\u5b66\u52a8\u6001\u548c\u7ecf\u6d4e\u6210\u672c\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u7ecf\u6d4e-\u6d41\u884c\u75c5\u5b66\u6846\u67b6\uff1a1) \u4f7f\u7528\u968f\u673a\u9694\u5ba4\u6a21\u578b\u5efa\u6a21\u6d41\u884c\u75c5\u52a8\u6001\uff1b2) \u6784\u5efa\u6700\u4f18\u63a7\u5236\u95ee\u9898\u4f18\u5316\u75ab\u82d7\u63a5\u79cd\u7b56\u7565\uff1b3) \u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u6821\u51c6\u53c2\u6570\u5e76\u89e3\u51b3\u9ad8\u7ef4\u63a7\u5236\u95ee\u9898\u3002", "result": "\u57fa\u4e8e\u6fb3\u5927\u5229\u4e9a\u7ef4\u591a\u5229\u4e9a\u5ddeCOVID-19\u6570\u636e\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u63a8\u5bfc\u51fa\u540c\u65f6\u6700\u5c0f\u5316\u75be\u75c5\u53d1\u75c5\u7387\u548c\u653f\u5e9c\u652f\u51fa\u7684\u6700\u4f18\u75ab\u82d7\u63a5\u79cd\u7b56\u7565\u3002", "conclusion": "\u8be5\u4e09\u9636\u6bb5\u6846\u67b6\u4f7f\u653f\u7b56\u5236\u5b9a\u8005\u80fd\u591f\u6839\u636e\u4e0d\u65ad\u53d8\u5316\u7684\u4f20\u64ad\u52a8\u6001\u8c03\u6574\u8f93\u5165\u503c\u5e76\u6301\u7eed\u66f4\u65b0\u7b56\u7565\uff0c\u4ece\u800c\u6700\u5c0f\u5316\u603b\u6210\u672c\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u5927\u6d41\u884c\u9632\u8303\u3002"}}
{"id": "2511.16931", "categories": ["cs.CY", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16931", "abs": "https://arxiv.org/abs/2511.16931", "authors": ["Chenyang Shao", "Dehao Huang", "Yu Li", "Keyu Zhao", "Weiquan Lin", "Yining Zhang", "Qingbin Zeng", "Zhiyu Chen", "Tianxing Li", "Yifei Huang", "Taozhong Wu", "Xinyang Liu", "Ruotong Zhao", "Mengsheng Zhao", "Xuhua Zhang", "Yue Wang", "Yuanyi Zhen", "Fengli Xu", "Yong Li", "Tie-Yan Liu"], "title": "OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists", "comment": null, "summary": "With the rapid development of Large Language Models (LLMs), AI agents have demonstrated increasing proficiency in scientific tasks, ranging from hypothesis generation and experimental design to manuscript writing. Such agent systems are commonly referred to as \"AI Scientists.\" However, existing AI Scientists predominantly formulate scientific discovery as a standalone search or optimization problem, overlooking the fact that scientific research is inherently a social and collaborative endeavor. Real-world science relies on a complex scientific infrastructure composed of collaborative mechanisms, contribution attribution, peer review, and structured scientific knowledge networks. Due to the lack of modeling for these critical dimensions, current systems struggle to establish a genuine research ecosystem or interact deeply with the human scientific community. To bridge this gap, we introduce OmniScientist, a framework that explicitly encodes the underlying mechanisms of human research into the AI scientific workflow. OmniScientist not only achieves end-to-end automation across data foundation, literature review, research ideation, experiment automation, scientific writing, and peer review, but also provides comprehensive infrastructural support by simulating the human scientific system, comprising: (1) a structured knowledge system built upon citation networks and conceptual correlations; (2) a collaborative research protocol (OSP), which enables seamless multi-agent collaboration and human researcher participation; and (3) an open evaluation platform (ScienceArena) based on blind pairwise user voting and Elo rankings. This infrastructure empowers agents to not only comprehend and leverage human knowledge systems but also to collaborate and co-evolve, fostering a sustainable and scalable innovation ecosystem.", "AI": {"tldr": "OmniScientist\u662f\u4e00\u4e2aAI\u79d1\u5b66\u5bb6\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u79d1\u7814\u7cfb\u7edf\u7684\u534f\u4f5c\u673a\u5236\u3001\u77e5\u8bc6\u7f51\u7edc\u548c\u540c\u884c\u8bc4\u5ba1\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u79d1\u7814\u6d41\u7a0b\u3002", "motivation": "\u73b0\u6709AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5c06\u79d1\u5b66\u53d1\u73b0\u89c6\u4e3a\u72ec\u7acb\u641c\u7d22\u95ee\u9898\uff0c\u5ffd\u89c6\u4e86\u79d1\u7814\u7684\u793e\u4f1a\u534f\u4f5c\u672c\u8d28\uff0c\u7f3a\u4e4f\u5bf9\u79d1\u5b66\u57fa\u7840\u8bbe\u65bd\u7684\u5efa\u6a21\uff0c\u96be\u4ee5\u4e0e\u4eba\u7c7b\u79d1\u5b66\u754c\u6df1\u5ea6\u4e92\u52a8\u3002", "method": "\u6784\u5efa\u7ed3\u6784\u5316\u77e5\u8bc6\u7cfb\u7edf\uff08\u57fa\u4e8e\u5f15\u6587\u7f51\u7edc\u548c\u6982\u5ff5\u5173\u8054\uff09\u3001\u534f\u4f5c\u7814\u7a76\u534f\u8baeOSP\uff08\u652f\u6301\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u4eba\u7c7b\u53c2\u4e0e\uff09\u3001\u5f00\u653e\u8bc4\u4f30\u5e73\u53f0ScienceArena\uff08\u57fa\u4e8e\u76f2\u5ba1\u6295\u7968\u548cElo\u6392\u540d\uff09\u3002", "result": "\u5b9e\u73b0\u4e86\u4ece\u6570\u636e\u57fa\u7840\u3001\u6587\u732e\u7efc\u8ff0\u3001\u7814\u7a76\u6784\u601d\u3001\u5b9e\u9a8c\u81ea\u52a8\u5316\u3001\u79d1\u5b66\u5199\u4f5c\u5230\u540c\u884c\u8bc4\u5ba1\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u5316\uff0c\u5efa\u7acb\u4e86\u53ef\u6301\u7eed\u7684\u521b\u65b0\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "OmniScientist\u901a\u8fc7\u7f16\u7801\u4eba\u7c7b\u79d1\u7814\u673a\u5236\uff0c\u4f7fAI\u667a\u80fd\u4f53\u80fd\u591f\u7406\u89e3\u5229\u7528\u4eba\u7c7b\u77e5\u8bc6\u7cfb\u7edf\uff0c\u534f\u4f5c\u5171\u8fdb\u5316\uff0c\u521b\u5efa\u53ef\u6269\u5c55\u7684\u79d1\u7814\u521b\u65b0\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2511.17333", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.17333", "abs": "https://arxiv.org/abs/2511.17333", "authors": ["Lorenzo Alvisi", "Victoria Popa", "Guglielmo Cola", "Serena Tardelli", "Maurizio Tesconi"], "title": "From Toxicity to Conformity: Adaptive user behavior to social norms in Telegram communities", "comment": "13 pages, 5 figures, 4 tables", "summary": "Toxic and antisocial user behavior on social media platforms has received considerable scholarly attention due to its detrimental effects on society. This study takes a holistic perspective on the phenomenon of online toxicity by investigating the impact of local community norms on toxic expression. By using six large-scale datasets, comprising over 500 million Telegram messages collected between 2015 and 2024, we analyze toxic user behavior across multiple chats and languages. We introduce a methodological framework that models user adaptation through a conformity index, capturing conformist, anti-conformist, and independent behavioral tendencies. Our findings show that most users tend to conform to local normative environments, adjusting their toxicity to match the toxicity levels of the chats in which they participate. These patterns are consistent across datasets and languages, suggesting that community norms and social influence play a decisive role in shaping user behavior online. Furthermore, we demonstrate that exposure to these norms, in terms of increased user participation in chats, is associated with a stronger tendency toward conformity with the surrounding social contexts. Collectively, these findings contribute to a deeper understanding of toxic online behavior and highlight the importance of contextualized approaches to content moderation.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u67905\u4ebf\u6761Telegram\u6d88\u606f\u53d1\u73b0\uff0c\u7528\u6237\u503e\u5411\u4e8e\u9002\u5e94\u5f53\u5730\u793e\u533a\u89c4\u8303\uff0c\u8c03\u6574\u81ea\u5df1\u7684\u6bd2\u6027\u8868\u8fbe\u4ee5\u5339\u914d\u6240\u53c2\u4e0e\u804a\u5929\u7684\u6bd2\u6027\u6c34\u5e73\uff0c\u793e\u533a\u89c4\u8303\u548c\u793e\u4f1a\u5f71\u54cd\u5728\u5851\u9020\u5728\u7ebf\u7528\u6237\u884c\u4e3a\u4e2d\u8d77\u51b3\u5b9a\u6027\u4f5c\u7528\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u6709\u6bd2\u548c\u53cd\u793e\u4f1a\u884c\u4e3a\u5bf9\u793e\u4f1a\u4ea7\u751f\u6709\u5bb3\u5f71\u54cd\uff0c\u9700\u8981\u4ece\u6574\u4f53\u89d2\u5ea6\u7814\u7a76\u5728\u7ebf\u6bd2\u6027\u73b0\u8c61\uff0c\u7279\u522b\u662f\u5f53\u5730\u793e\u533a\u89c4\u8303\u5bf9\u6bd2\u6027\u8868\u8fbe\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u516d\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff082015-2024\u5e74\u6536\u96c6\u76845\u4ebf\u591a\u6761Telegram\u6d88\u606f\uff09\uff0c\u5f15\u5165\u5efa\u6a21\u7528\u6237\u9002\u5e94\u7684\u65b9\u6cd5\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u4e00\u81f4\u6027\u6307\u6570\u6355\u6349\u987a\u4ece\u3001\u53cd\u987a\u4ece\u548c\u72ec\u7acb\u884c\u4e3a\u503e\u5411\u3002", "result": "\u5927\u591a\u6570\u7528\u6237\u503e\u5411\u4e8e\u9002\u5e94\u5f53\u5730\u89c4\u8303\u73af\u5883\uff0c\u8c03\u6574\u6bd2\u6027\u4ee5\u5339\u914d\u6240\u53c2\u4e0e\u804a\u5929\u7684\u6bd2\u6027\u6c34\u5e73\uff0c\u8fd9\u4e9b\u6a21\u5f0f\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u8bed\u8a00\u4e2d\u4e00\u81f4\uff0c\u7528\u6237\u53c2\u4e0e\u5ea6\u589e\u52a0\u4e0e\u66f4\u5f3a\u7684\u987a\u4ece\u503e\u5411\u76f8\u5173\u3002", "conclusion": "\u793e\u533a\u89c4\u8303\u548c\u793e\u4f1a\u5f71\u54cd\u5728\u5851\u9020\u5728\u7ebf\u7528\u6237\u884c\u4e3a\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u5f3a\u8c03\u9700\u8981\u60c5\u5883\u5316\u7684\u5185\u5bb9\u5ba1\u6838\u65b9\u6cd5\u3002"}}
{"id": "2511.16898", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16898", "abs": "https://arxiv.org/abs/2511.16898", "authors": ["Ariel Slepyan", "Laura Xing", "Rudy Zhang", "Nitish Thakor"], "title": "Single-Pixel Tactile Skin via Compressive Sampling", "comment": "24 pages, 6 main figures, 6 supplemental figures", "summary": "Development of large-area, high-speed electronic skins is a grand challenge for robotics, prosthetics, and human-machine interfaces, but is fundamentally limited by wiring complexity and data bottlenecks. Here, we introduce Single-Pixel Tactile Skin (SPTS), a paradigm that uses compressive sampling to reconstruct rich tactile information from an entire sensor array via a single output channel. This is achieved through a direct circuit-level implementation where each sensing element, equipped with a miniature microcontroller, contributes a dynamically weighted analog signal to a global sum, performing distributed compressed sensing in hardware. Our flexible, daisy-chainable design simplifies wiring to a few input lines and one output, and significantly reduces measurement requirements compared to raster scanning methods. We demonstrate the system's performance by achieving object classification at an effective 3500 FPS and by capturing transient dynamics, resolving an 8 ms projectile impact into 23 frames. A key feature is the support for adaptive reconstruction, where sensing fidelity scales with measurement time. This allows for rapid contact localization using as little as 7% of total data, followed by progressive refinement to a high-fidelity image - a capability critical for responsive robotic systems. This work offers an efficient pathway towards large-scale tactile intelligence for robotics and human-machine interfaces.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPTS\u7684\u5355\u50cf\u7d20\u89e6\u89c9\u76ae\u80a4\u7cfb\u7edf\uff0c\u901a\u8fc7\u538b\u7f29\u91c7\u6837\u6280\u672f\u4ece\u6574\u4e2a\u4f20\u611f\u5668\u9635\u5217\u4e2d\u91cd\u5efa\u4e30\u5bcc\u7684\u89e6\u89c9\u4fe1\u606f\uff0c\u4ec5\u4f7f\u7528\u5355\u4e00\u8f93\u51fa\u901a\u9053\uff0c\u89e3\u51b3\u4e86\u5927\u9762\u79ef\u9ad8\u901f\u7535\u5b50\u76ae\u80a4\u9762\u4e34\u7684\u5e03\u7ebf\u590d\u6742\u6027\u548c\u6570\u636e\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u5f00\u53d1\u5927\u9762\u79ef\u3001\u9ad8\u901f\u7535\u5b50\u76ae\u80a4\u662f\u673a\u5668\u4eba\u6280\u672f\u3001\u5047\u80a2\u548c\u4eba\u673a\u754c\u9762\u7684\u91cd\u5927\u6311\u6218\uff0c\u4f46\u53d7\u5230\u5e03\u7ebf\u590d\u6742\u6027\u548c\u6570\u636e\u74f6\u9888\u7684\u6839\u672c\u9650\u5236\u3002", "method": "\u91c7\u7528\u76f4\u63a5\u7535\u8def\u7ea7\u5b9e\u73b0\uff0c\u6bcf\u4e2a\u4f20\u611f\u5143\u4ef6\u914d\u5907\u5fae\u578b\u5fae\u63a7\u5236\u5668\uff0c\u5411\u5168\u5c40\u603b\u548c\u8d21\u732e\u52a8\u6001\u52a0\u6743\u7684\u6a21\u62df\u4fe1\u53f7\uff0c\u5728\u786c\u4ef6\u4e2d\u6267\u884c\u5206\u5e03\u5f0f\u538b\u7f29\u611f\u77e5\u3002\u91c7\u7528\u67d4\u6027\u3001\u53ef\u83ca\u82b1\u94fe\u8fde\u63a5\u7684\u8bbe\u8ba1\uff0c\u5c06\u5e03\u7ebf\u7b80\u5316\u4e3a\u51e0\u6761\u8f93\u5165\u7ebf\u548c\u4e00\u6761\u8f93\u51fa\u7ebf\u3002", "result": "\u5b9e\u73b0\u4e863500 FPS\u7684\u6709\u6548\u7269\u4f53\u5206\u7c7b\uff0c\u80fd\u591f\u6355\u6349\u77ac\u6001\u52a8\u6001\uff0c\u5c068\u6beb\u79d2\u7684\u5f39\u4e38\u649e\u51fb\u89e3\u6790\u4e3a23\u5e27\u3002\u652f\u6301\u81ea\u9002\u5e94\u91cd\u5efa\uff0c\u4ec5\u4f7f\u75287%\u7684\u603b\u6570\u636e\u5373\u53ef\u5feb\u901f\u5b9a\u4f4d\u63a5\u89e6\uff0c\u7136\u540e\u9010\u6b65\u7ec6\u5316\u5230\u9ad8\u4fdd\u771f\u56fe\u50cf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u673a\u5668\u4eba\u6280\u672f\u548c\u4eba\u673a\u754c\u9762\u7684\u5927\u89c4\u6a21\u89e6\u89c9\u667a\u80fd\u63d0\u4f9b\u4e86\u4e00\u6761\u9ad8\u6548\u9014\u5f84\u3002"}}
{"id": "2511.16837", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16837", "abs": "https://arxiv.org/abs/2511.16837", "authors": ["Oliver Kramer"], "title": "Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs", "comment": "6 pages, Submitted to ESANN 2026", "summary": "Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.", "AI": {"tldr": "Cognitive BASIC\u662f\u4e00\u79cd\u57fa\u4e8eBASIC\u98ce\u683c\u7684\u63d0\u793a\u8bed\u8a00\u548c\u6a21\u578b\u5185\u89e3\u91ca\u5668\uff0c\u5c06LLM\u63a8\u7406\u7ed3\u6784\u5316\u4e3a\u663e\u5f0f\u7684\u9010\u6b65\u6267\u884c\u8f68\u8ff9\uff0c\u901a\u8fc7\u6a21\u62df\u7b80\u77ed\u7a0b\u5e8f\u5b9e\u73b0\u900f\u660e\u7684\u591a\u6b65\u63a8\u7406\u3002", "motivation": "\u53d7\u590d\u53e4BASIC\u7b80\u5355\u6027\u7684\u542f\u53d1\uff0c\u91cd\u65b0\u5229\u7528\u7f16\u53f7\u884c\u548c\u7b80\u5355\u547d\u4ee4\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u8ba4\u77e5\u63a7\u5236\u5c42\uff0c\u4f7f\u73b0\u4ee3LLM\u80fd\u591f\u53ef\u9760\u6a21\u62df\u8fd9\u7c7b\u77ed\u7a0b\u5e8f\uff0c\u5b9e\u73b0\u6a21\u578b\u5185\u90e8\u900f\u660e\u7684\u591a\u6b65\u63a8\u7406\u3002", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u5668\u6587\u4ef6\u6307\u5b9a\u547d\u4ee4\u8bed\u4e49\u3001\u5185\u5b58\u66f4\u65b0\u548c\u65e5\u5fd7\u884c\u4e3a\uff0c\u901a\u8fc7\u5fc3\u7406\u6a21\u578b\u89e3\u91ca\u5668\u63d0\u53d6\u58f0\u660e\u6027\u548c\u7a0b\u5e8f\u6027\u77e5\u8bc6\uff0c\u68c0\u6d4b\u77db\u76fe\u5e76\u5728\u5fc5\u8981\u65f6\u4ea7\u751f\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u4e09\u4e2aLLM\u4e0a\u5bf9\u77e5\u8bc6\u63d0\u53d6\u3001\u51b2\u7a81\u68c0\u6d4b\u548c\u63a8\u7406\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u6240\u6709\u6a21\u578b\u90fd\u80fd\u6267\u884cCognitive BASIC\u7a0b\u5e8f\uff0c\u6574\u4f53\u8868\u73b0\u5f3a\u52b2\u4f46\u6027\u80fd\u4e0d\u5747\u3002", "conclusion": "Cognitive BASIC\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ed3\u6784\u5316LLM\u63a8\u7406\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u6267\u884c\u8f68\u8ff9\u589e\u5f3a\u4e86\u63a8\u7406\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.16983", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16983", "abs": "https://arxiv.org/abs/2511.16983", "authors": ["Xiao Yang", "Shuai Ma", "Yong Liang", "Guangming Shi"], "title": "Feature Partitioning and Semantic Equalization for Intrinsic Robustness in Semantic Communication under Packet Loss", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Semantic communication can improve transmission efficiency by focusing on task-relevant information. However, under packet-based communication protocols, any error typically results in the loss of an entire packet, making semantic communication particularly vulnerable to packet loss. Since high-dimensional semantic features must be partitioned into one-dimensional transmission units during packetization. A critical open question is how to partition semantic features to maximize robustness. To address this, we systematically investigate the performance of two mainstream architectures, Transformer and Convolutional neural networks (CNN), under various feature partitioning schemes. The results show that the Transformer architecture exhibits inherent robustness to packet loss when partitioned along the channel dimension. In contrast, the CNN-based baseline exhibits imbalanced channel utilization, causing severe degradation once dominant channels are lost. To enhance the CNN resilience, we propose a lightweight Semantic Equalization Mechanism (SEM) that balances channel contributions and prevents a few channels from dominating. SEM consists of two parallel approaches: a Dynamic Scale module that adaptively adjusts channel importance, and a Broadcast module that facilitates information interaction among channels. Experimental results demonstrate that CNN equipped with SEM achieve graceful degradation under packet loss (retaining about 85% of lossless PSNR at 40% packet loss), comparable to that of Transformer models. Our findings indicate that, under an appropriate partitioning strategy, maintaining a balanced semantic representation is a fundamental condition for achieving intrinsic robustness against packet loss. These insights may also extend to other modalities such as video and support practical semantic communication design.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8bed\u4e49\u901a\u4fe1\u4e2d\u7279\u5f81\u5212\u5206\u5bf9\u5305\u4e22\u5931\u9c81\u68d2\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0Transformer\u67b6\u6784\u5728\u901a\u9053\u7ef4\u5ea6\u5212\u5206\u65f6\u5177\u6709\u56fa\u6709\u9c81\u68d2\u6027\uff0c\u800cCNN\u67b6\u6784\u5b58\u5728\u901a\u9053\u5229\u7528\u4e0d\u5e73\u8861\u95ee\u9898\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u8f7b\u91cf\u7ea7\u7684\u8bed\u4e49\u5747\u8861\u673a\u5236(SEM)\u6765\u63d0\u5347CNN\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u8bed\u4e49\u901a\u4fe1\u867d\u7136\u80fd\u63d0\u9ad8\u4f20\u8f93\u6548\u7387\uff0c\u4f46\u5728\u57fa\u4e8e\u5305\u7684\u901a\u4fe1\u534f\u8bae\u4e0b\uff0c\u4efb\u4f55\u9519\u8bef\u90fd\u4f1a\u5bfc\u81f4\u6574\u4e2a\u5305\u4e22\u5931\uff0c\u4f7f\u5f97\u8bed\u4e49\u901a\u4fe1\u7279\u522b\u5bb9\u6613\u53d7\u5230\u5305\u4e22\u5931\u7684\u5f71\u54cd\u3002\u5173\u952e\u95ee\u9898\u662f\u5982\u4f55\u5212\u5206\u8bed\u4e49\u7279\u5f81\u4ee5\u6700\u5927\u5316\u9c81\u68d2\u6027\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u4e86Transformer\u548cCNN\u67b6\u6784\u5728\u4e0d\u540c\u7279\u5f81\u5212\u5206\u65b9\u6848\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0CNN\u5b58\u5728\u901a\u9053\u5229\u7528\u4e0d\u5e73\u8861\u95ee\u9898\u3002\u4e3a\u6b64\u63d0\u51fa\u4e86\u8bed\u4e49\u5747\u8861\u673a\u5236(SEM)\uff0c\u5305\u62ec\u52a8\u6001\u5c3a\u5ea6\u6a21\u5757\u548c\u5e7f\u64ad\u6a21\u5757\uff0c\u6765\u5e73\u8861\u901a\u9053\u8d21\u732e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u914d\u5907SEM\u7684CNN\u5728\u5305\u4e22\u5931\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u4f18\u96c5\u964d\u7ea7\uff08\u572840%\u5305\u4e22\u5931\u65f6\u4fdd\u6301\u7ea685%\u7684\u65e0\u635fPSNR\uff09\uff0c\u6027\u80fd\u4e0eTransformer\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u5728\u9002\u5f53\u7684\u5212\u5206\u7b56\u7565\u4e0b\uff0c\u4fdd\u6301\u5e73\u8861\u7684\u8bed\u4e49\u8868\u793a\u662f\u5b9e\u73b0\u5bf9\u5305\u4e22\u5931\u56fa\u6709\u9c81\u68d2\u6027\u7684\u57fa\u672c\u6761\u4ef6\uff0c\u8fd9\u4e00\u89c1\u89e3\u53ef\u80fd\u6269\u5c55\u5230\u89c6\u9891\u7b49\u5176\u4ed6\u6a21\u6001\uff0c\u5e76\u652f\u6301\u5b9e\u9645\u7684\u8bed\u4e49\u901a\u4fe1\u8bbe\u8ba1\u3002"}}
{"id": "2511.16954", "categories": ["stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.16954", "abs": "https://arxiv.org/abs/2511.16954", "authors": ["Qiyuan Liu", "Qirui Zhang", "Jinhong Du", "Siming Zhao", "Jingshu Wang"], "title": "Effects of Distance Metrics and Scaling on the Perturbation Discrimination Score", "comment": null, "summary": "The Perturbation Discrimination Score (PDS) is increasingly used to evaluate whether predicted perturbation effects remain distinguishable, including in Systema and the Virtual Cell Challenge. However, its behavior in high-dimensional gene-expression settings has not been examined in detail. We show that PDS is highly sensitive to the choice of similarity or distance measure and to the scale of predicted effects. Analysis of observed perturbation responses reveals that $\\ell_1$ and $\\ell_2$-based PDS behave very differently from cosine-based measures, even after norm matching. We provide geometric insight and discuss implications for future discrimination-based evaluation metrics.", "AI": {"tldr": "PDS\u4f5c\u4e3a\u8bc4\u4f30\u6270\u52a8\u6548\u5e94\u533a\u5206\u5ea6\u7684\u6307\u6807\uff0c\u5728\u57fa\u56e0\u8868\u8fbe\u7b49\u9ad8\u7ef4\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u5bf9\u76f8\u4f3c\u6027\u5ea6\u91cf\u548c\u6548\u5e94\u5c3a\u5ea6\u9009\u62e9\u9ad8\u5ea6\u654f\u611f\u3002", "motivation": "PDS\u5728Systema\u548cVirtual Cell Challenge\u7b49\u5e73\u53f0\u88ab\u5e7f\u6cdb\u7528\u4e8e\u8bc4\u4f30\u9884\u6d4b\u6270\u52a8\u6548\u5e94\u7684\u533a\u5206\u5ea6\uff0c\u4f46\u5176\u5728\u9ad8\u7ef4\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u4e2d\u7684\u884c\u4e3a\u5c1a\u672a\u88ab\u6df1\u5165\u7814\u7a76\u3002", "method": "\u5206\u6790\u89c2\u5bdf\u5230\u7684\u6270\u52a8\u54cd\u5e94\uff0c\u6bd4\u8f83\u57fa\u4e8e\u2113\u2081\u3001\u2113\u2082\u8303\u6570\u548c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684PDS\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u8303\u6570\u5339\u914d\u5206\u6790\u3002", "result": "\u53d1\u73b0\u57fa\u4e8e\u2113\u2081\u548c\u2113\u2082\u8303\u6570\u7684PDS\u4e0e\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684PDS\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0c\u5373\u4f7f\u7ecf\u8fc7\u8303\u6570\u5339\u914d\u540e\u4ecd\u7136\u5982\u6b64\u3002", "conclusion": "PDS\u5bf9\u76f8\u4f3c\u6027\u5ea6\u91cf\u548c\u6548\u5e94\u5c3a\u5ea6\u9ad8\u5ea6\u654f\u611f\uff0c\u8fd9\u4e3a\u672a\u6765\u57fa\u4e8e\u533a\u5206\u5ea6\u7684\u8bc4\u4f30\u6307\u6807\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2511.17124", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.17124", "abs": "https://arxiv.org/abs/2511.17124", "authors": ["Ariel Guerra-Adames", "Marta Avalos-Fernandez", "Oc\u00e9ane Dor\u00e9mus", "Leo Anthony Celi", "C\u00e9dric Gil-Jardin\u00e9", "Emmanuel Lagarde"], "title": "A Counterfactual LLM Framework for Detecting Human Biases: A Case Study of Sex/Gender in Emergency Triage", "comment": "Currently under review at npj Digital Medicine", "summary": "We present a novel, domain-agnostic counterfactual approach that uses Large Language Models (LLMs) to quantify gender disparities in human clinical decision-making. The method trains an LLM to emulate observed decisions, then evaluates counterfactual pairs in which only gender is flipped, estimating directional disparities while holding all other clinical factors constant. We study emergency triage, validating the approach on more than 150,000 admissions to the Bordeaux University Hospital (France) and replicating results on a subset of MIMIC-IV across a different language, population, and healthcare system. In the Bordeaux cohort, otherwise identical presentations were approximately 2.1% more likely to receive a lower-severity triage score when presented as female rather than male; scaled to national emergency volumes in France, this corresponds to more than 200,000 lower-severity assignments per year. Modality-specific analyses indicate that both explicit tabular gender indicators and implicit textual gender cues contribute to the disparity. Beyond emergency care, the approach supports bias audits in other settings (e.g., hiring, academic, and justice decisions), providing a scalable tool to detect and address inequities in real-world decision-making.", "AI": {"tldr": "\u4f7f\u7528LLMs\u91cf\u5316\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u6027\u522b\u5dee\u5f02\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5206\u6790\u53d1\u73b0\u5973\u6027\u5728\u6025\u8bca\u5206\u8bca\u4e2d\u88ab\u4f4e\u4f30\u4e25\u91cd\u7a0b\u5ea6\u7ea62.1%\uff0c\u6cd5\u56fd\u6bcf\u5e74\u8d85\u8fc720\u4e07\u4f8b\u3002", "motivation": "\u91cf\u5316\u4eba\u7c7b\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u6025\u8bca\u5206\u8bca\u7b49\u5173\u952e\u533b\u7597\u573a\u666f\u4e2d\uff0c\u4ee5\u68c0\u6d4b\u548c\u89e3\u51b3\u73b0\u5b9e\u51b3\u7b56\u4e2d\u7684\u4e0d\u5e73\u7b49\u95ee\u9898\u3002", "method": "\u8bad\u7ec3LLM\u6a21\u62df\u89c2\u5bdf\u5230\u7684\u51b3\u7b56\uff0c\u7136\u540e\u8bc4\u4f30\u4ec5\u6027\u522b\u7ffb\u8f6c\u7684\u53cd\u4e8b\u5b9e\u5bf9\uff0c\u5728\u4fdd\u6301\u6240\u6709\u5176\u4ed6\u4e34\u5e8a\u56e0\u7d20\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u4f30\u8ba1\u65b9\u5411\u6027\u5dee\u5f02\u3002", "result": "\u5728\u6cd5\u56fd\u6ce2\u5c14\u591a\u5927\u5b66\u533b\u966215\u4e07\u4f8b\u5165\u9662\u6570\u636e\u4e2d\uff0c\u76f8\u540c\u4e34\u5e8a\u8868\u73b0\u7684\u5973\u6027\u6bd4\u7537\u6027\u83b7\u5f97\u8f83\u4f4e\u4e25\u91cd\u7a0b\u5ea6\u5206\u8bca\u8bc4\u5206\u7684\u53ef\u80fd\u6027\u9ad8\u7ea62.1%\uff1b\u5728\u7f8e\u56fdMIMIC-IV\u6570\u636e\u96c6\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u68c0\u6d4b\u548c\u89e3\u51b3\u6025\u8bca\u62a4\u7406\u53ca\u5176\u4ed6\u9886\u57df\uff08\u5982\u62db\u8058\u3001\u5b66\u672f\u548c\u53f8\u6cd5\u51b3\u7b56\uff09\u4e2d\u7684\u504f\u89c1\u548c\u4e0d\u5e73\u7b49\u95ee\u9898\u3002"}}
{"id": "2511.16911", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.16911", "abs": "https://arxiv.org/abs/2511.16911", "authors": ["Yendo Hu", "Yiliang Wu", "Weican Chen"], "title": "Multi-UAV Swarm Obstacle Avoidance Based on Potential Field Optimization", "comment": "12 pages, 13 figures, and 2 tables", "summary": "In multi UAV scenarios,the traditional Artificial Potential Field (APF) method often leads to redundant flight paths and frequent abrupt heading changes due to unreasonable obstacle avoidance path planning,and is highly prone to inter UAV collisions during the obstacle avoidance process.To address these issues,this study proposes a novel hybrid algorithm that combines the improved Multi-Robot Formation Obstacle Avoidance (MRF IAPF) algorithm with an enhanced APF optimized for single UAV path planning.Its core ideas are as follows:first,integrating three types of interaction forces from MRF IAPF obstacle repulsion force,inter UAV interaction force,and target attraction force;second,incorporating a refined single UAV path optimization mechanism,including collision risk assessment and an auxiliary sub goal strategy.When a UAV faces a high collision threat,temporary waypoints are generated to guide obstacle avoidance,ensuring eventual precise arrival at the actual target.Simulation results demonstrate that compared with traditional APF based formation algorithms,the proposed algorithm achieves significant improvements in path length optimization and heading stability,can effectively avoid obstacles and quickly restore the formation configuration,thus verifying its applicability and effectiveness in static environments with unknown obstacles.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6539\u8fdb\u591a\u673a\u5668\u4eba\u7f16\u961f\u907f\u969c\u7b97\u6cd5\u548c\u589e\u5f3a\u4eba\u5de5\u52bf\u573a\u6cd5\u7684\u6df7\u5408\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfAPF\u5728\u591a\u65e0\u4eba\u673a\u573a\u666f\u4e2d\u8def\u5f84\u5197\u4f59\u3001\u822a\u5411\u7a81\u53d8\u548c\u78b0\u649e\u98ce\u9669\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u4eba\u5de5\u52bf\u573a\u6cd5\u5728\u591a\u65e0\u4eba\u673a\u573a\u666f\u4e2d\u5bfc\u81f4\u98de\u884c\u8def\u5f84\u5197\u4f59\u3001\u822a\u5411\u9891\u7e41\u7a81\u53d8\uff0c\u4e14\u5728\u907f\u969c\u8fc7\u7a0b\u4e2d\u6781\u6613\u53d1\u751f\u65e0\u4eba\u673a\u95f4\u78b0\u649e\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u63d0\u5347\u8def\u5f84\u89c4\u5212\u548c\u907f\u969c\u6548\u679c\u3002", "method": "\u96c6\u6210MRF IAPF\u7684\u4e09\u79cd\u76f8\u4e92\u4f5c\u7528\u529b\uff08\u969c\u788d\u7269\u65a5\u529b\u3001\u65e0\u4eba\u673a\u95f4\u4f5c\u7528\u529b\u3001\u76ee\u6807\u5f15\u529b\uff09\uff0c\u5e76\u52a0\u5165\u6539\u8fdb\u7684\u5355\u65e0\u4eba\u673a\u8def\u5f84\u4f18\u5316\u673a\u5236\uff0c\u5305\u62ec\u78b0\u649e\u98ce\u9669\u8bc4\u4f30\u548c\u8f85\u52a9\u5b50\u76ee\u6807\u7b56\u7565\uff0c\u5728\u78b0\u649e\u5a01\u80c1\u9ad8\u65f6\u751f\u6210\u4e34\u65f6\u822a\u70b9\u5f15\u5bfc\u907f\u969c\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edfAPF\u7f16\u961f\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u8def\u5f84\u957f\u5ea6\u4f18\u5316\u548c\u822a\u5411\u7a33\u5b9a\u6027\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u80fd\u6709\u6548\u907f\u969c\u5e76\u5feb\u901f\u6062\u590d\u7f16\u961f\u6784\u578b\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u5728\u672a\u77e5\u969c\u788d\u7269\u9759\u6001\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u591a\u65e0\u4eba\u673a\u7f16\u961f\u907f\u969c\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2511.16842", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16842", "abs": "https://arxiv.org/abs/2511.16842", "authors": ["Sang Truong", "Yuheng Tu", "Michael Hardy", "Anka Reuel", "Zeyu Tang", "Jirayu Burapacheep", "Jonathan Perera", "Chibuike Uwakwe", "Ben Domingue", "Nick Haber", "Sanmi Koyejo"], "title": "Fantastic Bugs and Where to Find Them in AI Benchmarks", "comment": null, "summary": "Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u54cd\u5e94\u6a21\u5f0f\u7edf\u8ba1\u5206\u6790\u6765\u8bc6\u522b\u65e0\u6548\u57fa\u51c6\u95ee\u9898\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u5ba1\u67e5\u548cLLM\u8f85\u52a9\u5ba1\u67e5\u63d0\u9ad8\u57fa\u51c6\u53ef\u9760\u6027", "motivation": "\u57fa\u51c6\u6d4b\u8bd5\u5bf9AI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u65e0\u6548\u7684\u57fa\u51c6\u95ee\u9898\u4f1a\u7834\u574f\u5176\u53ef\u9760\u6027\u3002\u624b\u52a8\u8bc6\u522b\u548c\u4fee\u6b63\u6570\u5343\u4e2a\u57fa\u51c6\u95ee\u9898\u4e0d\u53ef\u884c\uff0c\u6210\u4e3a\u53ef\u9760\u8bc4\u4f30\u7684\u5173\u952e\u74f6\u9888", "method": "\u57fa\u4e8e\u54cd\u5e94\u6a21\u5f0f\u7edf\u8ba1\u5206\u6790\uff0c\u5047\u8bbe\u5e73\u5747\u5206\u80fd\u5145\u5206\u603b\u7ed3\u6a21\u578b\u6027\u80fd\uff0c\u6784\u5efa\u5355\u7ef4\u6f5c\u5728\u7ed3\u6784\u3002\u5f53\u9879\u76ee\u7684\u7edf\u8ba1\u503c\u8d85\u51fa\u9884\u671f\u8303\u56f4\u65f6\uff0c\u6807\u8bb0\u4e3a\u6f5c\u5728\u95ee\u9898\uff0c\u7ed3\u5408\u4e13\u5bb6\u5ba1\u67e5\u548cLLM\u8f85\u52a9\u5ba1\u67e5", "result": "\u57289\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6307\u5bfc\u4e13\u5bb6\u5ba1\u67e5\u8bc6\u522b\u95ee\u9898\u95ee\u9898\u7684\u7cbe\u5ea6\u9ad8\u8fbe84%\uff0cLLM\u8f85\u52a9\u5ba1\u67e5\u8fdb\u4e00\u6b65\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7cfb\u7edf\u5316\u57fa\u51c6\u4fee\u8ba2\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u53ef\u9760\u6027"}}
{"id": "2511.17017", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17017", "abs": "https://arxiv.org/abs/2511.17017", "authors": ["Elisabeth Vogel", "Peter Langend\u00f6rfer"], "title": "Continuous Resilience in Cyber-Physical Systems of Systems: Extending Architectural Models through Adaptive Coordination and Learning", "comment": "27 pages, 6 tables, 1 figure", "summary": "Cyber-physical systems of systems (CPSoS) are highly complex, dynamic environments in which technical, cybernetic and organisational subsystems interact closely with one another. Dynamic, continuously adaptable resilience is required to ensure their functionality under variable conditions. However, existing resilience architectures usually only deal with adaptation implicitly and thus remain predominantly static. This paper addresses this gap by introducing a new Adaptive Coordination Layer (ACL) and conceptually redefining the Adaptation & Learning Layer (AL). The ACL acts as an operational control layer that detects risks in real time, prioritises countermeasures and coordinates them dynamically. The AL is reinterpreted as a strategic-cooperative layer that evaluates the operational decisions of the ACL, learns from them, and derives long-term adjustments at the policy, governance, and architecture levels. Together, both layers operationalise the resilience principle of adaptation and combine short-term responsiveness with long-term learning and development capabilities. The paper describes various implementation variants of both levels - from rule-based and KPI-driven approaches to AI-supported and meta-learning mechanisms - and shows how these can be combined depending on system complexity, data availability and degree of regulation. The proposed architecture model no longer understands resilience as a static system property, but as a continuous, data-driven process of mutual coordination and systemic learning. This creates a methodological basis for the next generation of adaptive and resilient CPSoS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u534f\u8c03\u5c42(ACL)\u548c\u91cd\u65b0\u5b9a\u4e49\u7684\u81ea\u9002\u5e94\u4e0e\u5b66\u4e60\u5c42(AL)\u67b6\u6784\uff0c\u7528\u4e8e\u5b9e\u73b0\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u7cfb\u7edf\u7684\u52a8\u6001\u5f39\u6027\u3002ACL\u8d1f\u8d23\u5b9e\u65f6\u98ce\u9669\u68c0\u6d4b\u548c\u534f\u8c03\u5e94\u5bf9\u63aa\u65bd\uff0cAL\u5219\u8fdb\u884c\u6218\u7565\u8bc4\u4f30\u548c\u957f\u671f\u5b66\u4e60\uff0c\u4e24\u8005\u7ed3\u5408\u5b9e\u73b0\u4e86\u77ed\u671f\u54cd\u5e94\u4e0e\u957f\u671f\u53d1\u5c55\u7684\u7edf\u4e00\u3002", "motivation": "\u73b0\u6709\u5f39\u6027\u67b6\u6784\u901a\u5e38\u53ea\u9690\u542b\u5904\u7406\u9002\u5e94\u6027\u95ee\u9898\uff0c\u4e3b\u8981\u4fdd\u6301\u9759\u6001\u7279\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3CPSoS\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9700\u6c42\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6301\u7eed\u9002\u5e94\u53d8\u5316\u7684\u52a8\u6001\u5f39\u6027\u673a\u5236\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u534f\u8c03\u5c42(ACL)\u4f5c\u4e3a\u64cd\u4f5c\u63a7\u5236\u5c42\uff0c\u8d1f\u8d23\u5b9e\u65f6\u98ce\u9669\u68c0\u6d4b\u3001\u4f18\u5148\u7ea7\u6392\u5e8f\u548c\u52a8\u6001\u534f\u8c03\uff1b\u91cd\u65b0\u5b9a\u4e49\u81ea\u9002\u5e94\u4e0e\u5b66\u4e60\u5c42(AL)\u4f5c\u4e3a\u6218\u7565\u534f\u4f5c\u5c42\uff0c\u8bc4\u4f30ACL\u51b3\u7b56\u5e76\u5b66\u4e60\u957f\u671f\u8c03\u6574\u7b56\u7565\u3002\u63d0\u4f9b\u4e86\u4ece\u89c4\u5219\u57fa\u7840\u5230AI\u652f\u6301\u7684\u591a\u79cd\u5b9e\u73b0\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u7684\u67b6\u6784\u6a21\u578b\u5c06\u5f39\u6027\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6301\u7eed\u7684\u6570\u636e\u9a71\u52a8\u8fc7\u7a0b\uff0c\u7ed3\u5408\u4e86\u76f8\u4e92\u534f\u8c03\u548c\u7cfb\u7edf\u5b66\u4e60\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u9002\u5e94\u5f39\u6027CPSoS\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e0d\u518d\u5c06\u5f39\u6027\u89c6\u4e3a\u9759\u6001\u7cfb\u7edf\u5c5e\u6027\uff0c\u800c\u662f\u4f5c\u4e3a\u6301\u7eed\u7684\u6570\u636e\u9a71\u52a8\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\u77ed\u671f\u54cd\u5e94\u80fd\u529b\u4e0e\u957f\u671f\u5b66\u4e60\u53d1\u5c55\u80fd\u529b\u7684\u7ed3\u5408\uff0c\u4e3a\u6784\u5efa\u66f4\u9002\u5e94\u590d\u6742\u73af\u5883\u7684CPSoS\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17148", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.17148", "abs": "https://arxiv.org/abs/2511.17148", "authors": ["David Solano", "Marta Solans", "Xavier Perafita", "Anna Ruiz-Comellas", "Marc Saez", "Maria A. Barcel\u00f3"], "title": "A spatiotemporal Bayesian hierarchical model of heat-related mortality in Catalonia, Spain (2012--2022): The role of environmental and socioeconomic modifiers", "comment": null, "summary": "Background: Extreme heat is a major public health risk, yet its relationship with mortality may be confounded or modified by air pollution and social determinants. Objectives: We aimed to quantify the effects of extreme maximum temperatures and heatwaves on daily mortality in Catalonia (2012--2022), and to assess the modifying and confounding roles of air pollutants and socioeconomic factors. Methods: We conducted a time--series ecological study across 379 basic health areas (ABS) during summer months. Mortality data from the Spanish National Statistics Institute were linked with meteorological and air pollution data. A hierarchical Bayesian spatiotemporal model, incorporating structured and unstructured random effects, was used to account for spatial and temporal dependencies, as well as observed socioeconomic confounders. Results: In total, 730,634 deaths occurred, with 216,989 in summer. Extreme heat alone was not independently associated with mortality, as its effect was fully confounded by high ozone levels and partly by socioeconomic indicators. Ozone concentrations ($\\ge 120 \u03bcg/m^3$) significantly increased mortality risk, especially among individuals aged $\\ge 85$ years. Greater income inequality and higher proportions of older residents also amplified vulnerability. Conclusion: Mortality risks from extreme heat in Catalonia were strongly influenced by ozone levels and social determinants. Adaptation strategies should address both compound environmental exposures together with socioeconomic vulnerability to better protect older and disadvantaged populations.", "AI": {"tldr": "\u6781\u7aef\u9ad8\u6e29\u672c\u8eab\u4e0e\u6b7b\u4ea1\u7387\u65e0\u72ec\u7acb\u5173\u8054\uff0c\u5176\u5f71\u54cd\u5b8c\u5168\u88ab\u9ad8\u81ed\u6c27\u6c34\u5e73\u6df7\u6dc6\uff0c\u90e8\u5206\u88ab\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u6df7\u6dc6\u3002\u81ed\u6c27\u6d53\u5ea6\u2265120\u03bcg/m\u00b3\u663e\u8457\u589e\u52a0\u6b7b\u4ea1\u98ce\u9669\uff0c\u7279\u522b\u662f85\u5c81\u4ee5\u4e0a\u4eba\u7fa4\u3002\u6536\u5165\u4e0d\u5e73\u7b49\u548c\u8001\u5e74\u4eba\u53e3\u6bd4\u4f8b\u589e\u52a0\u8106\u5f31\u6027\u3002", "motivation": "\u7814\u7a76\u6781\u7aef\u9ad8\u6e29\u4e0e\u6b7b\u4ea1\u7387\u7684\u5173\u7cfb\uff0c\u8bc4\u4f30\u7a7a\u6c14\u6c61\u67d3\u7269\u548c\u793e\u4f1a\u7ecf\u6d4e\u56e0\u7d20\u7684\u6df7\u6dc6\u548c\u4fee\u9970\u4f5c\u7528\uff0c\u4e3a\u5236\u5b9a\u66f4\u6709\u6548\u7684\u516c\u5171\u536b\u751f\u5e72\u9884\u63aa\u65bd\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u5728\u52a0\u6cf0\u7f57\u5c3c\u4e9a379\u4e2a\u57fa\u672c\u536b\u751f\u533a\u57df\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u751f\u6001\u5b66\u7814\u7a76\uff082012-2022\u5e74\u590f\u5b63\uff09\u3002\u4f7f\u7528\u5206\u5c42\u8d1d\u53f6\u65af\u65f6\u7a7a\u6a21\u578b\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u968f\u673a\u6548\u5e94\uff0c\u8003\u8651\u7a7a\u95f4\u548c\u65f6\u95f4\u4f9d\u8d56\u6027\u4ee5\u53ca\u793e\u4f1a\u7ecf\u6d4e\u6df7\u6742\u56e0\u7d20\u3002", "result": "\u5171\u8bb0\u5f55730,634\u4f8b\u6b7b\u4ea1\uff0c\u5176\u4e2d216,989\u4f8b\u53d1\u751f\u5728\u590f\u5b63\u3002\u6781\u7aef\u9ad8\u6e29\u672c\u8eab\u65e0\u72ec\u7acb\u5173\u8054\uff0c\u5176\u5f71\u54cd\u88ab\u81ed\u6c27\u6c34\u5e73\u5b8c\u5168\u6df7\u6dc6\uff0c\u90e8\u5206\u88ab\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u6df7\u6dc6\u3002\u81ed\u6c27\u6d53\u5ea6\u2265120\u03bcg/m\u00b3\u663e\u8457\u589e\u52a0\u6b7b\u4ea1\u98ce\u9669\uff0c\u7279\u522b\u662f85\u5c81\u4ee5\u4e0a\u4eba\u7fa4\u3002\u6536\u5165\u4e0d\u5e73\u7b49\u548c\u8001\u5e74\u4eba\u53e3\u6bd4\u4f8b\u589e\u52a0\u8106\u5f31\u6027\u3002", "conclusion": "\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u6781\u7aef\u9ad8\u6e29\u7684\u6b7b\u4ea1\u98ce\u9669\u53d7\u5230\u81ed\u6c27\u6c34\u5e73\u548c\u793e\u4f1a\u56e0\u7d20\u7684\u5f3a\u70c8\u5f71\u54cd\u3002\u9002\u5e94\u7b56\u7565\u5e94\u540c\u65f6\u89e3\u51b3\u590d\u5408\u73af\u5883\u66b4\u9732\u548c\u793e\u4f1a\u7ecf\u6d4e\u8106\u5f31\u6027\uff0c\u4ee5\u66f4\u597d\u5730\u4fdd\u62a4\u8001\u5e74\u548c\u5f31\u52bf\u4eba\u7fa4\u3002"}}
{"id": "2511.17179", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.17179", "abs": "https://arxiv.org/abs/2511.17179", "authors": ["Min-Kyu Kim", "Tae-An Yoo", "Ji-Bum Chung"], "title": "Toward Sustainable Generative AI: A Scoping Review of Carbon Footprint and Environmental Impacts Across Training and Inference Stages", "comment": "43 pages, 5 figure, 3 tables", "summary": "Generative AI is spreading rapidly, creating significant social and economic value while also raising concerns about its high energy use and environmental sustainability. While prior studies have predominantly focused on the energy-intensive nature of the training phase, the cumulative environmental footprint generated during large-scale service operations, particularly in the inference phase, has received comparatively less attention. To bridge this gap this study conducts a scoping review of methodologies and research trends in AI carbon footprint assessment. We analyze the classification and standardization status of existing AI carbon measurement tools and methodologies, and comparatively examine the environmental impacts arising from both training and inference stages. In addition, we identify how multidimensional factors such as model size, prompt complexity, serving environments, and system boundary definitions shape the resulting carbon footprint. Our review reveals critical limitations in current AI carbon accounting practices, including methodological inconsistencies, technology-specific biases, and insufficient attention to end-to-end system perspectives. Building on these insights, we propose future research and governance directions: (1) establishing standardized and transparent universal measurement protocols, (2) designing dynamic evaluation frameworks that incorporate user behavior, (3) developing life-cycle monitoring systems that encompass embodied emissions, and (4) advancing multidimensional sustainability assessment framework that balance model performance with environmental efficiency. This paper provides a foundation for interdisciplinary dialogue aimed at building a sustainable AI ecosystem and offers a baseline guideline for researchers seeking to understand the environmental implications of AI across technical, social, and operational dimensions.", "AI": {"tldr": "\u672c\u6587\u5bf9AI\u78b3\u8db3\u8ff9\u8bc4\u4f30\u65b9\u6cd5\u8fdb\u884c\u7efc\u8ff0\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u63a8\u7406\u9636\u6bb5\u7684\u78b3\u6392\u653e\uff0c\u6307\u51fa\u5f53\u524d\u6d4b\u91cf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u6807\u51c6\u5316\u6d4b\u91cf\u534f\u8bae\u3001\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u5de8\u5927\u4ef7\u503c\uff0c\u4f46\u5176\u9ad8\u80fd\u8017\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8bad\u7ec3\u9636\u6bb5\u80fd\u8017\uff0c\u800c\u5bf9\u5927\u89c4\u6a21\u670d\u52a1\u8fd0\u8425\u4e2d\u63a8\u7406\u9636\u6bb5\u7684\u7d2f\u79ef\u73af\u5883\u8db3\u8ff9\u5173\u6ce8\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u8303\u56f4\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u73b0\u6709AI\u78b3\u6d4b\u91cf\u5de5\u5177\u548c\u65b9\u6cd5\u7684\u5206\u7c7b\u4e0e\u6807\u51c6\u5316\u72b6\u51b5\uff0c\u6bd4\u8f83\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u7684\u73af\u5883\u5f71\u54cd\uff0c\u8bc6\u522b\u6a21\u578b\u89c4\u6a21\u3001\u63d0\u793a\u590d\u6742\u5ea6\u7b49\u591a\u7ef4\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5f53\u524dAI\u78b3\u6838\u7b97\u5b9e\u8df5\u5b58\u5728\u65b9\u6cd5\u4e0d\u4e00\u81f4\u3001\u6280\u672f\u7279\u5b9a\u504f\u89c1\u3001\u7f3a\u4e4f\u7aef\u5230\u7aef\u7cfb\u7edf\u89c6\u89d2\u7b49\u5173\u952e\u5c40\u9650\u3002\u4e0d\u540c\u56e0\u7d20\u5bf9\u78b3\u8db3\u8ff9\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u5efa\u7acb\u6807\u51c6\u5316\u6d4b\u91cf\u534f\u8bae\u3001\u8bbe\u8ba1\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\u3001\u5f00\u53d1\u751f\u547d\u5468\u671f\u76d1\u6d4b\u7cfb\u7edf\u3001\u63a8\u8fdb\u591a\u7ef4\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u6846\u67b6\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u6784\u5efa\u53ef\u6301\u7eedAI\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2511.16949", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.16949", "abs": "https://arxiv.org/abs/2511.16949", "authors": ["Junseo Kim", "Guido Dumont", "Xinyu Gao", "Gang Chen", "Holger Caesar", "Javier Alonso-Mora"], "title": "MobileOcc: A Human-Aware Semantic Occupancy Dataset for Mobile Robots", "comment": null, "summary": "Dense 3D semantic occupancy perception is critical for mobile robots operating in pedestrian-rich environments, yet it remains underexplored compared to its application in autonomous driving. To address this gap, we present MobileOcc, a semantic occupancy dataset for mobile robots operating in crowded human environments. Our dataset is built using an annotation pipeline that incorporates static object occupancy annotations and a novel mesh optimization framework explicitly designed for human occupancy modeling. It reconstructs deformable human geometry from 2D images and subsequently refines and optimizes it using associated LiDAR point data. Using MobileOcc, we establish benchmarks for two tasks, i) Occupancy prediction and ii) Pedestrian velocity prediction, using different methods including monocular, stereo, and panoptic occupancy, with metrics and baseline implementations for reproducible comparison. Beyond occupancy prediction, we further assess our annotation method on 3D human pose estimation datasets. Results demonstrate that our method exhibits robust performance across different datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86MobileOcc\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u79fb\u52a8\u673a\u5668\u4eba\u5728\u62e5\u6324\u4eba\u7c7b\u73af\u5883\u4e2d\u7684\u8bed\u4e49\u5360\u7528\u611f\u77e5\uff0c\u5305\u542b\u9759\u6001\u7269\u4f53\u548c\u4eba\u7c7b\u5360\u7528\u6807\u6ce8\uff0c\u5e76\u5efa\u7acb\u4e86\u5360\u7528\u9884\u6d4b\u548c\u884c\u4eba\u901f\u5ea6\u9884\u6d4b\u7684\u57fa\u51c6\u3002", "motivation": "\u5bc6\u96c63D\u8bed\u4e49\u5360\u7528\u611f\u77e5\u5728\u79fb\u52a8\u673a\u5668\u4eba\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728\u884c\u4eba\u5bc6\u96c6\u73af\u5883\u4e2d\uff0c\u9700\u8981\u4e13\u95e8\u7684\u6570\u636e\u96c6\u6765\u652f\u6301\u76f8\u5173\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u9759\u6001\u7269\u4f53\u5360\u7528\u6807\u6ce8\u548c\u4e13\u95e8\u7528\u4e8e\u4eba\u7c7b\u5360\u7528\u5efa\u6a21\u7684\u7f51\u683c\u4f18\u5316\u6846\u67b6\u7684\u6807\u6ce8\u6d41\u7a0b\uff0c\u4ece2D\u56fe\u50cf\u91cd\u5efa\u53ef\u53d8\u5f62\u4eba\u4f53\u51e0\u4f55\uff0c\u5e76\u4f7f\u7528LiDAR\u70b9\u4e91\u6570\u636e\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5efa\u7acb\u4e86\u5360\u7528\u9884\u6d4b\u548c\u884c\u4eba\u901f\u5ea6\u9884\u6d4b\u7684\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e86\u5355\u76ee\u3001\u7acb\u4f53\u548c\u5168\u666f\u5360\u7528\u7b49\u65b9\u6cd5\uff0c\u5e76\u57283D\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6807\u6ce8\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684MobileOcc\u6570\u636e\u96c6\u548c\u6807\u6ce8\u65b9\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u7a33\u5065\u6027\u80fd\uff0c\u4e3a\u79fb\u52a8\u673a\u5668\u4eba\u8bed\u4e49\u5360\u7528\u611f\u77e5\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2511.16916", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16916", "abs": "https://arxiv.org/abs/2511.16916", "authors": ["Ye Han", "Lijun Zhang", "Dejian Meng", "Zhuang Zhang"], "title": "Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving", "comment": null, "summary": "In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u5dee\u5206\u5956\u52b1\u673a\u5236\u89e3\u51b3\u591a\u8f66\u8f86\u534f\u540c\u9a7e\u9a76\u4e2d\u4f20\u7edf\u5956\u52b1\u51fd\u6570\u56e0\u5956\u52b1\u5dee\u5f02\u6d88\u5931\u5bfc\u81f4\u7684\u6536\u655b\u95ee\u9898\uff0c\u901a\u8fc7\u65f6\u95f4\u5dee\u5206\u5956\u52b1\u548c\u52a8\u4f5c\u68af\u5ea6\u5956\u52b1\u63d0\u4f9b\u9ad8\u4fe1\u566a\u6bd4\u4fe1\u53f7\uff0c\u663e\u8457\u63d0\u5347\u7b97\u6cd5\u6536\u655b\u901f\u5ea6\u548c\u7b56\u7565\u7a33\u5b9a\u6027\u3002", "motivation": "\u591a\u8f66\u8f86\u534f\u540c\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0c\u4f20\u7edf\u57fa\u4e8e\u72b6\u6001\u7684\u5956\u52b1\u51fd\u6570\u5b58\u5728\u5956\u52b1\u5dee\u5f02\u6d88\u5931\u95ee\u9898\uff0c\u5bfc\u81f4\u7b56\u7565\u68af\u5ea6\u7684\u4fe1\u566a\u6bd4\u4f4e\uff0c\u4e25\u91cd\u5f71\u54cd\u7b97\u6cd5\u6536\u655b\u548c\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u5dee\u5206\u5956\u52b1\u673a\u5236\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u5168\u5c40\u52bf\u51fd\u6570\u7684\u65f6\u95f4\u5dee\u5206\u5956\u52b1\uff0c\u5229\u7528\u52bf\u80fd\u6f14\u5316\u8d8b\u52bf\u786e\u4fdd\u6700\u4f18\u7b56\u7565\u4e0d\u53d8\u6027\u548c\u957f\u671f\u76ee\u6807\u4e00\u81f4\u6027\uff1b\u52a8\u4f5c\u68af\u5ea6\u5956\u52b1\u76f4\u63a5\u8861\u91cf\u52a8\u4f5c\u7684\u8fb9\u9645\u6548\u7528\uff0c\u63d0\u4f9b\u9ad8\u4fe1\u566a\u6bd4\u7684\u5c40\u90e8\u6307\u5bfc\u4fe1\u53f7\u3002", "result": "\u5728\u5728\u7ebf\u89c4\u5212\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cHDR\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u6536\u655b\u901f\u5ea6\u548c\u7b56\u7565\u7a33\u5b9a\u6027\uff0c\u5f15\u5bfc\u667a\u80fd\u4f53\u5b66\u4e60\u5230\u5e73\u8861\u4ea4\u901a\u6548\u7387\u548c\u5b89\u5168\u7684\u9ad8\u8d28\u91cf\u534f\u540c\u7b56\u7565\u3002", "conclusion": "HDR\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f66\u8f86\u534f\u540c\u9a7e\u9a76\u4e2d\u7684\u5956\u52b1\u4fe1\u53f7\u95ee\u9898\uff0c\u4e3a\u9ad8\u9891\u7387\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5956\u52b1\u8bbe\u8ba1\u6846\u67b6\u3002"}}
{"id": "2511.17025", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17025", "abs": "https://arxiv.org/abs/2511.17025", "authors": ["Michael Ruderman", "Elia Brescia", "Luigi P. Savastio", "Paolo R. Massenio", "David Naso", "Giuseppe L. Cascella"], "title": "Comparison of linear observation techniques for robust load torque estimation in actuators", "comment": "6 pages, 5 figures", "summary": "The paper addresses the problem of estimating robustly the external load torque in rotary actuator systems, when only the generated motor drive torque and angular displacement are the available input and output. We compare, theoretically and experimentally, two sufficiently established linear observation techniques (i) reduced-order Luenberger observer and (ii) disturbance observer, both using the same identified model of a permanent magnet synchronous motor (PMSM)-based actuator. Our goal is to highlight several aspects related to the implementation, relative degree of the input-torque to estimated-load-torque transfer characteristics, observer open-loop transfer function, and the associated sensitivity (respectively stability margins) with respect to inherently uncertain system plants. Apart from the developed analysis, a detailed experimental case study is demonstrated where the load torque sensor provides reference measurements and allows for evaluation of both observers.", "AI": {"tldr": "\u6bd4\u8f83\u4e24\u79cd\u7ebf\u6027\u89c2\u6d4b\u5668\uff08\u964d\u9636Luenberger\u89c2\u6d4b\u5668\u548c\u6270\u52a8\u89c2\u6d4b\u5668\uff09\u5728\u4ec5\u4f7f\u7528\u7535\u673a\u9a71\u52a8\u626d\u77e9\u548c\u89d2\u4f4d\u79fb\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u65cb\u8f6c\u6267\u884c\u5668\u7cfb\u7edf\u5916\u90e8\u8d1f\u8f7d\u626d\u77e9\u7684\u9c81\u68d2\u4f30\u8ba1\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u4ec5\u6709\u7535\u673a\u9a71\u52a8\u626d\u77e9\u548c\u89d2\u4f4d\u79fb\u4f5c\u4e3a\u8f93\u5165\u8f93\u51fa\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u9c81\u68d2\u5730\u4f30\u8ba1\u65cb\u8f6c\u6267\u884c\u5668\u7cfb\u7edf\u7684\u5916\u90e8\u8d1f\u8f7d\u626d\u77e9\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6c38\u78c1\u540c\u6b65\u7535\u673a\u6267\u884c\u5668\u7684\u76f8\u540c\u8fa8\u8bc6\u6a21\u578b\uff0c\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u6bd4\u8f83\u964d\u9636Luenberger\u89c2\u6d4b\u5668\u548c\u6270\u52a8\u89c2\u6d4b\u5668\u4e24\u79cd\u7ebf\u6027\u89c2\u6d4b\u6280\u672f\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u6848\u4f8b\u7814\u7a76\uff0c\u5229\u7528\u8d1f\u8f7d\u626d\u77e9\u4f20\u611f\u5668\u63d0\u4f9b\u53c2\u8003\u6d4b\u91cf\uff0c\u8bc4\u4f30\u4e86\u4e24\u79cd\u89c2\u6d4b\u5668\u7684\u6027\u80fd\u3002", "conclusion": "\u91cd\u70b9\u5206\u6790\u4e86\u4e24\u79cd\u89c2\u6d4b\u5668\u5728\u5b9e\u73b0\u3001\u8f93\u5165\u626d\u77e9\u5230\u4f30\u8ba1\u8d1f\u8f7d\u626d\u77e9\u4f20\u9012\u7279\u6027\u7684\u76f8\u5bf9\u9636\u6570\u3001\u89c2\u6d4b\u5668\u5f00\u73af\u4f20\u9012\u51fd\u6570\u4ee5\u53ca\u4e0e\u56fa\u6709\u4e0d\u786e\u5b9a\u7cfb\u7edf\u76f8\u5173\u7684\u7075\u654f\u5ea6\uff08\u7a33\u5b9a\u6027\u88d5\u5ea6\uff09\u7b49\u65b9\u9762\u7684\u5dee\u5f02\u3002"}}
{"id": "2511.17182", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.17182", "abs": "https://arxiv.org/abs/2511.17182", "authors": ["H. R. Paz"], "title": "The Promotion Wall: Efficiency-Equity Trade-offs of Direct Promotion Regimes in Engineering Education", "comment": "42 pages, 4 figures, 3 tables", "summary": "Progression and assessment rules are often treated as administrative details, yet they fundamentally shape who is allowed to remain in higher education, and on what terms. This article uses a calibrated agent-based model to examine how alternative progression regimes reconfigure dropout, time-to-degree, equity and students' psychological experience in a long, tightly sequenced engineering programme. Building on a leakage-aware longitudinal dataset of 1,343 students and a Kaplan-Meier survival analysis of time-to-dropout, we simulate three policy scenarios: (A) a historical \"regularity + finals\" regime, where students accumulate exam debt; (B) a direct-promotion regime that removes regularity and finals but requires full course completion each term; and (C) a direct-promotion regime complemented by a capacity-limited remedial \"safety net\" for marginal failures in bottleneck courses. The model is empirically calibrated to reproduce the observed dropout curve under Scenario A and then used to explore counterfactuals. Results show that direct promotion creates a \"promotion wall\": attrition becomes sharply front-loaded in the first two years, overall dropout rises, and equity gaps between low- and high-resilience students widen, even as exam debt disappears. The safety-net scenario partially dismantles this wall: it reduces dropout and equity gaps relative to pure direct promotion and yields the lowest final stress levels, at the cost of additional, targeted teaching capacity. These findings position progression rules as central objects of assessment policy rather than neutral background. The article argues that claims of improved efficiency are incomplete unless they are evaluated jointly with inclusion, equity and students' psychological wellbeing, and it illustrates how simulation-based decision support can help institutions rehearse assessment reforms before implementing them.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u578b\u5206\u6790\u4e09\u79cd\u5b66\u4e1a\u8fdb\u5ea6\u5236\u5ea6\u5bf9\u5de5\u7a0b\u4e13\u4e1a\u5b66\u751f\u8f8d\u5b66\u7387\u3001\u6bd5\u4e1a\u65f6\u95f4\u3001\u516c\u5e73\u6027\u548c\u5fc3\u7406\u4f53\u9a8c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u76f4\u63a5\u664b\u5347\u5236\u5ea6\u4f1a\u5f62\u6210\"\u664b\u5347\u5899\"\uff0c\u589e\u52a0\u8f8d\u5b66\u7387\u548c\u516c\u5e73\u5dee\u8ddd\uff0c\u800c\u5e26\u6709\u5b89\u5168\u7f51\u673a\u5236\u7684\u76f4\u63a5\u664b\u5347\u80fd\u90e8\u5206\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u5b66\u4e1a\u8fdb\u5ea6\u89c4\u5219\u901a\u5e38\u88ab\u89c6\u4e3a\u884c\u653f\u7ec6\u8282\uff0c\u4f46\u5b9e\u9645\u4e0a\u5b83\u4eec\u4ece\u6839\u672c\u4e0a\u51b3\u5b9a\u4e86\u8c01\u80fd\u591f\u7ee7\u7eed\u7559\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u4ee5\u53ca\u4ee5\u4f55\u79cd\u6761\u4ef6\u7ee7\u7eed\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u4e0d\u540c\u8fdb\u5ea6\u5236\u5ea6\u5982\u4f55\u91cd\u65b0\u914d\u7f6e\u8f8d\u5b66\u7387\u3001\u6bd5\u4e1a\u65f6\u95f4\u3001\u516c\u5e73\u6027\u548c\u5b66\u751f\u5fc3\u7406\u4f53\u9a8c\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e1,343\u540d\u5b66\u751f\u6570\u636e\u7684\u6821\u51c6\u4ee3\u7406\u6a21\u578b\uff0c\u6a21\u62df\u4e09\u79cd\u653f\u7b56\u60c5\u666f\uff1a\u5386\u53f2\"\u89c4\u5f8b\u6027+\u671f\u672b\u8003\u8bd5\"\u5236\u5ea6\u3001\u76f4\u63a5\u664b\u5347\u5236\u5ea6\u3001\u4ee5\u53ca\u5e26\u6709\u5b89\u5168\u7f51\u673a\u5236\u7684\u76f4\u63a5\u664b\u5347\u5236\u5ea6\u3002\u6a21\u578b\u7ecf\u8fc7\u7ecf\u9a8c\u6821\u51c6\u4ee5\u91cd\u73b0\u89c2\u5bdf\u5230\u7684\u8f8d\u5b66\u66f2\u7ebf\u3002", "result": "\u76f4\u63a5\u664b\u5347\u5236\u5ea6\u5f62\u6210\"\u664b\u5347\u5899\"\uff0c\u5bfc\u81f4\u524d\u4e24\u5e74\u8f8d\u5b66\u7387\u6025\u5267\u4e0a\u5347\uff0c\u603b\u4f53\u8f8d\u5b66\u7387\u589e\u52a0\uff0c\u4f4e\u97e7\u6027\u4e0e\u9ad8\u97e7\u6027\u5b66\u751f\u4e4b\u95f4\u7684\u516c\u5e73\u5dee\u8ddd\u6269\u5927\u3002\u5e26\u6709\u5b89\u5168\u7f51\u673a\u5236\u7684\u76f4\u63a5\u664b\u5347\u80fd\u51cf\u5c11\u8f8d\u5b66\u7387\u548c\u516c\u5e73\u5dee\u8ddd\uff0c\u5e76\u4ea7\u751f\u6700\u4f4e\u7684\u6700\u7ec8\u538b\u529b\u6c34\u5e73\uff0c\u4f46\u9700\u8981\u989d\u5916\u7684\u9488\u5bf9\u6027\u6559\u5b66\u8d44\u6e90\u3002", "conclusion": "\u5b66\u4e1a\u8fdb\u5ea6\u89c4\u5219\u5e94\u88ab\u89c6\u4e3a\u8bc4\u4f30\u653f\u7b56\u7684\u6838\u5fc3\u5bf9\u8c61\u800c\u975e\u4e2d\u6027\u80cc\u666f\u3002\u6539\u8fdb\u6548\u7387\u7684\u4e3b\u5f20\u5fc5\u987b\u4e0e\u5305\u5bb9\u6027\u3001\u516c\u5e73\u6027\u548c\u5b66\u751f\u5fc3\u7406\u5065\u5eb7\u5171\u540c\u8bc4\u4f30\uff0c\u57fa\u4e8e\u6a21\u62df\u7684\u51b3\u7b56\u652f\u6301\u53ef\u4ee5\u5e2e\u52a9\u673a\u6784\u5728\u5b9e\u65bd\u8bc4\u4f30\u6539\u9769\u524d\u8fdb\u884c\u9884\u6f14\u3002"}}
{"id": "2511.17001", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17001", "abs": "https://arxiv.org/abs/2511.17001", "authors": ["Sicheng Xie", "Lingchen Meng", "Zhiying Du", "Shuyuan Tu", "Haidong Cao", "Jiaqi Leng", "Zuxuan Wu", "Yu-Gang Jiang"], "title": "Stable Offline Hand-Eye Calibration for any Robot with Just One Mark", "comment": null, "summary": "Imitation learning has achieved remarkable success in a variety of robotic tasks by learning a mapping function from camera-space observations to robot-space actions. Recent work indicates that the use of robot-to-camera transformation information ({\\ie}, camera extrinsics) benefits the learning process and produces better results. However, camera extrinsics are oftentimes unavailable and estimation methods usually suffer from local minima and poor generalizations. In this paper, we present CalibAll, a simple yet effective method that \\textbf{requires only a single mark} and performs training-free, stable, and accurate camera extrinsic estimation across diverse robots and datasets through a coarse-to-fine calibration pipeline. In particular, we annotate a single mark on an end-effector (EEF), and leverage the correspondence ability emerged from vision foundation models (VFM) to automatically localize the corresponding mark across robots in diverse datasets. Using this mark, together with point tracking and the 3D EEF trajectory, we obtain a coarse camera extrinsic via temporal Perspective-n-Point (PnP). This estimate is further refined through a rendering-based optimization that aligns rendered and ground-true masks, yielding accurate and stable camera extrinsic. Experimental results demonstrate that our method outperforms state-of-the-art approaches, showing strong robustness and general effectiveness across three robot platforms. It also produces useful auxiliary annotations such as depth maps, link-wise masks, and end-effector 2D trajectories, which can further support downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCalibAll\u7684\u7b80\u5355\u6709\u6548\u65b9\u6cd5\uff0c\u4ec5\u9700\u5355\u4e2a\u6807\u8bb0\u5373\u53ef\u5728\u591a\u79cd\u673a\u5668\u4eba\u548c\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u514d\u8bad\u7ec3\u3001\u7a33\u5b9a\u4e14\u51c6\u786e\u7684\u76f8\u673a\u5916\u53c2\u4f30\u8ba1\uff0c\u901a\u8fc7\u4ece\u7c97\u5230\u7cbe\u7684\u6821\u51c6\u6d41\u7a0b\u5b8c\u6210\u3002", "motivation": "\u6a21\u4eff\u5b66\u4e60\u5728\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u76f8\u673a\u5916\u53c2\u4fe1\u606f\u5e38\u5e38\u4e0d\u53ef\u7528\uff0c\u73b0\u6709\u7684\u4f30\u8ba1\u65b9\u6cd5\u5b58\u5728\u5c40\u90e8\u6700\u5c0f\u503c\u548c\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002", "method": "\u5728\u672b\u7aef\u6267\u884c\u5668\u4e0a\u6807\u6ce8\u5355\u4e2a\u6807\u8bb0\uff0c\u5229\u7528\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u7684\u5bf9\u5e94\u80fd\u529b\u81ea\u52a8\u5b9a\u4f4d\u6807\u8bb0\uff0c\u7ed3\u5408\u70b9\u8ddf\u8e2a\u548c3D\u672b\u7aef\u8f68\u8ff9\u901a\u8fc7\u65f6\u5e8fPnP\u83b7\u5f97\u7c97\u5916\u53c2\uff0c\u518d\u901a\u8fc7\u57fa\u4e8e\u6e32\u67d3\u7684\u4f18\u5316\u5bf9\u9f50\u6e32\u67d3\u548c\u771f\u5b9e\u63a9\u7801\u8fdb\u884c\u7cbe\u70bc\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u4e09\u4e2a\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u548c\u901a\u7528\u6709\u6548\u6027\uff0c\u5e76\u80fd\u751f\u6210\u6df1\u5ea6\u56fe\u3001\u94fe\u63a5\u7ea7\u63a9\u7801\u548c\u672b\u7aef\u6267\u884c\u56682D\u8f68\u8ff9\u7b49\u6709\u7528\u8f85\u52a9\u6807\u6ce8\u3002", "conclusion": "CalibAll\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u76f8\u673a\u5916\u53c2\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u7528\u6027\uff0c\u80fd\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\u3002"}}
{"id": "2511.16961", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16961", "abs": "https://arxiv.org/abs/2511.16961", "authors": ["Erik P. Nyberg", "Steven Mascaro", "Ingrid Zukerman", "Michael Wybrow", "Duc-Minh Vo", "Ann Nicholson"], "title": "Comparing verbal, visual and combined explanations for Bayesian Network inferences", "comment": "26 pages total, 12 pages main, 14 pages for 5 appendices", "summary": "Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of BNs. To address this problem, we have designed verbal and visual extensions to the standard BN UI, which can guide users through common inference patterns.\n  We conducted a user study to compare our verbal, visual and combined UI extensions, and a baseline UI. Our main findings are: (1) users did better with all three types of extensions than with the baseline UI for questions about the impact of an observation, the paths that enable this impact, and the way in which an observation influences the impact of other observations; and (2) using verbal and visual modalities together is better than using either modality alone for some of these question types.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u8d1d\u53f6\u65af\u7f51\u7edc\u754c\u9762\u7684\u8bed\u8a00\u548c\u89c6\u89c9\u6269\u5c55\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u53d1\u73b0\u8fd9\u4e9b\u6269\u5c55\u80fd\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u63a8\u7406\u8fc7\u7a0b\uff0c\u4e14\u8bed\u8a00\u548c\u89c6\u89c9\u7ed3\u5408\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u5c3d\u7ba1\u8d1d\u53f6\u65af\u7f51\u7edc\u88ab\u8ba4\u4e3a\u662f\u900f\u660e\u6a21\u578b\uff0c\u4f46\u7528\u6237\u4ecd\u7136\u96be\u4ee5\u7406\u89e3\u5176\u63a8\u7406\u8fc7\u7a0b\uff0c\u73b0\u6709\u7528\u6237\u754c\u9762\u672a\u80fd\u6709\u6548\u6f84\u6e05\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u63a8\u7406\u673a\u5236\u3002", "method": "\u8bbe\u8ba1\u4e86\u8bed\u8a00\u548c\u89c6\u89c9\u6269\u5c55\u6765\u589e\u5f3a\u6807\u51c6\u8d1d\u53f6\u65af\u7f51\u7edc\u754c\u9762\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u6bd4\u8f83\u4e86\u8bed\u8a00\u6269\u5c55\u3001\u89c6\u89c9\u6269\u5c55\u3001\u7ec4\u5408\u6269\u5c55\u548c\u57fa\u7ebf\u754c\u9762\u7684\u6548\u679c\u3002", "result": "\u6240\u6709\u4e09\u79cd\u6269\u5c55\u754c\u9762\u90fd\u6bd4\u57fa\u7ebf\u754c\u9762\u8868\u73b0\u66f4\u597d\uff0c\u7279\u522b\u662f\u5728\u89c2\u5bdf\u5f71\u54cd\u3001\u5f71\u54cd\u8def\u5f84\u4ee5\u53ca\u89c2\u5bdf\u95f4\u76f8\u4e92\u5f71\u54cd\u7684\u95ee\u9898\u4e0a\uff1b\u8bed\u8a00\u548c\u89c6\u89c9\u7ec4\u5408\u5728\u67d0\u4e9b\u95ee\u9898\u7c7b\u578b\u4e0a\u4f18\u4e8e\u5355\u4e00\u6a21\u6001\u3002", "conclusion": "\u8bed\u8a00\u548c\u89c6\u89c9\u6269\u5c55\u80fd\u6709\u6548\u63d0\u5347\u7528\u6237\u5bf9\u8d1d\u53f6\u65af\u7f51\u7edc\u63a8\u7406\u7684\u7406\u89e3\uff0c\u591a\u6a21\u6001\u7ec4\u5408\u65b9\u6cd5\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.17102", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17102", "abs": "https://arxiv.org/abs/2511.17102", "authors": ["Ismum Ul Hossain", "Mohammad Nahidul Islam"], "title": "KNN and Time Series Based Prediction of Power Generation from Renewable Resources", "comment": null, "summary": "As the world shifts towards utilizing natural resources for electricity generation, there is need to enhance forecasting systems to guarantee a stable electricity provision and to incorporate the generated power into the network systems. This work provides a machine learning environment for renewable energy forecasting that prevents the flaws which are usually experienced in the actual process; intermittency, nonlinearity and intricacy in nature which is difficult to grasp by ordinary existing forecasting procedures. Leveraging a comprehensive approximately 30-year dataset encompassing multiple renewable energy sources, our research evaluates two distinct approaches: K-Nearest Neighbors (KNN) model and Non-Linear Autoregressive distributed called with Seasonal Autoregressive Integrated Moving Average (SARIMA) model to forecast total power generation using the solar, wind, and hydroelectric resources. The framework uses high temporal resolution and multiple parameters of the environment to improve the predictions. The fact that both the models in terms of error metrics were equally significant and had some unique tendencies at certain circumstances. The long history allows for better model calibration of temporal fluctuations and seasonal and climatic effects on power generation. The reliability enhancement in the prediction function, which benefits from 30 years of data, has value to grid operators, energy traders, and those establishing renewable energy policies and standards concerning reliability", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u752830\u5e74\u53ef\u518d\u751f\u80fd\u6e90\u6570\u636e\uff0c\u7ed3\u5408KNN\u548cSARIMA\u6a21\u578b\u6765\u9884\u6d4b\u592a\u9633\u80fd\u3001\u98ce\u80fd\u548c\u6c34\u529b\u53d1\u7535\u7684\u603b\u53d1\u7535\u91cf\uff0c\u89e3\u51b3\u53ef\u518d\u751f\u80fd\u6e90\u9884\u6d4b\u4e2d\u7684\u95f4\u6b47\u6027\u3001\u975e\u7ebf\u6027\u548c\u590d\u6742\u6027\u6311\u6218\u3002", "motivation": "\u968f\u7740\u4e16\u754c\u8f6c\u5411\u5229\u7528\u81ea\u7136\u8d44\u6e90\u53d1\u7535\uff0c\u9700\u8981\u589e\u5f3a\u9884\u6d4b\u7cfb\u7edf\u4ee5\u786e\u4fdd\u7a33\u5b9a\u7684\u7535\u529b\u4f9b\u5e94\u5e76\u5c06\u53ef\u518d\u751f\u80fd\u6e90\u6574\u5408\u5230\u7535\u7f51\u4e2d\uff0c\u89e3\u51b3\u73b0\u6709\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7684\u95f4\u6b47\u6027\u3001\u975e\u7ebf\u6027\u548c\u590d\u6742\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5305\u542b\u592a\u9633\u80fd\u3001\u98ce\u80fd\u548c\u6c34\u529b\u53d1\u7535\u7684\u7ea630\u5e74\u7efc\u5408\u6570\u636e\u96c6\uff0c\u8bc4\u4f30K-\u6700\u8fd1\u90bb(KNN)\u6a21\u578b\u548c\u975e\u7ebf\u6027\u81ea\u56de\u5f52\u5206\u5e03\u6ede\u540e\u4e0e\u5b63\u8282\u6027\u81ea\u56de\u5f52\u79ef\u5206\u79fb\u52a8\u5e73\u5747(SARIMA)\u6a21\u578b\uff0c\u5229\u7528\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\u548c\u591a\u79cd\u73af\u5883\u53c2\u6570\u6539\u8fdb\u9884\u6d4b\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u5728\u8bef\u5dee\u6307\u6807\u4e0a\u8868\u73b0\u76f8\u5f53\uff0c\u4f46\u5728\u7279\u5b9a\u60c5\u51b5\u4e0b\u5404\u6709\u72ec\u7279\u4f18\u52bf\u3002\u957f\u671f\u5386\u53f2\u6570\u636e\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u6821\u51c6\u65f6\u95f4\u6ce2\u52a8\u4ee5\u53ca\u5b63\u8282\u548c\u6c14\u5019\u5bf9\u53d1\u7535\u7684\u5f71\u54cd\u3002", "conclusion": "\u57fa\u4e8e30\u5e74\u6570\u636e\u7684\u9884\u6d4b\u529f\u80fd\u53ef\u9760\u6027\u589e\u5f3a\u5bf9\u7535\u7f51\u8fd0\u8425\u5546\u3001\u80fd\u6e90\u4ea4\u6613\u5546\u4ee5\u53ca\u5236\u5b9a\u53ef\u518d\u751f\u80fd\u6e90\u653f\u7b56\u548c\u53ef\u9760\u6027\u6807\u51c6\u7684\u673a\u6784\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.17256", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17256", "abs": "https://arxiv.org/abs/2511.17256", "authors": ["Haijiang Liu", "Jinguang Gu", "Xun Wu", "Daniel Hershcovich", "Qiaoling Xiao"], "title": "Cross-cultural value alignment frameworks for responsible AI governance: Evidence from China-West comparative analysis", "comment": "Presented on Academic Conference \"Technology for Good: Driving Social Impact\" (2025)", "summary": "As Large Language Models (LLMs) increasingly influence high-stakes decision-making across global contexts, ensuring their alignment with diverse cultural values has become a critical governance challenge. This study presents a Multi-Layered Auditing Platform for Responsible AI that systematically evaluates cross-cultural value alignment in China-origin and Western-origin LLMs through four integrated methodologies: Ethical Dilemma Corpus for assessing temporal stability, Diversity-Enhanced Framework (DEF) for quantifying cultural fidelity, First-Token Probability Alignment for distributional accuracy, and Multi-stAge Reasoning frameworK (MARK) for interpretable decision-making. Our comparative analysis of 20+ leading models, such as Qwen, GPT-4o, Claude, LLaMA, and DeepSeek, reveals universal challenges-fundamental instability in value systems, systematic under-representation of younger demographics, and non-linear relationships between model scale and alignment quality-alongside divergent regional development trajectories. While China-origin models increasingly emphasize multilingual data integration for context-specific optimization, Western models demonstrate greater architectural experimentation but persistent U.S.-centric biases. Neither paradigm achieves robust cross-cultural generalization. We establish that Mistral-series architectures significantly outperform LLaMA3-series in cross-cultural alignment, and that Full-Parameter Fine-Tuning on diverse datasets surpasses Reinforcement Learning from Human Feedback in preserving cultural variation...", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u5c42\u6b21\u7684\u8d1f\u8d23\u4efbAI\u5ba1\u8ba1\u5e73\u53f0\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u897f\u65b9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u4ef7\u503c\u5bf9\u9f50\u60c5\u51b5\uff0c\u53d1\u73b0\u666e\u904d\u5b58\u5728\u4ef7\u503c\u7cfb\u7edf\u4e0d\u7a33\u5b9a\u3001\u5e74\u8f7b\u7fa4\u4f53\u4ee3\u8868\u6027\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u4e14\u4e2d\u897f\u65b9\u6a21\u578b\u53d1\u5c55\u8f68\u8ff9\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5168\u7403\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u5f71\u54cd\u529b\u589e\u5f3a\uff0c\u786e\u4fdd\u5176\u4e0e\u591a\u5143\u6587\u5316\u4ef7\u503c\u89c2\u5bf9\u9f50\u5df2\u6210\u4e3a\u5173\u952e\u6cbb\u7406\u6311\u6218\u3002", "method": "\u91c7\u7528\u56db\u79cd\u96c6\u6210\u65b9\u6cd5\uff1a\u4f26\u7406\u56f0\u5883\u8bed\u6599\u5e93\u8bc4\u4f30\u65f6\u95f4\u7a33\u5b9a\u6027\u3001\u591a\u6837\u6027\u589e\u5f3a\u6846\u67b6\u91cf\u5316\u6587\u5316\u4fdd\u771f\u5ea6\u3001\u9996\u8bcd\u6982\u7387\u5bf9\u9f50\u8bc4\u4f30\u5206\u5e03\u51c6\u786e\u6027\u3001\u591a\u9636\u6bb5\u63a8\u7406\u6846\u67b6\u5b9e\u73b0\u53ef\u89e3\u91ca\u51b3\u7b56\u3002", "result": "\u5206\u679020\u591a\u4e2a\u9886\u5148\u6a21\u578b\u53d1\u73b0\u666e\u904d\u6311\u6218\uff1a\u4ef7\u503c\u7cfb\u7edf\u57fa\u7840\u4e0d\u7a33\u5b9a\u3001\u5e74\u8f7b\u7fa4\u4f53\u7cfb\u7edf\u6027\u4ee3\u8868\u6027\u4e0d\u8db3\u3001\u6a21\u578b\u89c4\u6a21\u4e0e\u5bf9\u9f50\u8d28\u91cf\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u4ee5\u53ca\u533a\u57df\u53d1\u5c55\u8f68\u8ff9\u5dee\u5f02\u3002\u4e2d\u56fd\u6a21\u578b\u66f4\u6ce8\u91cd\u591a\u8bed\u8a00\u6570\u636e\u96c6\u6210\uff0c\u897f\u65b9\u6a21\u578b\u67b6\u6784\u5b9e\u9a8c\u66f4\u591a\u4f46\u5b58\u5728\u7f8e\u56fd\u4e2d\u5fc3\u504f\u89c1\u3002", "conclusion": "\u4e24\u79cd\u8303\u5f0f\u5747\u65e0\u6cd5\u5b9e\u73b0\u7a33\u5065\u7684\u8de8\u6587\u5316\u6cdb\u5316\u3002Mistral\u7cfb\u5217\u67b6\u6784\u5728\u8de8\u6587\u5316\u5bf9\u9f50\u65b9\u9762\u663e\u8457\u4f18\u4e8eLLaMA3\u7cfb\u5217\uff0c\u4e14\u5168\u53c2\u6570\u5fae\u8c03\u5728\u4fdd\u6301\u6587\u5316\u53d8\u5f02\u65b9\u9762\u4f18\u4e8e\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u3002"}}
{"id": "2511.17013", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17013", "abs": "https://arxiv.org/abs/2511.17013", "authors": ["Yiwen Ying", "Hanjing Ye", "Senzi Luo", "Luyao Liu", "Yu Zhan", "Li He", "Hong Zhang"], "title": "MfNeuPAN: Proactive End-to-End Navigation in Dynamic Environments via Direct Multi-Frame Point Constraints", "comment": "6 pages, 9 figures, accepted at IEEE ROBIO 2025", "summary": "Obstacle avoidance in complex and dynamic environments is a critical challenge for real-time robot navigation. Model-based and learning-based methods often fail in highly dynamic scenarios because traditional methods assume a static environment and cannot adapt to real-time changes, while learning-based methods rely on single-frame observations for motion constraint estimation, limiting their adaptability. To overcome these limitations, this paper proposes a novel framework that leverages multi-frame point constraints, including current and future frames predicted by a dedicated module, to enable proactive end-to-end navigation. By incorporating a prediction module that forecasts the future path of moving obstacles based on multi-frame observations, our method allows the robot to proactively anticipate and avoid potential dangers. This proactive planning capability significantly enhances navigation robustness and efficiency in unknown dynamic environments. Simulations and real-world experiments validate the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u5e27\u70b9\u7ea6\u675f\u7684\u4e3b\u52a8\u7aef\u5230\u7aef\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u6a21\u5757\u9884\u6d4b\u79fb\u52a8\u969c\u788d\u7269\u672a\u6765\u8def\u5f84\uff0c\u589e\u5f3a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5047\u8bbe\u9759\u6001\u73af\u5883\u65e0\u6cd5\u9002\u5e94\u5b9e\u65f6\u53d8\u5316\uff0c\u800c\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u4f9d\u8d56\u5355\u5e27\u89c2\u6d4b\u8fdb\u884c\u8fd0\u52a8\u7ea6\u675f\u4f30\u8ba1\uff0c\u9650\u5236\u4e86\u5728\u9ad8\u5ea6\u52a8\u6001\u573a\u666f\u4e2d\u7684\u9002\u5e94\u6027\u3002", "method": "\u4f7f\u7528\u591a\u5e27\u70b9\u7ea6\u675f\uff08\u5305\u62ec\u5f53\u524d\u5e27\u548c\u9884\u6d4b\u6a21\u5757\u9884\u6d4b\u7684\u672a\u6765\u5e27\uff09\uff0c\u7ed3\u5408\u9884\u6d4b\u6a21\u5757\u57fa\u4e8e\u591a\u5e27\u89c2\u6d4b\u9884\u6d4b\u79fb\u52a8\u969c\u788d\u7269\u672a\u6765\u8def\u5f84\uff0c\u5b9e\u73b0\u4e3b\u52a8\u89c4\u5212\u548c\u907f\u969c\u3002", "result": "\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u672a\u77e5\u52a8\u6001\u73af\u5883\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5bfc\u822a\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u5e27\u7ea6\u675f\u548c\u9884\u6d4b\u6a21\u5757\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u4e3b\u52a8\u9884\u6d4b\u548c\u907f\u514d\u6f5c\u5728\u5371\u9669\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u673a\u5668\u4eba\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.16997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16997", "abs": "https://arxiv.org/abs/2511.16997", "authors": ["Qingbin Zeng", "Bingbing Fan", "Zhiyu Chen", "Sijian Ren", "Zhilun Zhou", "Xuhua Zhang", "Yuanyi Zhen", "Fengli Xu", "Yong Li", "Tie-Yan Liu"], "title": "MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists", "comment": "26 pages, 4 figures", "summary": "The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.", "AI": {"tldr": "MirrorMind\u662f\u4e00\u4e2a\u5206\u5c42\u8ba4\u77e5\u67b6\u6784\uff0c\u901a\u8fc7\u6574\u5408\u53cc\u8bb0\u5fc6\u8868\u793a\u6765\u6a21\u62df\u4eba\u7c7b\u79d1\u5b66\u53d1\u73b0\u7684\u793e\u4f1a\u5386\u53f2\u7279\u6027\uff0c\u5305\u542b\u4e2a\u4f53\u8ba4\u77e5\u8f68\u8ff9\u548c\u96c6\u4f53\u5b66\u79d1\u8bb0\u5fc6\u4e24\u4e2a\u5c42\u9762\u3002", "motivation": "\u5f53\u524dAI\u79d1\u5b66\u5bb6\u65b9\u6cd5\u5c06\u79d1\u5b66\u53d1\u73b0\u89c6\u4e3a\u5b64\u7acb\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u5ffd\u7565\u4e86\u77e5\u8bc6\u751f\u4ea7\u7684\u793e\u4f1a\u6027\u548c\u5386\u53f2\u6027\u672c\u8d28\u3002\u4eba\u7c7b\u79d1\u5b66\u6d1e\u5bdf\u6765\u81ea\u4e2a\u4f53\u8ba4\u77e5\u8f68\u8ff9\u548c\u96c6\u4f53\u5b66\u79d1\u8bb0\u5fc6\u4e24\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u6765\u6e90\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u6846\u67b6\uff1a\u4e2a\u4f53\u5c42\u9762\u6784\u5efa\u7814\u7a76\u8005\u7684\u8ba4\u77e5\u6a21\u578b\uff08\u60c5\u666f\u3001\u8bed\u4e49\u3001\u4eba\u683c\u8bb0\u5fc6\uff09\uff1b\u9886\u57df\u5c42\u9762\u5c06\u96c6\u4f53\u77e5\u8bc6\u6620\u5c04\u4e3a\u7ed3\u6784\u5316\u5b66\u79d1\u6982\u5ff5\u56fe\uff1b\u8de8\u5b66\u79d1\u5c42\u9762\u4f5c\u4e3a\u6b63\u4ea4\u7f16\u6392\u5f15\u64ce\u3002\u67b6\u6784\u5c06\u8bb0\u5fc6\u5b58\u50a8\u4e0e\u667a\u80fd\u6267\u884c\u5206\u79bb\u3002", "result": "\u5728\u56db\u4e2a\u7efc\u5408\u4efb\u52a1\u4e2d\u8bc4\u4f30\uff1a\u4f5c\u8005\u7ea7\u8ba4\u77e5\u6a21\u62df\u3001\u4e92\u8865\u63a8\u7406\u3001\u8de8\u5b66\u79d1\u534f\u4f5c\u4fc3\u8fdb\u3001\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u3002\u7ed3\u679c\u663e\u793aMirrorMind\u8d85\u8d8a\u4e86\u7b80\u5355\u4e8b\u5b9e\u68c0\u7d22\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u3001\u4e2a\u6027\u5316\u548c\u6d1e\u5bdf\u751f\u6210\u7684\u79d1\u5b66\u63a8\u7406\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u4e2a\u4f53\u8ba4\u77e5\u6df1\u5ea6\u548c\u96c6\u4f53\u5b66\u79d1\u5e7f\u5ea6\uff0cMirrorMind\u80fd\u591f\u8fdb\u884c\u7ed3\u6784\u5316\u7684\u3001\u4e2a\u6027\u5316\u7684\u3001\u80fd\u591f\u4ea7\u751f\u6d1e\u5bdf\u7684\u79d1\u5b66\u63a8\u7406\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.17104", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17104", "abs": "https://arxiv.org/abs/2511.17104", "authors": ["Abduljalil S. Aljadani", "Firdous U. Nazir", "Bikash C. Pal", "Izudin D\u017eafi\u0107", "Rabih A. Jabr"], "title": "Power Flow Solution in Unbalanced 3-Wire MV and 4-Wire LV Networks Using Symmetrical and Eigen-basis Coordinates", "comment": "10 pages, 7 figures. Submitted to Journal of Modern Power Systems and Clean Energy", "summary": "The large penetration of distributed generations impacts both the secondary low-voltage (LV) and the primary medium-voltage (MV) segments of the distribution network. Optimizing power flow calculations for the integrated MV/LV networks is crucial for the real-time management of modern distribution networks. Traditional methods in symmetrical coordinates are primarily limited to the three-wire model of three-phase networks, often leading to inaccuracies in power flow calculations when applied to three-phase four-wire LV segments. This paper introduces a novel power flow method for integrated three-wire MV and four-wire LV networks. Using eigenvector decomposition to diagonalize the admittance matrix of four-wire LV lines, the proposed method improves the computational efficiency of power flow calculations and accurately calculates the neutral-to-ground voltage. The results of the case studies show over 50\\% reduction in the number of non-zero elements in the LU factors of the bus admittance matrix, and speed-up factors of 2.78 on the IEEE 123-node test system and 3.63 on the IEEE 8500-node test system in execution times for Volt/Var control (VVC), compared to the phase coordinates model.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u96c6\u6210\u4e09\u7ebf\u4e2d\u538b\u548c\u56db\u7ebf\u4f4e\u538b\u7f51\u7edc\u7684\u65b0\u578b\u6f6e\u6d41\u8ba1\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u5f81\u5411\u91cf\u5206\u89e3\u5bf9\u89d2\u5316\u56db\u7ebf\u4f4e\u538b\u7ebf\u8def\u7684\u5bfc\u7eb3\u77e9\u9635\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u5e76\u51c6\u786e\u8ba1\u7b97\u4e2d\u6027\u70b9\u5bf9\u5730\u7535\u538b\u3002", "motivation": "\u5206\u5e03\u5f0f\u53d1\u7535\u7684\u5927\u89c4\u6a21\u6e17\u900f\u5f71\u54cd\u4e86\u914d\u7535\u7f51\u7684\u4e2d\u4f4e\u538b\u6bb5\uff0c\u4f20\u7edf\u5bf9\u79f0\u5750\u6807\u65b9\u6cd5\u4e3b\u8981\u9650\u4e8e\u4e09\u76f8\u4e09\u7ebf\u6a21\u578b\uff0c\u5728\u5e94\u7528\u4e8e\u4e09\u76f8\u56db\u7ebf\u4f4e\u538b\u6bb5\u65f6\u5f80\u5f80\u5bfc\u81f4\u6f6e\u6d41\u8ba1\u7b97\u4e0d\u51c6\u786e\u3002", "method": "\u4f7f\u7528\u7279\u5f81\u5411\u91cf\u5206\u89e3\u5bf9\u89d2\u5316\u56db\u7ebf\u4f4e\u538b\u7ebf\u8def\u7684\u5bfc\u7eb3\u77e9\u9635\uff0c\u6539\u8fdb\u96c6\u6210\u4e09\u7ebf\u4e2d\u538b\u548c\u56db\u7ebf\u4f4e\u538b\u7f51\u7edc\u7684\u6f6e\u6d41\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u663e\u793a\uff0c\u603b\u7ebf\u5bfc\u7eb3\u77e9\u9635LU\u56e0\u5b50\u4e2d\u975e\u96f6\u5143\u7d20\u6570\u91cf\u51cf\u5c11\u8d85\u8fc750%\uff0c\u5728IEEE 123\u8282\u70b9\u548c8500\u8282\u70b9\u6d4b\u8bd5\u7cfb\u7edf\u4e2d\uff0cVolt/Var\u63a7\u5236\u7684\u6267\u884c\u65f6\u95f4\u5206\u522b\u52a0\u901f2.78\u500d\u548c3.63\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u96c6\u6210\u4e2d\u4f4e\u538b\u7f51\u7edc\u6f6e\u6d41\u8ba1\u7b97\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u73b0\u4ee3\u914d\u7535\u7f51\u7684\u5b9e\u65f6\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17331", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.17331", "abs": "https://arxiv.org/abs/2511.17331", "authors": ["Sydney Reis"], "title": "AI Workers, Geopolitics, and Algorithmic Collective Action", "comment": null, "summary": "According to the theory of International Political Economy (IPE), states are often incentivized to rely on rather than constrain powerful corporations. For this reason, IPE provides a useful lens to explain why efforts to govern Artificial Intelligence (AI) at the international and national levels have thus far been developed, applied, and enforced unevenly. Building on recent work that explores how AI companies engage in geopolitics, this position paper argues that some AI workers can be considered actors of geopolitics. It makes the timely case that governance alone cannot ensure responsible, ethical, or robust AI development and use, and greater attention should be paid to bottom-up interventions at the site of AI development. AI workers themselves should be situated as individual agents of change, especially when considering their potential to foster Algorithmic Collective Action (ACA). Drawing on methods of Participatory Design (PD), this paper proposes engaging AI workers as sources of knowledge, relative power, and intentionality to encourage more responsible and just AI development and create the conditions that can facilitate ACA.", "AI": {"tldr": "\u672c\u6587\u4ece\u56fd\u9645\u653f\u6cbb\u7ecf\u6d4e\u5b66\u89c6\u89d2\u5206\u6790AI\u6cbb\u7406\u56f0\u5883\uff0c\u8ba4\u4e3aAI\u5de5\u4f5c\u8005\u5e94\u88ab\u89c6\u4e3a\u5730\u7f18\u653f\u6cbb\u53c2\u4e0e\u8005\uff0c\u5efa\u8bae\u901a\u8fc7\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\u8ba9AI\u5de5\u4f5c\u8005\u53c2\u4e0e\u6cbb\u7406\uff0c\u4fc3\u8fdb\u7b97\u6cd5\u96c6\u4f53\u884c\u52a8\u3002", "motivation": "\u5f53\u524dAI\u6cbb\u7406\u5728\u56fd\u9645\u548c\u56fd\u5bb6\u5c42\u9762\u53d1\u5c55\u4e0d\u5e73\u8861\uff0c\u4f20\u7edf\u6cbb\u7406\u65b9\u5f0f\u96be\u4ee5\u786e\u4fddAI\u7684\u8d1f\u8d23\u4efb\u53d1\u5c55\uff0c\u9700\u8981\u5173\u6ce8\u81ea\u4e0b\u800c\u4e0a\u7684\u5e72\u9884\u63aa\u65bd\u3002", "method": "\u91c7\u7528\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5c06AI\u5de5\u4f5c\u8005\u89c6\u4e3a\u77e5\u8bc6\u3001\u76f8\u5bf9\u6743\u529b\u548c\u610f\u56fe\u7684\u6765\u6e90\uff0c\u4fc3\u8fdb\u7b97\u6cd5\u96c6\u4f53\u884c\u52a8\u3002", "result": "\u63d0\u51fa\u5c06AI\u5de5\u4f5c\u8005\u5b9a\u4f4d\u4e3a\u53d8\u9769\u4e2a\u4f53\u4ee3\u7406\u4eba\u7684\u6846\u67b6\uff0c\u5f3a\u8c03\u4ed6\u4eec\u5728\u4fc3\u8fdb\u8d1f\u8d23\u4efbAI\u53d1\u5c55\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u4ec5\u9760\u6cbb\u7406\u65e0\u6cd5\u786e\u4fddAI\u7684\u8d1f\u8d23\u4efb\u53d1\u5c55\uff0c\u5e94\u66f4\u591a\u5173\u6ce8AI\u5f00\u53d1\u73b0\u573a\u7684\u57fa\u5c42\u5e72\u9884\uff0c\u5c06AI\u5de5\u4f5c\u8005\u89c6\u4e3a\u53d8\u9769\u63a8\u52a8\u8005\u3002"}}
{"id": "2511.17079", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17079", "abs": "https://arxiv.org/abs/2511.17079", "authors": ["Yijie Zhu", "Rui Shao", "Ziyang Liu", "Jie He", "Jizhihui Liu", "Jiuru Wang", "Zitong Yu"], "title": "H-GAR: A Hierarchical Interaction Framework via Goal-Driven Observation-Action Refinement for Robotic Manipulation", "comment": "Accepted to AAAI 2026 (Oral), Project Page: https://github.com/JiuTian-VL/H-GAR", "summary": "Unified video and action prediction models hold great potential for robotic manipulation, as future observations offer contextual cues for planning, while actions reveal how interactions shape the environment. However, most existing approaches treat observation and action generation in a monolithic and goal-agnostic manner, often leading to semantically misaligned predictions and incoherent behaviors. To this end, we propose H-GAR, a Hierarchical interaction framework via Goal-driven observation-Action Refinement.To anchor prediction to the task objective, H-GAR first produces a goal observation and a coarse action sketch that outline a high-level route toward the goal. To enable explicit interaction between observation and action under the guidance of the goal observation for more coherent decision-making, we devise two synergistic modules. (1) Goal-Conditioned Observation Synthesizer (GOS) synthesizes intermediate observations based on the coarse-grained actions and the predicted goal observation. (2) Interaction-Aware Action Refiner (IAAR) refines coarse actions into fine-grained, goal-consistent actions by leveraging feedback from the intermediate observations and a Historical Action Memory Bank that encodes prior actions to ensure temporal consistency. By integrating goal grounding with explicit action-observation interaction in a coarse-to-fine manner, H-GAR enables more accurate manipulation. Extensive experiments on both simulation and real-world robotic manipulation tasks demonstrate that H-GAR achieves state-of-the-art performance.", "AI": {"tldr": "H-GAR\u662f\u4e00\u4e2a\u5206\u5c42\u4ea4\u4e92\u6846\u67b6\uff0c\u901a\u8fc7\u76ee\u6807\u9a71\u52a8\u7684\u89c2\u5bdf-\u52a8\u4f5c\u7cbe\u70bc\u6765\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u9884\u6d4b\u3002\u5b83\u9996\u5148\u751f\u6210\u76ee\u6807\u89c2\u5bdf\u548c\u7c97\u7565\u52a8\u4f5c\u8349\u56fe\uff0c\u7136\u540e\u901a\u8fc7\u4e24\u4e2a\u534f\u540c\u6a21\u5757\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7cbe\u70bc\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u9891\u548c\u52a8\u4f5c\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u4ee5\u6574\u4f53\u548c\u4e0e\u76ee\u6807\u65e0\u5173\u7684\u65b9\u5f0f\u5904\u7406\u89c2\u5bdf\u548c\u52a8\u4f5c\u751f\u6210\uff0c\u5bfc\u81f4\u8bed\u4e49\u4e0d\u5bf9\u9f50\u7684\u9884\u6d4b\u548c\u4e0d\u8fde\u8d2f\u7684\u884c\u4e3a\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5c06\u9884\u6d4b\u951a\u5b9a\u5230\u4efb\u52a1\u76ee\u6807\u5e76\u5b9e\u73b0\u89c2\u5bdf\u4e0e\u52a8\u4f5c\u663e\u5f0f\u4ea4\u4e92\u7684\u65b9\u6cd5\u3002", "method": "H-GAR\u91c7\u7528\u5206\u5c42\u6846\u67b6\uff1a1) \u9996\u5148\u751f\u6210\u76ee\u6807\u89c2\u5bdf\u548c\u7c97\u7565\u52a8\u4f5c\u8349\u56fe\uff1b2) \u76ee\u6807\u6761\u4ef6\u89c2\u5bdf\u5408\u6210\u5668(GOS)\u57fa\u4e8e\u7c97\u7565\u52a8\u4f5c\u548c\u76ee\u6807\u89c2\u5bdf\u5408\u6210\u4e2d\u95f4\u89c2\u5bdf\uff1b3) \u4ea4\u4e92\u611f\u77e5\u52a8\u4f5c\u7cbe\u70bc\u5668(IAAR)\u5229\u7528\u4e2d\u95f4\u89c2\u5bdf\u53cd\u9988\u548c\u5386\u53f2\u52a8\u4f5c\u8bb0\u5fc6\u5e93\u7cbe\u70bc\u52a8\u4f5c\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cH-GAR\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5c06\u76ee\u6807\u951a\u5b9a\u4e0e\u663e\u5f0f\u7684\u52a8\u4f5c-\u89c2\u5bdf\u4ea4\u4e92\u4ee5\u4ece\u7c97\u5230\u7ec6\u7684\u65b9\u5f0f\u96c6\u6210\uff0cH-GAR\u80fd\u591f\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u64cd\u4f5c\u9884\u6d4b\u3002"}}
{"id": "2511.17006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17006", "abs": "https://arxiv.org/abs/2511.17006", "authors": ["Tengxiao Liu", "Zifeng Wang", "Jin Miao", "I-Hung Hsu", "Jun Yan", "Jiefeng Chen", "Rujun Han", "Fangyuan Xu", "Yanfei Chen", "Ke Jiang", "Samira Daruki", "Yi Liang", "William Yang Wang", "Tomas Pfister", "Chen-Yu Lee"], "title": "Budget-Aware Tool-Use Enables Effective Agent Scaling", "comment": null, "summary": "Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only \"thinking\" in tokens but also \"acting\" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack \"budget awareness\" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to \"dig deeper\" on a promising lead or \"pivot\" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u660e\u786e\u5de5\u5177\u8c03\u7528\u9884\u7b97\u7ea6\u675f\u4e0b\u5982\u4f55\u6709\u6548\u6269\u5c55\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\uff0c\u63d0\u51fa\u4e86\u9884\u7b97\u8ddf\u8e2a\u5668\u548cBATS\u6846\u67b6\uff0c\u4f7f\u667a\u80fd\u4f53\u5177\u5907\u9884\u7b97\u610f\u8bc6\u5e76\u52a8\u6001\u8c03\u6574\u7b56\u7565\uff0c\u6539\u5584\u4e86\u6210\u672c-\u6027\u80fd\u7684\u6269\u5c55\u66f2\u7ebf\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u5728\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u65f6\uff0c\u5355\u7eaf\u589e\u52a0\u5de5\u5177\u8c03\u7528\u9884\u7b97\u65e0\u6cd5\u63d0\u5347\u6027\u80fd\uff0c\u56e0\u4e3a\u667a\u80fd\u4f53\u7f3a\u4e4f\u9884\u7b97\u610f\u8bc6\uff0c\u5f88\u5feb\u8fbe\u5230\u6027\u80fd\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u4e86\u9884\u7b97\u8ddf\u8e2a\u5668\u63d2\u4ef6\u63d0\u4f9b\u6301\u7eed\u9884\u7b97\u610f\u8bc6\uff0c\u5e76\u5f00\u53d1\u4e86BATS\u6846\u67b6\uff0c\u5229\u7528\u9884\u7b97\u610f\u8bc6\u52a8\u6001\u8c03\u6574\u89c4\u5212\u548c\u9a8c\u8bc1\u7b56\u7565\uff0c\u51b3\u5b9a\u662f\u6df1\u5165\u63a2\u7d22\u8fd8\u662f\u8f6c\u5411\u65b0\u8def\u5f84\u3002", "result": "\u9884\u7b97\u611f\u77e5\u65b9\u6cd5\u4ea7\u751f\u4e86\u66f4\u6709\u5229\u7684\u6269\u5c55\u66f2\u7ebf\uff0c\u63a8\u52a8\u4e86\u6210\u672c-\u6027\u80fd\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u6269\u5c55\u3002", "conclusion": "\u9884\u7b97\u611f\u77e5\u65b9\u6cd5\u4e3a\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u7684\u6269\u5c55\u63d0\u4f9b\u4e86\u66f4\u900f\u660e\u548c\u539f\u5219\u6027\u7684\u7406\u89e3\uff0c\u6539\u5584\u4e86\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.17186", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17186", "abs": "https://arxiv.org/abs/2511.17186", "authors": ["Ali Azarbahram", "Chrystian Pool Yuca Huanca", "Gian Paolo Incremona", "Patrizio Colaneri"], "title": "Distributed Switching Model Predictive Control Meets Koopman Operator for Dynamic Obstacle Avoidance", "comment": null, "summary": "This paper introduces a Koopman-enhanced distributed switched model predictive control (SMPC) framework for safe and scalable navigation of quadrotor unmanned aerial vehicles (UAVs) in dynamic environments with moving obstacles. The proposed method integrates switched motion modes and data-driven prediction to enable real-time, collision-free coordination. A localized Koopman operator approximates nonlinear obstacle dynamics as linear models based on online measurements, enabling accurate trajectory forecasting. These predictions are embedded into a distributed SMPC structure, where each UAV makes autonomous decisions using local and cluster-based information. This computationally efficient architecture is particularly promising for applications in surface transportation, including coordinated vehicle flows, shared infrastructure with pedestrians or cyclists, and urban UAV traffic. Simulation results demonstrate reliable formation control and real-time obstacle avoidance, highlighting the frameworks broad relevance for intelligent and cooperative mobility systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKoopman\u7b97\u5b50\u7684\u5206\u5e03\u5f0f\u5207\u6362\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b89\u5168\u5bfc\u822a\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u969c\u788d\u7269\u8f68\u8ff9\u9884\u6d4b\u5b9e\u73b0\u5b9e\u65f6\u907f\u969c\u3002", "motivation": "\u89e3\u51b3\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4e0e\u79fb\u52a8\u969c\u788d\u7269\u8fdb\u884c\u5b89\u5168\u3001\u53ef\u6269\u5c55\u5bfc\u822a\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5730\u9762\u4ea4\u901a\u534f\u8c03\u3001\u4eba\u8f66\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u7b49\u5e94\u7528\u573a\u666f\u4e2d\u3002", "method": "\u96c6\u6210\u5207\u6362\u8fd0\u52a8\u6a21\u5f0f\u548c\u6570\u636e\u9a71\u52a8\u9884\u6d4b\uff0c\u4f7f\u7528\u5c40\u90e8Koopman\u7b97\u5b50\u5c06\u975e\u7ebf\u6027\u969c\u788d\u7269\u52a8\u6001\u8fd1\u4f3c\u4e3a\u7ebf\u6027\u6a21\u578b\uff0c\u5d4c\u5165\u5206\u5e03\u5f0f\u5207\u6362\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7ed3\u6784\u4e2d\uff0c\u5b9e\u73b0\u81ea\u4e3b\u51b3\u7b56\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u53ef\u9760\u7684\u7f16\u961f\u63a7\u5236\u548c\u5b9e\u65f6\u907f\u969c\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u667a\u80fd\u534f\u540c\u79fb\u52a8\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u9ad8\u6548\u7684\u67b6\u6784\u4e3a\u667a\u80fd\u534f\u540c\u79fb\u52a8\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u534f\u8c03\u8f66\u8f86\u6d41\u3001\u4eba\u8f66\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u548c\u57ce\u5e02\u65e0\u4eba\u673a\u4ea4\u901a\u7b49\u5e94\u7528\u3002"}}
{"id": "2511.17097", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17097", "abs": "https://arxiv.org/abs/2511.17097", "authors": ["Shuo Wang", "Yucheng Wang", "Guoxin Lian", "Yongcai Wang", "Maiyue Chen", "Kaihui Wang", "Bo Zhang", "Zhizhong Su", "Yutian Zhou", "Wanting Li", "Deying Li", "Zhaoxin Fan"], "title": "Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation", "comment": null, "summary": "Vision-Language Navigation requires agents to act coherently over long horizons by understanding not only local visual context but also how far they have advanced within a multi-step instruction. However, recent Vision-Language-Action models focus on direct action prediction and earlier progress methods predict numeric achievements; both overlook the monotonic co-progression property of the observation and instruction sequences. Building on this insight, Progress-Think introduces semantic progress reasoning, predicting instruction-style progress from visual observations to enable more accurate navigation. To achieve this without expensive annotations, we propose a three-stage framework. In the initial stage, Self-Aligned Progress Pretraining bootstraps a reasoning module via a novel differentiable alignment between visual history and instruction prefixes. Then, Progress-Guided Policy Pretraining injects learned progress states into the navigation context, guiding the policy toward consistent actions. Finally, Progress-Policy Co-Finetuning jointly optimizes both modules with tailored progress-aware reinforcement objectives. Experiments on R2R-CE and RxR-CE show state-of-the-art success and efficiency, demonstrating that semantic progress yields a more consistent representation of navigation advancement.", "AI": {"tldr": "Progress-Think\u901a\u8fc7\u8bed\u4e49\u8fdb\u5c55\u63a8\u7406\u6765\u6539\u8fdb\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\uff0c\u9884\u6d4b\u6307\u4ee4\u98ce\u683c\u7684\u8fdb\u5c55\u72b6\u6001\uff0c\u4ece\u800c\u5f15\u5bfc\u66f4\u51c6\u786e\u7684\u5bfc\u822a\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u65b9\u6cd5\u8981\u4e48\u53ea\u5173\u6ce8\u76f4\u63a5\u52a8\u4f5c\u9884\u6d4b\uff0c\u8981\u4e48\u9884\u6d4b\u6570\u503c\u8fdb\u5c55\uff0c\u90fd\u5ffd\u7565\u4e86\u89c2\u5bdf\u5e8f\u5217\u548c\u6307\u4ee4\u5e8f\u5217\u4e4b\u95f4\u7684\u5355\u8c03\u5171\u8fdb\u7279\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1) \u81ea\u5bf9\u9f50\u8fdb\u5c55\u9884\u8bad\u7ec3\u901a\u8fc7\u89c6\u89c9\u5386\u53f2\u548c\u6307\u4ee4\u524d\u7f00\u7684\u5fae\u5206\u5bf9\u9f50\u542f\u52a8\u63a8\u7406\u6a21\u5757\uff1b2) \u8fdb\u5c55\u5f15\u5bfc\u7b56\u7565\u9884\u8bad\u7ec3\u5c06\u5b66\u4e60\u5230\u7684\u8fdb\u5c55\u72b6\u6001\u6ce8\u5165\u5bfc\u822a\u4e0a\u4e0b\u6587\uff1b3) \u8fdb\u5c55-\u7b56\u7565\u534f\u540c\u5fae\u8c03\u4f7f\u7528\u8fdb\u5c55\u611f\u77e5\u5f3a\u5316\u76ee\u6807\u8054\u5408\u4f18\u5316\u4e24\u4e2a\u6a21\u5757\u3002", "result": "\u5728R2R-CE\u548cRxR-CE\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u6210\u529f\u7387\u548c\u6548\u7387\u65b9\u9762\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002", "conclusion": "\u8bed\u4e49\u8fdb\u5c55\u80fd\u591f\u63d0\u4f9b\u66f4\u4e00\u81f4\u7684\u5bfc\u822a\u8fdb\u5c55\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u5bfc\u822a\u6027\u80fd\u3002"}}
{"id": "2511.17038", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17038", "abs": "https://arxiv.org/abs/2511.17038", "authors": ["Hao Chen", "Renzheng Zhang", "Scott S. Howard"], "title": "DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing", "comment": null, "summary": "From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \\textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \\textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u89e3\u91ca\u4e86\u6269\u6563\u6a21\u578b\u5728\u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u4f5c\u7528\uff0c\u5c06\u5176\u89c6\u4e3a\u671f\u671b\u6700\u5927\u5316\u6846\u67b6\u4e2d\u7684\u521d\u59cb\u5316\u9636\u6bb5\uff0c\u63d0\u51fa\u4e86DAPS++\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u7684\u91cd\u5efa\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u8d1d\u53f6\u65af\u89c6\u89d2\u4e0b\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u65b9\u6cd5\u5728\u89e3\u51b3\u9006\u95ee\u9898\u65f6\uff0c\u5148\u9a8c\u63d0\u4f9b\u7684\u6307\u5bfc\u6709\u9650\uff0c\u91cd\u5efa\u4e3b\u8981\u7531\u6d4b\u91cf\u4e00\u81f4\u6027\u9879\u9a71\u52a8\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u4e0e\u6269\u6563\u52a8\u529b\u5b66\u6709\u6548\u89e3\u8026\u3002\u9700\u8981\u6f84\u6e05\u8fd9\u79cd\u7ed3\u6784\u5e76\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u5c06\u6269\u6563\u91cd\u65b0\u89e3\u91ca\u4e3a\u671f\u671b\u6700\u5927\u5316\u6846\u67b6\u4e2d\u7684\u521d\u59cb\u5316\u9636\u6bb5\uff0c\u5f15\u5165DAPS++\u65b9\u6cd5\uff0c\u4f7f\u4f3c\u7136\u9879\u80fd\u66f4\u76f4\u63a5\u5730\u6307\u5bfc\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u548c\u6d4b\u91cf\u4f18\u5316\u6b65\u9aa4\u3002", "result": "DAPS++\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u663e\u8457\u63d0\u5347\uff0c\u9700\u8981\u66f4\u5c11\u7684\u51fd\u6570\u8bc4\u4f30\uff0c\u5728\u5404\u79cd\u56fe\u50cf\u6062\u590d\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u91cd\u5efa\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6269\u6563\u9636\u6bb5\u4e0e\u6570\u636e\u9a71\u52a8\u7ec6\u5316\u5b8c\u5168\u89e3\u8026\uff0cDAPS++\u4e3a\u7edf\u4e00\u6269\u6563\u8f68\u8ff9\u5728\u5b9e\u8df5\u4e2d\u4fdd\u6301\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6548\u7a33\u5b9a\u7684\u9006\u95ee\u9898\u6c42\u89e3\u3002"}}
{"id": "2511.17212", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17212", "abs": "https://arxiv.org/abs/2511.17212", "authors": ["Lisa-Marie Schilling", "Christian Bornkessel", "Anna-Malin Schiffarth", "Thanh Tam Julian Ta", "Dirk Heberling", "Matthias Hein"], "title": "Influence of Transmission Rank on EMF Exposure Measured With Provoked Data Traffic Around 5G Massive MIMO Base Stations", "comment": "4 pages, 3 figures", "summary": "The introduction of 5G New Radio networks with massive MIMO technology has complicated electromagnetic field exposure assessments for radiation protection. Massive MIMO transmission enables beamforming, beam steering, and spatial multiplexing across multiple transmission layers, with the number of simultaneous transmission paths depending on the rank of the radio channel, further named 'transmission rank'. Since the total transmission power of a base station is shared among these layers, rank variations affect the measured exposure levels, e.g., when assessments use provoked traffic via user equipment. This study investigates the impact of the transmission rank on the measured maximum exposure in the 3.6 GHz (n78) band of a German 5G network employing massive MIMO technology. Field measurements were performed using a spectrum analyzer with isotropic probe, to capture maximum field strengths under full-load traffic conditions. The transmission rank was manipulated by artificially degrading the reception quality of the user equipment with a shielding bag, forcing a single transmission layer (rank-1). The results were compared with unshielded operation allowing up to the maximum number of four independent transmission layers (rank-4). The data reveal exposure differences ranging from 1.7 dB to 5.4 dB, with a median of 4.3 dB at the measurement points studied. These findings highlight the necessity of considering the transmission rank in exposure assessments to electromagnetic fields.", "AI": {"tldr": "5G\u5927\u89c4\u6a21MIMO\u6280\u672f\u4e2d\u7684\u4f20\u8f93\u79e9\u53d8\u5316\u4f1a\u5f71\u54cd\u7535\u78c1\u573a\u66b4\u9732\u8bc4\u4f30\uff0c\u7814\u7a76\u53d1\u73b0\u901a\u8fc7\u5c4f\u853d\u7528\u6237\u8bbe\u5907\u5f3a\u5236\u5355\u5c42\u4f20\u8f93\uff08\u79e91\uff09\u4e0e\u591a\u5c42\u4f20\u8f93\uff08\u79e94\uff09\u76f8\u6bd4\uff0c\u66b4\u9732\u6c34\u5e73\u5dee\u5f02\u4e2d\u4f4d\u6570\u4e3a4.3dB\u3002", "motivation": "5G\u65b0\u65e0\u7ebf\u7535\u7f51\u7edc\u91c7\u7528\u5927\u89c4\u6a21MIMO\u6280\u672f\uff0c\u901a\u8fc7\u6ce2\u675f\u6210\u5f62\u3001\u6ce2\u675f\u8f6c\u5411\u548c\u7a7a\u95f4\u590d\u7528\u5b9e\u73b0\u591a\u4f20\u8f93\u5c42\uff0c\u4f20\u8f93\u79e9\u7684\u53d8\u5316\u4f1a\u5f71\u54cd\u57fa\u7ad9\u603b\u529f\u7387\u5728\u5404\u5c42\u95f4\u7684\u5206\u914d\uff0c\u4ece\u800c\u5f71\u54cd\u6d4b\u91cf\u7684\u7535\u78c1\u573a\u66b4\u9732\u6c34\u5e73\u3002", "method": "\u5728\u5fb7\u56fd5G\u7f51\u7edc3.6GHz\u9891\u6bb5\u8fdb\u884c\u73b0\u573a\u6d4b\u91cf\uff0c\u4f7f\u7528\u9891\u8c31\u5206\u6790\u4eea\u548c\u5168\u5411\u63a2\u5934\uff0c\u901a\u8fc7\u5c4f\u853d\u888b\u4eba\u4e3a\u964d\u4f4e\u7528\u6237\u8bbe\u5907\u63a5\u6536\u8d28\u91cf\uff0c\u5f3a\u5236\u5355\u5c42\u4f20\u8f93\uff08\u79e91\uff09\uff0c\u5e76\u4e0e\u65e0\u5c4f\u853d\u65f6\u6700\u591a\u56db\u5c42\u4f20\u8f93\uff08\u79e94\uff09\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u6d4b\u91cf\u6570\u636e\u663e\u793a\uff0c\u4e0d\u540c\u4f20\u8f93\u79e9\u4e0b\u7684\u66b4\u9732\u5dee\u5f02\u8303\u56f4\u4e3a1.7dB\u81f35.4dB\uff0c\u4e2d\u4f4d\u6570\u4e3a4.3dB\u3002", "conclusion": "\u7535\u78c1\u573a\u66b4\u9732\u8bc4\u4f30\u4e2d\u5fc5\u987b\u8003\u8651\u4f20\u8f93\u79e9\u7684\u5f71\u54cd\u3002"}}
{"id": "2511.17166", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17166", "abs": "https://arxiv.org/abs/2511.17166", "authors": ["Tim Lakemann", "Daniel Bonilla Licea", "Viktor Walter", "Martin Saska"], "title": "Reflection-Based Relative Localization for Cooperative UAV Teams Using Active Markers", "comment": null, "summary": "Reflections of active markers in the environment are a common source of ambiguity in onboard visual relative localization. This work presents a novel approach for onboard relative localization in multi-robot teams that exploits these typically unwanted reflections of active markers in the environment. It operates without prior knowledge of robot size or predefined marker configurations and remains independent of surface properties, an essential feature for heterogeneous micro-aerial swarms cooperating in unknown environments. It explicitly accounts for uncertainties caused by non-flat surfaces, with a particular focus on dynamic water surfaces, which are especially relevant for marine deployments. We validated the approach in both indoor and outdoor experiments, demonstrating that the proposed reflection-based localization system operates reliably without prior knowledge of team member size and achieves greater effective range (above 30 m) and accuracy than state-of-the-art methods. The video and source code of this work will be made publicly available after publication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4e3b\u52a8\u6807\u8bb0\u5728\u73af\u5883\u4e2d\u7684\u53cd\u5c04\u8fdb\u884c\u591a\u673a\u5668\u4eba\u76f8\u5bf9\u5b9a\u4f4d\u7684\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u673a\u5668\u4eba\u5c3a\u5bf8\u6216\u6807\u8bb0\u914d\u7f6e\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u5ba4\u5185\u5916\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6709\u6548\u8303\u56f4\u548c\u7cbe\u5ea6\u3002", "motivation": "\u73af\u5883\u4e2d\u4e3b\u52a8\u6807\u8bb0\u7684\u53cd\u5c04\u901a\u5e38\u4f1a\u5bfc\u81f4\u89c6\u89c9\u76f8\u5bf9\u5b9a\u4f4d\u7684\u6a21\u7cca\u6027\uff0c\u4f46\u672c\u6587\u65e8\u5728\u5229\u7528\u8fd9\u4e9b\u901a\u5e38\u88ab\u89c6\u4e3a\u5e72\u6270\u7684\u53cd\u5c04\u6765\u5b9e\u73b0\u591a\u673a\u5668\u4eba\u56e2\u961f\u7684\u673a\u8f7d\u76f8\u5bf9\u5b9a\u4f4d\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u5c04\u7684\u5b9a\u4f4d\u7cfb\u7edf\uff0c\u4e0d\u4f9d\u8d56\u8868\u9762\u7279\u6027\uff0c\u7279\u522b\u8003\u8651\u4e86\u975e\u5e73\u5766\u8868\u9762\uff08\u5c24\u5176\u662f\u52a8\u6001\u6c34\u9762\uff09\u5f15\u8d77\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u672a\u77e5\u73af\u5883\u4e2d\u7684\u5f02\u6784\u5fae\u578b\u7a7a\u4e2d\u96c6\u7fa4\u534f\u4f5c\u3002", "result": "\u5728\u5ba4\u5185\u5916\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u80fd\u5728\u65e0\u56e2\u961f\u6210\u5458\u5c3a\u5bf8\u5148\u9a8c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u53ef\u9760\u8fd0\u884c\uff0c\u6709\u6548\u8303\u56f4\u8d85\u8fc730\u7c73\uff0c\u7cbe\u5ea6\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u53cd\u5c04\u7684\u5b9a\u4f4d\u7cfb\u7edf\u4e3a\u591a\u673a\u5668\u4eba\u76f8\u5bf9\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6d77\u6d0b\u90e8\u7f72\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u3002"}}
{"id": "2511.17056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17056", "abs": "https://arxiv.org/abs/2511.17056", "authors": ["Paloma Rabaey", "Adrick Tench", "Stefan Heytens", "Thomas Demeester"], "title": "Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks", "comment": null, "summary": "Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u60a3\u8005\u4fe1\u606f\u63d0\u53d6\u65b9\u6cd5\uff0c\u7ed3\u5408\u7ed3\u6784\u5316EHR\u6570\u636e\u548c\u4e34\u5e8a\u6587\u672c\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u7f51\u7edc\u548c\u795e\u7ecf\u6587\u672c\u5206\u7c7b\u5668\u8fdb\u884c\u878d\u5408\uff0c\u63d0\u9ad8\u9884\u6d4b\u6821\u51c6\u6027\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u65e2\u6709\u7ed3\u6784\u5316\u4fe1\u606f\uff08\u8bca\u65ad\u4ee3\u7801\u3001\u836f\u7269\u7b49\uff09\u4e5f\u6709\u975e\u7ed3\u6784\u5316\u6587\u672c\uff08\u51fa\u9662\u603b\u7ed3\u3001\u62a4\u7406\u8bb0\u5f55\uff09\uff0c\u9700\u8981\u6709\u6548\u878d\u5408\u8fd9\u4e24\u79cd\u4fe1\u606f\u6e90\u6765\u6784\u5efa\u900f\u660e\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u4e13\u5bb6\u6307\u5bfc\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u5904\u7406\u7ed3\u6784\u5316EHR\u7279\u5f81\uff0c\u7ed3\u5408\u795e\u7ecf\u6587\u672c\u5206\u7c7b\u5668\u5904\u7406\u4e34\u5e8a\u7b14\u8bb0\uff0c\u901a\u8fc7\u865a\u62df\u8bc1\u636e\u548c\u4e00\u81f4\u6027\u8282\u70b9\u8fdb\u884c\u6982\u7387\u878d\u5408\u3002", "result": "\u5728SimSUM\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e00\u81f4\u6027\u8282\u70b9\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528\u865a\u62df\u8bc1\u636e\u80fd\u6539\u5584\u9884\u6d4b\u6821\u51c6\uff0c\u66f4\u597d\u5730\u5904\u7406\u7f3a\u5931\u4fe1\u606f\u548c\u89e3\u51b3\u6570\u636e\u77db\u76fe\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u6982\u7387\u878d\u5408\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u6574\u5408\u591a\u6a21\u6001\u533b\u7597\u6570\u636e\uff0c\u63d0\u9ad8\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.17233", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17233", "abs": "https://arxiv.org/abs/2511.17233", "authors": ["Prabhat K. Mishra", "Mateus V. Gasparino", "Girish Chowdhary"], "title": "Algorithmic design and implementation considerations of deep MPC", "comment": null, "summary": "Deep Model Predictive Control (Deep MPC) is an evolving field that integrates model predictive control and deep learning. This manuscript is focused on a particular approach, which employs deep neural network in the loop with MPC. This class of approaches distributes control authority between a neural network and an MPC controller, in such a way that the neural network learns the model uncertainties while the MPC handles constraints. The approach is appealing because training data collected while the system is in operation can be used to fine-tune the neural network, and MPC prevents unsafe behavior during those learning transients. This manuscript explains implementation challenges of Deep MPC, algorithmic way to distribute control authority and argues that a poor choice in distributing control authority may lead to poor performance. A reason of poor performance is explained through a numerical experiment on a four-wheeled skid-steer dynamics.", "AI": {"tldr": "Deep MPC\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u4e0e\u6df1\u5ea6\u5b66\u4e60\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0cMPC\u5904\u7406\u7ea6\u675f\uff0c\u4f46\u63a7\u5236\u6743\u5206\u914d\u4e0d\u5f53\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u5229\u7528\u8fd0\u884c\u4e2d\u6536\u96c6\u7684\u8bad\u7ec3\u6570\u636e\u5fae\u8c03\u795e\u7ecf\u7f51\u7edc\uff0c\u540c\u65f6MPC\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u9632\u6b62\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u5b9e\u73b0\u5b89\u5168\u9ad8\u6548\u7684\u63a7\u5236\u3002", "method": "\u5728MPC\u5faa\u73af\u4e2d\u96c6\u6210\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5206\u914d\u63a7\u5236\u6743\uff1a\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0cMPC\u5904\u7406\u7ea6\u675f\u6761\u4ef6\u3002", "result": "\u901a\u8fc7\u56db\u8f6e\u6ed1\u79fb\u8f6c\u5411\u52a8\u529b\u5b66\u7684\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u63a7\u5236\u6743\u5206\u914d\u4e0d\u5f53\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "Deep MPC\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u63a7\u5236\u6743\u5206\u914d\u7b56\u7565\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4ed4\u7ec6\u8bbe\u8ba1\u4ee5\u907f\u514d\u6027\u80fd\u95ee\u9898\u3002"}}
{"id": "2511.17178", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17178", "abs": "https://arxiv.org/abs/2511.17178", "authors": ["Kento Kawaharazuka", "Yoshiki Obinata", "Naoaki Kanazawa", "Haoyu Jia", "Kei Okada"], "title": "Efficient Robot Design with Multi-Objective Black-Box Optimization and Large Language Models", "comment": null, "summary": "Various methods for robot design optimization have been developed so far. These methods are diverse, ranging from numerical optimization to black-box optimization. While numerical optimization is fast, it is not suitable for cases involving complex structures or discrete values, leading to frequent use of black-box optimization instead. However, black-box optimization suffers from low sampling efficiency and takes considerable sampling iterations to obtain good solutions. In this study, we propose a method to enhance the efficiency of robot body design based on black-box optimization by utilizing large language models (LLMs). In parallel with the sampling process based on black-box optimization, sampling is performed using LLMs, which are provided with problem settings and extensive feedback. We demonstrate that this method enables more efficient exploration of design solutions and discuss its characteristics and limitations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u57fa\u4e8e\u9ed1\u76d2\u4f18\u5316\u7684\u673a\u5668\u4eba\u8eab\u4f53\u8bbe\u8ba1\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u91c7\u6837\u63d0\u9ad8\u63a2\u7d22\u6548\u7387", "motivation": "\u6570\u503c\u4f18\u5316\u867d\u7136\u5feb\u901f\u4f46\u4e0d\u9002\u7528\u4e8e\u590d\u6742\u7ed3\u6784\u6216\u79bb\u6563\u503c\uff0c\u800c\u9ed1\u76d2\u4f18\u5316\u91c7\u6837\u6548\u7387\u4f4e\u3001\u9700\u8981\u5927\u91cf\u8fed\u4ee3\u624d\u80fd\u83b7\u5f97\u826f\u597d\u89e3\u51b3\u65b9\u6848", "method": "\u5728\u57fa\u4e8e\u9ed1\u76d2\u4f18\u5316\u7684\u91c7\u6837\u8fc7\u7a0b\u540c\u65f6\uff0c\u4f7f\u7528LLMs\u8fdb\u884c\u5e76\u884c\u91c7\u6837\uff0c\u4e3aLLMs\u63d0\u4f9b\u95ee\u9898\u8bbe\u7f6e\u548c\u5927\u91cf\u53cd\u9988", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u63a2\u7d22\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848", "conclusion": "\u8ba8\u8bba\u4e86\u8be5\u65b9\u6cd5\u7684\u7279\u6027\u548c\u5c40\u9650\u6027"}}
{"id": "2511.17162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17162", "abs": "https://arxiv.org/abs/2511.17162", "authors": ["Sara Zuppiroli", "Carmelo Fabio Longo", "Anna Sofia Lippolis", "Rocco Paolillo", "Lorenzo Giammei", "Miguel Ceriani", "Francesco Poggi", "Antonio Zinilli", "Andrea Giovanni Nuzzolese"], "title": "The Belief-Desire-Intention Ontology for modelling mental reality and agency", "comment": null, "summary": "The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684BDI\u672c\u4f53\uff0c\u4f5c\u4e3a\u6a21\u5757\u5316\u672c\u4f53\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u6355\u6349\u667a\u80fd\u4f53\u7684\u4fe1\u5ff5\u3001\u6b32\u671b\u3001\u610f\u56fe\u53ca\u5176\u52a8\u6001\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u4e0eLLMs\u548c\u63a8\u7406\u5e73\u53f0\u7684\u96c6\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "BDI\u6a21\u578b\u662f\u4eba\u5de5\u667a\u80fd\u548c\u8ba4\u77e5\u79d1\u5b66\u4e2d\u8868\u793a\u7406\u6027\u667a\u80fd\u4f53\u7684\u57fa\u77f3\uff0c\u4f46\u5176\u4e0e\u7ed3\u6784\u5316\u3001\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u77e5\u8bc6\u8868\u793a\u7684\u6574\u5408\u4ecd\u7136\u6709\u9650\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u672c\u4f53\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u4e0e\u57fa\u7840\u672c\u4f53\u5bf9\u9f50\u786e\u4fdd\u8bed\u4e49\u7cbe\u786e\u6027\u548c\u53ef\u91cd\u7528\u6027\uff1b\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\uff1a1) \u4e0eLLMs\u901a\u8fc7\u903b\u8f91\u589e\u5f3a\u751f\u6210\u7ed3\u5408\uff1b2) \u5728Semas\u63a8\u7406\u5e73\u53f0\u4e2d\u96c6\u6210\uff0c\u5b9e\u73b0RDF\u4e09\u5143\u7ec4\u4e0e\u667a\u80fd\u4f53\u5fc3\u7406\u72b6\u6001\u7684\u53cc\u5411\u6d41\u52a8\u3002", "result": "\u5b9e\u9a8c\u8868\u660eBDI\u672c\u4f53\u5728\u58f0\u660e\u6027\u548c\u7a0b\u5e8f\u6027\u667a\u80fd\u4e4b\u95f4\u8d77\u5230\u4e86\u6982\u5ff5\u548c\u64cd\u4f5c\u6865\u6881\u4f5c\u7528\uff0c\u4e3a\u8ba4\u77e5\u57fa\u7840\u3001\u53ef\u89e3\u91ca\u548c\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u548c\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002", "conclusion": "BDI\u672c\u4f53\u80fd\u591f\u6709\u6548\u8fde\u63a5\u58f0\u660e\u6027\u548c\u7a0b\u5e8f\u6027\u667a\u80fd\uff0c\u652f\u6301\u5728\u6570\u636e\u7f51\u7edc\u4e2d\u6784\u5efa\u8ba4\u77e5\u57fa\u7840\u3001\u53ef\u89e3\u91ca\u548c\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u7684\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2511.17297", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.17297", "abs": "https://arxiv.org/abs/2511.17297", "authors": ["Julius P. J. Krebbekx", "Eder Baron-Prada", "Roland T\u00f3th", "Amritam Das"], "title": "Computing the Hard Scaled Relative Graph of LTI Systems", "comment": "8 pages", "summary": "Scaled Relative Graphs (SRGs) provide a novel graphical frequency-domain method for the analysis of nonlinear systems, where Linear Time-Invariant (LTI) systems are the fundamental building block. To analyze feedback loops with unstable LTI components, the hard SRG is required, since it aptly captures the input/output behavior on the extended $L_2$ space. In this paper, we develop a systematic computational method to exactly compute the hard SRG of LTI systems, which may be unstable and contain integrators. We also study its connection to the Nyquist criterion, including the multivariable case, and demonstrate our method on several examples.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u8ba1\u7b97\u65b9\u6cd5\u6765\u7cbe\u786e\u8ba1\u7b97LTI\u7cfb\u7edf\u7684\u786cSRG\uff0c\u5305\u62ec\u4e0d\u7a33\u5b9a\u7cfb\u7edf\u548c\u5305\u542b\u79ef\u5206\u5668\u7684\u7cfb\u7edf\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u4e0e\u5948\u594e\u65af\u7279\u51c6\u5219\u7684\u8054\u7cfb\u3002", "motivation": "\u4e3a\u4e86\u5206\u6790\u5305\u542b\u4e0d\u7a33\u5b9aLTI\u7ec4\u4ef6\u7684\u53cd\u9988\u56de\u8def\uff0c\u9700\u8981\u786cSRG\uff0c\u56e0\u4e3a\u5b83\u80fd\u6070\u5f53\u5730\u6355\u6349\u6269\u5c55L2\u7a7a\u95f4\u4e0a\u7684\u8f93\u5165/\u8f93\u51fa\u884c\u4e3a\u3002", "method": "\u5f00\u53d1\u4e86\u7cfb\u7edf\u6027\u7684\u8ba1\u7b97\u65b9\u6cd5\u6765\u7cbe\u786e\u8ba1\u7b97LTI\u7cfb\u7edf\u7684\u786cSRG\uff0c\u5305\u62ec\u4e0d\u7a33\u5b9a\u548c\u5305\u542b\u79ef\u5206\u5668\u7684\u7cfb\u7edf\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u786cSRG\u7684\u7cbe\u786e\u8ba1\u7b97\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0e\u5948\u594e\u65af\u7279\u51c6\u5219\u7684\u8054\u7cfb\uff0c\u5305\u62ec\u591a\u53d8\u91cf\u60c5\u51b5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u56fe\u5f62\u5316\u9891\u57df\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5305\u542b\u4e0d\u7a33\u5b9aLTI\u7ec4\u4ef6\u7684\u53cd\u9988\u56de\u8def\u5206\u6790\u3002"}}
{"id": "2511.17225", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17225", "abs": "https://arxiv.org/abs/2511.17225", "authors": ["Shanshan Li", "Da Huang", "Yu He", "Yanwei Fu", "Yu-Gang Jiang", "Xiangyang Xue"], "title": "TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous Decision-Making", "comment": "Accepted at NeurIPS 2025", "summary": "In daily life, people often move through spaces to find objects that meet their needs, posing a key challenge in embodied AI. Traditional Demand-Driven Navigation (DDN) handles one need at a time but does not reflect the complexity of real-world tasks involving multiple needs and personal choices. To bridge this gap, we introduce Task-Preferenced Multi-Demand-Driven Navigation (TP-MDDN), a new benchmark for long-horizon navigation involving multiple sub-demands with explicit task preferences. To solve TP-MDDN, we propose AWMSystem, an autonomous decision-making system composed of three key modules: BreakLLM (instruction decomposition), LocateLLM (goal selection), and StatusMLLM (task monitoring). For spatial memory, we design MASMap, which combines 3D point cloud accumulation with 2D semantic mapping for accurate and efficient environmental understanding. Our Dual-Tempo action generation framework integrates zero-shot planning with policy-based fine control, and is further supported by an Adaptive Error Corrector that handles failure cases in real time. Experiments demonstrate that our approach outperforms state-of-the-art baselines in both perception accuracy and navigation robustness.", "AI": {"tldr": "\u63d0\u51fa\u4e86TP-MDDN\u65b0\u57fa\u51c6\u548cAWMSystem\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u9700\u6c42\u9a71\u52a8\u7684\u957f\u65f6\u7a0b\u5bfc\u822a\u4efb\u52a1\uff0c\u901a\u8fc7\u6a21\u5757\u5316LLM\u548c\u53cc\u8282\u594f\u52a8\u4f5c\u751f\u6210\u5b9e\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5355\u9700\u6c42\u5bfc\u822a\u65e0\u6cd5\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u4e2d\u591a\u9700\u6c42\u548c\u4e2a\u6027\u5316\u9009\u62e9\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u591a\u5b50\u9700\u6c42\u5e76\u8003\u8651\u4efb\u52a1\u504f\u597d\u7684\u5bfc\u822a\u7cfb\u7edf\u3002", "method": "AWMSystem\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1aBreakLLM\uff08\u6307\u4ee4\u5206\u89e3\uff09\u3001LocateLLM\uff08\u76ee\u6807\u9009\u62e9\uff09\u3001StatusMLLM\uff08\u4efb\u52a1\u76d1\u63a7\uff09\uff0c\u7ed3\u5408MASMap\u7a7a\u95f4\u8bb0\u5fc6\u7cfb\u7edf\uff083D\u70b9\u4e91+2D\u8bed\u4e49\u5730\u56fe\uff09\u548c\u53cc\u8282\u594f\u52a8\u4f5c\u751f\u6210\u6846\u67b6\uff08\u96f6\u6837\u672c\u89c4\u5212+\u7b56\u7565\u5fae\u63a7\uff09\uff0c\u5e76\u914d\u5907\u81ea\u9002\u5e94\u9519\u8bef\u6821\u6b63\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u611f\u77e5\u7cbe\u5ea6\u548c\u5bfc\u822a\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684TP-MDDN\u57fa\u51c6\u548cAWMSystem\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u591a\u9700\u6c42\u9a71\u52a8\u7684\u957f\u65f6\u7a0b\u5bfc\u822a\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u5bfc\u822a\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17165", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17165", "abs": "https://arxiv.org/abs/2511.17165", "authors": ["Kesheng Chen", "Wenjian Luo", "Bang Zhang", "Zeping Yin", "Zipeng Ye"], "title": "MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward", "comment": null, "summary": "Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86MIR\uff08\u4e92\u60e0\u5185\u5728\u5956\u52b1\uff09\uff0c\u4e00\u79cd\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7a00\u758f\u5956\u52b1\u95ee\u9898\u7684\u589e\u5f3a\u7b56\u7565\uff0c\u901a\u8fc7\u6fc0\u52b1\u667a\u80fd\u4f53\u63a2\u7d22\u5f71\u54cd\u961f\u53cb\u7684\u884c\u4e3a\u6765\u6539\u5584\u56e2\u961f\u63a2\u7d22\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7a00\u758f\u5956\u52b1\uff08\u7279\u522b\u662f\u60c5\u8282\u5956\u52b1\uff09\u5e26\u6765\u7684\u6311\u6218\uff0c\u5305\u62ec\u8054\u5408\u52a8\u4f5c\u8f68\u8ff9\u7684\u6307\u6570\u7ea7\u7a00\u758f\u6027\u548c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u5f71\u54cd\u56e2\u961f\u72b6\u6001\u7684\u8054\u5408\u52a8\u4f5c\u3002", "method": "\u63d0\u51faMIR\u65b9\u6cd5\uff0c\u6fc0\u52b1\u4e2a\u4f53\u667a\u80fd\u4f53\u63a2\u7d22\u80fd\u591f\u5f71\u54cd\u961f\u53cb\u7684\u52a8\u4f5c\uff0c\u7ed3\u5408\u539f\u59cb\u7b56\u7565\u6709\u6548\u523a\u6fc0\u56e2\u961f\u63a2\u7d22\u3002\u521b\u5efa\u4e86MiniGrid-MA\u73af\u5883\u7528\u4e8e\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728MiniGrid-MA\u73af\u5883\u4e2d\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eMIR\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "MIR\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u7b56\u7565\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e0b\u7684\u7b97\u6cd5\u6027\u80fd\u3002"}}
{"id": "2511.17433", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17433", "abs": "https://arxiv.org/abs/2511.17433", "authors": ["Abdallah Alalem Albustami", "Ahmad F. Taha"], "title": "The Iberian Blackout: A Black Swan or a Gray Rhino? A Thorough Power System Analysis", "comment": null, "summary": "On April 28, 2025, the Iberian power system suffered a full blackout. It was the first documented overvoltage-driven cascade in Europe. The event sparked debate about root causes, including high renewables output, low inertia, and operator actions. This paper presents a thorough power system analysis of the incident to sort signal from noise and explain, step by step, how the blackout unfolded. Specifically, we (i) reconstruct the timeline and causal chain of the incident, (ii) present and summarize contributing factors using factual findings from incident reports, (iii) reproduce the blackout on an IEEE test system, (iv) analyze the incident from a system-theoretic, voltage-control perspective, and (v) translate our analysis into practical, technical measures that aim to mitigate and prevent similar incidents.", "AI": {"tldr": "\u5bf92025\u5e744\u670828\u65e5\u4f0a\u6bd4\u5229\u4e9a\u7535\u7f51\u5168\u9ed1\u4e8b\u6545\u7684\u6df1\u5165\u5206\u6790\uff0c\u8fd9\u662f\u6b27\u6d32\u9996\u4e2a\u6709\u8bb0\u5f55\u7684\u8fc7\u7535\u538b\u9a71\u52a8\u7ea7\u8054\u6545\u969c\uff0c\u63a2\u8ba8\u4e86\u9ad8\u53ef\u518d\u751f\u80fd\u6e90\u8f93\u51fa\u3001\u4f4e\u60ef\u91cf\u548c\u64cd\u4f5c\u5458\u884c\u52a8\u7b49\u6839\u672c\u539f\u56e0\u3002", "motivation": "\u8be5\u4e8b\u6545\u5f15\u53d1\u4e86\u5173\u4e8e\u6839\u672c\u539f\u56e0\u7684\u4e89\u8bba\uff0c\u5305\u62ec\u9ad8\u53ef\u518d\u751f\u80fd\u6e90\u8f93\u51fa\u3001\u4f4e\u60ef\u91cf\u548c\u64cd\u4f5c\u5458\u884c\u52a8\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u5398\u6e05\u4fe1\u53f7\u4e0e\u566a\u58f0\uff0c\u9010\u6b65\u89e3\u91ca\u505c\u7535\u8fc7\u7a0b\u3002", "method": "\u91cd\u6784\u4e8b\u6545\u65f6\u95f4\u7ebf\u548c\u56e0\u679c\u94fe\uff1b\u603b\u7ed3\u4e8b\u6545\u62a5\u544a\u4e2d\u7684\u5173\u952e\u56e0\u7d20\uff1b\u5728IEEE\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u91cd\u73b0\u4e8b\u6545\uff1b\u4ece\u7cfb\u7edf\u7406\u8bba\u548c\u7535\u538b\u63a7\u5236\u89d2\u5ea6\u5206\u6790\uff1b\u63d0\u51fa\u5b9e\u9645\u6280\u672f\u63aa\u65bd\u3002", "result": "\u6210\u529f\u91cd\u73b0\u4e86\u8fc7\u7535\u538b\u9a71\u52a8\u7684\u7ea7\u8054\u6545\u969c\u8fc7\u7a0b\uff0c\u8bc6\u522b\u4e86\u5bfc\u81f4\u4e8b\u6545\u7684\u5173\u952e\u56e0\u7d20\u548c\u7cfb\u7edf\u8106\u5f31\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u6280\u672f\u63aa\u65bd\u6765\u51cf\u8f7b\u548c\u9884\u9632\u7c7b\u4f3c\u4e8b\u6545\uff0c\u5f3a\u8c03\u4e86\u7cfb\u7edf\u7535\u538b\u63a7\u5236\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.17237", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17237", "abs": "https://arxiv.org/abs/2511.17237", "authors": ["Alessio Saccuti", "Riccardo Monica", "Jacopo Aleotti"], "title": "A ROS2 Interface for Universal Robots Collaborative Manipulators Based on ur_rtde", "comment": null, "summary": "In this paper a novel ROS2 driver for UR robot manipulators is presented, based on the ur_rtde C++ library. The proposed driver aims to be a flexible solution, adaptable to a wide range of applications. The driver exposes the high-level commands of Universal Robots URScripts, and custom commands can be added using a plugin system. Several commands have been implemented, including motion execution along a waypoint-based path. The driver is published as open source.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eur_rtde C++\u5e93\u7684\u65b0\u578bROS2\u9a71\u52a8\uff0c\u7528\u4e8eUR\u673a\u5668\u4eba\uff0c\u652f\u6301\u63d2\u4ef6\u7cfb\u7edf\u6dfb\u52a0\u81ea\u5b9a\u4e49\u547d\u4ee4\u3002", "motivation": "\u4e3aUR\u673a\u5668\u4eba\u63d0\u4f9b\u7075\u6d3b\u3001\u53ef\u9002\u5e94\u591a\u79cd\u5e94\u7528\u7684ROS2\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8eur_rtde C++\u5e93\u5f00\u53d1\uff0c\u66b4\u9732URScripts\u9ad8\u7ea7\u547d\u4ee4\uff0c\u91c7\u7528\u63d2\u4ef6\u7cfb\u7edf\u652f\u6301\u81ea\u5b9a\u4e49\u547d\u4ee4\u6269\u5c55\u3002", "result": "\u5b9e\u73b0\u4e86\u591a\u79cd\u547d\u4ee4\uff0c\u5305\u62ec\u57fa\u4e8e\u8def\u5f84\u70b9\u7684\u8fd0\u52a8\u6267\u884c\uff0c\u5e76\u4f5c\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u53d1\u5e03\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u529f\u80fd\u4e30\u5bcc\u3001\u53ef\u6269\u5c55\u7684UR\u673a\u5668\u4ebaROS2\u9a71\u52a8\uff0c\u4e3a\u673a\u5668\u4eba\u5e94\u7528\u5f00\u53d1\u63d0\u4f9b\u4e86\u4fbf\u5229\u3002"}}
{"id": "2511.17198", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17198", "abs": "https://arxiv.org/abs/2511.17198", "authors": ["Kaiyu Li", "Jiayu Wang", "Zhi Wang", "Hui Qiao", "Weizhan Zhang", "Deyu Meng", "Xiangyong Cao"], "title": "Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism", "comment": "Page: https://earth-insights.github.io/EarthAgent", "summary": "LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5206\u5c42\u4efb\u52a1\u62bd\u8c61\u673a\u5236(HTAM)\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6EarthAgent\uff0c\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3\u9065\u611f\u7b49\u4e13\u4e1a\u9886\u57df\u4e2d\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7684\u6311\u6218\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u7684LLM\u9a71\u52a8\u667a\u80fd\u4f53\uff08\u5982ReAct\u6216\u57fa\u4e8e\u89d2\u8272\u626e\u6f14\u7684\u65b9\u6cd5\uff09\u5728\u9700\u8981\u4e25\u683c\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7684\u4e13\u4e1a\u9886\u57df\uff08\u5982\u9065\u611f\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e9b\u9886\u57df\u9700\u8981\u4e13\u95e8\u7684\u5de5\u5177\u548c\u591a\u6b65\u9aa4\u7a0b\u5e8f\u3002", "method": "\u5f15\u5165\u5206\u5c42\u4efb\u52a1\u62bd\u8c61\u673a\u5236(HTAM)\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6784\u5efa\u4e3a\u903b\u8f91\u5c42\u6b21\u7ed3\u6784\uff0c\u53cd\u6620\u9886\u57df\u5185\u5728\u7684\u4efb\u52a1\u4f9d\u8d56\u56fe\uff0c\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u987a\u5e8f\u5c42\uff0c\u6bcf\u5c42\u5b50\u667a\u80fd\u4f53\u57fa\u4e8e\u524d\u4e00\u5c42\u8f93\u51fa\u8fdb\u884c\u64cd\u4f5c\u3002", "result": "\u5728GeoPlan-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEarthAgent\u5728\u5de5\u5177\u9009\u62e9\u3001\u8def\u5f84\u76f8\u4f3c\u6027\u548c\u903b\u8f91\u5b8c\u6574\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "conclusion": "\u5c06\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u9886\u57df\u5185\u5728\u4efb\u52a1\u7ed3\u6784\u5bf9\u9f50\u662f\u6784\u5efa\u7a33\u5065\u53ef\u9760\u7684\u4e13\u4e1a\u81ea\u4e3b\u7cfb\u7edf\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2511.17436", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.17436", "abs": "https://arxiv.org/abs/2511.17436", "authors": ["Seth Siriya", "Jingge Zhu", "Dragan Ne\u0161i\u0107", "Ye Pu"], "title": "A Framework for Adaptive Stabilisation of Nonlinear Stochastic Systems", "comment": "22 pages, 1 figure", "summary": "We consider the adaptive control problem for discrete-time, nonlinear stochastic systems with linearly parameterised uncertainty. Assuming access to a parameterised family of controllers that can stabilise the system in a bounded set within an informative region of the state space when the parameter is well-chosen, we propose a certainty equivalence learning-based adaptive control strategy, and subsequently derive stability bounds on the closed-loop system that hold for some probabilities. We then show that if the entire state space is informative, and the family of controllers is globally stabilising with appropriately chosen parameters, high probability stability guarantees can be derived.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u786e\u5b9a\u6027\u7b49\u4ef7\u5b66\u4e60\u65b9\u6cd5\u7684\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\uff0c\u7528\u4e8e\u79bb\u6563\u65f6\u95f4\u975e\u7ebf\u6027\u968f\u673a\u7cfb\u7edf\uff0c\u5e76\u5728\u67d0\u4e9b\u6982\u7387\u4e0b\u63a8\u5bfc\u95ed\u73af\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u8fb9\u754c\u3002", "motivation": "\u89e3\u51b3\u79bb\u6563\u65f6\u95f4\u975e\u7ebf\u6027\u968f\u673a\u7cfb\u7edf\u4e2d\u7ebf\u6027\u53c2\u6570\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u81ea\u9002\u5e94\u63a7\u5236\u95ee\u9898\uff0c\u9700\u8981\u5728\u72b6\u6001\u7a7a\u95f4\u7684\u4fe1\u606f\u533a\u57df\u5185\u9009\u62e9\u5408\u9002\u7684\u63a7\u5236\u5668\u53c2\u6570\u6765\u7a33\u5b9a\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u786e\u5b9a\u6027\u7b49\u4ef7\u5b66\u4e60\u65b9\u6cd5\uff0c\u57fa\u4e8e\u53c2\u6570\u5316\u63a7\u5236\u5668\u5bb6\u65cf\uff0c\u5f53\u53c2\u6570\u9009\u62e9\u6070\u5f53\u65f6\u80fd\u5728\u72b6\u6001\u7a7a\u95f4\u7684\u6709\u754c\u96c6\u5185\u7a33\u5b9a\u7cfb\u7edf\u3002", "result": "\u63a8\u5bfc\u51fa\u5728\u67d0\u4e9b\u6982\u7387\u4e0b\u6210\u7acb\u7684\u95ed\u73af\u7cfb\u7edf\u7a33\u5b9a\u6027\u8fb9\u754c\uff0c\u5f53\u6574\u4e2a\u72b6\u6001\u7a7a\u95f4\u90fd\u5177\u6709\u4fe1\u606f\u6027\u4e14\u63a7\u5236\u5668\u5bb6\u65cf\u5177\u6709\u5168\u5c40\u7a33\u5b9a\u6027\u65f6\uff0c\u53ef\u83b7\u5f97\u9ad8\u6982\u7387\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\u80fd\u591f\u4e3a\u975e\u7ebf\u6027\u968f\u673a\u7cfb\u7edf\u63d0\u4f9b\u6982\u7387\u6027\u7a33\u5b9a\u6027\u4fdd\u8bc1\uff0c\u7279\u522b\u662f\u5728\u5168\u5c40\u4fe1\u606f\u6027\u6761\u4ef6\u4e0b\u53ef\u83b7\u5f97\u9ad8\u6982\u7387\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.17266", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17266", "abs": "https://arxiv.org/abs/2511.17266", "authors": ["Leone Costi", "Dario Izzo"], "title": "Simulation of Active Soft Nets for Capture of Space Debris", "comment": null, "summary": "In this work, we propose a simulator, based on the open-source physics engine MuJoCo, for the design and control of soft robotic nets for the autonomous removal of space debris. The proposed simulator includes net dynamics, contact between the net and the debris, self-contact of the net, orbital mechanics, and a controller that can actuate thrusters on the four satellites at the corners of the net. It showcases the case of capturing Envisat, a large ESA satellite that remains in orbit as space debris following the end of its mission. This work investigates different mechanical models, which can be used to simulate the net dynamics, simulating various degrees of compliance, and different control strategies to achieve the capture of the debris, depending on the relative position of the net and the target. Unlike previous works on this topic, we do not assume that the net has been previously ballistically thrown toward the target, and we start from a relatively static configuration. The results show that a more compliant net achieves higher performance when attempting the capture of Envisat. Moreover, when paired with a sliding mode controller, soft nets are able to achieve successful capture in 100% of the tested cases, whilst also showcasing a higher effective area at contact and a higher number of contact points between net and Envisat.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8eMuJoCo\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u7f51\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u7a7a\u95f4\u788e\u7247\u81ea\u4e3b\u6e05\u9664\uff0c\u6210\u529f\u6f14\u793a\u6355\u83b7Envisat\u536b\u661f\uff0c\u53d1\u73b0\u67d4\u6027\u7f51\u914d\u5408\u6ed1\u6a21\u63a7\u5236\u5668\u53ef\u5b9e\u73b0100%\u6355\u83b7\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u7a7a\u95f4\u788e\u7247\u6e05\u9664\u95ee\u9898\uff0c\u7279\u522b\u662f\u6355\u83b7\u5927\u578b\u5e9f\u5f03\u536b\u661f\u5982Envisat\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u7f51\u6355\u83b7\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528MuJoCo\u7269\u7406\u5f15\u64ce\u6784\u5efa\u6a21\u62df\u5668\uff0c\u5305\u542b\u7f51\u52a8\u529b\u5b66\u3001\u63a5\u89e6\u6a21\u578b\u3001\u8f68\u9053\u529b\u5b66\u548c\u63a7\u5236\u5668\uff0c\u7814\u7a76\u4e0d\u540c\u673a\u68b0\u6a21\u578b\u548c\u67d4\u6027\u7a0b\u5ea6\u7684\u7f51\uff0c\u91c7\u7528\u6ed1\u6a21\u63a7\u5236\u7b56\u7565\u3002", "result": "\u67d4\u6027\u7f51\u6027\u80fd\u66f4\u4f18\uff0c\u914d\u5408\u6ed1\u6a21\u63a7\u5236\u5668\u5728\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u5b9e\u73b0100%\u6355\u83b7\u6210\u529f\u7387\uff0c\u63a5\u89e6\u9762\u79ef\u548c\u63a5\u89e6\u70b9\u6570\u91cf\u4e5f\u66f4\u9ad8\u3002", "conclusion": "\u67d4\u6027\u8f6f\u4f53\u673a\u5668\u4eba\u7f51\u7ed3\u5408\u6ed1\u6a21\u63a7\u5236\u662f\u7a7a\u95f4\u788e\u7247\u6355\u83b7\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2511.17332", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.17332", "abs": "https://arxiv.org/abs/2511.17332", "authors": ["Virginia Dignum", "Frank Dignum"], "title": "Agentifying Agentic AI", "comment": "10 pages; 1 figure", "summary": "Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5c06AAMAS\u793e\u533a\u5f00\u53d1\u7684BDI\u67b6\u6784\u3001\u901a\u4fe1\u534f\u8bae\u3001\u673a\u5236\u8bbe\u8ba1\u548c\u5236\u5ea6\u5efa\u6a21\u7b49\u6982\u5ff5\u5de5\u5177\u4f5c\u4e3a\u667a\u80fd\u4f53AI\u7684\u57fa\u7840\uff0c\u4ee5\u6784\u5efa\u65e2\u5177\u5907\u80fd\u529b\u53c8\u900f\u660e\u3001\u5408\u4f5c\u548c\u53ef\u95ee\u8d23\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "motivation": "\u667a\u80fd\u4f53AI\u9700\u8981\u6301\u7eed\u81ea\u4e3b\u6027\u3001\u63a8\u7406\u548c\u4ea4\u4e92\u80fd\u529b\uff0c\u8fd9\u8981\u6c42\u660e\u786e\u5efa\u6a21\u8ba4\u77e5\u3001\u5408\u4f5c\u548c\u6cbb\u7406\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7ed3\u6784\u5316\u6a21\u578b\u6765\u786e\u4fdd\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u6027\u3002", "method": "\u5c06\u81ea\u9002\u5e94\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u548c\u534f\u8c03\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u5229\u7528BDI\u67b6\u6784\u3001\u901a\u4fe1\u534f\u8bae\u3001\u673a\u5236\u8bbe\u8ba1\u548c\u5236\u5ea6\u5efa\u6a21\u7b49AAMAS\u6982\u5ff5\u5de5\u5177\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fde\u63a5\u5f62\u5f0f\u7406\u8bba\u548c\u5b9e\u8df5\u81ea\u4e3b\u6027\u7684\u667a\u80fd\u4f53\u89c6\u89d2\uff0c\u4e3a\u6784\u5efa\u80fd\u529b\u5f3a\u5927\u4e14\u7075\u6d3b\u3001\u540c\u65f6\u5177\u5907\u900f\u660e\u6027\u3001\u5408\u4f5c\u6027\u548c\u53ef\u95ee\u8d23\u6027\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "AAMAS\u793e\u533a\u7684\u6982\u5ff5\u5de5\u5177\u4e3a\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u7406\u8bba\u57fa\u7840\uff0c\u80fd\u591f\u5b9e\u73b0\u5f62\u5f0f\u7406\u8bba\u4e0e\u5b9e\u9645\u81ea\u4e3b\u6027\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u63a8\u52a8\u667a\u80fd\u4f53\u7cfb\u7edf\u5411\u66f4\u8d1f\u8d23\u4efb\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2511.17276", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17276", "abs": "https://arxiv.org/abs/2511.17276", "authors": ["Julien Merand", "Boris Meden", "Mathieu Grossard"], "title": "Leveraging CVAE for Joint Configuration Estimation of Multifingered Grippers from Point Cloud Data", "comment": null, "summary": "This paper presents an efficient approach for determining the joint configuration of a multifingered gripper solely from the point cloud data of its poly-articulated chain, as generated by visual sensors, simulations or even generative neural networks. Well-known inverse kinematics (IK) techniques can provide mathematically exact solutions (when they exist) for joint configuration determination based solely on the fingertip pose, but often require post-hoc decision-making by considering the positions of all intermediate phalanges in the gripper's fingers, or rely on algorithms to numerically approximate solutions for more complex kinematics. In contrast, our method leverages machine learning to implicitly overcome these challenges. This is achieved through a Conditional Variational Auto-Encoder (CVAE), which takes point cloud data of key structural elements as input and reconstructs the corresponding joint configurations. We validate our approach on the MultiDex grasping dataset using the Allegro Hand, operating within 0.05 milliseconds and achieving accuracy comparable to state-of-the-art methods. This highlights the effectiveness of our pipeline for joint configuration estimation within the broader context of AI-driven techniques for grasp planning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08CVAE\uff09\u7684\u65b9\u6cd5\uff0c\u4ec5\u4ece\u591a\u6307\u6293\u624b\u7684\u70b9\u4e91\u6570\u636e\u4e2d\u9ad8\u6548\u786e\u5b9a\u5173\u8282\u914d\u7f6e\uff0c\u57280.05\u6beb\u79d2\u5185\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u9006\u8fd0\u52a8\u5b66\u65b9\u6cd5\u9700\u8981\u57fa\u4e8e\u6307\u5c16\u4f4d\u59ff\u8fdb\u884c\u540e\u9a8c\u51b3\u7b56\u6216\u6570\u503c\u8fd1\u4f3c\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u8fd0\u52a8\u5b66\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u9690\u5f0f\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08CVAE\uff09\uff0c\u4ee5\u5173\u952e\u7ed3\u6784\u5143\u7d20\u7684\u70b9\u4e91\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\uff0c\u91cd\u5efa\u76f8\u5e94\u7684\u5173\u8282\u914d\u7f6e\u3002", "result": "\u5728MultiDex\u6293\u53d6\u6570\u636e\u96c6\u4e0a\u4f7f\u7528Allegro Hand\u8fdb\u884c\u9a8c\u8bc1\uff0c\u8fd0\u884c\u65f6\u95f4\u57280.05\u6beb\u79d2\u5185\uff0c\u7cbe\u5ea6\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728AI\u9a71\u52a8\u7684\u6293\u53d6\u89c4\u5212\u6280\u672f\u80cc\u666f\u4e0b\uff0c\u4e3a\u5173\u8282\u914d\u7f6e\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17408", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17408", "abs": "https://arxiv.org/abs/2511.17408", "authors": ["Nathalie Kirch", "Samuel Dower", "Adrians Skapars", "Ekdeep Singh Lubana", "Dmitrii Krasheninnikov"], "title": "That's not natural: The Impact of Off-Policy Training Data on Probe Performance", "comment": "10 pages, EurIPS 2025 Workshop on Private AI Governance", "summary": "Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.", "AI": {"tldr": "\u8bc4\u4f30\u4e86\u4f7f\u7528\u5408\u6210\u548c\u79bb\u7b56\u7565\u6570\u636e\u5bf9LLM\u884c\u4e3a\u63a2\u6d4b\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u54cd\u5e94\u751f\u6210\u7b56\u7565\u663e\u8457\u5f71\u54cd\u63a2\u6d4b\u6027\u80fd\uff0c\u79bb\u7b56\u7565\u5230\u540c\u7b56\u7565\u7684\u6cdb\u5316\u6210\u529f\u53ef\u9884\u6d4b\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u597d\u5904\u7406\u5206\u5e03\u504f\u79fb\u7684\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u8bb8\u591a\u884c\u4e3a\u7684\u81ea\u7136\u6837\u672c\u7a00\u5c11\uff0c\u7814\u7a76\u4eba\u5458\u4e0d\u5f97\u4e0d\u4f9d\u8d56\u5408\u6210\u6216\u79bb\u7b56\u7565\u7684LLM\u54cd\u5e94\u6765\u8bad\u7ec3\u63a2\u6d4b\u6a21\u578b\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u4e9b\u6570\u636e\u5bf9\u63a2\u6d4b\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u5728\u516b\u79cd\u4e0d\u540c\u7684LLM\u884c\u4e3a\u4e0a\u6d4b\u8bd5\u7ebf\u6027\u548c\u6ce8\u610f\u529b\u63a2\u6d4b\u6a21\u578b\uff0c\u4f7f\u7528\u5408\u6210\u548c\u79bb\u7b56\u7565\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u8bc4\u4f30\u5176\u5728\u4e0d\u540c\u7b56\u7565\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6cdb\u5316\u6027\u80fd\u3002", "result": "\u54cd\u5e94\u751f\u6210\u7b56\u7565\u663e\u8457\u5f71\u54cd\u63a2\u6d4b\u6027\u80fd\uff0c\u79bb\u7b56\u7565\u5230\u540c\u7b56\u7565\u7684\u6cdb\u5316\u6210\u529f\u53ef\u9884\u6d4b\u771f\u5b9e\u573a\u666f\u8868\u73b0\uff1b\u8bad\u7ec3\u6570\u636e\u57df\u7684\u504f\u79fb\u4f1a\u5bfc\u81f4\u66f4\u5927\u7684\u6027\u80fd\u4e0b\u964d\uff1b\u4f7f\u7528\u540c\u57df\u79bb\u7b56\u7565\u6570\u636e\u6bd4\u4e0d\u540c\u57df\u540c\u7b56\u7565\u6570\u636e\u4ea7\u751f\u66f4\u53ef\u9760\u7684\u63a2\u6d4b\u3002", "conclusion": "\u5728\u7f3a\u4e4f\u540c\u7b56\u7565\u6570\u636e\u65f6\uff0c\u4f7f\u7528\u540c\u57df\u79bb\u7b56\u7565\u6570\u636e\u6bd4\u4f7f\u7528\u4e0d\u540c\u57df\u7684\u540c\u7b56\u7565\u6570\u636e\u80fd\u4ea7\u751f\u66f4\u53ef\u9760\u7684\u63a2\u6d4b\u6a21\u578b\uff0c\u5f3a\u8c03\u9700\u8981\u5f00\u53d1\u80fd\u66f4\u597d\u5904\u7406LLM\u76d1\u63a7\u4e2d\u5206\u5e03\u504f\u79fb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.17299", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17299", "abs": "https://arxiv.org/abs/2511.17299", "authors": ["Tom\u00e1\u0161 Musil", "Mat\u011bj Petrl\u00edk", "Martin Saska"], "title": "MonoSpheres: Large-Scale Monocular SLAM-Based UAV Exploration through Perception-Coupled Mapping and Planning", "comment": "8 pages, 9 figures, submitted to RA-L", "summary": "Autonomous exploration of unknown environments is a key capability for mobile robots, but it is largely unsolved for robots equipped with only a single monocular camera and no dense range sensors. In this paper, we present a novel approach to monocular vision-based exploration that can safely cover large-scale unstructured indoor and outdoor 3D environments by explicitly accounting for the properties of a sparse monocular SLAM frontend in both mapping and planning. The mapping module solves the problems of sparse depth data, free-space gaps, and large depth uncertainty by oversampling free space in texture-sparse areas and keeping track of obstacle position uncertainty. The planning module handles the added free-space uncertainty through rapid replanning and perception-aware heading control. We further show that frontier-based exploration is possible with sparse monocular depth data when parallax requirements and the possibility of textureless surfaces are taken into account. We evaluate our approach extensively in diverse real-world and simulated environments, including ablation studies. To the best of the authors' knowledge, the proposed method is the first to achieve 3D monocular exploration in real-world unstructured outdoor environments. We open-source our implementation to support future research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u76ee\u89c6\u89c9\u7684\u81ea\u4e3b\u63a2\u7d22\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u65e0\u7a20\u5bc6\u8ddd\u79bb\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u5b89\u5168\u8986\u76d6\u5927\u89c4\u6a21\u975e\u7ed3\u6784\u5316\u5ba4\u5185\u59163D\u73af\u5883\u3002", "motivation": "\u89e3\u51b3\u4ec5\u914d\u5907\u5355\u76ee\u76f8\u673a\u7684\u79fb\u52a8\u673a\u5668\u4eba\u5728\u672a\u77e5\u73af\u5883\u4e2d\u81ea\u4e3b\u63a2\u7d22\u7684\u95ee\u9898\uff0c\u8fd9\u662f\u76ee\u524d\u5c1a\u672a\u5b8c\u5168\u89e3\u51b3\u7684\u5173\u952e\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u663e\u5f0f\u8003\u8651\u7a00\u758f\u5355\u76eeSLAM\u524d\u7aef\u7684\u7279\u6027\uff0c\u5728\u6620\u5c04\u548c\u89c4\u5212\u4e2d\u5904\u7406\u7a00\u758f\u6df1\u5ea6\u6570\u636e\u3001\u81ea\u7531\u7a7a\u95f4\u95f4\u9699\u548c\u6df1\u5ea6\u4e0d\u786e\u5b9a\u6027\u3002\u6620\u5c04\u6a21\u5757\u901a\u8fc7\u8fc7\u91c7\u6837\u7eb9\u7406\u7a00\u758f\u533a\u57df\u7684\u81ea\u7531\u7a7a\u95f4\u5e76\u8ddf\u8e2a\u969c\u788d\u7269\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\u6765\u89e3\u51b3\u95ee\u9898\uff1b\u89c4\u5212\u6a21\u5757\u901a\u8fc7\u5feb\u901f\u91cd\u89c4\u5212\u548c\u611f\u77e5\u611f\u77e5\u7684\u822a\u5411\u63a7\u5236\u6765\u5904\u7406\u589e\u52a0\u7684\u81ea\u7531\u7a7a\u95f4\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u771f\u5b9e\u4e16\u754c\u548c\u6a21\u62df\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5305\u62ec\u6d88\u878d\u7814\u7a76\u3002\u636e\u4f5c\u8005\u6240\u77e5\uff0c\u8fd9\u662f\u9996\u4e2a\u5728\u771f\u5b9e\u4e16\u754c\u975e\u7ed3\u6784\u5316\u5ba4\u5916\u73af\u5883\u4e2d\u5b9e\u73b03D\u5355\u76ee\u63a2\u7d22\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728\u8003\u8651\u89c6\u5dee\u8981\u6c42\u548c\u65e0\u7eb9\u7406\u8868\u9762\u53ef\u80fd\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u57fa\u4e8e\u7a00\u758f\u5355\u76ee\u6df1\u5ea6\u6570\u636e\u7684\u8fb9\u754c\u63a2\u7d22\u662f\u53ef\u884c\u7684\u3002\u5f00\u6e90\u4e86\u5b9e\u73b0\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2511.17461", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17461", "abs": "https://arxiv.org/abs/2511.17461", "authors": ["Jiaxi Liu", "Chengyuan Ma", "Hang Zhou", "Weizhe Tang", "Shixiao Liang", "Haoyang Ding", "Xiaopeng Li", "Bin Ran"], "title": "SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception", "comment": null, "summary": "Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.", "AI": {"tldr": "\u63d0\u51faSRA-CP\u6846\u67b6\uff0c\u901a\u8fc7\u98ce\u9669\u611f\u77e5\u7684\u9009\u62e9\u6027\u534f\u4f5c\u611f\u77e5\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u5173\u952e\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5e26\u5bbd\u9700\u6c42", "motivation": "\u73b0\u6709\u901a\u7528\u534f\u4f5c\u611f\u77e5\u65b9\u6cd5\u9700\u8981\u4f20\u8f93\u5927\u91cf\u4e0e\u9a7e\u9a76\u5b89\u5168\u65e0\u5173\u7684\u611f\u77e5\u6570\u636e\uff0c\u8d85\u51fa\u53ef\u7528\u901a\u4fe1\u5e26\u5bbd\uff0c\u4e14\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u901a\u4fe1\u4f19\u4f34\uff0c\u4e0d\u9002\u5408\u52a8\u6001\u4ea4\u901a\u73af\u5883", "method": "\u53bb\u4e2d\u5fc3\u5316\u534f\u8bae\uff0c\u8f66\u8f86\u6301\u7eed\u5e7f\u64ad\u8f7b\u91cf\u7ea7\u611f\u77e5\u8986\u76d6\u6458\u8981\uff0c\u4ec5\u5728\u68c0\u6d4b\u5230\u98ce\u9669\u76f8\u5173\u76f2\u533a\u65f6\u542f\u52a8\u9488\u5bf9\u6027\u534f\u4f5c\uff1b\u5305\u542b\u611f\u77e5\u98ce\u9669\u8bc6\u522b\u6a21\u5757\u548c\u9009\u62e9\u6027\u4fe1\u606f\u4ea4\u6362\u878d\u5408\u6a21\u5757", "result": "\u76f8\u6bd4\u901a\u7528CP\u65b9\u6cd5\uff0c\u5b89\u5168\u5173\u952e\u5bf9\u8c61\u5e73\u5747\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e1%\uff0c\u4ec5\u4f7f\u752820%\u901a\u4fe1\u5e26\u5bbd\uff1b\u76f8\u6bd4\u73b0\u6709\u9009\u62e9\u6027CP\u65b9\u6cd5\uff0c\u611f\u77e5\u6027\u80fd\u63d0\u534715%", "conclusion": "SRA-CP\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u534f\u4f5c\u611f\u77e5\u4e2d\u7684\u901a\u4fe1\u5e26\u5bbd\u548c\u52a8\u6001\u73af\u5883\u9002\u5e94\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u98ce\u9669\u611f\u77e5\u9009\u62e9\u6027\u534f\u4f5c"}}
{"id": "2511.17318", "categories": ["cs.RO", "cs.AI", "cs.CE", "cs.LG", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2511.17318", "abs": "https://arxiv.org/abs/2511.17318", "authors": ["Mikael Lundb\u00e4ck", "Erik Wallin", "Carola H\u00e4ggstr\u00f6m", "Mattias Nystr\u00f6m", "Andreas Gr\u00f6nlund", "Mats Richardson", "Petrus J\u00f6nsson", "William Arnvik", "Lucas Hedstr\u00f6m", "Arvid F\u00e4lldin", "Martin Servin"], "title": "FORWARD: Dataset of a forwarder operating in rough terrain", "comment": "25 pages, 22 figures", "summary": "We present FORWARD, a high-resolution multimodal dataset of a cut-to-length forwarder operating in rough terrain on two harvest sites in the middle part of Sweden. The forwarder is a large Komatsu model equipped with a variety of sensors, including RTK-GNSS, 360-camera, operator vibration sensors, internal CAN-bus signal recording, and multiple IMUs. The data includes event time logs recorded in 5 Hz with e.g., driving speed, fuel consumption, vehicle position with centimeter accuracy, and crane use while the vehicle operates in forest areas laser-scanned with very high-resolution, $\\sim$1500 points per square meter. Production log files (StanForD standard) with time-stamped machine events, extensive video material, and terrain data in various formats are included as well. About 18 hours of regular wood extraction work during three days is annotated from 360-video material into individual work elements and included in the dataset. We also include scenario specifications of conducted experiments on forest roads and in terrain. Scenarios include repeatedly driving the same routes with and without steel tracks, different load weight, and different target driving speeds. The dataset is intended for developing models and algorithms for trafficability, perception, and autonomous control of forest machines using artificial intelligence, simulation, and experiments on physical testbeds. In part, we focus on forwarders traversing terrain, avoiding obstacles, and loading or unloading logs, with consideration for efficiency, fuel consumption, safety, and environmental impact. Other benefits of the open dataset include the ability to explore auto-generation and calibration of forestry machine simulators and automation scenario descriptions using the data recorded in the field.", "AI": {"tldr": "FORWARD\u6570\u636e\u96c6\uff1a\u5305\u542b\u745e\u5178\u4e2d\u90e8\u4e24\u4e2a\u91c7\u4f10\u573a\u5730\u7684\u8f6e\u5f0f\u96c6\u6750\u673a\u5728\u5d0e\u5c96\u5730\u5f62\u4e2d\u4f5c\u4e1a\u7684\u9ad8\u5206\u8fa8\u7387\u591a\u6a21\u6001\u6570\u636e\uff0c\u7528\u4e8e\u5f00\u53d1\u6797\u4e1a\u673a\u68b0\u7684\u53ef\u901a\u884c\u6027\u3001\u611f\u77e5\u548c\u81ea\u4e3b\u63a7\u5236\u6a21\u578b\u3002", "motivation": "\u4e3a\u5f00\u53d1\u6797\u4e1a\u673a\u68b0\u7684\u4eba\u5de5\u667a\u80fd\u3001\u4eff\u771f\u548c\u7269\u7406\u6d4b\u8bd5\u6a21\u578b\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u91cd\u70b9\u5173\u6ce8\u53ef\u901a\u884c\u6027\u3001\u611f\u77e5\u548c\u81ea\u4e3b\u63a7\u5236\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u914d\u5907RTK-GNSS\u3001360\u5ea6\u76f8\u673a\u3001\u632f\u52a8\u4f20\u611f\u5668\u3001CAN\u603b\u7ebf\u4fe1\u53f7\u8bb0\u5f55\u548c\u591a\u4e2aIMU\u7684\u5927\u578bKomatsu\u96c6\u6750\u673a\uff0c\u5728\u6fc0\u5149\u626b\u63cf\u7684\u9ad8\u5206\u8fa8\u7387\u5730\u5f62\u4e0a\u6536\u96c6\u6570\u636e\uff0c\u5305\u62ec18\u5c0f\u65f6\u7684\u4f5c\u4e1a\u89c6\u9891\u6807\u6ce8\u548c\u573a\u666f\u5b9e\u9a8c\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b\u5398\u7c73\u7ea7\u7cbe\u5ea6\u8f66\u8f86\u4f4d\u7f6e\u3001\u71c3\u6599\u6d88\u8017\u3001\u8d77\u91cd\u673a\u4f7f\u7528\u7b49\u8be6\u7ec6\u6570\u636e\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e0d\u540c\u8d1f\u8f7d\u91cd\u91cf\u3001\u76ee\u6807\u901f\u5ea6\u548c\u88c5\u5907\u914d\u7f6e\u7684\u91cd\u590d\u8def\u7ebf\u5b9e\u9a8c\u3002", "conclusion": "\u8be5\u5f00\u653e\u6570\u636e\u96c6\u4e3a\u6797\u4e1a\u673a\u68b0\u7684\u4eff\u771f\u5668\u81ea\u52a8\u751f\u6210\u4e0e\u6821\u51c6\u3001\u81ea\u52a8\u5316\u573a\u666f\u63cf\u8ff0\u4ee5\u53caAI\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u4f5c\u4e1a\u6548\u7387\u3001\u964d\u4f4e\u71c3\u6599\u6d88\u8017\u5e76\u51cf\u5c11\u73af\u5883\u5f71\u54cd\u3002"}}
{"id": "2511.17335", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.17335", "abs": "https://arxiv.org/abs/2511.17335", "authors": ["Chiori Hori", "Yoshiki Masuyama", "Siddarth Jain", "Radu Corcodel", "Devesh Jha", "Diego Romeres", "Jonathan Le Roux"], "title": "Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM", "comment": "Accepted to ASRU 2025", "summary": "Human-robot collaboration towards a shared goal requires robots to understand human action and interaction with the surrounding environment. This paper focuses on human-robot interaction (HRI) based on human-robot dialogue that relies on the robot action confirmation and action step generation using multimodal scene understanding. The state-of-the-art approach uses multimodal transformers to generate robot action steps aligned with robot action confirmation from a single clip showing a task composed of multiple micro steps. Although actions towards a long-horizon task depend on each other throughout an entire video, the current approaches mainly focus on clip-level processing and do not leverage long-context information. This paper proposes a long-context Q-former incorporating left and right context dependency in full videos. Furthermore, this paper proposes a text-conditioning approach to feed text embeddings directly into the LLM decoder to mitigate the high abstraction of the information in text by Q-former. Experiments with the YouCook2 corpus show that the accuracy of confirmation generation is a major factor in the performance of action planning. Furthermore, we demonstrate that the long-context Q-former improves the confirmation and action planning by integrating VideoLLaMA3.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u957f\u4e0a\u4e0b\u6587Q-former\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u89c6\u9891\u7684\u5de6\u53f3\u4e0a\u4e0b\u6587\u4f9d\u8d56\u5173\u7cfb\u6765\u6539\u8fdb\u4eba\u673a\u4ea4\u4e92\u4e2d\u7684\u52a8\u4f5c\u786e\u8ba4\u548c\u52a8\u4f5c\u89c4\u5212\uff0c\u5e76\u91c7\u7528\u6587\u672c\u6761\u4ef6\u5316\u65b9\u6cd5\u76f4\u63a5\u5411LLM\u89e3\u7801\u5668\u8f93\u5165\u6587\u672c\u5d4c\u5165\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7247\u6bb5\u7ea7\u5904\u7406\uff0c\u672a\u80fd\u5229\u7528\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u800c\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u52a8\u4f5c\u5728\u6574\u4e2a\u89c6\u9891\u4e2d\u76f8\u4e92\u4f9d\u8d56\uff0c\u9700\u8981\u66f4\u597d\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u957f\u4e0a\u4e0b\u6587Q-former\u6574\u5408\u5168\u89c6\u9891\u7684\u5de6\u53f3\u4e0a\u4e0b\u6587\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u4f7f\u7528\u6587\u672c\u6761\u4ef6\u5316\u65b9\u6cd5\u76f4\u63a5\u5411LLM\u89e3\u7801\u5668\u8f93\u5165\u6587\u672c\u5d4c\u5165\u4ee5\u7f13\u89e3\u4fe1\u606f\u62bd\u8c61\u95ee\u9898\u3002", "result": "\u5728YouCook2\u8bed\u6599\u5e93\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u786e\u8ba4\u751f\u6210\u7684\u51c6\u786e\u6027\u662f\u52a8\u4f5c\u89c4\u5212\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u957f\u4e0a\u4e0b\u6587Q-former\u901a\u8fc7\u6574\u5408VideoLLaMA3\u6539\u8fdb\u4e86\u786e\u8ba4\u548c\u52a8\u4f5c\u89c4\u5212\u3002", "conclusion": "\u957f\u4e0a\u4e0b\u6587Q-former\u80fd\u591f\u6709\u6548\u63d0\u5347\u4eba\u673a\u4ea4\u4e92\u4e2d\u52a8\u4f5c\u786e\u8ba4\u548c\u52a8\u4f5c\u89c4\u5212\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u6574\u5408\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.17366", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17366", "abs": "https://arxiv.org/abs/2511.17366", "authors": ["Yankai Fu", "Ning Chen", "Junkai Zhao", "Shaozhe Shan", "Guocai Yao", "Pengwei Wang", "Zhongyuan Wang", "Shanghang Zhang"], "title": "METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model", "comment": null, "summary": "Building a generalist robot that can perceive, reason, and act across diverse tasks remains an open challenge, especially for dexterous manipulation. A major bottleneck lies in the scarcity of large-scale, action-annotated data for dexterous skills, as teleoperation is difficult and costly. Human data, with its vast scale and diverse manipulation behaviors, provides rich priors for learning robotic actions. While prior works have explored leveraging human demonstrations, they are often constrained by limited scenarios and a large visual gap between human and robots. To eliminate these limitations, we propose METIS, a vision-language-action (VLA) model for dexterous manipulation pretrained on multi-source egocentric datasets. We first construct EgoAtlas, which integrates large-scale human and robotic data from multiple sources, all unified under a consistent action space. We further extract motion-aware dynamics, a compact and discretized motion representation, which provides efficient and expressive supervision for VLA training. Built upon them, METIS integrates reasoning and acting into a unified framework, enabling effective deployment to downstream dexterous manipulation tasks. Our method demonstrates exceptional dexterous manipulation capabilities, achieving highest average success rate in six real-world tasks. Experimental results also highlight the superior generalization and robustness to out-of-distribution scenarios. These findings emphasize METIS as a promising step toward a generalist model for dexterous manipulation.", "AI": {"tldr": "METIS\u662f\u4e00\u4e2a\u7528\u4e8e\u7075\u5de7\u64cd\u4f5c\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6e90\u81ea\u6211\u4e2d\u5fc3\u6570\u636e\u96c6\u548c\u63d0\u53d6\u8fd0\u52a8\u611f\u77e5\u52a8\u6001\u8868\u793a\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u4e2d\u5b9e\u73b0\u63a8\u7406\u548c\u884c\u52a8\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u9ad8\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u7075\u5de7\u64cd\u4f5c\u4e2d\u5927\u89c4\u6a21\u52a8\u4f5c\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u5229\u7528\u4eba\u7c7b\u6570\u636e\u63d0\u4f9b\u7684\u4e30\u5bcc\u5148\u9a8c\u77e5\u8bc6\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u5728\u573a\u666f\u9650\u5236\u548c\u89c6\u89c9\u5dee\u8ddd\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u6784\u5efaEgoAtlas\u6570\u636e\u96c6\u6574\u5408\u591a\u6e90\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u6570\u636e\uff0c\u63d0\u53d6\u8fd0\u52a8\u611f\u77e5\u52a8\u6001\u4f5c\u4e3a\u7d27\u51d1\u79bb\u6563\u7684\u8fd0\u52a8\u8868\u793a\uff0c\u5728VLA\u6846\u67b6\u4e2d\u7edf\u4e00\u63a8\u7406\u548c\u884c\u52a8\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u9ad8\u5e73\u5747\u6210\u529f\u7387\uff0c\u5728\u5206\u5e03\u5916\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "METIS\u662f\u8fc8\u5411\u7075\u5de7\u64cd\u4f5c\u901a\u7528\u6a21\u578b\u7684\u6709\u524d\u666f\u7684\u4e00\u6b65\uff0c\u5c55\u793a\u4e86\u5728\u7edf\u4e00\u6846\u67b6\u4e2d\u6574\u5408\u63a8\u7406\u548c\u884c\u52a8\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.17373", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17373", "abs": "https://arxiv.org/abs/2511.17373", "authors": ["Yixuan Pan", "Ruoyi Qiao", "Li Chen", "Kashyap Chitta", "Liang Pan", "Haoguang Mai", "Qingwen Bu", "Hao Zhao", "Cunyuan Zheng", "Ping Luo", "Hongyang Li"], "title": "Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data", "comment": null, "summary": "Humanoid robots are envisioned to perform a wide range of tasks in human-centered environments, requiring controllers that combine agility with robust balance. Recent advances in locomotion and whole-body tracking have enabled impressive progress in either agile dynamic skills or stability-critical behaviors, but existing methods remain specialized, focusing on one capability while compromising the other. In this work, we introduce AMS (Agility Meets Stability), the first framework that unifies both dynamic motion tracking and extreme balance maintenance in a single policy. Our key insight is to leverage heterogeneous data sources: human motion capture datasets that provide rich, agile behaviors, and physically constrained synthetic balance motions that capture stability configurations. To reconcile the divergent optimization goals of agility and stability, we design a hybrid reward scheme that applies general tracking objectives across all data while injecting balance-specific priors only into synthetic motions. Further, an adaptive learning strategy with performance-driven sampling and motion-specific reward shaping enables efficient training across diverse motion distributions. We validate AMS extensively in simulation and on a real Unitree G1 humanoid. Experiments demonstrate that a single policy can execute agile skills such as dancing and running, while also performing zero-shot extreme balance motions like Ip Man's Squat, highlighting AMS as a versatile control paradigm for future humanoid applications.", "AI": {"tldr": "AMS\u6846\u67b6\u9996\u6b21\u5728\u5355\u4e00\u7b56\u7565\u4e2d\u7edf\u4e00\u4e86\u52a8\u6001\u8fd0\u52a8\u8ffd\u8e2a\u548c\u6781\u7aef\u5e73\u8861\u7ef4\u62a4\uff0c\u901a\u8fc7\u7ed3\u5408\u4eba\u7c7b\u52a8\u4f5c\u6355\u6349\u6570\u636e\u548c\u7269\u7406\u7ea6\u675f\u7684\u5408\u6210\u5e73\u8861\u52a8\u4f5c\uff0c\u5b9e\u73b0\u4e86\u654f\u6377\u6027\u4e0e\u7a33\u5b9a\u6027\u7684\u7edf\u4e00\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u5f62\u673a\u5668\u4eba\u63a7\u5236\u5668\u8981\u4e48\u4e13\u6ce8\u4e8e\u654f\u6377\u52a8\u6001\u6280\u80fd\uff0c\u8981\u4e48\u4e13\u6ce8\u4e8e\u7a33\u5b9a\u6027\u5173\u952e\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u80fd\u591f\u540c\u65f6\u517c\u987e\u4e24\u8005\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u5229\u7528\u5f02\u6784\u6570\u636e\u6e90\uff1a\u4eba\u7c7b\u52a8\u4f5c\u6355\u6349\u6570\u636e\u96c6\u63d0\u4f9b\u654f\u6377\u884c\u4e3a\uff0c\u7269\u7406\u7ea6\u675f\u7684\u5408\u6210\u5e73\u8861\u52a8\u4f5c\u6355\u6349\u7a33\u5b9a\u6027\u914d\u7f6e\uff1b\u8bbe\u8ba1\u6df7\u5408\u5956\u52b1\u65b9\u6848\uff0c\u5728\u6240\u6709\u6570\u636e\u4e0a\u5e94\u7528\u901a\u7528\u8ffd\u8e2a\u76ee\u6807\uff0c\u4ec5\u5728\u5408\u6210\u52a8\u4f5c\u4e2d\u6ce8\u5165\u5e73\u8861\u7279\u5b9a\u5148\u9a8c\uff1b\u91c7\u7528\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u5355\u4e00\u7b56\u7565\u80fd\u591f\u6267\u884c\u821e\u8e48\u3001\u8dd1\u6b65\u7b49\u654f\u6377\u6280\u80fd\uff0c\u540c\u65f6\u4e5f\u80fd\u96f6\u6837\u672c\u6267\u884c\u53f6\u95ee\u8e72\u7b49\u6781\u7aef\u5e73\u8861\u52a8\u4f5c\u3002", "conclusion": "AMS\u4f5c\u4e3a\u591a\u529f\u80fd\u63a7\u5236\u8303\u5f0f\uff0c\u4e3a\u672a\u6765\u4eba\u5f62\u673a\u5668\u4eba\u5e94\u7528\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u63a7\u5236\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17375", "categories": ["cs.RO", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17375", "abs": "https://arxiv.org/abs/2511.17375", "authors": ["Benjamin R. Toaz", "Quentin Goss", "John Thompson", "Seta Bo\u011fosyan", "Shaunak D. Bopardikar", "Mustafa \u0130lhan Akba\u015f", "Metin G\u00f6ka\u015fan"], "title": "Vector Cost Behavioral Planning for Autonomous Robotic Systems with Contemporary Validation Strategies", "comment": "Technical report associated with submission to Journal of Intelligent & Robotic Systems, currently under review", "summary": "The vector cost bimatrix game is a method for multi-objective decision making that enables autonomous robotic systems to optimize for multiple goals at once while avoiding worst-case scenarios in neglected objectives. We expand this approach to arbitrary numbers of objectives and compare its performance to scalar weighted sum methods during competitive motion planning. Explainable Artificial Intelligence (XAI) software is used to aid in the analysis of high dimensional decision-making data. State-space Exploration of Multidimensional Boundaries using Adherence Strategies (SEMBAS) is applied to explore performance modes in the parameter space as a sensitivity study for the baseline and proposed frameworks. While some works have explored aspects of game theoretic planning and intelligent systems validation separately, we combine each of these into a novel and comprehensive simulation pipeline. This integration demonstrates a dramatic improvement of the vector cost method over scalarization and offers an interpretable and generalizable framework for robotic behavioral planning. Code available at https://github.com/toazbenj/race_simulation. The video companion to this work is available at https://tinyurl.com/vectorcostvideo.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5411\u91cf\u6210\u672c\u53cc\u77e9\u9635\u535a\u5f08\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u76ee\u6807\u51b3\u7b56\uff0c\u5728\u7ade\u4e89\u6027\u8fd0\u52a8\u89c4\u5212\u4e2d\u76f8\u6bd4\u6807\u91cf\u52a0\u6743\u548c\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u901a\u8fc7XAI\u548cSEMBAS\u6280\u672f\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5206\u6790\u6846\u67b6\u3002", "motivation": "\u4e3a\u81ea\u4e3b\u673a\u5668\u4eba\u7cfb\u7edf\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u4f18\u5316\u591a\u4e2a\u76ee\u6807\u5e76\u907f\u514d\u6700\u574f\u60c5\u51b5\u7684\u591a\u76ee\u6807\u51b3\u7b56\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edf\u6807\u91cf\u52a0\u6743\u548c\u65b9\u6cd5\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u6269\u5c55\u5411\u91cf\u6210\u672c\u53cc\u77e9\u9635\u535a\u5f08\u81f3\u4efb\u610f\u6570\u91cf\u76ee\u6807\uff0c\u7ed3\u5408\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd(XAI)\u548c\u72b6\u6001\u7a7a\u95f4\u591a\u7ef4\u8fb9\u754c\u63a2\u7d22(SEMBAS)\u6280\u672f\uff0c\u6784\u5efa\u7efc\u5408\u4eff\u771f\u6d41\u6c34\u7ebf\u8fdb\u884c\u6027\u80fd\u5206\u6790\u3002", "result": "\u5411\u91cf\u6210\u672c\u65b9\u6cd5\u76f8\u6bd4\u6807\u91cf\u5316\u65b9\u6cd5\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\uff0c\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u53ef\u63a8\u5e7f\u7684\u673a\u5668\u4eba\u884c\u4e3a\u89c4\u5212\u6846\u67b6\u3002", "conclusion": "\u5411\u91cf\u6210\u672c\u535a\u5f08\u65b9\u6cd5\u5728\u591a\u76ee\u6807\u51b3\u7b56\u4e2d\u4f18\u4e8e\u4f20\u7edf\u6807\u91cf\u65b9\u6cd5\uff0c\u4e3a\u673a\u5668\u4eba\u884c\u4e3a\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17384", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17384", "abs": "https://arxiv.org/abs/2511.17384", "authors": ["Yifan Li", "Lichi Li", "Anh Dao", "Xinyu Zhou", "Yicheng Qiao", "Zheda Mai", "Daeun Lee", "Zichen Chen", "Zhen Tan", "Mohit Bansal", "Yu Kong"], "title": "IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation", "comment": null, "summary": "While Visual Large Language Models (VLLMs) show great promise as embodied agents, they continue to face substantial challenges in spatial reasoning. Existing embodied benchmarks largely focus on passive, static household environments and evaluate only isolated capabilities, failing to capture holistic performance in dynamic, real-world complexity. To fill this gap, we present IndustryNav, the first dynamic industrial navigation benchmark for active spatial reasoning. IndustryNav leverages 12 manually created, high-fidelity Unity warehouse scenarios featuring dynamic objects and human movement. Our evaluation employs a PointGoal navigation pipeline that effectively combines egocentric vision with global odometry to assess holistic local-global planning. Crucially, we introduce the \"collision rate\" and \"warning rate\" metrics to measure safety-oriented behaviors and distance estimation. A comprehensive study of nine state-of-the-art VLLMs (including models such as GPT-5-mini, Claude-4.5, and Gemini-2.5) reveals that closed-source models maintain a consistent advantage; however, all agents exhibit notable deficiencies in robust path planning, collision avoidance and active exploration. This highlights a critical need for embodied research to move beyond passive perception and toward tasks that demand stable planning, active exploration, and safe behavior in dynamic, real-world environment.", "AI": {"tldr": "IndustryNav\u662f\u9996\u4e2a\u52a8\u6001\u5de5\u4e1a\u5bfc\u822a\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30VLLMs\u5728\u52a8\u6001\u4ed3\u5e93\u73af\u5883\u4e2d\u7684\u4e3b\u52a8\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u8def\u5f84\u89c4\u5212\u3001\u78b0\u649e\u907f\u514d\u548c\u4e3b\u52a8\u63a2\u7d22\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709\u5177\u8eab\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u5bb6\u5ead\u73af\u5883\uff0c\u65e0\u6cd5\u8bc4\u4f30\u6a21\u578b\u5728\u52a8\u6001\u3001\u771f\u5b9e\u4e16\u754c\u590d\u6742\u73af\u5883\u4e2d\u7684\u6574\u4f53\u6027\u80fd\uff0c\u7279\u522b\u662f\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u752812\u4e2a\u9ad8\u4fdd\u771fUnity\u4ed3\u5e93\u573a\u666f\uff0c\u7ed3\u5408PointGoal\u5bfc\u822a\u7ba1\u9053\uff0c\u5c06\u81ea\u6211\u4e2d\u5fc3\u89c6\u89c9\u4e0e\u5168\u5c40\u91cc\u7a0b\u8ba1\u7ed3\u5408\uff0c\u8bc4\u4f30\u5c40\u90e8-\u5168\u5c40\u89c4\u5212\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u78b0\u649e\u7387\u548c\u8b66\u544a\u7387\u6307\u6807\u3002", "result": "\u5bf99\u4e2a\u6700\u5148\u8fdbVLLMs\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u95ed\u6e90\u6a21\u578b\u4fdd\u6301\u4f18\u52bf\uff0c\u4f46\u6240\u6709\u4ee3\u7406\u5728\u7a33\u5065\u8def\u5f84\u89c4\u5212\u3001\u78b0\u649e\u907f\u514d\u548c\u4e3b\u52a8\u63a2\u7d22\u65b9\u9762\u90fd\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002", "conclusion": "\u5177\u8eab\u7814\u7a76\u9700\u8981\u8d85\u8d8a\u88ab\u52a8\u611f\u77e5\uff0c\u8f6c\u5411\u9700\u8981\u7a33\u5b9a\u89c4\u5212\u3001\u4e3b\u52a8\u63a2\u7d22\u548c\u5728\u52a8\u6001\u771f\u5b9e\u73af\u5883\u4e2d\u5b89\u5168\u884c\u4e3a\u7684\u4efb\u52a1\u3002"}}
{"id": "2511.17387", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17387", "abs": "https://arxiv.org/abs/2511.17387", "authors": ["Yusuf Baran Ates", "Omer Morgul"], "title": "Human Imitated Bipedal Locomotion with Frequency Based Gait Generator Network", "comment": null, "summary": "Learning human-like, robust bipedal walking remains difficult due to hybrid dynamics and terrain variability. We propose a lightweight framework that combines a gait generator network learned from human motion with Proximal Policy Optimization (PPO) controller for torque control. Despite being trained only on flat or mildly sloped ground, the learned policies generalize to steeper ramps and rough surfaces. Results suggest that pairing spectral motion priors with Deep Reinforcement Learning (DRL) offers a practical path toward natural and robust bipedal locomotion with modest training cost.", "AI": {"tldr": "\u7ed3\u5408\u4ece\u4eba\u7c7b\u8fd0\u52a8\u5b66\u4e60\u7684\u6b65\u6001\u751f\u6210\u7f51\u7edc\u548cPPO\u626d\u77e9\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u53cc\u8db3\u884c\u8d70\u6846\u67b6\uff0c\u5728\u5e73\u5766\u6216\u7f13\u5761\u8bad\u7ec3\u540e\u80fd\u6cdb\u5316\u5230\u9661\u5761\u548c\u7c97\u7cd9\u5730\u9762", "motivation": "\u7531\u4e8e\u6df7\u5408\u52a8\u529b\u5b66\u548c\u5730\u5f62\u53d8\u5316\uff0c\u5b66\u4e60\u7c7b\u4eba\u3001\u7a33\u5065\u7684\u53cc\u8db3\u884c\u8d70\u4ecd\u7136\u56f0\u96be", "method": "\u4f7f\u7528\u4ece\u4eba\u7c7b\u8fd0\u52a8\u5b66\u4e60\u7684\u6b65\u6001\u751f\u6210\u7f51\u7edc\u7ed3\u5408PPO\u63a7\u5236\u5668\u8fdb\u884c\u626d\u77e9\u63a7\u5236", "result": "\u5c3d\u7ba1\u4ec5\u5728\u5e73\u5766\u6216\u7f13\u5761\u5730\u9762\u8bad\u7ec3\uff0c\u5b66\u4e60\u5230\u7684\u7b56\u7565\u80fd\u6cdb\u5316\u5230\u66f4\u9661\u7684\u5761\u9053\u548c\u7c97\u7cd9\u8868\u9762", "conclusion": "\u5c06\u9891\u8c31\u8fd0\u52a8\u5148\u9a8c\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u4e3a\u81ea\u7136\u7a33\u5065\u7684\u53cc\u8db3\u8fd0\u52a8\u63d0\u4f9b\u4e86\u4e00\u6761\u5177\u6709\u9002\u5ea6\u8bad\u7ec3\u6210\u672c\u7684\u5b9e\u7528\u8def\u5f84"}}
{"id": "2511.17401", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.17401", "abs": "https://arxiv.org/abs/2511.17401", "authors": ["Xiaoshan Zhou", "Carol C. Menassa", "Vineet R. Kamat"], "title": "Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment", "comment": "37 pages, 9 figures, and 7 tables", "summary": "Non-invasive electroencephalography (EEG)-based brain-computer interfaces (BCIs) offer an intuitive means for individuals with severe motor impairments to independently operate assistive robotic wheelchairs and navigate built environments. Despite considerable progress in BCI research, most current motion control systems are limited to discrete commands, rather than supporting continuous pursuit, where users can freely adjust speed and direction in real time. Such natural mobility control is, however, essential for wheelchair users to navigate complex public spaces, such as transit stations, airports, hospitals, and indoor corridors, to interact socially with the dynamic populations with agility, and to move flexibly and comfortably as autonomous driving is refined to allow movement at will. In this study, we address the gap of continuous pursuit motion control in BCIs by proposing and validating a brain-inspired Bayesian inference framework, where embodied dynamics in acceleration-based motor representations are decoded. This approach contrasts with conventional kinematics-level decoding and deep learning-based methods. Using a public dataset with sixteen hours of EEG from four subjects performing motor imagery-based target-following, we demonstrate that our method, utilizing Automatic Relevance Determination for feature selection and continual online learning, reduces the normalized mean squared error between predicted and true velocities by 72% compared to autoregressive and EEGNet-based methods in a session-accumulative transfer learning setting. Theoretically, these findings empirically support embodied cognition theory and reveal the brain's intrinsic motor control dynamics in an embodied and predictive nature. Practically, grounding EEG decoding in the same dynamical principles that govern biological motion offers a promising path toward more stable and intuitive BCI control.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u8111\u673a\u63a5\u53e3\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u8fde\u7eed\u8ffd\u8e2a\u8fd0\u52a8\u63a7\u5236\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5c06\u901f\u5ea6\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e\u4e8672%\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u8111\u673a\u63a5\u53e3\u8fd0\u52a8\u63a7\u5236\u7cfb\u7edf\u5927\u591a\u9650\u4e8e\u79bb\u6563\u547d\u4ee4\u800c\u975e\u8fde\u7eed\u8ffd\u8e2a\u63a7\u5236\u7684\u5c40\u9650\u6027\uff0c\u4f7f\u8f6e\u6905\u7528\u6237\u80fd\u591f\u5728\u590d\u6742\u516c\u5171\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u81ea\u7136\u3001\u7075\u6d3b\u7684\u8fd0\u52a8\u63a7\u5236\u3002", "method": "\u91c7\u7528\u8111\u542f\u53d1\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6\uff0c\u89e3\u7801\u57fa\u4e8e\u52a0\u901f\u5ea6\u7684\u8fd0\u52a8\u8868\u5f81\u4e2d\u7684\u4f53\u73b0\u52a8\u6001\uff0c\u4f7f\u7528\u81ea\u52a8\u76f8\u5173\u6027\u786e\u5b9a\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u5e76\u91c7\u7528\u6301\u7eed\u5728\u7ebf\u5b66\u4e60\u3002", "result": "\u5728\u57fa\u4e8e\u8fd0\u52a8\u60f3\u8c61\u7684\u76ee\u6807\u8ffd\u8e2a\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u81ea\u56de\u5f52\u548cEEGNet\u65b9\u6cd5\uff0c\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u964d\u4f4e\u4e8672%\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4ece\u7ecf\u9a8c\u4e0a\u652f\u6301\u4e86\u4f53\u73b0\u8ba4\u77e5\u7406\u8bba\uff0c\u63ed\u793a\u4e86\u5927\u8111\u5185\u5728\u8fd0\u52a8\u63a7\u5236\u52a8\u6001\u7684\u4f53\u73b0\u548c\u9884\u6d4b\u6027\u8d28\uff0c\u4e3a\u66f4\u7a33\u5b9a\u76f4\u89c2\u7684\u8111\u673a\u63a5\u53e3\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2511.17411", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17411", "abs": "https://arxiv.org/abs/2511.17411", "authors": ["Nikolay Nikolov", "Giuliano Albanese", "Sombit Dey", "Aleksandar Yanev", "Luc Van Gool", "Jan-Nico Zaech", "Danda Pani Paudel"], "title": "SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding", "comment": null, "summary": "Robotic Foundation Models (RFMs) hold great promise as generalist, end-to-end systems for robot control. Yet their ability to generalize across new environments, tasks, and embodiments remains limited. We argue that a major bottleneck lies in their foundations: most RFMs are built by fine-tuning internet-pretrained Vision-Language Models (VLMs). However, these VLMs are trained on 2D image-language tasks and lack the 3D spatial reasoning inherently required for embodied control in the 3D world. Bridging this gap directly with large-scale robotic data is costly and difficult to scale. Instead, we propose to enrich easy-to-collect non-robotic image data with 3D annotations and enhance a pretrained VLM with 3D understanding capabilities. Following this strategy, we train SPEAR-VLM, a 3D-aware VLM that infers object coordinates in 3D space from a single 2D image. Building on SPEAR-VLM, we introduce our main contribution, $~\\textbf{SPEAR-1}$: a robotic foundation model that integrates grounded 3D perception with language-instructed embodied control. Trained on $\\sim$45M frames from 24 Open X-Embodiment datasets, SPEAR-1 outperforms or matches state-of-the-art models such as $\u03c0_0$-FAST and $\u03c0_{0.5}$, while it uses 20$\\times$ fewer robot demonstrations. This carefully-engineered training strategy unlocks new VLM capabilities and as a consequence boosts the reliability of embodied control beyond what is achievable with only robotic data. We make our model weights and 3D-annotated datasets publicly available.", "AI": {"tldr": "SPEAR-1\u662f\u4e00\u4e2a\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u589e\u5f3a\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u76843D\u7a7a\u95f4\u7406\u89e3\u80fd\u529b\uff0c\u5728\u51cf\u5c1120\u500d\u673a\u5668\u4eba\u6f14\u793a\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u8fbe\u5230\u6216\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b\u5927\u591a\u57fa\u4e8e\u4e92\u8054\u7f51\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u7f3a\u4e4f3D\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u800c\u76f4\u63a5\u6536\u96c6\u5927\u89c4\u6a21\u673a\u5668\u4eba\u6570\u636e\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u63d0\u51faSPEAR-VLM\uff0c\u901a\u8fc7\u4e3a\u6613\u4e8e\u6536\u96c6\u7684\u975e\u673a\u5668\u4eba\u56fe\u50cf\u6570\u636e\u6dfb\u52a03D\u6807\u6ce8\uff0c\u589e\u5f3a\u9884\u8bad\u7ec3VLM\u76843D\u7406\u89e3\u80fd\u529b\uff1b\u7136\u540e\u57fa\u4e8e\u6b64\u6784\u5efaSPEAR-1\u6a21\u578b\uff0c\u6574\u5408\u57fa\u4e8e3D\u611f\u77e5\u7684\u8bed\u8a00\u6307\u4ee4\u63a7\u5236\u3002", "result": "\u572824\u4e2aOpen X-Embodiment\u6570\u636e\u96c6\u7ea64500\u4e07\u5e27\u6570\u636e\u4e0a\u8bad\u7ec3\uff0cSPEAR-1\u6027\u80fd\u8fbe\u5230\u6216\u8d85\u8d8a\u03c0\u2080-FAST\u548c\u03c0\u2080.\u2085\u7b49\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u540c\u65f6\u4f7f\u7528\u7684\u673a\u5668\u4eba\u6f14\u793a\u6570\u636e\u51cf\u5c1120\u500d\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bad\u7ec3\u7b56\u7565\u89e3\u9501\u4e86VLM\u7684\u65b0\u80fd\u529b\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u5177\u8eab\u63a7\u5236\u7684\u53ef\u9760\u6027\uff0c\u8d85\u8d8a\u4e86\u4ec5\u4f7f\u7528\u673a\u5668\u4eba\u6570\u636e\u6240\u80fd\u8fbe\u5230\u7684\u6c34\u5e73\u3002"}}
{"id": "2511.17441", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17441", "abs": "https://arxiv.org/abs/2511.17441", "authors": ["Shihan Wu", "Xuecheng Liu", "Shaoxuan Xie", "Pengwei Wang", "Xinghang Li", "Bowen Yang", "Zhe Li", "Kai Zhu", "Hongyu Wu", "Yiheng Liu", "Zhaoye Long", "Yue Wang", "Chong Liu", "Dihan Wang", "Ziqiang Ni", "Xiang Yang", "You Liu", "Ruoxuan Feng", "Runtian Xu", "Lei Zhang", "Denghang Huang", "Chenghao Jin", "Anlan Yin", "Xinlong Wang", "Zhenguo Sun", "Junkai Zhao", "Mengfei Du", "Mingyu Cao", "Xiansheng Chen", "Hongyang Cheng", "Xiaojie Zhang", "Yankai Fu", "Ning Chen", "Cheng Chi", "Sixiang Chen", "Huaihai Lyu", "Xiaoshuai Hao", "Yankai Fu", "Yequan Wang", "Bo Lei", "Dong Liu", "Xi Yang", "Yance Jiao", "Tengfei Pan", "Yunyan Zhang", "Songjing Wang", "Ziqian Zhang", "Xu Liu", "Ji Zhang", "Caowei Meng", "Zhizheng Zhang", "Jiyang Gao", "Song Wang", "Xiaokun Leng", "Zhiqiang Xie", "Zhenzhen Zhou", "Peng Huang", "Wu Yang", "Yandong Guo", "Yichao Zhu", "Suibing Zheng", "Hao Cheng", "Xinmin Ding", "Yang Yue", "Huanqian Wang", "Chi Chen", "Jingrui Pang", "YuXi Qian", "Haoran Geng", "Lianli Gao", "Haiyuan Li", "Bin Fang", "Gao Huang", "Yaodong Yang", "Hao Dong", "He Wang", "Hang Zhao", "Yadong Mu", "Di Hu", "Hao Zhao", "Tiejun Huang", "Shanghang Zhang", "Yonghua Lin", "Zhongyuan Wang", "Guocai Yao"], "title": "RoboCOIN: An Open-Sourced Bimanual Robotic Data COllection for INtegrated Manipulation", "comment": null, "summary": "Bimanual manipulation is essential for achieving human-like dexterity in robots, but the large-scale and diverse bimanual robot datasets remain scarce due to hardware heterogeneity across robotic platforms. To address the challenge, we present RoboCOIN, a comprehensive multi-embodiment bimanual manipulation dataset with over 180,000 demonstrations collected from 15 distinct robotic platforms. The dataset covers 16 scenarios, including residential, commercial, and working environments, with 421 tasks systematically organized by bimanual coordination patterns and object properties. Our key innovation is a hierarchical capability pyramid that provides multi-level annotations, spanning trajectory-level concepts, segment-level subtasks, and frame-level kinematics. We further develop CoRobot, a comprehensive processing framework featuring Robot Trajectory Markup Language (RTML) for quality assessment, automated annotation generation, and unified multi-embodiment management. Extensive experiments demonstrate the reliability and effectiveness of RoboCOIN in multi-embodiment bimanual learning, with significant performance improvements across various model architectures and robotic platforms. The complete dataset and framework are open-sourced and publicly available for further research purposes. Project website: https://FlagOpen.github.io/RoboCOIN/.", "AI": {"tldr": "RoboCOIN\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u673a\u5668\u4eba\u5e73\u53f0\u7684\u53cc\u81c2\u64cd\u4f5c\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc718\u4e07\u6b21\u6f14\u793a\uff0c\u6db5\u76d616\u4e2a\u573a\u666f\u548c421\u4e2a\u4efb\u52a1\uff0c\u91c7\u7528\u5206\u5c42\u80fd\u529b\u91d1\u5b57\u5854\u8fdb\u884c\u591a\u7ea7\u6807\u6ce8\uff0c\u5e76\u5f00\u53d1\u4e86CoRobot\u5904\u7406\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u53cc\u81c2\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7531\u4e8e\u786c\u4ef6\u5f02\u6784\u6027\u5bfc\u81f4\u7684\u5927\u89c4\u6a21\u591a\u6837\u5316\u6570\u636e\u96c6\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u6536\u96c615\u4e2a\u4e0d\u540c\u673a\u5668\u4eba\u5e73\u53f0\u7684\u6f14\u793a\u6570\u636e\uff0c\u6784\u5efa\u5206\u5c42\u80fd\u529b\u91d1\u5b57\u5854\u8fdb\u884c\u591a\u7ea7\u6807\u6ce8\uff0c\u5f00\u53d1Robot Trajectory Markup Language (RTML)\u8fdb\u884c\u8d28\u91cf\u8bc4\u4f30\u548c\u7edf\u4e00\u7ba1\u7406\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b180,000+\u6f14\u793a\u7684\u5168\u9762\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u591a\u79cd\u6a21\u578b\u67b6\u6784\u548c\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u90fd\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "RoboCOIN\u6570\u636e\u96c6\u548cCoRobot\u6846\u67b6\u4e3a\u591a\u673a\u5668\u4eba\u5e73\u53f0\u7684\u53cc\u81c2\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u9760\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5df2\u5f00\u6e90\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u4f7f\u7528\u3002"}}
{"id": "2511.17496", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.17496", "abs": "https://arxiv.org/abs/2511.17496", "authors": ["Zhiyu Huang", "Zewei Zhou", "Tianhui Cai", "Yun Zhang", "Jiaqi Ma"], "title": "MDG: Masked Denoising Generation for Multi-Agent Behavior Modeling in Traffic Environments", "comment": null, "summary": "Modeling realistic and interactive multi-agent behavior is critical to autonomous driving and traffic simulation. However, existing diffusion and autoregressive approaches are limited by iterative sampling, sequential decoding, or task-specific designs, which hinder efficiency and reuse. We propose Masked Denoising Generation (MDG), a unified generative framework that reformulates multi-agent behavior modeling as the reconstruction of independently noised spatiotemporal tensors. Instead of relying on diffusion time steps or discrete tokenization, MDG applies continuous, per-agent and per-timestep noise masks that enable localized denoising and controllable trajectory generation in a single or few forward passes. This mask-driven formulation generalizes across open-loop prediction, closed-loop simulation, motion planning, and conditional generation within one model. Trained on large-scale real-world driving datasets, MDG achieves competitive closed-loop performance on the Waymo Sim Agents and nuPlan Planning benchmarks, while providing efficient, consistent, and controllable open-loop multi-agent trajectory generation. These results position MDG as a simple yet versatile paradigm for multi-agent behavior modeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86Masked Denoising Generation (MDG)\u6846\u67b6\uff0c\u901a\u8fc7\u72ec\u7acb\u566a\u58f0\u65f6\u7a7a\u5f20\u91cf\u91cd\u6784\u6765\u7edf\u4e00\u5efa\u6a21\u591a\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u6269\u6563\u6a21\u578b\u548c\u81ea\u56de\u5f52\u65b9\u6cd5\u7684\u8fed\u4ee3\u91c7\u6837\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u548c\u81ea\u56de\u5f52\u65b9\u6cd5\u53d7\u9650\u4e8e\u8fed\u4ee3\u91c7\u6837\u3001\u987a\u5e8f\u89e3\u7801\u6216\u4efb\u52a1\u7279\u5b9a\u8bbe\u8ba1\uff0c\u5f71\u54cd\u4e86\u6548\u7387\u548c\u53ef\u590d\u7528\u6027\uff0c\u9700\u8981\u66f4\u7edf\u4e00\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u5efa\u6a21\u6846\u67b6\u3002", "method": "MDG\u4f7f\u7528\u8fde\u7eed\u3001\u6bcf\u667a\u80fd\u4f53\u6bcf\u65f6\u95f4\u6b65\u7684\u566a\u58f0\u63a9\u7801\uff0c\u5b9e\u73b0\u5c40\u90e8\u53bb\u566a\u548c\u53ef\u63a7\u8f68\u8ff9\u751f\u6210\uff0c\u53ef\u5728\u5355\u6b21\u6216\u5c11\u91cf\u524d\u5411\u4f20\u64ad\u4e2d\u5b8c\u6210\uff0c\u652f\u6301\u5f00\u73af\u9884\u6d4b\u3001\u95ed\u73af\u4eff\u771f\u3001\u8fd0\u52a8\u89c4\u5212\u548c\u6761\u4ef6\u751f\u6210\u3002", "result": "\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u9a7e\u9a76\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0cMDG\u5728Waymo Sim Agents\u548cnuPlan Planning\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u7ade\u4e89\u6027\u95ed\u73af\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u9ad8\u6548\u3001\u4e00\u81f4\u548c\u53ef\u63a7\u7684\u5f00\u73af\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u751f\u6210\u3002", "conclusion": "MDG\u4f5c\u4e3a\u4e00\u4e2a\u7b80\u5355\u800c\u901a\u7528\u7684\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u5efa\u6a21\u8303\u5f0f\uff0c\u5c55\u793a\u4e86\u5728\u81ea\u52a8\u9a7e\u9a76\u548c\u4ea4\u901a\u4eff\u771f\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.17497", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17497", "abs": "https://arxiv.org/abs/2511.17497", "authors": ["Yuezhan Tao", "Dexter Ong", "Fernando Cladera", "Jason Hughes", "Camillo J. Taylor", "Pratik Chaudhari", "Vijay Kumar"], "title": "HALO: High-Altitude Language-Conditioned Monocular Aerial Exploration and Navigation", "comment": null, "summary": "We demonstrate real-time high-altitude aerial metric-semantic mapping and exploration using a monocular camera paired with a global positioning system (GPS) and an inertial measurement unit (IMU). Our system, named HALO, addresses two key challenges: (i) real-time dense 3D reconstruction using vision at large distances, and (ii) mapping and exploration of large-scale outdoor environments with accurate scene geometry and semantics. We demonstrate that HALO can plan informative paths that exploit this information to complete missions with multiple tasks specified in natural language. In simulation-based evaluation across large-scale environments of size up to 78,000 sq. m., HALO consistently completes tasks with less exploration time and achieves up to 68% higher competitive ratio in terms of the distance traveled compared to the state-of-the-art semantic exploration baseline. We use real-world experiments on a custom quadrotor platform to demonstrate that (i) all modules can run onboard the robot, and that (ii) in diverse environments HALO can support effective autonomous execution of missions covering up to 24,600 sq. m. area at an altitude of 40 m. Experiment videos and more details can be found on our project page: https://tyuezhan.github.io/halo/.", "AI": {"tldr": "HALO\u7cfb\u7edf\u5b9e\u73b0\u4e86\u57fa\u4e8e\u5355\u76ee\u76f8\u673a\u3001GPS\u548cIMU\u7684\u5b9e\u65f6\u9ad8\u7a7a\u822a\u62cd\u5ea6\u91cf-\u8bed\u4e49\u5efa\u56fe\u4e0e\u63a2\u7d22\uff0c\u80fd\u591f\u5728\u5927\u578b\u5ba4\u5916\u73af\u5883\u4e2d\u5b8c\u6210\u591a\u4efb\u52a1\u81ea\u4e3b\u6267\u884c\u3002", "motivation": "\u89e3\u51b3\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a(i) \u5728\u5927\u8ddd\u79bb\u4e0b\u4f7f\u7528\u89c6\u89c9\u8fdb\u884c\u5b9e\u65f6\u5bc6\u96c63D\u91cd\u5efa\uff0c(ii) \u5728\u5927\u89c4\u6a21\u5ba4\u5916\u73af\u5883\u4e2d\u8fdb\u884c\u5177\u6709\u51c6\u786e\u573a\u666f\u51e0\u4f55\u548c\u8bed\u4e49\u7684\u5efa\u56fe\u4e0e\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u5355\u76ee\u76f8\u673a\u3001GPS\u548cIMU\u7ec4\u5408\uff0c\u5f00\u53d1HALO\u7cfb\u7edf\u8fdb\u884c\u5b9e\u65f6\u5bc6\u96c63D\u91cd\u5efa\u548c\u8bed\u4e49\u5efa\u56fe\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u89c4\u5212\u3002", "result": "\u572878,000\u5e73\u65b9\u7c73\u7684\u5927\u89c4\u6a21\u73af\u5883\u4e2d\uff0cHALO\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u8bed\u4e49\u63a2\u7d22\u57fa\u7ebf\u51cf\u5c11\u63a2\u7d22\u65f6\u95f4\uff0c\u8ddd\u79bb\u65c5\u884c\u7ade\u4e89\u6bd4\u63d0\u9ad8\u8fbe68%\u3002\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8bc1\u660e\u6240\u6709\u6a21\u5757\u53ef\u5728\u673a\u5668\u4eba\u4e0a\u8fd0\u884c\uff0c\u572840\u7c73\u9ad8\u5ea6\u8986\u76d624,600\u5e73\u65b9\u7c73\u533a\u57df\u3002", "conclusion": "HALO\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u652f\u6301\u5927\u89c4\u6a21\u5ba4\u5916\u73af\u5883\u7684\u81ea\u4e3b\u4efb\u52a1\u6267\u884c\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u9ad8\u7a7a\u822a\u62cd\u5ea6\u91cf-\u8bed\u4e49\u5efa\u56fe\u4e0e\u63a2\u7d22\u3002"}}
{"id": "2511.17502", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17502", "abs": "https://arxiv.org/abs/2511.17502", "authors": ["Jun Cen", "Siteng Huang", "Yuqian Yuan", "Hangjie Yuan", "Chaohui Yu", "Yuming Jiang", "Jiayan Guo", "Kehan Li", "Hao Luo", "Fan Wang", "Xin Li", "Deli Zhao", "Hao Chen"], "title": "RynnVLA-002: A Unified Vision-Language-Action and World Model", "comment": null, "summary": "We introduce RynnVLA-002, a unified Vision-Language-Action (VLA) and world model. The world model leverages action and visual inputs to predict future image states, learning the underlying physics of the environment to refine action generation. Conversely, the VLA model produces subsequent actions from image observations, enhancing visual understanding and supporting the world model's image generation. The unified framework of RynnVLA-002 enables joint learning of environmental dynamics and action planning. Our experiments show that RynnVLA-002 surpasses individual VLA and world models, demonstrating their mutual enhancement. We evaluate RynnVLA-002 in both simulation and real-world robot tasks. RynnVLA-002 achieves 97.4% success rate on the LIBERO simulation benchmark without pretraining, while in real-world LeRobot experiments, its integrated world model boosts the overall success rate by 50%.", "AI": {"tldr": "RynnVLA-002\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u548c\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u73af\u5883\u52a8\u6001\u548c\u52a8\u4f5c\u89c4\u5212\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u548c\u4e16\u754c\u6a21\u578b\u901a\u5e38\u662f\u5206\u5f00\u7684\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u5b9e\u73b0\u4e24\u8005\u7684\u76f8\u4e92\u589e\u5f3a\uff0c\u63d0\u5347\u5bf9\u73af\u5883\u7684\u7269\u7406\u7406\u89e3\u548c\u52a8\u4f5c\u751f\u6210\u80fd\u529b\u3002", "method": "\u6784\u5efa\u7edf\u4e00\u7684VLA\u548c\u4e16\u754c\u6a21\u578b\u6846\u67b6\uff1a\u4e16\u754c\u6a21\u578b\u5229\u7528\u52a8\u4f5c\u548c\u89c6\u89c9\u8f93\u5165\u9884\u6d4b\u672a\u6765\u56fe\u50cf\u72b6\u6001\uff0c\u5b66\u4e60\u73af\u5883\u7269\u7406\uff1bVLA\u6a21\u578b\u4ece\u56fe\u50cf\u89c2\u5bdf\u751f\u6210\u540e\u7eed\u52a8\u4f5c\uff0c\u589e\u5f3a\u89c6\u89c9\u7406\u89e3\u5e76\u652f\u6301\u4e16\u754c\u6a21\u578b\u7684\u56fe\u50cf\u751f\u6210\u3002", "result": "\u5728LIBERO\u4eff\u771f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523097.4%\u7684\u6210\u529f\u7387\uff08\u65e0\u9700\u9884\u8bad\u7ec3\uff09\uff1b\u5728\u771f\u5b9e\u4e16\u754cLeRobot\u5b9e\u9a8c\u4e2d\uff0c\u96c6\u6210\u7684\u4e16\u754c\u6a21\u578b\u5c06\u6574\u4f53\u6210\u529f\u7387\u63d0\u5347\u4e8650%\u3002", "conclusion": "RynnVLA-002\u8bc1\u660e\u4e86\u7edf\u4e00VLA\u548c\u4e16\u754c\u6a21\u578b\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4e24\u8005\u76f8\u4e92\u589e\u5f3a\uff0c\u8d85\u8d8a\u4e86\u5355\u72ec\u7684\u6a21\u578b\u6027\u80fd\u3002"}}
