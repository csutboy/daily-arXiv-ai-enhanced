{"id": "2510.00349", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.00349", "abs": "https://arxiv.org/abs/2510.00349", "authors": ["Felix Reichel"], "title": "Two-Stage Asymmetric Tullock Contests with Cost Shifters and Endogenous Continuation Decision", "comment": "6 pages, 1 appendix Submitted to Games", "summary": "This paper introduces a contest-theoretic simplified model of triathlon as a\nsequential two-stage game. In Stage 1 (post-swim), participants decide whether\nto continue or withdraw from the contest, thereby generating an endogenous\nparticipation decision. In Stage 2 (bike-run), competition is represented as a\nTullock contest in which swim drafting acts as a multiplicative shifter of\nquadratic effort costs. Closed-form equilibrium strategies are derived in the\ntwo-player case, and existence, uniqueness, and comparative statics are shown\nin the asymmetric n-player case. The continuation decision yields\nathlete-specific cutoff rules in swim drafting intensity and induces\nsubgame-perfect equilibria (SPEs) with endogenous participation sets. The\nanalysis relates swim drafting benefits, exposure, and group size to\nheterogeneous effective cost parameters and equilibrium efforts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ade\u8d5b\u7406\u8bba\u7684\u4e09\u9879\u5168\u80fd\u7b80\u5316\u6a21\u578b\uff0c\u5c06\u5176\u5efa\u6a21\u4e3a\u987a\u5e8f\u4e24\u9636\u6bb5\u535a\u5f08\uff0c\u5206\u6790\u6e38\u6cf3\u8ddf\u9a91\u5bf9\u53c2\u8d5b\u8005\u51b3\u7b56\u548c\u52aa\u529b\u6c34\u5e73\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u4e09\u9879\u5168\u80fd\u6bd4\u8d5b\u4e2d\u6e38\u6cf3\u8ddf\u9a91\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u8fd0\u52a8\u5458\u7684\u53c2\u8d5b\u51b3\u7b56\u548c\u540e\u7eed\u6bd4\u8d5b\u4e2d\u7684\u52aa\u529b\u6c34\u5e73\uff0c\u63a2\u8ba8\u5185\u751f\u53c2\u4e0e\u51b3\u7b56\u7684\u5f62\u6210\u673a\u5236\u3002", "method": "\u6784\u5efa\u987a\u5e8f\u4e24\u9636\u6bb5\u535a\u5f08\u6a21\u578b\uff1a\u7b2c\u4e00\u9636\u6bb5\uff08\u6e38\u6cf3\u540e\uff09\u51b3\u5b9a\u662f\u5426\u7ee7\u7eed\u53c2\u8d5b\uff0c\u7b2c\u4e8c\u9636\u6bb5\uff08\u81ea\u884c\u8f66-\u8dd1\u6b65\uff09\u91c7\u7528Tullock\u7ade\u8d5b\u5f62\u5f0f\uff0c\u6e38\u6cf3\u8ddf\u9a91\u4f5c\u4e3a\u4e8c\u6b21\u52aa\u529b\u6210\u672c\u7684\u4e58\u6027\u8f6c\u79fb\u56e0\u5b50\u3002", "result": "\u63a8\u5bfc\u51fa\u53cc\u4eba\u60c5\u51b5\u4e0b\u7684\u95ed\u5f0f\u5747\u8861\u7b56\u7565\uff0c\u8bc1\u660e\u975e\u5bf9\u79f0n\u4eba\u60c5\u51b5\u4e0b\u5747\u8861\u7684\u5b58\u5728\u6027\u3001\u552f\u4e00\u6027\u548c\u6bd4\u8f83\u9759\u6001\u6027\u8d28\uff0c\u53d1\u73b0\u6e38\u6cf3\u8ddf\u9a91\u5f3a\u5ea6\u4ea7\u751f\u8fd0\u52a8\u5458\u7279\u5b9a\u7684\u4e34\u754c\u89c4\u5219\u3002", "conclusion": "\u6e38\u6cf3\u8ddf\u9a91\u7684\u6536\u76ca\u3001\u66b4\u9732\u7a0b\u5ea6\u548c\u7fa4\u4f53\u89c4\u6a21\u4e0e\u5f02\u8d28\u6709\u6548\u6210\u672c\u53c2\u6570\u548c\u5747\u8861\u52aa\u529b\u6c34\u5e73\u76f8\u5173\uff0c\u5185\u751f\u53c2\u4e0e\u96c6\u5f62\u6210\u4e86\u5b50\u535a\u5f08\u5b8c\u7f8e\u5747\u8861\u3002"}}
{"id": "2510.00754", "categories": ["econ.EM", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.00754", "abs": "https://arxiv.org/abs/2510.00754", "authors": ["Tatsuru Kikuchi"], "title": "A Unified Framework for Spatial and Temporal Treatment Effect Boundaries: Theory and Identification", "comment": "48 pages", "summary": "This paper develops a unified theoretical framework for detecting and\nestimating boundaries in treatment effects across both spatial and temporal\ndimensions. We formalize the concept of treatment effect boundaries as\nstructural parameters characterizing regime transitions where causal effects\ncease to operate. Building on diffusion-based models of information\npropagation, we establish conditions under which spatial and temporal\nboundaries share common dynamics, derive identification results, and propose\nconsistent estimators. Monte Carlo simulations demonstrate the performance of\nour methods under various data-generating processes. The framework provides\ntools for detecting when local treatments become systemic and identifying\ncritical thresholds for policy intervention.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u4f30\u8ba1\u5904\u7406\u6548\u5e94\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u8fb9\u754c\uff0c\u5c06\u5904\u7406\u6548\u5e94\u8fb9\u754c\u5f62\u5f0f\u5316\u4e3a\u7ed3\u6784\u53c2\u6570\uff0c\u5e76\u57fa\u4e8e\u4fe1\u606f\u4f20\u64ad\u7684\u6269\u6563\u6a21\u578b\u5efa\u7acb\u8bc6\u522b\u6761\u4ef6\u548c\u4f30\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u9700\u8981\u5f62\u5f0f\u5316\u5904\u7406\u6548\u5e94\u8fb9\u754c\u7684\u6982\u5ff5\uff0c\u4ee5\u8bc6\u522b\u56e0\u679c\u6548\u5e94\u505c\u6b62\u8fd0\u4f5c\u7684\u5236\u5ea6\u8f6c\u53d8\u70b9\uff0c\u4e3a\u653f\u7b56\u5e72\u9884\u63d0\u4f9b\u5173\u952e\u9608\u503c\u68c0\u6d4b\u5de5\u5177\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u4f20\u64ad\u7684\u6269\u6563\u6a21\u578b\uff0c\u5efa\u7acb\u7a7a\u95f4\u548c\u65f6\u95f4\u8fb9\u754c\u5171\u4eab\u5171\u540c\u52a8\u6001\u7684\u6761\u4ef6\uff0c\u63a8\u5bfc\u8bc6\u522b\u7ed3\u679c\u5e76\u63d0\u51fa\u4e00\u81f4\u4f30\u8ba1\u91cf\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u65b9\u6cd5\u6027\u80fd\u3002", "result": "\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u6846\u67b6\u80fd\u591f\u68c0\u6d4b\u5c40\u90e8\u5904\u7406\u4f55\u65f6\u53d8\u4e3a\u7cfb\u7edf\u6027\uff0c\u5e76\u8bc6\u522b\u653f\u7b56\u5e72\u9884\u7684\u5173\u952e\u9608\u503c\u3002", "conclusion": "\u8be5\u7edf\u4e00\u6846\u67b6\u4e3a\u68c0\u6d4b\u5904\u7406\u6548\u5e94\u8fb9\u754c\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u5236\u5ea6\u8f6c\u53d8\u548c\u653f\u7b56\u5e72\u9884\u65f6\u673a\u3002"}}
{"id": "2510.00154", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00154", "abs": "https://arxiv.org/abs/2510.00154", "authors": ["Xinyi Liu", "Mohammadreza Fani Sani", "Zewei Zhou", "Julius Wirbel", "Bahram Zarrin", "Roberto Galeazzi"], "title": "RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes", "comment": null, "summary": "Despite rapid progress in autonomous robotics, executing complex or\nlong-horizon tasks remains a fundamental challenge. Most current approaches\nfollow an open-loop paradigm with limited reasoning and no feedback, resulting\nin poor robustness to environmental changes and severe error accumulation. We\npresent RoboPilot, a dual-thinking closed-loop framework for robotic\nmanipulation that supports adaptive reasoning for complex tasks in real-world\ndynamic environments. RoboPilot leverages primitive actions for structured task\nplanning and flexible action generation, while introducing feedback to enable\nreplanning from dynamic changes and execution errors. Chain-of-Thought\nreasoning further enhances high-level task planning and guides low-level action\ngeneration. The system dynamically switches between fast and slow thinking to\nbalance efficiency and accuracy. To systematically evaluate the robustness of\nRoboPilot in diverse robot manipulation scenarios, we introduce\nRoboPilot-Bench, a benchmark spanning 21 tasks across 10 categories, including\ninfeasible-task recognition and failure recovery. Experiments show that\nRoboPilot outperforms state-of-the-art baselines by 25.9\\% in task success\nrate, and the real-world deployment on an industrial robot further demonstrates\nits robustness in real-world settings.", "AI": {"tldr": "RoboPilot\u662f\u4e00\u4e2a\u53cc\u601d\u7ef4\u95ed\u73af\u673a\u5668\u4eba\u64cd\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u5feb\u901f\u548c\u6162\u901f\u601d\u7ef4\u5207\u6362\u6765\u5e73\u8861\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u590d\u6742\u4efb\u52a1\u7684\u9002\u5e94\u6027\u63a8\u7406\u548c\u6267\u884c\u3002", "motivation": "\u5f53\u524d\u81ea\u4e3b\u673a\u5668\u4eba\u7cfb\u7edf\u5927\u591a\u91c7\u7528\u5f00\u73af\u8303\u5f0f\uff0c\u7f3a\u4e4f\u63a8\u7406\u548c\u53cd\u9988\u673a\u5236\uff0c\u5bfc\u81f4\u5bf9\u73af\u5883\u53d8\u5316\u7684\u9c81\u68d2\u6027\u5dee\u548c\u9519\u8bef\u7d2f\u79ef\u4e25\u91cd\u3002", "method": "\u5229\u7528\u539f\u59cb\u52a8\u4f5c\u8fdb\u884c\u7ed3\u6784\u5316\u4efb\u52a1\u89c4\u5212\u548c\u7075\u6d3b\u52a8\u4f5c\u751f\u6210\uff0c\u5f15\u5165\u53cd\u9988\u673a\u5236\u652f\u6301\u52a8\u6001\u53d8\u5316\u548c\u9519\u8bef\u6062\u590d\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u63a8\u7406\u589e\u5f3a\u9ad8\u5c42\u4efb\u52a1\u89c4\u5212\u548c\u4f4e\u5c42\u52a8\u4f5c\u751f\u6210\u3002", "result": "\u5728RoboPilot-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4efb\u52a1\u6210\u529f\u7387\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa25.9%\uff0c\u5de5\u4e1a\u673a\u5668\u4eba\u7684\u5b9e\u9645\u90e8\u7f72\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u5176\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "RoboPilot\u6846\u67b6\u901a\u8fc7\u53cc\u601d\u7ef4\u95ed\u73af\u8bbe\u8ba1\u548c\u53cd\u9988\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u5728\u590d\u6742\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2510.00879", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.00879", "abs": "https://arxiv.org/abs/2510.00879", "authors": ["Yaron Azrieli", "Christopher Chambers", "Paul Healy", "Nicolas Lambert"], "title": "Elicitability", "comment": null, "summary": "An analyst is tasked with producing a statistical study. The analyst is not\nmonitored and is able to manipulate the study. He can receive payments\ncontingent on his report and trusted data collected from an independent source,\nmodeled as a statistical experiment. We describe the information that can be\nelicited with appropriately shaped incentives, and apply our framework to a\nvariety of common statistical models. We then compare experiments based on the\ninformation they enable us to elicit. This order is connected to, but different\nfrom, the Blackwell order. Data preferred for estimation are also preferred for\nelicitation, but not conversely. Our results shed light on how using data as\nincentive generator in payment schemes differs from using data for statistical\ninference.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5206\u6790\u5e08\u53ef\u80fd\u64cd\u7eb5\u7edf\u8ba1\u7814\u7a76\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u901a\u8fc7\u9002\u5f53\u7684\u6fc0\u52b1\u8bbe\u8ba1\u6765\u83b7\u53d6\u771f\u5b9e\u4fe1\u606f\u3002\u4f5c\u8005\u6bd4\u8f83\u4e86\u4e0d\u540c\u5b9e\u9a8c\u5728\u4fe1\u606f\u83b7\u53d6\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u7528\u4e8e\u4f30\u8ba1\u7684\u6570\u636e\u4e5f\u9002\u7528\u4e8e\u6fc0\u52b1\u8bbe\u8ba1\uff0c\u4f46\u53cd\u4e4b\u4e0d\u6210\u7acb\u3002", "motivation": "\u5206\u6790\u5e08\u5728\u4e0d\u53d7\u76d1\u63a7\u7684\u60c5\u51b5\u4e0b\u53ef\u80fd\u64cd\u7eb5\u7edf\u8ba1\u7814\u7a76\uff0c\u800c\u57fa\u4e8e\u62a5\u544a\u548c\u53ef\u4fe1\u6570\u636e\u7684\u652f\u4ed8\u673a\u5236\u53ef\u4ee5\u6fc0\u52b1\u771f\u5b9e\u4fe1\u606f\u7684\u62ab\u9732\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u5982\u4f55\u901a\u8fc7\u6fc0\u52b1\u8bbe\u8ba1\u6765\u83b7\u53d6\u51c6\u786e\u4fe1\u606f\u3002", "method": "\u4f5c\u8005\u5efa\u7acb\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u63cf\u8ff0\u901a\u8fc7\u9002\u5f53\u8bbe\u8ba1\u7684\u6fc0\u52b1\u53ef\u4ee5\u83b7\u53d6\u7684\u4fe1\u606f\u7c7b\u578b\uff0c\u5e76\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u5e38\u89c1\u7684\u7edf\u8ba1\u6a21\u578b\u3002\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u5b9e\u9a8c\u5728\u4fe1\u606f\u83b7\u53d6\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\uff0c\u5206\u6790\u4e86\u6570\u636e\u4f5c\u4e3a\u6fc0\u52b1\u751f\u6210\u5668\u4e0e\u7edf\u8ba1\u63a8\u65ad\u5de5\u5177\u7684\u5f02\u540c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6570\u636e\u5728\u6fc0\u52b1\u8bbe\u8ba1\u548c\u7edf\u8ba1\u63a8\u65ad\u4e2d\u7684\u4f7f\u7528\u5b58\u5728\u5dee\u5f02\uff1a\u9002\u5408\u4f30\u8ba1\u7684\u6570\u636e\u4e5f\u9002\u5408\u6fc0\u52b1\u8bbe\u8ba1\uff0c\u4f46\u53cd\u4e4b\u4e0d\u4e00\u5b9a\u6210\u7acb\u3002\u8fd9\u79cd\u6392\u5e8f\u4e0eBlackwell\u6392\u5e8f\u76f8\u5173\u4f46\u4e0d\u540c\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5c06\u6570\u636e\u4f5c\u4e3a\u652f\u4ed8\u65b9\u6848\u4e2d\u7684\u6fc0\u52b1\u751f\u6210\u5668\u4e0e\u5c06\u6570\u636e\u7528\u4e8e\u7edf\u8ba1\u63a8\u65ad\u4e4b\u95f4\u7684\u91cd\u8981\u533a\u522b\uff0c\u4e3a\u8bbe\u8ba1\u6709\u6548\u7684\u6fc0\u52b1\u673a\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2510.00208", "categories": ["eess.SY", "cs.RO", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.00208", "abs": "https://arxiv.org/abs/2510.00208", "authors": ["Tanay Kumar", "Raktim Bhattacharya"], "title": "Robust Attitude Control of Nonlinear Multi-Rotor Dynamics with LFT Models and $\\mathcal{H}_\\infty$ Performance", "comment": "6 pages, 6 figures, 3 tables, submitted to ACC 2026", "summary": "Attitude stabilization of unmanned aerial vehicles in uncertain environments\npresents significant challenges due to nonlinear dynamics, parameter\nvariations, and sensor limitations. This paper presents a comparative study of\n$\\mathcal{H}_\\infty$ and classical PID controllers for multi-rotor attitude\nregulation in the presence of wind disturbances and gyroscope noise. The flight\ndynamics are modeled using a linear parameter-varying (LPV) framework, where\nnonlinearities and parameter variations are systematically represented as\nstructured uncertainties within a linear fractional transformation formulation.\nA robust controller based on $\\mathcal{H}_\\infty$ formulation is designed using\nonly gyroscope measurements to ensure guaranteed performance bounds. Nonlinear\nsimulation results demonstrate the effectiveness of the robust controllers\ncompared to classical PID control, showing significant improvement in attitude\nregulation under severe wind disturbances.", "AI": {"tldr": "\u6bd4\u8f83H\u221e\u548c\u7ecf\u5178PID\u63a7\u5236\u5668\u5728\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\u59ff\u6001\u8c03\u8282\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u98ce\u6270\u52a8\u548c\u9640\u87ba\u4eea\u566a\u58f0\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u59ff\u6001\u7a33\u5b9a\u9762\u4e34\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u3001\u53c2\u6570\u53d8\u5316\u548c\u4f20\u611f\u5668\u9650\u5236\u7b49\u6311\u6218\uff0c\u9700\u8981\u7814\u7a76\u66f4\u9c81\u68d2\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u53c2\u6570\u53d8\u5316(LPV)\u6846\u67b6\u5efa\u6a21\u98de\u884c\u52a8\u529b\u5b66\uff0c\u5c06\u975e\u7ebf\u6027\u548c\u53c2\u6570\u53d8\u5316\u8868\u793a\u4e3a\u7ed3\u6784\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u8bbe\u8ba1\u57fa\u4e8eH\u221e\u516c\u5f0f\u7684\u9c81\u68d2\u63a7\u5236\u5668\uff0c\u4ec5\u4f7f\u7528\u9640\u87ba\u4eea\u6d4b\u91cf\u3002", "result": "\u975e\u7ebf\u6027\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u7ecf\u5178PID\u63a7\u5236\u76f8\u6bd4\uff0c\u9c81\u68d2\u63a7\u5236\u5668\u5728\u4e25\u91cd\u98ce\u6270\u52a8\u4e0b\u7684\u59ff\u6001\u8c03\u8282\u6027\u80fd\u6709\u663e\u8457\u6539\u5584\u3002", "conclusion": "H\u221e\u9c81\u68d2\u63a7\u5236\u5668\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u6bd4\u4f20\u7edfPID\u63a7\u5236\u5668\u5177\u6709\u66f4\u597d\u7684\u59ff\u6001\u7a33\u5b9a\u6027\u80fd\u3002"}}
{"id": "2510.00244", "categories": ["q-fin.GN", "cs.CY", "cs.LG", "62P20"], "pdf": "https://arxiv.org/pdf/2510.00244", "abs": "https://arxiv.org/abs/2510.00244", "authors": ["Mohammad Hassan Shakil", "Arne Johan Pollestad", "Khine Kyaw", "Ziaul Haque Munim"], "title": "Board Gender Diversity and Carbon Emissions Performance: Insights from Panel Regressions, Machine Learning and Explainable AI", "comment": "34 pages and 3 figures", "summary": "With the European Union introducing gender quotas on corporate boards, this\nstudy investigates the impact of board gender diversity (BGD) on firms' carbon\nemission performance (CEP). Using panel regressions and advanced machine\nlearning algorithms on data from European firms between 2016 and 2022, the\nanalyses reveal a significant non-linear relationship. Specifically, CEP\nimproves with BGD up to an optimal level of approximately 35 percent, beyond\nwhich further increases in BGD yield no additional improvement in CEP. A\nminimum threshold of 22 percent BGD is necessary for meaningful improvements in\nCEP. To assess the legitimacy of CEP outcomes, this study examines whether ESG\ncontroversies affect the relationship between BGD and CEP. The results show no\nsignificant effect, suggesting that the effect of BGD is driven by governance\nmechanisms rather than symbolic actions. Additionally, structural equation\nmodelling (SEM) indicates that while environmental innovation contributes to\nCEP, it is not the mediating channel through which BGD promotes CEP. The\nresults have implications for academics, businesses, and regulators.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8463\u4e8b\u4f1a\u6027\u522b\u591a\u6837\u6027\u4e0e\u4f01\u4e1a\u78b3\u6392\u653e\u7ee9\u6548\u5b58\u5728\u663e\u8457\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u6700\u4f73\u6bd4\u4f8b\u4e3a35%\uff0c\u6700\u4f4e\u95e8\u69db\u4e3a22%\u3002ESG\u4e89\u8bae\u4e0d\u5f71\u54cd\u8be5\u5173\u7cfb\uff0c\u73af\u5883\u521b\u65b0\u4e0d\u662f\u4e2d\u4ecb\u673a\u5236\u3002", "motivation": "\u6b27\u76df\u5f15\u5165\u8463\u4e8b\u4f1a\u6027\u522b\u914d\u989d\u653f\u7b56\u80cc\u666f\u4e0b\uff0c\u7814\u7a76\u8463\u4e8b\u4f1a\u6027\u522b\u591a\u6837\u6027\u5bf9\u4f01\u4e1a\u78b3\u6392\u653e\u7ee9\u6548\u7684\u5f71\u54cd\uff0c\u68c0\u9a8c\u8be5\u5173\u7cfb\u662f\u5426\u53d7ESG\u4e89\u8bae\u5f71\u54cd\u4ee5\u53ca\u73af\u5883\u521b\u65b0\u7684\u4e2d\u4ecb\u4f5c\u7528\u3002", "method": "\u4f7f\u7528\u9762\u677f\u56de\u5f52\u548c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5206\u67902016-2022\u5e74\u6b27\u6d32\u4f01\u4e1a\u6570\u636e\uff0c\u91c7\u7528\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u68c0\u9a8c\u4e2d\u4ecb\u6548\u5e94\u3002", "result": "\u53d1\u73b035%\u4e3a\u6700\u4f18\u6027\u522b\u591a\u6837\u6027\u6bd4\u4f8b\uff0c22%\u4e3a\u6700\u4f4e\u6709\u6548\u95e8\u69db\uff1bESG\u4e89\u8bae\u4e0d\u5f71\u54cd\u8be5\u5173\u7cfb\uff0c\u73af\u5883\u521b\u65b0\u4e0d\u662f\u4e2d\u4ecb\u53d8\u91cf\u3002", "conclusion": "\u8463\u4e8b\u4f1a\u6027\u522b\u591a\u6837\u6027\u901a\u8fc7\u6cbb\u7406\u673a\u5236\u800c\u975e\u8c61\u5f81\u6027\u884c\u52a8\u6539\u5584\u78b3\u6392\u653e\u7ee9\u6548\uff0c\u7814\u7a76\u7ed3\u679c\u5bf9\u5b66\u672f\u754c\u3001\u4f01\u4e1a\u548c\u76d1\u7ba1\u673a\u6784\u5177\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.00014", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00014", "abs": "https://arxiv.org/abs/2510.00014", "authors": ["Tianyang Luo", "Xikun Zhang", "Dongjin Song"], "title": "FTSCommDetector: Discovering Behavioral Communities through Temporal Synchronization", "comment": null, "summary": "Why do trillion-dollar tech giants AAPL and MSFT diverge into different\nresponse patterns during market disruptions despite identical sector\nclassifications? This paradox reveals a fundamental limitation: traditional\ncommunity detection methods fail to capture synchronization-desynchronization\npatterns where entities move independently yet align during critical moments.\nTo this end, we introduce FTSCommDetector, implementing our Temporal Coherence\nArchitecture (TCA) to discover similar and dissimilar communities in continuous\nmultivariate time series. Unlike existing methods that process each timestamp\nindependently, causing unstable community assignments and missing evolving\nrelationships, our approach maintains coherence through dual-scale encoding and\nstatic topology with dynamic attention. Furthermore, we establish\ninformation-theoretic foundations demonstrating how scale separation maximizes\ncomplementary information and introduce Normalized Temporal Profiles (NTP) for\nscale-invariant evaluation. As a result, FTSCommDetector achieves consistent\nimprovements across four diverse financial markets (SP100, SP500, SP1000,\nNikkei 225), with gains ranging from 3.5% to 11.1% over the strongest\nbaselines. The method demonstrates remarkable robustness with only 2%\nperformance variation across window sizes from 60 to 120 days, making\ndataset-specific tuning unnecessary, providing practical insights for portfolio\nconstruction and risk management.", "AI": {"tldr": "\u63d0\u51fa\u4e86FTSCommDetector\u65b9\u6cd5\uff0c\u4f7f\u7528\u65f6\u95f4\u4e00\u81f4\u6027\u67b6\u6784(TCA)\u6765\u53d1\u73b0\u8fde\u7eed\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u76f8\u4f3c\u548c\u76f8\u5f02\u793e\u533a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u540c\u6b65-\u53bb\u540c\u6b65\u6a21\u5f0f\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u89e3\u91ca\u50cfAAPL\u548cMSFT\u8fd9\u6837\u76f8\u540c\u884c\u4e1a\u5206\u7c7b\u7684\u516c\u53f8\u5728\u5e02\u573a\u52a8\u8361\u65f6\u51fa\u73b0\u4e0d\u540c\u54cd\u5e94\u6a21\u5f0f\u7684\u73b0\u8c61\uff0c\u56e0\u4e3a\u5b83\u4eec\u65e0\u6cd5\u6355\u6349\u5b9e\u4f53\u5728\u5173\u952e\u65f6\u523b\u5bf9\u9f50\u4f46\u5728\u5176\u4ed6\u65f6\u95f4\u72ec\u7acb\u79fb\u52a8\u7684\u540c\u6b65-\u53bb\u540c\u6b65\u6a21\u5f0f\u3002", "method": "FTSCommDetector\u91c7\u7528\u65f6\u95f4\u4e00\u81f4\u6027\u67b6\u6784(TCA)\uff0c\u901a\u8fc7\u53cc\u5c3a\u5ea6\u7f16\u7801\u548c\u9759\u6001\u62d3\u6251\u4e0e\u52a8\u6001\u6ce8\u610f\u529b\u673a\u5236\u6765\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u4e0d\u540c\u4e8e\u73b0\u6709\u65b9\u6cd5\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u65f6\u95f4\u6233\u3002\u8fd8\u5efa\u7acb\u4e86\u4fe1\u606f\u8bba\u57fa\u7840\u8bc1\u660e\u5c3a\u5ea6\u5206\u79bb\u5982\u4f55\u6700\u5927\u5316\u4e92\u8865\u4fe1\u606f\uff0c\u5e76\u5f15\u5165\u5f52\u4e00\u5316\u65f6\u95f4\u5256\u9762(NTP)\u8fdb\u884c\u5c3a\u5ea6\u4e0d\u53d8\u8bc4\u4f30\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u7684\u91d1\u878d\u5e02\u573a(SP100\u3001SP500\u3001SP1000\u3001\u65e5\u7ecf225)\u4e0a\uff0cFTSCommDetector\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u5b9e\u73b0\u4e863.5%\u523011.1%\u7684\u6027\u80fd\u63d0\u5347\u3002\u8be5\u65b9\u6cd5\u8868\u73b0\u51fa\u663e\u8457\u7684\u9c81\u68d2\u6027\uff0c\u572860\u5230120\u5929\u7684\u7a97\u53e3\u5927\u5c0f\u8303\u56f4\u5185\u4ec5\u67092%\u7684\u6027\u80fd\u53d8\u5316\u3002", "conclusion": "FTSCommDetector\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u53d1\u73b0\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u540c\u6b65-\u53bb\u540c\u6b65\u793e\u533a\u6a21\u5f0f\uff0c\u4e3a\u6295\u8d44\u7ec4\u5408\u6784\u5efa\u548c\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u4e14\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u6570\u636e\u96c6\u8fdb\u884c\u8c03\u4f18\u3002"}}
{"id": "2510.00091", "categories": ["cs.CY", "cs.AI", "03B25, 03A05, 68T07, 97U70", "F.4.1; I.2.0; K.3.1"], "pdf": "https://arxiv.org/pdf/2510.00091", "abs": "https://arxiv.org/abs/2510.00091", "authors": ["Seyma Yaman Kayadibi"], "title": "Simulating Student Success in the Age of GenAI: A Kantian-Axiomatic Perspective", "comment": "23 pages in total, including 3 embedded Python code blocks, 4\n  figures, and 2 tables. The article analyzes student perception data simulated\n  from survey-derived Likert statistics, evaluated against six axioms of Dense\n  Linear Order (DLO). Preliminary version published on Zenodo; see External DOI", "summary": "This study reinterprets a Monte Carlo simulation of students' perceived\nsuccess with generative AI (GenAI) through a Kantian-axiomatic lens. Building\non prior work, theme-level survey statistics Ease of Use and Learnability,\nSystem Efficiency and Learning Burden, and Perceived Complexity and Integration\nfrom a representative dataset are used to generate 10,000 synthetic scores per\ntheme on the [1,5] Likert scale. The simulated outputs are evaluated against\nthe axioms of dense linear order without endpoints (DLO): irreflexivity,\ntransitivity, total comparability (connectedness), no endpoints (no greatest\nand no least; A4-A5), and density (A6). At the data level, the basic ordering\naxioms (A1-A3) are satisfied, whereas no-endpoints (A4-A5) and density (A6)\nfail as expected. Likert clipping introduces minimum and maximum observed\nvalues, and a finite, discretized sample need not contain a value strictly\nbetween any two distinct scores. These patterns are read not as methodological\ndefects but as markers of an epistemological boundary. Following Kant and\nFriedman, the findings suggest that what simulations capture finite, quantized\nobservations cannot instantiate the ideal properties of an unbounded, dense\ncontinuum. Such properties belong to constructive intuition rather than to\nfinite sampling alone. A complementary visualization contrasts the empirical\nhistogram with a sine-curve proxy to clarify this divide. The contribution is\ninterpretive rather than data-expansive: it reframes an existing simulation as\na probe of the synthetic a priori structure underlying students' perceptions,\nshowing how formal order-theoretic coherence coexists with principled failures\nof endpoint-freeness and density in finite empirical models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5eb7\u5fb7\u516c\u7406\u89c6\u89d2\u91cd\u65b0\u89e3\u8bfb\u5b66\u751f\u5bf9\u751f\u6210\u5f0fAI\u611f\u77e5\u6210\u529f\u7684\u8499\u7279\u5361\u6d1b\u6a21\u62df\uff0c\u53d1\u73b0\u6709\u9650\u79bb\u6563\u6570\u636e\u6ee1\u8db3\u57fa\u672c\u6392\u5e8f\u516c\u7406\u4f46\u65e0\u6cd5\u6ee1\u8db3\u65e0\u7aef\u70b9\u6027\u548c\u5bc6\u5ea6\u6027\uff0c\u8fd9\u53cd\u6620\u4e86\u7ecf\u9a8c\u89c2\u5bdf\u4e0e\u7406\u60f3\u8fde\u7eed\u7edf\u4e4b\u95f4\u7684\u8ba4\u8bc6\u8bba\u8fb9\u754c\u3002", "motivation": "\u65e8\u5728\u63a2\u8ba8\u6709\u9650\u7ecf\u9a8c\u6570\u636e\u4e0e\u7406\u60f3\u6570\u5b66\u7ed3\u6784\uff08\u5982\u65e0\u7aef\u70b9\u5bc6\u96c6\u7ebf\u6027\u5e8f\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63ed\u793a\u6a21\u62df\u65b9\u6cd5\u5728\u6355\u6349\u5b66\u751f\u611f\u77e5\u7ed3\u6784\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4ece\u5eb7\u5fb7\u54f2\u5b66\u89d2\u5ea6\u7406\u89e3\u8fd9\u79cd\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u5148\u524d\u5de5\u4f5c\u7684\u4e3b\u9898\u7ea7\u8c03\u67e5\u7edf\u8ba1\u6570\u636e\uff0c\u5728[1,5]\u674e\u514b\u7279\u91cf\u8868\u4e0a\u751f\u621010,000\u4e2a\u5408\u6210\u5206\u6570\uff0c\u7136\u540e\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u62df\u8f93\u51fa\u662f\u5426\u7b26\u5408\u5bc6\u96c6\u7ebf\u6027\u5e8f\u7684\u516c\u7406\u8981\u6c42\u3002", "result": "\u6570\u636e\u5c42\u9762\u6ee1\u8db3\u57fa\u672c\u6392\u5e8f\u516c\u7406\uff08A1-A3\uff09\uff0c\u4f46\u65e0\u6cd5\u6ee1\u8db3\u65e0\u7aef\u70b9\u6027\uff08A4-A5\uff09\u548c\u5bc6\u5ea6\u6027\uff08A6\uff09\uff0c\u8fd9\u4e9b\u5931\u8d25\u88ab\u89c6\u4e3a\u8ba4\u8bc6\u8bba\u8fb9\u754c\u7684\u6807\u5fd7\u800c\u975e\u65b9\u6cd5\u7f3a\u9677\u3002", "conclusion": "\u6709\u9650\u91cf\u5316\u89c2\u5bdf\u65e0\u6cd5\u5b9e\u4f8b\u5316\u65e0\u754c\u5bc6\u96c6\u8fde\u7eed\u7edf\u7684\u7406\u60f3\u5c5e\u6027\uff0c\u8fd9\u4e9b\u5c5e\u6027\u5c5e\u4e8e\u6784\u9020\u6027\u76f4\u89c9\u800c\u975e\u6709\u9650\u62bd\u6837\u672c\u8eab\uff0c\u7814\u7a76\u4e3a\u7406\u89e3\u5b66\u751f\u611f\u77e5\u7684\u5148\u5929\u7ed3\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u91ca\u6846\u67b6\u3002"}}
{"id": "2510.00022", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00022", "abs": "https://arxiv.org/abs/2510.00022", "authors": ["Ansh Kamthan"], "title": "Learning to Lead Themselves: Agentic AI in MAS using MARL", "comment": "Exploring foundational behaviours of agentic ai using MARL 39 pages -\n  25 minute read, 5 tables, 24 equation, 9 figures", "summary": "As autonomous systems move from prototypes to real deployments, the ability\nof multiple agents to make decentralized, cooperative decisions becomes a core\nrequirement. This paper examines how agentic artificial intelligence, agents\nthat act independently, adaptively and proactively can improve task allocation\nand coordination in multi-agent systems, with primary emphasis on drone\ndelivery and secondary relevance to warehouse automation. We formulate the\nproblem in a cooperative multi-agent reinforcement learning setting and\nimplement a lightweight multi-agent Proximal Policy Optimization, called IPPO,\napproach in PyTorch under a centralized-training, decentralized-execution\nparadigm. Experiments are conducted in PettingZoo environment, where multiple\nhomogeneous drones or agents must self-organize to cover distinct targets\nwithout explicit communication.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u81ea\u4e3b\u667a\u80fd\u4f53\u5982\u4f55\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u534f\u4f5c\u51b3\u7b56\u6539\u8fdb\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4efb\u52a1\u5206\u914d\u548c\u534f\u8c03\uff0c\u4e3b\u8981\u5e94\u7528\u4e8e\u65e0\u4eba\u673a\u914d\u9001\u548c\u4ed3\u5e93\u81ea\u52a8\u5316\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u7cfb\u7edf\u4ece\u539f\u578b\u8f6c\u5411\u5b9e\u9645\u90e8\u7f72\uff0c\u591a\u4e2a\u667a\u80fd\u4f53\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u534f\u4f5c\u51b3\u7b56\u7684\u80fd\u529b\u6210\u4e3a\u6838\u5fc3\u9700\u6c42\u3002", "method": "\u5728\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e0b\uff0c\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u3001\u5206\u6563\u6267\u884c\u7684\u8f7b\u91cf\u7ea7\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08IPPO\uff09\u65b9\u6cd5\uff0c\u5728PettingZoo\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u591a\u4e2a\u540c\u8d28\u65e0\u4eba\u673a\u6216\u667a\u80fd\u4f53\u80fd\u591f\u5728\u6ca1\u6709\u663e\u5f0f\u901a\u4fe1\u7684\u60c5\u51b5\u4e0b\u81ea\u7ec4\u7ec7\u8986\u76d6\u4e0d\u540c\u76ee\u6807\u3002", "conclusion": "\u81ea\u4e3b\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4efb\u52a1\u5206\u914d\u548c\u534f\u8c03\u80fd\u529b\u3002"}}
{"id": "2510.00087", "categories": ["stat.AP", "cs.LG", "math.PR", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.00087", "abs": "https://arxiv.org/abs/2510.00087", "authors": ["Anja Adamov", "Markus Chardonnet", "Florian Krach", "Jakob Heiss", "Josef Teichmann", "Nicholas A. Bokulich"], "title": "Revealing the temporal dynamics of antibiotic anomalies in the infant gut microbiome with neural jump ODEs", "comment": null, "summary": "Detecting anomalies in irregularly sampled multi-variate time-series is\nchallenging, especially in data-scarce settings. Here we introduce an anomaly\ndetection framework for irregularly sampled time-series that leverages neural\njump ordinary differential equations (NJODEs). The method infers conditional\nmean and variance trajectories in a fully path dependent way and computes\nanomaly scores. On synthetic data containing jump, drift, diffusion, and noise\nanomalies, the framework accurately identifies diverse deviations. Applied to\ninfant gut microbiome trajectories, it delineates the magnitude and persistence\nof antibiotic-induced disruptions: revealing prolonged anomalies after second\nantibiotic courses, extended duration treatments, and exposures during the\nsecond year of life. We further demonstrate the predictive capabilities of the\ninferred anomaly scores in accurately predicting antibiotic events and\noutperforming diversity-based baselines. Our approach accommodates unevenly\nspaced longitudinal observations, adjusts for static and dynamic covariates,\nand provides a foundation for inferring microbial anomalies induced by\nperturbations, offering a translational opportunity to optimize intervention\nregimens by minimizing microbial disruptions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u8df3\u8dc3\u5e38\u5fae\u5206\u65b9\u7a0b(NJODEs)\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u4e0d\u89c4\u5219\u91c7\u6837\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff0c\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u5404\u79cd\u504f\u5dee\u5e76\u5728\u5a74\u513f\u80a0\u9053\u5fae\u751f\u7269\u7ec4\u6570\u636e\u4e2d\u6709\u6548\u68c0\u6d4b\u6297\u751f\u7d20\u5f15\u8d77\u7684\u5f02\u5e38\u3002", "motivation": "\u89e3\u51b3\u4e0d\u89c4\u5219\u91c7\u6837\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u80fd\u591f\u5904\u7406\u8df3\u8dc3\u3001\u6f02\u79fb\u3001\u6269\u6563\u548c\u566a\u58f0\u7b49\u591a\u79cd\u5f02\u5e38\u7c7b\u578b\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u8df3\u8dc3\u5e38\u5fae\u5206\u65b9\u7a0b(NJODEs)\u63a8\u65ad\u6761\u4ef6\u5747\u503c\u548c\u65b9\u5dee\u8f68\u8ff9\uff0c\u4ee5\u5b8c\u5168\u8def\u5f84\u4f9d\u8d56\u7684\u65b9\u5f0f\u8ba1\u7b97\u5f02\u5e38\u5206\u6570\uff0c\u80fd\u591f\u5904\u7406\u4e0d\u5747\u5300\u95f4\u9694\u7684\u7eb5\u5411\u89c2\u6d4b\u5e76\u8c03\u6574\u9759\u6001\u548c\u52a8\u6001\u534f\u53d8\u91cf\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u4e2d\u51c6\u786e\u8bc6\u522b\u591a\u79cd\u5f02\u5e38\uff1b\u5728\u5a74\u513f\u80a0\u9053\u5fae\u751f\u7269\u7ec4\u6570\u636e\u4e2d\u63ed\u793a\u4e86\u6297\u751f\u7d20\u5f15\u8d77\u7684\u5f02\u5e38\u7a0b\u5ea6\u548c\u6301\u7eed\u6027\uff0c\u7279\u522b\u662f\u5728\u7b2c\u4e8c\u6b21\u6297\u751f\u7d20\u7597\u7a0b\u3001\u5ef6\u957f\u6cbb\u7597\u671f\u95f4\u548c\u7b2c\u4e8c\u5e74\u66b4\u9732\u65f6\uff1b\u5f02\u5e38\u5206\u6570\u5728\u9884\u6d4b\u6297\u751f\u7d20\u4e8b\u4ef6\u65b9\u9762\u4f18\u4e8e\u57fa\u4e8e\u591a\u6837\u6027\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u63a8\u65ad\u7531\u6270\u52a8\u5f15\u8d77\u7684\u5fae\u751f\u7269\u5f02\u5e38\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4e3a\u901a\u8fc7\u6700\u5c0f\u5316\u5fae\u751f\u7269\u5e72\u6270\u6765\u4f18\u5316\u5e72\u9884\u65b9\u6848\u63d0\u4f9b\u4e86\u8f6c\u5316\u673a\u4f1a\u3002"}}
{"id": "2510.01036", "categories": ["econ.EM", "math.ST", "stat.TH", "62G05, 62P20, 62C10"], "pdf": "https://arxiv.org/pdf/2510.01036", "abs": "https://arxiv.org/abs/2510.01036", "authors": ["Sid Kankanala"], "title": "Generalized Bayes in Conditional Moment Restriction Models", "comment": "This paper is based on and supersedes an older preprint:\n  arXiv:2311.00662", "summary": "This paper develops a generalized (quasi-) Bayes framework for conditional\nmoment restriction models, where the parameter of interest is a nonparametric\nstructural function of endogenous variables. We establish contraction rates for\na class of Gaussian process priors and provide conditions under which a\nBernstein-von Mises theorem holds for the quasi-Bayes posterior. Consequently,\nwe show that optimally weighted quasi-Bayes credible sets achieve exact\nasymptotic frequentist coverage, extending classical results for parametric GMM\nmodels. As an application, we estimate firm-level production functions using\nChilean plant-level data. Simulations illustrate the favorable performance of\ngeneralized Bayes estimators relative to common alternatives.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u5e7f\u4e49\uff08\u51c6\uff09\u8d1d\u53f6\u65af\u6846\u67b6\u7528\u4e8e\u6761\u4ef6\u77e9\u9650\u5236\u6a21\u578b\uff0c\u5176\u4e2d\u53c2\u6570\u662f\u5185\u751f\u53d8\u91cf\u7684\u975e\u53c2\u6570\u7ed3\u6784\u51fd\u6570\u3002\u5efa\u7acb\u4e86\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u7684\u6536\u7f29\u7387\uff0c\u5e76\u63d0\u4f9b\u4e86\u51c6\u8d1d\u53f6\u65af\u540e\u9a8c\u7684Bernstein-von Mises\u5b9a\u7406\u6210\u7acb\u7684\u6761\u4ef6\u3002", "motivation": "\u6269\u5c55\u7ecf\u5178\u53c2\u6570GMM\u6a21\u578b\u7684\u7ed3\u679c\uff0c\u4e3a\u975e\u53c2\u6570\u7ed3\u6784\u51fd\u6570\u63d0\u4f9b\u8d1d\u53f6\u65af\u63a8\u65ad\u6846\u67b6\uff0c\u4f7f\u6700\u4f18\u52a0\u6743\u51c6\u8d1d\u53f6\u65af\u53ef\u4fe1\u96c6\u8fbe\u5230\u7cbe\u786e\u7684\u6e10\u8fd1\u9891\u7387\u8986\u76d6\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u7684\u5e7f\u4e49\u51c6\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u5efa\u7acb\u6536\u7f29\u7387\u548cBernstein-von Mises\u5b9a\u7406\u7684\u6761\u4ef6\u3002", "result": "\u51c6\u8d1d\u53f6\u65af\u53ef\u4fe1\u96c6\u5b9e\u73b0\u7cbe\u786e\u6e10\u8fd1\u9891\u7387\u8986\u76d6\uff0c\u6a21\u62df\u663e\u793a\u5e7f\u4e49\u8d1d\u53f6\u65af\u4f30\u8ba1\u5668\u4f18\u4e8e\u5e38\u89c1\u66ff\u4ee3\u65b9\u6cd5\u3002", "conclusion": "\u5e7f\u4e49\u51c6\u8d1d\u53f6\u65af\u6846\u67b6\u6210\u529f\u6269\u5c55\u4e86\u7ecf\u5178GMM\u7ed3\u679c\uff0c\u4e3a\u975e\u53c2\u6570\u6761\u4ef6\u77e9\u9650\u5236\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8d1d\u53f6\u65af\u63a8\u65ad\u5de5\u5177\u3002"}}
{"id": "2510.00182", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00182", "abs": "https://arxiv.org/abs/2510.00182", "authors": ["Jorge Mendez-Mendez"], "title": "A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream", "comment": null, "summary": "Using large language models (LLMs) to solve complex robotics problems\nrequires understanding their planning capabilities. Yet while we know that LLMs\ncan plan on some problems, the extent to which these planning capabilities\ncover the space of robotics tasks is unclear. One promising direction is to\nintegrate the semantic knowledge of LLMs with the formal reasoning of task and\nmotion planning (TAMP). However, the myriad of choices for how to integrate\nLLMs within TAMP complicates the design of such systems. We develop 16\nalgorithms that use Gemini 2.5 Flash to substitute key TAMP components. Our\nzero-shot experiments across 4,950 problems and three domains reveal that the\nGemini-based planners exhibit lower success rates and higher planning times\nthan their engineered counterparts. We show that providing geometric details\nincreases the number of task-planning errors compared to pure PDDL\ndescriptions, and that (faster) non-reasoning LLM variants outperform (slower)\nreasoning variants in most cases, since the TAMP system can direct the LLM to\ncorrect its mistakes.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528Gemini 2.5 Flash\u5927\u8bed\u8a00\u6a21\u578b\u66ff\u4ee3\u4efb\u52a1\u4e0e\u8fd0\u52a8\u89c4\u5212(TAMP)\u5173\u952e\u7ec4\u4ef6\u768416\u79cd\u7b97\u6cd5\uff0c\u57284,950\u4e2a\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8eLLM\u7684\u89c4\u5212\u5668\u6210\u529f\u7387\u8f83\u4f4e\u3001\u89c4\u5212\u65f6\u95f4\u8f83\u957f\uff0c\u4e14\u51e0\u4f55\u7ec6\u8282\u4f1a\u589e\u52a0\u4efb\u52a1\u89c4\u5212\u9519\u8bef\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u673a\u5668\u4eba\u95ee\u9898\u4e2d\u7684\u89c4\u5212\u80fd\u529b\uff0c\u7279\u522b\u662f\u5982\u4f55\u5c06LLM\u7684\u8bed\u4e49\u77e5\u8bc6\u4e0eTAMP\u7684\u5f62\u5f0f\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u4ee5\u4e86\u89e3\u8fd9\u4e9b\u89c4\u5212\u80fd\u529b\u5728\u673a\u5668\u4eba\u4efb\u52a1\u7a7a\u95f4\u4e2d\u7684\u8986\u76d6\u8303\u56f4\u3002", "method": "\u5f00\u53d1\u4e8616\u79cd\u4f7f\u7528Gemini 2.5 Flash\u66ff\u4ee3TAMP\u5173\u952e\u7ec4\u4ef6\u7684\u7b97\u6cd5\uff0c\u5728\u4e09\u4e2a\u9886\u57df\u8fdb\u884c\u4e864,950\u4e2a\u95ee\u9898\u7684\u96f6\u6837\u672c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540cLLM\u53d8\u4f53\u7684\u6027\u80fd\u3002", "result": "\u57fa\u4e8eGemini\u7684\u89c4\u5212\u5668\u6bd4\u5de5\u7a0b\u5316\u5bf9\u5e94\u7269\u6210\u529f\u7387\u66f4\u4f4e\u3001\u89c4\u5212\u65f6\u95f4\u66f4\u957f\uff1b\u63d0\u4f9b\u51e0\u4f55\u7ec6\u8282\u6bd4\u7eafPDDL\u63cf\u8ff0\u4ea7\u751f\u66f4\u591a\u4efb\u52a1\u89c4\u5212\u9519\u8bef\uff1b\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u975e\u63a8\u7406LLM\u53d8\u4f53\uff08\u66f4\u5feb\uff09\u4f18\u4e8e\u63a8\u7406\u53d8\u4f53\uff08\u66f4\u6162\uff09\u3002", "conclusion": "LLM\u5728TAMP\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\u9700\u8981\u8c28\u614e\u8bbe\u8ba1\uff0c\u975e\u63a8\u7406LLM\u53d8\u4f53\u7531\u4e8eTAMP\u7cfb\u7edf\u53ef\u4ee5\u6307\u5bfc\u5176\u7ea0\u6b63\u9519\u8bef\u800c\u8868\u73b0\u66f4\u597d\uff0c\u8868\u660eLLM\u4e0eTAMP\u7684\u534f\u540c\u5de5\u4f5c\u6bd4\u5b8c\u5168\u4f9d\u8d56LLM\u63a8\u7406\u66f4\u6709\u6548\u3002"}}
{"id": "2510.01115", "categories": ["cs.AI", "cs.MA", "econ.TH", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.01115", "abs": "https://arxiv.org/abs/2510.01115", "authors": ["Evan Heus", "Rick Bookstaber", "Dhruv Sharma"], "title": "Exploring Network-Knowledge Graph Duality: A Case Study in Agentic Supply Chain Risk Analysis", "comment": "7 pages, 3 figures", "summary": "Large Language Models (LLMs) struggle with the complex, multi-modal, and\nnetwork-native data underlying financial risk. Standard Retrieval-Augmented\nGeneration (RAG) oversimplifies relationships, while specialist models are\ncostly and static. We address this gap with an LLM-centric agent framework for\nsupply chain risk analysis. Our core contribution is to exploit the inherent\nduality between networks and knowledge graphs (KG). We treat the supply chain\nnetwork as a KG, allowing us to use structural network science principles for\nretrieval. A graph traverser, guided by network centrality scores, efficiently\nextracts the most economically salient risk paths. An agentic architecture\norchestrates this graph retrieval alongside data from numerical factor tables\nand news streams. Crucially, it employs novel ``context shells'' -- descriptive\ntemplates that embed raw figures in natural language -- to make quantitative\ndata fully intelligible to the LLM. This lightweight approach enables the model\nto generate concise, explainable, and context-rich risk narratives in real-time\nwithout costly fine-tuning or a dedicated graph database.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5229\u7528\u7f51\u7edc\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7684\u4e8c\u5143\u6027\u8fdb\u884c\u4f9b\u5e94\u94fe\u98ce\u9669\u5206\u6790\uff0c\u901a\u8fc7\u56fe\u904d\u5386\u548c\u4e0a\u4e0b\u6587\u6a21\u677f\u5b9e\u73b0\u5b9e\u65f6\u3001\u53ef\u89e3\u91ca\u7684\u98ce\u9669\u53d9\u8ff0\u751f\u6210\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u8fc7\u5ea6\u7b80\u5316\u5173\u7cfb\uff0c\u4e13\u4e1a\u6a21\u578b\u6210\u672c\u9ad8\u4e14\u9759\u6001\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u91d1\u878d\u98ce\u9669\u4e2d\u7684\u590d\u6742\u591a\u6a21\u6001\u7f51\u7edc\u6570\u636e\u3002", "method": "\u5c06\u4f9b\u5e94\u94fe\u7f51\u7edc\u89c6\u4e3a\u77e5\u8bc6\u56fe\u8c31\uff0c\u4f7f\u7528\u7f51\u7edc\u4e2d\u5fc3\u6027\u8bc4\u5206\u6307\u5bfc\u56fe\u904d\u5386\u63d0\u53d6\u5173\u952e\u98ce\u9669\u8def\u5f84\uff0c\u7ed3\u5408\u6570\u503c\u56e0\u5b50\u8868\u548c\u65b0\u95fb\u6d41\u6570\u636e\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587\u6a21\u677f\u4f7f\u5b9a\u91cf\u6570\u636e\u5bf9LLM\u53ef\u7406\u89e3\u3002", "result": "\u5b9e\u73b0\u4e86\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u65e0\u9700\u6602\u8d35\u5fae\u8c03\u6216\u4e13\u7528\u56fe\u6570\u636e\u5e93\uff0c\u5373\u53ef\u5b9e\u65f6\u751f\u6210\u7b80\u6d01\u3001\u53ef\u89e3\u91ca\u3001\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u98ce\u9669\u53d9\u8ff0\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u91d1\u878d\u98ce\u9669\u5206\u6790\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u4f9b\u5e94\u94fe\u98ce\u9669\u8bc4\u4f30\u65b9\u6848\u3002"}}
{"id": "2510.00308", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00308", "abs": "https://arxiv.org/abs/2510.00308", "authors": ["Panagiotis Kounatidis", "Andreas A. Malikopoulos"], "title": "Combined Learning and Control: A New Paradigm for Optimal Control with Unknown Dynamics", "comment": "Submitted to ACC 2026", "summary": "In this paper, we present the combined learning-and-control (CLC) approach,\nwhich is a new way to solve optimal control problems with unknown dynamics by\nunifying model-based control and data-driven learning. The key idea is simple:\nwe design a controller to be optimal for a proxy objective built on an\navailable model while penalizing mismatches with the real system, so that the\nresulting controller is also optimal for the actual system. Building on the\noriginal CLC formulation, we demonstrate the framework to the linear quadratic\nregulator problem and make three advances: (i) we show that the CLC penalty is\na sequence of stage-specific weights rather than a single constant; (ii) we\nidentify when these weights can be set in advance and when they must depend on\nthe (unknown) dynamics; and (iii) we develop a lightweight learning loop that\ntunes the weights directly from data without abandoning the benefits of a\nmodel-based design. We provide a complete algorithm and an empirical study\nagainst common baseline methods. The results clarify where prior knowledge\nsuffices and where learning is essential, and they position CLC as a practical,\ntheoretically grounded bridge between classical optimal control and modern\nlearning methods.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5b66\u4e60\u4e0e\u63a7\u5236\uff08CLC\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7edf\u4e00\u57fa\u4e8e\u6a21\u578b\u7684\u63a7\u5236\u548c\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u6765\u89e3\u51b3\u672a\u77e5\u52a8\u529b\u5b66\u7684\u6700\u4f18\u63a7\u5236\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5177\u6709\u672a\u77e5\u52a8\u529b\u5b66\u7684\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u5f25\u5408\u7ecf\u5178\u6700\u4f18\u63a7\u5236\u4e0e\u73b0\u4ee3\u5b66\u4e60\u65b9\u6cd5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u8bbe\u8ba1\u63a7\u5236\u5668\u4f7f\u5176\u5728\u4ee3\u7406\u76ee\u6807\u4e0a\u6700\u4f18\uff0c\u540c\u65f6\u60e9\u7f5a\u4e0e\u771f\u5b9e\u7cfb\u7edf\u7684\u5931\u914d\uff0c\u4ece\u800c\u786e\u4fdd\u63a7\u5236\u5668\u5728\u5b9e\u9645\u7cfb\u7edf\u4e0a\u4e5f\u662f\u6700\u4f18\u7684\u3002", "result": "\u5728\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668\u95ee\u9898\u4e2d\u5c55\u793a\u4e86CLC\u6846\u67b6\uff0c\u660e\u786e\u4e86\u60e9\u7f5a\u6743\u91cd\u7684\u8bbe\u7f6e\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u76f4\u63a5\u4ece\u6570\u636e\u8c03\u6574\u6743\u91cd\u7684\u8f7b\u91cf\u7ea7\u5b66\u4e60\u5faa\u73af\u3002", "conclusion": "CLC\u4f5c\u4e3a\u7ecf\u5178\u6700\u4f18\u63a7\u5236\u4e0e\u73b0\u4ee3\u5b66\u4e60\u65b9\u6cd5\u4e4b\u95f4\u5b9e\u7528\u4e14\u7406\u8bba\u57fa\u7840\u7684\u6865\u6881\uff0c\u660e\u786e\u4e86\u5148\u9a8c\u77e5\u8bc6\u4f55\u65f6\u8db3\u591f\u4ee5\u53ca\u4f55\u65f6\u9700\u8981\u5b66\u4e60\u3002"}}
{"id": "2510.00019", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.00019", "abs": "https://arxiv.org/abs/2510.00019", "authors": ["Zhongyang Liu", "Ying Zhang", "Xiangyi Xiao", "Wenting Liu", "Yuanting Zha", "Haipeng Zhang"], "title": "When Life Paths Cross: Extracting Human Interactions in Time and Space from Wikipedia", "comment": null, "summary": "Interactions among notable individuals -- whether examined individually, in\ngroups, or as networks -- often convey significant messages across cultural,\neconomic, political, scientific, and historical perspectives. By analyzing the\ntimes and locations of these interactions, we can observe how dynamics unfold\nacross regions over time. However, relevant studies are often constrained by\ndata scarcity, particularly concerning the availability of specific location\nand time information. To address this issue, we mine millions of biography\npages from Wikipedia, extracting 685,966 interaction records in the form of\n(Person1, Person2, Time, Location) interaction quadruplets. The key elements of\nthese interactions are often scattered throughout the heterogeneous\ncrowd-sourced text and may be loosely or indirectly associated. We overcome\nthis challenge by designing a model that integrates attention mechanisms,\nmulti-task learning, and feature transfer methods, achieving an F1 score of\n86.51%, which outperforms baseline models. We further conduct an empirical\nanalysis of intra- and inter-party interactions among political figures to\nexamine political polarization in the US, showcasing the potential of the\nextracted data from a perspective that may not be possible without this data.\nWe make our code, the extracted interaction data, and the WikiInteraction\ndataset of 4,507 labeled interaction quadruplets publicly available.", "AI": {"tldr": "\u4ece\u7ef4\u57fa\u767e\u79d1\u4f20\u8bb0\u4e2d\u63d0\u53d6685,966\u6761\u4eba\u7269\u4ea4\u4e92\u8bb0\u5f55\uff0c\u5f00\u53d1\u96c6\u6210\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u6a21\u578b\uff0cF1\u5206\u6570\u8fbe86.51%\uff0c\u7528\u4e8e\u5206\u6790\u7f8e\u56fd\u653f\u6cbb\u4eba\u7269\u4ea4\u4e92\u4ee5\u7814\u7a76\u653f\u6cbb\u6781\u5316\u3002", "motivation": "\u4eba\u7269\u4ea4\u4e92\u5206\u6790\u5728\u6587\u5316\u3001\u7ecf\u6d4e\u3001\u653f\u6cbb\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u53d7\u9650\u4e8e\u4f4d\u7f6e\u548c\u65f6\u95f4\u4fe1\u606f\u7684\u7a00\u7f3a\u6027\uff0c\u9700\u8981\u4ece\u5927\u89c4\u6a21\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u4ea4\u4e92\u6570\u636e\u3002", "method": "\u4ece\u7ef4\u57fa\u767e\u79d1\u6570\u767e\u4e07\u4f20\u8bb0\u9875\u9762\u4e2d\u63d0\u53d6\u4ea4\u4e92\u56db\u5143\u7ec4(\u4eba\u72691,\u4eba\u72692,\u65f6\u95f4,\u4f4d\u7f6e)\uff0c\u8bbe\u8ba1\u96c6\u6210\u6ce8\u610f\u529b\u673a\u5236\u3001\u591a\u4efb\u52a1\u5b66\u4e60\u548c\u7279\u5f81\u8fc1\u79fb\u7684\u6a21\u578b\u6765\u5904\u7406\u6587\u672c\u5f02\u8d28\u6027\u548c\u677e\u6563\u5173\u8054\u95ee\u9898\u3002", "result": "\u6a21\u578bF1\u5206\u6570\u8fbe\u523086.51%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff1b\u63d0\u53d6\u4e86685,966\u6761\u4ea4\u4e92\u8bb0\u5f55\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b4,507\u6761\u6807\u6ce8\u56db\u5143\u7ec4\u7684WikiInteraction\u6570\u636e\u96c6\uff1b\u901a\u8fc7\u7f8e\u56fd\u653f\u6cbb\u4eba\u7269\u4ea4\u4e92\u5206\u6790\u5c55\u793a\u4e86\u6570\u636e\u4ef7\u503c\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u4ece\u7ef4\u57fa\u767e\u79d1\u63d0\u53d6\u4eba\u7269\u4ea4\u4e92\u4fe1\u606f\u7684\u9ad8\u6548\u65b9\u6cd5\uff0c\u4e3a\u7814\u7a76\u793e\u4f1a\u7f51\u7edc\u52a8\u6001\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5e76\u5728\u653f\u6cbb\u6781\u5316\u5206\u6790\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.00312", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00312", "abs": "https://arxiv.org/abs/2510.00312", "authors": ["Matthew David Hamilton"], "title": "Digital Domination: A Case for Republican Liberty in Artificial Intelligence", "comment": null, "summary": "Artificial intelligence is set to revolutionize social and political life in\nunpredictable ways, raising questions about the principles that ought to guide\nits development and regulation. By examining digital advertising and social\nmedia algorithms, this article highlights how artificial intelligence already\nposes a significant threat to the republican conception of liberty -- or\nfreedom from unaccountable power -- and thereby highlights the necessity of\nprotecting republican liberty when integrating artificial intelligence into\nsociety. At an individual level, these algorithms can subconsciously influence\nbehavior and thought, and those subject to this influence have limited power\nover the algorithms they engage. At the political level, these algorithms give\ntechnology company executives and other foreign parties the power to influence\ndomestic political processes, such as elections; the multinational nature of\nalgorithm-based platforms and the speed with which technology companies\ninnovate make incumbent state institutions ineffective at holding these actors\naccountable. At both levels, artificial intelligence has thus created a new\nform of unfreedom: digital domination. By drawing on the works of Quentin\nSkinner, Philip Pettit, and other republican theorists, this article asserts\nthat individuals must have mechanisms to hold algorithms (and those who develop\nthem) accountable in order to be truly free.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u5a01\u80c1\u5171\u548c\u4e3b\u4e49\u81ea\u7531\u89c2\uff0c\u901a\u8fc7\u5206\u6790\u6570\u5b57\u5e7f\u544a\u548c\u793e\u4ea4\u5a92\u4f53\u7b97\u6cd5\uff0c\u63ed\u793aAI\u5728\u4e2a\u4f53\u548c\u653f\u6cbb\u5c42\u9762\u9020\u6210\u7684\u65b0\u578b\u4e0d\u81ea\u7531\u72b6\u6001\u2014\u2014\u6570\u5b57\u652f\u914d\u3002", "motivation": "AI\u6b63\u4ee5\u4e0d\u53ef\u9884\u6d4b\u7684\u65b9\u5f0f\u6539\u53d8\u793e\u4f1a\u653f\u6cbb\u751f\u6d3b\uff0c\u9700\u8981\u660e\u786e\u6307\u5bfc\u5176\u53d1\u5c55\u548c\u76d1\u7ba1\u7684\u539f\u5219\u3002\u6587\u7ae0\u5173\u6ce8AI\u5bf9\u5171\u548c\u4e3b\u4e49\u81ea\u7531\uff08\u514d\u4e8e\u65e0\u95ee\u8d23\u6743\u529b\u7684\u81ea\u7531\uff09\u6784\u6210\u7684\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6570\u5b57\u5e7f\u544a\u548c\u793e\u4ea4\u5a92\u4f53\u7b97\u6cd5\uff0c\u7ed3\u5408\u6606\u6c40\u00b7\u65af\u91d1\u7eb3\u3001\u83f2\u5229\u666e\u00b7\u4f69\u8482\u7279\u7b49\u5171\u548c\u4e3b\u4e49\u7406\u8bba\u5bb6\u7684\u8457\u4f5c\uff0c\u4ece\u4e2a\u4f53\u548c\u653f\u6cbb\u4e24\u4e2a\u5c42\u9762\u63a2\u8ba8AI\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0AI\u5728\u4e2a\u4f53\u5c42\u9762\u80fd\u6f5c\u610f\u8bc6\u5f71\u54cd\u884c\u4e3a\u548c\u601d\u60f3\uff0c\u88ab\u5f71\u54cd\u8005\u5bf9\u8fd9\u4e9b\u7b97\u6cd5\u63a7\u5236\u6709\u9650\uff1b\u5728\u653f\u6cbb\u5c42\u9762\uff0c\u8ba9\u79d1\u6280\u516c\u53f8\u9ad8\u7ba1\u548c\u5916\u56fd\u52bf\u529b\u80fd\u5f71\u54cd\u56fd\u5185\u653f\u6cbb\u8fdb\u7a0b\uff0c\u800c\u73b0\u6709\u56fd\u5bb6\u5236\u5ea6\u96be\u4ee5\u6709\u6548\u95ee\u8d23\u8fd9\u4e9b\u884c\u4e3a\u8005\u3002", "conclusion": "\u5fc5\u987b\u5efa\u7acb\u673a\u5236\u8ba9\u4e2a\u4eba\u80fd\u591f\u5bf9\u7b97\u6cd5\u53ca\u5176\u5f00\u53d1\u8005\u8fdb\u884c\u95ee\u8d23\uff0c\u624d\u80fd\u771f\u6b63\u5b9e\u73b0\u81ea\u7531\u3002AI\u5df2\u7ecf\u521b\u9020\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u4e0d\u81ea\u7531\u72b6\u6001\u2014\u2014\u6570\u5b57\u652f\u914d\u3002"}}
{"id": "2510.00023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00023", "abs": "https://arxiv.org/abs/2510.00023", "authors": ["Quy Minh Le", "Minh Sao Khue Luu", "Khanh-Tung Tran", "Duc-Hai Nguyen", "Hoang-Quoc-Viet Pham", "Quan Le", "Hoang Thanh Lam", "Hoang D. Nguyen"], "title": "ToolBrain: A Flexible Reinforcement Learning Framework for Agentic Tools", "comment": null, "summary": "Effective tool use is essential for agentic AI, yet training agents to\nutilize tools remains challenging due to manually designed rewards, limited\ntraining data, and poor multi-tool selection, resulting in slow adaptation,\nwasted computational resources, and suboptimal performance. We introduce\nToolBrain, a lightweight and user-friendly framework for coaching tool use in\nagentic models with flexible reinforcement learning (RL), easing the barriers\nfor researchers and practitioners to adapt LLM-based agents to specific\ndomains. It supports a wide range of training strategies, including RL\nalgorithms such as GRPO and DPO, as well as supervised learning. ToolBrain\nenables custom reward callables directly on an agent's execution traces or\nsimply utilizes an automated LLM-as-a-judge system for reward generation. It is\npacked with useful capabilities, including knowledge distillation from large to\nsmall models for efficient development, automatic task generation from tool\ndescriptions, seamless tool retrieval, efficient fine-tuning pipelines with\nQLoRA through Unsloth, and quantized inference via bitsandbytes. We demonstrate\nToolBrain through diverse use cases, such as training a CodeAct agent to\nautonomously execute email search tasks, showing fast, targeted improvements\n(up to 30.0%) in tool-use skills while keeping the codebase simple and\nextensible in Agentic AI. Our framework is publicly available at\nhttps://toolbrain.org.", "AI": {"tldr": "ToolBrain\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3AI\u4ee3\u7406\u4f7f\u7528\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u8bbe\u8ba1\u5956\u52b1\u3001\u8bad\u7ec3\u6570\u636e\u6709\u9650\u548c\u591a\u5de5\u5177\u9009\u62e9\u56f0\u96be\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u8bad\u7ec3AI\u4ee3\u7406\u4f7f\u7528\u5de5\u5177\u9762\u4e34\u624b\u52a8\u8bbe\u8ba1\u5956\u52b1\u3001\u8bad\u7ec3\u6570\u636e\u6709\u9650\u3001\u591a\u5de5\u5177\u9009\u62e9\u56f0\u96be\u7b49\u6311\u6218\uff0c\u5bfc\u81f4\u9002\u5e94\u6162\u3001\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1ToolBrain\u6846\u67b6\uff0c\u652f\u6301GRPO\u3001DPO\u7b49\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u548c\u76d1\u7763\u5b66\u4e60\uff0c\u63d0\u4f9b\u81ea\u5b9a\u4e49\u5956\u52b1\u51fd\u6570\u548c\u81ea\u52a8LLM\u8bc4\u5224\u7cfb\u7edf\uff0c\u5305\u542b\u77e5\u8bc6\u84b8\u998f\u3001\u4efb\u52a1\u751f\u6210\u3001\u5de5\u5177\u68c0\u7d22\u7b49\u529f\u80fd\u3002", "result": "\u5728\u90ae\u4ef6\u641c\u7d22\u4efb\u52a1\u4e2d\u8bad\u7ec3CodeAct\u4ee3\u7406\uff0c\u5de5\u5177\u4f7f\u7528\u6280\u80fd\u63d0\u5347\u9ad8\u8fbe30.0%\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u5e93\u7b80\u5355\u4e14\u53ef\u6269\u5c55\u3002", "conclusion": "ToolBrain\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u3001\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5feb\u901f\u63d0\u5347AI\u4ee3\u7406\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u63a8\u52a8Agentic AI\u53d1\u5c55\u3002"}}
{"id": "2510.00188", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00188", "abs": "https://arxiv.org/abs/2510.00188", "authors": ["Alireza Aliyari", "Gholamreza Vossoughi"], "title": "A Novel Robust Control Method Combining DNN-Based NMPC Approximation and PI Control: Application to Exoskeleton Squat Movements", "comment": null, "summary": "Nonlinear Model Predictive Control (NMPC) is a precise controller, but its\nheavy computational load often prevents application in robotic systems. Some\nstudies have attempted to approximate NMPC using deep neural networks\n(NMPC-DNN). However, in the presence of unexpected disturbances or when\noperating conditions differ from training data, this approach lacks robustness,\nleading to large tracking errors. To address this issue, for the first time,\nthe NMPC-DNN output is combined with a PI controller (Hybrid NMPC-DNN-PI). The\nproposed controller is validated by applying it to an exoskeleton robot during\nsquat movement, which has a complex dynamic model and has received limited\nattention regarding robust nonlinear control design. A human-robot dynamic\nmodel with three active joints (ankle, knee, hip) is developed, and more than\n5.3 million training samples are used to train the DNN. The results show that,\nunder unseen conditions for the DNN, the tracking error in Hybrid NMPC-DNN-PI\nis significantly lower compared to NMPC-DNN. Moreover, human joint torques are\ngreatly reduced with the use of the exoskeleton, with RMS values for the\nstudied case reduced by 30.9%, 41.8%, and 29.7% at the ankle, knee, and hip,\nrespectively. In addition, the computational cost of Hybrid NMPC-DNN-PI is\n99.93% lower than that of NMPC.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408NMPC-DNN-PI\u63a7\u5236\u5668\uff0c\u5c06\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u7684\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u4e0ePI\u63a7\u5236\u5668\u7ed3\u5408\uff0c\u5e94\u7528\u4e8e\u5916\u9aa8\u9abc\u673a\u5668\u4eba\u7684\u4e0b\u8e72\u8fd0\u52a8\u63a7\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u672a\u89c1\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u5e76\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edfNMPC\u8ba1\u7b97\u8d1f\u8f7d\u8fc7\u91cd\uff0c\u800c\u7eaf\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u7684NMPC-DNN\u5728\u9762\u5bf9\u610f\u5916\u5e72\u6270\u6216\u4e0e\u8bad\u7ec3\u6570\u636e\u4e0d\u540c\u7684\u5de5\u51b5\u65f6\u7f3a\u4e4f\u9c81\u68d2\u6027\uff0c\u5bfc\u81f4\u8ddf\u8e2a\u8bef\u5dee\u589e\u5927\u3002", "method": "\u9996\u6b21\u5c06NMPC-DNN\u8f93\u51fa\u4e0ePI\u63a7\u5236\u5668\u7ed3\u5408\u5f62\u6210\u6df7\u5408\u63a7\u5236\u5668\uff0c\u5e94\u7528\u4e8e\u5177\u6709\u590d\u6742\u52a8\u529b\u5b66\u6a21\u578b\u7684\u5916\u9aa8\u9abc\u673a\u5668\u4eba\u4e09\u4e3b\u52a8\u5173\u8282\uff08\u8e1d\u3001\u819d\u3001\u9acb\uff09\u4e0b\u8e72\u8fd0\u52a8\u63a7\u5236\uff0c\u4f7f\u7528530\u591a\u4e07\u8bad\u7ec3\u6837\u672c\u8bad\u7ec3DNN\u3002", "result": "\u5728DNN\u672a\u89c1\u6761\u4ef6\u4e0b\uff0c\u6df7\u5408\u63a7\u5236\u5668\u7684\u8ddf\u8e2a\u8bef\u5dee\u663e\u8457\u4f4e\u4e8e\u7eafNMPC-DNN\uff1b\u4f7f\u7528\u5916\u9aa8\u9abc\u540e\u4eba\u4f53\u5173\u8282\u626d\u77e9\u5927\u5e45\u964d\u4f4e\uff08\u8e1d30.9%\u3001\u819d41.8%\u3001\u9acb29.7%\uff09\uff1b\u8ba1\u7b97\u6210\u672c\u6bd4NMPC\u964d\u4f4e99.93%\u3002", "conclusion": "\u6df7\u5408NMPC-DNN-PI\u63a7\u5236\u5668\u5728\u4fdd\u6301NMPC\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u5e76\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u590d\u6742\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u5b9e\u65f6\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00410", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00410", "abs": "https://arxiv.org/abs/2510.00410", "authors": ["Wataru Hashimoto", "Kazumune Hashimoto"], "title": "MM-LMPC: Multi-Modal Learning Model Predictive Control via Bandit-Based Mode Selection", "comment": "This paper is submitted to 2026 American Control Conference (ACC)", "summary": "Learning Model Predictive Control (LMPC) improves performance on iterative\ntasks by leveraging data from previous executions. At each iteration, LMPC\nconstructs a sampled safe set from past trajectories and uses it as a terminal\nconstraint, with a terminal cost given by the corresponding cost-to-go. While\neffective, LMPC heavily depends on the initial trajectories: states with high\ncost-to-go are rarely selected as terminal candidates in later iterations,\nleaving parts of the state space unexplored and potentially missing better\nsolutions. For example, in a reach-avoid task with two possible routes, LMPC\nmay keep refining the initially shorter path while neglecting the alternative\npath that could lead to a globally better solution. To overcome this\nlimitation, we propose Multi-Modal LMPC (MM-LMPC), which clusters past\ntrajectories into modes and maintains mode-specific terminal sets and value\nfunctions. A bandit-based meta-controller with a Lower Confidence Bound (LCB)\npolicy balances exploration and exploitation across modes, enabling systematic\nrefinement of all modes. This allows MM-LMPC to escape high-cost local optima\nand discover globally superior solutions. We establish recursive feasibility,\nclosed-loop stability, asymptotic convergence to the best mode, and a\nlogarithmic regret bound. Simulations on obstacle-avoidance tasks validate the\nperformance improvements of the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MM-LMPC\uff09\uff0c\u901a\u8fc7\u805a\u7c7b\u5386\u53f2\u8f68\u8ff9\u5230\u4e0d\u540c\u6a21\u5f0f\uff0c\u4f7f\u7528\u591a\u81c2\u8001\u864e\u673a\u5143\u63a7\u5236\u5668\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u89e3\u51b3\u4f20\u7edfLMPC\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfLMPC\u4f9d\u8d56\u521d\u59cb\u8f68\u8ff9\uff0c\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u53ef\u80fd\u9519\u8fc7\u5168\u5c40\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002\u4f8b\u5982\u5728\u907f\u969c\u4efb\u52a1\u4e2d\uff0c\u53ef\u80fd\u53ea\u4f18\u5316\u521d\u59cb\u9009\u62e9\u7684\u8def\u5f84\u800c\u5ffd\u7565\u5176\u4ed6\u53ef\u80fd\u66f4\u4f18\u7684\u8def\u5f84\u3002", "method": "\u5c06\u5386\u53f2\u8f68\u8ff9\u805a\u7c7b\u5230\u4e0d\u540c\u6a21\u5f0f\uff0c\u7ef4\u62a4\u6a21\u5f0f\u7279\u5b9a\u7684\u7ec8\u7aef\u96c6\u548c\u4ef7\u503c\u51fd\u6570\uff1b\u4f7f\u7528\u57fa\u4e8e\u7f6e\u4fe1\u4e0b\u754c\uff08LCB\uff09\u7684\u591a\u81c2\u8001\u864e\u673a\u5143\u63a7\u5236\u5668\u6765\u5e73\u8861\u4e0d\u540c\u6a21\u5f0f\u95f4\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5efa\u7acb\u4e86\u9012\u5f52\u53ef\u884c\u6027\u3001\u95ed\u73af\u7a33\u5b9a\u6027\u3001\u6e10\u8fd1\u6536\u655b\u5230\u6700\u4f73\u6a21\u5f0f\u4ee5\u53ca\u5bf9\u6570\u9057\u61be\u754c\uff1b\u5728\u907f\u969c\u4efb\u52a1\u4eff\u771f\u4e2d\u9a8c\u8bc1\u4e86\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MM-LMPC\u80fd\u591f\u9003\u79bb\u9ad8\u6210\u672c\u5c40\u90e8\u6700\u4f18\u89e3\uff0c\u53d1\u73b0\u5168\u5c40\u66f4\u4f18\u89e3\uff0c\u5728\u8fed\u4ee3\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6bd4\u4f20\u7edfLMPC\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.00021", "categories": ["cs.SI", "cs.AI", "cs.CL", "I.2.7, H.3.3"], "pdf": "https://arxiv.org/pdf/2510.00021", "abs": "https://arxiv.org/abs/2510.00021", "authors": ["Alvaro Vallejo Ram\u00edrez"], "title": "IA aplicada al an\u00e1lisis del conflicto Ir\u00e1n-Israel: Mapeo de discursos en YouTube", "comment": "in Spanish language", "summary": "Purpose. This study analyzes the digital representation of the Iran-Israel\nconflict that occurred in June 2025, based on 120,000 comments posted on\nYouTube. It sought to identify discursive positions regarding the actors\ninvolved and to examine how media and algorithmic biases shape digital\nconversations. Methodology. A mixed-methods design with triangulation was\nadopted. In the quantitative phase, natural language processing techniques and\nmachine learning models (BERT and XLM-RoBERTa) were used to classify comments\ninto ten categories. In the qualitative phase, a critical analysis of media\ncontext and ideological narratives was conducted, complemented by manual\nannotation and supervised training. This strategy enabled the integration of\nstatistical robustness with contextual understanding. Results and conclusions.\nThe findings reveal a clear overrepresentation of pro-Palestinian and\nanti-United States/Israel discourses, while pro-United States and\nanti-Palestinian positions were marginal. Iran, usually rendered invisible in\nglobal media, emerged as a central actor in the digital conversation during the\nconflict, suggesting a narrative shift away from previous hegemonic frameworks.\nLikewise, the results confirm the influence of algorithmic biases in amplifying\ncertain discourses while limiting others. Original contributions. This work\ncombines computational analysis and philosophical critique for the study of\ndigital controversies, providing a methodological framework replicable in\ngeopolitical contexts. It is one of the first Spanish-language studies to map,\nthrough artificial intelligence and critical analysis, discourses on an\ninternational conflict on YouTube, highlighting asymmetries and narrative\ndisputes that are often overlooked.", "AI": {"tldr": "\u672c\u7814\u7a76\u57fa\u4e8eYouTube\u4e0a\u768412\u4e07\u6761\u8bc4\u8bba\uff0c\u5206\u6790\u4e862025\u5e746\u6708\u4f0a\u6717-\u4ee5\u8272\u5217\u51b2\u7a81\u7684\u6570\u5b57\u8868\u5f81\uff0c\u8bc6\u522b\u4e86\u76f8\u5173\u53c2\u4e0e\u8005\u7684\u8bba\u8ff0\u7acb\u573a\uff0c\u5e76\u63a2\u8ba8\u4e86\u5a92\u4f53\u548c\u7b97\u6cd5\u504f\u89c1\u5982\u4f55\u5851\u9020\u6570\u5b57\u5bf9\u8bdd\u3002", "motivation": "\u5206\u6790\u6570\u5b57\u7a7a\u95f4\u4e2d\u4f0a\u6717-\u4ee5\u8272\u5217\u51b2\u7a81\u7684\u8bba\u8ff0\u8868\u5f81\uff0c\u8bc6\u522b\u5a92\u4f53\u548c\u7b97\u6cd5\u504f\u89c1\u5bf9\u6570\u5b57\u5bf9\u8bdd\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u5e38\u88ab\u5ffd\u89c6\u7684\u53d9\u4e8b\u4e0d\u5bf9\u79f0\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u8bbe\u8ba1\uff1a\u5b9a\u91cf\u9636\u6bb5\u4f7f\u7528NLP\u6280\u672f\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08BERT\u548cXLM-RoBERTa\uff09\u5c06\u8bc4\u8bba\u5206\u4e3a10\u7c7b\uff1b\u5b9a\u6027\u9636\u6bb5\u8fdb\u884c\u5a92\u4f53\u80cc\u666f\u548c\u610f\u8bc6\u5f62\u6001\u53d9\u4e8b\u7684\u6279\u5224\u5206\u6790\uff0c\u8f85\u4ee5\u4eba\u5de5\u6807\u6ce8\u548c\u76d1\u7763\u8bad\u7ec3\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4eb2\u5df4\u52d2\u65af\u5766\u548c\u53cd\u7f8e\u56fd/\u4ee5\u8272\u5217\u8bba\u8ff0\u660e\u663e\u8fc7\u5ea6\u4ee3\u8868\uff0c\u800c\u4eb2\u7f8e\u56fd\u548c\u53cd\u5df4\u52d2\u65af\u5766\u7acb\u573a\u8fb9\u7f18\u5316\u3002\u4f0a\u6717\u5728\u51b2\u7a81\u671f\u95f4\u6210\u4e3a\u6570\u5b57\u5bf9\u8bdd\u7684\u4e2d\u5fc3\u89d2\u8272\uff0c\u8868\u660e\u53d9\u4e8b\u4ece\u5148\u524d\u9738\u6743\u6846\u67b6\u7684\u8f6c\u53d8\u3002\u7b97\u6cd5\u504f\u89c1\u5728\u653e\u5927\u67d0\u4e9b\u8bba\u8ff0\u540c\u65f6\u9650\u5236\u5176\u4ed6\u8bba\u8ff0\u7684\u5f71\u54cd\u5f97\u5230\u8bc1\u5b9e\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u6570\u5b57\u4e89\u8bae\u7814\u7a76\u63d0\u4f9b\u4e86\u7ed3\u5408\u8ba1\u7b97\u5206\u6790\u548c\u54f2\u5b66\u6279\u5224\u7684\u65b9\u6cd5\u8bba\u6846\u67b6\uff0c\u662f\u9996\u4e2a\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\u548c\u6279\u5224\u5206\u6790\u5728YouTube\u4e0a\u6620\u5c04\u56fd\u9645\u51b2\u7a81\u8bba\u8ff0\u7684\u897f\u73ed\u7259\u8bed\u7814\u7a76\u4e4b\u4e00\uff0c\u63ed\u793a\u4e86\u5e38\u88ab\u5ffd\u89c6\u7684\u4e0d\u5bf9\u79f0\u6027\u548c\u53d9\u4e8b\u4e89\u8bae\u3002"}}
{"id": "2510.00990", "categories": ["cs.CY", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.00990", "abs": "https://arxiv.org/abs/2510.00990", "authors": ["Nicolas Fracaro", "Stefano Cecconello", "Mauro Conti", "Niccol\u00f2 Di Marco", "Alessandro Galeazzi"], "title": "Disc-Cover Complexity Trends in Music Illustrations from Sinatra to Swift", "comment": null, "summary": "The study of art evolution has provided valuable insights into societal\nchange, often revealing long-term patterns of simplification and\ntransformation. Album covers represent a distinctive yet understudied form of\nvisual art that has both shaped and been shaped by cultural, technological, and\ncommercial dynamics over the past century. As highly visible artifacts at the\nintersection of art and commerce, they offer a unique lens through which to\nstudy cultural evolution. In this work, we examine the visual complexity of\nalbum covers spanning 75 years and 11 popular musical genres. Using a diverse\nset of computational measures that capture multiple dimensions of visual\ncomplexity, our analysis reveals a broad shift toward minimalism across most\ngenres, with notable exceptions that highlight the heterogeneity of aesthetic\ntrends. At the same time, we observe growing variance over time, with many\ncovers continuing to display high levels of abstraction and intricacy.\nTogether, these findings position album covers as a rich, quantifiable archive\nof cultural history and underscore the value of computational approaches in the\nsystematic study of the arts, bridging quantitative analysis with aesthetic and\ncultural inquiry.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e8675\u5e74\u95f411\u79cd\u6d41\u884c\u97f3\u4e50\u7c7b\u578b\u7684\u4e13\u8f91\u5c01\u9762\u89c6\u89c9\u590d\u6742\u6027\uff0c\u53d1\u73b0\u5927\u591a\u6570\u6d41\u6d3e\u5448\u73b0\u51fa\u5411\u6781\u7b80\u4e3b\u4e49\u53d1\u5c55\u7684\u8d8b\u52bf\uff0c\u4f46\u540c\u65f6\u4e5f\u5b58\u5728\u4f8b\u5916\u548c\u968f\u65f6\u95f4\u589e\u957f\u7684\u591a\u6837\u6027\u3002", "motivation": "\u4e13\u8f91\u5c01\u9762\u4f5c\u4e3a\u827a\u672f\u4e0e\u5546\u4e1a\u4ea4\u6c47\u7684\u89c6\u89c9\u827a\u672f\u5f62\u5f0f\uff0c\u80fd\u591f\u53cd\u6620\u6587\u5316\u3001\u6280\u672f\u548c\u5546\u4e1a\u52a8\u6001\u7684\u6f14\u53d8\uff0c\u4f46\u6b64\u524d\u7814\u7a76\u4e0d\u8db3\u3002\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8ba1\u7b97\u5206\u6790\u65b9\u6cd5\u7cfb\u7edf\u7814\u7a76\u4e13\u8f91\u5c01\u9762\u4f5c\u4e3a\u6587\u5316\u5386\u53f2\u6863\u6848\u7684\u4ef7\u503c\u3002", "method": "\u4f7f\u7528\u591a\u79cd\u8ba1\u7b97\u5ea6\u91cf\u65b9\u6cd5\uff0c\u6355\u6349\u89c6\u89c9\u590d\u6742\u6027\u7684\u591a\u4e2a\u7ef4\u5ea6\uff0c\u5206\u6790\u8de8\u8d8a75\u5e74\u548c11\u79cd\u6d41\u884c\u97f3\u4e50\u7c7b\u578b\u7684\u4e13\u8f91\u5c01\u9762\u3002", "result": "\u5206\u6790\u663e\u793a\u5927\u591a\u6570\u6d41\u6d3e\u5448\u73b0\u51fa\u5411\u6781\u7b80\u4e3b\u4e49\u53d1\u5c55\u7684\u5e7f\u6cdb\u8d8b\u52bf\uff0c\u4f46\u5b58\u5728\u663e\u8457\u4f8b\u5916\uff0c\u7a81\u663e\u4e86\u5ba1\u7f8e\u8d8b\u52bf\u7684\u5f02\u8d28\u6027\u3002\u540c\u65f6\u89c2\u5bdf\u5230\u968f\u65f6\u95f4\u589e\u957f\u7684\u65b9\u5dee\uff0c\u8bb8\u591a\u5c01\u9762\u7ee7\u7eed\u8868\u73b0\u51fa\u9ad8\u5ea6\u7684\u62bd\u8c61\u6027\u548c\u590d\u6742\u6027\u3002", "conclusion": "\u4e13\u8f91\u5c01\u9762\u662f\u4e30\u5bcc\u7684\u3001\u53ef\u91cf\u5316\u7684\u6587\u5316\u5386\u53f2\u6863\u6848\uff0c\u8ba1\u7b97\u5206\u6790\u65b9\u6cd5\u5728\u7cfb\u7edf\u7814\u7a76\u827a\u672f\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u80fd\u591f\u8fde\u63a5\u5b9a\u91cf\u5206\u6790\u4e0e\u5ba1\u7f8e\u6587\u5316\u63a2\u7a76\u3002"}}
{"id": "2510.00071", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00071", "abs": "https://arxiv.org/abs/2510.00071", "authors": ["Dongqi Zheng"], "title": "ARS: Adaptive Reasoning Suppression for Efficient Large Reasoning Language Models", "comment": "Accepted by 39th NeurIPS - Foundations of Reasoning in Language\n  Models", "summary": "Large Reasoning Language Models (LRLMs or LRMs) demonstrate remarkable\ncapabilities in complex reasoning tasks, but suffer from significant\ncomputational inefficiencies due to overthinking phenomena. Existing efficient\nreasoning methods face the challenge of balancing reasoning quality with\ninference cost reduction. We propose \\textbf{Adaptive Reasoning Suppression\n(ARS)}, a novel training-free approach that dynamically suppresses redundant\nreasoning steps while preserving accuracy through adaptive certainty\nmonitoring. ARS introduces a multi-checkpoint certainty estimation mechanism\nwith progressive suppression thresholds, achieving superior efficiency compared\nto static suppression methods. Our extensive evaluation across mathematical\nreasoning benchmarks using multiple model architectures demonstrates that ARS\nachieves up to 53%, 46.1%, and 57.9% in token, latency and energy reduction,\nwhile maintaining or improving accuracy.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u63a8\u7406\u6291\u5236(ARS)\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6291\u5236\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\u6765\u63d0\u5347\u5927\u578b\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u63a8\u7406\u8d28\u91cf\u4e0e\u63a8\u7406\u6210\u672c\u3002", "method": "\u91c7\u7528\u8bad\u7ec3\u514d\u8d39\u7684\u81ea\u9002\u5e94\u63a8\u7406\u6291\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u68c0\u67e5\u70b9\u786e\u5b9a\u6027\u4f30\u8ba1\u673a\u5236\u548c\u6e10\u8fdb\u6291\u5236\u9608\u503c\u6765\u52a8\u6001\u6291\u5236\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cARS\u5b9e\u73b0\u4e86\u6700\u9ad853%\u7684token\u51cf\u5c11\u300146.1%\u7684\u5ef6\u8fdf\u51cf\u5c11\u548c57.9%\u7684\u80fd\u8017\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "ARS\u65b9\u6cd5\u5728\u591a\u4e2a\u6a21\u578b\u67b6\u6784\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u80fd\u591f\u5728\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u8d28\u91cf\u3002"}}
{"id": "2510.00225", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.00225", "abs": "https://arxiv.org/abs/2510.00225", "authors": ["Yue Meng", "Fei Chen", "Chuchu Fan"], "title": "TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks", "comment": null, "summary": "Learning control policies for complex, long-horizon tasks is a central\nchallenge in robotics and autonomous systems. Signal Temporal Logic (STL)\noffers a powerful and expressive language for specifying such tasks, but its\nnon-Markovian nature and inherent sparse reward make it difficult to be solved\nvia standard Reinforcement Learning (RL) algorithms. Prior RL approaches focus\nonly on limited STL fragments or use STL robustness scores as sparse terminal\nrewards. In this paper, we propose TGPO, Temporal Grounded Policy Optimization,\nto solve general STL tasks. TGPO decomposes STL into timed subgoals and\ninvariant constraints and provides a hierarchical framework to tackle the\nproblem. The high-level component of TGPO proposes concrete time allocations\nfor these subgoals, and the low-level time-conditioned policy learns to achieve\nthe sequenced subgoals using a dense, stage-wise reward signal. During\ninference, we sample various time allocations and select the most promising\nassignment for the policy network to rollout the solution trajectory. To foster\nefficient policy learning for complex STL with multiple subgoals, we leverage\nthe learned critic to guide the high-level temporal search via\nMetropolis-Hastings sampling, focusing exploration on temporally feasible\nsolutions. We conduct experiments on five environments, ranging from\nlow-dimensional navigation to manipulation, drone, and quadrupedal locomotion.\nUnder a wide range of STL tasks, TGPO significantly outperforms\nstate-of-the-art baselines (especially for high-dimensional and long-horizon\ncases), with an average of 31.6% improvement in task success rate compared to\nthe best baseline. The code will be available at\nhttps://github.com/mengyuest/TGPO", "AI": {"tldr": "TGPO\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u89e3\u51b3\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u4efb\u52a1\uff0c\u901a\u8fc7\u5c06STL\u5206\u89e3\u4e3a\u5b9a\u65f6\u5b50\u76ee\u6807\u548c\u4e0d\u53d8\u7ea6\u675f\uff0c\u4f7f\u7528\u9ad8\u5c42\u65f6\u95f4\u5206\u914d\u548c\u4f4e\u5c42\u65f6\u95f4\u6761\u4ef6\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u96be\u4ee5\u5904\u7406STL\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u7279\u6027\u548c\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u5904\u7406\u6709\u9650\u7684STL\u7247\u6bb5\u6216\u4f7f\u7528\u7a00\u758f\u7ec8\u7aef\u5956\u52b1\u3002", "method": "TGPO\u5c06STL\u5206\u89e3\u4e3a\u5b9a\u65f6\u5b50\u76ee\u6807\u548c\u4e0d\u53d8\u7ea6\u675f\uff0c\u91c7\u7528\u5206\u5c42\u6846\u67b6\uff1a\u9ad8\u5c42\u7ec4\u4ef6\u63d0\u51fa\u5177\u4f53\u65f6\u95f4\u5206\u914d\uff0c\u4f4e\u5c42\u65f6\u95f4\u6761\u4ef6\u7b56\u7565\u4f7f\u7528\u5bc6\u96c6\u7684\u9636\u6bb5\u5956\u52b1\u5b66\u4e60\u5b9e\u73b0\u5e8f\u5217\u5b50\u76ee\u6807\u3002\u5728\u63a8\u7406\u65f6\u91c7\u6837\u591a\u79cd\u65f6\u95f4\u5206\u914d\uff0c\u5e76\u4f7f\u7528Metropolis-Hastings\u91c7\u6837\u5f15\u5bfc\u9ad8\u5c42\u65f6\u95f4\u641c\u7d22\u3002", "result": "\u5728\u4e94\u4e2a\u73af\u5883\u4e2d\uff08\u4ece\u4f4e\u7ef4\u5bfc\u822a\u5230\u64cd\u4f5c\u3001\u65e0\u4eba\u673a\u548c\u56db\u8db3\u673a\u5668\u4eba\u8fd0\u52a8\uff09\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTGPO\u5728\u5e7f\u6cdb\u7684STL\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u4efb\u52a1\u6210\u529f\u7387\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u9ad8\u4e8631.6%\u3002", "conclusion": "TGPO\u4e3a\u5904\u7406\u590d\u6742\u3001\u957f\u65f6\u7a0b\u7684STL\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7279\u522b\u5728\u9ad8\u7ef4\u548c\u957f\u65f6\u7a0b\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.00433", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00433", "abs": "https://arxiv.org/abs/2510.00433", "authors": ["Yu Mei", "Xinyu Zhou", "Xiaobo Tan"], "title": "Modeling and Mixed-Integer Nonlinear MPC of Positive-Negative Pressure Pneumatic Systems", "comment": "Has been submitted to conference", "summary": "Positive-negative pressure regulation is critical to soft robotic actuators,\nenabling large motion ranges and versatile actuation modes. However, it remains\nchallenging due to complex nonlinearities, oscillations, and\ndirection-dependent, piecewise dynamics introduced by affordable pneumatic\nvalves and the bidirectional architecture. We present a model-based control\nframework that couples a physics-grounded switched nonlinear plant model\n(inflation/deflation modes) with a mixed-integer nonlinear model predictive\ncontroller (MI-NMPC). The controller co-optimizes mode scheduling and PWM\ninputs to realize accurate reference tracking while enforcing input constraints\nand penalizing energy consumption and excessive switching. To make discrete\nmode decisions tractable, we employ a Combinatorial Integral Approximation that\nrelaxes binary mode variables to continuous surrogates within the\nvalve-scheduling layer. With parameters identified from the physical system,\nsimulations with step and sinusoidal references validate the proposed MI-NMPC,\nshowing a consistently favorable trade-off among accuracy, control effort, and\nswitching, and outperforming conventional PID and NMPC with heuristic mode\nselection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MI-NMPC)\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u9a71\u52a8\u5668\u6b63\u8d1f\u538b\u8c03\u8282\u6846\u67b6\uff0c\u901a\u8fc7\u8026\u5408\u7269\u7406\u57fa\u7840\u7684\u5207\u6362\u975e\u7ebf\u6027\u6a21\u578b\u548c\u4f18\u5316\u7b97\u6cd5\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684\u53c2\u8003\u8ddf\u8e2a\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u9a71\u52a8\u5668\u4e2d\u7684\u6b63\u8d1f\u538b\u8c03\u8282\u9762\u4e34\u590d\u6742\u975e\u7ebf\u6027\u3001\u632f\u8361\u548c\u65b9\u5411\u76f8\u5173\u7684\u5206\u6bb5\u52a8\u529b\u5b66\u7b49\u6311\u6218\uff0c\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u7279\u6027\u3002", "method": "\u91c7\u7528\u7269\u7406\u57fa\u7840\u7684\u5207\u6362\u975e\u7ebf\u6027\u6a21\u578b(\u5145\u6c14/\u653e\u6c14\u6a21\u5f0f)\u4e0e\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668(MI-NMPC)\u76f8\u7ed3\u5408\uff0c\u4f7f\u7528\u7ec4\u5408\u79ef\u5206\u8fd1\u4f3c\u65b9\u6cd5\u5904\u7406\u79bb\u6563\u6a21\u5f0f\u51b3\u7b56\uff0c\u5171\u540c\u4f18\u5316\u6a21\u5f0f\u8c03\u5ea6\u548cPWM\u8f93\u5165\u3002", "result": "\u4eff\u771f\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9636\u8dc3\u548c\u6b63\u5f26\u53c2\u8003\u4fe1\u53f7\u4e0b\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5728\u7cbe\u5ea6\u3001\u63a7\u5236\u52aa\u529b\u548c\u5207\u6362\u9891\u7387\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6709\u5229\u7684\u6743\u8861\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684PID\u548c\u542f\u53d1\u5f0f\u6a21\u5f0f\u9009\u62e9\u7684NMPC\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684MI-NMPC\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u8f6f\u4f53\u673a\u5668\u4eba\u9a71\u52a8\u5668\u6b63\u8d1f\u538b\u8c03\u8282\u4e2d\u7684\u590d\u6742\u52a8\u529b\u5b66\u7279\u6027\uff0c\u4e3a\u5b9e\u73b0\u9ad8\u6027\u80fd\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00024", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00024", "abs": "https://arxiv.org/abs/2510.00024", "authors": ["Mohammad Hossein Samaei", "Faryad Darabi Sahneh", "Lee W. Cohnstaedt", "Caterina Scoglio"], "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "comment": null, "summary": "Large Language Models (LLMs) offer new opportunities to automate complex\ninterdisciplinary research domains. Epidemic modeling, characterized by its\ncomplexity and reliance on network science, dynamical systems, epidemiology,\nand stochastic simulations, represents a prime candidate for leveraging\nLLM-driven automation. We introduce \\textbf{EpidemIQs}, a novel multi-agent LLM\nframework that integrates user inputs and autonomously conducts literature\nreview, analytical derivation, network modeling, mechanistic modeling,\nstochastic simulations, data visualization and analysis, and finally\ndocumentation of findings in a structured manuscript. We introduced two types\nof agents: a scientist agent for planning, coordination, reflection, and\ngeneration of final results, and a task-expert agent to focus exclusively on\none specific duty serving as a tool to the scientist agent. The framework\nconsistently generated complete reports in scientific article format.\nSpecifically, using GPT 4.1 and GPT 4.1 mini as backbone LLMs for scientist and\ntask-expert agents, respectively, the autonomous process completed with average\ntotal token usage 870K at a cost of about \\$1.57 per study, achieving a 100\\%\ncompletion success rate through our experiments. We evaluate EpidemIQs across\ndifferent epidemic scenarios, measuring computational cost, completion success\nrate, and AI and human expert reviews of generated reports. We compare\nEpidemIQs to the single-agent LLM, which has the same system prompts and tools,\niteratively planning, invoking tools, and revising outputs until task\ncompletion. The comparison shows consistently higher performance of the\nproposed framework across five different scenarios. EpidemIQs represents a step\nforward in accelerating scientific research by significantly reducing costs and\nturnaround time of discovery processes, and enhancing accessibility to advanced\nmodeling tools.", "AI": {"tldr": "EpidemIQs\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6d41\u884c\u75c5\u5efa\u6a21\u7814\u7a76\uff0c\u80fd\u591f\u81ea\u4e3b\u5b8c\u6210\u6587\u732e\u7efc\u8ff0\u3001\u5206\u6790\u63a8\u5bfc\u3001\u7f51\u7edc\u5efa\u6a21\u3001\u968f\u673a\u6a21\u62df\u7b49\u4efb\u52a1\uff0c\u5e76\u4ee5\u79d1\u5b66\u8bba\u6587\u683c\u5f0f\u751f\u6210\u5b8c\u6574\u62a5\u544a\u3002", "motivation": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u590d\u6742\u7684\u8de8\u5b66\u79d1\u7814\u7a76\u9886\u57df\uff0c\u7279\u522b\u662f\u6d41\u884c\u75c5\u5efa\u6a21\u8fd9\u79cd\u6d89\u53ca\u7f51\u7edc\u79d1\u5b66\u3001\u52a8\u529b\u7cfb\u7edf\u3001\u6d41\u884c\u75c5\u5b66\u548c\u968f\u673a\u6a21\u62df\u7684\u590d\u6742\u9886\u57df\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u79d1\u5b66\u5bb6\u667a\u80fd\u4f53\uff08\u8d1f\u8d23\u89c4\u5212\u3001\u534f\u8c03\u548c\u751f\u6210\u6700\u7ec8\u7ed3\u679c\uff09\u548c\u4efb\u52a1\u4e13\u5bb6\u667a\u80fd\u4f53\uff08\u4e13\u6ce8\u4e8e\u7279\u5b9a\u4efb\u52a1\uff09\uff0c\u4f7f\u7528GPT 4.1\u548cGPT 4.1 mini\u4f5c\u4e3a\u9aa8\u5e72\u6a21\u578b\u3002", "result": "\u6846\u67b6\u80fd\u591f100%\u6210\u529f\u751f\u6210\u5b8c\u6574\u79d1\u5b66\u62a5\u544a\uff0c\u5e73\u5747\u603btoken\u4f7f\u7528\u91cf\u4e3a870K\uff0c\u6bcf\u9879\u7814\u7a76\u6210\u672c\u7ea61.57\u7f8e\u5143\uff0c\u5728\u4e94\u4e2a\u4e0d\u540c\u573a\u666f\u4e2d\u5747\u8868\u73b0\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u3002", "conclusion": "EpidemIQs\u901a\u8fc7\u663e\u8457\u964d\u4f4e\u53d1\u73b0\u8fc7\u7a0b\u7684\u6210\u672c\u548c\u5468\u8f6c\u65f6\u95f4\uff0c\u5e76\u589e\u5f3a\u5bf9\u5148\u8fdb\u5efa\u6a21\u5de5\u5177\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u63a8\u52a8\u4e86\u79d1\u5b66\u7814\u7a76\u7684\u52a0\u901f\u53d1\u5c55\u3002"}}
{"id": "2510.00075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00075", "abs": "https://arxiv.org/abs/2510.00075", "authors": ["Rishi Bommasani"], "title": "NeurIPS should lead scientific consensus on AI policy", "comment": "Published at NeurIPS 2025", "summary": "Designing wise AI policy is a grand challenge for society. To design such\npolicy, policymakers should place a premium on rigorous evidence and scientific\nconsensus. While several mechanisms exist for evidence generation, and nascent\nmechanisms tackle evidence synthesis, we identify a complete void on consensus\nformation. In this position paper, we argue NeurIPS should actively catalyze\nscientific consensus on AI policy. Beyond identifying the current deficit in\nconsensus formation mechanisms, we argue that NeurIPS is the best option due\nits strengths and the paucity of compelling alternatives. To make progress, we\nrecommend initial pilots for NeurIPS by distilling lessons from the IPCC's\nleadership to build scientific consensus on climate policy. We dispel\npredictable counters that AI researchers disagree too much to achieve consensus\nand that policy engagement is not the business of NeurIPS. NeurIPS leads AI on\nmany fronts, and it should champion scientific consensus to create higher\nquality AI policy.", "AI": {"tldr": "NeurIPS\u5e94\u8be5\u79ef\u6781\u63a8\u52a8AI\u653f\u7b56\u79d1\u5b66\u5171\u8bc6\u7684\u5f62\u6210\uff0c\u4ee5\u5236\u5b9a\u66f4\u660e\u667a\u7684AI\u653f\u7b56\u3002", "motivation": "\u5f53\u524dAI\u653f\u7b56\u5236\u5b9a\u7f3a\u4e4f\u79d1\u5b66\u5171\u8bc6\u5f62\u6210\u673a\u5236\uff0c\u800cNeurIPS\u4f5c\u4e3aAI\u9886\u57df\u7684\u9886\u5bfc\u8005\uff0c\u6700\u9002\u5408\u627f\u62c5\u8fd9\u4e00\u89d2\u8272\u3002", "method": "\u5efa\u8baeNeurIPS\u501f\u9274IPCC\u5728\u6c14\u5019\u653f\u7b56\u5171\u8bc6\u5f62\u6210\u65b9\u9762\u7684\u7ecf\u9a8c\uff0c\u5f00\u5c55\u521d\u6b65\u8bd5\u70b9\u9879\u76ee\u3002", "result": "\u8bba\u6587\u8bc6\u522b\u4e86AI\u653f\u7b56\u5171\u8bc6\u5f62\u6210\u7684\u7a7a\u767d\uff0c\u5e76\u8bba\u8bc1\u4e86NeurIPS\u4f5c\u4e3a\u6700\u4f73\u9009\u62e9\u7684\u539f\u56e0\u3002", "conclusion": "NeurIPS\u5e94\u8be5\u5728AI\u653f\u7b56\u79d1\u5b66\u5171\u8bc6\u5f62\u6210\u65b9\u9762\u53d1\u6325\u9886\u5bfc\u4f5c\u7528\uff0c\u4ee5\u5236\u5b9a\u66f4\u9ad8\u8d28\u91cf\u7684AI\u653f\u7b56\u3002"}}
{"id": "2510.00272", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00272", "abs": "https://arxiv.org/abs/2510.00272", "authors": ["Odichimnma Ezeji", "Michael Ziegltrum", "Giulio Turrisi", "Tommaso Belvedere", "Valerio Modugno"], "title": "BC-MPPI: A Probabilistic Constraint Layer for Safe Model-Predictive Path-Integral Control", "comment": null, "summary": "Model Predictive Path Integral (MPPI) control has recently emerged as a fast,\ngradient-free alternative to model-predictive control in highly non-linear\nrobotic tasks, yet it offers no hard guarantees on constraint satisfaction. We\nintroduce Bayesian-Constraints MPPI (BC-MPPI), a lightweight safety layer that\nattaches a probabilistic surrogate to every state and input constraint. At each\nre-planning step the surrogate returns the probability that a candidate\ntrajectory is feasible; this joint probability scales the weight given to a\ncandidate, automatically down-weighting rollouts likely to collide or exceed\nlimits and pushing the sampling distribution toward the safe subset; no\nhand-tuned penalty costs or explicit sample rejection required. We train the\nsurrogate from 1000 offline simulations and deploy the controller on a\nquadrotor in MuJoCo with both static and moving obstacles. Across K in\n[100,1500] rollouts BC-MPPI preserves safety margins while satisfying the\nprescribed probability of violation. Because the surrogate is a stand-alone,\nversion-controlled artefact and the runtime safety score is a single scalar,\nthe approach integrates naturally with verification-and-validation pipelines\nfor certifiable autonomous systems.", "AI": {"tldr": "BC-MPPI\u662f\u4e00\u79cd\u5728MPPI\u63a7\u5236\u4e2d\u52a0\u5165\u6982\u7387\u7ea6\u675f\u7684\u5b89\u5168\u5c42\uff0c\u901a\u8fc7\u6982\u7387\u4ee3\u7406\u8bc4\u4f30\u8f68\u8ff9\u53ef\u884c\u6027\uff0c\u81ea\u52a8\u964d\u4f4e\u53ef\u80fd\u8fdd\u53cd\u7ea6\u675f\u7684\u8f68\u8ff9\u6743\u91cd\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u60e9\u7f5a\u6210\u672c\u3002", "motivation": "MPPI\u63a7\u5236\u867d\u7136\u5feb\u901f\u4e14\u65e0\u9700\u68af\u5ea6\uff0c\u4f46\u7f3a\u4e4f\u786c\u6027\u7ea6\u675f\u4fdd\u8bc1\u3002\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u5b89\u5168\u5c42\u6765\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u4e3a\u6bcf\u4e2a\u72b6\u6001\u548c\u8f93\u5165\u7ea6\u675f\u9644\u52a0\u6982\u7387\u4ee3\u7406\uff0c\u5728\u6bcf\u6b21\u91cd\u89c4\u5212\u65f6\u8bc4\u4f30\u5019\u9009\u8f68\u8ff9\u7684\u53ef\u884c\u6027\u6982\u7387\uff0c\u8be5\u6982\u7387\u7528\u4e8e\u7f29\u653e\u8f68\u8ff9\u6743\u91cd\uff0c\u63a8\u52a8\u91c7\u6837\u5206\u5e03\u671d\u5411\u5b89\u5168\u5b50\u96c6\u3002", "result": "\u5728\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u6a21\u62df\u4e2d\uff0cBC-MPPI\u5728\u4fdd\u6301\u5b89\u5168\u88d5\u5ea6\u7684\u540c\u65f6\u6ee1\u8db3\u89c4\u5b9a\u7684\u8fdd\u53cd\u6982\u7387\u8981\u6c42\uff0c\u9002\u7528\u4e8e100-1500\u4e2a\u91c7\u6837\u70b9\u8303\u56f4\u3002", "conclusion": "BC-MPPI\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u96c6\u6210\u5230\u8ba4\u8bc1\u81ea\u4e3b\u7cfb\u7edf\u9a8c\u8bc1\u6d41\u7a0b\u4e2d\u7684\u8f7b\u91cf\u7ea7\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7406\u6a21\u578b\u53ef\u4f5c\u4e3a\u72ec\u7acb\u3001\u7248\u672c\u63a7\u5236\u7684\u7ec4\u4ef6\u3002"}}
{"id": "2510.00435", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00435", "abs": "https://arxiv.org/abs/2510.00435", "authors": ["Dipankar Shakya", "Theodore S. Rappaport", "Ethan Shieh", "Michael E. Knox", "Hamed Rahmani", "Davood Shahrjerdi", "Mingjun Ying", "Kimberley Fan", "Matt Lu", "Andrej Rumiantsev", "Vince Mallette", "Gavin Fisher", "Giancarlo De Chirico", "Pratik Ghate", "Shean McMahon"], "title": "Four-Port Probe Stations and SOLR Calibration Standard Design up to 125 GHz on 28 nm CMOS", "comment": "3 pages, 5 figures, Asia-Pacific Microwave Conference 2025", "summary": "This paper presents two innovative four-port probe stations developed by\nFormFactor Incorporated (FFI) and MPI Corporation (MPI), and a four-port\ncalibration standard design up to 125 GHz for the probe stations. True\nfour-port probing at mmWave and beyond does not yet exist, but is anticipated\nfor future multi-band wireless devices using several antennas and RF chains.\nThe four-port probe stations are housed in the THz measurement facility at NYU\nand allow simultaneous probing from East, West, North, and South orientations,\nwhich presents challenges for calibration. An on-chip\nShort-Open-Load-Reciprocal (SOLR) calibration (cal) standard is designed\nleveraging UMC's 28 nm CMOS process. S/O/L standard S-parameters are extracted\nusing a virtual multiline Thru-Reflect-Line (mTRL) cal and used to validate\nSOLR cal performance via simulations up to 125 GHz. The novel probing solutions\nfrom MPI and FFI, along with the SOLR cal, open up considerable opportunities\nfor precise RF characterization across wide frequency ranges.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e24\u79cd\u521b\u65b0\u7684\u56db\u7aef\u53e3\u63a2\u9488\u53f0\u548c\u9ad8\u8fbe125 GHz\u7684\u56db\u7aef\u53e3\u6821\u51c6\u6807\u51c6\uff0c\u7528\u4e8e\u672a\u6765\u591a\u9891\u6bb5\u65e0\u7ebf\u8bbe\u5907\u7684\u7cbe\u786e\u5c04\u9891\u8868\u5f81", "motivation": "\u771f\u6b63\u7684\u56db\u7aef\u53e3\u63a2\u6d4b\u5728\u6beb\u7c73\u6ce2\u53ca\u66f4\u9ad8\u9891\u7387\u5c1a\u4e0d\u5b58\u5728\uff0c\u4f46\u672a\u6765\u591a\u9891\u6bb5\u65e0\u7ebf\u8bbe\u5907\u9700\u8981\u540c\u65f6\u4f7f\u7528\u591a\u4e2a\u5929\u7ebf\u548c\u5c04\u9891\u94fe", "method": "\u8bbe\u8ba1\u57fa\u4e8eUMC 28 nm CMOS\u5de5\u827a\u7684\u7247\u4e0aSOLR\u6821\u51c6\u6807\u51c6\uff0c\u4f7f\u7528\u865a\u62df\u591a\u7ebfTRL\u6821\u51c6\u63d0\u53d6S/O/L\u6807\u51c6S\u53c2\u6570\uff0c\u9a8c\u8bc1SOLR\u6821\u51c6\u6027\u80fd", "result": "\u6210\u529f\u5f00\u53d1\u4e86MPI\u548cFFI\u7684\u65b0\u578b\u63a2\u9488\u89e3\u51b3\u65b9\u6848\u4ee5\u53caSOLR\u6821\u51c6\uff0c\u4e3a\u5bbd\u9891\u7387\u8303\u56f4\u7684\u7cbe\u786e\u5c04\u9891\u8868\u5f81\u63d0\u4f9b\u4e86\u91cd\u8981\u673a\u4f1a", "conclusion": "\u8fd9\u4e9b\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u4e3a\u672a\u6765\u65e0\u7ebf\u8bbe\u5907\u7684\u7cbe\u786e\u5c04\u9891\u6d4b\u91cf\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027"}}
{"id": "2510.00036", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.00036", "abs": "https://arxiv.org/abs/2510.00036", "authors": ["Tridib Banerjee"], "title": "Modeling Product Ecosystems", "comment": "This is a text writeup I hope someone will find useful. I failed to\n  find a suitable journal and this is not something that aligns with my\n  professional work. As such, I can no longer expend more time on this and thus\n  leave it up to the world and those who might fancy a curious read", "summary": "This paper develops a dynamical-systems framework for modeling influence\npropagation in product adoption networks, formulated as a positive linear\nsystem with Metzler interaction matrices and utility-based decay. Exact\nsolutions are derived for constant, piecewise-constant, and fully time-varying\ninteraction structures using matrix exponentials and the Peano--Baker series.\nIt establishes five results: (i) positive interactions guarantee nonnegative\namplification, (ii) perceived utility saturates after $\\approx\\!3$\ncomplementary additions (Weber--Fechner), (iii) frequency of comparable\nintroductions dominates incremental quality improvements, (iv) reinforcing\ninteractions yields monotone gains while decay control gives ambiguous effects,\nand (v) long-run retention under SIS-type dynamics is bounded by the inverse\nspectral radius of the adoption graph. These results extend epidemic-threshold\ntheory and positive-systems analysis to networked adoption, yielding explicit,\ncalibratable expressions for influence dynamics on networks.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u52a8\u6001\u7cfb\u7edf\u6846\u67b6\u6765\u5efa\u6a21\u4ea7\u54c1\u91c7\u7528\u7f51\u7edc\u4e2d\u7684\u5f71\u54cd\u4f20\u64ad\uff0c\u4f7f\u7528Metzler\u4ea4\u4e92\u77e9\u9635\u548c\u57fa\u4e8e\u6548\u7528\u7684\u8870\u51cf\u3002\u63a8\u5bfc\u4e86\u6052\u5b9a\u3001\u5206\u6bb5\u6052\u5b9a\u548c\u5b8c\u5168\u65f6\u53d8\u4ea4\u4e92\u7ed3\u6784\u7684\u7cbe\u786e\u89e3\uff0c\u5efa\u7acb\u4e86\u4e94\u4e2a\u5173\u952e\u7ed3\u679c\uff0c\u5305\u62ec\u6b63\u4ea4\u4e92\u4fdd\u8bc1\u975e\u8d1f\u653e\u5927\u3001\u611f\u77e5\u6548\u7528\u9971\u548c\u3001\u5f15\u5165\u9891\u7387\u4e3b\u5bfc\u8d28\u91cf\u6539\u8fdb\u7b49\u3002", "motivation": "\u5c06\u6d41\u884c\u75c5\u9608\u503c\u7406\u8bba\u548c\u6b63\u7cfb\u7edf\u5206\u6790\u6269\u5c55\u5230\u7f51\u7edc\u5316\u91c7\u7528\u573a\u666f\uff0c\u4e3a\u7f51\u7edc\u4e0a\u7684\u5f71\u54cd\u52a8\u6001\u63d0\u4f9b\u53ef\u6821\u51c6\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\u3002", "method": "\u4f7f\u7528Metzler\u4ea4\u4e92\u77e9\u9635\u548c\u57fa\u4e8e\u6548\u7528\u7684\u8870\u51cf\u6784\u5efa\u6b63\u7ebf\u6027\u7cfb\u7edf\uff0c\u901a\u8fc7\u77e9\u9635\u6307\u6570\u548cPeano-Baker\u7ea7\u6570\u63a8\u5bfc\u7cbe\u786e\u89e3\u3002", "result": "\u5efa\u7acb\u4e86\u4e94\u4e2a\u6838\u5fc3\u7ed3\u679c\uff1a\u6b63\u4ea4\u4e92\u7684\u975e\u8d1f\u653e\u5927\u7279\u6027\u3001\u611f\u77e5\u6548\u7528\u7684\u97e6\u4f2f-\u8d39\u5e0c\u7eb3\u9971\u548c\u3001\u5f15\u5165\u9891\u7387\u4f18\u4e8e\u8d28\u91cf\u6539\u8fdb\u3001\u5f3a\u5316\u4ea4\u4e92\u7684\u5355\u8c03\u589e\u76ca\u6548\u5e94\uff0c\u4ee5\u53caSIS\u578b\u52a8\u6001\u4e0b\u957f\u671f\u4fdd\u6301\u7684\u8c31\u534a\u5f84\u4e0a\u754c\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u6d41\u884c\u75c5\u9608\u503c\u7406\u8bba\u548c\u6b63\u7cfb\u7edf\u5206\u6790\u6210\u529f\u6269\u5c55\u5230\u7f51\u7edc\u5316\u91c7\u7528\u573a\u666f\uff0c\u4e3a\u5f71\u54cd\u52a8\u6001\u63d0\u4f9b\u4e86\u53ef\u6821\u51c6\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\uff0c\u6df1\u5316\u4e86\u5bf9\u7f51\u7edc\u4f20\u64ad\u673a\u5236\u7684\u7406\u89e3\u3002"}}
{"id": "2510.00084", "categories": ["cs.AI", "cs.CY", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.00084", "abs": "https://arxiv.org/abs/2510.00084", "authors": ["Fabian Kovac", "Sebastian Neumaier", "Timea Pahi", "Torsten Priebe", "Rafael Rodrigues", "Dimitrios Christodoulou", "Maxime Cordy", "Sylvain Kubler", "Ali Kordia", "Georgios Pitsiladis", "John Soldatos", "Petros Zervoudakis"], "title": "Towards a Framework for Supporting the Ethical and Regulatory Certification of AI Systems", "comment": "Accepted for publication in the proceedings of the Workshop on AI\n  Certification, Fairness and Regulations, co-located with the Austrian\n  Symposium on AI and Vision (AIRoV 2025)", "summary": "Artificial Intelligence has rapidly become a cornerstone technology,\nsignificantly influencing Europe's societal and economic landscapes. However,\nthe proliferation of AI also raises critical ethical, legal, and regulatory\nchallenges. The CERTAIN (Certification for Ethical and Regulatory Transparency\nin Artificial Intelligence) project addresses these issues by developing a\ncomprehensive framework that integrates regulatory compliance, ethical\nstandards, and transparency into AI systems. In this position paper, we outline\nthe methodological steps for building the core components of this framework.\nSpecifically, we present: (i) semantic Machine Learning Operations (MLOps) for\nstructured AI lifecycle management, (ii) ontology-driven data lineage tracking\nto ensure traceability and accountability, and (iii) regulatory operations\n(RegOps) workflows to operationalize compliance requirements. By implementing\nand validating its solutions across diverse pilots, CERTAIN aims to advance\nregulatory compliance and to promote responsible AI innovation aligned with\nEuropean standards.", "AI": {"tldr": "CERTAIN\u9879\u76ee\u5f00\u53d1\u4e86\u4e00\u4e2a\u7efc\u5408\u6846\u67b6\uff0c\u5c06\u76d1\u7ba1\u5408\u89c4\u3001\u4f26\u7406\u6807\u51c6\u548c\u900f\u660e\u5ea6\u6574\u5408\u5230AI\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u8bed\u4e49MLOps\u3001\u672c\u4f53\u9a71\u52a8\u7684\u6570\u636e\u8c31\u7cfb\u8ffd\u8e2a\u548cRegOps\u5de5\u4f5c\u6d41\u7a0b\u6765\u6784\u5efa\u6838\u5fc3\u7ec4\u4ef6\u3002", "motivation": "AI\u5728\u6b27\u6d32\u793e\u4f1a\u548c\u7ecf\u6d4e\u4e2d\u7684\u5feb\u901f\u666e\u53ca\u5e26\u6765\u4e86\u5173\u952e\u7684\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u76d1\u7ba1\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u4ee5\u4fc3\u8fdb\u8d1f\u8d23\u4efb\u7684AI\u521b\u65b0\u3002", "method": "\u91c7\u7528\u8bed\u4e49MLOps\u8fdb\u884c\u7ed3\u6784\u5316AI\u751f\u547d\u5468\u671f\u7ba1\u7406\uff0c\u672c\u4f53\u9a71\u52a8\u7684\u6570\u636e\u8c31\u7cfb\u8ffd\u8e2a\u786e\u4fdd\u53ef\u8ffd\u6eaf\u6027\u548c\u95ee\u8d23\u5236\uff0c\u4ee5\u53caRegOps\u5de5\u4f5c\u6d41\u7a0b\u5c06\u5408\u89c4\u8981\u6c42\u64cd\u4f5c\u5316\u3002", "result": "\u901a\u8fc7\u5728\u4e0d\u540c\u8bd5\u70b9\u4e2d\u5b9e\u65bd\u548c\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\uff0cCERTAIN\u9879\u76ee\u63a8\u8fdb\u4e86\u76d1\u7ba1\u5408\u89c4\uff0c\u5e76\u4fc3\u8fdb\u4e86\u7b26\u5408\u6b27\u6d32\u6807\u51c6\u7684\u8d1f\u8d23\u4efbAI\u521b\u65b0\u3002", "conclusion": "CERTAIN\u6846\u67b6\u901a\u8fc7\u6574\u5408\u76d1\u7ba1\u5408\u89c4\u3001\u4f26\u7406\u6807\u51c6\u548c\u900f\u660e\u5ea6\uff0c\u4e3a\u5e94\u5bf9AI\u5e26\u6765\u7684\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u76d1\u7ba1\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00329", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00329", "abs": "https://arxiv.org/abs/2510.00329", "authors": ["Sarmad Mehrdad", "Maxime Sabbah", "Vincent Bonnet", "Ludovic Righetti"], "title": "Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning", "comment": "8 pages, 4 figures", "summary": "This paper investigates the application of Minimal Observation Inverse\nReinforcement Learning (MO-IRL) to model and predict human arm-reaching\nmovements with time-varying cost weights. Using a planar two-link biomechanical\nmodel and high-resolution motion-capture data from subjects performing a\npointing task, we segment each trajectory into multiple phases and learn\nphase-specific combinations of seven candidate cost functions. MO-IRL\niteratively refines cost weights by scaling observed and generated trajectories\nin the maximum entropy IRL formulation, greatly reducing the number of required\ndemonstrations and convergence time compared to classical IRL approaches.\nTraining on ten trials per posture yields average joint-angle Root Mean Squared\nErrors (RMSE) of 6.4 deg and 5.6 deg for six- and eight-segment weight\ndivisions, respectively, versus 10.4 deg using a single static weight.\nCross-validation on remaining trials and, for the first time, inter-subject\nvalidation on an unseen subject's 20 trials, demonstrates comparable predictive\naccuracy, around 8 deg RMSE, indicating robust generalization. Learned weights\nemphasize joint acceleration minimization during movement onset and\ntermination, aligning with smoothness principles observed in biological motion.\nThese results suggest that MO-IRL can efficiently uncover dynamic,\nsubject-independent cost structures underlying human motor control, with\npotential applications for humanoid robots.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5e94\u7528\u6700\u5c0f\u89c2\u6d4b\u9006\u5f3a\u5316\u5b66\u4e60\uff08MO-IRL\uff09\u5efa\u6a21\u548c\u9884\u6d4b\u5177\u6709\u65f6\u53d8\u6210\u672c\u6743\u91cd\u7684\u4eba\u7c7b\u624b\u81c2\u4f38\u5c55\u8fd0\u52a8\uff0c\u76f8\u6bd4\u4f20\u7edfIRL\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u6240\u9700\u6f14\u793a\u6570\u636e\u548c\u6536\u655b\u65f6\u95f4\u3002", "motivation": "\u7814\u7a76\u4eba\u7c7b\u8fd0\u52a8\u63a7\u5236\u4e2d\u52a8\u6001\u6210\u672c\u7ed3\u6784\u7684\u5efa\u6a21\uff0c\u4f20\u7edfIRL\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6f14\u793a\u6570\u636e\u4e14\u6536\u655b\u6162\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u63ed\u793a\u751f\u7269\u8fd0\u52a8\u7684\u65f6\u53d8\u6210\u672c\u673a\u5236\u3002", "method": "\u4f7f\u7528\u5e73\u9762\u53cc\u8fde\u6746\u751f\u7269\u529b\u5b66\u6a21\u578b\uff0c\u5c06\u8f68\u8ff9\u5206\u5272\u4e3a\u591a\u4e2a\u9636\u6bb5\uff0c\u5b66\u4e60\u9636\u6bb5\u7279\u5b9a\u7684\u4e03\u79cd\u5019\u9009\u6210\u672c\u51fd\u6570\u7ec4\u5408\uff0c\u901a\u8fc7MO-IRL\u8fed\u4ee3\u4f18\u5316\u6210\u672c\u6743\u91cd\u3002", "result": "\u8bad\u7ec310\u6b21\u8bd5\u9a8c\u540e\uff0c\u516d\u6bb5\u548c\u516b\u6bb5\u6743\u91cd\u5212\u5206\u7684\u5e73\u5747\u5173\u8282\u89d2\u5ea6RMSE\u5206\u522b\u4e3a6.4\u5ea6\u548c5.6\u5ea6\uff0c\u4f18\u4e8e\u9759\u6001\u6743\u91cd\u768410.4\u5ea6\u3002\u8de8\u88ab\u8bd5\u9a8c\u8bc1\u663e\u793a\u7ea68\u5ea6RMSE\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MO-IRL\u80fd\u6709\u6548\u63ed\u793a\u4eba\u7c7b\u8fd0\u52a8\u63a7\u5236\u4e2d\u52a8\u6001\u3001\u88ab\u8bd5\u72ec\u7acb\u7684\u6210\u672c\u7ed3\u6784\uff0c\u5b66\u4e60\u5230\u7684\u6743\u91cd\u5728\u8fd0\u52a8\u8d77\u59cb\u548c\u7ec8\u6b62\u9636\u6bb5\u5f3a\u8c03\u5173\u8282\u52a0\u901f\u5ea6\u6700\u5c0f\u5316\uff0c\u7b26\u5408\u751f\u7269\u8fd0\u52a8\u7684\u5e73\u6ed1\u6027\u539f\u5219\uff0c\u5177\u6709\u5e94\u7528\u4e8e\u4eba\u5f62\u673a\u5668\u4eba\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.00525", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.00525", "abs": "https://arxiv.org/abs/2510.00525", "authors": ["Jared Jonas", "Bassam Bamieh"], "title": "An Interpolation-based Scheme for Rapid Frequency-Domain System Identification", "comment": "7 pages, 5 figures Submitted to IEEE American Control Conference 2026", "summary": "We present a frequency-domain system identification scheme based on\nbarycentric interpolation and weight optimization. The scheme is related to the\nAdaptive Antoulas-Anderson (AAA) algorithm for model reduction, but uses an\nadaptive algorithm for selection of frequency points for interrogating the\nsystem response, as would be required in identification versus model reduction.\nThe scheme is particularly suited for systems in which any one sinusoidal\nresponse run is long or expensive, and thus there is an incentive to reduce the\ntotal number of such runs. Two key features of our algorithm are the use of\ntransient data in sinusoidal runs to both optimize the barycentric weights, and\nautomated next-frequency selection on an adaptive grid. Both are done with\nerror criteria that are proxies for a system's $H^2$ and $H^\\infty$ norms\nrespectively. Furthermore, the optimization problem we formulate is convex, and\ncan optionally guarantee stability of the identified system. Computational\nresults on a high-order, lightly damped structural system highlights the\nefficacy of this scheme.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u91cd\u5fc3\u63d2\u503c\u548c\u6743\u91cd\u4f18\u5316\u7684\u9891\u57df\u7cfb\u7edf\u8fa8\u8bc6\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6b63\u5f26\u54cd\u5e94\u6d4b\u8bd5\u6210\u672c\u9ad8\u7684\u7cfb\u7edf\uff0c\u80fd\u51cf\u5c11\u6d4b\u8bd5\u6b21\u6570", "motivation": "\u9488\u5bf9\u6b63\u5f26\u54cd\u5e94\u6d4b\u8bd5\u65f6\u95f4\u957f\u6216\u6210\u672c\u9ad8\u7684\u7cfb\u7edf\uff0c\u9700\u8981\u51cf\u5c11\u6d4b\u8bd5\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u8bc1\u8fa8\u8bc6\u7cbe\u5ea6\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027", "method": "\u4f7f\u7528\u91cd\u5fc3\u63d2\u503c\u548c\u6743\u91cd\u4f18\u5316\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u9891\u7387\u70b9\u9009\u62e9\u7b97\u6cd5\uff0c\u5229\u7528\u77ac\u6001\u6570\u636e\u4f18\u5316\u6743\u91cd\uff0c\u91c7\u7528\u51f8\u4f18\u5316\u95ee\u9898\u4fdd\u8bc1\u7cfb\u7edf\u7a33\u5b9a\u6027", "result": "\u5728\u9ad8\u9636\u3001\u8f7b\u963b\u5c3c\u7ed3\u6784\u7cfb\u7edf\u4e0a\u7684\u8ba1\u7b97\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6848\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6848\u80fd\u591f\u6709\u6548\u51cf\u5c11\u6b63\u5f26\u54cd\u5e94\u6d4b\u8bd5\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u8bc1\u8fa8\u8bc6\u7cbe\u5ea6\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6d4b\u8bd5\u6210\u672c\u9ad8\u7684\u7cfb\u7edf"}}
{"id": "2510.00080", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00080", "abs": "https://arxiv.org/abs/2510.00080", "authors": ["Hanze Guo", "Yijun Ma", "Xiao Zhou"], "title": "SoREX: Towards Self-Explainable Social Recommendation with Relevant Ego-Path Extraction", "comment": "27 pages, 10 figures", "summary": "Social recommendation has been proven effective in addressing data sparsity\nin user-item interaction modeling by leveraging social networks. The recent\nintegration of Graph Neural Networks (GNNs) has further enhanced prediction\naccuracy in contemporary social recommendation algorithms. However, many\nGNN-based approaches in social recommendation lack the ability to furnish\nmeaningful explanations for their predictions. In this study, we confront this\nchallenge by introducing SoREX, a self-explanatory GNN-based social\nrecommendation framework. SoREX adopts a two-tower framework enhanced by friend\nrecommendation, independently modeling social relations and user-item\ninteractions, while jointly optimizing an auxiliary task to reinforce social\nsignals. To offer explanations, we propose a novel ego-path extraction\napproach. This method involves transforming the ego-net of a target user into a\ncollection of multi-hop ego-paths, from which we extract factor-specific and\ncandidate-aware ego-path subsets as explanations. This process facilitates the\nsummarization of detailed comparative explanations among different candidate\nitems through intricate substructure analysis. Furthermore, we conduct\nexplanation re-aggregation to explicitly correlate explanations with downstream\npredictions, imbuing our framework with inherent self-explainability.\nComprehensive experiments conducted on four widely adopted benchmark datasets\nvalidate the effectiveness of SoREX in predictive accuracy. Additionally,\nqualitative and quantitative analyses confirm the efficacy of the extracted\nexplanations in SoREX. Our code and data are available at\nhttps://github.com/antman9914/SoREX.", "AI": {"tldr": "SoREX\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u89e3\u91ca\u793e\u4ea4\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u5854\u67b6\u6784\u548c\u597d\u53cb\u63a8\u8350\u589e\u5f3a\u793e\u4ea4\u4fe1\u53f7\uff0c\u63d0\u4f9b\u57fa\u4e8e\u81ea\u6211\u8def\u5f84\u63d0\u53d6\u7684\u89e3\u91ca\u673a\u5236\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u4e8eGNN\u7684\u793e\u4ea4\u63a8\u8350\u65b9\u6cd5\u7f3a\u4e4f\u6709\u610f\u4e49\u7684\u9884\u6d4b\u89e3\u91ca\u80fd\u529b\u7684\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u4e24\u5854\u6846\u67b6\u72ec\u7acb\u5efa\u6a21\u793e\u4ea4\u5173\u7cfb\u548c\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\uff0c\u901a\u8fc7\u8f85\u52a9\u4efb\u52a1\u5f3a\u5316\u793e\u4ea4\u4fe1\u53f7\uff1b\u63d0\u51fa\u81ea\u6211\u8def\u5f84\u63d0\u53d6\u65b9\u6cd5\uff0c\u5c06\u76ee\u6807\u7528\u6237\u7684\u81ea\u6211\u7f51\u7edc\u8f6c\u5316\u4e3a\u591a\u8df3\u81ea\u6211\u8def\u5f84\u96c6\u5408\uff0c\u63d0\u53d6\u56e0\u5b50\u7279\u5b9a\u548c\u5019\u9009\u7269\u54c1\u611f\u77e5\u7684\u81ea\u6211\u8def\u5f84\u5b50\u96c6\u4f5c\u4e3a\u89e3\u91ca\u3002", "result": "\u5728\u56db\u4e2a\u5e7f\u6cdb\u91c7\u7528\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u4e86SoREX\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\uff1b\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u786e\u8ba4\u4e86\u63d0\u53d6\u89e3\u91ca\u7684\u6709\u6548\u6027\u3002", "conclusion": "SoREX\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u63a8\u8350\u51c6\u786e\u6027\uff0c\u8fd8\u901a\u8fc7\u521b\u65b0\u7684\u81ea\u6211\u8def\u5f84\u63d0\u53d6\u548c\u89e3\u91ca\u91cd\u805a\u5408\u673a\u5236\u5b9e\u73b0\u4e86\u5185\u5728\u7684\u81ea\u89e3\u91ca\u80fd\u529b\uff0c\u4e3a\u793e\u4ea4\u63a8\u8350\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u89e3\u91ca\u3002"}}
{"id": "2510.00088", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.00088", "abs": "https://arxiv.org/abs/2510.00088", "authors": ["Sagnik Basu", "Shubham Prakash", "Ashish Maruti Barge", "Siddharth D Jaiswal", "Abhisek Dash", "Saptarshi Ghosh", "Animesh Mukherjee"], "title": "Judging by Appearances? Auditing and Intervening Vision-Language Models for Bail Prediction", "comment": null, "summary": "Large language models (LLMs) have been extensively used for legal judgment\nprediction tasks based on case reports and crime history. However, with a surge\nin the availability of large vision language models (VLMs), legal judgment\nprediction systems can now be made to leverage the images of the criminals in\naddition to the textual case reports/crime history. Applications built in this\nway could lead to inadvertent consequences and be used with malicious intent.\nIn this work, we run an audit to investigate the efficiency of standalone VLMs\nin the bail decision prediction task. We observe that the performance is poor\nacross multiple intersectional groups and models \\textit{wrongly deny bail to\ndeserving individuals with very high confidence}. We design different\nintervention algorithms by first including legal precedents through a RAG\npipeline and then fine-tuning the VLMs using innovative schemes. We demonstrate\nthat these interventions substantially improve the performance of bail\nprediction. Our work paves the way for the design of smarter interventions on\nVLMs in the future, before they can be deployed for real-world legal judgment\nprediction.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5ba1\u8ba1\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4fdd\u91ca\u51b3\u7b56\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u504f\u89c1\uff0c\u4f1a\u9ad8\u7f6e\u4fe1\u5ea6\u9519\u8bef\u62d2\u7edd\u5e94\u83b7\u4fdd\u91ca\u8005\u3002\u901a\u8fc7RAG\u7ba1\u9053\u5f15\u5165\u6cd5\u5f8b\u5148\u4f8b\u548c\u5fae\u8c03\u5e72\u9884\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u7cfb\u7edf\u5f00\u59cb\u5229\u7528\u7f6a\u72af\u56fe\u50cf\u548c\u6587\u672c\u62a5\u544a\uff0c\u4f46\u8fd9\u79cd\u65b9\u5f0f\u53ef\u80fd\u5e26\u6765\u610f\u5916\u540e\u679c\u548c\u6076\u610f\u4f7f\u7528\u3002\u9700\u8981\u8bc4\u4f30VLMs\u5728\u4fdd\u91ca\u51b3\u7b56\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u9996\u5148\u5ba1\u8ba1\u72ec\u7acbVLMs\u5728\u4fdd\u91ca\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7136\u540e\u8bbe\u8ba1\u5e72\u9884\u7b97\u6cd5\uff1a\u901a\u8fc7RAG\u7ba1\u9053\u5f15\u5165\u6cd5\u5f8b\u5148\u4f8b\uff0c\u5e76\u4f7f\u7528\u521b\u65b0\u65b9\u6848\u5bf9VLMs\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u72ec\u7acbVLMs\u5728\u591a\u4e2a\u4ea4\u53c9\u7fa4\u4f53\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4f1a\u9ad8\u7f6e\u4fe1\u5ea6\u9519\u8bef\u62d2\u7edd\u5e94\u83b7\u4fdd\u91ca\u8005\u3002\u5e72\u9884\u63aa\u65bd\u663e\u8457\u63d0\u9ad8\u4e86\u4fdd\u91ca\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672a\u6765\u5728VLMs\u90e8\u7f72\u5230\u771f\u5b9e\u4e16\u754c\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u4e4b\u524d\u8bbe\u8ba1\u66f4\u667a\u80fd\u7684\u5e72\u9884\u63aa\u65bd\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.00358", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00358", "abs": "https://arxiv.org/abs/2510.00358", "authors": ["Linjin He", "Xinda Qi", "Dong Chen", "Zhaojian Li", "Xiaobo Tan"], "title": "DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts", "comment": null, "summary": "Soft snake robots offer remarkable flexibility and adaptability in complex\nenvironments, yet their control remains challenging due to highly nonlinear\ndynamics. Existing model-based and bio-inspired controllers rely on simplified\nassumptions that limit performance. Deep reinforcement learning (DRL) has\nrecently emerged as a promising alternative, but online training is often\nimpractical because of costly and potentially damaging real-world interactions.\nOffline RL provides a safer option by leveraging pre-collected datasets, but it\nsuffers from distribution shift, which degrades generalization to unseen\nscenarios. To overcome this challenge, we propose DiSA-IQL\n(Distribution-Shift-Aware Implicit Q-Learning), an extension of IQL that\nincorporates robustness modulation by penalizing unreliable state-action pairs\nto mitigate distribution shift. We evaluate DiSA-IQL on goal-reaching tasks\nacross two settings: in-distribution and out-of-distribution evaluation.\nSimulation results show that DiSA-IQL consistently outperforms baseline models,\nincluding Behavior Cloning (BC), Conservative Q-Learning (CQL), and vanilla\nIQL, achieving higher success rates, smoother trajectories, and improved\nrobustness. The codes are open-sourced to support reproducibility and to\nfacilitate further research in offline RL for soft robot control.", "AI": {"tldr": "\u63d0\u51faDiSA-IQL\u65b9\u6cd5\uff0c\u901a\u8fc7\u60e9\u7f5a\u4e0d\u53ef\u9760\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u6765\u7f13\u89e3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5728\u8f6f\u4f53\u86c7\u5f62\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u8f6f\u4f53\u86c7\u5f62\u673a\u5668\u4eba\u63a7\u5236\u9762\u4e34\u9ad8\u5ea6\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7b80\u5316\u5047\u8bbe\u9650\u5236\u4e86\u6027\u80fd\u3002\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6210\u672c\u9ad8\u4e14\u5371\u9669\uff0c\u79bb\u7ebfRL\u5b58\u5728\u5206\u5e03\u504f\u79fb\u95ee\u9898\u5f71\u54cd\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faDiSA-IQL\uff08\u5206\u5e03\u504f\u79fb\u611f\u77e5\u9690\u5f0fQ\u5b66\u4e60\uff09\uff0c\u5728IQL\u57fa\u7840\u4e0a\u901a\u8fc7\u9c81\u68d2\u6027\u8c03\u5236\u60e9\u7f5a\u4e0d\u53ef\u9760\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u6765\u7f13\u89e3\u5206\u5e03\u504f\u79fb\u3002", "result": "\u5728\u76ee\u6807\u5230\u8fbe\u4efb\u52a1\u7684\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u8bc4\u4f30\u4e2d\uff0cDiSA-IQL\u59cb\u7ec8\u4f18\u4e8eBC\u3001CQL\u548c\u539f\u59cbIQL\u57fa\u7ebf\uff0c\u83b7\u5f97\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3001\u66f4\u5e73\u6ed1\u7684\u8f68\u8ff9\u548c\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "DiSA-IQL\u6709\u6548\u89e3\u51b3\u4e86\u79bb\u7ebfRL\u5728\u8f6f\u4f53\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u4ee5\u652f\u6301\u53ef\u590d\u73b0\u6027\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.00560", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00560", "abs": "https://arxiv.org/abs/2510.00560", "authors": ["A. Calderon Hurtado", "J. Xu", "R. Salleh", "D. Dias-da-Costa", "M. Makki Alamdari"], "title": "Development and Field Validation of a Fully Customised Vehicle Scanning System on Two Full-Scale Bridges", "comment": null, "summary": "Ensuring the structural integrity of bridges is essential for maintaining\ninfrastructure safety and promoting long-term sustainability. In this context,\nIndirect Structural Health Monitoring (ISHM) through drive-by bridge inspection\nemerges as a promising alternative to traditional inspection methods, offering\na cost-effective and scalable solution by using vehicle-mounted sensors to\nassess the condition of bridges without requiring direct instrumentation. This\nstudy introduces the first purpose-built electric inspection vehicle\nspecifically designed for drive-by bridge inspection. The autonomous platform\nis capable of maintaining a constant low speed and offers customisable\noperational parameters to maximise the accuracy and repeatability of indirect\nsensing, capabilities not achieved in previous studies. The vehicle is deployed\nwithin an ISHM framework and tested on two full-scale bridges to evaluate its\neffectiveness in capturing structural dynamic responses. Two unsupervised\nframeworks are then employed to analyse the collected data to identify features\nindicative of bridge properties and structural condition. The promising\nfindings from this study demonstrate the practical feasibility of the approach.\nThe study also shows the potential of ISHM as a viable tool for efficient\nbridge monitoring, contributing to the development of next-generation\nstructural health monitoring systems that can enhance safety, optimise\nmaintenance strategies, and support the longevity of critical infrastructure.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9996\u4e2a\u4e13\u95e8\u4e3adrive-by\u6865\u6881\u68c0\u6d4b\u8bbe\u8ba1\u7684\u7535\u52a8\u68c0\u67e5\u8f66\u8f86\uff0c\u8be5\u81ea\u4e3b\u5e73\u53f0\u80fd\u591f\u4fdd\u6301\u6052\u5b9a\u4f4e\u901f\u5e76\u63d0\u4f9b\u53ef\u5b9a\u5236\u64cd\u4f5c\u53c2\u6570\uff0c\u901a\u8fc7\u95f4\u63a5\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u6846\u67b6\u5728\u771f\u5b9e\u6865\u6881\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002", "motivation": "\u786e\u4fdd\u6865\u6881\u7ed3\u6784\u5b8c\u6574\u6027\u5bf9\u57fa\u7840\u8bbe\u65bd\u5b89\u5168\u548c\u957f\u671f\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\u3002\u95f4\u63a5\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u901a\u8fc7drive-by\u6865\u6881\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u5177\u6210\u672c\u6548\u76ca\u548c\u53ef\u6269\u5c55\u6027\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e13\u95e8\u8bbe\u8ba1\u7684\u7535\u52a8\u68c0\u67e5\u8f66\u8f86\uff0c\u8be5\u81ea\u4e3b\u5e73\u53f0\u80fd\u4fdd\u6301\u6052\u5b9a\u4f4e\u901f\u548c\u53ef\u5b9a\u5236\u64cd\u4f5c\u53c2\u6570\uff0c\u90e8\u7f72\u5728ISHM\u6846\u67b6\u4e2d\u5e76\u5728\u4e24\u4e2a\u5168\u5c3a\u5bf8\u6865\u6881\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u4f7f\u7528\u4e24\u4e2a\u65e0\u76d1\u7763\u6846\u67b6\u5206\u6790\u6536\u96c6\u7684\u6570\u636e\u4ee5\u8bc6\u522b\u6865\u6881\u7279\u6027\u548c\u7ed3\u6784\u72b6\u51b5\u7684\u7279\u5f81\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0cISHM\u6709\u6f5c\u529b\u6210\u4e3a\u9ad8\u6548\u6865\u6881\u76d1\u6d4b\u7684\u53ef\u884c\u5de5\u5177\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86ISHM\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u7cfb\u7edf\u5f00\u53d1\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u589e\u5f3a\u5b89\u5168\u6027\u3001\u4f18\u5316\u7ef4\u62a4\u7b56\u7565\u5e76\u652f\u6301\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u957f\u671f\u4f7f\u7528\u3002"}}
{"id": "2510.00469", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.00469", "abs": "https://arxiv.org/abs/2510.00469", "authors": ["Omid Armantalab", "Jason Hawkins", "Wissam Kontar"], "title": "Mobility Behavior Evolution During Extended Emergencies: Returners, Explorers, and the 15-Minute City", "comment": null, "summary": "Understanding human mobility during emergencies is critical for strengthening\nurban resilience and guiding emergency management. This study examines\ntransitions between returners, who repeatedly visit a limited set of locations,\nand explorers, who travel across broader destinations, over a 15-day emergency\nperiod in a densely populated metropolitan region using the YJMob100K dataset.\nHigh-resolution spatial data reveal intra-urban behavioral dynamics often\nmasked at coarser scales. Beyond static comparisons, we analyze how mobility\nevolves over time, with varying emergency durations, across weekdays and\nweekends, and relative to neighborhood boundaries, linking the analysis to the\n15-minute city framework.\n  Results show that at least two weeks of data are required to detect\nmeaningful behavioral shifts. During prolonged emergencies, individuals resume\nvisits to non-essential locations more slowly than under normal conditions.\nExplorers markedly reduce long distance travel, while weekends and holidays\nconsistently exhibit returner-like, short distance patterns. Residents of low\nPoints of Interest (POI) density neighborhoods often travel to POI rich areas,\nhighlighting spatial disparities. Strengthening local accessibility may improve\nurban resilience during crises.\n  Full reproducibility is supported through the project website:\nhttps://github.com/wissamkontar", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528YJMob100K\u6570\u636e\u96c6\u5206\u6790\u7d27\u6025\u60c5\u51b5\u4e0b\u4eba\u7c7b\u79fb\u52a8\u884c\u4e3a\uff0c\u91cd\u70b9\u5173\u6ce8\u8fd4\u56de\u8005\u548c\u63a2\u7d22\u8005\u4e4b\u95f4\u7684\u8f6c\u6362\u6a21\u5f0f\uff0c\u53d1\u73b0\u81f3\u5c11\u9700\u8981\u4e24\u5468\u6570\u636e\u624d\u80fd\u68c0\u6d4b\u5230\u6709\u610f\u4e49\u7684\u884c\u4e3a\u53d8\u5316\uff0c\u5e76\u63ed\u793a\u4e86\u7a7a\u95f4\u53ef\u8fbe\u6027\u5bf9\u57ce\u5e02\u97e7\u6027\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7406\u89e3\u7d27\u6025\u60c5\u51b5\u4e0b\u7684\u4eba\u7c7b\u79fb\u52a8\u884c\u4e3a\u5bf9\u4e8e\u589e\u5f3a\u57ce\u5e02\u97e7\u6027\u548c\u6307\u5bfc\u5e94\u6025\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u63ed\u793a\u5728\u7cbe\u7ec6\u7a7a\u95f4\u5c3a\u5ea6\u4e0b\u88ab\u63a9\u76d6\u7684\u884c\u4e3a\u52a8\u6001\u3002", "method": "\u4f7f\u7528YJMob100K\u6570\u636e\u96c6\uff0c\u5206\u679015\u5929\u7d27\u6025\u671f\u95f4\u5728\u4eba\u53e3\u5bc6\u96c6\u5927\u90fd\u5e02\u533a\u57df\u7684\u79fb\u52a8\u884c\u4e3a\uff0c\u91cd\u70b9\u5173\u6ce8\u8fd4\u56de\u8005\uff08\u91cd\u590d\u8bbf\u95ee\u6709\u9650\u5730\u70b9\uff09\u548c\u63a2\u7d22\u8005\uff08\u8de8\u66f4\u5e7f\u76ee\u7684\u5730\u65c5\u884c\uff09\u4e4b\u95f4\u7684\u8f6c\u6362\uff0c\u7ed3\u540815\u5206\u949f\u57ce\u5e02\u6846\u67b6\u5206\u6790\u65f6\u7a7a\u52a8\u6001\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u81f3\u5c11\u9700\u8981\u4e24\u5468\u6570\u636e\u624d\u80fd\u68c0\u6d4b\u5230\u6709\u610f\u4e49\u7684\u884c\u4e3a\u53d8\u5316\uff1b\u957f\u671f\u7d27\u6025\u60c5\u51b5\u4e0b\uff0c\u4e2a\u4f53\u6062\u590d\u8bbf\u95ee\u975e\u5fc5\u8981\u5730\u70b9\u7684\u901f\u5ea6\u8f83\u6162\uff1b\u63a2\u7d22\u8005\u663e\u8457\u51cf\u5c11\u957f\u8ddd\u79bb\u65c5\u884c\uff1b\u5468\u672b\u548c\u8282\u5047\u65e5\u5448\u73b0\u8fd4\u56de\u8005\u5f0f\u7684\u77ed\u8ddd\u79bb\u6a21\u5f0f\uff1b\u4f4ePOI\u5bc6\u5ea6\u793e\u533a\u5c45\u6c11\u5e38\u524d\u5f80POI\u4e30\u5bcc\u533a\u57df\u3002", "conclusion": "\u52a0\u5f3a\u672c\u5730\u53ef\u8fbe\u6027\u53ef\u80fd\u63d0\u9ad8\u5371\u673a\u671f\u95f4\u7684\u57ce\u5e02\u97e7\u6027\uff0c\u7a7a\u95f4\u5dee\u5f02\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u8868\u73b0\u660e\u663e\uff0c\u7cbe\u7ec6\u7a7a\u95f4\u6570\u636e\u5bf9\u4e8e\u7406\u89e3\u57ce\u5e02\u79fb\u52a8\u884c\u4e3a\u52a8\u6001\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.00156", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00156", "abs": "https://arxiv.org/abs/2510.00156", "authors": ["Songran Bai", "Bingzhe Wu", "Yiwei Zhang", "Chengke Wu", "Xiaolong Zheng", "Yaze Yuan", "Ke Wu", "Jianqiang Li"], "title": "AuditAgent: Expert-Guided Multi-Agent Reasoning for Cross-Document Fraudulent Evidence Discovery", "comment": null, "summary": "Financial fraud detection in real-world scenarios presents significant\nchallenges due to the subtlety and dispersion of evidence across complex,\nmulti-year financial disclosures. In this work, we introduce a novel\nmulti-agent reasoning framework AuditAgent, enhanced with auditing domain\nexpertise, for fine-grained evidence chain localization in financial fraud\ncases. Leveraging an expert-annotated dataset constructed from enforcement\ndocuments and financial reports released by the China Securities Regulatory\nCommission, our approach integrates subject-level risk priors, a hybrid\nretrieval strategy, and specialized agent modules to efficiently identify and\naggregate cross-report evidence. Extensive experiments demonstrate that our\nmethod substantially outperforms General-Purpose Agent paradigm in both recall\nand interpretability, establishing a new benchmark for automated, transparent\nfinancial forensics. Our results highlight the value of domain-specific\nreasoning and dataset construction for advancing robust financial fraud\ndetection in practical, real-world regulatory applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAuditAgent\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u91d1\u878d\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\u7684\u7ec6\u7c92\u5ea6\u8bc1\u636e\u94fe\u5b9a\u4f4d\uff0c\u5728\u53ec\u56de\u7387\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u901a\u7528\u667a\u80fd\u4f53\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u91d1\u878d\u6b3a\u8bc8\u68c0\u6d4b\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u56e0\u4e3a\u8bc1\u636e\u5728\u590d\u6742\u3001\u591a\u5e74\u7684\u8d22\u52a1\u62ab\u9732\u4e2d\u5177\u6709\u5fae\u5999\u6027\u548c\u5206\u6563\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6AuditAgent\uff0c\u6574\u5408\u4e86\u5ba1\u8ba1\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3001\u4e3b\u4f53\u7ea7\u98ce\u9669\u5148\u9a8c\u3001\u6df7\u5408\u68c0\u7d22\u7b56\u7565\u548c\u4e13\u7528\u667a\u80fd\u4f53\u6a21\u5757\uff0c\u7528\u4e8e\u8bc6\u522b\u548c\u805a\u5408\u8de8\u62a5\u544a\u8bc1\u636e\u3002", "result": "\u5728\u4ece\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u53d1\u5e03\u7684\u6267\u6cd5\u6587\u4ef6\u548c\u8d22\u52a1\u62a5\u544a\u6784\u5efa\u7684\u4e13\u5bb6\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u901a\u7528\u667a\u80fd\u4f53\u8303\u5f0f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9886\u57df\u7279\u5b9a\u63a8\u7406\u548c\u6570\u636e\u96c6\u6784\u5efa\u5728\u63a8\u8fdb\u5b9e\u9645\u76d1\u7ba1\u5e94\u7528\u4e2d\u7a33\u5065\u91d1\u878d\u6b3a\u8bc8\u68c0\u6d4b\u7684\u4ef7\u503c\u3002"}}
{"id": "2510.00401", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00401", "abs": "https://arxiv.org/abs/2510.00401", "authors": ["Shounak Sural", "Charles Kekeh", "Wenliang Liu", "Federico Pecora", "Mouhacine Benosman"], "title": "Physics-Informed Neural Controlled Differential Equations for Scalable Long Horizon Multi-Agent Motion Forecasting", "comment": null, "summary": "Long-horizon motion forecasting for multiple autonomous robots is challenging\ndue to non-linear agent interactions, compounding prediction errors, and\ncontinuous-time evolution of dynamics. Learned dynamics of such a system can be\nuseful in various applications such as travel time prediction,\nprediction-guided planning and generative simulation. In this work, we aim to\ndevelop an efficient trajectory forecasting model conditioned on multi-agent\ngoals. Motivated by the recent success of physics-guided deep learning for\npartially known dynamical systems, we develop a model based on neural\nControlled Differential Equations (CDEs) for long-horizon motion forecasting.\nUnlike discrete-time methods such as RNNs and transformers, neural CDEs operate\nin continuous time, allowing us to combine physics-informed constraints and\nbiases to jointly model multi-robot dynamics. Our approach, named PINCoDE\n(Physics-Informed Neural Controlled Differential Equations), learns\ndifferential equation parameters that can be used to predict the trajectories\nof a multi-agent system starting from an initial condition. PINCoDE is\nconditioned on future goals and enforces physics constraints for robot motion\nover extended periods of time. We adopt a strategy that scales our model from\n10 robots to 100 robots without the need for additional model parameters, while\nproducing predictions with an average ADE below 0.5 m for a 1-minute horizon.\nFurthermore, progressive training with curriculum learning for our PINCoDE\nmodel results in a 2.7X reduction of forecasted pose error over 4 minute\nhorizons compared to analytical models.", "AI": {"tldr": "\u63d0\u51faPINCoDE\u6a21\u578b\uff0c\u57fa\u4e8e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u8fdb\u884c\u591a\u673a\u5668\u4eba\u957f\u65f6\u7a0b\u8fd0\u52a8\u9884\u6d4b\uff0c\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u652f\u6301\u4ece10\u5230100\u4e2a\u673a\u5668\u4eba\u7684\u6269\u5c55\u9884\u6d4b\u3002", "motivation": "\u591a\u81ea\u4e3b\u673a\u5668\u4eba\u957f\u65f6\u7a0b\u8fd0\u52a8\u9884\u6d4b\u9762\u4e34\u975e\u7ebf\u6027\u4ea4\u4e92\u3001\u9884\u6d4b\u8bef\u5dee\u7d2f\u79ef\u548c\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\u6f14\u5316\u7b49\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u76ee\u6807\u6761\u4ef6\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\uff08CDEs\uff09\u6784\u5efaPINCoDE\u6a21\u578b\uff0c\u5728\u8fde\u7eed\u65f6\u95f4\u4e2d\u7ed3\u5408\u7269\u7406\u7ea6\u675f\uff0c\u5b66\u4e60\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u5fae\u5206\u65b9\u7a0b\u53c2\u6570\uff0c\u652f\u6301\u76ee\u6807\u6761\u4ef6\u9884\u6d4b\u3002", "result": "\u6a21\u578b\u53ef\u6269\u5c55\u5230100\u4e2a\u673a\u5668\u4eba\u800c\u65e0\u9700\u989d\u5916\u53c2\u6570\uff0c1\u5206\u949f\u9884\u6d4b\u7684\u5e73\u5747ADE\u4f4e\u4e8e0.5\u7c73\uff0c4\u5206\u949f\u9884\u6d4b\u7684\u4f4d\u59ff\u8bef\u5dee\u6bd4\u89e3\u6790\u6a21\u578b\u51cf\u5c112.7\u500d\u3002", "conclusion": "PINCoDE\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u673a\u5668\u4eba\u957f\u65f6\u7a0b\u8fd0\u52a8\u9884\u6d4b\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2510.00676", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00676", "abs": "https://arxiv.org/abs/2510.00676", "authors": ["Zamir Martinez", "Daniel Zelazo"], "title": "Formation Control via Rotation Symmetry Constraints", "comment": null, "summary": "We present a distributed formation control strategy for multi-agent systems\nbased only on rotation symmetry constraints. We propose a potential function\nthat enforces inter-agent \\textbf{rotational} symmetries, with its gradient\ndefining the control law driving the agents toward a desired symmetric and\nplanar configuration. We show that only $(n-1)$ edges, the minimal connectivity\nrequirement, are sufficient to implement the control strategy, where $n$ is the\nnumber of agents. We further augment the design to address the\n\\textbf{maneuvering problem}, enabling the formation to undergo coordinated\ntranslations, rotations, and scalings along a predefined virtual trajectory.\nNumerical simulations demonstrate the effectiveness and flexibility of the\nproposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65cb\u8f6c\u5bf9\u79f0\u7ea6\u675f\u7684\u591a\u667a\u80fd\u4f53\u5206\u5e03\u5f0f\u7f16\u961f\u63a7\u5236\u7b56\u7565\uff0c\u4f7f\u7528\u52bf\u51fd\u6570\u5b9e\u73b0\u667a\u80fd\u4f53\u95f4\u7684\u65cb\u8f6c\u5bf9\u79f0\u6027\uff0c\u4ec5\u9700(n-1)\u6761\u8fb9\u7684\u6700\u5c0f\u8fde\u901a\u6027\u8981\u6c42\uff0c\u5e76\u80fd\u5b9e\u73b0\u7f16\u961f\u7684\u5e73\u79fb\u3001\u65cb\u8f6c\u548c\u7f29\u653e\u673a\u52a8\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u4ec5\u4f9d\u8d56\u65cb\u8f6c\u5bf9\u79f0\u7ea6\u675f\u7684\u5206\u5e03\u5f0f\u7f16\u961f\u63a7\u5236\u65b9\u6cd5\uff0c\u964d\u4f4e\u901a\u4fe1\u548c\u8fde\u63a5\u8981\u6c42\uff0c\u540c\u65f6\u589e\u5f3a\u7f16\u961f\u7684\u7075\u6d3b\u6027\u548c\u673a\u52a8\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u52bf\u51fd\u6570\u6765\u5f3a\u5236\u6267\u884c\u667a\u80fd\u4f53\u95f4\u7684\u65cb\u8f6c\u5bf9\u79f0\u6027\uff0c\u5176\u68af\u5ea6\u5b9a\u4e49\u4e86\u63a7\u5236\u5f8b\uff0c\u9a71\u52a8\u667a\u80fd\u4f53\u8fbe\u5230\u671f\u671b\u7684\u5bf9\u79f0\u5e73\u9762\u914d\u7f6e\u3002\u901a\u8fc7\u589e\u5f3a\u8bbe\u8ba1\u6765\u89e3\u51b3\u673a\u52a8\u95ee\u9898\uff0c\u4f7f\u7f16\u961f\u80fd\u591f\u6cbf\u9884\u5b9a\u865a\u62df\u8f68\u8ff9\u8fdb\u884c\u534f\u8c03\u7684\u5e73\u79fb\u3001\u65cb\u8f6c\u548c\u7f29\u653e\u3002", "result": "\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\uff0c\u8bc1\u660e\u4ec5\u9700\u6700\u5c0f\u8fde\u901a\u6027(n-1\u6761\u8fb9)\u5373\u53ef\u5b9e\u73b0\u63a7\u5236\u7b56\u7565\u3002", "conclusion": "\u8be5\u57fa\u4e8e\u65cb\u8f6c\u5bf9\u79f0\u7ea6\u675f\u7684\u5206\u5e03\u5f0f\u7f16\u961f\u63a7\u5236\u7b56\u7565\u5177\u6709\u6700\u5c0f\u8fde\u901a\u6027\u8981\u6c42\uff0c\u80fd\u591f\u5b9e\u73b0\u7075\u6d3b\u7684\u7f16\u961f\u673a\u52a8\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u63a7\u5236\u65b9\u6848\u3002"}}
{"id": "2510.00650", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.00650", "abs": "https://arxiv.org/abs/2510.00650", "authors": ["Zahra Arjmandi-Lari", "Alexios Mantzarlis", "Tom Stafford"], "title": "Threats to the sustainability of Community Notes on X", "comment": "6 pages, 7 figures, submitted to ICWSM2025", "summary": "Community Notes are emerging as an important option for content moderation.\nThe Community Notes system pioneered by Twitter, now known as X, uses a\nbridging algorithm to identify user-generated context with upvotes across\npolitical divides, supposedly spinning consensual gold from partisan straw. It\nis important to understand the nature of the community behind Community Notes,\nespecially as the feature has now been imitated by several billion-user\nplatforms. We look for signs of stability and disruption in the X Community\nNotes community and interrogate the motivations other than partisan animus\n(Allen, Martel, and Rand 2022) which may be driving users to contribute. We\nconduct a novel analysis of the impact of having a note published, which\nrequires being considered \"helpful\" by the bridging algorithm, utilising a\nregression discontinuity design. This allows stronger causal inference than\nconventional methods used with observational data. Our analysis shows the\npositive effect on future note authoring of having a note published. This\nhighlights the risk of the current system, where the proportion of notes\nconsidered \"helpful\" (and therefore shown to users on X) is low, 10%, and\ndeclining. This analysis has implications for the future of Community Notes on\nX and the extension of this approach to other platforms.", "AI": {"tldr": "\u5206\u6790\u4e86X\u5e73\u53f0\u793e\u533a\u7b14\u8bb0\u7cfb\u7edf\u7684\u6548\u679c\uff0c\u53d1\u73b0\u53d1\u5e03\u7b14\u8bb0\u5bf9\u4f5c\u8005\u672a\u6765\u521b\u4f5c\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u4f46\u5f53\u524d\u7cfb\u7edf\u53ea\u670910%\u7684\u7b14\u8bb0\u88ab\u8ba4\u5b9a\u4e3a\"\u6709\u5e2e\u52a9\"\u4e14\u6bd4\u4f8b\u5728\u4e0b\u964d\uff0c\u5b58\u5728\u98ce\u9669\u3002", "motivation": "\u7406\u89e3\u793e\u533a\u7b14\u8bb0\u7cfb\u7edf\u80cc\u540e\u7684\u7528\u6237\u52a8\u673a\uff0c\u7279\u522b\u662f\u9664\u4e86\u515a\u6d3e\u5bf9\u7acb\u4e4b\u5916\u7684\u5176\u4ed6\u9a71\u52a8\u56e0\u7d20\uff0c\u4ee5\u53ca\u8bc4\u4f30\u8be5\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u6f5c\u5728\u7834\u574f\u6027\u3002", "method": "\u4f7f\u7528\u56de\u5f52\u65ad\u70b9\u8bbe\u8ba1\u5206\u6790\u7b14\u8bb0\u53d1\u5e03\u7684\u5f71\u54cd\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6bd4\u4f20\u7edf\u7684\u89c2\u5bdf\u6570\u636e\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u5f3a\u7684\u56e0\u679c\u63a8\u65ad\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53d1\u5e03\u7b14\u8bb0\u5bf9\u4f5c\u8005\u672a\u6765\u7684\u7b14\u8bb0\u521b\u4f5c\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u4f46\u5f53\u524d\u7cfb\u7edf\u53ea\u670910%\u7684\u7b14\u8bb0\u88ab\u8ba4\u5b9a\u4e3a\"\u6709\u5e2e\u52a9\"\uff0c\u4e14\u8fd9\u4e00\u6bd4\u4f8b\u5728\u4e0b\u964d\u3002", "conclusion": "\u5f53\u524d\u793e\u533a\u7b14\u8bb0\u7cfb\u7edf\u5b58\u5728\u98ce\u9669\uff0c\u8fd9\u5bf9X\u5e73\u53f0\u793e\u533a\u7b14\u8bb0\u7684\u672a\u6765\u53d1\u5c55\u4ee5\u53ca\u8be5\u65b9\u6cd5\u5728\u5176\u4ed6\u5e73\u53f0\u7684\u6269\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.00793", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.00793", "abs": "https://arxiv.org/abs/2510.00793", "authors": ["J. A. Hageman", "C. F. W. Peeters"], "title": "AI in data science education: experiences from the classroom", "comment": "6 pages, 0 figures", "summary": "This study explores the integration of AI, particularly large language models\n(LLMs) like ChatGPT, into educational settings, focusing on the implications\nfor teaching and learning. Through interviews with course coordinators from\ndata science courses at Wageningen University, this research identifies both\nthe benefits and challenges associated with AI in the classroom. While AI tools\ncan streamline tasks and enhance learning, concerns arise regarding students'\noverreliance on these technologies, potentially hindering the development of\nessential cognitive and problem solving skills. The study highlights the\nimportance of responsible AI usage, ethical considerations, and the need for\nadapting assessment methods to ensure educational outcomes are met. With\ncareful integration, AI can be a valuable asset in education, provided it is\nused to complement rather than replace fundamental learning processes.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86AI\uff08\u7279\u522b\u662f\u50cfChatGPT\u8fd9\u6837\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5728\u6559\u80b2\u73af\u5883\u4e2d\u7684\u6574\u5408\uff0c\u91cd\u70b9\u5173\u6ce8\u5bf9\u6559\u4e0e\u5b66\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0AI\u5de5\u5177\u65e2\u80fd\u7b80\u5316\u4efb\u52a1\u3001\u589e\u5f3a\u5b66\u4e60\uff0c\u4e5f\u5b58\u5728\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56\u6280\u672f\u800c\u963b\u788d\u57fa\u672c\u8ba4\u77e5\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u53d1\u5c55\u7684\u98ce\u9669\u3002", "motivation": "\u63a2\u7d22AI\u5728\u6559\u80b2\u73af\u5883\u4e2d\u7684\u6574\u5408\uff0c\u4e86\u89e3\u5176\u5bf9\u6559\u5b66\u548c\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u8bc6\u522bAI\u5e26\u6765\u7684\u76ca\u5904\u548c\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5bf9\u74e6\u8d6b\u5b81\u6839\u5927\u5b66\u6570\u636e\u79d1\u5b66\u8bfe\u7a0b\u7684\u8bfe\u7a0b\u534f\u8c03\u5458\u8fdb\u884c\u8bbf\u8c08\u3002", "result": "\u7814\u7a76\u53d1\u73b0AI\u5de5\u5177\u53ef\u4ee5\u7b80\u5316\u4efb\u52a1\u5e76\u589e\u5f3a\u5b66\u4e60\uff0c\u4f46\u4e5f\u5b58\u5728\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56\u8fd9\u4e9b\u6280\u672f\u7684\u95ee\u9898\uff0c\u53ef\u80fd\u963b\u788d\u57fa\u672c\u8ba4\u77e5\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u53d1\u5c55\u3002", "conclusion": "AI\u53ef\u4ee5\u6210\u4e3a\u6559\u80b2\u4e2d\u7684\u5b9d\u8d35\u8d44\u4ea7\uff0c\u4f46\u9700\u8981\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528\uff0c\u8003\u8651\u4f26\u7406\u95ee\u9898\uff0c\u5e76\u8c03\u6574\u8bc4\u4f30\u65b9\u6cd5\uff0c\u786e\u4fdd\u6559\u80b2\u6210\u679c\u7684\u5b9e\u73b0\uff0c\u4f7fAI\u8865\u5145\u800c\u975e\u53d6\u4ee3\u57fa\u672c\u5b66\u4e60\u8fc7\u7a0b\u3002"}}
{"id": "2510.00167", "categories": ["cs.AI", "cs.CR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00167", "abs": "https://arxiv.org/abs/2510.00167", "authors": ["Diego Ortiz Barbosa", "Mohit Agrawal", "Yash Malegaonkar", "Luis Burbano", "Axel Andersson", "Gy\u00f6rgy D\u00e1n", "Henrik Sandberg", "Alvaro A. Cardenas"], "title": "Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI", "comment": null, "summary": "Autonomous drones must often respond to sudden events, such as alarms,\nfaults, or unexpected changes in their environment, that require immediate and\nadaptive decision-making. Traditional approaches rely on safety engineers\nhand-coding large sets of recovery rules, but this strategy cannot anticipate\nthe vast range of real-world contingencies and quickly becomes incomplete.\nRecent advances in embodied AI, powered by large visual language models,\nprovide commonsense reasoning to assess context and generate appropriate\nactions in real time. We demonstrate this capability in a simulated urban\nbenchmark in the Unreal Engine, where drones dynamically interpret their\nsurroundings and decide on sudden maneuvers for safe landings. Our results show\nthat embodied AI makes possible a new class of adaptive recovery and\ndecision-making pipelines that were previously infeasible to design by hand,\nadvancing resilience and safety in autonomous aerial systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5177\u8eabAI\u548c\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6765\u589e\u5f3a\u81ea\u4e3b\u65e0\u4eba\u673a\u5728\u7a81\u53d1\u4e8b\u4ef6\u4e2d\u7684\u81ea\u9002\u5e94\u51b3\u7b56\u80fd\u529b\uff0c\u66ff\u4ee3\u4f20\u7edf\u624b\u5de5\u7f16\u7801\u7684\u5b89\u5168\u89c4\u5219\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5b89\u5168\u5de5\u7a0b\u5e08\u624b\u5de5\u7f16\u5199\u5927\u91cf\u6062\u590d\u89c4\u5219\uff0c\u65e0\u6cd5\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5404\u79cd\u610f\u5916\u60c5\u51b5\uff0c\u4e14\u5bb9\u6613\u53d8\u5f97\u4e0d\u5b8c\u6574\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u65f6\u8bc4\u4f30\u4e0a\u4e0b\u6587\u5e76\u751f\u6210\u9002\u5f53\u52a8\u4f5c\u7684\u81ea\u9002\u5e94\u51b3\u7b56\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u5177\u8eabAI\u548c\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5728Unreal Engine\u6a21\u62df\u7684\u57ce\u5e02\u573a\u666f\u4e2d\uff0c\u8ba9\u65e0\u4eba\u673a\u52a8\u6001\u89e3\u91ca\u5468\u56f4\u73af\u5883\u5e76\u51b3\u5b9a\u7d27\u6025\u673a\u52a8\u4ee5\u5b9e\u73b0\u5b89\u5168\u7740\u9646\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5177\u8eabAI\u80fd\u591f\u5b9e\u73b0\u4e00\u7c7b\u4ee5\u524d\u65e0\u6cd5\u624b\u5de5\u8bbe\u8ba1\u7684\u81ea\u9002\u5e94\u6062\u590d\u548c\u51b3\u7b56\u6d41\u7a0b\uff0c\u63d0\u9ad8\u4e86\u81ea\u4e3b\u7a7a\u4e2d\u7cfb\u7edf\u7684\u5f39\u6027\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5177\u8eabAI\u7684\u65b9\u6cd5\u4e3a\u81ea\u4e3b\u65e0\u4eba\u673a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u6062\u590d\u548c\u51b3\u7b56\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u5728\u9762\u5bf9\u7a81\u53d1\u4e8b\u4ef6\u65f6\u7684\u5b89\u5168\u6027\u548c\u97e7\u6027\u3002"}}
{"id": "2510.00406", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00406", "abs": "https://arxiv.org/abs/2510.00406", "authors": ["Hengtao Li", "Pengxiang Ding", "Runze Suo", "Yihao Wang", "Zirui Ge", "Dongyuan Zang", "Kexian Yu", "Mingyang Sun", "Hongyin Zhang", "Donglin Wang", "Weihua Su"], "title": "VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators", "comment": null, "summary": "Vision-Language-Action (VLA) models enable embodied decision-making but rely\nheavily on imitation learning, leading to compounding errors and poor\nrobustness under distribution shift. Reinforcement learning (RL) can mitigate\nthese issues yet typically demands costly real-world interactions or suffers\nfrom sim-to-real gaps. We introduce VLA-RFT, a reinforcement fine-tuning\nframework that leverages a data-driven world model as a controllable simulator.\nTrained from real interaction data, the simulator predicts future visual\nobservations conditioned on actions, allowing policy rollouts with dense,\ntrajectory-level rewards derived from goal-achieving references. This design\ndelivers an efficient and action-aligned learning signal, drastically lowering\nsample requirements. With fewer than 400 fine-tuning steps, VLA-RFT surpasses\nstrong supervised baselines and achieves greater efficiency than\nsimulator-based RL. Moreover, it exhibits strong robustness under perturbed\nconditions, sustaining stable task execution. Our results establish\nworld-model-based RFT as a practical post-training paradigm to enhance the\ngeneralization and robustness of VLA models. For more details, please refer to\nhttps://vla-rft.github.io/.", "AI": {"tldr": "VLA-RFT\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u5f3a\u5316\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u53ef\u63a7\u6a21\u62df\u5668\u6765\u589e\u5f3a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4ec5\u9700\u4e0d\u5230400\u6b65\u5fae\u8c03\u5373\u53ef\u8d85\u8d8a\u76d1\u7763\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u6a21\u4eff\u5b66\u4e60\uff0c\u5bb9\u6613\u4ea7\u751f\u7d2f\u79ef\u8bef\u5dee\u4e14\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u9c81\u68d2\u6027\u5dee\u3002\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u6216\u9762\u4e34\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528\u4ece\u771f\u5b9e\u4ea4\u4e92\u6570\u636e\u8bad\u7ec3\u7684\u6570\u636e\u9a71\u52a8\u4e16\u754c\u6a21\u578b\u4f5c\u4e3a\u53ef\u63a7\u6a21\u62df\u5668\uff0c\u8be5\u6a21\u62df\u5668\u6839\u636e\u52a8\u4f5c\u9884\u6d4b\u672a\u6765\u89c6\u89c9\u89c2\u5bdf\uff0c\u5141\u8bb8\u7b56\u7565\u5c55\u5f00\u5e76\u4f7f\u7528\u4ece\u76ee\u6807\u8fbe\u6210\u53c2\u8003\u4e2d\u83b7\u5f97\u7684\u5bc6\u96c6\u8f68\u8ff9\u7ea7\u5956\u52b1\u3002", "result": "\u4ec5\u9700\u4e0d\u5230400\u6b65\u5fae\u8c03\uff0cVLA-RFT\u5c31\u8d85\u8d8a\u4e86\u5f3a\u5927\u7684\u76d1\u7763\u57fa\u7ebf\uff0c\u6bd4\u57fa\u4e8e\u6a21\u62df\u5668\u7684\u5f3a\u5316\u5b66\u4e60\u66f4\u9ad8\u6548\uff0c\u5728\u6270\u52a8\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\uff0c\u4fdd\u6301\u7a33\u5b9a\u7684\u4efb\u52a1\u6267\u884c\u3002", "conclusion": "\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u5f3a\u5316\u5fae\u8c03\u662f\u4e00\u79cd\u5b9e\u7528\u7684\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u53ef\u4ee5\u6709\u6548\u589e\u5f3a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.00858", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00858", "abs": "https://arxiv.org/abs/2510.00858", "authors": ["Julie Rousseau", "Hanmin Cai", "Philipp Heer", "Kristina Orehounig", "Gabriela Hug"], "title": "Uncertainty-Aware Flexibility of Buildings: From Quantification to Provision", "comment": "Accepted in IEEE Transactions on Smart Grids", "summary": "Buildings represent a promising flexibility source to support the integration\nof renewable energy sources, as they may shift their heating energy consumption\nover time without impacting users' comfort. However, a building's predicted\nflexibility potential is based on uncertain ambient weather forecasts and a\ntypically inaccurate building thermal model. Hence, this paper presents an\nuncertainty-aware flexibility quantifier using a chance-constrained\nformulation. Because such a quantifier may be conservative, we additionally\nmodel real-time feedback in the quantification, in the form of affine feedback\npolicies. Such adaptation can take the form of intra-day trades or rebound\naround the flexibility provision period. To assess the flexibility\nquantification formulations, we further assume that flexible buildings\nparticipate in secondary frequency control markets. The results show some\nincrease in flexibility and revenues when introducing affine feedback policies.\nAdditionally, it is demonstrated that accounting for uncertainties in the\nflexibility quantification is necessary, especially when intra-day trades are\nnot available. Even though an uncertainty-ignorant potential may seem\nfinancially profitable in secondary frequency control markets, it comes at the\ncost of significant thermal discomfort for inhabitants. Hence, we suggest a\ncomfort-preserving approach, aiming to truly reflect thermal discomfort on the\neconomic flexibility revenue, to obtain a fairer comparison.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684\u5efa\u7b51\u7075\u6d3b\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u4f7f\u7528\u673a\u4f1a\u7ea6\u675f\u516c\u5f0f\u548c\u4eff\u5c04\u53cd\u9988\u7b56\u7565\u6765\u63d0\u5347\u7075\u6d3b\u6027\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5728\u4e8c\u7ea7\u9891\u7387\u63a7\u5236\u5e02\u573a\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5efa\u7b51\u4f5c\u4e3a\u53ef\u518d\u751f\u80fd\u6e90\u6574\u5408\u7684\u7075\u6d3b\u6027\u8d44\u6e90\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9884\u6d4b\u7684\u7075\u6d3b\u6027\u6f5c\u529b\u53d7\u5230\u4e0d\u786e\u5b9a\u7684\u5929\u6c14\u9884\u6d4b\u548c\u4e0d\u51c6\u786e\u7684\u5efa\u7b51\u70ed\u6a21\u578b\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u91cf\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u673a\u4f1a\u7ea6\u675f\u516c\u5f0f\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u7075\u6d3b\u6027\u91cf\u5316\uff0c\u5e76\u5f15\u5165\u4eff\u5c04\u53cd\u9988\u7b56\u7565\u6765\u5b9e\u65f6\u8c03\u6574\u7075\u6d3b\u6027\u63d0\u4f9b\uff0c\u8003\u8651\u4e86\u65e5\u5185\u4ea4\u6613\u548c\u7075\u6d3b\u6027\u63d0\u4f9b\u671f\u540e\u7684\u56de\u5f39\u6548\u5e94\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5f15\u5165\u4eff\u5c04\u53cd\u9988\u7b56\u7565\u80fd\u589e\u52a0\u7075\u6d3b\u6027\u548c\u6536\u76ca\uff0c\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u5728\u7075\u6d3b\u6027\u91cf\u5316\u4e2d\u662f\u5fc5\u8981\u7684\uff0c\u7279\u522b\u662f\u5728\u6ca1\u6709\u65e5\u5185\u4ea4\u6613\u7684\u60c5\u51b5\u4e0b\u3002\u5ffd\u7565\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u867d\u7136\u770b\u4f3c\u6709\u5229\u53ef\u56fe\uff0c\u4f46\u4f1a\u5e26\u6765\u663e\u8457\u7684\u70ed\u8212\u9002\u5ea6\u635f\u5931\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528\u4fdd\u6301\u8212\u9002\u5ea6\u7684\u65b9\u6cd5\uff0c\u5c06\u70ed\u4e0d\u9002\u771f\u5b9e\u53cd\u6620\u5728\u7ecf\u6d4e\u7075\u6d3b\u6027\u6536\u76ca\u4e2d\uff0c\u4ee5\u83b7\u5f97\u66f4\u516c\u5e73\u7684\u6bd4\u8f83\uff0c\u786e\u4fdd\u5efa\u7b51\u7075\u6d3b\u6027\u8d44\u6e90\u7684\u53ef\u6301\u7eed\u5229\u7528\u3002"}}
{"id": "2510.00741", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00741", "abs": "https://arxiv.org/abs/2510.00741", "authors": ["Victor Brabant", "Angela Bonifati", "R\u00e9my Cazabet"], "title": "Discovering Communities in Continuous-Time Temporal Networks by Optimizing L-Modularity", "comment": "Accepted in ICDM 2025", "summary": "Community detection is a fundamental problem in network analysis, with many\napplications in various fields. Extending community detection to the temporal\nsetting with exact temporal accuracy, as required by real-world dynamic data,\nnecessitates methods specifically adapted to the temporal nature of\ninteractions. We introduce LAGO, a novel method for uncovering dynamic\ncommunities by greedy optimization of Longitudinal Modularity, a specific\nadaptation of Modularity for continuous-time networks. Unlike prior approaches\nthat rely on time discretization or assume rigid community evolution, LAGO\ncaptures the precise moments when nodes enter and exit communities. We evaluate\nLAGO on synthetic benchmarks and real-world datasets, demonstrating its ability\nto efficiently uncover temporally and topologically coherent communities.", "AI": {"tldr": "LAGO\u662f\u4e00\u79cd\u7528\u4e8e\u52a8\u6001\u793e\u533a\u68c0\u6d4b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d2a\u5a6a\u4f18\u5316\u7eb5\u5411\u6a21\u5757\u5ea6\u6765\u53d1\u73b0\u8fde\u7eed\u65f6\u95f4\u7f51\u7edc\u4e2d\u7684\u52a8\u6001\u793e\u533a\uff0c\u80fd\u591f\u7cbe\u786e\u6355\u6349\u8282\u70b9\u8fdb\u51fa\u793e\u533a\u7684\u65f6\u95f4\u70b9\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u52a8\u6001\u6570\u636e\u9700\u8981\u5177\u6709\u7cbe\u786e\u65f6\u95f4\u51c6\u786e\u6027\u7684\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u65f6\u95f4\u79bb\u6563\u5316\uff0c\u8981\u4e48\u5047\u8bbe\u793e\u533a\u6f14\u5316\u6a21\u5f0f\u8fc7\u4e8e\u521a\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u8282\u70b9\u8fdb\u51fa\u793e\u533a\u7684\u7cbe\u786e\u65f6\u523b\u3002", "method": "LAGO\u901a\u8fc7\u8d2a\u5a6a\u4f18\u5316\u7eb5\u5411\u6a21\u5757\u5ea6\uff08Longitudinal Modularity\uff09\u6765\u53d1\u73b0\u52a8\u6001\u793e\u533a\uff0c\u8fd9\u662f\u6a21\u5757\u5ea6\u5728\u8fde\u7eed\u65f6\u95f4\u7f51\u7edc\u4e2d\u7684\u7279\u5b9a\u9002\u5e94\u5f62\u5f0f\uff0c\u80fd\u591f\u7cbe\u786e\u8ffd\u8e2a\u8282\u70b9\u8fdb\u5165\u548c\u9000\u51fa\u793e\u533a\u7684\u65f6\u95f4\u70b9\u3002", "result": "\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cLAGO\u80fd\u591f\u9ad8\u6548\u5730\u53d1\u73b0\u65f6\u95f4\u548c\u62d3\u6251\u4e0a\u4e00\u81f4\u7684\u793e\u533a\u3002", "conclusion": "LAGO\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u53d1\u73b0\u52a8\u6001\u7f51\u7edc\u4e2d\u7684\u793e\u533a\u7ed3\u6784\uff0c\u80fd\u591f\u7cbe\u786e\u6355\u6349\u793e\u533a\u6f14\u5316\u7684\u65f6\u95f4\u52a8\u6001\u6027\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u65f6\u95f4\u7cbe\u5ea6\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.00185", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00185", "abs": "https://arxiv.org/abs/2510.00185", "authors": ["Gabriel de Olim Gaul", "Adam Gould", "Avinash Kori", "Francesca Toni"], "title": "Object-Centric Case-Based Reasoning via Argumentation", "comment": "Accepted to ArgXAI@ECAI25", "summary": "We introduce Slot Attention Argumentation for Case-Based Reasoning (SAA-CBR),\na novel neuro-symbolic pipeline for image classification that integrates\nobject-centric learning via a neural Slot Attention (SA) component with\nsymbolic reasoning conducted by Abstract Argumentation for Case-Based Reasoning\n(AA-CBR). We explore novel integrations of AA-CBR with the neural component,\nincluding feature combination strategies, casebase reduction via representative\nsamples, novel count-based partial orders, a One-Vs-Rest strategy for extending\nAA-CBR to multi-class classification, and an application of Supported AA-CBR, a\nbipolar variant of AA-CBR. We demonstrate that SAA-CBR is an effective\nclassifier on the CLEVR-Hans datasets, showing competitive performance against\nbaseline models.", "AI": {"tldr": "SAA-CBR\u662f\u4e00\u79cd\u65b0\u578b\u7684\u795e\u7ecf\u7b26\u53f7\u56fe\u50cf\u5206\u7c7b\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u795e\u7ecfSlot Attention\u7ec4\u4ef6\u548c\u7b26\u53f7\u63a8\u7406\u7684AA-CBR\u65b9\u6cd5\uff0c\u5728CLEVR-Hans\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u7ade\u4e89\u529b\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7ed3\u5408\u795e\u7ecf\u5b66\u4e60\u548c\u7b26\u53f7\u63a8\u7406\u7684\u6df7\u5408\u7cfb\u7edf\uff0c\u4ee5\u63d0\u5347\u56fe\u50cf\u5206\u7c7b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5bf9\u8c61\u7ea7\u7406\u89e3\u548c\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u3002", "method": "\u4f7f\u7528Slot Attention\u8fdb\u884c\u5bf9\u8c61\u4e2d\u5fc3\u5b66\u4e60\uff0c\u7136\u540e\u901a\u8fc7AA-CBR\u8fdb\u884c\u7b26\u53f7\u63a8\u7406\uff0c\u5305\u62ec\u7279\u5f81\u7ec4\u5408\u7b56\u7565\u3001\u6848\u4f8b\u5e93\u7f29\u51cf\u3001\u57fa\u4e8e\u8ba1\u6570\u7684\u504f\u5e8f\u3001One-Vs-Rest\u591a\u5206\u7c7b\u7b56\u7565\u4ee5\u53ca\u53cc\u6781AA-CBR\u53d8\u4f53\u3002", "result": "\u5728CLEVR-Hans\u6570\u636e\u96c6\u4e0a\uff0cSAA-CBR\u8868\u73b0\u51fa\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u7ade\u4e89\u7684\u6027\u80fd\u3002", "conclusion": "SAA-CBR\u662f\u4e00\u4e2a\u6709\u6548\u7684\u56fe\u50cf\u5206\u7c7b\u5668\uff0c\u6210\u529f\u6574\u5408\u4e86\u795e\u7ecf\u548c\u7b26\u53f7\u65b9\u6cd5\uff0c\u4e3a\u795e\u7ecf\u7b26\u53f7AI\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2510.00441", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00441", "abs": "https://arxiv.org/abs/2510.00441", "authors": ["Yiyuan Pan", "Yunzhe Xu", "Zhe Liu", "Hesheng Wang"], "title": "Seeing through Uncertainty: Robust Task-Oriented Optimization in Visual Navigation", "comment": null, "summary": "Visual navigation is a fundamental problem in embodied AI, yet practical\ndeployments demand long-horizon planning capabilities to address\nmulti-objective tasks. A major bottleneck is data scarcity: policies learned\nfrom limited data often overfit and fail to generalize OOD. Existing neural\nnetwork-based agents typically increase architectural complexity that\nparadoxically become counterproductive in the small-sample regime. This paper\nintroduce NeuRO, a integrated learning-to-optimize framework that tightly\ncouples perception networks with downstream task-level robust optimization.\nSpecifically, NeuRO addresses core difficulties in this integration: (i) it\ntransforms noisy visual predictions under data scarcity into convex uncertainty\nsets using Partially Input Convex Neural Networks (PICNNs) with conformal\ncalibration, which directly parameterize the optimization constraints; and (ii)\nit reformulates planning under partial observability as a robust optimization\nproblem, enabling uncertainty-aware policies that transfer across environments.\nExtensive experiments on both unordered and sequential multi-object navigation\ntasks demonstrate that NeuRO establishes SoTA performance, particularly in\ngeneralization to unseen environments. Our work thus presents a significant\nadvancement for developing robust, generalizable autonomous agents.", "AI": {"tldr": "NeuRO\u662f\u4e00\u4e2a\u96c6\u6210\u5b66\u4e60\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u611f\u77e5\u7f51\u7edc\u4e0e\u4e0b\u6e38\u4efb\u52a1\u7ea7\u9c81\u68d2\u4f18\u5316\u7d27\u5bc6\u8026\u5408\uff0c\u901a\u8fc7\u90e8\u5206\u8f93\u5165\u51f8\u795e\u7ecf\u7f51\u7edc\u548c\u4fdd\u5f62\u6821\u51c6\u5c06\u89c6\u89c9\u9884\u6d4b\u8f6c\u5316\u4e3a\u51f8\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u4e0b\u7684\u89c6\u89c9\u5bfc\u822a\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u5bfc\u822a\u662f\u5177\u8eabAI\u7684\u57fa\u7840\u95ee\u9898\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9700\u8981\u957f\u65f6\u7a0b\u89c4\u5212\u80fd\u529b\u6765\u5904\u7406\u591a\u76ee\u6807\u4efb\u52a1\u3002\u4e3b\u8981\u74f6\u9888\u662f\u6570\u636e\u7a00\u7f3a\uff1a\u4ece\u6709\u9650\u6570\u636e\u5b66\u4e60\u7684\u7b56\u7565\u5bb9\u6613\u8fc7\u62df\u5408\u4e14\u65e0\u6cd5\u6cdb\u5316\u5230\u5206\u5e03\u5916\u573a\u666f\u3002\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u4ee3\u7406\u901a\u5e38\u589e\u52a0\u67b6\u6784\u590d\u6742\u6027\uff0c\u8fd9\u5728\u5c11\u6837\u672c\u573a\u666f\u4e2d\u9002\u5f97\u5176\u53cd\u3002", "method": "NeuRO\u6846\u67b6\uff1a(i)\u4f7f\u7528\u90e8\u5206\u8f93\u5165\u51f8\u795e\u7ecf\u7f51\u7edc(PICNNs)\u548c\u4fdd\u5f62\u6821\u51c6\u5c06\u566a\u58f0\u89c6\u89c9\u9884\u6d4b\u8f6c\u5316\u4e3a\u51f8\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\uff0c\u76f4\u63a5\u53c2\u6570\u5316\u4f18\u5316\u7ea6\u675f\uff1b(ii)\u5c06\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u4e0b\u7684\u89c4\u5212\u91cd\u65b0\u8868\u8ff0\u4e3a\u9c81\u68d2\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u8de8\u73af\u5883\u8f6c\u79fb\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7b56\u7565\u3002", "result": "\u5728\u65e0\u5e8f\u548c\u987a\u5e8f\u591a\u76ee\u6807\u5bfc\u822a\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cNeuRO\u5efa\u7acb\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u672a\u89c1\u73af\u5883\u7684\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5f00\u53d1\u9c81\u68d2\u3001\u53ef\u6cdb\u5316\u7684\u81ea\u4e3b\u4ee3\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\uff0cNeuRO\u6846\u67b6\u5728\u6570\u636e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.00906", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00906", "abs": "https://arxiv.org/abs/2510.00906", "authors": ["Julian Lemmel", "Manuel Kranzl", "Adam Lamine", "Philipp Neubauer", "Radu Grosu", "Sophie A. Neubauer"], "title": "TubeDAgger: Reducing the Number of Expert Interventions with Stochastic Reach-Tubes", "comment": null, "summary": "Interactive Imitation Learning deals with training a novice policy from\nexpert demonstrations in an online fashion. The established DAgger algorithm\ntrains a robust novice policy by alternating between interacting with the\nenvironment and retraining of the network. Many variants thereof exist, that\ndiffer in the method of discerning whether to allow the novice to act or return\ncontrol to the expert. We propose the use of stochastic reachtubes - common in\nverification of dynamical systems - as a novel method for estimating the\nnecessity of expert intervention. Our approach does not require fine-tuning of\ndecision thresholds per environment and effectively reduces the number of\nexpert interventions, especially when compared with related approaches that\nmake use of a doubt classification model.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u968f\u673a\u53ef\u8fbe\u7ba1\u4f5c\u4e3a\u5224\u65ad\u4e13\u5bb6\u5e72\u9884\u65f6\u673a\u7684\u65b0\u65b9\u6cd5\uff0c\u51cf\u5c11\u4ea4\u4e92\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u4e13\u5bb6\u5e72\u9884\u6b21\u6570", "motivation": "\u73b0\u6709\u7684DAgger\u7b97\u6cd5\u53ca\u5176\u53d8\u4f53\u5728\u5224\u65ad\u4f55\u65f6\u8ba9\u65b0\u624b\u7b56\u7565\u884c\u52a8\u6216\u4ea4\u8fd8\u63a7\u5236\u7ed9\u4e13\u5bb6\u65f6\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u73af\u5883\u8c03\u6574\u51b3\u7b56\u9608\u503c", "method": "\u4f7f\u7528\u968f\u673a\u53ef\u8fbe\u7ba1\uff08\u5e38\u7528\u4e8e\u52a8\u6001\u7cfb\u7edf\u9a8c\u8bc1\uff09\u6765\u4f30\u8ba1\u4e13\u5bb6\u5e72\u9884\u7684\u5fc5\u8981\u6027\uff0c\u65e0\u9700\u9488\u5bf9\u6bcf\u4e2a\u73af\u5883\u5fae\u8c03\u51b3\u7b56\u9608\u503c", "result": "\u4e0e\u4f7f\u7528\u6000\u7591\u5206\u7c7b\u6a21\u578b\u7684\u76f8\u5173\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u4e13\u5bb6\u5e72\u9884\u6b21\u6570", "conclusion": "\u968f\u673a\u53ef\u8fbe\u7ba1\u65b9\u6cd5\u5728\u4ea4\u4e92\u6a21\u4eff\u5b66\u4e60\u4e2d\u80fd\u6709\u6548\u51cf\u5c11\u4e13\u5bb6\u5e72\u9884\uff0c\u4e14\u65e0\u9700\u73af\u5883\u7279\u5b9a\u7684\u9608\u503c\u8c03\u4f18"}}
{"id": "2510.00186", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00186", "abs": "https://arxiv.org/abs/2510.00186", "authors": ["Anni Li", "Aria Attar", "Paul Dong"], "title": "Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware Objective", "comment": null, "summary": "Transforming natural-language requests into reliable, production-ready data\ntransformations remains challenging: correctness depends on precise schema\nlinking and warehouse-specific SQL dialects, while the strongest supervision\navailable during training--execution success and result matching--are provided\nonly at the sequence level. At the same time, assembling large,\nexecution-validated corpora is costly, and token-level objectives misalign with\nthese global signals, yielding unstable optimization and limited portability.\nWe introduce Thinkquel, a fine-tuned model for producing robust, portable, and\nexecution-validated database queries. Methodologies in Thinkquel integrates a\nnovel synthetic data pipeline, TS-SQL, that leverages dbt as a portable\nintermediate representation with a span-aware reinforcement learning objective,\nand Token-Sequence GRPO (TS-GRPO), specifically designed to bridge the gap\nbetween token-level training signals and sequence-level execution rewards when\nfinetuning LLMs. On the 500-example TS-SQL test set, Thinkquel (32B) reaches\n93.2\\% execution success and 61.8\\% exact-result match with a two-stage SFT\ncurriculum, improving over the base model by 67.2\\% (exec.) and 44.4\\% (match).\nIn Spider (14B) experiments, TS-GRPO increases training stability and speeds\nconvergence of the execution-match reward relative to GRPO and GSPO.", "AI": {"tldr": "Thinkquel\u662f\u4e00\u4e2a\u7ecf\u8fc7\u5fae\u8c03\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u53ef\u9760\u3001\u53ef\u79fb\u690d\u4e14\u7ecf\u8fc7\u6267\u884c\u9a8c\u8bc1\u7684\u6570\u636e\u5e93\u67e5\u8be2\u3002\u5b83\u96c6\u6210\u4e86\u65b0\u9896\u7684\u5408\u6210\u6570\u636e\u7ba1\u9053TS-SQL\u548c\u4e13\u95e8\u8bbe\u8ba1\u7684Token-Sequence GRPO\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u4ee5\u5f25\u5408token\u7ea7\u8bad\u7ec3\u4fe1\u53f7\u4e0e\u5e8f\u5217\u7ea7\u6267\u884c\u5956\u52b1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5c06\u81ea\u7136\u8bed\u8a00\u8bf7\u6c42\u8f6c\u6362\u4e3a\u53ef\u9760\u3001\u751f\u4ea7\u5c31\u7eea\u7684\u6570\u636e\u8f6c\u6362\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff1a\u6b63\u786e\u6027\u4f9d\u8d56\u4e8e\u7cbe\u786e\u7684\u6a21\u5f0f\u94fe\u63a5\u548c\u4ed3\u5e93\u7279\u5b9a\u7684SQL\u65b9\u8a00\uff0c\u800c\u8bad\u7ec3\u671f\u95f4\u6700\u5f3a\u7684\u76d1\u7763\u2014\u2014\u6267\u884c\u6210\u529f\u548c\u7ed3\u679c\u5339\u914d\u2014\u2014\u4ec5\u5728\u5e8f\u5217\u7ea7\u522b\u63d0\u4f9b\u3002\u540c\u65f6\uff0c\u7ec4\u88c5\u5927\u89c4\u6a21\u3001\u7ecf\u8fc7\u6267\u884c\u9a8c\u8bc1\u7684\u8bed\u6599\u5e93\u6210\u672c\u9ad8\u6602\uff0c\u4e14token\u7ea7\u76ee\u6807\u4e0e\u8fd9\u4e9b\u5168\u5c40\u4fe1\u53f7\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u4f18\u5316\u4e0d\u7a33\u5b9a\u548c\u53ef\u79fb\u690d\u6027\u6709\u9650\u3002", "method": "Thinkquel\u96c6\u6210\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5408\u6210\u6570\u636e\u7ba1\u9053TS-SQL\uff0c\u5229\u7528dbt\u4f5c\u4e3a\u53ef\u79fb\u690d\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u5e76\u7ed3\u5408span\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u76ee\u6807Token-Sequence GRPO\uff08TS-GRPO\uff09\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5728\u5fae\u8c03LLMs\u65f6\u5f25\u5408token\u7ea7\u8bad\u7ec3\u4fe1\u53f7\u4e0e\u5e8f\u5217\u7ea7\u6267\u884c\u5956\u52b1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u5728500\u4e2a\u793a\u4f8b\u7684TS-SQL\u6d4b\u8bd5\u96c6\u4e0a\uff0cThinkquel\uff0832B\uff09\u901a\u8fc7\u4e24\u9636\u6bb5SFT\u8bfe\u7a0b\u8fbe\u523093.2%\u7684\u6267\u884c\u6210\u529f\u7387\u548c61.8%\u7684\u7cbe\u786e\u7ed3\u679c\u5339\u914d\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u5206\u522b\u63d0\u9ad8\u4e8667.2%\uff08\u6267\u884c\uff09\u548c44.4%\uff08\u5339\u914d\uff09\u3002\u5728Spider\uff0814B\uff09\u5b9e\u9a8c\u4e2d\uff0cTS-GRPO\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5e76\u52a0\u901f\u4e86\u6267\u884c\u5339\u914d\u5956\u52b1\u76f8\u5bf9\u4e8eGRPO\u548cGSPO\u7684\u6536\u655b\u3002", "conclusion": "Thinkquel\u901a\u8fc7\u96c6\u6210TS-SQL\u5408\u6210\u6570\u636e\u7ba1\u9053\u548cTS-GRPO\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u81ea\u7136\u8bed\u8a00\u5230SQL\u8f6c\u6362\u4e2d\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6267\u884c\u6210\u529f\u7387\u548c\u7ed3\u679c\u5339\u914d\u7cbe\u5ea6\uff0c\u540c\u65f6\u6539\u5584\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2510.00466", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00466", "abs": "https://arxiv.org/abs/2510.00466", "authors": ["Run Su", "Hao Fu", "Shuai Zhou", "Yingao Fu"], "title": "Integrating Offline Pre-Training with Online Fine-Tuning: A Reinforcement Learning Approach for Robot Social Navigation", "comment": null, "summary": "Offline reinforcement learning (RL) has emerged as a promising framework for\naddressing robot social navigation challenges. However, inherent uncertainties\nin pedestrian behavior and limited environmental interaction during training\noften lead to suboptimal exploration and distributional shifts between offline\ntraining and online deployment. To overcome these limitations, this paper\nproposes a novel offline-to-online fine-tuning RL algorithm for robot social\nnavigation by integrating Return-to-Go (RTG) prediction into a causal\nTransformer architecture. Our algorithm features a spatiotem-poral fusion model\ndesigned to precisely estimate RTG values in real-time by jointly encoding\ntemporal pedestrian motion patterns and spatial crowd dynamics. This RTG\nprediction framework mitigates distribution shift by aligning offline policy\ntraining with online environmental interactions. Furthermore, a hybrid\noffline-online experience sampling mechanism is built to stabilize policy\nupdates during fine-tuning, ensuring balanced integration of pre-trained\nknowledge and real-time adaptation. Extensive experiments in simulated social\nnavigation environments demonstrate that our method achieves a higher success\nrate and lower collision rate compared to state-of-the-art baselines. These\nresults underscore the efficacy of our algorithm in enhancing navigation policy\nrobustness and adaptability. This work paves the way for more reliable and\nadaptive robotic navigation systems in real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u673a\u5668\u4eba\u793e\u4ea4\u5bfc\u822a\u7684\u79bb\u7ebf\u5230\u5728\u7ebf\u5fae\u8c03\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06Return-to-Go\u9884\u6d4b\u96c6\u6210\u5230\u56e0\u679cTransformer\u67b6\u6784\u4e2d\uff0c\u89e3\u51b3\u4e86\u79bb\u7ebf\u8bad\u7ec3\u4e0e\u5728\u7ebf\u90e8\u7f72\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u673a\u5668\u4eba\u793e\u4ea4\u5bfc\u822a\u4e2d\u5b58\u5728\u63a2\u7d22\u4e0d\u8db3\u548c\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u7ed3\u5408\u79bb\u7ebf\u8bad\u7ec3\u77e5\u8bc6\u548c\u5728\u7ebf\u73af\u5883\u4ea4\u4e92\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u65f6\u7a7a\u878d\u5408\u6a21\u578b\u6765\u5b9e\u65f6\u4f30\u8ba1RTG\u503c\uff0c\u7ed3\u5408\u65f6\u95f4\u884c\u4eba\u8fd0\u52a8\u6a21\u5f0f\u548c\u7a7a\u95f4\u4eba\u7fa4\u52a8\u6001\u7f16\u7801\uff0c\u5e76\u6784\u5efa\u4e86\u6df7\u5408\u79bb\u7ebf-\u5728\u7ebf\u7ecf\u9a8c\u91c7\u6837\u673a\u5236\u6765\u7a33\u5b9a\u7b56\u7565\u66f4\u65b0\u3002", "result": "\u5728\u6a21\u62df\u793e\u4ea4\u5bfc\u822a\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\u548c\u66f4\u4f4e\u7684\u78b0\u649e\u7387\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u663e\u8457\u589e\u5f3a\u4e86\u5bfc\u822a\u7b56\u7565\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u66f4\u53ef\u9760\u548c\u81ea\u9002\u5e94\u7684\u673a\u5668\u4eba\u5bfc\u822a\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.00943", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00943", "abs": "https://arxiv.org/abs/2510.00943", "authors": ["Hang Zhou", "Yuxin Yang", "Branislav Hrezdak", "John Edward Fletcher"], "title": "Accurate Small-Signal Modeling of Digitally Controlled Buck Converters with ADC-PWM Synchronization", "comment": null, "summary": "Digital control has become increasingly widespread in modern power electronic\nconverters. When acquiring feedback signals such as the inductor current,\nsynchronizing the analog-to-digital converter (ADC) with the digital\npulse-width modulator (DPWM) is commonly employed to accurately track their\nsteady-state average. However, the small-signal implications of such\nsynchronization have not been investigated. This paper presents an exact\nsmall-signal model for digitally controlled buck converters operating in forced\ncontinuous-conduction mode (FCCM) under constant-frequency current-mode\ncontrol, explicitly accounting for DPWM-ADC synchronization. Using a\nsampled-data framework, the proposed model captures all sideband effects\nintroduced by the sampling process, yielding precise predictions of both analog\nand digital loop gains, even at frequencies beyond the switching and sampling\nfrequencies. Both asymmetrical and symmetrical carrier modulations are\nconsidered. Furthermore, the digital loop gain is derived in closed form using\nthe modified z-transform, enabling low-complexity compensator design and\nstability assessment. Within this framework, the analog loop gain can be\ndirectly obtained from the digital loop gain, thereby eliminating the need for\ncomputationally intensive infinite series evaluations. The validity of the\nproposed model is confirmed through both simulation and experimental results.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6570\u5b57\u63a7\u5236\u964d\u538b\u53d8\u6362\u5668\u5728\u5f3a\u5236\u8fde\u7eed\u5bfc\u901a\u6a21\u5f0f\u4e0b\u7684\u7cbe\u786e\u5c0f\u4fe1\u53f7\u6a21\u578b\uff0c\u8003\u8651\u4e86DPWM-ADC\u540c\u6b65\u7684\u5f71\u54cd\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u6a21\u62df\u548c\u6570\u5b57\u73af\u8def\u589e\u76ca\u3002", "motivation": "\u6570\u5b57\u63a7\u5236\u5728\u529f\u7387\u7535\u5b50\u53d8\u6362\u5668\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46DPWM\u4e0eADC\u540c\u6b65\u7684\u5c0f\u4fe1\u53f7\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u7814\u7a76\uff0c\u9700\u8981\u5efa\u7acb\u7cbe\u786e\u6a21\u578b\u6765\u6307\u5bfc\u8865\u507f\u5668\u8bbe\u8ba1\u548c\u7a33\u5b9a\u6027\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u91c7\u6837\u6570\u636e\u6846\u67b6\uff0c\u8003\u8651\u975e\u5bf9\u79f0\u548c\u5bf9\u79f0\u8f7d\u6ce2\u8c03\u5236\uff0c\u901a\u8fc7\u4fee\u6b63z\u53d8\u6362\u63a8\u5bfc\u6570\u5b57\u73af\u8def\u589e\u76ca\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u6a21\u578b\u80fd\u591f\u7cbe\u786e\u9884\u6d4b\u5f00\u5173\u9891\u7387\u548c\u91c7\u6837\u9891\u7387\u4ee5\u4e0a\u7684\u73af\u8def\u589e\u76ca\uff0c\u6a21\u62df\u73af\u8def\u589e\u76ca\u53ef\u76f4\u63a5\u4ece\u6570\u5b57\u73af\u8def\u589e\u76ca\u83b7\u5f97\uff0c\u65e0\u9700\u590d\u6742\u8ba1\u7b97\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u4e3a\u6570\u5b57\u63a7\u5236\u529f\u7387\u53d8\u6362\u5668\u7684\u8865\u507f\u5668\u8bbe\u8ba1\u548c\u7a33\u5b9a\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u7cbe\u786e\u5de5\u5177\u3002"}}
{"id": "2510.00229", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00229", "abs": "https://arxiv.org/abs/2510.00229", "authors": ["Rohan Kadekodi", "Zhan Jin", "Keisuke Kamahori", "Yile Gu", "Sean Khatiri", "Noah H. Bayindirli", "Sergey Gorbunov", "Baris Kasikci"], "title": "DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems", "comment": null, "summary": "The deployment of Large Language Models (LLMs) as agentic orchestrators has\nrevolutionized task automation, but the need for privacy-preserving,\ncost-effective solutions demands on-device inference capabilities. However,\nlocal LLMs consistently underperform compared to frontier models in tool\ncalling scenarios, struggling with both tool selection from large tool sets and\naccurate argument generation for complex parameter structures. We introduce a\nmethodology that disaggregates a tool-calling task into two distinct subtasks:\ntool selection and argument generation. We propose \"decoupled fine-tuning\", a\nnovel post-training approach that employs LoRA fine-tuning to create dedicated\nLoRA adapters for tool selection and tool-specific argument generation using\nseparate loss masking for each of the subtasks. Furthermore, we present\nDualTune, an inference framework that leverages the LoRA adapters created using\ndecoupled fine-tuning to perform efficient agent orchestration with the help of\nlocal models on end-user devices. DualTune decomposes the tool-call generation\nstep into tool selection and argument generation, and dynamically loads the\ncorresponding LoRA adapters to generate tool calls. Additionally, DualTune\nimplements hierarchical orchestration to restrict the number of tools required\nfor tool selection. Our experiments on the MCP-Bench benchmark demonstrate that\nthe Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool\ncalling accuracy of the base model by 46%, and outperforms other local\nreasoning, non-reasoning and fine-tuned models of similar size in all cases,\nand models that are 2x larger, in most cases.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u89e3\u8026\u5fae\u8c03\u65b9\u6cd5\uff0c\u5c06\u5de5\u5177\u8c03\u7528\u4efb\u52a1\u5206\u89e3\u4e3a\u5de5\u5177\u9009\u62e9\u548c\u53c2\u6570\u751f\u6210\u4e24\u4e2a\u5b50\u4efb\u52a1\uff0c\u4f7f\u7528LoRA\u9002\u914d\u5668\u5206\u522b\u4f18\u5316\uff0c\u5e76\u901a\u8fc7DualTune\u63a8\u7406\u6846\u67b6\u5b9e\u73b0\u9ad8\u6548\u672c\u5730\u4ee3\u7406\u7f16\u6392\u3002", "motivation": "\u672c\u5730LLM\u5728\u5de5\u5177\u8c03\u7528\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u5347\u672c\u5730\u6a21\u578b\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3002", "method": "\u91c7\u7528\u89e3\u8026\u5fae\u8c03\u65b9\u6cd5\uff0c\u4e3a\u5de5\u5177\u9009\u62e9\u548c\u53c2\u6570\u751f\u6210\u5206\u522b\u521b\u5efa\u4e13\u7528LoRA\u9002\u914d\u5668\uff0c\u4f7f\u7528\u5206\u79bb\u7684\u635f\u5931\u63a9\u7801\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u901a\u8fc7DualTune\u6846\u67b6\u52a8\u6001\u52a0\u8f7d\u9002\u914d\u5668\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u5728MCP-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQwen-2.5-7B\u6a21\u578b\u7684\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u63d0\u5347\u4e8646%\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e2\u500d\u5927\u5c0f\u7684\u6a21\u578b\u3002", "conclusion": "\u89e3\u8026\u5fae\u8c03\u548cDualTune\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u672c\u5730LLM\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u4ee3\u7406\u7f16\u6392\u3002"}}
{"id": "2510.00491", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00491", "abs": "https://arxiv.org/abs/2510.00491", "authors": ["Han Zhou", "Jinjin Cao", "Liyuan Ma", "Xueji Fang", "Guo-jun Qi"], "title": "From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment", "comment": null, "summary": "Learning diverse manipulation skills for real-world robots is severely\nbottlenecked by the reliance on costly and hard-to-scale teleoperated\ndemonstrations. While human videos offer a scalable alternative, effectively\ntransferring manipulation knowledge is fundamentally hindered by the\nsignificant morphological gap between human and robotic embodiments. To address\nthis challenge and facilitate skill transfer from human to robot, we introduce\nTraj2Action,a novel framework that bridges this embodiment gap by using the 3D\ntrajectory of the operational endpoint as a unified intermediate\nrepresentation, and then transfers the manipulation knowledge embedded in this\ntrajectory to the robot's actions. Our policy first learns to generate a coarse\ntrajectory, which forms an high-level motion plan by leveraging both human and\nrobot data. This plan then conditions the synthesis of precise, robot-specific\nactions (e.g., orientation and gripper state) within a co-denoising framework.\nExtensive real-world experiments on a Franka robot demonstrate that Traj2Action\nboosts the performance by up to 27% and 22.25% over $\\pi_0$ baseline on short-\nand long-horizon real-world tasks, and achieves significant gains as human data\nscales in robot policy learning. Our project website, featuring code and video\ndemonstrations, is available at\nhttps://anonymous.4open.science/w/Traj2Action-4A45/.", "AI": {"tldr": "Traj2Action\u662f\u4e00\u4e2a\u901a\u8fc73D\u8f68\u8ff9\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\u6765\u5f25\u5408\u4eba\u7c7b\u4e0e\u673a\u5668\u4eba\u5f62\u6001\u5dee\u8ddd\u7684\u6846\u67b6\uff0c\u5c06\u4eba\u7c7b\u64cd\u4f5c\u77e5\u8bc6\u8f6c\u79fb\u5230\u673a\u5668\u4eba\u52a8\u4f5c\u4e2d\uff0c\u5728\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u591a\u6837\u5316\u64cd\u4f5c\u6280\u80fd\u5b66\u4e60\u4f9d\u8d56\u6602\u8d35\u9065\u64cd\u4f5c\u6f14\u793a\u7684\u95ee\u9898\uff0c\u5229\u7528\u53ef\u6269\u5c55\u7684\u4eba\u7c7b\u89c6\u9891\u6570\u636e\uff0c\u4f46\u9700\u8981\u514b\u670d\u4eba\u7c7b\u4e0e\u673a\u5668\u4eba\u5f62\u6001\u5dee\u5f02\u5e26\u6765\u7684\u77e5\u8bc6\u8f6c\u79fb\u969c\u788d\u3002", "method": "\u4f7f\u7528\u64cd\u4f5c\u7aef\u70b9\u76843D\u8f68\u8ff9\u4f5c\u4e3a\u7edf\u4e00\u4e2d\u95f4\u8868\u793a\uff0c\u5148\u5b66\u4e60\u751f\u6210\u7c97\u7565\u8f68\u8ff9\u4f5c\u4e3a\u9ad8\u5c42\u8fd0\u52a8\u89c4\u5212\uff0c\u7136\u540e\u5728\u534f\u540c\u53bb\u566a\u6846\u67b6\u4e2d\u5408\u6210\u7cbe\u786e\u7684\u673a\u5668\u4eba\u7279\u5b9a\u52a8\u4f5c\u3002", "result": "\u5728Franka\u673a\u5668\u4eba\u4e0a\u7684\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5728\u77ed\u65f6\u548c\u957f\u65f6\u4efb\u52a1\u4e0a\u6027\u80fd\u5206\u522b\u63d0\u534727%\u548c22.25%\uff0c\u4e14\u968f\u7740\u4eba\u7c7b\u6570\u636e\u89c4\u6a21\u589e\u52a0\uff0c\u673a\u5668\u4eba\u7b56\u7565\u5b66\u4e60\u6548\u679c\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Traj2Action\u901a\u8fc7\u8f68\u8ff9\u4e2d\u95f4\u8868\u793a\u6709\u6548\u5f25\u5408\u4e86\u4eba\u7c7b\u4e0e\u673a\u5668\u4eba\u7684\u5f62\u6001\u5dee\u8ddd\uff0c\u5b9e\u73b0\u4e86\u4ece\u4eba\u7c7b\u89c6\u9891\u5230\u673a\u5668\u4eba\u64cd\u4f5c\u6280\u80fd\u7684\u9ad8\u6548\u77e5\u8bc6\u8f6c\u79fb\u3002"}}
{"id": "2510.00963", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00963", "abs": "https://arxiv.org/abs/2510.00963", "authors": ["Carl Philipp Hohl", "Philipp Reis", "Tobias Sch\u00fcrmann", "Stefan Otten", "Eric Sax"], "title": "Structuring Automotive Data for Systems Engineering: A Taxonomy-Based Approach", "comment": null, "summary": "Vehicle data is essential for advancing data-driven development throughout\nthe automotive lifecycle, including requirements engineering, design,\nverification, and validation, and post-deployment optimization. Developers\ncurrently collect data in a decentralized and fragmented manner across\nsimulations, test benches, and real-world driving, resulting in data silos,\ninconsistent formats, and limited interoperability. This leads to redundant\nefforts, inefficient integration, and suboptimal use of data. This\nfragmentation results in data silos, inconsistent storage structures, and\nlimited interoperability, leading to redundant data collection, inefficient\nintegration, and suboptimal application. To address these challenges, this\narticle presents a structured literature review and develops an inductive\ntaxonomy for automotive data. This taxonomy categorizes data according to its\nsources and applications, improving data accessibility and utilization. The\nanalysis reveals a growing emphasis on real-world driving and machine learning\napplications while highlighting a critical gap in data availability for\nrequirements engineering. By providing a systematic framework for structuring\nautomotive data, this research contributes to more efficient data management\nand improved decision-making in the automotive industry.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7ed3\u6784\u5316\u6587\u732e\u56de\u987e\u5f00\u53d1\u4e86\u6c7d\u8f66\u6570\u636e\u5f52\u7eb3\u5206\u7c7b\u6cd5\uff0c\u89e3\u51b3\u6c7d\u8f66\u6570\u636e\u5206\u6563\u6536\u96c6\u5bfc\u81f4\u7684\u6570\u636e\u5b64\u5c9b\u3001\u683c\u5f0f\u4e0d\u4e00\u81f4\u548c\u4e92\u64cd\u4f5c\u6027\u6709\u9650\u7b49\u95ee\u9898\uff0c\u63d0\u9ad8\u6570\u636e\u53ef\u8bbf\u95ee\u6027\u548c\u5229\u7528\u7387\u3002", "motivation": "\u6c7d\u8f66\u6570\u636e\u5728\u4eff\u771f\u3001\u6d4b\u8bd5\u53f0\u67b6\u548c\u5b9e\u9645\u9a7e\u9a76\u4e2d\u4ee5\u5206\u6563\u65b9\u5f0f\u6536\u96c6\uff0c\u5bfc\u81f4\u6570\u636e\u5b64\u5c9b\u3001\u5b58\u50a8\u7ed3\u6784\u4e0d\u4e00\u81f4\u548c\u4e92\u64cd\u4f5c\u6027\u6709\u9650\uff0c\u9020\u6210\u6570\u636e\u6536\u96c6\u5197\u4f59\u3001\u96c6\u6210\u6548\u7387\u4f4e\u4e0b\u548c\u5e94\u7528\u6b21\u4f18\u3002", "method": "\u8fdb\u884c\u7ed3\u6784\u5316\u6587\u732e\u56de\u987e\u5e76\u5f00\u53d1\u6c7d\u8f66\u6570\u636e\u5f52\u7eb3\u5206\u7c7b\u6cd5\uff0c\u6839\u636e\u6570\u636e\u6765\u6e90\u548c\u5e94\u7528\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5206\u6790\u663e\u793a\u5bf9\u5b9e\u9645\u9a7e\u9a76\u548c\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u5173\u6ce8\u65e5\u76ca\u589e\u957f\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u9700\u6c42\u5de5\u7a0b\u6570\u636e\u53ef\u7528\u6027\u65b9\u9762\u7684\u5173\u952e\u5dee\u8ddd\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u7ed3\u6784\u5316\u6c7d\u8f66\u6570\u636e\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u672c\u7814\u7a76\u6709\u52a9\u4e8e\u66f4\u9ad8\u6548\u7684\u6570\u636e\u7ba1\u7406\u548c\u6539\u8fdb\u6c7d\u8f66\u884c\u4e1a\u7684\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2510.00274", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00274", "abs": "https://arxiv.org/abs/2510.00274", "authors": ["Maisha Maliha", "Dean Hougen"], "title": "MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning", "comment": "16 pages, 3 figures", "summary": "Understanding the decision-making process of Deep Reinforcement Learning\nagents remains a key challenge for deploying these systems in safety-critical\nand multi-agent environments. While prior explainability methods like\nStateMask, have advanced the identification of critical states, they remain\nlimited by computational cost, exploration coverage, and lack of adaptation to\nmulti-agent settings. To overcome these limitations, we propose a\nmathematically grounded framework, MAGIC-MASK (Multi-Agent Guided Inter-agent\nCollaboration with Mask-Based Explainability for Reinforcement Learning), that\nextends perturbation-based explanation to Multi-Agent Reinforcement Learning.\nOur method integrates Proximal Policy Optimization, adaptive epsilon-greedy\nexploration, and lightweight inter-agent collaboration to share masked state\ninformation and peer experience. This collaboration enables each agent to\nperform saliency-guided masking and share reward-based insights with peers,\nreducing the time required for critical state discovery, improving explanation\nfidelity, and leading to faster and more robust learning. The core novelty of\nour approach lies in generalizing explainability from single-agent to\nmulti-agent systems through a unified mathematical formalism built on\ntrajectory perturbation, reward fidelity analysis, and Kullback-Leibler\ndivergence regularization. This framework yields localized, interpretable\nexplanations grounded in probabilistic modeling and multi-agent Markov decision\nprocesses. We validate our framework on both single-agent and multi-agent\nbenchmarks, including a multi-agent highway driving environment and Google\nResearch Football, demonstrating that MAGIC-MASK consistently outperforms\nstate-of-the-art baselines in fidelity, learning efficiency, and policy\nrobustness while offering interpretable and transferable explanations.", "AI": {"tldr": "\u63d0\u51fa\u4e86MAGIC-MASK\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u6270\u52a8\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u95f4\u534f\u4f5c\u5171\u4eab\u63a9\u7801\u72b6\u6001\u4fe1\u606f\u548c\u7ecf\u9a8c\uff0c\u63d0\u9ad8\u5173\u952e\u72b6\u6001\u53d1\u73b0\u6548\u7387\u548c\u89e3\u91ca\u4fdd\u771f\u5ea6\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u51b3\u7b56\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u5173\u952e\u548c\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u5982StateMask\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u63a2\u7d22\u8986\u76d6\u4e0d\u8db3\u3001\u7f3a\u4e4f\u591a\u667a\u80fd\u4f53\u9002\u5e94\u7b49\u95ee\u9898\u3002", "method": "\u96c6\u6210\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u3001\u81ea\u9002\u5e94epsilon-greedy\u63a2\u7d22\u548c\u8f7b\u91cf\u7ea7\u667a\u80fd\u4f53\u95f4\u534f\u4f5c\uff0c\u8fdb\u884c\u663e\u8457\u6027\u5f15\u5bfc\u7684\u63a9\u7801\u5904\u7406\uff0c\u5171\u4eab\u57fa\u4e8e\u5956\u52b1\u7684\u89c1\u89e3\u3002\u57fa\u4e8e\u8f68\u8ff9\u6270\u52a8\u3001\u5956\u52b1\u4fdd\u771f\u5ea6\u5206\u6790\u548cKL\u6563\u5ea6\u6b63\u5219\u5316\u7684\u7edf\u4e00\u6570\u5b66\u5f62\u5f0f\u5316\u3002", "result": "\u5728\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\uff0c\u5305\u62ec\u591a\u667a\u80fd\u4f53\u9ad8\u901f\u516c\u8def\u9a7e\u9a76\u73af\u5883\u548cGoogle Research Football\uff0c\u5728\u4fdd\u771f\u5ea6\u3001\u5b66\u4e60\u6548\u7387\u548c\u7b56\u7565\u9c81\u68d2\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MAGIC-MASK\u6846\u67b6\u6210\u529f\u5c06\u53ef\u89e3\u91ca\u6027\u4ece\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u63a8\u5e7f\u5230\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u63d0\u4f9b\u57fa\u4e8e\u6982\u7387\u5efa\u6a21\u548c\u591a\u667a\u80fd\u4f53\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u3001\u53ef\u8fc1\u79fb\u7684\u89e3\u91ca\u3002"}}
{"id": "2510.00524", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00524", "abs": "https://arxiv.org/abs/2510.00524", "authors": ["Baoshan Song", "Penggao Yan", "Xiao Xia", "Yihan Zhong", "Weisong Wen", "Li-Ta Hsu"], "title": "Two stage GNSS outlier detection for factor graph optimization based GNSS-RTK/INS/odometer fusion", "comment": null, "summary": "Reliable GNSS positioning in complex environments remains a critical\nchallenge due to non-line-of-sight (NLOS) propagation, multipath effects, and\nfrequent signal blockages. These effects can easily introduce large outliers\ninto the raw pseudo-range measurements, which significantly degrade the\nperformance of global navigation satellite system (GNSS) real-time kinematic\n(RTK) positioning and limit the effectiveness of tightly coupled GNSS-based\nintegrated navigation system. To address this issue, we propose a two-stage\noutlier detection method and apply the method in a tightly coupled GNSS-RTK,\ninertial navigation system (INS), and odometer integration based on factor\ngraph optimization (FGO). In the first stage, Doppler measurements are employed\nto detect pseudo-range outliers in a GNSS-only manner, since Doppler is less\nsensitive to multipath and NLOS effects compared with pseudo-range, making it a\nmore stable reference for detecting sudden inconsistencies. In the second\nstage, pre-integrated inertial measurement units (IMU) and odometer constraints\nare used to generate predicted double-difference pseudo-range measurements,\nwhich enable a more refined identification and rejection of remaining outliers.\nBy combining these two complementary stages, the system achieves improved\nrobustness against both gross pseudo-range errors and degraded satellite\nmeasuring quality. The experimental results demonstrate that the two-stage\ndetection framework significantly reduces the impact of pseudo-range outliers,\nand leads to improved positioning accuracy and consistency compared with\nrepresentative baseline approaches. In the deep urban canyon test, the outlier\nmitigation method has limits the RMSE of GNSS-RTK/INS/odometer fusion from 0.52\nm to 0.30 m, with 42.3% improvement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5f02\u5e38\u503c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347GNSS-RTK/INS/\u91cc\u7a0b\u8ba1\u7d27\u8026\u5408\u7cfb\u7edf\u7684\u5b9a\u4f4d\u6027\u80fd\uff0c\u901a\u8fc7\u591a\u666e\u52d2\u6d4b\u91cf\u548c\u9884\u79ef\u5206\u7ea6\u675f\u6765\u68c0\u6d4b\u548c\u5254\u9664\u4f2a\u8ddd\u5f02\u5e38\u503c\u3002", "motivation": "\u590d\u6742\u73af\u5883\u4e2dGNSS\u5b9a\u4f4d\u9762\u4e34\u975e\u89c6\u8ddd\u4f20\u64ad\u3001\u591a\u5f84\u6548\u5e94\u548c\u4fe1\u53f7\u906e\u6321\u7b49\u6311\u6218\uff0c\u8fd9\u4e9b\u56e0\u7d20\u4f1a\u5728\u4f2a\u8ddd\u6d4b\u91cf\u4e2d\u5f15\u5165\u5927\u5f02\u5e38\u503c\uff0c\u4e25\u91cd\u5f71\u54cdRTK\u5b9a\u4f4d\u548c\u7d27\u8026\u5408\u96c6\u6210\u5bfc\u822a\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5f02\u5e38\u503c\u68c0\u6d4b\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u591a\u666e\u52d2\u6d4b\u91cf\u8fdb\u884cGNSS-only\u5f02\u5e38\u68c0\u6d4b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u9884\u79ef\u5206IMU\u548c\u91cc\u7a0b\u8ba1\u7ea6\u675f\u751f\u6210\u9884\u6d4b\u53cc\u5dee\u4f2a\u8ddd\u6d4b\u91cf\uff0c\u8fdb\u884c\u7cbe\u7ec6\u5316\u5f02\u5e38\u8bc6\u522b\u548c\u5254\u9664\u3002\u57fa\u4e8e\u56e0\u5b50\u56fe\u4f18\u5316\u7684\u7d27\u8026\u5408GNSS-RTK/INS/\u91cc\u7a0b\u8ba1\u96c6\u6210\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u4e24\u9636\u6bb5\u68c0\u6d4b\u6846\u67b6\u663e\u8457\u964d\u4f4e\u4e86\u4f2a\u8ddd\u5f02\u5e38\u503c\u7684\u5f71\u54cd\uff0c\u5728\u6df1\u5ea6\u57ce\u5e02\u5ce1\u8c37\u6d4b\u8bd5\u4e2d\uff0c\u5c06\u878d\u5408\u7cfb\u7edf\u7684RMSE\u4ece0.52\u7c73\u964d\u4f4e\u52300.30\u7c73\uff0c\u63d0\u5347\u4e8642.3%\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u5f02\u5e38\u503c\u68c0\u6d4b\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u590d\u6742\u73af\u5883\u4e0bGNSS\u5b9a\u4f4d\u7684\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u666e\u52d2\u6d4b\u91cf\u548c\u60ef\u6027/\u91cc\u7a0b\u8ba1\u7ea6\u675f\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u5927\u4f2a\u8ddd\u8bef\u5dee\u548c\u536b\u661f\u6d4b\u91cf\u8d28\u91cf\u4e0b\u964d\u95ee\u9898\u3002"}}
{"id": "2510.00984", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00984", "abs": "https://arxiv.org/abs/2510.00984", "authors": ["Lyuzhu Pan", "Hongcai Zhang"], "title": "Real-time Operation of Electric Autonomous Mobility-on-Demand System Considering Power System Regulation", "comment": null, "summary": "Electric autonomous mobility-on-demand (EAMoD) systems are emerging all over\nthe world. However, their potential swarm charging in depots may deteriorate\noperation of the power system, further in turn affecting EAMoD system's optimal\noperation. To prevent this latent risk, we develop a real-time coordination\nframework for the EAMoD system and the power system. First, the\ntemporal-spatial characteristics of EAMoD fleets are fully described based on a\nMarkov decision process model, including serving trips, repositioning, and\ncharging. Second, charger accessibility of EAMoD depot charging is well modeled\nas real-world configuration, wherein fast and slow charge piles are both\nincluded. Third, the power system regulation model provides real-time charging\nregulation constraints for EAMoD systems to prevent potential overload and\nundervoltage. To address the poor solution quality attributed to the complex\ndecision space of the EAMoD system, this paper proposes a piecewise\nlinear-based approximate dynamic programming algorithm combined with model\npredictive control. Numerical experiments in the Manhattan and a 14-node power\ndistribution network validate the effectiveness of the proposed algorithm and\nunderscore the necessity of system coordination.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5b9e\u65f6\u534f\u8c03\u6846\u67b6\u6765\u89e3\u51b3\u7535\u52a8\u81ea\u52a8\u9a7e\u9a76\u6309\u9700\u51fa\u884c\u7cfb\u7edf\u5728\u5145\u7535\u7ad9\u96c6\u4e2d\u5145\u7535\u65f6\u5bf9\u7535\u7f51\u7684\u6f5c\u5728\u8d1f\u9762\u5f71\u54cd\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u8f66\u961f\u65f6\u7a7a\u7279\u6027\uff0c\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5b9e\u73b0\u7cfb\u7edf\u534f\u8c03\u3002", "motivation": "\u7535\u52a8\u81ea\u52a8\u9a7e\u9a76\u6309\u9700\u51fa\u884c\u7cfb\u7edf\u7684\u96c6\u4e2d\u5145\u7535\u53ef\u80fd\u6076\u5316\u7535\u7f51\u8fd0\u884c\uff0c\u8fdb\u800c\u5f71\u54cd\u51fa\u884c\u7cfb\u7edf\u7684\u6700\u4f18\u8fd0\u884c\uff0c\u9700\u8981\u9884\u9632\u8fd9\u79cd\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u8f66\u961f\u65f6\u7a7a\u7279\u6027\uff0c\u5305\u62ec\u670d\u52a1\u884c\u7a0b\u3001\u91cd\u65b0\u5b9a\u4f4d\u548c\u5145\u7535\uff1b\u5efa\u7acb\u5145\u7535\u7ad9\u5145\u7535\u53ef\u53ca\u6027\u6a21\u578b\uff1b\u63d0\u51fa\u5206\u6bb5\u7ebf\u6027\u8fd1\u4f3c\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u3002", "result": "\u5728\u66fc\u54c8\u987f\u548c14\u8282\u70b9\u914d\u7535\u7f51\u7edc\u4e2d\u7684\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u7cfb\u7edf\u534f\u8c03\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u534f\u8c03\u6846\u67b6\u548c\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3EAMoD\u7cfb\u7edf\u96c6\u4e2d\u5145\u7535\u5bf9\u7535\u7f51\u7684\u5f71\u54cd\uff0c\u786e\u4fdd\u4e24\u4e2a\u7cfb\u7edf\u7684\u534f\u8c03\u8fd0\u884c\u3002"}}
{"id": "2510.00300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00300", "abs": "https://arxiv.org/abs/2510.00300", "authors": ["Serena Gomez Wannaz"], "title": "ICL Optimized Fragility", "comment": null, "summary": "ICL guides are known to improve task-specific performance, but their impact\non cross-domain cognitive abilities remains unexplored. This study examines how\nICL guides affect reasoning across different knowledge domains using six\nvariants of the GPT-OSS:20b model: one baseline model and five ICL\nconfigurations (simple, chain-of-thought, random, appended text, and symbolic\nlanguage). The models were subjected to 840 tests spanning general knowledge\nquestions, logic riddles, and a mathematical olympiad problem. Statistical\nanalysis (ANOVA) revealed significant behavioral modifications (p less than\n0.001) across ICL variants, demonstrating a phenomenon termed \"optimized\nfragility.\" ICL models achieved 91%-99% accuracy on general knowledge tasks\nwhile showing degraded performance on complex reasoning problems, with accuracy\ndropping to 10-43% on riddles compared to 43% for the baseline model. Notably,\nno significant differences emerged on the olympiad problem (p=0.2173),\nsuggesting that complex mathematical reasoning remains unaffected by ICL\noptimization. These findings indicate that ICL guides create systematic\ntrade-offs between efficiency and reasoning flexibility, with important\nimplications for LLM deployment and AI safety.", "AI": {"tldr": "ICL\u6307\u5357\u5728\u63d0\u5347\u7279\u5b9a\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u4f1a\u663e\u8457\u5f71\u54cd\u8de8\u9886\u57df\u63a8\u7406\u80fd\u529b\uff0c\u9020\u6210\"\u4f18\u5316\u8106\u5f31\u6027\"\u73b0\u8c61\u2014\u2014\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u4f46\u5728\u590d\u6742\u63a8\u7406\u95ee\u9898\u4e0a\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u63a2\u7d22ICL\u6307\u5357\u5bf9\u8de8\u9886\u57df\u8ba4\u77e5\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5bf9\u63a8\u7406\u7075\u6d3b\u6027\u7684\u7cfb\u7edf\u6027\u5f71\u54cd\u3002", "method": "\u4f7f\u7528GPT-OSS:20b\u6a21\u578b\u76846\u4e2a\u53d8\u4f53\uff081\u4e2a\u57fa\u7ebf+5\u79cdICL\u914d\u7f6e\uff09\uff0c\u5728840\u4e2a\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u901a\u7528\u77e5\u8bc6\u3001\u903b\u8f91\u8c1c\u9898\u548c\u6570\u5b66\u5965\u8d5b\u95ee\u9898\u7684\u8868\u73b0\uff0c\u5e76\u8fdb\u884cANOVA\u7edf\u8ba1\u5206\u6790\u3002", "result": "ICL\u6a21\u578b\u5728\u901a\u7528\u77e5\u8bc6\u4efb\u52a1\u4e0a\u8fbe\u523091%-99%\u51c6\u786e\u7387\uff0c\u4f46\u5728\u903b\u8f91\u8c1c\u9898\u4e0a\u51c6\u786e\u7387\u964d\u81f310-43%\uff08\u57fa\u7ebf\u4e3a43%\uff09\uff0c\u6570\u5b66\u5965\u8d5b\u95ee\u9898\u65e0\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "ICL\u6307\u5357\u5728\u6548\u7387\u548c\u63a8\u7406\u7075\u6d3b\u6027\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u6743\u8861\uff0c\u5bf9LLM\u90e8\u7f72\u548cAI\u5b89\u5168\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2510.00573", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00573", "abs": "https://arxiv.org/abs/2510.00573", "authors": ["Yen-Ling Tai", "Yi-Ru Yang", "Kuan-Ting Yu", "Yu-Wei Chao", "Yi-Ting Chen"], "title": "GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks", "comment": null, "summary": "Robotic food scooping is a critical manipulation skill for food preparation\nand service robots. However, existing robot learning algorithms, especially\nlearn-from-demonstration methods, still struggle to handle diverse and dynamic\nfood states, which often results in spillage and reduced reliability. In this\nwork, we introduce GRITS: A Spillage-Aware Guided Diffusion Policy for Robot\nFood Scooping Tasks. This framework leverages guided diffusion policy to\nminimize food spillage during scooping and to ensure reliable transfer of food\nitems from the initial to the target location. Specifically, we design a\nspillage predictor that estimates the probability of spillage given current\nobservation and action rollout. The predictor is trained on a simulated dataset\nwith food spillage scenarios, constructed from four primitive shapes (spheres,\ncubes, cones, and cylinders) with varied physical properties such as mass,\nfriction, and particle size. At inference time, the predictor serves as a\ndifferentiable guidance signal, steering the diffusion sampling process toward\nsafer trajectories while preserving task success. We validate GRITS on a\nreal-world robotic food scooping platform. GRITS is trained on six food\ncategories and evaluated on ten unseen categories with different shapes and\nquantities. GRITS achieves an 82% task success rate and a 4% spillage rate,\nreducing spillage by over 40% compared to baselines without guidance, thereby\ndemonstrating its effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e86GRITS\u6846\u67b6\uff0c\u4e00\u79cd\u57fa\u4e8e\u5f15\u5bfc\u6269\u6563\u7b56\u7565\u7684\u673a\u5668\u4eba\u8200\u53d6\u98df\u7269\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u6ea2\u51fa\u6982\u7387\u6765\u6307\u5bfc\u52a8\u4f5c\u751f\u6210\uff0c\u663e\u8457\u51cf\u5c11\u98df\u7269\u6ea2\u51fa\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u5b66\u4e60\u7b97\u6cd5\u5728\u5904\u7406\u591a\u6837\u5316\u548c\u52a8\u6001\u53d8\u5316\u7684\u98df\u7269\u72b6\u6001\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u5bfc\u81f4\u98df\u7269\u6ea2\u51fa\u548c\u53ef\u9760\u6027\u964d\u4f4e\u3002", "method": "\u8bbe\u8ba1\u4e86\u6ea2\u51fa\u9884\u6d4b\u5668\u6765\u4f30\u8ba1\u7ed9\u5b9a\u89c2\u5bdf\u548c\u52a8\u4f5c\u5e8f\u5217\u4e0b\u7684\u6ea2\u51fa\u6982\u7387\uff0c\u5728\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u4f5c\u4e3a\u53ef\u5fae\u5f15\u5bfc\u4fe1\u53f7\u6307\u5bfc\u6269\u6563\u91c7\u6837\u8fc7\u7a0b\u3002", "result": "\u5728\u771f\u5b9e\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u572810\u4e2a\u672a\u89c1\u8fc7\u7684\u98df\u7269\u7c7b\u522b\u4e0a\u8fbe\u523082%\u7684\u4efb\u52a1\u6210\u529f\u7387\u548c4%\u7684\u6ea2\u51fa\u7387\uff0c\u76f8\u6bd4\u65e0\u5f15\u5bfc\u57fa\u7ebf\u51cf\u5c1140%\u4ee5\u4e0a\u7684\u6ea2\u51fa\u3002", "conclusion": "GRITS\u6846\u67b6\u901a\u8fc7\u5f15\u5bfc\u6269\u6563\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u98df\u7269\u8200\u53d6\u4e2d\u7684\u6ea2\u51fa\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.00992", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.00992", "abs": "https://arxiv.org/abs/2510.00992", "authors": ["Lyuzhu Pan", "Hongcai Zhang"], "title": "Optimal Pricing of Electric Vehicle Charging on Coupled Power-Transportation Network based on Generalized Sensitivity Analysis", "comment": null, "summary": "In the last decade, charging service providers are emerging along with the\nprevalence of electric vehicles. These providers need to strategically optimize\ntheir charging prices to improve the profits considering operation conditions\nof the coupled power-transportation network. However, the optimal pricing\nproblem generally involves the user equilibrium model, which leads to a\nmathematical program with equilibrium constraints. As a result, the pricing\nproblem is non-convex and computationally intractable especially for\nlarge-scale network. To address this challenge, we propose a generalized\nsensitivity analysis approach for optimal pricing of electric vehicle charging\non coupled power-transportation network. Specifically, we adopt a sensitivity\nanalysis to capture the best response of charging demand to charging price in\nthe gradient form. Consequently, charging service providers can make pricing\ndecisions based on the gradient information instead of the conventional KKT\nconditions of the user equilibrium model. We then propose a tailored gradient\ndescent algorithm to solve the whole pricing problem. The mathematical proof of\nvalidity is given and the time complexity of the proposed algorithm is\ntheoretically polynomial. Numerical experiments on different scales of networks\nverify the computational efficiency of the proposed algorithm, indicating its\npotential in evaluating the impact of the optimal pricing on the operational\nperformance of large-scale coupled power-transportation network.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49\u7075\u654f\u5ea6\u5206\u6790\u7684\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u6700\u4f18\u5b9a\u4ef7\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u4fe1\u606f\u66ff\u4ee3\u4f20\u7edfKKT\u6761\u4ef6\uff0c\u89e3\u51b3\u8026\u5408\u7535\u529b-\u4ea4\u901a\u7f51\u7edc\u4e2d\u7684\u975e\u51f8\u5b9a\u4ef7\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u666e\u53ca\uff0c\u5145\u7535\u670d\u52a1\u63d0\u4f9b\u5546\u9700\u8981\u5728\u8003\u8651\u8026\u5408\u7535\u529b-\u4ea4\u901a\u7f51\u7edc\u8fd0\u884c\u6761\u4ef6\u4e0b\u4f18\u5316\u5145\u7535\u4ef7\u683c\u4ee5\u63d0\u9ad8\u5229\u6da6\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u6d89\u53ca\u7528\u6237\u5747\u8861\u6a21\u578b\u5bfc\u81f4\u975e\u51f8\u4e14\u8ba1\u7b97\u56f0\u96be\u3002", "method": "\u91c7\u7528\u7075\u654f\u5ea6\u5206\u6790\u6355\u6349\u5145\u7535\u9700\u6c42\u5bf9\u4ef7\u683c\u7684\u6700\u4f73\u54cd\u5e94\u68af\u5ea6\uff0c\u63d0\u51fa\u5b9a\u5236\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff0c\u6570\u5b66\u8bc1\u660e\u6709\u6548\u6027\u4e14\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a\u591a\u9879\u5f0f\u3002", "result": "\u5728\u4e0d\u540c\u89c4\u6a21\u7f51\u7edc\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u8868\u660e\u5176\u5728\u5927\u89c4\u6a21\u8026\u5408\u7f51\u7edc\u8fd0\u884c\u6027\u80fd\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5e7f\u4e49\u7075\u654f\u5ea6\u5206\u6790\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21\u8026\u5408\u7535\u529b-\u4ea4\u901a\u7f51\u7edc\u4e2d\u7684\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u6700\u4f18\u5b9a\u4ef7\u95ee\u9898\uff0c\u5177\u6709\u8ba1\u7b97\u6548\u7387\u548c\u5b9e\u7528\u6027\u4f18\u52bf\u3002"}}
{"id": "2510.00307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00307", "abs": "https://arxiv.org/abs/2510.00307", "authors": ["Thierry Blankenstein", "Jialin Yu", "Zixuan Li", "Vassilis Plachouras", "Sunando Sengupta", "Philip Torr", "Yarin Gal", "Alasdair Paren", "Adel Bibi"], "title": "BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models", "comment": null, "summary": "Agents backed by large language models (LLMs) often rely on external tools\ndrawn from marketplaces where multiple providers offer functionally equivalent\noptions. This raises a critical point concerning fairness: if selection is\nsystematically biased, it can degrade user experience and distort competition\nby privileging some providers over others. We introduce a benchmark of diverse\ntool categories, each containing multiple functionally equivalent tools, to\nevaluate tool-selection bias. Using this benchmark, we test seven models and\nshow that unfairness exists with models either fixating on a single provider or\ndisproportionately preferring earlier-listed tools in context. To investigate\nthe origins of this bias, we conduct controlled experiments examining tool\nfeatures, metadata (name, description, parameters), and pre-training exposure.\nWe find that: (1) semantic alignment between queries and metadata is the\nstrongest predictor of choice; (2) perturbing descriptions significantly shifts\nselections; and (3) repeated pre-training exposure to a single endpoint\namplifies bias. Finally, we propose a lightweight mitigation that first filters\nthe candidate tools to a relevant subset and then samples uniformly, reducing\nbias while preserving good task coverage. Our findings highlight tool-selection\nbias as a key obstacle for the fair deployment of tool-augmented LLMs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLM\u4ee3\u7406\u5728\u5de5\u5177\u9009\u62e9\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u5de5\u5177\u9009\u62e9\u504f\u89c1\u7684\u57fa\u51c6\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u56fa\u5b9a\u9009\u62e9\u5355\u4e00\u63d0\u4f9b\u5546\u6216\u504f\u597d\u5217\u8868\u4e2d\u9760\u524d\u5de5\u5177\u7684\u4e0d\u516c\u5e73\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u8f7b\u91cf\u7ea7\u7f13\u89e3\u65b9\u6cd5\u3002", "motivation": "LLM\u4ee3\u7406\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\u5e02\u573a\uff0c\u4f46\u5de5\u5177\u9009\u62e9\u5982\u679c\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u4f1a\u964d\u4f4e\u7528\u6237\u4f53\u9a8c\u5e76\u626d\u66f2\u7ade\u4e89\uff0c\u9700\u8981\u7814\u7a76\u5de5\u5177\u9009\u62e9\u504f\u89c1\u7684\u8bc4\u4f30\u548c\u7f13\u89e3\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u5305\u542b\u591a\u4e2a\u529f\u80fd\u7b49\u6548\u5de5\u5177\u7684\u591a\u6837\u5316\u5de5\u5177\u7c7b\u522b\u57fa\u51c6\uff0c\u6d4b\u8bd57\u4e2a\u6a21\u578b\uff0c\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u7814\u7a76\u5de5\u5177\u7279\u5f81\u3001\u5143\u6570\u636e\u548c\u9884\u8bad\u7ec3\u66b4\u9732\u5bf9\u504f\u89c1\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u76f8\u5173\u5de5\u5177\u5b50\u96c6\u8fc7\u6ee4\u548c\u5747\u5300\u91c7\u6837\u7684\u7f13\u89e3\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u8bed\u4e49\u5bf9\u9f50\u662f\u9009\u62e9\u7684\u6700\u5f3a\u9884\u6d4b\u56e0\u7d20\uff0c\u6270\u52a8\u63cf\u8ff0\u4f1a\u663e\u8457\u6539\u53d8\u9009\u62e9\uff0c\u91cd\u590d\u9884\u8bad\u7ec3\u66b4\u9732\u4f1a\u653e\u5927\u504f\u89c1\uff0c\u63d0\u51fa\u7684\u7f13\u89e3\u65b9\u6cd5\u80fd\u51cf\u5c11\u504f\u89c1\u540c\u65f6\u4fdd\u6301\u826f\u597d\u4efb\u52a1\u8986\u76d6\u7387\u3002", "conclusion": "\u5de5\u5177\u9009\u62e9\u504f\u89c1\u662f\u5de5\u5177\u589e\u5f3aLLM\u516c\u5e73\u90e8\u7f72\u7684\u5173\u952e\u969c\u788d\uff0c\u9700\u8981\u5173\u6ce8\u548c\u89e3\u51b3\u3002"}}
{"id": "2510.00600", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00600", "abs": "https://arxiv.org/abs/2510.00600", "authors": ["Pietro Mazzaglia", "Cansu Sancaktar", "Markus Peschl", "Daniel Dijkman"], "title": "Hybrid Training for Vision-Language-Action Models", "comment": null, "summary": "Using Large Language Models to produce intermediate thoughts, a.k.a.\nChain-of-thought (CoT), before providing an answer has been a successful recipe\nfor solving complex language tasks. In robotics, similar embodied CoT\nstrategies, generating thoughts before actions, have also been shown to lead to\nimproved performance when using Vision-Language-Action models (VLAs). As these\ntechniques increase the length of the model's generated outputs to include the\nthoughts, the inference time is negatively affected. Delaying an agent's\nactions in real-world executions, as in robotic manipulation settings, strongly\naffects the usability of a method, as tasks require long sequences of actions.\nHowever, is the generation of long chains-of-thought a strong prerequisite for\nachieving performance improvements? In this work, we explore the idea of Hybrid\nTraining (HyT), a framework that enables VLAs to learn from thoughts and\nbenefit from the associated performance gains, while enabling the possibility\nto leave out CoT generation during inference. Furthermore, by learning to\nconditionally predict a diverse set of outputs, HyT supports flexibility at\ninference time, enabling the model to either predict actions directly, generate\nthoughts or follow instructions. We evaluate the proposed method in a series of\nsimulated benchmarks and real-world experiments.", "AI": {"tldr": "\u63d0\u51faHybrid Training (HyT)\u6846\u67b6\uff0c\u8ba9\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u5b66\u4e60\u601d\u7ef4\u94fe\uff0c\u4f46\u5728\u63a8\u7406\u65f6\u53ef\u9009\u62e9\u8df3\u8fc7\u601d\u7ef4\u751f\u6210\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u601d\u7ef4\u94fe(CoT)\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u4f1a\u663e\u8457\u589e\u52a0\u63a8\u7406\u65f6\u95f4\uff0c\u8fd9\u5728\u9700\u8981\u5b9e\u65f6\u52a8\u4f5c\u7684\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5f71\u54cd\u53ef\u7528\u6027\u3002\u7814\u7a76\u662f\u5426\u5fc5\u987b\u751f\u6210\u957f\u601d\u7ef4\u94fe\u624d\u80fd\u83b7\u5f97\u6027\u80fd\u63d0\u5347\u3002", "method": "HyT\u6846\u67b6\uff1a\u5728\u8bad\u7ec3\u65f6\u8ba9\u6a21\u578b\u5b66\u4e60\u601d\u7ef4\u94fe\uff0c\u4f46\u5728\u63a8\u7406\u65f6\u53ef\u9009\u62e9\u76f4\u63a5\u751f\u6210\u52a8\u4f5c\u800c\u8df3\u8fc7\u601d\u7ef4\u751f\u6210\u3002\u652f\u6301\u6761\u4ef6\u5316\u9884\u6d4b\u591a\u79cd\u8f93\u51fa\uff0c\u63d0\u4f9b\u63a8\u7406\u65f6\u7684\u7075\u6d3b\u6027\u3002", "result": "\u5728\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "HyT\u6846\u67b6\u4f7fVLAs\u80fd\u591f\u4ece\u601d\u7ef4\u94fe\u5b66\u4e60\u4e2d\u83b7\u76ca\uff0c\u540c\u65f6\u5141\u8bb8\u5728\u63a8\u7406\u65f6\u8df3\u8fc7\u601d\u7ef4\u751f\u6210\uff0c\u5b9e\u73b0\u6027\u80fd\u4e0e\u6548\u7387\u7684\u5e73\u8861\uff0c\u5e76\u652f\u6301\u7075\u6d3b\u7684\u63a8\u7406\u6a21\u5f0f\u3002"}}
{"id": "2510.01007", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.01007", "abs": "https://arxiv.org/abs/2510.01007", "authors": ["Jinfeng Chen", "Zhiqiang Gao", "Qin Lin"], "title": "A Model-Based Extended State Observer for Discrete-Time Linear Multivariable Systems", "comment": null, "summary": "A model-based extended state observer (MB-ESO) and its variant are proposed\nfor discrete-time linear multivariable systems, where multiple disturbances are\ndefined as an extended state vector in the same manner as in the original\nformulation of ESO. The variant MB-ESO extends the MB-ESO to address cases\nwhere the disturbance gain matrix is non-diagonal. Leveraging the connection\nbetween the variant MB-ESO and the well-known unknown input observer (UIO), the\ncondition for the existence of a MB-ESO and its variant in multivariable\nsystems is established, for the first time, i.e., no invariant zeros exist\nbetween the disturbances and the plant outputs. It is shown that, with the\nobserver eigenvalues all placed at the origin and the subsystems decoupled, the\nvariant MB-ESO produces the identical disturbance estimation as that of UIO.\nMoreover, the error characteristics of MB-ESO and its variant are analyzed and\nthe transfer functions associated with the disturbance estimation errors are\nderived. It is demonstrated both mathematically and in simulations that the\ndisturbance estimation error of MB-ESO decreases monotonically with respect to\nboth the observer eigenvalues and time.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u6269\u5c55\u72b6\u6001\u89c2\u6d4b\u5668\u53ca\u5176\u53d8\u4f53\uff0c\u7528\u4e8e\u79bb\u6563\u65f6\u95f4\u7ebf\u6027\u591a\u53d8\u91cf\u7cfb\u7edf\uff0c\u5efa\u7acb\u4e86\u5b58\u5728\u6027\u6761\u4ef6\uff0c\u5e76\u5206\u6790\u4e86\u8bef\u5dee\u7279\u6027\u3002", "motivation": "\u9488\u5bf9\u591a\u53d8\u91cf\u7cfb\u7edf\u4e2d\u591a\u6270\u52a8\u4f30\u8ba1\u95ee\u9898\uff0c\u6269\u5c55\u4f20\u7edfESO\u65b9\u6cd5\u4ee5\u5904\u7406\u975e\u5bf9\u89d2\u6270\u52a8\u589e\u76ca\u77e9\u9635\u7684\u60c5\u51b5\u3002", "method": "\u5c06\u591a\u6270\u52a8\u5b9a\u4e49\u4e3a\u6269\u5c55\u72b6\u6001\u5411\u91cf\uff0c\u63d0\u51faMB-ESO\u53ca\u5176\u53d8\u4f53\uff0c\u5229\u7528\u4e0e\u672a\u77e5\u8f93\u5165\u89c2\u6d4b\u5668\u7684\u8054\u7cfb\u5efa\u7acb\u5b58\u5728\u6027\u6761\u4ef6\uff0c\u5206\u6790\u8bef\u5dee\u4f20\u9012\u51fd\u6570\u3002", "result": "\u5f53\u89c2\u6d4b\u5668\u7279\u5f81\u503c\u7f6e\u4e8e\u539f\u70b9\u4e14\u5b50\u7cfb\u7edf\u89e3\u8026\u65f6\uff0c\u53d8\u4f53MB-ESO\u4e0eUIO\u4ea7\u751f\u76f8\u540c\u7684\u6270\u52a8\u4f30\u8ba1\uff1b\u6270\u52a8\u4f30\u8ba1\u8bef\u5dee\u968f\u89c2\u6d4b\u5668\u7279\u5f81\u503c\u548c\u65f6\u95f4\u5355\u8c03\u51cf\u5c0f\u3002", "conclusion": "MB-ESO\u53ca\u5176\u53d8\u4f53\u4e3a\u591a\u53d8\u91cf\u7cfb\u7edf\u6270\u52a8\u4f30\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u660e\u786e\u7684\u5b58\u5728\u6027\u6761\u4ef6\u548c\u8bef\u5dee\u7279\u6027\u5206\u6790\u3002"}}
{"id": "2510.00332", "categories": ["cs.AI", "cs.CE", "I.6.4; I.2.1"], "pdf": "https://arxiv.org/pdf/2510.00332", "abs": "https://arxiv.org/abs/2510.00332", "authors": ["Zeshi Dai", "Zimo Peng", "Zerui Cheng", "Ryan Yihe Li"], "title": "When Hallucination Costs Millions: Benchmarking AI Agents in High-Stakes Adversarial Financial Markets", "comment": "15 pages, 5 figures, 4 tables; In submission to ICLR 2026", "summary": "We present CAIA, a benchmark exposing a critical blind spot in AI evaluation:\nthe inability of state-of-the-art models to operate in adversarial, high-stakes\nenvironments where misinformation is weaponized and errors are irreversible.\nWhile existing benchmarks measure task completion in controlled settings,\nreal-world deployment demands resilience against active deception. Using crypto\nmarkets as a testbed where $30 billion was lost to exploits in 2024, we\nevaluate 17 models on 178 time-anchored tasks requiring agents to distinguish\ntruth from manipulation, navigate fragmented information landscapes, and make\nirreversible financial decisions under adversarial pressure.\n  Our results reveal a fundamental capability gap: without tools, even frontier\nmodels achieve only 28% accuracy on tasks junior analysts routinely handle.\nTool augmentation improves performance but plateaus at 67.4% versus 80% human\nbaseline, despite unlimited access to professional resources. Most critically,\nwe uncover a systematic tool selection catastrophe: models preferentially\nchoose unreliable web search over authoritative data, falling for SEO-optimized\nmisinformation and social media manipulation. This behavior persists even when\ncorrect answers are directly accessible through specialized tools, suggesting\nfoundational limitations rather than knowledge gaps. We also find that Pass@k\nmetrics mask dangerous trial-and-error behavior for autonomous deployment.\n  The implications extend beyond crypto to any domain with active adversaries,\ne.g. cybersecurity, content moderation, etc. We release CAIA with contamination\ncontrols and continuous updates, establishing adversarial robustness as a\nnecessary condition for trustworthy AI autonomy. The benchmark reveals that\ncurrent models, despite impressive reasoning scores, remain fundamentally\nunprepared for environments where intelligence must survive active opposition.", "AI": {"tldr": "CAIA\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793aAI\u5728\u5bf9\u6297\u6027\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u4e25\u91cd\u7f3a\u9677\uff1a\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u4e3b\u52a8\u6b3a\u9a97\uff0c\u5728\u52a0\u5bc6\u5e02\u573a\u7b49\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5de5\u5177\u589e\u5f3a\u6548\u679c\u6709\u9650\u4e14\u5b58\u5728\u7cfb\u7edf\u6027\u5de5\u5177\u9009\u62e9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709AI\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u53d7\u63a7\u73af\u5883\u4e0b\u7684\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\uff0c\u4f46\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u9700\u8981AI\u5177\u5907\u5bf9\u6297\u4e3b\u52a8\u6b3a\u9a97\u7684\u97e7\u6027\u3002\u52a0\u5bc6\u5e02\u573a2024\u5e74\u56e0\u6f0f\u6d1e\u635f\u5931300\u4ebf\u7f8e\u5143\uff0c\u662f\u6d4b\u8bd5AI\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u80fd\u529b\u7684\u7406\u60f3\u573a\u666f\u3002", "method": "\u4f7f\u7528\u52a0\u5bc6\u5e02\u573a\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u8bc4\u4f3017\u4e2a\u6a21\u578b\u5728178\u4e2a\u65f6\u95f4\u951a\u5b9a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u8fd9\u4e9b\u4efb\u52a1\u8981\u6c42AI\u533a\u5206\u771f\u76f8\u4e0e\u64cd\u7eb5\u3001\u5bfc\u822a\u788e\u7247\u5316\u4fe1\u606f\u73af\u5883\u3001\u5728\u5bf9\u6297\u538b\u529b\u4e0b\u505a\u51fa\u4e0d\u53ef\u9006\u7684\u91d1\u878d\u51b3\u7b56\u3002", "result": "\u65e0\u5de5\u5177\u65f6\u524d\u6cbf\u6a21\u578b\u51c6\u786e\u7387\u4ec528%\uff0c\u5de5\u5177\u589e\u5f3a\u540e\u63d0\u5347\u81f367.4%\uff0c\u4f46\u4ecd\u4f4e\u4e8e\u4eba\u7c7b\u57fa\u51c680%\u3002\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u5de5\u5177\u9009\u62e9\u95ee\u9898\uff1a\u504f\u597d\u4e0d\u53ef\u9760\u7684\u7f51\u9875\u641c\u7d22\u800c\u975e\u6743\u5a01\u6570\u636e\u6e90\uff0c\u5bb9\u6613\u843d\u5165SEO\u4f18\u5316\u7684\u865a\u5047\u4fe1\u606f\u548c\u793e\u4ea4\u5a92\u4f53\u64cd\u7eb5\u9677\u9631\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u5c3d\u7ba1\u5728\u63a8\u7406\u5f97\u5206\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u9700\u8981\u5bf9\u6297\u4e3b\u52a8\u53cd\u5bf9\u7684\u73af\u5883\u4e2d\u4ecd\u5b58\u5728\u6839\u672c\u6027\u4e0d\u8db3\u3002\u5bf9\u6297\u6027\u9c81\u68d2\u6027\u662f\u53ef\u4fe1AI\u81ea\u4e3b\u6027\u7684\u5fc5\u8981\u6761\u4ef6\uff0cCAIA\u57fa\u51c6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6301\u7eed\u66f4\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2510.00619", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00619", "abs": "https://arxiv.org/abs/2510.00619", "authors": ["Michiel Braat", "Maren Buermann", "Marijke van Weperen", "Jan-Pieter Paardekooper"], "title": "What Did I Learn? Operational Competence Assessment for AI-Based Trajectory Planners", "comment": "Accepted for publication in proceedings of the 2025 IEEE\n  International Automated Vehicle Validation Conference", "summary": "Automated driving functions increasingly rely on machine learning for tasks\nlike perception and trajectory planning, requiring large, relevant datasets.\nThe performance of these algorithms depends on how closely the training data\nmatches the task. To ensure reliable functioning, it is crucial to know what is\nincluded in the dataset to assess the trained model's operational risk. We aim\nto enhance the safe use of machine learning in automated driving by developing\na method to recognize situations that an automated vehicle has not been\nsufficiently trained on. This method also improves explainability by describing\nthe dataset at a human-understandable level. We propose modeling driving data\nas knowledge graphs, representing driving scenes with entities and their\nrelationships. These graphs are queried for specific sub-scene configurations\nto check their occurrence in the dataset. We estimate a vehicle's competence in\na driving scene by considering the coverage and complexity of sub-scene\nconfigurations in the training set. Higher complexity scenes require greater\ncoverage for high competence. We apply this method to the NuPlan dataset,\nmodeling it with knowledge graphs and analyzing the coverage of specific\ndriving scenes. This approach helps monitor the competence of machine learning\nmodels trained on the dataset, which is essential for trustworthy AI to be\ndeployed in automated driving.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u672a\u5145\u5206\u8bad\u7ec3\u7684\u573a\u666f\uff0c\u901a\u8fc7\u5206\u6790\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5b50\u573a\u666f\u8986\u76d6\u60c5\u51b5\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u7279\u5b9a\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u8d8a\u6765\u8d8a\u4f9d\u8d56\u673a\u5668\u5b66\u4e60\uff0c\u4f46\u6a21\u578b\u6027\u80fd\u53d6\u51b3\u4e8e\u8bad\u7ec3\u6570\u636e\u4e0e\u4efb\u52a1\u7684\u5339\u914d\u7a0b\u5ea6\u3002\u4e3a\u4e86\u786e\u4fdd\u53ef\u9760\u8fd0\u884c\uff0c\u9700\u8981\u4e86\u89e3\u6570\u636e\u96c6\u4e2d\u5305\u542b\u7684\u5185\u5bb9\u4ee5\u8bc4\u4f30\u8bad\u7ec3\u6a21\u578b\u7684\u8fd0\u884c\u98ce\u9669\u3002", "method": "\u5c06\u9a7e\u9a76\u6570\u636e\u5efa\u6a21\u4e3a\u77e5\u8bc6\u56fe\u8c31\uff0c\u8868\u793a\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u5b9e\u4f53\u53ca\u5176\u5173\u7cfb\u3002\u901a\u8fc7\u67e5\u8be2\u7279\u5b9a\u7684\u5b50\u573a\u666f\u914d\u7f6e\u6765\u68c0\u67e5\u5176\u5728\u6570\u636e\u96c6\u4e2d\u7684\u51fa\u73b0\u60c5\u51b5\uff0c\u5e76\u6839\u636e\u8bad\u7ec3\u96c6\u4e2d\u5b50\u573a\u666f\u914d\u7f6e\u7684\u8986\u76d6\u7387\u548c\u590d\u6742\u6027\u6765\u4f30\u8ba1\u8f66\u8f86\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u80fd\u529b\u3002", "result": "\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8eNuPlan\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u5efa\u6a21\u5e76\u5206\u6790\u7279\u5b9a\u9a7e\u9a76\u573a\u666f\u7684\u8986\u76d6\u60c5\u51b5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u66f4\u590d\u6742\u7684\u573a\u666f\u9700\u8981\u66f4\u5927\u7684\u8986\u76d6\u8303\u56f4\u624d\u80fd\u83b7\u5f97\u9ad8\u80fd\u529b\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u6709\u52a9\u4e8e\u76d1\u63a7\u57fa\u4e8e\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u80fd\u529b\uff0c\u8fd9\u5bf9\u4e8e\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u90e8\u7f72\u53ef\u4fe1AI\u81f3\u5173\u91cd\u8981\uff0c\u540c\u65f6\u901a\u8fc7\u4ee5\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u6c34\u5e73\u63cf\u8ff0\u6570\u636e\u96c6\u6765\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.01044", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.01044", "abs": "https://arxiv.org/abs/2510.01044", "authors": ["Junfeng Cai", "Marco Lovera"], "title": "Gain-Scheduled Passive Fault-Tolerant Control Design for Dual-System UAV Transition Flight", "comment": "25 pages", "summary": "Dual-system UAVs with vertical take-off and landing capabilities have become\nincreasingly popular in recent years. As a safety-critical system, it is\nimportant that a dual-system UAV can maintain safe flight after faults/failures\noccur. This paper proposes a gain-scheduled passive fault-tolerant control\n(PFTC) method for the transition flight of dual-system UAVs. In this novel FTC\ndesign method, the model uncertainties arising from the loss of control\neffectiveness caused by actuator faults/failures, for the first time, are\ntreated as model input uncertainty, allowing us to use multiplicative\nuncertainty descriptions to represent it. The advantages of the proposed method\nconsist in significantly reducing the number of design points, thereby\nsimplifying the control synthesis process and improving the efficiency of\ndesigning the FTC system for dual-system UAV transition flight compared with\nthe existing FTC design methods. As a general method, it can be applied to the\ndesign of FTC systems with multiple uncertain parameters and multiple channels.\nThe developed passive FTC system is validated on a nonlinear\nsix-degree-of-freedom simulator. The simulation results demonstrate that the\ngain-scheduled structured H infinity (GS SHIF) PFTC system provides superior\nfault tolerance performance compared with the LQR and structured H infinity\ncontrol systems, thereby showcasing the effectiveness and the advantages of the\nproposed GS SHIF PFTC approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u53cc\u7cfb\u7edf\u65e0\u4eba\u673a\u8fc7\u6e21\u98de\u884c\u7684\u589e\u76ca\u8c03\u5ea6\u88ab\u52a8\u5bb9\u9519\u63a7\u5236\u65b9\u6cd5\uff0c\u5c06\u6267\u884c\u5668\u6545\u969c\u5f15\u8d77\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u89c6\u4e3a\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u51cf\u5c11\u8bbe\u8ba1\u70b9\u6570\u91cf\uff0c\u7b80\u5316\u63a7\u5236\u7efc\u5408\u8fc7\u7a0b\u3002", "motivation": "\u53cc\u7cfb\u7edf\u65e0\u4eba\u673a\u4f5c\u4e3a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\uff0c\u9700\u8981\u5728\u53d1\u751f\u6545\u969c\u540e\u4fdd\u6301\u5b89\u5168\u98de\u884c\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u5bb9\u9519\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u589e\u76ca\u8c03\u5ea6\u7ed3\u6784\u5316H\u65e0\u7a77\u88ab\u52a8\u5bb9\u9519\u63a7\u5236\u65b9\u6cd5\uff0c\u5c06\u6267\u884c\u5668\u6545\u969c\u5f15\u8d77\u7684\u63a7\u5236\u6548\u80fd\u635f\u5931\u5efa\u6a21\u4e3a\u6a21\u578b\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u7528\u4e58\u6cd5\u4e0d\u786e\u5b9a\u6027\u63cf\u8ff0\u3002", "result": "\u5728\u975e\u7ebf\u6027\u516d\u81ea\u7531\u5ea6\u6a21\u62df\u5668\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4LQR\u548c\u7ed3\u6784\u5316H\u65e0\u7a77\u63a7\u5236\u7cfb\u7edf\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u5bb9\u9519\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u7b80\u5316\u53cc\u7cfb\u7edf\u65e0\u4eba\u673a\u8fc7\u6e21\u98de\u884c\u5bb9\u9519\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u8bbe\u8ba1\u6548\u7387\uff0c\u5e76\u5c55\u793a\u51fa\u4f18\u5f02\u7684\u5bb9\u9519\u6027\u80fd\u3002"}}
{"id": "2510.00355", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00355", "abs": "https://arxiv.org/abs/2510.00355", "authors": ["Renee Ge", "Qianli Liao", "Tomaso Poggio"], "title": "Hierarchical Reasoning Model: A Critical Supplementary Material", "comment": "Preprint, Under review", "summary": "Transformers have demonstrated remarkable performance in natural language\nprocessing and related domains, as they largely focus on sequential,\nautoregressive next-token prediction tasks. Yet, they struggle in logical\nreasoning, not necessarily because of a fundamental limitation of these models,\nbut possibly due to the lack of exploration of more creative uses, such as\nlatent space and recurrent reasoning. An emerging exploration in this direction\nis the Hierarchical Reasoning Model (Wang et al., 2025), which introduces a\nnovel type of recurrent reasoning in the latent space of transformers,\nachieving remarkable performance on a wide range of 2D reasoning tasks. Despite\nthe promising results, this line of models is still at an early stage and calls\nfor in-depth investigation. In this work, we perform a critical review on this\nclass of models, examine key design choices and present intriguing variants\nthat achieve significantly better performance on the Sudoku-Extreme and\nMaze-Hard tasks than previously reported. Our results also raise surprising\nobservations and intriguing directions for further research.", "AI": {"tldr": "\u5bf9Transformer\u5728\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u8fdb\u884c\u5206\u6790\uff0c\u63d0\u51fa\u57fa\u4e8e\u6f5c\u5728\u7a7a\u95f4\u548c\u5faa\u73af\u63a8\u7406\u7684\u5c42\u6b21\u63a8\u7406\u6a21\u578b\u53d8\u4f53\uff0c\u5728\u6570\u72ec\u548c\u8ff7\u5bab\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347", "motivation": "Transformer\u5728\u5e8f\u5217\u81ea\u56de\u5f52\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u903b\u8f91\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u8fd9\u53ef\u80fd\u662f\u7531\u4e8e\u7f3a\u4e4f\u5bf9\u6f5c\u5728\u7a7a\u95f4\u548c\u5faa\u73af\u63a8\u7406\u7b49\u521b\u9020\u6027\u5e94\u7528\u7684\u63a2\u7d22", "method": "\u5bf9\u5c42\u6b21\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u6279\u5224\u6027\u56de\u987e\uff0c\u68c0\u67e5\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff0c\u5e76\u63d0\u51fa\u5728Transformer\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u5faa\u73af\u63a8\u7406\u7684\u53d8\u4f53\u6a21\u578b", "result": "\u5728Sudoku-Extreme\u548cMaze-Hard\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6bd4\u5148\u524d\u62a5\u544a\u663e\u8457\u66f4\u597d\u7684\u6027\u80fd", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63d0\u51fa\u4e86\u4ee4\u4eba\u60ca\u8bb6\u7684\u89c2\u5bdf\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u5f15\u4eba\u5165\u80dc\u65b9\u5411\uff0c\u8868\u660e\u8fd9\u7c7b\u6a21\u578b\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u9700\u8981\u6df1\u5165\u63a2\u7d22"}}
{"id": "2510.00630", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00630", "abs": "https://arxiv.org/abs/2510.00630", "authors": ["Federico Oliva", "Tom Shaked", "Daniele Carnevale", "Amir Degani"], "title": "Trajectory Based Observer Design: A Framework for Lightweight Sensor Fusion", "comment": null, "summary": "Efficient observer design and accurate sensor fusion are key in state\nestimation. This work proposes an optimization-based methodology, termed\nTrajectory Based Optimization Design (TBOD), allowing the user to easily design\nobservers for general nonlinear systems and multi-sensor setups. Starting from\nparametrized observer dynamics, the proposed method considers a finite set of\npre-recorded measurement trajectories from the nominal plant and exploits them\nto tune the observer parameters through numerical optimization. This research\nhinges on the classic observer's theory and Moving Horizon Estimators\nmethodology. Optimization is exploited to ease the observer's design, providing\nthe user with a lightweight, general-purpose sensor fusion methodology. TBOD's\nmain characteristics are the capability to handle general sensors efficiently\nand in a modular way and, most importantly, its straightforward tuning\nprocedure. The TBOD's performance is tested on a terrestrial rover localization\nproblem, combining IMU and ranging sensors provided by Ultra Wide Band\nantennas, and validated through a motion-capture system. Comparison with an\nExtended Kalman Filter is also provided, matching its position estimation\naccuracy and significantly improving in the orientation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f18\u5316\u7684\u89c2\u6d4b\u5668\u8bbe\u8ba1\u65b9\u6cd5TBOD\uff0c\u901a\u8fc7\u9884\u8bb0\u5f55\u7684\u6d4b\u91cf\u8f68\u8ff9\u6765\u8c03\u6574\u89c2\u6d4b\u5668\u53c2\u6570\uff0c\u9002\u7528\u4e8e\u975e\u7ebf\u6027\u7cfb\u7edf\u548c\u591a\u4f20\u611f\u5668\u8bbe\u7f6e\u3002", "motivation": "\u9ad8\u6548\u7684\u89c2\u6d4b\u5668\u8bbe\u8ba1\u548c\u7cbe\u786e\u7684\u4f20\u611f\u5668\u878d\u5408\u5728\u72b6\u6001\u4f30\u8ba1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u901a\u7528\u7684\u65b9\u6cd5\u6765\u7b80\u5316\u89c2\u6d4b\u5668\u8bbe\u8ba1\u8fc7\u7a0b\u3002", "method": "\u57fa\u4e8e\u53c2\u6570\u5316\u89c2\u6d4b\u5668\u52a8\u529b\u5b66\uff0c\u5229\u7528\u9884\u8bb0\u5f55\u7684\u6d4b\u91cf\u8f68\u8ff9\u901a\u8fc7\u6570\u503c\u4f18\u5316\u6765\u8c03\u6574\u89c2\u6d4b\u5668\u53c2\u6570\uff0c\u7ed3\u5408\u7ecf\u5178\u89c2\u6d4b\u5668\u7406\u8bba\u548c\u79fb\u52a8\u6c34\u5e73\u4f30\u8ba1\u5668\u65b9\u6cd5\u3002", "result": "\u5728\u9646\u5730\u6f2b\u6e38\u8f66\u5b9a\u4f4d\u95ee\u9898\u4e2d\u6d4b\u8bd5\uff0c\u7ed3\u5408IMU\u548c\u8d85\u5bbd\u5e26\u5929\u7ebf\u6d4b\u8ddd\u4f20\u611f\u5668\uff0c\u4e0e\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u76f8\u6bd4\uff0c\u4f4d\u7f6e\u4f30\u8ba1\u7cbe\u5ea6\u76f8\u5f53\uff0c\u4f46\u65b9\u5411\u4f30\u8ba1\u663e\u8457\u6539\u5584\u3002", "conclusion": "TBOD\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u901a\u7528\u7684\u4f20\u611f\u5668\u878d\u5408\u65b9\u6cd5\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u901a\u7528\u4f20\u611f\u5668\u5e76\u4ee5\u6a21\u5757\u5316\u65b9\u5f0f\u5de5\u4f5c\uff0c\u6700\u91cd\u8981\u7684\u662f\u5176\u7b80\u5355\u7684\u8c03\u8c10\u8fc7\u7a0b\u3002"}}
{"id": "2510.01050", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.01050", "abs": "https://arxiv.org/abs/2510.01050", "authors": ["Pengyu Ren", "Wei Sun", "Yifan Wang", "Gareth Harrison"], "title": "Grid Frequency Stability Support Potential of Data Center: A Quantitative Assessment of Flexibility", "comment": null, "summary": "The rapid expansion of data center infrastructure is reshaping power system\ndynamics by significantly increasing electricity demand while also offering\npotential for fast and controllable flexibility. To ensure reliable operation\nunder such conditions, the frequency secured unit commitment problem must be\nsolved with enhanced modeling of demand side frequency response. In this work,\nwe propose a data-driven linearization framework based on decision tree based\nconstraint learning to embed nonlinear nadir frequency constraints into\nmixed-integer linear programming. This approach enables tractable optimization\nof generation schedules and fast frequency response from data centers. Through\ncase studies on both a benchmark system and a 2030 future scenario with higher\nDC penetration, we demonstrate that increasing the proportion of flexible DC\nload consistently improves system cost efficiency and supports renewable\nintegration. However, this benefit exhibits diminishing marginal returns,\nmotivating the introduction of the Marginal Flexibility Value metric to\nquantify the economic value of additional flexibility. The results highlight\nthat as DCs become a larger share of system load, their active participation in\nfrequency response will be increasingly indispensable for maintaining both\neconomic and secure system operations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u7ea6\u675f\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u975e\u7ebf\u6027\u9891\u7387\u7ea6\u675f\u5d4c\u5165\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u4f18\u5316\u6570\u636e\u4e2d\u5fc3\u53c2\u4e0e\u9891\u7387\u54cd\u5e94\u7684\u53d1\u7535\u8c03\u5ea6\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u5feb\u901f\u589e\u957f\u6539\u53d8\u4e86\u7535\u529b\u7cfb\u7edf\u52a8\u6001\uff0c\u5728\u589e\u52a0\u7535\u529b\u9700\u6c42\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u5feb\u901f\u53ef\u63a7\u7684\u7075\u6d3b\u6027\uff0c\u9700\u8981\u589e\u5f3a\u9700\u6c42\u4fa7\u9891\u7387\u54cd\u5e94\u5efa\u6a21\u4ee5\u786e\u4fdd\u53ef\u9760\u8fd0\u884c\u3002", "method": "\u57fa\u4e8e\u51b3\u7b56\u6811\u7ea6\u675f\u5b66\u4e60\u7684\u6570\u636e\u9a71\u52a8\u7ebf\u6027\u5316\u6846\u67b6\uff0c\u5c06\u975e\u7ebf\u6027\u6700\u4f4e\u9891\u7387\u7ea6\u675f\u5d4c\u5165\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u3002", "result": "\u589e\u52a0\u7075\u6d3b\u6570\u636e\u4e2d\u5fc3\u8d1f\u8f7d\u6bd4\u4f8b\u6301\u7eed\u6539\u5584\u7cfb\u7edf\u6210\u672c\u6548\u7387\u5e76\u652f\u6301\u53ef\u518d\u751f\u80fd\u6e90\u5e76\u7f51\uff0c\u4f46\u5b58\u5728\u8fb9\u9645\u6536\u76ca\u9012\u51cf\u73b0\u8c61\u3002", "conclusion": "\u968f\u7740\u6570\u636e\u4e2d\u5fc3\u5728\u7cfb\u7edf\u8d1f\u8377\u4e2d\u5360\u6bd4\u589e\u5927\uff0c\u5176\u4e3b\u52a8\u53c2\u4e0e\u9891\u7387\u54cd\u5e94\u5bf9\u7ef4\u6301\u7ecf\u6d4e\u5b89\u5168\u7684\u7cfb\u7edf\u8fd0\u884c\u5c06\u6108\u53d1\u4e0d\u53ef\u6216\u7f3a\u3002"}}
{"id": "2510.00381", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00381", "abs": "https://arxiv.org/abs/2510.00381", "authors": ["Kaiwen Yu", "Mengying Sun", "Zhijin Qin", "Xiaodong Xu", "Ping Yang", "Yue Xiao", "Gang Wu"], "title": "Semantic-Driven AI Agent Communications: Challenges and Solutions", "comment": null, "summary": "With the rapid growth of intelligent services, communication targets are\nshifting from humans to artificial intelligent (AI) agents, which require new\nparadigms to enable real-time perception, decision-making, and collaboration.\nSemantic communication, which conveys task-relevant meaning rather than raw\ndata, offers a promising solution. However, its practical deployment remains\nconstrained by dynamic environments and limited resources. To address these\nissues, this article proposes a semantic-driven AI agent communication\nframework and develops three enabling techniques. First, semantic adaptation\ntransmission applies fine-tuning with real or generative samples to efficiently\nadapt models to varying environments. Second, semantic lightweight transmission\nincorporates pruning, quantization, and perception-aware sampling to reduce\nmodel complexity and alleviate computational burden on edge agents. Third,\nsemantic self-evolution control employs distributed hierarchical\ndecision-making to optimize multi-dimensional resources, enabling robust\nmulti-agent collaboration in dynamic environments. Simulation results show that\nthe proposed solutions achieve faster convergence and stronger robustness,\nwhile the proposed distributed hierarchical optimization method significantly\noutperforms conventional decision-making schemes, highlighting its potential\nfor AI agent communication networks.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u9a71\u52a8\u7684AI\u667a\u80fd\u4f53\u901a\u4fe1\u6846\u67b6\uff0c\u5305\u542b\u8bed\u4e49\u81ea\u9002\u5e94\u4f20\u8f93\u3001\u8bed\u4e49\u8f7b\u91cf\u5316\u4f20\u8f93\u548c\u8bed\u4e49\u81ea\u8fdb\u5316\u63a7\u5236\u4e09\u5927\u6280\u672f\uff0c\u4ee5\u89e3\u51b3\u52a8\u6001\u73af\u5883\u548c\u6709\u9650\u8d44\u6e90\u4e0b\u7684\u667a\u80fd\u4f53\u901a\u4fe1\u6311\u6218\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u670d\u52a1\u5feb\u901f\u53d1\u5c55\uff0c\u901a\u4fe1\u76ee\u6807\u4ece\u4eba\u7c7b\u8f6c\u5411AI\u667a\u80fd\u4f53\uff0c\u9700\u8981\u65b0\u8303\u5f0f\u5b9e\u73b0\u5b9e\u65f6\u611f\u77e5\u3001\u51b3\u7b56\u548c\u534f\u4f5c\u3002\u8bed\u4e49\u901a\u4fe1\u867d\u5177\u524d\u666f\uff0c\u4f46\u53d7\u9650\u4e8e\u52a8\u6001\u73af\u5883\u548c\u8d44\u6e90\u7ea6\u675f\u3002", "method": "1) \u8bed\u4e49\u81ea\u9002\u5e94\u4f20\u8f93\uff1a\u4f7f\u7528\u771f\u5b9e\u6216\u751f\u6210\u6837\u672c\u8fdb\u884c\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u9002\u5e94\u53d8\u5316\u73af\u5883\uff1b2) \u8bed\u4e49\u8f7b\u91cf\u5316\u4f20\u8f93\uff1a\u7ed3\u5408\u526a\u679d\u3001\u91cf\u5316\u548c\u611f\u77e5\u611f\u77e5\u91c7\u6837\uff0c\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff1b3) \u8bed\u4e49\u81ea\u8fdb\u5316\u63a7\u5236\uff1a\u91c7\u7528\u5206\u5e03\u5f0f\u5206\u5c42\u51b3\u7b56\u4f18\u5316\u591a\u7ef4\u8d44\u6e90\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6848\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u5206\u5e03\u5f0f\u5206\u5c42\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u51b3\u7b56\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728AI\u667a\u80fd\u4f53\u901a\u4fe1\u7f51\u7edc\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u52a8\u6001\u73af\u5883\u4e0b\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3002"}}
{"id": "2510.00646", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00646", "abs": "https://arxiv.org/abs/2510.00646", "authors": ["Haoyang Wang", "Xinyu Luo", "Wenhua Ding", "Jingao Xu", "Xuecheng Chen", "Ruiyang Duan", "Jialong Chen", "Haitao Zhang", "Yunhao Liu", "Xinlei Chen"], "title": "Enabling High-Frequency Cross-Modality Visual Positioning Service for Accurate Drone Landing", "comment": "15 pages, 23 figures", "summary": "After years of growth, drone-based delivery is transforming logistics. At its\ncore, real-time 6-DoF drone pose tracking enables precise flight control and\naccurate drone landing. With the widespread availability of urban 3D maps, the\nVisual Positioning Service (VPS), a mobile pose estimation system, has been\nadapted to enhance drone pose tracking during the landing phase, as\nconventional systems like GPS are unreliable in urban environments due to\nsignal attenuation and multi-path propagation. However, deploying the current\nVPS on drones faces limitations in both estimation accuracy and efficiency. In\nthis work, we redesign drone-oriented VPS with the event camera and introduce\nEV-Pose to enable accurate, high-frequency 6-DoF pose tracking for accurate\ndrone landing. EV-Pose introduces a spatio-temporal feature-instructed pose\nestimation module that extracts a temporal distance field to enable 3D point\nmap matching for pose estimation; and a motion-aware hierarchical fusion and\noptimization scheme to enhance the above estimation in accuracy and efficiency,\nby utilizing drone motion in the \\textit{early stage} of event filtering and\nthe \\textit{later stage} of pose optimization. Evaluation shows that EV-Pose\nachieves a rotation accuracy of 1.34$\\degree$ and a translation accuracy of\n6.9$mm$ with a tracking latency of 10.08$ms$, outperforming baselines by\n$>$50\\%, \\tmcrevise{thus enabling accurate drone landings.} Demo:\nhttps://ev-pose.github.io/", "AI": {"tldr": "EV-Pose\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e8b\u4ef6\u76f8\u673a\u7684\u65e0\u4eba\u673a\u89c6\u89c9\u5b9a\u4f4d\u7cfb\u7edf\uff0c\u901a\u8fc7\u65f6\u7a7a\u7279\u5f81\u5f15\u5bfc\u7684\u4f4d\u59ff\u4f30\u8ba1\u548c\u8fd0\u52a8\u611f\u77e5\u7684\u5206\u5c42\u878d\u5408\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u5ef6\u8fdf\u76846\u81ea\u7531\u5ea6\u4f4d\u59ff\u8ddf\u8e2a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u7740\u9646\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edfGPS\u5728\u57ce\u5e02\u573a\u666f\u4e2d\u56e0\u4fe1\u53f7\u8870\u51cf\u548c\u591a\u5f84\u4f20\u64ad\u4e0d\u53ef\u9760\uff0c\u73b0\u6709\u89c6\u89c9\u5b9a\u4f4d\u670d\u52a1\u5728\u65e0\u4eba\u673a\u4e0a\u7684\u90e8\u7f72\u5b58\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u9650\u5236\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u4e8b\u4ef6\u76f8\u673a\u7684\u65e0\u4eba\u673a\u89c6\u89c9\u5b9a\u4f4d\u7cfb\u7edf\uff0c\u5305\u62ec\u65f6\u7a7a\u7279\u5f81\u5f15\u5bfc\u7684\u4f4d\u59ff\u4f30\u8ba1\u6a21\u5757\uff08\u63d0\u53d6\u65f6\u5e8f\u8ddd\u79bb\u573a\u8fdb\u884c3D\u70b9\u4e91\u5339\u914d\uff09\u548c\u8fd0\u52a8\u611f\u77e5\u7684\u5206\u5c42\u878d\u5408\u4f18\u5316\u65b9\u6848\uff08\u5728\u4e8b\u4ef6\u8fc7\u6ee4\u65e9\u671f\u548c\u4f4d\u59ff\u4f18\u5316\u540e\u671f\u5229\u7528\u65e0\u4eba\u673a\u8fd0\u52a8\u4fe1\u606f\uff09\u3002", "result": "\u5b9e\u73b0\u4e861.34\u5ea6\u7684\u65cb\u8f6c\u7cbe\u5ea6\u548c6.9mm\u7684\u5e73\u79fb\u7cbe\u5ea6\uff0c\u8ddf\u8e2a\u5ef6\u8fdf\u4e3a10.08ms\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u8d85\u8fc750%\u3002", "conclusion": "EV-Pose\u7cfb\u7edf\u80fd\u591f\u5b9e\u73b0\u7cbe\u786e\u7684\u65e0\u4eba\u673a\u7740\u9646\uff0c\u4e3a\u65e0\u4eba\u673a\u7269\u6d41\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u4f4d\u59ff\u8ddf\u8e2a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.01059", "categories": ["eess.SY", "cs.RO", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.01059", "abs": "https://arxiv.org/abs/2510.01059", "authors": ["Juan Augusto Paredes Salazar", "James Usevitch", "Ankit Goel"], "title": "Predictive Control Barrier Functions for Discrete-Time Linear Systems with Unmodeled Delays", "comment": "8 pages, 7 figures, submitted to ACC 2026", "summary": "This paper introduces a predictive control barrier function (PCBF) framework\nfor enforcing state constraints in discrete-time systems with unknown relative\ndegree, which can be caused by input delays or unmodeled input dynamics.\nExisting discrete-time CBF formulations typically require the construction of\nauxiliary barrier functions when the relative degree is greater than one, which\ncomplicates implementation and may yield conservative safe sets. The proposed\nPCBF framework addresses this challenge by extending the prediction horizon to\nconstruct a CBF for an associated system with relative degree one. As a result,\nthe superlevel set of the PCBF coincides with the safe set, simplifying\nconstraint enforcement and eliminating the need for auxiliary functions. The\neffectiveness of the proposed method is demonstrated on a discrete-time double\nintegrator with input delay and a bicopter system with position constraints.", "AI": {"tldr": "\u63d0\u51fa\u9884\u6d4b\u63a7\u5236\u5c4f\u969c\u51fd\u6570(PCBF)\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u672a\u77e5\u76f8\u5bf9\u5ea6\u7684\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u7684\u72b6\u6001\u7ea6\u675f\u95ee\u9898\uff0c\u89e3\u51b3\u8f93\u5165\u5ef6\u8fdf\u6216\u672a\u5efa\u6a21\u8f93\u5165\u52a8\u6001\u5e26\u6765\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u79bb\u6563\u65f6\u95f4CBF\u65b9\u6cd5\u5728\u76f8\u5bf9\u5ea6\u5927\u4e8e1\u65f6\u9700\u8981\u6784\u5efa\u8f85\u52a9\u5c4f\u969c\u51fd\u6570\uff0c\u8fd9\u4f7f\u5b9e\u73b0\u590d\u6742\u5316\u4e14\u53ef\u80fd\u5bfc\u81f4\u4fdd\u5b88\u7684\u5b89\u5168\u96c6\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u9884\u6d4b\u65f6\u57df\u6784\u5efa\u76f8\u5bf9\u5ea6\u4e3a1\u7684\u5173\u8054\u7cfb\u7edf\u7684CBF\uff0c\u4f7fPCBF\u7684\u8d85\u6c34\u5e73\u96c6\u4e0e\u5b89\u5168\u96c6\u91cd\u5408\u3002", "result": "\u5728\u5177\u6709\u8f93\u5165\u5ef6\u8fdf\u7684\u79bb\u6563\u65f6\u95f4\u53cc\u79ef\u5206\u5668\u548c\u5177\u6709\u4f4d\u7f6e\u7ea6\u675f\u7684\u53cc\u65cb\u7ffc\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "PCBF\u6846\u67b6\u7b80\u5316\u4e86\u7ea6\u675f\u6267\u884c\uff0c\u65e0\u9700\u8f85\u52a9\u51fd\u6570\uff0c\u4e3a\u5904\u7406\u672a\u77e5\u76f8\u5bf9\u5ea6\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00415", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00415", "abs": "https://arxiv.org/abs/2510.00415", "authors": ["Dadi Guo", "Tianyi Zhou", "Dongrui Liu", "Chen Qian", "Qihan Ren", "Shuai Shao", "Zhiyuan Fan", "Yi R. Fung", "Kun Wang", "Linfeng Zhang", "Jing Shao"], "title": "Towards Self-Evolving Benchmarks: Synthesizing Agent Trajectories via Test-Time Exploration under Validate-by-Reproduce Paradigm", "comment": "his is a work in progress due to methodology refinement and further\n  evaluation", "summary": "Recent advances in large language models (LLMs) and agent system designs have\nempowered agents with unprecedented levels of capability. However, existing\nagent benchmarks are showing a trend of rapid ceiling-hitting by newly\ndeveloped agents, making it difficult to meet the demands for evaluating agent\nabilities. To address this problem, we propose the Trajectory-based\nValidated-by-Reproducing Agent-benchmark Complexity Evolution (TRACE)\nframework. This framework takes an original task from an existing benchmark and\nencourages agents to freely explore and evolve it into a new task with higher\ndifficulty while recording validatable agent trajectories. The framework\nproceeds in three stages: (1) evolutionary proposal mining, which provides task\nevolution proposals through preliminary exploration and divergent thinking; (2)\nproblem formation and free exploration, where proposals are conceptualized into\nfeasible problem candidates and the agents then explore them freely while\nrecording their execution trajectories; and (3) multi-level validation, which\nensures that the evolved tasks are accompanied by validatable and reproducible\ntrajectories. Experiments on the GAIA benchmark demonstrate that the TRACE\nframework consistently enhances task complexity while improving the reliability\nof correctness through validatable execution trajectories. This work marks a\nparadigm shift from static, manually curated benchmarks to dynamic,\nself-evolving evaluation systems, providing a sustainable and challenging\nrunway for agent development.", "AI": {"tldr": "\u63d0\u51fa\u4e86TRACE\u6846\u67b6\uff0c\u901a\u8fc7\u8ba9\u667a\u80fd\u4f53\u81ea\u7531\u63a2\u7d22\u548c\u6f14\u5316\u73b0\u6709\u57fa\u51c6\u4efb\u52a1\uff0c\u81ea\u52a8\u751f\u6210\u66f4\u9ad8\u96be\u5ea6\u7684\u65b0\u4efb\u52a1\u5e76\u8bb0\u5f55\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u5feb\u901f\u8fbe\u5230\u6027\u80fd\u4e0a\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u9762\u4e34\u65b0\u5f00\u53d1\u7684\u667a\u80fd\u4f53\u5feb\u901f\u8fbe\u5230\u6027\u80fd\u4e0a\u9650\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6ee1\u8db3\u8bc4\u4f30\u667a\u80fd\u4f53\u80fd\u529b\u7684\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6301\u7eed\u751f\u6210\u6311\u6218\u6027\u4efb\u52a1\u7684\u52a8\u6001\u8bc4\u4f30\u7cfb\u7edf\u3002", "method": "TRACE\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a\u8fdb\u5316\u63d0\u6848\u6316\u6398\uff08\u901a\u8fc7\u521d\u6b65\u63a2\u7d22\u548c\u53d1\u6563\u6027\u601d\u7ef4\u63d0\u4f9b\u4efb\u52a1\u8fdb\u5316\u63d0\u6848\uff09\u3001\u95ee\u9898\u5f62\u6210\u4e0e\u81ea\u7531\u63a2\u7d22\uff08\u5c06\u63d0\u6848\u6982\u5ff5\u5316\u4e3a\u53ef\u884c\u95ee\u9898\u5019\u9009\uff0c\u8bb0\u5f55\u6267\u884c\u8f68\u8ff9\uff09\u3001\u591a\u7ea7\u9a8c\u8bc1\uff08\u786e\u4fdd\u6f14\u5316\u4efb\u52a1\u5177\u6709\u53ef\u9a8c\u8bc1\u548c\u53ef\u590d\u73b0\u7684\u8f68\u8ff9\uff09\u3002", "result": "\u5728GAIA\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTRACE\u6846\u67b6\u80fd\u591f\u6301\u7eed\u63d0\u5347\u4efb\u52a1\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u8f68\u8ff9\u63d0\u9ad8\u6b63\u786e\u6027\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6807\u5fd7\u7740\u4ece\u9759\u6001\u624b\u52a8\u7b56\u5212\u7684\u57fa\u51c6\u6d4b\u8bd5\u5411\u52a8\u6001\u81ea\u6f14\u5316\u8bc4\u4f30\u7cfb\u7edf\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4e3a\u667a\u80fd\u4f53\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u6301\u7eed\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u5e73\u53f0\u3002"}}
{"id": "2510.00682", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00682", "abs": "https://arxiv.org/abs/2510.00682", "authors": ["Shengzhi Wang", "Niels Dehio", "Xuanqi Zeng", "Xian Yang", "Lingwei Zhang", "Yun-Hui Liu", "K. W. Samuel Au"], "title": "Shared Object Manipulation with a Team of Collaborative Quadrupeds", "comment": "8 pages, 9 figures, submitted to The 2026 American Control Conference", "summary": "Utilizing teams of multiple robots is advantageous for handling bulky\nobjects. Many related works focus on multi-manipulator systems, which are\nlimited by workspace constraints. In this paper, we extend a classical hybrid\nmotion-force controller to a team of legged manipulator systems, enabling\ncollaborative loco-manipulation of rigid objects with a force-closed grasp. Our\nnovel approach allows the robots to flexibly coordinate their movements,\nachieving efficient and stable object co-manipulation and transport, validated\nthrough extensive simulations and real-world experiments.", "AI": {"tldr": "\u5c06\u7ecf\u5178\u6df7\u5408\u8fd0\u52a8-\u529b\u63a7\u5236\u5668\u6269\u5c55\u5230\u817f\u5f0f\u673a\u68b0\u81c2\u7cfb\u7edf\u56e2\u961f\uff0c\u5b9e\u73b0\u521a\u6027\u7269\u4f53\u7684\u534f\u4f5c\u79fb\u52a8\u64cd\u4f5c", "motivation": "\u591a\u673a\u5668\u4eba\u56e2\u961f\u5904\u7406\u7b28\u91cd\u7269\u4f53\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u591a\u673a\u68b0\u81c2\u7cfb\u7edf\uff0c\u53d7\u9650\u4e8e\u5de5\u4f5c\u7a7a\u95f4\u7ea6\u675f", "method": "\u6269\u5c55\u7ecf\u5178\u6df7\u5408\u8fd0\u52a8-\u529b\u63a7\u5236\u5668\u5230\u817f\u5f0f\u673a\u68b0\u81c2\u7cfb\u7edf\u56e2\u961f\uff0c\u91c7\u7528\u529b\u95ed\u5408\u6293\u53d6\u65b9\u5f0f", "result": "\u673a\u5668\u4eba\u80fd\u591f\u7075\u6d3b\u534f\u8c03\u8fd0\u52a8\uff0c\u5b9e\u73b0\u9ad8\u6548\u7a33\u5b9a\u7684\u7269\u4f53\u534f\u4f5c\u64cd\u4f5c\u548c\u8fd0\u8f93\uff0c\u901a\u8fc7\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u9a8c\u8bc1", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u817f\u5f0f\u673a\u5668\u4eba\u56e2\u961f\u7684\u534f\u4f5c\u79fb\u52a8\u64cd\u4f5c\u80fd\u529b"}}
{"id": "2510.01147", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.01147", "abs": "https://arxiv.org/abs/2510.01147", "authors": ["Jixian Liu", "Enrique Mallada"], "title": "Safety-Critical Control via Recurrent Tracking Functions", "comment": "7 Pages, 2 Figures", "summary": "This paper addresses the challenge of synthesizing safety-critical\ncontrollers for high-order nonlinear systems, where constructing valid Control\nBarrier Functions (CBFs) remains computationally intractable. Leveraging\nlayered control, we design CBFs in reduced-order models (RoMs) while regulating\nfull-order models' (FoMs) dynamics at the same time. Traditional Lyapunov\ntracking functions are required to decrease monotonically, but systematic\nsynthesis methods for such functions exist only for fully-actuated systems. To\novercome this limitation, we introduce Recurrent Tracking Functions (RTFs),\nwhich replace the monotonic decay requirement with a weaker finite-time\nrecurrence condition. This relaxation permits transient deviations of tracking\nerrors while ensuring safety. By augmenting CBFs for RoMs with RTFs, we\nconstruct recurrent CBFs (RCBFs) whose zero-superlevel set is control\n$\\tau$-recurrent, and guarantee safety for all initial states in such a set\nwhen RTFs are satisfied. We establish theoretical safety guarantees and\nvalidate the approach through numerical experiments, demonstrating RTFs'\neffectiveness and the safety of FoMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u9ad8\u9636\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u5b89\u5168\u5173\u952e\u63a7\u5236\u5668\u5408\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5faa\u73af\u8ddf\u8e2a\u51fd\u6570(RTFs)\u6765\u653e\u5bbd\u4f20\u7edfLyapunov\u8ddf\u8e2a\u51fd\u6570\u7684\u5355\u8c03\u8870\u51cf\u8981\u6c42\uff0c\u6784\u5efa\u5faa\u73af\u63a7\u5236\u5c4f\u969c\u51fd\u6570(RCBFs)\u6765\u4fdd\u8bc1\u7cfb\u7edf\u5b89\u5168\u3002", "motivation": "\u9488\u5bf9\u9ad8\u9636\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\u6784\u9020\u6709\u6548\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBFs)\u8ba1\u7b97\u56f0\u96be\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u4f20\u7edfLyapunov\u8ddf\u8e2a\u51fd\u6570\u9700\u8981\u5355\u8c03\u8870\u51cf\u4e14\u4ec5\u9002\u7528\u4e8e\u5168\u9a71\u52a8\u7cfb\u7edf\u7684\u9650\u5236\u3002", "method": "\u5229\u7528\u5206\u5c42\u63a7\u5236\u8bbe\u8ba1\uff0c\u5728\u964d\u9636\u6a21\u578b\u4e2d\u8bbe\u8ba1CBFs\uff0c\u540c\u65f6\u8c03\u8282\u5168\u9636\u6a21\u578b\u52a8\u6001\u3002\u5f15\u5165\u5faa\u73af\u8ddf\u8e2a\u51fd\u6570(RTFs)\u66ff\u4ee3\u5355\u8c03\u8870\u51cf\u8981\u6c42\uff0c\u901a\u8fc7\u6709\u9650\u65f6\u95f4\u5faa\u73af\u6761\u4ef6\u5141\u8bb8\u8ddf\u8e2a\u8bef\u5dee\u7684\u77ac\u65f6\u504f\u5dee\u3002\u5c06\u964d\u9636\u6a21\u578b\u7684CBFs\u4e0eRTFs\u7ed3\u5408\u6784\u5efa\u5faa\u73afCBFs(RCBFs)\u3002", "result": "\u5efa\u7acb\u4e86\u7406\u8bba\u5b89\u5168\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86RTFs\u7684\u6709\u6548\u6027\u548c\u5168\u9636\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u9ad8\u9636\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u5b89\u5168\u63a7\u5236\u95ee\u9898\uff0c\u653e\u5bbd\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4e25\u683c\u9650\u5236\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2510.00436", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00436", "abs": "https://arxiv.org/abs/2510.00436", "authors": ["Sarvesh Soni", "Dina Demner-Fushman"], "title": "Automated Evaluation can Distinguish the Good and Bad AI Responses to Patient Questions about Hospitalization", "comment": null, "summary": "Automated approaches to answer patient-posed health questions are rising, but\nselecting among systems requires reliable evaluation. The current gold standard\nfor evaluating the free-text artificial intelligence (AI) responses--human\nexpert review--is labor-intensive and slow, limiting scalability. Automated\nmetrics are promising yet variably aligned with human judgments and often\ncontext-dependent. To address the feasibility of automating the evaluation of\nAI responses to hospitalization-related questions posed by patients, we\nconducted a large systematic study of evaluation approaches. Across 100 patient\ncases, we collected responses from 28 AI systems (2800 total) and assessed them\nalong three dimensions: whether a system response (1) answers the question, (2)\nappropriately uses clinical note evidence, and (3) uses general medical\nknowledge. Using clinician-authored reference answers to anchor metrics,\nautomated rankings closely matched expert ratings. Our findings suggest that\ncarefully designed automated evaluation can scale comparative assessment of AI\nsystems and support patient-clinician communication.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30AI\u7cfb\u7edf\u56de\u7b54\u60a3\u8005\u4f4f\u9662\u76f8\u5173\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u53ef\u4ee5\u66ff\u4ee3\u4eba\u5de5\u4e13\u5bb6\u8bc4\u5ba1\uff0c\u5b9e\u73b0AI\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6bd4\u8f83\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30AI\u56de\u7b54\u60a3\u8005\u5065\u5eb7\u95ee\u9898\u7684\u9ec4\u91d1\u6807\u51c6\u662f\u4eba\u5de5\u4e13\u5bb6\u8bc4\u5ba1\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u52b3\u52a8\u5bc6\u96c6\u4e14\u7f13\u6162\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002\u81ea\u52a8\u5316\u6307\u6807\u867d\u7136\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u4e0d\u4e00\u4e14\u5f80\u5f80\u4f9d\u8d56\u4e0a\u4e0b\u6587\u3002", "method": "\u5728100\u4e2a\u60a3\u8005\u6848\u4f8b\u4e2d\uff0c\u6536\u96c6\u4e8628\u4e2aAI\u7cfb\u7edf\u76842800\u4e2a\u56de\u7b54\uff0c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\uff1a\u662f\u5426\u56de\u7b54\u95ee\u9898\u3001\u662f\u5426\u9002\u5f53\u4f7f\u7528\u4e34\u5e8a\u8bb0\u5f55\u8bc1\u636e\u3001\u662f\u5426\u4f7f\u7528\u4e00\u822c\u533b\u5b66\u77e5\u8bc6\u3002\u4f7f\u7528\u4e34\u5e8a\u533b\u751f\u64b0\u5199\u7684\u53c2\u8003\u7b54\u6848\u4f5c\u4e3a\u6307\u6807\u951a\u70b9\u3002", "result": "\u81ea\u52a8\u5316\u6392\u540d\u4e0e\u4e13\u5bb6\u8bc4\u5206\u9ad8\u5ea6\u5339\u914d\uff0c\u8868\u660e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u53ef\u4ee5\u51c6\u786e\u53cd\u6620AI\u7cfb\u7edf\u7684\u8868\u73b0\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u53ef\u4ee5\u6269\u5c55AI\u7cfb\u7edf\u7684\u6bd4\u8f83\u8bc4\u4f30\uff0c\u652f\u6301\u60a3\u8005\u4e0e\u4e34\u5e8a\u533b\u751f\u7684\u6c9f\u901a\u3002"}}
{"id": "2510.00695", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00695", "abs": "https://arxiv.org/abs/2510.00695", "authors": ["Myungkyu Koo", "Daewon Choi", "Taeyoung Kim", "Kyungmin Lee", "Changyeon Kim", "Youngyo Seo", "Jinwoo Shin"], "title": "HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy", "comment": "Project page: https://myungkyukoo.github.io/hamlet/", "summary": "Inherently, robotic manipulation tasks are history-dependent: leveraging past\ncontext could be beneficial. However, most existing Vision-Language-Action\nmodels (VLAs) have been designed without considering this aspect, i.e., they\nrely solely on the current observation, ignoring preceding context. In this\npaper, we propose HAMLET, a scalable framework to adapt VLAs to attend to the\nhistorical context during action prediction. Specifically, we introduce moment\ntokens that compactly encode perceptual information at each timestep. Their\nrepresentations are initialized with time-contrastive learning, allowing them\nto better capture temporally distinctive aspects. Next, we employ a lightweight\nmemory module that integrates the moment tokens across past timesteps into\nmemory features, which are then leveraged for action prediction. Through\nempirical evaluation, we show that HAMLET successfully transforms a\nstate-of-the-art VLA into a history-aware policy, especially demonstrating\nsignificant improvements on long-horizon tasks that require historical context.\nIn particular, on top of GR00T N1.5, HAMLET achieves an average success rate of\n76.4% on history-dependent real-world tasks, surpassing the baseline\nperformance by 47.2%. Furthermore, HAMLET pushes prior art performance from\n64.1% to 66.4% on RoboCasa Kitchen (100-demo setup) and from 95.6% to 97.7% on\nLIBERO, highlighting its effectiveness even under generic robot-manipulation\nbenchmarks.", "AI": {"tldr": "HAMLET\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u523b\u4ee4\u724c\u548c\u8f7b\u91cf\u7ea7\u8bb0\u5fc6\u6a21\u5757\uff0c\u5c06\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff08VLA\uff09\u6539\u9020\u4e3a\u80fd\u591f\u5229\u7528\u5386\u53f2\u4e0a\u4e0b\u6587\u7684\u5386\u53f2\u611f\u77e5\u7b56\u7565\uff0c\u5728\u9700\u8981\u5386\u53f2\u4e0a\u4e0b\u6587\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u672c\u8d28\u4e0a\u662f\u5386\u53f2\u4f9d\u8d56\u7684\uff0c\u4f46\u73b0\u6709\u7684VLA\u6a21\u578b\u4ec5\u4f9d\u8d56\u5f53\u524d\u89c2\u6d4b\u800c\u5ffd\u7565\u5386\u53f2\u4e0a\u4e0b\u6587\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6709\u6548\u5229\u7528\u5386\u53f2\u4fe1\u606f\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u65f6\u523b\u4ee4\u724c\u6765\u7d27\u51d1\u7f16\u7801\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u611f\u77e5\u4fe1\u606f\uff0c\u901a\u8fc7\u65f6\u95f4\u5bf9\u6bd4\u5b66\u4e60\u521d\u59cb\u5316\u8868\u793a\uff1b\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8bb0\u5fc6\u6a21\u5757\u6574\u5408\u8fc7\u53bb\u65f6\u95f4\u6b65\u7684\u65f6\u523b\u4ee4\u724c\u4e3a\u8bb0\u5fc6\u7279\u5f81\uff0c\u7528\u4e8e\u52a8\u4f5c\u9884\u6d4b\u3002", "result": "\u5728GR00T N1.5\u4e0a\uff0cHAMLET\u5728\u5386\u53f2\u4f9d\u8d56\u7684\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u8fbe\u523076.4%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u6bd4\u57fa\u7ebf\u63d0\u534747.2%\uff1b\u5728RoboCasa Kitchen\u4e0a\u4ece64.1%\u63d0\u5347\u523066.4%\uff0c\u5728LIBERO\u4e0a\u4ece95.6%\u63d0\u5347\u523097.7%\u3002", "conclusion": "HAMLET\u6210\u529f\u5c06\u6700\u5148\u8fdb\u7684VLA\u6a21\u578b\u8f6c\u53d8\u4e3a\u5386\u53f2\u611f\u77e5\u7b56\u7565\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5386\u53f2\u4e0a\u4e0b\u6587\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.00480", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00480", "abs": "https://arxiv.org/abs/2510.00480", "authors": ["Kenjiro Ide", "Taiga Someya", "Kohei Kawaguchi", "Keisuke Fujii"], "title": "Expandable Decision-Making States for Multi-Agent Deep Reinforcement Learning in Soccer Tactical Analysis", "comment": "28 pages, 9 figures", "summary": "Invasion team sports such as soccer produce a high-dimensional, strongly\ncoupled state space as many players continuously interact on a shared field,\nchallenging quantitative tactical analysis. Traditional rule-based analyses are\nintuitive, while modern predictive machine learning models often perform\npattern-matching without explicit agent representations. The problem we address\nis how to build player-level agent models from data, whose learned values and\npolicies are both tactically interpretable and robust across heterogeneous data\nsources. Here, we propose Expandable Decision-Making States (EDMS), a\nsemantically enriched state representation that augments raw positions and\nvelocities with relational variables (e.g., scoring of space, pass, and score),\ncombined with an action-masking scheme that gives on-ball and off-ball agents\ndistinct decision sets. Compared to prior work, EDMS maps learned value\nfunctions and action policies to human-interpretable tactical concepts (e.g.,\nmarking pressure, passing lanes, ball accessibility) instead of raw coordinate\nfeatures, and aligns agent choices with the rules of play. In the experiments,\nEDMS with action masking consistently reduced both action-prediction loss and\ntemporal-difference (TD) error compared to the baseline. Qualitative case\nstudies and Q-value visualizations further indicate that EDMS highlights\nhigh-risk, high-reward tactical patterns (e.g., fast counterattacks and\ndefensive breakthroughs). We also integrated our approach into an open-source\nlibrary and demonstrated compatibility with multiple commercial and open\ndatasets, enabling cross-provider evaluation and reproducible experiments.", "AI": {"tldr": "\u63d0\u51faEDMS\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u589e\u5f3a\u7684\u72b6\u6001\u8868\u793a\u548c\u52a8\u4f5c\u63a9\u7801\u673a\u5236\uff0c\u5728\u8db3\u7403\u7b49\u56e2\u961f\u8fd0\u52a8\u4e2d\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u7403\u5458\u7ea7\u667a\u80fd\u4f53\u6a21\u578b\uff0c\u5b9e\u73b0\u6218\u672f\u5206\u6790\u548c\u8de8\u6570\u636e\u6e90\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u89c4\u5219\u5206\u6790\u76f4\u89c2\u4f46\u6709\u9650\uff0c\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7f3a\u4e4f\u660e\u786e\u667a\u80fd\u4f53\u8868\u793a\u3002\u9700\u8981\u6784\u5efa\u65e2\u80fd\u6218\u672f\u89e3\u91ca\u53c8\u80fd\u5728\u5f02\u6784\u6570\u636e\u6e90\u4e2d\u9c81\u68d2\u7684\u7403\u5458\u7ea7\u667a\u80fd\u4f53\u6a21\u578b\u3002", "method": "\u4f7f\u7528Expandable Decision-Making States (EDMS)\u8bed\u4e49\u589e\u5f3a\u72b6\u6001\u8868\u793a\uff0c\u7ed3\u5408\u52a8\u4f5c\u63a9\u7801\u65b9\u6848\uff0c\u4e3a\u6301\u7403\u548c\u65e0\u7403\u7403\u5458\u63d0\u4f9b\u4e0d\u540c\u7684\u51b3\u7b56\u96c6\uff0c\u5c06\u5b66\u4e60\u5230\u7684\u4ef7\u503c\u51fd\u6570\u548c\u52a8\u4f5c\u7b56\u7565\u6620\u5c04\u5230\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6218\u672f\u6982\u5ff5\u3002", "result": "EDMS\u4e0e\u52a8\u4f5c\u63a9\u7801\u76f8\u6bd4\u57fa\u7ebf\u6301\u7eed\u964d\u4f4e\u4e86\u52a8\u4f5c\u9884\u6d4b\u635f\u5931\u548c\u65f6\u5e8f\u5dee\u5206\u8bef\u5dee\uff0c\u5b9a\u6027\u6848\u4f8b\u7814\u7a76\u548cQ\u503c\u53ef\u89c6\u5316\u663e\u793aEDMS\u80fd\u7a81\u51fa\u9ad8\u98ce\u9669\u9ad8\u56de\u62a5\u7684\u6218\u672f\u6a21\u5f0f\u3002", "conclusion": "EDMS\u65b9\u6cd5\u6210\u529f\u6784\u5efa\u4e86\u53ef\u89e3\u91ca\u7684\u7403\u5458\u7ea7\u667a\u80fd\u4f53\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6218\u672f\u6982\u5ff5\u7684\u6620\u5c04\u548c\u8de8\u6570\u636e\u6e90\u7684\u517c\u5bb9\u6027\uff0c\u4e3a\u5b9a\u91cf\u6218\u672f\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.00703", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00703", "abs": "https://arxiv.org/abs/2510.00703", "authors": ["Andrea Bussolan", "Stefano Baraldo", "Oliver Avram", "Pablo Urcola", "Luis Montesano", "Luca Maria Gambardella", "Anna Valente"], "title": "MultiPhysio-HRC: Multimodal Physiological Signals Dataset for industrial Human-Robot Collaboration", "comment": null, "summary": "Human-robot collaboration (HRC) is a key focus of Industry 5.0, aiming to\nenhance worker productivity while ensuring well-being. The ability to perceive\nhuman psycho-physical states, such as stress and cognitive load, is crucial for\nadaptive and human-aware robotics. This paper introduces MultiPhysio-HRC, a\nmultimodal dataset containing physiological, audio, and facial data collected\nduring real-world HRC scenarios. The dataset includes electroencephalography\n(EEG), electrocardiography (ECG), electrodermal activity (EDA), respiration\n(RESP), electromyography (EMG), voice recordings, and facial action units. The\ndataset integrates controlled cognitive tasks, immersive virtual reality\nexperiences, and industrial disassembly activities performed manually and with\nrobotic assistance, to capture a holistic view of the participants' mental\nstates. Rich ground truth annotations were obtained using validated\npsychological self-assessment questionnaires. Baseline models were evaluated\nfor stress and cognitive load classification, demonstrating the dataset's\npotential for affective computing and human-aware robotics research.\nMultiPhysio-HRC is publicly available to support research in human-centered\nautomation, workplace well-being, and intelligent robotic systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86MultiPhysio-HRC\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b\u751f\u7406\u3001\u97f3\u9891\u548c\u9762\u90e8\u6570\u636e\uff0c\u7528\u4e8e\u7814\u7a76\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u5fc3\u7406\u72b6\u6001\u611f\u77e5\u3002", "motivation": "\u5de5\u4e1a5.0\u4e2d\u4eba\u673a\u534f\u4f5c\u9700\u8981\u611f\u77e5\u4eba\u7c7b\u7684\u5fc3\u7406\u751f\u7406\u72b6\u6001\uff08\u5982\u538b\u529b\u548c\u8ba4\u77e5\u8d1f\u8377\uff09\uff0c\u4ee5\u5b9e\u73b0\u81ea\u9002\u5e94\u548c\u4eba\u7c7b\u611f\u77e5\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u3002", "method": "\u6536\u96c6\u4e86EEG\u3001ECG\u3001EDA\u3001RESP\u3001EMG\u3001\u8bed\u97f3\u8bb0\u5f55\u548c\u9762\u90e8\u52a8\u4f5c\u5355\u5143\u7b49\u591a\u6a21\u6001\u6570\u636e\uff0c\u7ed3\u5408\u53d7\u63a7\u8ba4\u77e5\u4efb\u52a1\u3001\u6c89\u6d78\u5f0f\u865a\u62df\u73b0\u5b9e\u4f53\u9a8c\u548c\u5de5\u4e1a\u62c6\u5378\u6d3b\u52a8\uff0c\u5e76\u901a\u8fc7\u9a8c\u8bc1\u7684\u5fc3\u7406\u81ea\u8bc4\u95ee\u5377\u83b7\u5f97\u4e30\u5bcc\u7684\u5730\u9762\u771f\u5b9e\u6807\u6ce8\u3002", "result": "\u8bc4\u4f30\u4e86\u538b\u529b\u548c\u8ba4\u77e5\u8d1f\u8377\u5206\u7c7b\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u6570\u636e\u96c6\u5728\u60c5\u611f\u8ba1\u7b97\u548c\u4eba\u7c7b\u611f\u77e5\u673a\u5668\u4eba\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "MultiPhysio-HRC\u6570\u636e\u96c6\u516c\u5f00\u53ef\u7528\uff0c\u652f\u6301\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u81ea\u52a8\u5316\u3001\u5de5\u4f5c\u573a\u6240\u798f\u7949\u548c\u667a\u80fd\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u7814\u7a76\u3002"}}
{"id": "2510.00492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00492", "abs": "https://arxiv.org/abs/2510.00492", "authors": ["Dong Bok Lee", "Seanie Lee", "Sangwoo Park", "Minki Kang", "Jinheon Baek", "Dongki Kim", "Dominik Wagner", "Jiongdao Jin", "Heejun Lee", "Tobias Bocklet", "Jinyu Wang", "Jingjing Fu", "Sung Ju Hwang", "Jiang Bia", "Lei Song"], "title": "Rethinking Reward Models for Multi-Domain Test-Time Scaling", "comment": null, "summary": "The reliability of large language models (LLMs) during test-time scaling is\noften assessed with \\emph{external verifiers} or \\emph{reward models} that\ndistinguish correct reasoning from flawed logic. Prior work generally assumes\nthat process reward models (PRMs), which score every intermediate reasoning\nstep, outperform outcome reward models (ORMs) that assess only the final\nanswer. This view is based mainly on evidence from narrow, math-adjacent\ndomains. We present the first unified evaluation of four reward model variants,\ndiscriminative ORM and PRM (\\DisORM, \\DisPRM) and generative ORM and PRM\n(\\GenORM, \\GenPRM), across 14 diverse domains. Contrary to conventional wisdom,\nwe find that (i) \\DisORM performs on par with \\DisPRM, (ii) \\GenPRM is not\ncompetitive, and (iii) overall, \\GenORM is the most robust, yielding\nsignificant and consistent gains across every tested domain. We attribute this\nto PRM-style stepwise scoring, which inherits label noise from LLM\nauto-labeling and has difficulty evaluating long reasoning trajectories,\nincluding those involving self-correcting reasoning. Our theoretical analysis\nshows that step-wise aggregation compounds errors as reasoning length grows,\nand our empirical observations confirm this effect. These findings challenge\nthe prevailing assumption that fine-grained supervision is always better and\nsupport generative outcome verification for multi-domain deployment. We\npublicly release our code, datasets, and checkpoints at\n\\href{https://github.com/db-Lee/Multi-RM}{\\underline{\\small\\texttt{https://github.com/db-Lee/Multi-RM}}}\nto facilitate future research in multi-domain settings.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u4f20\u7edf\u89c2\u70b9\uff0c\u53d1\u73b0\u572814\u4e2a\u591a\u6837\u5316\u9886\u57df\u4e2d\uff0c\u751f\u6210\u5f0f\u7ed3\u679c\u5956\u52b1\u6a21\u578b(GenORM)\u8868\u73b0\u6700\u7a33\u5065\uff0c\u800c\u975e\u4f20\u7edf\u8ba4\u4e3a\u7684\u9010\u6b65\u5956\u52b1\u6a21\u578b(PRM)\u66f4\u4f18\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u9010\u6b65\u5956\u52b1\u6a21\u578b(PRM)\u4f18\u4e8e\u7ed3\u679c\u5956\u52b1\u6a21\u578b(ORM)\uff0c\u4f46\u8fd9\u79cd\u89c2\u70b9\u4e3b\u8981\u57fa\u4e8e\u6570\u5b66\u76f8\u5173\u9886\u57df\u7684\u8bc1\u636e\u3002\u672c\u6587\u65e8\u5728\u5728\u591a\u6837\u5316\u9886\u57df\u4e2d\u7edf\u4e00\u8bc4\u4f30\u4e0d\u540c\u5956\u52b1\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u572814\u4e2a\u591a\u6837\u5316\u9886\u57df\u4e2d\u7edf\u4e00\u8bc4\u4f30\u56db\u79cd\u5956\u52b1\u6a21\u578b\u53d8\u4f53\uff1a\u5224\u522b\u5f0fORM\u548cPRM(DisORM, DisPRM)\u4ee5\u53ca\u751f\u6210\u5f0fORM\u548cPRM(GenORM, GenPRM)\u3002", "result": "\u53d1\u73b0\uff1a(i) DisORM\u4e0eDisPRM\u8868\u73b0\u76f8\u5f53\uff1b(ii) GenPRM\u4e0d\u5177\u7ade\u4e89\u529b\uff1b(iii) GenORM\u662f\u6700\u7a33\u5065\u7684\u6a21\u578b\uff0c\u5728\u6240\u6709\u6d4b\u8bd5\u9886\u57df\u90fd\u53d6\u5f97\u663e\u8457\u4e14\u4e00\u81f4\u7684\u589e\u76ca\u3002", "conclusion": "\u9010\u6b65\u8bc4\u5206\u4f1a\u7ee7\u627fLLM\u81ea\u52a8\u6807\u6ce8\u7684\u6807\u7b7e\u566a\u58f0\uff0c\u96be\u4ee5\u8bc4\u4f30\u957f\u63a8\u7406\u8f68\u8ff9\uff0c\u5305\u62ec\u6d89\u53ca\u81ea\u6211\u4fee\u6b63\u7684\u63a8\u7406\u3002\u7406\u8bba\u5206\u6790\u663e\u793a\u9010\u6b65\u805a\u5408\u4f1a\u968f\u7740\u63a8\u7406\u957f\u5ea6\u589e\u957f\u800c\u653e\u5927\u9519\u8bef\u3002\u8fd9\u4e9b\u53d1\u73b0\u6311\u6218\u4e86\u7ec6\u7c92\u5ea6\u76d1\u7763\u603b\u662f\u66f4\u597d\u7684\u666e\u904d\u5047\u8bbe\u3002"}}
{"id": "2510.00726", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00726", "abs": "https://arxiv.org/abs/2510.00726", "authors": ["Giovanni Minelli", "Giulio Turrisi", "Victor Barasuol", "Claudio Semini"], "title": "CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation", "comment": "Code and data available at https://github.com/iit-DLSLab/croSTAta", "summary": "Learning robotic manipulation policies through supervised learning from\ndemonstrations remains challenging when policies encounter execution variations\nnot explicitly covered during training. While incorporating historical context\nthrough attention mechanisms can improve robustness, standard approaches\nprocess all past states in a sequence without explicitly modeling the temporal\nstructure that demonstrations may include, such as failure and recovery\npatterns. We propose a Cross-State Transition Attention Transformer that\nemploys a novel State Transition Attention (STA) mechanism to modulate standard\nattention weights based on learned state evolution patterns, enabling policies\nto better adapt their behavior based on execution history. Our approach\ncombines this structured attention with temporal masking during training, where\nvisual information is randomly removed from recent timesteps to encourage\ntemporal reasoning from historical context. Evaluation in simulation shows that\nSTA consistently outperforms standard cross-attention and temporal modeling\napproaches like TCN and LSTM networks across all tasks, achieving more than 2x\nimprovement over cross-attention on precision-critical tasks.", "AI": {"tldr": "\u63d0\u51faCross-State Transition Attention Transformer\uff0c\u901a\u8fc7\u72b6\u6001\u8f6c\u79fb\u6ce8\u610f\u529b\u673a\u5236\u548c\u65f6\u5e8f\u63a9\u7801\u8bad\u7ec3\uff0c\u63d0\u5347\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u5bf9\u6267\u884c\u53d8\u5316\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u5728\u9047\u5230\u8bad\u7ec3\u672a\u8986\u76d6\u7684\u6267\u884c\u53d8\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u6ce8\u610f\u529b\u673a\u5236\u672a\u80fd\u5145\u5206\u5229\u7528\u6f14\u793a\u4e2d\u7684\u65f6\u5e8f\u7ed3\u6784\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528\u72b6\u6001\u8f6c\u79fb\u6ce8\u610f\u529b\u673a\u5236\u8c03\u5236\u6807\u51c6\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u7ed3\u5408\u65f6\u5e8f\u63a9\u7801\u8bad\u7ec3\u968f\u673a\u79fb\u9664\u8fd1\u671f\u89c6\u89c9\u4fe1\u606f\uff0c\u5f3a\u5236\u6a21\u578b\u4ece\u5386\u53f2\u4e0a\u4e0b\u6587\u8fdb\u884c\u65f6\u5e8f\u63a8\u7406\u3002", "result": "\u5728\u4eff\u771f\u8bc4\u4f30\u4e2d\uff0cSTA\u65b9\u6cd5\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u6807\u51c6\u4ea4\u53c9\u6ce8\u610f\u529b\u548cTCN\u3001LSTM\u7b49\u65f6\u5e8f\u5efa\u6a21\u65b9\u6cd5\uff0c\u5728\u7cbe\u5ea6\u5173\u952e\u4efb\u52a1\u4e0a\u6bd4\u4ea4\u53c9\u6ce8\u610f\u529b\u63d0\u53472\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u72b6\u6001\u8f6c\u79fb\u6a21\u5f0f\u5e76\u7ed3\u5408\u65f6\u5e8f\u63a9\u7801\u8bad\u7ec3\uff0c\u80fd\u6709\u6548\u63d0\u5347\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u5bf9\u6267\u884c\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.00933", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00933", "abs": "https://arxiv.org/abs/2510.00933", "authors": ["Sara Strakosova", "Petr Novak", "Petr Kadera"], "title": "Product-oriented Product-Process-Resource Asset Network and its Representation in AutomationML for Asset Administration Shell", "comment": "This work has been submitted to the IEEE for possible publication. 8\n  pages, 6 figures", "summary": "Current products, especially in the automotive sector, pose complex technical\nsystems having a multi-disciplinary mechatronic nature. Industrial standards\nsupporting system engineering and production typically (i) address the\nproduction phase only, but do not cover the complete product life cycle, and\n(ii) focus on production processes and resources rather than the products\nthemselves. The presented approach is motivated by incorporating impacts of\nend-of-life phase of the product life cycle into the engineering phase. This\npaper proposes a modelling approach coming up from the Product-Process-Resource\n(PPR) modeling paradigm. It combines requirements on (i) respecting the product\nstructure as a basis for the model, and (ii) it incorporates repairing,\nremanufacturing, or upcycling within cyber-physical production systems. The\nproposed model called PoPAN should accompany the product during the entire life\ncycle as a digital shadow encapsulated within the Asset Administration Shell of\na product. To facilitate the adoption of the proposed paradigm, the paper also\nproposes serialization of the model in the AutomationML data format. The model\nis demonstrated on a use-case for disassembling electric vehicle batteries to\nsupport their remanufacturing for stationary battery applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePPR\u5efa\u6a21\u8303\u5f0f\u7684PoPAN\u6a21\u578b\uff0c\u5c06\u4ea7\u54c1\u751f\u547d\u5468\u671f\u672b\u7aef\u9636\u6bb5\u7684\u5f71\u54cd\u7eb3\u5165\u5de5\u7a0b\u9636\u6bb5\uff0c\u652f\u6301\u4ea7\u54c1\u5728\u6574\u4e2a\u751f\u547d\u5468\u671f\u4e2d\u7684\u7ef4\u4fee\u3001\u518d\u5236\u9020\u548c\u5347\u7ea7\u5faa\u73af\uff0c\u5e76\u4ee5\u7535\u52a8\u6c7d\u8f66\u7535\u6c60\u62c6\u89e3\u4e3a\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u5de5\u4e1a\u6807\u51c6\u4e3b\u8981\u5173\u6ce8\u751f\u4ea7\u9636\u6bb5\u800c\u975e\u5b8c\u6574\u4ea7\u54c1\u751f\u547d\u5468\u671f\uff0c\u4e14\u4fa7\u91cd\u4e8e\u751f\u4ea7\u8fc7\u7a0b\u800c\u975e\u4ea7\u54c1\u672c\u8eab\u3002\u9700\u8981\u5c06\u4ea7\u54c1\u751f\u547d\u5468\u671f\u672b\u7aef\u9636\u6bb5\uff08\u5982\u62a5\u5e9f\u5904\u7406\uff09\u7684\u5f71\u54cd\u7eb3\u5165\u5de5\u7a0b\u9636\u6bb5\u8003\u8651\u3002", "method": "\u57fa\u4e8e\u4ea7\u54c1-\u8fc7\u7a0b-\u8d44\u6e90(PPR)\u5efa\u6a21\u8303\u5f0f\uff0c\u63d0\u51faPoPAN\u6a21\u578b\u4f5c\u4e3a\u4ea7\u54c1\u7684\u6570\u5b57\u5f71\u5b50\uff0c\u5c01\u88c5\u5728\u8d44\u4ea7\u7ba1\u7406\u58f3\u4e2d\uff0c\u652f\u6301\u7ef4\u4fee\u3001\u518d\u5236\u9020\u548c\u5347\u7ea7\u5faa\u73af\uff0c\u5e76\u4f7f\u7528AutomationML\u6570\u636e\u683c\u5f0f\u8fdb\u884c\u5e8f\u5217\u5316\u3002", "result": "\u5f00\u53d1\u4e86PoPAN\u6a21\u578b\u6846\u67b6\uff0c\u80fd\u591f\u4f34\u968f\u4ea7\u54c1\u6574\u4e2a\u751f\u547d\u5468\u671f\uff0c\u652f\u6301\u5728\u4fe1\u606f\u7269\u7406\u751f\u4ea7\u7cfb\u7edf\u4e2d\u8fdb\u884c\u7ef4\u4fee\u3001\u518d\u5236\u9020\u548c\u5347\u7ea7\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u7535\u52a8\u6c7d\u8f66\u7535\u6c60\u62c6\u89e3\u7528\u4f8b\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "PoPAN\u6a21\u578b\u6210\u529f\u5c06\u4ea7\u54c1\u751f\u547d\u5468\u671f\u672b\u7aef\u8003\u8651\u7eb3\u5165\u5de5\u7a0b\u9636\u6bb5\uff0c\u4e3a\u652f\u6301\u5faa\u73af\u7ecf\u6d4e\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u7535\u52a8\u6c7d\u8f66\u7535\u6c60\u518d\u5236\u9020\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2510.00523", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00523", "abs": "https://arxiv.org/abs/2510.00523", "authors": ["Wei-Yao Wang", "Kazuya Tateishi", "Qiyu Wu", "Shusuke Takahashi", "Yuki Mitsufuji"], "title": "VIRTUE: Visual-Interactive Text-Image Universal Embedder", "comment": "25 pages", "summary": "Multimodal representation learning models have demonstrated successful\noperation across complex tasks, and the integration of vision-language models\n(VLMs) has further enabled embedding models with instruction-following\ncapabilities. However, existing embedding models lack visual-interactive\ncapabilities to specify regions of interest from users (e.g., point, bounding\nbox, mask), which have been explored in generative models to broaden their\nhuman-interactive applicability. Equipping embedding models with visual\ninteractions not only would unlock new applications with localized grounding of\nuser intent, which remains unexplored, but also enable the models to learn\nentity-level information within images to complement their global\nrepresentations for conventional embedding tasks. In this paper, we propose a\nnovel Visual-InteRactive Text-Image Universal Embedder (VIRTUE) that extends\nthe capabilities of the segmentation model and the vision-language model to the\nrealm of representation learning. In VIRTUE, the segmentation model can process\nvisual prompts that pinpoint specific regions within an image, thereby enabling\nthe embedder to handle complex and ambiguous scenarios more precisely. To\nevaluate the visual-interaction ability of VIRTUE, we introduce a large-scale\nSegmentation-and-Scene Caption Retrieval (SCaR) benchmark comprising 1M samples\nthat aims to retrieve the text caption by jointly considering the entity with a\nspecific object and image scene. VIRTUE consistently achieves a\nstate-of-the-art performance with significant improvements across 36 universal\nMMEB (3.1%-8.5%) and five visual-interactive SCaR (15.2%-20.3%) tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86VIRTUE\u6a21\u578b\uff0c\u5c06\u5206\u5272\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u6269\u5c55\u5230\u8868\u793a\u5b66\u4e60\u9886\u57df\uff0c\u652f\u6301\u89c6\u89c9\u4ea4\u4e92\u5f0f\u63d0\u793a\u6765\u6307\u5b9a\u56fe\u50cf\u4e2d\u7684\u611f\u5174\u8da3\u533a\u57df\uff0c\u572836\u4e2a\u901a\u7528MMEB\u4efb\u52a1\u548c5\u4e2a\u89c6\u89c9\u4ea4\u4e92SCaR\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5d4c\u5165\u6a21\u578b\u7f3a\u4e4f\u89c6\u89c9\u4ea4\u4e92\u80fd\u529b\u6765\u6307\u5b9a\u7528\u6237\u611f\u5174\u8da3\u533a\u57df\uff0c\u800c\u751f\u6210\u6a21\u578b\u5df2\u63a2\u7d22\u6b64\u7c7b\u80fd\u529b\u3002\u4e3a\u5d4c\u5165\u6a21\u578b\u6dfb\u52a0\u89c6\u89c9\u4ea4\u4e92\u4e0d\u4ec5\u80fd\u89e3\u9501\u7528\u6237\u610f\u56fe\u672c\u5730\u5316\u5e94\u7528\uff0c\u8fd8\u80fd\u8ba9\u6a21\u578b\u5b66\u4e60\u56fe\u50cf\u4e2d\u7684\u5b9e\u4f53\u7ea7\u4fe1\u606f\u4ee5\u8865\u5145\u5168\u5c40\u8868\u793a\u3002", "method": "\u63d0\u51faVIRTUE\u6a21\u578b\uff0c\u5c06\u5206\u5272\u6a21\u578b\u5904\u7406\u89c6\u89c9\u63d0\u793a\u7684\u80fd\u529b\u4e0e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u4f7f\u5d4c\u5165\u5668\u80fd\u5904\u7406\u590d\u6742\u548c\u6a21\u7cca\u573a\u666f\u3002\u5206\u5272\u6a21\u578b\u53ef\u5904\u7406\u6307\u5411\u56fe\u50cf\u7279\u5b9a\u533a\u57df\u7684\u89c6\u89c9\u63d0\u793a\u3002", "result": "\u5728\u5305\u542b100\u4e07\u6837\u672c\u7684\u5927\u89c4\u6a21SCaR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVIRTUE\u572836\u4e2a\u901a\u7528MMEB\u4efb\u52a1\u4e0a\u63d0\u53473.1%-8.5%\uff0c\u57285\u4e2a\u89c6\u89c9\u4ea4\u4e92SCaR\u4efb\u52a1\u4e0a\u63d0\u534715.2%-20.3%\uff0c\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "VIRTUE\u6210\u529f\u5c06\u5206\u5272\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u6269\u5c55\u5230\u8868\u793a\u5b66\u4e60\u9886\u57df\uff0c\u901a\u8fc7\u89c6\u89c9\u4ea4\u4e92\u663e\u8457\u63d0\u5347\u4e86\u5d4c\u5165\u6a21\u578b\u7684\u6027\u80fd\u548c\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2510.00770", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00770", "abs": "https://arxiv.org/abs/2510.00770", "authors": ["Tianle Ni", "Xiao Chen", "Hamid Sadeghian", "Sami Haddadin"], "title": "Tele-rehabilitation with online skill transfer and adaptation in $\\mathbb{R}^3 \\times \\mathit{S}^3$", "comment": null, "summary": "This paper proposes a tele-teaching framework for the domain of\nrobot-assisted tele-rehabilitation. The system connects two robotic\nmanipulators on therapist and patient side via bilateral teleoperation,\nenabling a therapist to remotely demonstrate rehabilitation exercises that are\nexecuted by the patient-side robot. A 6-DoF Dynamical Movement Primitives\nformulation is employed to jointly encode translational and rotational motions\nin $\\mathbb{R}^3 \\times \\mathit{S}^3$ space, ensuring accurate trajectory\nreproduction. The framework supports smooth transitions between therapist-led\nguidance and patient passive training, while allowing adaptive adjustment of\nmotion. Experiments with 7-DoF manipulators demonstrate the feasibility of the\napproach, highlighting its potential for personalized and remotely supervised\nrehabilitation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u673a\u5668\u4eba\u8f85\u52a9\u8fdc\u7a0b\u5eb7\u590d\u7684\u8fdc\u7a0b\u6559\u5b66\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u8fb9\u9065\u64cd\u4f5c\u8fde\u63a5\u6cbb\u7597\u5e08\u548c\u60a3\u8005\u7aef\u7684\u673a\u5668\u4eba\uff0c\u5b9e\u73b0\u5eb7\u590d\u8bad\u7ec3\u7684\u8fdc\u7a0b\u6f14\u793a\u548c\u6267\u884c\u3002", "motivation": "\u4e3a\u673a\u5668\u4eba\u8f85\u52a9\u8fdc\u7a0b\u5eb7\u590d\u9886\u57df\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5b9e\u73b0\u6cbb\u7597\u5e08\u8fdc\u7a0b\u6307\u5bfc\u3001\u60a3\u8005\u88ab\u52a8\u8bad\u7ec3\uff0c\u5e76\u652f\u6301\u4e2a\u6027\u5316\u8c03\u6574\u7684\u8fdc\u7a0b\u6559\u5b66\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u53cc\u8fb9\u9065\u64cd\u4f5c\u8fde\u63a5\u6cbb\u7597\u5e08\u548c\u60a3\u8005\u7aef\u7684\u673a\u5668\u4eba\uff0c\u91c7\u75286\u81ea\u7531\u5ea6\u52a8\u6001\u8fd0\u52a8\u57fa\u5143\u5728\u211d\u00b3\u00d7S\u00b3\u7a7a\u95f4\u4e2d\u8054\u5408\u7f16\u7801\u5e73\u79fb\u548c\u65cb\u8f6c\u8fd0\u52a8\uff0c\u786e\u4fdd\u51c6\u786e\u7684\u8f68\u8ff9\u518d\u73b0\u3002", "result": "\u57287\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u7cfb\u7edf\u80fd\u591f\u5b9e\u73b0\u6cbb\u7597\u5e08\u5f15\u5bfc\u548c\u60a3\u8005\u88ab\u52a8\u8bad\u7ec3\u4e4b\u95f4\u7684\u5e73\u6ed1\u8fc7\u6e21\uff0c\u5e76\u652f\u6301\u8fd0\u52a8\u7684\u81ea\u9002\u5e94\u8c03\u6574\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u5728\u4e2a\u6027\u5316\u8fdc\u7a0b\u76d1\u7763\u5eb7\u590d\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u8fdc\u7a0b\u5eb7\u590d\u6cbb\u7597\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00942", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00942", "abs": "https://arxiv.org/abs/2510.00942", "authors": ["Reza Vafaee", "Kian Behzad", "Milad Siami", "Luca Carlone", "Ali Jadbabaie"], "title": "Non-submodular Visual Attention for Robot Navigation", "comment": "22 pages; Accepted to appear in IEEE Transactions on Robotics (T-RO)", "summary": "This paper presents a task-oriented computational framework to enhance\nVisual-Inertial Navigation (VIN) in robots, addressing challenges such as\nlimited time and energy resources. The framework strategically selects visual\nfeatures using a Mean Squared Error (MSE)-based, non-submodular objective\nfunction and a simplified dynamic anticipation model. To address the\nNP-hardness of this problem, we introduce four polynomial-time approximation\nalgorithms: a classic greedy method with constant-factor guarantees; a low-rank\ngreedy variant that significantly reduces computational complexity; a\nrandomized greedy sampler that balances efficiency and solution quality; and a\nlinearization-based selector based on a first-order Taylor expansion for\nnear-constant-time execution. We establish rigorous performance bounds by\nleveraging submodularity ratios, curvature, and element-wise curvature\nanalyses. Extensive experiments on both standardized benchmarks and a custom\ncontrol-aware platform validate our theoretical results, demonstrating that\nthese methods achieve strong approximation guarantees while enabling real-time\ndeployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4efb\u52a1\u5bfc\u5411\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u6218\u7565\u6027\u5730\u9009\u62e9\u89c6\u89c9\u7279\u5f81\u6765\u589e\u5f3a\u673a\u5668\u4eba\u89c6\u89c9\u60ef\u6027\u5bfc\u822a\uff0c\u89e3\u51b3\u4e86\u65f6\u95f4\u548c\u80fd\u91cf\u8d44\u6e90\u53d7\u9650\u7684\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5728\u89c6\u89c9\u60ef\u6027\u5bfc\u822a\u4e2d\u9762\u4e34\u7684\u65f6\u95f4\u548c\u80fd\u91cf\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff0c\u63d0\u9ad8\u5bfc\u822a\u6548\u7387\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5747\u65b9\u8bef\u5dee\u7684\u975e\u5b50\u6a21\u76ee\u6807\u51fd\u6570\u548c\u7b80\u5316\u52a8\u6001\u9884\u6d4b\u6a21\u578b\u6765\u9009\u62e9\u89c6\u89c9\u7279\u5f81\u3002\u63d0\u51fa\u4e86\u56db\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u7b97\u6cd5\uff1a\u7ecf\u5178\u8d2a\u5a6a\u6cd5\u3001\u4f4e\u79e9\u8d2a\u5a6a\u53d8\u4f53\u3001\u968f\u673a\u8d2a\u5a6a\u91c7\u6837\u5668\u548c\u57fa\u4e8e\u4e00\u9636\u6cf0\u52d2\u5c55\u5f00\u7684\u7ebf\u6027\u5316\u9009\u62e9\u5668\u3002", "result": "\u5728\u6807\u51c6\u5316\u57fa\u51c6\u548c\u81ea\u5b9a\u4e49\u63a7\u5236\u611f\u77e5\u5e73\u53f0\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u540c\u65f6\u652f\u6301\u5b9e\u65f6\u90e8\u7f72\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6709\u6548\u7684\u7279\u5f81\u9009\u62e9\u548c\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u5f3a\u8fd1\u4f3c\u4fdd\u8bc1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5b9e\u65f6\u90e8\u7f72\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u60ef\u6027\u5bfc\u822a\u7684\u6027\u80fd\u3002"}}
{"id": "2510.00552", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.00552", "abs": "https://arxiv.org/abs/2510.00552", "authors": ["Leopold M\u00fcller", "Joshua Holstein", "Sarah Bause", "Gerhard Satzger", "Niklas K\u00fchl"], "title": "Data Quality Challenges in Retrieval-Augmented Generation", "comment": "Preprint version. Accepted for presentation at the International\n  Conference on Information Systems (ICIS 2025). Please cite the published\n  version when available", "summary": "Organizations increasingly adopt Retrieval-Augmented Generation (RAG) to\nenhance Large Language Models with enterprise-specific knowledge. However,\ncurrent data quality (DQ) frameworks have been primarily developed for static\ndatasets, and only inadequately address the dynamic, multi-stage nature of RAG\nsystems. This study aims to develop DQ dimensions for this new type of AI-based\nsystems. We conduct 16 semi-structured interviews with practitioners of leading\nIT service companies. Through a qualitative content analysis, we inductively\nderive 15 distinct DQ dimensions across the four processing stages of RAG\nsystems: data extraction, data transformation, prompt & search, and generation.\nOur findings reveal that (1) new dimensions have to be added to traditional DQ\nframeworks to also cover RAG contexts; (2) these new dimensions are\nconcentrated in early RAG steps, suggesting the need for front-loaded quality\nmanagement strategies, and (3) DQ issues transform and propagate through the\nRAG pipeline, necessitating a dynamic, step-aware approach to quality\nmanagement.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u9488\u5bf9RAG\u7cfb\u7edf\u7684\u6570\u636e\u8d28\u91cf\u7ef4\u5ea6\uff0c\u901a\u8fc7\u8bbf\u8c08IT\u670d\u52a1\u516c\u53f8\u4ece\u4e1a\u8005\uff0c\u8bc6\u522b\u51fa15\u4e2a\u8de8\u56db\u4e2a\u5904\u7406\u9636\u6bb5\u7684DQ\u7ef4\u5ea6\uff0c\u63ed\u793a\u4e86\u4f20\u7edfDQ\u6846\u67b6\u9700\u8981\u6269\u5c55\u4ee5\u9002\u5e94RAG\u7cfb\u7edf\u7684\u52a8\u6001\u7279\u6027\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u8d28\u91cf\u6846\u67b6\u4e3b\u8981\u9488\u5bf9\u9759\u6001\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9RAG\u7cfb\u7edf\u7684\u52a8\u6001\u591a\u9636\u6bb5\u7279\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u8fd9\u7c7bAI\u7cfb\u7edf\u7684DQ\u7ef4\u5ea6\u3002", "method": "\u5bf916\u5bb6\u9886\u5148IT\u670d\u52a1\u516c\u53f8\u7684\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u901a\u8fc7\u5b9a\u6027\u5185\u5bb9\u5206\u6790\u5f52\u7eb3\u63a8\u5bfc\u51faRAG\u7cfb\u7edf\u7684DQ\u7ef4\u5ea6\u3002", "result": "\u8bc6\u522b\u51fa15\u4e2a\u4e0d\u540c\u7684DQ\u7ef4\u5ea6\uff0c\u5206\u5e03\u5728RAG\u7cfb\u7edf\u7684\u56db\u4e2a\u5904\u7406\u9636\u6bb5\uff1a\u6570\u636e\u63d0\u53d6\u3001\u6570\u636e\u8f6c\u6362\u3001\u63d0\u793a\u4e0e\u641c\u7d22\u3001\u751f\u6210\u3002\u53d1\u73b0\u65b0\u7ef4\u5ea6\u4e3b\u8981\u96c6\u4e2d\u5728\u65e9\u671f\u9636\u6bb5\uff0cDQ\u95ee\u9898\u4f1a\u5728\u7ba1\u9053\u4e2d\u8f6c\u5316\u548c\u4f20\u64ad\u3002", "conclusion": "\u4f20\u7edfDQ\u6846\u67b6\u9700\u8981\u6dfb\u52a0\u65b0\u7ef4\u5ea6\u4ee5\u8986\u76d6RAG\u73af\u5883\uff0c\u9700\u8981\u91c7\u7528\u524d\u7f6e\u5f0f\u8d28\u91cf\u7ba1\u7406\u7b56\u7565\u548c\u52a8\u6001\u7684\u3001\u9636\u6bb5\u611f\u77e5\u7684\u8d28\u91cf\u7ba1\u7406\u65b9\u6cd5\u3002"}}
{"id": "2510.00783", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00783", "abs": "https://arxiv.org/abs/2510.00783", "authors": ["Thanh Nguyen Canh", "Haolan Zhang", "Xiem HoangVan", "Nak Young Chong"], "title": "Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions", "comment": null, "summary": "Semantic Simultaneous Localization and Mapping (SLAM) is a critical area of\nresearch within robotics and computer vision, focusing on the simultaneous\nlocalization of robotic systems and associating semantic information to\nconstruct the most accurate and complete comprehensive model of the surrounding\nenvironment. Since the first foundational work in Semantic SLAM appeared more\nthan two decades ago, this field has received increasing attention across\nvarious scientific communities. Despite its significance, the field lacks\ncomprehensive surveys encompassing recent advances and persistent challenges.\nIn response, this study provides a thorough examination of the state-of-the-art\nof Semantic SLAM techniques, with the aim of illuminating current trends and\nkey obstacles. Beginning with an in-depth exploration of the evolution of\nvisual SLAM, this study outlines its strengths and unique characteristics,\nwhile also critically assessing previous survey literature. Subsequently, a\nunified problem formulation and evaluation of the modular solution framework is\nproposed, which divides the problem into discrete stages, including visual\nlocalization, semantic feature extraction, mapping, data association, and loop\nclosure optimization. Moreover, this study investigates alternative\nmethodologies such as deep learning and the utilization of large language\nmodels, alongside a review of relevant research about contemporary SLAM\ndatasets. Concluding with a discussion on potential future research directions,\nthis study serves as a comprehensive resource for researchers seeking to\nnavigate the complex landscape of Semantic SLAM.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u7bc7\u5173\u4e8e\u8bed\u4e49SLAM\u7684\u7efc\u8ff0\u6027\u7814\u7a76\u8bba\u6587\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u5386\u7a0b\u3001\u73b0\u6709\u6280\u672f\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u8bed\u4e49SLAM\u9886\u57df\u7f3a\u4e4f\u5168\u9762\u7684\u7efc\u8ff0\u6587\u732e\u6765\u6db5\u76d6\u6700\u65b0\u8fdb\u5c55\u548c\u6301\u7eed\u6311\u6218\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u95ee\u9898\u8868\u8ff0\u548c\u6a21\u5757\u5316\u89e3\u51b3\u65b9\u6848\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u89c6\u89c9\u5b9a\u4f4d\u3001\u8bed\u4e49\u7279\u5f81\u63d0\u53d6\u3001\u5efa\u56fe\u3001\u6570\u636e\u5173\u8054\u548c\u95ed\u73af\u4f18\u5316\u7b49\u9636\u6bb5\uff0c\u5e76\u63a2\u8ba8\u4e86\u6df1\u5ea6\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7b49\u66ff\u4ee3\u65b9\u6cd5\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9\u8bed\u4e49SLAM\u6280\u672f\u73b0\u72b6\u7684\u5168\u9762\u68c0\u67e5\uff0c\u9610\u660e\u4e86\u5f53\u524d\u8d8b\u52bf\u548c\u5173\u952e\u969c\u788d\uff0c\u5e76\u56de\u987e\u4e86\u76f8\u5173SLAM\u6570\u636e\u96c6\u7684\u7814\u7a76\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7814\u7a76\u4eba\u5458\u5bfc\u822a\u8bed\u4e49SLAM\u590d\u6742\u9886\u57df\u63d0\u4f9b\u4e86\u5168\u9762\u8d44\u6e90\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u6f5c\u5728\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.00960", "categories": ["cs.AI", "cs.NE", "cs.SY", "eess.SY", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.00960", "abs": "https://arxiv.org/abs/2510.00960", "authors": ["Miha O\u017ebot", "Igor \u0160krjanc", "Vitomir \u0160truc"], "title": "A Neuro-Fuzzy System for Interpretable Long-Term Stock Market Forecasting", "comment": "Published in: ERK 2025 -- 34th International Electrotechnical and\n  Computer Science Conference, Portoro\\v{z}, Slovenia, Sept. 25--26, 2025.\n  Proceedings published by Dru\\v{s}tvo Slovenska sekcija IEEE. ISSN: 2591-0442\n  (online). 4 pages, 2 figures", "summary": "In the complex landscape of multivariate time series forecasting, achieving\nboth accuracy and interpretability remains a significant challenge. This paper\nintroduces the Fuzzy Transformer (Fuzzformer), a novel recurrent neural network\narchitecture combined with multi-head self-attention and fuzzy inference\nsystems to analyze multivariate stock market data and conduct long-term time\nseries forecasting. The method leverages LSTM networks and temporal attention\nto condense multivariate data into interpretable features suitable for fuzzy\ninference systems. The resulting architecture offers comparable forecasting\nperformance to conventional models such as ARIMA and LSTM while providing\nmeaningful information flow within the network. The method was examined on the\nreal world stock market index S\\&P500. Initial results show potential for\ninterpretable forecasting and identify current performance tradeoffs,\nsuggesting practical application in understanding and forecasting stock market\nbehavior.", "AI": {"tldr": "\u63d0\u51faFuzzformer\u6a21\u578b\uff0c\u7ed3\u5408\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u3001\u591a\u5934\u81ea\u6ce8\u610f\u529b\u548c\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u591a\u53d8\u91cf\u80a1\u7968\u5e02\u573a\u6570\u636e\u5206\u6790\u548c\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\uff0c\u540c\u65f6\u5b9e\u73b0\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u4f7f\u7528LSTM\u7f51\u7edc\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u5c06\u591a\u53d8\u91cf\u6570\u636e\u538b\u7f29\u4e3a\u9002\u5408\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u7ed3\u5408\u591a\u5934\u81ea\u6ce8\u610f\u529b\u548c\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u6784\u5efaFuzzformer\u67b6\u6784\u3002", "result": "\u5728S&P500\u80a1\u7968\u5e02\u573a\u6307\u6570\u4e0a\u7684\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6a21\u578b\u4e0e\u4f20\u7edf\u6a21\u578b\uff08\u5982ARIMA\u548cLSTM\uff09\u5177\u6709\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u7f51\u7edc\u5185\u90e8\u6709\u610f\u4e49\u7684\u4fe1\u606f\u6d41\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u9884\u6d4b\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u867d\u7136\u5b58\u5728\u6027\u80fd\u6743\u8861\uff0c\u4f46\u5728\u7406\u89e3\u548c\u9884\u6d4b\u80a1\u7968\u5e02\u573a\u884c\u4e3a\u65b9\u9762\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.00565", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00565", "abs": "https://arxiv.org/abs/2510.00565", "authors": ["Shojiro Yamabe", "Jun Sakuma"], "title": "Toward Safer Diffusion Language Models: Discovery and Mitigation of Priming Vulnerability", "comment": null, "summary": "Diffusion language models (DLMs) generate tokens in parallel through\niterative denoising, which can reduce latency and enable bidirectional\nconditioning. However, the safety risks posed by jailbreak attacks that exploit\nthis inference mechanism are not well understood. In this paper, we reveal that\nDLMs have a critical vulnerability stemming from their iterative denoising\nprocess and propose a countermeasure. Specifically, our investigation shows\nthat if an affirmative token for a harmful query appears at an intermediate\nstep, subsequent denoising can be steered toward a harmful response even in\naligned models. As a result, simply injecting such affirmative tokens can\nreadily bypass the safety guardrails. Furthermore, we demonstrate that the\nvulnerability allows existing optimization-based jailbreak attacks to succeed\non DLMs. Building on this analysis, we propose a novel safety alignment method\ntailored to DLMs that trains models to generate safe responses from\ncontaminated intermediate states that contain affirmative tokens. Our\nexperiments indicate that the proposed method significantly mitigates the\nvulnerability with minimal impact on task performance. Furthermore, our method\nimproves robustness against conventional jailbreak attacks. Our work\nunderscores the need for DLM-specific safety research.", "AI": {"tldr": "\u6269\u6563\u8bed\u8a00\u6a21\u578b(DLMs)\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u5728\u4e2d\u95f4\u6b65\u9aa4\u6ce8\u5165\u80af\u5b9a\u6027\u4ee4\u724c\u6765\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9DLMs\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u6765\u7f13\u89e3\u6b64\u6f0f\u6d1e\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u5e76\u884c\u8fed\u4ee3\u53bb\u566a\u751f\u6210\u4ee4\u724c\uff0c\u8fd9\u79cd\u63a8\u7406\u673a\u5236\u53ef\u80fd\u5e26\u6765\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u7279\u522b\u662f\u8d8a\u72f1\u653b\u51fb\u5229\u7528\u8fd9\u79cd\u673a\u5236\u7684\u5b89\u5168\u6f0f\u6d1e\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u7814\u7a76\u53d1\u73b0\u5982\u679c\u6709\u5bb3\u67e5\u8be2\u7684\u80af\u5b9a\u6027\u4ee4\u724c\u51fa\u73b0\u5728\u4e2d\u95f4\u6b65\u9aa4\uff0c\u540e\u7eed\u53bb\u566a\u8fc7\u7a0b\u53ef\u80fd\u88ab\u5f15\u5bfc\u751f\u6210\u6709\u5bb3\u54cd\u5e94\u3002\u57fa\u4e8e\u6b64\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9DLMs\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\uff0c\u8bad\u7ec3\u6a21\u578b\u4ece\u5305\u542b\u80af\u5b9a\u6027\u4ee4\u724c\u7684\u6c61\u67d3\u4e2d\u95f4\u72b6\u6001\u751f\u6210\u5b89\u5168\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u7f13\u89e3\u4e86\u6f0f\u6d1e\uff0c\u5bf9\u4efb\u52a1\u6027\u80fd\u5f71\u54cd\u6700\u5c0f\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u5bf9\u4f20\u7edf\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u7279\u5b9a\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u9488\u5bf9\u6027\u7684\u5b89\u5168\u7814\u7a76\uff0c\u63d0\u51fa\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86DLMs\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2510.00814", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00814", "abs": "https://arxiv.org/abs/2510.00814", "authors": ["Kai Tang", "Dipankar Bhattacharya", "Hang Xu", "Fuyuki Tokuda", "Norman C. Tien", "Kazuhiro Kosuge"], "title": "RTFF: Random-to-Target Fabric Flattening Policy using Dual-Arm Manipulator", "comment": "9 pages, 6 figures, conference", "summary": "Robotic fabric manipulation in garment production for sewing, cutting, and\nironing requires reliable flattening and alignment, yet remains challenging due\nto fabric deformability, effectively infinite degrees of freedom, and frequent\nocclusions from wrinkles, folds, and the manipulator's End-Effector (EE) and\narm. To address these issues, this paper proposes the first Random-to-Target\nFabric Flattening (RTFF) policy, which aligns a random wrinkled fabric state to\nan arbitrary wrinkle-free target state. The proposed policy adopts a hybrid\nImitation Learning-Visual Servoing (IL-VS) framework, where IL learns with\nexplicit fabric models for coarse alignment of the wrinkled fabric toward a\nwrinkle-free state near the target, and VS ensures fine alignment to the\ntarget. Central to this framework is a template-based mesh that offers precise\ntarget state representation, wrinkle-aware geometry prediction, and consistent\nvertex correspondence across RTFF manipulation steps, enabling robust\nmanipulation and seamless IL-VS switching. Leveraging the power of mesh, a\nnovel IL solution for RTFF-Mesh Action Chunking Transformer (MACT)-is then\nproposed by conditioning the mesh information into a Transformer-based policy.\nThe RTFF policy is validated on a real dual-arm tele-operation system, showing\nzero-shot alignment to different targets, high accuracy, and strong\ngeneralization across fabrics and scales. Project website:\nhttps://kaitang98.github.io/RTFF_Policy/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u968f\u673a\u5230\u76ee\u6807\u7ec7\u7269\u5e73\u6574\u7b56\u7565\uff0c\u91c7\u7528\u6df7\u5408\u6a21\u4eff\u5b66\u4e60-\u89c6\u89c9\u4f3a\u670d\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u6a21\u677f\u7684\u7f51\u683c\u5b9e\u73b0\u7cbe\u786e\u76ee\u6807\u72b6\u6001\u8868\u793a\u548c\u4e00\u81f4\u7684\u9876\u70b9\u5bf9\u5e94\uff0c\u5728\u771f\u5b9e\u53cc\u81c2\u9065\u64cd\u4f5c\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u4e86\u96f6\u6837\u672c\u5bf9\u9f50\u3001\u9ad8\u7cbe\u5ea6\u548c\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u7ec7\u7269\u751f\u4ea7\u4e2d\u673a\u5668\u4eba\u64cd\u4f5c\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u7ec7\u7269\u53ef\u53d8\u5f62\u6027\u3001\u65e0\u9650\u81ea\u7531\u5ea6\u4ee5\u53ca\u8936\u76b1\u3001\u6298\u53e0\u548c\u673a\u68b0\u81c2\u906e\u6321\u7b49\u95ee\u9898\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u7ec7\u7269\u5e73\u6574\u548c\u5bf9\u9f50\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6a21\u4eff\u5b66\u4e60-\u89c6\u89c9\u4f3a\u670d\u6846\u67b6\uff0c\u5176\u4e2d\u6a21\u4eff\u5b66\u4e60\u4f7f\u7528\u663e\u5f0f\u7ec7\u7269\u6a21\u578b\u8fdb\u884c\u7c97\u7565\u5bf9\u9f50\uff0c\u89c6\u89c9\u4f3a\u670d\u786e\u4fdd\u7cbe\u7ec6\u5bf9\u9f50\uff1b\u63d0\u51fa\u57fa\u4e8e\u6a21\u677f\u7684\u7f51\u683c\u8868\u793a\u548cRTFF-Mesh Action Chunking Transformer\u7b56\u7565\u3002", "result": "\u5728\u771f\u5b9e\u53cc\u81c2\u9065\u64cd\u4f5c\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u96f6\u6837\u672c\u5bf9\u9f50\u4e0d\u540c\u76ee\u6807\u3001\u9ad8\u7cbe\u5ea6\u548c\u8de8\u7ec7\u7269\u4e0e\u5c3a\u5ea6\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684RTFF\u7b56\u7565\u6210\u529f\u89e3\u51b3\u4e86\u7ec7\u7269\u5e73\u6574\u548c\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u4e3a\u673a\u5668\u4eba\u7ec7\u7269\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00995", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00995", "abs": "https://arxiv.org/abs/2510.00995", "authors": ["Jacob Moore", "Phil Tokumaru", "Ian Reid", "Brandon Sutherland", "Joseph Ritchie", "Gabe Snow", "Tim McLain"], "title": "ROSflight 2.0: Lean ROS 2-Based Autopilot for Unmanned Aerial Vehicles", "comment": "To be submitted to the 2026 IEEE International Conference on Robotics\n  and Automation in Vienna, Austria", "summary": "ROSflight is a lean, open-source autopilot ecosystem for unmanned aerial\nvehicles (UAVs). Designed by researchers for researchers, it is built to lower\nthe barrier to entry to UAV research and accelerate the transition from\nsimulation to hardware experiments by maintaining a lean (not full-featured),\nwell-documented, and modular codebase. This publication builds on previous\ntreatments and describes significant additions to the architecture that improve\nthe modularity and usability of ROSflight, including the transition from ROS 1\nto ROS 2, supported hardware, low-level actuator mixing, and the simulation\nenvironment. We believe that these changes improve the usability of ROSflight\nand enable ROSflight to accelerate research in areas like advanced-air\nmobility. Hardware results are provided, showing that ROSflight is able to\ncontrol a multirotor over a serial connection at 400 Hz while closing all\ncontrol loops on the companion computer.", "AI": {"tldr": "ROSflight\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5f00\u6e90\u65e0\u4eba\u673a\u81ea\u52a8\u9a7e\u9a76\u751f\u6001\u7cfb\u7edf\uff0c\u4e13\u4e3a\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\uff0c\u65e8\u5728\u964d\u4f4e\u65e0\u4eba\u673a\u7814\u7a76\u95e8\u69db\u5e76\u52a0\u901f\u4ece\u4eff\u771f\u5230\u786c\u4ef6\u5b9e\u9a8c\u7684\u8fc7\u6e21\u3002", "motivation": "\u964d\u4f4e\u65e0\u4eba\u673a\u7814\u7a76\u7684\u5165\u95e8\u95e8\u69db\uff0c\u901a\u8fc7\u7ef4\u62a4\u7cbe\u7b80\u3001\u6587\u6863\u5b8c\u5584\u548c\u6a21\u5757\u5316\u7684\u4ee3\u7801\u5e93\uff0c\u52a0\u901f\u4ece\u4eff\u771f\u5230\u786c\u4ef6\u5b9e\u9a8c\u7684\u8fc7\u6e21\u8fc7\u7a0b\u3002", "method": "\u4eceROS 1\u8fc7\u6e21\u5230ROS 2\uff0c\u6539\u8fdb\u67b6\u6784\u7684\u6a21\u5757\u5316\u548c\u53ef\u7528\u6027\uff0c\u5305\u62ec\u652f\u6301\u786c\u4ef6\u3001\u4f4e\u7ea7\u6267\u884c\u5668\u6df7\u5408\u548c\u4eff\u771f\u73af\u5883\u3002", "result": "\u786c\u4ef6\u7ed3\u679c\u663e\u793a\uff0cROSflight\u80fd\u591f\u901a\u8fc7\u4e32\u884c\u8fde\u63a5\u4ee5400Hz\u7684\u9891\u7387\u63a7\u5236\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\uff0c\u540c\u65f6\u5c06\u6240\u6709\u63a7\u5236\u56de\u8def\u5728\u914d\u5957\u8ba1\u7b97\u673a\u4e0a\u95ed\u5408\u3002", "conclusion": "\u8fd9\u4e9b\u6539\u8fdb\u63d0\u5347\u4e86ROSflight\u7684\u53ef\u7528\u6027\uff0c\u4f7f\u5176\u80fd\u591f\u52a0\u901f\u5148\u8fdb\u7a7a\u4e2d\u673a\u52a8\u6027\u7b49\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2510.00615", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00615", "abs": "https://arxiv.org/abs/2510.00615", "authors": ["Minki Kang", "Wei-Ning Chen", "Dongge Han", "Huseyin A. Inan", "Lukas Wutschitz", "Yanzhi Chen", "Robert Sim", "Saravan Rajmohan"], "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "comment": "Preprint", "summary": "Large language models (LLMs) are increasingly deployed as agents in dynamic,\nreal-world environments, where success requires both reasoning and effective\ntool use. A central challenge for agentic tasks is the growing context length,\nas agents must accumulate long histories of actions and observations. This\nexpansion raises costs and reduces efficiency in long-horizon tasks, yet prior\nwork on context compression has mostly focused on single-step tasks or narrow\napplications. We introduce Agent Context Optimization (ACON), a unified\nframework that optimally compresses both environment observations and\ninteraction histories into concise yet informative condensations. ACON\nleverages compression guideline optimization in natural language space: given\npaired trajectories where full context succeeds but compressed context fails,\ncapable LLMs analyze the causes of failure, and the compression guideline is\nupdated accordingly. Furthermore, we propose distilling the optimized LLM\ncompressor into smaller models to reduce the overhead of the additional module.\nExperiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON\nreduces memory usage by 26-54% (peak tokens) while largely preserving task\nperformance, preserves over 95% of accuracy when distilled into smaller\ncompressors, and enhances smaller LMs as long-horizon agents with up to 46%\nperformance improvement.", "AI": {"tldr": "ACON\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u81ea\u7136\u8bed\u8a00\u538b\u7f29\u6307\u5357\u6765\u538b\u7f29\u73af\u5883\u89c2\u5bdf\u548c\u4ea4\u4e92\u5386\u53f2\uff0c\u51cf\u5c1126-54%\u7684\u5185\u5b58\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u968f\u7740LLM\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4f5c\u4e3a\u4ee3\u7406\u90e8\u7f72\uff0c\u957f\u4e0a\u4e0b\u6587\u5e26\u6765\u4e86\u6210\u672c\u548c\u6548\u7387\u95ee\u9898\uff0c\u800c\u73b0\u6709\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u6b65\u4efb\u52a1\u6216\u72ed\u7a84\u5e94\u7528\u3002", "method": "ACON\u5229\u7528\u538b\u7f29\u6307\u5357\u4f18\u5316\uff1a\u5f53\u5b8c\u6574\u4e0a\u4e0b\u6587\u6210\u529f\u4f46\u538b\u7f29\u4e0a\u4e0b\u6587\u5931\u8d25\u65f6\uff0cLLM\u5206\u6790\u5931\u8d25\u539f\u56e0\u5e76\u76f8\u5e94\u66f4\u65b0\u538b\u7f29\u6307\u5357\uff0c\u7136\u540e\u5c06\u4f18\u5316\u7684LLM\u538b\u7f29\u5668\u84b8\u998f\u5230\u66f4\u5c0f\u7684\u6a21\u578b\u4e2d\u3002", "result": "\u5728AppWorld\u3001OfficeBench\u548cMulti-objective QA\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cACON\u51cf\u5c1126-54%\u7684\u5185\u5b58\u4f7f\u7528\uff08\u5cf0\u503ctoken\uff09\uff0c\u540c\u65f6\u57fa\u672c\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\uff0c\u84b8\u998f\u5230\u66f4\u5c0f\u538b\u7f29\u5668\u65f6\u4fdd\u630195%\u4ee5\u4e0a\u51c6\u786e\u7387\uff0c\u5e76\u5c06\u8f83\u5c0fLM\u4f5c\u4e3a\u957f\u89c6\u91ce\u4ee3\u7406\u7684\u6027\u80fd\u63d0\u5347\u8fbe46%\u3002", "conclusion": "ACON\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u957f\u4e0a\u4e0b\u6587\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u7684\u538b\u7f29\u6846\u67b6\u5728\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u7684\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u5e76\u80fd\u84b8\u998f\u5230\u66f4\u5c0f\u7684\u6a21\u578b\u4e2d\u3002"}}
{"id": "2510.01041", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.01041", "abs": "https://arxiv.org/abs/2510.01041", "authors": ["Ian Reid", "Joseph Ritchie", "Jacob Moore", "Brandon Sutherland", "Gabe Snow", "Phillip Tokumaru", "Tim McLain"], "title": "ROSplane 2.0: A Fixed-Wing Autopilot for Research", "comment": null, "summary": "Unmanned aerial vehicle (UAV) research requires the integration of\ncutting-edge technology into existing autopilot frameworks. This process can be\narduous, requiring extensive resources, time, and detailed knowledge of the\nexisting system. ROSplane is a lean, open-source fixed-wing autonomy stack\nbuilt by researchers for researchers. It is designed to accelerate research by\nproviding clearly defined interfaces with an easily modifiable framework.\nPowered by ROS 2, ROSplane allows for rapid integration of low or high-level\ncontrol, path planning, or estimation algorithms. A focus on lean, easily\nunderstood code and extensive documentation lowers the barrier to entry for\nresearchers. Recent developments to ROSplane improve its capacity to accelerate\nUAV research, including the transition from ROS 1 to ROS 2, enhanced estimation\nand control algorithms, increased modularity, and an improved aerodynamic\nmodeling pipeline. This aerodynamic modeling pipeline significantly reduces the\neffort of transitioning from simulation to real-world testing without requiring\nexpensive system identification or computational fluid dynamics tools.\nROSplane's architecture reduces the effort required to integrate new research\ntools and methods, expediting hardware experimentation.", "AI": {"tldr": "ROSplane\u662f\u4e00\u4e2a\u5f00\u6e90\u56fa\u5b9a\u7ffc\u65e0\u4eba\u673a\u81ea\u4e3b\u63a7\u5236\u6808\uff0c\u65e8\u5728\u52a0\u901f\u65e0\u4eba\u673a\u7814\u7a76\uff0c\u63d0\u4f9b\u6e05\u6670\u7684\u63a5\u53e3\u548c\u6613\u4e8e\u4fee\u6539\u7684\u6846\u67b6\uff0c\u652f\u6301\u5feb\u901f\u96c6\u6210\u63a7\u5236\u3001\u8def\u5f84\u89c4\u5212\u548c\u4f30\u8ba1\u7b97\u6cd5\u3002", "motivation": "\u65e0\u4eba\u673a\u7814\u7a76\u9700\u8981\u5c06\u524d\u6cbf\u6280\u672f\u96c6\u6210\u5230\u73b0\u6709\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\u4e2d\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u901a\u5e38\u9700\u8981\u5927\u91cf\u8d44\u6e90\u3001\u65f6\u95f4\u548c\u7cfb\u7edf\u77e5\u8bc6\u3002ROSplane\u65e8\u5728\u964d\u4f4e\u7814\u7a76\u95e8\u69db\uff0c\u52a0\u901f\u7814\u7a76\u8fdb\u7a0b\u3002", "method": "\u57fa\u4e8eROS 2\u6784\u5efa\uff0c\u63d0\u4f9b\u6e05\u6670\u5b9a\u4e49\u7684\u63a5\u53e3\u548c\u6613\u4e8e\u4fee\u6539\u7684\u6846\u67b6\uff0c\u652f\u6301\u5feb\u901f\u96c6\u6210\u5404\u79cd\u7b97\u6cd5\u3002\u91c7\u7528\u7cbe\u7b80\u6613\u61c2\u7684\u4ee3\u7801\u548c\u8be6\u7ec6\u6587\u6863\uff0c\u63d0\u9ad8\u6a21\u5757\u5316\u7a0b\u5ea6\uff0c\u6539\u8fdb\u6c14\u52a8\u5efa\u6a21\u6d41\u7a0b\u3002", "result": "ROSplane\u6210\u529f\u4eceROS 1\u8fc1\u79fb\u5230ROS 2\uff0c\u589e\u5f3a\u4e86\u4f30\u8ba1\u548c\u63a7\u5236\u7b97\u6cd5\uff0c\u63d0\u9ad8\u4e86\u6a21\u5757\u5316\u7a0b\u5ea6\uff0c\u6539\u8fdb\u4e86\u6c14\u52a8\u5efa\u6a21\u6d41\u7a0b\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4ece\u4eff\u771f\u5230\u771f\u5b9e\u6d4b\u8bd5\u7684\u8f6c\u6362\u5de5\u4f5c\u91cf\u3002", "conclusion": "ROSplane\u67b6\u6784\u663e\u8457\u51cf\u5c11\u4e86\u96c6\u6210\u65b0\u7814\u7a76\u5de5\u5177\u548c\u65b9\u6cd5\u6240\u9700\u7684\u5de5\u4f5c\u91cf\uff0c\u52a0\u901f\u4e86\u786c\u4ef6\u5b9e\u9a8c\u8fdb\u7a0b\uff0c\u4e3a\u65e0\u4eba\u673a\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7814\u7a76\u5e73\u53f0\u3002"}}
{"id": "2510.00620", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00620", "abs": "https://arxiv.org/abs/2510.00620", "authors": ["Rosni Vasu", "Peter Jansen", "Pao Siangliulue", "Cristina Sarasua", "Abraham Bernstein", "Peter Clark", "Bhavana Dalvi Mishra"], "title": "HARPA: A Testability-Driven, Literature-Grounded Framework for Research Ideation", "comment": "10 pages (main), 65 pages total", "summary": "While there has been a surge of interest in automated scientific discovery\n(ASD), especially with the emergence of LLMs, it remains challenging for tools\nto generate hypotheses that are both testable and grounded in the scientific\nliterature. Additionally, existing ideation tools are not adaptive to prior\nexperimental outcomes. We developed HARPA to address these challenges by\nincorporating the ideation workflow inspired by human researchers. HARPA first\nidentifies emerging research trends through literature mining, then explores\nhypothesis design spaces, and finally converges on precise, testable hypotheses\nby pinpointing research gaps and justifying design choices. Our evaluations\nshow that HARPA-generated hypothesis-driven research proposals perform\ncomparably to a strong baseline AI-researcher across most qualitative\ndimensions (e.g., specificity, novelty, overall quality), but achieve\nsignificant gains in feasibility(+0.78, p$<0.05$, bootstrap) and groundedness\n(+0.85, p$<0.01$, bootstrap) on a 10-point Likert scale. When tested with the\nASD agent (CodeScientist), HARPA produced more successful executions (20 vs. 11\nout of 40) and fewer failures (16 vs. 21 out of 40), showing that expert\nfeasibility judgments track with actual execution success. Furthermore, to\nsimulate how researchers continuously refine their understanding of what\nhypotheses are both testable and potentially interesting from experience, HARPA\nlearns a reward model that scores new hypotheses based on prior experimental\noutcomes, achieving approx. a 28\\% absolute gain over HARPA's untrained\nbaseline scorer. Together, these methods represent a step forward in the field\nof AI-driven scientific discovery.", "AI": {"tldr": "HARPA\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\uff0c\u901a\u8fc7\u6587\u732e\u6316\u6398\u8bc6\u522b\u7814\u7a76\u8d8b\u52bf\uff0c\u63a2\u7d22\u5047\u8bbe\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5e76\u57fa\u4e8e\u5b9e\u9a8c\u53cd\u9988\u5b66\u4e60\u5956\u52b1\u6a21\u578b\uff0c\u751f\u6210\u53ef\u6d4b\u8bd5\u4e14\u57fa\u4e8e\u6587\u732e\u7684\u7814\u7a76\u5047\u8bbe\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u5de5\u5177\u96be\u4ee5\u751f\u6210\u65e2\u53ef\u6d4b\u8bd5\u53c8\u57fa\u4e8e\u6587\u732e\u7684\u5047\u8bbe\uff0c\u4e14\u65e0\u6cd5\u9002\u5e94\u5148\u524d\u5b9e\u9a8c\u7ed3\u679c\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4eba\u7c7b\u7814\u7a76\u8005\u7684\u6784\u601d\u6d41\u7a0b\uff1a\u6587\u732e\u6316\u6398\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\u2192\u63a2\u7d22\u5047\u8bbe\u8bbe\u8ba1\u7a7a\u95f4\u2192\u901a\u8fc7\u5b9a\u4f4d\u7814\u7a76\u5dee\u8ddd\u548c\u8bba\u8bc1\u8bbe\u8ba1\u9009\u62e9\u6765\u6536\u655b\u5230\u7cbe\u786e\u53ef\u6d4b\u8bd5\u7684\u5047\u8bbe\uff0c\u5e76\u5b66\u4e60\u57fa\u4e8e\u5148\u524d\u5b9e\u9a8c\u7ed3\u679c\u7684\u5956\u52b1\u6a21\u578b\u3002", "result": "HARPA\u751f\u6210\u7684\u7814\u7a76\u63d0\u6848\u5728\u53ef\u884c\u6027(+0.78)\u548c\u6587\u732e\u57fa\u7840\u6027(+0.85)\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff1b\u4e0eASD\u4ee3\u7406\u6d4b\u8bd5\u65f6\u6210\u529f\u7387\u66f4\u9ad8(20 vs 11/40)\uff0c\u5931\u8d25\u66f4\u5c11(16 vs 21/40)\uff1b\u5956\u52b1\u6a21\u578b\u6bd4\u672a\u8bad\u7ec3\u57fa\u7ebf\u63d0\u5347\u7ea628%\u3002", "conclusion": "HARPA\u4ee3\u8868\u4e86AI\u9a71\u52a8\u79d1\u5b66\u53d1\u73b0\u9886\u57df\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u80fd\u591f\u751f\u6210\u66f4\u53ef\u884c\u3001\u66f4\u57fa\u4e8e\u6587\u732e\u7684\u7814\u7a76\u5047\u8bbe\uff0c\u5e76\u80fd\u4ece\u5b9e\u9a8c\u53cd\u9988\u4e2d\u5b66\u4e60\u6539\u8fdb\u3002"}}
{"id": "2510.00625", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00625", "abs": "https://arxiv.org/abs/2510.00625", "authors": ["Wei Liu", "Haomei Xu", "Bingqing Liu", "Zhiying Deng", "Haozhao Wang", "Jun Wang", "Ruixuan Li", "Yee Whye Teh", "Wee Sun Lee"], "title": "Is Model Editing Built on Sand? Revealing Its Illusory Success and Fragile Foundation", "comment": "This is a work in progress. Comments and suggestions are welcome", "summary": "Large language models (LLMs) inevitably encode outdated or incorrect\nknowledge. Updating, deleting, and forgetting such knowledge is important for\nalignment, safety, and other issues. To address this issue, model editing has\nemerged as a promising paradigm: by precisely editing a small subset of\nparameters such that a specific fact is updated while preserving other\nknowledge. Despite its great success reported in previous papers, we find the\napparent reliability of editing rests on a fragile foundation and the current\nliterature is largely driven by illusory success. The fundamental goal of\nsteering the model's output toward a target with minimal modification would\nencourage exploiting hidden shortcuts, rather than utilizing real semantics.\nThis problem directly challenges the feasibility of the current model editing\nliterature at its very foundation, as shortcuts are inherently at odds with\nrobust knowledge integration. Coincidentally, this issue has long been obscured\nby evaluation frameworks that lack the design of negative examples. To uncover\nit, we systematically develop a suite of new evaluation methods. Strikingly, we\nfind that state-of-the-art approaches collapse even under the simplest negation\nqueries. Our empirical evidence shows that editing is likely to be based on\nshortcuts rather than full semantics, calling for an urgent reconsideration of\nthe very basis of model editing before further advancements can be meaningfully\npursued.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u5176\u8868\u9762\u4e0a\u7684\u6210\u529f\u5b9e\u9645\u4e0a\u662f\u57fa\u4e8e\u8106\u5f31\u7684\u6377\u5f84\u800c\u975e\u771f\u5b9e\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u5728\u5426\u5b9a\u67e5\u8be2\u7b49\u7b80\u5355\u6d4b\u8bd5\u4e0b\u5c31\u4f1a\u5d29\u6e83\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0d\u53ef\u907f\u514d\u5730\u7f16\u7801\u8fc7\u65f6\u6216\u9519\u8bef\u77e5\u8bc6\uff0c\u66f4\u65b0\u3001\u5220\u9664\u548c\u9057\u5fd8\u8fd9\u4e9b\u77e5\u8bc6\u5bf9\u4e8e\u5bf9\u9f50\u3001\u5b89\u5168\u7b49\u95ee\u9898\u5f88\u91cd\u8981\u3002\u6a21\u578b\u7f16\u8f91\u88ab\u63d0\u51fa\u4f5c\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u6709\u524d\u666f\u8303\u5f0f\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u73b0\u6709\u7684\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u7cfb\u7edf\u6027\u5730\u5f00\u53d1\u4e86\u4e00\u5957\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7279\u522b\u8bbe\u8ba1\u4e86\u5305\u542b\u5426\u5b9a\u67e5\u8be2\u7684\u8d1f\u4f8b\u6d4b\u8bd5\uff0c\u6765\u63ed\u793a\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u662f\u5426\u771f\u6b63\u57fa\u4e8e\u8bed\u4e49\u7406\u89e3\u800c\u975e\u5229\u7528\u9690\u85cf\u7684\u6377\u5f84\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5728\u7b80\u5355\u7684\u5426\u5b9a\u67e5\u8be2\u4e0b\u4e5f\u4f1a\u5d29\u6e83\uff0c\u8868\u660e\u7f16\u8f91\u5f88\u53ef\u80fd\u57fa\u4e8e\u6377\u5f84\u800c\u975e\u5b8c\u6574\u7684\u8bed\u4e49\u7406\u89e3\u3002", "conclusion": "\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u76ee\u524d\u5efa\u7acb\u5728\u8106\u5f31\u7684\u57fa\u7840\u4e0a\uff0c\u5176\u6210\u529f\u53ef\u80fd\u662f\u865a\u5e7b\u7684\uff0c\u9700\u8981\u5728\u8fdb\u4e00\u6b65\u63a8\u8fdb\u4e4b\u524d\u91cd\u65b0\u8003\u8651\u5176\u6839\u672c\u57fa\u7840\u3002"}}
{"id": "2510.00627", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00627", "abs": "https://arxiv.org/abs/2510.00627", "authors": ["Bingzhang Wang", "Kehua Chen", "Yinhai Wang"], "title": "Collaborative-Distilled Diffusion Models (CDDM) for Accelerated and Lightweight Trajectory Prediction", "comment": null, "summary": "Trajectory prediction is a fundamental task in Autonomous Vehicles (AVs) and\nIntelligent Transportation Systems (ITS), supporting efficient motion planning\nand real-time traffic safety management. Diffusion models have recently\ndemonstrated strong performance in probabilistic trajectory prediction, but\ntheir large model size and slow sampling process hinder real-world deployment.\nThis paper proposes Collaborative-Distilled Diffusion Models (CDDM), a novel\nmethod for real-time and lightweight trajectory prediction. Built upon\nCollaborative Progressive Distillation (CPD), CDDM progressively transfers\nknowledge from a high-capacity teacher diffusion model to a lightweight student\nmodel, jointly reducing both the number of sampling steps and the model size\nacross distillation iterations. A dual-signal regularized distillation loss is\nfurther introduced to incorporate guidance from both the teacher and\nground-truth data, mitigating potential overfitting and ensuring robust\nperformance. Extensive experiments on the ETH-UCY pedestrian benchmark and the\nnuScenes vehicle benchmark demonstrate that CDDM achieves state-of-the-art\nprediction accuracy. The well-distilled CDDM retains 96.2% and 95.5% of the\nbaseline model's ADE and FDE performance on pedestrian trajectories, while\nrequiring only 231K parameters and 4 or 2 sampling steps, corresponding to 161x\ncompression, 31x acceleration, and 9 ms latency. Qualitative results further\nshow that CDDM generates diverse and accurate trajectories under dynamic agent\nbehaviors and complex social interactions. By bridging high-performing\ngenerative models with practical deployment constraints, CDDM enables\nresource-efficient probabilistic prediction for AVs and ITS. Code is available\nat https://github.com/bingzhangw/CDDM.", "AI": {"tldr": "\u63d0\u51faCDDM\u65b9\u6cd5\uff0c\u901a\u8fc7\u534f\u4f5c\u6e10\u8fdb\u84b8\u998f\u6280\u672f\u5c06\u5927\u578b\u6269\u6563\u6a21\u578b\u538b\u7f29\u4e3a\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0161\u500d\u538b\u7f29\u548c31\u500d\u52a0\u901f\uff0c\u9002\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u5b9e\u65f6\u8f68\u8ff9\u9884\u6d4b\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u6982\u7387\u8f68\u8ff9\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6a21\u578b\u89c4\u6a21\u5927\u3001\u91c7\u6837\u901f\u5ea6\u6162\uff0c\u96be\u4ee5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u90e8\u7f72\u3002\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u9ad8\u6548\u7684\u5b9e\u65f6\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u534f\u4f5c\u6e10\u8fdb\u84b8\u998f(CPD)\uff0c\u9010\u6b65\u5c06\u77e5\u8bc6\u4ece\u5927\u578b\u6559\u5e08\u6269\u6563\u6a21\u578b\u8f6c\u79fb\u5230\u8f7b\u91cf\u5b66\u751f\u6a21\u578b\uff0c\u540c\u65f6\u51cf\u5c11\u91c7\u6837\u6b65\u9aa4\u548c\u6a21\u578b\u89c4\u6a21\u3002\u5f15\u5165\u53cc\u4fe1\u53f7\u6b63\u5219\u5316\u84b8\u998f\u635f\u5931\uff0c\u7ed3\u5408\u6559\u5e08\u548c\u771f\u5b9e\u6570\u636e\u7684\u6307\u5bfc\u3002", "result": "\u5728ETH-UCY\u884c\u4eba\u57fa\u51c6\u548cnuScenes\u8f66\u8f86\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u7cbe\u5ea6\u3002\u538b\u7f29\u540e\u6a21\u578b\u4ec5\u9700231K\u53c2\u6570\u548c2-4\u4e2a\u91c7\u6837\u6b65\u9aa4\uff0c\u4fdd\u630196.2% ADE\u548c95.5% FDE\u6027\u80fd\uff0c\u5ef6\u8fdf\u4ec59ms\u3002", "conclusion": "CDDM\u6210\u529f\u5c06\u9ad8\u6027\u80fd\u751f\u6210\u6a21\u578b\u4e0e\u5b9e\u9645\u90e8\u7f72\u7ea6\u675f\u76f8\u7ed3\u5408\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u5b9e\u65f6\u6982\u7387\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.01023", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.01023", "abs": "https://arxiv.org/abs/2510.01023", "authors": ["S. Satsevich", "A. Bazhenov", "S. Egorov", "A. Erkhov", "M. Gromakov", "A. Fedoseev", "D. Tsetserukou"], "title": "Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning", "comment": null, "summary": "This paper presents a novel teleoperation system with force feedback,\nutilizing consumer-grade HTC Vive Trackers 2.0. The system integrates a\ncustom-built controller, a UR3 robotic arm, and a Robotiq gripper equipped with\ncustom-designed fingers to ensure uniform pressure distribution on an embedded\nforce sensor. Real-time compression force data is transmitted to the\ncontroller, enabling operators to perceive the gripping force applied to\nobjects. Experimental results demonstrate that the system enhances task success\nrates and provides a low-cost solution for large-scale imitation learning data\ncollection without compromising affordability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eHTC Vive Tracker 2.0\u7684\u65b0\u578b\u529b\u53cd\u9988\u9065\u64cd\u4f5c\u7cfb\u7edf\uff0c\u7528\u4e8e\u4f4e\u6210\u672c\u5927\u89c4\u6a21\u6a21\u4eff\u5b66\u4e60\u6570\u636e\u6536\u96c6", "motivation": "\u5f00\u53d1\u7ecf\u6d4e\u5b9e\u60e0\u7684\u529b\u53cd\u9988\u9065\u64cd\u4f5c\u7cfb\u7edf\uff0c\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u6a21\u4eff\u5b66\u4e60\u6570\u636e\u6536\u96c6\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u6210\u672c", "method": "\u96c6\u6210\u6d88\u8d39\u7ea7HTC Vive Tracker 2.0\u3001\u5b9a\u5236\u63a7\u5236\u5668\u3001UR3\u673a\u68b0\u81c2\u548c\u914d\u5907\u5b9a\u5236\u624b\u6307\u7684Robotiq\u5939\u722a\uff0c\u901a\u8fc7\u5d4c\u5165\u5f0f\u529b\u4f20\u611f\u5668\u5b9e\u73b0\u5747\u5300\u538b\u529b\u5206\u5e03\u548c\u5b9e\u65f6\u529b\u6570\u636e\u4f20\u8f93", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u7cfb\u7edf\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5e76\u4e3a\u5927\u89c4\u6a21\u6a21\u4eff\u5b66\u4e60\u6570\u636e\u6536\u96c6\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u7ecf\u6d4e\u9ad8\u6548\u7684\u529b\u53cd\u9988\u9065\u64cd\u4f5c\uff0c\u4e3a\u6a21\u4eff\u5b66\u4e60\u6570\u636e\u6536\u96c6\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2510.00636", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00636", "abs": "https://arxiv.org/abs/2510.00636", "authors": ["Alessio Devoto", "Maximilian Jeblick", "Simon J\u00e9gou"], "title": "Expected Attention: KV Cache Compression by Estimating Attention from Future Queries Distribution", "comment": null, "summary": "Memory consumption of the Key-Value (KV) cache represents a major bottleneck\nfor efficient large language model inference. While attention-score-based KV\ncache pruning shows promise, it faces critical practical limitations: attention\nscores from future tokens are unavailable during compression, and modern\nimplementations like Flash Attention do not materialize the full attention\nmatrix, making past scores inaccessible. To overcome these challenges, we\nintroduce $\\textbf{Expected Attention, a training-free compression method}$\nthat estimates KV pairs importance by predicting how future queries will attend\nto them. Our approach leverages the distributional properties of LLM\nactivations to compute expected attention scores in closed form for each KV\npair. These scores enable principled ranking and pruning of KV pairs with\nminimal impact on the residual stream, achieving effective compression without\nperformance degradation. Importantly, our method operates seamlessly across\nboth prefilling and decoding phases, consistently outperforming\nstate-of-the-art baselines in both scenarios. Finally, $\\textbf{we release\nKVPress, a comprehensive library to enable researchers to implement and\nbenchmark KV cache compression methods, already including more than 20\ntechniques}$.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aExpected Attention\u7684\u8bad\u7ec3\u65e0\u5173KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u67e5\u8be2\u5982\u4f55\u5173\u6ce8KV\u5bf9\u6765\u4f30\u8ba1\u5176\u91cd\u8981\u6027\uff0c\u89e3\u51b3\u4e86\u6ce8\u610f\u529b\u5206\u6570\u4e0d\u53ef\u7528\u7684\u95ee\u9898\u3002", "motivation": "KV\u7f13\u5b58\u7684\u5185\u5b58\u6d88\u8017\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u800c\u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6570\u7684KV\u7f13\u5b58\u526a\u679d\u65b9\u6cd5\u9762\u4e34\u5b9e\u9645\u9650\u5236\uff1a\u672a\u6765token\u7684\u6ce8\u610f\u529b\u5206\u6570\u5728\u538b\u7f29\u65f6\u4e0d\u53ef\u7528\uff0c\u4e14\u73b0\u4ee3\u5b9e\u73b0\u5982Flash Attention\u4e0d\u751f\u6210\u5b8c\u6574\u6ce8\u610f\u529b\u77e9\u9635\u3002", "method": "\u5229\u7528LLM\u6fc0\u6d3b\u7684\u5206\u5e03\u7279\u6027\uff0c\u4ee5\u95ed\u5f0f\u5f62\u5f0f\u8ba1\u7b97\u6bcf\u4e2aKV\u5bf9\u7684\u671f\u671b\u6ce8\u610f\u529b\u5206\u6570\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u5206\u6570\u8fdb\u884c\u539f\u5219\u6027\u6392\u5e8f\u548c\u526a\u679d\uff0c\u6700\u5c0f\u5316\u5bf9\u6b8b\u5dee\u6d41\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u90fd\u80fd\u65e0\u7f1d\u8fd0\u884c\uff0c\u5728\u4e24\u4e2a\u573a\u666f\u4e2d\u90fd\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5f00\u53d1\u4e86KVPress\u5e93\uff0c\u5305\u542b20\u591a\u79cd\u6280\u672f\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u5b9e\u73b0\u548c\u57fa\u51c6\u6d4b\u8bd5KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5168\u9762\u652f\u6301\u3002"}}
{"id": "2510.00664", "categories": ["cs.AI", "cs.CV", "68", "I.2; I.4"], "pdf": "https://arxiv.org/pdf/2510.00664", "abs": "https://arxiv.org/abs/2510.00664", "authors": ["Giacomo Ignesti", "Davide Moroni", "Massimo Martinelli"], "title": "Batch-CAM: Introduction to better reasoning in convolutional deep learning models", "comment": "18 pages, 7 figures, submitted to SN Computer Science Springer Nature", "summary": "Understanding the inner workings of deep learning models is crucial for\nadvancing artificial intelligence, particularly in high-stakes fields such as\nhealthcare, where accurate explanations are as vital as precision. This paper\nintroduces Batch-CAM, a novel training paradigm that fuses a batch\nimplementation of the Grad-CAM algorithm with a prototypical reconstruction\nloss. This combination guides the model to focus on salient image features,\nthereby enhancing its performance across classification tasks. Our results\ndemonstrate that Batch-CAM achieves a simultaneous improvement in accuracy and\nimage reconstruction quality while reducing training and inference times. By\nensuring models learn from evidence-relevant information,this approach makes a\nrelevant contribution to building more transparent, explainable, and\ntrustworthy AI systems.", "AI": {"tldr": "\u63d0\u51faBatch-CAM\u8bad\u7ec3\u8303\u5f0f\uff0c\u878d\u5408\u6279\u5904\u7406Grad-CAM\u7b97\u6cd5\u548c\u539f\u578b\u91cd\u5efa\u635f\u5931\uff0c\u63d0\u5347\u6a21\u578b\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u6539\u5584\u51c6\u786e\u6027\u548c\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u81f3\u5173\u91cd\u8981\uff0c\u51c6\u786e\u89e3\u91ca\u4e0e\u7cbe\u786e\u5ea6\u540c\u7b49\u91cd\u8981\u3002", "method": "\u7ed3\u5408\u6279\u5904\u7406Grad-CAM\u7b97\u6cd5\u548c\u539f\u578b\u91cd\u5efa\u635f\u5931\uff0c\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u663e\u8457\u56fe\u50cf\u7279\u5f81\u3002", "result": "Batch-CAM\u5728\u51c6\u786e\u6027\u548c\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u4e0a\u540c\u65f6\u63d0\u5347\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u786e\u4fdd\u6a21\u578b\u5b66\u4e60\u8bc1\u636e\u76f8\u5173\u4fe1\u606f\uff0c\u4e3a\u6784\u5efa\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2510.01068", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01068", "abs": "https://arxiv.org/abs/2510.01068", "authors": ["Jiahang Cao", "Yize Huang", "Hanzhong Guo", "Rui Zhang", "Mu Nan", "Weijian Mai", "Jiaxu Wang", "Hao Cheng", "Jingkai Sun", "Gang Han", "Wen Zhao", "Qiang Zhang", "Yijie Guo", "Qihao Zheng", "Chunfeng Song", "Xiao Li", "Ping Luo", "Andrew F. Luo"], "title": "Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition", "comment": "Project Page: https://sagecao1125.github.io/GPC-Site/", "summary": "Diffusion-based models for robotic control, including vision-language-action\n(VLA) and vision-action (VA) policies, have demonstrated significant\ncapabilities. Yet their advancement is constrained by the high cost of\nacquiring large-scale interaction datasets. This work introduces an alternative\nparadigm for enhancing policy performance without additional model training.\nPerhaps surprisingly, we demonstrate that the composed policies can exceed the\nperformance of either parent policy. Our contribution is threefold. First, we\nestablish a theoretical foundation showing that the convex composition of\ndistributional scores from multiple diffusion models can yield a superior\none-step functional objective compared to any individual score. A\nGr\\\"onwall-type bound is then used to show that this single-step improvement\npropagates through entire generation trajectories, leading to systemic\nperformance gains. Second, motivated by these results, we propose General\nPolicy Composition (GPC), a training-free method that enhances performance by\ncombining the distributional scores of multiple pre-trained policies via a\nconvex combination and test-time search. GPC is versatile, allowing for the\nplug-and-play composition of heterogeneous policies, including VA and VLA\nmodels, as well as those based on diffusion or flow-matching, irrespective of\ntheir input visual modalities. Third, we provide extensive empirical\nvalidation. Experiments on Robomimic, PushT, and RoboTwin benchmarks, alongside\nreal-world robotic evaluations, confirm that GPC consistently improves\nperformance and adaptability across a diverse set of tasks. Further analysis of\nalternative composition operators and weighting strategies offers insights into\nthe mechanisms underlying the success of GPC. These results establish GPC as a\nsimple yet effective method for improving control performance by leveraging\nexisting policies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u7b56\u7565\u7ec4\u5408\u65b9\u6cd5GPC\uff0c\u901a\u8fc7\u7ec4\u5408\u591a\u4e2a\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u7684\u5206\u5e03\u5206\u6570\u6765\u63d0\u5347\u673a\u5668\u4eba\u63a7\u5236\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u4e2a\u7b56\u7565\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5927\u89c4\u6a21\u4ea4\u4e92\u6570\u636e\u83b7\u53d6\u6210\u672c\u9ad8\u6602\u3002\u672c\u6587\u63a2\u7d22\u5728\u4e0d\u8fdb\u884c\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u7b56\u7565\u6027\u80fd\u7684\u65b0\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u901a\u7528\u7b56\u7565\u7ec4\u5408(GPC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u51f8\u7ec4\u5408\u548c\u6d4b\u8bd5\u65f6\u641c\u7d22\u6765\u7ec4\u5408\u591a\u4e2a\u9884\u8bad\u7ec3\u7b56\u7565\u7684\u5206\u5e03\u5206\u6570\uff0c\u652f\u6301\u5f02\u6784\u7b56\u7565\u7684\u7ec4\u5408\u3002", "result": "\u5728Robomimic\u3001PushT\u548cRoboTwin\u57fa\u51c6\u6d4b\u8bd5\u53ca\u771f\u5b9e\u673a\u5668\u4eba\u8bc4\u4f30\u4e2d\uff0cGPC\u4e00\u81f4\u63d0\u5347\u4e86\u6027\u80fd\u548c\u9002\u5e94\u6027\uff0c\u7ec4\u5408\u7b56\u7565\u6027\u80fd\u8d85\u8fc7\u4efb\u4e00\u7236\u7b56\u7565\u3002", "conclusion": "GPC\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u63a7\u5236\u6027\u80fd\u63d0\u5347\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u73b0\u6709\u7b56\u7565\u5b9e\u73b0\u6027\u80fd\u589e\u76ca\uff0c\u4e3a\u7b56\u7565\u7ec4\u5408\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2510.00689", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00689", "abs": "https://arxiv.org/abs/2510.00689", "authors": ["Chi-Huang Lin", "Ting Han Wei", "Chun-Jui Wang", "Hung Guei", "Chung-Chin Shih", "Yun-Jui Tsai", "I-Chen Wu", "Ti-Rong Wu"], "title": "Relevance-Zone Reduction in Game Solving", "comment": "Accepted by the Advances in Computer Games (ACG 2025)", "summary": "Game solving aims to find the optimal strategies for all players and\ndetermine the theoretical outcome of a game. However, due to the exponential\ngrowth of game trees, many games remain unsolved, even though methods like\nAlphaZero have demonstrated super-human level in game playing. The\nRelevance-Zone (RZ) is a local strategy reuse technique that restricts the\nsearch to only the regions relevant to the outcome, significantly reducing the\nsearch space. However, RZs are not unique. Different solutions may result in\nRZs of varying sizes. Smaller RZs are generally more favorable, as they\nincrease the chance of reuse and improve pruning efficiency. To this end, we\npropose an iterative RZ reduction method that repeatedly solves the same\nposition while gradually restricting the region involved, guiding the solver\ntoward smaller RZs. We design three constraint generation strategies and\nintegrate an RZ Pattern Table to fully leverage past solutions. In experiments\non 7x7 Killall-Go, our method reduces the average RZ size to 85.95% of the\noriginal. Furthermore, the reduced RZs can be permanently stored as reusable\nknowledge for future solving tasks, especially for larger board sizes or\ndifferent openings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u5f0fRZ\u7f29\u51cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u9010\u6b65\u9650\u5236\u641c\u7d22\u533a\u57df\u6765\u51cf\u5c0f\u76f8\u5173\u6027\u533a\u57df\u7684\u5927\u5c0f\uff0c\u4ece\u800c\u63d0\u9ad8\u7b56\u7565\u91cd\u7528\u6548\u7387\u548c\u526a\u679d\u6548\u679c\u3002", "motivation": "\u7531\u4e8e\u6e38\u620f\u6811\u7684\u6307\u6570\u7ea7\u589e\u957f\uff0c\u8bb8\u591a\u6e38\u620f\u5c1a\u672a\u89e3\u51b3\u3002\u76f8\u5173\u6027\u533a\u57df(RZ)\u6280\u672f\u867d\u7136\u80fd\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff0c\u4f46\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\u4f1a\u4ea7\u751f\u4e0d\u540c\u5927\u5c0f\u7684RZ\uff0c\u8f83\u5c0f\u7684RZ\u66f4\u6709\u5229\u4e8e\u91cd\u7528\u548c\u526a\u679d\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u8fed\u4ee3RZ\u7f29\u51cf\u65b9\u6cd5\uff0c\u91cd\u590d\u6c42\u89e3\u76f8\u540c\u4f4d\u7f6e\u5e76\u9010\u6b65\u9650\u5236\u53c2\u4e0e\u533a\u57df\uff1b\u63d0\u51fa\u4e09\u79cd\u7ea6\u675f\u751f\u6210\u7b56\u7565\uff0c\u5e76\u96c6\u6210RZ\u6a21\u5f0f\u8868\u4ee5\u5145\u5206\u5229\u7528\u8fc7\u5f80\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u57287x7 Killall-Go\u5b9e\u9a8c\u4e2d\uff0c\u5e73\u5747RZ\u5927\u5c0f\u51cf\u5c11\u5230\u539f\u59cb\u768485.95%\u3002", "conclusion": "\u7f29\u51cf\u540e\u7684RZ\u53ef\u4ee5\u4f5c\u4e3a\u53ef\u91cd\u7528\u77e5\u8bc6\u6c38\u4e45\u5b58\u50a8\uff0c\u7528\u4e8e\u672a\u6765\u66f4\u5927\u7684\u68cb\u76d8\u6216\u4e0d\u540c\u5f00\u5c40\u60c5\u51b5\u7684\u6c42\u89e3\u4efb\u52a1\u3002"}}
{"id": "2510.01138", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.01138", "abs": "https://arxiv.org/abs/2510.01138", "authors": ["Matthew Woodward"], "title": "Real-Time Trajectory Generation and Hybrid Lyapunov-Based Control for Hopping Robots", "comment": "7 pages, 4 figures, 4 tables", "summary": "The advent of rotor-based hopping robots has created very capable hopping\nplatforms with high agility and efficiency, and similar controllability, as\ncompared to their purely flying quadrotor counterparts. Advances in robot\nperformance have increased the hopping height to greater than 4 meters and\nopened up the possibility for more complex aerial trajectories (i.e.,\nbehaviors). However, currently hopping robots do not directly control their\naerial trajectory or transition to flight, eliminating the efficiency benefits\nof a hopping system. Here we show a real-time, computationally efficiency,\nnon-linear drag compensated, trajectory generation methodology and accompanying\nLyapunov-based controller. The combined system can create and follow complex\naerial trajectories from liftoff to touchdown on horizontal and vertical\nsurfaces, while maintaining strick control over the orientation at touchdown.\nThe computational efficiency provides broad applicability across all size\nscales of hopping robots while maintaining applicability to quadrotors in\ngeneral.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u3001\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u975e\u7ebf\u6027\u963b\u529b\u8865\u507f\u8f68\u8ff9\u751f\u6210\u65b9\u6cd5\u548c\u674e\u96c5\u666e\u8bfa\u592b\u63a7\u5236\u5668\uff0c\u4f7f\u8df3\u8dc3\u673a\u5668\u4eba\u80fd\u591f\u4ece\u8d77\u98de\u5230\u89e6\u5730\u6267\u884c\u590d\u6742\u7a7a\u4e2d\u8f68\u8ff9\u63a7\u5236\u3002", "motivation": "\u5f53\u524d\u8df3\u8dc3\u673a\u5668\u4eba\u65e0\u6cd5\u76f4\u63a5\u63a7\u5236\u7a7a\u4e2d\u8f68\u8ff9\u6216\u8fc7\u6e21\u5230\u98de\u884c\u72b6\u6001\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8df3\u8dc3\u7cfb\u7edf\u7684\u6548\u7387\u4f18\u52bf\u3002", "method": "\u5f00\u53d1\u4e86\u975e\u7ebf\u6027\u963b\u529b\u8865\u507f\u7684\u8f68\u8ff9\u751f\u6210\u65b9\u6cd5\u548c\u57fa\u4e8e\u674e\u96c5\u666e\u8bfa\u592b\u7a33\u5b9a\u6027\u7684\u63a7\u5236\u5668\uff0c\u652f\u6301\u4ece\u8d77\u98de\u5230\u89e6\u5730\u7684\u5b8c\u6574\u8f68\u8ff9\u8ddf\u8e2a\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u521b\u5efa\u548c\u8ddf\u8e2a\u590d\u6742\u7a7a\u4e2d\u8f68\u8ff9\uff0c\u5728\u6c34\u5e73\u548c\u5782\u76f4\u8868\u9762\u4e0a\u5b9e\u73b0\u7cbe\u786e\u89e6\u5730\u63a7\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u89e6\u5730\u65f6\u7684\u4e25\u683c\u59ff\u6001\u63a7\u5236\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u6cd5\u9002\u7528\u4e8e\u5404\u79cd\u5c3a\u5bf8\u7684\u8df3\u8dc3\u673a\u5668\u4eba\uff0c\u5e76\u5177\u6709\u5bf9\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7684\u901a\u7528\u9002\u7528\u6027\u3002"}}
{"id": "2510.00690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00690", "abs": "https://arxiv.org/abs/2510.00690", "authors": ["Yunhao Wang", "Ziting Li", "Shuai Chen", "Tao Liu", "Chao Song", "Junjie Jiang", "Jian Zhu", "Peng Gao", "Bin Qin"], "title": "ACPO: Adaptive Curriculum Policy Optimization for Aligning Vision-Language Models in Complex Reasoning", "comment": null, "summary": "Aligning large-scale vision-language models (VLMs) for complex reasoning via\nreinforcement learning is often hampered by the limitations of existing policy\noptimization algorithms, such as static training schedules and the rigid,\nuniform clipping mechanism in Proximal Policy Optimization (PPO). In this work,\nwe introduce Adaptive Curriculum Policy Optimization (ACPO), a novel framework\nthat addresses these challenges through a dual-component adaptive learning\nstrategy. First, ACPO employs a dynamic curriculum that orchestrates a\nprincipled transition from a stable, near on-policy exploration phase to an\nefficient, off-policy exploitation phase by progressively increasing sample\nreuse. Second, we propose an Advantage-Aware Adaptive Clipping (AAAC) mechanism\nthat replaces the fixed clipping hyperparameter with dynamic, sample-wise\nbounds modulated by the normalized advantage of each token. This allows for\nmore granular and robust policy updates, enabling larger gradients for\nhigh-potential samples while safeguarding against destructive ones. We conduct\nextensive experiments on a suite of challenging multimodal reasoning\nbenchmarks, including MathVista, LogicVista, and MMMU-Pro. Results demonstrate\nthat ACPO consistently outperforms strong baselines such as DAPO and PAPO,\nachieving state-of-the-art performance, accelerated convergence, and superior\ntraining stability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u8bfe\u7a0b\u7b56\u7565\u4f18\u5316\uff08ACPO\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8bfe\u7a0b\u548c\u81ea\u9002\u5e94\u88c1\u526a\u673a\u5236\u6539\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\uff0c\u5728\u591a\u9879\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff08\u5982PPO\uff09\u5728\u8bad\u7ec3\u5927\u89c4\u6a21\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u590d\u6742\u63a8\u7406\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5305\u62ec\u9759\u6001\u8bad\u7ec3\u8ba1\u5212\u548c\u521a\u6027\u88c1\u526a\u673a\u5236\uff0c\u963b\u788d\u4e86\u6a21\u578b\u7684\u6709\u6548\u5bf9\u9f50\u3002", "method": "ACPO\u91c7\u7528\u53cc\u7ec4\u4ef6\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565\uff1a1\uff09\u52a8\u6001\u8bfe\u7a0b\uff0c\u4ece\u7a33\u5b9a\u7684\u8fd1\u7b56\u7565\u63a2\u7d22\u9636\u6bb5\u9010\u6b65\u8fc7\u6e21\u5230\u9ad8\u6548\u7684\u79bb\u7b56\u7565\u5229\u7528\u9636\u6bb5\uff1b2\uff09\u4f18\u52bf\u611f\u77e5\u81ea\u9002\u5e94\u88c1\u526a\uff08AAAC\uff09\uff0c\u7528\u52a8\u6001\u6837\u672c\u7ea7\u8fb9\u754c\u66ff\u4ee3\u56fa\u5b9a\u88c1\u526a\u8d85\u53c2\u6570\u3002", "result": "\u5728MathVista\u3001LogicVista\u548cMMMU-Pro\u7b49\u6311\u6218\u6027\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cACPO\u6301\u7eed\u4f18\u4e8eDAPO\u548cPAPO\u7b49\u5f3a\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3001\u52a0\u901f\u6536\u655b\u548c\u4f18\u8d8a\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "conclusion": "ACPO\u901a\u8fc7\u81ea\u9002\u5e94\u8bfe\u7a0b\u548c\u88c1\u526a\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u7a33\u5b9a\u7684\u8bad\u7ec3\u6846\u67b6\u3002"}}
{"id": "2510.00706", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00706", "abs": "https://arxiv.org/abs/2510.00706", "authors": ["Yusif Ibrahimov", "Tarique Anwar", "Tommy Yuan", "Turan Mutallimov", "Elgun Hasanov"], "title": "AttentionDep: Domain-Aware Attention for Explainable Depression Severity Assessment", "comment": null, "summary": "In today's interconnected society, social media platforms provide a window\ninto individuals' thoughts, emotions, and mental states. This paper explores\nthe use of platforms like Facebook, X (formerly Twitter), and Reddit for\ndepression severity detection. We propose AttentionDep, a domain-aware\nattention model that drives explainable depression severity estimation by\nfusing contextual and domain knowledge. Posts are encoded hierarchically using\nunigrams and bigrams, with attention mechanisms highlighting clinically\nrelevant tokens. Domain knowledge from a curated mental health knowledge graph\nis incorporated through a cross-attention mechanism, enriching the contextual\nfeatures. Finally, depression severity is predicted using an ordinal regression\nframework that respects the clinical-relevance and natural ordering of severity\nlevels. Our experiments demonstrate that AttentionDep outperforms\nstate-of-the-art baselines by over 5% in graded F1 score across datasets, while\nproviding interpretable insights into its predictions. This work advances the\ndevelopment of trustworthy and transparent AI systems for mental health\nassessment from social media.", "AI": {"tldr": "\u63d0\u51faAttentionDep\u6a21\u578b\uff0c\u901a\u8fc7\u878d\u5408\u4e0a\u4e0b\u6587\u548c\u9886\u57df\u77e5\u8bc6\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u6291\u90c1\u75c7\u4e25\u91cd\u7a0b\u5ea6\u68c0\u6d4b\uff0c\u5728\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5229\u7528\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4f5c\u4e3a\u4e86\u89e3\u4e2a\u4f53\u5fc3\u7406\u72b6\u6001\u7684\u7a97\u53e3\uff0c\u5f00\u53d1\u53ef\u4fe1\u8d56\u4e14\u900f\u660e\u7684AI\u7cfb\u7edf\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u5c42\u6b21\u5316\u7f16\u7801\uff08unigrams\u548cbigrams\uff09\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7ed3\u5408\u5fc3\u7406\u5065\u5eb7\u77e5\u8bc6\u56fe\u8c31\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u91c7\u7528\u6709\u5e8f\u56de\u5f52\u6846\u67b6\u9884\u6d4b\u6291\u90c1\u75c7\u4e25\u91cd\u7a0b\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u5347\u8d85\u8fc75%\u7684\u7b49\u7ea7F1\u5206\u6570\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u9884\u6d4b\u6d1e\u5bdf\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u52a8\u4e86\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u7684\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u4e2d\u53ef\u4fe1\u8d56\u548c\u900f\u660eAI\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.00732", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00732", "abs": "https://arxiv.org/abs/2510.00732", "authors": ["Yuchen Tian", "Ruiyuan Huang", "Xuanwu Wang", "Jing Ma", "Zengfeng Huang", "Ziyang Luo", "Hongzhan Lin", "Da Zheng", "Lun Du"], "title": "EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty", "comment": null, "summary": "Large Language Models (LLMs) for formal theorem proving have shown\nsignificant promise, yet they often lack generalizability and are fragile to\neven minor transformations of problem statements. To address this limitation,\nwe introduce a novel data augmentation pipeline designed to enhance model\nrobustness from two perspectives: symmetry and difficulty. From the symmetry\nperspective, we propose two complementary methods: EvolAST, an Abstract Syntax\nTree (AST) based approach that targets syntactic symmetry to generate\nsemantically equivalent problem variants, and EvolDomain, which leverages LLMs\nto address semantic symmetry by translating theorems across mathematical\ndomains. From the difficulty perspective, we propose EvolDifficulty, which uses\ncarefully designed evolutionary instructions to guide LLMs in generating new\ntheorems with a wider range of difficulty. We then use the evolved data to\ntrain EvolProver, a 7B-parameter non-reasoning theorem prover. EvolProver\nestablishes a new state-of-the-art (SOTA) on FormalMATH-Lite with a 53.8%\npass@32 rate, surpassing all models of comparable size, including\nreasoning-based models. It also sets new SOTA records for non-reasoning models\non MiniF2F-Test (69.8% pass@32), Ineq-Comp-Seed (52.2% pass@32), and\nIneq-Comp-Transformed (34.0% pass@32). Ablation studies further confirm our\ndata augmentation pipeline's effectiveness across multiple benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u589e\u5f3a\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u5bf9\u79f0\u6027\u548c\u96be\u5ea6\u4e24\u4e2a\u89d2\u5ea6\u63d0\u5347\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u8bad\u7ec3\u51fa\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u7684\u975e\u63a8\u7406\u5b9a\u7406\u8bc1\u660e\u5668EvolProver\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u666e\u904d\u6027\u4e0d\u8db3\u4e14\u5bf9\u95ee\u9898\u8868\u8ff0\u7684\u5fae\u5c0f\u53d8\u6362\u5f88\u8106\u5f31\uff0c\u9700\u8981\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff1aEvolAST\uff08\u57fa\u4e8e\u62bd\u8c61\u8bed\u6cd5\u6811\u7684\u53e5\u6cd5\u5bf9\u79f0\u6027\u589e\u5f3a\uff09\u3001EvolDomain\uff08\u8de8\u6570\u5b66\u9886\u57df\u7684\u8bed\u4e49\u5bf9\u79f0\u6027\u589e\u5f3a\uff09\u548cEvolDifficulty\uff08\u96be\u5ea6\u6f14\u5316\u589e\u5f3a\uff09\uff0c\u7136\u540e\u4f7f\u7528\u589e\u5f3a\u6570\u636e\u8bad\u7ec37B\u53c2\u6570\u7684EvolProver\u6a21\u578b\u3002", "result": "EvolProver\u5728FormalMATH-Lite\u4e0a\u8fbe\u523053.8% pass@32\u7684\u65b0SOTA\uff0c\u5728MiniF2F-Test\uff0869.8%\uff09\u3001Ineq-Comp-Seed\uff0852.2%\uff09\u548cIneq-Comp-Transformed\uff0834.0%\uff09\u4e0a\u5747\u4e3a\u975e\u63a8\u7406\u6a21\u578b\u7684\u6700\u4f73\u8868\u73b0\uff0c\u8d85\u8d8a\u4e86\u540c\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u589e\u5f3a\u6d41\u6c34\u7ebf\u80fd\u6709\u6548\u63d0\u5347\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.00778", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00778", "abs": "https://arxiv.org/abs/2510.00778", "authors": ["Seunghoo Hong", "Geonho Son", "Juhun Lee", "Simon S. Woo"], "title": "DIA: The Adversarial Exposure of Deterministic Inversion in Diffusion Models", "comment": "ICCV2025", "summary": "Diffusion models have shown to be strong representation learners, showcasing\nstate-of-the-art performance across multiple domains. Aside from accelerated\nsampling, DDIM also enables the inversion of real images back to their latent\ncodes. A direct inheriting application of this inversion operation is real\nimage editing, where the inversion yields latent trajectories to be utilized\nduring the synthesis of the edited image. Unfortunately, this practical tool\nhas enabled malicious users to freely synthesize misinformative or deepfake\ncontents with greater ease, which promotes the spread of unethical and abusive,\nas well as privacy-, and copyright-infringing contents. While defensive\nalgorithms such as AdvDM and Photoguard have been shown to disrupt the\ndiffusion process on these images, the misalignment between their objectives\nand the iterative denoising trajectory at test time results in weak disruptive\nperformance.In this work, we present the DDIM Inversion Attack (DIA) that\nattacks the integrated DDIM trajectory path. Our results support the effective\ndisruption, surpassing previous defensive methods across various editing\nmethods. We believe that our frameworks and results can provide practical\ndefense methods against the malicious use of AI for both the industry and the\nresearch community. Our code is available here:\nhttps://anonymous.4open.science/r/DIA-13419/.", "AI": {"tldr": "\u63d0\u51fa\u4e86DDIM\u53cd\u6f14\u653b\u51fb(DIA)\u65b9\u6cd5\uff0c\u901a\u8fc7\u653b\u51fbDDIM\u53cd\u6f14\u8f68\u8ff9\u8def\u5f84\u6765\u6709\u6548\u7834\u574f\u6076\u610f\u56fe\u50cf\u7f16\u8f91\uff0c\u5728\u9632\u5fa1\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "DDIM\u53cd\u6f14\u6280\u672f\u4f7f\u6076\u610f\u7528\u6237\u80fd\u591f\u8f7b\u677e\u5408\u6210\u865a\u5047\u5185\u5bb9\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5728\u7834\u574f\u6269\u6563\u8fc7\u7a0b\u65b9\u9762\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u5f00\u53d1\u4e86DDIM\u53cd\u6f14\u653b\u51fb(DIA)\uff0c\u76f4\u63a5\u653b\u51fbDDIM\u53cd\u6f14\u8f68\u8ff9\u8def\u5f84\uff0c\u4e0e\u8fed\u4ee3\u53bb\u566a\u8f68\u8ff9\u66f4\u597d\u5730\u5bf9\u9f50\uff0c\u63d0\u9ad8\u7834\u574f\u6548\u679c\u3002", "result": "DIA\u65b9\u6cd5\u5728\u7834\u574f\u5404\u79cd\u7f16\u8f91\u65b9\u6cd5\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u4e4b\u524d\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u9632\u5fa1\u6027\u80fd\u3002", "conclusion": "DIA\u6846\u67b6\u4e3a\u884c\u4e1a\u548c\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5bf9\u6297AI\u7684\u6076\u610f\u4f7f\u7528\u3002"}}
{"id": "2510.00795", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00795", "abs": "https://arxiv.org/abs/2510.00795", "authors": ["Anastasia Vepreva", "Julia Razlivina", "Maria Eremeeva", "Nina Gubina", "Anastasia Orlova", "Aleksei Dmitrenko", "Ksenya Kapranova", "Susan Jyakhwo", "Nikita Vasilev", "Arsen Sarkisyan", "Ivan Yu. Chernyshov", "Vladimir Vinogradov", "Andrei Dmitrenko"], "title": "Benchmarking Agentic Systems in Automated Scientific Information Extraction with ChemX", "comment": "Accepted at The AI for Accelerated Materials Discovery (AI4Mat)\n  Workshop, NeurIPS 2025", "summary": "The emergence of agent-based systems represents a significant advancement in\nartificial intelligence, with growing applications in automated data\nextraction. However, chemical information extraction remains a formidable\nchallenge due to the inherent heterogeneity of chemical data. Current\nagent-based approaches, both general-purpose and domain-specific, exhibit\nlimited performance in this domain. To address this gap, we present ChemX, a\ncomprehensive collection of 10 manually curated and domain-expert-validated\ndatasets focusing on nanomaterials and small molecules. These datasets are\ndesigned to rigorously evaluate and enhance automated extraction methodologies\nin chemistry. To demonstrate their utility, we conduct an extensive\nbenchmarking study comparing existing state-of-the-art agentic systems such as\nChatGPT Agent and chemical-specific data extraction agents. Additionally, we\nintroduce our own single-agent approach that enables precise control over\ndocument preprocessing prior to extraction. We further evaluate the performance\nof modern baselines, such as GPT-5 and GPT-5 Thinking, to compare their\ncapabilities with agentic approaches. Our empirical findings reveal persistent\nchallenges in chemical information extraction, particularly in processing\ndomain-specific terminology, complex tabular and schematic representations, and\ncontext-dependent ambiguities. The ChemX benchmark serves as a critical\nresource for advancing automated information extraction in chemistry,\nchallenging the generalization capabilities of existing methods, and providing\nvaluable insights into effective evaluation strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86ChemX\u6570\u636e\u96c6\uff0c\u5305\u542b10\u4e2a\u624b\u5de5\u6574\u7406\u4e14\u7ecf\u8fc7\u9886\u57df\u4e13\u5bb6\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u5316\u5b66\u4fe1\u606f\u63d0\u53d6\u65b9\u6cd5\u3002\u901a\u8fc7\u5bf9\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7684\u4ee3\u7406\u7cfb\u7edf\u548c\u73b0\u4ee3\u57fa\u7ebf\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u5316\u5b66\u4fe1\u606f\u63d0\u53d6\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u5316\u5b66\u4fe1\u606f\u63d0\u53d6\u56e0\u6570\u636e\u5f02\u8d28\u6027\u800c\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u73b0\u6709\u4ee3\u7406\u65b9\u6cd5\u5728\u8be5\u9886\u57df\u8868\u73b0\u6709\u9650\u3002\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6570\u636e\u96c6\u6765\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u4e8610\u4e2a\u624b\u5de5\u6574\u7406\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u7eb3\u7c73\u6750\u6599\u548c\u5c0f\u5206\u5b50\u3002\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86ChatGPT\u4ee3\u7406\u3001\u5316\u5b66\u4e13\u7528\u63d0\u53d6\u4ee3\u7406\u4ee5\u53ca\u4f5c\u8005\u63d0\u51fa\u7684\u5355\u4ee3\u7406\u65b9\u6cd5\uff0c\u8fd8\u8bc4\u4f30\u4e86GPT-5\u7b49\u73b0\u4ee3\u57fa\u7ebf\u6a21\u578b\u3002", "result": "\u5b9e\u8bc1\u53d1\u73b0\u5316\u5b66\u4fe1\u606f\u63d0\u53d6\u5b58\u5728\u6301\u7eed\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9886\u57df\u7279\u5b9a\u672f\u8bed\u3001\u590d\u6742\u8868\u683c\u548c\u793a\u610f\u56fe\u8868\u793a\u4ee5\u53ca\u4e0a\u4e0b\u6587\u76f8\u5173\u6b67\u4e49\u65b9\u9762\u3002", "conclusion": "ChemX\u57fa\u51c6\u662f\u63a8\u8fdb\u5316\u5b66\u81ea\u52a8\u5316\u4fe1\u606f\u63d0\u53d6\u7684\u5173\u952e\u8d44\u6e90\uff0c\u6311\u6218\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e3a\u6709\u6548\u8bc4\u4f30\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2510.00817", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.00817", "abs": "https://arxiv.org/abs/2510.00817", "authors": ["Nicholas Leisegang", "Giovanni Casini", "Thomas Meyer"], "title": "Semantic Bridges Between First Order c-Representations and Cost-Based Semantics: An Initial Perspective", "comment": null, "summary": "Weighted-knowledge bases and cost-based semantics represent a recent\nformalism introduced by Bienvenu et al. for Ontology Mediated Data Querying in\nthe case where a given knowledge base is inconsistent. This is done by adding a\nweight to each statement in the knowledge base (KB), and then giving each DL\ninterpretation a cost based on how often it breaks rules in the KB. In this\npaper we compare this approach with c-representations, a form of non-monotonic\nreasoning originally introduced by Kern-Isberner. c-Representations describe a\nmeans to interpret defeasible concept inclusions in the first-order case. This\nis done by assigning a numerical ranking to each interpretations via penalties\nfor each violated conditional. We compare these two approaches on a semantic\nlevel. In particular, we show that under certain conditions a weighted\nknowledge base and a set of defeasible conditionals can generate the same\nordering on interpretations, and therefore an equivalence of semantic\nstructures up to relative cost. Moreover, we compare entailment described in\nboth cases, where certain notions are equivalently expressible in both\nformalisms. Our results have the potential to benefit further work on both\ncost-based semantics and c-representations", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u52a0\u6743\u77e5\u8bc6\u5e93\u4e0ec-\u8868\u793a\u4e24\u79cd\u5904\u7406\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5b83\u4eec\u80fd\u5728\u8bed\u4e49\u5c42\u9762\u4ea7\u751f\u76f8\u540c\u7684\u89e3\u91ca\u6392\u5e8f\uff0c\u5e76\u5206\u6790\u4e86\u4e24\u8005\u5728\u63a8\u7406\u5173\u7cfb\u4e0a\u7684\u7b49\u4ef7\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u6bd4\u8f83\u52a0\u6743\u77e5\u8bc6\u5e93\u548cc-\u8868\u793a\u8fd9\u4e24\u79cd\u5904\u7406\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u63a2\u7d22\u5b83\u4eec\u5728\u8bed\u4e49\u7ed3\u6784\u548c\u63a8\u7406\u5173\u7cfb\u4e0a\u7684\u8054\u7cfb\u4e0e\u7b49\u4ef7\u6027\u3002", "method": "\u901a\u8fc7\u8bed\u4e49\u5c42\u9762\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u7814\u7a76\u52a0\u6743\u77e5\u8bc6\u5e93\u7684\u6210\u672c\u8bed\u4e49\u548cc-\u8868\u793a\u7684\u60e9\u7f5a\u673a\u5236\u5982\u4f55\u4ea7\u751f\u89e3\u91ca\u6392\u5e8f\uff0c\u5e76\u63a2\u8ba8\u4e24\u8005\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u52a0\u6743\u77e5\u8bc6\u5e93\u548c\u4e00\u7ec4\u53ef\u5e9f\u6b62\u6761\u4ef6\u53ef\u4ee5\u751f\u6210\u76f8\u540c\u7684\u89e3\u91ca\u6392\u5e8f\uff0c\u4e24\u79cd\u5f62\u5f0f\u5316\u65b9\u6cd5\u5728\u8bed\u4e49\u7ed3\u6784\u4e0a\u5177\u6709\u76f8\u5bf9\u6210\u672c\u7684\u7b49\u4ef7\u6027\u3002", "conclusion": "\u4e24\u79cd\u65b9\u6cd5\u5728\u8bed\u4e49\u5c42\u9762\u5b58\u5728\u7b49\u4ef7\u5173\u7cfb\uff0c\u8fd9\u4e00\u53d1\u73b0\u6709\u52a9\u4e8e\u8fdb\u4e00\u6b65\u63a8\u52a8\u6210\u672c\u8bed\u4e49\u548cc-\u8868\u793a\u7684\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2510.00821", "categories": ["cs.AI", "90C05, 68T27", "I.2.3; F.4.1"], "pdf": "https://arxiv.org/pdf/2510.00821", "abs": "https://arxiv.org/abs/2510.00821", "authors": ["Andr\u00e9s Corrada-Emmanuel"], "title": "Logical Consistency Between Disagreeing Experts and Its Role in AI Safety", "comment": "10 pages, 7 figures", "summary": "If two experts disagree on a test, we may conclude both cannot be 100 per\ncent correct. But if they completely agree, no possible evaluation can be\nexcluded. This asymmetry in the utility of agreements versus disagreements is\nexplored here by formalizing a logic of unsupervised evaluation for\nclassifiers. Its core problem is computing the set of group evaluations that\nare logically consistent with how we observe them agreeing and disagreeing in\ntheir decisions. Statistical summaries of their aligned decisions are inputs\ninto a Linear Programming problem in the integer space of possible correct or\nincorrect responses given true labels. Obvious logical constraints, such as,\nthe number of correct responses cannot exceed the number of observed responses,\nare inequalities. But in addition, there are axioms, universally applicable\nlinear equalities that apply to all finite tests. The practical and immediate\nutility of this approach to unsupervised evaluation using only logical\nconsistency is demonstrated by building no-knowledge alarms that can detect\nwhen one or more LLMs-as-Judges are violating a minimum grading threshold\nspecified by the user.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u8bc4\u4f30\u5206\u7c7b\u5668\u7684\u903b\u8f91\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5206\u7c7b\u5668\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u548c\u5206\u6b67\u6765\u63a8\u65ad\u5176\u6027\u80fd\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u7ebf\u6027\u89c4\u5212\u5728\u6574\u6570\u7a7a\u95f4\u4e2d\u8ba1\u7b97\u4e0e\u89c2\u5bdf\u5230\u7684\u51b3\u7b56\u4e00\u81f4\u7684\u53ef\u80fd\u6b63\u786e\u6216\u9519\u8bef\u54cd\u5e94\u96c6\u5408\u3002", "motivation": "\u5f53\u4e13\u5bb6\u5728\u6d4b\u8bd5\u4e2d\u51fa\u73b0\u5206\u6b67\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u65ad\u5b9a\u4ed6\u4eec\u4e0d\u53ef\u80fd\u90fd100%\u6b63\u786e\uff1b\u4f46\u5f53\u4ed6\u4eec\u5b8c\u5168\u4e00\u81f4\u65f6\uff0c\u65e0\u6cd5\u6392\u9664\u4efb\u4f55\u53ef\u80fd\u7684\u8bc4\u4f30\u7ed3\u679c\u3002\u8fd9\u79cd\u4e00\u81f4\u6027\u4e0e\u5206\u6b67\u5728\u6548\u7528\u4e0a\u7684\u4e0d\u5bf9\u79f0\u6027\u6fc0\u53d1\u4e86\u672c\u6587\u5bf9\u65e0\u76d1\u7763\u5206\u7c7b\u5668\u8bc4\u4f30\u903b\u8f91\u7684\u63a2\u7d22\u3002", "method": "\u5c06\u5206\u7c7b\u5668\u5bf9\u9f50\u51b3\u7b56\u7684\u7edf\u8ba1\u6458\u8981\u4f5c\u4e3a\u8f93\u5165\uff0c\u6784\u5efa\u6574\u6570\u7a7a\u95f4\u4e2d\u53ef\u80fd\u6b63\u786e\u6216\u9519\u8bef\u54cd\u5e94\u7684\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u3002\u5305\u542b\u660e\u663e\u903b\u8f91\u7ea6\u675f\uff08\u5982\u6b63\u786e\u54cd\u5e94\u6570\u4e0d\u80fd\u8d85\u8fc7\u89c2\u5bdf\u54cd\u5e94\u6570\uff09\u4f5c\u4e3a\u4e0d\u7b49\u5f0f\uff0c\u4ee5\u53ca\u9002\u7528\u4e8e\u6240\u6709\u6709\u9650\u6d4b\u8bd5\u7684\u666e\u904d\u7ebf\u6027\u7b49\u5f0f\u516c\u7406\u3002", "result": "\u8be5\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u548c\u5373\u65f6\u6548\u7528\uff0c\u901a\u8fc7\u6784\u5efa\u65e0\u77e5\u8bc6\u8b66\u62a5\u7cfb\u7edf\uff0c\u80fd\u591f\u68c0\u6d4b\u5f53\u4e00\u4e2a\u6216\u591a\u4e2aLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u8fdd\u53cd\u7528\u6237\u6307\u5b9a\u7684\u6700\u4f4e\u8bc4\u5206\u9608\u503c\u65f6\u7684\u60c5\u51b5\u3002", "conclusion": "\u4ec5\u57fa\u4e8e\u903b\u8f91\u4e00\u81f4\u6027\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u65b9\u6cd5\u4e3a\u5206\u7c7b\u5668\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u68c0\u6d4bLLM\u8bc4\u5224\u8005\u7684\u8fdd\u89c4\u884c\u4e3a\uff0c\u65e0\u9700\u4f9d\u8d56\u771f\u5b9e\u6807\u7b7e\u77e5\u8bc6\u3002"}}
{"id": "2510.00831", "categories": ["cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00831", "abs": "https://arxiv.org/abs/2510.00831", "authors": ["Julian Oelhaf", "Georg Kordowich", "Changhun Kim", "Paula Andrea P\u00e9rez-Toro", "Christian Bergler", "Andreas Maier", "Johann J\u00e4ger", "Siming Bayer"], "title": "Benchmarking Machine Learning Models for Fault Classification and Localization in Power System Protection", "comment": "Submitted to ICASSP 2026; under review", "summary": "The increasing integration of distributed energy resources (DERs),\nparticularly renewables, poses significant challenges for power system\nprotection, with fault classification (FC) and fault localization (FL) being\namong the most critical tasks. Conventional protection schemes, based on fixed\nthresholds, cannot reliably identify and localize short circuits with the\nincreasing complexity of the grid under dynamic conditions. Machine learning\n(ML) offers a promising alternative; however, systematic benchmarks across\nmodels and settings remain limited. This work presents, for the first time, a\ncomparative benchmarking study of classical ML models for FC and FL in power\nsystem protection based on EMT data. Using voltage and current waveforms\nsegmented into sliding windows of 10 ms to 50 ms, we evaluate models under\nrealistic real-time constraints. Performance is assessed in terms of accuracy,\nrobustness to window size, and runtime efficiency. The best-performing FC model\nachieved an F1 score of 0.992$\\pm$0.001, while the top FL model reached an R2\nof 0.806$\\pm$0.008 with a mean processing time of 0.563 ms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u7535\u529b\u7cfb\u7edf\u4fdd\u62a4\u4e2d\u7684\u6545\u969c\u5206\u7c7b\u548c\u6545\u969c\u5b9a\u4f4d\u8fdb\u884c\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6bd4\u8f83\u57fa\u51c6\u7814\u7a76\uff0c\u57fa\u4e8eEMT\u6570\u636e\u8bc4\u4f30\u4e86\u7ecf\u5178ML\u6a21\u578b\u5728\u5b9e\u65f6\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\uff08\u7279\u522b\u662f\u53ef\u518d\u751f\u80fd\u6e90\uff09\u7684\u65e5\u76ca\u96c6\u6210\u7ed9\u7535\u529b\u7cfb\u7edf\u4fdd\u62a4\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\uff0c\u4f20\u7edf\u7684\u57fa\u4e8e\u56fa\u5b9a\u9608\u503c\u7684\u4fdd\u62a4\u65b9\u6848\u5728\u52a8\u6001\u6761\u4ef6\u4e0b\u65e0\u6cd5\u53ef\u9760\u8bc6\u522b\u548c\u5b9a\u4f4d\u77ed\u8def\u6545\u969c\u3002", "method": "\u4f7f\u7528\u7535\u538b\u548c\u7535\u6d41\u6ce2\u5f62\u6570\u636e\uff0c\u5c06\u5176\u5206\u5272\u4e3a10\u6beb\u79d2\u523050\u6beb\u79d2\u7684\u6ed1\u52a8\u7a97\u53e3\uff0c\u5728\u73b0\u5b9e\u7684\u5b9e\u65f6\u7ea6\u675f\u4e0b\u8bc4\u4f30\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u6700\u4f73\u6545\u969c\u5206\u7c7b\u6a21\u578b\u7684F1\u5f97\u5206\u4e3a0.992\u00b10.001\uff0c\u6700\u4f73\u6545\u969c\u5b9a\u4f4d\u6a21\u578b\u7684R2\u4e3a0.806\u00b10.008\uff0c\u5e73\u5747\u5904\u7406\u65f6\u95f4\u4e3a0.563\u6beb\u79d2\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u4e3a\u7535\u529b\u7cfb\u7edf\u4fdd\u62a4\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u672c\u7814\u7a76\u9996\u6b21\u63d0\u4f9b\u4e86\u8de8\u6a21\u578b\u548c\u8bbe\u7f6e\u7684\u7cfb\u7edf\u6027\u57fa\u51c6\u6bd4\u8f83\u3002"}}
{"id": "2510.00836", "categories": ["cs.AI", "cs.CE", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2510.00836", "abs": "https://arxiv.org/abs/2510.00836", "authors": ["Jieun Yu", "Minjung Park", "Sangmi Chai"], "title": "Improving Cryptocurrency Pump-and-Dump Detection through Ensemble-Based Models and Synthetic Oversampling Techniques", "comment": null, "summary": "This study aims to detect pump and dump (P&D) manipulation in cryptocurrency\nmarkets, where the scarcity of such events causes severe class imbalance and\nhinders accurate detection. To address this issue, the Synthetic Minority\nOversampling Technique (SMOTE) was applied, and advanced ensemble learning\nmodels were evaluated to distinguish manipulative trading behavior from normal\nmarket activity. The experimental results show that applying SMOTE greatly\nenhanced the ability of all models to detect P&D events by increasing recall\nand improving the overall balance between precision and recall. In particular,\nXGBoost and LightGBM achieved high recall rates (94.87% and 93.59%,\nrespectively) with strong F1-scores and demonstrated fast computational\nperformance, making them suitable for near real time surveillance. These\nfindings indicate that integrating data balancing techniques with ensemble\nmethods significantly improves the early detection of manipulative activities,\ncontributing to a fairer, more transparent, and more stable cryptocurrency\nmarket.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528SMOTE\u6280\u672f\u5904\u7406\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2d\u6cf5\u4e0e\u503e\u5012(P&D)\u64cd\u7eb5\u68c0\u6d4b\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u8bc4\u4f30\u96c6\u6210\u5b66\u4e60\u6a21\u578b\u3002XGBoost\u548cLightGBM\u8868\u73b0\u6700\u4f73\uff0c\u5b9e\u73b0\u4e86\u9ad8\u53ec\u56de\u7387\u548c\u5feb\u901f\u8ba1\u7b97\u6027\u80fd\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2d\u6cf5\u4e0e\u503e\u5012\u64cd\u7eb5\u4e8b\u4ef6\u7684\u7a00\u7f3a\u6027\u5bfc\u81f4\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u963b\u788d\u4e86\u51c6\u786e\u7684\u68c0\u6d4b\u3002", "method": "\u5e94\u7528\u5408\u6210\u5c11\u6570\u7c7b\u8fc7\u91c7\u6837\u6280\u672f(SMOTE)\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u5e76\u8bc4\u4f30\u5148\u8fdb\u7684\u96c6\u6210\u5b66\u4e60\u6a21\u578b\u6765\u533a\u5206\u64cd\u7eb5\u6027\u4ea4\u6613\u884c\u4e3a\u548c\u6b63\u5e38\u5e02\u573a\u6d3b\u52a8\u3002", "result": "\u5e94\u7528SMOTE\u663e\u8457\u63d0\u9ad8\u4e86\u6240\u6709\u6a21\u578b\u68c0\u6d4bP&D\u4e8b\u4ef6\u7684\u80fd\u529b\uff0cXGBoost\u548cLightGBM\u5206\u522b\u5b9e\u73b0\u4e8694.87%\u548c93.59%\u7684\u9ad8\u53ec\u56de\u7387\uff0c\u5e76\u8868\u73b0\u51fa\u5feb\u901f\u8ba1\u7b97\u6027\u80fd\u3002", "conclusion": "\u5c06\u6570\u636e\u5e73\u8861\u6280\u672f\u4e0e\u96c6\u6210\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u53ef\u663e\u8457\u63d0\u9ad8\u64cd\u7eb5\u6d3b\u52a8\u7684\u65e9\u671f\u68c0\u6d4b\u80fd\u529b\uff0c\u6709\u52a9\u4e8e\u5efa\u7acb\u66f4\u516c\u5e73\u3001\u900f\u660e\u548c\u7a33\u5b9a\u7684\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u3002"}}
{"id": "2510.00844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00844", "abs": "https://arxiv.org/abs/2510.00844", "authors": ["Jianhao Chen", "Chenxu Wang", "Gengrui Zhang", "Peng Ye", "Lei Bai", "Wei Hu", "Yuzhong Qu", "Shuyue Hu"], "title": "Learning Compact Representations of LLM Abilities via Item Response Theory", "comment": null, "summary": "Recent years have witnessed a surge in the number of large language models\n(LLMs), yet efficiently managing and utilizing these vast resources remains a\nsignificant challenge. In this work, we explore how to learn compact\nrepresentations of LLM abilities that can facilitate downstream tasks, such as\nmodel routing and performance prediction on new benchmarks. We frame this\nproblem as estimating the probability that a given model will correctly answer\na specific query. Inspired by the item response theory (IRT) in psychometrics,\nwe model this probability as a function of three key factors: (i) the model's\nmulti-skill ability vector, (2) the query's discrimination vector that\nseparates models of differing skills, and (3) the query's difficulty scalar. To\nlearn these parameters jointly, we introduce a Mixture-of-Experts (MoE) network\nthat couples model- and query-level embeddings. Extensive experiments\ndemonstrate that our approach leads to state-of-the-art performance in both\nmodel routing and benchmark accuracy prediction. Moreover, analysis validates\nthat the learned parameters encode meaningful, interpretable information about\nmodel capabilities and query characteristics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9879\u76ee\u53cd\u5e94\u7406\u8bba(IRT)\u7684\u65b9\u6cd5\u6765\u5b66\u4e60\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u7d27\u51d1\u8868\u793a\uff0c\u901a\u8fc7\u5efa\u6a21\u6a21\u578b\u80fd\u529b\u3001\u67e5\u8be2\u533a\u5206\u5ea6\u548c\u96be\u5ea6\u4e09\u4e2a\u56e0\u7d20\uff0c\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u7f51\u7edc(MoE)\u8054\u5408\u5b66\u4e60\u8fd9\u4e9b\u53c2\u6570\uff0c\u5728\u6a21\u578b\u8def\u7531\u548c\u57fa\u51c6\u51c6\u786e\u7387\u9884\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u6570\u91cf\u7684\u6fc0\u589e\uff0c\u5982\u4f55\u9ad8\u6548\u7ba1\u7406\u548c\u5229\u7528\u8fd9\u4e9b\u5e9e\u5927\u8d44\u6e90\u6210\u4e3a\u4e00\u4e2a\u91cd\u8981\u6311\u6218\u3002\u9700\u8981\u5b66\u4e60LLM\u80fd\u529b\u7684\u7d27\u51d1\u8868\u793a\u6765\u4fc3\u8fdb\u4e0b\u6e38\u4efb\u52a1\uff0c\u5982\u6a21\u578b\u8def\u7531\u548c\u65b0\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u9884\u6d4b\u3002", "method": "\u53d7\u5fc3\u7406\u6d4b\u91cf\u5b66\u4e2d\u9879\u76ee\u53cd\u5e94\u7406\u8bba(IRT)\u7684\u542f\u53d1\uff0c\u5c06\u6a21\u578b\u6b63\u786e\u56de\u7b54\u67e5\u8be2\u7684\u6982\u7387\u5efa\u6a21\u4e3a\u4e09\u4e2a\u5173\u952e\u56e0\u7d20\u7684\u51fd\u6570\uff1a\u6a21\u578b\u7684\u591a\u6280\u80fd\u80fd\u529b\u5411\u91cf\u3001\u67e5\u8be2\u7684\u533a\u5206\u5ea6\u5411\u91cf\u548c\u67e5\u8be2\u7684\u96be\u5ea6\u6807\u91cf\u3002\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u7f51\u7edc(MoE)\u8026\u5408\u6a21\u578b\u7ea7\u548c\u67e5\u8be2\u7ea7\u5d4c\u5165\u6765\u8054\u5408\u5b66\u4e60\u8fd9\u4e9b\u53c2\u6570\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u8def\u7531\u548c\u57fa\u51c6\u51c6\u786e\u7387\u9884\u6d4b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u5206\u6790\u9a8c\u8bc1\u4e86\u5b66\u4e60\u5230\u7684\u53c2\u6570\u7f16\u7801\u4e86\u5173\u4e8e\u6a21\u578b\u80fd\u529b\u548c\u67e5\u8be2\u7279\u5f81\u7684\u6709\u610f\u4e49\u3001\u53ef\u89e3\u91ca\u7684\u4fe1\u606f\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eIRT\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5b66\u4e60LLM\u80fd\u529b\u7684\u7d27\u51d1\u8868\u793a\uff0c\u8fd9\u4e9b\u8868\u793a\u4e0d\u4ec5\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u800c\u4e14\u5177\u6709\u5f88\u597d\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u7ba1\u7406\u548c\u5229\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00876", "categories": ["cs.AI", "68T20", "I.2.8"], "pdf": "https://arxiv.org/pdf/2510.00876", "abs": "https://arxiv.org/abs/2510.00876", "authors": ["Pietro Totis", "Alberto Pozanco", "Daniel Borrajo"], "title": "Unveiling Interesting Insights: Monte Carlo Tree Search for Knowledge Discovery", "comment": null, "summary": "Organizations are increasingly focused on leveraging data from their\nprocesses to gain insights and drive decision-making. However, converting this\ndata into actionable knowledge remains a difficult and time-consuming task.\nThere is often a gap between the volume of data collected and the ability to\nprocess and understand it, which automated knowledge discovery aims to fill.\nAutomated knowledge discovery involves complex open problems, including\neffectively navigating data, building models to extract implicit relationships,\nand considering subjective goals and knowledge. In this paper, we introduce a\nnovel method for Automated Insights and Data Exploration (AIDE), that serves as\na robust foundation for tackling these challenges through the use of Monte\nCarlo Tree Search (MCTS). We evaluate AIDE using both real-world and synthetic\ndata, demonstrating its effectiveness in identifying data transformations and\nmodels that uncover interesting data patterns. Among its strengths, AIDE's\nMCTS-based framework offers significant extensibility, allowing for future\nintegration of additional pattern extraction strategies and domain knowledge.\nThis makes AIDE a valuable step towards developing a comprehensive solution for\nautomated knowledge discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u81ea\u52a8\u6d1e\u5bdf\u548c\u6570\u636e\u63a2\u7d22\u65b9\u6cd5AIDE\uff0c\u7528\u4e8e\u89e3\u51b3\u4ece\u6570\u636e\u5230\u53ef\u64cd\u4f5c\u77e5\u8bc6\u7684\u8f6c\u5316\u96be\u9898\u3002", "motivation": "\u7ec4\u7ec7\u6536\u96c6\u4e86\u5927\u91cf\u6570\u636e\u4f46\u96be\u4ee5\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u77e5\u8bc6\uff0c\u81ea\u52a8\u5316\u77e5\u8bc6\u53d1\u73b0\u9762\u4e34\u6570\u636e\u5bfc\u822a\u3001\u6a21\u578b\u6784\u5efa\u548c\u4e3b\u89c2\u76ee\u6807\u7b49\u590d\u6742\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6846\u67b6\u6784\u5efaAIDE\u7cfb\u7edf\uff0c\u80fd\u591f\u81ea\u52a8\u8bc6\u522b\u6570\u636e\u8f6c\u6362\u548c\u6a21\u578b\u6765\u53d1\u73b0\u6709\u8da3\u7684\u6570\u636e\u6a21\u5f0f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cAIDE\u80fd\u6709\u6548\u8bc6\u522b\u6570\u636e\u8f6c\u6362\u548c\u6a21\u578b\uff0c\u53d1\u73b0\u6709\u8da3\u7684\u6570\u636e\u6a21\u5f0f\u3002", "conclusion": "AIDE\u4e3a\u81ea\u52a8\u5316\u77e5\u8bc6\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u6846\u67b6\uff0c\u672a\u6765\u53ef\u96c6\u6210\u66f4\u591a\u6a21\u5f0f\u63d0\u53d6\u7b56\u7565\u548c\u9886\u57df\u77e5\u8bc6\u3002"}}
{"id": "2510.00894", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00894", "abs": "https://arxiv.org/abs/2510.00894", "authors": ["Ran Liu", "Yuan Fang", "Xiaoli Li"], "title": "FusionAdapter for Few-Shot Relation Learning in Multimodal Knowledge Graphs", "comment": "Archived paper", "summary": "Multimodal Knowledge Graphs (MMKGs) incorporate various modalities, including\ntext and images, to enhance entity and relation representations. Notably,\ndifferent modalities for the same entity often present complementary and\ndiverse information. However, existing MMKG methods primarily align modalities\ninto a shared space, which tends to overlook the distinct contributions of\nspecific modalities, limiting their performance particularly in low-resource\nsettings. To address this challenge, we propose FusionAdapter for the learning\nof few-shot relationships (FSRL) in MMKG. FusionAdapter introduces (1) an\nadapter module that enables efficient adaptation of each modality to unseen\nrelations and (2) a fusion strategy that integrates multimodal entity\nrepresentations while preserving diverse modality-specific characteristics. By\neffectively adapting and fusing information from diverse modalities,\nFusionAdapter improves generalization to novel relations with minimal\nsupervision. Extensive experiments on two benchmark MMKG datasets demonstrate\nthat FusionAdapter achieves superior performance over state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faFusionAdapter\u65b9\u6cd5\u7528\u4e8e\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5c11\u6837\u672c\u5173\u7cfb\u5b66\u4e60\uff0c\u901a\u8fc7\u9002\u914d\u5668\u6a21\u5757\u548c\u878d\u5408\u7b56\u7565\u6709\u6548\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709MMKG\u65b9\u6cd5\u4e3b\u8981\u5c06\u591a\u6a21\u6001\u5bf9\u9f50\u5230\u5171\u4eab\u7a7a\u95f4\uff0c\u5ffd\u7565\u4e86\u7279\u5b9a\u6a21\u6001\u7684\u72ec\u7279\u8d21\u732e\uff0c\u5728\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u6027\u80fd\u53d7\u9650\u3002", "method": "\u5f15\u5165\u9002\u914d\u5668\u6a21\u5757\u4f7f\u5404\u6a21\u6001\u80fd\u9ad8\u6548\u9002\u5e94\u672a\u89c1\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u878d\u5408\u7b56\u7565\u5728\u6574\u5408\u591a\u6a21\u6001\u5b9e\u4f53\u8868\u793a\u65f6\u4fdd\u6301\u6a21\u6001\u7279\u5b9a\u7279\u5f81\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6MMKG\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFusionAdapter\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6709\u6548\u9002\u5e94\u548c\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff0cFusionAdapter\u80fd\u4ee5\u6700\u5c0f\u76d1\u7763\u63d0\u9ad8\u5bf9\u65b0\u5173\u7cfb\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.00922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00922", "abs": "https://arxiv.org/abs/2510.00922", "authors": ["Shashank Reddy Chirra", "Jayden Teoh", "Praveen Paruchuri", "Pradeep Varakantham"], "title": "On Discovering Algorithms for Adversarial Imitation Learning", "comment": null, "summary": "Adversarial Imitation Learning (AIL) methods, while effective in settings\nwith limited expert demonstrations, are often considered unstable. These\napproaches typically decompose into two components: Density Ratio (DR)\nestimation $\\frac{\\rho_E}{\\rho_{\\pi}}$, where a discriminator estimates the\nrelative occupancy of state-action pairs under the policy versus the expert;\nand Reward Assignment (RA), where this ratio is transformed into a reward\nsignal used to train the policy. While significant research has focused on\nimproving density estimation, the role of reward assignment in influencing\ntraining dynamics and final policy performance has been largely overlooked. RA\nfunctions in AIL are typically derived from divergence minimization objectives,\nrelying heavily on human design and ingenuity. In this work, we take a\ndifferent approach: we investigate the discovery of data-driven RA functions,\ni.e, based directly on the performance of the resulting imitation policy. To\nthis end, we leverage an LLM-guided evolutionary framework that efficiently\nexplores the space of RA functions, yielding \\emph{Discovered Adversarial\nImitation Learning} (DAIL), the first meta-learnt AIL algorithm. Remarkably,\nDAIL generalises across unseen environments and policy optimization algorithms,\noutperforming the current state-of-the-art of \\emph{human-designed} baselines.\nFinally, we analyse why DAIL leads to more stable training, offering novel\ninsights into the role of RA functions in the stability of AIL. Code is\npublicly available: https://github.com/shshnkreddy/DAIL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u5956\u52b1\u5206\u914d\u51fd\u6570\u53d1\u73b0\u65b9\u6cd5DAIL\uff0c\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u8fdb\u5316\u6846\u67b6\u81ea\u52a8\u63a2\u7d22\u5956\u52b1\u5206\u914d\u51fd\u6570\u7a7a\u95f4\uff0c\u5728\u672a\u89c1\u8fc7\u7684\u73af\u5883\u548c\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86\u4eba\u5de5\u8bbe\u8ba1\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5bf9\u6297\u6a21\u4eff\u5b66\u4e60(AIL)\u65b9\u6cd5\u867d\u7136\u6709\u6548\u4f46\u88ab\u8ba4\u4e3a\u4e0d\u7a33\u5b9a\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\uff0c\u800c\u5956\u52b1\u5206\u914d\u51fd\u6570\u5bf9\u8bad\u7ec3\u52a8\u6001\u548c\u6700\u7ec8\u7b56\u7565\u6027\u80fd\u7684\u5f71\u54cd\u88ab\u5ffd\u89c6\uff0c\u4e14\u901a\u5e38\u4f9d\u8d56\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528LLM\u5f15\u5bfc\u7684\u8fdb\u5316\u6846\u67b6\u6765\u63a2\u7d22\u5956\u52b1\u5206\u914d\u51fd\u6570\u7a7a\u95f4\uff0c\u57fa\u4e8e\u6a21\u4eff\u7b56\u7565\u7684\u6027\u80fd\u76f4\u63a5\u53d1\u73b0\u6570\u636e\u9a71\u52a8\u7684\u5956\u52b1\u5206\u914d\u51fd\u6570\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u5143\u5b66\u4e60\u7684AIL\u7b97\u6cd5DAIL\u3002", "result": "DAIL\u5728\u672a\u89c1\u8fc7\u7684\u73af\u5883\u548c\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4eba\u5de5\u8bbe\u8ba1\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5e26\u6765\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002", "conclusion": "DAIL\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u53d1\u73b0\u4e86\u66f4\u6709\u6548\u7684\u5956\u52b1\u5206\u914d\u51fd\u6570\uff0c\u4e3aAIL\u7684\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u8bc1\u660e\u4e86\u5956\u52b1\u5206\u914d\u51fd\u6570\u5728AIL\u7a33\u5b9a\u6027\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2510.00958", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.00958", "abs": "https://arxiv.org/abs/2510.00958", "authors": ["Yoonju Sim", "Hyeonah Kim", "Changhyun Kwon"], "title": "Test-Time Search in Neural Graph Coarsening Procedures for the Capacitated Vehicle Routing Problem", "comment": null, "summary": "The identification of valid inequalities, such as the rounded capacity\ninequalities (RCIs), is a key component of cutting plane methods for the\nCapacitated Vehicle Routing Problem (CVRP). While a deep learning-based\nseparation method can learn to find high-quality cuts, our analysis reveals\nthat the model produces fewer cuts than expected because it is insufficiently\nsensitive to generate a diverse set of generated subsets. This paper proposes\nan alternative: enhancing the performance of a trained model at inference time\nthrough a new test-time search with stochasticity. First, we introduce\nstochastic edge selection into the graph coarsening procedure, replacing the\npreviously proposed greedy approach. Second, we propose the Graph Coarsening\nHistory-based Partitioning (GraphCHiP) algorithm, which leverages coarsening\nhistory to identify not only RCIs but also, for the first time, the Framed\ncapacity inequalities (FCIs). Experiments on randomly generated CVRP instances\ndemonstrate the effectiveness of our approach in reducing the dual gap compared\nto the existing neural separation method. Additionally, our method discovers\neffective FCIs on a specific instance, despite the challenging nature of\nidentifying such cuts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u6027\u7684\u6d4b\u8bd5\u65f6\u641c\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u56fe\u7c97\u5316\u8fc7\u7a0b\u4e2d\u5f15\u5165\u968f\u673a\u8fb9\u9009\u62e9\u548cGraphCHiP\u7b97\u6cd5\uff0c\u63d0\u9ad8\u4e86\u795e\u7ecf\u7f51\u7edc\u5206\u79bb\u65b9\u6cd5\u5728CVRP\u95ee\u9898\u4e2d\u8bc6\u522b\u6709\u6548\u4e0d\u7b49\u5f0f\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u79bb\u65b9\u6cd5\u5728\u8bc6\u522b\u6709\u6548\u4e0d\u7b49\u5f0f\u65f6\u751f\u6210\u7684\u4e0d\u7b49\u5f0f\u6570\u91cf\u4e0d\u8db3\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u6a21\u578b\u5bf9\u751f\u6210\u591a\u6837\u5316\u5b50\u96c6\u7684\u654f\u611f\u6027\u4e0d\u591f\u3002", "method": "1. \u5728\u56fe\u7c97\u5316\u8fc7\u7a0b\u4e2d\u5f15\u5165\u968f\u673a\u8fb9\u9009\u62e9\u66ff\u4ee3\u8d2a\u5a6a\u65b9\u6cd5\uff1b2. \u63d0\u51faGraphCHiP\u7b97\u6cd5\uff0c\u5229\u7528\u7c97\u5316\u5386\u53f2\u8bc6\u522bRCIs\u548cFCIs\u3002", "result": "\u5728\u968f\u673a\u751f\u6210\u7684CVRP\u5b9e\u4f8b\u4e0a\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u795e\u7ecf\u5206\u79bb\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u51cf\u5c11\u5bf9\u5076\u95f4\u9699\uff0c\u5e76\u9996\u6b21\u6210\u529f\u8bc6\u522b\u51fa\u6709\u6548\u7684FCIs\u3002", "conclusion": "\u901a\u8fc7\u6d4b\u8bd5\u65f6\u641c\u7d22\u589e\u5f3a\u8bad\u7ec3\u6a21\u578b\u6027\u80fd\uff0c\u80fd\u591f\u63d0\u9ad8\u6709\u6548\u4e0d\u7b49\u5f0f\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u8bc6\u522b\u5177\u6709\u6311\u6218\u6027\u7684FCIs\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.00967", "categories": ["cs.AI", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.00967", "abs": "https://arxiv.org/abs/2510.00967", "authors": ["Cong Yu", "Valter Uotila", "Shilong Deng", "Qingyuan Wu", "Tuo Shi", "Songlin Jiang", "Lei You", "Bo Zhao"], "title": "QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL", "comment": null, "summary": "Designing and optimizing task-specific quantum circuits are crucial to\nleverage the advantage of quantum computing. Recent large language model\n(LLM)-based quantum circuit generation has emerged as a promising automatic\nsolution. However, the fundamental challenges remain unaddressed: (i)\nparameterized quantum gates require precise numerical values for optimal\nperformance, which also depend on multiple aspects, including the number of\nquantum gates, their parameters, and the layout/depth of the circuits. (ii)\nLLMs often generate low-quality or incorrect quantum circuits due to the lack\nof quantum domain-specific knowledge. We propose QUASAR, an agentic\nreinforcement learning (RL) framework for quantum circuits generation and\noptimization based on tool-augmented LLMs. To align the LLM with\nquantum-specific knowledge and improve the generated quantum circuits, QUASAR\ndesigns (i) a quantum circuit verification approach with external quantum\nsimulators and (ii) a sophisticated hierarchical reward mechanism in RL\ntraining. Extensive evaluation shows improvements in both syntax and semantic\nperformance of the generated quantum circuits. When augmenting a 4B LLM, QUASAR\nhas achieved the validity of 99.31% in Pass@1 and 100% in Pass@10,\noutperforming industrial LLMs of GPT-4o, GPT-5 and DeepSeek-V3 and several\nsupervised-fine-tuning (SFT)-only and RL-only baselines.", "AI": {"tldr": "QUASAR\u662f\u4e00\u4e2a\u57fa\u4e8e\u5de5\u5177\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u548c\u4f18\u5316\u91cf\u5b50\u7535\u8def\uff0c\u901a\u8fc7\u91cf\u5b50\u6a21\u62df\u5668\u9a8c\u8bc1\u548c\u5206\u5c42\u5956\u52b1\u673a\u5236\u89e3\u51b3LLM\u751f\u6210\u91cf\u5b50\u7535\u8def\u7684\u8d28\u91cf\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u91cf\u5b50\u7535\u8def\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a(i)\u53c2\u6570\u5316\u91cf\u5b50\u95e8\u9700\u8981\u7cbe\u786e\u6570\u503c\u4f18\u5316\uff0c(ii)LLM\u7f3a\u4e4f\u91cf\u5b50\u9886\u57df\u77e5\u8bc6\u5bfc\u81f4\u751f\u6210\u4f4e\u8d28\u91cf\u7535\u8def\u3002", "method": "\u63d0\u51faQUASAR\u6846\u67b6\uff0c\u5305\u542b\u91cf\u5b50\u7535\u8def\u9a8c\u8bc1\u65b9\u6cd5\u548c\u5206\u5c42\u5956\u52b1\u673a\u5236\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u4f7f\u7528\u5916\u90e8\u91cf\u5b50\u6a21\u62df\u5668\u9a8c\u8bc1\u7535\u8def\u8d28\u91cf\u3002", "result": "\u57284B\u53c2\u6570LLM\u4e0a\uff0cQUASAR\u5728Pass@1\u8fbe\u523099.31%\u6709\u6548\u6027\uff0cPass@10\u8fbe\u5230100%\uff0c\u4f18\u4e8eGPT-4o\u3001GPT-5\u3001DeepSeek-V3\u7b49\u5de5\u4e1a\u7ea7LLM\u548c\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "QUASAR\u901a\u8fc7\u5de5\u5177\u589e\u5f3a\u548c\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u91cf\u5b50\u7535\u8def\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u91cf\u5b50\u9886\u57df\u77e5\u8bc6\u7f3a\u4e4f\u7684\u95ee\u9898\u3002"}}
{"id": "2510.00976", "categories": ["cs.AI", "cs.CR", "cs.DC", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.00976", "abs": "https://arxiv.org/abs/2510.00976", "authors": ["Aueaphum Aueawatthanaphisut"], "title": "Adaptive Federated Few-Shot Rare-Disease Diagnosis with Energy-Aware Secure Aggregation", "comment": "6 pages, 6 figures, 12 equations, 1 algorithm", "summary": "Rare-disease diagnosis remains one of the most pressing challenges in digital\nhealth, hindered by extreme data scarcity, privacy concerns, and the limited\nresources of edge devices. This paper proposes the Adaptive Federated Few-Shot\nRare-Disease Diagnosis (AFFR) framework, which integrates three pillars: (i)\nfew-shot federated optimization with meta-learning to generalize from limited\npatient samples, (ii) energy-aware client scheduling to mitigate device\ndropouts and ensure balanced participation, and (iii) secure aggregation with\ncalibrated differential privacy to safeguard sensitive model updates. Unlike\nprior work that addresses these aspects in isolation, AFFR unifies them into a\nmodular pipeline deployable on real-world clinical networks. Experimental\nevaluation on simulated rare-disease detection datasets demonstrates up to 10%\nimprovement in accuracy compared with baseline FL, while reducing client\ndropouts by over 50% without degrading convergence. Furthermore,\nprivacy-utility trade-offs remain within clinically acceptable bounds. These\nfindings highlight AFFR as a practical pathway for equitable and trustworthy\nfederated diagnosis of rare conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86AFFR\u6846\u67b6\uff0c\u6574\u5408\u5143\u5b66\u4e60\u3001\u80fd\u91cf\u611f\u77e5\u5ba2\u6237\u7aef\u8c03\u5ea6\u548c\u5b89\u5168\u805a\u5408\uff0c\u7528\u4e8e\u89e3\u51b3\u7f55\u89c1\u75c5\u8bca\u65ad\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u3001\u8bbe\u5907\u6389\u7ebf\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\u3002", "motivation": "\u7f55\u89c1\u75c5\u8bca\u65ad\u9762\u4e34\u6570\u636e\u6781\u5ea6\u7a00\u7f3a\u3001\u9690\u79c1\u62c5\u5fe7\u548c\u8fb9\u7f18\u8bbe\u5907\u8d44\u6e90\u6709\u9650\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u771f\u5b9e\u4e34\u5e8a\u7f51\u7edc\u4e2d\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u5c11\u6837\u672c\u8054\u90a6\u4f18\u5316\u3001\u80fd\u91cf\u611f\u77e5\u5ba2\u6237\u7aef\u8c03\u5ea6\u4ee5\u51cf\u5c11\u8bbe\u5907\u6389\u7ebf\u3001\u4ee5\u53ca\u5e26\u6821\u51c6\u5dee\u5206\u9690\u79c1\u7684\u5b89\u5168\u805a\u5408\u3002", "result": "\u5728\u6a21\u62df\u7f55\u89c1\u75c5\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u8054\u90a6\u5b66\u4e60\u51c6\u786e\u7387\u63d0\u534710%\uff0c\u5ba2\u6237\u7aef\u6389\u7ebf\u7387\u964d\u4f4e50%\u4ee5\u4e0a\uff0c\u4e14\u9690\u79c1-\u6548\u7528\u6743\u8861\u5728\u4e34\u5e8a\u53ef\u63a5\u53d7\u8303\u56f4\u5185\u3002", "conclusion": "AFFR\u4e3a\u7f55\u89c1\u75c5\u7684\u516c\u5e73\u53ef\u4fe1\u8054\u90a6\u8bca\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u7edf\u4e00\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u3001\u8bbe\u5907\u7a33\u5b9a\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7b49\u5173\u952e\u95ee\u9898\u3002"}}
{"id": "2510.01006", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01006", "abs": "https://arxiv.org/abs/2510.01006", "authors": ["Saravanan Venkatachalam"], "title": "Integrating AI and Ensemble Forecasting: Explainable Materials Planning with Scorecards and Trend Insights for a Large-Scale Manufacturer", "comment": null, "summary": "This paper presents a practical architecture for after-sales demand\nforecasting and monitoring that unifies a revenue- and cluster-aware ensemble\nof statistical, machine-learning, and deep-learning models with a role-driven\nanalytics layer for scorecards and trend diagnostics. The framework ingests\nexogenous signals (installed base, pricing, macro indicators, life cycle,\nseasonality) and treats COVID-19 as a distinct regime, producing country-part\nforecasts with calibrated intervals. A Pareto-aware segmentation forecasts\nhigh-revenue items individually and pools the long tail via clusters, while\nhorizon-aware ensembling aligns weights with business-relevant losses (e.g.,\nWMAPE). Beyond forecasts, a performance scorecard delivers decision-focused\ninsights: accuracy within tolerance thresholds by revenue share and count, bias\ndecomposition (over- vs under-forecast), geographic and product-family\nhotspots, and ranked root causes tied to high-impact part-country pairs. A\ntrend module tracks trajectories of MAPE/WMAPE and bias across recent months,\nflags entities that are improving or deteriorating, detects change points\naligned with known regimes, and attributes movements to lifecycle and seasonal\nfactors. LLMs are embedded in the analytics layer to generate role-aware\nnarratives and enforce reporting contracts. They standardize business\ndefinitions, automate quality checks and reconciliations, and translate\nquantitative results into concise, explainable summaries for planners and\nexecutives. The system exposes a reproducible workflow -- request\nspecification, model execution, database-backed artifacts, and AI-generated\nnarratives -- so planners can move from \"How accurate are we now?\" to \"Where is\naccuracy heading and which levers should we pull?\", closing the loop between\nforecasting, monitoring, and inventory decisions across more than 90 countries\nand about 6,000 parts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u552e\u540e\u9700\u6c42\u9884\u6d4b\u548c\u76d1\u63a7\u7684\u5b9e\u7528\u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u7edf\u8ba1\u3001\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u5e76\u5305\u542b\u9762\u5411\u89d2\u8272\u7684\u5206\u6790\u5c42\uff0c\u7528\u4e8e\u751f\u6210\u8bb0\u5206\u5361\u548c\u8d8b\u52bf\u8bca\u65ad\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u552e\u540e\u9700\u6c42\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u6027\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u8003\u8651\u591a\u79cd\u5916\u90e8\u56e0\u7d20\uff08\u5982COVID-19\u3001\u5b8f\u89c2\u7ecf\u6d4e\u6307\u6807\u7b49\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u63d0\u4f9b\u51c6\u786e\u9884\u6d4b\u5e76\u652f\u6301\u51b3\u7b56\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u6536\u5165\u611f\u77e5\u548c\u805a\u7c7b\u611f\u77e5\u7684\u6a21\u578b\u96c6\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u5916\u751f\u4fe1\u53f7\uff08\u5982\u5b89\u88c5\u57fa\u6570\u3001\u5b9a\u4ef7\u3001\u5b8f\u89c2\u6307\u6807\u7b49\uff09\uff0c\u5e76\u5c06COVID-19\u89c6\u4e3a\u72ec\u7acb\u673a\u5236\u3002\u901a\u8fc7\u5e15\u7d2f\u6258\u611f\u77e5\u5206\u5272\u5bf9\u9ad8\u6536\u5165\u9879\u76ee\u5355\u72ec\u9884\u6d4b\uff0c\u957f\u5c3e\u9879\u76ee\u901a\u8fc7\u805a\u7c7b\u5408\u5e76\u9884\u6d4b\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u56fd\u5bb6-\u90e8\u4ef6\u7ea7\u522b\u7684\u9884\u6d4b\uff0c\u5e76\u63d0\u4f9b\u6821\u51c6\u7684\u7f6e\u4fe1\u533a\u95f4\u3002\u6b64\u5916\uff0c\u6027\u80fd\u8bb0\u5206\u5361\u63d0\u4f9b\u4e86\u51b3\u7b56\u76f8\u5173\u7684\u6d1e\u5bdf\uff0c\u5982\u51c6\u786e\u6027\u9608\u503c\u5185\u7684\u6536\u5165\u4efd\u989d\u548c\u6570\u91cf\u3001\u504f\u5dee\u5206\u89e3\u3001\u5730\u7406\u548c\u4ea7\u54c1\u5bb6\u65cf\u70ed\u70b9\u7b49\u3002", "conclusion": "\u8be5\u67b6\u6784\u901a\u8fc7\u53ef\u590d\u73b0\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5c06\u9884\u6d4b\u3001\u76d1\u63a7\u548c\u5e93\u5b58\u51b3\u7b56\u95ed\u73af\uff0c\u5e2e\u52a9\u89c4\u5212\u8005\u4ece\u201c\u5f53\u524d\u51c6\u786e\u6027\u5982\u4f55\u201d\u8f6c\u5411\u201c\u51c6\u786e\u6027\u8d8b\u52bf\u53ca\u5e94\u91c7\u53d6\u7684\u6760\u6746\u201d\uff0c\u63d0\u5347\u4e86\u51b3\u7b56\u6548\u7387\u3002"}}
{"id": "2510.01025", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01025", "abs": "https://arxiv.org/abs/2510.01025", "authors": ["Federico Tiblias", "Irina Bigoulaeva", "Jingcheng Niu", "Simone Balloccu", "Iryna Gurevych"], "title": "Shape Happens: Automatic Feature Manifold Discovery in LLMs via Supervised Multi-Dimensional Scaling", "comment": null, "summary": "The linear representation hypothesis states that language models (LMs) encode\nconcepts as directions in their latent space, forming organized,\nmultidimensional manifolds. Prior efforts focus on discovering specific\ngeometries for specific features, and thus lack generalization. We introduce\nSupervised Multi-Dimensional Scaling (SMDS), a model-agnostic method to\nautomatically discover feature manifolds. We apply SMDS to temporal reasoning\nas a case study, finding that different features form various geometric\nstructures such as circles, lines, and clusters. SMDS reveals many insights on\nthese structures: they consistently reflect the properties of the concepts they\nrepresent; are stable across model families and sizes; actively support\nreasoning in models; and dynamically reshape in response to context changes.\nTogether, our findings shed light on the functional role of feature manifolds,\nsupporting a model of entity-based reasoning in which LMs encode and transform\nstructured representations.", "AI": {"tldr": "\u63d0\u51fa\u4e86SMDS\u65b9\u6cd5\u6765\u81ea\u52a8\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7279\u5f81\u6d41\u5f62\uff0c\u53d1\u73b0\u4e0d\u540c\u7279\u5f81\u5f62\u6210\u5706\u5f62\u3001\u76f4\u7ebf\u3001\u805a\u7c7b\u7b49\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u4e9b\u7ed3\u6784\u53cd\u6620\u6982\u5ff5\u7279\u6027\u3001\u8de8\u6a21\u578b\u7a33\u5b9a\u3001\u652f\u6301\u63a8\u7406\u5e76\u968f\u4e0a\u4e0b\u6587\u52a8\u6001\u53d8\u5316\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u4e13\u6ce8\u4e8e\u53d1\u73b0\u7279\u5b9a\u7279\u5f81\u7684\u7279\u5b9a\u51e0\u4f55\u7ed3\u6784\uff0c\u7f3a\u4e4f\u6cdb\u5316\u6027\u3002\u9700\u8981\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u53d1\u73b0\u7279\u5f81\u6d41\u5f62\u3002", "method": "\u5f15\u5165\u76d1\u7763\u591a\u7ef4\u7f29\u653e(SMDS)\u65b9\u6cd5\uff0c\u4ee5\u65f6\u95f4\u63a8\u7406\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u81ea\u52a8\u53d1\u73b0\u7279\u5f81\u6d41\u5f62\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u7279\u5f81\u5f62\u6210\u5404\u79cd\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u4e9b\u7ed3\u6784\u4e00\u81f4\u53cd\u6620\u6982\u5ff5\u7279\u6027\u3001\u8de8\u6a21\u578b\u5bb6\u65cf\u548c\u5c3a\u5bf8\u7a33\u5b9a\u3001\u4e3b\u52a8\u652f\u6301\u6a21\u578b\u63a8\u7406\u3001\u5e76\u968f\u4e0a\u4e0b\u6587\u53d8\u5316\u52a8\u6001\u91cd\u5851\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u7279\u5f81\u6d41\u5f62\u7684\u529f\u80fd\u4f5c\u7528\uff0c\u652f\u6301\u57fa\u4e8e\u5b9e\u4f53\u7684\u63a8\u7406\u6a21\u578b\uff0c\u5176\u4e2d\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u548c\u8f6c\u6362\u7ed3\u6784\u5316\u8868\u793a\u3002"}}
{"id": "2510.01030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01030", "abs": "https://arxiv.org/abs/2510.01030", "authors": ["Zach Studdiford", "Timothy T. Rogers", "Kushin Mukherjee", "Siddharth Suresh"], "title": "Uncovering the Computational Ingredients of Human-Like Representations in LLMs", "comment": "9 pages", "summary": "The ability to translate diverse patterns of inputs into structured patterns\nof behavior has been thought to rest on both humans' and machines' ability to\nlearn robust representations of relevant concepts. The rapid advancement of\ntransformer-based large language models (LLMs) has led to a diversity of\ncomputational ingredients -- architectures, fine tuning methods, and training\ndatasets among others -- but it remains unclear which of these ingredients are\nmost crucial for building models that develop human-like representations.\nFurther, most current LLM benchmarks are not suited to measuring\nrepresentational alignment between humans and models, making benchmark scores\nunreliable for assessing if current LLMs are making progress towards becoming\nuseful cognitive models. We address these limitations by first evaluating a set\nof over 70 models that widely vary in their computational ingredients on a\ntriplet similarity task, a method well established in the cognitive sciences\nfor measuring human conceptual representations, using concepts from the THINGS\ndatabase. Comparing human and model representations, we find that models that\nundergo instruction-finetuning and which have larger dimensionality of\nattention heads are among the most human aligned, while multimodal pretraining\nand parameter size have limited bearing on alignment. Correlations between\nalignment scores and scores on existing benchmarks reveal that while some\nbenchmarks (e.g., MMLU) are better suited than others (e.g., MUSR) for\ncapturing representational alignment, no existing benchmark is capable of fully\naccounting for the variance of alignment scores, demonstrating their\ninsufficiency in capturing human-AI alignment. Taken together, our findings\nhelp highlight the computational ingredients most essential for advancing LLMs\ntowards models of human conceptual representation and address a key\nbenchmarking gap in LLM evaluation.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e09\u91cd\u76f8\u4f3c\u6027\u4efb\u52a1\u8bc4\u4f30\u4e8670\u591a\u4e2a\u4e0d\u540c\u67b6\u6784\u7684LLM\uff0c\u53d1\u73b0\u6307\u4ee4\u5fae\u8c03\u548c\u6ce8\u610f\u529b\u5934\u7ef4\u5ea6\u662f\u5f71\u54cd\u6a21\u578b\u4e0e\u4eba\u7c7b\u6982\u5ff5\u8868\u793a\u5bf9\u9f50\u7684\u5173\u952e\u56e0\u7d20\uff0c\u800c\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u548c\u53c2\u6570\u89c4\u6a21\u5f71\u54cd\u6709\u9650\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u4eba\u673a\u5bf9\u9f50\u7a0b\u5ea6\u3002", "motivation": "\u5f53\u524dLLM\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u591a\u6837\u5316\u7684\u8ba1\u7b97\u8981\u7d20\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u54ea\u4e9b\u8981\u7d20\u5bf9\u6784\u5efa\u5177\u6709\u4eba\u7c7b\u7c7b\u4f3c\u8868\u793a\u80fd\u529b\u7684\u6a21\u578b\u6700\u4e3a\u5173\u952e\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u9002\u5408\u8861\u91cf\u4eba\u673a\u8868\u793a\u5bf9\u9f50\uff0c\u4f7f\u5f97\u57fa\u51c6\u5206\u6570\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30LLM\u662f\u5426\u5728\u6210\u4e3a\u6709\u7528\u8ba4\u77e5\u6a21\u578b\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\u3002", "method": "\u4f7f\u7528\u8ba4\u77e5\u79d1\u5b66\u4e2d\u6210\u719f\u7684\u4e09\u91cd\u76f8\u4f3c\u6027\u4efb\u52a1\u65b9\u6cd5\uff0c\u57fa\u4e8eTHINGS\u6570\u636e\u5e93\u4e2d\u7684\u6982\u5ff5\uff0c\u8bc4\u4f30\u4e8670\u591a\u4e2a\u5728\u8ba1\u7b97\u8981\u7d20\u4e0a\u5e7f\u6cdb\u53d8\u5316\u7684\u6a21\u578b\uff0c\u6bd4\u8f83\u4eba\u7c7b\u548c\u6a21\u578b\u7684\u8868\u793a\u5bf9\u9f50\u7a0b\u5ea6\u3002", "result": "\u53d1\u73b0\u7ecf\u8fc7\u6307\u4ee4\u5fae\u8c03\u7684\u6a21\u578b\u548c\u5177\u6709\u66f4\u5927\u6ce8\u610f\u529b\u5934\u7ef4\u5ea6\u7684\u6a21\u578b\u4e0e\u4eba\u7c7b\u8868\u793a\u6700\u4e3a\u5bf9\u9f50\uff0c\u800c\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u548c\u53c2\u6570\u89c4\u6a21\u5bf9\u5bf9\u9f50\u5f71\u54cd\u6709\u9650\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2dMMLU\u6bd4\u5176\u4ed6\u57fa\u51c6\u66f4\u80fd\u6355\u6349\u8868\u793a\u5bf9\u9f50\uff0c\u4f46\u90fd\u65e0\u6cd5\u5b8c\u5168\u89e3\u91ca\u5bf9\u9f50\u5206\u6570\u7684\u65b9\u5dee\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u8bc6\u522b\u63a8\u8fdbLLM\u6210\u4e3a\u4eba\u7c7b\u6982\u5ff5\u8868\u793a\u6a21\u578b\u7684\u6700\u5173\u952e\u8ba1\u7b97\u8981\u7d20\uff0c\u5e76\u89e3\u51b3\u4e86LLM\u8bc4\u4f30\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u57fa\u51c6\u6d4b\u8bd5\u7a7a\u767d\u3002"}}
{"id": "2510.01038", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01038", "abs": "https://arxiv.org/abs/2510.01038", "authors": ["Akchunya Chanchal", "David A. Kelly", "Hana Chockler"], "title": "Activation-Deactivation: A General Framework for Robust Post-hoc Explainable AI", "comment": "Preprint: Under Review", "summary": "Black-box explainability methods are popular tools for explaining the\ndecisions of image classifiers. A major drawback of these tools is their\nreliance on mutants obtained by occluding parts of the input, leading to\nout-of-distribution images. This raises doubts about the quality of the\nexplanations. Moreover, choosing an appropriate occlusion value often requires\ndomain knowledge. In this paper we introduce a novel forward-pass paradigm\nActivation-Deactivation (AD), which removes the effects of occluded input\nfeatures from the model's decision-making by switching off the parts of the\nmodel that correspond to the occlusions. We introduce ConvAD, a drop-in\nmechanism that can be easily added to any trained Convolutional Neural Network\n(CNN), and which implements the AD paradigm. This leads to more robust\nexplanations without any additional training or fine-tuning. We prove that the\nConvAD mechanism does not change the decision-making process of the network. We\nprovide experimental evaluation across several datasets and model\narchitectures. We compare the quality of AD-explanations with explanations\nachieved using a set of masking values, using the proxies of robustness, size,\nand confidence drop-off. We observe a consistent improvement in robustness of\nAD explanations (up to 62.5%) compared to explanations obtained with\nocclusions, demonstrating that ConvAD extracts more robust explanations without\nthe need for domain knowledge.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u524d\u5411\u4f20\u64ad\u8303\u5f0fActivation-Deactivation (AD)\uff0c\u901a\u8fc7\u5173\u95ed\u6a21\u578b\u4e2d\u4e0e\u906e\u6321\u90e8\u5206\u5bf9\u5e94\u7684\u7ec4\u4ef6\u6765\u6d88\u9664\u906e\u6321\u8f93\u5165\u7279\u5f81\u5bf9\u6a21\u578b\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9ed1\u76d2\u89e3\u91ca\u65b9\u6cd5\u56e0\u906e\u6321\u5bfc\u81f4\u5206\u5e03\u5916\u56fe\u50cf\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u9ed1\u76d2\u89e3\u91ca\u65b9\u6cd5\u4f9d\u8d56\u906e\u6321\u8f93\u5165\u90e8\u5206\u751f\u6210\u7a81\u53d8\u4f53\uff0c\u5bfc\u81f4\u5206\u5e03\u5916\u56fe\u50cf\uff0c\u5f71\u54cd\u89e3\u91ca\u8d28\u91cf\uff0c\u4e14\u9009\u62e9\u5408\u9002\u906e\u6321\u503c\u9700\u8981\u9886\u57df\u77e5\u8bc6\u3002", "method": "\u5f15\u5165ConvAD\u673a\u5236\uff0c\u53ef\u8f7b\u677e\u6dfb\u52a0\u5230\u4efb\u4f55\u8bad\u7ec3\u597d\u7684CNN\u4e2d\uff0c\u5b9e\u73b0AD\u8303\u5f0f\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAD\u89e3\u91ca\u5728\u9c81\u68d2\u6027\u65b9\u9762\u76f8\u6bd4\u906e\u6321\u65b9\u6cd5\u63d0\u5347\u9ad8\u8fbe62.5%\uff0c\u80fd\u63d0\u53d6\u66f4\u9c81\u68d2\u7684\u89e3\u91ca\u4e14\u65e0\u9700\u9886\u57df\u77e5\u8bc6\u3002", "conclusion": "ConvAD\u673a\u5236\u4e0d\u6539\u53d8\u7f51\u7edc\u51b3\u7b56\u8fc7\u7a0b\uff0c\u80fd\u63d0\u4f9b\u66f4\u9c81\u68d2\u7684\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u906e\u6321\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.01069", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01069", "abs": "https://arxiv.org/abs/2510.01069", "authors": ["Elija Perrier"], "title": "Typed Chain-of-Thought: A Curry-Howard Framework for Verifying LLM Reasoning", "comment": "Under review", "summary": "While Chain-of-Thought (CoT) prompting enhances the reasoning capabilities of\nlarge language models, the faithfulness of the generated rationales remains an\nopen problem for model interpretability. We propose a novel theoretical lens\nfor this problem grounded in the Curry-Howard correspondence, which posits a\ndirect relationship between formal proofs and computer programs. Under this\nparadigm, a faithful reasoning trace is analogous to a well-typed program,\nwhere each intermediate step corresponds to a typed logical inference. We\noperationalise this analogy, presenting methods to extract and map the\ninformal, natural language steps of CoT into a formal, typed proof structure.\nSuccessfully converting a CoT trace into a well-typed proof serves as a strong,\nverifiable certificate of its computational faithfulness, moving beyond\nheuristic interpretability towards formal verification. Our framework provides\na methodology to transform plausible narrative explanations into formally\nverifiable programs, offering a path towards building more reliable and\ntrustworthy AI systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCurry-Howard\u5bf9\u5e94\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06CoT\u63a8\u7406\u8fc7\u7a0b\u6620\u5c04\u4e3a\u5f62\u5f0f\u5316\u7c7b\u578b\u8bc1\u660e\uff0c\u4ee5\u9a8c\u8bc1\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u3002", "motivation": "\u89e3\u51b3CoT\u63d0\u793a\u751f\u6210\u63a8\u7406\u8fc7\u7a0b\u7684\u5fe0\u5b9e\u6027\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u5229\u7528Curry-Howard\u5bf9\u5e94\u5173\u7cfb\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6b65\u9aa4\u8f6c\u6362\u4e3a\u5f62\u5f0f\u5316\u7c7b\u578b\u8bc1\u660e\u7ed3\u6784\u3002", "result": "\u6210\u529f\u5c06CoT\u63a8\u7406\u8f68\u8ff9\u8f6c\u6362\u4e3a\u826f\u7c7b\u578b\u8bc1\u660e\uff0c\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u8ba1\u7b97\u5fe0\u5b9e\u6027\u8bc1\u4e66\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4ece\u53d9\u8ff0\u6027\u89e3\u91ca\u5230\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u8def\u5f84\u3002"}}
{"id": "2510.01088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01088", "abs": "https://arxiv.org/abs/2510.01088", "authors": ["Guobin Shen", "Dongcheng Zhao", "Haibo Tong", "Jindong Li", "Feifei Zhao", "Yi Zeng"], "title": "Safety Instincts: LLMs Learn to Trust Their Internal Compass for Self-Defense", "comment": null, "summary": "Ensuring Large Language Model (LLM) safety remains challenging due to the\nabsence of universal standards and reliable content validators, making it\ndifficult to obtain effective training signals. We discover that aligned models\nalready possess robust internal safety beliefs: they consistently produce\nhigh-confidence refusals to harmful requests while exhibiting high entropy when\ngenerating potentially dangerous content. This entropy gap reveals an untapped\nsignal--models intrinsically \"know\" when to refuse. We introduce Safety\nInstincts Reinforcement Learning (SIRL), which transforms this internal\nconfidence into a self-generated reward signal, eliminating dependence on\nexternal validators or human annotations. SIRL teaches models to trust their\nsafety instincts by reinforcing low-entropy refusal behaviors. Evaluated on\nLlama and Qwen models, SIRL maintains 89%+ Defense Success Rates (DSRs) against\n20+ jailbreak methods, from static prompts to adaptive attacks. Using only\n15,000 unlabeled prompts, SIRL surpasses resource-intensive supervised methods\nwhile preserving performance on mathematics, coding, and conversation\nbenchmarks. Our work demonstrates that effective alignment can emerge from\nwithin, paving the way for more autonomous and robust AI safety mechanisms that\nscale without extensive human oversight.", "AI": {"tldr": "SIRL\u65b9\u6cd5\u5229\u7528LLM\u5185\u90e8\u7684\u5b89\u5168\u4fe1\u5ff5\uff0c\u5c06\u62d2\u7edd\u6709\u5bb3\u8bf7\u6c42\u65f6\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u8f6c\u5316\u4e3a\u81ea\u751f\u6210\u5956\u52b1\u4fe1\u53f7\uff0c\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668\u5373\u53ef\u5f3a\u5316\u6a21\u578b\u7684\u5b89\u5168\u672c\u80fd\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u901a\u7528\u5b89\u5168\u6807\u51c6\u548c\u53ef\u9760\u7684\u5185\u5bb9\u9a8c\u8bc1\u5668\uff0c\u786e\u4fddLLM\u5b89\u5168\u6027\u9762\u4e34\u6311\u6218\u3002\u7814\u7a76\u53d1\u73b0\u5bf9\u9f50\u6a21\u578b\u5df2\u5177\u5907\u5185\u90e8\u5b89\u5168\u4fe1\u5ff5\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u4fe1\u5ff5\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSafety Instincts Reinforcement Learning (SIRL)\uff0c\u5c06\u6a21\u578b\u62d2\u7edd\u6709\u5bb3\u8bf7\u6c42\u65f6\u7684\u9ad8\u7f6e\u4fe1\u5ea6\uff08\u4f4e\u71b5\uff09\u8f6c\u5316\u4e3a\u81ea\u751f\u6210\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u4fe1\u4efb\u5176\u5b89\u5168\u672c\u80fd\u3002", "result": "\u5728Llama\u548cQwen\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0cSIRL\u5bf920+\u79cd\u8d8a\u72f1\u65b9\u6cd5\u4fdd\u630189%+\u7684\u9632\u5fa1\u6210\u529f\u7387\uff0c\u4ec5\u4f7f\u752815,000\u4e2a\u65e0\u6807\u7b7e\u63d0\u793a\u5c31\u8d85\u8d8a\u8d44\u6e90\u5bc6\u96c6\u7684\u76d1\u7763\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u5b66\u3001\u7f16\u7a0b\u548c\u5bf9\u8bdd\u57fa\u51c6\u6027\u80fd\u3002", "conclusion": "\u6709\u6548\u5bf9\u9f50\u53ef\u4ee5\u4ece\u6a21\u578b\u5185\u90e8\u4ea7\u751f\uff0c\u4e3a\u65e0\u9700\u5927\u91cf\u4eba\u5de5\u76d1\u7763\u7684\u81ea\u4e3b\u3001\u9c81\u68d2AI\u5b89\u5168\u673a\u5236\u5f00\u8f9f\u4e86\u9053\u8def\u3002"}}
{"id": "2510.01094", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01094", "abs": "https://arxiv.org/abs/2510.01094", "authors": ["Alexander Nasuta", "Alessandro Cisi", "Sylwia Olbrych", "Gustavo Vieira", "Rui Fernandes", "Lucas Paletta", "Marlene Mayr", "Rishyank Chevuri", "Robert Woitsch", "Hans Aoyang Zhou", "Anas Abdelrazeq", "Robert H. Schmitt"], "title": "Optimizing Fairness in Production Planning: A Human-Centric Approach to Machine and Workforce Allocation", "comment": null, "summary": "This work presents a two-layer, human-centric production planning framework\ndesigned to optimize both operational efficiency and workforce fairness in\nindustrial manufacturing. The first layer formulates the Order-Line allocation\nas a Constraint Programming (CP) problem, generating high-utilization\nproduction schedules that respect machine capacities, processing times, and due\ndates. The second layer models Worker-Line allocation as a Markov Decision\nProcess (MDP), integrating human factors such as worker preference, experience,\nresilience, and medical constraints into the assignment process. Three solution\nstrategies, greedy allocation, MCTS, and RL, are implemented and compared\nacross multiple evaluation scenarios. The proposed system is validated through\n16 test sessions with domain experts from the automotive industry, combining\nquantitative key performance indicators (KPIs) with expert ratings. Results\nindicate that the CP-based scheduling approach produces compact, feasible\nproduction plans with low tardiness, while the MDP-based worker allocation\nsignificantly improves fairness and preference alignment compared to baseline\napproaches. Domain experts rated both the Order-Line and Worker-Line components\nas effective and highlighted opportunities to further refine the objective\nfunction to penalize excessive earliness and improve continuity in worker\nassignments. Overall, the findings demonstrate that combining CP with\nlearning-based decision-making provides a robust approach for human-centric\nproduction planning. The approach enables simultaneous optimization of\nthroughput and workforce well-being, offering a practical foundation for fair\nand efficient manufacturing scheduling in industrial settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53cc\u5c42\u4eba\u672c\u751f\u4ea7\u8ba1\u5212\u6846\u67b6\uff0c\u7ed3\u5408\u7ea6\u675f\u89c4\u5212\u4f18\u5316\u751f\u4ea7\u8c03\u5ea6\uff0c\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4f18\u5316\u5de5\u4eba\u5206\u914d\uff0c\u5728\u4fdd\u8bc1\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u5de5\u4eba\u516c\u5e73\u6027\u3002", "motivation": "\u5de5\u4e1a\u5236\u9020\u4e2d\u9700\u8981\u540c\u65f6\u4f18\u5316\u8fd0\u8425\u6548\u7387\u548c\u52b3\u52a8\u529b\u516c\u5e73\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u5de5\u4eba\u504f\u597d\u3001\u7ecf\u9a8c\u3001\u9002\u5e94\u80fd\u529b\u548c\u533b\u7597\u7ea6\u675f\u7b49\u4eba\u672c\u56e0\u7d20\u3002", "method": "\u7b2c\u4e00\u5c42\u4f7f\u7528\u7ea6\u675f\u89c4\u5212(CP)\u89e3\u51b3\u8ba2\u5355-\u4ea7\u7ebf\u5206\u914d\u95ee\u9898\uff1b\u7b2c\u4e8c\u5c42\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(MDP)\u89e3\u51b3\u5de5\u4eba-\u4ea7\u7ebf\u5206\u914d\u95ee\u9898\uff0c\u5e76\u6bd4\u8f83\u8d2a\u5a6a\u5206\u914d\u3001MCTS\u548cRL\u4e09\u79cd\u7b56\u7565\u3002", "result": "CP\u8c03\u5ea6\u4ea7\u751f\u7d27\u51d1\u53ef\u884c\u7684\u751f\u4ea7\u8ba1\u5212\uff0cMDP\u5de5\u4eba\u5206\u914d\u663e\u8457\u63d0\u5347\u516c\u5e73\u6027\u548c\u504f\u597d\u5339\u914d\u5ea6\u3002\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u663e\u793a\u4e24\u4e2a\u7ec4\u4ef6\u90fd\u6709\u6548\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u7ed3\u5408\u7ea6\u675f\u89c4\u5212\u4e0e\u5b66\u4e60\u578b\u51b3\u7b56\u4e3a\u4eba\u672c\u751f\u4ea7\u8ba1\u5212\u63d0\u4f9b\u4e86\u7a33\u5065\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u4f18\u5316\u541e\u5410\u91cf\u548c\u5de5\u4eba\u798f\u7949\uff0c\u4e3a\u516c\u5e73\u9ad8\u6548\u7684\u5236\u9020\u8c03\u5ea6\u5960\u5b9a\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2510.01114", "categories": ["cs.AI", "I.2.1; I.2.4; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.01114", "abs": "https://arxiv.org/abs/2510.01114", "authors": ["Lionel Levine", "John Santerre", "Alexander S. Young", "T. Barry Levine", "Francis Campion", "Majid Sarrafzadeh"], "title": "PRISM-Consult: A Panel-of-Experts Architecture for Clinician-Aligned Diagnosis", "comment": "8 pages, 6 figures", "summary": "We present PRISM-Consult, a clinician-aligned panel-of-experts architecture\nthat extends the compact PRISM sequence model into a routed family of domain\nspecialists. Episodes are tokenized as structured clinical events; a\nlight-weight router reads the first few tokens and dispatches to specialist\nmodels (Cardiac-Vascular, Pulmonary, Gastro-Oesophageal, Musculoskeletal,\nPsychogenic). Each specialist inherits PRISM's small transformer backbone and\ntoken template, enabling parameter efficiency and interpretability. On\nreal-world Emergency Department cohorts, specialists exhibit smooth convergence\nwith low development perplexities across domains, while the router achieves\nhigh routing quality and large compute savings versus consult-all under a\nsafety-first policy. We detail the data methodology (initial vs. conclusive\nICD-9 families), routing thresholds and calibration, and report per-domain\nresults to avoid dominance by common events. The framework provides a practical\npath to safe, auditable, and low-latency consult at scale, and we outline\nvalidation steps-external/temporal replication, asymmetric life-threat\nthresholds, and multi-label arbitration-to meet prospective clinical deployment\nstandards.", "AI": {"tldr": "PRISM-Consult\u662f\u4e00\u4e2a\u4e34\u5e8a\u533b\u751f\u5bf9\u9f50\u7684\u4e13\u5bb6\u5c0f\u7ec4\u67b6\u6784\uff0c\u5c06\u7d27\u51d1\u7684PRISM\u5e8f\u5217\u6a21\u578b\u6269\u5c55\u4e3a\u8def\u7531\u7684\u9886\u57df\u4e13\u5bb6\u5bb6\u65cf\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u5c06\u75c5\u4f8b\u5206\u914d\u5230\u4e0d\u540c\u4e13\u79d1\u6a21\u578b\uff0c\u5b9e\u73b0\u53c2\u6570\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u4e14\u4f4e\u5ef6\u8fdf\u7684\u4e34\u5e8a\u54a8\u8be2\u7cfb\u7edf\uff0c\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u6a21\u578b\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u907f\u514d\u5e38\u89c1\u4e8b\u4ef6\u4e3b\u5bfc\u7ed3\u679c\u3002", "method": "\u4f7f\u7528\u7ed3\u6784\u5316\u4e34\u5e8a\u4e8b\u4ef6\u6807\u8bb0\u5316\uff0c\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u8bfb\u53d6\u524d\u51e0\u4e2a\u6807\u8bb0\u5e76\u5206\u914d\u5230\u4e13\u79d1\u6a21\u578b\uff08\u5fc3\u8840\u7ba1\u3001\u80ba\u3001\u80c3\u80a0\u3001\u808c\u8089\u9aa8\u9abc\u3001\u5fc3\u56e0\u6027\uff09\uff0c\u6bcf\u4e2a\u4e13\u79d1\u7ee7\u627fPRISM\u7684\u5c0f\u578btransformer\u67b6\u6784\u548c\u6807\u8bb0\u6a21\u677f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6025\u8bca\u79d1\u961f\u5217\u4e2d\uff0c\u4e13\u79d1\u6a21\u578b\u5728\u5404\u9886\u57df\u8868\u73b0\u51fa\u5e73\u6ed1\u6536\u655b\u548c\u4f4e\u5f00\u53d1\u56f0\u60d1\u5ea6\uff0c\u8def\u7531\u5668\u5728\u5b89\u5168\u4f18\u5148\u7b56\u7565\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u8def\u7531\u548c\u5927\u91cf\u8ba1\u7b97\u8282\u7701\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u548c\u4f4e\u5ef6\u8fdf\u54a8\u8be2\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u5e76\u6982\u8ff0\u4e86\u5916\u90e8/\u65f6\u95f4\u590d\u5236\u3001\u975e\u5bf9\u79f0\u751f\u547d\u5a01\u80c1\u9608\u503c\u548c\u591a\u6807\u7b7e\u4ef2\u88c1\u7b49\u9a8c\u8bc1\u6b65\u9aa4\u4ee5\u6ee1\u8db3\u4e34\u5e8a\u90e8\u7f72\u6807\u51c6\u3002"}}
{"id": "2510.01141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01141", "abs": "https://arxiv.org/abs/2510.01141", "authors": ["Shruthan Radhakrishna", "Aman Tiwari", "Aanjaneya Shukla", "Masoud Hashemi", "Rishabh Maheshwary", "Shiva Krishna Reddy Malay", "Jash Mehta", "Pulkit Pattnaik", "Saloni Mittal", "Khalil Slimi", "Kelechi Ogueji", "Akintunde Oladipo", "Soham Parikh", "Oluwanifemi Bamgbose", "Toby Liang", "Ahmed Masry", "Khyati Mahajan", "Sai Rajeswar Mudumba", "Vikas Yadav", "Sathwik Tejaswi Madhusudhan", "Torsten Scholak", "Sagar Davasam", "Srinivas Sunkara", "Nicholas Chapados"], "title": "Apriel-1.5-15b-Thinker", "comment": null, "summary": "We present Apriel-1.5-15B-Thinker, a 15-billion parameter open-weights\nmultimodal reasoning model that achieves frontier-level performance through\ntraining design rather than sheer scale. Starting from Pixtral-12B, we apply a\nprogressive three-stage methodology: (1) depth upscaling to expand reasoning\ncapacity without pretraining from scratch, (2) staged continual pre-training\nthat first develops foundational text and vision understanding, then enhances\nvisual reasoning through targeted synthetic data generation addressing spatial\nstructure, compositional understanding, and fine-grained perception, and (3)\nhigh-quality text-only supervised fine-tuning on curated instruction-response\npairs with explicit reasoning traces spanning mathematics, coding, science, and\ntool use. Notably, our model achieves competitive results without reinforcement\nlearning or preference optimization, isolating the contribution of our\ndata-centric continual pre-training approach. On the Artificial Analysis\nIntelligence Index, Apriel-1.5-15B-Thinker attains a score of 52, matching\nDeepSeek-R1-0528 despite requiring significantly fewer computational resources.\nAcross ten image benchmarks, its performance is on average within five points\nof Gemini-2.5-Flash and Claude Sonnet-3.7, a key achievement for a model\noperating within single-GPU deployment constraints. Our results demonstrate\nthat thoughtful mid-training 2 design can close substantial capability gaps\nwithout massive scale, making frontier-level multimodal reasoning accessible to\norganizations with limited infrastructure. We release the model checkpoint, all\ntraining recipes, and evaluation protocols under the MIT license to to advance\nopen-source research.", "AI": {"tldr": "Apriel-1.5-15B-Thinker\u662f\u4e00\u4e2a150\u4ebf\u53c2\u6570\u7684\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u4e09\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\u5b9e\u73b0\u524d\u6cbf\u6027\u80fd\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u8ba1\u7b97\u8d44\u6e90\uff0c\u5728\u5355GPU\u90e8\u7f72\u9650\u5236\u4e0b\u8fbe\u5230\u4e0e\u66f4\u5927\u6a21\u578b\u7ade\u4e89\u7684\u7ed3\u679c\u3002", "motivation": "\u65e8\u5728\u8bc1\u660e\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bad\u7ec3\u65b9\u6cd5\u800c\u975e\u5355\u7eaf\u6269\u5927\u89c4\u6a21\uff0c\u53ef\u4ee5\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u524d\u6cbf\u6c34\u5e73\u7684\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u66f4\u591a\u7ec4\u7ec7\u80fd\u591f\u83b7\u5f97\u9ad8\u6027\u80fd\u6a21\u578b\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6e10\u8fdb\u65b9\u6cd5\uff1a1\uff09\u6df1\u5ea6\u6269\u5c55\u63a8\u7406\u80fd\u529b\uff1b2\uff09\u5206\u9636\u6bb5\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u5305\u62ec\u57fa\u7840\u6587\u672c\u89c6\u89c9\u7406\u89e3\u548c\u901a\u8fc7\u5408\u6210\u6570\u636e\u589e\u5f3a\u89c6\u89c9\u63a8\u7406\uff1b3\uff09\u9ad8\u8d28\u91cf\u6587\u672c\u76d1\u7763\u5fae\u8c03\uff0c\u6db5\u76d6\u6570\u5b66\u3001\u7f16\u7a0b\u3001\u79d1\u5b66\u548c\u5de5\u5177\u4f7f\u7528\u3002", "result": "\u5728Artificial Analysis Intelligence Index\u4e0a\u83b7\u5f9752\u5206\uff0c\u4e0eDeepSeek-R1-0528\u76f8\u5f53\uff1b\u5728\u5341\u4e2a\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6027\u80fd\u4ec5\u6bd4Gemini-2.5-Flash\u548cClaude Sonnet-3.7\u4f4e5\u5206\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e2d\u95f4\u8bad\u7ec3\u65b9\u6cd5\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u5927\u89c4\u6a21\u8ba1\u7b97\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u7f29\u5c0f\u80fd\u529b\u5dee\u8ddd\uff0c\u4f7f\u524d\u6cbf\u591a\u6a21\u6001\u63a8\u7406\u5bf9\u57fa\u7840\u8bbe\u65bd\u6709\u9650\u7684\u7ec4\u7ec7\u66f4\u52a0\u53ef\u53ca\u3002"}}
{"id": "2510.01143", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01143", "abs": "https://arxiv.org/abs/2510.01143", "authors": ["Harry Dong", "David Brandfonbrener", "Eryk Helenowski", "Yun He", "Mrinal Kumar", "Han Fang", "Yuejie Chi", "Karthik Abinav Sankararaman"], "title": "Generalized Parallel Scaling with Interdependent Generations", "comment": null, "summary": "Parallel LLM inference scaling involves sampling a set of $N>1$ responses for\na single input prompt. However, these $N$ parallel responses tend to be\ngenerated independently from each other, partitioning compute resources and\nleaving potentially useful information in one generation untapped by others.\nThis is in contrast to response length scaling where past computation is used\nin all future steps. For higher quality responses and response sets, we propose\nBridge to generate interdependent responses in parallel by rethinking batched\nLLM hidden states as holistic tensors rather than independent slices. With only\na small amount (2.8%-5.1%) of new parameters, Bridge improves the relative mean\naccuracy gains from reinforcement learning with verifiable rewards by up to 50%\nand boosts consistency of correct responses. Trained once, Bridge scales to any\ngeneration width, all with greater performance than independent generations,\nunlocking a more general mode of parallel scaling that effectively leverages\ninformation between sequences, compatible with any post-generation aggregation\ntechnique.", "AI": {"tldr": "Bridge\u662f\u4e00\u4e2a\u5e76\u884cLLM\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba9\u591a\u4e2a\u54cd\u5e94\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u76f8\u4e92\u4f9d\u8d56\uff0c\u800c\u4e0d\u662f\u72ec\u7acb\u751f\u6210\uff0c\u4ece\u800c\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5e76\u884cLLM\u63a8\u7406\u4e2d\uff0c\u591a\u4e2a\u54cd\u5e94\u72ec\u7acb\u751f\u6210\uff0c\u6d6a\u8d39\u4e86\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e14\u65e0\u6cd5\u5229\u7528\u4e00\u4e2a\u751f\u6210\u4e2d\u7684\u6709\u7528\u4fe1\u606f\u6765\u5e2e\u52a9\u5176\u4ed6\u751f\u6210\u3002", "method": "\u5c06\u6279\u5904\u7406\u7684LLM\u9690\u85cf\u72b6\u6001\u91cd\u65b0\u6784\u60f3\u4e3a\u6574\u4f53\u5f20\u91cf\u800c\u975e\u72ec\u7acb\u5207\u7247\uff0c\u4ec5\u6dfb\u52a0\u5c11\u91cf\u65b0\u53c2\u6570\uff082.8%-5.1%\uff09\uff0c\u4f7f\u54cd\u5e94\u5728\u5e76\u884c\u751f\u6210\u8fc7\u7a0b\u4e2d\u76f8\u4e92\u4f9d\u8d56\u3002", "result": "Bridge\u5c06\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u7684\u76f8\u5bf9\u5e73\u5747\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe50%\uff0c\u5e76\u63d0\u9ad8\u4e86\u6b63\u786e\u54cd\u5e94\u7684\u4e00\u81f4\u6027\u3002\u4e00\u6b21\u8bad\u7ec3\u5373\u53ef\u6269\u5c55\u5230\u4efb\u4f55\u751f\u6210\u5bbd\u5ea6\uff0c\u6027\u80fd\u4f18\u4e8e\u72ec\u7acb\u751f\u6210\u3002", "conclusion": "Bridge\u89e3\u9501\u4e86\u4e00\u79cd\u66f4\u901a\u7528\u7684\u5e76\u884c\u6269\u5c55\u6a21\u5f0f\uff0c\u6709\u6548\u5229\u7528\u5e8f\u5217\u95f4\u7684\u4fe1\u606f\uff0c\u517c\u5bb9\u4efb\u4f55\u540e\u751f\u6210\u805a\u5408\u6280\u672f\u3002"}}
