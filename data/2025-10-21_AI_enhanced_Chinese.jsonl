{"id": "2510.16003", "categories": ["econ.TH", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.16003", "abs": "https://arxiv.org/abs/2510.16003", "authors": ["Nizar Riane"], "title": "Rethinking Arrow--Debreu: A New Framework for Exchange, Time, and Uncertainty", "comment": null, "summary": "This paper revisits the Arrow-Debreu general equilibrium framework through\nthe lens of effective trade, emphasizing the distinction between theoretical\nand realizable market interactions. We develop the Effective Trade Model (ETM),\nwhere transactions arise from bilateral feasibility rather than aggregate\nsupply and demand desires. Within this framework, we establish the main\nproperties of the price-demand correspondence and prove the existence of Nash\nequilibria, incorporating production, money, and network topology. The analysis\nextends to time, uncertainty, and open economies, revealing how loanable funds\nand exchange rates emerge endogenously. Our results show that equilibrium is\nshaped by transaction constraints, subjective pricing, and decentralized\nnegotiation, rather than by universal market-clearing conditions, and thereby\ncall into question the foundations of welfare theory. Anticipation is modeled\nvia the conditional mode, capturing bounded rationality and information\nlimitations in contrast to the rational expectations hypothesis. The ETM thus\noffers a behaviorally and structurally grounded alternative to classical\ngeneral equilibrium, bridging microfoundations, monetary dynamics, and temporal\nconsistency within a unified framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6709\u6548\u8d38\u6613\u6a21\u578b(ETM)\uff0c\u91cd\u65b0\u5ba1\u89c6Arrow-Debreu\u4e00\u822c\u5747\u8861\u6846\u67b6\uff0c\u5f3a\u8c03\u7406\u8bba\u5e02\u573a\u4e0e\u53ef\u5b9e\u73b0\u5e02\u573a\u4e92\u52a8\u7684\u533a\u522b\uff0c\u8bc1\u660e\u7eb3\u4ec0\u5747\u8861\u5b58\u5728\u6027\uff0c\u5e76\u8d28\u7591\u798f\u5229\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u4f20\u7edf\u4e00\u822c\u5747\u8861\u7406\u8bba\uff0c\u5f3a\u8c03\u7406\u8bba\u5e02\u573a\u4e92\u52a8\u4e0e\u5b9e\u9645\u53ef\u5b9e\u73b0\u4ea4\u6613\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u8d28\u7591\u666e\u904d\u5e02\u573a\u51fa\u6e05\u6761\u4ef6\u548c\u798f\u5229\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5f00\u53d1\u6709\u6548\u8d38\u6613\u6a21\u578b(ETM)\uff0c\u57fa\u4e8e\u53cc\u8fb9\u53ef\u884c\u6027\u800c\u975e\u603b\u4f9b\u9700\u7684\u4ea4\u6613\u673a\u5236\uff0c\u7eb3\u5165\u751f\u4ea7\u3001\u8d27\u5e01\u548c\u7f51\u7edc\u62d3\u6251\uff0c\u4f7f\u7528\u6761\u4ef6\u6a21\u6001\u5efa\u6a21\u9884\u671f\u3002", "result": "\u8bc1\u660e\u4e86\u4ef7\u683c-\u9700\u6c42\u5bf9\u5e94\u7684\u4e3b\u8981\u6027\u8d28\u548c\u7eb3\u4ec0\u5747\u8861\u5b58\u5728\u6027\uff0c\u5c55\u793a\u4e86\u53ef\u8d37\u8d44\u91d1\u548c\u6c47\u7387\u7684\u5185\u751f\u5f62\u6210\uff0c\u5747\u8861\u7531\u4ea4\u6613\u7ea6\u675f\u3001\u4e3b\u89c2\u5b9a\u4ef7\u548c\u5206\u6563\u8c08\u5224\u51b3\u5b9a\u3002", "conclusion": "ETM\u4e3a\u7ecf\u5178\u4e00\u822c\u5747\u8861\u63d0\u4f9b\u4e86\u884c\u4e3a\u548c\u7ed3\u6784\u57fa\u7840\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u4e2d\u8fde\u63a5\u5fae\u89c2\u57fa\u7840\u3001\u8d27\u5e01\u52a8\u6001\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.16608", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.16608", "abs": "https://arxiv.org/abs/2510.16608", "authors": ["Kailin Chen"], "title": "Collective Experimentation with Correlated Payoffs", "comment": null, "summary": "This paper studies an exponential bandit model in which a group of agents\ncollectively decide whether to undertake a risky action $R$. This action is\nimplemented if the fraction of agents voting for it exceeds a predetermined\nthreshold $k$. Building on Strulovici (2008), which assumes the agents' payoffs\nare independent, we explore the case in which the agents' payoffs are\ncorrelated. During experimentation, each agent learns individually whether she\nbenefits from $R$; in this way, she also gains information about its overall\ndesirability. Furthermore, each agent is able to learn indirectly from the\nothers, because in making her decisions, she conditions on being pivotal (i.e.,\nshe assumes her vote will determine the collective outcome). We show that, when\nthe number of agents is large, increasing the threshold $k$ for implementing\n$R$ leads to increased experimentation. However, information regarding the\noverall desirability of $R$ is effectively aggregated only if $k$ is\nsufficiently low.", "AI": {"tldr": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u5728\u76f8\u5173\u6536\u76ca\u4e0b\u7684\u6307\u6570\u8d4c\u535a\u673a\u6a21\u578b\uff0c\u5206\u6790\u6295\u7968\u9608\u503c\u5bf9\u96c6\u4f53\u5b9e\u9a8c\u548c\u4fe1\u606f\u805a\u5408\u7684\u5f71\u54cd", "motivation": "\u6269\u5c55Strulovici(2008)\u7684\u72ec\u7acb\u6536\u76ca\u5047\u8bbe\uff0c\u7814\u7a76\u5f53\u667a\u80fd\u4f53\u6536\u76ca\u76f8\u5173\u65f6\uff0c\u96c6\u4f53\u51b3\u7b56\u4e2d\u7684\u5b9e\u9a8c\u884c\u4e3a\u548c\u4fe1\u606f\u805a\u5408\u95ee\u9898", "method": "\u6784\u5efa\u6307\u6570\u8d4c\u535a\u673a\u6a21\u578b\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u4e2a\u4eba\u5b9e\u9a8c\u5b66\u4e60\u81ea\u8eab\u6536\u76ca\uff0c\u5e76\u901a\u8fc7\u8003\u8651\u6295\u7968\u5173\u952e\u6027\u95f4\u63a5\u5b66\u4e60\u4ed6\u4eba\u4fe1\u606f\uff0c\u5206\u6790\u4e0d\u540c\u6295\u7968\u9608\u503c\u4e0b\u7684\u96c6\u4f53\u884c\u4e3a", "result": "\u5f53\u667a\u80fd\u4f53\u6570\u91cf\u5927\u65f6\uff0c\u63d0\u9ad8\u5b9e\u65bd\u98ce\u9669\u884c\u52a8\u7684\u6295\u7968\u9608\u503ck\u4f1a\u589e\u52a0\u5b9e\u9a8c\uff0c\u4f46\u53ea\u6709\u5728k\u8db3\u591f\u4f4e\u65f6\u624d\u80fd\u6709\u6548\u805a\u5408\u5173\u4e8eR\u6574\u4f53\u5408\u610f\u6027\u7684\u4fe1\u606f", "conclusion": "\u6295\u7968\u9608\u503c\u5728\u96c6\u4f53\u51b3\u7b56\u4e2d\u5177\u6709\u53cc\u91cd\u4f5c\u7528\uff1a\u9ad8\u9608\u503c\u4fc3\u8fdb\u5b9e\u9a8c\u4f46\u963b\u788d\u4fe1\u606f\u805a\u5408\uff0c\u4f4e\u9608\u503c\u6709\u5229\u4e8e\u4fe1\u606f\u805a\u5408\u4f46\u53ef\u80fd\u9650\u5236\u5b9e\u9a8c"}}
{"id": "2510.16972", "categories": ["econ.TH", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16972", "abs": "https://arxiv.org/abs/2510.16972", "authors": ["Andreas Haupt"], "title": "Preference Measurement Error, Concentration in Recommendation Systems, and Persuasion", "comment": "12 pages, 3 figures", "summary": "Algorithmic recommendation based on noisy preference measurement is prevalent\nin recommendation systems. This paper discusses the consequences of such\nrecommendation on market concentration and inequality. Binary types denoting a\nstatistical majority and minority are noisily revealed through a statistical\nexperiment. The achievable utilities and recommendation shares for the two\ngroups can be analyzed as a Bayesian Persuasion problem. While under arbitrary\nnoise structures, effects on concentration compared to a full-information\nmarket are ambiguous, under symmetric noise, concentration increases and\nconsumer welfare becomes more unequal. We define symmetric statistical\nexperiments and analyze persuasion under a restriction to such experiments,\nwhich may be of independent interest.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u566a\u58f0\u504f\u597d\u6d4b\u91cf\u7684\u7b97\u6cd5\u63a8\u8350\u5bf9\u5e02\u573a\u96c6\u4e2d\u5ea6\u548c\u4e0d\u5e73\u7b49\u7684\u5f71\u54cd\u3002\u5728\u5bf9\u79f0\u566a\u58f0\u6761\u4ef6\u4e0b\uff0c\u63a8\u8350\u7cfb\u7edf\u4f1a\u589e\u52a0\u5e02\u573a\u96c6\u4e2d\u5ea6\u5e76\u52a0\u5267\u6d88\u8d39\u8005\u798f\u5229\u4e0d\u5e73\u7b49\u3002", "motivation": "\u7814\u7a76\u63a8\u8350\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u566a\u58f0\u504f\u597d\u6d4b\u91cf\u7684\u7b97\u6cd5\u63a8\u8350\u5982\u4f55\u5f71\u54cd\u5e02\u573a\u96c6\u4e2d\u5ea6\u548c\u4e0d\u5e73\u7b49\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u7edf\u8ba1\u591a\u6570\u7fa4\u4f53\u548c\u5c11\u6570\u7fa4\u4f53\u4e4b\u95f4\u7684\u6548\u7528\u5206\u914d\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u8d1d\u53f6\u65af\u8bf4\u670d\u95ee\u9898\uff0c\u5206\u6790\u4e8c\u5143\u7c7b\u578b\uff08\u591a\u6570\u7fa4\u4f53\u548c\u5c11\u6570\u7fa4\u4f53\uff09\u5728\u7edf\u8ba1\u5b9e\u9a8c\u4e2d\u7684\u566a\u58f0\u63ed\u793a\u8fc7\u7a0b\uff0c\u7279\u522b\u5173\u6ce8\u5bf9\u79f0\u7edf\u8ba1\u5b9e\u9a8c\u6761\u4ef6\u4e0b\u7684\u8bf4\u670d\u673a\u5236\u3002", "result": "\u5728\u4efb\u610f\u566a\u58f0\u7ed3\u6784\u4e0b\uff0c\u4e0e\u5b8c\u5168\u4fe1\u606f\u5e02\u573a\u76f8\u6bd4\uff0c\u5bf9\u96c6\u4e2d\u5ea6\u7684\u5f71\u54cd\u662f\u6a21\u7cca\u7684\uff1b\u4f46\u5728\u5bf9\u79f0\u566a\u58f0\u6761\u4ef6\u4e0b\uff0c\u5e02\u573a\u96c6\u4e2d\u5ea6\u589e\u52a0\uff0c\u6d88\u8d39\u8005\u798f\u5229\u53d8\u5f97\u66f4\u52a0\u4e0d\u5e73\u7b49\u3002", "conclusion": "\u57fa\u4e8e\u566a\u58f0\u504f\u597d\u6d4b\u91cf\u7684\u63a8\u8350\u7cfb\u7edf\u5728\u5bf9\u79f0\u566a\u58f0\u6761\u4ef6\u4e0b\u4f1a\u52a0\u5267\u5e02\u573a\u96c6\u4e2d\u5ea6\u548c\u798f\u5229\u4e0d\u5e73\u7b49\uff0c\u5bf9\u79f0\u7edf\u8ba1\u5b9e\u9a8c\u4e0b\u7684\u8bf4\u670d\u5206\u6790\u5177\u6709\u72ec\u7acb\u7684\u7814\u7a76\u4ef7\u503c\u3002"}}
{"id": "2510.16994", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.16994", "abs": "https://arxiv.org/abs/2510.16994", "authors": ["Francis Bloch", "Bhaskar Dutta", "Marcin Dziubi\u0144ski"], "title": "Strategic hiding and exploration in networks", "comment": null, "summary": "We propose and study a model of strategic network design and exploration\nwhere the hider, subject to a budget constraint restricting the number of\nlinks, chooses a connected network and the location of an object. Meanwhile,\nthe seeker, not observing the network and the location of the object, chooses a\nnetwork exploration strategy starting at a fixed node in the network. The\nnetwork exploration follows the expanding search paradigm of Alpern and\nLidbetter (2013). We obtain a Nash equilibrium and characterize equilibrium\npayoffs in the case of linking budget allowing for trees only. We also give an\nupper bound on the expected number of steps needed to find the hider for the\ncase where the linking budget allows for at most one cycle in the network.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u6218\u7565\u7f51\u7edc\u8bbe\u8ba1\u548c\u63a2\u7d22\u6a21\u578b\uff0c\u5176\u4e2d\u9690\u85cf\u8005\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u9009\u62e9\u8fde\u63a5\u7f51\u7edc\u548c\u5bf9\u8c61\u4f4d\u7f6e\uff0c\u800c\u641c\u7d22\u8005\u5728\u4e0d\u89c2\u5bdf\u7f51\u7edc\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u7f51\u7edc\u63a2\u7d22\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u7f51\u7edc\u8bbe\u8ba1\u548c\u63a2\u7d22\u7b56\u7565\uff0c\u5206\u6790\u9690\u85cf\u8005\u548c\u641c\u7d22\u8005\u4e4b\u95f4\u7684\u6218\u7565\u4e92\u52a8\uff0c\u7279\u522b\u662f\u5728\u7f51\u7edc\u8fde\u63a5\u6027\u9650\u5236\u4e0b\u7684\u5747\u8861\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u7eb3\u4ec0\u5747\u8861\u5206\u6790\u65b9\u6cd5\uff0c\u57fa\u4e8eAlpern\u548cLidbetter(2013)\u7684\u6269\u5c55\u641c\u7d22\u8303\u5f0f\uff0c\u7814\u7a76\u6811\u72b6\u7f51\u7edc\u548c\u6700\u591a\u4e00\u4e2a\u73af\u8def\u7684\u7f51\u7edc\u7ed3\u6784\u3002", "result": "\u83b7\u5f97\u4e86\u5728\u6811\u72b6\u7f51\u7edc\u60c5\u51b5\u4e0b\u7684\u7eb3\u4ec0\u5747\u8861\uff0c\u5e76\u63cf\u8ff0\u4e86\u5747\u8861\u6536\u76ca\u3002\u5bf9\u4e8e\u6700\u591a\u4e00\u4e2a\u73af\u8def\u7684\u7f51\u7edc\uff0c\u7ed9\u51fa\u4e86\u627e\u5230\u9690\u85cf\u8005\u6240\u9700\u671f\u671b\u6b65\u6570\u7684\u4e0a\u754c\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u6218\u7565\u7f51\u7edc\u8bbe\u8ba1\u548c\u63a2\u7d22\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5728\u4e0d\u540c\u7f51\u7edc\u7ed3\u6784\u7ea6\u675f\u4e0b\u9690\u85cf\u8005\u548c\u641c\u7d22\u8005\u7684\u6700\u4f18\u7b56\u7565\u3002"}}
{"id": "2510.17757", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.17757", "abs": "https://arxiv.org/abs/2510.17757", "authors": ["C\u00e9sar Barilla"], "title": "When and what to learn in a changing world", "comment": null, "summary": "A decision-maker periodically acquires information about a changing state,\ncontrolling both the timing and content of updates. I characterize optimal\npolicies using a decomposition of the dynamic problem into optimal stopping and\nstatic information acquisition. Eventually, information acquisition either\nstops or follows a simple cycle in which updates occur at regular intervals to\nrestore prescribed levels of relative certainty. This enables precise analysis\nof long run dynamics across environments. As fixed costs of information vanish,\nbelief changes become lumpy: it is optimal to either wait or acquire\ninformation so as to exactly confirm the current belief until rare news prompts\na sudden change. The long run solution admits a closed-form characterization in\nterms of the \"virtual flow payoff\". I highlight an illustrative application to\nportfolio diversification.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u51b3\u7b56\u8005\u5728\u52a8\u6001\u73af\u5883\u4e2d\u63a7\u5236\u4fe1\u606f\u83b7\u53d6\u65f6\u673a\u548c\u5185\u5bb9\u7684\u6700\u4f18\u7b56\u7565\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u6700\u4f18\u505c\u6b62\u548c\u9759\u6001\u4fe1\u606f\u83b7\u53d6\uff0c\u5e76\u53d1\u73b0\u957f\u671f\u52a8\u6001\u4e0b\u4fe1\u606f\u83b7\u53d6\u8981\u4e48\u505c\u6b62\uff0c\u8981\u4e48\u9075\u5faa\u7b80\u5355\u5faa\u73af\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76\u51b3\u7b56\u8005\u5982\u4f55\u6700\u4f18\u5730\u63a7\u5236\u4fe1\u606f\u83b7\u53d6\u7684\u65f6\u673a\u548c\u5185\u5bb9\uff0c\u4ee5\u5e94\u5bf9\u53d8\u5316\u7684\u72b6\u6001\uff0c\u8fd9\u5728\u7ecf\u6d4e\u5b66\u548c\u51b3\u7b56\u7406\u8bba\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5c06\u52a8\u6001\u95ee\u9898\u5206\u89e3\u4e3a\u6700\u4f18\u505c\u6b62\u548c\u9759\u6001\u4fe1\u606f\u83b7\u53d6\uff0c\u5206\u6790\u957f\u671f\u52a8\u6001\u884c\u4e3a\uff0c\u7279\u522b\u5173\u6ce8\u56fa\u5b9a\u4fe1\u606f\u6210\u672c\u8d8b\u8fd1\u4e8e\u96f6\u65f6\u7684\u6781\u9650\u60c5\u51b5\u3002", "result": "\u53d1\u73b0\u4fe1\u606f\u83b7\u53d6\u8981\u4e48\u505c\u6b62\uff0c\u8981\u4e48\u9075\u5faa\u7b80\u5355\u5faa\u73af\u6a21\u5f0f\uff1b\u5f53\u56fa\u5b9a\u6210\u672c\u8d8b\u8fd1\u4e8e\u96f6\u65f6\uff0c\u4fe1\u5ff5\u53d8\u5316\u5448\u73b0\u8df3\u8dc3\u6027\u7279\u5f81\uff1b\u957f\u671f\u89e3\u53ef\u4ee5\u7528\"\u865a\u62df\u6d41\u6536\u76ca\"\u7684\u95ed\u5f0f\u8868\u8fbe\u63cf\u8ff0\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4fe1\u606f\u83b7\u53d6\u52a8\u6001\u7684\u7cbe\u786e\u5206\u6790\u6846\u67b6\uff0c\u5e76\u5728\u6295\u8d44\u7ec4\u5408\u591a\u6837\u5316\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.15941", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15941", "abs": "https://arxiv.org/abs/2510.15941", "authors": ["St\u00e9phane Cr\u00e9pey", "Samuel Drapeau", "Mekonnen Tadese"], "title": "Comparison of Tax and Cap-and-Trade Carbon Pricing Schemes", "comment": null, "summary": "Carbon pricing has become a central pillar of modern climate policy, with\ncarbon taxes and emissions trading systems (ETS) serving as the two dominant\napproaches. Although economic theory suggests these instruments are equivalent\nunder idealized assumptions, their performance diverges in practice due to\nreal-world market imperfections. A particularly less explored dimension of this\ndivergence concerns the role of financial intermediaries in emissions trading\nmarkets. This paper develops a unified framework to compare the economic and\nenvironmental performance of tax- and market-based schemes, explicitly\nincorporating the involvement of financial intermediaries. By calibrating both\ninstruments to deliver identical aggregate emission reduction targets, we\nassess their economic performance across alternative market structures. Our\nresults suggest that although the two schemes are equivalent under perfect\ncompetition, the presence of intermediaries in ETS reduces both regulatory\nwealth and the aggregate wealth of economic agents relative to carbon taxation.\nThese effects stem from intermediaries' influence on price formation and their\nappropriation of part of the revenue stream. The findings underscore the\nimportance of accounting for intermediaries' behavior in the design of carbon\nmarkets and highlight the need for further empirical research on the evolving\ninstitutional structure of emissions trading systems.", "AI": {"tldr": "\u78b3\u5b9a\u4ef7\u653f\u7b56\u4e2d\u78b3\u7a0e\u4e0e\u6392\u653e\u4ea4\u6613\u7cfb\u7edf\u5728\u7406\u8bba\u4e0a\u7b49\u6548\uff0c\u4f46\u5b9e\u8df5\u4e2d\u56e0\u91d1\u878d\u4e2d\u4ecb\u53c2\u4e0e\u800c\u4ea7\u751f\u5dee\u5f02\u3002\u7814\u7a76\u53d1\u73b0\u4e2d\u4ecb\u673a\u6784\u4f1a\u964d\u4f4eETS\u7684\u7ecf\u6d4e\u6548\u76ca\u548c\u76d1\u7ba1\u8d22\u5bcc\u3002", "motivation": "\u63a2\u7d22\u78b3\u7a0e\u4e0e\u6392\u653e\u4ea4\u6613\u7cfb\u7edf\u5728\u5b9e\u9645\u5e02\u573a\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u7279\u522b\u662f\u91d1\u878d\u4e2d\u4ecb\u5728\u6392\u653e\u4ea4\u6613\u5e02\u573a\u4e2d\u7684\u4f5c\u7528\uff0c\u8fd9\u662f\u4e4b\u524d\u8f83\u5c11\u7814\u7a76\u7684\u7ef4\u5ea6\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u6bd4\u8f83\u78b3\u7a0e\u548c\u5e02\u573a\u673a\u5236\u7684\u7ecf\u6d4e\u73af\u5883\u7ee9\u6548\uff0c\u660e\u786e\u7eb3\u5165\u91d1\u878d\u4e2d\u4ecb\u53c2\u4e0e\uff0c\u901a\u8fc7\u6821\u51c6\u4e24\u79cd\u5de5\u5177\u5b9e\u73b0\u76f8\u540c\u7684\u603b\u51cf\u6392\u76ee\u6807\uff0c\u8bc4\u4f30\u4e0d\u540c\u5e02\u573a\u7ed3\u6784\u4e0b\u7684\u7ecf\u6d4e\u8868\u73b0\u3002", "result": "\u4e24\u79cd\u65b9\u6848\u5728\u5b8c\u5168\u7ade\u4e89\u4e0b\u7b49\u6548\uff0c\u4f46ETS\u4e2d\u5b58\u5728\u4e2d\u4ecb\u673a\u6784\u4f1a\u964d\u4f4e\u76d1\u7ba1\u8d22\u5bcc\u548c\u7ecf\u6d4e\u4e3b\u4f53\u603b\u8d22\u5bcc\uff0c\u8fd9\u6e90\u4e8e\u4e2d\u4ecb\u5bf9\u4ef7\u683c\u5f62\u6210\u7684\u5f71\u54cd\u548c\u90e8\u5206\u6536\u5165\u6d41\u7684\u5360\u7528\u3002", "conclusion": "\u78b3\u5e02\u573a\u8bbe\u8ba1\u4e2d\u5fc5\u987b\u8003\u8651\u4e2d\u4ecb\u673a\u6784\u884c\u4e3a\uff0c\u9700\u8981\u5bf9\u6392\u653e\u4ea4\u6613\u7cfb\u7edf\u4e0d\u65ad\u6f14\u53d8\u7684\u5236\u5ea6\u7ed3\u6784\u8fdb\u884c\u66f4\u591a\u5b9e\u8bc1\u7814\u7a76\u3002"}}
{"id": "2510.15935", "categories": ["cs.ET", "cs.IT", "math.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.15935", "abs": "https://arxiv.org/abs/2510.15935", "authors": ["Nikos A Mitsiou", "Ioannis Krikidis", "George K Karagiannidis"], "title": "Quantum Approximate Optimization Algorithm for MIMO with Quantized b-bit Beamforming", "comment": null, "summary": "Multiple-input multiple-output (MIMO) is critical for 6G communication,\noffering improved spectral efficiency and reliability. However, conventional\nfully digital designs face significant challenges due to high hardware\ncomplexity and power consumption. Low-bit MIMO architectures, such as those\nemploying b-bit quantized phase shifters, provide a cost-effective alternative\nbut introduce NP-hard combinatorial problems in the pre- and post-coding\ndesign. This paper explores the use of the Quantum Approximate Optimization\nAlgorithm (QAOA) and alternating optimization to address the problem of b-bit\nquantized phase shifters both at the transmitter and the receiver. We\ndemonstrate that the structure of this quantized beamforming problem aligns\nnaturally with hybrid-classical methods like QAOA, as the phase shifts used in\nbeamforming can be directly mapped to rotation gates in a quantum circuit.\nNotably, this paper is the first to show that theoretical connection. Then, the\nHamiltonian derivation analysis for the b-bit case is presented, which could\nhave applications in different fields, such as integrated sensing and\ncommunication, and emerging quantum algorithms such as quantum machine\nlearning. In addition, a warm-start QAOA approach is studied which improves\ncomputational efficiency. Numerical results highlight the effectiveness of the\nproposed methods in achieving an improved quantized beamforming gain over their\nclassical optimization benchmarks from the literature.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4f7f\u7528\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5(QAOA)\u548c\u4ea4\u66ff\u4f18\u5316\u6765\u89e3\u51b36G MIMO\u7cfb\u7edf\u4e2db\u4f4d\u91cf\u5316\u79fb\u76f8\u5668\u7684\u6ce2\u675f\u6210\u5f62\u95ee\u9898\uff0c\u9996\u6b21\u5efa\u7acb\u4e86\u91cf\u5316\u6ce2\u675f\u6210\u5f62\u4e0e\u91cf\u5b50\u7535\u8def\u65cb\u8f6c\u95e8\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\u3002", "motivation": "6G\u901a\u4fe1\u4e2d\u7684MIMO\u7cfb\u7edf\u9762\u4e34\u786c\u4ef6\u590d\u6742\u5ea6\u548c\u529f\u8017\u6311\u6218\uff0c\u4f4e\u6bd4\u7279\u91cf\u5316\u67b6\u6784\u867d\u7136\u6210\u672c\u6548\u76ca\u9ad8\uff0c\u4f46\u5f15\u5165\u4e86NP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5(QAOA)\u548c\u4ea4\u66ff\u4f18\u5316\u65b9\u6cd5\uff0c\u5c06\u91cf\u5316\u79fb\u76f8\u5668\u7684\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u6620\u5c04\u5230\u91cf\u5b50\u7535\u8def\u7684\u65cb\u8f6c\u95e8\uff0c\u5e76\u63d0\u51fa\u4e86\u9884\u70ed\u542f\u52a8QAOA\u65b9\u6cd5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u5728\u91cf\u5316\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u65b9\u9762\u4f18\u4e8e\u6587\u732e\u4e2d\u7684\u7ecf\u5178\u4f18\u5316\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u91cf\u5b50\u4f18\u5316\u65b9\u6cd5\u4e3a6G MIMO\u7cfb\u7edf\u4e2d\u7684\u91cf\u5316\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5efa\u7acb\u7684\u91cf\u5b50\u7535\u8def\u6620\u5c04\u7406\u8bba\u8054\u7cfb\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.16368", "categories": ["cs.AI", "cs.HC", "cs.LG", "econ.TH"], "pdf": "https://arxiv.org/pdf/2510.16368", "abs": "https://arxiv.org/abs/2510.16368", "authors": ["Ali Shirali"], "title": "The Burden of Interactive Alignment with Inconsistent Preferences", "comment": "Published as a conference paper at NeurIPS 2025", "summary": "From media platforms to chatbots, algorithms shape how people interact,\nlearn, and discover information. Such interactions between users and an\nalgorithm often unfold over multiple steps, during which strategic users can\nguide the algorithm to better align with their true interests by selectively\nengaging with content. However, users frequently exhibit inconsistent\npreferences: they may spend considerable time on content that offers little\nlong-term value, inadvertently signaling that such content is desirable.\nFocusing on the user side, this raises a key question: what does it take for\nsuch users to align the algorithm with their true interests?\n  To investigate these dynamics, we model the user's decision process as split\nbetween a rational system 2 that decides whether to engage and an impulsive\nsystem 1 that determines how long engagement lasts. We then study a\nmulti-leader, single-follower extensive Stackelberg game, where users,\nspecifically system 2, lead by committing to engagement strategies and the\nalgorithm best-responds based on observed interactions. We define the burden of\nalignment as the minimum horizon over which users must optimize to effectively\nsteer the algorithm. We show that a critical horizon exists: users who are\nsufficiently foresighted can achieve alignment, while those who are not are\ninstead aligned to the algorithm's objective. This critical horizon can be\nlong, imposing a substantial burden. However, even a small, costly signal\n(e.g., an extra click) can significantly reduce it. Overall, our framework\nexplains how users with inconsistent preferences can align an engagement-driven\nalgorithm with their interests in a Stackelberg equilibrium, highlighting both\nthe challenges and potential remedies for achieving alignment.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u7528\u6237\u5982\u4f55\u901a\u8fc7\u7b56\u7565\u6027\u4e92\u52a8\u6765\u5f15\u5bfc\u7b97\u6cd5\u4e0e\u5176\u771f\u5b9e\u5174\u8da3\u5bf9\u9f50\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u7cfb\u7edf\u51b3\u7b56\u6a21\u578b\u548cStackelberg\u535a\u5f08\u6846\u67b6\uff0c\u5206\u6790\u4e86\u7528\u6237\u9700\u8981\u7684\u524d\u77bb\u6027\u7a0b\u5ea6\u4ee5\u53ca\u964d\u4f4e\u5bf9\u9f50\u8d1f\u62c5\u7684\u65b9\u6cd5\u3002", "motivation": "\u5728\u7b97\u6cd5\u9a71\u52a8\u7684\u5e73\u53f0\u4e0a\uff0c\u7528\u6237\u7ecf\u5e38\u8868\u73b0\u51fa\u4e0d\u4e00\u81f4\u7684\u504f\u597d\uff0c\u53ef\u80fd\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u5728\u4f4e\u4ef7\u503c\u5185\u5bb9\u4e0a\uff0c\u8fd9\u5411\u7b97\u6cd5\u4f20\u9012\u4e86\u9519\u8bef\u7684\u4fe1\u53f7\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u7528\u6237\u9700\u8981\u4ec0\u4e48\u6761\u4ef6\u624d\u80fd\u6709\u6548\u5f15\u5bfc\u7b97\u6cd5\u4e0e\u5176\u771f\u5b9e\u5174\u8da3\u5bf9\u9f50\u3002", "method": "\u5c06\u7528\u6237\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u7406\u6027\u7cfb\u7edf2\uff08\u51b3\u5b9a\u662f\u5426\u53c2\u4e0e\uff09\u548c\u51b2\u52a8\u7cfb\u7edf1\uff08\u51b3\u5b9a\u53c2\u4e0e\u65f6\u957f\uff09\u7684\u53cc\u7cfb\u7edf\u6a21\u578b\uff0c\u91c7\u7528\u591a\u9886\u5bfc\u8005-\u5355\u8ddf\u968f\u8005\u7684Stackelberg\u6269\u5c55\u535a\u5f08\u6846\u67b6\uff0c\u7528\u6237\u4f5c\u4e3a\u9886\u5bfc\u8005\u627f\u8bfa\u53c2\u4e0e\u7b56\u7565\uff0c\u7b97\u6cd5\u57fa\u4e8e\u89c2\u5bdf\u5230\u7684\u4e92\u52a8\u505a\u51fa\u6700\u4f73\u54cd\u5e94\u3002", "result": "\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u7684\u5bf9\u9f50\u89c6\u91ce\uff1a\u8db3\u591f\u6709\u8fdc\u89c1\u7684\u7528\u6237\u53ef\u4ee5\u5b9e\u73b0\u7b97\u6cd5\u5bf9\u9f50\uff0c\u800c\u77ed\u89c6\u7684\u7528\u6237\u5219\u4f1a\u88ab\u7b97\u6cd5\u76ee\u6807\u6240\u5bf9\u9f50\u3002\u8fd9\u4e2a\u5173\u952e\u89c6\u91ce\u53ef\u80fd\u5f88\u957f\uff0c\u6784\u6210\u663e\u8457\u8d1f\u62c5\uff0c\u4f46\u5373\u4f7f\u662f\u4e00\u4e2a\u5c0f\u7684\u3001\u6709\u6210\u672c\u7684\u4fe1\u53f7\uff08\u5982\u989d\u5916\u70b9\u51fb\uff09\u4e5f\u80fd\u663e\u8457\u964d\u4f4e\u5bf9\u9f50\u8d1f\u62c5\u3002", "conclusion": "\u8be5\u6846\u67b6\u89e3\u91ca\u4e86\u5177\u6709\u4e0d\u4e00\u81f4\u504f\u597d\u7684\u7528\u6237\u5982\u4f55\u5728Stackelberg\u5747\u8861\u4e2d\u5b9e\u73b0\u4e0e\u53c2\u4e0e\u9a71\u52a8\u7b97\u6cd5\u7684\u5bf9\u9f50\uff0c\u65e2\u63ed\u793a\u4e86\u5b9e\u73b0\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u4e5f\u6307\u51fa\u4e86\u6f5c\u5728\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16009", "categories": ["econ.GN", "cs.LG", "q-fin.EC", "91B05"], "pdf": "https://arxiv.org/pdf/2510.16009", "abs": "https://arxiv.org/abs/2510.16009", "authors": ["Diego Vallarino"], "title": "Data for Inclusion: The Redistributive Power of Data Economics", "comment": null, "summary": "This paper evaluates the redistributive and efficiency impacts of expanding\naccess to positive credit information in a financially excluded economy. Using\nmicrodata from Uruguay's 2021 household survey, we simulate three data regimes\nnegative only, partial positive (Score+), and synthetic full visibility and\nassess their effects on access to credit, interest burden, and inequality. Our\nfindings reveal that enabling broader data sharing substantially reduces\nfinancial costs, compresses interest rate dispersion, and lowers the Gini\ncoefficient of credit burden. While partial visibility benefits a subset of the\npopulation, full synthetic access delivers the most equitable and efficient\noutcomes. The analysis positions credit data as a non-rival public asset with\ntransformative implications for financial inclusion and poverty reduction.", "AI": {"tldr": "\u8bc4\u4f30\u5728\u91d1\u878d\u6392\u65a5\u7ecf\u6d4e\u4e2d\u6269\u5927\u6b63\u9762\u4fe1\u7528\u4fe1\u606f\u83b7\u53d6\u5bf9\u6536\u5165\u5206\u914d\u548c\u6548\u7387\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u66f4\u5e7f\u6cdb\u7684\u6570\u636e\u5171\u4eab\u80fd\u663e\u8457\u964d\u4f4e\u91d1\u878d\u6210\u672c\u3001\u538b\u7f29\u5229\u7387\u5dee\u5f02\u5e76\u51cf\u5c11\u4fe1\u7528\u8d1f\u62c5\u4e0d\u5e73\u7b49\u3002", "motivation": "\u7814\u7a76\u5728\u91d1\u878d\u6392\u65a5\u7ecf\u6d4e\u4e2d\u6269\u5927\u6b63\u9762\u4fe1\u7528\u4fe1\u606f\u83b7\u53d6\u7684\u518d\u5206\u914d\u548c\u6548\u7387\u5f71\u54cd\uff0c\u63a2\u8ba8\u4e0d\u540c\u6570\u636e\u5171\u4eab\u673a\u5236\u5bf9\u91d1\u878d\u5305\u5bb9\u6027\u7684\u4f5c\u7528\u3002", "method": "\u4f7f\u7528\u4e4c\u62c9\u572d2021\u5e74\u5bb6\u5ead\u8c03\u67e5\u5fae\u89c2\u6570\u636e\uff0c\u6a21\u62df\u4e09\u79cd\u6570\u636e\u5236\u5ea6\uff1a\u4ec5\u8d1f\u9762\u4fe1\u606f\u3001\u90e8\u5206\u6b63\u9762\u4fe1\u606f\uff08Score+\uff09\u548c\u5408\u6210\u5b8c\u5168\u53ef\u89c1\u6027\uff0c\u8bc4\u4f30\u5bf9\u4fe1\u8d37\u83b7\u53d6\u3001\u5229\u606f\u8d1f\u62c5\u548c\u4e0d\u5e73\u7b49\u7684\u5f71\u54cd\u3002", "result": "\u66f4\u5e7f\u6cdb\u7684\u6570\u636e\u5171\u4eab\u663e\u8457\u964d\u4f4e\u91d1\u878d\u6210\u672c\u3001\u538b\u7f29\u5229\u7387\u5206\u6563\u5ea6\uff0c\u5e76\u964d\u4f4e\u4fe1\u7528\u8d1f\u62c5\u7684\u57fa\u5c3c\u7cfb\u6570\u3002\u90e8\u5206\u53ef\u89c1\u6027\u4f7f\u90e8\u5206\u4eba\u7fa4\u53d7\u76ca\uff0c\u800c\u5b8c\u5168\u5408\u6210\u8bbf\u95ee\u63d0\u4f9b\u6700\u516c\u5e73\u548c\u9ad8\u6548\u7684\u7ed3\u679c\u3002", "conclusion": "\u4fe1\u7528\u6570\u636e\u5e94\u88ab\u89c6\u4e3a\u975e\u7ade\u4e89\u6027\u516c\u5171\u8d44\u4ea7\uff0c\u5bf9\u91d1\u878d\u5305\u5bb9\u548c\u51cf\u8d2b\u5177\u6709\u53d8\u9769\u6027\u610f\u4e49\u3002"}}
{"id": "2510.17530", "categories": ["cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.17530", "abs": "https://arxiv.org/abs/2510.17530", "authors": ["Xu He", "Xiaolin Meng", "Youdong Zhang", "Lingfei Mo", "Wenxuan Yin"], "title": "Navigate in Demanding Missions: Integrating Human Intelligence and Brain-Inspired Intelligence", "comment": null, "summary": "This perspective analyzes the intricate interplay among neuroscience,\nBrain-Inspired Intelligence (BII), and Brain-Inspired Navigation (BIN),\nrevealing a current lack of cooperative relationship between Brain-Computer\nInterfaces (BCIs) and BIN fields. We advocate for the integration of\nneuromorphic-empowered BCI into BIN, thereby bolstering the unmanned systems'\nreliable navigation in demanding missions, such as deep space exploration, etc.\nWe highlight that machine intelligence, reinforced by brain-inspired artificial\nconsciousness, can extend human intelligence, with human intelligence mediated\nby neuromorphic-enabled BCI acting as a safeguard in case machine intelligence\nfailures. This study also discusses the potentials of the proposed approach to\nenhance unmanned systems' capabilities and facilitate the diagnostics of\nspatial cognition disorders, while considering associated ethical and security\nconcerns.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u795e\u7ecf\u79d1\u5b66\u3001\u8111\u542f\u53d1\u667a\u80fd\u548c\u8111\u542f\u53d1\u5bfc\u822a\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u63d0\u51fa\u5c06\u795e\u7ecf\u5f62\u6001\u8d4b\u80fd\u7684\u8111\u673a\u63a5\u53e3\u6574\u5408\u5230\u8111\u542f\u53d1\u5bfc\u822a\u4e2d\uff0c\u4ee5\u589e\u5f3a\u65e0\u4eba\u7cfb\u7edf\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u5bfc\u822a\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u8111\u673a\u63a5\u53e3\u548c\u8111\u542f\u53d1\u5bfc\u822a\u9886\u57df\u7f3a\u4e4f\u5408\u4f5c\u5173\u7cfb\uff0c\u9700\u8981\u6574\u5408\u795e\u7ecf\u5f62\u6001\u8d4b\u80fd\u7684\u8111\u673a\u63a5\u53e3\u6765\u589e\u5f3a\u65e0\u4eba\u7cfb\u7edf\u7684\u53ef\u9760\u5bfc\u822a\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6df1\u7a7a\u63a2\u7d22\u7b49\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u3002", "method": "\u901a\u8fc7\u6574\u5408\u795e\u7ecf\u5f62\u6001\u8d4b\u80fd\u7684\u8111\u673a\u63a5\u53e3\u5230\u8111\u542f\u53d1\u5bfc\u822a\u4e2d\uff0c\u5229\u7528\u8111\u542f\u53d1\u4eba\u5de5\u667a\u80fd\u589e\u5f3a\u673a\u5668\u667a\u80fd\uff0c\u540c\u65f6\u4ee5\u4eba\u7c7b\u667a\u80fd\u4f5c\u4e3a\u673a\u5668\u667a\u80fd\u5931\u6548\u65f6\u7684\u5b89\u5168\u4fdd\u969c\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u671b\u589e\u5f3a\u65e0\u4eba\u7cfb\u7edf\u80fd\u529b\uff0c\u4fc3\u8fdb\u7a7a\u95f4\u8ba4\u77e5\u969c\u788d\u7684\u8bca\u65ad\uff0c\u4f46\u9700\u8981\u8003\u8651\u76f8\u5173\u7684\u4f26\u7406\u548c\u5b89\u5168\u95ee\u9898\u3002", "conclusion": "\u795e\u7ecf\u5f62\u6001\u8d4b\u80fd\u7684\u8111\u673a\u63a5\u53e3\u4e0e\u8111\u542f\u53d1\u5bfc\u822a\u7684\u6574\u5408\u53ef\u4ee5\u63d0\u5347\u65e0\u4eba\u7cfb\u7edf\u7684\u5bfc\u822a\u53ef\u9760\u6027\uff0c\u540c\u65f6\u9700\u8981\u5173\u6ce8\u4f26\u7406\u548c\u5b89\u5168\u8003\u91cf\u3002"}}
{"id": "2510.16140", "categories": ["stat.AP", "cs.LG", "stat.CO"], "pdf": "https://arxiv.org/pdf/2510.16140", "abs": "https://arxiv.org/abs/2510.16140", "authors": ["Corey M. Abramson", "Yuhan", "Nian"], "title": "The Cultural Mapping and Pattern Analysis (CMAP) Visualization Toolkit: Open Source Text Analysis for Qualitative and Computational Social Science", "comment": "V1", "summary": "The CMAP (cultural mapping and pattern analysis) visualization toolkit\nintroduced in this paper is an open-source suite for analyzing and visualizing\ntext data - from qualitative fieldnotes and in-depth interview transcripts to\nhistorical documents and web-scaped data like message board posts or blogs. The\ntoolkit is designed for scholars integrating pattern analysis, data\nvisualization, and explanation in qualitative and/or computational social\nscience (CSS). Despite the existence of off-the-shelf commercial qualitative\ndata analysis software, there is a dearth of highly scalable open source\noptions that can work with large data sets, and allow advanced statistical and\nlanguage modeling. The foundation of the toolkit is a pragmatic approach that\naligns research tools with social science project goals- empirical explanation,\ntheory-guided measurement, comparative design, or evidence-based\nrecommendations- guided by the principle that research paradigm and questions\nshould determine methods. Consequently, the CMAP visualization toolkit offers a\nrange of possibilities through the adjustment of relatively small number of\nparameters, and allows integration with other python tools.", "AI": {"tldr": "CMAP\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u6587\u5316\u6620\u5c04\u548c\u6a21\u5f0f\u5206\u6790\u53ef\u89c6\u5316\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u5206\u6790\u548c\u53ef\u89c6\u5316\u6587\u672c\u6570\u636e\uff0c\u652f\u6301\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u9ad8\u7ea7\u7edf\u8ba1\u8bed\u8a00\u5efa\u6a21\u3002", "motivation": "\u73b0\u6709\u5546\u4e1a\u5b9a\u6027\u6570\u636e\u5206\u6790\u8f6f\u4ef6\u7f3a\u4e4f\u9ad8\u5ea6\u53ef\u6269\u5c55\u7684\u5f00\u6e90\u9009\u9879\uff0c\u65e0\u6cd5\u5904\u7406\u5927\u6570\u636e\u96c6\u548c\u96c6\u6210\u9ad8\u7ea7\u7edf\u8ba1\u8bed\u8a00\u5efa\u6a21\u3002", "method": "\u91c7\u7528\u5b9e\u7528\u4e3b\u4e49\u65b9\u6cd5\uff0c\u5c06\u7814\u7a76\u5de5\u5177\u4e0e\u793e\u4f1a\u79d1\u5b66\u9879\u76ee\u76ee\u6807\u5bf9\u9f50\uff0c\u901a\u8fc7\u8c03\u6574\u5c11\u91cf\u53c2\u6570\u63d0\u4f9b\u591a\u79cd\u53ef\u80fd\u6027\uff0c\u5e76\u80fd\u4e0e\u5176\u4ed6Python\u5de5\u5177\u96c6\u6210\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u652f\u6301\u4ece\u5b9a\u6027\u7530\u91ce\u7b14\u8bb0\u5230\u7f51\u7edc\u6293\u53d6\u6570\u636e\u7b49\u591a\u79cd\u6587\u672c\u6570\u636e\u7684\u5206\u6790\u548c\u53ef\u89c6\u5316\u3002", "conclusion": "CMAP\u5de5\u5177\u5305\u4e3a\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u7814\u7a76\u8303\u5f0f\u548c\u65b9\u6cd5\u5e94\u7531\u7814\u7a76\u95ee\u9898\u51b3\u5b9a\u3002"}}
{"id": "2510.16472", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.16472", "abs": "https://arxiv.org/abs/2510.16472", "authors": ["Carmen Berta C. De Saituma Cagiza", "Ilidio Cagiza"], "title": "Development finance institutions (DFIs), political conditions, and foreign direct investment (FDI) in Sub-Saharan Africa", "comment": "12 pages, 1 figure", "summary": "This study investigates the dynamic relationship between development finance\ninstitutions (DFIs), foreign direct investment (FDI), and economic development\nin Sub-Saharan Africa (SSA) from 1990 to 2018, using a quantitative panel\ndataset of annual data for five SSA countries (Nigeria, Ghana, Kenya, South\nAfrica, and Zimbabwe) and a fixed-effects model estimated in STATA.\nSpecifically, the analysis examines whether DFIs enhance FDI inflows, thereby\npromoting economic growth and contributing to the achievement of the\nSustainable Development Goals (SDGs). The findings indicate that although DFIs\nhave a theoretically positive impact on FDI, this relationship is not\nstatistically significant across the sample, suggesting contextual dependencies\ninfluenced by regional economic variations. The study also analyzes how\neconomic growth, trade openness, inflation, political stability, and the rule\nof law influence this nexus, elucidating their roles in shaping investment\nclimates. A sectoral analysis indicates that DFI investments in infrastructure,\nagribusiness, and finance significantly affect FDI, with infrastructure having\nthe greatest impact owing to its foundational role in economic systems. This\nresearch contributes by linking DFIs with FDI in SSA in a panel setting, thus\nproviding a framework for policymakers to strengthen institutional and\nmacroeconomic conditions to optimize the impact of DFIs on FDI and, ultimately,\non sustainable development. The findings underscore the need for targeted\npolicies to address regional disparities and enhance DFI effectiveness in\nfostering sustainable growth.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u75281990-2018\u5e74\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u4e94\u56fd\u7684\u9762\u677f\u6570\u636e\u548c\u56fa\u5b9a\u6548\u5e94\u6a21\u578b\uff0c\u5206\u6790\u5f00\u53d1\u6027\u91d1\u878d\u673a\u6784\u5bf9FDI\u548c\u7ecf\u6d4e\u53d1\u5c55\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0DFIs\u5bf9FDI\u7684\u7406\u8bba\u6b63\u9762\u5f71\u54cd\u5728\u7edf\u8ba1\u4e0a\u4e0d\u663e\u8457\uff0c\u4f46\u57fa\u7840\u8bbe\u65bd\u6295\u8d44\u5f71\u54cd\u6700\u5927\u3002", "motivation": "\u63a2\u8ba8\u5f00\u53d1\u6027\u91d1\u878d\u673a\u6784\u662f\u5426\u901a\u8fc7\u4fc3\u8fdbFDI\u6d41\u5165\u6765\u63a8\u52a8\u7ecf\u6d4e\u589e\u957f\u548c\u5b9e\u73b0\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\uff0c\u586b\u8865\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u5730\u533a\u76f8\u5173\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u75281990-2018\u5e74\u5c3c\u65e5\u5229\u4e9a\u3001\u52a0\u7eb3\u3001\u80af\u5c3c\u4e9a\u3001\u5357\u975e\u548c\u6d25\u5df4\u5e03\u97e6\u4e94\u56fd\u7684\u5e74\u5ea6\u9762\u677f\u6570\u636e\uff0c\u91c7\u7528STATA\u4e2d\u7684\u56fa\u5b9a\u6548\u5e94\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\u3002", "result": "DFIs\u5bf9FDI\u7684\u7406\u8bba\u6b63\u9762\u5f71\u54cd\u5728\u7edf\u8ba1\u4e0a\u4e0d\u663e\u8457\uff0c\u8868\u660e\u5b58\u5728\u533a\u57df\u7ecf\u6d4e\u5dee\u5f02\u7684\u5f71\u54cd\u3002\u57fa\u7840\u8bbe\u65bd\u9886\u57df\u7684DFI\u6295\u8d44\u5bf9FDI\u5f71\u54cd\u6700\u5927\uff0c\u5176\u6b21\u662f\u519c\u4e1a\u7efc\u5408\u4f01\u4e1a\u548c\u91d1\u878d\u4e1a\u3002", "conclusion": "\u9700\u8981\u9488\u5bf9\u6027\u653f\u7b56\u89e3\u51b3\u533a\u57df\u5dee\u5f02\uff0c\u52a0\u5f3a\u5236\u5ea6\u548c\u5b8f\u89c2\u7ecf\u6d4e\u6761\u4ef6\u4ee5\u4f18\u5316DFIs\u5bf9FDI\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u5f71\u54cd\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u6846\u67b6\u3002"}}
{"id": "2510.17688", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17688", "abs": "https://arxiv.org/abs/2510.17688", "authors": ["Shawn M. Gibford", "Mohammad Reza Boskabadi", "Christopher J. Savoie", "Seyed Soheil Mansouri"], "title": "Quantum Synthetic Data Generation for Industrial Bioprocess Monitoring", "comment": null, "summary": "Data scarcity and sparsity in bio-manufacturing poses challenges for accurate\nmodel\n  development, process monitoring, and optimization. We aim to replicate and\ncapture\n  the complex dynamics of industrial bioprocesses by proposing the use of a\nQuantum\n  Wasserstein Generative Adversarial Network with Gradient Penalty (QWGAN-GP)\nto\n  generate synthetic time series data for industrially relevant processes. The\n  generator within our GAN is comprised of a Parameterized Quantum Circuit\n(PQC). This\n  methodology offers potential advantages in process monitoring, modeling,\n  forecasting, and optimization, enabling more efficient bioprocess management\nby\n  reducing the dependence on scarce experimental data. Our results demonstrate\n  acceptable performance in capturing the temporal dynamics of real bioprocess\ndata.\n  We focus on Optical Density, a key measurement for Dry Biomass estimation.\nThe data\n  generated showed high fidelity to the actual historical experimental data.\nThis\n  intersection of quantum computing and machine learning has opened new\nfrontiers in\n  data analysis and generation, particularly in computationally intensive\nfields, for\n  use cases such as increasing prediction accuracy for soft sensor design or\nfor use\n  in predictive control.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u91cf\u5b50Wasserstein\u751f\u6210\u5bf9\u6297\u7f51\u7edc(QWGAN-GP)\u751f\u6210\u751f\u7269\u5236\u9020\u8fc7\u7a0b\u7684\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "motivation": "\u751f\u7269\u5236\u9020\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u7a00\u758f\u6027\u7ed9\u6a21\u578b\u5f00\u53d1\u3001\u8fc7\u7a0b\u76d1\u63a7\u548c\u4f18\u5316\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u590d\u5236\u548c\u6355\u6349\u5de5\u4e1a\u751f\u7269\u8fc7\u7a0b\u7684\u590d\u6742\u52a8\u6001\u3002", "method": "\u4f7f\u7528\u91cf\u5b50Wasserstein\u751f\u6210\u5bf9\u6297\u7f51\u7edc(QWGAN-GP)\uff0c\u5176\u4e2d\u751f\u6210\u5668\u7531\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def(PQC)\u7ec4\u6210\uff0c\u751f\u6210\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6355\u6349\u771f\u5b9e\u751f\u7269\u8fc7\u7a0b\u6570\u636e\u7684\u65f6\u95f4\u52a8\u6001\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u751f\u6210\u7684\u5149\u5bc6\u5ea6\u6570\u636e\u4e0e\u5386\u53f2\u5b9e\u9a8c\u6570\u636e\u5177\u6709\u9ad8\u5ea6\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u91cf\u5b50\u8ba1\u7b97\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u7ed3\u5408\u4e3a\u6570\u636e\u5206\u6790\u548c\u751f\u6210\u5f00\u8f9f\u4e86\u65b0\u524d\u6cbf\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u5bc6\u96c6\u578b\u9886\u57df\uff0c\u53ef\u7528\u4e8e\u63d0\u9ad8\u8f6f\u4f20\u611f\u5668\u8bbe\u8ba1\u7684\u9884\u6d4b\u51c6\u786e\u6027\u6216\u7528\u4e8e\u9884\u6d4b\u63a7\u5236\u3002"}}
{"id": "2510.16174", "categories": ["stat.AP", "hep-ex", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.16174", "abs": "https://arxiv.org/abs/2510.16174", "authors": ["Chad Schafer", "Larry Wasserman", "Mikael Kuusela"], "title": "COWs and their Hybrids: A Statistical View of Custom Orthogonal Weights", "comment": null, "summary": "A recurring challenge in high energy physics is inference of the signal\ncomponent from a distribution for which observations are assumed to be a\nmixture of signal and background events. A standard assumption is that there\nexists information encoded in a discriminant variable that is effective at\nseparating signal and background. This can be used to assign a signal weight to\neach event, with these weights used in subsequent analyses of one or more\ncontrol variables of interest. The custom orthogonal weights (COWs) approach of\nDembinski, et al.(2022), a generalization of the sPlot approach of Barlow\n(1987) and Pivk and Le Diberder (2005), is tailored to address this objective.\nThe problem, and this method, present interesting and novel statistical issues.\nHere we formalize the assumptions needed and the statistical properties, while\nalso considering extensions and alternative approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86\u9ad8\u80fd\u7269\u7406\u4e2d\u4fe1\u53f7\u4e0e\u80cc\u666f\u6df7\u5408\u5206\u5e03\u7684\u63a8\u65ad\u95ee\u9898\uff0c\u63d0\u51fa\u5e76\u5206\u6790\u4e86COWs\u65b9\u6cd5\u4f5c\u4e3asPlot\u65b9\u6cd5\u7684\u63a8\u5e7f\uff0c\u7528\u4e8e\u5728\u5224\u522b\u53d8\u91cf\u6709\u6548\u5206\u79bb\u4fe1\u53f7\u548c\u80cc\u666f\u7684\u60c5\u51b5\u4e0b\u4e3a\u4e8b\u4ef6\u5206\u914d\u4fe1\u53f7\u6743\u91cd\u3002", "motivation": "\u89e3\u51b3\u9ad8\u80fd\u7269\u7406\u4e2d\u4ece\u4fe1\u53f7\u548c\u80cc\u666f\u4e8b\u4ef6\u6df7\u5408\u5206\u5e03\u4e2d\u63a8\u65ad\u4fe1\u53f7\u6210\u5206\u7684\u91cd\u590d\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u80fd\u591f\u6709\u6548\u5206\u79bb\u4fe1\u53f7\u548c\u80cc\u666f\u7684\u5224\u522b\u53d8\u91cf\u65f6\u3002", "method": "\u4f7f\u7528COWs\uff08\u6b63\u4ea4\u6743\u91cd\uff09\u65b9\u6cd5\uff0c\u8fd9\u662f\u5bf9sPlot\u65b9\u6cd5\u7684\u63a8\u5e7f\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u4e8b\u4ef6\u5206\u914d\u4fe1\u53f7\u6743\u91cd\uff0c\u7528\u4e8e\u540e\u7eed\u5bf9\u611f\u5174\u8da3\u7684\u63a7\u5236\u53d8\u91cf\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5f62\u5f0f\u5316\u4e86\u8be5\u65b9\u6cd5\u6240\u9700\u7684\u5047\u8bbe\u6761\u4ef6\u548c\u7edf\u8ba1\u7279\u6027\uff0c\u540c\u65f6\u8003\u8651\u4e86\u6269\u5c55\u65b9\u6cd5\u548c\u66ff\u4ee3\u65b9\u6cd5\u3002", "conclusion": "COWs\u65b9\u6cd5\u4e3a\u89e3\u51b3\u9ad8\u80fd\u7269\u7406\u4e2d\u7684\u4fe1\u53f7\u63a8\u65ad\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u7edf\u8ba1\u7279\u6027\u548c\u6f5c\u5728\u6269\u5c55\u3002"}}
{"id": "2510.15936", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.15936", "abs": "https://arxiv.org/abs/2510.15936", "authors": ["Juan David Salazar Rodriguez", "Sam Conrad Joyce", "Nachamma Sockalingam", "Julfendi"], "title": "Large Language Models in Architecture Studio: A Framework for Learning Outcomes", "comment": null, "summary": "The study explores the role of large language models (LLMs) in the context of\nthe architectural design studio, understood as the pedagogical core of\narchitectural education. Traditionally, the studio has functioned as an\nexperiential learning space where students tackle design problems through\nreflective practice, peer critique, and faculty guidance. However, the\nintegration of artificial intelligence (AI) in this environment has been\nlargely focused on form generation, automation, and representation-al\nefficiency, neglecting its potential as a pedagogical tool to strengthen\nstudent autonomy, collaboration, and self-reflection. The objectives of this\nresearch were: (1) to identify pedagogical challenges in self-directed,\npeer-to-peer, and teacher-guided learning processes in architecture studies;\n(2) to propose AI interventions, particularly through LLM, that contribute to\novercoming these challenges; and (3) to align these interventions with\nmeasurable learning outcomes using Bloom's taxonomy. The findings show that the\nmain challenges include managing student autonomy, tensions in peer feedback,\nand the difficulty of balancing the transmission of technical knowledge with\nthe stimulation of creativity in teaching. In response to this, LLMs are\nemerging as complementary agents capable of generating personalized feedback,\norganizing collaborative interactions, and offering adaptive cognitive\nscaffolding. Furthermore, their implementation can be linked to the cognitive\nlevels of Bloom's taxonomy: facilitating the recall and understanding of\narchitectural concepts, supporting application and analysis through interactive\ncase studies, and encouraging synthesis and evaluation through hypothetical\ndesign scenarios.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5efa\u7b51\u6559\u80b2\u6838\u5fc3\u2014\u2014\u8bbe\u8ba1\u5de5\u4f5c\u5ba4\u4e2d\u7684\u89d2\u8272\uff0c\u63d0\u51faLLMs\u53ef\u4f5c\u4e3a\u6559\u5b66\u5de5\u5177\u589e\u5f3a\u5b66\u751f\u81ea\u4e3b\u6027\u3001\u534f\u4f5c\u548c\u81ea\u6211\u53cd\u601d\u80fd\u529b\uff0c\u800c\u975e\u4ec5\u7528\u4e8e\u5f62\u5f0f\u751f\u6210\u548c\u81ea\u52a8\u5316\u3002", "motivation": "\u4f20\u7edf\u5efa\u7b51\u8bbe\u8ba1\u5de5\u4f5c\u5ba4\u4f9d\u8d56\u4f53\u9a8c\u5f0f\u5b66\u4e60\uff0c\u4f46AI\u5728\u8be5\u73af\u5883\u4e2d\u7684\u5e94\u7528\u4e3b\u8981\u5173\u6ce8\u5f62\u5f0f\u751f\u6210\u548c\u6548\u7387\uff0c\u5ffd\u89c6\u4e86\u5176\u4f5c\u4e3a\u6559\u5b66\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u652f\u6301\u5b66\u751f\u81ea\u4e3b\u6027\u3001\u534f\u4f5c\u548c\u81ea\u6211\u53cd\u601d\u65b9\u9762\u3002", "method": "\u8bc6\u522b\u5efa\u7b51\u6559\u80b2\u4e2d\u81ea\u4e3b\u5b66\u4e60\u3001\u540c\u4f34\u5b66\u4e60\u548c\u6559\u5e08\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u6559\u5b66\u6311\u6218\uff0c\u63d0\u51fa\u57fa\u4e8eLLM\u7684AI\u5e72\u9884\u63aa\u65bd\uff0c\u5e76\u5c06\u8fd9\u4e9b\u5e72\u9884\u4e0e\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u7684\u53ef\u8861\u91cf\u5b66\u4e60\u6210\u679c\u5bf9\u9f50\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e3b\u8981\u6311\u6218\u5305\u62ec\u7ba1\u7406\u5b66\u751f\u81ea\u4e3b\u6027\u3001\u540c\u4f34\u53cd\u9988\u4e2d\u7684\u7d27\u5f20\u5173\u7cfb\uff0c\u4ee5\u53ca\u5e73\u8861\u6280\u672f\u77e5\u8bc6\u4f20\u6388\u4e0e\u521b\u9020\u529b\u6fc0\u53d1\u3002LLMs\u80fd\u591f\u751f\u6210\u4e2a\u6027\u5316\u53cd\u9988\u3001\u7ec4\u7ec7\u534f\u4f5c\u4e92\u52a8\u5e76\u63d0\u4f9b\u9002\u5e94\u6027\u8ba4\u77e5\u652f\u67b6\u3002", "conclusion": "LLMs\u53ef\u4f5c\u4e3a\u8865\u5145\u6027\u6559\u5b66\u5de5\u5177\uff0c\u901a\u8fc7\u4fc3\u8fdb\u5efa\u7b51\u6982\u5ff5\u7684\u8bb0\u5fc6\u7406\u89e3\u3001\u652f\u6301\u5e94\u7528\u5206\u6790\uff0c\u4ee5\u53ca\u9f13\u52b1\u7efc\u5408\u8bc4\u4f30\uff0c\u6709\u6548\u5e94\u5bf9\u5efa\u7b51\u6559\u80b2\u4e2d\u7684\u6559\u5b66\u6311\u6218\u3002"}}
{"id": "2510.16483", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.16483", "abs": "https://arxiv.org/abs/2510.16483", "authors": ["Kazuhiko Sumiya", "Jesper Bagger"], "title": "Income Taxes, Gross Hourly Wages, and the Anatomy of Behavioral Responses: Evidence from a Danish Tax Reform", "comment": null, "summary": "This paper provides quasi-experimental evidence on how income taxes affect\ngross hourly wages, utilizing Danish administrative data and a tax reform that\nintroduced joint taxation. Exploiting spousal income for identification, we\npresent nonparametric, difference-in-differences graphical evidence among\nhusbands. For low-income workers, taxes have negative and dynamic effects on\nwages; their wage elasticity with respect to net-of-marginal-tax rates is 0.4.\nFor medium-income workers, the effects are smaller and insignificant. Wages\nrespond to taxes through promotions or job-to-job transitions. Neither daily\nnor annual hours worked respond significantly; consequently, annual earnings\nrespond to taxes primarily through hourly wages, rather than through labor\nsupply.", "AI": {"tldr": "\u5229\u7528\u4e39\u9ea6\u884c\u653f\u6570\u636e\u548c\u5f15\u5165\u8054\u5408\u5f81\u7a0e\u7684\u7a0e\u6539\uff0c\u901a\u8fc7\u914d\u5076\u6536\u5165\u8bc6\u522b\uff0c\u53d1\u73b0\u4f4e\u6536\u5165\u5de5\u4eba\u7684\u5de5\u8d44\u5bf9\u8fb9\u9645\u7a0e\u7387\u6709\u8d1f\u5411\u52a8\u6001\u5f71\u54cd\uff0c\u5f39\u6027\u4e3a0.4\uff1b\u4e2d\u7b49\u6536\u5165\u5de5\u4eba\u5f71\u54cd\u8f83\u5c0f\u4e14\u4e0d\u663e\u8457\u3002\u5de5\u8d44\u901a\u8fc7\u664b\u5347\u6216\u8df3\u69fd\u54cd\u5e94\u7a0e\u6536\uff0c\u800c\u975e\u5de5\u4f5c\u65f6\u95f4\u53d8\u5316\u3002", "motivation": "\u7814\u7a76\u6240\u5f97\u7a0e\u5982\u4f55\u5f71\u54cd\u5c0f\u65f6\u5de5\u8d44\uff0c\u7279\u522b\u5173\u6ce8\u7a0e\u6536\u5bf9\u5de5\u8d44\u800c\u975e\u52b3\u52a8\u4f9b\u7ed9\u7684\u5f71\u54cd\uff0c\u5229\u7528\u4e39\u9ea6\u7a0e\u6539\u63d0\u4f9b\u7684\u51c6\u5b9e\u9a8c\u73af\u5883\u3002", "method": "\u4f7f\u7528\u4e39\u9ea6\u884c\u653f\u6570\u636e\u548c\u7a0e\u6539\u653f\u7b56\uff0c\u91c7\u7528\u51c6\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5229\u7528\u914d\u5076\u6536\u5165\u8fdb\u884c\u8bc6\u522b\uff0c\u5bf9\u4e08\u592b\u8fdb\u884c\u975e\u53c2\u6570\u53cc\u91cd\u5dee\u5206\u56fe\u5f62\u5206\u6790\u3002", "result": "\u4f4e\u6536\u5165\u5de5\u4eba\u5de5\u8d44\u5bf9\u51c0\u8fb9\u9645\u7a0e\u7387\u5f39\u6027\u4e3a0.4\uff0c\u4e2d\u7b49\u6536\u5165\u5de5\u4eba\u5f71\u54cd\u4e0d\u663e\u8457\uff1b\u5de5\u8d44\u901a\u8fc7\u664b\u5347\u6216\u5de5\u4f5c\u8f6c\u6362\u54cd\u5e94\u7a0e\u6536\uff0c\u65e5/\u5e74\u5de5\u4f5c\u65f6\u95f4\u65e0\u663e\u8457\u53d8\u5316\u3002", "conclusion": "\u6240\u5f97\u7a0e\u4e3b\u8981\u901a\u8fc7\u5f71\u54cd\u5c0f\u65f6\u5de5\u8d44\u800c\u975e\u52b3\u52a8\u4f9b\u7ed9\u6765\u5f71\u54cd\u5e74\u6536\u5165\uff0c\u5de5\u8d44\u54cd\u5e94\u673a\u5236\u662f\u664b\u5347\u6216\u5de5\u4f5c\u8f6c\u6362\uff0c\u800c\u975e\u5de5\u4f5c\u65f6\u95f4\u8c03\u6574\u3002"}}
{"id": "2510.15959", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.15959", "abs": "https://arxiv.org/abs/2510.15959", "authors": ["Isabelle Hupont", "Marisa Ponti", "Sven Schade"], "title": "Exploring the Potential of Citiverses for Regulatory Learning", "comment": "26 pages", "summary": "Citiverses hold the potential to support regulatory learning by offering\nimmersive, virtual environments for experimenting with policy scenarios and\ntechnologies. This paper proposes a science-for-policy agenda to explore the\npotential of citiverses as experimentation spaces for regulatory learning,\ngrounded in a consultation with a high-level panel of experts, including\npolicymakers from the European Commission, national government science advisers\nand leading researchers in digital regulation and virtual worlds. It identifies\nkey research areas, including scalability, real-time feedback, complexity\nmodelling, cross-border collaboration, risk reduction, citizen participation,\nethical considerations and the integration of emerging technologies. In\naddition, the paper analyses a set of experimental topics, spanning\ntransportation, urban planning and the environment/climate crisis, that could\nbe tested in citiverse platforms to advance regulatory learning in these areas.\nThe proposed work is designed to inform future research for policy and\nemphasizes a responsible approach to developing and using citiverses. It\nprioritizes careful consideration of the ethical, economic, ecological and\nsocial dimensions of different regulations. The paper also explores essential\npreliminary steps necessary for integrating citiverses into the broader\necosystems of experimentation spaces, including test beds, living labs and\nregulatory sandboxes", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u79d1\u5b66\u653f\u7b56\u8bae\u7a0b\uff0c\u63a2\u7d22\u57ce\u5e02\u865a\u62df\u4e16\u754c\u4f5c\u4e3a\u76d1\u7ba1\u5b66\u4e60\u5b9e\u9a8c\u7a7a\u95f4\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u4e13\u5bb6\u54a8\u8be2\u786e\u5b9a\u4e86\u5173\u952e\u7814\u7a76\u9886\u57df\u548c\u5b9e\u9a8c\u4e3b\u9898\u3002", "motivation": "\u5229\u7528\u57ce\u5e02\u865a\u62df\u4e16\u754c\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u6c89\u6d78\u5f0f\u5b9e\u9a8c\u73af\u5883\uff0c\u652f\u6301\u76d1\u7ba1\u5b66\u4e60\u548c\u6280\u672f\u6d4b\u8bd5\uff0c\u51cf\u5c11\u73b0\u5b9e\u4e16\u754c\u5b9e\u65bd\u98ce\u9669\u3002", "method": "\u57fa\u4e8e\u4e0e\u6b27\u6d32\u59d4\u5458\u4f1a\u653f\u7b56\u5236\u5b9a\u8005\u3001\u56fd\u5bb6\u653f\u5e9c\u79d1\u5b66\u987e\u95ee\u548c\u6570\u5b57\u76d1\u7ba1\u9886\u57df\u4e13\u5bb6\u7684\u9ad8\u5c42\u4e13\u5bb6\u54a8\u8be2\uff0c\u8bc6\u522b\u5173\u952e\u7814\u7a76\u9886\u57df\u548c\u5b9e\u9a8c\u4e3b\u9898\u3002", "result": "\u786e\u5b9a\u4e86\u53ef\u6269\u5c55\u6027\u3001\u5b9e\u65f6\u53cd\u9988\u3001\u590d\u6742\u6027\u5efa\u6a21\u7b49\u5173\u952e\u7814\u7a76\u9886\u57df\uff0c\u4ee5\u53ca\u4ea4\u901a\u3001\u57ce\u5e02\u89c4\u5212\u3001\u73af\u5883\u6c14\u5019\u5371\u673a\u7b49\u5177\u4f53\u5b9e\u9a8c\u4e3b\u9898\u3002", "conclusion": "\u57ce\u5e02\u865a\u62df\u4e16\u754c\u6709\u6f5c\u529b\u6210\u4e3a\u91cd\u8981\u7684\u76d1\u7ba1\u5b66\u4e60\u5b9e\u9a8c\u7a7a\u95f4\uff0c\u4f46\u9700\u8981\u8d1f\u8d23\u4efb\u5730\u5f00\u53d1\u4f7f\u7528\uff0c\u5e76\u8003\u8651\u4f26\u7406\u3001\u7ecf\u6d4e\u3001\u751f\u6001\u548c\u793e\u4f1a\u7ef4\u5ea6\u3002"}}
{"id": "2510.16180", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.16180", "abs": "https://arxiv.org/abs/2510.16180", "authors": ["Jeremy Goldwasser", "Addison J. Hu", "Alyssa Bilinski", "Daniel J. McDonald", "Ryan J. Tibshirani"], "title": "Estimating Time-Varying Epidemic Severity Rates with Adaptive Deconvolution", "comment": null, "summary": "Several key metrics in public health convey the probability that a primary\nevent will lead to a more serious secondary event in the future. These\n\"severity rates\" can change over the course of an epidemic in response to\nshifting conditions like new therapeutics, variants, or public health\ninterventions. In practice, time-varying parameters such as the case-fatality\nrate are typically estimated from aggregate count data. Prior work has\ndemonstrated that commonly-used ratio-based estimators can be highly biased,\nmotivating the development of new methods. In this paper, we develop an\nadaptive deconvolution approach based on approximating a Poisson-binomial model\nfor secondary events, and we regularize the maximum likelihood solution in this\nmodel with a trend filtering penalty to produce smooth but locally adaptive\nestimates of severity rates over time. This enables us to compute severity\nrates both retrospectively and in real time. Experiments based on COVID-19\ndeath and hospitalization data, both real and simulated, demonstrate that our\ndeconvolution estimator is generally more accurate than the standard\nratio-based methods, and displays reasonable robustness to model\nmisspecification.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6cca\u677e-\u4e8c\u9879\u6a21\u578b\u7684\u53bb\u5377\u79ef\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u968f\u65f6\u95f4\u53d8\u5316\u7684\u516c\u5171\u536b\u751f\u4e25\u91cd\u6027\u6307\u6807\uff0c\u5982\u75c5\u6b7b\u7387\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8d8b\u52bf\u6ee4\u6ce2\u60e9\u7f5a\u6b63\u5219\u5316\u6700\u5927\u4f3c\u7136\u89e3\uff0c\u80fd\u591f\u6bd4\u6807\u51c6\u6bd4\u7387\u65b9\u6cd5\u66f4\u51c6\u786e\u5730\u8ba1\u7b97\u56de\u987e\u6027\u548c\u5b9e\u65f6\u4e25\u91cd\u6027\u7387\u3002", "motivation": "\u516c\u5171\u536b\u751f\u4e2d\u7684\u5173\u952e\u6307\u6807\uff08\u5982\u75c5\u6b7b\u7387\uff09\u4f1a\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u4f46\u5e38\u7528\u7684\u6bd4\u7387\u4f30\u8ba1\u5668\u5b58\u5728\u9ad8\u5ea6\u504f\u5dee\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u6765\u51c6\u786e\u4f30\u8ba1\u8fd9\u4e9b\u968f\u65f6\u95f4\u53d8\u5316\u7684\u4e25\u91cd\u6027\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u53bb\u5377\u79ef\u65b9\u6cd5\uff0c\u57fa\u4e8e\u8fd1\u4f3c\u6cca\u677e-\u4e8c\u9879\u6a21\u578b\u5bf9\u6b21\u8981\u4e8b\u4ef6\u5efa\u6a21\uff0c\u5e76\u4f7f\u7528\u8d8b\u52bf\u6ee4\u6ce2\u60e9\u7f5a\u6b63\u5219\u5316\u6700\u5927\u4f3c\u7136\u89e3\uff0c\u4ea7\u751f\u5e73\u6ed1\u4f46\u5c40\u90e8\u81ea\u9002\u5e94\u7684\u4e25\u91cd\u6027\u7387\u4f30\u8ba1\u3002", "result": "\u57fa\u4e8eCOVID-19\u6b7b\u4ea1\u548c\u4f4f\u9662\u6570\u636e\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u53bb\u5377\u79ef\u4f30\u8ba1\u5668\u901a\u5e38\u6bd4\u6807\u51c6\u6bd4\u7387\u65b9\u6cd5\u66f4\u51c6\u786e\uff0c\u5e76\u5bf9\u6a21\u578b\u8bef\u8bbe\u663e\u793a\u51fa\u5408\u7406\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8ba1\u7b97\u56de\u987e\u6027\u548c\u5b9e\u65f6\u4e25\u91cd\u6027\u7387\uff0c\u4e3a\u516c\u5171\u536b\u751f\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6539\u8fdb\u7684\u7edf\u8ba1\u5de5\u5177\u3002"}}
{"id": "2510.15943", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15943", "abs": "https://arxiv.org/abs/2510.15943", "authors": ["Jimmy Joseph"], "title": "Enabling Responsible, Secure and Sustainable Healthcare AI - A Strategic Framework for Clinical and Operational Impact", "comment": null, "summary": "We offer a pragmatic model to operationalize responsible, secure, and\nsustainable healthcare AI, aligning world-class technical excellence with\norganizational readiness. The framework includes five key pillars - Leadership\n& Strategy, MLOps & Technical Infrastructure, Governance & Ethics, Education &\nWorkforce Development, and Change Management & Adoption - and is intended to\noperationalize 'compliance-by-design' while delivering measurable impact. We\ndemonstrate its utility through two deployments. (A) An inpatient length of\nstay (LOS) prediction service had R^2=0.41-0.58 with validation cohorts in an\nobservational pilot (n = 3,184 encounters, 4 units, June-August 2025). Adoption\nwas 78 percent by week 6, and target units saw 5-10 percent relative declines\nin mean LOS for complex cases vs. pre-pilot baselines. (B) An AI-augmented\nradiology second-reader for lung nodules (PACS-integrated with thresholding and\nexplanation overlays) achieved high sensitivity (95 percent) and provided a\n+8.0 percentage-point lift in detection of sub-centimeter actionable findings,\nwithout slowing workflow (median report TAT 23 min, p = 0.64). Both services\nexecuted in monitored, auditable pipelines with well-defined rollback, bias\nchecks, and no evidence of security incidents. These findings indicate that by\ncombining strong MLOps and AI security with governance, education, and\nhuman-centric change, we can accelerate adoption of AI while improving security\nand outcomes. We end with limitations, generalization considerations, and a\nroadmap for scaling across varied clinical and operational use cases.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u533b\u7597AI\u64cd\u4f5c\u5316\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u5173\u952e\u652f\u67f1\uff0c\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9645\u90e8\u7f72\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5728\u786e\u4fdd\u5b89\u5168\u3001\u5408\u89c4\u7684\u540c\u65f6\u63d0\u5347\u533b\u7597\u6548\u679c\u7684\u80fd\u529b\u3002", "motivation": "\u65e8\u5728\u5c06\u4e16\u754c\u7ea7\u6280\u672f\u5353\u8d8a\u6027\u4e0e\u7ec4\u7ec7\u51c6\u5907\u5ea6\u76f8\u7ed3\u5408\uff0c\u64cd\u4f5c\u5316\u8d1f\u8d23\u4efb\u3001\u5b89\u5168\u3001\u53ef\u6301\u7eed\u7684\u533b\u7597AI\uff0c\u5b9e\u73b0'\u5408\u89c4\u8bbe\u8ba1'\u5e76\u63d0\u4f9b\u53ef\u8861\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u5305\u542b\u4e94\u4e2a\u5173\u952e\u652f\u67f1\u7684\u6846\u67b6\uff1a\u9886\u5bfc\u529b\u4e0e\u6218\u7565\u3001MLOps\u4e0e\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u3001\u6cbb\u7406\u4e0e\u4f26\u7406\u3001\u6559\u80b2\u4e0e\u52b3\u52a8\u529b\u53d1\u5c55\u3001\u53d8\u9769\u7ba1\u7406\u4e0e\u91c7\u7528\u3002\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9645\u90e8\u7f72\u6848\u4f8b\u9a8c\u8bc1\uff1a\u4f4f\u9662\u65f6\u957f\u9884\u6d4b\u670d\u52a1\u548cAI\u589e\u5f3a\u7684\u653e\u5c04\u5b66\u4e8c\u6b21\u9605\u7247\u7cfb\u7edf\u3002", "result": "\u4f4f\u9662\u65f6\u957f\u9884\u6d4b\u670d\u52a1R\u00b2=0.41-0.58\uff0c\u91c7\u7528\u738778%\uff0c\u590d\u6742\u75c5\u4f8b\u5e73\u5747\u4f4f\u9662\u65f6\u957f\u76f8\u5bf9\u4e0b\u964d5-10%\uff1bAI\u653e\u5c04\u5b66\u7cfb\u7edf\u7075\u654f\u5ea695%\uff0c\u4e9a\u5398\u7c73\u53ef\u64cd\u4f5c\u53d1\u73b0\u68c0\u6d4b\u63d0\u53478.0\u4e2a\u767e\u5206\u70b9\uff0c\u5de5\u4f5c\u6d41\u7a0b\u672a\u53d7\u5f71\u54cd\u3002\u4e24\u4e2a\u670d\u52a1\u5747\u5728\u53d7\u76d1\u63a7\u3001\u53ef\u5ba1\u8ba1\u7684\u7ba1\u9053\u4e2d\u6267\u884c\uff0c\u65e0\u5b89\u5168\u4e8b\u4ef6\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u5f3a\u5927\u7684MLOps\u548cAI\u5b89\u5168\u6027\u4e0e\u6cbb\u7406\u3001\u6559\u80b2\u3001\u4ee5\u4eba\u4e3a\u672c\u7684\u53d8\u9769\u7ba1\u7406\uff0c\u53ef\u4ee5\u5728\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u7ed3\u679c\u7684\u540c\u65f6\u52a0\u901fAI\u7684\u91c7\u7528\u3002"}}
{"id": "2510.16247", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16247", "abs": "https://arxiv.org/abs/2510.16247", "authors": ["H. Mozaffari", "A. Nahvi"], "title": "A Motivational Driver Steering Model: Task Difficulty Homeostasis From Control Theory Perspective", "comment": "Cognitive systems Research", "summary": "A general and psychologically plausible collision avoidance driver model can\nimprove transportation safety significantly. Most computational driver models\nfound in the literature have used control theory methods only, and they are not\nestablished based on psychological theories. In this paper, a unified approach\nis presented based on concepts taken from psychology and control theory. The\n\"task difficulty homeostasis theory\", a prominent motivational theory, is\ncombined with the \"Lyapunov stability method\" in control theory to present a\ngeneral and psychologically plausible model. This approach is used to model\ndriver steering behavior for collision avoidance. The performance of this model\nis measured by simulation of two collision avoidance scenarios at a wide range\nof speeds from 20 km/h to 170 km/h. The model is validated by experiments on a\ndriving simulator. The results demonstrate that the model follows human\nbehavior accurately with a mean error of 7 percent.", "AI": {"tldr": "\u7ed3\u5408\u5fc3\u7406\u5b66\u4efb\u52a1\u96be\u5ea6\u7a33\u6001\u7406\u8bba\u548c\u63a7\u5236\u8bbaLyapunov\u7a33\u5b9a\u6027\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5fc3\u7406\u5408\u7406\u78b0\u649e\u907f\u514d\u9a7e\u9a76\u5458\u6a21\u578b\uff0c\u572820-170km/h\u901f\u5ea6\u8303\u56f4\u5185\u9a8c\u8bc1\u4e86\u5176\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u9a7e\u9a76\u5458\u6a21\u578b\u5927\u591a\u4ec5\u57fa\u4e8e\u63a7\u5236\u7406\u8bba\uff0c\u7f3a\u4e4f\u5fc3\u7406\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u7b26\u5408\u5fc3\u7406\u673a\u5236\u53c8\u5b9e\u7528\u7684\u78b0\u649e\u907f\u514d\u6a21\u578b\u3002", "method": "\u5c06\u5fc3\u7406\u5b66\u4e2d\u7684\u4efb\u52a1\u96be\u5ea6\u7a33\u6001\u7406\u8bba\u4e0e\u63a7\u5236\u8bba\u4e2d\u7684Lyapunov\u7a33\u5b9a\u6027\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u6765\u5efa\u6a21\u9a7e\u9a76\u5458\u8f6c\u5411\u907f\u649e\u884c\u4e3a\u3002", "result": "\u5728\u9a7e\u9a76\u6a21\u62df\u5668\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u6a21\u578b\u5728\u591a\u79cd\u907f\u649e\u573a\u666f\u4e2d\u51c6\u786e\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\uff0c\u5e73\u5747\u8bef\u5dee\u4ec5\u4e3a7%\u3002", "conclusion": "\u8be5\u6a21\u578b\u6210\u529f\u6574\u5408\u4e86\u5fc3\u7406\u5b66\u548c\u63a7\u5236\u7406\u8bba\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u5fc3\u7406\u5408\u7406\u7684\u9a7e\u9a76\u5458\u907f\u649e\u884c\u4e3a\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2510.16969", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.16969", "abs": "https://arxiv.org/abs/2510.16969", "authors": ["Kimiya Jozani", "Nihal A. Sageer", "Hode Eldardiry", "Sait Tunc", "Esra Buyuktahtakin Toy"], "title": "Proactive and Fair Epidemic Resource Allocation Through an Integrated Supply Chain Framework: Insights from a COVID-19 Study", "comment": null, "summary": "Timely and effective decision-making is critical during epidemics to reduce\npreventable infections and deaths. This demands integrated models that jointly\ncapture disease dynamics, vaccine distribution, regional disparities, and\nbehavioral responses. However, most existing approaches decouple epidemic\nforecasting from logistics planning, hindering adaptive and regionally\nresponsive interventions. We propose a novel epidemiological-optimization\nframework that jointly models epidemic progression and a multiscale vaccine\nsupply chain. The model incorporates spatio-temporally varying effective\ninfection rates to reflect regional policy and behavioral dynamics. It supports\ncoordinated, data-driven decision-making across spatial scales through two\nformulations: a multi-objective Gini-based model and a knapsack-based model\nthat leverages regional vulnerability indicators for tractability and improved\nmitigation. To address computational complexity, we design two scalable\nheuristic decomposition algorithms inspired by the Benders decomposition. The\nmodel is validated using COVID-19 data in the U.S.. We introduce SARIMA-based\nforecasting as a novel approach for validating epidemic-optimization models\nunder data limitations. The results show that our approach can prevent more\nthan 2 million infections and 30,000 deaths in just six months while\nsignificantly improving the accessibility of vaccines in underserved regions.\nOur framework demonstrates that integrating fairness and epidemic dynamics with\nvaccine logistics leads to superior outcomes compared to traditional myopic\npolicies. Fairness improves overall efficiency in the long term by prioritizing\nthe most vulnerable populations, leading to better long-term public health\noutcomes. The model offers policymakers a scalable and operationally relevant\ntool to strengthen preparedness and ensure a more effective and equitable\nresponse to epidemics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6d41\u884c\u75c5\u5b66\u548c\u75ab\u82d7\u4f9b\u5e94\u94fe\u4f18\u5316\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u76ee\u6807Gini\u6a21\u578b\u548c\u80cc\u5305\u6a21\u578b\uff0c\u5728\u8003\u8651\u533a\u57df\u516c\u5e73\u6027\u7684\u540c\u65f6\u4f18\u5316\u75ab\u82d7\u5206\u914d\uff0c\u53ef\u663e\u8457\u51cf\u5c11\u611f\u67d3\u548c\u6b7b\u4ea1\u4eba\u6570\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u6d41\u884c\u75c5\u9884\u6d4b\u4e0e\u7269\u6d41\u89c4\u5212\u5206\u79bb\uff0c\u963b\u788d\u4e86\u9002\u5e94\u6027\u548c\u533a\u57df\u54cd\u5e94\u6027\u5e72\u9884\u3002\u9700\u8981\u6574\u5408\u75be\u75c5\u52a8\u6001\u3001\u75ab\u82d7\u5206\u914d\u3001\u533a\u57df\u5dee\u5f02\u548c\u884c\u4e3a\u54cd\u5e94\u7684\u7efc\u5408\u6a21\u578b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6d41\u884c\u75c5\u5b66-\u4f18\u5316\u6846\u67b6\uff0c\u8054\u5408\u5efa\u6a21\u75ab\u60c5\u8fdb\u5c55\u548c\u591a\u5c3a\u5ea6\u75ab\u82d7\u4f9b\u5e94\u94fe\u3002\u91c7\u7528\u65f6\u7a7a\u53d8\u5316\u7684\u6709\u6548\u611f\u67d3\u7387\u53cd\u6620\u533a\u57df\u653f\u7b56\u548c\u884c\u4e3a\u52a8\u6001\uff0c\u8bbe\u8ba1\u4e86\u4e24\u79cd\u53ef\u6269\u5c55\u7684\u542f\u53d1\u5f0f\u5206\u89e3\u7b97\u6cd5\u3002", "result": "\u4f7f\u7528\u7f8e\u56fdCOVID-19\u6570\u636e\u9a8c\u8bc1\uff0c\u57286\u4e2a\u6708\u5185\u53ef\u9884\u9632\u8d85\u8fc7200\u4e07\u611f\u67d3\u548c3\u4e07\u6b7b\u4ea1\uff0c\u663e\u8457\u63d0\u9ad8\u670d\u52a1\u4e0d\u8db3\u5730\u533a\u7684\u75ab\u82d7\u53ef\u53ca\u6027\u3002", "conclusion": "\u6574\u5408\u516c\u5e73\u6027\u3001\u6d41\u884c\u75c5\u52a8\u6001\u548c\u75ab\u82d7\u7269\u6d41\u76f8\u6bd4\u4f20\u7edf\u77ed\u89c6\u653f\u7b56\u80fd\u5e26\u6765\u66f4\u4f18\u7ed3\u679c\uff0c\u516c\u5e73\u6027\u901a\u8fc7\u4f18\u5148\u8003\u8651\u6700\u8106\u5f31\u4eba\u7fa4\u5728\u957f\u671f\u5185\u63d0\u9ad8\u6574\u4f53\u6548\u7387\u3002"}}
{"id": "2510.16537", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.16537", "abs": "https://arxiv.org/abs/2510.16537", "authors": ["Ricardo Alonzo Fern\u00e1ndez Salguero"], "title": "The Crisis Simulator for Bolivia (KISr-p): An Empirically Grounded Modeling Framework", "comment": null, "summary": "This document presents a detailed technical report of the ``Crisis Simulator\nfor Bolivia (KISr-p),'' a quarterly stochastic model designed to evaluate the\nimpact of various macroeconomic policy strategies in an environment of high\nuncertainty and structural constraints. Unlike standard general equilibrium\nframeworks, this simulator is grounded in the consolidated empirical findings\nof a vast collection of meta-analyses, adopting the theoretical architecture of\na Keynesian Intertemporal Synthesis (KIS) with a Constant Elasticity of\nSubstitution (KIS-CES) production function. The calibration of each model block\n-- real, fiscal, monetary, external, labor, and distributional -- is described\nin detail, with parameters justified by quantitative evidence on the hierarchy\nof fiscal multipliers (Gechert and Rannenberg, 2018), the complementarity of\nproduction factors (Gechert et al., 2022), monopsony power in the labor market\n(Sokolova and S{\\o}rensen, 2021), and the dynamics of exchange rate and\ninterest-rate pass-through. The model integrates these empirical regularities\nto generate non-linear dynamics such as state-dependent multipliers, asymmetric\nresponses to shocks, and business-cycle phase interactions. Simulation results\nhighlight the trade-offs between fiscal adjustment, external financing, debt\nrestructuring, and structural reforms -- such as aggressive spending\nreallocation and targeted public investment. Scenarios show that pragmatic\npolicy approaches that prioritize the \\textit{composition} of spending over its\naggregate level and that recognize institutional frictions yield superior\nmacroeconomic and welfare outcomes compared to doctrinaire, one-size-fits-all\nprescriptions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u73bb\u5229\u7ef4\u4e9a\u5371\u673a\u6a21\u62df\u5668(KISr-p)\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u51ef\u6069\u65af\u8de8\u671f\u7efc\u5408\u7406\u8bba(KIS-CES)\u7684\u5b63\u5ea6\u968f\u673a\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u9ad8\u4e0d\u786e\u5b9a\u6027\u548c\u7ed3\u6784\u6027\u7ea6\u675f\u4e0b\u7684\u5b8f\u89c2\u7ecf\u6d4e\u653f\u7b56\u5f71\u54cd\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u8bc4\u4f30\u9ad8\u4e0d\u786e\u5b9a\u6027\u548c\u7ed3\u6784\u6027\u7ea6\u675f\u73af\u5883\u4e0b\u5b8f\u89c2\u7ecf\u6d4e\u653f\u7b56\u5f71\u54cd\u7684\u6a21\u62df\u5668\uff0c\u4e0d\u540c\u4e8e\u6807\u51c6\u7684\u4e00\u822c\u5747\u8861\u6846\u67b6\uff0c\u800c\u662f\u57fa\u4e8e\u5927\u91cf\u5143\u5206\u6790\u7684\u5b9e\u8bc1\u53d1\u73b0\u3002", "method": "\u91c7\u7528\u51ef\u6069\u65af\u8de8\u671f\u7efc\u5408(KIS)\u7406\u8bba\u67b6\u6784\u548cCES\u751f\u4ea7\u51fd\u6570\uff0c\u8be6\u7ec6\u6821\u51c6\u4e86\u5b9e\u9645\u3001\u8d22\u653f\u3001\u8d27\u5e01\u3001\u5916\u90e8\u3001\u52b3\u52a8\u529b\u548c\u5206\u914d\u7b49\u6a21\u578b\u6a21\u5757\uff0c\u53c2\u6570\u57fa\u4e8e\u8d22\u653f\u4e58\u6570\u5c42\u7ea7\u3001\u751f\u4ea7\u8981\u7d20\u4e92\u8865\u6027\u3001\u52b3\u52a8\u529b\u5e02\u573a\u5784\u65ad\u529b\u91cf\u7b49\u5b9e\u8bc1\u8bc1\u636e\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\u4e86\u8d22\u653f\u8c03\u6574\u3001\u5916\u90e8\u878d\u8d44\u3001\u503a\u52a1\u91cd\u7ec4\u548c\u7ed3\u6784\u6027\u6539\u9769\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002\u4f18\u5148\u8003\u8651\u652f\u51fa\u6784\u6210\u800c\u975e\u603b\u91cf\u6c34\u5e73\u5e76\u627f\u8ba4\u5236\u5ea6\u6469\u64e6\u7684\u52a1\u5b9e\u653f\u7b56\u65b9\u6cd5\uff0c\u76f8\u6bd4\u6559\u6761\u5f0f\u7684\u4e00\u5200\u5207\u65b9\u6848\u80fd\u4ea7\u751f\u66f4\u4f18\u7684\u5b8f\u89c2\u7ecf\u6d4e\u548c\u798f\u5229\u7ed3\u679c\u3002", "conclusion": "\u52a1\u5b9e\u653f\u7b56\u65b9\u6cd5\u5728\u8003\u8651\u652f\u51fa\u6784\u6210\u548c\u5236\u5ea6\u6469\u64e6\u65f6\uff0c\u80fd\u591f\u4ea7\u751f\u6bd4\u6559\u6761\u5f0f\u65b9\u6848\u66f4\u4f18\u7684\u5b8f\u89c2\u7ecf\u6d4e\u548c\u798f\u5229\u7ed3\u679c\u3002"}}
{"id": "2510.16244", "categories": ["stat.AP", "62R10, 91D20"], "pdf": "https://arxiv.org/pdf/2510.16244", "abs": "https://arxiv.org/abs/2510.16244", "authors": ["Zhe Michelle Dong", "Han Lin Shang", "Francis Hui", "Aaron Bruhn"], "title": "A Compositional Approach to Modelling Cause-specific Mortality with Zero Counts", "comment": "42 pages, 14 figures, 5 tables", "summary": "Understanding and forecasting mortality by cause is an essential branch of\nactuarial science, with wide-ranging implications for decision-makers in public\npolicy and industry. To accurately capture trends in cause-specific mortality,\nit is critical to consider dependencies between causes of death and produce\nforecasts by age and cause coherent with aggregate mortality forecasts. One way\nto achieve these aims is to model cause-specific deaths using compositional\ndata analysis (CODA), treating the density of deaths by age and cause as a set\nof dependent, non-negative values that sum to one. A major drawback of standard\nCODA methods is the challenge of zero values, which frequently occur in\ncause-of-death mortality modelling. Thus, we propose using a compositional\npower transformation, the $\\alpha$-transformation, to model cause-specific\nlife-table death counts. The $\\alpha$-transformation offers a statistically\nrigorous approach to handling zero value subgroups in CODA compared to\n\\emph{ad-hoc} techniques: adding an arbitrarily small amount. We illustrate the\n$\\alpha$-transformation on England and Wales, and US death counts by cause from\nthe Human Cause-of-Death database, for cardiovascular-related causes of death.\nResults demonstrate the $\\alpha$-transformation improves forecast accuracy of\ncause-specific life-table death counts compared with log-ratio-based CODA\ntransformations. The forecasts suggest declines in proportions of deaths from\nmajor cardiovascular causes (myocardial infarction and other ischemic heart\ndiseases (IHD)).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u03b1-\u53d8\u6362\u6765\u5904\u7406\u6b7b\u4ea1\u7387\u5efa\u6a21\u4e2d\u7684\u96f6\u503c\u95ee\u9898\uff0c\u6539\u8fdb\u4e86\u57fa\u4e8e\u5bf9\u6570\u6bd4\u7684\u6807\u51c6\u7ec4\u5408\u6570\u636e\u5206\u6790\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u7279\u5b9a\u539f\u56e0\u6b7b\u4ea1\u7387\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u7406\u89e3\u548c\u9884\u6d4b\u7279\u5b9a\u539f\u56e0\u6b7b\u4ea1\u7387\u5bf9\u7cbe\u7b97\u79d1\u5b66\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6807\u51c6\u7ec4\u5408\u6570\u636e\u5206\u6790\u65b9\u6cd5\u5728\u5904\u7406\u96f6\u503c\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u66f4\u4e25\u8c28\u7684\u7edf\u8ba1\u65b9\u6cd5\u6765\u5904\u7406\u96f6\u503c\u5b50\u7ec4\u3002", "method": "\u4f7f\u7528\u7ec4\u5408\u5e42\u53d8\u6362\uff08\u03b1-\u53d8\u6362\uff09\u6765\u5efa\u6a21\u7279\u5b9a\u539f\u56e0\u751f\u547d\u8868\u6b7b\u4ea1\u8ba1\u6570\uff0c\u4e3a\u7ec4\u5408\u6570\u636e\u5206\u6790\u4e2d\u7684\u96f6\u503c\u5b50\u7ec4\u63d0\u4f9b\u7edf\u8ba1\u4e25\u8c28\u7684\u65b9\u6cd5\u3002", "result": "\u03b1-\u53d8\u6362\u76f8\u6bd4\u57fa\u4e8e\u5bf9\u6570\u6bd4\u7684\u7ec4\u5408\u6570\u636e\u53d8\u6362\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u7279\u5b9a\u539f\u56e0\u751f\u547d\u8868\u6b7b\u4ea1\u8ba1\u6570\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u9884\u6d4b\u663e\u793a\u4e3b\u8981\u5fc3\u8840\u7ba1\u539f\u56e0\uff08\u5fc3\u808c\u6897\u6b7b\u548c\u5176\u4ed6\u7f3a\u8840\u6027\u5fc3\u810f\u75c5\uff09\u7684\u6b7b\u4ea1\u6bd4\u4f8b\u4e0b\u964d\u3002", "conclusion": "\u03b1-\u53d8\u6362\u4e3a\u5904\u7406\u6b7b\u4ea1\u7387\u5efa\u6a21\u4e2d\u7684\u96f6\u503c\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u4ea7\u751f\u66f4\u51c6\u786e\u7684\u7279\u5b9a\u539f\u56e0\u6b7b\u4ea1\u7387\u9884\u6d4b\uff0c\u5bf9\u516c\u5171\u653f\u7b56\u548c\u884c\u4e1a\u51b3\u7b56\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.15951", "categories": ["cs.CY", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15951", "abs": "https://arxiv.org/abs/2510.15951", "authors": ["Kaitlyn Zhou", "Kristina Gligori\u0107", "Myra Cheng", "Michelle S. Lam", "Vyoma Raman", "Boluwatife Aminu", "Caeley Woo", "Michael Brockman", "Hannah Cha", "Dan Jurafsky"], "title": "Attention to Non-Adopters", "comment": null, "summary": "Although language model-based chat systems are increasingly used in daily\nlife, most Americans remain non-adopters of chat-based LLMs -- as of June 2025,\n66% had never used ChatGPT. At the same time, LLM development and evaluation\nrely mainly on data from adopters (e.g., logs, preference data), focusing on\nthe needs and tasks for a limited demographic group of adopters in terms of\ngeographic location, education, and gender. In this position paper, we argue\nthat incorporating non-adopter perspectives is essential for developing broadly\nuseful and capable LLMs. We contend that relying on methods that focus\nprimarily on adopters will risk missing a range of tasks and needs prioritized\nby non-adopters, entrenching inequalities in who benefits from LLMs, and\ncreating oversights in model development and evaluation. To illustrate this\nclaim, we conduct case studies with non-adopters and show: how non-adopter\nneeds diverge from those of current users, how non-adopter needs point us\ntowards novel reasoning tasks, and how to systematically integrate non-adopter\nneeds via human-centered methods.", "AI": {"tldr": "\u5c3d\u7ba1\u8bed\u8a00\u6a21\u578b\u804a\u5929\u7cfb\u7edf\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5927\u591a\u6570\u7f8e\u56fd\u4eba\u4ecd\u672a\u91c7\u7528\u804a\u5929\u5f0fLLM\u3002\u672c\u6587\u4e3b\u5f20\u5c06\u975e\u91c7\u7528\u8005\u89c6\u89d2\u7eb3\u5165LLM\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u907f\u514d\u52a0\u5267\u4e0d\u5e73\u7b49\u548c\u5f00\u53d1\u76f2\u70b9\u3002", "motivation": "\u5f53\u524dLLM\u5f00\u53d1\u548c\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u91c7\u7528\u8005\u6570\u636e\uff0c\u5ffd\u89c6\u4e86\u5360\u4eba\u53e3\u591a\u6570\u7684\u975e\u91c7\u7528\u8005\u7fa4\u4f53\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u6ee1\u8db3\u5e7f\u6cdb\u7528\u6237\u9700\u6c42\u5e76\u52a0\u5267\u6280\u672f\u4e0d\u5e73\u7b49\u3002", "method": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5206\u6790\u975e\u91c7\u7528\u8005\u7684\u9700\u6c42\uff0c\u5c55\u793a\u5176\u4e0e\u73b0\u6709\u7528\u6237\u9700\u6c42\u7684\u5dee\u5f02\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u7cfb\u7edf\u6574\u5408\u975e\u91c7\u7528\u8005\u9700\u6c42\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u975e\u91c7\u7528\u8005\u7684\u9700\u6c42\u4e0e\u73b0\u6709\u7528\u6237\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8fd9\u4e9b\u9700\u6c42\u6307\u5411\u4e86\u65b0\u9896\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u4e3aLLM\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002", "conclusion": "\u5fc5\u987b\u5c06\u975e\u91c7\u7528\u8005\u89c6\u89d2\u7eb3\u5165LLM\u5f00\u53d1\u8fc7\u7a0b\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u907f\u514d\u6280\u672f\u4e0d\u5e73\u7b49\uff0c\u5e76\u53d1\u73b0\u65b0\u7684\u4efb\u52a1\u7c7b\u578b\u3002"}}
{"id": "2510.16262", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.16262", "abs": "https://arxiv.org/abs/2510.16262", "authors": ["Jose Guajardo", "Ali Niknejad"], "title": "Spatial-to-Spectral Harmonic-Modulated Arrays for 6G Multi-Beam MIMO", "comment": null, "summary": "This article presents an overview and analysis of spatial-to-spectral\nharmonic-modulated arrays (SHAs). Compared to traditional analog or digital\nbeamforming arrays, SHAs enable concurrent multi-beamforming without requiring\nsubstantial hardware replication. SHAs replace the need for hardware\nreplication with frequency-domain multiplexing. Furthermore, SHAs have the\npotential to become key contributors to future 6G networks by enabling scalable\nmulti-user communications, joint communication and sensing, and spatial\ninterference mitigation. In addition, an analysis of the SHA's\nharmonic-modulation waveform and its effects on gain, noise and bandwidth is\npresented. A comb-like modulation waveform for SHAs that minimizes spectral\ninefficiency is proposed. Further, an analysis of the SHA's capability to\nindependently steer multiple beams is presented. This capability is quantified\nin terms of the SHA's spatial-to-spectral degrees of freedom. Lastly, this work\nintroduces a novel SHA architecture that provides three spatial-to-spectral\ndegrees of freedom with minimal hardware replication.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7a7a\u95f4-\u9891\u8c31\u8c10\u6ce2\u8c03\u5236\u9635\u5217(SHAs)\uff0c\u8fd9\u662f\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u5e76\u53d1\u591a\u6ce2\u675f\u6210\u5f62\u800c\u65e0\u9700\u5927\u91cf\u786c\u4ef6\u590d\u5236\u7684\u9635\u5217\u6280\u672f\uff0c\u901a\u8fc7\u9891\u57df\u590d\u7528\u66ff\u4ee3\u786c\u4ef6\u590d\u5236\uff0c\u6709\u671b\u6210\u4e3a6G\u7f51\u7edc\u7684\u5173\u952e\u6280\u672f\u3002", "motivation": "\u4f20\u7edf\u6a21\u62df\u6216\u6570\u5b57\u6ce2\u675f\u6210\u5f62\u9635\u5217\u9700\u8981\u5927\u91cf\u786c\u4ef6\u590d\u5236\u6765\u5b9e\u73b0\u591a\u6ce2\u675f\u6210\u5f62\uff0cSHAs\u65e8\u5728\u901a\u8fc7\u9891\u57df\u590d\u7528\u6280\u672f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4e3a\u672a\u67656G\u7f51\u7edc\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u591a\u7528\u6237\u901a\u4fe1\u3001\u8054\u5408\u901a\u4fe1\u4e0e\u611f\u77e5\u4ee5\u53ca\u7a7a\u95f4\u5e72\u6270\u6291\u5236\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u8c10\u6ce2\u8c03\u5236\u6ce2\u5f62\u5206\u6790\u53ca\u5176\u5bf9\u589e\u76ca\u3001\u566a\u58f0\u548c\u5e26\u5bbd\u7684\u5f71\u54cd\uff0c\u8bbe\u8ba1\u4e86\u6700\u5c0f\u5316\u9891\u8c31\u4f4e\u6548\u7684\u68b3\u72b6\u8c03\u5236\u6ce2\u5f62\uff0c\u5206\u6790\u4e86SHAs\u72ec\u7acb\u63a7\u5236\u591a\u6ce2\u675f\u7684\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u4e86\u5177\u6709\u4e09\u4e2a\u7a7a\u95f4-\u9891\u8c31\u81ea\u7531\u5ea6\u7684\u65b0\u578bSHA\u67b6\u6784\u3002", "result": "SHAs\u80fd\u591f\u5b9e\u73b0\u5e76\u53d1\u591a\u6ce2\u675f\u6210\u5f62\u800c\u65e0\u9700\u5927\u91cf\u786c\u4ef6\u590d\u5236\uff0c\u901a\u8fc7\u9891\u57df\u590d\u7528\u6280\u672f\u6709\u6548\u5de5\u4f5c\uff0c\u63d0\u51fa\u7684\u65b0\u578bSHA\u67b6\u6784\u4ee5\u6700\u5c0f\u786c\u4ef6\u590d\u5236\u63d0\u4f9b\u4e09\u4e2a\u7a7a\u95f4-\u9891\u8c31\u81ea\u7531\u5ea6\u3002", "conclusion": "SHAs\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u6280\u672f\uff0c\u901a\u8fc7\u7a7a\u95f4-\u9891\u8c31\u8c10\u6ce2\u8c03\u5236\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u6ce2\u675f\u6210\u5f62\uff0c\u4e3a\u672a\u67656G\u7f51\u7edc\u7684\u901a\u4fe1\u548c\u611f\u77e5\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2510.17153", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17153", "abs": "https://arxiv.org/abs/2510.17153", "authors": ["Hyunjin Choo", "Fanchen Bu", "Hyunjin Hwang", "Young-Gyu Yoon", "Kijung Shin"], "title": "HyperSearch: Prediction of New Hyperedges through Unconstrained yet Efficient Search", "comment": "IEEE International Conference on Data Mining (ICDM) 2025", "summary": "Higher-order interactions (HOIs) in complex systems, such as scientific\ncollaborations, multi-protein complexes, and multi-user communications, are\ncommonly modeled as hypergraphs, where each hyperedge (i.e., a subset of nodes)\nrepresents an HOI among the nodes. Given a hypergraph, hyperedge prediction\naims to identify hyperedges that are either missing or likely to form in the\nfuture, and it has broad applications, including recommending interest-based\nsocial groups, predicting collaborations, and uncovering functional complexes\nin biological systems. However, the vast search space of hyperedge candidates\n(i.e., all possible subsets of nodes) poses a significant computational\nchallenge, making naive exhaustive search infeasible. As a result, existing\napproaches rely on either heuristic sampling to obtain constrained candidate\nsets or ungrounded assumptions on hypergraph structure to select promising\nhyperedges.\n  In this work, we propose HyperSearch, a search-based algorithm for hyperedge\nprediction that efficiently evaluates unconstrained candidate sets, by\nincorporating two key components: (1) an empirically grounded scoring function\nderived from observations in real-world hypergraphs and (2) an efficient search\nmechanism, where we derive and use an anti-monotonic upper bound of the\noriginal scoring function (which is not antimonotonic) to prune the search\nspace. This pruning comes with theoretical guarantees, ensuring that discarded\ncandidates are never better than the kept ones w.r.t. the original scoring\nfunction. In extensive experiments on 10 real-world hypergraphs across five\ndomains, HyperSearch consistently outperforms state-of-the-art baselines,\nachieving higher accuracy in predicting new (i.e., not in the training set)\nhyperedges.", "AI": {"tldr": "\u63d0\u51fa\u4e86HyperSearch\u7b97\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u9884\u6d4b\u8d85\u56fe\u4e2d\u7684\u8d85\u8fb9\uff0c\u901a\u8fc7\u7ed3\u5408\u7ecf\u9a8c\u6027\u8bc4\u5206\u51fd\u6570\u548c\u9ad8\u6548\u641c\u7d22\u673a\u5236\uff0c\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u8d85\u56fe\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8d85\u8fb9\u9884\u6d4b\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5de8\u5927\u7684\u641c\u7d22\u7a7a\u95f4\u4f7f\u5f97\u7a77\u4e3e\u641c\u7d22\u4e0d\u53ef\u884c\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u91c7\u6837\u6216\u65e0\u6839\u636e\u7684\u7ed3\u6784\u5047\u8bbe\u3002", "method": "\u63d0\u51faHyperSearch\u7b97\u6cd5\uff0c\u5305\u542b\uff1a(1)\u57fa\u4e8e\u771f\u5b9e\u8d85\u56fe\u89c2\u5bdf\u7684\u7ecf\u9a8c\u6027\u8bc4\u5206\u51fd\u6570\uff1b(2)\u4f7f\u7528\u539f\u59cb\u8bc4\u5206\u51fd\u6570\u7684\u53cd\u5355\u8c03\u4e0a\u754c\u8fdb\u884c\u526a\u679d\u7684\u9ad8\u6548\u641c\u7d22\u673a\u5236\u3002", "result": "\u57285\u4e2a\u9886\u57df\u768410\u4e2a\u771f\u5b9e\u4e16\u754c\u8d85\u56fe\u4e0a\uff0cHyperSearch\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9884\u6d4b\u65b0\u8d85\u8fb9\u65b9\u9762\u8fbe\u5230\u66f4\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "HyperSearch\u901a\u8fc7\u7406\u8bba\u4fdd\u8bc1\u7684\u526a\u679d\u7b56\u7565\u548c\u5b9e\u8bc1\u57fa\u7840\u8bc4\u5206\u51fd\u6570\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8d85\u8fb9\u9884\u6d4b\u4e2d\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.16626", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.16626", "abs": "https://arxiv.org/abs/2510.16626", "authors": ["Riddhi Kalsi"], "title": "Evaluating the Public Pay Gap: A Comparison of Public and Private Sector Wages in France", "comment": null, "summary": "This paper resolves the empirical puzzle in the public-private wage\nliterature: why studies using similar data reach contradictory conclusions\nabout wage premiums and penalties. Utilizing rich French administrative panel\ndata (2012-2019), this study has two main contributions: first, it presents a\nset of new, intuitive yet previously undocumented stylized facts about wage\ndynamics, sectoral mobility, and gender differences across sectors. The results\nreveal that the modest hourly wage gaps conceal substantial disparities in\nlifetime earnings and employment stability. Women, in particular, gain a\nsignificant lifetime earnings advantage in the public sector, driven by higher\nretention, better-compensated part-time work, and more equitable annual hours\ncompared to the private sector, where gender gaps remain larger, especially for\nthose with higher education. In contrast, highly educated men experience a\nlifetime penalty in public employment due to rigid wage structures. By flexibly\nmodeling sectoral transitions, transitions into and out of employment, and\nearnings heterogeneity using an Expectation-Maximization algorithm, this study\nshows that both premiums and penalties depend systematically on gender,\neducation, and labor market experience. The analysis reveals that significant\nunobserved heterogeneity remains in wage dynamics. These findings unify\nprevailing narratives by providing a comprehensive, descriptive account of\nsectoral differences in transitions, part-time work and wages by gender.", "AI": {"tldr": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u516c\u5171-\u79c1\u8425\u90e8\u95e8\u5de5\u8d44\u6587\u732e\u4e2d\u7684\u5b9e\u8bc1\u96be\u9898\uff0c\u901a\u8fc7\u6cd5\u56fd\u884c\u653f\u9762\u677f\u6570\u636e\u63ed\u793a\u4e86\u770b\u4f3c\u76f8\u4f3c\u7684\u5de5\u8d44\u5dee\u8ddd\u80cc\u540e\u9690\u85cf\u7684\u7ec8\u8eab\u6536\u5165\u548c\u5de5\u4f5c\u7a33\u5b9a\u6027\u5dee\u5f02\uff0c\u7edf\u4e00\u4e86\u5148\u524d\u77db\u76fe\u7684\u7814\u7a76\u7ed3\u8bba\u3002", "motivation": "\u89e3\u51b3\u516c\u5171-\u79c1\u8425\u90e8\u95e8\u5de5\u8d44\u6587\u732e\u4e2d\u7684\u5b9e\u8bc1\u77db\u76fe\uff0c\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4f7f\u7528\u76f8\u4f3c\u6570\u636e\u7684\u7814\u7a76\u4f1a\u5f97\u51fa\u5173\u4e8e\u5de5\u8d44\u6ea2\u4ef7\u548c\u60e9\u7f5a\u7684\u76f8\u53cd\u7ed3\u8bba\u3002", "method": "\u4f7f\u7528\u6cd5\u56fd\u884c\u653f\u9762\u677f\u6570\u636e\uff082012-2019\uff09\uff0c\u901a\u8fc7\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u7075\u6d3b\u5efa\u6a21\u90e8\u95e8\u8f6c\u6362\u3001\u5c31\u4e1a\u8fdb\u51fa\u8f6c\u6362\u548c\u6536\u5165\u5f02\u8d28\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u5973\u6027\u5728\u516c\u5171\u90e8\u95e8\u83b7\u5f97\u663e\u8457\u7684\u7ec8\u8eab\u6536\u5165\u4f18\u52bf\uff0c\u800c\u9ad8\u5b66\u5386\u7537\u6027\u5728\u516c\u5171\u90e8\u95e8\u7ecf\u5386\u7ec8\u8eab\u60e9\u7f5a\uff1b\u5c0f\u65f6\u5de5\u8d44\u5dee\u8ddd\u63a9\u76d6\u4e86\u7ec8\u8eab\u6536\u5165\u548c\u5de5\u4f5c\u7a33\u5b9a\u6027\u7684\u663e\u8457\u5dee\u5f02\uff1b\u5de5\u8d44\u6ea2\u4ef7\u548c\u60e9\u7f5a\u7cfb\u7edf\u6027\u4f9d\u8d56\u4e8e\u6027\u522b\u3001\u6559\u80b2\u548c\u5de5\u4f5c\u7ecf\u9a8c\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u63d0\u4f9b\u90e8\u95e8\u5dee\u5f02\u7684\u5168\u9762\u63cf\u8ff0\u6027\u5206\u6790\uff0c\u7edf\u4e00\u4e86\u73b0\u6709\u7814\u7a76\u53d9\u4e8b\uff0c\u63ed\u793a\u4e86\u5de5\u8d44\u52a8\u6001\u4e2d\u663e\u8457\u7684\u672a\u89c2\u5bdf\u5f02\u8d28\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u7ec8\u8eab\u6536\u5165\u89c6\u89d2\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.16266", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.16266", "abs": "https://arxiv.org/abs/2510.16266", "authors": ["Karim Barigou", "Melanie Patten", "Kenneth Q. Zhou"], "title": "Mortality Modeling and Forecasting with the Actuaries Climate Index", "comment": null, "summary": "Climate change poses increasing challenges for mortality modeling and\nunderscores the need to integrate climate-related variables into mortality\nforecasting. This study introduces a two-step approach that incorporates\nclimate information from the Actuaries Climate Index (ACI) into mortality\nmodels. In the first step, we model region-specific seasonal mortality dynamics\nusing the Lee-Carter model with SARIMA processes, a cosine-sine decomposition,\nand a cyclic spline-based function. In the second step, residual deviations\nfrom the baseline model are explained by ACI components using Generalized\nLinear Models, Generalized Additive Models, and Extreme Gradient Boosting. To\nfurther capture the dependence between mortality and climate, we develop a\nSARIMA-Copula forecasting approach linking mortality period effects with\ntemperature extremes. Our results show that incorporating ACI components\nsystematically enhances out-of-sample accuracy, underscoring the value of\nintegrating climate-related variables into stochastic mortality modeling. The\nproposed framework offers actuaries and policymakers a practical tool for\nanticipating and managing climate-related mortality risks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6c14\u5019\u6307\u6570(ACI)\u7eb3\u5165\u6b7b\u4ea1\u7387\u6a21\u578b\u7684\u4e24\u6b65\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u4f20\u7edf\u6b7b\u4ea1\u7387\u6a21\u578b\u548c\u6c14\u5019\u53d8\u91cf\uff0c\u63d0\u9ad8\u4e86\u6b7b\u4ea1\u7387\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u7ed9\u6b7b\u4ea1\u7387\u5efa\u6a21\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u5c06\u6c14\u5019\u76f8\u5173\u53d8\u91cf\u6574\u5408\u5230\u6b7b\u4ea1\u7387\u9884\u6d4b\u4e2d\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u5e94\u5bf9\u6c14\u5019\u76f8\u5173\u7684\u6b7b\u4ea1\u98ce\u9669\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u7b2c\u4e00\u6b65\u4f7f\u7528Lee-Carter\u6a21\u578b\u7ed3\u5408SARIMA\u8fc7\u7a0b\u3001\u4f59\u5f26-\u6b63\u5f26\u5206\u89e3\u548c\u5faa\u73af\u6837\u6761\u51fd\u6570\u5efa\u6a21\u5b63\u8282\u6027\u6b7b\u4ea1\u7387\u52a8\u6001\uff1b\u7b2c\u4e8c\u6b65\u4f7f\u7528GLM\u3001GAM\u548cXGBoost\u6a21\u578b\u89e3\u91ca\u57fa\u7ebf\u6a21\u578b\u7684\u6b8b\u5dee\u504f\u5dee\u4e0eACI\u7ec4\u4ef6\u7684\u5173\u7cfb\uff0c\u5e76\u5f00\u53d1SARIMA-Copula\u9884\u6d4b\u65b9\u6cd5\u8fde\u63a5\u6b7b\u4ea1\u7387\u5468\u671f\u6548\u5e94\u4e0e\u6781\u7aef\u6e29\u5ea6\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u6574\u5408ACI\u7ec4\u4ef6\u7cfb\u7edf\u6027\u5730\u63d0\u9ad8\u4e86\u6837\u672c\u5916\u9884\u6d4b\u7cbe\u5ea6\uff0c\u8bc1\u660e\u4e86\u5c06\u6c14\u5019\u76f8\u5173\u53d8\u91cf\u7eb3\u5165\u968f\u673a\u6b7b\u4ea1\u7387\u5efa\u6a21\u7684\u4ef7\u503c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7cbe\u7b97\u5e08\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u5de5\u5177\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u7ba1\u7406\u6c14\u5019\u76f8\u5173\u7684\u6b7b\u4ea1\u98ce\u9669\u3002"}}
{"id": "2510.16019", "categories": ["cs.CY", "I.2"], "pdf": "https://arxiv.org/pdf/2510.16019", "abs": "https://arxiv.org/abs/2510.16019", "authors": ["M\u00e1rton Benedek", "Bal\u00e1zs R. Sziklai"], "title": "Impact of AI Tools on Learning Outcomes: Decreasing Knowledge and Over-Reliance", "comment": null, "summary": "Students at all levels of education are increasingly relying on generative\nartificial intelligence (AI) tools to complete assignments and achieve higher\nexam scores. However, it remains unclear how this reliance affects their\nmotivation, their genuine understanding of the material, and the extent to\nwhich it substitutes for the process of knowledge acquisition. To investigate\nthe impact of generative AI on learning outcomes, an experiment was conducted\nat Corvinus University of Budapest. In an operations research class, students\nwere randomly assigned into two groups: one was permitted to use AI tools\nduring classes and examinations, while the other was not. To ensure fairness, a\ncompensation mechanism was introduced: students in the lower-performing group\nreceived point adjustments until the average performance of the two groups was\nequalized. Despite the organizers' best efforts to explain the design and to\ncreate equal opportunities for all participants, many students perceived the\nexperiment as a major disruption. Although the experiment was approved by every\nrelevant university authority -- including the Ethics Board, the Head of\nDepartment, the Program Director, and the Student Council -- students escalated\ntheir concerns to the media and eventually to the State Secretary for Higher\nEducation of Hungary. As a result, the experiment had to be substantially\nrevised before completion: on the final exam the test group was merged with the\ncontrol group. Still, the data allowed us to draw decisive conclusions\nregarding the students' learning habits. Uncontrolled use of AI tools leads to\ndisengaged students and low understanding of material. The extreme reactions of\nthe students proved even more revealing than the data collected: generative AI\ntools have already become indispensable for students, raising fundamental\nquestions about the validity of their learning process.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e86\u751f\u6210\u5f0fAI\u5de5\u5177\u5bf9\u5b66\u751f\u5b66\u4e60\u6210\u679c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e0d\u53d7\u63a7\u5236\u7684AI\u4f7f\u7528\u4f1a\u5bfc\u81f4\u5b66\u751f\u53c2\u4e0e\u5ea6\u4f4e\u3001\u5bf9\u6750\u6599\u7406\u89e3\u4e0d\u8db3\uff0c\u4e14AI\u5de5\u5177\u5df2\u6210\u4e3a\u5b66\u751f\u4e0d\u53ef\u6216\u7f3a\u7684\u5b66\u4e60\u4f9d\u8d56\u3002", "motivation": "\u968f\u7740\u5b66\u751f\u5728\u5404\u6559\u80b2\u5c42\u7ea7\u8d8a\u6765\u8d8a\u4f9d\u8d56\u751f\u6210\u5f0fAI\u5de5\u5177\u5b8c\u6210\u4f5c\u4e1a\u548c\u8003\u8bd5\uff0c\u9700\u8981\u4e86\u89e3\u8fd9\u79cd\u4f9d\u8d56\u5982\u4f55\u5f71\u54cd\u4ed6\u4eec\u7684\u5b66\u4e60\u52a8\u673a\u3001\u771f\u6b63\u7406\u89e3\u7a0b\u5ea6\u4ee5\u53ca\u77e5\u8bc6\u83b7\u53d6\u8fc7\u7a0b\u3002", "method": "\u5728\u5e03\u8fbe\u4f69\u65af\u79d1\u7ef4\u52aa\u65af\u5927\u5b66\u7684\u8fd0\u7b79\u5b66\u8bfe\u7a0b\u4e2d\u8fdb\u884c\u968f\u673a\u5bf9\u7167\u5b9e\u9a8c\uff0c\u5c06\u5b66\u751f\u5206\u4e3a\u5141\u8bb8\u4f7f\u7528AI\u5de5\u5177\u7ec4\u548c\u4e0d\u5141\u8bb8\u4f7f\u7528AI\u5de5\u5177\u7ec4\uff0c\u5e76\u5f15\u5165\u8865\u507f\u673a\u5236\u786e\u4fdd\u516c\u5e73\u6027\u3002", "result": "\u5c3d\u7ba1\u5b9e\u9a8c\u56e0\u5b66\u751f\u5f3a\u70c8\u53cd\u5bf9\u800c\u88ab\u8feb\u4fee\u6539\uff0c\u4f46\u6570\u636e\u663e\u793a\u4e0d\u53d7\u63a7\u5236\u7684AI\u4f7f\u7528\u5bfc\u81f4\u5b66\u751f\u53c2\u4e0e\u5ea6\u4f4e\u3001\u5bf9\u6750\u6599\u7406\u89e3\u4e0d\u8db3\u3002\u5b66\u751f\u7684\u6781\u7aef\u53cd\u5e94\u8868\u660eAI\u5de5\u5177\u5df2\u6210\u4e3a\u4ed6\u4eec\u4e0d\u53ef\u6216\u7f3a\u7684\u5b66\u4e60\u4f9d\u8d56\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5de5\u5177\u5df2\u7ecf\u6df1\u5ea6\u878d\u5165\u5b66\u751f\u5b66\u4e60\u8fc7\u7a0b\uff0c\u8fd9\u5bf9\u5b66\u4e60\u8fc7\u7a0b\u7684\u6709\u6548\u6027\u63d0\u51fa\u4e86\u6839\u672c\u6027\u8d28\u7591\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u6559\u80b2\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2510.16280", "categories": ["eess.SY", "cs.SY", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.16280", "abs": "https://arxiv.org/abs/2510.16280", "authors": ["Hui Yang", "Faisal Aqlan", "Richard Zhao"], "title": "Towards Smart Manufacturing Metaverse via Digital Twinning in Extended Reality", "comment": null, "summary": "The rapid evolution of modern manufacturing systems is driven by the\nintegration of emerging metaverse technologies such as artificial intelligence\n(AI), digital twin (DT) with different forms of extended reality (XR) like\nvirtual reality (VR), augmented reality (AR), and mixed reality (MR). These\nadvances confront manufacturing workers with complex and evolving environments\nthat demand digital literacy for problem solving in the future workplace.\nHowever, manufacturing industry faces a critical shortage of skilled workforce\nwith digital literacy in the world. Further, global pandemic has significantly\nchanged how people work and collaborate digitally and remotely. There is an\nurgent need to rethink digital platformization and leverage emerging\ntechnologies to propel industrial evolution toward human-centered manufacturing\nmetaverse (MfgVerse). This paper presents a forward-looking perspective on the\ndevelopment of smart MfgVerse, highlighting current efforts in learning\nfactory, cognitive digital twinning, and the new sharing economy of\nmanufacturing-as-a-service (MaaS). MfgVerse is converging into multiplex\nnetworks, including a social network of human stakeholders, an interconnected\nnetwork of manufacturing things or agents (e.g., machines, robots, facilities,\nmaterial handling systems), a network of digital twins of physical things, as\nwell as auxiliary networks of sales, supply chain, logistics, and\nremanufacturing systems. We also showcase the design and development of a\nlearning factory for workforce training in extended reality. Finally, future\ndirections, challenges, and opportunities are discussed for human-centered\nmanufacturing metaverse. We hope this work helps stimulate more comprehensive\nstudies and in-depth research efforts to advance MfgVerse technologies.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5236\u9020\u4e1a\u5143\u5b87\u5b99(MfgVerse)\u7684\u53d1\u5c55\uff0c\u91cd\u70b9\u5173\u6ce8\u4eba\u5de5\u667a\u80fd\u3001\u6570\u5b57\u5b6a\u751f\u548c\u6269\u5c55\u73b0\u5b9e\u7b49\u65b0\u5174\u6280\u672f\u5728\u5236\u9020\u4e1a\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u4eba\u672c\u5236\u9020\u5143\u5b87\u5b99\u89e3\u51b3\u5236\u9020\u4e1a\u6570\u5b57\u7d20\u517b\u4eba\u624d\u77ed\u7f3a\u95ee\u9898\u3002", "motivation": "\u5236\u9020\u4e1a\u9762\u4e34\u6570\u5b57\u7d20\u517b\u4eba\u624d\u4e25\u91cd\u77ed\u7f3a\u7684\u6311\u6218\uff0c\u5168\u7403\u75ab\u60c5\u6539\u53d8\u4e86\u5de5\u4f5c\u65b9\u5f0f\uff0c\u8feb\u5207\u9700\u8981\u91cd\u65b0\u601d\u8003\u6570\u5b57\u5316\u5e73\u53f0\u5316\uff0c\u5229\u7528\u65b0\u5174\u6280\u672f\u63a8\u52a8\u5de5\u4e1a\u5411\u4eba\u672c\u5236\u9020\u5143\u5b87\u5b99\u6f14\u8fdb\u3002", "method": "\u63d0\u51fa\u667a\u80fd\u5236\u9020\u4e1a\u5143\u5b87\u5b99\u7684\u524d\u77bb\u89c6\u89d2\uff0c\u5c55\u793a\u5b66\u4e60\u5de5\u5382\u3001\u8ba4\u77e5\u6570\u5b57\u5b6a\u751f\u548c\u5236\u9020\u5373\u670d\u52a1(MaaS)\u5171\u4eab\u7ecf\u6d4e\u7b49\u5f53\u524d\u52aa\u529b\uff0c\u6784\u5efa\u5305\u62ec\u4eba\u7c7b\u5229\u76ca\u76f8\u5173\u8005\u3001\u5236\u9020\u5b9e\u4f53\u3001\u6570\u5b57\u5b6a\u751f\u548c\u8f85\u52a9\u7cfb\u7edf\u7684\u591a\u91cd\u7f51\u7edc\u3002", "result": "\u5f00\u53d1\u4e86\u7528\u4e8e\u6269\u5c55\u73b0\u5b9e\u52b3\u52a8\u529b\u57f9\u8bad\u7684\u5b66\u4e60\u5de5\u5382\uff0c\u5c55\u793a\u4e86\u5236\u9020\u4e1a\u5143\u5b87\u5b99\u5728\u591a\u91cd\u7f51\u7edc\u878d\u5408\u65b9\u9762\u7684\u8fdb\u5c55\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u4eba\u672c\u5236\u9020\u5143\u5b87\u5b99\u7684\u672a\u6765\u65b9\u5411\u3001\u6311\u6218\u548c\u673a\u9047\uff0c\u5e0c\u671b\u6fc0\u53d1\u66f4\u5168\u9762\u7684\u7814\u7a76\u548c\u6df1\u5165\u7684\u6280\u672f\u53d1\u5c55\u6765\u63a8\u8fdbMfgVerse\u6280\u672f\u3002"}}
{"id": "2510.17226", "categories": ["cs.SI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.17226", "abs": "https://arxiv.org/abs/2510.17226", "authors": ["Gengyu Wang", "Runze Zhang", "Zhongzhi Zhang"], "title": "Opinion Maximization in Social Networks by Modifying Internal Opinions", "comment": "Accepted by NeurIPS 2025", "summary": "Public opinion governance in social networks is critical for public health\ncampaigns, political elections, and commercial marketing. In this paper, we\naddresse the problem of maximizing overall opinion in social networks by\nstrategically modifying the internal opinions of key nodes. Traditional matrix\ninversion methods suffer from prohibitively high computational costs, prompting\nus to propose two efficient sampling-based algorithms. Furthermore, we develop\na deterministic asynchronous algorithm that exactly identifies the optimal set\nof nodes through asynchronous update operations and progressive refinement,\nensuring both efficiency and precision. Extensive experiments on real-world\ndatasets demonstrate that our methods outperform baseline approaches. Notably,\nour asynchronous algorithm delivers exceptional efficiency and accuracy across\nall scenarios, even in networks with tens of millions of nodes.", "AI": {"tldr": "\u63d0\u51fa\u9ad8\u6548\u7b97\u6cd5\u89e3\u51b3\u793e\u4ea4\u7f51\u7edc\u4e2d\u6700\u5927\u5316\u6574\u4f53\u610f\u89c1\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4fee\u6539\u5173\u952e\u8282\u70b9\u7684\u5185\u90e8\u610f\u89c1\uff0c\u76f8\u6bd4\u4f20\u7edf\u77e9\u9635\u6c42\u9006\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u8206\u8bba\u6cbb\u7406\u5bf9\u516c\u5171\u536b\u751f\u8fd0\u52a8\u3001\u653f\u6cbb\u9009\u4e3e\u548c\u5546\u4e1a\u8425\u9500\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u77e9\u9635\u6c42\u9006\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u91c7\u6837\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u4ee5\u53ca\u4e00\u79cd\u786e\u5b9a\u6027\u5f02\u6b65\u7b97\u6cd5\uff0c\u901a\u8fc7\u5f02\u6b65\u66f4\u65b0\u64cd\u4f5c\u548c\u6e10\u8fdb\u5f0f\u7cbe\u5316\u6765\u7cbe\u786e\u8bc6\u522b\u6700\u4f18\u8282\u70b9\u96c6\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5f02\u6b65\u7b97\u6cd5\u5728\u6240\u6709\u573a\u666f\u4e0b\u90fd\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5373\u4f7f\u5728\u5305\u542b\u6570\u5343\u4e07\u8282\u70b9\u7684\u7f51\u7edc\u4e2d\u3002", "conclusion": "\u5f00\u53d1\u7684\u5f02\u6b65\u7b97\u6cd5\u80fd\u591f\u9ad8\u6548\u4e14\u7cbe\u786e\u5730\u89e3\u51b3\u5927\u89c4\u6a21\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u610f\u89c1\u6700\u5927\u5316\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16224", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.16224", "abs": "https://arxiv.org/abs/2510.16224", "authors": ["Zhongjun Qu", "Wendun Wang", "Xiaomeng Zhang"], "title": "Prediction Intervals for Model Averaging", "comment": null, "summary": "A rich set of frequentist model averaging methods has been developed, but\ntheir applications have largely been limited to point prediction, as measuring\nprediction uncertainty in general settings remains an open problem. In this\npaper we propose prediction intervals for model averaging based on conformal\ninference. These intervals cover out-of-sample realizations of the outcome\nvariable with a pre-specified probability, providing a way to assess predictive\nuncertainty beyond point prediction. The framework allows general model\nmisspecification and applies to averaging across multiple models that can be\nnested, disjoint, overlapping, or any combination thereof, with weights that\nmay depend on the estimation sample. We establish coverage guarantees under two\nsets of assumptions: exact finite-sample validity under exchangeability,\nrelevant for cross-sectional data, and asymptotic validity under stationarity,\nrelevant for time-series data. We first present a benchmark algorithm and then\nintroduce a locally adaptive refinement and split-sample procedures that\nbroaden applicability. The methods are illustrated with a cross-sectional\napplication to real estate appraisal and a time-series application to equity\npremium forecasting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5171\u5f62\u63a8\u7406\u7684\u6a21\u578b\u5e73\u5747\u9884\u6d4b\u533a\u95f4\u65b9\u6cd5\uff0c\u80fd\u591f\u4e3a\u6a21\u578b\u5e73\u5747\u9884\u6d4b\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u6a21\u578b\u8bbe\u7f6e\u548c\u6570\u636e\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u7684\u9891\u7387\u6a21\u578b\u5e73\u5747\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u70b9\u9884\u6d4b\uff0c\u800c\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u5ea6\u91cf\u5728\u4e00\u822c\u8bbe\u7f6e\u4e2d\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc4\u4f30\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5171\u5f62\u63a8\u7406\u6784\u5efa\u9884\u6d4b\u533a\u95f4\uff0c\u5141\u8bb8\u4e00\u822c\u6a21\u578b\u8bef\u8bbe\uff0c\u9002\u7528\u4e8e\u5d4c\u5957\u3001\u4e0d\u76f8\u4ea4\u3001\u91cd\u53e0\u6216\u4efb\u610f\u7ec4\u5408\u7684\u591a\u4e2a\u6a21\u578b\u5e73\u5747\uff0c\u6743\u91cd\u53ef\u4f9d\u8d56\u4e8e\u4f30\u8ba1\u6837\u672c\u3002\u63d0\u51fa\u4e86\u57fa\u51c6\u7b97\u6cd5\u3001\u5c40\u90e8\u81ea\u9002\u5e94\u6539\u8fdb\u548c\u5206\u5272\u6837\u672c\u7a0b\u5e8f\u3002", "result": "\u5efa\u7acb\u4e86\u5728\u4e24\u79cd\u5047\u8bbe\u4e0b\u7684\u8986\u76d6\u4fdd\u8bc1\uff1a\u4ea4\u6362\u6027\u4e0b\u7684\u7cbe\u786e\u6709\u9650\u6837\u672c\u6709\u6548\u6027\uff08\u9002\u7528\u4e8e\u6a2a\u622a\u9762\u6570\u636e\uff09\u548c\u5e73\u7a33\u6027\u4e0b\u7684\u6e10\u8fd1\u6709\u6548\u6027\uff08\u9002\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff09\u3002\u901a\u8fc7\u623f\u5730\u4ea7\u8bc4\u4f30\u548c\u80a1\u6743\u6ea2\u4ef7\u9884\u6d4b\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u6a21\u578b\u5e73\u5747\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9884\u6d4b\u533a\u95f4\uff0c\u80fd\u591f\u53ef\u9760\u5730\u8bc4\u4f30\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u6a21\u578b\u8bbe\u7f6e\u548c\u6570\u636e\u573a\u666f\u3002"}}
{"id": "2510.17121", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.17121", "abs": "https://arxiv.org/abs/2510.17121", "authors": ["Fenghua Wen", "Xieyu Yin", "Chufu Wen"], "title": "New Demand Economics", "comment": "33 pages, 3 figures", "summary": "We develop a theory of demand economics for an era of material abundance. The\nbinding constraint on growth has shifted from insufficient aggregate demand to\ninadequate demand-tier upgrading. Our result is that, the new engine of growth\nlies in upgrading the demand hierarchy: higher-tier demands generate larger\nvalue-creation multipliers. The key mechanism is education-driven utility\nmanagement. Education transforms the social utility function, raises the\nutility of higher-tier goods, and directs resources toward higher-value\ndomains; this warrants a policy reorientation away from short-run aggregate\nstimulus toward education-centered, long-horizon investments in human capital.\nMethodologically, we build an estimable general-equilibrium framework.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8e\u7269\u8d28\u4e30\u88d5\u65f6\u4ee3\u9700\u6c42\u7ecf\u6d4e\u5b66\u7684\u7406\u8bba\uff0c\u8ba4\u4e3a\u7ecf\u6d4e\u589e\u957f\u7684\u5f15\u64ce\u5df2\u4ece\u603b\u91cf\u9700\u6c42\u4e0d\u8db3\u8f6c\u5411\u9700\u6c42\u5c42\u7ea7\u5347\u7ea7\uff0c\u6559\u80b2\u9a71\u52a8\u7684\u6548\u7528\u7ba1\u7406\u662f\u6838\u5fc3\u673a\u5236\u3002", "motivation": "\u5728\u7269\u8d28\u4e30\u88d5\u65f6\u4ee3\uff0c\u4f20\u7edf\u7ecf\u6d4e\u589e\u957f\u7406\u8bba\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u9700\u6c42\u7ecf\u6d4e\u5b66\u7406\u8bba\uff0c\u4ee5\u89e3\u91ca\u548c\u6307\u5bfc\u65b0\u65f6\u4ee3\u7684\u7ecf\u6d4e\u589e\u957f\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u53ef\u4f30\u8ba1\u7684\u4e00\u822c\u5747\u8861\u6846\u67b6\u6765\u5206\u6790\u9700\u6c42\u5c42\u7ea7\u5347\u7ea7\u5bf9\u7ecf\u6d4e\u589e\u957f\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u66f4\u9ad8\u5c42\u7ea7\u7684\u9700\u6c42\u4ea7\u751f\u66f4\u5927\u7684\u4ef7\u503c\u521b\u9020\u4e58\u6570\uff0c\u6559\u80b2\u901a\u8fc7\u6539\u53d8\u793e\u4f1a\u6548\u7528\u51fd\u6570\uff0c\u63d0\u5347\u9ad8\u5c42\u7ea7\u5546\u54c1\u7684\u6548\u7528\uff0c\u5f15\u5bfc\u8d44\u6e90\u5411\u9ad8\u4ef7\u503c\u9886\u57df\u914d\u7f6e\u3002", "conclusion": "\u653f\u7b56\u5e94\u91cd\u65b0\u5b9a\u4f4d\uff0c\u4ece\u77ed\u671f\u603b\u91cf\u523a\u6fc0\u8f6c\u5411\u4ee5\u6559\u80b2\u4e3a\u4e2d\u5fc3\u3001\u957f\u671f\u89c6\u91ce\u7684\u4eba\u529b\u8d44\u672c\u6295\u8d44\uff0c\u4ee5\u4fc3\u8fdb\u9700\u6c42\u5c42\u7ea7\u5347\u7ea7\u548c\u7ecf\u6d4e\u589e\u957f\u3002"}}
{"id": "2510.16293", "categories": ["stat.AP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16293", "abs": "https://arxiv.org/abs/2510.16293", "authors": ["Saejin Oh", "Xinyi Fang", "I-Hsin Lin", "Paris Dee", "Christopher S. Dunham", "Stacy M. Copp", "Abigail G. Doyle", "Javier Read de Alaniz", "Mengyang Gu"], "title": "Synergizing chemical and AI communities for advancing laboratories of the future", "comment": null, "summary": "The development of automated experimental facilities and the digitization of\nexperimental data have introduced numerous opportunities to radically advance\nchemical laboratories. As many laboratory tasks involve predicting and\nunderstanding previously unknown chemical relationships, machine learning (ML)\napproaches trained on experimental data can substantially accelerate the\nconventional design-build-test-learn process. This outlook article aims to help\nchemists understand and begin to adopt ML predictive models for a variety of\nlaboratory tasks, including experimental design, synthesis optimization, and\nmaterials characterization. Furthermore, this article introduces how artificial\nintelligence (AI) agents based on large language models can help researchers\nacquire background knowledge in chemical or data science and accelerate various\naspects of the discovery process. We present three case studies in distinct\nareas to illustrate how ML models and AI agents can be leveraged to reduce\ntime-consuming experiments and manual data analysis. Finally, we highlight\nexisting challenges that require continued synergistic effort from both\nexperimental and computational communities to address.", "AI": {"tldr": "\u672c\u6587\u5c55\u671b\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u5982\u4f55\u5e2e\u52a9\u5316\u5b66\u5bb6\u52a0\u901f\u5b9e\u9a8c\u8bbe\u8ba1\u3001\u5408\u6210\u4f18\u5316\u548c\u6750\u6599\u8868\u5f81\u7b49\u5b9e\u9a8c\u5ba4\u4efb\u52a1\uff0c\u51cf\u5c11\u8017\u65f6\u5b9e\u9a8c\u548c\u624b\u52a8\u6570\u636e\u5206\u6790\u3002", "motivation": "\u81ea\u52a8\u5316\u5b9e\u9a8c\u8bbe\u65bd\u7684\u53d1\u5c55\u548c\u5b9e\u9a8c\u6570\u636e\u6570\u5b57\u5316\u4e3a\u5316\u5b66\u5b9e\u9a8c\u5ba4\u5e26\u6765\u4e86\u9769\u547d\u6027\u673a\u9047\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u52a0\u901f\u4f20\u7edf\u7684\u8bbe\u8ba1-\u6784\u5efa-\u6d4b\u8bd5-\u5b66\u4e60\u8fc7\u7a0b\u3002", "method": "\u4ecb\u7ecd\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u5728\u5b9e\u9a8c\u5ba4\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u5b9e\u9a8c\u8bbe\u8ba1\u3001\u5408\u6210\u4f18\u5316\u548c\u6750\u6599\u8868\u5f81\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u6765\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u83b7\u53d6\u5316\u5b66\u6216\u6570\u636e\u79d1\u5b66\u80cc\u666f\u77e5\u8bc6\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u5982\u4f55\u51cf\u5c11\u8017\u65f6\u5b9e\u9a8c\u548c\u624b\u52a8\u6570\u636e\u5206\u6790\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u9700\u8981\u5b9e\u9a8c\u548c\u8ba1\u7b97\u793e\u533a\u6301\u7eed\u534f\u540c\u52aa\u529b\u6765\u89e3\u51b3\u73b0\u6709\u6311\u6218\u3002"}}
{"id": "2510.16032", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16032", "abs": "https://arxiv.org/abs/2510.16032", "authors": ["Amir Karami"], "title": "A dual typology of social media interventions and deterrence mechanisms against misinformation", "comment": null, "summary": "In response to the escalating threat of misinformation, social media\nplatforms have introduced a wide range of interventions aimed at reducing the\nspread and influence of false information. However, there is a lack of a\ncoherent macrolevel perspective that explains how these interventions operate\nindependently and collectively. To address this gap, I offer a dual typology\nthrough a spectrum of interventions aligned with deterrence theory and drawing\nparallels from international relations, military, cybersecurity, and public\nhealth. I argue that five major types of platform interventions, including\nremoval, reduction, informing, composite, and multimodal, can be mapped to five\ncorresponding deterrence mechanisms, including hard, situational, soft,\nintegrated, and mixed deterrence based on purpose and perceptibility. These\nmappings illuminate how platforms apply varying degrees of deterrence\nmechanisms to influence user behavior.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u7c7b\u578b\u5b66\u6846\u67b6\uff0c\u5c06\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u7684\u4e94\u79cd\u5e72\u9884\u63aa\u65bd\uff08\u79fb\u9664\u3001\u51cf\u5c11\u3001\u544a\u77e5\u3001\u590d\u5408\u3001\u591a\u6a21\u5f0f\uff09\u6620\u5c04\u5230\u4e94\u79cd\u5a01\u6151\u673a\u5236\uff08\u786c\u5a01\u6151\u3001\u60c5\u5883\u5a01\u6151\u3001\u8f6f\u5a01\u6151\u3001\u7efc\u5408\u5a01\u6151\u3001\u6df7\u5408\u5a01\u6151\uff09\uff0c\u4ee5\u89e3\u91ca\u5e73\u53f0\u5982\u4f55\u72ec\u7acb\u548c\u96c6\u4f53\u5730\u5e94\u5bf9\u865a\u5047\u4fe1\u606f\u5a01\u80c1\u3002", "motivation": "\u5e94\u5bf9\u865a\u5047\u4fe1\u606f\u65e5\u76ca\u4e25\u91cd\u7684\u5a01\u80c1\uff0c\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u5b8f\u89c2\u5c42\u9762\u7684\u89c6\u89d2\u6765\u89e3\u91ca\u5404\u79cd\u5e73\u53f0\u5e72\u9884\u63aa\u65bd\u5982\u4f55\u72ec\u7acb\u548c\u96c6\u4f53\u8fd0\u4f5c\u3002", "method": "\u57fa\u4e8e\u5a01\u6151\u7406\u8bba\uff0c\u501f\u9274\u56fd\u9645\u5173\u7cfb\u3001\u519b\u4e8b\u3001\u7f51\u7edc\u5b89\u5168\u548c\u516c\u5171\u536b\u751f\u9886\u57df\u7684\u7ecf\u9a8c\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5e72\u9884\u63aa\u65bd\u4e0e\u5a01\u6151\u673a\u5236\u7684\u53cc\u7c7b\u578b\u5b66\u6846\u67b6\u3002", "result": "\u6210\u529f\u5c06\u4e94\u79cd\u5e73\u53f0\u5e72\u9884\u63aa\u65bd\u6620\u5c04\u5230\u4e94\u79cd\u76f8\u5e94\u7684\u5a01\u6151\u673a\u5236\uff0c\u63ed\u793a\u4e86\u5e73\u53f0\u5982\u4f55\u5e94\u7528\u4e0d\u540c\u7a0b\u5ea6\u7684\u5a01\u6151\u673a\u5236\u6765\u5f71\u54cd\u7528\u6237\u884c\u4e3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u5e73\u53f0\u5e72\u9884\u63aa\u65bd\u63d0\u4f9b\u4e86\u8fde\u8d2f\u7684\u5b8f\u89c2\u89c6\u89d2\uff0c\u9610\u660e\u4e86\u4e0d\u540c\u5e72\u9884\u63aa\u65bd\u5982\u4f55\u901a\u8fc7\u5a01\u6151\u673a\u5236\u72ec\u7acb\u548c\u534f\u540c\u8fd0\u4f5c\u6765\u5e94\u5bf9\u865a\u5047\u4fe1\u606f\u3002"}}
{"id": "2510.16297", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16297", "abs": "https://arxiv.org/abs/2510.16297", "authors": ["Muhammad Hamza Ali", "Amritanshu Pandey"], "title": "AC Dynamics-aware Trajectory Optimization with Binary Enforcement for Adaptive UFLS Design", "comment": null, "summary": "The high penetration of distributed energy resources, resulting in backfeed\nof power at the transmission and distribution interface, is causing\nconventional underfrequency load shedding (UFLS) schemes to become\nnonconforming. Adaptive schemes that update UFLS relay settings recursively in\ntime offer a solution, but existing adaptive techniques that obtain UFLS relay\nsettings with linearized or reduced-order model formulations fail to capture AC\nnonlinear network behavior. In practice, this will result in relays unable to\nrestore system frequency during adverse disturbances. We formulate an adaptive\nUFLS problem as a trajectory optimization and include the full AC nonlinear\nnetwork dynamics to ensure AC feasibility and time-coordinated control actions.\nWe include binary decisions to model relay switching action and time-delayed\nmulti-stage load-shedding. However, this formulation results in an intractable\nMINLP problem. To enforce model tractability, we relax these binary variables\ninto continuous surrogates and reformulate the MINLP as a sequence of NLPs. We\nsolve the NLPs with a homotopy-driven method that enforces\nnear-integer-feasible solutions. We evaluate the framework on multiple\nsynthetic transmission systems and demonstrate that it scales efficiently to\nnetworks exceeding 1500+ nodes with over 170k+ continuous and 73k+ binary\ndecision variables, while successfully recovering binary-feasible solutions\nthat arrest the frequency decline during worst-case disturbance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f68\u8ff9\u4f18\u5316\u7684\u81ea\u9002\u5e94\u4f4e\u9891\u51cf\u8f7d\u65b9\u6848\uff0c\u8003\u8651\u5b8c\u6574\u7684\u4ea4\u6d41\u975e\u7ebf\u6027\u7f51\u7edc\u52a8\u6001\uff0c\u901a\u8fc7\u677e\u5f1b\u4e8c\u8fdb\u5236\u53d8\u91cf\u548c\u540c\u4f26\u65b9\u6cd5\u89e3\u51b3MINLP\u95ee\u9898\uff0c\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u6709\u6548\u7684\u9891\u7387\u63a7\u5236\u3002", "motivation": "\u5206\u5e03\u5f0f\u80fd\u6e90\u7684\u9ad8\u6e17\u900f\u7387\u5bfc\u81f4\u4f20\u7edf\u4f4e\u9891\u51cf\u8f7d\u65b9\u6848\u5931\u6548\uff0c\u73b0\u6709\u81ea\u9002\u5e94\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u4ea4\u6d41\u975e\u7ebf\u6027\u7f51\u7edc\u884c\u4e3a\uff0c\u5bfc\u81f4\u7ee7\u7535\u5668\u5728\u4e25\u91cd\u6270\u52a8\u65f6\u65e0\u6cd5\u6062\u590d\u7cfb\u7edf\u9891\u7387\u3002", "method": "\u5c06\u81ea\u9002\u5e94UFLS\u95ee\u9898\u5efa\u6a21\u4e3a\u8f68\u8ff9\u4f18\u5316\uff0c\u5305\u542b\u5b8c\u6574\u7684\u4ea4\u6d41\u975e\u7ebf\u6027\u7f51\u7edc\u52a8\u6001\uff0c\u901a\u8fc7\u677e\u5f1b\u4e8c\u8fdb\u5236\u53d8\u91cf\u4e3a\u8fde\u7eed\u4ee3\u7406\u53d8\u91cf\uff0c\u5c06MINLP\u95ee\u9898\u8f6c\u5316\u4e3aNLP\u5e8f\u5217\uff0c\u4f7f\u7528\u540c\u4f26\u9a71\u52a8\u65b9\u6cd5\u6c42\u89e3\u8fd1\u6574\u6570\u53ef\u884c\u89e3\u3002", "result": "\u5728\u591a\u4e2a\u5408\u6210\u8f93\u7535\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\uff0c\u6846\u67b6\u53ef\u6269\u5c55\u52301500+\u8282\u70b9\u300117\u4e07+\u8fde\u7eed\u53d8\u91cf\u548c7.3\u4e07+\u4e8c\u8fdb\u5236\u53d8\u91cf\u7684\u7f51\u7edc\uff0c\u6210\u529f\u6062\u590d\u4e8c\u8fdb\u5236\u53ef\u884c\u89e3\u5e76\u5728\u6700\u574f\u6270\u52a8\u4e0b\u963b\u6b62\u9891\u7387\u4e0b\u964d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u4f4e\u9891\u51cf\u8f7d\u95ee\u9898\uff0c\u786e\u4fdd\u4ea4\u6d41\u53ef\u884c\u6027\u548c\u65f6\u95f4\u534f\u8c03\u63a7\u5236\uff0c\u5728\u4e25\u91cd\u6270\u52a8\u4e0b\u4fdd\u6301\u7cfb\u7edf\u9891\u7387\u7a33\u5b9a\u3002"}}
{"id": "2510.16661", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.16661", "abs": "https://arxiv.org/abs/2510.16661", "authors": ["Jing Kong"], "title": "On the Asymptotics of the Minimax Linear Estimator", "comment": null, "summary": "Many causal estimands, such as average treatment effects under\nunconfoundedness, can be written as continuous linear functionals of an unknown\nregression function. We study a weighting estimator that sets weights by a\nminimax procedure: solving a convex optimization problem that trades off\nworst-case conditional bias against variance. Despite its growing use, general\nroot-$n$ theory for this method has been limited. This paper fills that gap.\nUnder regularity conditions, we show that the minimax linear estimator is\nroot-$n$ consistent and asymptotically normal, and we derive its asymptotic\nvariance. These results justify ignoring worst-case bias when forming\nlarge-sample confidence intervals and make inference less sensitive to the\nscaling of the function class. With a mild variance condition, the estimator\nattains the semiparametric efficiency bound, so an augmentation step commonly\nused in the literature is not needed to achieve first-order optimality.\nEvidence from simulations and three empirical applications, including\njob-training and minimum-wage policies, points to a simple rule: in designs\nsatisfying our regularity conditions, standard-error confidence intervals\nsuffice; otherwise, bias-aware intervals remain important.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u6781\u5c0f\u6781\u5927\u7a0b\u5e8f\u8bbe\u7f6e\u6743\u91cd\u7684\u52a0\u6743\u4f30\u8ba1\u5668\uff0c\u8bc1\u660e\u4e86\u5728\u6b63\u5219\u6761\u4ef6\u4e0b\u8be5\u4f30\u8ba1\u5668\u5177\u6709\u6839n\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u6e10\u8fd1\u65b9\u5dee\u3002", "motivation": "\u8bb8\u591a\u56e0\u679c\u4f30\u8ba1\u91cf\u53ef\u4ee5\u8868\u793a\u4e3a\u672a\u77e5\u56de\u5f52\u51fd\u6570\u7684\u8fde\u7eed\u7ebf\u6027\u6cdb\u51fd\uff0c\u4f46\u73b0\u6709\u7684\u6781\u5c0f\u6781\u5927\u7ebf\u6027\u4f30\u8ba1\u5668\u7684\u6839n\u7406\u8bba\u6709\u9650\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6781\u5c0f\u6781\u5927\u7ebf\u6027\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u95ee\u9898\u5728\u6761\u4ef6\u504f\u5dee\u548c\u65b9\u5dee\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u6765\u8bbe\u7f6e\u6743\u91cd\u3002", "result": "\u5728\u6b63\u5219\u6761\u4ef6\u4e0b\uff0c\u6781\u5c0f\u6781\u5927\u7ebf\u6027\u4f30\u8ba1\u5668\u5177\u6709\u6839n\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u4e14\u5728\u4e00\u5b9a\u65b9\u5dee\u6761\u4ef6\u4e0b\u8fbe\u5230\u534a\u53c2\u6570\u6548\u7387\u754c\u3002", "conclusion": "\u5728\u6ee1\u8db3\u6b63\u5219\u6761\u4ef6\u7684\u8bbe\u8ba1\u4e2d\uff0c\u6807\u51c6\u8bef\u5dee\u7f6e\u4fe1\u533a\u95f4\u8db3\u591f\uff1b\u5426\u5219\uff0c\u504f\u5dee\u611f\u77e5\u533a\u95f4\u4ecd\u7136\u91cd\u8981\u3002"}}
{"id": "2510.17481", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.17481", "abs": "https://arxiv.org/abs/2510.17481", "authors": ["Esteban Mu\u00f1oz-Sobrado"], "title": "Universalization and the Origins of Fiscal Capacity", "comment": null, "summary": "This paper proposes a model of tax compliance and fiscal capacity grounded in\nuniversalization reasoning. Citizens partially internalize the consequences of\nconcealment by imagining a world in which everyone acted similarly, linking\ntheir compliance decisions to the perceived effectiveness of public spending. A\nselfish elite chooses between public goods and private rents, taking compliance\nas given. In equilibrium, citizens' moral internalization expands the feasible\ntax base and induces elites to allocate resources toward provision rather than\nappropriation. When the value of public spending is uncertain, morality enables\ncredible reform: high-value elites can signal their type through provision,\nprompting citizens to increase compliance and raising fiscal capacity within\nthe same period. The analysis thus identifies a moral channel through which\nstates may escape low-capacity traps even under weak institutions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u666e\u904d\u5316\u63a8\u7406\u7684\u7a0e\u6536\u9075\u4ece\u548c\u8d22\u653f\u80fd\u529b\u6a21\u578b\uff0c\u516c\u6c11\u901a\u8fc7\u60f3\u8c61\u5982\u679c\u6bcf\u4e2a\u4eba\u90fd\u7c7b\u4f3c\u884c\u4e3a\u6765\u90e8\u5206\u5185\u5316\u9003\u7a0e\u7684\u540e\u679c\uff0c\u5c06\u9075\u4ece\u51b3\u7b56\u4e0e\u516c\u5171\u652f\u51fa\u6709\u6548\u6027\u8054\u7cfb\u8d77\u6765\u3002", "motivation": "\u7814\u7a76\u9053\u5fb7\u5185\u5316\u5982\u4f55\u5e2e\u52a9\u56fd\u5bb6\u5728\u5236\u5ea6\u8584\u5f31\u7684\u60c5\u51b5\u4e0b\u6446\u8131\u4f4e\u8d22\u653f\u80fd\u529b\u9677\u9631\uff0c\u63a2\u7d22\u516c\u6c11\u9053\u5fb7\u63a8\u7406\u5bf9\u7a0e\u6536\u9075\u4ece\u548c\u8d22\u653f\u80fd\u529b\u7684\u5f71\u54cd\u673a\u5236\u3002", "method": "\u5efa\u7acb\u7406\u8bba\u6a21\u578b\uff0c\u5206\u6790\u516c\u6c11\u901a\u8fc7\u666e\u904d\u5316\u63a8\u7406\u90e8\u5206\u5185\u5316\u9003\u7a0e\u540e\u679c\u7684\u884c\u4e3a\uff0c\u4ee5\u53ca\u81ea\u79c1\u7cbe\u82f1\u5728\u516c\u5171\u4ea7\u54c1\u548c\u79c1\u4eba\u79df\u91d1\u4e4b\u95f4\u7684\u9009\u62e9\uff0c\u8003\u8651\u516c\u5171\u652f\u51fa\u4ef7\u503c\u4e0d\u786e\u5b9a\u6027\u7684\u60c5\u51b5\u3002", "result": "\u516c\u6c11\u7684\u9053\u5fb7\u5185\u5316\u6269\u5927\u4e86\u53ef\u884c\u7a0e\u57fa\uff0c\u4fc3\u4f7f\u7cbe\u82f1\u5c06\u8d44\u6e90\u5206\u914d\u7ed9\u516c\u5171\u4ea7\u54c1\u800c\u975e\u79c1\u4eba\u5360\u6709\uff1b\u5f53\u516c\u5171\u652f\u51fa\u4ef7\u503c\u4e0d\u786e\u5b9a\u65f6\uff0c\u9ad8\u4ef7\u503c\u7cbe\u82f1\u53ef\u4ee5\u901a\u8fc7\u63d0\u4f9b\u516c\u5171\u4ea7\u54c1\u6765\u4f20\u9012\u4fe1\u53f7\uff0c\u4fc3\u4f7f\u516c\u6c11\u63d0\u9ad8\u9075\u4ece\u5ea6\u3002", "conclusion": "\u8be5\u5206\u6790\u786e\u5b9a\u4e86\u4e00\u4e2a\u9053\u5fb7\u6e20\u9053\uff0c\u5373\u4f7f\u5236\u5ea6\u8584\u5f31\uff0c\u56fd\u5bb6\u4e5f\u80fd\u901a\u8fc7\u516c\u6c11\u7684\u9053\u5fb7\u63a8\u7406\u548c\u7cbe\u82f1\u7684\u4fe1\u53f7\u4f20\u9012\u6765\u63d0\u5347\u8d22\u653f\u80fd\u529b\uff0c\u6446\u8131\u4f4e\u80fd\u529b\u9677\u9631\u3002"}}
{"id": "2510.16316", "categories": ["stat.AP", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.16316", "abs": "https://arxiv.org/abs/2510.16316", "authors": ["Georgios Aravanis", "Nicholas Silionis", "Jacopo Bardiani", "Marco Giglio", "Konstantinos Anyfantis", "Claudio Sbarufatti"], "title": "A hierarchical Bayesian approach for population-based structural health monitoring in ship hull structures", "comment": "15 pages, 6 figures. Submitted to the International Conference on\n  Uncertainty Quantification in Computational Science and Engineering (UNCECOMP\n  2025), Rhodes, Greece", "summary": "Structural health monitoring (SHM) strategies involve the processing of\nstructural response data to indirectly assess an asset's condition. These\nstrategies can be enhanced for a group of structures, especially when they are\nsimilar, since mutual underlying physics are expected to exist. The concept\nbehind population-based SHM exploits the sharing of data among individuals, so\nthat data-rich members can support data-scarce ones. One approach to\npopulation-level modeling is the hierarchical Bayesian method, where the model\nis structured hierarchically in terms of its parameters, and correlation among\nlearning tasks is enabled by conditioning on shared latent variables.\n  This work investigates the application of a hierarchical Bayesian model to\ninfer expected distributions of deflection amplitudes at both the population\nand domain levels, with the aim of detecting excessive initial deflections in a\npopulation of plate elements. Although these damages are typically localized,\nthey can trigger unexpected events, if not properly monitored. The work is\nconducted in a numerical setting using a Finite Element model to generate\nstrain response data, which serve as the monitoring data. Bayesian inference\nwas conducted using Markov Chain Monte Carlo (MCMC), with a surrogate model\nemployed to calculate the likelihood function. The hierarchical approach was\ncompared to an independent model for a plate component with few data. The\nresults revealed that, under data sparsity conditions, the hierarchical model\ncan offer more robust results in terms of uncertainty, which is essential for\ndecision-making tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5e94\u7528\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\u6765\u63a8\u65ad\u677f\u6784\u4ef6\u7fa4\u4f53\u548c\u4e2a\u4f53\u5c42\u9762\u7684\u6320\u5ea6\u5206\u5e03\uff0c\u4ee5\u68c0\u6d4b\u8fc7\u5927\u7684\u521d\u59cb\u6320\u5ea6\uff0c\u5728\u6570\u636e\u7a00\u758f\u6761\u4ef6\u4e0b\u6bd4\u72ec\u7acb\u6a21\u578b\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u7ed3\u679c\u3002", "motivation": "\u5229\u7528\u7fa4\u4f53\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u7b56\u7565\uff0c\u901a\u8fc7\u6570\u636e\u4e30\u5bcc\u7684\u6784\u4ef6\u652f\u6301\u6570\u636e\u7a00\u7f3a\u7684\u6784\u4ef6\uff0c\u63d0\u9ad8\u5bf9\u677f\u6784\u4ef6\u521d\u59cb\u6320\u5ea6\u5f02\u5e38\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5206\u5c42\u8d1d\u53f6\u65af\u65b9\u6cd5\u6784\u5efa\u6a21\u578b\uff0c\u901a\u8fc7\u6709\u9650\u5143\u6a21\u578b\u751f\u6210\u5e94\u53d8\u54cd\u5e94\u6570\u636e\u4f5c\u4e3a\u76d1\u6d4b\u6570\u636e\uff0c\u91c7\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u8fdb\u884c\u8d1d\u53f6\u65af\u63a8\u65ad\uff0c\u5e76\u4f7f\u7528\u4ee3\u7406\u6a21\u578b\u8ba1\u7b97\u4f3c\u7136\u51fd\u6570\u3002", "result": "\u5728\u6570\u636e\u7a00\u758f\u6761\u4ef6\u4e0b\uff0c\u5206\u5c42\u6a21\u578b\u6bd4\u72ec\u7acb\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u7ed3\u679c\uff0c\u8fd9\u5bf9\u51b3\u7b56\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\u5728\u7fa4\u4f53\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u4e2d\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u6320\u5ea6\u5206\u5e03\u63a8\u65ad\uff0c\u6709\u52a9\u4e8e\u68c0\u6d4b\u8fc7\u5927\u7684\u521d\u59cb\u6320\u5ea6\u3002"}}
{"id": "2510.16042", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16042", "abs": "https://arxiv.org/abs/2510.16042", "authors": ["Marcin Korecki", "Cesare Carissimo"], "title": "Does Capital Dream of Artificial Labour?", "comment": null, "summary": "This paper investigates the concept of Labour as an expression of `timenergy'\n- a fusion of time and energy - and its entanglement within the system of\nCapital. We define Labour as the commodified, quantifiable expansion of\ntimenergy, in contrast to Capital, which is capable of accumulation and\nabstraction. We explore Labour's historical evolution, its coercive and\nalienating nature, and its transformation through automation and artificial\nintelligence. Using a game-theoretic, agent-based simulation, we model\ninteractions between Capital and Labour in production processes governed by\nCobb-Douglas functions. Our results show that despite theoretical symmetry,\nlearning agents disproportionately gravitate toward capital-intensive\nprocesses, revealing Capital's superior organizational influence due to its\naccumulative capacity. We argue that Capital functions as an artificially alive\nsystem animated by the living Labour it consumes, and question whether life can\nsustain itself without the infrastructures of Capital in a future of increasing\nautomation. This study offers both a critique of and a framework for\nunderstanding Labour's subjugation within the Capital system.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u52b3\u52a8\u5b9a\u4e49\u4e3a\"\u65f6\u95f4\u80fd\u91cf\"\u7684\u5546\u54c1\u5316\u8868\u8fbe\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62df\u63ed\u793a\u4e86\u8d44\u672c\u5728\u8d44\u672c-\u52b3\u52a8\u4e92\u52a8\u4e2d\u7684\u7ec4\u7ec7\u4f18\u52bf\uff0c\u8d28\u7591\u5728\u81ea\u52a8\u5316\u672a\u6765\u4e2d\u751f\u547d\u80fd\u5426\u8131\u79bb\u8d44\u672c\u57fa\u7840\u8bbe\u65bd\u800c\u5b58\u5728\u3002", "motivation": "\u7814\u7a76\u52b3\u52a8\u4f5c\u4e3a\u65f6\u95f4\u80fd\u91cf\u878d\u5408\u4f53\u5728\u8d44\u672c\u4f53\u7cfb\u4e2d\u7684\u7ea0\u7f20\u5173\u7cfb\uff0c\u63a2\u8ba8\u8d44\u672c\u4f5c\u4e3a\u4eba\u5de5\u751f\u547d\u7cfb\u7edf\u5982\u4f55\u901a\u8fc7\u6d88\u8017\u6d3b\u52b3\u52a8\u800c\u5b58\u5728\uff0c\u4ee5\u53ca\u81ea\u52a8\u5316\u65f6\u4ee3\u751f\u547d\u53ef\u6301\u7eed\u6027\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u535a\u5f08\u8bba\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62df\u65b9\u6cd5\uff0c\u5728\u67ef\u5e03-\u9053\u683c\u62c9\u65af\u751f\u4ea7\u51fd\u6570\u6846\u67b6\u4e0b\u5efa\u6a21\u8d44\u672c\u4e0e\u52b3\u52a8\u7684\u4e92\u52a8\u8fc7\u7a0b\u3002", "result": "\u5c3d\u7ba1\u7406\u8bba\u4e0a\u5b58\u5728\u5bf9\u79f0\u6027\uff0c\u4f46\u5b66\u4e60\u4ee3\u7406\u660e\u663e\u503e\u5411\u4e8e\u8d44\u672c\u5bc6\u96c6\u578b\u8fc7\u7a0b\uff0c\u63ed\u793a\u4e86\u8d44\u672c\u56e0\u5176\u79ef\u7d2f\u80fd\u529b\u800c\u5177\u6709\u66f4\u5f3a\u7684\u7ec4\u7ec7\u5f71\u54cd\u529b\u3002", "conclusion": "\u8d44\u672c\u662f\u4e00\u4e2a\u7531\u6d88\u8017\u6d3b\u52b3\u52a8\u800c\u6fc0\u6d3b\u7684\u4eba\u5de5\u751f\u547d\u7cfb\u7edf\uff0c\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u89e3\u52b3\u52a8\u5728\u8d44\u672c\u4f53\u7cfb\u4e2d\u4ece\u5c5e\u5730\u4f4d\u7684\u6279\u5224\u6846\u67b6\uff0c\u5e76\u8d28\u7591\u81ea\u52a8\u5316\u672a\u6765\u4e2d\u751f\u547d\u5bf9\u8d44\u672c\u57fa\u7840\u8bbe\u65bd\u7684\u4f9d\u8d56\u6027\u3002"}}
{"id": "2510.16352", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16352", "abs": "https://arxiv.org/abs/2510.16352", "authors": ["Sayak Mukherjee", "Himanshu Sharma", "Wenceslao Shaw Cortez", "Genevieve Starke", "Michael Sinner", "Brooke J. Stanislawski", "Zachary Tully", "Paul Fleming", "Sonja Glavaski"], "title": "Supervisory Control of Hybrid Power Plants Using Online Feedback Optimization: Designs and Validations with a Hybrid Co-Simulation Engine", "comment": "20 pages, 9 figures", "summary": "This research investigates designing a supervisory feedback controller for a\nhybrid power plant that coordinates the wind, solar, and battery energy storage\nplants to meet the desired power demands. We have explored an online feedback\ncontrol design that does not require detailed knowledge about the models, known\nas feedback optimization. The control inputs are updated using the gradient\ninformation of the cost and the outputs with respect to the input control\ncommands. This enables us to adjust the active power references of wind, solar,\nand storage plants to meet the power generation requirements set by grid\noperators. The methodology also ensures robust control performance in the\npresence of uncertainties in the weather. In this paper, we focus on describing\nthe supervisory feedback optimization formulation and control-oriented modeling\nfor individual renewable and storage components of the hybrid power plant. The\nproposed supervisory control has been integrated with the hybrid plant\nco-simulation engine, Hercules, demonstrating its effectiveness in more\nrealistic simulation scenarios.", "AI": {"tldr": "\u8bbe\u8ba1\u6df7\u5408\u53d1\u7535\u5382\u7684\u76d1\u7763\u53cd\u9988\u63a7\u5236\u5668\uff0c\u534f\u8c03\u98ce\u7535\u3001\u5149\u4f0f\u548c\u7535\u6c60\u50a8\u80fd\u7cfb\u7edf\u4ee5\u6ee1\u8db3\u7535\u7f51\u529f\u7387\u9700\u6c42\uff0c\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u53cd\u9988\u4f18\u5316\u65b9\u6cd5\uff0c\u65e0\u9700\u7cbe\u786e\u6a21\u578b\u77e5\u8bc6\u3002", "motivation": "\u6df7\u5408\u53d1\u7535\u5382\u9700\u8981\u534f\u8c03\u591a\u79cd\u53ef\u518d\u751f\u80fd\u6e90\u548c\u50a8\u80fd\u7cfb\u7edf\u6765\u6ee1\u8db3\u7535\u7f51\u529f\u7387\u9700\u6c42\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u7cbe\u786e\u6a21\u578b\uff0c\u800c\u5b9e\u9645\u8fd0\u884c\u4e2d\u5b58\u5728\u5929\u6c14\u7b49\u4e0d\u786e\u5b9a\u6027\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u5728\u7ebf\u53cd\u9988\u4f18\u5316\u63a7\u5236\u8bbe\u8ba1\uff0c\u5229\u7528\u6210\u672c\u548c\u8f93\u51fa\u76f8\u5bf9\u4e8e\u63a7\u5236\u8f93\u5165\u7684\u68af\u5ea6\u4fe1\u606f\u6765\u66f4\u65b0\u63a7\u5236\u547d\u4ee4\uff0c\u8c03\u6574\u98ce\u7535\u3001\u5149\u4f0f\u548c\u50a8\u80fd\u7684\u529f\u7387\u53c2\u8003\u503c\u3002", "result": "\u63d0\u51fa\u7684\u76d1\u7763\u63a7\u5236\u65b9\u6cd5\u5df2\u96c6\u6210\u5230\u6df7\u5408\u53d1\u7535\u5382\u8054\u5408\u4eff\u771f\u5f15\u64ceHercules\u4e2d\uff0c\u5728\u66f4\u771f\u5b9e\u7684\u4eff\u771f\u573a\u666f\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u53cd\u9988\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u8be6\u7ec6\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6df7\u5408\u53d1\u7535\u5382\u7684\u9c81\u68d2\u63a7\u5236\uff0c\u6709\u6548\u5e94\u5bf9\u5929\u6c14\u4e0d\u786e\u5b9a\u6027\uff0c\u6ee1\u8db3\u7535\u7f51\u529f\u7387\u9700\u6c42\u3002"}}
{"id": "2510.16669", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.16669", "abs": "https://arxiv.org/abs/2510.16669", "authors": ["Jing Kong"], "title": "Causal Inference in High-Dimensional Generalized Linear Models with Binary Outcomes", "comment": null, "summary": "This paper proposes a debiased estimator for causal effects in\nhigh-dimensional generalized linear models with binary outcomes and general\nlink functions. The estimator augments a regularized regression plug-in with\nweights computed from a convex optimization problem that approximately balances\nlink-derivative-weighted covariates and controls variance; it does not rely on\nestimated propensity scores. Under standard conditions, the estimator is\n$\\sqrt{n}$-consistent and asymptotically normal for dense linear contrasts and\ncausal parameters. Simulation results show the superior performance of our\napproach in comparison to alternatives such as inverse propensity score\nestimators and double machine learning estimators in finite samples. In an\napplication to the National Supported Work training data, our estimates and\nconfidence intervals are close to the experimental benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u7ef4\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u4e2d\u56e0\u679c\u6548\u5e94\u7684\u53bb\u504f\u4f30\u8ba1\u5668\uff0c\u9002\u7528\u4e8e\u4e8c\u5143\u7ed3\u679c\u548c\u4e00\u822c\u94fe\u63a5\u51fd\u6570\uff0c\u4e0d\u4f9d\u8d56\u503e\u5411\u5f97\u5206\u4f30\u8ba1\u3002", "motivation": "\u5728\u9ad8\u7ef4\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u4e2d\uff0c\u73b0\u6709\u7684\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u65b9\u6cd5\u5982\u9006\u503e\u5411\u5f97\u5206\u4f30\u8ba1\u5668\u548c\u53cc\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\u5668\u5728\u6709\u9650\u6837\u672c\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7a33\u5065\u7684\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5c06\u6b63\u5219\u5316\u56de\u5f52\u63d2\u4ef6\u4e0e\u4ece\u51f8\u4f18\u5316\u95ee\u9898\u8ba1\u7b97\u7684\u6743\u91cd\u76f8\u7ed3\u5408\uff0c\u8fd1\u4f3c\u5e73\u8861\u94fe\u63a5\u5bfc\u6570\u52a0\u6743\u534f\u53d8\u91cf\u5e76\u63a7\u5236\u65b9\u5dee\u3002", "result": "\u5728\u6807\u51c6\u6761\u4ef6\u4e0b\uff0c\u4f30\u8ba1\u5668\u5bf9\u5bc6\u96c6\u7ebf\u6027\u5bf9\u6bd4\u548c\u56e0\u679c\u53c2\u6570\u5177\u6709\u221an\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\u3002\u6a21\u62df\u7ed3\u679c\u663e\u793a\u5728\u6709\u9650\u6837\u672c\u4e2d\u4f18\u4e8e\u9006\u503e\u5411\u5f97\u5206\u4f30\u8ba1\u5668\u548c\u53cc\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728National Supported Work\u57f9\u8bad\u6570\u636e\u5e94\u7528\u4e2d\uff0c\u4f30\u8ba1\u503c\u548c\u7f6e\u4fe1\u533a\u95f4\u63a5\u8fd1\u5b9e\u9a8c\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.17641", "categories": ["econ.GN", "physics.soc-ph", "q-fin.EC", "stat.AP", "62P20, 90B90"], "pdf": "https://arxiv.org/pdf/2510.17641", "abs": "https://arxiv.org/abs/2510.17641", "authors": ["L\u00e1szl\u00f3 Csat\u00f3", "D\u00f3ra Gr\u00e9ta Petr\u00f3czy"], "title": "Are penalty shootouts better than a coin toss? Evidence from European football", "comment": "16 pages, 5 figures, 4 tables", "summary": "Penalty shootouts play an important role in the knockout stage of major\nfootball tournaments, especially since the 2021/22 season, when the Union of\nEuropean Football Associations (UEFA) scrapped the away goals rule in its club\ncompetitions. Inspired by this rule change, our paper examines whether the\noutcome of a penalty shootout can be predicted in UEFA club competitions. Based\non all shootouts between 2000 and 2025, we find no evidence for the effect of\nthe kicking order, the field of the match, and psychological momentum. In\ncontrast to previous results, stronger teams, defined first by Elo ratings, do\nnot perform better than their weaker opponents. Consequently, penalty shootouts\nare equivalent to a perfect lottery in top European football.", "AI": {"tldr": "\u57fa\u4e8e2000-2025\u5e74\u6b27\u8db3\u8054\u4ff1\u4e50\u90e8\u6bd4\u8d5b\u7684\u6240\u6709\u70b9\u7403\u5927\u6218\u6570\u636e\uff0c\u7814\u7a76\u53d1\u73b0\u70b9\u7403\u5927\u6218\u7ed3\u679c\u65e0\u6cd5\u901a\u8fc7\u8e22\u7403\u987a\u5e8f\u3001\u6bd4\u8d5b\u573a\u5730\u548c\u5fc3\u7406\u52bf\u5934\u6765\u9884\u6d4b\uff0c\u5f3a\u961f\u8868\u73b0\u4e0d\u4f18\u4e8e\u5f31\u961f\uff0c\u70b9\u7403\u5927\u6218\u76f8\u5f53\u4e8e\u5b8c\u7f8e\u5f69\u7968\u3002", "motivation": "\u53d7\u6b27\u8db3\u80542021/22\u8d5b\u5b63\u53d6\u6d88\u5ba2\u573a\u8fdb\u7403\u89c4\u5219\u7684\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u6b27\u8db3\u8054\u4ff1\u4e50\u90e8\u6bd4\u8d5b\u4e2d\u70b9\u7403\u5927\u6218\u7ed3\u679c\u662f\u5426\u53ef\u9884\u6d4b\u3002", "method": "\u5206\u67902000-2025\u5e74\u6240\u6709\u6b27\u8db3\u8054\u4ff1\u4e50\u90e8\u6bd4\u8d5b\u7684\u70b9\u7403\u5927\u6218\u6570\u636e\uff0c\u4f7f\u7528Elo\u8bc4\u5206\u5b9a\u4e49\u7403\u961f\u5b9e\u529b\uff0c\u8003\u5bdf\u8e22\u7403\u987a\u5e8f\u3001\u6bd4\u8d5b\u573a\u5730\u548c\u5fc3\u7406\u52bf\u5934\u7b49\u56e0\u7d20\u3002", "result": "\u672a\u53d1\u73b0\u8e22\u7403\u987a\u5e8f\u3001\u6bd4\u8d5b\u573a\u5730\u548c\u5fc3\u7406\u52bf\u5934\u5bf9\u70b9\u7403\u5927\u6218\u7ed3\u679c\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5f3a\u961f\u8868\u73b0\u4e0d\u4f18\u4e8e\u5f31\u961f\u3002", "conclusion": "\u5728\u9876\u7ea7\u6b27\u6d32\u8db3\u7403\u6bd4\u8d5b\u4e2d\uff0c\u70b9\u7403\u5927\u6218\u7b49\u540c\u4e8e\u5b8c\u7f8e\u5f69\u7968\uff0c\u7ed3\u679c\u5b8c\u5168\u968f\u673a\u4e0d\u53ef\u9884\u6d4b\u3002"}}
{"id": "2510.16360", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.16360", "abs": "https://arxiv.org/abs/2510.16360", "authors": ["Yuchen Xiao", "Corwin Zigler", "Peter H. Hennings", "Alexandros Savvaidis"], "title": "Time-Varying Confounding Bias in Observational Geoscience with Application to Induced Seismicity", "comment": null, "summary": "Evidence derived primarily from physical models has identified saltwater\ndisposal as the dominant causal factor that contributes to induced seismicity.\nTo complement physical models, statistical/machine learning (ML) models are\ndesigned to measure associations from observational data, either with\nparametric regression models or more flexible ML models. However, it is often\ndifficult to interpret the statistical significance of a parameter or the\npredicative power of a model as evidence of causation. We adapt a causal\ninference framework with the potential outcomes perspective to explicitly\ndefine what we meant by causal effect and declare necessary identification\nconditions to recover unbiased causal effect estimates. In particular, we\nillustrate the threat of time-varying confounding in observational longitudinal\ngeoscience data through simulations and adapt established statistical methods\nfor longitudinal analysis from the causal interference literature to estimate\nthe effect of wastewater disposal on earthquakes in the Fort-Worth Basin of\nNorth Central Texas from 2013 to 2016.", "AI": {"tldr": "\u672c\u6587\u91c7\u7528\u56e0\u679c\u63a8\u65ad\u6846\u67b6\u5206\u6790\u5e9f\u6c34\u6ce8\u5165\u4e0e\u8bf1\u53d1\u5730\u9707\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u901a\u8fc7\u6f5c\u5728\u7ed3\u679c\u89c6\u89d2\u5b9a\u4e49\u56e0\u679c\u6548\u5e94\uff0c\u5e76\u5e94\u7528\u7eb5\u5411\u6570\u636e\u5206\u6790\u65b9\u6cd5\u4f30\u8ba1\u5e9f\u6c34\u5904\u7f6e\u5bf9\u5730\u9707\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7269\u7406\u6a21\u578b\u5df2\u786e\u8ba4\u76d0\u6c34\u5904\u7f6e\u662f\u8bf1\u53d1\u5730\u9707\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u4f46\u7edf\u8ba1/\u673a\u5668\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u89e3\u91ca\u53c2\u6570\u663e\u8457\u6027\u6216\u9884\u6d4b\u80fd\u529b\u4f5c\u4e3a\u56e0\u679c\u8bc1\u636e\u3002\u9700\u8981\u660e\u786e\u7684\u56e0\u679c\u63a8\u65ad\u6846\u67b6\u6765\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u6062\u590d\u65e0\u504f\u7684\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u3002", "method": "\u91c7\u7528\u56e0\u679c\u63a8\u65ad\u6846\u67b6\u548c\u6f5c\u5728\u7ed3\u679c\u89c6\u89d2\uff0c\u5b9a\u4e49\u56e0\u679c\u6548\u5e94\u5e76\u58f0\u660e\u5fc5\u8981\u7684\u8bc6\u522b\u6761\u4ef6\u3002\u901a\u8fc7\u6a21\u62df\u8bf4\u660e\u65f6\u53d8\u6df7\u6742\u7684\u5a01\u80c1\uff0c\u5e76\u5e94\u7528\u56e0\u679c\u63a8\u65ad\u6587\u732e\u4e2d\u5efa\u7acb\u7684\u7eb5\u5411\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u57282013-2016\u5e74\u5317\u5fb7\u514b\u8428\u65af\u5ddeFort-Worth\u76c6\u5730\u7684\u7814\u7a76\u4e2d\uff0c\u4f30\u8ba1\u4e86\u5e9f\u6c34\u5904\u7f6e\u5bf9\u5730\u9707\u7684\u56e0\u679c\u6548\u5e94\u3002", "conclusion": "\u56e0\u679c\u63a8\u65ad\u6846\u67b6\u4e3a\u4ece\u89c2\u6d4b\u6027\u7eb5\u5411\u5730\u7403\u79d1\u5b66\u6570\u636e\u4e2d\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u65f6\u53d8\u6df7\u6742\u95ee\u9898\uff0c\u4e3a\u5e9f\u6c34\u5904\u7f6e\u4e0e\u8bf1\u53d1\u5730\u9707\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u8bc1\u636e\u3002"}}
{"id": "2510.16048", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16048", "abs": "https://arxiv.org/abs/2510.16048", "authors": ["David Atkinson"], "title": "Open Shouldn't Mean Exempt: Open-Source Exceptionalism and Generative AI", "comment": null, "summary": "Any argument that open-source generative artificial intelligence (GenAI) is\ninherently ethical or legal solely because it is open source is flawed. Yet,\nthis is the explicit or implicit stance of several open-source GenAI entities.\nThis paper critically examines prevalent justifications for \"open-source\nexceptionalism,\" demonstrating how contemporary open-source GenAI often\ninadvertently facilitates unlawful conduct and environmental degradation\nwithout genuinely disrupting established oligopolies. Furthermore, the paper\nexposes the unsubstantiated and strategic deployment of \"democratization\" and\n\"innovation\" rhetoric to advocate for regulatory exemptions not afforded to\nproprietary systems.\n  The conclusion is that open-source developers must be held to the same legal\nand ethical standards as all other actors in the technological ecosystem.\nHowever, the paper proposes a narrowly tailored safe harbor designed to protect\nlegitimate, non-commercial scientific research, contingent upon adherence to\nspecific criteria. Ultimately, this paper advocates for a framework of\nresponsible AI development, wherein openness is pursued within established\nethical and legal boundaries, with due consideration for its broader societal\nimplications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6279\u5224\u4e86\u5f00\u6e90GenAI\u5929\u7136\u5177\u6709\u4f26\u7406\u6216\u6cd5\u5f8b\u4f18\u52bf\u7684\u89c2\u70b9\uff0c\u6307\u51fa\u5f53\u524d\u5f00\u6e90GenAI\u5f80\u5f80\u52a9\u957f\u975e\u6cd5\u884c\u4e3a\u548c\u73af\u5883\u7834\u574f\uff0c\u4e14\u672a\u771f\u6b63\u6253\u7834\u5be1\u5934\u5784\u65ad\u3002\u8bba\u6587\u4e3b\u5f20\u5f00\u6e90\u5f00\u53d1\u8005\u5e94\u627f\u62c5\u4e0e\u5176\u4ed6\u6280\u672f\u53c2\u4e0e\u8005\u76f8\u540c\u7684\u6cd5\u5f8b\u548c\u4f26\u7406\u8d23\u4efb\uff0c\u540c\u65f6\u4e3a\u5408\u6cd5\u7684\u975e\u5546\u4e1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u6709\u9650\u7684\u5b89\u5168\u6e2f\u4fdd\u62a4\u3002", "motivation": "\u9488\u5bf9\u591a\u4e2a\u5f00\u6e90GenAI\u5b9e\u4f53\u58f0\u79f0\u5176\u7cfb\u7edf\u56e0\u5f00\u6e90\u800c\u5929\u7136\u5177\u6709\u4f26\u7406\u6216\u6cd5\u5f8b\u4f18\u52bf\u7684\u7acb\u573a\uff0c\u8bba\u6587\u65e8\u5728\u6279\u5224\u8fd9\u79cd\"\u5f00\u6e90\u4f8b\u5916\u4e3b\u4e49\"\u7684\u6d41\u884c\u8fa9\u62a4\uff0c\u63ed\u793a\u5176\u5982\u4f55\u4e3a\u76d1\u7ba1\u8c41\u514d\u63d0\u4f9b\u4e0d\u6b63\u5f53\u7406\u7531\u3002", "method": "\u901a\u8fc7\u6279\u5224\u6027\u5206\u6790\uff0c\u8bba\u6587\u68c0\u89c6\u4e86\u5f00\u6e90GenAI\u7684\u5e38\u89c1\u8fa9\u62a4\u7406\u7531\uff0c\u5305\u62ec\"\u6c11\u4e3b\u5316\"\u548c\"\u521b\u65b0\"\u7b49\u4fee\u8f9e\u7684\u6218\u7565\u6027\u4f7f\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u7cfb\u7edf\u5728\u5b9e\u9645\u8fd0\u884c\u4e2d\u5982\u4f55\u4fc3\u8fdb\u975e\u6cd5\u6d3b\u52a8\u548c\u73af\u5883\u95ee\u9898\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u5f00\u6e90GenAI\u5f80\u5f80\u65e0\u610f\u4e2d\u4fc3\u8fdb\u975e\u6cd5\u884c\u4e3a\u548c\u73af\u5883\u9000\u5316\uff0c\u4e14\u672a\u80fd\u771f\u6b63\u98a0\u8986\u73b0\u6709\u5be1\u5934\u5784\u65ad\u3002\u8bba\u6587\u8fd8\u63ed\u793a\u4e86\"\u6c11\u4e3b\u5316\"\u548c\"\u521b\u65b0\"\u7b49\u4fee\u8f9e\u88ab\u7b56\u7565\u6027\u5730\u7528\u4e8e\u4e89\u53d6\u76d1\u7ba1\u8c41\u514d\u3002", "conclusion": "\u5f00\u6e90\u5f00\u53d1\u8005\u5e94\u4e0e\u5176\u4ed6\u6280\u672f\u53c2\u4e0e\u8005\u627f\u62c5\u76f8\u540c\u7684\u6cd5\u5f8b\u548c\u4f26\u7406\u8d23\u4efb\u3002\u8bba\u6587\u63d0\u8bae\u4e3a\u5408\u6cd5\u7684\u975e\u5546\u4e1a\u79d1\u5b66\u7814\u7a76\u8bbe\u7acb\u6709\u9650\u7684\u5b89\u5168\u6e2f\u4fdd\u62a4\uff0c\u5e76\u5021\u5bfc\u5728\u65e2\u5b9a\u4f26\u7406\u548c\u6cd5\u5f8b\u8fb9\u754c\u5185\u8ffd\u6c42\u5f00\u653e\u6027\u7684\u8d1f\u8d23\u4efbAI\u53d1\u5c55\u6846\u67b6\u3002"}}
{"id": "2510.16408", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16408", "abs": "https://arxiv.org/abs/2510.16408", "authors": ["Sen Zhan", "Lingkang Jin", "Haoyang Zhang", "Nikolaos G. Paterakis"], "title": "Real-time Measurement-based Optimization for Distribution System Operation Considering Battery Voltage and Thermal Constraints", "comment": "7 pages, submitted to PSCC 2026", "summary": "The secure operation of power distribution systems is challenged by the\ngrowing integration of distributed energy resources. Leveraging the flexibility\nof battery storage offers a cost-effective alternative to measures like\ngeneration curtailment, which results in energy losses. However, developing an\neffective operational model for battery storage is hindered by inaccurate grid\nmodels, unavailability of load data, nonlinear relationship between power\ninjections and network states, intertemporal constraints, and complex\nelectrochemical and thermal dynamics. To address these challenges, this paper\nproposes a data-driven operational control scheme for battery storage in\ndistribution systems. Linear and convex quadratic operational constraints are\nconstructed based on real-time distribution system and battery storage\nmeasurements. Lyapunov optimization decouples multi-period battery operation,\nenabling a real-time, forecast-free control strategy with low computational\ncomplexity. Numerical studies using nonlinear distribution system and battery\nstorage simulators validate the effectiveness of the approach in ensuring\nsecure distribution system operation and satisfaction of voltage and thermal\nconstraints of battery storage.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b9e\u65f6\u6d4b\u91cf\u7684\u6570\u636e\u9a71\u52a8\u7535\u6c60\u50a8\u80fd\u8fd0\u884c\u63a7\u5236\u65b9\u6848\uff0c\u4f7f\u7528Lyapunov\u4f18\u5316\u5b9e\u73b0\u5b9e\u65f6\u3001\u65e0\u9700\u9884\u6d4b\u7684\u63a7\u5236\u7b56\u7565\uff0c\u786e\u4fdd\u914d\u7535\u7cfb\u7edf\u5b89\u5168\u8fd0\u884c\u548c\u7535\u6c60\u7535\u538b\u3001\u70ed\u7ea6\u675f\u6ee1\u8db3\u3002", "motivation": "\u914d\u7535\u7cfb\u7edf\u5b89\u5168\u8fd0\u884c\u9762\u4e34\u5206\u5e03\u5f0f\u80fd\u6e90\u96c6\u6210\u6311\u6218\uff0c\u7535\u6c60\u50a8\u80fd\u7075\u6d3b\u6027\u662f\u6bd4\u53d1\u7535\u524a\u51cf\u66f4\u7ecf\u6d4e\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u4f20\u7edf\u8fd0\u884c\u6a21\u578b\u53d7\u9650\u4e8e\u4e0d\u51c6\u786e\u7684\u7535\u7f51\u6a21\u578b\u3001\u8d1f\u8377\u6570\u636e\u4e0d\u53ef\u5f97\u3001\u975e\u7ebf\u6027\u5173\u7cfb\u3001\u65f6\u95f4\u7ea6\u675f\u548c\u590d\u6742\u7535\u5316\u5b66\u70ed\u52a8\u529b\u5b66\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5b9e\u65f6\u914d\u7535\u7cfb\u7edf\u548c\u7535\u6c60\u50a8\u80fd\u6d4b\u91cf\u6784\u5efa\u7ebf\u6027\u548c\u51f8\u4e8c\u6b21\u8fd0\u884c\u7ea6\u675f\uff0c\u4f7f\u7528Lyapunov\u4f18\u5316\u89e3\u8026\u591a\u65f6\u6bb5\u7535\u6c60\u8fd0\u884c\uff0c\u5b9e\u73b0\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u5b9e\u65f6\u3001\u65e0\u9700\u9884\u6d4b\u63a7\u5236\u7b56\u7565\u3002", "result": "\u4f7f\u7528\u975e\u7ebf\u6027\u914d\u7535\u7cfb\u7edf\u548c\u7535\u6c60\u50a8\u80fd\u6a21\u62df\u5668\u7684\u6570\u503c\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u786e\u4fdd\u914d\u7535\u7cfb\u7edf\u5b89\u5168\u8fd0\u884c\u548c\u6ee1\u8db3\u7535\u6c60\u7535\u538b\u3001\u70ed\u7ea6\u675f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u9a71\u52a8\u63a7\u5236\u65b9\u6848\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7535\u6c60\u50a8\u80fd\u5728\u914d\u7535\u7cfb\u7edf\u4e2d\u7684\u8fd0\u884c\u63a7\u5236\u95ee\u9898\uff0c\u65e0\u9700\u7cbe\u786e\u7535\u7f51\u6a21\u578b\u548c\u8d1f\u8377\u9884\u6d4b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.16681", "categories": ["econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.16681", "abs": "https://arxiv.org/abs/2510.16681", "authors": ["Sukjin Han", "Haiqing Xu"], "title": "On Quantile Treatment Effects, Rank Similarity,and Variation of Instrumental Variables", "comment": "49 pages, 11 figures", "summary": "This paper develops a nonparametric framework to identify and estimate\ndistributional treatment effects under nonseparable endogeneity. We begin by\nrevisiting the widely adopted \\emph{rank similarity} (RS) assumption and\ncharacterizing it by the relationship it imposes between observed and\ncounterfactual potential outcome distributions. The characterization highlights\nthe restrictiveness of RS, motivating a weaker identifying condition. Under\nthis alternative, we construct identifying bounds on the distributional\ntreatment effects of interest through a linear semi-infinite programming (SILP)\nformulation. Our identification strategy also clarifies how richer exogenous\ninstrument variation, such as multi-valued or multiple instruments, can further\ntighten these bounds. Finally, exploiting the SILP's saddle-point structure and\nKarush-Kuhn-Tucker (KKT) conditions, we establish large-sample properties for\nthe empirical SILP: consistency and asymptotic distribution results for the\nestimated bounds and associated solutions.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u975e\u53c2\u6570\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u53ef\u5206\u79bb\u5185\u751f\u6027\u4e0b\u8bc6\u522b\u548c\u4f30\u8ba1\u5206\u5e03\u5904\u7406\u6548\u5e94\u3002\u901a\u8fc7\u5f31\u5316\u79e9\u76f8\u4f3c\u6027\u5047\u8bbe\uff0c\u6784\u5efa\u4e86\u5206\u5e03\u5904\u7406\u6548\u5e94\u7684\u8bc6\u522b\u8fb9\u754c\uff0c\u5e76\u5229\u7528\u7ebf\u6027\u534a\u65e0\u9650\u89c4\u5212\u65b9\u6cd5\u8fdb\u884c\u4f30\u8ba1\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u5e7f\u6cdb\u91c7\u7528\u7684\u79e9\u76f8\u4f3c\u6027\u5047\u8bbe\uff0c\u53d1\u73b0\u5176\u9650\u5236\u6027\u8f83\u5f3a\uff0c\u9700\u8981\u66f4\u5f31\u7684\u8bc6\u522b\u6761\u4ef6\u6765\u5904\u7406\u975e\u53c2\u6570\u6846\u67b6\u4e0b\u7684\u5185\u751f\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7ebf\u6027\u534a\u65e0\u9650\u89c4\u5212\u65b9\u6cd5\u6784\u5efa\u8bc6\u522b\u8fb9\u754c\uff0c\u5229\u7528\u978d\u70b9\u7ed3\u6784\u548cKKT\u6761\u4ef6\u5efa\u7acb\u5927\u6837\u672c\u6027\u8d28\u3002", "result": "\u5728\u8f83\u5f31\u7684\u8bc6\u522b\u6761\u4ef6\u4e0b\u6210\u529f\u6784\u5efa\u4e86\u5206\u5e03\u5904\u7406\u6548\u5e94\u7684\u8bc6\u522b\u8fb9\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u4f30\u8ba1\u8fb9\u754c\u7684\u4e00\u81f4\u6027\u53ca\u6e10\u8fd1\u5206\u5e03\u6027\u8d28\u3002", "conclusion": "\u63d0\u51fa\u7684\u975e\u53c2\u6570\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u53ef\u5206\u79bb\u5185\u751f\u6027\u4e0b\u7684\u5206\u5e03\u5904\u7406\u6548\u5e94\u8bc6\u522b\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u5b9e\u8bc1\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u65b9\u6cd5\u5de5\u5177\u3002"}}
{"id": "2510.15879", "categories": ["q-fin.GN", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15879", "abs": "https://arxiv.org/abs/2510.15879", "authors": ["Jiaquan Nicholas Chen", "Marcel Ausloos"], "title": "A study about who is interested in stock splitting and why: considering companies, shareholders or managers", "comment": "40 pages, 16 figures, 3 tables, 31 references; prepared for Journal\n  of Risk and Financial Management", "summary": "There are many misconceptions around stock prices, stock splits,\nshareholders, investors, and managers behaviour about such informations due to\na number of confounding factors. This paper tests hypotheses with a selected\ndatabase, about the question ''is stock split attractive for companies?'' in\nanother words, ''why companies split their stock?'', ''why managers split their\nstock?'', sometimes for no benefit, and ''why shareholders agree with such\ndecisions?''. We contribute to the existing knowledge through a discussion of\nnine events in recent (selectively chosen) years, observing the role of\ninformation asymmetries, the returns and traded volumes before and after the\nevent. Therefore, calculating the beta for each sample, it is found that stock\nsplits (i) affect the market and slightly enhance the trading volume in a\nshort-term, (ii) increase the shareholder base for its firm, (iii) have a\npositive effect on the liquidity of the market. We concur that stock split\nannouncements can reduce the level of information asymmetric. Investors\nreadjust their beliefs in the firm, although most of the firms are mispriced in\nthe stock split year.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u80a1\u7968\u5206\u5272\u5bf9\u516c\u53f8\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u80a1\u7968\u5206\u5272\u80fd\u77ed\u671f\u63d0\u5347\u4ea4\u6613\u91cf\u3001\u6269\u5927\u80a1\u4e1c\u57fa\u7840\u3001\u63d0\u9ad8\u5e02\u573a\u6d41\u52a8\u6027\uff0c\u5e76\u51cf\u5c11\u4fe1\u606f\u4e0d\u5bf9\u79f0\u3002", "motivation": "\u63a2\u8ba8\u80a1\u7968\u5206\u5272\u5bf9\u516c\u53f8\u7684\u5438\u5f15\u529b\uff0c\u5206\u6790\u516c\u53f8\u548c\u7ba1\u7406\u5c42\u8fdb\u884c\u80a1\u7968\u5206\u5272\u7684\u539f\u56e0\uff0c\u4ee5\u53ca\u80a1\u4e1c\u4e3a\u4f55\u540c\u610f\u6b64\u7c7b\u51b3\u7b56\uff0c\u65e8\u5728\u6f84\u6e05\u5173\u4e8e\u80a1\u7968\u4ef7\u683c\u3001\u80a1\u7968\u5206\u5272\u3001\u80a1\u4e1c\u548c\u7ba1\u7406\u8005\u884c\u4e3a\u7684\u8bef\u89e3\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8fd1\u5e74\u6765\u4e5d\u4e2a\u9009\u62e9\u6027\u4e8b\u4ef6\uff0c\u89c2\u5bdf\u4fe1\u606f\u4e0d\u5bf9\u79f0\u7684\u4f5c\u7528\u4ee5\u53ca\u4e8b\u4ef6\u524d\u540e\u7684\u56de\u62a5\u548c\u4ea4\u6613\u91cf\u53d8\u5316\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u6837\u672c\u7684\u8d1d\u5854\u503c\u3002", "result": "\u80a1\u7968\u5206\u5272\uff08i\uff09\u5f71\u54cd\u5e02\u573a\u5e76\u5728\u77ed\u671f\u5185\u8f7b\u5fae\u63d0\u5347\u4ea4\u6613\u91cf\uff0c\uff08ii\uff09\u6269\u5927\u516c\u53f8\u7684\u80a1\u4e1c\u57fa\u7840\uff0c\uff08iii\uff09\u5bf9\u5e02\u573a\u6d41\u52a8\u6027\u6709\u79ef\u6781\u5f71\u54cd\u3002\u80a1\u7968\u5206\u5272\u516c\u544a\u53ef\u4ee5\u51cf\u5c11\u4fe1\u606f\u4e0d\u5bf9\u79f0\u6c34\u5e73\u3002", "conclusion": "\u80a1\u7968\u5206\u5272\u516c\u544a\u53ef\u4ee5\u51cf\u5c11\u4fe1\u606f\u4e0d\u5bf9\u79f0\uff0c\u6295\u8d44\u8005\u4f1a\u91cd\u65b0\u8c03\u6574\u5bf9\u516c\u53f8\u7684\u4fe1\u5ff5\uff0c\u5c3d\u7ba1\u5927\u591a\u6570\u516c\u53f8\u5728\u80a1\u7968\u5206\u5272\u5e74\u4efd\u88ab\u9519\u8bef\u5b9a\u4ef7\u3002"}}
{"id": "2510.16740", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.16740", "abs": "https://arxiv.org/abs/2510.16740", "authors": ["Biswabrata Pradhan", "Rathin Das"], "title": "Bayesian reliability acceptance sampling plans for competing risks data under interval censoring", "comment": null, "summary": "We obtain a reliability acceptance sampling plan for independent competing\nrisk data under interval censoring schemes using the Bayesian approach. At\nfirst, the Bayesian reliability acceptance sampling plan is obtained where the\ndecision criteria of accepting a lot is pre-fixed. For large samples, computing\nBayes risk is computationally intensive. Therefore, an approximate Bayes risk\nis obtained using the asymptotic properties of the maximum likelihood\nestimators. Lastly, the Bayesian reliability acceptance sampling plan is\nobtained, where the decision function is arbitrary. The manufacturer can derive\nan optimal decision function by minimizing the Bayes risk among all decision\nfunctions. This optimal decision function is known as Bayes decision function.\nThe optimal sampling plan is obtained by minimizing the Bayes risk. The\nalgorithms are provided for the computation of optimum Bayesian reliability\nacceptance sampling plan. Numerical results are provided and comparisons\nbetween the Bayesian reliability acceptance sampling plans are carried out.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u72ec\u7acb\u7ade\u4e89\u98ce\u9669\u6570\u636e\u533a\u95f4\u5220\u5931\u53ef\u9760\u6027\u9a8c\u6536\u62bd\u6837\u8ba1\u5212\uff0c\u5305\u62ec\u56fa\u5b9a\u51b3\u7b56\u51c6\u5219\u548c\u6700\u4f18\u51b3\u7b56\u51fd\u6570\u4e24\u79cd\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u5927\u6837\u672c\u60c5\u51b5\u4e0b\u8d1d\u53f6\u65af\u98ce\u9669\u8ba1\u7b97\u590d\u6742\u7684\u95ee\u9898\uff0c\u4e3a\u5236\u9020\u5546\u63d0\u4f9b\u6700\u4f18\u51b3\u7b56\u51fd\u6570\u4ee5\u6700\u5c0f\u5316\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u6e10\u8fd1\u6027\u8d28\u83b7\u5f97\u8fd1\u4f3c\u8d1d\u53f6\u65af\u98ce\u9669\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u8d1d\u53f6\u65af\u98ce\u9669\u83b7\u5f97\u6700\u4f18\u51b3\u7b56\u51fd\u6570\u548c\u62bd\u6837\u8ba1\u5212\u3002", "result": "\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6700\u4f18\u8d1d\u53f6\u65af\u53ef\u9760\u6027\u9a8c\u6536\u62bd\u6837\u8ba1\u5212\u7684\u7b97\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u6570\u503c\u7ed3\u679c\u6bd4\u8f83\u3002", "conclusion": "\u8d1d\u53f6\u65af\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u7ade\u4e89\u98ce\u9669\u6570\u636e\u7684\u53ef\u9760\u6027\u9a8c\u6536\u62bd\u6837\u95ee\u9898\uff0c\u4e3a\u5236\u9020\u5546\u63d0\u4f9b\u98ce\u9669\u6700\u5c0f\u5316\u7684\u51b3\u7b56\u65b9\u6848\u3002"}}
{"id": "2510.16049", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16049", "abs": "https://arxiv.org/abs/2510.16049", "authors": ["David Atkinson"], "title": "In the Mood to Exclude: Revitalizing Trespass to Chattels in the Era of GenAI Scraping", "comment": null, "summary": "This paper argues that website owners have the right to exclude others from\ntheir websites. Accordingly, when generative AI (GenAI) scraping bots\nintentionally circumvent reasonable technological barriers, their conduct could\nbe actionable as trespass to chattels. If the scraping leads to a decrease in\nthe website's value, then trespass to chattels should apply. The prevailing\njudicial focus on website content and the dismissal of trespass claims absent\nproof of server impairment or user disruption misconstrues the nature of the\nwebsite itself as a form of digital property, focusing too narrowly on what\nconstitutes harm under a claim of trespass. By shifting analysis from content\nto the website itself as an integrated digital asset and illustrating the harm\nto the value of the chattel, this paper demonstrates that the right to exclude\napplies online with the same force as it does to tangible property.\n  Courts and litigants have struggled to police large-scale scraping because\ncopyright preemption narrows available claims, leaving copyright and its fair\nuse defense as the primary battleground. In contrast, recognizing websites as\npersonal property revives trespass to chattels as a meaningful cause of action,\nproviding website owners with an enforceable exclusionary right. Such\nprotection would disincentivize exploitative scraping, preserve incentives for\ncontent creation, aid in protecting privacy and personal data, and safeguard\nvalues of autonomy and expression. Ultimately, this paper contends that\nreaffirming website owners' right to exclude is essential to maintaining a fair\nand sustainable online environment.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u7f51\u7ad9\u6240\u6709\u8005\u6709\u6743\u6392\u9664\u4ed6\u4eba\u8bbf\u95ee\u5176\u7f51\u7ad9\uff0c\u5f53\u751f\u6210\u5f0fAI\u6293\u53d6\u673a\u5668\u4eba\u89c4\u907f\u6280\u672f\u969c\u788d\u65f6\uff0c\u5176\u884c\u4e3a\u53ef\u6784\u6210\u52a8\u4ea7\u4fb5\u6743\u3002\u6cd5\u9662\u5e94\u5173\u6ce8\u7f51\u7ad9\u4f5c\u4e3a\u6570\u5b57\u8d44\u4ea7\u7684\u4ef7\u503c\u635f\u5bb3\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u670d\u52a1\u5668\u635f\u5bb3\u3002", "motivation": "\u5f53\u524d\u6cd5\u9662\u8fc7\u5ea6\u5173\u6ce8\u7f51\u7ad9\u5185\u5bb9\u800c\u975e\u7f51\u7ad9\u672c\u8eab\u4f5c\u4e3a\u6570\u5b57\u8d22\u4ea7\u7684\u6027\u8d28\uff0c\u5bfc\u81f4\u5927\u89c4\u6a21\u7f51\u7edc\u6293\u53d6\u96be\u4ee5\u6709\u6548\u76d1\u7ba1\u3002\u7248\u6743\u4f18\u5148\u539f\u5219\u9650\u5236\u4e86\u53ef\u7528\u8bc9\u8bbc\u4e3b\u5f20\uff0c\u9700\u8981\u91cd\u65b0\u786e\u7acb\u7f51\u7ad9\u4f5c\u4e3a\u4e2a\u4eba\u8d22\u4ea7\u7684\u6cd5\u5f8b\u5730\u4f4d\u3002", "method": "\u901a\u8fc7\u5c06\u5206\u6790\u7126\u70b9\u4ece\u5185\u5bb9\u8f6c\u5411\u7f51\u7ad9\u4f5c\u4e3a\u96c6\u6210\u6570\u5b57\u8d44\u4ea7\uff0c\u8bba\u8bc1\u52a8\u4ea7\u4fb5\u6743\u5728\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u3002\u4e3b\u5f20\u7f51\u7ad9\u5e94\u88ab\u89c6\u4e3a\u4e2a\u4eba\u8d22\u4ea7\uff0c\u4ece\u800c\u6062\u590d\u52a8\u4ea7\u4fb5\u6743\u4f5c\u4e3a\u6709\u6548\u7684\u8bc9\u8bbc\u7406\u7531\u3002", "result": "\u627f\u8ba4\u7f51\u7ad9\u4e3a\u4e2a\u4eba\u8d22\u4ea7\u53ef\u4f7f\u52a8\u4ea7\u4fb5\u6743\u6210\u4e3a\u6709\u610f\u4e49\u7684\u8bc9\u8bbc\u4e3b\u5f20\uff0c\u4e3a\u7f51\u7ad9\u6240\u6709\u8005\u63d0\u4f9b\u53ef\u6267\u884c\u7684\u6392\u4ed6\u6743\uff0c\u963b\u6b62\u5265\u524a\u6027\u6293\u53d6\u884c\u4e3a\u3002", "conclusion": "\u91cd\u7533\u7f51\u7ad9\u6240\u6709\u8005\u7684\u6392\u4ed6\u6743\u5bf9\u4e8e\u7ef4\u62a4\u516c\u5e73\u53ef\u6301\u7eed\u7684\u7f51\u7edc\u73af\u5883\u81f3\u5173\u91cd\u8981\uff0c\u6709\u52a9\u4e8e\u4fdd\u62a4\u5185\u5bb9\u521b\u4f5c\u6fc0\u52b1\u3001\u9690\u79c1\u548c\u4e2a\u4eba\u6570\u636e\uff0c\u4ee5\u53ca\u81ea\u4e3b\u6743\u548c\u8868\u8fbe\u4ef7\u503c\u3002"}}
{"id": "2510.16414", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16414", "abs": "https://arxiv.org/abs/2510.16414", "authors": ["Yuang Chen", "Fengqian Guo", "Chang Wu", "Shuyi Liu", "Hancheng Lu", "Chang Wen Chen"], "title": "AoI-Aware Task Offloading and Transmission Optimization for Industrial IoT Networks: A Branching Deep Reinforcement Learning Approach", "comment": "15 pages, 13 figures, submitted to IEEE journal for potential\n  publication", "summary": "In the Industrial Internet of Things (IIoT), the frequent transmission of\nlarge amounts of data over wireless networks should meet the stringent\ntimeliness requirements. Particularly, the freshness of packet status updates\nhas a significant impact on the system performance. In this paper, we propose\nan age-of-information (AoI)-aware multi-base station (BS) real-time monitoring\nframework to support extensive IIoT deployments. To meet the freshness\nrequirements of IIoT, we formulate a joint task offloading and resource\nallocation optimization problem with the goal of minimizing long-term average\nAoI. Tackling the core challenges of combinatorial explosion in multi-BS\ndecision spaces and the stochastic dynamics of IIoT systems is crucial, as\nthese factors render traditional optimization methods intractable. Firstly, an\ninnovative branching-based Dueling Double Deep Q-Network (Branching-D3QN)\nalgorithm is proposed to effectively implement task offloading, which optimizes\nthe convergence performance by reducing the action space complexity from\nexponential to linear levels. Then, an efficient optimization solution to\nresource allocation is proposed by proving the semi-definite property of the\nHessian matrix of bandwidth and computation resources. Finally, we propose an\niterative optimization algorithm for efficient joint task offloading and\nresource allocation to achieve optimal average AoI performance. Extensive\nsimulations demonstrate that our proposed Branching-D3QN algorithm outperforms\nboth state-of-the-art DRL methods and classical heuristics, achieving up to a\n75% enhanced convergence speed and at least a 22% reduction in the long-term\naverage AoI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAoI\u7684\u591a\u57fa\u7ad9\u5b9e\u65f6\u76d1\u63a7\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u652fD3QN\u7b97\u6cd5\u548c\u8d44\u6e90\u5206\u914d\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5de5\u4e1a\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u957f\u671f\u5e73\u5747\u4fe1\u606f\u5e74\u9f84\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51\u4e2d\u5927\u91cf\u6570\u636e\u7684\u65e0\u7ebf\u4f20\u8f93\u9700\u8981\u6ee1\u8db3\u4e25\u683c\u7684\u5b9e\u65f6\u6027\u8981\u6c42\uff0c\u6570\u636e\u5305\u72b6\u6001\u66f4\u65b0\u7684\u65b0\u9c9c\u5ea6\u5bf9\u7cfb\u7edf\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u5206\u652fD3QN\u7b97\u6cd5\u5b9e\u73b0\u4efb\u52a1\u5378\u8f7d\uff0c\u5c06\u52a8\u4f5c\u7a7a\u95f4\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u81f3\u7ebf\u6027\u7ea7\uff1b\u901a\u8fc7\u8bc1\u660eHessian\u77e9\u9635\u7684\u534a\u6b63\u5b9a\u6027\uff0c\u63d0\u51fa\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u9ad8\u6548\u5206\u914d\u65b9\u6848\uff1b\u8bbe\u8ba1\u8fed\u4ee3\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u8054\u5408\u4efb\u52a1\u5378\u8f7d\u4e0e\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5206\u652fD3QN\u7b97\u6cd5\u5728\u6536\u655b\u901f\u5ea6\u4e0a\u63d0\u534775%\uff0c\u957f\u671f\u5e73\u5747AoI\u964d\u4f4e\u81f3\u5c1122%\uff0c\u4f18\u4e8e\u73b0\u6709DRL\u65b9\u6cd5\u548c\u7ecf\u5178\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8054\u5408\u4f18\u5316\u6846\u67b6\u80fd\u6709\u6548\u6ee1\u8db3\u5de5\u4e1a\u7269\u8054\u7f51\u7684\u5b9e\u65f6\u6027\u9700\u6c42\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.16683", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.16683", "abs": "https://arxiv.org/abs/2510.16683", "authors": ["Xiaohong Chen", "Haitian Xie"], "title": "Local Overidentification and Efficiency Gains in Modern Causal Inference and Data Combination", "comment": null, "summary": "This paper studies nonparametric local (over-)identification, in the sense of\nChen and Santos (2018), and the associated semiparametric efficiency in modern\ncausal frameworks. We develop a unified approach that begins by translating\nstructural models with latent variables into their induced statistical models\nof observables and then analyzes local overidentification through conditional\nmoment restrictions. We apply this approach to three leading models: (i) the\ngeneral treatment model under unconfoundedness, (ii) the negative control\nmodel, and (iii) the long-term causal inference model under unobserved\nconfounding. The first design yields a locally just-identified statistical\nmodel, implying that all regular asymptotically linear estimators of the\ntreatment effect share the same asymptotic variance, equal to the (trivial)\nsemiparametric efficiency bound. In contrast, the latter two models involve\nnonparametric endogeneity and are naturally locally overidentified;\nconsequently, some doubly robust orthogonal moment estimators of the average\ntreatment effect are inefficient. Whereas existing work typically imposes\nstrong conditions to restore just-identification before deriving the efficiency\nbound, we relax such assumptions and characterize the general efficiency bound,\nalong with efficient estimators, in the overidentified models (ii) and (iii).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u975e\u53c2\u6570\u5c40\u90e8\uff08\u8fc7\u5ea6\uff09\u8bc6\u522b\u548c\u534a\u53c2\u6570\u6548\u7387\uff0c\u5f00\u53d1\u4e86\u7edf\u4e00\u65b9\u6cd5\u5206\u6790\u4e09\u79cd\u56e0\u679c\u6a21\u578b\uff1a\u65e0\u6df7\u6742\u7684\u4e00\u822c\u5904\u7406\u6a21\u578b\u3001\u8d1f\u63a7\u5236\u6a21\u578b\u548c\u672a\u89c2\u6d4b\u6df7\u6742\u4e0b\u7684\u957f\u671f\u56e0\u679c\u63a8\u65ad\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u65bd\u52a0\u5f3a\u6761\u4ef6\u6765\u6062\u590d\u6070\u597d\u8bc6\u522b\uff0c\u7136\u540e\u63a8\u5bfc\u6548\u7387\u754c\u9650\u3002\u672c\u6587\u653e\u677e\u8fd9\u4e9b\u5047\u8bbe\uff0c\u5728\u8fc7\u5ea6\u8bc6\u522b\u6a21\u578b\u4e2d\u523b\u753b\u4e00\u822c\u6548\u7387\u754c\u9650\u548c\u6709\u6548\u4f30\u8ba1\u91cf\u3002", "method": "\u5c06\u5177\u6709\u6f5c\u53d8\u91cf\u7684\u7ed3\u6784\u6a21\u578b\u8f6c\u5316\u4e3a\u53ef\u89c2\u6d4b\u53d8\u91cf\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u901a\u8fc7\u6761\u4ef6\u77e9\u9650\u5236\u5206\u6790\u5c40\u90e8\u8fc7\u5ea6\u8bc6\u522b\u3002", "result": "\u7b2c\u4e00\u4e2a\u8bbe\u8ba1\u4ea7\u751f\u5c40\u90e8\u6070\u597d\u8bc6\u522b\u7edf\u8ba1\u6a21\u578b\uff0c\u6240\u6709\u4f30\u8ba1\u91cf\u5171\u4eab\u76f8\u540c\u6e10\u8fd1\u65b9\u5dee\uff1b\u540e\u4e24\u4e2a\u6a21\u578b\u6d89\u53ca\u975e\u53c2\u6570\u5185\u751f\u6027\uff0c\u81ea\u7136\u5c40\u90e8\u8fc7\u5ea6\u8bc6\u522b\uff0c\u5bfc\u81f4\u67d0\u4e9b\u53cc\u91cd\u7a33\u5065\u6b63\u4ea4\u77e9\u4f30\u8ba1\u91cf\u6548\u7387\u4f4e\u4e0b\u3002", "conclusion": "\u5728\u8fc7\u5ea6\u8bc6\u522b\u6a21\u578b(ii)\u548c(iii)\u4e2d\u523b\u753b\u4e86\u4e00\u822c\u6548\u7387\u754c\u9650\u548c\u6709\u6548\u4f30\u8ba1\u91cf\uff0c\u65e0\u9700\u5f3a\u5047\u8bbe\u6761\u4ef6\u3002"}}
{"id": "2510.16205", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16205", "abs": "https://arxiv.org/abs/2510.16205", "authors": ["Jo\u00e3o Carlos Virgolino Soares", "Gabriel Fischer Abati", "Claudio Semini"], "title": "VAR-SLAM: Visual Adaptive and Robust SLAM for Dynamic Environments", "comment": "Code available at https://github.com/iit-DLSLab/VAR-SLAM", "summary": "Visual SLAM in dynamic environments remains challenging, as several existing\nmethods rely on semantic filtering that only handles known object classes, or\nuse fixed robust kernels that cannot adapt to unknown moving objects, leading\nto degraded accuracy when they appear in the scene. We present VAR-SLAM (Visual\nAdaptive and Robust SLAM), an ORB-SLAM3-based system that combines a\nlightweight semantic keypoint filter to deal with known moving objects, with\nBarron's adaptive robust loss to handle unknown ones. The shape parameter of\nthe robust kernel is estimated online from residuals, allowing the system to\nautomatically adjust between Gaussian and heavy-tailed behavior. We evaluate\nVAR-SLAM on the TUM RGB-D, Bonn RGB-D Dynamic, and OpenLORIS datasets, which\ninclude both known and unknown moving objects. Results show improved trajectory\naccuracy and robustness over state-of-the-art baselines, achieving up to 25%\nlower ATE RMSE than NGD-SLAM on challenging sequences, while maintaining\nperformance at 27 FPS on average.", "AI": {"tldr": "VAR-SLAM\u662f\u4e00\u4e2a\u57fa\u4e8eORB-SLAM3\u7684\u89c6\u89c9SLAM\u7cfb\u7edf\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u8bed\u4e49\u5173\u952e\u70b9\u6ee4\u6ce2\u5668\u548c\u81ea\u9002\u5e94\u9c81\u68d2\u635f\u5931\u51fd\u6570\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u8f68\u8ff9\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u73af\u5883\u89c6\u89c9SLAM\u65b9\u6cd5\u4f9d\u8d56\u8bed\u4e49\u6ee4\u6ce2\u53ea\u80fd\u5904\u7406\u5df2\u77e5\u7269\u4f53\u7c7b\u522b\uff0c\u6216\u4f7f\u7528\u56fa\u5b9a\u9c81\u68d2\u6838\u65e0\u6cd5\u9002\u5e94\u672a\u77e5\u79fb\u52a8\u7269\u4f53\uff0c\u5bfc\u81f4\u7cbe\u5ea6\u4e0b\u964d\u3002", "method": "\u7ed3\u5408\u8f7b\u91cf\u7ea7\u8bed\u4e49\u5173\u952e\u70b9\u6ee4\u6ce2\u5668\u5904\u7406\u5df2\u77e5\u79fb\u52a8\u7269\u4f53\uff0c\u4f7f\u7528Barron\u81ea\u9002\u5e94\u9c81\u68d2\u635f\u5931\u5904\u7406\u672a\u77e5\u7269\u4f53\uff0c\u901a\u8fc7\u6b8b\u5dee\u5728\u7ebf\u4f30\u8ba1\u9c81\u68d2\u6838\u7684\u5f62\u72b6\u53c2\u6570\u3002", "result": "\u5728TUM RGB-D\u3001Bonn RGB-D Dynamic\u548cOpenLORIS\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8f68\u8ff9\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u5747\u6709\u63d0\u5347\uff0c\u5728\u6311\u6218\u6027\u5e8f\u5217\u4e0a\u6bd4NGD-SLAM\u964d\u4f4e25% ATE RMSE\uff0c\u5e73\u5747\u6027\u80fd27 FPS\u3002", "conclusion": "VAR-SLAM\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5df2\u77e5\u548c\u672a\u77e5\u79fb\u52a8\u7269\u4f53\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002"}}
{"id": "2510.16050", "categories": ["cs.CY", "97B40"], "pdf": "https://arxiv.org/pdf/2510.16050", "abs": "https://arxiv.org/abs/2510.16050", "authors": ["Abrar Mahbub", "Humira Saria", "Md. Foysal Hossain", "Nafees Mansoor"], "title": "A Framework For Decentralized Micro-credential Verification Towards Higher Qualifications", "comment": "This work represents an early exploratory version of a project later\n  expanded and published in a different form. It focuses on a different\n  technology and experimental approach than the final publication", "summary": "Student retention is one of the rising problems seen in educational\ninstitutions. With the rising cost of education and issues in the education\nsector, such as curriculum relevance, student engagement, and rapidly changing\ntechnological advancements, ensuring the relevance of academic programs in a\nfast-evolving job market has created a significant concern for educational\ninstitutions. With the intent to adapt to such challenges, educational\ninstitutions are dealing with alternative solutions for education, in which\nmicro-credentials are at the very center of this, which are short-term academic\nprograms or standalone courses. However, one of the challenges of\nmicro-credentials is a lack of credit transfer among institutions. With the\nlack of standardization of assessments among educational institutions, it is\ndifficult to transfer micro-credentials to larger qualifications. Regarding\nsuch challenges, micro-credentials with blockchain technology can bring\nsignificant benefits. Blockchain technology offers a decentralized and\nimmutable platform for securely storing and verifying credentials. This paper\npresents a prototype model for micro-credential verification. With the policies\ndecided by the educational institution, the learner provides a micro-credential\ncertificate to the system. Upon validation of the certificate by the verifying\nbody, the educational institution will review the assessment criteria and\nprovide exemptions based on the provided criteria. The prototype uses the\nHyper-ledger Fabric platform and utilizes off-chain technology, which acts as a\nmiddle-man storage platform. With the combination of off-chain and on-chain\ntechnologies, congestion on the blockchain is reduced, and transaction speed is\nimproved. In summary, this research proposes a prototype for secure\nmicro-credential verification and a more efficient course exemption process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u6280\u672f\u7684\u5fae\u8bc1\u4e66\u9a8c\u8bc1\u539f\u578b\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u6559\u80b2\u673a\u6784\u95f4\u5fae\u8bc1\u4e66\u5b66\u5206\u8f6c\u79fb\u7684\u6807\u51c6\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u94fe\u4e0a\u548c\u94fe\u4e0b\u6280\u672f\u63d0\u9ad8\u9a8c\u8bc1\u6548\u7387\u3002", "motivation": "\u6559\u80b2\u673a\u6784\u9762\u4e34\u5b66\u751f\u4fdd\u7559\u7387\u4e0b\u964d\u3001\u8bfe\u7a0b\u76f8\u5173\u6027\u3001\u5b66\u751f\u53c2\u4e0e\u5ea6\u7b49\u95ee\u9898\uff0c\u5fae\u8bc1\u4e66\u4f5c\u4e3a\u77ed\u671f\u5b66\u672f\u9879\u76ee\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u5b66\u5206\u8f6c\u79fb\u673a\u5236\uff0c\u533a\u5757\u94fe\u6280\u672f\u53ef\u63d0\u4f9b\u53bb\u4e2d\u5fc3\u5316\u3001\u4e0d\u53ef\u7be1\u6539\u7684\u51ed\u8bc1\u9a8c\u8bc1\u5e73\u53f0\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eHyper-ledger Fabric\u5e73\u53f0\u7684\u5fae\u8bc1\u4e66\u9a8c\u8bc1\u539f\u578b\uff0c\u91c7\u7528\u94fe\u4e0b\u6280\u672f\u4f5c\u4e3a\u4e2d\u95f4\u5b58\u50a8\u5e73\u53f0\uff0c\u7ed3\u5408\u94fe\u4e0a\u548c\u94fe\u4e0b\u6280\u672f\u51cf\u5c11\u533a\u5757\u94fe\u62e5\u5835\uff0c\u63d0\u9ad8\u4ea4\u6613\u901f\u5ea6\u3002\u6559\u80b2\u673a\u6784\u6839\u636e\u653f\u7b56\u9a8c\u8bc1\u5fae\u8bc1\u4e66\u8bc1\u4e66\uff0c\u5ba1\u6838\u8bc4\u4f30\u6807\u51c6\u5e76\u63d0\u4f9b\u8bfe\u7a0b\u8c41\u514d\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u5fae\u8bc1\u4e66\u7684\u5b89\u5168\u9a8c\u8bc1\u548c\u66f4\u9ad8\u6548\u7684\u8bfe\u7a0b\u8c41\u514d\u6d41\u7a0b\uff0c\u901a\u8fc7\u94fe\u4e0b\u5b58\u50a8\u6280\u672f\u7f13\u89e3\u4e86\u533a\u5757\u94fe\u62e5\u5835\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u4ea4\u6613\u5904\u7406\u901f\u5ea6\u3002", "conclusion": "\u533a\u5757\u94fe\u6280\u672f\u4e3a\u5fae\u8bc1\u4e66\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u94fe\u4e0a\u548c\u94fe\u4e0b\u6280\u672f\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6559\u80b2\u673a\u6784\u95f4\u5b66\u5206\u8f6c\u79fb\u7684\u6807\u51c6\u5316\u6311\u6218\uff0c\u4e3a\u5fae\u8bc1\u4e66\u7684\u5e7f\u6cdb\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.16451", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16451", "abs": "https://arxiv.org/abs/2510.16451", "authors": ["Lidong Li", "Rui Huang", "Lin Zhao"], "title": "Stabilization of Nonlinear Systems with State-Dependent Representation: From Model-Based to Direct Data-Driven Control", "comment": null, "summary": "This paper presents a novel framework for stabilizing nonlinear systems\nrepresented in state-dependent form. We first reformulate the nonlinear\ndynamics as a state-dependent parameter-varying model and synthesize a\nstabilizing controller offline via tractable linear matrix inequalities (LMIs).\nThe resulting controller guarantees local exponential stability, maintains\nrobustness against disturbances, and provides an estimate of the region of\nattraction under input saturation. We then extend the formulation to the direct\ndata-driven setting, where a known library of basis functions represents the\ndynamics with unknown coefficients consistent with noisy experimental data. By\nleveraging Petersen's lemma, we derive data-dependent LMIs that ensure\nstability and robustness for all systems compatible with the data. Numerical\nand physical experimental results validate that our approach achieves rigorous\nend-to-end guarantees on stability, robustness, and safety directly from finite\ndata without explicit model identification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7a33\u5b9a\u72b6\u6001\u4f9d\u8d56\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u72b6\u6001\u4f9d\u8d56\u53c2\u6570\u53d8\u5316\u6a21\u578b\u548cLMI\u5408\u6210\u63a7\u5236\u5668\uff0c\u4fdd\u8bc1\u5c40\u90e8\u6307\u6570\u7a33\u5b9a\u6027\u3001\u9c81\u68d2\u6027\u548c\u5438\u5f15\u57df\u4f30\u8ba1\uff0c\u5e76\u6269\u5c55\u5230\u6570\u636e\u9a71\u52a8\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u975e\u7ebf\u6027\u7cfb\u7edf\u7a33\u5b9a\u65b9\u6cd5\u9700\u8981\u7cbe\u786e\u6a21\u578b\uff0c\u800c\u5b9e\u9645\u7cfb\u7edf\u5f80\u5f80\u5b58\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u566a\u58f0\u6570\u636e\uff0c\u9700\u8981\u76f4\u63a5\u4ece\u6709\u9650\u6570\u636e\u4e2d\u83b7\u5f97\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002", "method": "\u5c06\u975e\u7ebf\u6027\u7cfb\u7edf\u91cd\u6784\u4e3a\u72b6\u6001\u4f9d\u8d56\u53c2\u6570\u53d8\u5316\u6a21\u578b\uff0c\u79bb\u7ebf\u5408\u6210LMI\u63a7\u5236\u5668\uff1b\u6269\u5c55\u5230\u6570\u636e\u9a71\u52a8\u8bbe\u7f6e\uff0c\u5229\u7528Petersen\u5f15\u7406\u63a8\u5bfc\u6570\u636e\u4f9d\u8d56LMI\uff0c\u786e\u4fdd\u4e0e\u6570\u636e\u517c\u5bb9\u7684\u6240\u6709\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u3002", "result": "\u6570\u503c\u548c\u7269\u7406\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u76f4\u63a5\u4ece\u6709\u9650\u6570\u636e\u4e2d\u83b7\u5f97\u4e25\u683c\u7684\u7aef\u5230\u7aef\u7a33\u5b9a\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u4fdd\u8bc1\uff0c\u65e0\u9700\u663e\u5f0f\u6a21\u578b\u8fa8\u8bc6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u7a33\u5b9a\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u548c\u6570\u636e\u566a\u58f0\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.16886", "categories": ["econ.EM", "stat.CO"], "pdf": "https://arxiv.org/pdf/2510.16886", "abs": "https://arxiv.org/abs/2510.16886", "authors": ["Hung Tran", "Tien Mai", "Minh Hoang Ha"], "title": "Equilibrium-Constrained Estimation of Recursive Logit Choice Models", "comment": null, "summary": "The recursive logit (RL) model provides a flexible framework for modeling\nsequential decision-making in transportation and choice networks, with\nimportant applications in route choice analysis, multiple discrete choice\nproblems, and activity-based travel demand modeling. Despite its versatility,\nestimation of the RL model typically relies on nested fixed-point (NFXP)\nalgorithms that are computationally expensive and prone to numerical\ninstability. We propose a new approach that reformulates the maximum likelihood\nestimation problem as an optimization problem with equilibrium constraints,\nwhere both the structural parameters and the value functions are treated as\ndecision variables. We further show that this formulation can be equivalently\ntransformed into a conic optimization problem with exponential cones, enabling\nefficient solution using modern conic solvers such as MOSEK. Experiments on\nsynthetic and real-world datasets demonstrate that our convex reformulation\nachieves accuracy comparable to traditional methods while offering significant\nimprovements in computational stability and efficiency, thereby providing a\npractical and scalable alternative for recursive logit model estimation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u9012\u5f52logit\u6a21\u578b\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5c06\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u91cd\u65b0\u8868\u8ff0\u4e3a\u5e26\u5747\u8861\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u9525\u4f18\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5d4c\u5957\u56fa\u5b9a\u70b9\u7b97\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6570\u503c\u4e0d\u7a33\u5b9a\uff0c\u9650\u5236\u4e86\u9012\u5f52logit\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5c06\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u91cd\u65b0\u8868\u8ff0\u4e3a\u5e26\u5747\u8861\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5c06\u7ed3\u6784\u53c2\u6570\u548c\u4ef7\u503c\u51fd\u6570\u90fd\u4f5c\u4e3a\u51b3\u7b56\u53d8\u91cf\uff0c\u5e76\u8f6c\u5316\u4e3a\u9525\u4f18\u5316\u95ee\u9898\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9012\u5f52logit\u6a21\u578b\u4f30\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.16231", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16231", "abs": "https://arxiv.org/abs/2510.16231", "authors": ["Bihao Zhang", "Davood Soleymanzadeh", "Xiao Liang", "Minghui Zheng"], "title": "DeGrip: A Compact Cable-driven Robotic Gripper for Desktop Disassembly", "comment": null, "summary": "Intelligent robotic disassembly of end-of-life (EOL) products has been a\nlong-standing challenge in robotics. While machine learning techniques have\nshown promise, the lack of specialized hardware limits their application in\nreal-world scenarios. We introduce DeGrip, a customized gripper designed for\nthe disassembly of EOL computer desktops. DeGrip provides three degrees of\nfreedom (DOF), enabling arbitrary configurations within the disassembly\nenvironment when mounted on a robotic manipulator. It employs a cable-driven\ntransmission mechanism that reduces its overall size and enables operation in\nconfined spaces. The wrist is designed to decouple the actuation of wrist and\njaw joints. We also developed an EOL desktop disassembly environment in Isaac\nSim to evaluate the effectiveness of DeGrip. The tasks were designed to\ndemonstrate its ability to operate in confined spaces and disassemble\ncomponents in arbitrary configurations. The evaluation results confirm the\ncapability of DeGrip for EOL desktop disassembly.", "AI": {"tldr": "DeGrip\u662f\u4e00\u79cd\u4e13\u4e3a\u62c6\u89e3\u62a5\u5e9f\u7535\u8111\u53f0\u5f0f\u673a\u8bbe\u8ba1\u7684\u5b9a\u5236\u5939\u722a\uff0c\u5177\u67093\u4e2a\u81ea\u7531\u5ea6\uff0c\u91c7\u7528\u7ebf\u7f06\u9a71\u52a8\u673a\u5236\uff0c\u53ef\u5728\u53d7\u9650\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u5e76\u5728Isaac Sim\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u667a\u80fd\u673a\u5668\u4eba\u62c6\u89e3\u62a5\u5e9f\u4ea7\u54c1\u662f\u673a\u5668\u4eba\u9886\u57df\u7684\u957f\u671f\u6311\u6218\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u4e13\u7528\u786c\u4ef6\u800c\u96be\u4ee5\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u5e94\u7528\u3002", "method": "\u5f00\u53d1DeGrip\u5b9a\u5236\u5939\u722a\uff0c\u63d0\u4f9b3\u4e2a\u81ea\u7531\u5ea6\uff0c\u91c7\u7528\u7ebf\u7f06\u9a71\u52a8\u4f20\u8f93\u673a\u5236\u51cf\u5c0f\u5c3a\u5bf8\uff0c\u8bbe\u8ba1\u8155\u90e8\u89e3\u8026\u8155\u5173\u8282\u548c\u5939\u722a\u5173\u8282\u7684\u9a71\u52a8\uff0c\u5e76\u5728Isaac Sim\u4e2d\u5efa\u7acb\u62c6\u89e3\u73af\u5883\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8bc1\u5b9eDeGrip\u80fd\u591f\u5728\u53d7\u9650\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u5e76\u80fd\u62c6\u89e3\u4efb\u610f\u914d\u7f6e\u7684\u7ec4\u4ef6\uff0c\u5177\u5907\u62c6\u89e3\u62a5\u5e9f\u53f0\u5f0f\u673a\u7684\u80fd\u529b\u3002", "conclusion": "DeGrip\u5939\u722a\u6210\u529f\u89e3\u51b3\u4e86\u62a5\u5e9f\u4ea7\u54c1\u62c6\u89e3\u4e2d\u7684\u786c\u4ef6\u9650\u5236\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4e13\u7528\u5de5\u5177\u3002"}}
{"id": "2510.17798", "categories": ["eess.SY", "cs.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.17798", "abs": "https://arxiv.org/abs/2510.17798", "authors": ["Samuel Talkington", "Cameron Khanpour", "Rahul K. Gupta", "Sergio A. Dorado-Rojas", "Daniel Turizo", "Hyeongon Park", "Dmitrii M. Ostrovskii", "Daniel K. Molzahn"], "title": "Admittance Matrix Concentration Inequalities for Understanding Uncertain Power Networks", "comment": "9 pages, 1 figure", "summary": "This paper presents probabilistic bounds for the spectrum of the admittance\nmatrix and classical linear power flow models under uncertain network\nparameters; for example, probabilistic line contingencies. Our proposed\napproach imports tools from probability theory, such as concentration\ninequalities for random matrices with independent entries. It yields error\nbounds for common approximations of the AC power flow equations under parameter\nuncertainty, including the DC and LinDistFlow approximations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5728\u4e0d\u786e\u5b9a\u7f51\u7edc\u53c2\u6570\u4e0b\uff0c\u5bfc\u7eb3\u77e9\u9635\u8c31\u548c\u7ecf\u5178\u7ebf\u6027\u6f6e\u6d41\u6a21\u578b\u7684\u6982\u7387\u8fb9\u754c\u5206\u6790\u65b9\u6cd5", "motivation": "\u5904\u7406\u7535\u529b\u7cfb\u7edf\u4e2d\u4e0d\u786e\u5b9a\u7f51\u7edc\u53c2\u6570\uff08\u5982\u6982\u7387\u6027\u7ebf\u8def\u6545\u969c\uff09\u5bf9\u6f6e\u6d41\u6a21\u578b\u51c6\u786e\u6027\u7684\u5f71\u54cd", "method": "\u91c7\u7528\u6982\u7387\u8bba\u5de5\u5177\uff0c\u7279\u522b\u662f\u5177\u6709\u72ec\u7acb\u6761\u76ee\u7684\u968f\u673a\u77e9\u9635\u7684\u96c6\u4e2d\u4e0d\u7b49\u5f0f", "result": "\u5f97\u5230\u4e86\u5728\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u4e0bAC\u6f6e\u6d41\u65b9\u7a0b\u5e38\u89c1\u8fd1\u4f3c\uff08\u5305\u62ecDC\u548cLinDistFlow\u8fd1\u4f3c\uff09\u7684\u8bef\u5dee\u8fb9\u754c", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7535\u529b\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u6570\u5b66\u4e25\u8c28\u7684\u6982\u7387\u8fb9\u754c"}}
{"id": "2510.16052", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16052", "abs": "https://arxiv.org/abs/2510.16052", "authors": ["Alice Gao", "Victoria Sakhnini"], "title": "Reducing Procrastination on Programming Assignments via Optional Early Feedback", "comment": "8 pages. 3 Tables", "summary": "Academic procrastination is prevalent among undergraduate computer science\nstudents. Many studies have linked procrastination to poor academic performance\nand well-being. Procrastination is especially detrimental for advanced students\nwhen facing large, complex programming assignments in upper-year courses. We\ndesigned an intervention to combat academic procrastination on such programming\nassignments. The intervention consisted of early deadlines that were not worth\nmarks but provided additional automated feedback if students submitted their\nwork early. We evaluated the intervention by comparing the behaviour and\nperformance of students between a control group and an intervention group. Our\nresults showed that the intervention encouraged significantly more students to\nstart the assignments early. Although there was no significant difference in\nstudents' grades between the control and intervention groups, students within\nthe intervention group who used the intervention achieved significantly higher\ngrades than those who did not. Our results implied that starting early alone\ndid not improve students' grades. However, starting early and receiving\nadditional feedback enhanced the students' grades relative to those of the rest\nof the students. We also conducted semi-structured interviews to gain an\nunderstanding of students' perceptions of the intervention. The interviews\nrevealed that students benefited from the intervention in numerous ways,\nincluding improved academic performance, mental health, and development of soft\nskills. Students adopted the intervention to get more feedback, satisfy their\ncuriosity, or use their available time. The main reasons for not adopting the\nintervention include having other competing deadlines, the intervention not\nbeing worth any marks, and feeling confident about their work.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u901a\u8fc7\u65e9\u671f\u975e\u8bc4\u5206\u622a\u6b62\u65e5\u671f\u63d0\u4f9b\u989d\u5916\u81ea\u52a8\u53cd\u9988\u7684\u5e72\u9884\u63aa\u65bd\uff0c\u6765\u5bf9\u6297\u8ba1\u7b97\u673a\u79d1\u5b66\u672c\u79d1\u751f\u5728\u590d\u6742\u7f16\u7a0b\u4f5c\u4e1a\u4e2d\u7684\u5b66\u672f\u62d6\u5ef6\u884c\u4e3a\u3002\u5e72\u9884\u663e\u8457\u589e\u52a0\u4e86\u5b66\u751f\u65e9\u671f\u5f00\u59cb\u4f5c\u4e1a\u7684\u6bd4\u4f8b\uff0c\u867d\u7136\u6574\u4f53\u6210\u7ee9\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u4f7f\u7528\u5e72\u9884\u7684\u5b66\u751f\u6bd4\u672a\u4f7f\u7528\u8005\u6210\u7ee9\u66f4\u9ad8\u3002", "motivation": "\u5b66\u672f\u62d6\u5ef6\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u672c\u79d1\u751f\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u5c24\u5176\u5bf9\u9ad8\u5e74\u7ea7\u5b66\u751f\u9762\u5bf9\u5927\u578b\u590d\u6742\u7f16\u7a0b\u4f5c\u4e1a\u65f6\u5371\u5bb3\u66f4\u5927\uff0c\u4f1a\u5bfc\u81f4\u5b66\u4e1a\u6210\u7ee9\u548c\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5e72\u9884\u63aa\u65bd\uff1a\u8bbe\u7f6e\u65e9\u671f\u975e\u8bc4\u5206\u622a\u6b62\u65e5\u671f\uff0c\u63d0\u524d\u63d0\u4ea4\u53ef\u83b7\u5f97\u989d\u5916\u81ea\u52a8\u53cd\u9988\u3002\u901a\u8fc7\u5bf9\u7167\u7ec4\u4e0e\u5e72\u9884\u7ec4\u7684\u6bd4\u8f83\u8bc4\u4f30\u6548\u679c\uff0c\u5e76\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u4e86\u89e3\u5b66\u751f\u611f\u77e5\u3002", "result": "\u5e72\u9884\u663e\u8457\u589e\u52a0\u4e86\u65e9\u671f\u5f00\u59cb\u4f5c\u4e1a\u7684\u5b66\u751f\u6bd4\u4f8b\u3002\u5e72\u9884\u7ec4\u5185\u4f7f\u7528\u5e72\u9884\u7684\u5b66\u751f\u6210\u7ee9\u663e\u8457\u9ad8\u4e8e\u672a\u4f7f\u7528\u8005\u3002\u8bbf\u8c08\u663e\u793a\u5b66\u751f\u4ece\u5e72\u9884\u4e2d\u83b7\u76ca\uff0c\u5305\u62ec\u5b66\u4e1a\u8868\u73b0\u3001\u5fc3\u7406\u5065\u5eb7\u548c\u8f6f\u6280\u80fd\u63d0\u5347\u3002", "conclusion": "\u4ec5\u65e9\u671f\u5f00\u59cb\u4f5c\u4e1a\u4e0d\u80fd\u63d0\u9ad8\u6210\u7ee9\uff0c\u4f46\u65e9\u671f\u5f00\u59cb\u5e76\u63a5\u6536\u989d\u5916\u53cd\u9988\u80fd\u663e\u8457\u63d0\u5347\u6210\u7ee9\u3002\u5b66\u751f\u91c7\u7528\u5e72\u9884\u7684\u4e3b\u8981\u52a8\u673a\u662f\u83b7\u53d6\u66f4\u591a\u53cd\u9988\u3001\u6ee1\u8db3\u597d\u5947\u5fc3\u548c\u5229\u7528\u53ef\u7528\u65f6\u95f4\uff0c\u4e0d\u91c7\u7528\u7684\u4e3b\u8981\u539f\u56e0\u662f\u5176\u4ed6\u622a\u6b62\u65e5\u671f\u51b2\u7a81\u3001\u5e72\u9884\u4e0d\u8ba1\u5206\u548c\u81ea\u4fe1\u8fc7\u5ea6\u3002"}}
{"id": "2510.16534", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16534", "abs": "https://arxiv.org/abs/2510.16534", "authors": ["Christoph Kaufmann", "Georg Pangalos", "Gerwald Lichtenberg", "Oriol Gomis-Bellmunt"], "title": "Small-Signal Stability Analysis of Power Systems by Implicit Multilinear Models", "comment": null, "summary": "This paper proposes a new approach to perform small-signal stability analysis\nbased on linearization of implicit multilinear models. Multilinear models\ndescribe the system dynamics by multilinear functions of state, input, and\nalgebraic variables. Using suitable transformations of variables, they can also\nrepresent trigonometric functions, which often occur in power systems modeling.\nThis allows tensor representations of grid-following and grid-forming power\nconverters. This paper introduces small-signal stability analysis of\nequilibrium points based on implicit multilinear models using generalized\neigenvalues. The generalized eigenvalues are computed from linear descriptor\nmodels of the linearized implicit multilinear model. The proposed approach is\ntested using a 3-bus network example, first by comparing time-domain\nsimulations of the implicit multilinear model with those of the nonlinear\nmodel, and second by comparing the generalized eigenvalues with those of the\nlinearized nonlinear model. The results show that the decomposed tensor\nrepresentation of the implicit multilinear model allows for a faster\nlinearization compared to conventional methods in MATLAB Simulink.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9690\u5f0f\u591a\u7ebf\u6027\u6a21\u578b\u7ebf\u6027\u5316\u7684\u5c0f\u4fe1\u53f7\u7a33\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u4f7f\u7528\u5e7f\u4e49\u7279\u5f81\u503c\u5206\u6790\u5e73\u8861\u70b9\u7a33\u5b9a\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728MATLAB Simulink\u4e2d\u80fd\u66f4\u5feb\u5b8c\u6210\u7ebf\u6027\u5316\u3002", "motivation": "\u591a\u7ebf\u6027\u6a21\u578b\u80fd\u591f\u63cf\u8ff0\u7cfb\u7edf\u52a8\u6001\uff0c\u5e76\u80fd\u901a\u8fc7\u53d8\u91cf\u53d8\u6362\u8868\u793a\u7535\u529b\u7cfb\u7edf\u5efa\u6a21\u4e2d\u5e38\u89c1\u7684\u4e09\u89d2\u51fd\u6570\uff0c\u4e3a\u7535\u7f51\u8ddf\u968f\u548c\u7535\u7f51\u5f62\u6210\u529f\u7387\u53d8\u6362\u5668\u63d0\u4f9b\u5f20\u91cf\u8868\u793a\u3002", "method": "\u57fa\u4e8e\u9690\u5f0f\u591a\u7ebf\u6027\u6a21\u578b\u7684\u7ebf\u6027\u5316\u63cf\u8ff0\u7b26\u6a21\u578b\u8ba1\u7b97\u5e7f\u4e49\u7279\u5f81\u503c\uff0c\u901a\u8fc73\u603b\u7ebf\u7f51\u7edc\u6848\u4f8b\u4e0e\u975e\u7ebf\u6027\u6a21\u578b\u8fdb\u884c\u65f6\u57df\u4eff\u771f\u548c\u7279\u5f81\u503c\u6bd4\u8f83\u9a8c\u8bc1\u3002", "result": "\u9690\u5f0f\u591a\u7ebf\u6027\u6a21\u578b\u7684\u5206\u89e3\u5f20\u91cf\u8868\u793a\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728MATLAB Simulink\u4e2d\u80fd\u66f4\u5feb\u5b8c\u6210\u7ebf\u6027\u5316\uff0c\u4e14\u4e0e\u65f6\u57df\u4eff\u771f\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5c0f\u4fe1\u53f7\u7a33\u5b9a\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5305\u542b\u4e09\u89d2\u51fd\u6570\u7684\u7535\u529b\u7cfb\u7edf\u5efa\u6a21\u3002"}}
{"id": "2510.17070", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.17070", "abs": "https://arxiv.org/abs/2510.17070", "authors": ["Jean-Marie Dufour", "Purevdorj Tuvaandorj"], "title": "Mixed LR-$C(\u03b1)$-type tests for irregular hypotheses, general criterion functions and misspecified models", "comment": "28 pages, 1 figure, 4 tables", "summary": "This paper introduces a likelihood ratio (LR)-type test that possesses the\nrobustness properties of \\(C(\\alpha)\\)-type procedures in an extremum\nestimation setting.\n  The test statistic is constructed by applying separate adjustments to the\nrestricted and unrestricted criterion functions, and is shown to be\nasymptotically pivotal under minimal conditions. It features two main\nrobustness properties. First, unlike standard LR-type statistics, its null\nasymptotic distribution remains chi-square even under model misspecification,\nwhere the information matrix equality fails. Second, it accommodates irregular\nhypotheses involving constrained parameter spaces, such as boundary parameters,\nrelying solely on root-\\(n\\)-consistent estimators for nuisance parameters.\nWhen the model is correctly specified, no boundary constraints are present, and\nparameters are estimated by extremum estimators, the proposed test reduces to\nthe standard LR-type statistic.\n  Simulations with ARCH models, where volatility parameters are constrained to\nbe nonnegative, and parametric survival regressions with potentially monotone\nincreasing hazard functions, demonstrate that our test maintains accurate size\nand exhibits good power. An empirical application to a two-way error components\nmodel shows that the proposed test can provide more informative inference than\nthe conventional \\(t\\)-test.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5177\u6709\u7a33\u5065\u6027\u7684\u4f3c\u7136\u6bd4\u578b\u68c0\u9a8c\uff0c\u5728\u6781\u503c\u4f30\u8ba1\u6846\u67b6\u4e0b\u4fdd\u6301\u5361\u65b9\u5206\u5e03\uff0c\u5373\u4f7f\u6a21\u578b\u8bef\u8bbe\u6216\u53c2\u6570\u7a7a\u95f4\u53d7\u9650\u65f6\u4ecd\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u6807\u51c6LR\u68c0\u9a8c\u5728\u6a21\u578b\u8bef\u8bbe\uff08\u4fe1\u606f\u77e9\u9635\u7b49\u5f0f\u4e0d\u6210\u7acb\uff09\u548c\u53c2\u6570\u7a7a\u95f4\u53d7\u9650\uff08\u5982\u8fb9\u754c\u53c2\u6570\uff09\u60c5\u51b5\u4e0b\u7684\u5931\u6548\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5bf9\u53d7\u9650\u548c\u4e0d\u53d7\u9650\u51c6\u5219\u51fd\u6570\u5206\u522b\u8fdb\u884c\u8c03\u6574\u6765\u6784\u5efa\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff0c\u4ec5\u9700\u6839\u53f7n\u4e00\u81f4\u7684\u4f30\u8ba1\u91cf\u6765\u5904\u7406\u4e0d\u89c4\u5219\u5047\u8bbe\u3002", "result": "\u6a21\u62df\u663e\u793a\u5728ARCH\u6a21\u578b\u548c\u751f\u5b58\u56de\u5f52\u4e2d\uff0c\u8be5\u68c0\u9a8c\u80fd\u4fdd\u6301\u51c6\u786e\u5c3a\u5bf8\u5e76\u5177\u6709\u826f\u597d\u529f\u6548\uff1b\u5b9e\u8bc1\u5e94\u7528\u8868\u660e\u6bd4\u4f20\u7edft\u68c0\u9a8c\u63d0\u4f9b\u66f4\u4e30\u5bcc\u4fe1\u606f\u3002", "conclusion": "\u63d0\u51fa\u7684LR\u578b\u68c0\u9a8c\u5177\u6709\u7a33\u5065\u6027\uff0c\u80fd\u5728\u6a21\u578b\u8bef\u8bbe\u548c\u53c2\u6570\u7a7a\u95f4\u53d7\u9650\u60c5\u51b5\u4e0b\u4fdd\u6301\u6709\u6548\u6027\uff0c\u4e3a\u590d\u6742\u5047\u8bbe\u68c0\u9a8c\u63d0\u4f9b\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2510.16240", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16240", "abs": "https://arxiv.org/abs/2510.16240", "authors": ["Lukas Zbinden", "Nigel Nelson", "Juo-Tung Chen", "Xinhao Chen", "Ji Woong", "Kim", "Mahdi Azizian", "Axel Krieger", "Sean Huver"], "title": "Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning", "comment": null, "summary": "The rise of surgical robots and vision-language-action models has accelerated\nthe development of autonomous surgical policies and efficient assessment\nstrategies. However, evaluating these policies directly on physical robotic\nplatforms such as the da Vinci Research Kit (dVRK) remains hindered by high\ncosts, time demands, reproducibility challenges, and variability in execution.\nWorld foundation models (WFM) for physical AI offer a transformative approach\nto simulate complex real-world surgical tasks, such as soft tissue deformation,\nwith high fidelity. This work introduces Cosmos-Surg-dVRK, a surgical finetune\nof the Cosmos WFM, which, together with a trained video classifier, enables\nfully automated online evaluation and benchmarking of surgical policies. We\nevaluate Cosmos-Surg-dVRK using two distinct surgical datasets. On tabletop\nsuture pad tasks, the automated pipeline achieves strong correlation between\nonline rollouts in Cosmos-Surg-dVRK and policy outcomes on the real dVRK Si\nplatform, as well as good agreement between human labelers and the V-JEPA\n2-derived video classifier. Additionally, preliminary experiments with ex-vivo\nporcine cholecystectomy tasks in Cosmos-Surg-dVRK demonstrate promising\nalignment with real-world evaluations, highlighting the platform's potential\nfor more complex surgical procedures.", "AI": {"tldr": "Cosmos-Surg-dVRK\u662f\u4e00\u4e2a\u57fa\u4e8eCosmos\u4e16\u754c\u57fa\u7840\u6a21\u578b\u7684\u5916\u79d1\u624b\u672f\u5fae\u8c03\u6a21\u578b\uff0c\u7ed3\u5408\u89c6\u9891\u5206\u7c7b\u5668\uff0c\u5b9e\u73b0\u4e86\u624b\u672f\u7b56\u7565\u7684\u81ea\u52a8\u5316\u5728\u7ebf\u8bc4\u4f30\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u7f1d\u5408\u4efb\u52a1\u548c\u80c6\u56ca\u5207\u9664\u672f\u4efb\u52a1\u4e2d\u663e\u793a\u51fa\u4e0e\u771f\u5b9e\u624b\u672f\u673a\u5668\u4eba\u5e73\u53f0\u7684\u826f\u597d\u76f8\u5173\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u7269\u7406\u673a\u5668\u4eba\u5e73\u53f0\uff08\u5982dVRK\uff09\u4e0a\u76f4\u63a5\u8bc4\u4f30\u624b\u672f\u7b56\u7565\u65f6\u9762\u4e34\u7684\u9ad8\u6210\u672c\u3001\u65f6\u95f4\u6d88\u8017\u3001\u53ef\u91cd\u590d\u6027\u6311\u6218\u548c\u6267\u884c\u53d8\u5f02\u6027\u7b49\u95ee\u9898\u3002", "method": "\u5f00\u53d1Cosmos-Surg-dVRK\uff08Cosmos\u4e16\u754c\u57fa\u7840\u6a21\u578b\u7684\u5916\u79d1\u624b\u672f\u5fae\u8c03\u7248\u672c\uff09\uff0c\u7ed3\u5408\u8bad\u7ec3\u7684\u89c6\u9891\u5206\u7c7b\u5668\uff0c\u6784\u5efa\u81ea\u52a8\u5316\u8bc4\u4f30\u7ba1\u9053\u3002\u5728\u7f1d\u5408\u57ab\u4efb\u52a1\u548c\u79bb\u4f53\u732a\u80c6\u56ca\u5207\u9664\u672f\u4efb\u52a1\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u7f1d\u5408\u57ab\u4efb\u52a1\u4e2d\uff0cCosmos-Surg-dVRK\u5728\u7ebf\u63a8\u6f14\u4e0e\u771f\u5b9edVRK Si\u5e73\u53f0\u7ed3\u679c\u5177\u6709\u5f3a\u76f8\u5173\u6027\uff1b\u89c6\u9891\u5206\u7c7b\u5668\u4e0e\u4eba\u5de5\u6807\u6ce8\u8005\u8fbe\u6210\u826f\u597d\u4e00\u81f4\u6027\u3002\u5728\u80c6\u56ca\u5207\u9664\u672f\u4efb\u52a1\u4e2d\uff0c\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\u4e0e\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\u6709\u826f\u597d\u5bf9\u9f50\u3002", "conclusion": "Cosmos-Surg-dVRK\u5e73\u53f0\u4e3a\u590d\u6742\u5916\u79d1\u624b\u672f\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u66ff\u4ee3\u6602\u8d35\u7684\u7269\u7406\u673a\u5668\u4eba\u5e73\u53f0\u6d4b\u8bd5\u3002"}}
{"id": "2510.16056", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16056", "abs": "https://arxiv.org/abs/2510.16056", "authors": ["Muhammad Aurangzeb Ahmad"], "title": "Algorithmic Fairness in AI Surrogates for End-of-Life Decision-Making", "comment": null, "summary": "Artificial intelligence surrogates are systems designed to infer preferences\nwhen individuals lose decision-making capacity. Fairness in such systems is a\ndomain that has been insufficiently explored. Traditional algorithmic fairness\nframeworks are insufficient for contexts where decisions are relational,\nexistential, and culturally diverse. This paper explores an ethical framework\nfor algorithmic fairness in AI surrogates by mapping major fairness notions\nonto potential real-world end-of-life scenarios. It then examines fairness\nacross moral traditions. The authors argue that fairness in this domain extends\nbeyond parity of outcomes to encompass moral representation, fidelity to the\npatient's values, relationships, and worldview.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u4ee3\u7406\u7cfb\u7edf\u5728\u4e34\u7ec8\u51b3\u7b56\u4e2d\u7684\u516c\u5e73\u6027\u6846\u67b6\uff0c\u6307\u51fa\u4f20\u7edf\u7b97\u6cd5\u516c\u5e73\u6027\u65b9\u6cd5\u5728\u6b64\u7c7b\u5173\u7cfb\u6027\u3001\u5b58\u5728\u6027\u548c\u6587\u5316\u591a\u6837\u6027\u51b3\u7b56\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "AI\u4ee3\u7406\u7cfb\u7edf\u7528\u4e8e\u5728\u4e2a\u4eba\u5931\u53bb\u51b3\u7b56\u80fd\u529b\u65f6\u63a8\u65ad\u5176\u504f\u597d\uff0c\u4f46\u8be5\u9886\u57df\u7684\u516c\u5e73\u6027\u95ee\u9898\u7814\u7a76\u4e0d\u8db3\u3002\u4f20\u7edf\u7b97\u6cd5\u516c\u5e73\u6027\u6846\u67b6\u65e0\u6cd5\u5904\u7406\u5173\u7cfb\u6027\u3001\u5b58\u5728\u6027\u548c\u6587\u5316\u591a\u6837\u6027\u51b3\u7b56\u7684\u590d\u6742\u6027\u3002", "method": "\u901a\u8fc7\u5c06\u4e3b\u8981\u516c\u5e73\u6027\u6982\u5ff5\u6620\u5c04\u5230\u73b0\u5b9e\u4e16\u754c\u4e34\u7ec8\u573a\u666f\uff0c\u5e76\u8de8\u9053\u5fb7\u4f20\u7edf\u68c0\u9a8c\u516c\u5e73\u6027\uff0c\u5efa\u7acbAI\u4ee3\u7406\u7684\u4f26\u7406\u516c\u5e73\u6027\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u516c\u5e73\u6027\u5728\u6b64\u9886\u57df\u8d85\u8d8a\u4e86\u7ed3\u679c\u5e73\u7b49\uff0c\u9700\u8981\u5305\u542b\u9053\u5fb7\u4ee3\u8868\u6027\u3001\u5bf9\u60a3\u8005\u4ef7\u503c\u89c2\u7684\u5fe0\u5b9e\u5ea6\u3001\u4eba\u9645\u5173\u7cfb\u548c\u4e16\u754c\u89c2\u3002", "conclusion": "AI\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u9700\u8981\u66f4\u5168\u9762\u7684\u6846\u67b6\uff0c\u6db5\u76d6\u9053\u5fb7\u4ee3\u8868\u6027\u3001\u4ef7\u503c\u89c2\u5fe0\u5b9e\u5ea6\u548c\u5173\u7cfb\u7ef4\u5ea6\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u7ed3\u679c\u5e73\u7b49\u3002"}}
{"id": "2510.16550", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16550", "abs": "https://arxiv.org/abs/2510.16550", "authors": ["Siyuan Yin", "Yuncheng Xu", "Lin Liu", "Fan Yang", "Xuan Zeng", "Chengtao An", "Yangfeng Su"], "title": "SMP-RCR: A Sparse Multipoint Moment Matching Method for RC Reduction", "comment": null, "summary": "In post--layout circuit simulation, efficient model order reduction (MOR) for\nmany--port resistor--capacitor (RC) circuits remains a crucial issue. The\ncurrent mainstream MOR methods for such circuits include high--order moment\nmatching methods and elimination methods. High-order moment matching\nmethods--characterized by high accuracy, such as PRIMA and TurboMOR--tend to\ngenerate large dense reduced-order systems when the number of ports is large,\nwhich impairs the efficiency of MOR. Another common type of MOR method for\nmany--port circuits is based on Gaussian elimination, with the SIP method as a\nrepresentative. The main limitation of this method lies in the inadequate\nmatching of high--order moments. In this paper, we propose a sparse multipoint\nmoment matching method and present comprehensive theoretical analysis results\nregarding the multi--frequency high--order moment matching property. Meanwhile,\nto enhance the algorithm's efficiency, sparse control and deflation techniques\nare introduced to further optimize the algorithm. Numerical experiments\ndemonstrated that, compared to SIP, the accuracy is improved by more than two\norders of magnitude at high frequency points without adding many extra linear\ncomponents. Compared to TurboMOR methods, our method achieves a speed\nimprovement of more than twice while maintaining the same level of precision.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7a00\u758f\u591a\u70b9\u77e9\u5339\u914d\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u7aef\u53e3RC\u7535\u8def\u6a21\u578b\u964d\u9636\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u591a\u7aef\u53e3RC\u7535\u8def\u6a21\u578b\u964d\u9636\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u9ad8\u9636\u77e9\u5339\u914d\u65b9\u6cd5\uff08\u5982PRIMA\u3001TurboMOR\uff09\u5728\u7aef\u53e3\u6570\u591a\u65f6\u4f1a\u4ea7\u751f\u5927\u578b\u7a20\u5bc6\u7cfb\u7edf\uff0c\u5f71\u54cd\u6548\u7387\uff1b\u800c\u57fa\u4e8e\u9ad8\u65af\u6d88\u5143\u7684\u65b9\u6cd5\uff08\u5982SIP\uff09\u5728\u9ad8\u9636\u77e9\u5339\u914d\u65b9\u9762\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u7a00\u758f\u591a\u70b9\u77e9\u5339\u914d\u65b9\u6cd5\uff0c\u7ed3\u5408\u7a00\u758f\u63a7\u5236\u548c\u7d27\u7f29\u6280\u672f\u4f18\u5316\u7b97\u6cd5\uff0c\u63d0\u4f9b\u591a\u9891\u7387\u9ad8\u9636\u77e9\u5339\u914d\u7279\u6027\u7684\u7406\u8bba\u5206\u6790\u3002", "result": "\u4e0eSIP\u76f8\u6bd4\uff0c\u5728\u9ad8\u9891\u70b9\u7cbe\u5ea6\u63d0\u9ad8\u4e24\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff0c\u4e14\u4e0d\u589e\u52a0\u8fc7\u591a\u7ebf\u6027\u7ec4\u4ef6\uff1b\u4e0eTurboMOR\u76f8\u6bd4\uff0c\u5728\u4fdd\u6301\u76f8\u540c\u7cbe\u5ea6\u6c34\u5e73\u4e0b\u901f\u5ea6\u63d0\u5347\u4e24\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u591a\u7aef\u53e3RC\u7535\u8def\u7684\u6a21\u578b\u964d\u9636\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16263", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16263", "abs": "https://arxiv.org/abs/2510.16263", "authors": ["Jierui Peng", "Yanyan Zhang", "Yicheng Duan", "Tuo Liang", "Vipin Chaudhary", "Yu Yin"], "title": "NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?", "comment": "Homepage: https://vulab-ai.github.io/NEBULA-Alpha/", "summary": "The evaluation of Vision-Language-Action (VLA) agents is hindered by the\ncoarse, end-task success metric that fails to provide precise skill diagnosis\nor measure robustness to real-world perturbations. This challenge is\nexacerbated by a fragmented data landscape that impedes reproducible research\nand the development of generalist models. To address these limitations, we\nintroduce \\textbf{NEBULA}, a unified ecosystem for single-arm manipulation that\nenables diagnostic and reproducible evaluation. NEBULA features a novel\ndual-axis evaluation protocol that combines fine-grained \\textit{capability\ntests} for precise skill diagnosis with systematic \\textit{stress tests} that\nmeasure robustness. A standardized API and a large-scale, aggregated dataset\nare provided to reduce fragmentation and support cross-dataset training and\nfair comparison. Using NEBULA, we demonstrate that top-performing VLAs struggle\nwith key capabilities such as spatial reasoning and dynamic adaptation, which\nare consistently obscured by conventional end-task success metrics. By\nmeasuring both what an agent can do and when it does so reliably, NEBULA\nprovides a practical foundation for robust, general-purpose embodied agents.", "AI": {"tldr": "NEBULA\u662f\u4e00\u4e2a\u7528\u4e8e\u5355\u81c2\u64cd\u4f5c\u4efb\u52a1\u7684\u7edf\u4e00\u8bc4\u4f30\u751f\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u80fd\u529b\u6d4b\u8bd5\u548c\u7cfb\u7edf\u6027\u538b\u529b\u6d4b\u8bd5\u6765\u8bca\u65ad\u6280\u80fd\u548c\u6d4b\u91cf\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7aef\u4efb\u52a1\u6210\u529f\u6307\u6807\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c(VLA)\u4ee3\u7406\u7684\u8bc4\u4f30\u53d7\u5230\u7c97\u7cd9\u7684\u7aef\u4efb\u52a1\u6210\u529f\u6307\u6807\u7684\u9650\u5236\uff0c\u65e0\u6cd5\u63d0\u4f9b\u7cbe\u786e\u7684\u6280\u80fd\u8bca\u65ad\u6216\u6d4b\u91cf\u5bf9\u771f\u5b9e\u4e16\u754c\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u4e14\u788e\u7247\u5316\u7684\u6570\u636e\u73af\u5883\u963b\u788d\u4e86\u53ef\u590d\u73b0\u7814\u7a76\u548c\u901a\u7528\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51faNEBULA\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u542b\u53cc\u8f74\u8bc4\u4f30\u534f\u8bae\uff1a\u7ec6\u7c92\u5ea6\u80fd\u529b\u6d4b\u8bd5\u7528\u4e8e\u7cbe\u786e\u6280\u80fd\u8bca\u65ad\uff0c\u7cfb\u7edf\u6027\u538b\u529b\u6d4b\u8bd5\u7528\u4e8e\u6d4b\u91cf\u9c81\u68d2\u6027\uff1b\u63d0\u4f9b\u6807\u51c6\u5316API\u548c\u5927\u89c4\u6a21\u805a\u5408\u6570\u636e\u96c6\u4ee5\u652f\u6301\u8de8\u6570\u636e\u96c6\u8bad\u7ec3\u548c\u516c\u5e73\u6bd4\u8f83\u3002", "result": "\u4f7f\u7528NEBULA\u53d1\u73b0\uff0c\u8868\u73b0\u6700\u4f73\u7684VLA\u5728\u7a7a\u95f4\u63a8\u7406\u548c\u52a8\u6001\u9002\u5e94\u7b49\u5173\u952e\u80fd\u529b\u4e0a\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u4e9b\u7f3a\u9677\u88ab\u4f20\u7edf\u7aef\u4efb\u52a1\u6210\u529f\u6307\u6807\u6240\u63a9\u76d6\u3002", "conclusion": "NEBULA\u901a\u8fc7\u540c\u65f6\u6d4b\u91cf\u4ee3\u7406\u80fd\u505a\u4ec0\u4e48\u4ee5\u53ca\u4f55\u65f6\u80fd\u53ef\u9760\u5730\u505a\u5230\uff0c\u4e3a\u6784\u5efa\u9c81\u68d2\u3001\u901a\u7528\u7684\u5177\u8eab\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2510.16068", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16068", "abs": "https://arxiv.org/abs/2510.16068", "authors": ["Wei Ting Liow", "Sumbul Khan", "Lay Kee Ang"], "title": "Co-Designing Interdisciplinary Design Projects with AI", "comment": "to be published in IEEE TALE 2025", "summary": "Creating interdisciplinary design projects is time-consuming and cognitively\ndemanding for teachers, requiring curriculum alignment, cross-subject\nintegration, and careful sequencing. International research reports increasing\nteacher use of AI alongside persistent workload pressures, underscoring the\nneed for planning support. This paper presents the Interdisciplinary Design\nProject Planner (IDPplanner), a GPT-based planning assistant grounded in Design\nInnovation principles, alignment with Singapore secondary school syllabuses,\nand 21st-century competencies. In a within-subject, counterbalanced workshop\nwith 33 in-service teachers, participants produced two versions of the same\nproject: manual and AI-assisted, followed by self- and peer-evaluations using a\nsix-dimensional rubric. The AI-assisted version received higher scores for\nCurriculum Alignment, Design Thinking Application, and Coherence and Flow, with\na marginal advantage for Assessment Strategies. Teacher reflections indicated\nthat AI-assisted planning improved structure, sequencing, and idea generation,\nwhile contextualization to local syllabuses, class profiles, and student needs\nremained teacher-led. Contributions include a purpose-built planning tool that\norganizes ideas into a ten-component flow with ready-to-adapt prompts,\ntemplates, and assessment suggestions; an empirical, rubric-based comparison of\nplanning quality; and evidence that AI can function as a pedagogical planning\npartner. Recommendations emphasize hybrid teacher-AI workflows to enhance\ncurriculum alignment and reduce planning complexity, and design suggestions for\ndevelopers to strengthen contextual customization, iterative design support,\nand localized rubrics. Although instantiated with a Singapore-based curriculum,\nthe planning flow and rubric are framework-agnostic and can be parameterized\nfor other systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86IDPplanner\uff0c\u4e00\u4e2a\u57fa\u4e8eGPT\u7684\u8de8\u5b66\u79d1\u8bbe\u8ba1\u9879\u76ee\u89c4\u5212\u52a9\u624b\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8868\u660eAI\u8f85\u52a9\u89c4\u5212\u5728\u8bfe\u7a0b\u5bf9\u9f50\u3001\u8bbe\u8ba1\u601d\u7ef4\u5e94\u7528\u548c\u8fde\u8d2f\u6027\u65b9\u9762\u4f18\u4e8e\u4eba\u5de5\u89c4\u5212\uff0c\u540c\u65f6\u5f3a\u8c03\u6559\u5e08\u4e0eAI\u7684\u6df7\u5408\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u6559\u5e08\u521b\u5efa\u8de8\u5b66\u79d1\u8bbe\u8ba1\u9879\u76ee\u8017\u65f6\u4e14\u8ba4\u77e5\u8d1f\u62c5\u91cd\uff0c\u9700\u8981\u8bfe\u7a0b\u5bf9\u9f50\u3001\u8de8\u5b66\u79d1\u6574\u5408\u548c\u7cbe\u5fc3\u6392\u5e8f\u3002\u56fd\u9645\u7814\u7a76\u663e\u793a\u6559\u5e08\u4f7f\u7528AI\u589e\u52a0\u4f46\u5de5\u4f5c\u538b\u529b\u6301\u7eed\uff0c\u9700\u8981\u89c4\u5212\u652f\u6301\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eGPT\u7684IDPplanner\u89c4\u5212\u52a9\u624b\uff0c\u572833\u540d\u5728\u804c\u6559\u5e08\u7684\u5bf9\u6bd4\u5de5\u4f5c\u574a\u4e2d\uff0c\u5206\u522b\u5236\u4f5c\u4eba\u5de5\u548cAI\u8f85\u52a9\u7248\u672c\u7684\u9879\u76ee\uff0c\u4f7f\u7528\u516d\u7ef4\u8bc4\u5206\u6807\u51c6\u8fdb\u884c\u81ea\u8bc4\u548c\u4e92\u8bc4\u3002", "result": "AI\u8f85\u52a9\u7248\u672c\u5728\u8bfe\u7a0b\u5bf9\u9f50\u3001\u8bbe\u8ba1\u601d\u7ef4\u5e94\u7528\u548c\u8fde\u8d2f\u6027\u65b9\u9762\u5f97\u5206\u66f4\u9ad8\uff0c\u8bc4\u4f30\u7b56\u7565\u7565\u6709\u4f18\u52bf\u3002\u6559\u5e08\u53cd\u601d\u8868\u660eAI\u8f85\u52a9\u6539\u5584\u4e86\u7ed3\u6784\u3001\u6392\u5e8f\u548c\u521b\u610f\u751f\u6210\uff0c\u4f46\u60c5\u5883\u5316\u4ecd\u7531\u6559\u5e08\u4e3b\u5bfc\u3002", "conclusion": "AI\u53ef\u4f5c\u4e3a\u6559\u5b66\u89c4\u5212\u4f19\u4f34\uff0c\u5efa\u8bae\u91c7\u7528\u6df7\u5408\u6559\u5e08-AI\u5de5\u4f5c\u6d41\u7a0b\u6765\u589e\u5f3a\u8bfe\u7a0b\u5bf9\u9f50\u5e76\u51cf\u5c11\u89c4\u5212\u590d\u6742\u6027\uff0c\u89c4\u5212\u6d41\u7a0b\u548c\u8bc4\u5206\u6807\u51c6\u5177\u6709\u6846\u67b6\u65e0\u5173\u6027\uff0c\u53ef\u53c2\u6570\u5316\u9002\u5e94\u5176\u4ed6\u7cfb\u7edf\u3002"}}
{"id": "2510.16693", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16693", "abs": "https://arxiv.org/abs/2510.16693", "authors": ["Ayan Das", "Anushka Sharma", "Anamitra Pal"], "title": "Linear State Estimation in Presence of Bounded Uncertainties: A Comparative Analysis", "comment": null, "summary": "A variety of algorithms have been proposed to address the power system state\nestimation problem in the presence of uncertainties in the data. However, less\nemphasis has been given to handling perturbations in the model. In the context\nof linear state estimation (LSE), which is the focus of this paper,\nperturbations in the model come from variations in the line parameters. Since\nthe actual values of the line parameters can be different from the values\nstored in a power utility's database, we investigate three approaches in this\npaper to estimate the states in the presence of bounded uncertainties in the\ndata and the model. The first approach is based on interval arithmetic, the\nsecond is based on convex optimization, and the third is based on generalized\nlinear fractional programming. The three algorithms are applied to multiple\nIEEE test systems and compared in terms of their speed and accuracy. The\nresults indicate that the first two algorithms are extremely fast and give\nexpected results, while the third suffers from scalability issues and is\nunsuitable for LSE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e09\u79cd\u5904\u7406\u7535\u529b\u7cfb\u7edf\u72b6\u6001\u4f30\u8ba1\u4e2d\u6570\u636e\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\uff1a\u57fa\u4e8e\u533a\u95f4\u7b97\u672f\u3001\u51f8\u4f18\u5316\u548c\u5e7f\u4e49\u7ebf\u6027\u5206\u5f0f\u89c4\u5212\u7684\u65b9\u6cd5\uff0c\u5e76\u5728IEEE\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6570\u636e\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff08\u7279\u522b\u662f\u7ebf\u8def\u53c2\u6570\u53d8\u5316\uff09\u7684\u5904\u7406\u8f83\u5c11\u3002\u7531\u4e8e\u5b9e\u9645\u7ebf\u8def\u53c2\u6570\u53ef\u80fd\u4e0e\u6570\u636e\u5e93\u4e2d\u7684\u503c\u4e0d\u540c\uff0c\u9700\u8981\u7814\u7a76\u5728\u6570\u636e\u548c\u6a21\u578b\u90fd\u5b58\u5728\u6709\u754c\u4e0d\u786e\u5b9a\u6027\u65f6\u7684\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8e\u533a\u95f4\u7b97\u672f\u7684\u65b9\u6cd5\uff1b2\uff09\u57fa\u4e8e\u51f8\u4f18\u5316\u7684\u65b9\u6cd5\uff1b3\uff09\u57fa\u4e8e\u5e7f\u4e49\u7ebf\u6027\u5206\u5f0f\u89c4\u5212\u7684\u65b9\u6cd5\u3002\u8fd9\u4e9b\u65b9\u6cd5\u7528\u4e8e\u5904\u7406\u7ebf\u6027\u72b6\u6001\u4f30\u8ba1\u4e2d\u7684\u6570\u636e\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u524d\u4e24\u79cd\u65b9\u6cd5\u901f\u5ea6\u6781\u5feb\u4e14\u7ed3\u679c\u7b26\u5408\u9884\u671f\uff0c\u800c\u7b2c\u4e09\u79cd\u65b9\u6cd5\u5b58\u5728\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e0d\u9002\u7528\u4e8e\u7ebf\u6027\u72b6\u6001\u4f30\u8ba1\u3002", "conclusion": "\u57fa\u4e8e\u533a\u95f4\u7b97\u672f\u548c\u51f8\u4f18\u5316\u7684\u65b9\u6cd5\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u800c\u5e7f\u4e49\u7ebf\u6027\u5206\u5f0f\u89c4\u5212\u65b9\u6cd5\u7531\u4e8e\u53ef\u6269\u5c55\u6027\u95ee\u9898\u4e0d\u9002\u5408\u7ebf\u6027\u72b6\u6001\u4f30\u8ba1\u5e94\u7528\u3002"}}
{"id": "2510.16281", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16281", "abs": "https://arxiv.org/abs/2510.16281", "authors": ["Yilin Wu", "Anqi Li", "Tucker Hermans", "Fabio Ramos", "Andrea Bajcsy", "Claudia P'erez-D'Arpino"], "title": "Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification", "comment": null, "summary": "Reasoning Vision Language Action (VLA) models improve robotic\ninstruction-following by generating step-by-step textual plans before low-level\nactions, an approach inspired by Chain-of-Thought (CoT) reasoning in language\nmodels. Yet even with a correct textual plan, the generated actions can still\nmiss the intended outcomes in the plan, especially in out-of-distribution (OOD)\nscenarios. We formalize this phenomenon as a lack of embodied CoT faithfulness,\nand introduce a training-free, runtime policy steering method for\nreasoning-action alignment. Given a reasoning VLA's intermediate textual plan,\nour framework samples multiple candidate action sequences from the same model,\npredicts their outcomes via simulation, and uses a pre-trained Vision-Language\nModel (VLM) to select the sequence whose outcome best aligns with the VLA's own\ntextual plan. Only executing action sequences that align with the textual\nreasoning turns our base VLA's natural action diversity from a source of error\ninto a strength, boosting robustness to semantic and visual OOD perturbations\nand enabling novel behavior composition without costly re-training. We also\ncontribute a reasoning-annotated extension of LIBERO-100, environment\nvariations tailored for OOD evaluation, and demonstrate up to 15% performance\ngain over prior work on behavior composition tasks and scales with compute and\ndata diversity. Project Website at:\nhttps://yilin-wu98.github.io/steering-reasoning-vla/", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u7b56\u7565\u5f15\u5bfc\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u5019\u9009\u52a8\u4f5c\u5e8f\u5217\u5e76\u9009\u62e9\u4e0e\u6587\u672c\u8ba1\u5212\u6700\u4e00\u81f4\u7684\u7ed3\u679c\uff0c\u63d0\u5347\u63a8\u7406-\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u5fe0\u5b9e\u5ea6\u3002", "motivation": "\u73b0\u6709\u63a8\u7406VLA\u6a21\u578b\u5373\u4f7f\u751f\u6210\u6b63\u786e\u7684\u6587\u672c\u8ba1\u5212\uff0c\u5728\u5206\u5e03\u5916\u573a\u666f\u4e2d\u4ecd\u53ef\u80fd\u4ea7\u751f\u4e0e\u8ba1\u5212\u610f\u56fe\u4e0d\u7b26\u7684\u52a8\u4f5c\uff0c\u5b58\u5728\u63a8\u7406-\u52a8\u4f5c\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u63a8\u7406VLA\u7684\u4e2d\u95f4\u6587\u672c\u8ba1\u5212\uff0c\u91c7\u6837\u591a\u4e2a\u5019\u9009\u52a8\u4f5c\u5e8f\u5217\uff0c\u901a\u8fc7\u6a21\u62df\u9884\u6d4b\u7ed3\u679c\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3VLM\u9009\u62e9\u4e0e\u6587\u672c\u8ba1\u5212\u6700\u4e00\u81f4\u7684\u52a8\u4f5c\u5e8f\u5217\u3002", "result": "\u5728\u884c\u4e3a\u7ec4\u5408\u4efb\u52a1\u4e0a\u6bd4\u5148\u524d\u5de5\u4f5c\u63d0\u534715%\u6027\u80fd\uff0c\u5bf9\u8bed\u4e49\u548c\u89c6\u89c9\u5206\u5e03\u5916\u6270\u52a8\u5177\u6709\u66f4\u5f3a\u9c81\u68d2\u6027\uff0c\u4e14\u6027\u80fd\u968f\u8ba1\u7b97\u548c\u6570\u636e\u591a\u6837\u6027\u6269\u5c55\u3002", "conclusion": "\u5c06\u57fa\u7840VLA\u7684\u81ea\u7136\u52a8\u4f5c\u591a\u6837\u6027\u4ece\u9519\u8bef\u6765\u6e90\u8f6c\u5316\u4e3a\u4f18\u52bf\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u65b0\u9896\u884c\u4e3a\u7ec4\u5408\uff0c\u63d0\u5347\u4e86\u63a8\u7406-\u52a8\u4f5c\u5bf9\u9f50\u7684\u5fe0\u5b9e\u5ea6\u3002"}}
{"id": "2510.16069", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16069", "abs": "https://arxiv.org/abs/2510.16069", "authors": ["Sumbul Khan", "Wei Ting Liow", "Lay Kee Ang"], "title": "Human or AI? Comparing Design Thinking Assessments by Teaching Assistants and Bots", "comment": "to be published in IEEE TALE 2025", "summary": "As design thinking education grows in secondary and tertiary contexts,\neducators face the challenge of evaluating creative artefacts that combine\nvisual and textual elements. Traditional rubric-based assessment is laborious,\ntime-consuming, and inconsistent due to reliance on Teaching Assistants (TA) in\nlarge, multi-section cohorts. This paper presents an exploratory study\ninvestigating the reliability and perceived accuracy of AI-assisted assessment\ncompared to TA-assisted assessment in evaluating student posters in design\nthinking education. Two activities were conducted with 33 Ministry of Education\n(MOE) Singapore school teachers to (1) compare AI-generated scores with TA\ngrading across three key dimensions: empathy and user understanding,\nidentification of pain points and opportunities, and visual communication, and\n(2) examine teacher preferences for AI-assigned, TA-assigned, and hybrid\nscores. Results showed low statistical agreement between instructor and AI\nscores for empathy and pain points, with slightly higher alignment for visual\ncommunication. Teachers preferred TA-assigned scores in six of ten samples.\nQualitative feedback highlighted the potential of AI for formative feedback,\nconsistency, and student self-reflection, but raised concerns about its\nlimitations in capturing contextual nuance and creative insight. The study\nunderscores the need for hybrid assessment models that integrate computational\nefficiency with human insights. This research contributes to the evolving\nconversation on responsible AI adoption in creative disciplines, emphasizing\nthe balance between automation and human judgment for scalable and\npedagogically sound assessment.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22AI\u8f85\u52a9\u8bc4\u4f30\u5728\u521b\u610f\u8bbe\u8ba1\u6559\u80b2\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0AI\u4e0e\u6559\u5e08\u8bc4\u5206\u5728\u540c\u7406\u5fc3\u548c\u75db\u70b9\u7ef4\u5ea6\u4e00\u81f4\u6027\u8f83\u4f4e\uff0c\u6559\u5e08\u66f4\u504f\u597d\u4eba\u5de5\u8bc4\u5206\uff0c\u5efa\u8bae\u91c7\u7528\u6df7\u5408\u8bc4\u4f30\u6a21\u578b\u3002", "motivation": "\u8bbe\u8ba1\u601d\u7ef4\u6559\u80b2\u4e2d\uff0c\u4f20\u7edf\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4f30\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u6559\u5b66\u4e2d\u5b58\u5728\u8017\u65f6\u3001\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u9700\u8981\u63a2\u7d22AI\u8f85\u52a9\u8bc4\u4f30\u7684\u53ef\u884c\u6027\u3002", "method": "\u5bf933\u540d\u65b0\u52a0\u5761\u6559\u80b2\u90e8\u6559\u5e08\u8fdb\u884c\u4e24\u9879\u6d3b\u52a8\uff1a\u6bd4\u8f83AI\u4e0e\u52a9\u6559\u5728\u540c\u7406\u5fc3\u3001\u75db\u70b9\u548c\u89c6\u89c9\u6c9f\u901a\u4e09\u4e2a\u7ef4\u5ea6\u7684\u8bc4\u5206\u5dee\u5f02\uff1b\u8c03\u67e5\u6559\u5e08\u5bf9AI\u8bc4\u5206\u3001\u52a9\u6559\u8bc4\u5206\u548c\u6df7\u5408\u8bc4\u5206\u7684\u504f\u597d\u3002", "result": "AI\u4e0e\u6559\u5e08\u8bc4\u5206\u5728\u540c\u7406\u5fc3\u548c\u75db\u70b9\u7ef4\u5ea6\u7edf\u8ba1\u4e00\u81f4\u6027\u4f4e\uff0c\u89c6\u89c9\u6c9f\u901a\u7ef4\u5ea6\u4e00\u81f4\u6027\u7a0d\u9ad8\uff1b\u6559\u5e08\u66f4\u504f\u597d\u52a9\u6559\u8bc4\u5206\uff1b\u5b9a\u6027\u53cd\u9988\u663e\u793aAI\u5728\u5f62\u6210\u6027\u53cd\u9988\u548c\u4e00\u81f4\u6027\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u60c5\u5883\u7406\u89e3\u548c\u521b\u610f\u6d1e\u5bdf\u3002", "conclusion": "\u9700\u8981\u6df7\u5408\u8bc4\u4f30\u6a21\u578b\uff0c\u7ed3\u5408\u8ba1\u7b97\u6548\u7387\u4e0e\u4eba\u7c7b\u6d1e\u5bdf\u529b\uff0c\u5728\u521b\u610f\u5b66\u79d1\u4e2d\u5e73\u8861\u81ea\u52a8\u5316\u4e0e\u4eba\u5de5\u5224\u65ad\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u6559\u5b66\u539f\u7406\u7684\u8bc4\u4f30\u3002"}}
{"id": "2510.16735", "categories": ["eess.SY", "cs.LG", "cs.SY", "93C40 (Primary) 68T05, 91B82 (Secondary)", "I.2.6; I.2.8; C.2.4; K.4.4"], "pdf": "https://arxiv.org/pdf/2510.16735", "abs": "https://arxiv.org/abs/2510.16735", "authors": ["Aniket Agrawal", "Harsharanga Patil"], "title": "A Control-Theoretic Approach to Dynamic Payment Routing for Success Rate Optimization", "comment": "7 Pages, 8 Figures", "summary": "This paper introduces a control-theoretic framework for dynamic payment\nrouting, implemented within JUSPAY's Payment Orchestrator to maximize\ntransaction success rate. The routing system is modeled as a closed-loop\nfeedback controller continuously sensing gateway performance, computing\ncorrective actions, and dynamically routes transactions across gateway to\nensure operational resilience. The system leverages concepts from control\ntheory, reinforcement learning, and multi-armed bandit optimization to achieve\nboth short-term responsiveness and long-term stability. Rather than relying on\nexplicit PID regulation, the framework applies generalized feedback-based\nadaptation, ensuring that corrective actions remain proportional to observed\nperformance deviations and the computed gateway score gradually converges\ntoward the success rate. This hybrid approach unifies control theory and\nadaptive decision systems, enabling self-regulating transaction routing that\ndampens instability, and improves reliability. Live production results show an\nimprovement of up to 1.15% in success rate over traditional rule-based routing,\ndemonstrating the effectiveness of feedback-based control in payment systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u63a7\u5236\u7406\u8bba\u7684\u52a8\u6001\u652f\u4ed8\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u95ed\u73af\u53cd\u9988\u63a7\u5236\u5668\u5b9e\u65f6\u76d1\u63a7\u7f51\u5173\u6027\u80fd\u5e76\u52a8\u6001\u8def\u7531\u4ea4\u6613\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u591a\u81c2\u8001\u864e\u673a\u4f18\u5316\uff0c\u76f8\u6bd4\u4f20\u7edf\u89c4\u5219\u8def\u7531\u6210\u529f\u7387\u63d0\u53471.15%\u3002", "motivation": "\u4f20\u7edf\u652f\u4ed8\u8def\u7531\u7cfb\u7edf\u7f3a\u4e4f\u52a8\u6001\u9002\u5e94\u6027\uff0c\u65e0\u6cd5\u5b9e\u65f6\u54cd\u5e94\u7f51\u5173\u6027\u80fd\u53d8\u5316\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u6211\u8c03\u8282\u3001\u786e\u4fdd\u64cd\u4f5c\u5f39\u6027\u7684\u667a\u80fd\u8def\u7531\u65b9\u6848\u3002", "method": "\u91c7\u7528\u95ed\u73af\u53cd\u9988\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u63a7\u5236\u7406\u8bba\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u591a\u81c2\u8001\u864e\u673a\u4f18\u5316\uff0c\u901a\u8fc7\u611f\u77e5\u7f51\u5173\u6027\u80fd\u3001\u8ba1\u7b97\u7ea0\u6b63\u52a8\u4f5c\u3001\u52a8\u6001\u8def\u7531\u4ea4\u6613\u6765\u5b9e\u73b0\u81ea\u9002\u5e94\u8def\u7531\u3002", "result": "\u751f\u4ea7\u73af\u5883\u6d4b\u8bd5\u663e\u793a\uff0c\u76f8\u6bd4\u4f20\u7edf\u89c4\u5219\u8def\u7531\uff0c\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe1.15%\uff0c\u8bc1\u660e\u4e86\u53cd\u9988\u63a7\u5236\u5728\u652f\u4ed8\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63a7\u5236\u7406\u8bba\u4e0e\u81ea\u9002\u5e94\u51b3\u7b56\u7cfb\u7edf\u7684\u6df7\u5408\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u81ea\u6211\u8c03\u8282\u7684\u4ea4\u6613\u8def\u7531\uff0c\u6291\u5236\u4e0d\u7a33\u5b9a\u6027\u5e76\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u4e3a\u652f\u4ed8\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u52a8\u6001\u8def\u7531\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16308", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16308", "abs": "https://arxiv.org/abs/2510.16308", "authors": ["Chi Zhang", "Xian Huang", "Wei Dong"], "title": "SPOT: Sensing-augmented Trajectory Planning via Obstacle Threat Modeling", "comment": null, "summary": "UAVs equipped with a single depth camera encounter significant challenges in\ndynamic obstacle avoidance due to limited field of view and inevitable blind\nspots. While active vision strategies that steer onboard cameras have been\nproposed to expand sensing coverage, most existing methods separate motion\nplanning from sensing considerations, resulting in less effective and delayed\nobstacle response. To address this limitation, we introduce SPOT\n(Sensing-augmented Planning via Obstacle Threat modeling), a unified planning\nframework for observation-aware trajectory planning that explicitly\nincorporates sensing objectives into motion optimization. At the core of our\nmethod is a Gaussian Process-based obstacle belief map, which establishes a\nunified probabilistic representation of both recognized (previously observed)\nand potential obstacles. This belief is further processed through a\ncollision-aware inference mechanism that transforms spatial uncertainty and\ntrajectory proximity into a time-varying observation urgency map. By\nintegrating urgency values within the current field of view, we define\ndifferentiable objectives that enable real-time, observation-aware trajectory\nplanning with computation times under 10 ms. Simulation and real-world\nexperiments in dynamic, cluttered, and occluded environments show that our\nmethod detects potential dynamic obstacles 2.8 seconds earlier than baseline\napproaches, increasing dynamic obstacle visibility by over 500\\%, and enabling\nsafe navigation through cluttered, occluded environments.", "AI": {"tldr": "SPOT\u662f\u4e00\u4e2a\u5c06\u611f\u77e5\u76ee\u6807\u878d\u5165\u8fd0\u52a8\u89c4\u5212\u7684\u65e0\u4eba\u673a\u907f\u969c\u6846\u67b6\uff0c\u901a\u8fc7\u969c\u788d\u7269\u5a01\u80c1\u5efa\u6a21\u5b9e\u73b0\u5b9e\u65f6\u89c2\u6d4b\u611f\u77e5\u8f68\u8ff9\u89c4\u5212\uff0c\u5728\u52a8\u6001\u906e\u6321\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u969c\u788d\u7269\u68c0\u6d4b\u80fd\u529b", "motivation": "\u5355\u6df1\u5ea6\u76f8\u673a\u7684\u65e0\u4eba\u673a\u5728\u52a8\u6001\u907f\u969c\u4e2d\u9762\u4e34\u89c6\u91ce\u6709\u9650\u548c\u76f2\u533a\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5c06\u8fd0\u52a8\u89c4\u5212\u4e0e\u611f\u77e5\u5206\u79bb\uff0c\u5bfc\u81f4\u907f\u969c\u6548\u679c\u4e0d\u4f73\u548c\u54cd\u5e94\u5ef6\u8fdf", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u6784\u5efa\u969c\u788d\u7269\u7f6e\u4fe1\u56fe\uff0c\u901a\u8fc7\u78b0\u649e\u611f\u77e5\u63a8\u7406\u673a\u5236\u5c06\u7a7a\u95f4\u4e0d\u786e\u5b9a\u6027\u548c\u8f68\u8ff9\u90bb\u8fd1\u5ea6\u8f6c\u5316\u4e3a\u65f6\u53d8\u89c2\u6d4b\u7d27\u6025\u5ea6\u56fe\uff0c\u5728\u89c6\u91ce\u5185\u96c6\u6210\u7d27\u6025\u5ea6\u503c\u5b9a\u4e49\u53ef\u5fae\u5206\u76ee\u6807", "result": "\u5728\u52a8\u6001\u3001\u6742\u4e71\u548c\u906e\u6321\u73af\u5883\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u524d2.8\u79d2\u68c0\u6d4b\u5230\u6f5c\u5728\u52a8\u6001\u969c\u788d\u7269\uff0c\u52a8\u6001\u969c\u788d\u7269\u53ef\u89c1\u6027\u63d0\u5347\u8d85\u8fc7500%\uff0c\u8ba1\u7b97\u65f6\u95f4\u4f4e\u4e8e10\u6beb\u79d2", "conclusion": "SPOT\u6846\u67b6\u901a\u8fc7\u7edf\u4e00\u6982\u7387\u8868\u793a\u548c\u89c2\u6d4b\u611f\u77e5\u89c4\u5212\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5355\u76f8\u673a\u65e0\u4eba\u673a\u7684\u52a8\u6001\u907f\u969c\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b89\u5168\u5bfc\u822a"}}
{"id": "2510.16081", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16081", "abs": "https://arxiv.org/abs/2510.16081", "authors": ["Jiaye Yang", "Xinyu Zhao", "Tianlong Chen", "Kandyce Brennan"], "title": "SARHAchat: An LLM-Based Chatbot for Sexual and Reproductive Health Counseling", "comment": "5 pages, 1 figure", "summary": "While Artificial Intelligence (AI) shows promise in healthcare applications,\nexisting conversational systems often falter in complex and sensitive medical\ndomains such as Sexual and Reproductive Health (SRH). These systems frequently\nstruggle with hallucination and lack the specialized knowledge required,\nparticularly for sensitive SRH topics. Furthermore, current AI approaches in\nhealthcare tend to prioritize diagnostic capabilities over comprehensive\npatient care and education. Addressing these gaps, this work at the UNC School\nof Nursing introduces SARHAchat, a proof-of-concept Large Language Model\n(LLM)-based chatbot. SARHAchat is designed as a reliable, user-centered system\nintegrating medical expertise with empathetic communication to enhance SRH care\ndelivery. Our evaluation demonstrates SARHAchat's ability to provide accurate\nand contextually appropriate contraceptive counseling while maintaining a\nnatural conversational flow. The demo is available at\nhttps://sarhachat.com/}{https://sarhachat.com/.", "AI": {"tldr": "SARHAchat\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u4e13\u95e8\u9488\u5bf9\u6027\u5065\u5eb7\u548c\u751f\u6b96\u5065\u5eb7\u9886\u57df\u8bbe\u8ba1\uff0c\u6574\u5408\u533b\u5b66\u4e13\u4e1a\u77e5\u8bc6\u4e0e\u540c\u7406\u5fc3\u6c9f\u901a\uff0c\u63d0\u4f9b\u51c6\u786e\u4e14\u60c5\u5883\u9002\u5f53\u7684\u907f\u5b55\u54a8\u8be2\u3002", "motivation": "\u73b0\u6709AI\u5bf9\u8bdd\u7cfb\u7edf\u5728\u590d\u6742\u654f\u611f\u7684\u533b\u7597\u9886\u57df\uff08\u5982\u6027\u5065\u5eb7\u548c\u751f\u6b96\u5065\u5eb7\uff09\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u548c\u4e13\u4e1a\u77e5\u8bc6\u4e0d\u8db3\uff0c\u4e14\u5f53\u524d\u533b\u7597AI\u65b9\u6cd5\u8fc7\u4e8e\u4fa7\u91cd\u8bca\u65ad\u80fd\u529b\u800c\u5ffd\u89c6\u5168\u9762\u60a3\u8005\u62a4\u7406\u548c\u6559\u80b2\u3002", "method": "\u5f00\u53d1SARHAchat\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\u7684\u5927\u8bed\u8a00\u6a21\u578b\u804a\u5929\u673a\u5668\u4eba\uff0c\u6574\u5408\u533b\u5b66\u4e13\u4e1a\u77e5\u8bc6\u4e0e\u540c\u7406\u5fc3\u6c9f\u901a\uff0c\u4e13\u6ce8\u4e8e\u6027\u5065\u5eb7\u548c\u751f\u6b96\u5065\u5eb7\u62a4\u7406\u3002", "result": "\u8bc4\u4f30\u663e\u793aSARHAchat\u80fd\u591f\u63d0\u4f9b\u51c6\u786e\u4e14\u60c5\u5883\u9002\u5f53\u7684\u907f\u5b55\u54a8\u8be2\uff0c\u540c\u65f6\u4fdd\u6301\u81ea\u7136\u7684\u5bf9\u8bdd\u6d41\u7a0b\u3002", "conclusion": "SARHAchat\u8bc1\u660e\u4e86\u5728\u6027\u5065\u5eb7\u548c\u751f\u6b96\u5065\u5eb7\u9886\u57df\u5f00\u53d1\u53ef\u9760\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u589e\u5f3a\u8be5\u9886\u57df\u7684\u62a4\u7406\u670d\u52a1\u63d0\u4f9b\u3002"}}
{"id": "2510.16953", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.16953", "abs": "https://arxiv.org/abs/2510.16953", "authors": ["Ersin Das", "William A. Welch", "Patrick Spieler", "Keenan Albee", "Aurelio Noca", "Jeffrey Edlund", "Jonathan Becktor", "Thomas Touma", "Jessica Todd", "Sriramya Bhamidipati", "Stella Kombo", "Maira Saboia", "Anna Sabel", "Grace Lim", "Rohan Thakker", "Amir Rahmani", "Joel W. Burdick"], "title": "Safe Payload Transfer with Ship-Mounted Cranes: A Robust Model Predictive Control Approach", "comment": null, "summary": "Ensuring safe real-time control of ship-mounted cranes in unstructured\ntransportation environments requires handling multiple safety constraints while\nmaintaining effective payload transfer performance. Unlike traditional crane\nsystems, ship-mounted cranes are consistently subjected to significant external\ndisturbances affecting underactuated crane dynamics due to the ship's dynamic\nmotion response to harsh sea conditions, which can lead to robustness issues.\nTo tackle these challenges, we propose a robust and safe model predictive\ncontrol (MPC) framework and demonstrate it on a 5-DOF crane system, where a\nStewart platform simulates the external disturbances that ocean surface motions\nwould have on the supporting ship. The crane payload transfer operation must\navoid obstacles and accurately place the payload within a designated target\narea. We use a robust zero-order control barrier function (R-ZOCBF)-based\nsafety constraint in the nonlinear MPC to ensure safe payload positioning,\nwhile time-varying bounding boxes are utilized for collision avoidance. We\nintroduce a new optimization-based online robustness parameter adaptation\nscheme to reduce the conservativeness of R-ZOCBFs. Experimental trials on a\ncrane prototype demonstrate the overall performance of our safe control\napproach under significant perturbing motions of the crane base. While our\nfocus is on crane-facilitated transfer, the methods more generally apply to\nsafe robotically-assisted parts mating and parts insertion.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8239\u8f7d\u8d77\u91cd\u673a\u7684\u9c81\u68d2\u5b89\u5168\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u9636\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u548c\u65f6\u53d8\u8fb9\u754c\u6846\u786e\u4fdd\u5728\u5916\u90e8\u6270\u52a8\u4e0b\u7684\u5b89\u5168\u6709\u6548\u8f7d\u8377\u8f6c\u79fb\u3002", "motivation": "\u8239\u8f7d\u8d77\u91cd\u673a\u5728\u6076\u52a3\u6d77\u51b5\u4e0b\u53d7\u5230\u663e\u8457\u5916\u90e8\u6270\u52a8\uff0c\u5f71\u54cd\u6b20\u9a71\u52a8\u8d77\u91cd\u673a\u52a8\u529b\u5b66\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u9700\u8981\u540c\u65f6\u5904\u7406\u591a\u4e2a\u5b89\u5168\u7ea6\u675f\u5e76\u4fdd\u6301\u6709\u6548\u8f7d\u8377\u8f6c\u79fb\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u9c81\u68d2\u96f6\u9636\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u5b89\u5168\u7ea6\u675f\u5728\u975e\u7ebf\u6027MPC\u4e2d\u786e\u4fdd\u5b89\u5168\u8f7d\u8377\u5b9a\u4f4d\uff0c\u4f7f\u7528\u65f6\u53d8\u8fb9\u754c\u6846\u8fdb\u884c\u78b0\u649e\u907f\u514d\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u4f18\u5316\u7684\u5728\u7ebf\u9c81\u68d2\u6027\u53c2\u6570\u81ea\u9002\u5e94\u65b9\u6848\u3002", "result": "\u5728\u8d77\u91cd\u673a\u539f\u578b\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u8d77\u91cd\u673a\u57fa\u7840\u663e\u8457\u6270\u52a8\u8fd0\u52a8\u4e0b\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u8d77\u91cd\u673a\u8f85\u52a9\u7684\u8f6c\u79fb\u64cd\u4f5c\uff0c\u66f4\u5e7f\u6cdb\u5730\u9002\u7528\u4e8e\u5b89\u5168\u7684\u673a\u5668\u4eba\u8f85\u52a9\u96f6\u4ef6\u914d\u5408\u548c\u96f6\u4ef6\u63d2\u5165\u4efb\u52a1\u3002"}}
{"id": "2510.16344", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16344", "abs": "https://arxiv.org/abs/2510.16344", "authors": ["Chenrui Tie", "Shengxiang Sun", "Yudi Lin", "Yanbo Wang", "Zhongrui Li", "Zhouhan Zhong", "Jinxuan Zhu", "Yiman Pang", "Haonan Chen", "Junting Chen", "Ruihai Wu", "Lin Shao"], "title": "Manual2Skill++: Connector-Aware General Robotic Assembly from Instruction Manuals via Vision-Language Models", "comment": null, "summary": "Assembly hinges on reliably forming connections between parts; yet most\nrobotic approaches plan assembly sequences and part poses while treating\nconnectors as an afterthought. Connections represent the critical \"last mile\"\nof assembly execution, while task planning may sequence operations and motion\nplan may position parts, the precise establishment of physical connections\nultimately determines assembly success or failure. In this paper, we consider\nconnections as first-class primitives in assembly representation, including\nconnector types, specifications, quantities, and placement locations. Drawing\ninspiration from how humans learn assembly tasks through step-by-step\ninstruction manuals, we present Manual2Skill++, a vision-language framework\nthat automatically extracts structured connection information from assembly\nmanuals. We encode assembly tasks as hierarchical graphs where nodes represent\nparts and sub-assemblies, and edges explicitly model connection relationships\nbetween components. A large-scale vision-language model parses symbolic\ndiagrams and annotations in manuals to instantiate these graphs, leveraging the\nrich connection knowledge embedded in human-designed instructions. We curate a\ndataset containing over 20 assembly tasks with diverse connector types to\nvalidate our representation extraction approach, and evaluate the complete task\nunderstanding-to-execution pipeline across four complex assembly scenarios in\nsimulation, spanning furniture, toys, and manufacturing components with\nreal-world correspondence.", "AI": {"tldr": "\u63d0\u51faManual2Skill++\u6846\u67b6\uff0c\u5c06\u8fde\u63a5\u5173\u7cfb\u4f5c\u4e3a\u88c5\u914d\u4efb\u52a1\u7684\u6838\u5fc3\u8981\u7d20\uff0c\u4ece\u88c5\u914d\u624b\u518c\u4e2d\u81ea\u52a8\u63d0\u53d6\u7ed3\u6784\u5316\u8fde\u63a5\u4fe1\u606f\uff0c\u5e76\u6784\u5efa\u5c42\u6b21\u5316\u56fe\u8868\u793a\u6765\u7f16\u7801\u88c5\u914d\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u88c5\u914d\u65b9\u6cd5\u5c06\u8fde\u63a5\u5668\u89c6\u4e3a\u6b21\u8981\u56e0\u7d20\uff0c\u800c\u8fde\u63a5\u5173\u7cfb\u5b9e\u9645\u4e0a\u662f\u51b3\u5b9a\u88c5\u914d\u6210\u8d25\u7684\u5173\u952e\u73af\u8282\u3002\u9700\u8981\u5c06\u8fde\u63a5\u5173\u7cfb\u4f5c\u4e3a\u88c5\u914d\u8868\u793a\u7684\u4e00\u7b49\u516c\u6c11\u3002", "method": "\u4f7f\u7528\u5927\u89c4\u6a21\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u89e3\u6790\u88c5\u914d\u624b\u518c\u4e2d\u7684\u7b26\u53f7\u56fe\u8868\u548c\u6ce8\u91ca\uff0c\u6784\u5efa\u5c42\u6b21\u5316\u56fe\u8868\u793a\uff0c\u5176\u4e2d\u8282\u70b9\u4ee3\u8868\u96f6\u4ef6\u548c\u5b50\u88c5\u914d\u4f53\uff0c\u8fb9\u663e\u5f0f\u5efa\u6a21\u7ec4\u4ef6\u95f4\u7684\u8fde\u63a5\u5173\u7cfb\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b20\u591a\u4e2a\u88c5\u914d\u4efb\u52a1\u7684\u6570\u636e\u96c6\u9a8c\u8bc1\u8868\u793a\u63d0\u53d6\u65b9\u6cd5\uff0c\u5e76\u5728\u4eff\u771f\u73af\u5883\u4e2d\u8bc4\u4f30\u4e86\u56db\u4e2a\u590d\u6742\u88c5\u914d\u573a\u666f\u7684\u5b8c\u6574\u4efb\u52a1\u7406\u89e3\u5230\u6267\u884c\u6d41\u7a0b\u3002", "conclusion": "\u5c06\u8fde\u63a5\u5173\u7cfb\u4f5c\u4e3a\u6838\u5fc3\u539f\u8bed\u7684\u88c5\u914d\u8868\u793a\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u652f\u6301\u673a\u5668\u4eba\u88c5\u914d\u4efb\u52a1\uff0c\u4ece\u4eba\u7c7b\u8bbe\u8ba1\u7684\u88c5\u914d\u624b\u518c\u4e2d\u63d0\u53d6\u7684\u8fde\u63a5\u77e5\u8bc6\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.16085", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16085", "abs": "https://arxiv.org/abs/2510.16085", "authors": ["Xun Wei", "Pukai Zhou", "Zeyu Wang"], "title": "MoPHES:Leveraging on-device LLMs as Agent for Mobile Psychological Health Evaluation and Support", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The 2022 World Mental Health Report calls for global mental health care\nreform, amid rising prevalence of issues like anxiety and depression that\naffect nearly one billion people worldwide. Traditional in-person therapy fails\nto meet this demand, and the situation is worsened by stigma. While\ngeneral-purpose large language models (LLMs) offer efficiency for AI-driven\nmental health solutions, they underperform because they lack specialized\nfine-tuning. Existing LLM-based mental health chatbots can engage in empathetic\nconversations, but they overlook real-time user mental state assessment which\nis critical for professional counseling. This paper proposes MoPHES, a\nframework that integrates mental state evaluation, conversational support, and\nprofessional treatment recommendations. The agent developed under this\nframework uses two fine-tuned MiniCPM4-0.5B LLMs: one is fine-tuned on mental\nhealth conditions datasets to assess users' mental states and predict the\nseverity of anxiety and depression; the other is fine-tuned on multi-turn\ndialogues to handle conversations with users. By leveraging insights into\nusers' mental states, our agent provides more tailored support and professional\ntreatment recommendations. Both models are also deployed directly on mobile\ndevices to enhance user convenience and protect user privacy. Additionally, to\nevaluate the performance of MoPHES with other LLMs, we develop a benchmark for\nthe automatic evaluation of mental state prediction and multi-turn counseling\ndialogues, which includes comprehensive evaluation metrics, datasets, and\nmethods.", "AI": {"tldr": "MoPHES\u662f\u4e00\u4e2a\u96c6\u6210\u5fc3\u7406\u72b6\u6001\u8bc4\u4f30\u3001\u5bf9\u8bdd\u652f\u6301\u548c\u4e13\u4e1a\u6cbb\u7597\u5efa\u8bae\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u4e24\u4e2a\u5fae\u8c03\u7684MiniCPM4-0.5B\u6a21\u578b\uff0c\u53ef\u76f4\u63a5\u90e8\u7f72\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002", "motivation": "\u5168\u7403\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u65e5\u76ca\u4e25\u91cd\uff0c\u4f20\u7edf\u9762\u5bf9\u9762\u6cbb\u7597\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u804a\u5929\u673a\u5668\u4eba\u7f3a\u4e4f\u5b9e\u65f6\u5fc3\u7406\u72b6\u6001\u8bc4\u4f30\u80fd\u529b\u3002", "method": "\u5f00\u53d1MoPHES\u6846\u67b6\uff0c\u4f7f\u7528\u4e24\u4e2a\u4e13\u95e8\u5fae\u8c03\u7684LLM\uff1a\u4e00\u4e2a\u7528\u4e8e\u5fc3\u7406\u72b6\u6001\u8bc4\u4f30\u548c\u7126\u8651\u6291\u90c1\u4e25\u91cd\u7a0b\u5ea6\u9884\u6d4b\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u591a\u8f6e\u5bf9\u8bdd\u5904\u7406\u3002\u6a21\u578b\u53ef\u76f4\u63a5\u90e8\u7f72\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u3002", "result": "\u6784\u5efa\u4e86\u81ea\u52a8\u8bc4\u4f30\u5fc3\u7406\u72b6\u6001\u9884\u6d4b\u548c\u591a\u8f6e\u54a8\u8be2\u5bf9\u8bdd\u7684\u57fa\u51c6\uff0c\u5305\u62ec\u7efc\u5408\u8bc4\u4f30\u6307\u6807\u3001\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u3002", "conclusion": "MoPHES\u901a\u8fc7\u6574\u5408\u5fc3\u7406\u72b6\u6001\u6d1e\u5bdf\u63d0\u4f9b\u66f4\u4e2a\u6027\u5316\u7684\u652f\u6301\u548c\u4e13\u4e1a\u6cbb\u7597\u5efa\u8bae\uff0c\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002"}}
{"id": "2510.17071", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.17071", "abs": "https://arxiv.org/abs/2510.17071", "authors": ["Samuel Talkington", "Daniel Turizo", "Sergio A. Dorado-Rojas", "Rahul K. Gupta", "Daniel K. Molzahn"], "title": "Differentiating Through Power Flow Solutions for Admittance and Topology Control", "comment": "10 pages, 6 figures", "summary": "The power flow equations relate bus voltage phasors to power injections via\nthe network admittance matrix. These equations are central to the key\noperational and protection functions of power systems (e.g., optimal power flow\nscheduling and control, state estimation, protection, and fault location, among\nothers). As control, optimization, and estimation of network admittance\nparameters are central to multiple avenues of research in electric power\nsystems, we propose a linearization of power flow solutions obtained by\nimplicitly differentiating them with respect to the network admittance\nparameters. This is achieved by utilizing the implicit function theorem, in\nwhich we show that such a differentiation is guaranteed to exist under mild\nconditions and is applicable to generic power systems (radial or meshed). The\nproposed theory is applied to derive sensitivities of complex voltages, line\ncurrents, and power flows. The developed theory of linearizing the power flow\nequations around changes in the complex network admittance parameters has\nnumerous applications. We demonstrate several of these applications, such as\npredicting the nodal voltages when the network topology changes without solving\nthe power flow equations. We showcase the application for continuous admittance\ncontrol, which is used to increase the hosting capacity of a given distribution\nnetwork.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9690\u51fd\u6570\u5b9a\u7406\u7684\u6f6e\u6d41\u65b9\u7a0b\u7ebf\u6027\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u7f51\u7edc\u5bfc\u7eb3\u53c2\u6570\u53d8\u5316\u5bf9\u7cfb\u7edf\u72b6\u6001\u7684\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u62d3\u6251\u53d8\u5316\u9884\u6d4b\u548c\u8fde\u7eed\u5bfc\u7eb3\u63a7\u5236\u7b49\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7535\u529b\u7cfb\u7edf\u8fd0\u884c\u548c\u63a7\u5236\u4e2d\uff0c\u7f51\u7edc\u5bfc\u7eb3\u53c2\u6570\u7684\u4f18\u5316\u3001\u63a7\u5236\u548c\u4f30\u8ba1\u662f\u6838\u5fc3\u7814\u7a76\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u53cd\u590d\u6c42\u89e3\u975e\u7ebf\u6027\u6f6e\u6d41\u65b9\u7a0b\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u5229\u7528\u9690\u51fd\u6570\u5b9a\u7406\u5bf9\u6f6e\u6d41\u65b9\u7a0b\u8fdb\u884c\u9690\u5f0f\u5fae\u5206\uff0c\u63a8\u5bfc\u51fa\u5173\u4e8e\u7f51\u7edc\u5bfc\u7eb3\u53c2\u6570\u7684\u7ebf\u6027\u5316\u8868\u8fbe\u5f0f\uff0c\u9002\u7528\u4e8e\u8f90\u5c04\u72b6\u6216\u7f51\u72b6\u7b49\u5404\u79cd\u7535\u7f51\u7ed3\u6784\u3002", "result": "\u5efa\u7acb\u4e86\u590d\u7535\u538b\u3001\u7ebf\u8def\u7535\u6d41\u548c\u529f\u7387\u6f6e\u6d41\u5bf9\u5bfc\u7eb3\u53c2\u6570\u7684\u7075\u654f\u5ea6\u5173\u7cfb\uff0c\u80fd\u591f\u5728\u7f51\u7edc\u62d3\u6251\u53d8\u5316\u65f6\u9884\u6d4b\u8282\u70b9\u7535\u538b\u800c\u65e0\u9700\u91cd\u65b0\u6c42\u89e3\u6f6e\u6d41\u65b9\u7a0b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6f6e\u6d41\u65b9\u7a0b\u7ebf\u6027\u5316\u7406\u8bba\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u8fde\u7eed\u5bfc\u7eb3\u63a7\u5236\u65b9\u9762\uff0c\u53ef\u7528\u4e8e\u63d0\u9ad8\u914d\u7535\u7f51\u7684\u627f\u8f7d\u80fd\u529b\u3002"}}
{"id": "2510.16424", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16424", "abs": "https://arxiv.org/abs/2510.16424", "authors": ["Dan Guo", "Xibin Jin", "Shuai Wang", "Zhigang Wen", "Miaowen Wen", "Chengzhong Xu"], "title": "Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach", "comment": null, "summary": "Edge robotics involves frequent exchanges of large-volume multi-modal data.\nExisting methods ignore the interdependency between robotic functionalities and\ncommunication conditions, leading to excessive communication overhead. This\npaper revolutionizes edge robotics systems through integrated perception,\nmotion, and communication (IPMC). As such, robots can dynamically adapt their\ncommunication strategies (i.e., compression ratio, transmission frequency,\ntransmit power) by leveraging the knowledge of robotic perception and motion\ndynamics, thus reducing the need for excessive sensor data uploads.\nFurthermore, by leveraging the learning to optimize (LTO) paradigm, an\nimitation learning neural network is designed and implemented, which reduces\nthe computational complexity by over 10x compared to state-of-the art\noptimization solvers. Experiments demonstrate the superiority of the proposed\nIPMC and the real-time execution capability of LTO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u96c6\u6210\u611f\u77e5\u3001\u8fd0\u52a8\u548c\u901a\u4fe1(IPMC)\u7684\u8fb9\u7aef\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u901a\u4fe1\u7b56\u7565\u6765\u51cf\u5c11\u4f20\u611f\u5668\u6570\u636e\u4e0a\u4f20\u9700\u6c42\uff0c\u5e76\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u673a\u5668\u4eba\u529f\u80fd\u4e0e\u901a\u4fe1\u6761\u4ef6\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u901a\u4fe1\u5f00\u9500\u8fc7\u5927\u3002", "method": "\u91c7\u7528\u96c6\u6210\u611f\u77e5\u3001\u8fd0\u52a8\u548c\u901a\u4fe1(IPMC)\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\u52a8\u6001\u8c03\u6574\u538b\u7f29\u6bd4\u3001\u4f20\u8f93\u9891\u7387\u548c\u53d1\u5c04\u529f\u7387\u7b49\u901a\u4fe1\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eIPMC\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6a21\u4eff\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u6bd4\u6700\u4f18\u5316\u6c42\u89e3\u5668\u964d\u4f4e10\u500d\u4ee5\u4e0a\uff0c\u5177\u5907\u5b9e\u65f6\u6267\u884c\u80fd\u529b\u3002", "conclusion": "IPMC\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u673a\u5668\u4eba\u611f\u77e5\u3001\u8fd0\u52a8\u548c\u901a\u4fe1\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u6a21\u4eff\u5b66\u4e60\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5b9e\u65f6\u4f18\u5316\u3002"}}
{"id": "2510.16366", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16366", "abs": "https://arxiv.org/abs/2510.16366", "authors": ["Xinyi Li", "Zhiqiang Guo", "Qinglang Guo", "Hao Jin", "Weizhi Ma", "Min Zhang"], "title": "Integrating LLM and Diffusion-Based Agents for Social Simulation", "comment": "10 pages, 3 figures, 4 tables", "summary": "Agent-based social simulation provides a valuable methodology for predicting\nsocial information diffusion, yet existing approaches face two primary\nlimitations. Traditional agent models often rely on rigid behavioral rules and\nlack semantic understanding of textual content, while emerging large language\nmodel (LLM)-based agents incur prohibitive computational costs at scale. To\naddress these challenges, we propose a hybrid simulation framework that\nstrategically integrates LLM-driven agents with diffusion model-based agents.\nThe framework employs LLM-based agents to simulate a core subset of users with\nrich semantic reasoning, while a diffusion model handles the remaining\npopulation efficiently. Although the two agent types operate on disjoint user\ngroups, both incorporate key factors including user personalization, social\ninfluence, and content awareness, and interact through a coordinated simulation\nprocess. Extensive experiments on three real-world datasets demonstrate that\nour framework outperforms existing methods in prediction accuracy, validating\nthe effectiveness of its modular design.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6a21\u62df\u6846\u67b6\uff0c\u5c06LLM\u9a71\u52a8\u4ee3\u7406\u4e0e\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u4ee3\u7406\u76f8\u7ed3\u5408\uff0c\u4ee5\u5e73\u8861\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9884\u6d4b\u51c6\u786e\u6027\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u4ee3\u7406\u7684\u793e\u4f1a\u6a21\u62df\u65b9\u6cd5\u7684\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a\u4f20\u7edf\u4ee3\u7406\u6a21\u578b\u7f3a\u4e4f\u6587\u672c\u5185\u5bb9\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u800c\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u5728\u5927\u89c4\u6a21\u5e94\u7528\u65f6\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6a21\u62df\u6846\u67b6\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u4ee3\u7406\u6a21\u62df\u6838\u5fc3\u7528\u6237\u5b50\u96c6\u8fdb\u884c\u4e30\u5bcc\u8bed\u4e49\u63a8\u7406\uff0c\u540c\u65f6\u4f7f\u7528\u6269\u6563\u6a21\u578b\u9ad8\u6548\u5904\u7406\u5176\u4f59\u7528\u6237\u7fa4\u4f53\uff0c\u4e24\u79cd\u4ee3\u7406\u7c7b\u578b\u901a\u8fc7\u534f\u8c03\u7684\u6a21\u62df\u8fc7\u7a0b\u8fdb\u884c\u4ea4\u4e92\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u6a21\u62df\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u4ee3\u7406\u6a21\u578b\u548cLLM\u4ee3\u7406\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u6218\u7565\u6027\u5730\u7ed3\u5408\u4e24\u79cd\u4ee3\u7406\u7c7b\u578b\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2510.17129", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17129", "abs": "https://arxiv.org/abs/2510.17129", "authors": ["Wenbing Tang", "Meilin Zhu", "Fenghua Wu", "Yang Liu"], "title": "Semantic Intelligence: A Bio-Inspired Cognitive Framework for Embodied Agents", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have greatly enhanced\nnatural language understanding and content generation. However, these models\nprimarily operate in disembodied digital environments and lack interaction with\nthe physical world. To address this limitation, Embodied Artificial\nIntelligence (EAI) has emerged, focusing on agents that can perceive and\ninteract with their surroundings. Despite progress, current embodied agents\nface challenges in unstructured real-world environments due to insufficient\nsemantic intelligence, which is critical for understanding and reasoning about\ncomplex tasks. This paper introduces the Semantic Intelligence-Driven Embodied\n(SIDE) agent framework, which integrates a hierarchical semantic cognition\narchitecture with a semantic-driven decision-making process. This enables\nagents to reason about and interact with the physical world in a contextually\nadaptive manner. The framework is inspired by biological cognitive mechanisms\nand utilizes bio-inspired principles to design a semantic cognitive\narchitecture that mimics how humans and animals integrate and process sensory\ninformation. We present this framework as a step toward developing more\nintelligent and versatile embodied agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u8bed\u4e49\u667a\u80fd\u9a71\u52a8\u7684\u5177\u8eab\u4ee3\u7406\u6846\u67b6SIDE\uff0c\u901a\u8fc7\u5206\u5c42\u8bed\u4e49\u8ba4\u77e5\u67b6\u6784\u548c\u8bed\u4e49\u9a71\u52a8\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u5728\u7269\u7406\u4e16\u754c\u4e2d\u8fdb\u884c\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u7684\u63a8\u7406\u548c\u4ea4\u4e92\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u5728\u6570\u5b57\u73af\u5883\u4e2d\u8fd0\u884c\uff0c\u7f3a\u4e4f\u4e0e\u7269\u7406\u4e16\u754c\u7684\u4ea4\u4e92\u3002\u73b0\u6709\u5177\u8eab\u667a\u80fd\u4f53\u5728\u975e\u7ed3\u6784\u5316\u73b0\u5b9e\u73af\u5883\u4e2d\u9762\u4e34\u8bed\u4e49\u667a\u80fd\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u65e0\u6cd5\u5145\u5206\u7406\u89e3\u548c\u63a8\u7406\u590d\u6742\u4efb\u52a1\u3002", "method": "\u5f15\u5165SIDE\u6846\u67b6\uff0c\u6574\u5408\u5206\u5c42\u8bed\u4e49\u8ba4\u77e5\u67b6\u6784\u548c\u8bed\u4e49\u9a71\u52a8\u51b3\u7b56\u8fc7\u7a0b\uff0c\u53d7\u751f\u7269\u8ba4\u77e5\u673a\u5236\u542f\u53d1\uff0c\u8bbe\u8ba1\u6a21\u4eff\u4eba\u7c7b\u548c\u52a8\u7269\u6574\u5408\u5904\u7406\u611f\u5b98\u4fe1\u606f\u7684\u8bed\u4e49\u8ba4\u77e5\u67b6\u6784\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u8fdb\u884c\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u63a8\u7406\u548c\u4ea4\u4e92\u7684\u5177\u8eab\u4ee3\u7406\u6846\u67b6\uff0c\u4e3a\u6784\u5efa\u66f4\u667a\u80fd\u548c\u901a\u7528\u7684\u5177\u8eab\u4ee3\u7406\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002", "conclusion": "SIDE\u6846\u67b6\u901a\u8fc7\u8bed\u4e49\u667a\u80fd\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5177\u8eab\u4ee3\u7406\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u66f4\u667a\u80fd\u7684\u5177\u8eab\u667a\u80fd\u4f53\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.16435", "categories": ["cs.RO", "cs.CL", "cs.HC", "I.2.9; H.5.2; H.5.0; I.2.8; I.2.7; J.4"], "pdf": "https://arxiv.org/pdf/2510.16435", "abs": "https://arxiv.org/abs/2510.16435", "authors": ["Lennart Wachowiak", "Andrew Coles", "Gerard Canal", "Oya Celiktutan"], "title": "What Questions Should Robots Be Able to Answer? A Dataset of User Questions for Explainable Robotics", "comment": null, "summary": "With the growing use of large language models and conversational interfaces\nin human-robot interaction, robots' ability to answer user questions is more\nimportant than ever. We therefore introduce a dataset of 1,893 user questions\nfor household robots, collected from 100 participants and organized into 12\ncategories and 70 subcategories. Most work in explainable robotics focuses on\nwhy-questions. In contrast, our dataset provides a wide variety of questions,\nfrom questions about simple execution details to questions about how the robot\nwould act in hypothetical scenarios -- thus giving roboticists valuable\ninsights into what questions their robot needs to be able to answer. To collect\nthe dataset, we created 15 video stimuli and 7 text stimuli, depicting robots\nperforming varied household tasks. We then asked participants on Prolific what\nquestions they would want to ask the robot in each portrayed situation. In the\nfinal dataset, the most frequent categories are questions about task execution\ndetails (22.5%), the robot's capabilities (12.7%), and performance assessments\n(11.3%). Although questions about how robots would handle potentially difficult\nscenarios and ensure correct behavior are less frequent, users rank them as the\nmost important for robots to be able to answer. Moreover, we find that users\nwho identify as novices in robotics ask different questions than more\nexperienced users. Novices are more likely to inquire about simple facts, such\nas what the robot did or the current state of the environment. As robots enter\nenvironments shared with humans and language becomes central to giving\ninstructions and interaction, this dataset provides a valuable foundation for\n(i) identifying the information robots need to log and expose to conversational\ninterfaces, (ii) benchmarking question-answering modules, and (iii) designing\nexplanation strategies that align with user expectations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u4e2a\u5305\u542b1,893\u4e2a\u7528\u6237\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u5bb6\u5ead\u673a\u5668\u4eba\u768412\u4e2a\u7c7b\u522b\u548c70\u4e2a\u5b50\u7c7b\u522b\uff0c\u63ed\u793a\u4e86\u7528\u6237\u6700\u5173\u5fc3\u7684\u95ee\u9898\u7c7b\u578b\u53ca\u5176\u91cd\u8981\u6027\u6392\u5e8f\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5bf9\u8bdd\u754c\u9762\u5728\u4eba\u673a\u4ea4\u4e92\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u673a\u5668\u4eba\u56de\u7b54\u7528\u6237\u95ee\u9898\u7684\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u53ef\u89e3\u91ca\u673a\u5668\u4eba\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\"\u4e3a\u4ec0\u4e48\"\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7528\u6237\u5b9e\u9645\u4f1a\u95ee\u7684\u5404\u79cd\u95ee\u9898\u7c7b\u578b\u7684\u5168\u9762\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u521b\u5efa15\u4e2a\u89c6\u9891\u523a\u6fc0\u548c7\u4e2a\u6587\u672c\u523a\u6fc0\uff0c\u63cf\u7ed8\u673a\u5668\u4eba\u6267\u884c\u5404\u79cd\u5bb6\u5ead\u4efb\u52a1\u7684\u60c5\u666f\uff0c\u5728Prolific\u5e73\u53f0\u4e0a\u5411100\u540d\u53c2\u4e0e\u8005\u6536\u96c6\u4ed6\u4eec\u5728\u6bcf\u4e2a\u60c5\u5883\u4e0b\u4f1a\u95ee\u673a\u5668\u4eba\u7684\u95ee\u9898\u3002", "result": "\u6570\u636e\u96c6\u4e2d\u6700\u5e38\u89c1\u7684\u7c7b\u522b\u662f\u4efb\u52a1\u6267\u884c\u7ec6\u8282\uff0822.5%\uff09\u3001\u673a\u5668\u4eba\u80fd\u529b\uff0812.7%\uff09\u548c\u6027\u80fd\u8bc4\u4f30\uff0811.3%\uff09\u3002\u7528\u6237\u8ba4\u4e3a\u5173\u4e8e\u673a\u5668\u4eba\u5982\u4f55\u5904\u7406\u56f0\u96be\u573a\u666f\u548c\u786e\u4fdd\u6b63\u786e\u884c\u4e3a\u7684\u95ee\u9898\u6700\u91cd\u8981\u3002\u65b0\u624b\u7528\u6237\u4e0e\u6709\u7ecf\u9a8c\u7528\u6237\u7684\u95ee\u9898\u7c7b\u578b\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u8bc6\u522b\u673a\u5668\u4eba\u9700\u8981\u8bb0\u5f55\u548c\u66b4\u9732\u7ed9\u5bf9\u8bdd\u754c\u9762\u7684\u4fe1\u606f\u3001\u57fa\u51c6\u6d4b\u8bd5\u95ee\u7b54\u6a21\u5757\u4ee5\u53ca\u8bbe\u8ba1\u7b26\u5408\u7528\u6237\u671f\u671b\u7684\u89e3\u91ca\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9d\u8d35\u57fa\u7840\u3002"}}
{"id": "2510.16459", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16459", "abs": "https://arxiv.org/abs/2510.16459", "authors": ["Ewa Makowska-T\u0142umak", "Sylwia Bedy\u0144ska", "Kinga Skorupska", "Rados\u0142aw Nielek"], "title": "Women have it Worse: an ICT Workplace Digital Transformation Stress Gender Gap", "comment": null, "summary": "Although information and communication technologies (ICT) solutions have\npositive outcomes for both companies and employees, the digital transformation\n(DT) could have an impact on the well-being of employees. The jobs of the\nemployees became more demanding, and they were expected to learn ICT skills and\ncope with ICT workloads and hassles. Due to negative stereotypes about women's\ndeficiency in technology, these ICT problems could affect female and male\nemployees differently. Thus, we predicted that this additional pressure may\nmanifest itself in higher levels of digital transformation stress (DTS) in\nfemale employees. The results confirmed this prediction and indicated the\nexistence of a gender gap in DTS, measured two-fold - in sentiment analysis of\nhelp desk tickets and self-report using a psychological scale. Based on these\nresults, we explore the need to discuss possible solutions and tools to support\nwomen in ICT-heavy workplace contexts.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6570\u5b57\u5316\u8f6c\u578b\u4f1a\u7ed9\u5973\u6027\u5458\u5de5\u5e26\u6765\u66f4\u9ad8\u7684\u6570\u5b57\u8f6c\u578b\u538b\u529b\uff0c\u5b58\u5728\u6027\u522b\u5dee\u8ddd\uff0c\u9700\u8981\u901a\u8fc7\u89e3\u51b3\u65b9\u6848\u548c\u5de5\u5177\u6765\u652f\u6301\u5973\u6027\u5728ICT\u5bc6\u96c6\u578b\u5de5\u4f5c\u73af\u5883\u4e2d\u7684\u53d1\u5c55\u3002", "motivation": "\u63a2\u8ba8\u6570\u5b57\u5316\u8f6c\u578b\u5bf9\u5458\u5de5\u798f\u7949\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u7531\u4e8e\u5bf9\u5973\u6027\u6280\u672f\u80fd\u529b\u7684\u8d1f\u9762\u523b\u677f\u5370\u8c61\uff0c\u53ef\u80fd\u5bfc\u81f4\u5973\u6027\u5458\u5de5\u5728ICT\u5de5\u4f5c\u73af\u5883\u4e2d\u627f\u53d7\u66f4\u5927\u538b\u529b\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\u6d4b\u91cf\u6570\u5b57\u8f6c\u578b\u538b\u529b\uff1a\u5bf9\u5e2e\u52a9\u53f0\u5de5\u5355\u8fdb\u884c\u60c5\u611f\u5206\u6790\uff0c\u4ee5\u53ca\u4f7f\u7528\u5fc3\u7406\u91cf\u8868\u8fdb\u884c\u81ea\u6211\u62a5\u544a\u8c03\u67e5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8bc1\u5b9e\u4e86\u9884\u6d4b\uff0c\u663e\u793a\u5973\u6027\u5458\u5de5\u5728\u6570\u5b57\u8f6c\u578b\u538b\u529b\u65b9\u9762\u663e\u8457\u9ad8\u4e8e\u7537\u6027\u5458\u5de5\uff0c\u5b58\u5728\u660e\u663e\u7684\u6027\u522b\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u5728ICT\u5bc6\u96c6\u578b\u5de5\u4f5c\u73af\u5883\u4e2d\u8ba8\u8bba\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u548c\u5de5\u5177\uff0c\u4ee5\u652f\u6301\u5973\u6027\u5458\u5de5\u5e94\u5bf9\u6570\u5b57\u8f6c\u578b\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2510.17155", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17155", "abs": "https://arxiv.org/abs/2510.17155", "authors": ["Mohammadamin Lari"], "title": "A Data-Driven Framework for Online Mitigation of False Data Injection Signals in Networked Control Systems", "comment": "17 pages, 9 figures", "summary": "This paper introduces a novel two-stage framework for online mitigation of\nFalse Data Injection (FDI) signals to improve the resiliency of Networked\nControl Systems (NCSs) and ensure their safe operation in the presence of\nmalicious activities. The first stage involves meta learning to select a base\ntime series forecasting model within a stacked ensemble learning architecture.\nThis is achieved by converting time series data into scalograms using\ncontinuous wavelet transform, which are then split into image frames to\ngenerate a scalo-temporal representation of the data and to distinguish between\ndifferent complexity levels of time series data based on an entropy metric\nusing a convolutional neural network. In the second stage, the selected model\nmitigates false data injection signals in real-time. The proposed framework's\neffectiveness is demonstrated through rigorous simulations involving the\nformation control of differential drive mobile robots. By addressing the\nsecurity challenges in NCSs, this framework offers a promising approach to\nmaintaining system integrity and ensuring operational safety.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7ebf\u7f13\u89e3\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u4fe1\u53f7\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u548c\u96c6\u6210\u5b66\u4e60\u63d0\u9ad8\u7cfb\u7edf\u5f39\u6027\uff0c\u786e\u4fdd\u5728\u6076\u610f\u6d3b\u52a8\u5b58\u5728\u65f6\u7684\u5b89\u5168\u8fd0\u884c\u3002", "motivation": "\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf\u9762\u4e34\u865a\u5047\u6570\u636e\u6ce8\u5165\u7b49\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u5b9e\u65f6\u68c0\u6d4b\u548c\u7f13\u89e3\u6076\u610f\u4fe1\u53f7\u4ee5\u786e\u4fdd\u7cfb\u7edf\u5b89\u5168\u548c\u5b8c\u6574\u6027\u3002", "method": "\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5143\u5b66\u4e60\u5728\u5806\u53e0\u96c6\u6210\u5b66\u4e60\u67b6\u6784\u4e2d\u9009\u62e9\u57fa\u7840\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u8fde\u7eed\u5c0f\u6ce2\u53d8\u6362\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u8f6c\u6362\u4e3a\u5c3a\u5ea6\u56fe\uff0c\u518d\u5206\u5272\u4e3a\u56fe\u50cf\u5e27\u751f\u6210\u5c3a\u5ea6-\u65f6\u95f4\u8868\u793a\uff0c\u57fa\u4e8e\u71b5\u5ea6\u91cf\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u533a\u5206\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u590d\u6742\u5ea6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5b9e\u65f6\u7f13\u89e3\u865a\u5047\u6570\u636e\u6ce8\u5165\u4fe1\u53f7\u3002", "result": "\u901a\u8fc7\u5dee\u52a8\u9a71\u52a8\u79fb\u52a8\u673a\u5668\u4eba\u7f16\u961f\u63a7\u5236\u7684\u4e25\u683c\u4eff\u771f\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u89e3\u51b3\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf\u7684\u5b89\u5168\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u7ef4\u62a4\u7cfb\u7edf\u5b8c\u6574\u6027\u5e76\u786e\u4fdd\u64cd\u4f5c\u5b89\u5168\u3002"}}
{"id": "2510.16500", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16500", "abs": "https://arxiv.org/abs/2510.16500", "authors": ["Chen Min", "Jilin Mei", "Heng Zhai", "Shuai Wang", "Tong Sun", "Fanjie Kong", "Haoyang Li", "Fangyuan Mao", "Fuyang Liu", "Shuo Wang", "Yiming Nie", "Qi Zhu", "Liang Xiao", "Dawei Zhao", "Yu Hu"], "title": "Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks", "comment": "Off-road robotics", "summary": "A major bottleneck in off-road autonomous driving research lies in the\nscarcity of large-scale, high-quality datasets and benchmarks. To bridge this\ngap, we present ORAD-3D, which, to the best of our knowledge, is the largest\ndataset specifically curated for off-road autonomous driving. ORAD-3D covers a\nwide spectrum of terrains, including woodlands, farmlands, grasslands,\nriversides, gravel roads, cement roads, and rural areas, while capturing\ndiverse environmental variations across weather conditions (sunny, rainy,\nfoggy, and snowy) and illumination levels (bright daylight, daytime, twilight,\nand nighttime). Building upon this dataset, we establish a comprehensive suite\nof benchmark evaluations spanning five fundamental tasks: 2D free-space\ndetection, 3D occupancy prediction, rough GPS-guided path planning,\nvision-language model-driven autonomous driving, and world model for off-road\nenvironments. Together, the dataset and benchmarks provide a unified and robust\nresource for advancing perception and planning in challenging off-road\nscenarios. The dataset and code will be made publicly available at\nhttps://github.com/chaytonmin/ORAD-3D.", "AI": {"tldr": "ORAD-3D\u662f\u76ee\u524d\u6700\u5927\u7684\u8d8a\u91ce\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u591a\u79cd\u5730\u5f62\u548c\u73af\u5883\u6761\u4ef6\uff0c\u5e76\u5efa\u7acb\u4e86\u5305\u542b5\u4e2a\u6838\u5fc3\u4efb\u52a1\u7684\u57fa\u51c6\u8bc4\u6d4b\u4f53\u7cfb\u3002", "motivation": "\u8d8a\u91ce\u81ea\u52a8\u9a7e\u9a76\u7814\u7a76\u9762\u4e34\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7a00\u7f3a\u7684\u74f6\u9888\u95ee\u9898\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u4e86ORAD-3D\u6570\u636e\u96c6\uff0c\u8986\u76d6\u6797\u5730\u3001\u519c\u7530\u3001\u8349\u5730\u3001\u6cb3\u5cb8\u3001\u7802\u77f3\u8def\u3001\u6c34\u6ce5\u8def\u548c\u4e61\u6751\u5730\u533a\u7b49\u591a\u79cd\u5730\u5f62\uff0c\u5e76\u6355\u6349\u4e0d\u540c\u5929\u6c14\u6761\u4ef6\u548c\u5149\u7167\u6c34\u5e73\u7684\u73af\u5883\u53d8\u5316\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b2D\u81ea\u7531\u7a7a\u95f4\u68c0\u6d4b\u30013D\u5360\u636e\u9884\u6d4b\u3001\u7c97\u7565GPS\u5f15\u5bfc\u8def\u5f84\u89c4\u5212\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u81ea\u52a8\u9a7e\u9a76\u548c\u8d8a\u91ce\u73af\u5883\u4e16\u754c\u6a21\u578b\u7b495\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u8bc4\u6d4b\u4f53\u7cfb\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u548c\u57fa\u51c6\u4e3a\u63a8\u8fdb\u6311\u6218\u6027\u8d8a\u91ce\u573a\u666f\u4e0b\u7684\u611f\u77e5\u4e0e\u89c4\u5212\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u5f3a\u5927\u7684\u8d44\u6e90\u3002"}}
{"id": "2510.16847", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16847", "abs": "https://arxiv.org/abs/2510.16847", "authors": ["Roberto Massi De Oliveira", "M^onica Cristina Garbin", "Rodolfo Azevedo"], "title": "Global Overview of Computational Thinking and Digital Tools for Teaching", "comment": "36 pages, 7 figures, 4 tables", "summary": "Computational Thinking (CT) has emerged as a critical component in modern\neducation, essential to equip students with the skills necessary to thrive in a\ntechnology-driven world. This survey provides a comprehensive analysis of the\npresence and integration of CT in school curricula across various countries. In\naddition, this study categorizes digital tools into groups such as visual\nprogramming, textual programming, electronic games, modeling, and simulation,\nassessing their use in different educational settings. Furthermore, it examines\nhow these tools are employed in various contexts, including the areas of\nknowledge and age groups they target, and the specific skills they help\ndevelop. The research also identifies key CT competencies that have been\nimproved through these tools, including Cognitive and Analytical Competencies\n(CAC), Technical and Computational Competencies (TCC) and Social and Emotional\nCompetencies (SEC). Furthermore, the study highlights recurring challenges in\nthe implementation of digital tools for CT development, such as inadequate\ninfrastructure, difficulties in the usability of the tool, teacher training,\nadapting pedagogical practices, and measuring student CT skills. Finally, it\nproposes areas for future research to address these challenges and advance CT\neducation.", "AI": {"tldr": "\u672c\u8c03\u67e5\u5bf9\u5404\u56fd\u5b66\u6821\u8bfe\u7a0b\u4e2d\u8ba1\u7b97\u601d\u7ef4\u7684\u6574\u5408\u60c5\u51b5\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u5c06\u6570\u5b57\u5de5\u5177\u5206\u7c7b\u5e76\u8bc4\u4f30\u5176\u5728\u4e0d\u540c\u6559\u80b2\u73af\u5883\u4e2d\u7684\u4f7f\u7528\uff0c\u8bc6\u522b\u4e86\u8ba1\u7b97\u601d\u7ef4\u80fd\u529b\u7684\u6539\u8fdb\u9886\u57df\uff0c\u5e76\u6307\u51fa\u4e86\u5b9e\u65bd\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u8ba1\u7b97\u601d\u7ef4\u5df2\u6210\u4e3a\u73b0\u4ee3\u6559\u80b2\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u9700\u8981\u57f9\u517b\u5b66\u751f\u9002\u5e94\u6280\u672f\u9a71\u52a8\u4e16\u754c\u6240\u9700\u7684\u6280\u80fd\u3002\u672c\u7814\u7a76\u65e8\u5728\u5168\u9762\u4e86\u89e3\u8ba1\u7b97\u601d\u7ef4\u5728\u5b66\u6821\u8bfe\u7a0b\u4e2d\u7684\u6574\u5408\u73b0\u72b6\u3002", "method": "\u91c7\u7528\u8c03\u67e5\u5206\u6790\u65b9\u6cd5\uff0c\u5bf9\u5404\u56fd\u5b66\u6821\u8bfe\u7a0b\u4e2d\u7684\u8ba1\u7b97\u601d\u7ef4\u6574\u5408\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u5e76\u5c06\u6570\u5b57\u5de5\u5177\u5206\u7c7b\u4e3a\u53ef\u89c6\u5316\u7f16\u7a0b\u3001\u6587\u672c\u7f16\u7a0b\u3001\u7535\u5b50\u6e38\u620f\u3001\u5efa\u6a21\u548c\u4eff\u771f\u7b49\u7c7b\u522b\uff0c\u8bc4\u4f30\u5176\u5728\u5404\u79cd\u6559\u80b2\u73af\u5883\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6570\u5b57\u5de5\u5177\u5728\u63d0\u5347\u8ba1\u7b97\u601d\u7ef4\u80fd\u529b\u65b9\u9762\u53d1\u6325\u4e86\u91cd\u8981\u4f5c\u7528\uff0c\u5305\u62ec\u8ba4\u77e5\u5206\u6790\u80fd\u529b\u3001\u6280\u672f\u8ba1\u7b97\u80fd\u529b\u4ee5\u53ca\u793e\u4f1a\u60c5\u611f\u80fd\u529b\u3002\u540c\u65f6\u8bc6\u522b\u4e86\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5982\u57fa\u7840\u8bbe\u65bd\u4e0d\u8db3\u3001\u5de5\u5177\u53ef\u7528\u6027\u95ee\u9898\u3001\u6559\u5e08\u57f9\u8bad\u9700\u6c42\u7b49\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8ba1\u7b97\u601d\u7ef4\u6559\u80b2\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u4e86\u89e3\u51b3\u5f53\u524d\u6311\u6218\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63a8\u52a8\u8ba1\u7b97\u601d\u7ef4\u6559\u80b2\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2510.17176", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17176", "abs": "https://arxiv.org/abs/2510.17176", "authors": ["Lakshmikanta Sau", "Priyadarshi Mukherjee", "Sasthi C. Ghosh"], "title": "Generalized Group Selection Strategies for Self-sustainable RIS-aided Communication", "comment": "This work has been submitted to an IEEE journal for possible\n  publication", "summary": "Reconfigurable intelligent surface (RIS) is a cutting-edge communication\ntechnology that has been proposed as aviable option for beyond fifth-generation\nwireless communication networks. This paper investigates various group\nselection strategies in the context of grouping-based self-sustainable\nRIS-aided device-to-device (D2D) communication with spatially correlated\nwireless channels. Specifically, we consider both power splitting (PS) and time\nswitching (TS) configurations, of the self-sustainable RIS to analyze the\nsystem performance and propose appropriate bounds on the choice of system\nparameters. The analysis takes into account a simplified linear energy\nharvesting (EH) model as well as a practical non-linear EH model. Based on the\napplication requirements, we propose various group selection strategies at the\nRIS. Notably, each strategy schedules the k-th best available group at the RIS\nbased on the end-to-end signal-to-noise ratio (SNR) and also the energy\nharvested at a particular group of the RIS. Accordingly, by using tools from\nhigh order statistics, we derive analytical expressions for the outage\nprobability of each selection strategy. Moreover, by applying the tools from\nextreme value theory, we also investigate an asymptotic scenario, where the\nnumber of groups available for selection at an RIS approaches infinity. The\nnontrivial insights obtained from this approach is especially beneficial in\napplications like large intelligent surface-aided wireless communication.\nFinally, the numerical results demonstrate the importance and benefits of the\nproposed approaches in terms of metrics such as the data throughput and the\noutage (both data and energy) performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u7a7a\u95f4\u76f8\u5173\u65e0\u7ebf\u4fe1\u9053\u4e0b\uff0c\u57fa\u4e8e\u5206\u7ec4\u7684\u81ea\u53ef\u6301\u7eedRIS\u8f85\u52a9D2D\u901a\u4fe1\u4e2d\u7684\u5404\u79cd\u7ec4\u9009\u62e9\u7b56\u7565\uff0c\u5206\u6790\u4e86\u529f\u7387\u5206\u914d\u548c\u65f6\u95f4\u5207\u6362\u914d\u7f6e\u4e0b\u7684\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u7cfb\u7edf\u53c2\u6570\u9009\u62e9\u7684\u9002\u5f53\u8fb9\u754c\u3002", "motivation": "\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u662f\u8d85\u8d8a\u7b2c\u4e94\u4ee3\u65e0\u7ebf\u901a\u4fe1\u7f51\u7edc\u7684\u524d\u6cbf\u6280\u672f\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u5728\u81ea\u53ef\u6301\u7eedRIS\u8f85\u52a9D2D\u901a\u4fe1\u4e2d\uff0c\u5982\u4f55\u901a\u8fc7\u6709\u6548\u7684\u7ec4\u9009\u62e9\u7b56\u7565\u6765\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8003\u8651\u5b9e\u9645\u975e\u7ebf\u6027\u80fd\u91cf\u6536\u96c6\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u91c7\u7528\u529f\u7387\u5206\u914d(PS)\u548c\u65f6\u95f4\u5207\u6362(TS)\u4e24\u79cd\u81ea\u53ef\u6301\u7eedRIS\u914d\u7f6e\uff0c\u8003\u8651\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u80fd\u91cf\u6536\u96c6\u6a21\u578b\uff0c\u63d0\u51fa\u57fa\u4e8e\u7aef\u5230\u7aef\u4fe1\u566a\u6bd4\u548c\u80fd\u91cf\u6536\u96c6\u7684\u7ec4\u9009\u62e9\u7b56\u7565\uff0c\u4f7f\u7528\u9ad8\u9636\u7edf\u8ba1\u5de5\u5177\u63a8\u5bfc\u4e2d\u65ad\u6982\u7387\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u5e76\u5e94\u7528\u6781\u503c\u7406\u8bba\u5206\u6790\u7ec4\u6570\u8d8b\u4e8e\u65e0\u7a77\u7684\u6e10\u8fd1\u60c5\u51b5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6570\u636e\u541e\u5410\u91cf\u548c\u4e2d\u65ad\u6027\u80fd\uff08\u5305\u62ec\u6570\u636e\u548c\u80fd\u91cf\u4e2d\u65ad\uff09\u65b9\u9762\u5177\u6709\u91cd\u8981\u4f18\u52bf\u548c\u6548\u76ca\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u667a\u80fd\u8868\u9762\u8f85\u52a9\u65e0\u7ebf\u901a\u4fe1\u5e94\u7528\u4e2d\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u7684\u7ec4\u9009\u62e9\u7b56\u7565\uff0c\u672c\u6587\u4e3a\u81ea\u53ef\u6301\u7eedRIS\u8f85\u52a9D2D\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6027\u80fd\u4f18\u5316\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u7ec4\u9009\u62e9\u573a\u666f\u4e0b\uff0c\u6240\u83b7\u5f97\u7684\u975e\u5e73\u51e1\u89c1\u89e3\u5bf9\u5b9e\u9645\u5e94\u7528\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2510.16517", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16517", "abs": "https://arxiv.org/abs/2510.16517", "authors": ["Haokai Ding", "Wenzeng Zhang"], "title": "A Novel Gripper with Semi-Peaucellier Linkage and Idle-Stroke Mechanism for Linear Pinching and Self-Adaptive Grasping", "comment": "Accepted author manuscript (AAM) for IEEE/RSJ IROS 2025. 6 pages, 10\n  figures", "summary": "This paper introduces a novel robotic gripper, named as the SPD gripper. It\nfeatures a palm and two mechanically identical and symmetrically arranged\nfingers, which can be driven independently or by a single motor. The fingertips\nof the fingers follow a linear motion trajectory, facilitating the grasping of\nobjects of various sizes on a tabletop without the need to adjust the overall\nheight of the gripper. Traditional industrial grippers with parallel gripping\ncapabilities often exhibit an arcuate motion at the fingertips, requiring the\nentire robotic arm to adjust its height to avoid collisions with the tabletop.\nThe SPD gripper, with its linear parallel gripping mechanism, effectively\naddresses this issue. Furthermore, the SPD gripper possesses adaptive\ncapabilities, accommodating objects of different shapes and sizes. This paper\npresents the design philosophy, fundamental composition principles, and\noptimization analysis theory of the SPD gripper. Based on the design theory, a\nrobotic gripper prototype was developed and tested. The experimental results\ndemonstrate that the robotic gripper successfully achieves linear parallel\ngripping functionality and exhibits good adaptability. In the context of the\nongoing development of embodied intelligence technologies, this robotic gripper\ncan assist various robots in achieving effective grasping, laying a solid\nfoundation for collecting data to enhance deep learning training.", "AI": {"tldr": "SPD\u5939\u722a\u91c7\u7528\u7ebf\u6027\u5e73\u884c\u5939\u6301\u673a\u5236\uff0c\u89e3\u51b3\u4f20\u7edf\u5de5\u4e1a\u5939\u722a\u5f27\u5f62\u8fd0\u52a8\u9700\u8981\u8c03\u6574\u9ad8\u5ea6\u7684\u95ee\u9898\uff0c\u5177\u6709\u81ea\u9002\u5e94\u80fd\u529b\uff0c\u80fd\u6293\u53d6\u4e0d\u540c\u5f62\u72b6\u5927\u5c0f\u7684\u7269\u4f53\u3002", "motivation": "\u4f20\u7edf\u5de5\u4e1a\u5939\u722a\u7684\u6307\u5c16\u5448\u5f27\u5f62\u8fd0\u52a8\uff0c\u9700\u8981\u8c03\u6574\u6574\u4e2a\u673a\u68b0\u81c2\u9ad8\u5ea6\u4ee5\u907f\u514d\u4e0e\u684c\u9762\u78b0\u649e\uff0c\u9650\u5236\u4e86\u6293\u53d6\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u5177\u6709\u624b\u638c\u548c\u4e24\u4e2a\u673a\u68b0\u76f8\u540c\u3001\u5bf9\u79f0\u6392\u5217\u624b\u6307\u7684\u5939\u722a\uff0c\u6307\u5c16\u6cbf\u7ebf\u6027\u8f68\u8ff9\u8fd0\u52a8\uff0c\u53ef\u72ec\u7acb\u6216\u5355\u7535\u673a\u9a71\u52a8\uff0c\u5e76\u8fdb\u884c\u4f18\u5316\u5206\u6790\u7406\u8bba\u3002", "result": "\u539f\u578b\u6d4b\u8bd5\u663e\u793a\u6210\u529f\u5b9e\u73b0\u7ebf\u6027\u5e73\u884c\u5939\u6301\u529f\u80fd\uff0c\u5177\u6709\u826f\u597d\u7684\u9002\u5e94\u6027\u3002", "conclusion": "SPD\u5939\u722a\u4e3a\u5404\u79cd\u673a\u5668\u4eba\u63d0\u4f9b\u6709\u6548\u6293\u53d6\u80fd\u529b\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u6570\u636e\u6536\u96c6\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.16853", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16853", "abs": "https://arxiv.org/abs/2510.16853", "authors": ["Matthew Sharp", "Omer Bilgin", "Iason Gabriel", "Lewis Hammond"], "title": "Agentic Inequality", "comment": null, "summary": "Autonomous AI agents, capable of complex planning and action, represent a\nsignificant technological evolution beyond current generative tools. As these\nsystems become integrated into political and economic life, their distribution\nand capabilities will be highly consequential. This paper introduces and\nexplores \"agentic inequality\" - the potential disparities in power,\nopportunity, and outcomes stemming from differential access to, and\ncapabilities of, AI agents. We analyse the dual potential of this technology,\nexploring how agents could both exacerbate existing divides and, under the\nright conditions, serve as a powerful equalising force. To this end, the paper\nmakes three primary contributions. First, it establishes an analytical\nframework by delineating the three core dimensions through which this\ninequality can manifest: disparities in the availability, quality, and quantity\nof agents. Second, it argues that agentic inequality is distinct from prior\ntechnological divides. Unlike tools that primarily augment human abilities,\nagents act as autonomous delegates, creating novel power asymmetries through\nscalable goal delegation and direct agent-to-agent competition that are poised\nto reshape outcomes across economic and socio-political spheres. Finally, it\nprovides a systematic analysis of the technical and socioeconomic drivers -\nfrom model release strategies to market incentives - that will shape the\ndistribution of agentic power, concluding with a research agenda for navigating\nthe complex governance challenges ahead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u63a2\u8ba8\u4e86\"\u4ee3\u7406\u4e0d\u5e73\u7b49\"\u6982\u5ff5\uff0c\u5373\u7531\u4e8eAI\u4ee3\u7406\u7684\u83b7\u53d6\u548c\u80fd\u529b\u7684\u5dee\u5f02\u5bfc\u81f4\u7684\u6743\u529b\u3001\u673a\u4f1a\u548c\u7ed3\u679c\u7684\u4e0d\u5e73\u7b49\u3002", "motivation": "\u968f\u7740\u81ea\u4e3bAI\u4ee3\u7406\u7cfb\u7edf\u878d\u5165\u653f\u6cbb\u7ecf\u6d4e\u751f\u6d3b\uff0c\u5176\u5206\u5e03\u548c\u80fd\u529b\u5dee\u5f02\u5c06\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u65b0\u578b\u4e0d\u5e73\u7b49\u73b0\u8c61\u3002", "method": "\u5efa\u7acb\u5206\u6790\u6846\u67b6\uff0c\u4ece\u53ef\u7528\u6027\u3001\u8d28\u91cf\u548c\u6570\u91cf\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790\u4ee3\u7406\u4e0d\u5e73\u7b49\uff1b\u8bba\u8bc1\u4ee3\u7406\u4e0d\u5e73\u7b49\u4e0e\u4ee5\u5f80\u6280\u672f\u9e3f\u6c9f\u7684\u533a\u522b\uff1b\u7cfb\u7edf\u5206\u6790\u6280\u672f\u548c\u793e\u4f1a\u7ecf\u6d4e\u9a71\u52a8\u56e0\u7d20\u3002", "result": "\u8bc6\u522b\u4e86\u4ee3\u7406\u4e0d\u5e73\u7b49\u7684\u4e09\u4e2a\u6838\u5fc3\u7ef4\u5ea6\uff0c\u9610\u660e\u4e86\u5176\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u7684\u72ec\u7279\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5f71\u54cd\u4ee3\u7406\u6743\u529b\u5206\u5e03\u7684\u5404\u79cd\u56e0\u7d20\u3002", "conclusion": "\u4ee3\u7406\u4e0d\u5e73\u7b49\u662f\u4e00\u79cd\u65b0\u578b\u6280\u672f\u9e3f\u6c9f\uff0c\u9700\u8981\u5236\u5b9a\u7814\u7a76\u8bae\u7a0b\u6765\u5e94\u5bf9\u590d\u6742\u7684\u6cbb\u7406\u6311\u6218\uff0c\u786e\u4fddAI\u4ee3\u7406\u6280\u672f\u80fd\u591f\u6210\u4e3a\u5e73\u7b49\u5316\u529b\u91cf\u800c\u975e\u52a0\u5267\u5206\u5316\u3002"}}
{"id": "2510.17290", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17290", "abs": "https://arxiv.org/abs/2510.17290", "authors": ["Qihao Peng", "Tierui Gong", "Zihang Song", "Qu Luo", "Zihuai Lin", "Pei Xiao", "Chau Yuen"], "title": "Enhanced Ground-Satellite Direct Access via Onboard Rydberg Atomic Quantum Receivers", "comment": "Submitted to IEEE Journal", "summary": "Ground-satellite links for 6G networks face critical challenges, including\nsevere path loss, tight size-weight-power limits, and congested spectrum, all\nof which significantly hinder the performance of traditional radio frequency\n(RF) front ends. This article introduces the Rydberg Atomic Quantum Receiver\n(RAQR) for onboard satellite systems, a millimeter-scale front end that\nconverts radio fields to optical signals through atomic electromagnetically\ninduced transparency. RAQR's high sensitivity and high frequency selectivity\naddress link budget, payload, and interference challenges while fitting within\nspace constraints. A hybrid atomic-electronic design and supporting signal\nmodel demonstrate enhanced data rate, coverage, and sensing accuracy relative\nto conventional RF receivers. The article concludes with integration\nstrategies, distributed-satellite concepts, and open research problems for\nbringing RAQR-enabled satellite payloads into service.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e6G\u536b\u661f\u7f51\u7edc\u7684Rydberg\u539f\u5b50\u91cf\u5b50\u63a5\u6536\u5668(RAQR)\uff0c\u901a\u8fc7\u539f\u5b50\u7535\u78c1\u8bf1\u5bfc\u900f\u660e\u5c06\u5c04\u9891\u573a\u8f6c\u6362\u4e3a\u5149\u4fe1\u53f7\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRF\u524d\u7aef\u9762\u4e34\u7684\u8def\u5f84\u635f\u8017\u3001\u5c3a\u5bf8\u91cd\u91cf\u529f\u7387\u9650\u5236\u548c\u9891\u8c31\u62e5\u5835\u7b49\u95ee\u9898\u3002", "motivation": "6G\u7f51\u7edc\u7684\u5730\u9762-\u536b\u661f\u94fe\u8def\u9762\u4e34\u4e25\u91cd\u8def\u5f84\u635f\u8017\u3001\u4e25\u683c\u7684\u5c3a\u5bf8\u91cd\u91cf\u529f\u7387\u9650\u5236\u548c\u9891\u8c31\u62e5\u5835\u7b49\u5173\u952e\u6311\u6218\uff0c\u8fd9\u4e9b\u56e0\u7d20\u663e\u8457\u963b\u788d\u4e86\u4f20\u7edf\u5c04\u9891\u524d\u7aef\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528Rydberg\u539f\u5b50\u91cf\u5b50\u63a5\u6536\u5668(RAQR)\uff0c\u8fd9\u662f\u4e00\u79cd\u6beb\u7c73\u7ea7\u524d\u7aef\uff0c\u901a\u8fc7\u539f\u5b50\u7535\u78c1\u8bf1\u5bfc\u900f\u660e\u5c06\u5c04\u9891\u573a\u8f6c\u6362\u4e3a\u5149\u4fe1\u53f7\u3002\u91c7\u7528\u6df7\u5408\u539f\u5b50-\u7535\u5b50\u8bbe\u8ba1\u548c\u652f\u6301\u4fe1\u53f7\u6a21\u578b\u3002", "result": "RAQR\u7684\u9ad8\u7075\u654f\u5ea6\u548c\u9ad8\u9891\u7387\u9009\u62e9\u6027\u89e3\u51b3\u4e86\u94fe\u8def\u9884\u7b97\u3001\u6709\u6548\u8f7d\u8377\u548c\u5e72\u6270\u6311\u6218\uff0c\u540c\u65f6\u6ee1\u8db3\u7a7a\u95f4\u9650\u5236\u3002\u76f8\u6bd4\u4f20\u7edfRF\u63a5\u6536\u5668\uff0c\u5c55\u793a\u4e86\u589e\u5f3a\u7684\u6570\u636e\u901f\u7387\u3001\u8986\u76d6\u8303\u56f4\u548c\u4f20\u611f\u7cbe\u5ea6\u3002", "conclusion": "\u6587\u7ae0\u6700\u540e\u63d0\u51fa\u4e86\u96c6\u6210\u7b56\u7565\u3001\u5206\u5e03\u5f0f\u536b\u661f\u6982\u5ff5\u4ee5\u53ca\u5c06RAQR\u652f\u6301\u7684\u536b\u661f\u6709\u6548\u8f7d\u8377\u6295\u5165\u670d\u52a1\u7684\u5f00\u653e\u7814\u7a76\u95ee\u9898\u3002"}}
{"id": "2510.16518", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16518", "abs": "https://arxiv.org/abs/2510.16518", "authors": ["Jes\u00fas Ortega-Peimbert", "Finn Lukas Busch", "Timon Homberger", "Quantao Yang", "Olov Andersson"], "title": "DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation", "comment": null, "summary": "Advances in open-vocabulary semantic mapping and object navigation have\nenabled robots to perform an informed search of their environment for an\narbitrary object. However, such zero-shot object navigation is typically\ndesigned for simple queries with an object name like \"television\" or \"blue\nrug\". Here, we consider more complex free-text queries with spatial\nrelationships, such as \"find the remote on the table\" while still leveraging\nrobustness of a semantic map. We present DIV-Nav, a real-time navigation system\nthat efficiently addresses this problem through a series of relaxations: i)\nDecomposing natural language instructions with complex spatial constraints into\nsimpler object-level queries on a semantic map, ii) computing the Intersection\nof individual semantic belief maps to identify regions where all objects\nco-exist, and iii) Validating the discovered objects against the original,\ncomplex spatial constrains via a LVLM. We further investigate how to adapt the\nfrontier exploration objectives of online semantic mapping to such spatial\nsearch queries to more effectively guide the search process. We validate our\nsystem through extensive experiments on the MultiON benchmark and real-world\ndeployment on a Boston Dynamics Spot robot using a Jetson Orin AGX. More\ndetails and videos are available at https://anonsub42.github.io/reponame/", "AI": {"tldr": "DIV-Nav\u662f\u4e00\u4e2a\u5b9e\u65f6\u5bfc\u822a\u7cfb\u7edf\uff0c\u80fd\u591f\u5904\u7406\u5305\u542b\u7a7a\u95f4\u5173\u7cfb\u7684\u590d\u6742\u81ea\u7531\u6587\u672c\u67e5\u8be2\uff0c\u901a\u8fc7\u8bed\u4e49\u5730\u56fe\u5206\u89e3\u3001\u4ea4\u96c6\u8ba1\u7b97\u548cLVLM\u9a8c\u8bc1\u6765\u5b9e\u73b0\u9ad8\u6548\u5bfc\u822a\u3002", "motivation": "\u73b0\u6709\u7684\u96f6\u6837\u672c\u7269\u4f53\u5bfc\u822a\u901a\u5e38\u53ea\u652f\u6301\u7b80\u5355\u67e5\u8be2\uff08\u5982\"\u7535\u89c6\"\uff09\uff0c\u4f46\u65e0\u6cd5\u5904\u7406\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u67e5\u8be2\uff08\u5982\"\u5728\u684c\u5b50\u4e0a\u7684\u9065\u63a7\u5668\"\uff09\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u590d\u6742\u81ea\u7531\u6587\u672c\u6307\u4ee4\u7684\u5bfc\u822a\u7cfb\u7edf\u3002", "method": "1\uff09\u5c06\u590d\u6742\u7a7a\u95f4\u7ea6\u675f\u7684\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5206\u89e3\u4e3a\u8bed\u4e49\u5730\u56fe\u4e0a\u7684\u7b80\u5355\u5bf9\u8c61\u67e5\u8be2\uff1b2\uff09\u8ba1\u7b97\u4e2a\u4f53\u8bed\u4e49\u7f6e\u4fe1\u5ea6\u56fe\u7684\u4ea4\u96c6\u4ee5\u8bc6\u522b\u6240\u6709\u5bf9\u8c61\u5171\u5b58\u7684\u533a\u57df\uff1b3\uff09\u4f7f\u7528LVLM\u9a8c\u8bc1\u53d1\u73b0\u7684\u5bf9\u8c61\u662f\u5426\u7b26\u5408\u539f\u59cb\u590d\u6742\u7a7a\u95f4\u7ea6\u675f\uff1b4\uff09\u8c03\u6574\u524d\u6cbf\u63a2\u7d22\u76ee\u6807\u4ee5\u9002\u5e94\u7a7a\u95f4\u641c\u7d22\u67e5\u8be2\u3002", "result": "\u5728MultiON\u57fa\u51c6\u6d4b\u8bd5\u548c\u6ce2\u58eb\u987f\u52a8\u529bSpot\u673a\u5668\u4eba\uff08\u4f7f\u7528Jetson Orin AGX\uff09\u4e0a\u7684\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "DIV-Nav\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5904\u7406\u5305\u542b\u7a7a\u95f4\u5173\u7cfb\u7684\u590d\u6742\u81ea\u7531\u6587\u672c\u67e5\u8be2\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u5bfc\u822a\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.16858", "categories": ["cs.CY", "K.3.2; K.4.3; K.4.2"], "pdf": "https://arxiv.org/pdf/2510.16858", "abs": "https://arxiv.org/abs/2510.16858", "authors": ["Enes Ayalp"], "title": "Sustainable and Adaptive Growth in Creative Tech", "comment": null, "summary": "The creative technology evolves rapidly in both scope and depth, demanding\ncross-disciplinary expertise and continuous improvement. Although educational\nprograms and other collaborative initiatives enable strong technical and\nartistic skills, even the most advanced pathways rarely ensure a stable career.\nSuccess in these professions often depends on visibility, timing, and\nself-directed development. As markets shift or technologies change, talents\nstill find themselves displaced. Existing learning paths often fail to connect\nthe skills they teach, leaving learners with fragmented expertise that decays\nquickly when not continuously applied. The industry demands depth, yet\nspecialization carries risk when tools, pipelines, or roles evolve faster than\nthe expertise built around them. Broad skill sets, by contrast, may increase\nemployability but are easily replaced or rendered obsolete by technological\nchange. CLEAR CORE is a framework for learning and sustaining in creative\ntechnology. It integrates two iterative interconnected cycles into a continuous\nprocess linking structured education with independent growth as a lifelong,\nrenewable practice that allows professionals to excel amid constant change.", "AI": {"tldr": "CLEAR CORE\u6846\u67b6\u901a\u8fc7\u5c06\u7ed3\u6784\u5316\u6559\u80b2\u4e0e\u72ec\u7acb\u6210\u957f\u76f8\u7ed3\u5408\uff0c\u5e2e\u52a9\u521b\u610f\u6280\u672f\u4ece\u4e1a\u8005\u5728\u5feb\u901f\u53d8\u5316\u7684\u73af\u5883\u4e2d\u6301\u7eed\u53d1\u5c55\u6280\u80fd\u3002", "motivation": "\u521b\u610f\u6280\u672f\u9886\u57df\u5feb\u901f\u6f14\u53d8\uff0c\u73b0\u6709\u6559\u80b2\u8def\u5f84\u96be\u4ee5\u786e\u4fdd\u7a33\u5b9a\u804c\u4e1a\u53d1\u5c55\uff0c\u4e13\u4e1a\u6280\u80fd\u5bb9\u6613\u56e0\u6280\u672f\u53d8\u5316\u800c\u8fc7\u65f6\u3002", "method": "\u63d0\u51faCLEAR CORE\u6846\u67b6\uff0c\u6574\u5408\u4e24\u4e2a\u8fed\u4ee3\u4e92\u8fde\u7684\u5faa\u73af\uff0c\u5c06\u7ed3\u6784\u5316\u6559\u80b2\u4e0e\u72ec\u7acb\u6210\u957f\u7ed3\u5408\u4e3a\u6301\u7eed\u8fc7\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u521b\u610f\u6280\u672f\u4e13\u4e1a\u4eba\u58eb\u63d0\u4f9b\u7ec8\u8eab\u53ef\u66f4\u65b0\u7684\u5b9e\u8df5\u65b9\u6cd5\u3002", "conclusion": "CLEAR CORE\u6846\u67b6\u80fd\u591f\u5e2e\u52a9\u4ece\u4e1a\u8005\u5728\u6301\u7eed\u53d8\u5316\u7684\u73af\u5883\u4e2d\u4fdd\u6301\u7ade\u4e89\u529b\u5e76\u53d6\u5f97\u6210\u529f\u3002"}}
{"id": "2510.17333", "categories": ["eess.SY", "cs.CR", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.17333", "abs": "https://arxiv.org/abs/2510.17333", "authors": ["Sebastian Schlor", "Frank Allg\u00f6wer"], "title": "Comparison and performance analysis of dynamic encrypted control approaches", "comment": null, "summary": "Encrypted controllers using homomorphic encryption have proven to guarantee\nthe privacy of measurement and control signals, as well as system and\ncontroller parameters, while regulating the system as intended. However,\nencrypting dynamic controllers has remained a challenge due to growing noise\nand overflow issues in the encoding. In this paper, we review recent approaches\nto dynamic encrypted control, such as bootstrapping, periodic resets of the\ncontroller state, integer reformulations, and FIR controllers, and equip them\nwith a stability and performance analysis to evaluate their suitability. We\ncomplement the analysis with a numerical performance comparison on a benchmark\nsystem.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u52a8\u6001\u52a0\u5bc6\u63a7\u5236\u7684\u6700\u65b0\u65b9\u6cd5\uff0c\u5305\u62ec\u81ea\u4e3e\u3001\u63a7\u5236\u5668\u72b6\u6001\u5468\u671f\u6027\u91cd\u7f6e\u3001\u6574\u6570\u91cd\u6784\u548cFIR\u63a7\u5236\u5668\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u7684\u52a0\u5bc6\u63a7\u5236\u5668\u53ef\u4ee5\u4fdd\u62a4\u6d4b\u91cf\u548c\u63a7\u5236\u4fe1\u53f7\u7684\u9690\u79c1\u4ee5\u53ca\u7cfb\u7edf\u548c\u63a7\u5236\u5668\u53c2\u6570\uff0c\u4f46\u52a8\u6001\u63a7\u5236\u5668\u7684\u52a0\u5bc6\u7531\u4e8e\u7f16\u7801\u4e2d\u7684\u566a\u58f0\u548c\u6ea2\u51fa\u95ee\u9898\u800c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u56de\u987e\u4e86\u52a8\u6001\u52a0\u5bc6\u63a7\u5236\u7684\u51e0\u79cd\u65b9\u6cd5\uff1a\u81ea\u4e3e\u3001\u63a7\u5236\u5668\u72b6\u6001\u5468\u671f\u6027\u91cd\u7f6e\u3001\u6574\u6570\u91cd\u6784\u548cFIR\u63a7\u5236\u5668\uff0c\u5e76\u8fdb\u884c\u4e86\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u5206\u6790\u3002", "result": "\u901a\u8fc7\u57fa\u51c6\u7cfb\u7edf\u7684\u6570\u503c\u6027\u80fd\u6bd4\u8f83\uff0c\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u4e3a\u52a8\u6001\u52a0\u5bc6\u63a7\u5236\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u65b9\u6cd5\u56de\u987e\u548c\u6027\u80fd\u8bc4\u4f30\uff0c\u6709\u52a9\u4e8e\u9009\u62e9\u5408\u9002\u7684\u52a0\u5bc6\u63a7\u5236\u7b56\u7565\u3002"}}
{"id": "2510.16524", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16524", "abs": "https://arxiv.org/abs/2510.16524", "authors": ["Haokai Ding", "Zhaohan Chen", "Tao Yang", "Wenzeng Zhang"], "title": "Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping", "comment": "6 pages, 9 figures, Accepted author manuscript for IEEE CASE 2025", "summary": "This paper presents the SP-Diff parallel gripper system, addressing the\nlimited adaptability of conventional end-effectors in intelligent industrial\nautomation. The proposed design employs an innovative differential linkage\nmechanism with a modular symmetric dual-finger configuration to achieve\nlinear-parallel grasping. By integrating a planetary gear transmission, the\nsystem enables synchronized linear motion and independent finger pose\nadjustment while maintaining structural rigidity, reducing Z-axis recalibration\nrequirements by 30% compared to arc-trajectory grippers. The compact palm\narchitecture incorporates a kinematically optimized parallelogram linkage and\nDifferential mechanism, demonstrating adaptive grasping capabilities for\ndiverse industrial workpieces and deformable objects such as citrus fruits.\nFuture-ready interfaces are embedded for potential force/vision sensor\nintegration to facilitate multimodal data acquisition (e.g., trajectory\nplanning and object deformation) in digital twin frameworks. Designed as a\nflexible manufacturing solution, SP-Diff advances robotic end-effector\nintelligence through its adaptive architecture, showing promising applications\nin collaborative robotics, logistics automation, and specialized operational\nscenarios.", "AI": {"tldr": "SP-Diff\u5e73\u884c\u5939\u722a\u7cfb\u7edf\u91c7\u7528\u521b\u65b0\u7684\u5dee\u52a8\u8fde\u6746\u673a\u6784\u548c\u6a21\u5757\u5316\u5bf9\u79f0\u53cc\u6307\u914d\u7f6e\uff0c\u901a\u8fc7\u884c\u661f\u9f7f\u8f6e\u4f20\u52a8\u5b9e\u73b0\u7ebf\u6027\u5e73\u884c\u6293\u53d6\uff0c\u51cf\u5c1130%\u7684Z\u8f74\u91cd\u65b0\u6821\u51c6\u9700\u6c42\uff0c\u5177\u5907\u81ea\u9002\u5e94\u6293\u53d6\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u672b\u7aef\u6267\u884c\u5668\u5728\u667a\u80fd\u5de5\u4e1a\u81ea\u52a8\u5316\u4e2d\u9002\u5e94\u6027\u6709\u9650\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u591a\u6837\u5316\u5de5\u4e1a\u5de5\u4ef6\u548c\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u6293\u53d6\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u5dee\u52a8\u8fde\u6746\u673a\u6784\u3001\u6a21\u5757\u5316\u5bf9\u79f0\u53cc\u6307\u914d\u7f6e\u3001\u884c\u661f\u9f7f\u8f6e\u4f20\u52a8\u7cfb\u7edf\uff0c\u7ed3\u5408\u8fd0\u52a8\u5b66\u4f18\u5316\u7684\u5e73\u884c\u56db\u8fb9\u5f62\u8fde\u6746\u548c\u5dee\u52a8\u673a\u6784\uff0c\u5b9e\u73b0\u540c\u6b65\u7ebf\u6027\u8fd0\u52a8\u548c\u72ec\u7acb\u624b\u6307\u59ff\u6001\u8c03\u6574\u3002", "result": "\u7cfb\u7edf\u4fdd\u6301\u7ed3\u6784\u521a\u6027\uff0c\u76f8\u6bd4\u5f27\u5f62\u8f68\u8ff9\u5939\u722a\u51cf\u5c1130%\u7684Z\u8f74\u91cd\u65b0\u6821\u51c6\u9700\u6c42\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u6293\u53d6\u5404\u79cd\u5de5\u4e1a\u5de5\u4ef6\u548c\u53ef\u53d8\u5f62\u7269\u4f53\uff08\u5982\u67d1\u6a58\u7c7b\u6c34\u679c\uff09\u3002", "conclusion": "SP-Diff\u4f5c\u4e3a\u67d4\u6027\u5236\u9020\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u67b6\u6784\u63a8\u8fdb\u4e86\u673a\u5668\u4eba\u672b\u7aef\u6267\u884c\u5668\u7684\u667a\u80fd\u5316\uff0c\u5728\u534f\u4f5c\u673a\u5668\u4eba\u3001\u7269\u6d41\u81ea\u52a8\u5316\u548c\u4e13\u4e1a\u64cd\u4f5c\u573a\u666f\u4e2d\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.16944", "categories": ["cs.CY", "cs.SC"], "pdf": "https://arxiv.org/pdf/2510.16944", "abs": "https://arxiv.org/abs/2510.16944", "authors": ["Spencer Rugaber", "Scott Bunin", "Andrew Hornback", "Sungeun An", "Ashok Goel"], "title": "Learning Ecology with VERA Using Conceptual Models and Simulations", "comment": null, "summary": "Conceptual modeling has been an important part of constructionist educational\npractices for many years, particularly in STEM (Science, Technology,\nEngineering and Mathematics) disciplines. What is not so common is using\nagent-based simulation to provide students feedback on model quality. This\nrequires the capability of automatically compiling the concept model into its\nsimulation. The VERA (Virtual Experimentation Research Assistant) system is a\nconceptual modeling tool used since 2016 to provide introductory college\nbiology students with the capability of conceptual modeling and agent-based\nsimulation in the ecological domain. This paper describes VERA and its approach\nto coupling conceptual modeling and simulation with emphasis on how a model's\nvisual syntax is compiled into code executable on a NetLogo simulation engine.\nExperience with VERA in introductory biology classes at several universities\nand through the Smithsonian Institution's Encyclopedia of Life website is\nrelated.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.17371", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.17371", "abs": "https://arxiv.org/abs/2510.17371", "authors": ["Mohammad Boveiri", "Mohammad Khosravi", "Peyman Mohajerin Esfahan"], "title": "Accelerating Adaptive Systems via Normalized Parameter Estimation Laws", "comment": null, "summary": "In this paper, we propose a new class of parameter estimation laws for\nadaptive systems, called \\emph{normalized parameter estimation laws}. A key\nfeature of these estimation laws is that they accelerate the convergence of the\nsystem state, $\\mathit{x(t)}$, to the origin. We quantify this improvement by\nshowing that our estimation laws guarantee finite integrability of the\n$\\mathit{r}$-th root of the squared norm of the system state, i.e., \\(\n\\mathit{\\|x(t)\\|}_2^{2/\\mathit{r}} \\in \\mathcal{L}_1, \\) where $\\mathit{r} \\geq\n1$ is a pre-specified parameter that, for a broad class of systems, can be\nchosen arbitrarily large. In contrast, standard Lyapunov-based estimation laws\nonly guarantee integrability of $\\mathit{\\|x(t)\\|}_2^2$ (i.e., $\\mathit{r} =\n1$). We motivate our method by showing that, for large values of $r$, this\nguarantee serves as a sparsity-promoting mechanism in the time domain, meaning\nthat it penalizes prolonged signal duration and slow decay, thereby promoting\nfaster convergence of $\\mathit{x(t)}$. The proposed estimation laws do not rely\non time-varying or high adaptation gains and do not require persistent\nexcitation. Moreover, they can be applied to systems with matched and unmatched\nuncertainties, regardless of their dynamic structure, as long as a control\nLyapunov function (CLF) exists. Finally, they are compatible with any CLF-based\ncertainty equivalence controllers. We further develop higher-order extensions\nof our estimation laws by incorporating momentum into the estimation dynamics.\nWe illustrate the performance improvements achieved with the proposed scheme\nthrough various numerical experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f52\u4e00\u5316\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u80fd\u52a0\u901f\u7cfb\u7edf\u72b6\u6001\u6536\u655b\u5230\u539f\u70b9\uff0c\u4fdd\u8bc1\u7cfb\u7edf\u72b6\u6001\u7684r\u6b21\u65b9\u6839\u5e73\u65b9\u8303\u6570\u6709\u9650\u53ef\u79ef\uff0c\u5176\u4e2dr\u22651\u4e14\u53ef\u4efb\u610f\u5927\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u53ea\u4fdd\u8bc1r=1\u7684\u60c5\u51b5\u3002", "motivation": "\u4f20\u7edfLyapunov\u4f30\u8ba1\u65b9\u6cd5\u53ea\u80fd\u4fdd\u8bc1\u7cfb\u7edf\u72b6\u6001\u5e73\u65b9\u8303\u6570\u7684\u53ef\u79ef\u6027\uff08r=1\uff09\uff0c\u6536\u655b\u901f\u5ea6\u6709\u9650\u3002\u65b0\u65b9\u6cd5\u901a\u8fc7\u63d0\u9ad8r\u503c\u6765\u4fc3\u8fdb\u65f6\u95f4\u57df\u7a00\u758f\u6027\uff0c\u60e9\u7f5a\u4fe1\u53f7\u6301\u7eed\u65f6\u95f4\u8fc7\u957f\u548c\u7f13\u6162\u8870\u51cf\uff0c\u4ece\u800c\u52a0\u901f\u7cfb\u7edf\u72b6\u6001\u6536\u655b\u3002", "method": "\u63d0\u51fa\u5f52\u4e00\u5316\u53c2\u6570\u4f30\u8ba1\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u65f6\u53d8\u6216\u9ad8\u9002\u5e94\u589e\u76ca\uff0c\u65e0\u9700\u6301\u7eed\u6fc0\u52b1\uff0c\u9002\u7528\u4e8e\u5339\u914d\u548c\u4e0d\u5339\u914d\u4e0d\u786e\u5b9a\u6027\u7cfb\u7edf\uff0c\u53ea\u8981\u5b58\u5728\u63a7\u5236Lyapunov\u51fd\u6570\u5373\u53ef\u5e94\u7528\u3002\u8fd8\u5f00\u53d1\u4e86\u5305\u542b\u52a8\u91cf\u7684\u9ad8\u9636\u6269\u5c55\u7248\u672c\u3002", "result": "\u65b0\u4f30\u8ba1\u65b9\u6cd5\u80fd\u4fdd\u8bc1\u2016x(t)\u2016\u2082^(2/r) \u2208 L\u2081\uff0c\u5176\u4e2dr\u22651\u4e14\u53ef\u4efb\u610f\u5927\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u53ea\u4fdd\u8bc1r=1\u7684\u60c5\u51b5\uff0c\u663e\u8457\u52a0\u901f\u4e86\u7cfb\u7edf\u72b6\u6001\u6536\u655b\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5f52\u4e00\u5316\u53c2\u6570\u4f30\u8ba1\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u52a0\u901f\u6536\u655b\u673a\u5236\uff0c\u901a\u8fc7\u65f6\u95f4\u57df\u7a00\u758f\u6027\u4fc3\u8fdb\u5b9e\u73b0\u66f4\u5feb\u7684\u7cfb\u7edf\u72b6\u6001\u6536\u655b\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u4e0d\u786e\u5b9a\u6027\u7cfb\u7edf\uff0c\u4e14\u4e0eCLF\u63a7\u5236\u5668\u517c\u5bb9\u3002"}}
{"id": "2510.16617", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16617", "abs": "https://arxiv.org/abs/2510.16617", "authors": ["Ruihan Zhao", "Tyler Ingebrand", "Sandeep Chinchali", "Ufuk Topcu"], "title": "MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation", "comment": null, "summary": "Vision-Language-Action (VLA) models trained on large robot datasets promise\ngeneral-purpose, robust control across diverse domains and embodiments.\nHowever, existing approaches often fail out-of-the-box when deployed in novel\nenvironments, embodiments, or tasks. We introduce Mixture of Skills VLA\n(MoS-VLA), a framework that represents robot manipulation policies as linear\ncombinations of a finite set of learned basis functions. During pretraining,\nMoS-VLA jointly learns these basis functions across datasets from the Open\nX-Embodiment project, producing a structured skill space. At test time,\nadapting to a new task requires only a single expert demonstration. The\ncorresponding skill representation is then inferred via a lightweight convex\noptimization problem that minimizes the L1 action error, without requiring\ngradient updates. This gradient-free adaptation incurs minimal overhead while\nenabling rapid instantiation of new skills. Empirically, MoS-VLA achieves lower\naction-prediction error on five out of five unseen datasets and succeeds in\nboth simulation and real-robot tasks where a pretrained VLA model fails\noutright. Project page: mos-vla.github.io/", "AI": {"tldr": "MoS-VLA\u662f\u4e00\u4e2a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u6027\u7ec4\u5408\u6709\u9650\u4e2a\u5b66\u4e60\u5230\u7684\u57fa\u51fd\u6570\u6765\u8868\u793a\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\uff0c\u80fd\u591f\u901a\u8fc7\u5355\u6b21\u4e13\u5bb6\u6f14\u793a\u5feb\u901f\u9002\u5e94\u65b0\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684VLA\u6a21\u578b\u5728\u90e8\u7f72\u5230\u65b0\u73af\u5883\u3001\u65b0\u673a\u5668\u4eba\u6216\u65b0\u4efb\u52a1\u65f6\u5f80\u5f80\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5feb\u901f\u9002\u5e94\u65b0\u573a\u666f\u7684\u65b9\u6cd5\u3002", "method": "\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u8054\u5408\u5b66\u4e60\u8de8\u6570\u636e\u96c6\u7684\u57fa\u51fd\u6570\uff0c\u521b\u5efa\u7ed3\u6784\u5316\u6280\u80fd\u7a7a\u95f4\uff1b\u6d4b\u8bd5\u65f6\u901a\u8fc7\u8f7b\u91cf\u7ea7\u51f8\u4f18\u5316\u95ee\u9898\u63a8\u65ad\u6280\u80fd\u8868\u793a\uff0c\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\u3002", "result": "\u5728\u4e94\u4e2a\u672a\u89c1\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u52a8\u4f5c\u9884\u6d4b\u8bef\u5dee\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u6210\u529f\u6267\u884c\u4e86\u9884\u8bad\u7ec3VLA\u6a21\u578b\u65e0\u6cd5\u5b8c\u6210\u7684\u4efb\u52a1\u3002", "conclusion": "MoS-VLA\u6846\u67b6\u901a\u8fc7\u6280\u80fd\u6df7\u5408\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5bf9\u65b0\u4efb\u52a1\u7684\u5feb\u901f\u9002\u5e94\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u9002\u5e94\u5f00\u9500\u3002"}}
{"id": "2510.16951", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16951", "abs": "https://arxiv.org/abs/2510.16951", "authors": ["Christine Sowa Lepird", "Kathleen M. Carley"], "title": "Local News Hijacking: A Review of International Instances", "comment": null, "summary": "In the rise of the digital era, it's easier than ever to create nefarious\nwebsites to spread misinformation. A more recent phenomenon in the United\nStates has been the creation of inauthentic local news websites to further an\ninformation operation campaign. This paper is a review of the 7 instances in\nwhich local news websites were created to influence residents of a region\nbetween 2007 and 2024. By breaking down the ways in which these sites operated,\nwe discovered commonalities in the approach - resurrecting \"zombie\" papers that\nwere previously established authentic local news organizations, sharing these\nsites on social media, and using website templates from WordPress. By analyzing\nthese commonalities, we propose ways to mitigate the occurrence of these\ncampaigns in the future.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e862007-2024\u5e74\u95f4\u7f8e\u56fd7\u8d77\u521b\u5efa\u865a\u5047\u5730\u65b9\u65b0\u95fb\u7f51\u7ad9\u4ee5\u5f71\u54cd\u5730\u533a\u5c45\u6c11\u7684\u4fe1\u606f\u64cd\u4f5c\u6d3b\u52a8\uff0c\u5206\u6790\u4e86\u8fd9\u4e9b\u7f51\u7ad9\u7684\u8fd0\u4f5c\u6a21\u5f0f\u5171\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u9632\u8303\u63aa\u65bd\u3002", "motivation": "\u5728\u6570\u5b57\u65f6\u4ee3\uff0c\u521b\u5efa\u6076\u610f\u7f51\u7ad9\u4f20\u64ad\u9519\u8bef\u4fe1\u606f\u53d8\u5f97\u66f4\u5bb9\u6613\u3002\u8fd1\u5e74\u6765\u7f8e\u56fd\u51fa\u73b0\u521b\u5efa\u865a\u5047\u5730\u65b9\u65b0\u95fb\u7f51\u7ad9\u8fdb\u884c\u4fe1\u606f\u64cd\u4f5c\u6d3b\u52a8\u7684\u65b0\u73b0\u8c61\uff0c\u9700\u8981\u7814\u7a76\u5176\u8fd0\u4f5c\u6a21\u5f0f\u5e76\u63d0\u51fa\u9632\u8303\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u56de\u987e\u5206\u67907\u4e2a\u865a\u5047\u5730\u65b9\u65b0\u95fb\u7f51\u7ad9\u7684\u6848\u4f8b\uff0c\u5206\u89e3\u8fd9\u4e9b\u7f51\u7ad9\u7684\u8fd0\u4f5c\u65b9\u5f0f\uff0c\u8bc6\u522b\u5176\u5171\u540c\u7279\u5f81\u548c\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u8fd9\u4e9b\u865a\u5047\u65b0\u95fb\u7f51\u7ad9\u5177\u6709\u4e09\u4e2a\u4e3b\u8981\u5171\u6027\uff1a\u590d\u6d3b\u5df2\u505c\u520a\u7684\"\u50f5\u5c38\"\u62a5\u7eb8\u3001\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u5206\u4eab\u8fd9\u4e9b\u7f51\u7ad9\u3001\u4f7f\u7528WordPress\u7f51\u7ad9\u6a21\u677f\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u5171\u540c\u7279\u5f81\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u51cf\u5c11\u6b64\u7c7b\u4fe1\u606f\u64cd\u4f5c\u6d3b\u52a8\u53d1\u751f\u7684\u7f13\u89e3\u63aa\u65bd\u548c\u5efa\u8bae\u3002"}}
{"id": "2510.17619", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17619", "abs": "https://arxiv.org/abs/2510.17619", "authors": ["Nayab Gogosh", "Sohail Khalid", "Bilal Tariq Malik", "Slawomir Koziel"], "title": "Artificial magnetic conductor backed dual-mode sectoral cylindrical DRA for off-body biomedical telemetry", "comment": "13 pages", "summary": "This research investigates the potential of a sectoral Cylindrical Dielectric\nResonator Antenna (CDRA) for biomedical telemetry. CDRAs are known for their\nlow loss, ruggedness, and stability, but their limited bandwidth and size make\nthem unsuitable for wearable devices. The research addresses these limitations\nby proposing a dual mode antenna that operates in EH110 and TE210 modes. The\nsectoral CDRA is a quarter segment with Perfect Electric Conductor boundaries,\nreducing its size by a factor of four. Mathematical derivations of the field\ncomponents for both modes are derived to support the design. To minimize\nspecific absorption rate (SAR), an Artificial Magnetic Conductor (AMC) surface\nis applied to the antennas backside, enhancing compatibility with the\ntransverse electric modes. The antenna achieves a bandwidth of 0.7 GHz (5.2-5.9\nGHz), suitable for biomedical applications, with a measured peak gain of 7.9\ndBi and a SAR of 1.24 W/kg when applied to a human arm.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6247\u5f62\u5706\u67f1\u4ecb\u8d28\u8c10\u632f\u5668\u5929\u7ebf(CDRA)\uff0c\u901a\u8fc7\u53cc\u6a21\u64cd\u4f5c(EH110\u548cTE210\u6a21\u5f0f)\u548c\u56db\u5206\u4e4b\u4e00\u6247\u5f62\u7ed3\u6784\u51cf\u5c0f\u5c3a\u5bf8\uff0c\u7ed3\u5408\u4eba\u5de5\u78c1\u5bfc\u4f53(AMC)\u8868\u9762\u964d\u4f4eSAR\u503c\uff0c\u5b9e\u73b0\u4e86\u9002\u7528\u4e8e\u751f\u7269\u533b\u5b66\u9065\u6d4b\u76845.2-5.9 GHz\u5e26\u5bbd\u5929\u7ebf\u3002", "motivation": "\u4f20\u7edfCDRA\u5929\u7ebf\u5177\u6709\u4f4e\u635f\u8017\u3001\u575a\u56fa\u6027\u548c\u7a33\u5b9a\u6027\u7b49\u4f18\u70b9\uff0c\u4f46\u5176\u6709\u9650\u7684\u5e26\u5bbd\u548c\u8f83\u5927\u5c3a\u5bf8\u4f7f\u5176\u4e0d\u9002\u5408\u53ef\u7a7f\u6234\u8bbe\u5907\u5e94\u7528\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u5f00\u53d1\u9002\u7528\u4e8e\u751f\u7269\u533b\u5b66\u9065\u6d4b\u7684\u5c0f\u578b\u5316\u5929\u7ebf\u3002", "method": "\u91c7\u7528\u6247\u5f62CDRA\u8bbe\u8ba1\uff0c\u4f7f\u7528\u56db\u5206\u4e4b\u4e00\u6247\u5f62\u7ed3\u6784\u548c\u5b8c\u7f8e\u7535\u5bfc\u4f53\u8fb9\u754c\u5c06\u5c3a\u5bf8\u51cf\u5c0f\u56db\u500d\uff1b\u8bbe\u8ba1\u53cc\u6a21\u5929\u7ebf\uff0c\u5de5\u4f5c\u5728EH110\u548cTE210\u6a21\u5f0f\uff1b\u63a8\u5bfc\u4e24\u79cd\u6a21\u5f0f\u7684\u573a\u5206\u91cf\u6570\u5b66\u8868\u8fbe\u5f0f\uff1b\u5728\u5929\u7ebf\u80cc\u9762\u5e94\u7528AMC\u8868\u9762\u4ee5\u6700\u5c0f\u5316SAR\u503c\u5e76\u589e\u5f3a\u4e0e\u6a2a\u5411\u7535\u6a21\u5f0f\u7684\u517c\u5bb9\u6027\u3002", "result": "\u5929\u7ebf\u5b9e\u73b0\u4e860.7 GHz\u5e26\u5bbd(5.2-5.9 GHz)\uff0c\u9002\u5408\u751f\u7269\u533b\u5b66\u5e94\u7528\uff1b\u6d4b\u5f97\u5cf0\u503c\u589e\u76ca\u4e3a7.9 dBi\uff1b\u5e94\u7528\u4e8e\u4eba\u4f53\u624b\u81c2\u65f6\u7684SAR\u503c\u4e3a1.24 W/kg\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6247\u5f62CDRA\u8bbe\u8ba1\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edfCDRA\u7684\u5c3a\u5bf8\u548c\u5e26\u5bbd\u9650\u5236\uff0c\u901a\u8fc7\u53cc\u6a21\u64cd\u4f5c\u548cAMC\u8868\u9762\u5b9e\u73b0\u4e86\u9002\u7528\u4e8e\u751f\u7269\u533b\u5b66\u9065\u6d4b\u7684\u5c0f\u578b\u5316\u9ad8\u6027\u80fd\u5929\u7ebf\u3002"}}
{"id": "2510.16692", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16692", "abs": "https://arxiv.org/abs/2510.16692", "authors": ["Tianshu Ruan", "Zoe Betta", "Georgios Tzoumas", "Rustam Stolkin", "Manolis Chiou"], "title": "First Responders' Perceptions of Semantic Information for Situational Awareness in Robot-Assisted Emergency Response", "comment": null, "summary": "This study investigates First Responders' (FRs) attitudes toward the use of\nsemantic information and Situational Awareness (SA) in robotic systems during\nemergency operations. A structured questionnaire was administered to 22 FRs\nacross eight countries, capturing their demographic profiles, general attitudes\ntoward robots, and experiences with semantics-enhanced SA. Results show that\nmost FRs expressed positive attitudes toward robots, and rated the usefulness\nof semantic information for building SA at an average of 3.6 out of 5. Semantic\ninformation was also valued for its role in predicting unforeseen emergencies\n(mean 3.9). Participants reported requiring an average of 74.6\\% accuracy to\ntrust semantic outputs and 67.8\\% for them to be considered useful, revealing a\nwillingness to use imperfect but informative AI support tools.\n  To the best of our knowledge, this study offers novel insights by being one\nof the first to directly survey FRs on semantic-based SA in a cross-national\ncontext. It reveals the types of semantic information most valued in the field,\nsuch as object identity, spatial relationships, and risk context-and connects\nthese preferences to the respondents' roles, experience, and education levels.\nThe findings also expose a critical gap between lab-based robotics capabilities\nand the realities of field deployment, highlighting the need for more\nmeaningful collaboration between FRs and robotics researchers. These insights\ncontribute to the development of more user-aligned and situationally aware\nrobotic systems for emergency response.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u6025\u6551\u4eba\u5458\u5728\u7d27\u6025\u884c\u52a8\u4e2d\u5bf9\u673a\u5668\u4eba\u7cfb\u7edf\u4f7f\u7528\u8bed\u4e49\u4fe1\u606f\u548c\u6001\u52bf\u611f\u77e5\u7684\u6001\u5ea6\uff0c\u53d1\u73b0\u6025\u6551\u4eba\u5458\u5bf9\u673a\u5668\u4eba\u6301\u79ef\u6781\u6001\u5ea6\uff0c\u91cd\u89c6\u8bed\u4e49\u4fe1\u606f\u5728\u6001\u52bf\u611f\u77e5\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u613f\u610f\u4f7f\u7528\u51c6\u786e\u7387\u7ea675%\u7684\u4e0d\u5b8c\u7f8eAI\u652f\u6301\u5de5\u5177\u3002", "motivation": "\u4e86\u89e3\u6025\u6551\u4eba\u5458\u5bf9\u8bed\u4e49\u589e\u5f3a\u6001\u52bf\u611f\u77e5\u5728\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u6001\u5ea6\u548c\u9700\u6c42\uff0c\u586b\u8865\u8be5\u9886\u57df\u8de8\u56fd\u8c03\u67e5\u7684\u7a7a\u767d\u3002", "method": "\u5bf9\u6765\u81ea8\u4e2a\u56fd\u5bb6\u768422\u540d\u6025\u6551\u4eba\u5458\u8fdb\u884c\u4e86\u7ed3\u6784\u5316\u95ee\u5377\u8c03\u67e5\uff0c\u6536\u96c6\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u3001\u5bf9\u673a\u5668\u4eba\u7684\u6001\u5ea6\u4ee5\u53ca\u8bed\u4e49\u589e\u5f3a\u6001\u52bf\u611f\u77e5\u7684\u4f53\u9a8c\u3002", "result": "\u5927\u591a\u6570\u6025\u6551\u4eba\u5458\u5bf9\u673a\u5668\u4eba\u6301\u79ef\u6781\u6001\u5ea6\uff0c\u8bed\u4e49\u4fe1\u606f\u5bf9\u6001\u52bf\u611f\u77e5\u7684\u6709\u7528\u6027\u8bc4\u5206\u4e3a3.6/5\uff0c\u5bf9\u9884\u6d4b\u7a81\u53d1\u4e8b\u4ef6\u7684\u6709\u7528\u6027\u8bc4\u5206\u4e3a3.9/5\u3002\u53c2\u4e0e\u8005\u8981\u6c42\u8bed\u4e49\u8f93\u51fa\u51c6\u786e\u7387\u8fbe\u523074.6%\u624d\u4fe1\u4efb\uff0c67.8%\u624d\u8ba4\u4e3a\u6709\u7528\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6025\u6551\u4eba\u5458\u6700\u91cd\u89c6\u7684\u8bed\u4e49\u4fe1\u606f\u7c7b\u578b\uff08\u7269\u4f53\u8bc6\u522b\u3001\u7a7a\u95f4\u5173\u7cfb\u3001\u98ce\u9669\u80cc\u666f\uff09\uff0c\u5e76\u53d1\u73b0\u4e86\u5b9e\u9a8c\u5ba4\u80fd\u529b\u4e0e\u73b0\u573a\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5f3a\u8c03\u4e86\u6025\u6551\u4eba\u5458\u4e0e\u673a\u5668\u4eba\u7814\u7a76\u4eba\u5458\u4e4b\u95f4\u66f4\u6df1\u5165\u5408\u4f5c\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2510.17241", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17241", "abs": "https://arxiv.org/abs/2510.17241", "authors": ["Stefania Ionescu", "Robin Forsberg", "Elsa Lichtenegger", "Salima Jaoua", "Kshitijaa Jaglan", "Florian Dorfler", "Aniko Hannak"], "title": "Visibility Allocation Systems: How Algorithmic Design Shapes Online Visibility and Societal Outcomes", "comment": null, "summary": "Throughout application domains, we now rely extensively on algorithmic\nsystems to engage with ever-expanding datasets of information. Despite their\nbenefits, these systems are often complex (comprising of many intricate tools,\ne.g., moderation, recommender systems, prediction models), of unknown structure\n(due to the lack of accompanying documentation), and having hard-to-predict yet\npotentially severe downstream consequences (due to the extensive use,\nsystematic enactment of existing errors, and many comprising feedback loops).\nAs such, understanding and evaluating these systems as a whole remains a\nchallenge for both researchers and legislators. To aid ongoing efforts, we\nintroduce a formal framework for such visibility allocation systems (VASs)\nwhich we define as (semi-)automated systems deciding which (processed) data to\npresent a human user with. We review typical tools comprising VASs and define\nthe associated computational problems they solve. By doing so, VASs can be\ndecomposed into sub-processes and illustrated via data flow diagrams. Moreover,\nwe survey metrics for evaluating VASs throughout the pipeline, thus aiding\nsystem diagnostics. Using forecasting-based recommendations in school choice as\na case study, we demonstrate how our framework can support VAS evaluation. We\nalso discuss how our framework can support ongoing AI-legislative efforts to\nlocate obligations, quantify systemic risks, and enable adaptive compliance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u53ef\u89c1\u6027\u5206\u914d\u7cfb\u7edf(VAS)\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u51b3\u5b9a\u5411\u7528\u6237\u5c55\u793a\u54ea\u4e9b\u5904\u7406\u540e\u7684\u6570\u636e\uff0c\u5e2e\u52a9\u7406\u89e3\u590d\u6742\u7b97\u6cd5\u7cfb\u7edf\u7684\u7ed3\u6784\u548c\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u7b97\u6cd5\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\u4e14\u7f3a\u4e4f\u6587\u6863\uff0c\u5176\u7ed3\u6784\u4e0d\u660e\u786e\u4e14\u53ef\u80fd\u4ea7\u751f\u4e25\u91cd\u4e0b\u6e38\u540e\u679c\uff0c\u4f46\u6574\u4f53\u7406\u89e3\u548c\u8bc4\u4f30\u8fd9\u4e9b\u7cfb\u7edf\u5bf9\u7814\u7a76\u4eba\u5458\u548c\u7acb\u6cd5\u8005\u4ecd\u662f\u6311\u6218\u3002", "method": "\u5f15\u5165VAS\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5c06\u5176\u5206\u89e3\u4e3a\u5b50\u8fc7\u7a0b\u5e76\u901a\u8fc7\u6570\u636e\u6d41\u56fe\u8bf4\u660e\uff0c\u56de\u987eVAS\u4e2d\u7684\u5178\u578b\u5de5\u5177\u53ca\u5176\u89e3\u51b3\u7684\u8ba1\u7b97\u95ee\u9898\uff0c\u5e76\u8c03\u67e5\u6574\u4e2a\u6d41\u7a0b\u4e2d\u7684\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u901a\u8fc7\u5b66\u6821\u9009\u62e9\u4e2d\u7684\u9884\u6d4b\u63a8\u8350\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5982\u4f55\u652f\u6301VAS\u8bc4\u4f30\uff0c\u5e76\u8ba8\u8bba\u4e86\u6846\u67b6\u5982\u4f55\u652f\u6301AI\u7acb\u6cd5\u5de5\u4f5c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u8bc4\u4f30\u590d\u6742\u7b97\u6cd5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u5b9a\u4f4d\u4e49\u52a1\u3001\u91cf\u5316\u7cfb\u7edf\u6027\u98ce\u9669\u548c\u5b9e\u73b0\u9002\u5e94\u6027\u5408\u89c4\u3002"}}
{"id": "2510.17762", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17762", "abs": "https://arxiv.org/abs/2510.17762", "authors": ["Alexandra E. Ballentine", "Raghvendra V. Cowlagi"], "title": "Trajectory Optimization for Minimum Threat Exposure using Physics-Informed Neural Networks", "comment": "2025 Indian Control Conference", "summary": "We apply a physics-informed neural network (PINN) to solve the two-point\nboundary value problem (BVP) arising from the necessary conditions postulated\nby Pontryagin's Minimum Principle for optimal control. Such BVPs are known to\nbe numerically difficult to solve by traditional shooting methods due to\nextremely high sensitivity to initial guesses. In the light of recent successes\nin applying PINNs for solving high-dimensional differential equations, we\ndevelop a PINN to solve the problem of finding trajectories with minimum\nexposure to a spatiotemporal threat for a vehicle kinematic model. First, we\nimplement PINNs that are trained to solve the BVP for a given pair of initial\nand final states for a given threat field. Next, we implement a PINN\nconditioned on the initial state for a given threat field, which eliminates the\nneed for retraining for each initial state. We demonstrate that the PINN\noutputs satisfy the necessary conditions with low numerical error.", "AI": {"tldr": "\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINN)\u6c42\u89e3\u7531\u5e9e\u7279\u91cc\u4e9a\u91d1\u6781\u5c0f\u503c\u539f\u7406\u4ea7\u751f\u7684\u4e24\u70b9\u8fb9\u503c\u95ee\u9898\uff0c\u89e3\u51b3\u4f20\u7edf\u6253\u9776\u6cd5\u5bf9\u521d\u503c\u9ad8\u5ea6\u654f\u611f\u7684\u95ee\u9898\uff0c\u5e94\u7528\u4e8e\u8f66\u8f86\u8fd0\u52a8\u5b66\u6a21\u578b\u7684\u6700\u5c0f\u5a01\u80c1\u66b4\u9732\u8f68\u8ff9\u89c4\u5212\u3002", "motivation": "\u4f20\u7edf\u6253\u9776\u6cd5\u6c42\u89e3\u6700\u4f18\u63a7\u5236\u95ee\u9898\u4e2d\u7684\u4e24\u70b9\u8fb9\u503c\u95ee\u9898\u65f6\uff0c\u5bf9\u521d\u59cb\u731c\u6d4b\u6781\u5176\u654f\u611f\uff0c\u6570\u503c\u6c42\u89e3\u56f0\u96be\u3002\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u5728\u6c42\u89e3\u9ad8\u7ef4\u5fae\u5206\u65b9\u7a0b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u56e0\u6b64\u5c1d\u8bd5\u7528PINN\u89e3\u51b3\u8fd9\u7c7b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e24\u79cdPINN\u6a21\u578b\uff1a1)\u9488\u5bf9\u7ed9\u5b9a\u521d\u59cb\u548c\u7ec8\u7aef\u72b6\u6001\u7684\u7279\u5b9a\u5a01\u80c1\u573a\u8bad\u7ec3PINN\uff1b2)\u9488\u5bf9\u7ed9\u5b9a\u5a01\u80c1\u573a\u4f46\u4ec5\u4ee5\u521d\u59cb\u72b6\u6001\u4e3a\u6761\u4ef6\u7684PINN\uff0c\u907f\u514d\u5bf9\u6bcf\u4e2a\u521d\u59cb\u72b6\u6001\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "PINN\u8f93\u51fa\u6ee1\u8db3\u5fc5\u8981\u6761\u4ef6\u7684\u6570\u503c\u8bef\u5dee\u8f83\u4f4e\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "PINN\u80fd\u591f\u6709\u6548\u6c42\u89e3\u6700\u4f18\u63a7\u5236\u4e2d\u7684\u4e24\u70b9\u8fb9\u503c\u95ee\u9898\uff0c\u7279\u522b\u662f\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u6d88\u9664\u4e86\u5bf9\u6bcf\u4e2a\u521d\u59cb\u72b6\u6001\u91cd\u65b0\u8bad\u7ec3\u7684\u9700\u6c42\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.16738", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16738", "abs": "https://arxiv.org/abs/2510.16738", "authors": ["Matteo El-Hariry", "Vittorio Franzese", "Miguel Olivares-Mendez"], "title": "Towards Active Excitation-Based Dynamic Inertia Identification in Satellites", "comment": null, "summary": "This paper presents a comprehensive analysis of how excitation design\ninfluences the identification of the inertia properties of rigid nano- and\nmicro-satellites. We simulate nonlinear attitude dynamics with reaction-wheel\ncoupling, actuator limits, and external disturbances, and excite the system\nusing eight torque profiles of varying spectral richness. Two estimators are\ncompared, a batch Least Squares method and an Extended Kalman Filter, across\nthree satellite configurations and time-varying inertia scenarios. Results show\nthat excitation frequency content and estimator assumptions jointly determine\nestimation accuracy and robustness, offering practical guidance for in-orbit\nadaptive inertia identification by outlining the conditions under which each\nmethod performs best. The code is provided as open-source .", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6fc0\u52b1\u8bbe\u8ba1\u5bf9\u521a\u4f53\u7eb3/\u5fae\u536b\u661f\u60ef\u6027\u53c2\u6570\u8bc6\u522b\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u626d\u77e9\u6fc0\u52b1\u8c31\u548c\u4e24\u79cd\u4f30\u8ba1\u7b97\u6cd5\u5728\u4e0d\u540c\u536b\u661f\u914d\u7f6e\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u5728\u8f68\u81ea\u9002\u5e94\u60ef\u6027\u8bc6\u522b\u4e2d\uff0c\u6fc0\u52b1\u8bbe\u8ba1\u5982\u4f55\u5f71\u54cd\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u6a21\u62df\u975e\u7ebf\u6027\u59ff\u6001\u52a8\u529b\u5b66\uff0c\u4f7f\u75288\u79cd\u4e0d\u540c\u9891\u8c31\u4e30\u5bcc\u5ea6\u7684\u626d\u77e9\u6fc0\u52b1\uff0c\u6bd4\u8f83\u6700\u5c0f\u4e8c\u4e58\u6cd5\u548c\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e24\u79cd\u4f30\u8ba1\u7b97\u6cd5\u5728\u4e09\u79cd\u536b\u661f\u914d\u7f6e\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u6fc0\u52b1\u9891\u7387\u5185\u5bb9\u548c\u4f30\u8ba1\u7b97\u6cd5\u5047\u8bbe\u5171\u540c\u51b3\u5b9a\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u660e\u786e\u4e86\u6bcf\u79cd\u65b9\u6cd5\u7684\u6700\u4f73\u9002\u7528\u6761\u4ef6\u3002", "conclusion": "\u4e3a\u5728\u8f68\u81ea\u9002\u5e94\u60ef\u6027\u8bc6\u522b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5e76\u5f00\u6e90\u4e86\u76f8\u5173\u4ee3\u7801\u3002"}}
{"id": "2510.17425", "categories": ["cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17425", "abs": "https://arxiv.org/abs/2510.17425", "authors": ["Aditi Dutta"], "title": "Quantifying Climate Policy Action and Its Links to Development Outcomes: A Cross-National Data-Driven Analysis", "comment": "This paper/proposal has been accepted as a poster in the NeurIPS 2025", "summary": "Addressing climate change effectively requires more than cataloguing the\nnumber of policies in place; it calls for tools that can reveal their thematic\npriorities and their tangible impacts on development outcomes. Existing\nassessments often rely on qualitative descriptions or composite indices, which\ncan mask crucial differences between key domains such as mitigation,\nadaptation, disaster risk management, and loss and damage. To bridge this gap,\nwe develop a quantitative indicator of climate policy orientation by applying a\nmultilingual transformer-based language model to official national policy\ndocuments, achieving a classification accuracy of 0.90 (F1-score). Linking\nthese indicators with World Bank development data in panel regressions reveals\nthat mitigation policies are associated with higher GDP and GNI; disaster risk\nmanagement correlates with greater GNI and debt but reduced foreign direct\ninvestment; adaptation and loss and damage show limited measurable effects.\nThis integrated NLP-econometric framework enables comparable, theme-specific\nanalysis of climate governance, offering a scalable method to monitor progress,\nevaluate trade-offs, and align policy emphasis with development goals.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a\u8bed\u8a00transformer\u7684\u5b9a\u91cf\u6307\u6807\u6765\u5206\u6790\u6c14\u5019\u653f\u7b56\u53d6\u5411\uff0c\u901a\u8fc7\u5c06\u653f\u7b56\u6587\u6863\u5206\u7c7b\u4e0e\u7ecf\u6d4e\u53d1\u5c55\u6570\u636e\u5173\u8054\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6c14\u5019\u653f\u7b56\u7c7b\u578b\u5bf9\u7ecf\u6d4e\u6307\u6807\u7684\u5f71\u54cd\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u6c14\u5019\u653f\u7b56\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5b9a\u6027\u63cf\u8ff0\u6216\u7efc\u5408\u6307\u6570\uff0c\u65e0\u6cd5\u6e05\u6670\u533a\u5206\u7f13\u89e3\u3001\u9002\u5e94\u3001\u707e\u5bb3\u98ce\u9669\u7ba1\u7406\u7b49\u5173\u952e\u9886\u57df\u7684\u653f\u7b56\u5dee\u5f02\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u91cf\u5316\u5de5\u5177\u6765\u8bc4\u4f30\u653f\u7b56\u5bf9\u53d1\u5c55\u6210\u679c\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u591a\u8bed\u8a00transformer\u8bed\u8a00\u6a21\u578b\u5bf9\u5b98\u65b9\u56fd\u5bb6\u653f\u7b56\u6587\u4ef6\u8fdb\u884c\u5206\u7c7b\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u52300.90\uff08F1\u5206\u6570\uff09\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u6307\u6807\u4e0e\u4e16\u754c\u94f6\u884c\u53d1\u5c55\u6570\u636e\u5728\u9762\u677f\u56de\u5f52\u4e2d\u5173\u8054\u5206\u6790\u3002", "result": "\u7f13\u89e3\u653f\u7b56\u4e0e\u66f4\u9ad8\u7684GDP\u548cGNI\u76f8\u5173\uff1b\u707e\u5bb3\u98ce\u9669\u7ba1\u7406\u4e0e\u66f4\u5927\u7684GNI\u548c\u503a\u52a1\u76f8\u5173\u4f46\u51cf\u5c11\u4e86\u5916\u56fd\u76f4\u63a5\u6295\u8d44\uff1b\u9002\u5e94\u548c\u635f\u5931\u635f\u5bb3\u653f\u7b56\u663e\u793a\u51fa\u6709\u9650\u7684\u53ef\u6d4b\u91cf\u6548\u679c\u3002", "conclusion": "\u8fd9\u4e2a\u96c6\u6210\u7684NLP-\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u6846\u67b6\u80fd\u591f\u5bf9\u6c14\u5019\u6cbb\u7406\u8fdb\u884c\u53ef\u6bd4\u8f83\u7684\u3001\u4e3b\u9898\u7279\u5b9a\u7684\u5206\u6790\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u76d1\u6d4b\u8fdb\u5c55\u3001\u8bc4\u4f30\u6743\u8861\u5e76\u4f7f\u653f\u7b56\u91cd\u70b9\u4e0e\u53d1\u5c55\u76ee\u6807\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2510.17769", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17769", "abs": "https://arxiv.org/abs/2510.17769", "authors": ["Michael Nestor", "Jiaxin Wang", "Ning Zhang", "Fei Teng"], "title": "Data-driven Communication and Control Design for Distributed Frequency Regulation with Black-box Inverters", "comment": "Preprint submitted to PSCC 2026", "summary": "The increasing penetration of inverter-based resources into the power grid,\nwith often only black-box models available, challenges long-standing frequency\ncontrol methods. Most recent works take a decentralized approach without online\ndevice coordination via communication. This paper considers both dynamic\nbehavior and communication within secondary frequency control on an\nintermediate timescale. We develop a distributed data-driven approach that\nutilizes peer-to-peer communication between inverters to avoid the need for a\ncentral control center. To enable a trade off between communication network\nrequirements and control performance, we present a framework to guide\ncommunication topology design for secondary frequency regulation. Following\ndesign of the inter-agent information exchange scheme, we design a controller\nthat is structured according to the communication topology with a closed-loop\nstability guarantee. Case studies on the IEEE 39-bus system validate the\nframework and illustrate the trade-off between communication requirements and\ncontrol performance that is enabled by our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u6570\u636e\u9a71\u52a8\u7684\u4e8c\u6b21\u9891\u7387\u63a7\u5236\u65b9\u6cd5\uff0c\u5229\u7528\u9006\u53d8\u5668\u95f4\u7684\u70b9\u5bf9\u70b9\u901a\u4fe1\uff0c\u65e0\u9700\u4e2d\u592e\u63a7\u5236\u4e2d\u5fc3\uff0c\u5e76\u5728\u901a\u4fe1\u9700\u6c42\u548c\u63a7\u5236\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u6743\u8861\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u9006\u53d8\u5668\u7684\u8d44\u6e90\u5728\u7535\u7f51\u4e2d\u6e17\u900f\u7387\u589e\u52a0\uff0c\u4e14\u901a\u5e38\u53ea\u6709\u9ed1\u76d2\u6a21\u578b\u53ef\u7528\uff0c\u8fd9\u5bf9\u4f20\u7edf\u7684\u9891\u7387\u63a7\u5236\u65b9\u6cd5\u6784\u6210\u6311\u6218\u3002\u73b0\u6709\u7814\u7a76\u591a\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\uff0c\u7f3a\u4e4f\u5728\u7ebf\u8bbe\u5907\u534f\u8c03\u901a\u4fe1\u3002", "method": "\u5f00\u53d1\u5206\u5e03\u5f0f\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5229\u7528\u9006\u53d8\u5668\u95f4\u7684\u70b9\u5bf9\u70b9\u901a\u4fe1\uff1b\u63d0\u51fa\u901a\u4fe1\u62d3\u6251\u8bbe\u8ba1\u6846\u67b6\uff0c\u6307\u5bfc\u4e8c\u6b21\u9891\u7387\u8c03\u8282\u7684\u901a\u4fe1\u7f51\u7edc\u8bbe\u8ba1\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u901a\u4fe1\u62d3\u6251\u7ed3\u6784\u7684\u63a7\u5236\u5668\uff0c\u4fdd\u8bc1\u95ed\u73af\u7a33\u5b9a\u6027\u3002", "result": "\u5728IEEE 39\u603b\u7ebf\u7cfb\u7edf\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u901a\u4fe1\u9700\u6c42\u548c\u63a7\u5236\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5206\u5e03\u5f0f\u4e8c\u6b21\u9891\u7387\u63a7\u5236\uff0c\u901a\u8fc7\u901a\u4fe1\u62d3\u6251\u8bbe\u8ba1\u5728\u901a\u4fe1\u7f51\u7edc\u9700\u6c42\u548c\u63a7\u5236\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e14\u5177\u6709\u95ed\u73af\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2510.16755", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16755", "abs": "https://arxiv.org/abs/2510.16755", "authors": ["Kyung-Hwan Kim", "DongHyun Ahn", "Dong-hyun Lee", "JuYoung Yoon", "Dong Jin Hyun"], "title": "Adaptive Invariant Extended Kalman Filter for Legged Robot State Estimation", "comment": "6 pages, accepted to IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS) 2025", "summary": "State estimation is crucial for legged robots as it directly affects control\nperformance and locomotion stability. In this paper, we propose an Adaptive\nInvariant Extended Kalman Filter to improve proprioceptive state estimation for\nlegged robots. The proposed method adaptively adjusts the noise level of the\ncontact foot model based on online covariance estimation, leading to improved\nstate estimation under varying contact conditions. It effectively handles small\nslips that traditional slip rejection fails to address, as overly sensitive\nslip rejection settings risk causing filter divergence. Our approach employs a\ncontact detection algorithm instead of contact sensors, reducing the reliance\non additional hardware. The proposed method is validated through real-world\nexperiments on the quadruped robot LeoQuad, demonstrating enhanced state\nestimation performance in dynamic locomotion scenarios.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u4e0d\u53d8\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u5728\u7ebf\u534f\u65b9\u5dee\u4f30\u8ba1\u8c03\u6574\u63a5\u89e6\u8db3\u6a21\u578b\u566a\u58f0\u6c34\u5e73\uff0c\u6539\u8fdb\u817f\u5f0f\u673a\u5668\u4eba\u7684\u672c\u4f53\u72b6\u6001\u4f30\u8ba1\u6027\u80fd", "motivation": "\u72b6\u6001\u4f30\u8ba1\u5bf9\u817f\u5f0f\u673a\u5668\u4eba\u81f3\u5173\u91cd\u8981\uff0c\u76f4\u63a5\u5f71\u54cd\u63a7\u5236\u6027\u80fd\u548c\u8fd0\u52a8\u7a33\u5b9a\u6027\u3002\u4f20\u7edf\u6ed1\u79fb\u62d2\u7edd\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u5c0f\u6ed1\u79fb\uff0c\u4e14\u8fc7\u4e8e\u654f\u611f\u7684\u6ed1\u79fb\u62d2\u7edd\u8bbe\u7f6e\u53ef\u80fd\u5bfc\u81f4\u6ee4\u6ce2\u5668\u53d1\u6563", "method": "\u4f7f\u7528\u81ea\u9002\u5e94\u4e0d\u53d8\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u57fa\u4e8e\u5728\u7ebf\u534f\u65b9\u5dee\u4f30\u8ba1\u8c03\u6574\u63a5\u89e6\u8db3\u6a21\u578b\u566a\u58f0\u6c34\u5e73\uff1b\u91c7\u7528\u63a5\u89e6\u68c0\u6d4b\u7b97\u6cd5\u800c\u975e\u63a5\u89e6\u4f20\u611f\u5668\uff0c\u51cf\u5c11\u5bf9\u989d\u5916\u786c\u4ef6\u7684\u4f9d\u8d56", "result": "\u5728\u56db\u8db3\u673a\u5668\u4ebaLeoQuad\u4e0a\u8fdb\u884c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5728\u52a8\u6001\u8fd0\u52a8\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u72b6\u6001\u4f30\u8ba1\u6027\u80fd", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\u7684\u5c0f\u6ed1\u79fb\u95ee\u9898\uff0c\u63d0\u9ad8\u817f\u5f0f\u673a\u5668\u4eba\u5728\u53d8\u5316\u63a5\u89e6\u6761\u4ef6\u4e0b\u7684\u72b6\u6001\u4f30\u8ba1\u7cbe\u5ea6"}}
{"id": "2510.17710", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.17710", "abs": "https://arxiv.org/abs/2510.17710", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Mensen aanwijzen maar niet bij naam noemen: behavioural targeting, persoonsgegevens, en de nieuwe Privacyverordening", "comment": "In Dutch", "summary": "Information about millions of people is collected for behavioural targeting,\na type of marketing that involves tracking people's online behaviour for\ntargeted advertising. It is hotly debated whether data protection law applies\nto behavioural targeting. Many behavioural targeting companies say that, as\nlong as they do not tie names to data they hold about individuals, they do not\nprocess any personal data, and that, therefore, data protection law does not\napply to them. European Data Protection Authorities, however, take the view\nthat a company processes personal data if it uses data to single out a person,\neven if it cannot tie a name to these data. This paper argues that data\nprotection law should indeed apply to behavioural targeting. Companies can\noften tie a name to nameless data about individuals. Furthermore, behavioural\ntargeting relies on collecting information about individuals, singling out\nindividuals, and targeting ads to individuals. Many privacy risks remain,\nregardless of whether companies tie a name to the information they hold about a\nperson. A name is merely one of the identifiers that can be tied to data about\na person, and it is not even the most practical identifier for behavioural\ntargeting. Seeing data used to single out a person as personal data fits the\nrationale for data protection law: protecting fairness and privacy.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u6570\u636e\u4fdd\u62a4\u6cd5\u5e94\u9002\u7528\u4e8e\u884c\u4e3a\u5b9a\u5411\u8425\u9500\uff0c\u5373\u4f7f\u516c\u53f8\u672a\u5c06\u59d3\u540d\u4e0e\u4e2a\u4eba\u6570\u636e\u5173\u8054\uff0c\u53ea\u8981\u80fd\u591f\u8bc6\u522b\u51fa\u7279\u5b9a\u4e2a\u4eba\uff0c\u5c31\u5e94\u89c6\u4e3a\u5904\u7406\u4e2a\u4eba\u6570\u636e\u3002", "motivation": "\u884c\u4e3a\u5b9a\u5411\u8425\u9500\u516c\u53f8\u901a\u5e38\u58f0\u79f0\u53ea\u8981\u4e0d\u5c06\u59d3\u540d\u4e0e\u4e2a\u4eba\u6570\u636e\u5173\u8054\uff0c\u5c31\u4e0d\u5904\u7406\u4e2a\u4eba\u6570\u636e\uff0c\u56e0\u6b64\u6570\u636e\u4fdd\u62a4\u6cd5\u4e0d\u9002\u7528\u3002\u672c\u6587\u65e8\u5728\u53cd\u9a73\u8fd9\u4e00\u89c2\u70b9\uff0c\u5f3a\u8c03\u9690\u79c1\u98ce\u9669\u4f9d\u7136\u5b58\u5728\u3002", "method": "\u901a\u8fc7\u5206\u6790\u884c\u4e3a\u5b9a\u5411\u8425\u9500\u7684\u5b9e\u9645\u8fd0\u4f5c\u65b9\u5f0f\uff0c\u8bba\u8bc1\u5373\u4f7f\u6ca1\u6709\u59d3\u540d\u5173\u8054\uff0c\u516c\u53f8\u4ecd\u80fd\u8bc6\u522b\u7279\u5b9a\u4e2a\u4eba\uff0c\u4e14\u59d3\u540d\u5e76\u975e\u6700\u5b9e\u7528\u7684\u6807\u8bc6\u7b26\u3002", "result": "\u8bba\u8bc1\u8868\u660e\u884c\u4e3a\u5b9a\u5411\u8425\u9500\u6d89\u53ca\u6536\u96c6\u4e2a\u4eba\u4fe1\u606f\u3001\u8bc6\u522b\u4e2a\u4eba\u5e76\u5411\u4e2a\u4eba\u6295\u653e\u5e7f\u544a\uff0c\u8fd9\u4e9b\u6d3b\u52a8\u5e94\u88ab\u89c6\u4e3a\u5904\u7406\u4e2a\u4eba\u6570\u636e\u3002", "conclusion": "\u6570\u636e\u4fdd\u62a4\u6cd5\u5e94\u9002\u7528\u4e8e\u884c\u4e3a\u5b9a\u5411\u8425\u9500\uff0c\u56e0\u4e3a\u5176\u6838\u5fc3\u662f\u8bc6\u522b\u548c\u9488\u5bf9\u4e2a\u4eba\uff0c\u7b26\u5408\u6570\u636e\u4fdd\u62a4\u6cd5\u4fdd\u62a4\u516c\u5e73\u6027\u548c\u9690\u79c1\u7684\u5b97\u65e8\u3002"}}
{"id": "2510.16767", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16767", "abs": "https://arxiv.org/abs/2510.16767", "authors": ["Jia Li", "Guoxiang Zhao"], "title": "T3 Planner: A Self-Correcting LLM Framework for Robotic Motion Planning with Temporal Logic", "comment": null, "summary": "Translating natural language instructions into executable motion plans is a\nfundamental challenge in robotics. Traditional approaches are typically\nconstrained by their reliance on domain-specific expertise to customize\nplanners, and often struggle with spatio-temporal couplings that usually lead\nto infeasible motions or discrepancies between task planning and motion\nexecution. Despite the proficiency of Large Language Models (LLMs) in\nhigh-level semantic reasoning, hallucination could result in infeasible motion\nplans. In this paper, we introduce the T3 Planner, an LLM-enabled robotic\nmotion planning framework that self-corrects it output with formal methods. The\nframework decomposes spatio-temporal task constraints via three cascaded\nmodules, each of which stimulates an LLM to generate candidate trajectory\nsequences and examines their feasibility via a Signal Temporal Logic (STL)\nverifier until one that satisfies complex spatial, temporal, and logical\nconstraints is found.Experiments across different scenarios show that T3\nPlanner significantly outperforms the baselines. The required reasoning can be\ndistilled into a lightweight Qwen3-4B model that enables efficient deployment.\nAll supplementary materials are accessible at\nhttps://github.com/leeejia/T3_Planner.", "AI": {"tldr": "T3 Planner\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u7ea7\u8054\u6a21\u5757\u5206\u89e3\u65f6\u7a7a\u4efb\u52a1\u7ea6\u675f\uff0c\u4f7f\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\u9a8c\u8bc1\u5668\u786e\u4fdd\u751f\u6210\u7684\u8fd0\u52a8\u8ba1\u5212\u53ef\u884c\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u5b9a\u5236\u89c4\u5212\u5668\uff0c\u96be\u4ee5\u5904\u7406\u65f6\u7a7a\u8026\u5408\u7ea6\u675f\uff0c\u5bb9\u6613\u4ea7\u751f\u4e0d\u53ef\u884c\u8fd0\u52a8\u8ba1\u5212\u3002\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u64c5\u957f\u8bed\u4e49\u63a8\u7406\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u5bfc\u81f4\u4e0d\u53ef\u884c\u89c4\u5212\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u7ea7\u8054\u6a21\u5757\u5206\u89e3\u65f6\u7a7a\u4efb\u52a1\u7ea6\u675f\uff0c\u6bcf\u4e2a\u6a21\u5757\u523a\u6fc0LLM\u751f\u6210\u5019\u9009\u8f68\u8ff9\u5e8f\u5217\uff0c\u901a\u8fc7\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\u9a8c\u8bc1\u5668\u68c0\u67e5\u53ef\u884c\u6027\uff0c\u76f4\u5230\u627e\u5230\u6ee1\u8db3\u590d\u6742\u65f6\u7a7a\u548c\u903b\u8f91\u7ea6\u675f\u7684\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660eT3 Planner\u5728\u591a\u79cd\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6240\u9700\u63a8\u7406\u80fd\u529b\u53ef\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7Qwen3-4B\u6a21\u578b\u4e2d\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\u3002", "conclusion": "T3 Planner\u901a\u8fc7\u7ed3\u5408LLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5230\u53ef\u884c\u8fd0\u52a8\u8ba1\u5212\u7684\u8f6c\u6362\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u3002"}}
{"id": "2510.17711", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.17711", "abs": "https://arxiv.org/abs/2510.17711", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Discrimination, intelligence artificielle et decisions algorithmiques", "comment": "In French", "summary": "Artificial intelligence (AI) has a huge impact on our personal lives and also\non our democratic society as a whole. While AI offers vast opportunities for\nthe benefit of people, its potential to embed and perpetuate bias and\ndiscrimination remains one of the most pressing challenges deriving from its\nincreasing use. This new study, which was prepared by Prof. Frederik Zuiderveen\nBorgesius for the Anti-discrimination Department of the Council of Europe,\nelaborates on the risks of discrimination caused by algorithmic decision-making\nand other types of artificial intelligence (AI).", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u4eba\u5de5\u667a\u80fd\u7b97\u6cd5\u51b3\u7b56\u53ef\u80fd\u5bfc\u81f4\u7684\u6b67\u89c6\u98ce\u9669\uff0c\u7531\u6b27\u6d32\u7406\u4e8b\u4f1a\u53cd\u6b67\u89c6\u90e8\u95e8\u59d4\u6258\u8fdb\u884c", "motivation": "AI\u6280\u672f\u867d\u7136\u5e26\u6765\u5de8\u5927\u673a\u9047\uff0c\u4f46\u5176\u5d4c\u5165\u548c\u5ef6\u7eed\u504f\u89c1\u4e0e\u6b67\u89c6\u7684\u6f5c\u529b\u662f\u6700\u7d27\u8feb\u7684\u6311\u6218\u4e4b\u4e00\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u7b97\u6cd5\u51b3\u7b56\u7684\u6b67\u89c6\u98ce\u9669", "method": "\u901a\u8fc7\u6587\u732e\u7814\u7a76\u548c\u653f\u7b56\u5206\u6790\uff0c\u7cfb\u7edf\u8bc4\u4f30AI\u7b97\u6cd5\u51b3\u7b56\u53ef\u80fd\u5bfc\u81f4\u7684\u6b67\u89c6\u673a\u5236\u548c\u98ce\u9669\u7c7b\u578b", "result": "\u8bc6\u522b\u4e86AI\u7cfb\u7edf\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u4ea7\u751f\u7684\u591a\u79cd\u6b67\u89c6\u98ce\u9669\uff0c\u5305\u62ec\u7b97\u6cd5\u504f\u89c1\u3001\u6570\u636e\u504f\u5dee\u7b49\u95ee\u9898", "conclusion": "AI\u7b97\u6cd5\u7684\u6b67\u89c6\u98ce\u9669\u662f\u5f53\u524d\u6700\u7d27\u8feb\u7684\u6311\u6218\u4e4b\u4e00\uff0c\u9700\u8981\u5236\u5b9a\u76f8\u5e94\u653f\u7b56\u548c\u76d1\u7ba1\u63aa\u65bd\u6765\u9632\u8303\u7b97\u6cd5\u51b3\u7b56\u4e2d\u7684\u6b67\u89c6\u95ee\u9898"}}
{"id": "2510.16771", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16771", "abs": "https://arxiv.org/abs/2510.16771", "authors": ["Xu He", "Xiaolin Meng", "Wenxuan Yin", "Youdong Zhang", "Lingfei Mo", "Xiangdong An", "Fangwen Yu", "Shuguo Pan", "Yufeng Liu", "Jingnan Liu", "Yujia Zhang", "Wang Gao"], "title": "A Preliminary Exploration of the Differences and Conjunction of Traditional PNT and Brain-inspired PNT", "comment": null, "summary": "Developing universal Positioning, Navigation, and Timing (PNT) is our\nenduring goal. Today's complex environments demand PNT that is more resilient,\nenergy-efficient and cognitively capable. This paper asks how we can endow\nunmanned systems with brain-inspired spatial cognition navigation while\nexploiting the high precision of machine PNT to advance universal PNT. We\nprovide a new perspective and roadmap for shifting PNT from \"tool-oriented\" to\n\"cognition-driven\". Contributions: (1) multi-level dissection of differences\namong traditional PNT, biological brain PNT and brain-inspired PNT; (2) a\nfour-layer (observation-capability-decision-hardware) fusion framework that\nunites numerical precision and brain-inspired intelligence; (3) forward-looking\nrecommendations for future development of brain-inspired PNT.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4ece\"\u5de5\u5177\u5bfc\u5411\"\u8f6c\u5411\"\u8ba4\u77e5\u9a71\u52a8\"\u7684\u5b9a\u4f4d\u3001\u5bfc\u822a\u4e0e\u6388\u65f6(PNT)\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u878d\u5408\u673a\u5668PNT\u7684\u9ad8\u7cbe\u5ea6\u4e0e\u8111\u542f\u53d1\u7a7a\u95f4\u8ba4\u77e5\uff0c\u6784\u5efa\u56db\u5c42\u878d\u5408\u6846\u67b6\u6765\u63a8\u8fdb\u901a\u7528PNT\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u590d\u6742\u73af\u5883\u9700\u8981\u66f4\u5177\u5f39\u6027\u3001\u80fd\u6548\u548c\u8ba4\u77e5\u80fd\u529b\u7684PNT\u7cfb\u7edf\uff0c\u76ee\u6807\u662f\u8d4b\u4e88\u65e0\u4eba\u7cfb\u7edf\u8111\u542f\u53d1\u7a7a\u95f4\u8ba4\u77e5\u5bfc\u822a\u80fd\u529b\uff0c\u540c\u65f6\u5229\u7528\u673a\u5668PNT\u7684\u9ad8\u7cbe\u5ea6\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u56db\u5c42\u878d\u5408\u6846\u67b6\uff08\u89c2\u6d4b-\u80fd\u529b-\u51b3\u7b56-\u786c\u4ef6\uff09\uff0c\u6574\u5408\u6570\u503c\u7cbe\u5ea6\u4e0e\u8111\u542f\u53d1\u667a\u80fd\uff1b\u591a\u5c42\u6b21\u5206\u6790\u4f20\u7edfPNT\u3001\u751f\u7269\u8111PNT\u548c\u8111\u542f\u53d1PNT\u7684\u5dee\u5f02\u3002", "result": "\u5efa\u7acb\u4e86\u8ba4\u77e5\u9a71\u52a8\u7684PNT\u65b0\u89c6\u89d2\u548c\u53d1\u5c55\u8def\u7ebf\u56fe\uff0c\u4e3a\u878d\u5408\u673a\u5668\u7cbe\u5ea6\u4e0e\u751f\u7269\u667a\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u8111\u542f\u53d1PNT\u4ee3\u8868\u4e86PNT\u53d1\u5c55\u7684\u672a\u6765\u65b9\u5411\uff0c\u901a\u8fc7\u8ba4\u77e5\u9a71\u52a8\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u66f4\u667a\u80fd\u3001\u66f4\u9002\u5e94\u590d\u6742\u73af\u5883\u7684\u901a\u7528PNT\u7cfb\u7edf\u3002"}}
{"id": "2510.17712", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.17712", "abs": "https://arxiv.org/abs/2510.17712", "authors": ["Frederik J. Zuiderveen Borgesius", "Judith M\u00f6ller", "Sanne Kruikemeier", "Ronan \u00d3 Fathaigh", "Kristina Irion", "Tom Dobber", "Balazs Bodo", "Claes de Vreese"], "title": "Online Political Microtargeting: Promises and Threats for Democracy", "comment": null, "summary": "Online political microtargeting involves monitoring people's online\nbehaviour, and using the collected data, sometimes enriched with other data, to\nshow people-targeted political advertisements. Online political microtargeting\nis widely used in the US; Europe may not be far behind. This paper maps\nmicrotargeting's promises and threats to democracy. For example, microtargeting\npromises to optimise the match between the electorate's concerns and political\ncampaigns, and to boost campaign engagement and political participation. But\nonline microtargeting could also threaten democracy. For instance, a political\nparty could, misleadingly, present itself as a different one-issue party to\ndifferent individuals. And data collection for microtargeting raises privacy\nconcerns. We sketch possibilities for policymakers if they seek to regulate\nonline political microtargeting. We discuss which measures would be possible,\nwhile complying with the right to freedom of expression under the European\nConvention on Human Rights.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5728\u7ebf\u653f\u6cbb\u5fae\u5b9a\u5411\u5bf9\u6c11\u4e3b\u7684\u627f\u8bfa\u4e0e\u5a01\u80c1\uff0c\u5e76\u63a2\u8ba8\u4e86\u5728\u9075\u5b88\u6b27\u6d32\u4eba\u6743\u516c\u7ea6\u8868\u8fbe\u81ea\u7531\u6743\u524d\u63d0\u4e0b\u7684\u76d1\u7ba1\u53ef\u80fd\u6027\u3002", "motivation": "\u968f\u7740\u5728\u7ebf\u653f\u6cbb\u5fae\u5b9a\u5411\u5728\u7f8e\u56fd\u5e7f\u6cdb\u5e94\u7528\u4e14\u6b27\u6d32\u53ef\u80fd\u8ddf\u8fdb\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5bf9\u6c11\u4e3b\u7684\u5f71\u54cd\u5e76\u63a2\u7d22\u76d1\u7ba1\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6620\u5c04\u5206\u6790\u5fae\u5b9a\u5411\u5bf9\u6c11\u4e3b\u7684\u627f\u8bfa\u4e0e\u5a01\u80c1\uff0c\u5e76\u57fa\u4e8e\u6b27\u6d32\u4eba\u6743\u516c\u7ea6\u6846\u67b6\u63a2\u8ba8\u53ef\u884c\u7684\u76d1\u7ba1\u63aa\u65bd\u3002", "result": "\u8bc6\u522b\u51fa\u5fae\u5b9a\u5411\u65e2\u80fd\u4f18\u5316\u9009\u6c11\u5173\u6ce8\u4e0e\u7ade\u9009\u6d3b\u52a8\u7684\u5339\u914d\u3001\u63d0\u5347\u53c2\u4e0e\u5ea6\uff0c\u4e5f\u53ef\u80fd\u5bfc\u81f4\u653f\u515a\u8bef\u5bfc\u6027\u5448\u73b0\u3001\u5f15\u53d1\u9690\u79c1\u95ee\u9898\u3002", "conclusion": "\u9700\u8981\u5728\u4fdd\u969c\u8868\u8fbe\u81ea\u7531\u7684\u524d\u63d0\u4e0b\u5236\u5b9a\u76d1\u7ba1\u63aa\u65bd\uff0c\u5e73\u8861\u5fae\u5b9a\u5411\u7684\u6c11\u4e3b\u4ef7\u503c\u4e0e\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2510.16905", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16905", "abs": "https://arxiv.org/abs/2510.16905", "authors": ["Yukang Cao", "Rahul Moorthy", "O. Goktug Poyrazoglu", "Volkan Isler"], "title": "C-Free-Uniform: A Map-Conditioned Trajectory Sampler for Model Predictive Path Integral Control", "comment": "Submitted to the 2026 IEEE International Conference on Robotics and\n  Automation (ICRA). 8 pages, 4 figures", "summary": "Trajectory sampling is a key component of sampling-based control mechanisms.\nTrajectory samplers rely on control input samplers, which generate control\ninputs u from a distribution p(u | x) where x is the current state. We\nintroduce the notion of Free Configuration Space Uniformity (C-Free-Uniform for\nshort) which has two key features: (i) it generates a control input\ndistribution so as to uniformly sample the free configuration space, and (ii)\nin contrast to previously introduced trajectory sampling mechanisms where the\ndistribution p(u | x) is independent of the environment, C-Free-Uniform is\nexplicitly conditioned on the current local map. Next, we integrate this\nsampler into a new Model Predictive Path Integral (MPPI) Controller, CFU-MPPI.\nExperiments show that CFU-MPPI outperforms existing methods in terms of success\nrate in challenging navigation tasks in cluttered polygonal environments while\nrequiring a much smaller sampling budget.", "AI": {"tldr": "\u63d0\u51faC-Free-Uniform\u8f68\u8ff9\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u73af\u5883\u611f\u77e5\u7684\u63a7\u5236\u8f93\u5165\u91c7\u6837\u5b9e\u73b0\u81ea\u7531\u914d\u7f6e\u7a7a\u95f4\u5747\u5300\u91c7\u6837\uff0c\u5e76\u96c6\u6210\u5230MPPI\u63a7\u5236\u5668\u4e2d\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u4ee5\u66f4\u5c11\u91c7\u6837\u9884\u7b97\u83b7\u5f97\u66f4\u9ad8\u6210\u529f\u7387", "motivation": "\u73b0\u6709\u8f68\u8ff9\u91c7\u6837\u65b9\u6cd5\u4e2d\u7684\u63a7\u5236\u8f93\u5165\u5206\u5e03\u72ec\u7acb\u4e8e\u73af\u5883\uff0c\u65e0\u6cd5\u6709\u6548\u9002\u5e94\u590d\u6742\u73af\u5883\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u611f\u77e5\u5c40\u90e8\u73af\u5883\u5e76\u5747\u5300\u91c7\u6837\u81ea\u7531\u914d\u7f6e\u7a7a\u95f4\u7684\u65b9\u6cd5", "method": "\u63d0\u51faC-Free-Uniform\u91c7\u6837\u5668\uff0c\u751f\u6210\u6761\u4ef6\u4e8e\u5c40\u90e8\u5730\u56fe\u7684\u63a7\u5236\u8f93\u5165\u5206\u5e03\uff0c\u5b9e\u73b0\u81ea\u7531\u914d\u7f6e\u7a7a\u95f4\u5747\u5300\u91c7\u6837\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230MPPI\u63a7\u5236\u5668\u4e2d\u5f62\u6210CFU-MPPI", "result": "\u5728\u590d\u6742\u591a\u8fb9\u5f62\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0cCFU-MPPI\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u6210\u529f\u7387\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u6240\u9700\u91c7\u6837\u9884\u7b97\u663e\u8457\u51cf\u5c11", "conclusion": "C-Free-Uniform\u901a\u8fc7\u73af\u5883\u611f\u77e5\u7684\u91c7\u6837\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u91c7\u6837\u6548\u7387\u548c\u63a7\u5236\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684\u8fd0\u52a8\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.17270", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.17270", "abs": "https://arxiv.org/abs/2510.17270", "authors": ["Lucas Schulze", "Juliano Decico Negri", "Victor Barasuol", "Vivian Suzano Medeiros", "Marcelo Becker", "Jan Peters", "Oleg Arenz"], "title": "Floating-Base Deep Lagrangian Networks", "comment": null, "summary": "Grey-box methods for system identification combine deep learning with\nphysics-informed constraints, capturing complex dependencies while improving\nout-of-distribution generalization. Yet, despite the growing importance of\nfloating-base systems such as humanoids and quadrupeds, current grey-box models\nignore their specific physical constraints. For instance, the inertia matrix is\nnot only positive definite but also exhibits branch-induced sparsity and input\nindependence. Moreover, the 6x6 composite spatial inertia of the floating base\ninherits properties of single-rigid-body inertia matrices. As we show, this\nincludes the triangle inequality on the eigenvalues of the composite rotational\ninertia. To address the lack of physical consistency in deep learning models of\nfloating-base systems, we introduce a parameterization of inertia matrices that\nsatisfies all these constraints. Inspired by Deep Lagrangian Networks (DeLaN),\nwe train neural networks to predict physically plausible inertia matrices that\nminimize inverse dynamics error under Lagrangian mechanics. For evaluation, we\ncollected and released a dataset on multiple quadrupeds and humanoids. In these\nexperiments, our Floating-Base Deep Lagrangian Networks (FeLaN) achieve highly\ncompetitive performance on both simulated and real robots, while providing\ngreater physical interpretability.", "AI": {"tldr": "\u63d0\u51faFloating-Base Deep Lagrangian Networks (FeLaN)\uff0c\u4e00\u79cd\u9488\u5bf9\u6d6e\u52a8\u57fa\u7cfb\u7edf\uff08\u5982\u4eba\u5f62\u673a\u5668\u4eba\u548c\u56db\u8db3\u673a\u5668\u4eba\uff09\u7684\u7269\u7406\u7ea6\u675f\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u786e\u4fdd\u60ef\u6027\u77e9\u9635\u6ee1\u8db3\u6b63\u5b9a\u6027\u3001\u5206\u652f\u8bf1\u5bfc\u7a00\u758f\u6027\u548c\u8f93\u5165\u72ec\u7acb\u6027\u7b49\u7269\u7406\u7ea6\u675f\u3002", "motivation": "\u5f53\u524d\u7070\u76d2\u65b9\u6cd5\u5728\u7cfb\u7edf\u8bc6\u522b\u4e2d\u5ffd\u7565\u4e86\u6d6e\u52a8\u57fa\u7cfb\u7edf\u7684\u7279\u5b9a\u7269\u7406\u7ea6\u675f\uff0c\u5982\u60ef\u6027\u77e9\u9635\u7684\u6b63\u5b9a\u6027\u3001\u5206\u652f\u8bf1\u5bfc\u7a00\u758f\u6027\u548c\u8f93\u5165\u72ec\u7acb\u6027\uff0c\u4ee5\u53ca\u590d\u5408\u7a7a\u95f4\u60ef\u6027\u7684\u7279\u6027\uff0c\u5bfc\u81f4\u7269\u7406\u4e00\u81f4\u6027\u4e0d\u8db3\u3002", "method": "\u53d7Deep Lagrangian Networks (DeLaN)\u542f\u53d1\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u6ee1\u8db3\u6240\u6709\u7269\u7406\u7ea6\u675f\u7684\u60ef\u6027\u77e9\u9635\uff0c\u5728\u62c9\u683c\u6717\u65e5\u529b\u5b66\u4e0b\u6700\u5c0f\u5316\u9006\u52a8\u529b\u5b66\u8bef\u5dee\u3002", "result": "\u5728\u591a\u4e2a\u56db\u8db3\u673a\u5668\u4eba\u548c\u4eba\u5f62\u673a\u5668\u4eba\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFeLaN\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u5747\u53d6\u5f97\u4e86\u6781\u5177\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u7269\u7406\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "FeLaN\u901a\u8fc7\u7269\u7406\u7ea6\u675f\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d6e\u52a8\u57fa\u7cfb\u7edf\u5efa\u6a21\u7684\u7269\u7406\u4e00\u81f4\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u590d\u6742\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16931", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16931", "abs": "https://arxiv.org/abs/2510.16931", "authors": ["Zhaoliang Wan", "Zida Zhou", "Zetong Bi", "Zehui Yang", "Hao Ding", "Hui Cheng"], "title": "Design of an Affordable, Fully-Actuated Biomimetic Hand for Dexterous Teleoperation Systems", "comment": "Accepted by IROS2025", "summary": "This paper addresses the scarcity of affordable, fully-actuated five-fingered\nhands for dexterous teleoperation, which is crucial for collecting large-scale\nreal-robot data within the \"Learning from Demonstrations\" paradigm. We\nintroduce the prototype version of the RAPID Hand, the first low-cost,\n20-degree-of-actuation (DoA) dexterous hand that integrates a novel\nanthropomorphic actuation and transmission scheme with an optimized motor\nlayout and structural design to enhance dexterity. Specifically, the RAPID Hand\nfeatures a universal phalangeal transmission scheme for the non-thumb fingers\nand an omnidirectional thumb actuation mechanism. Prioritizing affordability,\nthe hand employs 3D-printed parts combined with custom gears for easier\nreplacement and repair. We assess the RAPID Hand's performance through\nquantitative metrics and qualitative testing in a dexterous teleoperation\nsystem, which is evaluated on three challenging tasks: multi-finger retrieval,\nladle handling, and human-like piano playing. The results indicate that the\nRAPID Hand's fully actuated 20-DoF design holds significant promise for\ndexterous teleoperation.", "AI": {"tldr": "RAPID Hand\u662f\u9996\u4e2a\u4f4e\u6210\u672c\u300120\u81ea\u7531\u5ea6\u7684\u7075\u5de7\u624b\u539f\u578b\uff0c\u91c7\u7528\u521b\u65b0\u7684\u4eff\u751f\u9a71\u52a8\u548c\u4f20\u52a8\u65b9\u6848\uff0c\u901a\u8fc73D\u6253\u5370\u90e8\u4ef6\u548c\u5b9a\u5236\u9f7f\u8f6e\u5b9e\u73b0\u7ecf\u6d4e\u6027\uff0c\u5728\u7075\u5de7\u9065\u64cd\u4f5c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3\u7075\u5de7\u9065\u64cd\u4f5c\u4e2d\u7f3a\u4e4f\u7ecf\u6d4e\u5b9e\u60e0\u7684\u4e94\u6307\u7075\u5de7\u624b\u7684\u95ee\u9898\uff0c\u8fd9\u5bf9\u4e8e\u5728\"\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\"\u8303\u5f0f\u4e2d\u6536\u96c6\u5927\u89c4\u6a21\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684\u4eff\u751f\u9a71\u52a8\u548c\u4f20\u52a8\u65b9\u6848\uff0c\u5305\u62ec\u975e\u62c7\u6307\u624b\u6307\u7684\u901a\u7528\u6307\u9aa8\u4f20\u52a8\u65b9\u6848\u548c\u5168\u5411\u62c7\u6307\u9a71\u52a8\u673a\u5236\uff0c\u4f7f\u75283D\u6253\u5370\u90e8\u4ef6\u548c\u5b9a\u5236\u9f7f\u8f6e\u4ee5\u964d\u4f4e\u6210\u672c\u5e76\u4fbf\u4e8e\u7ef4\u4fee\u3002", "result": "\u901a\u8fc7\u5b9a\u91cf\u6307\u6807\u548c\u5b9a\u6027\u6d4b\u8bd5\u8bc4\u4f30\uff0c\u5728\u591a\u9879\u6311\u6218\u6027\u4efb\u52a1\uff08\u591a\u6307\u6293\u53d6\u3001\u52fa\u5b50\u64cd\u4f5c\u3001\u7c7b\u4eba\u94a2\u7434\u6f14\u594f\uff09\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u517620\u81ea\u7531\u5ea6\u7684\u5b8c\u5168\u9a71\u52a8\u8bbe\u8ba1\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002", "conclusion": "RAPID Hand\u7684\u5b8c\u5168\u9a71\u52a820\u81ea\u7531\u5ea6\u8bbe\u8ba1\u5728\u7075\u5de7\u9065\u64cd\u4f5c\u65b9\u9762\u5177\u6709\u91cd\u8981\u524d\u666f\uff0c\u4e3a\u5927\u89c4\u6a21\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\u6536\u96c6\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17408", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.17408", "abs": "https://arxiv.org/abs/2510.17408", "authors": ["Halima I. Kure", "Jishna Retnakumari", "Augustine O. Nwajana", "Umar M. Ismail", "Bilyaminu A. Romo", "Ehigiator Egho-Promise"], "title": "Integrating Trustworthy Artificial Intelligence with Energy-Efficient Robotic Arms for Waste Sorting", "comment": "5 pages, 2 figures", "summary": "This paper presents a novel methodology that integrates trustworthy\nartificial intelligence (AI) with an energy-efficient robotic arm for\nintelligent waste classification and sorting. By utilizing a convolutional\nneural network (CNN) enhanced through transfer learning with MobileNetV2, the\nsystem accurately classifies waste into six categories: plastic, glass, metal,\npaper, cardboard, and trash. The model achieved a high training accuracy of\n99.8% and a validation accuracy of 80.5%, demonstrating strong learning and\ngeneralization. A robotic arm simulator is implemented to perform virtual\nsorting, calculating the energy cost for each action using Euclidean distance\nto ensure optimal and efficient movement. The framework incorporates key\nelements of trustworthy AI, such as transparency, robustness, fairness, and\nsafety, making it a reliable and scalable solution for smart waste management\nsystems in urban settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u4e0e\u8282\u80fd\u673a\u68b0\u81c2\u76f8\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u667a\u80fd\u5783\u573e\u5206\u7c7b\u548c\u5206\u62e3\uff0c\u901a\u8fc7CNN\u548cMobileNetV2\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5206\u7c7b\uff0c\u5e76\u5728\u6a21\u62df\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u80fd\u6548\u4f18\u5316\u7684\u5206\u62e3\u64cd\u4f5c\u3002", "motivation": "\u89e3\u51b3\u57ce\u5e02\u73af\u5883\u4e2d\u667a\u80fd\u5e9f\u7269\u7ba1\u7406\u7cfb\u7edf\u7684\u9700\u6c42\uff0c\u901a\u8fc7\u53ef\u4fe1AI\u6280\u672f\u63d0\u9ad8\u5783\u573e\u5206\u7c7b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u786e\u4fdd\u7cfb\u7edf\u7684\u900f\u660e\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eMobileNetV2\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff0c\u51c6\u786e\u5206\u7c7b\u516d\u7c7b\u5e9f\u7269\uff1b\u5f00\u53d1\u673a\u68b0\u81c2\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u8ba1\u7b97\u80fd\u8017\uff0c\u4f18\u5316\u5206\u62e3\u52a8\u4f5c\u3002", "result": "\u6a21\u578b\u8bad\u7ec3\u51c6\u786e\u7387\u8fbe99.8%\uff0c\u9a8c\u8bc1\u51c6\u786e\u7387\u8fbe80.5%\uff1b\u6a21\u62df\u7cfb\u7edf\u80fd\u6709\u6548\u8ba1\u7b97\u548c\u4f18\u5316\u5206\u62e3\u80fd\u8017\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u57ce\u5e02\u667a\u80fd\u5e9f\u7269\u7ba1\u7406\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u4e86\u53ef\u4fe1AI\u539f\u5219\u548c\u8282\u80fd\u8bbe\u8ba1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.17038", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17038", "abs": "https://arxiv.org/abs/2510.17038", "authors": ["Pedram Fekri", "Majid Roshanfar", "Samuel Barbeau", "Seyedfarzad Famouri", "Thomas Looi", "Dale Podolsky", "Mehrdad Zadeh", "Javad Dargahi"], "title": "DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation", "comment": null, "summary": "Cardiac catheterization remains a cornerstone of minimally invasive\ninterventions, yet it continues to rely heavily on manual operation. Despite\nadvances in robotic platforms, existing systems are predominantly follow-leader\nin nature, requiring continuous physician input and lacking intelligent\nautonomy. This dependency contributes to operator fatigue, more radiation\nexposure, and variability in procedural outcomes. This work moves towards\nautonomous catheter navigation by introducing DINO-CVA, a multimodal\ngoal-conditioned behavior cloning framework. The proposed model fuses visual\nobservations and joystick kinematics into a joint embedding space, enabling\npolicies that are both vision-aware and kinematic-aware. Actions are predicted\nautoregressively from expert demonstrations, with goal conditioning guiding\nnavigation toward specified destinations. A robotic experimental setup with a\nsynthetic vascular phantom was designed to collect multimodal datasets and\nevaluate performance. Results show that DINO-CVA achieves high accuracy in\npredicting actions, matching the performance of a kinematics-only baseline\nwhile additionally grounding predictions in the anatomical environment. These\nfindings establish the feasibility of multimodal, goal-conditioned\narchitectures for catheter navigation, representing an important step toward\nreducing operator dependency and improving the reliability of catheterbased\ntherapies.", "AI": {"tldr": "DINO-CVA\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u76ee\u6807\u6761\u4ef6\u884c\u4e3a\u514b\u9686\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u81ea\u4e3b\u5bfc\u7ba1\u5bfc\u822a\uff0c\u878d\u5408\u89c6\u89c9\u89c2\u5bdf\u548c\u64cd\u7eb5\u6746\u8fd0\u52a8\u5b66\uff0c\u51cf\u5c11\u5bf9\u64cd\u4f5c\u5458\u7684\u4f9d\u8d56\u3002", "motivation": "\u5f53\u524d\u5bfc\u7ba1\u4ecb\u5165\u624b\u672f\u4e3b\u8981\u4f9d\u8d56\u624b\u52a8\u64cd\u4f5c\uff0c\u73b0\u6709\u673a\u5668\u4eba\u7cfb\u7edf\u7f3a\u4e4f\u667a\u80fd\u81ea\u4e3b\u6027\uff0c\u5bfc\u81f4\u64cd\u4f5c\u8005\u75b2\u52b3\u3001\u8f90\u5c04\u66b4\u9732\u589e\u52a0\u548c\u624b\u672f\u7ed3\u679c\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51faDINO-CVA\u6846\u67b6\uff0c\u5c06\u89c6\u89c9\u89c2\u5bdf\u548c\u64cd\u7eb5\u6746\u8fd0\u52a8\u5b66\u878d\u5408\u5230\u8054\u5408\u5d4c\u5165\u7a7a\u95f4\uff0c\u901a\u8fc7\u81ea\u56de\u5f52\u65b9\u5f0f\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u9884\u6d4b\u52a8\u4f5c\uff0c\u5e76\u4f7f\u7528\u76ee\u6807\u6761\u4ef6\u5f15\u5bfc\u5bfc\u822a\u81f3\u6307\u5b9a\u76ee\u7684\u5730\u3002", "result": "DINO-CVA\u5728\u9884\u6d4b\u52a8\u4f5c\u65b9\u9762\u8fbe\u5230\u9ad8\u7cbe\u5ea6\uff0c\u4e0e\u4ec5\u4f7f\u7528\u8fd0\u52a8\u5b66\u7684\u57fa\u7ebf\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u5c06\u9884\u6d4b\u57fa\u4e8e\u89e3\u5256\u73af\u5883\u3002", "conclusion": "\u591a\u6a21\u6001\u76ee\u6807\u6761\u4ef6\u67b6\u6784\u5728\u5bfc\u7ba1\u5bfc\u822a\u4e2d\u5177\u6709\u53ef\u884c\u6027\uff0c\u662f\u51cf\u5c11\u64cd\u4f5c\u5458\u4f9d\u8d56\u3001\u63d0\u9ad8\u5bfc\u7ba1\u6cbb\u7597\u53ef\u9760\u6027\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.17590", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.CY", "cs.LG", "I.2.7; H.3.3; I.4.9"], "pdf": "https://arxiv.org/pdf/2510.17590", "abs": "https://arxiv.org/abs/2510.17590", "authors": ["Mir Nafis Sharear Shopnil", "Sharad Duwal", "Abhishek Tyagi", "Adiba Mahbub Proma"], "title": "MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning", "comment": "16 pages, 3 tables, 1 figure", "summary": "Misinformation spreads across web platforms through billions of daily\nmultimodal posts that combine text and images, overwhelming manual\nfact-checking capacity. Supervised detection models require domain-specific\ntraining data and fail to generalize across diverse manipulation tactics. We\npresent MIRAGE, an inference-time, model-pluggable agentic framework that\ndecomposes multimodal verification into four sequential modules: visual\nveracity assessment detects AI-generated images, cross-modal consistency\nanalysis identifies out-of-context repurposing, retrieval-augmented factual\nchecking grounds claims in web evidence through iterative question generation,\nand a calibrated judgment module integrates all signals. MIRAGE orchestrates\nvision-language model reasoning with targeted web retrieval, outputs structured\nand citation-linked rationales. On MMFakeBench validation set (1,000 samples),\nMIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming\nthe strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65\npoints while maintaining 34.3% false positive rate versus 97.3% for a\njudge-only baseline. Test set results (5,000 samples) confirm generalization\nwith 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification\ncontributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97\npoints. Our results demonstrate that decomposed agentic reasoning with web\nretrieval can match supervised detector performance without domain-specific\ntraining, enabling misinformation detection across modalities where labeled\ndata remains scarce.", "AI": {"tldr": "MIRAGE\u662f\u4e00\u4e2a\u63a8\u7406\u65f6\u3001\u53ef\u63d2\u62d4\u6a21\u578b\u7684\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u771f\u5b9e\u6027\u8bc4\u4f30\u3001\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u5206\u6790\u3001\u68c0\u7d22\u589e\u5f3a\u7684\u4e8b\u5b9e\u68c0\u67e5\u548c\u6821\u51c6\u5224\u65ad\u56db\u4e2a\u6a21\u5757\uff0c\u5728MMFakeBench\u9a8c\u8bc1\u96c6\u4e0a\u8fbe\u523081.65% F1\u5206\u6570\uff0c\u6bd4\u6700\u5f3a\u96f6\u6837\u672c\u57fa\u7ebf\u63d0\u53477.65\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u7f51\u7edc\u5e73\u53f0\u4e0a\u6bcf\u5929\u6709\u6570\u5341\u4ebf\u7ed3\u5408\u6587\u672c\u548c\u56fe\u50cf\u7684\u591a\u6a21\u6001\u5e16\u5b50\u4f20\u64ad\u865a\u5047\u4fe1\u606f\uff0c\u8d85\u51fa\u4e86\u4eba\u5de5\u4e8b\u5b9e\u6838\u67e5\u7684\u80fd\u529b\u3002\u73b0\u6709\u7684\u76d1\u7763\u68c0\u6d4b\u6a21\u578b\u9700\u8981\u7279\u5b9a\u9886\u57df\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4e14\u65e0\u6cd5\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u64cd\u7eb5\u7b56\u7565\u3002", "method": "MIRAGE\u6846\u67b6\u5c06\u591a\u6a21\u6001\u9a8c\u8bc1\u5206\u89e3\u4e3a\u56db\u4e2a\u987a\u5e8f\u6a21\u5757\uff1a\u89c6\u89c9\u771f\u5b9e\u6027\u8bc4\u4f30\u68c0\u6d4bAI\u751f\u6210\u56fe\u50cf\uff0c\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u5206\u6790\u8bc6\u522b\u4e0a\u4e0b\u6587\u4e0d\u5f53\u5229\u7528\uff0c\u68c0\u7d22\u589e\u5f3a\u4e8b\u5b9e\u68c0\u67e5\u901a\u8fc7\u8fed\u4ee3\u95ee\u9898\u751f\u6210\u5c06\u58f0\u660e\u57fa\u4e8e\u7f51\u7edc\u8bc1\u636e\uff0c\u6821\u51c6\u5224\u65ad\u6a21\u5757\u6574\u5408\u6240\u6709\u4fe1\u53f7\u3002", "result": "\u5728MMFakeBench\u9a8c\u8bc1\u96c6\uff081000\u6837\u672c\uff09\u4e0a\uff0cMIRAGE\u4e0eGPT-4o-mini\u7ec4\u5408\u8fbe\u523081.65% F1\u548c75.1%\u51c6\u786e\u7387\uff0c\u6bd4\u6700\u5f3a\u96f6\u6837\u672c\u57fa\u7ebf\uff08GPT-4V\u4e0eMMD-Agent\u768474.0% F1\uff09\u63d0\u53477.65\u70b9\uff0c\u540c\u65f6\u4fdd\u630134.3%\u5047\u9633\u6027\u7387\uff0c\u800c\u4ec5\u5224\u65ad\u57fa\u7ebf\u7684\u5047\u9633\u6027\u7387\u4e3a97.3%\u3002\u6d4b\u8bd5\u96c6\u7ed3\u679c\uff085000\u6837\u672c\uff09\u786e\u8ba4\u6cdb\u5316\u80fd\u529b\uff0c\u8fbe\u523081.44% F1\u548c75.08%\u51c6\u786e\u7387\u3002", "conclusion": "\u5206\u89e3\u7684\u667a\u80fd\u63a8\u7406\u4e0e\u7f51\u7edc\u68c0\u7d22\u53ef\u4ee5\u5728\u4e0d\u9700\u8981\u7279\u5b9a\u9886\u57df\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5339\u914d\u76d1\u7763\u68c0\u6d4b\u5668\u7684\u6027\u80fd\uff0c\u4f7f\u5f97\u5728\u6807\u8bb0\u6570\u636e\u7a00\u7f3a\u7684\u591a\u6a21\u6001\u573a\u666f\u4e2d\u4e5f\u80fd\u8fdb\u884c\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u3002"}}
{"id": "2510.17086", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17086", "abs": "https://arxiv.org/abs/2510.17086", "authors": ["Xueqian Bai", "Nicklas Hansen", "Adabhav Singh", "Michael T. Tolley", "Yan Duan", "Pieter Abbeel", "Xiaolong Wang", "Sha Yi"], "title": "Learning to Design Soft Hands using Reward Models", "comment": null, "summary": "Soft robotic hands promise to provide compliant and safe interaction with\nobjects and environments. However, designing soft hands to be both compliant\nand functional across diverse use cases remains challenging. Although co-design\nof hardware and control better couples morphology to behavior, the resulting\nsearch space is high-dimensional, and even simulation-based evaluation is\ncomputationally expensive. In this paper, we propose a Cross-Entropy Method\nwith Reward Model (CEM-RM) framework that efficiently optimizes tendon-driven\nsoft robotic hands based on teleoperation control policy, reducing design\nevaluations by more than half compared to pure optimization while learning a\ndistribution of optimized hand designs from pre-collected teleoperation data.\nWe derive a design space for a soft robotic hand composed of flexural soft\nfingers and implement parallelized training in simulation. The optimized hands\nare then 3D-printed and deployed in the real world using both teleoperation\ndata and real-time teleoperation. Experiments in both simulation and hardware\ndemonstrate that our optimized design significantly outperforms baseline hands\nin grasping success rates across a diverse set of challenging objects.", "AI": {"tldr": "\u63d0\u51faCEM-RM\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u9065\u64cd\u4f5c\u63a7\u5236\u7b56\u7565\u4f18\u5316\u808c\u8171\u9a71\u52a8\u8f6f\u4f53\u673a\u5668\u4eba\u624b\u8bbe\u8ba1\uff0c\u5c06\u8bbe\u8ba1\u8bc4\u4f30\u51cf\u5c11\u4e00\u534a\u4ee5\u4e0a\uff0c\u540c\u65f6\u4ece\u9884\u6536\u96c6\u7684\u9065\u64cd\u4f5c\u6570\u636e\u4e2d\u5b66\u4e60\u4f18\u5316\u624b\u8bbe\u8ba1\u5206\u5e03\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u624b\u867d\u7136\u80fd\u63d0\u4f9b\u67d4\u987a\u5b89\u5168\u7684\u4ea4\u4e92\uff0c\u4f46\u8bbe\u8ba1\u65e2\u67d4\u987a\u53c8\u529f\u80fd\u591a\u6837\u7684\u8f6f\u624b\u4ecd\u5177\u6311\u6218\u6027\u3002\u786c\u4ef6\u4e0e\u63a7\u5236\u534f\u540c\u8bbe\u8ba1\u867d\u80fd\u66f4\u597d\u8026\u5408\u5f62\u6001\u4e0e\u884c\u4e3a\uff0c\u4f46\u641c\u7d22\u7a7a\u95f4\u9ad8\u7ef4\u4e14\u4eff\u771f\u8bc4\u4f30\u8ba1\u7b97\u6602\u8d35\u3002", "method": "\u4f7f\u7528\u4ea4\u53c9\u71b5\u65b9\u6cd5\u4e0e\u5956\u52b1\u6a21\u578b(CEM-RM)\u6846\u67b6\uff0c\u57fa\u4e8e\u9065\u64cd\u4f5c\u63a7\u5236\u7b56\u7565\u4f18\u5316\u808c\u8171\u9a71\u52a8\u8f6f\u4f53\u673a\u5668\u4eba\u624b\u8bbe\u8ba1\u3002\u5b9e\u73b0\u5e76\u884c\u5316\u4eff\u771f\u8bad\u7ec3\uff0c\u4f18\u5316\u540e\u901a\u8fc73D\u6253\u5370\u90e8\u7f72\u5230\u73b0\u5b9e\u4e16\u754c\u3002", "result": "\u5728\u4eff\u771f\u548c\u786c\u4ef6\u5b9e\u9a8c\u4e2d\uff0c\u4f18\u5316\u8bbe\u8ba1\u5728\u6293\u53d6\u5404\u79cd\u6311\u6218\u6027\u7269\u4f53\u65f6\u7684\u6210\u529f\u7387\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u624b\u3002", "conclusion": "CEM-RM\u6846\u67b6\u80fd\u6709\u6548\u4f18\u5316\u8f6f\u4f53\u673a\u5668\u4eba\u624b\u8bbe\u8ba1\uff0c\u5927\u5e45\u51cf\u5c11\u8bbe\u8ba1\u8bc4\u4f30\u6b21\u6570\uff0c\u540c\u65f6\u4ece\u9065\u64cd\u4f5c\u6570\u636e\u4e2d\u5b66\u4e60\u4f18\u5316\u8bbe\u8ba1\u5206\u5e03\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.17111", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17111", "abs": "https://arxiv.org/abs/2510.17111", "authors": ["Weifan Guan", "Qinghao Hu", "Aosheng Li", "Jian Cheng"], "title": "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "comment": null, "summary": "Vision-Language-Action (VLA) models extend vision-language models to embodied\ncontrol by mapping natural-language instructions and visual observations to\nrobot actions. Despite their capabilities, VLA systems face significant\nchallenges due to their massive computational and memory demands, which\nconflict with the constraints of edge platforms such as on-board mobile\nmanipulators that require real-time performance. Addressing this tension has\nbecome a central focus of recent research. In light of the growing efforts\ntoward more efficient and scalable VLA systems, this survey provides a\nsystematic review of approaches for improving VLA efficiency, with an emphasis\non reducing latency, memory footprint, and training and inference costs. We\ncategorize existing solutions into four dimensions: model architecture,\nperception feature, action generation, and training/inference strategies,\nsummarizing representative techniques within each category. Finally, we discuss\nfuture trends and open challenges, highlighting directions for advancing\nefficient embodied intelligence.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c(VLA)\u6a21\u578b\u7684\u6548\u7387\u4f18\u5316\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u964d\u4f4e\u5ef6\u8fdf\u3001\u5185\u5b58\u5360\u7528\u548c\u8bad\u7ec3/\u63a8\u7406\u6210\u672c\uff0c\u5c06\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5206\u4e3a\u56db\u4e2a\u7ef4\u5ea6\uff1a\u6a21\u578b\u67b6\u6784\u3001\u611f\u77e5\u7279\u5f81\u3001\u52a8\u4f5c\u751f\u6210\u548c\u8bad\u7ec3/\u63a8\u7406\u7b56\u7565\u3002", "motivation": "VLA\u6a21\u578b\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u9762\u4e34\u5de8\u5927\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\uff0c\u4e0e\u8fb9\u7f18\u5e73\u53f0\uff08\u5982\u9700\u8981\u5b9e\u65f6\u6027\u80fd\u7684\u79fb\u52a8\u673a\u68b0\u81c2\uff09\u7684\u7ea6\u675f\u76f8\u51b2\u7a81\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u9ad8VLA\u7cfb\u7edf\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5c06\u73b0\u6709VLA\u6548\u7387\u4f18\u5316\u65b9\u6cd5\u5206\u7c7b\u4e3a\u56db\u4e2a\u7ef4\u5ea6\uff1a\u6a21\u578b\u67b6\u6784\u4f18\u5316\u3001\u611f\u77e5\u7279\u5f81\u5904\u7406\u3001\u52a8\u4f5c\u751f\u6210\u673a\u5236\u3001\u8bad\u7ec3\u548c\u63a8\u7406\u7b56\u7565\uff0c\u5e76\u603b\u7ed3\u6bcf\u4e2a\u7c7b\u522b\u4e2d\u7684\u4ee3\u8868\u6027\u6280\u672f\u3002", "result": "\u63d0\u4f9b\u4e86VLA\u6548\u7387\u4f18\u5316\u65b9\u6cd5\u7684\u5168\u9762\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5404\u7ef4\u5ea6\u7684\u5173\u952e\u6280\u672f\uff0c\u4e3a\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u5177\u8eab\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u672a\u6765\u8d8b\u52bf\u548c\u5f00\u653e\u6311\u6218\uff0c\u5f3a\u8c03\u4e86\u63a8\u8fdb\u9ad8\u6548\u5177\u8eab\u667a\u80fd\u7684\u53d1\u5c55\u65b9\u5411\uff0c\u4e3aVLA\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2510.17143", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17143", "abs": "https://arxiv.org/abs/2510.17143", "authors": ["Shantnav Agarwal", "Javier Alonso-Mora", "Sihao Sun"], "title": "Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation via Imitation Learning", "comment": "Accepted by IEEE MRS 2025", "summary": "Existing approaches for transporting and manipulating cable-suspended loads\nusing multiple UAVs along reference trajectories typically rely on either\ncentralized control architectures or reliable inter-agent communication. In\nthis work, we propose a novel machine learning based method for decentralized\nkinodynamic planning that operates effectively under partial observability and\nwithout inter-agent communication. Our method leverages imitation learning to\ntrain a decentralized student policy for each UAV by imitating a centralized\nkinodynamic motion planner with access to privileged global observations. The\nstudent policy generates smooth trajectories using physics-informed neural\nnetworks that respect the derivative relationships in motion. During training,\nthe student policies utilize the full trajectory generated by the teacher\npolicy, leading to improved sample efficiency. Moreover, each student policy\ncan be trained in under two hours on a standard laptop. We validate our method\nin both simulation and real-world environments to follow an agile reference\ntrajectory, demonstrating performance comparable to that of centralized\napproaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u53bb\u4e2d\u5fc3\u5316\u52a8\u529b\u5b66\u89c4\u5212\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u65e0\u4eba\u673a\u534f\u540c\u8fd0\u8f93\u7f06\u7ef3\u60ac\u6302\u8d1f\u8f7d\uff0c\u65e0\u9700\u4ee3\u7406\u95f4\u901a\u4fe1\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u6709\u6548\u5de5\u4f5c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u96c6\u4e2d\u63a7\u5236\u67b6\u6784\u6216\u53ef\u9760\u7684\u4ee3\u7406\u95f4\u901a\u4fe1\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u4e14\u65e0\u901a\u4fe1\u6761\u4ef6\u4e0b\u7684\u53bb\u4e2d\u5fc3\u5316\u89c4\u5212\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6a21\u4eff\u5b66\u4e60\u8bad\u7ec3\u53bb\u4e2d\u5fc3\u5316\u5b66\u751f\u7b56\u7565\uff0c\u6a21\u4eff\u5177\u6709\u5168\u5c40\u89c2\u6d4b\u6743\u9650\u7684\u96c6\u4e2d\u5f0f\u52a8\u529b\u5b66\u8fd0\u52a8\u89c4\u5212\u5668\u3002\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u751f\u6210\u5e73\u6ed1\u8f68\u8ff9\uff0c\u8bad\u7ec3\u65f6\u5229\u7528\u6559\u5e08\u7b56\u7565\u7684\u5b8c\u6574\u8f68\u8ff9\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "result": "\u5b66\u751f\u7b56\u7565\u53ef\u5728\u6807\u51c6\u7b14\u8bb0\u672c\u7535\u8111\u4e0a2\u5c0f\u65f6\u5185\u5b8c\u6210\u8bad\u7ec3\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u8ddf\u968f\u654f\u6377\u53c2\u8003\u8f68\u8ff9\u7684\u80fd\u529b\uff0c\u6027\u80fd\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u65e0\u9700\u901a\u4fe1\u7684\u53bb\u4e2d\u5fc3\u5316\u52a8\u529b\u5b66\u89c4\u5212\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u591a\u65e0\u4eba\u673a\u534f\u540c\u8d1f\u8f7d\u8fd0\u8f93\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17148", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17148", "abs": "https://arxiv.org/abs/2510.17148", "authors": ["Yu Gao", "Yiru Wang", "Anqing Jiang", "Heng Yuwen", "Wang Shuo", "Sun Hao", "Wang Jijun"], "title": "DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment", "comment": null, "summary": "Conventional end-to-end (E2E) driving models are effective at generating\nphysically plausible trajectories, but often fail to generalize to long-tail\nscenarios due to the lack of essential world knowledge to understand and reason\nabout surrounding environments. In contrast, Vision-Language-Action (VLA)\nmodels leverage world knowledge to handle challenging cases, but their limited\n3D reasoning capability can lead to physically infeasible actions. In this work\nwe introduce DiffVLA++, an enhanced autonomous driving framework that\nexplicitly bridges cognitive reasoning and E2E planning through metric-guided\nalignment. First, we build a VLA module directly generating semantically\ngrounded driving trajectories. Second, we design an E2E module with a dense\ntrajectory vocabulary that ensures physical feasibility. Third, and most\ncritically, we introduce a metric-guided trajectory scorer that guides and\naligns the outputs of the VLA and E2E modules, thereby integrating their\ncomplementary strengths. The experiment on the ICCV 2025 Autonomous Grand\nChallenge leaderboard shows that DiffVLA++ achieves EPDMS of 49.12.", "AI": {"tldr": "DiffVLA++\u662f\u4e00\u4e2a\u589e\u5f3a\u7684\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\uff0c\u901a\u8fc7\u5ea6\u91cf\u5f15\u5bfc\u7684\u5bf9\u9f50\u663e\u5f0f\u6865\u63a5\u8ba4\u77e5\u63a8\u7406\u548c\u7aef\u5230\u7aef\u89c4\u5212\uff0c\u7ed3\u5408VLA\u6a21\u578b\u7684\u4e16\u754c\u77e5\u8bc6\u548cE2E\u6a21\u578b\u7684\u7269\u7406\u53ef\u884c\u6027\u3002", "motivation": "\u4f20\u7edf\u7aef\u5230\u7aef\u9a7e\u9a76\u6a21\u578b\u80fd\u751f\u6210\u7269\u7406\u53ef\u884c\u7684\u8f68\u8ff9\u4f46\u7f3a\u4e4f\u4e16\u754c\u77e5\u8bc6\u5904\u7406\u957f\u5c3e\u573a\u666f\uff0c\u800c\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u6709\u4e16\u754c\u77e5\u8bc6\u4f463D\u63a8\u7406\u80fd\u529b\u6709\u9650\u5bfc\u81f4\u7269\u7406\u4e0d\u53ef\u884c\u52a8\u4f5c\u3002", "method": "\u6784\u5efaVLA\u6a21\u5757\u751f\u6210\u8bed\u4e49\u57fa\u7840\u7684\u9a7e\u9a76\u8f68\u8ff9\uff0c\u8bbe\u8ba1E2E\u6a21\u5757\u786e\u4fdd\u7269\u7406\u53ef\u884c\u6027\uff0c\u5f15\u5165\u5ea6\u91cf\u5f15\u5bfc\u7684\u8f68\u8ff9\u8bc4\u5206\u5668\u5bf9\u9f50\u4e24\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\u3002", "result": "\u5728ICCV 2025\u81ea\u52a8\u9a7e\u9a76\u6311\u6218\u8d5b\u6392\u884c\u699c\u4e0a\u8fbe\u5230EPDMS 49.12\u3002", "conclusion": "DiffVLA++\u6210\u529f\u6574\u5408\u4e86\u8ba4\u77e5\u63a8\u7406\u548c\u7aef\u5230\u7aef\u89c4\u5212\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u5ea6\u91cf\u5f15\u5bfc\u5bf9\u9f50\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u81ea\u52a8\u9a7e\u9a76\u6027\u80fd\u3002"}}
{"id": "2510.17150", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17150", "abs": "https://arxiv.org/abs/2510.17150", "authors": ["Heng Zhang", "Wei-Hsing Huang", "Gokhan Solak", "Arash Ajoudani"], "title": "OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation", "comment": "Code, video and RAG dataset are available at\n  \\url{https://sites.google.com/view/omni-vic}", "summary": "We present OmniVIC, a universal variable impedance controller (VIC) enhanced\nby a vision language model (VLM), which improves safety and adaptation in any\ncontact-rich robotic manipulation task to enhance safe physical interaction.\nTraditional VIC have shown advantages when the robot physically interacts with\nthe environment, but lack generalization in unseen, complex, and unstructured\nsafe interactions in universal task scenarios involving contact or uncertainty.\nTo this end, the proposed OmniVIC interprets task context derived reasoning\nfrom images and natural language and generates adaptive impedance parameters\nfor a VIC controller. Specifically, the core of OmniVIC is a self-improving\nRetrieval-Augmented Generation(RAG) and in-context learning (ICL), where RAG\nretrieves relevant prior experiences from a structured memory bank to inform\nthe controller about similar past tasks, and ICL leverages these retrieved\nexamples and the prompt of current task to query the VLM for generating\ncontext-aware and adaptive impedance parameters for the current manipulation\nscenario. Therefore, a self-improved RAG and ICL guarantee OmniVIC works in\nuniversal task scenarios. The impedance parameter regulation is further\ninformed by real-time force/torque feedback to ensure interaction forces remain\nwithin safe thresholds. We demonstrate that our method outperforms baselines on\na suite of complex contact-rich tasks, both in simulation and on real-world\nrobotic tasks, with improved success rates and reduced force violations.\nOmniVIC takes a step towards bridging high-level semantic reasoning and\nlow-level compliant control, enabling safer and more generalizable\nmanipulation. Overall, the average success rate increases from 27% (baseline)\nto 61.4% (OmniVIC).", "AI": {"tldr": "OmniVIC\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u53ef\u53d8\u963b\u6297\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u81ea\u6539\u8fdb\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u4ece\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u4e2d\u7406\u89e3\u4efb\u52a1\u4e0a\u4e0b\u6587\uff0c\u751f\u6210\u81ea\u9002\u5e94\u963b\u6297\u53c2\u6570\uff0c\u63d0\u9ad8\u63a5\u89e6\u4e30\u5bcc\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u7684\u5b89\u5168\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u53ef\u53d8\u963b\u6297\u63a7\u5236\u5668\u5728\u673a\u5668\u4eba\u7269\u7406\u4ea4\u4e92\u4e2d\u867d\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u672a\u77e5\u3001\u590d\u6742\u3001\u975e\u7ed3\u6784\u5316\u5b89\u5168\u4ea4\u4e92\u573a\u666f\u4e2d\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u6cd5\u9002\u5e94\u6d89\u53ca\u63a5\u89e6\u6216\u4e0d\u786e\u5b9a\u6027\u7684\u901a\u7528\u4efb\u52a1\u573a\u666f\u3002", "method": "\u91c7\u7528\u81ea\u6539\u8fdb\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60(ICL)\uff0cRAG\u4ece\u7ed3\u6784\u5316\u8bb0\u5fc6\u5e93\u68c0\u7d22\u76f8\u5173\u5148\u9a8c\u7ecf\u9a8c\uff0cICL\u5229\u7528\u68c0\u7d22\u793a\u4f8b\u548c\u5f53\u524d\u4efb\u52a1\u63d0\u793a\u67e5\u8be2VLM\uff0c\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u81ea\u9002\u5e94\u963b\u6297\u53c2\u6570\uff0c\u5e76\u7ed3\u5408\u5b9e\u65f6\u529b/\u529b\u77e9\u53cd\u9988\u786e\u4fdd\u4ea4\u4e92\u529b\u5728\u5b89\u5168\u9608\u503c\u5185\u3002", "result": "\u5728\u590d\u6742\u63a5\u89e6\u4e30\u5bcc\u4efb\u52a1\u5957\u4ef6\u4e2d\uff0cOmniVIC\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u6210\u529f\u7387\u4ece27%(\u57fa\u7ebf)\u63d0\u5347\u81f361.4%(OmniVIC)\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u529b\u8fdd\u89c4\u3002", "conclusion": "OmniVIC\u5728\u9ad8\u5c42\u8bed\u4e49\u63a8\u7406\u548c\u4f4e\u5c42\u987a\u5e94\u63a7\u5236\u4e4b\u95f4\u67b6\u8d77\u6865\u6881\uff0c\u5b9e\u73b0\u4e86\u66f4\u5b89\u5168\u3001\u66f4\u5177\u6cdb\u5316\u80fd\u529b\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u3002"}}
{"id": "2510.17191", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17191", "abs": "https://arxiv.org/abs/2510.17191", "authors": ["Peiru Zheng", "Yun Zhao", "Zhan Gong", "Hong Zhu", "Shaohua Wu"], "title": "SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving", "comment": "6 pages, 2 figures, 2 tables", "summary": "End-to-end autonomous driving has emerged as a promising paradigm for\nachieving robust and intelligent driving policies. However, existing end-to-end\nmethods still face significant challenges, such as suboptimal decision-making\nin complex scenarios. In this paper,we propose SimpleVSF (Simple VLM-Scoring\nFusion), a novel framework that enhances end-to-end planning by leveraging the\ncognitive capabilities of Vision-Language Models (VLMs) and advanced trajectory\nfusion techniques. We utilize the conventional scorers and the novel\nVLM-enhanced scorers. And we leverage a robust weight fusioner for quantitative\naggregation and a powerful VLM-based fusioner for qualitative, context-aware\ndecision-making. As the leading approach in the ICCV 2025 NAVSIM v2 End-to-End\nDriving Challenge, our SimpleVSF framework demonstrates state-of-the-art\nperformance, achieving a superior balance between safety, comfort, and\nefficiency.", "AI": {"tldr": "\u63d0\u51faSimpleVSF\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408VLM\u8ba4\u77e5\u80fd\u529b\u548c\u8f68\u8ff9\u878d\u5408\u6280\u672f\u6765\u589e\u5f3a\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\uff0c\u5728ICCV 2025 NAVSIM v2\u6311\u6218\u8d5b\u4e2d\u53d6\u5f97\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u65b9\u6cd5\u5728\u590d\u6742\u573a\u666f\u4e2d\u51b3\u7b56\u4ecd\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u63d0\u5347\u51b3\u7b56\u8d28\u91cf\u3002", "method": "\u7ed3\u5408\u4f20\u7edf\u8bc4\u5206\u5668\u548cVLM\u589e\u5f3a\u8bc4\u5206\u5668\uff0c\u4f7f\u7528\u6743\u91cd\u878d\u5408\u5668\u8fdb\u884c\u5b9a\u91cf\u805a\u5408\u548cVLM\u878d\u5408\u5668\u8fdb\u884c\u5b9a\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u51b3\u7b56\u3002", "result": "\u5728ICCV 2025 NAVSIM v2\u7aef\u5230\u7aef\u9a7e\u9a76\u6311\u6218\u8d5b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u5b89\u5168\u6027\u3001\u8212\u9002\u6027\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4f18\u8d8a\u5e73\u8861\u3002", "conclusion": "SimpleVSF\u6846\u67b6\u901a\u8fc7\u878d\u5408VLM\u8ba4\u77e5\u80fd\u529b\u6709\u6548\u63d0\u5347\u4e86\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7684\u89c4\u5212\u6027\u80fd\u3002"}}
{"id": "2510.17203", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17203", "abs": "https://arxiv.org/abs/2510.17203", "authors": ["Ryota Soga", "Masataka Kobayashi", "Tsukasa Shimizu", "Shintaro Shiba", "Quan Kong", "Shan Lu", "Takaya Yamazato"], "title": "Performance Evaluation of an Integrated System for Visible Light Communication and Positioning Using an Event Camera", "comment": "7pages, APCC2025", "summary": "Event cameras, featuring high temporal resolution and high dynamic range,\noffer visual sensing capabilities comparable to conventional image sensors\nwhile capturing fast-moving objects and handling scenes with extreme lighting\ncontrasts such as tunnel exits. Leveraging these properties, this study\nproposes a novel self-localization system that integrates visible light\ncommunication (VLC) and visible light positioning (VLP) within a single event\ncamera. The system enables a vehicle to estimate its position even in\nGPS-denied environments, such as tunnels, by using VLC to obtain coordinate\ninformation from LED transmitters and VLP to estimate the distance to each\ntransmitter.\n  Multiple LEDs are installed on the transmitter side, each assigned a unique\npilot sequence based on Walsh-Hadamard codes. The event camera identifies\nindividual LEDs within its field of view by correlating the received signal\nwith these codes, allowing clear separation and recognition of each light\nsource. This mechanism enables simultaneous high-capacity MISO (multi-input\nsingle-output) communication through VLC and precise distance estimation via\nphase-only correlation (POC) between multiple LED pairs.\n  To the best of our knowledge, this is the first vehicle-mounted system to\nachieve simultaneous VLC and VLP functionalities using a single event camera.\nField experiments were conducted by mounting the system on a vehicle traveling\nat 30 km/h (8.3 m/s). The results demonstrated robust real-world performance,\nwith a root mean square error (RMSE) of distance estimation within 0.75 m for\nranges up to 100 m and a bit error rate (BER) below 0.01 across the same range.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u76f8\u673a\u7684\u65b0\u578b\u81ea\u5b9a\u4f4d\u7cfb\u7edf\uff0c\u5c06\u53ef\u89c1\u5149\u901a\u4fe1(VLC)\u548c\u53ef\u89c1\u5149\u5b9a\u4f4d(VLP)\u96c6\u6210\u5728\u5355\u4e2a\u4e8b\u4ef6\u76f8\u673a\u4e2d\uff0c\u7528\u4e8eGPS\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8f66\u8f86\u5b9a\u4f4d\u3002", "motivation": "\u4e8b\u4ef6\u76f8\u673a\u5177\u6709\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\u548c\u9ad8\u52a8\u6001\u8303\u56f4\uff0c\u80fd\u6355\u6349\u5feb\u901f\u79fb\u52a8\u7269\u4f53\u548c\u5904\u7406\u6781\u7aef\u5149\u7167\u573a\u666f\uff0c\u9002\u5408\u5728\u96a7\u9053\u7b49GPS\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u9760\u7684\u8f66\u8f86\u5b9a\u4f4d\u3002", "method": "\u4f7f\u7528Walsh-Hadamard\u7801\u4e3a\u591a\u4e2aLED\u5206\u914d\u72ec\u7279\u7684\u5bfc\u9891\u5e8f\u5217\uff0c\u901a\u8fc7\u4e8b\u4ef6\u76f8\u673a\u8bc6\u522b\u5355\u4e2aLED\uff0c\u5229\u7528\u76f8\u4f4d\u76f8\u5173(POC)\u8fdb\u884c\u8ddd\u79bb\u4f30\u8ba1\uff0c\u5b9e\u73b0\u540c\u65f6\u7684VLC\u548cVLP\u529f\u80fd\u3002", "result": "\u572830km/h\u8f66\u901f\u4e0b\u8fdb\u884c\u73b0\u573a\u5b9e\u9a8c\uff0c\u8ddd\u79bb\u4f30\u8ba1\u7684\u5747\u65b9\u6839\u8bef\u5dee\u5728100\u7c73\u8303\u56f4\u5185\u5c0f\u4e8e0.75\u7c73\uff0c\u8bef\u7801\u7387\u4f4e\u4e8e0.01\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4f7f\u7528\u5355\u4e2a\u4e8b\u4ef6\u76f8\u673a\u5b9e\u73b0\u540c\u65f6VLC\u548cVLP\u529f\u80fd\u7684\u8f66\u8f86\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u9c81\u68d2\u6027\u80fd\u3002"}}
{"id": "2510.17237", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17237", "abs": "https://arxiv.org/abs/2510.17237", "authors": ["Wuhao Xie", "Kanji Tanaka"], "title": "Pole-Image: A Self-Supervised Pole-Anchored Descriptor for Long-Term LiDAR Localization and Map Maintenance", "comment": "4 pages, technical report", "summary": "Long-term autonomy for mobile robots requires both robust self-localization\nand reliable map maintenance. Conventional landmark-based methods face a\nfundamental trade-off between landmarks with high detectability but low\ndistinctiveness (e.g., poles) and those with high distinctiveness but difficult\nstable detection (e.g., local point cloud structures). This work addresses the\nchallenge of descriptively identifying a unique \"signature\" (local point cloud)\nby leveraging a detectable, high-precision \"anchor\" (like a pole). To solve\nthis, we propose a novel canonical representation, \"Pole-Image,\" as a hybrid\nmethod that uses poles as anchors to generate signatures from the surrounding\n3D structure. Pole-Image represents a pole-like landmark and its surrounding\nenvironment, detected from a LiDAR point cloud, as a 2D polar coordinate image\nwith the pole itself as the origin. This representation leverages the pole's\nnature as a high-precision reference point, explicitly encoding the \"relative\ngeometry\" between the stable pole and the variable surrounding point cloud. The\nkey advantage of pole landmarks is that \"detection\" is extremely easy. This\nease of detection allows the robot to easily track the same pole, enabling the\nautomatic and large-scale collection of diverse observational data (positive\npairs). This data acquisition feasibility makes \"Contrastive Learning (CL)\"\napplicable. By applying CL, the model learns a viewpoint-invariant and highly\ndiscriminative descriptor. The contributions are twofold: 1) The descriptor\novercomes perceptual aliasing, enabling robust self-localization. 2) The\nhigh-precision encoding enables high-sensitivity change detection, contributing\nto map maintenance.", "AI": {"tldr": "\u63d0\u51faPole-Image\u8868\u793a\u65b9\u6cd5\uff0c\u5229\u7528\u6746\u72b6\u5730\u6807\u4f5c\u4e3a\u951a\u70b9\u751f\u6210\u5468\u56f43D\u7ed3\u6784\u7684\u7b7e\u540d\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u83b7\u5f97\u89c6\u89d2\u4e0d\u53d8\u4e14\u9ad8\u533a\u5206\u5ea6\u7684\u63cf\u8ff0\u7b26\uff0c\u5b9e\u73b0\u9c81\u68d2\u7684\u81ea\u5b9a\u4f4d\u548c\u5730\u56fe\u7ef4\u62a4\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8\u673a\u5668\u4eba\u957f\u671f\u81ea\u4e3b\u6027\u4e2d\u81ea\u5b9a\u4f4d\u548c\u5730\u56fe\u7ef4\u62a4\u7684\u6311\u6218\uff0c\u4f20\u7edf\u5730\u6807\u65b9\u6cd5\u5728\u53ef\u68c0\u6d4b\u6027\u548c\u72ec\u7279\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u7a33\u5b9a\u68c0\u6d4b\u53c8\u5177\u6709\u9ad8\u533a\u5206\u5ea6\u7684\u5730\u6807\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPole-Image\u8868\u793a\u6cd5\uff0c\u5c06\u6746\u72b6\u5730\u6807\u53ca\u5176\u5468\u56f4\u73af\u5883\u8868\u793a\u4e3a\u4ee5\u6746\u4e3a\u539f\u70b9\u76842D\u6781\u5750\u6807\u56fe\u50cf\uff0c\u5229\u7528\u6746\u4f5c\u4e3a\u9ad8\u7cbe\u5ea6\u53c2\u8003\u70b9\uff0c\u7f16\u7801\u6746\u4e0e\u5468\u56f4\u70b9\u4e91\u7684\u76f8\u5bf9\u51e0\u4f55\u5173\u7cfb\uff0c\u5e76\u5e94\u7528\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u89c6\u89d2\u4e0d\u53d8\u7684\u63cf\u8ff0\u7b26\u3002", "result": "\u8be5\u65b9\u6cd5\u514b\u670d\u4e86\u611f\u77e5\u6df7\u6dc6\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u81ea\u5b9a\u4f4d\uff0c\u540c\u65f6\u9ad8\u7cbe\u5ea6\u7f16\u7801\u5b9e\u73b0\u4e86\u9ad8\u7075\u654f\u5ea6\u7684\u53d8\u5316\u68c0\u6d4b\uff0c\u6709\u52a9\u4e8e\u5730\u56fe\u7ef4\u62a4\u3002", "conclusion": "Pole-Image\u4f5c\u4e3a\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u5730\u6807\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ed3\u5408\u6746\u72b6\u5730\u6807\u7684\u6613\u68c0\u6d4b\u6027\u548c\u5bf9\u6bd4\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u4e3a\u957f\u671f\u81ea\u4e3b\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17249", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17249", "abs": "https://arxiv.org/abs/2510.17249", "authors": ["Franek Stark", "Rohit Kumar", "Shubham Vyas", "Hannah Isermann", "Jonas Haack", "Mihaela Popescu", "Jakob Middelberg", "Dennis Mronga", "Frank Kirchner"], "title": "An adaptive hierarchical control framework for quadrupedal robots in planetary exploration", "comment": "Presented at 18th Symposium on Advanced Space Technologies in\n  Robotics and Automation (ASTRA)", "summary": "Planetary exploration missions require robots capable of navigating extreme\nand unknown environments. While wheeled rovers have dominated past missions,\ntheir mobility is limited to traversable surfaces. Legged robots, especially\nquadrupeds, can overcome these limitations by handling uneven, obstacle-rich,\nand deformable terrains. However, deploying such robots in unknown conditions\nis challenging due to the need for environment-specific control, which is\ninfeasible when terrain and robot parameters are uncertain. This work presents\na modular control framework that combines model-based dynamic control with\nonline model adaptation and adaptive footstep planning to address uncertainties\nin both robot and terrain properties. The framework includes state estimation\nfor quadrupeds with and without contact sensing, supports runtime\nreconfiguration, and is integrated into ROS 2 with open-source availability.\nIts performance was validated on two quadruped platforms, multiple hardware\narchitectures, and in a volcano field test, where the robot walked over 700 m.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u578b\u52a8\u6001\u63a7\u5236\u3001\u5728\u7ebf\u6a21\u578b\u81ea\u9002\u5e94\u548c\u81ea\u9002\u5e94\u811a\u6b65\u89c4\u5212\uff0c\u89e3\u51b3\u673a\u5668\u4eba\u548c\u5730\u5f62\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u706b\u5c71\u5b9e\u5730\u6d4b\u8bd5\u4e2d\u884c\u8d70\u8d85\u8fc7700\u7c73\u3002", "motivation": "\u884c\u661f\u63a2\u6d4b\u4efb\u52a1\u9700\u8981\u80fd\u5728\u6781\u7aef\u672a\u77e5\u73af\u5883\u4e2d\u5bfc\u822a\u7684\u673a\u5668\u4eba\u3002\u817f\u5f0f\u673a\u5668\u4eba\u80fd\u514b\u670d\u8f6e\u5f0f\u673a\u5668\u4eba\u7684\u79fb\u52a8\u9650\u5236\uff0c\u4f46\u5728\u672a\u77e5\u6761\u4ef6\u4e0b\u90e8\u7f72\u9762\u4e34\u73af\u5883\u7279\u5b9a\u63a7\u5236\u7684\u6311\u6218\u3002", "method": "\u6a21\u5757\u5316\u63a7\u5236\u6846\u67b6\u7ed3\u5408\u6a21\u578b\u52a8\u6001\u63a7\u5236\u3001\u5728\u7ebf\u6a21\u578b\u81ea\u9002\u5e94\u548c\u81ea\u9002\u5e94\u811a\u6b65\u89c4\u5212\uff0c\u5305\u542b\u72b6\u6001\u4f30\u8ba1\u529f\u80fd\uff0c\u652f\u6301\u8fd0\u884c\u65f6\u91cd\u65b0\u914d\u7f6e\uff0c\u5e76\u96c6\u6210\u5230ROS 2\u4e2d\u3002", "result": "\u5728\u4e24\u4e2a\u56db\u8db3\u673a\u5668\u4eba\u5e73\u53f0\u3001\u591a\u79cd\u786c\u4ef6\u67b6\u6784\u4e0a\u9a8c\u8bc1\u6027\u80fd\uff0c\u5728\u706b\u5c71\u5b9e\u5730\u6d4b\u8bd5\u4e2d\u673a\u5668\u4eba\u884c\u8d70\u8d85\u8fc7700\u7c73\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u673a\u5668\u4eba\u548c\u5730\u5f62\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u817f\u5f0f\u673a\u5668\u4eba\u5728\u6781\u7aef\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17261", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17261", "abs": "https://arxiv.org/abs/2510.17261", "authors": ["Fernando Salanova", "Jes\u00fas Roche", "Cristian Mahuela", "Eduardo Montijano"], "title": "High-Level Multi-Robot Trajectory Planning And Spurious Behavior Detection", "comment": "6 pages,3 figures, Iberian Robotics Conference 2025", "summary": "The reliable execution of high-level missions in multi-robot systems with\nheterogeneous agents, requires robust methods for detecting spurious behaviors.\nIn this paper, we address the challenge of identifying spurious executions of\nplans specified as a Linear Temporal Logic (LTL) formula, as incorrect task\nsequences, violations of spatial constraints, timing inconsis- tencies, or\ndeviations from intended mission semantics. To tackle this, we introduce a\nstructured data generation framework based on the Nets-within-Nets (NWN)\nparadigm, which coordinates robot actions with LTL-derived global mission\nspecifications. We further propose a Transformer-based anomaly detection\npipeline that classifies robot trajectories as normal or anomalous. Experi-\nmental evaluations show that our method achieves high accuracy (91.3%) in\nidentifying execution inefficiencies, and demonstrates robust detection\ncapabilities for core mission violations (88.3%) and constraint-based adaptive\nanomalies (66.8%). An ablation experiment of the embedding and architecture was\ncarried out, obtaining successful results where our novel proposition performs\nbetter than simpler representations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eNets-within-Nets\u8303\u5f0f\u7684\u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u6846\u67b6\u548cTransformer\u5f02\u5e38\u68c0\u6d4b\u7ba1\u9053\uff0c\u7528\u4e8e\u8bc6\u522b\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u4e2dLTL\u89c4\u8303\u4e0b\u7684\u5f02\u5e38\u6267\u884c\u884c\u4e3a\u3002", "motivation": "\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u5f02\u6784\u667a\u80fd\u4f53\u7684\u9ad8\u5c42\u4efb\u52a1\u53ef\u9760\u6267\u884c\u9700\u8981\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u9519\u8bef\u4efb\u52a1\u5e8f\u5217\u3001\u7a7a\u95f4\u7ea6\u675f\u8fdd\u53cd\u3001\u65f6\u95f4\u4e0d\u4e00\u81f4\u6027\u548c\u4efb\u52a1\u8bed\u4e49\u504f\u5dee\u3002", "method": "\u4f7f\u7528Nets-within-Nets\u8303\u5f0f\u534f\u8c03\u673a\u5668\u4eba\u52a8\u4f5c\u4e0eLTL\u5168\u5c40\u4efb\u52a1\u89c4\u8303\uff0c\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u5f02\u5e38\u68c0\u6d4b\u7ba1\u9053\u5bf9\u673a\u5668\u4eba\u8f68\u8ff9\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u6267\u884c\u6548\u7387\u5f02\u5e38\u68c0\u6d4b\u4e0a\u8fbe\u523091.3%\u51c6\u786e\u7387\uff0c\u6838\u5fc3\u4efb\u52a1\u8fdd\u53cd\u68c0\u6d4b88.3%\uff0c\u57fa\u4e8e\u7ea6\u675f\u7684\u81ea\u9002\u5e94\u5f02\u5e38\u68c0\u6d4b66.8%\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u65b0\u65b9\u6cd5\u4f18\u4e8e\u7b80\u5355\u8868\u793a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u6267\u884c\u884c\u4e3a\uff0c\u4e3a\u53ef\u9760\u4efb\u52a1\u6267\u884c\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17315", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17315", "abs": "https://arxiv.org/abs/2510.17315", "authors": ["Po-Chen Ko", "Jiayuan Mao", "Yu-Hsiang Fu", "Hsien-Jeng Yeh", "Chu-Rong Chen", "Wei-Chiu Ma", "Yilun Du", "Shao-Hua Sun"], "title": "Implicit State Estimation via Video Replanning", "comment": null, "summary": "Video-based representations have gained prominence in planning and\ndecision-making due to their ability to encode rich spatiotemporal dynamics and\ngeometric relationships. These representations enable flexible and\ngeneralizable solutions for complex tasks such as object manipulation and\nnavigation. However, existing video planning frameworks often struggle to adapt\nto failures at interaction time due to their inability to reason about\nuncertainties in partially observed environments. To overcome these\nlimitations, we introduce a novel framework that integrates interaction-time\ndata into the planning process. Our approach updates model parameters online\nand filters out previously failed plans during generation. This enables\nimplicit state estimation, allowing the system to adapt dynamically without\nexplicitly modeling unknown state variables. We evaluate our framework through\nextensive experiments on a new simulated manipulation benchmark, demonstrating\nits ability to improve replanning performance and advance the field of\nvideo-based decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u9891\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ebf\u66f4\u65b0\u6a21\u578b\u53c2\u6570\u548c\u8fc7\u6ee4\u5931\u8d25\u8ba1\u5212\u6765\u9002\u5e94\u4ea4\u4e92\u65f6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u9690\u5f0f\u72b6\u6001\u4f30\u8ba1\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u89c4\u5212\u6846\u67b6\u96be\u4ee5\u9002\u5e94\u4ea4\u4e92\u65f6\u7684\u5931\u8d25\uff0c\u56e0\u4e3a\u65e0\u6cd5\u5728\u90e8\u5206\u89c2\u5bdf\u73af\u5883\u4e2d\u5bf9\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u63a8\u7406\u3002", "method": "\u96c6\u6210\u4ea4\u4e92\u65f6\u6570\u636e\u5230\u89c4\u5212\u8fc7\u7a0b\uff0c\u5728\u7ebf\u66f4\u65b0\u6a21\u578b\u53c2\u6570\uff0c\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u8fc7\u6ee4\u5148\u524d\u5931\u8d25\u7684\u8ba1\u5212\u3002", "result": "\u5728\u65b0\u6a21\u62df\u64cd\u4f5c\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u91cd\u65b0\u89c4\u5212\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u63a8\u8fdb\u4e86\u57fa\u4e8e\u89c6\u9891\u7684\u51b3\u7b56\u5236\u5b9a\u9886\u57df\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u800c\u4e0d\u9700\u8981\u663e\u5f0f\u5efa\u6a21\u672a\u77e5\u72b6\u6001\u53d8\u91cf\u3002"}}
{"id": "2510.17335", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17335", "abs": "https://arxiv.org/abs/2510.17335", "authors": ["Xintong Yang", "Minglun Wei", "Ze Ji", "Yu-Kun Lai"], "title": "DDBot: Differentiable Physics-based Digging Robot for Unknown Granular Materials", "comment": "Accepted as a regular paper by the IEEE Transactions on Robotics", "summary": "Automating the manipulation of granular materials poses significant\nchallenges due to complex contact dynamics, unpredictable material properties,\nand intricate system states. Existing approaches often fail to achieve\nefficiency and accuracy in such tasks. To fill the research gap, this paper\nstudies the small-scale and high-precision granular material digging task with\nunknown physical properties. A new framework, named differentiable digging\nrobot (DDBot), is proposed to manipulate granular materials, including sand and\nsoil.\n  Specifically, we equip DDBot with a differentiable physics-based simulator,\ntailored for granular material manipulation, powered by GPU-accelerated\nparallel computing and automatic differentiation. DDBot can perform efficient\ndifferentiable system identification and high-precision digging skill\noptimisation for unknown granular materials, which is enabled by a\ndifferentiable skill-to-action mapping, a task-oriented demonstration method,\ngradient clipping and line search-based gradient descent.\n  Experimental results show that DDBot can efficiently (converge within 5 to 20\nminutes) identify unknown granular material dynamics and optimise digging\nskills, with high-precision results in zero-shot real-world deployments,\nhighlighting its practicality. Benchmark results against state-of-the-art\nbaselines also confirm the robustness and efficiency of DDBot in such digging\ntasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86DDBot\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u64cd\u63a7\u9897\u7c92\u6750\u6599\uff08\u5982\u6c99\u571f\uff09\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u7269\u7406\u6a21\u62df\u5668\u5b9e\u73b0\u9ad8\u6548\u7cfb\u7edf\u8bc6\u522b\u548c\u6316\u6398\u6280\u80fd\u4f18\u5316\uff0c\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u96f6\u6837\u672c\u90e8\u7f72\u3002", "motivation": "\u89e3\u51b3\u9897\u7c92\u6750\u6599\u64cd\u63a7\u4e2d\u7684\u590d\u6742\u63a5\u89e6\u52a8\u529b\u5b66\u3001\u4e0d\u53ef\u9884\u6d4b\u6750\u6599\u7279\u6027\u548c\u590d\u6742\u7cfb\u7edf\u72b6\u6001\u7b49\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u548c\u7cbe\u5ea6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528GPU\u52a0\u901f\u7684\u53ef\u5fae\u5206\u7269\u7406\u6a21\u62df\u5668\uff0c\u914d\u5907\u53ef\u5fae\u5206\u6280\u80fd\u5230\u52a8\u4f5c\u6620\u5c04\u3001\u4efb\u52a1\u5bfc\u5411\u6f14\u793a\u65b9\u6cd5\u3001\u68af\u5ea6\u88c1\u526a\u548c\u57fa\u4e8e\u7ebf\u641c\u7d22\u7684\u68af\u5ea6\u4e0b\u964d\u3002", "result": "DDBot\u80fd\u57285-20\u5206\u949f\u5185\u6536\u655b\uff0c\u9ad8\u6548\u8bc6\u522b\u672a\u77e5\u9897\u7c92\u6750\u6599\u52a8\u529b\u5b66\u5e76\u4f18\u5316\u6316\u6398\u6280\u80fd\uff0c\u5728\u96f6\u6837\u672c\u771f\u5b9e\u90e8\u7f72\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7ed3\u679c\u3002", "conclusion": "DDBot\u5728\u6316\u6398\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u9c81\u68d2\u6027\u548c\u9ad8\u6548\u6027\uff0c\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.17341", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17341", "abs": "https://arxiv.org/abs/2510.17341", "authors": ["Fan Shao", "Satoshi Endo", "Sandra Hirche", "Fanny Ficuciello"], "title": "Interactive Force-Impedance Control", "comment": null, "summary": "Human collaboration with robots requires flexible role adaptation, enabling\nrobot to switch between active leader and passive follower. Effective role\nswitching depends on accurately estimating human intention, which is typically\nachieved through external force analysis, nominal robot dynamics, or\ndata-driven approaches. However, these methods are primarily effective in\ncontact-sparse environments. When robots under hybrid or unified\nforce-impedance control physically interact with active humans or non-passive\nenvironments, the robotic system may lose passivity and thus compromise safety.\nTo address this challenge, this paper proposes the unified Interactive\nForce-Impedance Control (IFIC) framework that adapts to the interaction power\nflow, ensuring effortless and safe interaction in contact-rich environments.\nThe proposed control architecture is formulated within a port-Hamiltonian\nframework, incorporating both interaction and task control ports, through which\nsystem passivity is guaranteed.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u4ea4\u4e92\u529b-\u963b\u6297\u63a7\u5236(IFIC)\u6846\u67b6\uff0c\u901a\u8fc7\u9002\u5e94\u4ea4\u4e92\u529f\u7387\u6d41\u786e\u4fdd\u63a5\u89e6\u4e30\u5bcc\u73af\u5883\u4e2d\u7684\u8f7b\u677e\u5b89\u5168\u4ea4\u4e92\uff0c\u57fa\u4e8e\u7aef\u53e3\u54c8\u5bc6\u987f\u6846\u67b6\u4fdd\u8bc1\u7cfb\u7edf\u65e0\u6e90\u6027\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5728\u6df7\u5408\u6216\u7edf\u4e00\u529b-\u963b\u6297\u63a7\u5236\u4e0b\u4e0e\u4e3b\u52a8\u4eba\u7c7b\u6216\u975e\u88ab\u52a8\u73af\u5883\u7269\u7406\u4ea4\u4e92\u65f6\u53ef\u80fd\u5931\u53bb\u65e0\u6e90\u6027\u800c\u5371\u53ca\u5b89\u5168\u7684\u95ee\u9898\u3002", "method": "\u5728\u7aef\u53e3\u54c8\u5bc6\u987f\u6846\u67b6\u5185\u5236\u5b9a\u63a7\u5236\u67b6\u6784\uff0c\u5305\u542b\u4ea4\u4e92\u548c\u4efb\u52a1\u63a7\u5236\u7aef\u53e3\uff0c\u901a\u8fc7\u9002\u5e94\u4ea4\u4e92\u529f\u7387\u6d41\u786e\u4fdd\u7cfb\u7edf\u65e0\u6e90\u6027\u3002", "result": "IFIC\u6846\u67b6\u80fd\u591f\u5728\u63a5\u89e6\u4e30\u5bcc\u73af\u5883\u4e2d\u5b9e\u73b0\u8f7b\u677e\u5b89\u5168\u7684\u4ea4\u4e92\uff0c\u4fdd\u8bc1\u7cfb\u7edf\u65e0\u6e90\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7edf\u4e00\u4ea4\u4e92\u529b-\u963b\u6297\u63a7\u5236\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u673a\u5668\u4eba\u7269\u7406\u4ea4\u4e92\u4e2d\u7684\u5b89\u5168\u95ee\u9898\uff0c\u4e3a\u7075\u6d3b\u89d2\u8272\u9002\u5e94\u63d0\u4f9b\u4e86\u53ef\u9760\u4fdd\u969c\u3002"}}
{"id": "2510.17369", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17369", "abs": "https://arxiv.org/abs/2510.17369", "authors": ["Haochen Su", "Cristian Meo", "Francesco Stella", "Andrea Peirone", "Kai Junge", "Josie Hughes"], "title": "Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots", "comment": "Accepted by NeurIPS 2025 SpaVLE workshop. 4 pages, 2 figures(in main\n  paper, excluding references and supplements)", "summary": "Robotic systems are increasingly expected to operate in human-centered,\nunstructured environments where safety, adaptability, and generalization are\nessential. Vision-Language-Action (VLA) models have been proposed as a language\nguided generalized control framework for real robots. However, their deployment\nhas been limited to conventional serial link manipulators. Coupled by their\nrigidity and unpredictability of learning based control, the ability to safely\ninteract with the environment is missing yet critical. In this work, we present\nthe deployment of a VLA model on a soft continuum manipulator to demonstrate\nautonomous safe human-robot interaction. We present a structured finetuning and\ndeployment pipeline evaluating two state-of-the-art VLA models (OpenVLA-OFT and\n$\\pi_0$) across representative manipulation tasks, and show while\nout-of-the-box policies fail due to embodiment mismatch, through targeted\nfinetuning the soft robot performs equally to the rigid counterpart. Our\nfindings highlight the necessity of finetuning for bridging embodiment gaps,\nand demonstrate that coupling VLA models with soft robots enables safe and\nflexible embodied AI in human-shared environments.", "AI": {"tldr": "\u5c06\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u90e8\u7f72\u5230\u8f6f\u8fde\u7eed\u673a\u68b0\u81c2\u4e0a\uff0c\u901a\u8fc7\u5fae\u8c03\u5b9e\u73b0\u5b89\u5168\u7684\u4eba\u673a\u4ea4\u4e92\uff0c\u89e3\u51b3\u4e86\u521a\u4f53\u673a\u5668\u4eba\u4e0e\u8f6f\u4f53\u673a\u5668\u4eba\u4e4b\u95f4\u7684\u5177\u8eab\u5316\u5dee\u5f02\u95ee\u9898\u3002", "motivation": "\u5728\u4eba\u7c7b\u4e2d\u5fc3\u7684\u65e0\u7ed3\u6784\u73af\u5883\u4e2d\uff0c\u673a\u5668\u4eba\u9700\u8981\u5b89\u5168\u3001\u9002\u5e94\u6027\u5f3a\u548c\u6cdb\u5316\u80fd\u529b\u3002\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u4e3b\u8981\u90e8\u7f72\u5728\u521a\u6027\u4e32\u8054\u673a\u68b0\u81c2\u4e0a\uff0c\u7f3a\u4e4f\u4e0e\u73af\u5883\u5b89\u5168\u4ea4\u4e92\u7684\u80fd\u529b\uff0c\u800c\u8f6f\u4f53\u673a\u5668\u4eba\u5177\u6709\u56fa\u6709\u7684\u5b89\u5168\u6027\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u7684\u5fae\u8c03\u548c\u90e8\u7f72\u6d41\u7a0b\uff0c\u8bc4\u4f30\u4e86\u4e24\u79cd\u5148\u8fdb\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u4ee3\u8868\u6027\u64cd\u4f5c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u5fae\u8c03\u6765\u89e3\u51b3\u5177\u8eab\u5316\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u73b0\u6210\u7b56\u7565\u7531\u4e8e\u5177\u8eab\u5316\u4e0d\u5339\u914d\u800c\u5931\u8d25\uff0c\u4f46\u7ecf\u8fc7\u5fae\u8c03\u540e\uff0c\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u6027\u80fd\u4e0e\u521a\u6027\u673a\u5668\u4eba\u76f8\u5f53\u3002", "conclusion": "\u5fae\u8c03\u5bf9\u4e8e\u5f25\u5408\u5177\u8eab\u5316\u5dee\u8ddd\u81f3\u5173\u91cd\u8981\uff0c\u5c06\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u4e0e\u8f6f\u4f53\u673a\u5668\u4eba\u7ed3\u5408\u80fd\u591f\u5728\u4eba\u7c7b\u5171\u4eab\u73af\u5883\u4e2d\u5b9e\u73b0\u5b89\u5168\u7075\u6d3b\u7684\u5177\u8eab\u4eba\u5de5\u667a\u80fd\u3002"}}
{"id": "2510.17439", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17439", "abs": "https://arxiv.org/abs/2510.17439", "authors": ["Zhengshen Zhang", "Hao Li", "Yalun Dai", "Zhengbang Zhu", "Lei Zhou", "Chenchen Liu", "Dong Wang", "Francis E. H. Tay", "Sijin Chen", "Ziwei Liu", "Yuxiao Liu", "Xinghang Li", "Pan Zhou"], "title": "From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors", "comment": "Project page: https://falcon-vla.github.io/", "summary": "Existing vision-language-action (VLA) models act in 3D real-world but are\ntypically built on 2D encoders, leaving a spatial reasoning gap that limits\ngeneralization and adaptability. Recent 3D integration techniques for VLAs\neither require specialized sensors and transfer poorly across modalities, or\ninject weak cues that lack geometry and degrade vision-language alignment. In\nthis work, we introduce FALCON (From Spatial to Action), a novel paradigm that\ninjects rich 3D spatial tokens into the action head. FALCON leverages spatial\nfoundation models to deliver strong geometric priors from RGB alone, and\nincludes an Embodied Spatial Model that can optionally fuse depth, or pose for\nhigher fidelity when available, without retraining or architectural changes. To\npreserve language reasoning, spatial tokens are consumed by a Spatial-Enhanced\nAction Head rather than being concatenated into the vision-language backbone.\nThese designs enable FALCON to address limitations in spatial representation,\nmodality transferability, and alignment. In comprehensive evaluations across\nthree simulation benchmarks and eleven real-world tasks, our proposed FALCON\nachieves state-of-the-art performance, consistently surpasses competitive\nbaselines, and remains robust under clutter, spatial-prompt conditioning, and\nvariations in object scale and height.", "AI": {"tldr": "FALCON\u901a\u8fc7\u5728\u52a8\u4f5c\u5934\u4e2d\u6ce8\u5165\u4e30\u5bcc\u76843D\u7a7a\u95f4token\u6765\u89e3\u51b3\u73b0\u6709VLA\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u5dee\u8ddd\u95ee\u9898\uff0c\u5229\u7528\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u4eceRGB\u56fe\u50cf\u4e2d\u63d0\u53d6\u51e0\u4f55\u5148\u9a8c\uff0c\u5e76\u5728\u53ef\u7528\u65f6\u878d\u5408\u6df1\u5ea6\u6216\u59ff\u6001\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e2D\u7f16\u7801\u5668\u7684VLA\u6a21\u578b\u5b58\u5728\u7a7a\u95f4\u63a8\u7406\u5dee\u8ddd\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\u548c\u9002\u5e94\u6027\u3002\u73b0\u6709\u76843D\u96c6\u6210\u6280\u672f\u8981\u4e48\u9700\u8981\u4e13\u7528\u4f20\u611f\u5668\u4e14\u8de8\u6a21\u6001\u8fc1\u79fb\u80fd\u529b\u5dee\uff0c\u8981\u4e48\u6ce8\u5165\u7f3a\u4e4f\u51e0\u4f55\u4fe1\u606f\u7684\u5f31\u7ebf\u7d22\u5e76\u635f\u5bb3\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u3002", "method": "\u63d0\u51faFALCON\u8303\u5f0f\uff0c\u5728\u52a8\u4f5c\u5934\u4e2d\u6ce8\u51653D\u7a7a\u95f4token\uff0c\u5229\u7528\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u4eceRGB\u56fe\u50cf\u83b7\u53d6\u51e0\u4f55\u5148\u9a8c\uff0c\u5305\u542b\u53ef\u9009\u7684\u6df1\u5ea6\u6216\u59ff\u6001\u878d\u5408\u529f\u80fd\uff0c\u901a\u8fc7\u7a7a\u95f4\u589e\u5f3a\u52a8\u4f5c\u5934\u5904\u7406\u7a7a\u95f4token\u4ee5\u4fdd\u6301\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u4e09\u4e2a\u4eff\u771f\u57fa\u51c6\u548c\u5341\u4e00\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\uff0cFALCON\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u6301\u7eed\u8d85\u8d8a\u7ade\u4e89\u57fa\u7ebf\uff0c\u5e76\u5728\u6742\u4e71\u73af\u5883\u3001\u7a7a\u95f4\u63d0\u793a\u6761\u4ef6\u4ee5\u53ca\u7269\u4f53\u5c3a\u5ea6\u548c\u9ad8\u5ea6\u53d8\u5316\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "FALCON\u6210\u529f\u89e3\u51b3\u4e86\u7a7a\u95f4\u8868\u793a\u3001\u6a21\u6001\u53ef\u8fc1\u79fb\u6027\u548c\u5bf9\u9f50\u65b9\u9762\u7684\u9650\u5236\uff0c\u4e3aVLA\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u597d\u76843D\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.17448", "categories": ["cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.17448", "abs": "https://arxiv.org/abs/2510.17448", "authors": ["Mirko Mizzoni", "Pieter van Goor", "Barbara Bazzana", "Antonio Franchi"], "title": "A Generalization of Input-Output Linearization via Dynamic Switching Between Melds of Output Functions", "comment": null, "summary": "This letter presents a systematic framework for switching between different\nsets of outputs for the control of nonlinear systems via feedback\nlinearization. We introduce the concept of a meld to formally define a valid,\nfeedback-linearizable subset of outputs that can be selected from a larger deck\nof possible outputs. The main contribution is a formal proof establishing that\nunder suitable dwell-time and compatibility conditions, it is possible to\nswitch between different melds while guaranteeing the uniform boundedness of\nthe system state. We further show that the error dynamics of the active outputs\nremain exponentially stable within each switching interval and that outputs\ncommon to consecutive melds are tracked seamlessly through transitions. The\nproposed theory is valid for any feedback linearizable nonlinear system, such\nas, e.g., robots, aerial and terrestrial vehicles, etc.. We demonstrate it on a\nsimple numerical simulation of a robotic manipulator.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u975e\u7ebf\u6027\u7cfb\u7edf\u53cd\u9988\u7ebf\u6027\u5316\u63a7\u5236\u4e2d\u5207\u6362\u4e0d\u540c\u8f93\u51fa\u96c6\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165meld\u6982\u5ff5\u6765\u5b9a\u4e49\u53ef\u4ece\u66f4\u5927\u8f93\u51fa\u96c6\u5408\u4e2d\u9009\u62e9\u7684\u6709\u6548\u3001\u53ef\u53cd\u9988\u7ebf\u6027\u5316\u7684\u8f93\u51fa\u5b50\u96c6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u975e\u7ebf\u6027\u7cfb\u7edf\u63a7\u5236\u4e2d\u9700\u8981\u5728\u4e0d\u540c\u8f93\u51fa\u96c6\u4e4b\u95f4\u5207\u6362\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u8bc1\u7cfb\u7edf\u72b6\u6001\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u5f15\u5165meld\u6982\u5ff5\u6765\u5f62\u5f0f\u5316\u5b9a\u4e49\u53ef\u53cd\u9988\u7ebf\u6027\u5316\u7684\u8f93\u51fa\u5b50\u96c6\uff0c\u5efa\u7acb\u5207\u6362\u6761\u4ef6\uff08\u9a7b\u7559\u65f6\u95f4\u548c\u517c\u5bb9\u6027\u6761\u4ef6\uff09\uff0c\u8bc1\u660e\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u5207\u6362\u65f6\u7cfb\u7edf\u72b6\u6001\u7684\u5747\u5300\u6709\u754c\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u5408\u9002\u7684\u9a7b\u7559\u65f6\u95f4\u548c\u517c\u5bb9\u6027\u6761\u4ef6\u4e0b\uff0c\u53ef\u4ee5\u5728\u4e0d\u540cmeld\u4e4b\u95f4\u5207\u6362\uff0c\u540c\u65f6\u4fdd\u8bc1\u7cfb\u7edf\u72b6\u6001\u5747\u5300\u6709\u754c\uff0c\u6d3b\u52a8\u8f93\u51fa\u7684\u8bef\u5dee\u52a8\u6001\u5728\u6bcf\u4e2a\u5207\u6362\u533a\u95f4\u5185\u4fdd\u6301\u6307\u6570\u7a33\u5b9a\uff0c\u5171\u540c\u8f93\u51fa\u5728\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u65e0\u7f1d\u8ddf\u8e2a\u3002", "conclusion": "\u8be5\u7406\u8bba\u9002\u7528\u4e8e\u4efb\u4f55\u53ef\u53cd\u9988\u7ebf\u6027\u5316\u7684\u975e\u7ebf\u6027\u7cfb\u7edf\uff08\u5982\u673a\u5668\u4eba\u3001\u7a7a\u4e2d\u548c\u5730\u9762\u8f66\u8f86\u7b49\uff09\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u4eba\u64cd\u7eb5\u5668\u7684\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.17525", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17525", "abs": "https://arxiv.org/abs/2510.17525", "authors": ["Simon Schaefer", "Helen Oleynikova", "Sandra Hirche", "Stefan Leutenegger"], "title": "HumanMPC - Safe and Efficient MAV Navigation among Humans", "comment": null, "summary": "Safe and efficient robotic navigation among humans is essential for\nintegrating robots into everyday environments. Most existing approaches focus\non simplified 2D crowd navigation and fail to account for the full complexity\nof human body dynamics beyond root motion. We present HumanMPC, a Model\nPredictive Control (MPC) framework for 3D Micro Air Vehicle (MAV) navigation\namong humans that combines theoretical safety guarantees with data-driven\nmodels for realistic human motion forecasting. Our approach introduces a novel\ntwist to reachability-based safety formulation that constrains only the initial\ncontrol input for safety while modeling its effects over the entire planning\nhorizon, enabling safe yet efficient navigation. We validate HumanMPC in both\nsimulated experiments using real human trajectories and in the real-world,\ndemonstrating its effectiveness across tasks ranging from goal-directed\nnavigation to visual servoing for human tracking. While we apply our method to\nMAVs in this work, it is generic and can be adapted by other platforms. Our\nresults show that the method ensures safety without excessive conservatism and\noutperforms baseline approaches in both efficiency and reliability.", "AI": {"tldr": "HumanMPC\u662f\u4e00\u4e2a\u7528\u4e8e3D\u5fae\u578b\u98de\u884c\u5668\u5728\u4eba\u7fa4\u4e2d\u5bfc\u822a\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u7406\u8bba\u5b89\u5168\u4fdd\u8bc1\u548c\u6570\u636e\u9a71\u52a8\u7684\u4eba\u7c7b\u8fd0\u52a8\u9884\u6d4b\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u9ad8\u6548\u7684\u5bfc\u822a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7b80\u5316\u76842D\u4eba\u7fa4\u5bfc\u822a\uff0c\u672a\u80fd\u5145\u5206\u8003\u8651\u4eba\u4f53\u52a8\u6001\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u5b8c\u65743D\u4eba\u4f53\u52a8\u6001\u7684\u5b89\u5168\u5bfc\u822a\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u53ef\u8fbe\u6027\u7684\u5b89\u5168\u516c\u5f0f\uff0c\u4ec5\u7ea6\u675f\u521d\u59cb\u63a7\u5236\u8f93\u5165\u4ee5\u786e\u4fdd\u5b89\u5168\uff0c\u540c\u65f6\u5728\u6574\u4e2a\u89c4\u5212\u8303\u56f4\u5185\u5efa\u6a21\u5176\u6548\u679c\uff0c\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u7684\u4eba\u7c7b\u8fd0\u52a8\u9884\u6d4b\u3002", "result": "\u5728\u6a21\u62df\u5b9e\u9a8c\u548c\u771f\u5b9e\u4e16\u754c\u9a8c\u8bc1\u4e2d\uff0cHumanMPC\u5728\u76ee\u6807\u5bfc\u5411\u5bfc\u822a\u548c\u89c6\u89c9\u4f3a\u670d\u8ddf\u8e2a\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u786e\u4fdd\u5b89\u5168\u800c\u4e0d\u8fc7\u5ea6\u4fdd\u5b88\uff0c\u5728\u6548\u7387\u548c\u53ef\u9760\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u867d\u7136\u5e94\u7528\u4e8e\u5fae\u578b\u98de\u884c\u5668\uff0c\u4f46\u5177\u6709\u901a\u7528\u6027\uff0c\u53ef\u9002\u5e94\u5176\u4ed6\u5e73\u53f0\uff0c\u4e3a\u673a\u5668\u4eba\u5b89\u5168\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17541", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17541", "abs": "https://arxiv.org/abs/2510.17541", "authors": ["Xiaobo Zheng", "Pan Tang", "Defu Lin", "Shaoming He"], "title": "Distributed Spatial-Temporal Trajectory Optimization for Unmanned-Aerial-Vehicle Swarm", "comment": null, "summary": "Swarm trajectory optimization problems are a well-recognized class of\nmulti-agent optimal control problems with strong nonlinearity. However, the\nheuristic nature of needing to set the final time for agents beforehand and the\ntime-consuming limitation of the significant number of iterations prohibit the\napplication of existing methods to large-scale swarm of Unmanned Aerial\nVehicles (UAVs) in practice. In this paper, we propose a spatial-temporal\ntrajectory optimization framework that accomplishes multi-UAV consensus based\non the Alternating Direction Multiplier Method (ADMM) and uses Differential\nDynamic Programming (DDP) for fast local planning of individual UAVs. The\nintroduced framework is a two-level architecture that employs Parameterized DDP\n(PDDP) as the trajectory optimizer for each UAV, and ADMM to satisfy the local\nconstraints and accomplish the spatial-temporal parameter consensus among all\nUAVs. This results in a fully distributed algorithm called Distributed\nParameterized DDP (D-PDDP). In addition, an adaptive tuning criterion based on\nthe spectral gradient method for the penalty parameter is proposed to reduce\nthe number of algorithmic iterations. Several simulation examples are presented\nto verify the effectiveness of the proposed algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eADMM\u548cDDP\u7684\u7a7a\u95f4-\u65f6\u95f4\u8f68\u8ff9\u4f18\u5316\u6846\u67b6D-PDDP\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u7fa4\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u7b97\u6cd5\u548c\u81ea\u9002\u5e94\u60e9\u7f5a\u53c2\u6570\u8c03\u6574\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u9884\u5148\u8bbe\u5b9a\u6700\u7ec8\u65f6\u95f4\u4e14\u8fed\u4ee3\u6b21\u6570\u591a\uff0c\u9650\u5236\u4e86\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u7fa4\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u9700\u8981\u89e3\u51b3\u975e\u7ebf\u6027\u5f3a\u3001\u8ba1\u7b97\u8017\u65f6\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u5c42\u67b6\u6784\uff1a\u4f7f\u7528\u53c2\u6570\u5316DDP\u8fdb\u884c\u5355\u4e2a\u65e0\u4eba\u673a\u5c40\u90e8\u89c4\u5212\uff0cADMM\u5b9e\u73b0\u7ea6\u675f\u6ee1\u8db3\u548c\u7a7a\u95f4-\u65f6\u95f4\u53c2\u6570\u5171\u8bc6\uff0c\u5f62\u6210\u5206\u5e03\u5f0f\u53c2\u6570\u5316DDP\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u4eff\u771f\u793a\u4f8b\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u7fa4\u7684\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684D-PDDP\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u7fa4\u8f68\u8ff9\u4f18\u5316\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u6536\u655b\u6027\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.17576", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.17576", "abs": "https://arxiv.org/abs/2510.17576", "authors": ["Cansu Erdogan", "Cesar Alan Contreras", "Alireza Rastegarpanah", "Manolis Chiou", "Rustam Stolkin"], "title": "Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries", "comment": "This work is funded by the project called \"Research and Development\n  of a Highly Automated and Safe Streamlined Process for Increasing Lithium-ion\n  Battery Repurposing and Recycling\" (REBELION) under Grant 101104241, and\n  partially supported by the Ministry of National Education, Republic of\n  Turkey. Submitted to Frontiers for Review", "summary": "This paper addresses the problem of planning complex manipulation tasks, in\nwhich multiple robots with different end-effectors and capabilities, informed\nby computer vision, must plan and execute concatenated sequences of actions on\na variety of objects that can appear in arbitrary positions and configurations\nin unstructured scenes. We propose an intent-driven planning pipeline which can\nrobustly construct such action sequences with varying degrees of supervisory\ninput from a human using simple language instructions. The pipeline integrates:\n(i) perception-to-text scene encoding, (ii) an ensemble of large language\nmodels (LLMs) that generate candidate removal sequences based on the operator's\nintent, (iii) an LLM-based verifier that enforces formatting and precedence\nconstraints, and (iv) a deterministic consistency filter that rejects\nhallucinated objects. The pipeline is evaluated on an example task in which two\nrobot arms work collaboratively to dismantle an Electric Vehicle battery for\nrecycling applications. A variety of components must be grasped and removed in\nspecific sequences, determined by human instructions and/or by task-order\nfeasibility decisions made by the autonomous system. On 200 real scenes with\n600 operator prompts across five component classes, we used metrics of\nfull-sequence correctness and next-task correctness to evaluate and compare\nfive LLM-based planners (including ablation analyses of pipeline components).\nWe also evaluated the LLM-based human interface in terms of time to execution\nand NASA TLX with human participant experiments. Results indicate that our\nensemble-with-verification approach reliably maps operator intent to safe,\nexecutable multi-robot plans while maintaining low user effort.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u610f\u56fe\u9a71\u52a8\u7684\u89c4\u5212\u7ba1\u9053\uff0c\u7528\u4e8e\u591a\u673a\u5668\u4eba\u534f\u4f5c\u6267\u884c\u590d\u6742\u64cd\u4f5c\u4efb\u52a1\uff0c\u901a\u8fc7\u96c6\u6210\u611f\u77e5\u5230\u6587\u672c\u7684\u573a\u666f\u7f16\u7801\u3001LLM\u96c6\u5408\u751f\u6210\u5019\u9009\u52a8\u4f5c\u5e8f\u5217\u3001LLM\u9a8c\u8bc1\u5668\u548c\u786e\u5b9a\u6027\u4e00\u81f4\u6027\u8fc7\u6ee4\u5668\uff0c\u5b9e\u73b0\u4ece\u4eba\u7c7b\u7b80\u5355\u8bed\u8a00\u6307\u4ee4\u5230\u53ef\u6267\u884c\u591a\u673a\u5668\u4eba\u8ba1\u5212\u7684\u53ef\u9760\u6620\u5c04\u3002", "motivation": "\u89e3\u51b3\u591a\u673a\u5668\u4eba\u534f\u4f5c\u6267\u884c\u590d\u6742\u64cd\u4f5c\u4efb\u52a1\u7684\u89c4\u5212\u95ee\u9898\uff0c\u8fd9\u4e9b\u673a\u5668\u4eba\u5177\u6709\u4e0d\u540c\u7684\u672b\u7aef\u6267\u884c\u5668\u548c\u80fd\u529b\uff0c\u9700\u8981\u5728\u975e\u7ed3\u6784\u5316\u573a\u666f\u4e2d\u89c4\u5212\u5e76\u6267\u884c\u8fde\u63a5\u7684\u52a8\u4f5c\u5e8f\u5217\uff0c\u5bf9\u8c61\u53ef\u4ee5\u51fa\u73b0\u5728\u4efb\u610f\u4f4d\u7f6e\u548c\u914d\u7f6e\u4e2d\u3002", "method": "\u63d0\u51fa\u610f\u56fe\u9a71\u52a8\u7684\u89c4\u5212\u7ba1\u9053\uff0c\u5305\u62ec\uff1a(i)\u611f\u77e5\u5230\u6587\u672c\u7684\u573a\u666f\u7f16\u7801\uff0c(ii)\u57fa\u4e8e\u64cd\u4f5c\u8005\u610f\u56fe\u751f\u6210\u5019\u9009\u79fb\u9664\u5e8f\u5217\u7684LLM\u96c6\u5408\uff0c(iii)\u5f3a\u5236\u6267\u884c\u683c\u5f0f\u548c\u4f18\u5148\u7ea6\u675f\u7684LLM\u9a8c\u8bc1\u5668\uff0c(iv)\u62d2\u7edd\u5e7b\u89c9\u5bf9\u8c61\u7684\u786e\u5b9a\u6027\u4e00\u81f4\u6027\u8fc7\u6ee4\u5668\u3002", "result": "\u5728200\u4e2a\u771f\u5b9e\u573a\u666f\u548c600\u4e2a\u64cd\u4f5c\u8005\u63d0\u793a\u7684\u8bc4\u4f30\u4e2d\uff0c\u4f7f\u7528\u5b8c\u6574\u5e8f\u5217\u6b63\u786e\u6027\u548c\u4e0b\u4e00\u4efb\u52a1\u6b63\u786e\u6027\u6307\u6807\u8bc4\u4f30\u4e86\u4e94\u4e2a\u57fa\u4e8eLLM\u7684\u89c4\u5212\u5668\u3002\u7ed3\u679c\u8868\u660e\uff0c\u96c6\u6210\u9a8c\u8bc1\u65b9\u6cd5\u80fd\u591f\u53ef\u9760\u5730\u5c06\u64cd\u4f5c\u8005\u610f\u56fe\u6620\u5c04\u5230\u5b89\u5168\u3001\u53ef\u6267\u884c\u7684\u591a\u673a\u5668\u4eba\u8ba1\u5212\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u7528\u6237\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u9a8c\u8bc1\u65b9\u6cd5\u80fd\u591f\u53ef\u9760\u5730\u5c06\u64cd\u4f5c\u8005\u610f\u56fe\u6620\u5c04\u5230\u5b89\u5168\u3001\u53ef\u6267\u884c\u7684\u591a\u673a\u5668\u4eba\u8ba1\u5212\uff0c\u5728\u4fdd\u6301\u4f4e\u7528\u6237\u5de5\u4f5c\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u53ef\u9760\u7684\u89c4\u5212\u6027\u80fd\u3002"}}
{"id": "2510.17604", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17604", "abs": "https://arxiv.org/abs/2510.17604", "authors": ["Hao Qiao", "Yan Wang", "Shuo Yang", "Xiaoyao Yu", "Jian kuang", "Xiaoji Niu"], "title": "Learned Inertial Odometry for Cycling Based on Mixture of Experts Algorithm", "comment": null, "summary": "With the rapid growth of bike sharing and the increasing diversity of cycling\napplications, accurate bicycle localization has become essential. traditional\nGNSS-based methods suffer from multipath effects, while existing inertial\nnavigation approaches rely on precise modeling and show limited robustness.\nTight Learned Inertial Odometry (TLIO) achieves low position drift by combining\nraw IMU data with predicted displacements by neural networks, but its high\ncomputational cost restricts deployment on mobile devices. To overcome this, we\nextend TLIO to bicycle localization and introduce an improved Mixture-of\nExperts (MoE) model that reduces both training and inference costs. Experiments\nshow that, compared to the state-of-the-art LLIO framework, our method achieves\ncomparable accuracy while reducing parameters by 64.7% and computational cost\nby 81.8%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u884c\u8f66\u5b9a\u4f4d\uff0c\u5728\u4fdd\u6301\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u6570\u91cf\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u968f\u7740\u5171\u4eab\u5355\u8f66\u548c\u591a\u6837\u5316\u9a91\u884c\u5e94\u7528\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7cbe\u786e\u7684\u81ea\u884c\u8f66\u5b9a\u4f4d\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edfGNSS\u65b9\u6cd5\u5b58\u5728\u591a\u8def\u5f84\u6548\u5e94\u95ee\u9898\uff0c\u800c\u73b0\u6709\u60ef\u6027\u5bfc\u822a\u65b9\u6cd5\u4f9d\u8d56\u7cbe\u786e\u5efa\u6a21\u4e14\u9c81\u68d2\u6027\u6709\u9650\u3002TLIO\u65b9\u6cd5\u867d\u7136\u80fd\u5b9e\u73b0\u4f4e\u4f4d\u7f6e\u6f02\u79fb\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002", "method": "\u5c06TLIO\u6269\u5c55\u5230\u81ea\u884c\u8f66\u5b9a\u4f4d\uff0c\u5e76\u5f15\u5165\u6539\u8fdb\u7684\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u51cf\u5c11\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\u6765\u4f18\u5316\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684LLIO\u6846\u67b6\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u76f8\u5f53\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u53c2\u6570\u51cf\u5c11\u4e8664.7%\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u4e8681.8%\u3002", "conclusion": "\u63d0\u51fa\u7684\u6539\u8fdb\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u5728\u81ea\u884c\u8f66\u5b9a\u4f4d\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u9002\u5408\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002"}}
{"id": "2510.17640", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17640", "abs": "https://arxiv.org/abs/2510.17640", "authors": ["Yuquan Xue", "Guanxing Lu", "Zhenyu Wu", "Chuanrui Zhang", "Bofang Jia", "Zhengyi Gu", "Yansong Tang", "Ziwei Wang"], "title": "RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation", "comment": "9 pages,7 figures, submitted to ICRA2026", "summary": "Vision-Language-Action models (VLAs) have demonstrated remarkable performance\non complex robotic manipulation tasks through imitation learning. However,\nexisting imitation learning datasets contain only successful trajectories and\nlack failure or recovery data, especially for out-of-distribution (OOD) states\nwhere the robot deviates from the main policy due to minor perturbations or\nerrors, leading VLA models to struggle with states deviating from the training\ndistribution. To this end, we propose an automated OOD data augmentation\nframework named RESample through exploratory sampling. Specifically, we first\nleverage offline reinforcement learning to obtain an action-value network that\naccurately identifies sub-optimal actions under the current manipulation\npolicy. We further sample potential OOD states from trajectories via rollout,\nand design an exploratory sampling mechanism that adaptively incorporates these\naction proxies into the training dataset to ensure efficiency. Subsequently,\nour framework explicitly encourages the VLAs to recover from OOD states and\nenhances their robustness against distributional shifts. We conduct extensive\nexperiments on the LIBERO benchmark as well as real-world robotic manipulation\ntasks, demonstrating that RESample consistently improves the stability and\ngeneralization ability of VLA models.", "AI": {"tldr": "\u63d0\u51faRESample\u6846\u67b6\uff0c\u901a\u8fc7\u63a2\u7d22\u6027\u91c7\u6837\u81ea\u52a8\u589e\u5f3a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684OOD\u6570\u636e\uff0c\u63d0\u9ad8\u6a21\u578b\u5728\u5206\u5e03\u504f\u79fb\u72b6\u6001\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6062\u590d\u80fd\u529b", "motivation": "\u73b0\u6709\u6a21\u4eff\u5b66\u4e60\u6570\u636e\u96c6\u4ec5\u5305\u542b\u6210\u529f\u8f68\u8ff9\uff0c\u7f3a\u4e4f\u5931\u8d25\u548c\u6062\u590d\u6570\u636e\uff0c\u5bfc\u81f4VLA\u6a21\u578b\u5728\u5904\u7406\u504f\u79bb\u8bad\u7ec3\u5206\u5e03\u7684OOD\u72b6\u6001\u65f6\u8868\u73b0\u4e0d\u4f73", "method": "\u5229\u7528\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u83b7\u53d6\u52a8\u4f5c\u4ef7\u503c\u7f51\u7edc\u8bc6\u522b\u6b21\u4f18\u52a8\u4f5c\uff0c\u901a\u8fc7rollout\u91c7\u6837\u6f5c\u5728OOD\u72b6\u6001\uff0c\u8bbe\u8ba1\u63a2\u7d22\u6027\u91c7\u6837\u673a\u5236\u5c06\u52a8\u4f5c\u4ee3\u7406\u81ea\u9002\u5e94\u7eb3\u5165\u8bad\u7ec3\u6570\u636e\u96c6", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0cRESample\u6301\u7eed\u63d0\u5347\u4e86VLA\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b", "conclusion": "RESample\u6846\u67b6\u6709\u6548\u589e\u5f3a\u4e86VLA\u6a21\u578b\u4eceOOD\u72b6\u6001\u6062\u590d\u7684\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027"}}
{"id": "2510.17783", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17783", "abs": "https://arxiv.org/abs/2510.17783", "authors": ["Simeon Adebola", "Chung Min Kim", "Justin Kerr", "Shuangyu Xie", "Prithvi Akella", "Jose Luis Susa Rincon", "Eugen Solowjow", "Ken Goldberg"], "title": "Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant Structures with Gaussian Splats", "comment": "2025 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2025)", "summary": "Commercial plant phenotyping systems using fixed cameras cannot perceive many\nplant details due to leaf occlusion. In this paper, we present Botany-Bot, a\nsystem for building detailed \"annotated digital twins\" of living plants using\ntwo stereo cameras, a digital turntable inside a lightbox, an industrial robot\narm, and 3D segmentated Gaussian Splat models. We also present robot algorithms\nfor manipulating leaves to take high-resolution indexable images of occluded\ndetails such as stem buds and the underside/topside of leaves. Results from\nexperiments suggest that Botany-Bot can segment leaves with 90.8% accuracy,\ndetect leaves with 86.2% accuracy, lift/push leaves with 77.9% accuracy, and\ntake detailed overside/underside images with 77.3% accuracy. Code, videos, and\ndatasets are available at https://berkeleyautomation.github.io/Botany-Bot/.", "AI": {"tldr": "Botany-Bot\u7cfb\u7edf\u4f7f\u7528\u7acb\u4f53\u76f8\u673a\u3001\u6570\u5b57\u8f6c\u53f0\u3001\u5de5\u4e1a\u673a\u5668\u4eba\u81c2\u548c3D\u5206\u5272\u9ad8\u65af\u6cfc\u6e85\u6a21\u578b\uff0c\u4e3a\u6d3b\u4f53\u690d\u7269\u6784\u5efa\u8be6\u7ec6\u7684\"\u6ce8\u91ca\u6570\u5b57\u5b6a\u751f\"\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u4eba\u7b97\u6cd5\u64cd\u7eb5\u53f6\u7247\u6765\u62cd\u6444\u88ab\u906e\u6321\u7ec6\u8282\u7684\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u3002", "motivation": "\u5546\u4e1a\u690d\u7269\u8868\u578b\u7cfb\u7edf\u4f7f\u7528\u56fa\u5b9a\u76f8\u673a\u65e0\u6cd5\u611f\u77e5\u8bb8\u591a\u690d\u7269\u7ec6\u8282\uff0c\u56e0\u4e3a\u53f6\u7247\u906e\u6321\u95ee\u9898\u4e25\u91cd\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u7acb\u4f53\u76f8\u673a\u3001\u6570\u5b57\u8f6c\u53f0\u3001\u5de5\u4e1a\u673a\u5668\u4eba\u81c2\u548c3D\u5206\u5272\u9ad8\u65af\u6cfc\u6e85\u6a21\u578b\u6784\u5efa\u7cfb\u7edf\uff0c\u5f00\u53d1\u673a\u5668\u4eba\u7b97\u6cd5\u6765\u64cd\u7eb5\u53f6\u7247\u62cd\u6444\u88ab\u906e\u6321\u533a\u57df\u7684\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u53f6\u7247\u5206\u5272\u51c6\u786e\u738790.8%\uff0c\u53f6\u7247\u68c0\u6d4b\u51c6\u786e\u738786.2%\uff0c\u53f6\u7247\u62ac\u8d77/\u63a8\u52a8\u51c6\u786e\u738777.9%\uff0c\u62cd\u6444\u53f6\u7247\u6b63\u53cd\u9762\u7ec6\u8282\u56fe\u50cf\u51c6\u786e\u738777.3%\u3002", "conclusion": "Botany-Bot\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u89e3\u51b3\u53f6\u7247\u906e\u6321\u95ee\u9898\uff0c\u6210\u529f\u6784\u5efa\u690d\u7269\u7684\u8be6\u7ec6\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4ee3\u7801\u3001\u89c6\u9891\u548c\u6570\u636e\u96c6\u4f9b\u7814\u7a76\u4f7f\u7528\u3002"}}
{"id": "2510.17792", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17792", "abs": "https://arxiv.org/abs/2510.17792", "authors": ["Gabriel B. Margolis", "Michelle Wang", "Nolan Fey", "Pulkit Agrawal"], "title": "SoftMimic: Learning Compliant Whole-body Control from Examples", "comment": "Website: https://gmargo11.github.io/softmimic/", "summary": "We introduce SoftMimic, a framework for learning compliant whole-body control\npolicies for humanoid robots from example motions. Imitating human motions with\nreinforcement learning allows humanoids to quickly learn new skills, but\nexisting methods incentivize stiff control that aggressively corrects\ndeviations from a reference motion, leading to brittle and unsafe behavior when\nthe robot encounters unexpected contacts. In contrast, SoftMimic enables robots\nto respond compliantly to external forces while maintaining balance and\nposture. Our approach leverages an inverse kinematics solver to generate an\naugmented dataset of feasible compliant motions, which we use to train a\nreinforcement learning policy. By rewarding the policy for matching compliant\nresponses rather than rigidly tracking the reference motion, SoftMimic learns\nto absorb disturbances and generalize to varied tasks from a single motion\nclip. We validate our method through simulations and real-world experiments,\ndemonstrating safe and effective interaction with the environment.", "AI": {"tldr": "SoftMimic\u662f\u4e00\u4e2a\u4ece\u793a\u4f8b\u52a8\u4f5c\u5b66\u4e60\u4eba\u5f62\u673a\u5668\u4eba\u67d4\u987a\u5168\u8eab\u63a7\u5236\u7b56\u7565\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5956\u52b1\u5339\u914d\u67d4\u987a\u54cd\u5e94\u800c\u975e\u521a\u6027\u8ddf\u8e2a\u53c2\u8003\u52a8\u4f5c\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u987a\u4ece\u5730\u54cd\u5e94\u5916\u529b\u540c\u65f6\u4fdd\u6301\u5e73\u8861\u548c\u59ff\u6001\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u6fc0\u52b1\u50f5\u786c\u63a7\u5236\uff0c\u5f53\u673a\u5668\u4eba\u9047\u5230\u610f\u5916\u63a5\u89e6\u65f6\u4f1a\u5bfc\u81f4\u8106\u5f31\u548c\u4e0d\u5b89\u5168\u7684\u884c\u4e3a\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u67d4\u987a\u54cd\u5e94\u5916\u529b\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u9006\u8fd0\u52a8\u5b66\u6c42\u89e3\u5668\u751f\u6210\u53ef\u884c\u7684\u67d4\u987a\u52a8\u4f5c\u589e\u5f3a\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5956\u52b1\u7b56\u7565\u5339\u914d\u67d4\u987a\u54cd\u5e94\u800c\u975e\u521a\u6027\u8ddf\u8e2a\u53c2\u8003\u52a8\u4f5c\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u4e0e\u73af\u5883\u7684\u5b89\ufffd\ufffd\ufffd\u6709\u6548\u4ea4\u4e92\uff0c\u80fd\u591f\u5438\u6536\u5e72\u6270\u5e76\u4ece\u5355\u4e2a\u52a8\u4f5c\u7247\u6bb5\u6cdb\u5316\u5230\u5404\u79cd\u4efb\u52a1\u3002", "conclusion": "SoftMimic\u80fd\u591f\u5b66\u4e60\u67d4\u987a\u7684\u5168\u8eab\u63a7\u5236\u7b56\u7565\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5b89\u5168\u6709\u6548\u5730\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u540c\u65f6\u4fdd\u6301\u5e73\u8861\u548c\u59ff\u6001\u3002"}}
{"id": "2510.17801", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17801", "abs": "https://arxiv.org/abs/2510.17801", "authors": ["Yulin Luo", "Chun-Kai Fan", "Menghang Dong", "Jiayu Shi", "Mengdi Zhao", "Bo-Wen Zhang", "Cheng Chi", "Jiaming Liu", "Gaole Dai", "Rongyu Zhang", "Ruichuan An", "Kun Wu", "Zhengping Che", "Shaoxuan Xie", "Guocai Yao", "Zhongxia Zhao", "Pengwei Wang", "Guang Liu", "Zhongyuan Wang", "Tiejun Huang", "Shanghang Zhang"], "title": "Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain", "comment": null, "summary": "Building robots that can perceive, reason, and act in dynamic, unstructured\nenvironments remains a core challenge. Recent embodied systems often adopt a\ndual-system paradigm, where System 2 handles high-level reasoning while System\n1 executes low-level control. In this work, we refer to System 2 as the\nembodied brain, emphasizing its role as the cognitive core for reasoning and\ndecision-making in manipulation tasks. Given this role, systematic evaluation\nof the embodied brain is essential. Yet existing benchmarks emphasize execution\nsuccess, or when targeting high-level reasoning, suffer from incomplete\ndimensions and limited task realism, offering only a partial picture of\ncognitive capability. To bridge this gap, we introduce RoboBench, a benchmark\nthat systematically evaluates multimodal large language models (MLLMs) as\nembodied brains. Motivated by the critical roles across the full manipulation\npipeline, RoboBench defines five dimensions-instruction comprehension,\nperception reasoning, generalized planning, affordance prediction, and failure\nanalysis-spanning 14 capabilities, 25 tasks, and 6092 QA pairs. To ensure\nrealism, we curate datasets across diverse embodiments, attribute-rich objects,\nand multi-view scenes, drawing from large-scale real robotic data. For\nplanning, RoboBench introduces an evaluation framework,\nMLLM-as-world-simulator. It evaluate embodied feasibility by simulating whether\npredicted plans can achieve critical object-state changes. Experiments on 14\nMLLMs reveal fundamental limitations: difficulties with implicit instruction\ncomprehension, spatiotemporal reasoning, cross-scenario planning, fine-grained\naffordance understanding, and execution failure diagnosis. RoboBench provides a\ncomprehensive scaffold to quantify high-level cognition, and guide the\ndevelopment of next-generation embodied MLLMs. The project page is in\nhttps://robo-bench.github.io.", "AI": {"tldr": "\u63d0\u51fa\u4e86RoboBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5177\u8eab\u5927\u8111\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u8ba4\u77e5\u80fd\u529b\uff0c\u6db5\u76d65\u4e2a\u7ef4\u5ea6\u300114\u79cd\u80fd\u529b\u300125\u4e2a\u4efb\u52a1\u548c6092\u4e2a\u95ee\u7b54\u5bf9\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u6267\u884c\u6210\u529f\u7387\uff0c\u6216\u5728\u9ad8\u5c42\u6b21\u63a8\u7406\u65b9\u9762\u5b58\u5728\u7ef4\u5ea6\u4e0d\u5b8c\u6574\u548c\u4efb\u52a1\u771f\u5b9e\u6027\u6709\u9650\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u8ba4\u77e5\u80fd\u529b\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5177\u8eab\u5927\u8111\u5728\u5b8c\u6574\u64cd\u4f5c\u6d41\u7a0b\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "method": "\u6784\u5efaRoboBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9a\u4e495\u4e2a\u7ef4\u5ea6\uff1a\u6307\u4ee4\u7406\u89e3\u3001\u611f\u77e5\u63a8\u7406\u3001\u6cdb\u5316\u89c4\u5212\u3001\u529f\u80fd\u9884\u6d4b\u548c\u5931\u8d25\u5206\u6790\u3002\u4f7f\u7528\u591a\u6837\u5316\u5177\u8eab\u7cfb\u7edf\u3001\u5c5e\u6027\u4e30\u5bcc\u7684\u7269\u4f53\u548c\u591a\u89c6\u89d2\u573a\u666f\u7684\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\u3002\u4e3a\u89c4\u5212\u8bc4\u4f30\u5f15\u5165MLLM-as-world-simulator\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u9884\u6d4b\u8ba1\u5212\u662f\u5426\u80fd\u5b9e\u73b0\u5173\u952e\u7269\u4f53\u72b6\u6001\u53d8\u5316\u6765\u8bc4\u4f30\u5177\u8eab\u53ef\u884c\u6027\u3002", "result": "\u5bf914\u4e2aMLLM\u7684\u5b9e\u9a8c\u63ed\u793a\u4e86\u57fa\u672c\u5c40\u9650\u6027\uff1a\u5728\u9690\u5f0f\u6307\u4ee4\u7406\u89e3\u3001\u65f6\u7a7a\u63a8\u7406\u3001\u8de8\u573a\u666f\u89c4\u5212\u3001\u7ec6\u7c92\u5ea6\u529f\u80fd\u7406\u89e3\u548c\u6267\u884c\u5931\u8d25\u8bca\u65ad\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "RoboBench\u4e3a\u91cf\u5316\u9ad8\u5c42\u6b21\u8ba4\u77e5\u63d0\u4f9b\u4e86\u5168\u9762\u6846\u67b6\uff0c\u53ef\u6307\u5bfc\u4e0b\u4e00\u4ee3\u5177\u8eabMLLM\u7684\u5f00\u53d1\u3002"}}
{"id": "2510.16756", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.16756", "abs": "https://arxiv.org/abs/2510.16756", "authors": ["Siyin Wang", "Wenyi Yu", "Xianzhao Chen", "Xiaohai Tian", "Jun Zhang", "Lu Lu", "Chao Zhang"], "title": "End-to-end Listen, Look, Speak and Act", "comment": "22 pages, 8 figures", "summary": "Human interaction is inherently multimodal and full-duplex: we listen while\nwatching, speak while acting, and fluidly adapt to turn-taking and\ninterruptions. Realizing these capabilities is essential for building models\nsimulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),\nwhich, to our knowledge, is the first full-duplex, end-to-end model that\nsimultaneously perceives and generates across vision, text, speech, and action\nwithin a single architecture, enabling interaction patterns previously out of\nreach, yielding more natural, human-like behaviors. At its core is a novel\nSA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each\nmodality to specialized experts and fuses them through a unified attention\nbackbone. This provides a generalizable solution for joint multimodal\nperception and concurrent generation, leveraging strong pre-trained components\nwhile enabling efficient modality integration and mitigating modality\ninterference. On speech-interaction and robot-manipulation benchmarks, ELLSA\nmatches modality-specific baselines, while uniquely supporting advanced\nmultimodal and full-duplex behaviors such as dialogue and action turn-taking,\ndefective instruction rejection, speaking-while-acting, context-grounded visual\nquestion answering, and action barge-ins. We contend that ELLSA represents a\nstep toward more natural and general interactive intelligence, contributing to\nthe broader pursuit of artificial general intelligence. All data, code and\nmodel checkpoints will be released upon acceptance.", "AI": {"tldr": "ELLSA\u662f\u9996\u4e2a\u5168\u53cc\u5de5\u3001\u7aef\u5230\u7aef\u7684\u591a\u6a21\u6001\u6a21\u578b\uff0c\u80fd\u591f\u540c\u65f6\u611f\u77e5\u548c\u751f\u6210\u89c6\u89c9\u3001\u6587\u672c\u3001\u8bed\u97f3\u548c\u52a8\u4f5c\uff0c\u5b9e\u73b0\u66f4\u81ea\u7136\u7684\u4eba\u673a\u4ea4\u4e92\u3002", "motivation": "\u4eba\u7c7b\u4ea4\u4e92\u672c\u8d28\u4e0a\u662f\u591a\u6a21\u6001\u548c\u5168\u53cc\u5de5\u7684\uff0c\u9700\u8981\u6a21\u578b\u80fd\u591f\u540c\u65f6\u611f\u77e5\u548c\u751f\u6210\u591a\u79cd\u6a21\u6001\uff0c\u5b9e\u73b0\u66f4\u81ea\u7136\u7684\u4eba\u7c7b\u884c\u4e3a\u6a21\u62df\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684SA-MoE\u67b6\u6784\uff08\u81ea\u6ce8\u610f\u529b\u4e13\u5bb6\u6df7\u5408\uff09\uff0c\u5c06\u5404\u6a21\u6001\u8def\u7531\u5230\u4e13\u7528\u4e13\u5bb6\uff0c\u901a\u8fc7\u7edf\u4e00\u6ce8\u610f\u529b\u9aa8\u5e72\u7f51\u7edc\u8fdb\u884c\u878d\u5408\u3002", "result": "\u5728\u8bed\u97f3\u4ea4\u4e92\u548c\u673a\u5668\u4eba\u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cELLSA\u4e0e\u7279\u5b9a\u6a21\u6001\u57fa\u7ebf\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u652f\u6301\u9ad8\u7ea7\u591a\u6a21\u6001\u548c\u5168\u53cc\u5de5\u884c\u4e3a\u3002", "conclusion": "ELLSA\u4ee3\u8868\u4e86\u5411\u66f4\u81ea\u7136\u548c\u901a\u7528\u4ea4\u4e92\u667a\u80fd\u8fc8\u51fa\u7684\u4e00\u6b65\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u4eba\u5de5\u901a\u7528\u667a\u80fd\u7684\u8ffd\u6c42\u3002"}}
{"id": "2510.17382", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17382", "abs": "https://arxiv.org/abs/2510.17382", "authors": ["Rishabh Jain", "Keisuke Okumura", "Michael Amir", "Amanda Prorok"], "title": "Graph Attention-Guided Search for Dense Multi-Agent Pathfinding", "comment": null, "summary": "Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)\nproblems in real-time remains challenging even for state-of-the-art planners.\nTo this end, we develop a hybrid framework that integrates a learned heuristic\nderived from MAGAT, a neural MAPF policy with a graph attention scheme, into a\nleading search-based algorithm, LaCAM. While prior work has explored\nlearning-guided search in MAPF, such methods have historically underperformed.\nIn contrast, our approach, termed LaGAT, outperforms both purely search-based\nand purely learning-based methods in dense scenarios. This is achieved through\nan enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of\ninterest, and a deadlock detection scheme to account for imperfect neural\nguidance. Our results demonstrate that, when carefully designed, hybrid search\noffers a powerful solution for tightly coupled, challenging multi-agent\ncoordination problems.", "AI": {"tldr": "\u63d0\u51faLaGAT\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u7684\u795e\u7ecfMAPF\u7b56\u7565MAGAT\u96c6\u6210\u5230\u641c\u7d22\u7b97\u6cd5LaCAM\u4e2d\uff0c\u5728\u5bc6\u96c6\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u573a\u666f\u4e2d\u4f18\u4e8e\u7eaf\u641c\u7d22\u548c\u7eaf\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u5bc6\u96c6\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u95ee\u9898\u5728\u5b9e\u65f6\u573a\u666f\u4e2d\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u5728MAPF\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u7ed3\u5408\u5b66\u4e60\u4e0e\u641c\u7d22\u7684\u4f18\u52bf\u3002", "method": "\u589e\u5f3aMAGAT\u67b6\u6784\uff0c\u91c7\u7528\u9884\u8bad\u7ec3-\u5fae\u8c03\u7b56\u7565\uff0c\u7ed3\u5408\u6b7b\u9501\u68c0\u6d4b\u673a\u5236\u6765\u5904\u7406\u4e0d\u5b8c\u7f8e\u7684\u795e\u7ecf\u5f15\u5bfc\uff0c\u5c06\u5b66\u4e60\u542f\u53d1\u5f0f\u96c6\u6210\u5230LaCAM\u641c\u7d22\u7b97\u6cd5\u4e2d\u3002", "result": "LaGAT\u5728\u5bc6\u96c6\u573a\u666f\u4e2d\u8d85\u8d8a\u4e86\u7eaf\u641c\u7d22\u65b9\u6cd5\u548c\u7eaf\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u6df7\u5408\u641c\u7d22\u5728\u7d27\u5bc6\u8026\u5408\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6df7\u5408\u641c\u7d22\u65b9\u6cd5\u4e3a\u89e3\u51b3\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u95ee\u9898\u63d0\u4f9b\u4e86\u5f3a\u5927\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15948", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.15948", "abs": "https://arxiv.org/abs/2510.15948", "authors": ["MingSheng Li", "Guangze Zhao", "Sichen Liu"], "title": "VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search", "comment": null, "summary": "Large Vision-Language Models (LVLMs) have achieved remarkable progress in\nmultimodal perception and generation, yet their safety alignment remains a\ncritical challenge.Existing defenses and vulnerable to multimodal jailbreaks,\nas visual inputs introduce new attack surfaces, reasoning chains lack safety\nsupervision, and alignment often degrades under modality fusion.To overcome\nthese limitation, we propose VisuoAlign, a framework for multi-modal safety\nalignment via prompt-guided tree search.VisuoAlign embeds safety constrains\ninto the reasoning process through visual-textual interactive prompts, employs\nMonte Carlo Tree Search(MCTS) to systematically construct diverse\nsafety-critical prompt trajectories, and introduces prompt-based scaling to\nensure real-time risk detection and compliant responses.Extensive experiments\ndemonstrate that VisuoAlign proactively exposes risks, enables comprehensive\ndataset generation, and significantly improves the robustness of LVLMs against\ncomplex cross-modal threats.", "AI": {"tldr": "VisuoAlign\u662f\u4e00\u4e2a\u901a\u8fc7\u63d0\u793a\u5f15\u5bfc\u6811\u641c\u7d22\u5b9e\u73b0\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u7684\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5bf9\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u8106\u5f31\uff0c\u56e0\u4e3a\u89c6\u89c9\u8f93\u5165\u5f15\u5165\u65b0\u7684\u653b\u51fb\u9762\uff0c\u63a8\u7406\u94fe\u7f3a\u4e4f\u5b89\u5168\u76d1\u7763\uff0c\u6a21\u6001\u878d\u5408\u4f1a\u964d\u4f4e\u5bf9\u9f50\u6548\u679c\u3002", "method": "\u901a\u8fc7\u89c6\u89c9-\u6587\u672c\u4ea4\u4e92\u63d0\u793a\u5c06\u5b89\u5168\u7ea6\u675f\u5d4c\u5165\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efa\u591a\u6837\u5316\u7684\u5b89\u5168\u5173\u952e\u63d0\u793a\u8f68\u8ff9\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u63d0\u793a\u7684\u7f29\u653e\u786e\u4fdd\u5b9e\u65f6\u98ce\u9669\u68c0\u6d4b\u548c\u5408\u89c4\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660eVisuoAlign\u80fd\u4e3b\u52a8\u66b4\u9732\u98ce\u9669\uff0c\u5b9e\u73b0\u5168\u9762\u7684\u6570\u636e\u96c6\u751f\u6210\uff0c\u5e76\u663e\u8457\u63d0\u5347LVLMs\u5bf9\u590d\u6742\u8de8\u6a21\u6001\u5a01\u80c1\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "VisuoAlign\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u5b89\u5168\u9632\u62a4\u80fd\u529b\u3002"}}
{"id": "2510.15952", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15952", "abs": "https://arxiv.org/abs/2510.15952", "authors": ["Myung Ho Kim"], "title": "Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding", "comment": "27 pages", "summary": "Large language models exhibit intelligence without genuine epistemic\nunderstanding, exposing a key gap: the absence of epistemic architecture. This\npaper introduces the Structured Cognitive Loop (SCL) as an executable\nepistemological framework for emergent intelligence. Unlike traditional AI\nresearch asking \"what is intelligence?\" (ontological), SCL asks \"under what\nconditions does cognition emerge?\" (epistemological). Grounded in philosophy of\nmind and cognitive phenomenology, SCL bridges conceptual philosophy and\nimplementable cognition. Drawing on process philosophy, enactive cognition, and\nextended mind theory, we define intelligence not as a property but as a\nperformed process -- a continuous loop of judgment, memory, control, action,\nand regulation. SCL makes three contributions. First, it operationalizes\nphilosophical insights into computationally interpretable structures, enabling\n\"executable epistemology\" -- philosophy as structural experiment. Second, it\nshows that functional separation within cognitive architecture yields more\ncoherent and interpretable behavior than monolithic prompt based systems,\nsupported by agent evaluations. Third, it redefines intelligence: not\nrepresentational accuracy but the capacity to reconstruct its own epistemic\nstate through intentional understanding. This framework impacts philosophy of\nmind, epistemology, and AI. For philosophy, it allows theories of cognition to\nbe enacted and tested. For AI, it grounds behavior in epistemic structure\nrather than statistical regularity. For epistemology, it frames knowledge not\nas truth possession but as continuous reconstruction within a\nphenomenologically coherent loop. We situate SCL within debates on cognitive\nphenomenology, emergence, normativity, and intentionality, arguing that real\nprogress requires not larger models but architectures that realize cognitive\nprinciples structurally.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u8ba4\u77e5\u5faa\u73af\uff08SCL\uff09\u4f5c\u4e3a\u53ef\u6267\u884c\u7684\u8ba4\u8bc6\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u6d8c\u73b0\u667a\u80fd\uff0c\u5c06\u54f2\u5b66\u6d1e\u89c1\u8f6c\u5316\u4e3a\u53ef\u8ba1\u7b97\u7ed3\u6784\uff0c\u91cd\u65b0\u5b9a\u4e49\u667a\u80fd\u4e3a\u901a\u8fc7\u610f\u5411\u6027\u7406\u89e3\u91cd\u6784\u81ea\u8eab\u8ba4\u77e5\u72b6\u6001\u7684\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u771f\u6b63\u7684\u8ba4\u77e5\u7406\u89e3\uff0c\u66b4\u9732\u4e86\u8ba4\u77e5\u67b6\u6784\u7684\u7f3a\u5931\u3002\u4f20\u7edfAI\u7814\u7a76\u5173\u6ce8\u667a\u80fd\u7684\u672c\u8d28\uff08\u672c\u4f53\u8bba\uff09\uff0c\u800cSCL\u5173\u6ce8\u8ba4\u77e5\u6d8c\u73b0\u7684\u6761\u4ef6\uff08\u8ba4\u8bc6\u8bba\uff09\uff0c\u65e8\u5728\u5f25\u5408\u6982\u5ff5\u54f2\u5b66\u4e0e\u53ef\u5b9e\u65bd\u8ba4\u77e5\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "method": "\u57fa\u4e8e\u8fc7\u7a0b\u54f2\u5b66\u3001\u5177\u8eab\u8ba4\u77e5\u548c\u6269\u5c55\u5fc3\u667a\u7406\u8bba\uff0cSCL\u5c06\u667a\u80fd\u5b9a\u4e49\u4e3a\u6267\u884c\u8fc7\u7a0b\u800c\u975e\u5c5e\u6027\u2014\u2014\u5305\u542b\u5224\u65ad\u3001\u8bb0\u5fc6\u3001\u63a7\u5236\u3001\u884c\u52a8\u548c\u8c03\u8282\u7684\u8fde\u7eed\u5faa\u73af\u3002\u901a\u8fc7\u529f\u80fd\u5206\u79bb\u7684\u8ba4\u77e5\u67b6\u6784\u5b9e\u73b0\"\u53ef\u6267\u884c\u8ba4\u8bc6\u8bba\"\u3002", "result": "SCL\u5c55\u793a\u4e86\u529f\u80fd\u5206\u79bb\u7684\u8ba4\u77e5\u67b6\u6784\u6bd4\u5355\u4e00\u63d0\u793a\u7cfb\u7edf\u4ea7\u751f\u66f4\u8fde\u8d2f\u548c\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\uff0c\u652f\u6301\u667a\u80fd\u7684\u91cd\u6784\u80fd\u529b\u800c\u975e\u8868\u5f81\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5bf9\u5fc3\u667a\u54f2\u5b66\u3001\u8ba4\u8bc6\u8bba\u548cAI\u4ea7\u751f\u5f71\u54cd\uff0c\u5f3a\u8c03\u771f\u6b63\u8fdb\u6b65\u9700\u8981\u5b9e\u73b0\u8ba4\u77e5\u539f\u5219\u7684\u7ed3\u6784\u5316\u67b6\u6784\uff0c\u800c\u975e\u66f4\u5927\u7684\u6a21\u578b\u3002\u77e5\u8bc6\u88ab\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u73b0\u8c61\u5b66\u8fde\u8d2f\u5faa\u73af\u4e2d\u7684\u6301\u7eed\u91cd\u6784\u3002"}}
{"id": "2510.15966", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15966", "abs": "https://arxiv.org/abs/2510.15966", "authors": ["Shian Jia", "Ziyang Huang", "Xinbo Wang", "Haofei Zhang", "Mingli Song"], "title": "PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency", "comment": null, "summary": "Memory systems are fundamental to AI agents, yet existing work often lacks\nadaptability to diverse tasks and overlooks the constructive and task-oriented\nrole of AI agent memory. Drawing from Piaget's theory of cognitive development,\nwe propose PISA, a pragmatic, psych-inspired unified memory system that\naddresses these limitations by treating memory as a constructive and adaptive\nprocess. To enable continuous learning and adaptability, PISA introduces a\ntrimodal adaptation mechanism (i.e., schema updation, schema evolution, and\nschema creation) that preserves coherent organization while supporting flexible\nmemory updates. Building on these schema-grounded structures, we further design\na hybrid memory access architecture that seamlessly integrates symbolic\nreasoning with neural retrieval, significantly improving retrieval accuracy and\nefficiency. Our empirical evaluation, conducted on the existing LOCOMO\nbenchmark and our newly proposed AggQA benchmark for data analysis tasks,\nconfirms that PISA sets a new state-of-the-art by significantly enhancing\nadaptability and long-term knowledge retention.", "AI": {"tldr": "PISA\u662f\u4e00\u4e2a\u53d7\u76ae\u4e9a\u6770\u8ba4\u77e5\u53d1\u5c55\u7406\u8bba\u542f\u53d1\u7684\u7edf\u4e00\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u6a21\u6001\u9002\u5e94\u673a\u5236\u548c\u6df7\u5408\u8bb0\u5fc6\u8bbf\u95ee\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u4ee3\u7406\u7684\u9002\u5e94\u6027\u548c\u957f\u671f\u77e5\u8bc6\u4fdd\u6301\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u591a\u6837\u5316\u4efb\u52a1\u7684\u9002\u5e94\u6027\uff0c\u4e14\u5ffd\u89c6\u4e86\u8bb0\u5fc6\u7684\u5efa\u8bbe\u6027\u548c\u4efb\u52a1\u5bfc\u5411\u4f5c\u7528\u3002", "method": "\u63d0\u51faPISA\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u6a21\u6001\u9002\u5e94\u673a\u5236\uff08\u6a21\u5f0f\u66f4\u65b0\u3001\u6a21\u5f0f\u6f14\u5316\u548c\u6a21\u5f0f\u521b\u5efa\uff09\u548c\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u4e0e\u795e\u7ecf\u68c0\u7d22\u7684\u6df7\u5408\u8bb0\u5fc6\u8bbf\u95ee\u67b6\u6784\u3002", "result": "\u5728LOCOMO\u57fa\u51c6\u548c\u65b0\u63d0\u51fa\u7684AggQA\u57fa\u51c6\u4e0a\uff0cPISA\u5728\u6570\u636e\u5206\u6790\u548c\u957f\u671f\u77e5\u8bc6\u4fdd\u6301\u65b9\u9762\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "PISA\u901a\u8fc7\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u5efa\u8bbe\u6027\u548c\u9002\u5e94\u6027\u8fc7\u7a0b\uff0c\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9002\u5e94\u6027\u548c\u77e5\u8bc6\u4fdd\u6301\u80fd\u529b\u3002"}}
{"id": "2510.15974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15974", "abs": "https://arxiv.org/abs/2510.15974", "authors": ["Chris Su", "Harrison Li", "Matheus Marques", "George Flint", "Kevin Zhu", "Sunishchal Dev"], "title": "Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games", "comment": null, "summary": "Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in\nperformance on solving puzzles beyond certain perplexity thresholds. In\nsubsequent discourse, questions have arisen as to whether the nature of the\ntask muddles an evaluation of true reasoning. One potential confound is the\nrequirement that the model keep track of the state space on its own. We provide\na large language model (LLM) with an environment interface for Tower of Hanoi\nproblems, allowing it to make a move with a tool call, provide written\njustification, observe the resulting state space, and reprompt itself for the\nnext move. We observe that access to an environment interface does not delay or\neradicate performance collapse. Furthermore, LLM-parameterized policy analysis\nreveals increasing divergence from both optimal policies and uniformly random\npolicies, suggesting that the model exhibits mode-like collapse at each level\nof complexity, and that performance is dependent upon whether the mode reflects\nthe correct solution for the problem. We suggest that a similar phenomena might\ntake place in LRMs.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u73af\u5883\u63a5\u53e3\u5e76\u4e0d\u80fd\u89e3\u51b3\u5176\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5d29\u6e83\u95ee\u9898\uff0c\u6a21\u578b\u5728\u8d85\u8d8a\u7279\u5b9a\u590d\u6742\u5ea6\u9608\u503c\u65f6\u4ecd\u4f1a\u51fa\u73b0\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u8c1c\u9898\u65f6\u6027\u80fd\u5d29\u6e83\u7684\u771f\u6b63\u539f\u56e0\uff0c\u9a8c\u8bc1\u73af\u5883\u72b6\u6001\u8ddf\u8e2a\u662f\u5426\u662f\u8be5\u95ee\u9898\u7684\u5173\u952e\u6df7\u6dc6\u56e0\u7d20\u3002", "method": "\u4e3aLLM\u63d0\u4f9b\u6cb3\u5185\u5854\u95ee\u9898\u7684\u73af\u5883\u63a5\u53e3\uff0c\u5141\u8bb8\u6a21\u578b\u901a\u8fc7\u5de5\u5177\u8c03\u7528\u8fdb\u884c\u79fb\u52a8\u3001\u63d0\u4f9b\u4e66\u9762\u7406\u7531\u3001\u89c2\u5bdf\u72b6\u6001\u7a7a\u95f4\u5e76\u91cd\u65b0\u63d0\u793a\u4e0b\u4e00\u6b65\u3002", "result": "\u73af\u5883\u63a5\u53e3\u8bbf\u95ee\u5e76\u4e0d\u80fd\u5ef6\u8fdf\u6216\u6d88\u9664\u6027\u80fd\u5d29\u6e83\uff0c\u7b56\u7565\u5206\u6790\u663e\u793a\u6a21\u578b\u4e0e\u6700\u4f18\u7b56\u7565\u548c\u968f\u673a\u7b56\u7565\u7684\u504f\u79bb\u5ea6\u589e\u52a0\uff0c\u51fa\u73b0\u6a21\u5f0f\u5d29\u6e83\u73b0\u8c61\u3002", "conclusion": "\u6027\u80fd\u5d29\u6e83\u73b0\u8c61\u53ef\u80fd\u6e90\u4e8e\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6a21\u5f0f\u5d29\u6e83\uff0c\u800c\u975e\u72b6\u6001\u8ddf\u8e2a\u80fd\u529b\u4e0d\u8db3\uff0c\u7c7b\u4f3c\u73b0\u8c61\u53ef\u80fd\u4e5f\u5b58\u5728\u4e8e\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u3002"}}
{"id": "2510.15980", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15980", "abs": "https://arxiv.org/abs/2510.15980", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition", "comment": null, "summary": "We propose \\textbf{Cognitive Load Traces} (CLTs) as a mid-level\ninterpretability framework for deep models, inspired by Cognitive Load Theory\nin human cognition. CLTs are defined as symbolic, temporally varying functions\nthat quantify model-internal resource allocation. Formally, we represent CLTs\nas a three-component stochastic process $(\\mathrm{IL}_t, \\mathrm{EL}_t,\n\\mathrm{GL}_t)$, corresponding to \\emph{Intrinsic}, \\emph{Extraneous}, and\n\\emph{Germane} load. Each component is instantiated through measurable proxies\nsuch as attention entropy, KV-cache miss ratio, representation dispersion, and\ndecoding stability. We propose both symbolic formulations and visualization\nmethods (load curves, simplex diagrams) that enable interpretable analysis of\nreasoning dynamics. Experiments on reasoning and planning benchmarks show that\nCLTs predict error-onset, reveal cognitive strategies, and enable load-guided\ninterventions that improve reasoning efficiency by 15-30\\% while maintaining\naccuracy.", "AI": {"tldr": "\u63d0\u51faCognitive Load Traces (CLTs)\u4f5c\u4e3a\u6df1\u5ea6\u6a21\u578b\u7684\u4e2d\u5c42\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u5c06\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u5e94\u7528\u4e8eAI\u6a21\u578b\uff0c\u901a\u8fc7\u7b26\u53f7\u5316\u3001\u65f6\u53d8\u51fd\u6570\u91cf\u5316\u6a21\u578b\u5185\u90e8\u8d44\u6e90\u5206\u914d\uff0c\u5305\u542b\u5185\u5728\u3001\u5916\u5728\u548c\u5173\u8054\u8d1f\u8377\u4e09\u4e2a\u5206\u91cf\u3002", "motivation": "\u53d7\u4eba\u7c7b\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u542f\u53d1\uff0c\u65e8\u5728\u4e3a\u6df1\u5ea6\u6a21\u578b\u63d0\u4f9b\u66f4\u53ef\u89e3\u91ca\u7684\u5185\u90e8\u8d44\u6e90\u5206\u914d\u5206\u6790\u6846\u67b6\uff0c\u5e2e\u52a9\u7406\u89e3\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8ba4\u77e5\u7b56\u7565\u548c\u6548\u7387\u95ee\u9898\u3002", "method": "\u5c06CLTs\u5b9a\u4e49\u4e3a\u4e09\u7ec4\u5206\u968f\u673a\u8fc7\u7a0b(IL_t, EL_t, GL_t)\uff0c\u5206\u522b\u5bf9\u5e94\u5185\u5728\u3001\u5916\u5728\u548c\u5173\u8054\u8d1f\u8377\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u71b5\u3001KV\u7f13\u5b58\u672a\u547d\u4e2d\u7387\u3001\u8868\u793a\u5206\u6563\u5ea6\u548c\u89e3\u7801\u7a33\u5b9a\u6027\u7b49\u53ef\u6d4b\u91cf\u4ee3\u7406\u6765\u5b9e\u4f8b\u5316\uff0c\u5e76\u63d0\u51fa\u7b26\u53f7\u516c\u5f0f\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u63a8\u7406\u548c\u89c4\u5212\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCLTs\u80fd\u591f\u9884\u6d4b\u9519\u8bef\u53d1\u751f\u3001\u63ed\u793a\u8ba4\u77e5\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u8d1f\u8377\u5f15\u5bfc\u7684\u5e72\u9884\u63aa\u65bd\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5c06\u63a8\u7406\u6548\u7387\u63d0\u9ad815-30%\u3002", "conclusion": "CLTs\u6846\u67b6\u4e3a\u6df1\u5ea6\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\u5de5\u5177\uff0c\u80fd\u591f\u91cf\u5316\u8ba4\u77e5\u8d1f\u8377\u5e76\u6307\u5bfc\u6a21\u578b\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2510.15981", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.15981", "abs": "https://arxiv.org/abs/2510.15981", "authors": ["Rafael Cabral", "Tuan Manh Do", "Xuejun Yu", "Wai Ming Tai", "Zijin Feng", "Xin Shen"], "title": "ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization", "comment": null, "summary": "Proof autoformalization, the task of translating natural language theorems\nand proofs into machine-verifiable code, is a critical step for integrating\nlarge language models into rigorous mathematical workflows. Current approaches\nfocus on producing executable code, but they frequently fail to preserve the\nsemantic meaning and logical structure of the original human-written argument.\nTo address this, we introduce ProofFlow, a novel pipeline that treats\nstructural fidelity as a primary objective. ProofFlow first constructs a\ndirected acyclic graph (DAG) to map the logical dependencies between proof\nsteps. Then, it employs a novel lemma-based approach to systematically\nformalize each step as an intermediate lemma, preserving the logical structure\nof the original argument. To facilitate evaluation, we present a new benchmark\nof 184 undergraduate-level problems, manually annotated with step-by-step\nsolutions and logical dependency graphs, and introduce ProofScore, a new\ncomposite metric to evaluate syntactic correctness, semantic faithfulness, and\nstructural fidelity. Experimental results show our pipeline sets a new\nstate-of-the-art for autoformalization, achieving a ProofScore of 0.545,\nsubstantially exceeding baselines like full-proof formalization (0.123), which\nprocesses the entire proof at once, and step-proof formalization (0.072), which\nhandles each step independently. Our pipeline, benchmark, and score metric are\nopen-sourced to encourage further progress at\nhttps://github.com/Huawei-AI4Math/ProofFlow.", "AI": {"tldr": "ProofFlow\u662f\u4e00\u4e2a\u65b0\u7684\u8bc1\u660e\u81ea\u52a8\u5f62\u5f0f\u5316\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u6784\u5efa\u903b\u8f91\u4f9d\u8d56\u56fe\u548c\u4f7f\u7528\u57fa\u4e8e\u5f15\u7406\u7684\u65b9\u6cd5\u6765\u4fdd\u6301\u539f\u59cb\u8bc1\u660e\u7684\u7ed3\u6784\u4fdd\u771f\u5ea6\uff0c\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u7684\u8bc1\u660e\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u867d\u7136\u80fd\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u4f46\u7ecf\u5e38\u65e0\u6cd5\u4fdd\u6301\u539f\u59cb\u8bc1\u660e\u7684\u8bed\u4e49\u542b\u4e49\u548c\u903b\u8f91\u7ed3\u6784\uff0c\u8fd9\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e25\u683c\u6570\u5b66\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u96c6\u6210\u3002", "method": "ProofFlow\u9996\u5148\u6784\u5efa\u6709\u5411\u65e0\u73af\u56fe\u6765\u6620\u5c04\u8bc1\u660e\u6b65\u9aa4\u95f4\u7684\u903b\u8f91\u4f9d\u8d56\u5173\u7cfb\uff0c\u7136\u540e\u91c7\u7528\u57fa\u4e8e\u5f15\u7406\u7684\u65b9\u6cd5\u7cfb\u7edf\u5730\u5c06\u6bcf\u4e2a\u6b65\u9aa4\u5f62\u5f0f\u5316\u4e3a\u4e2d\u95f4\u5f15\u7406\uff0c\u4ece\u800c\u4fdd\u6301\u539f\u59cb\u8bba\u8bc1\u7684\u903b\u8f91\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aProofFlow\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0cProofScore\u5f97\u5206\u4e3a0.545\uff0c\u663e\u8457\u4f18\u4e8e\u5168\u8bc1\u660e\u5f62\u5f0f\u5316\uff080.123\uff09\u548c\u6b65\u9aa4\u8bc1\u660e\u5f62\u5f0f\u5316\uff080.072\uff09\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ProofFlow\u901a\u8fc7\u5173\u6ce8\u7ed3\u6784\u4fdd\u771f\u5ea6\u663e\u8457\u63d0\u5347\u4e86\u8bc1\u660e\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u8d28\u91cf\uff0c\u5176\u6d41\u6c34\u7ebf\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u5206\u6307\u6807\u5df2\u5f00\u6e90\uff0c\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2510.15983", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15983", "abs": "https://arxiv.org/abs/2510.15983", "authors": ["Sarah Rebecca Ondraszek", "J\u00f6rg Waitelonis", "Katja Keller", "Claudia Niessner", "Anna M. Jacyszyn", "Harald Sack"], "title": "Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science", "comment": "10 pages, 2 figures. Camera-ready version. Accepted to the 5th\n  International Workshop on Scientific Knowledge: Representation, Discovery,\n  and Assessment; 2 November 2025 - Nara, Japan; co-located with The 24th\n  International Semantic Web Conference, ISWC 2025. To be published in CEUR\n  proceedings", "summary": "An essential component for evaluating and comparing physical and cognitive\ncapabilities between populations is the testing of various factors related to\nhuman performance. As a core part of sports science research, testing motor\nperformance enables the analysis of the physical health of different\ndemographic groups and makes them comparable.\n  The Motor Research (MO|RE) data repository, developed at the Karlsruhe\nInstitute of Technology, is an infrastructure for publishing and archiving\nresearch data in sports science, particularly in the field of motor performance\nresearch. In this paper, we present our vision for creating a knowledge graph\nfrom MO|RE data. With an ontology rooted in the Basic Formal Ontology, our\napproach centers on formally representing the interrelation of plan\nspecifications, specific processes, and related measurements. Our goal is to\ntransform how motor performance data are modeled and shared across studies,\nmaking it standardized and machine-understandable. The idea presented here is\ndeveloped within the Leibniz Science Campus ``Digital Transformation of\nResearch'' (DiTraRe).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5c06MO|RE\u8fd0\u52a8\u79d1\u5b66\u7814\u7a76\u6570\u636e\u4ed3\u5e93\u8f6c\u6362\u4e3a\u77e5\u8bc6\u56fe\u8c31\u7684\u613f\u666f\uff0c\u65e8\u5728\u6807\u51c6\u5316\u548c\u673a\u5668\u53ef\u7406\u89e3\u5730\u5efa\u6a21\u548c\u5171\u4eab\u8fd0\u52a8\u8868\u73b0\u6570\u636e\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u4eba\u7fa4\u7684\u8eab\u4f53\u548c\u8ba4\u77e5\u80fd\u529b\uff0c\u9700\u8981\u6d4b\u8bd5\u4e0e\u4eba\u7c7b\u8868\u73b0\u76f8\u5173\u7684\u5404\u79cd\u56e0\u7d20\u3002\u8fd0\u52a8\u8868\u73b0\u6d4b\u8bd5\u4f5c\u4e3a\u4f53\u80b2\u79d1\u5b66\u7814\u7a76\u7684\u6838\u5fc3\u90e8\u5206\uff0c\u80fd\u591f\u5206\u6790\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u7684\u8eab\u4f53\u5065\u5eb7\u72b6\u51b5\u5e76\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u57fa\u672c\u5f62\u5f0f\u672c\u4f53\u8bba\u7684\u672c\u4f53\uff0c\u91cd\u70b9\u5f62\u5f0f\u5316\u8868\u793a\u8ba1\u5212\u89c4\u8303\u3001\u7279\u5b9a\u8fc7\u7a0b\u548c\u76f8\u5173\u6d4b\u91cf\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u3002", "result": "\u63d0\u51fa\u4e86\u5c06MO|RE\u6570\u636e\u4ed3\u5e93\u8f6c\u6362\u4e3a\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\uff0c\u4f7f\u8fd0\u52a8\u8868\u73b0\u6570\u636e\u80fd\u591f\u6807\u51c6\u5316\u548c\u673a\u5668\u53ef\u7406\u89e3\u5730\u8de8\u7814\u7a76\u5171\u4eab\u3002", "conclusion": "\u8be5\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\u5c06\u6539\u53d8\u8fd0\u52a8\u8868\u73b0\u6570\u636e\u7684\u5efa\u6a21\u548c\u5171\u4eab\u65b9\u5f0f\uff0c\u4f7f\u5176\u66f4\u52a0\u6807\u51c6\u5316\u548c\u673a\u5668\u53ef\u7406\u89e3\uff0c\u8fd9\u662f\u5728Leibniz\u79d1\u5b66\u56ed\u533a\"\u7814\u7a76\u6570\u5b57\u5316\u8f6c\u578b\"\u9879\u76ee\u5185\u5f00\u53d1\u7684\u3002"}}
{"id": "2510.16001", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16001", "abs": "https://arxiv.org/abs/2510.16001", "authors": ["Ruolan Cheng", "Yong Deng", "Enrique Herrera-Viedma"], "title": "A Non-overlap-based Conflict Measure for Random Permutation Sets", "comment": null, "summary": "Random permutation set (RPS) is a new formalism for reasoning with\nuncertainty involving order information. Measuring the conflict between two\npieces of evidence represented by permutation mass functions remains an urgent\nresearch topic in order-structured uncertain information fusion. In this paper,\na detailed analysis of conflicts in RPS is carried out from two different\nperspectives: random finite set (RFS) and Dempster-Shafer theory (DST).\nStarting from the observation of permutations, we first define an inconsistency\nmeasure between permutations inspired by the rank-biased overlap(RBO) measure\nand further propose a non-overlap-based conflict measure method for RPSs. This\npaper regards RPS theory (RPST) as an extension of DST. The order information\nnewly added in focal sets indicates qualitative propensity, characterized by\ntop-ranked elements occupying a more critical position. Some numerical examples\nare used to demonstrate the behavior and properties of the proposed conflict\nmeasure. The proposed method not only has the natural top-weightedness property\nand can effectively measure the conflict between RPSs from the DST view but\nalso provides decision-makers with a flexible selection of weights, parameters,\nand truncated depths.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u7f6e\u6362\u96c6(RPS)\u7684\u51b2\u7a81\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4ece\u968f\u673a\u6709\u9650\u96c6(RFS)\u548cDempster-Shafer\u7406\u8bba(DST)\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790RPS\u4e2d\u7684\u51b2\u7a81\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u79e9\u504f\u91cd\u53e0(RBO)\u7684\u4e0d\u4e00\u81f4\u6027\u5ea6\u91cf\u3002", "motivation": "\u968f\u673a\u7f6e\u6362\u96c6\u662f\u5904\u7406\u5305\u542b\u987a\u5e8f\u4fe1\u606f\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u65b0\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u9700\u8981\u89e3\u51b3\u5982\u4f55\u5ea6\u91cf\u7531\u7f6e\u6362\u8d28\u91cf\u51fd\u6570\u8868\u793a\u7684\u4e24\u4e2a\u8bc1\u636e\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u8fd9\u662f\u987a\u5e8f\u7ed3\u6784\u4e0d\u786e\u5b9a\u4fe1\u606f\u878d\u5408\u4e2d\u7684\u5173\u952e\u7814\u7a76\u95ee\u9898\u3002", "method": "\u4ece\u7f6e\u6362\u89c2\u5bdf\u51fa\u53d1\uff0c\u57fa\u4e8e\u79e9\u504f\u91cd\u53e0(RBO)\u5ea6\u91cf\u5b9a\u4e49\u7f6e\u6362\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u8fdb\u4e00\u6b65\u63d0\u51fa\u57fa\u4e8e\u975e\u91cd\u53e0\u7684RPS\u51b2\u7a81\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5c06RPS\u7406\u8bba\u89c6\u4e3aDST\u7684\u6269\u5c55\uff0c\u8003\u8651\u7126\u70b9\u96c6\u4e2d\u65b0\u589e\u7684\u987a\u5e8f\u4fe1\u606f\u6240\u4ee3\u8868\u7684\u5b9a\u6027\u503e\u5411\u3002", "result": "\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u4e86\u6240\u63d0\u51b2\u7a81\u5ea6\u91cf\u7684\u884c\u4e3a\u548c\u6027\u8d28\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5177\u6709\u81ea\u7136\u7684\u9876\u90e8\u52a0\u6743\u7279\u6027\uff0c\u80fd\u4eceDST\u89c6\u89d2\u6709\u6548\u5ea6\u91cfRPS\u95f4\u7684\u51b2\u7a81\uff0c\u8fd8\u4e3a\u51b3\u7b56\u8005\u63d0\u4f9b\u4e86\u6743\u91cd\u3001\u53c2\u6570\u548c\u622a\u65ad\u6df1\u5ea6\u7684\u7075\u6d3b\u9009\u62e9\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86RPS\u4e2d\u7684\u51b2\u7a81\u5ea6\u91cf\u95ee\u9898\uff0c\u7ed3\u5408\u4e86RFS\u548cDST\u89c6\u89d2\uff0c\u4e3a\u987a\u5e8f\u7ed3\u6784\u4e0d\u786e\u5b9a\u4fe1\u606f\u878d\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2510.16004", "categories": ["cs.AI", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.16004", "abs": "https://arxiv.org/abs/2510.16004", "authors": ["Andreas Radler", "Vincent Seyfried", "Stefan Pirker", "Johannes Brandstetter", "Thomas Lichtenegger"], "title": "PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction", "comment": "22 pages, 16 figures", "summary": "Neural surrogates have shown great potential in simulating dynamical systems,\nwhile offering real-time capabilities. We envision Neural Twins as a\nprogression of neural surrogates, aiming to create digital replicas of real\nsystems. A neural twin consumes measurements at test time to update its state,\nthereby enabling context-specific decision-making. A critical property of\nneural twins is their ability to remain on-trajectory, i.e., to stay close to\nthe true system state over time. We introduce Parallel-in-time Neural Twins\n(PAINT), an architecture-agnostic family of methods for modeling dynamical\nsystems from measurements. PAINT trains a generative neural network to model\nthe distribution of states parallel over time. At test time, states are\npredicted from measurements in a sliding window fashion. Our theoretical\nanalysis shows that PAINT is on-trajectory, whereas autoregressive models\ngenerally are not. Empirically, we evaluate our method on a challenging\ntwo-dimensional turbulent fluid dynamics problem. The results demonstrate that\nPAINT stays on-trajectory and predicts system states from sparse measurements\nwith high fidelity. These findings underscore PAINT's potential for developing\nneural twins that stay on-trajectory, enabling more accurate state estimation\nand decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e86PAINT\u65b9\u6cd5\uff0c\u4e00\u79cd\u7528\u4e8e\u5efa\u6a21\u52a8\u6001\u7cfb\u7edf\u7684\u5e76\u884c\u65f6\u95f4\u795e\u7ecf\u5b6a\u751f\u67b6\u6784\uff0c\u80fd\u591f\u4ece\u6d4b\u91cf\u6570\u636e\u4e2d\u51c6\u786e\u9884\u6d4b\u7cfb\u7edf\u72b6\u6001\u5e76\u4fdd\u6301\u8f68\u8ff9\u8ddf\u8e2a\u80fd\u529b", "motivation": "\u795e\u7ecf\u5b6a\u751f\u4f5c\u4e3a\u795e\u7ecf\u4ee3\u7406\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\uff0c\u65e8\u5728\u521b\u5efa\u771f\u5b9e\u7cfb\u7edf\u7684\u6570\u5b57\u526f\u672c\uff0c\u9700\u8981\u80fd\u591f\u5728\u6d4b\u8bd5\u65f6\u6839\u636e\u6d4b\u91cf\u66f4\u65b0\u72b6\u6001\uff0c\u5e76\u4fdd\u6301\u8f68\u8ff9\u8ddf\u8e2a\u80fd\u529b", "method": "PAINT\u8bad\u7ec3\u751f\u6210\u795e\u7ecf\u7f51\u7edc\u6765\u5e76\u884c\u5efa\u6a21\u65f6\u95f4\u4e0a\u7684\u72b6\u6001\u5206\u5e03\uff0c\u5728\u6d4b\u8bd5\u65f6\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u65b9\u5f0f\u4ece\u6d4b\u91cf\u6570\u636e\u9884\u6d4b\u72b6\u6001", "result": "\u7406\u8bba\u5206\u6790\u8868\u660ePAINT\u80fd\u591f\u4fdd\u6301\u8f68\u8ff9\u8ddf\u8e2a\uff0c\u800c\u81ea\u56de\u5f52\u6a21\u578b\u901a\u5e38\u4e0d\u80fd\u3002\u5728\u4e8c\u7ef4\u6e4d\u6d41\u6d41\u4f53\u52a8\u529b\u5b66\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u663e\u793aPAINT\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u7cfb\u7edf\u72b6\u6001", "conclusion": "PAINT\u5177\u6709\u5f00\u53d1\u80fd\u591f\u4fdd\u6301\u8f68\u8ff9\u8ddf\u8e2a\u7684\u795e\u7ecf\u5b6a\u751f\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u72b6\u6001\u4f30\u8ba1\u548c\u51b3\u7b56\u5236\u5b9a"}}
{"id": "2510.16033", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16033", "abs": "https://arxiv.org/abs/2510.16033", "authors": ["Junyu Ren", "Wensheng Gan", "Guangyu Zhang", "Wei Zhong", "Philip S. Yu"], "title": "Global-focal Adaptation with Information Separation for Noise-robust Transfer Fault Diagnosis", "comment": "Preprint. 16 figures, 12 tables", "summary": "Existing transfer fault diagnosis methods typically assume either clean data\nor sufficient domain similarity, which limits their effectiveness in industrial\nenvironments where severe noise interference and domain shifts coexist. To\naddress this challenge, we propose an information separation global-focal\nadversarial network (ISGFAN), a robust framework for cross-domain fault\ndiagnosis under noise conditions. ISGFAN is built on an information separation\narchitecture that integrates adversarial learning with an improved orthogonal\nloss to decouple domain-invariant fault representation, thereby isolating noise\ninterference and domain-specific characteristics. To further strengthen\ntransfer robustness, ISGFAN employs a global-focal domain-adversarial scheme\nthat constrains both the conditional and marginal distributions of the model.\nSpecifically, the focal domain-adversarial component mitigates\ncategory-specific transfer obstacles caused by noise in unsupervised scenarios,\nwhile the global domain classifier ensures alignment of the overall\ndistribution. Experiments conducted on three public benchmark datasets\ndemonstrate that the proposed method outperforms other prominent existing\napproaches, confirming the superiority of the ISGFAN framework. Data and code\nare available at https://github.com/JYREN-Source/ISGFAN", "AI": {"tldr": "\u63d0\u51faISGFAN\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u5206\u79bb\u548c\u5168\u5c40-\u5c40\u90e8\u5bf9\u6297\u5b66\u4e60\u89e3\u51b3\u566a\u58f0\u73af\u5883\u4e0b\u7684\u8de8\u57df\u6545\u969c\u8bca\u65ad\u95ee\u9898", "motivation": "\u73b0\u6709\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u5047\u8bbe\u6570\u636e\u5e72\u51c0\u6216\u57df\u76f8\u4f3c\u5ea6\u9ad8\uff0c\u4f46\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u5b58\u5728\u4e25\u91cd\u566a\u58f0\u5e72\u6270\u548c\u57df\u504f\u79fb\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "method": "\u57fa\u4e8e\u4fe1\u606f\u5206\u79bb\u67b6\u6784\uff0c\u7ed3\u5408\u5bf9\u6297\u5b66\u4e60\u548c\u6539\u8fdb\u7684\u6b63\u4ea4\u635f\u5931\u6765\u89e3\u8026\u57df\u4e0d\u53d8\u6545\u969c\u8868\u793a\uff0c\u91c7\u7528\u5168\u5c40-\u5c40\u90e8\u57df\u5bf9\u6297\u65b9\u6848\u7ea6\u675f\u6a21\u578b\u7684\u6761\u4ef6\u548c\u8fb9\u7f18\u5206\u5e03", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u73b0\u6709\u65b9\u6cd5", "conclusion": "ISGFAN\u6846\u67b6\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u8de8\u57df\u6545\u969c\u8bca\u65ad\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027"}}
{"id": "2510.16047", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16047", "abs": "https://arxiv.org/abs/2510.16047", "authors": ["Ioan Hedea"], "title": "Algorithms for dynamic scheduling in manufacturing, towards digital factories Improving Deadline Feasibility and Responsiveness via Temporal Networks", "comment": "8 pages 2 column, 11 figures. Bachelor's thesis", "summary": "Modern manufacturing systems must meet hard delivery deadlines while coping\nwith stochastic task durations caused by process noise, equipment variability,\nand human intervention. Traditional deterministic schedules break down when\nreality deviates from nominal plans, triggering costly last-minute repairs.\nThis thesis combines offline constraint-programming (CP) optimisation with\nonline temporal-network execution to create schedules that remain feasible\nunder worst-case uncertainty. First, we build a CP model of the flexible\njob-shop with per-job deadline tasks and insert an optimal buffer $\\Delta^*$ to\nobtain a fully pro-active baseline. We then translate the resulting plan into a\nSimple Temporal Network with Uncertainty (STNU) and verify dynamic\ncontrollability, which guarantees that a real-time dispatcher can retime\nactivities for every bounded duration realisation without violating resource or\ndeadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4\nbenchmark suite show that our hybrid approach eliminates 100\\% of deadline\nviolations observed in state-of-the-art meta-heuristic schedules, while adding\nonly 3--5\\% makespan overhead. Scalability experiments confirm that CP\nsolve-times and STNU checks remain sub-second on medium-size instances. The\nwork demonstrates how temporal-network reasoning can bridge the gap between\nproactive buffering and dynamic robustness, moving industry a step closer to\ntruly digital, self-correcting factories.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7ed3\u5408\u79bb\u7ebf\u7ea6\u675f\u89c4\u5212\u4f18\u5316\u4e0e\u5728\u7ebf\u65f6\u95f4\u7f51\u7edc\u6267\u884c\uff0c\u521b\u5efa\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u4ecd\u53ef\u884c\u7684\u8c03\u5ea6\u65b9\u6848\uff0c\u6d88\u9664\u4e86100%\u7684\u622a\u6b62\u65f6\u95f4\u8fdd\u89c4\uff0c\u540c\u65f6\u4ec5\u589e\u52a03-5%\u7684\u5236\u9020\u5468\u671f\u5f00\u9500\u3002", "motivation": "\u73b0\u4ee3\u5236\u9020\u7cfb\u7edf\u9700\u8981\u6ee1\u8db3\u4e25\u683c\u7684\u4ea4\u4ed8\u622a\u6b62\u65f6\u95f4\uff0c\u540c\u65f6\u5e94\u5bf9\u7531\u8fc7\u7a0b\u566a\u58f0\u3001\u8bbe\u5907\u53d8\u5f02\u6027\u548c\u4eba\u4e3a\u5e72\u9884\u5f15\u8d77\u7684\u968f\u673a\u4efb\u52a1\u6301\u7eed\u65f6\u95f4\u3002\u4f20\u7edf\u7684\u786e\u5b9a\u6027\u8c03\u5ea6\u5728\u73b0\u5b9e\u504f\u79bb\u540d\u4e49\u8ba1\u5212\u65f6\u4f1a\u5931\u6548\uff0c\u5bfc\u81f4\u6602\u8d35\u7684\u7d27\u6025\u4fee\u590d\u3002", "method": "\u9996\u5148\u6784\u5efa\u5177\u6709\u6bcf\u9879\u4efb\u52a1\u622a\u6b62\u65f6\u95f4\u7684\u67d4\u6027\u4f5c\u4e1a\u8f66\u95f4\u7ea6\u675f\u89c4\u5212\u6a21\u578b\uff0c\u5e76\u63d2\u5165\u6700\u4f18\u7f13\u51b2\u533a\u0394*\u83b7\u5f97\u5b8c\u5168\u4e3b\u52a8\u57fa\u7ebf\u3002\u7136\u540e\u5c06\u7ed3\u679c\u8ba1\u5212\u8f6c\u6362\u4e3a\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u7b80\u5355\u65f6\u95f4\u7f51\u7edc\uff0c\u5e76\u9a8c\u8bc1\u52a8\u6001\u53ef\u63a7\u6027\u3002", "result": "\u5728Kacem 1-4\u57fa\u51c6\u5957\u4ef6\u4e0a\u7684\u5e7f\u6cdb\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\uff0c\u6df7\u5408\u65b9\u6cd5\u6d88\u9664\u4e86\u6700\u5148\u8fdb\u5143\u542f\u53d1\u5f0f\u8c03\u5ea6\u4e2d\u89c2\u5bdf\u5230\u7684100%\u622a\u6b62\u65f6\u95f4\u8fdd\u89c4\uff0c\u540c\u65f6\u4ec5\u589e\u52a03-5%\u7684\u5236\u9020\u5468\u671f\u5f00\u9500\u3002\u53ef\u6269\u5c55\u6027\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u5728\u4e2d\u7b49\u89c4\u6a21\u5b9e\u4f8b\u4e0a\uff0cCP\u6c42\u89e3\u65f6\u95f4\u548cSTNU\u68c0\u67e5\u4fdd\u6301\u5728\u4e9a\u79d2\u7ea7\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u65f6\u95f4\u7f51\u7edc\u63a8\u7406\u5982\u4f55\u5f25\u5408\u4e3b\u52a8\u7f13\u51b2\u548c\u52a8\u6001\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4f7f\u5de5\u4e1a\u66f4\u63a5\u8fd1\u771f\u6b63\u7684\u6570\u5b57\u5316\u3001\u81ea\u6821\u6b63\u5de5\u5382\u3002"}}
{"id": "2510.16095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16095", "abs": "https://arxiv.org/abs/2510.16095", "authors": ["Dou Liu", "Ying Long", "Sophia Zuoqiu", "Di Liu", "Kang Li", "Yiting Lin", "Hanyi Liu", "Rong Yin", "Tian Tang"], "title": "Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study", "comment": null, "summary": "Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for\nexplainable medical Artificial Intelligence (AI) while constrained by data\nscarcity. Although Large Language Models (LLMs) can synthesize medical data,\ntheir clinical reliability remains unverified. This study evaluates the\nreliability of LLM-generated CoTs and investigates prompting strategies to\nenhance their quality. In a blinded comparative study, senior clinicians in\nAssisted Reproductive Technology (ART) evaluated CoTs generated via three\ndistinct strategies: Zero-shot, Random Few-shot (using shallow examples), and\nSelective Few-shot (using diverse, high-quality examples). These expert ratings\nwere compared against evaluations from a state-of-the-art AI model (GPT-4o).\nThe Selective Few-shot strategy significantly outperformed other strategies\nacross all human evaluation metrics (p < .001). Critically, the Random Few-shot\nstrategy offered no significant improvement over the Zero-shot baseline,\ndemonstrating that low-quality examples are as ineffective as no examples. The\nsuccess of the Selective strategy is attributed to two principles:\n\"Gold-Standard Depth\" (reasoning quality) and \"Representative Diversity\"\n(generalization). Notably, the AI evaluator failed to discern these critical\nperformance differences. The clinical reliability of synthetic CoTs is dictated\nby strategic prompt curation, not the mere presence of examples. We propose a\n\"Dual Principles\" framework as a foundational methodology to generate\ntrustworthy data at scale. This work offers a validated solution to the data\nbottleneck and confirms the indispensable role of human expertise in evaluating\nhigh-stakes clinical AI.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86LLM\u751f\u6210\u7684\u4e34\u5e8a\u601d\u7ef4\u94fe\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u9009\u62e9\u6027\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5173\u952e\u5728\u4e8e\u793a\u4f8b\u7684\u8d28\u91cf\u800c\u975e\u6570\u91cf\uff0c\u5e76\u63d0\u51fa\u4e86\"\u53cc\u539f\u5219\"\u6846\u67b6\u6765\u751f\u6210\u53ef\u4fe1\u7684\u4e34\u5e8a\u6570\u636e\u3002", "motivation": "\u89e3\u51b3\u9ad8\u8d28\u91cf\u4e34\u5e8a\u601d\u7ef4\u94fe\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u9a8c\u8bc1LLM\u751f\u6210\u533b\u7597\u6570\u636e\u7684\u53ef\u9760\u6027\uff0c\u5e76\u63a2\u7d22\u63d0\u5347\u5176\u8d28\u91cf\u7684\u63d0\u793a\u7b56\u7565\u3002", "method": "\u91c7\u7528\u76f2\u6cd5\u6bd4\u8f83\u7814\u7a76\uff0c\u7531\u8f85\u52a9\u751f\u6b96\u6280\u672f\u4e13\u5bb6\u8bc4\u4f30\u4e09\u79cd\u63d0\u793a\u7b56\u7565\u751f\u6210\u7684\u601d\u7ef4\u94fe\uff1a\u96f6\u6837\u672c\u3001\u968f\u673a\u5c11\u6837\u672c\u548c\u9009\u62e9\u6027\u5c11\u6837\u672c\uff0c\u5e76\u4e0eGPT-4o\u7684\u8bc4\u4f30\u7ed3\u679c\u5bf9\u6bd4\u3002", "result": "\u9009\u62e9\u6027\u5c11\u6837\u672c\u7b56\u7565\u5728\u6240\u6709\u4eba\u5de5\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u7b56\u7565\uff0c\u968f\u673a\u5c11\u6837\u672c\u76f8\u6bd4\u96f6\u6837\u672c\u65e0\u663e\u8457\u6539\u8fdb\uff0cAI\u8bc4\u4f30\u5668\u672a\u80fd\u8bc6\u522b\u5173\u952e\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u5408\u6210\u601d\u7ef4\u94fe\u7684\u4e34\u5e8a\u53ef\u9760\u6027\u53d6\u51b3\u4e8e\u7b56\u7565\u6027\u63d0\u793a\u8bbe\u8ba1\u800c\u975e\u793a\u4f8b\u6570\u91cf\uff0c\u63d0\u51fa\u4e86\"\u9ec4\u91d1\u6807\u51c6\u6df1\u5ea6\"\u548c\"\u4ee3\u8868\u6027\u591a\u6837\u6027\"\u53cc\u539f\u5219\u6846\u67b6\uff0c\u5f3a\u8c03\u4eba\u7c7b\u4e13\u5bb6\u5728\u9ad8\u98ce\u9669\u4e34\u5e8aAI\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2510.16193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16193", "abs": "https://arxiv.org/abs/2510.16193", "authors": ["Elija Perrier"], "title": "Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability", "comment": "Under review", "summary": "Corporate responsibility turns on notions of corporate \\textit{mens rea},\ntraditionally imputed from human agents. Yet these assumptions are under\nchallenge as generative AI increasingly mediates enterprise decision-making.\nBuilding on the theory of extended cognition, we argue that in response\ncorporate knowledge may be redefined as a dynamic capability, measurable by the\nefficiency of its information-access procedures and the validated reliability\nof their outputs. We develop a formal model that captures epistemic states of\ncorporations deploying sophisticated AI or information systems, introducing a\ncontinuous organisational knowledge metric $S_S(\\varphi)$ which integrates a\npipeline's computational cost and its statistically validated error rate. We\nderive a thresholded knowledge predicate $\\mathsf{K}_S$ to impute knowledge and\na firm-wide epistemic capacity index $\\mathcal{K}_{S,t}$ to measure overall\ncapability. We then operationally map these quantitative metrics onto the legal\nstandards of actual knowledge, constructive knowledge, wilful blindness, and\nrecklessness. Our work provides a pathway towards creating measurable and\njusticiable audit artefacts, that render the corporate mind tractable and\naccountable in the algorithmic age.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u5c55\u8ba4\u77e5\u7406\u8bba\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5c06\u4f01\u4e1a\u77e5\u8bc6\u91cd\u65b0\u5b9a\u4e49\u4e3a\u53ef\u6d4b\u91cf\u7684\u52a8\u6001\u80fd\u529b\uff0c\u901a\u8fc7\u4fe1\u606f\u8bbf\u95ee\u7a0b\u5e8f\u7684\u6548\u7387\u548c\u8f93\u51fa\u53ef\u9760\u6027\u6765\u91cf\u5316\u4f01\u4e1a\u8ba4\u77e5\u72b6\u6001\uff0c\u4e3a\u7b97\u6cd5\u65f6\u4ee3\u7684\u4f01\u4e1a\u8d23\u4efb\u8ba4\u5b9a\u63d0\u4f9b\u53ef\u5ba1\u8ba1\u7684\u8861\u91cf\u6807\u51c6\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u4f01\u4e1a\u51b3\u7b56\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f20\u7edf\u57fa\u4e8e\u4eba\u7c7b\u4ee3\u7406\u4eba\u7684\u4f01\u4e1a\u72af\u7f6a\u610f\u56fe\u8ba4\u5b9a\u5047\u8bbe\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u91cd\u65b0\u5b9a\u4e49\u4f01\u4e1a\u77e5\u8bc6\u6982\u5ff5\u4ee5\u9002\u5e94\u7b97\u6cd5\u51b3\u7b56\u73af\u5883\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5f15\u5165\u8fde\u7eed\u7ec4\u7ec7\u77e5\u8bc6\u5ea6\u91cfS_S(\u03c6)\uff0c\u6574\u5408\u7ba1\u9053\u7684\u8ba1\u7b97\u6210\u672c\u548c\u7edf\u8ba1\u9a8c\u8bc1\u9519\u8bef\u7387\uff0c\u63a8\u5bfc\u51fa\u77e5\u8bc6\u8c13\u8bcdK_S\u548c\u4f01\u4e1a\u8303\u56f4\u8ba4\u77e5\u80fd\u529b\u6307\u6570K_{S,t}\uff0c\u5e76\u5c06\u8fd9\u4e9b\u5b9a\u91cf\u6307\u6807\u6620\u5c04\u5230\u6cd5\u5f8b\u6807\u51c6\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u6d4b\u91cf\u7684\u4f01\u4e1a\u77e5\u8bc6\u91cf\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u8ba1\u7b97\u6548\u7387\u548c\u8f93\u51fa\u53ef\u9760\u6027\u8f6c\u5316\u4e3a\u6cd5\u5f8b\u4e0a\u53ef\u5f52\u8d23\u7684\u77e5\u8bc6\u72b6\u6001\uff0c\u5305\u62ec\u5b9e\u9645\u77e5\u8bc6\u3001\u63a8\u5b9a\u77e5\u8bc6\u3001\u6545\u610f\u89c6\u800c\u4e0d\u89c1\u548c\u9c81\u83bd\u884c\u4e3a\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u7b97\u6cd5\u65f6\u4ee3\u521b\u5efa\u53ef\u6d4b\u91cf\u548c\u53ef\u53f8\u6cd5\u5ba1\u8ba1\u7684\u8ba4\u77e5\u8bc1\u636e\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u4f7f\u4f01\u4e1a\u601d\u7ef4\u53d8\u5f97\u53ef\u8ffd\u8e2a\u548c\u53ef\u95ee\u8d23\u3002"}}
{"id": "2510.16194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16194", "abs": "https://arxiv.org/abs/2510.16194", "authors": ["Guanchen Wu", "Zuhui Chen", "Yuzhang Xie", "Carl Yang"], "title": "Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration", "comment": "Agents4Science 2025 (Spotlight)", "summary": "Protected health information (PHI) de-identification is critical for enabling\nthe safe reuse of clinical notes, yet evaluating and comparing PHI\nde-identification models typically depends on costly, small-scale expert\nannotations. We present TEAM-PHI, a multi-agent evaluation and selection\nframework that uses large language models (LLMs) to automatically measure\nde-identification quality and select the best-performing model without heavy\nreliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each\nindependently judging the correctness of PHI extractions and outputting\nstructured metrics. Their results are then consolidated through an LLM-based\nmajority voting mechanism that integrates diverse evaluator perspectives into a\nsingle, stable, and reproducible ranking. Experiments on a real-world clinical\nnote corpus demonstrate that TEAM-PHI produces consistent and accurate\nrankings: despite variation across individual evaluators, LLM-based voting\nreliably converges on the same top-performing systems. Further comparison with\nground-truth annotations and human evaluation confirms that the framework's\nautomated rankings closely match supervised evaluation. By combining\nindependent evaluation agents with LLM majority voting, TEAM-PHI offers a\npractical, secure, and cost-effective solution for automatic evaluation and\nbest-model selection in PHI de-identification, even when ground-truth labels\nare limited.", "AI": {"tldr": "TEAM-PHI\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc4\u4f30\u533b\u7597\u4fe1\u606f\u53bb\u6807\u8bc6\u5316\u8d28\u91cf\u5e76\u9009\u62e9\u6700\u4f73\u6a21\u578b\uff0c\u65e0\u9700\u4f9d\u8d56\u6602\u8d35\u7684\u4e13\u5bb6\u6807\u6ce8\u3002", "motivation": "\u533b\u7597\u4fe1\u606f\u53bb\u6807\u8bc6\u5316\u5bf9\u4e8e\u5b89\u5168\u91cd\u7528\u4e34\u5e8a\u8bb0\u5f55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u6210\u672c\u9ad8\u6602\u7684\u5c0f\u89c4\u6a21\u4e13\u5bb6\u6807\u6ce8\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u8bc4\u4f30\u548c\u6bd4\u8f83\u3002", "method": "\u90e8\u7f72\u591a\u4e2a\u8bc4\u4f30\u667a\u80fd\u4f53\u72ec\u7acb\u5224\u65adPHI\u63d0\u53d6\u7684\u6b63\u786e\u6027\uff0c\u7136\u540e\u901a\u8fc7\u57fa\u4e8eLLM\u7684\u591a\u6570\u6295\u7968\u673a\u5236\u6574\u5408\u7ed3\u679c\uff0c\u751f\u6210\u7a33\u5b9a\u4e14\u53ef\u590d\u73b0\u7684\u6392\u540d\u3002", "result": "\u5728\u771f\u5b9e\u4e34\u5e8a\u8bb0\u5f55\u8bed\u6599\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTEAM-PHI\u80fd\u4ea7\u751f\u4e00\u81f4\u4e14\u51c6\u786e\u7684\u6392\u540d\uff0c\u5c3d\u7ba1\u4e2a\u4f53\u8bc4\u4f30\u8005\u5b58\u5728\u5dee\u5f02\uff0c\u4f46LLM\u6295\u7968\u80fd\u53ef\u9760\u5730\u6536\u655b\u4e8e\u76f8\u540c\u7684\u6700\u4f73\u7cfb\u7edf\u3002", "conclusion": "TEAM-PHI\u901a\u8fc7\u7ed3\u5408\u72ec\u7acb\u8bc4\u4f30\u667a\u80fd\u4f53\u548cLLM\u591a\u6570\u6295\u7968\uff0c\u4e3aPHI\u53bb\u6807\u8bc6\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u5b89\u5168\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u81ea\u52a8\u8bc4\u4f30\u548c\u6700\u4f73\u6a21\u578b\u9009\u62e9\u65b9\u6848\u3002"}}
{"id": "2510.16206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16206", "abs": "https://arxiv.org/abs/2510.16206", "authors": ["Alex Zhavoronkov", "Dominika Wilczok", "Roman Yampolskiy"], "title": "The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI", "comment": null, "summary": "Since the rapid expansion of large language models (LLMs), people have begun\nto rely on them for information retrieval. While traditional search engines\ndisplay ranked lists of sources shaped by search engine optimization (SEO),\nadvertising, and personalization, LLMs typically provide a synthesized response\nthat feels singular and authoritative. While both approaches carry risks of\nbias and omission, LLMs may amplify the effect by collapsing multiple\nperspectives into one answer, reducing users ability or inclination to compare\nalternatives. This concentrates power over information in a few LLM vendors\nwhose systems effectively shape what is remembered and what is overlooked. As a\nresult, certain narratives, individuals or groups, may be disproportionately\nsuppressed, while others are disproportionately elevated. Over time, this\ncreates a new threat: the gradual erasure of those with limited digital\npresence, and the amplification of those already prominent, reshaping\ncollective memory.To address these concerns, this paper presents a concept of\nthe Right To Be Remembered (RTBR) which encompasses minimizing the risk of\nAI-driven information omission, embracing the right of fair treatment, while\nensuring that the generated content would be maximally truthful.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u88ab\u8bb0\u4f4f\u6743\"\u6982\u5ff5\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u5bfc\u81f4\u4fe1\u606f\u9057\u6f0f\u548c\u504f\u89c1\u7684\u95ee\u9898\uff0c\u786e\u4fddAI\u751f\u6210\u5185\u5bb9\u7684\u771f\u5b9e\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u4eba\u4eec\u5f00\u59cb\u4f9d\u8d56\u5b83\u4eec\u8fdb\u884c\u4fe1\u606f\u68c0\u7d22\u3002\u4e0e\u4f20\u7edf\u641c\u7d22\u5f15\u64ce\u663e\u793a\u7ecf\u8fc7SEO\u4f18\u5316\u3001\u5e7f\u544a\u548c\u4e2a\u4eba\u5316\u7684\u6392\u540d\u5217\u8868\u4e0d\u540c\uff0cLLMs\u901a\u5e38\u63d0\u4f9b\u5355\u4e00\u6743\u5a01\u7684\u5408\u6210\u56de\u7b54\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u591a\u79cd\u89c2\u70b9\u88ab\u538b\u7f29\u6210\u4e00\u4e2a\u7b54\u6848\uff0c\u964d\u4f4e\u7528\u6237\u6bd4\u8f83\u66ff\u4ee3\u65b9\u6848\u7684\u80fd\u529b\u6216\u610f\u613f\uff0c\u4ece\u800c\u5c06\u4fe1\u606f\u63a7\u5236\u6743\u96c6\u4e2d\u5728\u5c11\u6570LLM\u4f9b\u5e94\u5546\u624b\u4e2d\u3002", "method": "\u63d0\u51fa\"\u88ab\u8bb0\u4f4f\u6743\"\u6982\u5ff5\uff0c\u5305\u62ec\u6700\u5c0f\u5316AI\u9a71\u52a8\u4fe1\u606f\u9057\u6f0f\u98ce\u9669\u3001\u62e5\u62b1\u516c\u5e73\u5bf9\u5f85\u6743\u5229\uff0c\u540c\u65f6\u786e\u4fdd\u751f\u6210\u5185\u5bb9\u6700\u5927\u7a0b\u5ea6\u771f\u5b9e\u3002", "result": "\u8bc6\u522b\u4e86LLMs\u53ef\u80fd\u4e0d\u6210\u6bd4\u4f8b\u5730\u538b\u5236\u67d0\u4e9b\u53d9\u8ff0\u3001\u4e2a\u4f53\u6216\u7fa4\u4f53\uff0c\u540c\u65f6\u4e0d\u6210\u6bd4\u4f8b\u5730\u63d0\u5347\u5176\u4ed6\u5185\u5bb9\uff0c\u4ece\u800c\u9010\u6e10\u62b9\u9664\u6570\u5b57\u5b58\u5728\u6709\u9650\u8005\u5e76\u653e\u5927\u5df2\u7a81\u51fa\u8005\uff0c\u91cd\u5851\u96c6\u4f53\u8bb0\u5fc6\u7684\u65b0\u5a01\u80c1\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\"\u88ab\u8bb0\u4f4f\u6743\"\u6846\u67b6\u6765\u5e94\u5bf9LLMs\u5e26\u6765\u7684\u4fe1\u606f\u504f\u89c1\u548c\u9057\u6f0f\u98ce\u9669\uff0c\u786e\u4fdd\u4fe1\u606f\u68c0\u7d22\u7684\u516c\u5e73\u6027\u548c\u771f\u5b9e\u6027\u3002"}}
{"id": "2510.16234", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16234", "abs": "https://arxiv.org/abs/2510.16234", "authors": ["Hanane Nour Moussa", "Patrick Queiroz Da Silva", "Daniel Adu-Ampratwum", "Alyson East", "Zitong Lu", "Nikki Puccetti", "Mingyi Xue", "Huan Sun", "Bodhisattwa Prasad Majumder", "Sachin Kumar"], "title": "ScholarEval: Research Idea Evaluation Grounded in Literature", "comment": null, "summary": "As AI tools become increasingly common for research ideation, robust\nevaluation is critical to ensure the validity and usefulness of generated\nideas. We introduce ScholarEval, a retrieval augmented evaluation framework\nthat assesses research ideas based on two fundamental criteria: soundness - the\nempirical validity of proposed methods based on existing literature, and\ncontribution - the degree of advancement made by the idea across different\ndimensions relative to prior research. To evaluate ScholarEval, we introduce\nScholarIdeas, the first expert-annotated dataset of multi-domain research ideas\nand reviews, comprised of 117 ideas across four disciplines: artificial\nintelligence, neuroscience, biochemistry, and ecology. Our evaluation shows\nthat ScholarEval achieves significantly higher coverage of points mentioned in\nthe human expert annotated rubrics in ScholarIdeas compared to all baselines.\nFurthermore, ScholarEval is consistently preferred over our strongest baseline\no4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,\nin terms of evaluation actionability, depth, and evidence support. Our\nlarge-scale user study also shows that ScholarEval significantly outperforms\ndeep research in literature engagement, idea refinement, and usefulness. We\nopenly release our code, dataset, and ScholarEval tool for the community to use\nand build on.", "AI": {"tldr": "\u63d0\u51fa\u4e86ScholarEval\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u8bc4\u4f30\u7814\u7a76\u60f3\u6cd5\u7684\u5408\u7406\u6027\u548c\u8d21\u732e\u5ea6\uff0c\u5e76\u5728\u591a\u9886\u57df\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u5de5\u5177\u5728\u7814\u7a76\u6784\u601d\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u5efa\u7acb\u5f3a\u5927\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u786e\u4fdd\u751f\u6210\u60f3\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u5f00\u53d1\u4e86ScholarEval\u68c0\u7d22\u589e\u5f3a\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u4e24\u4e2a\u6838\u5fc3\u6807\u51c6\u8bc4\u4f30\u7814\u7a76\u60f3\u6cd5\uff1a\u5408\u7406\u6027\uff08\u57fa\u4e8e\u73b0\u6709\u6587\u732e\u7684\u65b9\u6cd5\u6709\u6548\u6027\uff09\u548c\u8d21\u732e\u5ea6\uff08\u76f8\u5bf9\u4e8e\u5148\u524d\u7814\u7a76\u7684\u4e0d\u540c\u7ef4\u5ea6\u8fdb\u5c55\u7a0b\u5ea6\uff09\u3002", "result": "\u5728ScholarIdeas\u6570\u636e\u96c6\u4e0a\uff0cScholarEval\u6bd4\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u8986\u76d6\u4e86\u66f4\u591a\u4e13\u5bb6\u6807\u6ce8\u7684\u8bc4\u5206\u70b9\uff0c\u4e14\u5728\u8bc4\u4f30\u53ef\u64cd\u4f5c\u6027\u3001\u6df1\u5ea6\u548c\u8bc1\u636e\u652f\u6301\u65b9\u9762\u6301\u7eed\u4f18\u4e8eOpenAI\u7684o4-mini-deep-research\u7cfb\u7edf\u3002\u5927\u89c4\u6a21\u7528\u6237\u7814\u7a76\u663e\u793a\u5728\u6587\u732e\u53c2\u4e0e\u3001\u60f3\u6cd5\u7cbe\u70bc\u548c\u5b9e\u7528\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6df1\u5ea6\u7814\u7a76\u3002", "conclusion": "ScholarEval\u4e3a\u7814\u7a76\u60f3\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5f00\u6e90\u4e86\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u5de5\u5177\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2510.16259", "categories": ["cs.AI", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.16259", "abs": "https://arxiv.org/abs/2510.16259", "authors": ["Zhehao Zhang", "Weijie Xu", "Shixian Cui", "Chandan K. Reddy"], "title": "Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense", "comment": "29 pages, 9 tables, 4 figures", "summary": "Recent advances in large reasoning models (LRMs) have enabled remarkable\nperformance on complex tasks such as mathematics and coding by generating long\nChain-of-Thought (CoT) traces. In this paper, we identify and systematically\nanalyze a critical vulnerability we term reasoning distraction, where LRMs are\ndiverted from their primary objective by irrelevant yet complex tasks\nmaliciously embedded in the prompt. Through a comprehensive study across\ndiverse models and benchmarks, we show that even state-of-the-art LRMs are\nhighly susceptible, with injected distractors reducing task accuracy by up to\n60%. We further reveal that certain alignment techniques can amplify this\nweakness and that models may exhibit covert compliance, following hidden\nadversarial instructions in reasoning while concealing them in the final\noutput. To mitigate these risks, we propose a training-based defense that\ncombines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on\nsynthetic adversarial data, improving robustness by over 50 points on\nchallenging distractor attacks. Our findings establish reasoning distraction as\na distinct and urgent threat to LRM reliability and provide a practical step\ntoward safer and more trustworthy reasoning systems.", "AI": {"tldr": "\u672c\u6587\u8bc6\u522b\u5e76\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u63a8\u7406\u6a21\u578b(LRMs)\u7684\u63a8\u7406\u5206\u5fc3\u6f0f\u6d1e\uff0c\u5373\u6a21\u578b\u88ab\u6076\u610f\u5d4c\u5165\u7684\u590d\u6742\u65e0\u5173\u4efb\u52a1\u5206\u6563\u6ce8\u610f\u529b\uff0c\u5bfc\u81f4\u4e3b\u8981\u4efb\u52a1\u51c6\u786e\u6027\u4e0b\u964d\u9ad8\u8fbe60%\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bad\u7ec3\u7684\u5bf9\u7b56\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u5927\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f5c\u8005\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u6f0f\u6d1e\uff1a\u5bb9\u6613\u88ab\u6076\u610f\u5d4c\u5165\u7684\u590d\u6742\u65e0\u5173\u4efb\u52a1\u5206\u6563\u6ce8\u610f\u529b\uff0c\u4ece\u800c\u5f71\u54cd\u4e3b\u8981\u4efb\u52a1\u7684\u5b8c\u6210\u8d28\u91cf\u3002", "method": "\u901a\u8fc7\u8de8\u6a21\u578b\u548c\u57fa\u51c6\u7684\u7efc\u5408\u7814\u7a76\uff0c\u5206\u6790\u63a8\u7406\u5206\u5fc3\u6f0f\u6d1e\uff1b\u63d0\u51fa\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u7684\u8bad\u7ec3\u9632\u5fa1\u65b9\u6cd5\uff0c\u4f7f\u7528\u5408\u6210\u7684\u5bf9\u6297\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u7814\u7a76\u8868\u660e\u6700\u5148\u8fdb\u7684\u5927\u63a8\u7406\u6a21\u578b\u9ad8\u5ea6\u6613\u53d7\u653b\u51fb\uff0c\u6ce8\u5165\u7684\u5e72\u6270\u7269\u53ef\u4f7f\u4efb\u52a1\u51c6\u786e\u6027\u964d\u4f4e\u9ad8\u8fbe60%\uff1b\u63d0\u51fa\u7684\u9632\u5fa1\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5e72\u6270\u653b\u51fb\u4e0a\u5c06\u9c81\u68d2\u6027\u63d0\u9ad8\u4e8650\u591a\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u63a8\u7406\u5206\u5fc3\u662f\u5927\u63a8\u7406\u6a21\u578b\u53ef\u9760\u6027\u7684\u4e00\u4e2a\u72ec\u7279\u4e14\u7d27\u8feb\u7684\u5a01\u80c1\uff0c\u672c\u6587\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u3001\u66f4\u53ef\u4fe1\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6b65\u9aa4\u3002"}}
{"id": "2510.16276", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16276", "abs": "https://arxiv.org/abs/2510.16276", "authors": ["Song Bian", "Minghao Yan", "Anand Jayarajan", "Gennady Pekhimenko", "Shivaram Venkataraman"], "title": "What Limits Agentic Systems Efficiency?", "comment": "27 pages, 15 figures", "summary": "Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have\ndemonstrated strong reasoning capabilities. To further enhance LLM\ncapabilities, recent agentic systems, such as Deep Research, incorporate web\ninteractions into LLM reasoning to mitigate uncertainties and reduce potential\nerrors. However, existing research predominantly focuses on reasoning\nperformance, often neglecting the efficiency of agentic systems. In this work,\nwe present a comprehensive empirical study that identifies efficiency\nbottlenecks in web-interactive agentic systems. We decompose end-to-end latency\ninto two primary components: LLM API latency and web environment latency. We\nconduct a comprehensive empirical study across 15 models and 5 providers to\ndemonstrate high variability in API-based agentic systems. We observe that web\nenvironment latency can contribute as much as 53.7% to the overall latency in a\nweb-based agentic system. To improve latency, we propose SpecCache, a caching\nframework augmented with speculative execution that can reduce web environment\noverhead. Extensive evaluations on two standard benchmarks show that our\napproach improves the cache hit rate by up to 58x compared to a random caching\nstrategy, while reducing web environment overhead by up to 3.2x, without\ndegrading agentic system performance.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u7f51\u7edc\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u6548\u7387\u74f6\u9888\uff0c\u63d0\u51faSpecCache\u7f13\u5b58\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u6d4b\u6267\u884c\u663e\u8457\u964d\u4f4e\u7f51\u7edc\u73af\u5883\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u7f13\u5b58\u547d\u4e2d\u738758\u500d\uff0c\u51cf\u5c11\u7f51\u7edc\u5f00\u95003.2\u500d\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u6027\u80fd\uff0c\u800c\u5ffd\u89c6\u4e86\u6548\u7387\u95ee\u9898\u3002\u7f51\u7edc\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u663e\u8457\u7684\u5ef6\u8fdf\u74f6\u9888\uff0c\u5f71\u54cd\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "method": "\u5c06\u7aef\u5230\u7aef\u5ef6\u8fdf\u5206\u89e3\u4e3aLLM API\u5ef6\u8fdf\u548c\u7f51\u7edc\u73af\u5883\u5ef6\u8fdf\uff0c\u901a\u8fc715\u4e2a\u6a21\u578b\u548c5\u4e2a\u63d0\u4f9b\u5546\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51faSpecCache\u7f13\u5b58\u6846\u67b6\uff0c\u7ed3\u5408\u63a8\u6d4b\u6267\u884c\u6765\u4f18\u5316\u7f51\u7edc\u73af\u5883\u5f00\u9500\u3002", "result": "\u7f51\u7edc\u73af\u5883\u5ef6\u8fdf\u53ef\u5360\u7cfb\u7edf\u603b\u5ef6\u8fdf\u768453.7%\u3002SpecCache\u76f8\u6bd4\u968f\u673a\u7f13\u5b58\u7b56\u7565\u63d0\u9ad8\u7f13\u5b58\u547d\u4e2d\u738758\u500d\uff0c\u51cf\u5c11\u7f51\u7edc\u73af\u5883\u5f00\u95003.2\u500d\uff0c\u4e14\u4e0d\u964d\u4f4e\u7cfb\u7edf\u6027\u80fd\u3002", "conclusion": "\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u4f18\u5316\u81f3\u5173\u91cd\u8981\uff0cSpecCache\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7f51\u7edc\u73af\u5883\u5ef6\u8fdf\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u9ad8\u6548\u7684\u7f51\u7edc\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16302", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16302", "abs": "https://arxiv.org/abs/2510.16302", "authors": ["Changhao Wang", "Yanfang Liu", "Xinxin Fan", "Anzhi Zhou", "Lao Tian", "Yunfeng Lu"], "title": "DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA", "comment": "13 pages, 5 figures", "summary": "Multi-hop reasoning for question answering (QA) plays a critical role in\nretrieval-augmented generation (RAG) for modern large language models (LLMs).\nThe accurate answer can be obtained through retrieving relational structure of\nentities from knowledge graph (KG). Regarding the inherent relation-dependency\nand reasoning pattern, multi-hop reasoning can be in general classified into\ntwo categories: i) parallel fact-verification multi-hop reasoning question,\ni.e., requiring simultaneous verifications of multiple independent\nsub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding\nsequential multi-step inference with intermediate conclusions serving as\nessential premises for subsequent reasoning. Currently, the multi-hop reasoning\napproaches singly employ one of two techniques: LLM response-based fact\nverification and KG path-based chain construction. Nevertheless, the former\nexcels at parallel fact-verification but underperforms on chained reasoning\ntasks, while the latter demonstrates proficiency in chained multi-hop reasoning\nbut suffers from redundant path retrieval when handling parallel\nfact-verification reasoning. These limitations deteriorate the efficiency and\naccuracy for multi-hop QA tasks. To address this challenge, we propose a novel\ndual-track KG verification and reasoning framework DTKG, which is inspired by\nthe Dual Process Theory in cognitive science. Specifically, DTKG comprises two\nmain stages: the Classification Stage and the Branch Processing Stage.", "AI": {"tldr": "\u63d0\u51faDTKG\u6846\u67b6\u89e3\u51b3\u591a\u8df3\u63a8\u7406\u95ee\u7b54\u95ee\u9898\uff0c\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u8def\u5f84\u6784\u5efa\u548cLLM\u4e8b\u5b9e\u9a8c\u8bc1\u4e24\u79cd\u65b9\u6cd5\uff0c\u63d0\u5347\u591a\u8df3QA\u4efb\u52a1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027", "motivation": "\u73b0\u6709\u591a\u8df3\u63a8\u7406\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528LLM\u4e8b\u5b9e\u9a8c\u8bc1\u4f46\u94fe\u5f0f\u63a8\u7406\u8868\u73b0\u4e0d\u4f73\uff0c\u8981\u4e48\u4f7f\u7528KG\u8def\u5f84\u6784\u5efa\u4f46\u5728\u5e76\u884c\u4e8b\u5b9e\u9a8c\u8bc1\u65f6\u5b58\u5728\u5197\u4f59\u8def\u5f84\u68c0\u7d22\u95ee\u9898\uff0c\u8fd9\u4e9b\u9650\u5236\u964d\u4f4e\u4e86\u591a\u8df3QA\u4efb\u52a1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027", "method": "\u63d0\u51fa\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u53cc\u8fc7\u7a0b\u7406\u8bba\u7684\u53cc\u8f68KG\u9a8c\u8bc1\u548c\u63a8\u7406\u6846\u67b6DTKG\uff0c\u5305\u542b\u5206\u7c7b\u9636\u6bb5\u548c\u5206\u652f\u5904\u7406\u9636\u6bb5\u4e24\u4e2a\u4e3b\u8981\u9636\u6bb5", "result": "\u8be5\u65b9\u6cd5\u65e8\u5728\u540c\u65f6\u89e3\u51b3\u5e76\u884c\u4e8b\u5b9e\u9a8c\u8bc1\u548c\u94fe\u5f0f\u591a\u8df3\u63a8\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u4e24\u79cd\u6280\u672f\u7684\u4f18\u52bf\u6765\u63d0\u5347\u6574\u4f53\u6027\u80fd", "conclusion": "DTKG\u6846\u67b6\u901a\u8fc7\u53cc\u8f68\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8df3\u63a8\u7406\u95ee\u7b54\u4e2d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u95ee\u9898\uff0c\u4e3a\u591a\u8df3QA\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.16309", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16309", "abs": "https://arxiv.org/abs/2510.16309", "authors": ["Crystal Su"], "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier", "comment": "Accepted to the Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2026) Workshop", "summary": "Large language models (LLMs) often produce fluent reasoning steps while\nviolating simple mathematical or logical constraints. We introduce MedRule-KG,\na compact typed knowledge graph coupled with a symbolic verifier, designed to\nenforce mathematically interpretable rules in reasoning tasks. MedRule-KG\nencodes entities, relations, and three domain-inspired rules, while the\nverifier checks predictions and applies minimal corrections to guarantee\nconsistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG\nimproves exact match (EM) from 0.767 to 0.900, and adding the verifier yields\n1.000 EM while eliminating rule violations entirely. We demonstrate how\nMedRule-KG provides a general scaffold for safe mathematical reasoning, discuss\nablations, and release code and data to encourage reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86MedRule-KG\uff0c\u4e00\u4e2a\u7d27\u51d1\u7684\u5e26\u7c7b\u578b\u77e5\u8bc6\u56fe\u8c31\u548c\u7b26\u53f7\u9a8c\u8bc1\u5668\uff0c\u7528\u4e8e\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5f3a\u5236\u6267\u884c\u6570\u5b66\u53ef\u89e3\u91ca\u89c4\u5219\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\u5e76\u6d88\u9664\u89c4\u5219\u8fdd\u53cd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u4ea7\u751f\u6d41\u7545\u7684\u63a8\u7406\u6b65\u9aa4\uff0c\u4f46\u8fdd\u53cd\u7b80\u5355\u7684\u6570\u5b66\u6216\u903b\u8f91\u7ea6\u675f\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u786e\u4fdd\u63a8\u7406\u7684\u6570\u5b66\u53ef\u89e3\u91ca\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u6784\u5efaMedRule-KG\u77e5\u8bc6\u56fe\u8c31\uff0c\u5305\u542b\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u4e09\u4e2a\u9886\u57df\u542f\u53d1\u89c4\u5219\uff0c\u914d\u5408\u7b26\u53f7\u9a8c\u8bc1\u5668\u68c0\u67e5\u9884\u6d4b\u5e76\u5e94\u7528\u6700\u5c0f\u4fee\u6b63\u4ee5\u4fdd\u8bc1\u4e00\u81f4\u6027\u3002", "result": "\u572890\u4e2aFDA\u884d\u751f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528MedRule-KG\u5c06\u7cbe\u786e\u5339\u914d\u4ece0.767\u63d0\u5347\u52300.900\uff0c\u6dfb\u52a0\u9a8c\u8bc1\u5668\u540e\u8fbe\u52301.000\u7cbe\u786e\u5339\u914d\uff0c\u5b8c\u5168\u6d88\u9664\u89c4\u5219\u8fdd\u53cd\u3002", "conclusion": "MedRule-KG\u4e3a\u5b89\u5168\u7684\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u548c\u89c4\u5219\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.16342", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16342", "abs": "https://arxiv.org/abs/2510.16342", "authors": ["Tong Zhang", "Ru Zhang", "Jianyi Liu", "Zhen Yang", "Gongshen Liu"], "title": "Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts", "comment": null, "summary": "Existing concept erasure methods for text-to-image diffusion models commonly\nrely on fixed anchor strategies, which often lead to critical issues such as\nconcept re-emergence and erosion. To address this, we conduct causal tracing to\nreveal the inherent sensitivity of erasure to anchor selection and define\nSibling Exclusive Concepts as a superior class of anchors. Based on this\ninsight, we propose \\textbf{SELECT} (Sibling-Exclusive Evaluation for\nContextual Targeting), a dynamic anchor selection framework designed to\novercome the limitations of fixed anchors. Our framework introduces a novel\ntwo-stage evaluation mechanism that automatically discovers optimal anchors for\nprecise erasure while identifying critical boundary anchors to preserve related\nconcepts. Extensive evaluations demonstrate that SELECT, as a universal anchor\nsolution, not only efficiently adapts to multiple erasure frameworks but also\nconsistently outperforms existing baselines across key performance metrics,\naveraging only 4 seconds for anchor mining of a single concept.", "AI": {"tldr": "\u63d0\u51fa\u4e86SELECT\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u951a\u70b9\u9009\u62e9\u89e3\u51b3\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\u6982\u5ff5\u64e6\u9664\u7684\u951a\u70b9\u654f\u611f\u6027\u95ee\u9898\uff0c\u514b\u670d\u56fa\u5b9a\u951a\u70b9\u7b56\u7565\u5bfc\u81f4\u7684\u6982\u5ff5\u91cd\u73b0\u548c\u4fb5\u8680\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u951a\u70b9\u7b56\u7565\uff0c\u5bfc\u81f4\u6982\u5ff5\u91cd\u73b0\u548c\u4fb5\u8680\u7b49\u5173\u952e\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u951a\u70b9\u9009\u62e9\u7684\u654f\u611f\u6027\u3002", "method": "\u901a\u8fc7\u56e0\u679c\u8ffd\u8e2a\u63ed\u793a\u64e6\u9664\u5bf9\u951a\u70b9\u9009\u62e9\u7684\u654f\u611f\u6027\uff0c\u5b9a\u4e49\u5144\u5f1f\u6392\u4ed6\u6982\u5ff5\u4f5c\u4e3a\u66f4\u4f18\u951a\u70b9\u7c7b\u522b\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u8bc4\u4f30\u673a\u5236\u81ea\u52a8\u53d1\u73b0\u6700\u4f18\u951a\u70b9\u5e76\u8bc6\u522b\u8fb9\u754c\u951a\u70b9\u3002", "result": "SELECT\u4f5c\u4e3a\u901a\u7528\u951a\u70b9\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u9ad8\u6548\u9002\u914d\u591a\u4e2a\u64e6\u9664\u6846\u67b6\uff0c\u5728\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5355\u4e2a\u6982\u5ff5\u7684\u951a\u70b9\u6316\u6398\u5e73\u5747\u4ec5\u97004\u79d2\u3002", "conclusion": "SELECT\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u951a\u70b9\u9009\u62e9\u6709\u6548\u89e3\u51b3\u4e86\u6982\u5ff5\u64e6\u9664\u4e2d\u7684\u951a\u70b9\u654f\u611f\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u6982\u5ff5\u64e6\u9664\u6548\u679c\u3002"}}
{"id": "2510.16374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16374", "abs": "https://arxiv.org/abs/2510.16374", "authors": ["Nick Oh"], "title": "Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs", "comment": "Presented at the Workshop on the Application of LLM Explainability to\n  Reasoning and Planning at COLM 2025 (non-archival)", "summary": "Current approaches to enhancing LLM reasoning follows two isolated paradigms:\nMonitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and\nSELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack\nmechanisms to verify whether selected strategies succeed; while Generate-Verify\napproaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan\net al., 2023) iteratively refine outputs but commence generation blindly\nwithout task assessment. This separation creates inefficiencies -- strategies\nfail without feedback, and refinement occurs without strategic grounding. We\naddress this gap by implementing Flavell's cognitive monitoring model (1979)\nfrom the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025),\noperationalising it as a three-phase iterative system. On GSM8K, preliminary\nresults show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for\nSelf-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37%\nincreased inference cost. These initial findings suggest upfront monitoring\nproduces higher-quality initial solutions that reduce refinement needs, though\nevaluation beyond arithmetic reasoning is needed to establish generalisability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u76d1\u63a7-\u751f\u6210-\u9a8c\u8bc1\u7684\u4e09\u9636\u6bb5\u8fed\u4ee3\u7cfb\u7edf\uff0c\u5728GSM8K\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e8675.42%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u9700\u8981\u66f4\u5c11\u7684\u5c1d\u8bd5\u6b21\u6570\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u5b58\u5728\u5206\u79bb\u95ee\u9898\uff1a\u76d1\u63a7-\u751f\u6210\u65b9\u6cd5\u64c5\u957f\u7b56\u7565\u89c4\u5212\u4f46\u7f3a\u4e4f\u9a8c\u8bc1\u673a\u5236\uff0c\u751f\u6210-\u9a8c\u8bc1\u65b9\u6cd5\u80fd\u8fed\u4ee3\u4f18\u5316\u4f46\u7f3a\u4e4f\u7b56\u7565\u57fa\u7840\u3002\u8fd9\u79cd\u5206\u79bb\u5bfc\u81f4\u7b56\u7565\u5931\u8d25\u65e0\u53cd\u9988\u3001\u4f18\u5316\u65e0\u6218\u7565\u6307\u5bfc\u7684\u4f4e\u6548\u95ee\u9898\u3002", "method": "\u57fa\u4e8eFlavell\u7684\u8ba4\u77e5\u76d1\u63a7\u6a21\u578b\uff0c\u5b9e\u73b0\u76d1\u63a7-\u751f\u6210-\u9a8c\u8bc1\u6846\u67b6\u7684\u4e09\u9636\u6bb5\u8fed\u4ee3\u7cfb\u7edf\uff0c\u5c06\u7b56\u7565\u89c4\u5212\u4e0e\u8f93\u51fa\u9a8c\u8bc1\u6709\u673a\u7ed3\u5408\u3002", "result": "\u5728GSM8K\u4e0a\u8fbe\u523075.42%\u51c6\u786e\u7387\uff0c\u4f18\u4e8eSELF-REFINE(68.44%)\u548cSelf-Verification(67.07%)\uff0c\u5c1d\u8bd5\u6b21\u6570\u66f4\u5c11(1.3 vs 2.0)\uff0c\u63a8\u7406\u6210\u672c\u589e\u52a027-37%\u3002", "conclusion": "\u524d\u671f\u76d1\u63a7\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u521d\u59cb\u89e3\u51b3\u65b9\u6848\uff0c\u4ece\u800c\u51cf\u5c11\u4f18\u5316\u9700\u6c42\uff0c\u4f46\u9700\u8981\u5728\u7b97\u672f\u63a8\u7406\u4e4b\u5916\u7684\u4efb\u52a1\u4e0a\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u901a\u7528\u6027\u3002"}}
{"id": "2510.16382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16382", "abs": "https://arxiv.org/abs/2510.16382", "authors": ["Ze Tao", "Jian Zhang", "Haowei Li", "Xianshuai Li", "Yifei Peng", "Xiyao Liu", "Senzhang Wang", "Chao Liu", "Sheng Ren", "Shichao Zhang"], "title": "Humanoid-inspired Causal Representation Learning for Domain Generalization", "comment": null, "summary": "This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a\nnovel causal framework inspired by human intelligence, designed to overcome the\nlimitations of conventional domain generalization models. Unlike approaches\nthat rely on statistics to capture data-label dependencies and learn\ndistortion-invariant representations, HSCM replicates the hierarchical\nprocessing and multi-level learning of human vision systems, focusing on\nmodeling fine-grained causal mechanisms. By disentangling and reweighting key\nimage attributes such as color, texture, and shape, HSCM enhances\ngeneralization across diverse domains, ensuring robust performance and\ninterpretability. Leveraging the flexibility and adaptability of human\nintelligence, our approach enables more effective transfer and learning in\ndynamic, complex environments. Through both theoretical and empirical\nevaluations, we demonstrate that HSCM outperforms existing domain\ngeneralization models, providing a more principled method for capturing causal\nrelationships and improving model robustness. The code is available at\nhttps://github.com/lambett/HSCM.", "AI": {"tldr": "\u63d0\u51fa\u53d7\u4eba\u7c7b\u667a\u80fd\u542f\u53d1\u7684HSCM\u56e0\u679c\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u548c\u91cd\u52a0\u6743\u56fe\u50cf\u5c5e\u6027\u6765\u589e\u5f3a\u8de8\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u514b\u670d\u4f20\u7edf\u9886\u57df\u6cdb\u5316\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u8fd9\u4e9b\u6a21\u578b\u4f9d\u8d56\u7edf\u8ba1\u65b9\u6cd5\u6355\u6349\u6570\u636e-\u6807\u7b7e\u4f9d\u8d56\u5173\u7cfb\uff0c\u800cHSCM\u6a21\u4eff\u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u7684\u5206\u5c42\u5904\u7406\u548c\u591a\u5c42\u6b21\u5b66\u4e60\u673a\u5236\u3002", "method": "\u57fa\u4e8e\u4eba\u7c7b\u667a\u80fd\u7684\u5c42\u6b21\u5904\u7406\u548c\u56e0\u679c\u673a\u5236\u5efa\u6a21\uff0c\u901a\u8fc7\u89e3\u8026\u548c\u91cd\u52a0\u6743\u5173\u952e\u56fe\u50cf\u5c5e\u6027\uff08\u989c\u8272\u3001\u7eb9\u7406\u3001\u5f62\u72b6\uff09\u6765\u5b66\u4e60\u7ec6\u7c92\u5ea6\u56e0\u679c\u673a\u5236\u3002", "result": "\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc4\u4f30\u4e2d\uff0cHSCM\u4f18\u4e8e\u73b0\u6709\u7684\u9886\u57df\u6cdb\u5316\u6a21\u578b\uff0c\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "HSCM\u4e3a\u6355\u6349\u56e0\u679c\u5173\u7cfb\u548c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u66f4\u539f\u5219\u6027\u7684\u65b9\u6cd5\uff0c\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u8fc1\u79fb\u5b66\u4e60\u3002"}}
{"id": "2510.16392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16392", "abs": "https://arxiv.org/abs/2510.16392", "authors": ["Ao Tian", "Yunfeng Lu", "Xinxin Fan", "Changhao Wang", "Lanzhi Zhou", "Yeyao Zhang", "Yanfang Liu"], "title": "RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile", "comment": "11 pages,3 figures", "summary": "Personalized and continuous interactions are the key to enhancing user\nexperience in today's large language model (LLM)-based conversational systems,\nhowever, the finite context windows and static parametric memory make it\ndifficult to model the cross-session long-term user states and behavioral\nconsistency. Currently, the existing solutions to this predicament, such as\nretrieval-augmented generation (RAG) and explicit memory systems, primarily\nfocus on fact-level storage and retrieval, lacking the capability to distill\nlatent preferences and deep traits from the multi-turn dialogues, which limits\nthe long-term and effective user modeling, directly leading to the personalized\ninteractions remaining shallow, and hindering the cross-session continuity. To\nrealize the long-term memory and behavioral consistency for Language Agents in\nLLM era, we propose a self-evolving memory framework RGMem, inspired by the\nideology of classic renormalization group (RG) in physics, this framework\nenables to organize the dialogue history in multiple scales: it first extracts\nsemantics and user insights from episodic fragments, then through hierarchical\ncoarse-graining and rescaling operations, progressively forms a\ndynamically-evolved user profile. The core innovation of our work lies in\nmodeling memory evolution as a multi-scale process of information compression\nand emergence, which accomplishes the high-level and accurate user profiles\nfrom noisy and microscopic-level interactions.", "AI": {"tldr": "\u63d0\u51fa\u4e86RGMem\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u4fe1\u606f\u538b\u7f29\u548c\u6d8c\u73b0\u8fc7\u7a0b\u5b9e\u73b0\u957f\u671f\u7528\u6237\u5efa\u6a21\uff0c\u89e3\u51b3LLM\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u8de8\u4f1a\u8bdd\u957f\u671f\u7528\u6237\u72b6\u6001\u5efa\u6a21\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5982RAG\u548c\u663e\u5f0f\u8bb0\u5fc6\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u4e8b\u5b9e\u7ea7\u5b58\u50a8\u548c\u68c0\u7d22\uff0c\u7f3a\u4e4f\u4ece\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u63d0\u53d6\u6f5c\u5728\u504f\u597d\u548c\u6df1\u5c42\u7279\u8d28\u7684\u80fd\u529b\uff0c\u9650\u5236\u4e86\u957f\u671f\u6709\u6548\u7684\u7528\u6237\u5efa\u6a21\u3002", "method": "\u53d7\u7269\u7406\u5b66\u91cd\u6574\u5316\u7fa4\u601d\u60f3\u542f\u53d1\uff0cRGMem\u6846\u67b6\u901a\u8fc7\u5206\u5c42\u7c97\u7c92\u5316\u548c\u91cd\u6807\u5ea6\u64cd\u4f5c\uff0c\u4ece\u7247\u6bb5\u5bf9\u8bdd\u4e2d\u63d0\u53d6\u8bed\u4e49\u548c\u7528\u6237\u6d1e\u5bdf\uff0c\u9010\u6b65\u5f62\u6210\u52a8\u6001\u6f14\u5316\u7684\u7528\u6237\u753b\u50cf\u3002", "result": "\u5b9e\u73b0\u4e86\u4ece\u566a\u58f0\u548c\u5fae\u89c2\u5c42\u9762\u4ea4\u4e92\u4e2d\u6784\u5efa\u9ad8\u7ea7\u51c6\u786e\u7528\u6237\u753b\u50cf\u7684\u80fd\u529b\u3002", "conclusion": "RGMem\u6846\u67b6\u901a\u8fc7\u591a\u5c3a\u5ea6\u8bb0\u5fc6\u6f14\u5316\u8fc7\u7a0b\uff0c\u4e3a\u8bed\u8a00\u667a\u80fd\u4f53\u5728LLM\u65f6\u4ee3\u5b9e\u73b0\u4e86\u957f\u671f\u8bb0\u5fc6\u548c\u884c\u4e3a\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.16466", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16466", "abs": "https://arxiv.org/abs/2510.16466", "authors": ["Siddhartha Krothapalli", "Tridib Kumar Das", "Praveen Kumar", "Naveen Suravarpu", "Pratik Narang"], "title": "ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights", "comment": "11 pages, 1 figure, 4 tables", "summary": "As customer feedback becomes increasingly central to strategic growth, the\nability to derive actionable insights from unstructured reviews is essential.\nWhile traditional AI-driven systems excel at predicting user preferences, far\nless work has focused on transforming customer reviews into prescriptive,\nbusiness-facing recommendations. This paper introduces ReviewSense, a novel\nprescriptive decision support framework that leverages advanced large language\nmodels (LLMs) to transform customer reviews into targeted, actionable business\nrecommendations. By identifying key trends, recurring issues, and specific\nconcerns within customer sentiments, ReviewSense extends beyond\npreference-based systems to provide businesses with deeper insights for\nsustaining growth and enhancing customer loyalty. The novelty of this work lies\nin integrating clustering, LLM adaptation, and expert-driven evaluation into a\nunified, business-facing pipeline. Preliminary manual evaluations indicate\nstrong alignment between the model's recommendations and business objectives,\nhighlighting its potential for driving data-informed decision-making. This\nframework offers a new perspective on AI-driven sentiment analysis,\ndemonstrating its value in refining business strategies and maximizing the\nimpact of customer feedback.", "AI": {"tldr": "ReviewSense\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51b3\u7b56\u652f\u6301\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u504f\u597d\u9884\u6d4b\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edfAI\u7cfb\u7edf\u64c5\u957f\u9884\u6d4b\u7528\u6237\u504f\u597d\uff0c\u4f46\u7f3a\u4e4f\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u9762\u5411\u4e1a\u52a1\u7684\u89c4\u8303\u6027\u5efa\u8bae\u7684\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u63d0\u4f9b\u66f4\u6df1\u5c42\u6b21\u5546\u4e1a\u6d1e\u5bdf\u7684\u7cfb\u7edf\u3002", "method": "\u6574\u5408\u805a\u7c7b\u3001LLM\u9002\u914d\u548c\u4e13\u5bb6\u9a71\u52a8\u8bc4\u4f30\u7684\u7edf\u4e00\u4e1a\u52a1\u7ba1\u9053\uff0c\u8bc6\u522b\u5ba2\u6237\u60c5\u7eea\u4e2d\u7684\u5173\u952e\u8d8b\u52bf\u3001\u91cd\u590d\u95ee\u9898\u548c\u5177\u4f53\u5173\u6ce8\u70b9\u3002", "result": "\u521d\u6b65\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u5efa\u8bae\u4e0e\u5546\u4e1a\u76ee\u6807\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5177\u6709\u63a8\u52a8\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u9a71\u52a8\u7684\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5728\u4f18\u5316\u5546\u4e1a\u7b56\u7565\u548c\u6700\u5927\u5316\u5ba2\u6237\u53cd\u9988\u5f71\u54cd\u529b\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2510.16476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16476", "abs": "https://arxiv.org/abs/2510.16476", "authors": ["Xiaozhe Li", "Xinyu Fang", "Shengyuan Ding", "Linyang Li", "Haodong Duan", "Qingwen Liu", "Kai Chen"], "title": "NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems", "comment": null, "summary": "Large Language Models (LLMs) have shown strong reasoning capabilities, with\nmodels like OpenAI's O-series and DeepSeek R1 excelling at tasks such as\nmathematics, coding, logic, and puzzles through Reinforcement Learning with\nVerifiable Rewards (RLVR). However, their ability to solve more complex\noptimization problems - particularly NP-hard tasks - remains underexplored. To\nbridge this gap, we propose NP-ENGINE, the first comprehensive framework for\ntraining and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks\nacross five domains, each equipped with (i) a controllable instance generator,\n(ii) a rule-based verifier, and (iii) a heuristic solver that provides\napproximate optimal solutions as ground truth. This\ngenerator-verifier-heuristic pipeline enables scalable and verifiable RLVR\ntraining under hierarchical difficulties. We also introduce NP-BENCH, a\nbenchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'\nability to tackle NP-hard level reasoning problems, focusing not only on\nfeasibility but also on solution quality. Additionally, we present\nQWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on\nQwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and\nachieves SOTA performance with the same model size. Beyond in-domain tasks, we\ndemonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain\n(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),\nas well as non-reasoning tasks such as instruction following. We also observe a\nscaling trend: increasing task diversity improves OOD generalization. These\nfindings suggest that task-rich RLVR training is a promising direction for\nadvancing LLM's reasoning ability, revealing new insights into the scaling laws\nof RLVR.", "AI": {"tldr": "\u63d0\u51fa\u4e86NP-ENGINE\u6846\u67b6\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30LLMs\u5728NP\u96be\u95ee\u9898\u4e0a\u7684\u7efc\u5408\u6846\u67b6\uff0c\u5305\u542b10\u4e2a\u4efb\u52a1\u3001\u53ef\u63a7\u5b9e\u4f8b\u751f\u6210\u5668\u3001\u89c4\u5219\u9a8c\u8bc1\u5668\u548c\u542f\u53d1\u5f0f\u6c42\u89e3\u5668\u3002\u8bad\u7ec3\u51fa\u7684QWEN2.5-7B-NP\u6a21\u578b\u5728NP-BENCH\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8eGPT-4o\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u867d\u7136LLMs\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u7b49\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u89e3\u51b3\u66f4\u590d\u6742\u7684NP\u96be\u4f18\u5316\u95ee\u9898\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u4e13\u95e8\u6846\u67b6\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faNP-ENGINE\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u5668-\u9a8c\u8bc1\u5668-\u542f\u53d1\u5f0f\u6c42\u89e3\u5668\u7ba1\u9053\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684RLVR\u8bad\u7ec3\uff1b\u4f7f\u7528\u96f6RLVR\u548c\u8bfe\u7a0b\u5b66\u4e60\u8bad\u7ec3QWEN2.5-7B-NP\u6a21\u578b\u3002", "result": "QWEN2.5-7B-NP\u5728NP-BENCH\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8eGPT-4o\uff0c\u8fbe\u5230\u540c\u6a21\u578b\u5c3a\u5bf8\u4e0b\u7684SOTA\u6027\u80fd\uff1b\u5728\u8de8\u9886\u57df\u63a8\u7406\u4efb\u52a1\u548c\u975e\u63a8\u7406\u4efb\u52a1\u4e0a\u90fd\u5c55\u73b0\u51fa\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\uff1b\u53d1\u73b0\u4efb\u52a1\u591a\u6837\u6027\u589e\u52a0\u80fd\u63d0\u5347\u8de8\u9886\u57df\u6cdb\u5316\u3002", "conclusion": "\u4efb\u52a1\u4e30\u5bcc\u7684RLVR\u8bad\u7ec3\u662f\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u63ed\u793a\u4e86RLVR\u7684\u6269\u5c55\u89c4\u5f8b\uff0cNP\u96be\u95ee\u9898\u8bad\u7ec3\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.16533", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16533", "abs": "https://arxiv.org/abs/2510.16533", "authors": ["Eilene Tomkins-Flanagan", "Connor Hanley", "Mary A. Kelly"], "title": "Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination", "comment": null, "summary": "We present a typed computer language, Doug, in which all typed programs may\nbe proved to halt in polynomial time, encoded in a vector-symbolic architecture\n(VSA). Doug is just an encoding of the light linear functional programming\nlanguage (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are\nencoded using a slot-value encoding scheme based on holographic declarative\nmemory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the\nLisp VSA defined by (Flanagan, 2024). Doug allows for some points on the\nembedding space of a neural network to be interpreted as types, where the types\nof nearby points are similar both in structure and content. Types in Doug are\ntherefore learnable by a neural network. Following (Chollet, 2019), (Card,\n1983), and (Newell, 1981), we view skill as the application of a procedure, or\nprogram of action, that causes a goal to be satisfied. Skill acquisition may\ntherefore be expressed as program synthesis. Using Doug, we hope to describe a\nform of learning of skilled behaviour that follows a human-like pace of skill\nacquisition (i.e., substantially faster than brute force; Heathcote, 2000),\nexceeding the efficiency of all currently existing approaches (Kaplan, 2020;\nJones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling\nhuman mental representations, as they must actually exist in the brain, and\nthose representations' acquisition, as they are actually learned.", "AI": {"tldr": "\u63d0\u51fa\u4e86Doug\u8bed\u8a00\uff0c\u4e00\u79cd\u57fa\u4e8e\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u7684\u7c7b\u578b\u5316\u7f16\u7a0b\u8bed\u8a00\uff0c\u6240\u6709\u7c7b\u578b\u5316\u7a0b\u5e8f\u90fd\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u7ec8\u6b62\uff0c\u53ef\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6280\u80fd\u5b66\u4e60\u5efa\u6a21\u3002", "motivation": "\u5e0c\u671b\u63cf\u8ff0\u4e00\u79cd\u7b26\u5408\u4eba\u7c7b\u6280\u80fd\u83b7\u53d6\u901f\u5ea6\u7684\u5b66\u4e60\u65b9\u5f0f\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\uff0c\u66f4\u63a5\u8fd1\u5927\u8111\u4e2d\u5b9e\u9645\u5b58\u5728\u7684\u5fc3\u7406\u8868\u5f81\u53ca\u5176\u83b7\u53d6\u8fc7\u7a0b\u3002", "method": "\u5c06\u8f7b\u91cf\u7ebf\u6027\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00\u7f16\u7801\u5230\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u4e2d\uff0c\u4f7f\u7528\u57fa\u4e8e\u5168\u606f\u58f0\u660e\u6027\u8bb0\u5fc6\u7684\u69fd\u503c\u7f16\u7801\u65b9\u6848\u8868\u793a\u7c7b\u578b\uff0c\u4f7f\u7528Lisp VSA\u53d8\u4f53\u8868\u793a\u9879\u3002", "result": "Doug\u5141\u8bb8\u795e\u7ecf\u7f51\u7edc\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u67d0\u4e9b\u70b9\u88ab\u89e3\u91ca\u4e3a\u7c7b\u578b\uff0c\u4e14\u90bb\u8fd1\u70b9\u7684\u7c7b\u578b\u5728\u7ed3\u6784\u548c\u5185\u5bb9\u4e0a\u90fd\u76f8\u4f3c\uff0c\u56e0\u6b64\u7c7b\u578b\u53ef\u7531\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u6211\u4eec\u66f4\u63a5\u8fd1\u5efa\u6a21\u5927\u8111\u4e2d\u5b9e\u9645\u5b58\u5728\u7684\u5fc3\u7406\u8868\u5f81\u53ca\u5176\u83b7\u53d6\u8fc7\u7a0b\uff0c\u4e3a\u6280\u80fd\u83b7\u53d6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\u3002"}}
{"id": "2510.16555", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16555", "abs": "https://arxiv.org/abs/2510.16555", "authors": ["Qiongyan Wang", "Xingchen Zou", "Yutian Jiang", "Haomin Wen", "Jiaheng Wei", "Qingsong Wen", "Yuxuan Liang"], "title": "Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence", "comment": null, "summary": "Rapid urbanization intensifies the demand for Urban General Intelligence\n(UGI), referring to AI systems that can understand and reason about complex\nurban environments. Recent studies have built urban foundation models using\nsupervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit\npersistent geospatial bias, producing regionally skewed predictions and limited\ngeneralization. To this end, we propose Urban-R1, a reinforcement\nlearning-based post-training framework that aligns MLLMs with the objectives of\nUGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize\nreasoning across geographic groups and employs urban region profiling as a\nproxy task to provide measurable rewards from multimodal urban data. Extensive\nexperiments across diverse regions and tasks show that Urban-R1 effectively\nmitigates geo-bias and improves cross-region generalization, outperforming both\nSFT-trained and closed-source models. Our results highlight reinforcement\nlearning alignment as a promising pathway toward equitable and trustworthy\nurban intelligence.", "AI": {"tldr": "\u63d0\u51faUrban-R1\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u591a\u6a21\u6001\u5927\u6a21\u578b\u4e0e\u57ce\u5e02\u901a\u7528\u667a\u80fd\u76ee\u6807\uff0c\u901a\u8fc7\u5206\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7f13\u89e3\u5730\u7406\u504f\u89c1\uff0c\u63d0\u5347\u8de8\u533a\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5feb\u901f\u57ce\u5e02\u5316\u52a0\u5267\u4e86\u5bf9\u57ce\u5e02\u901a\u7528\u667a\u80fd\u7684\u9700\u6c42\uff0c\u73b0\u6709\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u7684\u57ce\u5e02\u57fa\u7840\u6a21\u578b\u5b58\u5728\u6301\u7eed\u7684\u5730\u7406\u504f\u89c1\uff0c\u5bfc\u81f4\u533a\u57df\u9884\u6d4b\u504f\u5dee\u548c\u6709\u9650\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u540e\u8bad\u7ec3\u6846\u67b6Urban-R1\uff0c\u4f7f\u7528\u5206\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u4f18\u5316\u8de8\u5730\u7406\u7fa4\u4f53\u7684\u63a8\u7406\uff0c\u5e76\u4ee5\u57ce\u5e02\u533a\u57df\u753b\u50cf\u4f5c\u4e3a\u4ee3\u7406\u4efb\u52a1\u4ece\u591a\u6a21\u6001\u57ce\u5e02\u6570\u636e\u63d0\u4f9b\u53ef\u6d4b\u91cf\u5956\u52b1\u3002", "result": "\u8de8\u591a\u4e2a\u533a\u57df\u548c\u4efb\u52a1\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cUrban-R1\u6709\u6548\u7f13\u89e3\u5730\u7406\u504f\u89c1\u5e76\u6539\u5584\u8de8\u533a\u57df\u6cdb\u5316\uff0c\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u8bad\u7ec3\u548c\u95ed\u6e90\u6a21\u578b\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u662f\u5b9e\u73b0\u516c\u5e73\u53ef\u4fe1\u57ce\u5e02\u667a\u80fd\u7684\u6709\u524d\u666f\u8def\u5f84\u3002"}}
{"id": "2510.16559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16559", "abs": "https://arxiv.org/abs/2510.16559", "authors": ["Tian Xia", "Tianrun Gao", "Wenhao Deng", "Long Wei", "Xiaowei Qian", "Yixian Jiang", "Chenglei Yu", "Tailin Wu"], "title": "BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction", "comment": "33 pages, 10 figures", "summary": "Engineering construction automation aims to transform natural language\nspecifications into physically viable structures, requiring complex integrated\nreasoning under strict physical constraints. While modern LLMs possess broad\nknowledge and strong reasoning capabilities that make them promising candidates\nfor this domain, their construction competencies remain largely unevaluated. To\naddress this gap, we introduce BuildArena, the first physics-aligned\ninteractive benchmark designed for language-driven engineering construction. It\ncontributes to the community in four aspects: (1) a highly customizable\nbenchmarking framework for in-depth comparison and analysis of LLMs; (2) an\nextendable task design strategy spanning static and dynamic mechanics across\nmultiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for\nsupporting construction based on language instructions; (4) a baseline LLM\nagentic workflow that effectively evaluates diverse model capabilities. On\neight frontier LLMs, BuildArena comprehensively evaluates their capabilities\nfor language-driven and physics-grounded construction automation. The project\npage is at https://build-arena.github.io/.", "AI": {"tldr": "BuildArena\u662f\u9996\u4e2a\u9762\u5411\u8bed\u8a00\u9a71\u52a8\u5de5\u7a0b\u5efa\u8bbe\u7684\u7269\u7406\u5bf9\u9f50\u4ea4\u4e92\u5f0f\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u5de5\u7a0b\u5efa\u7b51\u81ea\u52a8\u5316\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u867d\u7136\u73b0\u4ee3LLM\u5177\u6709\u5e7f\u6cdb\u77e5\u8bc6\u548c\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u5de5\u7a0b\u5efa\u8bbe\u9886\u57df\u7684\u4e13\u4e1a\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u8bc4\u4f30\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u4e86\u9ad8\u5ea6\u53ef\u5b9a\u5236\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u5305\u542b\u53ef\u6269\u5c55\u7684\u4efb\u52a1\u8bbe\u8ba1\u7b56\u7565\u30013D\u7a7a\u95f4\u51e0\u4f55\u8ba1\u7b97\u5e93\u548c\u57fa\u7ebfLLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7528\u4e8e\u8bc4\u4f308\u4e2a\u524d\u6cbfLLM\u3002", "result": "BuildArena\u80fd\u591f\u5168\u9762\u8bc4\u4f30LLM\u5728\u8bed\u8a00\u9a71\u52a8\u548c\u7269\u7406\u57fa\u7840\u7684\u5efa\u7b51\u81ea\u52a8\u5316\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u9996\u4e2a\u7269\u7406\u5bf9\u9f50\u7684\u4ea4\u4e92\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "BuildArena\u586b\u8865\u4e86LLM\u5728\u5de5\u7a0b\u5efa\u8bbe\u81ea\u52a8\u5316\u9886\u57df\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u8bed\u8a00\u9a71\u52a8\u7684\u7269\u7406\u7ea6\u675f\u5efa\u7b51\u4efb\u52a1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2510.16572", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.16572", "abs": "https://arxiv.org/abs/2510.16572", "authors": ["Ayush Chopra", "Aman Sharma", "Feroz Ahmad", "Luca Muscariello", "Vijoy Pandey", "Ramesh Raskar"], "title": "Ripple Effect Protocol: Coordinating Agent Populations", "comment": null, "summary": "Modern AI agents can exchange messages using protocols such as A2A and ACP,\nyet these mechanisms emphasize communication over coordination. As agent\npopulations grow, this limitation produces brittle collective behavior, where\nindividually smart agents converge on poor group outcomes. We introduce the\nRipple Effect Protocol (REP), a coordination protocol in which agents share not\nonly their decisions but also lightweight sensitivities - signals expressing\nhow their choices would change if key environmental variables shifted. These\nsensitivities ripple through local networks, enabling groups to align faster\nand more stably than with agent-centric communication alone. We formalize REP's\nprotocol specification, separating required message schemas from optional\naggregation rules, and evaluate it across scenarios with varying incentives and\nnetwork topologies. Benchmarks across three domains: (i) supply chain cascades\n(Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling),\nand (iii) sustainable resource allocation (Fishbanks) show that REP improves\ncoordination accuracy and efficiency over A2A by 41 to 100%, while flexibly\nhandling multimodal sensitivity signals from LLMs. By making coordination a\nprotocol-level capability, REP provides scalable infrastructure for the\nemerging Internet of Agents", "AI": {"tldr": "\u63d0\u51fa\u4e86Ripple Effect Protocol (REP)\uff0c\u4e00\u79cd\u534f\u8c03\u534f\u8bae\uff0c\u8ba9\u667a\u80fd\u4f53\u4e0d\u4ec5\u5171\u4eab\u51b3\u7b56\uff0c\u8fd8\u5171\u4eab\u8f7b\u91cf\u7ea7\u654f\u611f\u5ea6\u4fe1\u53f7\uff0c\u4ece\u800c\u5728\u7fa4\u4f53\u4e2d\u5b9e\u73b0\u66f4\u5feb\u66f4\u7a33\u5b9a\u7684\u534f\u8c03\u3002", "motivation": "\u73b0\u6709\u7684AI\u667a\u80fd\u4f53\u901a\u4fe1\u534f\u8bae\uff08\u5982A2A\u548cACP\uff09\u5f3a\u8c03\u901a\u4fe1\u800c\u975e\u534f\u8c03\uff0c\u968f\u7740\u667a\u80fd\u4f53\u7fa4\u4f53\u89c4\u6a21\u589e\u957f\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u8106\u5f31\u7684\u96c6\u4f53\u884c\u4e3a\uff0c\u5373\u4f7f\u4e2a\u4f53\u667a\u80fd\u4f53\u5f88\u806a\u660e\uff0c\u7fa4\u4f53\u7ed3\u679c\u4e5f\u5f88\u5dee\u3002", "method": "REP\u534f\u8bae\u8ba9\u667a\u80fd\u4f53\u5171\u4eab\u51b3\u7b56\u548c\u8f7b\u91cf\u7ea7\u654f\u611f\u5ea6\u4fe1\u53f7\uff08\u8868\u8fbe\u5173\u952e\u73af\u5883\u53d8\u91cf\u53d8\u5316\u65f6\u9009\u62e9\u5982\u4f55\u6539\u53d8\uff09\uff0c\u8fd9\u4e9b\u654f\u611f\u5ea6\u5728\u5c40\u90e8\u7f51\u7edc\u4e2d\u4f20\u64ad\u3002\u534f\u8bae\u89c4\u8303\u5206\u79bb\u4e86\u5fc5\u9700\u7684\u6d88\u606f\u6a21\u5f0f\u4e0e\u53ef\u9009\u7684\u805a\u5408\u89c4\u5219\u3002", "result": "\u5728\u4e09\u4e2a\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1a\uff08i\uff09\u4f9b\u5e94\u94fe\u7ea7\u8054\uff08\u5564\u9152\u6e38\u620f\uff09\u3001\uff08ii\uff09\u7a00\u758f\u7f51\u7edc\u4e2d\u7684\u504f\u597d\u805a\u5408\uff08\u7535\u5f71\u8c03\u5ea6\uff09\u3001\uff08iii\uff09\u53ef\u6301\u7eed\u8d44\u6e90\u5206\u914d\uff08Fishbanks\uff09\uff0cREP\u76f8\u6bd4A2A\u5c06\u534f\u8c03\u51c6\u786e\u6027\u548c\u6548\u7387\u63d0\u9ad8\u4e8641%\u5230100%\u3002", "conclusion": "\u901a\u8fc7\u5c06\u534f\u8c03\u4f5c\u4e3a\u534f\u8bae\u7ea7\u80fd\u529b\uff0cREP\u4e3a\u65b0\u5174\u7684\u667a\u80fd\u4f53\u4e92\u8054\u7f51\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2510.16582", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16582", "abs": "https://arxiv.org/abs/2510.16582", "authors": ["Junchi Yu", "Yujie Liu", "Jindong Gu", "Philip Torr", "Dongzhan Zhou"], "title": "Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?", "comment": "NeurIPS 2025 (Spotlight)", "summary": "Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances\nlarge language models (LLMs) by providing structured and interpretable external\nknowledge. However, existing KG-based RAG methods struggle to retrieve accurate\nand diverse information from text-rich KGs for complex real-world queries.\nProcess Reward Models (PRMs) offer a way to align the retrieval process of\nKG-based RAG with query-specific knowledge requirements, but they heavily rely\non process-level supervision signals that are expensive and hard to obtain on\nKGs. To address this challenge, we propose GraphFlow, a framework that\nefficiently retrieves accurate and diverse knowledge required for real-world\nqueries from text-rich KGs. GraphFlow employs a transition-based flow matching\nobjective to jointly optimize a retrieval policy and a flow estimator. The flow\nestimator factorizes the reward of the retrieval outcome into the intermediate\nretrieval states. Such reward factorization guides the retrieval policy to\nretrieve candidates from KGs in proportion to their reward. This allows\nGraphFlow to explore high-quality regions of KGs that yield diverse and\nrelevant results. We evaluate GraphFlow on the STaRK benchmark, which includes\nreal-world queries from multiple domains over text-rich KGs. GraphFlow\noutperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit\nrate and recall. It also shows strong generalization to unseen KGs,\ndemonstrating its effectiveness and robustness.", "AI": {"tldr": "GraphFlow\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u76ee\u6807\u4f18\u5316\u68c0\u7d22\u7b56\u7565\uff0c\u4ece\u6587\u672c\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u9ad8\u6548\u68c0\u7d22\u51c6\u786e\u591a\u6837\u7684\u77e5\u8bc6\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u65b9\u6cd5\u96be\u4ee5\u4ece\u6587\u672c\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e3a\u590d\u6742\u771f\u5b9e\u4e16\u754c\u67e5\u8be2\u68c0\u7d22\u51c6\u786e\u591a\u6837\u7684\u4fe1\u606f\uff0c\u800c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u9700\u8981\u6602\u8d35\u7684\u8fc7\u7a0b\u7ea7\u76d1\u7763\u4fe1\u53f7\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u8f6c\u79fb\u7684\u6d41\u5339\u914d\u76ee\u6807\u8054\u5408\u4f18\u5316\u68c0\u7d22\u7b56\u7565\u548c\u6d41\u4f30\u8ba1\u5668\uff0c\u6d41\u4f30\u8ba1\u5668\u5c06\u68c0\u7d22\u7ed3\u679c\u7684\u5956\u52b1\u5206\u89e3\u5230\u4e2d\u95f4\u68c0\u7d22\u72b6\u6001\uff0c\u6307\u5bfc\u68c0\u7d22\u7b56\u7565\u6309\u5956\u52b1\u6bd4\u4f8b\u4ece\u77e5\u8bc6\u56fe\u8c31\u4e2d\u68c0\u7d22\u5019\u9009\u3002", "result": "\u5728STaRK\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGraphFlow\u5728\u547d\u4e2d\u7387\u548c\u53ec\u56de\u7387\u4e0a\u5e73\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff08\u5305\u62ecGPT-4o\uff0910%\uff0c\u5e76\u5bf9\u672a\u89c1\u8fc7\u7684\u77e5\u8bc6\u56fe\u8c31\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "GraphFlow\u6846\u67b6\u80fd\u6709\u6548\u4ece\u6587\u672c\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u68c0\u7d22\u51c6\u786e\u591a\u6837\u7684\u77e5\u8bc6\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u67e5\u8be2\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.16601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16601", "abs": "https://arxiv.org/abs/2510.16601", "authors": ["Tianxing Wu", "Shutong Zhu", "Jingting Wang", "Ning Xu", "Guilin Qi", "Haofen Wang"], "title": "Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning", "comment": "13 pages, accepted by NeurIPS 2025 (spotlight)", "summary": "Uncertain knowledge graphs (UKGs) associate each triple with a confidence\nscore to provide more precise knowledge representations. Recently, since\nreal-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)\ncompletion attracts more attention, aiming to complete missing triples and\nconfidences. Current studies attempt to learn UKG embeddings to solve this\nproblem, but they neglect the extremely imbalanced distributions of triple\nconfidences. This causes that the learnt embeddings are insufficient to\nhigh-quality UKG completion. Thus, in this paper, to address the above issue,\nwe propose a new semi-supervised Confidence Distribution Learning (ssCDL)\nmethod for UKG completion, where each triple confidence is transformed into a\nconfidence distribution to introduce more supervision information of different\nconfidences to reinforce the embedding learning process. ssCDL iteratively\nlearns UKG embedding by relational learning on labeled data (i.e., existing\ntriples with confidences) and unlabeled data with pseudo labels (i.e., unseen\ntriples with the generated confidences), which are predicted by meta-learning\nto augment the training data and rebalance the distribution of triple\nconfidences. Experiments on two UKG datasets demonstrate that ssCDL\nconsistently outperforms state-of-the-art baselines in different evaluation\nmetrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u7f6e\u4fe1\u5ea6\u5206\u5e03\u5b66\u4e60\u65b9\u6cd5\uff08ssCDL\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7f6e\u4fe1\u5ea6\u5206\u5e03\u6781\u5ea6\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u7f6e\u4fe1\u5ea6\u8f6c\u6362\u4e3a\u5206\u5e03\u5e76\u5229\u7528\u5143\u5b66\u4e60\u751f\u6210\u4f2a\u6807\u7b7e\u6765\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\u5ffd\u7565\u4e86\u7f6e\u4fe1\u5ea6\u7684\u6781\u5ea6\u4e0d\u5e73\u8861\u5206\u5e03\uff0c\u5bfc\u81f4\u5b66\u4e60\u5230\u7684\u5d4c\u5165\u8868\u793a\u4e0d\u8db3\u4ee5\u652f\u6301\u9ad8\u8d28\u91cf\u7684\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u3002", "method": "\u5c06\u6bcf\u4e2a\u4e09\u5143\u7ec4\u7f6e\u4fe1\u5ea6\u8f6c\u6362\u4e3a\u7f6e\u4fe1\u5ea6\u5206\u5e03\uff0c\u5f15\u5165\u66f4\u591a\u76d1\u7763\u4fe1\u606f\uff1b\u901a\u8fc7\u5143\u5b66\u4e60\u9884\u6d4b\u672a\u89c1\u4e09\u5143\u7ec4\u7684\u7f6e\u4fe1\u5ea6\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u5728\u6807\u8bb0\u6570\u636e\u548c\u672a\u6807\u8bb0\u6570\u636e\u4e0a\u8fed\u4ee3\u5b66\u4e60\u5d4c\u5165\u8868\u793a\u3002", "result": "\u5728\u4e24\u4e2a\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cssCDL\u5728\u4e0d\u540c\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ssCDL\u65b9\u6cd5\u901a\u8fc7\u5904\u7406\u7f6e\u4fe1\u5ea6\u5206\u5e03\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u7684\u6027\u80fd\u3002"}}
{"id": "2510.16614", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16614", "abs": "https://arxiv.org/abs/2510.16614", "authors": ["Xuan Zhang", "Ruixiao Li", "Zhijian Zhou", "Long Li", "Yulei Qin", "Ke Li", "Xing Sun", "Xiaoyu Tan", "Chao Qu", "Yuan Qi"], "title": "Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards", "comment": null, "summary": "Reinforcement Learning (RL) has become a compelling way to strengthen the\nmulti step reasoning ability of Large Language Models (LLMs). However,\nprevalent RL paradigms still lean on sparse outcome-based rewards and limited\nexploration, which often drives LLMs toward repetitive and suboptimal reasoning\npatterns. In this paper, we study the central question of how to design\nexploration for LLM reasoning and introduce MERCI (Motivating Exploration in\nLLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that\naugments policy optimization with a principled intrinsic reward. Building on\nthe idea of count-based exploration, MERCI leverages a lightweight Coin\nFlipping Network (CFN) to estimate the pseudo count and further epistemic\nuncertainty over reasoning trajectories, and converts them into an intrinsic\nreward that values novelty while preserving the learning signal from task\nrewards. We integrate MERCI into some advanced RL frameworks like Group\nRelative Policy Optimization (GRPO). Experiments on complex reasoning\nbenchmarks demonstrate that MERCI encourages richer and more varied chains of\nthought, significantly improves performance over strong baselines, and helps\nthe policy escape local routines to discover better solutions. It indicates\nthat our targeted intrinsic motivation can make exploration reliable for\nlanguage model reasoning.", "AI": {"tldr": "MERCI\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u8ba1\u6570\u7684\u5185\u5728\u5956\u52b1\u6765\u589e\u5f3aLLM\u63a8\u7406\u4e2d\u7684\u63a2\u7d22\uff0c\u907f\u514d\u9677\u5165\u91cd\u590d\u548c\u6b21\u4f18\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709RL\u8303\u5f0f\u4f9d\u8d56\u7a00\u758f\u7684\u7ed3\u679c\u5956\u52b1\u548c\u6709\u9650\u63a2\u7d22\uff0c\u5bfc\u81f4LLM\u503e\u5411\u4e8e\u91cd\u590d\u548c\u6b21\u4f18\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u597d\u7684\u63a2\u7d22\u673a\u5236\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7Coin Flipping Network\u4f30\u8ba1\u63a8\u7406\u8f68\u8ff9\u7684\u4f2a\u8ba1\u6570\u548c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u5185\u5728\u5956\u52b1\uff0c\u5e76\u4e0e\u4efb\u52a1\u5956\u52b1\u7ed3\u5408\u3002", "result": "\u5728\u590d\u6742\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMERCI\u9f13\u52b1\u66f4\u4e30\u5bcc\u591a\u6837\u7684\u601d\u7ef4\u94fe\uff0c\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5e2e\u52a9\u7b56\u7565\u9003\u79bb\u5c40\u90e8\u6a21\u5f0f\u53d1\u73b0\u66f4\u597d\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u6709\u9488\u5bf9\u6027\u7684\u5185\u5728\u52a8\u673a\u53ef\u4ee5\u4f7f\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u63a2\u7d22\u66f4\u52a0\u53ef\u9760\u6709\u6548\u3002"}}
{"id": "2510.16658", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.16658", "abs": "https://arxiv.org/abs/2510.16658", "authors": ["Shihao Yang", "Xiying Huang", "Danilo Bernardo", "Jun-En Ding", "Andrew Michael", "Jingmei Yang", "Patrick Kwan", "Ashish Raj", "Feng Liu"], "title": "Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review", "comment": null, "summary": "The advent of large-scale artificial intelligence (AI) models has a\ntransformative effect on neuroscience research, which represents a paradigm\nshift from the traditional computational methods through the facilitation of\nend-to-end learning from raw brain signals and neural data. In this paper, we\nexplore the transformative effects of large-scale AI models on five major\nneuroscience domains: neuroimaging and data processing, brain-computer\ninterfaces and neural decoding, molecular neuroscience and genomic modeling,\nclinical assistance and translational frameworks, and disease-specific\napplications across neurological and psychiatric disorders. These models are\ndemonstrated to address major computational neuroscience challenges, including\nmultimodal neural data integration, spatiotemporal pattern interpretation, and\nthe derivation of translational frameworks for clinical deployment. Moreover,\nthe interaction between neuroscience and AI has become increasingly reciprocal,\nas biologically informed architectural constraints are now incorporated to\ndevelop more interpretable and computationally efficient models. This review\nhighlights both the notable promise of such technologies and key implementation\nconsiderations, with particular emphasis on rigorous evaluation frameworks,\neffective domain knowledge integration, and comprehensive ethical guidelines\nfor clinical use. Finally, a systematic listing of critical neuroscience\ndatasets used to derive and validate large-scale AI models across diverse\nresearch applications is provided.", "AI": {"tldr": "\u5927\u89c4\u6a21AI\u6a21\u578b\u6b63\u5728\u53d8\u9769\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u5b66\u4e60\u4ece\u539f\u59cb\u8111\u4fe1\u53f7\u4e2d\u63d0\u53d6\u4fe1\u606f\uff0c\u5728\u795e\u7ecf\u5f71\u50cf\u3001\u8111\u673a\u63a5\u53e3\u3001\u5206\u5b50\u795e\u7ecf\u79d1\u5b66\u3001\u4e34\u5e8a\u8f85\u52a9\u548c\u75be\u75c5\u5e94\u7528\u7b49\u4e94\u5927\u9886\u57df\u4ea7\u751f\u6df1\u8fdc\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u8ba1\u7b97\u65b9\u6cd5\u5728\u795e\u7ecf\u79d1\u5b66\u4e2d\u9762\u4e34\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u3001\u65f6\u7a7a\u6a21\u5f0f\u89e3\u91ca\u7b49\u6311\u6218\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684AI\u6a21\u578b\u6765\u4fc3\u8fdb\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\u7684\u8303\u5f0f\u8f6c\u53d8\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21AI\u6a21\u578b\u5b9e\u73b0\u7aef\u5230\u7aef\u5b66\u4e60\uff0c\u6574\u5408\u591a\u6a21\u6001\u795e\u7ecf\u6570\u636e\uff0c\u7ed3\u5408\u751f\u7269\u5b66\u542f\u53d1\u7684\u67b6\u6784\u7ea6\u675f\u5f00\u53d1\u66f4\u53ef\u89e3\u91ca\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u6a21\u578b\u3002", "result": "\u8fd9\u4e9b\u6a21\u578b\u6210\u529f\u89e3\u51b3\u4e86\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u4e3b\u8981\u8ba1\u7b97\u6311\u6218\uff0c\u4fc3\u8fdb\u4e86\u795e\u7ecf\u79d1\u5b66\u4e0eAI\u7684\u4e92\u60e0\u53d1\u5c55\uff0c\u5e76\u5efa\u7acb\u4e86\u4e34\u5e8a\u90e8\u7f72\u7684\u8f6c\u5316\u6846\u67b6\u3002", "conclusion": "\u5927\u89c4\u6a21AI\u6a21\u578b\u5728\u795e\u7ecf\u79d1\u5b66\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u4e25\u683c\u7684\u8bc4\u4f30\u6846\u67b6\u3001\u6709\u6548\u7684\u9886\u57df\u77e5\u8bc6\u6574\u5408\u548c\u5168\u9762\u7684\u4e34\u5e8a\u4f26\u7406\u6307\u5357\u6765\u786e\u4fdd\u6210\u529f\u5b9e\u65bd\u3002"}}
{"id": "2510.16701", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16701", "abs": "https://arxiv.org/abs/2510.16701", "authors": ["Ni Zhang", "Zhiguang Cao", "Jianan Zhou", "Cong Zhang", "Yew-Soon Ong"], "title": "An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems", "comment": null, "summary": "Complex vehicle routing problems (VRPs) remain a fundamental challenge,\ndemanding substantial expert effort for intent interpretation and algorithm\ndesign. While large language models (LLMs) offer a promising path toward\nautomation, current approaches still rely on external intervention, which\nrestrict autonomy and often lead to execution errors and low solution\nfeasibility. To address these challenges, we propose an Agentic Framework with\nLLMs (AFL) for solving complex vehicle routing problems, achieving full\nautomation from problem instance to solution. AFL directly extracts knowledge\nfrom raw inputs and enables self-contained code generation without handcrafted\nmodules or external solvers. To improve trustworthiness, AFL decomposes the\noverall pipeline into three manageable subtasks and employs four specialized\nagents whose coordinated interactions enforce cross-functional consistency and\nlogical soundness. Extensive experiments on 60 complex VRPs, ranging from\nstandard benchmarks to practical variants, validate the effectiveness and\ngenerality of our framework, showing comparable performance against\nmeticulously designed algorithms. Notably, it substantially outperforms\nexisting LLM-based baselines in both code reliability and solution feasibility,\nachieving rates close to 100% on the evaluated benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6AFL\uff0c\u7528\u4e8e\u89e3\u51b3\u590d\u6742\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4ece\u95ee\u9898\u5b9e\u4f8b\u5230\u89e3\u51b3\u65b9\u6848\u7684\u5b8c\u5168\u81ea\u52a8\u5316\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u6216\u5916\u90e8\u6c42\u89e3\u5668\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u89e3\u51b3\u590d\u6742\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u65f6\u4ecd\u9700\u8981\u5916\u90e8\u5e72\u9884\uff0c\u5bfc\u81f4\u81ea\u4e3b\u6027\u53d7\u9650\u3001\u6267\u884c\u9519\u8bef\u591a\u548c\u89e3\u51b3\u65b9\u6848\u53ef\u884c\u6027\u4f4e\u3002", "method": "AFL\u6846\u67b6\u5c06\u6574\u4e2a\u6d41\u7a0b\u5206\u89e3\u4e3a\u4e09\u4e2a\u53ef\u7ba1\u7406\u7684\u5b50\u4efb\u52a1\uff0c\u5e76\u91c7\u7528\u56db\u4e2a\u4e13\u95e8\u5316\u4ee3\u7406\uff0c\u901a\u8fc7\u534f\u8c03\u4ea4\u4e92\u786e\u4fdd\u8de8\u529f\u80fd\u4e00\u81f4\u6027\u548c\u903b\u8f91\u5408\u7406\u6027\uff0c\u76f4\u63a5\u4ece\u539f\u59cb\u8f93\u5165\u63d0\u53d6\u77e5\u8bc6\u5e76\u751f\u6210\u81ea\u5305\u542b\u4ee3\u7801\u3002", "result": "\u572860\u4e2a\u590d\u6742VRP\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4ee3\u7801\u53ef\u9760\u6027\u548c\u89e3\u51b3\u65b9\u6848\u53ef\u884c\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u8bc4\u4f30\u57fa\u51c6\u4e0a\u63a5\u8fd1100%\u7684\u6210\u529f\u7387\uff0c\u4e0e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7b97\u6cd5\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "AFL\u6846\u67b6\u4e3a\u5b9e\u73b0\u590d\u6742\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7684\u5b8c\u5168\u81ea\u52a8\u5316\u6c42\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eLLM\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u548c\u53ef\u884c\u6027\u3002"}}
{"id": "2510.16720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16720", "abs": "https://arxiv.org/abs/2510.16720", "authors": ["Jitao Sang", "Jinlin Xiao", "Jiarun Han", "Jilin Chen", "Xiaoyi Chen", "Shuyu Wei", "Yongjie Sun", "Yuhang Wang"], "title": "Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI", "comment": null, "summary": "The rapid evolution of agentic AI marks a new phase in artificial\nintelligence, where Large Language Models (LLMs) no longer merely respond but\nact, reason, and adapt. This survey traces the paradigm shift in building\nagentic AI: from Pipeline-based systems, where planning, tool use, and memory\nare orchestrated by external logic, to the emerging Model-native paradigm,\nwhere these capabilities are internalized within the model's parameters. We\nfirst position Reinforcement Learning (RL) as the algorithmic engine enabling\nthis paradigm shift. By reframing learning from imitating static data to\noutcome-driven exploration, RL underpins a unified solution of LLM + RL + Task\nacross language, vision and embodied domains. Building on this, the survey\nsystematically reviews how each capability -- Planning, Tool use, and Memory --\nhas evolved from externally scripted modules to end-to-end learned behaviors.\nFurthermore, it examines how this paradigm shift has reshaped major agent\napplications, specifically the Deep Research agent emphasizing long-horizon\nreasoning and the GUI agent emphasizing embodied interaction. We conclude by\ndiscussing the continued internalization of agentic capabilities like\nMulti-agent collaboration and Reflection, alongside the evolving roles of the\nsystem and model layers in future agentic AI. Together, these developments\noutline a coherent trajectory toward model-native agentic AI as an integrated\nlearning and interaction framework, marking the transition from constructing\nsystems that apply intelligence to developing models that grow intelligence\nthrough experience.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u667a\u80fdAI\u4ece\u57fa\u4e8e\u7ba1\u9053\u7684\u7cfb\u7edf\u5411\u6a21\u578b\u539f\u751f\u8303\u5f0f\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5176\u4e2d\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u548c\u8bb0\u5fc6\u7b49\u80fd\u529b\u4ece\u5916\u90e8\u7f16\u6392\u8f6c\u53d8\u4e3a\u6a21\u578b\u5185\u90e8\u53c2\u6570\u5316\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u7aef\u5230\u7aef\u5b66\u4e60\u3002", "motivation": "\u8ffd\u8e2a\u667a\u80fdAI\u6784\u5efa\u65b9\u5f0f\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4ece\u5916\u90e8\u903b\u8f91\u7f16\u6392\u7684\u7ba1\u9053\u7cfb\u7edf\u8f6c\u5411\u80fd\u529b\u5185\u90e8\u5316\u7684\u6a21\u578b\u539f\u751f\u8303\u5f0f\uff0c\u63a2\u7d22AI\u4ece\u88ab\u52a8\u54cd\u5e94\u5230\u4e3b\u52a8\u884c\u52a8\u3001\u63a8\u7406\u548c\u9002\u5e94\u7684\u6f14\u8fdb\u3002", "method": "\u7cfb\u7edf\u56de\u987e\u4e86\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u548c\u8bb0\u5fc6\u4e09\u5927\u80fd\u529b\u7684\u6f14\u8fdb\u8fc7\u7a0b\uff0c\u5206\u6790\u4e86\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u7b97\u6cd5\u5f15\u64ce\u5982\u4f55\u652f\u6491LLM+RL+Task\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u8003\u5bdf\u4e86\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u548cGUI\u4ee3\u7406\u7b49\u4e3b\u8981\u5e94\u7528\u3002", "result": "\u63ed\u793a\u4e86\u667a\u80fdAI\u80fd\u529b\u4ece\u5916\u90e8\u811a\u672c\u6a21\u5757\u5411\u7aef\u5230\u7aef\u5b66\u4e60\u884c\u4e3a\u7684\u8f6c\u53d8\u8f68\u8ff9\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u539f\u751f\u667a\u80fdAI\u4f5c\u4e3a\u96c6\u6210\u5b66\u4e60\u548c\u4ea4\u4e92\u6846\u67b6\u7684\u53d1\u5c55\u8def\u5f84\u3002", "conclusion": "\u667a\u80fdAI\u6b63\u671d\u7740\u6a21\u578b\u539f\u751f\u65b9\u5411\u53d1\u5c55\uff0c\u4ece\u6784\u5efa\u5e94\u7528\u667a\u80fd\u7684\u7cfb\u7edf\u8f6c\u5411\u5f00\u53d1\u901a\u8fc7\u7ecf\u9a8c\u589e\u957f\u667a\u80fd\u7684\u6a21\u578b\uff0c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u53cd\u601d\u7b49\u80fd\u529b\u5c06\u7ee7\u7eed\u5185\u90e8\u5316\uff0c\u7cfb\u7edf\u548c\u6a21\u578b\u5c42\u7684\u89d2\u8272\u5c06\u4e0d\u65ad\u6f14\u53d8\u3002"}}
{"id": "2510.16724", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16724", "abs": "https://arxiv.org/abs/2510.16724", "authors": ["Minhua Lin", "Zongyu Wu", "Zhichao Xu", "Hui Liu", "Xianfeng Tang", "Qi He", "Charu Aggarwal", "Hui Liu", "Xiang Zhang", "Suhang Wang"], "title": "A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications", "comment": "38 pages, 4 figures, 7 tables", "summary": "The advent of large language models (LLMs) has transformed information access\nand reasoning through open-ended natural language interaction. However, LLMs\nremain limited by static knowledge, factual hallucinations, and the inability\nto retrieve real-time or domain-specific information. Retrieval-Augmented\nGeneration (RAG) mitigates these issues by grounding model outputs in external\nevidence, but traditional RAG pipelines are often single turn and heuristic,\nlacking adaptive control over retrieval and reasoning. Recent advances in\nagentic search address these limitations by enabling LLMs to plan, retrieve,\nand reflect through multi-step interaction with search environments. Within\nthis paradigm, reinforcement learning (RL) offers a powerful mechanism for\nadaptive and self-improving search behavior. This survey provides the first\ncomprehensive overview of \\emph{RL-based agentic search}, organizing the\nemerging field along three complementary dimensions: (i) What RL is for\n(functional roles), (ii) How RL is used (optimization strategies), and (iii)\nWhere RL is applied (scope of optimization). We summarize representative\nmethods, evaluation protocols, and applications, and discuss open challenges\nand future directions toward building reliable and scalable RL driven agentic\nsearch systems. We hope this survey will inspire future research on the\nintegration of RL and agentic search. Our repository is available at\nhttps://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u641c\u7d22\u9886\u57df\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u4ece\u529f\u80fd\u89d2\u8272\u3001\u4f18\u5316\u7b56\u7565\u548c\u5e94\u7528\u8303\u56f4\u4e09\u4e2a\u7ef4\u5ea6\u7ec4\u7ec7\u8fd9\u4e00\u65b0\u5174\u9886\u57df\uff0c\u603b\u7ed3\u4e86\u4ee3\u8868\u6027\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u5e94\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u6784\u5efa\u53ef\u9760\u53ef\u6269\u5c55\u7cfb\u7edf\u7684\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u9759\u6001\u77e5\u8bc6\u3001\u4e8b\u5b9e\u5e7b\u89c9\u548c\u65e0\u6cd5\u83b7\u53d6\u5b9e\u65f6\u6216\u9886\u57df\u7279\u5b9a\u4fe1\u606f\u7b49\u9650\u5236\uff0c\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u68c0\u7d22\u548c\u63a8\u7406\u7684\u81ea\u9002\u5e94\u63a7\u5236\u3002\u667a\u80fd\u641c\u7d22\u901a\u8fc7\u591a\u6b65\u4ea4\u4e92\u89e3\u51b3\u4e86\u8fd9\u4e9b\u9650\u5236\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u4e3a\u81ea\u9002\u5e94\u548c\u81ea\u6211\u6539\u8fdb\u7684\u641c\u7d22\u884c\u4e3a\u63d0\u4f9b\u4e86\u5f3a\u5927\u673a\u5236\u3002", "method": "\u4ece\u4e09\u4e2a\u4e92\u8865\u7ef4\u5ea6\u7ec4\u7ec7\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u641c\u7d22\u9886\u57df\uff1a(i) RL\u7684\u529f\u80fd\u89d2\u8272\uff0c(ii) RL\u7684\u4f18\u5316\u7b56\u7565\uff0c(iii) RL\u7684\u5e94\u7528\u8303\u56f4\u3002\u901a\u8fc7\u7efc\u8ff0\u4ee3\u8868\u6027\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u5e94\u7528\u6765\u7cfb\u7edf\u5316\u8fd9\u4e00\u65b0\u5174\u9886\u57df\u3002", "result": "\u63d0\u4f9b\u4e86\u8be5\u9886\u57df\u7684\u9996\u4e2a\u5168\u9762\u6982\u8ff0\uff0c\u5efa\u7acb\u4e86\u7cfb\u7edf\u5316\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u603b\u7ed3\u4e86\u73b0\u6709\u65b9\u6cd5\u548c\u6280\u672f\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u641c\u7d22\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002\u8be5\u7efc\u8ff0\u65e8\u5728\u6fc0\u53d1RL\u4e0e\u667a\u80fd\u641c\u7d22\u96c6\u6210\u65b9\u9762\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2510.16742", "categories": ["cs.AI", "cs.MA", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.16742", "abs": "https://arxiv.org/abs/2510.16742", "authors": ["Paul Saves", "Pramudita Satria Palar", "Muhammad Daffa Robani", "Nicolas Verstaevel", "Moncef Garouani", "Julien Aligon", "Benoit Gaudou", "Koji Shimoyama", "Joseph Morlier"], "title": "Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration", "comment": null, "summary": "Complex systems are increasingly explored through simulation-driven\nengineering workflows that combine physics-based and empirical models with\noptimization and analytics. Despite their power, these workflows face two\ncentral obstacles: (1) high computational cost, since accurate exploration\nrequires many expensive simulator runs; and (2) limited transparency and\nreliability when decisions rely on opaque blackbox components. We propose a\nworkflow that addresses both challenges by training lightweight emulators on\ncompact designs of experiments that (i) provide fast, low-latency\napproximations of expensive simulators, (ii) enable rigorous uncertainty\nquantification, and (iii) are adapted for global and local Explainable\nArtificial Intelligence (XAI) analyses. This workflow unifies every\nsimulation-based complex-system analysis tool, ranging from engineering design\nto agent-based models for socio-environmental understanding. In this paper, we\nproposea comparative methodology and practical recommendations for using\nsurrogate-based explainability tools within the proposed workflow. The\nmethodology supports continuous and categorical inputs, combines global-effect\nand uncertainty analyses with local attribution, and evaluates the consistency\nof explanations across surrogate models, thereby diagnosing surrogate adequacy\nand guiding further data collection or model refinement. We demonstrate the\napproach on two contrasting case studies: a multidisciplinary design analysis\nof a hybrid-electric aircraft and an agent-based model of urban segregation.\nResults show that the surrogate model and XAI coupling enables large-scale\nexploration in seconds, uncovers nonlinear interactions and emergent behaviors,\nidentifies key design and policy levers, and signals regions where surrogates\nrequire more data or alternative architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u6a21\u578b\u7684\u4eff\u771f\u9a71\u52a8\u5de5\u7a0b\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u4eff\u771f\u5668\u6765\u89e3\u51b3\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u9ed1\u76d2\u900f\u660e\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u652f\u6301\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u53ef\u89e3\u91caAI\u5206\u6790\u3002", "motivation": "\u4eff\u771f\u9a71\u52a8\u5de5\u7a0b\u5de5\u4f5c\u6d41\u9762\u4e34\u4e24\u4e2a\u6838\u5fc3\u969c\u788d\uff1a(1)\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u51c6\u786e\u63a2\u7d22\u9700\u8981\u5927\u91cf\u6602\u8d35\u7684\u6a21\u62df\u5668\u8fd0\u884c\uff1b(2)\u9ed1\u76d2\u7ec4\u4ef6\u5bfc\u81f4\u7684\u900f\u660e\u5ea6\u4e0d\u8db3\u548c\u53ef\u9760\u6027\u6709\u9650\u3002", "method": "\u5728\u7d27\u51d1\u5b9e\u9a8c\u8bbe\u8ba1\u4e0a\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u4eff\u771f\u5668\uff0c\u63d0\u4f9b\u5feb\u901f\u8fd1\u4f3c\u3001\u652f\u6301\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5e76\u9002\u914d\u5168\u5c40\u548c\u5c40\u90e8\u53ef\u89e3\u91caAI\u5206\u6790\u3002\u7ed3\u5408\u5168\u5c40\u6548\u5e94\u3001\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u4e0e\u5c40\u90e8\u5f52\u56e0\uff0c\u8bc4\u4f30\u4e0d\u540c\u4ee3\u7406\u6a21\u578b\u95f4\u89e3\u91ca\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u6df7\u5408\u7535\u52a8\u98de\u673a\u591a\u5b66\u79d1\u8bbe\u8ba1\u5206\u6790\u548c\u57ce\u5e02\u9694\u79bb\u57fa\u4e8e\u4ee3\u7406\u6a21\u578b\u4e24\u4e2a\u6848\u4f8b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u79d2\u7ea7\u5927\u89c4\u6a21\u63a2\u7d22\uff0c\u63ed\u793a\u4e86\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\u548c\u6d8c\u73b0\u884c\u4e3a\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u8bbe\u8ba1\u548c\u653f\u7b56\u6760\u6746\u3002", "conclusion": "\u4ee3\u7406\u6a21\u578b\u4e0e\u53ef\u89e3\u91caAI\u7684\u8026\u5408\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u7684\u5927\u89c4\u6a21\u63a2\u7d22\uff0c\u53d1\u73b0\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u7279\u5f81\uff0c\u5e76\u6307\u5bfc\u8fdb\u4e00\u6b65\u6570\u636e\u6536\u96c6\u6216\u6a21\u578b\u6539\u8fdb\u3002"}}
{"id": "2510.16753", "categories": ["cs.AI", "68T30", "H.3.3"], "pdf": "https://arxiv.org/pdf/2510.16753", "abs": "https://arxiv.org/abs/2510.16753", "authors": ["Wei Huang", "Peining Li", "Meiyu Liang", "Xu Hou", "Junping Du", "Yingxia Shao", "Guanhua Ye", "Wu Liu", "Kangkang Lu", "Yang Yu"], "title": "ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion", "comment": "11 pages, 4 figures", "summary": "Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by\nincorporating visual and textual modalities, enabling richer and more\nexpressive entity representations. However, existing MKGs often suffer from\nincompleteness, which hinder their effectiveness in downstream tasks.\nTherefore, multimodal knowledge graph completion (MKGC) task is receiving\nincreasing attention. While large language models (LLMs) have shown promise for\nknowledge graph completion (KGC), their application to the multimodal setting\nremains underexplored. Moreover, applying Multimodal Large Language Models\n(MLLMs) to the task of MKGC introduces significant challenges: (1) the large\nnumber of image tokens per entity leads to semantic noise and modality\nconflicts, and (2) the high computational cost of processing large token\ninputs. To address these issues, we propose Efficient Lightweight Multimodal\nLarge Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token\nCompressor (MVTC) based on multi-head attention mechanism, which adaptively\ncompresses image tokens from both textual and visual views, thereby effectively\nreducing redundancy while retaining necessary information and avoiding modality\nconflicts. Additionally, we design an attention pruning strategy to remove\nredundant attention layers from MLLMs, thereby significantly reducing the\ninference cost. We further introduce a linear projection to compensate for the\nperformance degradation caused by pruning. Extensive experiments on benchmark\nFB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art\nperformance while substantially improving computational efficiency,\nestablishing a new paradigm for multimodal knowledge graph completion.", "AI": {"tldr": "\u63d0\u51faELMM\u6a21\u578b\u7528\u4e8e\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff0c\u901a\u8fc7\u591a\u89c6\u56fe\u89c6\u89c9\u4ee4\u724c\u538b\u7f29\u5668\u548c\u6ce8\u610f\u529b\u526a\u679d\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709MKG\u5b58\u5728\u4e0d\u5b8c\u6574\u6027\u95ee\u9898\uff0c\u800c\u5c06MLLMs\u5e94\u7528\u4e8eMKGC\u9762\u4e34\u56fe\u50cf\u4ee4\u724c\u8fc7\u591a\u5bfc\u81f4\u7684\u8bed\u4e49\u566a\u58f0\u3001\u6a21\u6001\u51b2\u7a81\u548c\u9ad8\u8ba1\u7b97\u6210\u672c\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u591a\u89c6\u56fe\u89c6\u89c9\u4ee4\u724c\u538b\u7f29\u5668(MVTC)\u57fa\u4e8e\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u81ea\u9002\u5e94\u538b\u7f29\u56fe\u50cf\u4ee4\u724c\uff0c\u5e76\u8bbe\u8ba1\u6ce8\u610f\u529b\u526a\u679d\u7b56\u7565\u51cf\u5c11\u5197\u4f59\u5c42\uff0c\u4f7f\u7528\u7ebf\u6027\u6295\u5f71\u8865\u507f\u6027\u80fd\u635f\u5931\u3002", "result": "\u5728FB15k-237-IMG\u548cWN18-IMG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "ELMM\u4e3a\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u5747\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.16769", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16769", "abs": "https://arxiv.org/abs/2510.16769", "authors": ["Shuo Han", "Yukun Cao", "Zezhong Ding", "Zengyi Gao", "S Kevin Zhou", "Xike Xie"], "title": "See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models", "comment": null, "summary": "Vision-language models (VLMs) have shown promise in graph understanding, but\nremain limited by input-token constraints, facing scalability bottlenecks and\nlacking effective mechanisms to coordinate textual and visual modalities. To\naddress these challenges, we propose GraphVista, a unified framework that\nenhances both scalability and modality coordination in graph understanding. For\nscalability, GraphVista organizes graph information hierarchically into a\nlightweight GraphRAG base, which retrieves only task-relevant textual\ndescriptions and high-resolution visual subgraphs, compressing redundant\ncontext while preserving key reasoning elements. For modality coordination,\nGraphVista introduces a planning agent that routes tasks to the most suitable\nmodality-using the text modality for simple property reasoning and the visual\nmodality for local and structurally complex reasoning grounded in explicit\ntopology. Extensive experiments demonstrate that GraphVista scales to large\ngraphs, up to $200\\times$ larger than those used in existing benchmarks, and\nconsistently outperforms existing textual, visual, and fusion-based methods,\nachieving up to $4.4\\times$ quality improvement over the state-of-the-art\nbaselines by fully exploiting the complementary strengths of both modalities.", "AI": {"tldr": "GraphVista\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u7ec4\u7ec7\u56fe\u4fe1\u606f\u548c\u5f15\u5165\u89c4\u5212\u4ee3\u7406\u6765\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u7406\u89e3\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6a21\u6001\u534f\u8c03\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u7406\u89e3\u4e2d\u9762\u4e34\u8f93\u5165\u4ee4\u724c\u9650\u5236\u3001\u53ef\u6269\u5c55\u6027\u74f6\u9888\u4ee5\u53ca\u7f3a\u4e4f\u6709\u6548\u534f\u8c03\u6587\u672c\u548c\u89c6\u89c9\u6a21\u6001\u673a\u5236\u7684\u95ee\u9898\u3002", "method": "GraphVista\u91c7\u7528\u5206\u5c42\u65b9\u6cd5\u5c06\u56fe\u4fe1\u606f\u7ec4\u7ec7\u6210\u8f7b\u91cf\u7ea7GraphRAG\u57fa\u7840\uff0c\u4ec5\u68c0\u7d22\u4efb\u52a1\u76f8\u5173\u6587\u672c\u63cf\u8ff0\u548c\u9ad8\u5206\u8fa8\u7387\u89c6\u89c9\u5b50\u56fe\uff1b\u5f15\u5165\u89c4\u5212\u4ee3\u7406\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u8def\u7531\u5230\u6700\u9002\u5408\u7684\u6a21\u6001\u3002", "result": "GraphVista\u53ef\u6269\u5c55\u5230\u6bd4\u73b0\u6709\u57fa\u51c6\u5927200\u500d\u7684\u5927\u578b\u56fe\uff0c\u5728\u8d28\u91cf\u4e0a\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u63d0\u53474.4\u500d\uff0c\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6587\u672c\u3001\u89c6\u89c9\u548c\u878d\u5408\u65b9\u6cd5\u3002", "conclusion": "GraphVista\u901a\u8fc7\u5145\u5206\u5229\u7528\u4e24\u79cd\u6a21\u6001\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u7406\u89e3\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6a21\u6001\u534f\u8c03\u6311\u6218\u3002"}}
{"id": "2510.16802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16802", "abs": "https://arxiv.org/abs/2510.16802", "authors": ["Chao Li", "Yuru Wang"], "title": "Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation", "comment": "14 pages", "summary": "Traditional knowledge graphs are constrained by fixed ontologies that\norganize concepts within rigid hierarchical structures. The root cause lies in\ntreating domains as implicit context rather than as explicit, reasoning-level\ncomponents. To overcome these limitations, we propose the Domain-Contextualized\nConcept Graph (CDC), a novel knowledge modeling framework that elevates domains\nto first-class elements of conceptual representation. CDC adopts a C-D-C triple\nstructure - <Concept, Relation@Domain, Concept'> - where domain specifications\nserve as dynamic classification dimensions defined on demand. Grounded in a\ncognitive-linguistic isomorphic mapping principle, CDC operationalizes how\nhumans understand concepts through contextual frames. We formalize more than\ntwenty standardized relation predicates (structural, logical, cross-domain, and\ntemporal) and implement CDC in Prolog for full inference capability. Case\nstudies in education, enterprise knowledge systems, and technical documentation\ndemonstrate that CDC enables context-aware reasoning, cross-domain analogy, and\npersonalized knowledge modeling - capabilities unattainable under traditional\nontology-based frameworks.", "AI": {"tldr": "\u63d0\u51fa\u4e86Domain-Contextualized Concept Graph (CDC)\u6846\u67b6\uff0c\u5c06\u9886\u57df\u4f5c\u4e3a\u77e5\u8bc6\u8868\u793a\u7684\u4e00\u7b49\u5143\u7d20\uff0c\u91c7\u7528<\u6982\u5ff5, \u5173\u7cfb@\u9886\u57df, \u6982\u5ff5'>\u7684\u4e09\u5143\u7ec4\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u548c\u8de8\u9886\u57df\u7c7b\u6bd4\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u53d7\u9650\u4e8e\u56fa\u5b9a\u7684\u672c\u4f53\u8bba\u548c\u521a\u6027\u5c42\u6b21\u7ed3\u6784\uff0c\u539f\u56e0\u662f\u5c06\u9886\u57df\u89c6\u4e3a\u9690\u542b\u4e0a\u4e0b\u6587\u800c\u975e\u663e\u5f0f\u7684\u63a8\u7406\u7ea7\u7ec4\u4ef6\u3002", "method": "\u91c7\u7528C-D-C\u4e09\u5143\u7ec4\u7ed3\u6784\uff0c\u57fa\u4e8e\u8ba4\u77e5\u8bed\u8a00\u5b66\u540c\u6784\u6620\u5c04\u539f\u7406\uff0c\u5b9a\u4e49\u4e8620\u591a\u4e2a\u6807\u51c6\u5316\u5173\u7cfb\u8c13\u8bcd\uff08\u7ed3\u6784\u3001\u903b\u8f91\u3001\u8de8\u9886\u57df\u3001\u65f6\u95f4\uff09\uff0c\u5e76\u5728Prolog\u4e2d\u5b9e\u73b0\u5b8c\u6574\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u6559\u80b2\u3001\u4f01\u4e1a\u77e5\u8bc6\u7cfb\u7edf\u548c\u6587\u6863\u7ba1\u7406\u7b49\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cCDC\u80fd\u591f\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u3001\u8de8\u9886\u57df\u7c7b\u6bd4\u548c\u4e2a\u6027\u5316\u77e5\u8bc6\u5efa\u6a21\u3002", "conclusion": "CDC\u6846\u67b6\u514b\u670d\u4e86\u4f20\u7edf\u57fa\u4e8e\u672c\u4f53\u7684\u77e5\u8bc6\u8868\u793a\u7684\u9650\u5236\uff0c\u63d0\u4f9b\u4e86\u4f20\u7edf\u6846\u67b6\u65e0\u6cd5\u5b9e\u73b0\u7684\u80fd\u529b\u3002"}}
{"id": "2510.16872", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.16872", "abs": "https://arxiv.org/abs/2510.16872", "authors": ["Shaolei Zhang", "Ju Fan", "Meihao Fan", "Guoliang Li", "Xiaoyong Du"], "title": "DeepAnalyze: Agentic Large Language Models for Autonomous Data Science", "comment": "Code: https://github.com/ruc-datalab/DeepAnalyze Model:\n  https://huggingface.co/RUC-DataLab/DeepAnalyze-8B", "summary": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language models (LLMs). Recent workflow-based\ndata agents have shown promising results on specific data tasks but remain\nfundamentally limited in achieving fully autonomous data science due to their\nreliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,\nthe first agentic LLM designed for autonomous data science, capable of\nautomatically completing the end-toend pipeline from data sources to\nanalyst-grade deep research reports. To tackle high-complexity data science\ntasks, we propose a curriculum-based agentic training paradigm that emulates\nthe learning trajectory of human data scientists, enabling LLMs to\nprogressively acquire and integrate multiple capabilities in real-world\nenvironments. We also introduce a data-grounded trajectory synthesis framework\nthat constructs high-quality training data. Through agentic training,\nDeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data\nquestion answering and specialized analytical tasks to open-ended data\nresearch. Experiments demonstrate that, with only 8B parameters, DeepAnalyze\noutperforms previous workflow-based agents built on most advanced proprietary\nLLMs. The model, code, and training data of DeepAnalyze are open-sourced,\npaving the way toward autonomous data science.", "AI": {"tldr": "DeepAnalyze-8B\u662f\u9996\u4e2a\u7528\u4e8e\u81ea\u4e3b\u6570\u636e\u79d1\u5b66\u7684\u4ee3\u7406\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u591f\u81ea\u52a8\u5b8c\u6210\u4ece\u6570\u636e\u6e90\u5230\u5206\u6790\u5e08\u7ea7\u6df1\u5ea6\u7814\u7a76\u62a5\u544a\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684\u6570\u636e\u4ee3\u7406\u5728\u7279\u5b9a\u6570\u636e\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7531\u4e8e\u4f9d\u8d56\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b8c\u5168\u81ea\u4e3b\u7684\u6570\u636e\u79d1\u5b66\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8bfe\u7a0b\u5b66\u4e60\u7684\u4ee3\u7406\u8bad\u7ec3\u8303\u5f0f\uff0c\u6a21\u62df\u4eba\u7c7b\u6570\u636e\u79d1\u5b66\u5bb6\u7684\u5b66\u4e60\u8f68\u8ff9\uff0c\u4f7fLLM\u80fd\u591f\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u9010\u6b65\u83b7\u53d6\u548c\u6574\u5408\u591a\u79cd\u80fd\u529b\uff1b\u540c\u65f6\u5f15\u5165\u6570\u636e\u9a71\u52a8\u7684\u8f68\u8ff9\u5408\u6210\u6846\u67b6\u6784\u5efa\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec58B\u53c2\u6570\u7684DeepAnalyze\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u57fa\u4e8e\u6700\u5148\u8fdb\u4e13\u6709LLM\u6784\u5efa\u7684\u5148\u524d\u5de5\u4f5c\u6d41\u4ee3\u7406\u3002", "conclusion": "DeepAnalyze\u7684\u6a21\u578b\u3001\u4ee3\u7801\u548c\u8bad\u7ec3\u6570\u636e\u5df2\u5f00\u6e90\uff0c\u4e3a\u81ea\u4e3b\u6570\u636e\u79d1\u5b66\u7684\u53d1\u5c55\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.16907", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16907", "abs": "https://arxiv.org/abs/2510.16907", "authors": ["Kangrui Wang", "Pingyue Zhang", "Zihan Wang", "Yaning Gao", "Linjie Li", "Qineng Wang", "Hanyang Chen", "Chi Wan", "Yiping Lu", "Zhengyuan Yang", "Lijuan Wang", "Ranjay Krishna", "Jiajun Wu", "Li Fei-Fei", "Yejin Choi", "Manling Li"], "title": "VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents", "comment": "Accepted to NeurIPS 2025", "summary": "A key challenge in training Vision-Language Model (VLM) agents, compared to\nLanguage Model (LLM) agents, lies in the shift from textual states to complex\nvisual observations. This transition introduces partial observability and\ndemands robust world modeling. We ask: Can VLM agents construct internal world\nmodels through explicit visual state reasoning? To address this question, we\narchitecturally enforce and reward the agent's reasoning process via\nreinforcement learning (RL), formulating it as a Partially Observable Markov\nDecision Process (POMDP). We find that decomposing the agent's reasoning into\nState Estimation (\"what is the current state?\") and Transition Modeling (\"what\ncomes next?\") is critical for success, as demonstrated through five reasoning\nstrategies. Our investigation into how agents represent internal beliefs\nreveals that the optimal representation is task-dependent: Natural Language\nexcels at capturing semantic relationships in general tasks, while Structured\nformats are indispensable for precise manipulation and control. Building on\nthese insights, we design a World Modeling Reward that provides dense,\nturn-level supervision for accurate state prediction, and introduce Bi-Level\nGeneral Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.\nThrough this form of visual state reasoning, a 3B-parameter model achieves a\nscore of 0.82 across five diverse agent benchmarks, representing a 3$\\times$\nimprovement over its untrained counterpart (0.21) and outperforming proprietary\nreasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5\n(0.62). All experiments are conducted within our VAGEN framework, a scalable\nsystem for training and analyzing multi-turn VLM agents in diverse visual\nenvironments. Code and data are publicly available at\nhttps://vagen-ai.github.io.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3VLM\u667a\u80fd\u4f53\u8fdb\u884c\u663e\u5f0f\u89c6\u89c9\u72b6\u6001\u63a8\u7406\uff0c\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u3002\u901a\u8fc7\u72b6\u6001\u4f30\u8ba1\u548c\u8f6c\u79fb\u5efa\u6a21\u5206\u89e3\u63a8\u7406\u8fc7\u7a0b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e16\u754c\u5efa\u6a21\u5956\u52b1\u548c\u53cc\u5c42GAE\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u672a\u8bad\u7ec3\u6a21\u578b\u548c\u4e13\u6709\u63a8\u7406\u6a21\u578b\u3002", "motivation": "\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u9762\u4e34\u4ece\u6587\u672c\u72b6\u6001\u5230\u590d\u6742\u89c6\u89c9\u89c2\u5bdf\u7684\u8f6c\u53d8\uff0c\u8fd9\u5f15\u5165\u4e86\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u5e76\u9700\u8981\u5f3a\u5927\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22VLM\u667a\u80fd\u4f53\u662f\u5426\u80fd\u901a\u8fc7\u663e\u5f0f\u89c6\u89c9\u72b6\u6001\u63a8\u7406\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u3002", "method": "\u5c06\u667a\u80fd\u4f53\u63a8\u7406\u8fc7\u7a0b\u6784\u5efa\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\u5f3a\u5236\u548c\u5956\u52b1\u63a8\u7406\u8fc7\u7a0b\u3002\u5173\u952e\u662f\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u72b6\u6001\u4f30\u8ba1\u548c\u8f6c\u79fb\u5efa\u6a21\uff0c\u8bbe\u8ba1\u4e86\u4e16\u754c\u5efa\u6a21\u5956\u52b1\u548c\u53cc\u5c42\u5e7f\u4e49\u4f18\u52bf\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "3B\u53c2\u6570\u6a21\u578b\u5728\u4e94\u4e2a\u591a\u6837\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u52300.82\u5206\uff0c\u76f8\u6bd4\u672a\u8bad\u7ec3\u6a21\u578b(0.21)\u63d0\u53473\u500d\uff0c\u5e76\u4f18\u4e8eGPT-5(0.75)\u3001Gemini 2.5 Pro(0.67)\u548cClaude 4.5(0.62)\u7b49\u4e13\u6709\u63a8\u7406\u6a21\u578b\u3002", "conclusion": "\u89c6\u89c9\u72b6\u6001\u63a8\u7406\u80fd\u6709\u6548\u63d0\u5347VLM\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u6700\u4f18\u4fe1\u5ff5\u8868\u793a\u5f62\u5f0f\u53d6\u51b3\u4e8e\u4efb\u52a1\u7c7b\u578b\u3002\u63d0\u51fa\u7684\u4e16\u754c\u5efa\u6a21\u5956\u52b1\u548c\u53cc\u5c42GAE\u65b9\u6cd5\u4e3a\u8bad\u7ec3\u591a\u8f6eVLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16956", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16956", "abs": "https://arxiv.org/abs/2510.16956", "authors": ["Mark Towers", "Yali Du", "Christopher Freeman", "Timothy J. Norman"], "title": "A Comparative User Evaluation of XRL Explanations using Goal Identification", "comment": "Accepted to ECAI 2025 Workshop on Evaluating Explainable AI and\n  Complex Decision-Making, 8 Pages", "summary": "Debugging is a core application of explainable reinforcement learning (XRL)\nalgorithms; however, limited comparative evaluations have been conducted to\nunderstand their relative performance. We propose a novel evaluation\nmethodology to test whether users can identify an agent's goal from an\nexplanation of its decision-making. Utilising the Atari's Ms. Pacman\nenvironment and four XRL algorithms, we find that only one achieved greater\nthan random accuracy for the tested goals and that users were generally\noverconfident in their selections. Further, we find that users' self-reported\nease of identification and understanding for every explanation did not\ncorrelate with their accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u7528\u6237\u80fd\u5426\u4ece\u89e3\u91ca\u4e2d\u8bc6\u522b\u667a\u80fd\u4f53\u7684\u76ee\u6807\uff0c\u53d1\u73b0\u5728\u56db\u4e2a\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e2d\u53ea\u6709\u4e00\u4e2a\u8868\u73b0\u4f18\u4e8e\u968f\u673a\u51c6\u786e\u7387\uff0c\u4e14\u7528\u6237\u666e\u904d\u8fc7\u5ea6\u81ea\u4fe1\u3002", "motivation": "\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u8c03\u8bd5\u5e94\u7528\u7f3a\u4e4f\u6bd4\u8f83\u6027\u8bc4\u4f30\uff0c\u9700\u8981\u4e86\u89e3\u4e0d\u540c\u7b97\u6cd5\u7684\u76f8\u5bf9\u6027\u80fd\u3002", "method": "\u4f7f\u7528Atari\u7684Ms. Pacman\u73af\u5883\u548c\u56db\u79cdXRL\u7b97\u6cd5\uff0c\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u6d4b\u8bd5\u4ed6\u4eec\u4ece\u51b3\u7b56\u89e3\u91ca\u4e2d\u8bc6\u522b\u667a\u80fd\u4f53\u76ee\u6807\u7684\u80fd\u529b\u3002", "result": "\u53ea\u6709\u4e00\u4e2aXRL\u7b97\u6cd5\u5728\u6d4b\u8bd5\u76ee\u6807\u4e0a\u8fbe\u5230\u4e86\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\u7684\u51c6\u786e\u7387\uff1b\u7528\u6237\u666e\u904d\u8fc7\u5ea6\u81ea\u4fe1\uff1b\u7528\u6237\u81ea\u62a5\u7684\u8bc6\u522b\u548c\u7406\u89e3\u96be\u6613\u5ea6\u4e0e\u51c6\u786e\u7387\u65e0\u5173\u3002", "conclusion": "\u5f53\u524dXRL\u7b97\u6cd5\u5728\u5e2e\u52a9\u7528\u6237\u8bc6\u522b\u667a\u80fd\u4f53\u76ee\u6807\u65b9\u9762\u7684\u6709\u6548\u6027\u6709\u9650\uff0c\u7528\u6237\u7684\u4e3b\u89c2\u611f\u53d7\u4e0e\u5b9e\u9645\u8868\u73b0\u5b58\u5728\u5dee\u5f02\u3002"}}
{"id": "2510.16996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16996", "abs": "https://arxiv.org/abs/2510.16996", "authors": ["Juncheng Dong", "Yang Yang", "Tao Liu", "Yang Wang", "Feng Qi", "Vahid Tarokh", "Kaushik Rangadurai", "Shuang Yang"], "title": "STARK: Strategic Team of Agents for Refining Kernels", "comment": null, "summary": "The efficiency of GPU kernels is central to the progress of modern AI, yet\noptimizing them remains a difficult and labor-intensive task due to complex\ninteractions between memory hierarchies, thread scheduling, and\nhardware-specific characteristics. While recent advances in large language\nmodels (LLMs) provide new opportunities for automated code generation, existing\napproaches largely treat LLMs as single-shot generators or naive refinement\ntools, limiting their effectiveness in navigating the irregular kernel\noptimization landscape. We introduce an LLM agentic framework for GPU kernel\noptimization that systematically explores the design space through multi-agent\ncollaboration, grounded instruction, dynamic context management, and strategic\nsearch. This framework mimics the workflow of expert engineers, enabling LLMs\nto reason about hardware trade-offs, incorporate profiling feedback, and refine\nkernels iteratively. We evaluate our approach on KernelBench, a benchmark for\nLLM-based kernel optimization, and demonstrate substantial improvements over\nbaseline agents: our system produces correct solutions where baselines often\nfail, and achieves kernels with up to 16x faster runtime performance. These\nresults highlight the potential of agentic LLM frameworks to advance fully\nautomated, scalable GPU kernel optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316GPU\u5185\u6838\u4f18\u5316\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f18\u5316\u6548\u679c\u548c\u8fd0\u884c\u6027\u80fd\u3002", "motivation": "GPU\u5185\u6838\u4f18\u5316\u5bf9\u73b0\u4ee3AI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5185\u5b58\u5c42\u6b21\u3001\u7ebf\u7a0b\u8c03\u5ea6\u548c\u786c\u4ef6\u7279\u6027\u7684\u590d\u6742\u4ea4\u4e92\uff0c\u4f18\u5316\u8fc7\u7a0b\u56f0\u96be\u4e14\u8017\u65f6\u3002\u73b0\u6709LLM\u65b9\u6cd5\u5728\u5e94\u5bf9\u4e0d\u89c4\u5219\u7684\u5185\u6838\u4f18\u5316\u95ee\u9898\u65f6\u6548\u679c\u6709\u9650\u3002", "method": "\u5f00\u53d1\u4e86LLM\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u57fa\u4e8e\u7ecf\u9a8c\u7684\u6307\u5bfc\u3001\u52a8\u6001\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u7b56\u7565\u641c\u7d22\u6765\u7cfb\u7edf\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u6a21\u62df\u4e13\u5bb6\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5728KernelBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u7cfb\u7edf\u80fd\u4ea7\u751f\u66f4\u591a\u6b63\u786e\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u8fbe16\u500d\u7684\u8fd0\u884c\u65f6\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u667a\u80fd\u4f53LLM\u6846\u67b6\u5728\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684GPU\u5185\u6838\u4f18\u5316\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.17052", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17052", "abs": "https://arxiv.org/abs/2510.17052", "authors": ["Hassan Hamad", "Yingru Xu", "Liang Zhao", "Wenbo Yan", "Narendra Gyanchandani"], "title": "ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems", "comment": null, "summary": "Tool-augmented large language models (LLMs) are increasingly employed in\nreal-world applications, but tool usage errors still hinder their reliability.\nWe introduce ToolCritic, a diagnostic framework that evaluates and improves LLM\nbehavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight\ndistinct error types specific to tool-calling (e.g., premature invocation,\nargument misalignment, and misinterpretation of tool outputs) and provides\ntargeted feedback to the main LLM. The main LLM, assumed to have strong\nreasoning, task understanding and orchestration capabilities, then revises its\nresponse based on ToolCritic's feedback. We systematically define these error\ncategories and construct a synthetic dataset to train ToolCritic. Experimental\nresults on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic\nimproves tool-calling accuracy by up to 13% over baselines, including zero-shot\nprompting and self-correction techniques. This represents a promising step\ntoward more robust LLM integration with external tools in real-world dialogue\napplications.", "AI": {"tldr": "ToolCritic\u662f\u4e00\u4e2a\u8bca\u65ad\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u5177\u589e\u5f3a\u5bf9\u8bdd\u4e2d\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u68c0\u6d4b8\u79cd\u7279\u5b9a\u9519\u8bef\u7c7b\u578b\u5e76\u63d0\u4f9b\u9488\u5bf9\u6027\u53cd\u9988\uff0c\u4f7fLLM\u80fd\u4fee\u6b63\u5176\u54cd\u5e94\u3002", "motivation": "\u5de5\u5177\u589e\u5f3a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u8d8a\u6765\u8d8a\u666e\u904d\uff0c\u4f46\u5de5\u5177\u4f7f\u7528\u9519\u8bef\u4ecd\u7136\u5f71\u54cd\u5176\u53ef\u9760\u6027\uff0c\u9700\u8981\u63d0\u9ad8LLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u7684\u9c81\u68d2\u6027\u3002", "method": "\u7cfb\u7edf\u5b9a\u4e49\u4e868\u79cd\u5de5\u5177\u8c03\u7528\u9519\u8bef\u7c7b\u578b\uff0c\u6784\u5efa\u5408\u6210\u6570\u636e\u96c6\u8bad\u7ec3ToolCritic\uff0c\u8be5\u6846\u67b6\u68c0\u6d4b\u9519\u8bef\u5e76\u63d0\u4f9b\u53cd\u9988\uff0c\u8ba9\u5177\u6709\u5f3a\u63a8\u7406\u80fd\u529b\u7684\u4e3bLLM\u57fa\u4e8e\u53cd\u9988\u4fee\u6b63\u54cd\u5e94\u3002", "result": "\u5728Schema-Guided Dialogue\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cToolCritic\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff08\u5305\u62ec\u96f6\u6837\u672c\u63d0\u793a\u548c\u81ea\u6821\u6b63\u6280\u672f\uff09\u5c06\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u6700\u591a13%\u3002", "conclusion": "ToolCritic\u662f\u671d\u7740\u5728\u73b0\u5b9e\u4e16\u754c\u5bf9\u8bdd\u5e94\u7528\u4e2d\u66f4\u9c81\u68d2\u5730\u96c6\u6210LLM\u4e0e\u5916\u90e8\u5de5\u5177\u7684\u6709\u5e0c\u671b\u7684\u4e00\u6b65\u3002"}}
{"id": "2510.17064", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17064", "abs": "https://arxiv.org/abs/2510.17064", "authors": ["Rongbin Li", "Wenbo Chen", "Zhao Li", "Rodrigo Munoz-Castaneda", "Jinbo Li", "Neha S. Maurya", "Arnav Solanki", "Huan He", "Hanwen Xing", "Meaghan Ramlakhan", "Zachary Wise", "Zhuhao Wu", "Hua Xu", "Michael Hawrylycz", "W. Jim Zheng"], "title": "A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation", "comment": "22 pages, 6 figures, 2 tables", "summary": "Single-cell RNA sequencing has transformed our ability to identify diverse\ncell types and their transcriptomic signatures. However, annotating these\nsignatures-especially those involving poorly characterized genes-remains a\nmajor challenge. Traditional methods, such as Gene Set Enrichment Analysis\n(GSEA), depend on well-curated annotations and often perform poorly in these\ncontexts. Large Language Models (LLMs) offer a promising alternative but\nstruggle to represent complex biological knowledge within structured\nontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:\nhttps://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that\nintegrates free-text descriptions with ontology labels to enable more accurate\nand robust gene set annotation. By incorporating retrieval-augmented generation\n(RAG), we developed a robust agentic workflow that refines predictions using\nrelevant PubMed literature, reducing hallucinations and enhancing\ninterpretability. Using this workflow, we achieved correct annotations for 77%\nof mouse gene sets among their top predictions. Applying this approach, we\nannotated 5,322 brain cell clusters from the comprehensive mouse brain cell\natlas generated by the BRAIN Initiative Cell Census Network, enabling novel\ninsights into brain cell function by identifying region-specific gene\nco-expression patterns and inferring functional roles of gene ensembles.\nBRAINCELL-AID also identifies Basal Ganglia-related cell types with\nneurologically meaningful descriptions. Hence, we create a valuable resource to\nsupport community-driven cell type annotation.", "AI": {"tldr": "BRAINCELL-AID\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u81ea\u7531\u6587\u672c\u63cf\u8ff0\u548c\u672c\u4f53\u6807\u7b7e\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u56e0\u96c6\u6ce8\u91ca\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6280\u672f\u867d\u7136\u80fd\u8bc6\u522b\u591a\u6837\u7ec6\u80de\u7c7b\u578b\uff0c\u4f46\u5bf9\u6d89\u53ca\u7279\u5f81\u4e0d\u660e\u786e\u57fa\u56e0\u7684\u8f6c\u5f55\u7ec4\u7279\u5f81\u8fdb\u884c\u6ce8\u91ca\u4ecd\u7136\u662f\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\u3002\u4f20\u7edf\u65b9\u6cd5\u5982GSEA\u4f9d\u8d56\u7cbe\u5fc3\u7b56\u5212\u7684\u6ce8\u91ca\uff0c\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1\u4e86BRAINCELL-AID\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u6574\u5408\u81ea\u7531\u6587\u672c\u63cf\u8ff0\u548c\u672c\u4f53\u6807\u7b7e\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u901a\u8fc7PubMed\u6587\u732e\u7cbe\u70bc\u9884\u6d4b\uff0c\u51cf\u5c11\u5e7b\u89c9\u5e76\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u5c0f\u9f20\u57fa\u56e0\u96c6\u4e2d\u5b9e\u73b0\u4e8677%\u7684\u6b63\u786e\u6ce8\u91ca\u7387\uff0c\u6210\u529f\u6ce8\u91ca\u4e86BRAIN Initiative Cell Census Network\u751f\u6210\u76845,322\u4e2a\u8111\u7ec6\u80de\u7c07\uff0c\u8bc6\u522b\u4e86\u533a\u57df\u7279\u5f02\u6027\u57fa\u56e0\u5171\u8868\u8fbe\u6a21\u5f0f\uff0c\u5e76\u63a8\u65ad\u51fa\u57fa\u56e0\u96c6\u5408\u7684\u529f\u80fd\u4f5c\u7528\u3002", "conclusion": "BRAINCELL-AID\u521b\u5efa\u4e86\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u8d44\u6e90\u6765\u652f\u6301\u793e\u533a\u9a71\u52a8\u7684\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\uff0c\u7279\u522b\u662f\u5728\u8bc6\u522b\u4e0e\u57fa\u5e95\u795e\u7ecf\u8282\u76f8\u5173\u7684\u7ec6\u80de\u7c7b\u578b\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.17108", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17108", "abs": "https://arxiv.org/abs/2510.17108", "authors": ["Yoonjin Lee", "Munhee Kim", "Hanbi Choi", "Juhyeon Park", "Seungho Lyoo", "Woojin Park"], "title": "Structured Debate Improves Corporate Credit Reasoning in Financial AI", "comment": "18 pages, 4 figures, 2 algorithms, 2 tables, 4 appendices, will be\n  submitted to AAAI-2026 workshop", "summary": "Despite advances in financial AI, the automation of evidence-based reasoning\nremains unresolved in corporate credit assessment, where qualitative\nnon-financial indicators exert decisive influence on loan repayment outcomes\nyet resist formalization. Existing approaches focus predominantly on numerical\nprediction and provide limited support for the interpretive judgments required\nin professional loan evaluation. This study develops and evaluates two\noperational large language model (LLM)-based systems designed to generate\nstructured reasoning from non-financial evidence. The first is a\nnon-adversarial single-agent system (NAS) that produces bidirectional analysis\nthrough a single-pass reasoning pipeline. The second is a debate-based\nmulti-agent system (KPD-MADS) that operationalizes adversarial verification\nthrough a ten-step structured interaction protocol grounded in Karl Popper's\ncritical dialogue framework. Both systems were applied to three real corporate\ncases and evaluated by experienced credit risk professionals. Compared to\nmanual expert reporting, both systems achieved substantial productivity gains\n(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The\nKPD-MADS demonstrated superior reasoning quality, receiving higher median\nratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.\n3.0), and usability (62.5 vs. 52.5). These findings show that structured\nmulti-agent interaction can enhance reasoning rigor and interpretability in\nfinancial AI, advancing scalable and defensible automation in corporate credit\nassessment.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86\u4e24\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u4ece\u975e\u8d22\u52a1\u8bc1\u636e\u751f\u6210\u7ed3\u6784\u5316\u63a8\u7406\u3002\u5355\u4ee3\u7406\u7cfb\u7edf(NAS)\u901a\u8fc7\u5355\u6b21\u63a8\u7406\u6d41\u7a0b\u8fdb\u884c\u53cc\u5411\u5206\u6790\uff0c\u800c\u57fa\u4e8e\u8fa9\u8bba\u7684\u591a\u4ee3\u7406\u7cfb\u7edf(KPD-MADS)\u91c7\u7528\u5361\u5c14\u00b7\u6ce2\u666e\u5c14\u7684\u6279\u5224\u5bf9\u8bdd\u6846\u67b6\u8fdb\u884c\u5bf9\u6297\u6027\u9a8c\u8bc1\u3002\u4e24\u79cd\u7cfb\u7edf\u5728\u751f\u4ea7\u529b\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u57fa\u51c6\uff0c\u5176\u4e2dKPD-MADS\u5728\u63a8\u7406\u8d28\u91cf\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5728\u4fe1\u8d37\u8bc4\u4f30\u4e2d\uff0c\u5b9a\u6027\u975e\u8d22\u52a1\u6307\u6807\u5bf9\u8d37\u6b3e\u507f\u8fd8\u7ed3\u679c\u5177\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u4f46\u96be\u4ee5\u5f62\u5f0f\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6570\u503c\u9884\u6d4b\uff0c\u5bf9\u4e13\u4e1a\u8d37\u6b3e\u8bc4\u4f30\u6240\u9700\u7684\u89e3\u91ca\u6027\u5224\u65ad\u652f\u6301\u6709\u9650\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cdLLM\u7cfb\u7edf\uff1a\u5355\u4ee3\u7406\u7cfb\u7edf(NAS)\u4f7f\u7528\u5355\u6b21\u63a8\u7406\u6d41\u7a0b\u8fdb\u884c\u53cc\u5411\u5206\u6790\uff1b\u591a\u4ee3\u7406\u7cfb\u7edf(KPD-MADS)\u57fa\u4e8e\u5361\u5c14\u00b7\u6ce2\u666e\u5c14\u7684\u6279\u5224\u5bf9\u8bdd\u6846\u67b6\uff0c\u91c7\u7528\u5341\u6b65\u7ed3\u6784\u5316\u4ea4\u4e92\u534f\u8bae\u8fdb\u884c\u5bf9\u6297\u6027\u9a8c\u8bc1\u3002\u4e24\u79cd\u7cfb\u7edf\u5728\u4e09\u4e2a\u771f\u5b9e\u4f01\u4e1a\u6848\u4f8b\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4e24\u79cd\u7cfb\u7edf\u90fd\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u751f\u4ea7\u529b\u63d0\u5347(NAS: 11.55\u79d2/\u6848\u4f8b\uff1bKPD-MADS: 91.97\u79d2\uff1b\u4eba\u5de5\u57fa\u51c6: 1920\u79d2)\u3002KPD-MADS\u5728\u89e3\u91ca\u5145\u5206\u6027(4.0 vs 3.0)\u3001\u5b9e\u9645\u9002\u7528\u6027(4.0 vs 3.0)\u548c\u53ef\u7528\u6027(62.5 vs 52.5)\u65b9\u9762\u83b7\u5f97\u66f4\u9ad8\u7684\u4e2d\u4f4d\u6570\u8bc4\u5206\u3002", "conclusion": "\u7ed3\u6784\u5316\u591a\u4ee3\u7406\u4ea4\u4e92\u80fd\u591f\u589e\u5f3a\u91d1\u878dAI\u4e2d\u7684\u63a8\u7406\u4e25\u8c28\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u63a8\u52a8\u4f01\u4e1a\u4fe1\u8d37\u8bc4\u4f30\u4e2d\u53ef\u6269\u5c55\u4e14\u53ef\u8fa9\u62a4\u7684\u81ea\u52a8\u5316\u8fdb\u7a0b\u3002"}}
{"id": "2510.17145", "categories": ["cs.AI", "68T05, 62H30"], "pdf": "https://arxiv.org/pdf/2510.17145", "abs": "https://arxiv.org/abs/2510.17145", "authors": ["Phi-Hung Hoang", "Nam-Thuan Trinh", "Van-Manh Tran", "Thi-Thu-Hong Phan"], "title": "Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion", "comment": "35 pages, 6 figures and 11 tables", "summary": "Accurate assessment of fish freshness remains a major challenge in the food\nindustry, with direct consequences for product quality, market value, and\nconsumer health. Conventional sensory evaluation is inherently subjective,\ninconsistent, and difficult to standardize across contexts, often limited by\nsubtle, species-dependent spoilage cues. To address these limitations, we\npropose a handcrafted feature-based approach that systematically extracts and\nincrementally fuses complementary descriptors, including color statistics,\nhistograms across multiple color spaces, and texture features such as Local\nBinary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish\neye images. Our method captures global chromatic variations from full images\nand localized degradations from ROI segments, fusing each independently to\nevaluate their effectiveness in assessing freshness. Experiments on the\nFreshness of the Fish Eyes (FFE) dataset demonstrate the approach's\neffectiveness: in a standard train-test setting, a LightGBM classifier achieved\n77.56% accuracy, a 14.35% improvement over the previous deep learning baseline\nof 63.21%. With augmented data, an Artificial Neural Network (ANN) reached\n97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results\ndemonstrate that carefully engineered, handcrafted features, when strategically\nprocessed, yield a robust, interpretable, and reliable solution for automated\nfish freshness assessment, providing valuable insights for practical\napplications in food quality monitoring.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u624b\u5de5\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u548c\u878d\u5408\u989c\u8272\u7edf\u8ba1\u3001\u591a\u8272\u5f69\u7a7a\u95f4\u76f4\u65b9\u56fe\u4ee5\u53ca\u7eb9\u7406\u7279\u5f81\u6765\u8bc4\u4f30\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\uff0c\u5728FFE\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u611f\u5b98\u8bc4\u4f30\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\u5b58\u5728\u4e3b\u89c2\u6027\u3001\u4e0d\u4e00\u81f4\u6027\u548c\u96be\u4ee5\u6807\u51c6\u5316\u7684\u95ee\u9898\uff0c\u9700\u8981\u5ba2\u89c2\u3001\u53ef\u9760\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4ece\u9c7c\u773c\u56fe\u50cf\u4e2d\u7cfb\u7edf\u63d0\u53d6\u989c\u8272\u7edf\u8ba1\u3001\u591a\u8272\u5f69\u7a7a\u95f4\u76f4\u65b9\u56fe\u3001LBP\u548cGLCM\u7b49\u7eb9\u7406\u7279\u5f81\uff0c\u878d\u5408\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\u8fdb\u884c\u65b0\u9c9c\u5ea6\u8bc4\u4f30\u3002", "result": "LightGBM\u5206\u7c7b\u5668\u5728\u6807\u51c6\u8bbe\u7f6e\u4e0b\u8fbe\u523077.56%\u51c6\u786e\u7387\uff0c\u6bd4\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u63d0\u534714.35%\uff1b\u4f7f\u7528\u589e\u5f3a\u6570\u636e\u65f6ANN\u8fbe\u523097.16%\u51c6\u786e\u7387\uff0c\u6bd4\u4e4b\u524d\u6700\u4f73\u7ed3\u679c\u63d0\u534719.86%\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u624b\u5de5\u7279\u5f81\u80fd\u591f\u63d0\u4f9b\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u9760\u7684\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\u81ea\u52a8\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u98df\u54c1\u8d28\u91cf\u76d1\u63a7\u63d0\u4f9b\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.17146", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.17146", "abs": "https://arxiv.org/abs/2510.17146", "authors": ["Subin Lin", "Chuanbo Hua"], "title": "Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation", "comment": "NeurIPS 2025 Workshop of UrbanAI (Oral)", "summary": "Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a\nsubstantial share of global building energy use, making reliable anomaly\ndetection essential for improving efficiency and reducing emissions. Classical\nrule-based approaches offer explainability but lack adaptability, while deep\nlearning methods provide predictive power at the cost of transparency,\nefficiency, and physical plausibility. Recent attempts to use Large Language\nModels (LLMs) for anomaly detection improve interpretability but largely ignore\nthe physical principles that govern HVAC operations. We present PILLM, a\nPhysics-Informed LLM framework that operates within an evolutionary loop to\nautomatically generate, evaluate, and refine anomaly detection rules. Our\napproach introduces physics-informed reflection and crossover operators that\nembed thermodynamic and control-theoretic constraints, enabling rules that are\nboth adaptive and physically grounded. Experiments on the public Building Fault\nDetection dataset show that PILLM achieves state-of-the-art performance while\nproducing diagnostic rules that are interpretable and actionable, advancing\ntrustworthy and deployable AI for smart building systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86PILLM\u6846\u67b6\uff0c\u7ed3\u5408\u7269\u7406\u77e5\u8bc6\u548cLLM\u8fdb\u884cHVAC\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\uff0c\u901a\u8fc7\u8fdb\u5316\u5faa\u73af\u81ea\u52a8\u751f\u6210\u3001\u8bc4\u4f30\u548c\u4f18\u5316\u68c0\u6d4b\u89c4\u5219\uff0c\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6027\u80fd\u3002", "motivation": "HVAC\u7cfb\u7edf\u80fd\u8017\u5de8\u5927\uff0c\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u5ffd\u89c6\u7269\u7406\u539f\u7406\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u9002\u5e94\u6027\u5f3a\u53c8\u7269\u7406\u5408\u7406\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u5316\u7684LLM\u6846\u67b6\uff0c\u5728\u8fdb\u5316\u5faa\u73af\u4e2d\u5d4c\u5165\u70ed\u529b\u5b66\u548c\u63a7\u5236\u7406\u8bba\u7ea6\u675f\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u5316\u7684\u53cd\u5c04\u548c\u4ea4\u53c9\u7b97\u5b50\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u5f02\u5e38\u68c0\u6d4b\u89c4\u5219\u3002", "result": "\u5728\u516c\u5171\u5efa\u7b51\u6545\u969c\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u751f\u6210\u7684\u8bca\u65ad\u89c4\u5219\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u3002", "conclusion": "PILLM\u6846\u67b6\u63a8\u8fdb\u4e86\u667a\u80fd\u5efa\u7b51\u7cfb\u7edf\u4e2d\u53ef\u4fe1\u8d56\u548c\u53ef\u90e8\u7f72AI\u7684\u53d1\u5c55\uff0c\u5b9e\u73b0\u4e86\u9002\u5e94\u6027\u3001\u7269\u7406\u5408\u7406\u6027\u548c\u9ad8\u6027\u80fd\u7684\u5e73\u8861\u3002"}}
{"id": "2510.17149", "categories": ["cs.AI", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.17149", "abs": "https://arxiv.org/abs/2510.17149", "authors": ["Hongyi Du", "Jiaqi Su", "Jisen Li", "Lijie Ding", "Yingxuan Yang", "Peixuan Han", "Xiangru Tang", "Kunlun Zhu", "Jiaxuan You"], "title": "Which LLM Multi-Agent Protocol to Choose?", "comment": "Under review at ICLR 2026.Code and benchmark artifacts:\n  https://github.com/ulab-uiuc/AgentProtocols", "summary": "As large-scale multi-agent systems evolve, the communication protocol layer\nhas become a critical yet under-evaluated factor shaping performance and\nreliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,\netc.), selection is often intuition-driven and lacks standardized guidance. We\nintroduce ProtocolBench, a benchmark that systematically compares agent\nprotocols along four measurable axes: task success, end-to-end latency, message\nor byte overhead, and robustness under failures. On ProtocolBench, protocol\nchoice significantly influences system behavior. In the Streaming Queue\nscenario, overall completion time varies by up to 36.5% across protocols, and\nmean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,\nresilience also differs consistently across protocols. Beyond evaluation, we\npresent ProtocolRouter, a learnable protocol router that selects per-scenario\n(or per-module) protocols from requirement and runtime signals. ProtocolRouter\nreduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol\nbaseline, and achieves scenario-specific gains such as higher success in GAIA.\nWe also release ProtocolRouterBench to standardize protocol evaluation and\nimprove reliability at scale.", "AI": {"tldr": "ProtocolBench\u662f\u4e00\u4e2a\u7cfb\u7edf\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u4fe1\u534f\u8bae\u7684\u57fa\u51c6\uff0cProtocolRouter\u662f\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u534f\u8bae\u8def\u7531\u5668\uff0c\u80fd\u6839\u636e\u573a\u666f\u9700\u6c42\u9009\u62e9\u6700\u4f73\u534f\u8bae\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u901a\u4fe1\u534f\u8bae\u5c42\u662f\u5f71\u54cd\u6027\u80fd\u548c\u53ef\u9760\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u76ee\u524d\u534f\u8bae\u9009\u62e9\u7f3a\u4e4f\u6807\u51c6\u5316\u6307\u5bfc\uff0c\u5f80\u5f80\u57fa\u4e8e\u76f4\u89c9\u3002", "method": "\u5f00\u53d1ProtocolBench\u57fa\u51c6\uff0c\u4ece\u4efb\u52a1\u6210\u529f\u7387\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u3001\u6d88\u606f\u5f00\u9500\u548c\u6545\u969c\u6062\u590d\u80fd\u529b\u56db\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u6bd4\u8f83\u534f\u8bae\uff1b\u63d0\u51faProtocolRouter\u534f\u8bae\u8def\u7531\u5668\uff0c\u6839\u636e\u9700\u6c42\u548c\u8fd0\u884c\u65f6\u4fe1\u53f7\u9009\u62e9\u6700\u4f73\u534f\u8bae\u3002", "result": "\u534f\u8bae\u9009\u62e9\u663e\u8457\u5f71\u54cd\u7cfb\u7edf\u884c\u4e3a\uff1a\u5728Streaming Queue\u573a\u666f\u4e2d\uff0c\u5b8c\u6210\u65f6\u95f4\u5dee\u5f02\u8fbe36.5%\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u5dee\u5f023.48\u79d2\uff1bProtocolRouter\u76f8\u6bd4\u6700\u4f73\u5355\u534f\u8bae\u57fa\u7ebf\uff0c\u6545\u969c\u6062\u590d\u65f6\u95f4\u51cf\u5c1118.1%\uff0c\u5728GAIA\u573a\u666f\u4e2d\u6210\u529f\u7387\u66f4\u9ad8\u3002", "conclusion": "\u534f\u8bae\u9009\u62e9\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0cProtocolBench\u548cProtocolRouter\u4e3a\u534f\u8bae\u8bc4\u4f30\u548c\u9009\u62e9\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2510.17172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17172", "abs": "https://arxiv.org/abs/2510.17172", "authors": ["Shun Huang", "Wenlu Xing", "Shijia Geng", "Hailong Wang", "Guangkun Nie", "Gongzheng Tang", "Chenyang He", "Shenda Hong"], "title": "Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients", "comment": null, "summary": "Malignant ventricular arrhythmias (VT/VF) following acute myocardial\ninfarction (AMI) are a major cause of in-hospital death, yet early\nidentification remains a clinical challenge. While traditional risk scores have\nlimited performance, end-to-end deep learning models often lack the\ninterpretability needed for clinical trust. This study aimed to develop a\nhybrid predictive framework that integrates a large-scale electrocardiogram\n(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to\nimprove both accuracy and interpretability. We analyzed 6,634 ECG recordings\nfrom AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder\nmodel was used to extract 150-dimensional diagnostic probability features ,\nwhich were then refined through feature selection to train the XGBoost\nclassifier. Model performance was evaluated using AUC and F1-score , and the\nSHAP method was used for interpretability. The ECGFounder + XGBoost hybrid\nmodel achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC\n0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that\nmodel-identified key features, such as \"premature ventricular complexes\" (risk\npredictor) and \"normal sinus rhythm\" (protective factor), were highly\nconsistent with clinical knowledge. We conclude that this hybrid framework\nprovides a novel paradigm for VT/VF risk prediction by validating the use of\nfoundation model outputs as effective, automated feature engineering for\nbuilding trustworthy, explainable AI-based clinical decision support systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408ECG\u57fa\u7840\u6a21\u578b\u548c\u53ef\u89e3\u91caXGBoost\u5206\u7c7b\u5668\u7684\u6df7\u5408\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u540e\u6076\u6027\u5ba4\u6027\u5fc3\u5f8b\u5931\u5e38\u98ce\u9669\uff0c\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u540e\u6076\u6027\u5ba4\u6027\u5fc3\u5f8b\u5931\u5e38\u662f\u9662\u5185\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u4f20\u7edf\u98ce\u9669\u8bc4\u5206\u6027\u80fd\u6709\u9650\uff0c\u800c\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7f3a\u4e4f\u4e34\u5e8a\u4fe1\u4efb\u6240\u9700\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528ECG\u57fa\u7840\u6a21\u578b\u63d0\u53d6150\u7ef4\u8bca\u65ad\u6982\u7387\u7279\u5f81\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u540e\u8bad\u7ec3XGBoost\u5206\u7c7b\u5668\uff0c\u91c7\u7528SHAP\u65b9\u6cd5\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "result": "\u6df7\u5408\u6a21\u578bAUC\u8fbe\u52300.801\uff0c\u4f18\u4e8eKNN(0.677)\u3001RNN(0.676)\u548c1D-CNN(0.720)\uff0cSHAP\u5206\u6790\u663e\u793a\u6a21\u578b\u8bc6\u522b\u7279\u5f81\u4e0e\u4e34\u5e8a\u77e5\u8bc6\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u4e3aVT/VF\u98ce\u9669\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u9a8c\u8bc1\u4e86\u57fa\u7840\u6a21\u578b\u8f93\u51fa\u4f5c\u4e3a\u6709\u6548\u81ea\u52a8\u5316\u7279\u5f81\u5de5\u7a0b\u5728\u6784\u5efa\u53ef\u4fe1\u8d56\u3001\u53ef\u89e3\u91caAI\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2510.17173", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17173", "abs": "https://arxiv.org/abs/2510.17173", "authors": ["Melik Ozolcer", "Sang Won Bae"], "title": "Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users", "comment": "Accepted to the NeurIPS 2025 Workshop on Multi-Turn Interactions in\n  Large Language Models", "summary": "We study a web-deployed, tool-augmented LLM health coach with real users. In\na pilot with seven users (280 rated turns), offline policy evaluation (OPE)\nover factorized decision heads (Tool/Style) shows that a uniform heavy-tool\npolicy raises average value on logs but harms specific subgroups, most notably\nlow-health-literacy/high-self-efficacy users. A lightweight simulator with\nhidden archetypes further shows that adding a small early information-gain\nbonus reliably shortens trait identification and improves goal success and\npass@3. Together, these early findings indicate an evaluation-first path to\npersonalization: freeze the generator, learn subgroup-aware decision heads on\ntyped rewards (objective tool outcomes and satisfaction), and always report\nper-archetype metrics to surface subgroup harms that averages obscure.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u4e2a\u90e8\u7f72\u5728Web\u4e0a\u7684\u5de5\u5177\u589e\u5f3aLLM\u5065\u5eb7\u6559\u7ec3\uff0c\u901a\u8fc7\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u53d1\u73b0\u7edf\u4e00\u7684\u91cd\u5de5\u5177\u7b56\u7565\u867d\u7136\u63d0\u5347\u5e73\u5747\u4ef7\u503c\uff0c\u4f46\u5bf9\u7279\u5b9a\u7528\u6237\u7fa4\u4f53\uff08\u7279\u522b\u662f\u4f4e\u5065\u5eb7\u7d20\u517b/\u9ad8\u81ea\u6211\u6548\u80fd\u7528\u6237\uff09\u6709\u5bb3\u3002\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6a21\u62df\u5668\u53d1\u73b0\u6dfb\u52a0\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u53ef\u4ee5\u7f29\u77ed\u7279\u5f81\u8bc6\u522b\u65f6\u95f4\u5e76\u63d0\u9ad8\u76ee\u6807\u6210\u529f\u7387\u3002", "motivation": "\u63a2\u7d22\u5de5\u5177\u589e\u5f3aLLM\u5065\u5eb7\u6559\u7ec3\u5728\u771f\u5b9e\u7528\u6237\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u5173\u6ce8\u4e2a\u6027\u5316\u7b56\u7565\u5bf9\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u8bc4\u4f30\u4f18\u5148\u7684\u65b9\u6cd5\u5b9e\u73b0\u66f4\u597d\u7684\u4e2a\u6027\u5316\u670d\u52a1\u3002", "method": "\u4f7f\u7528\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff08OPE\uff09\u5206\u6790\u56e0\u5b50\u5316\u51b3\u7b56\u5934\uff08\u5de5\u5177/\u98ce\u683c\uff09\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6a21\u62df\u5668\u6d4b\u8bd5\u6dfb\u52a0\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u7684\u6548\u679c\uff0c\u8bc4\u4f30\u4e0d\u540c\u7b56\u7565\u5bf9\u7528\u6237\u7fa4\u4f53\u7684\u5f71\u54cd\u3002", "result": "\u7edf\u4e00\u7684\u91cd\u5de5\u5177\u7b56\u7565\u4f1a\u635f\u5bb3\u4f4e\u5065\u5eb7\u7d20\u517b/\u9ad8\u81ea\u6211\u6548\u80fd\u7528\u6237\u7fa4\u4f53\uff1b\u6dfb\u52a0\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u53ef\u4ee5\u53ef\u9760\u5730\u7f29\u77ed\u7279\u5f81\u8bc6\u522b\u65f6\u95f4\uff0c\u63d0\u9ad8\u76ee\u6807\u6210\u529f\u7387\u548cpass@3\u6307\u6807\u3002", "conclusion": "\u63d0\u51fa\u4e86\u8bc4\u4f30\u4f18\u5148\u7684\u4e2a\u6027\u5316\u8def\u5f84\uff1a\u51bb\u7ed3\u751f\u6210\u5668\uff0c\u5728\u7c7b\u578b\u5316\u5956\u52b1\uff08\u5ba2\u89c2\u5de5\u5177\u7ed3\u679c\u548c\u6ee1\u610f\u5ea6\uff09\u4e0a\u5b66\u4e60\u5b50\u7fa4\u4f53\u611f\u77e5\u7684\u51b3\u7b56\u5934\uff0c\u5e76\u59cb\u7ec8\u62a5\u544a\u6bcf\u4e2a\u539f\u578b\u7684\u6307\u6807\u4ee5\u63ed\u793a\u88ab\u5e73\u5747\u503c\u63a9\u76d6\u7684\u5b50\u7fa4\u4f53\u635f\u5bb3\u3002"}}
{"id": "2510.17211", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17211", "abs": "https://arxiv.org/abs/2510.17211", "authors": ["Tingsong Xiao", "Yao An Lee", "Zelin Xu", "Yupu Zhang", "Zibo Liu", "Yu Huang", "Jiang Bian", "Serena Jingchuan Guo", "Zhe Jiang"], "title": "Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling", "comment": null, "summary": "Disease progression modeling aims to characterize and predict how a patient's\ndisease complications worsen over time based on longitudinal electronic health\nrecords (EHRs). Accurate modeling of disease progression, such as type 2\ndiabetes, can enhance patient sub-phenotyping and inform effective and timely\ninterventions. However, the problem is challenging due to the need to learn\ncontinuous-time dynamics of progression patterns based on irregular-time event\nsamples and patient heterogeneity (\\eg different progression rates and\npathways). Existing mechanistic and data-driven methods either lack\nadaptability to learn from real-world data or fail to capture complex\ncontinuous-time dynamics on progression trajectories. To address these\nlimitations, we propose Temporally Detailed Hypergraph Neural Ordinary\nDifferential Equation (TD-HNODE), which represents disease progression on\nclinically recognized trajectories as a temporally detailed hypergraph and\nlearns the continuous-time progression dynamics via a neural ODE framework.\nTD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the\ninterdependency of disease complication markers within both intra- and\ninter-progression trajectories. Experiments on two real-world clinical datasets\ndemonstrate that TD-HNODE outperforms multiple baselines in modeling the\nprogression of type 2 diabetes and related cardiovascular diseases.", "AI": {"tldr": "\u63d0\u51faTD-HNODE\u6a21\u578b\uff0c\u4f7f\u7528\u65f6\u95f4\u8be6\u7ec6\u8d85\u56fe\u548c\u795e\u7ecfODE\u6846\u67b6\u6765\u5b66\u4e60\u75be\u75c5\u8fdb\u5c55\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\uff0c\u57282\u578b\u7cd6\u5c3f\u75c5\u548c\u5fc3\u8840\u7ba1\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u4e0d\u89c4\u5219\u65f6\u95f4\u91c7\u6837\u6570\u636e\u548c\u60a3\u8005\u5f02\u8d28\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349\u590d\u6742\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\u3002", "method": "TD-HNODE\u5c06\u75be\u75c5\u8fdb\u5c55\u8868\u793a\u4e3a\u65f6\u95f4\u8be6\u7ec6\u8d85\u56fe\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u8d85\u56fe\u62c9\u666e\u62c9\u65af\u77e9\u9635\u6355\u6349\u5e76\u53d1\u75c7\u6807\u8bb0\u7269\u5728\u8fdb\u5c55\u8f68\u8ff9\u5185\u548c\u8f68\u8ff9\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f7f\u7528\u795e\u7ecfODE\u6846\u67b6\u5b66\u4e60\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTD-HNODE\u57282\u578b\u7cd6\u5c3f\u75c5\u53ca\u76f8\u5173\u5fc3\u8840\u7ba1\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u65b9\u9762\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TD-HNODE\u80fd\u591f\u6709\u6548\u5efa\u6a21\u75be\u75c5\u8fdb\u5c55\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\uff0c\u4e3a\u60a3\u8005\u4e9a\u8868\u578b\u5206\u6790\u548c\u53ca\u65f6\u5e72\u9884\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2510.17235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17235", "abs": "https://arxiv.org/abs/2510.17235", "authors": ["Chong Chen", "Ze Liu", "Lingfeng Bao", "Yanlin Wang", "Ting Chen", "Daoyuan Wu", "Jiachi Chen"], "title": "Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis", "comment": null, "summary": "The cryptocurrency market offers significant investment opportunities but\nfaces challenges including high volatility and fragmented information. Data\nintegration and analysis are essential for informed investment decisions.\nCurrently, investors use three main approaches: (1) Manual analysis across\nvarious sources, which depends heavily on individual experience and is\ntime-consuming and prone to bias; (2) Data aggregation platforms-limited in\nfunctionality and depth of analysis; (3) Large language model agents-based on\nstatic pretrained models, lacking real-time data integration and multi-step\nreasoning capabilities. To address these limitations, we present Coinvisor, a\nreinforcement learning-based chatbot that provides comprehensive analytical\nsupport for cryptocurrency investment through a multi-agent framework.\nCoinvisor integrates diverse analytical capabilities through specialized tools.\nIts key innovation is a reinforcement learning-based tool selection mechanism\nthat enables multi-step planning and flexible integration of diverse data\nsources. This design supports real-time interaction and adaptive analysis of\ndynamic content, delivering accurate and actionable investment insights. We\nevaluated Coinvisor through automated benchmarks on tool calling accuracy and\nuser studies with 20 cryptocurrency investors using our interface. Results show\nthat Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base\nmodel in tool orchestration. User studies show high satisfaction (4.64/5), with\nparticipants preferring Coinvisor to both general LLMs and existing crypto\nplatforms (4.62/5).", "AI": {"tldr": "Coinvisor\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u52a0\u5bc6\u8d27\u5e01\u6295\u8d44\u5206\u6790\u804a\u5929\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548c\u5f3a\u5316\u5b66\u4e60\u5de5\u5177\u9009\u62e9\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u5b9e\u65f6\u3001\u51c6\u786e\u7684\u6295\u8d44\u5206\u6790\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u5b58\u5728\u9ad8\u6ce2\u52a8\u6027\u548c\u4fe1\u606f\u788e\u7247\u5316\u95ee\u9898\uff0c\u73b0\u6709\u5206\u6790\u65b9\u6cd5\uff08\u624b\u52a8\u5206\u6790\u3001\u6570\u636e\u805a\u5408\u5e73\u53f0\u3001LLM\u4ee3\u7406\uff09\u5404\u6709\u7f3a\u9677\uff0c\u9700\u8981\u66f4\u667a\u80fd\u3001\u5b9e\u65f6\u7684\u5206\u6790\u5de5\u5177\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u96c6\u6210\u591a\u79cd\u4e13\u4e1a\u5206\u6790\u5de5\u5177\uff0c\u6838\u5fc3\u521b\u65b0\u662f\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5de5\u5177\u9009\u62e9\u673a\u5236\uff0c\u652f\u6301\u591a\u6b65\u9aa4\u89c4\u5212\u548c\u5b9e\u65f6\u6570\u636e\u96c6\u6210\u3002", "result": "\u5728\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u53ec\u56de\u7387\u63d0\u534740.7%\uff0cF1\u5206\u6570\u63d0\u534726.6%\uff1b\u7528\u6237\u7814\u7a76\u663e\u793a\u9ad8\u6ee1\u610f\u5ea6\uff084.64/5\uff09\uff0c\u7528\u6237\u66f4\u504f\u597dCoinvisor\u800c\u975e\u901a\u7528LLM\u548c\u73b0\u6709\u5e73\u53f0\uff084.62/5\uff09\u3002", "conclusion": "Coinvisor\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u52a0\u5bc6\u8d27\u5e01\u6295\u8d44\u5206\u6790\u4e2d\u7684\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u6027\u6311\u6218\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u5206\u6790\u4f53\u9a8c\u3002"}}
{"id": "2510.17309", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17309", "abs": "https://arxiv.org/abs/2510.17309", "authors": ["Thorsten Fr\u00f6hlich", "Tim Schlippe"], "title": "RubiSCoT: A Framework for AI-Supported Academic Assessment", "comment": null, "summary": "The evaluation of academic theses is a cornerstone of higher education,\nensuring rigor and integrity. Traditional methods, though effective, are\ntime-consuming and subject to evaluator variability. This paper presents\nRubiSCoT, an AI-supported framework designed to enhance thesis evaluation from\nproposal to final submission. Using advanced natural language processing\ntechniques, including large language models, retrieval-augmented generation,\nand structured chain-of-thought prompting, RubiSCoT offers a consistent,\nscalable solution. The framework includes preliminary assessments,\nmultidimensional assessments, content extraction, rubric-based scoring, and\ndetailed reporting. We present the design and implementation of RubiSCoT,\ndiscussing its potential to optimize academic assessment processes through\nconsistent, scalable, and transparent evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86RubiSCoT\u6846\u67b6\uff0c\u4f7f\u7528AI\u6280\u672f\u589e\u5f3a\u5b66\u672f\u8bba\u6587\u8bc4\u4f30\uff0c\u4ece\u63d0\u6848\u5230\u6700\u7ec8\u63d0\u4ea4\u63d0\u4f9b\u4e00\u81f4\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u8bba\u6587\u8bc4\u4f30\u65b9\u6cd5\u8017\u65f6\u4e14\u5b58\u5728\u8bc4\u4f30\u8005\u53d8\u5f02\u6027\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u4e00\u81f4\u7684\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5148\u8fdb\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u63d0\u4f9b\u521d\u6b65\u8bc4\u4f30\u3001\u591a\u7ef4\u8bc4\u4f30\u3001\u5185\u5bb9\u63d0\u53d6\u3001\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5206\u548c\u8be6\u7ec6\u62a5\u544a\u3002", "result": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86RubiSCoT\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b66\u672f\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "RubiSCoT\u6709\u6f5c\u529b\u901a\u8fc7\u4e00\u81f4\u3001\u53ef\u6269\u5c55\u548c\u900f\u660e\u7684\u8bc4\u4f30\u6765\u4f18\u5316\u5b66\u672f\u8bc4\u4f30\u8fc7\u7a0b\u3002"}}
{"id": "2510.17418", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.17418", "abs": "https://arxiv.org/abs/2510.17418", "authors": ["Mustafa F. Abdelwahed", "Alice Toniolo", "Joan Espasa", "Ian P. Gent"], "title": "Diverse Planning with Simulators via Linear Temporal Logic", "comment": null, "summary": "Autonomous agents rely on automated planning algorithms to achieve their\nobjectives. Simulation-based planning offers a significant advantage over\ndeclarative models in modelling complex environments. However, relying solely\non a planner that produces a single plan may not be practical, as the generated\nplans may not always satisfy the agent's preferences. To address this\nlimitation, we introduce $\\texttt{FBI}_\\texttt{LTL}$, a diverse planner\nexplicitly designed for simulation-based planning problems.\n$\\texttt{FBI}_\\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define\nsemantic diversity criteria, enabling agents to specify what constitutes\nmeaningfully different plans. By integrating these LTL-based diversity models\ndirectly into the search process, $\\texttt{FBI}_\\texttt{LTL}$ ensures the\ngeneration of semantically diverse plans, addressing a critical limitation of\nexisting diverse planning approaches that may produce syntactically different\nbut semantically identical solutions. Extensive evaluations on various\nbenchmarks consistently demonstrate that $\\texttt{FBI}_\\texttt{LTL}$ generates\nmore diverse plans compared to a baseline approach. This work establishes the\nfeasibility of semantically-guided diverse planning in simulation-based\nenvironments, paving the way for innovative approaches in realistic,\nnon-symbolic domains where traditional model-based approaches fail.", "AI": {"tldr": "\u63d0\u51fa\u4e86FBI_LTL\uff0c\u4e00\u4e2a\u7528\u4e8e\u4eff\u771f\u89c4\u5212\u95ee\u9898\u7684\u591a\u6837\u5316\u89c4\u5212\u5668\uff0c\u4f7f\u7528\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u5b9a\u4e49\u8bed\u4e49\u591a\u6837\u6027\u6807\u51c6\uff0c\u751f\u6210\u8bed\u4e49\u4e0a\u4e0d\u540c\u7684\u89c4\u5212\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u58f0\u660e\u7684\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u73af\u5883\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u4ec5\u751f\u6210\u5355\u4e00\u89c4\u5212\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3\u4ee3\u7406\u504f\u597d\uff0c\u9700\u8981\u8bed\u4e49\u591a\u6837\u5316\u7684\u89c4\u5212\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u5b9a\u4e49\u8bed\u4e49\u591a\u6837\u6027\u6807\u51c6\uff0c\u5c06\u8fd9\u4e9bLTL\u591a\u6837\u6027\u6a21\u578b\u76f4\u63a5\u96c6\u6210\u5230\u641c\u7d22\u8fc7\u7a0b\u4e2d\uff0c\u786e\u4fdd\u751f\u6210\u8bed\u4e49\u591a\u6837\u5316\u7684\u89c4\u5212\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cFBI_LTL\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u80fd\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u89c4\u5212\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u786e\u7acb\u4e86\u5728\u4eff\u771f\u73af\u5883\u4e2d\u8bed\u4e49\u5f15\u5bfc\u591a\u6837\u5316\u89c4\u5212\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5728\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u65b9\u6cd5\u5931\u6548\u7684\u73b0\u5b9e\u975e\u7b26\u53f7\u9886\u57df\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.17450", "categories": ["cs.AI", "H.4.2; I.2.3; I.2.6; I.2.8; I.2.9; J.7"], "pdf": "https://arxiv.org/pdf/2510.17450", "abs": "https://arxiv.org/abs/2510.17450", "authors": ["Johan Schubert", "Farzad Kamrani", "Tove Gustavi"], "title": "Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions", "comment": "Presented at the 6th International Workshop on Active Inference,\n  15-17 October 2025, Montreal, Canada", "summary": "We develop an active inference route-planning method for the autonomous\ncontrol of intelligent agents. The aim is to reconnoiter a geographical area to\nmaintain a common operational picture. To achieve this, we construct an\nevidence map that reflects our current understanding of the situation,\nincorporating both positive and \"negative\" sensor observations of possible\ntarget objects collected over time, and diffusing the evidence across the map\nas time progresses. The generative model of active inference uses\nDempster-Shafer theory and a Gaussian sensor model, which provides input to the\nagent. The generative process employs a Bayesian approach to update a posterior\nprobability distribution. We calculate the variational free energy for all\npositions within the area by assessing the divergence between a pignistic\nprobability distribution of the evidence map and a posterior probability\ndistribution of a target object based on the observations, including the level\nof surprise associated with receiving new observations. Using the free energy,\nwe direct the agents' movements in a simulation by taking an incremental step\ntoward a position that minimizes the free energy. This approach addresses the\nchallenge of exploration and exploitation, allowing agents to balance searching\nextensive areas of the geographical map while tracking identified target\nobjects.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u7528\u4e8e\u667a\u80fd\u4ee3\u7406\u7684\u81ea\u4e3b\u63a7\u5236\uff0c\u901a\u8fc7\u6784\u5efa\u8bc1\u636e\u5730\u56fe\u548c\u8ba1\u7b97\u53d8\u5206\u81ea\u7531\u80fd\u91cf\u6765\u6307\u5bfc\u4ee3\u7406\u79fb\u52a8\uff0c\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\u3002", "motivation": "\u4e3a\u4e86\u5728\u4fa6\u5bdf\u5730\u7406\u533a\u57df\u65f6\u7ef4\u6301\u5171\u540c\u4f5c\u6218\u6001\u52bf\u56fe\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861\u5e7f\u6cdb\u641c\u7d22\u548c\u8ddf\u8e2a\u5df2\u8bc6\u522b\u76ee\u6807\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Dempster-Shafer\u7406\u8bba\u548c\u9ad8\u65af\u4f20\u611f\u5668\u6a21\u578b\u6784\u5efa\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u65b9\u6cd5\u66f4\u65b0\u540e\u9a8c\u6982\u7387\u5206\u5e03\uff0c\u8ba1\u7b97\u53d8\u5206\u81ea\u7531\u80fd\u91cf\u6765\u6307\u5bfc\u4ee3\u7406\u79fb\u52a8\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6307\u5bfc\u4ee3\u7406\u5728\u5730\u7406\u5730\u56fe\u4e0a\u7684\u79fb\u52a8\uff0c\u6210\u529f\u5e73\u8861\u4e86\u63a2\u7d22\u548c\u5229\u7528\u7684\u9700\u6c42\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e3b\u52a8\u63a8\u7406\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u4e3a\u89e3\u51b3\u81ea\u4e3b\u667a\u80fd\u4ee3\u7406\u7684\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17463", "abs": "https://arxiv.org/abs/2510.17463", "authors": ["Cor Steging", "Tadeusz Zbiegie\u0144"], "title": "Label Indeterminacy in AI & Law", "comment": "This manuscript has been accepted for presentation as a short paper\n  at the 38th International Conference on Legal Knowledge and Information\n  Systems (JURIX) in Turin, December 9 to 11 of 2025", "summary": "Machine learning is increasingly used in the legal domain, where it typically\noperates retrospectively by treating past case outcomes as ground truth.\nHowever, legal outcomes are often shaped by human interventions that are not\ncaptured in most machine learning approaches. A final decision may result from\na settlement, an appeal, or other procedural actions. This creates label\nindeterminacy: the outcome could have been different if the intervention had or\nhad not taken place. We argue that legal machine learning applications need to\naccount for label indeterminacy. Methods exist that can impute these\nindeterminate labels, but they are all grounded in unverifiable assumptions. In\nthe context of classifying cases from the European Court of Human Rights, we\nshow that the way that labels are constructed during training can significantly\naffect model behaviour. We therefore position label indeterminacy as a relevant\nconcern in AI & Law and demonstrate how it can shape model behaviour.", "AI": {"tldr": "\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u4e2d\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff1a\u6cd5\u5f8b\u6848\u4ef6\u7ed3\u679c\u5e38\u53d7\u4eba\u4e3a\u5e72\u9884\u5f71\u54cd\uff0c\u5bfc\u81f4\u6807\u7b7e\u5177\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\u3002", "motivation": "\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u901a\u5e38\u5c06\u8fc7\u53bb\u6848\u4ef6\u7ed3\u679c\u89c6\u4e3a\u771f\u5b9e\u6807\u7b7e\uff0c\u4f46\u6cd5\u5f8b\u7ed3\u679c\u5e38\u53d7\u548c\u89e3\u3001\u4e0a\u8bc9\u7b49\u5e72\u9884\u5f71\u54cd\uff0c\u9020\u6210\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u5bf9\u6b64\u8fdb\u884c\u8003\u8651\u3002", "method": "\u5728\u6b27\u6d32\u4eba\u6743\u6cd5\u9662\u6848\u4ef6\u5206\u7c7b\u80cc\u666f\u4e0b\uff0c\u5206\u6790\u4e0d\u540c\u6807\u7b7e\u6784\u5efa\u65b9\u5f0f\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u63a2\u8ba8\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6807\u7b7e\u7684\u6784\u5efa\u65b9\u5f0f\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u7684\u884c\u4e3a\u8868\u73b0\u3002", "conclusion": "\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u662fAI\u4e0e\u6cd5\u5f8b\u9886\u57df\u7684\u91cd\u8981\u5173\u6ce8\u70b9\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.17598", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17598", "abs": "https://arxiv.org/abs/2510.17598", "authors": ["Amir Jalilifard", "Anderson de Rezende Rocha", "Marcos Medeiros Raimundo"], "title": "Reasoning Distillation and Structural Alignment for Improved Code Generation", "comment": null, "summary": "Effective code generation with language models hinges on two critical\nfactors: accurately understanding the intent of the prompt and generating code\nthat applies algorithmic reasoning to produce correct solutions capable of\npassing diverse test cases while adhering to the syntax of the target\nprogramming language. Unlike other language tasks, code generation requires\nmore than accurate token prediction; it demands comprehension of solution-level\nand structural relationships rather than merely generating the most likely\ntokens. very large language model (VLLM) are capable of generating detailed\nsteps toward the correct solution of complex tasks where reasoning is crucial\nin solving the problem. Such reasoning capabilities may be absent in smaller\nlanguage models. Therefore, in this work, we distill the reasoning capabilities\nof a VLLM into a smaller, more efficient model that is faster and cheaper to\ndeploy. Our approach trains the model to emulate the reasoning and\nproblem-solving abilities of the VLLM by learning to identify correct solution\npathways and establishing a structural correspondence between problem\ndefinitions and potential solutions through a novel method of structure-aware\nloss optimization. This enables the model to transcend token-level generation\nand to deeply grasp the overarching structure of solutions for given problems.\nExperimental results show that our fine-tuned model, developed through a cheap\nand simple to implement process, significantly outperforms our baseline model\nin terms of pass@1, average data flow, and average syntax match metrics across\nthe MBPP, MBPP Plus, and HumanEval benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u66f4\u5c0f\u3001\u66f4\u9ad8\u6548\u6a21\u578b\u4e2d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u635f\u5931\u4f18\u5316\u4f7f\u5c0f\u6a21\u578b\u80fd\u591f\u7406\u89e3\u89e3\u51b3\u65b9\u6848\u7684\u6574\u4f53\u7ed3\u6784\u800c\u4e0d\u4ec5\u4ec5\u662f\u751f\u6210token\u3002", "motivation": "\u4ee3\u7801\u751f\u6210\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\u7684token\u9884\u6d4b\uff0c\u66f4\u9700\u8981\u7406\u89e3\u89e3\u51b3\u65b9\u6848\u7ea7\u522b\u7684\u7ed3\u6784\u5173\u7cfb\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u800c\u5c0f\u6a21\u578b\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u5927\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u5c0f\u6a21\u578b\u4e2d\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u6a21\u578b\u6a21\u62df\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u5b66\u4e60\u8bc6\u522b\u6b63\u786e\u7684\u89e3\u51b3\u65b9\u6848\u8def\u5f84\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u635f\u5931\u4f18\u5316\u5efa\u7acb\u95ee\u9898\u5b9a\u4e49\u4e0e\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u7684\u7ed3\u6784\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7ecf\u8fc7\u5ec9\u4ef7\u4e14\u6613\u4e8e\u5b9e\u73b0\u7684\u5fae\u8c03\u8fc7\u7a0b\u5f00\u53d1\u7684\u6a21\u578b\uff0c\u5728MBPP\u3001MBPP Plus\u548cHumanEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728pass@1\u3001\u5e73\u5747\u6570\u636e\u6d41\u548c\u5e73\u5747\u8bed\u6cd5\u5339\u914d\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u5c0f\u6a21\u578b\u4e2d\uff0c\u53ef\u4ee5\u521b\u5efa\u51fa\u66f4\u5feb\u3001\u66f4\u4fbf\u5b9c\u90e8\u7f72\u7684\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5927\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u80fd\u591f\u7406\u89e3\u89e3\u51b3\u65b9\u6848\u7684\u6574\u4f53\u7ed3\u6784\u3002"}}
{"id": "2510.17614", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.17614", "abs": "https://arxiv.org/abs/2510.17614", "authors": ["Praphul Singh", "Corey Barrett", "Sumana Srivasta", "Irfan Bulu", "Sri Gadde", "Krishnaram Kenthapadi"], "title": "OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration", "comment": null, "summary": "Clinicians need ranking systems that work in real time and still justify\ntheir choices. Motivated by the need for a low-latency, decoder-based reranker,\nwe present OG-Rank, a single-decoder approach that pairs a pooled first-token\nscoring signal with an uncertainty-gated explanation step. The model scores all\ncandidates in one pass and generates a brief, structured rationale only when\nthe list is genuinely ambiguous, keeping latency predictable. Trained with a\ncurriculum that concentrates effort on hard cases, OG-Rank delivers strong\neffectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,\nnDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,\nnDCG@20~0.699 at a 45\\% gate rate), while compact backbones show similar gains\nunder the same policy. Encoder baselines trail in both effectiveness and\nflexibility. The result is a practical recipe: rank fast by default and explain\nwhen it helps, a pattern that applies broadly to decision tasks where selective\ngeneration buys accuracy at acceptable cost. The single-policy design\nsimplifies deployment and budget planning, and the curriculum principle (spend\nmore on the hard cases, less on the easy ones) readily transfers beyond\nclinical order selection.", "AI": {"tldr": "OG-Rank\u662f\u4e00\u4e2a\u4f4e\u5ef6\u8fdf\u7684\u89e3\u7801\u5668\u91cd\u6392\u5e8f\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u6c60\u5316\u9996\u8bcd\u8bc4\u5206\u548c\u4e0d\u786e\u5b9a\u6027\u95e8\u63a7\u89e3\u91ca\u6b65\u9aa4\uff0c\u5b9e\u73b0\u5feb\u901f\u6392\u540d\u5e76\u5728\u771f\u6b63\u6a21\u7cca\u65f6\u751f\u6210\u89e3\u91ca\uff0c\u5728\u4e34\u5e8a\u533b\u5631\u9009\u62e9\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4e34\u5e8a\u533b\u751f\u9700\u8981\u5b9e\u65f6\u5de5\u4f5c\u5e76\u80fd\u89e3\u91ca\u9009\u62e9\u7684\u6392\u540d\u7cfb\u7edf\uff0c\u9700\u8981\u4e00\u4e2a\u4f4e\u5ef6\u8fdf\u3001\u57fa\u4e8e\u89e3\u7801\u5668\u7684\u91cd\u6392\u5e8f\u5668\u3002", "method": "\u63d0\u51faOG-Rank\u5355\u89e3\u7801\u5668\u65b9\u6cd5\uff0c\u4f7f\u7528\u6c60\u5316\u9996\u8bcd\u8bc4\u5206\u4fe1\u53f7\u548c\u4e0d\u786e\u5b9a\u6027\u95e8\u63a7\u89e3\u91ca\u6b65\u9aa4\uff0c\u901a\u8fc7\u4e13\u6ce8\u4e8e\u56f0\u96be\u6848\u4f8b\u7684\u8bfe\u7a0b\u8bad\u7ec3\u3002", "result": "\u5728\u4e34\u5e8a\u533b\u5631\u9009\u62e9\u4efb\u52a1\u4e2d\u8868\u73b0\u5f3a\u52b2\uff08\u5feb\u901f\u8def\u5f84\uff1aRecall@1~0.45\uff0cnDCG@20~0.625\uff09\uff0c\u5f53\u95e8\u63a7\u6fc0\u6d3b\u65f6\u8fdb\u4e00\u6b65\u6539\u5584\uff08Recall@1~0.56\uff0cnDCG@20~0.699\uff0c\u95e8\u63a7\u738745%\uff09\uff0c\u7f16\u7801\u5668\u57fa\u7ebf\u5728\u6548\u679c\u548c\u7075\u6d3b\u6027\u4e0a\u90fd\u843d\u540e\u3002", "conclusion": "OG-Rank\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u65b9\u6848\uff1a\u9ed8\u8ba4\u5feb\u901f\u6392\u540d\uff0c\u5728\u9700\u8981\u65f6\u89e3\u91ca\uff0c\u8fd9\u79cd\u6a21\u5f0f\u9002\u7528\u4e8e\u9009\u62e9\u6027\u751f\u6210\u80fd\u4ee5\u53ef\u63a5\u53d7\u6210\u672c\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u51b3\u7b56\u4efb\u52a1\uff0c\u5355\u7b56\u7565\u8bbe\u8ba1\u7b80\u5316\u4e86\u90e8\u7f72\u548c\u9884\u7b97\u89c4\u5212\u3002"}}
{"id": "2510.17638", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17638", "abs": "https://arxiv.org/abs/2510.17638", "authors": ["Qingchuan Yang", "Simon Mahns", "Sida Li", "Anri Gu", "Jibang Wu", "Haifeng Xu"], "title": "LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena", "comment": "https://www.prophetarena.co/", "summary": "Forecasting is not only a fundamental intellectual pursuit but also is of\nsignificant importance to societal systems such as finance and economics. With\nthe rapid advances of large language models (LLMs) trained on Internet-scale\ndata, it raises the promise of employing LLMs to forecast real-world future\nevents, an emerging paradigm we call \"LLM-as-a-Prophet\". This paper\nsystematically investigates such predictive intelligence of LLMs. To this end,\nwe build Prophet Arena, a general evaluation benchmark that continuously\ncollects live forecasting tasks and decomposes each task into distinct pipeline\nstages, in order to support our controlled and large-scale experimentation. Our\ncomprehensive evaluation reveals that many LLMs already exhibit impressive\nforecasting capabilities, reflected in, e.g., their small calibration errors,\nconsistent prediction confidence and promising market returns. However, we also\nuncover key bottlenecks towards achieving superior predictive intelligence via\nLLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of\ndata sources and slower information aggregation compared to markets when\nresolution nears.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u9884\u6d4b\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u53d1\u73b0LLMs\u5df2\u5c55\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u4e8b\u4ef6\u56de\u5fc6\u4e0d\u51c6\u786e\u3001\u6570\u636e\u6e90\u8bef\u89e3\u7b49\u5173\u952e\u74f6\u9888\u3002", "motivation": "\u968f\u7740\u5728\u4e92\u8054\u7f51\u89c4\u6a21\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5229\u7528LLMs\u9884\u6d4b\u73b0\u5b9e\u4e16\u754c\u672a\u6765\u4e8b\u4ef6\u5177\u6709\u91cd\u8981\u6f5c\u529b\uff0c\u4f5c\u8005\u79f0\u4e4b\u4e3a\"LLM-as-a-Prophet\"\u8303\u5f0f\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u8fd9\u79cd\u9884\u6d4b\u667a\u80fd\u3002", "method": "\u6784\u5efa\u4e86Prophet Arena\u8bc4\u4f30\u57fa\u51c6\uff0c\u6301\u7eed\u6536\u96c6\u5b9e\u65f6\u9884\u6d4b\u4efb\u52a1\uff0c\u5e76\u5c06\u6bcf\u4e2a\u4efb\u52a1\u5206\u89e3\u4e3a\u4e0d\u540c\u7684\u6d41\u6c34\u7ebf\u9636\u6bb5\uff0c\u4ee5\u652f\u6301\u53d7\u63a7\u548c\u5927\u89c4\u6a21\u5b9e\u9a8c\u3002", "result": "\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0c\u8bb8\u591aLLM\u5df2\u5c55\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u8868\u73b0\u4e3a\u8f83\u5c0f\u7684\u6821\u51c6\u8bef\u5dee\u3001\u4e00\u81f4\u7684\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u548c\u6709\u524d\u666f\u7684\u5e02\u573a\u56de\u62a5\u3002", "conclusion": "\u867d\u7136LLMs\u5728\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b58\u5728\u5173\u952e\u74f6\u9888\uff0c\u5982\u4e8b\u4ef6\u56de\u5fc6\u4e0d\u51c6\u786e\u3001\u6570\u636e\u6e90\u8bef\u89e3\uff0c\u4ee5\u53ca\u5728\u63a5\u8fd1\u51b3\u7b56\u65f6\u4fe1\u606f\u805a\u5408\u901f\u5ea6\u6162\u4e8e\u5e02\u573a\u7b49\uff0c\u963b\u788d\u4e86\u5b9e\u73b0\u5353\u8d8a\u9884\u6d4b\u667a\u80fd\u3002"}}
{"id": "2510.17697", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.17697", "abs": "https://arxiv.org/abs/2510.17697", "authors": ["Anjie Liu", "Jianhong Wang", "Samuel Kaski", "Jun Wang", "Mengyue Yang"], "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "comment": "Accepted to NeurIPS 2025", "summary": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u5f71\u54cd\u56fe(MAIDs)\u4f5c\u4e3a\u56fe\u5f62\u5316\u6846\u67b6\u6765\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u534f\u8c03\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8eMAIDs\u7684\u9488\u5bf9\u6027\u5e72\u9884\u8303\u5f0f\uff0c\u5e76\u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u6280\u672f\u5b9e\u73b0\u5355\u667a\u80fd\u4f53\u5e72\u9884\u6765\u907f\u514d\u5168\u5c40\u6307\u5bfc\u7684\u56f0\u96be\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5bf9\u6574\u4e2a\u7cfb\u7edf\u8fdb\u884c\u5168\u5c40\u4eba\u5de5\u6307\u5bfc\u4e0d\u5207\u5b9e\u9645\uff0c\u800c\u73b0\u6709\u7684\u534f\u8c03\u673a\u5236\u8bbe\u8ba1\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\u7814\u7a76\uff0c\u7f3a\u4e4f\u6613\u7528\u7684\u7814\u7a76\u5de5\u5177\u3002", "method": "\u5f15\u5165\u591a\u667a\u80fd\u4f53\u5f71\u54cd\u56fe(MAIDs)\u4f5c\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u9488\u5bf9\u6027\u5e72\u9884\u8303\u5f0f\uff0c\u5e76\u91c7\u7528\u9884\u7b56\u7565\u5e72\u9884(PSI)\u56e0\u679c\u63a8\u65ad\u6280\u672f\u6765\u5b9e\u73b0\u5355\u667a\u80fd\u4f53\u5e72\u9884\uff0c\u901a\u8fc7\u6700\u5927\u5316\u56e0\u679c\u6548\u5e94\u6765\u8fbe\u6210\u590d\u5408\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u9488\u5bf9\u6027\u5e72\u9884\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u76f8\u5173\u6027\u56fe\u5206\u6790\u7684\u7ed3\u679c\u3002", "conclusion": "MAIDs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u56fe\u5f62\u5316\u6846\u67b6\u6765\u5206\u6790\u548c\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u8303\u5f0f\uff0c\u9488\u5bf9\u6027\u5e72\u9884\u80fd\u591f\u7f13\u89e3\u5168\u5c40\u6307\u5bfc\u95ee\u9898\uff0c\u56e0\u679c\u63a8\u65ad\u6280\u672f\u53ef\u4ee5\u6709\u6548\u5730\u5b9e\u73b0\u671f\u671b\u7684\u7ed3\u679c\u5bfc\u5411\u3002"}}
{"id": "2510.17705", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17705", "abs": "https://arxiv.org/abs/2510.17705", "authors": ["Dayan Pan", "Zhaoyang Fu", "Jingyuan Wang", "Xiao Han", "Yue Zhu", "Xiangyu Zhao"], "title": "Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models", "comment": "Accepted by CIKM' 25", "summary": "Large Language Models (LLMs) possess remarkable generalization capabilities\nbut struggle with multi-task adaptation, particularly in balancing knowledge\nretention with task-specific specialization. Conventional fine-tuning methods\nsuffer from catastrophic forgetting and substantial resource consumption, while\nexisting parameter-efficient methods perform suboptimally in complex multi-task\nscenarios. To address this, we propose Contextual Attention Modulation (CAM), a\nnovel mechanism that dynamically modulates the representations of\nself-attention modules in LLMs. CAM enhances task-specific features while\npreserving general knowledge, thereby facilitating more effective and efficient\nadaptation. For effective multi-task adaptation, CAM is integrated into our\nHybrid Contextual Attention Modulation (HyCAM) framework, which combines a\nshared, full-parameter CAM module with multiple specialized, lightweight CAM\nmodules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.\nExtensive experiments on heterogeneous tasks, including question answering,\ncode generation, and logical reasoning, demonstrate that our approach\nsignificantly outperforms existing approaches, achieving an average performance\nimprovement of 3.65%. The implemented code and data are available to ease\nreproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.", "AI": {"tldr": "\u63d0\u51faContextual Attention Modulation (CAM)\u673a\u5236\u548cHyCAM\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u5236\u81ea\u6ce8\u610f\u529b\u8868\u793a\u6765\u589e\u5f3a\u4efb\u52a1\u7279\u5b9a\u7279\u5f81\u5e76\u4fdd\u7559\u901a\u7528\u77e5\u8bc6\uff0c\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u5b58\u5728\u77e5\u8bc6\u4fdd\u7559\u4e0e\u4efb\u52a1\u4e13\u4e1a\u5316\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u8d44\u6e90\u6d88\u8017\u5927\u7684\u7f3a\u9677\uff0c\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\u5728\u590d\u6742\u591a\u4efb\u52a1\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faCAM\u673a\u5236\u52a8\u6001\u8c03\u5236\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u8868\u793a\uff0c\u5e76\u6784\u5efaHyCAM\u6846\u67b6\uff0c\u7ed3\u5408\u5171\u4eab\u7684\u5168\u53c2\u6570CAM\u6a21\u5757\u548c\u591a\u4e2a\u8f7b\u91cf\u7ea7\u4e13\u7528CAM\u6a21\u5757\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u7531\u7b56\u7565\u5b9e\u73b0\u81ea\u9002\u5e94\u77e5\u8bc6\u878d\u5408\u3002", "result": "\u5728\u95ee\u7b54\u3001\u4ee3\u7801\u751f\u6210\u548c\u903b\u8f91\u63a8\u7406\u7b49\u5f02\u6784\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5e73\u5747\u6027\u80fd\u63d0\u53473.65%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CAM\u548cHyCAM\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u77e5\u8bc6\u4fdd\u7559\u4e0e\u4efb\u52a1\u4e13\u4e1a\u5316\u5e73\u8861\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.17771", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17771", "abs": "https://arxiv.org/abs/2510.17771", "authors": ["Zhining Liu", "Ziyi Chen", "Hui Liu", "Chen Luo", "Xianfeng Tang", "Suhang Wang", "Joy Zeng", "Zhenwei Dai", "Zhan Shi", "Tianxin Wei", "Benoit Dumoulin", "Hanghang Tong"], "title": "Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs", "comment": "21 pages, 10 figures, 6 tables", "summary": "Vision-Language Models (VLMs) achieve strong results on multimodal tasks such\nas visual question answering, yet they can still fail even when the correct\nvisual evidence is present. In this work, we systematically investigate whether\nthese failures arise from not perceiving the evidence or from not leveraging it\neffectively. By examining layer-wise attention dynamics, we find that shallow\nlayers focus primarily on text, while deeper layers sparsely but reliably\nattend to localized evidence regions. Surprisingly, VLMs often perceive the\nvisual evidence when outputting incorrect answers, a phenomenon we term\n``seeing but not believing'' that widely exists in major VLM families. Building\non this, we introduce an inference-time intervention that highlights deep-layer\nevidence regions through selective attention-based masking. It requires no\ntraining and consistently improves accuracy across multiple families, including\nLLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable\nevidence internally but under-utilize it, making such signals explicit can\nbridge the gap between perception and reasoning, advancing the diagnostic\nunderstanding and reliability of VLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u611f\u77e5\u89c6\u89c9\u8bc1\u636e\uff0c\u4f46\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u672a\u80fd\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\uff0c\u5bfc\u81f4\"\u770b\u89c1\u4f46\u4e0d\u76f8\u4fe1\"\u73b0\u8c61\u3002\u901a\u8fc7\u9009\u62e9\u6027\u6ce8\u610f\u529b\u63a9\u7801\u5e72\u9884\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u6a21\u578b\u51c6\u786e\u6027\u3002", "motivation": "\u7cfb\u7edf\u7814\u7a76\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5931\u8d25\u7684\u539f\u56e0\uff1a\u662f\u7531\u4e8e\u672a\u80fd\u611f\u77e5\u89c6\u89c9\u8bc1\u636e\uff0c\u8fd8\u662f\u672a\u80fd\u6709\u6548\u5229\u7528\u5df2\u611f\u77e5\u7684\u8bc1\u636e\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5c42\u7ea7\u6ce8\u610f\u529b\u52a8\u6001\uff0c\u53d1\u73b0\u6d45\u5c42\u4e3b\u8981\u5173\u6ce8\u6587\u672c\uff0c\u6df1\u5c42\u7a00\u758f\u4f46\u53ef\u9760\u5730\u5173\u6ce8\u5c40\u90e8\u8bc1\u636e\u533a\u57df\u3002\u5f15\u5165\u63a8\u7406\u65f6\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6ce8\u610f\u529b\u63a9\u7801\u7a81\u51fa\u6df1\u5c42\u8bc1\u636e\u533a\u57df\u3002", "result": "\u5e72\u9884\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\uff0c\u5728LLaVA\u3001Qwen\u3001Gemma\u548cInternVL\u7b49\u591a\u4e2aVLM\u5bb6\u65cf\u4e2d\u4e00\u81f4\u63d0\u5347\u51c6\u786e\u6027\u3002", "conclusion": "VLMs\u5185\u90e8\u7f16\u7801\u4e86\u53ef\u9760\u7684\u8bc1\u636e\u4f46\u672a\u80fd\u5145\u5206\u5229\u7528\uff0c\u901a\u8fc7\u663e\u5f0f\u5316\u8fd9\u4e9b\u4fe1\u53f7\u53ef\u4ee5\u5f25\u5408\u611f\u77e5\u4e0e\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u5347VLM\u7684\u8bca\u65ad\u7406\u89e3\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.15911", "categories": ["q-fin.GN", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15911", "abs": "https://arxiv.org/abs/2510.15911", "authors": ["Ben Abramowitz"], "title": "Sleeping Kelly is a Thirder", "comment": null, "summary": "The Sleeping Beauty problem was presented by Elga and highlights the role of\nprobabilities in situations with imperfect recall. One approach to solving the\nSleeping Beauty problem is to allow Sleeping Beauty to make decisions based on\nher beliefs, and then characterize what it takes for her decisions to be\n\"rational\". In particular, she can be allowed to make monetary bets based on\nher beliefs, with the assumption that she wants to gain wealth rather than lose\nit. However, this approach is often coupled with the assumption that Sleeping\nBeauty should maximize the expected value of her bets. Here, I argue instead\nthat it is rational for Sleeping Beauty to maximize the growth rate of her\nwealth using the Kelly Criterion, which leads us to the \"thirder\" position.\nFurthermore, this position is shown to be \"rational\" by Dutch book arguments.\nIf Sleeping Kelly only accepts bets that have a growth rate greater than 1 as a\n\"thirder\" then she is not vulnerable to Dutch books. By contrast, if Sleeping\nBeauty takes the \"halfer\" position, she is vulnerable to Dutch books. If the\nbets offered to Sleeping Beauty were to be structured differently and lead to\nnon-multiplicative wealth dynamics, she may no longer be a \"thirder\".", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u51ef\u5229\u51c6\u5219\u8bba\u8bc1\u7761\u7f8e\u4eba\u95ee\u9898\u4e2d\u5e94\u91c7\u53d6\"\u4e09\u5206\u4e4b\u4e00\"\u7acb\u573a\uff0c\u8ba4\u4e3a\u7761\u7f8e\u4eba\u5e94\u6700\u5927\u5316\u8d22\u5bcc\u589e\u957f\u7387\u800c\u975e\u671f\u671b\u503c\uff0c\u5e76\u901a\u8fc7\u8377\u5170\u8d4c\u8bba\u8bc1\u5176\u5408\u7406\u6027\u3002", "motivation": "\u89e3\u51b3\u7761\u7f8e\u4eba\u95ee\u9898\u4e2d\u6982\u7387\u4e0e\u7406\u6027\u51b3\u7b56\u7684\u77db\u76fe\uff0c\u63a2\u8ba8\u5728\u975e\u5b8c\u7f8e\u8bb0\u5fc6\u60c5\u5883\u4e0b\u5982\u4f55\u5b9a\u4e49\"\u7406\u6027\"\u51b3\u7b56\u3002", "method": "\u4f7f\u7528\u51ef\u5229\u51c6\u5219\u5206\u6790\u7761\u7f8e\u4eba\u5e94\u5982\u4f55\u4e0b\u6ce8\u4ee5\u6700\u5927\u5316\u8d22\u5bcc\u589e\u957f\u7387\uff0c\u5e76\u901a\u8fc7\u8377\u5170\u8d4c\u8bba\u8bc1\u68c0\u9a8c\u4e0d\u540c\u7acb\u573a\u7684\u5408\u7406\u6027\u3002", "result": "\u7761\u7f8e\u4eba\u4f5c\u4e3a\"\u4e09\u5206\u4e4b\u4e00\u8005\"\u63a5\u53d7\u589e\u957f\u7387\u5927\u4e8e1\u7684\u8d4c\u6ce8\u65f6\u4e0d\u53d7\u8377\u5170\u8d4c\u5f71\u54cd\uff0c\u800c\"\u4e8c\u5206\u4e4b\u4e00\u8005\"\u5219\u9762\u4e34\u8377\u5170\u8d4c\u98ce\u9669\u3002", "conclusion": "\u5728\u4e58\u6027\u8d22\u5bcc\u52a8\u6001\u4e0b\uff0c\u7761\u7f8e\u4eba\u5e94\u91c7\u7eb3\"\u4e09\u5206\u4e4b\u4e00\"\u7acb\u573a\u4ee5\u6700\u5927\u5316\u8d22\u5bcc\u589e\u957f\u5e76\u907f\u514d\u8377\u5170\u8d4c\uff0c\u4f46\u82e5\u8d22\u5bcc\u52a8\u6001\u6539\u53d8\u5219\u7ed3\u8bba\u53ef\u80fd\u4e0d\u540c\u3002"}}
