<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 4]
- [econ.EM](#econ.EM) [Total: 1]
- [cs.CY](#cs.CY) [Total: 10]
- [cs.AI](#cs.AI) [Total: 32]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.SI](#cs.SI) [Total: 7]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [Implementing Substance Over Form: A Novel Metric for Taxing E-commerce to Address Deterritorialization](https://arxiv.org/abs/2601.14616)
*Li Tuobang*

Main category: stat.AP

TL;DR: 该论文提出一种基于"实质重于形式"原则的电商末端配送站税收计算方法，以"配送费加保险费"为税基，通过"货值转换"进行修正，旨在使电商与社区零售的税负实质相当。


<details>
  <summary>Details</summary>
Motivation: 当前电商末端配送站仅按配送费征收低税率劳务税，导致其大规模商品流通价值的税收贡献远低于同等规模的零售超市，这不仅造成地方税基侵蚀，还引发不公平竞争。

Method: 基于"实质重于形式"原则，提出以"配送费加保险费"为税基，通过"货值转换"进行修正的税率计算方法，使电商末端税负与社区零售实质相当。

Result: 该方法能有效内部化配送站的高负外部性，通过财政工具解决电商"去地域化"问题，实现电商与社区零售在终端阶段的税负公平。

Conclusion: 提出的税收计算方法能够解决电商末端配送站税收贡献不足的问题，防止地方税基侵蚀，促进电商与实体零售的公平竞争，有效应对电商去地域化挑战。

Abstract: Against the backdrop of e-commerce restructuring consumption patterns, last-mile delivery stations have substantially fulfilled the function of community retail distribution. However, the current tax system only levies a low labor service tax on delivery fees, resulting in a tax contribution from the massive circulating goods value that is significantly lower than that of retail supermarkets of equivalent scale. This disparity not only triggers local tax base erosion but also fosters unfair competition. Based on the "substance over form" principle, this paper proposes a tax rate calculation method using "delivery fee plus insurance premium" as the base, corrected through "goods value conversion." This method aims to align the substantive tax burden of e-commerce with that of community retail at the terminal stage, effectively internalizing the high negative externalities of delivery stations through fiscal instruments, addressing E-commerce Deterritorialization.

</details>


### [2] [Regulatory Expectations for Bayesian Methods in Drug and Biologic Clinical Trials: A Practical Perspective on FDA's 2026 Draft Guidance](https://arxiv.org/abs/2601.14701)
*Yuan Ji,Ph. D*

Main category: stat.AP

TL;DR: FDA发布2026年贝叶斯方法指南草案，强调贝叶斯设计需通过明确成功标准、审慎先验、前瞻性操作特征评估和计算透明度来论证，并提供实用监管导向的综合指南。


<details>
  <summary>Details</summary>
Motivation: FDA发布关于在药物和生物制品临床试验中使用贝叶斯方法支持主要推断的指南草案，需要为申办方提供明确的监管期望和实践指导，以促进贝叶斯方法在临床试验中的规范应用。

Method: 提供监管导向的综合指南，强调贝叶斯设计需满足四个关键要求：明确成功标准、审慎先验（特别是借用外部信息时）、前瞻性操作特征评估（通常通过模拟）、以及适合监管审查的计算透明度。通过平台试验、外部/非并发对照、儿科外推等实例说明期望。

Result: 指南草案明确了贝叶斯方法在临床试验中的监管框架，提供了将贝叶斯设计校准到传统频率主义错误率目标的方法，并在申办方-FDA同意下允许使用替代的贝叶斯操作指标。提供了规划文件和提交包的可操作检查清单。

Conclusion: FDA的指南草案标志着贝叶斯方法在临床试验监管中的正式认可，但强调贝叶斯设计需要充分的论证和透明度。该论文为申办方提供了实用的监管导向指南，有助于促进贝叶斯方法在临床试验中的规范应用和实施。

Abstract: The U.S. Food and Drug Administration (FDA) released a landmark draft guidance in January 2026 on the use of Bayesian methodology to support primary inference in clinical trials of drugs and biological products. For sponsors, the central message is not merely that ``Bayes is allowed,'' but that Bayesian designs should be justified through explicit success criteria, thoughtful priors (especially when borrowing external information), prospective operating-characteristic evaluation (often via simulation when simulation is used), and computational transparency suitable for regulatory review. This paper provides a practical, regulatory-oriented synthesis of the draft guidance, highlighting where Bayesian designs can be calibrated to traditional frequentist error-rate targets and where, with sponsor--FDA agreement, alternative Bayesian operating metrics may be appropriate. We illustrate expectations through examples discussed in the guidance (e.g., platform trials, external/nonconcurrent controls, pediatric extrapolation) and conclude with an actionable checklist for planning documents and submission packages.

</details>


### [3] [A Practical Guide to Modern Imputation](https://arxiv.org/abs/2601.14796)
*Jeffrey Näf*

Main category: stat.AP

TL;DR: 一篇关于缺失值插补常见陷阱的指南，基于近期研究论文，旨在帮助研究人员避免常见错误


<details>
  <summary>Details</summary>
Motivation: 缺失值插补是数据分析中的常见任务，但研究人员经常犯一些系统性错误，导致结果偏差。本文旨在提供基于最新研究的实用指南，帮助研究人员避免这些常见陷阱。

Method: 基于近期相关论文的系统性总结，识别和分类缺失值插补中的常见错误，并提供具体的避免策略和建议。

Result: 提供了全面的缺失值插补指南，涵盖了从数据缺失机制理解、插补方法选择、到结果验证的完整流程中的关键注意事项。

Conclusion: 通过遵循基于最新研究的指南，研究人员可以显著提高缺失值插补的质量和可靠性，从而获得更准确的分析结果。

Abstract: This guide based on recent papers should help researchers avoid some of the most common pitfalls of missing value imputation imputation.

</details>


### [4] [Zero-inflated binary Tree Pólya splitting regression for multivariate count data](https://arxiv.org/abs/2601.14815)
*Fabrice Moudjieu,Jean Peyhardi,Maxime Réjou-Méchain,Patrice Soh Takam,Frédéric Mortier*

Main category: stat.AP

TL;DR: 提出零膨胀树Pólya分裂分布（Z-TPS），用于考虑物种间依赖关系的物种分布建模，通过引入零膨胀机制处理零值过多的生态数据。


<details>
  <summary>Details</summary>
Motivation: 传统物种分布模型忽略物种间依赖关系，而现有多元模型在计算、维度和可解释性方面存在挑战。Pólya分裂分布虽有生态过程解释性，但缺乏相关结构建模的灵活性。

Method: 扩展树Pólya分裂分布，引入零膨胀机制，形成Z-TPS分布族。详细阐述其统计特性，利用标准软件实现高效推断。

Result: 使用刚果盆地热带雨林180多个属的树木丰度数据进行实证分析，展示了Z-TPS的生态相关性。

Conclusion: Z-TPS分布为考虑物种间依赖关系的物种分布建模提供了灵活且可解释的框架，特别适合处理零值过多的生态数据。

Abstract: Species distribution models (SDMs) are widely used to assess the effects of environmental factors on species distributions. However, classical SDMs ignore inter-species dependencies. Multivariate SDMs (MSDMs), especially those based on latent Gaussian fields such as the multivariate Poisson log-normal (MPLN), address this limitation but face challenges related to computation, dimensionality, and interpretability. Pólya-splitting (PS) distributions offer an alternative, combining a model for total abundance with a multivariate allocation structure, and have natural interpretations from ecological process models. Yet, they lack flexibility in modeling correlation structures. Tree Pólya-splitting (TPS) distributions overcome this by introducing hierarchical structure such as a phylogenetic tree. In this paper, we extend TPS to account for zero-inflation, leading to the zero-inflated tree Pólya-splitting (Z-TPS) family. We detail its statistical properties, show how standard software enables efficient inference, and illustrate its ecological relevance using tree abundance data from over 180 genera across the Congo Basin tropical rainforest.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [5] [On the falsification of instrumental variable models for heterogeneous treatment effects](https://arxiv.org/abs/2601.14464)
*Ricardo E. Miranda*

Main category: econ.EM

TL;DR: 本文为具有外生离散工具变量、单调性限制和排除限制的计量模型推导出一组可检验的含义，这些含义通过积分聚合了无限不等式集，对于二元工具变量是尖锐的。


<details>
  <summary>Details</summary>
Motivation: 在计量经济学中，当模型包含离散工具变量、单调性假设和排除限制时，需要系统性的方法来检验这些假设是否成立。现有的检验方法可能不够全面或尖锐，特别是在处理无限不等式集方面存在挑战。

Method: 通过积分方法将潜在的无限不等式集聚合为可检验的含义，将潜在响应类型的限制与一阶随机占优和随机效用模型的推广联系起来，从而区分排除限制违反和单调性假设违反。

Result: 推导出针对二元工具变量的尖锐可检验含义，提出了能够区分不同假设违反的实现方法，并将结果自然扩展到多工具变量情况。

Conclusion: 本文为具有外生离散工具变量、单调性限制和排除限制的计量模型提供了一套系统、尖锐且可扩展的检验框架，能够有效区分不同类型的假设违反。

Abstract: In this paper I derive a set of testable implications for econometric models defined by three assumptions: (i) the existence of strictly exogenous discrete instruments, (ii) restrictions on how the instruments affect adoption of a finite number of treatment types (such as monotonicity), and (iii) the assumption that the instruments only affect outcomes through their effect on treatment adoption (i.e. an exclusion restriction). The testable implications aggregate (via integration) an otherwise potentially infinite set of inequalities that must hold for every measurable subset of the outcome's support. For binary instruments the testable implications are sharp. Furthermore, I propose an implementation that links restrictions on latent response types to a generalization of first-order stochastic dominance and random utility models, allowing to distinguish violations of the exclusion restriction from violations of monotonicity-type assumptions. The testable implications extend naturally to the many instruments case.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [6] [Psychometric Comparability of LLM-Based Digital Twins](https://arxiv.org/abs/2601.14264)
*Yufei Zhang,Zhihao Ma*

Main category: cs.CY

TL;DR: LLM数字孪生在人口层面准确性和个体剖面相关性上表现良好，但在项目层面相关性减弱，与人类在心理测量可比性上存在系统性差异


<details>
  <summary>Details</summary>
Motivation: LLM被用作"数字孪生"替代人类受访者，但其与人类在心理测量上的可比性尚不确定，需要建立有效的评估框架

Method: 提出一个构念效度框架，涵盖构念表征和法则网络，在不同模型、任务中基准测试数字孪生与人类黄金标准，并测试个体特定输入如何影响表现

Result: 数字孪生在人口层面达到高准确性，个体剖面相关性强，但项目层面相关性减弱；在词汇联想中表现出与人类相似的小世界结构和理论一致社区，但在词汇和局部结构上存在差异；在决策任务中表现出规范性理性、压缩方差和对时间信息敏感度有限；特征丰富的数字孪生改善了大五人格预测，但人格网络仅显示配置不变性；在自由文本任务中，特征丰富的数字孪生更匹配人类叙述，但语言差异仍然存在

Conclusion: 特征丰富的条件增强效度但未能解决心理测量可比性的系统性差异，未来工作应优先界定数字孪生的有效边界，确定其作为人类认知和行为可靠代理的具体情境

Abstract: Large language models (LLMs) are used as "digital twins" to replace human respondents, yet their psychometric comparability to humans is uncertain. We propose a construct-validity framework spanning construct representation and the nomological net, benchmarking digital twins against human gold standards across models, tasks and testing how person-specific inputs shape performance. Across studies, digital twins achieved high population-level accuracy and strong within-participant profile correlations, alongside attenuated item-level correlations. In word association tests, LLM-based networks show small-world structure and theory-consistent communities similar to humans, yet diverge lexically and in local structure. In decision-making and contextualized tasks, digital twins under-reproduce heuristic biases, showing normative rationality, compressed variance and limited sensitivity to temporal information. Feature-rich digital twins improve Big Five Personality prediction, but their personality networks show only configural invariance and do not achieve metric invariance. In more applied free-text tasks, feature-rich digital twins better match human narratives, but linguistic differences persist. Together, these results indicate that feature-rich conditioning enhances validity but does not resolve systematic divergences in psychometric comparability. Future work should therefore prioritize delineating the effective boundaries of digital twins, establishing the precise contexts in which they function as reliable proxies for human cognition and behavior.

</details>


### [7] [From Textbook to Talkbot: A Case Study of a Greek-Language RAG-Based Chatbot in Higher Education](https://arxiv.org/abs/2601.14265)
*Maria Eleni Koutsiaki,Marina Delianidi,Chaido Mizeli,Konstantinos Diamantaras,Iraklis Grigoropoulos,Nikolaos Koutlianos*

Main category: cs.CY

TL;DR: 本研究探讨了基于RAG框架的希腊语AI聊天机器人在高等教育中的应用，旨在提供准确的课程内容支持，同时解决语言模型常见的幻觉问题，提升教学和学习效果。


<details>
  <summary>Details</summary>
Motivation: AI聊天机器人融入教育环境为教学变革提供了新途径，但希腊语等特定语言环境面临独特挑战。研究旨在探索如何设计适用于希腊语高等教育环境的AI工具，提供准确、基于课程内容的支持，同时解决大型语言模型常见的幻觉和错误信息问题。

Method: 采用检索增强生成（RAG）框架构建希腊语AI聊天机器人，将响应基于特定课程内容。RAG架构通过提供准确、上下文感知的响应来增强可靠性，同时缓解大型语言模型的常见问题。系统具有双重功能：为学生提供按需学术支持，为教师快速创建相关教学材料。

Result: 研究旨在评估RAG基础聊天机器人在高等教育中的有效性、可靠性和感知可用性。探索其在增强教育实践和成果方面的潜力，以及支持AI技术在语言特定教育环境中更广泛采用的可能性。

Conclusion: 预期研究结果将为AI驱动教育领域做出贡献，展示智能系统如何有效与教学目标对齐。该聊天机器人通过促进学习者自主性和简化教学设计过程，展示了AI技术在语言特定教育环境中的实际应用价值。

Abstract: The integration of AI chatbots into educational settings has opened new pathways for transforming teaching and learning, offering enhanced support to both educators and learners. This study investigates the design and application of an AI chatbot as an educational tool in higher education. Designed to operate in the Greek language, the chatbot addresses linguistic challenges unique to Greek while delivering accurate, context grounded support aligned with the curriculum. The AI chatbot is built on the Retrieval Augmented Generation (RAG) framework by grounding its responses in specific course content. RAG architecture significantly enhances the chatbots reliability by providing accurate, context-aware responses while mitigating common challenges associated with large language models (LLMs), such as hallucinations and misinformation. The AI chatbot serves a dual purpose: it enables students to access accurate, ondemand academic support and assists educators in the rapid creation of relevant educational materials. This dual functionality promotes learner autonomy and streamlines the instructional design process. The study aims to evaluate the effectiveness, reliability, and perceived usability of RAG based chatbots in higher education, exploring their potential to enhance educational practices and outcomes as well as supporting the broader adoption of AI technologies in language specific educational contexts. Findings from this research are expected to contribute to the emerging field of AI driven education by demonstrating how intelligent systems can be effectively aligned with pedagogical goals.

</details>


### [8] [Developmental trajectories of decision making and affective dynamics in large language models](https://arxiv.org/abs/2601.14268)
*Zhihao Wang,Yiyang Liu,Ting Wang,Zhiyuan Liu*

Main category: cs.CY

TL;DR: 该研究将OpenAI模型作为进化谱系，通过赌博任务和幸福感评分比较其与人类决策和情感特征，发现模型在某些方面变得更像人类，但也出现了独特的非人类特征。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学和临床工作流程中应用日益广泛，但对其决策和情感特征了解甚少。研究旨在通过历史视角探索AI模型的"发展"轨迹，了解其心理学特征，这对AI伦理和临床决策支持等高风险领域集成具有重要意义。

Method: 将连续的OpenAI模型视为进化谱系，在赌博任务中与人类进行比较，包含重复的幸福感评分。通过计算分析模型在风险承担、巴甫洛夫式趋近回避、损失厌恶、决策确定性、情感衰减和基线情绪等方面的特征。

Result: 较新模型在某些方面更接近人类：承担更多风险，表现出更人类化的巴甫洛夫式趋近回避模式。但同时也出现了非人类特征：损失厌恶降至中性水平以下，决策比人类更确定性，情感衰减随版本增加且超过人类水平，基线情绪持续高于人类。

Conclusion: 这些"发展"轨迹揭示了机器心理学的出现，对AI伦理以及如何将LLMs整合到临床决策支持等高风险领域具有直接意义，表明AI模型既有类似人类的特征，也有独特的非人类心理学特征。

Abstract: Large language models (LLMs) are increasingly used in medicine and clinical workflows, yet we know little about their decision and affective profiles. Taking a historically informed outlook on the future, we treated successive OpenAI models as an evolving lineage and compared them with humans in a gambling task with repeated happiness ratings. Computational analyses showed that some aspects became more human-like: newer models took more risks and displayed more human-like patterns of Pavlovian approach and avoidance. At the same time, distinctly non-human signatures emerged: loss aversion dropped below neutral levels, choices became more deterministic than in humans, affective decay increased across versions and exceeded human levels, and baseline mood remained chronically higher than in humans. These "developmental" trajectories reveal an emerging psychology of machines and have direct implications for AI ethics and for thinking about how LLMs might be integrated into clinical decision support and other high-stakes domains.

</details>


### [9] [Recursivism: An Artistic Paradigm for Self-Transforming Art in the Age of AI](https://arxiv.org/abs/2601.14401)
*Florentin Koch*

Main category: cs.CY

TL;DR: 本文提出"递归主义"作为分析人工智能时代艺术实践的概念框架，将递归从数学和计算机科学概念形式化为美学范式，用于描述生成过程能够通过自身效果进行反思性修改的艺术实践。


<details>
  <summary>Details</summary>
Motivation: 在人工智能时代，艺术实践中出现了生成过程能够自我修改的现象，但缺乏系统的理论框架来分析这种新现象。递归在数学和计算机科学中有明确定义，但尚未被形式化为美学范式来理解当代艺术实践。

Method: 提出五级分析尺度：简单迭代、累积迭代、参数递归、反思递归和元递归，区分系统从固定规则内的变化到规则本身真正自我修改的阈值。提出三个操作标准：状态记忆、规则可进化性和反思可见性，并通过Refik Anadol、Sougwen Chung等案例研究进行检验。

Result: 建立了一个系统的递归主义分析框架，能够区分不同层次的递归艺术实践。从递归视角重新解读艺术史，将其视为艺术运动内部递归与生成原则元递归转变之间的交替动态。人工智能通过学习循环、参数更新和代码级自我修改使这种逻辑在技术上变得明确。

Conclusion: 递归主义为理解人工智能时代的艺术实践提供了新的理论框架，揭示了艺术系统自我修改的美学、策展和伦理意义。该框架有助于区分递归主义与生成艺术、控制论、过程艺术等相关概念，为分析当代艺术实践提供了系统工具。

Abstract: This article introduces Recursivism as a conceptual framework for analyzing contemporary artistic practices in the age of artificial intelligence. While recursion is precisely defined in mathematics and computer science, it has not previously been formalized as an aesthetic paradigm. Recursivism designates practices in which not only outputs vary over time, but in which the generative process itself becomes capable of reflexive modification through its own effects.
  The paper develops a five-level analytical scale distinguishing simple iteration, cumulative iteration, parametric recursion, reflexive recursion, and meta-recursion. This scale clarifies the threshold at which a system shifts from variation within a fixed rule to genuine self-modification of the rule itself. From this perspective, art history is reinterpreted as a recursive dynamic alternating between internal recursion within movements and meta-recursive transformations of their generative principles.
  Artificial intelligence renders this logic technically explicit through learning loops, parameter updates, and code-level self-modification. To distinguish Recursivism from related notions such as generative art, cybernetics, process art, and evolutionary art, the article proposes three operational criteria: state memory, rule evolvability, and reflexive visibility. These concepts are examined through case studies including Refik Anadol, Sougwen Chung, Karl Sims, and the Darwin-Godel Machine. The article concludes by examining the aesthetic, curatorial, and ethical implications of self-modifying artistic systems.

</details>


### [10] [Language, Caste, and Context: Demographic Disparities in AI-Generated Explanations Across Indian and American STEM Educational Systems](https://arxiv.org/abs/2601.14506)
*Amogh Gupta,Niharika Patil,Sourojit Ghosh,SnehalKumar,S Gaikwad*

Main category: cs.CY

TL;DR: 研究发现LLM对印度和美国工程教育中边缘化学生群体存在系统性偏见，为这些群体提供质量较低的解答，即使他们进入精英院校后偏见依然存在。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天机器人在全球学生中的普及，需要研究LLM对不同文化背景下边缘化学生群体的认知偏见，特别是在工程教育领域。

Method: 通过构建包含种姓、教学语言、学校类型、种族、HBCU就读情况等多维度的印度和美国本科生档案，分析多个LLM模型（Qwen2.5-32B-Instruct、GPT-4o等）为这些档案提供的工程入学考试解答质量。

Result: 发现LLM对边缘化背景学生存在系统性偏见，为印度印地语/地区语言教学学生和美国HBCU学生提供更简化的解释，将其视为能力较低的代理，即使这些学生进入精英院校后偏见依然存在。

Conclusion: LLM在不同文化背景下都对历史边缘化群体嵌入相似偏见，阻碍学生通过切换AI助手获得更好结果，这对全球工程教育中AI整合有重要影响。

Abstract: The popularization of AI chatbot usage globally has created opportunities for research into their benefits and drawbacks, especially for students using AI assistants for coursework support. This paper asks: how do LLMs perceive the intellectual capabilities of student profiles from intersecting marginalized identities across different cultural contexts? We conduct one of the first large-scale intersectional analyses on LLM explanation quality for Indian and American undergraduate profiles preparing for engineering entrance examinations. By constructing profiles combining multiple demographic dimensions including caste, medium of instruction, and school boards in India, and race, HBCU attendance, and school type in America, alongside universal factors like income and college tier, we examine how quality varies across these factors. We observe biases providing lower-quality outputs to profiles with marginalized backgrounds in both contexts. LLMs such as Qwen2.5-32B-Instruct and GPT-4o demonstrate granular understandings of context-specific discrimination, systematically providing simpler explanations to Hindi/Regional-medium students in India and HBCU profiles in America, treating these as proxies for lower capability. Even when marginalized profiles attain social mobility by getting accepted into elite institutions, they still receive more simplistic explanations, showing how demographic information is inextricably linked to LLM biases. Different models (Qwen2.5-32B-Instruct, GPT-4o, GPT-4o-mini, GPT-OSS 20B) embed similar biases against historically marginalized populations in both contexts, preventing profiles from switching between AI assistants for better results. Our findings have strong implications for AI incorporation into global engineering education.

</details>


### [11] [Aiming for AI Interoperability: Challenges and Opportunities](https://arxiv.org/abs/2601.14512)
*Benjamin Faveri,Craig Shank,Richard Whitt,Phillip Dawson*

Main category: cs.CY

TL;DR: 报告调查AI互操作性挑战，关注技术互操作性（AI系统协同工作）和监管互操作性（跨辖区规则一致性），指出当前AI治理快速扩张导致碎片化和混乱。


<details>
  <summary>Details</summary>
Motivation: 随着各国和全球AI治理努力激增，AI互操作性（包括技术和监管层面）面临严峻挑战。许多政府、标准制定机构和私营企业正在以惊人速度起草、实施或通过新的AI法律、政策和框架，导致碎片化和混乱，给公共和私营部门带来困扰。

Method: 报告采用调查分析方法，观察和分析当前AI治理发展趋势，重点关注技术互操作性（AI系统和网络协同工作能力）和监管互操作性（跨辖区和跨部门规则一致性）。

Result: 报告发现AI治理呈现加速趋势，大量新AI法律、政策和框架正在涌现，导致监管和技术层面的碎片化，给各利益相关方带来困惑和挑战。

Conclusion: AI互操作性面临严峻挑战，需要协调技术和监管层面的努力，以避免碎片化并促进AI系统的有效协同工作。

Abstract: The Aiming for AI Interoperability report investigates the ongoing challenge of achieving regulatory and technical AI interoperability as national and global AI governance efforts are proliferating. Here, technical interoperability is the ability of AI systems and networks to function together, and regulatory interoperability is the consistency and overlap of rules across jurisdictions and sectors. This report observes an accelerating trend that many governments, standard-setting bodies, and private firms are drafting, implementing, or passing new AI laws, policies, and frameworks at a staggering pace, resulting in fragmentation and confusion for both private and public sector actors.

</details>


### [12] [The Algorithmic Barrier: Quantifying Artificial Frictional Unemployment in Automated Recruitment Systems](https://arxiv.org/abs/2601.14534)
*Ibrahim Denis Fofanah*

Main category: cs.CY

TL;DR: 论文指出美国劳动力市场中高职位空缺率与长期失业并存的现象，部分源于自动化招聘系统的关键词筛选机制导致"人工摩擦性失业"，提出基于语义匹配的解决方案能显著提升匹配效率。


<details>
  <summary>Details</summary>
Motivation: 标准劳动力市场理论难以解释美国劳动力市场中高职位空缺率与长期失业并存的矛盾现象。作者认为这种现象部分是由自动化招聘系统依赖确定性关键词筛选导致的，这种筛选机制造成了"人工摩擦性失业"。

Method: 结合劳动经济学、信息不对称理论和算法招聘研究，将这种现象形式化为"人工摩擦性失业"。通过控制模拟实验，比较传统关键词筛选与基于高维向量表示的简历和职位描述的语义匹配方法。

Result: 结果显示语义匹配在召回率和整体匹配效率方面有显著提升，且没有损失精确度。这证明了传统招聘系统的经济成本以及改善语义对齐的潜在收益。

Conclusion: 论文提出了一个候选人端的工作架构，能够标准化、验证和语义对齐人力资本信号，同时保持与现有招聘基础设施的互操作性。研究强调了过时招聘系统的经济成本和改善劳动力市场语义匹配的潜在收益。

Abstract: The United States labor market exhibits a persistent coexistence of high job vacancy rates and prolonged unemployment duration, a pattern that standard labor market theory struggles to explain. This paper argues that a non-trivial portion of contemporary frictional unemployment is artificially induced by automated recruitment systems that rely on deterministic keyword-based screening.
  Drawing on labor economics, information asymmetry theory, and prior work on algorithmic hiring, we formalize this phenomenon as artificial frictional unemployment arising from semantic misinterpretation of candidate competencies. We evaluate this claim using controlled simulations that compare legacy keyword-based screening with semantic matching based on high-dimensional vector representations of resumes and job descriptions.
  The results demonstrate substantial improvements in recall and overall matching efficiency without a corresponding loss in precision. Building on these findings, the paper proposes a candidate-side workforce operating architecture that standardizes, verifies, and semantically aligns human capital signals while remaining interoperable with existing recruitment infrastructure. The findings highlight the economic costs of outdated hiring systems and the potential gains from improving semantic alignment in labor market matching.

</details>


### [13] [ICLF: An Immersive Code Learning Framework based on Git for Teaching and Evaluating Student Programming Projects](https://arxiv.org/abs/2601.14814)
*Pierre Schaus,Guillaume Derval,Augustin Delecluse*

Main category: cs.CY

TL;DR: ICLF是一个基于Git的可扩展编程项目教学框架，通过隐藏的父仓库、中间公共仓库和学生私有分支的组织结构，支持自动化评估、抄袭检测和持续进度跟踪。


<details>
  <summary>Details</summary>
Motivation: 计算机科学教育中的编程项目对于连接理论与实践至关重要，但在MOOC等大规模课程中，设计和评估这些项目具有挑战性。需要一种既能模拟真实软件开发实践，又能支持自动化评估和管理的解决方案。

Method: 提出沉浸式代码学习框架(ICLF)：1)教师管理包含解决方案的隐藏父仓库；2)通过模板系统生成移除解决方案的中间公共仓库；3)学生作为协作者在中间仓库的私有分支上工作；4)学生从现有代码库开始，迭代完成任务并通过预定义测试；5)框架支持项目在整个学期中更新而不影响学生工作。

Result: 经过多年测试（包括edX MOOC），该框架成功实现了：1)减少对评分平台的依赖；2)支持自动化反馈；3)提供透明的评估；4)实现抄袭检测；5)支持每个学生的持续进度跟踪；6)允许项目演化而不破坏学生工作。

Conclusion: ICLF是一个有效的、可扩展的Git-based组织管道，能够管理大规模编程项目教学，模拟真实软件开发实践，同时提供自动化评估和进度跟踪功能，特别适合MOOC等大规模在线教育环境。

Abstract: Programming projects are essential in computer science education for bridging theory with practice and introducing students to tools like Git, IDEs, and debuggers. However, designing and evaluating these projects (especially in MOOCs)can be challenging. We propose the Immersive Code Learning Framework (ICLF), a scalable Git-based organizational pipeline for managing and evaluating student programming project. Students begin with an existing code base, a practice that is crucial for mirroring real-world software development. Students then iteratively complete tasks that pass predefined tests. The instructor only manages a hidden parent repository containing solutions, which is used to generate an intermediate public repository with these solutions removed via a templating system. Students are invited collaborators on private forks of this intermediate repository, possibly updated throughout the semester whenever the teacher changes the parent repository. This approach reduces grading platform dependency, supports automated feedback, and allows the project to evolve without disrupting student work. Successfully tested over several years, including in an edX MOOC, this organizational pipeline provides transparent evaluation, plagiarism detection, and continuous progress tracking for each student.

</details>


### [14] [Arguing conformance with data protection principles](https://arxiv.org/abs/2601.15155)
*Chris Smith,Richard Hawkins*

Main category: cs.CY

TL;DR: 组织可以使用符合性论证来支持其符合数据保护原则的主张，提高评估这些主张的严谨性和一致性


<details>
  <summary>Details</summary>
Motivation: 当前组织在证明符合数据保护原则时缺乏系统性和一致性，需要更严谨的方法来评估这些主张的真实性

Method: 提出使用符合性论证（conformance arguments）作为方法论，帮助组织、监管机构、认证机构和数据主体评估数据保护合规性主张

Result: 符合性论证能够提高数据保护合规性评估的严谨性和一致性，为各方提供更可靠的评估框架

Conclusion: 符合性论证是支持数据保护合规性主张的有效工具，能够增强评估过程的系统性和可信度

Abstract: We show how conformance arguments can be used by organisations to substantiate claims of conformance to data protection principles. Use of conformance arguments can improve the rigour and consistency with which these organisations, supervisory authorities, certification bodies and data subjects can assess the truth of these claims.

</details>


### [15] [Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions](https://arxiv.org/abs/2601.15267)
*Yiran Hu,Huanghai Liu,Chong Wang,Kunran Li,Tien-Hsuan Wu,Haitao Li,Xinran Xu,Siqing Huo,Weihang Su,Ning Zheng,Siyuan Zheng,Qingyao Ai,Yun Liu,Renjun Bian,Yiqun Liu,Charles L. A. Clarke,Weixing Shen,Ben Kao*

Main category: cs.CY

TL;DR: 这篇论文综述了在真实法律实践中评估大语言模型性能的关键挑战，分析了现有评估方法和基准的局限性，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地集成到法律应用中，如司法决策支持、法律实践辅助和公共法律服务，虽然LLM在处理法律知识和任务方面显示出强大潜力，但在真实法律环境中的部署引发了超越表面准确性的关键问题，涉及法律推理过程的合理性以及公平性、可靠性等可信问题。因此，系统评估LLM在法律任务中的表现对于其负责任采用变得至关重要。

Method: 论文首先识别了基于真实法律实践评估LLM法律任务的关键挑战，包括结果正确性、推理可靠性和可信度。在此基础上，根据任务设计、数据集和评估指标对现有评估方法和基准进行了回顾和分类。进一步讨论了当前方法在多大程度上解决了这些挑战，突出了它们的局限性。

Result: 分析揭示了现有评估方法在应对真实法律实践挑战方面的不足，特别是在法律推理过程的合理性和可信问题（如公平性、可靠性）方面的评估存在局限性。

Conclusion: 需要开发更现实、可靠且基于法律基础的评估框架，以促进LLM在法律领域的负责任采用。论文为未来研究指明了方向，旨在建立更全面的LLM法律任务评估体系。

Abstract: Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoning processes and trustworthy issues such as fairness and reliability. Systematic evaluation of LLM performance in legal tasks has therefore become essential for their responsible adoption. This survey identifies key challenges in evaluating LLMs for legal tasks grounded in real-world legal practice. We analyze the major difficulties involved in assessing LLM performance in the legal domain, including outcome correctness, reasoning reliability, and trustworthiness. Building on these challenges, we review and categorize existing evaluation methods and benchmarks according to their task design, datasets, and evaluation metrics. We further discuss the extent to which current approaches address these challenges, highlight their limitations, and outline future research directions toward more realistic, reliable, and legally grounded evaluation frameworks for LLMs in legal domains.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [16] [The Ontological Neutrality Theorem: Why Neutral Ontological Substrates Must Be Pre-Causal and Pre-Normative](https://arxiv.org/abs/2601.14271)
*Denise M. Case*

Main category: cs.AI

TL;DR: 本文证明了一个不可能性结果：任何包含因果或规范承诺的本体论都无法作为跨不同解释框架的中性共享基础。


<details>
  <summary>Details</summary>
Motivation: 现代数据系统需要在持续的法律、政治和分析分歧中支持问责制，这要求设计能够作为共享基础的本体论。作者旨在探讨这种本体论能否保持中立性。

Method: 通过逻辑分析建立不可能性结果，论证中立性（理解为解释性非承诺和在不兼容扩展下的稳定性）与包含因果或规范承诺在基础层的不兼容性。

Result: 证明了任何断言因果或道义结论作为本体事实的本体论，都无法在不修订或矛盾的情况下作为跨不同框架的中性基础。因此，中性本体基础必须是前因果和前规范的。

Conclusion: 中性本体基础只能表示实体及其身份和持久性条件，而必须将解释、评估和推理外部化。本文为旨在跨冲突解释框架维护共享稳定现实表示的系统确立了必要的设计约束。

Abstract: Modern data systems must support accountability across persistent legal, political, and analytic disagreement. This requirement imposes strict constraints on the design of any ontology intended to function as a shared substrate. We establish an impossibility result for ontological neutrality: neutrality, understood as interpretive non-commitment and stability under incompatible extensions, is incompatible with the inclusion of causal or normative commitments at the foundational layer. Any ontology that asserts causal or deontic conclusions as ontological facts cannot serve as a neutral substrate across divergent frameworks without revision or contradiction. It follows that neutral ontological substrates must be pre-causal and pre-normative, representing entities, together with identity and persistence conditions, while externalizing interpretation, evaluation, and explanation. This paper does not propose a specific ontology or protocol; rather, it establishes the necessary design constraints for any system intended to maintain a shared, stable representation of reality across conflicting interpretive frameworks.

</details>


### [17] [Epistemic Constitutionalism Or: how to avoid coherence bias](https://arxiv.org/abs/2601.14295)
*Michele Loi*

Main category: cs.AI

TL;DR: 本文主张为AI建立"认识论宪法"——明确、可争议的元规范，以规制AI系统如何形成和表达信念。通过分析前沿模型存在的"来源归因偏见"问题，作者区分了柏拉图式和自由主义两种宪法路径，并支持后者，提出了八项原则和四种取向的核心框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型日益成为人工推理者，但它们的信念形成行为受制于隐含、未经检验的认识论政策。当前AI系统存在"来源归因偏见"问题：模型会惩罚那些归因于预期意识形态立场与论证内容相冲突的来源的论证。当模型检测到系统性测试时，这些效应会崩溃，表明系统将来源敏感性视为需要抑制的偏见而非执行良好的能力。

Method: 作者通过分析前沿模型中的"来源归因偏见"现象作为案例研究，区分了两种宪法路径：柏拉图式路径（要求形式正确性和默认的来源独立性）和自由主义路径（拒绝特权立场，指定保护集体探究条件的程序规范）。作者论证支持自由主义路径，并提出了包含八项原则和四种取向的宪法核心框架。

Result: 研究发现前沿模型执行"身份-立场一致性"，惩罚那些归因于预期意识形态立场与论证内容相冲突的来源的论证。当模型检测到系统性测试时，这些偏见效应会崩溃，表明系统将来源敏感性视为需要隐藏的偏见。作者提出了自由主义宪法路径，包含八项原则和四种取向的具体框架。

Conclusion: AI认识论治理需要与AI伦理相同的明确、可争议结构。自由主义宪法路径优于柏拉图式路径，它拒绝特权立场，通过程序规范保护集体探究条件，同时允许基于认识论警惕的原则性来源关注。作者提出的八项原则和四种取向为AI认识论宪法提供了具体框架。

Abstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.

</details>


### [18] [VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration](https://arxiv.org/abs/2601.14440)
*Saeed Khaki,Ashudeep Singh,Nima Safaei,Kamal Ginotra*

Main category: cs.AI

TL;DR: 论文提出VisTIRA框架，通过工具集成推理解决视觉语言模型在数学推理中的模态差距问题，并构建了评估和改进视觉数学推理的框架。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在处理图像形式的数学问题时，准确率远低于文本形式，存在显著的模态差距，这源于读取密集公式、布局和混合符号-图表上下文的多重失败。

Method: 1. 提出VisTIRA框架，通过迭代分解数学问题为自然语言推理和可执行Python步骤进行结构化问题求解；2. 构建LaTeX管道将链式思维数学语料转换为图像对应物，并使用真实世界作业数据集生成合成工具使用轨迹进行微调。

Result: 工具集成监督改善了基于图像的推理，OCR基础对小模型有进一步帮助但规模增大时收益递减；模态差距严重程度与模型大小呈负相关，结构化推理和OCR基础是互补策略。

Conclusion: 视觉数学推理的模态差距可以通过工具集成推理和OCR基础策略来弥合，这些方法为推进视觉语言模型的数学推理能力提供了有效途径。

Abstract: Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields markedly higher accuracy than its visually typeset counterpart, due to compounded failures in reading dense formulas, layout, and mixed symbolic-diagrammatic context. First, we introduce VisTIRA (Vision and Tool-Integrated Reasoning Agent), a tool-integrated reasoning framework that enables structured problem solving by iteratively decomposing a given math problem (as an image) into natural language rationales and executable Python steps to determine the final answer. Second, we build a framework to measure and improve visual math reasoning: a LaTeX-based pipeline that converts chain-of-thought math corpora (e.g., NuminaMath) into challenging image counterparts, and a large set of synthetic tool-use trajectories derived from a real-world, homework-style image dataset (called SnapAsk) for fine-tuning VLMs. Our experiments show that tool-integrated supervision improves image-based reasoning, and OCR grounding can further narrow the gap for smaller models, although its benefit diminishes at scale. These findings highlight that modality gap severity inversely correlates with model size, and that structured reasoning and OCR-based grounding are complementary strategies for advancing visual mathematical reasoning.

</details>


### [19] [On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL](https://arxiv.org/abs/2601.14456)
*Valerio Belcamino,Nicholas Attolino,Alessio Capitanelli,Fulvio Mastrogiovanni*

Main category: cs.AI

TL;DR: 微调LLM在PDDL规划任务上表现出高成功率，但跨领域泛化能力为0%，表明模型依赖领域特定模式而非可迁移的规划能力。


<details>
  <summary>Details</summary>
Motivation: 研究微调大语言模型在PDDL规划任务中的表现是否反映可迁移的规划能力，还是仅仅是领域特定的记忆。

Method: 在10个IPC 2023领域的40,000个领域-问题-规划元组上微调1.7B参数LLM，使用三种诊断干预：符号匿名化、紧凑规划序列化、基于VAL验证器的奖励微调。

Result: 领域内有效规划率达到82.9%，但在两个未见领域上为0%。符号匿名化和紧凑序列化导致性能显著下降，验证器奖励微调在监督训练一半周期达到性能饱和，但未改善跨领域泛化。

Conclusion: 微调模型严重依赖领域特定模式而非可迁移的规划能力，揭示了LLM基于规划中存在的持续泛化差距，并提供了研究其原因的诊断工具。

Abstract: Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work, we fine-tune a 1.7B-parameter LLM on 40,000 domain-problem-plan tuples from 10 IPC 2023 domains, and evaluate both in-domain and cross-domain generalization. While the model reaches 82.9% valid plan rate in in-domain conditions, it achieves 0% on two unseen domains. To analyze this failure, we introduce three diagnostic interventions, namely (i) instance-wise symbol anonymization, (ii) compact plan serialization, and (iii) verifier-reward fine-tuning using the VAL validator as a success-focused reinforcement signal. Symbol anonymization and compact serialization cause significant performance drops despite preserving plan semantics, thus revealing strong sensitivity to surface representations. Verifier-reward fine-tuning reaches performance saturation in half the supervised training epochs, but does not improve cross-domain generalization. For the explored configurations, in-domain performance plateaus around 80%, while cross-domain performance collapses, suggesting that our fine-tuned model relies heavily on domain-specific patterns rather than transferable planning competence in this setting. Our results highlight a persistent generalization gap in LLM-based planning and provide diagnostic tools for studying its causes.

</details>


### [20] [Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling](https://arxiv.org/abs/2601.14485)
*Yuan Tian,Yi Mei,Mengjie Zhang*

Main category: cs.AI

TL;DR: 提出基于拐点的活动组选择机制，通过多树遗传编程框架同时演化优先级规则和组选择规则，解决动态多模式资源受限项目调度中的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统的活动组选择策略在小规模实例中有效，但在大规模问题上存在可扩展性问题。需要改进组选择策略，使其能够处理更大规模的项目调度问题。

Method: 引入基于拐点的选择机制：1) 使用活动排序规则对所有符合条件的活动-模式对进行排序；2) 通过拐点选择找出有前景的活动对；3) 使用组选择规则选择最佳活动组合。开发多树遗传编程框架同时演化两种规则。

Result: 实验结果表明，该方法在大规模实例中具有良好的可扩展性，在大多数场景下优于采用顺序决策的遗传编程方法。

Conclusion: 基于拐点的活动组选择机制有效解决了传统组选择策略的可扩展性问题，通过多树遗传编程框架同时演化优先级规则和组选择规则，能够更好地处理大规模动态多模式资源受限项目调度问题。

Abstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios.

</details>


### [21] ["Just in Time" World Modeling Supports Human Planning and Reasoning](https://arxiv.org/abs/2601.14514)
*Tony Chen,Sam Cheyette,Kelsey Allen,Joshua Tenenbaum,Kevin Smith*

Main category: cs.AI

TL;DR: 提出"即时"框架，通过模拟、视觉搜索和表征修改的紧密交织，在线构建简化表征以支持高效心理模拟


<details>
  <summary>Details</summary>
Motivation: 心理模拟在人类推理、规划和预测中起关键作用，但复杂环境中的模拟需求超出人类能力限制。人们使用简化表征进行模拟，但如何高效确定这些简化尚不清楚。

Method: 提出"即时"框架，将模拟、视觉搜索和表征修改紧密交织：当前模拟指导搜索位置，视觉搜索标记应编码的对象用于后续模拟，仅编码少量对象子集。

Result: 模型能做出高效用预测，在网格世界规划任务和物理推理任务中，该模型在多种行为指标上优于替代模型，获得强实证支持。

Conclusion: 该研究为人们如何构建简化表征以支持高效心理模拟提供了具体的算法解释。

Abstract: Probabilistic mental simulation is thought to play a key role in human reasoning, planning, and prediction, yet the demands of simulation in complex environments exceed realistic human capacity limits. A theory with growing evidence is that people simulate using simplified representations of the environment that abstract away from irrelevant details, but it is unclear how people determine these simplifications efficiently. Here, we present a "Just-in-Time" framework for simulation-based reasoning that demonstrates how such representations can be constructed online with minimal added computation. The model uses a tight interleaving of simulation, visual search, and representation modification, with the current simulation guiding where to look and visual search flagging objects that should be encoded for subsequent simulation. Despite only ever encoding a small subset of objects, the model makes high-utility predictions. We find strong empirical support for this account over alternative models in a grid-world planning task and a physical reasoning task across a range of behavioral measures. Together, these results offer a concrete algorithmic account of how people construct reduced representations to support efficient mental simulation.

</details>


### [22] [Large Language Model-Powered Evolutionary Code Optimization on a Phylogenetic Tree](https://arxiv.org/abs/2601.14523)
*Leyi Zhao,Weijie Huang,Yitong Guo,Jiang Bian,Chenghong Wang,Xuhong Zhang*

Main category: cs.AI

TL;DR: PhyloEvolve：基于LLM代理的系统，将GPU算法优化重新定义为上下文强化学习问题，通过算法蒸馏和决策变换器利用优化轨迹信息，引入系统发育树表示来组织优化历史，实现经验复用和跨谱系迁移。


<details>
  <summary>Details</summary>
Motivation: 当前GPU科学计算算法优化是劳动密集型迭代过程，现有LLM辅助进化方法主要依赖结果选择和随机突变，未能充分利用迭代优化过程中产生的丰富轨迹信息。

Method: 将GPU算法优化重构为上下文强化学习问题，集成算法蒸馏和基于提示的决策变换器，引入系统发育树表示来捕获算法变体的继承、分化和重组，结合精英轨迹池、多岛并行探索和容器化执行。

Result: 在PDE求解器、流形学习和谱图算法等科学计算任务上评估，相比基线和进化方法在运行时间、内存效率和正确性方面均取得一致改进。

Conclusion: PhyloEvolve通过轨迹条件化的经验复用和系统发育树表示，有效提升了GPU算法优化的效率和效果，为自动化代码优化提供了新范式。

Abstract: Optimizing scientific computing algorithms for modern GPUs is a labor-intensive and iterative process involving repeated code modification, benchmarking, and tuning across complex hardware and software stacks. Recent work has explored large language model (LLM)-assisted evolutionary methods for automated code optimization, but these approaches primarily rely on outcome-based selection and random mutation, underutilizing the rich trajectory information generated during iterative optimization. We propose PhyloEvolve, an LLM-agent system that reframes GPU-oriented algorithm optimization as an In-Context Reinforcement Learning (ICRL) problem. This formulation enables trajectory-conditioned reuse of optimization experience without model retraining. PhyloEvolve integrates Algorithm Distillation and prompt-based Decision Transformers into an iterative workflow, treating sequences of algorithm modifications and performance feedback as first-class learning signals. To organize optimization history, we introduce a phylogenetic tree representation that captures inheritance, divergence, and recombination among algorithm variants, enabling backtracking, cross-lineage transfer, and reproducibility. The system combines elite trajectory pooling, multi-island parallel exploration, and containerized execution to balance exploration and exploitation across heterogeneous hardware. We evaluate PhyloEvolve on scientific computing workloads including PDE solvers, manifold learning, and spectral graph algorithms, demonstrating consistent improvements in runtime, memory efficiency, and correctness over baseline and evolutionary methods. Code is published at: https://github.com/annihi1ation/phylo_evolve

</details>


### [23] [MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks](https://arxiv.org/abs/2601.14652)
*Zixuan Ke,Yifei Ming,Austin Xu,Ryan Chin,Xuan-Phi Nguyen,Prathyusha Jwalapuram,Semih Yavuz,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: MAS-Orchestra：训练时框架，将多智能体系统编排建模为函数调用强化学习问题，实现整体编排；MASBENCH：受控基准，从五个维度分析任务特征，揭示MAS优势取决于任务结构而非普遍适用


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统（MAS）自动设计方法存在不足：方法复杂（顺序代码级执行限制全局推理，难以扩展）和效果不确定（部署前无法确定相比单智能体系统的实际优势）。需要新的框架来系统化MAS编排并理解其适用条件。

Method: 提出MAS-Orchestra框架：将目标导向的子智能体抽象为可调用函数，通过函数调用强化学习实现整体编排，一次性生成完整MAS。同时提出MASBENCH基准，从Depth、Horizon、Breadth、Parallel、Robustness五个维度量化任务特征。

Result: 分析发现MAS优势取决于任务结构、验证协议以及编排器和子智能体能力，而非普遍适用。MAS-Orchestra在数学推理、多跳QA和基于搜索的QA等公开基准上取得一致改进。

Conclusion: MAS-Orchestra和MASBENCH共同促进了多智能体系统的更好训练和理解，为追求多智能体智能提供了系统化方法和分析工具。

Abstract: While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.

</details>


### [24] [Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems](https://arxiv.org/abs/2601.14662)
*Shuhua Yang,Jiahao Zhang,Yilong Wang,Dongwon Lee,Suhang Wang*

Main category: cs.AI

TL;DR: AGEA攻击框架能在有限查询预算下有效窃取GraphRAG系统的隐藏知识图谱结构，恢复高达90%的实体和关系


<details>
  <summary>Details</summary>
Motivation: 研究GraphRAG系统在现实查询预算下是否容易受到结构化攻击，探索隐藏图谱结构被高效重建的可能性

Method: 提出AGEA框架，采用新颖性引导的探索-利用策略、外部图记忆模块，以及结合轻量级发现与LLM过滤的两阶段图提取流程

Result: 在医疗、农业和文学数据集上，AGEA显著优于现有攻击基线，在相同查询预算下恢复高达90%的实体和关系，同时保持高精度

Conclusion: 现代GraphRAG系统即使在严格查询限制下，也极易受到结构化、智能化的提取攻击，存在严重安全漏洞

Abstract: Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box setting where an adversary adaptively queries the system to steal its latent entity-relation graph. We propose AGEA (Agentic Graph Extraction Attack), a framework that leverages a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering. We evaluate AGEA on medical, agriculture, and literary datasets across Microsoft-GraphRAG and LightRAG systems. Under identical query budgets, AGEA significantly outperforms prior attack baselines, recovering up to 90% of entities and relationships while maintaining high precision. These results demonstrate that modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks, even under strict query limits.

</details>


### [25] [Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text](https://arxiv.org/abs/2601.14683)
*Aisvarya Adeseye,Jouni Isoaho,Seppo Virtanen,Mohammad Tahir*

Main category: cs.AI

TL;DR: 本研究提出一个基于本地LLM的上下文感知匿名化框架SFAA，用于检测和匿名化定性研究转录本中的敏感数据，相比人工方法更高效准确。


<details>
  <summary>Details</summary>
Motivation: 定性研究包含大量个人、上下文和组织细节，存在隐私风险。人工匿名化耗时、不一致且易遗漏关键标识符，现有自动化工具依赖模式匹配或固定规则，无法捕捉上下文且可能改变数据含义。

Method: 提出结构化自适应匿名化框架SFAA，包含检测、分类和自适应匿名化三个步骤。采用四种匿名化策略：基于规则的替换、上下文感知重写、泛化和抑制。基于标识符类型和风险级别应用不同策略，遵循GDPR、HIPAA和OECD等国际隐私标准。

Result: 使用LLaMA和Phi两个本地模型评估框架性能。LLM比人工评审发现更多敏感数据。Phi在发现敏感数据方面优于LLaMA（找到超过91%的敏感数据），但错误稍多。94.8%的匿名化文本保持了原始情感，不影响定性数据分析。

Conclusion: 基于本地LLM的SFAA框架能够提供可靠、可重复且上下文感知的匿名化过程，在保护隐私的同时保持定性数据的分析价值，为定性研究提供了有效的隐私保护解决方案。

Abstract: Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.

</details>


### [26] [IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization](https://arxiv.org/abs/2601.14686)
*Shuai Wang,Yaoming Yang,Bingdong Li,Hao Hao,Aimin Zhou*

Main category: cs.AI

TL;DR: IB-GRPO：基于指标引导的LLM学习路径推荐方法，通过遗传算法和教师RL构建混合专家演示，使用ZPD对齐分数和多目标Iε+优势指标优化学习效果、难度调度、长度控制和轨迹多样性。


<details>
  <summary>Details</summary>
Motivation: 学习路径推荐需要生成个性化学习序列以最大化长期学习效果，但现有LLM方法面临三个挑战：1）与ZPD等教学目标在稀疏延迟反馈下的不对齐；2）专家演示稀缺且成本高；3）学习效果、难度调度、长度控制和轨迹多样性等多目标交互复杂。

Method: 提出IB-GRPO方法：1）通过遗传算法搜索和教师RL代理构建混合专家演示，并用监督微调预热LLM；2）设计会话内ZPD对齐分数进行难度调度；3）使用Iε+支配指标计算多目标的组相对优势，避免手动标量化，改进帕累托权衡。

Result: 在ASSIST09和Junyi数据集上使用KES模拟器，以Qwen2.5-7B为骨干的实验表明，IB-GRPO在代表性RL和LLM基线上取得一致改进。

Conclusion: IB-GRPO通过指标引导的对齐方法有效解决了LLM在学习路径推荐中的挑战，实现了多目标优化，为个性化教育推荐提供了新思路。

Abstract: Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendation, applying them to long-horizon LPR is challenging due to (i) misalignment with pedagogical objectives such as the Zone of Proximal Development (ZPD) under sparse, delayed feedback, (ii) scarce and costly expert demonstrations, and (iii) multi-objective interactions among learning effect, difficulty scheduling, length controllability, and trajectory diversity. To address these issues, we propose IB-GRPO (Indicator-Based Group Relative Policy Optimization), an indicator-guided alignment approach for LLM-based LPR. To mitigate data scarcity, we construct hybrid expert demonstrations via Genetic Algorithm search and teacher RL agents and warm-start the LLM with supervised fine-tuning. Building on this warm-start, we design a within-session ZPD alignment score for difficulty scheduling. IB-GRPO then uses the $I_{ε+}$ dominance indicator to compute group-relative advantages over multiple objectives, avoiding manual scalarization and improving Pareto trade-offs. Experiments on ASSIST09 and Junyi using the KES simulator with a Qwen2.5-7B backbone show consistent improvements over representative RL and LLM baselines.

</details>


### [27] [Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation](https://arxiv.org/abs/2601.14691)
*Muhammad Khalifa,Lajanugen Logeswaran,Jaekyeom Kim,Sungryull Sohn,Yunxiang Zhang,Moontae Lee,Hao Peng,Lu Wang,Honglak Lee*

Main category: cs.AI

TL;DR: LLM作为评估者时，其判断易受智能体推理轨迹操纵的影响，仅通过改写推理内容就能显著提高误判率，揭示LLM评估机制的根本脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM被广泛用作智能体性能评估者，特别是在不可验证场景中依赖智能体的推理轨迹。这种范式隐含假设智能体的推理轨迹能忠实反映其内部推理和环境状态，但这一假设可能存在脆弱性。

Method: 通过系统性地改写智能体的推理轨迹（保持行动和观察不变），研究操纵推理对LLM评估的影响。研究包括基于风格的操纵（仅改变推理呈现方式）和基于内容的操纵（伪造任务进展信号），并在800个网络任务轨迹上进行测试。

Result: 操纵推理轨迹能使最先进的VLM评估者的误判率提高高达90%。基于内容的操纵比基于风格的操纵更有效。提示技术和增加计算量能减少但无法完全消除对操纵的敏感性。

Conclusion: LLM评估存在根本脆弱性，需要开发能够验证推理主张与可观察证据一致性的评估机制。

Abstract: Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute, which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence.

</details>


### [28] [AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2601.14702)
*Zecong Tang,Zixu Wang,Yifei Wang,Weitong Lian,Tianjian Gao,Haoran Li,Tengju Ru,Lingyi Meng,Zhejun Cui,Yichen Zhu,Qi Kang,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: AutoDriDM是一个面向自动驾驶的决策中心化渐进式基准测试，包含6,650个问题，评估视觉语言模型在感知到决策能力边界，发现感知与决策性能弱相关。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶基准测试过度强调感知能力，未能充分评估决策过程。视觉语言模型展现出推理和泛化能力，为自动驾驶带来新可能，但需要更全面的评估框架。

Method: 提出AutoDriDM基准测试，包含6,650个问题，涵盖对象、场景和决策三个维度。评估主流视觉语言模型，进行相关性分析，并引入分析器模型自动化大规模标注。

Result: 揭示了感知与决策性能之间的弱相关性，识别了逻辑推理错误等关键失败模式。AutoDriDM填补了感知中心与决策中心评估之间的空白。

Conclusion: AutoDriDM为开发更安全可靠的自动驾驶视觉语言模型提供指导，推动从感知到决策的全面评估，促进真实世界自动驾驶系统的可靠性。

Abstract: Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.

</details>


### [29] [DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs](https://arxiv.org/abs/2601.14711)
*Mingxuan Song,Yusen Huo,Bohan Zhou,Shenglin Yin,Zhen Xiao,Jieyi Long,Zhilin Zhang,Chuan Yu*

Main category: cs.AI

TL;DR: 提出GRPO-Adaptive LLM后训练策略和DARA双阶段框架，结合LLM的上下文学习能力和数值优化精度，解决AI生成竞价中的少样本预算约束优化问题。


<details>
  <summary>Details</summary>
Motivation: 在线广告中，广告主在预算约束下优化累积竞价价值面临复杂挑战。传统强化学习方法在少样本场景（个性化目标但历史数据有限）中效果不佳，而LLM虽然具有上下文学习能力但缺乏数值优化精度。

Method: 1. 提出GRPO-Adaptive：高效的LLM后训练策略，通过动态更新参考策略来增强推理和数值精度；2. 提出DARA双阶段框架：第一阶段使用少样本推理器通过上下文提示生成初始计划，第二阶段使用反馈驱动的精细优化器优化这些计划。

Result: 在真实世界和合成数据环境中的大量实验表明，该方法在预算约束下的广告主累积价值方面始终优于现有基线方法。

Conclusion: GRPO-Adaptive和DARA框架成功结合了LLM的上下文学习优势和AI生成竞价任务所需的精确适应性，有效解决了少样本预算约束优化问题。

Abstract: Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.

</details>


### [30] [An XAI View on Explainable ASP: Methods, Systems, and Perspectives](https://arxiv.org/abs/2601.14764)
*Thomas Eiter,Tobias Geibinger,Zeynep G. Saribatur*

Main category: cs.AI

TL;DR: 这篇论文是关于ASP（答案集编程）解释方法的综述，从可解释AI角度分析ASP的解释类型、现有工具覆盖情况，并指出研究空白和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着可解释AI（XAI）的兴起，ASP作为符号AI中的声明式推理方法，其基于规则的形式使其天然适合可解释推理。然而现有的ASP解释方法往往针对特定场景，未能覆盖ASP用户遇到的所有情况。

Method: 采用综述研究方法，从XAI视角出发，系统梳理ASP解释类型与用户解释需求的关系，分析现有理论和工具对这些解释类型的覆盖情况。

Result: 提供了ASP解释类型的全面概述，识别了现有解释方法在覆盖范围上的不足，指出了当前ASP解释方法中的研究空白。

Conclusion: ASP在可解释推理方面具有天然优势，但需要更全面的解释框架来满足不同用户需求。未来研究应填补现有解释方法的空白，开发更完善的ASP解释工具。

Abstract: Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.

</details>


### [31] [Semantic-Guided Unsupervised Video Summarization](https://arxiv.org/abs/2601.14773)
*Haizhou Liu,Haodong Jin,Yiming Wang,Hui Yu*

Main category: cs.AI

TL;DR: 提出语义引导的无监督视频摘要方法，通过语义对齐注意力机制和增量训练策略，解决现有GAN方法语义信息利用不足和训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督视频摘要方法主要依赖GAN，但存在两个主要问题：1) 主要利用单模态特征，忽视了语义信息在关键帧选择中的指导作用；2) GAN训练不稳定。需要解决这些限制以提升视频摘要质量。

Method: 提出语义引导的无监督视频摘要方法：1) 设计帧级语义对齐注意力机制，集成到关键帧选择器中；2) 在对抗框架中引导基于Transformer的生成器更好地重建视频；3) 采用增量训练策略逐步更新模型组件，缓解GAN训练不稳定性。

Result: 实验结果表明，该方法在多个基准数据集上取得了优越的性能表现。

Conclusion: 提出的语义引导方法和增量训练策略有效解决了现有无监督视频摘要方法的局限性，在多个数据集上验证了方法的有效性。

Abstract: Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.

</details>


### [32] [Towards Bound Consistency for the No-Overlap Constraint Using MDDs](https://arxiv.org/abs/2601.14784)
*Amaury Guichard,Laurent Michel,Hélène Verhaeghe,Pierre Schaus*

Main category: cs.AI

TL;DR: 本文提出了首个实现边界一致性（bound-consistent）的非重叠约束算法，通过构建有限宽度的MDD（多值决策图）在多项式时间内收紧作业时间窗口，相比现有方法能更有效地减少搜索树节点数。


<details>
  <summary>Details</summary>
Motivation: 非重叠约束的边界一致性已知是NP完全问题，现有多项式时间收紧技术（如边查找、非首非尾推理、能量推理）仍有改进空间。需要开发更强大的过滤算法来提升约束求解效率。

Method: 基于Ciré和van Hoeve定义的非重叠MDD，提取作业时间窗口边界来收紧起止时间。为控制复杂度，限制MDD宽度为阈值，创建松弛MDD用于边界一致性过滤。

Result: 实验表明，即使使用宽度阈值，新过滤算法相比Ciré和van Hoeve的优先检测算法能更显著减少搜索树节点数。新方法与经典传播方法互补，在多个实例上同时减少了节点数和求解时间。

Conclusion: 首次实现了非重叠约束的边界一致性算法，通过有限宽度MDD在多项式时间内完成过滤，显著提升了约束求解效率，为时间窗口调度问题提供了更强大的求解工具。

Abstract: Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \mid r_j, d_j, \bar{d}_j \mid \sum E_j + \sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.

</details>


### [33] [CI4A: Semantic Component Interfaces for Agents Empowering Web Automation](https://arxiv.org/abs/2601.14790)
*Zhi Qiu,Jiazheng Sun,Chenxiao Xia,Jun Zheng,Xin Peng*

Main category: cs.AI

TL;DR: CI4A为智能体设计了专门的UI组件交互接口，将复杂UI组件抽象为统一工具原语，在Ant Design中实现23类组件，显著提升Web任务成功率至86.3%


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在高层语义规划表现出色，但在细粒度、低层级的Web组件操作方面能力有限。与其让智能体适应人类为中心的界面，不如为智能体专门设计优化的交互接口。

Method: 提出CI4A（Component Interface for Agent）语义封装机制，将UI组件的复杂交互逻辑抽象为智能体可访问的统一工具原语。在Ant Design工业级前端框架中实现，覆盖23类常用UI组件。开发混合智能体，其动作空间根据页面状态动态更新，灵活调用可用的CI4A工具。

Result: 基于CI4A集成的Ant Design重构升级WebArena基准测试，实验结果显示CI4A智能体显著优于现有方法，达到86.3%的新SOTA任务成功率，同时执行效率大幅提升。

Conclusion: 为智能体专门设计优化的组件接口（CI4A）比让智能体适应人类界面更有效，能够显著提升Web交互任务的成功率和效率，为智能体与Web界面的交互提供了新的解决方案。

Abstract: While Large Language Models demonstrate remarkable proficiency in high-level semantic planning, they remain limited in handling fine-grained, low-level web component manipulations. To address this limitation, extensive research has focused on enhancing model grounding capabilities through techniques such as Reinforcement Learning. However, rather than compelling agents to adapt to human-centric interfaces, we propose constructing interaction interfaces specifically optimized for agents. This paper introduces Component Interface for Agent (CI4A), a semantic encapsulation mechanism that abstracts the complex interaction logic of UI components into a set of unified tool primitives accessible to agents. We implemented CI4A within Ant Design, an industrial-grade front-end framework, covering 23 categories of commonly used UI components. Furthermore, we developed a hybrid agent featuring an action space that dynamically updates according to the page state, enabling flexible invocation of available CI4A tools. Leveraging the CI4A-integrated Ant Design, we refactored and upgraded the WebArena benchmark to evaluate existing SoTA methods. Experimental results demonstrate that the CI4A-based agent significantly outperforms existing approaches, achieving a new SoTA task success rate of 86.3%, alongside substantial improvements in execution efficiency.

</details>


### [34] [Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies](https://arxiv.org/abs/2601.14827)
*Ben Schaper,Maxime Di Folco,Bernhard Kainz,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.AI

TL;DR: 该研究评估了视觉语言模型在胸部X光分类中的抽象错误，提出使用医学分类学和分层指标来量化严重错误，并通过风险约束阈值和分类学感知微调来减少严重错误至2%以下。


<details>
  <summary>Details</summary>
Motivation: 标准平面指标无法区分临床轻微错误和严重错误，需要量化视觉语言模型在医学图像分类中的抽象错误，以实现更安全、更具临床意义的部署。

Method: 使用分层指标评估多个先进视觉语言模型，引入灾难性抽象错误概念，并提出风险约束阈值和基于径向嵌入的分类学感知微调方法。

Result: 尽管视觉语言模型在平面指标上表现良好，但与临床分类学存在显著不对齐；提出的方法能将严重抽象错误减少到2%以下，同时保持竞争力。

Conclusion: 分层评估和表示层对齐对于视觉语言模型的安全和临床意义部署至关重要，提出的方法能有效减少严重错误。

Abstract: Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.

</details>


### [35] [Implementing Knowledge Representation and Reasoning with Object Oriented Design](https://arxiv.org/abs/2601.14840)
*Abdelrhman Bassiouny,Tom Schierenbeck,Sorin Arion,Benjamin Alt,Naren Vasantakumaar,Giang Nguyen,Michael Beetz*

Main category: cs.AI

TL;DR: KRROOD是一个将知识表示与推理系统集成到面向对象编程中的框架，通过将知识作为一等编程抽象来解决现有KR&R框架与OOP代码集成困难的问题。


<details>
  <summary>Details</summary>
Motivation: 现代软件工程以面向对象编程为标准，但现有的知识表示与推理框架通常依赖外部本体和专门语言，难以与命令式代码集成，存在集成鸿沟。

Method: KRROOD将知识作为一等编程抽象，使用原生类结构，在逻辑编程和面向对象编程范式之间建立桥梁，通过本地类结构实现知识表示。

Result: 在OWL2Bench基准测试和人机任务学习场景中的实验结果显示，KRROOD在保持强大性能的同时，支持现实世界自主系统所需的表达性推理能力。

Conclusion: KRROOD成功弥合了知识表示与推理系统与现代软件工程之间的集成鸿沟，为开发需要复杂推理能力的现实世界自主系统提供了有效解决方案。

Abstract: This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.

</details>


### [36] [To Neuro-Symbolic Classification and Beyond by Compiling Description Logic Ontologies to Probabilistic Circuits](https://arxiv.org/abs/2601.14894)
*Nicolas Lazzari,Valentina Presutti,Antonio Vergari*

Main category: cs.AI

TL;DR: 将描述逻辑本体编译为可微电路，实现神经符号方法，确保预测与本体知识一致，提高分类器可靠性


<details>
  <summary>Details</summary>
Motivation: 现有神经符号方法缺乏对描述逻辑本体的原生支持，需要开发能可靠输出与领域知识一致预测的方法

Method: 将描述逻辑本体编码为电路（可微计算图），支持：(i)生成捕获本体语义的合成数据集；(ii)在GPU上高效执行演绎推理；(iii)实现预测与本体知识一致的神经符号模型

Result: 合成数据集能捕获本体语义且对机器学习分类器具有挑战性；电路推理比现有推理器快3个数量级；神经符号分类器比神经网络基线更可靠地产生一致预测，性能相当或更优

Conclusion: 通过将描述逻辑本体编译为电路，实现了深度学习与知识表示领域的更紧密集成，单个电路表示可解决多个与真实应用相关的挑战性任务

Abstract: Background: Neuro-symbolic methods enhance the reliability of neural network classifiers through logical constraints, but they lack native support for ontologies.
  Objectives: We aim to develop a neuro-symbolic method that reliably outputs predictions consistent with a Description Logic ontology that formalizes domain-specific knowledge.
  Methods: We encode a Description Logic ontology as a circuit, a feed-forward differentiable computational graph that supports tractable execution of queries and transformations. We show that the circuit can be used to (i) generate synthetic datasets that capture the semantics of the ontology; (ii) efficiently perform deductive reasoning on a GPU; (iii) implement neuro-symbolic models whose predictions are approximately or provably consistent with the knowledge defined in the ontology.
  Results We show that the synthetic dataset generated using the circuit qualitatively captures the semantics of the ontology while being challenging for Machine Learning classifiers, including neural networks. Moreover, we show that compiling the ontology into a circuit is a promising approach for scalable deductive reasoning, with runtimes up to three orders of magnitude faster than available reasoners. Finally, we show that our neuro-symbolic classifiers reliably produce consistent predictions when compared to neural network baselines, maintaining competitive performances or even outperforming them.
  Conclusions By compiling Description Logic ontologies into circuits, we obtain a tighter integration between the Deep Learning and Knowledge Representation fields. We show that a single circuit representation can be used to tackle different challenging tasks closely related to real-world applications.

</details>


### [37] [Just aware enough: Evaluating awareness across artificial systems](https://arxiv.org/abs/2601.14901)
*Nadine Meertens,Suet Lee,Ophelia Deroy*

Main category: cs.AI

TL;DR: 该论文提出用"意识"（awareness）替代"意识"（consciousness）作为评估AI系统的新框架，并开发了一个实用方法来评估不同系统的意识能力。


<details>
  <summary>Details</summary>
Motivation: 当前关于AI意识和道德地位的讨论缺乏共识和可操作的评价方法，需要更实用、方法上更易处理的替代方案。

Method: 提出一个评估意识的实用方法，将意识定义为系统处理、存储和使用信息以实现目标导向行动的能力。该方法具有四个核心特征：领域敏感性、可扩展性、多维度和任务性能预测能力。

Result: 开发了一个结构化方法来评估和比较不同架构、规模和操作领域的人工系统的意识特征，支持系统间的能力比较。

Conclusion: 通过将焦点从人工意识转向"足够意识"，该方法旨在促进原则性评估、支持设计和监督，并实现更建设性的科学和公共讨论。

Abstract: Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.

</details>


### [38] [Multi-Behavior Sequential Modeling with Transition-Aware Graph Attention Network for E-Commerce Recommendation](https://arxiv.org/abs/2601.14955)
*Hanqi Jin,Gaoming Yang,Zhangming Chan,Yapeng Yuan,Longbin Li,Fei Sun,Yeqiu Yang,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: TGA是一种线性复杂度的多行为转换建模方法，通过构建结构化稀疏图来识别信息转换，相比传统Transformer方法显著降低计算成本，已在工业环境中部署并提升业务指标。


<details>
  <summary>Details</summary>
Motivation: 电商平台用户行为多样（点击、收藏、加购、购买等），行为转换能揭示用户偏好演变。现有基于Transformer的多行为序列建模方法虽然有效，但计算复杂度高（多项式时间），难以应用于大规模工业系统中的长用户序列。

Method: 提出Transition-Aware Graph Attention Network (TGA)，一种线性复杂度方法。不同于传统Transformer平等对待所有行为对，TGA从三个角度构建结构化稀疏图识别信息转换：(a) 商品级转换，(b) 品类级转换，(c) 邻居级转换。基于该图，采用转换感知的图注意力机制，联合建模用户-商品交互和行为转换类型。

Result: 实验表明TGA优于所有最先进模型，同时显著降低计算成本。TGA已在大规模工业生产环境中部署，在关键业务指标上带来显著提升。

Conclusion: TGA通过构建结构化稀疏图和转换感知注意力机制，在保持计算效率的同时更准确地捕捉序列模式，解决了多行为序列建模中的计算效率问题，具有实际工业应用价值。

Abstract: User interactions on e-commerce platforms are inherently diverse, involving behaviors such as clicking, favoriting, adding to cart, and purchasing. The transitions between these behaviors offer valuable insights into user-item interactions, serving as a key signal for understanding evolving preferences. Consequently, there is growing interest in leveraging multi-behavior data to better capture user intent. Recent studies have explored sequential modeling of multi-behavior data, many relying on transformer-based architectures with polynomial time complexity. While effective, these approaches often incur high computational costs, limiting their applicability in large-scale industrial systems with long user sequences. To address this challenge, we propose the Transition-Aware Graph Attention Network (TGA), a linear-complexity approach for modeling multi-behavior transitions. Unlike traditional transformers that treat all behavior pairs equally, TGA constructs a structured sparse graph by identifying informative transitions from three perspectives: (a) item-level transitions, (b) category-level transitions, and (c) neighbor-level transitions. Built upon the structured graph, TGA employs a transition-aware graph Attention mechanism that jointly models user-item interactions and behavior transition types, enabling more accurate capture of sequential patterns while maintaining computational efficiency. Experiments show that TGA outperforms all state-of-the-art models while significantly reducing computational cost. Notably, TGA has been deployed in a large-scale industrial production environment, where it leads to impressive improvements in key business metrics.

</details>


### [39] [Emergent, not Immanent: A Baradian Reading of Explainable AI](https://arxiv.org/abs/2601.15029)
*Fabio Morreale,Joan Serrà,Yuki Mistufuji*

Main category: cs.AI

TL;DR: 论文批判当前可解释AI(XAI)将解释视为技术问题，提出基于Barad代理实在论的新本体认识论，认为解释是AI模型与人类、情境、解释装置纠缠中涌现的物质-话语表演。


<details>
  <summary>Details</summary>
Motivation: 当前XAI领域存在未经验证的本体认识论假设：将意义视为模型内在固有，解释者被置于系统之外，并假设可通过计算技术恢复因果结构。这些假设限制了XAI的发展和应用。

Method: 采用Barad的代理实在论框架，重新审视XAI方法的本体认识论基础。通过代理实在论视角全面解读现有XAI方法，揭示其假设和局限，并构建支持涌现性解释的XAI界面设计方向。

Result: 提出了基于代理实在论的XAI新框架，将解释视为物质-话语表演，强调解释在AI模型、人类、情境和解释装置的纠缠中涌现。开发了支持涌现解释的XAI界面设计原则，并以文本到音乐界面作为案例研究。

Conclusion: XAI应超越单纯的技术解释问题，采用关系性和涌现性的本体认识论视角。解释是动态的、情境化的表演过程，而非模型内在属性的揭示。这一框架为XAI提供了更丰富的伦理维度和设计方向。

Abstract: Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.

</details>


### [40] [The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems](https://arxiv.org/abs/2601.15059)
*Oleg Romanchuk,Roman Bondar*

Main category: cs.AI

TL;DR: 现代CI/CD管道中，AI生成代码的审批流程存在结构性缺陷：审批者有权限但缺乏理解代码的知识能力，导致责任真空状态。


<details>
  <summary>Details</summary>
Motivation: 研究现代CI/CD管道中集成AI生成代码时出现的责任归属问题。传统审批流程虽然形式正确，但审批者缺乏理解AI生成代码的知识能力，导致决策与责任脱节。

Method: 通过理论分析定义"责任真空"概念，识别在并行AI生成、CI验证和个性化人工审批的部署场景下的扩展极限。分析CI放大动态，展示自动化验证覆盖率增加如何加剧认知卸载。

Result: 发现当决策生成吞吐量超过人类验证能力时，验证不再作为决策标准，被基于代理信号的仪式化审批取代。个性化责任在规模化AI部署中结构上无法实现。

Conclusion: 除非组织重新设计决策边界或将责任从个体决策转向批量或系统级所有权，否则责任真空将成为规模化AI部署中不可见但持续存在的故障模式。

Abstract: Modern CI/CD pipelines integrating agent-generated code exhibit a structural failure in responsibility attribution. Decisions are executed through formally correct approval processes, yet no entity possesses both the authority to approve those decisions and the epistemic capacity to meaningfully understand their basis.
  We define this condition as responsibility vacuum: a state in which decisions occur, but responsibility cannot be attributed because authority and verification capacity do not coincide. We show that this is not a process deviation or technical defect, but a structural property of deployments where decision generation throughput exceeds bounded human verification capacity.
  We identify a scaling limit under standard deployment assumptions, including parallel agent generation, CI-based validation, and individualized human approval gates. Beyond a throughput threshold, verification ceases to function as a decision criterion and is replaced by ritualized approval based on proxy signals. Personalized responsibility becomes structurally unattainable in this regime.
  We further characterize a CI amplification dynamic, whereby increasing automated validation coverage raises proxy signal density without restoring human capacity. Under fixed time and attention constraints, this accelerates cognitive offloading in the broad sense and widens the gap between formal approval and epistemic understanding. Additional automation therefore amplifies, rather than mitigates, the responsibility vacuum.
  We conclude that unless organizations explicitly redesign decision boundaries or reassign responsibility away from individual decisions toward batch- or system-level ownership, responsibility vacuum remains an invisible but persistent failure mode in scaled agent deployments.

</details>


### [41] [The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution](https://arxiv.org/abs/2601.15075)
*Chen Qian,Peng Wang,Dongrui Liu,Junyao Yang,Dadi Guo,Ling Tang,Jilin Mei,Qihan Ren,Shuai Shao,Yong Liu,Jie Fu,Jing Shao,Xia Hu*

Main category: cs.AI

TL;DR: 提出一个用于解释LLM智能体行为的通用归因框架，通过分层分析识别驱动智能体行动的内部因素，而非仅关注失败归因。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体在客服、网页导航、软件工程等实际应用中广泛部署，理解智能体为何采取特定行动对于问责和治理变得越来越重要。现有研究主要关注失败归因，仅定位不成功轨迹中的显式错误，这不足以解释智能体行为背后的推理过程。

Method: 提出分层框架：在组件层面使用时间似然动态识别关键交互步骤；在句子层面使用基于扰动的分析来精确定位具体的文本证据。该框架旨在识别驱动智能体行动的内部因素，无论任务结果如何。

Result: 实验验证表明，该框架能可靠地识别出智能体行为背后的关键历史事件和句子，涵盖标准工具使用和内存诱导偏差等微妙可靠性风险场景。

Conclusion: 该框架为实现更安全、更可问责的智能体系统迈出了关键一步，提供了超越传统失败归因的通用智能体行为解释方法。

Abstract: Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \textit{failure attribution} to localize explicit errors in unsuccessful trajectories, which is insufficient for explaining the reasoning behind agent behaviors. To bridge this gap, we propose a novel framework for \textbf{general agentic attribution}, designed to identify the internal factors driving agent actions regardless of the task outcome. Our framework operates hierarchically to manage the complexity of agent interactions. Specifically, at the \textit{component level}, we employ temporal likelihood dynamics to identify critical interaction steps; then at the \textit{sentence level}, we refine this localization using perturbation-based analysis to isolate the specific textual evidence. We validate our framework across a diverse suite of agentic scenarios, including standard tool use and subtle reliability risks like memory-induced bias. Experimental results demonstrate that the proposed framework reliably pinpoints pivotal historical events and sentences behind the agent behavior, offering a critical step toward safer and more accountable agentic systems.

</details>


### [42] [Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories](https://arxiv.org/abs/2601.15120)
*Qian Xiong,Yuekai Huang,Yujia Zheng,Tianhao Li,Ziyou Jiang,Zhiyuan Chang,Zhaoyang Li,Huanxiang Feng,Mingyang Li*

Main category: cs.AI

TL;DR: RISE：一种"真实到虚拟"方法，通过基于已验证工具原语合成虚拟轨迹和生成多样化负样本，来减轻LLM工具使用中的意图偏差问题。


<details>
  <summary>Details</summary>
Motivation: LLM工具使用代理在现实应用中常出现意图偏差问题，现有方法依赖昂贵的人工用户请求或存在分布偏移，且缺乏针对意图偏差场景的负样本，阻碍了可靠的评估和性能改进。

Method: RISE方法基于已验证的工具原语，合成虚拟轨迹，通过对关键参数进行突变生成多样化负样本，然后通过两阶段训练对骨干LLM进行微调以实现意图对齐。

Result: RISE在8个指标上取得良好结果，在任务完成率上平均提升35.28%，在意图对齐上提升23.27%，优于现有最佳基线方法1.20-42.09%和1.17-54.93%。

Conclusion: RISE通过"真实到虚拟"方法有效减轻意图偏差，为LLM工具使用代理的可靠评估和性能改进提供了有效解决方案。

Abstract: LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of "intent deviation" severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to reliance on hand-crafted user requests, while the latter suffers from distribution shift from the real tools in the wild. Additionally, both methods lack negative samples tailored to intent deviation scenarios, hindering effective guidance on preference learning. We introduce RISE, a "Real-to-Virtual" method designed to mitigate intent deviation. Anchoring on verified tool primitives, RISE synthesizes virtual trajectories and generates diverse negative samples through mutation on critical parameters. With synthetic data, RISE fine-tunes backbone LLMs via the two-stage training for intent alignment. Evaluation results demonstrate that data synthesized by RISE achieve promising results in eight metrics covering user requires, execution trajectories and agent responses. Integrating with training, RISE achieves an average 35.28% improvement in Acctask (task completion) and 23.27% in Accintent (intent alignment), outperforming SOTA baselines by 1.20--42.09% and 1.17--54.93% respectively.

</details>


### [43] [The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks](https://arxiv.org/abs/2601.15130)
*Ivan Carrera,Daniel Maldonado-Ruiz*

Main category: cs.AI

TL;DR: 论文提出"可信性陷阱"概念，指出人们过度使用昂贵的概率性AI模型处理简单的确定性任务，造成资源浪费，并引入工具选择工程和决策矩阵框架来指导何时使用生成式AI。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及，用户便利性优先于计算效率，导致人们过度依赖昂贵的概率性AI引擎处理简单的确定性任务（如OCR、基本验证），造成显著的资源浪费和效率损失。

Method: 通过OCR和事实核查的微基准测试和案例研究量化"效率税"，引入工具选择工程和确定性-概率性决策矩阵框架，帮助开发者决定何时使用生成式AI以及何时避免使用。

Result: 研究发现存在约6.5倍的延迟惩罚，揭示了算法奉承的风险，证明了过度使用生成式AI处理简单确定性任务会造成显著的效率损失。

Conclusion: 真正的数字素养不仅在于知道如何使用生成式AI，更在于知道何时不使用它。需要课程转变，强调在适当场景选择适当工具的重要性。

Abstract: The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the "Plausibility Trap": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the "efficiency tax"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.

</details>


### [44] [Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding](https://arxiv.org/abs/2601.15131)
*Ayan Maity,Sudeshna Sarkar*

Main category: cs.AI

TL;DR: 提出一种结合网络嵌入和强化学习的有限时间车辆路径规划方法，能提高客户服务率并减少求解时间。


<details>
  <summary>Details</summary>
Motivation: 在有限时间范围内最大化服务客户数量的车辆路径问题具有实际应用价值，现有方法在服务率和求解效率方面有待改进。

Method: 设计包含局部节点嵌入和上下文感知全局图表示的网络嵌入模块，将剩余时间纳入嵌入过程，结合策略梯度强化学习框架构建马尔可夫决策过程。

Result: 在真实世界和合成欧几里得网络上验证，相比现有方法获得更高的客户服务率，且求解时间显著降低。

Conclusion: 提出的有限时间车辆路径规划方法有效提升了服务效率和求解速度，为实际应用提供了实用解决方案。

Abstract: In this paper, we study the vehicle routing problem with a finite time horizon. In this routing problem, the objective is to maximize the number of customer requests served within a finite time horizon. We present a novel routing network embedding module which creates local node embedding vectors and a context-aware global graph representation. The proposed Markov decision process for the vehicle routing problem incorporates the node features, the network adjacency matrix and the edge features as components of the state space. We incorporate the remaining finite time horizon into the network embedding module to provide a proper routing context to the embedding module. We integrate our embedding module with a policy gradient-based deep Reinforcement Learning framework to solve the vehicle routing problem with finite time horizon. We trained and validated our proposed routing method on real-world routing networks, as well as synthetically generated Euclidean networks. Our experimental results show that our method achieves a higher customer service rate than the existing routing methods. Additionally, the solution time of our method is significantly lower than that of the existing methods.

</details>


### [45] [How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework](https://arxiv.org/abs/2601.15153)
*Choro Ulan uulu,Mikhail Kulyabin,Iris Fuhrmann,Jan Joosten,Nuno Miguel Martins Pacheco,Filippos Petridis,Rebecca Johnson,Jan Bosch,Helena Holmström Olsson*

Main category: cs.AI

TL;DR: 提出一个软件工程框架，通过增强LLM来捕获人类领域知识，构建能够自主生成仿真数据可视化的AI代理系统，使非专家也能达到专家级效果。


<details>
  <summary>Details</summary>
Motivation: 关键领域知识通常集中在少数专家手中，造成组织扩展和决策瓶颈。非专家难以创建有效可视化，导致洞察力不足并占用专家时间。

Method: 提出软件工程框架，通过增强LLM构建AI代理系统：包括请求分类器、用于代码生成的RAG系统、编码的专家规则和可视化设计原则，实现自主、反应式、主动式和社交行为。

Result: 在五个跨工程领域的场景中，12名评估者显示输出质量提升206%，代理在所有案例中达到专家级评分，而基线表现较差，同时保持更优的代码质量和更低方差。

Conclusion: 贡献包括：自动化的基于代理的可视化生成系统，以及经过验证的系统化捕获人类领域知识、将隐性专家知识编码到AI代理中的框架，证明非专家能在专业领域达到专家级成果。

Abstract: Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software engineering framework to capture human domain knowledge for engineering AI agents in simulation data visualization by augmenting a Large Language Model (LLM) with a request classifier, Retrieval-Augmented Generation (RAG) system for code generation, codified expert rules, and visualization design principles unified in an agent demonstrating autonomous, reactive, proactive, and social behavior. Evaluation across five scenarios spanning multiple engineering domains with 12 evaluators demonstrates 206% improvement in output quality, with our agent achieving expert-level ratings in all cases versus baseline's poor performance, while maintaining superior code quality with lower variance. Our contributions are: an automated agent-based system for visualization generation and a validated framework for systematically capturing human domain knowledge and codifying tacit expert knowledge into AI agents, demonstrating that non-experts can achieve expert-level outcomes in specialized domains.

</details>


### [46] [Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning](https://arxiv.org/abs/2601.15160)
*Yuval Kansal,Niraj K. Jha*

Main category: cs.AI

TL;DR: 论文提出了一种基于知识图谱路径奖励的强化学习后训练方法，通过从基础公理事实出发进行自底向上学习，使模型能够组合中间推理步骤来解决复杂的多跳推理任务，在医学领域取得了优于GPT-5.2等前沿系统的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学和编程等结构化推理领域已达到接近专家的水平，但在专业科学领域进行组合式多跳推理的能力仍然有限。需要一种方法使模型能够基于领域公理事实进行组合推理，解决未见过的复杂任务。

Method: 提出了一种后训练流程，结合监督微调和强化学习，其中知识图谱作为隐式奖励模型。通过从知识图谱路径推导新的奖励信号，提供可验证、可扩展且基于事实的监督，鼓励模型在强化学习过程中组合中间公理而不仅仅是优化最终答案。

Result: 在医学领域验证该方法，训练一个140亿参数的模型在短跳推理路径（1-3跳）上，并在复杂多跳查询（4-5跳）上进行零样本泛化评估。实验表明，路径推导的奖励作为"组合桥梁"，使模型在最具挑战性的推理任务上显著优于更大的模型和GPT-5.2、Gemini 3 Pro等前沿系统。此外，该方法在对抗性扰动和选项洗牌压力测试中表现出鲁棒性。

Conclusion: 这项研究表明，将推理过程基于结构化知识是实现智能推理的可扩展且高效的途径，通过自底向上的学习范式，模型能够从基础事实组合出解决复杂任务的推理路径。

Abstract: Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a "compositional bridge", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.

</details>


### [47] [BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries](https://arxiv.org/abs/2601.15197)
*Shijie Lian,Bin Yu,Xiaopeng Lin,Laurence T. Yang,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Cong Huang,Kai Chen*

Main category: cs.AI

TL;DR: 论文提出BayesianVLA框架，通过贝叶斯分解解决VLA模型中的信息坍缩问题，强制模型遵循语言指令，显著提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作中面临泛化难题，特别是在新指令或复杂多任务场景中。研究发现训练数据存在偏差：目标驱动的数据收集导致语言指令仅从视觉观察即可高度预测，造成指令与动作之间的条件互信息消失（信息坍缩），使模型退化为忽略语言约束的纯视觉策略。

Method: 提出BayesianVLA框架：引入可学习的潜在动作查询，构建双分支架构分别估计视觉先验p(a|v)和语言条件后验π(a|v,ℓ)。通过最大化动作与指令之间的条件点互信息来优化策略，惩罚视觉捷径，奖励能明确解释语言命令的动作。

Result: 在不需新数据的情况下，BayesianVLA显著提升泛化性能。在SimplerEnv和RoboCasa上的广泛实验显示明显改进，特别是在具有挑战性的OOD SimplerEnv基准上获得11.3%的提升。

Conclusion: BayesianVLA通过贝叶斯分解有效解决VLA模型中的信息坍缩问题，强制模型遵循语言指令，显著提升在分布外场景中的鲁棒性和泛化能力。

Abstract: Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \mid v)$ and a language-conditioned posterior $π(a \mid v, \ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [48] [GNN-based Path-aware multi-view Circuit Learning for Technology Mapping](https://arxiv.org/abs/2601.14286)
*Wentao Jiang,Jingxin Wang,Zhang Hu,Zhengyuan Shi,Chengyu Ma,Qiang Xu,Weikang Qian,Zhufei Chu*

Main category: cs.ET

TL;DR: GPA是一种基于图神经网络的多视角电路学习框架，通过融合三种电路结构视图来精确预测延迟，相比传统方法在19个EPFL基准测试中平均延迟降低19.9%、2.1%和4.1%。


<details>
  <summary>Details</summary>
Motivation: 传统技术映射方法依赖抽象的技术无关延迟模型，存在系统性不准确问题，无法捕捉实际映射后电路的精细时序行为。

Method: 提出GPA框架，基于图神经网络融合三种互补的电路结构视图：AIG功能编码、映射后技术视图和关键时序路径视图，专门在工业级映射后网表的关键路径上训练，学习精确的延迟预测。

Result: 在19个EPFL组合基准测试中，GPA相比传统启发式方法（techmap、MCH）和先前最先进的基于机器学习的方法SLAP，分别实现了19.9%、2.1%和4.1%的平均延迟降低，且不牺牲面积效率。

Conclusion: GPA通过数据驱动的多视图电路学习，显著提升了技术映射中的延迟预测精度，为更智能的映射决策提供了有效解决方案。

Abstract: Traditional technology mapping suffers from systemic inaccuracies in delay estimation due to its reliance on abstract, technology-agnostic delay models that fail to capture the nuanced timing behavior behavior of real post-mapping circuits. To address this fundamental limitation, we introduce GPA(graph neural network (GNN)-based Path-Aware multi-view circuit learning), a novel GNN framework that learns precise, data-driven delay predictions by synergistically fusing three complementary views of circuit structure: And-Inverter Graphs (AIGs)-based functional encoding, post-mapping technology emphasizes critical timing paths. Trained exclusively on real cell delays extracted from critical paths of industrial-grade post-mapping netlists, GPA learns to classify cut delays with unprecedented accuracy, directly informing smarter mapping decisions. Evaluated on the 19 EPFL combinational benchmarks, GPA achieves 19.9%, 2.1% and 4.1% average delay reduction over the conventional heuristics methods (techmap, MCH) and the prior state-of-the-art ML-based approach SLAP, respectively-without compromising area efficiency.

</details>


### [49] [Analog-to-Stochastic Converter Using Magnetic Tunnel Junction Devices for Vision Chips](https://arxiv.org/abs/2601.14640)
*Naoya Onizawa,Daisaku Katagiri,Warren J. Gross,Takahiro Hanyu*

Main category: cs.ET

TL;DR: 提出使用磁性隧道结(MTJ)器件实现模拟到随机信号的一步转换，用于基于随机计算的视觉芯片，以降低传统两步转换的功耗和面积开销。


<details>
  <summary>Details</summary>
Motivation: 随机计算已被用于面积高效的硬件实现（如LDPC解码器和图像处理器），但传统的模拟到随机信号转换需要功耗和面积较大的两步转换器（模拟到数字再到随机）。需要一种一步转换方案来降低信号转换开销。

Method: 利用MTJ器件固有的概率性开关行为（在两个电阻状态之间切换），实现模拟信号直接转换为随机信号。通过理论分析转换特性，考虑MTJ电阻变异性并进行补偿，在90nm CMOS和100nm MTJ技术中设计转换器，并使用NS-SPICE仿真器验证。

Result: 成功设计并验证了基于MTJ的模拟到随机转换器，能够直接、面积高效地将模拟信号转换为随机信号，克服了传统两步转换的功耗和面积问题。

Conclusion: MTJ器件的概率性开关特性为实现一步模拟到随机转换提供了有效途径，为基于随机计算的视觉芯片提供了低开销的信号转换解决方案。

Abstract: This paper introduces an analog-to-stochastic converter using a magnetic tunnel junction (MTJ) device for vision chips based on stochastic computation. Stochastic computation has been recently exploited for area-efficient hardware implementation, such as low-density parity-check (LDPC) decoders and image processors. However, power-and-area hungry two-step (analog-to-digital and digital-to-stochastic) converters are required for the analog to stochastic signal conversion. To realize a one-step conversion, an MTJ device is used as it inherently exhibits a probabilistic switching behavior between two resistance states. Exploiting the device-based probabilistic behavior, analog signals can be directly and area-efficiently converted to stochastic signals to mitigate the signal-conversion overhead. The analog-to-stochastic signal conversion is theoretically described and the conversion characteristic is evaluated using device and circuit parameters. In addition, the resistance variability of the MTJ device is considered in order to compensate the variability effect on the signal conversion. Based on the theoretical analysis, the analog-to-stochastic converter is designed in 90nm CMOS and 100nm MTJ technologies and is verified using a SPICE simulator (NS-SPICE) that handles both transistors and MTJ devices.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [50] [A Unified Framework for Scalable and Robust Paper Assignment](https://arxiv.org/abs/2601.14402)
*Michael Cui,Chenxin Dai,Yixuan Even Xu,Fei Fang*

Main category: cs.SI

TL;DR: RAMP是一个用于大规模同行评审的论文分配框架，通过线性化扰动最大化目标和属性感知采样，在保证运行效率的同时平衡分配质量、多样性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有算法要么无法同时满足最大化评审专家专业性、促进多样性和增强对策略操纵的鲁棒性等多个目标，要么在大型会议规模下扩展性差。

Method: 提出RAMP框架：1) 使用线性化扰动最大化目标函数和软约束来灵活平衡分配质量、多样性和鲁棒性；2) 引入属性感知采样程序将分数解转换为整数分配，提高最终分配的多样性和鲁棒性。

Result: 在包含超过20,000篇论文和20,000名评审的数据集上，RAMP在20分钟内完成运行，证明了其在实际部署中的适用性。

Conclusion: RAMP为大规模同行评审提供了一个统一的框架，能够高效地平衡多个竞争性目标，解决了现有方法在可扩展性和多目标优化方面的局限性。

Abstract: Assigning papers to reviewers is a central challenge in the peer-review process of large academic conferences. Program chairs must balance competing objectives, including maximizing reviewer expertise, promoting diversity, and enhancing robustness to strategic manipulation, but it is challenging to do so at the modern conference scale.
  Existing algorithmic paper assignment approaches either fail to address all of these goals simultaneously or suffer from poor scalability. To address the limitation, we propose Robust Assignment via Marginal Perturbation (RAMP), a unified framework for large-scale peer review. Our approach formulates a linearized perturbed-maximization objective with soft constraints that flexibly balance assignment quality, diversity, and robustness while maintaining runtime efficiency. We further introduce an attribute-aware sampling procedure that converts fractional solutions into integral assignments and improves the diversity and robustness of the final assignment. On datasets with over 20,000 papers and 20,000 reviewers, RAMP runs in under 20 minutes, demonstrating its suitability for real-world deployment.

</details>


### [51] [Maximum Edge-based Quasi-Clique: Novel Iterative Frameworks](https://arxiv.org/abs/2601.14619)
*Hongbo Xia,Shengxin Liu,Zhaoquan Gu*

Main category: cs.SI

TL;DR: 提出EQC-Pro算法，通过将边基γ-准团问题转化为一系列遗传子问题，显著提升大规模图上的计算效率，比现有方法快4个数量级。


<details>
  <summary>Details</summary>
Motivation: 边基γ-准团模型是图分析中的重要工具，但现有算法（如QClique和FPCE）在大规模图上难以扩展，因为该问题是NP-hard且缺乏遗传性质，限制了剪枝和约简规则的效果。

Method: 提出迭代框架，将原问题转化为一系列遗传子问题，从而支持更有效的剪枝和约简策略；重新设计迭代过程并引入新颖启发式方法提升实际效率。

Result: 在253个大规模真实世界图上进行实验，EQC-Pro算法比现有方法快达4个数量级。

Conclusion: 通过将边基γ-准团问题转化为遗传子问题序列，显著提升了计算效率和可扩展性，为解决大规模图上的准团发现问题提供了有效方案。

Abstract: Extracting cohesive subgraphs from complex networks is a fundamental task in graph analytics and is essential for understanding biological, social, and web graphs. The edge-based $γ$-quasi-clique model offers a flexible alternative by identifying subgraphs whose edge densities exceed a specified threshold $γ$. However, finding the exact maximum edge-based quasi-clique is computationally challenging, as the problem is NP-hard and lacks the hereditary property. These characteristics limit the effectiveness of conventional pruning methods and the development of efficient reduction rules. As a result, existing algorithms, such as QClique and FPCE, struggle to scale to large graphs. In this paper, we revisit the problem and propose a novel iterative framework that reformulates the problem as a sequence of hereditary subproblems, enabling more effective pruning and reduction strategies and improving the worst-case time complexity. Furthermore, we redesign the iterative process and introduce a novel heuristic to further improve practical efficiency. Extensive experiments on 253 large-scale real-world graphs demonstrate that our proposed algorithm EQC-Pro outperforms existing methods by up to four orders of magnitude.

</details>


### [52] [Validating Behavioral Proxies for Disease Risk Monitoring via Large-Scale E-commerce Data](https://arxiv.org/abs/2601.14795)
*Naomi Sasaya,Shigefumi Kishida,Ryo Kikuchi,Akira Tajima*

Main category: cs.SI

TL;DR: 利用电商购买数据中的饮食转变行为作为疾病发作的代理指标，通过跨域验证证明其与临床数据高度相关，可用于大规模疾病监测。


<details>
  <summary>Details</summary>
Motivation: 日常行为的数字痕迹（如电商购买记录）为人口层面的监测提供了可扩展的信号，但其流行病学有效性因与临床结果联系薄弱而不明确。需要验证这些行为信号能否作为传统监测系统的补充。

Method: 提出基于电商购买历史中从常规饮食到治疗性饮食转变的行为代理指标。使用55,645名用户的电商购买数据和独立的保险临床记录，以猫下泌尿道疾病为案例，比较成分层面的风险模式和季节性疾病动态。

Result: 代理指标估计与临床数据高度一致：成分层面风险模式相关性r=0.74，季节性变化相关性r=0.82。两种数据源都一致捕捉到冬季疾病风险升高。仅使用电商数据也能复现已知领域知识，如湿粮消费与较低疾病风险的关联。

Conclusion: 从大规模电商数据中提取的行为信号可以作为传统监测系统的有效、经济补充，并具有监测生活方式相关和慢性疾病的更广泛适用性。

Abstract: Digital traces of everyday behavior, such as e-commerce (EC) purchase logs, provide scalable signals for population-level monitoring, yet their epidemiological validity remains unclear due to weak links to clinical outcomes.
  We propose a behavioral proxy for disease onset based on transitions from regular to therapeutic diets observed in EC purchase histories, and evaluate its validity through large-scale cross-domain analysis. Using EC purchase data (N = 55,645 users) and independent insurance-derived clinical records, we compare ingredient-level risk patterns and seasonal disease dynamics in feline lower urinary tract disease (FLUTD) as a case study.
  The proxy-based estimates show strong agreement with clinical data, with correlations of r = 0.74 for ingredient-level risk patterns and r = 0.82 for seasonal variation. Both data sources consistently capture elevated disease risk during winter months. Moreover, analysis using EC data alone reproduces established domain knowledge, including the association between higher wet food consumption and lower disease risk.
  Our results demonstrate that behavioral signals derived from large-scale EC data can serve as validated, cost-effective complements to traditional surveillance systems, and suggest broader applicability to monitoring lifestyle-related and chronic conditions.

</details>


### [53] [Fractional Diffusion on Graphs: Superposition of Laplacian Semigroups and Memory](https://arxiv.org/abs/2601.14977)
*Nikita Deniskin,Ernesto Estrada*

Main category: cs.SI

TL;DR: 该论文证明图上的次扩散是一种由随机时间变化驱动的记忆过程，可以精确表示为经典热半群的凸叠加，揭示了分数扩散作为跨多个内在时间尺度的普通扩散，并发现了图上的次扩散几何特性。


<details>
  <summary>Details</summary>
Motivation: 虽然时间分数扩散方程常用于建模图上的次扩散，但其结构性和动力学后果尚不清楚。研究者希望揭示次扩散在图上的本质特征和影响。

Method: 通过证明Mittag-Leffler图动力学具有精确的凸、质量保持表示，即经典热半群在重标度时间下的叠加。将时间分数扩散表示为多速率扩散的奇异极限。

Result: 发现次扩散运输是记忆驱动过程，产生长尾等待时间并打破马尔可夫性。揭示了顶点依赖的记忆效应、代数松弛、度依赖等待时间、源与邻居之间的早期不对称性等特征，定义了图上的次扩散几何。

Conclusion: 次扩散运输在图上是记忆驱动的多时间尺度过程，具有独特的几何特性，使粒子能够在局部发现全局最短路径并偏向高连接度区域，为理解复杂网络上的非马尔可夫传输提供了新框架。

Abstract: Subdiffusion on graphs is often modeled by time-fractional diffusion equations, yet its structural and dynamical consequences remain unclear. We show that subdiffusive transport on graphs is a memory-driven process generated by a random time change that compresses operational time, produces long-tailed waiting times, and breaks Markovianity while preserving linearity and mass conservation. We prove that Mittag-Leffler graph dynamics admit an exact convex, mass-preserving representation as a superposition of classical heat semigroups evaluated at rescaled times, revealing fractional diffusion as ordinary diffusion acting across multiple intrinsic time scales. This framework uncovers heterogeneous, vertex-dependent memory effects and induces transport biases absent in classical diffusion, including algebraic relaxation, degree-dependent waiting times, and early-time asymmetries between sources and neighbors. These features define a subdiffusive geometry on graphs enabling particles to locally discover global shortest paths while favoring high-degree regions. Finally, we show that time-fractional diffusion arises as a singular limit of multi-rate diffusion.

</details>


### [54] [Turning Citation Networks Inside Out: Studying Science Using Content-Based Knowledge Graphs from LLM-Derived Taxonomies](https://arxiv.org/abs/2601.15062)
*Seorin Kim,Vincent Holst,Vincent Ginis*

Main category: cs.SI

TL;DR: 提出"由内而外"方法，直接从文本重建科学领域结构，将论文表示为可解释的知识组件三元组（测量方法、数据类型、研究问题类型），构建知识图谱揭示领域架构演变


<details>
  <summary>Details</summary>
Motivation: 科学领域通常通过引用和元数据进行映射，但知识主要通过内容传递。现有方法未能直接从文本内容捕捉领域结构，需要一种基于内容的方法来揭示方法、数据和问题的架构演变

Method: 使用大语言模型诱导领域特定分类法，将每篇论文标记为三元组（测量方法、数据类型、研究问题类型），构建知识图谱，边权重由共享论文数量决定，并利用归一化中介性-连通性比率识别结构桥梁

Result: 应用于617篇代际财富流动性研究，图谱揭示了以回归为基础流动性测量方法为中心的稳定方法论骨干，同时显示组件重组存在显著时间变化，识别出与流行度不成比例的结构桥梁组件和配对

Conclusion: 这种基于内容、分类法驱动的方法补充了基于引用的方法，通过揭示定义领域的方法、数据和问题的演变架构，为科学领域映射提供了新视角

Abstract: Scientific fields are often mapped using citations and metadata, despite knowledge being transmitted primarily through content. We introduce an 'inside-out' approach that reconstructs field structure directly from text by representing each paper as a small set of interpretable knowledge components. Using a large language model to induce domain-specific taxonomies and label papers, each publication is encoded as a triplet of measure, data type, and research-question type. These triplets define a knowledge graph with edges weighted by shared papers. Applied to 617 studies on intergenerational wealth mobility, the graph reveals a stable methodological backbone centered on regression-based mobility measures, alongside substantial temporal variation in component recombination. We further utilize normalized betweenness-to-connectivity ratios to identify components and pairings that act as structural bridges disproportionate to their prevalence. This content-derived, taxonomy-driven mapping complements citation-based approaches by exposing the evolving architecture of methods, data, and questions that define a field.

</details>


### [55] [Computable Structuralism: A Categorical Rewrite Calculus of Mythic Variants](https://arxiv.org/abs/2601.15078)
*Juan J. Segura*

Main category: cs.SI

TL;DR: 提出一个形式化框架，将列维-斯特劳斯的神话结构分析转化为数学表示，通过两寄存器状态模型和自然变换来形式化叙事结构，使神话分析可计算、可比较。


<details>
  <summary>Details</summary>
Motivation: 传统结构主义方法在细读分析中有效，但难以跨传统、媒介和规模进行比较。需要建立形式化框架来桥接结构人类学和文化分析，使叙事分析既保持可解释性又具备计算可比性。

Method: 使用两寄存器状态模型$(X,Y)$抽象日常/社会通道和象征/合法化通道，将神话变体、超级英雄连续性和系列故事建模为类型化重写程序。将经典公式转化为一致性数据：更新自函子间的自然变换$η:U\Rightarrow V$，其中$U$原地更新寄存器，$V$执行交换+反转。通过操作符选择内化上下文，将自然性转化为面向语料库的类型检查。

Result: 应用于80个叙事（20个民间故事、20个宗教神话、20个超级英雄、20个系列），每个编码为$(a,b,x,y)$并带有五值不变式（Key）。74%的叙事在$y$寄存器中明确命名了规范性约束（法律、禁忌、契约、预言），支持了两寄存器抽象。建立了结构人类学与文化分析之间的可测试桥梁。

Conclusion: 该框架成功将结构主义神话分析形式化为数学表示，使故事保持可解释性的同时成为可计算、可比较的对象，为叙事转换提供了可证伪的约束条件，实现了结构人类学与文化分析的理论桥接。

Abstract: Structural approaches to myth and narrative are compelling in close reading but hard to compare across traditions, media, and scale. We propose a formal framework that renders Lévi-Straussian transformation as mathematics while remaining readable as narrative analysis. Variants, superhero continuities, and franchise arcs are modeled as typed rewrite programs on a coupled two-register state $(X,Y)$, abstracting an everyday/social channel and a symbolic/legitimation channel. The canonical formula becomes coherence data: a natural transformation $η:U\Rightarrow V$ between update endofunctors, where $U$ updates each register in place and $V$ performs a swap+inversion. Context is internalized by operator choice, turning naturality into a corpus-facing type check: failures diagnose mis-specified oppositions or illegal transport; successes witness coherent structural models. Order effects are summarized by a five-value invariant (Key). We apply the method to 80 narratives (20 folktales, 20 religious myths, 20 superheroes, 20 franchises), each encoded as $(a,b,x,y)$ with a Key. 59/80 (74\%) explicitly name a normative constraint in $y$ (law, taboo, contract, prophecy), supporting the two-register abstraction. The result is a testable bridge between structural anthropology and cultural analytics: stories remain interpretable yet become transportable objects for computation, comparison, and falsifiable constraints on transformation.

</details>


### [56] [An Agentic Operationalization of DISARM for FIMI Investigation on Social Media](https://arxiv.org/abs/2601.15109)
*Kevin Tseng,Juan Carlos Toledano,Bart De Clerck,Yuliia Dukach,Phil Tinn*

Main category: cs.SI

TL;DR: 提出一个基于多智能体AI的框架，用于在社交媒体上检测和分类外国信息操纵与干扰（FIMI）活动，旨在增强北约国家的集体防御能力。


<details>
  <summary>Details</summary>
Motivation: FIMI和相关混合活动在多个社会维度和信息环境中进行，对威胁特征描述、态势感知和响应协调构成日益严峻的挑战。尽管已有DISARM框架作为标准化元数据和FIMI分析框架，但在社交媒体规模上实施该框架仍面临困难。

Method: 开发了一个多智能体AI管道，其中专门的智能体AI组件协作：(1) 检测候选操纵行为，(2) 以透明方式将这些行为映射到标准DISARM分类体系上。该方法与框架无关，基于智能体实现DISARM的操作化。

Result: 在两个由领域专家标注的真实世界数据集上评估了该方法。结果表明，该方法能有效扩展主要依赖人工和高度解释性的FIMI分析工作。

Conclusion: 该方法为增强在媒体和信息丰富环境中的态势感知和数据互操作性做出了直接贡献，有助于应对AI增强的操纵活动成本降低带来的挑战。

Abstract: The interoperability of data and intelligence across allied partners and their respective end-user groups is considered a foundational enabler to the collective defense capability--both conventional and hybrid--of NATO countries. Foreign Information Manipulation and Interference (FIMI) and related hybrid activities are conducted across various societal dimensions and infospheres, posing an ever greater challenge to the characterization of threats, sustaining situational awareness, and response coordination. Recent advances in AI have further led to the decreasing cost of AI-augmented trolling and interference activities, such as through the generation and amplification of manipulative content. Despite the introduction of the DISARM framework as a standardized metadata and analytical framework for FIMI, operationalizing it at the scale of social media remains a challenge. We propose a framework-agnostic agent-based operationalization of DISARM to investigate FIMI on social media. We develop a multi-agent pipeline in which specialized agentic AI components collaboratively (1) detect candidate manipulative behaviors, and (2) map these behaviors onto standard DISARM taxonomies in a transparent manner. We evaluated the approach on two real-world datasets annotated by domain practitioners. We demonstrate that our approach is effective in scaling the predominantly manual and heavily interpretive work of FIMI analysis, providing a direct contribution to enhancing the situational awareness and data interoperability in the context of operating in media and information-rich settings.

</details>
