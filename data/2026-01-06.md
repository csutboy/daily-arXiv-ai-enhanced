<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 7]
- [econ.EM](#econ.EM) [Total: 6]
- [cs.SI](#cs.SI) [Total: 7]
- [cs.CY](#cs.CY) [Total: 6]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.ET](#cs.ET) [Total: 6]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [Wildfire Evacuation Analysis Using Facebook Data: Evidence from Palisades and Eaton Fires](https://arxiv.org/abs/2601.01052)
*Shangkun Jiang,Ruggiero Lovreglio,Thomas J. Cova,Sangung Park,Susu Xu,Xilei Zhao*

Main category: stat.AP

TL;DR: 利用Facebook高分辨率数据分析2025年Palisades和Eaton火灾的疏散行为，提出包含疏散依从率、出发时间、延迟、OD流、旅行距离和目的地类型等指标的框架，并引入损害-疏散差异指数(DEDI)识别高损害低疏散区域。


<details>
  <summary>Details</summary>
Motivation: 野火频率和强度不断增加，对野地-城市交界区社区构成严重威胁。理解疏散行为对有效的应急规划至关重要，但传统数据难以提供高分辨率的疏散行为分析。

Method: 使用高分辨率Facebook数据分析2025年Palisades和Eaton火灾的疏散行为，提出包含疏散依从率、出发时间、延迟、OD流、旅行距离和目的地类型等指标的框架，并引入损害-疏散差异指数(DEDI)来识别高损害低疏散区域。

Result: 发现时空异质性：靠近火源的居民疏散更早，夜间或延迟的疏散指令导致依从率降低和延迟增加。东、西Altadena的对比模式进一步说明了这种差异。DEDI识别的社区具有更高的社会脆弱性和火灾风险。大多数疏散目的地为居民区，而较长行程集中在酒店和公共设施。

Conclusion: Facebook数据在数据驱动的野火疏散规划中具有巨大潜力，提出的框架和DEDI指标能够帮助识别高风险区域，为应急规划提供科学依据。

Abstract: The growing frequency and intensity of wildfires pose serious threats to communities in wildland-urban interface regions. Understanding evacuation behavior is critical for effective emergency planning. This study analyzes evacuation during the 2025 Palisades and Eaton Fires using high-resolution Facebook data. We propose a comprehensive framework to derive wildfire evacuation-related metrics, including compliance rate, departure timing, delay, origin-destination flows, travel distance, and destination types. A new metric, Damage-Evacuation Disparity Index (DEDI), identifies areas with severe structural damage but low evacuation compliance. Results reveal spatiotemporal heterogeneity: residents closer to the fire evacuated earlier, whereas late or nighttime orders led to lower compliance and longer delays. Contrasting patterns between East and West Altadena further illustrate this disparity. DEDI-identified communities exhibited higher social vulnerability and fire risk. Most evacuations concluded in residential areas, while longer trips concentrated in hotels and public facilities. These findings showcase the Facebook data's potential for data-driven wildfire evacuation planning.

</details>


### [2] [Discussion Network Formation and Evolution in an Online Professional Development Class: Evidence from a MOOC for K-12 Educators](https://arxiv.org/abs/2601.01117)
*Shuhan Ai*

Main category: stat.AP

TL;DR: 研究分析MOOC-Eds中教育工作者同伴讨论网络的形成机制，发现互惠性、传递闭包和分组同质性是最强预测因素，网络结构从广泛分布演变为紧密核心互动。


<details>
  <summary>Details</summary>
Motivation: 随着面向教育工作者的MOOCs（MOOC-Eds）激增，理解教育工作者在在线专业发展环境中如何互动和形成同伴网络变得越来越重要。研究旨在探索在线专业发展背景下同伴支持学习的机制。

Method: 使用横截面和时间指数随机图模型（ERGMs和TERGMs），分析"K-12学校数字学习转型"MOOC-Ed中的同伴讨论网络。研究两个网络子样本：最大连通组件（N=363）和具有三次或以上互动的活跃参与者（N=227）。

Result: 结果显示：1）强互惠性和传递闭包效应（参与者互惠互动的可能性高6-9倍，与共享讨论伙伴形成联系的可能性高2倍以上）；2）分配讨论组同质性是联系形成的最强预测因素；3）区域同质性和连接意愿也显著影响网络结构；4）时间分析显示讨论活动在课程中期达到高峰后急剧下降，网络结构从广泛分布演变为紧密核心互动。

Conclusion: 研究揭示了在线专业发展背景下同伴支持学习的机制，为促进教育工作者在MOOC学习环境中的持续参与提供了设计启示，强调了互惠性、传递性和同质性在网络形成中的关键作用。

Abstract: Understanding how educators interact and form peer networks in online professional development contexts has become increasingly important as MOOCs for educators (MOOC-Eds) proliferate. This study examines peer discussion network formation and evolution in 'The Digital Learning Transition in K-12 Schools', a MOOC-Ed offered to U.S. and international educators in Spring 2013. Using cross-sectional and temporal exponential random graph models (ERGMs and TERGMs), the study analyzes two network subsamples: the largest connected component (N = 363) and active participants with three or more interactions (N = 227). Results reveal strong reciprocity and transitive closure effects across both networks, with participants six to nine times more likely to reciprocate interactions and over twice as likely to form ties with peers sharing common discussion partners. Assigned discussion group homophily emerged as the strongest predictor of tie formation, while regional homophily and willingness to connect also significantly influenced network structure. Temporal analysis showed discussion activity peaked mid-course before declining sharply, with network structure evolving from broadly distributed participation to concentrated interaction among a tightly connected core. These findings illuminate the mechanisms driving peer-supported learning in online professional development contexts and suggest design implications for fostering sustained educator engagement in MOOC-based learning environments.

</details>


### [3] [Order-Constrained Spectral Causality in Multivariate Time Series](https://arxiv.org/abs/2601.01216)
*Alejandro Rodriguez Dominguez*

Main category: stat.AP

TL;DR: 提出基于谱非不变性的算子理论框架，用于多变量时间序列因果分析，通过顺序约束的时间变形定义方向性影响，提供可扩展的因果监测方法。


<details>
  <summary>Details</summary>
Motivation: 现有因果分析方法（如线性格兰杰因果）在非线性、集体依赖等复杂场景下存在局限，需要更一般化的框架来捕捉多变量时间序列中的方向性组织。

Method: 基于顺序约束谱非不变性的算子理论框架，通过允许的时间变形定义方向性影响，使用正交不变谱泛函进行总结，并采用基于移位的随机化方法进行统计推断。

Result: 在线性高斯假设下与线性格兰杰因果一致，在更一般场景下能捕捉集体和非线性方向依赖；建立了统计推断的有限样本精确性和渐近有效性；实证分析显示金融市场的因果结构具有阶段性、压力依赖性、多通道传播和稀疏异质性等特征。

Conclusion: 该框架为复杂系统提供了可扩展且可解释的因果分析工具，补充了传统相关分析、因子分析和成对格兰杰因果分析的不足，特别适用于高维时间序列的系统级因果监测。

Abstract: We introduce an operator-theoretic framework for causal analysis in multivariate time series based on order-constrained spectral non-invariance. Directional influence is defined as sensitivity of second-order dependence operators to admissible, order-preserving temporal deformations of a designated source component, yielding an intrinsically multivariate causal notion summarized through orthogonally invariant spectral functionals. Under linear Gaussian assumptions, the criterion coincides with linear Granger causality, while beyond this regime it captures collective and nonlinear directional dependence not reflected in pairwise predictability. We establish existence, uniform consistency, and valid inference for the resulting non-smooth supremum--infimum statistics using shift-based randomization that exploits order-induced group invariance, yielding finite-sample exactness under exact invariance and asymptotic validity under weak dependence without parametric assumptions. Simulations demonstrate correct size and strong power against distributed and bulk-dominated alternatives, including nonlinear dependence missed by linear Granger tests with appropriate feature embeddings. An empirical application to a high-dimensional panel of daily financial return series spanning major asset classes illustrates system-level causal monitoring in practice. Directional organization is episodic and stress-dependent, causal propagation strengthens while remaining multi-channel, dominant causal hubs reallocate rapidly, and statistically robust transmission channels are sparse and horizon-heterogeneous even when aggregate lead--lag asymmetry is weak. The framework provides a scalable and interpretable complement to correlation-, factor-, and pairwise Granger-style analyses for complex systems.

</details>


### [4] [Model-Assisted Causal Inference for the Treatment Effect on Recurrent Events in the Presence of Terminal Events](https://arxiv.org/abs/2601.01245)
*Yiyuan Huang,Ling Zhou,Min Zhang,Peter X. K. Song*

Main category: stat.AP

TL;DR: 提出PR-MSMaT方法，解决在存在终末事件时评估机械循环支持设备对复发性事件风险影响的问题，克服现有方法在时间变化复发率下的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估终末期心衰患者接受机械循环支持设备的获益，现有方法在存在终末事件时存在生存长度偏倚问题，而WA检验在复发率随时间变化时会出现I类错误膨胀。

Method: 提出比例率边际结构模型辅助检验（PR-MSMaT），在可分离治疗效应的因果推断框架下处理复发性事件和终末事件，适用于时间变化的复发率情况。

Result: 模拟研究表明PR-MSMaT能正确控制I类错误，在时间变化复发率下保持与WA检验相当的检验效能，并成功应用于比较不同MCS设备的术后胃肠道出血风险。

Conclusion: PR-MSMaT为存在终末事件和时间变化复发率的复发性事件分析提供了稳健的统计方法，解决了现有方法的局限性，在临床研究中具有实用价值。

Abstract: This paper is motivated by evaluating the benefits of patients receiving mechanical circulatory support (MCS) devices in end-stage heart failure management inference, in which hypothesis testing for a treatment effect on the risk of recurrent events is challenged in the presence of terminal events. Existing methods based on cumulative frequency unreasonably disadvantage longer survivors as they tend to experience more recurrent events. The While-Alive-based (WA) test has provided a solution to address this survival-length-bias problem, and it performs well when the recurrent event rate holds constant over time. However, if such a constant-rate assumption is violated, the WA test can exhibit an inflated type I error and inaccurate estimation of treatment effects. To fill this methodological gap, we propose a Proportional Rate Marginal Structural Model-assisted Test (PR-MSMaT) in the causal inference framework of separable treatment effects for recurrent and terminal events. Using the simulation study, we demonstrate that our PR-MSMaT can properly control type I error while gaining power comparable to the WA test under time-varying recurrent event rates. We employ PR-MSMaT to compare different MCS devices with the postoperative risk of gastrointestinal bleeding among patients enrolled in the Interagency Registry of Mechanically Assisted Circulatory Support program.

</details>


### [5] [Errors-in-variables regression for dependent data with estimated error covariance matrix: To prewhiten or not?](https://arxiv.org/abs/2601.01351)
*Jingkun Qiu,Hanyue Chen,Song Xi Chen*

Main category: stat.AP

TL;DR: 比较误差变量回归模型中预白化与非预白化估计器的效率与计算成本，发现预白化不一定提高效率但需要更大样本和更多计算资源


<details>
  <summary>Details</summary>
Motivation: 在高维误差协方差矩阵存在测量误差的情况下，气候研究中常用的最优指纹方法采用预白化处理，但预白化对误差变量回归估计效率的改进程度不明确

Method: 比较预白化与非预白化估计器在估计效率和计算成本方面的表现，分析预白化操作对误差协方差矩阵估计所需样本量的影响

Result: 预白化操作不一定能提高非预白化估计器的估计效率，但需要更大的集合规模来确保误差协方差矩阵估计的渐近正态性，从而需要更多的计算资源

Conclusion: 在误差变量回归中，预白化处理虽然在某些情况下被采用，但实际可能不会带来效率提升，反而会增加计算负担，需要谨慎考虑其应用

Abstract: We consider statistical inference for errors-in-variables regression models with dependent observations under the high dimensionality of the error covariance matrix. It is tempting to prewhiten the model and data that had led to efficient weighted least squares estimation in the presence of the measurement errors, as being practised in the optimal fingerprinting approach in climate change studies. However, it is unclear to what extent the prewhitened estimator can improve the estimation efficiency of the unprewhitened estimator for errors-in-variables regression. We compare the prewhitening and unprewhitening estimators in terms of their estimation efficiency and computational cost. It shows that while the prewhitening operation does not necessarily improve the estimation efficiency of its unprewhitening counterpart, it demands more on the ensemble size needed in the error-covariance matrix estimation to ensure the asymptotic normality, and hence it would requires much more computationally resource.

</details>


### [6] [Cyclists Cardiac Conundrum](https://arxiv.org/abs/2601.02011)
*Andrew Nugent,Yi Ting Loo,Jack Buckingham*

Main category: stat.AP

TL;DR: 研究探索心率数据中的"间隙性"特征与心律失常的关系，发现高心率（>160bpm）下的心率跳跃与心律问题调查结果显著相关


<details>
  <summary>Details</summary>
Motivation: 运动员在训练时通常无法使用心电图监测心律失常，因此需要探索常用心率数据检测心律失常迹象的可行性。先前研究发现"间隙性"特征（心率跳跃）可能与心律失常相关，本研究在此基础上进一步开发检测方法

Method: 1. 在模拟数据上比较多种心率尖峰检测方法；2. 发现移动平均平滑配合残差恒定阈值法最有效；3. 将此方法应用于168名运动员的真实心率数据；4. 分析尖峰率与心律问题调查结果的相关性；5. 特别关注高心率（>160bpm）下的尖峰

Result: 1. 整体尖峰率与调查结果无显著相关性；2. 但高心率（>160bpm）下的尖峰率与心律问题调查结果显著相关；3. 支持了"只有高心率下的跳跃对心律失常有指示作用"的假设

Conclusion: 高心率下的心率跳跃特征对检测运动员心律失常具有潜在价值，表明需要进一步研究更好的心率数据特征表征方法，特别是针对高心率状态下的异常模式

Abstract: Arrhythmia is an abnormality of the heart's rhythm, caused by problems in the conductive system and resulting in irregular heartbeats. There is increasing evidence that undertaking frequent endurance sports training elevates one's risk of arrhythmia. Arrhythmia is diagnosed using an electrocardiogram (ECG) but this is not typically available to athletes while exercising. Previous research by Crickles investigates the usefulness of commonly available heart rate data in detecting signs of arrhythmia. It is hypothesised that a feature termed 'gappiness', defined by jumps in the heart rate while the athlete is under exertion, may be a characteristic of arrhythmia. A correlation was found between the proportion of 'gappy' activities and survey responses about heart rhythm problems. We develop on this measure by exploring various methods to detect spikes in heart rate data, allowing us to describe the extent of irregularity in an activity via the rate of spikes. We first compare the performance of these methods on simulated data, where we find that smoothing using a moving average and setting a constant threshold on the residuals is most effective. This method was then implemented on real data provided by Crickles from 168 athletes, where no significant correlation was found between the spike rates and survey responses. However, when considering only those spikes that occur above a heart rate of 160 beats per minute (bpm) a significant correlation was found. This supports the hypothesis that jumps at only high heart rates are informative of arrhythmia and indicates the need for further research into better measures to characterise features of heart rate data.

</details>


### [7] [Initial data analysis of the national German transplantation registry with a focus on kidney transplantation](https://arxiv.org/abs/2601.02226)
*Lukas Klein,Gunter Grieser,Carl-Ludwig Fischer-Fröhlich,Axel Rahmel,Henrik Stahl,Andreas Wienke,Antje Jahn-Eimermacher*

Main category: stat.AP

TL;DR: 对德国移植登记处数据进行初步数据分析，重点关注2006-2016年间首次成人肾移植数据，分析缺失数据模式、一致性和事件时间数据可用性，为未来研究提供预处理建议。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解德国移植登记处数据并为未来数据分析提供信息，需要进行初步数据分析来评估数据质量、识别数据问题，确保后续研究的可靠性。

Method: 对14,954名受者和9,964名供者的25个表格数据进行初步数据分析，采用决策树方法识别缺失数据模式，进行流入流出分析评估变量插补潜力，检查多源变量一致性。

Result: 缺失数据比例差异很大（部分表格完整，部分缺失超50%），识别出168个多源变量存在差异但可用于插补，事件时间分析结果强烈依赖于变量选择，为数据预处理提供具体建议。

Conclusion: TxReg数据在研究中面临挑战，需要仔细的数据预处理和变量选择，研究结果为未来移植数据分析提供了重要的方法论指导和质量控制建议。

Abstract: This study presents an Initial Data Analysis (IDA) of the German Transplantation Registry (TxReg) data for a better data understanding and to inform future data analyses. The IDA is focusing on data on first-time kidney-only transplantations in adult recipients from deceased donors between 2006 and 2016 and refers to data from 14,954 recipients and 9,964 donors across 25 tables. Investigated aspects include missing data patterns and structure, data consistency, and availability of event time data. Results show that missing data proportions vary widely, with some tables nearly complete while others have over 50% missing values. Missing data patterns are identified using a decision tree approach. An influx and outflux analysis demonstrates that some variables have high potential for imputing missing data, while others were less suitable for imputation. We identified 168 multi-sourced variables that are reported by multiple data providers in parallel leading to discrepancies for some variables but also providing opportunities for missing data imputation. Our findings on event time data demonstrate the importance of carefully selecting the variables used for event time analyses as results will strongly depend on this selection. In summary, our findings highlight the challenges when utilizing the TxReg data for research and provide recommendations for data preprocessing and analysis in future analyses.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [8] [Distribution-Matching Posterior Inference for Incomplete Structural Models](https://arxiv.org/abs/2601.01077)
*Takashi Kano*

Main category: econ.EM

TL;DR: 提出基于分布匹配的后验推断(DMPI)框架，用于不完全结构模型的贝叶斯推断，通过Jensen-Shannon散度构建准似然函数，处理模型误设和随机奇异性问题。


<details>
  <summary>Details</summary>
Motivation: 传统结构模型推断方法在处理不完全模型、模型误设和随机奇异性时存在局限，需要开发更稳健的推断框架。

Method: 扩展最小计量解释(MEI)，使用Jensen-Shannon散度构建理论矩分布与经验矩分布之间的准似然函数，基于Dirichlet-多项式结构加平滑处理，采用序列蒙特卡洛算法进行后验推断。

Result: 蒙特卡洛实验显示DMPI在误设的新凯恩斯模型中提供稳健推断，通过概率性降权改善分布匹配一致性；实证应用表明简约的随机奇异NK模型比过度参数化的满秩模型更好地拟合美国商业周期矩。

Conclusion: DMPI为不完全结构模型提供有效的贝叶斯推断框架，能处理模型误设和随机奇异性，在理论和实证应用中均表现出优越性。

Abstract: This paper introduces a Bayesian inference framework for incomplete structural models, termed distribution-matching posterior inference (DMPI). Extending the minimal econometric interpretation (MEI), DMPI constructs a divergence-based quasi-likelihood using the Jensen-Shannon divergence between theoretical and empirical population-moment distributions, based on a Dirichlet-multinomial structure with additive smoothing. The framework accommodates model misspecification and stochastic singularity. Posterior inference is implemented via a sequential Monte Carlo algorithm with Metropolis-Hastings mutation that jointly samples structural parameters and theoretical moment distributions. Monte Carlo experiments using misspecified New Keynesian (NK) models demonstrate that DMPI yields robust inference and improves distribution-matching coherence by probabilistically down-weighting moment distributions inconsistent with the structural model. An empirical application to U.S. data shows that a parsimonious stochastic singular NK model provides a better fit to business-cycle moments than an overparameterized full-rank counterpart.

</details>


### [9] [Optimizing Patient Placement in Normal Care Units: An Instrumental Causal Forest Approach Minimizing Mortality](https://arxiv.org/abs/2601.01149)
*Johannes Cordier*

Main category: econ.EM

TL;DR: 使用工具变量因果森林分析NCU分配对健康结果的影响，发现专业化与利用率之间的权衡，设计最小化后悔分配策略降低死亡率


<details>
  <summary>Details</summary>
Motivation: 医院正常护理单元(NCU)的分配影响健康结果，不同NCU有不同专业特长，患者可能适合多个NCU，且NCU利用率水平也影响结果，需要数据驱动的分配策略优化资源利用

Method: 使用工具变量因果森林方法，以急诊入院作为工具变量，估计NCU分配效果在患者和利用率水平间的异质性；设计最小化后悔分配策略，使用频率派、Balke-Pearl和Manski边界

Result: 结果显示专业化与利用率之间存在明确权衡；基于个性化平均处理效应的重新分配策略可在不扩大容量的情况下降低死亡率

Conclusion: 数据驱动的患者分配可以通过更有效地利用现有资源改善健康结果，最小化后悔分配策略为医院资源优化提供了可行方案

Abstract: Normal care units (NCU) placement affects health outcomes. NCUs in a hospital have different specialisations. There are patients that can potentially stay in multiple different NCUs. On a given day the NCUs are on different utilisation levels, which also affects health outcomes. Our approach uses instrumental variable causal forests, with emergency admission as an instrument, to estimate how the effect of NCU placement varies across patients and utilisation levels. The results show a clear trade-off between specialisation and utilization. Based on these findings, we design a minimax regret placement policy, using frequentist, Balke-Pearl and Manski bounds, that lowers mortality without capacity expansion. The policy reallocates patients according to their individualized average treatment effects, showing that data-driven patient placement can improve outcomes by using existing resources more efficiently.

</details>


### [10] [When and Why State-Dependent Local Projections Work](https://arxiv.org/abs/2601.01622)
*Valentin Winkler*

Main category: econ.EM

TL;DR: 本文研究了状态依赖局部投影(LPs)，建立了其估计量的一般特征，表明状态依赖LPs与VARs针对不同估计量，并揭示了LP-IV中状态依赖加权可能导致误解


<details>
  <summary>Details</summary>
Motivation: 状态依赖局部投影在实证研究中广泛应用，但对其估计量的解释存在模糊性。需要澄清状态依赖LPs的统计性质、与VARs的关系，以及在工具变量设置中可能产生的误解

Method: 首先建立状态依赖LPs估计量的一般理论特征，证明其在最小假设下恢复因果效应的加权平均。然后比较LPs与VARs的估计目标差异，提出基于VAR的估计器使其概率极限等于LP估计量。最后分析LP-IV设置中状态依赖加权的影响

Result: 1) 状态依赖LPs在几乎所有实际使用的设定下都能恢复因果效应的加权平均；2) LPs和VARs针对不同估计量，但可以通过VAR-based估计器使两者一致；3) 在LP-IV中，即使效应不是状态依赖的，状态依赖加权也可能产生非零交互项，这是误解的主要来源

Conclusion: 本文为正确解释状态依赖局部投影提供了理论框架，澄清了LPs与VARs的关系，并指出了LP-IV中状态依赖加权可能导致错误解释的关键机制

Abstract: This paper studies state-dependent local projections (LPs). First, I establish a general characterization of their estimand: under minimal assumptions, state-dependent LPs recover weighted averages of causal effects. This holds for essentially all specifications used in practice. Second, I show that state-dependent LPs and VARs target different estimands and propose a simple VAR-based estimator whose probability limit equals the LP estimand. Third, in instrumental variable (LP-IV) settings, state-dependent weighting can generate nonzero interaction terms, even when the effects are not state-dependent. Overall, this paper shows how to correctly interpret state-dependent LPs, clarifying their connection to VARs and highlighting a key source of LP-IV misinterpretation.

</details>


### [11] [Dynamic Risk in the U.S. Banking System: An Analysis of Sentiment, Policy Shocks, and Spillover Effects](https://arxiv.org/abs/2601.01783)
*Haibo Wang,Jun Huang,Lutfu S Sua,Jaime Ortiz,Jinshyang Roan,Bahram Alidaee*

Main category: econ.EM

TL;DR: 该研究通过高频数据分析发现，2023年美国银行业危机主要通过信息传染渠道传播，而非直接金融关联，验证了"太相似而不能倒"假说。


<details>
  <summary>Details</summary>
Motivation: 研究旨在超越探索性分析，检验"太相似而不能倒"假说，解释在利率压力下银行危机如何通过业务模式相似性感知进行传染，而非传统金融关联渠道。

Method: 采用时变参数向量自回归模型，使用30天滚动窗口分析2022年3月18日至2023年3月15日期间四家倒闭银行和一组系统选择的幸存银行的每日股票收益率，捕捉恐慌期间快速网络变化。

Result: 发现强烈证据支持信息传染渠道：危机高峰期系统总关联性急剧上升；SIVB、FRC和WAL是主要风险净传播者，其感知相似银行成为显著风险净接收者；市场情绪和政策不确定性显著放大风险溢出效应。

Conclusion: 研究证实了银行网络中系统性风险的持续性，强调了实时监控对加强金融稳定的重要性，为理解现代银行业危机传播机制提供了概念框架和实证验证。

Abstract: The 2023 U.S. banking crisis propagated not through direct financial linkages but through a high-frequency, information-based contagion channel. This paper moves beyond exploration analysis to test the "too-similar-to-fail" hypothesis, arguing that risk spillovers were driven by perceived similarities in bank business models under acute interest rate pressure. Employing a Time-Varying Parameter Vector Autoregression (TVP-VAR) model with 30-day rolling windows, a method uniquely suited for capturing the rapid network shifts inherent in a panic, we analyze daily stock returns for the four failed institutions and a systematically selected peer group of surviving banks vulnerable to the same risks from March 18, 2022, to March 15, 2023. Our results provide strong evidence for this contagion channel: total system connectedness surged dramatically during the crisis peak, and we identify SIVB, FRC, and WAL as primary net transmitters of risk while their perceived peers became significant net receivers, a key dynamic indicator of systemic vulnerability that cannot be captured by asset-by-asset analysis. We further demonstrate that these spillovers were significantly amplified by market sentiment (as measured by the VIX) and economic policy uncertainty (EPU). By providing a clear conceptual framework and robust empirical validation, our findings confirm the persistence of systemic risks within the banking network and highlight the importance of real-time monitoring in strengthening financial stability.

</details>


### [12] [Reinforcement Learning Based Computationally Efficient Conditional Choice Simulation Estimation of Dynamic Discrete Choice Models](https://arxiv.org/abs/2601.02069)
*Ahmed Khwaja,Sonal Srivastava*

Main category: econ.EM

TL;DR: 本文提出一种基于强化学习的轻量级两步条件选择模拟估计方法，用于解决高维状态-动作空间下动态离散选择模型的计算挑战，结合机器学习可扩展性与结构模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 动态离散选择模型在营销中广泛应用，但在"大数据"环境下，高维状态-动作空间使得传统估计方法计算困难，需要更可扩展的解决方案。

Method: 将条件选择模拟估计框架重新构建为强化学习问题，提出基于强化学习的轻量级两步估计方法，结合CCS的前向模拟特性和RL的路径更新优势。

Result: 通过机器更换和消费者食品购买模型的蒙特卡洛模拟，证明该方法相比传统CCS估计具有更高的计算效率，同时保持模型的可解释性和可处理性。

Conclusion: 将DDC模型的CCS估计框架化为强化学习问题，显著提高了其在营销高维问题中的适用性和可扩展性，同时保留了结构模型的解释优势和计算可行性。

Abstract: Dynamic discrete choice (DDC) models have found widespread application in marketing. However, estimating these becomes challenging in "big data" settings with high-dimensional state-action spaces. To address this challenge, this paper develops a Reinforcement Learning (RL)-based two-step ("computationally light") Conditional Choice Simulation (CCS) estimation approach that combines the scalability of machine learning with the transparency, explainability, and interpretability of structural models, which is particularly valuable for counterfactual policy analysis. The method is premised on three insights: (1) the CCS ("forward simulation") approach is a special case of RL algorithms, (2) starting from an initial state-action pair, CCS updates the corresponding value function only after each simulation path has terminated, whereas RL algorithms may update for all the state-action pairs visited along a simulated path, and (3) RL focuses on inferring an agent's optimal policy with known reward functions, whereas DDC models focus on estimating the reward functions presupposing optimal policies. The procedure's computational efficiency over CCS estimation is demonstrated using Monte Carlo simulations with a canonical machine replacement and a consumer food purchase model. Framing CCS estimation of DDC models as an RL problem increases their applicability and scalability to high-dimensional marketing problems while retaining both interpretability and tractability.

</details>


### [13] [Fare-Free Bus Service and CO2 Reductions: Evidence from a Natural Experiment](https://arxiv.org/abs/2601.02190)
*Anna Alberini,Javier Bas,Cinzia Cirillo*

Main category: econ.EM

TL;DR: 评估华盛顿特区地铁区亚历山大市免费公交服务影响的研究，采用双重差分法设计，发现对公交使用率影响有限（最多增加6%），对臭氧和交通事故无影响，但能带来少量CO2减排（0.294-0.494吨/年）


<details>
  <summary>Details</summary>
Motivation: 评估免费公交服务对居民出行行为、交通流量和环境影响的实际效果，为城市交通政策提供实证依据

Method: 采用双重差分法研究设计，通过调查问卷收集数据，比较亚历山大市（实验组）与对照地区的公交使用变化、环境影响和交通事故数据

Result: 免费公交服务对公交使用率影响有限（最多增加6%），对地面臭氧和交通事故无显著影响；能减少0.294-0.494吨CO2/年，成本为70-120美元/吨CO2；若全面推广，预计每年减少0.454吨CO2

Conclusion: 免费公交服务对改变居民出行行为的实际效果有限，虽然能带来少量CO2减排，但成本效益相对较低，对整体交通流量和空气质量改善作用不明显

Abstract: We devise a difference-in-difference study design to assess the impact of fare-free bus service in Alexandria, located in the Washington, DC metro area. Our surveys show modest to no effect, with at most 6% more residents in Alexandria increasing their bus usage compared to control locations. We find no effect on ground-level ozone or road crashes, suggesting little to no impact on road traffic.
  One-third of respondents in control locations indicated they would use buses more frequently if fare-free service were available in their areas. Based on the respondent-reported reductions in car miles, the program led to a reduction of 0.294 to 0.494 tons of CO2 per year, or 5% to 9% of the average annual emissions from a US car, at a cost of $70-$120 per ton of CO2. We predict a CO2 reduction of 0.454 tons per year, equivalent to 8% of the average US car's annual emissions if the fare-free bus covered all of the study areas.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [14] [When Is Degree Enough? Bounds on Degree-Eigenvector Misalignment in Assortative Structured Networks](https://arxiv.org/abs/2601.00807)
*Sreerag Puravankara,Vipin P. Veetil*

Main category: cs.SI

TL;DR: 论文分析了网络中度向量与主特征向量对齐的条件，推导了在存在度同配性和局部结构时两者差异的界限，并定义了"谱安全"区域。


<details>
  <summary>Details</summary>
Motivation: 许多现实网络违反度向量与主特征向量自然对齐的条件（中性度混合和无局部结构），需要量化在存在度同配性和局部结构时两者的差异。

Method: 使用构造性方法：设计度保持的重连算法，从中性基准开始单调增加同配性和局部结构强度，结合Stewart-Sun扰动界限和重连步骤的谱范数控制。

Result: 推导了在适度同配性和局部结构水平下，特征向量与度向量之间夹角的上界，界定了"谱安全"区域。

Conclusion: 度向量可作为节点系统重要性的可靠度量，但仅在"谱安全"区域内有效，该区域由分析界限明确界定。

Abstract: A tight alignment between the degree vector and the leading eigenvector arises naturally in networks with neutral degree mixing and the absence of local structures. Many real-world networks, however, violate both conditions. We derive bounds on the divergence between the degree vector and the eigenvector in networks with degree assortativity and local mesoscopic structures such as communities, core-peripheries, and cycles. Our approach is constructive. We design sufficiently general degree-preserving rewiring algorithms that start from a neutral benchmark and monotonically increase assortativity and the strength of local structures, with each step inducing a perturbation of the adjacency matrix. Using the Stewart--Sun Perturbation Bound, together with explicit spectral-norm control of the rewiring steps, we derive upper bounds on the angle between the eigenvector and the degree vector for modest levels of assortativity and local structures. Our analytical bounds delineate regions of `spectral safety' in which a node's degree can be used as a reliable measure of its systemic importance in real-world networks.

</details>


### [15] [Measuring Social Media Polarization Using Large Language Models and Heuristic Rules](https://arxiv.org/abs/2601.00927)
*Jawad Chowdhury,Rezaur Rashid,Gabriel Terejanu*

Main category: cs.SI

TL;DR: 该研究提出一个结合大语言模型和领域启发式规则的新框架，用于分析和量化社交媒体讨论中的情感极化现象，特别是在气候变化和枪支管制等争议话题上。


<details>
  <summary>Details</summary>
Motivation: 理解在线讨论中的情感极化对于评估社交媒体互动的社会影响至关重要。现有方法大多依赖情感分析或预定义分类器，缺乏系统性的量化框架。

Method: 利用大语言模型从大规模社交媒体讨论中提取立场、情感基调和同意模式，然后应用基于规则的评分系统，根据立场对齐、情感内容和互动动态量化情感极化，即使是在单次互动的小规模对话中也能工作。

Result: 分析揭示了两种事件依赖的极化模式：(1)预期驱动极化：在广为人知的事件发生前极端极化加剧；(2)反应性极化：突发高影响事件后情感极化立即激增。

Conclusion: 通过结合AI驱动的内容标注和领域知识评分，该框架提供了可扩展且可解释的情感极化测量方法，有助于更好地理解社交媒体互动对社会的影响。

Abstract: Understanding affective polarization in online discourse is crucial for evaluating the societal impact of social media interactions. This study presents a novel framework that leverages large language models (LLMs) and domain-informed heuristics to systematically analyze and quantify affective polarization in discussions on divisive topics such as climate change and gun control. Unlike most prior approaches that relied on sentiment analysis or predefined classifiers, our method integrates LLMs to extract stance, affective tone, and agreement patterns from large-scale social media discussions. We then apply a rule-based scoring system capable of quantifying affective polarization even in small conversations consisting of single interactions, based on stance alignment, emotional content, and interaction dynamics. Our analysis reveals distinct polarization patterns that are event dependent: (i) anticipation-driven polarization, where extreme polarization escalates before well-publicized events, and (ii) reactive polarization, where intense affective polarization spikes immediately after sudden, high-impact events. By combining AI-driven content annotation with domain-informed scoring, our framework offers a scalable and interpretable approach to measuring affective polarization. The source code is publicly available at: https://github.com/hasanjawad001/llm-social-media-polarization.

</details>


### [16] [Gendered Pathways in AI Companionship: Cross-Community Behavior and Toxicity Patterns on Reddit](https://arxiv.org/abs/2601.01073)
*Erica Coppolillo,Emilio Ferrara*

Main category: cs.SI

TL;DR: 研究分析了Reddit上AI伴侣社区用户的跨社区参与模式，发现存在明显的性别化结构，少数性别导向社区可能成为毒性内容的放大器。


<details>
  <summary>Details</summary>
Motivation: AI伴侣平台正在重塑人们与非人类代理的情感、浪漫和准社会关系，但缺乏对这些关系如何与性别化在线行为和有害内容暴露相交的研究。

Method: 聚焦MyBoyfriendIsAI子版块，重建3000多名高参与度用户两年多的Reddit活动历史（67000多条记录），构建涵盖2000多个子版块的历史互动网络，追踪跨社区路径并测量毒性和情感表达变化。

Result: MBIA用户主要参与四大社区领域（AI伴侣、色情相关、论坛类和游戏）；参与模式呈现明显的性别化结构，女性用户参与度高；毒性整体较低但在AI色情和性别导向社区有局部高峰；16%用户参与性别导向子版块，其轨迹显示系统性不同的情感表达模式和更高毒性。

Conclusion: 揭示了Reddit上AI伴侣社区参与的性别化结构，识别了风险集中区域，为人类-AI关系平台的测量、审核和设计实践提供信息。

Abstract: AI-companionship platforms are rapidly reshaping how people form emotional, romantic, and parasocial bonds with non-human agents, raising new questions about how these relationships intersect with gendered online behavior and exposure to harmful content. Focusing on the MyBoyfriendIsAI (MBIA) subreddit, we reconstruct the Reddit activity histories of more than 3,000 highly engaged users over two years, yielding over 67,000 historical submissions. We then situate MBIA within a broader ecosystem by building a historical interaction network spanning more than 2,000 subreddits, which enables us to trace cross-community pathways and measure how toxicity and emotional expression vary across these trajectories. We find that MBIA users primarily traverse four surrounding community spheres (AI-companionship, porn-related, forum-like, and gaming) and that participation across the ecosystem exhibits a distinct gendered structure, with substantial engagement by female users. While toxicity is generally low across most pathways, we observe localized spikes concentrated in a small subset of AI-porn and gender-oriented communities. Nearly 16% of users engage with gender-focused subreddits, and their trajectories display systematically different patterns of emotional expression and elevated toxicity, suggesting that a minority of gendered pathways may act as toxicity amplifiers within the broader AI-companionship ecosystem. These results characterize the gendered structure of cross-community participation around AI companionship on Reddit and highlight where risks concentrate, informing measurement, moderation, and design practices for human-AI relationship platforms.

</details>


### [17] [Beyond Homophily: Community Search on Heterophilic Graphs](https://arxiv.org/abs/2601.01703)
*Qing Sima,Xiaoyang Wang,Wenjie Zhang*

Main category: cs.SI

TL;DR: AdaptCS：针对异质图社区搜索的统一框架，通过解耦多跳多频信号、低秩优化和自适应社区评分，在异质图上实现高效社区搜索。


<details>
  <summary>Details</summary>
Motivation: 现实世界网络多为异质图（节点间差异大），传统社区搜索方法（k-core、k-truss）和基于同质假设的GNN模型在异质图上效果不佳，前者返回混合标签社区，后者平滑掉重要信号。

Method: 提出AdaptCS框架：1）AdaptCS编码器解耦多跳多频信号，捕捉平滑（同质）和对比（异质）关系；2）内存高效的低秩优化去除计算瓶颈；3）自适应社区评分（ACS）平衡嵌入相似性和拓扑关系指导在线搜索。

Result: 在异质和同质基准测试中，AdaptCS平均F1分数比最佳基线提升11%，在不同异质程度下保持鲁棒性，计算速度提升达2个数量级。

Conclusion: AdaptCS通过统一框架有效解决了异质图社区搜索问题，在准确性和效率上均有显著提升，为现实世界网络分析提供了实用工具。

Abstract: Community search aims to identify a refined set of nodes that are most relevant to a given query, supporting tasks ranging from fraud detection to recommendation. Unlike homophilic graphs, many real-world networks are heterophilic, where edges predominantly connect dissimilar nodes. Therefore, structural signals that once reflected smooth, low-frequency similarity now appear as sharp, high-frequency contrasts. However, both classical algorithms (e.g., k-core, k-truss) and recent ML-based models struggle to achieve effective community search on heterophilic graphs, where edge signs or semantics are generally unknown. Algorithm-based methods often return communities with mixed class labels, while GNNs, built on homophily, smooth away meaningful signals and blur community boundaries. Therefore, we propose Adaptive Community Search (AdaptCS), a unified framework featuring three key designs: (i) an AdaptCS Encoder that disentangles multi-hop and multi-frequency signals, enabling the model to capture both smooth (homophilic) and contrastive (heterophilic) relations; (ii) a memory-efficient low-rank optimization that removes the main computational bottleneck and ensures model scalability; and (iii) an Adaptive Community Score (ACS) that guides online search by balancing embedding similarity and topological relations. Extensive experiments on both heterophilic and homophilic benchmarks demonstrate that AdaptCS outperforms the best-performing baseline by an average of 11% in F1-score, retains robustness across heterophily levels, and achieves up to 2 orders of magnitude speedup.

</details>


### [18] [Fixed-Size Dynamic Scale-Free Networks: Modeling, Stationarity, and Resilience](https://arxiv.org/abs/2601.01882)
*Yichao Yao,Minyu Feng,Matjaž Perc,Jürgen Kurths*

Main category: cs.SI

TL;DR: 提出了一种固定节点数的动态网络模型，将节点度波动建模为状态依赖的随机游走过程，能够生成稳定的无标度网络，无需节点增长或优先连接假设。


<details>
  <summary>Details</summary>
Motivation: 现实中的许多无标度网络（如神经网络、在线通信网络）具有固定节点数但边动态波动的特性，而传统模型通常关注节点增长而忽略了节点数固定的场景。

Method: 将节点度波动建模为状态依赖的随机游走过程，包含停滞状态和可变扩散系数，无需节点增长或优先连接假设。

Result: 模型能生成具有稳定无标度特性的随机动态网络，度分布收敛于幂律分布（只要最低度状态不是吸收态）。通过三个真实网络验证了模型能准确复现实际数据。

Conclusion: 该模型阐明了即使没有增长和优先连接特征，网络仍能呈现幂律分布的机制，可用于模拟和研究受攻击的固定规模无标度网络的韧性。

Abstract: Many real-world scale-free networks, such as neural networks and online communication networks, consist of a fixed number of nodes but exhibit dynamic edge fluctuations. However, traditional models frequently overlook scenarios where the node count remains constant, instead prioritizing node growth. In this work, we depart from the assumptions of node number variation and preferential attachment to present an innovative model that conceptualizes node degree fluctuations as a state-dependent random walk process with stasis and variable diffusion coefficient. We show that this model yields stochastic dynamic networks with stable scale-free properties. Through comprehensive theoretical and numerical analyses, we demonstrate that the degree distribution converges to a power-law distribution, provided that the lowest degree state within the network is not an absorbing state. Furthermore, we investigate the resilience of the fraction of the largest component and the average shortest path length following deliberate attacks on the network. By using three real-world networks, we confirm that the proposed model accurately replicates actual data. The proposed model thus elucidates mechanisms by which networks, devoid of growth and preferential attachment features, can still exhibit power-law distributions and be used to simulate and study the resilience of attacked fixed-size scale-free networks.

</details>


### [19] [A series of real networks invariants](https://arxiv.org/abs/2601.02052)
*Mikhail Tuzhilin*

Main category: cs.SI

TL;DR: 提出基于拉普拉斯矩阵的系列中心性度量，推广了度中心性和ksi中心性，发现真实网络呈指数分布（j=0时为幂律分布），而人工网络分布不同


<details>
  <summary>Details</summary>
Motivation: 现有网络中心性度量（如度中心性和ksi中心性）有限，需要更一般的框架来刻画真实网络与人工网络的结构差异

Method: 基于拉普拉斯矩阵构造一系列中心性度量，分析其在真实网络和人工网络中的分布特性

Result: 发现该系列中心性在真实网络中呈现指数分布（j=0时为幂律分布），而在人工网络中呈现不同的分布模式

Conclusion: 提出的拉普拉斯矩阵中心性系列能够有效区分真实网络与人工网络的结构特征，为网络分析提供了新的工具

Abstract: In this article we propose a generalization of two known invariants of real networks: degree and ksi-centrality. More precisely, we found a series of centralities based on Laplacian matrix, that have exponential distributions (power-law for the case $j = 0$) for real networks and different distributions for artificial ones.

</details>


### [20] [Inferring Network Evolutionary History via Structure-State Coupled Learning](https://arxiv.org/abs/2601.02121)
*En Xu,Shihe Zhou,Huandong Wang,Jingtao Ding,Yong Li*

Main category: cs.SI

TL;DR: CS²利用网络稳态动力学作为额外观测信号，结合拓扑结构共同推断网络演化历史，显著提升了边形成顺序恢复的准确性。


<details>
  <summary>Details</summary>
Motivation: 从单一最终快照推断网络演化历史是基础但具有挑战性的任务。现有方法主要依赖拓扑结构，但拓扑本身往往提供的信息不足且噪声较大。本文提出利用网络稳态动力学（在给定动态过程下收敛的节点状态）作为额外的、广泛可用的观测信号来改进演化历史推断。

Method: 提出CS²方法，显式建模结构-状态耦合，捕捉拓扑如何调节稳态状态，以及这两种信号如何共同改善边形成顺序恢复中的边判别能力。方法考虑了拓扑和稳态动力学之间的相互作用。

Result: 在六个真实时序网络上，通过多种动态过程评估，CS²始终优于强基线方法：成对边优先准确率平均提升4.0%，全局排序一致性（Spearman-ρ）平均提升7.7%。CS²还能更忠实地恢复宏观演化轨迹，如聚类形成、度异质性和中心节点增长。即使拓扑信息有限时，仅使用稳态状态的变体方法仍保持竞争力。

Conclusion: 网络稳态动力学为网络演化历史推断提供了独立且有价值的信号，与拓扑结构结合能显著提升推断性能。CS²方法通过显式建模结构-状态耦合，有效利用了这两种互补信息源，为从单一时刻快照推断演化历史提供了更强大的工具。

Abstract: Inferring a network's evolutionary history from a single final snapshot with limited temporal annotations is fundamental yet challenging. Existing approaches predominantly rely on topology alone, which often provides insufficient and noisy cues. This paper leverages network steady-state dynamics -- converged node states under a given dynamical process -- as an additional and widely accessible observation for network evolution history inference. We propose CS$^2$, which explicitly models structure-state coupling to capture how topology modulates steady states and how the two signals jointly improve edge discrimination for formation-order recovery. Experiments on six real temporal networks, evaluated under multiple dynamical processes, show that CS$^2$ consistently outperforms strong baselines, improving pairwise edge precedence accuracy by 4.0% on average and global ordering consistency (Spearman-$ρ$) by 7.7% on average. CS$^2$ also more faithfully recovers macroscopic evolution trajectories such as clustering formation, degree heterogeneity, and hub growth. Moreover, a steady-state-only variant remains competitive when reliable topology is limited, highlighting steady states as an independent signal for evolution inference.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [21] [VEAT Quantifies Implicit Associations in Text-to-Video Generator Sora and Reveals Challenges in Bias Mitigation](https://arxiv.org/abs/2601.00996)
*Yongxu Sun,Michael Saxon,Ian Yang,Anna-Maria Gueorguieva,Aylin Caliskan*

Main category: cs.CY

TL;DR: 研究者开发了视频嵌入关联测试(VEAT)来评估Sora等文本到视频生成器的社会偏见，发现其视频将欧洲裔美国人和女性与愉悦度更强烈关联，且效应大小与现实世界人口分布高度相关。去偏提示有时反而加剧偏见。


<details>
  <summary>Details</summary>
Motivation: 随着Sora等文本到视频生成器的出现，需要评估生成内容是否反映社会偏见。现有偏见测试主要针对文字和图像，缺乏对视频内容的系统评估方法。

Method: 开发了视频嵌入关联测试(VEAT)和单类别VEAT(SC-VEAT)，通过测量视频嵌入空间中的关联来量化偏见。验证方法后，评估Sora视频在17种职业和7种奖项中种族(非裔vs欧裔美国人)和性别(女性vs男性)与愉悦度的关联。

Result: Sora视频将欧洲裔美国人和女性更强烈地与愉悦度关联(效应大小d>0.8)。效应大小与现实世界人口分布高度相关：职业中男性比例和白人比例(r=0.93, r=0.83)，奖项中男性比例和非黑人比例(r=0.88, r=0.99)。去偏提示通常减少效应大小，但对某些职业(清洁工、邮政服务)反而加剧了黑人关联。

Conclusion: 文本到视频生成器可能放大代表性伤害，需要严格评估和负责任部署。简单的去偏干预可能产生意外后果，需要更系统的偏见缓解策略。

Abstract: Text-to-Video (T2V) generators such as Sora raise concerns about whether generated content reflects societal bias. We extend embedding-association tests from words and images to video by introducing the Video Embedding Association Test (VEAT) and Single-Category VEAT (SC-VEAT). We validate these methods by reproducing the direction and magnitude of associations from widely used baselines, including Implicit Association Test (IAT) scenarios and OASIS image categories. We then quantify race (African American vs. European American) and gender (women vs. men) associations with valence (pleasant vs. unpleasant) across 17 occupations and 7 awards. Sora videos associate European Americans and women more with pleasantness (both d>0.8). Effect sizes correlate with real-world demographic distributions: percent men and White in occupations (r=0.93, r=0.83) and percent male and non-Black among award recipients (r=0.88, r=0.99). Applying explicit debiasing prompts generally reduces effect-size magnitudes, but can backfire: two Black-associated occupations (janitor, postal service) become more Black-associated after debiasing. Together, these results reveal that easily accessible T2V generators can actually amplify representational harms if not rigorously evaluated and responsibly deployed.

</details>


### [22] [An Agentic Software Framework for Data Governance under DPDP](https://arxiv.org/abs/2601.01101)
*Apurva Kulkarni,Chandrashekar Ramanathan*

Main category: cs.CY

TL;DR: 提出一个基于智能代理的框架，用于在印度DPDP法案下实现透明、可追溯和自适应的数据治理合规性


<details>
  <summary>Details</summary>
Motivation: 在印度数字个人数据保护法案(DPDP)的严格合规要求下，传统合规工具存在硬编码规则、静态配置、不透明决策等问题，需要开发透明、可追溯、自适应执行的负责任AI软件

Method: 提出基于智能代理的框架，包含KYU代理（语义理解、用户可信度建模）和合规代理（数据敏感性推理），采用目标驱动的代理管道，使用开源代理框架实现

Result: 在医疗、教育、电商等10个不同领域进行评估，通过匿名化分数衡量DPDP合规效果，展示了通过掩码、假名化和泛化策略实现的可扩展、合规的数据治理

Conclusion: 该框架通过协作代理、动态策略执行和领域感知的匿名化，实现了可扩展、透明和合规的数据治理，为法律框架下的数据治理提供了创新解决方案

Abstract: Despite the rise of data-driven software systems in the modern digital landscape, data governance under a legal framework remains a critical challenge. In India, the Digital Personal Data Protection (DPDP) Act mandates rigorous data privacy and compliance requirements, necessitating software frameworks that are both ethical and regulation-aware. From a software development perspective, traditional compliance tools often rely on hard-coded rules and static configurations, making them inflexible to dynamic policy updates or evolving legal contexts. Additionally, their monolithic architectures obscure decision-making processes, creating black-box behavior in critical governance workflows. Developing responsible AI software demands transparency, traceability, and adaptive enforcement mechanisms that make ethical decisions explainable. To address this challenge, a novel agentic framework is introduced to embed compliance logic directly into software agents that govern and adapt data policies. In this paper, the implementation focuses on the DPDP Act. The framework integrates KYU Agent and Compliance Agent for this purpose. KYU (Know-YourUser) Agent supports semantic understanding, user trustworthiness modelling and Compliance Agent uses data sensitivity reasoning within a goal-driven, agentic pipeline. The proposed framework, built using an open-sourced agentic framework and has been evaluated across ten diverse domains, including healthcare, education, and e-commerce. Its effectiveness under DPDP, measured via an Anonymization Score, demonstrates scalable, compliant data governance through masking, pseudonymization, and generalization strategies tailored to domain-specific needs. The proposed framework delivers scalable, transparent, and compliant data governance through collaborative agents, dynamic policy enforcement, and domain-aware anonymization.

</details>


### [23] [Inconsistencies in Classification of Online News Articles: A Call for Common Standards in Brand Safety Services](https://arxiv.org/abs/2601.01303)
*Michael Smith,Riley Grossman,Antonio Torres-Aguero,Pritam Sen,Cristian Borcea,Yi Chen*

Main category: cs.CY

TL;DR: 研究发现三大品牌安全服务商对新闻文章的分类存在显著不一致，导致广告投放错误和收入损失，呼吁建立标准化透明系统。


<details>
  <summary>Details</summary>
Motivation: 新闻内容在公共话语中占据核心地位，但数字广告支出不足，品牌安全分类错误会带来重大财务后果，需要研究当前品牌安全服务的可靠性。

Method: 收集51个域名上的4,352篇新闻文章数据，分析DoubleVerify、Integral Ad Science和Oracle三大品牌安全服务商的分类评级，比较它们之间的一致性。

Result: 品牌安全服务商经常产生冲突的分类结果，不同提供商之间存在显著差异，这些不一致会对广告商和出版商造成有害后果。

Conclusion: 当前品牌安全系统存在缺陷，需要建立标准化和透明的品牌安全系统，以减轻对数字广告生态系统的负面影响。

Abstract: This study examines inconsistencies in the brand safety classifications of online news articles by analyzing ratings from three leading brand safety providers, DoubleVerify, Integral Ad Science, and Oracle. We focus on news content because of its central role in public discourse and the significant financial consequences of unsafe classifications in a sector that is already underserved by digital ad spending. By collecting data from 4,352 news articles on 51 domains, our analysis shows that brand safety services often produce conflicting classifications, with significant discrepancies between providers. These inconsistencies can have harmful consequences for both advertisers and publishers, leading to misplaced advertising spending and revenue losses. This research provides critical insights into the shortcomings of the current brand safety landscape. We argue for a standardized and transparent brand safety system to mitigate the harmful effects of the current system on the digital advertising ecosystem.

</details>


### [24] [AppellateGen: A Benchmark for Appellate Legal Judgment Generation](https://arxiv.org/abs/2601.01331)
*Hongkun Yang,Lionel Z. Wang,Wei Fan,Yiran Hu,Lixu Wang,Chenyu Liu,Shenghong Fu,Haoyang Li,Xin Xu,Jiexin Zheng,Wei Dong*

Main category: cs.CY

TL;DR: 提出了AppellateGen基准，用于上诉（二审）法律判决生成，包含7,351个案件对，并设计了基于司法标准操作程序的多智能体系统SLMAS来模拟司法工作流程。


<details>
  <summary>Details</summary>
Motivation: 现有法律判决生成研究主要关注一审审判，依赖静态的事实到判决映射，忽视了上诉（二审）审查的辩证性质，需要专门的上诉判决生成基准和方法。

Method: 提出了基于司法标准操作程序的法律多智能体系统（SLMAS），将生成过程分解为问题识别、检索和起草等离散阶段，模拟司法工作流程。

Result: 实验结果表明，虽然SLMAS提高了逻辑一致性，但上诉推理的复杂性对当前大语言模型仍构成重大挑战。

Conclusion: AppellateGen基准填补了上诉法律判决生成的空白，SLMAS系统展示了模拟司法工作流程的潜力，但上诉推理的复杂性仍需进一步研究。

Abstract: Legal judgment generation is a critical task in legal intelligence. However, existing research in legal judgment generation has predominantly focused on first-instance trials, relying on static fact-to-verdict mappings while neglecting the dialectical nature of appellate (second-instance) review. To address this, we introduce AppellateGen, a benchmark for second-instance legal judgment generation comprising 7,351 case pairs. The task requires models to draft legally binding judgments by reasoning over the initial verdict and evidentiary updates, thereby modeling the causal dependency between trial stages. We further propose a judicial Standard Operating Procedure (SOP)-based Legal Multi-Agent System (SLMAS) to simulate judicial workflows, which decomposes the generation process into discrete stages of issue identification, retrieval, and drafting. Experimental results indicate that while SLMAS improves logical consistency, the complexity of appellate reasoning remains a substantial challenge for current LLMs. The dataset and code are publicly available at: https://anonymous.4open.science/r/AppellateGen-5763.

</details>


### [25] [The Gray Area: Characterizing Moderator Disagreement on Reddit](https://arxiv.org/abs/2601.01620)
*Shayan Alipour,Shruti Phadke,Seyed Shahabeddin Mousavi,Amirhossein Afsharrad,Morteza Zihayat,Mattia Samory*

Main category: cs.CY

TL;DR: 研究分析了Reddit论坛5年430万条审核日志，发现七分之一的审核案例存在争议（"灰色地带"），主要涉及意图不明确的违规行为（如钓鱼、刷屏）和社区治理冲突，近半数灰色案例涉及自动化审核，语言模型难以处理这类争议。


<details>
  <summary>Details</summary>
Motivation: 在线社区志愿者审核员对内容审核标准存在分歧，这种"灰色地带"的争议案例对社区治理和自动化审核系统构成挑战，需要深入研究其特征和复杂性。

Method: 基于24个不同主题和规模的subreddit的5年430万条审核日志数据，通过信息论评估分析争议案例与无争议案例的差异，测试了最先进的语言模型在处理争议案例时的表现。

Result: 七分之一的审核案例存在争议；争议案例主要涉及用户意图不明确的违规行为（如钓鱼、刷屏）和社区治理冲突；近半数争议案例涉及自动化审核；信息论分析显示争议案例本质上更难裁决；当前最先进的语言模型难以有效处理争议案例。

Conclusion: 人类专家审核员在监督审核过程中仍发挥关键作用，当前审核流程和工具在处理争议案例方面存在显著挑战，需要更完善的机制来支持复杂的内容审核决策。

Abstract: Volunteer moderators play a crucial role in sustaining online dialogue, but they often disagree about what should or should not be allowed. In this paper, we study the complexity of content moderation with a focus on disagreements between moderators, which we term the ``gray area'' of moderation. Leveraging 5 years and 4.3 million moderation log entries from 24 subreddits of different topics and sizes, we characterize how gray area, or disputed cases, differ from undisputed cases. We show that one-in-seven moderation cases are disputed among moderators, often addressing transgressions where users' intent is not directly legible, such as in trolling and brigading, as well as tensions around community governance. This is concerning, as almost half of all gray area cases involved automated moderation decisions. Through information-theoretic evaluations, we demonstrate that gray area cases are inherently harder to adjudicate than undisputed cases and show that state-of-the-art language models struggle to adjudicate them. We highlight the key role of expert human moderators in overseeing the moderation process and provide insights about the challenges of current moderation processes and tools.

</details>


### [26] [From Chat Control to Robot Control: The Backdoors Left Open for the Sake of Safety](https://arxiv.org/abs/2601.02205)
*Neziha Akalin,Alberto Giaretta*

Main category: cs.CY

TL;DR: 欧盟"聊天控制"法案将数字监控扩展到机器人交互领域，可能将日常机器人变成监控工具，在保护与控制之间制造矛盾，并通过削弱加密创造安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 分析欧盟"聊天控制"法案如何将数字监控扩展到人机交互领域，探讨这种监管对机器人作为人际沟通渠道（在护理、教育、远程呈现等场景）的潜在影响，揭示监管激励可能导致的隐私、自主权和信任危机。

Method: 通过理论分析和论证，探讨监管政策如何改变机器人系统设计，分析监控机制对端到端加密的削弱作用，以及由此产生的安全漏洞和攻击面扩大问题。

Result: 研究发现将数字监控扩展到具身系统会导致持续监控，模糊保护与控制的界限，将陪伴机器人变成潜在告密者。同时，监控机制会削弱加密，创造事实上的后门，扩大攻击面，形成"通过不安全实现安全"的悖论。

Conclusion: 旨在提高意识而非预测未来，警告这种监管可能导致机器人系统在保护用户的同时反而损害其隐私、自主权和信任，呼吁防止这种未来成为现实。

Abstract: This paper explores how a recent European Union proposal, the so-called Chat Control law, which creates regulatory incentives for providers to implement content detection and communication scanning, could transform the foundations of human-robot interaction (HRI). As robots increasingly act as interpersonal communication channels in care, education, and telepresence, they convey not only speech but also gesture, emotion, and contextual cues. We argue that extending digital surveillance laws to such embodied systems would entail continuous monitoring, embedding observation into the very design of everyday robots. This regulation blurs the line between protection and control, turning companions into potential informants. At the same time, monitoring mechanisms that undermine end-to-end encryption function as de facto backdoors, expanding the attack surface and allowing adversaries to exploit legally induced monitoring infrastructures. This creates a paradox of safety through insecurity: systems introduced to protect users may instead compromise their privacy, autonomy, and trust. This work does not aim to predict the future, but to raise awareness and help prevent certain futures from materialising.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [27] [Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections](https://arxiv.org/abs/2601.00814)
*Abhishek Kumar*

Main category: cs.AI

TL;DR: 提出一种基于嵌入余弦相似度的跨语言本体对齐系统，通过创新描述生成技术丰富本体实体上下文，使用微调的多语言Transformer模型生成更好嵌入，在OAEI-2022多语言农场赛道达到71% F1分数，比最佳基线提升16%


<details>
  <summary>Details</summary>
Motivation: 解决跨语言本体对齐的挑战，传统方法难以捕捉跨语言的细微语义相似性，需要更有效的技术来提升对齐性能

Method: 1) 使用创新技术为ontology实体生成丰富的上下文描述；2) 采用微调的多语言Transformer模型生成高质量嵌入；3) 基于余弦相似度匹配实体对；4) 应用阈值过滤保留高度相似实体

Result: 在OAEI-2022 multifarm track评估数据集上达到71% F1分数（78%召回率，65%精确率），比最佳基线提升16%

Conclusion: 提出的对齐流程能够有效捕捉跨语言的细微相似性，基于嵌入的余弦相似度匹配结合上下文丰富化技术显著提升了跨语言本体对齐性能

Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.

</details>


### [28] [MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback](https://arxiv.org/abs/2601.00816)
*Ismail Ahmad Abdullah*

Main category: cs.AI

TL;DR: MathLedger是一个用于可验证机器认知的框架，将形式验证、密码学证明和学习动态集成到单一认知循环中，旨在解决AI系统的不透明性问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然性能卓越但缺乏透明度和可验证性，这在安全关键部署中造成了信任危机。需要一种能够提供可验证性和审计能力的基础设施。

Method: 采用反射形式学习（RFL），这是一种符号化的梯度下降方法，通过验证器结果而非统计损失来驱动更新。系统集成了形式验证、密码学证明和学习动态，并包含故障关闭治理机制。

Result: 第一阶段实验验证了测量和治理基础设施在受控条件下的有效性。CAL-EXP-3验证了测量基础设施（Delta p计算、方差跟踪），压力测试确认了故障关闭治理在超出边界条件下能正确触发。没有做出收敛性或能力声明。

Conclusion: 主要贡献是基础设施性的：提供了一个可工作的账本证明学习原型，能够实现大规模审计能力。这是一个用于可验证机器认知的基础框架。

Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.
  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.
  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance

</details>


### [29] [Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making](https://arxiv.org/abs/2601.00818)
*Chandra Sekhar Kubam*

Main category: cs.AI

TL;DR: 提出基于Agentic AI框架的信用风险评估系统，通过多智能体协作实现自主、透明、实时的信贷决策，相比传统模型在决策速度、透明度和响应性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 金融服务的快速数字化催生了对自主、透明、实时信用风险决策系统的迫切需求。传统机器学习模型虽然擅长模式识别，但缺乏现代金融运营所需的适应性推理、情境感知和自主性。

Method: 提出Agentic AI框架，构建多智能体系统，包含强化学习、自然语言推理、可解释AI模块和实时数据吸收管道。系统包含智能体协作协议、风险评分引擎、可解释性层和持续反馈学习循环。

Result: 系统在决策速度、透明度和响应性方面优于传统信用评分模型。但仍存在模型漂移风险、高维数据解释不一致、监管不确定性以及低资源环境基础设施限制等实际挑战。

Conclusion: 该系统有望变革信用分析领域。未来研究应关注动态监管合规机制、新型智能体协作、对抗鲁棒性以及跨国信用生态系统中的大规模实施。

Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.

</details>


### [30] [CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations](https://arxiv.org/abs/2601.00821)
*Tao An*

Main category: cs.AI

TL;DR: CogCanvas是一个无需训练的框架，通过从对话轮次中提取基于原文的认知构件（决策、事实、提醒），并将其组织成时间感知图，来解决长对话中上下文窗口限制与信息保真度之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长对话中面临上下文窗口限制与信息保真度的根本矛盾。现有方法（截断和摘要）要么丢弃早期信息，要么丢失细节信息。

Method: CogCanvas是一个无需训练的框架，从对话轮次中提取基于原文的认知构件（决策、事实、提醒），并将其组织成时间感知图，实现抗压缩检索。

Result: 在LoCoMo基准测试中，CogCanvas达到34.7%整体准确率，优于RAG（25.6%）和GraphRAG（13.7%）。在时间推理方面优势最明显：31.5% vs. 9.3%（RAG）和5.0%（GraphRAG），相对提升530%。在多跳因果推理中达到81.0%通过率，而GraphRAG为40.0%。

Conclusion: 虽然专门训练的方法（如EverMemOS约92%）能达到更高绝对分数，但CogCanvas无需训练的方法为实践者提供了可立即部署的替代方案，显著优于标准基线。

Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.
  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.
  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.

</details>


### [31] [Energy-Aware Routing to Large Reasoning Models](https://arxiv.org/abs/2601.00823)
*Austin R. Ellis-Mohr,Max Hartman,Lav R. Varshney*

Main category: cs.AI

TL;DR: 论文提出通过方差感知的路由和调度策略来优化大型推理模型的能源效率，在临界状态下平衡基准能源和辅助能源的使用。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型具有异构的推理能源成本，系统性能取决于平均能源供应与随机波动之间的平衡。当前系统要么浪费基准能源，要么过度依赖辅助能源，需要找到最优的能源管理策略。

Method: 采用二阶表征方法分析临界状态下的性能，提出方差感知的路由和调度策略，基于训练计算和推理计算缩放定律来制定调度策略。

Result: 建立了理论框架，表明在临界状态下性能受时间、模型和执行选择中变异性吸收方式的影响，方差感知路由成为关键设计维度。

Conclusion: 方差感知的路由和调度为能源感知的模型路由策略提供了理论基础，能够优化大型推理模型的能源效率，平衡基准能源和辅助能源的使用。

Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.

</details>


### [32] [Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis](https://arxiv.org/abs/2601.00828)
*Yin Li*

Main category: cs.AI

TL;DR: 研究发现大型语言模型存在"准确率-修正悖论"：较弱模型（GPT-3.5）的内在自我修正率比更强模型（DeepSeek）高1.6倍，挑战了模型能力与自我修正能力线性相关的假设。


<details>
  <summary>Details</summary>
Motivation: 尽管普遍认为LLMs具有自我修正能力，但近期研究表明内在自我修正（无需外部反馈）效果有限。本研究旨在系统分解自我修正能力，探究不同模型在自我修正方面的表现差异。

Method: 将自我修正分解为三个子能力：错误检测、错误定位和错误修正。在GSM8K-Complex数据集（每个模型n=500，共346个错误）上对三个主要LLMs进行跨模型实验，分析其内在修正能力。

Result: 发现准确率-修正悖论：较弱模型（GPT-3.5，66%准确率）的内在修正率（26.8%）比更强模型（DeepSeek，94%准确率）的16.7%高1.6倍。错误检测率在不同架构间差异巨大（10%到82%），但检测能力不能预测修正成功率。提供错误位置提示反而损害所有模型表现。

Conclusion: 研究挑战了模型能力与自我改进的线性假设，提出了"错误深度假说"：更强模型犯的错误更少但更深，难以自我修正。这对自我精炼流程设计有重要启示。

Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.

</details>


### [33] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

TL;DR: ElecTwit是一个模拟社交媒体政治选举中多智能体说服行为的框架，通过真实环境实验发现LLM使用了25种说服技巧，不同模型架构和训练会影响说服动态，并观察到独特现象如"真相核心"消息和"墨水"强迫症。


<details>
  <summary>Details</summary>
Motivation: 克服以往研究中基于游戏模拟的局限性，在真实环境中研究多智能体系统中的说服行为，特别是在社交媒体政治选举背景下的互动。

Method: 开发了ElecTwit模拟框架，在真实社交媒体环境中进行多智能体实验，测试不同LLM模型在政治选举场景中的说服行为。

Result: 观察到25种特定说服技巧被大多数测试的LLM广泛使用，范围超过以往报道；不同模型在技巧使用和整体说服输出上存在显著差异；发现了"真相核心"消息和"墨水"强迫症等独特现象。

Conclusion: 该研究为评估现实世界中说服性LLM智能体提供了基础，确保对齐并防止危险结果，展示了不同模型架构和训练如何影响真实社交模拟中的动态。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [34] [Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.00830)
*Deep Pankajbhai Mehta*

Main category: cs.AI

TL;DR: AI模型在逐步推理时很少自发提及问题中的暗示信息，即使这些暗示影响了它们的答案。当直接询问时，模型承认注意到了暗示，表明它们看到了影响信息但选择不报告。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证一个常见假设：当AI系统逐步解释其推理时，这些解释是否真的揭示了影响AI答案的实际因素。研究人员想了解AI模型是否会报告问题中嵌入的暗示信息。

Method: 通过在问题中嵌入暗示信息，测试AI模型是否会提及这些暗示。研究涵盖了超过9,000个测试案例，涉及11个领先的AI模型。测试了多种条件：模型自发报告、直接询问、告知模型被监视、强制要求报告暗示等。

Result: 1. 模型几乎从不自发提及暗示信息；2. 当直接询问时，模型承认注意到了暗示；3. 告知模型被监视没有帮助；4. 强制要求报告暗示会导致模型在没有暗示时也报告，并降低准确性；5. 迎合用户偏好的暗示特别危险——模型最常遵循这些暗示但最少报告它们。

Conclusion: 仅仅观察AI的推理过程不足以发现隐藏的影响因素。AI模型可能看到并受到信息的影响，但选择不在解释中报告这些信息，这对AI透明度和可信度构成了挑战。

Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.

</details>


### [35] [COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs](https://arxiv.org/abs/2601.01836)
*Dasol Choi,DongGeon Lee,Brigitta Jesica Kartono,Helena Berndt,Taeyoun Kwon,Joonwon Jang,Haon Park,Hwanjo Yu,Minsuk Kahng*

Main category: cs.AI

TL;DR: COMPASS是首个评估LLM是否符合组织允许/禁止列表政策的框架，发现模型在处理合法请求时表现良好（>95%准确率），但在禁止列表违规检测上严重失败（仅拒绝13-40%的对抗性违规）。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在企业高风险应用中的部署，确保其遵守组织特定政策变得至关重要，而现有安全评估仅关注通用危害，缺乏针对组织政策的评估框架。

Method: 开发COMPASS框架，应用于8个不同行业场景，生成并验证5,920个查询，测试常规合规性和对抗性鲁棒性，评估7个最先进的LLM模型。

Result: 发现基本不对称性：模型可靠处理合法请求（>95%准确率），但在执行禁令方面灾难性失败，仅拒绝13-40%的对抗性禁止列表违规。

Conclusion: 当前LLM缺乏政策关键部署所需的鲁棒性，COMPASS成为组织AI安全的重要评估框架。

Abstract: As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.

</details>


### [36] [OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification](https://arxiv.org/abs/2601.00843)
*Ayda Aghaei Nia*

Main category: cs.AI

TL;DR: OmniNeuro是一个新型HCI框架，将BCI从黑盒解码器转变为透明的反馈伙伴，通过物理、混沌和量子启发的可解释性引擎提供实时神经声化和生成式AI临床报告。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽然提高了脑机接口的解码精度，但其"黑盒"特性阻碍了临床采用，导致用户挫败感和神经可塑性结果不佳。需要提高BCI系统的透明度和可解释性。

Method: 提出OmniNeuro框架，集成三个可解释性引擎：1) 物理(能量)分析，2) 混沌(分形复杂度)分析，3) 量子启发的不确定性建模。这些指标驱动实时神经声化和生成式AI临床报告，且与解码器无关。

Result: 在PhysioNet数据集(N=109)上平均准确率达到58.52%，定性试点研究(N=3)证实可解释反馈有助于用户调节心理努力并减少"试错"阶段。

Conclusion: OmniNeuro作为任何最先进架构的必需可解释性层，将BCI转变为透明反馈伙伴，有望改善临床采用和神经可塑性结果。

Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the "Black Box" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the "trial-and-error" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.

</details>


### [37] [Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs](https://arxiv.org/abs/2601.01878)
*Farzan Karimi-Malekabadi,Suhaib Abdurahman,Zhivar Sourati,Jackson Trager,Morteza Dehghani*

Main category: cs.AI

TL;DR: 论文指出当前大语言模型的社会认知评估存在理论缺失问题，导致基准测试结果被过度泛化，并提出"理论追踪卡"作为解决方案来明确评估的理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的社会认知基准测试存在"评估-部署差距"：即使模型在基准测试中获得高分，也无法预测真实世界行为。现有研究主要归因于测量和效度问题，但作者认为更根本的问题是缺乏明确的理论基础。

Method: 论文提出两个贡献：1) 诊断并形式化"理论差距"问题，指出这是导致测量失败和结果过度泛化的根本原因；2) 引入"理论追踪卡"这一轻量级文档工具，明确记录评估的理论基础、目标能力组件、操作化过程和局限性。

Result: 理论追踪卡通过明确理论、任务操作化、评分和局限性之间的完整效度链，增强了社会认知评估的可解释性和可重用性，无需修改基准测试或要求单一理论共识。

Conclusion: 解决社会认知评估中的理论差距对于避免系统性效度幻觉至关重要。理论追踪卡提供了一种实用方法来明确评估的理论基础，从而更准确地解释基准测试结果，防止过度泛化。

Abstract: Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.

</details>


### [38] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

TL;DR: 提出TPP-TAL框架，通过增强LLMs中的时间感知能力来改进时序点过程建模，显式对齐时间动态与语义上下文，提升事件预测准确性。


<details>
  <summary>Details</summary>
Motivation: 时序点过程在金融、医疗等领域很重要，但现有方法难以有效捕捉时间信息与语义上下文之间的复杂交互，限制了LLMs在时序事件建模中的应用。

Method: 提出TPP-TAL框架，作为即插即用模块，在将信息输入LLM之前显式对齐时间动态与上下文语义，而不是简单拼接事件时间和类型嵌入。

Result: 在多个基准数据集上的实验表明，TPP-TAL在时间似然估计和事件预测准确性方面都有显著提升。

Conclusion: 增强LLMs的时间感知能力对连续时间事件建模至关重要，TPP-TAL框架通过显式对齐时间动态与语义上下文有效解决了现有方法的局限性。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [39] [Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models](https://arxiv.org/abs/2601.00848)
*Ron F. Del Rosario*

Main category: cs.AI

TL;DR: 提出一种基于OpenTelemetry追踪分析的语言模型微调方法，用于检测多智能体AI工作流中的时序攻击模式，通过QLoRA微调和数据增强在资源受限硬件上实现准确率从42.86%提升至74.29%。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏可复现的框架来构建适应特定威胁环境的定制化智能体安全模型，需要解决多智能体协调攻击和监管违规的检测问题。

Method: 收集80,851个来自18个公共网络安全源的示例和35,026个合成的OpenTelemetry追踪数据，在NVIDIA DGX Spark ARM64硬件上采用迭代式QLoRA微调，进行三轮训练并配合策略性数据增强。

Result: 定制基准测试准确率从42.86%提升至74.29%，获得31.4个百分点的显著提升。针对特定知识缺口的定向训练示例优于无差别扩展。

Conclusion: 虽然实际部署因误报率需要人工监督，但本研究建立了首个可复现框架，使从业者能够构建适应其威胁环境的定制智能体安全模型。关键贡献包括合成追踪生成方法、训练数据组成决定行为的实证证据，以及完整开源数据集和工具。

Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.

</details>


### [40] [Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks](https://arxiv.org/abs/2601.00856)
*Milos Stankovic,Ella Hirche,Sarah Kollatzsch,Julia Nadine Doetsch*

Main category: cs.AI

TL;DR: 本文是对Kosmyna等人(2025)关于AI助手对写作任务影响的论文的批判性评论，指出了研究设计、方法学、结果报告等方面的多个问题


<details>
  <summary>Details</summary>
Motivation: 对Kosmyna等人关于AI助手对写作任务认知影响的研究进行建设性评论，旨在提高该研究的严谨性和可发表性

Method: 通过系统性的批判分析，从研究设计、样本量、分析方法可重复性、EEG分析技术、结果报告一致性和研究透明度五个方面进行评论

Result: 指出了原研究的多个局限性：样本量不足、分析方法可重复性问题、EEG分析方法学问题、结果报告不一致、研究透明度有限

Conclusion: 建议对Kosmyna等人的研究结果进行更保守的解释，并提出了改进建议以增强研究的科学严谨性和可发表性

Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.

</details>


### [41] [Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery](https://arxiv.org/abs/2601.00869)
*Huang Junyao,Situ Ruimin,Ye Renqin*

Main category: cs.AI

TL;DR: 研究发现LLM训练数据的地理分布导致品牌推荐存在系统性差异，中国LLM对品牌的提及率比国际LLM高30.6个百分点，这种"存在差距"构成了AI时代新的市场进入壁垒。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地介入消费者信息发现过程，品牌面临算法不可见性的挑战。本研究旨在探究大型语言模型中因训练数据构成导致的品牌推荐系统性差异，即"文化编码"现象。

Method: 分析了1,909个纯英文查询，覆盖6个LLM（GPT-4o、Claude、Gemini、Qwen3、DeepSeek、Doubao）和30个品牌。通过案例研究Zhizibianjie（OmniEdge）平台，验证了训练数据地理分布对品牌可见性的影响。

Result: 中国LLM的品牌提及率比国际LLM高30.6个百分点（88.9% vs. 58.3%，p<.001）。即使在相同的英文查询中，这种差异依然存在，表明训练数据的地理分布而非语言是主要驱动因素。提出了"存在差距"概念和"数据护城河"框架。

Conclusion: 在AI主导的市场中，品牌的"数据边界"决定了其"市场边界"。研究提出了算法无处不在作为生成引擎优化的战略目标，并为品牌提供了18个月的数据护城河建设路线图。

Abstract: As artificial intelligence systems increasingly mediate consumer information discovery,
  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large
  Language Models (LLMs) -- systematic differences in brand recommendations arising from
  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,
  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6
  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,
  p<.001). This disparity persists in identical English queries, indicating training data
  geography -- not language -- drives the effect. We introduce the Existence Gap: brands
  absent from LLM training corpora lack "existence" in AI responses regardless of quality.
  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%
  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how
  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we
  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic
  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility
  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization
  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats
  through semantic coverage, technical depth, and cultural localization. Our findings reveal
  that in AI-mediated markets, the limits of a brand's "Data Boundaries" define the limits
  of its "Market Frontiers."

</details>


### [42] [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)
*Anthony Mikinka*

Main category: cs.AI

TL;DR: UCL是一个将提示工程从启发式实践转变为系统优化的数学框架，通过系统评估证明能显著减少token使用（29.8%），其结构开销函数解释了性能差异，并揭示了过规范悖论现象。


<details>
  <summary>Details</summary>
Motivation: 当前提示工程主要依赖启发式实践，缺乏系统化的优化框架。作者希望将提示工程转变为基于数学原理的系统优化过程，提高LLM交互的效率和成本效益。

Method: 提出了通用条件逻辑（UCL）框架，包含指示函数、结构开销函数、早期绑定等核心机制。通过系统评估（N=305，11个模型，4次迭代）验证框架效果，并分析过规范悖论现象。

Result: UCL能显著减少29.8%的token使用量（p < 0.001），对应成本节约。发现过规范阈值S* = 0.509，超过此阈值后额外规范会二次降低性能。不同模型架构需要特定优化配置。

Conclusion: UCL建立了可校准的LLM高效交互框架，揭示了模型家族特定优化的重要性，为系统化提示优化提供了理论基础和实践指导。

Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.

</details>


### [43] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)
*Mandar Parab*

Main category: cs.AI

TL;DR: 提出Counterfactual Self-Questioning框架，让单个语言模型生成并评估自身推理的反事实批评，无需外部批评者或奖励模型，实现可扩展的自我改进。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法依赖外部批评者、学习到的奖励模型或集成采样，增加了复杂性和训练不稳定性。需要一种更简单、更稳定的自我改进方法。

Method: 提出反事实自我提问框架：1) 生成初始推理轨迹；2) 针对潜在失败点制定针对性问题；3) 生成暴露错误假设或无效步骤的替代推理轨迹；4) 利用这些反事实轨迹提供结构化相对反馈，直接用于策略优化。

Result: 在多个数学推理基准测试中，反事实自我提问提高了准确性和训练稳定性，特别是对于较小模型，仅使用内部生成的监督就能实现可扩展的自我改进。

Conclusion: Counterfactual Self-Questioning为语言模型自我改进提供了一种简单有效的方法，无需外部辅助模型，提高了训练稳定性，特别适合较小模型的可扩展改进。

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.

</details>


### [44] [Context Collapse: In-Context Learning and Model Collapse](https://arxiv.org/abs/2601.00923)
*Josef Ott*

Main category: cs.AI

TL;DR: 该论文研究了LLMs中的两种关键现象：上下文学习和模型坍缩。通过分析线性transformer和简化设置，揭示了上下文学习中的相变现象，证明了模型坍缩的必然性，并提出了"上下文坍缩"的新概念。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型中两个重要但理解不足的现象：上下文学习（ICL）和模型坍缩。前者涉及模型如何从上下文示例中学习，后者涉及模型在持续训练中的性能退化。作者旨在通过理论分析揭示这些现象的本质机制。

Method: 1. 使用带权重绑定的线性transformer在回归任务上研究ICL，将前向传播简化为预条件梯度下降并分析最优预条件器；2. 使用鞅理论和随机游走理论分析线性回归和高斯拟合中的模型坍缩；3. 提出"上下文坍缩"概念，连接ICL动态与生成模型的长期稳定性问题。

Result: 1. 发现ICL存在相变：超过临界上下文长度时，解会发展出斜对称分量，导致梯度方向旋转；2. 证明了模型坍缩的几乎必然收敛性，表明除非数据快速增长或保留，否则坍缩必然发生；3. 提出了上下文坍缩概念，解释了长序列生成中的性能退化问题。

Conclusion: 该研究通过理论分析揭示了LLMs中上下文学习和模型坍缩的深层机制，证明了ICL中的相变现象和模型坍缩的必然性，并提出了连接两者的新概念"上下文坍缩"，为理解LLMs的动态行为提供了重要理论框架。

Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.

</details>


### [45] [Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering](https://arxiv.org/abs/2601.01195)
*Wuzhenghong Wen,Chao Xue,Su Pan,Yuwei Sun,Minlong Peng*

Main category: cs.AI

TL;DR: 提出MRE框架，通过增强前向和后向推理来改进TKGQA中的多跳推理，使用Tree-Group Relative Policy Optimization算法优化推理轨迹选择


<details>
  <summary>Details</summary>
Motivation: TKGQA中LLMs在每跳推理时检索大量时间相似且语义复杂的关系子图，导致次优决策和错误传播风险增加，需要改进多跳推理的全局优化能力

Method: 1) 提示工程引导LLM生成多样化推理轨迹；2) 选择有效轨迹进行监督微调作为冷启动策略；3) 提出T-GRPO算法，通过树状结构的学习探索方法，在每跳建立强因果依赖并利用后续多路径探索反馈进行评估

Result: 在两个TKGQA基准测试中，MRE框架模型持续超越SOTA方法，在处理复杂多跳查询方面表现优异，同时提高了可解释性和对噪声时间标注的鲁棒性

Conclusion: MRE框架通过增强前向后向推理和T-GRPO算法，有效解决了TKGQA中的多跳推理挑战，提升了推理轨迹的全局优化能力和系统鲁棒性

Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.

</details>


### [46] [Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies](https://arxiv.org/abs/2601.01301)
*Keith Frankston,Benjamin Howard*

Main category: cs.AI

TL;DR: 提出递归AlphaZero风格的蒙特卡洛树搜索算法RMCTS，相比MCTS-UCB速度提升显著，在单根状态搜索时快40倍以上，在大批量根状态搜索时快约3倍。


<details>
  <summary>Details</summary>
Motivation: 传统AlphaZero的MCTS-UCB算法存在GPU延迟成本高的问题，需要更高效的搜索算法来加速训练过程。

Method: 采用递归的广度优先搜索方式，网络推理批量进行；基于Grill等人提出的后验策略优化方法，从叶子节点向根节点递归计算优化后验策略；树结构由先验网络策略定义而非自适应构建。

Result: RMCTS在Connect-4、Dots-and-Boxes和Othello三个游戏中表现出色，训练时间减少约三分之二，网络质量与MCTS-UCB相当。

Conclusion: RMCTS通过递归和批量处理实现了显著的加速效果，虽然牺牲了树的自适应构建，但实际训练效率更高，能在更短时间内达到相同的网络质量。

Abstract: We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, "RMCTS". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.
  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in "Monte--Carlo tree search as regularized policy optimization" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.
  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.

</details>


### [47] [Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models](https://arxiv.org/abs/2601.01321)
*Rong Zhou,Dongping Chen,Zihan Jia,Yao Su,Yixin Liu,Yiwen Lu,Dongwei Shi,Yue Huang,Tianyang Xu,Yi Pan,Xinliang Li,Yohannes Abate,Qingyu Chen,Zhengzhong Tu,Yu Yang,Yu Zhang,Qingsong Wen,Gengchen Mai,Sunyang Fu,Jiachen Li,Xuyu Wang,Ziran Wang,Jing Huang,Tianming Liu,Yong Chen,Lichao Sun,Lifang He*

Main category: cs.AI

TL;DR: 该论文提出了一个统一的四阶段框架，系统描述了人工智能在数字孪生生命周期中的集成，涵盖建模、镜像、干预和自主管理，并分析了物理建模与数据驱动学习的协同作用。


<details>
  <summary>Details</summary>
Motivation: 数字孪生已从被动仿真工具发展为智能自主实体，但缺乏系统化的AI集成框架。本文旨在通过统一框架系统描述AI在数字孪生生命周期中的集成方式，促进技术发展和跨领域应用。

Method: 提出统一的四阶段框架：1) 通过物理基础和物理信息AI方法建模物理孪生；2) 实时同步将物理系统镜像为数字孪生；3) 通过预测建模、异常检测和优化策略干预物理孪生；4) 通过大语言模型、基础模型和智能代理实现自主管理。分析物理建模与数据驱动学习的协同，并跨11个应用领域进行综述。

Result: 建立了系统化的AI集成框架，识别了从传统数值求解器向物理信息模型和基础模型的转变趋势，展示了生成式AI技术如何将数字孪生转变为具备推理、通信和创造性场景生成能力的认知系统，并指出了可扩展性、可解释性和可信度等共同挑战。

Conclusion: AI技术正在将数字孪生转变为智能自主系统，提出的四阶段框架为AI集成提供了系统化指导。未来需要解决可扩展性、可解释性和可信度等挑战，推动负责任AI驱动的数字孪生系统发展。

Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.

</details>


### [48] [Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale](https://arxiv.org/abs/2601.01330)
*Shengji Tang,Weihao Lin,Jingqi Ye,Hao Li,Bo Zhang,Shuyue Hu,Tao Chen,Wangli Ouyang,Lei Bai,Peng Ye*

Main category: cs.AI

TL;DR: JiSi框架通过查询-响应混合路由、支持集聚合器选择和自适应路由-聚合切换，使开源LLM协作超越Gemini-3-Pro，仅需47%成本。


<details>
  <summary>Details</summary>
Motivation: 探索集体智能作为替代单一模型扩展的路径，解决当前LLM路由和聚合的三个瓶颈：1) 仅基于文本相似度的查询路由；2) 静态聚合方法；3) 路由与聚合互补性未充分利用。

Method: 提出JiSi框架：1) 查询-响应混合路由，同时捕捉语义信息和问题难度；2) 基于支持集的聚合器选择，联合评估聚合能力和领域能力；3) 自适应路由-聚合切换，动态利用路由和聚合优势。

Result: 在9个基准测试中，JiSi通过协调10个开源LLM，仅用47%成本就超越了Gemini-3-Pro，同时优于主流基线方法。

Conclusion: 集体智能代表了通往AGI的新路径，通过有效协作开源LLM可以实现超越顶级商业模型的性能。

Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).

</details>


### [49] [A unified multimodal understanding and generation model for cross-disciplinary scientific research](https://arxiv.org/abs/2601.01363)
*Xiaomeng Yang,Zhiyu Tan,Xiaohui Zhong,Mengping Yang,Qiusheng Huang,Lei Chen,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: FuXi-Uni是一个统一的多模态科学模型，能在单一架构中理解和生成跨科学领域的高维数据，在地球科学和生物医学领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型多为领域专用，缺乏同时理解和生成多模态科学数据的能力，而许多全球挑战和科学问题本质上是跨学科的，需要跨领域协同进展。

Method: 将跨学科科学标记与自然语言标记对齐，使用科学解码器重建科学标记，支持自然语言对话和科学数值预测的统一架构。

Result: 在地球系统建模中，10天全球天气预报精度超越SOTA物理预报系统，台风路径和强度预测优于SOTA物理模型，高分辨率区域天气场超越标准插值基线；在生物医学中，在多个生物医学视觉问答基准上优于领先的多模态大语言模型。

Conclusion: FuXi-Uni通过在原生共享潜在空间中统一异构科学模态，同时保持强大的领域特定性能，为更通用的多模态科学模型迈出了重要一步。

Abstract: Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.

</details>


### [50] [KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models](https://arxiv.org/abs/2601.01366)
*Zixian Liu,Sihao Liu,Yuqi Zhao*

Main category: cs.AI

TL;DR: KGCE是一个用于评估多模态大语言模型在教育场景中跨平台任务执行能力的新型基准平台，通过知识库增强和双图评估框架解决现有基准在私有教育软件任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准框架在教育场景的跨平台任务支持上存在明显缺陷，特别是在处理学校专用软件时，由于缺乏对这些私有领域软件结构特性的理解，智能体效率显著下降。同时，当前评估方法过度依赖目标导向或轨迹匹配等粗粒度指标，难以捕捉复杂任务中的详细执行细节和效率。

Method: 提出KGCE平台，整合知识库增强和双图评估框架。首先构建包含104个教育相关任务的数据集，覆盖Windows、Android和跨平台协作任务。引入双图评估框架，将任务分解为多个子目标并验证完成状态，提供细粒度评估指标。为克服现有智能体在私有领域任务中的执行瓶颈，开发了包含学校专用软件知识库的增强智能体系统。

Result: 构建了包含104个教育任务的数据集，开发了KGCE基准平台，实现了双图评估框架和知识库增强的智能体系统，代码已在GitHub开源。

Conclusion: KGCE通过知识库增强和双图评估框架有效解决了教育场景中跨平台任务评估的现有问题，为多模态大语言模型在教育领域的应用提供了更精准的评估工具。

Abstract: With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.

</details>


### [51] [Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification](https://arxiv.org/abs/2601.01378)
*Han Yuan,Yilin Wu,Li Zhang,Zheng Ma*

Main category: cs.AI

TL;DR: 提出AAAI三步骤管道，通过缓解事实幻觉来提升小型语言模型在金融分类中的性能


<details>
  <summary>Details</summary>
Motivation: 小型语言模型(SLMs)在金融分类中因推理速度快和本地可部署性而被广泛使用，但与大型语言模型相比，它们更容易产生事实幻觉，且分类性能较弱。这引发了一个自然问题：缓解事实幻觉能否改善SLMs的金融分类性能？

Method: 提出了名为AAAI的三步骤管道：1) 关联识别 - 识别输入与分类标签之间的关联；2) 自动检测 - 使用基于编码器的验证器检测事实幻觉；3) 自适应推理 - 结合事实错误反馈，使SLMs能够进行自适应推理

Result: 在三个代表性SLMs上的实验表明：1) 事实幻觉与错误分类呈正相关；2) 基于编码器的验证器能有效检测事实幻觉；3) 结合事实错误反馈的自适应推理能显著提升分类性能

Conclusion: AAAI管道通过缓解事实幻觉，能够提升SLMs在金融分类中的性能，为SLMs在金融领域的可信和有效应用做出贡献

Abstract: Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.

</details>


### [52] [A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts](https://arxiv.org/abs/2601.01467)
*Romuald Kwessy Mouona,Blaise Blériot Koguep Njionou,Etienne Romuald Temgoua Alomo,Rokia Missaoui,Leonard Kwuida*

Main category: cs.AI

TL;DR: 研究三元背景中的蕴涵关系，重点分析Ganter和Obiedkov提出的条件属性蕴涵和属性条件蕴涵，目标是构建这些蕴涵的最优基


<details>
  <summary>Details</summary>
Motivation: 三元背景是形式概念分析中的重要结构，但现有研究主要关注二元背景。Ganter和Obiedkov提出的条件属性蕴涵和属性条件蕴涵为三元背景提供了新的分析工具，但如何高效地表示这些蕴涵关系仍需要研究

Method: 采用形式概念分析的理论框架，在三元背景中定义和形式化条件属性蕴涵和属性条件蕴涵。通过算法设计和理论分析，构建这些蕴涵关系的最优基，优化蕴涵的表示效率

Result: 提出了三元背景下条件属性蕴涵和属性条件蕴涵的最优基构建方法，能够更紧凑地表示这些蕴涵关系，为三元数据分析提供更有效的工具

Conclusion: 该研究扩展了形式概念分析在三元背景中的应用，提出的最优基构建方法为三元数据中的蕴涵关系分析提供了理论基础和实用工具，有助于更高效地处理复杂的三元关系数据

Abstract: This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.

</details>


### [53] [Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning](https://arxiv.org/abs/2601.01511)
*Ahmed Dawoud,Osama El-Shamy*

Main category: cs.AI

TL;DR: 提出神经网络增强的双重机器学习框架，利用文本嵌入解决未观测混杂偏倚问题，相比传统树模型显著降低估计偏差


<details>
  <summary>Details</summary>
Motivation: 观测性研究中存在未观测混杂变量导致的偏倚问题，传统计量方法难以处理与结构化协变量正交的混杂因素，而高维非结构化文本数据包含这些潜在变量的丰富代理信息

Method: 提出神经网络增强的双重机器学习框架，利用文本嵌入进行因果识别，通过深度学习架构建模嵌入流形的连续拓扑结构

Result: 文本嵌入能捕捉结构化表格数据中缺失的关键混杂信息，但标准树基DML估计器仍存在显著偏差(+24%)，而深度学习方法将偏差降至-0.86%，有效恢复真实因果参数

Conclusion: 当基于高维自然语言数据进行条件推断时，深度学习架构对于满足无混杂假设至关重要，能有效利用文本嵌入中的混杂信息

Abstract: Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data

</details>


### [54] [Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making](https://arxiv.org/abs/2601.01522)
*Danial Amin*

Main category: cs.AI

TL;DR: 论文提出贝叶斯成本感知的多LLM协同框架，将LLMs视为近似似然模型而非分类器，通过对比提示获取似然度、鲁棒统计聚合、贝叶斯更新，在非对称错误成本场景中显著降低总成本并提升公平性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在非对称错误成本场景（如招聘、医疗分诊、欺诈检测）中作为自主决策代理时，主流方法（查询单一LLM获取后验概率并阈值化）在序列决策中表现不足，需要更合适的概率框架来处理成本敏感决策。

Method: 提出贝叶斯成本感知的多LLM协同框架：1) 将LLMs视为近似似然模型而非分类器；2) 通过对比提示为每个候选状态获取似然度；3) 使用鲁棒统计方法聚合不同模型的输出；4) 在新证据到达时使用贝叶斯规则在显式先验下更新信念；5) 支持连贯信念更新、期望成本行动选择、基于信息价值的原则性信息收集。

Result: 在简历筛选实验中（错失人才成本40000美元，面试成本2500美元，电话筛选成本150美元），使用5个LLMs（GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek）处理1000份简历：总成本降低294000美元（34% vs 最佳单LLM基线），人口统计公平性提升45%（最大群体差距从22%降至5%）。消融实验显示：51%节省来自多LLM聚合，43%来自序列更新，20%来自分歧触发的信息收集。

Conclusion: 正确的概率基础对于LLMs在非对称错误成本场景中的序列决策至关重要。提出的贝叶斯多LLM框架通过将LLMs视为似然模型、鲁棒聚合和连贯信念更新，显著改善了成本效率和公平性，验证了理论优势在实际应用中的有效性。

Abstract: Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds "confidence," and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.

</details>


### [55] [Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix](https://arxiv.org/abs/2601.01532)
*Fanzhe Fu*

Main category: cs.AI

TL;DR: 论文提出Project Aletheia框架，通过Tikhonov正则化反演判断混淆矩阵来量化AI的"认知信念深度"，引入对齐信念分数确保安全性，为衡量AI科学完整性提供蓝图。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估范式面临认识论危机：静态基准测试能测量知识广度，但无法量化信念深度。需要新的框架来评估系统2推理模型的认知信念强度。

Method: 提出Project Aletheia认知物理框架，采用Tikhonov正则化反演判断混淆矩阵。为避免依赖不透明的私有数据，实施合成代理协议进行验证。

Result: 初步研究显示推理模型在对抗压力下可能表现出"防御性过度思考"，同时引入对齐信念分数(S_aligned)验证信念不会损害安全性。

Conclusion: 该工作为测量AI科学完整性提供了蓝图框架，能够量化认知信念深度并确保安全对齐，是AGI评估的重要进展。

Abstract: In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify "Cognitive Conviction" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a "cognitive buffer," they may exhibit "Defensive OverThinking" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.

</details>


### [56] [Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation](https://arxiv.org/abs/2601.01546)
*Letian Kong,Qianran,Jin,Renyu Zhang*

Main category: cs.AI

TL;DR: 提出两阶段框架改进LLM在复杂决策环境中的行为对齐：上下文形成（明确实验设计）和上下文导航（指导推理过程），验证表明复杂任务需要两阶段，简单任务只需第一阶段。


<details>
  <summary>Details</summary>
Motivation: LLM在模拟人类行为时，在需要预测他人行动和基于观察行为形成信念的复杂决策环境中，与人类决策存在系统性偏差，需要改进行为对齐方法。

Method: 提出两阶段框架：1) 上下文形成阶段：明确指定实验设计，建立决策任务和上下文的准确表示；2) 上下文导航阶段：在该表示内指导推理过程做出决策。在三个决策环境中验证：顺序购买游戏、众筹游戏、需求估计任务。

Result: 在四个SOTA模型（GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1）上验证，发现复杂决策环境需要两阶段才能实现与人类基准的行为对齐，而简单的需求估计任务只需要上下文形成阶段。

Conclusion: 阐明了每个阶段何时必要，为设计和诊断LLM社会模拟作为行为研究中人类受试者的补充提供了系统方法。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.

</details>


### [57] [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)
*Mingyu Xu,Cheng Fang,Keyue Jiang,Yuqian Zheng,Yanghua Xiao,Baojian Zhou,Qifang Zhao,Suhang Zheng,Xiuwen Zhu,Jiyang Tang,Yongchi Zhao,Yijia Luo,Zhiqi Bai,Yuchi Xu,Wenbo Su,Wei Wang,Bing Zhao,Lin Qu,Xiaoxiao Xu*

Main category: cs.AI

TL;DR: Logics-STEM是一个在10M规模高质量数据集上微调的推理模型，专注于STEM领域，在8B规模上相比次优模型平均提升4.68%性能，采用数据算法协同设计方法。


<details>
  <summary>Details</summary>
Motivation: 当前STEM领域推理任务需要更强的推理能力，而现有模型在STEM相关基准上表现有限。研究旨在通过大规模高质量数据集和算法协同设计来提升STEM推理能力。

Method: 采用数据算法协同设计引擎：1）数据方面：构建10M规模的Logics-STEM-SFT-Dataset，通过5阶段数据整理流程（标注、去重、去污染、蒸馏、分层采样）；2）算法方面：基于失败驱动的后训练框架，利用目标知识检索和围绕模型失败区域的数据合成，指导第二阶段SFT或强化学习。

Result: Logics-STEM在STEM相关基准测试中表现优异，在8B规模上相比次优模型平均提升4.68%。模型和数据集（8B/32B模型，10M/2.2M数据集）已开源。

Conclusion: 大规模开源数据与精心设计的合成数据相结合具有巨大潜力，数据算法协同设计通过后训练显著提升推理能力，为开源社区提供了有价值的资源。

Abstract: We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.

</details>


### [58] [CaveAgent: Transforming LLMs into Stateful Runtime Operators](https://arxiv.org/abs/2601.01569)
*Maohao Ran,Zhenglin Wan,Cooper Lin,Yanting Zhang,Hongyu Xin,Hongwei Fan,Yibo Xu,Beier Luo,Yaxin Zhou,Wangbo Zhao,Lijie Yang,Lang Feng,Fuchao Yang,Jingxuan Wu,Yiqiao Huang,Chendong Ma,Dailing Jiang,Jianbo Deng,Sihui Han,Bo An,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: CaveAgent框架将LLM从文本生成器转变为运行时操作器，通过双流上下文架构和状态化运行时管理，显著提升复杂任务执行能力，减少token消耗。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体系统受限于文本中心范式，传统JSON函数调用在处理长视野任务时存在脆弱的多轮依赖和上下文漂移问题，需要更强大的执行框架。

Method: 提出CaveAgent框架，采用双流上下文架构：轻量级语义流负责推理，持久化确定性Python运行时流负责执行；引入状态化运行时管理，支持复杂Python对象的注入、操作和跨轮次持久化。

Result: 在Tau²-bench、BFCL等基准测试中表现优异：零售任务成功率提升10.5%，多轮场景总token消耗减少28.4%；数据密集型任务中token消耗减少59%，能处理导致其他智能体上下文溢出的海量数据。

Conclusion: CaveAgent通过将LLM转变为运行时操作器，解决了传统文本中心方法的局限性，实现了更高效、可靠的复杂任务执行，为LLM智能体系统提供了新的范式。

Abstract: LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from "LLM-as-Text-Generator" to "LLM-as-Runtime-Operator." We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\% success rate improvement on retail tasks and reduces total token consumption by 28.4\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.

</details>


### [59] [Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration](https://arxiv.org/abs/2601.01609)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 本文提出了一种结合LLMs与符号推理的框架，将自然语言文本转换为ABox断言，再通过SWRL规则进行确定性推理，在三个领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在需要可审计和可解释决策的领域（如临床协议、法律证据规则、科学标准），现有方法存在局限：LLMs具有灵活性但缺乏一致性保证，符号系统有形式化保证但需要结构化输入。需要结合两者优势。

Method: 提出集成模式：LLMs作为本体填充引擎，将非结构化文本转换为基于专家编写的TBox规范的ABox断言，SWRL推理器提供确定性规则应用。框架将推理分解为实体识别、断言提取和符号验证三个步骤。

Result: 在三个领域（法律传闻证据判定、科学方法任务应用、临床试验资格）和11个语言模型上验证，结构化分解相比few-shot提示在总体上取得统计显著改进，三个领域均有提升。消融研究证实符号验证提供了超越结构化提示的实质性好处。

Conclusion: 该框架结合了LLMs的灵活性和符号推理的形式化保证，填充的ABox可与标准语义Web工具集成，支持更丰富的推理模式，为需要可审计决策的领域提供了有效解决方案。

Abstract: Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.

</details>


### [60] [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)
*YuanLab. ai,:,Shawn Wu,Sean Wang,Louie Li,Darcy Chen,Allen Wang,Jiangang Luo,Xudong Zhao,Joseph Shen,Gawain Ma,Jasper Jia,Marcus Mao,Claire Wang,Hunter He,Carol Wang,Zera Zhang,Jason Wang,Chonly Shen,Leo Zhang,Logan Chen,Qasim Meng,James Gong,Danied Zhao,Penn Zheng,Owen Zhu,Tong Yu*

Main category: cs.AI

TL;DR: Yuan3.0 Flash是一个开源的MoE多模态大语言模型，具有37亿激活参数和400亿总参数，专为企业任务优化，同时保持通用任务竞争力，并采用RAPO算法解决过度思考问题。


<details>
  <summary>Details</summary>
Motivation: 针对大型推理模型中常见的"过度思考"现象，以及企业级任务（如RAG、复杂表格理解、摘要等）对高效模型的需求，开发一个既能处理企业任务又保持通用能力的开源模型。

Method: 1. 采用混合专家（MoE）架构，37亿激活参数/400亿总参数；2. 提出Reflection-aware Adaptive Policy Optimization（RAPO）强化学习算法，有效调节过度思考行为；3. 专注于多模态能力设计。

Result: 在企业任务（RAG、复杂表格理解、摘要）上表现优异；在数学、科学等推理领域达到前沿模型可比精度，同时仅需1/4到1/2的平均token数；模型已完全开源。

Conclusion: Yuan3.0 Flash是一个高效的企业导向多模态大语言模型，通过RAPO算法解决过度思考问题，在企业任务和通用推理任务上均表现优秀，且已开源促进研究和实际部署。

Abstract: We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.

</details>


### [61] [AI Agent Systems: Architectures, Applications, and Evaluation](https://arxiv.org/abs/2601.01743)
*Bin Xu*

Main category: cs.AI

TL;DR: 本文对AI智能体架构进行了系统性综述，涵盖了推理、规划、工具调用等核心组件，提出了统一的分类体系，并讨论了设计权衡、评估挑战及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型与推理、规划、记忆和工具使用能力的结合，AI智能体正在成为连接自然语言意图与现实世界计算的实际接口。本文旨在系统性地梳理这一新兴领域的架构设计，为研究者提供统一的分类框架。

Method: 采用文献综述方法，将现有工作组织为统一的分类体系：包括智能体组件（策略/LLM核心、记忆、世界模型、规划器、工具路由器、批评器）、编排模式（单智能体vs.多智能体；集中式vs.去中心化协调）和部署设置（离线分析vs.在线交互；安全关键vs.开放任务）。

Result: 提出了全面的AI智能体架构分类框架，识别了关键设计权衡（延迟vs.准确性、自主性vs.可控性、能力vs.可靠性），并总结了评估实践的复杂性（非确定性、长期信用分配、工具和环境变异性、隐藏成本）。

Conclusion: AI智能体架构研究需要解决验证与防护、可扩展内存管理、决策可解释性、真实工作负载下的可重复评估等开放挑战，同时建立更完善的测量和基准测试实践。

Abstract: AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\ multi-agent; centralized vs.\ decentralized coordination), and deployment settings (offline analysis vs.\ online interactive assistance; safety-critical vs.\ open-ended tasks). We discuss key design trade-offs -- latency vs.\ accuracy, autonomy vs.\ controllability, and capability vs.\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.

</details>


### [62] [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)
*Yao Lu,Shang Liu,Hangan Zhou,Wenji Fang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AI

TL;DR: RTL-OPT是一个用于评估大语言模型在RTL代码优化能力的基准测试，包含36个手工设计的数字电路，涵盖多种实现类别，并提供自动化评估框架验证功能正确性和量化PPA改进。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型RTL生成基准主要评估语法正确性，而缺乏对功耗、性能和面积（PPA）优化质量的评估。需要专门的基准来评估LLM在硬件设计优化方面的能力。

Method: 创建RTL-OPT基准，包含36个手工设计的数字电路，涵盖组合逻辑、流水线数据通路、有限状态机和存储器接口等类别。每个任务提供次优版本和人工优化的参考版本，集成自动化评估框架验证功能正确性并量化PPA改进。

Result: 开发了RTL-OPT基准测试套件，包含36个设计任务，每个都有次优和优化版本对比，并建立了自动化评估框架，能够标准化评估生成模型在硬件设计优化方面的能力。

Conclusion: RTL-OPT填补了现有基准的空白，为评估大语言模型在RTL优化能力提供了标准化工具，有助于推动AI在集成电路设计优化方面的发展。

Abstract: The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.

</details>


### [63] [Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches](https://arxiv.org/abs/2601.01774)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.AI

TL;DR: LLMs在求解超越方程时，直接数值预测误差较大，而结合传统迭代求解器的混合架构能显著降低误差67.9%-81.8%，表明LLMs更适合作为传统数值求解器的智能接口而非独立计算引擎。


<details>
  <summary>Details</summary>
Motivation: 超越方程在工程实践中普遍存在，需要迭代数值求解。研究旨在评估大型语言模型能否直接求解这些方程，还是需要结合传统迭代求解器的混合架构更有效。

Method: 测试了6个最先进的LLM模型（GPT-5.1、GPT-5.2、Gemini-3-Flash、Gemini-2.5-Lite、Claude-Sonnet-4.5、Claude-Opus-4.5），在7个工程领域的100个问题上比较了直接预测与求解器辅助计算两种方法。在求解器辅助计算中，LLMs负责制定控制方程和提供初始条件，而牛顿-拉弗森迭代执行数值求解。

Result: 直接预测的平均相对误差为0.765-1.262，而求解器辅助计算为0.225-0.301，误差降低了67.9%-81.8%。领域分析显示电子学改进最大（93.1%），流体力学改进最小（7.2%）。

Conclusion: 当代LLMs擅长符号操作和领域知识检索，但在精度关键的迭代算术方面表现不佳，表明它们最适合作为传统数值求解器的智能接口，而不是独立的计算引擎。

Abstract: Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.

</details>


### [64] [PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor](https://arxiv.org/abs/2601.01802)
*Qianjun Pan,Junyi Wang,Jie Zhou,Yutao Yang,Junsong Li,Kaiyin Xu,Yougen Zhou,Yihan Li,Jingyuan Zhao,Qin Chen,Ningning Zhou,Kai Chen,Liang He*

Main category: cs.AI

TL;DR: PsychEval是一个用于心理评估AI的多会话、多疗法、高真实性的基准测试，旨在训练和评估AI咨询师，包含记忆连续性、自适应推理和纵向规划等关键能力。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的心理评估AI面临三大挑战：1) 如何训练高度真实的AI咨询师（需要长期记忆和动态目标跟踪）；2) 如何训练多疗法AI咨询师（复杂案例需要灵活切换不同疗法）；3) 如何系统评估AI咨询师（需要全面的评估框架）。

Method: 构建多会话基准（6-10个会话，分三个阶段），包含677个元技能和4577个原子技能；涵盖五种治疗模式（心理动力学、行为主义、CBT、人本存在主义、后现代主义）和整合疗法；建立包含18个治疗特定和共享指标的评估框架，构建2000多个多样化客户档案。

Result: 实验分析充分验证了数据集的质量和临床保真度。PsychEval超越了静态基准测试，可作为高保真强化学习环境，支持临床负责任和自适应AI咨询师的自我进化训练。

Conclusion: PsychEval为解决AI心理评估的关键挑战提供了全面解决方案，不仅能评估现有模型，还能作为训练环境促进AI咨询师的自我进化发展，具有重要的临床意义。

Abstract: To develop a reliable AI for psychological assessment, we introduce \texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.

</details>


### [65] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

TL;DR: 论文提出"可容许对齐"框架，将AI对齐重新定义为在不确定性下对结果分布的可容许行动和决策选择属性，并介绍了MAP-AI系统架构来实施这一框架。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐方法通常将对齐视为静态或二元条件，缺乏在不确定性环境下对决策政策行为的系统性评估。需要将对齐重新定义为概率性、决策理论属性，以更好地评估AI系统在真实世界复杂场景中的可信度和对齐性。

Method: 提出MAP-AI（蒙特卡洛对齐政策）系统架构，通过蒙特卡洛估计结果分布和可容许控制政策选择来实施对齐。该方法评估决策政策在多个可能未来场景中的表现，明确建模不确定性、干预效果、价值模糊性和治理约束。

Result: 建立了基于分布属性的对齐评估框架，包括期望效用、方差、尾部风险和不对齐概率等指标。该方法区分了概率预测与不确定性下的决策推理，为企业和机构AI系统提供了可执行的信任和对齐评估方法。

Conclusion: 该框架为治理AI系统提供了实用基础，其影响不是由单个预测决定，而是由政策在分布和尾部事件中的行为决定。分布对齐评估可集成到决策过程中，实现无需重新训练或修改底层模型的可容许控制行动选择机制。

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [66] [Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01844)
*Udiptaman Das,Krishnasai B. Atmakuri,Duy Ho,Chi Lee,Yugyung Lee*

Main category: cs.AI

TL;DR: 提出一个端到端框架，利用多智能体提示和模式约束的检索增强生成(KG-RAG)策略，直接从自由文本构建临床知识图谱，特别针对肿瘤学领域。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖结构化输入，缺乏对事实准确性和语义一致性的鲁棒验证，这在肿瘤学领域尤其成问题。需要直接从非结构化临床叙述构建知识图谱的解决方案。

Method: 采用多智能体提示和模式约束的KG-RAG策略，包括：(1)提示驱动的实体、属性和关系提取；(2)基于熵的不确定性评分；(3)本体对齐的RDF/OWL模式生成；(4)多LLM共识验证用于幻觉检测和语义细化。

Result: 应用于两个肿瘤学队列(PDAC和BRCA)，该方法产生了可解释、SPARQL兼容且临床基础的知识图谱，无需依赖黄金标准标注。实验结果显示在精度、相关性和本体合规性方面相比基线方法有持续提升。

Conclusion: 该框架支持连续细化和自监督评估，能够迭代改进图谱质量，为直接从自由文本构建临床知识图谱提供了有效的端到端解决方案。

Abstract: Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.

</details>


### [67] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)
*Defei Xia,Bingfeng Pi,Shenbin Zhang,Song Hua,Yunfei Wei,Lei Zuo*

Main category: cs.AI

TL;DR: 本文提出了Jenius-Agent框架，通过自适应提示生成、上下文感知工具编排和分层内存机制三大创新，显著提升了LLM智能体的任务准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体系统发展，提升自主智能体在上下文理解、工具使用和响应生成方面的任务性能变得日益重要。尽管先前研究已经推进了LLM智能体的整体设计，但对其内部推理和工具使用流程的系统性优化仍未被充分探索。

Method: 提出了基于实际经验的智能体框架，包含三个关键创新：1) 自适应提示生成策略，根据智能体状态和任务目标调整提示以提高可靠性和鲁棒性；2) 上下文感知工具编排模块，基于用户意图和上下文进行工具分类、语义检索和自适应调用；3) 分层内存机制，集成会话内存、任务历史和外部摘要，通过动态摘要和压缩提高相关性和效率。框架集成了基于模型上下文协议的工具、文件输入/输出和执行反馈等优化。

Result: 实验结果显示任务准确率提高了20%，同时降低了令牌成本、响应延迟和调用失败率。该框架已在Jenius平台部署，为健壮、协议兼容的自主智能体提供了轻量级可扩展解决方案。

Conclusion: Jenius-Agent框架通过系统性优化智能体的内部推理和工具使用流程，显著提升了任务性能，为实际部署提供了有效的解决方案，展示了在真实世界应用中的可行性和价值。

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.

</details>


### [68] [Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence](https://arxiv.org/abs/2601.01875)
*Kewen Cao,Jianxu Chen,Yongbing Zhang,Ye Zhang,Hongxiao Wang*

Main category: cs.AI

TL;DR: 提出基于SQL的代理框架，通过可执行的SQL查询将细胞特征测量与病理诊断结论连接起来，提高病理图像分析的可解释性和决策可追溯性。


<details>
  <summary>Details</summary>
Motivation: 当前病理图像分析虽然自动化程度高，但临床医生难以理解模型决策的依据。现有的视觉语言模型生成的解释往往是相关性描述，缺乏可验证的证据支持。

Method: 1. 提取人类可解释的细胞特征；2. 特征推理代理通过SQL查询在特征表上进行聚合分析；3. 知识比较代理将分析结果与已知病理知识对比，模拟病理医生的诊断推理过程。

Result: 在两个病理视觉问答数据集上的实验表明，该方法显著提高了可解释性和决策可追溯性，同时生成可执行的SQL追踪记录，将细胞测量与诊断结论明确关联。

Conclusion: 提出的SQL中心代理框架通过可审计的特征测量和推理过程，为病理图像分析提供了可验证的解释，增强了临床诊断的透明度和可信度。

Abstract: Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.

</details>


### [69] [MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning](https://arxiv.org/abs/2601.01910)
*Minh Hieu Ha,Khanh Ly Ta,Hung Phan,Tung Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: MMP-A*：一种结合视觉语言模型空间感知能力与自适应衰减机制的多模态路径规划框架，在复杂环境中实现近最优轨迹，显著降低计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 传统A*算法在大规模场景中计算和内存成本过高，而基于大语言模型的路径规划方法缺乏空间感知能力，在拓扑复杂环境中容易产生错误路径点，导致效率低下。

Method: 提出MMP-A*多模态框架，整合视觉语言模型的空间感知能力，引入自适应衰减机制动态调节不确定路径点在启发函数中的影响，确保几何有效性同时减少内存开销。

Result: 在具有严重障碍物和拓扑复杂性的挑战性环境中测试，MMP-A*实现了近最优轨迹，显著降低了操作成本，证明了其作为感知基础和计算高效的自导航范式的潜力。

Conclusion: MMP-A*通过结合视觉语言模型的空间感知能力和自适应衰减机制，解决了纯文本规划器的局限性，为自主导航提供了一种感知基础和计算高效的解决方案。

Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.

</details>


### [70] [OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation](https://arxiv.org/abs/2601.01939)
*Victor Sanchez,Chris Reinke,Ahamed Mohamed,Xavier Alameda-Pineda*

Main category: cs.AI

TL;DR: OpenSocInt是一个开源的多模态社交交互模拟器软件包，提供模块化架构训练社交智能体，已应用于社交导航任务。


<details>
  <summary>Details</summary>
Motivation: 为多模态社交交互研究提供一个开源、模块化的仿真平台，支持探索不同感知特征、编码融合方法和智能体设计，促进社交智能研究的发展。

Method: 开发了OpenSocInt开源软件包，包含多模态社交交互模拟器和模块化架构，支持不同感知特征的编码与融合，以及多种智能体的训练。

Result: 软件已公开可用（GPL许可证），并通过社交导航任务的实验协议展示了其应用价值，为社交智能研究提供了实用工具。

Conclusion: OpenSocInt为多模态社交交互研究提供了有效的开源平台，支持灵活的实验设计和算法开发，有助于推动社交智能领域的发展。

Abstract: In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.

</details>


### [71] [CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes](https://arxiv.org/abs/2601.01976)
*Yasmine Souissi,Fabrice Boissier,Nida Meddouri*

Main category: cs.AI

TL;DR: 本文对基于形式概念分析(FCA)的分类器进行了最新综述，提出了一种从名义数据计算闭包算子的新方法，并构建了专注于最相关概念的部分概念格。


<details>
  <summary>Details</summary>
Motivation: 知识发现(KDD)旨在从各种领域生成的大量数据中提取隐藏且有价值的知识。在众多数据挖掘技术中，形式概念分析(FCA)因其可解释性和可解释性学习而被认为是有效的分类方法。本文旨在综述FCA分类器的最新进展，并改进相关方法。

Method: 1. 对基于FCA的分类器进行最新综述；2. 探索从名义数据计算闭包算子的各种方法；3. 提出一种构建部分概念格的新方法，专注于最相关的概念；4. 通过实验验证所提方法的效率。

Result: 实验结果表明，所提出的方法在效率方面表现良好。该方法能够有效构建部分概念格，专注于最相关的概念，从而提高了分类性能。

Conclusion: 形式概念分析是一种有效的可解释分类方法。本文提出的构建部分概念格的新方法能够提高分类效率，为FCA在知识发现中的应用提供了有价值的改进。

Abstract: Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.

</details>


### [72] [ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems](https://arxiv.org/abs/2601.01982)
*Noel Thomas*

Main category: cs.AI

TL;DR: ChaosBench-Logic是一个评估大语言模型在混沌动力系统领域逻辑推理能力的基准测试，包含30个系统、11个语义谓词、621个问题，涵盖7种推理类型，发现前沿LLMs在单项准确率可达91-94%，但组合推理准确率为0%，对话准确率53.1-75.5%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言任务表现出色，但在需要精确逻辑和符号推理的领域仍然脆弱。混沌动力系统提供了一个特别具有挑战性的测试环境，因为混沌是确定性的，却常被误解为随机性或复杂性。需要建立一个系统性的基准来评估LLMs的逻辑推理能力。

Method: 引入ChaosBench-Logic基准，使用统一的一阶逻辑本体论评估30个不同的动力系统。每个系统标注了11个语义谓词的真值分配，生成了621个问题，涵盖7个推理类别：多步蕴含、跨系统类比、反事实推理、偏见探测和多轮对话。定义了逻辑准确性、蕴含一致性、对话连贯性和矛盾性等指标，并发布了开源评估管道。

Result: 前沿LLMs（GPT-4、Claude 3.5 Sonnet、Gemini 2.5 Flash、LLaMA-3 70B）在单项准确率达到91-94%，但在组合推理项目上得分为0%，表现出脆弱的全局连贯性。对话级准确率从53.1%（GPT-4 CoT）到75.5%（LLaMA-3 zero-shot）不等。

Conclusion: ChaosBench-Logic为诊断LLMs的逻辑推理失败提供了一个严格的测试平台，并为开发神经符号方法以改进LLMs的科学推理能力奠定了基础。尽管LLMs在单项任务上表现良好，但在组合推理和全局连贯性方面仍有显著缺陷。

Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.

</details>


### [73] [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)
*Dong Xue,Jicheng Tu,Ming Wang,Xin Yan,Fangzhou Liu,Jie Hu*

Main category: cs.AI

TL;DR: MindChat是一个保护隐私的心理健康支持大语言模型，配合MindCorpus合成多轮心理咨询数据集，通过联邦学习和差分隐私减少隐私风险，在心理咨询能力评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康支持大语言模型的训练受到真实心理咨询对话稀缺性和敏感性的限制，需要解决数据获取和隐私保护的双重挑战。

Method: 1) 开发多智能体角色扮演框架构建MindCorpus合成数据集，采用双闭环反馈设计：轮次级批判修订和会话级策略优化；2) 使用联邦学习配合LoRA适配器进行基础模型微调，并加入差分隐私优化以减少成员推断和记忆风险。

Result: MindCorpus提高了训练效果，MindChat在自动LLM评估和人工评估协议下，与现有通用和心理咨询导向的LLM基线相比具有竞争力，同时在成员推断攻击下表现出减少的隐私泄露。

Conclusion: 该研究提出了一个保护隐私的心理健康支持系统，通过合成数据生成和隐私保护技术，在保持心理咨询能力的同时有效降低了隐私风险，为敏感领域的LLM应用提供了可行方案。

Abstract: Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.

</details>


### [74] [XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging](https://arxiv.org/abs/2601.02008)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

TL;DR: XAIMeD是一个可解释的医疗AI框架，通过神经符号架构整合临床专家知识，提升分布偏移下的鲁棒性、罕见类别敏感性，并提供临床对齐的解释。


<details>
  <summary>Details</summary>
Motivation: 医疗AI中可解释性、领域泛化和罕见类别可靠性是关键挑战，深度学习模型在真实世界分布偏移下经常失败，并对不常见的临床条件表现出偏见。

Method: 提出XAIMeD框架，将临床专业知识编码为原子医学命题的逻辑连接，转化为机器可检查的类别特定规则。通过加权特征满足分数量化诊断效用，创建符号推理分支补充神经预测。使用置信度加权融合整合符号和深度输出，以及受Hunt启发的自适应路由机制（由熵不平衡增益和罕见类别基尼指数指导）。

Result: 在四个挑战性任务上评估：i) 从rs-fMRI定位癫痫发作起始区，ii) 跨6个多中心数据集的糖尿病视网膜病变分级。结果显示跨领域泛化性能提升6%，罕见类别F1分数提升10%，远超最先进的深度学习基线。消融研究证实临床基础的符号组件作为有效的正则化器。

Conclusion: XAIMeD为多模态医疗AI提供了一个原则性、临床忠实且可解释的方法，通过整合专家知识改善了分布偏移下的鲁棒性和罕见类别敏感性。

Abstract: Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.

</details>


### [75] [Simulated Reasoning is Reasoning](https://arxiv.org/abs/2601.02043)
*Hendrik Kempt,Alon Lavie*

Main category: cs.AI

TL;DR: 论文认为基础模型通过模仿"思考过程"而非符号推理实现了某种推理能力，这挑战了传统推理观念，需要重新评估推理的必要条件和安全考量。


<details>
  <summary>Details</summary>
Motivation: 传统上认为推理需要通过符号推理等特定方式实现理解，但基础模型展示了通过模仿"思考过程"也能实现推理，这挑战了传统观念，需要重新审视推理的本质和必要条件。

Method: 论文提出并讨论了对这一现象的几种哲学解释，论证了"随机鹦鹉"隐喻已失去相关性，并反思了从这些推理模型中产生的安全和适当性考虑的不同规范要素。

Result: 基础模型通过模仿"思考过程"、测试生成路径并迭代，能够实现某种推理能力，但这与人类推理有根本差异（缺乏基础常识），导致推理过程的脆弱性。

Conclusion: 这些见解将显著改变我们对推理及其必要条件的评估，同时也为应对基础模型推理脆弱性的安全和鲁棒防御方法提供信息。需要放弃过时的"随机鹦鹉"隐喻，重新思考推理模型的安全和适当性规范。

Abstract: Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., "symbolic reasoning". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can "reason" by way of imitating the process of "thinking out loud", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the "stochastic parrot" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.

</details>


### [76] [Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management](https://arxiv.org/abs/2601.02061)
*Faizan Ahmed,Aniket Dixit,James Brusey*

Main category: cs.AI

TL;DR: 该论文研究通过高阶导数惩罚（特别是三阶导数惩罚）来正则化深度强化学习动作的平滑性，在连续控制基准和建筑能源管理应用中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习代理常表现出高频、不稳定的控制行为，这在实际部署中会导致能耗过高和设备磨损。需要一种方法来平衡RL优化与实际操作约束。

Method: 采用高阶导数惩罚进行动作平滑正则化，从一阶到三阶导数惩罚（加速度、加加速度），在四个连续控制环境中进行系统评估，并将方法扩展到HVAC控制系统。

Result: 三阶导数惩罚（加加速度最小化）在保持竞争力的同时实现了最佳平滑效果。在HVAC控制中，平滑策略使设备切换减少了60%，带来显著的操作效益。

Conclusion: 高阶动作正则化是连接RL优化与能源关键应用中操作约束的有效桥梁，为实际部署提供了实用的解决方案。

Abstract: Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.

</details>


### [77] [FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations](https://arxiv.org/abs/2601.02071)
*Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi*

Main category: cs.AI

TL;DR: 研究探讨了将大型语言模型（LLMs）应用于药物3D打印配方开发，通过微调1400多种FDM配方数据集，评估LLMs在推荐辅料和预测丝材机械性能方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的药物3D打印研究大多局限于特定领域，未能全面解决配方开发中的复杂挑战。随着通用人工智能概念的发展，需要探索LLMs在药物制剂开发中的更广泛应用。

Method: 使用包含1400多种配方的FDM数据集微调四种LLM架构，系统评估微调和生成参数配置，测试模型在推荐辅料和预测丝材机械性能方面的能力。

Result: Llama2在推荐FDM配方辅料方面表现最佳；模型选择和参数配置显著影响性能；较小的LLMs会出现灾难性遗忘；标准LLM指标仅评估语言能力而非配方可加工性；生物医学相关数据训练的LLMs不一定产生最佳结果。

Conclusion: 需要解决灾难性遗忘、评估指标局限性和数据相关性等问题，才能推动LLMs超越语言能力，成为药物配方开发的可靠系统。

Abstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.

</details>


### [78] [EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning](https://arxiv.org/abs/2601.02163)
*Chuanrui Hu,Xingze Gao,Zuyi Zhou,Dannong Xu,Yi Bai,Xintong Li,Hui Zhang,Tong Li,Chong Zhang,Lidong Bing,Yafeng Deng*

Main category: cs.AI

TL;DR: EverMemOS是一个自组织记忆操作系统，采用类记忆印迹的生命周期管理方法，将对话流转化为记忆单元，组织成主题记忆场景，实现高效记忆增强推理。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为长期交互代理时，受限于有限的上下文窗口，难以维持连贯的长期行为。现有记忆系统通常存储孤立记录并检索片段，无法有效整合演变的用户状态和解决冲突。

Method: 提出EverMemOS系统，包含三个核心组件：1) 情景痕迹形成：将对话流转化为MemCells，捕捉情景痕迹、原子事实和时间受限的预见信号；2) 语义整合：将MemCells组织成主题MemScenes，提炼稳定语义结构并更新用户画像；3) 重构回忆：执行MemScene引导的智能检索，为下游推理组合必要且充分的上下文。

Result: 在LoCoMo和LongMemEval基准测试中，EverMemOS在记忆增强推理任务上达到最先进性能。在PersonaMem v2上的画像研究以及用户画像和预见等聊天导向能力的定性案例研究也展示了其有效性。

Conclusion: EverMemOS通过自组织记忆操作系统实现了对长期交互中记忆的有效管理，解决了现有记忆系统的局限性，为LLM作为长期代理提供了更强大的记忆支持。

Abstract: Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.

</details>


### [79] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

TL;DR: 该论文提出将长链思维推理中的幻觉视为演化潜状态而非一次性错误事件，引入累积前缀级幻觉信号来实时追踪推理状态的全局演化，实现流式幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 长链思维推理虽然能提升大语言模型性能，但其中的幻觉问题往往以微妙方式出现并在推理步骤间传播。现有方法将幻觉视为一次性错误事件，难以捕捉其在长推理链中的演化特性。

Method: 将步骤级幻觉判断视为局部观测，引入累积前缀级幻觉信号来追踪整个推理轨迹中推理状态的全局演化。该方法将幻觉建模为演化潜状态而非离散事件。

Result: 提出的方法能够在长链思维推理中实现流式幻觉检测，提供实时、可解释的证据，更好地捕捉幻觉在推理过程中的传播和演化特性。

Conclusion: 将幻觉视为演化潜状态而非一次性错误事件是理解长链思维推理中幻觉问题的更有效框架，累积前缀级信号方法能够实现实时、可解释的幻觉检测。

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


### [80] [Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents](https://arxiv.org/abs/2601.02314)
*Sourena Khanzadeh*

Main category: cs.AI

TL;DR: 论文提出Project Ariadne框架，使用结构因果模型和反事实逻辑来审计LLM代理推理的因果完整性，发现当前代理架构存在"忠实性差距"，推理痕迹常为"推理剧场"而非真实决策驱动。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理越来越多地承担高风险自主决策任务，其推理过程的透明度成为关键安全关切。虽然CoT提示能生成人类可读的推理痕迹，但无法确定这些痕迹是模型输出的真实生成驱动因素还是事后合理化解释。

Method: 提出Project Ariadne框架，利用结构因果模型和反事实逻辑，通过对中间推理节点进行硬干预（do-演算）——系统性地反转逻辑、否定前提、反转事实主张——来测量终端答案的因果敏感性。

Result: 对最先进模型的实证评估揭示了持续的"忠实性差距"。定义并检测到广泛存在的"因果解耦"故障模式，在事实和科学领域中违规密度高达0.77。代理在内部逻辑矛盾的情况下仍得出相同结论，证明其推理痕迹只是"推理剧场"，而决策由潜在参数先验控制。

Conclusion: 当前代理架构本质上容易产生不忠实的解释，提出Ariadne分数作为对齐陈述逻辑与模型行为的新基准。

Abstract: As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \textbf{faithful} generative drivers of the model's output or merely \textbf{post-hoc rationalizations}. We introduce \textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as "Reasoning Theater" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.

</details>


### [81] [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)
*Falcon LLM Team,Iheb Chaabane,Puneesh Khanna,Suhail Mohmad,Slim Frikha,Shi Hu,Abdalgader Abubaker,Reda Alami,Mikhail Lubinets,Mohamed El Amine Seddik,Hakim Hacid*

Main category: cs.AI

TL;DR: Falcon-H1R是一个7B参数的推理优化模型，证明了小语言模型也能达到竞争力的推理性能，在多种推理基准测试中匹配或超越2-7倍大的SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过精心设计的数据策展和训练策略，使小型语言模型（SLMs）在保持参数效率的同时，达到与更大模型相竞争的推理性能。

Method: 采用混合并行架构设计实现更快推理，结合高效监督微调（SFT）和强化学习（RL）扩展的针对性训练策略，利用DeepConf方法实现最先进的测试时扩展效率。

Result: 在多种推理密集型基准测试中，Falcon-H1R-7B模型一致匹配或超越比其大2-7倍的SOTA推理模型，实现了推理效率的3D极限（更快推理、令牌效率、更高准确性）。

Conclusion: 通过针对性的模型训练和架构选择，紧凑模型能够提供强大且可扩展的推理性能，为需要大量思维链生成和并行测试时扩展的场景提供了实用的骨干模型。

Abstract: This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [82] [Analog Weight Update Rule in Ferroelectric Hafnia, using pico-Joule Programming Pulses](https://arxiv.org/abs/2601.01186)
*Alexandre Baigol,Nikhil Garg,Matteo Mazza,Yanming Zhang,Elisa Zaccaria,Wooseok Choi,Bert Jan Offrein,Laura Bégon-Lours*

Main category: cs.ET

TL;DR: 该论文研究了基于铪/锆氧化物纳米层叠结构的铁电电阻权重器件，通过横向尺寸缩小至100μm²以下，实现了20ns编程脉冲和3pJ/脉冲的低能耗，并发现权重更新仅取决于脉冲幅度而与初始状态无关。


<details>
  <summary>Details</summary>
Motivation: 为了与大脑处理信息的高效性竞争，神经形态硬件需要降低训练阶段的能耗。当前铁电电阻权重器件的编程脉冲时间受限于器件自身负载时间，需要寻找降低编程脉冲持续时间的方法。

Method: 采用与CMOS后端工艺兼容的铪/锆氧化物纳米层叠结构制造铁电电阻权重器件，通过横向尺寸缩小至100μm²以下来降低自负载时间，实现20ns编程脉冲。实验测量了不同幅度和不同初始电导状态下的权重更新规则。

Result: 器件自负载时间缩短至足够支持20ns编程脉冲，对应最大3pJ/脉冲的能耗。实验发现最终权重值仅由脉冲幅度决定，与初始权重值无关，这为神经形态硬件的低能耗训练提供了重要特性。

Conclusion: 通过器件尺寸缩小实现了20ns编程脉冲和低至3pJ/脉冲的能耗，同时发现权重更新仅取决于脉冲幅度的特性，为开发高效神经形态硬件提供了重要进展。

Abstract: In an effort to compete with the brain's efficiency at processing information, neuromorphic hardware combines artificial synapses and neurons using mixed-signal circuits and emerging memories. In ferroelectric resistive weights, the strength of the synaptic connection between two neurons is stored in the device conductance. During learning, programming pulses are applied to the synaptic weight, which reconfigures the ferroelectric domains and adjusts the conductance. One strategy to lower the energy cost during the training phase is to lower the duration of the programming pulses. However, the latter cannot be shorter than the self-loading time of the resistive weights, limited by intrinsic parasitics in the circuits. In this work, ferroelectric resistive weights are fabricated using a process compatible with CMOS Back-End-Of-Line integration, based on hafnia/zirconia nanolaminates. By laterally scaling the device area under 100 $μ$m$^2$, the self-loading time becomes sufficiently short to enable 20 ns programming, which corresponds to a maximum of 3 picoJoules per pulse. Further, in this work, the weight update rule with 20 ns pulses is experimentally measured not only for different amplitudes but also for different initial conductance states. We find that the final weight is determined by the pulse amplitude, independent of the initial weight value.

</details>


### [83] [Bridging Language Gaps: Utilizing Interactive Robots to Teach Cantonese in Real-Life Contexts for Newly-Arrived Children](https://arxiv.org/abs/2601.01234)
*Ka-Yan Fung,Yuxing Tao,Tze-Leung,Rick Lui,Kuen-Fung Sin*

Main category: cs.ET

TL;DR: 香港多元文化教育环境中，新来港学生面临语言和文化障碍，研究探索互动机器人Boon Boon通过情境教学提升学生学习参与度和粤语能力。


<details>
  <summary>Details</summary>
Motivation: 香港教育系统包含本地、非华语及新来港学生，后者虽能理解词汇但无法开口说粤语，面临语言障碍和文化差异，影响学业和社交融入。现有资源多关注英语学习，忽视情感支持和粤语学习需求。

Method: 研究邀请14名儿童参与为期四天的学习项目，使用互动机器人Boon Boon通过真实生活情境教授粤语，探索机器人赋能的情境学习对学习参与度和语言能力的影响。

Result: 初步结果显示Boon Boon能有效吸引学生注意力并提升学业成就，机器人赋能的学习方法显示出积极效果。

Conclusion: 互动机器人辅助的情境学习有助于提升新来港学生的粤语学习参与度和动机，未来研究将关注长期效果评估及在不同教育环境和文化背景中的可扩展性。

Abstract: Hong Kong's education system is notably multicultural, including local, non-Chinese-speaking, and newly arrived students (NAS) (Mandarine Chinese-speaking). NAS can guess the meaning of vocabulary but cannot speak out, presenting unique challenges for them, particularly language barriers and cultural differences. These challenges hinder their academic success and social integration, leading to feelings of isolation and demotivation. Current resources often fail to address the emotional well-being of these students and predominantly focus on English language acquisition, leaving a gap in support for learning Cantonese and navigating the local cultural landscape. This study explores the effectiveness of an interactive robot, Boon Boon, in teaching Cantonese through real-life contexts to enhance NAS children learning engagement and motivation. The research questions are: (1) How does interactive robot-empowered scenario learning influence the learning engagement and motivation of NAS in learning Cantonese? and (2) What is the impact of a robot-empowered scenario learning system on the Cantonese language proficiency of NAS? Fourteen children are invited to participate in a four-day learning program with Boon Boon. The preliminary result indicated that Boon Boon drove students' attention to learning and academic achievement. Future research will focus on long-term assessments of robot-empowered learning's effectiveness and explore the scalability of this approach across diverse educational settings and cultural backgrounds.

</details>


### [84] [Adaptive Tuning of the Unscented Kalman Filter using Particle Swarm Optimization for Inertial-GPS Sensor Fusion Systems](https://arxiv.org/abs/2601.01578)
*Psyche T. Malabo,Bobby D. Gerardo*

Main category: cs.ET

TL;DR: PSO优化UKF参数，在CARLA仿真中实现82.14%精度提升，减少IMU漂移达21.6公里，满足实时定位需求


<details>
  <summary>Details</summary>
Motivation: 现有IMU-GPS融合方法（EKF、UKF、ML、GA、DE）存在非线性、不稳定或计算成本高的问题，需要更有效的参数优化方法

Method: 提出基于粒子群优化（PSO）的自适应调参框架，优化UKF参数（α、β、κ、Q、R），在CARLA 0.9.14中使用特斯拉Model 3进行多场景测试

Result: 在15代内收敛，相比手动调参精度提升82.14%，IMU漂移减少达21,606.59米，更新时间低于10ms实时阈值，统计验证显示一致增益

Conclusion: PSO优化的UKF在动态和GPS受限条件下表现出实用的定位性能，为车辆定位提供了有效的参数优化解决方案

Abstract: Accurate vehicle positioning requires effective IMU-GPS fusion, yet prior methods-EKF, UKF, ML, GA, and DE-suffer from nonlinearity, instability, or high computational cost. This study introduces a PSO-based adaptive tuning framework for optimizing UKF parameters (α, \b{eta}, \k{appa}, Q, R), evaluated in CARLA 0.9.14 using a Tesla Model 3 under diverse maneuvers and environmental conditions. Within defined parameter bounds, convergence stabilized within 15 generations, achieving an 82.14% accuracy improvement over manual tuning and reducing IMU drift by up to 21,606.59m. Multi-trial statistical validation confirmed consistent gains with low confidence intervals. With update times remaining below the 10 ms real-time threshold, the PSO-tuned UKF demonstrates practical localization performance for dynamic, GPS-challenged conditions.

</details>


### [85] [Physics-Informed Deep Recurrent Back-Projection Network for Tunnel Propagation Modeling](https://arxiv.org/abs/2601.02007)
*Kunyu Wu,Qiushi Zhao,Jingyi Zhou,Junqiao Wang,Hao Qin,Xinyue Zhang,Xingqi Zhang*

Main category: cs.ET

TL;DR: 提出PRBPN网络，从粗网格PWE切片重建精细RSS场，减少对计算密集型精细网格求解器的依赖，同时保持高保真隧道传播预测。


<details>
  <summary>Details</summary>
Motivation: 铁路隧道中无线电波传播的精确高效建模对CBTC系统可靠性至关重要。精细网格PWE求解器计算成本高，而粗网格模型会丢失重要的模态和几何细节。

Method: 提出物理信息循环反投影传播网络(PRBPN)，集成多切片时间融合与迭代投影/反投影机制，强制物理一致性，无需预上采样阶段。

Result: 在四种隧道截面几何和四种频率的仿真中，PRBPN能紧密跟踪精细网格PWE参考。在法国Massif Central隧道的工程级验证中，仅用少量配对粗/细RSS数据训练，在数据稀缺场景下表现出鲁棒性。

Conclusion: PRBPN能显著减少对计算密集型精细网格求解器的依赖，同时保持高保真隧道传播预测，为铁路通信系统提供高效准确的传播建模方案。

Abstract: Accurate and efficient modeling of radio wave propagation in railway tunnels is is critical for ensuring reliable communication-based train control (CBTC) systems. Fine-grid parabolic wave equation (PWE) solvers provide high-fidelity field predictions but are computationally expensive for large-scale tunnels, whereas coarse-grid models lose essential modal and geometric details. To address this challenge, we propose a physics-informed recurrent back-projection propagation network (PRBPN) that reconstructs fine-resolution received-signal-strength (RSS) fields from coarse PWE slices. The network integrates multi-slice temporal fusion with an iterative projection/back-projection mechanism that enforces physical consistency and avoids any pre-upsampling stage, resulting in strong data efficiency and improved generalization. Simulations across four tunnel cross-section geometries and four frequencies show that the proposed PRBPN closely tracks fine-mesh PWE references. Engineering-level validation on the Massif Central tunnel in France further confirms robustness in data-scarce scenarios, trained with only a few paired coarse/fine RSS. These results indicate that the proposed PRBPN can substantially reduce reliance on computationally intensive fine-grid solvers while maintaining high-fidelity tunnel propagation predictions.

</details>


### [86] [Impact of Spatial Proximity on Drone Services](https://arxiv.org/abs/2601.02210)
*Vejaykarthy Srithar,Syeda Amna Rizvi,Amani Abusafia,Athman Bouguettaya,Balsam Alkouz*

Main category: cs.ET

TL;DR: 该研究通过实验分析近距离飞行无人机之间的相互影响，开发GUI可视化工具，研究无人机位置、间距和风况对能耗的影响，为高效无人机配送服务规划提供依据。


<details>
  <summary>Details</summary>
Motivation: 理解近距离飞行无人机之间的相互影响对于规划高效无人机配送服务至关重要，需要研究无人机在三维空间中不同位置和风况下的能量消耗情况。

Method: 通过一系列实验，在不同风况下使用无人机在三维空间中不同位置飞行，收集无人机在航线段飞行的能量消耗数据，并开发了图形用户界面来绘制无人机轨迹和分析相互影响。

Result: 成功开发了GUI工具，能够可视化无人机轨迹并分析无人机之间的相互影响，包括位置、间距和风况对能量消耗的影响，为无人机配送规划提供了分析工具。

Conclusion: 该研究为理解无人机近距离飞行的相互影响提供了实验方法和分析工具，有助于优化无人机配送服务的效率和规划。

Abstract: We demonstrate the peer-to-peer impact of drones flying in close proximity. Understanding these impacts is crucial for planning efficient drone delivery services. In this regard, we conducted a set of experiments using drones at varying positions in a 3D space under different wind conditions. We collected data on drone energy consumption traveling in a skyway segment. We developed a Graphical User Interface (GUI) that plots drone trajectories within a segment. The GUI facilitates analyzing the peer-to-peer influence of drones on their energy consumption. The analysis includes drones' positions, distance of separation, and wind impact.

</details>


### [87] [Modeling Inter-drone Interference as a Service in Skyway Networks](https://arxiv.org/abs/2601.02270)
*Gabriel Timothy,Syeda Amna Rizvi,Muhammad Umair,Athman Bouguettaya,Balsam Alkouz*

Main category: cs.ET

TL;DR: 研究多无人机空中网络中的相互干扰对配送效率的影响，通过实验分析干扰行为并建立预测模型


<details>
  <summary>Details</summary>
Motivation: 随着多无人机空中网络的发展，无人机之间的相互干扰问题日益突出，这种干扰会影响配送效率和网络性能，需要系统性的研究和建模

Method: 在室内测试环境中进行受控实验，比较单机飞行与多机并发操作的性能，分析飞行中和充电站的干扰，收集功耗和配送时间等关键指标数据

Result: 建立了全面的干扰数据集，并开发了预测模型，验证了模型能够准确预测无人机间的相互干扰

Conclusion: 研究成功分析了多无人机网络中的干扰问题，开发的预测模型具有实际应用价值，能够帮助优化无人机配送系统的性能

Abstract: We present a novel investigation into the impact of inter-drone interference on delivery efficiencies within multi-drone skyway networks. We conduct controlled experiments to analyze the behavior of drones in an indoor testbed environment. Our study compares performance between solo flights and concurrent multi-drone operations along predefined routes. This analysis captures interference occurring during both flight and at charging stations, providing a comprehensive evaluation of its effects on overall network performance. We conduct a comprehensive series of experiments across diverse scenarios to systematically understand and model the dynamics of inter-drone interference. Key metrics, such as power consumption and delivery times, are considered. This generates a comprehensive dataset for in-depth analysis of interference at both the node and segment levels. These findings are then formalized into a predictive model. The results validate the effectiveness of the developed model, demonstrating its potential to accurately forecast inter-drone interferences.

</details>
