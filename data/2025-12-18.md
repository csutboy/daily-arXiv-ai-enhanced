<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 6]
- [cs.AI](#cs.AI) [Total: 23]
- [cs.CY](#cs.CY) [Total: 3]
- [econ.EM](#econ.EM) [Total: 1]
- [cs.SI](#cs.SI) [Total: 11]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [Restless Multi-Process Multi-Armed Bandits with Applications to Self-Driving Microscopies](https://arxiv.org/abs/2512.14930)
*Jaume Anguera Peris,Songtao Cheng,Hanzhao Zhang,Wei Ouyang,Joakim Jaldén*

Main category: stat.AP

TL;DR: 提出RMPMAB框架，将活细胞成像区域建模为马尔可夫链集合，通过Whittle索引策略实现资源约束下的智能显微镜控制，显著提升实验效率。


<details>
  <summary>Details</summary>
Motivation: 高内涵筛选显微镜产生大量活细胞成像数据，但现有方法无法确定何时何地最有效地成像。静态采样或启发式方法忽略了生物过程的动态演化，导致效率低下和事件遗漏。需要在数千个动态演化的感兴趣区域中平衡采集时间、计算能力和光漂白预算。

Method: 引入RMPMAB（不安多过程多臂老虎机）框架，将每个实验区域建模为马尔可夫链集合而非单一过程，捕捉生物系统的异质性。推导聚合过程的瞬态和渐近行为的闭式表达式，设计具有亚线性复杂度的Whittle索引策略。

Result: 在模拟中，算法比Thompson Sampling、Bayesian UCB、epsilon-Greedy和Round Robin减少超过37%的累积遗憾；在真实活细胞成像实验中，捕获了93%更多的生物相关事件。在资源约束下实现了吞吐量的显著提升。

Conclusion: RMPMAB框架将随机决策理论与最优自主显微镜控制统一起来，为跨学科科学的加速发现提供了原则性方法。该框架不仅提高了实验效率，还具有变革智能显微镜的潜力。

Abstract: High-content screening microscopy generates large amounts of live-cell imaging data, yet its potential remains constrained by the inability to determine when and where to image most effectively. Optimally balancing acquisition time, computational capacity, and photobleaching budgets across thousands of dynamically evolving regions of interest remains an open challenge, further complicated by limited field-of-view adjustments and sensor sensitivity. Existing approaches either rely on static sampling or heuristics that neglect the dynamic evolution of biological processes, leading to inefficiencies and missed events. Here, we introduce the restless multi-process multi-armed bandit (RMPMAB), a new decision-theoretic framework in which each experimental region is modeled not as a single process but as an ensemble of Markov chains, thereby capturing the inherent heterogeneity of biological systems such as asynchronous cell cycles and heterogeneous drug responses. Building upon this foundation, we derive closed-form expressions for transient and asymptotic behaviors of aggregated processes, and design scalable Whittle index policies with sub-linear complexity in the number of imaging regions. Through both simulations and a real biological live-cell imaging dataset, we show that our approach achieves substantial improvements in throughput under resource constraints. Notably, our algorithm outperforms Thomson Sampling, Bayesian UCB, epsilon-Greedy, and Round Robin by reducing cumulative regret by more than 37% in simulations and capturing 93% more biologically relevant events in live imaging experiments, underscoring its potential for transformative smart microscopy. Beyond improving experimental efficiency, the RMPMAB framework unifies stochastic decision theory with optimal autonomous microscopy control, offering a principled approach to accelerate discovery across multidisciplinary sciences.

</details>


### [2] [Early CRAB-like Biomarker Signatures Reveal a Preclinical Susceptibility Continuum for Multiple Myeloma](https://arxiv.org/abs/2512.15056)
*Bingjie Li,Jiadai Xu,Yiqing Sun,Peng Liu,Zhigang Yao*

Main category: stat.AP

TL;DR: 该研究利用UK Biobank数据，发现常规血液检测中的贫血和蛋白质代谢标志物（如血红蛋白、总蛋白、白蛋白/球蛋白比）与未来多发性骨髓瘤风险显著相关，可在诊断前10年预测风险，提升风险区分能力。


<details>
  <summary>Details</summary>
Motivation: 多发性骨髓瘤（MM）发展过程长达数十年，但目前缺乏在临床发病前长期识别高危个体的有效工具。需要探索常规检测标志物是否能早期预测MM风险。

Method: 使用UK Biobank中378,930名参与者的数据，系统分析常规测量的"CRAB样"生物标志物（血液学指标、蛋白质代谢标志物、肾功能、血清钙）的纵向动态和预测价值。采用多变量模型评估这些标志物与未来MM风险的关联。

Result: 反映贫血和蛋白质失衡的生物标志物（血红蛋白、红细胞指数、总蛋白、白蛋白、白蛋白/球蛋白比）与未来MM风险有强且一致的关联。这些标志物显示显著的非线性剂量-反应关系，将5年和10年MM风险区分的C指数从0.66提升到0.76。纵向分析显示在诊断前10年红细胞形态和蛋白质代谢谱已出现渐进性变化。

Conclusion: 常规实验室检查中微小的可量化偏差反映了恶性浆细胞扩增前的早期微环境变化，为风险分层和针对性监测提供了机会，支持在普通人群中存在可检测的临床前易感性连续体。

Abstract: Multiple myeloma (MM) evolves over decades, yet robust tools for identifying individuals at risk long before clinical onset remain limited. Using data from 378,930 UK Biobank participants, we systematically characterized the longitudinal dynamics and predictive value of routinely measured "CRAB-like" biomarkers, including hematologic indices, protein metabolism markers, renal function, and serum calcium. Across multivariable models, biomarkers reflecting anemia and protein imbalance (including hemoglobin, red blood cell indices, total protein, albumin, and the albumin/globulin ratio) showed strong and consistent associations with future MM, independent of demographic, lifestyle, clinical, and genetic risk factors. These markers displayed pronounced non-linear dose-response relationships and contributed substantially to 5- and 10-year MM risk discrimination, with the C-index improving from 0.66 to 0.76. Longitudinal analyses revealed progressive shifts in red cell morphology and protein metabolism profiles up to a decade before diagnosis, supporting the existence of a preclinical susceptibility continuum detectable in the general population. Our findings suggest that subtle yet quantifiable deviations in common laboratory tests reflect early microenvironmental changes that precede malignant plasma cell expansion, offering opportunities for risk stratification and targeted surveillance.

</details>


### [3] [A Blind Source Separation Framework to Monitor Sectoral Power Demand from Grid-Scale Load Measurements](https://arxiv.org/abs/2512.15232)
*Guillaume Koechlin,Filippo Bovera,Elena Degli Innocenti,Barbara Santini,Alessandro Venturi,Simona Vazio,Piercesare Secchi*

Main category: stat.AP

TL;DR: 提出基于约束非负矩阵分解的盲源分离框架，从高压电网总负荷中分解出居民、服务业和工业部门的高频用电曲线，应用于意大利2021-2023年数据。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源主导的分散式电力系统发展，需求侧灵活性变得至关重要。但在区域或国家层面，由于收集终端用户数据的复杂性和成本，难以了解不同消费类别对总负荷的相对贡献。

Method: 采用基于约束非负矩阵分解的盲源分离框架，从聚合的高压电网负荷测量数据中监测居民、服务业和工业部门的高频用电情况。

Result: 成功重建了各部门的精确小时用电曲线，发现居民和服务业用电行为受季节和日期类型影响呈现两种不同模式，而工业需求则保持单一稳定的日用电模式。分解后的月度用电估计与基于样本的指数高度一致，且比基于这些指数的预测方法更精确。

Conclusion: 该方法能够从总负荷数据中有效分解各部门用电，为实时监测提供比传统预测方法更精确的解决方案，有助于理解电力需求构成和支持需求侧灵活性管理。

Abstract: As we are moving towards decentralized power systems dominated by intermittent electricity generation from renewable energy sources, demand-side flexibility is becoming a critical issue. In this context, it is essential to understand the composition of electricity demand at various scales of the power grid. At the regional or national scale, there is however little visibility on the relative contributions of different consumer categories, due to the complexity and costs of collecting end-users consumption data. To address this issue, we propose a blind source separation framework based on a constrained variant of non-negative matrix factorization to monitor the consumption of residential, services and industrial sectors at high frequency from aggregate high-voltage grid load measurements. Applying the method to Italy's national load curve between 2021 and 2023, we reconstruct accurate hourly consumption profiles for each sector. Results reveal that both households and services daily consumption behaviors are driven by two distinct regimes related to the season and day type whereas industrial demand follows a single, stable daily profile. Besides, the monthly consumption estimates of each sector derived from the disaggregated load are found to closely align with sample-based indices and be more precise than forecasting approaches based on these indices for real-time monitoring.

</details>


### [4] [Cyclists route choice modeling from trip duration data in urban areas](https://arxiv.org/abs/2512.15257)
*Bertrand Jouve,Paul Rochet,Mohamadou Salifou*

Main category: stat.AP

TL;DR: 基于共享单车系统出行时长和起讫点数据，通过对数正态混合模型推断实际骑行路径，揭示城市骑行行为的稳定性和多样性。


<details>
  <summary>Details</summary>
Motivation: GPS数据的缺乏限制了城市骑行实际路径的重建能力，需要仅基于共享单车系统的出行时长和起讫点数据来推断骑行行为模式。

Method: 使用对数正态混合模型对出行时间分布进行建模，识别不同的行为模式；将观测时长与OpenStreetMap估计的最快路径时间进行比较；应用于图卢兹都市区380万次出行记录。

Result: 多数站点对的出行时长与OSM建议的最快路径时间高度一致，反映常规骑行行为；混合模型揭示了更异质的行为，包括较长行程、绕行或中途停留。

Conclusion: 该方法在数据有限情况下为使用分析提供了稳健工具，无需空间显式数据即可洞察城市移动动态，突出了骑行实践的稳定性和多样性。

Abstract: The lack of GPS data limits the ability to reconstruct the actual routes taken by cyclists in urban areas. This article introduces an inference method based solely on trip durations and origin-destination pairs from bike-sharing system (BSS) users. Travel time distributions are modeled using log-normal mixture models, allowing us to identify the presence of distinct behaviors. The approach is applied to 3.8 million trips recorded in 2022 in the Toulouse metropolitan area, with observed durations compared against travel times estimated by OpenStreetMap (OSM). Results show that, for many station pairs, trip durations align closely with the fastest route suggested by OSM, reflecting a dominant and routine practice. In other cases, mixture models reveal more heterogeneous behaviors, including longer trips, detours, or intermediate stops. This approach highlights both the stability and diversity of cycling practices, providing a robust tool for usage analysis in data-limited contexts, and offering new insights into urban mobility dynamics without relying on spatially explicit data.

</details>


### [5] [Change detection with adaptive sampling for binary responses](https://arxiv.org/abs/2512.15507)
*Yanqing Yi,Su-Fen Yang*

Main category: stat.AP

TL;DR: 提出一种自适应抽样方法用于多产线系统的变化检测，通过学习哪条产线更可能发生变化来分配更多抽样单元，通过马尔可夫决策过程优化抽样策略，在样本量≥20时比均匀抽样具有更好的统计功效。


<details>
  <summary>Details</summary>
Motivation: 在多产线系统中，传统均匀抽样方法效率低下，无法根据产线变化概率动态调整抽样资源。需要一种能够学习产线变化概率并自适应分配抽样单元的方法，以提高变化检测的统计功效和效率。

Method: 将自适应抽样过程建模为马尔可夫决策过程，整合抽样信息和变化似然比定义奖励函数，基于平均奖励准则使用贝尔曼算子迭代近似最优抽样策略。针对二元响应使用精确分布方法实现自适应抽样。

Result: 数值结果表明：1）自适应抽样更频繁地抽样有变化的产线；2）在样本量≥20时，检测变化的统计功效优于均匀抽样；3）随着样本量增加或失控与受控概率差异增大，自适应抽样平均分配给有变化产线的比例更高，统计功效相应提升。

Conclusion: 提出的自适应抽样方法能有效学习产线变化概率并优化抽样分配，在多产线系统变化检测中比传统均匀抽样方法具有更好的性能和统计功效，特别适用于中等及以上样本量的场景。

Abstract: We propose using an adaptive sampling method to detect changes for a system with multiple lines. The adaptive sampling utilizes the information in responses to learn on which line is more likely to have a change thus allocating more units to the line. The learning process is formatted as a Markov decision process by integrating sampling information with likelihood ratio for changes to define rewards and the optimal sampling is approximated by using the Bellman operator iteratively based on the average reward criterion. We demonstrate the performance of the proposed method for binary responses using the exact distribution method for adaptive sampling. Our numeric results show that the adaptive sampling samples more often the line that has a change and the statistical power to detect a change is better than those with the equal randomization for sample sizes of 20 or higher. When sample sizes increase or the difference between out-of-control and in-control probabilities increases, the adaptive sampling allocates higher proportion of units averagely to the line with a change and the statistical power to detect a change increases.

</details>


### [6] [A Statistical Framework for Spatial Boundary Estimation and Change Detection: Application to the Sahel Sahara Climate Transition](https://arxiv.org/abs/2512.15650)
*Stephen Tivenan,Indranil Sahoo,Yanjun Qian*

Main category: stat.AP

TL;DR: 提出一个结合异方差高斯过程回归与尺度化最大绝对差异全局包络检验的统一框架，用于估计空间边界曲线并检测其随时间变化，应用于萨赫勒-撒哈拉过渡带气候边界分析。


<details>
  <summary>Details</summary>
Motivation: 空间边界（如生态过渡带或气候体制界面）反映了陡峭的环境梯度，其结构变化可指示环境变化。然而，从噪声网格环境数据中量化边界位置的不确定性并正式检验其时间变化仍具挑战性。

Method: 结合异方差高斯过程回归与尺度化最大绝对差异全局包络检验的统一框架。异方差GP提供边界线的灵活概率重建，捕获空间变化的均值结构和位置特定变异性；检验提供严格的假设检验工具，用于检测边界行为偏离预期的情况。

Result: 模拟研究表明该方法在零假设下具有正确的检验水平，检测局部边界变化具有高功效。应用于1960-1989年萨赫勒-撒哈拉过渡带，未发现干旱-半干旱或半干旱-非干旱界面在十年尺度上的统计显著变化，但成功识别了1983和1984年极端干旱年份的局部边界变化，与气候研究记录的该时期界面异常一致。

Conclusion: 该框架为空间边界分析提供了统一的概率方法，能够量化不确定性并正式检验时间变化，成功应用于气候边界检测，识别了极端干旱事件期间的局部变化。

Abstract: Spatial boundaries, such as ecological transitions or climatic regime interfaces, capture steep environmental gradients, and shifts in their structure can signal emerging environmental changes. Quantifying uncertainty in spatial boundary locations and formally testing for temporal shifts remains challenging, especially when boundaries are derived from noisy, gridded environmental data. We present a unified framework that combines heteroskedastic Gaussian process (GP) regression with a scaled Maximum Absolute Difference (MAD) Global Envelope Test (GET) to estimate spatial boundary curves and assess whether they evolve over time. The heteroskedastic GP provides a flexible probabilistic reconstruction of boundary lines, capturing spatially varying mean structure and location specific variability, while the test offers a rigorous hypothesis testing tool for detecting departures from expected boundary behaviors. Simulation studies show that the proposed method achieves the correct size under the null and high power for detecting local boundary shifts. Applying our framework to the Sahel Sahara transition zone, using annual Koppen Trewartha climate classifications from 1960 to 1989, we find no statistically significant decade scale changes in the arid and semi arid or semi arid and non arid interfaces. However, the method successfully identifies localized boundary shifts during the extreme drought years of 1983 and 1984, consistent with climate studies documenting regional anomalies in these interfaces during that period.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning](https://arxiv.org/abs/2512.14709)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 该论文将Transformer自注意力机制解释为近似的向量符号架构(VSA)，认为注意力权重执行软解绑，残差连接实现多个绑定结构的叠加，并提出VSA启发的架构偏置来提升逻辑推理的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Transformer语言模型展现出类似推理的行为，但在需要稳定符号操作的任务上仍然脆弱。本文旨在通过向量符号架构(VSA)的视角来统一理解这些现象，解释Transformer内部机制如何近似实现符号操作，并解决常见的失败模式。

Method: 将自注意力机制解释为VSA：查询和键定义角色空间，值编码填充物，注意力权重执行软解绑，残差连接实现绑定结构的叠加。基于此视角，提出VSA启发的架构偏置，包括显式的绑定/解绑头和超维记忆层，以及促进角色-填充分离和鲁棒叠加的训练目标。

Result: 建立了Transformer内部机制与思维链跟踪、基于程序的推理和记忆增强工具使用之间的代数联系，解释了变量混淆和逻辑相关提示不一致等特征性失败模式。提出了衡量"VSA相似性"和逻辑组合性的度量标准。

Conclusion: 将注意力视为软向量符号计算为构建更可解释和逻辑可靠的推理系统提供了原则性途径。该视角有助于理解Transformer的推理能力及其局限性，并指导未来架构设计。

Abstract: Transformer-based language models display impressive reasoning-like behavior, yet remain brittle on tasks that require stable symbolic manipulation. This paper develops a unified perspective on these phenomena by interpreting self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA). In this view, queries and keys define role spaces, values encode fillers, attention weights perform soft unbinding, and residual connections realize superposition of many bound structures. We use this algebraic lens to relate transformer internals to chain-of-thought traces, program-based reasoning, and memory-augmented tool use, and to explain characteristic failure modes such as variable confusion and inconsistency across logically related prompts. Building on this perspective, we propose VSA-inspired architectural biases, including explicit binding/unbinding heads and hyperdimensional memory layers, and training objectives that promote role-filler separation and robust superposition. Finally, we outline metrics for measuring "VSA-likeness" and logical compositionality, and pose theoretical and architectural open problems. Overall, the paper argues that viewing attention as soft vector-symbolic computation offers a principled route toward more interpretable and logically reliable reasoning systems.

</details>


### [8] [GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge](https://arxiv.org/abs/2512.14766)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Jiaoyan Chen,Steffen Staab,Yuan He,Evgeny Kharlamov*

Main category: cs.AI

TL;DR: 该论文提出了一种在知识图谱不完整情况下构建KGQA基准的方法，并开发了自适应图推理智能体（GR-Agent）来解决不完整KG中的推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有KGQA基准通常假设知识图谱是完整的，这忽略了现实世界中知识图谱不完整的事实。当直接支持的三元组缺失时，需要从现有事实中进行推理，而现有方法在这种不完整情况下的推理能力有限。

Method: 1) 提出构建不完整KG基准的方法论，移除直接支持的三元组但保留替代推理路径；2) 开发自适应图推理智能体（GR-Agent），将KG构建为交互环境，将KGQA形式化为智能体与环境交互，使用图推理工具作为动作空间，并维护潜在支持推理证据的记忆。

Result: 实验显示现有方法在不完整KG下性能显著下降，而GR-Agent在完整和不完整设置下均优于非训练基线，并与基于训练的方法表现相当。

Conclusion: 该研究强调了评估KGQA方法在不完整KG下的重要性，提出的GR-Agent通过智能体-环境交互框架有效解决了不完整KG中的推理挑战，展示了强大的推理能力。

Abstract: Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from existing facts. We bridge this gap by proposing a methodology for constructing benchmarks under KG incompleteness, which removes direct supporting triples while ensuring that alternative reasoning paths required to infer the answer remain. Experiments on benchmarks constructed using our methodology show that existing methods suffer consistent performance degradation under incompleteness, highlighting their limited reasoning ability. To overcome this limitation, we present the Adaptive Graph Reasoning Agent (GR-Agent). It first constructs an interactive environment from the KG, and then formalizes KGQA as agent environment interaction within this environment. GR-Agent operates over an action space comprising graph reasoning tools and maintains a memory of potential supporting reasoning evidence, including relevant relations and reasoning paths. Extensive experiments demonstrate that GR-Agent outperforms non-training baselines and performs comparably to training-based methods under both complete and incomplete settings.

</details>


### [9] [IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection](https://arxiv.org/abs/2512.14792)
*Roman Nekrasov,Stefano Fossati,Indika Kumara,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.AI

TL;DR: 该研究通过系统注入结构化配置知识，显著提升了LLM生成Terraform IaC代码的成功率，但发现技术正确性与意图对齐之间存在差距。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在生成正确且意图对齐的基础设施即代码(IaC)方面成功率较低，需要探索改进方法。

Method: 增强IaC-Eval基准测试，开发LLM辅助IaC生成的错误分类法，实施从朴素RAG到图RAG的知识注入技术，包括语义增强和资源间依赖建模。

Result: 基线LLM性能较差(27.1%总体成功率)，注入结构化配置知识后技术验证成功率提升至75.3%，总体成功率提升至62.6%。

Conclusion: 虽然技术正确性显著提升，但意图对齐存在瓶颈，揭示了"正确性-一致性差距"：LLM可以成为熟练的"编码者"，但在满足细微用户意图方面仍是有限的"架构师"。

Abstract: Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a "Correctness-Congruence Gap" where LLMs can become proficient "coders" but remain limited "architects" in fulfilling nuanced user intent.

</details>


### [10] [AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally](https://arxiv.org/abs/2512.14910)
*Nadine Angela Cantonjos,Arpita Biswas*

Main category: cs.AI

TL;DR: AgroAskAI是一个用于农业气候适应的多智能体推理系统，通过模块化架构协调专门化智能体，集成实时工具和数据，为农村社区提供可操作的气候适应决策支持。


<details>
  <summary>Details</summary>
Motivation: 农村农业地区面临干旱、强降雨和天气模式变化等气候相关风险的损害，需要适应性风险管理解决方案。现有系统多为单智能体模型或多智能体仅用于静态功能，缺乏支持动态协作推理和情境感知输出的架构。

Method: 提出AgroAskAI多智能体推理系统，采用模块化、角色专门化架构，使用责任链方法协调自主智能体，集成实时工具和数据集。系统包含治理机制减少幻觉，支持内部反馈和多语言交互。

Result: 实验表明，通过额外工具和提示优化，AgroAskAI在常见农业气候适应查询中能提供更可操作、有依据且包容的输出，展示了智能体AI在农业气候适应决策支持中的潜力。

Conclusion: AgroAskAI展示了智能体AI在农业气候适应中提供可持续和负责任决策支持的潜力，特别关注弱势农村社区的需求，通过多智能体协作推理实现更有效的解决方案。

Abstract: Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.

</details>


### [11] [Beyond Accuracy: A Geometric Stability Analysis of Large Language Models in Chess Evaluation](https://arxiv.org/abs/2512.15033)
*Xidan Song,Weiqi Wang,Ruifeng Cao,Qingya Hu*

Main category: cs.AI

TL;DR: 论文提出几何稳定性框架，发现LLMs在标准棋局评估中表现良好，但在几何变换下出现灾难性性能下降，揭示了准确性与稳定性之间的悖论。


<details>
  <summary>Details</summary>
Motivation: 传统基于准确率的LLMs评估方法无法区分真正的几何推理与对标准棋盘状态的表面记忆，需要更严格的评估框架来测试模型在不变变换下的稳定性。

Method: 提出几何稳定性框架，通过棋盘旋转、镜像对称、颜色反转和格式转换等不变变换，对6个最先进的LLMs（包括GPT-5.1、Claude Sonnet 4.5和Kimi K2 Turbo）进行测试，使用约3000个棋局数据集。

Result: 发现准确性-稳定性悖论：GPT-5.1在标准位置上接近最优准确率，但在几何扰动下（特别是旋转任务）错误率飙升600%以上；Claude Sonnet 4.5和Kimi K2 Turbo在所有变换轴上保持高一致性；Gemini 2.5 Flash在非法状态拒绝方面表现最佳（96.0%）。

Conclusion: 几何稳定性为AI评估提供了正交且必要的指标，能够有效区分推理能力与数据污染和过拟合，是评估大规模模型真实理解能力的关键代理指标。

Abstract: The evaluation of Large Language Models (LLMs) in complex reasoning domains typically relies on performance alignment with ground-truth oracles. In the domain of chess, this standard manifests as accuracy benchmarks against strong engines like Stockfish. However, high scalar accuracy does not necessarily imply robust conceptual understanding. This paper argues that standard accuracy metrics fail to distinguish between genuine geometric reasoning and the superficial memorization of canonical board states. To address this gap, we propose a Geometric Stability Framework, a novel evaluation methodology that rigorously tests model consistency under invariant transformations-including board rotation, mirror symmetry, color inversion, and format conversion. We applied this framework to a comparative analysis of six state-of-the-art LLMs including GPT-5.1, Claude Sonnet 4.5, and Kimi K2 Turbo, utilizing a dataset of approximately 3,000 positions. Our results reveal a significant Accuracy-Stability Paradox. While models such as GPT-5.1 achieve near-optimal accuracy on standard positions, they exhibit catastrophic degradation under geometric perturbation, specifically in rotation tasks where error rates surge by over 600%. This disparity suggests a reliance on pattern matching over abstract spatial logic. Conversely, Claude Sonnet 4.5 and Kimi K2 Turbo demonstrate superior dual robustness, maintaining high consistency across all transformation axes. Furthermore, we analyze the trade-off between helpfulness and safety, identifying Gemini 2.5 Flash as the leader in illegal state rejection (96.0%). We conclude that geometric stability provides an orthogonal and essential metric for AI evaluation, offering a necessary proxy for disentangling reasoning capabilities from data contamination and overfitting in large-scale models.

</details>


### [12] [ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I](https://arxiv.org/abs/2512.15298)
*Seok-Hyun Ga,Chun-Yen Chang*

Main category: cs.AI

TL;DR: 该研究分析了GPT-4o、Gemini 2.5等大语言模型在韩国高考地球科学I试题上的表现，发现模型存在感知-认知鸿沟、计算-概念化差异和过程幻觉等认知局限，为设计"AI抗性题目"提供了依据。


<details>
  <summary>Details</summary>
Motivation: 随着学生使用AI完成作业的情况日益普遍，学术诚信和评估有效性受到威胁。研究旨在深入分析先进大语言模型的多模态科学推理能力和认知局限，为应对AI在课程作业中的未经授权使用提供解决方案。

Method: 使用2025年韩国高考地球科学I试题，评估GPT-4o、Gemini 2.5 Flash和Gemini 2.5 Pro三种模型。设计三种实验条件：整页输入、单项输入和优化多模态输入，评估不同数据结构下的模型表现。进行定量和定性分析。

Result: 非结构化输入导致因分割和OCR失败而性能显著下降。即使在优化条件下，模型仍表现出基本推理缺陷。定性分析发现"感知错误"占主导，存在"感知-认知鸿沟"（模型能识别视觉数据但无法解释示意图的符号意义）、"计算-概念化差异"（能计算但无法应用科学概念）和"过程幻觉"（跳过视觉验证依赖背景知识）。

Conclusion: 研究揭示了AI模型在科学推理中的特定认知弱点，为设计针对这些弱点的"AI抗性题目"提供了可行线索。通过利用AI的感知-认知鸿沟等弱点，教育者可以区分真实学生能力与AI生成回答，确保评估公平性。

Abstract: The rapid development of Generative AI is bringing innovative changes to education and assessment. As the prevalence of students utilizing AI for assignments increases, concerns regarding academic integrity and the validity of assessments are growing. This study utilizes the Earth Science I section of the 2025 Korean College Scholastic Ability Test (CSAT) to deeply analyze the multimodal scientific reasoning capabilities and cognitive limitations of state-of-the-art Large Language Models (LLMs), including GPT-4o, Gemini 2.5 Flash, and Gemini 2.5 Pro. Three experimental conditions (full-page input, individual item input, and optimized multimodal input) were designed to evaluate model performance across different data structures. Quantitative results indicated that unstructured inputs led to significant performance degradation due to segmentation and Optical Character Recognition (OCR) failures. Even under optimized conditions, models exhibited fundamental reasoning flaws. Qualitative analysis revealed that "Perception Errors" were dominant, highlighting a "Perception-Cognition Gap" where models failed to interpret symbolic meanings in schematic diagrams despite recognizing visual data. Furthermore, models demonstrated a "Calculation-Conceptualization Discrepancy," successfully performing calculations while failing to apply the underlying scientific concepts, and "Process Hallucination," where models skipped visual verification in favor of plausible but unfounded background knowledge. Addressing the challenge of unauthorized AI use in coursework, this study provides actionable cues for designing "AI-resistant questions" that target these specific cognitive vulnerabilities. By exploiting AI's weaknesses, such as the gap between perception and cognition, educators can distinguish genuine student competency from AI-generated responses, thereby ensuring assessment fairness.

</details>


### [13] [LADY: Linear Attention for Autonomous Driving Efficiency without Transformers](https://arxiv.org/abs/2512.15038)
*Jihao Huang,Xi Xia,Zhiyuan Li,Tianle Liu,Jingke Wang,Junbo Chen,Tengju Ye*

Main category: cs.AI

TL;DR: LADY是首个完全基于线性注意力的端到端自动驾驶生成模型，通过线性注意力机制实现恒定计算和内存成本的长时序建模，并在边缘设备上验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的端到端自动驾驶方法存在二次注意力计算成本问题，限制了长时空序列建模能力，特别是在资源受限的边缘平台上。同时，现有线性注意力架构仅支持自注意力，缺乏对自动驾驶至关重要的跨模态和跨时序交互支持。

Method: 提出LADY模型，采用完全线性注意力机制，实现恒定计算和内存成本的长时序上下文融合。引入轻量级线性交叉注意力机制，支持有效的跨模态信息交换。模型在推理时能够融合长范围时序上下文。

Result: 在NAVSIM和Bench2Drive基准测试中达到最先进性能，具有恒定时间和内存复杂度，提升了规划性能并显著降低了计算成本。模型已在边缘设备上部署验证，在资源受限场景中表现出实用性。

Conclusion: LADY通过线性注意力机制解决了端到端自动驾驶中的长时序建模效率问题，实现了恒定复杂度的长范围上下文融合和跨模态交互，为资源受限的边缘平台提供了实用的解决方案。

Abstract: End-to-end paradigms have demonstrated great potential for autonomous driving. Additionally, most existing methods are built upon Transformer architectures. However, transformers incur a quadratic attention cost, limiting their ability to model long spatial and temporal sequences-particularly on resource-constrained edge platforms. As autonomous driving inherently demands efficient temporal modeling, this challenge severely limits their deployment and real-time performance. Recently, linear attention mechanisms have gained increasing attention due to their superior spatiotemporal complexity. However, existing linear attention architectures are limited to self-attention, lacking support for cross-modal and cross-temporal interactions-both crucial for autonomous driving. In this work, we propose LADY, the first fully linear attention-based generative model for end-to-end autonomous driving. LADY enables fusion of long-range temporal context at inference with constant computational and memory costs, regardless of the history length of camera and LiDAR features. Additionally, we introduce a lightweight linear cross-attention mechanism that enables effective cross-modal information exchange. Experiments on the NAVSIM and Bench2Drive benchmarks demonstrate that LADY achieves state-of-the-art performance with constant-time and memory complexity, offering improved planning performance and significantly reduced computational cost. Additionally, the model has been deployed and validated on edge devices, demonstrating its practicality in resource-limited scenarios.

</details>


### [14] [Agentic AI for Integrated Sensing and Communication: Analysis, Framework, and Case Study](https://arxiv.org/abs/2512.15044)
*Wenwen Xie,Geng Sun,Ruichen Zhang,Xuejie Liu,Yinqiu Liu,Jiacheng Wang,Dusit Niyato,Ping Zhang*

Main category: cs.AI

TL;DR: 本文探讨了智能体AI在ISAC系统中的应用价值与前景，提出了一个新颖的智能体ISAC框架，并通过案例研究验证了其在优化ISAC性能方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 随着无线环境日益动态复杂，ISAC系统需要更智能的处理和更自主的操作来保持效率和适应性。智能体AI通过实现动态环境中的连续感知-推理-行动循环，为ISAC系统提供智能、自主、高效运行的可行解决方案。

Method: 首先全面回顾智能体AI和ISAC系统的关键特性；其次展示ISAC系统的几种常见优化方法，并突出基于生成式AI的智能体AI的显著优势；然后提出一个新颖的智能体ISAC框架，并通过案例研究验证其优越性。

Result: 提出的智能体ISAC框架在优化ISAC性能方面表现出优越性，案例研究验证了其有效性。智能体AI能够显著提升ISAC系统在动态复杂环境中的自适应能力和运行效率。

Conclusion: 智能体AI为ISAC系统提供了强大的智能化和自主化解决方案，能够有效应对动态复杂无线环境的挑战。未来需要进一步研究智能体AI在ISAC系统中的具体应用方向和技术实现路径。

Abstract: Integrated sensing and communication (ISAC) has emerged as a key development direction in the sixth-generation (6G) era, which provides essential support for the collaborative sensing and communication of future intelligent networks. However, as wireless environments become increasingly dynamic and complex, ISAC systems require more intelligent processing and more autonomous operation to maintain efficiency and adaptability. Meanwhile, agentic artificial intelligence (AI) offers a feasible solution to address these challenges by enabling continuous perception-reasoning-action loops in dynamic environments to support intelligent, autonomous, and efficient operation for ISAC systems. As such, we delve into the application value and prospects of agentic AI in ISAC systems in this work. Firstly, we provide a comprehensive review of agentic AI and ISAC systems to demonstrate their key characteristics. Secondly, we show several common optimization approaches for ISAC systems and highlight the significant advantages of generative artificial intelligence (GenAI)-based agentic AI. Thirdly, we propose a novel agentic ISAC framework and prensent a case study to verify its superiority in optimizing ISAC performance. Finally, we clarify future research directions for agentic AI-based ISAC systems.

</details>


### [15] [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)
*Jinwu Hu,Dongjin Yang,Langyu Bian,Zhiquan Wen,Yufeng Wang,Yaofo Chen,Bin Xiao,Yuanqing Li,Mingkui Tan*

Main category: cs.AI

TL;DR: CogER是一个受人类分层推理启发的框架，通过动态选择最适合每个查询的推理策略来平衡LLM推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理策略主要依赖LLM自身的快慢模式（如o1思考），难以在不同难度查询间平衡推理效率和准确性。

Method: 1) 评估查询复杂度并分配到预定义级别；2) 将策略选择建模为马尔可夫决策过程，使用强化学习训练CogER-Agent；3) 引入认知工具辅助推理，使LLM能在思维链中自主调用外部工具。

Result: CogER在In-Domain任务上实现至少13%的相对平均精确匹配提升，在Out-of-Domain任务上实现8%的相对增益，优于最先进的测试时扩展方法。

Conclusion: CogER通过动态策略选择和工具集成，有效解决了LLM推理中效率与准确性的平衡问题，为自适应推理提供了新方向。

Abstract: Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.

</details>


### [16] [A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem](https://arxiv.org/abs/2512.15198)
*Mohsen Nafar,Michael Römer,Lin Xie*

Main category: cs.AI

TL;DR: 提出基于聚类的变量排序框架，通过将变量分组来减少动态排序启发式搜索空间，提高决策图松弛质量，在最大加权独立集问题上显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 决策图松弛的质量（对偶界紧度）严重依赖变量排序和合并决策。动态变量排序启发式能收紧界，但全局评估所有未固定变量计算开销大，需要平衡这一权衡。

Method: 提出聚类框架：先将变量分区成簇，再基于结构分解指导排序。研究两种策略：1) 簇到簇策略，按问题特定聚合标准（如MWISP中累积顶点权重）顺序处理簇；2) 选取排序策略，迭代从各簇选择并排序代表变量以平衡局部多样性和启发式指导。基于MWISP决策图大小增长理论分析，提出两种设置簇数策略。

Result: 将策略嵌入基于决策图的分支定界算法，在MWISP基准实例上评估。相比标准动态变量排序基线，所提方法一致降低计算成本。

Conclusion: 基于聚类的变量排序框架能有效减少动态排序启发式的搜索空间，在保持对偶界质量的同时显著降低计算开销，为离散优化中决策图编译提供了更高效的变量排序方法。

Abstract: Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these relaxed diagrams, i.e. the tightness of the resulting dual bounds, depends critically on the variable ordering and the merging decisions executed during compilation. While dynamic variable ordering heuristics effectively tighten bounds, they often incur computational overhead when evaluated globally across the entire variable set. To mitigate this trade-off, this work introduces a novel clustering-based framework for variable ordering. Instead of applying dynamic ordering heuristics to the full set of unfixed variables, we first partition variables into clusters. We then leverage this structural decomposition to guide the ordering process, significantly reducing the heuristic's search space. Within this framework, we investigate two distinct strategies: Cluster-to-Cluster, which processes clusters sequentially using problem-specific aggregate criteria (such as cumulative vertex weights in the Maximum Weighted Independent Set Problem (MWISP)), and Pick-and-Sort, which iteratively selects and sorts representative variables from each cluster to balance local diversity with heuristic guidance. Later on, developing some theoretical results on the growth of the size of DDs for MWISP we propose two different policies for setting the number of clusters within the proposed framework. We embed these strategies into a DD-based branch-and-bound algorithm and evaluate them on the MWISP. Across benchmark instances, the proposed methodology consistently reduces computational costs compared to standard dynamic variable ordering baseline.

</details>


### [17] [CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications](https://arxiv.org/abs/2512.15231)
*Zhengchao Chen,Haoran Wang,Jing Yao,Pedram Ghamisi,Jun Zhou,Peter M. Atkinson,Bing Zhang*

Main category: cs.AI

TL;DR: CangLing-KnowFlow是一个统一智能代理框架，通过集成程序知识库、动态工作流调整和进化记忆模块，实现遥感数据处理从预处理到高级解释的端到端自动化。


<details>
  <summary>Details</summary>
Motivation: 现有遥感自动化系统通常是任务特定的，缺乏统一框架来管理从数据预处理到高级解释的多样化端到端工作流。需要解决通用智能代理在处理复杂遥感任务时出现的幻觉问题和工作流失败问题。

Method: 提出CangLing-KnowFlow框架，包含三个核心组件：1) 程序知识库(PKB)，包含1,008个专家验证的工作流案例，覆盖162个实际遥感任务；2) 动态工作流调整，在运行时失败时自主诊断和重新规划恢复策略；3) 进化记忆模块，从失败事件中持续学习，迭代增强代理知识和性能。

Result: 在KnowFlow-Bench基准测试（包含324个受真实应用启发的工作流）上评估，使用13个顶级LLM骨干（从开源到商业）。在所有复杂任务中，CangLing-KnowFlow在任务成功率上比Reflexion基线至少高出4%。

Conclusion: CangLing-KnowFlow通过将专家知识转化为自适应且可验证的程序，展示了作为解决复杂地球观测挑战的稳健、高效、可扩展自动化解决方案的巨大潜力。

Abstract: The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--across diverse RS applications. To address this gap, this paper introduces CangLing-KnowFlow, a unified intelligent agent framework that integrates a Procedural Knowledge Base (PKB), Dynamic Workflow Adjustment, and an Evolutionary Memory Module. The PKB, comprising 1,008 expert-validated workflow cases across 162 practical RS tasks, guides planning and substantially reduces hallucinations common in general-purpose agents. During runtime failures, the Dynamic Workflow Adjustment autonomously diagnoses and replans recovery strategies, while the Evolutionary Memory Module continuously learns from these events, iteratively enhancing the agent's knowledge and performance. This synergy enables CangLing-KnowFlow to adapt, learn, and operate reliably across diverse, complex tasks. We evaluated CangLing-KnowFlow on the KnowFlow-Bench, a novel benchmark of 324 workflows inspired by real-world applications, testing its performance across 13 top Large Language Model (LLM) backbones, from open-source to commercial. Across all complex tasks, CangLing-KnowFlow surpassed the Reflexion baseline by at least 4% in Task Success Rate. As the first most comprehensive validation along this emerging field, this research demonstrates the great potential of CangLing-KnowFlow as a robust, efficient, and scalable automated solution for complex EO challenges by leveraging expert knowledge (Knowledge) into adaptive and verifiable procedures (Flow).

</details>


### [18] [Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis](https://arxiv.org/abs/2512.15295)
*Toshihide Ubukata,Enhong Mu,Takuto Yamauchi,Mingyue Zhang,Jialong Li,Kenji Tei*

Main category: cs.AI

TL;DR: 本文提出GCRL方法，通过图神经网络增强强化学习，改进控制器合成中的探索策略，在大多数基准域中表现出更好的学习效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 控制器合成是自动生成满足特定属性的LTS控制器的形式化方法，但其效率严重依赖探索策略。现有方法通常基于固定规则或仅考虑有限当前特征的强化学习策略，缺乏对历史探索信息的有效利用。

Method: 提出GCRL方法，将图神经网络与强化学习结合，将LTS探索历史编码为图结构，从而捕获更广泛的非当前上下文信息，提升探索策略的智能性。

Result: 在五个基准域的对比实验中，GCRL在四个域中表现出优于现有方法的学习效率和泛化能力，但在一个具有高对称性和严格局部交互特性的域中表现不佳。

Conclusion: GCRL通过整合图神经网络有效增强了控制器合成中的探索策略，在大多数情况下提升了学习效率和泛化能力，但对于特定结构特征的域仍需进一步改进。

Abstract: Controller synthesis is a formal method approach for automatically generating Labeled Transition System (LTS) controllers that satisfy specified properties. The efficiency of the synthesis process, however, is critically dependent on exploration policies. These policies often rely on fixed rules or strategies learned through reinforcement learning (RL) that consider only a limited set of current features. To address this limitation, this paper introduces GCRL, an approach that enhances RL-based methods by integrating Graph Neural Networks (GNNs). GCRL encodes the history of LTS exploration into a graph structure, allowing it to capture a broader, non-current-based context. In a comparative experiment against state-of-the-art methods, GCRL exhibited superior learning efficiency and generalization across four out of five benchmark domains, except one particular domain characterized by high symmetry and strictly local interactions.

</details>


### [19] [SCOPE: Prompt Evolution for Enhancing Agent Effectiveness](https://arxiv.org/abs/2512.15374)
*Zehua Pei,Hui-Ling Zhen,Shixiong Kai,Sinno Jialin Pan,Yunhe Wang,Mingxuan Yuan,Bei Yu*

Main category: cs.AI

TL;DR: SCOPE通过自动演化提示来优化LLM代理的上下文管理，将上下文管理视为在线优化问题，显著提升了任务成功率


<details>
  <summary>Details</summary>
Motivation: LLM代理在动态环境中面临上下文管理的瓶颈，静态提示缺乏有效管理机制，导致频繁的纠正和增强失败

Method: 提出SCOPE框架，将上下文管理视为在线优化问题，采用双流机制平衡战术特异性（解决即时错误）和战略通用性（演化长期原则），并引入视角驱动探索最大化策略覆盖

Result: 在HLE基准测试中，任务成功率从14.23%提升到38.64%，无需人工干预

Conclusion: SCOPE通过自动演化提示有效解决了LLM代理的上下文管理问题，显著提升了代理在动态环境中的性能

Abstract: Large Language Model (LLM) agents are increasingly deployed in environments that generate massive, dynamic contexts. However, a critical bottleneck remains: while agents have access to this context, their static prompts lack the mechanisms to manage it effectively, leading to recurring Corrective and Enhancement failures. To address this capability gap, we introduce \textbf{SCOPE} (Self-evolving Context Optimization via Prompt Evolution). SCOPE frames context management as an \textit{online optimization} problem, synthesizing guidelines from execution traces to automatically evolve the agent's prompt. We propose a Dual-Stream mechanism that balances tactical specificity (resolving immediate errors) with strategic generality (evolving long-term principles). Furthermore, we introduce Perspective-Driven Exploration to maximize strategy coverage, increasing the likelihood that the agent has the correct strategy for any given task. Experiments on the HLE benchmark show that SCOPE improves task success rates from 14.23\% to 38.64\% without human intervention. We make our code publicly available at https://github.com/JarvisPei/SCOPE.

</details>


### [20] [Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations](https://arxiv.org/abs/2512.15388)
*Reinhard Moratz,Niklas Daute,James Ondieki,Markus Kattenbeck,Mario Krajina,Ioannis Giannopoulos*

Main category: cs.AI

TL;DR: 该论文通过定性空间关系提升大语言模型为行人提供路线指引的能力


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在提供行人路线指引时缺乏对空间关系的准确理解和表达，需要改进其空间推理能力

Method: 利用定性空间关系（如方向、拓扑、距离等关系）来增强大语言模型的空间理解和表达

Result: 改进后的大语言模型能够提供更准确、更符合人类认知的行人路线指引

Conclusion: 定性空间关系是提升大语言模型空间推理和路线指引能力的有效方法

Abstract: This paper deals with improving the capabilities of Large Language Models (LLM) to provide route instructions for pedestrian wayfinders by means of qualitative spatial relations.

</details>


### [21] [Outer-Learning Framework for Playing Multi-Player Trick-Taking Card Games: A Case Study in Skat](https://arxiv.org/abs/2512.15435)
*Stefan Edelkamp*

Main category: cs.AI

TL;DR: 提出一个通过自对弈AI游戏扩展人类专家游戏数据库的通用外学习框架，提高多玩家纸牌游戏早期决策的预测准确性


<details>
  <summary>Details</summary>
Motivation: 在多玩家纸牌游戏（如Skat或Bridge）中，早期阶段（叫牌、游戏选择、初始牌选择）比中后期游戏对成功更为关键。当前计算限制下，这些早期决策依赖于从大量人类专家游戏中提取的统计信息，但数据有限。

Method: 提出通用引导外学习框架，通过自对弈AI游戏生成数百万新游戏来扩展人类游戏数据库，合并统计信息。使用完美特征哈希函数处理压缩表，构建自改进的纸牌游戏引擎，在自学习过程中持续改进新推断的知识。

Result: 在Skat游戏中的案例研究表明，该自动化方法可以支持游戏中的各种决策，提高预测准确性。

Conclusion: 通过结合人类专家数据和AI自对弈生成的扩展数据，可以显著改进多玩家纸牌游戏的早期决策系统，实现持续自我改进的游戏引擎。

Abstract: In multi-player card games such as Skat or Bridge, the early stages of the game, such as bidding, game selection, and initial card selection, are often more critical to the success of the play than refined middle- and end-game play. At the current limits of computation, such early decision-making resorts to using statistical information derived from a large corpus of human expert games. In this paper, we derive and evaluate a general bootstrapping outer-learning framework that improves prediction accuracy by expanding the database of human games with millions of self-playing AI games to generate and merge statistics. We implement perfect feature hash functions to address compacted tables, producing a self-improving card game engine, where newly inferred knowledge is continuously improved during self-learning. The case study in Skat shows that the automated approach can be used to support various decisions in the game.

</details>


### [22] [Intent-Driven UAM Rescheduling](https://arxiv.org/abs/2512.15462)
*Jeongseok Kim,Kangjin Kim*

Main category: cs.AI

TL;DR: 本文提出一个结合ASP和MILP的集成系统，用于处理UAM垂直起降机场的动态调度需求，支持模糊的人类重调度请求，提供可解释的自适应调度框架。


<details>
  <summary>Details</summary>
Motivation: 城市空中交通(UAM)中垂直起降机场资源有限，需要高效调度。现有调度问题通常采用混合整数线性规划(MILP)和资源受限项目调度问题(RCPSP)建模，但需要同时处理动态操作需求和模糊的人类重调度请求。

Method: 使用三值逻辑解释模糊用户意图和决策树，提出结合答案集编程(ASP)和MILP的新集成系统。该框架优化调度并透明支持人类输入。

Result: 开发了一个集成框架，能够优化UAM垂直起降机场的调度，同时处理动态需求和模糊的人类重调度请求，提供可解释的决策过程。

Conclusion: 提出的ASP-MILP集成系统为UAM调度提供了鲁棒、可解释、自适应的框架，能够有效处理动态操作需求和模糊的人类重调度请求。

Abstract: Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling problem (RCPSP). In this paper, we show our approach to handle both dynamic operation requirements and vague rescheduling requests from humans. Particularly, we utilize a three-valued logic for interpreting ambiguous user intents and a decision tree, proposing a newly integrated system that combines Answer Set Programming (ASP) and MILP. This integrated framework optimizes schedules and supports human inputs transparently. With this system, we provide a robust structure for explainable, adaptive UAM scheduling.

</details>


### [23] [Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision](https://arxiv.org/abs/2512.15489)
*Wei Du,Shubham Toshniwal,Branislav Kisacanin,Sadegh Mahdavi,Ivan Moshkov,George Armstrong,Stephen Ge,Edgar Minasyan,Feng Chen,Igor Gitman*

Main category: cs.AI

TL;DR: Nemotron-Math是一个大规模数学推理数据集，包含750万条解题轨迹，涵盖高、中、低三种推理模式，支持Python工具集成推理，在多个数学基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据集在推理风格多样性、长形式解题轨迹和工具集成方面存在局限，需要更高质量、更大规模的监督数据来提升数学推理模型的性能。

Method: 利用GPT-OSS-120B的多模式生成能力，整合85K个AoPS竞赛问题和262K个StackExchange-Math社区问题，创建包含7.5M解题轨迹的数据集，并开发顺序分桶策略加速长上下文训练。

Result: Nemotron-Math在匹配的AoPS问题上持续优于原始OpenMathReasoning，StackExchange-Math的加入显著提升了鲁棒性和泛化能力，在AIME 2024和2025上实现100% maj@16准确率。

Conclusion: Nemotron-Math通过大规模、多样化的数学推理数据，结合高效的长上下文训练策略，实现了最先进的数学推理性能，为数学AI研究提供了重要资源。

Abstract: High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).
  The dataset integrates 85K curated AoPS problems with 262K community-sourced StackExchange-Math problems, combining structured competition tasks with diverse real-world mathematical queries. We conduct controlled evaluations to assess the dataset quality.
  Nemotron-Math consistently outperforms the original OpenMathReasoning on matched AoPS problems. Incorporating StackExchange-Math substantially improves robustness and generalization, especially on HLE-Math, while preserving accuracy on math competition benchmarks.
  To support efficient long-context training, we develop a sequential bucketed strategy that accelerates 128K context-length fine-tuning by 2--3$\times$ without significant accuracy loss. Overall, Nemotron-Math enables state-of-the-art performance, including 100\% maj@16 accuracy on AIME 2024 and 2025 with Python TIR.

</details>


### [24] [Evaluating Large Language Models in Scientific Discovery](https://arxiv.org/abs/2512.15567)
*Zhangde Song,Jieyu Lu,Yuanqi Du,Botao Yu,Thomas M. Pruyn,Yue Huang,Kehan Guo,Xiuzhe Luo,Yuanhao Qu,Yi Qu,Yinkai Wang,Haorui Wang,Jeff Guo,Jingru Gan,Parshin Shojaee,Di Luo,Andres M Bran,Gen Li,Qiyuan Zhao,Shao-Xiong Lennon Luo,Yuxuan Zhang,Xiang Zou,Wanru Zhao,Yifan F. Zhang,Wucheng Zhang,Shunan Zheng,Saiyang Zhang,Sartaaj Takrim Khan,Mahyar Rajabi-Kochi,Samantha Paradi-Maropakis,Tony Baltoiu,Fengyu Xie,Tianyang Chen,Kexin Huang,Weiliang Luo,Meijing Fang,Xin Yang,Lixue Cheng,Jiajun He,Soha Hassoun,Xiangliang Zhang,Wei Wang,Chandan K. Reddy,Chao Zhang,Zhiling Zheng,Mengdi Wang,Le Cong,Carla P. Gomes,Chang-Yu Hsieh,Aditya Nandy,Philippe Schwaller,Heather J. Kulik,Haojun Jia,Huan Sun,Seyed Mohamad Moosavi,Chenru Duan*

Main category: cs.AI

TL;DR: 论文提出了一个基于场景的科学发现评估框架，用于评估大语言模型在真实科学研究项目中的能力，发现当前模型在科学发现方面存在系统性弱点，距离通用科学"超级智能"还很遥远。


<details>
  <summary>Details</summary>
Motivation: 当前的科学基准测试主要评估去语境化的知识，而忽略了驱动科学发现的迭代推理、假设生成和观察解释等关键能力。需要一个新的评估框架来更真实地评估LLMs在科学发现中的表现。

Method: 引入一个场景驱动的基准测试，由领域专家定义真正感兴趣的研究项目，并将其分解为模块化的研究场景。采用两阶段科学发现评估框架：1) 问题级准确性评估；2) 项目级性能评估，包括提出可测试假设、设计实验和解释结果。

Result: 评估显示：1) 与通用科学基准相比存在一致的性能差距；2) 模型规模和推理能力的扩展收益递减；3) 不同提供商的最先进模型存在系统性弱点；4) 研究场景间性能差异大，导致最佳模型选择不稳定。

Conclusion: 当前所有LLMs距离通用科学"超级智能"还很遥远，但已展现出在多种科学发现项目中的潜力。该框架为LLMs的科学发现相关评估提供了可复现的基准，并为其发展指明了实用路径。

Abstract: Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-grounded benchmark that evaluates LLMs across biology, chemistry, materials, and physics, where domain experts define research projects of genuine interest and decompose them into modular research scenarios from which vetted questions are sampled. The framework assesses models at two levels: (i) question-level accuracy on scenario-tied items and (ii) project-level performance, where models must propose testable hypotheses, design simulations or experiments, and interpret results. Applying this two-phase scientific discovery evaluation (SDE) framework to state-of-the-art LLMs reveals a consistent performance gap relative to general science benchmarks, diminishing return of scaling up model sizes and reasoning, and systematic weaknesses shared across top-tier models from different providers. Large performance variation in research scenarios leads to changing choices of the best performing model on scientific discovery projects evaluated, suggesting all current LLMs are distant to general scientific "superintelligence". Nevertheless, LLMs already demonstrate promise in a great variety of scientific discovery projects, including cases where constituent scenario scores are low, highlighting the role of guided exploration and serendipity in discovery. This SDE framework offers a reproducible benchmark for discovery-relevant evaluation of LLMs and charts practical paths to advance their development toward scientific discovery.

</details>


### [25] [A Decision-Theoretic Approach for Managing Misalignment](https://arxiv.org/abs/2512.15584)
*Daniel A. Herrmann,Abinav Chari,Isabelle Qian,Sree Sharvesh,B. A. Levinstein*

Main category: cs.AI

TL;DR: 论文提出了一个决策理论框架，用于在不确定性下确定何时应将决策委托给AI系统，强调需要在价值对齐、认知准确性和行动范围之间权衡，而非追求完美对齐。


<details>
  <summary>Details</summary>
Motivation: 现有价值对齐文献主要关注如何塑造AI价值观，但较少研究在不确定性条件下，如何判断不完美的对齐是否足以证明委托决策的合理性。需要系统分析委托决策的理性基础。

Method: 引入形式化的决策理论框架，精确分析委托决策中的权衡，考虑主体对AI价值对齐、认知准确性和行动范围的不确定性。开发了新颖的评分框架来量化事前决策。

Result: 分析揭示了两种委托场景的显著区别：通用委托需要近乎完美的价值对齐和完全的认知信任（实践中罕见）；而情境特定委托即使在显著不对齐的情况下也可能是最优的，因为AI的更高准确性或更广行动范围可能带来更好的整体决策问题。

Conclusion: 研究提供了原则性方法来确定AI在特定情境下是否足够对齐，将重点从实现完美对齐转向在不确定性下管理委托的风险和回报。情境特定委托可以在显著不对齐的情况下合理化。

Abstract: When should we delegate decisions to AI systems? While the value alignment literature has developed techniques for shaping AI values, less attention has been paid to how to determine, under uncertainty, when imperfect alignment is good enough to justify delegation. We argue that rational delegation requires balancing an agent's value (mis)alignment with its epistemic accuracy and its reach (the acts it has available). This paper introduces a formal, decision-theoretic framework to analyze this tradeoff precisely accounting for a principal's uncertainty about these factors. Our analysis reveals a sharp distinction between two delegation scenarios. First, universal delegation (trusting an agent with any problem) demands near-perfect value alignment and total epistemic trust, conditions rarely met in practice. Second, we show that context-specific delegation can be optimal even with significant misalignment. An agent's superior accuracy or expanded reach may grant access to better overall decision problems, making delegation rational in expectation. We develop a novel scoring framework to quantify this ex ante decision. Ultimately, our work provides a principled method for determining when an AI is aligned enough for a given context, shifting the focus from achieving perfect alignment to managing the risks and rewards of delegation under uncertainty.

</details>


### [26] [Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning](https://arxiv.org/abs/2512.15662)
*Jiaqi Xu,Cuiling Lan,Xuejin Chen,Yan LU*

Main category: cs.AI

TL;DR: STC框架在LLM中集成推理与自我批判，通过混合强化学习联合优化推理质量和自我评估，在数学推理基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有LLM将推理与验证分离：要么生成推理而不进行自我检查，要么依赖外部验证器事后检测错误。前者缺乏即时反馈，后者增加系统复杂性并阻碍同步学习。受人类批判性思维启发，需要统一框架在单模型中交织推理与自我批判。

Method: 提出Stepwise Think-Critique (STC)框架，在每一步推理中交织推理和自我批判。使用混合强化学习目标训练，结合推理奖励和批判一致性奖励，联合优化推理质量和自我评估。

Result: 在数学推理基准测试中，STC展现出强大的批判性思维能力，产生更可解释的推理轨迹，代表了LLM内置批判性思维的一步进展。

Conclusion: STC框架通过将推理与自我批判交织在单模型中，实现了更接近人类批判性思维的能力，为LLM内置批判性思维提供了有效途径。

Abstract: Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.

</details>


### [27] [Explaining the Reasoning of Large Language Models Using Attribution Graphs](https://arxiv.org/abs/2512.15663)
*Chase Walker,Rickard Ewetz*

Main category: cs.AI

TL;DR: CAGE框架通过构建属性图来改进大语言模型的解释性，量化每个生成内容如何受到提示和先前生成的影响，相比现有方法将忠实度平均提升达40%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然能力强大但推理过程不透明，存在安全和信任问题。现有的上下文属性方法只能直接关联生成标记与提示，忽略了生成过程中的代际影响，导致解释不完整。

Method: 提出CAGE框架，构建属性图（有向图）来量化每个生成内容如何受到提示和所有先前生成的影响。该图保持因果性和行随机性两个属性，通过沿图中路径边缘化中间贡献来计算上下文属性。

Result: 在多个模型、数据集、指标和方法上的实验表明，CAGE显著提升了上下文属性的忠实度，平均增益高达40%。

Conclusion: CAGE框架通过考虑代际影响改进了大语言模型的解释性，提供了更完整和忠实的上下文属性解释，有助于增强模型的安全性和可信度。

Abstract: Large language models (LLMs) exhibit remarkable capabilities, yet their reasoning remains opaque, raising safety and trust concerns. Attribution methods, which assign credit to input features, have proven effective for explaining the decision making of computer vision models. From these, context attributions have emerged as a promising approach for explaining the behavior of autoregressive LLMs. However, current context attributions produce incomplete explanations by directly relating generated tokens to the prompt, discarding inter-generational influence in the process. To overcome these shortcomings, we introduce the Context Attribution via Graph Explanations (CAGE) framework. CAGE introduces an attribution graph: a directed graph that quantifies how each generation is influenced by both the prompt and all prior generations. The graph is constructed to preserve two properties-causality and row stochasticity. The attribution graph allows context attributions to be computed by marginalizing intermediate contributions along paths in the graph. Across multiple models, datasets, metrics, and methods, CAGE improves context attribution faithfulness, achieving average gains of up to 40%.

</details>


### [28] [Artism: AI-Driven Dual-Engine System for Art Generation and Critique](https://arxiv.org/abs/2512.15710)
*Shuai Liu,Yiqing Tian,Yang Chen,Mar Canet Sola*

Main category: cs.AI

TL;DR: 提出双引擎AI架构方法，通过AIDA艺术社交网络和Ismism批判分析系统，探索艺术演化的潜在轨迹


<details>
  <summary>Details</summary>
Motivation: 解决艺术演化轨迹探索的复杂问题，从传统的单向批判转向智能交互的反思实践模式

Method: 采用深度学习与多智能体协作，构建AIDA（人工艺术家社交网络）和Ismism批判分析系统，实现艺术历史发展和概念创新模式的多维模拟

Result: 目前正在当代艺术概念研究中应用该方法，建立了基于AI驱动批判循环的通用方法论

Conclusion: 该框架为艺术的计算分析提供了新的可能性，实现了从传统批判到智能交互反思实践的转变

Abstract: This paper proposes a dual-engine AI architectural method designed to address the complex problem of exploring potential trajectories in the evolution of art. We present two interconnected components: AIDA (an artificial artist social network) and the Ismism Machine, a system for critical analysis. The core innovation lies in leveraging deep learning and multi-agent collaboration to enable multidimensional simulations of art historical developments and conceptual innovation patterns. The framework explores a shift from traditional unidirectional critique toward an intelligent, interactive mode of reflexive practice. We are currently applying this method in experimental studies on contemporary art concepts. This study introduces a general methodology based on AI-driven critical loops, offering new possibilities for computational analysis of art.

</details>


### [29] [Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants](https://arxiv.org/abs/2512.15712)
*Vincent Huang,Dami Choi,Daniel D. Johnson,Sarah Schwettmann,Jacob Steinhardt*

Main category: cs.AI

TL;DR: 提出Predictive Concept Decoder (PCD)，通过端到端训练的可解释性助手，从神经网络激活中提取稀疏概念列表来预测模型行为


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法依赖人工设计的代理来假设和测试内部激活与外部行为的关系，这种方法难以扩展且不够高效。需要一种更自动化的方法来解释神经网络的内部激活

Method: 训练可解释性助手，通过通信瓶颈将激活压缩为稀疏概念列表，然后解码器读取该列表并回答关于模型的自然语言问题。先在大规模无结构数据上预训练，然后针对特定问题进行微调

Result: PCD具有良好的扩展性：瓶颈概念的自解释分数随数据增加而提升，下游应用性能也相应改善。能够检测越狱攻击、秘密提示和植入的潜在概念，并能准确揭示潜在用户属性

Conclusion: 将可解释性任务转化为端到端训练目标的方法是有效的，PCD架构能够从神经网络激活中提取有意义的概念，为模型行为提供更忠实且可扩展的解释

Abstract: Interpreting the internal activations of neural networks can produce more faithful explanations of their behavior, but is difficult due to the complex structure of activation space. Existing approaches to scalable interpretability use hand-designed agents that make and test hypotheses about how internal activations relate to external behavior. We propose to instead turn this task into an end-to-end training objective, by training interpretability assistants to accurately predict model behavior from activations through a communication bottleneck. Specifically, an encoder compresses activations to a sparse list of concepts, and a decoder reads this list and answers a natural language question about the model. We show how to pretrain this assistant on large unstructured data, then finetune it to answer questions. The resulting architecture, which we call a Predictive Concept Decoder, enjoys favorable scaling properties: the auto-interp score of the bottleneck concepts improves with data, as does the performance on downstream applications. Specifically, PCDs can detect jailbreaks, secret hints, and implanted latent concepts, and are able to accurately surface latent user attributes.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [30] [How frontier AI companies could implement an internal audit function](https://arxiv.org/abs/2512.14902)
*Francesca Gomez,Adam Buick,Leah Ferentinos,Haelee Kim,Elley Lee*

Main category: cs.CY

TL;DR: 本文探讨了前沿AI开发者如何设计内部审计功能来提供有意义的保证，分析了审计范围、资源安排、频率和敏感信息访问四个核心设计维度及其权衡。


<details>
  <summary>Details</summary>
Motivation: 前沿AI开发者面临快速技术进步、极端风险暴露和日益严格的监管审查。虽然出现了各种外部评估和安全框架，但对内部组织保证如何构建以提供持续、基于证据的灾难性和系统性风险监督的关注相对较少。

Method: 基于专业内部审计标准、基于风险的保证理论和新兴的前沿AI治理文献，分析四个核心设计维度：审计范围（模型级、系统级、治理级控制）、资源安排（内部、共同外包、完全外包）、审计频率和节奏、以及获取敏感信息的访问权限。

Result: 研究发现，如果针对前沿AI背景进行精心设计，内部审计可以在加强安全治理、补充外部评估、为董事会和监管机构提供更高置信度的系统级灾难风险控制保证方面发挥核心作用。

Conclusion: 内部审计是前沿AI开发者风险管理体系的重要组成部分，需要平衡组织需求和安全性考量，通过合理的制度设计可以提供有效的系统级风险控制保证。

Abstract: Frontier AI developers operate at the intersection of rapid technical progress, extreme risk exposure, and growing regulatory scrutiny. While a range of external evaluations and safety frameworks have emerged, comparatively little attention has been paid to how internal organizational assurance should be structured to provide sustained, evidence-based oversight of catastrophic and systemic risks. This paper examines how an internal audit function could be designed to provide meaningful assurance for frontier AI developers, and the practical trade-offs that shape its effectiveness. Drawing on professional internal auditing standards, risk-based assurance theory, and emerging frontier-AI governance literature, we analyze four core design dimensions: (i) audit scope across model-level, system-level, and governance-level controls; (ii) sourcing arrangements (in-house, co-sourced, and outsourced); (iii) audit frequency and cadence; and (iv) access to sensitive information required for credible assurance. For each dimension, we define the relevant option space, assess benefits and limitations, and identify key organizational and security trade-offs. Our findings suggest that internal audit, if deliberately designed for the frontier AI context, can play a central role in strengthening safety governance, complementing external evaluations, and providing boards and regulators with higher-confidence, system-wide assurance over catastrophic risk controls.

</details>


### [31] [Governing rapid technological change: Policy Delphi on the future of European AI governance](https://arxiv.org/abs/2512.15196)
*Atte Ojanen,Johannes Anttila,Thilo H. K. Thelitz,Anna Bjork*

Main category: cs.CY

TL;DR: 本文通过德尔菲法研究欧洲AI治理，发现未来AI监管更依赖实施执行而非技术细节，并识别出理想政策方向与实际可行性之间的差距。


<details>
  <summary>Details</summary>
Motivation: AI快速发展给政策制定者带来独特挑战，需要前瞻性治理方法。本文旨在探讨专家对欧洲AI治理发展的关键分歧，并评估德尔菲法在AI等新兴技术治理中的适用性。

Method: 采用两轮政策德尔菲法研究，于2024年中与欧洲政策制定者、研究人员和非政府组织专家进行调研，收集他们对AI治理未来的共识与分歧。

Result: 研究发现：1）未来AI监管成功更依赖实际实施和执行而非技术细节；2）存在理想-概率差距，如公民参与等理想政策方向被认为可行性较低；3）揭示了监管监督与技术快速变化之间的张力。

Conclusion: 德尔菲法能有效揭示AI治理的多元视角，但理想政策方向与实际可行性之间存在显著差距，突显了监管适应技术变革的实践挑战。

Abstract: The rapid advancements in artificial intelligence (AI) present unique challenges for policymakers that seek to govern the technology. In this context, the Delphi method has become an established way to identify consensus and disagreement on emerging technological issues among experts in the field of futures studies and foresight. The aim of this article is twofold: first, it examines key tensions experts see in the development of AI governance in Europe, and second, it reflects on the Delphi method's capacity to inform anticipatory governance of emerging technologies like AI based on these insights. The analysis is based on the results of a two-round Policy Delphi study on the future of AI governance with European policymakers, researchers and NGOs, conducted in mid-2024. The Policy Delphi proved useful in revealing diverse perspectives on European AI governance, drawing out a consensus that future-proof AI regulation will likely depend more on practical implementation and enforcement of legislation than on its technical specifics or scope. Furthermore, the study identified a desirability-probability gap in AI governance: desirable policy directions, like greater citizen participation, were perceived as less probable and feasible. This highlights a tension between desirable regulatory oversight and the practical difficulty for regulation to keep up with technological change.

</details>


### [32] [Gaming the Arena: AI Model Evaluation and the Viral Capture of Attention](https://arxiv.org/abs/2512.15252)
*Sam Hind*

Main category: cs.CY

TL;DR: 论文探讨了AI创新中的"竞技场化"现象，即通过类似角斗士比赛的平台（如LMArena）来评估AI模型性能，这种趋势由追求关注度的"病毒式"欲望驱动，对AI产品的规模化和商业化至关重要。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和大型语言模型的爆发式发展，AI社区需要新的方法来独立评估模型性能。传统上由大学主导的AI创新正逐渐被行业所影响，因此需要研究新兴的评估实践如何塑造AI创新。

Method: 采用媒体研究、STS和计算机科学中关于基准测试和AI评估实践的研究方法，通过对领先的用户驱动AI模型评估平台LMArena进行技术志（technography）分析，考察AI模型评估中的"竞技场"现象。

Result: 识别了AI创新"竞技场化"的五个核心主题，揭示了这种趋势由追求AI社区内外关注的"病毒式"欲望驱动，这对AI产品的规模化和商业化至关重要。同时发现了"竞技场游戏"现象，即模型开发者试图通过这种平台获取关注。

Conclusion: AI创新的"竞技场化"反映了行业对AI评估实践的影响日益增强，这种基于关注度竞争的评估模式对AI产品的商业化有重要影响，但也引发了关于评估客观性和创新导向的思考。

Abstract: Innovation in artificial intelligence (AI) has always been dependent on technological infrastructures, from code repositories to computing hardware. Yet industry -- rather than universities -- has become increasingly influential in shaping AI innovation. As generative forms of AI powered by large language models (LLMs) have driven the breakout of AI into the wider world, the AI community has sought to develop new methods for independently evaluating the performance of AI models. How best, in other words, to compare the performance of AI models against other AI models -- and how best to account for new models launched on nearly a daily basis? Building on recent work in media studies, STS, and computer science on benchmarking and the practices of AI evaluation, I examine the rise of so-called 'arenas' in which AI models are evaluated with reference to gladiatorial-style 'battles'. Through a technography of a leading user-driven AI model evaluation platform, LMArena, I consider five themes central to the emerging 'arena-ization' of AI innovation. Accordingly, I argue that the arena-ization is being powered by a 'viral' desire to capture attention both in, and outside of, the AI community, critical to the scaling and commercialization of AI products. In the discussion, I reflect on the implications of 'arena gaming', a phenomenon through which model developers hope to capture attention.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [33] [Environmental Policy and Firm Performance in Europe: A Difference-in-Differences Approach with Spillovers](https://arxiv.org/abs/2512.15377)
*Andrea Ciaccio,Francesco Moscone,Elisa Tosetti*

Main category: econ.EM

TL;DR: 欧盟排放交易体系对受监管企业的直接减排效果被交易机制产生的间接溢出效应完全抵消，导致政策整体环境效益被中和。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注排放上限的政策效果，但忽略了交易机制在企业间创造的复杂相互依赖关系，这些关系可能改变政策的预期效果。需要区分政策的直接因果效应和交易产生的间接溢出效应。

Method: 开发了一种新颖的双重差分方法，能够区分政策对受监管企业的直接因果效应和企业间交易产生的间接溢出效应。该方法考虑了处理单元之间的潜在干扰，并通过蒙特卡洛模拟验证了估计量在有限样本中的良好表现。构建了2001-2017年欧洲工业场所排放的新数据库，将欧盟委员会的社区独立交易日志中的受监管工厂信息与欧洲污染物排放和转移登记册的排放数据相匹配。

Result: 研究发现，该体系仅减少了非交易工厂的排放，但当考虑交易工厂的溢出效应时，这种减排效果被完全抵消。这表明交易机制中和了政策的环境效益。

Conclusion: 交易机制可能削弱环境政策的有效性，这对未来环境政策设计和现有总量控制与交易政策的持续评估具有重要启示。需要更全面地考虑政策干预的间接效应。

Abstract: In this paper we investigate the causal impact of the European Union Emissions Trading System, a cap-and-trade scheme limiting greenhouse gas emissions of firms, on their environmental performance. Although previous studies have focused primarily on the effect of the emission cap imposed by the policy, we argue that the trading mechanism creates complex interdependencies among firms that can change the policy's intended effects. We develop a novel Difference-in-Differences approach that disentangles the direct causal effects of the scheme on regulated firms from the indirect spillover effects arising from trading among firms. By incorporating potential interference between treated units, our methodology allows a more comprehensive assessment of the policy's overall effectiveness. Monte Carlo simulations show that our proposed estimators perform well in finite samples, confirming the reliability of our approach. To assess the direct and indirect effects of the scheme, we construct a novel database on emissions of European industrial sites by matching information on treated plants from the European Commission's Community Independent Transaction Log with emission data from the European Pollutant Release and Transfer Register for the years from 2001 to 2017. We find that the scheme reduced emissions only for non-trading plants, but such reduction is entirely offset when accounting for spillovers from trading plants, thus suggesting that the trading mechanism neutralizes the environmental benefits of the policy. Our findings have important implications for the design of future environmental policies and the ongoing evaluation of cap and trade policies.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [34] [Effectively Detecting and Responding to Online Harassment with Large Language Models](https://arxiv.org/abs/2512.14700)
*Pinxian Lu,Nimra Ishfaq,Emma Win,Morgan Rose,Sierra R Strickland,Candice L Biernesser,Jamie Zelazny,Munmun De Choudhury*

Main category: cs.SI

TL;DR: 利用大语言模型（LLM）检测Instagram私信中的网络骚扰，并通过LLM生成比人类回复更有帮助的应对回复


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注公共社交媒体平台的网络骚扰，而对私信平台的关注较少。Instagram作为流行的私信平台，需要有效应对网络骚扰的方法

Method: 1) 招募人工标注者识别Instagram消息中的网络骚扰；2) 利用LLM流水线进行大规模标注，并与人工标注对比评估；3) 使用LLM生成并评估针对网络骚扰消息的模拟回复

Result: LLM标注流水线能够有效识别私信中的网络骚扰；与原始人类回复相比，LLM生成的模拟回复在帮助性方面表现更优

Conclusion: LLM在私信平台网络骚扰检测和应对方面具有应用潜力，能够提供比人类回复更有帮助的应对策略

Abstract: Online harassment has been a persistent issue in the online space. Predominantly, research focused on online harassment in public social media platforms, while less is placed on private messaging platforms. To address online harassment on one private messaging platform, Instagram, we leverage the capabilities of Large Language Models (LLMs). To achieve this, we recruited human labelers to identify online harassment in an Instagram messages dataset. Using the previous conversation as context, we utilize an LLM pipeline to conduct large-scale labeling on Instagram messages and evaluate its performance against human labels. Then, we use LLM to generate and evaluate simulated responses to online harassment messages. We find that the LLM labeling pipeline is capable of identifying online harassment in private messages. By comparing human responses and simulated responses, we also demonstrate that our simulated responses are superior in helpfulness compared to original human responses.

</details>


### [35] [SEMO: A Socio-Evolutionary Adaptive Optimization Framework for Dynamic Social Network Tie Management](https://arxiv.org/abs/2512.14703)
*Mohammad Zare*

Main category: cs.SI

TL;DR: 提出一个结合多臂老虎机（MAB）和马尔可夫决策过程（MDP）的计算框架，用于建模人类在不确定性下的社会决策，通过Social-UCB算法平衡探索新社会关系和利用现有关系以最大化社会进化适应度。


<details>
  <summary>Details</summary>
Motivation: 现有文献在探索-利用动态、网络演化和社会学习之间存在研究空白，需要统一的框架来研究适应性人类社会行为。

Method: 结合强化学习、贝叶斯信念更新和基于代理的模拟，在动态社会图上构建MAB-MDP集成优化问题，提出Social-UCB算法，使用UCB策略进行关系形成，并定义包含个体收益和网络级收益的社会进化适应度函数。

Result: Social-UCB算法在理论上保证对数遗憾，在模拟实验中比基线启发式方法获得更高的累积社会适应度和更高效的网络连接性。

Conclusion: 该集成模型通过统一探索-利用动态、网络演化和社会学习，为研究适应性人类社会行为提供了严谨的新工具。

Abstract: We propose a novel computational framework that models human social decision-making under uncertainty as an integrated Multi-Armed Bandit (MAB) and Markov Decision Process (MDP) optimization problem, in which agents adaptively balance the exploration of new social ties and the exploitation of existing relationships to maximize a socio-evolutionary fitness. The framework combines reinforcement learning, Bayesian belief updating, and agent-based simulation on a dynamic social graph, allowing each agent to use bandit-based Upper-Confidence-Bound (UCB) strategies for tie formation within an MDP of long-term social planning. We define a formal socio-evolutionary fitness function that captures both individual payoffs (e.g. shared information or support) and network-level benefits, and we derive update rules incorporating cognitive constraints and bounded rationality. Our Social-UCB algorithm, presented in full pseudocode, provably yields logarithmic regret and ensures stable exploitation via UCB-style bounds. In simulation experiments, Social-UCB consistently achieves higher cumulative social fitness and more efficient network connectivity than baseline heuristics. We include detailed descriptions of envisioned figures and tables (e.g. network evolution plots, model comparisons) to illustrate key phenomena. This integrated model bridges gaps in the literature by unifying exploration-exploitation dynamics, network evolution, and social learning, offering a rigorous new tool for studying adaptive human social behavior.

</details>


### [36] [Tourists Profiling by Interest Analysis](https://arxiv.org/abs/2512.14704)
*Sonia Djebali,Quentin Gabot,Guillaume Guerard*

Main category: cs.SI

TL;DR: 该论文提出结合定性和定量分析数字痕迹来理解旅游行为动态，特别是景点网络


<details>
  <summary>Details</summary>
Motivation: 数字革命改变了旅游行为分析，现有研究主要关注数字痕迹的定量方面，缺乏对定性维度的深入理解

Method: 建议采用定性和定量相结合的方法分析游客在旅行中留下的数字痕迹，特别关注景点网络动态

Result: 论文提出了一个研究框架，但未提供具体结果（基于摘要信息）

Conclusion: 需要结合定性和定量分析数字痕迹来更全面理解旅游行为动态和景点网络关系

Abstract: With the recent digital revolution, analyzing of tourists' behaviors and research fields associated with it have changed profoundly. It is now easier to examine behaviors of tourists using digital traces they leave during their travels. The studies conducted on diverse aspects of tourism focus on quantitative aspects of digital traces to reach its conclusions. In this paper, we suggest a study focused on both qualitative and quantitative aspect of digital traces to understand the dynamics governing tourist behavior, especially those concerning attractions networks.

</details>


### [37] [The Graph-Embedded Hazard Model (GEHM): Stochastic Network Survival Dynamics on Economic Graphs](https://arxiv.org/abs/2512.14705)
*Diego Vallarino*

Main category: cs.SI

TL;DR: 提出非线性演化框架，通过耦合图p-Laplacian扩散算子和随机结构漂移来建模加权经济网络上的生存动态，分析节点生存对非线性扩散压力的响应和稳定性阈值。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个框架来建模经济网络中的生存动态，考虑非线性扩散效应和网络结构的随机变化，以理解节点生存如何响应扩散压力以及网络拓扑如何影响稳定性。

Method: 耦合图p-Laplacian扩散算子和随机结构漂移，构建有限维PDE-SDE系统；使用增生算子理论、非线性半群方法和随机分析建立温和解的存在唯一性；推导拓扑依赖的能量耗散不等式；通过数值实验在Barabási-Albert网络上验证。

Result: 建立了温和解的存在唯一性；推导了拓扑依赖的能量耗散不等式；刻画了区分耗散、临界、放大和爆炸状态的稳定性阈值；数值实验显示枢纽主导放大非线性梯度并压缩稳定性边界，产生重尾生存分布和偶尔的爆炸行为。

Conclusion: 该框架成功捕捉了加权经济网络中生存动态的非线性扩散和随机结构漂移效应，揭示了网络拓扑（特别是枢纽主导）对稳定性边界的压缩效应，为理解经济网络中的生存分布和爆炸行为提供了理论工具。

Abstract: This paper develops a nonlinear evolution framework for modelling survival dynamics on weighted economic networks by coupling a graph-based $p$-Laplacian diffusion operator with a stochastic structural drift. The resulting finite-dimensional PDE--SDE system captures how node-level survival reacts to nonlinear diffusion pressures while an aggregate complexity factor evolves according to an Itô{} process. Using accretive operator theory, nonlinear semigroup methods, and stochastic analysis, we establish existence and uniqueness of mild solutions, derive topology-dependent energy dissipation inequalities, and characterise the stability threshold separating dissipative, critical, amplifying, and explosive regimes. Numerical experiments on Barabási--Albert networks confirm that hub dominance magnifies nonlinear gradients and compresses stability margins, producing heavy-tailed survival distributions and occasional explosive behaviour.

</details>


### [38] [Boundaries in Hypernetwork Theory: Structure and Scope](https://arxiv.org/abs/2512.14707)
*Richard D. Charlesworth*

Main category: cs.SI

TL;DR: 边界是超网络理论中的非结构性标签，用于限制可见性而不改变底层网络结构，通过投影操作创建子系统视图，支持模块化建模和重叠视角。


<details>
  <summary>Details</summary>
Motivation: 为超网络理论提供一个简单且保守的作用域机制，支持可重现的视图提取、稳定的子系统隔离和安全的模型探索，同时保持全局结构不变。

Method: 将边界形式化为附加在超单纯形上的注释，定义边界投影操作B(H, b) = π_b(H)来过滤携带特定边界的超单纯形，并定义作用域操作符应用作为对投影视图的普通结构核组合。

Result: 建立了边界作为保守作用域机制的形式化框架，实现了身份保持的子系统视图，支持局部推理而不修改全局超网络，与结构核完全兼容。

Conclusion: 边界提供了一种精确且最小化的作用域机制，补充但不扩展结构核，完善了超网络理论中实际多级建模所需的作用域机制。

Abstract: Boundaries in Hypernetwork Theory (HT) are non-structural tags that restrict visibility without altering the underlying hypernetwork. They attach to hypersimplices as annotations and participate in no identity, typing, or alpha/beta semantics. Projection over a boundary, B(H, b) = pi_b(H), is filtering only: it selects exactly those hypersimplices carrying b and preserves all axioms of the structural kernel. The backcloth remains immutable, and no new structure is created, removed, or inferred.
  This paper formalises boundaries as a simple and conservative scoping mechanism. It clarifies their syntax, their interaction with projection, and their use in producing identity-preserving subsystem views that support modular modelling and overlapping perspectives. The account also makes explicit why conservative scoping matters: boundaries provide reproducible view extraction, stable subsystem isolation, and safe model exploration without altering the global structure.
  Scoped operator application is defined as ordinary structural-kernel composition applied to projected views, ensuring that view-level reasoning remains local and does not modify the global hypernetwork. This establishes a disciplined separation between immutable structure and scoped analysis while retaining full compatibility with the structural kernel.
  The paper includes a worked example demonstrating how boundaries yield coherent, identity-preserving subsystem views and how scoped reasoning supports refinement within these views. The result is a precise and minimal account of boundaries that complements - but does not extend - the structural kernel and completes the scoping mechanism required for practical multilevel modelling with HT.

</details>


### [39] [Promoting Fairness in Information Access within Social Networks](https://arxiv.org/abs/2512.14711)
*Changan Liu,Xiaotian Zhou,Ahad N. Zehmakan,Zhongzhi Zhang*

Main category: cs.SI

TL;DR: 提出线性时间算法优化社交网络连接，以增强不同人口群体间的信息获取公平性


<details>
  <summary>Details</summary>
Motivation: 在线社交网络中，少数群体成员由于网络位置劣势，可能较少接收到传播的信息，需要优化网络连接来增强信息获取的公平性

Method: 1) 基于电阻距离的信息获取度量模型；2) 提出简单贪婪算法；3) 通过新颖近似技术将时间复杂度从立方降低到线性

Result: 1) 证明问题是NP-hard；2) 线性时间算法能在百万节点网络上产生准确解；3) 在真实和合成数据集上进行了广泛实验验证

Conclusion: 提出的线性时间算法能有效优化社交网络连接，显著提高不同群体间的信息获取公平性，适用于大规模网络

Abstract: The advent of online social networks has facilitated fast and wide spread of information. However, some users, especially members of minority groups, may be less likely to receive information spreading on the network, due to their disadvantaged network position. We study the optimization problem of adding new connections to a network to enhance fairness in information access among different demographic groups.
  We provide a concrete formulation of this problem where information access is measured in terms of resistance distance, {offering a new perspective that emphasizes global network structure and multi-path connectivity.} The problem is shown to be NP-hard. We propose a simple greedy algorithm which turns out to output accurate solutions, but its run time is cubic, which makes it undesirable for large networks. As our main technical contribution, we reduce its time complexity to linear, leveraging several novel approximation techniques. In addition to our theoretical findings, we also conduct an extensive set of experiments using both real-world and synthetic datasets. We demonstrate that our linear-time algorithm can produce accurate solutions for networks with millions of nodes.

</details>


### [40] [SoMe: A Realistic Benchmark for LLM-based Social Media Agents](https://arxiv.org/abs/2512.14720)
*Dizhan Xue,Jing Cui,Shengsheng Qian,Chuanrui Hu,Changsheng Xu*

Main category: cs.SI

TL;DR: SoMe是首个评估LLM智能体在社交媒体环境中能力的综合性基准，包含8个任务、900多万帖子、6000多用户资料，发现当前主流LLM在真实社交媒体任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在社交媒体上展现出强大能力并日益流行，但缺乏对其理解媒体内容、用户行为和复杂决策能力的全面评估。现有数据集和基准无法为基于LLM的社交媒体智能体提供真实多样的测试平台。

Method: 构建SoMe基准，包含8个社交媒体智能体任务、9,164,284个帖子、6,591个用户资料、25,686个报告和17,869个标注任务查询，涵盖多个社交媒体平台和外部网站，为LLM智能体提供访问和分析社交媒体数据的工具。

Result: 通过广泛的定量和定性分析，首次揭示了主流LLM智能体在真实社交媒体环境中的表现，发现当前闭源和开源LLM都无法令人满意地处理社交媒体智能体任务。

Conclusion: SoMe为未来社交媒体智能体提供了具有挑战性但有意义的测试平台，当前LLM在社交媒体任务处理上仍有明显局限，需要进一步改进。

Abstract: Intelligent agents powered by large language models (LLMs) have recently demonstrated impressive capabilities and gained increasing popularity on social media platforms. While LLM agents are reshaping the ecology of social media, there exists a current gap in conducting a comprehensive evaluation of their ability to comprehend media content, understand user behaviors, and make intricate decisions. To address this challenge, we introduce SoMe, a pioneering benchmark designed to evaluate social media agents equipped with various agent tools for accessing and analyzing social media data. SoMe comprises a diverse collection of 8 social media agent tasks, 9,164,284 posts, 6,591 user profiles, and 25,686 reports from various social media platforms and external websites, with 17,869 meticulously annotated task queries. Compared with the existing datasets and benchmarks for social media tasks, SoMe is the first to provide a versatile and realistic platform for LLM-based social media agents to handle diverse social media tasks. By extensive quantitative and qualitative analysis, we provide the first overview insight into the performance of mainstream agentic LLMs in realistic social media environments and identify several limitations. Our evaluation reveals that both the current closed-source and open-source LLMs cannot handle social media agent tasks satisfactorily. SoMe provides a challenging yet meaningful testbed for future social media agents. Our code and data are available at https://github.com/LivXue/SoMe

</details>


### [41] [Compute the edge p-Laplacian centrality for air traffic network](https://arxiv.org/abs/2512.14749)
*Loc Hoang Tran,Bao Nguyen Tran,Luong Anh Tuan Nguyen*

Main category: cs.SI

TL;DR: 本文提出了一种计算航空交通网络边p-Laplacian中心性的新方法，通过将网络转换为线图，然后计算线图的节点p-Laplacian中心性来间接获得边中心性。


<details>
  <summary>Details</summary>
Motivation: 直接计算航空交通网络的边p-Laplacian中心性非常困难，需要找到一种有效的替代方法来评估航空网络中的边重要性。

Method: 将航空交通网络转换为线图，然后基于未归一化图p-Laplacian算子（包括图的曲率算子，即未归一化图1-Laplacian算子）开发新的节点p-Laplacian中心性计算方法，用于计算线图的节点中心性。

Result: 实验结果表明，未归一化图p-Laplacian排序方法可以成功实现，能够有效计算航空网络的边中心性。

Conclusion: 通过线图转换和未归一化图p-Laplacian方法，成功解决了航空交通网络边p-Laplacian中心性的计算难题。

Abstract: The problem that we would like to solve in this paper is to compute the edge p-Laplacian centrality for the air traffic network. In this problem, instead of computing the edge p-Laplacian centrality directly which is the very hard problem, we convert the air traffic network to the line graph. Finally, we will compute the node p-Laplacian centrality of the line graph which is equivalent to the edge p-Laplacian of the air traffic network. In this paper, the novel un-normalized graph (p-) Laplacian based ranking method will be developed based on the un-normalized graph p-Laplacian operator definitions such as the curvature operator of graph (i.e. the un-normalized graph 1-Laplacian operator) and will be used to compute the node p-Laplacian centrality of the line graph. The results from the experiments show that the un-normalized graph p-Laplacian ranking methods can be implemented successfully.

</details>


### [42] [Cyberswarm: a novel swarm intelligence algorithm inspired by cyber community dynamics](https://arxiv.org/abs/2512.14752)
*Abdelsadeq Elfergany,Ammar Adl,Mohammed Kayed*

Main category: cs.SI

TL;DR: 提出一种基于群体智能的通用推荐算法，通过动态超图建模用户偏好和社区影响，利用中心性特征提取和Node2Vec嵌入，在多种推荐任务中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统难以适应动态变化的用户偏好和复杂社交网络中的交互，缺乏跨领域泛化能力，需要更自适应和通用的解决方案。

Method: 受社会心理学启发，提出通用群体智能推荐算法：1) 动态超图结构建模用户偏好和社区影响；2) 中心性特征提取和Node2Vec嵌入；3) 消息传递机制和分层图建模引导偏好演化；4) 实时适应变化行为。

Result: 在社交网络和内容发现等推荐任务中，HR、MRR、NDCG等关键指标在多个数据集上持续优于基线方法，模型在动态环境中表现出良好的适应性和精确性。

Conclusion: 该算法通过整合群体智能和网络动态，在个体偏好和社区影响之间建立桥梁，其通用设计适用于社交图、个性化学习和医疗图等多个领域，为解决推荐系统中的复杂优化问题提供了新思路。

Abstract: Recommendation systems face challenges in dynamically adapting to evolving user preferences and interactions within complex social networks. Traditional approaches often fail to account for the intricate interactions within cyber-social systems and lack the flexibility to generalize across diverse domains, highlighting the need for more adaptive and versatile solutions. In this work, we introduce a general-purpose swarm intelligence algorithm for recommendation systems, designed to adapt seamlessly to varying applications. It was inspired by social psychology principles. The framework models user preferences and community influences within a dynamic hypergraph structure. It leverages centrality-based feature extraction and Node2Vec embeddings. Preference evolution is guided by message-passing mechanisms and hierarchical graph modeling, enabling real-time adaptation to changing behaviors. Experimental evaluations demonstrated the algorithm's superior performance in various recommendation tasks, including social networks and content discovery. Key metrics such as Hit Rate (HR), Mean Reciprocal Rank (MRR), and Normalized Discounted Cumulative Gain (NDCG) consistently outperformed baseline methods across multiple datasets. The model's adaptability to dynamic environments allowed for contextually relevant and precise recommendations. The proposed algorithm represents an advancement in recommendation systems by bridging individual preferences and community influences. Its general-purpose design enables applications in diverse domains, including social graphs, personalized learning, and medical graphs. This work highlights the potential of integrating swarm intelligence with network dynamics to address complex optimization challenges in recommendation systems.

</details>


### [43] [Trustworthy Neighborhoods Mining: Homophily-Aware Neutral Contrastive Learning for Graph Clustering](https://arxiv.org/abs/2512.15027)
*Liang Peng,Yixuan Ye,Cheng Liu,Hangjun Che,Man-Fai Leung,Si Wu,Hau-San Wong*

Main category: cs.SI

TL;DR: 提出NeuCGC方法，通过引入中性对和自适应对比学习机制，解决传统基于邻居的对比学习在低同质性图上的局限性，实现更鲁棒的图聚类。


<details>
  <summary>Details</summary>
Motivation: 传统基于邻居的对比学习方法依赖于同质性假设（相连节点具有相似类别标签），但现实世界图中同质性水平各异。在低同质性图上应用这些方法会导致节点表示难以区分，因为邻居信息不可靠，难以识别不同同质性水平下的可信邻居。

Method: 提出NeuCGC方法，引入中性对（作为加权正对而非严格正负对），根据图的同质性水平动态调整。包含两个关键组件：1) 自适应对比邻居分布对齐，根据图的同质性水平调整；2) 对比邻居节点特征一致性学习，利用高置信度图的可靠邻居信息学习鲁棒节点表示。

Result: 实验结果表明该方法有效且鲁棒，优于其他最先进的图聚类方法。

Conclusion: NeuCGC通过中性对和自适应对比学习机制，能够处理不同同质性水平的图，有效利用可信邻居信息，实现更鲁棒的图聚类。

Abstract: Recently, neighbor-based contrastive learning has been introduced to effectively exploit neighborhood information for clustering. However, these methods rely on the homophily assumption-that connected nodes share similar class labels and should therefore be close in feature space-which fails to account for the varying homophily levels in real-world graphs. As a result, applying contrastive learning to low-homophily graphs may lead to indistinguishable node representations due to unreliable neighborhood information, making it challenging to identify trustworthy neighborhoods with varying homophily levels in graph clustering. To tackle this, we introduce a novel neighborhood Neutral Contrastive Graph Clustering method, NeuCGC, that extends traditional contrastive learning by incorporating neutral pairs-node pairs treated as weighted positive pairs, rather than strictly positive or negative. These neutral pairs are dynamically adjusted based on the graph's homophily level, enabling a more flexible and robust learning process. Leveraging neutral pairs in contrastive learning, our method incorporates two key components: (1) an adaptive contrastive neighborhood distribution alignment that adjusts based on the homophily level of the given attribute graph, ensuring effective alignment of neighborhood distributions, and (2) a contrastive neighborhood node feature consistency learning mechanism that leverages reliable neighborhood information from high-confidence graphs to learn robust node representations, mitigating the adverse effects of varying homophily levels and effectively exploiting highly trustworthy neighborhood information. Experimental results demonstrate the effectiveness and robustness of our approach, outperforming other state-of-the-art graph clustering methods. Our code is available at https://github.com/THPengL/NeuCGC.

</details>


### [44] [Model inference for ranking from pairwise comparisons](https://arxiv.org/abs/2512.15269)
*Daniel Sánchez Catalina,George T. Cantwell*

Main category: cs.SI

TL;DR: 提出一种贝叶斯算法，可从噪声成对比较数据中同时推断对象强度和强度到概率的映射函数，无需先验知识


<details>
  <summary>Details</summary>
Motivation: 解决从噪声成对比较（如网球比赛结果）中排名对象的问题，传统方法需要已知强度如何影响结果的先验知识，本文旨在消除这一限制

Method: 采用贝叶斯方法，设计高效算法同时推断未观测的对象强度和将强度映射到比较概率的函数，尽管问题欠定但能获得稳健结果

Result: 实验证据表明该贝叶斯方法对不同模型设定具有鲁棒性，多个真实数据集案例研究验证了方法的有效性

Conclusion: 提出的算法能够在无需先验知识的情况下，从噪声成对比较中可靠地推断对象排名和潜在的概率映射关系

Abstract: We consider the problem of ranking objects from noisy pairwise comparisons, for example, ranking tennis players from the outcomes of matches. We follow a standard approach to this problem and assume that each object has an unobserved strength and that the outcome of each comparison depends probabilistically on the strengths of the comparands. However, we do not assume to know a priori how skills affect outcomes. Instead, we present an efficient algorithm for simultaneously inferring both the unobserved strengths and the function that maps strengths to probabilities. Despite this problem being under-constrained, we present experimental evidence that the conclusions of our Bayesian approach are robust to different model specifications. We include several case studies to exemplify the method on real-world data sets.

</details>
