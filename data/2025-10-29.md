<div id=toc></div>

# Table of Contents

- [eess.SY](#eess.SY) [Total: 16]
- [econ.TH](#econ.TH) [Total: 3]
- [cs.RO](#cs.RO) [Total: 34]
- [econ.EM](#econ.EM) [Total: 3]
- [stat.AP](#stat.AP) [Total: 7]
- [cs.SI](#cs.SI) [Total: 9]
- [cs.AI](#cs.AI) [Total: 48]
- [econ.GN](#econ.GN) [Total: 6]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.CY](#cs.CY) [Total: 3]


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [1] [Maximal Load Shedding Verification for Neural Network Models of AC Line Switching](https://arxiv.org/abs/2510.23806)
*Samuel Chevalier,Duncan Starkenburg,Robert Parker,Noah Rhodes*

Main category: eess.SY

TL;DR: 该论文提出了一种双层攻击者-防御者验证方法，用于评估神经网络在电力系统线路切换决策中的最坏情况负载削减影响。


<details>
  <summary>Details</summary>
Motivation: 虽然机器学习模型可以快速预测接近最优的线路切换决策，但在实际部署前验证其性能和影响至关重要，特别是评估最坏情况下的负载削减。

Method: 采用双层攻击者-防御者验证框架，结合交流潮流凸松弛和局部神经网络搜索，通过MathOptAI.jl求解最坏情况负载削减的下界。

Result: 与随机采样方法相比，基于优化的方法总能找到更大的负载削减，在多个PGLib测试案例和包含超过1000万参数的神经网络模型上进行了验证。

Conclusion: 提出的优化方法能够有效评估神经网络线路切换决策的最坏情况性能，为实际部署前的安全验证提供了可靠工具。

Abstract: Solving for globally optimal line switching decisions in AC transmission
grids can be intractability slow. Machine learning (ML) models, meanwhile, can
be trained to predict near-optimal decisions at a fraction of the speed.
Verifying the performance and impact of these ML models on network operation,
however, is a critically important step prior to their actual deployment. In
this paper, we train a Neural Network (NN) to solve the optimal power shutoff
line switching problem. To assess the worst-case load shedding induced by this
model, we propose a bilevel attacker-defender verification approach that finds
the NN line switching decisions that cause the highest quantity of network load
shedding. Solving this problem to global optimality is challenging (due to AC
power flow and NN nonconvexities), so our approach exploits a convex relaxation
of the AC physics, combined with a local NN search, to find a guaranteed lower
bound on worst--case load shedding. These under-approximation bounds are solved
via MathOptAI.jl. We benchmark against a random sampling approach, and we find
that our optimization-based approach always finds larger load shedding. Test
results are collected on multiple PGLib test cases and on trained NN models
which contain more than 10 million model parameters.

</details>


### [2] [A Simultaneous ECG-PCG Acquisition System with Real-Time Burst-Adaptive Noise Cancellation](https://arxiv.org/abs/2510.23819)
*Avishka Herath,Malith Jayalath,Kumudu Kaushalya,Sanjana Kapukotuwa,Chathuni Wijegunawardena,Pahan Mendis,Kithmin Wickremasinghe,Duminda Samarasinghe,Wageesha N. Manamperi,Chamira U. S. Edussooriya*

Main category: eess.SY

TL;DR: 提出了一种集成实时自适应噪声消除的端到端系统，用于同时采集心电图和心音图信号，在嘈杂医院环境中显著改善信噪比。


<details>
  <summary>Details</summary>
Motivation: 心脏听诊是重要临床技能，但仅凭心音诊断困难，现有噪声消除方案要么非实时要么计算量大，不适合便携系统。

Method: 开发了集成实时自适应噪声消除管道的端到端系统，同时采集心电图和心音图信号。

Result: 在嘈杂医院环境中，心音图和心电图信号的信噪比分别提高了37.01 dB和30.32 dB。

Conclusion: 该系统能够在资源受限的嘈杂医院环境中实现可靠且可访问的心脏筛查。

Abstract: Cardiac auscultation is an essential clinical skill, requiring excellent
hearing to distinguish subtle differences in timing and pitch of heart sounds.
However, diagnosing solely from these sounds is often challenging due to
interference from surrounding noise, and the information may be limited.
Existing solutions that adaptively cancel external noise are either not
real-time or are computationally intensive, making them unsuitable for
implementation in a portable system. This work proposes an end-to-end system
with a real-time adaptive noise cancellation pipeline integrated into a device
that simultaneously acquires electrocardiogram (ECG) and phonocardiogram (PCG)
signals. The performance of the system is validated using real-world hospital
noise datasets and recordings captured with the dual-modality device. For PCG
and ECG signals recorded from the device in noisy hospital settings, the
proposed algorithms achieved signal-to-noise ratio improvements of 37.01 dB and
30.32 dB, respectively. These results demonstrate the systems effectiveness in
enabling reliable and accessible cardiac screening, including noisy hospital
environments typical of resource-constrained settings.

</details>


### [3] [MDP-based Energy-aware Task Scheduling for Battery-less IoT](https://arxiv.org/abs/2510.23820)
*Shahab Jahanbazi,Mateen Ashraf,Onel L. A. López*

Main category: eess.SY

TL;DR: 提出了一种基于马尔可夫决策过程的最优固定阈值调度策略，用于提升无电池物联网设备的长期任务完成率，相比ALAP策略显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 解决无电池物联网设备在环境能量收集条件下，由于能量随机性和时变性导致的长期任务完成率低的问题。

Method: 采用马尔可夫决策过程框架处理能量变化，定义两种奖励函数，推导出最优固定阈值调度策略。

Result: OSTB策略相比ALAP策略提高了8.6%的任务完成率，减少了65%的功率故障和86.29%的执行延迟。

Conclusion: OSTB调度策略能有效应对能量变化，显著提升无电池物联网设备的任务完成性能。

Abstract: Realizing high long-term task completion rates represents a fundamental
challenge in battery-less Internet of Things (IoT) devices powered by ambient
energy harvesting. This difficulty is primarily due to the stochastic and
time-varying characteristics of the available energy, which significantly
complicate the design of optimal task scheduling policies. In this paper, we
consider a battery-less IoT device that must periodically report sensing
measurements to a monitoring center. We adopt the Markov decision process (MDP)
framework to handle energy variability while aiming to maximize the long-term
task completion rate. For this, we first identify its components and then
define two appropriate reward functions. We demonstrate the inherent properties
associated with the MDP formulation and the related optimal policy.
Subsequently, we solve the resulting optimization problem, leading to the
optimal stationary threshold-based (OSTB) scheduling. Simulation results
demonstrate that OSTB outperforms the well-known ``as late as possible'' (ALAP)
scheduling strategy. For instance, an $8.6\%$ increase in the task completion
rate, along with a $65\%$ reduction in power failures and a $86.29\%$ decrease
in execution delays during task execution are registered assuming a $4.7$ mF
capacitor.

</details>


### [4] [Neural Two-Stage Stochastic Volt-VAR Optimization for Three-Phase Unbalanced Distribution Systems with Network Reconfiguration](https://arxiv.org/abs/2510.23867)
*Zhentong Shao,Jingtao Qin,Nanpeng Yu*

Main category: eess.SY

TL;DR: 提出一种用于三相不平衡配电网的神经两阶段随机电压-无功优化方法，通过神经网络近似第二级模型实现计算加速，相比传统方法提速50倍以上。


<details>
  <summary>Details</summary>
Motivation: 间歇性分布式能源资源接入导致配电网电压波动加剧，给电压调节和无功管理带来挑战，需要解决大规模随机优化问题的计算复杂性。

Method: 采用学习型加速策略，用神经网络近似第二级追索模型，并将其嵌入混合整数线性规划中，在考虑网络重构不确定性的情况下实现约束有效执行。

Result: 在123节点不平衡配电网上的数值仿真显示，相比传统求解器和分解方法，该方法实现50倍以上加速，最优性差距保持在0.30%以下。

Conclusion: 该方法在处理大规模随机电压-无功优化问题时具有高效性和可扩展性，适用于实际运行条件。

Abstract: The increasing integration of intermittent distributed energy resources
(DERs) has introduced significant variability in distribution networks, posing
challenges to voltage regulation and reactive power management. This paper
presents a novel neural two-stage stochastic Volt-VAR optimization (2S-VVO)
method for three-phase unbalanced distribution systems considering network
reconfiguration under uncertainty. To address the computational intractability
associated with solving large-scale scenario-based 2S-VVO problems, a
learning-based acceleration strategy is introduced, wherein the second-stage
recourse model is approximated by a neural network. This neural approximation
is embedded into the optimization model as a mixed-integer linear program
(MILP), enabling effective enforcement of operational constraints related to
the first-stage decisions. Numerical simulations on a 123-bus unbalanced
distribution system demonstrate that the proposed approach achieves over 50
times speedup compared to conventional solvers and decomposition methods, while
maintaining a typical optimality gap below 0.30%. These results underscore the
method's efficacy and scalability in addressing large-scale stochastic VVO
problems under practical operating conditions.

</details>


### [5] [A Spatio-Temporal Graph Learning Approach to Real-Time Economic Dispatch with Multi-Transmission-Node DER Aggregation](https://arxiv.org/abs/2510.23873)
*Zhentong Shao,Jingtao Qin,Xianbang Chen,Nanpeng Yu*

Main category: eess.SY

TL;DR: 本文提出了一种实时经济调度框架，通过时空图卷积网络预测分布因子，结合迭代约束识别策略，实现了多传输节点分布式能源资源的有效聚合，提高了市场清算效率。


<details>
  <summary>Details</summary>
Motivation: FERC Order 2222要求将分布式能源资源整合到批发电力市场中，这给系统运行带来了新的挑战。为了与现有市场结构保持一致，需要开发能够高效处理多传输节点DER聚合的实时经济调度方法。

Method: 开发了实时经济调度框架，采用时空图卷积网络自适应预测分布因子，捕捉单个传输节点DER在传输系统中的动态影响，并结合迭代约束识别策略来缓解传输安全约束。

Result: 在大型测试系统（包括修改的118、2383和3012总线网络）上进行验证，结果显示在降低运营成本和保持传输网络可行性方面有显著改进，证明了该框架的可扩展性和实用性。

Conclusion: 所提出的方法加速了市场清算过程，在当前市场范式下支持了传输节点DER聚合器的有效参与，为分布式能源资源整合提供了可行的技术解决方案。

Abstract: The integration of distributed energy resources (DERs) into wholesale
electricity markets, as mandated by FERC Order 2222, imposes new challenges on
system operations. To remain consistent with existing market structures,
regional transmission organizations (RTOs) have advanced the aggregation of
transmission-node-level DERs (T-DERs), where a nodal virtual power plant (VPP)
represents the mapping of all distribution-level DERs to their respective
transmission nodes. This paper develops a real-time economic dispatch (RTED)
framework that enables multi-transmission-node DER aggregation while addressing
computational efficiency. To this end, we introduce a spatio-temporal graph
convolutional network (ST-GCN) for adaptive prediction of distribution factors
(DFs), thereby capturing the dynamic influence of individual T-DERs across the
transmission system. Furthermore, an iterative constraint identification
strategy is incorporated to alleviate transmission security constraints without
compromising system reliability. Together, these innovations accelerate the
market clearing process and support the effective participation of T-DER
aggregators under current market paradigms. The proposed approach is validated
on large-scale test systems, including modified 118-, 2383-, and 3012-bus
networks under a rolling RTED setting with real demand data. Numerical results
demonstrate significant improvements in reducing operational costs and
maintaining transmission network feasibility, underscoring the scalability and
practicality of the proposed framework.

</details>


### [6] [Carbon-Aware Optimal Power Flow with Data-Driven Carbon Emission Tracing](https://arxiv.org/abs/2510.23877)
*Zhentong Shao,Nanpeng Yu*

Main category: eess.SY

TL;DR: 提出了一种结合数据驱动碳追踪的碳感知最优潮流框架，能够快速估算电力负荷的节点碳排放，并将其整合到DC最优潮流模型中作为线性约束。


<details>
  <summary>Details</summary>
Motivation: 量化电网中的位置碳排放对于依赖电力的客户实施有效的碳减排策略至关重要。

Method: 通过数据驱动技术开发发电机到负荷的碳排放分布因子，推导出平均和边际碳排放的解析公式，并将其作为线性约束无缝集成到DC最优潮流模型中。

Result: 在IEEE测试系统上的仿真验证了所提方法的准确性和计算效率，突显了其在实时碳感知系统运行中的适用性。

Conclusion: 所提出的碳感知最优潮流模型使市场运营商能够在优化能源调度的同时减少温室气体排放。

Abstract: Quantifying locational carbon emissions in power grids is crucial for
implementing effective carbon reduction strategies for customers relying on
electricity. This paper presents a carbon-aware optimal power flow (OPF)
framework that incorporates data-driven carbon tracing, enabling rapid
estimation of nodal carbon emissions from electric loads. By developing
generator-to-load carbon emission distribution factors through data-driven
technique, the analytical formulas for both average and marginal carbon
emissions can be derived and integrated seamlessly into DC OPF models as linear
constraints. The proposed carbon-aware OPF model enables market operators to
optimize energy dispatch while reducing greenhouse gas emissions. Simulations
on IEEE test systems confirm the accuracy and computational efficiency of the
proposed approach, highlighting its applicability for real-time carbon-aware
system operations.

</details>


### [7] [Modeling and Scheduling of Fusion Patterns in Autonomous Driving Systems (Extended Version)](https://arxiv.org/abs/2510.23895)
*Hoora Sobhani,Hyoseung Kim*

Main category: eess.SY

TL;DR: 提出了一个系统化框架来分析自动驾驶系统中各种数据融合模式及其性能影响，通过整数线性规划优化多个实时性能指标。


<details>
  <summary>Details</summary>
Motivation: 现有DAG调度方法过度简化数据融合任务，假设固定触发机制，无法捕捉真实自动驾驶软件栈中的多样化融合模式。

Method: 建模三种不同的融合任务类型：定时触发、等待全部和立即融合，采用基于整数线性规划的方法优化多个实时性能指标。

Result: 在真实自动驾驶案例研究、树莓派实现和随机生成DAG上的评估表明，该框架能处理超出现有工作范围的多样化融合模式，并在可比场景中实现显著性能提升。

Conclusion: 该框架为自动驾驶系统中的数据融合任务提供了更全面和优化的调度解决方案，显著提升了系统性能。

Abstract: In Autonomous Driving Systems (ADS), Directed Acyclic Graphs (DAGs) are
widely used to model complex data dependencies and inter-task communication.
However, existing DAG scheduling approaches oversimplify data fusion tasks by
assuming fixed triggering mechanisms, failing to capture the diverse fusion
patterns found in real-world ADS software stacks. In this paper, we propose a
systematic framework for analyzing various fusion patterns and their
performance implications in ADS. Our framework models three distinct fusion
task types: timer-triggered, wait-for-all, and immediate fusion, which
comprehensively represent real-world fusion behaviors. Our Integer Linear
Programming (ILP)-based approach enables an optimization of multiple real-time
performance metrics, including reaction time, time disparity, age of
information, and response time, while generating deterministic offline
schedules directly applicable to real platforms. Evaluation using real-world
ADS case studies, Raspberry Pi implementation, and randomly generated DAGs
demonstrates that our framework handles diverse fusion patterns beyond the
scope of existing work, and achieves substantial performance improvements in
comparable scenarios.

</details>


### [8] [Dynamical Modeling of Temperature and Smoke Evolution in a Thermal-Runaway Event of a Large-Format Lithium-ion Battery in a Mine Tunnel](https://arxiv.org/abs/2510.23910)
*Khadija Omar Said,Yukta Pareek,Satadru Dey,Ashish Ranjan Kumar*

Main category: eess.SY

TL;DR: 开发了降阶模型来模拟锂离子电池在地下矿井中的热失控传播，替代昂贵危险的高保真模型。


<details>
  <summary>Details</summary>
Motivation: 大型锂离子电池在矿井中使用时可能发生热失控，释放有毒易燃物质。高保真模型资源密集且不实用，需要更高效的模拟方法。

Method: 构建了降阶模型框架内的动态模型来表示瞬态燃烧事件。

Result: 降阶模型合理复现了温度和烟雾趋势，与真实数据集高度一致。

Conclusion: 降阶模型为矿井中锂离子电池热失控传播提供了一种实用且准确的模拟方法。

Abstract: Large-format lithium-ion batteries (LIBs) provide effective energy storage
solutions for high-power equipment used in underground mining operations. They
have high Columbic efficiency and minimal heat and emission footprints.
However, improper use of LIBs, accidents, or other factors may increase the
probability of thermal runaway (TR), a rapid combustion reaction that
discharges toxic and flammable substances. Several such incidents have been
documented in mines. Since repeatable TR experiments to uncover the
transient-state propagation of TR are expensive and hazardous, high-fidelity
models are usually developed to mimic the impact of these events. They are
resource-intensive and are impractical to develop for many scenarios that could
be observed in a mine. Therefore, dynamic models within a reduced-order
framework were constructed to represent the transient-state combustion event.
Reduced order models (ROMs) reasonably replicate trends in temperature and
smoke, showing strong alignment with the ground-truth dataset.

</details>


### [9] [Secure Control of Connected and Autonomous Electrified Vehicles Under Adversarial Cyber-Attacks](https://arxiv.org/abs/2510.23922)
*Shashank Dhananjay Vyas,Satadru Dey*

Main category: eess.SY

TL;DR: 提出了一种用于联网自动驾驶电动汽车(CAEV)的安全控制架构，通过强化学习设计额外的控制输入来缓解网络攻击的影响，确保车队安全运行


<details>
  <summary>Details</summary>
Motivation: 虽然CAEV具有高效交通流和清洁环境的优势，但由于其自主电动操作和连接性，仍然容易受到网络攻击

Method: 设计基于强化学习的额外控制输入，与电池指令输入一起应用于车辆动力系统

Result: 仿真案例研究表明，该方法能够有效抑制对抗性攻击的影响，保持CAEV车队安全运行且无碰撞

Conclusion: 提出的安全控制架构能够有效缓解CAEV面临的网络攻击威胁，确保智能交通系统的安全性

Abstract: Connected and Autonomous Electrified Vehicles (CAEV) is the solution to the
future smart mobility having benefits of efficient traffic flow and cleaner
environmental impact. Although CAEV has advantages they are still susceptible
to adversarial cyber attacks due to their autonomous electric operation and the
involved connectivity. To alleviate this issue, we propose a secure control
architecture of CAEV. Particularly, we design an additional control input using
Reinforcement Learning (RL) to be applied to the vehicle powertrain along with
the input commanded by the battery. We present simulation case studies to
demonstrate the potential of the proposed approach in keeping the CAEV platoon
operating safely without collisions by curbing the effect of adversarial
attacks.

</details>


### [10] [Sample-based Moving Horizon Estimation](https://arxiv.org/abs/2510.24191)
*Isabelle Krauss,Victor G. Lopez,Matthias A. Müller*

Main category: eess.SY

TL;DR: 提出了一种基于采样的移动水平估计算法，用于处理非线性系统中不规则和/或不频繁的测量数据，并在满足采样检测性条件下实现鲁棒全局指数稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统中由于测量数据不规则或不频繁导致的系统状态估计问题，传统方法难以处理此类非均匀采样场景。

Method: 设计了一种基于采样的移动水平估计方案，通过适当设计MHE优化问题的成本函数来适应不规则输出序列，并建立了采样检测性条件。

Result: 在满足采样增量输入/输出到状态稳定性条件下，所提出的基于采样的MHE实现了鲁棒全局指数稳定性，并在线性系统中建立了采样可观测性与采样i-IOSS之间的联系。

Conclusion: 该方法能够有效处理不规则测量数据，为非线性系统状态估计提供了新的解决方案，并通过仿真验证了其有效性。

Abstract: In this paper, we propose a sample-based moving horizon estimation (MHE)
scheme for general nonlinear systems to estimate the current system state using
irregularly and/or infrequently available measurements. The cost function of
the MHE optimization problem is suitably designed to accommodate these
irregular output sequences. We also establish that, under a suitable
sample-based detectability condition known as sample-based incremental
input/output-to-state stability (i-IOSS), the proposed sample-based MHE
achieves robust global exponential stability (RGES). Additionally, for the case
of linear systems, we draw connections between sample-based observability and
sample-based i-IOSS. This demonstrates that previously established conditions
for linear systems to be sample-based observable can be utilized to verify or
design sampling strategies that satisfy the conditions to guarantee RGES of the
sample-based MHE. Finally, the effectiveness of the proposed sample-based MHE
is illustrated through a simulation example.

</details>


### [11] [A comparison between joint and dual UKF implementations for state estimation and leak localization in water distribution networks](https://arxiv.org/abs/2510.24228)
*Luis Romero-Ben,Paul Irofti,Florin Stoican,Vicenç Puig*

Main category: eess.SY

TL;DR: 比较两种基于无迹卡尔曼滤波(UKF)的数据驱动状态估计方法，用于城市供水管网的水头和流量估计，分析单估计器和双估计器方案的特性差异。


<details>
  <summary>Details</summary>
Motivation: 现代城市的可持续性高度依赖于高效的水分配管理，包括有效的压力控制和泄漏检测定位，因此需要准确的管网水力状态信息。

Method: 使用两种基于UKF的数据驱动状态估计方法：一种采用联合状态向量的单估计器，另一种采用双估计器方案，融合压力、需求和流量数据进行水头和流量估计。

Result: 在L-TOWN基准测试中展示了多种估计结果，能够讨论这些方法在实际实施中的特性。

Conclusion: 通过理论分析和实际实现比较了两种UKF方法的准确性、复杂性、差异、优势和局限性。

Abstract: The sustainability of modern cities highly depends on efficient water
distribution management, including effective pressure control and leak
detection and localization. Accurate information about the network hydraulic
state is therefore essential. This article presents a comparison between two
data-driven state estimation methods based on the Unscented Kalman Filter
(UKF), fusing pressure, demand and flow data for head and flow estimation. One
approach uses a joint state vector with a single estimator, while the other
uses a dual-estimator scheme. We analyse their main characteristics, discussing
differences, advantages and limitations, and compare them theoretically in
terms of accuracy and complexity. Finally, we show several estimation results
for the L-TOWN benchmark, allowing to discuss their properties in a real
implementation.

</details>


### [12] [Survey and Tutorial of Reinforcement Learning Methods in Process Systems Engineering](https://arxiv.org/abs/2510.24272)
*Maximilian Bloor,Max Mowbray,Ehecatl Antonio Del Rio Chanona,Calvin Tsay*

Main category: eess.SY

TL;DR: 这篇论文是关于强化学习在过程系统工程中的综述与教程，介绍了RL的基本概念、算法家族及其在PSE领域的应用，并讨论了该领域的挑战与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理复杂随机系统的控制和优化时存在局限性，而强化学习提供了一种数据驱动的方法来应对这些过程系统工程挑战。

Method: 提供了强化学习的教程，涵盖基本概念和关键算法家族（基于价值、基于策略和演员-评论家方法），并综述了这些RL技术在PSE领域的现有应用。

Result: 系统总结了RL在PSE领域的应用情况，包括分批和连续过程控制、过程优化、供应链管理等不同领域。

Conclusion: 通过综合RL算法开发现状及其对PSE的影响，识别了成功案例、挑战、趋势，并规划了这两个领域交叉研究的未来方向。

Abstract: Sequential decision making under uncertainty is central to many Process
Systems Engineering (PSE) challenges, where traditional methods often face
limitations related to controlling and optimizing complex and stochastic
systems. Reinforcement Learning (RL) offers a data-driven approach to derive
control policies for such challenges. This paper presents a survey and tutorial
on RL methods, tailored for the PSE community. We deliver a tutorial on RL,
covering fundamental concepts and key algorithmic families including
value-based, policy-based and actor-critic methods. Subsequently, we survey
existing applications of these RL techniques across various PSE domains, such
as in fed-batch and continuous process control, process optimization, and
supply chains. We conclude with PSE focused discussion of specialized
techniques and emerging directions. By synthesizing the current state of RL
algorithm development and implications for PSE this work identifies successes,
challenges, trends, and outlines avenues for future research at the interface
of these fields.

</details>


### [13] [Mechanism-Guided Residual Lifting and Control Consistent Modeling for Pneumatic Drying Processes](https://arxiv.org/abs/2510.24370)
*Yue Wu*

Main category: eess.SY

TL;DR: 提出了一种物理引导的残差提升与控制一致校正的统一混合建模框架，用于解决气动干燥过程的建模和控制难题，在工业批次验证中取得了高精度预测性能。


<details>
  <summary>Details</summary>
Motivation: 工业气动干燥过程因多源干扰、耦合阶段动态和显著测量延迟而难以建模和控制，传统建模方法无法同时满足精度、可解释性和闭环适用性要求。

Method: 结合瞬态机理模型与稳定性约束的数据驱动组件，采用物理引导的残差学习方案，利用机理模型中间状态构建物理启发字典，并通过控制一致扩展动态模态分解学习残差动态。

Result: 在10个工业批次63000个样本上验证，对未见测试数据，出口水分和温度的均方绝对误差分别为0.016%和0.015°C，预测残差呈现白噪声特性，低频谱能量显著降低。

Conclusion: 该混合建模框架成功解决了气动干燥过程的建模挑战，提供了高精度预测和稳定性保证，适用于预测控制应用。

Abstract: Pneumatic drying processes in industries such as agriculture, chemicals,and
pharmaceuticals are notoriously difficult to model and control due to
multi-source disturbances,coupled stage dynamics, and significant measurement
delays. Traditional modeling paradigms often fail to simultaneously deliver
accuracy, interpretability, and closed-loop applicability. To address this
challenge, this paper introduces a unified hybrid modeling framework, termed
Physics-Guided Residual Lifting with Control-Consistent Correction,which
integrates a transient mechanistic model with a stability-constrained
data-driven component. The framework covers the complete process chain of
drying, transport, and winnowing. On the mechanistic level, the model unifies
mass transfer dynamics using the partial pressure difference of water vapor,
incorporates water activity clamping and latent heat corrections for bound
water, and ensures energy closure with moisture-dependent specific heat. On the
data-driven level,we propose an orthogonal residual learning scheme. It
leverages intermediate states from the mechanistic model as proxy variables to
construct a physics-inspired dictionary, preventing parameter compensation and
overfitting during ridge regression. Furthermore, to ensure suitability for
predictive control, a Control-Consistent Extended Dynamic Mode Decomposition
with stability constraints is employed to learn the residual dynamics, for
which we provide boundedness proofs and stability guarantees. The framework was
validated on 10 industrial batches, comprising 63,000 samples. On unseen test
data, the hybrid model achieved a Mean Absolute Error of 0.016% for outlet
moisture and 0.015 {\deg}C for outlet temperature, with values improving to
0.986 and 0.995, respectively. The resulting prediction residuals exhibit
white-noise characteristics, with significantly reduced spectral energy at low
frequencies.

</details>


### [14] [Development of a Digital Twin for an Electric Vehicle Emulator Modeling, Control, and Experimental Validation](https://arxiv.org/abs/2510.24389)
*Lamine Chalal,Ahmed Rachid*

Main category: eess.SY

TL;DR: 开发并验证了一个用于电动汽车模拟器的数字孪生系统，该系统采用Energetic Macroscopic Representation (EMR)框架，能够准确模拟车辆纵向动力学，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统图形化建模工具（如框图）在表示能量交互和推导控制结构方面存在局限性，需要一种更清晰的方法来模拟电动汽车在不同工况下的动力学特性。

Method: 使用EMR框架构建数字孪生系统，集成分离励磁直流电机、四象限DC-DC变换器、电池模拟器和机械负载模拟器，基于牛顿第二定律建模牵引力、空气阻力和坡度阻力。

Result: 实验测试显示模拟结果与实际测量高度一致，确定了180W电机在1900rpm下的最大允许车辆质量为13.5kg，并实现了可靠的四象限运行。

Conclusion: 所提出的框架为电动汽车仿真、控制设计和能量管理验证提供了一种可扩展且有效的方法。

Abstract: This paper presents the development and validation of a digital twin for a
scaled-down electric vehicle (EV) emulator, designed to replicate longitudinal
vehicle dynamics under diverse operating conditions. The emulator integrates a
separately excited DC motor (SEDCM), a four-quadrant DC-DC converter, a battery
emulator, and a mechanical load emulator. The system models tractive effort,
aerodynamic drag, and gradient resistance using Newton's second law. In
contrast to conventional graphical modeling tools (e.g., block diagrams and
bond graphs), the adopted Energetic Macroscopic Representation (EMR) framework
offers clear advantages by explicitly representing energy interactions and
facilitating the systematic derivation of control structures. A control
strategy developed within this framework governs energy flow across the
powertrain, enabling accurate speed control via armature voltage regulation.
Experimental tests conducted on a Lucas-Nulle test bench show strong
correlation with simulation results. The study also introduces a methodology to
compute the maximum admissible vehicle mass - determined to be 13.5 kg for a
180 W motor operating at 1900 rpm - based on acceleration and slope
constraints. Furthermore, a switching algorithm for the bidirectional converter
ensures reliable four quadrant operation. Overall, the proposed framework
provides a scalable and effective approach for EV emulation, control design,
and energy management validation.

</details>


### [15] [Contributions to Semialgebraic-Set-Based Stability Verification of Dynamical Systems with Neural-Network-Based Controllers](https://arxiv.org/abs/2510.24391)
*Alvaro Detailleur,Dalim Wahby,Guillaume Ducard,Christopher Onder*

Main category: eess.SY

TL;DR: 本文改进了基于神经网络的控制器(NNCs)的闭环稳定性验证方法，通过引入新的半代数激活函数、扩展支持递归平衡网络(RENs)、丰富Lyapunov函数参数化以及直接优化吸引域估计，降低了验证的保守性。


<details>
  <summary>Details</summary>
Motivation: 神经网络控制器能够表示复杂的非线性控制律，但验证其闭环稳定性仍然具有挑战性。现有基于半代数集输入输出建模的稳定性验证方法在处理超越激活函数时存在保守性，且仅限于前馈神经网络。

Method: 1) 引入新型半代数激活函数，保留常见超越激活函数的关键特性；2) 证明更广泛的递归平衡网络(RENs)与此验证程序的兼容性；3) 使用更丰富的Lyapunov函数参数化；4) 制定新的半定规划(SDPs)直接优化吸引域估计。

Result: 通过两个数值示例展示了这些贡献的价值，显著改进了局部吸引域估计的间接优化效果。

Conclusion: 提出的方法有效降低了神经网络控制器稳定性验证的保守性，扩展了可验证的网络类型，并提高了吸引域估计的准确性。

Abstract: Neural-network-based controllers (NNCs) can represent complex, highly
nonlinear control laws, but verifying the closed-loop stability of dynamical
systems using them remains challenging. This work presents contributions to a
state-of-the-art stability verification procedure for NNC-controlled systems
which relies on semialgebraic-set-based input-output modeling to pose the
search for a Lyapunov function as an optimization problem. Specifically, this
procedure's conservatism when analyzing NNCs using transcendental activation
functions and the restriction to feedforward NNCs are addressed by a)
introducing novel semialgebraic activation functions that preserve key
properties of common transcendental activations and b) proving compatibility of
NNCs from the broader class of recurrent equilibrium networks (RENs) with this
procedure. Furthermore, the indirect optimization of a local region of
attraction (RoA) estimate using a restricted set of candidate Lyapunov
functions is greatly improved via c) the introduction of a richer
parameterization of candidate Lyapunov functions than previously reported and
d) the formulation of novel semidefinite programs (SDPs) that directly optimize
the resulting RoA estimate. The value of these contributions is highlighted in
two numerical examples.

</details>


### [16] [Analyzing Parametric Oscillator Ising Machines through the Kuramoto Lens](https://arxiv.org/abs/2510.24416)
*Nikhat Khan,E. M. H. E. B. Ekanayake,Nicolas Casilli,Cristian Cassella,Luke Theogarajan,Nikhil Shukla*

Main category: eess.SY

TL;DR: 本文开发了参量振荡器伊辛机的Kuramoto式规范相位描述，揭示了相位动力学包含相位差耦合和相位和项，解释了为何不需要显式二次谐波驱动，并分析了振幅异质性对解质量的影响。


<details>
  <summary>Details</summary>
Motivation: 参量振荡器网络作为实现伊辛机器的物理平台日益重要，但其与传统振荡器伊辛机的关系尚未充分探索，需要建立统一的相位描述框架。

Method: 从Stuart-Landau振荡器模型出发，开发参量振荡器伊辛机的Kuramoto式规范相位描述，考虑共轭耦合产生的相位和项。

Result: 得到了结合标准Kuramoto模型相位差耦合和固有相位和项的相位动力学，解释了参量振荡器中无需显式二次谐波驱动的原因，揭示了振幅异质性对自旋相互作用强度的影响。

Conclusion: 这项工作为基于振荡器的伊辛机设计提供了统一视角，建立了参量振荡器实现与经典振荡器伊辛机之间的联系。

Abstract: Networks of coupled nonlinear oscillators are emerging as powerful physical
platforms for implementing Ising machines. Yet the relationship between
parametric-oscillator implementations and traditional oscillator-based Ising
machines remains underexplored. In this work, we develop a Kuramoto-style,
canonical phase description of parametric oscillator Ising machines by starting
from the Stuart-Landau oscillator model -- the canonical normal form near a
Hopf bifurcation, and a natural reduced description for many parametric
oscillator implementations such as the degenerate optical parametric oscillator
(DOPO) among others. The resulting phase dynamics combine the usual
phase-difference coupling observed in the standard Kuramoto model along with an
intrinsic phase sum term that is generated when conjugate coupling is
considered. Moreover, our formulation helps explain why explicit
second-harmonic driving is unnecessary in parametric oscillators and also
reveals how quasi-steady amplitude heterogeneity scales the original strength
of the spin interaction with potentially adverse impacts on the solution
quality. Our work helps develop a unifying view of the oscillator-based
approach to designing Ising machines.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [17] [Strategic Learning with Asymmetric Rationality](https://arxiv.org/abs/2510.23951)
*Qingmin Liu,Yuyang Miao*

Main category: econ.TH

TL;DR: 分析完全理性的私有信息发送者与有限理性、有记忆约束的无信息接收者之间的动态互动，研究信息回避、观点极化等行为模式如何作为非对称理性的均衡响应出现。


<details>
  <summary>Details</summary>
Motivation: 研究在认知和信息不对称环境中，发送者控制信息流而接收者设计决策协议时，有限理性如何影响战略学习和决策制定。

Method: 建立发送者与接收者的博弈模型，接收者使用有限状态机作为决策协议，控制信息解释、内存状态演变和决策时机。

Result: 发现信息回避、观点极化和犹豫不决等行为模式是非对称理性的均衡响应，接收者需要最优利用有限状态来学习和激励发送者提供信息。

Conclusion: 该模型为认知和信息不对称环境中的战略学习和决策制定提供了表达性框架，可应用于监管审查和媒体不信任等场景。

Abstract: This paper analyzes the dynamic interaction between a fully rational,
privately informed sender and a boundedly rational, uninformed receiver with
memory constraints. The sender controls the flow of information, while the
receiver designs a decision-making protocol, modeled as a finite-state machine,
that governs how information is interpreted, how internal memory states evolve,
and when and what decisions are made. The receiver must use the limited set of
states optimally, both to learn and to create incentives for the sender to
provide information. We show that behavior patterns such as information
avoidance, opinion polarization, and indecision arise as equilibrium responses
to asymmetric rationality. The model offers an expressive framework for
strategic learning and decision-making in environments with cognitive and
informational asymmetries, with applications to regulatory review and media
distrust.

</details>


### [18] [The Role of Mathematical Folk Puzzles in Developing mathematical Thinking and Problem-Solving Skills](https://arxiv.org/abs/2510.24266)
*Duaa Abdullah,Jasem Hamoud*

Main category: econ.TH

TL;DR: 本文探讨了各种数学民间谜题，包括几何、逻辑、代数、概率和组合挑战，并介绍了现代数字化改进。提出了"多联骨牌最小分割路径问题"的新概念，证明N个方格的多联骨牌需要N-1次直线切割才能分解为单个单元。


<details>
  <summary>Details</summary>
Motivation: 通过有趣的数学谜题提高学生的参与度和理解力，将数学概念与游戏化方法相结合，使学习更加愉快有效。

Method: 分析各类传统数学谜题，探索现代数字化改进，并引入新的多联骨牌最小分割路径问题进行数学证明。

Result: 证明了多联骨牌最小分割路径问题的结论：N个方格的多联骨牌需要恰好N-1次直线切割才能分解为单个单元。

Conclusion: 数学谜题作为教学工具能有效加强核心数学概念的理解，如面积、空间推理和优化，使学习过程既有趣又高效。

Abstract: This paper covers a variety of mathematical folk puzzles, including geometric
(Tangrams, dissection puzzles), logic, algebraic, probability (Monty Hall
Problem, Birthday Paradox), and combinatorial challenges (Eight Queens Puzzle,
Tower of Hanoi). It also explores modern modifications, such as digital and
gamified approaches, to improve student involvement and comprehension.
Furthermore, a novel concept, the "Minimal Dissection Path Problem for
Polyominoes," is introduced and proven, demonstrating that the minimum number
of straight-line cuts required to dissect a polyomino of N squares into its
constituent units is $\mathrm{N}-1$. This problem, along with other puzzles,
offers practical classroom applications that reinforce core mathematical
concepts like area, spatial reasoning, and optimization, making learning both
enjoyable and effective.

</details>


### [19] [A Characterization of Egalitarian and Proportional Sharing Principles: An Efficient Extension Operator Approach](https://arxiv.org/abs/2510.24388)
*Yukihiko Funaki,Yukio Koriyama,Satoshi Nakada*

Main category: econ.TH

TL;DR: 本文提出了一种通过高效扩展算子恢复合作博弈解效率的新方法，统一描述了平等剩余分享和比例分享方法，为f-ESS和f-PS值提供了新理论依据。


<details>
  <summary>Details</summary>
Motivation: 许多著名的合作博弈解（如Banzhaf值、Myerson值等）缺乏效率性，虽然具有其他优良特性。本文旨在通过高效扩展算子来恢复这些解的效率性。

Method: 提出高效扩展算子概念，考虑新的公理体系，统一刻画平等剩余分享和比例分享方法。

Result: 为Funaki和Koriyama（2025）提出的f-ESS值和f-PS值提供了新的理论依据，这些值是平等剩余分享值和比例分享值的推广。

Conclusion: 该方法为任意基础解提供了额外理论依据，并应用于带通信网络的TU博弈和带联盟结构的TU博弈的高效公平扩展。

Abstract: Some well-known solutions for cooperative games with transferable utility
(TU-games), such as the Banzhaf value, the Myerson value, and the Aumann-Dreze
value, fail to satisfy efficiency, although they possess other desirable
properties. This paper proposes a new approach to restore efficiency by
extending any underlying solution to an efficient one, through what we call an
efficient extension operator. We consider novel axioms for an efficient
extension operator and characterize the egalitarian surplus sharing method and
the proportional sharing method in a unified manner. These results can be
considered as new justifications for the f-ESS values and the f-PS values
introduced by Funaki and Koriyama (2025), which are generalizations of the
equal surplus sharing value and the proportional sharing value. Our results
offer an additional rationale for the values with an arbitrary underlying
solution. As applications, we develop an efficient-fair extension of the
solutions for the TU-games with communication networks and its variant for
TU-games with coalition structures.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [20] [RoboOmni: Proactive Robot Manipulation in Omni-modal Context](https://arxiv.org/abs/2510.23763)
*Siyin Wang,Jinlan Fu,Feihong Liu,Xinzhe He,Huangxuan Wu,Junhao Shi,Kexin Huang,Zhaoye Fei,Jingjing Gong,Zuxuan Wu,Yugang Jiang,See-Kiong Ng,Tat-Seng Chua,Xipeng Qiu*

Main category: cs.RO

TL;DR: 提出了RoboOmni框架，基于全模态LLMs，通过融合听觉和视觉信号进行意图识别，支持直接语音交互，在机器人操作中实现主动意图推断。


<details>
  <summary>Details</summary>
Motivation: 现实世界中人类很少直接发出指令，有效协作需要机器人主动推断用户意图，而现有方法主要依赖显式指令。

Method: 提出RoboOmni框架，采用Perceiver-Thinker-Talker-Executor架构，基于端到端全模态LLMs，时空融合听觉和视觉信号进行意图识别。

Result: 在仿真和真实环境实验中，RoboOmni在成功率、推理速度、意图识别和主动协助方面优于基于文本和ASR的基线方法。

Conclusion: RoboOmni框架通过跨模态上下文指令实现了更自然的人机交互，为主动意图识别的机器人操作提供了有效解决方案。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid
progress in Vision-Language-Action (VLA) models for robotic manipulation.
Although effective in many scenarios, current approaches largely rely on
explicit instructions, whereas in real-world interactions, humans rarely issue
instructions directly. Effective collaboration requires robots to infer user
intentions proactively. In this work, we introduce cross-modal contextual
instructions, a new setting where intent is derived from spoken dialogue,
environmental sounds, and visual cues rather than explicit commands. To address
this new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor
framework based on end-to-end omni-modal LLMs that unifies intention
recognition, interaction confirmation, and action execution. RoboOmni fuses
auditory and visual signals spatiotemporally for robust intention recognition,
while supporting direct speech interaction. To address the absence of training
data for proactive intention recognition in robotic manipulation, we build
OmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640
backgrounds, and six contextual instruction types. Experiments in simulation
and real-world settings show that RoboOmni surpasses text- and ASR-based
baselines in success rate, inference speed, intention recognition, and
proactive assistance.

</details>


### [21] [Motivating Students' Self-study with Goal Reminder and Emotional Support](https://arxiv.org/abs/2510.23860)
*Hyung Chan Cho,Go-Eum Cha,Yanfu Liu,Sooyeon Jeong*

Main category: cs.RO

TL;DR: 社交机器人作为同伴学习伴侣，通过目标提醒和情感支持提升大学生自主学习效果


<details>
  <summary>Details</summary>
Motivation: 虽然社交机器人在学习任务支持方面已有广泛研究，但在自主学习情境中的潜力尚未充分探索

Method: 采用Wizard-of-Oz探索性研究，比较目标提醒、情感支持和仅物理存在（对照组）三种条件对学生学习的影响

Result: 目标提醒和情感支持条件下的参与者报告了更好的易用性，目标提醒组更愿意在未来学习中使用机器人；参与者对机器人的满意度与其将机器人视为社交实体的感知相关，这种感知能预测学习目标达成程度

Conclusion: 社交辅助机器人通过功能性和情感性参与，在自主学习支持方面具有重要潜力

Abstract: While the efficacy of social robots in supporting people in learning tasks
has been extensively investigated, their potential impact in assisting students
in self-studying contexts has not been investigated much. This study explores
how a social robot can act as a peer study companion for college students
during self-study tasks by delivering task-oriented goal reminder and positive
emotional support. We conducted an exploratory Wizard-of-Oz study to explore
how these robotic support behaviors impacted students' perceived focus,
productivity, and engagement in comparison to a robot that only provided
physical presence (control). Our study results suggest that participants in the
goal reminder and the emotional support conditions reported greater ease of
use, with the goal reminder condition additionally showing a higher willingness
to use the robot in future study sessions. Participants' satisfaction with the
robot was correlated with their perception of the robot as a social other, and
this perception was found to be a predictor for their level of goal achievement
in the self-study task. These findings highlight the potential of socially
assistive robots to support self-study through both functional and emotional
engagement.

</details>


### [22] [Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped](https://arxiv.org/abs/2510.23902)
*Jans Solano,Diego Quiroz*

Main category: cs.RO

TL;DR: 提出了一种面向低成本轮腿式四足机器人的恢复感知视觉惯性导航系统，利用深度相机视觉感知和深度强化学习策略实现鲁棒运动控制和自主跌倒恢复。


<details>
  <summary>Details</summary>
Motivation: 现有轮腿式机器人依赖昂贵执行器和传感器，且很少集成跌倒恢复功能，特别是针对轮腿式形态。本工作旨在降低自主导航和鲁棒运动策略在预算受限机器人平台上的部署门槛。

Method: 结合深度相机视觉感知和深度强化学习策略，开发了视觉惯性导航系统，用于鲁棒运动控制和自主跌倒恢复。

Result: 仿真实验显示在非规则地形上使用低扭矩执行器实现敏捷移动，并能可靠地从外部扰动和自诱导故障中恢复。在结构化室内环境中展示了低成本感知的目标导向导航。

Conclusion: 该方法显著降低了在预算受限机器人平台上部署自主导航和鲁棒运动策略的技术门槛。

Abstract: Wheeled-legged robots combine the efficiency of wheels with the obstacle
negotiation of legs, yet many state-of-the-art systems rely on costly actuators
and sensors, and fall-recovery is seldom integrated, especially for
wheeled-legged morphologies. This work presents a recovery-aware
visual-inertial navigation system on a low-cost wheeled quadruped. The proposed
system leverages vision-based perception from a depth camera and deep
reinforcement learning policies for robust locomotion and autonomous recovery
from falls across diverse terrains. Simulation experiments show agile mobility
with low-torque actuators over irregular terrain and reliably recover from
external perturbations and self-induced failures. We further show goal directed
navigation in structured indoor spaces with low-cost perception. Overall, this
approach lowers the barrier to deploying autonomous navigation and robust
locomotion policies in budget-constrained robotic platforms.

</details>


### [23] [Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments](https://arxiv.org/abs/2510.23928)
*Raman Jha,Yang Zhou,Giuseppe Loianno*

Main category: cs.RO

TL;DR: 提出了一种自适应关键帧选择方法，通过结合基于误差的选择模块和基于动量的更新模块，动态调整关键帧选择阈值，在动态环境中实现更好的3D场景重建。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中实时感知的数据瓶颈问题，通过动态选择最具信息量的帧来创建高质量的3D世界表示，这对于复杂动态环境中的可扩展机器人学习和部署至关重要。

Method: 集成两个互补模块：基于光度误差和结构相似性(SSIM)误差的选择模块，以及基于动量的更新模块，该模块根据场景运动动态动态调整关键帧选择阈值。

Result: 在Spann3r和CUT3R两个最先进的3D重建网络上评估，观察到重建质量的一致改进，相比传统的静态关键帧选择策略有显著提升。

Conclusion: 该方法代表了自适应感知系统的有意义的进展，能够动态响应复杂和演变的视觉场景，消融研究证实了各个组件的有效性。

Abstract: In this paper, we propose an adaptive keyframe selection method for improved
3D scene reconstruction in dynamic environments. The proposed method integrates
two complementary modules: an error-based selection module utilizing
photometric and structural similarity (SSIM) errors, and a momentum-based
update module that dynamically adjusts keyframe selection thresholds according
to scene motion dynamics. By dynamically curating the most informative frames,
our approach addresses a key data bottleneck in real-time perception. This
allows for the creation of high-quality 3D world representations from a
compressed data stream, a critical step towards scalable robot learning and
deployment in complex, dynamic environments. Experimental results demonstrate
significant improvements over traditional static keyframe selection strategies,
such as fixed temporal intervals or uniform frame skipping. These findings
highlight a meaningful advancement toward adaptive perception systems that can
dynamically respond to complex and evolving visual scenes. We evaluate our
proposed adaptive keyframe selection module on two recent state-of-the-art 3D
reconstruction networks, Spann3r and CUT3R, and observe consistent improvements
in reconstruction quality across both frameworks. Furthermore, an extensive
ablation study confirms the effectiveness of each individual component in our
method, underlining their contribution to the overall performance gains.

</details>


### [24] [A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots with Multiple Tubes and Tendons](https://arxiv.org/abs/2510.23954)
*Pejman Kheradmand,Behnam Moradkhani,Raghavasimhan Sankaranarayanan,Kent K. Yamamoto,Tanner J. Zachem,Patrick J. Codd,Yash Chitalia,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 提出了基于Cosserat杆的建模框架，用于模拟由n个同心管组成的肌腱驱动同心管机构，每个管由m_i个肌腱驱动，实现了尖端预测误差小于总长度4%的精确形状估计。


<details>
  <summary>Details</summary>
Motivation: 肌腱驱动同心管机构结合了肌腱驱动连续体机器人和同心管机器人的优点，但缺乏完整通用的力学模型。现有模型无法充分描述这种复杂系统的行为。

Method: 使用Cosserat杆理论框架建模n个同心管，每个管由m_i个肌腱驱动。模型允许每个管扭转和伸长，同时强制弯曲时共享中心线。

Result: 通过两管和三管组件的实验验证，在各种肌腱布线配置下实现尖端预测误差小于机器人总长度的4%。应用于现有机器人时，最大尖端偏差保持在总长度约5%左右。

Conclusion: 该模型为先进肌腱驱动同心管机器人的精确形状估计和控制提供了基础，解决了该领域长期存在的通用建模问题。

Abstract: Tendon-actuated concentric tube mechanisms combine the advantages of
tendon-driven continuum robots and concentric tube robots while addressing
their respective limitations. They overcome the restricted degrees of freedom
often seen in tendon-driven designs, and mitigate issues such as snapping
instability associated with concentric tube robots. However, a complete and
general mechanical model for these systems remains an open problem. In this
work, we propose a Cosserat rod-based framework for modeling the general case
of $n$ concentric tubes, each actuated by $m_i$ tendons, where $i = \{1,
\ldots, n\}$. The model allows each tube to twist and elongate while enforcing
a shared centerline for bending. We validate the proposed framework through
experiments with two-tube and three tube assemblies under various tendon
routing configurations, achieving tip prediction errors $<4\%$ of the robot's
total length. We further demonstrate the model's generality by applying it to
existing robots in the field, where maximum tip deviations remain around $5\%$
of the total length. This model provides a foundation for accurate shape
estimation and control of advanced tendon-actuated concentric tube robots.

</details>


### [25] [Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping](https://arxiv.org/abs/2510.23963)
*Hiroki Ishikawa,Kyosuke Ishibashi,Ko Yamamoto*

Main category: cs.RO

TL;DR: 提出了一种具有自适应扭转变形能力的软体机器人手指，能够通过包裹方式抓取物体，特别适用于从密集堆叠的物体中抓取单个物体。


<details>
  <summary>Details</summary>
Motivation: 软体手需要从密集堆叠的多个物体中抓取单个物体，这要求软体手指具备在平面内和平面外方向的自适应扭转变形功能，以便深入物体间的狭窄间隙进行抓取。

Method: 设计了一种可变刚度机制，通过单一驱动源实现自适应扭转变形和抓取力控制，利用有限元分析确定设计参数，并开发了软体手指进行实验验证。

Result: 通过开发的软体手指进行了基础实验和多种物体的抓取演示，验证了其自适应扭转变形和包裹抓取能力。

Conclusion: 提出的可变刚度软体手指成功实现了自适应扭转变形功能，能够有效深入狭窄间隙并通过包裹方式抓取物体，为密集环境下的物体抓取提供了有效解决方案。

Abstract: This paper presents a soft robot finger capable of adaptive-twist deformation
to grasp objects by wrapping them. For a soft hand to grasp and pick-up one
object from densely contained multiple objects, a soft finger requires the
adaptive-twist deformation function in both in-plane and out-of-plane
directions. The function allows the finger to be inserted deeply into a limited
gap among objects. Once inserted, the soft finger requires appropriate control
of grasping force normal to contact surface, thereby maintaining the twisted
deformation. In this paper, we refer to this type of grasping as grasping by
wrapping. To achieve these two functions by a single actuation source, we
propose a variable stiffness mechanism that can adaptively change the stiffness
as the pressure is higher. We conduct a finite element analysis (FEA) on the
proposed mechanism and determine its design parameter based on the FEA result.
Using the developed soft finger, we report basic experimental results and
demonstrations on grasping various objects.

</details>


### [26] [A Survey on Collaborative SLAM with 3D Gaussian Splatting](https://arxiv.org/abs/2510.23988)
*Phuc Nguyen Xuan,Thanh Nguyen Canh,Huu-Hung Nguyen,Nak Young Chong,Xiem HoangVan*

Main category: cs.RO

TL;DR: 本文综述了基于3D高斯泼溅的多机器人协同SLAM技术，分析了集中式和分布式架构，探讨了全局一致性、通信效率等核心挑战，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅作为显式场景表示方法，能够实现实时高保真渲染，非常适合机器人应用。但在多机器人系统中，如何保持全局一致性、管理通信和融合异构数据源面临重大挑战。

Method: 系统性地按架构（集中式、分布式）分类方法，分析多智能体一致性对齐、通信效率、高斯表示、语义蒸馏、融合与位姿优化、实时可扩展性等核心组件。

Result: 提供了关键数据集和评估指标的总结，为性能评估提供背景。识别了当前方法在全局一致性维护和异构数据融合方面的挑战。

Conclusion: 指出了未来关键研究方向：终身建图、语义关联与建图、多模型鲁棒性以及Sim2Real差距的弥合。

Abstract: This survey comprehensively reviews the evolving field of multi-robot
collaborative Simultaneous Localization and Mapping (SLAM) using 3D Gaussian
Splatting (3DGS). As an explicit scene representation, 3DGS has enabled
unprecedented real-time, high-fidelity rendering, ideal for robotics. However,
its use in multi-robot systems introduces significant challenges in maintaining
global consistency, managing communication, and fusing data from heterogeneous
sources. We systematically categorize approaches by their architecture --
centralized, distributed -- and analyze core components like multi-agent
consistency and alignment, communication-efficient, Gaussian representation,
semantic distillation, fusion and pose optimization, and real-time scalability.
In addition, a summary of critical datasets and evaluation metrics is provided
to contextualize performance. Finally, we identify key open challenges and
chart future research directions, including lifelong mapping, semantic
association and mapping, multi-model for robustness, and bridging the Sim2Real
gap.

</details>


### [27] [VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion](https://arxiv.org/abs/2510.23997)
*Stanley Wu,Mohamad H. Danesh,Simon Li,Hanna Yurchyk,Amin Abyaneh,Anas El Houssaini,David Meger,Hsiu-Chin Lin*

Main category: cs.RO

TL;DR: VOCALoco是一个模块化技能选择框架，通过动态评估预训练策略的安全性和能耗来选择最佳运动策略，在楼梯任务中比端到端DRL方法更安全高效。


<details>
  <summary>Details</summary>
Motivation: 现有端到端深度强化学习方法在复杂地形导航中存在安全性和可解释性不足的问题，特别是在面对新地形时。

Method: 使用预训练运动策略，通过预测执行安全性和运输成本来评估策略可行性，选择既安全又节能的策略。

Result: 在楼梯上下任务中，VOCALoco在仿真和真实四足机器人上都表现出比传统端到端DRL方法更好的鲁棒性和安全性。

Conclusion: 模块化技能选择框架VOCALoco能够有效提升腿式机器人在复杂地形上的运动安全性和效率。

Abstract: Recent advancements in legged robot locomotion have facilitated traversal
over increasingly complex terrains. Despite this progress, many existing
approaches rely on end-to-end deep reinforcement learning (DRL), which poses
limitations in terms of safety and interpretability, especially when
generalizing to novel terrains. To overcome these challenges, we introduce
VOCALoco, a modular skill-selection framework that dynamically adapts
locomotion strategies based on perceptual input. Given a set of pre-trained
locomotion policies, VOCALoco evaluates their viability and energy-consumption
by predicting both the safety of execution and the anticipated cost of
transport over a fixed planning horizon. This joint assessment enables the
selection of policies that are both safe and energy-efficient, given the
observed local terrain. We evaluate our approach on staircase locomotion tasks,
demonstrating its performance in both simulated and real-world scenarios using
a quadrupedal robot. Empirical results show that VOCALoco achieves improved
robustness and safety during stair ascent and descent compared to a
conventional end-to-end DRL policy

</details>


### [28] [Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model](https://arxiv.org/abs/2510.24029)
*Andrew Gerstenslager,Bekarys Dukenbaev,Ali A. Minai*

Main category: cs.RO

TL;DR: 该论文提出了一种包含垂直角度敏感性的3D边界向量细胞模型，解决了传统2D模型在水平对称环境中容易产生空间模糊的问题，显著提高了生物启发机器人模型中的空间定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统边界向量细胞模型局限于二维环境，在存在水平对称性的环境中容易产生空间模糊，无法有效处理真实世界的三维空间导航问题。

Method: 在BVC框架中引入垂直角度敏感性，处理LiDAR数据以捕捉垂直轮廓，从而区分在纯2D表示中无法区分的位点。

Result: 在垂直变化最小的环境中，3D模型与2D基线性能相当；但随着3D复杂度增加，3D模型产生更显著不同的位置场，并显著减少空间混叠。

Conclusion: 在BVC定位中加入垂直维度可以显著增强真实世界3D空间中的导航和映射能力，同时在简单的近平面场景中保持性能相当。

Abstract: Boundary Vector Cells (BVCs) are a class of neurons in the brains of
vertebrates that encode environmental boundaries at specific distances and
allocentric directions, playing a central role in forming place fields in the
hippocampus. Most computational BVC models are restricted to two-dimensional
(2D) environments, making them prone to spatial ambiguities in the presence of
horizontal symmetries in the environment. To address this limitation, we
incorporate vertical angular sensitivity into the BVC framework, thereby
enabling robust boundary detection in three dimensions, and leading to
significantly more accurate spatial localization in a biologically-inspired
robot model.
  The proposed model processes LiDAR data to capture vertical contours, thereby
disambiguating locations that would be indistinguishable under a purely 2D
representation. Experimental results show that in environments with minimal
vertical variation, the proposed 3D model matches the performance of a 2D
baseline; yet, as 3D complexity increases, it yields substantially more
distinct place fields and markedly reduces spatial aliasing. These findings
show that adding a vertical dimension to BVC-based localization can
significantly enhance navigation and mapping in real-world 3D spaces while
retaining performance parity in simpler, near-planar scenarios.

</details>


### [29] [SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration](https://arxiv.org/abs/2510.24052)
*Jongsuk Kim,Jaeyoung Lee,Gyojin Han,Dongjae Lee,Minki Jeong,Junmo Kim*

Main category: cs.RO

TL;DR: SynAD是首个利用合成数据增强端到端自动驾驶模型的框架，通过在多智能体合成场景中指定具有最全面驾驶信息的智能体作为自车，将路径级场景投影到地图上，并使用Map-to-BEV网络生成鸟瞰图特征，有效提升安全性能。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习和高质量真实驾驶数据集推动了端到端自动驾驶的发展，但仅依赖真实数据限制了训练场景的多样性。合成场景生成虽能丰富训练数据，但在端到端自动驾驶模型中的应用仍未被充分探索，主要因为缺乏指定的自车和相关传感器输入。

Method: 在多智能体合成场景中指定具有最全面驾驶信息的智能体作为自车；将路径级场景投影到地图上；开发Map-to-BEV网络在不依赖传感器输入的情况下生成鸟瞰图特征；设计训练策略有效整合地图基合成数据与真实驾驶数据。

Result: 实验结果表明SynAD有效整合了所有组件，显著提升了安全性能。

Conclusion: 通过桥接合成场景生成和端到端自动驾驶，SynAD为更全面和鲁棒的自动驾驶模型铺平了道路。

Abstract: Recent advancements in deep learning and the availability of high-quality
real-world driving datasets have propelled end-to-end autonomous driving.
Despite this progress, relying solely on real-world data limits the variety of
driving scenarios for training. Synthetic scenario generation has emerged as a
promising solution to enrich the diversity of training data; however, its
application within E2E AD models remains largely unexplored. This is primarily
due to the absence of a designated ego vehicle and the associated sensor
inputs, such as camera or LiDAR, typically provided in real-world scenarios. To
address this gap, we introduce SynAD, the first framework designed to enhance
real-world E2E AD models using synthetic data. Our method designates the agent
with the most comprehensive driving information as the ego vehicle in a
multi-agent synthetic scenario. We further project path-level scenarios onto
maps and employ a newly developed Map-to-BEV Network to derive bird's-eye-view
features without relying on sensor inputs. Finally, we devise a training
strategy that effectively integrates these map-based synthetic data with real
driving data. Experimental results demonstrate that SynAD effectively
integrates all components and notably enhances safety performance. By bridging
synthetic scenario generation and E2E AD, SynAD paves the way for more
comprehensive and robust autonomous driving models.

</details>


### [30] [Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation](https://arxiv.org/abs/2510.24055)
*Xiucheng Zhang,Yang Jiang,Hongwei Qing,Jiashuo Bai*

Main category: cs.RO

TL;DR: 提出LCVR和LMoE-DP框架，通过语义基础和专家专业化解决模仿学习中感知模糊和任务冲突问题，在真实机器人基准测试中显著提升多任务操作性能


<details>
  <summary>Details</summary>
Motivation: 感知模糊和任务冲突限制了通过模仿学习实现多任务机器人操作的效果，需要解决视觉相似任务的区分和多任务间的冲突问题

Method: 结合语言条件视觉表示(LCVR)模块和语言条件混合专家密度策略(LMoE-DP)。LCVR通过语言指令基础视觉特征解决感知模糊，LMoE-DP使用稀疏专家架构专门处理不同的多模态动作分布，并通过梯度调制稳定训练

Result: 在真实机器人基准测试中，LCVR将Action Chunking with Transformers (ACT)和Diffusion Policy (DP)的成功率分别提升33.75%和25%。完整框架达到79%的平均成功率，比先进基线高21%

Conclusion: 结合语义基础和专家专业化能够实现鲁棒、高效的多任务操作，为解决模仿学习中的感知模糊和任务冲突提供了有效方案

Abstract: Perceptual ambiguity and task conflict limit multitask robotic manipulation
via imitation learning. We propose a framework combining a Language-Conditioned
Visual Representation (LCVR) module and a Language-conditioned
Mixture-ofExperts Density Policy (LMoE-DP). LCVR resolves perceptual
ambiguities by grounding visual features with language instructions, enabling
differentiation between visually similar tasks. To mitigate task conflict,
LMoE-DP uses a sparse expert architecture to specialize in distinct, multimodal
action distributions, stabilized by gradient modulation. On real-robot
benchmarks, LCVR boosts Action Chunking with Transformers (ACT) and Diffusion
Policy (DP) success rates by 33.75% and 25%, respectively. The full framework
achieves a 79% average success, outperforming the advanced baseline by 21%. Our
work shows that combining semantic grounding and expert specialization enables
robust, efficient multi-task manipulation

</details>


### [31] [Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition](https://arxiv.org/abs/2510.24067)
*Tianyi Ding,Ronghao Zheng,Senlin Zhang,Meiqin Liu*

Main category: cs.RO

TL;DR: 提出了一种分布式多机器人自主在线探索方法，通过拓扑图Voronoi算法实现平衡的区域划分和任务分配，在障碍密集的非凸环境中提高探索效率和负载均衡。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在障碍密集非凸环境中的协作探索问题，特别关注分布式探索规划以实现动态平衡的区域划分和任务分配。

Method: 使用新颖的拓扑地图结构表征空间连通性和全局探索完整性，提出分布式加权拓扑图Voronoi算法进行平衡图空间划分，并结合局部规划器优化探索目标访问序列。

Result: 与现有最先进方法相比，在探索效率、完整性和机器人团队工作负载平衡方面表现出显著改进。

Conclusion: 该方法为多机器人协作探索提供了理论保证的分布式共识收敛和恒定边界的公平图空间划分，能够生成安全、平滑且动态可行的运动轨迹。

Abstract: This work addresses the collaborative multi-robot autonomous online
exploration problem, particularly focusing on distributed exploration planning
for dynamically balanced exploration area partition and task allocation among a
team of mobile robots operating in obstacle-dense non-convex environments.
  We present a novel topological map structure that simultaneously
characterizes both spatial connectivity and global exploration completeness of
the environment. The topological map is updated incrementally to utilize known
spatial information for updating reachable spaces, while exploration targets
are planned in a receding horizon fashion under global coverage guidance.
  A distributed weighted topological graph Voronoi algorithm is introduced
implementing balanced graph space partitions of the fused topological maps.
Theoretical guarantees are provided for distributed consensus convergence and
equitable graph space partitions with constant bounds.
  A local planner optimizes the visitation sequence of exploration targets
within the balanced partitioned graph space to minimize travel distance, while
generating safe, smooth, and dynamically feasible motion trajectories.
  Comprehensive benchmarking against state-of-the-art methods demonstrates
significant improvements in exploration efficiency, completeness, and workload
balance across the robot team.

</details>


### [32] [Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition](https://arxiv.org/abs/2510.24069)
*Sangmin Kim,Hajun Kim,Gijeong Kim,Min-Gyu Kim,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出基于相位的轨迹优化方法，确保足式机器人在整个轨迹中满足平移动力学和摩擦锥约束，通过贝塞尔多项式的性质实现动态可靠的运动生成。


<details>
  <summary>Details</summary>
Motivation: 为了通过轨迹优化为足式机器人生成可靠运动，需要同时计算机器人路径和接触序列，并在问题表述中准确考虑动力学约束。

Method: 利用线性微分方程的叠加特性解耦各接触点的平移动力学，使用贝塞尔多项式的微分矩阵推导位置与力的解析关系，并利用贝塞尔多项式的凸包性质确保摩擦锥约束。

Result: 该轨迹优化框架能够为足式机器人生成具有各种步态序列的动态可靠运动，在四足机器人模型上验证了动力学和运动生成的可行性。

Conclusion: 提出的基于相位的轨迹优化方法能够有效确保足式机器人运动轨迹的动力学可行性和摩擦锥约束满足，为可靠运动生成提供了有效解决方案。

Abstract: To generate reliable motion for legged robots through trajectory
optimization, it is crucial to simultaneously compute the robot's path and
contact sequence, as well as accurately consider the dynamics in the problem
formulation. In this paper, we present a phase-based trajectory optimization
that ensures the feasibility of translational dynamics and friction cone
constraints throughout the entire trajectory. Specifically, our approach
leverages the superposition properties of linear differential equations to
decouple the translational dynamics for each contact point, which operates
under different phase sequences. Furthermore, we utilize the differentiation
matrix of B{\'e}zier polynomials to derive an analytical relationship between
the robot's position and force, thereby ensuring the consistent satisfaction of
translational dynamics. Additionally, by exploiting the convex closure property
of B{\'e}zier polynomials, our method ensures compliance with friction cone
constraints. Using the aforementioned approach, the proposed trajectory
optimization framework can generate dynamically reliable motions with various
gait sequences for legged robots. We validate our framework using a quadruped
robot model, focusing on the feasibility of dynamics and motion generation.

</details>


### [33] [ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring](https://arxiv.org/abs/2510.24108)
*Zhenxin Li,Wenhao Yao,Zi Wang,Xinglong Sun,Jingde Chen,Nadine Chang,Maying Shen,Jingyu Song,Zuxuan Wu,Shiyi Lan,Jose M. Alvarez*

Main category: cs.RO

TL;DR: ZTRS是首个完全消除模仿学习、仅从奖励中学习并直接处理高维传感器数据的端到端自动驾驶框架，结合了离线强化学习和轨迹评分，在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶框架主要依赖模仿学习，但受到次优专家演示和部署时协变量偏移的限制；而强化学习通常局限于低维符号输入，无法实现从原始传感器数据的完整端到端学习。

Method: 提出ZTRS框架，结合传感器输入和强化学习训练，使用离线强化学习和提出的详尽策略优化(EPO)方法，这是一种针对可枚举动作和奖励的策略梯度变体。

Result: ZTRS在三个基准测试中表现强劲：Navtest(通用现实世界开环规划)、Navhard(挑战性现实世界和合成场景中的开环规划)和HUGSIM(模拟闭环驾驶)，在Navhard上达到最先进结果，在HUGSIM上优于基于模仿学习的基线方法。

Conclusion: ZTRS成功展示了无需模仿学习、仅从奖励中学习并直接处理高维传感器数据的端到端自动驾驶的可行性，为更鲁棒的自动驾驶规划提供了新途径。

Abstract: End-to-end autonomous driving maps raw sensor inputs directly into
ego-vehicle trajectories to avoid cascading errors from perception modules and
to leverage rich semantic cues. Existing frameworks largely rely on Imitation
Learning (IL), which can be limited by sub-optimal expert demonstrations and
covariate shift during deployment. On the other hand, Reinforcement Learning
(RL) has recently shown potential in scaling up with simulations, but is
typically confined to low-dimensional symbolic inputs (e.g. 3D objects and
maps), falling short of full end-to-end learning from raw sensor data. We
introduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory
Scoring), a framework that combines the strengths of both worlds: sensor inputs
without losing information and RL training for robust planning. To the best of
our knowledge, ZTRS is the first framework that eliminates IL entirely by only
learning from rewards while operating directly on high-dimensional sensor data.
ZTRS utilizes offline reinforcement learning with our proposed Exhaustive
Policy Optimization (EPO), a variant of policy gradient tailored for enumerable
actions and rewards. ZTRS demonstrates strong performance across three
benchmarks: Navtest (generic real-world open-loop planning), Navhard (open-loop
planning in challenging real-world and synthetic scenarios), and HUGSIM
(simulated closed-loop driving). Specifically, ZTRS achieves the
state-of-the-art result on Navhard and outperforms IL-based baselines on
HUGSIM. Code will be available at https://github.com/woxihuanjiangguo/ZTRS.

</details>


### [34] [PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI](https://arxiv.org/abs/2510.24109)
*Wenbin Ding,Jun Chen,Mingjia Chen,Fei Xie,Qi Mao,Philip Dames*

Main category: cs.RO

TL;DR: 本文提出了一种基于视觉语言模型(VLM)的智能机器人代理框架，通过人机语音交互、视觉语言代理和动作执行模块，显著提高了复杂自然语言控制任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLM)的发展，人本人工智能(HAI)对机器人的智能水平提出了更高要求，特别是在自然语言交互、复杂任务规划和执行方面。现有基于LLM的具身代理缺乏在线规划和执行复杂自然语言控制任务的能力。

Method: 提出了一个包含人机语音交互模块、视觉语言代理模块和动作执行模块的机器人具身代理框架。视觉语言代理模块包括基于视觉的任务规划器、自然语言指令转换器和任务性能反馈评估器。

Result: 实验结果显示，该代理在模拟和真实环境中相比仅使用LLM+CLIP的方法，平均任务成功率提高了28%，显著提升了高级自然语言指令任务的执行成功率。

Conclusion: 基于视觉语言模型的智能机器人代理框架能够有效提高复杂自然语言控制任务的执行性能，为实现人本人工智能提供了新的技术路径。

Abstract: The rapid advancement of Large Language Models (LLMs) has marked a
significant breakthrough in Artificial Intelligence (AI), ushering in a new era
of Human-centered Artificial Intelligence (HAI). HAI aims to better serve human
welfare and needs, thereby placing higher demands on the intelligence level of
robots, particularly in aspects such as natural language interaction, complex
task planning, and execution. Intelligent agents powered by LLMs have opened up
new pathways for realizing HAI. However, existing LLM-based embodied agents
often lack the ability to plan and execute complex natural language control
tasks online. This paper explores the implementation of intelligent robotic
manipulating agents based on Vision-Language Models (VLMs) in the physical
world. We propose a novel embodied agent framework for robots, which comprises
a human-robot voice interaction module, a vision-language agent module and an
action execution module. The vision-language agent itself includes a
vision-based task planner, a natural language instruction converter, and a task
performance feedback evaluator. Experimental results demonstrate that our agent
achieves a 28\% higher average task success rate in both simulated and real
environments compared to approaches relying solely on LLM+CLIP, significantly
improving the execution success rate of high-level natural language instruction
tasks.

</details>


### [35] [LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation](https://arxiv.org/abs/2510.24118)
*Haotian Zhou,Xiaole Wang,He Li,Fusheng Sun,Shengyu Guo,Guolei Qi,Jianghuan Xu,Huijing Zhao*

Main category: cs.RO

TL;DR: LagMemo是一个基于语言3D高斯泼溅记忆的视觉导航系统，支持多模态、开放词汇表和多目标导航，通过构建统一的3D语言记忆并集成局部感知验证机制来实现目标定位和导航。


<details>
  <summary>Details</summary>
Motivation: 传统视觉导航方法局限于单目标、单模态和封闭集目标设置，无法满足实际应用中多模态、开放词汇表查询和多目标导航的需求。

Method: 系统在探索阶段构建统一的3D语言记忆，根据任务目标查询记忆预测候选目标位置，并集成局部感知验证机制在导航过程中动态匹配和验证目标。

Result: 实验结果表明LagMemo的记忆模块能够有效实现多模态开放词汇表目标定位，在多目标视觉导航任务中优于现有最先进方法。

Conclusion: LagMemo通过语言3D高斯泼溅记忆和局部验证机制，成功解决了多模态开放词汇表多目标视觉导航的挑战，在GOAT-Core基准测试中表现优异。

Abstract: Navigating to a designated goal using visual information is a fundamental
capability for intelligent robots. Most classical visual navigation methods are
restricted to single-goal, single-modality, and closed set goal settings. To
address the practical demands of multi-modal, open-vocabulary goal queries and
multi-goal visual navigation, we propose LagMemo, a navigation system that
leverages a language 3D Gaussian Splatting memory. During exploration, LagMemo
constructs a unified 3D language memory. With incoming task goals, the system
queries the memory, predicts candidate goal locations, and integrates a local
perception-based verification mechanism to dynamically match and validate goals
during navigation. For fair and rigorous evaluation, we curate GOAT-Core, a
high-quality core split distilled from GOAT-Bench tailored to multi-modal
open-vocabulary multi-goal visual navigation. Experimental results show that
LagMemo's memory module enables effective multi-modal open-vocabulary goal
localization, and that LagMemo outperforms state-of-the-art methods in
multi-goal visual navigation. Project page:
https://weekgoodday.github.io/lagmemo

</details>


### [36] [Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames](https://arxiv.org/abs/2510.24194)
*Ev Zisselman,Mirco Mutti,Shelly Francis-Meretzki,Elisei Shafer,Aviv Tamar*

Main category: cs.RO

TL;DR: 提出"蒙眼专家"方法，在行为克隆中向演示者隐藏部分任务信息，迫使进行非平凡探索，从而在未见任务上获得更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统行为克隆需要人类专家提供完整任务信息的(近乎)最优演示，但这种方法在需要泛化到众多任务时需大量演示。本文探索通过限制演示者信息来提升泛化能力。

Method: 向演示者隐藏部分任务信息，创建"蒙眼专家"，迫使其进行探索性行为。克隆这种探索性演示而非完全信息下的最优演示。

Result: 在真实机器人插孔任务和Procgen基准视频游戏中，克隆蒙眼专家比克隆完全信息专家在未见任务上泛化更好。理论分析表明泛化误差与√(I/m)成正比，其中I是演示者可获得的任务信息量，m是演示任务数。

Conclusion: 克隆蒙眼专家在较少演示任务下能获得更好的泛化性能，理论和实验均支持这一结论。

Abstract: Behavioral cloning is a simple yet effective technique for learning
sequential decision-making from demonstrations. Recently, it has gained
prominence as the core of foundation models for the physical world, where
achieving generalization requires countless demonstrations of a multitude of
tasks. Typically, a human expert with full information on the task demonstrates
a (nearly) optimal behavior. In this paper, we propose to hide some of the
task's information from the demonstrator. This ``blindfolded'' expert is
compelled to employ non-trivial exploration to solve the task. We show that
cloning the blindfolded expert generalizes better to unseen tasks than its
fully-informed counterpart. We conduct experiments of real-world robot peg
insertion tasks with (limited) human demonstrations, alongside videogames from
the Procgen benchmark. Additionally, we support our findings with theoretical
analysis, which confirms that the generalization error scales with
$\sqrt{I/m}$, where $I$ measures the amount of task information available to
the demonstrator, and $m$ is the number of demonstrated tasks. Both theory and
practice indicate that cloning blindfolded experts generalizes better with
fewer demonstrated tasks. Project page with videos and code:
https://sites.google.com/view/blindfoldedexperts/home

</details>


### [37] [Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors](https://arxiv.org/abs/2510.24257)
*Ziqi Ma,Changda Tian,Yue Gao*

Main category: cs.RO

TL;DR: 提出HMAMP方法，通过对抗运动先验学习人类风格的操纵技能，在锤击任务中表现优于基线方法，并展示了在真实机器人上的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 开发能够以更自然直观方式与人类互动的机器人和自主系统，关键挑战是让这些系统能够以类似人类的方式操纵物体和工具。

Method: 使用对抗网络建模工具和物体操纵的复杂动态以及操纵任务的目标，判别器结合真实世界数据和智能体执行的仿真数据进行训练，训练生成符合人类运动统计特性的真实运动轨迹的策略。

Result: 在锤击任务中，HMAMP能够学习人类风格的操纵技能，表现优于当前基线方法，并在真实机器人臂锤击任务中展示了实际应用潜力。

Conclusion: HMAMP代表了开发能够以更自然直观方式与人类互动的机器人和自主系统的重要进展，通过学习以类似人类的方式操纵工具和物体。

Abstract: In recent years, there has been growing interest in developing robots and
autonomous systems that can interact with human in a more natural and intuitive
way. One of the key challenges in achieving this goal is to enable these
systems to manipulate objects and tools in a manner that is similar to that of
humans. In this paper, we propose a novel approach for learning human-style
manipulation skills by using adversarial motion priors, which we name HMAMP.
The approach leverages adversarial networks to model the complex dynamics of
tool and object manipulation, as well as the aim of the manipulation task. The
discriminator is trained using a combination of real-world data and simulation
data executed by the agent, which is designed to train a policy that generates
realistic motion trajectories that match the statistical properties of human
motion. We evaluated HMAMP on one challenging manipulation task: hammering, and
the results indicate that HMAMP is capable of learning human-style manipulation
skills that outperform current baseline methods. Additionally, we demonstrate
that HMAMP has potential for real-world applications by performing real robot
arm hammering tasks. In general, HMAMP represents a significant step towards
developing robots and autonomous systems that can interact with humans in a
more natural and intuitive way, by learning to manipulate tools and objects in
a manner similar to how humans do.

</details>


### [38] [Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance](https://arxiv.org/abs/2510.24457)
*Jorge Vicente-Martinez,Edgar Ramirez-Laboreo*

Main category: cs.RO

TL;DR: 提出基于微分平坦性的3D桥式起重机最优轨迹生成方法，能够直接处理非线性摩擦和碰撞避免等复杂约束，实现快速安全的起重机运动。


<details>
  <summary>Details</summary>
Motivation: 传统起重机轨迹规划方法难以处理复杂的物理和动态约束，如非线性摩擦和碰撞避免，这限制了起重机的运动速度和安全性。

Method: 利用微分平坦性框架，直接包含非线性摩擦和碰撞避免约束，仅在终点约束载荷摆动，实现激进运动。

Result: 对比仿真验证了方法的有效性，忽略干摩擦会导致执行器饱和和碰撞，摩擦建模是实现快速安全轨迹的基本要求。

Conclusion: 所提出的基于微分平坦性的方法能够有效处理复杂约束，生成快速安全的3D起重机轨迹，摩擦建模对轨迹性能至关重要。

Abstract: This paper presents an optimal trajectory generation method for 3D overhead
cranes by leveraging differential flatness. This framework enables the direct
inclusion of complex physical and dynamic constraints, such as nonlinear
friction and collision avoidance for both payload and rope. Our approach allows
for aggressive movements by constraining payload swing only at the final point.
A comparative simulation study validates our approach, demonstrating that
neglecting dry friction leads to actuator saturation and collisions. The
results show that friction modeling is a fundamental requirement for fast and
safe crane trajectories.

</details>


### [39] [DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation](https://arxiv.org/abs/2510.24261)
*Jingyi Tian,Le Wang,Sanping Zhou,Sen Wang,Jiayi Li,Gang Hua*

Main category: cs.RO

TL;DR: DynaRend是一个通过可微分体积渲染学习3D感知和动态感知的三平面特征的表示学习框架，用于改进机器人操作任务


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作策略泛化性差的问题，现有方法要么依赖2D视觉预训练只关注静态语义或场景几何，要么使用大规模视频预测模型只关注2D动态，无法联合学习操作所需的几何、语义和动态信息

Method: 使用可微分体积渲染通过掩码重建和未来预测学习3D感知和动态感知的三平面特征，在多视角RGB-D视频数据上进行预训练

Result: 在两个挑战性基准测试RLBench和Colosseum以及真实机器人实验中，在策略成功率、对环境扰动的泛化性和真实世界适用性方面都显示出显著改进

Conclusion: DynaRend能够有效联合学习空间几何、未来动态和任务语义的统一三平面表示，这些表示可以通过动作价值图预测有效转移到下游机器人操作任务

Abstract: Learning generalizable robotic manipulation policies remains a key challenge
due to the scarcity of diverse real-world training data. While recent
approaches have attempted to mitigate this through self-supervised
representation learning, most either rely on 2D vision pretraining paradigms
such as masked image modeling, which primarily focus on static semantics or
scene geometry, or utilize large-scale video prediction models that emphasize
2D dynamics, thus failing to jointly learn the geometry, semantics, and
dynamics required for effective manipulation. In this paper, we present
DynaRend, a representation learning framework that learns 3D-aware and
dynamics-informed triplane features via masked reconstruction and future
prediction using differentiable volumetric rendering. By pretraining on
multi-view RGB-D video data, DynaRend jointly captures spatial geometry, future
dynamics, and task semantics in a unified triplane representation. The learned
representations can be effectively transferred to downstream robotic
manipulation tasks via action value map prediction. We evaluate DynaRend on two
challenging benchmarks, RLBench and Colosseum, as well as in real-world robotic
experiments, demonstrating substantial improvements in policy success rate,
generalization to environmental perturbations, and real-world applicability
across diverse manipulation tasks.

</details>


### [40] [Feature Matching-Based Gait Phase Prediction for Obstacle Crossing Control of Powered Transfemoral Prosthesis](https://arxiv.org/abs/2510.24676)
*Jiaxuan Zhang,Yuquan Leng,Yixuan Guo,Chenglong Fu*

Main category: cs.RO

TL;DR: 使用健康脚踝的惯性传感器指导截肢者动力大腿假肢的越障运动，通过遗传算法优化神经网络结构预测关节角度，实现高精度的步态相位估计和关节角度预测。


<details>
  <summary>Details</summary>
Motivation: 解决截肢者使用动力大腿假肢时在复杂地形和障碍物导航方面的挑战，提高假肢的越障能力。

Method: 在健康脚踝放置惯性传感器，使用遗传算法计算最优神经网络结构来预测大腿和膝关节所需角度，结合步态进展预测算法确定假肢膝关节电机的驱动角度。

Result: 当大腿角度数据的噪声标准差小于1时，能有效消除噪声干扰，在150Hz下实现100%的步态相位估计准确率，大腿角度预测误差8.71%，膝关节角度预测误差6.78%。

Conclusion: 该方法能准确预测步态进展和关节角度，对动力大腿假肢的越障应用具有重要实用价值。

Abstract: For amputees with powered transfemoral prosthetics, navigating obstacles or
complex terrain remains challenging. This study addresses this issue by using
an inertial sensor on the sound ankle to guide obstacle-crossing movements. A
genetic algorithm computes the optimal neural network structure to predict the
required angles of the thigh and knee joints. A gait progression prediction
algorithm determines the actuation angle index for the prosthetic knee motor,
ultimately defining the necessary thigh and knee angles and gait progression.
Results show that when the standard deviation of Gaussian noise added to the
thigh angle data is less than 1, the method can effectively eliminate noise
interference, achieving 100\% accuracy in gait phase estimation under 150 Hz,
with thigh angle prediction error being 8.71\% and knee angle prediction error
being 6.78\%. These findings demonstrate the method's ability to accurately
predict gait progression and joint angles, offering significant practical value
for obstacle negotiation in powered transfemoral prosthetics.

</details>


### [41] [Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground Cooperation](https://arxiv.org/abs/2510.24315)
*Baozhe Zhang,Xinwei Chen,Qingcheng Chen,Chao Xu,Fei Gao,Yanjun Cao*

Main category: cs.RO

TL;DR: 提出CoNi-OA算法，专门用于无人机-无人车协同场景中的障碍物避让，无需全局状态估计或障碍物预测，仅使用单帧LiDAR数据实时生成避障轨迹。


<details>
  <summary>Details</summary>
Motivation: CoNi-MPC框架虽然为无人机控制提供了高效方案，但缺乏环境信息导致障碍物避让面临挑战。

Method: 利用无人机单帧原始LiDAR数据生成调制矩阵，直接调整四旋翼速度实现障碍物避让，在无人车非惯性坐标系中实时生成无碰撞轨迹。

Result: 算法计算需求低（每次迭代小于5毫秒），在动态不可预测环境中保持安全性，适用于静态和动态环境。

Conclusion: CoNi-OA为无人机-无人车协同系统提供了一种高效、实时的障碍物避让解决方案，无需全局状态估计或障碍物预测。

Abstract: CoNi-MPC provides an efficient framework for UAV control in air-ground
cooperative tasks by relying exclusively on relative states, eliminating the
need for global state estimation. However, its lack of environmental
information poses significant challenges for obstacle avoidance. To address
this issue, we propose a novel obstacle avoidance algorithm, Cooperative
Non-inertial frame-based Obstacle Avoidance (CoNi-OA), designed explicitly for
UAV-UGV cooperative scenarios without reliance on global state estimation or
obstacle prediction. CoNi-OA uniquely utilizes a single frame of raw LiDAR data
from the UAV to generate a modulation matrix, which directly adjusts the
quadrotor's velocity to achieve obstacle avoidance. This modulation-based
method enables real-time generation of collision-free trajectories within the
UGV's non-inertial frame, significantly reducing computational demands (less
than 5 ms per iteration) while maintaining safety in dynamic and unpredictable
environments. The key contributions of this work include: (1) a
modulation-based obstacle avoidance algorithm specifically tailored for UAV-UGV
cooperation in non-inertial frames without global states; (2) rapid, real-time
trajectory generation based solely on single-frame LiDAR data, removing the
need for obstacle modeling or prediction; and (3) adaptability to both static
and dynamic environments, thus extending applicability to featureless or
unknown scenarios.

</details>


### [42] [NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation](https://arxiv.org/abs/2510.24335)
*Mingyu Jeong,Eunsung Kim,Sehun Park,Andrew Jaeyong Choi*

Main category: cs.RO

TL;DR: NVSim是一个从普通图像序列自动构建大规模可导航室内模拟器的框架，解决了传统3D扫描的成本和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统3D扫描方法在构建大规模室内环境时面临成本高和可扩展性差的问题，需要一种仅从常见图像序列就能自动构建可导航模拟器的解决方案。

Method: 采用3D高斯溅射技术，引入地板感知高斯溅射来确保清洁可导航的地面平面，并提出基于渲染视图直接分析的网格无关可穿越性检查算法来构建拓扑图。

Result: 系统能够从真实世界数据生成有效的大规模导航图，解决了稀疏观测地板上的视觉伪影问题。

Conclusion: NVSim框架成功实现了仅从图像序列自动构建大规模可导航室内模拟器，为机器人导航提供了成本效益高的解决方案。

Abstract: We present NVSim, a framework that automatically constructs large-scale,
navigable indoor simulators from only common image sequences, overcoming the
cost and scalability limitations of traditional 3D scanning. Our approach
adapts 3D Gaussian Splatting to address visual artifacts on sparsely observed
floors a common issue in robotic traversal data. We introduce Floor-Aware
Gaussian Splatting to ensure a clean, navigable ground plane, and a novel
mesh-free traversability checking algorithm that constructs a topological graph
by directly analyzing rendered views. We demonstrate our system's ability to
generate valid, large-scale navigation graphs from real-world data. A video
demonstration is avilable at https://youtu.be/tTiIQt6nXC8

</details>


### [43] [Supervisory Measurement-Guided Noise Covariance Estimation](https://arxiv.org/abs/2510.24508)
*Haoying Li,Yifan Peng,Junfeng Wu*

Main category: cs.RO

TL;DR: 提出了一种双层优化方法，将噪声协方差估计表述为贝叶斯问题，通过因子分解实现高效并行计算，在合成和真实数据集上显示出比现有基线更高的效率。


<details>
  <summary>Details</summary>
Motivation: 传感器噪声协方差在实际中难以准确指定，因为受到环境变化、前端预处理等因素影响，而可靠的状态估计依赖于准确的噪声协方差规范。

Method: 将噪声协方差估计构建为双层优化问题，通过贝叶斯视角因子化解里程计和监控测量的联合似然。下层使用带状态增强的不变扩展卡尔曼滤波器估计轨迹，同时导数滤波器并行计算分析梯度；上层通过梯度更新优化协方差。

Result: 在合成和真实数据集上的实验表明，该方法比现有基线方法具有更高的效率。

Conclusion: 提出的双层优化框架能够有效估计噪声协方差，在平衡信息利用和计算效率方面表现优异。

Abstract: Reliable state estimation hinges on accurate specification of sensor noise
covariances, which weigh heterogeneous measurements. In practice, these
covariances are difficult to identify due to environmental variability,
front-end preprocessing, and other reasons. We address this by formulating
noise covariance estimation as a bilevel optimization that, from a Bayesian
perspective, factorizes the joint likelihood of so-called odometry and
supervisory measurements, thereby balancing information utilization with
computational efficiency. The factorization converts the nested Bayesian
dependency into a chain structure, enabling efficient parallel computation: at
the lower level, an invariant extended Kalman filter with state augmentation
estimates trajectories, while a derivative filter computes analytical gradients
in parallel for upper-level gradient updates. The upper level refines the
covariance to guide the lower-level estimation. Experiments on synthetic and
real-world datasets show that our method achieves higher efficiency over
existing baselines.

</details>


### [44] [Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems](https://arxiv.org/abs/2510.24515)
*Malintha Fernando,Petter Ögren,Silun Zhang*

Main category: cs.RO

TL;DR: 该论文提出了随机奖品收集游戏(SPCG)作为团队定向问题(TOP)的扩展，用于在自利机器人、能量约束和随机转移条件下进行规划。通过理论分析和算法设计，证明了在特定条件下存在纯纳什均衡，并提出两种算法来学习最优策略。


<details>
  <summary>Details</summary>
Motivation: 现有的团队定向问题(TOP)假设所有机器人合作追求单一目标，无法扩展到奖励稀缺环境中机器人竞争的场景。需要一种能够处理自利机器人竞争的新模型。

Method: 提出了随机奖品收集游戏(SPCG)框架，设计了两种算法：序数排名搜索(ORS)用于确定局部邻域中的有效排名，以及虚构序数响应学习(FORL)用于学习针对高排名对手的最佳响应策略。

Result: 在道路网络和合成图上的实证评估显示：1) ORS的条件状态混叠使策略学习在大型团队中更高效；2) FORL训练的策略在非均衡奖品分布下泛化能力更强；3) 学习策略达到了87%-95%的最优性。

Conclusion: SPCG框架成功扩展了TOP以处理机器人竞争场景，提出的算法能够有效学习接近最优的策略，在复杂多机器人系统中具有实际应用价值。

Abstract: The Team Orienteering Problem (TOP) generalizes many real-world multi-robot
scheduling and routing tasks that occur in autonomous mobility, aerial
logistics, and surveillance applications. While many flavors of the TOP exist
for planning in multi-robot systems, they assume that all the robots cooperate
toward a single objective; thus, they do not extend to settings where the
robots compete in reward-scarce environments. We propose Stochastic
Prize-Collecting Games (SPCG) as an extension of the TOP to plan in the
presence of self-interested robots operating on a graph, under energy
constraints and stochastic transitions. A theoretical study on complete and
star graphs establishes that there is a unique pure Nash equilibrium in SPCGs
that coincides with the optimal routing solution of an equivalent TOP given a
rank-based conflict resolution rule. This work proposes two algorithms: Ordinal
Rank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in
temporarily-formed local neighborhoods during the games' stages, and Fictitious
Ordinal Response Learning (FORL) to obtain best-response policies against one's
senior-rank opponents. Empirical evaluations conducted on road networks and
synthetic graphs under both dynamic and stationary prize distributions show
that 1) the state-aliasing induced by OR-conditioning enables learning policies
that scale more efficiently to large team sizes than those trained with the
global index, and 2) Policies trained with FORL generalize better to imbalanced
prize distributions than those with other multi-agent training methods.
Finally, the learned policies in the SPCG achieved between 87% and 95%
optimality compared to an equivalent TOP solution obtained by mixed-integer
linear programming.

</details>


### [45] [GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater Robots](https://arxiv.org/abs/2510.24533)
*Yuan Shen,Yuze Hong,Guangyang Zeng,Tengfei Zhang,Pui Yi Chui,Ziyang Hong,Junfeng Wu*

Main category: cs.RO

TL;DR: GeVI-SLAM是一个重力增强的立体视觉惯性SLAM系统，通过利用立体相机直接深度估计和重力初始化，解决了水下机器人SLAM中视觉退化和IMU运动激励不足的问题。


<details>
  <summary>Details</summary>
Motivation: 水下机器人VI SLAM面临视觉频繁退化和IMU运动激励不足的挑战，导致定位和建图精度下降。

Method: 利用立体相机直接深度估计消除IMU初始化中的尺度估计需求；通过精确重力初始化解耦俯仰和滚转，使用4自由度PnP进行位姿跟踪；提出偏差消除的4-DOF PnP估计器；动态运动时联合估计IMU协方差并优化6-DOF位姿。

Result: 在模拟和真实世界数据上的大量实验表明，GeVI-SLAM相比最先进方法具有更高的精度和更好的稳定性。

Conclusion: GeVI-SLAM系统通过重力增强和4-DOF PnP方法，有效解决了水下VI SLAM的挑战，实现了更准确和稳定的性能。

Abstract: Accurate visual inertial simultaneous localization and mapping (VI SLAM) for
underwater robots remains a significant challenge due to frequent visual
degeneracy and insufficient inertial measurement unit (IMU) motion excitation.
In this paper, we present GeVI-SLAM, a gravity-enhanced stereo VI SLAM system
designed to address these issues. By leveraging the stereo camera's direct
depth estimation ability, we eliminate the need to estimate scale during IMU
initialization, enabling stable operation even under low acceleration dynamics.
With precise gravity initialization, we decouple the pitch and roll from the
pose estimation and solve a 4 degrees of freedom (DOF) Perspective-n-Point
(PnP) problem for pose tracking. This allows the use of a minimal 3-point
solver, which significantly reduces computational time to reject outliers
within a Random Sample Consensus framework. We further propose a
bias-eliminated 4-DOF PnP estimator with provable consistency, ensuring the
relative pose converges to the true value as the feature number increases. To
handle dynamic motion, we refine the full 6-DOF pose while jointly estimating
the IMU covariance, enabling adaptive weighting of the gravity prior. Extensive
experiments on simulated and real-world data demonstrate that GeVI-SLAM
achieves higher accuracy and greater stability compared to state-of-the-art
methods.

</details>


### [46] [An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments](https://arxiv.org/abs/2510.24554)
*Vignesh Kottayam Viswanathan,Yifan Bai,Scott Fredriksson,Sumeet Satpute,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出分层框架用于机器人巡检，通过全局规划与局部重规划相结合，应对环境不确定性，在真实矿井中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖已知环境模型规划巡检路径，但实际环境与模型存在差异（如地形变化、路径阻塞），需要适应环境不确定性的解决方案。

Method: 分层框架：1）基于历史地图生成全局视图规划；2）局部视图重规划以适应当前地形形态，保持全局覆盖目标的同时实现局部自适应。

Result: 在真实地下矿井中使用四足机器人部署验证，框架能够保持对环境不确定性的鲁棒性并完成巡检任务。

Conclusion: 分层框架成功解决了环境模型与实际条件差异的问题，实现了全局覆盖与局部自适应的平衡，提升了机器人巡检的鲁棒性和完成率。

Abstract: In this work, we present a hierarchical framework designed to support robotic
inspection under environment uncertainty. By leveraging a known environment
model, existing methods plan and safely track inspection routes to visit points
of interest. However, discrepancies between the model and actual site
conditions, caused by either natural or human activities, can alter the surface
morphology or introduce path obstructions. To address this challenge, the
proposed framework divides the inspection task into: (a) generating the initial
global view-plan for region of interests based on a historical map and (b)
local view replanning to adapt to the current morphology of the inspection
scene. The proposed hierarchy preserves global coverage objectives while
enabling reactive adaptation to the local surface morphology. This enables the
local autonomy to remain robust against environment uncertainty and complete
the inspection tasks. We validate the approach through deployments in
real-world subterranean mines using quadrupedal robot.

</details>


### [47] [Spatiotemporal Calibration of Doppler Velocity Logs for Underwater Robots](https://arxiv.org/abs/2510.24571)
*Hongxu Zhao,Guangyang Zeng,Yunling Shao,Tengfei Zhang,Junfeng Wu*

Main category: cs.RO

TL;DR: 提出了统一迭代校准(UIC)框架，用于多传感器系统的外参和时间偏移联合估计，特别针对水下SLAM中的DVL传感器校准问题。


<details>
  <summary>Details</summary>
Motivation: 现有DVL校准方法要么局限于特定传感器配置，要么依赖过度简化的假设，且没有同时估计平移外参和时间偏移的方法。

Method: 采用最大后验概率估计框架，结合高斯过程运动先验进行高保真运动插值，交替执行高效的GP运动状态更新和基于梯度的校准变量更新。

Result: 开发了开源的DVL-相机校准工具箱，通过仿真和真实世界测试验证了方法的有效性。

Conclusion: UIC框架不仅适用于水下应用，其GP先验集成和可靠初始化程序等特性可广泛应用于其他多传感器校准问题。

Abstract: The calibration of extrinsic parameters and clock offsets between sensors for
high-accuracy performance in underwater SLAM systems remains insufficiently
explored. Existing methods for Doppler Velocity Log (DVL) calibration are
either constrained to specific sensor configurations or rely on oversimplified
assumptions, and none jointly estimate translational extrinsics and time
offsets. We propose a Unified Iterative Calibration (UIC) framework for general
DVL sensor setups, formulated as a Maximum A Posteriori (MAP) estimation with a
Gaussian Process (GP) motion prior for high-fidelity motion interpolation. UIC
alternates between efficient GP-based motion state updates and gradient-based
calibration variable updates, supported by a provably statistically consistent
sequential initialization scheme. The proposed UIC can be applied to IMU,
cameras and other modalities as co-sensors. We release an open-source
DVL-camera calibration toolbox. Beyond underwater applications, several aspects
of UIC-such as the integration of GP priors for MAP-based calibration and the
design of provably reliable initialization procedures-are broadly applicable to
other multi-sensor calibration problems. Finally, simulations and real-world
tests validate our approach.

</details>


### [48] [Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning](https://arxiv.org/abs/2510.24584)
*Jørgen Anker Olsen,Lars Rønhaug Pettersen,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出基于课程学习的强化学习框架，训练机器人Olympus实现精确高性能跳跃。分别开发垂直和水平跳跃策略，通过弹道运动规律稠密化稀疏奖励，使用参考状态初始化加速探索，结合行走策略实现多功能动态运动。实验验证了1.25米水平跳跃和1.0米垂直跳跃的厘米级精度。


<details>
  <summary>Details</summary>
Motivation: 训练机器人实现精确高性能跳跃面临奖励稀疏和探索困难等挑战，需要开发有效的学习框架来克服这些问题。

Method: 采用课程式强化学习，分别训练垂直和水平跳跃策略；利用弹道运动规律稠密化稀疏奖励；使用参考状态初始化方案加速动态跳跃行为探索；结合行走策略实现多功能运动。

Result: 实验验证了在多样化地形上的行走能力，跳跃性能超越先前工作，水平跳跃达1.25米（厘米精度），垂直跳跃达1.0米，成功跨越Sim2Real差距。

Conclusion: 该方法有效解决了机器人跳跃学习中的关键挑战，实现了高性能精确跳跃，且只需少量修改即可学习全向跳跃，展现了良好的通用性。

Abstract: This paper presents a curriculum-based reinforcement learning framework for
training precise and high-performance jumping policies for the robot `Olympus'.
Separate policies are developed for vertical and horizontal jumps, leveraging a
simple yet effective strategy. First, we densify the inherently sparse jumping
reward using the laws of projectile motion. Next, a reference state
initialization scheme is employed to accelerate the exploration of dynamic
jumping behaviors without reliance on reference trajectories. We also present a
walking policy that, when combined with the jumping policies, unlocks versatile
and dynamic locomotion capabilities. Comprehensive testing validates walking on
varied terrain surfaces and jumping performance that exceeds previous works,
effectively crossing the Sim2Real gap. Experimental validation demonstrates
horizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to
1.0 m. Additionally, we show that with only minor modifications, the proposed
method can be used to learn omnidirectional jumping.

</details>


### [49] [GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization](https://arxiv.org/abs/2510.24623)
*Nicolai Steinke,Daniel Goehring*

Main category: cs.RO

TL;DR: GroundLoc是一种仅使用LiDAR的定位系统，通过BEV图像投影和关键点识别技术，在大规模室外环境中实现移动机器人定位，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发一种高效、轻量级的LiDAR定位系统，能够在大型室外环境中实现精确的在线定位，同时支持多种传感器模型。

Method: 使用BEV图像投影聚焦感知地面区域，结合R2D2或SIFT关键点识别技术进行地图配准，将先验地图存储为2D栅格图像。

Result: 在SemanticKITTI和HeLiPR数据集上超越现有方法，多会话定位平均轨迹误差低于50cm，满足在线运行要求，支持多种传感器。

Conclusion: GroundLoc提供了一种高效、轻量级的LiDAR定位解决方案，在精度和效率方面表现出色，具有广泛的应用潜力。

Abstract: In this letter, we introduce GroundLoc, a LiDAR-only localization pipeline
designed to localize a mobile robot in large-scale outdoor environments using
prior maps. GroundLoc employs a Bird's-Eye View (BEV) image projection focusing
on the perceived ground area and utilizes the place recognition network R2D2,
or alternatively, the non-learning approach Scale-Invariant Feature Transform
(SIFT), to identify and select keypoints for BEV image map registration. Our
results demonstrate that GroundLoc outperforms state-of-the-art methods on the
SemanticKITTI and HeLiPR datasets across various sensors. In the multi-session
localization evaluation, GroundLoc reaches an Average Trajectory Error (ATE)
well below 50 cm on all Ouster OS2 128 sequences while meeting online runtime
requirements. The system supports various sensor models, as evidenced by
evaluations conducted with Velodyne HDL-64E, Ouster OS2 128, Aeva Aeries II,
and Livox Avia sensors. The prior maps are stored as 2D raster image maps,
which can be created from a single drive and require only 4 MB of storage per
square kilometer. The source code is available at
https://github.com/dcmlr/groundloc.

</details>


### [50] [Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder](https://arxiv.org/abs/2510.24671)
*Li Li,Tobias Brinkmann,Till Temmen,Markus Eisenbarth,Jakob Andert*

Main category: cs.RO

TL;DR: 提出了一种基于Transformer增强的条件变分自编码器(CVAE-T)模型，用于生成环岛多智能体交通场景，以支持智能驾驶功能的验证和开发。


<details>
  <summary>Details</summary>
Motivation: 随着智能驾驶功能在量产车中的集成度提高，确保其功能性和鲁棒性面临更大挑战。相比传统道路测试，基于场景的虚拟测试在时间成本、可重复性和边缘案例探索方面具有显著优势。

Method: 使用Transformer增强的条件变分自编码器(CVAE-T)模型，针对具有高车辆动态和复杂布局的环岛场景，生成多智能体交通场景。

Result: 模型能够准确重建原始场景并生成真实多样的合成场景。潜在空间分析显示部分解纠缠，多个潜在维度对场景属性（如车辆进出时间、速度曲线）具有可解释的影响。

Conclusion: 该模型能够生成用于验证涉及多智能体交互的智能驾驶功能的场景，并为开发和迭代改进提供数据增强。

Abstract: With the increasing integration of intelligent driving functions into
serial-produced vehicles, ensuring their functionality and robustness poses
greater challenges. Compared to traditional road testing, scenario-based
virtual testing offers significant advantages in terms of time and cost
efficiency, reproducibility, and exploration of edge cases. We propose a
Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for
generating multi-agent traffic scenarios in roundabouts, which are
characterized by high vehicle dynamics and complex layouts, yet remain
relatively underexplored in current research. The results show that the
proposed model can accurately reconstruct original scenarios and generate
realistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators
(KPIs) are employed to evaluate the interactive behavior in the generated
scenarios. Analysis of the latent space reveals partial disentanglement, with
several latent dimensions exhibiting distinct and interpretable effects on
scenario attributes such as vehicle entry timing, exit timing, and velocity
profiles. The results demonstrate the model's capability to generate scenarios
for the validation of intelligent driving functions involving multi-agent
interactions, as well as to augment data for their development and iterative
improvement.

</details>


### [51] [Fare: Failure Resilience in Learned Visual Navigation Control](https://arxiv.org/abs/2510.24680)
*Zishuo Wang,Joel Loo,David Hsu*

Main category: cs.RO

TL;DR: Fare框架构建具有故障恢复能力的模仿学习策略，通过OOD检测和识别实现自动故障检测与恢复，无需显式故障数据。


<details>
  <summary>Details</summary>
Motivation: 模仿学习策略在分布外场景中容易发生不可预测的故障，需要能够自动检测并从故障中恢复的稳健策略。

Method: 在模仿学习策略中嵌入OOD检测和识别机制，无需使用显式故障数据，并结合恢复启发式方法。

Result: 真实世界实验表明，Fare能够在两种不同策略架构上实现故障恢复，支持复杂环境中的稳健长距离导航。

Conclusion: Fare框架成功构建了具有故障恢复能力的模仿学习策略，显著提升了视觉导航系统的稳健性。

Abstract: While imitation learning (IL) enables effective visual navigation, IL
policies are prone to unpredictable failures in out-of-distribution (OOD)
scenarios. We advance the notion of failure-resilient policies, which not only
detect failures but also recover from them automatically. Failure recognition
that identifies the factors causing failure is key to informing recovery: e.g.
pinpointing image regions triggering failure detections can provide cues to
guide recovery. We present Fare, a framework to construct failure-resilient IL
policies, embedding OOD-detection and recognition in them without using
explicit failure data, and pairing them with recovery heuristics. Real-world
experiments show that Fare enables failure recovery across two different policy
architectures, enabling robust long-range navigation in complex environments.

</details>


### [52] [A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers](https://arxiv.org/abs/2510.24683)
*Caleb Escobedo,Nataliya Nechyporenko,Shreyas Kadekodi,Alessandro Roncone*

Main category: cs.RO

TL;DR: 提出了一个分析物体感知控制器的框架，重点关注运动学、运动曲线和虚拟约束三个设计考虑因素，并通过实验验证和比较了三种代表性控制器。


<details>
  <summary>Details</summary>
Motivation: 实时控制是机器人在动态物体环境中安全操作的关键方面，需要开发能够预测和避免碰撞的物体感知控制器。

Method: 建立了一个分析框架，基于运动学、运动曲线和虚拟约束三个设计考虑因素，通过基础机器人-障碍物实验场景验证机器人行为，并比较三种代表性物体感知控制器。

Result: 分析发现物体感知控制器的设计通常缺乏运动学考虑、控制点连续性以及运动曲线的稳定性。

Conclusion: 该框架可用于未来设计、比较和基准测试避障方法。

Abstract: Real-time control is an essential aspect of safe robot operation in the real
world with dynamic objects. We present a framework for the analysis of
object-aware controllers, methods for altering a robot's motion to anticipate
and avoid possible collisions. This framework is focused on three design
considerations: kinematics, motion profiles, and virtual constraints.
Additionally, the analysis in this work relies on verification of robot
behaviors using fundamental robot-obstacle experimental scenarios. To showcase
the effectiveness of our method we compare three representative object-aware
controllers. The comparison uses metrics originating from the design
considerations. From the analysis, we find that the design of object-aware
controllers often lacks kinematic considerations, continuity of control points,
and stability in movement profiles. We conclude that this framework can be used
in the future to design, compare, and benchmark obstacle avoidance methods.

</details>


### [53] [Embodying Physical Computing into Soft Robots](https://arxiv.org/abs/2510.24692)
*Jun Wang,Ziyang Zhou,Ardalan Kahak,Suyi Li*

Main category: cs.RO

TL;DR: 这篇视角论文提出了将物理计算嵌入软体机器人的框架，讨论了三种独特策略：模拟振荡器、物理储备池计算和物理算法计算，使软体机器人能够执行复杂行为而无需传统电子设备。


<details>
  <summary>Details</summary>
Motivation: 软化和集成计算机与控制器是软体机器人实现日常使用鲁棒性和智能化的关键前沿领域，物理计算为实现这一目标提供了令人兴奋的潜力。

Method: 提出了将物理计算嵌入软体机器人的框架，重点介绍了三种具体方法：模拟振荡器、物理储备池计算和物理算法计算，这些方法利用机械计算内核的内部相互作用来处理输入输出。

Result: 这些嵌入式计算机使软体机器人能够执行复杂行为，包括带避障的协调运动、有效载荷重量和方向分类，以及基于逻辑规则的可编程操作，这些功能原本需要CMOS电子设备才能实现。

Conclusion: 论文详细阐述了这些嵌入式物理计算方法的原理，调查了当前最新进展，并提出了未来发展的展望，为软体机器人的智能化提供了新的技术路径。

Abstract: Softening and onboarding computers and controllers is one of the final
frontiers in soft robotics towards their robustness and intelligence for
everyday use. In this regard, embodying soft and physical computing presents
exciting potential. Physical computing seeks to encode inputs into a mechanical
computing kernel and leverage the internal interactions among this kernel's
constituent elements to compute the output. Moreover, such input-to-output
evolution can be re-programmable. This perspective paper proposes a framework
for embodying physical computing into soft robots and discusses three unique
strategies in the literature: analog oscillators, physical reservoir computing,
and physical algorithmic computing. These embodied computers enable the soft
robot to perform complex behaviors that would otherwise require CMOS-based
electronics -- including coordinated locomotion with obstacle avoidance,
payload weight and orientation classification, and programmable operation based
on logical rules. This paper will detail the working principles of these
embodied physical computing methods, survey the current state-of-the-art, and
present a perspective for future development.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [54] [Control VAR: a counterfactual based approach to inference in macroeconomics](https://arxiv.org/abs/2510.23762)
*Raimondo Pala*

Main category: econ.EM

TL;DR: 本文提出control-VAR方法，使用控制变量而非独立性假设来估计VAR模型中的因果效应，并通过自然灾害对美国经济影响的实证分析验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统VAR模型依赖独立性假设来获得因果解释，但在许多实际经济情境中这种假设不成立，需要开发不依赖独立性假设的因果识别方法。

Method: 提出control-VAR方法，使用控制变量（如德国作为控制组）来估计因果效应，可估计虚拟政策的平均处理效应或连续政策的平均因果响应。

Result: 实证分析发现自然灾害对美国经济有负面影响，没有周期性正面效应，这与先前文献结论不同，表明control-VAR方法能提供更可信的因果估计。

Conclusion: control-VAR为严格独立性假设提供了可行的替代方案，在政策设计特别是应对自然灾害方面具有重要应用价值。

Abstract: This paper addresses the challenges of giving a causal interpretation to
vector autoregressions (VARs). I show that under independence assumptions VARs
can identify average treatment effects, average causal responses, or a mix of
the two, depending on the distribution of the policy. But what about situations
in which the economist cannot rely on independence assumptions? I propose an
alternative method, defined as control-VAR, which uses control variables to
estimate causal effects. Control-VAR can estimate average treatment effects on
the treated for dummy policies or average causal responses over time for
continuous policies.
  The advantages of control-based approaches are demonstrated by examining the
impact of natural disasters on the US economy, using Germany as a control.
Contrary to previous literature, the results indicate that natural disasters
have a negative economic impact without any cyclical positive effect. These
findings suggest that control-VARs provide a viable alternative to strict
independence assumptions, offering more credible causal estimates and
significant implications for policy design in response to natural disasters.

</details>


### [55] [Nearest Neighbor Matching as Least Squares Density Ratio Estimation and Riesz Regression](https://arxiv.org/abs/2510.24433)
*Masahiro Kato*

Main category: econ.EM

TL;DR: 该研究证明了最近邻匹配可以解释为Riesz回归的一个实例，用于自动去偏机器学习。作者首先证明了Lin等人(2023)提出的密度比估计方法本质上等同于Kanamori等人(2009)提出的最小二乘重要性拟合(LSIF)，然后基于LSIF框架推导了Riesz回归，并最终从Riesz回归推导出最近邻匹配。


<details>
  <summary>Details</summary>
Motivation: 建立最近邻匹配与Riesz回归之间的理论联系，将最近邻匹配统一到自动去偏机器学习的理论框架中，为理解这两种方法的内在关系提供理论基础。

Method: 首先证明Lin等人(2023)的密度比估计方法与LSIF的等价性，然后在LSIF框架下推导Riesz回归，最后从Riesz回归推导出最近邻匹配。

Result: 成功建立了最近邻匹配与Riesz回归的理论等价关系，证明了最近邻匹配可以视为Riesz回归的一个特例，为自动去偏机器学习提供了统一的理论视角。

Conclusion: 该研究通过理论推导建立了最近邻匹配与Riesz回归的深刻联系，将两种看似不同的方法统一到同一个理论框架下，为自动去偏机器学习方法的发展提供了重要的理论支撑。

Abstract: This study proves that Nearest Neighbor (NN) matching can be interpreted as
an instance of Riesz regression for automatic debiased machine learning. Lin et
al. (2023) shows that NN matching is an instance of density-ratio estimation
with their new density-ratio estimator. Chernozhukov et al. (2024) develops
Riesz regression for automatic debiased machine learning, which directly
estimates the Riesz representer (or equivalently, the bias-correction term) by
minimizing the mean squared error. In this study, we first prove that the
density-ratio estimation method proposed in Lin et al. (2023) is essentially
equivalent to Least-Squares Importance Fitting (LSIF) proposed in Kanamori et
al. (2009) for direct density-ratio estimation. Furthermore, we derive Riesz
regression using the LSIF framework. Based on these results, we derive NN
matching from Riesz regression. This study is based on our work Kato (2025a)
and Kato (2025b).

</details>


### [56] [Panel data models with randomly generated groups](https://arxiv.org/abs/2510.24496)
*Jean-Pierre Florens,Anna Simoni*

Main category: econ.EM

TL;DR: 提出了一种用于动态面板数据模型中未观测异质性建模和推断的结构框架，基于有限混合的混合方法，避免了狄利克雷过程混合的聚类不一致问题，并提供可解释的聚类结构表示。


<details>
  <summary>Details</summary>
Motivation: 传统方法将聚类视为描述性工具，而本文旨在建模异质性作为潜在的聚类机制，其中聚类数量未知且需要估计，以更准确地捕捉动态面板数据中的异质性结构。

Method: 基于有限混合的混合方法，扩展了Fruhwirth-Schnatter等人的Telescoping Sampler到带有协变量的动态面板模型，开发了高效的MCMC算法进行全贝叶斯推断。

Result: 渐近分析显示混合测度的后验分布在Wasserstein距离下以参数速率收缩到真实值，确保了聚类和结构参数的恢复。模拟研究展示了良好的有限样本性能。

Conclusion: 该方法能够有效识别动态面板数据中的潜在异质性，在收入-民主关系应用中，只有在控制额外协变量时才能揭示潜在的异质性。

Abstract: We develop a structural framework for modeling and inferring unobserved
heterogeneity in dynamic panel-data models. Unlike methods treating clustering
as a descriptive device, we model heterogeneity as arising from a latent
clustering mechanism, where the number of clusters is unknown and estimated.
Building on the mixture of finite mixtures (MFM) approach, our method avoids
the clustering inconsistency issues of Dirichlet process mixtures and provides
an interpretable representation of the population clustering structure. We
extend the Telescoping Sampler of Fruhwirth-Schnatter et al. (2021) to dynamic
panels with covariates, yielding an efficient MCMC algorithm that delivers full
Bayesian inference and credible sets. We show that asymptotically the posterior
distribution of the mixing measure contracts around the truth at parametric
rates in Wasserstein distance, ensuring recovery of clustering and structural
parameters. Simulations demonstrate strong finite-sample performance. Finally,
an application to the income-democracy relationship reveals latent
heterogeneity only when controlling for additional covariates.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [57] [A modified particle filter that reduces weight collapse](https://arxiv.org/abs/2510.23740)
*Shay Gilpin,Michael Herty*

Main category: stat.AP

TL;DR: 提出一种基于能量多样性度量的改进粒子滤波器，通过最小化双体能量势来调整粒子权重，防止权重崩溃，提高状态估计精度。


<details>
  <summary>Details</summary>
Motivation: 解决粒子滤波器中常见的权重崩溃问题，即单个权重接近1而其他权重接近0，导致估计分布崩溃。

Method: 引入基于能量多样性度量的权重调整方法，最小化双体能量势来促进权重分布平衡。

Result: 在线性和非线性动力学模型的数值实验中，相比经典粒子滤波器，新方法改善了权重分布并提高了状态估计精度。

Conclusion: 所提出的改进粒子滤波器能有效缓解权重崩溃问题，在状态估计方面优于经典粒子滤波器。

Abstract: Particle filters are a widely used Monte Carlo based data assimilation
technique that estimates the probability distribution of a system's state
conditioned on observations through a collection of weights and particles. A
known problem for particle filters is weight collapse, or degeneracy, where a
single weight attains a value of one while all others are close to zero,
thereby collapsing the estimated distribution. We address this issue by
introducing a novel modification to the particle filter that is simple to
implement and inspired by energy-based diversity measures. Our approach adjusts
particle weights to minimize a two-body energy potential, promoting balanced
weight distributions and mitigating collapse. We demonstrate the performance of
this modified particle filter in a series of numerical experiments with linear
and nonlinear dynamical models, where we compare with the classical particle
filter and ensemble Kalman filters in the nonlinear case. We find that our new
approach improves weight distributions compared to the classical particle
filter and thereby improve state estimates.

</details>


### [58] [A web-based user interface for Fam3PRO, a multi-gene, multi-cancer risk prediction model for families with cancer history](https://arxiv.org/abs/2510.23805)
*Xueying Chen,Jianfeng Ke,Lauren Flynn,Giovanni Parmigiani,Danielle Braun*

Main category: stat.AP

TL;DR: 开发了F3PI网络应用界面，使Fam3PRO遗传性癌症风险评估模型更易于临床使用


<details>
  <summary>Details</summary>
Motivation: 现有的Fam3PRO R包缺乏用户界面，限制了其在临床环境中的实际应用，需要开发基于网络的用户界面来扩大使用范围

Method: 使用R Shiny构建F3PI界面，通过pedigreejs交互式可视化和修改家谱数据，后端Fam3PRO模型处理输入数据生成携带概率和未来癌症风险

Result: F3PI简化了患者和家族史数据收集，平均一分钟内提供18种癌症的个性化风险评估和22个遗传性癌症基因的变异携带概率，结果支持交互查看和下载

Conclusion: F3PI是一个易于使用的交互式网络应用，使癌症和遗传风险信息更容易被医疗提供者和患者获取

Abstract: Purpose: Hereditary cancer risk is key to guiding screening and prevention
strategies. Cancer risks can vary by individual due to the presence or absence
of high- and moderate-risk pathogenic variants (PV) in cancer-associated genes,
in addition to sex, age, and other risk factors. We previously developed
Fam3PRO, a flexible multi-gene, multi-cancer Mendelian risk prediction model
that estimates a patient's risk of carrying a PV in hereditary cancer genes and
their future risk of developing several types of cancer. The Fam3PRO R package
includes 22 genes with 18 associated cancers, allowing users to build
customized sub-models from any gene-cancer set. However, the current R package
lacks a user interface (UI), limiting its practical use in clinical settings.
Therefore, we aim to develop a web-based UI for broader use of the Fam3PRO
functionalities.
  Methods: The Fam3PRO UI (F3PI), built with R Shiny, collects and formats
inputs including family health history, genetic test results, and other risk
factors. Pedigree data are interactively visualized and modified via
pedigreejs, while the backend Fam3PRO model takes all the inputs to generate
carrier probabilities and future cancer risks, presented through an interactive
UI.
  Results: F3PI streamlines the collection of patient and family history data,
which is analyzed by the Fam3PRO models to provide personalized cancer risks
for each proband across 18 cancers, as well as probabilities that a proband has
a PV in up to 22 hereditary cancer genes. These results are returned to the
user, within one minute on average and are available in both interactive and
downloadable formats.
  Conclusion: We have developed F3PI, an easy-to-use, interactive web
application that makes cancer and genetic risk information more accessible to
providers and their patients.

</details>


### [59] [Universal Inference for Testing Calibration of Mean Estimates within the Exponential Dispersion Family](https://arxiv.org/abs/2510.23821)
*Łukasz Delong,Mario Wüthrich*

Main category: stat.AP

TL;DR: 本文提出了一种在指数分散族中使用子采样分割似然比检验来验证均值校准的方法，该方法提供有限样本保证和普遍有效的临界值。


<details>
  <summary>Details</summary>
Motivation: 在金融和精算决策等领域，预测的均值校准验证至关重要。需要开发具有有限样本保证的校准测试方法。

Method: 在指数分散族中开发子采样分割似然比检验，使用普遍有效的临界值，并提出基于该检验的新测试统计量。

Result: 数值分析表明，该方法在检测错误校准方面具有高功效，是经典似然比检验的有吸引力的替代方案。

Conclusion: 子采样分割似然比检验为均值校准验证提供了具有有限样本保证的有效方法，在检测错误校准方面表现出色。

Abstract: Calibration of mean estimates for predictions is a crucial property in many
applications, particularly in the fields of financial and actuarial
decision-making. In this paper, we first review classical approaches for
validating mean-calibration, and we discuss the Likelihood Ratio Test (LRT)
within the Exponential Dispersion Family (EDF). Then, we investigate the
framework of universal inference to test for mean-calibration. We develop a
sub-sampled split LRT within the EDF that provides finite sample guarantees
with universally valid critical values. We investigate type I error, power and
e-power of this sub-sampled split LRT, we compare it to the classical LRT, and
we propose a novel test statistics based on the sub-sampled split LRT to
enhance the performance of the calibration test. A numerical analysis verifies
that our proposal is an attractive alternative to the classical LRT achieving a
high power in detecting miscalibration.

</details>


### [60] [Forecasting Melting Points in Svalbard, Norway Using Quantile Gradient Boosting and Adaptive Conformal Prediction Region](https://arxiv.org/abs/2510.23976)
*Richard Berk*

Main category: stat.AP

TL;DR: 使用分位数梯度提升方法预测挪威斯瓦尔巴群岛2023年每日气温，采用14天滞后天气指标作为预测因子，提供两周提前期的温度预测和不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 为斯瓦尔巴群岛提供准确的气温预测，满足当地利益相关者的需求，并支持北极适应政策的制定。

Method: 应用分位数梯度提升（小型AI）方法，使用5个常规收集的天气指标（滞后14天）作为预测因子，0.60分位数损失函数对低估赋予更高权重，并采用保形预测区域量化不确定性。

Result: 成功生成了两周提前期的温度预测，并通过保形预测区域提供了具有理论保证覆盖率的预测不确定性量化。

Conclusion: 该方法能够为北极地区提供可靠的气温预测，对当地适应气候变化具有重要政策意义。

Abstract: Using data from the Longyearbyen weather station, quantile gradient boosting
(``small AI'') is applied to forecast daily 2023 temperatures in Svalbard,
Norway. The 0.60 quantile loss weights underestimates about 1.5 times more than
overestimates. Predictors include five routinely collected indicators of
weather conditions, each lagged by 14~days, yielding temperature forecasts with
a two-week lead time. Conformal prediction regions quantify forecasting
uncertainty with provably valid coverage. Forecast accuracy is evaluated with
attention to local stakeholder concerns, and implications for Arctic adaptation
policy are discussed.

</details>


### [61] [Machine Learning for the Production of Official Statistics: Density Ratio Estimation using Biased Transaction Data for Japanese labor statistics](https://arxiv.org/abs/2510.24153)
*Yuya Takada,Kiyoshi Izumi*

Main category: stat.AP

TL;DR: 本文展示了即使存在选择偏差的交易数据，通过机器学习中的密度比估计和协变量偏移监督学习方法，也能用于及时发布官方统计数据。


<details>
  <summary>Details</summary>
Motivation: 国家统计机构开始使用非传统数据源（如POS数据和手机GPS数据）来制作官方统计数据。这些数据具有显著提升统计有用性的潜力，但由于非抽样调查收集方式存在严重选择偏差，进展缓慢。

Method: 采用机器学习中的密度比估计和协变量偏移监督学习方法，处理交易数据中的选择偏差问题。以日本私营就业机构的有偏数据为案例研究。

Result: 能够及时生成初步统计数据，使得关键劳动力市场指标可以提前发布，否则可能会延迟长达一年，从而无法用于及时决策。

Conclusion: 即使存在偏差的交易数据，通过适当的方法处理选择偏差，可以成为官方统计的宝贵资源，显著扩展统计范围并改善决策质量。

Abstract: National statistical institutes are beginning to use non-traditional data
sources to produce official statistics. These sources, originally collected for
non-statistical purposes, include point-of-sales(POS) data and mobile phone
global positioning system(GPS) data. Such data have the potential to
significantly enhance the usefulness of official statistics. In the era of big
data, many private companies are accumulating vast amounts of transaction data.
Exploring how to leverage these data for official statistics is increasingly
important. However, progress has been slower than expected, mainly because such
data are not collected through sample-based survey methods and therefore
exhibit substantial selection bias. If this bias can be properly addressed,
these data could become a valuable resource for official statistics,
substantially expanding their scope and improving the quality of
decision-making, including economic policy. This paper demonstrates that even
biased transaction data can be useful for producing official statistics for
prompt release, by drawing on the concepts of density ratio estimation and
supervised learning under covariate shift, both developed in the field of
machine learning. As a case study, we show that preliminary statistics can be
produced in a timely manner using biased data from a Japanese private
employment agency. This approach enables the early release of a key labor
market indicator that would otherwise be delayed by up to a year, thereby
making it unavailable for timely decision-making.

</details>


### [62] [Streamlining business functions in official statistical production with Machine Learning](https://arxiv.org/abs/2510.24394)
*Sandra Barragán,Adrián Pérez-Bote,Carlos Sáez,David Salgado,Luis Sanguiao-Sande*

Main category: stat.AP

TL;DR: 使用统计学习模型优化官方统计生产流程中业务功能的试点和生产经验总结


<details>
  <summary>Details</summary>
Motivation: 寻求在准确性、成本效益、及时性、粒度、响应负担减少和频率等方面的改进，以提高统计生产流程的质量

Method: 采用统计学习模型，在西班牙统计局(INE)的真实调查数据上进行试点实验

Result: 成功实施了试点经验，验证了该方法在优化业务功能方面的可行性

Conclusion: 统计学习模型能够有效提升官方统计生产流程的效率和效果

Abstract: We provide a description of pilot and production experiences to streamline
some business functions in the official statistical production process using
statistical learning models. Our approach is quality-oriented searching for an
improvement on accuracy, cost-efficiency, timeliness, granularity, response
burden reduction, and frequency. Pilot experiences have been conducted with
data from real surveys in Statistics Spain (INE).

</details>


### [63] [GNAR-HARX Models for Realised Volatility: Incorporating Exogenous Predictors and Network Effects](https://arxiv.org/abs/2510.24443)
*Tom Ó Nualláin*

Main category: stat.AP

TL;DR: GNAR-HARX模型结合网络自回归结构和异质自回归动态，用于预测已实现波动率，在16年样本外测试中优于单变量基准模型。


<details>
  <summary>Details</summary>
Motivation: 设计能够同时捕捉金融市场时间持续性和横截面溢出效应的波动率预测模型。

Method: 将广义网络自回归(GNAR)结构与异质自回归(HAR)动态及外生预测变量(如隐含波动率)相结合，应用于10个国际股指的日度已实现方差数据，采用滚动窗口进行一步预测。

Result: 基于QLIKE损失的最佳模型是不含外生变量的局部GNAR-HAR，而最低MSE由含隐含波动率的标准GNAR-HARX实现。全连接网络始终优于动态估计的图套索网络。

Conclusion: 局部和标准GNAR-HAR(X)模型提供最强预测能力，虽然参数多于简约的全局变体，但所有GNAR-HAR(X)模型都优于单变量HAR(X)基准。隐含波动率和隔夜收益是最有用的外生预测变量。

Abstract: This project introduces the GNAR-HARX model, which combines Generalised
Network Autoregressive (GNAR) structure with Heterogeneous Autoregressive (HAR)
dynamics and exogenous predictors such as implied volatility. The model is
designed for forecasting realised volatility by capturing both temporal
persistence and cross-sectional spillovers in financial markets. We apply it to
daily realised variance data for ten international stock indices, generating
one-step-ahead forecasts in a rolling window over an out-of-sample period of
approximately 16 years (2005-2020).
  Forecast accuracy is evaluated using the Quasi-Likelihood (QLIKE) loss and
mean squared error (MSE), and we compare global, standard, and local variants
across different network structures and exogenous specifications. The best
model found by QLIKE is a local GNAR-HAR without exogenous variables, while the
lowest MSE is achieved by a standard GNAR-HARX with implied volatility. Fully
connected networks consistently outperform dynamically estimated graphical
lasso networks.
  Overall, local and standard GNAR-HAR(X) models deliver the strongest
forecasts, though at the cost of more parameters than the parsimonious global
variant, which nevertheless remains competitive. Across all cases, GNAR-HAR(X)
models outperform univariate HAR(X) benchmarks, which often require more
parameters than the GNAR-based specifications. While the top model found by
QLIKE does not use exogenous variables, implied volatility and overnight
returns emerge as the most useful predictors when included.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [64] [Global YouTube Trending Dataset (2022-2025): Three Years of Platform-Curated, Cross-National Trends in Digital Culture](https://arxiv.org/abs/2510.23645)
*Alexandre Goncalves,Yee Man Margaret Ng*

Main category: cs.SI

TL;DR: 本研究提供了一个为期三年的YouTube Trending视频存档数据集，涵盖2022年7月1日至2025年6月30日期间104个国家的每日四次快照，包含78.4百万条视频记录，为研究数字文化、平台治理和内容流行度动态提供了独特的跨国纵向数据。


<details>
  <summary>Details</summary>
Motivation: YouTube于2025年7月1日关闭了其长达十年的公开"Trending"页面，这标志着平台策划的非个性化视频发现时代的结束。Trending列表长期以来是研究算法影响、文化传播和危机沟通的重要窗口，提供了研究全球关注度和文化显著性的难得"真实参考"。

Method: 收集了2022年7月1日至2025年6月30日期间104个国家的YouTube Trending视频数据，每日四次快照，每个快照捕获最多200个趋势视频。数据集包含446,971个快照，涵盖78.4百万条视频条目（726,627个独特视频）及相关元数据。

Result: 创建了一个包含446,971个快照的数据集，每个记录包括核心标识符（快照时间、国家、排名）和内容元数据（视频ID、频道ID、标题、描述、标签、发布日期、类别、频道名称、语言、直播状态、观看次数和评论）。

Conclusion: 该数据集提供了前所未有的跨国和纵向覆盖范围，为研究数字文化、平台治理和内容流行度的时间动态提供了宝贵资源，填补了先前数据集在地理范围和时间框架上的局限性。

Abstract: On July 1, 2025, YouTube retired its decade-long public "Trending" pages,
ending platform-curated, non-personalized video discovery. The Trending list
had long served as a vital lens into algorithmic influence, cultural diffusion,
and crisis communication globally, offering a rare "ground-truth" reference to
study global attention and cultural salience. We present a three-year archival
dataset of YouTube Trending videos, collected from July 1, 2022, to June 30,
2025, with four daily snapshots for each of the 104 countries. The dataset
includes 446,971 snapshots, each capturing up to 200 trending videos,
encompassing 78.4 million video entries (726,627 unique videos) and associated
metadata. Each record includes core identifiers (snapshot time, country, rank)
and content metadata (video ID, channel ID, title, description, tags,
publication date, category, channel name, language, live status, views, and
comments). Unlike previous datasets with limited geographic scope or short
timeframes, our non-personalized data provides exceptional cross-national and
longitudinal coverage for studying digital culture, platform governance, and
temporal dynamics in content popularity. We document the data collection
methodology, schema design, coverage, descriptive statistics for both global
and U.S. trending videos, and the ethical safeguards implemented throughout.

</details>


### [65] [Hamming Graph Metrics: A Multi-Scale Framework for Structural Redundancy and Uniqueness in Graphs](https://arxiv.org/abs/2510.23646)
*R. Scott Johnson*

Main category: cs.SI

TL;DR: 提出了汉明图度量（HGM）框架，通过精确k可达性张量表示图结构，能够量化多尺度连通性模式的独特性，为网络弹性和功能分析提供新工具。


<details>
  <summary>Details</summary>
Motivation: 传统图中心性度量能有效量化节点重要性，但无法捕捉多尺度连通性模式的结构独特性，这对于理解网络弹性和功能至关重要。

Method: 使用精确k可达性张量表示图，定义张量汉明距离作为图间度量，并开发了多尺度谱分析、总结统计量、图间比较方法和分析性质。

Result: HGM框架具有置换不变性、是标记图上的真度量、对边扰动具有Lipschitz稳定性，并提供了度相关的显式常数。

Conclusion: HGM框架为图结构分析提供了新的多尺度视角，能够有效捕捉传统方法忽略的结构独特性，在网络弹性和功能分析中具有重要应用价值。

Abstract: Traditional graph centrality measures effectively quantify node importance
but fail to capture the structural uniqueness of multi-scale connectivity
patterns -- critical for understanding network resilience and function. This
paper introduces \emph{Hamming Graph Metrics (HGM)}, a framework that
represents a graph by its exact-$k$ reachability tensor
$\mathcal{B}G\in{0,1}^{N\times N\times D}$ with slices
$(\mathcal{B}G){:,:,1}=A$ and, for $k\ge 2$,
$(\mathcal{B}G){:,:,k}=\mathbf{1}!\left[\sum{t=1}^{k}
A^t>0\right]-\mathbf{1}!\left[\sum_{t=1}^{k-1} A^t>0\right]$ (shortest-path
distance exactly $k$). Guarantees. (i) \emph{Permutation invariance}:
$d_{\mathrm{HGM}}(\pi(G),\pi(H))=d_{\mathrm{HGM}}(G,H)$ for all vertex
relabelings $\pi$; (ii) the \emph{tensor Hamming distance}
$d_{\mathrm{HGM}}(G,H):=|,\mathcal{B}G-\mathcal{B}H,|{1}=\sum{i,j,k}\mathbf{1}!\big[(\mathcal{B}G){ijk}\neq(\mathcal{B}H){ijk}\big]$
is a \emph{true metric} on labeled graphs; and (iii) \emph{Lipschitz stability}
to edge perturbations with explicit degree-dependent constants (see
Graph-to-Graph Comparison'' $\to$ Tensor Hamming metric''; ``Stability to edge
perturbations''; Appendix A). We develop: (1) \emph{per-scale spectral
analysis} via classical MDS on double-centered Hamming matrices $D^{(k)}$,
yielding spectral coordinates and explained variances; (2) \emph{summary
statistics} for node-wise and graph-level structural dissimilarity; (3)
\emph{graph-to-graph comparison} via the metric above; and (4) \emph{analytic
properties} including extremal characterizations, multi-scale limits, and
stability bounds.

</details>


### [66] [RoGBot: Relationship-Oblivious Graph-based Neural Network with Contextual Knowledge for Bot Detection](https://arxiv.org/abs/2510.23648)
*Ashutosh Anshul,Mohammad Zia Ur Rehman,Sri Akash Kadali,Nagendra Kumar*

Main category: cs.SI

TL;DR: 提出了一种新颖的多模态框架，用于检测Twitter上的自动化账户（机器人），该框架结合了文本特征和用户元数据，使用基于图的方法但不需要关注者数据。


<details>
  <summary>Details</summary>
Motivation: 现有机器人检测方法严重依赖用户间关系数据，限制了在缺乏此类信息场景下的应用。需要开发不依赖显式用户关系数据的检测方法。

Method: 使用基于Transformer的模型（如BERT）提取推文的深度语义嵌入，通过最大池化形成用户级表示，结合辅助行为特征，再通过GraphSAGE模型捕获用户行为的局部和全局模式。

Result: 在Cresci-15、Cresci-17和PAN 2019数据集上的实验结果显示，准确率分别达到99.8%、99.1%和96.8%。

Conclusion: 该方法在不依赖关注者数据的情况下实现了高性能的机器人检测，对日益复杂的机器人策略具有有效性。

Abstract: Detecting automated accounts (bots) among genuine users on platforms like
Twitter remains a challenging task due to the evolving behaviors and adaptive
strategies of such accounts. While recent methods have achieved strong
detection performance by combining text, metadata, and user relationship
information within graph-based frameworks, many of these models heavily depend
on explicit user-user relationship data. This reliance limits their
applicability in scenarios where such information is unavailable. To address
this limitation, we propose a novel multimodal framework that integrates
detailed textual features with enriched user metadata while employing
graph-based reasoning without requiring follower-following data. Our method
uses transformer-based models (e.g., BERT) to extract deep semantic embeddings
from tweets, which are aggregated using max pooling to form comprehensive
user-level representations. These are further combined with auxiliary
behavioral features and passed through a GraphSAGE model to capture both local
and global patterns in user behavior. Experimental results on the Cresci-15,
Cresci-17, and PAN 2019 datasets demonstrate the robustness of our approach,
achieving accuracies of 99.8%, 99.1%, and 96.8%, respectively, and highlighting
its effectiveness against increasingly sophisticated bot strategies.

</details>


### [67] [JiuTian Chuanliu: A Large Spatiotemporal Model for General-purpose Dynamic Urban Sensing](https://arxiv.org/abs/2510.23662)
*Liangzhe Han,Leilei Sun,Tongyu Zhu,Tao Tao,Jibin Wang,Weifeng Lv*

Main category: cs.SI

TL;DR: 提出GDHME框架，通过自监督学习将大规模人流数据建模为动态图，学习通用节点嵌入，支持多种城市感知任务


<details>
  <summary>Details</summary>
Motivation: 现有方法通常从特定角度处理特定任务，对人类移动性建模不足，学习到的知识在下游应用中适用性有限

Method: 两阶段框架：第一阶段将人和区域视为动态图中的节点，使用连续时间编码器计算演化节点表示；第二阶段利用这些表示支持各种任务

Result: 离线实验证明GDHME能从海量数据中自动学习有价值的节点特征，并已部署到九天川流大模型系统中

Conclusion: GDHME框架能有效学习通用的人类移动性表示，支持多种城市感知应用

Abstract: As a window for urban sensing, human mobility contains rich spatiotemporal
information that reflects both residents' behavior preferences and the
functions of urban areas. The analysis of human mobility has attracted the
attention of many researchers. However, existing methods often address specific
tasks from a particular perspective, leading to insufficient modeling of human
mobility and limited applicability of the learned knowledge in various
downstream applications. To address these challenges, this paper proposes to
push massive amounts of human mobility data into a spatiotemporal model,
discover latent semantics behind mobility behavior and support various urban
sensing tasks. Specifically, a large-scale and widely covering human mobility
data is collected through the ubiquitous base station system and a framework
named General-purpose and Dynamic Human Mobility Embedding (GDHME) for urban
sensing is introduced. The framework follows the self-supervised learning idea
and contains two major stages. In stage 1, GDHME treats people and regions as
nodes within a dynamic graph, unifying human mobility data as
people-region-time interactions. An encoder operating in continuous-time
dynamically computes evolving node representations, capturing dynamic states
for both people and regions. Moreover, an autoregressive self-supervised task
is specially designed to guide the learning of the general-purpose node
embeddings. In stage 2, these representations are utilized to support various
tasks. To evaluate the effectiveness of our GDHME framework, we further
construct a multi-task urban sensing benchmark. Offline experiments demonstrate
GDHME's ability to automatically learn valuable node features from vast amounts
of data. Furthermore, our framework is used to deploy the JiuTian ChuanLiu Big
Model, a system that has been presented at the 2023 China Mobile Worldwide
Partner Conference.

</details>


### [68] [Detecting sub-populations in online health communities: A mixed-methods exploration of breastfeeding messages in BabyCenter Birth Clubs](https://arxiv.org/abs/2510.23692)
*Calla Beauregard,Parisa Suchdev,Ashley M. A. Fehr,Isabelle T. Smith,Tabia Tanzin Prama,Julia Witte Zimmerman,Carter Ward,Juniper Lovato,Christopher M. Danforth,Peter Sheridan Dodd*

Main category: cs.SI

TL;DR: 本研究通过分析BabyCenter平台上331,843名用户的543万条帖子，发现父母在怀孕、分娩和育儿讨论中，焦虑相关词汇的使用从2017年到2024年持续增加。母乳喂养话题中，睡眠、焦虑和工作/日托是主要主题。


<details>
  <summary>Details</summary>
Motivation: 美国卫生局局长2024年将父母压力列为全国健康危机，期望父母在各种平台上寻求建议和分享经验。本研究旨在通过分析大型在线社区BabyCenter的数据，了解父母如何讨论怀孕、分娩和育儿话题。

Method: 使用BERTopic定位母乳喂养主题帖子，LDA主题建模分析主题，比较母乳喂养主题与其他出生俱乐部内容的差异，分析时间序列中的词汇排名变化。

Result: 发现包含焦虑相关词汇的帖子从2017年4月到2024年1月稳步增加；母乳喂养人群中，睡眠主题占主导地位，焦虑和工作/日托主题在母乳喂养人群中更突出，但在整个出生俱乐部数据集中不占主导。

Conclusion: 父母在在线社区中的讨论反映了日益增长的焦虑情绪，母乳喂养父母特别关注睡眠、焦虑和工作/日托问题，这些发现对支持父母心理健康具有重要意义。

Abstract: Parental stress is a nationwide health crisis according to the U.S. Surgeon
General's 2024 advisory. To allay stress, expecting parents seek advice and
share experiences in a variety of venues, from in-person birth education
classes and parenting groups to virtual communities, for example, BabyCenter, a
moderated online forum community with over 4 million members in the United
States alone. In this study, we aim to understand how parents talk about
pregnancy, birth, and parenting by analyzing 5.43M posts and comments from the
April 2017--January 2024 cohort of 331,843 BabyCenter "birth club" users (that
is, users who participate in due date forums or "birth clubs" based on their
babies' due dates). Using BERTopic to locate breastfeeding threads and LDA to
summarize themes, we compare documents in breastfeeding threads to all other
birth-club content. Analyzing time series of word rank, we find that posts and
comments containing anxiety-related terms increased steadily from April 2017 to
January 2024. We used an ensemble of topic models to identify dominant
breastfeeding topics within birth clubs, and then explored trends among all
user content versus those who posted in threads related to breastfeeding
topics. We conducted Latent Dirichlet Allocation (LDA) topic modeling to
identify the most common topics in the full population, as well as within the
subset breastfeeding population. We find that the topic of sleep dominates in
content generated by the breastfeeding population, as well anxiety-related and
work/daycare topics that are not predominant in the full BabyCenter birth club
dataset.

</details>


### [69] [Rewarding Engagement and Personalization in Popularity-Based Rankings Amplifies Extremism and Polarization](https://arxiv.org/abs/2510.24354)
*Jacopo D'Ignazi,Andreas Kaltenbrunner,Gaël Le Mens,Fabrizio Germano,Vicenç Gómez*

Main category: cs.SI

TL;DR: 排名算法通过位置偏见、同质内容偏好、极端用户更活跃以及基于流行度的排名机制，在奖励主动参与和个性化排名时，会放大极端主义和极化现象。


<details>
  <summary>Details</summary>
Motivation: 尽管有大量研究，但在线平台如何影响极端主义和极化的机制仍不清楚。本文旨在识别和测试一个基于经验证据的机制，解释排名算法如何放大这些现象。

Method: 建立动态模型，通过模拟和与数百名人类参与者的交互实验来评估，其中排名会根据用户活动动态更新。

Result: 在满足四个关键假设（位置偏见、同质内容偏好、极端用户更活跃、基于流行度的排名）的条件下，当平台奖励主动参与并实施个性化排名时，用户不可避免地会转向更极端和极化的新闻消费。

Conclusion: 排名算法在特定条件下会系统性推动用户走向极端主义和极化，这揭示了平台设计对用户行为的重要影响。

Abstract: Despite extensive research, the mechanisms through which online platforms
shape extremism and polarization remain poorly understood. We identify and test
a mechanism, grounded in empirical evidence, that explains how ranking
algorithms can amplify both phenomena. This mechanism is based on
well-documented assumptions: (i) users exhibit position bias and tend to prefer
items displayed higher in the ranking, (ii) users prefer like-minded content,
(iii) users with more extreme views are more likely to engage actively, and
(iv) ranking algorithms are popularity-based, assigning higher positions to
items that attract more clicks. Under these conditions, when platforms
additionally reward \emph{active} engagement and implement \emph{personalized}
rankings, users are inevitably driven toward more extremist and polarized news
consumption. We formalize this mechanism in a dynamical model, which we
evaluate by means of simulations and interactive experiments with hundreds of
human participants, where the rankings are updated dynamically in response to
user activity.

</details>


### [70] [Assessing the influence of social media feedback on traveler's future trip-planning behavior: A multi-model machine learning approach](https://arxiv.org/abs/2510.24077)
*Sayantan Mukherjee,Pritam Ranjan,Joysankar Bhattacharya*

Main category: cs.SI

TL;DR: 本文开发了一个多模型机器学习框架，用于预测社交媒体反馈（社交回报）如何影响印度年轻游客的短期未来旅行决策，准确率超过75%。


<details>
  <summary>Details</summary>
Motivation: 随着印度国内旅游的兴起和社交媒体对年轻游客的影响，研究社交媒体分享获得的反馈如何影响短期未来旅行决策具有重要意义。

Method: 通过问卷调查收集印度游客数据，使用鲁棒过采样方法处理数据不平衡问题，并应用蒙特卡洛交叉验证技术确保预测模型的可靠性。

Result: 模型在预测社交回报对未来旅行计划改变的影响方面达到至少75%的整体准确率。

Conclusion: 研究结果为印度国内旅游业提供了重要的实践启示，并为社交媒体、目的地营销、智慧旅游、遗产旅游等领域的未来研究指明了方向。

Abstract: With the surge of domestic tourism in India and the influence of social media
on young tourists, this paper aims to address the research question on how
"social return" - responses received on social media sharing - of recent trip
details can influence decision-making for short-term future travels. The paper
develops a multi-model framework to build a predictive machine learning model
that establishes a relationship between a traveler's social return, various
social media usage, trip-related factors, and her future trip-planning
behavior. The primary data was collected via a survey from Indian tourists.
After data cleaning, the imbalance in the data was addressed using a robust
oversampling method, and the reliability of the predictive model was ensured by
applying a Monte Carlo cross-validation technique. The results suggest at least
75% overall accuracy in predicting the influence of social return on changing
the future trip plan. Moreover, the model fit results provide crucial practical
implications for the domestic tourism sector in India with future research
directions concerning social media, destination marketing, smart tourism,
heritage tourism, etc.

</details>


### [71] [GRAPHIA: Harnessing Social Graph Data to Enhance LLM-Based Social Simulation](https://arxiv.org/abs/2510.24251)
*Jiarui Ji,Zehua Zhang,Zhewei Wei,Bin Tong,Guan Wang,Bo Zheng*

Main category: cs.SI

TL;DR: Graphia是首个基于LLM的社交图模拟框架，利用图数据通过强化学习对LLM进行后训练，在微观和宏观层面都显著提升了社交网络模拟的准确性。


<details>
  <summary>Details</summary>
Motivation: 社交图提供了高质量的监督信号，编码了局部交互和全局网络结构，但在LLM训练中尚未充分利用。

Method: 通过基于GNN的结构奖励，训练专门代理进行目标选择和边生成，然后通过设计的图生成流程进行模拟。

Result: 在三个真实世界网络上，Graphia在微观层面提升了6.1%的目标选择分数、12%的边分类准确率和27.9%的边内容BERTScore；在宏观层面实现了41.11%更高的结构相似性和32.98%更好的社交现象复制。

Conclusion: 社交图可以作为LLM后训练的高质量监督信号，缩小基于LLM的模拟中代理行为与网络动态之间的差距。

Abstract: Large language models (LLMs) have shown promise in simulating human-like
social behaviors. Social graphs provide high-quality supervision signals that
encode both local interactions and global network structure, yet they remain
underutilized for LLM training. To address this gap, we propose Graphia, the
first general LLM-based social graph simulation framework that leverages graph
data as supervision for LLM post-training via reinforcement learning. With
GNN-based structural rewards, Graphia trains specialized agents to predict whom
to interact with (destination selection) and how to interact (edge generation),
followed by designed graph generation pipelines. We evaluate Graphia under two
settings: Transductive Dynamic Graph Generation (TDGG), a micro-level task with
our proposed node-wise interaction alignment metrics; and Inductive Dynamic
Graph Generation (IDGG), a macro-level task with our proposed metrics for
aligning emergent network properties. On three real-world networks, Graphia
improves micro-level alignment by 6.1% in the composite destination selection
score, 12% in edge classification accuracy, and 27.9% in edge content BERTScore
over the strongest baseline. For macro-level alignment, it achieves 41.11%
higher structural similarity and 32.98% better replication of social phenomena
such as power laws and echo chambers. Graphia also supports counterfactual
simulation, generating plausible behavioral shifts under platform incentives.
Our results show that social graphs can serve as high-quality supervision
signals for LLM post-training, closing the gap between agent behaviors and
network dynamics for LLM-based simulation. Code is available at
https://github.com/Ji-Cather/Graphia.git.

</details>


### [72] [Importance of Overlapping Network Nodes in Influence Spreading](https://arxiv.org/abs/2510.24360)
*Kosti Koistinen,Vesa Kuikka,Kimmo Kaski*

Main category: cs.SI

TL;DR: 该研究分析了复杂网络中重叠子结构（圆圈）对传播过程的影响，发现重叠节点在简单和复杂传播过程中始终比非重叠节点具有更大的影响力。


<details>
  <summary>Details</summary>
Motivation: 复杂网络中重叠子结构或"圆圈"包含属于多个凝聚子群的节点，但这些重叠节点在影响传播过程中的作用尚未得到充分探索。

Method: 使用概率影响传播模型分析具有圆圈结构的网络，通过三个指标量化节点角色：内中心性（易感性）、外中心性（传播力）和中介中心性（中介作用）。

Result: 在传播过程的每个阶段，重叠节点始终表现出比非重叠节点更大的影响力。定义圆圈的标准会影响重叠效应，仅分析最大圆圈时发现圆圈不仅反映节点级属性，还反映拓扑重要性。

Conclusion: 这些发现阐明了局部属性驱动的圆圈与全局社区结构之间的区别，突出了重叠节点在传播动态中的战略重要性，为未来研究重叠节点在圆圈和社区中的作用奠定了基础。

Abstract: In complex networks there are overlapping substructures or "circles" that
consist of nodes belonging to multiple cohesive subgroups. Yet the role of
these overlapping nodes in influence spreading processes remains underexplored.
In the present study, we analyse networks with circle structures using a
probabilistic influence spreading model for processes of simple and complex
contagion. We quantify the roles of nodes using three metrics, i.e.,
In-Centrality, Out-Centrality, and Betweenness Centrality that represent the
susceptibility, spreading power, and mediatory role of nodes, respectively, and
find that at each stage of the spreading process the overlapping nodes
consistently exhibit greater influence than the non-overlapping ones.
Furthermore, we observe that the criteria to define circles shape the
overlapping effects. When we restrict our analysis to only largest circles, we
find that circles reflect not only node-level attributes but also of
topological importance. These findings clarify the distinction between local
attribute-driven circles and global community structures, thus highlighting the
strategic importanc of overlapping nodes in spreading dynamics. This provides
foundation for future research on overlapping nodes in both circles and
communities.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [73] [Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents](https://arxiv.org/abs/2510.23691)
*Zihao Wang,Xujing Li,Yining Ye,Junjie Fang,Haoming Wang,Longxiang Liu,Shihao Liang,Junting Lu,Zhiyong Wu,Jiazhan Feng,Wanjun Zhong,Zili Li,Yu Wang,Yu Miao,Bo Zhou,Yuanfan Li,Hao Wang,Zhongkai Zhao,Faming Wu,Zhengxuan Jiang,Weihao Tan,Heyuan Yao,Shi Yan,Xiangyang Li,Yitao Liang,Yujia Qin,Guang Shi*

Main category: cs.AI

TL;DR: Game-TARS是一个通用游戏智能体，使用统一、可扩展的键盘鼠标动作空间进行训练，通过大规模跨领域预训练在多种游戏环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够跨异构领域（操作系统、网页、模拟游戏）持续预训练的通用游戏智能体，避免API或GUI方法的限制。

Method: 使用基于人类键盘鼠标输入的统一动作空间，进行500B token的大规模预训练，采用衰减持续损失减少因果混淆，以及稀疏思考策略平衡推理深度和推理成本。

Result: 在开放世界Minecraft任务中成功率是之前最佳模型的2倍，在未见过的网页3D游戏中接近人类新手水平，在FPS基准测试中超越GPT-5、Gemini-2.5-Pro和Claude-4-Sonnet。

Conclusion: 简单可扩展的动作表示结合大规模预训练为开发具有广泛计算机使用能力的通用智能体提供了有前景的路径。

Abstract: We present Game-TARS, a generalist game agent trained with a unified,
scalable action space anchored to human-aligned native keyboard-mouse inputs.
Unlike API- or GUI-based approaches, this paradigm enables large-scale
continual pre-training across heterogeneous domains, including OS, web, and
simulation games. Game-TARS is pre-trained on over 500B tokens with diverse
trajectories and multimodal data. Key techniques include a decaying continual
loss to reduce causal confusion and an efficient Sparse-Thinking strategy that
balances reasoning depth and inference cost. Experiments show that Game-TARS
achieves about 2 times the success rate over the previous sota model on
open-world Minecraft tasks, is close to the generality of fresh humans in
unseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet
in FPS benchmarks. Scaling results on training-time and test-time confirm that
the unified action space sustains improvements when scaled to cross-game and
multimodal data. Our results demonstrate that simple, scalable action
representations combined with large-scale pre-training provide a promising path
toward generalist agents with broad computer-use abilities.

</details>


### [74] [AI and the Decentering of Disciplinary Creativity](https://arxiv.org/abs/2510.23734)
*Eamon Duede*

Main category: cs.AI

TL;DR: 本文探讨AI在科学问题解决中的作用及其对学科创造力的影响，区分了创造性方法与创造性产品，并通过数学案例说明AI可能取代学科创造力。


<details>
  <summary>Details</summary>
Motivation: 研究AI在科学问题解决中的角色，特别关注其对学科创造力的潜在影响，旨在理解AI如何改变科学追求的价值。

Method: 基于创造力哲学理论，区分创造性方法与产品，引入学科创造力概念，并通过两个数学案例进行分析。

Result: 研究发现计算可以扩展学科创造力，但某些AI方法可能取代学科创造力，从而可能改变科学追求的价值。

Conclusion: AI在科学中的应用既可能扩展也可能取代学科创造力，这种替代可能影响科学追求的价值和意义。

Abstract: This paper examines the role of artificial intelligence in scientific
problem-solving, with a focus on its implications for disciplinary creativity.
Drawing on recent work in the philosophy of creativity, I distinguish between
creative approaches and creative products, and introduce the concept of
disciplinary creativity -the creative application of discipline-specific
expertise to a valued problem within that field. Through two cases in
mathematics, I show that while computation can extend disciplinary creativity,
certain approaches involving AI can serve to displace it. This displacement has
the potential to alter (and, perhaps, diminish) the value of scientific
pursuit.

</details>


### [75] [Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability](https://arxiv.org/abs/2510.23744)
*Eline M. Bovy,Caleb Probine,Marnix Suilen,Ufuk Topcu,Nils Jansen*

Main category: cs.AI

TL;DR: 本文提出了多环境POMDP（ME-POMDP）的概念，用于处理具有离散模型不确定性的POMDP问题，并开发了精确和近似算法来计算鲁棒策略。


<details>
  <summary>Details</summary>
Motivation: 当多个领域专家对问题建模存在分歧时，需要一种能够处理模型不确定性的框架，目标是找到一个在所有可能POMDP模型中都表现良好的单一鲁棒策略。

Method: 将ME-POMDP推广为具有初始信念集合的AB-POMDP，证明ME-POMDP可以简化为仅在转移和奖励函数或仅在观察和奖励函数上变化的模型，并设计了精确和基于点的近似算法。

Result: 成功将标准POMDP基准扩展到多环境设置，并能够计算相应的鲁棒策略。

Conclusion: ME-POMDP框架有效处理了POMDP中的模型不确定性，通过AB-POMDP的推广和简化方法，结合开发的算法，能够为多环境问题计算鲁棒策略。

Abstract: Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete
model uncertainty. ME-POMDPs represent a finite set of POMDPs that share the
same state, action, and observation spaces, but may arbitrarily vary in their
transition, observation, and reward models. Such models arise, for instance,
when multiple domain experts disagree on how to model a problem. The goal is to
find a single policy that is robust against any choice of POMDP within the set,
i.e., a policy that maximizes the worst-case reward across all POMDPs. We
generalize and expand on existing work in the following way. First, we show
that ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which
we call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any
arbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its
transition and reward functions or only in its observation and reward
functions, while preserving (optimal) policies. We then devise exact and
approximate (point-based) algorithms to compute robust policies for AB-POMDPs,
and thus ME-POMDPs. We demonstrate that we can compute policies for standard
POMDP benchmarks extended to the multi-environment setting.

</details>


### [76] [Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra](https://arxiv.org/abs/2510.23746)
*Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani*

Main category: cs.AI

TL;DR: 提出了一种基于测试时调优的框架，通过增强预训练transformer模型直接从串联质谱和分子式生成分子结构，无需中间步骤或数据库匹配，在两个基准测试中性能显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前串联质谱分析方法依赖数据库匹配或多步骤流程，难以识别未知化合物，特别是参考数据库中不存在的分子。

Method: 利用测试时调优增强预训练transformer模型，实现从串联质谱和分子式端到端的从头分子结构生成，无需人工标注和中间步骤。

Result: 在NPLIB1和MassSpecGym两个基准测试中分别超越DiffMS方法100%和20%，测试时调优相比传统微调在MassSpecGym上性能提升62%。

Conclusion: 该方法能够动态适应新质谱数据，即使预测偏离真实值，生成的分子候选结构仍然准确，为人工解释和可靠识别提供有价值指导。

Abstract: Tandem Mass Spectrometry enables the identification of unknown compounds in
crucial fields such as metabolomics, natural product discovery and
environmental analysis. However, current methods rely on database matching from
previously observed molecules, or on multi-step pipelines that require
intermediate fragment or fingerprint prediction. This makes finding the correct
molecule highly challenging, particularly for compounds absent from reference
databases. We introduce a framework that, by leveraging test-time tuning,
enhances the learning of a pre-trained transformer model to address this gap,
enabling end-to-end de novo molecular structure generation directly from the
tandem mass spectra and molecular formulae, bypassing manual annotations and
intermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on
two popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.
Test-time tuning on experimental spectra allows the model to dynamically adapt
to novel spectra, and the relative performance gain over conventional
fine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground
truth, the generated molecular candidates remain structurally accurate,
providing valuable guidance for human interpretation and more reliable
identification.

</details>


### [77] [Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions](https://arxiv.org/abs/2510.23772)
*Vivek Veeriah,Federico Barbero,Marcus Chiam,Xidong Feng,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Johan Obando-Ceron,Jiaxin Shi,Shaobo Hou,Satinder Singh,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 研究开发了一个AI系统来生成具有美学吸引力、新颖性、反直觉和独特解决方案的国际象棋谜题，并邀请三位世界级专家评估其创造力。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的快速发展，需要探究其是否能够产生创造性和新颖的输出，特别是在国际象棋谜题领域。

Method: 开发了一个AI系统来生成具有美学吸引力、新颖性、反直觉和独特解决方案的国际象棋谜题，并邀请三位国际象棋专家（国际大师Amatzia Avni、特级大师Jonathan Levitt和Matthew Sadler）评估这些谜题的创造力、挑战性和美学设计。

Result: 三位世界级专家对AI生成的谜题进行了评估，选择了他们最喜欢的谜题，并解释了这些谜题的吸引力所在。

Conclusion: 该研究展示了AI系统在国际象棋谜题生成方面的潜力，能够产生具有创造性和美学价值的输出。

Abstract: The rapid advancement of Generative AI has raised significant questions
regarding its ability to produce creative and novel outputs. Our recent work
investigates this question within the domain of chess puzzles and presents an
AI system designed to generate puzzles characterized by aesthetic appeal,
novelty, counter-intuitive and unique solutions. We briefly discuss our method
below and refer the reader to the technical paper for more details. To assess
our system's creativity, we presented a curated booklet of AI-generated puzzles
to three world-renowned experts: International Master for chess compositions
Amatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All
three are noted authors on chess aesthetics and the evolving role of computers
in the game. They were asked to select their favorites and explain what made
them appealing, considering qualities such as their creativity, level of
challenge, or aesthetic design.

</details>


### [78] [Why Foundation Models in Pathology Are Failing](https://arxiv.org/abs/2510.23807)
*Hamid R. Tizhoosh*

Main category: cs.AI

TL;DR: 病理学基础模型存在根本性缺陷，包括诊断准确率低、鲁棒性差、几何不稳定、计算需求大和安全漏洞等问题，源于通用AI基础模型假设与人体组织内在复杂性之间的概念不匹配。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在计算机视觉和语言处理领域取得了革命性突破，但在计算病理学中的快速应用并未带来预期的癌症诊断、预后和多模态检索方面的突破，反而暴露了系统性弱点。

Method: 通过系统性评估分析病理学基础模型的缺陷，识别了七个相互关联的根本原因：生物复杂性、无效的自监督学习、过度泛化、过度架构复杂性、缺乏领域特定创新、数据不足以及与组织切片大小相关的基本设计缺陷。

Result: 研究发现当前病理学基础模型在概念上与组织形态学本质存在严重不匹配，导致性能不佳和系统性弱点。

Conclusion: 当前病理学基础模型存在根本性概念偏差，需要对整个范式进行根本性重新思考，以更好地适应人体组织的固有复杂性。

Abstract: In non-medical domains, foundation models (FMs) have revolutionized computer
vision and language processing through large-scale self-supervised and
multimodal learning. Consequently, their rapid adoption in computational
pathology was expected to deliver comparable breakthroughs in cancer diagnosis,
prognostication, and multimodal retrieval. However, recent systematic
evaluations reveal fundamental weaknesses: low diagnostic accuracy, poor
robustness, geometric instability, heavy computational demands, and concerning
safety vulnerabilities. This short paper examines these shortcomings and argues
that they stem from deeper conceptual mismatches between the assumptions
underlying generic foundation modeling in mainstream AI and the intrinsic
complexity of human tissue. Seven interrelated causes are identified:
biological complexity, ineffective self-supervision, overgeneralization,
excessive architectural complexity, lack of domain-specific innovation,
insufficient data, and a fundamental design flaw related to tissue patch size.
These findings suggest that current pathology foundation models remain
conceptually misaligned with the nature of tissue morphology and call for a
fundamental rethinking of the paradigm itself.

</details>


### [79] [ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents](https://arxiv.org/abs/2510.23822)
*Zhenyu Zhang,Tianyi Chen,Weiran Xu,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: ReCAP是一个用于大语言模型的分层推理规划框架，通过计划分解、父计划结构化重注入和内存高效执行机制，解决长时程任务中的上下文漂移和目标信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在需要多步推理和动态重规划的长时程任务中面临的上下文漂移、目标信息丢失和重复失败循环等问题。

Method: 结合三个关键机制：计划前瞻分解（生成完整子任务列表，执行第一项并优化剩余）、结构化重注入父计划（在递归返回时保持多级上下文一致性）、内存高效执行（限制活动提示使成本随任务深度线性扩展）。

Result: 在各种长时程推理基准测试中显著提高了子目标对齐和成功率，在同步Robotouille上获得32%提升，在异步Robotouille上获得29%改进（严格pass@1协议）。

Conclusion: ReCAP框架通过将高层目标与低层动作对齐、减少冗余提示和保持连贯的上下文更新，有效提升了长时程推理任务的性能。

Abstract: Long-horizon tasks requiring multi-step reasoning and dynamic re-planning
remain challenging for large language models (LLMs). Sequential prompting
methods are prone to context drift, loss of goal information, and recurrent
failure cycles, while hierarchical prompting methods often weaken cross-level
continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive
Context-Aware Reasoning and Planning), a hierarchical framework with shared
context for reasoning and planning in LLMs. ReCAP combines three key
mechanisms: (i) plan-ahead decomposition, in which the model generates a full
subtask list, executes the first item, and refines the remainder; (ii)
structured re-injection of parent plans, maintaining consistent multi-level
context during recursive return; and (iii) memory-efficient execution, bounding
the active prompt so costs scale linearly with task depth. Together these
mechanisms align high-level goals with low-level actions, reduce redundant
prompting, and preserve coherent context updates across recursion. Experiments
demonstrate that ReCAP substantially improves subgoal alignment and success
rates on various long-horizon reasoning benchmarks, achieving a 32% gain on
synchronous Robotouille and a 29% improvement on asynchronous Robotouille under
the strict pass@1 protocol.

</details>


### [80] [Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents](https://arxiv.org/abs/2510.24383)
*Juraj Mavračić*

Main category: cs.AI

TL;DR: Policy Cards是一种机器可读的部署层标准，用于表达AI代理的操作、监管和伦理约束，使其在运行时遵循规定限制。


<details>
  <summary>Details</summary>
Motivation: 现有透明度工具如模型卡、数据卡和系统卡缺乏规范性约束层，无法确保AI代理在部署时遵守操作、监管和伦理要求。

Method: 通过定义包含允许/拒绝规则、义务、证据要求和与NIST AI RMF、ISO/IEC 42001、欧盟AI法案等保证框架映射的规范性层来扩展现有透明度工具。

Result: 每个Policy Card可以自动验证、版本控制，并链接到运行时执行或持续审计管道，为自主代理提供可验证的合规性。

Conclusion: Policy Cards为多代理生态系统中的分布式保证奠定了基础，提供了将高级治理与工程实践整合的实用机制，实现了大规模可问责的自主性。

Abstract: Policy Cards are introduced as a machine-readable, deployment-layer standard
for expressing operational, regulatory, and ethical constraints for AI agents.
The Policy Card sits with the agent and enables it to follow required
constraints at runtime. It tells the agent what it must and must not do. As
such, it becomes an integral part of the deployed agent. Policy Cards extend
existing transparency artifacts such as Model, Data, and System Cards by
defining a normative layer that encodes allow/deny rules, obligations,
evidentiary requirements, and crosswalk mappings to assurance frameworks
including NIST AI RMF, ISO/IEC 42001, and the EU AI Act. Each Policy Card can
be validated automatically, version-controlled, and linked to runtime
enforcement or continuous-audit pipelines. The framework enables verifiable
compliance for autonomous agents, forming a foundation for distributed
assurance in multi-agent ecosystems. Policy Cards provide a practical mechanism
for integrating high-level governance with hands-on engineering practice and
enabling accountable autonomy at scale.

</details>


### [81] [Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models](https://arxiv.org/abs/2510.23824)
*Murad Ismayilov,Edwin Meriaux,Shuo Wen,Gregory Dudek*

Main category: cs.AI

TL;DR: 本文研究了多智能体路径规划中的去中心化目标分配问题，比较了贪心启发式、最优分配和基于大语言模型的智能体方法，发现LLM智能体在良好提示下能达到接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化条件下多个自主智能体在共享环境中的协调挑战，探索语言模型在目标分配任务中的潜力。

Method: 智能体基于环境结构化表示独立生成目标偏好排序，通过固定冲突解决规则进行分配，系统比较贪心启发式、最优分配和LLM智能体方法。

Result: LLM智能体在良好提示和定量信息支持下，能实现接近最优的完工时间，并持续优于传统启发式方法。

Conclusion: 语言模型在去中心化多智能体路径规划中具有潜力，信息结构设计对此类系统至关重要。

Abstract: Coordinating multiple autonomous agents in shared environments under
decentralized conditions is a long-standing challenge in robotics and
artificial intelligence. This work addresses the problem of decentralized goal
assignment for multi-agent path planning, where agents independently generate
ranked preferences over goals based on structured representations of the
environment, including grid visualizations and scenario data. After this
reasoning phase, agents exchange their goal rankings, and assignments are
determined by a fixed, deterministic conflict-resolution rule (e.g., agent
index ordering), without negotiation or iterative coordination. We
systematically compare greedy heuristics, optimal assignment, and large
language model (LLM)-based agents in fully observable grid-world settings. Our
results show that LLM-based agents, when provided with well-designed prompts
and relevant quantitative information, can achieve near-optimal makespans and
consistently outperform traditional heuristics. These findings underscore the
potential of language models for decentralized goal assignment in multi-agent
path planning and highlight the importance of information structure in such
systems.

</details>


### [82] [Law in Silico: Simulating Legal Society with LLM-Based Agents](https://arxiv.org/abs/2510.24442)
*Yiding Wang,Yuxuan Chen,Fanxu Meng,Xifan Chen,Xiaolei Yang,Muhan Zhang*

Main category: cs.AI

TL;DR: Law in Silico是一个基于LLM的法律社会模拟框架，通过AI代理模拟个体决策和立法、裁决、执法等制度机制，验证了LLM能够复现宏观犯罪趋势并为法律理论发展提供支持。


<details>
  <summary>Details</summary>
Motivation: 由于现实法律实验成本高昂或不可行，需要开发AI系统来模拟法律社会，以验证和发展法律理论，支持法律管理。LLM凭借其世界知识和角色扮演能力，是构建法律社会模拟的理想基础。

Method: 提出Law in Silico框架，使用基于LLM的代理来模拟法律场景，包括个体决策和立法、裁决、执法等制度机制。通过比较模拟犯罪率与现实数据来验证框架有效性。

Result: 实验表明LLM代理能够很大程度上复现宏观层面的犯罪趋势，并提供与现实观察一致的见解。微观层面模拟显示，功能良好、透明且适应性的法律系统能更好地保护弱势个体的权利。

Conclusion: LLM能够有效模拟法律系统，不仅复现宏观犯罪模式，还揭示良好法律体系对弱势群体保护的重要性，为法律理论验证和发展提供了可行的技术路径。

Abstract: Since real-world legal experiments are often costly or infeasible, simulating
legal societies with Artificial Intelligence (AI) systems provides an effective
alternative for verifying and developing legal theory, as well as supporting
legal administration. Large Language Models (LLMs), with their world knowledge
and role-playing capabilities, are strong candidates to serve as the foundation
for legal society simulation. However, the application of LLMs to simulate
legal systems remains underexplored. In this work, we introduce Law in Silico,
an LLM-based agent framework for simulating legal scenarios with individual
decision-making and institutional mechanisms of legislation, adjudication, and
enforcement. Our experiments, which compare simulated crime rates with
real-world data, demonstrate that LLM-based agents can largely reproduce
macro-level crime trends and provide insights that align with real-world
observations. At the same time, micro-level simulations reveal that a
well-functioning, transparent, and adaptive legal system offers better
protection of the rights of vulnerable individuals.

</details>


### [83] [From Benchmarks to Business Impact: Deploying IBM Generalist Agent in Enterprise Production](https://arxiv.org/abs/2510.23856)
*Segev Shlomov,Alon Oved,Sami Marreed,Ido Levy,Offer Akrabi,Avi Yaeli,Łukasz Strąk,Elizabeth Koumpan,Yinon Goldshtein,Eilam Shapira,Nir Mashkif,Asaf Adi*

Main category: cs.AI

TL;DR: IBM开发了通用代理CUGA，在学术基准上表现优异，并在企业业务流程外包人才招聘领域进行了试点，展示了在企业环境中部署通用代理的可行性。


<details>
  <summary>Details</summary>
Motivation: 企业面临将AI代理从原型部署到生产系统的挑战，需要解决框架碎片化、开发缓慢和缺乏标准化评估等问题。通用代理在学术基准上表现出色，但在企业生产环境中的应用证据有限。

Method: CUGA采用分层规划器-执行器架构，具有强大的分析基础。在AppWorld和WebArena上实现最先进性能，并在业务流程外包人才招聘领域进行试点评估。

Result: CUGA在BPO-TA基准测试（包含26个任务的13个分析端点）中接近专用代理的准确性，同时显示出减少开发时间和成本的潜力。

Conclusion: 研究提供了通用代理在企业规模运行的早期证据，并总结了技术和组织方面的经验教训，为将研究级架构发展为稳健的企业就绪系统奠定了基础。

Abstract: Agents are rapidly advancing in automating digital work, but enterprises face
a harder challenge: moving beyond prototypes to deployed systems that deliver
measurable business value. This path is complicated by fragmented frameworks,
slow development, and the absence of standardized evaluation practices.
Generalist agents have emerged as a promising direction, excelling on academic
benchmarks and offering flexibility across task types, applications, and
modalities. Yet, evidence of their use in production enterprise settings
remains limited. This paper reports IBM's experience developing and piloting
the Computer Using Generalist Agent (CUGA), which has been open-sourced for the
community (https://github.com/cuga-project/cuga-agent). CUGA adopts a
hierarchical planner--executor architecture with strong analytical foundations,
achieving state-of-the-art performance on AppWorld and WebArena. Beyond
benchmarks, it was evaluated in a pilot within the Business-Process-Outsourcing
talent acquisition domain, addressing enterprise requirements for scalability,
auditability, safety, and governance. To support assessment, we introduce
BPO-TA, a 26-task benchmark spanning 13 analytics endpoints. In preliminary
evaluations, CUGA approached the accuracy of specialized agents while
indicating potential for reducing development time and cost. Our contribution
is twofold: presenting early evidence of generalist agents operating at
enterprise scale, and distilling technical and organizational lessons from this
initial pilot. We outline requirements and next steps for advancing
research-grade architectures like CUGA into robust, enterprise-ready systems.

</details>


### [84] [An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine](https://arxiv.org/abs/2510.24359)
*Pedram Fard,Alaleh Azhir,Neguine Rezaii,Jiazi Tian,Hossein Estiri*

Main category: cs.AI

TL;DR: 提出多智能体生态系统用于N-of-1决策支持，从单一模型转向协调智能，使医疗AI更透明、公平且以个体为中心。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI服务于平均患者，在罕见变异、多病共存和代表性不足人群等边缘情况下表现不佳，这种平均患者谬误损害了公平性和信任度。

Method: 设计多智能体生态系统，按器官系统、患者群体和分析模式聚类智能体，共享模型库和证据合成工具，通过协调层整合结果并评估可靠性、不确定性和数据密度。

Result: 为临床医生提供决策支持包：包含置信区间风险估计、异常值标记和关联证据；验证从群体平均转向个体可靠性，测量低密度区域误差、小样本校准和风险-覆盖权衡。

Conclusion: 该方法通过从单一模型转向协调智能，使医疗AI与医学首要原则保持一致：提供透明、公平且以个体为中心的护理。

Abstract: Artificial intelligence in medicine is built to serve the average patient. By
minimizing error across large datasets, most systems deliver strong aggregate
accuracy yet falter at the margins: patients with rare variants,
multimorbidity, or underrepresented demographics. This average patient fallacy
erodes both equity and trust. We propose a different design: a multi-agent
ecosystem for N-of-1 decision support. In this environment, agents clustered by
organ systems, patient populations, and analytic modalities draw on a shared
library of models and evidence synthesis tools. Their results converge in a
coordination layer that weighs reliability, uncertainty, and data density
before presenting the clinician with a decision-support packet: risk estimates
bounded by confidence ranges, outlier flags, and linked evidence. Validation
shifts from population averages to individual reliability, measured by error in
low-density regions, calibration in the small, and risk--coverage trade-offs.
Anticipated challenges include computational demands, automation bias, and
regulatory fit, addressed through caching strategies, consensus checks, and
adaptive trial frameworks. By moving from monolithic models to orchestrated
intelligence, this approach seeks to align medical AI with the first principle
of medicine: care that is transparent, equitable, and centered on the
individual.

</details>


### [85] [Generating Creative Chess Puzzles](https://arxiv.org/abs/2510.23881)
*Xidong Feng,Vivek Veeriah,Marcus Chiam,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Federico Barbero,Johan Obando-Ceron,Jiaxin Shi,Satinder Singh,Shaobo Hou,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的国际象棋谜题生成方法，通过设计新颖的奖励函数来增强谜题的独特性、反直觉性、多样性和真实性，显著提升了生成谜题的质量。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在各个领域快速发展，但生成真正具有创造性、美学价值和反直觉性的输出仍然是一个挑战。本文旨在解决国际象棋谜题生成领域的这些困难。

Method: 首先对生成式AI架构进行基准测试，然后引入基于国际象棋引擎搜索统计的强化学习框架，设计了增强谜题独特性、反直觉性、多样性和真实性的奖励函数。

Result: 强化学习方法将反直觉谜题生成率从0.22%提升到2.5%，超过了现有数据集(2.1%)和最佳Lichess训练模型(0.4%)。生成的谜题在独特性、多样性方面表现优异，人类专家评价其比传统书籍谜题更具创造性、趣味性和反直觉性。

Conclusion: 该方法成功生成了高质量的AI国际象棋谜题，最终成果获得了三位世界知名专家的认可，证明了强化学习在创造性任务生成中的有效性。

Abstract: While Generative AI rapidly advances in various domains, generating truly
creative, aesthetic, and counter-intuitive outputs remains a challenge. This
paper presents an approach to tackle these difficulties in the domain of chess
puzzles. We start by benchmarking Generative AI architectures, and then
introduce an RL framework with novel rewards based on chess engine search
statistics to overcome some of those shortcomings. The rewards are designed to
enhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.
Our RL approach dramatically increases counter-intuitive puzzle generation by
10x, from 0.22\% (supervised) to 2.5\%, surpassing existing dataset rates
(2.1\%) and the best Lichess-trained model (0.4\%). Our puzzles meet novelty
and diversity benchmarks, retain aesthetic themes, and are rated by human
experts as more creative, enjoyable, and counter-intuitive than composed book
puzzles, even approaching classic compositions. Our final outcome is a curated
booklet of these AI-generated puzzles, which is acknowledged for creativity by
three world-renowned experts.

</details>


### [86] [Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research](https://arxiv.org/abs/2510.24337)
*Daria Kravets-Meinke,Hannah Schmid-Petri,Sonja Niemann,Ute Schmid*

Main category: cs.AI

TL;DR: 本文探讨了生成式大语言模型在传播学内容分析中的应用，提出了应对七大挑战的最佳实践指南，旨在使gLLM辅助的内容分析更易用且符合学科质量标准。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式大语言模型在传播学内容分析中展现出巨大潜力，能够超越众包工作者和训练有素的编码员，但其在传播研究方法论中的整合仍不成熟，需要解决影响结果质量的七大关键挑战。

Method: 综合新兴研究，提出包含代码本开发、提示工程、模型选择、参数调优、迭代优化、可靠性验证和性能提升的七步最佳实践框架。

Result: 通过系统化方法，使gLLM辅助的定量内容分析更易为传播研究者使用，同时确保结果的有效性、可靠性、可重复性和研究伦理。

Conclusion: gLLM辅助的定量内容分析代表了自动化内容分析的范式转变，通过解决七大挑战并遵循最佳实践，可以显著提升传播研究的效率和质量。

Abstract: Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly
being used in communication research for content analysis. Studies show that
gLLMs can outperform both crowd workers and trained coders, such as research
assistants, on various coding tasks relevant to communication science, often at
a fraction of the time and cost. Additionally, gLLMs can decode implicit
meanings and contextual information, be instructed using natural language,
deployed with only basic programming skills, and require little to no annotated
data beyond a validation dataset - constituting a paradigm shift in automated
content analysis. Despite their potential, the integration of gLLMs into the
methodological toolkit of communication research remains underdeveloped. In
gLLM-assisted quantitative content analysis, researchers must address at least
seven critical challenges that impact result quality: (1) codebook development,
(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)
iterative refinement, (6) validation of the model's reliability, and
optionally, (7) performance enhancement. This paper synthesizes emerging
research on gLLM-assisted quantitative content analysis and proposes a
comprehensive best-practice guide to navigate these challenges. Our goal is to
make gLLM-based content analysis more accessible to a broader range of
communication researchers and ensure adherence to established disciplinary
quality standards of validity, reliability, reproducibility, and research
ethics.

</details>


### [87] [Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins](https://arxiv.org/abs/2510.23882)
*Adil Rasheed,Oscar Ravik,Omer San*

Main category: cs.AI

TL;DR: 该研究比较了数字孪生中的四种预测模型（线性、物理建模、LSTM、混合建模）和三种控制策略（MPC、RL、LLM控制），发现在温室测试平台上，HAM模型在精度、泛化性和计算效率方面表现最均衡，而MPC控制器稳健，RL适应性强，LLM控制器提供灵活的人机交互。


<details>
  <summary>Details</summary>
Motivation: 研究数字孪生在动态系统建模和控制中的应用，整合物理基础、数据驱动和混合方法，比较传统和AI驱动控制器的性能差异。

Method: 使用微型温室作为测试平台，开发四种预测模型（线性、PBM、LSTM、HAM）和三种控制策略（MPC、RL、LLM控制），在插值和外推场景下进行比较评估。

Result: HAM模型在精度、泛化性和计算效率方面表现最均衡；LSTM精度高但资源消耗大；MPC控制器稳健可预测；RL控制器适应性强；LLM控制器与预测工具结合时提供灵活的人机交互。

Conclusion: HAM模型在建模方面提供最佳平衡性能，MPC控制器稳健，RL适应性强，LLM控制器在结合预测工具时实现灵活的人机交互，为数字孪生系统提供了实用的建模和控制方案。

Abstract: This work investigates the use of digital twins for dynamical system modeling
and control, integrating physics-based, data-driven, and hybrid approaches with
both traditional and AI-driven controllers. Using a miniature greenhouse as a
test platform, four predictive models Linear, Physics-Based Modeling (PBM),
Long Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are
developed and compared under interpolation and extrapolation scenarios. Three
control strategies Model Predictive Control (MPC), Reinforcement Learning (RL),
and Large Language Model (LLM) based control are also implemented to assess
trade-offs in precision, adaptability, and implementation effort. Results show
that in modeling HAM provides the most balanced performance across accuracy,
generalization, and computational efficiency, while LSTM achieves high
precision at greater resource cost. Among controllers, MPC delivers robust and
predictable performance, RL demonstrates strong adaptability, and LLM-based
controllers offer flexible human-AI interaction when coupled with predictive
tools.

</details>


### [88] [Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges](https://arxiv.org/abs/2510.23883)
*Shrestha Datta,Shahriar Kabir Nahin,Anshuman Chhabra,Prasant Mohapatra*

Main category: cs.AI

TL;DR: 本文调查了基于大语言模型的智能AI代理系统所面临的安全威胁，提出了威胁分类法，并讨论了评估方法和防御策略。


<details>
  <summary>Details</summary>
Motivation: 随着具备规划、工具使用、记忆和自主能力的AI代理系统在web、软件和物理环境中自主执行任务，它们带来了不同于传统AI安全和软件安全的新型安全风险，需要专门研究。

Method: 采用调查分析方法，构建了针对智能AI代理的威胁分类法，回顾了最近的基准测试和评估方法，并从技术和治理两个角度讨论防御策略。

Result: 系统梳理了当前研究现状，识别了智能AI代理特有的安全威胁类型，并总结了现有的评估和防御方法。

Conclusion: 强调了智能AI代理安全风险的特殊性，指出了开放挑战，旨在支持开发安全设计的智能代理系统。

Abstract: Agentic AI systems powered by large language models (LLMs) and endowed with
planning, tool use, memory, and autonomy, are emerging as powerful, flexible
platforms for automation. Their ability to autonomously execute tasks across
web, software, and physical environments creates new and amplified security
risks, distinct from both traditional AI safety and conventional software
security. This survey outlines a taxonomy of threats specific to agentic AI,
reviews recent benchmarks and evaluation methodologies, and discusses defense
strategies from both technical and governance perspectives. We synthesize
current research and highlight open challenges, aiming to support the
development of secure-by-design agent systems.

</details>


### [89] [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)
*Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.AI

TL;DR: 提出基于摊销变分推理的可扩展训练算法，通过多样性强化学习和贝叶斯推理缩放策略，提升大型视觉语言模型的推理能力、泛化性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的SFT、PPO和GRPO训练算法在未见推理任务上泛化能力不足，且过度依赖有偏的奖励模型，需要更有效的推理训练方法。

Method: 将LVLM推理重新表述为后验推断，采用摊销变分推理框架，结合多样性强化学习设计稀疏奖励函数，并使用贝叶斯推理缩放策略替代昂贵的Best-of-N和Beam Search。

Result: 在七个推理基准测试中，该方法显著提升了最先进LVLM模型的有效性、泛化性和可解释性。

Conclusion: 提出的基于变分推理的训练算法能够有效解决现有方法的局限性，为LVLM的推理能力提供了可扩展且可靠的训练方案。

Abstract: Chain-of-thought (CoT) reasoning is critical for improving the
interpretability and reliability of Large Vision-Language Models (LVLMs).
However, existing training algorithms such as SFT, PPO, and GRPO may not
generalize well across unseen reasoning tasks and heavily rely on a biased
reward model. To address this challenge, we reformulate reasoning in LVLMs as
posterior inference and propose a scalable training algorithm based on
amortized variational inference. By leveraging diversity-seeking reinforcement
learning algorithms, we introduce a novel sparse reward function for
token-level learning signals that encourage diverse, high-likelihood latent
CoT, overcoming deterministic sampling limitations and avoiding reward hacking.
Additionally, we implement a Bayesian inference-scaling strategy that replaces
costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank
optimal rationales and answers. We empirically demonstrate that the proposed
method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in
terms of effectiveness, generalization, and interpretability.

</details>


### [90] [Decentralized Causal Discovery using Judo Calculus](https://arxiv.org/abs/2510.23942)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 提出了一种基于直觉主义去中心化框架的因果发现理论——柔道演算，使用j-稳定因果推断和j-do演算在层拓扑中形式化处理因果效应的情境依赖性。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，因果效应往往依赖于具体情境（如年龄、国家、剂量、基因型等），需要形式化处理这种情境依赖性。

Method: 使用柔道演算，通过Lawvere-Tierney模态算子j选择相关情境，结合标准的基于分数、约束和梯度的因果发现方法。

Result: 实验结果显示，基于层理论的去中心化因果发现具有计算效率优势，且性能优于经典因果发现方法。

Conclusion: 柔道演算为处理情境依赖的因果发现提供了形式化框架，在计算效率和性能方面都表现出优势。

Abstract: We describe a theory and implementation of an intuitionistic decentralized
framework for causal discovery using judo calculus, which is formally defined
as j-stable causal inference using j-do-calculus in a topos of sheaves. In
real-world applications -- from biology to medicine and social science --
causal effects depend on regime (age, country, dose, genotype, or lab
protocol). Our proposed judo calculus formalizes this context dependence
formally as local truth: a causal claim is proven true on a cover of regimes,
not everywhere at once. The Lawvere-Tierney modal operator j chooses which
regimes are relevant; j-stability means the claim holds constructively and
consistently across that family. We describe an algorithmic and implementation
framework for judo calculus, combining it with standard score-based,
constraint-based, and gradient-based causal discovery methods. We describe
experimental results on a range of domains, from synthetic to real-world
datasets from biology and economics. Our experimental results show the
computational efficiency gained by the decentralized nature of sheaf-theoretic
causal discovery, as well as improved performance over classical causal
discovery methods.

</details>


### [91] [The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity](https://arxiv.org/abs/2510.23965)
*Aymane El Gadarri,Ali Aouad,Vivek F. Farias*

Main category: cs.AI

TL;DR: 提出了一种名为sign estimator的新方法，通过将交叉熵损失替换为二元分类损失，解决了传统LLM对齐方法在人类偏好异质性下的不一致性问题，实现了可证明的一致性和高效估计。


<details>
  <summary>Details</summary>
Motivation: 传统LLM对齐方法对人类偏好的异质性很敏感，使用朴素概率模型拟合成对比较数据会产生不一致的群体平均效用估计，这是社会福利的规范衡量标准。

Method: 提出sign estimator方法，在聚合步骤中用二元分类损失替换交叉熵损失，在温和假设下恢复一致的有序对齐，并在此设置中首次实现多项式有限样本误差界限。

Result: 在基于数字孪生的LLM对齐现实模拟中，sign estimator显著减少了模拟人物面板的偏好失真，将估计误差降低了近35%，与真实群体偏好的不一致性从12%降至8%。

Conclusion: 该方法优于明确建模用户异质性并需要跟踪个体级偏好数据的面板数据启发式方法，同时保持了现有LLM对齐管道的实现简单性。

Abstract: Traditional LLM alignment methods are vulnerable to heterogeneity in human
preferences. Fitting a na\"ive probabilistic model to pairwise comparison data
(say over prompt-completion pairs) yields an inconsistent estimate of the
population-average utility -a canonical measure of social welfare. We propose a
new method, dubbed the sign estimator, that provides a simple, provably
consistent, and efficient estimator by replacing cross-entropy with binary
classification loss in the aggregation step. This simple modification recovers
consistent ordinal alignment under mild assumptions and achieves the first
polynomial finite-sample error bounds in this setting. In realistic simulations
of LLM alignment using digital twins, the sign estimator substantially reduces
preference distortion over a panel of simulated personas, cutting (angular)
estimation error by nearly 35% and decreasing disagreement with true population
preferences from 12% to 8% compared to standard RLHF. Our method also compares
favorably to panel data heuristics that explicitly model user heterogeneity and
require tracking individual-level preference data-all while maintaining the
implementation simplicity of existing LLM alignment pipelines.

</details>


### [92] [Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance](https://arxiv.org/abs/2510.23989)
*Shangde Gao,Zelin Xu,Zhe Jiang*

Main category: cs.AI

TL;DR: 该研究提出了一种条件深度学习模型，通过整合个体的社会基础设施韧性(SIR)和空间上下文，来预测破坏性事件后个体移动模式的变化。


<details>
  <summary>Details</summary>
Motivation: 预测破坏性事件前个体移动模式变化具有挑战性，因为缺乏衡量个体异质性社会基础设施韧性的方法，传统特征难以大规模获取，且个体移动模式与空间上下文的复杂交互关系未被充分捕捉。

Method: 开发了一个条件深度学习模型，整合个体的社会基础设施韧性(SIR)和局部空间上下文，使用大规模稀疏的个体级数据来捕捉个体移动模式与空间环境的复杂关系。

Result: 实验表明，整合个体的SIR和空间上下文能够增强模型预测事件后个体移动模式的能力。条件模型能够捕捉到具有相似事件前移动模式但SIR不同的个体在移动模式上的差异变化。

Conclusion: 该研究证明了将个体社会基础设施韧性和空间上下文整合到深度学习模型中，可以有效预测破坏性事件后个体移动模式的变化，为理解个体行为对社区资源需求的影响提供了新视角。

Abstract: Shifts in individual movement patterns following disruptive events can reveal
changing demands for community resources. However, predicting such shifts
before disruptive events remains challenging for several reasons. First,
measures are lacking for individuals' heterogeneous social infrastructure
resilience (SIR), which directly influences their movement patterns, and
commonly used features are often limited or unavailable at scale, e.g.,
sociodemographic characteristics. Second, the complex interactions between
individual movement patterns and spatial contexts have not been sufficiently
captured. Third, individual-level movement may be spatially sparse and not
well-suited to traditional decision-making methods for movement predictions.
This study incorporates individuals' SIR into a conditioned deep learning model
to capture the complex relationships between individual movement patterns and
local spatial context using large-scale, sparse individual-level data. Our
experiments demonstrate that incorporating individuals' SIR and spatial context
can enhance the model's ability to predict post-event individual movement
patterns. The conditioned model can capture the divergent shifts in movement
patterns among individuals who exhibit similar pre-event patterns but differ in
SIR.

</details>


### [93] [Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling](https://arxiv.org/abs/2510.24013)
*İbrahim Oğuz Çetinkaya,İ. Esra Büyüktahtakın,Parshin Shojaee,Chandan K. Reddy*

Main category: cs.AI

TL;DR: 利用大型语言模型发现新的启发式算法来解决单机总延迟调度问题，提出了EDDC和MDDC两种算法，在大规模实例中表现优于传统启发式方法。


<details>
  <summary>Details</summary>
Motivation: 针对单机总延迟这一NP难组合优化问题，传统启发式方法性能有限，而精确方法在大规模实例中计算不可行，需要开发更有效的启发式算法。

Method: 利用大型语言模型发现新的启发式规则，开发了EDDC和MDDC算法，并与混合整数规划和动态规划等精确方法以及传统启发式方法进行对比评估。

Result: 在超过100个作业的大规模实例中，EDDC改进了经典EDD规则，MDDC始终优于传统启发式方法，在复杂实例中与精确方法保持竞争力。

Conclusion: 人机协作可以产生可扩展的高性能启发式算法，即使在资源有限的情况下，也能有效解决NP难的组合优化问题。

Abstract: Our study contributes to the scheduling and combinatorial optimization
literature with new heuristics discovered by leveraging the power of Large
Language Models (LLMs). We focus on the single-machine total tardiness (SMTT)
problem, which aims to minimize total tardiness by sequencing n jobs on a
single processor without preemption, given processing times and due dates. We
develop and benchmark two novel LLM-discovered heuristics, the EDD Challenger
(EDDC) and MDD Challenger (MDDC), inspired by the well-known Earliest Due Date
(EDD) and Modified Due Date (MDD) rules. In contrast to prior studies that
employed simpler rule-based heuristics, we evaluate our LLM-discovered
algorithms using rigorous criteria, including optimality gaps and solution time
derived from a mixed-integer programming (MIP) formulation of SMTT. We compare
their performance against state-of-the-art heuristics and exact methods across
various job sizes (20, 100, 200, and 500 jobs). For instances with more than
100 jobs, exact methods such as MIP and dynamic programming become
computationally intractable. Up to 500 jobs, EDDC improves upon the classic EDD
rule and another widely used algorithm in the literature. MDDC consistently
outperforms traditional heuristics and remains competitive with exact
approaches, particularly on larger and more complex instances. This study shows
that human-LLM collaboration can produce scalable, high-performing heuristics
for NP-hard constrained combinatorial optimization, even under limited
resources when effectively configured.

</details>


### [94] [OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2510.24028)
*Tingyue Pan,Mingyue Cheng,Shilong Zhang,Zhiding Liu,Xiaoyu Tao,Yucong Luo,Jintao Zhang,Qi Liu*

Main category: cs.AI

TL;DR: OneCast是一个结构化、模块化的跨域时间序列预测框架，通过将时间序列分解为季节性和趋势分量，分别使用轻量级投影模块和基于离散扩散的语义感知分词器进行建模，在多个领域实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决跨域时间序列预测中因领域特定趋势变化和不一致周期性模式导致的泛化能力不足问题，现有方法将时间序列视为未分化的序列，未能显式解耦其内在结构组件。

Method: 提出OneCast框架：1）将时间序列分解为季节性和趋势分量；2）季节性分量通过轻量级投影模块使用可解释基函数重建周期性模式；3）趋势分量通过语义感知分词器编码为段级离散标记，使用掩码离散扩散机制进行推断；4）两个分支输出结合生成最终预测。

Result: 在八个领域的广泛实验中，OneCast大多优于最先进的基线方法。

Conclusion: 通过显式解耦时间序列的结构组件并分别建模，OneCast能够有效捕捉季节性模式同时跟踪领域特定趋势，在跨域时间序列预测任务中表现出色。

Abstract: Cross-domain time series forecasting is a valuable task in various web
applications. Despite its rapid advancement, achieving effective generalization
across heterogeneous time series data remains a significant challenge. Existing
methods have made progress by extending single-domain models, yet often fall
short when facing domain-specific trend shifts and inconsistent periodic
patterns. We argue that a key limitation lies in treating temporal series as
undifferentiated sequence, without explicitly decoupling their inherent
structural components. To address this, we propose OneCast, a structured and
modular forecasting framework that decomposes time series into seasonal and
trend components, each modeled through tailored generative pathways.
Specifically, the seasonal component is captured by a lightweight projection
module that reconstructs periodic patterns via interpretable basis functions.
In parallel, the trend component is encoded into discrete tokens at segment
level via a semantic-aware tokenizer, and subsequently inferred through a
masked discrete diffusion mechanism. The outputs from both branches are
combined to produce a final forecast that captures seasonal patterns while
tracking domain-specific trends. Extensive experiments across eight domains
demonstrate that OneCast mostly outperforms state-of-the-art baselines.

</details>


### [95] [LLMLogAnalyzer: A Clustering-Based Log Analysis Chatbot using Large Language Models](https://arxiv.org/abs/2510.24031)
*Peng Cai,Reza Ryan,Nickson M. Karie*

Main category: cs.AI

TL;DR: LLMLogAnalyzer是一个基于聚类的日志分析聊天机器人，结合大语言模型和机器学习算法，简化日志分析流程，在多个任务上比现有LLM聊天机器人性能提升39%-68%。


<details>
  <summary>Details</summary>
Motivation: 系统日志是网络安全的核心，但分析大量多样化日志数据面临高成本、缺乏专业知识和时间限制等挑战，许多组织难以进行基本分析。

Method: 采用模块化架构，包括路由器、日志识别器、日志解析器和搜索工具，结合聚类技术和大语言模型，解决LLM的上下文窗口限制和结构化文本处理能力差的问题。

Result: 在四个不同领域日志和各种任务上的评估显示，相比ChatGPT、ChatPDF和NotebookLM等最先进的LLM聊天机器人，性能显著提升39%-68%，鲁棒性增强，使用ROUGE-1分数时四分位距减少93%。

Conclusion: 该框架通过增强LLM在结构化文本分析方面的能力，提高了准确性和鲁棒性，为网络安全专家和非技术用户提供了有价值的资源。

Abstract: System logs are a cornerstone of cybersecurity, supporting proactive breach
prevention and post-incident investigations. However, analyzing vast amounts of
diverse log data remains significantly challenging, as high costs, lack of
in-house expertise, and time constraints make even basic analysis difficult for
many organizations. This study introduces LLMLogAnalyzer, a clustering-based
log analysis chatbot that leverages Large Language Models (LLMs) and Machine
Learning (ML) algorithms to simplify and streamline log analysis processes.
This innovative approach addresses key LLM limitations, including context
window constraints and poor structured text handling capabilities, enabling
more effective summarization, pattern extraction, and anomaly detection tasks.
LLMLogAnalyzer is evaluated across four distinct domain logs and various tasks.
Results demonstrate significant performance improvements over state-of-the-art
LLM-based chatbots, including ChatGPT, ChatPDF, and NotebookLM, with consistent
gains ranging from 39% to 68% across different tasks. The system also exhibits
strong robustness, achieving a 93% reduction in interquartile range (IQR) when
using ROUGE-1 scores, indicating significantly lower result variability. The
framework's effectiveness stems from its modular architecture comprising a
router, log recognizer, log parser, and search tools. This design enhances LLM
capabilities for structured text analysis while improving accuracy and
robustness, making it a valuable resource for both cybersecurity experts and
non-technical users.

</details>


### [96] [Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach](https://arxiv.org/abs/2510.24085)
*Md. Shihab Uddin,Md Nazmus Shakib,Rahul Bhadani*

Main category: cs.AI

TL;DR: 比较经典模型和机器学习模型在电动汽车跟车行为预测中的表现，发现随机森林模型在所有场景下都优于物理模型。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车普及，需要理解其驾驶行为以提升交通安全和开发智能驾驶系统。

Method: 使用IDM、OVM、OVRV、CACC等经典物理模型和随机森林回归器，基于真实世界数据集进行参数校准和预测。

Result: 随机森林模型表现最佳，RMSE分别为0.0046（中等间距）、0.0016（长间距）和0.0025（超长间距）；经典模型中CACC表现最好，长间距RMSE为2.67。

Conclusion: 机器学习模型在预测电动汽车跟车行为方面优于经典物理模型，对模拟EV行为和混合自动驾驶交通动态分析具有重要价值。

Abstract: The increasing adoption of electric vehicles (EVs) necessitates an
understanding of their driving behavior to enhance traffic safety and develop
smart driving systems. This study compares classical and machine learning
models for EV car following behavior. Classical models include the Intelligent
Driver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative
Velocity (OVRV), and a simplified CACC model, while the machine learning
approach employs a Random Forest Regressor. Using a real world dataset of an EV
following an internal combustion engine (ICE) vehicle under varied driving
conditions, we calibrated classical model parameters by minimizing the RMSE
between predictions and real data. The Random Forest model predicts
acceleration using spacing, speed, and gap type as inputs. Results demonstrate
the Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),
0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,
CACC performed best, with an RMSE of 2.67 for long gaps. These findings
highlight the machine learning model's performance across all scenarios. Such
models are valuable for simulating EV behavior and analyzing mixed autonomy
traffic dynamics in EV integrated environments.

</details>


### [97] [HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology](https://arxiv.org/abs/2510.24115)
*Sandeep Vissapragada,Vikrant Sahu,Gagan Raj Gupta,Vandita Singh*

Main category: cs.AI

TL;DR: 开发了HistoLens系统，这是一个透明、可解释的AI助手，让病理学家能够用自然语言提问并获得带有视觉证明的诊断报告。


<details>
  <summary>Details</summary>
Motivation: 为了让医生真正信任AI，需要打破AI的黑箱特性，使其推理过程像咨询同事一样透明可理解。

Method: 创建了HistoLens系统，能够将病理学家的自然语言问题翻译为精确查询，生成结构化报告，并提供热力图形式的视觉证明来展示AI分析所用的具体细胞和区域。

Result: 系统能够专注于患者组织，忽略背景噪声，让病理学家保持专家主导地位，使用可信的AI助手验证见解并做出更快、更自信的诊断。

Conclusion: HistoLens成功实现了透明协作的AI伙伴模式，增强了医生对AI的信任，提高了诊断效率和信心。

Abstract: For doctors to truly trust artificial intelligence, it can't be a black box.
They need to understand its reasoning, almost as if they were consulting a
colleague. We created HistoLens1 to be that transparent, collaborative partner.
It allows a pathologist to simply ask a question in plain English about a
tissue slide--just as they would ask a trainee. Our system intelligently
translates this question into a precise query for its AI engine, which then
provides a clear, structured report. But it doesn't stop there. If a doctor
ever asks, "Why?", HistoLens can instantly provide a 'visual proof' for any
finding--a heatmap that points to the exact cells and regions the AI used for
its analysis. We've also ensured the AI focuses only on the patient's tissue,
just like a trained pathologist would, by teaching it to ignore distracting
background noise. The result is a workflow where the pathologist remains the
expert in charge, using a trustworthy AI assistant to verify their insights and
make faster, more confident diagnoses.

</details>


### [98] [From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems](https://arxiv.org/abs/2510.24145)
*Yu Luo,Jiamin Jiang,Jingfei Feng,Lei Tao,Qingliang Zhang,Xidao Wen,Yongqian Sun,Shenglin Zhang,Jielong Huang,Nan Qi,Dan Pei*

Main category: cs.AI

TL;DR: OpsAgent是一个轻量级、自演进的多智能体系统，用于云系统的事件管理，通过免训练数据处理器将异构可观测数据转换为结构化文本描述，并使用多智能体协作框架实现透明可审计的诊断推理。


<details>
  <summary>Details</summary>
Motivation: 传统手动事件管理在处理大规模异构可观测数据时劳动密集且容易出错，现有自动化方法存在跨系统泛化能力差、可解释性有限和部署成本高等问题，阻碍了实际应用。

Method: 采用免训练数据处理器处理异构可观测数据，构建多智能体协作框架进行诊断推理，并引入双自演进机制（内部模型更新和外部经验积累）实现持续能力增长。

Result: 在OPENRCA基准测试中表现出最先进的性能，证明OpsAgent具有可泛化、可解释、成本效益高和自演进的特点。

Conclusion: OpsAgent是一个实际可部署且可持续的解决方案，适用于真实云系统的长期运维。

Abstract: Incident management (IM) is central to the reliability of large-scale cloud
systems. Yet manual IM, where on-call engineers examine metrics, logs, and
traces is labor-intensive and error-prone in the face of massive and
heterogeneous observability data. Existing automated IM approaches often
struggle to generalize across systems, provide limited interpretability, and
incur high deployment costs, which hinders adoption in practice. In this paper,
we present OpsAgent, a lightweight, self-evolving multi-agent system for IM
that employs a training-free data processor to convert heterogeneous
observability data into structured textual descriptions, along with a
multi-agent collaboration framework that makes diagnostic inference transparent
and auditable. To support continual capability growth, OpsAgent also introduces
a dual self-evolution mechanism that integrates internal model updates with
external experience accumulation, thereby closing the deployment loop.
Comprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art
performance and show that OpsAgent is generalizable, interpretable,
cost-efficient, and self-evolving, making it a practically deployable and
sustainable solution for long-term operation in real-world cloud systems.

</details>


### [99] [BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data](https://arxiv.org/abs/2510.24151)
*Bingsen Qiu,Zijian Liu,Xiao Liu,Haoshen Yang,Zeren Gao,Bingjie Wang,Feier Zhang,Yixuan Qin,Chunyan Li*

Main category: cs.AI

TL;DR: 提出自动化框架生成高难度多跳问答数据集，解决训练数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 现有评估数据集不适合监督微调或强化学习，且人工构建多跳问题成本高昂，形成训练高能力检索推理代理的数据瓶颈

Method: 从半结构化知识源自动生成多跳问题：通过NLI关系分类和多样性扩展构建证据簇；应用反向问题构建创建模糊线索；使用多模型共识过滤和结构化约束分解进行质量评估

Result: 开发出可扩展流程，生成复杂、检索抵抗但可验证的问题，适用于SFT/RL训练和挑战性评估

Conclusion: 该框架显著减少人工标注工作量，同时保持强评估基准的难度特征

Abstract: Building training-ready multi-hop question answering (QA) datasets that truly
stress a model's retrieval and reasoning abilities remains highly challenging
recently. While there have been a few recent evaluation datasets that capture
the characteristics of hard-to-search but easy-to-verify problems -- requiring
the integration of ambiguous, indirect, and cross-domain cues -- these data
resources remain scarce and are mostly designed for evaluation, making them
unsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).
Meanwhile, manually curating non-trivially retrievable questions -- where
answers cannot be found through a single direct query but instead require
multi-hop reasoning over oblique and loosely connected evidence -- incurs
prohibitive human costs and fails to scale, creating a critical data bottleneck
for training high-capability retrieval-and-reasoning agents.
  To address this, we present an automated framework for generating
high-difficulty, training-ready multi-hop questions from semi-structured
knowledge sources. The system (i) grows diverse, logically labeled evidence
clusters through Natural Language Inference (NLI)-based relation typing and
diversity-aware expansion; (ii) applies reverse question construction to
compose oblique cues so that isolated signals are underinformative but their
combination uniquely identifies the target entity; and (iii) enforces quality
with a two-step evaluation pipeline that combines multi-model consensus
filtering with structured constraint decomposition and evidence-based matching.
The result is a scalable process that yields complex, retrieval-resistant yet
verifiable questions suitable for SFT/RL training as well as challenging
evaluation, substantially reducing human curation effort while preserving the
difficulty profile of strong evaluation benchmarks.

</details>


### [100] [BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning](https://arxiv.org/abs/2510.24161)
*Wentao Tan,Bowen Wang,Heng Zhi,Chenyu Liu,Zhe Li,Jian Liu,Zengrong Lin,Yukun Dai,Yipeng Chen,Wenjie Yang,Enci Xie,Hao Xue,Baixu Ji,Chen Xu,Zhibin Wang,Tianshi Wang,Lei Zhu,Heng Tao Shen*

Main category: cs.AI

TL;DR: BLM₁是一个多模态空间基础模型，通过两阶段训练实现跨空间传输、跨任务学习和跨具身泛化，在数字和物理任务中都优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在数字-物理空间和具身智能体间泛化能力差，VLAs缺乏高级推理能力，ELLMs局限于数字空间，需要统一的跨空间、跨具身模型。

Method: 两阶段训练：阶段I通过数字语料注入具身知识，阶段II训练策略模块通过意图桥接接口从MLLM提取高级语义指导控制，不微调MLLM主干。

Result: 在数字和物理基准测试中，单个BLM₁实例优于MLLMs、ELLMs、VLAs和GMLMs四类模型，数字任务提升约6%，物理任务提升约3%。

Conclusion: BLM₁成功实现了跨空间、跨任务和跨具身的统一模型，为具身智能提供了有效的解决方案。

Abstract: Multimodal large language models (MLLMs) have advanced vision-language
reasoning and are increasingly deployed in embodied agents. However,
significant limitations remain: MLLMs generalize poorly across digital-physical
spaces and embodiments; vision-language-action models (VLAs) produce low-level
actions yet lack robust high-level embodied reasoning; and most embodied large
language models (ELLMs) are constrained to digital-space with poor
generalization to the physical world. Thus, unified models that operate
seamlessly across digital and physical spaces while generalizing across
embodiments and tasks remain absent. We introduce the \textbf{Boundless Large
Model (BLM$_1$)}, a multimodal spatial foundation model that preserves
instruction following and reasoning, incorporates embodied knowledge, and
supports robust cross-embodiment control. BLM$_1$ integrates three key
capabilities -- \textit{cross-space transfer, cross-task learning, and
cross-embodiment generalization} -- via a two-stage training paradigm. Stage I
injects embodied knowledge into the MLLM through curated digital corpora while
maintaining language competence. Stage II trains a policy module through an
intent-bridging interface that extracts high-level semantics from the MLLM to
guide control, without fine-tuning the MLLM backbone. This process is supported
by a self-collected cross-embodiment demonstration suite spanning four robot
embodiments and six progressively challenging tasks. Evaluations across digital
and physical benchmarks show that a single BLM$_1$ instance outperforms four
model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving
$\sim\!\textbf{6%}$ gains in digital tasks and $\sim\!\textbf{3%}$ in physical
tasks.

</details>


### [101] [UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle Decision-Making Systems via Multi-Dataset Integration](https://arxiv.org/abs/2510.24166)
*Xin Yang,Yuhang Zhang,Wei Li,Xin Lin,Wenbin Zou,Chen Xu*

Main category: cs.AI

TL;DR: 提出了UniPlanner框架，通过多数据集集成解决自动驾驶运动规划的鲁棒性问题，包含三个创新组件：历史-未来轨迹字典网络、梯度自由轨迹映射器和稀疏到密集范式。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法局限于单数据集训练，限制了规划系统的鲁棒性。研究发现不同数据集中的车辆轨迹分布和历史-未来相关性具有显著一致性，这为多数据集集成提供了基础。

Method: 1. HFTDN：从多数据集聚合历史-未来轨迹对，基于历史轨迹相似性检索相关未来轨迹生成跨数据集规划指导
2. GFTM：从多数据集学习鲁棒的历史-未来相关性，将历史轨迹转换为通用规划先验，梯度自由设计防止捷径学习
3. S2D：训练时选择性抑制规划先验实现鲁棒学习，推理时充分利用先验最大化规划性能

Result: UniPlanner实现了跨数据集的统一学习，能够生成更安全、更高效的轨迹规划，提升了自动驾驶决策系统的鲁棒性。

Conclusion: 该研究证明了多数据集集成在自动驾驶运动规划中的可行性和有效性，UniPlanner框架为提升规划系统的泛化能力和鲁棒性提供了新的解决方案。

Abstract: Motion planning is a critical component of autonomous vehicle decision-making
systems, directly determining trajectory safety and driving efficiency. While
deep learning approaches have advanced planning capabilities, existing methods
remain confined to single-dataset training, limiting their robustness in
planning.
  Through systematic analysis, we discover that vehicular trajectory
distributions and history-future correlations demonstrate remarkable
consistency across different datasets. Based on these findings, we propose
UniPlanner, the first planning framework designed for multi-dataset integration
in autonomous vehicle decision-making. UniPlanner achieves unified
cross-dataset learning through three synergistic innovations.
  First, the History-Future Trajectory Dictionary Network (HFTDN) aggregates
history-future trajectory pairs from multiple datasets, using historical
trajectory similarity to retrieve relevant futures and generate cross-dataset
planning guidance.
  Second, the Gradient-Free Trajectory Mapper (GFTM) learns robust
history-future correlations from multiple datasets, transforming historical
trajectories into universal planning priors. Its gradient-free design ensures
the introduction of valuable priors while preventing shortcut learning, making
the planning knowledge safely transferable. Third, the Sparse-to-Dense (S2D)
paradigm implements adaptive dropout to selectively suppress planning priors
during training for robust learning, while enabling full prior utilization
during inference to maximize planning performance.

</details>


### [102] [MGA: Memory-Driven GUI Agent for Observation-Centric Interaction](https://arxiv.org/abs/2510.24168)
*Weihua Cheng,Ersheng Ni,Wenlong Wang,Yifei Sun,Junming Liu,Wangyu Shen,Yirong Chen,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: 提出了Memory-Driven GUI Agent (MGA)，采用"先观察后决策"原则，通过当前截图、空间信息和动态结构化记忆的三元组表示环境状态，在GUI交互任务中显著提升了鲁棒性、泛化性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理存在两个主要问题：对历史轨迹的依赖导致错误传播放大，以及"先决策后观察"机制导致的局部探索偏差，忽视了关键界面线索。

Method: MGA将每个步骤建模为独立的环境状态，使用三元组表示：当前截图、任务无关的空间信息和动态更新的结构化记忆，遵循"先观察后决策"原则。

Result: 在OSworld基准测试、真实桌面应用（Chrome、VSCode、VLC）和跨任务迁移实验中，MGA相比最先进的基线方法在鲁棒性、泛化性和效率方面取得了显著提升。

Conclusion: MGA通过重构GUI交互范式为"先观察后决策"，并引入动态结构化记忆机制，有效解决了现有方法的局限性，为GUI代理的发展提供了新方向。

Abstract: The rapid progress of Large Language Models (LLMs) and their multimodal
extensions (MLLMs) has enabled agentic systems capable of perceiving and acting
across diverse environments. A challenging yet impactful frontier is the
development of GUI agents, which must navigate complex desktop and web
interfaces while maintaining robustness and generalization. Existing paradigms
typically model tasks as long-chain executions, concatenating historical
trajectories into the context. While approaches such as Mirage and GTA1 refine
planning or introduce multi-branch action selection, they remain constrained by
two persistent issues: Dependence on historical trajectories, which amplifies
error propagation. And Local exploration bias, where "decision-first,
observation-later" mechanisms overlook critical interface cues. We introduce
the Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the
principle of observe first, then decide. MGA models each step as an
independent, context-rich environment state represented by a triad: current
screenshot, task-agnostic spatial information, and a dynamically updated
structured memory. Experiments on OSworld benchmarks, real desktop applications
(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves
substantial gains in robustness, generalization, and efficiency compared to
state-of-the-art baselines. The code is publicly available at:
{https://anonymous.4open.science/r/MGA-3571}.

</details>


### [103] [MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools](https://arxiv.org/abs/2510.24284)
*Wenhao Wang,Peizhi Niu,Zhao Xu,Zhaoyu Chen,Jian Du,Yaxin Du,Xianghe Pang,Keduan Huang,Yanfeng Wang,Qiang Yan,Siheng Chen*

Main category: cs.AI

TL;DR: MCP-Flow是一个自动化网络代理驱动的管道，用于大规模服务器发现、数据合成和模型训练，旨在提升LLM在MCP生态系统中的工具使用能力。


<details>
  <summary>Details</summary>
Motivation: 现有MCP研究覆盖服务器数量有限，依赖昂贵的手动整理，缺乏训练支持，阻碍了在实际部署中的进展。

Method: 通过自动化流程从1166个服务器和11536个工具中收集和过滤数据，生成68733个高质量指令-函数调用对和6439个轨迹。

Result: 实验证明MCP-Flow在工具选择、函数调用生成和代理任务性能方面表现优异，远超先前工作的规模和多样性。

Conclusion: MCP-Flow为提升LLM代理在真实世界MCP环境中的熟练度提供了可扩展的基础。

Abstract: Large Language Models (LLMs) increasingly rely on external tools to perform
complex, realistic tasks, yet their ability to utilize the rapidly expanding
Model Contextual Protocol (MCP) ecosystem remains limited. Existing MCP
research covers few servers, depends on costly manual curation, and lacks
training support, hindering progress toward real-world deployment. To overcome
these limitations, we introduce MCP-Flow, an automated web-agent-driven
pipeline for large-scale server discovery, data synthesis, and model training.
MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing
68733 high-quality instruction-function call pairs and 6439 trajectories, far
exceeding prior work in scale and diversity. Extensive experiments demonstrate
MCP-Flow's effectiveness in driving superior MCP tool selection, function-call
generation, and enhanced agentic task performance. MCP-Flow thus provides a
scalable foundation for advancing LLM agents' proficiency in real-world MCP
environments. MCP-Flow is publicly available at
\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.

</details>


### [104] [Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms](https://arxiv.org/abs/2510.24297)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 本文针对MCTS中抽象节点内多个动作具有相同UCB值的问题，提出了几种替代随机平局规则的内部抽象策略，并证明其中多数策略在大多数环境和参数设置下优于随机策略。


<details>
  <summary>Details</summary>
Motivation: MCTS的样本效率问题可以通过状态/动作抽象来解决，但现有抽象算法（如pruned OGA）在多个动作属于同一抽象节点时，由于UCB值相同而需要平局规则，目前仅使用随机平局规则，存在改进空间。

Method: 提出并实证评估了多种内部抽象策略（intra-abstraction policies），作为随机平局规则的替代方案。

Result: 实验结果表明，提出的多种内部抽象策略在大多数环境和参数设置下表现优于随机策略。

Conclusion: 通过改进抽象节点内部的平局规则，可以显著提升MCTS抽象算法的性能，为MCTS的样本效率问题提供了更有效的解决方案。

Abstract: One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which
can be addressed by building and using state and/or action abstractions in
parallel to the tree search such that information can be shared among nodes of
the same layer. The primary usage of abstractions for MCTS is to enhance the
Upper Confidence Bound (UCB) value during the tree policy by aggregating visits
and returns of an abstract node. However, this direct usage of abstractions
does not take the case into account where multiple actions with the same parent
might be in the same abstract node, as these would then all have the same UCB
value, thus requiring a tiebreak rule. In state-of-the-art abstraction
algorithms such as pruned On the Go Abstractions (pruned OGA), this case has
not been noticed, and a random tiebreak rule was implicitly chosen. In this
paper, we propose and empirically evaluate several alternative
intra-abstraction policies, several of which outperform the random policy
across a majority of environments and parameter settings.

</details>


### [105] [Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank](https://arxiv.org/abs/2510.24299)
*Jiayu Liu,Wei Dai,Zhenya Huang,Ning Miao,Enhong Chen*

Main category: cs.AI

TL;DR: 提出了一种基于LLM内部行为的自我指示方法，通过计算输入问题与输出推理路径的相关矩阵秩来判断推理正确性，无需额外训练或复杂提示。


<details>
  <summary>Details</summary>
Motivation: 现有检查方法依赖外部资源（如训练验证器或复杂提示），计算开销大且仅适用于特定领域，需要更高效通用的检查方法。

Method: 利用LLM内部行为，通过计算输入问题与输出推理路径的相关矩阵秩作为推理正确性指标，设计自指示方法对候选推理路径进行重加权。

Result: 在多个不同规模和家族的LLM上验证有效，区分正确与错误推理路径的准确率超过75%，在三个推理基准上的准确率提升超过8%。

Conclusion: LLM内部行为已隐含其推理路径的可信度，提出的自指示方法简单、即插即用，显著优于其他投票和验证方法，计算开销极小。

Abstract: Despite the strong reasoning ability of large language models~(LLMs), they
are prone to errors and hallucinations. As a result, how to check their outputs
effectively and efficiently has become a critical problem in their
applications. Existing checking methods heavily rely on external resources,
such as trained verifiers (e.g., process/outcome reward models) or elaborate
prompts, which lead to high computational overhead and are only applicable to
specific domains. In this paper, we investigate whether the internal behaviors
of LLMs have already implied the credibility of their reasoning paths.
Specifically, we find that the rank of the correlation matrix between the input
problem and the output reasoning path is a robust indicator of reasoning
correctness. Different from other correctness indicators for LLMs, the
calculation of the correlation matrix only relies on the LLM itself, which
avoids the hassle of training a separate model or designing complicated
prompts. Based on it, we design a simple, plug-and-play Self-Indicator method
to reweight candidate reasoning paths, which achieves significant performance
improvements than other voting and verification methods with very few
computational overhead. Our experiments across multiple LLMs of varying scales
and model families have further shown the effectiveness of Self-Indicator. It
achieves over 75% accuracy in distinguishing correct reasoning paths from
incorrect ones, and, in turn, improves the accuracies on three reasoning
benchmarks by more than 8%.

</details>


### [106] [Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting](https://arxiv.org/abs/2510.24303)
*Deniz Gorur,Antoni Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 提出了一种用于判断性预测的多智能体框架，通过不同智能体对声明真实性产生分歧并收集正反证据，使用定量双极论证框架表示，实验表明多智能体组合能提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 将判断性预测视为声明验证任务，需要评估未来事件的可能性，传统方法缺乏多视角证据整合和可解释性。

Method: 设计多智能体框架，包含ArgLLM、RbAM和RAG-ArgLLM三种基于大语言模型的智能体，分别采用不同方法生成和评估定量双极论证框架。

Result: 在标准判断性预测数据集上的实验显示，特别是三个智能体组合时，能显著提高预测准确性，并提供可解释的证据组合。

Conclusion: 多智能体框架能有效整合不同证据源，提高判断性预测的准确性和可解释性，为声明验证提供新方法。

Abstract: Judgmental forecasting is the task of making predictions about future events
based on human judgment. This task can be seen as a form of claim verification,
where the claim corresponds to a future event and the task is to assess the
plausibility of that event. In this paper, we propose a novel multi-agent
framework for claim verification, whereby different agents may disagree on
claim veracity and bring specific evidence for and against the claims,
represented as quantitative bipolar argumentation frameworks (QBAFs). We then
instantiate the framework for supporting claim verification, with a variety of
agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an
existing approach for claim verification that generates and evaluates QBAFs;
(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)
from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,
extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of
arguments from external sources. Finally, we conduct experiments with two
standard judgmental forecasting datasets, with instances of our framework with
two or three agents, empowered by six different base LLMs. We observe that
combining evidence from agents can improve forecasting accuracy, especially in
the case of three agents, while providing an explainable combination of
evidence for claim verification.

</details>


### [107] [VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation](https://arxiv.org/abs/2510.24339)
*Yunxuan Jiang,Silan Hu,Xiaoning Wang,Yuanyuan Zhang,Xiangyu Chang*

Main category: cs.AI

TL;DR: VDSAgents是一个基于PCS原则的多智能体系统，用于提升LLM驱动数据科学系统的可信度和鲁棒性，在多个数据集上优于现有端到端系统。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的数据科学系统仅依赖模型内部推理，缺乏科学和理论原则指导，在处理噪声和复杂现实数据集时可信度和鲁棒性不足。

Method: 基于PCS原则构建多智能体系统，采用模块化工作流处理数据清洗、特征工程、建模和评估，每个阶段由专门智能体负责，结合扰动分析、单元测试和模型验证。

Result: 在9个不同特征的数据集上评估，使用DeepSeek-V3和GPT-4o作为后端，VDSAgents持续优于AutoKaggle和DataInterpreter等最先进端到端系统。

Conclusion: 将PCS原则嵌入LLM驱动数据科学自动化是可行的，能显著提升系统性能。

Abstract: Large language models (LLMs) become increasingly integrated into data science
workflows for automated system design. However, these LLM-driven data science
systems rely solely on the internal reasoning of LLMs, lacking guidance from
scientific and theoretical principles. This limits their trustworthiness and
robustness, especially when dealing with noisy and complex real-world datasets.
This paper provides VDSAgents, a multi-agent system grounded in the
Predictability-Computability-Stability (PCS) principles proposed in the
Veridical Data Science (VDS) framework. Guided by PCS principles, the system
implements a modular workflow for data cleaning, feature engineering, modeling,
and evaluation. Each phase is handled by an elegant agent, incorporating
perturbation analysis, unit testing, and model validation to ensure both
functionality and scientific auditability. We evaluate VDSAgents on nine
datasets with diverse characteristics, comparing it with state-of-the-art
end-to-end data science systems, such as AutoKaggle and DataInterpreter, using
DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the
results of AutoKaggle and DataInterpreter, which validates the feasibility of
embedding PCS principles into LLM-driven data science automation.

</details>


### [108] [A Unified Geometric Space Bridging AI Models and the Human Brain](https://arxiv.org/abs/2510.24342)
*Silin Chen,Yuzhong Chen,Zifan Wang,Junhao Wang,Zifeng Jia,Keith M Kendrick,Tuo Zhang,Lin Zhao,Dezhong Yao,Tianming Liu,Xi Jiang*

Main category: cs.AI

TL;DR: 本文提出了"类脑空间"概念，这是一个统一的几何空间，可以将任何AI模型的内在空间注意力拓扑组织映射到人类功能脑网络上，实现跨模态、跨任务的模型比较。


<details>
  <summary>Details</summary>
Motivation: 现有的大脑-AI对齐研究局限于特定输入和任务，缺乏比较不同模态AI模型内在组织的统一框架。

Method: 通过分析151个基于Transformer的模型，将模型的内在空间注意力拓扑组织映射到标准人类功能脑网络上，构建统一的类脑空间。

Result: 发现模型在类脑空间中呈现连续的弧形几何结构，反映脑相似度的渐变；模型分布模式受预训练范式和位置编码方案影响。

Conclusion: 类脑空间为跨领域智能的定位、量化和比较提供了首个统一框架，揭示了机器与大脑之间的深层组织原则。

Abstract: For decades, neuroscientists and computer scientists have pursued a shared
ambition: to understand intelligence and build it. Modern artificial neural
networks now rival humans in language, perception, and reasoning, yet it is
still largely unknown whether these artificial systems organize information as
the brain does. Existing brain-AI alignment studies have shown the striking
correspondence between the two systems, but such comparisons remain bound to
specific inputs and tasks, offering no common ground for comparing how AI
models with different kinds of modalities-vision, language, or multimodal-are
intrinsically organized. Here we introduce a groundbreaking concept of
Brain-like Space: a unified geometric space in which every AI model can be
precisely situated and compared by mapping its intrinsic spatial attention
topological organization onto canonical human functional brain networks,
regardless of input modality, task, or sensory domain. Our extensive analysis
of 151 Transformer-based models spanning state-of-the-art large vision models,
large language models, and large multimodal models uncovers a continuous
arc-shaped geometry within this space, reflecting a gradual increase of
brain-likeness; different models exhibit distinct distribution patterns within
this geometry associated with different degrees of brain-likeness, shaped not
merely by their modality but by whether the pretraining paradigm emphasizes
global semantic abstraction and whether the positional encoding scheme
facilitates deep fusion across different modalities. Moreover, the degree of
brain-likeness for a model and its downstream task performance are not
"identical twins". The Brain-like Space provides the first unified framework
for situating, quantifying, and comparing intelligence across domains,
revealing the deep organizational principles that bridge machines and the
brain.

</details>


### [109] [Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion](https://arxiv.org/abs/2510.24390)
*Xianjun Gao,Jianchun Liu,Hongli Xu,Liusheng Huang*

Main category: cs.AI

TL;DR: Orion是一个高效推理框架，通过依赖感知的查询分解和逻辑并行内容扩展，解决了LLM在实时Web应用中的延迟和吞吐量瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理存在计算效率低下的顺序生成和僵化推理策略问题，无法同时满足Web服务对高质量复杂推理和低延迟高吞吐量的双重需求。

Method: Orion将查询推理分解为两个协同阶段：关键点生成（通过检索增强的少样本提示提取逻辑结构化的关键点）和内容并行扩展（基于依赖图并行扩展内容以确保逻辑一致性），并引入流水线调度机制实现跨查询并行。

Result: 在多样化基准测试中，Orion相比基线实现了最高4.33倍的token生成速度提升、3.42倍的答案延迟降低，并通过显式建模点间依赖关系将推理质量提升最高18.75%。

Conclusion: Orion框架成功平衡了LLM推理的效率和质量，为实时Web应用提供了可行的解决方案，显著提升了推理性能和逻辑一致性。

Abstract: The integration of Large Language Models (LLMs) into real-time Web
applications, such as AI-powered search and conversational agents, presents a
fundamental Web infrastructure challenge: reconciling the demand for
high-quality, complex reasoning with the stringent low-latency and
high-throughput requirements of interactive services. Current LLM reasoning,
hindered by computationally inefficient sequential generation and rigid
reasoning strategies, creates a critical bottleneck for the Web services.
Existing approaches typically optimize the LLM reasoning for either efficiency
or quality but struggle to achieve both, and thus fail to meet the dual
requirements of modern Web platforms. To overcome these limitations, we propose
Orion, a novel and efficient reasoning framework that enables dependency-aware
query decomposition and logic-parallel content expansion. Concretely, Orion
decomposes a single query reasoning process into two synergistic phases: (1)
\textit{key point generation}, which distills logically structured key points
through retrieval-augmented few-shot prompting, and (2) \textit{content
parallel expansion}, which concurrently elaborates on these points based on a
dependency graph to ensure logical consistency. Furthermore, Orion introduces a
pipeline scheduling mechanism that exploits the complementary computational
characteristics of the two phases (generation imposes pressure on GPU computing
and expansion stresses on GPU memory) across multiple queries, enabling
cross-query parallelism and dramatically improving reasoning performance (\ie,
efficiency and quality). Experiments on diverse benchmarks show that Orion not
only delivers up to 4.33x higher token generation speed and 3.42x lower answer
latency over the baselines but also improves reasoning quality by up to 18.75%
through explicitly modeling inter-point dependencies.

</details>


### [110] [APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training](https://arxiv.org/abs/2510.24397)
*Jiarui Qin,Yunjia Xi,Junjie Huang,Renting Rui,Di Yin,Weiwen Liu,Yong Yu,Weinan Zhang,Xing Sun*

Main category: cs.AI

TL;DR: 提出了APTBench框架，将真实世界智能体任务转化为适合基础模型评估的选择题或文本补全问题，用于在预训练阶段评估模型作为智能体的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前预训练基准主要关注孤立静态技能，无法反映模型的智能体能力；而智能体基准通常针对后训练模型，基础模型难以支持多轮任务执行。需要能在预训练阶段评估智能体潜力的基准。

Method: 将真实世界智能体任务和成功轨迹转化为选择题或文本补全问题，聚焦规划和行动等核心智能体能力，覆盖软件工程和深度研究等关键场景。

Result: 相比现有通用基准，APTBench能更准确地预测模型作为智能体的下游性能，同时比后训练的端到端智能体评估更轻量、成本更低。

Conclusion: APTBench填补了预训练阶段智能体能力评估的空白，为更有效地指导模型训练提供了解决方案。

Abstract: With the rapid development of LLM-based agents, there is a growing trend to
incorporate agent-specific data into the pre-training stage of LLMs, aiming to
better align LLMs with real-world autonomous task execution. However, current
pre-training benchmarks primarily focus on isolated and static skills, e.g.,
common knowledge or mathematical/code reasoning, and fail to reflect model's
agentic capabilities. On the other hand, agent benchmarks are typically
designed for post-trained models, requiring multi-turn task execution abilities
that base models struggle to support. Thus, there is a compelling need for a
benchmark that can evaluate agentic potentials during pre-training and guide
the model training more effectively. To address this gap, we propose APTBench,
a framework that converts real-world agent tasks and successful trajectories
into multiple-choice or text completion questions tailored for base models. It
focuses on core agentic abilities, e.g., planning and action, and covers key
agent scenarios, software engineering and deep research. Compared to existing
general-purpose benchmarks, APTBench offers a more predictive signal of a
model's downstream performance as an agent, while remaining significantly more
lightweight and cost-effective than full-scale, end-to-end agent evaluations
after post-training.

</details>


### [111] [Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks](https://arxiv.org/abs/2510.24461)
*Korneel Van den Berghe,Stein Stroobants,Vijay Janapa Reddi,G. C. H. E. de Croon*

Main category: cs.AI

TL;DR: 该论文提出了一种改进脉冲神经网络在强化学习中训练性能的方法，通过分析替代梯度斜率设置和引入特权引导策略，显著提升了无人机位置控制任务的性能。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络在能量受限机器人系统中具有巨大潜力，但其应用面临两个关键挑战：脉冲神经元的不可微分性需要替代梯度方法，以及SNN的状态动态需要在序列上训练，这在强化学习中受到早期训练序列长度限制的影响。

Method: 系统分析替代梯度斜率设置，发现较浅的斜率能增加深层梯度幅度但降低与真实梯度的对齐；提出利用特权引导策略来引导学习过程，同时保持与环境的在线交互；结合自适应斜率调度方法。

Result: 在强化学习环境中，较浅斜率或调度斜率使训练和最终部署性能提升2.1倍；在真实世界无人机位置控制任务中，平均回报达到400分，显著优于行为克隆和TD3BC方法（最多-200分）。

Conclusion: 这项工作推进了对SNN中替代梯度学习的理论理解，并为神经形态控制器在实际机器人系统中的训练方法提供了实用解决方案。

Abstract: Neuromorphic computing systems are set to revolutionize energy-constrained
robotics by achieving orders-of-magnitude efficiency gains, while enabling
native temporal processing. Spiking Neural Networks (SNNs) represent a
promising algorithmic approach for these systems, yet their application to
complex control tasks faces two critical challenges: (1) the non-differentiable
nature of spiking neurons necessitates surrogate gradients with unclear
optimization properties, and (2) the stateful dynamics of SNNs require training
on sequences, which in reinforcement learning (RL) is hindered by limited
sequence lengths during early training, preventing the network from bridging
its warm-up period.
  We address these challenges by systematically analyzing surrogate gradient
slope settings, showing that shallower slopes increase gradient magnitude in
deeper layers but reduce alignment with true gradients. In supervised learning,
we find no clear preference for fixed or scheduled slopes. The effect is much
more pronounced in RL settings, where shallower slopes or scheduled slopes lead
to a 2.1x improvement in both training and final deployed performance. Next, we
propose a novel training approach that leverages a privileged guiding policy to
bootstrap the learning process, while still exploiting online environment
interactions with the spiking policy. Combining our method with an adaptive
slope schedule for a real-world drone position control task, we achieve an
average return of 400 points, substantially outperforming prior techniques,
including Behavioral Cloning and TD3BC, which achieve at most --200 points
under the same conditions. This work advances both the theoretical
understanding of surrogate gradient learning in SNNs and practical training
methodologies for neuromorphic controllers demonstrated in real-world robotic
systems.

</details>


### [112] [OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows](https://arxiv.org/abs/2510.24411)
*Qiushi Sun,Mukai Li,Zhoumianze Liu,Zhihui Xie,Fangzhi Xu,Zhangyue Yin,Kanzhi Cheng,Zehao Li,Zichen Ding,Qi Liu,Zhiyong Wu,Zhuosheng Zhang,Ben Kao,Lingpeng Kong*

Main category: cs.AI

TL;DR: MobileRisk-Live是一个动态沙盒环境和安全检测基准，用于评估移动AI代理的安全性风险。OS-Sentinel混合框架结合形式验证器和VLM上下文判断器，在移动设备安全检测上比现有方法提升10%-30%。


<details>
  <summary>Details</summary>
Motivation: 基于视觉语言模型的移动AI代理在数字环境中展现出类人操作能力，但其潜在的安全风险（如系统破坏、隐私泄露）尚未得到充分研究，需要建立系统化的安全检测方法。

Method: 提出OS-Sentinel混合安全检测框架，结合形式验证器检测系统级违规和基于VLM的上下文判断器评估情境风险与代理行为。

Result: 实验表明OS-Sentinel在多个指标上比现有方法提升10%-30%，为开发更安全可靠的自主移动代理提供了关键见解。

Conclusion: MobileRisk-Live为移动代理安全研究奠定了基础，OS-Sentinel框架有效提升了安全检测能力，促进了更安全可靠的自主移动代理发展。

Abstract: Computer-using agents powered by Vision-Language Models (VLMs) have
demonstrated human-like capabilities in operating digital environments like
mobile platforms. While these agents hold great promise for advancing digital
automation, their potential for unsafe operations, such as system compromise
and privacy leakage, is raising significant concerns. Detecting these safety
concerns across the vast and complex operational space of mobile environments
presents a formidable challenge that remains critically underexplored. To
establish a foundation for mobile agent safety research, we introduce
MobileRisk-Live, a dynamic sandbox environment accompanied by a safety
detection benchmark comprising realistic trajectories with fine-grained
annotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety
detection framework that synergistically combines a Formal Verifier for
detecting explicit system-level violations with a VLM-based Contextual Judge
for assessing contextual risks and agent actions. Experiments show that
OS-Sentinel achieves 10%-30% improvements over existing approaches across
multiple metrics. Further analysis provides critical insights that foster the
development of safer and more reliable autonomous mobile agents.

</details>


### [113] [Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning](https://arxiv.org/abs/2510.24435)
*Benjamin Grando Moreira*

Main category: cs.AI

TL;DR: 本研究比较了多个大型语言模型在逻辑和抽象推理能力方面的表现，并与人类表现进行基准测试，揭示了LLMs在演绎推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型的推理能力对于推进人工智能发展至关重要，这超越了单纯的语言任务表现，涉及理解模型是否真正理解信息、进行推理并以逻辑有效的方式得出结论。

Method: 使用八个定制设计的推理问题，比较了GPT、Claude、DeepSeek、Gemini、Grok、Llama、Mistral、Perplexity和Sabi'a等多个LLMs的逻辑和抽象推理技能，并将结果与人类在相同任务上的表现进行基准测试。

Result: 研究结果显示LLMs与人类表现存在显著差异，表明LLMs在演绎推理方面存在困难。

Conclusion: 大型语言模型在逻辑和抽象推理能力方面仍有待改进，特别是在演绎推理任务上表现不佳。

Abstract: Evaluating reasoning ability in Large Language Models (LLMs) is important for
advancing artificial intelligence, as it transcends mere linguistic task
performance. It involves understanding whether these models truly understand
information, perform inferences, and are able to draw conclusions in a logical
and valid way. This study compare logical and abstract reasoning skills of
several LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,
Perplexity, and Sabi\'a - using a set of eight custom-designed reasoning
questions. The LLM results are benchmarked against human performance on the
same tasks, revealing significant differences and indicating areas where LLMs
struggle with deduction.

</details>


### [114] [Affordance Representation and Recognition for Autonomous Agents](https://arxiv.org/abs/2510.24459)
*Habtom Kahsay Gidey,Niklas Huber,Alexander Lenz,Alois Knoll*

Main category: cs.AI

TL;DR: 提出两种架构模式：DOM转换模式处理网页复杂性，将冗长DOM转换为紧凑的任务相关表示；超媒体功能识别模式使代理能动态发现和集成未知Web服务的能力。


<details>
  <summary>Details</summary>
Motivation: 软件代理的自主性依赖于从结构化数据构建可操作内部世界模型的能力，但原始HTML的冗长性和硬编码API集成的静态性阻碍了代理的适应性和可扩展性。

Method: DOM转换模式：将原始DOM提炼为紧凑的世界模型；超媒体功能识别模式：解析标准化语义描述以动态发现和集成Web服务能力。

Result: 为工程化代理提供了一个稳健框架，能够高效构建和维护准确的世界模型。

Conclusion: 这些模式共同支持在Web及其扩展资源上实现可扩展、自适应和可互操作的自动化。

Abstract: The autonomy of software agents is fundamentally dependent on their ability
to construct an actionable internal world model from the structured data that
defines their digital environment, such as the Document Object Model (DOM) of
web pages and the semantic descriptions of web services. However, constructing
this world model from raw structured data presents two critical challenges: the
verbosity of raw HTML makes it computationally intractable for direct use by
foundation models, while the static nature of hardcoded API integrations
prevents agents from adapting to evolving services.
  This paper introduces a pattern language for world modeling from structured
data, presenting two complementary architectural patterns. The DOM Transduction
Pattern addresses the challenge of web page complexity by distilling} a
verbose, raw DOM into a compact, task-relevant representation or world model
optimized for an agent's reasoning core. Concurrently, the Hypermedia
Affordances Recognition Pattern enables the agent to dynamically enrich its
world model by parsing standardized semantic descriptions to discover and
integrate the capabilities of unknown web services at runtime. Together, these
patterns provide a robust framework for engineering agents that can efficiently
construct and maintain an accurate world model, enabling scalable, adaptive,
and interoperable automation across the web and its extended resources.

</details>


### [115] [From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning](https://arxiv.org/abs/2510.24528)
*Zihan Chen,Song Wang,Xingbo Fu,Chengshuai Shi,Zhenyu Lei,Cong Shen,Jundong Li*

Main category: cs.AI

TL;DR: 提出了一种成本效益高的两阶段管道，通过跨任务示例和基于图的标签传播方法，减少对LLM数据标注的依赖，用于构建ICL的演示示例。


<details>
  <summary>Details</summary>
Motivation: 为新任务或挑战性任务收集高质量示例成本高昂且劳动密集，需要减少对LLM标注的依赖。

Method: 两阶段管道：首先使用跨任务示例提示LLM伪标注少量目标实例，然后引入基于图的标签传播方法将标签信息传播到剩余目标示例中，无需额外LLM查询。

Result: 在五个任务上的实验表明，该方法在降低标注成本的同时实现了强劲性能。

Conclusion: 该管道结合了跨任务监督的灵活性和无LLM传播的可扩展性，为ICL提供了成本效益高的解决方案。

Abstract: The capability of in-context learning (ICL) enables large language models
(LLMs) to perform novel tasks without parameter updates by conditioning on a
few input-output examples. However, collecting high-quality examples for new or
challenging tasks can be costly and labor-intensive. In this work, we propose a
cost-efficient two-stage pipeline that reduces reliance on LLMs for data
labeling. Our approach first leverages readily available cross-task examples to
prompt an LLM and pseudo-label a small set of target task instances. We then
introduce a graph-based label propagation method that spreads label information
to the remaining target examples without additional LLM queries. The resulting
fully pseudo-labeled dataset is used to construct in-task demonstrations for
ICL. This pipeline combines the flexibility of cross-task supervision with the
scalability of LLM-free propagation. Experiments across five tasks demonstrate
that our method achieves strong performance while lowering labeling costs.

</details>


### [116] [Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives](https://arxiv.org/abs/2510.24551)
*Gang Chen,Changshuo Liu,Gene Anne Ooi,Marcus Tan,Zhongle Xie,Jianwei Yin,James Wei Luen Yip,Wenqiao Zhang,Jiaqi Zhu,Beng Chin Ooi*

Main category: cs.AI

TL;DR: 本文提出了一种以数据为中心的方法来设计和部署医疗领域的生成式AI系统，将医疗数据生态系统作为生成式医疗系统的基础支撑。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在医疗领域具有巨大潜力，但需要深入理解医疗任务和可实现的范围。当前需要一种系统化的方法来支持GenAI在医疗中的高质量部署。

Method: 重新定位数据生命周期，构建医疗数据生态系统作为基础支撑，支持多模态医疗数据的集成、表示和检索。通过语义向量搜索和上下文查询等高效数据处理管道，为上游模型组件和下游临床应用提供支持。

Result: 该生态系统不仅为基座模型提供高质量多模态数据进行大规模预训练和领域特定微调，还作为知识检索后端通过代理层支持任务特定推理。

Conclusion: 这种以数据为中心的方法能够实现生成式AI在医疗领域的高质量和有效部署，改善医疗服务交付。

Abstract: Generative Artificial Intelligence (GenAI) is taking the world by storm. It
promises transformative opportunities for advancing and disrupting existing
practices, including healthcare. From large language models (LLMs) for clinical
note synthesis and conversational assistance to multimodal systems that
integrate medical imaging, electronic health records, and genomic data for
decision support, GenAI is transforming the practice of medicine and the
delivery of healthcare, such as diagnosis and personalized treatments, with
great potential in reducing the cognitive burden on clinicians, thereby
improving overall healthcare delivery. However, GenAI deployment in healthcare
requires an in-depth understanding of healthcare tasks and what can and cannot
be achieved. In this paper, we propose a data-centric paradigm in the design
and deployment of GenAI systems for healthcare. Specifically, we reposition the
data life cycle by making the medical data ecosystem as the foundational
substrate for generative healthcare systems. This ecosystem is designed to
sustainably support the integration, representation, and retrieval of diverse
medical data and knowledge. With effective and efficient data processing
pipelines, such as semantic vector search and contextual querying, it enables
GenAI-powered operations for upstream model components and downstream clinical
applications. Ultimately, it not only supplies foundation models with
high-quality, multimodal data for large-scale pretraining and domain-specific
fine-tuning, but also serves as a knowledge retrieval backend to support
task-specific inference via the agentic layer. The ecosystem enables the
deployment of GenAI for high-quality and effective healthcare delivery.

</details>


### [117] [FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling](https://arxiv.org/abs/2510.24645)
*Zengzhuang Xu,Bingguang Hao,Zechuan Wang,Yuntao Wen,Maolin Wang,Yang Liu,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Chenyi Zhuang,Jinjie Gu,Leilei Gan,Xiangyu Zhao,Shi Gu*

Main category: cs.AI

TL;DR: FunReason-MT是一个用于生成多轮工具调用训练数据的新框架，解决了现有方法在真实环境中的局限性，通过环境-API图交互、高级工具查询合成和引导迭代链等技术，在BFCL基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据合成方法（如随机环境采样或多智能体角色扮演）在真实环境中无法生成高质量的多轮工具调用训练数据，存在目标模型训练、工具架构隔离和多轮逻辑依赖等实际挑战。

Method: FunReason-MT框架采用三种核心技术：1）环境-API图交互收集多样化高质量轨迹；2）高级工具查询合成简化复杂查询构建；3）引导迭代链生成复杂思维链。

Result: 在Berkeley Function-Calling Leaderboard (BFCLv3)上，基于FunReason-MT生成数据训练的4B模型在同等规模模型中达到最先进性能，甚至优于大多数闭源模型。在BFCLv4上的进一步性能改进证实了该框架的可靠性。

Conclusion: FunReason-MT为智能体学习提供了可靠且鲁棒的数据源，能够有效解决多轮函数调用数据合成的复杂性障碍。

Abstract: Function calling (FC) empowers large language models (LLMs) and autonomous
agents to interface with external tools, a critical capability for solving
complex, real-world problems. As this ability becomes increasingly central to
advanced AI systems, the need for high-quality, multi-turn training data to
develop and refine it cannot be overstated. Existing data synthesis methods,
such as random environment sampling or multi-agent role-playing, are not
powerful enough to generate high-quality data in real-world environments.
Practical challenges come in three folds: targeted model training, isolation of
tool architecture, and multi-turn logical dependency. To address these
structural deficiencies, we present FunReason-MT, a novel data synthesis
framework for real-world multi-turn tool use. FunReason-MT resolves the
complexity barrier in multi-turn FC data by employing 1) Environment-API Graph
Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query
Synthesis to simplify hard query construction, and 3) Guided Iterative Chain
for sophisticated CoT generation. Evaluations on Berkeley Function-Calling
Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built
upon FunReason-MT generated data achieves state-of-the-art performance among
comparable-sized models, outperforming most close-source models. Further
performance improvements on BFCLv4 confirm that FunReason-MT provides a
reliable and robust source for agentic learning.

</details>


### [118] [Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning](https://arxiv.org/abs/2510.24650)
*Nitin Rai,Daeun,Choi,Nathan S. Boyd,Arnold W. Schumann*

Main category: cs.AI

TL;DR: 该综述分析了约40篇关于基础模型在作物精准病害管理中的应用文献，重点关注大语言模型和视觉语言模型，讨论了它们在自适应学习、强化学习和数字孪生框架中的作用。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和深度学习在实时计算机视觉中的快速发展，作物精准病害管理从手工特征提取发展到大规模自动化特征学习。基础模型以全新方式处理作物病害数据，整合视觉和文本数据，解释症状文本，推理症状与管理的关系，并为种植者和教育者提供交互式问答支持。

Method: 通过文献综述方法，筛选了约40篇关于基础模型在精准病害管理中应用的论文，特别关注大语言模型和视觉语言模型，分析它们在自适应学习、强化学习和数字孪生框架中的作用。

Result: 主要发现包括：基础模型在2023-24年文献激增；视觉语言模型发展快于大语言模型，出版物增长5-10倍；强化学习和自适应学习在智能喷洒中仍处于早期阶段；数字孪生与强化学习可模拟虚拟靶向喷洒；解决仿真到现实的差距对实际部署至关重要；人机协作仍然有限；多模态基础模型与实时反馈将推动下一代精准病害管理。

Conclusion: 基础模型正在改变作物精准病害管理的方式，特别是视觉语言模型的发展最为迅速。虽然强化学习和自适应学习应用仍处于早期阶段，但数字孪生与强化学习的结合显示出巨大潜力。未来需要解决仿真到现实的差距，加强人机协作，发展多模态基础模型与实时反馈系统，以推动下一代精准病害管理技术的发展。

Abstract: Site-specific disease management (SSDM) in crops has advanced rapidly through
machine and deep learning (ML and DL) for real-time computer vision. Research
evolved from handcrafted feature extraction to large-scale automated feature
learning. With foundation models (FMs), crop disease datasets are now processed
in fundamentally new ways. Unlike traditional neural networks, FMs integrate
visual and textual data, interpret symptoms in text, reason about
symptom-management relationships, and support interactive QA for growers and
educators. Adaptive and imitation learning in robotics further enables
field-based disease management. This review screened approx. 40 articles on FM
applications for SSDM, focusing on large-language models (LLMs) and
vision-language models (VLMs), and discussing their role in adaptive learning
(AL), reinforcement learning (RL), and digital twin frameworks for targeted
spraying. Key findings: (a) FMs are gaining traction with surging literature in
2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL
and AL are still nascent for smart spraying; (d) digital twins with RL can
simulate targeted spraying virtually; (e) addressing the sim-to-real gap is
critical for real-world deployment; (f) human-robot collaboration remains
limited, especially in human-in-the-loop approaches where robots detect early
symptoms and humans validate uncertain cases; (g) multi-modal FMs with
real-time feedback will drive next-gen SSDM. For updates, resources, and
contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to
submit papers, code, or datasets.

</details>


### [119] [OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs](https://arxiv.org/abs/2510.24663)
*Yifu Lu,Shengjie Liu,Li Dong*

Main category: cs.AI

TL;DR: OrchDAG是一个合成数据生成管道，将工具执行建模为具有可控复杂度的有向无环图，用于基准测试模型性能并提出基于图的奖励来增强RLVR训练。


<details>
  <summary>Details</summary>
Motivation: 现有工作大多忽视了多轮工具交互的复杂性，需要更好的方法来建模和训练多轮工具使用。

Method: 引入OrchDAG合成数据生成管道，将工具执行建模为有向无环图，并提出基于图的奖励来增强RLVR训练。

Result: 实验表明该数据集提供了一个具有挑战性但可解决的基准，所提出的奖励与GRPO风格算法结合时效果显著。

Conclusion: 在多轮工具使用中，利用拓扑结构和数据复杂度具有重要意义。

Abstract: Agentic tool use has gained traction with the rise of agentic tool calling,
yet most existing work overlooks the complexity of multi-turn tool
interactions. We introduce OrchDAG, a synthetic data generation pipeline that
models tool execution as directed acyclic graphs (DAGs) with controllable
complexity. Using this dataset, we benchmark model performance and propose a
graph-based reward to enhance RLVR training. Experiments show that the dataset
presents a challenging but solvable benchmark, and the proposed reward is
effective when combined with GRPO-style algorithms, highlighting the importance
of leveraging topological structure and data complexity in multi-turn tool use.

</details>


### [120] [Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning](https://arxiv.org/abs/2510.24690)
*Shengjie Liu,Li Dong,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 提出了一个通过构建工具和文档知识图谱来增强示例工件生成的框架，通过融合工具依赖关系和领域知识来改进规划生成。


<details>
  <summary>Details</summary>
Motivation: 现有的工具增强方法往往忽视了工具之间的依赖关系以及工具与领域知识之间的关联，限制了示例工件生成的质量和效果。

Method: 首先从工具模式构建工具知识图谱，同时从内部文档和SOP构建补充知识图谱，然后将两者融合。采用深度-稀疏集成策略对齐结构工具依赖与程序知识来生成示例计划。

Result: 实验表明该统一框架能有效建模工具交互并改进计划生成，证明了将工具图谱与领域知识图谱链接的益处。

Conclusion: 通过融合工具依赖关系和领域知识，该框架显著提升了工具增强推理和规划的效果，为复杂任务规划提供了有效解决方案。

Abstract: We present a framework for uncovering and exploiting dependencies among tools
and documents to enhance exemplar artifact generation. Our method begins by
constructing a tool knowledge graph from tool schemas,including descriptions,
arguments, and output payloads, using a DeepResearch-inspired analysis. In
parallel, we derive a complementary knowledge graph from internal documents and
SOPs, which is then fused with the tool graph. To generate exemplar plans, we
adopt a deep-sparse integration strategy that aligns structural tool
dependencies with procedural knowledge. Experiments demonstrate that this
unified framework effectively models tool interactions and improves plan
generation, underscoring the benefits of linking tool graphs with domain
knowledge graphs for tool-augmented reasoning and planning.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [121] [What Work is AI Actually Doing? Uncovering the Drivers of Generative AI Adoption](https://arxiv.org/abs/2510.23669)
*Peeyush Agarwal,Harsh Agarwal,Akshat Ranaa*

Main category: econ.GN

TL;DR: 研究通过分析400万次Claude AI交互数据，发现高创造性、复杂性和认知需求但低常规性的任务最吸引AI参与，并识别出三种任务原型，其中仅5%的任务占据了59%的AI使用量。


<details>
  <summary>Details</summary>
Motivation: 预测AI如何重塑工作需要了解其实际采用方式，而不仅仅是能力。本研究旨在探索哪些内在任务特征驱动用户将工作委托给AI系统。

Method: 使用Anthropic经济指数数据集中的400万次Claude AI交互数据，映射到O*NET任务，通过35个参数系统评估7个关键维度，并采用多元技术识别潜在任务原型。

Result: 高创造性、复杂性和认知需求但低常规性的任务获得最多AI参与。识别出三种任务原型：动态问题解决、程序性与分析工作、标准化操作任务。AI适用性最好通过任务特征组合而非单个因素来预测。

Conclusion: 本研究首次系统地将真实世界生成式AI使用与全面的多维任务特征框架联系起来，为分析新兴的人机分工提供了数据驱动的工作原型分类框架。

Abstract: Purpose: The rapid integration of artificial intelligence (AI) systems like
ChatGPT, Claude AI, etc., has a deep impact on how work is done. Predicting how
AI will reshape work requires understanding not just its capabilities, but how
it is actually being adopted. This study investigates which intrinsic task
characteristics drive users' decisions to delegate work to AI systems.
Methodology: This study utilizes the Anthropic Economic Index dataset of four
million Claude AI interactions mapped to O*NET tasks. We systematically scored
each task across seven key dimensions: Routine, Cognitive, Social Intelligence,
Creativity, Domain Knowledge, Complexity, and Decision Making using 35
parameters. We then employed multivariate techniques to identify latent task
archetypes and analyzed their relationship with AI usage. Findings: Tasks
requiring high creativity, complexity, and cognitive demand, but low
routineness, attracted the most AI engagement. Furthermore, we identified three
task archetypes: Dynamic Problem Solving, Procedural & Analytical Work, and
Standardized Operational Tasks, demonstrating that AI applicability is best
predicted by a combination of task characteristics, over individual factors.
Our analysis revealed highly concentrated AI usage patterns, with just 5% of
tasks accounting for 59% of all interactions. Originality: This research
provides the first systematic evidence linking real-world generative AI usage
to a comprehensive, multi-dimensional framework of intrinsic task
characteristics. It introduces a data-driven classification of work archetypes
that offers a new framework for analyzing the emerging human-AI division of
labor.

</details>


### [122] [How Does Environmental Information Disclosure Affect Corporate Environmental Performance? Evidence from Chinese A-Share Listed Companies](https://arxiv.org/abs/2510.24002)
*Zehao Lin*

Main category: econ.GN

TL;DR: 环境信息披露显著改善企业环境绩效，在人口密度高、绿地有限的地区效果更明显，为通过企业透明度促进可持续发展提供了实证依据。


<details>
  <summary>Details</summary>
Motivation: 全球气候变暖和空气污染对经济发展和公共安全构成严重威胁，企业作为资源利用和排放的关键参与者，其环境战略和实践受到政策制定者、研究人员和公众的日益关注。

Method: 采用双向固定效应面板模型研究环境信息披露对企业环境绩效的影响、区域异质性及其潜在机制。

Result: 环境信息披露显著提高了企业环境绩效，在人口密度高、绿地有限的地区效果更为显著。

Conclusion: 研究强调了针对性、区域特异性政策的重要性，以最大化信息披露的有效性，为通过增强企业透明度促进可持续发展提供了宝贵见解。

Abstract: Global climate warming and air pollution pose severe threats to economic
development and public safety, presenting significant challenges to sustainable
development worldwide. Corporations, as key players in resource utilization and
emissions, have drawn increasing attention from policymakers, researchers, and
the public regarding their environmental strategies and practices. This study
employs a two-way fixed effects panel model to examine the impact of
environmental information disclosure on corporate environmental performance,
its regional heterogeneity, and the underlying mechanisms. The results
demonstrate that environmental information disclosure significantly improves
corporate environmental performance, with the effect being more pronounced in
areas of high population density and limited green space. These findings
provide empirical evidence supporting the role of environmental information
disclosure as a critical tool for improving corporate environmental practices.
The study highlights the importance of targeted, region-specific policies to
maximize the effectiveness of disclosure, offering valuable insights for
promoting sustainable development through enhanced corporate transparency.

</details>


### [123] [Moment connectedness and driving factors in the energy-food nexus: A time-frequency perspective](https://arxiv.org/abs/2510.24174)
*Yun-Shi Dai,Peng-Fei Dai,Stéphane Goutte,Duc Khuong Nguyen,Wei-Xing Zhou*

Main category: econ.GN

TL;DR: 该研究提出一个集成框架分析能源与食品市场间的多维风险溢出效应，发现原油是主要风险传播者，不同矩（收益、偏度、峰度、波动率）的溢出效应在不同时间尺度上表现各异，受多种宏观和气候因素影响。


<details>
  <summary>Details</summary>
Motivation: 随着宏观经济不确定性加剧，能源与食品市场间的风险联动日益复杂，对全球能源和食品安全构成严重挑战，需要系统研究其风险溢出机制。

Method: 结合GJRSK模型、时频联动分析和随机森林方法，构建集成框架来研究能源-食品关联中的矩联动性，并探索各种溢出效应的关键驱动因素。

Result: 发现显著的多维风险溢出，具有明显的时间变化性、异质性和危机敏感性。收益和偏度联动主要由短期溢出驱动，峰度联动在中长期更突出，波动率联动则受长期动态主导。原油在不同联动网络中始终是核心传播者。

Conclusion: 研究结果为能源与食品市场的协同治理、多层次风险预警系统改进以及投资策略优化提供了有价值的见解。

Abstract: With escalating macroeconomic uncertainty, the risk interlinkages between
energy and food markets have become increasingly complex, posing serious
challenges to global energy and food security. This paper proposes an
integrated framework combining the GJRSK model, the time-frequency
connectedness analysis, and the random forest method to systematically
investigate the moment connectedness within the energy-food nexus and explore
the key drivers of various spillover effects. The results reveal significant
multidimensional risk spillovers with pronounced time variation, heterogeneity,
and crisis sensitivity. Return and skewness connectedness are primarily driven
by short-term spillovers, kurtosis connectedness is more prominent over the
medium term, while volatility connectedness is dominated by long-term dynamics.
Notably, crude oil consistently serves as a central transmitter in diverse
connectedness networks. Furthermore, the spillover effects are influenced by
multiple factors, including macro-financial conditions, oil supply-demand
fundamentals, policy uncertainties, and climate-related shocks, with the core
drivers of connectedness varying considerably across different moments and
timescales. These findings provide valuable insights for the coordinated
governance of energy and food markets, the improvement of multilayered risk
early-warning systems, and the optimization of investment strategies.

</details>


### [124] [The Effects of Immigration on Places and People -- Identification and Interpretation](https://arxiv.org/abs/2510.24225)
*Christian Dustmann,Sebastian Otten,Uta Schönberg,Jan Stuhler*

Main category: econ.GN

TL;DR: 本文提出了一个统一实证框架，将移民的区域效应分解为基本组成部分，并展示了如何通过追踪工人的时间序列数据来识别这些效应。


<details>
  <summary>Details</summary>
Motivation: 现有关于移民劳动力市场影响的研究大多使用重复横截面数据来估计移民对区域的影响，但这些区域效应实际上是多个基本效应的复合体，无法通过重复横截面数据识别。

Method: 提供了一个统一实证框架，将移民的区域效应分解为其基本组成部分，并展示了如何通过追踪工人随时间变化的数据来识别这些效应。

Result: 实证应用表明，这种分析方法能够更全面地揭示移民对工资、就业和职业升级的影响。

Conclusion: 使用追踪工人的时间序列数据进行分析，能够提供比传统重复横截面数据更丰富、更有信息量的移民影响图景。

Abstract: Most studies on the labor market effects of immigration use repeated
cross-sectional data to estimate the effects of immigration on regions. This
paper shows that such regional effects are composites of effects that address
fundamental questions in the immigration debate but remain unidentified with
repeated cross-sectional data. We provide a unifying empirical framework that
decomposes the regional effects of immigration into their underlying components
and show how these are identifiable from data that track workers over time. Our
empirical application illustrates that such analysis yields a far more
informative picture of immigration's effects on wages, employment, and
occupational upgrading.

</details>


### [125] [Are They Willing to Participate? A Review on Behavioral Economics Approach to Voters Turnout](https://arxiv.org/abs/2510.24344)
*Mostafa Raeisi Sarkandiz*

Main category: econ.GN

TL;DR: 本文使用经济模型研究影响选举参与率和方式的基本因素，将影响人们决策的结构参数分为经济文化心理因素和政府绩效因素两类，并通过发展中国家的国有民粹主义就业计划案例进行分析。


<details>
  <summary>Details</summary>
Motivation: 研究选举参与的根本影响因素，特别是经济因素（如通胀和失业）如何影响选民决策，以及政府如何通过操纵经济变量来维持执政地位。

Method: 采用经济模型方法，将影响选民决策的结构参数分为两类：一是经济、民生、文化和心理因素；二是投票类型和政府绩效因素。使用博弈论分析政府与选民的关系，并通过假设案例研究发展中国家的国有民粹主义就业计划。

Result: 研究发现通胀和失业是最重要的经济因素，政府与支持选民处于纳什均衡博弈中，选民通常是回顾性的，因此政府会通过刻意改变经济因素（特别是通胀和失业率）来维持地位。

Conclusion: 选举参与受到经济因素的显著影响，政府会策略性地操纵经济变量来影响选民行为，这在发展中国家的民粹主义政策中表现尤为明显。

Abstract: This article investigates the fundamental factors influencing the rate and
manner of Electoral participation with an economic model-based approach. In
this study, the structural parameters affecting people's decision making are
divided into two categories. The first category includes general topics such as
economic and livelihood status, cultural factors and, also, psychological
variables. In this section, given that voters are analyzed within the context
of consumer behavior theory, inflation and unemployment are considered as the
most important economic factors. The second group of factors focuses more on
the type of voting, with emphasis on government performance. Since the
incumbent government and its supportive voters are in a game with two Nash
equilibrium, and also because the voters in most cases are retrospect, the
government seeks to keep its position by a deliberate change in economic
factors, especially inflation and unemployment rates. Finally, to better
understand the issue, a hypothetical example is presented and analyzed in a
developing country in the form of a state-owned populist employment plan.

</details>


### [126] [Implicit quantile preferences of the Fed and the Taylor rule](https://arxiv.org/abs/2510.24362)
*Gabriel Montes-Rojas,Fernando Toledo,Nicolás Bertholet,Kevin Corfield*

Main category: econ.GN

TL;DR: 该论文研究中央银行采用分位数效用目标而非期望效用时的最优货币政策，通过分位数指数映射鹰派/鸽派立场与对不利宏观经济结果的关注度。


<details>
  <summary>Details</summary>
Motivation: 传统货币政策基于期望效用，但实际决策者可能更关注特定分位数结果。研究旨在建立更透明的风险态度与政策立场映射关系。

Method: 使用带分位数算子的贝尔曼方程构建无限期问题，采用欧拉方程方法推导泰勒规则型反应函数，通过间接推断方法推导中央银行风险厌恶隐含分位数指数。

Result: 基于美国数据的实证实施显示，美联储主要表现出鸽派行为，但某些时期具有鹰派态度。

Conclusion: 分位数效用框架为理解中央银行风险态度和政策立场提供了新视角，实证结果表明美联储政策立场存在时间变化。

Abstract: We study optimal monetary policy when a central bank maximizes a quantile
utility objective rather than expected utility. In our framework, the central
bank's risk attitude is indexed by the quantile index level, providing a
transparent mapping between hawkish/dovish stances and attention to adverse
macroeconomic realizations. We formulate the infinite-horizon problem using a
Bellman equation with the quantile operator. Implementing an Euler-equation
approach, we derive Taylor-rule-type reaction functions. Using an indirect
inference approach, we derive a central bank risk aversion implicit quantile
index. An empirical implementation for the US is outlined based on reduced-form
laws of motion with conditional heteroskedasticity, enabling estimation of the
new monetary policy rule and its dependence on the Fed risk attitudes. The
results reveal that the Fed has mostly a dovish-type behavior but with some
periods of hawkish attitudes.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [127] [Bridging Function Approximation and Device Physics via Negative Differential Resistance Networks](https://arxiv.org/abs/2510.23638)
*Songyuan Li,Teng Wang,Jinrong Tang,Ruiqi Liu,Yuyao Lu,Feng Xu,Bin Gao,Xiangwei Zhu*

Main category: cs.ET

TL;DR: KANalogue是一种完全模拟的Kolmogorov-Arnold网络实现，利用负微分电阻器件作为可学习单变量基函数的物理实现，为高效模拟机器学习系统提供新路径。


<details>
  <summary>Details</summary>
Motivation: 传统模拟神经网络中，非线性激活函数成为性能瓶颈，通常需要数字或混合解决方案。本文旨在实现完全模拟的神经网络计算，特别是解决非线性操作的模拟实现问题。

Method: 利用NbSi2N4/HfSi2N4异质结构隧道二极管的负微分电阻特性，构建具有不同曲率和支撑轮廓的坐标方向非线性函数，通过提取I-V数据并拟合高阶多项式来模拟二极管行为，训练KAN网络。

Result: KANalogue能够以最少的参数逼近复杂函数，同时在视觉基准测试中保持与数字基线相当的分类准确率。

Conclusion: 这项工作连接了器件级物理和函数逼近理论，为可扩展、高能效的模拟机器学习系统开辟了新路径。

Abstract: Achieving fully analog neural computation requires hardware that can natively
implement both linear and nonlinear operations with high efficiency. While
analogue matrix-vector multiplication has advanced via compute-in-memory
architectures, nonlinear activation functions remain a bottleneck, often
requiring digital or hybrid solutions. Inspired by the Kolmogorov-Arnold
framework, we propose KANalogue, a fully analogue implementation of
Kolmogorov-Arnold Networks (KANs) using negative differential resistance
devices as physical realizations of learnable univariate basis functions. By
leveraging the intrinsic negative differential resistance characteristics of
tunnel diodes fabricated from NbSi2N4/HfSi2N4 heterostructures, we construct
coordinate-wise nonlinearities with distinct curvature and support profiles. We
extract I-V data from fabricated armchair and zigzag devices, fit high-order
polynomials to emulate diode behavior in software, and train KANs on vision
benchmarks using these learned basis functions. Our results demonstrate that
KANalogue can approximate complex functions with minimal parameters while
maintaining classification accuracy competitive with digital baselines. This
work bridges device-level physics and function approximation theory, charting a
path toward scalable, energy-efficient analogue machine learning systems.

</details>


### [128] [Evaluating Fitness Averaging Strategies in Cooperative NeuroCoEvolution for Automated Soft Actuator Design](https://arxiv.org/abs/2510.24510)
*Hugo Alcaraz-Herrera,Michail-Antisthenis Tsompanas,Igor Balaz,Andrew Adamatzky*

Main category: cs.ET

TL;DR: 本研究提出了一种基于CPPN-NEAT的协同神经协同进化方法，用于自动设计软机器人执行器的形态和控制器，应用于药物输送系统，相比多目标优化方法取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 软机器人由于其材料的非线性特性在医疗等领域具有适应性优势，但这些特性也给形态和控制器设计带来挑战。该领域历史较短，缺乏系统设计知识，因此需要自动化设计过程。

Method: 使用CPPN-NEAT方法协同进化软机器人执行器的形态和控制器，通过合作种群中的前n个个体实现协同进化，测试了多种平均方法来确定个体适应度。

Result: CPPN-NEAT方法相比之前的多目标优化方法产生了更优的形态，计算量和时间更少。最佳配置是使用合作种群中前两个最佳个体进行协同进化，并采用加权平均方法计算适应度。

Conclusion: 协同神经协同进化方法能够有效优化软机器人执行器的设计，在药物输送系统应用中表现出优越性能，为软机器人自动化设计提供了有效解决方案。

Abstract: Soft robotics are increasingly favoured in specific applications such as
healthcare, due to their adaptability, which stems from the non-linear
properties of their building materials. However, these properties also pose
significant challenges in designing the morphologies and controllers of soft
robots. The relatively short history of this field has not yet produced
sufficient knowledge to consistently derive optimal solutions. Consequently, an
automated process for the design of soft robot morphologies can be extremely
helpful. This study focusses on the cooperative NeuroCoEvolution of networks
that are indirect representations of soft robot actuators. Both the
morphologies and controllers represented by Compositional Pattern Producing
Networks are evolved using the well-established method NeuroEvolution of
Augmented Topologies (CPPN-NEAT). The CoEvolution of controllers and
morphologies is implemented using the top n individuals from the cooperating
population, with various averaging methods tested to determine the fitness of
the evaluated individuals. The test-case application for this research is the
optimisation of a soft actuator for a drug delivery system. The primary metric
used is the maximum displacement of one end of the actuator in a specified
direction. Additionally, the robustness of the evolved morphologies is assessed
against a range of randomly generated controllers to simulate potential noise
in real-world applications. The results of this investigation indicate that
CPPN-NEAT produces superior morphologies compared to previously published
results from multi-objective optimisation, with reduced computational effort
and time. Moreover, the best configuration is found to be CoEvolution with the
two best individuals from the cooperative population and the averaging of their
fitness using the weighted mean method.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [129] [MFiSP: A Multimodal Fire Spread Prediction Framework](https://arxiv.org/abs/2510.23934)
*Alec Sathiyamoorthy,Wenhao Zhou,Xiangmin Zhou,Xiaodong Li,Iqbal Gondal*

Main category: cs.CY

TL;DR: 提出了一种多模态火灾蔓延预测框架(MFiSP)，整合社交媒体数据和遥感观测，通过动态调整燃料地图来提升火灾蔓延预测精度


<details>
  <summary>Details</summary>
Motivation: 2019-2020年澳大利亚黑色夏季山火造成巨大破坏，凸显了改进火灾预测的紧迫性。传统火灾模型依赖专家手动解释和静态环境数据，存在准确性和操作限制

Method: 开发了多模态火灾蔓延预测框架，整合NASA FIRMS卫星影像和志愿者地理信息，在数据同化周期间调整燃料地图操作策略，动态调整火灾行为预测以匹配观测蔓延速率

Result: 使用合成生成的火灾事件多边形在多种场景下评估，结果表明整合多模态数据的MFiSP框架相比依赖专家知识和静态输入的传统方法能改善火灾蔓延预测

Conclusion: 多模态数据整合方法能够超越传统依赖FBAn专业知识和静态输入的火灾预测方法，提供更准确的火灾蔓延预测

Abstract: The 2019-2020 Black Summer bushfires in Australia devastated 19 million
hectares, destroyed 3,000 homes, and lasted seven months, demonstrating the
escalating scale and urgency of wildfire threats requiring better forecasting
for effective response. Traditional fire modeling relies on manual
interpretation by Fire Behaviour Analysts (FBAns) and static environmental
data, often leading to inaccuracies and operational limitations. Emerging data
sources, such as NASA's FIRMS satellite imagery and Volunteered Geographic
Information, offer potential improvements by enabling dynamic fire spread
prediction. This study proposes a Multimodal Fire Spread Prediction Framework
(MFiSP) that integrates social media data and remote sensing observations to
enhance forecast accuracy. By adapting fuel map manipulation strategies between
assimilation cycles, the framework dynamically adjusts fire behavior
predictions to align with the observed rate of spread. We evaluate the efficacy
of MFiSP using synthetically generated fire event polygons across multiple
scenarios, analyzing individual and combined impacts on forecast perimeters.
Results suggest that our MFiSP integrating multimodal data can improve fire
spread prediction beyond conventional methods reliant on FBAn expertise and
static inputs.

</details>


### [130] [AI for a Planet Under Pressure](https://arxiv.org/abs/2510.24373)
*Victor Galaz,Maria Schewenius,Jonathan F. Donges,Ingo Fetzer,Erik Zhivkoplias,Wolfram Barfuss,Louis Delannoy,Lan Wang-Erlandsson,Maximilian Gelbrecht,Jobst Heitzig,Jonas Hentati-Sundberg,Christopher Kennedy,Nielja Knecht,Romi Lotcheris,Miguel Mahecha,Andrew Merrie,David Montero,Timon McPhearson,Ahmed Mustafa,Magnus Nyström,Drew Purves,Juan C. Rocha,Masahiro Ryo,Claudia van der Salm,Samuel T. Segun,Anna B. Stephenson,Elizabeth Tellman,Felipe Tobar,Alice Vadrot*

Main category: cs.CY

TL;DR: 该报告探讨了AI在解决八大可持续发展挑战中的潜力和局限性，基于专家对话、AI支持的文献综述和八个具体领域的深入研究。


<details>
  <summary>Details</summary>
Motivation: AI已在多个科学领域推动突破，但能否负责任且有效地应用于解决复杂且相互关联的可持续发展挑战是一个关键问题。

Method: 采用迭代专家对话评估、AI支持的文献综述（涵盖8500多篇学术出版物）以及八个具体问题领域的专家深度研究。

Result: 构建了对AI在可持续发展中应用的潜力和局限性的理解，并为不同利益相关方提供了具体建议。

Conclusion: AI作为研究方法在应对可持续发展挑战方面具有重要潜力，但需要负责任的应用和多方协作。

Abstract: Artificial intelligence (AI) is already driving scientific breakthroughs in a
variety of research fields, ranging from the life sciences to mathematics. This
raises a critical question: can AI be applied both responsibly and effectively
to address complex and interconnected sustainability challenges? This report is
the result of a collaboration between the Stockholm resilience Centre
(Stockholm University), the Potsdam Institute for Climate Impact Research
(PIK), and Google DeepMind. Our work explores the potential and limitations of
using AI as a research method to help tackle eight broad sustainability
challenges. The results build on iterated expert dialogues and assessments, a
systematic AI-supported literature overview including over 8,500 academic
publications, and expert deep-dives into eight specific issue areas. The report
also includes recommendations to sustainability scientists, research funders,
the private sector, and philanthropies.

</details>


### [131] [Politically Speaking: LLMs on Changing International Affairs](https://arxiv.org/abs/2510.24582)
*Xuenan Cao,Wai Kei Chung,Ye Zhao,Lidia Mengyuan Zhou*

Main category: cs.CY

TL;DR: 该研究通过角色提示和相似性度量，发现四个主流大语言模型（OpenAI GPT、Google Gemini、Anthropic Claude、DeepSeek）在讨论中国和伊朗政治时，即使被要求从不同国家专家视角回答，生成内容仍高度同质化和固化。


<details>
  <summary>Details</summary>
Motivation: 研究关注LLM应用可能导致文化同质化和视角扁平化的问题，特别是预训练模型在讨论中国、伊朗、俄罗斯和美国政治时，倾向于重复西方世界固化的政治术语，尽管这些国家的实际情况在不断变化。

Method: 结合角色提示（让AI模拟俄罗斯和美国专家视角）和相似性度量方法，分析四个主流大语言模型生成的政治论述。

Result: 实验结果显示，关于伊朗和中国的AI生成论述在所有四个模型中都最为同质化和不变，即使改变提示视角和现实情况已发生变化。

Conclusion: 研究表明AI生成的政治论述存在显著同质化现象，特别是在涉及中国和伊朗的话题上，这对数字空间中政治论述的未来发展轨迹提出了重要警示。

Abstract: Ask your chatbot to impersonate an expert from Russia and an expert from US
and query it on Chinese politics. How might the outputs differ? Or, to prepare
ourselves for the worse, how might they converge? Scholars have raised concerns
LLM based applications can homogenize cultures and flatten perspectives. But
exactly how much does LLM generated outputs converge despite explicit different
role assignment? This study provides empirical evidence to the above question.
The critique centres on pretrained models regurgitating ossified political
jargons used in the Western world when speaking about China, Iran, Russian, and
US politics, despite changes in these countries happening daily or hourly. The
experiments combine role-prompting and similarity metrics. The results show
that AI generated discourses from four models about Iran and China are the most
homogeneous and unchanging across all four models, including OpenAI GPT, Google
Gemini, Anthropic Claude, and DeepSeek, despite the prompted perspective change
and the actual changes in real life. This study does not engage with history,
politics, or literature as traditional disciplinary approaches would; instead,
it takes cues from international and area studies and offers insight on the
future trajectory of shifting political discourse in a digital space
increasingly cannibalised by AI.

</details>
