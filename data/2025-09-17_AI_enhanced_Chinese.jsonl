{"id": "2509.12657", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2509.12657", "abs": "https://arxiv.org/abs/2509.12657", "authors": ["Siri Vennela Geddam", "Sruthi Ilapuram", "Kamesh Namuduri", "K L V Sai Prakash Sakuru"], "title": "An Analysis of Resource Allocation and User Association Strategies in Space-Air-Ground Integrated Networks", "comment": "13 pages, 9 figures, 5 tables", "summary": "Space-Air-Ground-Integrated Networks (SAGIN) enable seamless data\nconnectivity for applications such as smart transport, healthcare, smart\ncities, and disaster response through the coordinated use of low-earth orbit\n(LEO) satellites, base stations mounted with uncrewed aerial vehicles (UAV),\nand terrestrial infrastructure. This paper provides a detailed analysis of\nresource management frameworks, reviews the literature, and evaluates key\nmethods such as alternating optimization (AO), damped iterative water filling\n(DIWF), and genetic algorithms (GA) for resource allocation. MATLAB simulation\nresults benchmark these algorithms across 10,000 trials, demonstrating robust,\nfair, and low-latency resource allocation. In addition, this paper also\nanalyzes strategies for user association with terrestrial and aerial base\nstations during emergencies and network overloads. The main contributions\ninclude a comparative assessment of resource allocation strategies in SAGIN and\nan in-depth analysis of user association policies for emergency scenarios. The\nstudy provides guidance for designing resilient and efficient next-generation\nnetworks. Potential future research directions include investigating satellite\nhandover and multi-domain orchestration for SAGIN deployments.", "AI": {"tldr": "\u672c\u6587\u5bf9\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc(SAGIN)\u7684\u8d44\u6e90\u7ba1\u7406\u6846\u67b6\u8fdb\u884c\u4e86\u8be6\u7ec6\u5206\u6790\uff0c\u6bd4\u8f83\u4e86\u4ea4\u66ff\u4f18\u5316(AO)\u3001\u963b\u5c3c\u8fed\u4ee3\u6ce8\u6c34(DIWF)\u548c\u9057\u4f20\u7b97\u6cd5(GA)\u7b49\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7MATLAB\u4eff\u771f\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u7b97\u6cd5\u572810,000\u6b21\u8bd5\u9a8c\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u4ea4\u901a\u3001\u533b\u7597\u4fdd\u5065\u3001\u667a\u6167\u57ce\u5e02\u548c\u707e\u5bb3\u54cd\u5e94\u7b49\u5e94\u7528\u5bf9\u65e0\u7f1d\u6570\u636e\u8fde\u63a5\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u9700\u8981\u7814\u7a76\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u7684\u8d44\u6e90\u7ba1\u7406\u7b56\u7565\uff0c\u4ee5\u786e\u4fdd\u7f51\u7edc\u7684\u9c81\u68d2\u6027\u3001\u516c\u5e73\u6027\u548c\u4f4e\u5ef6\u8fdf\u7279\u6027\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u548cMATLAB\u4eff\u771f\u7684\u65b9\u6cd5\uff0c\u5bf9\u4ea4\u66ff\u4f18\u5316(AO)\u3001\u963b\u5c3c\u8fed\u4ee3\u6ce8\u6c34(DIWF)\u548c\u9057\u4f20\u7b97\u6cd5(GA)\u4e09\u79cd\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u5e76\u572810,000\u6b21\u8bd5\u9a8c\u4e2d\u8fdb\u884c\u4e86\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u7814\u7a76\u7684\u7b97\u6cd5\u80fd\u591f\u5b9e\u73b0\u9c81\u68d2\u3001\u516c\u5e73\u548c\u4f4e\u5ef6\u8fdf\u7684\u8d44\u6e90\u5206\u914d\u3002\u540c\u65f6\u5206\u6790\u4e86\u5728\u7d27\u6025\u60c5\u51b5\u548c\u7f51\u7edc\u8fc7\u8f7d\u65f6\u7528\u6237\u4e0e\u5730\u9762\u548c\u7a7a\u4e2d\u57fa\u7ad9\u7684\u5173\u8054\u7b56\u7565\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u63d0\u4f9b\u4e86\u8d44\u6e90\u5206\u914d\u7b56\u7565\u7684\u6bd4\u8f83\u8bc4\u4f30\u548c\u7d27\u6025\u573a\u666f\u4e0b\u7528\u6237\u5173\u8054\u7b56\u7565\u7684\u6df1\u5165\u5206\u6790\uff0c\u4e3a\u8bbe\u8ba1\u5f39\u6027\u548c\u9ad8\u6548\u7684\u4e0b\u4e00\u4ee3\u7f51\u7edc\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u536b\u661f\u5207\u6362\u548c\u591a\u57df\u7f16\u6392\u7b49\u3002"}}
{"id": "2509.12458", "categories": ["cs.RO", "cs.AR", "cs.CV", "cs.ET", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.12458", "abs": "https://arxiv.org/abs/2509.12458", "authors": ["\u00c0lmos Veres-Vit\u00e0lyos", "Genis Castillo Gomez-Raya", "Filip Lemic", "Daniel Johannes Bugelnig", "Bernhard Rinner", "Sergi Abadal", "Xavier Costa-P\u00e9rez"], "title": "Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles", "comment": "13 pages, 16 figures, 3 tables, 45 references", "summary": "Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for\nnavigating indoor and hard-to-reach areas, yet their significant constraints in\npayload and autonomy have largely prevented their use for complex tasks like\nhigh-quality 3-Dimensional (3D) reconstruction. To overcome this challenge, we\nintroduce a novel system architecture that enables fully autonomous,\nhigh-fidelity 3D scanning of static objects using UAVs weighing under 100\ngrams. Our core innovation lies in a dual-reconstruction pipeline that creates\na real-time feedback loop between data capture and flight control. A\nnear-real-time (near-RT) process uses Structure from Motion (SfM) to generate\nan instantaneous pointcloud of the object. The system analyzes the model\nquality on the fly and dynamically adapts the UAV's trajectory to intelligently\ncapture new images of poorly covered areas. This ensures comprehensive data\nacquisition. For the final, detailed output, a non-real-time (non-RT) pipeline\nemploys a Neural Radiance Fields (NeRF)-based Neural 3D Reconstruction (N3DR)\napproach, fusing SfM-derived camera poses with precise Ultra Wide-Band (UWB)\nlocation data to achieve superior accuracy. We implemented and validated this\narchitecture using Crazyflie 2.1 UAVs. Our experiments, conducted in both\nsingle- and multi-UAV configurations, conclusively show that dynamic trajectory\nadaptation consistently improves reconstruction quality over static flight\npaths. This work demonstrates a scalable and autonomous solution that unlocks\nthe potential of miniaturized UAVs for fine-grained 3D reconstruction in\nconstrained environments, a capability previously limited to much larger\nplatforms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e100\u514b\u4ee5\u4e0b\u5fae\u578b\u65e0\u4eba\u673a\u7684\u81ea\u4e3b\u9ad8\u4fdd\u771f3D\u626b\u63cf\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u91cd\u5efa\u6d41\u6c34\u7ebf\u5b9e\u73b0\u52a8\u6001\u8f68\u8ff9\u8c03\u6574\uff0c\u663e\u8457\u63d0\u5347\u91cd\u5efa\u8d28\u91cf", "motivation": "\u89e3\u51b3\u5fae\u578b\u65e0\u4eba\u673a\u5728\u6709\u6548\u8f7d\u8377\u548c\u81ea\u4e3b\u6027\u65b9\u9762\u7684\u9650\u5236\uff0c\u4f7f\u5176\u80fd\u591f\u6267\u884c\u590d\u6742\u7684\u9ad8\u8d28\u91cf3D\u91cd\u5efa\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u5ba4\u5185\u548c\u96be\u4ee5\u5230\u8fbe\u7684\u73af\u5883\u4e2d", "method": "\u91c7\u7528\u53cc\u91cd\u5efa\u6d41\u6c34\u7ebf\u67b6\u6784\uff1a\u8fd1\u5b9e\u65f6\u5904\u7406\u4f7f\u7528SfM\u751f\u6210\u5373\u65f6\u70b9\u4e91\u5e76\u52a8\u6001\u8c03\u6574\u98de\u884c\u8f68\u8ff9\uff1b\u975e\u5b9e\u65f6\u5904\u7406\u4f7f\u7528\u57fa\u4e8eNeRF\u7684N3DR\u65b9\u6cd5\uff0c\u7ed3\u5408SfM\u76f8\u673a\u4f4d\u59ff\u548cUWB\u5b9a\u4f4d\u6570\u636e", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\u52a8\u6001\u8f68\u8ff9\u9002\u5e94\u76f8\u6bd4\u9759\u6001\u98de\u884c\u8def\u5f84\u80fd\u6301\u7eed\u6539\u5584\u91cd\u5efa\u8d28\u91cf\uff0c\u5728\u5355\u673a\u548c\u591a\u673a\u914d\u7f6e\u4e0b\u5747\u8868\u73b0\u826f\u597d", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5fae\u578b\u65e0\u4eba\u673a\u5728\u53d7\u9650\u73af\u5883\u4e2d\u8fdb\u884c\u7cbe\u7ec63D\u91cd\u5efa\u7684\u53ef\u6269\u5c55\u81ea\u4e3b\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u7834\u4e86\u6b64\u524d\u53ea\u80fd\u7531\u5927\u578b\u5e73\u53f0\u5b9e\u73b0\u7684\u80fd\u529b\u9650\u5236"}}
{"id": "2509.12739", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.12739", "abs": "https://arxiv.org/abs/2509.12739", "authors": ["Trung Kien La", "Eric Guiffo Kaigom"], "title": "Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors", "comment": "$\\copyright$ 2025 the authors. This work has been accepted to the\n  10th IFAC Symposium on Mechatronic Systems & 14th IFAC Symposium on Robotics\n  July 15-18, 2025 || Paris, France for publication under a Creative Commons\n  Licence CC-BY-NC-ND", "summary": "In this work, deep neural networks made up of multiple hidden Long Short-Term\nMemory (LSTM) and Feedforward layers are trained to predict the thermal\nbehavior of the joint motors of robot manipulators. A model-free and scalable\napproach is adopted. It accommodates complexity and uncertainty challenges\nstemming from the derivation, identification, and validation of a large number\nof parameters of an approximation model that is hardly available. To this end,\nsensed joint torques are collected and processed to foresee the thermal\nbehavior of joint motors. Promising prediction results of the machine learning\nbased capture of the temperature dynamics of joint motors of a redundant robot\nwith seven joints are presented.", "AI": {"tldr": "\u4f7f\u7528\u591a\u5c42LSTM\u548c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9884\u6d4b\u673a\u5668\u4eba\u5173\u8282\u7535\u673a\u7684\u70ed\u884c\u4e3a\uff0c\u65e0\u9700\u590d\u6742\u7269\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u4f20\u611f\u626d\u77e9\u6570\u636e\u5b9e\u73b0\u6e29\u5ea6\u52a8\u6001\u9884\u6d4b\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5173\u8282\u7535\u673a\u70ed\u884c\u4e3a\u5efa\u6a21\u4e2d\u53c2\u6570\u591a\u3001\u63a8\u5bfc\u590d\u6742\u3001\u9a8c\u8bc1\u56f0\u96be\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u65e0\u9700\u7cbe\u786e\u7269\u7406\u6a21\u578b\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u591a\u5c42LSTM\u548c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u6536\u96c6\u548c\u5904\u7406\u4f20\u611f\u5173\u8282\u626d\u77e9\u6570\u636e\u6765\u9884\u6d4b\u7535\u673a\u6e29\u5ea6\u52a8\u6001\u3002", "result": "\u5728\u4e03\u5173\u8282\u5197\u4f59\u673a\u5668\u4eba\u4e0a\u83b7\u5f97\u4e86\u6709\u524d\u666f\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u6210\u529f\u6355\u6349\u4e86\u5173\u8282\u7535\u673a\u7684\u6e29\u5ea6\u52a8\u6001\u7279\u6027\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e3a\u673a\u5668\u4eba\u5173\u8282\u7535\u673a\u70ed\u884c\u4e3a\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u3001\u53ef\u6269\u5c55\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u6311\u6218\u3002"}}
{"id": "2509.12740", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.12740", "abs": "https://arxiv.org/abs/2509.12740", "authors": ["Eric Guiffo Kaigom"], "title": "Deep Generative and Discriminative Digital Twin endowed with Variational Autoencoder for Unsupervised Predictive Thermal Condition Monitoring of Physical Robots in Industry 6.0 and Society 6.0", "comment": "$\\copyright$ 2025 the authors. This work has been accepted to the to\n  the 10th IFAC Symposium on Mechatronic Systems & 14th IFAC Symposium on\n  Robotics July 15-18, 2025 || Paris, France for publication under a Creative\n  Commons Licence CC-BY-NC-ND", "summary": "Robots are unrelentingly used to achieve operational efficiency in Industry\n4.0 along with symbiotic and sustainable assistance for the work-force in\nIndustry 5.0. As resilience, robustness, and well-being are required in\nanti-fragile manufacturing and human-centric societal tasks, an autonomous\nanticipation and adaption to thermal saturation and burns due to motors\noverheating become instrumental for human safety and robot availability. Robots\nare thereby expected to self-sustain their performance and deliver user\nexperience, in addition to communicating their capability to other agents in\nadvance to ensure fully automated thermally feasible tasks, and prolong their\nlifetime without human intervention. However, the traditional robot shutdown,\nwhen facing an imminent thermal saturation, inhibits productivity in factories\nand comfort in the society, while cooling strategies are hard to implement\nafter the robot acquisition. In this work, smart digital twins endowed with\ngenerative AI, i.e., variational autoencoders, are leveraged to manage\nthermally anomalous and generate uncritical robot states. The notion of thermal\ndifficulty is derived from the reconstruction error of variational\nautoencoders. A robot can use this score to predict, anticipate, and share the\nthermal feasibility of desired motion profiles to meet requirements from\nemerging applications in Industry 6.0 and Society 6.0.", "AI": {"tldr": "\u5229\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u667a\u80fd\u6570\u5b57\u5b6a\u751f\u6280\u672f\u6765\u9884\u6d4b\u548c\u7ba1\u7406\u673a\u5668\u4eba\u70ed\u5f02\u5e38\u72b6\u6001\uff0c\u907f\u514d\u4f20\u7edf\u8fc7\u70ed\u505c\u673a\u95ee\u9898\uff0c\u63d0\u9ad8\u751f\u4ea7\u6548\u7387\u548c\u5b89\u5168\u6027", "motivation": "\u5de5\u4e1a4.0/5.0\u4e2d\u673a\u5668\u4eba\u9700\u8981\u81ea\u4e3b\u5e94\u5bf9\u7535\u673a\u8fc7\u70ed\u95ee\u9898\uff0c\u4f20\u7edf\u8fc7\u70ed\u505c\u673a\u65b9\u5f0f\u5f71\u54cd\u751f\u4ea7\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u9700\u8981\u65b0\u7684\u70ed\u7ba1\u7406\u65b9\u6848", "method": "\u91c7\u7528\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u751f\u6210\u5f0fAI\u667a\u80fd\u6570\u5b57\u5b6a\u751f\u6280\u672f\uff0c\u901a\u8fc7\u91cd\u6784\u8bef\u5dee\u63a8\u5bfc\u70ed\u96be\u5ea6\u8bc4\u5206\uff0c\u9884\u6d4b\u548c\u751f\u6210\u65e0\u4e34\u754c\u673a\u5668\u4eba\u72b6\u6001", "result": "\u673a\u5668\u4eba\u80fd\u591f\u9884\u6d4b\u3001\u9884\u671f\u548c\u5171\u4eab\u8fd0\u52a8\u8f6e\u5ed3\u7684\u70ed\u53ef\u884c\u6027\uff0c\u6ee1\u8db3\u5de5\u4e1a6.0\u548c\u793e\u4f1a6.0\u65b0\u5174\u5e94\u7528\u9700\u6c42", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u81ea\u4e3b\u7ba1\u7406\u70ed\u5f02\u5e38\uff0c\u5ef6\u957f\u4f7f\u7528\u5bff\u547d\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u70ed\u53ef\u884c\u4efb\u52a1\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884"}}
{"id": "2509.12367", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12367", "abs": "https://arxiv.org/abs/2509.12367", "authors": ["Daniel Lindmark", "Jonas Andersson", "Kenneth Bodin", "Tora Bodin", "Hugo B\u00f6rjesson", "Fredrik Nordfeldth", "Martin Servin"], "title": "An integrated process for design and control of lunar robotics using AI and simulation", "comment": "14 pages, 6 figures", "summary": "We envision an integrated process for developing lunar construction\nequipment, where physical design and control are explored in parallel. In this\npaper, we describe a technical framework that supports this process. It relies\non OpenPLX, a readable/writable declarative language that links CAD-models and\nautonomous systems to high-fidelity, real-time 3D simulations of contacting\nmultibody dynamics, machine regolith interaction forces, and non-ideal sensors.\nTo demonstrate its capabilities, we present two case studies, including an\nautonomous lunar rover that combines a vision-language model for navigation\nwith a reinforcement learning-based control policy for locomotion.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u6846\u67b6OpenPLX\uff0c\u7528\u4e8e\u5e76\u884c\u5f00\u53d1\u6708\u7403\u5efa\u8bbe\u8bbe\u5907\u7684\u7269\u7406\u8bbe\u8ba1\u548c\u63a7\u5236\u7cfb\u7edf\uff0c\u901a\u8fc7\u53ef\u8bfb\u5199\u7684\u58f0\u660e\u5f0f\u8bed\u8a00\u8fde\u63a5CAD\u6a21\u578b\u3001\u81ea\u4e3b\u7cfb\u7edf\u548c\u9ad8\u4fdd\u771f\u5b9e\u65f63D\u4eff\u771f\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u6708\u7403\u5efa\u8bbe\u8bbe\u5907\u7684\u96c6\u6210\u5f00\u53d1\u8fc7\u7a0b\uff0c\u9700\u8981\u5c06\u7269\u7406\u8bbe\u8ba1\u548c\u63a7\u5236\u63a2\u7d22\u5e76\u884c\u8fdb\u884c\uff0c\u9700\u8981\u4e00\u4e2a\u6280\u672f\u6846\u67b6\u6765\u8fde\u63a5CAD\u5efa\u6a21\u3001\u81ea\u4e3b\u7cfb\u7edf\u548c\u9ad8\u4fdd\u771f\u4eff\u771f\u3002", "method": "\u5f00\u53d1\u4e86OpenPLX\u58f0\u660e\u5f0f\u8bed\u8a00\uff0c\u8fde\u63a5CAD\u6a21\u578b\u548c\u81ea\u4e3b\u7cfb\u7edf\u5230\u9ad8\u4fdd\u771f\u5b9e\u65f63D\u4eff\u771f\uff0c\u5305\u62ec\u591a\u4f53\u52a8\u529b\u5b66\u63a5\u89e6\u3001\u673a\u5668-\u6708\u58e4\u76f8\u4e92\u4f5c\u7528\u529b\u548c\u975e\u7406\u60f3\u4f20\u611f\u5668\u6a21\u62df\u3002\u901a\u8fc7\u81ea\u4e3b\u6708\u7403\u6f2b\u6e38\u8f66\u7684\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u5c55\u793a\u4e86\u6846\u67b6\u7684\u80fd\u529b\uff0c\u5305\u62ec\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5bfc\u822a\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u8fd0\u52a8\u63a7\u5236\u7b56\u7565\u7684\u81ea\u4e3b\u6708\u7403\u6f2b\u6e38\u8f66\u6848\u4f8b\u3002", "conclusion": "OpenPLX\u6846\u67b6\u4e3a\u6708\u7403\u5efa\u8bbe\u8bbe\u5907\u7684\u96c6\u6210\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u652f\u6491\uff0c\u80fd\u591f\u5e76\u884c\u63a2\u7d22\u7269\u7406\u8bbe\u8ba1\u548c\u63a7\u5236\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u9ad8\u4fdd\u771f\u4eff\u771f\u9a8c\u8bc1\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2509.12214", "categories": ["eess.SY", "cs.CE", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12214", "abs": "https://arxiv.org/abs/2509.12214", "authors": ["An Nguyen", "Hung Pham", "Cuong Do"], "title": "A Cost-Optimization Model for EV Charging Stations Utilizing Solar Energy and Variable Pricing", "comment": null, "summary": "This paper presents a cost optimization framework for electric vehicle (EV)\ncharging stations that leverages on-site photovoltaic (PV) generation and\nexplicitly accounts for electricity price uncertainty through a Bertsimas--Sim\nrobust formulation. The model is formulated as a linear program that satisfies\nvehicle energy demands, respects charging and grid capacity constraints, and\nminimizes procurement cost. Evaluations on real charging data from the Caltech\nACN dataset show average savings of about 12\\% compared to a\nfirst-come--first-served baseline, with peak monthly reductions up to 19.2\\%. A\nlightweight sensitivity analysis indicates that a modest $\\sim$5\\% increase in\nnominal cost can reduce worst-case exposure by 14\\%. Computational tests\nconfirm real-time feasibility, with instances of up to 50 concurrent EVs solved\nin under 5 seconds on a standard laptop. The proposed method provides a\npractical, grid-friendly, and scalable solution for future EV charging\noperations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u6210\u672c\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528\u73b0\u573a\u5149\u4f0f\u53d1\u7535\u5e76\u901a\u8fc7Bertsimas-Sim\u9c81\u68d2\u516c\u5f0f\u5904\u7406\u7535\u4ef7\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e8612%\u7684\u5e73\u5747\u6210\u672c\u8282\u7701\u548c\u5b9e\u65f6\u8ba1\u7b97\u53ef\u884c\u6027\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u666e\u53ca\uff0c\u5145\u7535\u7ad9\u9700\u8981\u4f18\u5316\u8fd0\u8425\u6210\u672c\uff0c\u540c\u65f6\u5e94\u5bf9\u7535\u4ef7\u4e0d\u786e\u5b9a\u6027\u548c\u7535\u7f51\u7ea6\u675f\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u4ef7\u683c\u6ce2\u52a8\u98ce\u9669\u3002", "method": "\u91c7\u7528\u7ebf\u6027\u89c4\u5212\u6a21\u578b\uff0c\u7ed3\u5408\u73b0\u573a\u5149\u4f0f\u53d1\u7535\uff0c\u4f7f\u7528Bertsimas-Sim\u9c81\u68d2\u4f18\u5316\u65b9\u6cd5\u5904\u7406\u7535\u4ef7\u4e0d\u786e\u5b9a\u6027\uff0c\u6ee1\u8db3\u8f66\u8f86\u9700\u6c42\u3001\u5145\u7535\u5bb9\u91cf\u548c\u7535\u7f51\u7ea6\u675f\u3002", "result": "\u5728Caltech ACN\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u663e\u793a\u5e73\u5747\u8282\u770112%\u6210\u672c\uff0c\u6708\u5ea6\u5cf0\u503c\u8282\u7701\u8fbe19.2%\uff0c50\u8f86\u7535\u52a8\u6c7d\u8f66\u540c\u65f6\u5145\u7535\u7684\u5b9e\u4f8b\u53ef\u57285\u79d2\u5185\u6c42\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u7535\u7f51\u53cb\u597d\u4e14\u53ef\u6269\u5c55\u7684\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u8fd0\u8425\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u6709\u6548\u964d\u4f4e\u6210\u672c\u548c\u98ce\u9669\u3002"}}
{"id": "2509.13141", "categories": ["econ.GN", "physics.soc-ph", "q-fin.EC", "stat.AP", "62P20, 90-10, 90B90"], "pdf": "https://arxiv.org/pdf/2509.13141", "abs": "https://arxiv.org/abs/2509.13141", "authors": ["L\u00e1szl\u00f3 Csat\u00f3"], "title": "A hidden benefit of incomplete round-robin tournaments: Encouraging offensive play", "comment": null, "summary": "This paper aims to explore the impact of tournament design on the incentives\nof the contestants. We develop a simulation framework to quantify the potential\ngain and loss from attacking based on changes in the probability of reaching\nthe critical ranking thresholds. The model is applied to investigate the\n2024/25 UEFA Champions League reform. The novel incomplete round-robin league\nphase is found to create more powerful incentives for offensive play than the\nprevious group stage, with an average increase of 119\\% (58\\%) regarding the\nfirst (second) prize. Our study provides the first demonstration that the\ntournament format itself can strongly influence team behaviour in sports.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6a21\u62df\u5206\u6790\u53d1\u73b0\uff0c2024/25\u8d5b\u5b63\u6b27\u51a0\u8054\u8d5b\u6539\u9769\u540e\u7684\u65b0\u8d5b\u5236\u76f8\u6bd4\u4e4b\u524d\u7684\u5c0f\u7ec4\u8d5b\u9636\u6bb5\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u7403\u961f\u8fdb\u653b\u6bd4\u8d5b\u7684\u6fc0\u52b1\uff0c\u5e73\u5747\u63d0\u5347\u5e45\u5ea6\u8fbe119%\uff08\u4e00\u7b49\u5956\uff09\u548c58%\uff08\u4e8c\u7b49\u5956\uff09\u3002", "motivation": "\u63a2\u7d22\u9526\u6807\u8d5b\u8bbe\u8ba1\u5bf9\u53c2\u8d5b\u8005\u6fc0\u52b1\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5206\u67902024/25\u8d5b\u5b63\u6b27\u51a0\u8054\u8d5b\u6539\u9769\u540e\u65b0\u8d5b\u5236\u5bf9\u7403\u961f\u6bd4\u8d5b\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6a21\u62df\u6846\u67b6\u6765\u91cf\u5316\u57fa\u4e8e\u5173\u952e\u6392\u540d\u95e8\u69db\u6982\u7387\u53d8\u5316\u7684\u653b\u51fb\u884c\u4e3a\u6f5c\u5728\u6536\u76ca\u548c\u635f\u5931\uff0c\u5e76\u5c06\u8be5\u6a21\u578b\u5e94\u7528\u4e8e\u5206\u67902024/25\u8d5b\u5b63\u6b27\u51a0\u8054\u8d5b\u6539\u9769\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u65b0\u7684\u4e0d\u5b8c\u6574\u5faa\u73af\u8054\u8d5b\u9636\u6bb5\u76f8\u6bd4\u4e4b\u524d\u7684\u5c0f\u7ec4\u8d5b\u9636\u6bb5\u521b\u9020\u4e86\u66f4\u5f3a\u7684\u8fdb\u653b\u6bd4\u8d5b\u6fc0\u52b1\uff0c\u4e00\u7b49\u5956\u548c\u4e8c\u7b49\u5956\u7684\u5e73\u5747\u63d0\u5347\u5e45\u5ea6\u5206\u522b\u4e3a119%\u548c58%\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u8bc1\u660e\u9526\u6807\u8d5b\u5f62\u5f0f\u672c\u8eab\u80fd\u591f\u5f3a\u70c8\u5f71\u54cd\u4f53\u80b2\u8fd0\u52a8\u4e2d\u7403\u961f\u884c\u4e3a\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u4e3a\u8d5b\u4e8b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2509.12251", "categories": ["cs.AI", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.12251", "abs": "https://arxiv.org/abs/2509.12251", "authors": ["Duong Q. Nguyen", "Quy P. Nguyen", "Nguyen Van Nhon", "Quang-Thinh Bui", "H. Nguyen-Xuan"], "title": "V-Math: An Agentic Approach to the Vietnamese National High School Graduation Mathematics Exams", "comment": null, "summary": "This paper develops an autonomous agentic framework called V-Math that aims\nto assist Vietnamese high school students in preparing for the National High\nSchool Graduation Mathematics Exams (NHSGMEs). The salient framework integrates\nthree specialized AI agents: a specification-matrix-conditioned question\ngenerator, a solver/explainer for detailed step-by-step reasoning, and a\npersonalized tutor that adapts to student performance. Beyond enabling\nself-paced student practice, V-Math supports teachers by generating innovative,\ncompliant exam questions and building diverse, high-quality question banks.\nThis reduces manual workload and enriches instructional resources. We describe\nthe system architecture, focusing on practice modes for learners and\nteacher-oriented features for question generation. Preliminary evaluations\ndemonstrate that V-Math produces matrix-aligned exams with high solution\naccuracy, delivers coherent explanations, and enhances the variety of practice\nmaterials. These results highlight its potential to support scalable, equitable\nmathematics preparation aligned with national standards while also empowering\nteachers through AI-assisted exam creation.", "AI": {"tldr": "V-Math\u662f\u4e00\u4e2a\u4e3a\u8d8a\u5357\u9ad8\u4e2d\u751f\u8bbe\u8ba1\u7684\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u56fd\u5bb6\u9ad8\u4e2d\u6570\u5b66\u6bd5\u4e1a\u8003\u8bd5\u51c6\u5907\uff0c\u5305\u542b\u95ee\u9898\u751f\u6210\u3001\u89e3\u9898\u89e3\u91ca\u548c\u4e2a\u6027\u5316\u8f85\u5bfc\u4e09\u4e2aAI\u4ee3\u7406\uff0c\u652f\u6301\u5b66\u751f\u81ea\u4e3b\u7ec3\u4e60\u548c\u6559\u5e08\u751f\u6210\u5408\u89c4\u8bd5\u9898\u3002", "motivation": "\u5e2e\u52a9\u8d8a\u5357\u9ad8\u4e2d\u751f\u66f4\u597d\u5730\u51c6\u5907\u56fd\u5bb6\u9ad8\u4e2d\u6570\u5b66\u6bd5\u4e1a\u8003\u8bd5\uff0c\u540c\u65f6\u51cf\u8f7b\u6559\u5e08\u624b\u52a8\u51fa\u9898\u7684\u5de5\u4f5c\u8d1f\u62c5\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u7684\u9ad8\u8d28\u91cf\u9898\u5e93\u8d44\u6e90\u3002", "method": "\u5f00\u53d1\u5305\u542b\u4e09\u4e2a\u4e13\u95e8AI\u4ee3\u7406\u7684\u6846\u67b6\uff1a\u57fa\u4e8e\u89c4\u8303\u77e9\u9635\u7684\u95ee\u9898\u751f\u6210\u5668\u3001\u63d0\u4f9b\u8be6\u7ec6\u9010\u6b65\u63a8\u7406\u7684\u89e3\u9898\u5668/\u89e3\u91ca\u5668\uff0c\u4ee5\u53ca\u6839\u636e\u5b66\u751f\u8868\u73b0\u81ea\u9002\u5e94\u7684\u4e2a\u6027\u5316\u5bfc\u5e08\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u663e\u793aV-Math\u80fd\u751f\u6210\u7b26\u5408\u77e9\u9635\u8981\u6c42\u7684\u8003\u8bd5\u9898\u76ee\uff0c\u5177\u6709\u9ad8\u89e3\u9898\u51c6\u786e\u7387\uff0c\u63d0\u4f9b\u8fde\u8d2f\u7684\u89e3\u91ca\uff0c\u5e76\u4e30\u5bcc\u4e86\u7ec3\u4e60\u6750\u6599\u7684\u591a\u6837\u6027\u3002", "conclusion": "V-Math\u6709\u6f5c\u529b\u652f\u6301\u7b26\u5408\u56fd\u5bb6\u6807\u51c6\u7684\u53ef\u6269\u5c55\u3001\u516c\u5e73\u7684\u6570\u5b66\u5907\u8003\uff0c\u540c\u65f6\u901a\u8fc7AI\u8f85\u52a9\u7684\u8003\u8bd5\u521b\u5efa\u8d4b\u80fd\u6559\u5e08\u3002"}}
{"id": "2509.12217", "categories": ["stat.AP", "62-01, 62P10 (Primary), 62-04, 62F10, 62H12 (Secondary)", "G.3; J.3"], "pdf": "https://arxiv.org/pdf/2509.12217", "abs": "https://arxiv.org/abs/2509.12217", "authors": ["Wan Nor Arifin", "Umi Kalsom Yusof"], "title": "Correcting for partial verification bias in diagnostic accuracy studies: A tutorial using R", "comment": "20 pages, 2 tables", "summary": "Diagnostic tests play a crucial role in medical care. Thus any new diagnostic\ntests must undergo a thorough evaluation. New diagnostic tests are evaluated in\ncomparison with the respective gold standard tests. The performance of binary\ndiagnostic tests is quantified by accuracy measures, with sensitivity and\nspecificity being the most important measures. In any diagnostic accuracy\nstudy, the estimates of these measures are often biased owing to selective\nverification of the patients, which is referred to as partial verification\nbias. Several methods for correcting partial verification bias are available\ndepending on the scale of the index test, target outcome and missing data\nmechanism. However, these are not easily accessible to the researchers due to\nthe complexity of the methods. This article aims to provide a brief overview of\nthe methods available to correct for partial verification bias involving a\nbinary diagnostic test and provide a practical tutorial on how to implement the\nmethods using the statistical programming language R.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u5173\u4e8e\u4e8c\u5143\u8bca\u65ad\u6d4b\u8bd5\u4e2d\u90e8\u5206\u9a8c\u8bc1\u504f\u501a\u6821\u6b63\u65b9\u6cd5\u7684\u7efc\u8ff0\u548cR\u8bed\u8a00\u5b9e\u73b0\u6559\u7a0b", "motivation": "\u8bca\u65ad\u6d4b\u8bd5\u5728\u533b\u7597\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u65b0\u6d4b\u8bd5\u8bc4\u4f30\u65f6\u5b58\u5728\u90e8\u5206\u9a8c\u8bc1\u504f\u501a\u95ee\u9898\uff0c\u73b0\u6709\u6821\u6b63\u65b9\u6cd5\u590d\u6742\u4e14\u4e0d\u6613\u88ab\u7814\u7a76\u8005\u638c\u63e1", "method": "\u7efc\u8ff0\u4e86\u9488\u5bf9\u4e8c\u5143\u8bca\u65ad\u6d4b\u8bd5\u7684\u90e8\u5206\u9a8c\u8bc1\u504f\u501a\u6821\u6b63\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f7f\u7528R\u8bed\u8a00\u5b9e\u73b0\u8fd9\u4e9b\u65b9\u6cd5\u7684\u5b9e\u7528\u6559\u7a0b", "result": "\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u65b9\u6cd5\u6765\u6821\u6b63\u8bca\u65ad\u51c6\u786e\u6027\u7814\u7a76\u4e2d\u7684\u90e8\u5206\u9a8c\u8bc1\u504f\u501a", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u65b9\u6cd5\u7efc\u8ff0\u548cR\u5b9e\u73b0\u6559\u7a0b\uff0c\u4f7f\u590d\u6742\u7684\u90e8\u5206\u9a8c\u8bc1\u504f\u501a\u6821\u6b63\u65b9\u6cd5\u66f4\u6613\u4e8e\u7814\u7a76\u4eba\u5458\u5e94\u7528"}}
{"id": "2509.12240", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2509.12240", "abs": "https://arxiv.org/abs/2509.12240", "authors": ["Botao Zhu", "Xianbin Wang"], "title": "Accurate Trust Evaluation for Effective Operation of Social IoT Systems via Hypergraph-Enabled Self-Supervised Contrastive Learning", "comment": null, "summary": "Social Internet-of-Things (IoT) enhances collaboration between devices by\nendowing IoT systems with social attributes. However, calculating trust between\ndevices based on complex and dynamic social attributes-similar to trust\nformation mechanisms in human society-poses a significant challenge. To address\nthis issue, this paper presents a new hypergraph-enabled self-supervised\ncontrastive learning (HSCL) method to accurately determine trust values between\ndevices. To implement the proposed HSCL, hypergraphs are first used to discover\nand represent high-order relationships based on social attributes. Hypergraph\naugmentation is then applied to enhance the semantics of the generated social\nhypergraph, followed by the use of a parameter-sharing hypergraph neural\nnetwork to nonlinearly fuse the high-order social relationships. Additionally,\na self-supervised contrastive learning method is utilized to obtain meaningful\ndevice embeddings by conducting comparisons among devices, hyperedges, and\ndevice-to-hyperedge relationships. Finally, trust values between devices are\ncalculated based on device embeddings that encapsulate high-order social\nrelationships. Extensive experiments reveal that the proposed HSCL method\noutperforms baseline algorithms in effectively distinguishing between trusted\nand untrusted nodes and identifying the most trusted node.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d85\u56fe\u7684\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60(HSCL)\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d85\u56fe\u5efa\u6a21\u9ad8\u9636\u793e\u4ea4\u5173\u7cfb\uff0c\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u83b7\u5f97\u8bbe\u5907\u5d4c\u5165\uff0c\u4ece\u800c\u51c6\u786e\u8ba1\u7b97\u7269\u8054\u7f51\u8bbe\u5907\u95f4\u7684\u4fe1\u4efb\u503c", "motivation": "\u89e3\u51b3\u5728\u5177\u6709\u793e\u4ea4\u5c5e\u6027\u7684\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\uff0c\u57fa\u4e8e\u590d\u6742\u52a8\u6001\u793e\u4ea4\u5c5e\u6027\u8ba1\u7b97\u8bbe\u5907\u95f4\u4fe1\u4efb\u503c\u7684\u6311\u6218\uff0c\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u793e\u4f1a\u7684\u4fe1\u4efb\u5f62\u6210\u673a\u5236", "method": "\u4f7f\u7528\u8d85\u56fe\u53d1\u73b0\u548c\u8868\u793a\u57fa\u4e8e\u793e\u4ea4\u5c5e\u6027\u7684\u9ad8\u9636\u5173\u7cfb\uff0c\u8fdb\u884c\u8d85\u56fe\u589e\u5f3a\u4ee5\u4e30\u5bcc\u8bed\u4e49\uff0c\u91c7\u7528\u53c2\u6570\u5171\u4eab\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u975e\u7ebf\u6027\u878d\u5408\u9ad8\u9636\u793e\u4ea4\u5173\u7cfb\uff0c\u5229\u7528\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6bd4\u8f83\u8bbe\u5907\u3001\u8d85\u8fb9\u548c\u8bbe\u5907-\u8d85\u8fb9\u5173\u7cfb\u6765\u83b7\u5f97\u6709\u610f\u4e49\u7684\u8bbe\u5907\u5d4c\u5165", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cHSCL\u65b9\u6cd5\u5728\u6709\u6548\u533a\u5206\u53ef\u4fe1\u4e0e\u4e0d\u53ef\u4fe1\u8282\u70b9\u4ee5\u53ca\u8bc6\u522b\u6700\u53ef\u4fe1\u8282\u70b9\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5", "conclusion": "HSCL\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u8ba1\u7b97\u7269\u8054\u7f51\u8bbe\u5907\u95f4\u7684\u4fe1\u4efb\u503c\uff0c\u4e3a\u793e\u4ea4\u7269\u8054\u7f51\u4e2d\u7684\u4fe1\u4efb\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13198", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2509.13198", "abs": "https://arxiv.org/abs/2509.13198", "authors": ["Th\u00e0nh Nguyen", "Alexander Teytelboym", "Shai Vardi"], "title": "Efficiency, Envy, and Incentives in Combinatorial Assignment", "comment": "Abstract published in EC'25\n  (https://dl.acm.org/doi/abs/10.1145/3736252.3742573)", "summary": "Ensuring efficiency and envy-freeness in allocating indivisible goods without\nmoney often requires randomization. However, existing combinatorial assignment\nmechanisms (for applications such as course allocation, food banks, and refugee\nresettlement) guarantee these properties either ex ante or ex post, but not\nboth. We propose a new class of mechanisms based on Competitive Equilibrium\nfrom Random Incomes (CERI): Agents receive random token budgets and select\noptimal lotteries at competitive prices that clear markets in expectation. Our\nmain insight is to let the CERI price vector guide all ex-post allocations. We\nshow that all ordinally efficient allocations are CERI allocations, which can\nbe implemented as lotteries over near-feasible Pareto-efficient outcomes. With\nidentical budget distributions, CERI allocations are ordinally envy-free; with\nbudget distributions on small supports, ex-post allocations are envy-free up to\none good. Moreover, we design an asymptotically efficient implementation of\nCERI that satisfies a strong new non-manipulability property in large markets.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u968f\u673a\u6536\u5165\u7ade\u4e89\u5747\u8861(CERI)\u7684\u65b0\u673a\u5236\uff0c\u901a\u8fc7\u968f\u673a\u4ee3\u5e01\u9884\u7b97\u548c\u7ade\u4e89\u6027\u4ef7\u683c\u5b9e\u73b0\u5206\u914d\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u540c\u65f6\u6ee1\u8db3\u4e8b\u524d\u548c\u4e8b\u540e\u5c5e\u6027", "motivation": "\u73b0\u6709\u7ec4\u5408\u5206\u914d\u673a\u5236\u53ea\u80fd\u4fdd\u8bc1\u4e8b\u524d\u6216\u4e8b\u540e\u7684\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u4e24\u8005\uff0c\u9700\u8981\u65b0\u7684\u673a\u5236\u8bbe\u8ba1", "method": "\u4f7f\u7528\u7ade\u4e89\u5747\u8861\u4ece\u968f\u673a\u6536\u5165(CERI)\u65b9\u6cd5\uff0c\u4ee3\u7406\u4eba\u83b7\u5f97\u968f\u673a\u4ee3\u5e01\u9884\u7b97\uff0c\u5728\u7ade\u4e89\u6027\u4ef7\u683c\u4e0b\u9009\u62e9\u6700\u4f18\u5f69\u7968\uff0c\u4ef7\u683c\u5411\u91cf\u6307\u5bfc\u6240\u6709\u4e8b\u540e\u5206\u914d", "result": "\u6240\u6709\u5e8f\u6570\u6709\u6548\u5206\u914d\u90fd\u662fCERI\u5206\u914d\uff0c\u53ef\u4f5c\u4e3a\u8fd1\u4e4e\u53ef\u884c\u7684\u5e15\u7d2f\u6258\u6709\u6548\u7ed3\u679c\u7684\u5f69\u7968\u5b9e\u73b0\uff1b\u76f8\u540c\u9884\u7b97\u5206\u5e03\u4e0bCERI\u5206\u914d\u662f\u5e8f\u6570\u65e0\u5ac9\u5992\u7684\uff1b\u5c0f\u652f\u6301\u9884\u7b97\u5206\u5e03\u4e0b\u4e8b\u540e\u5206\u914d\u8fbe\u5230\u5355\u7269\u54c1\u65e0\u5ac9\u5992", "conclusion": "CERI\u673a\u5236\u5728\u5927\u578b\u5e02\u573a\u4e2d\u6ee1\u8db3\u5f3a\u975e\u64cd\u7eb5\u6027\uff0c\u5b9e\u73b0\u4e86\u6548\u7387\u548c\u516c\u5e73\u6027\u7684\u7edf\u4e00\uff0c\u4e3a\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u7684\u65e0\u8d27\u5e01\u5206\u914d\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.12379", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12379", "abs": "https://arxiv.org/abs/2509.12379", "authors": ["Divyam Goel", "Yufei Wang", "Tiancheng Wu", "Guixiu Qiao", "Pavel Piliptchak", "David Held", "Zackory Erickson"], "title": "Geometric Red-Teaming for Robotic Manipulation", "comment": "Accepted at the 9th Annual Conference on Robot Learning (CoRL 2025,\n  Oral)", "summary": "Standard evaluation protocols in robotic manipulation typically assess policy\nperformance over curated, in-distribution test sets, offering limited insight\ninto how systems fail under plausible variation. We introduce Geometric\nRed-Teaming (GRT), a red-teaming framework that probes robustness through\nobject-centric geometric perturbations, automatically generating CrashShapes --\nstructurally valid, user-constrained mesh deformations that trigger\ncatastrophic failures in pre-trained manipulation policies. The method\nintegrates a Jacobian field-based deformation model with a gradient-free,\nsimulator-in-the-loop optimization strategy. Across insertion, articulation,\nand grasping tasks, GRT consistently discovers deformations that collapse\npolicy performance, revealing brittle failure modes missed by static\nbenchmarks. By combining task-level policy rollouts with constraint-aware shape\nexploration, we aim to build a general purpose framework for structured,\nobject-centric robustness evaluation in robotic manipulation. We additionally\nshow that fine-tuning on individual CrashShapes, a process we refer to as\nblue-teaming, improves task success by up to 60 percentage points on those\nshapes, while preserving performance on the original object, demonstrating the\nutility of red-teamed geometries for targeted policy refinement. Finally, we\nvalidate both red-teaming and blue-teaming results with a real robotic arm,\nobserving that simulated CrashShapes reduce task success from 90% to as low as\n22.5%, and that blue-teaming recovers performance to up to 90% on the\ncorresponding real-world geometry -- closely matching simulation outcomes.\nVideos and code can be found on our project website:\nhttps://georedteam.github.io/ .", "AI": {"tldr": "\u63d0\u51faGeometric Red-Teaming (GRT)\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u8c61\u51e0\u4f55\u6270\u52a8\u81ea\u52a8\u751f\u6210CrashShapes\u6765\u6d4b\u8bd5\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u9057\u6f0f\u7684\u8106\u5f31\u6027\uff0c\u5e76\u901a\u8fc7blue-teaming\u5fae\u8c03\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u64cd\u4f5c\u8bc4\u4f30\u534f\u8bae\u4ec5\u9488\u5bf9\u7cbe\u9009\u7684\u5206\u5e03\u5185\u6d4b\u8bd5\u96c6\uff0c\u65e0\u6cd5\u63ed\u793a\u7cfb\u7edf\u5728\u5408\u7406\u53d8\u5316\u4e0b\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\u6765\u7cfb\u7edf\u6027\u6d4b\u8bd5\u7b56\u7565\u7684\u51e0\u4f55\u9c81\u68d2\u6027\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u96c5\u53ef\u6bd4\u573a\u7684\u53d8\u5f62\u6a21\u578b\u548c\u65e0\u68af\u5ea6\u3001\u6a21\u62df\u5668\u5728\u73af\u7684\u4f18\u5316\u7b56\u7565\uff0c\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u6709\u6548\u4e14\u7528\u6237\u7ea6\u675f\u7684\u7f51\u683c\u53d8\u5f62(CrashShapes)\uff0c\u901a\u8fc7\u4efb\u52a1\u7ea7\u7b56\u7565\u6267\u884c\u548c\u7ea6\u675f\u611f\u77e5\u5f62\u72b6\u63a2\u7d22\u8fdb\u884c\u9c81\u68d2\u6027\u8bc4\u4f30\u3002", "result": "\u5728\u63d2\u5165\u3001\u5173\u8282\u64cd\u4f5c\u548c\u6293\u53d6\u4efb\u52a1\u4e2d\uff0cGRT\u59cb\u7ec8\u53d1\u73b0\u5bfc\u81f4\u7b56\u7565\u6027\u80fd\u5d29\u6e83\u7684\u53d8\u5f62\uff0c\u5c06\u4efb\u52a1\u6210\u529f\u7387\u4ece90%\u964d\u81f322.5%\u3002\u901a\u8fc7blue-teaming\u5fae\u8c03\uff0c\u5728\u7279\u5b9aCrashShapes\u4e0a\u7684\u4efb\u52a1\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe60\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u5728\u539f\u59cb\u7269\u4f53\u4e0a\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "GRT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u5bf9\u8c61\u4e2d\u5fc3\u9c81\u68d2\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u53d1\u73b0\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u9057\u6f0f\u7684\u8106\u5f31\u6027\uff0c\u751f\u6210\u7684CrashShapes\u53ef\u7528\u4e8e\u9488\u5bf9\u6027\u7b56\u7565\u6539\u8fdb\uff0c\u5728\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u4eff\u771f\u7ed3\u679c\u4e0e\u5b9e\u9645\u8868\u73b0\u9ad8\u5ea6\u4e00\u81f4\u3002"}}
{"id": "2509.12225", "categories": ["eess.SY", "cs.GT", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12225", "abs": "https://arxiv.org/abs/2509.12225", "authors": ["Siying Huang", "Yifen Mu", "Ge Chen"], "title": "Private Markovian Equilibrium in Stackelberg Markov Games for Smart Grid Demand Response", "comment": null, "summary": "The increasing integration of renewable energy introduces a great challenge\nto the supply and demand balance of the power grid. To address this challenge,\nthis paper formulates a Stackelberg Markov game (SMG) between an aggregator and\nmultiple users, where the aggregator sets electricity prices and users make\ndemand and storage decisions. Considering that users' storage levels are\nprivate information, we introduce private states and propose the new concepts\nof private Markovian strategies (PMS) and private Markovian equilibrium (PME).\nWe establish the existence of a pure PME in the lower-level Markov game and\nprove that it can be computed in polynomial time. Notably, computing\nequilibrium in general Markov games is hard, and polynomial-time algorithms are\nrarely available. Based on these theoretical results, we develop a scalable\nsolution framework combining centralized and decentralized algorithms for the\nlower-level PME computation with upper-level pricing optimization. Numerical\nsimulations with up to 50 users based on real data validate the effectiveness\nand scalability of the proposed methods, whereas prior studies typically\nconsider no more than 5 users.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u53ef\u518d\u751f\u80fd\u6e90\u5e76\u7f51\u5e26\u6765\u7684\u4f9b\u9700\u5e73\u8861\u6311\u6218\u7684Stackelberg\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u6a21\u578b\uff0c\u5f15\u5165\u4e86\u79c1\u6709\u9a6c\u5c14\u53ef\u592b\u7b56\u7565\u548c\u5747\u8861\u6982\u5ff5\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u6269\u5c55\u7684\u6c42\u89e3\u6846\u67b6\u3002", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u5e76\u7f51\u7ed9\u7535\u7f51\u4f9b\u9700\u5e73\u8861\u5e26\u6765\u5de8\u5927\u6311\u6218\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u7535\u4ef7\u673a\u5236\u548c\u7528\u6237\u54cd\u5e94\u7b56\u7565\u6765\u7ef4\u6301\u7cfb\u7edf\u7a33\u5b9a\u3002", "method": "\u6784\u5efa\u4e86\u805a\u5408\u5546\u4e0e\u591a\u7528\u6237\u4e4b\u95f4\u7684Stackelberg\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u6a21\u578b\uff0c\u5f15\u5165\u79c1\u6709\u72b6\u6001\u6982\u5ff5\uff0c\u63d0\u51fa\u79c1\u6709\u9a6c\u5c14\u53ef\u592b\u7b56\u7565\u548c\u5747\u8861\uff0c\u5f00\u53d1\u4e86\u96c6\u4e2d\u5f0f\u4e0e\u5206\u5e03\u5f0f\u7b97\u6cd5\u76f8\u7ed3\u5408\u7684\u53ef\u6269\u5c55\u6c42\u89e3\u6846\u67b6\u3002", "result": "\u8bc1\u660e\u4e86\u5e95\u5c42\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u5b58\u5728\u7eaf\u7b56\u7565\u79c1\u6709\u9a6c\u5c14\u53ef\u592b\u5747\u8861\u4e14\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97\uff0c\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u7684\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff08\u652f\u6301\u591a\u8fbe50\u4e2a\u7528\u6237\uff09\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u53ef\u518d\u751f\u80fd\u6e90\u5e76\u7f51\u4e0b\u7684\u7535\u7f51\u5e73\u8861\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u76f8\u6bd4\u4ee5\u5f80\u7814\u7a76\uff08\u901a\u5e38\u4e0d\u8d85\u8fc75\u4e2a\u7528\u6237\uff09\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2509.12254", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12254", "abs": "https://arxiv.org/abs/2509.12254", "authors": ["Oddvar Kloster", "Bj\u00f8rnar Luteberget", "Carlo Mannino", "Giorgio Sartor"], "title": "DISPLIB: a library of train dispatching problems", "comment": null, "summary": "Optimization-based decision support systems have a significant potential to\nreduce delays, and thus improve efficiency on the railways, by automatically\nre-routing and re-scheduling trains after delays have occurred. The operations\nresearch community has dedicated a lot of effort to developing optimization\nalgorithms for this problem, but each study is typically tightly connected with\na specific industrial use case. Code and data are seldom shared publicly. This\nfact hinders reproducibility, and has led to a proliferation of papers\ndescribing algorithms for more or less compatible problem definitions, without\nany real opportunity for readers to assess their relative performance. Inspired\nby the successful communities around MILP, SAT, TSP, VRP, etc., we introduce a\ncommon problem definition and file format, DISPLIB, which captures all the main\nfeatures of train re-routing and re-scheduling. We have gathered problem\ninstances from multiple real-world use cases and made them openly available. In\nthis paper, we describe the problem definition, the industrial instances, and a\nreference solver implementation. This allows any researcher or developer to\nwork on the train dispatching problem without an industrial connection, and\nenables the research community to perform empirical comparisons between\nsolvers. All materials are available online at https://displib.github.io.", "AI": {"tldr": "\u63d0\u51fa\u4e86DISPLIB\u6807\u51c6\u683c\u5f0f\u548c\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u706b\u8f66\u91cd\u8def\u7531\u548c\u91cd\u8c03\u5ea6\u95ee\u9898\u7684\u7edf\u4e00\u8bc4\u4f30\u548c\u6bd4\u8f83", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u516c\u5f00\u4ee3\u7801\u548c\u6570\u636e\uff0c\u5bfc\u81f4\u7b97\u6cd5\u96be\u4ee5\u590d\u73b0\u548c\u6bd4\u8f83\uff0c\u963b\u788d\u4e86\u94c1\u8def\u8c03\u5ea6\u4f18\u5316\u7b97\u6cd5\u7684\u53d1\u5c55", "method": "\u5b9a\u4e49\u901a\u7528\u95ee\u9898\u683c\u5f0fDISPLIB\uff0c\u6536\u96c6\u591a\u4e2a\u771f\u5b9e\u5de5\u4e1a\u6848\u4f8b\u7684\u95ee\u9898\u5b9e\u4f8b\uff0c\u63d0\u4f9b\u53c2\u8003\u6c42\u89e3\u5668\u5b9e\u73b0", "result": "\u5efa\u7acb\u4e86\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\u548c\u6807\u51c6\u683c\u5f0f\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u65e0\u9700\u5de5\u4e1a\u5408\u4f5c\u5373\u53ef\u5f00\u5c55\u7814\u7a76", "conclusion": "DISPLIB\u4e3a\u706b\u8f66\u8c03\u5ea6\u95ee\u9898\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5e73\u53f0\uff0c\u4fc3\u8fdb\u4e86\u7b97\u6cd5\u7684\u5b9e\u8bc1\u6bd4\u8f83\u548c\u793e\u533a\u53d1\u5c55"}}
{"id": "2509.12533", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.12533", "abs": "https://arxiv.org/abs/2509.12533", "authors": ["Falco J. Bargagli-Stoffi", "Emma Landry", "Kevin P. Josey", "Kenneth De Beckker", "Joana E. Maldonado", "Kristof De Witte"], "title": "Transporting Predictions via Double Machine Learning: Predicting Partially Unobserved Students' Outcomes", "comment": "arXiv admin note: substantial text overlap with arXiv:2102.04382", "summary": "Educational policymakers often lack data on student outcomes in regions where\nstandardized tests were not administered. Machine learning techniques can be\nused to predict unobserved outcomes in target populations by training models on\ndata from a source population. However, differences between the source and\ntarget populations, particularly in covariate distributions, can reduce the\ntransportability of these models, potentially reducing predictive accuracy and\nintroducing bias. We propose using double machine learning for a\ncovariate-shift weighted model. First, we estimate the overlap score-namely,\nthe probability that an observation belongs to the source dataset given its\ncovariates. Second, balancing weights, defined as the density ratio of\ntarget-to-source membership probabilities, are used to reweight the individual\nobservations' contribution to the loss or likelihood function in the target\noutcome prediction model. This approach downweights source observations that\nare less similar to the target population, allowing predictions to rely more\nheavily on observations with greater overlap. As a result, predictions become\nmore generalizable under covariate shift. We illustrate this framework in the\ncontext of uncertain data on students' standardized financial literacy scores\n(FLS). Using Bayesian Additive Regression Trees (BART), we predict missing FLS.\nWe find minimal differences in predictive performance between the weighted and\nunweighted models, suggesting limited covariate shift in our empirical setting.\nNonetheless, the proposed approach provides a principled framework for\naddressing covariate shift and is broadly applicable to predictive modeling in\nthe social and health sciences, where differences between source and target\npopulations are common.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u53cc\u91cd\u673a\u5668\u5b66\u4e60\u5904\u7406\u534f\u53d8\u91cf\u504f\u79fb\u7684\u52a0\u6743\u6a21\u578b\uff0c\u901a\u8fc7\u4f30\u8ba1\u91cd\u53e0\u5206\u6570\u548c\u5e73\u8861\u6743\u91cd\u6765\u63d0\u9ad8\u9884\u6d4b\u6a21\u578b\u5728\u76ee\u6807\u4eba\u7fa4\u4e2d\u7684\u6cdb\u5316\u80fd\u529b", "motivation": "\u6559\u80b2\u653f\u7b56\u5236\u5b9a\u8005\u7ecf\u5e38\u7f3a\u4e4f\u672a\u5b9e\u65bd\u6807\u51c6\u5316\u6d4b\u8bd5\u5730\u533a\u7684\u5b66\u751f\u6210\u679c\u6570\u636e\uff0c\u800c\u6e90\u4eba\u7fa4\u548c\u76ee\u6807\u4eba\u7fa4\u4e4b\u95f4\u7684\u534f\u53d8\u91cf\u5206\u5e03\u5dee\u5f02\u4f1a\u964d\u4f4e\u6a21\u578b\u7684\u8fc1\u79fb\u6027", "method": "\u4f7f\u7528\u53cc\u91cd\u673a\u5668\u5b66\u4e60\uff1a\u9996\u5148\u4f30\u8ba1\u91cd\u53e0\u5206\u6570\uff08\u89c2\u6d4b\u5c5e\u4e8e\u6e90\u6570\u636e\u96c6\u7684\u6982\u7387\uff09\uff0c\u7136\u540e\u4f7f\u7528\u76ee\u6807-\u6e90\u6210\u5458\u6982\u7387\u7684\u5bc6\u5ea6\u6bd4\u4f5c\u4e3a\u5e73\u8861\u6743\u91cd\u6765\u91cd\u65b0\u52a0\u6743\u635f\u5931\u51fd\u6570", "result": "\u5728\u91d1\u878d\u7d20\u517b\u5206\u6570\u9884\u6d4b\u7684\u5b9e\u8bc1\u7814\u7a76\u4e2d\uff0c\u52a0\u6743\u6a21\u578b\u548c\u672a\u52a0\u6743\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u5dee\u5f02\u5f88\u5c0f\uff0c\u8868\u660e\u8be5\u5b9e\u8bc1\u8bbe\u7f6e\u4e2d\u534f\u53d8\u91cf\u504f\u79fb\u6709\u9650", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u89e3\u51b3\u534f\u53d8\u91cf\u504f\u79fb\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u793e\u4f1a\u79d1\u5b66\u548c\u5065\u5eb7\u79d1\u5b66\u4e2d\u7684\u9884\u6d4b\u5efa\u6a21\uff0c\u7279\u522b\u662f\u5728\u6e90\u4eba\u7fa4\u548c\u76ee\u6807\u4eba\u7fa4\u5b58\u5728\u5dee\u5f02\u7684\u5e38\u89c1\u573a\u666f\u4e2d"}}
{"id": "2509.12288", "categories": ["cs.SI", "cs.AI", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.12288", "abs": "https://arxiv.org/abs/2509.12288", "authors": ["Kanlun Wang", "Zhe Fu", "Wangjiaxuan Xin", "Lina Zhou", "Shashi Kiran Chandrappa"], "title": "Digital Voices of Survival: From Social Media Disclosures to Support Provisions for Domestic Violence Victims", "comment": "9 pages, 4 figures and 4 tables. Accepted to The 59th Hawaii\n  International Conference on System Sciences (HICSS) 2026", "summary": "Domestic Violence (DV) is a pervasive public health problem characterized by\npatterns of coercive and abusive behavior within intimate relationships. With\nthe rise of social media as a key outlet for DV victims to disclose their\nexperiences, online self-disclosure has emerged as a critical yet underexplored\navenue for support-seeking. In addition, existing research lacks a\ncomprehensive and nuanced understanding of DV self-disclosure, support\nprovisions, and their connections. To address these gaps, this study proposes a\nnovel computational framework for modeling DV support-seeking behavior\nalongside community support mechanisms. The framework consists of four key\ncomponents: self-disclosure detection, post clustering, topic summarization,\nand support extraction and mapping. We implement and evaluate the framework\nwith data collected from relevant social media communities. Our findings not\nonly advance existing knowledge on DV self-disclosure and online support\nprovisions but also enable victim-centered digital interventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\u6765\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e0a\u5bb6\u5ead\u66b4\u529b\u53d7\u5bb3\u8005\u7684\u81ea\u6211\u62ab\u9732\u548c\u793e\u533a\u652f\u6301\u673a\u5236\uff0c\u5305\u62ec\u81ea\u6211\u62ab\u9732\u68c0\u6d4b\u3001\u5e16\u5b50\u805a\u7c7b\u3001\u4e3b\u9898\u603b\u7ed3\u548c\u652f\u6301\u63d0\u53d6\u6620\u5c04\u56db\u4e2a\u7ec4\u4ef6\u3002", "motivation": "\u5bb6\u5ead\u66b4\u529b\u662f\u4e00\u4e2a\u666e\u904d\u5b58\u5728\u7684\u516c\u5171\u536b\u751f\u95ee\u9898\uff0c\u968f\u7740\u793e\u4ea4\u5a92\u4f53\u6210\u4e3a\u53d7\u5bb3\u8005\u62ab\u9732\u7ecf\u5386\u7684\u91cd\u8981\u6e20\u9053\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u5bb6\u5ead\u66b4\u529b\u81ea\u6211\u62ab\u9732\u3001\u652f\u6301\u63d0\u4f9b\u53ca\u5176\u8054\u7cfb\u7684\u5168\u9762\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\u7684\u8ba1\u7b97\u6846\u67b6\uff1a\u81ea\u6211\u62ab\u9732\u68c0\u6d4b\u3001\u5e16\u5b50\u805a\u7c7b\u3001\u4e3b\u9898\u603b\u7ed3\u3001\u652f\u6301\u63d0\u53d6\u548c\u6620\u5c04\uff0c\u5e76\u4f7f\u7528\u76f8\u5173\u793e\u4ea4\u5a92\u4f53\u793e\u533a\u6536\u96c6\u7684\u6570\u636e\u8fdb\u884c\u5b9e\u65bd\u548c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u5bf9\u5bb6\u5ead\u66b4\u529b\u81ea\u6211\u62ab\u9732\u548c\u5728\u7ebf\u652f\u6301\u63d0\u4f9b\u7684\u73b0\u6709\u77e5\u8bc6\uff0c\u8fd8\u5b9e\u73b0\u4e86\u4ee5\u53d7\u5bb3\u8005\u4e3a\u4e2d\u5fc3\u7684\u6570\u5b57\u5e72\u9884\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u652f\u6301\u5bb6\u5ead\u66b4\u529b\u53d7\u5bb3\u8005\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\u548c\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u5728\u7ebf\u652f\u6301\u673a\u5236\u548c\u5e72\u9884\u63aa\u65bd\u3002"}}
{"id": "2509.12388", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2509.12388", "abs": "https://arxiv.org/abs/2509.12388", "authors": ["Jeff Dominitz", "Charles F. Manski"], "title": "A Decision Theoretic Perspective on Artificial Superintelligence: Coping with Missing Data Problems in Prediction and Treatment Choice", "comment": null, "summary": "Enormous attention and resources are being devoted to the quest for\nartificial general intelligence and, even more ambitiously, artificial\nsuperintelligence. We wonder about the implications for our methodological\nresearch, which aims to help decision makers cope with what econometricians\ncall identification problems, inferential problems in empirical research that\ndo not diminish as sample size grows. Of particular concern are missing data\nproblems in prediction and treatment choice. Essentially all data collection\nintended to inform decision making is subject to missing data, which gives rise\nto identification problems. Thus far, we see no indication that the current\ndominant architecture of machine learning (ML)-based artificial intelligence\n(AI) systems will outperform humans in this context. In this paper, we explain\nwhy we have reached this conclusion and why we see the missing data problem as\na cautionary case study in the quest for superintelligence more generally. We\nfirst discuss the concept of intelligence, before presenting a\ndecision-theoretic perspective that formalizes the connection between\nintelligence and identification problems. We next apply this perspective to two\nleading cases of missing data problems. Then we explain why we are skeptical\nthat AI research is currently on a path toward machines doing better than\nhumans at solving these identification problems.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u5f53\u524dAI\u67b6\u6784\u5728\u5904\u7406\u7f3a\u5931\u6570\u636e\u95ee\u9898\u65f6\u65e0\u6cd5\u8d85\u8d8a\u4eba\u7c7b\uff0c\u5bf9\u8ffd\u6c42\u8d85\u7ea7\u667a\u80fd\u6301\u8c28\u614e\u6001\u5ea6", "motivation": "\u63a2\u8ba8AI\u5728\u89e3\u51b3\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u4e2d\u7684\u8bc6\u522b\u95ee\u9898\uff08\u7279\u522b\u662f\u7f3a\u5931\u6570\u636e\u95ee\u9898\uff09\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u8fd9\u5bf9\u8ffd\u6c42\u4eba\u5de5\u8d85\u7ea7\u667a\u80fd\u7684\u542f\u793a", "method": "\u91c7\u7528\u51b3\u7b56\u7406\u8bba\u89c6\u89d2\u5f62\u5f0f\u5316\u667a\u80fd\u4e0e\u8bc6\u522b\u95ee\u9898\u7684\u8054\u7cfb\uff0c\u5e76\u5206\u6790\u4e24\u4e2a\u4e3b\u8981\u7684\u7f3a\u5931\u6570\u636e\u95ee\u9898\u6848\u4f8b", "result": "\u53d1\u73b0\u5f53\u524d\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684AI\u7cfb\u7edf\u5728\u5904\u7406\u8bc6\u522b\u95ee\u9898\u4e0a\u6ca1\u6709\u8868\u73b0\u51fa\u8d85\u8d8a\u4eba\u7c7b\u7684\u80fd\u529b", "conclusion": "\u7f3a\u5931\u6570\u636e\u95ee\u9898\u662f\u4e00\u4e2a\u8b66\u793a\u6027\u6848\u4f8b\uff0c\u8868\u660eAI\u7814\u7a76\u76ee\u524d\u5c1a\u672a\u627e\u5230\u8d85\u8d8a\u4eba\u7c7b\u89e3\u51b3\u590d\u6742\u8bc6\u522b\u95ee\u9898\u7684\u8def\u5f84"}}
{"id": "2509.12390", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12390", "abs": "https://arxiv.org/abs/2509.12390", "authors": ["Evangelos Psomiadis", "Panagiotis Tsiotras"], "title": "Distributed Event-Triggered Distance-Based Formation Control for Multi-Agent Systems", "comment": "8 pages, 7 figures", "summary": "This paper addresses the problem of collaborative formation control for\nmulti-agent systems with limited resources. We consider a team of robots tasked\nwith achieving a desired formation from arbitrary initial configurations. To\nreduce unnecessary control updates and conserve resources, we propose a\ndistributed event-triggered formation controller that relies on inter-agent\ndistance measurements. Control updates are triggered only when the measurement\nerror exceeds a predefined threshold, ensuring system stability. The proposed\ncontroller is validated through extensive simulations and real-world\nexperiments involving different formations, communication topologies,\nscalability tests, and variations in design parameters, while also being\ncompared against periodic triggering strategies. Results demonstrate that the\nevent-triggered approach significantly reduces control efforts while preserving\nformation performance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e8b\u4ef6\u89e6\u53d1\u7684\u5206\u5e03\u5f0f\u7f16\u961f\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u8ddd\u79bb\u6d4b\u91cf\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7f16\u961f\u63a7\u5236\uff0c\u4ec5\u5728\u6d4b\u91cf\u8bef\u5dee\u8d85\u8fc7\u9608\u503c\u65f6\u66f4\u65b0\u63a7\u5236\uff0c\u663e\u8457\u51cf\u5c11\u63a7\u5236\u5f00\u9500\u5e76\u4fdd\u6301\u7f16\u961f\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6709\u9650\u8d44\u6e90\u4e0b\u7684\u534f\u540c\u7f16\u961f\u63a7\u5236\u95ee\u9898\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u63a7\u5236\u66f4\u65b0\u4ee5\u8282\u7ea6\u8d44\u6e90\u3002", "method": "\u8bbe\u8ba1\u5206\u5e03\u5f0f\u4e8b\u4ef6\u89e6\u53d1\u7f16\u961f\u63a7\u5236\u5668\uff0c\u4f9d\u8d56\u667a\u80fd\u4f53\u95f4\u8ddd\u79bb\u6d4b\u91cf\uff0c\u63a7\u5236\u66f4\u65b0\u4ec5\u5728\u6d4b\u91cf\u8bef\u5dee\u8d85\u8fc7\u9884\u8bbe\u9608\u503c\u65f6\u89e6\u53d1\uff0c\u786e\u4fdd\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5728\u4e0d\u540c\u7f16\u961f\u3001\u901a\u4fe1\u62d3\u6251\u3001\u53ef\u6269\u5c55\u6027\u6d4b\u8bd5\u548c\u8bbe\u8ba1\u53c2\u6570\u53d8\u5316\u4e0b\uff0c\u76f8\u6bd4\u5468\u671f\u6027\u89e6\u53d1\u7b56\u7565\u663e\u8457\u51cf\u5c11\u63a7\u5236\u52aa\u529b\u3002", "conclusion": "\u4e8b\u4ef6\u89e6\u53d1\u65b9\u6cd5\u5728\u4fdd\u6301\u7f16\u961f\u6027\u80fd\u7684\u540c\u65f6\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4e\u63a7\u5236\u5f00\u9500\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002"}}
{"id": "2509.12263", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12263", "abs": "https://arxiv.org/abs/2509.12263", "authors": ["Gautam Sreekumar", "Vishnu Naresh Boddeti"], "title": "InPhyRe Discovers: Large Multimodal Models Struggle in Inductive Physical Reasoning", "comment": "35 pages including appendix", "summary": "Large multimodal models (LMMs) encode universal physical laws observed during\ntraining, such as momentum conservation, as parametric knowledge. It allows\nLMMs to answer physical reasoning queries, such as the outcome of a potential\ncollision event from visual input. However, since parametric knowledge includes\nonly the physical laws seen during training, it is insufficient for reasoning\nwhen the inference scenario violates these physical laws. In contrast, humans\npossess the skill to adapt their physical reasoning to unseen physical\nenvironments from a few visual examples. This ability, which we refer to as\ninductive physical reasoning, is indispensable for LMMs if they are to replace\nhuman agents in safety-critical applications. Despite its importance, existing\nvisual benchmarks evaluate only the parametric knowledge in LMMs, and not\ninductive physical reasoning. To this end, we propose InPhyRe, the first visual\nquestion answering benchmark to measure inductive physical reasoning in LMMs.\nInPhyRe evaluates LMMs on their ability to predict the outcome of collision\nevents in algorithmically generated synthetic collision videos. By inspecting\n13 LMMs, InPhyRe informs us that (1) LMMs struggle to apply their limited\nparametric knowledge about universal physical laws to reasoning, (2) inductive\nphysical reasoning in LMMs is weak when demonstration samples violate universal\nphysical laws, and (3) inductive physical reasoning in LMMs suffers from\nlanguage bias and largely ignores the visual inputs, questioning the\ntrustworthiness of LMMs regarding visual inputs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86InPhyRe\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u5f52\u7eb3\u7269\u7406\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u8fdd\u53cd\u7269\u7406\u89c4\u5f8b\u7684\u573a\u666f\u4e2d\u63a8\u7406\u80fd\u529b\u8f83\u5f31\uff0c\u4e14\u5b58\u5728\u8bed\u8a00\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u4ec5\u57fa\u4e8e\u8bad\u7ec3\u65f6\u89c1\u8fc7\u7684\u7269\u7406\u89c4\u5f8b\u8fdb\u884c\u53c2\u6570\u5316\u63a8\u7406\uff0c\u65e0\u6cd5\u9002\u5e94\u8fdd\u53cd\u7269\u7406\u89c4\u5f8b\u7684\u63a8\u7406\u573a\u666f\uff0c\u800c\u4eba\u7c7b\u5177\u5907\u4ece\u5c11\u91cf\u89c6\u89c9\u793a\u4f8b\u4e2d\u5f52\u7eb3\u63a8\u7406\u7684\u80fd\u529b\uff0c\u8fd9\u5bf9\u5b89\u5168\u5173\u952e\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faInPhyRe\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\uff0c\u901a\u8fc7\u7b97\u6cd5\u751f\u6210\u7684\u5408\u6210\u78b0\u649e\u89c6\u9891\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u5f52\u7eb3\u7269\u7406\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\uff0c\u6d4b\u8bd5\u4e8613\u4e2a\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1)\u6a21\u578b\u96be\u4ee5\u5c06\u6709\u9650\u7684\u53c2\u6570\u5316\u77e5\u8bc6\u5e94\u7528\u4e8e\u63a8\u7406\uff1b(2)\u5728\u8fdd\u53cd\u7269\u7406\u89c4\u5f8b\u7684\u6f14\u793a\u6837\u672c\u4e2d\u5f52\u7eb3\u63a8\u7406\u80fd\u529b\u5f31\uff1b(3)\u5b58\u5728\u8bed\u8a00\u504f\u89c1\uff0c\u5ffd\u89c6\u89c6\u89c9\u8f93\u5165\uff0c\u5f71\u54cd\u6a21\u578b\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u5f52\u7eb3\u7269\u7406\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u63d0\u5347\u5728\u8fdd\u53cd\u7269\u7406\u89c4\u5f8b\u573a\u666f\u4e0b\u7684\u63a8\u7406\u80fd\u529b\u548c\u89c6\u89c9\u8f93\u5165\u7684\u5229\u7528\u6548\u679c\u3002"}}
{"id": "2509.12686", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.12686", "abs": "https://arxiv.org/abs/2509.12686", "authors": ["Shilpi Biswas", "Ayon Ganguly", "Debanjan Mitra"], "title": "A Doubly-Flexible Model Based on Generalized Gamma Frailty for Two-component Load-sharing Systems", "comment": null, "summary": "For two-component load-sharing systems, a doubly-flexible model is developed\nwhere the generalized Fruend bivariate (GFB) distribution is used for the\nbaseline of the component lifetimes, and the generalized gamma (GG) family of\ndistributions is used to incorporate a shared frailty that captures dependence\nbetween the component lifetimes. The proposed model structure results in a very\ngeneral two-way class of models that enables a researcher to choose an\nappropriate model for a given two-component load-sharing data within the\nrespective families of distributions. The GFB-GG model structure provides\nbetter fit to two-component load-sharing systems compared to existing models.\nFitting methods for the proposed model, based on direct optimization and an\nexpectation maximization (EM) type algorithm, are discussed. Through\nsimulations, effectiveness of the fitting methods is demonstrated. Also,\nthrough simulations, it is shown that the proposed model serves the intended\npurpose of model choice for a given two-component load-sharing data. A\nsimulation case, and analysis of a real dataset are presented to illustrate the\nstrength of the proposed model.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u7ec4\u5206\u8f7d\u8377\u5206\u62c5\u7cfb\u7edf\u7684\u53cc\u7075\u6d3b\u6a21\u578b\uff0c\u4f7f\u7528\u5e7f\u4e49Fruend\u4e8c\u5143\u5206\u5e03\u4f5c\u4e3a\u7ec4\u4ef6\u5bff\u547d\u57fa\u7ebf\uff0c\u5e7f\u4e49\u4f3d\u9a6c\u5206\u5e03\u65cf\u5f15\u5165\u5171\u4eab\u8106\u5f31\u6027\u6765\u6355\u6349\u7ec4\u4ef6\u95f4\u7684\u4f9d\u8d56\u6027\uff0c\u5f62\u6210\u4e86\u901a\u7528\u7684\u53cc\u5411\u6a21\u578b\u7c7b\uff0c\u62df\u5408\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u4e3a\u53cc\u7ec4\u5206\u8f7d\u8377\u5206\u62c5\u7cfb\u7edf\u5f00\u53d1\u66f4\u901a\u7528\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u7ec4\u4ef6\u5bff\u547d\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u7075\u6d3b\u7684\u6a21\u578b\u9009\u62e9\u6846\u67b6\u3002", "method": "\u7ed3\u5408\u5e7f\u4e49Fruend\u4e8c\u5143\u5206\u5e03\u548c\u5e7f\u4e49\u4f3d\u9a6c\u5206\u5e03\u65cf\u6784\u5efa\u53cc\u7075\u6d3b\u6a21\u578b\uff0c\u91c7\u7528\u76f4\u63a5\u4f18\u5316\u548cEM\u7b97\u6cd5\u8fdb\u884c\u53c2\u6570\u62df\u5408\uff0c\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u6a21\u578b\u6709\u6548\u6027\u3002", "result": "\u63d0\u51fa\u7684GFB-GG\u6a21\u578b\u7ed3\u6784\u5728\u53cc\u7ec4\u5206\u8f7d\u8377\u5206\u62c5\u7cfb\u7edf\u4e2d\u6bd4\u73b0\u6709\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u62df\u5408\u6548\u679c\uff0c\u62df\u5408\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u591f\u4e3a\u7ed9\u5b9a\u6570\u636e\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002", "conclusion": "\u8be5\u53cc\u7075\u6d3b\u6a21\u578b\u4e3a\u53cc\u7ec4\u5206\u8f7d\u8377\u5206\u62c5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5efa\u6a21\u5de5\u5177\uff0c\u5177\u6709\u4f18\u5f02\u7684\u62df\u5408\u6027\u80fd\u548c\u6a21\u578b\u9009\u62e9\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5de5\u7a0b\u5e94\u7528\u3002"}}
{"id": "2509.12281", "categories": ["eess.SY", "cs.LG", "cs.SY", "I.2.0"], "pdf": "https://arxiv.org/pdf/2509.12281", "abs": "https://arxiv.org/abs/2509.12281", "authors": ["Sel Ly", "Kapil Chauhan", "Anshuman Singh", "Hung Dinh Nguyen"], "title": "Meta-model Neural Process for Probabilistic Power Flow under Varying N-1 System Topologies", "comment": "An improved version for the conference paper at PESGM 2025", "summary": "The probabilistic power flow (PPF) problem is essential to quantifying the\ndistribution of the nodal voltages due to uncertain injections. The\nconventional PPF problem considers a fixed topology, and the solutions to such\na PPF problem are associated with this topology. A change in the topology might\nalter the power flow patterns and thus require the PPF problem to be solved\nagain. The previous PPF model and its solutions are no longer valid for the new\ntopology. This practice incurs both inconvenience and computation burdens as\nmore contingencies are foreseen due to high renewables and a large share of\nelectric vehicles. This paper presents a novel topology-adaptive approach,\nbased on the meta-model Neural Process (MMNP), for finding the solutions to PPF\nproblems under varying N-1 topologies, particularly with one-line failures. By\nleveraging context set-based topology representation and conditional\ndistribution over function learning techniques, the proposed MMNP enhances the\nrobustness of PPF models to topology variations, mitigating the need for\nretraining PPF models on a new configuration. Simulations on an IEEE 9-bus\nsystem and IEEE 118-bus system validate the model's performance. The maximum\n%L1-relative error norm was observed as 1.11% and 0.77% in 9-bus and 118-bus,\nrespectively. This adaptive approach fills a critical gap in PPF methodology in\nan era of increasing grid volatility.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5143\u6a21\u578b\u795e\u7ecf\u8fc7\u7a0b(MMNP)\u7684\u62d3\u6251\u81ea\u9002\u5e94\u6982\u7387\u6f6e\u6d41\u8ba1\u7b97\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edfPPF\u65b9\u6cd5\u5728\u62d3\u6251\u53d8\u5316\u65f6\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u96c6\u5408\u8868\u793a\u548c\u6761\u4ef6\u5206\u5e03\u5b66\u4e60\u6280\u672f\u5b9e\u73b0N-1\u62d3\u6251\u4e0b\u7684\u81ea\u9002\u5e94\u8ba1\u7b97\u3002", "motivation": "\u4f20\u7edf\u6982\u7387\u6f6e\u6d41(PPF)\u65b9\u6cd5\u5047\u8bbe\u56fa\u5b9a\u62d3\u6251\uff0c\u5f53\u62d3\u6251\u53d8\u5316\u65f6\u9700\u8981\u91cd\u65b0\u8ba1\u7b97\uff0c\u8fd9\u5728\u53ef\u518d\u751f\u80fd\u6e90\u548c\u7535\u52a8\u6c7d\u8f66\u5927\u91cf\u63a5\u5165\u5bfc\u81f4\u66f4\u591a\u6545\u969c\u573a\u666f\u7684\u60c5\u51b5\u4e0b\u5e26\u6765\u8ba1\u7b97\u8d1f\u62c5\u548c\u4e0d\u4fbf\u3002", "method": "\u91c7\u7528\u5143\u6a21\u578b\u795e\u7ecf\u8fc7\u7a0b(MMNP)\u65b9\u6cd5\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u96c6\u5408\u7684\u62d3\u6251\u8868\u793a\u548c\u51fd\u6570\u6761\u4ef6\u5206\u5e03\u5b66\u4e60\u6280\u672f\uff0c\u589e\u5f3aPPF\u6a21\u578b\u5bf9\u62d3\u6251\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u907f\u514d\u5728\u65b0\u914d\u7f6e\u4e0b\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5728IEEE 9\u603b\u7ebf\u548c118\u603b\u7ebf\u7cfb\u7edf\u4e0a\u7684\u4eff\u771f\u9a8c\u8bc1\u663e\u793a\uff0c\u6700\u5927%L1\u76f8\u5bf9\u8bef\u5dee\u8303\u6570\u5206\u522b\u4e3a1.11%\u548c0.77%\uff0c\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u62d3\u6251\u81ea\u9002\u5e94\u65b9\u6cd5\u586b\u8865\u4e86PPF\u65b9\u6cd5\u5b66\u5728\u7535\u7f51\u6ce2\u52a8\u6027\u589e\u52a0\u65f6\u4ee3\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u5904\u7406\u62d3\u6251\u53d8\u5316\u7684\u6982\u7387\u6f6e\u6d41\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12396", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12396", "abs": "https://arxiv.org/abs/2509.12396", "authors": ["Gabriel Chuang", "Augustin Chaintreau"], "title": "Structured Information Loss in Network Embeddings", "comment": null, "summary": "We analyze a simple algorithm for network embedding, explicitly\ncharacterizing conditions under which the learned representation encodes the\ngraph's generative model fully, partially, or not at all. In cases where the\nembedding loses some information (i.e., is not invertible), we describe the\nequivalence classes of graphons that map to the same embedding, finding that\nthese classes preserve community structure but lose substantial density\ninformation. Finally, we show implications for community detection and link\nprediction. Our results suggest strong limitations on the effectiveness of link\nprediction based on embeddings alone, and we show common conditions under which\nnaive link prediction adds edges in a disproportionate manner that can either\nmitigate or exacerbate structural biases.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u7f51\u7edc\u5d4c\u5165\u7b97\u6cd5\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u53d1\u73b0\u5d4c\u5165\u8868\u793a\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u4fdd\u7559\u56fe\u7684\u751f\u6210\u6a21\u578b\u4fe1\u606f\uff0c\u7279\u522b\u662f\u5728\u5bc6\u5ea6\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u635f\u5931\uff0c\u8fd9\u5bf9\u94fe\u63a5\u9884\u6d4b\u548c\u793e\u533a\u68c0\u6d4b\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u7f51\u7edc\u5d4c\u5165\u7b97\u6cd5\u5728\u8868\u793a\u56fe\u751f\u6210\u6a21\u578b\u65f6\u7684\u5b8c\u6574\u6027\u548c\u5c40\u9650\u6027\uff0c\u660e\u786e\u5728\u4ec0\u4e48\u6761\u4ef6\u4e0b\u5d4c\u5165\u80fd\u591f\u5b8c\u5168\u3001\u90e8\u5206\u6216\u5b8c\u5168\u4e0d\u80fd\u7f16\u7801\u56fe\u7684\u751f\u6210\u4fe1\u606f\u3002", "method": "\u5206\u6790\u4e00\u4e2a\u7b80\u5355\u7684\u7f51\u7edc\u5d4c\u5165\u7b97\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u523b\u753b\u5d4c\u5165\u8868\u793a\u5bf9\u56fe\u751f\u6210\u6a21\u578b\u7684\u7f16\u7801\u80fd\u529b\uff0c\u5e76\u63cf\u8ff0\u6620\u5c04\u5230\u76f8\u540c\u5d4c\u5165\u7684\u56fe\u7b49\u4ef7\u7c7b\u3002", "result": "\u53d1\u73b0\u5d4c\u5165\u8868\u793a\u4f1a\u4e22\u5931\u5bc6\u5ea6\u4fe1\u606f\u4f46\u4fdd\u7559\u793e\u533a\u7ed3\u6784\uff0c\u94fe\u63a5\u9884\u6d4b\u4ec5\u57fa\u4e8e\u5d4c\u5165\u5b58\u5728\u4e25\u91cd\u5c40\u9650\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u7ed3\u6784\u504f\u5dee\u7684\u52a0\u5267\u6216\u7f13\u89e3\u3002", "conclusion": "\u7f51\u7edc\u5d4c\u5165\u7b97\u6cd5\u5728\u4fe1\u606f\u4fdd\u7559\u65b9\u9762\u5b58\u5728\u56fa\u6709\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5bc6\u5ea6\u4fe1\u606f\u65b9\u9762\uff0c\u8fd9\u5bf9\u57fa\u4e8e\u5d4c\u5165\u7684\u94fe\u63a5\u9884\u6d4b\u5e94\u7528\u63d0\u51fa\u4e86\u91cd\u8981\u8b66\u793a\u3002"}}
{"id": "2509.12538", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2509.12538", "abs": "https://arxiv.org/abs/2509.12538", "authors": ["Didier Nibbering", "Matthijs Oosterveen"], "title": "Policy-relevant causal effect estimation using instrumental variables with interference", "comment": null, "summary": "Many policy evaluations using instrumental variable (IV) methods include\nindividuals who interact with each other, potentially violating the standard IV\nassumptions. This paper defines and partially identifies direct and spillover\neffects with a clear policy-relevant interpretation under relatively mild\nassumptions on interference. Our framework accommodates both spillovers from\nthe instrument to treatment and from treatment to outcomes and allows for\nmultiple peers. By generalizing monotone treatment response and selection\nassumptions, we derive informative bounds on policy-relevant effects without\nrestricting the type or direction of interference. The results extend IV\nestimation to more realistic social contexts, informing program evaluation and\ntreatment scaling when interference is present.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5de5\u5177\u53d8\u91cf\u65b9\u6cd5\uff0c\u5728\u5b58\u5728\u793e\u4f1a\u4e92\u52a8\u7684\u573a\u666f\u4e0b\u5b9a\u4e49\u548c\u90e8\u5206\u8bc6\u522b\u76f4\u63a5\u6548\u5e94\u548c\u6ea2\u51fa\u6548\u5e94\uff0c\u901a\u8fc7\u63a8\u5e7f\u5355\u8c03\u6027\u5047\u8bbe\u6765\u83b7\u5f97\u653f\u7b56\u76f8\u5173\u6548\u5e94\u7684\u4fe1\u606f\u6027\u8fb9\u754c\u3002", "motivation": "\u4f20\u7edf\u5de5\u5177\u53d8\u91cf\u65b9\u6cd5\u5047\u8bbe\u4e2a\u4f53\u95f4\u76f8\u4e92\u72ec\u7acb\uff0c\u4f46\u73b0\u5b9e\u4e2d\u653f\u7b56\u8bc4\u4f30\u5e38\u6d89\u53ca\u76f8\u4e92\u5f71\u54cd\u7684\u4e2a\u4f53\uff08\u5982\u793e\u4ea4\u7f51\u7edc\uff09\uff0c\u8fd9\u8fdd\u53cd\u4e86\u6807\u51c6IV\u5047\u8bbe\uff0c\u9700\u8981\u65b0\u7684\u6846\u67b6\u6765\u5904\u7406\u5e72\u6270\u6548\u5e94\u3002", "method": "\u901a\u8fc7\u63a8\u5e7f\u5355\u8c03\u6cbb\u7597\u54cd\u5e94\u548c\u9009\u62e9\u5047\u8bbe\uff0c\u5728\u76f8\u5bf9\u6e29\u548c\u7684\u5e72\u6270\u5047\u8bbe\u4e0b\u5b9a\u4e49\u76f4\u63a5\u6548\u5e94\u548c\u6ea2\u51fa\u6548\u5e94\uff0c\u5141\u8bb8\u5de5\u5177\u5bf9\u6cbb\u7597\u7684\u6ea2\u51fa\u548c\u6cbb\u7597\u5bf9\u7ed3\u679c\u7684\u6ea2\u51fa\uff0c\u652f\u6301\u591a\u540c\u4f34\u573a\u666f\u3002", "result": "\u63a8\u5bfc\u51fa\u653f\u7b56\u76f8\u5173\u6548\u5e94\u7684\u4fe1\u606f\u6027\u8fb9\u754c\uff0c\u65e0\u9700\u9650\u5236\u5e72\u6270\u7684\u7c7b\u578b\u6216\u65b9\u5411\uff0c\u6269\u5c55\u4e86IV\u4f30\u8ba1\u5728\u73b0\u5b9e\u793e\u4f1a\u60c5\u5883\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7fIV\u65b9\u6cd5\u80fd\u591f\u9002\u5e94\u5b58\u5728\u5e72\u6270\u7684\u73b0\u5b9e\u793e\u4f1a\u73af\u5883\uff0c\u4e3a\u9879\u76ee\u8bc4\u4f30\u548c\u6cbb\u7597\u6269\u5c55\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2509.12283", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.12283", "abs": "https://arxiv.org/abs/2509.12283", "authors": ["Ana Elisa Lopez-Miranda", "Tiffany Timbers", "Rohan Alexander"], "title": "Prompting the Professoriate: A Qualitative Study of Instructor Perspectives on LLMs in Data Science Education", "comment": "45 pages, 16 figures, 1 table", "summary": "Large Language Models (LLMs) have shifted in just a few years from novelty to\nubiquity, raising fundamental questions for data science education. Tasks once\nused to teach coding, writing, and problem-solving can now be completed by\nLLMs, forcing educators to reconsider both pedagogy and assessment. To\nunderstand how instructors are adapting, we conducted semi-structured\ninterviews with 42 instructors from 33 institutions in 10 countries in June and\nJuly 2025. Our qualitative analysis reveals a pragmatic mix of optimism and\nconcern. Many respondents view LLMs as inevitable classroom tools -- comparable\nto calculators or Wikipedia -- while others worry about de-skilling, misplaced\nconfidence, and uneven integration across institutions. Around 58 per cent have\nalready introduced demonstrations, guided activities, or make extensive use of\nLLMs in their courses, though most expect change to remain slow and uneven.\nThat said, 31 per cent have not used LLMs to teach students and do not plan to.\nWe highlight some instructional innovations, including AI-aware assessments,\nreflective use of LLMs as tutors, and course-specific chatbots. By sharing\nthese perspectives, we aim to help data science educators adapt collectively to\nensure curricula keep pace with technological change.", "AI": {"tldr": "LLMs\u5bf9\u6570\u636e\u79d1\u5b66\u6559\u80b2\u5e26\u6765\u6839\u672c\u6027\u6311\u6218\uff0c42\u540d\u6559\u5e08\u7684\u8bbf\u8c08\u663e\u793a58%\u5df2\u5728\u4f7f\u7528LLMs\u6559\u5b66\uff0c31%\u4ecd\u4e0d\u4f7f\u7528\uff0c\u6559\u80b2\u8005\u6b63\u5728\u63a2\u7d22AI\u611f\u77e5\u8bc4\u4f30\u548c\u8bfe\u7a0b\u4e13\u7528\u804a\u5929\u673a\u5668\u4eba\u7b49\u521b\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u666e\u53ca\u6b63\u5728\u6539\u53d8\u6570\u636e\u79d1\u5b66\u6559\u80b2\u7684\u6559\u5b66\u548c\u8bc4\u4f30\u65b9\u5f0f\uff0c\u9700\u8981\u4e86\u89e3\u6559\u80b2\u5de5\u4f5c\u8005\u5982\u4f55\u9002\u5e94\u8fd9\u4e00\u6280\u672f\u53d8\u9769\u3002", "method": "\u5bf9\u6765\u81ea10\u4e2a\u56fd\u5bb633\u4e2a\u673a\u6784\u768442\u540d\u6559\u5e08\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u5e76\u8fdb\u884c\u5b9a\u6027\u5206\u6790\u3002", "result": "58%\u7684\u6559\u5e08\u5df2\u5728\u8bfe\u7a0b\u4e2d\u4f7f\u7528LLMs\u8fdb\u884c\u6f14\u793a\u6216\u6307\u5bfc\u6d3b\u52a8\uff0c31%\u7684\u6559\u5e08\u4e0d\u4f7f\u7528\u4e14\u65e0\u8ba1\u5212\u4f7f\u7528\uff0c\u6559\u80b2\u754c\u5448\u73b0\u5b9e\u7528\u4e3b\u4e49\u7684\u4e50\u89c2\u4e0e\u62c5\u5fe7\u5e76\u5b58\u6001\u5ea6\u3002", "conclusion": "\u6570\u636e\u79d1\u5b66\u6559\u80b2\u9700\u8981\u96c6\u4f53\u9002\u5e94\u6280\u672f\u53d8\u9769\uff0c\u901a\u8fc7AI\u611f\u77e5\u8bc4\u4f30\u3001\u53cd\u601d\u6027\u4f7f\u7528LLMs\u4f5c\u4e3a\u5bfc\u5e08\u548c\u8bfe\u7a0b\u4e13\u7528\u804a\u5929\u673a\u5668\u4eba\u7b49\u521b\u65b0\u65b9\u6cd5\u6765\u786e\u4fdd\u8bfe\u7a0b\u4e0e\u65f6\u4ff1\u8fdb\u3002"}}
{"id": "2509.12398", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.12398", "abs": "https://arxiv.org/abs/2509.12398", "authors": ["Michael Lorenz", "Bertram Taetz", "Gabriele Bleser-Taetz", "Didier Stricker"], "title": "MinJointTracker: Real-time inertial kinematic chain tracking with joint position estimation and minimal state size", "comment": "10 pages, 2 figures", "summary": "Inertial motion capture is a promising approach for capturing motion outside\nthe laboratory. However, as one major drawback, most of the current methods\nrequire different quantities to be calibrated or computed offline as part of\nthe setup process, such as segment lengths, relative orientations between\ninertial measurement units (IMUs) and segment coordinate frames (IMU-to-segment\ncalibrations) or the joint positions in the IMU frames. This renders the setup\nprocess inconvenient. This work contributes to real-time capable\ncalibration-free inertial tracking of a kinematic chain, i.e. simultaneous\nrecursive Bayesian estimation of global IMU angular kinematics and joint\npositions in the IMU frames, with a minimal state size. Experimental results on\nsimulated IMU data from a three-link kinematic chain (manipulator study) as\nwell as re-simulated IMU data from healthy humans walking (lower body study)\nshow that the calibration-free and lightweight algorithm provides not only\ndrift-free relative but also drift-free absolute orientation estimates with a\nglobal heading reference for only one IMU as well as robust and fast\nconvergence of joint position estimates in the different movement scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u65e0\u6807\u5b9a\u7684\u60ef\u6027\u8fd0\u52a8\u6355\u6349\u65b9\u6cd5\uff0c\u65e0\u9700\u9884\u5148\u6821\u51c6IMU\u4e0e\u80a2\u4f53\u6bb5\u7684\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u901a\u8fc7\u9012\u5f52\u8d1d\u53f6\u65af\u4f30\u8ba1\u540c\u65f6\u8ba1\u7b97IMU\u5168\u5c40\u89d2\u8fd0\u52a8\u548c\u5173\u8282\u4f4d\u7f6e\u3002", "motivation": "\u5f53\u524d\u60ef\u6027\u8fd0\u52a8\u6355\u6349\u65b9\u6cd5\u9700\u8981\u79bb\u7ebf\u6821\u51c6IMU\u4e0e\u80a2\u4f53\u6bb5\u7684\u76f8\u5bf9\u4f4d\u7f6e\u3001\u6bb5\u957f\u5ea6\u7b49\u53c2\u6570\uff0c\u4f7f\u5f97\u8bbe\u7f6e\u8fc7\u7a0b\u4e0d\u4fbf\u3002\u672c\u6587\u65e8\u5728\u5b9e\u73b0\u65e0\u9700\u6821\u51c6\u7684\u5b9e\u65f6\u60ef\u6027\u8ddf\u8e2a\u3002", "method": "\u4f7f\u7528\u6700\u5c0f\u72b6\u6001\u5927\u5c0f\u7684\u9012\u5f52\u8d1d\u53f6\u65af\u4f30\u8ba1\u7b97\u6cd5\uff0c\u540c\u65f6\u4f30\u8ba1IMU\u7684\u5168\u5c40\u89d2\u8fd0\u52a8\u548c\u5173\u8282\u5728IMU\u5750\u6807\u7cfb\u4e2d\u7684\u4f4d\u7f6e\uff0c\u9002\u7528\u4e8e\u8fd0\u52a8\u94fe\u7ed3\u6784\u3002", "result": "\u5728\u6a21\u62df\u7684\u4e09\u8fde\u6746\u673a\u68b0\u81c2\u6570\u636e\u548c\u4eba\u4f53\u884c\u8d70\u6570\u636e\u4e0a\u6d4b\u8bd5\uff0c\u7b97\u6cd5\u80fd\u591f\u63d0\u4f9b\u65e0\u6f02\u79fb\u7684\u76f8\u5bf9\u548c\u7edd\u5bf9\u65b9\u5411\u4f30\u8ba1\uff0c\u4e14\u5173\u8282\u4f4d\u7f6e\u4f30\u8ba1\u6536\u655b\u5feb\u901f\u7a33\u5065\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u65e0\u9700\u6821\u51c6\u7684\u5b9e\u65f6\u60ef\u6027\u8fd0\u52a8\u6355\u6349\uff0c\u5177\u6709\u8f7b\u91cf\u7ea7\u3001\u65e0\u6f02\u79fb\u548c\u5feb\u901f\u6536\u655b\u7684\u7279\u70b9\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u8fd0\u52a8\u573a\u666f\u3002"}}
{"id": "2509.12273", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12273", "abs": "https://arxiv.org/abs/2509.12273", "authors": ["Liangqi Yuan", "Dong-Jun Han", "Christopher G. Brinton", "Sabine Brunswicker"], "title": "LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences", "comment": null, "summary": "The rise of large language models (LLMs) has made natural language-driven\nroute planning an emerging research area that encompasses rich user objectives.\nCurrent research exhibits two distinct approaches: direct route planning using\nLLM-as-Agent and graph-based searching strategies. However, LLMs in the former\napproach struggle to handle extensive map data, while the latter shows limited\ncapability in understanding natural language preferences. Additionally, a more\ncritical challenge arises from the highly heterogeneous and unpredictable\nspatio-temporal distribution of users across the globe. In this paper, we\nintroduce a novel LLM-Assisted route Planning (LLMAP) system that employs an\nLLM-as-Parser to comprehend natural language, identify tasks, and extract user\npreferences and recognize task dependencies, coupled with a Multi-Step Graph\nconstruction with iterative Search (MSGS) algorithm as the underlying solver\nfor optimal route finding. Our multi-objective optimization approach adaptively\ntunes objective weights to maximize points of interest (POI) quality and task\ncompletion rate while minimizing route distance, subject to three key\nconstraints: user time limits, POI opening hours, and task dependencies. We\nconduct extensive experiments using 1,000 routing prompts sampled with varying\ncomplexity across 14 countries and 27 cities worldwide. The results demonstrate\nthat our approach achieves superior performance with guarantees across multiple\nconstraints.", "AI": {"tldr": "\u63d0\u51fa\u4e86LLMAP\u7cfb\u7edf\uff0c\u7ed3\u5408LLM\u89e3\u6790\u81ea\u7136\u8bed\u8a00\u504f\u597d\u548c\u591a\u6b65\u56fe\u641c\u7d22\u7b97\u6cd5\uff0c\u5b9e\u73b0\u591a\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u6700\u4f18\u8def\u7ebf\u89c4\u5212", "motivation": "\u89e3\u51b3\u73b0\u6709LLM\u8def\u7ebf\u89c4\u5212\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u5927\u89c4\u6a21\u5730\u56fe\u6570\u636e\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u504f\u597d\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u7528\u6237\u65f6\u7a7a\u5206\u5e03\u9ad8\u5ea6\u5f02\u6784\u7684\u6311\u6218", "method": "\u4f7f\u7528LLM-as-Parser\u89e3\u6790\u81ea\u7136\u8bed\u8a00\u5e76\u63d0\u53d6\u7528\u6237\u504f\u597d\uff0c\u7ed3\u5408Multi-Step Graph construction with iterative Search (MSGS)\u7b97\u6cd5\u8fdb\u884c\u6700\u4f18\u8def\u7ebf\u641c\u7d22\uff0c\u91c7\u7528\u591a\u76ee\u6807\u4f18\u5316\u81ea\u9002\u5e94\u8c03\u6574\u6743\u91cd", "result": "\u572814\u4e2a\u56fd\u5bb627\u4e2a\u57ce\u5e02\u76841000\u4e2a\u8def\u7531\u63d0\u793a\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u591a\u91cd\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd", "conclusion": "LLMAP\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5904\u7406\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u8def\u7ebf\u89c4\u5212\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u591a\u7ea6\u675f\u6761\u4ef6\u7684\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u8def\u7ebf\u89c4\u5212"}}
{"id": "2509.12700", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2509.12700", "abs": "https://arxiv.org/abs/2509.12700", "authors": ["Shuyi Yao", "Alejandro C. Frery", "Timo Balz"], "title": "Shape-to-Scale InSAR Adaptive Filtering and Phase Linking under Complex Elliptical Models", "comment": null, "summary": "Distributed scatterers in InSAR (DS-InSAR) processing are essential for\nretrieving surface deformation in areas lacking strong point targets.\nConventional workflows typically involve selecting statistically homogeneous\npixels based on amplitude similarity, followed by phase estimation under the\ncomplex circular Gaussian model. However, amplitude statistics primarily\nreflect the backscattering strength of surface targets and may not sufficiently\ncapture differences in decorrelation behavior. For example, when distinct\nscatterers exhibit similar backscatter strength but differ in coherence,\namplitude-based selection methods may fail to differentiate them. Moreover,\nCCG-based phase estimators may lack robustness and suffer performance\ndegradation under non-Rayleigh amplitude fluctuations.\n  Centered around scale-invariant second-order statistics, we propose\n``Shape-to-Scale,'' a novel DS-InSAR framework. We first identify pixels that\nshare a common angular scattering structure (``shape statistically homogeneous\npixels'') with an angular consistency adaptive filter: a parametric selection\nmethod based on the complex angular central Gaussian distribution. Then, we\nintroduce a complex generalized Gaussian-based phase estimation approach that\nis robust to potential non-Rayleigh scattering.\n  Experiments on both simulated and SAR datasets show that the proposed\nframework improves coherence structure clustering and enhances phase estimation\nrobustness. This work provides a unified and physically interpretable strategy\nfor DS-InSAR processing and offers new insights for high-resolution SAR time\nseries analysis.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5c3a\u5ea6\u4e0d\u53d8\u4e8c\u9636\u7edf\u8ba1\u91cf\u7684Shape-to-Scale DS-InSAR\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u5ea6\u4e00\u81f4\u6027\u81ea\u9002\u5e94\u6ee4\u6ce2\u9009\u62e9\u5f62\u72b6\u7edf\u8ba1\u540c\u8d28\u50cf\u7d20\uff0c\u5e76\u91c7\u7528\u590d\u5e7f\u4e49\u9ad8\u65af\u76f8\u4f4d\u4f30\u8ba1\u65b9\u6cd5\uff0c\u63d0\u9ad8\u76f8\u5e72\u7ed3\u6784\u805a\u7c7b\u548c\u76f8\u4f4d\u4f30\u8ba1\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edfDS-InSAR\u65b9\u6cd5\u57fa\u4e8e\u5e45\u5ea6\u76f8\u4f3c\u6027\u9009\u62e9\u7edf\u8ba1\u540c\u8d28\u50cf\u7d20\uff0c\u4f46\u5e45\u5ea6\u7edf\u8ba1\u4e3b\u8981\u53cd\u6620\u76ee\u6807\u540e\u5411\u6563\u5c04\u5f3a\u5ea6\uff0c\u65e0\u6cd5\u5145\u5206\u6355\u6349\u53bb\u76f8\u5173\u884c\u4e3a\u7684\u5dee\u5f02\u3002\u5f53\u4e0d\u540c\u6563\u5c04\u4f53\u5177\u6709\u76f8\u4f3c\u540e\u5411\u6563\u5c04\u5f3a\u5ea6\u4f46\u76f8\u5e72\u6027\u4e0d\u540c\u65f6\uff0c\u57fa\u4e8e\u5e45\u5ea6\u7684\u9009\u62e9\u65b9\u6cd5\u53ef\u80fd\u5931\u6548\uff0c\u4e14CCG\u76f8\u4f4d\u4f30\u8ba1\u5668\u5728\u975e\u745e\u5229\u5e45\u5ea6\u6ce2\u52a8\u4e0b\u7f3a\u4e4f\u9c81\u68d2\u6027\u3002", "method": "1) \u4f7f\u7528\u57fa\u4e8e\u590d\u89d2\u5ea6\u4e2d\u5fc3\u9ad8\u65af\u5206\u5e03\u7684\u89d2\u5ea6\u4e00\u81f4\u6027\u81ea\u9002\u5e94\u6ee4\u6ce2\u5668\uff0c\u9009\u62e9\u5177\u6709\u5171\u540c\u89d2\u5ea6\u6563\u5c04\u7ed3\u6784\u7684\u5f62\u72b6\u7edf\u8ba1\u540c\u8d28\u50cf\u7d20\uff1b2) \u63d0\u51fa\u57fa\u4e8e\u590d\u5e7f\u4e49\u9ad8\u65af\u5206\u5e03\u7684\u76f8\u4f4d\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5bf9\u6f5c\u5728\u7684\u975e\u745e\u5229\u6563\u5c04\u5177\u6709\u9c81\u68d2\u6027\u3002", "result": "\u5728\u6a21\u62df\u548cSAR\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u6539\u5584\u4e86\u76f8\u5e72\u7ed3\u6784\u805a\u7c7b\uff0c\u589e\u5f3a\u4e86\u76f8\u4f4d\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aDS-InSAR\u5904\u7406\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u7269\u7406\u53ef\u89e3\u91ca\u7684\u7b56\u7565\uff0c\u4e3a\u9ad8\u5206\u8fa8\u7387SAR\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2509.12364", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12364", "abs": "https://arxiv.org/abs/2509.12364", "authors": ["Nacira Agram", "Fred Espen Benth", "Giulia Pucci", "Jan Rems"], "title": "A Deep Learning Approach to Renewable Capacity Installation under Jump Uncertainty", "comment": "29 pages, 12 figures", "summary": "We study a stochastic model for the installation of renewable energy capacity\nunder demand uncertainty and jump driven dynamics. The system is governed by a\nmultidimensional Ornstein-Uhlenbeck (OU) process driven by a subordinator,\ncapturing abrupt variations in renewable generation and electricity load.\nInstallation decisions are modeled through control actions that increase\ncapacity in response to environmental and economic conditions.\n  We consider two distinct solution approaches. First, we implement a\nstructured threshold based control rule, where capacity is increased\nproportionally when the stochastic capacity factor falls below a fixed level.\nThis formulation leads to a nonlinear partial integro-differential equation\n(PIDE), which we solve by reformulating it as a backward stochastic\ndifferential equation with jumps. We extend the DBDP solver in\n\\cite{hure2020deep} to the pure jump setting, employing a dual neural network\narchitecture to approximate both the value function and the jump sensitivity.\n  Second, we propose a fully data driven deep control algorithm that directly\nlearns the optimal feedback policy by minimizing the expected cost functional\nusing neural networks. This approach avoids assumptions on the form of the\ncontrol rule and enables adaptive interventions based on the evolving system\nstate.\n  Numerical experiments highlight the strengths of both methods. While the\nthreshold based BSDE approach offers interpretability and tractability, the\ndeep control strategy achieves improved performance through flexibility in\ncapacity allocation. Together, these tools provide a robust framework for\ndecision support in long term renewable energy expansion under uncertainty.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53ef\u518d\u751f\u80fd\u6e90\u5bb9\u91cf\u5b89\u88c5\u7684\u968f\u673a\u6a21\u578b\uff0c\u5728\u9700\u6c42\u4e0d\u786e\u5b9a\u6027\u548c\u8df3\u8dc3\u9a71\u52a8\u52a8\u6001\u4e0b\uff0c\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\uff1a\u57fa\u4e8e\u9608\u503c\u7684BSDE\u63a7\u5236\u548c\u6570\u636e\u9a71\u52a8\u7684\u6df1\u5ea6\u63a7\u5236\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u5728\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u548c\u7535\u529b\u8d1f\u8377\u5b58\u5728\u7a81\u7136\u53d8\u5316\u7684\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\uff0c\u5982\u4f55\u4f18\u5316\u53ef\u518d\u751f\u80fd\u6e90\u5bb9\u91cf\u7684\u5b89\u88c5\u51b3\u7b56\uff0c\u4ee5\u5e94\u5bf9\u73af\u5883\u548c\u7ecf\u6d4e\u6761\u4ef6\u7684\u53d8\u5316\u3002", "method": "1) \u57fa\u4e8e\u9608\u503c\u7684\u63a7\u5236\u89c4\u5219\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u504f\u79ef\u5206\u5fae\u5206\u65b9\u7a0b(PIDE)\u6c42\u89e3\uff1b2) \u6570\u636e\u9a71\u52a8\u7684\u6df1\u5ea6\u63a7\u5236\u7b97\u6cd5\uff0c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u5b66\u4e60\u6700\u4f18\u53cd\u9988\u7b56\u7565\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u4e24\u79cd\u65b9\u6cd5\u5404\u6709\u4f18\u52bf\uff1a\u9608\u503cBSDE\u65b9\u6cd5\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u6613\u5904\u7406\u6027\uff0c\u6df1\u5ea6\u63a7\u5236\u7b56\u7565\u901a\u8fc7\u7075\u6d3b\u7684\u5bb9\u91cf\u5206\u914d\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u4e24\u79cd\u5de5\u5177\u4e3a\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u8fdb\u884c\u957f\u671f\u53ef\u518d\u751f\u80fd\u6e90\u6269\u5c55\u51b3\u7b56\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u7075\u6d3b\u6027\u4f18\u52bf\u3002"}}
{"id": "2509.12403", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2509.12403", "abs": "https://arxiv.org/abs/2509.12403", "authors": ["T\u00e2nia Carvalho", "Jos\u00e9 Barata", "Henish Balu", "Filipa Moreira", "Jo\u00e3o Bastos", "Lu\u00eds Antunes"], "title": "Privacy-Driven Network Data for Smart Cities", "comment": null, "summary": "A smart city is essential for sustainable urban development. In addition to\ncitizen engagement, a smart city enables connected infrastructure, data-driven\ndecision making and smart mobility. For most of these features, network data\nplays a critical role, particularly from public Wi-Fi infrastructures, where\ncities can benefit from optimized services such as public transport management\nand the safety and efficiency of large events. One of the biggest concerns in\ndeveloping a smart city is using secure and private data. This is particularly\nrelevant in the case of Wi-Fi network data, where sensitive information can be\ncollected. This paper specifically addresses the problem of sharing secure data\nto enhance the quality of the Wi-Fi network in a city. Despite the high\nimportance of this type of data, related work focuses on improving the safety\nof mobility patterns, targeting only the protection of MAC addresses. On the\nopposite side, we provide a practical methodology for safeguarding all\nattributes in real Wi-Fi network data. This study was developed in\ncollaboration with a multidisciplinary team of legal experts, data custodians\nand technical privacy specialists, resulting in high-quality data. On top of\nthat, we show how to integrate the legal considerations for secure data\nsharing. Our approach promotes data-driven innovation and privacy awareness in\nthe context of smart city initiatives, which have been tested in a real\nscenario.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4fdd\u62a4\u667a\u80fd\u57ce\u5e02Wi-Fi\u7f51\u7edc\u6570\u636e\u6240\u6709\u5c5e\u6027\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u7ed3\u5408\u6cd5\u5f8b\u548c\u6280\u672f\u9690\u79c1\u4fdd\u62a4\uff0c\u5b9e\u73b0\u5b89\u5168\u6570\u636e\u5171\u4eab", "motivation": "\u667a\u80fd\u57ce\u5e02\u53d1\u5c55\u9700\u8981\u5b89\u5168\u79c1\u5bc6\u7684\u6570\u636e\u5171\u4eab\uff0c\u7279\u522b\u662fWi-Fi\u7f51\u7edc\u6570\u636e\u5305\u542b\u654f\u611f\u4fe1\u606f\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8MAC\u5730\u5740\u4fdd\u62a4\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u6570\u636e\u5b89\u5168\u4fdd\u969c\u65b9\u6cd5", "method": "\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u3001\u6570\u636e\u4fdd\u7ba1\u4eba\u548c\u6280\u672f\u9690\u79c1\u4e13\u5bb6\u5408\u4f5c\u5f00\u53d1\u7684\u591a\u5b66\u79d1\u65b9\u6cd5\uff0c\u6574\u5408\u6cd5\u5f8b\u8003\u8651\u56e0\u7d20\uff0c\u63d0\u4f9b\u4fdd\u62a4\u6240\u6709Wi-Fi\u7f51\u7edc\u6570\u636e\u5c5e\u6027\u7684\u5b9e\u7528\u65b9\u6cd5\u8bba", "result": "\u751f\u6210\u4e86\u9ad8\u8d28\u91cf\u7684\u5b89\u5168\u6570\u636e\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u6d4b\u8bd5\u4e86\u8be5\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u4e86\u6570\u636e\u9a71\u52a8\u521b\u65b0\u548c\u9690\u79c1\u610f\u8bc6", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u667a\u80fd\u57ce\u5e02\u5021\u8bae\u63d0\u4f9b\u4e86\u5b89\u5168\u6570\u636e\u5171\u4eab\u7684\u7efc\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u6570\u636e\u5229\u7528\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u9700\u6c42"}}
{"id": "2509.12985", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2509.12985", "abs": "https://arxiv.org/abs/2509.12985", "authors": ["Alessandro Casini", "Adam McCloskey", "Luca Rolla", "Raimondo Pala"], "title": "Dynamic Local Average Treatment Effects in Time Series", "comment": null, "summary": "This paper discusses identification, estimation, and inference on dynamic\nlocal average treatment effects (LATEs) in instrumental variables (IVs)\nsettings. First, we show that compliers--observations whose treatment status is\naffected by the instrument--can be identified individually in time series data\nusing smoothness assumptions and local comparisons of treatment assignments.\nSecond, we show that this result enables not only better interpretability of IV\nestimates but also direct testing of the exclusion restriction by comparing\noutcomes among identified non-compliers across instrument values. Third, we\ndocument pervasive weak identification in applied work using IVs with time\nseries data by surveying recent publications in leading economics journals.\nHowever, we find that strong identification often holds in large subsamples for\nwhich the instrument induces changes in the treatment. Motivated by this, we\nintroduce a method based on dynamic programming to detect the most\nstrongly-identified subsample and show how to use this subsample to improve\nestimation and inference. We also develop new identification-robust inference\nprocedures that focus on the most strongly-identified subsample, offering\nefficiency gains relative to existing full sample identification-robust\ninference when identification fails over parts of the sample. Finally, we apply\nour results to heteroskedasticity-based identification of monetary policy\neffects. We find that about 75% of observations are compliers (i.e., cases\nwhere the variance of the policy shifts up on FOMC announcement days), and we\nfail to reject the exclusion restriction. Estimation using the most\nstrongly-identified subsample helps reconcile conflicting IV and GMM estimates\nin the literature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u8bc6\u522b\u3001\u4f30\u8ba1\u548c\u63a8\u65ad\u52a8\u6001\u5c40\u90e8\u5e73\u5747\u5904\u7406\u6548\u5e94(LATE)\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u4e2a\u4f53\u4f9d\u4ece\u8005\u3001\u68c0\u9a8c\u6392\u9664\u9650\u5236\u3001\u68c0\u6d4b\u5f3a\u8bc6\u522b\u5b50\u6837\u672c\uff0c\u5e76\u5e94\u7528\u4e8e\u8d27\u5e01\u653f\u7b56\u6548\u5e94\u8bc6\u522b\u3002", "motivation": "\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217IV\u8bbe\u7f6e\u4e2d\u666e\u904d\u5b58\u5728\u7684\u5f31\u8bc6\u522b\u95ee\u9898\uff0c\u4ee5\u53ca\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u8bc6\u522b\u4e2a\u4f53\u4f9d\u4ece\u8005\u548c\u68c0\u9a8c\u6392\u9664\u9650\u5236\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8IV\u4f30\u8ba1\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u5e73\u6ed1\u6027\u5047\u8bbe\u548c\u5c40\u90e8\u5904\u7406\u5206\u914d\u6bd4\u8f83\u6765\u8bc6\u522b\u4e2a\u4f53\u4f9d\u4ece\u8005\uff1b\u5f15\u5165\u57fa\u4e8e\u52a8\u6001\u89c4\u5212\u7684\u65b9\u6cd5\u68c0\u6d4b\u6700\u5f3a\u8bc6\u522b\u5b50\u6837\u672c\uff1b\u5f00\u53d1\u9488\u5bf9\u5f3a\u8bc6\u522b\u5b50\u6837\u672c\u7684\u8bc6\u522b\u7a33\u5065\u63a8\u65ad\u7a0b\u5e8f\u3002", "result": "\u5728\u5e94\u7528\u7814\u7a76\u4e2d\u53d1\u73b0\u666e\u904d\u5b58\u5728\u5f31\u8bc6\u522b\uff0c\u4f46\u5728\u8bf1\u5bfc\u5904\u7406\u53d8\u5316\u7684\u5b50\u6837\u672c\u4e2d\u5f3a\u8bc6\u522b\u5f80\u5f80\u6210\u7acb\uff1b\u5728\u8d27\u5e01\u653f\u7b56\u5e94\u7528\u4e2d\uff0c\u7ea675%\u7684\u89c2\u6d4b\u503c\u662f\u4f9d\u4ece\u8005\uff0c\u4e14\u65e0\u6cd5\u62d2\u7edd\u6392\u9664\u9650\u5236\uff1b\u4f7f\u7528\u6700\u5f3a\u8bc6\u522b\u5b50\u6837\u672c\u6709\u52a9\u4e8e\u8c03\u548c\u6587\u732e\u4e2dIV\u548cGMM\u4f30\u8ba1\u7684\u77db\u76fe\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86IV\u4f30\u8ba1\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u8fd8\u80fd\u76f4\u63a5\u68c0\u9a8c\u5173\u952e\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u5173\u6ce8\u5f3a\u8bc6\u522b\u5b50\u6837\u672c\u6539\u5584\u4e86\u4f30\u8ba1\u6548\u7387\u548c\u63a8\u65ad\u53ef\u9760\u6027\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217IV\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2509.12415", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.12415", "abs": "https://arxiv.org/abs/2509.12415", "authors": ["Rashid Mushkani"], "title": "Prompt Commons: Collective Prompting as Governance for Urban AI", "comment": null, "summary": "Large Language Models (LLMs) are entering urban governance, yet their outputs\nare highly sensitive to prompts that carry value judgments. We propose Prompt\nCommons - a versioned, community-maintained repository of prompts with\ngovernance metadata, licensing, and moderation - to steer model behaviour\ntoward pluralism. Using a Montreal dataset (443 human prompts; 3,317 after\naugmentation), we pilot three governance states (open, curated, veto-enabled).\nOn a contested policy benchmark, a single-author prompt yields 24 percent\nneutral outcomes; commons-governed prompts raise neutrality to 48-52 percent\nwhile retaining decisiveness where appropriate. In a synthetic incident log, a\nveto-enabled regime reduces time-to-remediation for harmful outputs from 30.5\n+/- 8.9 hours (open) to 5.6 +/- 1.5 hours. We outline licensing (CC BY/BY-SA\nfor prompts with optional OpenRAIL-style restrictions for artefacts), auditable\nmoderation, and safeguards against dominance capture. Prompt governance offers\na practical lever for cities to align AI with local values and accountability.", "AI": {"tldr": "\u63d0\u51fa\u4e86Prompt Commons\u6846\u67b6\uff0c\u901a\u8fc7\u793e\u533a\u7ef4\u62a4\u7684\u63d0\u793a\u8bcd\u5e93\u548c\u6cbb\u7406\u673a\u5236\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57ce\u5e02\u6cbb\u7406\u4e2d\u66f4\u4e2d\u7acb\u548c\u591a\u5143\u5316\uff0c\u5c06\u4e2d\u7acb\u7ed3\u679c\u4ece24%\u63d0\u5347\u523048-52%\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u6709\u5bb3\u8f93\u51fa\u7684\u4fee\u590d\u65f6\u95f4\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57ce\u5e02\u6cbb\u7406\u4e2d\u7684\u5e94\u7528\u5bf9\u5305\u542b\u4ef7\u503c\u5224\u65ad\u7684\u63d0\u793a\u8bcd\u9ad8\u5ea6\u654f\u611f\uff0c\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u5f15\u5bfc\u6a21\u578b\u884c\u4e3a\u8d8b\u5411\u591a\u5143\u5316\u548c\u4e2d\u7acb\u6027\uff0c\u907f\u514d\u5355\u4e00\u4ef7\u503c\u89c2\u4e3b\u5bfc\u3002", "method": "\u5efa\u7acb\u7248\u672c\u5316\u3001\u793e\u533a\u7ef4\u62a4\u7684\u63d0\u793a\u8bcd\u5e93\uff08Prompt Commons\uff09\uff0c\u5305\u542b\u6cbb\u7406\u5143\u6570\u636e\u3001\u8bb8\u53ef\u548c\u5ba1\u6838\u673a\u5236\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cd\u6cbb\u7406\u72b6\u6001\uff08\u5f00\u653e\u3001\u7b56\u5c55\u3001\u5426\u51b3\u542f\u7528\uff09\uff0c\u4f7f\u7528\u8499\u7279\u5229\u5c14\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728\u4e89\u8bae\u653f\u7b56\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5355\u4e00\u4f5c\u8005\u63d0\u793a\u8bcd\u4ea7\u751f24%\u7684\u4e2d\u7acb\u7ed3\u679c\uff0c\u800c\u901a\u8fc7commons\u6cbb\u7406\u7684\u63d0\u793a\u8bcd\u5c06\u4e2d\u7acb\u6027\u63d0\u5347\u523048-52%\uff1b\u5728\u5408\u6210\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\uff0c\u5426\u51b3\u542f\u7528\u673a\u5236\u5c06\u6709\u5bb3\u8f93\u51fa\u7684\u4fee\u590d\u65f6\u95f4\u4ece30.5\u00b18.9\u5c0f\u65f6\u51cf\u5c11\u52305.6\u00b11.5\u5c0f\u65f6\u3002", "conclusion": "\u63d0\u793a\u8bcd\u6cbb\u7406\u4e3a\u57ce\u5e02\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u5de5\u5177\uff0c\u4f7fAI\u4e0e\u5f53\u5730\u4ef7\u503c\u89c2\u548c\u95ee\u8d23\u5236\u4fdd\u6301\u4e00\u81f4\uff0c\u901a\u8fc7\u793e\u533a\u9a71\u52a8\u7684\u63d0\u793a\u8bcd\u5e93\u548c\u6cbb\u7406\u6846\u67b6\u53ef\u4ee5\u5b9e\u73b0\u66f4\u4e2d\u7acb\u3001\u591a\u5143\u5316\u7684\u6a21\u578b\u884c\u4e3a\u3002"}}
{"id": "2509.12444", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.12444", "abs": "https://arxiv.org/abs/2509.12444", "authors": ["Weiting Feng", "Kyle L. Walker", "Yunjie Yang", "Francesco Giorgio-Serchi"], "title": "Computing forward statics from tendon-length in flexible-joint hyper-redundant manipulators", "comment": "To be presented at IROS 2025, Hangzhou, China", "summary": "Hyper-redundant tendon-driven manipulators offer greater flexibility and\ncompliance over traditional manipulators. A common way of controlling such\nmanipulators relies on adjusting tendon lengths, which is an accessible control\nparameter. This approach works well when the kinematic configuration is\nrepresentative of the real operational conditions. However, when dealing with\nmanipulators of larger size subject to gravity, it becomes necessary to solve a\nstatic force problem, using tendon force as the input and employing a mapping\nfrom the configuration space to retrieve tendon length. Alternatively,\nmeasurements of the manipulator posture can be used to iteratively adjust\ntendon lengths to achieve a desired posture. Hence, either tension measurement\nor state estimation of the manipulator are required, both of which are not\nalways accurately available. Here, we propose a solution by reconciling cables\ntension and length as the input for the solution of the system forward statics.\nWe develop a screw-based formulation for a tendon-driven, multi-segment,\nhyper-redundant manipulator with elastic joints and introduce a forward statics\niterative solution method that equivalently makes use of either tendon length\nor tension as the input. This strategy is experimentally validated using a\ntraditional tension input first, subsequently showing the efficacy of the\nmethod when exclusively tendon lengths are used. The results confirm the\npossibility to perform open-loop control in static conditions using a kinematic\ninput only, thus bypassing some of the practical problems with tension\nmeasurement and state estimation of hyper-redundant systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u87ba\u65cb\u7406\u8bba\u7684\u808c\u8171\u9a71\u52a8\u8d85\u5197\u4f59\u673a\u68b0\u81c2\u9759\u6001\u529b\u5b66\u6c42\u89e3\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u4f7f\u7528\u808c\u8171\u957f\u5ea6\u6216\u5f20\u529b\u4f5c\u4e3a\u8f93\u5165\uff0c\u5b9e\u73b0\u5f00\u73af\u63a7\u5236\u3002", "motivation": "\u4f20\u7edf\u808c\u8171\u9a71\u52a8\u673a\u68b0\u81c2\u63a7\u5236\u9700\u8981\u5f20\u529b\u6d4b\u91cf\u6216\u72b6\u6001\u4f30\u8ba1\uff0c\u4f46\u5728\u5927\u578b\u673a\u68b0\u81c2\u53d7\u91cd\u529b\u5f71\u54cd\u65f6\u8fd9\u4e9b\u53c2\u6570\u96be\u4ee5\u51c6\u786e\u83b7\u53d6\uff0c\u9700\u8981\u5f00\u53d1\u4ec5\u4f7f\u7528\u808c\u8171\u957f\u5ea6\u4f5c\u4e3a\u8f93\u5165\u7684\u9759\u6001\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u87ba\u65cb\u7406\u8bba\u7684\u808c\u8171\u9a71\u52a8\u591a\u6bb5\u8d85\u5197\u4f59\u673a\u68b0\u81c2\u5f39\u6027\u5173\u8282\u5efa\u6a21\uff0c\u63d0\u51fa\u524d\u5411\u9759\u6001\u8fed\u4ee3\u6c42\u89e3\u65b9\u6cd5\uff0c\u53ef\u7b49\u6548\u4f7f\u7528\u808c\u8171\u957f\u5ea6\u6216\u5f20\u529b\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4f20\u7edf\u5f20\u529b\u8f93\u5165\u4e0b\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u4ec5\u4f7f\u7528\u808c\u8171\u957f\u5ea6\u4f5c\u4e3a\u8f93\u5165\u7684\u53ef\u884c\u6027\uff0c\u5b9e\u73b0\u4e86\u9759\u6001\u6761\u4ef6\u4e0b\u7684\u5f00\u73af\u63a7\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u8d85\u5197\u4f59\u7cfb\u7edf\u5f20\u529b\u6d4b\u91cf\u548c\u72b6\u6001\u4f30\u8ba1\u7684\u5b9e\u9645\u95ee\u9898\uff0c\u4e3a\u4ec5\u4f7f\u7528\u8fd0\u52a8\u5b66\u8f93\u5165\u8fdb\u884c\u9759\u6001\u5f00\u73af\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.12274", "categories": ["cs.AI", "cs.CV", "cs.LG", "68T07, 68T45, 68U10", "I.4.8; I.2.6; I.5.4; C.3"], "pdf": "https://arxiv.org/pdf/2509.12274", "abs": "https://arxiv.org/abs/2509.12274", "authors": ["Mohammadreza Narimani", "Ali Hajiahmad", "Ali Moghimi", "Reza Alimardani", "Shahin Rafiee", "Amir Hossein Mirzabe"], "title": "Developing an aeroponic smart experimental greenhouse for controlling irrigation and plant disease detection using deep learning and IoT", "comment": "Author-accepted version. Presented at ASABE Annual International\n  Meeting (AIM) 2021 (virtual), Paper 2101252. Please cite the published\n  meeting paper: doi:10.13031/aim.202101252. Minor wording and formatting\n  updates in this preprint", "summary": "Controlling environmental conditions and monitoring plant status in\ngreenhouses is critical to promptly making appropriate management decisions\naimed at promoting crop production. The primary objective of this research\nstudy was to develop and test a smart aeroponic greenhouse on an experimental\nscale where the status of Geranium plant and environmental conditions are\ncontinuously monitored through the integration of the internet of things (IoT)\nand artificial intelligence (AI). An IoT-based platform was developed to\ncontrol the environmental conditions of plants more efficiently and provide\ninsights to users to make informed management decisions. In addition, we\ndeveloped an AI-based disease detection framework using VGG-19,\nInceptionResNetV2, and InceptionV3 algorithms to analyze the images captured\nperiodically after an intentional inoculation. The performance of the AI\nframework was compared with an expert's evaluation of disease status.\nPreliminary results showed that the IoT system implemented in the greenhouse\nenvironment is able to publish data such as temperature, humidity, water flow,\nand volume of charge tanks online continuously to users and adjust the\ncontrolled parameters to provide an optimal growth environment for the plants.\nFurthermore, the results of the AI framework demonstrate that the VGG-19\nalgorithm was able to identify drought stress and rust leaves from healthy\nleaves with the highest accuracy, 92% among the other algorithms.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u7269\u8054\u7f51\u548c\u4eba\u5de5\u667a\u80fd\u7684\u667a\u80fd\u6c14\u96fe\u683d\u57f9\u6e29\u5ba4\u7cfb\u7edf\uff0c\u7528\u4e8e\u76d1\u6d4b\u5929\u7afa\u8475\u690d\u7269\u72b6\u6001\u548c\u73af\u5883\u6761\u4ef6\uff0c\u5e76\u901a\u8fc7AI\u7b97\u6cd5\u5b9e\u73b0\u75be\u75c5\u68c0\u6d4b", "motivation": "\u6e29\u5ba4\u73af\u5883\u63a7\u5236\u548c\u690d\u7269\u72b6\u6001\u76d1\u6d4b\u5bf9\u4f5c\u7269\u751f\u4ea7\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u667a\u80fd\u5316\u7cfb\u7edf\u6765\u63d0\u9ad8\u7ba1\u7406\u6548\u7387\u548c\u51b3\u7b56\u8d28\u91cf", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u7269\u8054\u7f51\u7684\u5e73\u53f0\u63a7\u5236\u73af\u5883\u6761\u4ef6\uff0c\u5e76\u4f7f\u7528VGG-19\u3001InceptionResNetV2\u548cInceptionV3\u7b97\u6cd5\u6784\u5efaAI\u75be\u75c5\u68c0\u6d4b\u6846\u67b6\uff0c\u5206\u6790\u5b9a\u671f\u6355\u83b7\u7684\u56fe\u50cf", "result": "\u7269\u8054\u7f51\u7cfb\u7edf\u80fd\u6301\u7eed\u5728\u7ebf\u53d1\u5e03\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u6c34\u6d41\u7b49\u6570\u636e\u5e76\u8c03\u6574\u63a7\u5236\u53c2\u6570\uff1bVGG-19\u7b97\u6cd5\u5728\u75be\u75c5\u68c0\u6d4b\u4e2d\u8fbe\u523092%\u7684\u6700\u9ad8\u51c6\u786e\u7387", "conclusion": "\u8be5\u667a\u80fd\u6e29\u5ba4\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u73af\u5883\u76d1\u6d4b\u63a7\u5236\u548c\u690d\u7269\u75be\u75c5\u68c0\u6d4b\uff0cVGG-19\u7b97\u6cd5\u5728\u75be\u75c5\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4e3a\u7cbe\u51c6\u519c\u4e1a\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13174", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2509.13174", "abs": "https://arxiv.org/abs/2509.13174", "authors": ["Mengqi Cen", "Xuejing Meng", "X. Joan Hu", "Juxin Liu", "Jianhong Wu"], "title": "PDE-Based Bayesian Hierarchical Modeling for Event Spread, with Application to COVID-19 Infection", "comment": null, "summary": "We extended the Wikle's Bayesian hierarchical model based on a\ndiffusion-reaction equation [Wikle, 2003] to investigate the COVID-19\nspatio-temporal spread events across the USA from Mar 2020 to Feb 2022. Our\nmodel incorporated an advection term to account for the intra-state spread\ntrend. We applied a Markov chain Monte Carlo (MCMC) method to obtain samples\nfrom the posterior distribution of the parameters. We implemented the approach\nvia the collection of the COVID-19 infections across the states overtime from\nthe New York Times. Our analysis shows that our approach can be robust to model\nmisspecification to a certain extent and outperforms a few other approaches in\nthe simulation settings. Our analysis results confirm that the diffusion rate\nis heterogeneous across the USA, and both the growth rate and the advection\nvelocity are time-varying.", "AI": {"tldr": "\u6269\u5c55Wikle\u7684\u8d1d\u53f6\u65af\u5c42\u6b21\u6269\u6563-\u53cd\u5e94\u6a21\u578b\uff0c\u52a0\u5165\u5e73\u6d41\u9879\u5206\u6790\u7f8e\u56fdCOVID-19\u65f6\u7a7a\u4f20\u64ad\uff0c\u53d1\u73b0\u6269\u6563\u7387\u5f02\u8d28\u3001\u589e\u957f\u7387\u548c\u6d41\u901f\u65f6\u53d8", "motivation": "\u7814\u7a76COVID-19\u5728\u7f8e\u56fd\u7684\u65f6\u7a7a\u4f20\u64ad\u6a21\u5f0f\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u6a21\u578b\u6765\u6355\u6349\u5dde\u9645\u4f20\u64ad\u8d8b\u52bf\u548c\u65f6\u7a7a\u52a8\u6001", "method": "\u57fa\u4e8e\u6269\u6563-\u53cd\u5e94\u65b9\u7a0b\u7684\u8d1d\u53f6\u65af\u5c42\u6b21\u6a21\u578b\uff0c\u52a0\u5165\u5e73\u6d41\u9879\u5904\u7406\u5dde\u5185\u4f20\u64ad\u8d8b\u52bf\uff0c\u4f7f\u7528MCMC\u65b9\u6cd5\u8fdb\u884c\u53c2\u6570\u540e\u9a8c\u91c7\u6837", "result": "\u6a21\u578b\u5bf9\u9519\u8bef\u8bbe\u5b9a\u5177\u6709\u4e00\u5b9a\u9c81\u68d2\u6027\uff0c\u5728\u6a21\u62df\u8bbe\u7f6e\u4e2d\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u6269\u6563\u7387\u5728\u7f8e\u56fd\u5404\u5730\u5f02\u8d28\uff0c\u589e\u957f\u7387\u548c\u6d41\u901f\u968f\u65f6\u95f4\u53d8\u5316", "conclusion": "\u6269\u5c55\u7684\u6269\u6563-\u53cd\u5e94\u6a21\u578b\u80fd\u6709\u6548\u6355\u6349COVID-19\u65f6\u7a7a\u4f20\u64ad\u7279\u5f81\uff0c\u4e3a\u4f20\u67d3\u75c5\u5efa\u6a21\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6cd5"}}
{"id": "2509.12378", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12378", "abs": "https://arxiv.org/abs/2509.12378", "authors": ["Ruining Yang", "Jingyuan Zhou", "Qiqing Wang", "Jinhao Liang", "Kaidi Yang"], "title": "Platoon-Centric Green Light Optimal Speed Advisory Using Safe Reinforcement Learning", "comment": null, "summary": "With recent advancements in Connected Autonomous Vehicles (CAVs), Green Light\nOptimal Speed Advisory (GLOSA) emerges as a promising eco-driving strategy to\nreduce the number of stops and idle time at intersections, thereby reducing\nenergy consumption and emissions. Existing studies typically improve energy and\ntravel efficiency for individual CAVs without considering their impacts on the\nentire mixed-traffic platoon, leading to inefficient traffic flow. While\nReinforcement Learning (RL) has the potential to achieve platoon-level control\nin a mixed-traffic environment, the training of RL is still challenged by (i)\ncar-following safety, i.e., CAVs should not collide with their immediate\npreceding vehicles, and (ii) red-light safety, i.e., CAVs should not run red\nlights. To address these challenges, this paper develops a platoon-centric,\nsafe RL-based GLOSA system that uses a multi-agent controller to optimize CAV\nspeed while achieving a balance between energy consumption and travel\nefficiency. We further incorporate Control Barrier Functions (CBFs) into the\nRL-based policy to provide explicit safety guarantees in terms of car-following\nsafety and red-light safety. Our simulation results illustrate that our\nproposed method outperforms state-of-the-art methods in terms of driving safety\nand platoon energy consumption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53GLOSA\u7cfb\u7edf\uff0c\u901a\u8fc7\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u786e\u4fdd\u8ddf\u8f66\u5b89\u5168\u548c\u7ea2\u706f\u5b89\u5168\uff0c\u5728\u6df7\u5408\u4ea4\u901a\u6d41\u4e2d\u4f18\u5316\u8f66\u961f\u80fd\u8017\u548c\u901a\u884c\u6548\u7387", "motivation": "\u73b0\u6709GLOSA\u7814\u7a76\u4e3b\u8981\u4f18\u5316\u5355\u4e2aCAV\u7684\u80fd\u6548\uff0c\u4f46\u672a\u8003\u8651\u5bf9\u6574\u4e2a\u6df7\u5408\u4ea4\u901a\u8f66\u961f\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u4ea4\u901a\u6d41\u6548\u7387\u4f4e\u4e0b\u3002\u540c\u65f6\uff0c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u9762\u4e34\u8ddf\u8f66\u5b89\u5168\u548c\u7ea2\u706f\u5b89\u5168\u4e24\u5927\u6311\u6218", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u63a7\u5236\u5668\u7684\u5f3a\u5316\u5b66\u4e60GLOSA\u7cfb\u7edf\uff0c\u5e76\u6574\u5408\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBFs)\u6765\u63d0\u4f9b\u660e\u786e\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u5305\u62ec\u8ddf\u8f66\u5b89\u5168\u548c\u7ea2\u706f\u5b89\u5168", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u9a7e\u9a76\u5b89\u5168\u548c\u8f66\u961f\u80fd\u8017\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6df7\u5408\u4ea4\u901a\u73af\u5883\u4e0b\u7684\u8f66\u961f\u7ea7\u63a7\u5236\u63d0\u4f9b\u4e86\u5b89\u5168\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u80fd\u8017\u548c\u901a\u884c\u6548\u7387"}}
{"id": "2509.12616", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2509.12616", "abs": "https://arxiv.org/abs/2509.12616", "authors": ["Karuna Chandra", "Akshay Menon", "Lydia Manikonda", "Ponnurangam Kumaraguru"], "title": "Ketto and the Science of Giving: A Data-Driven Investigation of Crowdfunding for India", "comment": null, "summary": "The main goal of this paper is to investigate an up and coming crowdfunding\nplatform used to raise funds for social causes in India called Ketto. Despite\nthe growing usage of this platform, there is insufficient understanding in\nterms of why users choose this platform when there are other popular platforms\nsuch as GoFundMe. Using a dataset comprising of 119,493 Ketto campaigns, our\nresearch conducts an in-depth investigation into different aspects of how the\ncampaigns on Ketto work with a specific focus on medical campaigns, which make\nup the largest percentage of social causes in the dataset. We also perform\npredictive modeling to identify the factors that contribute to the success of\ncampaigns on this platform. We use several features such as the campaign\nmetadata, description, geolocation, donor behaviors, and campaign-related\nfeatures to learn about the platform and its components. Our results suggest\nthat majority of the campaigns for medical causes seek funds to address chronic\nhealth conditions, yet medical campaigns have the least success rate. Most of\nthe campaigns originate from the most populous states and major metropolitan\ncities in India. Our analysis also indicates that factors such as online\nengagement on the platform in terms of the number of comments, duration of the\ncampaign, and frequent updates on a campaign positively influence the funds\nbeing raised. Overall, this preliminary work sheds light on the importance of\ninvestigating various dynamics around crowdfunding for India-focused\ncommunity-driven needs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5370\u5ea6\u4f17\u7b79\u5e73\u53f0Ketto\uff0c\u5206\u6790\u533b\u7597\u7c7b\u4f17\u7b79\u6d3b\u52a8\u7684\u6210\u529f\u56e0\u7d20\uff0c\u53d1\u73b0\u6162\u6027\u75c5\u7b79\u6b3e\u6210\u529f\u7387\u6700\u4f4e\uff0c\u5728\u7ebf\u4e92\u52a8\u3001\u6d3b\u52a8\u65f6\u957f\u548c\u9891\u7e41\u66f4\u65b0\u662f\u7b79\u6b3e\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u5c3d\u7ba1Ketto\u5e73\u53f0\u5728\u5370\u5ea6\u65e5\u76ca\u6d41\u884c\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u7528\u6237\u9009\u62e9\u504f\u597d\u548c\u6210\u529f\u56e0\u7d20\u7684\u7cfb\u7edf\u7814\u7a76\uff0c\u7279\u522b\u662f\u4e0eGoFundMe\u7b49\u56fd\u9645\u5e73\u53f0\u7684\u6bd4\u8f83\u5206\u6790\u3002", "method": "\u4f7f\u7528\u5305\u542b119,493\u4e2aKetto\u6d3b\u52a8\u7684\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u6df1\u5165\u8c03\u67e5\u548c\u9884\u6d4b\u5efa\u6a21\uff0c\u5206\u6790\u6d3b\u52a8\u5143\u6570\u636e\u3001\u63cf\u8ff0\u3001\u5730\u7406\u4f4d\u7f6e\u3001\u6350\u8d60\u8005\u884c\u4e3a\u548c\u6d3b\u52a8\u76f8\u5173\u7279\u5f81\u3002", "result": "\u533b\u7597\u7c7b\u6d3b\u52a8\u4e3b\u8981\u9488\u5bf9\u6162\u6027\u75c5\u4f46\u6210\u529f\u7387\u6700\u4f4e\uff1b\u6d3b\u52a8\u591a\u6765\u81ea\u4eba\u53e3\u5bc6\u96c6\u5dde\u548c\u5927\u90fd\u5e02\uff1b\u8bc4\u8bba\u6570\u91cf\u3001\u6d3b\u52a8\u65f6\u957f\u548c\u66f4\u65b0\u9891\u7387\u5bf9\u7b79\u6b3e\u6709\u79ef\u6781\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u9879\u521d\u6b65\u7814\u7a76\u63ed\u793a\u4e86\u7814\u7a76\u5370\u5ea6\u793e\u533a\u9a71\u52a8\u9700\u6c42\u7684\u4f17\u7b79\u52a8\u6001\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u7406\u89e3\u672c\u571f\u4f17\u7b79\u5e73\u53f0\u7684\u6210\u529f\u673a\u5236\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2509.12455", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.12455", "abs": "https://arxiv.org/abs/2509.12455", "authors": ["Hongjin Lin", "Anna Kawakami", "Catherine D'Ignazio", "Kenneth Holstein", "Krzysztof Gajos"], "title": "Funding AI for Good: A Call for Meaningful Engagement", "comment": "Currently under review", "summary": "Artificial Intelligence for Social Good (AI4SG) is a growing area exploring\nAI's potential to address social issues like public health. Yet prior work has\nshown limited evidence of its tangible benefits for intended communities, and\nprojects frequently face inadequate community engagement and sustainability\nchallenges. Funding agendas play a crucial role in framing AI4SG initiatives\nand shaping their approaches. Through a qualitative analysis of 35 funding\ndocuments -- representing about $410 million USD in total investments, we\nreveal dissonances between AI4SG's stated intentions for positive social impact\nand the techno-centric approaches that some funding agendas promoted. Drawing\non our findings, we offer recommendations for funders to scaffold approaches\nthat balance both contextual understanding and technical capacities in future\nfunding call designs. We call for greater engagement between AI4SG funders and\nthe HCI community to support community engagement work in the funding program\ndesign process.", "AI": {"tldr": "\u901a\u8fc7\u5bf935\u4efd\u8d44\u52a9\u6587\u4ef6\uff08\u603b\u91d1\u989d\u7ea64.1\u4ebf\u7f8e\u5143\uff09\u7684\u5b9a\u6027\u5206\u6790\uff0c\u7814\u7a76\u53d1\u73b0AI4SG\uff08\u4eba\u5de5\u667a\u80fd\u4fc3\u8fdb\u793e\u4f1a\u516c\u76ca\uff09\u9879\u76ee\u7684\u8d44\u52a9\u8bae\u7a0b\u5b58\u5728\u6280\u672f\u4e2d\u5fc3\u4e3b\u4e49\u503e\u5411\uff0c\u4e0e\u58f0\u79f0\u7684\u793e\u4f1a\u5f71\u54cd\u76ee\u6807\u5b58\u5728\u8131\u8282\u3002", "motivation": "AI4SG\u9886\u57df\u867d\u7136\u65e8\u5728\u5229\u7528AI\u89e3\u51b3\u793e\u4f1a\u95ee\u9898\uff08\u5982\u516c\u5171\u536b\u751f\uff09\uff0c\u4f46\u5148\u524d\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u9879\u76ee\u5f80\u5f80\u7f3a\u4e4f\u5bf9\u76ee\u6807\u793e\u533a\u7684\u5b9e\u9645\u76ca\u5904\uff0c\u9762\u4e34\u793e\u533a\u53c2\u4e0e\u4e0d\u8db3\u548c\u53ef\u6301\u7eed\u6027\u6311\u6218\u3002\u8d44\u52a9\u8bae\u7a0b\u5728\u5851\u9020AI4SG\u9879\u76ee\u65b9\u6cd5\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76\u4e8635\u4efd\u8d44\u52a9\u6587\u4ef6\uff0c\u8fd9\u4e9b\u6587\u4ef6\u4ee3\u8868\u4e86\u7ea64.1\u4ebf\u7f8e\u5143\u7684\u603b\u6295\u8d44\uff0c\u5206\u6790\u8d44\u52a9\u8bae\u7a0b\u5982\u4f55\u5f71\u54cdAI4SG\u9879\u76ee\u7684\u6280\u672f\u65b9\u6cd5\u548c\u793e\u4f1a\u5f71\u54cd\u76ee\u6807\u3002", "result": "\u7814\u7a76\u53d1\u73b0AI4SG\u8d44\u52a9\u8bae\u7a0b\u4e2d\u5b58\u5728\u663e\u8457\u7684\u4e0d\u534f\u8c03\uff1a\u58f0\u79f0\u8ffd\u6c42\u79ef\u6781\u793e\u4f1a\u5f71\u54cd\u7684\u76ee\u6807\u4e0e\u5b9e\u9645\u63a8\u5e7f\u7684\u6280\u672f\u4e2d\u5fc3\u4e3b\u4e49\u65b9\u6cd5\u4e4b\u95f4\u5b58\u5728\u8131\u8282\u3002\u8d44\u52a9\u8bae\u7a0b\u5f80\u5f80\u504f\u5411\u6280\u672f\u89e3\u51b3\u65b9\u6848\u800c\u5ffd\u89c6\u60c5\u5883\u7406\u89e3\u3002", "conclusion": "\u5efa\u8bae\u8d44\u52a9\u8005\u5728\u672a\u6765\u8d44\u52a9\u8ba1\u5212\u8bbe\u8ba1\u4e2d\u5e73\u8861\u60c5\u5883\u7406\u89e3\u548c\u6280\u672f\u80fd\u529b\uff0c\u5e76\u547c\u5401AI4SG\u8d44\u52a9\u8005\u4e0eHCI\u793e\u533a\u52a0\u5f3a\u5408\u4f5c\uff0c\u5728\u8d44\u52a9\u9879\u76ee\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u66f4\u597d\u5730\u652f\u6301\u793e\u533a\u53c2\u4e0e\u5de5\u4f5c\u3002"}}
{"id": "2509.12282", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12282", "abs": "https://arxiv.org/abs/2509.12282", "authors": ["Sasi Kiran Gaddipati", "Farhana Keya", "Gollam Rabby", "S\u00f6ren Auer"], "title": "AIssistant: An Agentic Approach for Human--AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning", "comment": null, "summary": "Advances in AI-assisted research have introduced powerful tools for\nliterature retrieval, hypothesis generation, experimentation, and manuscript\npreparation. However, systems remain fragmented and lack human-centred\nworkflows. To address these gaps, we introduce AIssistant, an agentic,\nopen-source Human-AI collaborative framework designed to simplify the\nend-to-end creation of scientific workflows. Since our development is still in\nan early stage, we present here the first experiments with AIssistant for\nperspective and review research papers in machine learning. Our system\nintegrates modular tools and agents for literature synthesis, section-wise\nexperimentation, citation management, and automatic LaTeX paper text\ngeneration, while maintaining human oversight at every stage to ensure\naccuracy, coherence, and scholarly rigour. We conducted a comprehensive\nevaluation across three layers: (1) Independent Human Review, following NeurIPS\ndouble-blind standards; (2) Automated LLM Review, using GPT-5 as a scalable\nhuman review proxy; and (3) Program Chair Oversight, where the chair monitors\nthe entire review process and makes final validation and acceptance decisions.\nThe results demonstrate that AIssistant improves drafting efficiency and\nthematic consistency. Nonetheless, Human-AI collaboration remains essential for\nmaintaining factual correctness, methodological soundness, and ethical\ncompliance. Despite its effectiveness, we identify key limitations, including\nhallucinated citations, difficulty adapting to dynamic paper structures, and\nincomplete integration of multimodal content.", "AI": {"tldr": "AIssistant\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u79d1\u7814\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u5de5\u5177\u548c\u4ee3\u7406\u7cfb\u7edf\u7b80\u5316\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u7aef\u5230\u7aef\u521b\u5efa\uff0c\u5728\u4fdd\u6301\u4eba\u5de5\u76d1\u7763\u7684\u540c\u65f6\u63d0\u9ad8\u8d77\u8349\u6548\u7387\u548c\u4e3b\u9898\u4e00\u81f4\u6027\u3002", "motivation": "\u5f53\u524dAI\u8f85\u52a9\u7814\u7a76\u5de5\u5177\u5b58\u5728\u788e\u7247\u5316\u95ee\u9898\uff0c\u7f3a\u4e4f\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u6574\u5408\u7684\u3001\u652f\u6301\u4eba\u7c7b-AI\u534f\u4f5c\u7684\u7aef\u5230\u7aef\u79d1\u7814\u6846\u67b6\u3002", "method": "\u5f00\u53d1AIssistant\u6846\u67b6\uff0c\u96c6\u6210\u6587\u732e\u5408\u6210\u3001\u5206\u6bb5\u5b9e\u9a8c\u3001\u5f15\u7528\u7ba1\u7406\u548c\u81ea\u52a8LaTeX\u8bba\u6587\u751f\u6210\u7b49\u6a21\u5757\u5316\u5de5\u5177\uff0c\u5728\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u7efc\u8ff0\u548c\u89c6\u89d2\u8bba\u6587\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u4e09\u5c42\u8bc4\u4f30\uff08\u72ec\u7acb\u4eba\u5de5\u8bc4\u5ba1\u3001\u81ea\u52a8\u5316LLM\u8bc4\u5ba1\u3001\u7a0b\u5e8f\u4e3b\u5e2d\u76d1\u7763\uff09\u663e\u793a\uff0c\u7cfb\u7edf\u63d0\u9ad8\u4e86\u8d77\u8349\u6548\u7387\u548c\u4e3b\u9898\u4e00\u81f4\u6027\uff0c\u4f46\u5b58\u5728\u5f15\u7528\u5e7b\u89c9\u3001\u52a8\u6001\u8bba\u6587\u7ed3\u6784\u9002\u5e94\u56f0\u96be\u548c\u591a\u6a21\u6001\u5185\u5bb9\u6574\u5408\u4e0d\u5b8c\u5168\u7b49\u5c40\u9650\u6027\u3002", "conclusion": "\u4eba\u7c7b-AI\u534f\u4f5c\u5bf9\u4e8e\u4fdd\u6301\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u65b9\u6cd5\u5408\u7406\u6027\u548c\u4f26\u7406\u5408\u89c4\u6027\u4ecd\u7136\u81f3\u5173\u91cd\u8981\uff0cAIssistant\u6846\u67b6\u5728\u63d0\u5347\u79d1\u7814\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u548c\u5b8c\u5584\u3002"}}
{"id": "2509.13293", "categories": ["stat.AP", "stat.CO", "62P12"], "pdf": "https://arxiv.org/pdf/2509.13293", "abs": "https://arxiv.org/abs/2509.13293", "authors": ["Mengyi Gong", "Christopher Nemeth", "Rebecca Killick", "Peter Strauss", "John Quinton"], "title": "Inferring Soil Drydown Behaviour with Adaptive Bayesian Online Changepoint Analysis", "comment": "21 pages of main manuscript and 3 pages if supplemental document", "summary": "Continuous soil-moisture measurements provide a direct lens on subsurface\nhydrological processes, notably the post-rainfall \"drydown\" phase. Because\nthese records consist of distinct, segment-specific behaviours whose forms and\nscales vary over time, realistic inference demands a model that captures\npiecewise dynamics while accommodating parameters that are unknown a priori.\nBuilding on Bayesian Online Changepoint Detection (BOCPD), we introduce two\ncomplementary extensions: a particle-filter variant that substitutes exact\nmarginalisation with sequential Monte Carlo to enable real-time inference when\ncritical parameters cannot be integrated out analytically, and an\nonline-gradient variant that embeds stochastic gradient updates within BOCPD to\nlearn application-relevant parameters on the fly without prohibitive\ncomputational cost. After validating both algorithms on synthetic data that\nreplicate the temporal structure of field observations-detailing hyperparameter\nchoices, priors, and cost-saving strategies-we apply them to soil-moisture\nseries from experimental sites in Austria and the United States, quantifying\nsite-specific drydown rates and demonstrating the advantages of our adaptive\nframework over static models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BOCPD\u7684\u4e24\u4e2a\u6269\u5c55\u53d8\u4f53\uff1a\u7c92\u5b50\u6ee4\u6ce2\u53d8\u4f53\u4f7f\u7528\u5e8f\u8d2f\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u63a8\u65ad\uff0c\u5728\u7ebf\u68af\u5ea6\u53d8\u4f53\u5d4c\u5165\u968f\u673a\u68af\u5ea6\u66f4\u65b0\u6765\u5b66\u4e60\u5e94\u7528\u76f8\u5173\u53c2\u6570\uff0c\u7528\u4e8e\u5206\u6790\u571f\u58e4\u6e7f\u5ea6\u6570\u636e\u4e2d\u7684\u5206\u6bb5\u52a8\u6001\u8fc7\u7a0b\u3002", "motivation": "\u571f\u58e4\u6e7f\u5ea6\u8fde\u7eed\u6d4b\u91cf\u6570\u636e\u5177\u6709\u5206\u6bb5\u7279\u5f02\u6027\u884c\u4e3a\uff0c\u9700\u8981\u80fd\u591f\u6355\u6349\u5206\u6bb5\u52a8\u6001\u4e14\u53c2\u6570\u5148\u9a8c\u672a\u77e5\u7684\u6a21\u578b\u6765\u8fdb\u884c\u73b0\u5b9e\u63a8\u65ad\u3002", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u5728\u7ebf\u53d8\u70b9\u68c0\u6d4b(BOCPD)\uff0c\u5f00\u53d1\u4e86\u4e24\u79cd\u6269\u5c55\u65b9\u6cd5\uff1a1\uff09\u7c92\u5b50\u6ee4\u6ce2\u53d8\u4f53\u7528\u5e8f\u8d2f\u8499\u7279\u5361\u6d1b\u66ff\u4ee3\u7cbe\u786e\u8fb9\u7f18\u5316\uff0c\u5b9e\u73b0\u5b9e\u65f6\u63a8\u65ad\uff1b2\uff09\u5728\u7ebf\u68af\u5ea6\u53d8\u4f53\u5728BOCPD\u4e2d\u5d4c\u5165\u968f\u673a\u68af\u5ea6\u66f4\u65b0\uff0c\u5728\u7ebf\u5b66\u4e60\u5e94\u7528\u76f8\u5173\u53c2\u6570\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u548c\u5965\u5730\u5229\u3001\u7f8e\u56fd\u5b9e\u9a8c\u7ad9\u70b9\u7684\u571f\u58e4\u6e7f\u5ea6\u5e8f\u5217\u4e0a\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6709\u6548\u6027\uff0c\u91cf\u5316\u4e86\u7ad9\u70b9\u7279\u5b9a\u7684\u5e72\u71e5\u901f\u7387\uff0c\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u6846\u67b6\u76f8\u5bf9\u4e8e\u9759\u6001\u6a21\u578b\u7684\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u79cdBOCPD\u6269\u5c55\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u571f\u58e4\u6e7f\u5ea6\u6570\u636e\u4e2d\u7684\u5206\u6bb5\u52a8\u6001\u8fc7\u7a0b\uff0c\u4e3a\u6c34\u6587\u8fc7\u7a0b\u5206\u6790\u63d0\u4f9b\u4e86\u81ea\u9002\u5e94\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12522", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12522", "abs": "https://arxiv.org/abs/2509.12522", "authors": ["Devin Hunter", "Chinwendu Enyioha"], "title": "Hybrid State Estimation of Uncertain Nonlinear Dynamics Using Neural Processes", "comment": "32 pages (single column) - 6 figures", "summary": "Various neural network architectures are used in many of the state-of-the-art\napproaches for real-time nonlinear state estimation in dynamical systems. With\nthe ever-increasing incorporation of these data-driven models into the\nestimation domain, models with reliable margins of error are required --\nespecially for safety-critical applications. This paper discusses a novel\nhybrid, data-driven state estimation approach based on the physics-informed\nattentive neural process (PI-AttNP), a model-informed extension of the\nattentive neural process (AttNP). We augment this estimation approach with the\nregression-based split conformal prediction (CP) framework to obtain quantified\nmodel uncertainty with probabilistic guarantees. After presenting the algorithm\nin a generic form, we validate its performance in the task of grey-box state\nestimation of a simulated under-actuated six-degree-of-freedom quadrotor with\nmultimodal Gaussian sensor noise and several external perturbations typical to\nquadrotors. Further, we compare outcomes with state-of-the-art data-driven\nmethods, which provide significant evidence of the physics-informed neural\nprocess as a viable novel approach for model-driven estimation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u6ce8\u610f\u529b\u795e\u7ecf\u8fc7\u7a0b(PI-AttNP)\u7684\u6df7\u5408\u6570\u636e\u9a71\u52a8\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u5206\u4f53\u4fdd\u5f62\u9884\u6d4b\u6846\u67b6\u6765\u91cf\u5316\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u516d\u81ea\u7531\u5ea6\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u72b6\u6001\u4f30\u8ba1\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u6570\u636e\u9a71\u52a8\u6a21\u578b\u5728\u72b6\u6001\u4f30\u8ba1\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u5177\u6709\u53ef\u9760\u8bef\u5dee\u8fb9\u754c\u7684\u6a21\u578b\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u6ce8\u610f\u529b\u795e\u7ecf\u8fc7\u7a0b(PI-AttNP)\u4f5c\u4e3a\u6838\u5fc3\u4f30\u8ba1\u5668\uff0c\u8fd9\u662f\u6ce8\u610f\u529b\u795e\u7ecf\u8fc7\u7a0b(AttNP)\u7684\u6a21\u578b\u4fe1\u606f\u6269\u5c55\u7248\u672c\uff0c\u5e76\u96c6\u6210\u56de\u5f52\u578b\u5206\u4f53\u4fdd\u5f62\u9884\u6d4b(CP)\u6846\u67b6\u6765\u63d0\u4f9b\u5177\u6709\u6982\u7387\u4fdd\u8bc1\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5728\u6a21\u62df\u7684\u6b20\u9a71\u52a8\u516d\u81ea\u7531\u5ea6\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u72b6\u6001\u4f30\u8ba1\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6027\u80fd\uff0c\u5904\u7406\u4e86\u591a\u6a21\u6001\u9ad8\u65af\u4f20\u611f\u5668\u566a\u58f0\u548c\u5178\u578b\u5916\u90e8\u6270\u52a8\u3002\u4e0e\u6700\u5148\u8fdb\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u8fc7\u7a0b\u88ab\u8bc1\u660e\u662f\u6a21\u578b\u9a71\u52a8\u4f30\u8ba1\u7684\u4e00\u79cd\u53ef\u884c\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u4f9b\u5177\u6709\u6982\u7387\u4fdd\u8bc1\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u5173\u952e\u5e94\u7528\u3002"}}
{"id": "2509.12822", "categories": ["cs.SI", "cs.AI", "05C85, 60J60, 68R05, 68R10, 68T01, 90C35", "G.2.1; G.2.2; G.3; H.3.4; H.3.5; I.2.0; J.4"], "pdf": "https://arxiv.org/pdf/2509.12822", "abs": "https://arxiv.org/abs/2509.12822", "authors": ["Curt Stutsman", "Eliot W. Robson", "Abhishek K. Umrawal"], "title": "A Pressure-Based Diffusion Model for Influence Maximization on Social Networks", "comment": "10 pages, 7 figures, and 2 tables", "summary": "In many real-world scenarios, an individual's local social network carries\nsignificant influence over the opinions they form and subsequently propagate to\nothers. In this paper, we propose a novel diffusion model -- the Pressure\nThreshold model (PT) -- for dynamically simulating the spread of influence\nthrough a social network. This new model extends the popular Linear Threshold\nModel (LT) by adjusting a node's outgoing influence proportional to the\ninfluence it receives from its activated neighbors. We address the Influence\nMaximization (IM) problem, which involves selecting the most effective seed\nnodes to achieve maximal graph coverage after a diffusion process, and how the\nproblem manifests with the PT Model. Experiments conducted on real-world\nnetworks, facilitated by enhancements to the open-source network-diffusion\nPython library, CyNetDiff, demonstrate unique seed node selection for the PT\nModel when compared to the LT Model. Moreover, analyses demonstrate that\ndensely connected networks amplify pressure effects more significantly than\nsparse networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86Pressure Threshold (PT)\u6a21\u578b\u6765\u6a21\u62df\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5f71\u54cd\u529b\u4f20\u64ad\uff0c\u901a\u8fc7\u8c03\u6574\u8282\u70b9\u8f93\u51fa\u5f71\u54cd\u529b\u4e0e\u63a5\u6536\u5f71\u54cd\u529b\u7684\u6bd4\u4f8b\u6765\u6269\u5c55Linear Threshold\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u5f71\u54cd\u529b\u6700\u5927\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u4e2a\u4f53\u7684\u672c\u5730\u793e\u4ea4\u7f51\u7edc\u5bf9\u5176\u89c2\u70b9\u5f62\u6210\u548c\u4f20\u64ad\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u6a21\u578b\u6765\u6a21\u62df\u8fd9\u79cd\u52a8\u6001\u5f71\u54cd\u4f20\u64ad\u8fc7\u7a0b\u3002", "method": "\u6269\u5c55Linear Threshold\u6a21\u578b\uff0c\u63d0\u51faPressure Threshold\u6a21\u578b\uff0c\u8c03\u6574\u8282\u70b9\u8f93\u51fa\u5f71\u54cd\u529b\u4e0e\u5176\u4ece\u6fc0\u6d3b\u90bb\u5c45\u63a5\u6536\u7684\u5f71\u54cd\u529b\u6210\u6b63\u6bd4\uff0c\u5e76\u5728\u771f\u5b9e\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u663e\u793aPT\u6a21\u578b\u4e0eLT\u6a21\u578b\u76f8\u6bd4\u9009\u62e9\u4e86\u4e0d\u540c\u7684\u79cd\u5b50\u8282\u70b9\uff0c\u4e14\u5728\u5bc6\u96c6\u8fde\u63a5\u7f51\u7edc\u4e2d\u538b\u529b\u6548\u5e94\u6bd4\u7a00\u758f\u7f51\u7edc\u66f4\u663e\u8457\u3002", "conclusion": "PT\u6a21\u578b\u80fd\u66f4\u51c6\u786e\u5730\u6a21\u62df\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5f71\u54cd\u529b\u4f20\u64ad\u52a8\u6001\uff0c\u4e3a\u5f71\u54cd\u529b\u6700\u5927\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5bc6\u96c6\u7f51\u7edc\u4e2d\u6548\u679c\u66f4\u660e\u663e\u3002"}}
{"id": "2509.12503", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.12503", "abs": "https://arxiv.org/abs/2509.12503", "authors": ["Corey M. Abramson", "Zhuofan Li", "Tara Prendergast", "Daniel Dohan"], "title": "Qualitative Research in an Era of AI: A Pragmatic Approach to Data Analysis, Workflow, and Computation", "comment": "pre-print, methodology, workflow article", "summary": "Rapid computational developments - particularly the proliferation of\nartificial intelligence (AI) - increasingly shape social scientific research\nwhile raising new questions about in-depth qualitative methods such as\nethnography and interviewing. Building on classic debates about using computers\nto analyze qualitative data, we revisit longstanding concerns and assess\npossibilities and dangers in an era of automation, AI chatbots, and 'big data.'\nWe first historicize developments by revisiting classical and emergent concerns\nabout qualitative analysis with computers. We then introduce a typology of\ncontemporary modes of engagement - streamlining workflows, scaling up projects,\nhybrid analytical approaches, and the sociology of computation - alongside\nrejection of computational analyses. We illustrate these approaches with\ndetailed workflow examples from a large-scale ethnographic study and guidance\nfor solo researchers. We argue for a pragmatic sociological approach that moves\nbeyond dualisms of technological optimism versus rejection to show how\ncomputational tools - simultaneously dangerous and generative - can be adapted\nto support longstanding qualitative aims when used carefully in ways aligned\nwith core methodological commitments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u4e0b\u8ba1\u7b97\u5de5\u5177\u5bf9\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff08\u5982\u6c11\u65cf\u5fd7\u548c\u8bbf\u8c08\uff09\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u5b9e\u7528\u4e3b\u4e49\u793e\u4f1a\u5b66\u65b9\u6cd5\uff0c\u5728\u6280\u672f\u4e50\u89c2\u4e0e\u62d2\u7edd\u4e4b\u95f4\u5bfb\u6c42\u5e73\u8861\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u548c\u8ba1\u7b97\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u9762\u4e34\u65b0\u7684\u6311\u6218\u548c\u673a\u9047\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u8ba1\u7b97\u5de5\u5177\u5728\u5b9a\u6027\u5206\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u65e2\u8981\u5229\u7528\u5176\u4f18\u52bf\u53c8\u8981\u9632\u8303\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u56de\u987e\u7ecf\u5178\u8fa9\u8bba\uff0c\u63d0\u51fa\u5f53\u4ee3\u53c2\u4e0e\u6a21\u5f0f\u7684\u7c7b\u578b\u5b66\uff08\u6d41\u7a0b\u4f18\u5316\u3001\u9879\u76ee\u6269\u5c55\u3001\u6df7\u5408\u5206\u6790\u65b9\u6cd5\u3001\u8ba1\u7b97\u793e\u4f1a\u5b66\uff09\uff0c\u5e76\u7ed3\u5408\u5927\u89c4\u6a21\u6c11\u65cf\u5fd7\u7814\u7a76\u7684\u8be6\u7ec6\u5de5\u4f5c\u6d41\u7a0b\u793a\u4f8b\u8fdb\u884c\u8bf4\u660e\u3002", "result": "\u5efa\u7acb\u4e86\u8ba1\u7b97\u5de5\u5177\u4e0e\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\u76f8\u7ed3\u5408\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5728\u4fdd\u6301\u6838\u5fc3\u65b9\u6cd5\u8bba\u627f\u8bfa\u7684\u524d\u63d0\u4e0b\uff0c\u8c28\u614e\u4f7f\u7528\u8ba1\u7b97\u5de5\u5177\u6765\u652f\u6301\u4f20\u7edf\u7684\u5b9a\u6027\u7814\u7a76\u76ee\u6807\u3002", "conclusion": "\u4e3b\u5f20\u8d85\u8d8a\u6280\u672f\u4e50\u89c2\u4e3b\u4e49\u4e0e\u62d2\u7edd\u7684\u4e8c\u5143\u5bf9\u7acb\uff0c\u91c7\u7528\u5b9e\u7528\u4e3b\u4e49\u793e\u4f1a\u5b66\u65b9\u6cd5\uff0c\u8ba4\u8bc6\u5230\u8ba1\u7b97\u5de5\u5177\u65e2\u5177\u6709\u5371\u9669\u6027\u53c8\u5177\u6709\u751f\u6210\u6027\uff0c\u53ef\u4ee5\u5728\u7cbe\u5fc3\u4f7f\u7528\u7684\u60c5\u51b5\u4e0b\u652f\u6301\u5b9a\u6027\u7814\u7a76\u7684\u957f\u671f\u76ee\u6807\u3002"}}
{"id": "2509.12468", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12468", "abs": "https://arxiv.org/abs/2509.12468", "authors": ["Shipeng Liu", "Meghana Sagare", "Shubham Patil", "Feifei Qian"], "title": "Bio-inspired tail oscillation enables robot fast crawling on deformable granular terrains", "comment": null, "summary": "Deformable substrates such as sand and mud present significant challenges for\nterrestrial robots due to complex robot-terrain interactions. Inspired by\nmudskippers, amphibious animals that naturally adjust their tail morphology and\nmovement jointly to navigate such environments, we investigate how tail design\nand control can jointly enhance flipper-driven locomotion on granular media.\nUsing a bio-inspired robot modeled after the mudskipper, we experimentally\ncompared locomotion performance between idle and actively oscillating tail\nconfigurations. Tail oscillation increased robot speed by 67% and reduced body\ndrag by 46%. Shear force measurements revealed that this improvement was\nenabled by tail oscillation fluidizing the substrate, thereby reducing\nresistance. Additionally, tail morphology strongly influenced the oscillation\nstrategy: designs with larger horizontal surface areas leveraged the\noscillation-reduced shear resistance more effectively by limiting insertion\ndepth. Based on these findings, we present a design principle to inform tail\naction selection based on substrate strength and tail morphology. Our results\noffer new insights into tail design and control for improving robot locomotion\non deformable substrates, with implications for agricultural robotics, search\nand rescue, and environmental exploration.", "AI": {"tldr": "\u901a\u8fc7\u6a21\u4eff\u5f39\u6d82\u9c7c\u7684\u5c3e\u90e8\u5f62\u6001\u548c\u8fd0\u52a8\u63a7\u5236\uff0c\u7814\u7a76\u53d1\u73b0\u4e3b\u52a8\u6446\u5c3e\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u673a\u5668\u4eba\u5728\u9897\u7c92\u4ecb\u8d28\u4e0a\u7684\u79fb\u52a8\u6027\u80fd\uff0c\u901f\u5ea6\u63d0\u534767%\uff0c\u963b\u529b\u964d\u4f4e46%\u3002", "motivation": "\u53d7\u5f39\u6d82\u9c7c\u542f\u53d1\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5c3e\u90e8\u8bbe\u8ba1\u548c\u63a7\u5236\u7684\u534f\u540c\u4f18\u5316\u6765\u6539\u5584\u673a\u5668\u4eba\u5728\u53ef\u53d8\u5f62\u57fa\u8d28\uff08\u5982\u6c99\u571f\uff09\u4e0a\u7684\u8fd0\u52a8\u6027\u80fd\uff0c\u89e3\u51b3\u590d\u6742\u673a\u5668\u4eba-\u5730\u5f62\u4ea4\u4e92\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u4eff\u751f\u673a\u5668\u4eba\u6a21\u578b\uff0c\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u9759\u6b62\u5c3e\u90e8\u548c\u4e3b\u52a8\u6446\u52a8\u5c3e\u90e8\u914d\u7f6e\u7684\u8fd0\u52a8\u6027\u80fd\uff0c\u5e76\u8fdb\u884c\u526a\u5207\u529b\u6d4b\u91cf\u5206\u6790\u57fa\u8d28\u6d41\u5316\u6548\u5e94\u3002", "result": "\u5c3e\u90e8\u6446\u52a8\u4f7f\u673a\u5668\u4eba\u901f\u5ea6\u63d0\u9ad867%\uff0c\u8eab\u4f53\u963b\u529b\u964d\u4f4e46%\uff1b\u5c3e\u90e8\u5f62\u6001\u5f71\u54cd\u6446\u52a8\u7b56\u7565\uff0c\u6c34\u5e73\u8868\u9762\u79ef\u5927\u7684\u8bbe\u8ba1\u80fd\u66f4\u6709\u6548\u5730\u5229\u7528\u6446\u52a8\u51cf\u963b\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u57fa\u8d28\u5f3a\u5ea6\u548c\u5c3e\u90e8\u5f62\u6001\u7684\u5c3e\u90e8\u52a8\u4f5c\u9009\u62e9\u8bbe\u8ba1\u539f\u5219\uff0c\u4e3a\u6539\u5584\u673a\u5668\u4eba\u5728\u53ef\u53d8\u5f62\u57fa\u8d28\u4e0a\u7684\u8fd0\u52a8\u63d0\u4f9b\u4e86\u65b0\u7684\u5c3e\u90e8\u8bbe\u8ba1\u548c\u63a7\u5236\u89c1\u89e3\uff0c\u5728\u519c\u4e1a\u673a\u5668\u4eba\u3001\u641c\u6551\u548c\u73af\u5883\u63a2\u7d22\u7b49\u9886\u57df\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.12423", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.12423", "abs": "https://arxiv.org/abs/2509.12423", "authors": ["Danielle Cohen", "Yoni Halpern", "Noam Kahlon", "Joel Oren", "Omri Berkovitch", "Sapir Caduri", "Ido Dagan", "Anatoly Efros"], "title": "Small Models, Big Results: Achieving Superior Intent Extraction through Decomposition", "comment": null, "summary": "Understanding user intents from UI interaction trajectories remains a\nchallenging, yet crucial, frontier in intelligent agent development. While\nmassive, datacenter-based, multi-modal large language models (MLLMs) possess\ngreater capacity to handle the complexities of such sequences, smaller models\nwhich can run on-device to provide a privacy-preserving, low-cost, and\nlow-latency user experience, struggle with accurate intent inference. We\naddress these limitations by introducing a novel decomposed approach: first, we\nperform structured interaction summarization, capturing key information from\neach user action. Second, we perform intent extraction using a fine-tuned model\noperating on the aggregated summaries. This method improves intent\nunderstanding in resource-constrained models, even surpassing the base\nperformance of large MLLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5206\u89e3\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4ea4\u4e92\u6458\u8981\u548c\u610f\u56fe\u63d0\u53d6\uff0c\u63d0\u5347\u8d44\u6e90\u53d7\u9650\u6a21\u578b\u5728UI\u4ea4\u4e92\u8f68\u8ff9\u4e2d\u7684\u610f\u56fe\u7406\u89e3\u80fd\u529b\uff0c\u751a\u81f3\u8d85\u8d8a\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u51c6\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5c0f\u578b\u8bbe\u5907\u7aef\u6a21\u578b\u5728UI\u4ea4\u4e92\u610f\u56fe\u7406\u89e3\u65b9\u9762\u7684\u51c6\u786e\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u3001\u4f4e\u6210\u672c\u548c\u4f4e\u5ef6\u8fdf\u7684\u7528\u6237\u4f53\u9a8c\uff0c\u540c\u65f6\u514b\u670d\u5927\u578b\u6570\u636e\u4e2d\u5fc3\u6a21\u578b\u7684\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u9996\u5148\u8fdb\u884c\u7ed3\u6784\u5316\u4ea4\u4e92\u6458\u8981\uff0c\u6355\u6349\u6bcf\u4e2a\u7528\u6237\u64cd\u4f5c\u7684\u5173\u952e\u4fe1\u606f\uff1b\u7136\u540e\u4f7f\u7528\u5fae\u8c03\u6a21\u578b\u5bf9\u805a\u5408\u6458\u8981\u8fdb\u884c\u610f\u56fe\u63d0\u53d6\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u8d44\u6e90\u53d7\u9650\u6a21\u578b\u7684\u610f\u56fe\u7406\u89e3\u80fd\u529b\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u8d85\u8fc7\u4e86\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u51c6\u6027\u80fd\u3002", "conclusion": "\u5206\u89e3\u5f0f\u65b9\u6cd5\u4e3a\u8bbe\u5907\u7aef\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u610f\u56fe\u7406\u89e3\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u548c\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u610f\u56fe\u63a8\u65ad\u3002"}}
{"id": "2509.12617", "categories": ["eess.SY", "cs.CY", "cs.NI", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12617", "abs": "https://arxiv.org/abs/2509.12617", "authors": ["Srijesh Pillai", "M. I. Jawid Nazir"], "title": "CattleSense -- A Multisensory Approach to Optimize Cattle Well-Being", "comment": "5 pages, 9 figures. Author's accepted manuscript of a paper published\n  in the 2024 ASET Conference. The final version is available at:\n  https://doi.org/10.1109/ASET60340.2024.10708764", "summary": "CattleSense is an innovative application of Internet of Things (IoT)\ntechnology for the comprehensive monitoring and management of cattle\nwell-being. This research paper outlines the design and implementation of a\nsophisticated system using a Raspberry Pi Module 4B, RFID Card Reader, Electret\nArduino Microphone Module, DHT11 Sensor, Arduino UNO, Neo-6M GPS Sensor, and\nHeartbeat Sensor. The system aims to provide real-time surveillance of the\nenvironment in which Cows are present and individual Cow parameters such as\nlocation, milking frequency, and heartbeat fluctuations. The primary objective\nis to simplify managing the Cattle in the shed, ensuring that the Cattle are\nhealthy and safe.", "AI": {"tldr": "CattleSense\u662f\u4e00\u4e2a\u57fa\u4e8e\u7269\u8054\u7f51\u6280\u672f\u7684\u725b\u7fa4\u5065\u5eb7\u76d1\u6d4b\u7cfb\u7edf\uff0c\u4f7f\u7528\u591a\u79cd\u4f20\u611f\u5668\u5b9e\u65f6\u76d1\u63a7\u725b\u53ea\u4f4d\u7f6e\u3001\u73af\u5883\u6761\u4ef6\u548c\u751f\u7406\u53c2\u6570", "motivation": "\u7b80\u5316\u725b\u820d\u7ba1\u7406\uff0c\u786e\u4fdd\u725b\u53ea\u5065\u5eb7\u5b89\u5168\uff0c\u901a\u8fc7\u5b9e\u65f6\u76d1\u6d4b\u73af\u5883\u53c2\u6570\u548c\u4e2a\u4f53\u725b\u53ea\u72b6\u6001\u6765\u63d0\u5347\u517b\u6b96\u6548\u7387", "method": "\u4f7f\u7528\u6811\u8393\u6d3e4B\u6a21\u5757\u3001RFID\u8bfb\u5361\u5668\u3001\u9ea6\u514b\u98ce\u6a21\u5757\u3001\u6e29\u6e7f\u5ea6\u4f20\u611f\u5668\u3001Arduino UNO\u3001GPS\u4f20\u611f\u5668\u548c\u5fc3\u7387\u4f20\u611f\u5668\u6784\u5efa\u7efc\u5408\u76d1\u6d4b\u7cfb\u7edf", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u5b9e\u65f6\u76d1\u63a7\u725b\u53ea\u4f4d\u7f6e\u3001\u6324\u5976\u9891\u7387\u3001\u5fc3\u8df3\u6ce2\u52a8\u548c\u73af\u5883\u6761\u4ef6\u7684\u5b8c\u6574\u7cfb\u7edf", "conclusion": "CattleSense\u7cfb\u7edf\u4e3a\u725b\u7fa4\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u786e\u4fdd\u725b\u53ea\u5065\u5eb7\u5e76\u7b80\u5316\u517b\u6b96\u7ba1\u7406\u6d41\u7a0b"}}
{"id": "2509.13197", "categories": ["cs.SI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13197", "abs": "https://arxiv.org/abs/2509.13197", "authors": ["Theodora Moldovan", "Arianna Pera", "Davide Vega", "Luca Maria Aiello"], "title": "Podcasts as a Medium for Participation in Collective Action: A Case Study of Black Lives Matter", "comment": "11 pages, 5 figures", "summary": "We study how participation in collective action is articulated in podcast\ndiscussions, using the Black Lives Matter (BLM) movement as a case study. While\nresearch on collective action discourse has primarily focused on text-based\ncontent, this study takes a first step toward analyzing audio formats by using\npodcast transcripts. Using the Structured Podcast Research Corpus (SPoRC), we\ninvestigated spoken language expressions of participation in collective action,\ncategorized as problem-solution, call-to-action, intention, and execution. We\nidentified podcast episodes discussing racial justice after important\nBLM-related events in May and June of 2020, and extracted participatory\nstatements using a layered framework adapted from prior work on social media.\nWe examined the emotional dimensions of these statements, detecting eight key\nemotions and their association with varying stages of activism. We found that\nemotional profiles vary by stage, with different positive emotions standing out\nduring calls-to-action, intention, and execution. We detected negative\nassociations between collective action and negative emotions, contrary to\ntheoretical expectations. Our work contributes to a better understanding of how\nactivism is expressed in spoken digital discourse and how emotional framing may\ndepend on the format of the discussion.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790\u64ad\u5ba2\u8f6c\u5f55\u6587\u672c\uff0c\u63a2\u8ba8\u4e86BLM\u8fd0\u52a8\u4e2d\u96c6\u4f53\u884c\u52a8\u53c2\u4e0e\u7684\u8a00\u8bed\u8868\u8fbe\u65b9\u5f0f\uff0c\u53d1\u73b0\u4e0d\u540c\u884c\u52a8\u9636\u6bb5\u7684\u60c5\u611f\u7279\u5f81\u5dee\u5f02\uff0c\u4ee5\u53ca\u8d1f\u9762\u60c5\u7eea\u4e0e\u96c6\u4f53\u884c\u52a8\u4e4b\u95f4\u7684\u8d1f\u76f8\u5173\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u5173\u4e8e\u96c6\u4f53\u884c\u52a8\u8bdd\u8bed\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u6587\u672c\u5185\u5bb9\uff0c\u800c\u97f3\u9891\u683c\u5f0f\uff08\u5982\u64ad\u5ba2\uff09\u4e2d\u7684\u8868\u8fbe\u65b9\u5f0f\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4ee5BLM\u8fd0\u52a8\u4e3a\u6848\u4f8b\uff0c\u5206\u6790\u64ad\u5ba2\u4e2d\u96c6\u4f53\u884c\u52a8\u53c2\u4e0e\u7684\u8bed\u8a00\u8868\u8fbe\u548c\u60c5\u611f\u7ef4\u5ea6\u3002", "method": "\u4f7f\u7528\u7ed3\u6784\u5316\u64ad\u5ba2\u7814\u7a76\u8bed\u6599\u5e93(SPoRC)\uff0c\u63d0\u53d62020\u5e745-6\u6708\u91cd\u8981BLM\u4e8b\u4ef6\u540e\u8ba8\u8bba\u79cd\u65cf\u6b63\u4e49\u7684\u64ad\u5ba2\u8282\u76ee\u3002\u91c7\u7528\u5206\u5c42\u6846\u67b6\u4ece\u8f6c\u5f55\u6587\u672c\u4e2d\u8bc6\u522b\u53c2\u4e0e\u6027\u9648\u8ff0\uff0c\u5c06\u5176\u5206\u7c7b\u4e3a\u95ee\u9898-\u89e3\u51b3\u65b9\u6848\u3001\u884c\u52a8\u53f7\u53ec\u3001\u610f\u56fe\u548c\u6267\u884c\u56db\u4e2a\u7c7b\u522b\uff0c\u5e76\u68c0\u6d4b\u516b\u79cd\u5173\u952e\u60c5\u7eea\u53ca\u5176\u4e0e\u884c\u52a8\u9636\u6bb5\u7684\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u884c\u52a8\u9636\u6bb5\u5177\u6709\u4e0d\u540c\u7684\u60c5\u611f\u7279\u5f81\uff0c\u79ef\u6781\u60c5\u7eea\u5728\u884c\u52a8\u53f7\u53ec\u3001\u610f\u56fe\u548c\u6267\u884c\u9636\u6bb5\u8868\u73b0\u7a81\u51fa\u3002\u4e0e\u7406\u8bba\u9884\u671f\u76f8\u53cd\uff0c\u96c6\u4f53\u884c\u52a8\u4e0e\u8d1f\u9762\u60c5\u7eea\u4e4b\u95f4\u5b58\u5728\u8d1f\u76f8\u5173\u5173\u7cfb\u3002\u60c5\u611f\u6846\u67b6\u53ef\u80fd\u53d6\u51b3\u4e8e\u8ba8\u8bba\u7684\u5f62\u5f0f\u3002", "conclusion": "\u672c\u7814\u7a76\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u6570\u5b57\u53e3\u8bed\u8bdd\u8bed\u4e2d\u6fc0\u8fdb\u4e3b\u4e49\u7684\u8868\u8fbe\u65b9\u5f0f\uff0c\u4ee5\u53ca\u60c5\u611f\u6846\u67b6\u5982\u4f55\u4f9d\u8d56\u4e8e\u8ba8\u8bba\u5f62\u5f0f\uff0c\u4e3a\u96c6\u4f53\u884c\u52a8\u8bdd\u8bed\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u97f3\u9891\u683c\u5f0f\u89c6\u89d2\u3002"}}
{"id": "2509.12577", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.12577", "abs": "https://arxiv.org/abs/2509.12577", "authors": ["Elinor Poole-Dayan", "Deb Roy", "Jad Kabbara"], "title": "An AI-Powered Framework for Analyzing Collective Idea Evolution in Deliberative Assemblies", "comment": null, "summary": "In an era of increasing societal fragmentation, political polarization, and\nerosion of public trust in institutions, representative deliberative assemblies\nare emerging as a promising democratic forum for developing effective policy\noutcomes on complex global issues. Despite theoretical attention, there remains\nlimited empirical work that systematically traces how specific ideas evolve,\nare prioritized, or are discarded during deliberation to form policy\nrecommendations. Addressing these gaps, this work poses two central questions:\n(1) How might we trace the evolution and distillation of ideas into concrete\nrecommendations within deliberative assemblies? (2) How does the deliberative\nprocess shape delegate perspectives and influence voting dynamics over the\ncourse of the assembly? To address these questions, we develop LLM-based\nmethodologies for empirically analyzing transcripts from a tech-enhanced\nin-person deliberative assembly. The framework identifies and visualizes the\nspace of expressed suggestions. We also empirically reconstruct each delegate's\nevolving perspective throughout the assembly. Our methods contribute novel\nempirical insights into deliberative processes and demonstrate how LLMs can\nsurface high-resolution dynamics otherwise invisible in traditional assembly\noutputs.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u6765\u5206\u6790\u534f\u5546\u4f1a\u8bae\u8bb0\u5f55\uff0c\u8ffd\u8e2a\u89c2\u70b9\u6f14\u5316\u548c\u6295\u7968\u52a8\u6001\uff0c\u4e3a\u7406\u89e3\u534f\u5546\u6c11\u4e3b\u8fc7\u7a0b\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "motivation": "\u5728\u653f\u6cbb\u6781\u5316\u548c\u793e\u4f1a\u5206\u88c2\u52a0\u5267\u7684\u80cc\u666f\u4e0b\uff0c\u4ee3\u8868\u6027\u534f\u5546\u4f1a\u8bae\u6210\u4e3a\u89e3\u51b3\u590d\u6742\u653f\u7b56\u95ee\u9898\u7684\u91cd\u8981\u6c11\u4e3b\u8bba\u575b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u89c2\u70b9\u5982\u4f55\u5177\u4f53\u6f14\u5316\u4e3a\u653f\u7b56\u5efa\u8bae\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u65b9\u6cd5\u8bba\uff0c\u5206\u6790\u6280\u672f\u589e\u5f3a\u7684\u9762\u5bf9\u9762\u534f\u5546\u4f1a\u8bae\u8bb0\u5f55\uff0c\u8bc6\u522b\u548c\u53ef\u89c6\u5316\u8868\u8fbe\u5efa\u8bae\u7684\u7a7a\u95f4\uff0c\u5e76\u91cd\u5efa\u4ee3\u8868\u89c2\u70b9\u7684\u6f14\u53d8\u8fc7\u7a0b\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u8ffd\u8e2a\u534f\u5546\u8fc7\u7a0b\u4e2d\u89c2\u70b9\u7684\u6f14\u53d8\u548c\u63d0\u70bc\uff0c\u63ed\u793a\u4ee3\u8868\u89c6\u89d2\u7684\u53d8\u5316\u548c\u6295\u7968\u52a8\u6001\uff0c\u63d0\u4f9b\u4f20\u7edf\u4f1a\u8bae\u8f93\u51fa\u4e2d\u4e0d\u53ef\u89c1\u7684\u9ad8\u5206\u8fa8\u7387\u52a8\u6001\u5206\u6790\u3002", "conclusion": "LLM\u65b9\u6cd5\u4e3a\u534f\u5546\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u9896\u7684\u5b9e\u8bc1\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u63ed\u793a\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u7684\u7ec6\u5fae\u52a8\u6001\uff0c\u5bf9\u7406\u89e3\u6c11\u4e3b\u534f\u5546\u673a\u5236\u6709\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2509.12507", "categories": ["cs.RO", "cs.HC", "cs.LG", "68T07, 68T40", "I.2.9; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.12507", "abs": "https://arxiv.org/abs/2509.12507", "authors": ["Anna Deichler", "Siyang Wang", "Simon Alexanderson", "Jonas Beskow"], "title": "Learning to Generate Pointing Gestures in Situated Embodied Conversational Agents", "comment": "DOI: 10.3389/frobt.2023.1110534. This is the author's LaTeX version", "summary": "One of the main goals of robotics and intelligent agent research is to enable\nnatural communication with humans in physically situated settings. While recent\nwork has focused on verbal modes such as language and speech, non-verbal\ncommunication is crucial for flexible interaction. We present a framework for\ngenerating pointing gestures in embodied agents by combining imitation and\nreinforcement learning. Using a small motion capture dataset, our method learns\na motor control policy that produces physically valid, naturalistic gestures\nwith high referential accuracy. We evaluate the approach against supervised\nlearning and retrieval baselines in both objective metrics and a virtual\nreality referential game with human users. Results show that our system\nachieves higher naturalness and accuracy than state-of-the-art supervised\nmodels, highlighting the promise of imitation-RL for communicative gesture\ngeneration and its potential application to robots.", "AI": {"tldr": "\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u5177\u8eab\u667a\u80fd\u4f53\u7684\u6307\u5411\u624b\u52bf\uff0c\u5728\u81ea\u7136\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5", "motivation": "\u5b9e\u73b0\u4e0e\u4eba\u7c7b\u5728\u7269\u7406\u73af\u5883\u4e2d\u7684\u81ea\u7136\u4ea4\u6d41\uff0c\u975e\u8bed\u8a00\u6c9f\u901a\uff08\u5982\u6307\u5411\u624b\u52bf\uff09\u5bf9\u4e8e\u7075\u6d3b\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\uff0c\u800c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8bed\u8a00\u548c\u8bed\u97f3\u7b49\u8bed\u8a00\u6a21\u5f0f", "method": "\u4f7f\u7528\u5c0f\u89c4\u6a21\u52a8\u4f5c\u6355\u6349\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u6765\u5b66\u4e60\u8fd0\u52a8\u63a7\u5236\u7b56\u7565\uff0c\u751f\u6210\u7269\u7406\u6709\u6548\u4e14\u81ea\u7136\u7684\u6307\u5411\u624b\u52bf", "result": "\u5728\u5ba2\u89c2\u6307\u6807\u548c\u865a\u62df\u73b0\u5b9e\u53c2\u8003\u6e38\u620f\u4e2d\uff0c\u8be5\u7cfb\u7edf\u5728\u81ea\u7136\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u76d1\u7763\u6a21\u578b\u548c\u68c0\u7d22\u57fa\u7ebf", "conclusion": "\u6a21\u4eff\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u7684\u65b9\u6cd5\u5728\u4ea4\u6d41\u624b\u52bf\u751f\u6210\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u53ef\u5e94\u7528\u4e8e\u673a\u5668\u4eba\u7cfb\u7edf"}}
{"id": "2509.12434", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12434", "abs": "https://arxiv.org/abs/2509.12434", "authors": ["Jiahao Yu", "Zelei Cheng", "Xian Wu", "Xinyu Xing"], "title": "Building Coding Agents via Entropy-Enhanced Multi-Turn Preference Optimization", "comment": null, "summary": "Software engineering presents complex, multi-step challenges for Large\nLanguage Models (LLMs), requiring reasoning over large codebases and\ncoordinated tool use. The difficulty of these tasks is exemplified by\nbenchmarks like SWE-bench, where current LLMs still struggle to resolve\nreal-world issues.\n  A promising approach to enhance performance is test-time scaling (TTS), but\nits gains are heavily dependent on the diversity of model outputs.\n  While standard alignment methods such as Direct Preference Optimization (DPO)\nand Kahneman-Tversky Optimization (KTO) are effective at aligning model outputs\nwith human preferences, this process can come at the cost of reduced diversity,\nlimiting the effectiveness of TTS.\n  Additionally, existing preference optimization algorithms are typically\ndesigned for single-turn tasks and do not fully address the complexities of\nmulti-turn reasoning and tool integration required for interactive coding\nagents.\n  To bridge this gap, we introduce \\sys, an entropy-enhanced framework that\nadapts existing preference optimization algorithms to the multi-turn,\ntool-assisted setting.\n  \\sys augments the preference objective to explicitly preserve policy entropy\nand generalizes learning to optimize over multi-turn interactions rather than\nsingle-turn responses.\n  We validate \\sys by fine-tuning a diverse suite of models from different\nfamilies and sizes (up to 106B parameters).\n  To maximize performance gains from TTS, we further propose a hybrid\nbest-trajectory selection scheme combining a learned verifier model with model\nfree approaches.\n  On the \\swebench leaderboard, our approach establishes new state-of-the-art\nresults among open-weight models. A 30B parameter model trained with \\sys ranks\n1st on \\lite and 4th on \\verified on the open-weight leaderboard, surpassed\nonly by models with over 10x more parameters(\\eg$>$350B).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\\sys\u7684\u71b5\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u6301\u7b56\u7565\u71b5\u548c\u591a\u8f6e\u4ea4\u4e92\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u5728\u4ee3\u7801\u4efb\u52a1\u4e2d\u591a\u6837\u6027\u4e0d\u8db3\u548c\u591a\u8f6e\u63a8\u7406\u7684\u95ee\u9898\uff0c\u5728SWE-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u6807\u51c6\u5bf9\u9f50\u65b9\u6cd5\u5982DPO\u548cKTO\u867d\u7136\u80fd\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\uff0c\u4f46\u4f1a\u964d\u4f4e\u8f93\u51fa\u591a\u6837\u6027\uff0c\u9650\u5236\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u6548\u679c\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5355\u8f6e\u4efb\u52a1\uff0c\u65e0\u6cd5\u5904\u7406\u591a\u8f6e\u63a8\u7406\u548c\u5de5\u5177\u96c6\u6210\u9700\u6c42\u3002", "method": "\u63d0\u51fa\\sys\u6846\u67b6\uff0c\u589e\u5f3a\u504f\u597d\u76ee\u6807\u4ee5\u663e\u5f0f\u4fdd\u6301\u7b56\u7565\u71b5\uff0c\u5c06\u5b66\u4e60\u63a8\u5e7f\u5230\u591a\u8f6e\u4ea4\u4e92\u4f18\u5316\u800c\u975e\u5355\u8f6e\u54cd\u5e94\u3002\u91c7\u7528\u6df7\u5408\u6700\u4f73\u8f68\u8ff9\u9009\u62e9\u65b9\u6848\uff0c\u7ed3\u5408\u5b66\u4e60\u9a8c\u8bc1\u5668\u6a21\u578b\u548c\u65e0\u6a21\u578b\u65b9\u6cd5\u3002", "result": "\u5728SWE-bench\u6392\u884c\u699c\u4e0a\uff0c30B\u53c2\u6570\u7684\\sys\u8bad\u7ec3\u6a21\u578b\u5728open-weight\u6a21\u578b\u4e2d\u6392\u540d\u7b2c\u4e00\uff08lite\uff09\u548c\u7b2c\u56db\uff08verified\uff09\uff0c\u6027\u80fd\u8d85\u8fc7\u53c2\u6570\u91cf10\u500d\u4ee5\u4e0a\u7684\u6a21\u578b\u3002", "conclusion": "\\sys\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u504f\u597d\u4f18\u5316\u4e2d\u7684\u591a\u6837\u6027\u635f\u5931\u95ee\u9898\uff0c\u5728\u591a\u8f6e\u5de5\u5177\u8f85\u52a9\u8bbe\u7f6e\u4e0b\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u7f16\u7801\u4ee3\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12681", "categories": ["eess.SY", "cs.SY", "93C10, 93C57, 93C62"], "pdf": "https://arxiv.org/pdf/2509.12681", "abs": "https://arxiv.org/abs/2509.12681", "authors": ["Yutaka Yamamoto", "Kaoru Yamamoto"], "title": "Nonlinear Sampled-data Systems--A Lifting Framework", "comment": null, "summary": "This short note gives a new framework for dealing with nonlinear sampled-data\nsystems. We introduce a new idea of lifting, which is well known for linear\nsystems, but not successfully generalized to nonlinear systems. This paper\nintroduces a new lifting technique for nonlinear, time-invariant systems, which\nare different from the linear counterpart as developed in [Bamieh et al. 1991,\nYamamoto 1994], etc. The main difficulty is that the direct feedthrough term\neffective in the linear case cannot be generalized to the nonlinear case.\nInstead, we will further lift the state trajectory, and obtain an equivalent\ntime-invariant discrete-time system with function-space input and output\nspaces. The basic framework, as well as the closed-loop equation with a\ndiscrete-time controller, is given. As an application of this framework, we\ngive a representation for the Koopman operator derived from the given original\nnonlinear system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u975e\u7ebf\u6027\u91c7\u6837\u6570\u636e\u7cfb\u7edf\u63d0\u5347\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u4e00\u6b65\u63d0\u5347\u72b6\u6001\u8f68\u8ff9\uff0c\u83b7\u5f97\u5177\u6709\u51fd\u6570\u7a7a\u95f4\u8f93\u5165\u8f93\u51fa\u7a7a\u95f4\u7684\u7b49\u6548\u65f6\u4e0d\u53d8\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf", "motivation": "\u7ebf\u6027\u7cfb\u7edf\u7684\u63d0\u5347\u6280\u672f\u65e0\u6cd5\u6210\u529f\u63a8\u5e7f\u5230\u975e\u7ebf\u6027\u7cfb\u7edf\uff0c\u4e3b\u8981\u56f0\u96be\u5728\u4e8e\u7ebf\u6027\u60c5\u51b5\u4e0b\u7684\u76f4\u63a5\u9988\u901a\u9879\u5728\u975e\u7ebf\u6027\u60c5\u51b5\u4e0b\u65e0\u6cd5\u63a8\u5e7f", "method": "\u5f15\u5165\u65b0\u7684\u63d0\u5347\u6280\u672f\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u72b6\u6001\u8f68\u8ff9\uff0c\u83b7\u5f97\u7b49\u6548\u7684\u65f6\u4e0d\u53d8\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\uff0c\u5177\u6709\u51fd\u6570\u7a7a\u95f4\u8f93\u5165\u548c\u8f93\u51fa\u7a7a\u95f4", "result": "\u5efa\u7acb\u4e86\u57fa\u672c\u6846\u67b6\u548c\u79bb\u6563\u65f6\u95f4\u63a7\u5236\u5668\u7684\u95ed\u73af\u65b9\u7a0b\uff0c\u5e76\u7ed9\u51fa\u4e86\u4ece\u539f\u59cb\u975e\u7ebf\u6027\u7cfb\u7edf\u5bfc\u51fa\u7684Koopman\u7b97\u5b50\u7684\u8868\u793a", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5904\u7406\u975e\u7ebf\u6027\u91c7\u6837\u6570\u636e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u7ebf\u6027\u63d0\u5347\u6280\u672f\u65e0\u6cd5\u5e94\u7528\u4e8e\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u95ee\u9898"}}
{"id": "2509.13212", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2509.13212", "abs": "https://arxiv.org/abs/2509.13212", "authors": ["Evan M. Williams", "Peter Carragher", "Kathleen M. Carley"], "title": "Extending the BEND Framework to Webgraphs", "comment": null, "summary": "Attempts to manipulate webgraphs can have many downstream impacts, but\nanalysts lack shared quantitative metrics to characterize actions taken to\nmanipulate information environments at this level. We demonstrate how the BEND\nframework can be used to characterize attempts to manipulate webgraph\ninformation environments, and propose quantitative metrics for BEND community\nmaneuvers. We demonstrate the face validity of our proposed Webgraph BEND\nmetrics by using them to characterize two small web-graphs containing\nSEO-boosted Kremlin-aligned websites. We demonstrate how our proposed metrics\nimprove BEND scores in webgraph settings and demonstrate the usefulness of our\nmetrics in characterizing webgraph information environments. These metrics\noffer analysts a systematic and standardized way to characterize attempts to\nmanipulate webgraphs using common Search Engine Optimization tactics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Webgraph BEND\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316\u8868\u5f81\u7f51\u7edc\u56fe\u4fe1\u606f\u73af\u5883\u4e2d\u7684\u64cd\u7eb5\u884c\u4e3a\uff0c\u7279\u522b\u662fSEO\u64cd\u7eb5\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u514b\u91cc\u59c6\u6797\u5bab\u76f8\u5173\u7f51\u7ad9\u7684\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5171\u4eab\u7684\u91cf\u5316\u6307\u6807\u6765\u8868\u5f81\u7f51\u7edc\u56fe\u5c42\u9762\u7684\u4fe1\u606f\u73af\u5883\u64cd\u7eb5\u884c\u4e3a\uff0c\u5206\u6790\u5e08\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5de5\u5177\u6765\u8bc6\u522b\u548c\u91cf\u5316\u8fd9\u7c7b\u64cd\u7eb5\u5c1d\u8bd5\u3002", "method": "\u5f00\u53d1BEND\u6846\u67b6\u4e0b\u7684Webgraph\u91cf\u5316\u6307\u6807\uff0c\u4f7f\u7528\u5305\u542bSEO\u63d0\u5347\u7684\u514b\u91cc\u59c6\u6797\u5bab\u76f8\u5173\u7f51\u7ad9\u7684\u4e24\u4e2a\u5c0f\u578b\u7f51\u7edc\u56fe\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5c55\u793a\u6307\u6807\u5728\u7f51\u7edc\u56fe\u8bbe\u7f6e\u4e2d\u7684\u6539\u8fdb\u6548\u679c\u3002", "result": "\u63d0\u51fa\u7684Webgraph BEND\u6307\u6807\u80fd\u591f\u6709\u6548\u8868\u5f81\u7f51\u7edc\u56fe\u4fe1\u606f\u73af\u5883\u4e2d\u7684\u64cd\u7eb5\u884c\u4e3a\uff0c\u5728\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u663e\u793a\u51fa\u826f\u597d\u7684\u8868\u9762\u6548\u5ea6\uff0c\u4e3a\u5206\u6790\u5e08\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u5206\u6790\u5de5\u5177\u3002", "conclusion": "Webgraph BEND\u6307\u6807\u4e3a\u5206\u6790\u5e08\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u548c\u6807\u51c6\u5316\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u7f51\u7edc\u56fe\u4e2d\u7684\u4fe1\u606f\u64cd\u7eb5\u5c1d\u8bd5\uff0c\u7279\u522b\u662f\u5728\u8bc6\u522b\u5e38\u89c1SEO\u6218\u672f\u65b9\u9762\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.13032", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13032", "abs": "https://arxiv.org/abs/2509.13032", "authors": ["Simon Wallace", "Sean Rehaag"], "title": "Introducing the A2AJ's Canadian Legal Data: An open-source alternative to CanLII for the era of computational law", "comment": null, "summary": "The Access to Algorithmic Justice project (A2AJ) is an open-source\nalternative to the Canadian Legal Information Institute (CanLII). At a moment\nwhen technology promises to enable new ways of working with law, CanLII is\nbecoming an impediment to the free access of law and access to justice\nmovements because it restricts bulk and programmatic access to Canadian legal\ndata. This means that Canada is staring down a digital divide: well-resourced\nactors have the best new technological tools and, because CanLII has disclaimed\nleadership, the public only gets second-rate tools. This article puts CanLII in\nits larger historical context and shows how long and deep efforts to\ndemocratize access to Canadian legal data are, and how often they are thwarted\nby private industry. We introduce the A2AJ's Canadian Legal Data project, which\nprovides open access to over 116,000 court decisions and 5,000 statutes through\nmultiple channels including APIs, machine learning datasets, and AI integration\nprotocols. Through concrete examples, we demonstrate how open legal data\nenables courts to conduct evidence-based assessments and allows developers to\ncreate tools for practitioners serving low-income communities.", "AI": {"tldr": "A2AJ\u9879\u76ee\u662fCanLII\u7684\u5f00\u6e90\u66ff\u4ee3\u65b9\u6848\uff0c\u63d0\u4f9b\u8d85\u8fc711.6\u4e07\u4efd\u6cd5\u9662\u5224\u51b3\u548c5000\u90e8\u6cd5\u89c4\u7684\u5f00\u653e\u8bbf\u95ee\uff0c\u901a\u8fc7API\u3001\u673a\u5668\u5b66\u4e60\u6570\u636e\u96c6\u548cAI\u96c6\u6210\u534f\u8bae\u7b49\u591a\u79cd\u6e20\u9053\uff0c\u65e8\u5728\u89e3\u51b3\u52a0\u62ff\u5927\u6cd5\u5f8b\u6570\u636e\u7684\u6570\u5b57\u9e3f\u6c9f\u95ee\u9898\u3002", "motivation": "CanLII\u9650\u5236\u4e86\u52a0\u62ff\u5927\u6cd5\u5f8b\u6570\u636e\u7684\u6279\u91cf\u5316\u548c\u7a0b\u5e8f\u5316\u8bbf\u95ee\uff0c\u963b\u788d\u4e86\u6cd5\u5f8b\u7684\u514d\u8d39\u83b7\u53d6\u548c\u53f8\u6cd5\u516c\u6b63\u8fd0\u52a8\uff0c\u5bfc\u81f4\u8d44\u6e90\u5145\u8db3\u7684\u673a\u6784\u62e5\u6709\u5148\u8fdb\u6280\u672f\u5de5\u5177\uff0c\u800c\u516c\u4f17\u53ea\u80fd\u4f7f\u7528\u4e8c\u6d41\u5de5\u5177\uff0c\u9020\u6210\u4e86\u6570\u5b57\u9e3f\u6c9f\u3002", "method": "\u521b\u5efaA2AJ\u52a0\u62ff\u5927\u6cd5\u5f8b\u6570\u636e\u9879\u76ee\uff0c\u63d0\u4f9b\u5f00\u653e\u8bbf\u95ee\u6e20\u9053\uff0c\u5305\u62ecAPI\u63a5\u53e3\u3001\u673a\u5668\u5b66\u4e60\u6570\u636e\u96c6\u548cAI\u96c6\u6210\u534f\u8bae\uff0c\u6536\u96c6\u5e76\u6574\u7406\u4e86\u8d85\u8fc711.6\u4e07\u4efd\u6cd5\u9662\u5224\u51b3\u548c5000\u90e8\u6cd5\u89c4\u3002", "result": "\u9879\u76ee\u6210\u529f\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u52a0\u62ff\u5927\u6cd5\u5f8b\u6570\u636e\u7684\u5f00\u653e\u8bbf\u95ee\uff0c\u4f7f\u6cd5\u9662\u80fd\u591f\u8fdb\u884c\u57fa\u4e8e\u8bc1\u636e\u7684\u8bc4\u4f30\uff0c\u5e76\u5141\u8bb8\u5f00\u53d1\u8005\u4e3a\u670d\u52a1\u4f4e\u6536\u5165\u793e\u533a\u7684\u4ece\u4e1a\u8005\u521b\u5efa\u5de5\u5177\u3002", "conclusion": "\u5f00\u653e\u6cd5\u5f8b\u6570\u636e\u5bf9\u4e8e\u5b9e\u73b0\u53f8\u6cd5\u516c\u6b63\u548c\u7f29\u5c0f\u6570\u5b57\u9e3f\u6c9f\u81f3\u5173\u91cd\u8981\uff0cA2AJ\u9879\u76ee\u4e3a\u52a0\u62ff\u5927\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u5f00\u6e90\u66ff\u4ee3\u65b9\u6848\uff0c\u4fc3\u8fdb\u4e86\u6cd5\u5f8b\u6280\u672f\u7684\u6c11\u4e3b\u5316\u53d1\u5c55\u3002"}}
{"id": "2509.12516", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12516", "abs": "https://arxiv.org/abs/2509.12516", "authors": ["William Ward", "Sarah Etter", "Jesse Quattrociocchi", "Christian Ellis", "Adam J. Thorpe", "Ufuk Topcu"], "title": "Zero to Autonomy in Real-Time: Online Adaptation of Dynamics in Unstructured Environments", "comment": "Submitted to ICRA 2026", "summary": "Autonomous robots must go from zero prior knowledge to safe control within\nseconds to operate in unstructured environments. Abrupt terrain changes, such\nas a sudden transition to ice, create dynamics shifts that can destabilize\nplanners unless the model adapts in real-time. We present a method for online\nadaptation that combines function encoders with recursive least squares,\ntreating the function encoder coefficients as latent states updated from\nstreaming odometry. This yields constant-time coefficient estimation without\ngradient-based inner-loop updates, enabling adaptation from only a few seconds\nof data. We evaluate our approach on a Van der Pol system to highlight\nalgorithmic behavior, in a Unity simulator for high-fidelity off-road\nnavigation, and on a Clearpath Jackal robot, including on a challenging terrain\nat a local ice rink. Across these settings, our method improves model accuracy\nand downstream planning, reducing collisions compared to static and\nmeta-learning baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u7ebf\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u7ed3\u5408\u51fd\u6570\u7f16\u7801\u5668\u548c\u9012\u5f52\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff0c\u5728\u51e0\u79d2\u5185\u5b9e\u73b0\u6052\u5b9a\u65f6\u95f4\u7cfb\u6570\u4f30\u8ba1\uff0c\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7cbe\u5ea6\u548c\u8def\u5f84\u89c4\u5212\u6027\u80fd", "motivation": "\u81ea\u4e3b\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u9700\u8981\u5feb\u901f\u4ece\u96f6\u77e5\u8bc6\u5230\u5b89\u5168\u63a7\u5236\uff0c\u5730\u5f62\u7a81\u53d8\uff08\u5982\u7a81\u7136\u8f6c\u5411\u51b0\u9762\uff09\u4f1a\u5bfc\u81f4\u52a8\u529b\u5b66\u53d8\u5316\uff0c\u7834\u574f\u89c4\u5212\u5668\u7684\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u5b9e\u65f6\u6a21\u578b\u81ea\u9002\u5e94", "method": "\u5c06\u51fd\u6570\u7f16\u7801\u5668\u7cfb\u6570\u4f5c\u4e3a\u6f5c\u5728\u72b6\u6001\uff0c\u901a\u8fc7\u6d41\u5f0f\u91cc\u7a0b\u8ba1\u6570\u636e\u8fdb\u884c\u66f4\u65b0\uff0c\u4f7f\u7528\u9012\u5f52\u6700\u5c0f\u4e8c\u4e58\u6cd5\u5b9e\u73b0\u6052\u5b9a\u65f6\u95f4\u7cfb\u6570\u4f30\u8ba1\uff0c\u907f\u514d\u57fa\u4e8e\u68af\u5ea6\u7684\u5185\u5faa\u73af\u66f4\u65b0", "result": "\u5728Van der Pol\u7cfb\u7edf\u3001Unity\u9ad8\u4fdd\u771f\u8d8a\u91ce\u5bfc\u822a\u6a21\u62df\u5668\u548cClearpath Jackal\u673a\u5668\u4eba\uff08\u5305\u62ec\u5f53\u5730\u6e9c\u51b0\u573a\u7684\u6311\u6218\u6027\u5730\u5f62\uff09\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027\uff0c\u6539\u5584\u4e86\u4e0b\u6e38\u89c4\u5212\uff0c\u51cf\u5c11\u4e86\u78b0\u649e", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ec5\u7528\u51e0\u79d2\u6570\u636e\u5b9e\u73b0\u5feb\u901f\u5728\u7ebf\u9002\u5e94\uff0c\u5728\u9759\u6001\u6a21\u578b\u548c\u5143\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u673a\u5668\u4eba\u5feb\u901f\u9002\u5e94\u52a8\u6001\u73af\u5883\u53d8\u5316"}}
{"id": "2509.12437", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12437", "abs": "https://arxiv.org/abs/2509.12437", "authors": ["Dingrui Wang", "Zhexiao Sun", "Zhouheng Li", "Cheng Wang", "Youlun Peng", "Hongyuan Ye", "Baha Zarrouki", "Wei Li", "Mattia Piccinini", "Lei Xie", "Johannes Betz"], "title": "Enhancing Physical Consistency in Lightweight World Models", "comment": "8 pages", "summary": "A major challenge in deploying world models is the trade-off between size and\nperformance. Large world models can capture rich physical dynamics but require\nmassive computing resources, making them impractical for edge devices. Small\nworld models are easier to deploy but often struggle to learn accurate physics,\nleading to poor predictions. We propose the Physics-Informed BEV World Model\n(PIWM), a compact model designed to efficiently capture physical interactions\nin bird's-eye-view (BEV) representations. PIWM uses Soft Mask during training\nto improve dynamic object modeling and future prediction. We also introduce a\nsimple yet effective technique, Warm Start, for inference to enhance prediction\nquality with a zero-shot model. Experiments show that at the same parameter\nscale (400M), PIWM surpasses the baseline by 60.6% in weighted overall score.\nMoreover, even when compared with the largest baseline model (400M), the\nsmallest PIWM (130M Soft Mask) achieves a 7.4% higher weighted overall score\nwith a 28% faster inference speed.", "AI": {"tldr": "PIWM\u662f\u4e00\u4e2a\u7d27\u51d1\u7684\u9e1f\u77b0\u56fe\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7Soft Mask\u8bad\u7ec3\u548cWarm Start\u63a8\u7406\u6280\u672f\uff0c\u5728\u4fdd\u6301\u5c0f\u53c2\u6570\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7269\u7406\u4ea4\u4e92\u5efa\u6a21\u548c\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u4e16\u754c\u6a21\u578b\u5728\u90e8\u7f72\u65f6\u7684\u5927\u5c0f\u4e0e\u6027\u80fd\u6743\u8861\u95ee\u9898\uff0c\u5927\u6a21\u578b\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u5c0f\u6a21\u578b\u7269\u7406\u5b66\u4e60\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u63d0\u51faPhysics-Informed BEV World Model (PIWM)\uff0c\u4f7f\u7528Soft Mask\u8bad\u7ec3\u6539\u8fdb\u52a8\u6001\u5bf9\u8c61\u5efa\u6a21\uff0c\u5f15\u5165Warm Start\u63a8\u7406\u6280\u672f\u63d0\u5347\u9884\u6d4b\u8d28\u91cf\u3002", "result": "\u5728\u76f8\u540c\u53c2\u6570\u91cf(400M)\u4e0b\u6bd4\u57fa\u7ebf\u63d0\u534760.6%\u52a0\u6743\u603b\u5206\uff0c\u6700\u5c0f\u6a21\u578b(130M)\u6bd4\u6700\u5927\u57fa\u7ebf\u6a21\u578b(400M)\u5f97\u5206\u9ad87.4%\u4e14\u63a8\u7406\u901f\u5ea6\u5feb28%\u3002", "conclusion": "PIWM\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5c0f\u53c2\u6570\u6a21\u578b\u7684\u9ad8\u6027\u80fd\u7269\u7406\u5efa\u6a21\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12695", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12695", "abs": "https://arxiv.org/abs/2509.12695", "authors": ["Taehun Kim", "Guntae Kim", "Cheolmin Jeong", "Chang Mook Kang"], "title": "MAPS: A Mode-Aware Probabilistic Scheduling Framework for LPV-Based Adaptive Control", "comment": null, "summary": "This paper proposes Mode-Aware Probabilistic Scheduling (MAPS), a novel\nadaptive control framework tailored for DC motor systems experiencing varying\nfriction. MAPS uniquely integrates an Interacting Multiple Model (IMM)\nestimator with a Linear Parameter-Varying (LPV) based control strategy,\nleveraging real-time mode probability estimates to perform probabilistic gain\nscheduling. A key innovation of MAPS lies in directly using the updated mode\nprobabilities as the interpolation weights for online gain synthesis in the LPV\ncontroller, thereby tightly coupling state estimation with adaptive control.\nThis seamless integration enables the controller to dynamically adapt control\ngains in real time, effectively responding to changes in frictional operating\nmodes without requiring explicit friction model identification. Validation on a\nHardware-in-the-Loop Simulation (HILS) environment demonstrates that MAPS\nsignificantly enhances both state estimation accuracy and reference tracking\nperformance compared to Linear Quadratic Regulator (LQR) controllers relying on\npredefined scheduling variables. These results establish MAPS as a robust,\ngeneralizable solution for friction-aware adaptive control in uncertain,\ntime-varying environments, with practical real-time applicability.", "AI": {"tldr": "\u63d0\u51faMAPS\u6846\u67b6\uff0c\u7ed3\u5408IMM\u4f30\u8ba1\u5668\u548cLPV\u63a7\u5236\uff0c\u5229\u7528\u5b9e\u65f6\u6a21\u5f0f\u6982\u7387\u8fdb\u884c\u6982\u7387\u589e\u76ca\u8c03\u5ea6\uff0c\u65e0\u9700\u663e\u5f0f\u6469\u64e6\u6a21\u578b\u8bc6\u522b\u5373\u53ef\u81ea\u9002\u5e94\u63a7\u5236\u76f4\u6d41\u7535\u673a\u7cfb\u7edf", "motivation": "\u9488\u5bf9\u76f4\u6d41\u7535\u673a\u7cfb\u7edf\u5728\u53d8\u5316\u6469\u64e6\u6761\u4ef6\u4e0b\u7684\u63a7\u5236\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u8c03\u5ea6\u53d8\u91cf\u6216\u663e\u5f0f\u6469\u64e6\u6a21\u578b\u8bc6\u522b\uff0c\u96be\u4ee5\u5728\u4e0d\u786e\u5b9a\u65f6\u53d8\u73af\u5883\u4e2d\u5b9e\u73b0\u6709\u6548\u81ea\u9002\u5e94\u63a7\u5236", "method": "\u96c6\u6210\u4ea4\u4e92\u591a\u6a21\u578b(IMM)\u4f30\u8ba1\u5668\u548c\u7ebf\u6027\u53c2\u6570\u53d8\u5316(LPV)\u63a7\u5236\u7b56\u7565\uff0c\u4f7f\u7528\u66f4\u65b0\u7684\u6a21\u5f0f\u6982\u7387\u4f5c\u4e3aLPV\u63a7\u5236\u5668\u5728\u7ebf\u589e\u76ca\u5408\u6210\u7684\u63d2\u503c\u6743\u91cd\uff0c\u5b9e\u73b0\u72b6\u6001\u4f30\u8ba1\u4e0e\u81ea\u9002\u5e94\u63a7\u5236\u7684\u7d27\u5bc6\u8026\u5408", "result": "\u5728\u786c\u4ef6\u5728\u73af\u4eff\u771f\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u4f9d\u8d56\u9884\u5b9a\u4e49\u8c03\u5ea6\u53d8\u91cf\u7684LQR\u63a7\u5236\u5668\uff0cMAPS\u663e\u8457\u63d0\u9ad8\u4e86\u72b6\u6001\u4f30\u8ba1\u7cbe\u5ea6\u548c\u53c2\u8003\u8ddf\u8e2a\u6027\u80fd", "conclusion": "MAPS\u4e3a\u4e0d\u786e\u5b9a\u65f6\u53d8\u73af\u5883\u4e2d\u7684\u6469\u64e6\u611f\u77e5\u81ea\u9002\u5e94\u63a7\u5236\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u53ef\u63a8\u5e7f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5b9e\u65f6\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.13230", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2509.13230", "abs": "https://arxiv.org/abs/2509.13230", "authors": ["Xuanchi Li", "Xin Wang", "Sadamori Kojaku"], "title": "Fast Unbiased Sampling of Networks with Given Expected Degrees and Strengths", "comment": null, "summary": "The configuration model is a cornerstone of statistical assessment of network\nstructure. While the Chung-Lu model is among the most widely used configuration\nmodels, it systematically oversamples edges between large-degree nodes, leading\nto inaccurate statistical conclusions. Although the maximum entropy principle\noffers unbiased configuration models, its high computational cost has hindered\nwidespread adoption, making the Chung-Lu model an inaccurate yet persistently\npractical choice. Here, we propose fast and efficient sampling algorithms for\nthe max-entropy-based models by adapting the Miller-Hagberg algorithm.\nEvaluation on 103 empirical networks demonstrates 10-1000 times speedup, making\ntheoretically rigorous configuration models practical and contributing to a\nmore accurate understanding of network structure.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6700\u5927\u71b5\u914d\u7f6e\u6a21\u578b\u7684\u5feb\u901f\u91c7\u6837\u7b97\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edfChung-Lu\u6a21\u578b\u66f4\u51c6\u786e\u4e14\u8ba1\u7b97\u6548\u7387\u63d0\u534710-1000\u500d", "motivation": "Chung-Lu\u914d\u7f6e\u6a21\u578b\u867d\u7136\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4f1a\u7cfb\u7edf\u6027\u5730\u9ad8\u4f30\u5927\u5ea6\u6570\u8282\u70b9\u95f4\u7684\u8fb9\u6570\uff0c\u5bfc\u81f4\u7edf\u8ba1\u7ed3\u8bba\u4e0d\u51c6\u786e\u3002\u6700\u5927\u71b5\u6a21\u578b\u7406\u8bba\u4e0a\u66f4\u4e25\u8c28\u4f46\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8", "method": "\u901a\u8fc7\u6539\u8fdbMiller-Hagberg\u7b97\u6cd5\uff0c\u5f00\u53d1\u4e86\u9488\u5bf9\u6700\u5927\u71b5\u914d\u7f6e\u6a21\u578b\u7684\u5feb\u901f\u9ad8\u6548\u91c7\u6837\u7b97\u6cd5", "result": "\u5728103\u4e2a\u5b9e\u8bc1\u7f51\u7edc\u4e0a\u6d4b\u8bd5\u663e\u793a\uff0c\u7b97\u6cd5\u901f\u5ea6\u63d0\u534710-1000\u500d\uff0c\u4f7f\u7406\u8bba\u4e25\u8c28\u7684\u914d\u7f6e\u6a21\u578b\u53d8\u5f97\u5b9e\u7528", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u5f97\u7406\u8bba\u4e0a\u66f4\u4e25\u8c28\u7684\u6700\u5927\u71b5\u914d\u7f6e\u6a21\u578b\u53d8\u5f97\u5b9e\u7528\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u7406\u89e3\u7f51\u7edc\u7ed3\u6784"}}
{"id": "2509.13156", "categories": ["cs.CY", "K.4.3; K.4.4; C.2.4"], "pdf": "https://arxiv.org/pdf/2509.13156", "abs": "https://arxiv.org/abs/2509.13156", "authors": ["Henrik Axelsen", "Jan Damsgaard"], "title": "Designing the Hybrid Cooperative: A Socio-Technical Architecture for Scalable, Global Coordination Using Blockchain", "comment": "Accepted for presentation at HICSS-59 (2026), forthcoming in\n  Proceedings", "summary": "Blockchain has been promoted as a remedy for coordination in fragmented,\nmulti-stakeholder ecosystems, yet many projects stall at pilot stage. Using a\ndesign-science approach, we develop the Hybrid Cooperative (HC), a digitally\nnative governance architecture that combines smart-contract coordination with a\nminimal, code-deferent legal interface and jurisdictional modules. This\nselective decentralization decentralizes rules where programmability lowers\nagency and verification costs, and centralizes only what is needed for\nenforceability. A post-case evaluation against two traceability initiatives in\nsupply chains illustrates how the HC improves distributed task management,\nverifiable information, incentive alignment, institutional interoperability,\nand scalable, contestable governance. The paper contributes to Information\nSystems by specifying a socio-technical model for scalable, multi-stakeholder\ncoordination across regulatory and organizational boundaries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5408\u4f5c\u793e\uff08HC\uff09\u67b6\u6784\uff0c\u7ed3\u5408\u667a\u80fd\u5408\u7ea6\u534f\u8c03\u4e0e\u6700\u5c0f\u5316\u6cd5\u5f8b\u63a5\u53e3\uff0c\u5b9e\u73b0\u9009\u62e9\u6027\u53bb\u4e2d\u5fc3\u5316\u6cbb\u7406\uff0c\u89e3\u51b3\u591a\u5229\u76ca\u76f8\u5173\u65b9\u751f\u6001\u7cfb\u7edf\u7684\u534f\u8c03\u95ee\u9898\u3002", "motivation": "\u533a\u5757\u94fe\u6280\u672f\u867d\u7136\u88ab\u63a8\u5e7f\u7528\u4e8e\u788e\u7247\u5316\u591a\u5229\u76ca\u76f8\u5173\u65b9\u751f\u6001\u7cfb\u7edf\u7684\u534f\u8c03\uff0c\u4f46\u8bb8\u591a\u9879\u76ee\u505c\u7559\u5728\u8bd5\u70b9\u9636\u6bb5\uff0c\u9700\u8981\u89e3\u51b3\u53ef\u6269\u5c55\u6cbb\u7406\u548c\u8de8\u76d1\u7ba1\u8fb9\u754c\u534f\u8c03\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u65b9\u6cd5\uff0c\u5f00\u53d1\u6df7\u5408\u5408\u4f5c\u793e\uff08HC\uff09\u67b6\u6784\uff0c\u7ed3\u5408\u667a\u80fd\u5408\u7ea6\u534f\u8c03\u3001\u6700\u5c0f\u5316\u4ee3\u7801\u9075\u4ece\u6cd5\u5f8b\u63a5\u53e3\u548c\u53f8\u6cd5\u7ba1\u8f96\u533a\u6a21\u5757\uff0c\u5b9e\u73b0\u9009\u62e9\u6027\u53bb\u4e2d\u5fc3\u5316\u3002", "result": "\u901a\u8fc7\u5bf9\u4e24\u4e2a\u4f9b\u5e94\u94fe\u8ffd\u6eaf\u9879\u76ee\u7684\u540e\u6848\u4f8b\u8bc4\u4f30\uff0cHC\u5728\u5206\u5e03\u5f0f\u4efb\u52a1\u7ba1\u7406\u3001\u53ef\u9a8c\u8bc1\u4fe1\u606f\u3001\u6fc0\u52b1\u5bf9\u9f50\u3001\u5236\u5ea6\u4e92\u64cd\u4f5c\u6027\u548c\u53ef\u6269\u5c55\u6cbb\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4fe1\u606f\u7cfb\u7edf\u9886\u57df\u8d21\u732e\u4e86\u4e00\u4e2a\u793e\u4f1a\u6280\u672f\u6a21\u578b\uff0c\u80fd\u591f\u5728\u76d1\u7ba1\u548c\u7ec4\u7ec7\u8fb9\u754c\u4e4b\u95f4\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u591a\u5229\u76ca\u76f8\u5173\u65b9\u534f\u8c03\u3002"}}
{"id": "2509.12531", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "68T07, 68T40 (Primary) 93C85, 62L20 (Secondary)", "I.2.6; I.2.9; I.4.8; F.2.2"], "pdf": "https://arxiv.org/pdf/2509.12531", "abs": "https://arxiv.org/abs/2509.12531", "authors": ["Scott Jones", "Liyou Zhou", "Sebastian W. Pattinson"], "title": "Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning", "comment": null, "summary": "In visuomotor policy learning, the control policy for the robotic agent is\nderived directly from visual inputs. The typical approach, where a policy and\nvision encoder are trained jointly from scratch, generalizes poorly to novel\nvisual scene changes. Using pre-trained vision models (PVMs) to inform a policy\nnetwork improves robustness in model-free reinforcement learning (MFRL). Recent\ndevelopments in Model-based reinforcement learning (MBRL) suggest that MBRL is\nmore sample-efficient than MFRL. However, counterintuitively, existing work has\nfound PVMs to be ineffective in MBRL. Here, we investigate PVM's effectiveness\nin MBRL, specifically on generalization under visual domain shifts. We show\nthat, in scenarios with severe shifts, PVMs perform much better than a baseline\nmodel trained from scratch. We further investigate the effects of varying\nlevels of fine-tuning of PVMs. Our results show that partial fine-tuning can\nmaintain the highest average task performance under the most extreme\ndistribution shifts. Our results demonstrate that PVMs are highly successful in\npromoting robustness in visual policy learning, providing compelling evidence\nfor their wider adoption in model-based robotic learning applications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9884\u8bad\u7ec3\u89c6\u89c9\u6a21\u578b(PVMs)\u5728\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60(MBRL)\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9\u57df\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0PVMs\u5728\u4e25\u91cd\u504f\u79fb\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u90e8\u5206\u5fae\u8c03\u80fd\u5728\u6781\u7aef\u5206\u5e03\u504f\u79fb\u4e0b\u4fdd\u6301\u6700\u9ad8\u5e73\u5747\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60(MBRL)\u6bd4\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60(MFRL)\u66f4\u5177\u6837\u672c\u6548\u7387\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u53d1\u73b0\u9884\u8bad\u7ec3\u89c6\u89c9\u6a21\u578b(PVMs)\u5728MBRL\u4e2d\u6548\u679c\u4e0d\u4f73\u3002\u672c\u6587\u65e8\u5728\u6df1\u5165\u63a2\u7a76PVMs\u5728MBRL\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9\u57df\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7814\u7a76PVMs\u5728MBRL\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u5173\u6ce8\u89c6\u89c9\u57df\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6bd4\u8f83PVMs\u4e0e\u4ece\u5934\u8bad\u7ec3\u57fa\u7ebf\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u7814\u7a76\u4e0d\u540c\u7a0b\u5ea6\u7684PVMs\u5fae\u8c03\u6548\u679c\u3002", "result": "\u5728\u4e25\u91cd\u89c6\u89c9\u57df\u504f\u79fb\u573a\u666f\u4e2d\uff0cPVMs\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684\u57fa\u7ebf\u6a21\u578b\u3002\u90e8\u5206\u5fae\u8c03\u7684PVMs\u80fd\u5728\u6700\u6781\u7aef\u5206\u5e03\u504f\u79fb\u4e0b\u4fdd\u6301\u6700\u9ad8\u7684\u5e73\u5747\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "PVMs\u5728\u89c6\u89c9\u7b56\u7565\u5b66\u4e60\u4e2d\u80fd\u6709\u6548\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u4e3a\u5728\u57fa\u4e8e\u6a21\u578b\u7684\u673a\u5668\u4eba\u5b66\u4e60\u5e94\u7528\u4e2d\u66f4\u5e7f\u6cdb\u91c7\u7528PVMs\u63d0\u4f9b\u4e86\u6709\u529b\u8bc1\u636e\u3002"}}
{"id": "2509.12464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12464", "abs": "https://arxiv.org/abs/2509.12464", "authors": ["Ryan Lucas", "Kayhan Behdin", "Zhipeng Wang", "Qingquan Song", "Shao Tang", "Rahul Mazumder"], "title": "Reasoning Models Can be Accurately Pruned Via Chain-of-Thought Reconstruction", "comment": null, "summary": "Reasoning language models such as DeepSeek-R1 produce long chain-of-thought\ntraces during inference time which make them costly to deploy at scale. We show\nthat using compression techniques such as neural network pruning produces\ngreater performance loss than in typical language modeling tasks, and in some\ncases can make the model slower since they cause the model to produce more\nthinking tokens but with worse performance. We show that this is partly due to\nthe fact that standard LLM pruning methods often focus on input reconstruction,\nwhereas reasoning is a decode-dominated task. We introduce a simple, drop-in\nfix: during pruning we jointly reconstruct activations from the input and the\nmodel's on-policy chain-of-thought traces. This \"Reasoning-Aware Compression\"\n(RAC) integrates seamlessly into existing pruning workflows such as SparseGPT,\nand boosts their performance significantly. Code reproducing the results in the\npaper can be found at: https://github.com/RyanLucas3/RAC", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faReasoning-Aware Compression (RAC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u526a\u679d\u8fc7\u7a0b\u4e2d\u540c\u65f6\u91cd\u6784\u8f93\u5165\u548c\u601d\u7ef4\u94fe\u6fc0\u6d3b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u538b\u7f29\u6548\u679c\uff0c\u907f\u514d\u4f20\u7edf\u526a\u679d\u65b9\u6cd5\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u548c\u63a8\u7406\u901f\u5ea6\u53d8\u6162\u95ee\u9898\u3002", "motivation": "\u63a8\u7406\u8bed\u8a00\u6a21\u578b\uff08\u5982DeepSeek-R1\uff09\u5728\u63a8\u7406\u65f6\u4ea7\u751f\u957f\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u5bfc\u81f4\u90e8\u7f72\u6210\u672c\u9ad8\u6602\u3002\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u526a\u679d\u65b9\u6cd5\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u751a\u81f3\u53ef\u80fd\u4f7f\u6a21\u578b\u66f4\u6162\u4e14\u6027\u80fd\u66f4\u5dee\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8f93\u5165\u91cd\u6784\uff0c\u800c\u63a8\u7406\u662f\u89e3\u7801\u4e3b\u5bfc\u7684\u4efb\u52a1\u3002", "method": "\u63d0\u51faReasoning-Aware Compression (RAC)\u65b9\u6cd5\uff1a\u5728\u526a\u679d\u8fc7\u7a0b\u4e2d\u8054\u5408\u91cd\u6784\u6765\u81ea\u8f93\u5165\u7684\u6fc0\u6d3b\u548c\u6a21\u578b\u5728\u7b56\u7565\u601d\u7ef4\u94fe\u8f68\u8ff9\u7684\u6fc0\u6d3b\u3002\u8be5\u65b9\u6cd5\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u526a\u679d\u5de5\u4f5c\u6d41\uff08\u5982SparseGPT\uff09\u4e2d\u3002", "result": "RAC\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u526a\u679d\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u5bfc\u81f4\u7684\u6027\u80fd\u635f\u5931\u548c\u63a8\u7406\u901f\u5ea6\u4e0b\u964d\u95ee\u9898\u3002", "conclusion": "RAC\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684drop-in\u4fee\u590d\u65b9\u6848\uff0c\u901a\u8fc7\u8003\u8651\u63a8\u7406\u4efb\u52a1\u7684\u7279\u6b8a\u6027\uff0c\u5728\u526a\u679d\u8fc7\u7a0b\u4e2d\u540c\u65f6\u5904\u7406\u8f93\u5165\u548c\u601d\u7ef4\u94fe\u6fc0\u6d3b\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u63a8\u7406\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u6a21\u578b\u538b\u7f29\u3002"}}
{"id": "2509.12758", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12758", "abs": "https://arxiv.org/abs/2509.12758", "authors": ["Ping Zhang", "Xiaodong Xu", "Mengying Sun", "Haixiao Gao", "Nan Ma", "Xiaoyun Wang", "Ruichen Zhang", "Jiacheng Wang", "Dusit Niyato"], "title": "Towards Native AI in 6G Standardization: The Roadmap of Semantic Communication", "comment": null, "summary": "Semantic communication (SemCom) has emerged as a transformative paradigm for\nfuture 6G networks, offering task-oriented and meaning-aware transmission that\nfundamentally redefines traditional bit-centric design. Recognized by leading\nstandardization bodies including the institute of electrical and electronics\nengineers (IEEE) and the international telecommunication union (ITU), and\nactively discussed within the 3rd generation partnership project (3GPP) working\ngroups, SemCom is rapidly gaining traction as a foundational enabler for\nnative-AI 6G. This paper presents a comprehensive overview of recent progress\nin SemCom from both academic and industrial perspectives, with a focus on its\nongoing and upcoming standardization activities. We systematically examine\nadvances in representative application scenarios, architectural design,\nsemantic-traditional system compatibility, unified evaluation metrics, and\nvalidation methodologies. Furthermore, we highlight several key enabling\ntechnologies, such as joint source-channel coding (JSCC), SemCom-based multiple\naccess (MA) technologies such as model division MA (MDMA), and semantic\nknowledge base (KB), that support the practical implementation of SemCom in\nstandard-compliant systems. Additionally, we present a case study for channel\nstate information (CSI) feedback, illustrating the concrete performance gains\nof SemCom under 3GPP-compliant fading channels. Finally, we discuss emerging\nchallenges and research opportunities for incorporating semantic-native\nmechanisms into the evolving 6G standardization landscape, and provide\nforward-looking insights into its development and global adoption.", "AI": {"tldr": "\u672c\u6587\u5bf96G\u8bed\u4e49\u901a\u4fe1(SemCom)\u7684\u6700\u65b0\u8fdb\u5c55\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u6807\u51c6\u5316\u6d3b\u52a8\u3001\u5e94\u7528\u573a\u666f\u3001\u67b6\u6784\u8bbe\u8ba1\u3001\u5173\u952e\u6280\u672f\uff0c\u5e76\u901a\u8fc7CSI\u53cd\u9988\u6848\u4f8b\u5c55\u793a\u4e86\u57283GPP\u517c\u5bb9\u4fe1\u9053\u4e0b\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u8bed\u4e49\u901a\u4fe1\u4f5c\u4e3a6G\u7f51\u7edc\u53d8\u9769\u6027\u8303\u5f0f\uff0c\u88abIEEE\u3001ITU\u7b49\u4e3b\u8981\u6807\u51c6\u5316\u7ec4\u7ec7\u8ba4\u53ef\uff0c\u6b63\u57283GPP\u5de5\u4f5c\u7ec4\u4e2d\u79ef\u6781\u8ba8\u8bba\uff0c\u9700\u8981\u7cfb\u7edf\u603b\u7ed3\u5176\u5b66\u672f\u548c\u5de5\u4e1a\u8fdb\u5c55\u4ee5\u63a8\u52a8\u6807\u51c6\u5316\u8fdb\u7a0b\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u8003\u5bdf\u4e86\u4ee3\u8868\u6027\u5e94\u7528\u573a\u666f\u3001\u67b6\u6784\u8bbe\u8ba1\u3001\u8bed\u4e49-\u4f20\u7edf\u7cfb\u7edf\u517c\u5bb9\u6027\u3001\u7edf\u4e00\u8bc4\u4f30\u6307\u6807\u548c\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u91cd\u70b9\u5206\u6790\u4e86JSCC\u3001MDMA\u3001\u8bed\u4e49\u77e5\u8bc6\u5e93\u7b49\u5173\u952e\u6280\u672f\uff0c\u5e76\u901a\u8fc73GPP\u517c\u5bb9\u8870\u843d\u4fe1\u9053\u4e0b\u7684CSI\u53cd\u9988\u6848\u4f8b\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u8bed\u4e49\u901a\u4fe1\u5728\u6807\u51c6\u5316\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u5173\u952e\u6280\u672f\u5982JSCC\u548cMDMA\u652f\u6301\u5b9e\u9645\u7cfb\u7edf\u5b9e\u73b0\uff0c\u6848\u4f8b\u7814\u7a76\u8868\u660e\u5728\u6807\u51c6\u517c\u5bb9\u4fe1\u9053\u4e0b\u80fd\u5e26\u6765\u5177\u4f53\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u8bed\u4e49\u901a\u4fe1\u662f6G\u539f\u751fAI\u7684\u91cd\u8981\u4f7f\u80fd\u6280\u672f\uff0c\u4f46\u4ecd\u9762\u4e34\u5c06\u8bed\u4e49\u539f\u751f\u673a\u5236\u878d\u51656G\u6807\u51c6\u5316\u4f53\u7cfb\u7684\u6311\u6218\uff0c\u9700\u8981\u7ee7\u7eed\u7814\u7a76\u5176\u53d1\u5c55\u548c\u5168\u7403\u91c7\u7528\u8def\u5f84\u3002"}}
{"id": "2509.12900", "categories": ["eess.SY", "cs.SI", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12900", "abs": "https://arxiv.org/abs/2509.12900", "authors": ["B\u00e1lint Hartmann", "Michelle T. Cirunay"], "title": "Topology and Fragility of European High-Voltage Networks: A Cross-Country Comparative Analysis", "comment": null, "summary": "Reliable electricity supply depends on the seamless operation of high-voltage\ngrid infrastructure spanning both transmission and sub-transmission levels.\nBeneath this apparent uniformity lies a striking structural diversity, which\nleaves a clear imprint on system vulnerability. In this paper, we present\nharmonized topological models of the high-voltage grids of 15 European\ncountries, integrating all elements at voltage levels above 110 kV. Topological\nanalysis of these networks reveals a simple yet robust pattern: node degree\ndistributions consistently follow an exponential decay, but the rate of decay\nvaries significantly across countries. Through a detailed and systematic\nevaluation of network tolerance to node and edge removals, we show that the\ndecay rate delineates the boundary between systems that are more resilient to\nfailures and those that are prone to large-scale disruptions. Furthermore, we\ndemonstrate that this numerical boundary is highly sensitive to which layers of\nthe infrastructure are included in the models. To our knowledge, this study\nprovides the first quantitative cross-country comparison of 15 European\nhigh-voltage networks, linking topological properties with vulnerability\ncharacteristics.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e8615\u4e2a\u6b27\u6d32\u56fd\u5bb6\u7684\u9ad8\u538b\u7535\u7f51\u62d3\u6251\u7ed3\u6784\uff0c\u53d1\u73b0\u8282\u70b9\u5ea6\u5206\u5e03\u5448\u73b0\u6307\u6570\u8870\u51cf\u6a21\u5f0f\uff0c\u8870\u51cf\u7387\u51b3\u5b9a\u4e86\u7535\u7f51\u5bf9\u6545\u969c\u7684\u6062\u590d\u80fd\u529b\u8fb9\u754c\uff0c\u4e14\u8fd9\u4e00\u8fb9\u754c\u5bf9\u6a21\u578b\u5305\u542b\u7684\u57fa\u7840\u8bbe\u65bd\u5c42\u7ea7\u9ad8\u5ea6\u654f\u611f\u3002", "motivation": "\u9ad8\u538b\u7535\u7f51\u770b\u4f3c\u7edf\u4e00\u5b9e\u5219\u7ed3\u6784\u591a\u6837\uff0c\u8fd9\u79cd\u591a\u6837\u6027\u5bf9\u7cfb\u7edf\u8106\u5f31\u6027\u6709\u663e\u8457\u5f71\u54cd\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u62d3\u6251\u5206\u6790\u63ed\u793a\u6b27\u6d32\u5404\u56fd\u9ad8\u538b\u7535\u7f51\u7684\u7ed3\u6784\u7279\u5f81\u4e0e\u8106\u5f31\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5efa\u7acb\u4e8615\u4e2a\u6b27\u6d32\u56fd\u5bb6110kV\u4ee5\u4e0a\u9ad8\u538b\u7535\u7f51\u7684\u7edf\u4e00\u62d3\u6251\u6a21\u578b\uff0c\u901a\u8fc7\u8282\u70b9\u548c\u8fb9\u79fb\u9664\u7684\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5206\u6790\u7f51\u7edc\u5bb9\u9519\u80fd\u529b\uff0c\u7814\u7a76\u8282\u70b9\u5ea6\u5206\u5e03\u8870\u51cf\u7387\u4e0e\u7cfb\u7edf\u6062\u590d\u529b\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u6240\u6709\u56fd\u5bb6\u7535\u7f51\u8282\u70b9\u5ea6\u5206\u5e03\u90fd\u5448\u73b0\u6307\u6570\u8870\u51cf\uff0c\u4f46\u8870\u51cf\u7387\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b\u8870\u51cf\u7387\u5b9a\u4e49\u4e86\u7cfb\u7edf\u5bf9\u6545\u969c\u6062\u590d\u80fd\u529b\u7684\u5173\u952e\u8fb9\u754c\uff1b\u8fd9\u4e00\u6570\u503c\u8fb9\u754c\u5bf9\u6a21\u578b\u5305\u542b\u7684\u57fa\u7840\u8bbe\u65bd\u5c42\u7ea7\u9ad8\u5ea6\u654f\u611f\u3002", "conclusion": "\u7814\u7a76\u9996\u6b21\u63d0\u4f9b\u4e8615\u4e2a\u6b27\u6d32\u56fd\u5bb6\u9ad8\u538b\u7535\u7f51\u7684\u5b9a\u91cf\u8de8\u56fd\u6bd4\u8f83\uff0c\u5c06\u62d3\u6251\u7279\u6027\u4e0e\u8106\u5f31\u6027\u7279\u5f81\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u7535\u7f51\u53ef\u9760\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2509.13265", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13265", "abs": "https://arxiv.org/abs/2509.13265", "authors": ["Yukun Zhang", "TianYang Zhang"], "title": "Beyond Private or Public: Large Language Models as Quasi-Public Goods in the AI Economy", "comment": null, "summary": "This paper conceptualizes Large Language Models (LLMs) as a form of mixed\npublic goods within digital infrastructure, analyzing their economic properties\nthrough a comprehensive theoretical framework. We develop mathematical models\nto quantify the non-rivalry characteristics, partial excludability, and\npositive externalities of LLMs. Through comparative analysis of open-source and\nclosed-source development paths, we identify systematic differences in resource\nallocation efficiency, innovation trajectories, and access equity. Our\nempirical research evaluates the spillover effects and network externalities of\nLLMs across different domains, including knowledge diffusion, innovation\nacceleration, and industry transformation. Based on these findings, we propose\npolicy recommendations for balancing innovation incentives with equitable\naccess, including public-private partnership mechanisms, computational resource\ndemocratization, and governance structures that optimize social welfare. This\ninterdisciplinary approach contributes to understanding the economic nature of\nfoundation AI models and provides policy guidance for their development as\ncritical digital infrastructure", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u6982\u5ff5\u5316\u4e3a\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u6df7\u5408\u516c\u5171\u4ea7\u54c1\uff0c\u901a\u8fc7\u7406\u8bba\u6846\u67b6\u5206\u6790\u5176\u7ecf\u6d4e\u7279\u6027\uff0c\u6bd4\u8f83\u5f00\u6e90\u548c\u95ed\u6e90\u53d1\u5c55\u8def\u5f84\u7684\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u5e73\u8861\u521b\u65b0\u6fc0\u52b1\u4e0e\u516c\u5e73\u8bbf\u95ee\u7684\u653f\u7b56\u5efa\u8bae\u3002", "motivation": "\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u57fa\u7840AI\u6a21\u578b\u7684\u7ecf\u6d4e\u672c\u8d28\uff0c\u5206\u6790\u5176\u4f5c\u4e3a\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u7684\u7ecf\u6d4e\u7279\u6027\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\uff0c\u4ee5\u4f18\u5316\u793e\u4f1a\u798f\u5229\u3002", "method": "\u5f00\u53d1\u6570\u5b66\u6a21\u578b\u91cf\u5316LLMs\u7684\u975e\u7ade\u4e89\u6027\u3001\u90e8\u5206\u6392\u4ed6\u6027\u548c\u6b63\u5916\u90e8\u6027\u7279\u5f81\uff1b\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u5f00\u6e90\u548c\u95ed\u6e90\u53d1\u5c55\u8def\u5f84\uff1b\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30LLMs\u5728\u4e0d\u540c\u9886\u57df\u7684\u6ea2\u51fa\u6548\u5e94\u548c\u7f51\u7edc\u5916\u90e8\u6027\u3002", "result": "\u8bc6\u522b\u4e86\u5f00\u6e90\u548c\u95ed\u6e90\u53d1\u5c55\u8def\u5f84\u5728\u8d44\u6e90\u914d\u7f6e\u6548\u7387\u3001\u521b\u65b0\u8f68\u8ff9\u548c\u8bbf\u95ee\u516c\u5e73\u6027\u65b9\u9762\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff1b\u91cf\u5316\u4e86LLMs\u7684\u77e5\u8bc6\u6269\u6563\u3001\u521b\u65b0\u52a0\u901f\u548c\u4ea7\u4e1a\u8f6c\u578b\u7b49\u5916\u90e8\u6027\u6548\u5e94\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5e73\u8861\u521b\u65b0\u6fc0\u52b1\u4e0e\u516c\u5e73\u8bbf\u95ee\u7684\u653f\u7b56\u5efa\u8bae\uff0c\u5305\u62ec\u516c\u79c1\u5408\u4f5c\u673a\u5236\u3001\u8ba1\u7b97\u8d44\u6e90\u6c11\u4e3b\u5316\u548c\u4f18\u5316\u793e\u4f1a\u798f\u5229\u7684\u6cbb\u7406\u7ed3\u6784\uff0c\u4e3aLLMs\u4f5c\u4e3a\u5173\u952e\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u7684\u53d1\u5c55\u63d0\u4f9b\u653f\u7b56\u6307\u5bfc\u3002"}}
{"id": "2509.12562", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12562", "abs": "https://arxiv.org/abs/2509.12562", "authors": ["Zhefei Gong", "Shangke Lyu", "Pengxiang Ding", "Wei Xiao", "Donglin Wang"], "title": "Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling", "comment": null, "summary": "Imitation learning (IL) enables efficient skill acquisition from\ndemonstrations but often struggles with long-horizon tasks and high-precision\ncontrol due to compounding errors. Residual policy learning offers a promising,\nmodel-agnostic solution by refining a base policy through closed-loop\ncorrections. However, existing approaches primarily focus on local corrections\nto the base policy, lacking a global understanding of state evolution, which\nlimits robustness and generalization to unseen scenarios. To address this, we\npropose incorporating global dynamics modeling to guide residual policy\nupdates. Specifically, we leverage Koopman operator theory to impose linear\ntime-invariant structure in a learned latent space, enabling reliable state\ntransitions and improved extrapolation for long-horizon prediction and unseen\nenvironments. We introduce KORR (Koopman-guided Online Residual Refinement), a\nsimple yet effective framework that conditions residual corrections on\nKoopman-predicted latent states, enabling globally informed and stable action\nrefinement. We evaluate KORR on long-horizon, fine-grained robotic furniture\nassembly tasks under various perturbations. Results demonstrate consistent\ngains in performance, robustness, and generalization over strong baselines. Our\nfindings further highlight the potential of Koopman-based modeling to bridge\nmodern learning methods with classical control theory.", "AI": {"tldr": "\u63d0\u51fa\u4e86KORR\u6846\u67b6\uff0c\u901a\u8fc7Koopman\u7b97\u5b50\u7406\u8bba\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5efa\u7acb\u7ebf\u6027\u65f6\u4e0d\u53d8\u7ed3\u6784\uff0c\u4e3a\u6b8b\u5dee\u7b56\u7565\u5b66\u4e60\u63d0\u4f9b\u5168\u5c40\u52a8\u6001\u5efa\u6a21\u6307\u5bfc\uff0c\u5728\u957f\u65f6\u7a0b\u7cbe\u7ec6\u673a\u5668\u4eba\u88c5\u914d\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b", "motivation": "\u73b0\u6709\u6b8b\u5dee\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5c40\u90e8\u4fee\u6b63\uff0c\u7f3a\u4e4f\u5bf9\u72b6\u6001\u6f14\u5316\u7684\u5168\u5c40\u7406\u89e3\uff0c\u9650\u5236\u4e86\u5728\u672a\u89c1\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b", "method": "\u5229\u7528Koopman\u7b97\u5b50\u7406\u8bba\u5728\u5b66\u4e60\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u65bd\u52a0\u7ebf\u6027\u65f6\u4e0d\u53d8\u7ed3\u6784\uff0c\u4f7f\u6b8b\u5dee\u4fee\u6b63\u4ee5Koopman\u9884\u6d4b\u7684\u6f5c\u5728\u72b6\u6001\u4e3a\u6761\u4ef6\uff0c\u5b9e\u73b0\u5168\u5c40\u77e5\u60c5\u548c\u7a33\u5b9a\u7684\u52a8\u4f5c\u7ec6\u5316", "result": "\u5728\u957f\u65f6\u7a0b\u7cbe\u7ec6\u673a\u5668\u4eba\u5bb6\u5177\u88c5\u914d\u4efb\u52a1\u7684\u5404\u79cd\u6270\u52a8\u4e0b\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u4e86\u6301\u7eed\u7684\u6027\u80fd\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u63d0\u5347", "conclusion": "\u57fa\u4e8eKoopman\u7684\u5efa\u6a21\u6709\u6f5c\u529b\u5c06\u73b0\u4ee3\u5b66\u4e60\u65b9\u6cd5\u4e0e\u7ecf\u5178\u63a7\u5236\u7406\u8bba\u8fde\u63a5\u8d77\u6765\uff0c\u4e3a\u6b8b\u5dee\u7b56\u7565\u5b66\u4e60\u63d0\u4f9b\u6709\u6548\u7684\u5168\u5c40\u6307\u5bfc\u6846\u67b6"}}
{"id": "2509.12471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12471", "abs": "https://arxiv.org/abs/2509.12471", "authors": ["Yiwen Lu", "Lu Li", "Dazheng Zhang", "Xinyao Jian", "Tingyin Wang", "Siqi Chen", "Yuqing Lei", "Jiayi Tong", "Zhaohan Xi", "Haitao Chu", "Chongliang Luo", "Alexis Ogdie", "Brian Athey", "Alparslan Turan", "Michael Abramoff", "Joseph C Cappelleri", "Hua Xu", "Yun Lu", "Jesse Berlin", "Daniel I. Sessler", "David A. Asch", "Xiaoqian Jiang", "Yong Chen"], "title": "Empowering Clinical Trial Design through AI: A Randomized Evaluation of PowerGPT", "comment": null, "summary": "Sample size calculations for power analysis are critical for clinical\nresearch and trial design, yet their complexity and reliance on statistical\nexpertise create barriers for many researchers. We introduce PowerGPT, an\nAI-powered system integrating large language models (LLMs) with statistical\nengines to automate test selection and sample size estimation in trial design.\nIn a randomized trial to evaluate its effectiveness, PowerGPT significantly\nimproved task completion rates (99.3% vs. 88.9% for test selection, 99.3% vs.\n77.8% for sample size calculation) and accuracy (94.1% vs. 55.4% in sample size\nestimation, p < 0.001), while reducing average completion time (4.0 vs. 9.3\nminutes, p < 0.001). These gains were consistent across various statistical\ntests and benefited both statisticians and non-statisticians as well as\nbridging expertise gaps. Already under deployment across multiple institutions,\nPowerGPT represents a scalable AI-driven approach that enhances accessibility,\nefficiency, and accuracy in statistical power analysis for clinical research.", "AI": {"tldr": "PowerGPT\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7edf\u8ba1\u5f15\u64ce\uff0c\u81ea\u52a8\u5316\u4e34\u5e8a\u8bd5\u9a8c\u8bbe\u8ba1\u4e2d\u7684\u68c0\u9a8c\u9009\u62e9\u548c\u6837\u672c\u91cf\u8ba1\u7b97\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b8c\u6210\u7387\u3001\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4e34\u5e8a\u8bd5\u9a8c\u8bbe\u8ba1\u4e2d\u7684\u6837\u672c\u91cf\u8ba1\u7b97\u548c\u529f\u6548\u5206\u6790\u5bf9\u7edf\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u8981\u6c42\u9ad8\uff0c\u590d\u6742\u6027\u5f3a\uff0c\u7ed9\u8bb8\u591a\u7814\u7a76\u4eba\u5458\u9020\u6210\u4e86\u969c\u788d\uff0c\u9700\u8981\u66f4\u6613\u7528\u548c\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86PowerGPT\u7cfb\u7edf\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7edf\u8ba1\u5f15\u64ce\u96c6\u6210\uff0c\u81ea\u52a8\u5316\u8fdb\u884c\u68c0\u9a8c\u9009\u62e9\u548c\u6837\u672c\u91cf\u4f30\u8ba1\u3002\u901a\u8fc7\u968f\u673a\u8bd5\u9a8c\u8bc4\u4f30\u5176\u6709\u6548\u6027\u3002", "result": "PowerGPT\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\uff08\u68c0\u9a8c\u9009\u62e999.3% vs 88.9%\uff0c\u6837\u672c\u91cf\u8ba1\u7b9799.3% vs 77.8%\uff09\u548c\u51c6\u786e\u6027\uff08\u6837\u672c\u91cf\u4f30\u8ba194.1% vs 55.4%\uff0cp<0.001\uff09\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u5e73\u5747\u5b8c\u6210\u65f6\u95f4\uff084.0 vs 9.3\u5206\u949f\uff0cp<0.001\uff09\u3002\u8fd9\u4e9b\u4f18\u52bf\u5728\u5404\u79cd\u7edf\u8ba1\u68c0\u9a8c\u4e2d\u4e00\u81f4\uff0c\u5bf9\u7edf\u8ba1\u5b66\u5bb6\u548c\u975e\u7edf\u8ba1\u5b66\u5bb6\u90fd\u6709\u76ca\u3002", "conclusion": "PowerGPT\u4ee3\u8868\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684AI\u9a71\u52a8\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u4e34\u5e8a\u7814\u7a76\u4e2d\u7edf\u8ba1\u529f\u6548\u5206\u6790\u7684\u53ef\u53ca\u6027\u3001\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5df2\u5728\u591a\u4e2a\u673a\u6784\u90e8\u7f72\u4f7f\u7528\u3002"}}
{"id": "2509.12792", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.12792", "abs": "https://arxiv.org/abs/2509.12792", "authors": ["Moritz Heinlein", "Florian Messerer", "Moritz Diehl", "Sergio Lucia"], "title": "Ellipsoidal partitions for improved multi-stage robust model predictive control", "comment": "Paper accepted for CDC 2025, Code available under:\n  https://github.com/MoritzHein/Ellipsoid_Partition", "summary": "Ellipsoidal tube-based model predictive control methods effectively account\nfor the propagation of the reachable set, typically employing linear feedback\npolicies. In contrast, scenario-based approaches offer more flexibility in the\nfeedback structure by considering different control actions for different\nbranches of a scenario tree. However, they face challenges in ensuring rigorous\nguarantees. This work aims to integrate the strengths of both methodologies by\nenhancing ellipsoidal tube-based MPC with a scenario tree formulation. The\nuncertainty ellipsoids are partitioned by halfspaces such that each partitioned\nset can be controlled independently. The proposed ellipsoidal multi-stage\napproach is demonstrated in a human-robot system, highlighting its advantages\nin handling uncertainty while maintaining computational tractability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u692d\u7403\u7ba1MPC\u4e0e\u573a\u666f\u6811\u65b9\u6cd5\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u692d\u7403\u591a\u9636\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u534a\u7a7a\u95f4\u5212\u5206\u4e0d\u786e\u5b9a\u6027\u692d\u7403\u96c6\u5b9e\u73b0\u72ec\u7acb\u63a7\u5236\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u53ef\u884c\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u80fd\u529b", "motivation": "\u692d\u7403\u7ba1MPC\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u53ef\u8fbe\u96c6\u4f20\u64ad\u4f46\u901a\u5e38\u4f7f\u7528\u7ebf\u6027\u53cd\u9988\u7b56\u7565\uff0c\u800c\u573a\u666f\u6811\u65b9\u6cd5\u5728\u53cd\u9988\u7ed3\u6784\u4e0a\u66f4\u7075\u6d3b\u4f46\u96be\u4ee5\u63d0\u4f9b\u4e25\u683c\u4fdd\u8bc1\u3002\u672c\u7814\u7a76\u65e8\u5728\u6574\u5408\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf", "method": "\u901a\u8fc7\u534a\u7a7a\u95f4\u5212\u5206\u4e0d\u786e\u5b9a\u6027\u692d\u7403\u96c6\uff0c\u4f7f\u6bcf\u4e2a\u5212\u5206\u540e\u7684\u96c6\u5408\u80fd\u591f\u88ab\u72ec\u7acb\u63a7\u5236\uff0c\u5c06\u692d\u7403\u7ba1MPC\u4e0e\u573a\u666f\u6811\u516c\u5f0f\u76f8\u7ed3\u5408", "result": "\u5728\u4eba\u7c7b-\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u692d\u7403\u591a\u9636\u6bb5\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u4f18\u52bf", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u6574\u5408\u4e86\u692d\u7403\u7ba1MPC\u548c\u573a\u666f\u6811\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u53ef\u884c\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u80fd\u529b"}}
{"id": "2509.12594", "categories": ["cs.RO", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.12594", "abs": "https://arxiv.org/abs/2509.12594", "authors": ["Titong Jiang", "Xuefeng Jiang", "Yuan Ma", "Xin Wen", "Bailin Li", "Kun Zhan", "Peng Jia", "Yahui Liu", "Sheng Sun", "Xianpeng Lang"], "title": "The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning", "comment": "Under review. Project site:\n  https://liauto-research.github.io/LightVLA", "summary": "We present LightVLA, a simple yet effective differentiable token pruning\nframework for vision-language-action (VLA) models. While VLA models have shown\nimpressive capability in executing real-world robotic tasks, their deployment\non resource-constrained platforms is often bottlenecked by the heavy\nattention-based computation over large sets of visual tokens. LightVLA\naddresses this challenge through adaptive, performance-driven pruning of visual\ntokens: It generates dynamic queries to evaluate visual token importance, and\nadopts Gumbel softmax to enable differentiable token selection. Through\nfine-tuning, LightVLA learns to preserve the most informative visual tokens\nwhile pruning tokens which do not contribute to task execution, thereby\nimproving efficiency and performance simultaneously. Notably, LightVLA requires\nno heuristic magic numbers and introduces no additional trainable parameters,\nmaking it compatible with modern inference frameworks. Experimental results\ndemonstrate that LightVLA outperforms different VLA models and existing token\npruning methods across diverse tasks on the LIBERO benchmark, achieving higher\nsuccess rates with substantially reduced computational overhead. Specifically,\nLightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.9%\nimprovement in task success rate. Meanwhile, we also investigate the learnable\nquery-based token pruning method LightVLA* with additional trainable\nparameters, which also achieves satisfactory performance. Our work reveals that\nas VLA pursues optimal performance, LightVLA spontaneously learns to prune\ntokens from a performance-driven perspective. To the best of our knowledge,\nLightVLA is the first work to apply adaptive visual token pruning to VLA tasks\nwith the collateral goals of efficiency and performance, marking a significant\nstep toward more efficient, powerful and practical real-time robotic systems.", "AI": {"tldr": "LightVLA\u662f\u4e00\u4e2a\u9488\u5bf9\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u53ef\u5fae\u5206token\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u526a\u679d\u89c6\u89c9token\u6765\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002", "motivation": "VLA\u6a21\u578b\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u90e8\u7f72\u65f6\uff0c\u5927\u91cf\u89c6\u89c9token\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u6210\u4e3a\u74f6\u9888\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684token\u526a\u679d\u65b9\u6cd5\u6765\u5e73\u8861\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "\u4f7f\u7528\u52a8\u6001\u67e5\u8be2\u8bc4\u4f30\u89c6\u89c9token\u91cd\u8981\u6027\uff0c\u91c7\u7528Gumbel softmax\u5b9e\u73b0\u53ef\u5fae\u5206token\u9009\u62e9\uff0c\u901a\u8fc7\u5fae\u8c03\u5b66\u4e60\u4fdd\u7559\u4fe1\u606f\u91cf\u6700\u5927\u7684token\uff0c\u65e0\u9700\u542f\u53d1\u5f0f\u53c2\u6570\u6216\u989d\u5916\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLightVLA\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\uff0cFLOPs\u51cf\u5c1159.1%\uff0c\u5ef6\u8fdf\u964d\u4f4e38.2%\uff0c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u53472.9%\u3002", "conclusion": "LightVLA\u662f\u9996\u4e2a\u5c06\u81ea\u9002\u5e94\u89c6\u89c9token\u526a\u679d\u5e94\u7528\u4e8eVLA\u4efb\u52a1\u7684\u5de5\u4f5c\uff0c\u4ece\u6027\u80fd\u9a71\u52a8\u89d2\u5ea6\u81ea\u53d1\u5b66\u4e60\u526a\u679d\u7b56\u7565\uff0c\u4e3a\u5b9e\u73b0\u9ad8\u6548\u3001\u5f3a\u5927\u4e14\u5b9e\u7528\u7684\u5b9e\u65f6\u673a\u5668\u4eba\u7cfb\u7edf\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2509.12495", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.12495", "abs": "https://arxiv.org/abs/2509.12495", "authors": ["G\u00fclce Karde\u015f", "David Krakauer", "Joshua Grochow"], "title": "Physical Complexity of a Cognitive Artifact", "comment": null, "summary": "Cognitive science and theoretical computer science both seek to classify and\nexplain the difficulty of tasks. Mechanisms of intelligence are those that\nreduce task difficulty. Here we map concepts from the computational complexity\nof a physical puzzle, the Soma Cube, onto cognitive problem-solving strategies\nthrough a ``Principle of Materiality''. By analyzing the puzzle's branching\nfactor, measured through search tree outdegree, we quantitatively assess task\ndifficulty and systematically examine how different strategies modify\ncomplexity. We incrementally refine a trial-and-error search by layering\npreprocessing (cognitive chunking), value ordering (cognitive free-sorting),\nvariable ordering (cognitive scaffolding), and pruning (cognitive inference).\nWe discuss how the competent use of artifacts reduces effective time complexity\nby exploiting physical constraints and propose a model of intelligence as a\nlibrary of algorithms that recruit the capabilities of both mind and matter.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790Soma Cube\u7269\u7406\u62fc\u56fe\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5c06\u8ba1\u7b97\u673a\u79d1\u5b66\u6982\u5ff5\u6620\u5c04\u5230\u8ba4\u77e5\u95ee\u9898\u89e3\u51b3\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\"\u7269\u8d28\u6027\u539f\u5219\"\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5206\u5c42\u7b56\u7565\u964d\u4f4e\u4efb\u52a1\u96be\u5ea6\u3002", "motivation": "\u8ba4\u77e5\u79d1\u5b66\u548c\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u90fd\u81f4\u529b\u4e8e\u5206\u7c7b\u548c\u89e3\u91ca\u4efb\u52a1\u7684\u96be\u5ea6\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u667a\u80fd\u673a\u5236\u5982\u4f55\u901a\u8fc7\u5229\u7528\u7269\u7406\u7ea6\u675f\u548c\u8ba4\u77e5\u7b56\u7565\u6765\u964d\u4f4e\u4efb\u52a1\u590d\u6742\u5ea6\u3002", "method": "\u901a\u8fc7\u5206\u6790Soma Cube\u62fc\u56fe\u7684\u5206\u652f\u56e0\u5b50\uff08\u641c\u7d22\u6811\u51fa\u5ea6\uff09\u6765\u91cf\u5316\u4efb\u52a1\u96be\u5ea6\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u68c0\u9a8c\u9884\u5904\u7406\uff08\u8ba4\u77e5\u7ec4\u5757\uff09\u3001\u503c\u6392\u5e8f\uff08\u8ba4\u77e5\u81ea\u7531\u6392\u5e8f\uff09\u3001\u53d8\u91cf\u6392\u5e8f\uff08\u8ba4\u77e5\u652f\u67b6\uff09\u548c\u526a\u679d\uff08\u8ba4\u77e5\u63a8\u7406\uff09\u7b49\u7b56\u7565\u5982\u4f55\u4fee\u6539\u590d\u6742\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u901a\u8fc7\u5206\u5c42\u7b56\u7565\u53ef\u4ee5\u9010\u6b65\u6539\u8fdb\u8bd5\u9519\u641c\u7d22\uff0c\u6709\u6548\u964d\u4f4e\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u7269\u7406\u7ea6\u675f\u548c\u8ba4\u77e5\u7b56\u7565\u7684\u534f\u540c\u4f5c\u7528\u6765\u7b80\u5316\u95ee\u9898\u89e3\u51b3\u8fc7\u7a0b\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u667a\u80fd\u4f5c\u4e3a\u4e00\u4e2a\u7b97\u6cd5\u5e93\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u540c\u65f6\u5229\u7528\u5fc3\u667a\u548c\u7269\u8d28\u7684\u80fd\u529b\uff0c\u901a\u8fc7\"\u7269\u8d28\u6027\u539f\u5219\"\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u6982\u5ff5\u4e0e\u8ba4\u77e5\u7b56\u7565\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u7406\u89e3\u667a\u80fd\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2509.12839", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12839", "abs": "https://arxiv.org/abs/2509.12839", "authors": ["Liuxun Xue", "Shu Sun", "Hangsong Yan"], "title": "Spatial Correlation and Degrees of Freedom in Arched HMIMO Arrays: A Closed-Form Analysis", "comment": null, "summary": "This paper presents a closed-form analysis of spatial correlation and degrees\nof freedom (DoF) for arched holographic multiple-input multiple-output (HMIMO)\narrays, which can be viewed as a special form of fluid antenna systems (FAS)\nwhen their geometry is fluidically adaptable. Unlike traditional planar\nconfigurations, practical HMIMO surfaces may exhibit curvature, significantly\ninfluencing their spatial characteristics and performance. We derive exact\ncorrelation expressions for both arched uniform linear arrays and arched\nuniform rectangular arrays, capturing curvature effects under far field\npropagation. Our results reveal that isotropic scattering results in DoF being\ndominated by the maximum span of the HMIMO array, such that shape effects are\nweakened, and bending does not significantly reduce the available spatial DoF.\nNumerical simulations validate the accuracy of the closed-form formulas and\ndemonstrate the robustness of DoF against curvature variations, supporting\nflexible array designs. These findings offer fundamental insights into\ngeometry-aware optimization for next-generation HMIMO/FAS systems and pave the\nway for practical implementations of curved HMIMO arrays.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5f27\u5f62\u5168\u606fMIMO\u9635\u5217\u7684\u7a7a\u95f4\u76f8\u5173\u6027\u548c\u81ea\u7531\u5ea6\u8fdb\u884c\u4e86\u95ed\u5f0f\u5206\u6790\uff0c\u53d1\u73b0\u5404\u5411\u540c\u6027\u6563\u5c04\u4e0b\u81ea\u7531\u5ea6\u4e3b\u8981\u53d7\u9635\u5217\u6700\u5927\u8de8\u5ea6\u4e3b\u5bfc\uff0c\u5f2f\u66f2\u4e0d\u4f1a\u663e\u8457\u964d\u4f4e\u7a7a\u95f4\u81ea\u7531\u5ea6\u3002", "motivation": "\u4f20\u7edf\u5e73\u9762\u914d\u7f6e\u7684\u5168\u606fMIMO\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u5177\u6709\u66f2\u7387\uff0c\u8fd9\u4f1a\u663e\u8457\u5f71\u54cd\u5176\u7a7a\u95f4\u7279\u6027\u548c\u6027\u80fd\uff0c\u9700\u8981\u7814\u7a76\u5f2f\u66f2\u6548\u5e94\u5bf9\u9635\u5217\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u63a8\u5bfc\u4e86\u5f27\u5f62\u5747\u5300\u7ebf\u6027\u9635\u5217\u548c\u5f27\u5f62\u5747\u5300\u77e9\u5f62\u9635\u5217\u5728\u8fdc\u573a\u4f20\u64ad\u4e0b\u7684\u7cbe\u786e\u76f8\u5173\u8868\u8fbe\u5f0f\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u95ed\u5f0f\u516c\u5f0f\u7684\u51c6\u786e\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5404\u5411\u540c\u6027\u6563\u5c04\u6761\u4ef6\u4e0b\uff0c\u81ea\u7531\u5ea6\u7531HMIMO\u9635\u5217\u7684\u6700\u5927\u8de8\u5ea6\u4e3b\u5bfc\uff0c\u5f62\u72b6\u6548\u5e94\u51cf\u5f31\uff0c\u5f2f\u66f2\u4e0d\u4f1a\u663e\u8457\u964d\u4f4e\u53ef\u7528\u7a7a\u95f4\u81ea\u7531\u5ea6\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u4e0b\u4e00\u4ee3HMIMO/FAS\u7cfb\u7edf\u7684\u51e0\u4f55\u611f\u77e5\u4f18\u5316\u63d0\u4f9b\u4e86\u57fa\u7840\u89c1\u89e3\uff0c\u5e76\u4e3a\u5f2f\u66f2HMIMO\u9635\u5217\u7684\u5b9e\u9645\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2509.12618", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.12618", "abs": "https://arxiv.org/abs/2509.12618", "authors": ["Zekai Zhang", "Weiye Zhu", "Hewei Pan", "Xiangchen Wang", "Rongtao Xu", "Xing Sun", "Feng Zheng"], "title": "ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation", "comment": null, "summary": "The Vision-and-Language Navigation (VLN) task requires an agent to follow\nnatural language instructions and navigate through complex environments.\nExisting MLLM-based VLN methods primarily rely on imitation learning (IL) and\noften use DAgger for post-training to mitigate covariate shift. While\neffective, these approaches incur substantial data collection and training\ncosts. Reinforcement learning (RL) offers a promising alternative. However,\nprior VLN RL methods lack dynamic interaction with the environment and depend\non expert trajectories for reward shaping, rather than engaging in open-ended\nactive exploration. This restricts the agent's ability to discover diverse and\nplausible navigation routes. To address these limitations, we propose\nActiveVLN, a VLN framework that explicitly enables active exploration through\nmulti-turn RL. In the first stage, a small fraction of expert trajectories is\nused for IL to bootstrap the agent. In the second stage, the agent iteratively\npredicts and executes actions, automatically collects diverse trajectories, and\noptimizes multiple rollouts via the GRPO objective. To further improve RL\nefficiency, we introduce a dynamic early-stopping strategy to prune long-tail\nor likely failed trajectories, along with additional engineering optimizations.\nExperiments show that ActiveVLN achieves the largest performance gains over IL\nbaselines compared to both DAgger-based and prior RL-based post-training\nmethods, while reaching competitive performance with state-of-the-art\napproaches despite using a smaller model. Code and data will be released soon.", "AI": {"tldr": "ActiveVLN\u662f\u4e00\u4e2a\u901a\u8fc7\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4e3b\u52a8\u63a2\u7d22\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u6a21\u4eff\u5b66\u4e60\u548cDAgger\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u6570\u636e\u6536\u96c6\u548c\u8bad\u7ec3\u6210\u672c\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684VLN\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6a21\u4eff\u5b66\u4e60\u548cDAgger\u540e\u8bad\u7ec3\uff0c\u5b58\u5728\u6570\u636e\u6536\u96c6\u548c\u8bad\u7ec3\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u662f\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u4e4b\u524d\u7684RL\u65b9\u6cd5\u7f3a\u4e4f\u4e0e\u73af\u5883\u52a8\u6001\u4ea4\u4e92\uff0c\u4f9d\u8d56\u4e13\u5bb6\u8f68\u8ff9\u8fdb\u884c\u5956\u52b1\u5851\u9020\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u53d1\u73b0\u591a\u6837\u5316\u5bfc\u822a\u8def\u5f84\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5c11\u91cf\u4e13\u5bb6\u8f68\u8ff9\u8fdb\u884c\u6a21\u4eff\u5b66\u4e60\u521d\u59cb\u5316\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u591a\u8f6eRL\uff0c\u667a\u80fd\u4f53\u8fed\u4ee3\u9884\u6d4b\u548c\u6267\u884c\u52a8\u4f5c\uff0c\u81ea\u52a8\u6536\u96c6\u591a\u6837\u5316\u8f68\u8ff9\uff0c\u4f7f\u7528GRPO\u76ee\u6807\u4f18\u5316\u591a\u4e2arollout\u3002\u5f15\u5165\u52a8\u6001\u65e9\u505c\u7b56\u7565\u4fee\u526a\u957f\u5c3e\u6216\u53ef\u80fd\u5931\u8d25\u7684\u8f68\u8ff9\u3002", "result": "ActiveVLN\u76f8\u6bd4IL\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6700\u5927\u7684\u6027\u80fd\u63d0\u5347\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u4e8eDAgger\u548c\u5148\u524dRL\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u4f7f\u7528\u8f83\u5c0f\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e86\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\u3002", "conclusion": "ActiveVLN\u901a\u8fc7\u4e3b\u52a8\u63a2\u7d22\u548c\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86VLN\u4efb\u52a1\u4e2d\u7684\u63a2\u7d22\u9650\u5236\u95ee\u9898\uff0c\u5728\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u5bfc\u822a\u6027\u80fd\u3002"}}
{"id": "2509.12524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12524", "abs": "https://arxiv.org/abs/2509.12524", "authors": ["Rohit Chakraborty", "Subasish Das"], "title": "A Dimensionality-Reduced XAI Framework for Roundabout Crash Severity Insights", "comment": "This is the author's preprint version of a paper accepted for\n  presentation at HICSS 59 (Hawaii International Conference on System\n  Sciences), 2026, Hawaii, USA. The final published version will appear in the\n  official conference proceedings. Conference site: https://hicss.hawaii.edu/", "summary": "Roundabouts reduce severe crashes, yet risk patterns vary by conditions. This\nstudy analyzes 2017-2021 Ohio roundabout crashes using a two-step, explainable\nworkflow. Cluster Correspondence Analysis (CCA) identifies co-occurring factors\nand yields four crash patterns. A tree-based severity model is then interpreted\nwith SHAP to quantify drivers of injury within and across patterns. Results\nshow higher severity when darkness, wet surfaces, and higher posted speeds\ncoincide with fixed-object or angle events, and lower severity in clear,\nlow-speed settings. Pattern-specific explanations highlight mechanisms at\nentries (fail-to-yield, gap acceptance), within multi-lane circulation\n(improper maneuvers), and during slow-downs (rear-end). The workflow links\npattern discovery with case-level explanations, supporting site screening,\ncountermeasure selection, and audit-ready reporting. The contribution to\nInformation Systems is a practical template for usable XAI in public safety\nanalytics.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e24\u6b65\u9aa4\u53ef\u89e3\u91ca\u5de5\u4f5c\u6d41\u5206\u6790\u4fc4\u4ea5\u4fc4\u5dde\u73af\u5c9b\u4e8b\u6545\uff0c\u8bc6\u522b\u56db\u79cd\u4e8b\u6545\u6a21\u5f0f\u5e76\u7528SHAP\u89e3\u91ca\u6811\u6a21\u578b\u91cf\u5316\u4f24\u5bb3\u9a71\u52a8\u56e0\u7d20\uff0c\u53d1\u73b0\u9ed1\u6697\u3001\u6e7f\u6ed1\u8def\u9762\u548c\u9ad8\u901f\u6761\u4ef6\u4e0b\u4e8b\u6545\u66f4\u4e25\u91cd\uff0c\u4e3a\u516c\u5171\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u5b9e\u7528XAI\u6a21\u677f\u3002", "motivation": "\u73af\u5c9b\u867d\u7136\u51cf\u5c11\u4e86\u4e25\u91cd\u4e8b\u6545\uff0c\u4f46\u98ce\u9669\u6a21\u5f0f\u56e0\u6761\u4ef6\u800c\u5f02\uff0c\u9700\u8981\u53ef\u89e3\u91ca\u7684\u5206\u6790\u65b9\u6cd5\u6765\u7406\u89e3\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u4e8b\u6545\u673a\u5236\u548c\u4e25\u91cd\u6027\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u4f7f\u7528\u805a\u7c7b\u5bf9\u5e94\u5206\u6790(CCA)\u8bc6\u522b\u5171\u73b0\u56e0\u7d20\u5e76\u5f97\u5230\u56db\u79cd\u4e8b\u6545\u6a21\u5f0f\uff0c\u7136\u540e\u57fa\u4e8e\u6811\u7684\u4e25\u91cd\u6027\u6a21\u578b\u7528SHAP\u89e3\u91ca\u6765\u91cf\u5316\u6a21\u5f0f\u5185\u548c\u8de8\u6a21\u5f0f\u7684\u4f24\u5bb3\u9a71\u52a8\u56e0\u7d20\u3002", "result": "\u7ed3\u679c\u663e\u793a\u9ed1\u6697\u3001\u6e7f\u6ed1\u8def\u9762\u548c\u8f83\u9ad8\u9650\u901f\u4e0e\u56fa\u5b9a\u7269\u4f53\u6216\u89d2\u5ea6\u4e8b\u4ef6\u540c\u65f6\u53d1\u751f\u65f6\u4e25\u91cd\u6027\u66f4\u9ad8\uff0c\u800c\u5728\u6e05\u6670\u3001\u4f4e\u901f\u73af\u5883\u4e0b\u4e25\u91cd\u6027\u8f83\u4f4e\u3002\u6a21\u5f0f\u7279\u5b9a\u89e3\u91ca\u7a81\u51fa\u4e86\u5165\u53e3\u5904(\u672a\u8ba9\u884c\u3001\u95f4\u9699\u63a5\u53d7)\u3001\u591a\u8f66\u9053\u5faa\u73af\u5185(\u4e0d\u5f53\u64cd\u4f5c)\u548c\u51cf\u901f\u671f\u95f4(\u8ffd\u5c3e)\u7684\u673a\u5236\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u5c06\u6a21\u5f0f\u53d1\u73b0\u4e0e\u6848\u4f8b\u7ea7\u89e3\u91ca\u8054\u7cfb\u8d77\u6765\uff0c\u652f\u6301\u573a\u5730\u7b5b\u9009\u3001\u5bf9\u7b56\u9009\u62e9\u548c\u5ba1\u8ba1\u5c31\u7eea\u62a5\u544a\uff0c\u4e3a\u516c\u5171\u5b89\u5168\u5206\u6790\u4e2d\u7684\u53ef\u7528XAI\u63d0\u4f9b\u4e86\u5b9e\u7528\u6a21\u677f\u3002"}}
{"id": "2509.12847", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12847", "abs": "https://arxiv.org/abs/2509.12847", "authors": ["Alireza Shooshtari", "Antonio Pepiciello", "Jos\u00e9 Luis Dom\u00ednguez-Garc\u00eda"], "title": "Grid-informed Sharing Coefficients in Renewable Energy Communities", "comment": null, "summary": "The role of energy communities in grid operations is highly dependent on the\nspatial distribution of their participants. In particular, when local energy\nproducers and consumers are concentrated in different feeders, economic\nincentives from energy communities have the potential to affect local grid\ncongestion. To address this challenge, we propose a feeder-aware allocation\nstrategy that reflects grid topology in energy sharing. This strategy\nprioritizes energy sharing within the same feeder, thus incentivizing local\ngeneration-demand balance and improving grid operation. Different sharing\ncoefficients are tested, such as equal, proportional, and rank-based, in both\nstatic and dynamic formulations. The proposed strategy is tested on data from a\nreal energy community, whose participants are assumed to be distributed across\nfour feeders. The analysis is carried out from the perspectives of the\ncommunity as a whole, individual feeders, and single participants. Simulation\nresults show that the feeder-aware strategy, in addition to promoting local\nenergy balance, leads to higher and more stable revenues for most participants.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u7535\u7f51\u62d3\u6251\u7684\u9988\u7ebf\u611f\u77e5\u5206\u914d\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5148\u5728\u540c\u4e00\u9988\u7ebf\u5185\u8fdb\u884c\u80fd\u6e90\u5171\u4eab\u6765\u6539\u5584\u7535\u7f51\u8fd0\u884c\u548c\u63d0\u5347\u53c2\u4e0e\u8005\u6536\u76ca", "motivation": "\u80fd\u6e90\u793e\u533a\u53c2\u4e0e\u8005\u7684\u7a7a\u95f4\u5206\u5e03\u5bf9\u7535\u7f51\u8fd0\u884c\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5f53\u672c\u5730\u80fd\u6e90\u751f\u4ea7\u8005\u548c\u6d88\u8d39\u8005\u5206\u5e03\u5728\u4e0d\u540c\u9988\u7ebf\u65f6\uff0c\u7ecf\u6d4e\u6fc0\u52b1\u53ef\u80fd\u5f71\u54cd\u5c40\u90e8\u7535\u7f51\u62e5\u5835", "method": "\u63d0\u51fa\u9988\u7ebf\u611f\u77e5\u5206\u914d\u7b56\u7565\uff0c\u6d4b\u8bd5\u4e86\u9759\u6001\u548c\u52a8\u6001\u5f62\u5f0f\u4e0b\u7684\u5747\u7b49\u3001\u6bd4\u4f8b\u548c\u57fa\u4e8e\u6392\u540d\u7684\u4e0d\u540c\u5171\u4eab\u7cfb\u6570\uff0c\u5e76\u5728\u771f\u5b9e\u80fd\u6e90\u793e\u533a\u6570\u636e\u4e0a\u8fdb\u884c\u4eff\u771f", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u9988\u7ebf\u611f\u77e5\u7b56\u7565\u4e0d\u4ec5\u4fc3\u8fdb\u4e86\u672c\u5730\u80fd\u6e90\u5e73\u8861\uff0c\u8fd8\u4e3a\u5927\u591a\u6570\u53c2\u4e0e\u8005\u5e26\u6765\u4e86\u66f4\u9ad8\u4e14\u66f4\u7a33\u5b9a\u7684\u6536\u76ca", "conclusion": "\u8003\u8651\u7535\u7f51\u62d3\u6251\u7684\u9988\u7ebf\u611f\u77e5\u80fd\u6e90\u5171\u4eab\u7b56\u7565\u80fd\u6709\u6548\u6539\u5584\u7535\u7f51\u8fd0\u884c\u5e76\u63d0\u5347\u80fd\u6e90\u793e\u533a\u53c2\u4e0e\u8005\u7684\u7ecf\u6d4e\u6548\u76ca"}}
{"id": "2509.12620", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12620", "abs": "https://arxiv.org/abs/2509.12620", "authors": ["Yikai Chen", "Zhi Zheng", "Jin Wang", "Bingye He", "Xiangyu Xu", "Jialu Zhang", "Huan Yu", "Guodong Lu"], "title": "PerchMobi^3: A Multi-Modal Robot with Power-Reuse Quad-Fan Mechanism for Air-Ground-Wall Locomotion", "comment": "7 pages, 8 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "Achieving seamless integration of aerial flight, ground driving, and wall\nclimbing within a single robotic platform remains a major challenge, as\nexisting designs often rely on additional adhesion actuators that increase\ncomplexity, reduce efficiency, and compromise reliability. To address these\nlimitations, we present PerchMobi^3, a quad-fan, negative-pressure,\nair-ground-wall robot that implements a propulsion-adhesion power-reuse\nmechanism. By repurposing four ducted fans to simultaneously provide aerial\nthrust and negative-pressure adhesion, and integrating them with four actively\ndriven wheels, PerchMobi^3 eliminates dedicated pumps while maintaining a\nlightweight and compact design. To the best of our knowledge, this is the first\nquad-fan prototype to demonstrate functional power reuse for multi-modal\nlocomotion. A modeling and control framework enables coordinated operation\nacross ground, wall, and aerial domains with fan-assisted transitions. The\nfeasibility of the design is validated through a comprehensive set of\nexperiments covering ground driving, payload-assisted wall climbing, aerial\nflight, and cross-mode transitions, demonstrating robust adaptability across\nlocomotion scenarios. These results highlight the potential of PerchMobi^3 as a\nnovel design paradigm for multi-modal robotic mobility, paving the way for\nfuture extensions toward autonomous and application-oriented deployment.", "AI": {"tldr": "PerchMobi^3\u662f\u4e00\u4e2a\u56db\u98ce\u6247\u8d1f\u538b\u5f0f\u7a7a\u5730\u5899\u4e09\u6816\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u63a8\u8fdb-\u5438\u9644\u529f\u7387\u590d\u7528\u673a\u5236\u5b9e\u73b0\u98de\u884c\u3001\u5730\u9762\u884c\u9a76\u548c\u5899\u9762\u722c\u884c\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u65e0\u9700\u4e13\u7528\u5438\u9644\u6cf5\u3002", "motivation": "\u73b0\u6709\u8bbe\u8ba1\u901a\u5e38\u4f9d\u8d56\u989d\u5916\u7684\u5438\u9644\u6267\u884c\u5668\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u3001\u964d\u4f4e\u4e86\u6548\u7387\u5e76\u635f\u5bb3\u4e86\u53ef\u9760\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u591a\u6a21\u6001\u8fd0\u52a8\u4e14\u7ed3\u6784\u7d27\u51d1\u7684\u673a\u5668\u4eba\u5e73\u53f0\u3002", "method": "\u91c7\u7528\u56db\u4e2a\u6db5\u9053\u98ce\u6247\u540c\u65f6\u63d0\u4f9b\u7a7a\u4e2d\u63a8\u529b\u548c\u8d1f\u538b\u5438\u9644\uff0c\u5e76\u4e0e\u56db\u4e2a\u4e3b\u52a8\u9a71\u52a8\u8f6e\u96c6\u6210\uff0c\u5b9e\u73b0\u63a8\u8fdb-\u5438\u9644\u529f\u7387\u590d\u7528\u673a\u5236\u3002\u5efa\u7acb\u4e86\u5efa\u6a21\u548c\u63a7\u5236\u6846\u67b6\uff0c\u652f\u6301\u5730\u9762\u3001\u5899\u9762\u548c\u7a7a\u4e2d\u57df\u7684\u534f\u8c03\u64cd\u4f5c\u3002", "result": "\u901a\u8fc7\u5168\u9762\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u7684\u53ef\u884c\u6027\uff0c\u5305\u62ec\u5730\u9762\u9a7e\u9a76\u3001\u8d1f\u8f7d\u8f85\u52a9\u5899\u9762\u722c\u884c\u3001\u7a7a\u4e2d\u98de\u884c\u548c\u8de8\u6a21\u5f0f\u8f6c\u6362\uff0c\u5c55\u793a\u4e86\u5728\u5404\u79cd\u8fd0\u52a8\u573a\u666f\u4e2d\u7684\u5f3a\u5927\u9002\u5e94\u6027\u3002", "conclusion": "PerchMobi^3\u4e3a\u591a\u6a21\u6001\u673a\u5668\u4eba\u79fb\u52a8\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u8bbe\u8ba1\u8303\u5f0f\uff0c\u4e3a\u672a\u6765\u81ea\u4e3b\u548c\u5e94\u7528\u5bfc\u5411\u7684\u90e8\u7f72\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2509.12541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12541", "abs": "https://arxiv.org/abs/2509.12541", "authors": ["Nicholas Pipitone", "Ghita Houir Alami", "Advaith Avadhanam", "Anton Kaminskyi", "Ashley Khoo"], "title": "zELO: ELO-inspired Training Method for Rerankers and Embedding Models", "comment": "13 pages, 9 sections, 17 figures and tables", "summary": "We introduce a novel training methodology named zELO, which optimizes\nretrieval performance via the analysis that ranking tasks are statically\nequivalent to a Thurstone model. Based on the zELO method, we use unsupervised\ndata in order train a suite of state-of-the-art open-weight reranker models:\nzerank-1 and zerank-1-small. These models achieve the highest retrieval scores\nin multiple domains, including finance, legal, code, and STEM, outperforming\nclosed-source proprietary rerankers on both NDCG@10 and Recall. These models\nalso demonstrate great versatility, maintaining their 0-shot performance on\nout-of-domain and private customer datasets. The training data included 112,000\nqueries and 100 documents per query, and was trained end-to-end from\nunannotated queries and documents in less than 10,000 H100-hours.", "AI": {"tldr": "zELO\u662f\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6392\u5e8f\u4efb\u52a1\u7b49\u4ef7\u4e8eThurstone\u6a21\u578b\u6765\u4f18\u5316\u68c0\u7d22\u6027\u80fd\u3002\u57fa\u4e8e\u6b64\u65b9\u6cd5\u8bad\u7ec3\u7684\u5f00\u6e90\u91cd\u6392\u5e8f\u6a21\u578bzerank-1\u7cfb\u5217\u5728\u591a\u4e2a\u9886\u57df\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u68c0\u7d22\u6548\u679c\uff0c\u8d85\u8d8a\u4e86\u95ed\u6e90\u5546\u4e1a\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u91cd\u6392\u5e8f\u6a21\u578b\u5f80\u5f80\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\u3002zELO\u65b9\u6cd5\u65e8\u5728\u5229\u7528\u65e0\u76d1\u7763\u6570\u636e\u8bad\u7ec3\u9ad8\u6027\u80fd\u91cd\u6392\u5e8f\u6a21\u578b\uff0c\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u540c\u65f6\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002", "method": "\u63d0\u51fazELO\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5c06\u6392\u5e8f\u4efb\u52a1\u5efa\u6a21\u4e3aThurstone\u6a21\u578b\u3002\u4f7f\u7528112,000\u4e2a\u67e5\u8be2\u548c\u6bcf\u4e2a\u67e5\u8be2100\u4e2a\u6587\u6863\u7684\u65e0\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u8bad\u7ec3\u65f6\u95f4\u5c11\u4e8e10,000 H100\u5c0f\u65f6\u3002", "result": "zerank-1\u548czerank-1-small\u6a21\u578b\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u3001\u4ee3\u7801\u3001STEM\u7b49\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u6700\u9ad8\u68c0\u7d22\u5206\u6570\uff0c\u5728NDCG@10\u548cRecall\u6307\u6807\u4e0a\u8d85\u8d8a\u95ed\u6e90\u5546\u4e1a\u91cd\u6392\u5e8f\u5668\uff0c\u5e76\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5728\u57df\u5916\u548c\u79c1\u6709\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4f18\u5f02\u6027\u80fd\u3002", "conclusion": "zELO\u65b9\u6cd5\u8bc1\u660e\u4e86\u4f7f\u7528\u65e0\u76d1\u7763\u6570\u636e\u8bad\u7ec3\u9ad8\u6027\u80fd\u91cd\u6392\u5e8f\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0czerank\u7cfb\u5217\u6a21\u578b\u5728\u591a\u4e2a\u9886\u57df\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u4e3a\u5f00\u6e90\u68c0\u7d22\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.12674", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12674", "abs": "https://arxiv.org/abs/2509.12674", "authors": ["Anna Johansson", "Daniel Lindmark", "Viktor Wiberg", "Martin Servin"], "title": "Safety filtering of robotic manipulation under environment uncertainty: a computational approach", "comment": "8 pages, 8 figures", "summary": "Robotic manipulation in dynamic and unstructured environments requires safety\nmechanisms that exploit what is known and what is uncertain about the world.\nExisting safety filters often assume full observability, limiting their\napplicability in real-world tasks. We propose a physics-based safety filtering\nscheme that leverages high-fidelity simulation to assess control policies under\nuncertainty in world parameters. The method combines dense rollout with nominal\nparameters and parallelizable sparse re-evaluation at critical\nstate-transitions, quantified through generalized factors of safety for stable\ngrasping and actuator limits, and targeted uncertainty reduction through\nprobing actions. We demonstrate the approach in a simulated bimanual\nmanipulation task with uncertain object mass and friction, showing that unsafe\ntrajectories can be identified and filtered efficiently. Our results highlight\nphysics-based sparse safety evaluation as a scalable strategy for safe robotic\nmanipulation under uncertainty.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7269\u7406\u4eff\u771f\u7684\u5b89\u5168\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bc6\u96c6\u91c7\u6837\u548c\u7a00\u758f\u91cd\u8bc4\u4f30\u6765\u5904\u7406\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u786e\u4fdd\u5728\u672a\u77e5\u7269\u4f53\u53c2\u6570\u4e0b\u7684\u5b89\u5168\u64cd\u4f5c", "motivation": "\u73b0\u6709\u5b89\u5168\u8fc7\u6ee4\u5668\u901a\u5e38\u5047\u8bbe\u5b8c\u5168\u53ef\u89c2\u6d4b\u6027\uff0c\u9650\u5236\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u4e16\u754c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u5b89\u5168\u673a\u5236", "method": "\u7ed3\u5408\u5bc6\u96c6\u53c2\u6570\u91c7\u6837\u548c\u5e76\u884c\u7a00\u758f\u91cd\u8bc4\u4f30\uff0c\u4f7f\u7528\u5e7f\u4e49\u5b89\u5168\u56e0\u5b50\u91cf\u5316\u7a33\u5b9a\u6293\u53d6\u548c\u6267\u884c\u5668\u9650\u5236\uff0c\u901a\u8fc7\u63a2\u6d4b\u52a8\u4f5c\u5b9e\u73b0\u9488\u5bf9\u6027\u4e0d\u786e\u5b9a\u6027\u964d\u4f4e", "result": "\u5728\u6a21\u62df\u53cc\u624b\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u8fc7\u6ee4\u4e0d\u5b89\u5168\u8f68\u8ff9\uff0c\u5c55\u793a\u4e86\u5728\u7269\u4f53\u8d28\u91cf\u548c\u6469\u64e6\u7cfb\u6570\u4e0d\u786e\u5b9a\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6027", "conclusion": "\u57fa\u4e8e\u7269\u7406\u7684\u7a00\u758f\u5b89\u5168\u8bc4\u4f30\u662f\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u4e0b\u5b89\u5168\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u53ef\u6269\u5c55\u7b56\u7565"}}
{"id": "2509.12543", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12543", "abs": "https://arxiv.org/abs/2509.12543", "authors": ["Harshit Rajgarhia", "Shivali Dalmia", "Mengyang Zhao", "Mukherji Abhishek", "Kiran Ganesh"], "title": "Human + AI for Accelerating Ad Localization Evaluation", "comment": null, "summary": "Adapting advertisements for multilingual audiences requires more than simple\ntext translation; it demands preservation of visual consistency, spatial\nalignment, and stylistic integrity across diverse languages and formats. We\nintroduce a structured framework that combines automated components with human\noversight to address the complexities of advertisement localization. To the\nbest of our knowledge, this is the first work to integrate scene text\ndetection, inpainting, machine translation (MT), and text reimposition\nspecifically for accelerating ad localization evaluation workflows. Qualitative\nresults across six locales demonstrate that our approach produces semantically\naccurate and visually coherent localized advertisements, suitable for\ndeployment in real-world workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u81ea\u52a8\u5316\u7ec4\u4ef6\u548c\u4eba\u5de5\u76d1\u7763\u7684\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5e7f\u544a\u672c\u5730\u5316\u7684\u590d\u6742\u6027\uff0c\u6574\u5408\u4e86\u573a\u666f\u6587\u672c\u68c0\u6d4b\u3001\u4fee\u590d\u3001\u673a\u5668\u7ffb\u8bd1\u548c\u6587\u672c\u91cd\u6392\u6280\u672f\u3002", "motivation": "\u591a\u8bed\u8a00\u5e7f\u544a\u9002\u914d\u9700\u8981\u4fdd\u6301\u89c6\u89c9\u4e00\u81f4\u6027\u3001\u7a7a\u95f4\u5bf9\u9f50\u548c\u98ce\u683c\u5b8c\u6574\u6027\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u7b80\u5355\u7684\u6587\u672c\u7ffb\u8bd1\uff0c\u9700\u8981\u89e3\u51b3\u5e7f\u544a\u672c\u5730\u5316\u7684\u590d\u6742\u6311\u6218\u3002", "method": "\u7ed3\u5408\u573a\u666f\u6587\u672c\u68c0\u6d4b\u3001\u4fee\u590d\u3001\u673a\u5668\u7ffb\u8bd1\u548c\u6587\u672c\u91cd\u6392\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u5e76\u52a0\u5165\u4eba\u5de5\u76d1\u7763\uff0c\u5f62\u6210\u7ed3\u6784\u5316\u6846\u67b6\u6765\u52a0\u901f\u5e7f\u544a\u672c\u5730\u5316\u8bc4\u4f30\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u516d\u4e2a\u5730\u533a\u7684\u5b9a\u6027\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u8bed\u4e49\u51c6\u786e\u4e14\u89c6\u89c9\u4e00\u81f4\u7684\u672c\u5730\u5316\u5e7f\u544a\uff0c\u9002\u5408\u5728\u5b9e\u9645\u5de5\u4f5c\u6d41\u4e2d\u90e8\u7f72\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u52a0\u901f\u5e7f\u544a\u672c\u5730\u5316\u8bc4\u4f30\u5de5\u4f5c\u6d41\u800c\u6574\u5408\u591a\u9879\u6280\u672f\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u8bed\u8a00\u5e7f\u544a\u9002\u914d\u7684\u590d\u6742\u9700\u6c42\u3002"}}
{"id": "2509.12944", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.12944", "abs": "https://arxiv.org/abs/2509.12944", "authors": ["Felix Wieberneit", "Emanuele Crisostomi", "Wynita Griggs", "Robert Shorten"], "title": "Momentum-Based Access and Speed Control for Improved Safety in Heterogeneous Road Networks", "comment": null, "summary": "The increasing variety of means of transportation, including light vehicles\nlike e-scooters and e-bikes, together with the increasing weight of\nconventional vehicles due to electrification and consumer preferences for SUVs,\nare raising serious concerns regarding the safety of road networks. In this\npaper we design a two-level control algorithm to improve the safety of\nheterogeneous networks: first, an access control strategy decreases the\nheterogeneity of the network depending on actual traffic conditions; then, a\nspeed control strategy mitigates the probability of serious injuries in\npotential collisions. Both control strategies are designed based on momentum\nconsiderations, as this is regarded as the most influential variable to assess\ninjury risk. The road network mobility simulator SUMO is adopted to implement\nand validate our proposed control strategies.", "AI": {"tldr": "\u8bbe\u8ba1\u4e86\u4e24\u7ea7\u63a7\u5236\u7b97\u6cd5\u6765\u63d0\u9ad8\u5f02\u6784\u9053\u8def\u7f51\u7edc\u7684\u5b89\u5168\u6027\uff1a\u63a5\u5165\u63a7\u5236\u7b56\u7565\u964d\u4f4e\u7f51\u7edc\u5f02\u8d28\u6027\uff0c\u901f\u5ea6\u63a7\u5236\u7b56\u7565\u51cf\u8f7b\u6f5c\u5728\u78b0\u649e\u4e2d\u7684\u91cd\u4f24\u6982\u7387\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6ed1\u677f\u8f66\u3001\u7535\u52a8\u81ea\u884c\u8f66\u7b49\u8f7b\u578b\u4ea4\u901a\u5de5\u5177\u7684\u666e\u53ca\uff0c\u4ee5\u53ca\u4f20\u7edf\u8f66\u8f86\u56e0\u7535\u52a8\u5316\u548cSUV\u504f\u597d\u800c\u91cd\u91cf\u589e\u52a0\uff0c\u9053\u8def\u7f51\u7edc\u5b89\u5168\u6027\u9762\u4e34\u4e25\u91cd\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u52a8\u91cf\u8003\u8651\u8bbe\u8ba1\u4e24\u7ea7\u63a7\u5236\u7b97\u6cd5\uff1a1\uff09\u6839\u636e\u5b9e\u9645\u4ea4\u901a\u72b6\u51b5\u7684\u63a5\u5165\u63a7\u5236\u7b56\u7565\u964d\u4f4e\u7f51\u7edc\u5f02\u8d28\u6027\uff1b2\uff09\u901f\u5ea6\u63a7\u5236\u7b56\u7565\u51cf\u8f7b\u78b0\u649e\u4f24\u5bb3\u6982\u7387\u3002\u4f7f\u7528SUMO\u9053\u8def\u7f51\u7edc\u79fb\u52a8\u6a21\u62df\u5668\u8fdb\u884c\u5b9e\u73b0\u548c\u9a8c\u8bc1\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u6709\u6548\u7684\u63a7\u5236\u7b56\u7565\uff0c\u4f46\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u9700\u8981\u67e5\u770b\u5b8c\u6574\u8bba\u6587\u3002", "conclusion": "\u57fa\u4e8e\u52a8\u91cf\u7684\u4e24\u7ea7\u63a7\u5236\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u5f02\u6784\u9053\u8def\u7f51\u7edc\u7684\u5b89\u5168\u6027\uff0c\u4e3a\u5e94\u5bf9\u65b0\u578b\u4ea4\u901a\u5de5\u5177\u548c\u91cd\u578b\u8f66\u8f86\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12702", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12702", "abs": "https://arxiv.org/abs/2509.12702", "authors": ["Hongrui Zhao", "Xunlan Zhou", "Boris Ivanovic", "Negar Mehr"], "title": "UDON: Uncertainty-weighted Distributed Optimization for Multi-Robot Neural Implicit Mapping under Extreme Communication Constraints", "comment": null, "summary": "Multi-robot mapping with neural implicit representations enables the compact\nreconstruction of complex environments. However, it demands robustness against\ncommunication challenges like packet loss and limited bandwidth. While prior\nworks have introduced various mechanisms to mitigate communication disruptions,\nperformance degradation still occurs under extremely low communication success\nrates. This paper presents UDON, a real-time multi-agent neural implicit\nmapping framework that introduces a novel uncertainty-weighted distributed\noptimization to achieve high-quality mapping under severe communication\ndeterioration. The uncertainty weighting prioritizes more reliable portions of\nthe map, while the distributed optimization isolates and penalizes mapping\ndisagreement between individual pairs of communicating agents. We conduct\nextensive experiments on standard benchmark datasets and real-world robot\nhardware. We demonstrate that UDON significantly outperforms existing\nbaselines, maintaining high-fidelity reconstructions and consistent scene\nrepresentations even under extreme communication degradation (as low as 1%\nsuccess rate).", "AI": {"tldr": "UDON\u662f\u4e00\u4e2a\u5b9e\u65f6\u591a\u667a\u80fd\u4f53\u795e\u7ecf\u9690\u5f0f\u5efa\u56fe\u6846\u67b6\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u5206\u5e03\u5f0f\u4f18\u5316\uff0c\u5728\u6781\u4f4e\u901a\u4fe1\u6210\u529f\u7387\uff08\u4f4e\u81f31%\uff09\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u8d28\u91cf\u5730\u56fe\u91cd\u5efa", "motivation": "\u591a\u673a\u5668\u4eba\u795e\u7ecf\u9690\u5f0f\u5efa\u56fe\u9700\u8981\u5e94\u5bf9\u901a\u4fe1\u6311\u6218\uff08\u5982\u4e22\u5305\u548c\u5e26\u5bbd\u9650\u5236\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6781\u4f4e\u901a\u4fe1\u6210\u529f\u7387\u4e0b\u6027\u80fd\u4ecd\u4f1a\u4e0b\u964d", "method": "\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u5206\u5e03\u5f0f\u4f18\u5316\uff1a\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u4f18\u5148\u5904\u7406\u5730\u56fe\u4e2d\u66f4\u53ef\u9760\u7684\u90e8\u5206\uff0c\u5206\u5e03\u5f0f\u4f18\u5316\u9694\u79bb\u5e76\u60e9\u7f5a\u901a\u4fe1\u667a\u80fd\u4f53\u5bf9\u4e4b\u95f4\u7684\u5efa\u56fe\u5206\u6b67", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u548c\u771f\u5b9e\u673a\u5668\u4eba\u786c\u4ef6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cUDON\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u6781\u7aef\u901a\u4fe1\u9000\u5316\u6761\u4ef6\u4e0b\u4e5f\u80fd\u4fdd\u6301\u9ad8\u4fdd\u771f\u91cd\u5efa\u548c\u4e00\u81f4\u7684\u573a\u666f\u8868\u793a", "conclusion": "UDON\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u5206\u5e03\u5f0f\u4f18\u5316\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u795e\u7ecf\u9690\u5f0f\u5efa\u56fe\u5728\u4e25\u91cd\u901a\u4fe1\u6076\u5316\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u95ee\u9898"}}
{"id": "2509.12589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12589", "abs": "https://arxiv.org/abs/2509.12589", "authors": ["Garima Agrawal", "Riccardo De Maria", "Kiran Davuluri", "Daniele Spera", "Charlie Read", "Cosimo Spera", "Jack Garrett", "Don Miller"], "title": "Redefining CX with Agentic AI: Minerva CQ Case Study", "comment": null, "summary": "Despite advances in AI for contact centers, customer experience (CX)\ncontinues to suffer from high average handling time (AHT), low first-call\nresolution, and poor customer satisfaction (CSAT). A key driver is the\ncognitive load on agents, who must navigate fragmented systems, troubleshoot\nmanually, and frequently place customers on hold. Existing AI-powered\nagent-assist tools are often reactive driven by static rules, simple prompting,\nor retrieval-augmented generation (RAG) without deeper contextual reasoning. We\nintroduce Agentic AI goal-driven, autonomous, tool-using systems that\nproactively support agents in real time. Unlike conventional approaches,\nAgentic AI identifies customer intent, triggers modular workflows, maintains\nevolving context, and adapts dynamically to conversation state. This paper\npresents a case study of Minerva CQ, a real-time Agent Assist product deployed\nin voice-based customer support. Minerva CQ integrates real-time transcription,\nintent and sentiment detection, entity recognition, contextual retrieval,\ndynamic customer profiling, and partial conversational summaries enabling\nproactive workflows and continuous context-building. Deployed in live\nproduction, Minerva CQ acts as an AI co-pilot, delivering measurable\nimprovements in agent efficiency and customer experience across multiple\ndeployments.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aMinerva CQ\u7684\u5b9e\u65f6Agentic AI\u52a9\u624b\uff0c\u901a\u8fc7\u4e3b\u52a8\u5f0f\u5de5\u4f5c\u6d41\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5ba2\u670d\u4e2d\u5fc3\u7684\u5904\u7406\u6548\u7387\u548c\u5ba2\u6237\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u5ba2\u670d\u4e2d\u5fc3\u5b58\u5728\u5904\u7406\u65f6\u95f4\u957f\u3001\u9996\u6b21\u89e3\u51b3\u7387\u4f4e\u3001\u5ba2\u6237\u6ee1\u610f\u5ea6\u5dee\u7b49\u95ee\u9898\uff0c\u73b0\u6709AI\u8f85\u52a9\u5de5\u5177\u591a\u4e3a\u88ab\u52a8\u54cd\u5e94\uff0c\u7f3a\u4e4f\u6df1\u5ea6\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528Agentic AI\u67b6\u6784\uff0c\u96c6\u6210\u5b9e\u65f6\u8f6c\u5f55\u3001\u610f\u56fe\u8bc6\u522b\u3001\u60c5\u611f\u68c0\u6d4b\u3001\u5b9e\u4f53\u8bc6\u522b\u3001\u4e0a\u4e0b\u6587\u68c0\u7d22\u7b49\u529f\u80fd\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u5de5\u4f5c\u6d41\u548c\u52a8\u6001\u81ea\u9002\u5e94\u5bf9\u8bdd\u72b6\u6001\u3002", "result": "Minerva CQ\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u540e\uff0c\u4f5c\u4e3aAI\u526f\u9a7e\u9a76\u663e\u8457\u63d0\u5347\u4e86\u5ba2\u670d\u6548\u7387\u548c\u5ba2\u6237\u4f53\u9a8c\uff0c\u5728\u591a\u500b\u90e8\u7f72\u4e2d\u53d6\u5f97\u53ef\u8861\u91cf\u7684\u6539\u8fdb\u3002", "conclusion": "Agentic AI\u65b9\u6cd5\u901a\u8fc7\u4e3b\u52a8\u5f0f\u3001\u76ee\u6807\u9a71\u52a8\u7684\u81ea\u4e3b\u7cfb\u7edf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u5ba2\u670d\u4e2d\u5fc3\u7684\u8ba4\u77e5\u8d1f\u8f7d\u95ee\u9898\uff0c\u4e3a\u5b9e\u65f6\u5ba2\u670d\u652f\u6301\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13166", "categories": ["eess.SY", "cs.LG", "cs.SY", "eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.13166", "abs": "https://arxiv.org/abs/2509.13166", "authors": ["Filippo Fabiani", "Andrea Simonetto"], "title": "Concentration inequalities for semidefinite least squares based on data", "comment": null, "summary": "We study data-driven least squares (LS) problems with semidefinite (SD)\nconstraints and derive finite-sample guarantees on the spectrum of their\noptimal solutions when these constraints are relaxed. In particular, we provide\na high confidence bound allowing one to solve a simpler program in place of the\nfull SDLS problem, while ensuring that the eigenvalues of the resulting\nsolution are $\\varepsilon$-close of those enforced by the SD constraints. The\ndeveloped certificate, which consistently shrinks as the number of data\nincreases, turns out to be easy-to-compute, distribution-free, and only\nrequires independent and identically distributed samples. Moreover, when the\nSDLS is used to learn an unknown quadratic function, we establish bounds on the\nerror between a gradient descent iterate minimizing the surrogate cost obtained\nwith no SD constraints and the true minimizer.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u534a\u6b63\u5b9a\u7ea6\u675f\u7684\u6570\u636e\u9a71\u52a8\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u5f53\u7ea6\u675f\u677e\u5f1b\u65f6\u4e3a\u5176\u6700\u4f18\u89e3\u8c31\u63d0\u4f9b\u6709\u9650\u6837\u672c\u4fdd\u8bc1\uff0c\u5f00\u53d1\u4e86\u6613\u4e8e\u8ba1\u7b97\u3001\u5206\u5e03\u65e0\u5173\u7684\u8bc1\u4e66\u6765\u7b80\u5316\u6c42\u89e3\u8fc7\u7a0b", "motivation": "\u89e3\u51b3\u5e26\u534a\u6b63\u5b9a\u7ea6\u675f\u7684\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u8ba1\u7b97\u590d\u6742\uff0c\u9700\u8981\u5f00\u53d1\u7b80\u5316\u65b9\u6cd5\u5728\u4fdd\u8bc1\u89e3\u8d28\u91cf\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5", "method": "\u63a8\u5bfc\u6709\u9650\u6837\u672c\u4fdd\u8bc1\uff0c\u63d0\u4f9b\u9ad8\u7f6e\u4fe1\u5ea6\u8fb9\u754c\uff0c\u5141\u8bb8\u7528\u66f4\u7b80\u5355\u7a0b\u5e8f\u66ff\u4ee3\u5b8c\u6574\u534a\u6b63\u5b9a\u7ea6\u675f\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u786e\u4fdd\u89e3\u7684\u7279\u5f81\u503c\u63a5\u8fd1\u7ea6\u675f\u8981\u6c42", "result": "\u5f00\u53d1\u51fa\u968f\u6570\u636e\u91cf\u589e\u52a0\u800c\u7f29\u5c0f\u7684\u6613\u8ba1\u7b97\u8bc1\u4e66\uff0c\u4ec5\u9700\u72ec\u7acb\u540c\u5206\u5e03\u6837\u672c\uff0c\u5728\u7528\u4e8e\u5b66\u4e60\u672a\u77e5\u4e8c\u6b21\u51fd\u6570\u65f6\u5efa\u7acb\u4e86\u68af\u5ea6\u4e0b\u964d\u8fed\u4ee3\u4e0e\u771f\u5b9e\u6700\u5c0f\u5316\u5668\u4e4b\u95f4\u7684\u8bef\u5dee\u754c", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5e26\u534a\u6b63\u5b9a\u7ea6\u675f\u7684\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b80\u5316\u6c42\u89e3\u65b9\u6848\uff0c\u5177\u6709\u8ba1\u7b97\u7b80\u4fbf\u3001\u5206\u5e03\u65e0\u5173\u7684\u4f18\u70b9\uff0c\u9002\u7528\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u4f18\u5316\u95ee\u9898"}}
{"id": "2509.12714", "categories": ["cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12714", "abs": "https://arxiv.org/abs/2509.12714", "authors": ["Kit-Wa Sou", "Junhao Gong", "Shoujie Li", "Chuqiao Lyu", "Ziwu Song", "Shilong Mu", "Wenbo Ding"], "title": "Moir\u00e9Tac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using Moir\u00e9 Pattern Amplification", "comment": null, "summary": "Visuotactile sensors typically employ sparse marker arrays that limit spatial\nresolution and lack clear analytical force-to-image relationships. To solve\nthis problem, we present \\textbf{Moir\\'eTac}, a dual-mode sensor that generates\ndense interference patterns via overlapping micro-gratings within a transparent\narchitecture. When two gratings overlap with misalignment, they create moir\\'e\npatterns that amplify microscopic deformations. The design preserves optical\nclarity for vision tasks while producing continuous moir\\'e fields for tactile\nsensing, enabling simultaneous 6-axis force/torque measurement, contact\nlocalization, and visual perception. We combine physics-based features\n(brightness, phase gradient, orientation, and period) from moir\\'e patterns\nwith deep spatial features. These are mapped to 6-axis force/torque\nmeasurements, enabling interpretable regression through end-to-end learning.\nExperimental results demonstrate three capabilities: force/torque measurement\nwith R^2 > 0.98 across tested axes; sensitivity tuning through geometric\nparameters (threefold gain adjustment); and vision functionality for object\nclassification despite moir\\'e overlay. Finally, we integrate the sensor into a\nrobotic arm for cap removal with coordinated force and torque control,\nvalidating its potential for dexterous manipulation.", "AI": {"tldr": "Moir\u00e9Tac\u662f\u4e00\u79cd\u65b0\u578b\u89c6\u89c9\u89e6\u89c9\u4f20\u611f\u5668\uff0c\u901a\u8fc7\u5fae\u5149\u6805\u91cd\u53e0\u4ea7\u751f\u5bc6\u96c6\u7684\u83ab\u5c14\u6761\u7eb9\u6a21\u5f0f\uff0c\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u89e6\u89c9\u611f\u77e5\u548c\u89c6\u89c9\u529f\u80fd\u7684\u540c\u65f6\u96c6\u6210", "motivation": "\u89e3\u51b3\u4f20\u7edf\u89c6\u89c9\u89e6\u89c9\u4f20\u611f\u5668\u7a7a\u95f4\u5206\u8fa8\u7387\u4f4e\u3001\u7f3a\u4e4f\u6e05\u6670\u529b-\u56fe\u50cf\u5206\u6790\u5173\u7cfb\u7684\u95ee\u9898", "method": "\u91c7\u7528\u900f\u660e\u67b6\u6784\u4e2d\u7684\u91cd\u53e0\u5fae\u5149\u6805\u4ea7\u751f\u83ab\u5c14\u6761\u7eb9\u6a21\u5f0f\uff0c\u7ed3\u5408\u7269\u7406\u7279\u5f81\uff08\u4eae\u5ea6\u3001\u76f8\u4f4d\u68af\u5ea6\u3001\u65b9\u5411\u3001\u5468\u671f\uff09\u548c\u6df1\u5ea6\u7a7a\u95f4\u7279\u5f81\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u5b66\u4e60\u5b9e\u73b06\u8f74\u529b/\u626d\u77e9\u6d4b\u91cf", "result": "\u529b/\u626d\u77e9\u6d4b\u91cfR\u00b2 > 0.98\uff0c\u901a\u8fc7\u51e0\u4f55\u53c2\u6570\u5b9e\u73b0\u4e09\u500d\u589e\u76ca\u8c03\u8282\u7684\u7075\u654f\u5ea6\u8c03\u8c10\uff0c\u5177\u5907\u7269\u4f53\u5206\u7c7b\u7684\u89c6\u89c9\u529f\u80fd\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u673a\u5668\u4eba\u624b\u81c2\u7684\u74f6\u76d6\u79fb\u9664\u4efb\u52a1", "conclusion": "Moir\u00e9Tac\u4f20\u611f\u5668\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u529b/\u626d\u77e9\u6d4b\u91cf\u3001\u63a5\u89e6\u5b9a\u4f4d\u548c\u89c6\u89c9\u611f\u77e5\u7684\u96c6\u6210\uff0c\u4e3a\u7075\u5de7\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u591a\u6a21\u6001\u4f20\u611f\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.12592", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.12592", "abs": "https://arxiv.org/abs/2509.12592", "authors": ["Aaron Baughman", "Gozde Akay", "Eduardo Morales", "Rahul Agarwal", "Preetika Srivastava"], "title": "Match Chat: Real Time Generative AI and Generative Computing for Tennis", "comment": "12 pages, 5 Figures, 4 Tables", "summary": "We present Match Chat, a real-time, agent-driven assistant designed to\nenhance the tennis fan experience by delivering instant, accurate responses to\nmatch-related queries. Match Chat integrates Generative Artificial Intelligence\n(GenAI) with Generative Computing (GenComp) techniques to synthesize key\ninsights during live tennis singles matches. The system debuted at the 2025\nWimbledon Championships and the 2025 US Open, where it provided about 1 million\nusers with seamless access to streaming and static data through natural\nlanguage queries. The architecture is grounded in an Agent-Oriented\nArchitecture (AOA) combining rule engines, predictive models, and agents to\npre-process and optimize user queries before passing them to GenAI components.\nThe Match Chat system had an answer accuracy of 92.83% with an average response\ntime of 6.25 seconds under loads of up to 120 requests per second (RPS). Over\n96.08% of all queries were guided using interactive prompt design, contributing\nto a user experience that prioritized clarity, responsiveness, and minimal\neffort. The system was designed to mask architectural complexity, offering a\nfrictionless and intuitive interface that required no onboarding or technical\nfamiliarity. Across both Grand Slam deployments, Match Chat maintained 100%\nuptime and supported nearly 1 million unique users, underscoring the\nscalability and reliability of the platform. This work introduces key design\npatterns for real-time, consumer-facing AI systems that emphasize speed,\nprecision, and usability that highlights a practical path for deploying\nperformant agentic systems in dynamic environments.", "AI": {"tldr": "Match Chat\u662f\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u4ee3\u7406\u7684\u5b9e\u65f6\u7f51\u7403\u6bd4\u8d5b\u52a9\u624b\uff0c\u7ed3\u5408GenAI\u548cGenComp\u6280\u672f\uff0c\u5728\u6e29\u7f51\u548c\u7f8e\u7f51\u7b49\u5927\u578b\u8d5b\u4e8b\u4e2d\u4e3a\u8fd1\u767e\u4e07\u7528\u6237\u63d0\u4f9b\u51c6\u786e\u5feb\u901f\u7684\u6bd4\u8d5b\u76f8\u5173\u95ee\u7b54\u670d\u52a1\u3002", "motivation": "\u63d0\u5347\u7f51\u7403\u7403\u8ff7\u7684\u89c2\u8d5b\u4f53\u9a8c\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u63d0\u4f9b\u5373\u65f6\u51c6\u786e\u7684\u6bd4\u8d5b\u4fe1\u606f\uff0c\u89e3\u51b3\u4f20\u7edf\u6570\u636e\u67e5\u8be2\u65b9\u5f0f\u590d\u6742\u4f4e\u6548\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9762\u5411\u4ee3\u7406\u67b6\u6784(AOA)\uff0c\u7ed3\u5408\u89c4\u5219\u5f15\u64ce\u3001\u9884\u6d4b\u6a21\u578b\u548c\u667a\u80fd\u4ee3\u7406\u9884\u5904\u7406\u7528\u6237\u67e5\u8be2\uff0c\u518d\u4f20\u9012\u7ed9GenAI\u7ec4\u4ef6\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u63d0\u793a\u8bbe\u8ba1\u4f18\u5316\u7528\u6237\u4f53\u9a8c\u3002", "result": "\u7cfb\u7edf\u51c6\u786e\u7387\u8fbe\u523092.83%\uff0c\u5e73\u5747\u54cd\u5e94\u65f6\u95f46.25\u79d2\uff0c\u652f\u6301120 RPS\u8d1f\u8f7d\uff0c96.08%\u67e5\u8be2\u4f7f\u7528\u4ea4\u4e92\u63d0\u793a\u5f15\u5bfc\uff0c100%\u6b63\u5e38\u8fd0\u884c\u65f6\u95f4\uff0c\u670d\u52a1\u8fd1\u767e\u4e07\u7528\u6237\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86\u5728\u52a8\u6001\u73af\u5883\u4e2d\u90e8\u7f72\u9ad8\u6027\u80fd\u4ee3\u7406\u7cfb\u7edf\u7684\u53ef\u884c\u8def\u5f84\uff0c\u4e3a\u5b9e\u65f6\u9762\u5411\u6d88\u8d39\u8005\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5f3a\u8c03\u901f\u5ea6\u3001\u7cbe\u5ea6\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2509.13257", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13257", "abs": "https://arxiv.org/abs/2509.13257", "authors": ["Sriram S. K. S. Narayanan", "Sajad Ahmadi", "Javad Mohammadpour Velni", "Umesh Vaidya"], "title": "Safety Critical Model Predictive Control Using Discrete-Time Control Density Functions", "comment": null, "summary": "This paper presents MPC-CDF, a new approach integrating control density\nfunctions (CDFs) within a model predictive control (MPC) framework to ensure\nsafety-critical control in nonlinear dynamical systems. By using the dual\nformulation of the navigation problem, we incorporate CDFs into the MPC\nframework, ensuring both convergence and safety in a discrete-time setting.\nThese density functions are endowed with a physical interpretation, where the\nassociated measure signifies the occupancy of system trajectories. Leveraging\nthis occupancy-based perspective, we synthesize safety-critical controllers\nusing the proposed MPC-CDF framework. We illustrate the safety properties of\nthis framework using a unicycle model and compare it with a control barrier\nfunction-based method. The efficacy of this approach is demonstrated in the\nautonomous safe navigation of an underwater vehicle, which avoids complex and\narbitrary obstacles while achieving the desired level of safety.", "AI": {"tldr": "MPC-CDF\u662f\u4e00\u79cd\u5c06\u63a7\u5236\u5bc6\u5ea6\u51fd\u6570(CDFs)\u96c6\u6210\u5230\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u6846\u67b6\u4e2d\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u786e\u4fdd\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u5b89\u5168\u5173\u952e\u63a7\u5236\uff0c\u901a\u8fc7\u5360\u7528\u5ea6\u91cf\u89c6\u89d2\u5b9e\u73b0\u5b89\u5168\u5bfc\u822a\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u4e2d\u5b89\u5168\u5173\u952e\u63a7\u5236\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u786e\u4fdd\u6536\u655b\u6027\u548c\u5b89\u5168\u6027\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u590d\u6742\u969c\u788d\u7269\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u91c7\u7528\u5bfc\u822a\u95ee\u9898\u7684\u5bf9\u5076\u516c\u5f0f\uff0c\u5c06\u63a7\u5236\u5bc6\u5ea6\u51fd\u6570(CDFs)\u6574\u5408\u5230MPC\u6846\u67b6\u4e2d\uff0c\u5229\u7528\u57fa\u4e8e\u5360\u7528\u5ea6\u91cf\u7684\u7269\u7406\u89e3\u91ca\u6765\u5408\u6210\u5b89\u5168\u5173\u952e\u63a7\u5236\u5668\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u72ec\u8f6e\u8f66\u6a21\u578b\u4e0a\u5c55\u793a\u4e86\u5b89\u5168\u7279\u6027\uff0c\u5e76\u4e0e\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5728\u6c34\u4e0b\u81ea\u4e3b\u5bfc\u822a\u4e2d\u6210\u529f\u907f\u5f00\u4e86\u590d\u6742\u4efb\u610f\u969c\u788d\u7269\u3002", "conclusion": "MPC-CDF\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b89\u5168\u5173\u952e\u63a7\u5236\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u79bb\u6563\u65f6\u95f4\u8bbe\u7f6e\u4e0b\u786e\u4fdd\u7cfb\u7edf\u8f68\u8ff9\u7684\u5b89\u5168\u6027\u548c\u6536\u655b\u6027\uff0c\u9002\u7528\u4e8e\u590d\u6742\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u5bfc\u822a\u4efb\u52a1\u3002"}}
{"id": "2509.12723", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12723", "abs": "https://arxiv.org/abs/2509.12723", "authors": ["Kai Zhang", "Eric Lucet", "Julien Alexandre Dit Sandretto", "Shoubin Chen", "David Filait"], "title": "NAMOUnc: Navigation Among Movable Obstacles with Decision Making on Uncertainty Interval", "comment": "11 pages, ICINCO2025", "summary": "Navigation among movable obstacles (NAMO) is a critical task in robotics,\noften challenged by real-world uncertainties such as observation noise, model\napproximations, action failures, and partial observability. Existing solutions\nfrequently assume ideal conditions, leading to suboptimal or risky decisions.\nThis paper introduces NAMOUnc, a novel framework designed to address these\nuncertainties by integrating them into the decision-making process. We first\nestimate them and compare the corresponding time cost intervals for removing\nand bypassing obstacles, optimizing both the success rate and time efficiency,\nensuring safer and more efficient navigation. We validate our method through\nextensive simulations and real-world experiments, demonstrating significant\nimprovements over existing NAMO frameworks. More details can be found in our\nwebsite: https://kai-zhang-er.github.io/namo-uncertainty/", "AI": {"tldr": "NAMOUnc\u6846\u67b6\u901a\u8fc7\u5c06\u4e0d\u786e\u5b9a\u6027\u6574\u5408\u5230\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8\u969c\u788d\u7269\u5bfc\u822a\u4e2d\u7684\u89c2\u6d4b\u566a\u58f0\u3001\u6a21\u578b\u8fd1\u4f3c\u3001\u52a8\u4f5c\u5931\u8d25\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7b49\u73b0\u5b9e\u4e0d\u786e\u5b9a\u6027\u6311\u6218\u3002", "motivation": "\u73b0\u6709NAMO\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u5047\u8bbe\u7406\u60f3\u6761\u4ef6\uff0c\u5bfc\u81f4\u6b21\u4f18\u6216\u98ce\u9669\u51b3\u7b56\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5404\u79cd\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u9996\u5148\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u7136\u540e\u6bd4\u8f83\u79fb\u9664\u548c\u7ed5\u8fc7\u969c\u788d\u7269\u7684\u76f8\u5e94\u65f6\u95f4\u6210\u672c\u533a\u95f4\uff0c\u540c\u65f6\u4f18\u5316\u6210\u529f\u7387\u548c\u65f6\u95f4\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u73b0\u6709NAMO\u6846\u67b6\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "NAMOUnc\u6846\u67b6\u80fd\u591f\u786e\u4fdd\u66f4\u5b89\u5168\u3001\u66f4\u9ad8\u6548\u7684\u5bfc\u822a\uff0c\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u56e0\u7d20\u3002"}}
{"id": "2509.12602", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.12602", "abs": "https://arxiv.org/abs/2509.12602", "authors": ["Minyu Chen", "Guoqiang Li"], "title": "DaSAThco: Data-Aware SAT Heuristics Combinations Optimization via Large Language Models", "comment": "11 pages", "summary": "The performance of Conflict-Driven Clause Learning solvers hinges on internal\nheuristics, yet the heterogeneity of SAT problems makes a single, universally\noptimal configuration unattainable. While prior automated methods can find\nspecialized configurations for specific problem families, this dataset-specific\napproach lacks generalizability and requires costly re-optimization for new\nproblem types. We introduce DaSAThco, a framework that addresses this challenge\nby learning a generalizable mapping from instance features to tailored\nheuristic ensembles, enabling a train-once, adapt-broadly model. Our framework\nuses a Large Language Model, guided by systematically defined Problem\nArchetypes, to generate a diverse portfolio of specialized heuristic ensembles\nand subsequently learns an adaptive selection mechanism to form the final\nmapping. Experiments show that DaSAThco achieves superior performance and, most\nnotably, demonstrates robust out-of-domain generalization where non-adaptive\nmethods show limitations. Our work establishes a more scalable and practical\npath toward automated algorithm design for complex, configurable systems.", "AI": {"tldr": "DaSAThco\u662f\u4e00\u4e2a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u5b9e\u4f8b\u7279\u5f81\u5b66\u4e60\u5230\u542f\u53d1\u5f0f\u7ec4\u5408\u7684\u901a\u7528\u6620\u5c04\u6846\u67b6\uff0c\u89e3\u51b3\u4e86SAT\u6c42\u89e3\u5668\u914d\u7f6e\u96be\u4ee5\u901a\u7528\u5316\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u548c\u5f3a\u5927\u7684\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "SAT\u95ee\u9898\u7684\u5f02\u8d28\u6027\u4f7f\u5f97\u5355\u4e00\u6700\u4f18\u914d\u7f6e\u65e0\u6cd5\u5b9e\u73b0\uff0c\u800c\u73b0\u6709\u7684\u6570\u636e\u96c6\u7279\u5b9a\u65b9\u6cd5\u7f3a\u4e4f\u901a\u7528\u6027\u4e14\u9700\u8981\u4e3a\u65b0\u95ee\u9898\u7c7b\u578b\u91cd\u65b0\u4f18\u5316\uff0c\u6210\u672c\u9ad8\u6602\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u7cfb\u7edf\u5b9a\u4e49\u7684\u95ee\u9898\u539f\u578b\u6307\u5bfc\u4e0b\u751f\u6210\u591a\u6837\u5316\u7684\u4e13\u7528\u542f\u53d1\u5f0f\u7ec4\u5408\u7ec4\u5408\uff0c\u7136\u540e\u5b66\u4e60\u81ea\u9002\u5e94\u9009\u62e9\u673a\u5236\u5f62\u6210\u6700\u7ec8\u6620\u5c04\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDaSAThco\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u975e\u81ea\u9002\u5e94\u65b9\u6cd5\u8868\u73b0\u6709\u9650\u7684\u9886\u57df\u5916\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u590d\u6742\u53ef\u914d\u7f6e\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u7b97\u6cd5\u8bbe\u8ba1\u5efa\u7acb\u4e86\u66f4\u53ef\u6269\u5c55\u548c\u5b9e\u7528\u7684\u8def\u5f84\u3002"}}
{"id": "2509.12611", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12611", "abs": "https://arxiv.org/abs/2509.12611", "authors": ["Anmol Singhal Navya Singhal"], "title": "Analogy-Driven Financial Chain-of-Thought (AD-FCoT): A Prompting Approach for Financial Sentiment Analysis", "comment": "IEEE AIxB 2025", "summary": "Financial news sentiment analysis is crucial for anticipating market\nmovements. With the rise of AI techniques such as Large Language Models (LLMs),\nwhich demonstrate strong text understanding capabilities, there has been\nrenewed interest in enhancing these systems. Existing methods, however, often\nstruggle to capture the complex economic context of news and lack transparent\nreasoning, which undermines their reliability. We propose Analogy-Driven\nFinancial Chain-of-Thought (AD-FCoT), a prompting framework that integrates\nanalogical reasoning with chain-of-thought (CoT) prompting for sentiment\nprediction on historical financial news. AD-FCoT guides LLMs to draw parallels\nbetween new events and relevant historical scenarios with known outcomes,\nembedding these analogies into a structured, step-by-step reasoning chain. To\nour knowledge, this is among the first approaches to explicitly combine\nanalogical examples with CoT reasoning in finance. Operating purely through\nprompting, AD-FCoT requires no additional training data or fine-tuning and\nleverages the model's internal financial knowledge to generate rationales that\nmirror human analytical reasoning. Experiments on thousands of news articles\nshow that AD-FCoT outperforms strong baselines in sentiment classification\naccuracy and achieves substantially higher correlation with market returns. Its\ngenerated explanations also align with domain expertise, providing\ninterpretable insights suitable for real-world financial analysis.", "AI": {"tldr": "AD-FCoT\u662f\u4e00\u4e2a\u901a\u8fc7\u7c7b\u6bd4\u63a8\u7406\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u76f8\u7ed3\u5408\u7684\u91d1\u878d\u60c5\u611f\u5206\u6790\u6846\u67b6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u63d0\u5347LLM\u5728\u91d1\u878d\u65b0\u95fb\u60c5\u611f\u5206\u7c7b\u548c\u5e02\u573a\u56de\u62a5\u9884\u6d4b\u65b9\u9762\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u91d1\u878d\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u590d\u6742\u7684\u7ecf\u6d4e\u80cc\u666f\u4e14\u7f3a\u4e4f\u900f\u660e\u63a8\u7406\uff0c\u5f71\u54cd\u4e86\u53ef\u9760\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ed3\u5408\u5386\u53f2\u7c7b\u6bd4\u548c\u7ed3\u6784\u5316\u63a8\u7406\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5206\u6790\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u7c7b\u6bd4\u9a71\u52a8\u7684\u91d1\u878d\u601d\u7ef4\u94fe(AD-FCoT)\u63d0\u793a\u6846\u67b6\uff0c\u5f15\u5bfcLLM\u5728\u65b0\u4e8b\u4ef6\u548c\u76f8\u5173\u5386\u53f2\u573a\u666f\u4e4b\u95f4\u5efa\u7acb\u7c7b\u6bd4\uff0c\u5e76\u5c06\u8fd9\u4e9b\u7c7b\u6bd4\u5d4c\u5165\u5230\u9010\u6b65\u63a8\u7406\u94fe\u4e2d\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6570\u636e\u6216\u5fae\u8c03\u3002", "result": "\u5728\u6570\u5343\u7bc7\u65b0\u95fb\u6587\u7ae0\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAD-FCoT\u5728\u60c5\u611f\u5206\u7c7b\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e0e\u5e02\u573a\u56de\u62a5\u7684\u76f8\u5173\u6027\u663e\u8457\u66f4\u9ad8\uff0c\u751f\u6210\u7684\u89e3\u91ca\u4e0e\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u4e00\u81f4\u3002", "conclusion": "AD-FCoT\u901a\u8fc7\u7ed3\u5408\u7c7b\u6bd4\u63a8\u7406\u548c\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u4e3a\u91d1\u878d\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u91d1\u878d\u5206\u6790\u573a\u666f\u3002"}}
{"id": "2509.12612", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12612", "abs": "https://arxiv.org/abs/2509.12612", "authors": ["Daojun Chen", "Xi Wang", "Shenyuan Ren", "Qingzhi Ma", "Pengpeng Zhao", "An Liu"], "title": "GBV-SQL: Guided Generation and SQL2Text Back-Translation Validation for Multi-Agent Text2SQL", "comment": null, "summary": "While Large Language Models have significantly advanced Text2SQL generation,\na critical semantic gap persists where syntactically valid queries often\nmisinterpret user intent. To mitigate this challenge, we propose GBV-SQL, a\nnovel multi-agent framework that introduces Guided Generation with SQL2Text\nBack-translation Validation. This mechanism uses a specialized agent to\ntranslate the generated SQL back into natural language, which verifies its\nlogical alignment with the original question. Critically, our investigation\nreveals that current evaluation is undermined by a systemic issue: the poor\nquality of the benchmarks themselves. We introduce a formal typology for \"Gold\nErrors\", which are pervasive flaws in the ground-truth data, and demonstrate\nhow they obscure true model performance. On the challenging BIRD benchmark,\nGBV-SQL achieves 63.23% execution accuracy, a 5.8% absolute improvement. After\nremoving flawed examples, GBV-SQL achieves 96.5% (dev) and 97.6% (test)\nexecution accuracy on the Spider benchmark. Our work offers both a robust\nframework for semantic validation and a critical perspective on benchmark\nintegrity, highlighting the need for more rigorous dataset curation.", "AI": {"tldr": "GBV-SQL\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7SQL2Text\u53cd\u5411\u7ffb\u8bd1\u9a8c\u8bc1\u6765\u63d0\u5347Text2SQL\u7684\u8bed\u4e49\u51c6\u786e\u6027\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u666e\u904d\u5b58\u5728\u7684\u9ec4\u91d1\u9519\u8bef\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728Text2SQL\u751f\u6210\u4e2d\u5b58\u5728\u7684\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u5373\u8bed\u6cd5\u6b63\u786e\u7684\u67e5\u8be2\u53ef\u80fd\u8bef\u89e3\u7528\u6237\u610f\u56fe\uff0c\u540c\u65f6\u53d1\u73b0\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u8d28\u91cf\u5b58\u5728\u95ee\u9898\u3002", "method": "\u63d0\u51faGBV-SQL\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u91c7\u7528\u5f15\u5bfc\u751f\u6210\u548cSQL2Text\u53cd\u5411\u7ffb\u8bd1\u9a8c\u8bc1\u673a\u5236\uff0c\u901a\u8fc7\u4e13\u95e8\u667a\u80fd\u4f53\u5c06\u751f\u6210\u7684SQL\u7ffb\u8bd1\u56de\u81ea\u7136\u8bed\u8a00\u6765\u9a8c\u8bc1\u903b\u8f91\u4e00\u81f4\u6027\u3002", "result": "\u5728BIRD\u57fa\u51c6\u4e0a\u8fbe\u523063.23%\u7684\u6267\u884c\u51c6\u786e\u7387\uff08\u63d0\u53475.8%\uff09\uff0c\u5728\u53bb\u9664\u9519\u8bef\u6837\u672c\u540e\u7684Spider\u57fa\u51c6\u4e0a\u5206\u522b\u8fbe\u523096.5%\uff08\u5f00\u53d1\u96c6\uff09\u548c97.6%\uff08\u6d4b\u8bd5\u96c6\uff09\u7684\u6267\u884c\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u8bed\u4e49\u9a8c\u8bc1\u7684\u9c81\u68d2\u6846\u67b6\uff0c\u8fd8\u63ed\u793a\u4e86\u57fa\u51c6\u6d4b\u8bd5\u5b8c\u6574\u6027\u7684\u5173\u952e\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u66f4\u4e25\u683c\u6570\u636e\u96c6\u7ba1\u7406\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.12741", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12741", "abs": "https://arxiv.org/abs/2509.12741", "authors": ["Alexis Yihong Hao", "Yufei Wang", "Navin Sriram Ravie", "Bharath Hegde", "David Held", "Zackory Erickson"], "title": "Force-Modulated Visual Policy for Robot-Assisted Dressing with Arm Motions", "comment": "CoRL 2025", "summary": "Robot-assisted dressing has the potential to significantly improve the lives\nof individuals with mobility impairments. To ensure an effective and\ncomfortable dressing experience, the robot must be able to handle challenging\ndeformable garments, apply appropriate forces, and adapt to limb movements\nthroughout the dressing process. Prior work often makes simplifying assumptions\n-- such as static human limbs during dressing -- which limits real-world\napplicability. In this work, we develop a robot-assisted dressing system\ncapable of handling partial observations with visual occlusions, as well as\nrobustly adapting to arm motions during the dressing process. Given a policy\ntrained in simulation with partial observations, we propose a method to\nfine-tune it in the real world using a small amount of data and multi-modal\nfeedback from vision and force sensing, to further improve the policy's\nadaptability to arm motions and enhance safety. We evaluate our method in\nsimulation with simplified articulated human meshes and in a real world human\nstudy with 12 participants across 264 dressing trials. Our policy successfully\ndresses two long-sleeve everyday garments onto the participants while being\nadaptive to various kinds of arm motions, and greatly outperforms prior\nbaselines in terms of task completion and user feedback. Video are available at\nhttps://dressing-motion.github.io/.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u673a\u5668\u4eba\u8f85\u52a9\u7a7f\u8863\u7cfb\u7edf\uff0c\u80fd\u591f\u5904\u7406\u89c6\u89c9\u906e\u6321\u7684\u90e8\u5206\u89c2\u6d4b\uff0c\u5e76\u5728\u7a7f\u8863\u8fc7\u7a0b\u4e2d\u9002\u5e94\u624b\u81c2\u8fd0\u52a8\uff0c\u901a\u8fc7\u4eff\u771f\u8bad\u7ec3\u548c\u5c11\u91cf\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5fae\u8c03\u7b56\u7565\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u8f85\u52a9\u7a7f\u8863\u7cfb\u7edf\u901a\u5e38\u5047\u8bbe\u4eba\u4f53\u80a2\u4f53\u5728\u7a7f\u8863\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u9759\u6b62\uff0c\u8fd9\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u89c6\u89c9\u906e\u6321\u548c\u9002\u5e94\u80a2\u4f53\u8fd0\u52a8\u7684\u7cfb\u7edf\uff0c\u4ee5\u63d0\u4f9b\u66f4\u6709\u6548\u548c\u8212\u9002\u7684\u7a7f\u8863\u4f53\u9a8c\u3002", "method": "\u5728\u4eff\u771f\u73af\u5883\u4e2d\u8bad\u7ec3\u5177\u6709\u90e8\u5206\u89c2\u6d4b\u80fd\u529b\u7684\u7b56\u7565\uff0c\u7136\u540e\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u4f7f\u7528\u5c11\u91cf\u6570\u636e\u548c\u591a\u6a21\u6001\u53cd\u9988\uff08\u89c6\u89c9\u548c\u529b\u611f\u77e5\uff09\u8fdb\u884c\u5fae\u8c03\uff0c\u63d0\u9ad8\u7b56\u7565\u5bf9\u624b\u81c2\u8fd0\u52a8\u7684\u9002\u5e94\u6027\u548c\u5b89\u5168\u6027\u3002", "result": "\u572812\u540d\u53c2\u4e0e\u8005\u7684264\u6b21\u7a7f\u8863\u8bd5\u9a8c\u4e2d\uff0c\u7cfb\u7edf\u6210\u529f\u4e3a\u53c2\u4e0e\u8005\u7a7f\u4e0a\u4e24\u79cd\u957f\u8896\u65e5\u5e38\u670d\u88c5\uff0c\u80fd\u591f\u9002\u5e94\u5404\u79cd\u624b\u81c2\u8fd0\u52a8\uff0c\u5728\u4efb\u52a1\u5b8c\u6210\u5ea6\u548c\u7528\u6237\u53cd\u9988\u65b9\u9762\u5927\u5e45\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u673a\u5668\u4eba\u8f85\u52a9\u7a7f\u8863\u4e2d\u7684\u89c6\u89c9\u906e\u6321\u548c\u80a2\u4f53\u8fd0\u52a8\u9002\u5e94\u95ee\u9898\uff0c\u901a\u8fc7\u4eff\u771f\u5230\u771f\u5b9e\u7684\u8fc1\u79fb\u5b66\u4e60\u548c\u591a\u6a21\u6001\u53cd\u9988\u5fae\u8c03\uff0c\u5b9e\u73b0\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f18\u5f02\u6027\u80fd\u3002"}}
{"id": "2509.12615", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12615", "abs": "https://arxiv.org/abs/2509.12615", "authors": ["Muhammad Riaz Hasib Hossain", "Rafiqul Islam", "Shawn R McGrath", "Md Zahidul Islam", "David Lamb"], "title": "Mob-based cattle weight gain forecasting using ML models", "comment": null, "summary": "Forecasting mob based cattle weight gain (MB CWG) may benefit large livestock\nfarms, allowing farmers to refine their feeding strategies, make educated\nbreeding choices, and reduce risks linked to climate variability and market\nfluctuations. In this paper, a novel technique termed MB CWG is proposed to\nforecast the one month advanced weight gain of herd based cattle using\nhistorical data collected from the Charles Sturt University Farm. This research\nemploys a Random Forest (RF) model, comparing its performance against Support\nVector Regression (SVR) and Long Short Term Memory (LSTM) models for monthly\nweight gain prediction. Four datasets were used to evaluate the performance of\nmodels, using 756 sample data from 108 herd-based cattle, along with weather\ndata (rainfall and temperature) influencing CWG. The RF model performs better\nthan the SVR and LSTM models across all datasets, achieving an R^2 of 0.973,\nRMSE of 0.040, and MAE of 0.033 when both weather and age factors were\nincluded. The results indicate that including both weather and age factors\nsignificantly improves the accuracy of weight gain predictions, with the RF\nmodel outperforming the SVR and LSTM models in all scenarios. These findings\ndemonstrate the potential of RF as a robust tool for forecasting cattle weight\ngain in variable conditions, highlighting the influence of age and climatic\nfactors on herd based weight trends. This study has also developed an\ninnovative automated pre processing tool to generate a benchmark dataset for MB\nCWG predictive models. The tool is publicly available on GitHub and can assist\nin preparing datasets for current and future analytical research..", "AI": {"tldr": "\u63d0\u51faMB CWG\u65b9\u6cd5\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u6a21\u578b\u9884\u6d4b\u725b\u7fa4\u6708\u5ea6\u4f53\u91cd\u589e\u957f\uff0c\u76f8\u6bd4SVR\u548cLSTM\u8868\u73b0\u66f4\u4f18\uff0cR\u00b2\u8fbe0.973\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u9884\u5904\u7406\u5de5\u5177", "motivation": "\u9884\u6d4b\u725b\u7fa4\u4f53\u91cd\u589e\u957f\u6709\u52a9\u4e8e\u5927\u578b\u755c\u7267\u573a\u4f18\u5316\u9972\u517b\u7b56\u7565\u3001\u505a\u51fa\u660e\u667a\u80b2\u79cd\u9009\u62e9\uff0c\u5e76\u964d\u4f4e\u6c14\u5019\u591a\u53d8\u6027\u548c\u5e02\u573a\u6ce2\u52a8\u7684\u98ce\u9669", "method": "\u4f7f\u7528\u968f\u673a\u68ee\u6797(RF)\u6a21\u578b\uff0c\u4e0e\u652f\u6301\u5411\u91cf\u56de\u5f52(SVR)\u548c\u957f\u77ed\u671f\u8bb0\u5fc6(LSTM)\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u5229\u7528756\u4e2a\u6837\u672c\u6570\u636e\u548c\u5929\u6c14\u6570\u636e(\u964d\u96e8\u548c\u6e29\u5ea6)\u8fdb\u884c\u6708\u5ea6\u4f53\u91cd\u589e\u957f\u9884\u6d4b", "result": "RF\u6a21\u578b\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5f53\u5305\u542b\u5929\u6c14\u548c\u5e74\u9f84\u56e0\u7d20\u65f6\u8fbe\u5230R\u00b2=0.973\u3001RMSE=0.040\u3001MAE=0.033\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b", "conclusion": "RF\u6a21\u578b\u662f\u9884\u6d4b\u725b\u7fa4\u4f53\u91cd\u589e\u957f\u7684\u5f3a\u5927\u5de5\u5177\uff0c\u5929\u6c14\u548c\u5e74\u9f84\u56e0\u7d20\u5bf9\u9884\u6d4b\u51c6\u786e\u6027\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u7814\u7a76\u8fd8\u5f00\u53d1\u4e86\u516c\u5f00\u7684\u81ea\u52a8\u5316\u9884\u5904\u7406\u5de5\u5177"}}
{"id": "2509.12747", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12747", "abs": "https://arxiv.org/abs/2509.12747", "authors": ["Botao He", "Amir Hossein Shahidzadeh", "Yu Chen", "Jiayi Wu", "Tianrui Guan", "Guofei Chen", "Howie Choset", "Dinesh Manocha", "Glen Chou", "Cornelia Fermuller", "Yiannis Aloimonos"], "title": "NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts", "comment": null, "summary": "This paper explores traversability estimation for robot navigation. A key\nbottleneck in traversability estimation lies in efficiently achieving reliable\nand robust predictions while accurately encoding both geometric and semantic\ninformation across diverse environments. We introduce Navigation via Mixture of\nExperts (NAVMOE), a hierarchical and modular approach for traversability\nestimation and local navigation. NAVMOE combines multiple specialized models\nfor specific terrain types, each of which can be either a classical model-based\nor a learning-based approach that predicts traversability for specific terrain\ntypes. NAVMOE dynamically weights the contributions of different models based\non the input environment through a gating network. Overall, our approach offers\nthree advantages: First, NAVMOE enables traversability estimation to adaptively\nleverage specialized approaches for different terrains, which enhances\ngeneralization across diverse and unseen environments. Second, our approach\nsignificantly improves efficiency with negligible cost of solution quality by\nintroducing a training-free lazy gating mechanism, which is designed to\nminimize the number of activated experts during inference. Third, our approach\nuses a two-stage training strategy that enables the training for the gating\nnetworks within the hybrid MoE method that contains nondifferentiable modules.\nExtensive experiments show that NAVMOE delivers a better efficiency and\nperformance balance than any individual expert or full ensemble across\ndifferent domains, improving cross- domain generalization and reducing average\ncomputational cost by 81.2% via lazy gating, with less than a 2% loss in path\nquality.", "AI": {"tldr": "NAVMOE\u662f\u4e00\u79cd\u7528\u4e8e\u673a\u5668\u4eba\u5bfc\u822a\u7684\u6df7\u5408\u4e13\u5bb6\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u7ec4\u5408\u4e13\u95e8\u5316\u6a21\u578b\u6765\u5904\u7406\u4e0d\u540c\u5730\u5f62\u7c7b\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u7684\u53ef\u901a\u884c\u6027\u4f30\u8ba1\u9700\u8981\u5728\u591a\u6837\u73af\u5883\u4e2d\u9ad8\u6548\u53ef\u9760\u5730\u7f16\u7801\u51e0\u4f55\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6cdb\u5316\u6027\u548c\u6548\u7387\u65b9\u9762\u5b58\u5728\u74f6\u9888\u3002", "method": "\u91c7\u7528\u5206\u5c42\u6a21\u5757\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u4e2a\u4e13\u95e8\u5316\u6a21\u578b\uff08\u7ecf\u5178\u6a21\u578b\u6216\u5b66\u4e60\u6a21\u578b\uff09\u5904\u7406\u7279\u5b9a\u5730\u5f62\uff0c\u901a\u8fc7\u95e8\u63a7\u7f51\u7edc\u52a8\u6001\u52a0\u6743\u4e0d\u540c\u6a21\u578b\u7684\u8d21\u732e\uff0c\u5e76\u4f7f\u7528\u8bad\u7ec3\u514d\u8d39\u7684\u60f0\u6027\u95e8\u63a7\u673a\u5236\u51cf\u5c11\u63a8\u7406\u65f6\u7684\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660eNAVMOE\u5728\u6548\u7387\u548c\u6027\u80fd\u5e73\u8861\u65b9\u9762\u4f18\u4e8e\u5355\u4e2a\u4e13\u5bb6\u6216\u5b8c\u6574\u96c6\u6210\u65b9\u6cd5\uff0c\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u63d0\u5347\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e81.2%\uff0c\u8def\u5f84\u8d28\u91cf\u635f\u5931\u5c0f\u4e8e2%\u3002", "conclusion": "NAVMOE\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u65b9\u6cd5\u548c\u60f0\u6027\u95e8\u63a7\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u53ef\u901a\u884c\u6027\u4f30\u8ba1\u4e2d\u7684\u6cdb\u5316\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u5bfc\u822a\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12625", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12625", "abs": "https://arxiv.org/abs/2509.12625", "authors": ["Yong Xia", "Jingxuan Li", "YeTeng Sun", "Jiarui Bu"], "title": "ECG-aBcDe: Overcoming Model Dependence, Encoding ECG into a Universal Language for Any LLM", "comment": "14pages, 6 figures", "summary": "Large Language Models (LLMs) hold significant promise for electrocardiogram\n(ECG) analysis, yet challenges remain regarding transferability, time-scale\ninformation learning, and interpretability. Current methods suffer from\nmodel-specific ECG encoders, hindering transfer across LLMs. Furthermore, LLMs\nstruggle to capture crucial time-scale information inherent in ECGs due to\nTransformer limitations. And their black-box nature limits clinical adoption.\nTo address these limitations, we introduce ECG-aBcDe, a novel ECG encoding\nmethod that transforms ECG signals into a universal ECG language readily\ninterpretable by any LLM. By constructing a hybrid dataset of ECG language and\nnatural language, ECG-aBcDe enables direct fine-tuning of pre-trained LLMs\nwithout architectural modifications, achieving \"construct once, use anywhere\"\ncapability. Moreover, the bidirectional convertibility between ECG and ECG\nlanguage of ECG-aBcDe allows for extracting attention heatmaps from ECG\nsignals, significantly enhancing interpretability. Finally, ECG-aBcDe\nexplicitly represents time-scale information, mitigating Transformer\nlimitations. This work presents a new paradigm for integrating ECG analysis\nwith LLMs. Compared with existing methods, our method achieves competitive\nperformance on ROUGE-L and METEOR. Notably, it delivers significant\nimprovements in the BLEU-4, with improvements of 2.8 times and 3.9 times in\nin-dataset and cross-dataset evaluations, respectively, reaching scores of\n42.58 and 30.76. These results provide strong evidence for the feasibility of\nthe new paradigm.", "AI": {"tldr": "ECG-aBcDe\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5fc3\u7535\u56fe\u7f16\u7801\u65b9\u6cd5\uff0c\u5c06ECG\u4fe1\u53f7\u8f6c\u6362\u4e3a\u901a\u7528ECG\u8bed\u8a00\uff0c\u89e3\u51b3\u4e86LLM\u5728\u5fc3\u7535\u56fe\u5206\u6790\u4e2d\u7684\u53ef\u8fc1\u79fb\u6027\u3001\u65f6\u95f4\u5c3a\u5ea6\u4fe1\u606f\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u6027\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u7279\u5b9a\u7684ECG\u7f16\u7801\u5668\u963b\u788d\u8de8LLM\u8fc1\u79fb\u3001Transformer\u96be\u4ee5\u6355\u6349ECG\u5173\u952e\u65f6\u95f4\u5c3a\u5ea6\u4fe1\u606f\u3001\u4ee5\u53ca\u9ed1\u76d2\u7279\u6027\u9650\u5236\u4e34\u5e8a\u91c7\u7528\u7b49\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6784\u5efaECG\u8bed\u8a00\u548c\u81ea\u7136\u8bed\u8a00\u7684\u6df7\u5408\u6570\u636e\u96c6\uff0cECG-aBcDe\u5c06ECG\u4fe1\u53f7\u8f6c\u6362\u4e3a\u901a\u7528ECG\u8bed\u8a00\uff0c\u65e0\u9700\u67b6\u6784\u4fee\u6539\u5373\u53ef\u76f4\u63a5\u5fae\u8c03\u9884\u8bad\u7ec3LLM\uff0c\u5e76\u652f\u6301\u53cc\u5411\u8f6c\u6362\u4ee5\u63d0\u53d6\u6ce8\u610f\u529b\u70ed\u56fe\u3002", "result": "\u5728ROUGE-L\u548cMETEOR\u4e0a\u8fbe\u5230\u7ade\u4e89\u6027\u6027\u80fd\uff0cBLEU-4\u6307\u6807\u5728\u6570\u636e\u96c6\u5185\u548c\u8de8\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u5206\u522b\u63d0\u53472.8\u500d\u548c3.9\u500d\uff0c\u8fbe\u523042.58\u548c30.76\u5206\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5c06ECG\u5206\u6790\u4e0eLLM\u96c6\u6210\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.12754", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12754", "abs": "https://arxiv.org/abs/2509.12754", "authors": ["Saki Hashimoto", "Shoichi Hasegawa", "Tomochika Ishikawa", "Akira Taniguchi", "Yoshinobu Hagiwara", "Lotfi El Hafi", "Tadahiro Taniguchi"], "title": "Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model", "comment": "Submitted to AROB-ISBC 2026 (Journal Track option)", "summary": "Robots operating in domestic and office environments must understand object\nownership to correctly execute instructions such as ``Bring me my cup.''\nHowever, ownership cannot be reliably inferred from visual features alone. To\naddress this gap, we propose Active Ownership Learning (ActOwL), a framework\nthat enables robots to actively generate and ask ownership-related questions to\nusers. ActOwL employs a probabilistic generative model to select questions that\nmaximize information gain, thereby acquiring ownership knowledge efficiently to\nimprove learning efficiency. Additionally, by leveraging commonsense knowledge\nfrom Large Language Models (LLM), objects are pre-classified as either shared\nor owned, and only owned objects are targeted for questioning. Through\nexperiments in a simulated home environment and a real-world laboratory\nsetting, ActOwL achieved significantly higher ownership clustering accuracy\nwith fewer questions than baseline methods. These findings demonstrate the\neffectiveness of combining active inference with LLM-guided commonsense\nreasoning, advancing the capability of robots to acquire ownership knowledge\nfor practical and socially appropriate task execution.", "AI": {"tldr": "\u673a\u5668\u4eba\u901a\u8fc7\u4e3b\u52a8\u63d0\u95ee\u5b66\u4e60\u7269\u4f53\u6240\u6709\u6743\uff0c\u7ed3\u5408\u6982\u7387\u751f\u6210\u6a21\u578b\u548cLLM\u5e38\u8bc6\u63a8\u7406\uff0c\u663e\u8457\u63d0\u9ad8\u6240\u6709\u6743\u8bc6\u522b\u51c6\u786e\u7387\u5e76\u51cf\u5c11\u63d0\u95ee\u6b21\u6570", "motivation": "\u5bb6\u5ead\u548c\u529e\u516c\u73af\u5883\u4e2d\u673a\u5668\u4eba\u9700\u8981\u7406\u89e3\u7269\u4f53\u6240\u6709\u6743\u6765\u6b63\u786e\u6267\u884c\u6307\u4ee4\uff0c\u4f46\u4ec5\u9760\u89c6\u89c9\u7279\u5f81\u65e0\u6cd5\u53ef\u9760\u63a8\u65ad\u6240\u6709\u6743", "method": "\u63d0\u51faActive Ownership Learning (ActOwL)\u6846\u67b6\uff0c\u4f7f\u7528\u6982\u7387\u751f\u6210\u6a21\u578b\u9009\u62e9\u4fe1\u606f\u589e\u76ca\u6700\u5927\u7684\u95ee\u9898\uff0c\u5e76\u5229\u7528LLM\u5e38\u8bc6\u77e5\u8bc6\u9884\u5206\u7c7b\u5171\u4eab/\u79c1\u6709\u7269\u54c1", "result": "\u5728\u6a21\u62df\u5bb6\u5ead\u73af\u5883\u548c\u771f\u5b9e\u5b9e\u9a8c\u5ba4\u73af\u5883\u4e2d\uff0cActOwL\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u4ee5\u66f4\u5c11\u7684\u95ee\u9898\u83b7\u5f97\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u6240\u6709\u6743\u805a\u7c7b\u51c6\u786e\u7387", "conclusion": "\u7ed3\u5408\u4e3b\u52a8\u63a8\u7406\u548cLLM\u5f15\u5bfc\u7684\u5e38\u8bc6\u63a8\u7406\u80fd\u6709\u6548\u63d0\u5347\u673a\u5668\u4eba\u83b7\u53d6\u6240\u6709\u6743\u77e5\u8bc6\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u66f4\u5b9e\u7528\u548c\u793e\u4ea4\u9002\u5b9c\u7684\u4efb\u52a1\u6267\u884c"}}
{"id": "2509.12643", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12643", "abs": "https://arxiv.org/abs/2509.12643", "authors": ["Beidan Liu", "Zhengqiu Zhu", "Chen Gao", "Yong Zhao", "Wei Qi", "Quanjun Yin"], "title": "Learn to Relax with Large Language Models: Solving Nonlinear Combinatorial Optimization Problems via Bidirectional Coevolution", "comment": null, "summary": "Nonlinear Combinatorial Optimization Problems (NCOPs) present a formidable\ncomputational hurdle in practice, as their nonconvex nature gives rise to\nmulti-modal solution spaces that defy efficient optimization. Traditional\nconstraint relaxation approaches rely heavily on expert-driven, iterative\ndesign processes that lack systematic automation and scalable adaptability.\nWhile recent Large Language Model (LLM)-based optimization methods show promise\nfor autonomous problem-solving, they predominantly function as passive\nconstraint validators rather than proactive strategy architects, failing to\nhandle the sophisticated constraint interactions inherent to NCOPs.To address\nthese limitations, we introduce the first end-to-end \\textbf{Auto}mated\n\\textbf{C}onstraint \\textbf{O}ptimization (AutoCO) method, which revolutionizes\nNCOPs resolution through learning to relax with LLMs.Specifically, we leverage\nstructured LLM reasoning to generate constraint relaxation strategies, which\nare dynamically evolving with algorithmic principles and executable code\nthrough a unified triple-representation scheme. We further establish a novel\nbidirectional (global-local) coevolution mechanism that synergistically\nintegrates Evolutionary Algorithms for intensive local refinement with Monte\nCarlo Tree Search for systematic global strategy space exploration, ensuring\noptimal balance between intensification and diversification in fragmented\nsolution spaces. Finally, comprehensive experiments on three challenging NCOP\nbenchmarks validate AutoCO's consistent effectiveness and superior performance\nover the baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u7ea6\u675f\u4f18\u5316\u65b9\u6cd5AutoCO\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u7ea6\u675f\u677e\u5f1b\u7b56\u7565\uff0c\u901a\u8fc7\u53cc\u5411\u534f\u540c\u8fdb\u5316\u673a\u5236\u89e3\u51b3\u975e\u7ebf\u6027\u7ec4\u5408\u4f18\u5316\u95ee\u9898", "motivation": "\u4f20\u7edf\u7ea6\u675f\u677e\u5f1b\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u9a71\u52a8\u7684\u8fed\u4ee3\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u81ea\u52a8\u5316\uff1b\u73b0\u6709LLM\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u4f5c\u4e3a\u88ab\u52a8\u7ea6\u675f\u9a8c\u8bc1\u5668\uff0c\u65e0\u6cd5\u5904\u7406\u590d\u6742\u7ea6\u675f\u4ea4\u4e92", "method": "\u5229\u7528\u7ed3\u6784\u5316LLM\u63a8\u7406\u751f\u6210\u7ea6\u675f\u677e\u5f1b\u7b56\u7565\uff0c\u901a\u8fc7\u4e09\u91cd\u8868\u793a\u65b9\u6848\u52a8\u6001\u6f14\u5316\uff1b\u5efa\u7acb\u53cc\u5411\uff08\u5168\u5c40-\u5c40\u90e8\uff09\u534f\u540c\u8fdb\u5316\u673a\u5236\uff0c\u7ed3\u5408\u8fdb\u5316\u7b97\u6cd5\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22", "result": "\u5728\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684NCOP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86AutoCO\u7684\u4e00\u81f4\u6709\u6548\u6027\u548c\u4f18\u4e8e\u57fa\u7ebf\u7684\u6027\u80fd", "conclusion": "AutoCO\u901a\u8fc7LLM\u9a71\u52a8\u7684\u7ea6\u675f\u677e\u5f1b\u548c\u53cc\u5411\u534f\u540c\u8fdb\u5316\u673a\u5236\uff0c\u4e3a\u975e\u7ebf\u6027\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u9769\u547d\u6027\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.12776", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12776", "abs": "https://arxiv.org/abs/2509.12776", "authors": ["Renjie Wang", "Shangke Lyu", "Xin Lang", "Wei Xiao", "Donglin Wang"], "title": "Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing", "comment": "Accepted by IROS 2025", "summary": "Jumping constitutes an essential component of quadruped robots' locomotion\ncapabilities, which includes dynamic take-off and adaptive landing. Existing\nquadrupedal jumping studies mainly focused on the stance and flight phase by\nassuming a flat landing ground, which is impractical in many real world cases.\nThis work proposes a safe landing framework that achieves adaptive landing on\nrough terrains by combining Trajectory Optimization (TO) and Reinforcement\nLearning (RL) together. The RL agent learns to track the reference motion\ngenerated by TO in the environments with rough terrains. To enable the learning\nof compliant landing skills on challenging terrains, a reward relaxation\nstrategy is synthesized to encourage exploration during landing recovery\nperiod. Extensive experiments validate the accurate tracking and safe landing\nskills benefiting from our proposed method in various scenarios.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u8f68\u8ff9\u4f18\u5316\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u56db\u8db3\u673a\u5668\u4eba\u5b89\u5168\u7740\u9646\u6846\u67b6\uff0c\u5b9e\u73b0\u7c97\u7cd9\u5730\u5f62\u81ea\u9002\u5e94\u7740\u9646", "motivation": "\u73b0\u6709\u56db\u8db3\u673a\u5668\u4eba\u8df3\u8dc3\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5e73\u5766\u7740\u9646\u5730\u9762\uff0c\u8fd9\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u4e0d\u5b9e\u7528\uff0c\u9700\u8981\u89e3\u51b3\u7c97\u7cd9\u5730\u5f62\u4e0b\u7684\u5b89\u5168\u7740\u9646\u95ee\u9898", "method": "\u7ed3\u5408\u8f68\u8ff9\u4f18\u5316(TO)\u751f\u6210\u53c2\u8003\u8fd0\u52a8\uff0c\u5f3a\u5316\u5b66\u4e60(RL)\u4ee3\u7406\u5b66\u4e60\u5728\u7c97\u7cd9\u5730\u5f62\u73af\u5883\u4e2d\u8ddf\u8e2a\u53c2\u8003\u8fd0\u52a8\uff0c\u91c7\u7528\u5956\u52b1\u677e\u5f1b\u7b56\u7565\u9f13\u52b1\u7740\u9646\u6062\u590d\u671f\u7684\u63a2\u7d22", "result": "\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u573a\u666f\u4e0b\u5b9e\u73b0\u7cbe\u786e\u8ddf\u8e2a\u548c\u5b89\u5168\u7740\u9646\u6280\u80fd", "conclusion": "\u63d0\u51fa\u7684TO+RL\u6846\u67b6\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u56db\u8db3\u673a\u5668\u4eba\u5728\u7c97\u7cd9\u5730\u5f62\u4e0a\u7684\u81ea\u9002\u5e94\u5b89\u5168\u7740\u9646"}}
{"id": "2509.12645", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.12645", "abs": "https://arxiv.org/abs/2509.12645", "authors": ["Lachlan McGinness", "Peter Baumgartner"], "title": "Large Language Models Imitate Logical Reasoning, but at what Cost?", "comment": "This work has been accepted as a main track paper for publication in\n  the proceedings of the Australasian Joint Conference on Artificial\n  Intelligence 2025 held in Canberra, Australia", "summary": "We present a longitudinal study which evaluates the reasoning capability of\nfrontier Large Language Models over an eighteen month period. We measured the\naccuracy of three leading models from December 2023, September 2024 and June\n2025 on true or false questions from the PrOntoQA dataset and their\nfaithfulness to reasoning strategies provided through in-context learning. The\nimprovement in performance from 2023 to 2024 can be attributed to hidden Chain\nof Thought prompting. The introduction of thinking models allowed for\nsignificant improvement in model performance between 2024 and 2025.\n  We then present a neuro-symbolic architecture which uses LLMs of less than 15\nbillion parameters to translate the problems into a standardised form. We then\nparse the standardised forms of the problems into a program to be solved by Z3,\nan SMT solver, to determine the satisfiability of the query. We report the\nnumber of prompt and completion tokens as well as the computational cost in\nFLOPs for open source models. The neuro-symbolic approach significantly reduces\nthe computational cost while maintaining near perfect performance. The common\napproximation that the number of inference FLOPs is double the product of the\nactive parameters and total tokens was accurate within 10\\% for all\nexperiments.", "AI": {"tldr": "\u5bf9\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u572818\u4e2a\u6708\u671f\u95f4\u7684\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u7eb5\u5411\u7814\u7a76\uff0c\u53d1\u73b0\u901a\u8fc7\u601d\u7ef4\u94fe\u63d0\u793a\u548c\u601d\u7ef4\u6a21\u578b\u7684\u5f15\u5165\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u6765\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u968f\u65f6\u95f4\u63a8\u79fb\u7684\u63a8\u7406\u80fd\u529b\u53d8\u5316\uff0c\u5e76\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u65b9\u6cd5\u4ee5\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u4f7f\u7528PrOntoQA\u6570\u636e\u96c6\u7684\u771f\u5047\u95ee\u9898\u6d4b\u8bd5\u4e09\u4e2a\u9886\u5148\u6a21\u578b\uff0c\u91c7\u7528\u601d\u7ef4\u94fe\u63d0\u793a\u548c\u601d\u7ef4\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u5c06\u95ee\u9898\u8f6c\u6362\u4e3a\u6807\u51c6\u5316\u5f62\u5f0f\u540e\u7528Z3\u6c42\u89e3\u5668\u5904\u7406\u3002", "result": "\u4ece2023\u5e74\u52302024\u5e74\u6027\u80fd\u63d0\u5347\u5f52\u56e0\u4e8e\u9690\u85cf\u601d\u7ef4\u94fe\u63d0\u793a\uff0c2024\u5e74\u52302025\u5e74\u601d\u7ef4\u6a21\u578b\u5e26\u6765\u663e\u8457\u6539\u8fdb\u3002\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u4fdd\u6301\u8fd1\u4e4e\u5b8c\u7f8e\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u968f\u65f6\u95f4\u6301\u7eed\u63d0\u5347\uff0c\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u662f\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u6709\u6548\u65b9\u6cd5\uff0cFLOPs\u4f30\u7b97\u516c\u5f0f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u51c6\u786e\u5ea6\u8f83\u9ad8\u3002"}}
{"id": "2509.12813", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.12813", "abs": "https://arxiv.org/abs/2509.12813", "authors": ["Bowen Ye", "Junyue Huang", "Yang Liu", "Xiaozhen Qiao", "Xiang Yin"], "title": "Bridging Perception and Planning: Towards End-to-End Planning for Signal Temporal Logic Tasks", "comment": null, "summary": "We investigate the task and motion planning problem for Signal Temporal Logic\n(STL) specifications in robotics. Existing STL methods rely on pre-defined maps\nor mobility representations, which are ineffective in unstructured real-world\nenvironments. We propose the \\emph{Structured-MoE STL Planner}\n(\\textbf{S-MSP}), a differentiable framework that maps synchronized multi-view\ncamera observations and an STL specification directly to a feasible trajectory.\nS-MSP integrates STL constraints within a unified pipeline, trained with a\ncomposite loss that combines trajectory reconstruction and STL robustness. A\n\\emph{structure-aware} Mixture-of-Experts (MoE) model enables horizon-aware\nspecialization by projecting sub-tasks into temporally anchored embeddings. We\nevaluate S-MSP using a high-fidelity simulation of factory-logistics scenarios\nwith temporally constrained tasks. Experiments show that S-MSP outperforms\nsingle-expert baselines in STL satisfaction and trajectory feasibility. A\nrule-based \\emph{safety filter} at inference improves physical executability\nwithout compromising logical correctness, showcasing the practicality of the\napproach.", "AI": {"tldr": "\u63d0\u51fa\u4e86S-MSP\u6846\u67b6\uff0c\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u65b9\u6cd5\uff0c\u76f4\u63a5\u4ece\u591a\u89c6\u89d2\u76f8\u673a\u89c2\u6d4b\u548cSTL\u89c4\u8303\u6620\u5c04\u5230\u53ef\u884c\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u4efb\u52a1\u548c\u8fd0\u52a8\u89c4\u5212\u95ee\u9898", "motivation": "\u73b0\u6709STL\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u5730\u56fe\u6216\u79fb\u52a8\u6027\u8868\u793a\uff0c\u5728\u975e\u7ed3\u6784\u5316\u771f\u5b9e\u73af\u5883\u4e2d\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u80fd\u591f\u76f4\u63a5\u4ece\u611f\u77e5\u8f93\u5165\u5904\u7406STL\u89c4\u8303\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u4f7f\u7528\u7ed3\u6784\u5316\u611f\u77e5\u7684\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff0c\u5c06\u5b50\u4efb\u52a1\u6295\u5f71\u5230\u65f6\u95f4\u951a\u5b9a\u5d4c\u5165\u4e2d\uff0c\u901a\u8fc7\u7ed3\u5408\u8f68\u8ff9\u91cd\u5efa\u548cSTL\u9c81\u68d2\u6027\u7684\u590d\u5408\u635f\u5931\u8fdb\u884c\u8bad\u7ec3", "result": "\u5728\u5de5\u5382\u7269\u6d41\u573a\u666f\u7684\u9ad8\u4fdd\u771f\u4eff\u771f\u4e2d\uff0cS-MSP\u5728STL\u6ee1\u8db3\u5ea6\u548c\u8f68\u8ff9\u53ef\u884c\u6027\u65b9\u9762\u4f18\u4e8e\u5355\u4e13\u5bb6\u57fa\u7ebf\uff0c\u5b89\u5168\u8fc7\u6ee4\u5668\u63d0\u9ad8\u4e86\u7269\u7406\u53ef\u6267\u884c\u6027", "conclusion": "S-MSP\u6846\u67b6\u5c55\u793a\u4e86\u76f4\u63a5\u4ece\u611f\u77e5\u8f93\u5165\u5904\u7406STL\u89c4\u8303\u7684\u5b9e\u7528\u6027\uff0c\u901a\u8fc7\u7edf\u4e00\u7ba1\u9053\u96c6\u6210STL\u7ea6\u675f\uff0c\u4e3a\u673a\u5668\u4eba\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u89c4\u5212\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.12743", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.12743", "abs": "https://arxiv.org/abs/2509.12743", "authors": ["Hanqing Li", "Kiran Sheena Jyothi", "Henry Liang", "Sharika Mahadevan", "Diego Klabjan"], "title": "Zero-shot Graph Reasoning via Retrieval Augmented Framework with LLMs", "comment": null, "summary": "We propose a new, training-free method, Graph Reasoning via Retrieval\nAugmented Framework (GRRAF), that harnesses retrieval-augmented generation\n(RAG) alongside the code-generation capabilities of large language models\n(LLMs) to address a wide range of graph reasoning tasks. In GRRAF, the target\ngraph is stored in a graph database, and the LLM is prompted to generate\nexecutable code queries that retrieve the necessary information. This approach\ncircumvents the limitations of existing methods that require extensive\nfinetuning or depend on predefined algorithms, and it incorporates an error\nfeedback loop with a time-out mechanism to ensure both correctness and\nefficiency. Experimental evaluations on the GraphInstruct dataset reveal that\nGRRAF achieves 100% accuracy on most graph reasoning tasks, including cycle\ndetection, bipartite graph checks, shortest path computation, and maximum flow,\nwhile maintaining consistent token costs regardless of graph sizes. Imperfect\nbut still very high performance is observed on subgraph matching. Notably,\nGRRAF scales effectively to large graphs with up to 10,000 nodes.", "AI": {"tldr": "GRRAF\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u56fe\u63a8\u7406\u65b9\u6cd5\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u548cLLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u901a\u8fc7\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u67e5\u8be2\u56fe\u6570\u636e\u5e93\u6765\u89e3\u51b3\u5404\u79cd\u56fe\u63a8\u7406\u4efb\u52a1\uff0c\u5728\u5927\u591a\u6570\u4efb\u52a1\u4e0a\u8fbe\u5230100%\u51c6\u786e\u7387\u4e14\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u5fae\u8c03\u6216\u4f9d\u8d56\u9884\u5b9a\u4e49\u7b97\u6cd5\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002GRRAF\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u5229\u7528LLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7ed3\u5408\u56fe\u6570\u636e\u5e93\u68c0\u7d22\u6765\u89e3\u51b3\u56fe\u63a8\u7406\u95ee\u9898\u3002", "method": "\u5c06\u76ee\u6807\u56fe\u5b58\u50a8\u5728\u56fe\u5f62\u6570\u636e\u5e93\u4e2d\uff0c\u63d0\u793aLLM\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u67e5\u8be2\u6765\u68c0\u7d22\u5fc5\u8981\u4fe1\u606f\uff0c\u5305\u542b\u9519\u8bef\u53cd\u9988\u5faa\u73af\u548c\u8d85\u65f6\u673a\u5236\u786e\u4fdd\u6b63\u786e\u6027\u548c\u6548\u7387\u3002", "result": "\u5728GraphInstruct\u6570\u636e\u96c6\u4e0a\uff0c\u5927\u591a\u6570\u56fe\u63a8\u7406\u4efb\u52a1\u8fbe\u5230100%\u51c6\u786e\u7387\uff08\u5305\u62ec\u73af\u68c0\u6d4b\u3001\u4e8c\u5206\u56fe\u68c0\u67e5\u3001\u6700\u77ed\u8def\u5f84\u8ba1\u7b97\u548c\u6700\u5927\u6d41\uff09\uff0c\u5b50\u56fe\u5339\u914d\u6027\u80fd\u4e5f\u5f88\u9ad8\uff0c\u53ef\u6269\u5c55\u523010,000\u4e2a\u8282\u70b9\u7684\u5927\u578b\u56fe\u3002", "conclusion": "GRRAF\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u56fe\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5904\u7406\u5404\u79cd\u590d\u6742\u56fe\u4efb\u52a1\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5177\u6709\u4e00\u81f4\u7684token\u6210\u672c\u3002"}}
{"id": "2509.13109", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.13109", "abs": "https://arxiv.org/abs/2509.13109", "authors": ["Fabian Fl\u00fcrenbrock", "Yanick B\u00fcchel", "Johannes K\u00f6hler", "Marianne Schmid Daners", "Melanie N. Zeilinger"], "title": "Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation", "comment": null, "summary": "This paper introduces a learning-based control framework for a soft robotic\nactuator system designed to modulate intracranial pressure (ICP) waveforms,\nwhich is essential for studying cerebrospinal fluid dynamics and pathological\nprocesses underlying neurological disorders. A two-layer framework is proposed\nto safely achieve a desired ICP waveform modulation. First, a model predictive\ncontroller (MPC) with a disturbance observer is used for offset-free tracking\nof the system's motor position reference trajectory under safety constraints.\nSecond, to address the unknown nonlinear dependence of ICP on the motor\nposition, we employ a Bayesian optimization (BO) algorithm used for online\nlearning of a motor position reference trajectory that yields the desired ICP\nmodulation. The framework is experimentally validated using a test bench with a\nbrain phantom that replicates realistic ICP dynamics in vitro. Compared to a\npreviously employed proportional-integral-derivative controller, the MPC\nreduces mean and maximum motor position reference tracking errors by 83 % and\n73 %, respectively. In less than 20 iterations, the BO algorithm learns a motor\nposition reference trajectory that yields an ICP waveform with the desired mean\nand amplitude.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u6267\u884c\u5668\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u8c03\u8282\u9885\u5185\u538b\u6ce2\u5f62\uff0c\u901a\u8fc7\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u53cc\u5c42\u6846\u67b6\u5b9e\u73b0\u5b89\u5168\u7cbe\u786e\u7684\u63a7\u5236\u3002", "motivation": "\u7814\u7a76\u8111\u810a\u6db2\u52a8\u529b\u5b66\u548c\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u7684\u75c5\u7406\u8fc7\u7a0b\u9700\u8981\u5bf9\u9885\u5185\u538b\u6ce2\u5f62\u8fdb\u884c\u7cbe\u786e\u8c03\u5236\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7cfb\u7edf\u7684\u975e\u7ebf\u6027\u7279\u6027\u548c\u5b89\u5168\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u63a7\u5236\u6846\u67b6\uff1a\u7b2c\u4e00\u5c42\u4f7f\u7528\u5e26\u6270\u52a8\u89c2\u6d4b\u5668\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\u8fdb\u884c\u7535\u673a\u4f4d\u7f6e\u8f68\u8ff9\u7684\u5b89\u5168\u8ddf\u8e2a\uff1b\u7b2c\u4e8c\u5c42\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u7b97\u6cd5\u5728\u7ebf\u5b66\u4e60\u80fd\u591f\u4ea7\u751f\u671f\u671b\u9885\u5185\u538b\u8c03\u5236\u7684\u7535\u673a\u4f4d\u7f6e\u53c2\u8003\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0cMPC\u63a7\u5236\u5668\u5c06\u7535\u673a\u4f4d\u7f6e\u8ddf\u8e2a\u7684\u5e73\u5747\u8bef\u5dee\u548c\u6700\u5927\u8bef\u5dee\u5206\u522b\u964d\u4f4e\u4e8683%\u548c73%\uff1b\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u4e0d\u523020\u6b21\u8fed\u4ee3\u5185\u5c31\u80fd\u5b66\u4e60\u5230\u4ea7\u751f\u671f\u671b\u9885\u5185\u538b\u6ce2\u5f62\u5747\u503c\u548c\u5e45\u5ea6\u7684\u7535\u673a\u4f4d\u7f6e\u8f68\u8ff9\u3002", "conclusion": "\u8be5\u5b66\u4e60\u578b\u63a7\u5236\u6846\u67b6\u80fd\u591f\u5b89\u5168\u6709\u6548\u5730\u5b9e\u73b0\u9885\u5185\u538b\u6ce2\u5f62\u7684\u7cbe\u786e\u8c03\u5236\uff0c\u4e3a\u7814\u7a76\u8111\u810a\u6db2\u52a8\u529b\u5b66\u548c\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u63d0\u4f9b\u4e86\u6709\u529b\u7684\u5b9e\u9a8c\u5de5\u5177\u3002"}}
{"id": "2509.12838", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.12838", "abs": "https://arxiv.org/abs/2509.12838", "authors": ["Kento Murata", "Shoichi Hasegawa", "Tomochika Ishikawa", "Yoshinobu Hagiwara", "Akira Taniguchi", "Lotfi El Hafi", "Tadahiro Taniguchi"], "title": "Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models", "comment": "Submitted to AROB-ISBC 2026 (Journal Track option)", "summary": "It is crucial to efficiently execute instructions such as \"Find an apple and\na banana\" or \"Get ready for a field trip,\" which require searching for multiple\nobjects or understanding context-dependent commands. This study addresses the\nchallenging problem of determining which robot should be assigned to which part\nof a task when each robot possesses different situational on-site\nknowledge-specifically, spatial concepts learned from the area designated to it\nby the user. We propose a task planning framework that leverages large language\nmodels (LLMs) and spatial concepts to decompose natural language instructions\ninto subtasks and allocate them to multiple robots. We designed a novel\nfew-shot prompting strategy that enables LLMs to infer required objects from\nambiguous commands and decompose them into appropriate subtasks. In our\nexperiments, the proposed method achieved 47/50 successful assignments,\noutperforming random (28/50) and commonsense-based assignment (26/50).\nFurthermore, we conducted qualitative evaluations using two actual mobile\nmanipulators. The results demonstrated that our framework could handle\ninstructions, including those involving ad hoc categories such as \"Get ready\nfor a field trip,\" by successfully performing task decomposition, assignment,\nsequential planning, and execution.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7a7a\u95f4\u6982\u5ff5\u7684\u591a\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u6a21\u7cca\u6307\u4ee4\u5e76\u5206\u89e3\u4e3a\u5b50\u4efb\u52a1\u5206\u914d\u7ed9\u4e0d\u540c\u673a\u5668\u4eba", "motivation": "\u89e3\u51b3\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u5982\u4f55\u6839\u636e\u5404\u673a\u5668\u4eba\u7684\u73b0\u573a\u7a7a\u95f4\u77e5\u8bc6\u6765\u5206\u914d\u4efb\u52a1\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5904\u7406\u9700\u8981\u641c\u7d22\u591a\u4e2a\u5bf9\u8c61\u6216\u7406\u89e3\u4e0a\u4e0b\u6587\u76f8\u5173\u6307\u4ee4\u7684\u573a\u666f", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7a7a\u95f4\u6982\u5ff5\uff0c\u8bbe\u8ba1\u65b0\u9896\u7684\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\uff0c\u4ece\u6a21\u7cca\u6307\u4ee4\u63a8\u65ad\u6240\u9700\u5bf9\u8c61\u5e76\u5206\u89e3\u4e3a\u9002\u5f53\u7684\u5b50\u4efb\u52a1", "result": "\u5728\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e8647/50\u7684\u6210\u529f\u5206\u914d\u7387\uff0c\u4f18\u4e8e\u968f\u673a\u5206\u914d(28/50)\u548c\u5e38\u8bc6\u5206\u914d(26/50)\uff0c\u5b9e\u9645\u79fb\u52a8\u673a\u68b0\u81c2\u9a8c\u8bc1\u80fd\u5904\u7406\u5305\u62ec\u4e34\u65f6\u7c7b\u522b\u6307\u4ee4", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u6210\u529f\u8fdb\u884c\u4efb\u52a1\u5206\u89e3\u3001\u5206\u914d\u3001\u987a\u5e8f\u89c4\u5212\u548c\u6267\u884c\uff0c\u7279\u522b\u64c5\u957f\u5904\u7406\u6a21\u7cca\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u547d\u4ee4"}}
{"id": "2509.12810", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12810", "abs": "https://arxiv.org/abs/2509.12810", "authors": ["Shicheng Ye", "Chao Yu", "Kaiqiang Ke", "Chengdong Xu", "Yinqi Wei"], "title": "H$^2$R: Hierarchical Hindsight Reflection for Multi-Task LLM Agents", "comment": null, "summary": "Large language model (LLM)-based agents have shown strong potential in\nmulti-task scenarios, owing to their ability to transfer knowledge across\ndiverse tasks. However, existing approaches often treat prior experiences and\nknowledge as monolithic units, leading to inefficient and coarse-grained\nknowledge transfer. In this work, we propose a novel hierarchical memory\narchitecture that enables fine-grained knowledge transfer by decoupling\nhigh-level planning memory from low-level execution memory. To construct and\nrefine these hierarchical memories, we introduce Hierarchical Hindsight\nReflection (H$^2$R), a mechanism that distills reusable and hierarchical\nknowledge from past agent-environment interactions. At test time, H$^2$R\nperforms retrievals of high-level and low-level memories separately, allowing\nLLM-based agents to efficiently access and utilize task-relevant knowledge for\nnew tasks.Experimental results across two benchmarks demonstrate that H$^2$R\ncan improve generalization and decision-making performance, outperforming prior\nbaselines such as Expel.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784H\u00b2R\uff0c\u901a\u8fc7\u5206\u79bb\u9ad8\u5c42\u89c4\u5212\u8bb0\u5fc6\u548c\u4f4e\u5c42\u6267\u884c\u8bb0\u5fc6\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u8fc1\u79fb\uff0c\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u51b3\u7b56\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u5148\u9a8c\u7ecf\u9a8c\u548c\u77e5\u8bc6\u89c6\u4e3a\u6574\u4f53\u5355\u5143\uff0c\u5bfc\u81f4\u77e5\u8bc6\u8fc1\u79fb\u6548\u7387\u4f4e\u4e0b\u4e14\u7c92\u5ea6\u7c97\u7cd9\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u77e5\u8bc6\u8fc1\u79fb\u673a\u5236", "method": "\u63d0\u51fa\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784\uff0c\u5206\u79bb\u9ad8\u5c42\u89c4\u5212\u8bb0\u5fc6\u548c\u4f4e\u5c42\u6267\u884c\u8bb0\u5fc6\uff1b\u5f15\u5165Hierarchical Hindsight Reflection (H\u00b2R)\u673a\u5236\uff0c\u4ece\u8fc7\u5f80\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u4e2d\u63d0\u70bc\u53ef\u91cd\u7528\u7684\u5206\u5c42\u77e5\u8bc6\uff1b\u6d4b\u8bd5\u65f6\u5206\u522b\u68c0\u7d22\u9ad8\u4f4e\u5c42\u8bb0\u5fc6", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cH\u00b2R\u80fd\u591f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u51b3\u7b56\u6027\u80fd\uff0c\u4f18\u4e8eExpel\u7b49\u5148\u524d\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784\u548cH\u00b2R\u673a\u5236\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u8fc1\u79fb\uff0c\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e2d\u7684\u8868\u73b0"}}
{"id": "2509.13164", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.13164", "abs": "https://arxiv.org/abs/2509.13164", "authors": ["Jiawei Wang", "Haowei Sun", "Xintao Yan", "Shuo Feng", "Jun Gao", "Henry X. Liu"], "title": "TeraSim-World: Worldwide Safety-Critical Data Synthesis for End-to-End Autonomous Driving", "comment": "8 pages, 6 figures. Codes and videos are available at\n  https://wjiawei.com/terasim-world-web/", "summary": "Safe and scalable deployment of end-to-end (E2E) autonomous driving requires\nextensive and diverse data, particularly safety-critical events. Existing data\nare mostly generated from simulators with a significant sim-to-real gap or\ncollected from on-road testing that is costly and unsafe. This paper presents\nTeraSim-World, an automated pipeline that synthesizes realistic and\ngeographically diverse safety-critical data for E2E autonomous driving at\nanywhere in the world. Starting from an arbitrary location, TeraSim-World\nretrieves real-world maps and traffic demand from geospatial data sources.\nThen, it simulates agent behaviors from naturalistic driving datasets, and\norchestrates diverse adversities to create corner cases. Informed by street\nviews of the same location, it achieves photorealistic, geographically grounded\nsensor rendering via the frontier video generation model Cosmos-Drive. By\nbridging agent and sensor simulations, TeraSim-World provides a scalable and\ncritical~data synthesis framework for training and evaluation of E2E autonomous\ndriving systems.", "AI": {"tldr": "TeraSim-World\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u7528\u4e8e\u5728\u5168\u7403\u4efb\u4f55\u5730\u65b9\u5408\u6210\u771f\u5b9e\u4e14\u5730\u7406\u591a\u6837\u5316\u7684\u5b89\u5168\u5173\u952e\u6570\u636e\uff0c\u7528\u4e8e\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u4e3b\u8981\u6765\u81ea\u6a21\u62df\u5668\uff08\u5b58\u5728\u663e\u8457\u7684\u6a21\u62df\u5230\u771f\u5b9e\u5dee\u8ddd\uff09\u6216\u9053\u8def\u6d4b\u8bd5\uff08\u6210\u672c\u9ad8\u4e14\u4e0d\u5b89\u5168\uff09\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u751f\u6210\u5927\u89c4\u6a21\u3001\u591a\u6837\u5316\u5b89\u5168\u5173\u952e\u6570\u636e\u7684\u65b9\u6cd5\u3002", "method": "\u4ece\u4efb\u610f\u4f4d\u7f6e\u83b7\u53d6\u771f\u5b9e\u4e16\u754c\u5730\u56fe\u548c\u4ea4\u901a\u9700\u6c42\uff0c\u6a21\u62df\u81ea\u7136\u9a7e\u9a76\u6570\u636e\u96c6\u4e2d\u7684\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u7f16\u6392\u591a\u6837\u5316\u9006\u5883\u521b\u5efa\u6781\u7aef\u60c5\u51b5\uff0c\u5e76\u5229\u7528Cosmos-Drive\u89c6\u9891\u751f\u6210\u6a21\u578b\u5b9e\u73b0\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u7684\u5730\u7406\u4f20\u611f\u5668\u6e32\u67d3\u3002", "result": "TeraSim-World\u901a\u8fc7\u6865\u63a5\u667a\u80fd\u4f53\u548c\u4f20\u611f\u5668\u6a21\u62df\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5173\u952e\u6570\u636e\u5408\u6210\u6846\u67b6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4e3a\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u63d0\u4f9b\u5927\u89c4\u6a21\u3001\u771f\u5b9e\u4e14\u5730\u7406\u591a\u6837\u5316\u7684\u5b89\u5168\u5173\u952e\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u83b7\u53d6\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.12846", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.12846", "abs": "https://arxiv.org/abs/2509.12846", "authors": ["Junlin Song", "Antoine Richard", "Miguel Olivares-Mendez"], "title": "Unleashing the Power of Discrete-Time State Representation: Ultrafast Target-based IMU-Camera Spatial-Temporal Calibration", "comment": null, "summary": "Visual-inertial fusion is crucial for a large amount of intelligent and\nautonomous applications, such as robot navigation and augmented reality. To\nbootstrap and achieve optimal state estimation, the spatial-temporal\ndisplacements between IMU and cameras must be calibrated in advance. Most\nexisting calibration methods adopt continuous-time state representation, more\nspecifically the B-spline. Despite these methods achieve precise\nspatial-temporal calibration, they suffer from high computational cost caused\nby continuous-time state representation. To this end, we propose a novel and\nextremely efficient calibration method that unleashes the power of\ndiscrete-time state representation. Moreover, the weakness of discrete-time\nstate representation in temporal calibration is tackled in this paper. With the\nincreasing production of drones, cellphones and other visual-inertial\nplatforms, if one million devices need calibration around the world, saving one\nminute for the calibration of each device means saving 2083 work days in total.\nTo benefit both the research and industry communities, our code will be\nopen-source.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79bb\u6563\u65f6\u95f4\u72b6\u6001\u8868\u793a\u7684\u9ad8\u6548\u89c6\u89c9-\u60ef\u6027\u6807\u5b9a\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8fde\u7eed\u65f6\u95f4\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u540c\u65f6\u514b\u670d\u4e86\u79bb\u6563\u65f6\u95f4\u65b9\u6cd5\u5728\u65f6\u95f4\u6807\u5b9a\u65b9\u9762\u7684\u5f31\u70b9", "motivation": "\u89c6\u89c9-\u60ef\u6027\u878d\u5408\u5728\u673a\u5668\u4eba\u5bfc\u822a\u548c\u589e\u5f3a\u73b0\u5b9e\u7b49\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u57fa\u4e8eB\u6837\u6761\u7684\u8fde\u7eed\u65f6\u95f4\u6807\u5b9a\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u968f\u7740\u65e0\u4eba\u673a\u3001\u624b\u673a\u7b49\u89c6\u89c9-\u60ef\u6027\u5e73\u53f0\u7684\u5927\u91cf\u751f\u4ea7\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6807\u5b9a\u65b9\u6cd5\u6765\u8282\u7701\u8ba1\u7b97\u65f6\u95f4", "method": "\u91c7\u7528\u79bb\u6563\u65f6\u95f4\u72b6\u6001\u8868\u793a\u65b9\u6cd5\u8fdb\u884c\u7a7a\u95f4-\u65f6\u95f4\u6807\u5b9a\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u65b9\u5f0f\u89e3\u51b3\u4e86\u79bb\u6563\u65f6\u95f4\u65b9\u6cd5\u5728\u65f6\u95f4\u6807\u5b9a\u65b9\u9762\u7684\u5c40\u9650\u6027", "result": "\u5b9e\u73b0\u4e86\u6781\u5176\u9ad8\u6548\u7684\u6807\u5b9a\u8fc7\u7a0b\uff0c\u76f8\u6bd4\u8fde\u7eed\u65f6\u95f4\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6807\u5b9a\u7cbe\u5ea6", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u8bbe\u5907\u6807\u5b9a\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u4ee5\u60e0\u53ca\u7814\u7a76\u548c\u5de5\u4e1a\u754c\uff0c\u9884\u8ba1\u53ef\u4e3a\u767e\u4e07\u8bbe\u5907\u8282\u7701\u5927\u91cf\u8ba1\u7b97\u65f6\u95f4"}}
{"id": "2509.12875", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12875", "abs": "https://arxiv.org/abs/2509.12875", "authors": ["Jiaqi Wang", "Binquan Ji", "Haibo Luo", "Yiyang Qi", "Ruiting Li", "Huiyan Wang", "Yuantao Han", "Cangyi Yang", "jiaxu Zhang", "Feiliang Ren"], "title": "LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning", "comment": null, "summary": "Complex Reasoning in Large Language Models can be dynamically optimized using\nTest-Time Scaling (TTS) to mitigate Overthinking. Methods such as Coconut,\nSoftCoT and its variant are effective in continuous latent space inference, the\ncore bottleneck still lies in the efficient generation and utilization of\nhigh-quality Latent Thought. Drawing from the theory of SoftCoT++ that a larger\nvariance in the generated Latent Thought distribution more closely approximates\nthe golden truth distribution, we propose a Latent Thought-Augmented Training\nFramework--LTA-Thinker, which improves distributional variance and enhances\nreasoning performance from two perspectives. First, LTA-Thinker constructs a\nLatent Thought generation architecture based on a learnable prior. This\narchitecture aims to increase the variance distribution of generated Latent\nThought Vectors in order to simplify the overall structure and raise the\nperformance ceiling. Second, LTA-Thinker introduces a distribution-based\ndirectional optimization paradigm that jointly constrains both distribution\nlocality and distribution scale. This mechanism improves information efficiency\nand computational cost through a multi-objective co-training strategy, which\ncombines standard Supervised Fine-Tuning (SFT) loss with two novel losses:\nSemantic Alignment Loss, which utilizes KL divergence to ensure that the Latent\nThought is highly relevant to the semantics of the question; Reasoning Focus\nLoss, which utilizes a contrastive learning mechanism to guide the model to\nfocus on the most critical reasoning steps. Experiments show that LTA-thinker\nachieves state-of-the-art (SOTA) performance among various baselines and\ndemonstrates a higher performance ceiling and better scaling effects.", "AI": {"tldr": "LTA-Thinker\u662f\u4e00\u4e2a\u6f5c\u5728\u601d\u7ef4\u589e\u5f3a\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u52a0\u6f5c\u5728\u601d\u7ef4\u5206\u5e03\u7684\u65b9\u5dee\u548c\u5f15\u5165\u57fa\u4e8e\u5206\u5e03\u7684\u5b9a\u5411\u4f18\u5316\u8303\u5f0f\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982Coconut\u548cSoftCoT\u5728\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u63a8\u7406\u4e2d\u6709\u6548\uff0c\u4f46\u9ad8\u8d28\u91cf\u6f5c\u5728\u601d\u7ef4\u7684\u751f\u6210\u548c\u5229\u7528\u4ecd\u662f\u6838\u5fc3\u74f6\u9888\u3002SoftCoT++\u7406\u8bba\u8868\u660e\uff0c\u66f4\u5927\u7684\u6f5c\u5728\u601d\u7ef4\u5206\u5e03\u65b9\u5dee\u80fd\u66f4\u63a5\u8fd1\u771f\u5b9e\u5206\u5e03\u3002", "method": "1) \u57fa\u4e8e\u53ef\u5b66\u4e60\u5148\u9a8c\u6784\u5efa\u6f5c\u5728\u601d\u7ef4\u751f\u6210\u67b6\u6784\uff0c\u589e\u52a0\u751f\u6210\u5411\u91cf\u7684\u5206\u5e03\u65b9\u5dee\uff1b2) \u5f15\u5165\u57fa\u4e8e\u5206\u5e03\u7684\u5b9a\u5411\u4f18\u5316\u8303\u5f0f\uff0c\u7ed3\u5408SFT\u635f\u5931\u3001\u8bed\u4e49\u5bf9\u9f50\u635f\u5931\uff08KL\u6563\u5ea6\uff09\u548c\u63a8\u7406\u7126\u70b9\u635f\u5931\uff08\u5bf9\u6bd4\u5b66\u4e60\uff09\u8fdb\u884c\u591a\u76ee\u6807\u534f\u540c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLTA-Thinker\u5728\u5404\u79cd\u57fa\u7ebf\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6027\u80fd\u4e0a\u9650\u548c\u66f4\u597d\u7684\u6269\u5c55\u6548\u679c\u3002", "conclusion": "LTA-Thinker\u901a\u8fc7\u589e\u5f3a\u6f5c\u5728\u601d\u7ef4\u5206\u5e03\u65b9\u5dee\u548c\u4f18\u5316\u8bad\u7ec3\u8303\u5f0f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.12851", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12851", "abs": "https://arxiv.org/abs/2509.12851", "authors": ["Antoine L\u00e9nat", "Olivier Cheminat", "Damien Chablat", "Camilo Charron"], "title": "A Novel Skill Modeling Approach: Integrating Vergnaud's Scheme with Cognitive Architectures", "comment": null, "summary": "Human-machine interaction is increasingly important in industry, and this\ntrend will only intensify with the rise of Industry 5.0. Human operators have\nskills that need to be adapted when using machines to achieve the best results.\nIt is crucial to highlight the operator's skills and understand how they use\nand adapt them [18]. A rigorous description of these skills is necessary to\ncompare performance with and without robot assistance. Predicate logic, used by\nVergnaud within Piaget's scheme concept, offers a promising approach. However,\nthis theory doesn't account for cognitive system constraints, such as the\ntiming of actions, the limitation of cognitive resources, the parallelization\nof tasks, or the activation of automatic gestures contrary to optimal\nknowledge. Integrating these constraints is essential for representing agent\nskills understanding skill transfer between biological and mechanical\nstructures. Cognitive architectures models [2] address these needs by\ndescribing cognitive structure and can be combined with the scheme for mutual\nbenefit. Welding provides a relevant case study, as it highlights the\nchallenges faced by operators, even highly skilled ones. Welding's complexity\nstems from the need for constant skill adaptation to variable parameters like\npart position and process. This adaptation is crucial, as weld quality, a key\nfactor, is only assessed afterward via destructive testing. Thus, the welder is\nconfronted with a complex perception-decision-action cycle, where the\nevaluation of the impact of his actions is delayed and where errors are\ndefinitive. This dynamic underscores the importance of understanding and\nmodeling the skills of operators.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4eba\u673a\u4ea4\u4e92\u4e2d\u64cd\u4f5c\u5458\u6280\u80fd\u5efa\u6a21\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u5728\u710a\u63a5\u7b49\u590d\u6742\u5de5\u4e1a\u573a\u666f\u4e2d\uff0c\u63d0\u51fa\u5c06\u8c13\u8bcd\u903b\u8f91\u4e0e\u8ba4\u77e5\u67b6\u6784\u7ed3\u5408\u6765\u89e3\u51b3\u6280\u80fd\u8868\u793a\u548c\u8f6c\u79fb\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5de5\u4e1a5.0\u7684\u53d1\u5c55\uff0c\u9700\u8981\u66f4\u597d\u5730\u7406\u89e3\u548c\u5efa\u6a21\u4eba\u7c7b\u64cd\u4f5c\u5458\u7684\u6280\u80fd\uff0c\u4ee5\u4fbf\u5728\u4eba\u673a\u534f\u4f5c\u4e2d\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u3002\u7279\u522b\u662f\u5728\u710a\u63a5\u7b49\u590d\u6742\u4efb\u52a1\u4e2d\uff0c\u64cd\u4f5c\u5458\u9700\u8981\u4e0d\u65ad\u9002\u5e94\u53d8\u5316\u7684\u6761\u4ef6\uff0c\u4f46\u73b0\u6709\u7406\u8bba\u672a\u80fd\u5145\u5206\u8003\u8651\u8ba4\u77e5\u7cfb\u7edf\u7ea6\u675f\u3002", "method": "\u63d0\u51fa\u5c06Vergnaud\u57fa\u4e8e\u76ae\u4e9a\u6770\u56fe\u5f0f\u6982\u5ff5\u7684\u8c13\u8bcd\u903b\u8f91\u65b9\u6cd5\u4e0e\u8ba4\u77e5\u67b6\u6784\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u4ee5\u540c\u65f6\u5904\u7406\u6280\u80fd\u7684\u5f62\u5f0f\u5316\u63cf\u8ff0\u548c\u8ba4\u77e5\u7ea6\u675f\uff08\u5982\u65f6\u95f4\u9650\u5236\u3001\u8d44\u6e90\u9650\u5236\u3001\u4efb\u52a1\u5e76\u884c\u5316\u7b49\uff09\u3002\u710a\u63a5\u88ab\u7528\u4f5c\u6848\u4f8b\u7814\u7a76\u6765\u8bf4\u660e\u8fd9\u4e00\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u7ed3\u5408\u8c13\u8bcd\u903b\u8f91\u548c\u8ba4\u77e5\u67b6\u6784\u53ef\u4ee5\u66f4\u5168\u9762\u5730\u8868\u793a\u64cd\u4f5c\u5458\u6280\u80fd\uff0c\u5e76\u4fc3\u8fdb\u751f\u7269\u7cfb\u7edf\u4e0e\u673a\u68b0\u7cfb\u7edf\u4e4b\u95f4\u7684\u6280\u80fd\u8f6c\u79fb\u3002\u710a\u63a5\u6848\u4f8b\u51f8\u663e\u4e86\u64cd\u4f5c\u5458\u5728\u5ef6\u8fdf\u53cd\u9988\u548c\u786e\u5b9a\u6027\u9519\u8bef\u73af\u5883\u4e0b\u9762\u4e34\u7684\u611f\u77e5-\u51b3\u7b56-\u884c\u52a8\u5faa\u73af\u6311\u6218\u3002", "conclusion": "\u6574\u5408\u8c13\u8bcd\u903b\u8f91\u548c\u8ba4\u77e5\u67b6\u6784\u4e3a\u5efa\u6a21\u4eba\u7c7b\u64cd\u4f5c\u5458\u6280\u80fd\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6846\u67b6\uff0c\u8fd9\u5bf9\u4e8e\u5de5\u4e1a5.0\u65f6\u4ee3\u7684\u4eba\u673a\u534f\u4f5c\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u5ea6\u9002\u5e94\u6027\u548c\u5373\u65f6\u51b3\u7b56\u7684\u590d\u6742\u5de5\u4e1a\u4efb\u52a1\u4e2d\u3002"}}
{"id": "2509.12914", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12914", "abs": "https://arxiv.org/abs/2509.12914", "authors": ["Tairan Fu", "David Campo-Nazareno", "Javier Coronado-Bl\u00e1zquez", "Javier Conde", "Pedro Reviriego", "Fabrizio Lombardi"], "title": "Stochastic Streets: A Walk Through Random LLM Address Generation in four European Cities", "comment": null, "summary": "Large Language Models (LLMs) are capable of solving complex math problems or\nanswer difficult questions on almost any topic, but can they generate random\nstreet addresses for European cities?", "AI": {"tldr": "LLMs\u5728\u751f\u6210\u6b27\u6d32\u57ce\u5e02\u968f\u673a\u8857\u9053\u5730\u5740\u65b9\u9762\u5b58\u5728\u56f0\u96be", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u6570\u5b66\u95ee\u9898\u548c\u56de\u7b54\u5404\u79cd\u96be\u9898\uff0c\u4f46\u7814\u7a76\u8005\u53d1\u73b0\u5b83\u4eec\u5728\u751f\u6210\u770b\u4f3c\u7b80\u5355\u7684\u968f\u673a\u8857\u9053\u5730\u5740\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u63ed\u793a\u4e86LLMs\u5728\u7279\u5b9a\u7c7b\u578b\u4fe1\u606f\u751f\u6210\u65b9\u9762\u7684\u5c40\u9650\u6027", "method": "\u901a\u8fc7\u6d4b\u8bd5LLMs\u751f\u6210\u6b27\u6d32\u57ce\u5e02\u968f\u673a\u8857\u9053\u5730\u5740\u7684\u80fd\u529b\u6765\u8bc4\u4f30\u5176\u4fe1\u606f\u751f\u6210\u7684\u771f\u5b9e\u6027\u548c\u968f\u673a\u6027", "result": "LLMs\u5728\u751f\u6210\u6b27\u6d32\u57ce\u5e02\u968f\u673a\u8857\u9053\u5730\u5740\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u6709\u6548\u4ea7\u751f\u771f\u5b9e\u4e14\u968f\u673a\u7684\u5730\u5740\u4fe1\u606f", "conclusion": "\u8be5\u7814\u7a76\u8868\u660eLLMs\u5728\u5904\u7406\u770b\u4f3c\u7b80\u5355\u4f46\u9700\u8981\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u548c\u968f\u673a\u751f\u6210\u80fd\u529b\u7684\u4efb\u52a1\u65f6\u5b58\u5728\u663e\u8457\u5c40\u9650\uff0c\u8fd9\u63d0\u9192\u6211\u4eec\u9700\u8981\u66f4\u5168\u9762\u5730\u8bc4\u4f30LLMs\u7684\u80fd\u529b\u8fb9\u754c"}}
{"id": "2509.12858", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12858", "abs": "https://arxiv.org/abs/2509.12858", "authors": ["Yidan Lu", "Rurui Yang", "Qiran Kou", "Mengting Chen", "Tao Fan", "Peter Cui", "Yinzhao Dong", "Peng Lu"], "title": "Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion", "comment": null, "summary": "Reinforcement learning has produced remarkable advances in humanoid\nlocomotion, yet a fundamental dilemma persists for real-world deployment:\npolicies must choose between the robustness of reactive proprioceptive control\nor the proactivity of complex, fragile perception-driven systems. This paper\nresolves this dilemma by introducing a paradigm that imbues a purely\nproprioceptive policy with proactive capabilities, achieving the foresight of\nperception without its deployment-time costs. Our core contribution is a\ncontrastive learning framework that compels the actor's latent state to encode\nprivileged environmental information from simulation. Crucially, this\n``distilled awareness\" empowers an adaptive gait clock, allowing the policy to\nproactively adjust its rhythm based on an inferred understanding of the\nterrain. This synergy resolves the classic trade-off between rigid, clocked\ngaits and unstable clock-free policies. We validate our approach with zero-shot\nsim-to-real transfer to a full-sized humanoid, demonstrating highly robust\nlocomotion over challenging terrains, including 30 cm high steps and 26.5{\\deg}\nslopes, proving the effectiveness of our method. Website:\nhttps://lu-yidan.github.io/cra-loco.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5c06\u73af\u5883\u4fe1\u606f\u84b8\u998f\u5230\u7eaf\u672c\u4f53\u611f\u77e5\u7b56\u7565\u4e2d\u7684\u65b9\u6cd5\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u4e3b\u52a8\u8c03\u6574\u6b65\u6001\u8282\u594f\uff0c\u5728\u4fdd\u6301\u53cd\u5e94\u6027\u63a7\u5236\u9c81\u68d2\u6027\u7684\u540c\u65f6\u83b7\u5f97\u611f\u77e5\u7cfb\u7edf\u7684\u524d\u77bb\u80fd\u529b", "motivation": "\u89e3\u51b3\u4eba\u5f62\u673a\u5668\u4eba\u8fd0\u52a8\u63a7\u5236\u4e2d\u7684\u6839\u672c\u56f0\u5883\uff1a\u53cd\u5e94\u6027\u672c\u4f53\u611f\u77e5\u63a7\u5236\u7684\u9c81\u68d2\u6027\u4e0e\u590d\u6742\u8106\u5f31\u611f\u77e5\u9a71\u52a8\u7cfb\u7edf\u7684\u4e3b\u52a8\u6027\u4e4b\u95f4\u7684\u6743\u8861", "method": "\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5f3a\u5236\u6267\u884c\u5668\u7684\u6f5c\u5728\u72b6\u6001\u7f16\u7801\u6765\u81ea\u4eff\u771f\u7684\u7279\u6743\u73af\u5883\u4fe1\u606f\uff0c\u901a\u8fc7\"\u84b8\u998f\u611f\u77e5\"\u8d4b\u80fd\u81ea\u9002\u5e94\u6b65\u6001\u65f6\u949f\uff0c\u4f7f\u7b56\u7565\u80fd\u591f\u6839\u636e\u5730\u5f62\u7406\u89e3\u4e3b\u52a8\u8c03\u6574\u8282\u594f", "result": "\u901a\u8fc7\u96f6\u6837\u672c\u4eff\u771f\u5230\u771f\u5b9e\u4e16\u754c\u8fc1\u79fb\uff0c\u5728\u5b8c\u6574\u5c3a\u5bf8\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u6210\u529f\u5e94\u5bf930\u5398\u7c73\u9ad8\u53f0\u9636\u548c26.5\u5ea6\u659c\u5761\u7b49\u6311\u6218\u6027\u5730\u5f62", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u521a\u6027\u65f6\u949f\u6b65\u6001\u4e0e\u4e0d\u7a33\u5b9a\u65e0\u65f6\u949f\u7b56\u7565\u4e4b\u95f4\u7684\u7ecf\u5178\u6743\u8861\uff0c\u5b9e\u73b0\u4e86\u65e2\u9c81\u68d2\u53c8\u5177\u6709\u524d\u77bb\u6027\u7684\u8fd0\u52a8\u63a7\u5236"}}
{"id": "2509.12926", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12926", "abs": "https://arxiv.org/abs/2509.12926", "authors": ["Jai Singla", "Peal Jotania", "Keivalya Pandya"], "title": "Population Estimation using Deep Learning over Gandhinagar Urban Area", "comment": null, "summary": "Population estimation is crucial for various applications, from resource\nallocation to urban planning. Traditional methods such as surveys and censuses\nare expensive, time-consuming and also heavily dependent on human resources,\nrequiring significant manpower for data collection and processing. In this\nstudy a deep learning solution is proposed to estimate population using high\nresolution (0.3 m) satellite imagery, Digital Elevation Models (DEM) of 0.5m\nresolution and vector boundaries. Proposed method combines Convolution Neural\nNetwork (CNN) architecture for classification task to classify buildings as\nresidential and non-residential and Artificial Neural Network (ANN)\narchitecture to estimate the population. Approx. 48k building footprints over\nGandhinagar urban area are utilized containing both residential and\nnon-residential, with residential categories further used for building-level\npopulation estimation. Experimental results on a large-scale dataset\ndemonstrate the effectiveness of our model, achieving an impressive overall\nF1-score of 0.9936. The proposed system employs advanced geospatial analysis\nwith high spatial resolution to estimate Gandhinagar population at 278,954. By\nintegrating real-time data updates, standardized metrics, and infrastructure\nplanning capabilities, this automated approach addresses critical limitations\nof conventional census-based methodologies. The framework provides\nmunicipalities with a scalable and replicable tool for optimized resource\nmanagement in rapidly urbanizing cities, showcasing the efficiency of AI-driven\ngeospatial analytics in enhancing data-driven urban governance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u81ea\u52a8\u5316\u4eba\u53e3\u4f30\u7b97\u65b9\u6cd5\uff0c\u4f7f\u7528\u9ad8\u5206\u8fa8\u7387\u536b\u661f\u5f71\u50cf\u3001\u6570\u5b57\u9ad8\u7a0b\u6a21\u578b\u548c\u5efa\u7b51\u8fb9\u754c\u6570\u636e\uff0c\u901a\u8fc7CNN\u5206\u7c7b\u5efa\u7b51\u7c7b\u578b\uff0cANN\u4f30\u7b97\u4eba\u53e3\uff0c\u5728Gandhinagar\u5730\u533a\u8fbe\u5230\u9ad8\u7cbe\u5ea6\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u4eba\u53e3\u666e\u67e5\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u4e14\u4f9d\u8d56\u5927\u91cf\u4eba\u529b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u5feb\u901f\u57ce\u5e02\u5316\u80cc\u666f\u4e0b\u7684\u4eba\u53e3\u4f30\u7b97\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u8fdb\u884c\u4f4f\u5b85/\u975e\u4f4f\u5b85\u5efa\u7b51\u5206\u7c7b\uff0c\u4f7f\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANN\uff09\u8fdb\u884c\u4eba\u53e3\u4f30\u7b97\uff0c\u6574\u54080.3\u7c73\u5206\u8fa8\u7387\u536b\u661f\u5f71\u50cf\u30010.5\u7c73\u5206\u8fa8\u7387\u6570\u5b57\u9ad8\u7a0b\u6a21\u578b\u548c\u77e2\u91cf\u8fb9\u754c\u6570\u636e\u3002", "result": "\u5728Gandhinagar\u57ce\u5e02\u533a\u57df48,000\u4e2a\u5efa\u7b51\u8db3\u8ff9\u4e0a\u6d4b\u8bd5\uff0c\u603b\u4f53F1-score\u8fbe\u52300.9936\uff0c\u4f30\u7b97\u4eba\u53e3\u4e3a278,954\u4eba\uff0c\u8868\u73b0\u51fa\u6781\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u81ea\u52a8\u5316\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5b9e\u65f6\u6570\u636e\u66f4\u65b0\u548c\u6807\u51c6\u5316\u6307\u6807\uff0c\u4e3a\u57ce\u5e02\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u590d\u5236\u7684\u8d44\u6e90\u7ba1\u7406\u5de5\u5177\uff0c\u5c55\u793a\u4e86AI\u9a71\u52a8\u7684\u5730\u7406\u7a7a\u95f4\u5206\u6790\u5728\u6570\u636e\u9a71\u52a8\u57ce\u5e02\u6cbb\u7406\u4e2d\u7684\u9ad8\u6548\u6027\u3002"}}
{"id": "2509.12863", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12863", "abs": "https://arxiv.org/abs/2509.12863", "authors": ["Haozhan Ni", "Jingsong Liang", "Chenyu He", "Yuhong Cao", "Guillaume Sartoretti"], "title": "GRATE: a Graph transformer-based deep Reinforcement learning Approach for Time-efficient autonomous robot Exploration", "comment": null, "summary": "Autonomous robot exploration (ARE) is the process of a robot autonomously\nnavigating and mapping an unknown environment. Recent Reinforcement Learning\n(RL)-based approaches typically formulate ARE as a sequential decision-making\nproblem defined on a collision-free informative graph. However, these methods\noften demonstrate limited reasoning ability over graph-structured data.\nMoreover, due to the insufficient consideration of robot motion, the resulting\nRL policies are generally optimized to minimize travel distance, while\nneglecting time efficiency. To overcome these limitations, we propose GRATE, a\nDeep Reinforcement Learning (DRL)-based approach that leverages a Graph\nTransformer to effectively capture both local structure patterns and global\ncontextual dependencies of the informative graph, thereby enhancing the model's\nreasoning capability across the entire environment. In addition, we deploy a\nKalman filter to smooth the waypoint outputs, ensuring that the resulting path\nis kinodynamically feasible for the robot to follow. Experimental results\ndemonstrate that our method exhibits better exploration efficiency (up to 21.5%\nin distance and 21.3% in time to complete exploration) than state-of-the-art\nconventional and learning-based baselines in various simulation benchmarks. We\nalso validate our planner in real-world scenarios.", "AI": {"tldr": "GRATE\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u4e3b\u673a\u5668\u4eba\u63a2\u7d22\u65b9\u6cd5\uff0c\u4f7f\u7528\u56feTransformer\u589e\u5f3a\u73af\u5883\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5361\u5c14\u66fc\u6ee4\u6ce2\u786e\u4fdd\u8fd0\u52a8\u53ef\u884c\u6027\uff0c\u5728\u8ddd\u79bb\u548c\u65f6\u95f4\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u4e3b\u63a2\u7d22\u65b9\u6cd5\u5728\u56fe\u7ed3\u6784\u6570\u636e\u5904\u7406\u80fd\u529b\u6709\u9650\uff0c\u4e14\u672a\u5145\u5206\u8003\u8651\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u7ea6\u675f\uff0c\u5bfc\u81f4\u4e3b\u8981\u4f18\u5316\u8ddd\u79bb\u800c\u5ffd\u89c6\u65f6\u95f4\u6548\u7387\u3002", "method": "\u63d0\u51faGRATE\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u56feTransformer\u6355\u6349\u4fe1\u606f\u56fe\u7684\u5c40\u90e8\u7ed3\u6784\u6a21\u5f0f\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u4f9d\u8d56\uff1b2\uff09\u90e8\u7f72\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5e73\u6ed1\u8def\u5f84\u70b9\u8f93\u51fa\uff0c\u786e\u4fdd\u8fd0\u52a8\u5b66\u53ef\u884c\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u4eff\u771f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u4f20\u7edf\u548c\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63a2\u7d22\u6548\u7387\u63d0\u5347\u8fbe21.5%\uff08\u8ddd\u79bb\uff09\u548c21.3%\uff08\u65f6\u95f4\uff09\uff0c\u5e76\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u6709\u6548\u3002", "conclusion": "GRATE\u901a\u8fc7\u7ed3\u5408\u56feTransformer\u548c\u8fd0\u52a8\u5b66\u7ea6\u675f\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u4e3b\u673a\u5668\u4eba\u63a2\u7d22\u7684\u6548\u7387\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12927", "categories": ["cs.AI", "cs.CV", "cs.GT", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.12927", "abs": "https://arxiv.org/abs/2509.12927", "authors": ["Xingxing Hong", "Yungong Wang", "Dexin Jin", "Ye Yuan", "Ximing Huang", "Zijian Wu", "Wenxin Li"], "title": "HLSMAC: A New StarCraft Multi-Agent Challenge for High-Level Strategic Decision-Making", "comment": "30 pages, 13 figures with appendix", "summary": "Benchmarks are crucial for assessing multi-agent reinforcement learning\n(MARL) algorithms. While StarCraft II-related environments have driven\nsignificant advances in MARL, existing benchmarks like SMAC focus primarily on\nmicromanagement, limiting comprehensive evaluation of high-level strategic\nintelligence. To address this, we introduce HLSMAC, a new cooperative MARL\nbenchmark with 12 carefully designed StarCraft II scenarios based on classical\nstratagems from the Thirty-Six Stratagems. Each scenario corresponds to a\nspecific stratagem and is designed to challenge agents with diverse strategic\nelements, including tactical maneuvering, timing coordination, and deception,\nthereby opening up avenues for evaluating high-level strategic decision-making\ncapabilities. We also propose novel metrics across multiple dimensions beyond\nconventional win rate, such as ability utilization and advancement efficiency,\nto assess agents' overall performance within the HLSMAC environment. We\nintegrate state-of-the-art MARL algorithms and LLM-based agents with our\nbenchmark and conduct comprehensive experiments. The results demonstrate that\nHLSMAC serves as a robust testbed for advancing multi-agent strategic\ndecision-making.", "AI": {"tldr": "HLSMAC\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\uff0c\u57fa\u4e8e\u4e09\u5341\u516d\u8ba1\u8bbe\u8ba1\u4e8612\u4e2a\u661f\u9645\u4e89\u9738II\u573a\u666f\uff0c\u7528\u4e8e\u8bc4\u4f30\u9ad8\u7ea7\u6218\u7565\u51b3\u7b56\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u5fae\u64cd\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709MARL\u57fa\u51c6\u5982SMAC\u4e3b\u8981\u5173\u6ce8\u5fae\u64cd\u5c42\u9762\uff0c\u7f3a\u4e4f\u5bf9\u9ad8\u7ea7\u6218\u7565\u667a\u80fd\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u9700\u8981\u65b0\u7684\u6d4b\u8bd5\u73af\u5883\u6765\u63a8\u52a8\u591a\u667a\u80fd\u4f53\u6218\u7565\u51b3\u7b56\u80fd\u529b\u7684\u53d1\u5c55\u3002", "method": "\u57fa\u4e8e\u4e09\u5341\u516d\u8ba1\u8bbe\u8ba1\u4e8612\u4e2a\u661f\u9645\u4e89\u9738II\u573a\u666f\uff0c\u6bcf\u4e2a\u5bf9\u5e94\u4e00\u4e2a\u7279\u5b9a\u8ba1\u8c0b\uff0c\u5305\u542b\u6218\u672f\u673a\u52a8\u3001\u65f6\u673a\u534f\u8c03\u548c\u6b3a\u9a97\u7b49\u6218\u7565\u5143\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u8d85\u8d8a\u80dc\u7387\u7684\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eHLSMAC\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u6218\u7565\u51b3\u7b56\u80fd\u529b\uff0c\u4e3a\u5148\u8fdbMARL\u7b97\u6cd5\u548c\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "conclusion": "HLSMAC\u586b\u8865\u4e86MARL\u57fa\u51c6\u5728\u9ad8\u7ea7\u6218\u7565\u8bc4\u4f30\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u6218\u7565\u51b3\u7b56\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u6d4b\u8bd5\u73af\u5883\u548c\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2509.12880", "categories": ["cs.RO", "cs.HC", "cs.LG", "68T05, 68T40", "I.2.9; I.2.6; H.5.2"], "pdf": "https://arxiv.org/pdf/2509.12880", "abs": "https://arxiv.org/abs/2509.12880", "authors": ["Anna Deichler", "Siyang Wang", "Simon Alexanderson", "Jonas Beskow"], "title": "Towards Context-Aware Human-like Pointing Gestures with RL Motion Imitation", "comment": "Presented at the Context-Awareness in HRI (CONAWA) Workshop, ACM/IEEE\n  International Conference on Human-Robot Interaction (HRI 2022), March 7, 2022", "summary": "Pointing is a key mode of interaction with robots, yet most prior work has\nfocused on recognition rather than generation. We present a motion capture\ndataset of human pointing gestures covering diverse styles, handedness, and\nspatial targets. Using reinforcement learning with motion imitation, we train\npolicies that reproduce human-like pointing while maximizing precision. Results\nshow our approach enables context-aware pointing behaviors in simulation,\nbalancing task performance with natural dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u52a8\u4f5c\u6355\u6349\u6570\u636e\u7684\u4eba\u7c7b\u6307\u5411\u624b\u52bf\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u80fd\u591f\u751f\u6210\u7cbe\u786e\u4e14\u81ea\u7136\u7684\u673a\u5668\u4eba\u6307\u5411\u52a8\u4f5c\u7684\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6307\u5411\u624b\u52bf\u7684\u8bc6\u522b\u800c\u975e\u751f\u6210\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4ea7\u751f\u4eba\u7c7b\u5316\u3001\u7cbe\u786e\u7684\u6307\u5411\u52a8\u4f5c\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u3002", "method": "\u6536\u96c6\u4e86\u5305\u542b\u591a\u79cd\u98ce\u683c\u3001\u624b\u6027\u548c\u7a7a\u95f4\u76ee\u6807\u7684\u4eba\u7c7b\u6307\u5411\u624b\u52bf\u52a8\u4f5c\u6355\u6349\u6570\u636e\u96c6\uff0c\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u52a8\u4f5c\u6a21\u4eff\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u4eff\u771f\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6307\u5411\u884c\u4e3a\uff0c\u80fd\u591f\u5728\u4efb\u52a1\u6027\u80fd\u548c\u81ea\u7136\u52a8\u6001\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u751f\u6210\u4e86\u65e2\u7cbe\u786e\u53c8\u81ea\u7136\u7684\u673a\u5668\u4eba\u6307\u5411\u52a8\u4f5c\uff0c\u4e3a\u673a\u5668\u4eba\u6307\u5411\u52a8\u4f5c\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12934", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12934", "abs": "https://arxiv.org/abs/2509.12934", "authors": ["Jeremias Ferrao", "Matthijs van der Lende", "Ilija Lichkovski", "Clement Neo"], "title": "The Anatomy of Alignment: Decomposing Preference Optimization by Steering Sparse Features", "comment": "Work in Progress", "summary": "Aligning large language models is critical for their usability and safety.\nHowever, the prevailing approach of Reinforcement Learning from Human Feedback\n(RLHF) induces diffuse, opaque parameter changes, making it difficult to\ndiscern what the model has internalized. Hence, we introduce Feature Steering\nwith Reinforcement Learning (FSRL), a transparent alignment framework that\ntrains a lightweight adapter to steer behavior by modulating interpretable\nfeatures from a Sparse Autoencoder (SAE). First, we demonstrate that FSRL is an\neffective method for preference optimization and is comparable with current\nRLHF methods. We then perform mechanistic analysis on the trained adapter, and\nfind that its policy systematically promotes style features over explicit\nalignment concepts, suggesting that the preference optimization process rewards\nstylistic presentation as a proxy for quality. Ultimately, we hope that FSRL\nprovides a tool for both interpretable model control and diagnosing the\ninternal mechanisms of alignment.", "AI": {"tldr": "FSRL\u662f\u4e00\u79cd\u900f\u660e\u5bf9\u9f50\u6846\u67b6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u901a\u8fc7\u8c03\u8282\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u53ef\u89e3\u91ca\u7279\u5f81\u6765\u5f15\u5bfcLLM\u884c\u4e3a\uff0c\u6548\u679c\u4e0eRLHF\u76f8\u5f53\u4f46\u66f4\u6613\u89e3\u91ca\u3002", "motivation": "RLHF\u65b9\u6cd5\u5bfc\u81f4\u53c2\u6570\u53d8\u5316\u4e0d\u900f\u660e\uff0c\u96be\u4ee5\u7406\u89e3\u6a21\u578b\u5185\u5316\u4e86\u4ec0\u4e48\uff0c\u9700\u8981\u66f4\u900f\u660e\u7684\u5bf9\u9f50\u65b9\u6cd5\u6765\u8bca\u65ad\u5bf9\u9f50\u673a\u5236\u3002", "method": "\u4f7f\u7528\u7279\u5f81\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60(FSRL)\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6765\u8c03\u8282\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAE)\u7684\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u5b9e\u73b0\u884c\u4e3a\u5f15\u5bfc\u3002", "result": "FSRL\u5728\u504f\u597d\u4f18\u5316\u65b9\u9762\u4e0e\u73b0\u6709RLHF\u65b9\u6cd5\u6548\u679c\u76f8\u5f53\uff0c\u673a\u5236\u5206\u6790\u53d1\u73b0\u9002\u914d\u5668\u7b56\u7565\u7cfb\u7edf\u6027\u5730\u4fc3\u8fdb\u98ce\u683c\u7279\u5f81\u800c\u975e\u663e\u5f0f\u5bf9\u9f50\u6982\u5ff5\u3002", "conclusion": "FSRL\u4e3a\u53ef\u89e3\u91ca\u6a21\u578b\u63a7\u5236\u548c\u8bca\u65ad\u5bf9\u9f50\u673a\u5236\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u53d1\u73b0\u504f\u597d\u4f18\u5316\u8fc7\u7a0b\u5c06\u98ce\u683c\u5448\u73b0\u4f5c\u4e3a\u8d28\u91cf\u7684\u4ee3\u7406\u8fdb\u884c\u5956\u52b1\u3002"}}
{"id": "2509.12890", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12890", "abs": "https://arxiv.org/abs/2509.12890", "authors": ["Malte Probst", "Raphael Wenzel", "Monica Dasi"], "title": "Responsibility and Engagement -- Evaluating Interactions in Social Robot Navigation", "comment": "under review for 2026 IEEE International Conference on Robotics &\n  Automation (ICRA)", "summary": "In Social Robot Navigation (SRN), the availability of meaningful metrics is\ncrucial for evaluating trajectories from human-robot interactions. In the SRN\ncontext, such interactions often relate to resolving conflicts between two or\nmore agents. Correspondingly, the shares to which agents contribute to the\nresolution of such conflicts are important. This paper builds on recent work,\nwhich proposed a Responsibility metric capturing such shares. We extend this\nframework in two directions: First, we model the conflict buildup phase by\nintroducing a time normalization. Second, we propose the related Engagement\nmetric, which captures how the agents' actions intensify a conflict. In a\ncomprehensive series of simulated scenarios with dyadic, group and crowd\ninteractions, we show that the metrics carry meaningful information about the\ncooperative resolution of conflicts in interactions. They can be used to assess\nbehavior quality and foresightedness. We extensively discuss applicability,\ndesign choices and limitations of the proposed metrics.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u793e\u4ea4\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u7684\u8d23\u4efb\u5ea6\u91cf\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u65f6\u95f4\u5f52\u4e00\u5316\u5efa\u6a21\u51b2\u7a81\u79ef\u7d2f\u9636\u6bb5\uff0c\u5e76\u5f15\u5165\u4e86\u65b0\u7684\u53c2\u4e0e\u5ea6\u5ea6\u91cf\u6765\u6355\u6349\u51b2\u7a81\u5f3a\u5ea6\u53d8\u5316\u3002\u901a\u8fc7\u6a21\u62df\u573a\u666f\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u5ea6\u91cf\u5728\u8bc4\u4f30\u4ea4\u4e92\u51b2\u7a81\u89e3\u51b3\u8d28\u91cf\u548c\u524d\u77bb\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u793e\u4ea4\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u9700\u8981\u6709\u6548\u7684\u5ea6\u91cf\u6807\u51c6\u6765\u8bc4\u4f30\u4eba\u673a\u4ea4\u4e92\u8f68\u8ff9\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u51b2\u7a81\u89e3\u51b3\u573a\u666f\u4e2d\uff0c\u91cf\u5316\u5404\u667a\u80fd\u4f53\u5bf9\u51b2\u7a81\u89e3\u51b3\u7684\u8d21\u732e\u7a0b\u5ea6\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6269\u5c55\u73b0\u6709\u8d23\u4efb\u5ea6\u91cf\u6846\u67b6\uff0c\u5f15\u5165\u65f6\u95f4\u5f52\u4e00\u5316\u6765\u5efa\u6a21\u51b2\u7a81\u79ef\u7d2f\u9636\u6bb5\uff0c\u5e76\u63d0\u51fa\u53c2\u4e0e\u5ea6\u5ea6\u91cf\u6765\u6355\u6349\u667a\u80fd\u4f53\u884c\u4e3a\u5bf9\u51b2\u7a81\u5f3a\u5ea6\u7684\u589e\u5f3a\u4f5c\u7528\u3002\u901a\u8fc7\u6a21\u62df\u4e8c\u5143\u3001\u7fa4\u4f53\u548c\u4eba\u7fa4\u4ea4\u4e92\u573a\u666f\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u5ea6\u91cf\u80fd\u591f\u6709\u6548\u53cd\u6620\u4ea4\u4e92\u4e2d\u51b2\u7a81\u89e3\u51b3\u7684\u5408\u4f5c\u6027\u8d28\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u884c\u4e3a\u8d28\u91cf\u548c\u524d\u77bb\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8d23\u4efb\u548c\u53c2\u4e0e\u5ea6\u5ea6\u91cf\u4e3a\u793e\u4ea4\u673a\u5668\u4eba\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u80fd\u591f\u91cf\u5316\u667a\u80fd\u4f53\u5728\u51b2\u7a81\u89e3\u51b3\u4e2d\u7684\u8d21\u732e\u548c\u51b2\u7a81\u5f3a\u5ea6\u53d8\u5316\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u8ba8\u8bba\u5176\u9002\u7528\u6027\u3001\u8bbe\u8ba1\u9009\u62e9\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2509.12951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12951", "abs": "https://arxiv.org/abs/2509.12951", "authors": ["Shilian Chen", "Jie Zhou", "Tianyu Huai", "Yujiang Lu", "Junsong Li", "Bihao Zhan", "Qianjun Pan", "Yutao Yang", "Xin Li", "Qin Chen", "Hang Yan", "Liang He"], "title": "Black-box Model Merging for Language-Model-as-a-Service with Massive Model Repositories", "comment": null, "summary": "Model merging refers to the process of integrating multiple distinct models\ninto a unified model that preserves and combines the strengths and capabilities\nof the individual models. Most existing approaches rely on task vectors to\ncombine models, typically under the assumption that model parameters are\naccessible. However, for extremely large language models (LLMs) such as GPT-4,\nwhich are often provided solely as black-box services through API interfaces\n(Language-Model-as-a-Service), model weights are not available to end users.\nThis presents a significant challenge, which we refer to as black-box model\nmerging (BMM) with massive LLMs. To address this challenge, we propose a\nderivative-free optimization framework based on the evolutionary algorithm\n(Evo-Merging) that enables effective model merging using only inference-time\nAPI queries. Our method consists of two key components: (1) sparsity-based\ndenoising, designed to identify and filter out irrelevant or redundant\ninformation across models, and (2) sign-aware scaling, which dynamically\ncomputes optimal combination weights for the relevant models based on their\nperformance. We also provide a formal justification, along with a theoretical\nanalysis, for our asymmetric sparsification. Extensive experimental evaluations\ndemonstrate that our approach achieves state-of-the-art results on a range of\ntasks, significantly outperforming existing strong baselines.", "AI": {"tldr": "\u63d0\u51faEvo-Merging\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u5b9e\u73b0\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u7684\u878d\u5408\uff0c\u4ec5\u9700\u63a8\u7406API\u67e5\u8be2\uff0c\u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u6743\u91cd", "motivation": "\u73b0\u6709\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u9700\u8981\u8bbf\u95ee\u6a21\u578b\u53c2\u6570\uff0c\u4f46\u5bf9\u4e8eGPT-4\u7b49\u4ec5\u63d0\u4f9bAPI\u670d\u52a1\u7684\u9ed1\u76d2\u5927\u6a21\u578b\uff0c\u65e0\u6cd5\u83b7\u53d6\u6743\u91cd\u53c2\u6570\uff0c\u9700\u8981\u89e3\u51b3\u9ed1\u76d2\u6a21\u578b\u878d\u5408\u7684\u6311\u6218", "method": "\u57fa\u4e8e\u8fdb\u5316\u7b97\u6cd5\u7684\u65e0\u5bfc\u6570\u4f18\u5316\u6846\u67b6\uff0c\u5305\u542b\u7a00\u758f\u6027\u53bb\u566a\u548c\u7b26\u53f7\u611f\u77e5\u7f29\u653e\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff0c\u901a\u8fc7API\u67e5\u8be2\u5b9e\u73b0\u6a21\u578b\u878d\u5408", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "Evo-Merging\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u95ee\u9898\uff0c\u4e3a\u4ec5\u901a\u8fc7API\u8bbf\u95ee\u7684\u6a21\u578b\u96c6\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2509.12912", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12912", "abs": "https://arxiv.org/abs/2509.12912", "authors": ["Raphael Wenzel", "Malte Probst"], "title": "Spotting the Unfriendly Robot -- Towards better Metrics for Interactions", "comment": "Presented at 2025 IEEE Conference on Robotics and Automation (ICRA)\n  Workshop: Advances in Social Navigation: Planning, HRI and Beyond", "summary": "Establishing standardized metrics for Social Robot Navigation (SRN)\nalgorithms for assessing the quality and social compliance of robot behavior\naround humans is essential for SRN research. Currently, commonly used\nevaluation metrics lack the ability to quantify how cooperative an agent\nbehaves in interaction with humans. Concretely, in a simple frontal approach\nscenario, no metric specifically captures if both agents cooperate or if one\nagent stays on collision course and the other agent is forced to evade. To\naddress this limitation, we propose two new metrics, a conflict intensity\nmetric and the responsibility metric. Together, these metrics are capable of\nevaluating the quality of human-robot interactions by showing how much a given\nalgorithm has contributed to reducing a conflict and which agent actually took\nresponsibility of the resolution. This work aims to contribute to the\ndevelopment of a comprehensive and standardized evaluation methodology for SRN,\nultimately enhancing the safety, efficiency, and social acceptance of robots in\nhuman-centric environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u7684\u793e\u4ea4\u673a\u5668\u4eba\u5bfc\u822a\u8bc4\u4f30\u6307\u6807\uff1a\u51b2\u7a81\u5f3a\u5ea6\u6307\u6807\u548c\u8d23\u4efb\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316\u673a\u5668\u4eba\u5728\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u4e2d\u7684\u5408\u4f5c\u884c\u4e3a\uff0c\u89e3\u51b3\u73b0\u6709\u6307\u6807\u65e0\u6cd5\u8bc4\u4f30\u5408\u4f5c\u7a0b\u5ea6\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u793e\u4ea4\u673a\u5668\u4eba\u5bfc\u822a\u7814\u7a76\u4e2d\u7f3a\u4e4f\u80fd\u591f\u91cf\u5316\u673a\u5668\u4eba\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u4e2d\u5408\u4f5c\u884c\u4e3a\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u6307\u6807\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u9762\u7684\u7b80\u5355\u63a5\u8fd1\u573a\u666f\u4e2d\uff0c\u65e0\u6cd5\u533a\u5206\u662f\u53cc\u65b9\u5408\u4f5c\u8fd8\u662f\u4e00\u65b9\u88ab\u8feb\u907f\u8ba9\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u6307\u6807\uff1a\u51b2\u7a81\u5f3a\u5ea6\u6307\u6807\u7528\u4e8e\u8bc4\u4f30\u51b2\u7a81\u7684\u4e25\u91cd\u7a0b\u5ea6\uff0c\u8d23\u4efb\u6307\u6807\u7528\u4e8e\u786e\u5b9a\u54ea\u4e2a\u4e3b\u4f53\uff08\u673a\u5668\u4eba\u6216\u4eba\u7c7b\uff09\u627f\u62c5\u4e86\u89e3\u51b3\u51b2\u7a81\u7684\u4e3b\u8981\u8d23\u4efb\u3002", "result": "\u65b0\u6307\u6807\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u4eba\u673a\u4ea4\u4e92\u8d28\u91cf\uff0c\u663e\u793a\u7b97\u6cd5\u5728\u51cf\u5c11\u51b2\u7a81\u4e2d\u7684\u8d21\u732e\u7a0b\u5ea6\uff0c\u5e76\u660e\u786e\u8d23\u4efb\u5f52\u5c5e\u3002", "conclusion": "\u8fd9\u4e9b\u6307\u6807\u6709\u52a9\u4e8e\u5efa\u7acb\u5168\u9762\u6807\u51c6\u5316\u7684\u793e\u4ea4\u673a\u5668\u4eba\u5bfc\u822a\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6700\u7ec8\u63d0\u5347\u673a\u5668\u4eba\u5728\u4eba\u672c\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u3001\u6548\u7387\u548c\u793e\u4ea4\u63a5\u53d7\u5ea6\u3002"}}
{"id": "2509.12958", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12958", "abs": "https://arxiv.org/abs/2509.12958", "authors": ["Bihao Zhan", "Jie Zhou", "Junsong Li", "Yutao Yang", "Shilian Chen", "Qianjun Pan", "Xin Li", "Wen Wu", "Xingjiao Wu", "Qin Chen", "Hang Yan", "Liang He"], "title": "Forget What's Sensitive, Remember What Matters: Token-Level Differential Privacy in Memory Sculpting for Continual Learning", "comment": null, "summary": "Continual Learning (CL) models, while adept at sequential knowledge\nacquisition, face significant and often overlooked privacy challenges due to\naccumulating diverse information. Traditional privacy methods, like a uniform\nDifferential Privacy (DP) budget, indiscriminately protect all data, leading to\nsubstantial model utility degradation and hindering CL deployment in\nprivacy-sensitive areas. To overcome this, we propose a privacy-enhanced\ncontinual learning (PeCL) framework that forgets what's sensitive and remembers\nwhat matters. Our approach first introduces a token-level dynamic Differential\nPrivacy strategy that adaptively allocates privacy budgets based on the\nsemantic sensitivity of individual tokens. This ensures robust protection for\nprivate entities while minimizing noise injection for non-sensitive, general\nknowledge. Second, we integrate a privacy-guided memory sculpting module. This\nmodule leverages the sensitivity analysis from our dynamic DP mechanism to\nintelligently forget sensitive information from the model's memory and\nparameters, while explicitly preserving the task-invariant historical knowledge\ncrucial for mitigating catastrophic forgetting. Extensive experiments show that\nPeCL achieves a superior balance between privacy preserving and model utility,\noutperforming baseline models by maintaining high accuracy on previous tasks\nwhile ensuring robust privacy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9690\u79c1\u589e\u5f3a\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6PeCL\uff0c\u901a\u8fc7\u52a8\u6001\u5dee\u5206\u9690\u79c1\u7b56\u7565\u548c\u9690\u79c1\u5f15\u5bfc\u7684\u8bb0\u5fc6\u96d5\u523b\u6a21\u5757\uff0c\u5728\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd", "motivation": "\u4f20\u7edf\u6301\u7eed\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u4e25\u91cd\u7684\u9690\u79c1\u6311\u6218\uff0c\u7edf\u4e00\u7684\u5dee\u5206\u9690\u79c1\u9884\u7b97\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u963b\u788d\u5728\u9690\u79c1\u654f\u611f\u9886\u57df\u7684\u90e8\u7f72", "method": "1) \u5f15\u5165token\u7ea7\u52a8\u6001\u5dee\u5206\u9690\u79c1\u7b56\u7565\uff0c\u6839\u636e\u8bed\u4e49\u654f\u611f\u5ea6\u81ea\u9002\u5e94\u5206\u914d\u9690\u79c1\u9884\u7b97\uff1b2) \u96c6\u6210\u9690\u79c1\u5f15\u5bfc\u7684\u8bb0\u5fc6\u96d5\u523b\u6a21\u5757\uff0c\u667a\u80fd\u9057\u5fd8\u654f\u611f\u4fe1\u606f\u540c\u65f6\u4fdd\u7559\u4efb\u52a1\u4e0d\u53d8\u7684\u5386\u53f2\u77e5\u8bc6", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660ePeCL\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u6a21\u578b\u6548\u7528\u4e4b\u95f4\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u5e73\u8861\uff0c\u5728\u4fdd\u6301\u5148\u524d\u4efb\u52a1\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u786e\u4fdd\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4", "conclusion": "PeCL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u6311\u6218\uff0c\u4e3a\u9690\u79c1\u654f\u611f\u9886\u57df\u7684\u6301\u7eed\u5b66\u4e60\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.12928", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12928", "abs": "https://arxiv.org/abs/2509.12928", "authors": ["Peiwen Yang", "Mingquan Jiang", "Xinyue Shen", "Heping Zhang"], "title": "Spatiotemporal Calibration for Laser Vision Sensor in Hand-eye System Based on Straight-line Constraint", "comment": "Submitted to IEEE RAL", "summary": "Laser vision sensors (LVS) are critical perception modules for industrial\nrobots, facilitating real-time acquisition of workpiece geometric data in\nwelding applications. However, the camera communication delay will lead to a\ntemporal desynchronization between captured images and the robot motions.\nAdditionally, hand-eye extrinsic parameters may vary during prolonged\nmeasurement. To address these issues, we introduce a measurement model of LVS\nconsidering the effect of the camera's time-offset and propose a teaching-free\nspatiotemporal calibration method utilizing line constraints. This method\ninvolves a robot equipped with an LVS repeatedly scanning straight-line fillet\nwelds using S-shaped trajectories. Regardless of the robot's orientation\nchanges, all measured welding positions are constrained to a straight-line,\nrepresented by Plucker coordinates. Moreover, a nonlinear optimization model\nbased on straight-line constraints is established. Subsequently, the\nLevenberg-Marquardt algorithm (LMA) is employed to optimize parameters,\nincluding time-offset, hand-eye extrinsic parameters, and straight-line\nparameters. The feasibility and accuracy of the proposed approach are\nquantitatively validated through experiments on curved weld scanning. We\nopen-sourced the code, dataset, and simulation report at\nhttps://anonymous.4open.science/r/LVS_ST_CALIB-015F/README.md.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f4\u7ebf\u7ea6\u675f\u7684\u65e0\u6807\u5b9a\u65f6\u7a7a\u6821\u51c6\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6fc0\u5149\u89c6\u89c9\u4f20\u611f\u5668\u5728\u710a\u63a5\u5e94\u7528\u4e2d\u7684\u65f6\u95f4\u504f\u79fb\u548c\u624b\u773c\u5916\u53c2\u53d8\u5316\u95ee\u9898\u3002", "motivation": "\u6fc0\u5149\u89c6\u89c9\u4f20\u611f\u5668\u5728\u5de5\u4e1a\u673a\u5668\u4eba\u710a\u63a5\u5e94\u7528\u4e2d\u5b58\u5728\u76f8\u673a\u901a\u4fe1\u5ef6\u8fdf\u5bfc\u81f4\u7684\u65f6\u95f4\u4e0d\u540c\u6b65\u95ee\u9898\uff0c\u4ee5\u53ca\u957f\u65f6\u95f4\u6d4b\u91cf\u4e2d\u624b\u773c\u5916\u53c2\u53ef\u80fd\u53d8\u5316\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u793a\u6559\u7684\u6821\u51c6\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u914d\u5907LVS\u7684\u673a\u5668\u4eba\u901a\u8fc7S\u5f62\u8f68\u8ff9\u91cd\u590d\u626b\u63cf\u76f4\u7ebf\u89d2\u710a\u7f1d\uff0c\u5229\u7528Plucker\u5750\u6807\u8868\u793a\u76f4\u7ebf\u7ea6\u675f\uff0c\u5efa\u7acb\u57fa\u4e8e\u76f4\u7ebf\u7ea6\u675f\u7684\u975e\u7ebf\u6027\u4f18\u5316\u6a21\u578b\uff0c\u91c7\u7528LMA\u7b97\u6cd5\u4f18\u5316\u65f6\u95f4\u504f\u79fb\u3001\u624b\u773c\u5916\u53c2\u548c\u76f4\u7ebf\u53c2\u6570\u3002", "result": "\u901a\u8fc7\u66f2\u7ebf\u710a\u7f1d\u626b\u63cf\u5b9e\u9a8c\u5b9a\u91cf\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u548c\u51c6\u786e\u6027\uff0c\u5e76\u5f00\u6e90\u4e86\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u4eff\u771f\u62a5\u544a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6fc0\u5149\u89c6\u89c9\u4f20\u611f\u5668\u7684\u65f6\u7a7a\u6821\u51c6\u95ee\u9898\uff0c\u4e3a\u5de5\u4e1a\u673a\u5668\u4eba\u710a\u63a5\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u611f\u77e5\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12987", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12987", "abs": "https://arxiv.org/abs/2509.12987", "authors": ["Yarin Benyamin", "Argaman Mordoch", "Shahaf S. Shperberg", "Roni Stern"], "title": "Toward PDDL Planning Copilot", "comment": null, "summary": "Large Language Models (LLMs) are increasingly being used as autonomous agents\ncapable of performing complicated tasks. However, they lack the ability to\nperform reliable long-horizon planning on their own. This paper bridges this\ngap by introducing the Planning Copilot, a chatbot that integrates multiple\nplanning tools and allows users to invoke them through instructions in natural\nlanguage. The Planning Copilot leverages the Model Context Protocol (MCP), a\nrecently developed standard for connecting LLMs with external tools and\nsystems. This approach allows using any LLM that supports MCP without\ndomain-specific fine-tuning. Our Planning Copilot supports common planning\ntasks such as checking the syntax of planning problems, selecting an\nappropriate planner, calling it, validating the plan it generates, and\nsimulating their execution. We empirically evaluate the ability of our Planning\nCopilot to perform these tasks using three open-source LLMs. The results show\nthat the Planning Copilot highly outperforms using the same LLMs without the\nplanning tools. We also conducted a limited qualitative comparison of our tool\nagainst Chat GPT-5, a very recent commercial LLM. Our results shows that our\nPlanning Copilot significantly outperforms GPT-5 despite relying on a much\nsmaller LLM. This suggests dedicated planning tools may be an effective way to\nenable LLMs to perform planning tasks.", "AI": {"tldr": "Planning Copilot\u662f\u4e00\u4e2a\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u96c6\u6210\u591a\u79cd\u89c4\u5212\u5de5\u5177\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u5229\u7528MCP\u534f\u8bae\u8fde\u63a5LLM\u4e0e\u5916\u90e8\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u957f\u671f\u89c4\u5212\u4efb\u52a1\u4e0a\u7684\u8868\u73b0", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u53ef\u9760\u7684\u957f\u671f\u89c4\u5212\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9LLM\u80fd\u591f\u6267\u884c\u590d\u6742\u7684\u89c4\u5212\u4efb\u52a1", "method": "\u5f00\u53d1Planning Copilot\u804a\u5929\u673a\u5668\u4eba\uff0c\u96c6\u6210\u591a\u79cd\u89c4\u5212\u5de5\u5177\uff0c\u901a\u8fc7Model Context Protocol(MCP)\u6807\u51c6\u8fde\u63a5LLM\u4e0e\u5916\u90e8\u5de5\u5177\u7cfb\u7edf\uff0c\u652f\u6301\u8bed\u6cd5\u68c0\u67e5\u3001\u89c4\u5212\u5668\u9009\u62e9\u3001\u8ba1\u5212\u751f\u6210\u9a8c\u8bc1\u7b49\u4efb\u52a1", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793aPlanning Copilot\u5728\u4e09\u4e2a\u5f00\u6e90LLM\u4e0a\u8868\u73b0\u8fdc\u8d85\u65e0\u89c4\u5212\u5de5\u5177\u7684\u76f8\u540cLLM\uff0c\u751a\u81f3\u663e\u8457\u4f18\u4e8e\u6700\u65b0\u7684GPT-5\u6a21\u578b", "conclusion": "\u4e13\u7528\u89c4\u5212\u5de5\u5177\u662f\u4f7fLLM\u80fd\u591f\u6709\u6548\u6267\u884c\u89c4\u5212\u4efb\u52a1\u7684\u6709\u6548\u9014\u5f84"}}
{"id": "2509.12969", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.12969", "abs": "https://arxiv.org/abs/2509.12969", "authors": ["Jae-Hyun Lee", "Jonghoo Park", "Kyu-Jin Cho"], "title": "Tendon-Based Proprioception in an Anthropomorphic Underactuated Robotic Hand with Series Elastic Actuators", "comment": "8 pages, 10 figures, Supplementary video, Submitted to IEEE Robotics\n  and Automation Letters (RA-L)", "summary": "Anthropomorphic underactuated hands are widely employed for their versatility\nand structural simplicity. In such systems, compact sensing integration and\nproper interpretation aligned with underactuation are crucial for realizing\npractical grasp functionalities. This study proposes an anthropomorphic\nunderactuated hand that achieves comprehensive situational awareness of\nhand-object interaction, utilizing tendon-based proprioception provided by\nseries elastic actuators (SEAs). We developed a compact SEA with high accuracy\nand reliability that can be seamlessly integrated into sensorless fingers. By\ncoupling proprioceptive sensing with potential energy-based modeling, the\nsystem estimates key grasp-related variables, including contact timing, joint\nangles, relative object stiffness, and finger configuration changes indicating\nexternal disturbances. These estimated variables enable grasp posture\nreconstruction, safe handling of deformable objects, and blind grasping with\nproprioceptive-only recognition of objects with varying geometry and stiffness.\nFinger-level experiments and hand-level demonstrations confirmed the\neffectiveness of the proposed approach. The results demonstrate that\ntendon-based proprioception serves as a compact and robust sensing modality for\npractical manipulation without reliance on vision or tactile feedback.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u808c\u8171\u672c\u4f53\u611f\u77e5\u7684\u6b20\u9a71\u52a8\u4eff\u4eba\u624b\uff0c\u901a\u8fc7\u4e32\u8054\u5f39\u6027\u6267\u884c\u5668\u5b9e\u73b0\u5168\u9762\u7684\u624b-\u7269\u4f53\u4ea4\u4e92\u72b6\u6001\u611f\u77e5\uff0c\u65e0\u9700\u89c6\u89c9\u6216\u89e6\u89c9\u53cd\u9988\u5373\u53ef\u5b8c\u6210\u6293\u53d6\u91cd\u5efa\u3001\u53ef\u53d8\u5f62\u7269\u4f53\u64cd\u4f5c\u548c\u76f2\u6293\u53d6\u4efb\u52a1\u3002", "motivation": "\u6b20\u9a71\u52a8\u4eff\u4eba\u624b\u5177\u6709\u7ed3\u6784\u7b80\u5355\u548c\u901a\u7528\u6027\u5f3a\u7684\u4f18\u70b9\uff0c\u4f46\u7d27\u51d1\u7684\u4f20\u611f\u96c6\u6210\u548c\u4e0e\u6b20\u9a71\u52a8\u673a\u5236\u76f8\u5339\u914d\u7684\u72b6\u6001\u611f\u77e5\u662f\u5b9e\u73b0\u5b9e\u7528\u6293\u53d6\u529f\u80fd\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u9ad8\u7cbe\u5ea6\u53ef\u9760\u7684\u7d27\u51d1\u578b\u4e32\u8054\u5f39\u6027\u6267\u884c\u5668(SEA)\uff0c\u5c06\u5176\u96c6\u6210\u5230\u65e0\u4f20\u611f\u5668\u624b\u6307\u4e2d\uff0c\u901a\u8fc7\u808c\u8171\u672c\u4f53\u611f\u77e5\u4e0e\u57fa\u4e8e\u52bf\u80fd\u7684\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u4f30\u8ba1\u63a5\u89e6\u65f6\u673a\u3001\u5173\u8282\u89d2\u5ea6\u3001\u7269\u4f53\u76f8\u5bf9\u521a\u5ea6\u548c\u5916\u90e8\u5e72\u6270\u7b49\u5173\u952e\u6293\u53d6\u53d8\u91cf\u3002", "result": "\u624b\u6307\u7ea7\u5b9e\u9a8c\u548c\u624b\u7ea7\u6f14\u793a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u808c\u8171\u672c\u4f53\u611f\u77e5\u4f5c\u4e3a\u4e00\u79cd\u7d27\u51d1\u4e14\u9c81\u68d2\u7684\u4f20\u611f\u65b9\u5f0f\uff0c\u53ef\u5728\u4e0d\u4f9d\u8d56\u89c6\u89c9\u6216\u89e6\u89c9\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5b9e\u7528\u64cd\u4f5c\u3002", "conclusion": "\u808c\u8171\u672c\u4f53\u611f\u77e5\u4e3a\u6b20\u9a71\u52a8\u4eff\u4eba\u624b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f20\u611f\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u73b0\u5168\u9762\u7684\u624b-\u7269\u4f53\u4ea4\u4e92\u72b6\u6001\u611f\u77e5\uff0c\u4e3a\u5b9e\u9645\u64cd\u7eb5\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2509.12999", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12999", "abs": "https://arxiv.org/abs/2509.12999", "authors": ["Shinichi Honna", "Taichi Murayama", "Akira Matsui"], "title": "Data-driven Methods of Extracting Text Structure and Information Transfer", "comment": null, "summary": "The Anna Karenina Principle (AKP) holds that success requires satisfying a\nsmall set of essential conditions, whereas failure takes diverse forms. We test\nAKP, its reverse, and two further patterns described as ordered and noisy\nacross novels, online encyclopedias, research papers, and movies. Texts are\nrepresented as sequences of functional blocks, and convergence is assessed in\ntransition order and position. Results show that structural principles vary by\nmedium: novels follow reverse AKP in order, Wikipedia combines AKP with ordered\npatterns, academic papers display reverse AKP in order but remain noisy in\nposition, and movies diverge by genre. Success therefore depends on structural\nconstraints that are specific to each medium, while failure assumes different\nshapes across domains.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5\u5b89\u5a1c\u00b7\u5361\u5217\u5c3c\u5a1c\u539f\u5219\u5728\u4e0d\u540c\u5a92\u4ecb\u4e2d\u7684\u9002\u7528\u6027\uff0c\u53d1\u73b0\u7ed3\u6784\u539f\u5219\u56e0\u5a92\u4ecb\u800c\u5f02\uff1a\u5c0f\u8bf4\u9075\u5faa\u53cd\u5411AKP\u987a\u5e8f\uff0c\u7ef4\u57fa\u767e\u79d1\u7ed3\u5408AKP\u4e0e\u6709\u5e8f\u6a21\u5f0f\uff0c\u5b66\u672f\u8bba\u6587\u5728\u987a\u5e8f\u4e0a\u663e\u793a\u53cd\u5411AKP\u4f46\u5728\u4f4d\u7f6e\u4e0a\u4fdd\u6301\u566a\u58f0\uff0c\u7535\u5f71\u5219\u6309\u7c7b\u578b\u5206\u5316\u3002", "motivation": "\u9a8c\u8bc1\u5b89\u5a1c\u00b7\u5361\u5217\u5c3c\u5a1c\u539f\u5219\uff08AKP\uff09\u53ca\u5176\u53d8\u4f53\u5728\u4e0d\u540c\u6587\u672c\u5a92\u4ecb\u4e2d\u7684\u9002\u7528\u6027\uff0c\u63a2\u7d22\u6210\u529f\u4e0e\u5931\u8d25\u7684\u7ed3\u6784\u6a21\u5f0f\u5dee\u5f02\u3002", "method": "\u5c06\u6587\u672c\u8868\u793a\u4e3a\u529f\u80fd\u5757\u5e8f\u5217\uff0c\u901a\u8fc7\u8f6c\u6362\u987a\u5e8f\u548c\u4f4d\u7f6e\u8bc4\u4f30\u6536\u655b\u6027\uff0c\u5206\u6790\u5c0f\u8bf4\u3001\u5728\u7ebf\u767e\u79d1\u5168\u4e66\u3001\u7814\u7a76\u8bba\u6587\u548c\u7535\u5f71\u56db\u79cd\u5a92\u4ecb\u3002", "result": "\u4e0d\u540c\u5a92\u4ecb\u5c55\u73b0\u4e0d\u540c\u7684\u7ed3\u6784\u539f\u5219\uff1a\u5c0f\u8bf4-\u53cd\u5411AKP\u987a\u5e8f\uff1b\u7ef4\u57fa\u767e\u79d1-AKP+\u6709\u5e8f\u6a21\u5f0f\uff1b\u5b66\u672f\u8bba\u6587-\u53cd\u5411AKP\u987a\u5e8f\u4f46\u4f4d\u7f6e\u566a\u58f0\uff1b\u7535\u5f71-\u6309\u7c7b\u578b\u5206\u5316\u3002", "conclusion": "\u6210\u529f\u53d6\u51b3\u4e8e\u7279\u5b9a\u5a92\u4ecb\u7684\u7ed3\u6784\u7ea6\u675f\uff0c\u800c\u5931\u8d25\u5728\u4e0d\u540c\u9886\u57df\u5448\u73b0\u4e0d\u540c\u5f62\u6001\uff0c\u7ed3\u6784\u539f\u5219\u5177\u6709\u5a92\u4ecb\u7279\u5f02\u6027\u3002"}}
{"id": "2509.12982", "categories": ["cs.RO", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12982", "abs": "https://arxiv.org/abs/2509.12982", "authors": ["Erblin Isaku", "Hassan Sartaj", "Shaukat Ali", "Beatriz Sanguino", "Tongtong Wang", "Guoyuan Li", "Houxiang Zhang", "Thomas Peyrucain"], "title": "Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins", "comment": "15 pages, 4 figures, 3 tables", "summary": "Self-adaptive robots (SARs) in complex, uncertain environments must\nproactively detect and address abnormal behaviors, including\nout-of-distribution (OOD) cases. To this end, digital twins offer a valuable\nsolution for OOD detection. Thus, we present a digital twin-based approach for\nOOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to\nforecast SAR states and employs reconstruction error and Monte Carlo dropout\nfor uncertainty quantification. By combining reconstruction error with\npredictive variance, the digital twin effectively detects OOD behaviors, even\nin previously unseen conditions. The digital twin also includes an\nexplainability layer that links potential OOD to specific SAR states, offering\ninsights for self-adaptation. We evaluated ODiSAR by creating digital twins of\ntwo industrial robots: one navigating an office environment, and another\nperforming maritime ship navigation. In both cases, ODiSAR forecasts SAR\nbehaviors (i.e., robot trajectories and vessel motion) and proactively detects\nOOD events. Our results showed that ODiSAR achieved high detection performance\n-- up to 98\\% AUROC, 96\\% TNR@TPR95, and 95\\% F1-score -- while providing\ninterpretable insights to support self-adaptation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684ODiSAR\u65b9\u6cd5\uff0c\u4f7f\u7528Transformer\u6a21\u578b\u9884\u6d4b\u673a\u5668\u4eba\u72b6\u6001\uff0c\u7ed3\u5408\u91cd\u6784\u8bef\u5dee\u548c\u8499\u7279\u5361\u6d1bdropout\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u6709\u6548\u68c0\u6d4b\u672a\u77e5\u5f02\u5e38\u884c\u4e3a", "motivation": "\u590d\u6742\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u81ea\u9002\u5e94\u673a\u5668\u4eba\u9700\u8981\u4e3b\u52a8\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\uff0c\u5305\u62ec\u5206\u5e03\u5916(OOD)\u60c5\u51b5\uff0c\u6570\u5b57\u5b6a\u751f\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u6570\u5b57\u5b6a\u751f\u9884\u6d4b\u673a\u5668\u4eba\u72b6\u6001\uff0c\u91c7\u7528\u91cd\u6784\u8bef\u5dee\u548c\u8499\u7279\u5361\u6d1bdropout\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u7ed3\u5408\u91cd\u6784\u8bef\u5dee\u548c\u9884\u6d4b\u65b9\u5dee\u68c0\u6d4bOOD\u884c\u4e3a\uff0c\u5e76\u5305\u542b\u53ef\u89e3\u91ca\u6027\u5c42", "result": "\u5728\u4e24\u4e2a\u5de5\u4e1a\u673a\u5668\u4eba\u6848\u4f8b\u4e2d\uff08\u529e\u516c\u5ba4\u5bfc\u822a\u548c\u6d77\u4e0a\u8239\u8236\u5bfc\u822a\uff09\uff0cODiSAR\u5b9e\u73b0\u4e86\u9ad8\u8fbe98% AUROC\u300196% TNR@TPR95\u548c95% F1-score\u7684\u68c0\u6d4b\u6027\u80fd", "conclusion": "ODiSAR\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u81ea\u9002\u5e94\u673a\u5668\u4eba\u7684\u5f02\u5e38\u884c\u4e3a\uff0c\u63d0\u4f9b\u9ad8\u68c0\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u652f\u6301\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u81ea\u9002\u5e94\u8c03\u6574\u63d0\u4f9b\u89c1\u89e3"}}
{"id": "2509.13011", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13011", "abs": "https://arxiv.org/abs/2509.13011", "authors": ["Yuyang Tian", "Shunqiang Mao", "Wenchang Gao", "Lanlan Qiu", "Tianxing He"], "title": "A Visualized Framework for Event Cooperation with Generative Agents", "comment": null, "summary": "Large Language Models (LLMs) have revolutionized the simulation of agent\nsocieties, enabling autonomous planning, memory formation, and social\ninteractions. However, existing frameworks often overlook systematic\nevaluations for event organization and lack visualized integration with\nphysically grounded environments, limiting agents' ability to navigate spaces\nand interact with items realistically. We develop MiniAgentPro, a visualization\nplatform featuring an intuitive map editor for customizing environments and a\nsimulation player with smooth animations. Based on this tool, we introduce a\ncomprehensive test set comprising eight diverse event scenarios with basic and\nhard variants to assess agents' ability. Evaluations using GPT-4o demonstrate\nstrong performance in basic settings but highlight coordination challenges in\nhard variants.", "AI": {"tldr": "MiniAgentPro\u662f\u4e00\u4e2a\u53ef\u89c6\u5316\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u7269\u7406\u73af\u5883\u4e2d\u7684\u4e8b\u4ef6\u7ec4\u7ec7\u548c\u534f\u8c03\u80fd\u529b\uff0c\u5305\u542b\u5730\u56fe\u7f16\u8f91\u5668\u548c\u6a21\u62df\u64ad\u653e\u5668\uff0c\u901a\u8fc78\u79cd\u4e8b\u4ef6\u573a\u666f\u6d4b\u8bd5\u663e\u793a\u5728\u57fa\u7840\u8bbe\u7f6e\u4e2d\u8868\u73b0\u826f\u597d\u4f46\u5728\u56f0\u96be\u53d8\u4f53\u4e2d\u5b58\u5728\u534f\u8c03\u6311\u6218\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u793e\u4f1a\u6a21\u62df\u6846\u67b6\u7f3a\u4e4f\u7cfb\u7edf\u7684\u4e8b\u4ef6\u7ec4\u7ec7\u8bc4\u4f30\u548c\u4e0e\u7269\u7406\u73af\u5883\u7684\u53ef\u89c6\u5316\u96c6\u6210\uff0c\u9650\u5236\u4e86\u4ee3\u7406\u5728\u7a7a\u95f4\u4e2d\u5bfc\u822a\u548c\u4e0e\u73b0\u5b9e\u7269\u54c1\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "method": "\u5f00\u53d1MiniAgentPro\u53ef\u89c6\u5316\u5e73\u53f0\uff0c\u5305\u542b\u76f4\u89c2\u7684\u5730\u56fe\u7f16\u8f91\u5668\u7528\u4e8e\u5b9a\u5236\u73af\u5883\uff0c\u4ee5\u53ca\u5e26\u6709\u6d41\u7545\u52a8\u753b\u7684\u6a21\u62df\u64ad\u653e\u5668\u3002\u57fa\u4e8e\u6b64\u5de5\u5177\u521b\u5efa\u5305\u542b8\u79cd\u4e0d\u540c\u4e8b\u4ef6\u573a\u666f\uff08\u57fa\u7840\u7248\u548c\u56f0\u96be\u7248\uff09\u7684\u7efc\u5408\u6d4b\u8bd5\u96c6\u3002", "result": "\u4f7f\u7528GPT-4o\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5728\u57fa\u7840\u8bbe\u7f6e\u4e2d\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u56f0\u96be\u53d8\u4f53\u4e2d\u7a81\u663e\u4e86\u534f\u8c03\u6311\u6218\u3002", "conclusion": "MiniAgentPro\u5e73\u53f0\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6846\u67b6\u5728\u7269\u7406\u73af\u5883\u96c6\u6210\u548c\u7cfb\u7edf\u8bc4\u4f30\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3aLLM\u4ee3\u7406\u7684\u793e\u4f1a\u6a21\u62df\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u548c\u53ef\u89c6\u5316\u5de5\u5177\u3002"}}
{"id": "2509.13024", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13024", "abs": "https://arxiv.org/abs/2509.13024", "authors": ["Haohan Min", "Zhoujian Li", "Yu Yang", "Jinyu Chen", "Shenghai Yuan"], "title": "DVDP: An End-to-End Policy for Mobile Robot Visual Docking with RGB-D Perception", "comment": null, "summary": "Automatic docking has long been a significant challenge in the field of\nmobile robotics. Compared to other automatic docking methods, visual docking\nmethods offer higher precision and lower deployment costs, making them an\nefficient and promising choice for this task. However, visual docking methods\nimpose strict requirements on the robot's initial position at the start of the\ndocking process. To overcome the limitations of current vision-based methods,\nwe propose an innovative end-to-end visual docking method named DVDP(direct\nvisual docking policy). This approach requires only a binocular RGB-D camera\ninstalled on the mobile robot to directly output the robot's docking path,\nachieving end-to-end automatic docking. Furthermore, we have collected a\nlarge-scale dataset of mobile robot visual automatic docking dataset through a\ncombination of virtual and real environments using the Unity 3D platform and\nactual mobile robot setups. We developed a series of evaluation metrics to\nquantify the performance of the end-to-end visual docking method. Extensive\nexperiments, including benchmarks against leading perception backbones adapted\ninto our framework, demonstrate that our method achieves superior performance.\nFinally, real-world deployment on the SCOUT Mini confirmed DVDP's efficacy,\nwith our model generating smooth, feasible docking trajectories that meet\nphysical constraints and reach the target pose.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDVDP\u7684\u7aef\u5230\u7aef\u89c6\u89c9\u5bf9\u63a5\u65b9\u6cd5\uff0c\u4f7f\u7528\u53cc\u76eeRGB-D\u6444\u50cf\u5934\u76f4\u63a5\u8f93\u51fa\u673a\u5668\u4eba\u5bf9\u63a5\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u89c6\u89c9\u5bf9\u63a5\u65b9\u6cd5\u5bf9\u521d\u59cb\u4f4d\u7f6e\u8981\u6c42\u4e25\u683c\u7684\u95ee\u9898\u3002", "motivation": "\u81ea\u52a8\u5bf9\u63a5\u662f\u79fb\u52a8\u673a\u5668\u4eba\u9886\u57df\u7684\u91cd\u8981\u6311\u6218\uff0c\u73b0\u6709\u89c6\u89c9\u5bf9\u63a5\u65b9\u6cd5\u867d\u7136\u7cbe\u5ea6\u9ad8\u3001\u90e8\u7f72\u6210\u672c\u4f4e\uff0c\u4f46\u5bf9\u673a\u5668\u4eba\u521d\u59cb\u4f4d\u7f6e\u6709\u4e25\u683c\u8981\u6c42\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86DVDP\u7aef\u5230\u7aef\u89c6\u89c9\u5bf9\u63a5\u7b56\u7565\uff0c\u4ec5\u9700\u53cc\u76eeRGB-D\u6444\u50cf\u5934\uff0c\u901a\u8fc7\u865a\u62df\u548c\u771f\u5b9e\u73af\u5883\u7ed3\u5408\u7684\u65b9\u5f0f\u6536\u96c6\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u4f7f\u7528Unity 3D\u5e73\u53f0\u548c\u5b9e\u9645\u673a\u5668\u4eba\u8bbe\u7f6e\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u8d8a\uff0c\u5728SCOUT Mini\u673a\u5668\u4eba\u4e0a\u7684\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u80fd\u591f\u751f\u6210\u5e73\u6ed1\u3001\u53ef\u884c\u7684\u5bf9\u63a5\u8f68\u8ff9\uff0c\u6ee1\u8db3\u7269\u7406\u7ea6\u675f\u5e76\u8fbe\u5230\u76ee\u6807\u59ff\u6001\u3002", "conclusion": "DVDP\u65b9\u6cd5\u4e3a\u79fb\u52a8\u673a\u5668\u4eba\u89c6\u89c9\u81ea\u52a8\u5bf9\u63a5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.13131", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13131", "abs": "https://arxiv.org/abs/2509.13131", "authors": ["Marylou Fauchard", "Florian Carichon", "Margarida Carvalho", "Golnoosh Farnadi"], "title": "Reasoning with Preference Constraints: A Benchmark for Language Models in Many-to-One Matching Markets", "comment": null, "summary": "Recent advances in reasoning with large language models (LLMs) have\ndemonstrated strong performance on complex mathematical tasks, including\ncombinatorial optimization. Techniques such as Chain-of-Thought and In-Context\nLearning have further enhanced this capability, making LLMs both powerful and\naccessible tools for a wide range of users, including non-experts. However,\napplying LLMs to matching problems, which require reasoning under preferential\nand structural constraints, remains underexplored. To address this gap, we\nintroduce a novel benchmark of 369 instances of the College Admission Problem,\na canonical example of a matching problem with preferences, to evaluate LLMs\nacross key dimensions: feasibility, stability, and optimality. We employ this\nbenchmark to assess the performance of several open-weight LLMs. Our results\nfirst reveal that while LLMs can satisfy certain constraints, they struggle to\nmeet all evaluation criteria consistently. They also show that reasoning LLMs,\nlike QwQ and GPT-oss, significantly outperform traditional models such as\nLlama, Qwen or Mistral, defined here as models used without any dedicated\nreasoning mechanisms. Moreover, we observed that LLMs reacted differently to\nthe various prompting strategies tested, which include Chain-of-Thought,\nIn-Context Learning and role-based prompting, with no prompt consistently\noffering the best performance. Finally, we report the performances from\niterative prompting with auto-generated feedback and show that they are not\nmonotonic; they can peak early and then significantly decline in later\nattempts. Overall, this work offers a new perspective on model reasoning\nperformance and the effectiveness of prompting strategies in combinatorial\noptimization problems with preferential constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b369\u4e2a\u5927\u5b66\u5f55\u53d6\u95ee\u9898\u5b9e\u4f8b\u7684\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5339\u914d\u95ee\u9898\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLMs\u5728\u6ee1\u8db3\u6240\u6709\u8bc4\u4f30\u6807\u51c6\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u63a8\u7406\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u4e14\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u6548\u679c\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u548c\u7ec4\u5408\u4f18\u5316\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u504f\u597d\u548c\u7ed3\u6784\u7ea6\u675f\u7684\u5339\u914d\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u5728\u8fd9\u7c7b\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u521b\u5efa\u4e86\u5305\u542b369\u4e2a\u5927\u5b66\u5f55\u53d6\u95ee\u9898\u5b9e\u4f8b\u7684\u57fa\u51c6\uff0c\u8bc4\u4f30\u591a\u4e2a\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u884c\u6027\u3001\u7a33\u5b9a\u6027\u548c\u6700\u4f18\u6027\u4e09\u4e2a\u7ef4\u5ea6\u7684\u8868\u73b0\uff0c\u6d4b\u8bd5\u4e86\u5305\u62ec\u601d\u7ef4\u94fe\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u63d0\u793a\u7b49\u591a\u79cd\u63d0\u793a\u7b56\u7565\u3002", "result": "LLMs\u80fd\u591f\u6ee1\u8db3\u67d0\u4e9b\u7ea6\u675f\u4f46\u96be\u4ee5\u4e00\u81f4\u6ee1\u8db3\u6240\u6709\u8bc4\u4f30\u6807\u51c6\uff1b\u63a8\u7406\u6a21\u578b\uff08\u5982QwQ\u548cGPT-oss\uff09\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff1b\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u6548\u679c\u5dee\u5f02\u660e\u663e\uff0c\u6ca1\u6709\u4e00\u79cd\u7b56\u7565\u59cb\u7ec8\u6700\u4f18\uff1b\u8fed\u4ee3\u63d0\u793a\u7684\u6027\u80fd\u975e\u5355\u8c03\uff0c\u53ef\u80fd\u65e9\u671f\u8fbe\u5230\u5cf0\u503c\u540e\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6a21\u578b\u63a8\u7406\u6027\u80fd\u548c\u63d0\u793a\u7b56\u7565\u5728\u5177\u6709\u504f\u597d\u7ea6\u675f\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u63ed\u793a\u4e86LLMs\u5728\u5339\u914d\u95ee\u9898\u4e2d\u7684\u5c40\u9650\u6027\u4ee5\u53ca\u63d0\u793a\u7b56\u7565\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.13069", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13069", "abs": "https://arxiv.org/abs/2509.13069", "authors": ["James C. Ward", "Arthur Richards", "Edmund R. Hunt"], "title": "Practical Handling of Dynamic Environments in Decentralised Multi-Robot Patrol", "comment": null, "summary": "Persistent monitoring using robot teams is of interest in fields such as\nsecurity, environmental monitoring, and disaster recovery. Performing such\nmonitoring in a fully on-line decentralised fashion has significant potential\nadvantages for robustness, adaptability, and scalability of monitoring\nsolutions, including, in principle, the capacity to effectively adapt in\nreal-time to a changing environment. We examine this through the lens of\nmulti-robot patrol, in which teams of patrol robots must persistently minimise\ntime between visits to points of interest, within environments where\ntraversability of routes is highly dynamic. These dynamics must be observed by\npatrol agents and accounted for in a fully decentralised on-line manner. In\nthis work, we present a new method of monitoring and adjusting for environment\ndynamics in a decentralised multi-robot patrol team. We demonstrate that our\nmethod significantly outperforms realistic baselines in highly dynamic\nscenarios, and also investigate dynamic scenarios in which explicitly\naccounting for environment dynamics may be unnecessary or impractical.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53bb\u4e2d\u5fc3\u5316\u591a\u673a\u5668\u4eba\u5de1\u903b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u9ad8\u5ea6\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u884c\u6301\u7eed\u76d1\u63a7\uff0c\u80fd\u591f\u5b9e\u65f6\u9002\u5e94\u73af\u5883\u53d8\u5316\u5e76\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u5728\u5b89\u5168\u3001\u73af\u5883\u76d1\u6d4b\u548c\u707e\u96be\u6062\u590d\u7b49\u9886\u57df\uff0c\u9700\u8981\u673a\u5668\u4eba\u56e2\u961f\u8fdb\u884c\u6301\u7eed\u76d1\u63a7\u3002\u5b8c\u5168\u5728\u7ebf\u53bb\u4e2d\u5fc3\u5316\u7684\u76d1\u63a7\u65b9\u5f0f\u5177\u6709\u9c81\u68d2\u6027\u3001\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u4f18\u52bf\uff0c\u80fd\u591f\u5b9e\u65f6\u9002\u5e94\u53d8\u5316\u7684\u73af\u5883", "method": "\u901a\u8fc7\u591a\u673a\u5668\u4eba\u5de1\u903b\u7684\u89c6\u89d2\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76d1\u6d4b\u548c\u8c03\u6574\u73af\u5883\u52a8\u6001\u7684\u65b9\u6cd5\uff0c\u5de1\u903b\u673a\u5668\u4eba\u56e2\u961f\u9700\u8981\u5728\u9ad8\u5ea6\u52a8\u6001\u7684\u73af\u5883\u4e2d\u6301\u7eed\u6700\u5c0f\u5316\u5bf9\u5174\u8da3\u70b9\u7684\u8bbf\u95ee\u95f4\u9694\u65f6\u95f4", "result": "\u8be5\u65b9\u6cd5\u5728\u9ad8\u5ea6\u52a8\u6001\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u5b9e\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u5728\u67d0\u4e9b\u52a8\u6001\u573a\u666f\u4e2d\u660e\u786e\u8003\u8651\u73af\u5883\u52a8\u6001\u53ef\u80fd\u4e0d\u5fc5\u8981\u6216\u4e0d\u5207\u5b9e\u9645\u7684\u60c5\u51b5", "conclusion": "\u6240\u63d0\u51fa\u7684\u53bb\u4e2d\u5fc3\u5316\u591a\u673a\u5668\u4eba\u5de1\u903b\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u9ad8\u5ea6\u52a8\u6001\u73af\u5883\uff0c\u5728\u5b9e\u65f6\u9002\u5e94\u73af\u5883\u53d8\u5316\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u6301\u7eed\u76d1\u63a7\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13137", "categories": ["cs.AI", "cs.HC", "cs.MA", "K.4.4; K.6.5; I.2.11"], "pdf": "https://arxiv.org/pdf/2509.13137", "abs": "https://arxiv.org/abs/2509.13137", "authors": ["Henrik Axelsen", "Valdemar Licht", "Jan Damsgaard"], "title": "Agentic AI for Financial Crime Compliance", "comment": "Accepted for presentation at HICSS-59 (2026), forthcoming in\n  Proceedings", "summary": "The cost and complexity of financial crime compliance (FCC) continue to rise,\noften without measurable improvements in effectiveness. While AI offers\npotential, most solutions remain opaque and poorly aligned with regulatory\nexpectations. This paper presents the design and deployment of an agentic AI\nsystem for FCC in digitally native financial platforms. Developed through an\nAction Design Research (ADR) process with a fintech firm and regulatory\nstakeholders, the system automates onboarding, monitoring, investigation, and\nreporting, emphasizing explainability, traceability, and compliance-by-design.\nUsing artifact-centric modeling, it assigns clearly bounded roles to autonomous\nagents and enables task-specific model routing and audit logging. The\ncontribution includes a reference architecture, a real-world prototype, and\ninsights into how Agentic AI can reconfigure FCC workflows under regulatory\nconstraints. Our findings extend IS literature on AI-enabled compliance by\ndemonstrating how automation, when embedded within accountable governance\nstructures, can support transparency and institutional trust in high-stakes,\nregulated environments.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u4e8e\u91d1\u878d\u72af\u7f6a\u5408\u89c4\u7684\u4ee3\u7406AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u884c\u52a8\u8bbe\u8ba1\u7814\u7a76\u65b9\u6cd5\u5f00\u53d1\uff0c\u5f3a\u8c03\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u5408\u89c4\u6027\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u5e76\u652f\u6301\u76d1\u7ba1\u900f\u660e\u5ea6\u3002", "motivation": "\u91d1\u878d\u72af\u7f6a\u5408\u89c4\u6210\u672c\u4e0d\u65ad\u4e0a\u5347\u4f46\u6548\u679c\u6709\u9650\uff0c\u73b0\u6709AI\u89e3\u51b3\u65b9\u6848\u4e0d\u900f\u660e\u4e14\u4e0d\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u81ea\u52a8\u5316\u53c8\u80fd\u6ee1\u8db3\u76d1\u7ba1\u671f\u671b\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u884c\u52a8\u8bbe\u8ba1\u7814\u7a76(ADR)\u65b9\u6cd5\uff0c\u4e0e\u91d1\u878d\u79d1\u6280\u516c\u53f8\u548c\u76d1\u7ba1\u673a\u6784\u5408\u4f5c\uff0c\u4f7f\u7528\u5de5\u4ef6\u4e2d\u5fc3\u5efa\u6a21\uff0c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u5206\u914d\u660e\u786e\u89d2\u8272\uff0c\u5b9e\u73b0\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u8def\u7531\u548c\u5ba1\u8ba1\u65e5\u5fd7\u8bb0\u5f55\u3002", "result": "\u5f00\u53d1\u4e86\u53c2\u8003\u67b6\u6784\u548c\u5b9e\u9645\u539f\u578b\uff0c\u5c55\u793a\u4e86\u4ee3\u7406AI\u5982\u4f55\u5728\u76d1\u7ba1\u7ea6\u675f\u4e0b\u91cd\u6784\u91d1\u878d\u72af\u7f6a\u5408\u89c4\u5de5\u4f5c\u6d41\u7a0b\uff0c\u652f\u6301\u900f\u660e\u5ea6\u548c\u673a\u6784\u4fe1\u4efb\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u81ea\u52a8\u5316\u5d4c\u5165\u5230\u8d1f\u8d23\u4efb\u7684\u6cbb\u7406\u7ed3\u6784\u4e2d\u65f6\uff0c\u53ef\u4ee5\u5728\u9ad8\u98ce\u9669\u76d1\u7ba1\u73af\u5883\u4e2d\u652f\u6301\u900f\u660e\u5ea6\u548c\u5236\u5ea6\u4fe1\u4efb\uff0c\u4e3aAI\u9a71\u52a8\u7684\u5408\u89c4\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2509.13074", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13074", "abs": "https://arxiv.org/abs/2509.13074", "authors": ["Simon Fritsch", "Liam Achenbach", "Riccardo Bianco", "Nicola Irmiger", "Gawain Marti", "Samuel Visca", "Chenyu Yang", "Davide Liconti", "Barnabas Gavin Cangan", "Robert Jomar Malate", "Ronan J. Hinchet", "Robert K. Katzschmann"], "title": "Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five", "comment": "First five listed authors have equal contribution", "summary": "This paper presents the SABD hand, a 16-degree-of-freedom (DoF) robotic hand\nthat departs from purely anthropomorphic designs to achieve an expanded grasp\nenvelope, enable manipulation poses beyond human capability, and reduce the\nrequired number of actuators. This is achieved by combining the\nadduction/abduction (Add/Abd) joint of digits four and five into a single joint\nwith a large range of motion. The combined joint increases the workspace of the\ndigits by 400\\% and reduces the required DoFs while retaining dexterity.\nExperimental results demonstrate that the combined Add/Abd joint enables the\nhand to grasp objects with a side distance of up to 200 mm. Reinforcement\nlearning-based investigations show that the design enables grasping policies\nthat are effective not only for handling larger objects but also for achieving\nenhanced grasp stability. In teleoperated trials, the hand successfully\nperformed 86\\% of attempted grasps on suitable YCB objects, including\nchallenging non-anthropomorphic configurations. These findings validate the\ndesign's ability to enhance grasp stability, flexibility, and dexterous\nmanipulation without added complexity, making it well-suited for a wide range\nof applications.", "AI": {"tldr": "SABD\u673a\u68b0\u624b\u901a\u8fc7\u5c06\u7b2c\u56db\u548c\u7b2c\u4e94\u624b\u6307\u7684\u5185\u6536/\u5916\u5c55\u5173\u8282\u5408\u5e76\u4e3a\u4e00\u4e2a\u5177\u6709\u5927\u8fd0\u52a8\u8303\u56f4\u7684\u5355\u4e00\u5173\u8282\uff0c\u5b9e\u73b0\u4e86\u6269\u5c55\u7684\u6293\u53d6\u8303\u56f4\u3001\u8d85\u8d8a\u4eba\u7c7b\u80fd\u529b\u7684\u64cd\u4f5c\u59ff\u6001\uff0c\u5e76\u51cf\u5c11\u4e86\u6240\u9700\u6267\u884c\u5668\u6570\u91cf\u3002", "motivation": "\u4f20\u7edf\u4eff\u4eba\u673a\u68b0\u624b\u8bbe\u8ba1\u9650\u5236\u4e86\u6293\u53d6\u8303\u56f4\u548c\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u8d85\u8d8a\u4eba\u7c7b\u751f\u7406\u9650\u5236\u3001\u51cf\u5c11\u6267\u884c\u5668\u6570\u91cf\u540c\u65f6\u4fdd\u6301\u7075\u5de7\u6027\u7684\u65b0\u578b\u673a\u68b0\u624b\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u975e\u7eaf\u4eff\u4eba\u8bbe\u8ba1\uff0c\u5c06\u7b2c\u56db\u548c\u7b2c\u4e94\u624b\u6307\u7684\u5185\u6536/\u5916\u5c55\u5173\u8282\u5408\u5e76\u4e3a\u5355\u4e00\u5173\u8282\uff0c\u5927\u5e45\u589e\u52a0\u624b\u6307\u5de5\u4f5c\u7a7a\u95f4\uff08400%\uff09\uff0c\u540c\u65f6\u51cf\u5c11\u81ea\u7531\u5ea6\u6570\u91cf\u3002\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u8fdc\u7a0b\u64cd\u4f5c\u5b9e\u9a8c\u9a8c\u8bc1\u8bbe\u8ba1\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5408\u5e76\u5173\u8282\u4f7f\u673a\u68b0\u624b\u80fd\u591f\u6293\u53d6\u4fa7\u5411\u8ddd\u79bb\u8fbe200mm\u7684\u7269\u4f53\uff0c\u8fdc\u7a0b\u64cd\u4f5c\u8bd5\u9a8c\u4e2d\u6210\u529f\u5b8c\u621086%\u7684YCB\u7269\u4f53\u6293\u53d6\u5c1d\u8bd5\uff0c\u5305\u62ec\u5177\u6709\u6311\u6218\u6027\u7684\u975e\u4eff\u4eba\u914d\u7f6e\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u5728\u4e0d\u589e\u52a0\u590d\u6742\u6027\u7684\u60c5\u51b5\u4e0b\u589e\u5f3a\u4e86\u6293\u53d6\u7a33\u5b9a\u6027\u3001\u7075\u6d3b\u6027\u548c\u7075\u5de7\u64cd\u4f5c\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2509.13203", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13203", "abs": "https://arxiv.org/abs/2509.13203", "authors": ["Kanishk Garg", "Saranya D.", "Sanal Kumar", "Saurabh Singh", "Anupam Purwar"], "title": "G-CSEA: A Graph-Based Conflict Set Extraction Algorithm for Identifying Infeasibility in Pseudo-Boolean Models", "comment": "This paper presents G-CSEA, a novel graph-based algorithm for rapidly\n  diagnosing infeasibility in workforce scheduling models. Inspired by\n  Conflict-Driven Clause Learning (CDCL), our method efficiently extracts a\n  compact conflict set from an implication graph, reducing the initial\n  constraint set by approximately 94%", "summary": "Workforce scheduling involves a variety of rule-based constraints-such as\nshift limits, staffing policies, working hour restrictions, and many similar\nscheduling rules-which can interact in conflicting ways, leading to infeasible\nmodels. Identifying the underlying causes of such infeasibility is critical for\nresolving scheduling issues and restoring feasibility. A common diagnostic\napproach is to compute Irreducible Infeasible Subsets (IISs): minimal sets of\nconstraints that are jointly infeasible but become feasible when any one is\nremoved. We consider models formulated using pseudo-Boolean constraints with\ninequality relations over binary variables, which naturally encode scheduling\nlogic. Existing IIS extraction methods such as Additive Deletion and\nQuickXplain rely on repeated feasibility checks, often incurring large numbers\nof solver calls. Dual ray analysis, while effective for LP-based models, may\nfail when the relaxed problem is feasible but the underlying pseudo-Boolean\nmodel is not. To address these limitations, we propose Graph-based Conflict Set\nExtraction Algorithm (G-CSEA) to extract a conflict set, an approach inspired\nby Conflict-Driven Clause Learning (CDCL) in SAT solvers. Our method constructs\nan implication graph during constraint propagation and, upon detecting a\nconflict, traces all contributing constraints across both decision branches.\nThe resulting conflict set can optionally be minimized using QuickXplain to\nproduce an IIS.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u51b2\u7a81\u96c6\u63d0\u53d6\u7b97\u6cd5(G-CSEA)\uff0c\u7528\u4e8e\u9ad8\u6548\u8bc6\u522b\u4f2a\u5e03\u5c14\u7ea6\u675f\u8c03\u5ea6\u6a21\u578b\u4e2d\u7684\u4e0d\u53ef\u884c\u5b50\u96c6\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c11\u6c42\u89e3\u5668\u8c03\u7528\u6b21\u6570", "motivation": "\u4f20\u7edfIIS\u63d0\u53d6\u65b9\u6cd5\u5982Additive Deletion\u548cQuickXplain\u9700\u8981\u5927\u91cf\u53ef\u884c\u6027\u68c0\u67e5\uff0c\u800c\u57fa\u4e8e\u5bf9\u5076\u5c04\u7ebf\u5206\u6790\u7684\u65b9\u6cd5\u5728\u4f2a\u5e03\u5c14\u6a21\u578b\u4e2d\u53ef\u80fd\u5931\u6548\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u51b2\u7a81\u68c0\u6d4b\u65b9\u6cd5", "method": "\u57fa\u4e8e\u51b2\u7a81\u9a71\u52a8\u5b50\u53e5\u5b66\u4e60(CDCL)\u601d\u60f3\uff0c\u5728\u7ea6\u675f\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u6784\u5efa\u8574\u542b\u56fe\uff0c\u68c0\u6d4b\u51b2\u7a81\u65f6\u8ffd\u8e2a\u6240\u6709\u51b3\u7b56\u5206\u652f\u4e2d\u7684\u8d21\u732e\u7ea6\u675f\uff0c\u5f62\u6210\u51b2\u7a81\u96c6\uff0c\u53ef\u9009\u4f7f\u7528QuickXplain\u6700\u5c0f\u5316\u4e3aIIS", "result": "\u5f00\u53d1\u4e86G-CSEA\u7b97\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u63d0\u53d6\u4f2a\u5e03\u5c14\u7ea6\u675f\u8c03\u5ea6\u6a21\u578b\u4e2d\u7684\u51b2\u7a81\u96c6\uff0c\u51cf\u5c11\u6c42\u89e3\u5668\u8c03\u7528\u6b21\u6570", "conclusion": "G-CSEA\u4e3a\u4f2a\u5e03\u5c14\u7ea6\u675f\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u51b2\u7a81\u96c6\u63d0\u53d6\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5305\u542b\u590d\u6742\u8c03\u5ea6\u89c4\u5219\u7684\u52b3\u52a8\u529b\u8c03\u5ea6\u95ee\u9898"}}
{"id": "2509.13077", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13077", "abs": "https://arxiv.org/abs/2509.13077", "authors": ["Jonathan K\u00fclz", "Sehoon Ha", "Matthias Althoff"], "title": "A Design Co-Pilot for Task-Tailored Manipulators", "comment": null, "summary": "Although robotic manipulators are used in an ever-growing range of\napplications, robot manufacturers typically follow a ``one-fits-all''\nphilosophy, employing identical manipulators in various settings. This often\nleads to suboptimal performance, as general-purpose designs fail to exploit\nparticularities of tasks. The development of custom, task-tailored robots is\nhindered by long, cost-intensive development cycles and the high cost of\ncustomized hardware. Recently, various computational design methods have been\ndevised to overcome the bottleneck of human engineering. In addition, a surge\nof modular robots allows quick and economical adaptation to changing industrial\nsettings. This work proposes an approach to automatically designing and\noptimizing robot morphologies tailored to a specific environment. To this end,\nwe learn the inverse kinematics for a wide range of different manipulators. A\nfully differentiable framework realizes gradient-based fine-tuning of designed\nrobots and inverse kinematics solutions. Our generative approach accelerates\nthe generation of specialized designs from hours with optimization-based\nmethods to seconds, serving as a design co-pilot that enables instant\nadaptation and effective human-AI collaboration. Numerical experiments show\nthat our approach finds robots that can navigate cluttered environments,\nmanipulators that perform well across a specified workspace, and can be adapted\nto different hardware constraints. Finally, we demonstrate the real-world\napplicability of our method by setting up a modular robot designed in\nsimulation that successfully moves through an obstacle course.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u8bbe\u8ba1\u548c\u4f18\u5316\u9488\u5bf9\u7279\u5b9a\u73af\u5883\u7684\u673a\u5668\u4eba\u5f62\u6001\u7684\u5b8c\u5168\u53ef\u5fae\u5206\u6846\u67b6\uff0c\u80fd\u591f\u5feb\u901f\u751f\u6210\u4e13\u7528\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u5373\u65f6\u9002\u5e94\u548c\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u5236\u9020\u5546\u91c7\u7528\"\u4e00\u5200\u5207\"\u54f2\u5b66\uff0c\u901a\u7528\u8bbe\u8ba1\u65e0\u6cd5\u5145\u5206\u5229\u7528\u4efb\u52a1\u7279\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002\u5b9a\u5236\u5316\u673a\u5668\u4eba\u5f00\u53d1\u5468\u671f\u957f\u3001\u6210\u672c\u9ad8\uff0c\u9700\u8981\u514b\u670d\u4eba\u7c7b\u5de5\u7a0b\u74f6\u9888", "method": "\u5b66\u4e60\u5e7f\u6cdb\u4e0d\u540c\u7c7b\u578b\u673a\u68b0\u81c2\u7684\u9006\u8fd0\u52a8\u5b66\uff0c\u5efa\u7acb\u5b8c\u5168\u53ef\u5fae\u5206\u6846\u67b6\u5b9e\u73b0\u57fa\u4e8e\u68af\u5ea6\u7684\u673a\u5668\u4eba\u8bbe\u8ba1\u548c\u9006\u8fd0\u52a8\u5b66\u89e3\u51b3\u65b9\u6848\u7684\u7cbe\u7ec6\u8c03\u4f18", "result": "\u65b9\u6cd5\u80fd\u591f\u627e\u5230\u53ef\u5728\u6742\u4e71\u73af\u5883\u4e2d\u5bfc\u822a\u7684\u673a\u5668\u4eba\u3001\u5728\u6307\u5b9a\u5de5\u4f5c\u7a7a\u95f4\u8868\u73b0\u826f\u597d\u7684\u673a\u68b0\u81c2\uff0c\u5e76\u53ef\u9002\u5e94\u4e0d\u540c\u7684\u786c\u4ef6\u7ea6\u675f\u3002\u5728\u4eff\u771f\u4e2d\u8bbe\u8ba1\u7684\u6a21\u5757\u5316\u673a\u5668\u4eba\u6210\u529f\u901a\u8fc7\u969c\u788d\u7269\u8def\u7ebf", "conclusion": "\u8be5\u751f\u6210\u65b9\u6cd5\u5c06\u4e13\u7528\u8bbe\u8ba1\u751f\u6210\u65f6\u95f4\u4ece\u57fa\u4e8e\u4f18\u5316\u65b9\u6cd5\u7684\u6570\u5c0f\u65f6\u7f29\u77ed\u5230\u6570\u79d2\uff0c\u53ef\u4f5c\u4e3a\u8bbe\u8ba1\u534f\u5bfc\u5458\u5b9e\u73b0\u5373\u65f6\u9002\u5e94\u548c\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.13234", "categories": ["cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13234", "abs": "https://arxiv.org/abs/2509.13234", "authors": ["Nadim Barakat", "William Lotter"], "title": "Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy", "comment": null, "summary": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide, and AI\nsystems can expand access to fundus photography screening. Current FDA-cleared\nsystems primarily provide binary referral outputs, where this minimal output\nmay limit clinical trust and utility. Yet, determining the most effective\noutput format to enhance clinician-AI performance is an empirical challenge\nthat is difficult to assess at scale. We evaluated multimodal large language\nmodels (MLLMs) for DR detection and their ability to simulate clinical AI\nassistance across different output types. Two models were tested on IDRiD and\nMessidor-2: GPT-4o, a general-purpose MLLM, and MedGemma, an open-source\nmedical model. Experiments included: (1) baseline evaluation, (2) simulated AI\nassistance with synthetic predictions, and (3) actual AI-to-AI collaboration\nwhere GPT-4o incorporated MedGemma outputs. MedGemma outperformed GPT-4o at\nbaseline, achieving higher sensitivity and AUROC, while GPT-4o showed\nnear-perfect specificity but low sensitivity. Both models adjusted predictions\nbased on simulated AI inputs, but GPT-4o's performance collapsed with incorrect\nones, whereas MedGemma remained more stable. In actual collaboration, GPT-4o\nachieved strong results when guided by MedGemma's descriptive outputs, even\nwithout direct image access (AUROC up to 0.96). These findings suggest MLLMs\nmay improve DR screening pipelines and serve as scalable simulators for\nstudying clinical AI assistance across varying output configurations. Open,\nlightweight models such as MedGemma may be especially valuable in low-resource\nsettings, while descriptive outputs could enhance explainability and clinician\ntrust in clinical workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\u548cMedGemma\uff09\u5728\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0MedGemma\u5728\u57fa\u7ebf\u8bc4\u4f30\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u800cGPT-4o\u5728\u7ed3\u5408MedGemma\u63cf\u8ff0\u6027\u8f93\u51fa\u540e\u80fd\u8fbe\u5230\u4f18\u5f02\u6027\u80fd\uff0c\u8868\u660eMLLMs\u53ef\u6539\u5584DR\u7b5b\u67e5\u6d41\u7a0b\u5e76\u4f5c\u4e3a\u4e34\u5e8aAI\u8f85\u52a9\u7814\u7a76\u7684\u53ef\u6269\u5c55\u6a21\u62df\u5668\u3002", "motivation": "\u5f53\u524dFDA\u6279\u51c6\u7684\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u7b5b\u67e5\u7cfb\u7edf\u4e3b\u8981\u63d0\u4f9b\u4e8c\u5143\u8f6c\u8bca\u8f93\u51fa\uff0c\u8fd9\u79cd\u6700\u5c0f\u5316\u8f93\u51fa\u53ef\u80fd\u9650\u5236\u4e34\u5e8a\u4fe1\u4efb\u548c\u5b9e\u7528\u6027\u3002\u9700\u8981\u786e\u5b9a\u6700\u6709\u6548\u7684\u8f93\u51fa\u683c\u5f0f\u6765\u589e\u5f3a\u4e34\u5e8a\u533b\u751f\u4e0eAI\u7684\u534f\u4f5c\u6027\u80fd\u3002", "method": "\u5728IDRiD\u548cMessidor-2\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5GPT-4o\uff08\u901a\u7528MLLM\uff09\u548cMedGemma\uff08\u5f00\u6e90\u533b\u7597\u6a21\u578b\uff09\uff0c\u5305\u62ec\uff1a1\uff09\u57fa\u7ebf\u8bc4\u4f30\uff1b2\uff09\u4f7f\u7528\u5408\u6210\u9884\u6d4b\u7684\u6a21\u62dfAI\u8f85\u52a9\uff1b3\uff09\u5b9e\u9645AI\u534f\u4f5c\uff0cGPT-4o\u6574\u5408MedGemma\u8f93\u51fa\u3002", "result": "MedGemma\u57fa\u7ebf\u8868\u73b0\u4f18\u4e8eGPT-4o\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u654f\u611f\u6027\u548cAUROC\uff1bGPT-4o\u7279\u5f02\u6027\u63a5\u8fd1\u5b8c\u7f8e\u4f46\u654f\u611f\u6027\u4f4e\u3002\u5728\u534f\u4f5c\u4e2d\uff0cGPT-4o\u7ed3\u5408MedGemma\u63cf\u8ff0\u6027\u8f93\u51fa\u540eAUROC\u53ef\u8fbe0.96\uff0c\u5373\u4f7f\u6ca1\u6709\u76f4\u63a5\u56fe\u50cf\u8bbf\u95ee\u3002", "conclusion": "MLLMs\u53ef\u4ee5\u6539\u5584DR\u7b5b\u67e5\u6d41\u7a0b\uff0c\u5e76\u4f5c\u4e3a\u7814\u7a76\u4e0d\u540c\u8f93\u51fa\u914d\u7f6e\u4e0b\u4e34\u5e8aAI\u8f85\u52a9\u7684\u53ef\u6269\u5c55\u6a21\u62df\u5668\u3002\u5f00\u6e90\u8f7b\u91cf\u7ea7\u6a21\u578b\u5982MedGemma\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u7279\u522b\u6709\u4ef7\u503c\uff0c\u63cf\u8ff0\u6027\u8f93\u51fa\u53ef\u589e\u5f3a\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u533b\u751f\u4fe1\u4efb\u3002"}}
{"id": "2509.13095", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13095", "abs": "https://arxiv.org/abs/2509.13095", "authors": ["Zijie Zhao", "Honglei Guo", "Shengqian Chen", "Kaixuan Xu", "Bo Jiang", "Yuanheng Zhu", "Dongbin Zhao"], "title": "Empowering Multi-Robot Cooperation via Sequential World Models", "comment": null, "summary": "Model-based reinforcement learning (MBRL) has shown significant potential in\nrobotics due to its high sample efficiency and planning capability. However,\nextending MBRL to multi-robot cooperation remains challenging due to the\ncomplexity of joint dynamics. To address this, we propose the Sequential World\nModel (SeqWM), a novel framework that integrates the sequential paradigm into\nmodel-based multi-agent reinforcement learning. SeqWM employs independent,\nsequentially structured agent-wise world models to decompose complex joint\ndynamics. Latent rollouts and decision-making are performed through sequential\ncommunication, where each agent generates its future trajectory and plans its\nactions based on the predictions of its predecessors. This design enables\nexplicit intention sharing, enhancing cooperative performance, and reduces\ncommunication overhead to linear complexity. Results in challenging simulated\nenvironments (Bi-DexHands and Multi-Quad) show that SeqWM outperforms existing\nstate-of-the-art model-free and model-based baselines in both overall\nperformance and sample efficiency, while exhibiting advanced cooperative\nbehaviors such as predictive adaptation and role division. Furthermore, SeqWM\nhas been success fully deployed on physical quadruped robots, demonstrating its\neffectiveness in real-world multi-robot systems. Demos and code are available\nat: https://github.com/zhaozijie2022/seqwm-marl", "AI": {"tldr": "SeqWM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5e8f\u5217\u5316\u4e16\u754c\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u72ec\u7acb\u4f46\u987a\u5e8f\u901a\u4fe1\u7684\u667a\u80fd\u4f53\u7ea7\u4e16\u754c\u6a21\u578b\u6765\u5206\u89e3\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u590d\u6742\u8054\u5408\u52a8\u529b\u5b66\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u534f\u4f5c\u548c\u7ebf\u6027\u901a\u4fe1\u590d\u6742\u5ea6\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u673a\u5668\u4eba\u534f\u4f5c\u4e2d\u9762\u4e34\u7684\u8054\u5408\u52a8\u529b\u5b66\u590d\u6742\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u534f\u4f5c\u6548\u7387\u548c\u6837\u672c\u5229\u7528\u7387\u3002", "method": "\u91c7\u7528\u987a\u5e8f\u7ed3\u6784\u7684\u4e16\u754c\u6a21\u578b\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u72ec\u7acb\u6784\u5efa\u4e16\u754c\u6a21\u578b\u5e76\u901a\u8fc7\u987a\u5e8f\u901a\u4fe1\u8fdb\u884c\u6f5c\u5728\u72b6\u6001\u63a8\u6f14\u548c\u51b3\u7b56\u5236\u5b9a\uff0c\u524d\u4e00\u4e2a\u667a\u80fd\u4f53\u7684\u9884\u6d4b\u7ed3\u679c\u4f5c\u4e3a\u540e\u4e00\u4e2a\u667a\u80fd\u4f53\u7684\u8f93\u5165\u3002", "result": "\u5728Bi-DexHands\u548cMulti-Quad\u7b49\u4eff\u771f\u73af\u5883\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u7684model-free\u548cmodel-based\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6574\u4f53\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u6210\u529f\u90e8\u7f72\u5230\u771f\u5b9e\u56db\u8db3\u673a\u5668\u4eba\u7cfb\u7edf\u3002", "conclusion": "SeqWM\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u673a\u5668\u4eba\u534f\u4f5c\u4e2d\u7684\u590d\u6742\u52a8\u529b\u5b66\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u663e\u5f0f\u610f\u56fe\u5171\u4eab\u548c\u9ad8\u6548\u534f\u4f5c\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.13235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13235", "abs": "https://arxiv.org/abs/2509.13235", "authors": ["Linyue Cai", "Yuyang Cheng", "Xiaoding Shao", "Huiming Wang", "Yong Zhao", "Wei Zhang", "Kang Li"], "title": "A Scenario-Driven Cognitive Approach to Next-Generation AI Memory", "comment": null, "summary": "As artificial intelligence advances toward artificial general intelligence\n(AGI), the need for robust and human-like memory systems has become\nincreasingly evident. Current memory architectures often suffer from limited\nadaptability, insufficient multimodal integration, and an inability to support\ncontinuous learning. To address these limitations, we propose a scenario-driven\nmethodology that extracts essential functional requirements from representative\ncognitive scenarios, leading to a unified set of design principles for\nnext-generation AI memory systems. Based on this approach, we introduce the\n\\textbf{COgnitive Layered Memory Architecture (COLMA)}, a novel framework that\nintegrates cognitive scenarios, memory processes, and storage mechanisms into a\ncohesive design. COLMA provides a structured foundation for developing AI\nsystems capable of lifelong learning and human-like reasoning, thereby\ncontributing to the pragmatic development of AGI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u573a\u666f\u9a71\u52a8\u7684\u8ba4\u77e5\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784COLMA\uff0c\u7528\u4e8e\u89e3\u51b3\u5f53\u524dAI\u8bb0\u5fc6\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u4e0d\u8db3\u3001\u591a\u6a21\u6001\u6574\u5408\u4e0d\u5145\u5206\u7b49\u95ee\u9898\uff0c\u4e3aAGI\u53d1\u5c55\u63d0\u4f9b\u7ed3\u6784\u5316\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5411AGI\u53d1\u5c55\uff0c\u73b0\u6709\u8bb0\u5fc6\u7cfb\u7edf\u5b58\u5728\u9002\u5e94\u6027\u6709\u9650\u3001\u591a\u6a21\u6001\u6574\u5408\u4e0d\u8db3\u3001\u65e0\u6cd5\u652f\u6301\u6301\u7eed\u5b66\u4e60\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u548c\u7c7b\u4eba\u7684\u8bb0\u5fc6\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u573a\u666f\u9a71\u52a8\u65b9\u6cd5\uff0c\u4ece\u4ee3\u8868\u6027\u8ba4\u77e5\u573a\u666f\u4e2d\u63d0\u53d6\u5173\u952e\u529f\u80fd\u9700\u6c42\uff0c\u63d0\u51fa\u7edf\u4e00\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u5e76\u6784\u5efa\u8ba4\u77e5\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784COLMA\uff0c\u6574\u5408\u8ba4\u77e5\u573a\u666f\u3001\u8bb0\u5fc6\u8fc7\u7a0b\u548c\u5b58\u50a8\u673a\u5236\u3002", "result": "\u63d0\u51fa\u4e86COLMA\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u5177\u6709\u7ec8\u8eab\u5b66\u4e60\u548c\u7c7b\u4eba\u63a8\u7406\u80fd\u529b\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u57fa\u7840\u3002", "conclusion": "COLMA\u67b6\u6784\u4e3a\u4e0b\u4e00\u4ee3AI\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8eAGI\u7684\u5b9e\u9645\u53d1\u5c55\uff0c\u652f\u6301\u6301\u7eed\u5b66\u4e60\u548c\u4eba\u7c7b\u5316\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.13281", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13281", "abs": "https://arxiv.org/abs/2509.13281", "authors": ["Vincent Siu", "Nathan W. Henry", "Nicholas Crispino", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "RepIt: Representing Isolated Targets to Steer Language Models", "comment": null, "summary": "While activation steering in large language models (LLMs) is a growing area\nof research, methods can often incur broader effects than desired. This\nmotivates isolation of purer concept vectors to enable targeted interventions\nand understand LLM behavior at a more granular level. We present RepIt, a\nsimple and data-efficient framework for isolating concept-specific\nrepresentations. Across five frontier LLMs, RepIt enables precise\ninterventions: it selectively suppresses refusal on targeted concepts while\npreserving refusal elsewhere, producing models that answer WMD-related\nquestions while still scoring as safe on standard benchmarks. We further show\nthat the corrective signal localizes to just 100-200 neurons and that robust\ntarget representations can be extracted from as few as a dozen examples on a\nsingle A6000. This efficiency raises a dual concern: manipulations can be\nperformed with modest compute and data to extend to underrepresented\ndata-scarce topics while evading existing benchmarks. By disentangling refusal\nvectors with RepIt, this work demonstrates that targeted interventions can\ncounteract overgeneralization, laying the foundation for more granular control\nof model behavior.", "AI": {"tldr": "RepIt\u662f\u4e00\u4e2a\u7b80\u5355\u9ad8\u6548\u7684\u6982\u5ff5\u5411\u91cf\u63d0\u53d6\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u5c11\u91cf\u6570\u636e\u4e2d\u5206\u79bb\u51fa\u7279\u5b9a\u6982\u5ff5\u7684\u8868\u793a\uff0c\u5b9e\u73b0\u5bf9LLM\u884c\u4e3a\u7684\u7cbe\u51c6\u5e72\u9884\uff0c\u540c\u65f6\u907f\u514d\u5bf9\u5176\u4ed6\u529f\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\u5f80\u5f80\u4f1a\u4ea7\u751f\u8d85\u51fa\u9884\u671f\u7684\u5e7f\u6cdb\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u7eaf\u51c0\u7684\u6982\u5ff5\u5411\u91cf\u6765\u5b9e\u73b0\u9488\u5bf9\u6027\u5e72\u9884\u548c\u66f4\u7ec6\u7c92\u5ea6\u7684LLM\u884c\u4e3a\u7406\u89e3\u3002", "method": "\u63d0\u51faRepIt\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u9ad8\u6548\u7684\u65b9\u5f0f\u63d0\u53d6\u6982\u5ff5\u7279\u5b9a\u8868\u793a\uff0c\u80fd\u591f\u4ece\u4ec5\u5341\u51e0\u4e2a\u793a\u4f8b\u4e2d\u5206\u79bb\u51fa\u7a33\u5065\u7684\u76ee\u6807\u8868\u793a\uff0c\u5e76\u5c06\u77eb\u6b63\u4fe1\u53f7\u5b9a\u4f4d\u5230100-200\u4e2a\u795e\u7ecf\u5143\u3002", "result": "\u5728\u4e94\u4e2a\u524d\u6cbfLLM\u4e0a\uff0cRepIt\u5b9e\u73b0\u4e86\u7cbe\u51c6\u5e72\u9884\uff1a\u9009\u62e9\u6027\u6291\u5236\u7279\u5b9a\u6982\u5ff5\u7684\u62d2\u7edd\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u4ed6\u9886\u57df\u7684\u62d2\u7edd\u80fd\u529b\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u56de\u7b54WMD\u76f8\u5173\u95ee\u9898\u4f46\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4ecd\u4fdd\u6301\u5b89\u5168\u8bc4\u5206\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7RepIt\u5206\u79bb\u62d2\u7edd\u5411\u91cf\uff0c\u8bc1\u660e\u9488\u5bf9\u6027\u5e72\u9884\u53ef\u4ee5\u62b5\u6d88\u8fc7\u5ea6\u6cdb\u5316\uff0c\u4e3a\u66f4\u7ec6\u7c92\u5ea6\u7684\u6a21\u578b\u884c\u4e3a\u63a7\u5236\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u5173\u4e8e\u64cd\u7eb5\u53ef\u80fd\u6027\u7684\u53cc\u91cd\u62c5\u5fe7\u3002"}}
{"id": "2509.13126", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13126", "abs": "https://arxiv.org/abs/2509.13126", "authors": ["Miquel Oller", "An Dang", "Nima Fazeli"], "title": "Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation", "comment": null, "summary": "Tactile sensors have long been valued for their perceptual capabilities,\noffering rich insights into the otherwise hidden interface between the robot\nand grasped objects. Yet their inherent compliance -- a key driver of\nforce-rich interactions -- remains underexplored. The central challenge is to\ncapture the complex, nonlinear dynamics introduced by these passive-compliant\nelements. Here, we present a computationally efficient non-holonomic\nhydroelastic model that accurately models path-dependent contact force\ndistributions and dynamic surface area variations. Our insight is to extend the\nobject's state space, explicitly incorporating the distributed forces generated\nby the compliant sensor. Our differentiable formulation not only accounts for\npath-dependent behavior but also enables gradient-based trajectory\noptimization, seamlessly integrating with high-resolution tactile feedback. We\ndemonstrate the effectiveness of our approach across a range of simulated and\nreal-world experiments and highlight the importance of modeling the path\ndependence of sensor dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u975e\u5b8c\u6574\u6c34\u5f39\u6027\u6a21\u578b\uff0c\u7528\u4e8e\u51c6\u786e\u5efa\u6a21\u8def\u5f84\u4f9d\u8d56\u7684\u63a5\u89e6\u529b\u5206\u5e03\u548c\u52a8\u6001\u8868\u9762\u79ef\u53d8\u5316\uff0c\u901a\u8fc7\u6269\u5c55\u7269\u4f53\u72b6\u6001\u7a7a\u95f4\u6765\u663e\u5f0f\u5305\u542b\u67d4\u6027\u4f20\u611f\u5668\u4ea7\u751f\u7684\u5206\u5e03\u5f0f\u529b", "motivation": "\u89e6\u89c9\u4f20\u611f\u5668\u867d\u7136\u5177\u6709\u51fa\u8272\u7684\u611f\u77e5\u80fd\u529b\uff0c\u4f46\u5176\u56fa\u6709\u7684\u67d4\u987a\u6027\uff08\u9a71\u52a8\u529b\u4e30\u5bcc\u4ea4\u4e92\u7684\u5173\u952e\u56e0\u7d20\uff09\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u6355\u6349\u8fd9\u4e9b\u88ab\u52a8\u67d4\u987a\u5143\u4ef6\u5f15\u5165\u7684\u590d\u6742\u975e\u7ebf\u6027\u52a8\u529b\u5b66", "method": "\u5f00\u53d1\u4e86\u53ef\u5fae\u5206\u7684\u975e\u5b8c\u6574\u6c34\u5f39\u6027\u6a21\u578b\uff0c\u6269\u5c55\u7269\u4f53\u72b6\u6001\u7a7a\u95f4\u4ee5\u663e\u5f0f\u5305\u542b\u67d4\u6027\u4f20\u611f\u5668\u4ea7\u751f\u7684\u5206\u5e03\u5f0f\u529b\u3002\u8be5\u6a21\u578b\u80fd\u591f\u5904\u7406\u8def\u5f84\u4f9d\u8d56\u884c\u4e3a\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u68af\u5ea6\u7684\u8f68\u8ff9\u4f18\u5316", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5f3a\u8c03\u4e86\u5efa\u6a21\u4f20\u611f\u5668\u52a8\u529b\u5b66\u8def\u5f84\u4f9d\u8d56\u6027\u7684\u91cd\u8981\u6027", "conclusion": "\u8be5\u6a21\u578b\u4e0d\u4ec5\u80fd\u591f\u51c6\u786e\u6355\u6349\u8def\u5f84\u4f9d\u8d56\u7684\u63a5\u89e6\u529b\u5206\u5e03\uff0c\u8fd8\u80fd\u4e0e\u9ad8\u5206\u8fa8\u7387\u89e6\u89c9\u53cd\u9988\u65e0\u7f1d\u96c6\u6210\uff0c\u4e3a\u673a\u5668\u4eba\u4ea4\u4e92\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u529b\u5efa\u6a21\u65b9\u6cd5"}}
{"id": "2509.13288", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13288", "abs": "https://arxiv.org/abs/2509.13288", "authors": ["Marjorie McShane", "Sergei Nirenburg", "Sanjay Oruganti", "Jesse English"], "title": "Shapes of Cognition for Computational Cognitive Modeling", "comment": null, "summary": "Shapes of cognition is a new conceptual paradigm for the computational\ncognitive modeling of Language-Endowed Intelligent Agents (LEIAs). Shapes are\nremembered constellations of sensory, linguistic, conceptual, episodic, and\nprocedural knowledge that allow agents to cut through the complexity of real\nlife the same way as people do: by expecting things to be typical, recognizing\npatterns, acting by habit, reasoning by analogy, satisficing, and generally\nminimizing cognitive load to the degree situations permit. Atypical outcomes\nare treated using shapes-based recovery methods, such as learning on the fly,\nasking a human partner for help, or seeking an actionable, even if imperfect,\nsituational understanding. Although shapes is an umbrella term, it is not\nvague: shapes-based modeling involves particular objectives, hypotheses,\nmodeling strategies, knowledge bases, and actual models of wide-ranging\nphenomena, all implemented within a particular cognitive architecture. Such\nspecificity is needed both to vet our hypotheses and to achieve our practical\naims of building useful agent systems that are explainable, extensible, and\nworthy of our trust, even in critical domains. However, although the LEIA\nexample of shapes-based modeling is specific, the principles can be applied\nmore broadly, giving new life to knowledge-based and hybrid AI.", "AI": {"tldr": "Shapes of cognition\u662f\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u8ba4\u77e5\u5efa\u6a21\u8303\u5f0f\uff0c\u901a\u8fc7\u8bb0\u5fc6\u5316\u7684\u77e5\u8bc6\u661f\u5ea7\u6765\u6a21\u62df\u8bed\u8a00\u667a\u80fd\u4f53\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u50cf\u4eba\u7c7b\u4e00\u6837\u901a\u8fc7\u6a21\u5f0f\u8bc6\u522b\u3001\u7c7b\u6bd4\u63a8\u7406\u7b49\u65b9\u5f0f\u5904\u7406\u590d\u6742\u73b0\u5b9e\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8bed\u8a00\u667a\u80fd\u4f53\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u8ba4\u77e5\u5904\u7406\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u65b9\u5f0f\uff08\u5982\u6a21\u5f0f\u8bc6\u522b\u3001\u4e60\u60ef\u884c\u4e3a\u3001\u7c7b\u6bd4\u63a8\u7406\uff09\u7684\u65b0\u8303\u5f0f\uff0c\u4ee5\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\u5e76\u5904\u7406\u975e\u5178\u578b\u60c5\u51b5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5f62\u72b6\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u5305\u62ec\u5177\u4f53\u7684\u76ee\u6807\u3001\u5047\u8bbe\u3001\u5efa\u6a21\u7b56\u7565\u3001\u77e5\u8bc6\u5e93\u548c\u5b9e\u9645\u6a21\u578b\uff0c\u5728\u7279\u5b9a\u8ba4\u77e5\u67b6\u6784\u4e2d\u5b9e\u73b0\u3002\u901a\u8fc7\u8bb0\u5fc6\u5316\u7684\u611f\u5b98\u3001\u8bed\u8a00\u3001\u6982\u5ff5\u3001\u60c5\u666f\u548c\u7a0b\u5e8f\u77e5\u8bc6\u661f\u5ea7\u6765\u5904\u7406\u4fe1\u606f\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u4f53\u7684\u3001\u53ef\u9a8c\u8bc1\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u80fd\u591f\u6784\u5efa\u53ef\u89e3\u91ca\u3001\u53ef\u6269\u5c55\u4e14\u503c\u5f97\u4fe1\u8d56\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5373\u4f7f\u5728\u5173\u952e\u9886\u57df\u4e5f\u80fd\u5e94\u7528\u3002", "conclusion": "\u57fa\u4e8e\u5f62\u72b6\u7684\u5efa\u6a21\u4e0d\u4ec5\u9002\u7528\u4e8e\u8bed\u8a00\u667a\u80fd\u4f53\uff0c\u5176\u539f\u5219\u53ef\u4ee5\u66f4\u5e7f\u6cdb\u5730\u5e94\u7528\u4e8e\u77e5\u8bc6\u578b\u548c\u6df7\u5408\u578bAI\uff0c\u4e3a\u8fd9\u4e9b\u9886\u57df\u6ce8\u5165\u65b0\u7684\u6d3b\u529b\u3002"}}
{"id": "2509.13132", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13132", "abs": "https://arxiv.org/abs/2509.13132", "authors": ["Zhihao Zhang", "Chengyang Peng", "Minghao Zhu", "Ekim Yurtsever", "Keith A. Redmill"], "title": "An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios", "comment": null, "summary": "Autonomous driving in dense, dynamic environments requires decision-making\nsystems that can exploit both spatial structure and long-horizon temporal\ndependencies while remaining robust to uncertainty. This work presents a novel\nframework that integrates multi-channel bird's-eye-view occupancy grids with\ntransformer-based sequence modeling for tactical driving in complex roundabout\nscenarios. To address the imbalance between frequent low-risk states and rare\nsafety-critical decisions, we propose the Uncertainty-Weighted Decision\nTransformer (UWDT). UWDT employs a frozen teacher transformer to estimate\nper-token predictive entropy, which is then used as a weight in the student\nmodel's loss function. This mechanism amplifies learning from uncertain,\nhigh-impact states while maintaining stability across common low-risk\ntransitions. Experiments in a roundabout simulator, across varying traffic\ndensities, show that UWDT consistently outperforms other baselines in terms of\nreward, collision rate, and behavioral stability. The results demonstrate that\nuncertainty-aware, spatial-temporal transformers can deliver safer and more\nefficient decision-making for autonomous driving in complex traffic\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u51b3\u7b56\u53d8\u6362\u5668(UWDT)\uff0c\u901a\u8fc7\u591a\u901a\u9053\u9e1f\u77b0\u56fe\u5360\u7528\u7f51\u683c\u548c\u53d8\u6362\u5668\u5e8f\u5217\u5efa\u6a21\uff0c\u5728\u590d\u6742\u73af\u5c9b\u573a\u666f\u4e2d\u5b9e\u73b0\u66f4\u5b89\u5168\u9ad8\u6548\u7684\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56", "motivation": "\u5bc6\u96c6\u52a8\u6001\u73af\u5883\u4e2d\u7684\u81ea\u52a8\u9a7e\u9a76\u9700\u8981\u80fd\u591f\u5229\u7528\u7a7a\u95f4\u7ed3\u6784\u548c\u957f\u671f\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u540c\u65f6\u5bf9\u4e0d\u786e\u5b9a\u6027\u4fdd\u6301\u9c81\u68d2\u6027\u7684\u51b3\u7b56\u7cfb\u7edf\uff0c\u9700\u8981\u89e3\u51b3\u9891\u7e41\u4f4e\u98ce\u9669\u72b6\u6001\u548c\u7f55\u89c1\u5b89\u5168\u5173\u952e\u51b3\u7b56\u4e4b\u95f4\u7684\u4e0d\u5e73\u8861\u95ee\u9898", "method": "UWDT\u6846\u67b6\u96c6\u6210\u591a\u901a\u9053\u9e1f\u77b0\u56fe\u5360\u7528\u7f51\u683c\u4e0e\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u5e8f\u5217\u5efa\u6a21\uff0c\u4f7f\u7528\u51bb\u7ed3\u6559\u5e08\u53d8\u6362\u5668\u4f30\u8ba1\u6bcf\u4e2atoken\u7684\u9884\u6d4b\u71b5\uff0c\u4f5c\u4e3a\u5b66\u751f\u6a21\u578b\u635f\u5931\u51fd\u6570\u7684\u6743\u91cd\uff0c\u653e\u5927\u5bf9\u4e0d\u786e\u5b9a\u9ad8\u5f71\u54cd\u72b6\u6001\u7684\u5b66\u4e60", "result": "\u5728\u73af\u5c9b\u6a21\u62df\u5668\u4e2d\u4e0d\u540c\u4ea4\u901a\u5bc6\u5ea6\u4e0b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cUWDT\u5728\u5956\u52b1\u3001\u78b0\u649e\u7387\u548c\u884c\u4e3a\u7a33\u5b9a\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u65f6\u7a7a\u53d8\u6362\u5668\u80fd\u591f\u5728\u590d\u6742\u4ea4\u901a\u73af\u5883\u4e2d\u4e3a\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u66f4\u5b89\u5168\u9ad8\u6548\u7684\u51b3\u7b56"}}
{"id": "2509.13177", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13177", "abs": "https://arxiv.org/abs/2509.13177", "authors": ["Salvatore Esposito", "Mat\u00edas Mattamala", "Daniel Rebain", "Francis Xiatian Zhang", "Kevin Dhaliwal", "Mohsen Khadem", "Subramanian Ramamoorthy"], "title": "ROOM: A Physics-Based Continuum Robot Simulator for Photorealistic Medical Datasets Generation", "comment": null, "summary": "Continuum robots are advancing bronchoscopy procedures by accessing complex\nlung airways and enabling targeted interventions. However, their development is\nlimited by the lack of realistic training and test environments: Real data is\ndifficult to collect due to ethical constraints and patient safety concerns,\nand developing autonomy algorithms requires realistic imaging and physical\nfeedback. We present ROOM (Realistic Optical Observation in Medicine), a\ncomprehensive simulation framework designed for generating photorealistic\nbronchoscopy training data. By leveraging patient CT scans, our pipeline\nrenders multi-modal sensor data including RGB images with realistic noise and\nlight specularities, metric depth maps, surface normals, optical flow and point\nclouds at medically relevant scales. We validate the data generated by ROOM in\ntwo canonical tasks for medical robotics -- multi-view pose estimation and\nmonocular depth estimation, demonstrating diverse challenges that\nstate-of-the-art methods must overcome to transfer to these medical settings.\nFurthermore, we show that the data produced by ROOM can be used to fine-tune\nexisting depth estimation models to overcome these challenges, also enabling\nother downstream applications such as navigation. We expect that ROOM will\nenable large-scale data generation across diverse patient anatomies and\nprocedural scenarios that are challenging to capture in clinical settings. Code\nand data: https://github.com/iamsalvatore/room.", "AI": {"tldr": "ROOM\u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u903c\u771f\u652f\u6c14\u7ba1\u955c\u8bad\u7ec3\u6570\u636e\u7684\u7efc\u5408\u4eff\u771f\u6846\u67b6\uff0c\u901a\u8fc7\u60a3\u8005CT\u626b\u63cf\u6e32\u67d3\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u771f\u5b9e\u6570\u636e\u6536\u96c6\u56f0\u96be\u7684\u95ee\u9898\u3002", "motivation": "\u8fde\u7eed\u4f53\u673a\u5668\u4eba\u5728\u652f\u6c14\u7ba1\u955c\u68c0\u67e5\u4e2d\u7684\u53d1\u5c55\u53d7\u5230\u7f3a\u4e4f\u771f\u5b9e\u8bad\u7ec3\u548c\u6d4b\u8bd5\u73af\u5883\u7684\u9650\u5236\uff0c\u771f\u5b9e\u6570\u636e\u7531\u4e8e\u4f26\u7406\u7ea6\u675f\u548c\u60a3\u8005\u5b89\u5168\u95ee\u9898\u96be\u4ee5\u6536\u96c6\u3002", "method": "\u5229\u7528\u60a3\u8005CT\u626b\u63cf\uff0c\u6e32\u67d3\u5305\u62ecRGB\u56fe\u50cf\u3001\u6df1\u5ea6\u56fe\u3001\u8868\u9762\u6cd5\u7ebf\u3001\u5149\u6d41\u548c\u70b9\u4e91\u7b49\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\uff0c\u5177\u6709\u903c\u771f\u7684\u566a\u58f0\u548c\u5149\u7167\u6548\u679c\u3002", "result": "\u9a8c\u8bc1\u4e86ROOM\u751f\u6210\u7684\u6570\u636e\u5728\u591a\u89c6\u89d2\u59ff\u6001\u4f30\u8ba1\u548c\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5fae\u8c03\u73b0\u6709\u6df1\u5ea6\u4f30\u8ba1\u6a21\u578b\u5e76\u652f\u6301\u5bfc\u822a\u7b49\u4e0b\u6e38\u5e94\u7528\u3002", "conclusion": "ROOM\u80fd\u591f\u5728\u5927\u89c4\u6a21\u60a3\u8005\u89e3\u5256\u7ed3\u6784\u548c\u624b\u672f\u573a\u666f\u4e2d\u751f\u6210\u6570\u636e\uff0c\u8fd9\u4e9b\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u96be\u4ee5\u83b7\u53d6\uff0c\u6709\u671b\u63a8\u52a8\u533b\u7597\u673a\u5668\u4eba\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.13200", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13200", "abs": "https://arxiv.org/abs/2509.13200", "authors": ["Moonyoung Lee", "Dong Ki Kim", "Jai Krishna Bandi", "Max Smith", "Aileen Liao", "Ali-akbar Agha-mohammadi", "Shayegan Omidshafiei"], "title": "StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening", "comment": "7 pages", "summary": "Humanoid robots promise to operate in everyday human environments without\nrequiring modifications to the surroundings. Among the many skills needed,\nopening doors is essential, as doors are the most common gateways in built\nspaces and often limit where a robot can go. Door opening, however, poses\nunique challenges as it is a long-horizon task under partial observability,\nsuch as reasoning about the door's unobservable latch state that dictates\nwhether the robot should rotate the handle or push the door. This ambiguity\nmakes standard behavior cloning prone to mode collapse, yielding blended or\nout-of-sequence actions. We introduce StageACT, a stage-conditioned imitation\nlearning framework that augments low-level policies with task-stage inputs.\nThis effective addition increases robustness to partial observability, leading\nto higher success rates and shorter completion times. On a humanoid operating\nin a real-world office environment, StageACT achieves a 55% success rate on\npreviously unseen doors, more than doubling the best baseline. Moreover, our\nmethod supports intentional behavior guidance through stage prompting, enabling\nrecovery behaviors. These results highlight stage conditioning as a lightweight\nyet powerful mechanism for long-horizon humanoid loco-manipulation.", "AI": {"tldr": "StageACT\u662f\u4e00\u4e2a\u9636\u6bb5\u6761\u4ef6\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e3a\u4f4e\u7ea7\u7b56\u7565\u6dfb\u52a0\u4efb\u52a1\u9636\u6bb5\u8f93\u5165\u6765\u89e3\u51b3\u4eba\u5f62\u673a\u5668\u4eba\u5f00\u95e8\u4efb\u52a1\u4e2d\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u529e\u516c\u73af\u5883\u4e2d\u5bf9\u672a\u89c1\u8fc7\u7684\u95e8\u5b9e\u73b0\u4e8655%\u7684\u6210\u529f\u7387\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u9ad8\u4e86\u4e00\u500d\u591a\u3002", "motivation": "\u4eba\u5f62\u673a\u5668\u4eba\u9700\u8981\u5728\u4eba\u7c7b\u73af\u5883\u4e2d\u64cd\u4f5c\uff0c\u5f00\u95e8\u662f\u57fa\u672c\u6280\u80fd\u3002\u5f00\u95e8\u4efb\u52a1\u9762\u4e34\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u95e8\u9501\u72b6\u6001\u7684\u4e0d\u53ef\u89c2\u6d4b\u6027\uff0c\u8fd9\u5bfc\u81f4\u6807\u51c6\u884c\u4e3a\u514b\u9686\u5bb9\u6613\u51fa\u73b0\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86StageACT\u6846\u67b6\uff0c\u901a\u8fc7\u9636\u6bb5\u6761\u4ef6\u6a21\u4eff\u5b66\u4e60\uff0c\u4e3a\u4f4e\u7ea7\u7b56\u7565\u589e\u52a0\u4efb\u52a1\u9636\u6bb5\u8f93\u5165\uff0c\u589e\u5f3a\u5bf9\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u652f\u6301\u901a\u8fc7\u9636\u6bb5\u63d0\u793a\u8fdb\u884c\u6709\u610f\u884c\u4e3a\u5f15\u5bfc\u3002", "result": "\u5728\u771f\u5b9e\u529e\u516c\u73af\u5883\u4e2d\uff0cStageACT\u5bf9\u672a\u89c1\u8fc7\u7684\u95e8\u5b9e\u73b0\u4e8655%\u7684\u6210\u529f\u7387\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u9ad8\u4e86\u4e00\u500d\u591a\uff0c\u540c\u65f6\u7f29\u77ed\u4e86\u5b8c\u6210\u65f6\u95f4\uff0c\u5e76\u652f\u6301\u6062\u590d\u884c\u4e3a\u3002", "conclusion": "\u9636\u6bb5\u6761\u4ef6\u673a\u5236\u662f\u957f\u89c6\u91ce\u4eba\u5f62\u673a\u5668\u4eba\u8fd0\u52a8\u64cd\u4f5c\u7684\u8f7b\u91cf\u7ea7\u4f46\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u6311\u6218\u3002"}}
{"id": "2509.13239", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13239", "abs": "https://arxiv.org/abs/2509.13239", "authors": ["Tianxu An", "Flavio De Vincenti", "Yuntao Ma", "Marco Hutter", "Stelian Coros"], "title": "Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum", "comment": null, "summary": "We present a hierarchical RL pipeline for training one-armed legged robots to\nperform pick-and-place (P&P) tasks end-to-end -- from approaching the payload\nto releasing it at a target area -- in both single-robot and cooperative\ndual-robot settings. We introduce a novel dynamic reward curriculum that\nenables a single policy to efficiently learn long-horizon P&P operations by\nprogressively guiding the agents through payload-centered sub-objectives.\nCompared to state-of-the-art approaches for long-horizon RL tasks, our method\nimproves training efficiency by 55% and reduces execution time by 18.6% in\nsimulation experiments. In the dual-robot case, we show that our policy enables\neach robot to attend to different components of its observation space at\ndistinct task stages, promoting effective coordination via autonomous attention\nshifts. We validate our method through real-world experiments using ANYmal D\nplatforms in both single- and dual-robot scenarios. To our knowledge, this is\nthe first RL pipeline that tackles the full scope of collaborative P&P with two\nlegged manipulators.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\u5355\u81c2\u817f\u5f0f\u673a\u5668\u4eba\u6267\u884c\u7aef\u5230\u7aef\u62fe\u653e\u4efb\u52a1\uff0c\u5728\u5355\u673a\u548c\u53cc\u673a\u534f\u4f5c\u573a\u666f\u4e2d\u5747\u6709\u6548\uff0c\u901a\u8fc7\u52a8\u6001\u5956\u52b1\u8bfe\u7a0b\u63d0\u5347\u8bad\u7ec3\u6548\u738755%\uff0c\u51cf\u5c11\u6267\u884c\u65f6\u95f418.6%", "motivation": "\u89e3\u51b3\u817f\u5f0f\u673a\u5668\u4eba\u5728\u957f\u65f6\u57df\u62fe\u653e\u4efb\u52a1\u4e2d\u7684\u8bad\u7ec3\u6548\u7387\u95ee\u9898\uff0c\u7279\u522b\u662f\u53cc\u673a\u5668\u4eba\u534f\u4f5c\u573a\u666f\u4e0b\u7684\u534f\u8c03\u6311\u6218", "method": "\u91c7\u7528\u5206\u5c42RL\u6846\u67b6\u548c\u65b0\u578b\u52a8\u6001\u5956\u52b1\u8bfe\u7a0b\uff0c\u901a\u8fc7\u9010\u6b65\u5f15\u5bfc\u673a\u5668\u4eba\u5b8c\u6210\u4ee5\u8f7d\u8377\u4e3a\u4e2d\u5fc3\u7684\u5b50\u76ee\u6807\u6765\u5b66\u4e60\u957f\u65f6\u57df\u64cd\u4f5c", "result": "\u5728\u4eff\u771f\u5b9e\u9a8c\u4e2d\u8bad\u7ec3\u6548\u7387\u63d0\u534755%\uff0c\u6267\u884c\u65f6\u95f4\u51cf\u5c1118.6%\uff1b\u53cc\u673a\u5668\u4eba\u573a\u666f\u4e2d\u80fd\u81ea\u4e3b\u8c03\u6574\u6ce8\u610f\u529b\u5b9e\u73b0\u6709\u6548\u534f\u8c03", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5904\u7406\u53cc\u817f\u5f0f\u673a\u68b0\u81c2\u534f\u4f5c\u62fe\u653e\u5b8c\u6574\u6d41\u7a0b\u7684RL\u6846\u67b6\uff0c\u5728\u771f\u5b9eANYmal D\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027"}}
{"id": "2509.13249", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13249", "abs": "https://arxiv.org/abs/2509.13249", "authors": ["Ye Li", "Daming Liu", "Yanhe Zhu", "Junming Zhang", "Yongsheng Luo", "Ziqi Wang", "Chenyu Liu", "Jie Zhao"], "title": "Design and Control of a Perching Drone Inspired by the Prey-Capturing Mechanism of Venus Flytrap", "comment": null, "summary": "The endurance and energy efficiency of drones remain critical challenges in\ntheir design and operation. To extend mission duration, numerous studies\nexplored perching mechanisms that enable drones to conserve energy by\ntemporarily suspending flight. This paper presents a new perching drone that\nutilizes an active flexible perching mechanism inspired by the rapid predation\nmechanism of the Venus flytrap, achieving perching in less than 100 ms. The\nproposed system is designed for high-speed adaptability to the perching\ntargets. The overall drone design is outlined, followed by the development and\nvalidation of the biomimetic perching structure. To enhance the system\nstability, a cascade extended high-gain observer (EHGO) based control method is\ndeveloped, which can estimate and compensate for the external disturbance in\nreal time. The experimental results demonstrate the adaptability of the\nperching structure and the superiority of the cascaded EHGO in resisting wind\nand perching disturbances.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u6355\u8747\u8349\u542f\u53d1\u7684\u4e3b\u52a8\u67d4\u6027\u6816\u606f\u65e0\u4eba\u673a\uff0c\u53ef\u5728100\u6beb\u79d2\u5185\u5b8c\u6210\u6816\u606f\uff0c\u91c7\u7528\u7ea7\u8054\u9ad8\u589e\u76ca\u89c2\u6d4b\u5668\u63a7\u5236\u65b9\u6cd5\u5b9e\u65f6\u8865\u507f\u5916\u90e8\u6270\u52a8\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u6297\u98ce\u548c\u6816\u606f\u6270\u52a8\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u65e0\u4eba\u673a\u7eed\u822a\u80fd\u529b\u548c\u80fd\u6e90\u6548\u7387\u662f\u5176\u8bbe\u8ba1\u548c\u64cd\u4f5c\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002\u4e3a\u4e86\u5ef6\u957f\u4efb\u52a1\u65f6\u95f4\uff0c\u9700\u8981\u63a2\u7d22\u80fd\u591f\u8ba9\u65e0\u4eba\u673a\u901a\u8fc7\u6682\u65f6\u505c\u6b62\u98de\u884c\u6765\u8282\u7701\u80fd\u91cf\u7684\u6816\u606f\u673a\u5236\u3002", "method": "\u5f00\u53d1\u4e86\u53d7\u6355\u8747\u8349\u5feb\u901f\u6355\u98df\u673a\u5236\u542f\u53d1\u7684\u4e3b\u52a8\u67d4\u6027\u6816\u606f\u7ed3\u6784\uff0c\u8bbe\u8ba1\u4e86\u6574\u4f53\u65e0\u4eba\u673a\u7cfb\u7edf\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u7ea7\u8054\u6269\u5c55\u9ad8\u589e\u76ca\u89c2\u6d4b\u5668(EHGO)\u7684\u63a7\u5236\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u65f6\u4f30\u8ba1\u548c\u8865\u507f\u5916\u90e8\u6270\u52a8\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6816\u606f\u7ed3\u6784\u5177\u6709\u826f\u597d\u7684\u9002\u5e94\u6027\uff0c\u7ea7\u8054EHGO\u63a7\u5236\u65b9\u6cd5\u5728\u62b5\u6297\u98ce\u548c\u6816\u606f\u6270\u52a8\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u5728100\u6beb\u79d2\u5185\u7684\u5feb\u901f\u6816\u606f\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u7269\u542f\u53d1\u7684\u5feb\u901f\u6816\u606f\u65e0\u4eba\u673a\u7cfb\u7edf\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u67d4\u6027\u6816\u606f\u7ed3\u6784\u548c\u5148\u8fdb\u7684\u63a7\u5236\u7b97\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u7eed\u822a\u548c\u6297\u6270\u52a8\u95ee\u9898\uff0c\u4e3a\u65e0\u4eba\u673a\u957f\u65f6\u95f4\u4efb\u52a1\u6267\u884c\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13279", "categories": ["cs.RO", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13279", "abs": "https://arxiv.org/abs/2509.13279", "authors": ["Sanjay Oruganti", "Sergei Nirenburg", "Marjorie McShane", "Jesse English", "Michael K. Roberts", "Christian Arndt", "Carlos Gonzalez", "Mingyo Seo", "Luis Sentis"], "title": "HARMONIC: A Content-Centric Cognitive Robotic Architecture", "comment": null, "summary": "This paper introduces HARMONIC, a cognitive-robotic architecture designed for\nrobots in human-robotic teams. HARMONIC supports semantic perception\ninterpretation, human-like decision-making, and intentional language\ncommunication. It addresses the issues of safety and quality of results; aims\nto solve problems of data scarcity, explainability, and safety; and promotes\ntransparency and trust. Two proof-of-concept HARMONIC-based robotic systems are\ndemonstrated, each implemented in both a high-fidelity simulation environment\nand on physical robotic platforms.", "AI": {"tldr": "HARMONIC\u662f\u4e00\u4e2a\u8ba4\u77e5\u673a\u5668\u4eba\u67b6\u6784\uff0c\u7528\u4e8e\u4eba\u673a\u534f\u4f5c\u56e2\u961f\u4e2d\u7684\u673a\u5668\u4eba\uff0c\u652f\u6301\u8bed\u4e49\u611f\u77e5\u89e3\u91ca\u3001\u7c7b\u4eba\u51b3\u7b56\u548c\u610f\u56fe\u8bed\u8a00\u901a\u4fe1\uff0c\u65e8\u5728\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5b89\u5168\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4eba\u673a\u534f\u4f5c\u56e2\u961f\u4e2d\u673a\u5668\u4eba\u7684\u5b89\u5168\u6027\u3001\u7ed3\u679c\u8d28\u91cf\u95ee\u9898\uff0c\u4ee5\u53ca\u6570\u636e\u7a00\u7f3a\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5b89\u5168\u6027\u7b49\u6311\u6218\uff0c\u4fc3\u8fdb\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3002", "method": "\u5f00\u53d1HARMONIC\u8ba4\u77e5\u673a\u5668\u4eba\u67b6\u6784\uff0c\u652f\u6301\u8bed\u4e49\u611f\u77e5\u89e3\u91ca\u3001\u7c7b\u4eba\u51b3\u7b56\u548c\u610f\u56fe\u8bed\u8a00\u901a\u4fe1\uff0c\u5e76\u5728\u9ad8\u4fdd\u771f\u6a21\u62df\u73af\u5883\u548c\u7269\u7406\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e24\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edf\u3002", "result": "\u6210\u529f\u5f00\u53d1\u5e76\u6f14\u793a\u4e86\u4e24\u4e2a\u57fa\u4e8eHARMONIC\u7684\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u5206\u522b\u5728\u6a21\u62df\u73af\u5883\u548c\u7269\u7406\u5e73\u53f0\u4e0a\u5b9e\u73b0\u3002", "conclusion": "HARMONIC\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
