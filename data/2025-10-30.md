<div id=toc></div>

# Table of Contents

- [econ.TH](#econ.TH) [Total: 4]
- [econ.GN](#econ.GN) [Total: 4]
- [cs.AI](#cs.AI) [Total: 28]
- [econ.EM](#econ.EM) [Total: 4]
- [cs.CY](#cs.CY) [Total: 18]
- [cs.RO](#cs.RO) [Total: 30]
- [stat.AP](#stat.AP) [Total: 5]
- [eess.SY](#eess.SY) [Total: 22]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.SI](#cs.SI) [Total: 5]


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [1] [Learning to Unlearn: Education as a Remedy for Misspecified Beliefs](https://arxiv.org/abs/2510.24735)
*Daria Fedyaeva,Georgy Lukyanov,Hannah Tollié*

Main category: econ.TH

TL;DR: 该研究探讨了教育如何纠正错误信念，分析了教育在打破错误信息级联中的作用及其福利影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在序列社会学习模型中，未受教育个体对行动历史的误解问题，以及教育如何帮助纠正这些错误信念。

Method: 定义了错误信念完美贝叶斯均衡，使用阈值规则和单对数似然指数来分析教育决策，开发了教育价值统计量来比较受教育与未受教育决策的准确性。

Result: 研究表明教育能够以高概率在有限时间内打破错误级联，提供了明确的预期打破时间界限，并量化了教育带来的福利增益。

Conclusion: 教育是纠正错误信念的有效工具，即使小额教育补贴也能显著提高打破级联的概率并改善社会福利。

Abstract: We study education as a remedy for misspecified beliefs in a canonical
sequential social-learning model. Uneducated agents misinterpret action
histories - treating actions as if they were independent signals and,
potentially, overstating signal precision - while educated agents use the
correct likelihoods (and may also enjoy higher private precision). We define a
misspecified-belief PBE and show existence with a simple structure: education
is a cutoff in the realized cost and actions are threshold rules in a single
log-likelihood index. A closed-form value-of-education statistic compares the
accuracy of the educated versus uneducated decision at any history; this yields
transparent conditions for self-education. When a misspecified process sustains
an incorrect cascade, uniformly positive private value and a positive flip
probability imply that education breaks the cascade almost surely in finite
time, with an explicit bound on expected break time. We quantify welfare gains
from making education available and show how small per-education subsidies
sharply raise de-cascading probabilities and improve discounted welfare.
Extensions cover imperfect observability of education choices and a planner who
deploys history-dependent subsidies.

</details>


### [2] [Frequentist Persuasion](https://arxiv.org/abs/2510.25066)
*Arnav Sood,James Best*

Main category: econ.TH

TL;DR: 研究发送者如何通过私下选择实验来说服策略上幼稚的决策者，决策者通过从（状态、消息）样本中学习形成后验信念。在正则条件下，经验收益函数会收敛到完全信息基准。


<details>
  <summary>Details</summary>
Motivation: 研究在发送者私下选择实验且决策者通过样本学习的情况下，信息传递和说服的效果如何收敛到贝叶斯基准，以及有限样本大小如何影响实验设计。

Method: 使用非参数学习方法，决策者从独立同分布的（状态、消息）样本中形成后验信念。分析经验收益函数的收敛性，并研究有限样本大小对发送者实验选择的影响。

Result: 经验收益函数会收敛到完全信息基准，收益和最优信号收敛到贝叶斯基准。有限样本大小的影响是非单调的：在某些情况下会诱导比贝叶斯基准更信息丰富的实验，在偏好完全一致的情况下也会减少信息揭示。

Conclusion: 对于状态独立偏好的问题，存在一个最优的有限样本大小。尽管决策者总是偏好更大的样本，但样本大小会影响发送者的实验选择。结果对不完美信息反馈和学习规则选择具有鲁棒性。

Abstract: A sender persuades a strategically naive decisionmaker (DM) by committing
privately to an experiment. Sender's choice of experiment is unknown to the DM,
who must form her posterior beliefs nonparametrically by applying some learning
rule to an IID sample of (state, message) realizations.
  We show that, given mild regularity conditions, the empirical payoff
functions hypo-converge to the full-information counterpart. This is sufficient
to ensure that payoffs and optimal signals converge to the Bayesian benchmark.
  For finite sample sizes, the force of this "sampling friction" is
nonmonotonic: it can induce more informative experiments than the Bayesian
benchmark in settings like the classic Prosecutor-Judge game, and less
revelation even in situations with perfectly aligned preferences. For many
problems with state-independent preferences, we show that there is an optimal
finite sample size for the DM. Although the DM would always prefer a larger
sample for a fixed experiment, this result holds because the sample size
affects sender's choice of experiment.
  Our results are robust to imperfectly informative feedback and the choice of
learning rule.

</details>


### [3] [New methods to compensate artists in music streaming platforms](https://arxiv.org/abs/2510.25275)
*Gustavo Bergantiños,Juan D. Moreno-Ternero*

Main category: econ.TH

TL;DR: 该论文研究音乐流媒体平台中艺术家受欢迎度测量及相应报酬分配方法，通过公理化方法探索受欢迎度指标空间，并与合作博弈论中的Shapley值建立联系。


<details>
  <summary>Details</summary>
Motivation: 解决音乐行业对更公平艺术家报酬分配方法的日益关注，探索新的版税模型。

Method: 采用公理化方法，通过探索具有规范吸引力的原则所蕴含的若干公理来研究受欢迎度指标空间。

Result: 刻画了几个指标族，其中一些与Shapley值密切相关，这些特征化有助于为艺术家提供更适当的奖励方法。

Conclusion: 将所提出的指标族与Spotify和Deezer最近推出的新版税模型联系起来，为音乐流媒体平台的报酬分配提供了理论基础。

Abstract: We study the problem of measuring the popularity of artists in music
streaming platforms and the ensuing methods to compensate them (from the
revenues platforms raise by charging users). We uncover the space of popularity
indices upon exploring the implications of several axioms capturing principles
with normative appeal. As a result, we characterize several families of
indices. Some of them are intimately connected to the Shapley value, the
central tool in cooperative game theory. Our characterizations might help to
address the rising concern in the music industry to explore new methods that
reward artists more appropriately. We actually connect our families to the new
royalties models, recently launched by Spotify and Deezer.

</details>


### [4] [Walrasian equilibria are almost always finite in number](https://arxiv.org/abs/2510.25738)
*Sofia B. S. D. Castro,Peter B. Gothen*

Main category: econ.TH

TL;DR: 该论文证明了在由全开放价格单纯形上的总超额需求函数定义的交换经济中，一般经济具有有限数量的均衡。


<details>
  <summary>Details</summary>
Motivation: 研究交换经济中均衡数量的普遍性质，特别是在全开放价格单纯形上的总超额需求函数背景下。

Method: 使用奇点理论中的有限奇点类型概念，证明具有有限奇点类型的映射构成所有光滑映射的开放稠密子集，并将结果转化为交换经济的总超额需求函数集。

Result: 证明了在惠特尼拓扑下，一般经济（包括临界经济）具有有限数量的均衡，且这一性质在开放稠密子集中成立。

Conclusion: 扩展了Sonnenschein-Mantel-Debreu的经典结果，证明了在全开放价格单纯形（而不仅仅是单纯形的紧子集）上定义的总超额需求函数的均衡有限性。

Abstract: We show that in the context of exchange economies defined by aggregate excess
demand functions on the full open price simplex, the generic economy has a
finite number of equilibria. Genericicity is proved also for critical economies
and, in both cases, in the strong sense that it holds for an open dense subset
of economies in the Whitney topology. We use the concept of finite singularity
type from singularity theory. This concept ensures that the number of
equilibria of a map appear only in finite number. We then show that maps of
finite singularity type make up an open and dense subset of all smooth maps and
translate the result to the set of aggregate excess demand functions of an
exchange economy.
  Along the way, we extend the classical results of Sonnenschein-Mantel-Debreu
to aggregate excess demand functions defined on the full open price simplex,
rather than just compact subsets of the simplex.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [5] [Estimating Nationwide High-Dosage Tutoring Expenditures: A Predictive Model Approach](https://arxiv.org/abs/2510.24899)
*Jason Godfrey,Trisha Banerjee*

Main category: econ.GN

TL;DR: 使用优化的XGBoost回归模型从不完整的行政数据中估计学区级高剂量辅导支出，预测总支出约22亿美元


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行导致K-12学生出现前所未有的学习损失，联邦政府拨款1900亿美元用于救济，但缺乏各支出类别的具体金额信息

Method: 使用自定义爬取的7000多份ESSER计划数据集，基于学区特征（入学人数、总资金、城市化程度、学校数量）建立XGBoost回归模型

Result: 模型样本外R²=0.358，具有中等预测准确性，估计辅导支出总额约22亿美元

Conclusion: 梯度提升决策树可在结构化数据稀疏时重建大规模财政模式，该方法可推广到其他依赖从半结构化文本和稀疏行政来源恢复潜在变量的政策评估领域

Abstract: This study applies an optimized XGBoost regression model to estimate
district-level expenditures on high-dosage tutoring from incomplete
administrative data. The COVID-19 pandemic caused unprecedented learning loss,
with K-12 students losing up to half a grade level in certain subjects. To
address this, the federal government allocated \$190 billion in relief. We know
from previous research that small-group tutoring, summer and after school
programs, and increased support staff were all common expenditures for
districts. We don't know how much was spent in each category. Using a custom
scraped dataset of over 7,000 ESSER (Elementary and Secondary School Emergency
Relief) plans, we model tutoring allocations as a function of district
characteristics such as enrollment, total ESSER funding, urbanicity, and school
count. Extending the trained model to districts that mention tutoring but omit
cost information yields an estimated aggregate allocation of approximately
\$2.2 billion. The model achieved an out-of-sample $R^2$=0.358, demonstrating
moderate predictive accuracy given substantial reporting heterogeneity.
Methodologically, this work illustrates how gradient-boosted decision trees can
reconstruct large-scale fiscal patterns where structured data are sparse or
missing. The framework generalizes to other domains where policy evaluation
depends on recovering latent financial or behavioral variables from
semi-structured text and sparse administrative sources.

</details>


### [6] [Productivity Beliefs and Efficiency in Science](https://arxiv.org/abs/2510.24916)
*Fabio Bertolotti,Kyle Myers,Wei Yang Tham*

Main category: econ.GN

TL;DR: 开发了一种在产出数量和投入价格不可观测时估计生产者生产力信念的方法，并将其应用于科学市场评估。通过研究人员劳动供给模型，揭示了他们对投入的支付意愿如何反映其生产力信念。


<details>
  <summary>Details</summary>
Motivation: 在产出数量和投入价格不可观测的情况下，需要开发新方法来估计生产者的生产力信念，特别是针对科学研究市场进行有效评估。

Method: 构建研究人员劳动供给模型，通过他们对投入的支付意愿来揭示生产力信念。使用全国代表性研究人员调查数据进行参数估计。

Result: 发现生产力分布非常偏斜。反事实分析表明，当前预算的更有效分配可能价值数十亿美元。

Conclusion: 开发识别有才华科学家的新方法具有巨大价值，能够带来显著收益。

Abstract: We develop a method to estimate producers' productivity beliefs when output
quantities and input prices are unobservable, and we use it to evaluate the
market for science. Our model of researchers' labor supply shows how their
willingness to pay for inputs reveals their productivity beliefs. We estimate
the model's parameters using data from a nationally representative survey of
researchers and find the distribution of productivity to be very skewed. Our
counterfactuals indicate that a more efficient allocation of the current budget
could be worth billions of dollars. There are substantial gains from developing
new ways of identifying talented scientists.

</details>


### [7] [Automation Experiments and Inequality](https://arxiv.org/abs/2510.24923)
*Seth Benzell,Kyle Myers*

Main category: econ.GN

TL;DR: 本文分析了自动化技术对劳动力生产率的影响，特别关注不平等效应。研究发现不平等效应取决于任务技能相关性和工人技能相对于技术能力的交互作用，且往往呈现非单调性变化。


<details>
  <summary>Details</summary>
Motivation: 研究自动化技术对劳动力生产率的影响，特别是探讨技术是否会加剧或减轻不平等问题，以及如何预测技术持续改进时的分配效应。

Method: 构建理论模型，形式化实证测试的理论内容。工人产出取决于任务级生产函数，工人具有异质性的任务级技能。工人可以选择自己执行任务或将任务委托给自动化技术。

Result: 研究发现自动化改进的不平等效应取决于两个因素的交互：(i)任务级技能在工人间的相关性；(ii)工人技能相对于技术能力。不平等效应的符号通常是非单调的，随着技术改进，不平等可能先减少后增加，或反之。

Conclusion: 自动化技术的多样性将在不平等的演变中发挥重要作用。通过数据和理论分析，识别了技能可能正相关或负相关的案例情况。

Abstract: An increasingly large number of experiments study the labor productivity
effects of automation technologies such as generative algorithms. A popular
question in these experiments relates to inequality: does the technology
increase output more for high- or low-skill workers? The answer is often used
to anticipate the distributional effects of the technology as it continues to
improve. In this paper, we formalize the theoretical content of this empirical
test, focusing on automation experiments as commonly designed. Worker-level
output depends on a task-level production function, and workers are
heterogeneous in their task-level skills. Workers perform a task themselves, or
they delegate it to the automation technology. The inequality effect of
improved automation depends on the interaction of two factors: ($i$) the
correlation in task-level skills across workers, and ($ii$) workers' skills
relative to the technology's capability. Importantly, the sign of the
inequality effect is often non-monotonic -- as technologies improve, inequality
may decrease then increase, or vice versa. Finally, we use data and theory to
highlight cases when skills are likely to be positively or negatively
correlated. The model generally suggests that the diversity of automation
technologies will play an important role in the evolution of inequality.

</details>


### [8] [The Latin Monetary Union and Trade: A Closer Look](https://arxiv.org/abs/2510.25487)
*Jacopo Timini*

Main category: econ.GN

TL;DR: 本文重新评估了19世纪拉丁货币联盟对贸易的影响，发现该联盟在1870年代初期前对成员国间贸易有积极影响，之后效果逐渐消失。


<details>
  <summary>Details</summary>
Motivation: 重新审视拉丁货币联盟对贸易的影响，采用更先进的重力模型方法，并更严谨地定义控制组以考虑早期不同货币制度的多样性。

Method: 使用最新的重力模型进展，采用更严格的控制组定义方法，考虑早期不同货币制度的多样性，并进行多种稳健性检验。

Result: 拉丁货币联盟在1870年代初期前对成员国贸易有积极影响，此后效果逐渐消失并趋近于零。结果对各种潜在混杂因素、不同样本和方法选择都具有稳健性。

Conclusion: 拉丁货币联盟在双金属制仍被视为可行货币体系的时期对贸易有促进作用，但随着时间推移这种影响逐渐消失。

Abstract: This paper reexamines the effects of the Latin Monetary Union (LMU) - a 19th
century agreement among several European countries to standardize their
currencies through a bimetallic system based on fixed gold and silver content -
on trade. Unlike previous studies, this paper adopts the latest advances in
gravity modeling and a more rigorous approach to defining the control group by
accounting for the diversity of currency regimes during the early years of the
LMU. My findings suggest that the LMU had a positive effect on trade between
its members until the early 1870s, when bimetallism was still considered a
viable monetary system. These effects then faded, converging to zero. Results
are robust to the inclusion of additional potential confounders, the use of
various samples spanning different countries and trade data sources, and
alternative methodological choices.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Scheduling Your LLM Reinforcement Learning with Reasoning Trees](https://arxiv.org/abs/2510.24832)
*Hong Wang,Zhezheng Hao,Jian Luo,Chenxing Wei,Yao Shu,Lei Liu,Qiang Lin,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: 提出了基于推理树结构的新指标r-score和调度算法Re-Schedule，在六个数学推理基准测试中显著提升准确率


<details>
  <summary>Details</summary>
Motivation: 现有RLVR数据调度方法依赖基于路径的指标来排序查询，忽略了查询的推理树结构

Method: 引入推理分数(r-score)衡量查询的学习难度，基于r-score提出推理树调度算法(Re-Schedule)，构建从结构简单到复杂的课程

Result: 在六个数学推理基准测试中，Re-Schedule显著提高平均准确率，最高提升3.2%

Conclusion: 对推理树的结构理解为RLVR数据调度提供了更强大和原则性的基础

Abstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large
Language Models (LLMs) can be conceptualized as progressively editing a query's
`Reasoning Tree'. This process involves exploring nodes (tokens) and
dynamically modifying the model's policy at each node. When combined with data
scheduling, this process yields further gains in data efficiency and accuracy.
However, existing RLVR data scheduling methods typically rely on path-based
metrics to rank queries, overlooking the reasoning tree structures of these
queries. In this paper, we introduce a novel metric, namely Reasoning Score
(r-score), which measures the query's learning difficulty based on the
structure of its reasoning tree. Based on the r-score, we propose the Reasoning
Tree Schedule (Re-Schedule), a scheduling algorithm that constructs a
curriculum progressing from structurally simple (high r-score) to complex (low
r-score) queries. Experiments on six math-reasoning benchmarks show that
Re-Schedule significantly improves average accuracy, achieving gains of up to
3.2%. These strong results validate our approach and demonstrate that a
structural understanding of the reasoning tree provides a more powerful and
principled foundation for RLVR data scheduling.

</details>


### [10] [Cyclic Counterfactuals under Shift-Scale Interventions](https://arxiv.org/abs/2510.25005)
*Saptarshi Saha,Dhruv Vansraj Rathore,Utpal Garain*

Main category: cs.AI

TL;DR: 研究循环结构因果模型中的反事实推理，关注移位-缩放干预下的推理方法


<details>
  <summary>Details</summary>
Motivation: 传统反事实推理框架假设无环结构因果模型，但现实系统（如生物系统）常包含反馈循环或循环依赖，违反无环性假设

Method: 研究循环结构因果模型在移位-缩放干预下的反事实推理，这种干预是软性、策略式的变化，重新缩放和/或移动变量的机制

Result: 未在摘要中明确说明

Conclusion: 未在摘要中明确说明

Abstract: Most counterfactual inference frameworks traditionally assume acyclic
structural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,
many real-world systems (e.g. biological systems) contain feedback loops or
cyclic dependencies that violate acyclicity. In this work, we study
counterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,
soft, policy-style changes that rescale and/or shift a variable's mechanism.

</details>


### [11] [Taming the Real-world Complexities in CPT E/M Coding with Large Language Models](https://arxiv.org/abs/2510.25007)
*Islam Nassar,Yang Lin,Yuan Jin,Rongxin Zhu,Chang Wei Tan,Zenan Zhai,Nitika Mathur,Thanh Tien Vu,Xu Zhong,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: 本文提出了ProFees框架，这是一个基于LLM的系统，用于自动化医疗评估与管理(E/M)编码任务，在真实数据集上比商业系统提高了36%以上的编码准确率。


<details>
  <summary>Details</summary>
Motivation: E/M编码是医生的重要辅助任务，增加了文档负担。自动化该任务可以减轻医生负担、提高计费效率，从而改善患者护理质量。

Method: 提出了ProFees框架，这是一个基于大型语言模型(LLM)的系统，专门设计用于解决E/M编码中的现实世界复杂性。

Result: 在专家策划的真实世界数据集上，ProFees比商业CPT E/M编码系统提高了36%以上的编码准确率，比最强的单提示基线提高了近5%。

Conclusion: ProFees框架有效解决了E/M编码自动化中的现实世界复杂性，证明了其在医疗计费自动化方面的有效性。

Abstract: Evaluation and Management (E/M) coding, under the Current Procedural
Terminology (CPT) taxonomy, documents medical services provided to patients by
physicians. Used primarily for billing purposes, it is in physicians' best
interest to provide accurate CPT E/M codes. %While important, it is an
auxiliary task that adds to physicians' documentation burden. Automating this
coding task will help alleviate physicians' documentation burden, improve
billing efficiency, and ultimately enable better patient care. However, a
number of real-world complexities have made E/M encoding automation a
challenging task. In this paper, we elaborate some of the key complexities and
present ProFees, our LLM-based framework that tackles them, followed by a
systematic evaluation. On an expert-curated real-world dataset, ProFees
achieves an increase in coding accuracy of more than 36\% over a commercial CPT
E/M coding system and almost 5\% over our strongest single-prompt baseline,
demonstrating its effectiveness in addressing the real-world complexities.

</details>


### [12] [Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading](https://arxiv.org/abs/2510.25014)
*Minkyung Kim,Junsik Kim,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 提出了Autoregressive State-Tracking Prompting (ASTP)方法，通过显式状态跟踪和占位符后处理，解决LLM在游戏交易系统中无法遵循规则流程的问题，实现了99%的状态合规性和99.3%的计算精度。


<details>
  <summary>Details</summary>
Motivation: LLM在游戏交易系统中缺乏对规则流程（浏览-报价-审核-确认）的遵循能力，这会损害玩家信任，因此需要平衡LLM的创造灵活性与交易系统的程序性要求。

Method: ASTP方法通过精心设计的提示词强制LLM显式报告预定义状态标签，并结合状态特定的占位符后处理方法确保交易完整性。

Result: 在300个交易对话评估中，实现了超过99%的状态合规性和99.3%的计算精度。小模型(Gemini-2.5-Flash)使用ASTP后性能与更大模型相当，响应时间从21.2秒降至2.4秒。

Conclusion: ASTP为商业游戏提供了满足实时需求和资源限制的实用解决方案，平衡了LLM的灵活性与交易系统的程序性要求。

Abstract: Large Language Models (LLMs) enable dynamic game interactions but fail to
follow essential procedural flows in rule-governed trading systems, eroding
player trust. This work resolves the core tension between the creative
flexibility of LLMs and the procedural demands of in-game trading
(browse-offer-review-confirm). To this end, Autoregressive State-Tracking
Prompting (ASTP) is introduced, a methodology centered on a strategically
orchestrated prompt that compels an LLM to make its state-tracking process
explicit and verifiable. Instead of relying on implicit contextual
understanding, ASTP tasks the LLM with identifying and reporting a predefined
state label from the previous turn. To ensure transactional integrity, this is
complemented by a state-specific placeholder post-processing method for
accurate price calculations. Evaluation across 300 trading dialogues
demonstrates >99% state compliance and 99.3% calculation precision. Notably,
ASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)
matches larger models' (Gemini-2.5-Pro) performance while reducing response
time from 21.2s to 2.4s, establishing a practical foundation that satisfies
both real-time requirements and resource constraints of commercial games.

</details>


### [13] [Reasoning-Aware GRPO using Process Mining](https://arxiv.org/abs/2510.25065)
*Taekhyun Park,Yongjae Lee,Hyerim Bae*

Main category: cs.AI

TL;DR: PM4GRPO是一种基于过程挖掘的推理感知组相对策略优化方法，通过增强标准答案/格式奖励，利用过程挖掘技术计算一致性奖励来衡量策略模型推理与预训练教师模型的对齐程度。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的后训练奖励方案通常是结果导向的，缺乏对推理过程的关注，这限制了大型推理模型的多步推理能力。

Method: 提出PM4GRPO方法，在标准答案/格式奖励基础上增加推理过程信号，使用过程挖掘技术计算标量一致性奖励，衡量策略模型推理与预训练教师模型的对齐程度。

Result: 在五个基准测试上的实证结果表明，PM4GRPO显著优于现有的基于GRPO的后训练方法。

Conclusion: 利用过程挖掘进行推理感知的GRPO能有效增强策略模型的推理能力。

Abstract: Reinforcement learning (RL)-based post-training has been crucial for enabling
multi-step reasoning in large reasoning models (LRMs), yet current reward
schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware
Group Relative Policy Optimization (GRPO) that augments standard answer/format
rewards with signals over the reasoning procedure. To this end, process mining
techniques are utilized to compute a scalar conformance reward that measures
how closely a policy model's reasoning aligns with the pretrained teacher
model. The empirical results on five benchmarks demonstrate that PM4GRPO
significantly outperforms existing methodologies for GRPO-based post-training.
These results highlight that leveraging process mining for reasoning-aware GRPO
effectively enhances the reasoning capabilities of policy models.

</details>


### [14] [H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts](https://arxiv.org/abs/2510.25091)
*Peilin Tan,Liang Xie,Churan Zhi,Dian Tu,Chuanqi Shi*

Main category: cs.AI

TL;DR: H3M-SSMoEs是一个基于超图的多模态股票预测架构，结合LLM推理和风格结构专家混合，通过多模态超图、LLM增强推理和风格专家混合三个创新点，在多个股票市场实现了优越的预测精度和投资表现。


<details>
  <summary>Details</summary>
Motivation: 股票预测面临复杂的时间依赖、异构模态和动态股票关系的挑战，现有方法难以在可扩展框架内统一结构、语义和制度自适应建模。

Method: 1) 多上下文多模态超图：通过局部和全局上下文超图分层捕获时空动态和股票间依赖关系；2) LLM增强推理模块：利用冻结大语言模型进行语义融合；3) 风格结构专家混合：结合共享市场专家和行业专业专家。

Result: 在三个主要股票市场的广泛实验表明，H3M-SSMoEs在预测精度和投资表现上均超越最先进方法，同时展现有效的风险控制。

Conclusion: H3M-SSMoEs通过创新的多模态超图架构、LLM推理和风格专家混合，成功解决了股票预测中的复杂挑战，实现了优越的性能表现。

Abstract: Stock movement prediction remains fundamentally challenging due to complex
temporal dependencies, heterogeneous modalities, and dynamically evolving
inter-stock relationships. Existing approaches often fail to unify structural,
semantic, and regime-adaptive modeling within a scalable framework. This work
introduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with
LLM reasoning and Style-Structured Mixture of Experts, integrating three key
innovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically
captures fine-grained spatiotemporal dynamics via a Local Context Hypergraph
(LCH) and persistent inter-stock dependencies through a Global Context
Hypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon
Divergence weighting mechanism for adaptive relational learning and cross-modal
alignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large
language model with lightweight adapters to semantically fuse and align
quantitative and textual modalities, enriching representations with
domain-specific financial knowledge; and (3) a Style-Structured Mixture of
Experts (SSMoEs) that combines shared market experts and industry-specialized
experts, each parameterized by learnable style vectors enabling regime-aware
specialization under sparse activation. Extensive experiments on three major
stock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in
both superior predictive accuracy and investment performance, while exhibiting
effective risk control. Datasets, source code, and model weights are available
at our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs.

</details>


### [15] [KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA](https://arxiv.org/abs/2510.25101)
*Zhuo Chen,Fei Wang,Zixuan Li,Zhao Zhang,Weiwei Ding,Chuanguang Yang,Yongjun Xu,Xiaolong Jin,Jiafeng Guo*

Main category: cs.AI

TL;DR: KnowCoder-A1是一个通过多阶段课程强化学习训练的LLM，能够在知识库上进行自主推理问答，仅使用结果监督就显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有KBQA方法通常通过过程监督微调LLMs，但这种方法探索激励不足，无法有效增强代理推理能力。

Method: 采用多阶段课程强化学习：首先在高质量轨迹上微调LLM建立基础能力，然后通过从易到难的奖励调度应用课程RL，缓解结果监督中的奖励稀疏问题。

Result: 在三个主流数据集上持续优于先前方法，在GrailQA的零样本子集上实现了11.1%的相对改进，仅使用十二分之一的训练数据。

Conclusion: 仅使用结果监督训练的KnowCoder-A1展现出强大的推理行为，证明了其在知识库问答中的高效代理推理能力。

Abstract: Knowledge Base Question Answering (KBQA) aims to answer natural-language
questions over a structured Knowledge Base (KB). Recent work improves KBQA by
adopting an agentic reasoning paradigm, in which Large Language Models (LLMs)
iteratively decompose a question, generate its corresponding logical queries,
and interact with the KB to derive the answer. However, these methods typically
fine-tune LLMs on reasoning trajectories synthesized via process supervision,
which offers weak incentives for exploration and thus fails to strengthen the
agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that
can autonomously perform agentic reasoning on KBs to obtain answers. To
incentivize autonomous exploration, KnowCoder-A1 trains the LLM under
outcome-only supervision via a multi-stage curriculum reinforcement learning
with an easy-to-hard curriculum. To establish foundational agentic
capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of
high-quality trajectories obtained through outcome-based rejection sampling.
Then, to alleviate the reward sparsity inherent in outcome-only supervision, it
applies multi-stage curriculum RL with reward schedules that progress from easy
to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful
reasoning behaviors and consistently outperforms prior approaches across three
mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1
achieves up to an 11.1% relative improvement while using only one-twelfth of
the training data, demonstrating strong agentic reasoning capabilities.

</details>


### [16] [Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models](https://arxiv.org/abs/2510.25179)
*Juan Ren,Mark Dras,Usman Naseem*

Main category: cs.AI

TL;DR: Agentic Moderation是一个模型无关框架，利用专门代理防御多模态系统免受越狱攻击，通过动态协作代理实现上下文感知和可解释的审核。


<details>
  <summary>Details</summary>
Motivation: 扩展智能体方法到安全对齐领域，解决现有静态方法只能提供二元分类的局限性，实现更灵活、可解释的安全治理。

Method: 采用动态协作代理架构，包括Shield、Responder、Evaluator和Reflector等专门代理，实现上下文感知的审核。

Result: 在5个数据集和4个大型视觉语言模型上的实验显示，攻击成功率降低7-19%，拒绝率提高4-20%，保持稳定的不遵循率。

Conclusion: Agentic Moderation展示了智能体系统作为自动化安全治理基础的潜力，提供模块化、可扩展和细粒度的安全执行。

Abstract: Agentic methods have emerged as a powerful and autonomous paradigm that
enhances reasoning, collaboration, and adaptive control, enabling systems to
coordinate and independently solve complex tasks. We extend this paradigm to
safety alignment by introducing Agentic Moderation, a model-agnostic framework
that leverages specialised agents to defend multimodal systems against
jailbreak attacks. Unlike prior approaches that apply as a static layer over
inputs or outputs and provide only binary classifications (safe or unsafe), our
method integrates dynamic, cooperative agents, including Shield, Responder,
Evaluator, and Reflector, to achieve context-aware and interpretable
moderation. Extensive experiments across five datasets and four representative
Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the
Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),
and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,
and well-balanced safety performance. By harnessing the flexibility and
reasoning capacity of agentic architectures, Agentic Moderation provides
modular, scalable, and fine-grained safety enforcement, highlighting the
broader potential of agentic systems as a foundation for automated safety
governance.

</details>


### [17] [Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision](https://arxiv.org/abs/2510.25205)
*Yuyang Xia,Zibo Liang,Liwei Deng,Yan Zhao,Han Su,Kai Zheng*

Main category: cs.AI

TL;DR: EneAD是一个节能的自动驾驶框架，通过自适应感知模块和鲁棒决策模块，在保持感知精度的同时显著降低计算能耗，提升电动车的续航里程。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术虽然带来诸多好处，但其计算引擎的高能耗限制了电动车的续航里程。感知计算作为最耗电的部分，现有压缩技术往往导致模型尺寸过大或精度显著下降。

Method: 1. 自适应感知模块：管理多个不同计算消耗的感知模型，动态调整执行帧率；使用贝叶斯优化进行可转移调优；2. 轻量级分类模型区分不同场景的感知难度；3. 鲁棒决策模块：基于强化学习的决策模型，设计正则化项增强驾驶稳定性。

Result: EneAD能将感知能耗降低1.9倍到3.5倍，从而将驾驶里程提升3.9%到8.5%。

Conclusion: 该框架在能耗和驾驶性能方面均表现出优越性，为解决自动驾驶能耗问题提供了有效方案。

Abstract: Autonomous driving is an emerging technology that is expected to bring
significant social, economic, and environmental benefits. However, these
benefits come with rising energy consumption by computation engines, limiting
the driving range of vehicles, especially electric ones. Perception computing
is typically the most power-intensive component, as it relies on largescale
deep learning models to extract environmental features. Recently, numerous
studies have employed model compression techniques, such as sparsification,
quantization, and distillation, to reduce computational consumption. However,
these methods often result in either a substantial model size or a significant
drop in perception accuracy compared to high-computation models. To address
these challenges, we propose an energy-efficient autonomous driving framework,
called EneAD. In the adaptive perception module, a perception optimization
strategy is designed from the perspective of data management and tuning.
Firstly, we manage multiple perception models with different computational
consumption and adjust the execution framerate dynamically. Then, we define
them as knobs and design a transferable tuning method based on Bayesian
optimization to identify promising knob values that achieve low computation
while maintaining desired accuracy. To adaptively switch the knob values in
various traffic scenarios, a lightweight classification model is proposed to
distinguish the perception difficulty in different scenarios. In the robust
decision module, we propose a decision model based on reinforcement learning
and design a regularization term to enhance driving stability in the face of
perturbed perception results. Extensive experiments evidence the superiority of
our framework in both energy consumption and driving performance. EneAD can
reduce perception consumption by 1.9x to 3.5x and thus improve driving range by
3.9% to 8.5%

</details>


### [18] [RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models](https://arxiv.org/abs/2510.25206)
*Tianqianjin Lin,Xi Zhao,Xingyao Zhang,Rujiao Long,Yi Xu,Zhuoren Jiang,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: 本文提出RAVR框架，通过利用答案来引导LLM生成高质量推理路径，解决了在LLM当前能力范围之外的任务中，RL难以采样有效推理路径的问题。


<details>
  <summary>Details</summary>
Motivation: 受认知科学启发，发现"为什么这是答案"比"答案是什么"更容易回答，因为前者避免了开放式探索的认知负担，转而进行解释性重构。当LLM无法直接生成高质量推理时，可以利用答案来推导推理路径。

Method: 提出RAVR框架，使用答案条件推理作为仅问题推理的变分替代。通过形式化证明，条件化答案能够提高采样推理路径的期望效用，将难以处理的问题转化为可学习的问题。

Result: 在通用和数学领域的实验中，RAVR相比强基线方法表现出持续改进。分析发现RAVR减少了犹豫，加强了结论整合，并促进了问题特定的推理策略。

Conclusion: 答案引导的推理能够有效提升LLM在复杂任务中的推理能力，特别是在LLM当前能力范围之外的任务中，RAVR框架提供了一种可行的学习路径。

Abstract: Reinforcement learning (RL) can refine the reasoning abilities of large
language models (LLMs), but critically depends on a key prerequisite: the LLM
can already generate high-utility reasoning paths with non-negligible
probability. For tasks beyond the LLM's current competence, such reasoning path
can be hard to sample, and learning risks reinforcing familiar but suboptimal
reasoning. We are motivated by the insight from cognitive science that Why is
this the answer is often an easier question than What is the answer, as it
avoids the heavy cognitive load of open-ended exploration, opting instead for
explanatory reconstruction-systematically retracing the reasoning that links a
question to its answer. We show that LLMs can similarly leverage answers to
derive high-quality reasoning paths. We formalize this phenomenon and prove
that conditioning on answer provably increases the expected utility of sampled
reasoning paths, thereby transforming intractable problems into learnable ones.
Building on this insight, we introduce RAVR (Reference-Answer-guided
Variational Reasoning), an end-to-end framework that uses answer-conditioned
reasoning as a variational surrogate for question-only reasoning. Experiments
in both general and math domains demonstrate consistent improvements over
strong baselines. We further analyze the reasoning behavior and find that RAVR
reduces hesitation, strengthens conclusion consolidation, and promotes
problem-specific strategies in reasoning.

</details>


### [19] [FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data](https://arxiv.org/abs/2510.25223)
*Kun ouyang,Haoyu Wang,Dong Fang*

Main category: cs.AI

TL;DR: FELA是一个基于LLM的多代理进化系统，用于从复杂的工业事件日志数据中自动提取高性能特征，解决了现有自动特征工程方法在可解释性、操作灵活性和异构数据适应性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 工业事件日志数据具有大规模、高维度、异构性和复杂结构的特点，使得特征工程极具挑战性。现有的自动特征工程方法存在可解释性差、操作固定、对复杂异构数据适应性差等问题。

Method: FELA采用多代理进化系统，包含创意代理、代码代理、批评代理和评估代理，结合LLM的推理和编码能力与洞察引导的自进化范式，使用强化学习和遗传算法原理平衡探索与利用。

Result: 在真实工业数据集上的实验表明，FELA能够生成可解释、领域相关的特征，显著提升模型性能并减少人工工作量。

Conclusion: 基于LLM的多代理系统有潜力成为复杂现实环境中自动化、可解释和自适应特征工程的通用框架。

Abstract: Event log data, recording fine-grained user actions and system events,
represent one of the most valuable assets for modern digital services. However,
the complexity and heterogeneity of industrial event logs--characterized by
large scale, high dimensionality, diverse data types, and intricate temporal or
relational structures--make feature engineering extremely challenging. Existing
automatic feature engineering approaches, such as AutoML or genetic methods,
often suffer from limited explainability, rigid predefined operations, and poor
adaptability to complicated heterogeneous data. In this paper, we propose FELA
(Feature Engineering LLM Agents), a multi-agent evolutionary system that
autonomously extracts meaningful and high-performing features from complex
industrial event log data. FELA integrates the reasoning and coding
capabilities of large language models (LLMs) with an insight-guided
self-evolution paradigm. Specifically, FELA employs specialized agents--Idea
Agents, Code Agents, and Critic Agents--to collaboratively generate, validate,
and implement novel feature ideas. An Evaluation Agent summarizes feedback and
updates a hierarchical knowledge base and dual-memory system to enable
continual improvement. Moreover, FELA introduces an agentic evolution
algorithm, combining reinforcement learning and genetic algorithm principles to
balance exploration and exploitation across the idea space. Extensive
experiments on real industrial datasets demonstrate that FELA can generate
explainable, domain-relevant features that significantly improve model
performance while reducing manual effort. Our results highlight the potential
of LLM-based multi-agent systems as a general framework for automated,
interpretable, and adaptive feature engineering in complex real-world
environments.

</details>


### [20] [From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity](https://arxiv.org/abs/2510.25232)
*Tianxi Wan,Jiaming Luo,Siyuan Chen,Kunyao Lan,Jianhua Chen,Haiyang Geng,Mengyue Wu*

Main category: cs.AI

TL;DR: 开发了PsyCoTalk，首个支持共病诊断的大规模对话数据集，包含3000个多轮诊断对话，通过合成EMR和多智能体框架构建，经精神科医生验证具有高真实性和诊断有效性。


<details>
  <summary>Details</summary>
Motivation: 精神疾病共病在临床上具有重要意义但诊断复杂，现有方法难以处理多种共病情况，需要开发支持共病诊断的大规模对话数据集。

Method: 整合合成患者电子病历构建和多智能体诊断对话生成，创建502个合成EMR，将临床访谈协议转换为分层状态机和上下文树，支持130多个诊断状态。

Result: 构建了包含3000个多轮诊断对话的PsyCoTalk数据集，相比真实临床记录，在对话长度、标记分布和诊断推理策略方面具有高结构性和语言保真度。

Conclusion: PsyCoTalk数据集为精神疾病共病研究提供了宝贵资源，能够开发和评估在一次对话中完成多疾病精神筛查的模型。

Abstract: Psychiatric comorbidity is clinically significant yet challenging due to the
complexity of multiple co-occurring disorders. To address this, we develop a
novel approach integrating synthetic patient electronic medical record (EMR)
construction and multi-agent diagnostic dialogue generation. We create 502
synthetic EMRs for common comorbid conditions using a pipeline that ensures
clinical relevance and diversity. Our multi-agent framework transfers the
clinical interview protocol into a hierarchical state machine and context tree,
supporting over 130 diagnostic states while maintaining clinical standards.
Through this rigorous process, we construct PsyCoTalk, the first large-scale
dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic
dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy
and treatment planning, offering a valuable resource for psychiatric
comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk
exhibits high structural and linguistic fidelity in terms of dialogue length,
token distribution, and diagnostic reasoning strategies. Licensed psychiatrists
confirm the realism and diagnostic validity of the dialogues. This dataset
enables the development and evaluation of models capable of multi-disorder
psychiatric screening in a single conversational pass.

</details>


### [21] [GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning](https://arxiv.org/abs/2510.25320)
*Jiaqi Wu,Qinlao Zhao,Zefeng Chen,Kai Qin,Yifei Zhao,Xueqian Wang,Yuhang Yao*

Main category: cs.AI

TL;DR: 提出了GAP框架，通过图基规划建模任务依赖关系，实现自适应并行和串行工具执行，显著提升多步推理任务的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自主代理（如ReAct）采用顺序推理执行，无法利用独立子任务的并行性，导致工具利用效率低下和多步推理性能不佳。

Method: 训练代理基础模型将复杂任务分解为依赖感知的子任务图，自主确定可并行执行和必须顺序执行的工具。采用两阶段训练策略：在高质量图规划数据集上监督微调，然后在策略采样查询上进行基于正确性的强化学习。

Result: 在MHQA数据集上的实验表明，GAP显著优于传统ReAct基线，特别是在多步检索任务上，同时通过智能并行化大幅提升工具调用效率。

Conclusion: GAP框架通过依赖感知的编排机制，有效解决了顺序推理瓶颈，为复杂任务解决提供了更高效的并行工具执行方案。

Abstract: Autonomous agents powered by large language models (LLMs) have shown
impressive capabilities in tool manipulation for complex task-solving. However,
existing paradigms such as ReAct rely on sequential reasoning and execution,
failing to exploit the inherent parallelism among independent sub-tasks. This
sequential bottleneck leads to inefficient tool utilization and suboptimal
performance in multi-step reasoning scenarios. We introduce Graph-based Agent
Planning (GAP), a novel framework that explicitly models inter-task
dependencies through graph-based planning to enable adaptive parallel and
serial tool execution. Our approach trains agent foundation models to decompose
complex tasks into dependency-aware sub-task graphs, autonomously determining
which tools can be executed in parallel and which must follow sequential
dependencies. This dependency-aware orchestration achieves substantial
improvements in both execution efficiency and task accuracy. To train GAP, we
construct a high-quality dataset of graph-based planning traces derived from
the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage
training strategy: supervised fine-tuning (SFT) on the curated dataset,
followed by reinforcement learning (RL) with a correctness-based reward
function on strategically sampled queries where tool-based reasoning provides
maximum value. Experimental results on MHQA datasets demonstrate that GAP
significantly outperforms traditional ReAct baselines, particularly on
multi-step retrieval tasks, while achieving dramatic improvements in tool
invocation efficiency through intelligent parallelization. The project page is
available at: https://github.com/WJQ7777/Graph-Agent-Planning.

</details>


### [22] [Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm](https://arxiv.org/abs/2510.25388)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 提出了KVDA-UCT算法，通过分析即时奖励推断价值差异，在MCTS中检测更多抽象，提高样本效率


<details>
  <summary>Details</summary>
Motivation: 现有OGA-UCT算法要求状态-动作对具有相同即时奖励，限制了可发现的抽象数量，影响样本效率

Method: 基于已知价值差异抽象框架，修改OGA-UCT为KVDA-UCT，通过分析即时奖励推断价值差异，分组价值可能不同的状态-动作对

Result: 在多种确定性环境和参数设置下，KVDA-UCT检测到的抽象数量显著多于OGA-UCT，性能表现更优

Conclusion: KVDA-UCT通过推断价值差异而非要求价值等价，有效提高了MCTS的样本效率，无需额外参数

Abstract: A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,
which can be improved by grouping state-action pairs and using their aggregate
statistics instead of single-node statistics. On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS
abstraction algorithm for deterministic environments that builds its
abstraction using the Abstractions of State-Action Pairs (ASAP) framework,
which aims to detect states and state-action pairs with the same value under
optimal play by analysing the search graph. ASAP, however, requires two
state-action pairs to have the same immediate reward, which is a rigid
condition that limits the number of abstractions that can be found and thereby
the sample efficiency. In this paper, we break with the paradigm of grouping
value-equivalent states or state-action pairs and instead group states and
state-action pairs with possibly different values as long as the difference
between their values can be inferred. We call this abstraction framework Known
Value Difference Abstractions (KVDA), which infers the value differences by
analysis of the immediate rewards and modifies OGA-UCT to use this framework
instead. The modification is called KVDA-UCT, which detects significantly more
abstractions than OGA-UCT, introduces no additional parameter, and outperforms
OGA-UCT on a variety of deterministic environments and parameter settings.

</details>


### [23] [Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions](https://arxiv.org/abs/2510.25445)
*Mohamad Abou Ali,Fadi Dornaika*

Main category: cs.AI

TL;DR: 本调查提出了一个双范式框架，将智能体AI系统分为符号/经典范式（基于算法规划和持久状态）和神经/生成范式（基于随机生成和提示驱动编排），通过系统文献综述揭示了两种范式在不同应用领域的选择策略和伦理挑战。


<details>
  <summary>Details</summary>
Motivation: 解决智能体AI快速发展导致的认知碎片化问题，澄清现代神经系统与过时符号模型之间的概念混淆，为理解和分类智能体系统提供清晰的理论框架。

Method: 采用PRISMA系统综述方法，分析了2018-2025年间的90项研究，从三个维度进行结构化分析：理论基础与架构原则、领域特定实现、伦理与治理挑战。

Result: 发现范式选择具有战略性：符号系统主导安全关键领域（如医疗），神经系统在适应性强的数据丰富环境（如金融）中占优；识别出符号系统治理模型不足和神经符号混合架构需求等关键研究空白。

Conclusion: 智能体AI的未来不在于单一范式的支配，而在于两种范式的有意整合，以创建既适应性强又可靠的系统，为未来研究、开发和政策提供了概念工具包。

Abstract: Agentic AI represents a transformative shift in artificial intelligence, but
its rapid advancement has led to a fragmented understanding, often conflating
modern neural systems with outdated symbolic models -- a practice known as
conceptual retrofitting. This survey cuts through this confusion by introducing
a novel dual-paradigm framework that categorizes agentic systems into two
distinct lineages: the Symbolic/Classical (relying on algorithmic planning and
persistent state) and the Neural/Generative (leveraging stochastic generation
and prompt-driven orchestration). Through a systematic PRISMA-based review of
90 studies (2018--2025), we provide a comprehensive analysis structured around
this framework across three dimensions: (1) the theoretical foundations and
architectural principles defining each paradigm; (2) domain-specific
implementations in healthcare, finance, and robotics, demonstrating how
application constraints dictate paradigm selection; and (3) paradigm-specific
ethical and governance challenges, revealing divergent risks and mitigation
strategies. Our analysis reveals that the choice of paradigm is strategic:
symbolic systems dominate safety-critical domains (e.g., healthcare), while
neural systems prevail in adaptive, data-rich environments (e.g., finance).
Furthermore, we identify critical research gaps, including a significant
deficit in governance models for symbolic systems and a pressing need for
hybrid neuro-symbolic architectures. The findings culminate in a strategic
roadmap arguing that the future of Agentic AI lies not in the dominance of one
paradigm, but in their intentional integration to create systems that are both
adaptable and reliable. This work provides the essential conceptual toolkit to
guide future research, development, and policy toward robust and trustworthy
hybrid intelligent systems.

</details>


### [24] [Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?](https://arxiv.org/abs/2510.25471)
*Willem Fourie*

Main category: cs.AI

TL;DR: 本文提出AI对齐研究的新视角：将工具性目标视为需要接受和管理的特征，而非需要限制的故障。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐理论将工具性目标视为风险来源，试图限制其症状，但这种方法可能不够有效。

Method: 借鉴亚里士多德本体论及其现代诠释，构建哲学论证，将高级AI系统视为具有形式与物质构成的产物。

Result: 论证表明工具性倾向是AI系统构成的内在结果，而非偶然故障。

Conclusion: 应将重点从消除工具性目标转向理解、管理并将其导向人类对齐的目标。

Abstract: In artificial intelligence (AI) alignment research, instrumental goals, also
called instrumental subgoals or instrumental convergent goals, are widely
associated with advanced AI systems. These goals, which include tendencies such
as power-seeking and self-preservation, become problematic when they conflict
with human aims. Conventional alignment theory treats instrumental goals as
sources of risk that become problematic through failure modes such as reward
hacking or goal misgeneralization, and attempts to limit the symptoms of
instrumental goals, notably resource acquisition and self-preservation. This
article proposes an alternative framing: that a philosophical argument can be
constructed according to which instrumental goals may be understood as features
to be accepted and managed rather than failures to be limited. Drawing on
Aristotle's ontology and its modern interpretations, an ontology of concrete,
goal-directed entities, it argues that advanced AI systems can be seen as
artifacts whose formal and material constitution gives rise to effects distinct
from their designers' intentions. In this view, the instrumental tendencies of
such systems correspond to per se outcomes of their constitution rather than
accidental malfunctions. The implication is that efforts should focus less on
eliminating instrumental goals and more on understanding, managing, and
directing them toward human-aligned ends.

</details>


### [25] [Multi-Objective Search: Algorithms, Applications, and Emerging Directions](https://arxiv.org/abs/2510.25504)
*Oren Salzman,Carlos Hernández Ulloa,Ariel Felner,Sven Koenig*

Main category: cs.AI

TL;DR: 多目标搜索（MOS）作为规划与决策问题的统一框架，用于平衡多个常冲突的标准。本文综述MOS发展，强调跨学科机会，并概述新兴前沿的开放挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统很少仅优化单一指标，近年来在机器人、交通和运筹学等AI应用中MOS重新受到关注，反映了多目标优化的实际需求。

Method: 本文采用综述方法，系统梳理多目标搜索领域的发展历程、当前研究现状和跨学科应用机会。

Result: 识别了多目标搜索在不同应用领域的实际价值，明确了该领域的新兴研究前沿和关键挑战。

Conclusion: 多目标搜索是一个重要且活跃的研究领域，具有广泛的跨学科应用潜力，但仍面临诸多开放挑战需要进一步探索。

Abstract: Multi-objective search (MOS) has emerged as a unifying framework for planning
and decision-making problems where multiple, often conflicting, criteria must
be balanced. While the problem has been studied for decades, recent years have
seen renewed interest in the topic across AI applications such as robotics,
transportation, and operations research, reflecting the reality that real-world
systems rarely optimize a single measure. This paper surveys developments in
MOS while highlighting cross-disciplinary opportunities, and outlines open
challenges that define the emerging frontier of MOS

</details>


### [26] [MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL](https://arxiv.org/abs/2510.25510)
*Zekun Xu,Siyu Xia,Chuhuai Yue,Jiajun Chai,Mingxue Tian,Xiaohan Wang,Wei Lin,Haoxuan Li,Guojun Yin*

Main category: cs.AI

TL;DR: 提出MTIR-SQL框架，通过多轮工具集成推理和动态执行反馈来提升Text-to-SQL性能，在BIRD和SPIDER数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖静态执行反馈，限制了实时错误纠正能力。集成多轮工具调用和动态反馈可以显著提高适应性和鲁棒性。

Method: 提出MTIR-SQL框架，采用执行感知的多轮推理范式，在每个推理步骤中无缝整合数据库执行反馈。扩展GRPO算法，添加轨迹过滤机制并移除KL损失约束。

Result: MTIR-SQL在BIRD Dev上达到64.4%准确率，在SPIDER Dev上达到84.6%执行准确率，显著优于现有方法。

Conclusion: 多轮工具集成推理结合动态执行反馈能有效提升Text-to-SQL任务的性能，所提方法在多个基准测试中表现出色。

Abstract: As large language models (LLMs) are increasingly used in Text-to-SQL tasks,
Reinforcement Learning (RL) has become a common method for improving
performance. Existing methods primarily rely on static execution feedback,
which restricts real-time error correction. However, integrating multi-turn
tool invocation along with dynamic feedback could significantly improve
adaptability and robustness, ultimately enhancing model performance. To address
these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated
Reasoning reinforcement learning framework for Text-to-SQL. Our approach
introduces an execution-aware multi-turn reasoning paradigm that seamlessly
incorporates database execution feedback at each reasoning step, enabling
context-sensitive query generation and progressive refinement throughout the
reasoning process. The framework extends the GRPO algorithm to accommodate
complex multi-turn interaction scenarios. Considering the training instability
characteristics of MTIR and the potential for significant Deviation of model
distribution from the initial model, we enhance the GRPO algorithm by adding a
trajectory filtering mechanism and removing KL loss constraints. Experimental
results demonstrate that MTIR-SQL, with 4B parameters, achieves \textbf{64.4}\%
accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,
significantly outperforming existing approaches.

</details>


### [27] [Predicate Renaming via Large Language Models](https://arxiv.org/abs/2510.25517)
*Elisabetta Gentili,Tony Ribeiro,Fabrizio Riguzzi,Katsumi Inoue*

Main category: cs.AI

TL;DR: 使用大型语言模型为逻辑规则中的未命名谓词生成有意义的名称，以提升逻辑理论的可读性、可解释性和可重用性。


<details>
  <summary>Details</summary>
Motivation: 在归纳逻辑编程中，各种规则生成方法（特别是谓词发明）会产生包含未命名谓词的规则，这阻碍了逻辑理论的可读性、可解释性和可重用性。

Method: 利用大型语言模型处理自然语言和代码的能力，为未命名谓词提供语义上有意义的命名建议。

Result: 在手工制作的逻辑规则上评估表明，大型语言模型在此任务上具有潜力。

Conclusion: 大型语言模型能够有效为逻辑规则中的未命名谓词生成有意义的名称，解决逻辑理论的可读性问题。

Abstract: In this paper, we address the problem of giving names to predicates in logic
rules using Large Language Models (LLMs). In the context of Inductive Logic
Programming, various rule generation methods produce rules containing unnamed
predicates, with Predicate Invention being a key example. This hinders the
readability, interpretability, and reusability of the logic theory. Leveraging
recent advancements in LLMs development, we explore their ability to process
natural language and code to provide semantically meaningful suggestions for
giving a name to unnamed predicates. The evaluation of our approach on some
hand-crafted logic rules indicates that LLMs hold potential for this task.

</details>


### [28] [Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation](https://arxiv.org/abs/2510.25518)
*Thomas Cook,Richard Osuagwu,Liman Tsatiashvili,Vrynsia Vrynsia,Koustav Ghosal,Maraim Masoud,Riccardo Mattivi*

Main category: cs.AI

TL;DR: 本文提出了一种面向金融科技领域的智能RAG架构，通过模块化代理系统解决专业领域检索中的术语、缩略语和复杂查询问题，在检索精度和相关性方面优于标准RAG基线。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统在金融科技等专业领域面临挑战，包括领域特定本体、密集术语和缩略语，这些问题影响了检索和合成的有效性。

Method: 采用模块化代理架构，包括智能查询重构、基于关键词提取的迭代子查询分解、上下文缩略语解析以及基于交叉编码器的上下文重排序。

Result: 在包含85个问答参考三元组的金融科技知识库数据集上评估，代理RAG系统在检索精度和相关性方面优于基线，但延迟有所增加。

Conclusion: 结构化、多代理方法为增强复杂领域特定环境中的检索鲁棒性提供了有前景的方向。

Abstract: Retrieval-Augmented Generation (RAG) systems often face limitations in
specialized domains such as fintech, where domain-specific ontologies, dense
terminology, and acronyms complicate effective retrieval and synthesis. This
paper introduces an agentic RAG architecture designed to address these
challenges through a modular pipeline of specialized agents. The proposed
system supports intelligent query reformulation, iterative sub-query
decomposition guided by keyphrase extraction, contextual acronym resolution,
and cross-encoder-based context re-ranking. We evaluate our approach against a
standard RAG baseline using a curated dataset of 85 question--answer--reference
triples derived from an enterprise fintech knowledge base. Experimental results
demonstrate that the agentic RAG system outperforms the baseline in retrieval
precision and relevance, albeit with increased latency. These findings suggest
that structured, multi-agent methodologies offer a promising direction for
enhancing retrieval robustness in complex, domain-specific settings.

</details>


### [29] [Zero Reinforcement Learning Towards General Domains](https://arxiv.org/abs/2510.25528)
*Yuyuan Zeng,Yufei Huang,Can Xu,Qingfeng Sun,Jianfeng Yan,Guanghui Xu,Tao Yang,Fengzong Lian*

Main category: cs.AI

TL;DR: 提出了一种新的零强化学习范式，通过结合可验证奖励和生成式奖励模型，在可验证和不可验证领域进行多任务训练，提升语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前零强化学习研究主要集中在可验证奖励信号的领域（如数学、编程），但在验证不直接的多样化场景中激发推理能力的研究仍不足。

Method: 结合可验证奖励与生成式奖励模型进行多任务零强化学习训练，设计平滑长度惩罚机制防止奖励攻击，鼓励生成更全面的思考标记。

Result: 在Qwen3-8B-Base和Qwen3-14B-Base上的实验表明，该方法在需要广泛推理的任务和更一般的任务上都取得了优越的推理性能。

Conclusion: 该方法成功提升了语言模型在可验证和不可验证领域的推理能力，实现了推理能力在领域间的迁移。

Abstract: Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach
for enhancing the reasoning capabilities of large language models (LLMs) by
directly applying reinforcement learning with verifiable rewards on pretrained
models, without the need for a supervised fine-tuning phase. However, current
research on zero-RL primarily focuses on domains with easily verifiable reward
signals, such as mathematics, programming, and other reasoning tasks. The
challenge of eliciting reasoning abilities in more diverse scenarios, where
verification is not straightforward, remains underexplored. To address this
gap, we propose a novel zero-RL paradigm designed to improve a model's
reasoning ability across both verifiable and non-verifiable domains. By
combining verifiable rewards with a generative reward model, we conduct
multi-task zero-RL training across both domains, facilitating the transfer of
reasoning capabilities between them. Furthermore, to mitigate reward hacking in
the generative reward model, we design a smooth length penalty that encourages
the generation of more comprehensive thinking tokens in general domains.
Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our
approach achieves superior reasoning performance, not only on tasks requiring
extensive reasoning but also on more general tasks.

</details>


### [30] [Off-policy Reinforcement Learning with Model-based Exploration Augmentation](https://arxiv.org/abs/2510.25529)
*Likun Wang,Xiangteng Zhang,Yinuo Wang,Guojian Zhan,Wenxuan Wang,Haoyu Gao,Jingliang Duan,Shengbo Eben Li*

Main category: cs.AI

TL;DR: 提出了MoGE方法，通过生成未充分探索的关键状态和动态一致的体验来增强强化学习中的探索能力，显著提高了样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有探索方法存在局限性：主动探索在高维环境中表现不佳，被动探索受限于样本多样性不足。需要解决被动探索的局限性。

Method: MoGE包含两个组件：(1)基于扩散模型的关键状态生成器，通过效用函数评估状态对策略探索的潜在影响；(2)一步想象世界模型，基于关键状态构建关键转换用于智能体学习。

Result: 在OpenAI Gym和DeepMind Control Suite上的实验结果表明，MoGE有效连接了探索和策略学习，在复杂控制任务中显著提高了样本效率和性能。

Conclusion: MoGE采用模块化设计，可与现有算法无缝集成，在不改变核心结构的情况下改善探索能力，是强化学习探索的有效解决方案。

Abstract: Exploration is fundamental to reinforcement learning (RL), as it determines
how effectively an agent discovers and exploits the underlying structure of its
environment to achieve optimal performance. Existing exploration methods
generally fall into two categories: active exploration and passive exploration.
The former introduces stochasticity into the policy but struggles in
high-dimensional environments, while the latter adaptively prioritizes
transitions in the replay buffer to enhance exploration, yet remains
constrained by limited sample diversity. To address the limitation in passive
exploration, we propose Modelic Generative Exploration (MoGE), which augments
exploration through the generation of under-explored critical states and
synthesis of dynamics-consistent experiences through transition models. MoGE is
composed of two components: (1) a diffusion-based generator that synthesizes
critical states under the guidance of a utility function evaluating each
state's potential influence on policy exploration, and (2) a one-step
imagination world model for constructing critical transitions based on the
critical states for agent learning. Our method adopts a modular formulation
that aligns with the principles of off-policy learning, allowing seamless
integration with existing algorithms to improve exploration without altering
their core structures. Empirical results on OpenAI Gym and DeepMind Control
Suite reveal that MoGE effectively bridges exploration and policy learning,
leading to remarkable gains in both sample efficiency and performance across
complex control tasks.

</details>


### [31] [Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2510.25588)
*Eranga Bandara,Ross Gore,Atmaram Yarlagadda,Anita H. Clayton,Preston Samuel,Christopher K. Rhea,Sachin Shetty*

Main category: cs.AI

TL;DR: 提出一个基于微调大语言模型联盟和推理LLM的决策支持系统，用于精神障碍的临床诊断，通过共识决策机制提高诊断标准化和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前精神障碍诊断主要依赖医患对话，存在主观性和诊断不一致的问题，需要标准化方法来提高可靠性和一致性。

Method: 使用在精神科医患对话数据集上微调的LLM，通过共识决策机制聚合各模型预测，并由OpenAI-gpt-oss推理LLM进行精炼，部署LLM代理协调整个诊断流程。

Result: 实验结果表明，结合微调LLM和推理模型能够创建稳健且高精度的精神健康评估诊断系统，原型系统已与美国陆军医疗研究团队合作开发。

Conclusion: 这是首个将微调LLM联盟与推理LLM集成应用于临床精神健康诊断的工作，为下一代AI驱动的电子健康系统标准化精神科诊断开辟了道路。

Abstract: The diagnosis of most mental disorders, including psychiatric evaluations,
primarily depends on dialogues between psychiatrists and patients. This
subjective process can lead to variability in diagnoses across clinicians and
patients, resulting in inconsistencies and challenges in achieving reliable
outcomes. To address these issues and standardize psychiatric diagnoses, we
propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss
Reasoning LLM-enabled Decision Support System for the clinical diagnosis of
mental disorders. Our approach leverages fine-tuned LLMs trained on
conversational datasets involving psychiatrist-patient interactions focused on
mental health conditions (e.g., depression). The diagnostic predictions from
individual models are aggregated through a consensus-based decision-making
process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method
for deploying LLM agents that orchestrate communication between the LLM
consortium and the reasoning LLM, ensuring transparency, reliability, and
responsible AI across the entire diagnostic workflow. Experimental results
demonstrate the transformative potential of combining fine-tuned LLMs with a
reasoning model to create a robust and highly accurate diagnostic system for
mental health assessment. A prototype of the proposed platform, integrating
three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in
collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,
USA. To the best of our knowledge, this work represents the first application
of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical
mental health diagnosis paving the way for next-generation AI-powered eHealth
systems aimed at standardizing psychiatric diagnoses.

</details>


### [32] [Counterfactual-based Agent Influence Ranker for Agentic AI Workflows](https://arxiv.org/abs/2510.25612)
*Amit Giloni,Chiara Picardi,Roy Betser,Shamik Bose,Aishvariya Priya Rathina Sabapathy,Roman Vainshtein*

Main category: cs.AI

TL;DR: 提出了CAIR方法，首个用于评估多智能体系统中各智能体对最终输出影响程度的方法，通过反事实分析实现任务无关的分析。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI工作流的广泛应用，需要从质量和安全角度深入理解其运作，但目前缺乏评估各智能体对最终输出影响的方法。

Method: 使用反事实分析技术，通过改变单个智能体的输出来评估其对整体输出的影响程度，支持离线和推理时分析。

Result: 在包含30个用例和230个功能的AAW数据集上评估，CAIR产生一致的排名，优于基线方法，并能有效提升下游任务的效果和相关性。

Conclusion: CAIR是首个能够评估多智能体系统中智能体影响力的方法，为理解和改进AAW系统提供了重要工具。

Abstract: An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,
is an autonomous system that assembles several LLM-based agents to work
collaboratively towards a shared goal. The high autonomy, widespread adoption,
and growing interest in such AAWs highlight the need for a deeper understanding
of their operations, from both quality and security aspects. To this day, there
are no existing methods to assess the influence of each agent on the AAW's
final output. Adopting techniques from related fields is not feasible since
existing methods perform only static structural analysis, which is unsuitable
for inference time execution. We present Counterfactual-based Agent Influence
Ranker (CAIR) - the first method for assessing the influence level of each
agent on the AAW's output and determining which agents are the most
influential. By performing counterfactual analysis, CAIR provides a
task-agnostic analysis that can be used both offline and at inference time. We
evaluate CAIR using an AAWs dataset of our creation, containing 30 different
use cases with 230 different functionalities. Our evaluation showed that CAIR
produces consistent rankings, outperforms baseline methods, and can easily
enhance the effectiveness and relevancy of downstream tasks.

</details>


### [33] [ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents](https://arxiv.org/abs/2510.25668)
*Tianyu Yang,Terry Ruas,Yijun Tian,Jan Philip Wahle,Daniel Kurzawe,Bela Gipp*

Main category: cs.AI

TL;DR: ALDEN是一个基于强化学习的多轮导航框架，通过将视觉语言模型训练为交互式智能体，使其能够主动导航长文档，解决了现有方法在长文档理解中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理长而复杂的多页文档时表现不佳，主要因为固定的推理模板和刚性流程限制了模型的主动性和泛化能力。

Method: 提出ALDEN框架，包含新颖的fetch动作直接按索引访问页面，结合搜索动作更好地利用文档结构；采用基于规则的跨层级奖励机制进行密集过程监督；引入视觉语义锚定机制稳定训练过程。

Result: 在三个开源数据集构建的语料库上训练后，ALDEN在五个长文档基准测试中达到了最先进的性能。

Conclusion: ALDEN标志着从被动文档阅读向自主导航和跨长文档推理的智能体的转变，为更准确和高效的长文档理解提供了稳健路径。

Abstract: Vision-language models (VLMs) excel at interpreting text-rich images but
struggle with long, visually complex documents that demand analysis and
integration of information spread across multiple pages. Existing approaches
typically rely on fixed reasoning templates or rigid pipelines, which force
VLMs into a passive role and hinder both efficiency and generalization. We
present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement
learning framework that fine-tunes VLMs as interactive agents capable of
actively navigating long, visually rich documents. ALDEN introduces a novel
fetch action that directly accesses the page by index, complementing the
classic search action and better exploiting document structure. For dense
process supervision and efficient training, we propose a rule-based cross-level
reward that provides both turn- and token-level signals. To address the
empirically observed training instability caused by numerous visual tokens from
long documents, we further propose a visual-semantic anchoring mechanism that
applies a dual-path KL-divergence constraint to stabilize visual and textual
representations separately during training. Trained on a corpus constructed
from three open-source datasets, ALDEN achieves state-of-the-art performance on
five long-document benchmarks. Overall, ALDEN marks a step beyond passive
document reading toward agents that autonomously navigate and reason across
long, visually rich documents, offering a robust path to more accurate and
efficient long-document understanding.

</details>


### [34] [Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning](https://arxiv.org/abs/2510.25679)
*Federica Tonti,Ricardo Vinuesa*

Main category: cs.AI

TL;DR: 提出了一种基于深度强化学习的无人机最优导航策略，结合PPO算法和GTrXL架构，在复杂城市气流环境中显著提升了导航成功率并降低了碰撞率。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在城市区域用于配送和监控的日益普及，需要开发能够在复杂城市气流环境中有效导航的智能算法。

Method: 采用基于深度强化学习的流感知PPO算法，结合GTrXL架构，为无人机提供更丰富的湍流场信息。

Result: 与PPO+LSTM、PPO+GTrXL（无次级预测任务）和传统Zermelo导航算法相比，该方法显著提高了成功率(SR)并降低了碰撞率(CR)。

Conclusion: 该研究为在复杂城市环境中重新构想无人机应用前景铺平了道路。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for
delivery and surveillance purposes. In this work, we develop an optimal
navigation strategy based on Deep Reinforcement Learning. The environment is
represented by a three-dimensional high-fidelity simulation of an urban flow,
characterized by turbulence and recirculation zones. The algorithm presented
here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated
Transformer eXtra Large (GTrXL) architecture, giving the agent richer
information about the turbulent flow field in which it navigates. The results
are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO
combined with Long Short Term Memory (LSTM) cells and a traditional navigation
algorithm. The obtained results show a significant increase in the success rate
(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the
classical Zermelo's navigation algorithm, paving the way to a completely
reimagined UAV landscape in complex urban environments.

</details>


### [35] [BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph](https://arxiv.org/abs/2510.25724)
*Vanya Arikutharam,Arkadiy Ukolov*

Main category: cs.AI

TL;DR: BambooKG是一种带频率权重的知识图谱，通过非三元组边减少信息损失，提升单跳和多跳推理性能


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法独立处理检索块，难以进行多跳或关系推理；标准知识图谱会遗漏不符合三元组结构的信息

Method: 引入BambooKG，在非三元组边上应用基于频率的权重，反映链接强度，借鉴赫布原理

Result: 减少了信息损失，在单跳和多跳推理任务上表现优于现有解决方案

Conclusion: BambooKG通过频率加权边有效提升了知识图谱的推理能力，解决了传统方法的局限性

Abstract: Retrieval-Augmented Generation allows LLMs to access external knowledge,
reducing hallucinations and ageing-data issues. However, it treats retrieved
chunks independently and struggles with multi-hop or relational reasoning,
especially across documents. Knowledge graphs enhance this by capturing the
relationships between entities using triplets, enabling structured, multi-chunk
reasoning. However, these tend to miss information that fails to conform to the
triplet structure. We introduce BambooKG, a knowledge graph with
frequency-based weights on non-triplet edges which reflect link strength,
drawing on the Hebbian principle of "fire together, wire together". This
decreases information loss and results in improved performance on single- and
multi-hop reasoning, outperforming the existing solutions.

</details>


### [36] [TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling](https://arxiv.org/abs/2510.25758)
*He Hu,Yucheng Zhou,Chiyuan Ma,Qianning Wang,Zheng Zhang,Fei Ma,Laizhong Cui,Qi Tian*

Main category: cs.AI

TL;DR: TheraMind是一个用于纵向心理咨询的战略性自适应代理，采用双循环架构解决现有LLM在心理咨询中缺乏情感理解、自适应策略和跨会话长期记忆的问题。


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询方法缺乏情感理解、自适应策略和跨会话治疗方法的长期记忆，与真实临床实践差距较大。

Method: 提出新颖的双循环架构：会话内循环用于战术对话管理，感知患者情绪状态并动态选择响应策略；跨会话循环用于战略治疗规划，评估治疗效果并调整后续方法。

Result: 在高保真模拟环境中的广泛评估显示，TheraMind在多会话指标（如连贯性、灵活性和治疗协调性）上优于其他方法。

Conclusion: 双循环设计在模拟战略性、自适应和纵向治疗行为方面有效，验证了该方法在心理咨询中的实用性。

Abstract: Large language models (LLMs) in psychological counseling have attracted
increasing attention. However, existing approaches often lack emotional
understanding, adaptive strategies, and the use of therapeutic methods across
multiple sessions with long-term memory, leaving them far from real clinical
practice. To address these critical gaps, we introduce TheraMind, a strategic
and adaptive agent for longitudinal psychological counseling. The cornerstone
of TheraMind is a novel dual-loop architecture that decouples the complex
counseling process into an Intra-Session Loop for tactical dialogue management
and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session
Loop perceives the patient's emotional state to dynamically select response
strategies while leveraging cross-session memory to ensure continuity.
Crucially, the Cross-Session Loop empowers the agent with long-term
adaptability by evaluating the efficacy of the applied therapy after each
session and adjusting the method for subsequent interactions. We validate our
approach in a high-fidelity simulation environment grounded in real clinical
cases. Extensive evaluations show that TheraMind outperforms other methods,
especially on multi-session metrics like Coherence, Flexibility, and
Therapeutic Attunement, validating the effectiveness of its dual-loop design in
emulating strategic, adaptive, and longitudinal therapeutic behavior. The code
is publicly available at https://0mwwm0.github.io/TheraMind/.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [37] [Dynamic Spatial Treatment Effects and Network Fragility: Theory and Evidence from European Banking](https://arxiv.org/abs/2510.24775)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 本文基于连续函数框架分析金融网络系统性风险，使用动态空间效应方法研究欧洲银行系统的传染动态。研究发现COVID-19大流行使网络脆弱性增加26.9%，尽管银行数量减少46%，但整合增加了系统性脆弱性。


<details>
  <summary>Details</summary>
Motivation: 开发连续函数框架来分析金融网络系统性风险，扩展先前研究的Navier-Stokes方法，通过谱特性表征欧洲银行系统的传染动态。

Method: 使用欧洲银行管理局透明度演习(2014-2023)的高质量双边暴露数据，采用空间双重差分方法估计COVID-19对网络脆弱性的因果影响。

Result: COVID-19使网络脆弱性(由系统拉普拉斯矩阵的代数连通性λ2衡量)比大流行前水平增加26.9%(95% CI: [7.4%, 46.5%], p<0.05)，尽管银行数量减少46%，但整合增加了系统性脆弱性。

Conclusion: 研究验证了连续空间动力学的关键预测：处理效应通过空间溢出随时间放大，当耦合强度增加时整合会增加脆弱性，系统表现出结构滞后性。结果证明了连续函数方法在金融稳定性分析中的实证相关性，并为宏观审慎政策设计提供了新见解。

Abstract: This paper develops and empirically implements a continuous functional
framework for analyzing systemic risk in financial networks, building on the
dynamic spatial treatment effect methodology established in our previous
studies. We extend the Navier-Stokes-based approach from our previous studies
to characterize contagion dynamics in the European banking system through the
spectral properties of network evolution operators. Using high-quality
bilateral exposure data from the European Banking Authority Transparency
Exercise (2014-2023), we estimate the causal impact of the COVID-19 pandemic on
network fragility using spatial difference-in-differences methods adapted from
our previous studies. Our empirical analysis reveals that COVID-19 elevated
network fragility, measured by the algebraic connectivity $\lambda_2$ of the
system Laplacian, by 26.9% above pre-pandemic levels (95% CI: [7.4%, 46.5%],
p<0.05), with effects persisting through 2023. Paradoxically, this occurred
despite a 46% reduction in the number of banks, demonstrating that
consolidation increased systemic vulnerability by intensifying
interconnectedness-consistent with theoretical predictions from continuous
spatial dynamics. Our findings validate the key predictions from
\citet{kikuchi2024dynamical}: treatment effects amplify over time through
spatial spillovers, consolidation increases fragility when coupling strength
rises, and systems exhibit structural hysteresis preventing automatic reversion
to pre-shock equilibria. The results demonstrate the empirical relevance of
continuous functional methods for financial stability analysis and provide new
insights for macroprudential policy design. We propose network-based capital
requirements targeting spectral centrality and stress testing frameworks
incorporating diffusion dynamics to address the coupling externalities
identified in our analysis.

</details>


### [38] [Dual-Channel Technology Diffusion: Spatial Decay and Network Contagion in Supply Chain Networks](https://arxiv.org/abs/2510.24781)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 本文开发了一个双通道框架分析技术扩散，整合了连续函数分析的空间衰减机制和谱图理论的网络传染动态，发现技术采纳通过地理邻近和供应链连接同时传播。


<details>
  <summary>Details</summary>
Motivation: 基于先前关于空间处理效应和金融网络脆弱性的研究，探索技术采纳如何通过地理和网络渠道传播，为技术政策提供微观基础。

Method: 使用2010-2023年500家公司采用六种技术的综合数据，结合空间衰减分析和谱图理论，构建双通道扩散框架。

Result: 发现技术采纳具有强指数地理衰减（κ≈0.043/公里），供应链连接使代数连通性增加300-380%，传统方法存在61%偏差，COVID-19后网络脆弱性增加24.5%。

Conclusion: 干预措施具有69公里的空间范围和10.8的网络放大因子，需要协调地理和供应链目标以实现最佳效果。

Abstract: This paper develops a dual-channel framework for analyzing technology
diffusion that integrates spatial decay mechanisms from continuous functional
analysis with network contagion dynamics from spectral graph theory. Building
on our previous studies, which establish Navier-Stokes-based approaches to
spatial treatment effects and financial network fragility, we demonstrate that
technology adoption spreads simultaneously through both geographic proximity
and supply chain connections. Using comprehensive data on six technologies
adopted by 500 firms over 2010-2023, we document three key findings. First,
technology adoption exhibits strong exponential geographic decay with spatial
decay rate $\kappa \approx 0.043$ per kilometer, implying a spatial boundary of
$d^* \approx 69$ kilometers beyond which spillovers are negligible (R-squared =
0.99). Second, supply chain connections create technology-specific networks
whose algebraic connectivity ($\lambda_2$) increases 300-380 percent as
adoption spreads, with correlation between $\lambda_2$ and adoption exceeding
0.95 across all technologies. Third, traditional difference-in-differences
methods that ignore spatial and network structure exhibit 61 percent bias in
estimated treatment effects. An event study around COVID-19 reveals that
network fragility increased 24.5 percent post-shock, amplifying treatment
effects through supply chain spillovers in a manner analogous to financial
contagion documented in our recent study. Our framework provides
micro-foundations for technology policy: interventions have spatial reach of 69
kilometers and network amplification factor of 10.8, requiring coordinated
geographic and supply chain targeting for optimal effectiveness.

</details>


### [39] [Inference on Welfare and Value Functionals under Optimal Treatment Assignment](https://arxiv.org/abs/2510.25607)
*Xiaohong Chen,Zhenxiao Chen,Wayne Yuan Gao*

Main category: econ.EM

TL;DR: 本文研究了在最优治疗分配下非参数条件平均治疗效果(CATE)函数的福利和价值泛函的估计与推断理论，建立了半参数估计量的渐近正态性，并提供了方差估计方法。


<details>
  <summary>Details</summary>
Motivation: 研究在最优治疗分配策略下如何估计和推断CATE函数的福利和价值泛函，为政策评估提供理论支持。

Method: 使用半参数插件估计方法，基于筛Riesz表示器构建一致的方差估计器，并提出在子流形上进行数值积分的计算程序。

Result: 对于最优福利泛函，插件估计量具有√n渐近正态性；对于一般价值泛函，估计量在1维非参数估计速率下渐近正态。蒙特卡洛模拟显示方法在有限样本下表现良好。

Conclusion: 福利泛函与一般价值泛函的收敛速率差异源于边界子群体上被积函数的性质不同，所提出的估计和推断方法在实际应用中具有良好性能。

Abstract: We provide theoretical results for the estimation and inference of a class of
welfare and value functionals of the nonparametric conditional average
treatment effect (CATE) function under optimal treatment assignment, i.e.,
treatment is assigned to an observed type if and only if its CATE is
nonnegative. For the optimal welfare functional defined as the average value of
CATE on the subpopulation with nonnegative CATE, we establish the $\sqrt{n}$
asymptotic normality of the semiparametric plug-in estimators and provide an
analytical asymptotic variance formula. For more general value functionals, we
show that the plug-in estimators are typically asymptotically normal at the
1-dimensional nonparametric estimation rate, and we provide a consistent
variance estimator based on the sieve Riesz representer, as well as a proposed
computational procedure for numerical integration on submanifolds. The key
reason underlying the different convergence rates for the welfare functional
versus the general value functional lies in that, on the boundary subpopulation
for whom CATE is zero, the integrand vanishes for the welfare functional but
does not for general value functionals. We demonstrate in Monte Carlo
simulations the good finite-sample performance of our estimation and inference
procedures, and conduct an empirical application of our methods on the
effectiveness of job training programs on earnings using the JTPA data set.

</details>


### [40] [Agentic Economic Modeling](https://arxiv.org/abs/2510.25743)
*Bohan Zhang,Jiaxuan Li,Ali Hortaçsu,Xiaoyang Ye,Victor Chernozhukov,Angelo Ni,Edward Huang*

Main category: econ.EM

TL;DR: AEM框架通过LLM生成合成选择数据，然后学习偏差校正映射，使LLM选择与人类证据对齐，从而进行可靠的经济计量推断。


<details>
  <summary>Details</summary>
Motivation: 解决小样本人类数据下经济计量推断的可靠性问题，利用LLM生成合成数据来补充有限的人类证据。

Method: 首先生成任务条件化的LLM合成选择，然后学习从任务特征和原始LLM选择到人类对齐选择的偏差校正映射，最后使用标准经济计量估计器进行推断。

Result: 在大规模联合研究中，仅使用10%原始数据拟合校正模型就能降低需求参数估计误差；在区域实地实验中，校准模型估计的处理效应与完整人类实验结果高度匹配；时间外推实验中，仅使用第一天人类数据训练就能获得显著改进的结果。

Conclusion: AEM有潜力提高随机对照试验效率，并为基于LLM的反事实生成建立了基础方法。

Abstract: We introduce Agentic Economic Modeling (AEM), a framework that aligns
synthetic LLM choices with small-sample human evidence for reliable econometric
inference. AEM first generates task-conditioned synthetic choices via LLMs,
then learns a bias-correction mapping from task features and raw LLM choices to
human-aligned choices, upon which standard econometric estimators perform
inference to recover demand elasticities and treatment effects.We validate AEM
in two experiments. In a large scale conjoint study with millions of
observations, using only 10% of the original data to fit the correction model
lowers the error of the demand-parameter estimates, while uncorrected LLM
choices even increase the errors. In a regional field experiment, a mixture
model calibrated on 10% of geographic regions estimates an out-of-domain
treatment effect of -65\pm10 bps, closely matching the full human experiment
(-60\pm8 bps).Under time-wise extrapolation, training with only day-one human
data yields -24 bps (95% CI: [-26, -22], p<1e-5),improving over the human-only
day-one baseline (-17 bps, 95% CI: [-43, +9], p=0.2049).These results
demonstrate AEM's potential to improve RCT efficiency and establish a
foundation method for LLM-based counterfactual generation.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [41] [The Epistemic Suite: A Post-Foundational Diagnostic Methodology for Assessing AI Knowledge Claims](https://arxiv.org/abs/2510.24721)
*Matthew Kelly*

Main category: cs.CY

TL;DR: 本文提出了Epistemic Suite，一种后基础诊断方法，用于揭示AI输出的认识论条件，通过20个诊断视角识别模式如信心洗白、叙事压缩等，产生可检查的FACS包（标志、注释、矛盾地图、暂停日志），并引入认识论暂停机制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的流畅文本可能误导用户将模拟连贯性误认为真正理解，需要一种方法来诊断AI输出的认识论条件，而不是判断真伪。

Method: 采用后基础诊断方法，通过20个诊断视角分析AI输出，产生FACS包（标志、注释、矛盾地图、暂停日志），包含认识论暂停机制、认识论分诊协议和元治理层。

Result: 该方法将语言模型转变为诊断立场，在AI输出和人类判断之间创建中间层，保持表现与理解的区别，实现可问责的审议。

Conclusion: Epistemic Suite作为外部支架运行，保持可消耗性和拒绝作为保障而非失败，维护认识论谦逊，与将对齐嵌入模型架构的内部方法不同。

Abstract: Large Language Models (LLMs) generate fluent, plausible text that can mislead
users into mistaking simulated coherence for genuine understanding. This paper
introduces the Epistemic Suite, a post-foundational diagnostic methodology for
surfacing the epistemic conditions under which AI outputs are produced and
received. Rather than determining truth or falsity, the Suite operates through
twenty diagnostic lenses, applied by practitioners as context warrants, to
reveal patterns such as confidence laundering, narrative compression, displaced
authority, and temporal drift. It is grounded in three design principles:
diagnosing production before evaluating claims, preferring diagnostic traction
over foundational settlement, and embedding reflexivity as a structural
requirement rather than an ethical ornament. When enacted, the Suite shifts
language models into a diagnostic stance, producing inspectable
artifacts-flags, annotations, contradiction maps, and suspension logs (the FACS
bundle)-that create an intermediary layer between AI output and human judgment.
A key innovation is epistemic suspension, a practitioner-enacted circuit
breaker that halts continuation when warrant is exceeded, with resumption based
on judgment rather than rule. The methodology also includes an Epistemic Triage
Protocol and a Meta-Governance Layer to manage proportionality and link
activation to relational accountability, consent, historical context, and
pluralism safeguards. Unlike internalist approaches that embed alignment into
model architectures (e.g., RLHF or epistemic-integrity proposals), the Suite
operates externally as scaffolding, preserving expendability and refusal as
safeguards rather than failures. It preserves the distinction between
performance and understanding, enabling accountable deliberation while
maintaining epistemic modesty.

</details>


### [42] [Topic-aware Large Language Models for Summarizing the Lived Healthcare Experiences Described in Health Stories](https://arxiv.org/abs/2510.24765)
*Maneesh Bilalpur,Megan Hamm,Young Ji Lee,Natasha Norman,Kathleen M. McTigue,Yanshan Wang*

Main category: cs.CY

TL;DR: 使用LDA主题建模和LLM分层摘要技术分析非裔美国人医疗经历故事，识别出26个主题并生成高质量摘要，为医疗干预提供见解。


<details>
  <summary>Details</summary>
Motivation: 探索故事叙述在医疗沟通中的价值，利用LLM技术从非裔美国人的医疗经历故事中识别潜在因素和干预途径，以改善医疗结果差距。

Method: 采用LDA主题建模技术分析50个非裔美国人故事，使用开源LLM进行分层摘要：先对单个故事摘要，再对同一主题的故事摘要进行汇总。

Result: 识别出26个相关主题（如健康行为、医患互动等），GPT4评估显示主题摘要无虚构、准确性高、全面且有用，与专家评估具有中等到高度一致性。

Conclusion: LDA和LLM结合能有效从非结构化叙事中识别主题和生成摘要，为健康研究和临床改进提供新途径，最终改善患者和照顾者的健康结果。

Abstract: Storytelling is a powerful form of communication and may provide insights
into factors contributing to gaps in healthcare outcomes. To determine whether
Large Language Models (LLMs) can identify potential underlying factors and
avenues for intervention, we performed topic-aware hierarchical summarization
of narratives from African American (AA) storytellers. Fifty transcribed
stories of AA experiences were used to identify topics in their experience
using the Latent Dirichlet Allocation (LDA) technique. Stories about a given
topic were summarized using an open-source LLM-based hierarchical summarization
approach. Topic summaries were generated by summarizing across story summaries
for each story that addressed a given topic. Generated topic summaries were
rated for fabrication, accuracy, comprehensiveness, and usefulness by the GPT4
model, and the model's reliability was validated against the original story
summaries by two domain experts. 26 topics were identified in the fifty AA
stories. The GPT4 ratings suggest that topic summaries were free from
fabrication, highly accurate, comprehensive, and useful. The reliability of GPT
ratings compared to expert assessments showed moderate to high agreement. Our
approach identified AA experience-relevant topics such as health behaviors,
interactions with medical team members, caregiving and symptom management,
among others. Such insights could help researchers identify potential factors
and interventions by learning from unstructured narratives in an efficient
manner-leveraging the communicative power of storytelling. The use of LDA and
LLMs to identify and summarize the experience of AA individuals suggests a
variety of possible avenues for health research and possible clinical
improvements to support patients and caregivers, thereby ultimately improving
health outcomes.

</details>


### [43] [PANORAMA: A Dataset and Benchmarks Capturing Decision Trails and Rationales in Patent Examination](https://arxiv.org/abs/2510.24774)
*Hyunseung Lim,Sooyohn Nam,Sungmin Na,Ji Yong Cho,June Yong Yang,Hyungyu Shin,Yoonjoo Lee,Juho Kim,Moontae Lee,Hwajung Hong*

Main category: cs.CY

TL;DR: PANORAMA是一个包含8,143条美国专利审查记录的完整数据集，保留了完整的决策轨迹，包括原始申请、引用文献、非最终驳回和授权通知。该数据集将审查过程分解为序列化基准测试，用于评估大语言模型在专利审查各步骤中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有NLP研究将专利审查简化为预测任务，忽略了审查员基于详细信息进行的逐步评估过程，特别是办公室行动文件中提供的决策理由，这使得难以衡量当前技术在专利审查过程中的实际表现。

Method: 构建PANORAMA数据集，包含完整的专利审查决策轨迹，并将其分解为模拟专利专业人士审查过程的序列化基准测试，以评估大语言模型在检索相关现有技术、识别关键段落以及评估新颖性和非显而易见性等步骤中的能力。

Result: 研究发现，大语言模型在检索相关现有技术和识别关键段落方面相对有效，但在评估专利权利要求的新颖性和非显而易见性方面表现不佳。

Conclusion: 推进专利领域的NLP技术（包括大语言模型）需要对真实世界的专利审查过程有更深入的理解。PANORAMA数据集为这一研究方向提供了重要资源。

Abstract: Patent examination remains an ongoing challenge in the NLP literature even
after the advent of large language models (LLMs), as it requires an extensive
yet nuanced human judgment on whether a submitted claim meets the statutory
standards of novelty and non-obviousness against previously granted claims --
prior art -- in expert domains. Previous NLP studies have approached this
challenge as a prediction task (e.g., forecasting grant outcomes) with
high-level proxies such as similarity metrics or classifiers trained on
historical labels. However, this approach often overlooks the step-by-step
evaluations that examiners must make with profound information, including
rationales for the decisions provided in office actions documents, which also
makes it harder to measure the current state of techniques in patent review
processes. To fill this gap, we construct PANORAMA, a dataset of 8,143 U.S.
patent examination records that preserves the full decision trails, including
original applications, all cited references, Non-Final Rejections, and Notices
of Allowance. Also, PANORAMA decomposes the trails into sequential benchmarks
that emulate patent professionals' patent review processes and allow
researchers to examine large language models' capabilities at each step of
them. Our findings indicate that, although LLMs are relatively effective at
retrieving relevant prior art and pinpointing the pertinent paragraphs, they
struggle to assess the novelty and non-obviousness of patent claims. We discuss
these results and argue that advancing NLP, including LLMs, in the patent
domain requires a deeper understanding of real-world patent examination. Our
dataset is openly available at
https://huggingface.co/datasets/LG-AI-Research/PANORAMA.

</details>


### [44] [AI & Data Competencies: Scaffolding holistic AI literacy in Higher Education](https://arxiv.org/abs/2510.24783)
*Kathleen Kennedy,Anuj Gupta*

Main category: cs.CY

TL;DR: 提出了AI与数据素养学习成果框架，用于指导高等教育中AI素养的整合，包含四个熟练度等级和七个知识维度，平衡技术技能与伦理考量。


<details>
  <summary>Details</summary>
Motivation: 为高等教育提供结构化工具，系统整合AI素养教育，帮助学生全面发展AI相关能力，应对生成式AI在学术和职业环境中的应用需求。

Method: 通过协作过程开发框架，定义AI和数据相关能力，提供课程设计、学习活动和评估的实施策略。

Result: 建立了包含四个熟练度等级和七个知识维度的综合框架，为教育者提供实施AI教育的结构化方法。

Conclusion: 该框架为发展学生全面AI素养提供了路线图，使学习者能够在学术和职业环境中有效利用生成式AI能力。

Abstract: This chapter introduces the AI & Data Acumen Learning Outcomes Framework, a
comprehensive tool designed to guide the integration of AI literacy across
higher education. Developed through a collaborative process, the framework
defines key AI and data-related competencies across four proficiency levels and
seven knowledge dimensions. It provides a structured approach for educators to
scaffold student learning in AI, balancing technical skills with ethical
considerations and sociocultural awareness. The chapter outlines the
framework's development process, its structure, and practical strategies for
implementation in curriculum design, learning activities, and assessment. We
address challenges in implementation and future directions for AI education. By
offering a roadmap for developing students' holistic AI literacy, this
framework prepares learners to leverage generative AI capabilities in both
academic and professional contexts.

</details>


### [45] [The Economics of AI Training Data: A Research Agenda](https://arxiv.org/abs/2510.24990)
*Hamidah Oderinwale,Anna Kazlauskas*

Main category: cs.CY

TL;DR: 本文建立数据经济学作为一个连贯领域，通过分析数据的独特属性、记录AI训练数据交易模式，并提出数据交换单位层次结构，为理解数据在AI生产中的作用提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 随着AI实验室耗尽公共数据并转向专有数据源，数据交易达到数亿美元规模，但计算机科学、经济学、法律和政策等领域的研究碎片化，需要建立统一的数据经济学框架。

Method: 1) 分析数据的三个独特属性：非竞争性、情境依赖性和通过污染产生的竞争性；2) 系统记录2020-2025年AI训练数据交易；3) 提出可交换数据单位的正式层次结构。

Result: 揭示了市场持续碎片化、五种不同的定价机制，以及大多数交易将原始创作者排除在补偿之外。提出了数据在生产函数中的显式表示方法。

Conclusion: 建立了数据经济学的基础框架，并提出了四个开放研究问题：衡量情境依赖价值、平衡治理与隐私、估计数据对生产的贡献、以及为异质组合商品设计机制。

Abstract: Despite data's central role in AI production, it remains the least understood
input. As AI labs exhaust public data and turn to proprietary sources, with
deals reaching hundreds of millions of dollars, research across computer
science, economics, law, and policy has fragmented. We establish data economics
as a coherent field through three contributions. First, we characterize data's
distinctive properties -- nonrivalry, context dependence, and emergent rivalry
through contamination -- and trace historical precedents for market formation
in commodities such as oil and grain. Second, we present systematic
documentation of AI training data deals from 2020 to 2025, revealing persistent
market fragmentation, five distinct pricing mechanisms (from per-unit licensing
to commissioning), and that most deals exclude original creators from
compensation. Third, we propose a formal hierarchy of exchangeable data units
(token, record, dataset, corpus, stream) and argue for data's explicit
representation in production functions. Building on these foundations, we
outline four open research problems foundational to data economics: measuring
context-dependent value, balancing governance with privacy, estimating data's
contribution to production, and designing mechanisms for heterogeneous,
compositional goods.

</details>


### [46] [Mutual Wanting in Human--AI Interaction: Empirical Evidence from Large-Scale Analysis of GPT Model Transitions](https://arxiv.org/abs/2510.24796)
*HaoYang Shang,Xuan Liu*

Main category: cs.CY

TL;DR: 该研究引入"相互期望"概念分析人类与AI系统间的双向期望动态，通过论坛评论分析和控制实验验证了期望动态的存在，开发了相互期望对齐框架用于用户体验管理和AI系统设计。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展在用户和AI系统之间创造了复杂的双向期望，但这些期望动态尚未被充分理解，需要系统性的实证研究。

Method: 分析主要AI论坛的用户评论，在多个OpenAI模型上进行控制实验，使用双算法主题建模和多维特征提取等先进NLP技术。

Result: 近半数用户使用拟人化语言，信任显著超过背叛语言，用户可分为不同的"相互期望"类型，识别了可测量的期望违反模式并量化了模型发布后的期望-现实差距。

Conclusion: 相互期望是可测量的现象，对构建更值得信赖和关系感知的AI系统具有明确意义，开发的相互期望对齐框架可用于主动用户体验管理和AI系统设计。

Abstract: The rapid evolution of large language models (LLMs) creates complex
bidirectional expectations between users and AI systems that are poorly
understood. We introduce the concept of "mutual wanting" to analyze these
expectations during major model transitions. Through analysis of user comments
from major AI forums and controlled experiments across multiple OpenAI models,
we provide the first large-scale empirical validation of bidirectional desire
dynamics in human-AI interaction. Our findings reveal that nearly half of users
employ anthropomorphic language, trust significantly exceeds betrayal language,
and users cluster into distinct "mutual wanting" types. We identify measurable
expectation violation patterns and quantify the expectation-reality gap
following major model releases. Using advanced NLP techniques including
dual-algorithm topic modeling and multi-dimensional feature extraction, we
develop the Mutual Wanting Alignment Framework (M-WAF) with practical
applications for proactive user experience management and AI system design.
These findings establish mutual wanting as a measurable phenomenon with clear
implications for building more trustworthy and relationally-aware AI systems.

</details>


### [47] [Managing Administrative Law Cases using an Adaptable Model-driven Norm-enforcing Tool](https://arxiv.org/abs/2510.24822)
*Marten C. Steketee,Nina M. Verheijen,L. Thomas van Binsbergen*

Main category: cs.CY

TL;DR: 开发了一个基于模型驱动的行政法案件管理工具，通过eFLINT规范语言实现自动规范推理，确保程序规范执行并提高决策透明度


<details>
  <summary>Details</summary>
Motivation: 政府机构在处理行政法案件时面临众多法律法规，手动执行政策既复杂又耗时，容易产生错误和延迟，限制了公民的司法可及性

Method: 实现了一个与eFLINT解释器交互的模型驱动案件管理工具，eFLINT是一种用于规范说明的领域特定语言，通过自动规范推理来执行规范

Result: 该工具能够确保程序规范得到遵循，并为公民提供决策推理的透明度，从而改善公民的司法可及性

Conclusion: 报告了案件管理工具的当前状态，并提出了进一步发展的方向，展示了自动化规范推理在行政法案件处理中的潜力

Abstract: Governmental organisations cope with many laws and policies when handling
administrative law cases. Making sure these norms are enforced in the handling
of cases is for the most part done manually. However, enforcing policies can
get complicated and time consuming with ever-changing (interpretations of) laws
and varying cases. This introduces errors and delays in the decision-making
process and therefore limits the access to justice for citizens. A potential
solution is offered by our tool in which norms are enforced using automated
normative reasoning. By ensuring the procedural norms are followed and
transparency can be provided about the reasoning behind a decision to citizens,
the tool benefits the access to justice for citizens. In this paper we report
on the implementation of a model-driven case management tool for administrative
law cases, based on a set of requirements elicited during earlier research. Our
tool achieves adaptability and norm enforcement by interacting with an
interpreter for eFLINT, a domain-specific language for norm specification. We
report on the current state of the case management tool and suggest directions
for further development.

</details>


### [48] [Do Chatbots Walk the Talk of Responsible AI?](https://arxiv.org/abs/2510.24823)
*Susan Ariel Aaronson,Michael Moreno*

Main category: cs.CY

TL;DR: 研究发现主要AI聊天机器人公司在负责任AI原则的实践与公开宣传之间存在显著差距


<details>
  <summary>Details</summary>
Motivation: 检验领先AI聊天机器人公司是否真正实施了他们公开倡导的负责任AI原则

Method: 采用混合方法分析四款主要聊天机器人（ChatGPT、Gemini、DeepSeek、Grok），包括公司网站分析、技术文档审查和直接聊天机器人评估

Result: 发现企业言论与实践之间存在显著差距

Conclusion: AI公司在负责任AI原则的实施方面存在言行不一的问题

Abstract: This study examines whether leading AI chatbot companies implement the
responsible AI principles they publicly advocate. The authors used a
mixed-methods approach analyzing four major chatbots (ChatGPT, Gemini,
DeepSeek, and Grok) across company websites, technical documentation, and
direct chatbot evaluations. We found significant gaps between corporate
rhetoric and practice.

</details>


### [49] [The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems](https://arxiv.org/abs/2510.24831)
*Stefano Natangelo*

Main category: cs.CY

TL;DR: 本文提出了叙事连续性测试(NCT)框架，用于评估AI系统的身份持久性和历时连贯性，指出当前大语言模型缺乏持久状态的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统能够生成连贯内容，但缺乏持久状态，每次推理都需从头重建上下文，无法维持跨时间的身份一致性。

Method: 定义五个必要维度：情境记忆、目标持久性、自主自我修正、风格语义稳定性、角色连续性，并通过案例分析展示现有架构的连续性失败。

Result: 案例分析显示现有系统在无状态推理下会出现可预测的连续性失败，NCT框架为未来基准测试和架构设计提供了概念要求。

Conclusion: NCT将AI评估从性能转向持久性，为支持生成模型长期身份和目标连贯性的架构设计指明了方向。

Abstract: Artificial intelligence systems based on large language models (LLMs) can now
generate coherent text, music, and images, yet they operate without a
persistent state: each inference reconstructs context from scratch. This paper
introduces the Narrative Continuity Test (NCT) -- a conceptual framework for
evaluating identity persistence and diachronic coherence in AI systems. Unlike
capability benchmarks that assess task performance, the NCT examines whether an
LLM remains the same interlocutor across time and interaction gaps. The
framework defines five necessary axes -- Situated Memory, Goal Persistence,
Autonomous Self-Correction, Stylistic & Semantic Stability, and Persona/Role
Continuity -- and explains why current architectures systematically fail to
support them. Case analyses (Character.AI, Grok, Replit, Air Canada) show
predictable continuity failures under stateless inference. The NCT reframes AI
evaluation from performance to persistence, outlining conceptual requirements
for future benchmarks and architectural designs that could sustain long-term
identity and goal coherence in generative models.

</details>


### [50] [Adaptive Data Collection for Latin-American Community-sourced Evaluation of Stereotypes (LACES)](https://arxiv.org/abs/2510.24958)
*Guido Ivetta,Pietro Palombini,Sofía Martinelli,Marcos J Gomez,Sunipa Dev,Vinodkumar Prabhakaran,Luciana Benotti*

Main category: cs.CY

TL;DR: 该论文提出了一个针对拉丁美洲的大规模刻板印象数据集，通过动态数据收集方法解决NLP模型评估中的地理文化偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有NLP偏见评估基准过度集中于英语和美国人口统计数据，导致拉丁美洲等地区严重缺乏评估资源，无法有效评估和减轻语言技术传播有害地区刻板印象的问题。

Method: 通过有针对性的社区合作开发大规模刻板印象数据集，并采用新颖的动态数据收集方法，将新刻板印象条目的收集和现有数据的验证整合到统一工作流程中。

Result: 创建了一个比静态收集方法具有更广泛覆盖面和更高地区细微差别的资源，为拉丁美洲提供了重要的公平性评估工具。

Conclusion: 这种新方法可应用于收集其他类型的社会文化知识，该数据集为解决拉丁美洲公平性资源的地理文化赤字提供了关键新资源。

Abstract: The evaluation of societal biases in NLP models is critically hindered by a
glaring geo-cultural gap, as existing benchmarks are overwhelmingly
English-centric and focused on U.S. demographics. This leaves regions such as
Latin America severely underserved, making it impossible to adequately assess
or mitigate the perpetuation of harmful regional stereotypes by language
technologies. To address this gap, we introduce a new, large-scale dataset of
stereotypes developed through targeted community partnerships within Latin
America. Furthermore, we present a novel dynamic data collection methodology
that uniquely integrates the sourcing of new stereotype entries and the
validation of existing data within a single, unified workflow. This combined
approach results in a resource with significantly broader coverage and higher
regional nuance than static collection methods. We believe that this new method
could be applicable in gathering sociocultural knowledge of other kinds, and
that this dataset provides a crucial new resource enabling robust stereotype
evaluation and significantly addressing the geo-cultural deficit in fairness
resources for Latin America.

</details>


### [51] [Teaching Probabilistic Machine Learning in the Liberal Arts: Empowering Socially and Mathematically Informed AI Discourse](https://arxiv.org/abs/2510.25049)
*Yaniv Yacoby*

Main category: cs.CY

TL;DR: 介绍了一个面向STEM少数群体学生的本科ML课程，采用框架优先方法，通过概率编程降低数学门槛，结合社会技术影响和辩证思维培养。


<details>
  <summary>Details</summary>
Motivation: 为在STEM领域被边缘化的学生设计ML课程，将数学基础与社会技术影响联系起来，培养学生的批判性思维和参与AI讨论的能力。

Method: 采用框架优先方法，使用概率编程降低数学障碍；通过虚构的"星际假设医院"主题使内容相关且易理解；结合技术内容与反叙事案例研究培养辩证思维。

Result: 课程成功帮助学生将数学形式主义与社会技术影响联系起来，增强了他们在AI讨论中的参与信心，认识到自身独特视角的价值。

Conclusion: 这种教学方法能够有效赋能学生，让他们既掌握技术知识又具备批判性思维，成为自信的技术专家和批判性公民。

Abstract: We present a new undergraduate ML course at our institution, a small liberal
arts college serving students minoritized in STEM, designed to empower students
to critically connect the mathematical foundations of ML with its
sociotechnical implications. We propose a "framework-focused" approach,
teaching students the language and formalism of probabilistic modeling while
leveraging probabilistic programming to lower mathematical barriers. We
introduce methodological concepts through a whimsical, yet realistic theme, the
"Intergalactic Hypothetical Hospital," to make the content both relevant and
accessible. Finally, we pair each technical innovation with counter-narratives
that challenge its value using real, open-ended case-studies to cultivate
dialectical thinking. By encouraging creativity in modeling and highlighting
unresolved ethical challenges, we help students recognize the value and need of
their unique perspectives, empowering them to participate confidently in AI
discourse as technologists and critical citizens.

</details>


### [52] [The Iceberg Index: Measuring Workforce Exposure Across the AI Economy](https://arxiv.org/abs/2510.25137)
*Ayush Chopra,Santanu Bhattacharya,DeAndrea Salvador,Ayan Paul,Teddy Wright,Aditi Garg,Feroz Ahmad,Alice C. Schwarze,Ramesh Raskar,Prasanna Balaprakash*

Main category: cs.CY

TL;DR: 论文提出了冰山指数来衡量AI系统在各职业中可执行技能的工资价值，揭示AI技术能力对劳动力市场的潜在影响远超表面可见的采用情况。


<details>
  <summary>Details</summary>
Motivation: 传统劳动力指标无法捕捉AI能力与人类技能重叠的潜在影响，只能测量颠覆发生后的就业结果，无法预测AI采用前的技能暴露风险。

Method: 使用大型人口模型模拟人-AI劳动力市场，将1.51亿工人表示为执行32,000多种技能的自主代理，并与数千种AI工具交互，引入以技能为中心的冰山指数。

Result: 分析显示可见的AI采用集中在计算和技术领域（2.2%工资价值，约2110亿美元）只是冰山一角，技术能力通过认知自动化延伸到行政、金融和专业服务领域（11.7%，约1.2万亿美元），暴露程度是五倍且地理分布更广。

Conclusion: 传统指标只能解释不到5%的技能基础变异，需要新指数来捕捉AI经济中的暴露风险，冰山模型使政策制定者和商业领袖能够在投入数十亿美元实施前识别暴露热点、优先投资和测试干预措施。

Abstract: Artificial Intelligence is reshaping America's \$9.4 trillion labor market,
with cascading effects that extend far beyond visible technology sectors. When
AI transforms quality control tasks in automotive plants, consequences spread
through logistics networks, supply chains, and local service economies. Yet
traditional workforce metrics cannot capture these ripple effects: they measure
employment outcomes after disruption occurs, not where AI capabilities overlap
with human skills before adoption crystallizes. Project Iceberg addresses this
gap using Large Population Models to simulate the human-AI labor market,
representing 151 million workers as autonomous agents executing over 32,000
skills and interacting with thousands of AI tools. It introduces the Iceberg
Index, a skills-centered metric that measures the wage value of skills AI
systems can perform within each occupation. The Index captures technical
exposure, where AI can perform occupational tasks, not displacement outcomes or
adoption timelines. Analysis shows that visible AI adoption concentrated in
computing and technology (2.2% of wage value, approx \$211 billion) represents
only the tip of the iceberg. Technical capability extends far below the surface
through cognitive automation spanning administrative, financial, and
professional services (11.7%, approx \$1.2 trillion). This exposure is fivefold
larger and geographically distributed across all states rather than confined to
coastal hubs. Traditional indicators such as GDP, income, and unemployment
explain less than 5% of this skills-based variation, underscoring why new
indices are needed to capture exposure in the AI economy. By simulating how
these capabilities may spread under scenarios, Iceberg enables policymakers and
business leaders to identify exposure hotspots, prioritize investments, and
test interventions before committing billions to implementation

</details>


### [53] [Scaling Cultural Resources for Improving Generative Models](https://arxiv.org/abs/2510.25167)
*Hayk Stepanyan,Aishwarya Verma,Andrew Zaldivar,Rutledge Chin Feman,Erin MacMurray van Liemt,Charu Kalia,Vinodkumar Prabhakaran,Sunipa Dev*

Main category: cs.CY

TL;DR: 构建了一个可重复、可扩展的多管齐下管道来收集和贡献具有文化显著性的多语言数据，以评估和改进生成式AI模型的跨文化能力。


<details>
  <summary>Details</summary>
Motivation: 生成模型在不同全球文化背景和语言中表现不佳，需要专门的数据资源来评估和改进模型的跨文化能力。

Method: 构建可重复、可扩展的多管齐下管道来收集和贡献具有文化显著性的多语言数据。

Result: 开发了系统化的数据收集方法，能够评估生成式AI模型的全球适用性状态。

Conclusion: 通过专门的文化显著多语言数据可以识别并改进生成式AI模型的跨文化差距。

Abstract: Generative models are known to have reduced performance in different global
cultural contexts and languages. While continual data updates have been
commonly conducted to improve overall model performance, bolstering and
evaluating this cross-cultural competence of generative AI models requires data
resources to be intentionally expanded to include global contexts and
languages. In this work, we construct a repeatable, scalable, multi-pronged
pipeline to collect and contribute culturally salient, multilingual data. We
posit that such data can assess the state of the global applicability of our
models and thus, in turn, help identify and improve upon cross-cultural gaps.

</details>


### [54] [The Open Source Resume: How Open Source Contributions Help Students Demonstrate Alignment with Employer Needs](https://arxiv.org/abs/2510.25180)
*Utsab Saha,Jeffrey D'Andria,Tyler Menezes*

Main category: cs.CY

TL;DR: 研究探讨雇主如何看待学生开源贡献，发现雇主重视非技术特质如主动性，学生了解雇主期望能提高参与开源项目的动机。


<details>
  <summary>Details</summary>
Motivation: 随着GenAI发展，雇主对计算机科学毕业生的期望提高，教育者希望通过开源贡献提升学生就业竞争力，但缺乏雇主对学生开源贡献看法的研究。

Method: 定性研究：访谈美国招聘经理，制定"招聘经理协议"；定量研究：基于期望价值理论调查650名美国公立大学本科生。

Result: 雇主期望许多传统CS课程难以教授的非技术特质，如主动性；学生了解雇主期望后，参与开源项目的动机显著提高。

Conclusion: 开源贡献有助于CS本科生就业，但需要持续多领域参与；教育者可通过分享雇主期望激励学生，但需进一步研究行为改变效果。

Abstract: Computer science educators are increasingly integrating open source
contributions into classes to prepare students for higher expectations due to
GenAI, and to improve employment outcomes in an increasingly competitive job
market. However, little is known about how employers view student open source
contributions. This paper addresses two research questions qualitatively: what
traits do employers desire for entry-level hires in 2025, and how can they be
demonstrated through open source contributions? It also tests quantitatively
the hypothesis that student knowledge of employers' expectations will improve
their motivation to work on open source projects. To answer our qualitative
questions, we conducted interviews with US hiring managers. We collaborated
with each interviewee to create a "hiring manager agreement," which listed
desirable traits and specific ways to demonstrate them through open source,
along with a promise to interview some students meeting the criteria. To
evaluate our quantitative hypothesis, we surveyed 650 undergraduates attending
public universities in the US using an instrument based on expectancy-value
theory. Hiring managers wanted many non-technical traits that are difficult to
teach in traditional CS classes, such as initiative. There were many
commonalities in how employers wanted to see these traits demonstrated in open
source contributions. Viewing hiring manager agreements improved student
motivation to contribute to open source projects. Our findings suggest that
open source contributions may help CS undergraduates get hired, but this
requires sustained engagement in multiple areas. Educators can motivate
students by sharing employer expectations, but further work is required to
determine if this changes their behavior.

</details>


### [55] [Human Resilience in the AI Era -- What Machines Can't Replace](https://arxiv.org/abs/2510.25218)
*Shaoshan Liu,Anina Schwarzenbach,Yiyu Shi*

Main category: cs.CY

TL;DR: 本文主张人类应对AI挑战的关键对策是韧性，从心理、社会和组织三个层面定义韧性，并提供了培养韧性的实用框架。


<details>
  <summary>Details</summary>
Motivation: AI正在替代任务、介入高风险决策并产生大量合成内容，这动摇了工作、身份认同和社会信任，因此需要找到有效的人类应对策略。

Method: 通过定义三个层面的韧性（心理、社会、组织），综合早期证据分析这些能力如何缓冲个体压力、减少职业倦怠并降低AI工作流程中的隐性失败。

Result: 研究表明韧性能力能够缓冲个体压力、通过社会支持减少职业倦怠，并通过团队规范和风险响应治理降低AI中介工作流程中的隐性失败。

Conclusion: 通过将AI辩论重新聚焦于可操作的人类韧性，本文为政策制定者、教育工作者和操作者提供了保护人类能动性和引导负责任AI采用的实用视角。

Abstract: AI is displacing tasks, mediating high-stakes decisions, and flooding
communication with synthetic content, unsettling work, identity, and social
trust. We argue that the decisive human countermeasure is resilience. We define
resilience across three layers: psychological, including emotion regulation,
meaning-making, cognitive flexibility; social, including trust, social capital,
coordinated response; organizational, including psychological safety, feedback
mechanisms, and graceful degradation. We synthesize early evidence that these
capacities buffer individual strain, reduce burnout through social support, and
lower silent failure in AI-mediated workflows through team norms and
risk-responsive governance. We also show that resilience can be cultivated
through training that complements rather than substitutes for structural
safeguards. By reframing the AI debate around actionable human resilience, this
article offers policymakers, educators, and operators a practical lens to
preserve human agency and steer responsible adoption.

</details>


### [56] [Tackling the Algorithmic Control Crisis -- the Technical, Legal, and Ethical Challenges of Research into Algorithmic Agents](https://arxiv.org/abs/2510.25337)
*B. Bodo,N. Helberger,K. Irion,F. Zuiderveen Borgesius,J. Moller,B. Van der Velde,N. Bol,B. van Es,C. de Vreese*

Main category: cs.CY

TL;DR: 本文探讨了研究算法推荐系统的方法论、伦理和法律挑战，提出了跟踪算法代理的研究方法，并讨论了不同监控方法的成本效益比较。


<details>
  <summary>Details</summary>
Motivation: 算法代理在我们的数字生活中无处不在，它们基于大规模监控构建的数字档案进行内容筛选、推荐和创作。研究这些算法代理面临方法论、伦理和后勤方面的挑战，需要开发合适的研究方法来理解它们对个人和社会的影响。

Method: 描述了一种研究算法推荐系统影响的方法，包括跟踪算法代理的行为，比较不同监控方法的成本和效益，并分享研究经验。

Result: 提出了解决算法研究实践、伦理和法律挑战的具体建议，强调了理解用户与算法代理互动方式的重要性。

Conclusion: 需要开发既符合伦理又合法的算法治理研究方法，同时考虑不同监控方法的相对优劣，以更好地理解算法对用户和社会的影响。

Abstract: Algorithmic agents permeate every instant of our online existence. Based on
our digital profiles built from the massive surveillance of our digital
existence, algorithmic agents rank search results, filter our emails, hide and
show news items on social networks feeds, try to guess what products we might
buy next for ourselves and for others, what movies we want to watch, and when
we might be pregnant. Algorithmic agents select, filter, and recommend
products, information, and people. Increasingly, algorithmic agents don't just
select from the range of human created alternatives, but also they create.
Burgeoning algorithmic agents are capable of providing us with content made
just for us, and engage with us through one-of-a-kind, personalized
interactions. Studying these algorithmic agents presents a host of
methodological, ethical, and logistical challenges. The objectives of our paper
are two-fold. The first aim is to describe one possible approach to researching
the individual and societal effects of algorithmic recommenders, and to share
our experiences with the academic community. The second is to contribute to a
more fundamental discussion about the ethical and legal issues of "tracking the
trackers", as well as the costs and trade-offs involved. Our paper will
contribute to the discussion on the relative merits, costs and benefits of
different approaches to ethically and legally sound research on algorithmic
governance. We will argue that besides shedding light on how users interact
with algorithmic agents, we also need to be able to understand how different
methods of monitoring our algorithmically controlled digital environments
compare to each other in terms of costs and benefits. We conclude our article
with a number of concrete suggestions for how to address the practical, ethical
and legal challenges of researching algorithms and their effects on users and
society.

</details>


### [57] [Tracking Walls, Take-It-Or-Leave-It Choices, the GDPR, and the ePrivacy Regulation](https://arxiv.org/abs/2510.25339)
*Frederik J. Zuiderveen Borgesius,Sanne Kruikemeier,Sophie C. Boerman,Natali Helberger*

Main category: cs.CY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: On the internet, we encounter take-it-or-leave-it choices regarding our
privacy on a daily basis. In Europe, online tracking for targeted advertising
generally requires the internet users' consent to be lawful. Some websites use
a tracking wall, a barrier that visitors can only pass if they consent to
tracking by third parties. When confronted with such a tracking wall, many
people click 'I agree' to tracking. A survey that we conducted shows that most
people find tracking walls unfair and unacceptable. We analyse under which
conditions the ePrivacy Directive and the General Data Protection Regulation
allow tracking walls. We provide a list of circumstances to assess when a
tracking wall makes consent invalid. We also explore how the EU lawmaker could
regulate tracking walls, for instance in the ePrivacy Regulation. It should be
seriously considered to ban tracking walls, at least in certain circumstances.

</details>


### [58] [Shifts in U.S. Social Media Use, 2020-2024: Decline, Fragmentation, and Enduring Polarization](https://arxiv.org/abs/2510.25417)
*Petter Törnberg*

Main category: cs.CY

TL;DR: 基于2020和2024年美国国家选举研究数据，分析美国社交媒体格局变化：整体使用率下降，平台碎片化，Facebook、YouTube、Twitter/X用户减少，TikTok和Reddit小幅增长；平台用户老龄化、教育程度提高且更多元化；政治倾向向共和党偏移但总体仍偏民主党，Twitter/X政治立场翻转最显著；政治发帖与情感极化密切相关，最党派化的用户最活跃。


<details>
  <summary>Details</summary>
Motivation: 追踪美国社交媒体格局在平台、人口统计和政治倾向方面的变化趋势，了解数字公共领域如何变得更加碎片化和极端化。

Method: 使用2020年和2024年美国国家选举研究（ANES）的全国代表性数据进行对比分析，考察社交媒体使用模式、人口特征和政治倾向的变化。

Result: 整体社交媒体使用率下降，年轻人和老年人弃用增多；Facebook、YouTube、Twitter/X市场份额减少，TikTok和Reddit小幅增长；平台用户老龄化、教育程度提高、更多元化；大多数平台政治倾向向共和党偏移但仍偏民主党，Twitter/X发帖从民主党向共和党翻转近50个百分点；政治发帖与情感极化高度相关。

Conclusion: 随着普通用户退出而极化党派用户保持活跃，在线公共领域变得更小、更尖锐、意识形态更极端，反映了数字公共领域的碎片化和极化趋势。

Abstract: Using nationally representative data from the 2020 and 2024 American National
Election Studies (ANES), this paper traces how the U.S. social media landscape
has shifted across platforms, demographics, and politics. Overall platform use
has declined, with the youngest and oldest Americans increasingly abstaining
from social media altogether. Facebook, YouTube, and Twitter/X have lost
ground, while TikTok and Reddit have grown modestly, reflecting a more
fragmented digital public sphere. Platform audiences have aged and become
slightly more educated and diverse. Politically, most platforms have moved
toward Republican users while remaining, on balance, Democratic-leaning.
Twitter/X has experienced the sharpest shift: posting has flipped nearly 50
percentage points from Democrats to Republicans. Across platforms, political
posting remains tightly linked to affective polarization, as the most partisan
users are also the most active. As casual users disengage and polarized
partisans remain vocal, the online public sphere grows smaller, sharper, and
more ideologically extreme.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [59] [SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving](https://arxiv.org/abs/2510.24949)
*Anil Yildiz,Sarah M. Thornton,Carl Hildebrandt,Sreeja Roy-Singh,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 提出SCOUT轻量级代理模型，通过知识蒸馏从智能体潜在传感器表示预测场景覆盖标签，无需持续使用大型视觉语言模型或人工标注，实现高效可扩展的场景覆盖评估。


<details>
  <summary>Details</summary>
Motivation: 现有场景覆盖评估方法依赖昂贵的人工标注或计算密集型大型视觉语言模型，在大规模部署中成本高、效率低，需要更实用的解决方案。

Method: 通过蒸馏过程训练轻量级代理模型SCOUT，学习近似LVLM生成的覆盖标签，利用预计算感知特征避免冗余计算，直接从智能体潜在传感器表示预测场景覆盖。

Result: 在真实自主导航场景数据集上评估，SCOUT在保持高精度的同时显著降低计算成本，为大规模覆盖分析提供有效实用替代方案。

Conclusion: SCOUT是自主系统中高效场景覆盖监督的重要进展，虽然性能依赖于LVLM生成训练标签的质量，但实现了成本效益和可扩展性的平衡。

Abstract: Assessing scenario coverage is crucial for evaluating the robustness of
autonomous agents, yet existing methods rely on expensive human annotations or
computationally intensive Large Vision-Language Models (LVLMs). These
approaches are impractical for large-scale deployment due to cost and
efficiency constraints. To address these shortcomings, we propose SCOUT
(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate
model designed to predict scenario coverage labels directly from an agent's
latent sensor representations. SCOUT is trained through a distillation process,
learning to approximate LVLM-generated coverage labels while eliminating the
need for continuous LVLM inference or human annotation. By leveraging
precomputed perception features, SCOUT avoids redundant computations and
enables fast, scalable scenario coverage estimation. We evaluate our method
across a large dataset of real-life autonomous navigation scenarios,
demonstrating that it maintains high accuracy while significantly reducing
computational cost. Our results show that SCOUT provides an effective and
practical alternative for large-scale coverage analysis. While its performance
depends on the quality of LVLM-generated training labels, SCOUT represents a
major step toward efficient scenario coverage oversight in autonomous systems.

</details>


### [60] [Smooth path planning with safety margins using Piece-Wise Bezier curves](https://arxiv.org/abs/2510.24972)
*Iancu Andrei,Marius Kloetzer,Cristian Mahulea,Catalin Dosoftei*

Main category: cs.RO

TL;DR: 提出了一种计算高效的二次规划方法，使用分段二次贝塞尔曲线为移动机器人生成平滑的C^1连续路径，在保证安全裕度的同时平衡轨迹平滑性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统分段线性路径规划方法在轨迹平滑性和鲁棒性方面存在不足，需要一种能在实时和嵌入式应用中平衡计算效率和路径质量的方法。

Method: 使用分段二次贝塞尔曲线，在结构化优化框架中显式纳入安全裕度，通过二次规划方法生成平滑路径。

Result: 与传统分段线性方法相比，轨迹偏差减小，鲁棒性增强，整体路径质量提高，在代表性场景中使用Pure-Pursuit控制器验证了有效性。

Conclusion: 该方法在安全导航方面具有实际有效性和可扩展性，特别适合实时和嵌入式应用。

Abstract: In this paper, we propose a computationally efficient quadratic programming
(QP) approach for generating smooth, $C^1$ continuous paths for mobile robots
using piece-wise quadratic Bezier (PWB) curves. Our method explicitly
incorporates safety margins within a structured optimization framework,
balancing trajectory smoothness and robustness with manageable numerical
complexity suitable for real-time and embedded applications. Comparative
simulations demonstrate clear advantages over traditional piece-wise linear
(PWL) path planning methods, showing reduced trajectory deviations, enhanced
robustness, and improved overall path quality. These benefits are validated
through simulations using a Pure-Pursuit controller in representative
scenarios, highlighting the practical effectiveness and scalability of our
approach for safe navigation.

</details>


### [61] [Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT](https://arxiv.org/abs/2510.24994)
*Matsive Ali,Blake Gassen,Sen Liu*

Main category: cs.RO

TL;DR: 提出了一种集成机器人FDM 3D打印系统，通过闭环热控制、6自由度机械臂和视觉系统实现智能原位缺陷检测与修正。


<details>
  <summary>Details</summary>
Motivation: 解决3D打印过程中实时质量保证的挑战，提高复杂轨迹打印的精度和可靠性。

Method: 使用ROS2协调的6自由度机械臂，配备IoT微控制器调节热端温度，通过OpenCV视觉系统检测层间缺陷，并自动重新挤出修正。

Result: 实验验证显示系统成功缓解了打印操作中的缺陷，能够在不中断打印过程的情况下修正表面异常。

Conclusion: 通过整合实时热调节、运动控制和智能缺陷检测与修正，建立了一个可扩展且自适应的机器人增材制造框架，适用于航空航天、生物医学和工业应用。

Abstract: This paper presents an integrated robotic fused deposition modeling additive
manufacturing system featuring closed-loop thermal control and intelligent
in-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D
camera. The robot arm end effector was modified to mount an E3D hotend
thermally regulated by an IoT microcontroller, enabling precise temperature
control through real-time feedback. Filament extrusion system was synchronized
with robotic motion, coordinated via ROS2, ensuring consistent deposition along
complex trajectories. A vision system based on OpenCV detects layer-wise
defects position, commanding autonomous re-extrusion at identified sites.
Experimental validation demonstrated successful defect mitigation in printing
operations. The integrated system effectively addresses challenges real-time
quality assurance. Inverse kinematics were used for motion planning, while
homography transformations corrected camera perspectives for accurate defect
localization. The intelligent system successfully mitigated surface anomalies
without interrupting the print process. By combining real-time thermal
regulation, motion control, and intelligent defect detection & correction, this
architecture establishes a scalable and adaptive robotic additive manufacturing
framework suitable for aerospace, biomedical, and industrial applications.

</details>


### [62] [Scalable predictive processing framework for multitask caregiving robots](https://arxiv.org/abs/2510.25053)
*Hayato Idei,Tamon Miyake,Tetsuya Ogata,Yuichi Yamashita*

Main category: cs.RO

TL;DR: 提出基于预测处理和自由能原理的分层多模态循环神经网络，能够直接处理高维视觉-本体感觉输入，在无需任务特定特征工程的情况下学习护理任务。


<details>
  <summary>Details</summary>
Motivation: 现有护理机器人系统多为任务特定且依赖手工预处理，缺乏泛化能力。受人类大脑分层预测处理理论的启发，旨在开发能够灵活适应多样化场景的自主护理机器人。

Method: 构建基于预测处理和自由能原理的分层多模态循环神经网络，直接整合超过30,000维的视觉-本体感觉输入，无需降维处理。

Result: 模型成功学习了刚性物体重新定位和柔性毛巾擦拭两个代表性护理任务，表现出分层潜在动态自组织、视觉退化下的鲁棒性以及多任务学习中的不对称干扰特性。

Conclusion: 预测处理作为一种通用且可扩展的计算原理，为实现鲁棒、灵活和自主的护理机器人提供了理论基础，同时也为理解人类大脑在不确定现实环境中实现灵活适应的能力提供了理论洞见。

Abstract: The rapid aging of societies is intensifying demand for autonomous care
robots; however, most existing systems are task-specific and rely on
handcrafted preprocessing, limiting their ability to generalize across diverse
scenarios. A prevailing theory in cognitive neuroscience proposes that the
human brain operates through hierarchical predictive processing, which
underlies flexible cognition and behavior by integrating multimodal sensory
signals. Inspired by this principle, we introduce a hierarchical multimodal
recurrent neural network grounded in predictive processing under the
free-energy principle, capable of directly integrating over 30,000-dimensional
visuo-proprioceptive inputs without dimensionality reduction. The model was
able to learn two representative caregiving tasks, rigid-body repositioning and
flexible-towel wiping, without task-specific feature engineering. We
demonstrate three key properties: (i) self-organization of hierarchical latent
dynamics that regulate task transitions, capture variability in uncertainty,
and infer occluded states; (ii) robustness to degraded vision through
visuo-proprioceptive integration; and (iii) asymmetric interference in
multitask learning, where the more variable wiping task had little influence on
repositioning, whereas learning the repositioning task led to a modest
reduction in wiping performance, while the model maintained overall robustness.
Although the evaluation was limited to simulation, these results establish
predictive processing as a universal and scalable computational principle,
pointing toward robust, flexible, and autonomous caregiving robots while
offering theoretical insight into the human brain's ability to achieve flexible
adaptation in uncertain real-world environments.

</details>


### [63] [Non-Invasive Calibration Of A Stewart Platform By Photogrammetry](https://arxiv.org/abs/2510.25072)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 提出了一种基于Denavit-Hartenberg约定的前向运动学标定方法，使用摄影测量技术对Stewart平台进行非侵入式标定，通过最小二乘法估计误差补偿策略，显著提高了平台位姿精度。


<details>
  <summary>Details</summary>
Motivation: Stewart平台的前向运动学校准具有挑战性，因为前向运动学通常会产生多个可行和不可行的解，且六个执行器路径之间的复杂运动学关系使得难以建立直接高效的校准方法。

Method: 使用Denavit-Hartenberg约定开发新的前向运动学校准方法，采用摄影测量技术（高分辨率数码相机和现成软件）捕获移动平台中心的位姿，通过最小二乘法估计误差并采用三种补偿策略。

Result: 三种补偿方法都显示出平台位姿精度的显著提升，表明还有进一步改进的空间。

Conclusion: 基于摄影测量的非侵入式标定方法有效提高了Stewart平台的精度，该方法不需要附加设备或修改硬件，具有实用价值。

Abstract: Accurate calibration of a Stewart platform is important for their precise and
efficient operation. However, the calibration of these platforms using forward
kinematics is a challenge for researchers because forward kinematics normally
generates multiple feasible and unfeasible solutions for any pose of the moving
platform. The complex kinematic relations among the six actuator paths
connecting the fixed base to the moving platform further compound the
difficulty in establishing a straightforward and efficient calibration method.
The authors developed a new forward kinematics-based calibration method using
Denavit-Hartenberg convention and used the Stewart platform Tiger 66.1
developed in their lab for experimenting with the photogrammetry-based
calibration strategies described in this paper. This system became operational
upon completion of construction, marking its inaugural use. The authors used
their calibration model for estimating the errors in the system and adopted
three compensation options or strategies as per Least Square method to improve
the accuracy of the system. These strategies leveraged a high-resolution
digital camera and off-the-shelf software to capture the poses of the moving
platform's center. This process is non-invasive and does not need any
additional equipment to be attached to the hexapod or any alteration of the
hexapod hardware. This photogrammetry-based calibration process involves
multiple high-resolution images from different angles to measure the position
and orientation of the platform center in the three-dimensional space. The
Target poses and Actual poses are then compared, and the error compensations
are estimated using the Least-Squared methods to calculate the Predicted poses.
Results from each of the three compensation approaches demonstrated noticeable
enhancements in platform pose accuracies, suggesting room for further
improvements.

</details>


### [64] [Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration](https://arxiv.org/abs/2510.25086)
*Guibin Sun,Jinhu Lü,Kexin Liu,Zhenqian Wang,Guanrong Chen*

Main category: cs.RO

TL;DR: 本文综述了机器人群体无分配协作的最新进展，重点研究形状形成问题，介绍了均值漂移探索策略及其在智能仓储、区域探索和货物运输等工业场景中的应用。


<details>
  <summary>Details</summary>
Motivation: 自然界中群体行为启发了高效协作的机器人群体设计，但传统的基于分配的方法在效率和鲁棒性方面存在根本性限制，无法扩展到大规模群体变体。

Method: 采用均值漂移探索策略作为关键理论组件，实现无分配协作，特别关注形状形成问题。

Result: 均值漂移探索策略将大规模群体的协作效率提高了数十倍，且随着群体规模的增加，效率提升更加显著。

Conclusion: 无分配协作方法为机器人群体提供了更高效和鲁棒的解决方案，均值漂移探索策略在多个工业应用场景中展现出巨大潜力。

Abstract: Swarms evolving from collective behaviors among multiple individuals are
commonly seen in nature, which enables biological systems to exhibit more
efficient and robust collaboration. Creating similar swarm intelligence in
engineered robots poses challenges to the design of collaborative algorithms
that can be programmed at large scales. The assignment-based method has played
an eminent role for a very long time in solving collaboration problems of robot
swarms. However, it faces fundamental limitations in terms of efficiency and
robustness due to its unscalability to swarm variants. This article presents a
tutorial review on recent advances in assignment-free collaboration of robot
swarms, focusing on the problem of shape formation. A key theoretical component
is the recently developed \emph{mean-shift exploration} strategy, which
improves the collaboration efficiency of large-scale swarms by dozens of times.
Further, the efficiency improvement is more significant as the swarm scale
increases. Finally, this article discusses three important applications of the
mean-shift exploration strategy, including precise shape formation, area
coverage formation, and maneuvering formation, as well as their corresponding
industrial scenarios in smart warehousing, area exploration, and cargo
transportation.

</details>


### [65] [NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies](https://arxiv.org/abs/2510.25122)
*Jiahong Chen,Jing Wang,Long Chen,Chuwei Cai,Jinghui Lu*

Main category: cs.RO

TL;DR: NanoVLA是一个轻量级视觉-语言-动作模型家族，专为资源受限的边缘设备设计，通过视觉语言解耦、长短动作分块和动态路由等创新技术，在保持高性能的同时显著降低计算需求和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在资源受限的边缘设备（如移动机器人、Jetson Orin Nano）上部署困难，因为计算需求高，而实际应用中功耗、延迟和计算资源是关键限制因素。

Method: 1) 视觉语言解耦：将早期视觉语言融合改为后期融合，实现缓存和降低推理开销；2) 长短动作分块：确保平滑连贯的多步规划，同时保持实时响应性；3) 动态路由：根据任务复杂度自适应分配轻量级或重量级骨干网络，优化推理效率。

Result: 在多个基准测试和实际部署中，NanoVLA在边缘设备上实现比现有最先进VLA模型快52倍的推理速度，参数减少98%，同时保持或超越任务准确性和泛化能力。

Conclusion: NanoVLA通过创新的架构设计，实现了在资源受限硬件上实用、高精度的机器人操作，消融研究证实解耦策略保持了跨任务可迁移性，路由模块增强了成本-性能权衡。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
manipulation by integrating vision-language models (VLMs), and action decoders
into a unified architecture. However, their deployment on resource-constrained
edge devices, such as mobile robots or embedded systems (e.g., Jetson Orin
Nano), remains challenging due to high computational demands, especially in
real-world scenarios where power, latency, and computational resources are
critical. To close this gap, we introduce Nano-scale Vision-Language Action
(NanoVLA), a family of lightweight VLA architectures that achieve high
performance with minimal resources. Our core innovations include: (1)
vision-language decoupling that moves conventional early vision and language
inputs fusion in VLM to late stage, achieving better performance while enabling
caching and reduce inference overhead and latency; (2) long-short action
chunking to ensure smooth, coherent multi-step planning without sacrificing
real-time responsiveness; (3) dynamic routing that adaptively assigns
lightweight or heavy backbones based on task complexity, further optimizing
inference efficiency. Experimental results on several benchmarks, as well as
real-world deployments, demonstrate that NanoVLA achieves up to 52x faster
inference on edge devices compared to previous state-of-the-art VLA models,
with 98% less parameters while maintaining or surpassing their task accuracy
and generalization. Ablation studies confirm that our decoupling strategy
preserves cross-task transferability, and the routing module enhances
cost-performance trade-offs, enabling practical, high-precision robotic
manipulation on resource-constrained hardware.

</details>


### [66] [Learning Spatial-Aware Manipulation Ordering](https://arxiv.org/abs/2510.25138)
*Yuxiang Yan,Zhiyuan Zhou,Xin Gao,Guanghao Li,Shenglin Li,Jiaqi Chen,Qunyan Pu,Jian Pu*

Main category: cs.RO

TL;DR: OrderMind是一个统一的空间感知操作排序框架，通过直接学习基于空间上下文的对象操作优先级来解决杂乱环境中的操作顺序问题。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中操作时，对象间的空间依赖关系会导致不当的操作顺序引发碰撞或访问阻塞，现有方法往往忽视这些空间关系，限制了灵活性和可扩展性。

Method: 构建空间图使用k近邻聚合局部布局的几何信息，编码对象-对象和对象-操作器交互，结合空间上下文编码器和时间优先级结构化模块，并通过空间先验标注方法生成监督信号。

Result: 在包含163,222个样本的操作排序基准测试中，OrderMind在仿真和真实环境中均显著优于现有方法，实现了有效且高效的操作。

Conclusion: OrderMind通过空间感知的优先级学习，能够在杂乱场景中实现鲁棒的操作，解决了空间依赖关系带来的操作顺序挑战。

Abstract: Manipulation in cluttered environments is challenging due to spatial
dependencies among objects, where an improper manipulation order can cause
collisions or blocked access. Existing approaches often overlook these spatial
relationships, limiting their flexibility and scalability. To address these
limitations, we propose OrderMind, a unified spatial-aware manipulation
ordering framework that directly learns object manipulation priorities based on
spatial context. Our architecture integrates a spatial context encoder with a
temporal priority structuring module. We construct a spatial graph using
k-Nearest Neighbors to aggregate geometric information from the local layout
and encode both object-object and object-manipulator interactions to support
accurate manipulation ordering in real-time. To generate physically and
semantically plausible supervision signals, we introduce a spatial prior
labeling method that guides a vision-language model to produce reasonable
manipulation orders for distillation. We evaluate OrderMind on our Manipulation
Ordering Benchmark, comprising 163,222 samples of varying difficulty. Extensive
experiments in both simulation and real-world environments demonstrate that our
method significantly outperforms prior approaches in effectiveness and
efficiency, enabling robust manipulation in cluttered scenes.

</details>


### [67] [SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning](https://arxiv.org/abs/2510.25191)
*Hongyu Song,Rishabh Dev Yadav,Cheng Guo,Wei Pan*

Main category: cs.RO

TL;DR: SoraNav是一个自适应无人机导航框架，结合零样本视觉语言模型推理与几何感知决策，在2.5D和3D场景中显著提升导航成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航方法主要针对地面机器人，难以推广到需要完整3D空间推理的空中任务，而大型视觉语言模型缺乏空间基础，无法直接用于导航。

Method: 将几何先验整合到图像标注中约束VLM动作空间，采用混合切换策略结合VLM推理和基于几何的探索，使用PX4软硬件平台进行可重复评估。

Result: 在2.5D场景中，成功率提升25.7%，路径长度加权成功率提升17%；在3D场景中，成功率提升29.5%，路径长度加权成功率提升18.5%。

Conclusion: SoraNav框架有效解决了无人机在复杂3D环境中的语言驱动导航问题，显著提升了导航性能。

Abstract: Interpreting visual observations and natural language instructions for
complex task execution remains a key challenge in robotics and AI. Despite
recent advances, language-driven navigation is still difficult, particularly
for UAVs in small-scale 3D environments. Existing Vision-Language Navigation
(VLN) approaches are mostly designed for ground robots and struggle to
generalize to aerial tasks that require full 3D spatial reasoning. The
emergence of large Vision-Language Models (VLMs), such as GPT and Claude,
enables zero-shot semantic reasoning from visual and textual inputs. However,
these models lack spatial grounding and are not directly applicable to
navigation. To address these limitations, SoraNav is introduced, an adaptive
UAV navigation framework that integrates zero-shot VLM reasoning with
geometry-aware decision-making. Geometric priors are incorporated into image
annotations to constrain the VLM action space and improve decision quality. A
hybrid switching strategy leverages navigation history to alternate between VLM
reasoning and geometry-based exploration, mitigating dead-ends and redundant
revisits. A PX4-based hardware-software platform, comprising both a digital
twin and a physical micro-UAV, enables reproducible evaluation. Experimental
results show that in 2.5D scenarios, our method improves Success Rate (SR) by
25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it
improves SR by 29.5% and SPL by 18.5% relative to the baseline.

</details>


### [68] [RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis](https://arxiv.org/abs/2510.25211)
*Amith Khandakar,David Michelson,Shaikh Golam Rabbani,Fariya Bintay Shafi,Md. Faysal Ahamed,Khondokar Radwanur Rahman,Md Abidur Rahman,Md. Fahmidun Nabi,Mohamed Arselene Ayari,Khaled Khan,Ponnuthurai Nagaratnam Suganthan*

Main category: cs.RO

TL;DR: 提出一个结合GPS、加速度计、陀螺仪等多种传感器数据与GIS、天气和视频信息的综合道路质量监测数据集，旨在促进智能交通系统研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量标准化数据集，道路质量监测研究进展缓慢。智能手机内置传感器提供了一种成本效益高且简单的方法来评估道路质量。

Method: 开发移动应用程序收集GPS、加速度计、陀螺仪、磁力计、重力传感器和方向传感器数据，并整合GIS数据、天气信息和道路状况视频。

Result: 创建了一个综合数据集，包含车辆速度、加速度、旋转速率、磁场强度等传感器数据，以及GIS、天气和视频提供的视觉和空间上下文信息。

Conclusion: 该数据集将公开可用，为交通管理、基础设施发展、道路安全和城市规划提供数据支持，促进智能交通系统的进一步研究和创新。

Abstract: It's important to monitor road issues such as bumps and potholes to enhance
safety and improve road conditions. Smartphones are equipped with various
built-in sensors that offer a cost-effective and straightforward way to assess
road quality. However, progress in this area has been slow due to the lack of
high-quality, standardized datasets. This paper discusses a new dataset created
by a mobile app that collects sensor data from devices like GPS,
accelerometers, gyroscopes, magnetometers, gravity sensors, and orientation
sensors. This dataset is one of the few that integrates Geographic Information
System (GIS) data with weather information and video footage of road
conditions, providing a comprehensive understanding of road issues with
geographic context. The dataset allows for a clearer analysis of road
conditions by compiling essential data, including vehicle speed, acceleration,
rotation rates, and magnetic field intensity, along with the visual and spatial
context provided by GIS, weather, and video data. Its goal is to provide
funding for initiatives that enhance traffic management, infrastructure
development, road safety, and urban planning. Additionally, the dataset will be
publicly accessible to promote further research and innovation in smart
transportation systems.

</details>


### [69] [Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery](https://arxiv.org/abs/2510.25233)
*Jee Won Lee,Hansol Lim,Sooyeun Yang,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: 提出了一种混合视觉跟踪框架，结合全局模板匹配、深度特征LK算法和残差回归器，在严重遮挡下仍能保持亚像素级跟踪精度，为机器人视觉伺服控制提供稳定输入。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉跟踪方法在遮挡情况下易失效的问题，同时避免深度学习方法的计算负担，为机器人视觉伺服控制提供稳定可靠的跟踪解决方案。

Method: 采用多阶段混合方法：1）全局模板匹配约束位姿搜索区域；2）基于VGG早期层的深度特征LK模块进行亚像素级对齐；3）轻量级残差回归器校正局部错位；4）当视觉置信度低时，GRU预测器从运动历史中推断位姿更新。

Result: 在手持视频序列上测试，即使面对90%遮挡，系统仍能维持低于2像素的跟踪误差，为30Hz图像伺服控制提供直接控制信号。

Conclusion: 该混合框架在遮挡情况下表现出优异的鲁棒性和低延迟精度，满足了实际机器人视觉应用对可靠性的要求。

Abstract: Vision-based control systems, such as image-based visual servoing (IBVS),
have been extensively explored for precise robot manipulation. A persistent
challenge, however, is maintaining robust target tracking under partial or full
occlusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking
but are fragile to occlusion and drift, while deep learning-based approaches
often require continuous visibility and intensive computation. To address these
gaps, we propose a hybrid visual tracking framework that bridges advanced
perception with real-time servo control. First, a fast global template matcher
constrains the pose search region; next, a deep-feature Lucas-Kanade module
operating on early VGG layers refines alignment to sub-pixel accuracy (<2px);
then, a lightweight residual regressor corrects local misalignments caused by
texture degradation or partial occlusion. When visual confidence falls below a
threshold, a GRU-based predictor seamlessly extrapolates pose updates from
recent motion history. Crucially, the pipeline's final outputs-translation,
rotation, and scale deltas-are packaged as direct control signals for 30Hz
image-based servo loops. Evaluated on handheld video sequences with up to 90%
occlusion, our system sustains under 2px tracking error, demonstrating the
robustness and low-latency precision essential for reliable real-world robot
vision applications.

</details>


### [70] [One-shot Humanoid Whole-body Motion Learning](https://arxiv.org/abs/2510.25241)
*Hao Huang,Geeta Chandra Raju Bethala,Shuaihang Yuan,Congcong Wen,Anthony Tzes,Yi Fang*

Main category: cs.RO

TL;DR: 提出一种仅需单个非行走动作样本和现成行走动作就能训练人形机器人运动策略的新方法，通过最优传输和插值生成中间姿态，在CMU MoCap数据集上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要每个动作类别的多个训练样本，导致高质量人体运动数据集的收集既费力又昂贵，需要更高效的数据利用方法。

Method: 利用保序最优传输计算行走和非行走序列间的距离，沿测地线插值生成新的中间姿态骨架，优化为无碰撞配置并重定向到人形机器人，最后通过强化学习在模拟环境中训练策略。

Result: 在CMU MoCap数据集上的实验评估表明，该方法始终优于基线方法，在所有指标上都取得了更优的性能。

Conclusion: 该方法能够仅用单个非行走动作样本和现成行走动作有效训练人形机器人运动策略，为数据高效的人形运动学习提供了可行方案。

Abstract: Whole-body humanoid motion represents a cornerstone challenge in robotics,
integrating balance, coordination, and adaptability to enable human-like
behaviors. However, existing methods typically require multiple training
samples per motion category, rendering the collection of high-quality human
motion datasets both labor-intensive and costly. To address this, we propose a
novel approach that trains effective humanoid motion policies using only a
single non-walking target motion sample alongside readily available walking
motions. The core idea lies in leveraging order-preserving optimal transport to
compute distances between walking and non-walking sequences, followed by
interpolation along geodesics to generate new intermediate pose skeletons,
which are then optimized for collision-free configurations and retargeted to
the humanoid before integration into a simulated environment for policy
training via reinforcement learning. Experimental evaluations on the CMU MoCap
dataset demonstrate that our method consistently outperforms baselines,
achieving superior performance across metrics. Code will be released upon
acceptance.

</details>


### [71] [Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths](https://arxiv.org/abs/2510.25255)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文研究机器人搬运装有液体的杯子时的轨迹规划问题，目标是沿指定路径在最短时间内运输，同时最小化液体晃动避免溢出。


<details>
  <summary>Details</summary>
Motivation: 处理松散放置物体对机器人来说是困难任务，特别是当物体是装有液体的容器时更加复杂，因为需要考虑液体晃动动力学。

Method: 将液体晃动动力学纳入动态模型，在最优控制问题中采用直接多重打靶法求解优化问题。

Result: 开发了包含液体晃动动力学的优化控制方法，能够有效规划机器人搬运液体容器的轨迹。

Conclusion: 通过将液体晃动动力学整合到最优控制问题中，可以实现机器人安全高效地运输液体容器，同时最小化溢出风险。

Abstract: Handling loosely placed objects with robotic manipulators is a difficult task
from the point of view of trajectory planning and control. This becomes even
more challenging when the object to be handled is a container filled with
liquid. This paper addresses the task of transporting a liquid-filled cup
placed on a tray along a prescribed path in shortest time. The objective is to
minimize swapping, thus avoiding spillage of the fluid. To this end, the
sloshing dynamics is incorporated into the dynamic model used within the
optimal control problem formulation. The optimization problem is solved using a
direct multiple shooting approach.

</details>


### [72] [SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation](https://arxiv.org/abs/2510.25268)
*Wang zhi,Yuyan Liu,Liu Liu,Li Zhang,Ruixuan Lu,Dan Guo*

Main category: cs.RO

TL;DR: 提出了SynHLMA框架，用于生成带语言指令的铰接物体手部抓取序列，支持HAOI生成、预测和插值三种任务。


<details>
  <summary>Details</summary>
Motivation: 铰接物体手部交互需要同时考虑物体功能性和长期操作序列，现有方法难以处理物体变形过程中的动态抓取需求。

Method: 使用离散HAOI表示建模手部交互帧，结合语言嵌入，通过HAOI操作语言模型在共享表示空间中对齐抓取过程和语言描述，采用关节感知损失确保抓取跟随铰接关节的动态变化。

Result: 在HAOI-lang数据集上评估，相比现有方法展现出优越的手部抓取序列生成性能，并展示了机器人抓取应用。

Conclusion: SynHLMA框架能够有效生成铰接物体的手部操作序列，为具身AI和VR/AR应用提供了实用的解决方案。

Abstract: Generating hand grasps with language instructions is a widely studied topic
that benefits from embodied AI and VR/AR applications. While transferring into
hand articulatied object interaction (HAOI), the hand grasps synthesis requires
not only object functionality but also long-term manipulation sequence along
the object deformation. This paper proposes a novel HAOI sequence generation
framework SynHLMA, to synthesize hand language manipulation for articulated
objects. Given a complete point cloud of an articulated object, we utilize a
discrete HAOI representation to model each hand object interaction frame. Along
with the natural language embeddings, the representations are trained by an
HAOI manipulation language model to align the grasping process with its
language description in a shared representation space. A joint-aware loss is
employed to ensure hand grasps follow the dynamic variations of articulated
object joints. In this way, our SynHLMA achieves three typical hand
manipulation tasks for articulated objects of HAOI generation, HAOI prediction
and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and
experimental results demonstrate the superior hand grasp sequence generation
performance comparing with state-of-the-art. We also show a robotics grasp
application that enables dexterous grasps execution from imitation learning
using the manipulation sequence provided by our SynHLMA. Our codes and datasets
will be made publicly available.

</details>


### [73] [Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance](https://arxiv.org/abs/2510.25280)
*Yusuke Tsunoda,Seiya Yamamoto,Kazuki Ito,Runze Xiao,Keisuke Naniwa,Koichi Osuka*

Main category: cs.RO

TL;DR: 开发了一种能够在陆地和水域环境中使用统一控制方案导航的蜈蚣型移动机器人，通过巧妙设计腿部结构实现在不同环境下的高效运动。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂地形中具有高机动性，但为每个环境设计特定步态和准确切换控制器具有挑战性。本研究旨在开发一种能够在陆地和水域环境中使用简单统一控制方案导航的机器人。

Method: 基于隐式-显式控制理念，设计具有柔性关节和左右腿的蜈蚣型机器人结构，重点关注与环境广泛接触的腿部结构。开发了三种不同的腿部结构，并以腿部滑动率和执行器能耗为评价指标评估运动性能。

Result: 实验结果表明，存在一种合适的腿部结构能够在相同控制下实现在陆地和水域环境中的导航。

Conclusion: 通过巧妙设计腿部结构，可以实现多足机器人在不同环境中使用统一控制方案进行有效导航，简化了复杂环境下的控制策略。

Abstract: Multi-legged mobile robots possess high mobility performance in rough terrain
environments, stemming from their high postural stability, joint flexibility,
and the redundancy provided by multiple legs. In prior research on navigating
between different environments such as land and water, the primary strategy
employed involves switching to a controller that generates an appropriate gait
for the new environment upon entering it. However, designing appropriate gaits
for each complex and diverse environment and accurately determining controller
switching for each environment is challenging. Therefore, this research
develops a centipede-type mobile robot that navigates both aquatic and
terrestrial environments with a simple, unified control scheme, based on the
implicit-explicit control philosophy and by ingeniously designing the robot's
body structure. In this research, we developed the robot featuring flexible
joints and left and right legs on each body segment and focused on the leg
structure which has extensive contact with the environment. This paper
evaluates the locomotion performance on land and water using the three
developed leg structures, using the robot's leg slip rate and actuator energy
consumption as evaluation metrics. The experimental results confirmed the
existence of an appropriate leg structure capable of navigating both aquatic
and terrestrial environments under identical control.

</details>


### [74] [An approach for combining transparency and motion assistance of a lower body exoskeleton](https://arxiv.org/abs/2510.25335)
*Jakob Ziegler,Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种结合透明模式和运动辅助模式的下半身外骨骼步态辅助方法，利用齿轮间隙实现透明模式，通过自适应振荡器学习周期性运动信号来提供辅助扭矩。


<details>
  <summary>Details</summary>
Motivation: 结合透明模式和运动辅助两种概念，在用户自由运动时最小化感知交互力，在行走时提供额外的扭矩引导腿部运动。

Method: 利用驱动单元的齿轮间隙实现透明模式，使用自适应振荡器学习周期性运动信号，在行走时叠加辅助模式施加额外扭矩。

Result: 初步实验显示出有希望的结果。

Conclusion: 该方法成功结合了透明性和运动辅助功能，为下半身外骨骼步态辅助提供了有效解决方案。

Abstract: In this paper, an approach for gait assistance with a lower body exoskeleton
is described. Two concepts, transparency and motion assistance, are combined.
The transparent mode, where the system is following the user's free motion with
a minimum of perceived interaction forces, is realized by exploiting the gear
backlash of the actuation units. During walking a superimposed assistance mode
applies an additional torque guiding the legs to their estimated future
position. The concept of adaptive oscillators is utilized to learn the
quasi-periodic signals typical for locomotion. First experiments showed
promising results.

</details>


### [75] [Geometric Robot Calibration Using a Calibration Plate](https://arxiv.org/abs/2510.25338)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种使用校准板进行几何机器人校准的新方法，通过板上已知距离的测量点来确定系统误差参数，相比传统方法更经济、坚固且便携。


<details>
  <summary>Details</summary>
Motivation: 传统机器人校准方法如激光跟踪仪或运动捕捉系统成本高、设备笨重，需要更经济、机械坚固且易于运输的替代方案。

Method: 使用具有精确已知距离测量点的校准板，通过板上两点间的相对测量确定系统误差参数，采用最小二乘法和约束优化问题进行参数识别。

Result: 实验验证了该方法的可行性，获得了与激光跟踪仪校准相一致的令人满意的结果。

Conclusion: 该方法为机器人几何校准提供了一种经济、坚固且便携的替代方案，虽然基于龙门机器开发，但适用于其他类型机器人。

Abstract: In this paper a new method for geometric robot calibration is introduced,
which uses a calibration plate with precisely known distances between its
measuring points. The relative measurement between two points on the
calibration plate is used to determine predefined error parameters of the
system. In comparison to conventional measurement methods, like laser tracker
or motion capture systems, the calibration plate provides a more mechanically
robust and cheaper alternative, which is furthermore easier to transport due to
its small size. The calibration method, the plate design, the mathematical
description of the error system as well as the identification of the parameters
are described in detail. For identifying the error parameters, the least
squares method and a constrained optimization problem are used. The
functionality of this method was demonstrated in experiments that led to
promising results, correlated with one of a laser tracker calibration. The
modeling and identification of the error parameters is done for a gantry
machine, but is not restricted to that type of robot.

</details>


### [76] [Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods](https://arxiv.org/abs/2510.25386)
*Kumar Manas,Mert Keser,Alois Knoll*

Main category: cs.RO

TL;DR: 本文综述了将法律和逻辑规范整合到自动驾驶系统感知、预测和规划模块中的方法，分析了确保监管合规性和可解释性的技术，并提出了分类法来系统化现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要在动态不确定的驾驶环境中确保监管合规性和决策可解释性，当前方法在感知可靠性、法律合规性和决策合理性方面面临挑战。

Method: 采用系统综述方法，引入基于理论基础、架构实现和验证策略的分类法，重点关注处理感知不确定性和整合明确法律规范的方法。

Result: 综述了神经符号集成感知方法、逻辑驱动规则表示和规范感知预测策略，这些方法有助于实现透明和可问责的自动驾驶操作。

Conclusion: 指出了关键开放问题和实际权衡，为未来开发法律合规的自动驾驶系统提供了工程、逻辑和法律等多学科见解。

Abstract: This survey provides an analysis of current methodologies integrating legal
and logical specifications into the perception, prediction, and planning
modules of automated driving systems. We systematically explore techniques
ranging from logic-based frameworks to computational legal reasoning
approaches, emphasizing their capability to ensure regulatory compliance and
interpretability in dynamic and uncertain driving environments. A central
finding is that significant challenges arise at the intersection of perceptual
reliability, legal compliance, and decision-making justifiability. To
systematically analyze these challenges, we introduce a taxonomy categorizing
existing approaches by their theoretical foundations, architectural
implementations, and validation strategies. We particularly focus on methods
that address perceptual uncertainty and incorporate explicit legal norms,
facilitating decisions that are both technically robust and legally defensible.
The review covers neural-symbolic integration methods for perception,
logic-driven rule representation, and norm-aware prediction strategies, all
contributing toward transparent and accountable autonomous vehicle operation.
We highlight critical open questions and practical trade-offs that must be
addressed, offering multidisciplinary insights from engineering, logic, and law
to guide future developments in legally compliant autonomous driving systems.

</details>


### [77] [Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning](https://arxiv.org/abs/2510.25405)
*Kei Ikemura,Yifei Dong,David Blanco-Mulero,Alberta Longhini,Li Chen,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的强化学习方法，通过应力惩罚奖励和课程学习策略，实现对易碎物体的温和操作，在模拟和真实环境中均能有效减少36.5%的应力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖精确物体模型或专用传感器，增加了复杂性且缺乏泛化能力，需要解决易碎物体操作中避免损伤的问题。

Method: 使用视觉强化学习，结合应力惩罚奖励机制、离线演示和从刚性代理到可变形物体的课程学习策略。

Result: 在模拟和真实环境中验证，学习到的策略能零样本迁移到现实世界，成功完成豆腐拾取和推动等任务，相比普通RL策略减少36.5%的应力。

Conclusion: 该方法能学习到损伤感知的温和操作行为，在实现任务目标的同时显著降低对易碎物体的应力，展示了模拟到现实的零样本迁移能力。

Abstract: Robotic manipulation of deformable and fragile objects presents significant
challenges, as excessive stress can lead to irreversible damage to the object.
While existing solutions rely on accurate object models or specialized sensors
and grippers, this adds complexity and often lacks generalization. To address
this problem, we present a vision-based reinforcement learning approach that
incorporates a stress-penalized reward to discourage damage to the object
explicitly. In addition, to bootstrap learning, we incorporate offline
demonstrations as well as a designed curriculum progressing from rigid proxies
to deformables. We evaluate the proposed method in both simulated and
real-world scenarios, showing that the policy learned in simulation can be
transferred to the real world in a zero-shot manner, performing tasks such as
picking up and pushing tofu. Our results show that the learned policies exhibit
a damage-aware, gentle manipulation behavior, demonstrating their effectiveness
by decreasing the stress applied to fragile objects by 36.5% while achieving
the task goals, compared to vanilla RL policies.

</details>


### [78] [Solving the Right Problem with Multi-Robot Formations](https://arxiv.org/abs/2510.25422)
*Chaz Cornwall,Jeremy P. Bos*

Main category: cs.RO

TL;DR: 提出一种编队规划器，通过两步优化问题来减少编队形状与原始成本函数之间的不匹配，使用代理成本函数来近似非线性不可微成本，并通过非合作编队控制器实现期望的相对位置。


<details>
  <summary>Details</summary>
Motivation: 传统编队控制将复杂成本函数简化为固定形状，但当环境信息变化时，静态形状无法最小化原始保护成本，导致编队形状与成本函数之间存在不匹配。

Method: 两步优化：首先用加权代理成本函数估计非线性不可微成本，然后最小化加权代理成本函数得到期望相对位置，最后使用基于李雅普诺夫直接法的非合作编队控制器实现位置。

Result: 仿真显示编队规划器可将单一成本降低75%以上，同时最小化多个成本函数时，使用自适应权重的编队规划器可降低成本20-40%。

Conclusion: 编队规划通过最小化近似原始成本函数的代理成本函数，而不是依赖形状抽象，提供了更好的性能表现。

Abstract: Formation control simplifies minimizing multi-robot cost functions by
encoding a cost function as a shape the robots maintain. However, by reducing
complex cost functions to formations, discrepancies arise between maintaining
the shape and minimizing the original cost function. For example, a Diamond or
Box formation shape is often used for protecting all members of the formation.
When more information about the surrounding environment becomes available, a
static shape often no longer minimizes the original protection cost. We propose
a formation planner to reduce mismatch between a formation and the cost
function while still leveraging efficient formation controllers. Our formation
planner is a two-step optimization problem that identifies desired relative
robot positions. We first solve a constrained problem to estimate non-linear
and non-differentiable costs with a weighted sum of surrogate cost functions.
We theoretically analyze this problem and identify situations where weights do
not need to be updated. The weighted, surrogate cost function is then minimized
using relative positions between robots. The desired relative positions are
realized using a non-cooperative formation controller derived from Lyapunov's
direct approach. We then demonstrate the efficacy of this approach for
military-like costs such as protection and obstacle avoidance. In simulations,
we show a formation planner can reduce a single cost by over 75%. When
minimizing a variety of cost functions simultaneously, using a formation
planner with adaptive weights can reduce the cost by 20-40%. Formation planning
provides better performance by minimizing a surrogate cost function that
closely approximates the original cost function instead of relying on a shape
abstraction.

</details>


### [79] [Combining Moving Mass Actuators and Manoeuvring Models for Underwater Vehicles: A Lagrangian Approach](https://arxiv.org/abs/2510.25479)
*Alexander B. Rambech,Ivar B. Saksvik,Vahid Hassani*

Main category: cs.RO

TL;DR: 提出了水下航行器内部移动质量作动器的牛顿-欧拉运动方程，将移动质量动力学作为Fossen操纵模型的扩展，并在仿真中验证了与传统哈密顿方法的对比。


<details>
  <summary>Details</summary>
Motivation: 为水下航行器内部移动质量作动器建立更直观的牛顿-欧拉运动方程，扩展传统操纵模型以包含移动质量的影响。

Method: 基于牛顿-欧拉公式推导运动方程，从基尔霍夫方程推导科里奥利-向心效应，使用基本原理推导流体静力学，将移动质量影响描述为附加运动学方程和耦合刚体动力学的一部分。

Result: 提出的牛顿-欧拉模型通过仿真验证，并与传统的哈密顿内部移动质量作动器公式进行了比较。

Conclusion: 成功建立了水下航行器内部移动质量作动器的牛顿-欧拉运动方程，验证了该方法的有效性，为水下航行器控制提供了更直观的建模工具。

Abstract: In this paper, we present a Newton-Euler formulation of the equations of
motion for underwater vehicles with an interntal moving mass actuator.
Furthermore, the moving mass dynamics are expressed as an extension to the
manoeuvring model for underwater vehicles, originally introduced by Fossen
(1991). The influence of the moving mass is described in body-frame and
included as states in both an additional kinematic equation and as part of the
coupled rigid-body kinetics of the underwater vehicle. The Coriolis-centripetal
effects are derived from Kirchhoff's equations and the hydrostatics are derived
using first principals. The proposed Newton-Euler model is validated through
simulation and compared with the traditional Hamiltonian internal moving mass
actuator formulation.

</details>


### [80] [Octopus-like Reaching Motion: A Perspective Inspired by Whipping](https://arxiv.org/abs/2510.25520)
*Shengyao Zhang,Yiyuan Zhang,Chenrui Zhang,Yiming Li,Wenci Xin,Yuliang Liufu,Hong Wei Ng,Cecilia Laschi*

Main category: cs.RO

TL;DR: 该研究通过实验验证章鱼触手伸展运动与鞭子被动动力学的相似性，发现虽然能在水中重现弯曲传播，但速度分布不同，证明章鱼运动不是单纯的被动鞭打行为。


<details>
  <summary>Details</summary>
Motivation: 研究章鱼触手伸展运动的高效控制机制，探索其与鞭子动力学的潜在相似性，理解生物运动原理。

Method: 在水和空气中进行平台鞭打测试，系统改变材料刚度和驱动速度，通过图像量化分析运动学特征。

Result: Ecoflex Gel 2臂在150rpm驱动下在水中重现了类似章鱼的弯曲传播，但弯曲点速度呈单调递减而非生物钟形分布，空气中无传播现象。

Conclusion: 章鱼伸展运动不是单纯的被动鞭打行为，周围介质在形成类似运动中起关键作用，为理解生物运动和流体动力学研究提供新视角。

Abstract: The stereotypical reaching motion of the octopus arm has drawn growing
attention for its efficient control of a highly deformable body. Previous
studies suggest that its characteristic bend propagation may share underlying
principles with the dynamics of a whip. This work investigates whether
whip-like passive dynamics in water can reproduce the kinematic features
observed in biological reaching and their similarities and differences.
Platform-based whipping tests were performed in water and air while
systematically varying material stiffness and driving speed. Image-based
quantification revealed that the Ecoflex Gel 2 arm driven at 150 rpm (motor
speed) reproduced curvature propagation similar to that observed in octopus
reaching. However, its bend-point velocity decreased monotonically rather than
exhibiting the biological bell-shaped profile, confirming that the octopus
reaching movement is not merely a passive whipping behavior. The absence of
propagation in air further highlights the critical role of the surrounding
medium in forming octopus-like reaching motion. This study provides a new
perspective for understand biological reaching movement, and offers a potential
platform for future hydrodynamic research.

</details>


### [81] [Using VLM Reasoning to Constrain Task and Motion Planning](https://arxiv.org/abs/2510.25548)
*Muyang Yan,Miras Mengdibayev,Ardon Floros,Weihang Guo,Lydia E. Kavraki,Zachary Kingston*

Main category: cs.RO

TL;DR: VIZ-COAST利用预训练视觉语言模型的常识空间推理能力，在任务规划阶段提前识别向下细化问题，避免在规划过程中修复这些失败，从而显著减少规划时间。


<details>
  <summary>Details</summary>
Motivation: 在任务和运动规划中，高层次任务规划基于世界抽象进行，但当领域的向下细化能力较差时，看似有效的任务级计划可能在运动规划阶段失败，需要重新规划，导致整体性能下降。

Method: 利用大型预训练视觉语言模型的常识空间推理能力，从图像和领域描述中提取合理的约束条件，在任务规划阶段提前识别向下细化问题。

Result: 在两个具有挑战性的TAMP领域上的实验表明，该方法能够从图像和领域描述中提取合理的约束，显著减少规划时间，在某些情况下完全消除向下细化失败，并能泛化到更广泛领域的多样化实例。

Conclusion: VIZ-COAST通过利用视觉语言模型的常识推理能力，在任务规划阶段预先识别向下细化问题，有效提高了任务和运动规划的效率。

Abstract: In task and motion planning, high-level task planning is done over an
abstraction of the world to enable efficient search in long-horizon robotics
problems. However, the feasibility of these task-level plans relies on the
downward refinability of the abstraction into continuous motion. When a
domain's refinability is poor, task-level plans that appear valid may
ultimately fail during motion planning, requiring replanning and resulting in
slower overall performance. Prior works mitigate this by encoding refinement
issues as constraints to prune infeasible task plans. However, these approaches
only add constraints upon refinement failure, expending significant search
effort on infeasible branches. We propose VIZ-COAST, a method of leveraging the
common-sense spatial reasoning of large pretrained Vision-Language Models to
identify issues with downward refinement a priori, bypassing the need to fix
these failures during planning. Experiments on two challenging TAMP domains
show that our approach is able to extract plausible constraints from images and
domain descriptions, drastically reducing planning times and, in some cases,
eliminating downward refinement failures altogether, generalizing to a diverse
range of instances from the broader domain.

</details>


### [82] [Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills](https://arxiv.org/abs/2510.25634)
*Weikang Wan,Fabio Ramos,Xuning Yang,Caelan Garrett*

Main category: cs.RO

TL;DR: 提出了一种分层框架，将长时程接触丰富的双手操作问题建模为技能规划与调度问题，支持同时技能调用，相比端到端RL方法和传统顺序规划器表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决长时程接触丰富的双手操作任务中复杂的协调问题，包括并行执行和顺序协作的混合模式，超越纯顺序决策的限制。

Method: 构建单臂和双手原始技能库，使用GPU加速模拟中的强化学习训练技能，然后训练基于Transformer的规划器作为高层调度器，同时预测离散技能调度和连续参数。

Result: 在复杂接触丰富的任务上比端到端RL方法获得更高成功率，比传统顺序规划器产生更高效、协调的行为。

Conclusion: 分层框架通过集成技能规划与调度，有效解决了双手操作中的复杂协调问题，展示了在接触丰富任务中的优越性能。

Abstract: Long-horizon contact-rich bimanual manipulation presents a significant
challenge, requiring complex coordination involving a mixture of parallel
execution and sequential collaboration between arms. In this paper, we
introduce a hierarchical framework that frames this challenge as an integrated
skill planning & scheduling problem, going beyond purely sequential
decision-making to support simultaneous skill invocation. Our approach is built
upon a library of single-arm and bimanual primitive skills, each trained using
Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a
Transformer-based planner on a dataset of skill compositions to act as a
high-level scheduler, simultaneously predicting the discrete schedule of skills
as well as their continuous parameters. We demonstrate that our method achieves
higher success rates on complex, contact-rich tasks than end-to-end RL
approaches and produces more efficient, coordinated behaviors than traditional
sequential-only planners.

</details>


### [83] [Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics](https://arxiv.org/abs/2510.25650)
*Ahmad Kokhahi,Mary Kurz*

Main category: cs.RO

TL;DR: 该论文提出了一种考虑能耗的AGV多智能体路径规划方法，包含基于能耗和时间的碰撞避免策略，以及NSGA和ALNS两种多目标任务分配算法。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF研究主要关注碰撞避免和旅行时间最小化，但忽略了AGV的能耗问题。本文旨在同时解决AGV之间的碰撞避免和任务分配问题，并考虑能耗优化。

Method: 提出新的碰撞避免策略，综合考虑能耗和旅行时间；使用NSGA和ALNS两种多目标算法进行任务分配。

Result: 比较评估表明，所提方法在碰撞避免和任务分配方面均优于现有方法。

Conclusion: 同时考虑能耗和旅行时间的路径规划方法能有效提升AGV系统的整体性能。

Abstract: Multi-Agent Path Finding (MAPF) has gained significant attention, with most
research focusing on minimizing collisions and travel time. This paper also
considers energy consumption in the path planning of automated guided vehicles
(AGVs). It addresses two main challenges: i) resolving collisions between AGVs
and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy
that takes both energy use and travel time into account. For task assignment,
we present two multi-objective algorithms: Non-Dominated Sorting Genetic
Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative
evaluations show that these proposed methods perform better than existing
approaches in both collision avoidance and task assignment.

</details>


### [84] [Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models](https://arxiv.org/abs/2510.25713)
*Boshi An,Chenyu Yang,Robert Katzschmann*

Main category: cs.RO

TL;DR: 该论文提出了一种改进的视觉-语言-动作模型，用于灵巧的人机协作，通过添加任务感知视觉处理、辅助意图预测和动作空间后处理，实现了最小化语言提示下的协作行为。


<details>
  <summary>Details</summary>
Motivation: 开发能够与人类进行灵巧协作的机器人系统，减少对复杂语言指令的依赖，提高协作的自然性和效率。

Method: 在预训练的VLA模型基础上添加：(1) FiLM条件化视觉骨干网络实现任务感知；(2) 辅助意图头预测合作者手部姿态和目标线索；(3) 动作空间后处理预测紧凑的增量动作和PCA降维的手指关节。

Result: 增量动作表现良好，4个主成分解释了约96%的手关节方差；动作后处理是主要性能驱动因素；实现了实时协作堆栈（0.3秒延迟）。

Conclusion: 方法成功实现了长时程协作行为，但发现了对特定演示者过度拟合（trainer overfitting）是主要限制。

Abstract: We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for
dexterous human-robot collaboration with minimal language prompting. Our
approach adds (i) FiLM conditioning to visual backbones for task-aware
perception, (ii) an auxiliary intent head that predicts collaborator hand pose
and target cues, and (iii) action-space post-processing that predicts compact
deltas (position/rotation) and PCA-reduced finger joints before mapping to full
commands. Using a multi-view, teleoperated Franka and Mimic-hand dataset
augmented with MediaPipe hand poses, we demonstrate that delta actions are
well-behaved and that four principal components explain ~96% of hand-joint
variance. Ablations identify action post-processing as the primary performance
driver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is
detrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes
"pick-up" and "pass" into a long-horizon behavior. We surface "trainer
overfitting" to specific demonstrators as the key limitation.

</details>


### [85] [A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation](https://arxiv.org/abs/2510.25725)
*Eunju Kwon,Seungwon Oh,In-Chang Baek,Yucheon Park,Gyungbo Kim,JaeYoung Moon,Yunho Choi,Kyung-Joong Kim*

Main category: cs.RO

TL;DR: 提出了一个用于操作可变形软物体的人形视觉-触觉-动作数据集，通过遥操作收集，捕捉了不同压力条件下的多模态交互。


<details>
  <summary>Details</summary>
Motivation: 先前机器人学习数据集主要关注刚性物体，未能充分体现真实世界操作中压力条件的多样性，特别是在操作可变形软物体方面存在不足。

Method: 通过配备灵巧手的人形机器人进行遥操作收集数据，捕捉多模态交互和不同压力条件。

Result: 创建了一个包含视觉、触觉和动作信息的数据集，专门针对可变形软物体的操作任务。

Conclusion: 这项工作将推动未来研究开发能够有效利用触觉信号复杂性和多样性的模型，并采用先进的优化策略。

Abstract: Contact-rich manipulation has become increasingly important in robot
learning. However, previous studies on robot learning datasets have focused on
rigid objects and underrepresented the diversity of pressure conditions for
real-world manipulation. To address this gap, we present a humanoid
visual-tactile-action dataset designed for manipulating deformable soft
objects. The dataset was collected via teleoperation using a humanoid robot
equipped with dexterous hands, capturing multi-modal interactions under varying
pressure conditions. This work also motivates future research on models with
advanced optimization strategies capable of effectively leveraging the
complexity and diversity of tactile signals.

</details>


### [86] [Modeling Collapse of Steered Vine Robots Under Their Own Weight](https://arxiv.org/abs/2510.25727)
*Ciera McFarland,Margaret McGuinness*

Main category: cs.RO

TL;DR: 提出了一个全面的坍塌模型，能够预测软体生长机器人在任何形状下的坍塌长度，使用真实形状信息和尾部张力。


<details>
  <summary>Details</summary>
Motivation: 软体生长机器人在受限环境中具有高机动性，但在面对环境间隙时可能因自身重量而坍塌，需要预测和防止坍塌行为。

Method: 开发了一个坍塌模型，使用真实形状信息和尾部张力来预测坍塌长度，通过实验验证模型准确性，包括无转向机器人和单执行器转向机器人的测试。

Result: 模型准确预测了无转向机器人的坍塌趋势，并能准确预测单执行器转向机器人的坍塌发生。在间隙跨越任务中，机器人需要充气执行器才能避免坍塌，模型支持这一发现。

Conclusion: 该模型能够在任何开放环境中模拟机器人的坍塌行为，并理解其在3D导航任务中成功所需的参数，可应用于其他机器人变体。

Abstract: Soft, vine-inspired growing robots that move by eversion are highly mobile in
confined environments, but, when faced with gaps in the environment, they may
collapse under their own weight while navigating a desired path. In this work,
we present a comprehensive collapse model that can predict the collapse length
of steered robots in any shape using true shape information and tail tension.
We validate this model by collapsing several unsteered robots without true
shape information. The model accurately predicts the trends of those
experiments. We then attempt to collapse a robot steered with a single actuator
at different orientations. Our models accurately predict collapse when it
occurs. Finally, we demonstrate how this could be used in the field by having a
robot attempt a gap-crossing task with and without inflating its actuators. The
robot needs its actuators inflated to cross the gap without collapsing, which
our model supports. Our model has been specifically tested on straight and
series pouch motor-actuated robots made of non-stretchable material, but it
could be applied to other robot variations. This work enables us to model the
robot's collapse behavior in any open environment and understand the parameters
it needs to succeed in 3D navigation tasks.

</details>


### [87] [GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions](https://arxiv.org/abs/2510.25754)
*Bohan Wu,Paul de La Sayette,Li Fei-Fei,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: GeT-USE是一个两阶段方法，通过在模拟中学习扩展机器人本体，然后将学到的几何知识迁移到真实机器人视觉运动策略中，实现通用工具使用。


<details>
  <summary>Details</summary>
Motivation: 当前机器人工具使用方法假设只有一个可用对象且该对象能够完成任务，无法从多个对象中选择最佳工具，特别是在最优工具缺失时。

Method: 首先在模拟中探索机器人本体扩展（构建新末端执行器），识别对任务最有利的通用工具几何形状，然后将学到的几何知识蒸馏到真实机器人策略中。

Result: 在22自由度的真实机器人上，GeT-USE在三个基于视觉的双手机器人移动操作工具使用任务中，比最先进方法成功率高出30-60%。

Conclusion: 通过模拟中学习本体扩展来获取通用工具几何知识，然后迁移到真实机器人，能够有效实现通用工具使用，显著提升机器人问题解决能力。

Abstract: The ability to use random objects as tools in a generalizable manner is a
missing piece in robots' intelligence today to boost their versatility and
problem-solving capabilities. State-of-the-art robotic tool usage methods
focused on procedurally generating or crowd-sourcing datasets of tools for a
task to learn how to grasp and manipulate them for that task. However, these
methods assume that only one object is provided and that it is possible, with
the correct grasp, to perform the task; they are not capable of identifying,
grasping, and using the best object for a task when many are available,
especially when the optimal tool is absent. In this work, we propose GeT-USE, a
two-step procedure that learns to perform real-robot generalized tool usage by
learning first to extend the robot's embodiment in simulation and then
transferring the learned strategies to real-robot visuomotor policies. Our key
insight is that by exploring a robot's embodiment extensions (i.e., building
new end-effectors) in simulation, the robot can identify the general tool
geometries most beneficial for a task. This learned geometric knowledge can
then be distilled to perform generalized tool usage tasks by selecting and
using the best available real-world object as tool. On a real robot with 22
degrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by
30-60% success rates across three vision-based bimanual mobile manipulation
tool-usage tasks.

</details>


### [88] [STITCH 2.0: Extending Augmented Suturing with EKF Needle Estimation and Thread Management](https://arxiv.org/abs/2510.25768)
*Kush Hari,Ziyang Chen,Hansoul Kim,Ken Goldberg*

Main category: cs.RO

TL;DR: STITCH 2.0是一个改进的手术缝合机器人系统，通过7项技术改进实现了74.4%的伤口闭合率，比基线方法缝合数量增加66%，时间减少38%。


<details>
  <summary>Details</summary>
Motivation: 外科医生缝合技能差异大，现有机器人缝合系统如STITCH 1.0因针位跟踪不准和线管理不善而难以完全闭合伤口。

Method: 提出了STITCH 2.0增强灵巧性管道，包括改进的EKF针位估计、新的解线方法和自动3D缝合对齐算法等7项改进。

Result: 在15次试验中，STITCH 2.0平均实现74.4%伤口闭合，每次试验4.87针；允许两次人工干预时，平均6针实现100%伤口闭合率。

Conclusion: STITCH 2.0显著提升了机器人缝合性能，为自动化手术缝合提供了有效解决方案。

Abstract: Surgical suturing is a high-precision task that impacts patient healing and
scarring. Suturing skill varies widely between surgeons, highlighting the need
for robot assistance. Previous robot suturing works, such as STITCH 1.0 [1],
struggle to fully close wounds due to inaccurate needle tracking and poor
thread management. To address these challenges, we present STITCH 2.0, an
elevated augmented dexterity pipeline with seven improvements including:
improved EKF needle pose estimation, new thread untangling methods, and an
automated 3D suture alignment algorithm. Experimental results over 15 trials
find that STITCH 2.0 on average achieves 74.4% wound closure with 4.87 sutures
per trial, representing 66% more sutures in 38% less time compared to the
previous baseline. When two human interventions are allowed, STITCH 2.0
averages six sutures with 100% wound closure rate. Project website:
https://stitch-2.github.io/

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [89] [How can methods for classifying and clustering trajectories be used for prevention trials? An example in Alzheimer's disease area](https://arxiv.org/abs/2510.24751)
*Céline Bougel,Sébastien Déjean,Caroline Giulioli,Philippe Saint-Pierre,Nicolas Savy,Sandrine Andrieu*

Main category: stat.AP

TL;DR: 该研究探讨了在阿尔茨海默病预防试验中使用数据驱动方法进行轨迹分类的可行性，以解决传统参数假设检验无法检测亚组效应的问题。


<details>
  <summary>Details</summary>
Motivation: 传统临床试验基于参数假设检验，当研究人群未观察到效应时，可能无法检测到亚组中的效应。特别是在预防试验中，终点是重复测量的轨迹，需要能够处理数据自相关的方法。

Method: 使用无监督方法（纵向数据k-means、层次聚类分析、图形符号学）和有监督分析（根据应答状态进行二分类），对MAPT试验的复合Z评分轨迹数据进行分类。

Result: 纵向数据k-means识别出三个组，其中一个组在三年随访期间表现出认知下降。其他无监督方法需要选择轨迹变化指标来处理纵向数据。

Conclusion: 数据驱动的无监督方法可以识别认知下降的相似轨迹模式，突显了人群异质性可能掩盖治疗效果的问题，为亚组分析提供了替代方案。

Abstract: Background: Clinical trials are designed to prove the efficacy of an
intervention by means of model-based approaches involving parametric hypothesis
testing. Issues arise when no effect is observed in the study population.
Indeed, an effect may be present in a subgroup and the statistical test cannot
detect it. To investigate this possibility, we proposed to change the paradigm
to a data-driven approach. We selected exploratory methods to provide another
perspective on the data and to identify particular homogeneous subgroups of
subjects within which an effect might be detected. In the setting of prevention
trials, the endpoint is a trajectory of repeated measures. In the settings of
prevention trials, the endpoint is a trajectory of repeated measures, which
requires the use of methods that can take data autocorrelation into account.
The primary aim of this work was to explore the applicability of different
methods for clustering and classifying trajectories. Methods: The Multidomain
Alzheimer Preventive Trial (MAPT) was a three-year randomized controlled trial
with four parallel arms (NCT00672685). The primary outcome was a composite
Z-score combining four cognitive tests. The data were analyzed by quadratic
mixed effects model. This study was inconclusive. Exploratory analysis is
therefore relevant to investigate the use of data-driven methods for trajectory
classification. The methods used were unsupervised: k-means for longitudinal
data, Hierarchical Cluster Analysis (HCA), graphic semiology, and supervised
analysis with dichotomous classification according to responder status.
Results: Using k-means for longitudinal data, three groups were obtained and
one of these groups showed cognitive decline over the three years of follow-up.
This method could be applied directly to the primary outcome, the composite
Z-score with repeated observations over time. With the two others unsupervised
methods, we were unable to process longitudinal data directly. It was therefore
necessary to choose an indicator of change in trajectories and to consider the
rate of change between two measurements. For the HCA method, Ward's aggregation
was performed. The Euclidean distance and rates of change were applied for the
graphic semiology method. Lastly, as there were no objective criteria to define
responder status, we defined our responders based on clinical criteria.
Discussion: In the princeps study, the prevention trial was found to be
inconclusive, likely due to the heterogeneity of the population, which may have
masked a treatment effect later identified in a refined subgroup of high Beta
Amyloid subjects. So, we have adopted an alternative unsupervised approach to
subject stratification based on their trajectories. We could then identify
patterns of similar trajectories of cognitive decline and also highlight the
potential problem of a large heterogeneity of the profiles, maybe due to the
final endpoint considered.

</details>


### [90] [Forecasting Australian Electricity Generation by Fuel Mix](https://arxiv.org/abs/2510.25185)
*Han Lin Shang,Lin Han,Stefan Trück*

Main category: stat.AP

TL;DR: 提出了两种基于预测协调和成分数据分析的统计方法，用于预测短期电力供应中的燃料组合，并在澳大利亚五个电力市场验证了自下而上分层预测方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 随着可变可再生能源在电力系统中的份额增加，电力需求和发电变得越来越不可预测，准确预测燃料组合对市场运营、电网稳定、成本优化和可持续能源规划至关重要。

Method: 引入了两种统计方法：预测协调和成分数据分析，重点关注自下而上的分层预测方法来预测不同燃料类型的短期电力供应。

Result: 在澳大利亚五个电力市场的实证研究中，自下而上分层预测方法始终优于其他方法，并且在化石燃料发电占比较高的电力系统中预测精度最高。

Conclusion: 自下而上的分层预测方法是预测电力供应燃料组合的最有效方法，特别是在化石燃料发电占主导的电力系统中表现最佳。

Abstract: Electricity demand and generation have become increasingly unpredictable with
the growing share of variable renewable energy sources in the power system.
Forecasting electricity supply by fuel mix is crucial for market operation,
ensuring grid stability, optimizing costs, integrating renewable energy
sources, and supporting sustainable energy planning. We introduce two
statistical methods, centering on forecast reconciliation and compositional
data analysis, to forecast short-term electricity supply by different types of
fuel mix. Using data for five electricity markets in Australia, we study the
forecast accuracy of these techniques. The bottom-up hierarchical forecasting
method consistently outperforms the other approaches. Moreover, fuel mix
forecasting is most accurate in power systems with a higher share of stable
fossil fuel generation.

</details>


### [91] [Inferring Mobility Reductions from COVID-19 Disease Spread along the Urban-Rural Gradient](https://arxiv.org/abs/2510.25424)
*Sydney Paltra,Jonas Dehning,Viola Priesemann,Kai Nagel*

Main category: stat.AP

TL;DR: 该研究使用贝叶斯层次模型分析德国400个地区在疫情期间的移动性变化，发现城市地区对疾病传播的反应最强，就业部门和政策变量在不同阶段影响不同，但移动性减少仅部分转化为发病率降低。


<details>
  <summary>Details</summary>
Motivation: 了解在COVID-19大流行期间，哪些环境、社会和人口因素促进了移动性减少和疫情缓解，因为现有知识存在空白。

Method: 使用贝叶斯层次模型分析德国400个地区的匿名手机数据，将移动性分解为疾病响应成分和疾病无关因素（温度、学校假期、公共假日）。

Result: 发现城市地区对疾病传播的反应最强；就业部门在第一波疫情中解释反应强度差异，政策变量在第二波疫情中变得显著；移动性减少仅部分转化为发病率降低。

Conclusion: 识别了移动性减少的关键驱动因素，证明移动性行为可作为人口响应的操作代理指标，但其他隐藏因素也影响疫情传播。

Abstract: The COVID-19 pandemic reshaped human mobility through policy interventions
and voluntary behavioral changes. Mobility adaptions helped mitigate pandemic
spread, however our knowledge which environmental, social, and demographic
factors helped mobility reduction and pandemic mitigation is patchy. We
introduce a Bayesian hierarchical model to quantify heterogeneity in mobility
responses across time and space in Germany's 400 districts using anonymized
mobile phone data. Decomposing mobility into a disease-responsive component and
disease-independent factors (temperature, school vacations, public holidays)
allows us to quantify the impact of each factor. We find significant
differences in reaction to disease spread along the urban-rural gradient, with
large cities reducing mobility most strongly. Employment sectors further help
explain variance in reaction strength during the first wave, while political
variables gain significance during the second wave. However, reduced mobility
only partially translates to lower peak incidence, indicating the influence of
other hidden factors. Our results identify key drivers of mobility reductions
and demonstrate that mobility behavior can serve as an operational proxy for
population response.

</details>


### [92] [General model for estimating range variances of terrestrial laser scanners based on (un-)scaled intensity values](https://arxiv.org/abs/2510.25587)
*Omar AbdelGafar,Selin Palaz,Yihui Yang,Christoph Holst*

Main category: stat.AP

TL;DR: 该研究提出了测量和估计地面激光扫描仪(TLS)测距方差的有效方法，使用原始和缩放强度值，为构建完整的随机模型提供关键支持。


<details>
  <summary>Details</summary>
Motivation: 随着TLS在测量变形分析中广泛应用，需要开发能准确捕捉测量不确定性的综合随机模型，其中构建完整的方差-协方差矩阵是关键，而测距方差随不同强度测量而变化。

Method: 采用二维扫描方法，对控制目标和任意物体进行扫描，使用提供原始强度值的TLS仪器(如Z+F Imager 5016A)和输出缩放强度的仪器(如Leica ScanStation P50)，并在水坝表面进行实地观测验证。

Result: 研究开发了测量和估计TLS测距方差的有效方法，能够处理不同强度测量条件下的方差变化问题。

Conclusion: 这项工作为高端TLS系统中的测距不确定性建模引入了全面的工作流程，为构建完整的随机模型提供了重要基础。

Abstract: Recent advancements in technology have established terrestrial laser scanners
(TLS) as a powerful instrument in geodetic deformation analysis. As TLS becomes
increasingly integrated into this field, it is essential to develop a
comprehensive stochastic model that accurately captures the measurement
uncertainties. A key component of this model is the construction of a complete
and valid variance-covariance matrix (VCM) for TLS polar measurements, which
requires the estimation of variances for range, vertical, and horizontal
angles, as well as their correlations. While angular variances can be obtained
from manufacturer specifications, the range variance varies with different
intensity measurements. As a primary contribution, this study presents an
effective methodology for measuring and estimating TLS range variances using
both raw and scaled intensity values. A two-dimensional scanning approach is
applied to both controlled targets and arbitrary objects using TLS instruments
that provide raw intensity values (e.g., Z+F~Imager~5016A) and those that
output scaled intensities (e.g., Leica~ScanStation~P50). The methodology is
further evaluated using field observations on a water dam surface. Overall,
this work introduces a comprehensive workflow for modeling range uncertainties
in high-end TLS systems.

</details>


### [93] [COBASE: A new copula-based shuffling method for ensemble weather forecast postprocessing](https://arxiv.org/abs/2510.25610)
*Maurits Flos,Bastien François,Irene Schicker,Kirien Whan,Elisa Perrone*

Main category: stat.AP

TL;DR: COBASE是一个新颖的基于copula的集成后处理框架，通过秩洗牌机制结合参数化建模的灵活性和非参数技术的优势，提供经过校准的边缘分布和真实的依赖结构重建。


<details>
  <summary>Details</summary>
Motivation: 传统两步法后处理中，参数化方法（如GCA）由于随机采样校正后的单变量边缘而产生校准不良的多变量预测，而非参数方法在历史数据有限时表现不佳。

Method: COBASE框架采用copula基础，通过秩洗牌机制模仿非参数技术，同时保持参数化建模的灵活性。

Result: 在奥地利ALADIN-LAEF系统和荷兰ECMWF系统的多站点温度预测评估中，COBASE变体始终优于传统copula方法（如GCA），并与最先进的非参数方法（SimSchaake和ECC）性能相当。

Conclusion: COBASE为多变量集成后处理提供了一个有竞争力且稳健的替代方案，在参数化和非参数化依赖重建之间建立了原则性桥梁。

Abstract: Weather predictions are often provided as ensembles generated by repeated
runs of numerical weather prediction models. These forecasts typically exhibit
bias and inaccurate dependence structures due to numerical and dispersion
errors, requiring statistical postprocessing for improved precision. A common
correction strategy is the two-step approach: first adjusting the univariate
forecasts, then reconstructing the multivariate dependence. The second step is
usually handled with nonparametric methods, which can underperform when
historical data are limited. Parametric alternatives, such as the Gaussian
Copula Approach (GCA), offer theoretical advantages but often produce poorly
calibrated multivariate forecasts due to random sampling of the corrected
univariate margins. In this work, we introduce COBASE, a novel copula-based
postprocessing framework that preserves the flexibility of parametric modeling
while mimicking the nonparametric techniques through a rank-shuffling
mechanism. This design ensures calibrated margins and realistic dependence
reconstruction. We evaluate COBASE on multi-site 2-meter temperature forecasts
from the ALADIN-LAEF ensemble over Austria and on joint forecasts of
temperature and dew point temperature from the ECMWF system in the Netherlands.
Across all regions, COBASE variants consistently outperform traditional
copula-based approaches, such as GCA, and achieve performance on par with
state-of-the-art nonparametric methods like SimSchaake and ECC, with only
minimal differences across settings. These results position COBASE as a
competitive and robust alternative for multivariate ensemble postprocessing,
offering a principled bridge between parametric and nonparametric dependence
reconstruction.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [94] [Blockage-Aware Multi-RIS WSR Maximization via Per-RIS Indexed Synchronization Sequences and Closed-Form Riemannian Updates](https://arxiv.org/abs/2510.24723)
*Sehyun Ryu,Hyun Jong Yang*

Main category: eess.SY

TL;DR: 提出了一种针对毫米波多用户MIMO系统中阻塞问题的多RIS加权和速率优化框架，通过能量检测识别阻塞面板，并采用闭式黎曼相位对齐算法联合优化基站预编码器和RIS相位。


<details>
  <summary>Details</summary>
Motivation: 毫米波多用户MIMO系统易受阻塞影响，而现有研究大多假设RIS可用性理想，忽略了RIS链路本身也可能被阻塞的问题。

Method: 基站发送短期的每RIS索引同步信号，用户通过简单能量检测测试识别阻塞面板；基于检测到的可行集合，采用闭式黎曼相位对齐算法联合优化基站预编码器和RIS相位。

Result: 仿真验证了可靠的阻塞检测性能，并在加权和速率和收敛速度方面相比现有基线方法取得了显著提升。

Conclusion: 所提出的框架能够有效处理RIS阻塞问题，通过闭式黎曼相位对齐算法实现了高效优化，为毫米波多用户MIMO系统的鲁棒性提供了解决方案。

Abstract: Millimeter-wave (mmWave) multi-user MIMO systems are highly vulnerable to
blockage, and reconfigurable intelligent surfaces (RIS) have been proposed as a
remedy. However, RIS links may themselves be blocked, while most prior works
assume ideal RIS availability. We propose an end-to-end blockage-aware
multi-RIS weighted sum-rate (WSR) optimization framework. The BS transmits
short per-RIS indexed synchronization signals, enabling each user to identify
blocked panels through a simple energy detection test. Based on the detected
feasible sets, we jointly optimize the BS precoder and RIS phases via a
Closed-form Riemannian Phase Alignment (CRPA) algorithm. CRPA provides
unit-modulus-preserving closed-form updates, requiring no projection or line
search, and ensures monotone ascent. Simulations validate reliable blockage
detection and notable WSR and convergence gains over existing baselines.

</details>


### [95] [Constructive Lyapunov Functions via Topology-Preserving Neural Networks](https://arxiv.org/abs/2510.24730)
*Jaehong Oh*

Main category: eess.SY

TL;DR: ONN算法在收敛速度、边缘效率和计算复杂度方面达到最优性能，在300万节点语义网络上比基线方法提升99.75%，ORTSF集成到transformer中在WikiText-103上实现14.7%困惑度降低和2.3倍收敛加速。


<details>
  <summary>Details</summary>
Motivation: 将Massera的抽象存在定理转化为具体可扩展算法，为神经网络、机器人和分布式系统中的稳定性分析开辟新途径。

Method: 开发ONN（Optimal Neural Network）算法，建立与最优控制、信息几何、拓扑数据分析、离散几何和范畴论的深层联系。

Result: 在3M节点语义网络上实现99.75%性能提升，ORTSF集成transformer在WikiText-103上减少14.7%困惑度并加速2.3倍收敛，证明指数收敛（μ=3.2×10⁻⁴）和拓扑保持。

Conclusion: 该工作将理论存在定理转化为具有可证明保证的具体可扩展算法，为神经网络、机器人和分布式系统的构造性稳定性分析开辟了新途径。

Abstract: We prove that ONN achieves order-optimal performance on convergence rate
($\mu \propto \lambda_2$), edge efficiency ($E = N$ for minimal connectivity $k
= 2$), and computational complexity ($O(N d^2)$). Empirical validation on
3M-node semantic networks demonstrates 99.75\% improvement over baseline
methods, confirming exponential convergence ($\mu = 3.2 \times 10^{-4}$) and
topology preservation. ORTSF integration into transformers achieves 14.7\%
perplexity reduction and 2.3 faster convergence on WikiText-103. We establish
deep connections to optimal control (Hamilton-Jacobi-Bellman), information
geometry (Fisher-efficient natural gradient), topological data analysis
(persistent homology computation in $O(KN)$), discrete geometry (Ricci flow),
and category theory (adjoint functors). This work transforms Massera's abstract
existence theorem into a concrete, scalable algorithm with provable guarantees,
opening pathways for constructive stability analysis in neural networks,
robotics, and distributed systems.

</details>


### [96] [Principal and Combination Parametric Resonances of an Electromagnetically Suspended Vehicle subject to Base Excitation](https://arxiv.org/abs/2510.24756)
*Jithu Paul,Karel N. van Dalen,Andrei B. Faragau,Rens J. van Leijden,Biagio Carboni,Andrei V. Metrikine*

Main category: eess.SY

TL;DR: 研究电磁悬浮车辆在周期性激励下的动态稳定性，分析参数共振对系统稳定性的影响，发现组合参数共振的稳定性边界最大。


<details>
  <summary>Details</summary>
Motivation: 电磁悬浮系统（如Hyperloop和磁悬浮）中车辆与支撑结构之间的间隙很小，使得系统对外部激励高度敏感，需要研究其动态稳定性。

Method: 建立三自由度模型，推导包含非线性电磁力和PD控制的运动方程，通过线性化得到时变系数系统，使用扩展Hills方法和Floquet理论分析参数共振。

Result: 在控制增益参数空间中获得了椭圆形的稳定性边界，主参数共振的两个椭圆尺寸比为3:1，组合参数共振为14:1，组合参数共振的椭圆最大。

Conclusion: 电磁悬浮系统的稳定性边界在参数空间中呈椭圆形状，组合参数共振对系统稳定性影响最大，需要特别关注。

Abstract: This paper investigates the dynamic stability of an electromagnetically
suspended vehicle, encountered in Hyperloop and Maglev systems, subject to
periodic excitations caused by surface irregularities or vibration of the
support induced by external noise. The narrow clearance between the vehicle and
the support can make it highly sensitive to small oscillations, since the
admissible amplitudes of the vehicle oscillations can be comparable to external
excitation amplitude. The vehicle is modelled as a three-degree-of-freedom
model where the vehicle is suspended via two identical electromagnetic
actuators from a rigid support that oscillates. The governing equations are
derived using force and torque balances, incorporating nonlinear
electromagnetic forces, and Kirchhoffs law for the electromagnets with PD
control strategy on the airgap. The equations of motion are linearized around
the steady state induced by the surface oscillation, yielding a system with
time-periodic coefficients. We analytically explore both principal and
combination parametric resonances using an extended Hills method, and Floquet
theory is used for numerical validation. The stability boundaries are obtained
as ellipses in control gain parameter space, and the influence of system
parameters on these boundaries is characterized. For the principal parametric
resonance, the ratio of the sizes of the two obtained ellipses is three to one,
whereas for the combination parametric resonance, the ratio is fourteen to one.
When all ellipses are simultaneously present, one of the ellipses associated
with the combination parametric resonance is the largest.

</details>


### [97] [Stable-by-Design Neural Network-Based LPV State-Space Models for System Identification](https://arxiv.org/abs/2510.24757)
*Ahmet Eren Sertbaş,Tufan Kumbasar*

Main category: eess.SY

TL;DR: 提出了一种稳定设计的LPV神经网络状态空间模型，通过Schur参数化保证稳定性，直接从数据中学习潜在状态和内部调度变量。


<details>
  <summary>Details</summary>
Motivation: 传统非线性系统辨识方法难以同时捕捉潜在动态和保持稳定性，需要一种既能学习复杂动态又能保证稳定性的建模方法。

Method: 使用神经网络构建状态空间模型，通过编码器估计初始状态，状态空间表示网络构建调度依赖的系统矩阵，采用Schur参数化保证状态转移矩阵稳定性，结合多步预测损失和状态一致性正则化进行训练。

Result: 在基准非线性系统上的评估表明，该模型性能优于经典子空间辨识方法和近期梯度方法，能够准确匹配或超越现有方法。

Conclusion: 稳定性约束的神经LPV辨识为复杂非线性系统建模提供了一个可扩展且可靠的框架。

Abstract: Accurate modeling of nonlinear systems is essential for reliable control, yet
conventional identification methods often struggle to capture latent dynamics
while maintaining stability. We propose a \textit{stable-by-design LPV neural
network-based state-space} (NN-SS) model that simultaneously learns latent
states and internal scheduling variables directly from data. The
state-transition matrix, generated by a neural network using the learned
scheduling variables, is guaranteed to be stable through a Schur-based
parameterization. The architecture combines an encoder for initial state
estimation with a state-space representer network that constructs the full set
of scheduling-dependent system matrices. For training the NN-SS, we develop a
framework that integrates multi-step prediction losses with a state-consistency
regularization term, ensuring robustness against drift and improving
long-horizon prediction accuracy. The proposed NN-SS is evaluated on benchmark
nonlinear systems, and the results demonstrate that the model consistently
matches or surpasses classical subspace identification methods and recent
gradient-based approaches. These findings highlight the potential of
stability-constrained neural LPV identification as a scalable and reliable
framework for modeling complex nonlinear systems.

</details>


### [98] [A Digital Twin Framework for Decision-Support and Optimization of EV Charging Infrastructure in Localized Urban Systems](https://arxiv.org/abs/2510.24758)
*Linh Do-Bui-Khanh,Thanh H. Nguyen,Nghi Huynh Quang,Doanh Nguyen-Ngoc,Laurent El Ghaoui*

Main category: eess.SY

TL;DR: 提出了一个数字孪生框架，通过基于代理的决策支持和嵌入式优化来动态模拟电动汽车充电行为、基础设施布局和政策响应，应用于河内大学校园案例。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车在城市环境中加速普及，优化充电基础设施对于平衡用户满意度、能源效率和财务可行性至关重要，需要超越静态模型的动态仿真方法。

Method: 开发数字孪生框架，整合基于代理的决策支持和嵌入式元启发式优化，模拟电动汽车充电行为、基础设施布局和政策响应，并应用于河内大学校园案例。

Result: 实时通知新可用充电位提高用户满意度；汽油禁令和闲置费以最小复杂度提高充电位周转率；嵌入式优化找到快充和标准太阳能充电器的近最优组合；太阳能效率10月至3月下降20%，风电贡献不足5%。

Conclusion: 该数字孪生提供了一个灵活、计算驱动的电动汽车基础设施规划平台，具有可转移的模块化设计，能够从局部无缝扩展到城市范围。

Abstract: As Electric Vehicle (EV) adoption accelerates in urban environments,
optimizing charging infrastructure is vital for balancing user satisfaction,
energy efficiency, and financial viability. This study advances beyond static
models by proposing a digital twin framework that integrates agent-based
decision support with embedded optimization to dynamically simulate EV charging
behaviors, infrastructure layouts, and policy responses across scenarios.
Applied to a localized urban site (a university campus) in Hanoi, Vietnam, the
model evaluates operational policies, EV station configurations, and renewable
energy sources. The interactive dashboard enables seasonal analysis, revealing
a 20% drop in solar efficiency from October to March, with wind power
contributing under 5% of demand, highlighting the need for adaptive energy
management. Simulations show that real-time notifications of newly available
charging slots improve user satisfaction, while gasoline bans and idle fees
enhance slot turnover with minimal added complexity. Embedded metaheuristic
optimization identifies near-optimal mixes of fast (30kW) and standard (11kW)
solar-powered chargers, balancing energy performance, profitability, and demand
with high computational efficiency. This digital twin provides a flexible,
computation-driven platform for EV infrastructure planning, with a
transferable, modular design that enables seamless scaling from localized to
city-wide urban contexts.

</details>


### [99] [Decentralized Merging Control of Connected and Automated Vehicles to Enhance Safety and Energy Efficiency using Control Barrier Functions](https://arxiv.org/abs/2510.24871)
*Shreshta Rajakumar Deshpande,Mrdjan Jankovic*

Main category: eess.SY

TL;DR: 提出基于分散式控制障碍函数的高速公路合流控制方法，通过车辆间协商实现安全节能的合流操作，无需明确优先级且能避免交通拥堵。


<details>
  <summary>Details</summary>
Motivation: 解决高速公路合流场景中车辆协同控制问题，旨在提高系统能效和交通流量，同时增强控制器的鲁棒性。

Method: 采用分散式CBF控制算法，车辆在控制区内与其他智能体协商，通过预测-校正循环解决分歧，无明确车辆顺序或优先级。

Result: 蒙特卡洛仿真显示，相比先到先得方法显著提升系统能效和交通流量，分散控制器比集中式具有更好的鲁棒性。

Conclusion: 分散式CBF方法能有效实现高速公路安全合流，避免交通拥堵，提高能效和交通效率，且鲁棒性优于集中控制。

Abstract: This paper presents a decentralized Control Barrier Function (CBF) based
approach for highway merging of Connected and Automated Vehicles (CAVs). In
this control algorithm, each "host" vehicle negotiates with other agents in a
control zone of the highway network, and enacts its own action, to perform safe
and energy-efficient merge maneuvers. It uses predictor-corrector loops within
the robust CBF setting for negotiation and to reconcile disagreements that may
arise. There is no explicit order of vehicles and no priority. A notable
feature is absence of gridlocks due to instability of the inter-agent system.
Results from Monte Carlo simulations show significant improvement in the
system-wide energy efficiency and traffic flow compared to a first-in-first-out
approach, as well as enhanced robustness of the proposed decentralized
controller compared to its centralized counterpart.

</details>


### [100] [Delay Tolerant Control for Autonomous Driving Using CDOB](https://arxiv.org/abs/2510.24898)
*Xincheng Cao,Haochong Chen,Levent Guvenc,Bilin Aksun-Guvenc*

Main category: eess.SY

TL;DR: 提出了一种延迟容忍的通信扰动观测器(CDOB)框架，用于解决自动驾驶车辆路径跟踪控制中的通信延迟问题，在存在不确定和变化延迟条件下仍能保持精确的轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的快速发展，路径跟踪控制成为确保复杂交通场景下安全性和效率的关键。然而，联网自动驾驶车辆(CAV)固有的通信延迟和计算延迟会显著降低传统控制器(如PID)和先进控制器(如扰动观测器DOB)的性能。

Method: 提出延迟容忍的通信扰动观测器(CDOB)框架，补偿时间延迟的不利影响，即使在不确定和变化的延迟条件下也能保持准确的轨迹跟踪。

Result: 仿真研究表明，该控制架构在各种场景下(包括单车道变换、双车道变换和弹性带生成的避碰路径)都能与参考轨迹保持紧密对齐。仿真结果进一步证明，该方法在跟踪精度和延迟鲁棒性方面均优于传统方法。

Conclusion: 所提出的延迟容忍通信扰动观测器框架适用于自动驾驶应用，在存在各种时间延迟的情况下仍能保持精确的路径跟踪性能。

Abstract: With the rapid growth of autonomous vehicle technologies, effective
path-tracking control has become a critical component in ensuring safety and
efficiency in complex traffic scenarios. When a high level decision making
agent generates a collision free path, a robust low level controller is
required to precisely follow this trajectory. However, connected autonomous
vehicles (CAV) are inherently affected by communication delays and computation
delays, which significantly degrade the performance of conventional controllers
such as PID or other more advanced controllers like disturbance observers
(DOB). While DOB-based designs have shown effectiveness in rejecting
disturbances under nominal conditions, their performance deteriorates
considerably in the presence of unknown time delays. To address this challenge,
this paper proposes a delay-tolerant communication disturbance observer (CDOB)
framework for path-tracking control in delayed systems. The proposed CDOB
compensates for the adverse effects of time delays, maintaining accurate
trajectory tracking even under uncertain and varying delay conditions. It is
shown through a simulation study that the proposed control architecture
maintains close alignment with the reference trajectory across various
scenarios, including single lane change, double-= lane change, and Elastic Band
generated collision avoidance paths under various time delays. Simulation
results further demonstrate that the proposed method outperforms conventional
approaches in both tracking accuracy and delay robustness, making it well
suited for autonomous driving applications.

</details>


### [101] [A Hamilton-Jacobi Reachability Framework with Soft Constraints for Safety-Critical Systems](https://arxiv.org/abs/2510.24933)
*Chams Eddine Mballo,Donggun Lee,Claire J. Tomlin*

Main category: eess.SY

TL;DR: 提出了一种软约束可达性框架，扩展了Hamilton-Jacobi可达性分析，用于处理同时包含硬约束和软约束的安全关键系统验证。


<details>
  <summary>Details</summary>
Motivation: 传统可达性方法将状态约束视为不可违反的，在复杂操作场景中可能导致过于保守或不可行的解决方案。实际中的许多约束（如电动汽车电池状态、推荐速度范围、舒适性约束）本质上是软约束，允许在安全范围内临时违反。

Method: 框架包含两个主要组件：(i) 具有辅助预算状态的增强状态模型，用于跟踪软约束违反情况；(ii) 基于正则化的不连续Hamilton-Jacobi值函数近似方法。

Result: 通过点质量模型着陆和固定翼飞机紧急下降的数值示例验证了框架的有效性，展示了在风扰动下同时管理硬约束和软约束的能力。

Conclusion: 该软约束可达性框架为安全关键系统提供了形式化验证方法，能够处理硬约束和软约束的混合情况，在保证安全的同时允许有限的约束违反。

Abstract: Traditional reachability methods provide formal guarantees of safety under
bounded disturbances. However, they strictly enforce state constraints as
inviolable, which can result in overly conservative or infeasible solutions in
complex operational scenarios. Many constraints encountered in practice, such
as bounds on battery state of charge in electric vehicles, recommended speed
envelopes, and comfort constraints in passenger-carrying vehicles, are
inherently soft. Soft constraints allow temporary violations within predefined
safety margins to accommodate uncertainty and competing operational demands,
albeit at a cost such as increased wear or higher operational expenses. This
paper introduces a novel soft-constrained reachability framework that extends
Hamilton-Jacobi reachability analysis for the formal verification of
safety-critical systems subject to both hard and soft constraints.
Specifically, the framework characterizes a subset of the state space, referred
to as the soft-constrained reach-avoid set, from which the system is guaranteed
to reach a desired set safely, under worst-case disturbances, while ensuring
that cumulative soft-constraint violations remain within a user-specified
budget. The framework comprises two principal components: (i) an
augmented-state model with an auxiliary budget state that tracks
soft-constraint violations, and (ii) a regularization-based approximation of
the discontinuous Hamilton-Jacobi value function associated with the
reach-avoid differential game studied herein. The effectiveness of the proposed
framework is demonstrated through numerical examples involving the landing of a
simple point-mass model and a fixed-wing aircraft executing an emergency
descent, both under wind disturbances. The simulation results validate the
framework's ability to simultaneously manage both hard and soft constraints in
safety-critical settings

</details>


### [102] [Control Synthesis with Reinforcement Learning: A Modeling Perspective](https://arxiv.org/abs/2510.25063)
*Nikki Xu,Hien Tran*

Main category: eess.SY

TL;DR: 强化学习设计的控制器对模型不匹配很敏感，在虚拟仿真环境中使用不准确模型设计的控制器不适合在实际物理环境中部署。


<details>
  <summary>Details</summary>
Motivation: 研究强化学习控制器在模型不匹配情况下的鲁棒性问题，验证在虚拟仿真中使用准确模型的重要性。

Method: 使用灵敏度分析来解释控制器性能差异，并通过经验吸引区域估计来可视化鲁棒性。

Result: 基于准确模型设计的控制器对干扰和小的模型不匹配具有鲁棒性，而基于差模型设计的控制器在仿真中表现良好但在物理实验中失败。

Conclusion: 控制器设计需要准确的模型，模型质量直接影响控制器在实际物理环境中的性能和鲁棒性。

Abstract: Controllers designed with reinforcement learning can be sensitive to model
mismatch. We demonstrate that designing such controllers in a virtual
simulation environment with an inaccurate model is not suitable for deployment
in a physical setup. Controllers designed using an accurate model is robust
against disturbance and small mismatch between the physical setup and the
mathematical model derived from first principles; while a poor model results in
a controller that performs well in simulation but fails in physical
experiments. Sensitivity analysis is used to justify these discrepancies and an
empirical region of attraction estimation help us visualize their robustness.

</details>


### [103] [Stochastic Long-Term Joint Decarbonization Planning for Power Systems and Data Centers: A Case Study in PJM](https://arxiv.org/abs/2510.25118)
*Zhentong Shao,Nanpeng Yu,Daniel Wong*

Main category: eess.SY

TL;DR: 提出动态联合规划框架，在15年内共同优化数据中心和电力系统的长期发展，考虑运营和隐含碳排放，通过两阶段随机规划处理多尺度不确定性。


<details>
  <summary>Details</summary>
Motivation: 随着AI和云服务的快速发展，数据中心能耗和碳排放问题日益突出，现有研究多假设静态电力系统、仅关注运营排放且缺乏协同优化。

Method: 建立大规模两阶段随机规划模型，采用增强的Benders分解求解，共同优化数据中心选址、容量、类型以及发电扩展、储能部署和退役决策。

Result: 在PJM互联系统中可支持55GW峰值数据中心需求，弗吉尼亚和北伊利诺伊为最优选址。相比非联合规划，投资成本降低12.6%，运营成本降低8.25%，排放减少5.63%。

Conclusion: 生命周期排放考虑使可再生能源部署增加25.5%，表明隐含碳在深度脱碳中的重要作用，联合规划框架能显著提升系统经济性和环境效益。

Abstract: With the rapid growth of artificial intelligence (AI) and cloud services,
data centers have become critical infrastructures driving digital economies,
with increasing energy demand heightening concerns over electricity use and
carbon emissions, emphasizing the need for carbon-aware infrastructure
planning. Most studies assume static power systems, focus only on operational
emissions, and overlook co-optimization. This paper proposes a dynamic joint
planning framework that co-optimizes long-term data center and power system
development over 15 years. The model determines siting, capacity, and type of
data centers alongside power generation expansion, storage deployment, and
retirements, accounting for both operational and embodied emissions. To handle
multi-scale uncertainty, a large-scale two-stage stochastic program is
formulated and solved via an enhanced Benders decomposition. Applied to the PJM
Interconnection, with curated datasets released on GitHub, results show the
system can support up to 55 GW peak data center demand, with Virginia (DOM) and
Northern Illinois (ComEd) as optimal hosts. Compared to non-joint planning, the
framework cuts investment cost by 12.6%, operational cost by 8.25%, and
emissions by 5.63%. Including lifecycle emissions further raises renewable
deployment by 25.5%, highlighting embodied carbon's role in deeper
decarbonization.

</details>


### [104] [The Waterbed Effect on Quasiperiodic Disturbance Observer: Avoidance of Sensitivity Tradeoff with Time Delays](https://arxiv.org/abs/2510.25131)
*Hisayoshi Muramatsu*

Main category: eess.SY

TL;DR: 本文为使用时间延迟的准周期扰动观测器提供了类似Bode的灵敏度积分，阐明了时间延迟如何避免灵敏度权衡效应。


<details>
  <summary>Details</summary>
Motivation: 准周期扰动观测器的开环传递函数由于包含时间延迟而非有理函数，不满足现有Bode灵敏度积分的假设条件，需要建立新的灵敏度积分理论。

Method: 为连续时间和离散时间表示的准周期扰动观测器推导了类似Bode的灵敏度积分，分析了时间延迟对灵敏度权衡的影响。

Result: 建立了适用于准周期扰动观测器的灵敏度积分理论，阐明了时间延迟如何避免传统灵敏度权衡效应。

Conclusion: 时间延迟使准周期扰动观测器能够实现宽带谐波抑制，同时不放大非周期扰动或改变谐波抑制频率，从而避免了传统灵敏度权衡。

Abstract: In linear time-invariant systems, the sensitivity function to disturbances is
designed under a sensitivity tradeoff known as the waterbed effect. To
compensate for a quasiperiodic disturbance, a quasiperiodic disturbance
observer using time delays was proposed. Its sensitivity function avoids the
sensitivity tradeoff, achieving wideband harmonic suppression without
amplifying aperiodic disturbances or shifting harmonic suppression frequencies.
However, its open-loop transfer function is not rational and does not satisfy
the assumptions of existing Bode sensitivity integrals due to its time delays.
This paper provides Bode-like sensitivity integrals for the quasiperiodic
disturbance observer in both continuous-time and discrete-time representations
and clarifies the avoided sensitivity tradeoff with time delays.

</details>


### [105] [Silicon-based Josephson junction field-effect transistors enabling cryogenic logic and quantum technologies](https://arxiv.org/abs/2510.25208)
*Yusheng Xiong,Kaveh Delfanazari*

Main category: eess.SY

TL;DR: 该综述回顾了从约瑟夫森结到场效应晶体管的演变，重点分析了JJFET在超低温条件下的性能、材料兼容性和开关动力学，特别关注超导体-硅-超导体约瑟夫森结作为JJFET架构的有源核心，展示了JJFET作为下一代低温逻辑和量子电子系统基础构建模块的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着MOSFET持续微型化超越摩尔定律预测，在低温条件下开发创新的器件范式以实现超低功耗和高速功能变得至关重要。JJFET通过集成超导源漏电极，为超低温下的高效、相位相干操作提供了替代方案，有望桥接传统半导体电子学与低温逻辑和量子电路。

Method: 该综述追踪了从约瑟夫森结到场效应晶体管的演变历程，分析了在Si、GaAs和InGaAs衬底上制造的JJFET的性能和材料兼容性，特别关注超导体-硅-超导体约瑟夫森结作为JJFET架构的有源核心，并评估了其开关动力学特性。

Result: 通过分析超过四十年的实验进展，研究发现JJFET具有作为下一代低温逻辑和量子电子系统基础构建模块的潜力，能够实现跨温度域的高能效和高相干信号处理。

Conclusion: JJFET展示了作为桥接传统半导体电子学与低温量子系统的有前景技术路径，通过超导-半导体混合架构为下一代超低功耗、高速电子器件提供了基础支撑。

Abstract: The continuous miniaturisation of metal-oxide-semiconductor field-effect
transistors (MOSFETs) from long- to short-channel architectures has advanced
beyond the predictions of Moore's Law. Continued advances in semiconductor
electronics, even near current scaling and performance boundaries under
cryogenic conditions, are driving the development of innovative device
paradigms that enable ultra-low-power and high-speed functionality. Among
emerging candidates, the Josephson Junction Field-Effect Transistor (JJFET or
JoFET) provides an alternative by integrating superconducting source and drain
electrodes for efficient, phase-coherent operation at ultra-low temperatures.
These hybrid devices have the potential to bridge conventional semiconductor
electronics with cryogenic logic and quantum circuits, enabling
energy-efficient and high-coherence signal processing across temperature
domains. This review traces the evolution from Josephson junctions to
field-effect transistors, emphasising the structural and functional innovations
that underpin modern device scalability. The performance and material
compatibility of JJFETs fabricated on Si, GaAs, and InGaAs substrates are
analysed, alongside an assessment of their switching dynamics and material
compatibility. Particular attention is given to
superconductor-silicon-superconductor Josephson junctions as the active core of
JJFET architectures. By unfolding more than four decades of experimental
progress, this work highlights the promise of JJFETs as foundational building
blocks for next-generation cryogenic logic and quantum electronic systems.

</details>


### [106] [Shared Control for Vehicle Lane-Changing with Uncertain Driver Behaviors](https://arxiv.org/abs/2510.25284)
*Jiamin Wu,Chenguang Zhao,Huan Yu*

Main category: eess.SY

TL;DR: 提出了一种人机共享的变道控制框架，通过马尔可夫跳变过程建模人类驾驶行为，设计名义稳定控制器和最小干预控制器，在保持驾驶员权限的同时实现稳定变道。


<details>
  <summary>Details</summary>
Motivation: 人类驾驶的变道行为具有随机性和不确定性，可能破坏交通流的弦稳定性。需要一种既能保持驾驶员控制权，又能提供自动化辅助以确保稳定性的共享控制方法。

Method: 将人类驾驶行为建模为任务难度驱动的马尔可夫跳变过程，设计了名义稳定控制器保证随机L2弦稳定性，并开发了最小干预控制器在限制自动化干预的同时保持可接受的稳定性。

Result: 在NGSIM数据集上的仿真显示，名义控制器减少了速度扰动和变道时间，最小干预控制器进一步降低了自动化干预并提高了舒适度。在TGSIM数据集上的验证表明，最小干预控制器比SAE Level 2控制能更早完成变道。

Conclusion: 共享控制策略能够在稳定性、效率和驾驶员接受度之间取得平衡，具有实际应用潜力。

Abstract: Lane changes are common yet challenging driving maneuvers that require
continuous decision-making and dynamic interaction with surrounding vehicles.
Relying solely on human drivers for lane-changing can lead to traffic
disturbances due to the stochastic nature of human behavior and its variability
under different task demands. Such uncertainties may significantly degrade
traffic string stability, which is critical for suppressing disturbance
propagation and ensuring smooth merging of the lane-changing vehicles. This
paper presents a human-automation shared lane-changing control framework that
preserves driver authority while allowing automated assistance to achieve
stable maneuvers in the presence of driver's behavioral uncertainty. Human
driving behavior is modeled as a Markov jump process with transitions driven by
task difficulty, providing a tractable representation of stochastic state
switching. Based on this model, we first design a nominal stabilizing
controller that guarantees stochastic ${L}_2$ string stability under imperfect
mode estimation. To further balance performance and automated effort, we then
develop a Minimal Intervention Controller (MIC) that retains acceptable
stability while limiting automation. Simulations using lane-changing data from
the NGSIM dataset verify that the nominal controller reduces speed
perturbations and shorten lane-changing time, while the MIC further reduces
automated effort and enhances comfort but with moderate stability and
efficiency loss. Validations on the TGSIM dataset with SAE Level 2 vehicles
show that the MIC enables earlier lane changes than Level 2 control while
preserving driver authority with a slight stability compromise. These findings
highlight the potential of shared control strategies to balance stability,
efficiency, and driver acceptance.

</details>


### [107] [Data-Enabled Predictive Control and Guidance for Autonomous Underwater Vehicles](https://arxiv.org/abs/2510.25309)
*Sebastian Zieglmeier,Mathias Hudoba de Badyn,Narada D. Warakagoda,Thomas R. Krogstad,Paal Engelstad*

Main category: eess.SY

TL;DR: 提出基于数据驱动预测控制(DeePC)的自主水下航行器控制框架，无需显式水动力学建模，通过测量数据预测和优化系统行为。


<details>
  <summary>Details</summary>
Motivation: 消除传统水下航行器控制中对显式水动力学建模的需求，提高在海洋环境扰动和非线性工况下的控制性能。

Method: 使用经典DeePC进行航向控制，提出级联DeePC架构进行深度调节，结合自适应视线算法进行3D路径跟踪。

Result: 在REMUS 100 AUV上验证，相比传统PI/PID控制，在海洋流扰动和非线性条件下表现出更优的跟踪性能和鲁棒性。

Conclusion: DeePC方法显著减少了建模工作量，同时提高了自主水下航行器在复杂环境下的控制性能。

Abstract: This paper presents a fully data-driven control framework for autonomous
underwater vehicles (AUVs) based on Data-Enabled Predictive Control (DeePC).
The approach eliminates the need for explicit hydrodynamic modeling by
exploiting measured input-output data to predict and optimize future system
behavior. Classic DeePC was employed in the heading control, while a cascaded
DeePC architecture is proposed for depth regulation, incorporating a
loop-frequency separation to handle the different dynamic modes of input and
output. For 3-D waypoint path following, the Adaptive Line-of-Sight algorithm
is extended to a predictive formulation and integrated with DeePC. All methods
are validated in extensive simulation on the REMUS 100 AUV and compared with
classical PI/PID control. The results demonstrate superior tracking performance
and robustness of DeePC under ocean-current disturbances and nonlinear
operating conditions, while significantly reducing modeling effort.

</details>


### [108] [Tight Collision Avoidance for Stochastic Optimal Control: with Applications in Learning-based, Interactive Motion Planning](https://arxiv.org/abs/2510.25324)
*Erik Börve,Nikolce Murgovski,Leo Laine*

Main category: eess.SY

TL;DR: 提出一个随机最优控制框架，用于解决密集交互交通场景中的轨迹规划问题，处理人类驾驶员行为不确定性和非凸碰撞避免约束。


<details>
  <summary>Details</summary>
Motivation: 在密集交互交通场景中，自动驾驶车辆面临人类驾驶员行为不确定性和非凸碰撞避免约束的挑战，现有方法往往过于保守或计算不可行。

Method: 将人类驾驶员决策建模为马尔可夫决策过程，提出处理非凸车辆形状碰撞避免的方法，通过紧凑集之间的正距离约束实现。研究了三种机会约束公式，并引入紧致、连续可微的重构公式确保计算可行性。

Result: 通过两个具有挑战性的交互场景仿真验证了方法的有效性：无管制交叉口穿越和高速公路密集交通中的车道变换。

Conclusion: 该随机最优控制框架能够同时处理人类行为不确定性和非凸碰撞约束，避免了过度保守的近似，在复杂交互场景中表现出良好性能。

Abstract: Trajectory planning in dense, interactive traffic scenarios presents
significant challenges for autonomous vehicles, primarily due to the
uncertainty of human driver behavior and the non-convex nature of collision
avoidance constraints. This paper introduces a stochastic optimal control
framework to address these issues simultaneously, without excessively
conservative approximations. We opt to model human driver decisions as a Markov
Decision Process and propose a method for handling collision avoidance between
non-convex vehicle shapes by imposing a positive distance constraint between
compact sets. In this framework, we investigate three alternative chance
constraint formulations. To ensure computational tractability, we introduce
tight, continuously differentiable reformulations of both the non-convex
distance constraints and the chance constraints. The efficacy of our approach
is demonstrated through simulation studies of two challenging interactive
scenarios: an unregulated intersection crossing and a highway lane change in
dense traffic.

</details>


### [109] [Lightweight Federated Learning in Mobile Edge Computing with Statistical and Device Heterogeneity Awareness](https://arxiv.org/abs/2510.25342)
*Jinghong Tan,Zhichen Zhang,Kun Guo,Tsung-Hui Chang,Tony Q. S. Quek*

Main category: eess.SY

TL;DR: 提出了一种轻量级个性化联邦学习框架，通过参数解耦将模型分为共享和私有子空间，分别应用梯度稀疏化和模型剪枝，在异构环境下显著降低通信和计算成本。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在移动边缘计算中面临高通信计算成本和统计设备异构性问题，现有压缩方法可能增加训练轮次，特别是在异构环境下。

Method: 基于参数解耦的个性化FL框架，将模型分为共享和私有子空间，对共享组件应用梯度稀疏化，对私有组件应用模型剪枝，并联合优化稀疏度、剪枝率和无线带宽。

Result: 仿真结果显示更快的收敛速度，通信和计算成本显著降低，精度损失可忽略不计。

Conclusion: 在资源受限的异构环境中，协调和资源感知的个性化方法能够有效平衡效率和性能。

Abstract: Federated learning enables collaborative machine learning while preserving
data privacy, but high communication and computation costs, exacerbated by
statistical and device heterogeneity, limit its practicality in mobile edge
computing. Existing compression methods like sparsification and pruning reduce
per-round costs but may increase training rounds and thus the total training
cost, especially under heterogeneous environments. We propose a lightweight
personalized FL framework built on parameter decoupling, which separates the
model into shared and private subspaces, enabling us to uniquely apply gradient
sparsification to the shared component and model pruning to the private one.
This structural separation confines communication compression to global
knowledge exchange and computation reduction to local personalization,
protecting personalization quality while adapting to heterogeneous client
resources. We theoretically analyze convergence under the combined effects of
sparsification and pruning, revealing a sparsity-pruning trade-off that links
to the iteration complexity. Guided by this analysis, we formulate a joint
optimization that selects per-client sparsity and pruning rates and wireless
bandwidth to reduce end-to-end training time. Simulation results demonstrate
faster convergence and substantial reductions in overall communication and
computation costs with negligible accuracy loss, validating the benefits of
coordinated and resource-aware personalization in resource-constrained
heterogeneous environments.

</details>


### [110] [Quantum-Resilient Threat Modelling for Secure RIS-Assisted ISAC in 6G UAV Corridors](https://arxiv.org/abs/2510.25411)
*Sana Hafeez,Ghulam E Mustafa Abro,Hifza Mustafa*

Main category: eess.SY

TL;DR: 提出了一个量子弹性威胁建模框架，用于无人机走廊中的RIS辅助ISAC系统，整合了后量子密码学、场景水印和联合优化，以应对量子计算带来的安全威胁。


<details>
  <summary>Details</summary>
Motivation: 6G网络中无人机走廊的快速部署需要安全的ISAC系统，而量子计算的出现增加了窃听和欺骗风险，RIS虽然提升了性能但也引入了新的安全漏洞。

Method: 采用后量子密码学原语（ML-KEM和Falcon）、RIS编码场景水印技术、广义似然比检验，以及联合优化保密率、欺骗检测和吞吐量的安全ISAC效用函数。

Result: 在3GPP Release 19中频城市峡谷模型下，欺骗检测概率接近0.99（虚警率1e-3），对抗量子能力对手的保密率保持超过90%，信号干扰利用率比基线提高约25%。

Conclusion: 该框架为智能城市和非地面网络中的无人机走廊提供了一条符合标准的可靠量子弹性ISAC路径。

Abstract: The rapid deployment of unmanned aerial vehicle (UAV) corridors in
sixth-generation (6G) networks requires safe, intelligence-driven integrated
sensing and communications (ISAC). Reconfigurable intelligent surfaces (RIS)
enhance spectrum efficiency, localisation accuracy, and situational awareness,
while introducing new vulnerabilities. The rise of quantum computing increases
the risks associated with harvest-now-decrypt-later strategies and
quantum-enhanced spoofing. We propose a Quantum-Resilient Threat Modelling
(QRTM) framework for RIS-assisted ISAC in UAV corridors to address these
challenges. QRTM integrates classical, quantum-ready, and quantum-aided
adversaries, countered using post-quantum cryptographic (PQC) primitives:
ML-KEM for key establishment and Falcon for authentication, both embedded
within RIS control signalling and UAV coordination. To strengthen security
sensing, the framework introduces RIS-coded scene watermarking validated
through a generalised likelihood ratio test (GLRT), with its detection
probability characterised by the Marcum Q function. Furthermore, a Secure ISAC
Utility (SIU) jointly optimises secrecy rate, spoofing detection, and
throughput under RIS constraints, enabled by a scheduler with computational
complexity of O(n^2). Monte Carlo evaluations using 3GPP Release 19 mid-band
urban-canyon models (7-15 GHz) demonstrate a spoof-detection probability
approaching 0.99 at a false-alarm rate of 1e-3, secrecy-rate retention
exceeding 90 percent against quantum-capable adversaries, and
signal-interference utilisation improvements of about 25 percent compared with
baselines. These results show a standards-compliant path towards reliable,
quantum-resilient ISAC for UAV corridors in smart cities and non-terrestrial
networks.

</details>


### [111] [A New Neural Network Paradigm for Scalable and Generalizable Stability Analysis of Power Systems](https://arxiv.org/abs/2510.25501)
*Tong Han,Yan Xu,Rui Zhang*

Main category: eess.SY

TL;DR: 提出了一种用于电力系统稳定性分析的新型神经网络范式，包含神经稳定性描述器和样本增强迭代训练方案，能够实现可扩展和可泛化的稳定性分析。


<details>
  <summary>Details</summary>
Motivation: 传统电力系统稳定性分析方法难以适应系统结构变化和参数变化，需要一种能够跨不同系统结构进行泛化的稳定性分析工具。

Method: 基于系统分解构建稳定性分析对象作为多个神经网络的聚合，采用样本增强迭代训练方案，通过定制的保守性感知损失函数进行训练。

Result: 在大电网大扰动稳定性分析和微电网小扰动稳定性条件两个实现中，数值研究证明了该神经网络范式的适用性和有效性。

Conclusion: 该神经网络范式为电力系统稳定性分析提供了一种可扩展且可泛化的新方法，能够适应系统结构和参数的变化。

Abstract: This paper presents a new neural network (NN) paradigm for scalable and
generalizable stability analysis of power systems. The paradigm consists of two
parts: the neural stability descriptor and the sample-augmented iterative
training scheme. The first part, based on system decomposition, constructs the
object (such as a stability function or condition) for stability analysis as a
scalable aggregation of multiple NNs. These NNs remain fixed across varying
power system structures and parameters, and are repeatedly shared within each
system instance defined by these variations, thereby enabling the
generalization of the neural stability descriptor across a class of power
systems. The second part learns the neural stability descriptor by iteratively
training the NNs with sample augmentation, guided by the tailored
conservativeness-aware loss function. The training set is strategically
constructed to promote the descriptor's generalizability, which is
systematically evaluated by verification and validation during the training
process. Specifically, the proposed NN paradigm is implemented for
large-disturbance stability analysis of the bulk power grid and
small-disturbance stability conditions of the microgrid system. Finally,
numerical studies for the two implementations demonstrate the applicability and
effectiveness of the proposed NN paradigm.

</details>


### [112] [Optimal and Heuristic Approaches for Platooning Systems with Deadlines](https://arxiv.org/abs/2510.25564)
*Thiago S. Gomides,Evangelos Kranakis,Ioannis Lambadaris,Yannis Viniotis,Gennady Shaikhet*

Main category: eess.SY

TL;DR: 研究卡车编队在有限容量和截止时间约束下的最优编队与调度策略，通过马尔可夫决策过程建模，分析最优策略结构并提出启发式算法。


<details>
  <summary>Details</summary>
Motivation: 卡车编队能有效降低货运成本、燃料消耗和排放，但必须满足截止时间约束以避免罚款，需要在编队效率与等待成本之间取得平衡。

Method: 将问题建模为马尔可夫决策过程，分析最优策略的单调性结构，识别不可达状态，并提出基于条件和深度学习的启发式算法。

Result: 证明了最优策略在状态空间上具有单调性，识别了不可达状态类别，提出的启发式算法在保持低计算复杂度的同时利用了结构洞察。

Conclusion: 通过结构分析为大规模卡车编队调度问题提供了理论基础，提出的启发式方法能够有效处理状态空间指数增长的问题。

Abstract: Efficient truck platooning is a key strategy for reducing freight costs,
lowering fuel consumption, and mitigating emissions. Deadlines are critical in
this context, as trucks must depart within specific time windows to meet
delivery requirements and avoid penalties. In this paper, we investigate the
optimal formation and dispatch of truck platoons at a highway station with
finite capacity $L$ and deadline constraints $T$. The system operates in
discrete time, with each arriving truck assigned a deadline of $T$ slot units.
The objective is to leverage the efficiency gains from forming large platoons
while accounting for waiting costs and deadline violations. We formulate the
problem as a Markov decision process and analyze the structure of the optimal
policy $\pi^\star$ for $L = 3$, extending insights to arbitrary $L$. We prove
that the $\pi^\star$ is monotone in the state space $\mathcal{S}$ and identify
classes of unreachable states. Moreover, since $\mathcal{S}$ grows
exponentially with $L$ and $T$, we propose heuristics-including conditional and
deep-learning based approaches-that exploit these structural insights while
maintaining low computational complexity.

</details>


### [113] [Incorporating Social Awareness into Control of Unknown Multi-Agent Systems: A Real-Time Spatiotemporal Tubes Approach](https://arxiv.org/abs/2510.25597)
*Siddhartha Upadhyay,Ratnangshu Das,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 提出了一种结合社会意识的分散式控制框架，用于具有未知动态的多智能体系统，在动态环境中实现规定时间的到达-避障-停留任务。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统缺乏对社会行为的建模，无法处理异构社会行为（合作与自利）的智能体在动态环境中的协调控制问题。

Method: 基于时空管框架，提出实时STT框架，为每个智能体在线合成时空管，同时捕捉其与其他智能体的社会交互。推导出闭式、无近似的控制律，确保智能体在其演化的STT内运动。

Result: 该方法能够确保智能体在规定时间内到达目标，同时避免动态障碍物和智能体间碰撞，以社会意识的方式实现协调。

Conclusion: 所提出的方法提供了安全和时序的正式保证，计算轻量、无模型且对未知干扰具有鲁棒性，通过仿真和硬件实验验证了其有效性和可扩展性。

Abstract: This paper presents a decentralized control framework that incorporates
social awareness into multi-agent systems with unknown dynamics to achieve
prescribed-time reach-avoid-stay tasks in dynamic environments. Each agent is
assigned a social awareness index that quantifies its level of cooperation or
self-interest, allowing heterogeneous social behaviors within the system.
Building on the spatiotemporal tube (STT) framework, we propose a real-time STT
framework that synthesizes tubes online for each agent while capturing its
social interactions with others. A closed-form, approximation-free control law
is derived to ensure that each agent remains within its evolving STT, thereby
avoiding dynamic obstacles while also preventing inter-agent collisions in a
socially aware manner, and reaching the target within a prescribed time. The
proposed approach provides formal guarantees on safety and timing, and is
computationally lightweight, model-free, and robust to unknown disturbances.
The effectiveness and scalability of the framework are validated through
simulation and hardware experiments on a 2D omnidirectional

</details>


### [114] [An OPF-based Control Framework for Hybrid AC-MTDC Power Systems under Uncertainty](https://arxiv.org/abs/2510.25671)
*Hongjin Du,Rahul Rane,Weijie Xia,Pedro P. Vergara,Aleksandra Lekić*

Main category: eess.SY

TL;DR: 提出了一种基于预测集成和最优潮流的自适应控制框架，用于解决高比例可再生能源接入下混合AC-HVDC系统的稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 可再生能源（特别是海上风电）的不断增加给混合AC-HVDC系统带来了显著的不确定性，传统控制策略依赖固定设定点且忽略频率偏差，在快速可再生能源波动下可能危及系统稳定性。

Method: 使用随机森林模型生成风速预测，将其集成到时间耦合最优潮流中确定基准换流器设定点，并基于实际运行条件实时调整；开发了同时考虑直流电压和交流频率偏差的自适应下垂控制方案。

Result: 通过硬件在环仿真验证了所提控制框架的有效性，证明其能够确保高比例可再生能源接入下混合AC-HVDC系统的稳定鲁棒运行。

Conclusion: 该预测集成的自适应控制框架能够有效应对可再生能源波动带来的挑战，提高混合AC-HVDC系统的运行稳定性和鲁棒性。

Abstract: The increasing integration of renewable energy, particularly offshore wind,
introduces significant uncertainty into hybrid AC-HVDC systems due to forecast
errors and power fluctuations. Conventional control strategies typically rely
on fixed setpoints and neglect frequency deviations, which can compromise
system stability under rapid renewable variations. To address this challenge,
this paper presents a forecast-integrated, optimal power flow (OPF)-based
adaptive control framework. Wind speed forecasts generated using a Random
Forest model are incorporated into a time-coupled OPF to determine baseline
converter setpoints in anticipation of wind fluctuations, which are further
adjusted in real time based on actual operating conditions. An adaptive droop
control scheme is developed that jointly considers DC voltage and AC frequency
deviations. The effectiveness of the proposed control framework is validated
through hardware-in-the-loop (HIL) simulations, demonstrating its capability to
ensure stable and robust operation of hybrid AC-HVDC systems under high
penetration of renewable energy.

</details>


### [115] [Over 3 kV and Ultra-Low leakage Vertical (011) \b{eta}-Ga2O3 Power Diodes with Engineered Schottky Contact and High-permittivity Dielectric Field Plate](https://arxiv.org/abs/2510.25695)
*Emerson J. Hollar,Esmat Farzana*

Main category: eess.SY

TL;DR: 该论文报道了基于(011)取向β-Ga2O3的功率器件，通过肖特基势垒工程和高介电常数ZrO2场板实现了超过3 kV的击穿电压和超低漏电流。


<details>
  <summary>Details</summary>
Motivation: 开发能够支持kV级垂直β-Ga2O3功率开关的器件，利用(011)取向β-Ga2O3的低背景掺杂和厚漂移层特性，同时通过肖特基势垒工程和场板技术提高击穿电压和降低漏电流。

Method: 采用复合Pt帽/PtOx/Pt(1.5 nm)阳极接触进行肖特基势垒工程，利用PtOx增强反向阻断能力，同时通过薄Pt层实现低开启电压。使用高介电常数ZrO2场板进行边缘电场管理。在同一晶圆上制备共处理的Pt/(011)β-Ga2O3肖特基势垒二极管进行比较研究。

Result: 裸SBD的击穿电压约为1.5 kV，带场板的Pt/(011)β-Ga2O3 SBD击穿电压提高到2.75 kV。通过复合Pt帽/PtOx/Pt(1.5 nm)肖特基接触进一步将场板二极管的击穿电压提升至3.7 kV，同时保持与Pt/(011)β-Ga2O3 SBD相似的开启电压。

Conclusion: 复合Pt帽/PtOx/Pt(1.5 nm)接触的有效隧穿漏电流管理、高介电常数ZrO2场板的边缘电场减小以及(011)β-Ga2O3的有利材料特性相结合，为开发超低漏电流和多kV级垂直(011)β-Ga2O3功率器件提供了一种有前景的策略。

Abstract: We report over 3 kV breakdown voltage and ultra-low leakage (011)
\b{eta}-Ga2O3 power devices utilizing Schottky barrier engineering and
high-permittivity (\k{appa}) dielectric (ZrO2) field plate. The (011)
orientation of \b{eta}-Ga2O3 enabled low background doping and thick drift
layers which are promising to support kV-class vertical \b{eta}-Ga2O3 power
switches. The Schottky barrier engineering was performed with a composite Pt
cap/PtOx/Pt (1.5 nm) anode contact to take advantage of the enhanced reverse
blocking capabilities enabled by PtOx while allowing low turn-on voltage by the
interfacing thin Pt layer. We also performed a systematic study using a
co-processed Pt/(011) \b{eta}-Ga2O3 Schottky barrier diodes (SBDs) on the same
wafer. The bare SBDs revealed a breakdown voltage of ~1.5 kV, while the
field-plate Pt/(011) \b{eta}-Ga2O3 SBDs achieved an increased breakdown voltage
of 2.75 kV owing to the edge field management. Further enhancement of the
breakdown voltage was achieved by tunneling leakage management using composite
Pt cap/PtOx/Pt (1.5 nm) Schottky contacts that ultimately enabled breakdown
voltage of 3.7 kV for the field-plate diodes. Remarkably, the Pt cap/PtOx/Pt
(1.5 nm) Schottky contacts maintained similar turn-on voltage as the Pt/(011)
\b{eta}-Ga2O3 SBDs. The combination of efficient tunneling leakage management
by composite Pt cap/PtOx/Pt (1.5 nm) contacts with similar turn-on voltage,
edge field reduction by high-\k{appa} dielectric ZrO2 field plate, as well as
the advantageous material properties offered by (011) \b{eta}-Ga2O3 demonstrate
a promising strategy for developing ultra-low leakage and multi-kV class
vertical (011) \b{eta}-Ga2O3 power devices.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [116] [Cryogenic Characterization of Ferroelectric Non-volatile Capacitors](https://arxiv.org/abs/2510.25040)
*Madhav Vadlamani,Dyutimoy Chakraborty,Jianwei Jia,Halid Mulaosmanovic,Stefan Duenkel,Sven Beyer,Suman Datta,Shimeng Yu*

Main category: cs.ET

TL;DR: 该论文研究了铁电电容交叉阵列在低温下的性能，通过在28nm工艺平台上表征非易失性电容器，并在低温下模拟电容交叉阵列，实现了更高的有效比特数（约5比特）用于128x128乘累加运算。


<details>
  <summary>Details</summary>
Motivation: 铁电电容交叉阵列虽然解决了电阻交叉阵列的漏电路径和高静态功耗问题，但易受热噪声影响，限制了加权和的有效比特数。降低温度是减少热噪声的直接方法。

Method: 在28nm工艺平台上表征非易失性电容器在低温下的性能，包括存储窗口和ON状态保持特性，然后使用校准后的器件模型在SPICE中模拟低温下的电容交叉阵列。

Result: 在低温下（低至77K），电容交叉阵列实现了更高的有效比特数（约5比特），适用于128x128乘累加运算。

Conclusion: 通过降低温度可以有效减少铁电电容交叉阵列的热噪声，提高有效比特数，为低温环境下实现高精度内存计算提供了可行方案。

Abstract: Ferroelectric-based capacitive crossbar arrays have been proposed for
energy-efficient in-memory computing in the charge domain. They combat the
challenges like sneak paths and high static power faced by resistive crossbar
arrays but are susceptible to thermal noise limiting the effective number of
bits (ENOB) for the weighted sum. A direct way to reduce this thermal noise is
by lowering the temperature as thermal noise is proportional to temperature. In
this work, we first characterize the non-volatile capacitors (nvCaps) on a
foundry 28 nm platform at cryogenic temperatures to evaluate the memory window,
ON state retention as a function of temperature down to 77K, and then use the
calibrated device models to simulate the capacitive crossbar arrays in SPICE at
lower temperatures to demonstrate higher ENOB (~5 bits) for 128x128
multiple-and-accumulate (MAC) operations.

</details>


### [117] [Modulation Schemes for Functionalized Vesicle-based MC Transmitters](https://arxiv.org/abs/2510.25676)
*Teena tom Dieck,Lukas Brand,Sebastian Lotter,Kathrin Castiglione,Robert Schober,Maximilian Schäfer*

Main category: cs.ET

TL;DR: 提出了一种更现实的分子通信发射器模型，考虑了分子释放延迟和生物噪声，并设计了两种调制方案来减轻发射器引起的内存效应。


<details>
  <summary>Details</summary>
Motivation: 现有分子通信研究大多依赖简化的发射器模型，未考虑实际生物硬件的物理和生化限制，需要开发更实用的分子通信系统模型。

Method: 构建了基于功能化囊泡的发射器模型，包含分子释放延迟和发射器噪声，并提出了两种专门设计的调制方案来减轻内存效应。

Result: 数值评估表明，所提出的方案在现实生化约束下提高了通信可靠性，使接收器设计更加简化。

Conclusion: 这项工作为实现物理上可实现的分子通信系统迈出了重要一步，通过直接在发射端减轻内存效应来简化接收器设计。

Abstract: Molecular communication (MC) enables information exchange through the
transmission of signaling molecules (SMs) and holds promise for many innovative
applications. However, most existing MC studies rely on simplified transmitter
(TX) models that do not account for the physical and biochemical limitations of
realistic biological hardware. This work extends previous efforts toward
developing models for practical MC systems by proposing a more realistic TX
model that incorporates the delay in SM release and TX noise introduced by
biological components. Building on this more realistic, functionalized
vesicle-based TX model, we propose two novel modulation schemes specifically
designed for this TX to mitigate TX-induced memory effects that arise from
delayed and imperfectly controllable SM release. The proposed modulation
schemes enable low-complexity receiver designs by mitigating memory effects
directly at the TX. Numerical evaluations demonstrate that the proposed schemes
improve communication reliability under realistic biochemical constraints,
offering an important step toward physically realizable MC systems.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [118] [Merit Network Telescope: Processing and Initial Insights from Nearly 20 Years of Darknet Traffic for Cybersecurity Research](https://arxiv.org/abs/2510.25050)
*Shereen Ismail,Eman Hammad,William Hatcher,Salah Dandan,Ammar Alomari,Michael Spratt*

Main category: cs.SI

TL;DR: 对2005-2025年美国最大网络望远镜收集的未经请求互联网流量进行纵向分析，采用粗到细的方法处理近20年数据，揭示全球威胁活动的长期趋势和周期性流量高峰。


<details>
  <summary>Details</summary>
Motivation: 利用美国最大的网络望远镜收集的长期数据，分析全球威胁活动模式，包括扫描、反射攻击和DDoS活动等关键指标，填补长期网络威胁监测的空白。

Method: 采用粗到细的处理方法：首先通过资源高效的元数据子管道提取总体洞察，然后通过更详细的包头子管道进行细粒度分析，建立两个子管道以实现近20年望远镜数据的可扩展处理。

Result: 揭示了长期趋势和周期性流量高峰，部分归因于全网扫描事件，其他可能与DoS活动相关。提供了2006-2024年的总体观察，并对2024年的流量特征进行了重点分析。

Conclusion: 该研究建立了处理长期网络望远镜数据的可扩展方法，为理解全球网络威胁活动提供了独特的纵向视角，揭示了扫描和DoS活动的长期模式。

Abstract: This paper presents an initial longitudinal analysis of unsolicited Internet
traffic collected between 2005 and 2025 by one of the largest and most
persistent network telescopes in the United States, operated by Merit Network.
The dataset provides a unique view into global threat activity as observed
through scanning and backscatter traffic, key indicators of large-scale probing
behavior, data outages, and ongoing denial-of-service (DoS) campaigns. To
process this extensive archive, coarse-to-fine methodology is adopted in which
general insights are first extracted through a resource-efficient metadata
sub-pipeline, followed by a more detailed packet header sub-pipeline for
finer-grained analysis. The methodology establishes two sub-pipelines to enable
scalable processing of nearly two decades of telescope data and supports
multi-level exploration of traffic dynamics. Initial insights highlight
long-term trends and recurring traffic spikes, some attributable to
Internet-wide scanning events and others likely linked to DoS activities.We
present general observations spanning 2006-2024, with a focused analysis of
traffic characteristics during 2024.

</details>


### [119] [MMM-Fact: A Multimodal, Multi-Domain Fact-Checking Dataset with Multi-Level Retrieval Difficulty](https://arxiv.org/abs/2510.25120)
*Wenyan Xu,Dawei Xiang,Tianqi Ding,Weihai Lu*

Main category: cs.SI

TL;DR: MMM-Fact是一个大规模多模态事实核查基准，包含125,449个事实核查声明（1995-2025年），涵盖多个领域，每个声明都配有完整的事实核查文章和多模态证据（文本、图像、视频、表格），支持复杂证据聚合和纵向分析。


<details>
  <summary>Details</summary>
Motivation: 现有事实核查基准存在不足：主要是单模态（仅文本）、时间跨度短、证据浅层、领域覆盖不均、经常省略完整文章，无法反映模型在真实世界中的能力。

Method: 收集来自四个事实核查网站和一个新闻机构的完整事实核查文章和多模态证据，采用三层检索难度分类（基础1-5个来源、中级6-10个、高级>10个），支持三步真实性分类（真/假/信息不足）。

Result: 主流LLM的基线测试显示MMM-Fact明显比现有资源更难，随着证据复杂性增加，性能会下降。

Conclusion: MMM-Fact提供了一个现实、可扩展的基准，支持透明、可靠的多模态事实核查，能够评估多步骤、跨模态推理能力。

Abstract: Misinformation and disinformation demand fact checking that goes beyond
simple evidence-based reasoning. Existing benchmarks fall short: they are
largely single modality (text-only), span short time horizons, use shallow
evidence, cover domains unevenly, and often omit full articles -- obscuring
models' real-world capability. We present MMM-Fact, a large-scale benchmark of
125,449 fact-checked statements (1995--2025) across multiple domains, each
paired with the full fact-check article and multimodal evidence (text, images,
videos, tables) from four fact-checking sites and one news outlet. To reflect
verification effort, each statement is tagged with a retrieval-difficulty tier
-- Basic (1--5 sources), Intermediate (6--10), and Advanced (>10) -- supporting
fairness-aware evaluation for multi-step, cross-modal reasoning. The dataset
adopts a three-class veracity scheme (true/false/not enough information) and
enables tasks in veracity prediction, explainable fact-checking, complex
evidence aggregation, and longitudinal analysis. Baselines with mainstream LLMs
show MMM-Fact is markedly harder than prior resources, with performance
degrading as evidence complexity rises. MMM-Fact offers a realistic, scalable
benchmark for transparent, reliable, multimodal fact-checking.

</details>


### [120] [Stable Emotional Co-occurrence Patterns Revealed by Network Analysis of Social Media](https://arxiv.org/abs/2510.25204)
*Qianyun Wu,Orr Levy,Yoed N. Kenett,Yukie Sano,Hideki Takayasu,Shlomo Havlin,Misako Takayasu*

Main category: cs.SI

TL;DR: 本研究提出基于网络理论的计算方法，分析社交媒体中情绪网络在危机时期（地震和COVID-19疫苗接种）和非危机时期的动态变化，发现情绪网络结构在人口层面具有稳定性。


<details>
  <summary>Details</summary>
Motivation: 探索危机和正常时期情绪网络如何波动演化，理解人类心理在危机情境下的表现，挑战情绪共现是情境依赖的假设。

Method: 利用日本社交媒体大规模数据，基于情绪相关概念（词汇）的共现构建情绪网络，通过网络理论分析情绪链接强度。

Result: 发现情绪网络结构在不同情境和时间上保持稳定，地震和疫苗接种前时期与紧张相关的情绪链接显著增强，但情绪链接的排名保持高度一致。

Conclusion: 挑战了情绪共现是情境依赖的假设，揭示了情绪的内在结构稳定性，为使用大规模文本数据进行心理研究提供了系统性、可扩展的分析框架。

Abstract: Examining emotion interactions as an emotion network in social media offers
key insights into human psychology, yet few studies have explored how
fluctuations in such emotion network evolve during crises and normal times.
This study proposes a novel computational approach grounded in network theory,
leveraging large-scale Japanese social media data spanning varied crisis events
(earthquakes and COVID-19 vaccination) and non-crisis periods over the past
decade. Our analysis identifies and evaluates links between emotions through
the co-occurrence of emotion-related concepts (words), revealing a stable
structure of emotion network across situations and over time at the population
level. We find that some emotion links (represented as link strength) such as
emotion links associated with Tension are significantly strengthened during
earthquake and pre-vaccination periods. However, the rank of emotion links
remains highly intact. These findings challenge the assumption that emotion
co-occurrence is context-based and offer a deeper understanding of emotions'
intrinsic structure. Moreover, our network-based framework offers a systematic,
scalable method for analyzing emotion co-occurrence dynamics, opening new
avenues for psychological research using large-scale textual data.

</details>


### [121] [Testing Correlation in Graphs by Counting Bounded Degree Motifs](https://arxiv.org/abs/2510.25289)
*Dong Huang,Pengkun Yang*

Main category: cs.SI

TL;DR: 提出了一种基于有界度模体计数的多项式时间测试方法，用于检测两个Erdős-Rényi图之间的相关性，突破了先前方法对相关系数的限制要求。


<details>
  <summary>Details</summary>
Motivation: 相关性分析是从复杂数据集中提取有意义见解的基本步骤。本文研究检测两个Erdős-Rényi图之间相关性的问题，将其构建为假设检验问题：在零假设下两个图独立，在备择假设下它们相关。

Method: 通过计数有界度模体开发多项式时间测试方法，这些模体在真实网络中普遍存在，使得所提出的统计量既自然又可扩展。

Result: 证明了当边连接概率满足p≥n^{-2/3}时，该方法对任何常数相关系数ρ都有效，突破了先前要求ρ≥√α（α≈0.338为Otter常数）的限制。

Conclusion: 该方法在合成和真实共引网络上得到验证，证实这种简单的模体族能有效捕捉相关性信号并展现出强大的实证性能。

Abstract: Correlation analysis is a fundamental step for extracting meaningful insights
from complex datasets. In this paper, we investigate the problem of detecting
correlation between two Erd\H{o}s-R\'enyi graphs $G(n,p)$, formulated as a
hypothesis testing problem: under the null hypothesis, the two graphs are
independent, while under the alternative hypothesis, they are correlated. We
develop a polynomial-time test by counting bounded degree motifs and prove its
effectiveness for any constant correlation coefficient $\rho$ when the edge
connecting probability satisfies $p\ge n^{-2/3}$. Our results overcome the
limitation requiring $\rho \ge \sqrt{\alpha}$, where $\alpha\approx 0.338$ is
the Otter's constant, extending it to any constant $\rho$. Methodologically,
bounded degree motifs -- ubiquitous in real networks -- make the proposed
statistic both natural and scalable. We also validate our method on synthetic
and real co-citation networks, further confirming that this simple motif family
effectively captures correlation signals and exhibits strong empirical
performance.

</details>


### [122] [Large-Scale Network Embedding in Apache Spark](https://arxiv.org/abs/2106.10620)
*Wenqing Lin*

Main category: cs.SI

TL;DR: 提出了一种基于Apache Spark的高效分布式网络嵌入算法，通过递归分区处理大规模图，在保持性能的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统网络嵌入方法无法高效处理大规模图，因为图计算成本高且中间结果过大，难以在单机上处理。

Method: 使用Apache Spark分布式框架，递归将大图划分为多个小规模子图，并行计算每个子图的网络嵌入，最后聚合得到完整节点嵌入。

Result: 能够在几小时内处理数十亿边的大图，比现有方法快4倍以上，在链接预测和节点分类任务上分别提升4.25%和4.27%。

Conclusion: 该分布式算法在腾讯在线游戏中成功部署，用于好友推荐和物品推荐，运行时间减少91.11%，评估指标提升12.80%。

Abstract: Network embedding has been widely used in social recommendation and network
analysis, such as recommendation systems and anomaly detection with graphs.
However, most of previous approaches cannot handle large graphs efficiently,
due to that (i) computation on graphs is often costly and (ii) the size of
graph or the intermediate results of vectors could be prohibitively large,
rendering it difficult to be processed on a single machine. In this paper, we
propose an efficient and effective distributed algorithm for network embedding
on large graphs using Apache Spark, which recursively partitions a graph into
several small-sized subgraphs to capture the internal and external structural
information of nodes, and then computes the network embedding for each subgraph
in parallel. Finally, by aggregating the outputs on all subgraphs, we obtain
the embeddings of nodes in a linear cost. After that, we demonstrate in various
experiments that our proposed approach is able to handle graphs with billions
of edges within a few hours and is at least 4 times faster than the
state-of-the-art approaches. Besides, it achieves up to $4.25\%$ and $4.27\%$
improvements on link prediction and node classification tasks respectively. In
the end, we deploy the proposed algorithms in two online games of Tencent with
the applications of friend recommendation and item recommendation, which
improve the competitors by up to $91.11\%$ in running time and up to $12.80\%$
in the corresponding evaluation metrics.

</details>
