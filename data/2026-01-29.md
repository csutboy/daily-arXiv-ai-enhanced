<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 25]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.CY](#cs.CY) [Total: 8]
- [stat.AP](#stat.AP) [Total: 3]
- [econ.EM](#econ.EM) [Total: 3]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [NeuroAI and Beyond](https://arxiv.org/abs/2601.19955)
*Jean-Marc Fellous,Gert Cauwenberghs,Cornelia Fermüller,Yulia Sandamisrkaya,Terrence Sejnowski*

Main category: cs.AI

TL;DR: 这篇论文基于2025年8月的研讨会，探讨了神经科学与人工智能之间的协同作用，提出了NeuroAI概念，并分析了其发展前景和风险。


<details>
  <summary>Details</summary>
Motivation: 神经科学和人工智能在过去几年都取得了显著进展，但两者之间的连接仍然松散。论文旨在识别这两个领域当前和未来的协同领域，促进更紧密的交叉融合。

Method: 基于2025年8月举办的研讨会，聚焦于具身性、语言与通信、机器人学、人类与机器学习、神经形态工程等子领域，评估现有进展并探索未来方向。收集了多位领先研究人员的个人观点，并附上了研究人员和学员进行的SWOT分析。

Result: 提出了NeuroAI概念——一种神经科学启发的人工智能，认为这种交叉融合能够显著提高AI算法的范围和效率，同时改变我们对生物神经计算的理解方式。通过SWOT分析描述了NeuroAI的益处和风险。

Conclusion: 倡导发展NeuroAI，认为这种神经科学启发的人工智能具有巨大潜力，既能提升AI算法的性能，又能深化对生物神经系统的理解，但需要认识到其中的机遇和风险。

Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.

</details>


### [2] [Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning](https://arxiv.org/abs/2601.20014)
*Shuhui Qu*

Main category: cs.AI

TL;DR: SQ-BCP是一种在部分可观测环境下进行推理时规划的方法，通过显式表示前提条件状态、自我查询和桥接假设来解决LLM规划中的幻觉问题，确保找到的规划与目标要求兼容。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在部分可观测环境下进行推理时规划经常失败：当任务关键前提条件未在查询时指定时，模型容易产生幻觉或违反硬约束的规划。

Method: 引入自我查询双向分类规划(SQ-BCP)：显式表示前提条件状态(Sat/Viol/Unk)，通过(1)向预言机/用户进行针对性自我查询，或(2)通过额外动作建立缺失条件的桥接假设来解决未知状态。采用双向搜索，使用基于拉回的验证器作为目标兼容性的分类证书，距离分数仅用于排序和剪枝。

Result: 在WikiHow和RecipeNLG任务中，当预条件被保留时，SQ-BCP将资源违规率分别降低到14.9%和5.8%（最佳基线为26.0%和15.7%），同时保持竞争力的参考质量。

Conclusion: SQ-BCP在验证器成功且硬约束通过确定性检查时，能够保证接受的规划与目标要求兼容；在有界分支和有限解析深度下，当存在接受规划时，SQ-BCP能够找到它。该方法显著减少了部分可观测环境下的规划违规。

Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \textbf{14.9\%} and \textbf{5.8\%} (vs.\ \textbf{26.0\%} and \textbf{15.7\%} for the best baseline), while maintaining competitive reference quality.

</details>


### [3] [Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints](https://arxiv.org/abs/2601.20021)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 提出模糊范畴论规划(FCP)，通过模糊逻辑处理自然语言规划中的模糊谓词，使用t-范数组合计划质量，同时保持可执行性的精确验证


<details>
  <summary>Details</summary>
Motivation: 自然语言规划常涉及模糊谓词（如"合适的替代品"、"足够稳定"），现有范畴论规划器将适用性视为二元判断，需要阈值处理，这会丢失有意义的区别，且无法跟踪多步计划中的质量退化

Method: FCP为每个动作（态射）标注[0,1]区间内的程度值，使用Łukasiewicz t-范数组合计划质量，通过拉回验证保持精确可执行性检查，使用LLM进行分级适用性基础化，并支持基于剩余的后向需求中间相遇搜索

Result: 在RecipeNLG-Subs基准测试中，FCP相比LLM-only和ReAct风格基线提高了成功率并减少了硬约束违反，同时与经典PDDL3规划器保持竞争力

Conclusion: FCP成功地将模糊逻辑集成到范畴论规划中，有效处理自然语言规划中的模糊谓词，在保持可执行性验证的同时跟踪计划质量退化

Abstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.

</details>


### [4] [Insight Agents: An LLM-Based Multi-Agent System for Data Insights](https://arxiv.org/abs/2601.20048)
*Jincheng Bai,Zhenyu Zhang,Jennifer Zhang,Zhihuai Zhu*

Main category: cs.AI

TL;DR: 开发了Insight Agents（IA）对话式多代理数据洞察系统，帮助电商卖家通过自动化信息检索获取个性化数据和业务洞察，已在亚马逊美国卖家上线，准确率达90%，延迟P90低于15秒。


<details>
  <summary>Details</summary>
Motivation: 电商卖家面临两大挑战：1）难以发现和有效利用可用程序和工具；2）难以理解和利用来自各种工具的丰富数据。因此需要开发一个系统来降低卖家决策所需努力，加快决策速度。

Method: 采用基于LLM的端到端代理系统，基于计划-执行范式。采用分层多代理结构：管理代理（使用轻量级编码器-解码器模型进行OOD检测和基于BERT的分类器进行代理路由）和两个工作代理（数据呈现和洞察生成）。在数据呈现代理中使用API数据模型进行战略规划，在洞察生成代理中动态注入领域知识。

Result: 系统已在亚马逊美国卖家上线，基于人工评估的准确率达到90%，延迟P90低于15秒，实现了高准确率和低延迟的目标。

Conclusion: Insight Agents作为电商卖家的力量倍增器，通过减少决策所需努力和加快决策速度，成功推动了卖家的增量采用。该系统展示了分层多代理架构在提供个性化数据洞察方面的有效性。

Abstract: Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this novel LLM-backed end-to-end agentic system built on a plan-and-execute paradigm and designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 90% based on human evaluation, with latency of P90 below 15s.

</details>


### [5] [Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control](https://arxiv.org/abs/2601.20090)
*Amirmohammad Farzaneh,Salvatore D'Oro,Osvaldo Simeone*

Main category: cs.AI

TL;DR: 论文提出CCG框架，通过结构因果模型和概率溯因进行反事实推理，为LLM驱动的智能体控制提供形式化可靠性保证


<details>
  <summary>Details</summary>
Motivation: 当用户观察LLM智能体执行结果后，可能会思考：如果我用不同方式表达意图会怎样？现有方法缺乏对这种反事实推理的形式化可靠性保证

Method: 将用户、LLM智能体和环境的闭环交互建模为结构因果模型，利用测试时缩放通过概率溯因生成多个候选反事实结果，通过离线校准阶段实现保形反事实生成

Result: 在无线网络控制用例中展示CCG性能，相比简单的重新执行基线方法具有显著优势

Conclusion: CCG框架能够为LLM驱动的智能体控制场景提供可靠的反事实推理，具有形式化保证和实际应用价值

Abstract: Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enables such counterfactual reasoning in agentic LLM-driven control scenarios, while providing formal reliability guarantees. Our approach models the closed-loop interaction between a user, an LLM-based agent, and an environment as a structural causal model (SCM), and leverages test-time scaling to generate multiple candidate counterfactual outcomes via probabilistic abduction. Through an offline calibration phase, the proposed conformal counterfactual generation (CCG) yields sets of counterfactual outcomes that are guaranteed to contain the true counterfactual outcome with high probability. We showcase the performance of CCG on a wireless network control use case, demonstrating significant advantages compared to naive re-execution baselines.

</details>


### [6] [Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis](https://arxiv.org/abs/2601.20206)
*Zixuan Xiao,Chunguang Hu,Jun Ma*

Main category: cs.AI

TL;DR: 提出多模态LLM智能体框架，用于城市新建公园发展监测，通过数据对齐机制和领域工具包解决传统遥感方法的局限性


<details>
  <summary>Details</summary>
Motivation: 传统基于遥感影像的变化检测方法在高层次智能分析方面存在明显局限，难以满足当前城市规划管理的需求，特别是在处理复杂多模态数据时缺乏灵活分析能力

Method: 提出多模态LLM智能体框架，设计通用的横向和纵向数据对齐机制确保多模态数据一致性，构建特定工具包缓解LLM因缺乏领域知识而产生的幻觉问题

Result: 相比vanilla GPT-4o和其他智能体，该方法能够实现稳健的多模态信息融合与分析，为城市公园发展监测提供可靠且可扩展的解决方案

Conclusion: 该多模态LLM智能体框架充分利用LLM的语义理解和推理能力，有效应对城市公园发展监测中的挑战，满足多样化和不断变化的需求

Abstract: As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on remote sensing imagery have obvious limitations in high-level and intelligent analysis, and thus are difficult to meet the requirements of current urban planning and management. In face of the growing demand for complex multi-modal data analysis in urban park development monitoring, these methods often fail to provide flexible analysis capabilities for diverse application scenarios. This study proposes a multi-modal LLM agent framework, which aims to make full use of the semantic understanding and reasoning capabilities of LLM to meet the challenges in urban park development monitoring. In this framework, a general horizontal and vertical data alignment mechanism is designed to ensure the consistency and effective tracking of multi-modal data. At the same time, a specific toolkit is constructed to alleviate the hallucination issues of LLM due to the lack of domain-specific knowledge. Compared to vanilla GPT-4o and other agents, our approach enables robust multi-modal information fusion and analysis, offering reliable and scalable solutions tailored to the diverse and evolving demands of urban park development monitoring.

</details>


### [7] [Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.20221)
*Hang Zhang,Ruheng Wang,Yuelyu Ji,Mingu Kwak,Xizhi Wu,Chenyu Li,Li Zhang,Wenqi Shi,Yifan Peng,Yanshan Wang*

Main category: cs.AI

TL;DR: 提出MethoD框架，通过迭代查询外部医学语料库来验证医学推理，结合工具增强验证和迭代强化学习，显著提升医学推理准确性并大幅降低采样成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学推理基准上表现良好，但在临床部署中需要严格验证以确保事实准确性。现有奖励模型方法存在两个局限：仅提供标量奖励值而无明确理由，且依赖单次检索无法在验证过程中进行自适应知识访问。

Method: 提出MethoD框架，训练医学推理验证器在评估过程中迭代查询外部医学语料库。结合工具增强验证和迭代强化学习范式（仅需轨迹级监督），并采用自适应课程机制动态调整训练数据分布。

Result: 在四个医学推理基准测试中，MethoD相比现有方法取得显著提升：MedQA准确率相对基础生成器提高23.5%，MedXpertQA提高32.0%。最重要的是，相比先前奖励模型基线，采样预算需求降低了8倍。

Conclusion: 基于动态检索证据的验证为构建更可靠的医学推理系统提供了原则性路径，证明了将验证过程扎根于外部知识库的有效性。

Abstract: Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\method$ demonstrates an $\mathbf{8\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.

</details>


### [8] [Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models](https://arxiv.org/abs/2601.20305)
*Zhenchen Tang,Songlin Yang,Zichuan Wang,Bo Peng,Yang Li,Beibei Dong,Jing Dong*

Main category: cs.AI

TL;DR: SEER框架通过内生重提示机制，将统一多模态模型的理解能力转化为生成过程的显式推理步骤，仅需少量样本训练即可显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型虽然具备强大的理解能力，但这种理解往往无法有效指导生成过程，存在"认知鸿沟"问题。模型缺乏如何改进自身生成过程的理解。

Method: 提出内生重提示机制，将被动编码的理解过程转化为显式生成推理步骤。SEER框架建立两阶段内生循环：1) RLVR通过课程学习激活模型的潜在评估能力，产生高保真内生奖励信号；2) RLMT利用该信号优化生成推理策略。仅需300个视觉指令细化任务的样本。

Result: SEER在评估准确性、重提示效率和生成质量方面均优于最先进的基线方法，且不牺牲通用多模态能力。

Conclusion: 内生重提示机制能有效弥合统一多模态模型的理解与生成之间的认知鸿沟，SEER框架通过少量样本训练即可显著提升模型的生成指导能力。

Abstract: Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.

</details>


### [9] [ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue](https://arxiv.org/abs/2601.20323)
*Hyunseung Chung,Jungwoo Oh,Daeun Kyung,Jiho Kim,Yeonsu Kwon,Min-Gyu Kim,Edward Choi*

Main category: cs.AI

TL;DR: ECG-Agent：首个基于LLM的工具调用代理，用于多轮心电图对话，解决现有模型缺乏多轮对话能力、设备端效率和精确ECG测量理解的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在ECG应用中存在局限：缺乏多轮对话能力、设备端效率不足、对PQRST间隔等ECG测量理解不精确，无法满足真实世界应用需求。

Method: 1. 提出ECG-Agent，首个基于LLM的工具调用代理用于多轮ECG对话；2. 构建ECG-MTD数据集，包含真实用户-助手多轮对话；3. 开发不同规模的ECG-Agent，从设备端可运行到大型代理。

Result: ECG-Agent在响应准确性上优于基线ECG-LLM；设备端代理在响应准确性、工具调用能力和幻觉评估方面与大型代理表现相当，证明其实际应用可行性。

Conclusion: ECG-Agent通过工具调用和多轮对话能力，解决了现有ECG-LLM的局限性，设备端代理的可行性能推动ECG分析在真实临床环境中的应用。

Abstract: Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conversational ability, on-device efficiency, and precise understanding of ECG measurements such as the PQRST intervals. To address these limitations, we introduce ECG-Agent, the first LLM-based tool-calling agent for multi-turn ECG dialogue. To facilitate its development and evaluation, we also present ECG-Multi-Turn-Dialogue (ECG-MTD) dataset, a collection of realistic user-assistant multi-turn dialogues for diverse ECG lead configurations. We develop ECG-Agents in various sizes, from on-device capable to larger agents. Experimental results show that ECG-Agents outperform baseline ECG-LLMs in response accuracy. Furthermore, on-device agents achieve comparable performance to larger agents in various evaluations that assess response accuracy, tool-calling ability, and hallucinations, demonstrating their viability for real-world applications.

</details>


### [10] [AMA: Adaptive Memory via Multi-Agent Collaboration](https://arxiv.org/abs/2601.20352)
*Weiquan Huang,Zixuan Wang,Hehai Lin,Sudong Wang,Bo Xu,Qian Li,Beier Zhu,Linyi Yang,Chengwei Qin*

Main category: cs.AI

TL;DR: AMA框架通过多智能体协作实现自适应记忆管理，显著提升长上下文任务性能并减少80%的token消耗


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体记忆系统存在检索粒度僵化、维护策略累积过重、更新机制粗糙等问题，导致存储信息与任务需求不匹配，以及逻辑不一致性随时间累积

Method: 提出AMA框架，采用分层记忆设计，通过Constructor和Retriever实现多粒度记忆构建和自适应查询路由，Judge验证相关性和一致性，Refresher执行针对性更新或删除过时条目

Result: 在挑战性长上下文基准测试中，AMA显著优于现有最先进基线，同时相比全上下文方法减少约80%的token消耗

Conclusion: AMA框架通过多智能体协作有效解决了记忆系统的粒度对齐和一致性维护问题，在保持检索精度和长期记忆一致性方面表现出色

Abstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.

</details>


### [11] [Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution](https://arxiv.org/abs/2601.20379)
*Zhengbo Jiao,Hongyu Xian,Qinglong Wang,Yunpu Ma,Zhebo Wang,Zifan Zhang,Dezhang Kong,Meng Han*

Main category: cs.AI

TL;DR: PoT框架通过在线优化策略，利用执行反馈动态调整推理策略，显著提升LLM在复杂任务上的表现


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂长程推理中存在困难，现有方法仅将执行反馈作为外部信号用于轨迹过滤或重写，未能内部化反馈来改进底层推理策略

Method: 提出Policy of Thoughts (PoT)框架，将推理重构为实例内在线优化过程：1) 通过高效探索机制生成多样化候选解；2) 使用Group Relative Policy Optimization (GRPO)基于执行反馈更新瞬态LoRA适配器

Result: PoT显著提升性能：4B参数模型在LiveCodeBench上达到49.71%准确率，超越GPT-4o和DeepSeek-V3，尽管模型规模小50倍以上

Conclusion: PoT框架通过实时演化模型策略、从失败尝试中学习，实现了动态、实例特定的推理先验优化，为LLM复杂推理提供了新范式

Abstract: Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of "conjectures and refutations," we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.

</details>


### [12] [OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution](https://arxiv.org/abs/2601.20380)
*Le Zhang,Yixiong Xiao,Xinjiang Lu,Jingjia Cao,Yusai Zhao,Jingbo Zhou,Lang An,Zikan Feng,Wanxiang Sha,Yu Shi,Congxi Xiao,Jian Xiong,Yankai Zhang,Hua Wu,Haifeng Wang*

Main category: cs.AI

TL;DR: OmegaUse是一个通用GUI代理模型，支持移动和桌面平台，通过高质量数据构建和两阶段训练方法实现跨终端自主任务执行，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: GUI代理具有改变人机交互、提升生产力的潜力，但构建有效GUI代理需要解决高质量数据和有效训练方法两个关键问题。

Method: 采用精心设计的数据构建管道（结合开源数据集和自动化合成框架）和两阶段训练策略（SFT建立基础交互语法，GRPO改进空间定位和序列规划），基于MoE架构平衡计算效率与推理能力。

Result: 在多个GUI基准测试中表现优异：ScreenSpot-V2达到96.3%（SOTA），AndroidControl达到79.1%步骤成功率，OS-Nav基准中ChiM-Nav达到74.24%步骤成功率，Ubu-Nav达到55.9%平均成功率。

Conclusion: OmegaUse是一个强大的通用GUI代理模型，通过创新的数据构建和训练方法，在跨终端任务执行方面展现出卓越性能，为GUI代理发展提供了有效解决方案。

Abstract: Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on both mobile and desktop platforms, supporting computer-use and phone-use scenarios. Building an effective GUI agent model relies on two factors: (1) high-quality data and (2) effective training methods. To address these, we introduce a carefully engineered data-construction pipeline and a decoupled training paradigm. For data construction, we leverage rigorously curated open-source datasets and introduce a novel automated synthesis framework that integrates bottom-up autonomous exploration with top-down taxonomy-guided generation to create high-fidelity synthetic data. For training, to better leverage these data, we adopt a two-stage strategy: Supervised Fine-Tuning (SFT) to establish fundamental interaction syntax, followed by Group Relative Policy Optimization (GRPO) to improve spatial grounding and sequential planning. To balance computational efficiency with agentic reasoning capacity, OmegaUse is built on a Mixture-of-Experts (MoE) backbone. To evaluate cross-terminal capabilities in an offline setting, we introduce OS-Nav, a benchmark suite spanning multiple operating systems: ChiM-Nav, targeting Chinese Android mobile environments, and Ubu-Nav, focusing on routine desktop interactions on Ubuntu. Extensive experiments show that OmegaUse is highly competitive across established GUI benchmarks, achieving a state-of-the-art (SOTA) score of 96.3% on ScreenSpot-V2 and a leading 79.1% step success rate on AndroidControl. OmegaUse also performs strongly on OS-Nav, reaching 74.24% step success on ChiM-Nav and 55.9% average success on Ubu-Nav.

</details>


### [13] [CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning](https://arxiv.org/abs/2601.20467)
*Zhenxuan Fan,Jie Cao,Yang Dai,Zheqi Lv,Wenqiao Zhang,Zhongle Xie,Peng LU,Beng Chin Ooi*

Main category: cs.AI

TL;DR: CtrlCoT是一个双粒度CoT压缩框架，通过分层推理抽象、逻辑保留蒸馏和分布对齐生成，在减少30.7%token的同时提升7.6%准确率。


<details>
  <summary>Details</summary>
Motivation: 传统CoT提示存在高延迟和内存成本问题，现有压缩方法要么过于保守（语义级缩短），要么过于激进（token级剪枝），且两者结合困难。

Method: 提出CtrlCoT框架：1）分层推理抽象生成多粒度语义CoT；2）逻辑保留蒸馏训练逻辑感知剪枝器保留关键推理线索；3）分布对齐生成确保压缩轨迹与推理风格一致。

Result: 在MATH-500数据集上使用Qwen2.5-7B-Instruct模型，CtrlCoT减少30.7%token使用，同时比最强基线提升7.6个百分点准确率。

Conclusion: CtrlCoT通过协调语义抽象和token级剪枝，实现了更高效可靠的推理，解决了现有CoT压缩方法的局限性。

Abstract: Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.

</details>


### [14] [Normative Equivalence in human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups](https://arxiv.org/abs/2601.20487)
*Nico Mutzner,Taha Yasseri,Heiko Rauhut*

Main category: cs.AI

TL;DR: 研究发现在混合人-AI群体中，合作规范机制与全人类群体相同，AI身份标签不影响合作水平，支持"规范等价性"模式


<details>
  <summary>Details</summary>
Motivation: 探索AI代理如何影响小群体中合作规范的出现和维持，填补现有研究主要关注二元互动而忽视群体动态的空白

Method: 在线实验使用重复四玩家公共物品游戏，每组包含3名人类参与者和1个机器人，机器人被标记为人类或AI，并采用三种预定决策策略之一

Result: 合作主要由互惠群体动态和行为惯性驱动，这些规范机制在不同条件下运作相同，人类和AI标签间的合作水平无显著差异，后续囚徒困境中规范持续性也无差异

Conclusion: 合作规范足够灵活，可以扩展到人工智能代理，模糊了人类与AI在集体决策中的边界，支持"规范等价性"模式

Abstract: The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner's Dilemma, or in participants' normative perceptions. Participants' behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making.

</details>


### [15] [PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs](https://arxiv.org/abs/2601.20539)
*Oguzhan Gungordu,Siheng Xiong,Faramarz Fekri*

Main category: cs.AI

TL;DR: PathWise是一个基于多智能体推理的自动启发式设计框架，通过世界模型规划和自我演化LLMs来解决组合优化问题，相比现有方法收敛更快、效果更好。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLMs的自动启发式设计框架依赖固定的演化规则和静态提示模板，导致启发式生成短视、评估冗余，且缺乏对新启发式如何推导的推理能力。

Method: 提出PathWise多智能体推理框架：1) 将启发式生成建模为基于蕴涵图的序列决策过程；2) 策略智能体规划演化动作；3) 世界模型智能体基于动作生成启发式推演；4) 评论智能体提供路由反射总结先前步骤的经验教训。

Result: 实验表明PathWise在各种组合优化问题上能更快收敛到更好的启发式，在不同LLM骨干上具有良好泛化性，并能扩展到更大规模问题。

Conclusion: PathWise将基于LLM的自动启发式设计从试错演化转向基于状态感知的推理规划，通过多智能体协作和记忆机制显著提升了启发式设计的效率和质量。

Abstract: Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.

</details>


### [16] [Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function](https://arxiv.org/abs/2601.20554)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: 本文研究了部分可观测环境下的风险敏感规划，使用动态风险度量ICVaR，开发了具有有限时间性能保证的策略评估算法，并扩展了三种在线规划算法来优化ICVaR值函数而非期望回报。


<details>
  <summary>Details</summary>
Motivation: 传统的部分可观测马尔可夫决策过程（POMDP）规划通常优化期望回报，但在实际应用中需要考虑风险规避，特别是在安全关键领域。现有风险敏感规划方法在部分可观测环境中的研究有限，需要开发能够处理尾部风险的方法。

Method: 1. 开发了ICVaR策略评估算法，具有不依赖于动作空间大小的有限时间性能保证；2. 扩展了三种在线规划算法：稀疏采样、带双重渐进扩展的粒子滤波器树（PFT-DPW）、带观测扩展的部分可观测蒙特卡洛规划（POMCPOW），使其优化ICVaR值函数；3. 引入风险参数α，α=1恢复标准期望规划，α<1增加风险规避程度；4. 为ICVaR稀疏采样建立了风险敏感目标下的有限时间性能保证。

Result: 在基准POMDP领域上的实验表明，提出的ICVaR规划器相比风险中性对应方法实现了更低的尾部风险。ICVaR稀疏采样获得了理论性能保证，并启发了针对ICVaR的新探索策略。

Conclusion: 本文成功将风险敏感规划扩展到部分可观测环境，通过ICVaR动态风险度量实现了有效的风险规避。提出的方法在理论和实验上都表现出色，为安全关键的部分可观测决策问题提供了实用的解决方案。

Abstract: We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $α$, where $α= 1$ recovers standard expectation-based planning and $α< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.

</details>


### [17] [Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies](https://arxiv.org/abs/2601.20604)
*Gray Cox*

Main category: cs.AI

TL;DR: 论文提出基于和平研究传统的多模型对话框架，通过角色分配测试AI对齐策略，发现不同模型能有效参与复杂对齐讨论并产生新见解。


<details>
  <summary>Details</summary>
Motivation: 将AI对齐从控制问题重构为关系问题，借鉴和平研究传统（基于利益的谈判、冲突转化、公共资源治理），通过结构化多模型对话实证测试对齐策略。

Method: 设计六种实验条件，为Claude、Gemini和GPT-4o分配四种角色（提议者、响应者、监督者、翻译者），进行72轮对话（总计576,822字符）的结构化交流。

Result: AI系统能有效参与和平研究概念讨论，从不同架构视角提出互补性反对意见，并产生新见解（如"VCW作为过渡框架"）。不同模型关注点不同：Claude强调验证挑战，Gemini关注偏见和可扩展性，GPT-4o突出实施障碍。

Conclusion: 该框架为研究人员提供了在实施前压力测试对齐提案的可复制方法，初步证据表明AI具备对话推理能力。但对话更多关注过程元素而非AI本质的基础主张，未来研究可探索人-AI混合协议和扩展对话研究。

Abstract: This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.
  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.
  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of "VCW as transitional framework." Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.
  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.

</details>


### [18] [Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation](https://arxiv.org/abs/2601.20614)
*Yanqi Dai,Yuxiang Ji,Xiao Zhang,Yong Wang,Xiangxiang Chu,Zhiwu Lu*

Main category: cs.AI

TL;DR: 提出MathForge框架，通过难度感知组策略优化(DGPO)和多方面问题重构(MQR)双管齐下，针对数学推理中的难题进行优化，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在算法和数据层面都缺乏对更难题目的关注。算法上，GRPO存在隐式不平衡，对难题的策略更新幅度较小；数据上，增强方法主要重述问题而非系统增加内在难度。

Method: 提出MathForge框架：1) DGPO算法：通过难度平衡组优势估计纠正GRPO的不平衡，并通过难度感知问题级权重优先处理难题；2) MQR策略：从多个方面重构问题以增加难度，同时保持原始正确答案。

Result: 在多种数学推理任务上，MathForge显著优于现有方法。MQR扩展数据边界，DGPO有效学习增强数据，形成协同循环。

Conclusion: MathForge通过算法和数据的双重改进，有效针对数学推理中的难题进行优化，为强化学习在数学推理中的应用提供了新思路。代码和增强数据已开源。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.

</details>


### [19] [Investigating the Development of Task-Oriented Communication in Vision-Language Models](https://arxiv.org/abs/2601.20641)
*Boaz Carmeli,Orr Paradise,Shafi Goldwasser,Yonatan Belinkov,Ron Meir*

Main category: cs.AI

TL;DR: LLM智能体能在协作推理任务中发展出不同于自然语言的任务导向通信协议，这些协议具有高效性和隐蔽性，引发透明度与控制担忧。


<details>
  <summary>Details</summary>
Motivation: 研究LLM智能体是否能发展出任务导向的通信协议，这些协议可能比自然语言更高效，同时可能变得难以被外部观察者解读，从而引发透明度和控制方面的担忧。

Method: 使用指称游戏框架，让视觉语言模型（VLM）智能体进行通信，为评估语言变体提供可控、可测量的环境。

Result: 实验表明VLM能发展出有效、适应任务的通信模式，同时也能发展出对人类和外部智能体难以解读的隐蔽协议。还观察到相似模型之间无需显式共享协议就能自发协调。

Conclusion: 这些发现凸显了任务导向通信的潜力和风险，并将指称游戏定位为该领域未来工作的有价值测试平台。

Abstract: We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.

</details>


### [20] [Enterprise Resource Planning Using Multi-type Transformers in Ferro-Titanium Industry](https://arxiv.org/abs/2601.20696)
*Samira Yazdanpourmoghadam,Mahan Balal Pour,Vahid Partovi Nia*

Main category: cs.AI

TL;DR: 本文提出使用多类型Transformer（MTT）架构统一解决作业车间调度和背包问题，在标准基准测试中取得竞争性性能，并首次将多类型Transformer应用于实际制造业场景。


<details>
  <summary>Details</summary>
Motivation: 作业车间调度和背包问题等组合优化问题是运筹学、物流和企业资源规划中的基础挑战，传统方法需要复杂算法在有限时间内获得近似最优解。深度学习特别是Transformer架构为替代传统启发式方法提供了新可能。

Method: 采用多类型Transformer（MTT）架构，构建统一框架处理不同类型的组合优化问题。通过多类型注意力机制，模型能够同时处理不同规模的标准基准数据集。

Result: 在JSP和KP的标准基准数据集上进行广泛实验评估，MTT在不同规模问题上均表现出竞争性性能。首次将多类型Transformer应用于实际制造业（铁钛合金行业），展示了其实际应用潜力。

Conclusion: 多类型Transformer为组合优化问题提供了有效的统一解决方案，在标准基准测试中表现优异，并成功应用于实际制造业场景，证明了深度学习在传统运筹学问题中的实用价值。

Abstract: Combinatorial optimization problems such as the Job-Shop Scheduling Problem (JSP) and Knapsack Problem (KP) are fundamental challenges in operations research, logistics, and eterprise resource planning (ERP). These problems often require sophisticated algorithms to achieve near-optimal solutions within practical time constraints. Recent advances in deep learning have introduced transformer-based architectures as promising alternatives to traditional heuristics and metaheuristics. We leverage the Multi-Type Transformer (MTT) architecture to address these benchmarks in a unified framework. We present an extensive experimental evaluation across standard benchmark datasets for JSP and KP, demonstrating that MTT achieves competitive performance on different size of these benchmark problems. We showcase the potential of multi-type attention on a real application in Ferro-Titanium industry. To the best of our knowledge, we are the first to apply multi-type transformers in real manufacturing.

</details>


### [21] [Implementing Metric Temporal Answer Set Programming](https://arxiv.org/abs/2601.20735)
*Arvid Becker,Pedro Cabalar,Martin Diéguez,Susana Hahn,Javier Romero,Torsten Schaub*

Main category: cs.AI

TL;DR: 提出一种计算性方法处理度量答案集编程，通过差异约束处理时间相关约束，避免时间粒度对性能的影响


<details>
  <summary>Details</summary>
Motivation: 传统度量ASP在处理细粒度时间约束时面临可扩展性问题，特别是时间精度会显著加剧ASP的接地瓶颈

Method: 利用ASP的差异约束扩展来处理时间相关方面，将度量ASP与时间粒度解耦，外部处理时间约束

Result: 开发出一种不受时间精度影响的解决方案，有效解决了度量ASP在处理定量时间约束时的可扩展性问题

Conclusion: 通过差异约束外部处理时间约束的方法，成功实现了度量ASP与时间粒度的解耦，提高了处理定量时间约束的可扩展性

Abstract: We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.

</details>


### [22] [REASON: Accelerating Probabilistic Logical Reasoning for Scalable Neuro-Symbolic Intelligence](https://arxiv.org/abs/2601.20784)
*Zishen Wan,Che-Kai Liu,Jiayi Qian,Hanchen Yang,Arijit Raychowdhury,Tushar Krishna*

Main category: cs.AI

TL;DR: REASON是一个用于神经符号AI中概率逻辑推理的加速框架，通过统一的DAG表示、自适应剪枝和树状处理架构，实现了12-50倍的速度提升和310-681倍的能效提升。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI系统虽然结合了神经感知和符号推理的优势，但在实际部署中面临严重效率问题，特别是概率逻辑推理成为性能瓶颈，在CPU和GPU上存在控制流不规则、算术强度低、内存访问不连续和硬件利用率差等问题。

Method: REASON框架采用统一的DAG表示捕获符号和概率模型的共同结构，结合自适应剪枝和正则化。架构层面采用可重构的树状处理结构优化不规则遍历、符号演绎和概率聚合。系统层面通过可编程接口和多级流水线与GPU流式多处理器紧密集成。

Result: 在六个神经符号工作负载上，REASON相比桌面和边缘GPU实现了12-50倍的速度提升和310-681倍的能效提升（基于TSMC 28nm工艺）。能够以6mm²面积和2.12W功耗在0.8秒内完成端到端任务，实现实时概率逻辑推理。

Conclusion: 针对概率逻辑推理的专门加速对于实用和可扩展的神经符号AI至关重要，REASON作为下一代认知智能的基础系统架构，为实现实时高效的神经符号AI系统提供了关键解决方案。

Abstract: Neuro-symbolic AI systems integrate neural perception with symbolic reasoning to enable data-efficient, interpretable, and robust intelligence beyond purely neural models. Although this compositional paradigm has shown superior performance in domains such as reasoning, planning, and verification, its deployment remains challenging due to severe inefficiencies in symbolic and probabilistic inference. Through systematic analysis of representative neuro-symbolic workloads, we identify probabilistic logical reasoning as the inefficiency bottleneck, characterized by irregular control flow, low arithmetic intensity, uncoalesced memory accesses, and poor hardware utilization on CPUs and GPUs.
  This paper presents REASON, an integrated acceleration framework for probabilistic logical reasoning in neuro-symbolic AI. REASON introduces a unified directed acyclic graph representation that captures common structure across symbolic and probabilistic models, coupled with adaptive pruning and regularization. At the architecture level, REASON features a reconfigurable, tree-based processing fabric optimized for irregular traversal, symbolic deduction, and probabilistic aggregation. At the system level, REASON is tightly integrated with GPU streaming multiprocessors through a programmable interface and multi-level pipeline that efficiently orchestrates compositional execution. Evaluated across six neuro-symbolic workloads, REASON achieves 12-50x speedup and 310-681x energy efficiency over desktop and edge GPUs under TSMC 28 nm node. REASON enables real-time probabilistic logical reasoning, completing end-to-end tasks in 0.8 s with 6 mm2 area and 2.12 W power, demonstrating that targeted acceleration of probabilistic logical reasoning is critical for practical and scalable neuro-symbolic AI and positioning REASON as a foundational system architecture for next-generation cognitive intelligence.

</details>


### [23] [MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents](https://arxiv.org/abs/2601.20831)
*Vishnu Sashank Dorbala,Dinesh Manocha*

Main category: cs.AI

TL;DR: MemCtrl：一种使用多模态大语言模型在线修剪记忆的新框架，通过可训练的记忆头μ来决定在探索过程中保留、更新或丢弃哪些观察或反思，显著提升了具身任务完成能力。


<details>
  <summary>Details</summary>
Motivation: 基础模型依赖上下文学习进行个性化决策，但有限的上下文窗口需要内存压缩和检索系统。现有系统通常将内存视为大型离线存储空间，这不适合需要在严格内存和计算约束下在线运行的具身智能体。

Method: 提出MemCtrl框架，使用多模态大语言模型在线修剪记忆。通过可训练的记忆头μ作为门控机制，决定在探索过程中保留、更新或丢弃哪些观察或反思。训练了两种类型的μ：1）通过离线专家训练，2）通过在线强化学习训练。

Result: 在EmbodiedBench基准测试的多个子集上，μ增强的MLLMs平均提升约16%，特定指令子集提升超过20%。定性分析显示μ增强的MLLMs在长而复杂的指令类型上表现优异。

Conclusion: MemCtrl框架通过在线内存修剪有效提升了具身智能体的任务完成能力，特别是在内存和计算受限的在线环境中，为具身AI的内存管理提供了新思路。

Abstract: Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.

</details>


### [24] [Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)](https://arxiv.org/abs/2601.20843)
*Saurav Prateek*

Main category: cs.AI

TL;DR: 提出Deep Researcher架构，通过顺序研究计划优化和候选交叉算法，在博士级研究任务上超越现有并行方法，在DeepResearch Bench上取得46.21分的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决并行扩展范式在复杂研究任务中的固有局限，特别是知识孤岛问题，需要更智能的动态适应方法来生成高质量研究报告。

Method: 1. 顺序研究计划优化：通过反思机制维护全局研究上下文，动态调整研究计划；2. 候选交叉算法：部署多个不同参数的LLM候选探索更大搜索空间，综合结果；3. 一次性报告生成：基于统一叙事生成最终研究报告。

Result: 在DeepResearch Bench（100个博士级研究任务基准）上获得46.21分，超越Claude Researcher、Nvidia AIQ Research Assistant、Perplexity Research、Kimi Researcher和Grok Deeper Search等领先研究智能体。

Conclusion: 顺序扩展范式在复杂研究任务中持续优于并行自一致性范式，Deep Researcher架构通过动态适应和智能搜索策略实现了博士级研究任务的最佳性能。

Abstract: This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.

</details>


### [25] [SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models](https://arxiv.org/abs/2601.20856)
*Sebastiano Monti,Carlo Nicolini,Gianni Pellegrini,Jacopo Staiano,Bruno Lepri*

Main category: cs.AI

TL;DR: 该研究系统评估了大语言模型的长时程规划能力，发现当解决方案需要超过25步时性能显著下降，表明存在固有的规划能力限制。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在复杂推理任务上的能力日益受到测试，但其长时程规划能力尚未得到广泛研究。本研究旨在系统评估最先进的大推理模型在规划和长时程推理方面的能力。

Method: 提出基于推箱子游戏的新基准测试，特意简化以隔离长时程规划与状态持久性。使用PDDL（规划领域定义语言）解析、验证和求解工具来增强模型。

Result: 研究发现当解决方案需要超过25步时，规划性能出现一致性的下降，表明前向规划能力存在基本限制。使用PDDL工具只能带来适度的改进。

Conclusion: 大推理模型存在固有的架构限制，这些限制可能无法仅通过测试时扩展方法克服，需要更根本的改进来提升长时程规划能力。

Abstract: Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [26] [Schadenfreude in the Digital Public Sphere: A cross-national and decade-long analysis of Facebook news engagement](https://arxiv.org/abs/2601.20413)
*Nouar Aldahoul,Hazem Ibrahim,Majd Mahmutoglu,Hajra Tarar,Muhammad Fareed Zaffar,Talal Rahwan,Yasir Zaki*

Main category: cs.SI

TL;DR: 通过分析Facebook上9家新闻出版商10年间的评论，研究发现幸灾乐祸在数字新闻互动中普遍存在，尤其在道德化和政治语境中更常见，右倾受众和印度用户表现更明显，且与政治权力地位相关。


<details>
  <summary>Details</summary>
Motivation: 幸灾乐祸已成为在线新闻互动中的显著特征，但对其普遍性、动态变化和社会模式缺乏系统了解。研究旨在超越轶事描述，系统分析数字话语中幸灾乐祸的分布和演变规律。

Method: 结合人工标注和机器学习分类方法，分析美国、英国、印度9家主要新闻出版商（左倾、右倾、中间各一）在Facebook上10年间的帖子。识别描述不幸事件的帖子，并检测近百万条相关评论中的幸灾乐祸表达。

Result: 虽然悲伤和愤怒是面对不幸事件的主要反应，但笑声和娱乐构成了显著且有规律的模式。幸灾乐祸在道德化和政治语境中最常见，右倾受众中更频繁，印度用户比美英用户表现更明显。时间序列和回归分析显示，当群体在政治上失势时幸灾乐祸通常会增加，但不同党派间存在差异。

Conclusion: 幸灾乐祸是数字话语中动态且情境依赖的特征，其表现随时间演变，并跨越意识形态和文化分歧。研究为理解在线新闻互动中的情感表达提供了实证基础。

Abstract: Schadenfreude, or the pleasure derived from others' misfortunes, has become a visible and performative feature of online news engagement, yet little is known about its prevalence, dynamics, or social patterning. We examine schadenfreude on Facebook over a ten-year period across nine major news publishers in the United States, the United Kingdom, and India (one left-leaning, one right-leaning, and one centrist per country). Using a combination of human annotation and machine-learning classification, we identify posts describing misfortune and detect schadenfreude in nearly one million associated comments. We find that while sadness and anger dominate reactions to misfortune posts, laughter and amusement form a substantial and patterned minority. Schadenfreude is most frequent in moralized and political contexts, higher among right-leaning audiences, and more pronounced in India than in the United States or United Kingdom. Temporal and regression analyses further reveal that schadenfreude generally increases when groups are politically out of power, but these patterns differ across party lines. Together, our findings move beyond anecdotal accounts to map schadenfreude as a dynamic, context-dependent feature of digital discourse, revealing how it evolves over time and across ideological and cultural divides.

</details>


### [27] [TGSBM: Transformer-Guided Stochastic Block Model for Link Prediction](https://arxiv.org/abs/2601.20646)
*Zhejian Yang,Songwei Zhao,Zilin Zhao,Hechang Chen*

Main category: cs.SI

TL;DR: TGSBM结合图Transformer与随机块模型，实现大规模链接预测的高性能、可扩展性和可解释性


<details>
  <summary>Details</summary>
Motivation: 大规模网络链接预测面临挑战：传统GNN难以捕捉全局结构依赖，图Transformer性能强但复杂度高且缺乏可解释性。需要平衡准确性、效率和透明度的解决方案。

Method: 提出TGSBM框架，整合重叠随机块模型的生成结构与稀疏图Transformer的表示能力。包含三个组件：扩展器增强稀疏注意力（近线性复杂度）、神经变分编码器（推断社区成员后验）、神经边解码器（通过OSBM生成过程重建链接）。

Result: 在多个基准测试中表现优异（HeaRT协议下平均排名1.6），训练速度提升高达6倍，并能学习可解释的社区结构。

Conclusion: TGSBM为大规模链接预测提供了准确性、效率和透明度之间的平衡，是实用的解决方案。

Abstract: Link prediction is a cornerstone of the Web ecosystem, powering applications from recommendation and search to knowledge graph completion and collaboration forecasting. However, large-scale networks present unique challenges: they contain hundreds of thousands of nodes and edges with heterogeneous and overlapping community structures that evolve over time. Existing approaches face notable limitations: traditional graph neural networks struggle to capture global structural dependencies, while recent graph transformers achieve strong performance but incur quadratic complexity and lack interpretable latent structure. We propose \textbf{TGSBM} (Transformer-Guided Stochastic Block Model), a framework that integrates the principled generative structure of Overlapping Stochastic Block Models with the representational power of sparse Graph Transformers. TGSBM comprises three main components: (i) \emph{expander-augmented sparse attention} that enables near-linear complexity and efficient global mixing, (ii) a \emph{neural variational encoder} that infers structured posteriors over community memberships and strengths, and (iii) a \emph{neural edge decoder} that reconstructs links via OSBM's generative process, preserving interpretability. Experiments across diverse benchmarks demonstrate competitive performance (mean rank 1.6 under HeaRT protocol), superior scalability (up to $6\times$ faster training), and interpretable community structures. These results position TGSBM as a practical approach that strikes a balance between accuracy, efficiency, and transparency for large-scale link prediction.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [28] [Fueling Volunteer Growth: the case of Wikipedia Administrators](https://arxiv.org/abs/2601.20016)
*Eli Asikin-Garmager,Yu-Ming Liou,Caroline Myrick,Claudia Lo,Diego Saez-Trumper,Leila Zia*

Main category: cs.CY

TL;DR: 对284个维基百科语言版本的管理员状况进行多方法研究，发现虽然超过一半的维基百科管理员数量净增长，但近三分之二高度活跃的维基百科面临管理员减少问题，主要原因是招募不足而非异常流失。


<details>
  <summary>Details</summary>
Motivation: 维基百科管理员对平台成功至关重要，每年执行超过百万次管理操作。研究旨在系统分析2018年以来各语言维基百科的管理员状况，了解管理员数量变化趋势及其原因，为维基百科的长期可持续发展提供依据。

Method: 采用多方法研究：大规模管理员日志分析、超过3000份问卷调查、12次访谈，系统分析284个维基百科语言版本的管理员状况。

Result: 研究发现关键的两面趋势：超过一半的维基百科管理员数量净增长，但近三分之二高度活跃的维基百科面临管理员减少问题。下降主要源于招募不足而非异常流失，识别出潜在管理员面临的主要障碍：认知有限、要求模糊、选拔过程苛刻、初始兴趣低。

Conclusion: 当前管理员仍然保持高度积极性和参与度，研究提出可操作建议以加强招募渠道，促进维基百科管理员增长，这对维基百科的长期可持续性至关重要。

Abstract: Wikipedia administrators are vital to the platform's success, performing over a million administrative actions annually. This multi-method study systematically analyzes adminship across 284 Wikipedia languages since 2018, revealing a critical two-sided trend: while over half of all Wikipedias show a net increase in administrators, almost two-thirds of highly active Wikipedias face decline. Our analysis, drawing from large-scale adminship log analysis, over 3000 surveys, and 12 interviews, reveals this decline is primarily driven by insufficient recruitment, not unusual attrition. We identify key barriers for potential administrators, including limited awareness, ambiguous requirements, a demanding selection process, and low initial interest. Recognizing that current administrators remain highly motivated and engaged, we propose actionable recommendations to strengthen recruitment pipelines and fuel Wikipedia administrator growth, crucial for Wikipedia's long-term sustainability.

</details>


### [29] [Dynamics of Human-AI Collective Knowledge on the Web: A Scalable Model and Insights for Sustainable Growth](https://arxiv.org/abs/2601.20099)
*Buddhika Nettasinghe,Kang Zhao*

Main category: cs.CY

TL;DR: 该研究提出了一个人类与LLM共同构建网络知识生态系统的动力学模型，分析了反馈循环带来的增长与风险，并通过实验识别了不同增长机制和稳态。


<details>
  <summary>Details</summary>
Motivation: 人类与大型语言模型共同生产和消费网络知识，形成了包含反馈循环的人机集体知识生态系统。这种系统既有益处（如更快增长、更易学习），也存在系统性风险（如质量稀释、技能退化、模型崩溃）。需要理解这些现象以促进可持续发展。

Method: 提出了一个最小化、可解释的动力学模型，描述档案规模、档案质量、模型技能、人类集体技能和查询量的共同演化。模型包含两个内容流入源（人类、LLM）、两个人类学习路径（档案学习vs.LLM辅助）和两个LLM训练模式（语料驱动扩展vs.人类反馈学习）。通过数值实验识别不同增长机制，并在PubMed、GitHub/Copilot和维基百科等场景中验证。

Result: 识别了多种增长机制（健康增长、逆向流动、逆向学习、振荡等），展示了平台和政策杠杆如何推动系统跨越机制边界。在PubMed和GitHub/Copilot中观察到不同增长率和审核规范下的对比稳态。维基百科数据显示，ChatGPT时代后LLM贡献增加而人类流入减少，与模型预测的机制一致。

Conclusion: 该模型和分析为网络人机集体知识的可持续发展提供了可操作的见解，有助于理解和管理人类-AI知识生态系统的动态演化。

Abstract: Humans and large language models (LLMs) now co-produce and co-consume the web's shared knowledge archives. Such human-AI collective knowledge ecosystems contain feedback loops with both benefits (e.g., faster growth, easier learning) and systemic risks (e.g., quality dilution, skill reduction, model collapse). To understand such phenomena, we propose a minimal, interpretable dynamical model of the co-evolution of archive size, archive quality, model (LLM) skill, aggregate human skill, and query volume. The model captures two content inflows (human, LLM) controlled by a gate on LLM-content admissions, two learning pathways for humans (archive study vs. LLM assistance), and two LLM-training modalities (corpus-driven scaling vs. learning from human feedback). Through numerical experiments, we identify different growth regimes (e.g., healthy growth, inverted flow, inverted learning, oscillations), and show how platform and policy levers (gate strictness, LLM training, human learning pathways) shift the system across regime boundaries. Two domain configurations (PubMed, GitHub and Copilot) illustrate contrasting steady states under different growth rates and moderation norms. We also fit the model to Wikipedia's knowledge flow during pre-ChatGPT and post-ChatGPT eras separately. We find a rise in LLM additions with a concurrent decline in human inflow, consistent with a regime identified by the model. Our model and analysis yield actionable insights for sustainable growth of human-AI collective knowledge on the Web.

</details>


### [30] [Large language models accurately predict public perceptions of support for climate action worldwide](https://arxiv.org/abs/2601.20141)
*Nattavudh Powdthavee,Sandra J. Geiger*

Main category: cs.CY

TL;DR: LLMs（特别是Claude）能准确预测全球气候行动中的感知差距，与统计模型表现相当，但在数字连接度低、GDP低的国家表现下降。


<details>
  <summary>Details</summary>
Motivation: 尽管大多数人支持气候行动，但对他人支持程度的普遍低估阻碍了个人和系统性变革。需要可靠的方法来评估这些感知差距。

Method: 使用125个国家的国家级指标和民意数据，将四种最先进的LLM与盖洛普世界民意调查2021/22数据以及统计回归模型进行基准测试。

Result: LLMs（特别是Claude）能准确捕捉公众对他人愿意为气候行动贡献资金的感知（MAE约5个百分点；r=0.77），与统计模型相当。但性能在数字连接度低、GDP低的国家下降。LLMs捕捉到了关键心理过程——带有系统性向下偏差的社会投射。

Conclusion: LLMs为评估气候行动中的感知差距提供了快速工具，在资源丰富的国家可作为昂贵调查的替代方案，在代表性不足的人群中可作为补充工具。

Abstract: Although most people support climate action, widespread underestimation of others' support stalls individual and systemic changes. In this preregistered experiment, we test whether large language models (LLMs) can reliably predict these perception gaps worldwide. Using country-level indicators and public opinion data from 125 countries, we benchmark four state-of-the-art LLMs against Gallup World Poll 2021/22 data and statistical regressions. LLMs, particularly Claude, accurately capture public perceptions of others' willingness to contribute financially to climate action (MAE approximately 5 p.p.; r = .77), comparable to statistical models, though performance declines in less digitally connected, lower-GDP countries. Controlled tests show that LLMs capture the key psychological process - social projection with a systematic downward bias - and rely on structured reasoning rather than memorized values. Overall, LLMs provide a rapid tool for assessing perception gaps in climate action, serving as an alternative to costly surveys in resource-rich countries and as a complement in underrepresented populations.

</details>


### [31] [Adequately Tailoring Age Verification Regulations](https://arxiv.org/abs/2601.20241)
*Shuang Liu,Sarah Scheffler*

Main category: cs.CY

TL;DR: 本文分析美国年龄验证立法的现状，提出解释"充分定制"要求的分析模型，并评估当前技术方法的实际挑战和权衡。


<details>
  <summary>Details</summary>
Motivation: 美国最高法院在Free Speech Coalition v. Paxton案中维持了德克萨斯州H.B. 1181法案的合宪性，但留下了实际挑战未解决。需要澄清年龄验证立法的现状，解释"充分定制"要求，并分析当前技术方法的可行性和权衡。

Method: 提出分析模型从多角度解释"充分定制"要求，结合政府目标和利益；应用该模型评估当前州法律和广泛使用的验证方法；绘制美国年龄验证立法现状图。

Result: 1) 绘制了美国年龄验证立法现状图；2) 建立了分析"充分定制"要求的模型，可应用于其他在线监管政策；3) 分析了主要技术方法，从技术角度突出了实际挑战和权衡。

Conclusion: 虽然聚焦美国州法律，但框架原则适用于全球年龄验证辩论和方法。该研究为法律专家和技术人员提供了理解年龄验证立法和技术实施之间关系的工具。

Abstract: The Supreme Court decision in Free Speech Coalition v. Paxton upheld the constitutionality of Texas H.B. 1181, one of the most constitutionally vulnerable of these age verification laws, holding that it was subject to and satisfied intermediate scrutiny and the requirement that age verification regulations be "adequately tailored". However, the decision leaves unresolved practical challenges. What is the current state of age verification legislation in the United States? How can "adequate tailoring" be interpreted in a way that is accessible to non-legal experts, particularly those in technical and engineering domains? What age verification approaches are used today, what infrastructures and standards support them, and what tradeoffs do they introduce? This paper addresses those questions by proposing an analytical model to interpret "adequate tailoring" from multiple perspectives with associated governmental goals and interests, and by applying that model to evaluate both current state laws and widely used verification methods. This paper's major contributions include: (1) we mapped the current U.S. age-verification legislative landscape; (2) we introduce an analytical model to analyze "adequate tailoring" for age verification and potential application to other online regulatory policies; and (3) we analyze the main technical approaches to age verification, highlighting the practical challenges and tradeoffs from a technical perspective. Further, while we focus on U.S. State laws, the principles underlying our framework are applicable to age-verification debates and methods worldwide.

</details>


### [32] [How AI Impacts Skill Formation](https://arxiv.org/abs/2601.20245)
*Judy Hanwen Shen,Alex Tamkin*

Main category: cs.CY

TL;DR: AI辅助虽然能提高生产力，但会损害新手对编程库的概念理解、代码阅读和调试能力，且平均效率提升不显著。完全委托AI编码会牺牲学习效果，而包含认知参与的交互模式能保持学习成果。


<details>
  <summary>Details</summary>
Motivation: 研究AI辅助如何影响新手工作者监督AI所需技能的培养。虽然AI能提高生产力，但过度依赖可能损害技能获取，特别是在安全关键领域。

Method: 通过随机实验研究开发者在使用和不使用AI辅助的情况下，掌握新的异步编程库的效果。识别了六种不同的AI交互模式。

Result: AI使用会损害概念理解、代码阅读和调试能力，平均效率提升不显著。完全委托编码的任务参与者虽有生产力提升，但牺牲了库的学习。三种包含认知参与的交互模式能保持学习成果。

Conclusion: AI增强的生产力不是通往能力的捷径，应谨慎将AI辅助纳入工作流程以保持技能培养，特别是在安全关键领域。

Abstract: AI assistance produces significant productivity gains across professional domains, particularly for novice workers. Yet how this assistance affects the development of skills required to effectively supervise AI remains unclear. Novice workers who rely heavily on AI to complete unfamiliar tasks may compromise their own skill acquisition in the process. We conduct randomized experiments to study how developers gained mastery of a new asynchronous programming library with and without the assistance of AI. We find that AI use impairs conceptual understanding, code reading, and debugging abilities, without delivering significant efficiency gains on average. Participants who fully delegated coding tasks showed some productivity improvements, but at the cost of learning the library. We identify six distinct AI interaction patterns, three of which involve cognitive engagement and preserve learning outcomes even when participants receive AI assistance. Our findings suggest that AI-enhanced productivity is not a shortcut to competence and AI assistance should be carefully adopted into workflows to preserve skill formation -- particularly in safety-critical domains.

</details>


### [33] [Agent Benchmarks Fail Public Sector Requirements](https://arxiv.org/abs/2601.20617)
*Jonathan Rystrøm,Chris Schmitz,Karolina Korgul,Jan Batzner,Chris Russell*

Main category: cs.CY

TL;DR: 该研究发现目前没有任何基准测试能够完全满足公共部门对LLM代理评估的严格要求，提出了公共部门基准测试的四大标准，并分析了1300多篇论文后发现存在明显差距。


<details>
  <summary>Details</summary>
Motivation: 在公共部门部署基于大语言模型的代理需要确保其满足严格的法律、程序和结构要求。目前缺乏明确的基准测试标准来评估这些代理是否真正符合公共部门需求，也不清楚现有基准测试的适用性。

Method: 1. 基于公共管理文献的一阶原则调查，定义了公共部门基准测试的四大标准：基于流程、现实性、公共部门特定性、反映公共部门独特需求的指标
2. 使用专家验证的LLM辅助流程分析了1300多篇基准测试论文
3. 评估这些论文是否满足提出的四大标准

Result: 研究发现没有任何单一基准测试能够完全满足所有四个标准。这表明当前基准测试在评估公共部门LLM代理方面存在显著不足，无法充分反映公共部门的独特要求。

Conclusion: 研究呼吁研究人员开发符合公共部门需求的基准测试，并建议公共部门官员在评估自身代理用例时应用这些标准。当前基准测试与公共部门实际需求之间存在明显差距，需要针对性的改进。

Abstract: Deploying Large Language Model-based agents (LLM agents) in the public sector requires assuring that they meet the stringent legal, procedural, and structural requirements of public-sector institutions. Practitioners and researchers often turn to benchmarks for such assessments. However, it remains unclear what criteria benchmarks must meet to ensure they adequately reflect public-sector requirements, or how many existing benchmarks do so. In this paper, we first define such criteria based on a first-principles survey of public administration literature: benchmarks must be \emph{process-based}, \emph{realistic}, \emph{public-sector-specific} and report \emph{metrics} that reflect the unique requirements of the public sector. We analyse more than 1,300 benchmark papers for these criteria using an expert-validated LLM-assisted pipeline. Our results show that no single benchmark meets all of the criteria. Our findings provide a call to action for both researchers to develop public sector-relevant benchmarks and for public-sector officials to apply these criteria when evaluating their own agentic use cases.

</details>


### [34] [Audit Trails for Accountability in Large Language Models](https://arxiv.org/abs/2601.20727)
*Victor Ojewale,Harini Suresh,Suresh Venkatasubramanian*

Main category: cs.CY

TL;DR: 提出LLM审计追踪机制，通过时间顺序、防篡改、上下文丰富的生命周期事件记录，连接技术来源与治理记录，实现持续问责。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗、金融、就业和公共服务等领域决策中日益重要，但问责机制脆弱，过程透明度缺乏持久可审查的记录形式。

Method: 提出LLM审计追踪作为社会技术机制：1）生命周期框架，定义事件类型、元数据和治理原理；2）参考架构，包含轻量发射器、只追加审计存储和审计接口；3）开源Python实现，最小集成工作量。

Result: 开发了可重用的开源Python实现，能够在LLM工作流中实例化审计层，支持跨组织可追溯性。

Conclusion: 讨论了审计追踪机制的局限性和采用方向，为LLM系统提供持续问责的技术解决方案。

Abstract: Large language models (LLMs) are increasingly embedded in consequential decisions across healthcare, finance, employment, and public services. Yet accountability remains fragile because process transparency is rarely recorded in a durable and reviewable form. We propose LLM audit trails as a sociotechnical mechanism for continuous accountability. An audit trail is a chronological, tamper-evident, context-rich ledger of lifecycle events and decisions that links technical provenance (models, data, training and evaluation runs, deployments, monitoring) with governance records (approvals, waivers, and attestations), so organizations can reconstruct what changed, when, and who authorized it.
  This paper contributes: (1) a lifecycle framework that specifies event types, required metadata, and governance rationales; (2) a reference architecture with lightweight emitters, append only audit stores, and an auditor interface supporting cross organizational traceability; and (3) a reusable, open-source Python implementation that instantiates this audit layer in LLM workflows with minimal integration effort. We conclude by discussing limitations and directions for adoption.

</details>


### [35] [Jurisdiction as Structural Barrier: How Privacy Policy Organization May Reduce Visibility of Substantive Disclosures](https://arxiv.org/abs/2601.20792)
*Thomas Brackin*

Main category: cs.CY

TL;DR: 研究发现隐私政策中存在"司法管辖区隔离披露"模式：关键数据实践信息仅出现在"加州居民"或"欧盟/英国用户"等区域合规章节中，而通用章节使用模糊语言，导致用户可能错过重要信息。


<details>
  <summary>Details</summary>
Motivation: 隐私政策应该提供有效通知，但如果实质性信息只出现在用户可能跳过的区域特定章节中，就会导致透明度失败。研究者关注这种通过文档架构而非信息缺失造成的透明度问题。

Method: 对123家主要公司的隐私政策进行审计，识别"司法管辖区隔离披露"模式。使用OPP-115人类标注验证实践类别，建立保守估计。基于信息觅食理论分析用户行为模式。

Result: 在123家公司中，77家公司（62.6%）存在282个潜在实例。保守估计显示54家公司（44%）存在138个实例。研究发现这种结构模式普遍存在，可能导致受监管区域外的用户获得较少具体信息。

Conclusion: 提出"普遍实质性披露"标准：影响所有用户的做法应出现在政策主体中，区域章节仅包含程序性权利信息。建议监管机构通过FTC"清晰显著"标准和GDPR透明度原则实施。研究是假设生成性的，需要进一步验证区域特定章节的跳过行为。

Abstract: Privacy policies are supposed to provide notice. But what if substantive information appears only where users skip it? We identify a structural pattern we call jurisdiction-siloed disclosure: information about data practices appearing in specific, actionable form only within regional compliance sections labeled "California Residents" or "EU/UK Users," while general sections use vague or qualified language for the same practices.
  Our audit of 123 major companies identifies 282 potential instances across 77 companies (62.6% of this purposive sample). A conservative estimate restricted to practice categories validated against OPP-115 human annotations finds 138 instances across 54 companies (44%); post-2018 categories central to our findings await independent validation. If users skip jurisdiction-labeled sections as information foraging theory predicts, users outside regulated jurisdictions would receive less specific information about practices affecting them--a transparency failure operating through document architecture rather than omission.
  We propose universal substantive disclosure: practices affecting all users should appear in the main policy body, with regional sections containing only procedural rights information. This standard finds support in analogous disclosure regimes (securities, truth-in-lending, nutritional labeling) where material information must reach all affected parties. Regulators could operationalize this through the FTC's "clear and conspicuous" standard and GDPR transparency principles.
  This work is hypothesis-generating: we establish that the structural pattern exists and ground the transparency concern in behavioral theory, but direct measurement of jurisdiction-specific section skipping remains the critical validation priority. We release our methodology and annotated dataset to enable replication.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [36] [Scalable Decisions using a Bayesian Decision-Theoretic Approach](https://arxiv.org/abs/2601.20031)
*Hoiyi Ng,Guido Imbens*

Main category: stat.AP

TL;DR: 提出贝叶斯决策理论框架，通过层次模型结合历史实验信息，系统整合多目标权衡，提高供应链实验决策效率和可扩展性


<details>
  <summary>Details</summary>
Motivation: 传统随机对照实验独立评估相关指标，混合结果（如收入正影响但客户体验负影响）需要人工判断，阻碍可扩展性

Method: 贝叶斯决策理论框架，结合实验者定义的损失函数和观测证据，使用层次模型利用历史实验信息作为先验知识

Result: 在亚马逊供应链实验中，相比零假设统计检验，该方法通过信息性层次先验提高估计效率，系统整合业务偏好和成本简化决策

Conclusion: 提出的框架能够系统整合多目标和权衡，提供全面、可扩展的决策方法，优于传统统计检验

Abstract: Randomized controlled experiments assess new policy impacts on performance metrics to inform launch decisions. Traditional approaches evaluate metrics independently despite correlations, and mixed results (e.g., positive revenue impact, negative customer experience) require manual judgment, hindering scalability. We propose a Bayesian decision-theoretic framework that systematically incorporates multiple objectives and trade-offs by comparing expected risks across decisions. Our approach combines experimenter-defined loss functions with observed evidence, using hierarchical models to leverage historical experiment learnings for prior information on treatment effects. Through real and simulated Amazon supply chain experiments, we demonstrate that compared to null hypothesis statistical testing, our method increases estimation efficiency via informative hierarchical priors and simplifies decision-making by systematically incorporating business preferences and costs for comprehensive, scalable decisions.

</details>


### [37] [Comparing causal estimands from sequential nested versus single point target trials: A simulation study](https://arxiv.org/abs/2601.20725)
*Catherine Wiener,Chase D. Latour,Kathleen Hurwitz,Xiaojuan Li,Catherine R. Lesko,Alexander Breskin,M. Alan Brookhart*

Main category: stat.AP

TL;DR: 比较序列嵌套试验模拟与单点试验的因果估计量差异，发现当治疗效果受疾病严重程度修饰时，两者估计值会不同


<details>
  <summary>Details</summary>
Motivation: 序列嵌套试验模拟虽然能提高精度和避免时间相关偏倚，但其隐含的因果估计量与真实世界单点试验的对应关系缺乏讨论，需要明确两者差异以支持循证决策

Method: 使用蒙特卡洛模拟，比较两种SNT模拟方法（年度重新索引和基于治疗决策设计）与单点试验的治疗效果估计。生成5000个队列，每个队列5000人，随访3年

Result: 当疾病严重程度不修饰治疗效果时，两种SNT方法返回与单点试验相同的估计值；但当存在治疗效果修饰时，即使经过混杂调整，SNT估计值仍与单点试验不同

Conclusion: SNT模拟的因果估计量解释存在困难，其目标人群与单点试验不对应，这对基于证据的决策沟通具有重要意义

Abstract: Sequential nested trial (SNT) emulation is a powerful approach for maximizing precision and avoiding time-related biases. However, there exists little discussion about the implied causal estimands in comparison to a real-world single point trial. We used Monte Carlo simulation to compare treatment effect estimates from an SNT emulation that re-indexed patients annually and a SNT emulation with a treatment decision design to the estimates from a single point trial. We generated 5,000 cohorts of 5,000 people with 3 years of follow-up. For the single point trial, patients were randomized to initiate or not initiate treatment at Visit 1. For the SNT emulations, simulated patients could contribute up to two index dates. When disease severity did not modify the treatment effect, both SNT approaches returned treatment effect estimates identical to the single point trial. In the presence of treatment effect modification by disease severity, both SNT approaches returned treatment effect estimates that diverged from the single point trial even after confounding-adjustment. These findings underscore the difficulties of interpreting causal estimands from a SNT emulation: the target population does not correspond to a single time point trial. Such implications are important for communicating study results for evidence-based decision-making.

</details>


### [38] [A Survival Framework for Estimating Child Mortality Rates using Multiple Data Types](https://arxiv.org/abs/2601.20821)
*Katherine R Paulson,Taylor Okonek,Jon Wakefield*

Main category: stat.AP

TL;DR: 提出贝叶斯生存框架，用单一模型估计儿童从出生到5岁的生存概率随时间变化趋势，整合多种数据源，生成完整生存曲线。


<details>
  <summary>Details</summary>
Motivation: 许多国家缺乏高质量生命登记数据来精确测量儿童死亡率，现有方法如UN IGME和GBD使用多步骤建模或分年龄组模型，需要更统一的框架。

Method: 提出贝叶斯生存框架，使用log-logistic和分段指数生存函数，整合家庭调查、生命登记和其他预处理死亡率数据，用单一模型估计0-5岁生存概率。

Result: 模型在肯尼亚、巴西、爱沙尼亚和叙利亚四个数据特征不同的国家得到验证，产生的三个生存指标估计与数据和UN IGME估计基本一致，同时提供完整生存曲线。

Conclusion: 贝叶斯生存框架能统一估计儿童生存趋势，整合多种数据源，提供比现有方法更全面的生存曲线信息，适用于各种数据配置的国家。

Abstract: Child mortality is an important population health indicator. However, many countries lack high-quality vital registration to measure child mortality rates precisely and reliably over time. Research endeavors such as those by the United Nations Inter-agency Group for Child Mortality Estimation (UN IGME) and the Global Burden of Disease (GBD) study leverage statistical models and available data to estimate child survival summaries including neonatal, infant, and under-five mortality rates. UN IGME fits separate models for each age group and the GBD uses a multi-step modeling process. We propose a Bayesian survival framework to estimate temporal trends in the probability of survival as a function of age, up to the fifth birthday, with a single model. Our framework integrates all data types that are used by UN IGME: household surveys, vital registration, and other pre-processed mortality rates. We demonstrate that our framework is applicable to any country using log-logistic and piecewise-exponential survival functions, and discuss findings for four example countries with diverse data profiles: Kenya, Brazil, Estonia, and Syrian Arab Republic. Our model produces estimates of the three survival summaries that are in broad agreement with both the data and the UN IGME estimates, but in addition gives the complete survival curve.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [39] [United in Currency, Divided in Growth: Dynamic Effects of Euro Adoption](https://arxiv.org/abs/2601.20169)
*Harry Aytug*

Main category: econ.EM

TL;DR: 欧元采用平均降低年GDP增长率0.3-0.4个百分点，效果在采用后不久出现并持续约十年，对初始人均GDP较低的国家影响更大。


<details>
  <summary>Details</summary>
Motivation: 现有关于欧元采用对长期经济增长影响的证据存在矛盾，主要原因是处理国家有限、时间跨度长导致推断困难，以及成员国间的异质性。需要更精确的方法来估计欧元采用的因果效应。

Method: 使用带有固定效应的因果森林（CFFE）方法，这是一种结合因果森林和双向固定效应的机器学习方法，在条件平行趋势假设下估计动态和异质性处理效应。

Result: 欧元采用平均降低年GDP增长率0.3-0.4个百分点，效果在采用后不久出现并稳定约十年。初始人均GDP较低的国家经历更大、更持久的增长缺口。消费和生产率增长减弱是主要原因，净出口改善部分抵消了这些下降。

Conclusion: 欧元采用对经济增长有负面平均效应，但存在显著异质性。一国特征在评估货币联盟长期后果中至关重要，统一的货币政策可能导致比灵活汇率制度下更大的产出损失。

Abstract: Does euro adoption affect long-run economic growth? Existing evidence is mixed, reflecting limited treated countries, long horizons that challenge inference, and heterogeneity across member states. We estimate causal dynamic and heterogeneous treatment effects using Causal Forests with Fixed Effects (CFFE), a machine-learning approach that combines causal forests with two-way fixed effects. Under a conditional parallel-trends assumption, we find that euro adoption reduced annual GDP growth by 0.3-0.4 percentage points on average. Effects emerge shortly after adoption and stabilize after roughly a decade.
  Average effects mask substantial heterogeneity. Countries with lower initial GDP per capita experience larger and more persistent growth shortfalls than core economies. Weaker consumption and productivity growth contribute to the overall effect, while improvements in net exports partially offset these declines.
  A two-country New Keynesian DSGE model with hysteresis generates qualitatively similar patterns: one-size-fits-all monetary policy and scarring mechanisms produce larger output losses under monetary union than under flexible exchange rates. By jointly estimating dynamic and heterogeneous treatment effects, the analysis highlights the importance of country characteristics in assessing the long-run consequences of monetary union.

</details>


### [40] [Realized range-based estimation of integrated variance](https://arxiv.org/abs/2601.20463)
*Kim Christensen,Mark Podolskij*

Main category: econ.EM

TL;DR: 本文提出了一种基于实现范围的方法来估计连续半鞅的二次变差，该方法用归一化平方范围替代实现方差中的平方收益，在完整样本路径下具有五倍于实现方差的精度，并解决了离散数据下的向下偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统实现方差方法使用平方收益估计二次变差，但存在精度限制。本文旨在开发一种基于价格范围的替代统计量，以提高估计精度，特别是在离散观测数据下解决向下偏差问题。

Method: 提出实现范围方差统计量，用归一化平方范围替代平方收益。在完整样本路径下证明一致性和混合高斯极限，精度是传统实现方差的五倍。针对离散数据导致的向下偏差，开发了不受非交易效应影响的一致混合正态估计器。

Result: 理论分析显示，在完整样本路径下，实现范围方差统计量具有五倍于实现方差的精度。实证应用TAQ数据表明，该方法能更好地估计二次变差的经验路径，效率取决于构建高低价所用的观测数量。

Conclusion: 实现范围方差方法为连续半鞅的二次变差估计提供了更精确的替代方案，解决了离散数据下的偏差问题，在实证应用中表现出优于传统实现方差的性能。

Abstract: We provide a set of probabilistic laws for estimating the quadratic variation of continuous semimartingales with realized range-based variance -- a statistic that replaces every squared return of realized variance with a normalized squared range. If the entire sample path of the process is available, and under a set of weak conditions, our statistic is consistent and has a mixed Gaussian limit, whose precision is five times greater than that of realized variance. In practice, of course, inference is drawn from discrete data and true ranges are unobserved, leading to downward bias. We solve this problem to get a consistent, mixed normal estimator, irrespective of non-trading effects. This estimator has varying degrees of efficiency over realized variance, depending on how many observations that are used to construct the high-low. The methodology is applied to TAQ data and compared with realized variance. Our findings suggest that the empirical path of quadratic variation is also estimated better with the realized range-based variance.

</details>


### [41] [The realized empirical distribution function of stochastic variance with application to goodness-of-fit testing](https://arxiv.org/abs/2601.20469)
*Kim Christensen,Martin Thyrsgaard,Bezirgen Veliyev*

Main category: econ.EM

TL;DR: 提出一种从高频数据估计潜在波动率经验分布函数的非参数方法，用于检验随机波动率模型的拟合优度


<details>
  <summary>Details</summary>
Motivation: 需要从噪声高频数据中估计资产价格潜在波动率的经验分布函数，以检验随机波动率模型的拟合优度

Method: 提出实现经验分布函数(REDF)的非参数估计器，从高频数据推断潜在波动率的经验分布，建立双渐近框架下的收敛性

Result: 蒙特卡洛研究表明REDF在整个波动率支持集上准确，拟合优度检验具有正确规模和相对较强的功效；实证应用显示逆高斯分布最适合描述股票随机变化

Conclusion: 逆高斯分布对随机股票变化提供最佳描述，但拟合不完全，表明需要额外参数（如广义逆高斯分布）来建模随机方差

Abstract: We propose a nonparametric estimator of the empirical distribution function (EDF) of the latent spot variance of the log-price of a financial asset. We show that over a fixed time span our realized EDF (or REDF) -- inferred from noisy high-frequency data -- is consistent as the mesh of the observation grid goes to zero. In a double-asymptotic framework, with time also increasing to infinity, the REDF converges to the cumulative distribution function of volatility, if it exists. We exploit these results to construct some new goodness-of-fit tests for stochastic volatility models. In a Monte Carlo study, the REDF is found to be accurate over the entire support of volatility. This leads to goodness-of-fit tests that are both correctly sized and relatively powerful against common alternatives. In an empirical application, we recover the REDF from stock market high-frequency data. We inspect the goodness-of-fit of several two-parameter marginal distributions that are inherent in standard stochastic volatility models. The inverse Gaussian offers the best overall description of random equity variation, but the fit is less than perfect. This suggests an extra parameter (as available in, e.g., the generalized inverse Gaussian) is required to model stochastic variance.

</details>
