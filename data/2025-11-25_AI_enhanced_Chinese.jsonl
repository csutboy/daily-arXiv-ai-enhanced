{"id": "2511.17928", "categories": ["econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.17928", "abs": "https://arxiv.org/abs/2511.17928", "authors": ["Wen Jiang", "Yachen Wang", "Zeqi Wu", "Xingbai Xu"], "title": "Limit Theorems for Network Data without Metric Structure", "comment": null, "summary": "This paper develops limit theorems for random variables with network dependence, without requiring that individuals in the network to be located in a Euclidean or metric space. This distinguishes our approach from most existing limit theorems in network econometrics, which are based on weak dependence concepts such as strong mixing, near-epoch dependence, and $\u03c8$-dependence. By relaxing the assumption of an underlying metric space, our theorems can be applied to a broader range of network data, including financial and social networks. To derive the limit theorems, we generalize the concept of functional dependence (also known as physical dependence) from time series to random variables with network dependence. Using this framework, we establish several inequalities, a law of large numbers, and central limit theorems. Furthermore, we verify the conditions for these limit theorems based on primitive assumptions for spatial autoregressive models, which are widely used in network data analysis.", "AI": {"tldr": "\u672c\u6587\u4e3a\u7f51\u7edc\u4f9d\u8d56\u968f\u673a\u53d8\u91cf\u53d1\u5c55\u4e86\u6781\u9650\u5b9a\u7406\uff0c\u65e0\u9700\u5047\u8bbe\u7f51\u7edc\u4e2a\u4f53\u4f4d\u4e8e\u6b27\u51e0\u91cc\u5f97\u6216\u5ea6\u91cf\u7a7a\u95f4\u4e2d\uff0c\u533a\u522b\u4e8e\u57fa\u4e8e\u5f3a\u6df7\u5408\u3001\u8fd1\u90bb\u4f9d\u8d56\u7b49\u5f31\u4f9d\u8d56\u6982\u5ff5\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u4e2d\u7684\u6781\u9650\u5b9a\u7406\u5927\u591a\u57fa\u4e8e\u5f31\u4f9d\u8d56\u6982\u5ff5\uff0c\u8981\u6c42\u7f51\u7edc\u4e2a\u4f53\u4f4d\u4e8e\u5ea6\u91cf\u7a7a\u95f4\u4e2d\uff0c\u9650\u5236\u4e86\u5728\u91d1\u878d\u7f51\u7edc\u3001\u793e\u4ea4\u7f51\u7edc\u7b49\u66f4\u5e7f\u6cdb\u7f51\u7edc\u6570\u636e\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5c06\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u51fd\u6570\u4f9d\u8d56\uff08\u7269\u7406\u4f9d\u8d56\uff09\u6982\u5ff5\u63a8\u5e7f\u5230\u7f51\u7edc\u4f9d\u8d56\u968f\u673a\u53d8\u91cf\uff0c\u57fa\u4e8e\u6b64\u6846\u67b6\u5efa\u7acb\u4e0d\u7b49\u5f0f\u3001\u5927\u6570\u5b9a\u5f8b\u548c\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\u3002", "result": "\u5efa\u7acb\u4e86\u7f51\u7edc\u4f9d\u8d56\u968f\u673a\u53d8\u91cf\u7684\u6781\u9650\u7406\u8bba\uff0c\u5e76\u5728\u7a7a\u95f4\u81ea\u56de\u5f52\u6a21\u578b\u7b49\u5e38\u7528\u7f51\u7edc\u5206\u6790\u6a21\u578b\u4e2d\u9a8c\u8bc1\u4e86\u5b9a\u7406\u6761\u4ef6\u3002", "conclusion": "\u901a\u8fc7\u653e\u677e\u5ea6\u91cf\u7a7a\u95f4\u5047\u8bbe\uff0c\u672c\u6587\u7684\u7406\u8bba\u6846\u67b6\u80fd\u591f\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u7f51\u7edc\u6570\u636e\u7c7b\u578b\uff0c\u4e3a\u7f51\u7edc\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.18550", "categories": ["econ.EM", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.18550", "abs": "https://arxiv.org/abs/2511.18550", "authors": ["Oguzhan Akgun", "Ryo Okui"], "title": "Robust Inference Methods for Latent Group Panel Models under Possible Group Non-Separation", "comment": null, "summary": "This paper presents robust inference methods for general linear hypotheses in linear panel data models with latent group structure in the coefficients. We employ a selective conditional inference approach, deriving the conditional distribution of coefficient estimates given the group structure estimated from the data. Our procedure provides valid inference under possible violations of group separation, where distributional properties of group-specific coefficients remain unestablished. Furthermore, even when group separation does hold, our method demonstrates superior finite-sample properties compared to traditional asymptotic approaches. This improvement stems from our procedure's ability to account for statistical uncertainty in the estimation of group structure. We demonstrate the effectiveness of our approach through Monte Carlo simulations and apply the methods to two datasets on: (i) the relationship between income and democracy, and (ii) the cyclicality of firm-level R&D investment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7ebf\u6027\u9762\u677f\u6570\u636e\u6a21\u578b\u4e2d\u5177\u6709\u6f5c\u5728\u7ec4\u7ed3\u6784\u7cfb\u6570\u7684\u7a33\u5065\u63a8\u65ad\u65b9\u6cd5\uff0c\u91c7\u7528\u9009\u62e9\u6027\u6761\u4ef6\u63a8\u65ad\u65b9\u6cd5\uff0c\u5728\u7ec4\u5206\u79bb\u53ef\u80fd\u4e0d\u6210\u7acb\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u6709\u6548\u63a8\u65ad\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u7ec4\u7ed3\u6784\u4f30\u8ba1\u5b58\u5728\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u65f6\u63a8\u65ad\u6027\u80fd\u4e0d\u4f73\uff0c\u4e14\u5f53\u7ec4\u5206\u79bb\u5047\u8bbe\u4e0d\u6210\u7acb\u65f6\u63a8\u65ad\u65e0\u6548\u3002", "method": "\u4f7f\u7528\u9009\u62e9\u6027\u6761\u4ef6\u63a8\u65ad\u65b9\u6cd5\uff0c\u63a8\u5bfc\u7ed9\u5b9a\u6570\u636e\u4f30\u8ba1\u7684\u7ec4\u7ed3\u6784\u6761\u4ef6\u4e0b\u7cfb\u6570\u4f30\u8ba1\u7684\u6761\u4ef6\u5206\u5e03\u3002", "result": "\u5373\u4f7f\u5728\u7ec4\u5206\u79bb\u4e0d\u6210\u7acb\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u63d0\u4f9b\u6709\u6548\u63a8\u65ad\uff0c\u5728\u7ec4\u5206\u79bb\u6210\u7acb\u65f6\u76f8\u6bd4\u4f20\u7edf\u6e10\u8fd1\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6709\u9650\u6837\u672c\u6027\u8d28\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u7ec4\u7ed3\u6784\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.19121", "categories": ["econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19121", "abs": "https://arxiv.org/abs/2511.19121", "authors": ["Xiaohong Chen", "Wayne Yuan Gao", "Likang Wen"], "title": "ReLU-Based and DNN-Based Generalized Maximum Score Estimators", "comment": null, "summary": "We propose a new formulation of the maximum score estimator that uses compositions of rectified linear unit (ReLU) functions, instead of indicator functions as in Manski (1975,1985), to encode the sign alignment restrictions. Since the ReLU function is Lipschitz, our new ReLU-based maximum score criterion function is substantially easier to optimize using standard gradient-based optimization pacakges. We also show that our ReLU-based maximum score (RMS) estimator can be generalized to an umbrella framework defined by multi-index single-crossing (MISC) conditions, while the original maximum score estimator cannot be applied. We establish the $n^{-s/(2s+1)}$ convergence rate and asymptotic normality for the RMS estimator under order-$s$ Holder smoothness. In addition, we propose an alternative estimator using a further reformulation of RMS as a special layer in a deep neural network (DNN) architecture, which allows the estimation procedure to be implemented via state-of-the-art software and hardware for DNN.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eReLU\u51fd\u6570\u7684\u6700\u5927\u5f97\u5206\u4f30\u8ba1\u5668\u65b0\u516c\u5f0f\uff0c\u66ff\u4ee3\u4e86Manski(1975,1985)\u4e2d\u7684\u6307\u793a\u51fd\u6570\uff0c\u4f7f\u4f18\u5316\u66f4\u5bb9\u6613\uff0c\u5e76\u6269\u5c55\u5230\u591a\u6307\u6807\u5355\u4ea4\u53c9\u6761\u4ef6\u6846\u67b6\u3002", "motivation": "\u4f20\u7edf\u6700\u5927\u5f97\u5206\u4f30\u8ba1\u5668\u4f7f\u7528\u6307\u793a\u51fd\u6570\u5bfc\u81f4\u4f18\u5316\u56f0\u96be\uff0cReLU\u51fd\u6570\u7684Lipschitz\u6027\u8d28\u4f7f\u5f97\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u66f4\u5bb9\u6613\u4f18\u5316\u3002", "method": "\u4f7f\u7528ReLU\u51fd\u6570\u7ec4\u5408\u7f16\u7801\u7b26\u53f7\u5bf9\u9f50\u9650\u5236\uff0c\u6784\u5efaReLU\u57fa\u6700\u5927\u5f97\u5206\u51c6\u5219\u51fd\u6570\uff0c\u5e76\u8fdb\u4e00\u6b65\u5c06\u5176\u91cd\u6784\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u7279\u6b8a\u5c42\u3002", "result": "\u5efa\u7acb\u4e86\u5728s\u9636Holder\u5e73\u6ed1\u5ea6\u4e0b\u7684n^{-s/(2s+1)}\u6536\u655b\u901f\u5ea6\u548c\u6e10\u8fd1\u6b63\u6001\u6027\u3002", "conclusion": "ReLU\u57fa\u6700\u5927\u5f97\u5206\u4f30\u8ba1\u5668\u4e0d\u4ec5\u4f18\u5316\u66f4\u5bb9\u6613\uff0c\u8fd8\u80fd\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684\u591a\u6307\u6807\u5355\u4ea4\u53c9\u6761\u4ef6\u6846\u67b6\uff0c\u4e14\u53ef\u901a\u8fc7\u73b0\u4ee3DNN\u8f6f\u786c\u4ef6\u5b9e\u73b0\u3002"}}
{"id": "2511.19372", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2511.19372", "abs": "https://arxiv.org/abs/2511.19372", "authors": ["Raimondo Pala"], "title": "Identification, estimation and inference in Panel Vector Autoregressions using external instruments", "comment": null, "summary": "This paper proposes an identification inspired from the SVAR-IV literature that uses external instruments to identify PVARs, and discusses associated issues of identification, estimation, and inference.\n  I introduce a form of local average treatment effect - the $\u03bc$-LATE - which arises when a continuous instrument targets a binary treatment. Under standard assumptions of independence, exclusion, and monotonicity, I show that externally instrumented PVARs estimate the $\u03bc$-LATE. Monte Carlo simulations illustrate that confidence sets based on the Anderson-Rubin statistics deliver reliable convergence for impulse responses.\n  As an application, I instrument state-level military spending with the state's share of national spending to estimate the dynamic fiscal multiplier. I find multipliers above unity, with effects concentrated in the contemporaneous year and persisting into the following year.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSVAR-IV\u6587\u732e\u7684\u5916\u90e8\u5de5\u5177\u53d8\u91cf\u8bc6\u522b\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u9762\u677f\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u8ba8\u8bba\u4e86\u76f8\u5173\u7684\u8bc6\u522b\u3001\u4f30\u8ba1\u548c\u63a8\u65ad\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u9762\u677f\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u8bc6\u522b\u95ee\u9898\uff0c\u4f5c\u8005\u501f\u9274SVAR-IV\u6587\u732e\u4e2d\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u53d8\u91cf\u6765\u8bc6\u522bPVAR\u6a21\u578b\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u8bc6\u522b\u7b56\u7565\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u5c40\u90e8\u5e73\u5747\u5904\u7406\u6548\u5e94\uff08\u03bc-LATE\uff09\u7684\u6982\u5ff5\uff0c\u5f53\u8fde\u7eed\u5de5\u5177\u53d8\u91cf\u9488\u5bf9\u4e8c\u5143\u5904\u7406\u65f6\u51fa\u73b0\u3002\u5728\u72ec\u7acb\u6027\u3001\u6392\u4ed6\u6027\u548c\u5355\u8c03\u6027\u6807\u51c6\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u5916\u90e8\u5de5\u5177\u53d8\u91cfPVAR\u4f30\u8ba1\u03bc-LATE\u3002\u4f7f\u7528Anderson-Rubin\u7edf\u8ba1\u91cf\u6784\u5efa\u7f6e\u4fe1\u96c6\u8fdb\u884c\u63a8\u65ad\u3002", "result": "\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\uff0c\u57fa\u4e8eAnderson-Rubin\u7edf\u8ba1\u91cf\u7684\u7f6e\u4fe1\u96c6\u80fd\u591f\u4e3a\u8109\u51b2\u54cd\u5e94\u63d0\u4f9b\u53ef\u9760\u7684\u6536\u655b\u6027\u3002\u5e94\u7528\u7814\u7a76\u4e2d\uff0c\u4f7f\u7528\u5dde\u7ea7\u519b\u4e8b\u652f\u51fa\u5360\u5168\u56fd\u652f\u51fa\u7684\u4efd\u989d\u4f5c\u4e3a\u5de5\u5177\u53d8\u91cf\u4f30\u8ba1\u52a8\u6001\u8d22\u653f\u4e58\u6570\uff0c\u53d1\u73b0\u4e58\u6570\u5927\u4e8e1\uff0c\u6548\u5e94\u96c6\u4e2d\u5728\u5f53\u5e74\u5e76\u6301\u7eed\u5230\u4e0b\u4e00\u5e74\u3002", "conclusion": "\u5916\u90e8\u5de5\u5177\u53d8\u91cf\u65b9\u6cd5\u4e3aPVAR\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bc6\u522b\u7b56\u7565\uff0c\u03bc-LATE\u6982\u5ff5\u6709\u52a9\u4e8e\u7406\u89e3\u8fde\u7eed\u5de5\u5177\u53d8\u91cf\u5bf9\u4e8c\u5143\u5904\u7406\u7684\u6548\u5e94\uff0cAnderson-Rubin\u7f6e\u4fe1\u96c6\u5728\u63a8\u65ad\u4e2d\u8868\u73b0\u53ef\u9760\uff0c\u5e94\u7528\u7814\u7a76\u8bc1\u5b9e\u4e86\u8d22\u653f\u4e58\u6570\u5927\u4e8e1\u7684\u53d1\u73b0\u3002"}}
{"id": "2511.17816", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.17816", "abs": "https://arxiv.org/abs/2511.17816", "authors": ["Jose R. Palacio", "Katherine B. Ensor", "Sallie A. Keller", "Rebecca Schneider", "Kaavya Domakonda", "Loren Hopkins", "Lauren B. Stadler"], "title": "Inferring Transmission Dynamics of Respiratory Syncytial Virus from Houston Wastewater", "comment": "17 pages (including Appendix, pp. 15-18), 6 figures", "summary": "Wastewater-based epidemiology (WBE) is an effective tool for tracking community circulation of respiratory viruses. We address estimating the effective reproduction number ($R_t$) and the relative number of infections from wastewater viral load. Using weekly Houston data on respiratory syncytial virus (RSV), we implement a parsimonious Bayesian renewal model that links latent infections to measured viral load through biologically motivated generation and shedding kernels. The framework yields estimates of $R_t$ and relative infections, enabling a coherent interpretation of transmission timing and phase. We compare two input strategies-(i) raw viral-load measurements with a log-scale standard deviation, and (ii) state-space-filtered load estimates with time-varying variances-and find no practically meaningful differences in inferred trajectories or peak timing. Given this equivalence, we report the filtered input as a pragmatic default because it embeds week-specific variances while leaving epidemiological conclusions unchanged.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u8d1d\u53f6\u65af\u66f4\u65b0\u6a21\u578b\uff0c\u901a\u8fc7\u5e9f\u6c34\u75c5\u6bd2\u8f7d\u91cf\u6570\u636e\u4f30\u7b97\u547c\u5438\u9053\u5408\u80de\u75c5\u6bd2\u7684\u6709\u6548\u518d\u751f\u6570(R_t)\u548c\u76f8\u5bf9\u611f\u67d3\u6570\uff0c\u6bd4\u8f83\u4e86\u4e24\u79cd\u8f93\u5165\u7b56\u7565\u5e76\u63a8\u8350\u4f7f\u7528\u72b6\u6001\u7a7a\u95f4\u6ee4\u6ce2\u65b9\u6cd5\u3002", "motivation": "\u5e9f\u6c34\u6d41\u884c\u75c5\u5b66\u662f\u8ffd\u8e2a\u793e\u533a\u547c\u5438\u9053\u75c5\u6bd2\u4f20\u64ad\u7684\u6709\u6548\u5de5\u5177\uff0c\u4f46\u9700\u8981\u5f00\u53d1\u53ef\u9760\u7684\u65b9\u6cd5\u4ece\u5e9f\u6c34\u75c5\u6bd2\u8f7d\u91cf\u6570\u636e\u4e2d\u4f30\u7b97\u5173\u952e\u6d41\u884c\u75c5\u5b66\u53c2\u6570\u5982\u6709\u6548\u518d\u751f\u6570\u548c\u611f\u67d3\u89c4\u6a21\u3002", "method": "\u4f7f\u7528\u4f11\u65af\u987f\u547c\u5438\u9053\u5408\u80de\u75c5\u6bd2\u7684\u5468\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7b80\u7ea6\u7684\u8d1d\u53f6\u65af\u66f4\u65b0\u6a21\u578b\uff0c\u901a\u8fc7\u751f\u7269\u5b66\u9a71\u52a8\u7684\u4e16\u4ee3\u548c\u8131\u843d\u6838\u51fd\u6570\u5c06\u6f5c\u5728\u611f\u67d3\u4e0e\u6d4b\u91cf\u7684\u75c5\u6bd2\u8f7d\u91cf\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u6bd4\u8f83\u4e86\u4e24\u79cd\u8f93\u5165\u7b56\u7565\uff08\u539f\u59cb\u75c5\u6bd2\u8f7d\u91cf\u6d4b\u91cf\u548c\u72b6\u6001\u7a7a\u95f4\u6ee4\u6ce2\u4f30\u8ba1\uff09\uff0c\u53d1\u73b0\u5728\u63a8\u65ad\u8f68\u8ff9\u6216\u5cf0\u503c\u65f6\u95f4\u4e0a\u6ca1\u6709\u5b9e\u9645\u610f\u4e49\u7684\u5dee\u5f02\u3002", "conclusion": "\u63a8\u8350\u4f7f\u7528\u72b6\u6001\u7a7a\u95f4\u6ee4\u6ce2\u8f93\u5165\u4f5c\u4e3a\u5b9e\u7528\u9ed8\u8ba4\u65b9\u6cd5\uff0c\u56e0\u4e3a\u5b83\u5d4c\u5165\u4e86\u5468\u7279\u5f02\u6027\u65b9\u5dee\u540c\u65f6\u4fdd\u6301\u6d41\u884c\u75c5\u5b66\u7ed3\u8bba\u4e0d\u53d8\u3002"}}
{"id": "2511.17540", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17540", "abs": "https://arxiv.org/abs/2511.17540", "authors": ["Ryudai Iwakami", "Bo Peng", "Hiroyuki Hanyu", "Tasuku Ishigooka", "Takuya Azumi"], "title": "AUTOSAR AP and ROS 2 Collaboration Framework", "comment": "9 pages. This version includes minor \\lstlisting configuration adjustments for successful compilation. The page count is now nine pages due to the addition of author information. There are no other significant changes to the content or layout. Originally published at Euromicro Conference DSD 2024", "summary": "The field of autonomous vehicle research is advancing rapidly, necessitating platforms that meet real-time performance, safety, and security requirements for practical deployment. AUTOSAR Adaptive Platform (AUTOSAR AP) is widely adopted in development to meet these criteria; however, licensing constraints and tool implementation challenges limit its use in research. Conversely, Robot Operating System 2 (ROS 2) is predominantly used in research within the autonomous driving domain, leading to a disparity between research and development platforms that hinders swift commercialization. This paper proposes a collaboration framework that enables AUTOSAR AP and ROS 2 to communicate with each other using a Data Distribution Service for Real-Time Systems (DDS). In contrast, AUTOSAR AP uses Scalable service-Oriented Middleware over IP (SOME/IP) for communication. The proposed framework bridges these protocol differences, ensuring seamless interaction between the two platforms. We validate the functionality and performance of our bridge converter through empirical analysis, demonstrating its efficiency in conversion time and ease of integration with ROS 2 tools. Furthermore, the availability of the proposed collaboration framework is improved by automatically generating a configuration file for the proposed bridge converter.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8fde\u63a5AUTOSAR AP\u548cROS 2\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7DDS\u534f\u8bae\u6865\u63a5\u4e24\u79cd\u5e73\u53f0\u7684\u901a\u4fe1\u5dee\u5f02\uff0c\u5b9e\u73b0\u7814\u7a76\u5e73\u53f0\u4e0e\u5f00\u53d1\u5e73\u53f0\u7684\u96c6\u6210\u3002", "motivation": "AUTOSAR AP\u5728\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\u4f46\u53d7\u9650\u4e8e\u8bb8\u53ef\u548c\u5de5\u5177\u95ee\u9898\uff0cROS 2\u5728\u7814\u7a76\u4e2d\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u5bfc\u81f4\u7814\u7a76\u5f00\u53d1\u5e73\u53f0\u5206\u79bb\u963b\u788d\u5546\u4e1a\u5316\u8fdb\u7a0b\u3002", "method": "\u4f7f\u7528DDS\u534f\u8bae\u6784\u5efa\u6865\u63a5\u8f6c\u6362\u5668\uff0c\u89e3\u51b3AUTOSAR AP\u7684SOME/IP\u534f\u8bae\u4e0eROS 2\u7684\u901a\u4fe1\u534f\u8bae\u5dee\u5f02\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u914d\u7f6e\u6587\u4ef6\u3002", "result": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u9a8c\u8bc1\u4e86\u6865\u63a5\u8f6c\u6362\u5668\u7684\u529f\u80fd\u548c\u6027\u80fd\uff0c\u5728\u8f6c\u6362\u65f6\u95f4\u548cROS 2\u5de5\u5177\u96c6\u6210\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u534f\u4f5c\u6846\u67b6\u6210\u529f\u8fde\u63a5\u4e86AUTOSAR AP\u548cROS 2\u5e73\u53f0\uff0c\u63d0\u9ad8\u4e86\u6846\u67b6\u53ef\u7528\u6027\uff0c\u4fc3\u8fdb\u4e86\u7814\u7a76\u5411\u5546\u4e1a\u5316\u7684\u8f6c\u5316\u3002"}}
{"id": "2511.18542", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.18542", "abs": "https://arxiv.org/abs/2511.18542", "authors": ["Chengwei Zhou", "Gourav Datta"], "title": "Learning Scalable Temporal Representations in Spiking Neural Networks Without Labels", "comment": "Under review", "summary": "Spiking neural networks (SNNs) exhibit temporal, sparse, and event-driven dynamics that make them appealing for efficient inference. However, extending these models to self-supervised regimes remains challenging because the discontinuities introduced by spikes break the cross-view gradient correspondences required by contrastive and consistency-driven objectives. This work introduces a training paradigm that enables large SNN architectures to be optimized without labeled data. We formulate a dual-path neuron in which a spike-generating process is paired with a differentiable surrogate branch, allowing gradients to propagate across augmented inputs while preserving a fully spiking implementation at inference. In addition, we propose temporal alignment objectives that enforce representational coherence both across spike timesteps and between augmented views. Using convolutional and transformer-style SNN backbones, we demonstrate ImageNet-scale self-supervised pretraining and strong transfer to classification, detection, and segmentation benchmarks. Our best model, a fully self-supervised Spikformer-16-512, achieves 70.1% top-1 accuracy on ImageNet-1K, demonstrating that unlabeled learning in high-capacity SNNs is feasible at modern scale", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u53cc\u8def\u5f84\u795e\u7ecf\u5143\u548c\u65f6\u5e8f\u5bf9\u9f50\u76ee\u6807\uff0c\u5b9e\u73b0\u5728\u5927\u89c4\u6a21\u65e0\u6807\u7b7e\u6570\u636e\u4e0a\u7684\u8bad\u7ec3\uff0c\u5728ImageNet\u4e0a\u8fbe\u523070.1%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u9ad8\u6548\u63a8\u7406\u7684\u4f18\u52bf\uff0c\u4f46\u5176\u8109\u51b2\u7684\u4e0d\u8fde\u7eed\u6027\u7834\u574f\u4e86\u5bf9\u6bd4\u5b66\u4e60\u548c\u4e00\u81f4\u6027\u76ee\u6807\u6240\u9700\u7684\u8de8\u89c6\u56fe\u68af\u5ea6\u5bf9\u5e94\u5173\u7cfb\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u81ea\u76d1\u7763\u5b66\u4e60\u573a\u666f\u3002", "method": "\u8bbe\u8ba1\u4e86\u53cc\u8def\u5f84\u795e\u7ecf\u5143\u7ed3\u6784\uff0c\u5c06\u8109\u51b2\u751f\u6210\u8fc7\u7a0b\u4e0e\u53ef\u5fae\u5206\u4ee3\u7406\u5206\u652f\u914d\u5bf9\uff0c\u5141\u8bb8\u68af\u5ea6\u5728\u589e\u5f3a\u8f93\u5165\u95f4\u4f20\u64ad\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u65f6\u7684\u5168\u8109\u51b2\u5b9e\u73b0\uff1b\u63d0\u51fa\u4e86\u8de8\u8109\u51b2\u65f6\u95f4\u6b65\u548c\u589e\u5f3a\u89c6\u56fe\u95f4\u7684\u65f6\u5e8f\u5bf9\u9f50\u76ee\u6807\u3002", "result": "\u4f7f\u7528\u5377\u79ef\u548cTransformer\u98ce\u683c\u7684SNN\u9aa8\u5e72\u7f51\u7edc\uff0c\u5728ImageNet\u89c4\u6a21\u4e0a\u5b9e\u73b0\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u5728\u5206\u7c7b\u3001\u68c0\u6d4b\u548c\u5206\u5272\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0cSpikformer-16-512\u6a21\u578b\u8fbe\u523070.1%\u7684ImageNet-1K top-1\u51c6\u786e\u7387\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728\u9ad8\u5bb9\u91cfSNN\u4e2d\u8fdb\u884c\u65e0\u6807\u7b7e\u5b66\u4e60\u5728\u73b0\u4ee3\u89c4\u6a21\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17541", "categories": ["cs.AI", "cs.IT", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.17541", "abs": "https://arxiv.org/abs/2511.17541", "authors": ["Seyma Yaman Kayadibi"], "title": "Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation", "comment": null, "summary": "This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.", "AI": {"tldr": "\u57fa\u4e8e\u83b1\u5e03\u5c3c\u8328\u5355\u5b50\u8bba\u6784\u5efa\u4e86\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u8bb0\u5fc6\u7cfb\u7edf\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5c0620\u4e2a\u6838\u5fc3\u547d\u9898\u6620\u5c04\u5230\u4fe1\u606f\u8bba\u67b6\u6784\uff0c\u5b9a\u4e49\u4e86\u6a21\u5757\u5316\u8bb0\u5fc6\u5355\u5143\u53ca\u5176\u6f14\u5316\u89c4\u5f8b\u3002", "motivation": "\u4e3a\u4eba\u5de5\u667a\u80fd\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u6570\u5b66\u4e25\u8c28\u3001\u54f2\u5b66\u57fa\u7840\u575a\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u53e4\u5178\u5f62\u800c\u4e0a\u5b66\u6982\u5ff5\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u4fe1\u606f\u8bba\u6307\u6807\u3002", "method": "\u5c06\u5355\u5b50\u8bba\u547d\u9898\u6620\u5c04\u5230\u4fe1\u606f\u8bba\u67b6\u6784\uff0c\u5b9a\u4e49\u8bb0\u5fc6\u5355\u5143\u7684\u4e09\u4e2a\u6838\u5fc3\u53c2\u6570\uff08\u771f\u503c\u5206\u6570\u3001\u5197\u4f59\u53c2\u6570\u3001\u6743\u91cd\u8d21\u732e\uff09\uff0c\u4f7f\u7528\u5bf9\u6570\u53d8\u6362\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u6709\u754c\u5ea6\u91cf\u3002", "result": "\u5efa\u7acb\u4e86\u8bb0\u5fc6\u8001\u5316\u3001\u8868\u5f81\u7a33\u5b9a\u6027\u3001\u663e\u8457\u6027\u7684\u91cf\u5316\u6307\u6807\uff0c\u8bc1\u660e\u4e86\u7cbe\u70bc\u4e0d\u53d8\u6027\u3001\u7ed3\u6784\u53ef\u5206\u89e3\u6027\u548c\u5c3a\u5ea6\u53d8\u6362\u5355\u8c03\u6027\u7b49\u6570\u5b66\u6027\u8d28\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u8bc4\u4f30\u5de5\u5177\uff0c\u8fd8\u4e3a\u6784\u5efa\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u4eba\u5de5\u667a\u80fd\u8bb0\u5fc6\u67b6\u6784\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u84dd\u56fe\u3002"}}
{"id": "2511.17866", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.17866", "abs": "https://arxiv.org/abs/2511.17866", "authors": ["Ethan Hartley"], "title": "Narratives to Numbers: Large Language Models and Economic Policy Uncertainty", "comment": null, "summary": "This study evaluates large language models as estimable classifiers and clarifies how modeling choices shape downstream measurement error. Revisiting the Economic Policy Uncertainty index, we show that contemporary classifiers substantially outperform dictionary rules, better track human audit assessments, and extend naturally to noisy historical and multilingual news. We use these tools to construct a new nineteenth-century U.S. index from more than 360 million newspaper articles and exploratory cross-country indices with a single multilingual model. Taken together, our results show that LLMs can systematically improve text-derived measures and should be integrated as explicit measurement tools in empirical economics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u53ef\u4f30\u8ba1\u5206\u7c7b\u5668\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86LLM\u5982\u4f55\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u8bcd\u5178\u89c4\u5219\uff0c\u66f4\u597d\u5730\u8ddf\u8e2a\u4eba\u5de5\u5ba1\u8ba1\u8bc4\u4f30\uff0c\u5e76\u80fd\u81ea\u7136\u5730\u6269\u5c55\u5230\u5608\u6742\u7684\u5386\u53f2\u548c\u591a\u8bed\u8a00\u65b0\u95fb\u6570\u636e\u4e2d\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u6f84\u6e05\u5efa\u6a21\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u4e0b\u6e38\u6d4b\u91cf\u8bef\u5dee\uff0c\u5e76\u8bc4\u4f30LLM\u5728\u6587\u672c\u6d4b\u91cf\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u7ecf\u6d4e\u653f\u7b56\u4e0d\u786e\u5b9a\u6027\u7b49\u6307\u6807\u7684\u6784\u5efa\u4e2d\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6\u7ecf\u6d4e\u653f\u7b56\u4e0d\u786e\u5b9a\u6027\u6307\u6570\uff0c\u4f7f\u7528\u5f53\u4ee3\u5206\u7c7b\u5668\u66ff\u4ee3\u4f20\u7edf\u8bcd\u5178\u89c4\u5219\uff0c\u6784\u5efa\u65b0\u768419\u4e16\u7eaa\u7f8e\u56fd\u6307\u6570\uff08\u57fa\u4e8e3.6\u4ebf\u591a\u7bc7\u62a5\u7eb8\u6587\u7ae0\uff09\u548c\u63a2\u7d22\u6027\u8de8\u56fd\u6307\u6570\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u4ee3\u5206\u7c7b\u5668\u663e\u8457\u4f18\u4e8e\u5b57\u5178\u89c4\u5219\uff0c\u80fd\u66f4\u597d\u5730\u8ddf\u8e2a\u4eba\u7c7b\u5ba1\u8ba1\u8bc4\u4f30\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u5608\u6742\u7684\u5386\u53f2\u548c\u591a\u8bed\u8a00\u65b0\u95fb\u6570\u636e\u3002", "conclusion": "LLM\u53ef\u4ee5\u7cfb\u7edf\u6027\u5730\u6539\u8fdb\u6587\u672c\u884d\u751f\u6d4b\u91cf\uff0c\u5e94\u8be5\u4f5c\u4e3a\u660e\u786e\u7684\u6d4b\u91cf\u5de5\u5177\u6574\u5408\u5230\u5b9e\u8bc1\u7ecf\u6d4e\u5b66\u4e2d\u3002"}}
{"id": "2511.17715", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17715", "abs": "https://arxiv.org/abs/2511.17715", "authors": ["Siying Li", "Lang Tong", "Timothy D. Mount"], "title": "Risk-Based Capacity Accreditation of Resource-Colocated Large Loads in Capacity Markets", "comment": null, "summary": "We study capacity accreditation of resource-colocated large loads, defined as large demands such as data center and manufacturing loads colocated with behind-the-meter generation and storage resources, synchronously connected to the bulk power system, and capable of participating in the wholesale electricity market as an integrated unit. Because the qualified capacity of a resource portfolio is not equal to the sum of its individual resources' qualified capacities, we propose a novel risk-based capacity accreditation framework that evaluates the collective contribution to system reliability. Grounded in the effective load carrying capability (ELCC) metric, the proposed capacity accreditation employs a convex optimization engine that jointly dispatches colocated resources to minimize reliability risk. We apply the developed methodology to a hydrogen manufacturing facility with colocated renewable generation, storage, and fuel cell resources.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u98ce\u9669\u7684\u5bb9\u91cf\u8ba4\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u8d44\u6e90\u5171\u5740\u5927\u578b\u8d1f\u8377\uff08\u5982\u6570\u636e\u4e2d\u5fc3\u548c\u5236\u9020\u8d1f\u8377\uff09\u5bf9\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u96c6\u4f53\u8d21\u732e\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u8054\u5408\u8c03\u5ea6\u5171\u5740\u8d44\u6e90\u6765\u6700\u5c0f\u5316\u53ef\u9760\u6027\u98ce\u9669\u3002", "motivation": "\u7814\u7a76\u8d44\u6e90\u5171\u5740\u5927\u578b\u8d1f\u8377\u7684\u5bb9\u91cf\u8ba4\u8bc1\u95ee\u9898\uff0c\u56e0\u4e3a\u8d44\u6e90\u7ec4\u5408\u7684\u5408\u683c\u5bb9\u91cf\u4e0d\u7b49\u4e8e\u5176\u5404\u4e2a\u8d44\u6e90\u5408\u683c\u5bb9\u91cf\u7684\u603b\u548c\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5bf9\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u96c6\u4f53\u8d21\u732e\u3002", "method": "\u57fa\u4e8e\u6709\u6548\u8d1f\u8377\u627f\u8f7d\u80fd\u529b\uff08ELCC\uff09\u6307\u6807\uff0c\u91c7\u7528\u51f8\u4f18\u5316\u5f15\u64ce\u8054\u5408\u8c03\u5ea6\u5171\u5740\u8d44\u6e90\u4ee5\u6700\u5c0f\u5316\u53ef\u9760\u6027\u98ce\u9669\u3002", "result": "\u5c06\u6240\u5f00\u53d1\u7684\u65b9\u6cd5\u5e94\u7528\u4e8e\u5177\u6709\u5171\u5740\u53ef\u518d\u751f\u80fd\u6e90\u3001\u50a8\u80fd\u548c\u71c3\u6599\u7535\u6c60\u8d44\u6e90\u7684\u6c22\u5236\u9020\u8bbe\u65bd\u3002", "conclusion": "\u63d0\u51fa\u7684\u98ce\u9669\u57fa\u5bb9\u91cf\u8ba4\u8bc1\u6846\u67b6\u80fd\u591f\u51c6\u786e\u8bc4\u4f30\u8d44\u6e90\u5171\u5740\u5927\u578b\u8d1f\u8377\u5bf9\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u8d21\u732e\uff0c\u4e3a\u7535\u529b\u5e02\u573a\u53c2\u4e0e\u63d0\u4f9b\u53ef\u9760\u4f9d\u636e\u3002"}}
{"id": "2511.17569", "categories": ["cs.SI", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.17569", "abs": "https://arxiv.org/abs/2511.17569", "authors": ["Huilin Wang Wenjun Zhang Weibing Deng"], "title": "Diffusion Signals Reveal Hidden Connections: A Physics-Inspired Framework for Link Prediction via Personalized PageRank Signals", "comment": null, "summary": "Link prediction in complex networks--identifying the missing or future connections--remains a cornerstone problem for understanding network evolution and function, yet existing methods struggle to balance computational efficiency with theoretical rigor across heterogeneous topologies. This work introduces a physically principled framework, Diffusion Distance with Personalized PageRank (D-PPR), which unifies static topology with dynamic information flow by modeling nodes as signal sources propagating through the network via Personalized PageRank (PPR) vectors. The method quantifies node-pair similarity through the graph Laplacian-governed diffusion distance between their topology-aware signal distributions, thereby bridging microscopic interactions with macroscopic network dynamics. Systematic benchmarking on synthetic (Barab\u00e1si-Albert, LFR) and seven large-scale real-world networks spanning technology, biology, and social domains demonstrates that D-PPR achieves highly competitive performance, yielding favorable results when compared to representative local and global heuristics, particularly in sparse and modular networks. These findings establish a rigorous foundation for physics-inspired link prediction by revealing that incorporating dynamical processes into structural similarity metrics enables deeper insights into network connectivity patterns, offering both methodological advances and new theoretical perspectives on the interplay between topology and dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6269\u6563\u8ddd\u79bb\u548c\u4e2a\u6027\u5316PageRank\u7684\u7269\u7406\u539f\u7406\u6846\u67b6D-PPR\uff0c\u7528\u4e8e\u590d\u6742\u7f51\u7edc\u4e2d\u7684\u94fe\u8def\u9884\u6d4b\uff0c\u901a\u8fc7\u5efa\u6a21\u8282\u70b9\u4fe1\u53f7\u4f20\u64ad\u6765\u7edf\u4e00\u9759\u6001\u62d3\u6251\u548c\u52a8\u6001\u4fe1\u606f\u6d41\u3002", "motivation": "\u73b0\u6709\u94fe\u8def\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7406\u8bba\u4e25\u8c28\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u5f02\u6784\u62d3\u6251\u7f51\u7edc\u4e2d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7ed3\u5408\u7f51\u7edc\u7ed3\u6784\u548c\u52a8\u6001\u8fc7\u7a0b\u7684\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u7406\u89e3\u7f51\u7edc\u6f14\u5316\u3002", "method": "\u4f7f\u7528\u4e2a\u6027\u5316PageRank\u5411\u91cf\u5efa\u6a21\u8282\u70b9\u4f5c\u4e3a\u4fe1\u53f7\u6e90\u5728\u7f51\u7edc\u4e2d\u7684\u4f20\u64ad\uff0c\u901a\u8fc7\u56fe\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u63a7\u5236\u7684\u6269\u6563\u8ddd\u79bb\u6765\u91cf\u5316\u8282\u70b9\u5bf9\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u5c06\u5fae\u89c2\u76f8\u4e92\u4f5c\u7528\u4e0e\u5b8f\u89c2\u7f51\u7edc\u52a8\u6001\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u5728\u5408\u6210\u7f51\u7edc\uff08Barab\u00e1si-Albert\u3001LFR\uff09\u548c\u4e03\u4e2a\u5927\u89c4\u6a21\u771f\u5b9e\u7f51\u7edc\u4e0a\u7684\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0cD-PPR\u5728\u7a00\u758f\u548c\u6a21\u5757\u5316\u7f51\u7edc\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u4ee3\u8868\u6027\u7684\u5c40\u90e8\u548c\u5168\u5c40\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u52a8\u6001\u8fc7\u7a0b\u878d\u5165\u7ed3\u6784\u76f8\u4f3c\u6027\u5ea6\u91cf\u80fd\u591f\u66f4\u6df1\u5165\u5730\u6d1e\u5bdf\u7f51\u7edc\u8fde\u63a5\u6a21\u5f0f\uff0c\u4e3a\u7269\u7406\u542f\u53d1\u7684\u94fe\u8def\u9884\u6d4b\u5960\u5b9a\u4e86\u4e25\u683c\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u8fdb\u5c55\u548c\u5173\u4e8e\u62d3\u6251\u4e0e\u52a8\u6001\u76f8\u4e92\u4f5c\u7528\u7684\u65b0\u7406\u8bba\u89c6\u89d2\u3002"}}
{"id": "2511.18647", "categories": ["econ.TH", "econ.EM"], "pdf": "https://arxiv.org/pdf/2511.18647", "abs": "https://arxiv.org/abs/2511.18647", "authors": ["Maxwell Rosenthal"], "title": "Prior-Free Information Design", "comment": null, "summary": "This paper introduces a prior-free framework for information design based on partial identification and applies it to robust causal inference. The decision maker observes the distribution of signals generated by an information structure and ranks alternatives by their worst-case payoff over the state distributions consistent with those signals. We characterize the set of robustly implementable actions and show that each can be implemented by an information structure that withholds at most one dimension of information from the decision maker. In the potential outcomes model, every treatment is implementable via an experiment that is almost fully informative.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u90e8\u5206\u8bc6\u522b\u7684\u65e0\u5148\u9a8c\u4fe1\u606f\u8bbe\u8ba1\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u7a33\u5065\u56e0\u679c\u63a8\u65ad\u3002\u51b3\u7b56\u8005\u89c2\u5bdf\u4fe1\u606f\u7ed3\u6784\u751f\u6210\u7684\u4fe1\u53f7\u5206\u5e03\uff0c\u5e76\u6839\u636e\u4e0e\u8fd9\u4e9b\u4fe1\u53f7\u4e00\u81f4\u7684\u72b6\u6001\u5206\u5e03\u7684\u6700\u574f\u60c5\u51b5\u6536\u76ca\u6765\u5bf9\u5907\u9009\u65b9\u6848\u8fdb\u884c\u6392\u5e8f\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u8bbe\u8ba1\u901a\u5e38\u4f9d\u8d56\u4e8e\u5148\u9a8c\u5206\u5e03\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u4e0d\u4f9d\u8d56\u5148\u9a8c\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u90e8\u5206\u8bc6\u522b\u65b9\u6cd5\u5b9e\u73b0\u7a33\u5065\u7684\u4fe1\u606f\u8bbe\u8ba1\uff0c\u7279\u522b\u5173\u6ce8\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u90e8\u5206\u8bc6\u522b\u65b9\u6cd5\uff0c\u51b3\u7b56\u8005\u57fa\u4e8e\u4fe1\u53f7\u5206\u5e03\u7684\u6700\u574f\u60c5\u51b5\u6536\u76ca\u6765\u8bc4\u4f30\u5907\u9009\u65b9\u6848\u3002\u901a\u8fc7\u5206\u6790\u4fe1\u606f\u7ed3\u6784\uff0c\u8bc1\u660e\u6bcf\u4e2a\u53ef\u7a33\u5065\u5b9e\u65bd\u7684\u52a8\u4f5c\u53ef\u4ee5\u901a\u8fc7\u6700\u591a\u4fdd\u7559\u4e00\u7ef4\u4fe1\u606f\u7684\u4fe1\u606f\u7ed3\u6784\u6765\u5b9e\u73b0\u3002", "result": "\u5728\u6f5c\u5728\u7ed3\u679c\u6a21\u578b\u4e2d\uff0c\u6bcf\u4e2a\u5904\u7406\u90fd\u53ef\u4ee5\u901a\u8fc7\u51e0\u4e4e\u5b8c\u5168\u4fe1\u606f\u5316\u7684\u5b9e\u9a8c\u6765\u5b9e\u65bd\u3002\u8bc1\u660e\u4e86\u7a33\u5065\u53ef\u5b9e\u65bd\u52a8\u4f5c\u96c6\u5408\u7684\u7279\u5f81\uff0c\u5e76\u5c55\u793a\u4e86\u4fe1\u606f\u4fdd\u7559\u7684\u7ef4\u5ea6\u9650\u5236\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65e0\u5148\u9a8c\u4fe1\u606f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u5904\u7406\u6548\u679c\u8bc4\u4f30\uff0c\u901a\u8fc7\u6709\u9650\u7684\u4fe1\u606f\u4fdd\u7559\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u7684\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2511.18844", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.18844", "abs": "https://arxiv.org/abs/2511.18844", "authors": ["Iona Ann Sebastian", "S. M. Sunoj"], "title": "Fractional cumulative Residual Inaccuracy in the Quantile Framework and its Appications", "comment": null, "summary": "Fractional cumulative residual inaccuracy (FCRI) measure allows to determine regions of discrepancy between systems, depending on their respective fractional and chaotic map parameters. Most of the theoretical results and applications related to the FCRI of the lifetime random variable are based on the distribution function approach. However, there are situations in which the distribution function may not be available in explicit form but has a closed-form quantile function (QF), an alternative method of representing a probability distribution. Motivated by these, the present study is devoted to introduce a quantile-based FCRI and study its various properties. We also deal with non-parametric estimation of quantile-based FCRI and examine its validity using simulation studies and illustrate its usefulness in measuring the discrepancy between chaotic systems and in measuring the discrepancy in two different time regimes using Nifty 50 dataset.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u5206\u6570\u7d2f\u79ef\u6b8b\u5dee\u4e0d\u7cbe\u786e\u6027(FCRI)\u5ea6\u91cf\uff0c\u7814\u7a76\u4e86\u5176\u6027\u8d28\uff0c\u5e76\u63d0\u51fa\u4e86\u975e\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548cNifty 50\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u5176\u5728\u6d4b\u91cf\u6df7\u6c8c\u7cfb\u7edf\u548c\u4e0d\u540c\u65f6\u95f4\u533a\u95f4\u5dee\u5f02\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u4f20\u7edfFCRI\u65b9\u6cd5\u57fa\u4e8e\u5206\u5e03\u51fd\u6570\uff0c\u4f46\u5728\u5206\u5e03\u51fd\u6570\u65e0\u6cd5\u663e\u5f0f\u8868\u8fbe\u800c\u53ea\u6709\u95ed\u5f0f\u5206\u4f4d\u6570\u51fd\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u5f00\u53d1\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5206\u4f4d\u6570\u7684FCRI\u5b9a\u4e49\uff0c\u7814\u7a76\u4e86\u5176\u6570\u5b66\u6027\u8d28\uff0c\u5f00\u53d1\u4e86\u975e\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548c\u771f\u5b9e\u6570\u636e\u96c6(Nifty 50)\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86\u57fa\u4e8e\u5206\u4f4d\u6570\u7684FCRI\u7406\u8bba\u6846\u67b6\uff0c\u9a8c\u8bc1\u4e86\u4f30\u8ba1\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u6d4b\u91cf\u6df7\u6c8c\u7cfb\u7edf\u5dee\u5f02\u548c\u4e0d\u540c\u65f6\u95f4\u533a\u95f4\u5dee\u5f02\u65b9\u9762\u7684\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u57fa\u4e8e\u5206\u4f4d\u6570\u7684FCRI\u4e3a\u5728\u53ea\u6709\u5206\u4f4d\u6570\u51fd\u6570\u53ef\u7528\u7684\u60c5\u51b5\u4e0b\u6d4b\u91cf\u7cfb\u7edf\u5dee\u5f02\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5728\u6df7\u6c8c\u7cfb\u7edf\u548c\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.17578", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17578", "abs": "https://arxiv.org/abs/2511.17578", "authors": ["Neelotpal Dutta", "Tianyu Zhang", "Tao Liu", "Yongxue Chen", "Charlie C. L. Wang"], "title": "Implicit Neural Field-Based Process Planning for Multi-Axis Manufacturing: Direct Control over Collision Avoidance and Toolpath Geometry", "comment": null, "summary": "Existing curved-layer-based process planning methods for multi-axis manufacturing address collisions only indirectly and generate toolpaths in a post-processing step, leaving toolpath geometry uncontrolled during optimization. We present an implicit neural field-based framework for multi-axis process planning that overcomes these limitations by embedding both layer generation and toolpath design within a single differentiable pipeline. Using sinusoidally activated neural networks to represent layers and toolpaths as implicit fields, our method enables direct evaluation of field values and derivatives at any spatial point, thereby allowing explicit collision avoidance and joint optimization of manufacturing layers and toolpaths. We further investigate how network hyperparameters and objective definitions influence singularity behavior and topology transitions, offering built-in mechanisms for regularization and stability control. The proposed approach is demonstrated on examples in both additive and subtractive manufacturing, validating its generality and effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u573a\u7684\u591a\u8f74\u5236\u9020\u5de5\u827a\u89c4\u5212\u6846\u67b6\uff0c\u5c06\u5c42\u751f\u6210\u548c\u5200\u5177\u8def\u5f84\u8bbe\u8ba1\u6574\u5408\u5230\u5355\u4e00\u53ef\u5fae\u5206\u6d41\u7a0b\u4e2d\uff0c\u5b9e\u73b0\u76f4\u63a5\u78b0\u649e\u907f\u514d\u548c\u8054\u5408\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u66f2\u9762\u5206\u5c42\u5236\u9020\u65b9\u6cd5\u53ea\u80fd\u95f4\u63a5\u5904\u7406\u78b0\u649e\u95ee\u9898\uff0c\u4e14\u5200\u5177\u8def\u5f84\u5728\u540e\u7eed\u5904\u7406\u4e2d\u751f\u6210\uff0c\u5bfc\u81f4\u4f18\u5316\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u63a7\u5236\u5200\u5177\u8def\u5f84\u51e0\u4f55\u5f62\u72b6\u3002", "method": "\u4f7f\u7528\u6b63\u5f26\u6fc0\u6d3b\u795e\u7ecf\u7f51\u7edc\u5c06\u5236\u9020\u5c42\u548c\u5200\u5177\u8def\u5f84\u8868\u793a\u4e3a\u9690\u5f0f\u573a\uff0c\u6784\u5efa\u53ef\u5fae\u5206\u7ba1\u9053\uff0c\u53ef\u76f4\u63a5\u8bc4\u4f30\u4efb\u610f\u7a7a\u95f4\u70b9\u7684\u573a\u503c\u548c\u5bfc\u6570\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u589e\u6750\u548c\u51cf\u6750\u5236\u9020\u793a\u4f8b\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u901a\u7528\u6027\u548c\u6709\u6548\u6027\uff0c\u80fd\u591f\u63a7\u5236\u5947\u70b9\u884c\u4e3a\u548c\u62d3\u6251\u8f6c\u6362\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u5185\u7f6e\u7684\u6b63\u5219\u5316\u548c\u7a33\u5b9a\u6027\u63a7\u5236\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5236\u9020\u5c42\u548c\u5200\u5177\u8def\u5f84\u7684\u8054\u5408\u4f18\u5316\u3002"}}
{"id": "2511.19348", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.19348", "abs": "https://arxiv.org/abs/2511.19348", "authors": ["Komal Komal", "Frances Cleary", "Ram Prasadh Narayanan", "John Wells", "Marco Buiatti", "Louise Bennett"], "title": "Design and Validation of a Modular Smart Headband with Embroidered Electrodes for Comfortable EEG Monitoring", "comment": null, "summary": "The wearable EEG device sector is advancing rapidly, enabling fast and reliable detection of brain activity for investigating brain function and pathology. However, many current EEG systems remain challenging for users with neurological conditions due to bulky wiring, lengthy skin preparation, gel-induced discomfort, risk of irritation, and high cost, all of which limit long-term monitoring. This study presents a proof-of-concept smart modular headband incorporating adjustable, replaceable embroidered electrodes for EEG acquisition. Compared with conventional devices, the smart headband reduces wiring complexity, removes the need for skin preparation, and minimizes irritation associated with gel-based electrodes. Its modular structure allows adjustable fitting without requiring multiple size options, enhancing comfort and adaptability for everyday EEG monitoring. The smart headband prototype was tested on 10 healthy university students using three behavioral tasks: (1) eyes open/closed, (2) auditory oddball, and (3) visual oddball paradigms. The smart headband successfully captured alpha peaks during the eyes-open/closed task (p = 0.01) and reliably recorded the event-related potentials associated with the oddball effects - the auditory P300 (p = 0.014) and the visual N170 (p = 0.013) - demonstrating an equivalent performance to a commercial sponge-based EEG cap. A user survey indicated improved comfort and usability, with participants reporting that the soft, structurally designed headband enhanced wearability relative to a conventional cap. Overall, this prototype provides a comfortable, modular, and cost-effective solution to reliable EEG monitoring in real-world applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u667a\u80fd\u6a21\u5757\u5316\u5934\u5e26\uff0c\u91c7\u7528\u53ef\u8c03\u8282\u3001\u53ef\u66f4\u6362\u7684\u523a\u7ee3\u7535\u6781\u8fdb\u884cEEG\u91c7\u96c6\uff0c\u76f8\u6bd4\u4f20\u7edf\u8bbe\u5907\u51cf\u5c11\u4e86\u5e03\u7ebf\u590d\u6742\u6027\uff0c\u65e0\u9700\u76ae\u80a4\u51c6\u5907\uff0c\u5e76\u6700\u5c0f\u5316\u4e86\u51dd\u80f6\u7535\u6781\u7684\u4e0d\u9002\u611f\u3002", "motivation": "\u5f53\u524dEEG\u7cfb\u7edf\u5b58\u5728\u5e03\u7ebf\u590d\u6742\u3001\u76ae\u80a4\u51c6\u5907\u65f6\u95f4\u957f\u3001\u51dd\u80f6\u5f15\u8d77\u4e0d\u9002\u3001\u523a\u6fc0\u98ce\u9669\u548c\u6210\u672c\u9ad8\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u957f\u671f\u76d1\u6d4b\uff0c\u7279\u522b\u662f\u5bf9\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u60a3\u8005\u3002", "method": "\u8bbe\u8ba1\u667a\u80fd\u6a21\u5757\u5316\u5934\u5e26\u539f\u578b\uff0c\u572810\u540d\u5065\u5eb7\u5927\u5b66\u751f\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u4f7f\u7528\u4e09\u79cd\u884c\u4e3a\u4efb\u52a1\uff1a\u7741\u773c/\u95ed\u773c\u3001\u542c\u89c9oddball\u548c\u89c6\u89c9oddball\u8303\u5f0f\u3002", "result": "\u667a\u80fd\u5934\u5e26\u6210\u529f\u6355\u6349\u5230\u7741\u773c/\u95ed\u773c\u4efb\u52a1\u4e2d\u7684alpha\u5cf0(p=0.01)\uff0c\u53ef\u9760\u8bb0\u5f55\u4e86oddball\u6548\u5e94\u76f8\u5173\u7684\u4e8b\u4ef6\u76f8\u5173\u7535\u4f4d - \u542c\u89c9P300(p=0.014)\u548c\u89c6\u89c9N170(p=0.013)\uff0c\u6027\u80fd\u4e0e\u5546\u4e1a\u6d77\u7ef5\u57faEEG\u5e3d\u76f8\u5f53\u3002\u7528\u6237\u8c03\u67e5\u663e\u793a\u8212\u9002\u5ea6\u548c\u53ef\u7528\u6027\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u8be5\u539f\u578b\u4e3a\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u53ef\u9760EEG\u76d1\u6d4b\u63d0\u4f9b\u4e86\u8212\u9002\u3001\u6a21\u5757\u5316\u548c\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17643", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17643", "abs": "https://arxiv.org/abs/2511.17643", "authors": ["Yayan Qiu", "Sean Hanna"], "title": "Fluid Grey 2: How Well Does Generative Adversarial Network Learn Deeper Topology Structure in Architecture That Matches Images?", "comment": null, "summary": "Taking into account the regional characteristics of intrinsic and extrinsic properties of space is an essential issue in architectural design and urban renewal, which is often achieved step by step using image and graph-based GANs. However, each model nesting and data conversion may cause information loss, and it is necessary to streamline the tools to facilitate architects and users to participate in the design. Therefore, this study hopes to prove that I2I GAN also has the potential to recognize topological relationships autonomously. Therefore, this research proposes a method for quickly detecting the ability of pix2pix to learn topological relationships, which is achieved by adding two Grasshopper-based detection modules before and after GAN. At the same time, quantitative data is provided and its learning process is visualized, and changes in different input modes such as greyscale and RGB affect its learning efficiency. There are two innovations in this paper: 1) It proves that pix2pix can automatically learn spatial topological relationships and apply them to architectural design. 2) It fills the gap in detecting the performance of Image-based Generation GAN from a topological perspective. Moreover, the detection method proposed in this study takes a short time and is simple to operate. The two detection modules can be widely used for customizing image datasets with the same topological structure and for batch detection of topological relationships of images. In the future, this paper may provide a theoretical foundation and data support for the application of architectural design and urban renewal that use GAN to preserve spatial topological characteristics.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc1\u660epix2pix GAN\u80fd\u591f\u81ea\u52a8\u5b66\u4e60\u7a7a\u95f4\u62d3\u6251\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7Grasshopper\u6a21\u5757\u5728GAN\u524d\u540e\u8fdb\u884c\u68c0\u6d4b\uff0c\u4e3a\u5efa\u7b51\u8bbe\u8ba1\u548c\u57ce\u5e02\u66f4\u65b0\u4e2d\u4fdd\u6301\u7a7a\u95f4\u62d3\u6251\u7279\u6027\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u56fe\u50cf\u548c\u56fe\u8868\u7684GAN\u65b9\u6cd5\u5728\u6a21\u578b\u5d4c\u5957\u548c\u6570\u636e\u8f6c\u6362\u4e2d\u53ef\u80fd\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u9700\u8981\u7b80\u5316\u5de5\u5177\u4ee5\u4fbf\u5efa\u7b51\u5e08\u548c\u7528\u6237\u53c2\u4e0e\u8bbe\u8ba1\u8fc7\u7a0b\u3002", "method": "\u5728pix2pix GAN\u524d\u540e\u6dfb\u52a0\u57fa\u4e8eGrasshopper\u7684\u68c0\u6d4b\u6a21\u5757\uff0c\u63d0\u4f9b\u5b9a\u91cf\u6570\u636e\u5e76\u53ef\u89c6\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7814\u7a76\u4e0d\u540c\u8f93\u5165\u6a21\u5f0f\uff08\u7070\u5ea6\u3001RGB\uff09\u5bf9\u5b66\u4e60\u6548\u7387\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660epix2pix\u80fd\u591f\u81ea\u52a8\u5b66\u4e60\u7a7a\u95f4\u62d3\u6251\u5173\u7cfb\u5e76\u5e94\u7528\u4e8e\u5efa\u7b51\u8bbe\u8ba1\uff0c\u586b\u8865\u4e86\u4ece\u62d3\u6251\u89d2\u5ea6\u68c0\u6d4b\u57fa\u4e8e\u56fe\u50cf\u7684\u751f\u6210GAN\u6027\u80fd\u7684\u7a7a\u767d\u3002", "conclusion": "\u8be5\u68c0\u6d4b\u65b9\u6cd5\u8017\u65f6\u77ed\u3001\u64cd\u4f5c\u7b80\u5355\uff0c\u53ef\u5e7f\u6cdb\u7528\u4e8e\u5b9a\u5236\u5177\u6709\u76f8\u540c\u62d3\u6251\u7ed3\u6784\u7684\u56fe\u50cf\u6570\u636e\u96c6\u548c\u6279\u91cf\u68c0\u6d4b\u56fe\u50cf\u62d3\u6251\u5173\u7cfb\uff0c\u4e3a\u4fdd\u6301\u7a7a\u95f4\u62d3\u6251\u7279\u6027\u7684\u5efa\u7b51\u8bbe\u8ba1\u548c\u57ce\u5e02\u66f4\u65b0\u5e94\u7528\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2511.18576", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.18576", "abs": "https://arxiv.org/abs/2511.18576", "authors": ["Ayobami Paul Abolade", "Ibrahim Olanrewaju Lawal", "Kamoru Lanre Akanbi", "Ahmed Orilonise Salami"], "title": "Unlocking The Future of Food Security Through Access to Finance for Sustainable Agribusiness Performance", "comment": "Keywords: Access To Finance, Farmer, Agribusiness, Food Security", "summary": "Access to finance is vital for improving food security, particularly in developing nations where agricultural production is crucial. Despite several financial interventions targeted at increasing agricultural production, smallholder farmers continue to lack access to reasonable, timely, and sufficient financing, limiting their ability to invest in improved technology and inputs, lowering productivity and food supply. This study examines the relationship between access to finance and food security among smallholder farmers in Ogun State, employing institutional theory as a theoretical framework. The study takes a quantitative method, with a survey for the research design and a population of 37,200 agricultural smallholder farmers. A sample size of 380 was chosen using probability sampling and simple random techniques. The data were analysed via Partial Least Squares Structural Equation Modelling (PLS-SEM). The findings demonstrate a favourable relationship between access to finance and food security, with an R2-value of 0.615 indicating a robust link. These findings underline the need of improving financial institutions and implementing enabling policies to enable farmers have access to the financial resources they need to achieve food security outcomes.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5c3c\u65e5\u5229\u4e9a\u5965\u8d21\u5dde\u5c0f\u519c\u6237\u83b7\u53d6\u91d1\u878d\u4e0e\u7cae\u98df\u5b89\u5168\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u4e24\u8005\u5b58\u5728\u663e\u8457\u6b63\u76f8\u5173\u5173\u7cfb\u3002", "motivation": "\u5728\u53d1\u5c55\u4e2d\u56fd\u5bb6\uff0c\u5c3d\u7ba1\u6709\u9488\u5bf9\u519c\u4e1a\u751f\u4ea7\u7684\u91d1\u878d\u5e72\u9884\u63aa\u65bd\uff0c\u4f46\u5c0f\u519c\u6237\u4ecd\u7136\u96be\u4ee5\u83b7\u5f97\u5408\u7406\u3001\u53ca\u65f6\u548c\u5145\u8db3\u7684\u878d\u8d44\uff0c\u8fd9\u9650\u5236\u4e86\u4ed6\u4eec\u5bf9\u6539\u826f\u6280\u672f\u548c\u6295\u5165\u7684\u6295\u8d44\u80fd\u529b\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u751f\u4ea7\u529b\u548c\u7cae\u98df\u4f9b\u5e94\u3002", "method": "\u91c7\u7528\u5b9a\u91cf\u7814\u7a76\u65b9\u6cd5\uff0c\u4f7f\u7528\u8c03\u67e5\u95ee\u5377\uff0c\u901a\u8fc7\u6982\u7387\u62bd\u6837\u548c\u7b80\u5355\u968f\u673a\u62bd\u6837\u4ece37,200\u540d\u5c0f\u519c\u6237\u4e2d\u9009\u53d6380\u4e2a\u6837\u672c\uff0c\u4f7f\u7528\u504f\u6700\u5c0f\u4e8c\u4e58\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b(PLS-SEM)\u5206\u6790\u6570\u636e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u83b7\u53d6\u91d1\u878d\u4e0e\u7cae\u98df\u5b89\u5168\u4e4b\u95f4\u5b58\u5728\u79ef\u6781\u5173\u7cfb\uff0cR2\u503c\u4e3a0.615\uff0c\u8868\u660e\u4e24\u8005\u5173\u7cfb\u5bc6\u5207\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u6539\u5584\u91d1\u878d\u673a\u6784\u548c\u5b9e\u65bd\u652f\u6301\u6027\u653f\u7b56\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u4f7f\u519c\u6c11\u80fd\u591f\u83b7\u5f97\u5b9e\u73b0\u7cae\u98df\u5b89\u5168\u6240\u9700\u7684\u91d1\u878d\u8d44\u6e90\u3002"}}
{"id": "2511.17730", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17730", "abs": "https://arxiv.org/abs/2511.17730", "authors": ["Zeinab Nezami", "Shehr Bano", "Abdelaziz Salama", "Maryam Hafeez", "Syed Ali Raza Zaidi"], "title": "Safety and Risk Pathways in Cooperative Generative Multi-Agent Systems: A Telecom Perspective", "comment": null, "summary": "Generative multiagent systems are rapidly emerging as transformative tools for scalable automation and adaptive decisionmaking in telecommunications. Despite their promise, these systems introduce novel risks that remain underexplored, particularly when agents operate asynchronously across layered architectures. This paper investigates key safety pathways in telecomfocused Generative MultiAgent Systems (GMAS), emphasizing risks of miscoordination and semantic drift shaped by persona diversity. We propose a modular safety evaluation framework that integrates agentlevel checks on code quality and compliance with systemlevel safety metrics. Using controlled simulations across 32 persona sets, five questions, and multiple iterative runs, we demonstrate progressive improvements in analyzer penalties and AllocatorCoder consistency, alongside persistent vulnerabilities such as policy drift and variability under specific persona combinations. Our findings provide the first domaingrounded evidence that persona design, coding style, and planning orientation directly influence the stability and safety of telecom GMAS, highlighting both promising mitigation strategies and open risks for future deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u7535\u4fe1\u9886\u57df\u751f\u6210\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b89\u5168\u98ce\u9669\uff0c\u91cd\u70b9\u5173\u6ce8\u89d2\u8272\u591a\u6837\u6027\u5bfc\u81f4\u7684\u534f\u8c03\u5931\u8bef\u548c\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u7535\u4fe1\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5f02\u6b65\u64cd\u4f5c\u548c\u5206\u5c42\u67b6\u6784\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u7279\u522b\u662f\u89d2\u8272\u591a\u6837\u6027\u5bfc\u81f4\u7684\u534f\u8c03\u5931\u8bef\u548c\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u6a21\u5757\u5316\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u6574\u5408\u4e86\u667a\u80fd\u4f53\u7ea7\u522b\u7684\u4ee3\u7801\u8d28\u91cf\u548c\u5408\u89c4\u6027\u68c0\u67e5\uff0c\u4ee5\u53ca\u7cfb\u7edf\u7ea7\u522b\u7684\u5b89\u5168\u6307\u6807\u3002\u901a\u8fc732\u4e2a\u89d2\u8272\u96c6\u30015\u4e2a\u95ee\u9898\u548c\u591a\u6b21\u8fed\u4ee3\u7684\u53d7\u63a7\u6a21\u62df\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5206\u6790\u5668\u60e9\u7f5a\u548c\u5206\u914d\u5668-\u7f16\u7801\u5668\u4e00\u81f4\u6027\u9010\u6b65\u6539\u5584\uff0c\u4f46\u7279\u5b9a\u89d2\u8272\u7ec4\u5408\u4e0b\u4ecd\u5b58\u5728\u7b56\u7565\u6f02\u79fb\u548c\u53d8\u5f02\u6027\u7b49\u6301\u7eed\u6f0f\u6d1e\u3002\u89d2\u8272\u8bbe\u8ba1\u3001\u7f16\u7801\u98ce\u683c\u548c\u89c4\u5212\u5bfc\u5411\u76f4\u63a5\u5f71\u54cd\u7cfb\u7edf\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u7814\u7a76\u9996\u6b21\u63d0\u4f9b\u4e86\u9886\u57df\u5b9e\u8bc1\uff0c\u8868\u660e\u89d2\u8272\u8bbe\u8ba1\u3001\u7f16\u7801\u98ce\u683c\u548c\u89c4\u5212\u5bfc\u5411\u5bf9\u7535\u4fe1GMAS\u7684\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u6709\u76f4\u63a5\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u6709\u524d\u666f\u7684\u7f13\u89e3\u7b56\u7565\u548c\u672a\u6765\u90e8\u7f72\u4e2d\u7684\u5f00\u653e\u98ce\u9669\u3002"}}
{"id": "2511.17574", "categories": ["cs.SI", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.17574", "abs": "https://arxiv.org/abs/2511.17574", "authors": ["Eamon Earl", "Chen Ding", "Richard Valenzano", "Drai Paulen-Patterson"], "title": "Constructing Political Coordinates: Aggregating Over the Opposition for Diverse News Recommendation", "comment": "Due to appear in the proceedings of the 2025 IEEE International Conference on Big Data", "summary": "In the past two decades, open access to news and information has increased rapidly, empowering educated political growth within democratic societies. News recommender systems (NRSs) have shown to be useful in this process, minimizing political disengagement and information overload by providing individuals with articles on topics that matter to them. Unfortunately, NRSs often conflate underlying user interest with the partisan bias of the articles in their reading history and with the most popular biases present in the coverage of their favored topics. Over extended interaction, this can result in the formation of filter bubbles and the polarization of user partisanship. In this paper, we propose a novel embedding space called Constructed Political Coordinates (CPC), which models the political partisanship of users over a given topic-space, relative to a larger sample population. We apply a simple collaborative filtering (CF) framework using CPC-based correlation to recommend articles sourced from oppositional users, who have different biases from the user in question. We compare against classical CF methods and find that CPC-based methods promote pointed bias diversity and better match the true political tolerance of users, while classical methods implicitly exploit biases to maximize interaction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5d4c\u5165\u7a7a\u95f4CPC\u6765\u5efa\u6a21\u7528\u6237\u653f\u6cbb\u7acb\u573a\uff0c\u901a\u8fc7\u57fa\u4e8eCPC\u7684\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u5bf9\u7acb\u7528\u6237\u7684\u6587\u7ae0\uff0c\u4ee5\u4fc3\u8fdb\u504f\u89c1\u591a\u6837\u6027\u548c\u5339\u914d\u7528\u6237\u771f\u5b9e\u653f\u6cbb\u5bb9\u5fcd\u5ea6\u3002", "motivation": "\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u7ecf\u5e38\u5c06\u7528\u6237\u5174\u8da3\u4e0e\u6587\u7ae0\u515a\u6d3e\u504f\u89c1\u6df7\u6dc6\uff0c\u5bfc\u81f4\u8fc7\u6ee4\u6c14\u6ce1\u548c\u7528\u6237\u515a\u6d3e\u6781\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faConstructed Political Coordinates (CPC)\u5d4c\u5165\u7a7a\u95f4\u5efa\u6a21\u7528\u6237\u653f\u6cbb\u7acb\u573a\uff0c\u5e94\u7528\u57fa\u4e8eCPC\u76f8\u5173\u6027\u7684\u534f\u540c\u8fc7\u6ee4\u6846\u67b6\u63a8\u8350\u5bf9\u7acb\u7528\u6237\u7684\u6587\u7ae0\u3002", "result": "CPC\u65b9\u6cd5\u80fd\u4fc3\u8fdb\u504f\u89c1\u591a\u6837\u6027\u5e76\u66f4\u597d\u5339\u914d\u7528\u6237\u771f\u5b9e\u653f\u6cbb\u5bb9\u5fcd\u5ea6\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u4f1a\u9690\u5f0f\u5229\u7528\u504f\u89c1\u6765\u6700\u5927\u5316\u4e92\u52a8\u3002", "conclusion": "CPC\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8fc7\u6ee4\u6c14\u6ce1\u548c\u515a\u6d3e\u6781\u5316\u95ee\u9898\u3002"}}
{"id": "2511.17981", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.17981", "abs": "https://arxiv.org/abs/2511.17981", "authors": ["Zeyu He"], "title": "Exploration Is Not What It Seeks: Catalytic Exploration under Status Quo Uncertainty", "comment": "This is the extended working paper version containing additional proofs, structural estimation details, and theoretical extensions", "summary": "We identify a distinct motive for search, termed catalytic exploration, where agents rationally explore alternatives they expect to reject to resolve uncertainty about the status quo. By decomposing option value into switching and catalytic components, we show that high exploration rates can coexist with bounded switching probabilities. This mechanism generates three insights. First, strong catalytic motives cause separating equilibria to collapse in signaling games as receivers explore indiscriminately. Second, agents optimally acquire more precise information about the status quo than about alternatives, reversing rational inattention intuitions. Third, catalytic exploration creates negative externalities: information technology improvements can paradoxically reduce welfare by encouraging excessive benchmarking.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\"\u50ac\u5316\u63a2\u7d22\"\u6982\u5ff5\uff0c\u5373\u7406\u6027\u4ee3\u7406\u4eba\u4f1a\u63a2\u7d22\u9884\u671f\u4f1a\u62d2\u7edd\u7684\u9009\u9879\uff0c\u4ee5\u89e3\u51b3\u5bf9\u73b0\u72b6\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u901a\u8fc7\u5c06\u671f\u6743\u4ef7\u503c\u5206\u89e3\u4e3a\u8f6c\u6362\u548c\u50ac\u5316\u6210\u5206\uff0c\u89e3\u91ca\u4e86\u9ad8\u63a2\u7d22\u7387\u4e0e\u6709\u9650\u8f6c\u6362\u6982\u7387\u5171\u5b58\u7684\u73b0\u8c61\u3002", "motivation": "\u8bc6\u522b\u4e00\u79cd\u65b0\u7684\u641c\u7d22\u52a8\u673a\u2014\u2014\u50ac\u5316\u63a2\u7d22\uff0c\u89e3\u91ca\u4e3a\u4ec0\u4e48\u7406\u6027\u4ee3\u7406\u4eba\u4f1a\u63a2\u7d22\u4ed6\u4eec\u9884\u671f\u4f1a\u62d2\u7edd\u7684\u9009\u9879\uff0c\u4ee5\u53ca\u8fd9\u79cd\u63a2\u7d22\u884c\u4e3a\u5982\u4f55\u5f71\u54cd\u51b3\u7b56\u8fc7\u7a0b\u548c\u5e02\u573a\u5747\u8861\u3002", "method": "\u5c06\u671f\u6743\u4ef7\u503c\u5206\u89e3\u4e3a\u8f6c\u6362\u6210\u5206\u548c\u50ac\u5316\u6210\u5206\uff0c\u5efa\u7acb\u7406\u8bba\u6a21\u578b\u5206\u6790\u50ac\u5316\u63a2\u7d22\u5bf9\u51b3\u7b56\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5e76\u5e94\u7528\u4e8e\u4fe1\u53f7\u535a\u5f08\u3001\u7406\u6027\u758f\u5ffd\u548c\u4fe1\u606f\u5916\u90e8\u6027\u7b49\u573a\u666f\u3002", "result": "\u53d1\u73b0\u50ac\u5316\u63a2\u7d22\u5bfc\u81f4\u4e09\u4e2a\u91cd\u8981\u7ed3\u679c\uff1a1\uff09\u5f3a\u50ac\u5316\u52a8\u673a\u4f1a\u4f7f\u4fe1\u53f7\u535a\u5f08\u4e2d\u7684\u5206\u79bb\u5747\u8861\u5d29\u6e83\uff1b2\uff09\u4ee3\u7406\u4eba\u4f1a\u4f18\u5148\u83b7\u53d6\u5173\u4e8e\u73b0\u72b6\u7684\u7cbe\u786e\u4fe1\u606f\u800c\u975e\u66ff\u4ee3\u9009\u9879\uff1b3\uff09\u50ac\u5316\u63a2\u7d22\u4ea7\u751f\u8d1f\u5916\u90e8\u6027\uff0c\u4fe1\u606f\u6280\u672f\u6539\u8fdb\u53ef\u80fd\u56e0\u9f13\u52b1\u8fc7\u5ea6\u57fa\u51c6\u6d4b\u8bd5\u800c\u964d\u4f4e\u798f\u5229\u3002", "conclusion": "\u50ac\u5316\u63a2\u7d22\u4f5c\u4e3a\u4e00\u79cd\u72ec\u7279\u7684\u641c\u7d22\u52a8\u673a\uff0c\u5bf9\u4f20\u7edf\u51b3\u7b56\u7406\u8bba\u548c\u5e02\u573a\u5747\u8861\u5206\u6790\u63d0\u51fa\u4e86\u91cd\u8981\u4fee\u6b63\uff0c\u63ed\u793a\u4e86\u4fe1\u606f\u83b7\u53d6\u548c\u63a2\u7d22\u884c\u4e3a\u4e2d\u672a\u88ab\u5145\u5206\u8ba4\u8bc6\u7684\u7406\u6027\u673a\u5236\u3002"}}
{"id": "2511.19039", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.19039", "abs": "https://arxiv.org/abs/2511.19039", "authors": ["Cassandra C. Chou", "Scott L. Zeger", "Benjamin Q. Huynh"], "title": "Validity in machine learning for extreme event attribution", "comment": null, "summary": "Extreme event attribution (EEA), an approach for assessing the extent to which disasters are caused by climate change, is crucial for informing climate policy and legal proceedings. Machine learning is increasingly used for EEA by modeling rare weather events otherwise too complex or computationally intensive to model using traditional simulation methods. However, the validity of using machine learning in this context remains unclear, particularly as high-stakes machine learning applications in general are criticized for inherent bias and lack of robustness. Here we use machine learning and simulation analyses to evaluate EEA in the context of California wildfire data from 2003-2020. We identify three major threats to validity: (1) individual event attribution estimates are highly sensitive to algorithmic design choices; (2) common performance metrics like area under the ROC curve or Brier score are not strongly correlated with attribution error, facilitating suboptimal model selection; and (3) distribution shift -- changes in temperature across climate scenarios -- substantially degrades predictive performance. To address these challenges, we propose a more valid and robust attribution analysis based on aggregate machine learning estimates, using an additional metric -- mean calibration error -- to assess model performance, and using subgroup and propensity diagnostics to assess distribution shift.", "AI": {"tldr": "\u673a\u5668\u5b66\u4e60\u5728\u6781\u7aef\u4e8b\u4ef6\u5f52\u56e0\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u6709\u6548\u6027\u5a01\u80c1\uff1a\u7b97\u6cd5\u9009\u62e9\u654f\u611f\u6027\u3001\u6027\u80fd\u6307\u6807\u4e0e\u5f52\u56e0\u8bef\u5dee\u76f8\u5173\u6027\u5f31\u3001\u5206\u5e03\u504f\u79fb\u5f71\u54cd\u9884\u6d4b\u6027\u80fd\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u805a\u5408\u4f30\u8ba1\u3001\u5e73\u5747\u6821\u51c6\u8bef\u5dee\u548c\u5206\u5e03\u504f\u79fb\u8bca\u65ad\u7684\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u5728\u6781\u7aef\u4e8b\u4ef6\u5f52\u56e0\u4e2d\u7684\u6709\u6548\u6027\uff0c\u56e0\u4e3a\u9ad8\u98ce\u9669\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u5e38\u88ab\u6279\u8bc4\u5b58\u5728\u504f\u89c1\u548c\u7f3a\u4e4f\u7a33\u5065\u6027\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u6a21\u62df\u5206\u6790\u8bc4\u4f30\u52a0\u5dde2003-2020\u5e74\u91ce\u706b\u6570\u636e\u7684\u6781\u7aef\u4e8b\u4ef6\u5f52\u56e0\uff0c\u8bc6\u522b\u6709\u6548\u6027\u5a01\u80c1\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u4e3b\u8981\u6709\u6548\u6027\u5a01\u80c1\uff1a\u7b97\u6cd5\u8bbe\u8ba1\u654f\u611f\u6027\u3001\u6027\u80fd\u6307\u6807\u4e0e\u5f52\u56e0\u8bef\u5dee\u76f8\u5173\u6027\u5f31\u3001\u6e29\u5ea6\u5206\u5e03\u504f\u79fb\u663e\u8457\u964d\u4f4e\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u57fa\u4e8e\u805a\u5408\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\u3001\u5e73\u5747\u6821\u51c6\u8bef\u5dee\u548c\u5206\u5e03\u504f\u79fb\u8bca\u65ad\u7684\u66f4\u6709\u6548\u548c\u7a33\u5065\u7684\u5f52\u56e0\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2511.17603", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.17603", "abs": "https://arxiv.org/abs/2511.17603", "authors": ["Chelsea-Xi Chen", "Zhe Zhang", "Aven-Le Zhou"], "title": "Translating Cultural Choreography from Humanoid Forms to Robotic Arm", "comment": null, "summary": "Robotic arm choreography often reproduces trajectories while missing cultural semantics. This study examines whether symbolic posture transfer with joint space compatible notation can preserve semantic fidelity on a six-degree-of-freedom arm and remain portable across morphologies. We implement ROPERA, a three-stage pipeline for encoding culturally codified postures, composing symbolic sequences, and decoding to servo commands. A scene from Kunqu opera, \\textit{The Peony Pavilion}, serves as the material for evaluation. The procedure includes corpus-based posture selection, symbolic scoring, direct joint angle execution, and a visual layer with light painting and costume-informed colors. Results indicate reproducible execution with intended timing and cultural legibility reported by experts and audiences. The study points to non-anthropocentric cultural preservation and portable authoring workflows. Future work will design dance-informed transition profiles, extend the notation to locomotion with haptic, musical, and spatial cues, and test portability across platforms.", "AI": {"tldr": "\u63d0\u51faROPERA\u7cfb\u7edf\uff0c\u901a\u8fc7\u7b26\u53f7\u59ff\u6001\u8f6c\u79fb\u548c\u5173\u8282\u7a7a\u95f4\u517c\u5bb9\u8868\u793a\u6cd5\uff0c\u5728\u516d\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u4e0a\u5b9e\u73b0\u6587\u5316\u8bed\u4e49\u4fdd\u771f\u5ea6\u7684\u6606\u66f2\u821e\u8e48\u7f16\u6392\uff0c\u5e76\u9a8c\u8bc1\u5176\u8de8\u5f62\u6001\u79fb\u690d\u6027\u3002", "motivation": "\u4f20\u7edf\u673a\u68b0\u81c2\u7f16\u821e\u5e38\u590d\u5236\u8f68\u8ff9\u4f46\u7f3a\u5931\u6587\u5316\u8bed\u4e49\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u4fdd\u6301\u6587\u5316\u8bed\u4e49\u4fdd\u771f\u5ea6\u4e14\u53ef\u8de8\u5e73\u53f0\u79fb\u690d\u7684\u7b26\u53f7\u5316\u7f16\u821e\u65b9\u6cd5\u3002", "method": "\u5b9e\u73b0ROPERA\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u7f16\u7801\u6587\u5316\u7f16\u7801\u59ff\u6001\u3001\u7ec4\u5408\u7b26\u53f7\u5e8f\u5217\u3001\u89e3\u7801\u4e3a\u4f3a\u670d\u547d\u4ee4\uff0c\u4f7f\u7528\u6606\u66f2\u300a\u7261\u4e39\u4ead\u300b\u573a\u666f\u8fdb\u884c\u8bc4\u4f30\uff0c\u5305\u542b\u57fa\u4e8e\u8bed\u6599\u7684\u59ff\u6001\u9009\u62e9\u3001\u7b26\u53f7\u8bb0\u8c31\u3001\u76f4\u63a5\u5173\u8282\u89d2\u5ea6\u6267\u884c\u548c\u89c6\u89c9\u5c42\u5904\u7406\u3002", "result": "\u7ed3\u679c\u663e\u793a\u53ef\u91cd\u73b0\u7684\u6267\u884c\u6548\u679c\uff0c\u5177\u6709\u9884\u671f\u7684\u65f6\u95f4\u5b89\u6392\uff0c\u4e13\u5bb6\u548c\u89c2\u4f17\u62a5\u544a\u6587\u5316\u53ef\u8bfb\u6027\u826f\u597d\u3002", "conclusion": "\u7814\u7a76\u6307\u5411\u975e\u4eba\u7c7b\u4e2d\u5fc3\u7684\u6587\u5316\u4fdd\u5b58\u548c\u53ef\u79fb\u690d\u7684\u521b\u4f5c\u5de5\u4f5c\u6d41\u7a0b\uff0c\u672a\u6765\u5c06\u8bbe\u8ba1\u821e\u8e48\u611f\u77e5\u7684\u8fc7\u6e21\u914d\u7f6e\u6587\u4ef6\uff0c\u6269\u5c55\u7b26\u53f7\u8868\u793a\u6cd5\u4ee5\u5305\u542b\u89e6\u89c9\u3001\u97f3\u4e50\u548c\u7a7a\u95f4\u7ebf\u7d22\uff0c\u5e76\u6d4b\u8bd5\u8de8\u5e73\u53f0\u79fb\u690d\u6027\u3002"}}
{"id": "2511.17648", "categories": ["cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2511.17648", "abs": "https://arxiv.org/abs/2511.17648", "authors": ["Florian Laronze", "Audrey Landuran", "Bernard N'kaoua"], "title": "Technologies to Support Self-determination for People with Intellectual Disability and ASD", "comment": null, "summary": "This article focuses on the concept of self-determination and the design and validation of digital tools intended to promote the self-determination of vulnerable people. Self-determination is an essential skill for carrying out daily activities. But in certain situations, and for certain populations, self-determination is lacking, which leads to the inability to live an independent life and in favorable conditions of well-being and health. In recent years, self-determination enhancing technologies have been developed and used to promote independent living among people with self-determination disorders. We will illustrate the main digital tools to support self-determination developed for two populations of people suffering from self-determination disorders: people with an intellectual disability and people with an autism spectrum disorder. The ability of these digital assistants to improve the comfort of life of these people will also be presented and discussed.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4fc3\u8fdb\u5f31\u52bf\u7fa4\u4f53\u81ea\u51b3\u80fd\u529b\u7684\u6570\u5b57\u5de5\u5177\u8bbe\u8ba1\u4e0e\u9a8c\u8bc1\uff0c\u91cd\u70b9\u5173\u6ce8\u667a\u529b\u969c\u788d\u548c\u81ea\u95ed\u75c7\u8c31\u7cfb\u969c\u788d\u4eba\u7fa4\u7684\u81ea\u51b3\u652f\u6301\u6280\u672f\u3002", "motivation": "\u81ea\u51b3\u80fd\u529b\u662f\u5f00\u5c55\u65e5\u5e38\u6d3b\u52a8\u7684\u91cd\u8981\u6280\u80fd\uff0c\u4f46\u67d0\u4e9b\u4eba\u7fa4\u7f3a\u4e4f\u81ea\u51b3\u80fd\u529b\uff0c\u5bfc\u81f4\u65e0\u6cd5\u72ec\u7acb\u751f\u6d3b\u5e76\u5f71\u54cd\u798f\u7949\u548c\u5065\u5eb7\u3002", "method": "\u5f00\u53d1\u548c\u4f7f\u7528\u81ea\u51b3\u589e\u5f3a\u6280\u672f\uff0c\u4e3a\u667a\u529b\u969c\u788d\u548c\u81ea\u95ed\u75c7\u8c31\u7cfb\u969c\u788d\u4eba\u7fa4\u8bbe\u8ba1\u6570\u5b57\u652f\u6301\u5de5\u5177\u3002", "result": "\u5c55\u793a\u4e86\u4e3b\u8981\u6570\u5b57\u5de5\u5177\u53ca\u5176\u6539\u5584\u8fd9\u4e9b\u4eba\u7fa4\u751f\u6d3b\u8212\u9002\u5ea6\u7684\u80fd\u529b\u3002", "conclusion": "\u6570\u5b57\u52a9\u624b\u80fd\u591f\u6709\u6548\u4fc3\u8fdb\u81ea\u51b3\u969c\u788d\u4eba\u7fa4\u7684\u72ec\u7acb\u751f\u6d3b\uff0c\u5176\u6548\u679c\u5df2\u5f97\u5230\u9a8c\u8bc1\u548c\u8ba8\u8bba\u3002"}}
{"id": "2511.17644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17644", "abs": "https://arxiv.org/abs/2511.17644", "authors": ["Chaitanya Kumar Kolli"], "title": "Hybrid Neuro-Symbolic Models for Ethical AI in Risk-Sensitive Domains", "comment": "6 pages, 6 figures", "summary": "Artificial intelligence deployed in risk-sensitive domains such as healthcare, finance, and security must not only achieve predictive accuracy but also ensure transparency, ethical alignment, and compliance with regulatory expectations. Hybrid neuro symbolic models combine the pattern-recognition strengths of neural networks with the interpretability and logical rigor of symbolic reasoning, making them well-suited for these contexts. This paper surveys hybrid architectures, ethical design considerations, and deployment patterns that balance accuracy with accountability. We highlight techniques for integrating knowledge graphs with deep inference, embedding fairness-aware rules, and generating human-readable explanations. Through case studies in healthcare decision support, financial risk management, and autonomous infrastructure, we show how hybrid systems can deliver reliable and auditable AI. Finally, we outline evaluation protocols and future directions for scaling neuro symbolic frameworks in complex, high stakes environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8c03\u67e5\u4e86\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u5728\u98ce\u9669\u654f\u611f\u9886\u57df\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u5982\u4f55\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u5f0f\u8bc6\u522b\u80fd\u529b\u548c\u7b26\u53f7\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\u6765\u5e73\u8861\u51c6\u786e\u6027\u4e0e\u95ee\u8d23\u6027\u3002", "motivation": "\u5728\u533b\u7597\u3001\u91d1\u878d\u548c\u5b89\u5168\u7b49\u98ce\u9669\u654f\u611f\u9886\u57df\uff0cAI\u4e0d\u4ec5\u9700\u8981\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u5fc5\u987b\u786e\u4fdd\u900f\u660e\u5ea6\u3001\u4f26\u7406\u5bf9\u9f50\u548c\u76d1\u7ba1\u5408\u89c4\u3002\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u7ed3\u5408\u4e86\u795e\u7ecf\u7f51\u7edc\u548c\u7b26\u53f7\u63a8\u7406\u7684\u4f18\u52bf\uff0c\u9002\u5408\u8fd9\u4e9b\u573a\u666f\u3002", "method": "\u8c03\u67e5\u6df7\u5408\u67b6\u6784\u3001\u4f26\u7406\u8bbe\u8ba1\u8003\u8651\u548c\u90e8\u7f72\u6a21\u5f0f\uff0c\u91cd\u70b9\u4ecb\u7ecd\u77e5\u8bc6\u56fe\u8c31\u4e0e\u6df1\u5ea6\u63a8\u7406\u7684\u96c6\u6210\u3001\u516c\u5e73\u611f\u77e5\u89c4\u5219\u7684\u5d4c\u5165\u4ee5\u53ca\u751f\u6210\u4eba\u7c7b\u53ef\u8bfb\u89e3\u91ca\u7684\u6280\u672f\u3002", "result": "\u901a\u8fc7\u533b\u7597\u51b3\u7b56\u652f\u6301\u3001\u91d1\u878d\u98ce\u9669\u7ba1\u7406\u548c\u81ea\u4e3b\u57fa\u7840\u8bbe\u65bd\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u6df7\u5408\u7cfb\u7edf\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u4e14\u53ef\u5ba1\u8ba1\u7684AI\u3002", "conclusion": "\u6982\u8ff0\u4e86\u8bc4\u4f30\u534f\u8bae\u548c\u672a\u6765\u65b9\u5411\uff0c\u65e8\u5728\u5728\u590d\u6742\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u6269\u5c55\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u3002"}}
{"id": "2511.18582", "categories": ["econ.GN", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18582", "abs": "https://arxiv.org/abs/2511.18582", "authors": ["David Almog"], "title": "Barriers to AI Adoption: Image Concerns at Work", "comment": null, "summary": "Concerns about how workers are perceived can deter effective collaboration with artificial intelligence (AI). In a field experiment on a large online labor market, I hired 450 U.S.-based remote workers to complete an image-categorization job assisted by AI recommendations. Workers were incentivized by the prospect of a contract extension based on an HR evaluator's feedback. I find that workers adopt AI recommendations at lower rates when their reliance on AI is visible to the evaluator, resulting in a measurable decline in task performance. The effects are present despite a conservative design in which workers know that the evaluator is explicitly instructed to assess expected accuracy on the same AI-assisted task. This reduction in AI reliance persists even when the evaluator is reassured about workers' strong performance history on the platform, underscoring how difficult these concerns are to alleviate. Leveraging the platform's public feedback feature, I introduce a novel incentive-compatible elicitation method showing that workers fear heavy reliance on AI signals a lack of confidence in their own judgment, a trait they view as essential when collaborating with AI.", "AI": {"tldr": "\u5de5\u4eba\u62c5\u5fc3\u88abHR\u8bc4\u4f30\u8005\u770b\u5230\u8fc7\u5ea6\u4f9d\u8d56AI\u4f1a\u663e\u5f97\u7f3a\u4e4f\u81ea\u4fe1\uff0c\u4ece\u800c\u964d\u4f4eAI\u63a8\u8350\u91c7\u7eb3\u7387\uff0c\u5bfc\u81f4\u4efb\u52a1\u8868\u73b0\u4e0b\u964d", "motivation": "\u7814\u7a76\u5de5\u4eba\u5bf9AI\u534f\u4f5c\u7684\u611f\u77e5\u62c5\u5fe7\u5982\u4f55\u5f71\u54cd\u5408\u4f5c\u6548\u679c\uff0c\u7279\u522b\u662f\u5f53AI\u4f9d\u8d56\u53ef\u89c1\u65f6\u5bf9\u5de5\u4f5c\u8868\u73b0\u7684\u5f71\u54cd", "method": "\u5728\u5927\u578b\u5728\u7ebf\u52b3\u52a8\u529b\u5e02\u573a\u8fdb\u884c\u5b9e\u5730\u5b9e\u9a8c\uff0c\u96c7\u4f63450\u540d\u7f8e\u56fd\u8fdc\u7a0b\u5de5\u4f5c\u8005\u5b8c\u6210\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff0c\u4f7f\u7528AI\u63a8\u8350\u8f85\u52a9\uff0c\u901a\u8fc7HR\u8bc4\u4f30\u53cd\u9988\u6fc0\u52b1\u5de5\u4eba", "result": "\u5f53\u5de5\u4eba\u4f9d\u8d56AI\u7684\u884c\u4e3a\u5bf9\u8bc4\u4f30\u8005\u53ef\u89c1\u65f6\uff0cAI\u63a8\u8350\u91c7\u7eb3\u7387\u663e\u8457\u964d\u4f4e\uff0c\u4efb\u52a1\u8868\u73b0\u4e0b\u964d\uff1b\u5373\u4f7f\u8bc4\u4f30\u8005\u88ab\u544a\u77e5\u5de5\u4eba\u6709\u826f\u597d\u8868\u73b0\u5386\u53f2\uff0c\u8fd9\u79cd\u5f71\u54cd\u4f9d\u7136\u5b58\u5728", "conclusion": "\u5de5\u4eba\u62c5\u5fc3\u8fc7\u5ea6\u4f9d\u8d56AI\u4f1a\u88ab\u89c6\u4e3a\u7f3a\u4e4f\u81ea\u4fe1\uff0c\u8fd9\u79cd\u62c5\u5fe7\u96be\u4ee5\u6d88\u9664\uff0c\u663e\u8457\u5f71\u54cdAI\u534f\u4f5c\u6548\u679c"}}
{"id": "2511.17865", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17865", "abs": "https://arxiv.org/abs/2511.17865", "authors": ["Suk Ki Lee", "Ronnie F. P. Stone", "Max Gao", "Wenlong Zhang", "Zhenghui Sha", "Hyunwoong Ko"], "title": "Generative Model Predictive Control in Manufacturing Processes: A Review", "comment": "24 pages, 5 figures, Review article", "summary": "Manufacturing processes are inherently dynamic and uncertain, with varying parameters and nonlinear behaviors, making robust control essential for maintaining quality and reliability. Traditional control methods often fail under these conditions due to their reactive nature. Model Predictive Control (MPC) has emerged as a more advanced framework, leveraging process models to predict future states and optimize control actions. However, MPC relies on simplified models that often fail to capture complex dynamics, and it struggles with accurate state estimation and handling the propagation of uncertainty in manufacturing environments. Machine learning (ML) has been introduced to enhance MPC by modeling nonlinear dynamics and learning latent representations that support predictive modeling, state estimation, and optimization. Yet existing ML-driven MPC approaches remain deterministic and correlation-focused, motivating the exploration of generative. Generative ML offers new opportunities by learning data distributions, capturing hidden patterns, and inherently managing uncertainty, thereby complementing MPC. This review highlights five representative methods and examines how each has been integrated into MPC components, including predictive modeling, state estimation, and optimization. By synthesizing these cases, we outline the common ways generative ML can systematically enhance MPC and provide a framework for understanding its potential in diverse manufacturing processes. We identify key research gaps, propose future directions, and use a representative case to illustrate how generative ML-driven MPC can extend broadly across manufacturing. Taken together, this review positions generative ML not as an incremental add-on but as a transformative approach to reshape predictive control for next-generation manufacturing systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u5982\u4f55\u589e\u5f3a\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5728\u5236\u9020\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5efa\u6a21\u975e\u7ebf\u6027\u52a8\u6001\u3001\u5b66\u4e60\u6f5c\u5728\u8868\u793a\u6765\u6539\u8fdb\u9884\u6d4b\u5efa\u6a21\u3001\u72b6\u6001\u4f30\u8ba1\u548c\u4f18\u5316\uff0c\u4ece\u800c\u5e94\u5bf9\u5236\u9020\u73af\u5883\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u590d\u6742\u52a8\u6001\u3002", "motivation": "\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u5728\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u7684\u5236\u9020\u8fc7\u7a0b\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0cMPC\u867d\u7136\u66f4\u5148\u8fdb\u4f46\u4f9d\u8d56\u7b80\u5316\u6a21\u578b\u4e14\u96be\u4ee5\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u3002\u673a\u5668\u5b66\u4e60\u88ab\u5f15\u5165\u589e\u5f3aMPC\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4ecd\u662f\u786e\u5b9a\u6027\u7684\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u751f\u6210\u5f0fML\u6765\u66f4\u597d\u5730\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u7efc\u8ff0\u4e86\u4e94\u79cd\u4ee3\u8868\u6027\u65b9\u6cd5\uff0c\u5206\u6790\u5b83\u4eec\u5982\u4f55\u96c6\u6210\u5230MPC\u7ec4\u4ef6\u4e2d\uff0c\u5305\u62ec\u9884\u6d4b\u5efa\u6a21\u3001\u72b6\u6001\u4f30\u8ba1\u548c\u4f18\u5316\u3002\u901a\u8fc7\u6848\u4f8b\u7efc\u5408\uff0c\u6784\u5efa\u4e86\u751f\u6210\u5f0fML\u7cfb\u7edf\u589e\u5f3aMPC\u7684\u6846\u67b6\u3002", "result": "\u751f\u6210\u5f0fML\u80fd\u591f\u5b66\u4e60\u6570\u636e\u5206\u5e03\u3001\u6355\u6349\u9690\u85cf\u6a21\u5f0f\u5e76\u56fa\u6709\u5730\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u4ece\u800c\u8865\u5145MPC\u3002\u901a\u8fc7\u4ee3\u8868\u6027\u6848\u4f8b\u5c55\u793a\u4e86\u751f\u6210\u5f0fML\u9a71\u52a8\u7684MPC\u5728\u5236\u9020\u8fc7\u7a0b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u751f\u6210\u5f0fML\u4e0d\u662f\u6e10\u8fdb\u5f0f\u9644\u52a0\u7ec4\u4ef6\uff0c\u800c\u662f\u91cd\u5851\u4e0b\u4e00\u4ee3\u5236\u9020\u7cfb\u7edf\u9884\u6d4b\u63a7\u5236\u7684\u53d8\u9769\u6027\u65b9\u6cd5\uff0c\u4e3a\u5236\u9020\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u4e0d\u786e\u5b9a\u6027\u7ba1\u7406\u548c\u590d\u6742\u52a8\u6001\u5efa\u6a21\u80fd\u529b\u3002"}}
{"id": "2511.17657", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.17657", "abs": "https://arxiv.org/abs/2511.17657", "authors": ["Imran Ansari", "Pawanesh Pawanesh"], "title": "A Comprehensive Review of Core-Periphery and Community Detection Paradigms", "comment": null, "summary": "Meso-scale structures, such as core-periphery (CP) and community structure, have attracted significant attention in modern network science. While communities are characterized by dense intra-group and sparse inter-group connections, CP structures consist of a densely interconnected core and a loosely connected periphery, where peripheral nodes are typically linked to the core. Despite growing interest, identifying CP structures remains an ill-posed problem, with no universally accepted definition or standardized detection methodology. This ambiguity has led to conceptual overlaps, inconsistent evaluation metrics and slowed methodological progress. In this review, we provide a structured overview of foundational concepts, recent advances, key challenges and comparative evaluations of CP detection approaches, along with a discussion of their interplay with community structure and applications in real-world networks.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u7f51\u7edc\u79d1\u5b66\u4e2d\u6838\u5fc3-\u8fb9\u7f18\u7ed3\u6784\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u5305\u62ec\u57fa\u672c\u6982\u5ff5\u3001\u6700\u65b0\u8fdb\u5c55\u3001\u5173\u952e\u6311\u6218\u4ee5\u53ca\u68c0\u6d4b\u65b9\u6cd5\u7684\u6bd4\u8f83\u8bc4\u4f30\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u4e0e\u793e\u533a\u7ed3\u6784\u7684\u76f8\u4e92\u4f5c\u7528\u548c\u5728\u73b0\u5b9e\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u6838\u5fc3-\u8fb9\u7f18\u7ed3\u6784\u8bc6\u522b\u662f\u4e00\u4e2a\u5b9a\u4e49\u4e0d\u660e\u786e\u3001\u7f3a\u4e4f\u6807\u51c6\u5316\u68c0\u6d4b\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u8fd9\u79cd\u6a21\u7cca\u6027\u5bfc\u81f4\u4e86\u6982\u5ff5\u91cd\u53e0\u3001\u8bc4\u4f30\u6307\u6807\u4e0d\u4e00\u81f4\uff0c\u963b\u788d\u4e86\u65b9\u6cd5\u5b66\u8fdb\u5c55\u3002", "method": "\u63d0\u4f9b\u7ed3\u6784\u5316\u7684\u7efc\u8ff0\uff0c\u6db5\u76d6\u57fa\u7840\u6982\u5ff5\u3001\u6700\u65b0\u8fdb\u5c55\u3001\u5173\u952e\u6311\u6218\u548c\u68c0\u6d4b\u65b9\u6cd5\u7684\u6bd4\u8f83\u8bc4\u4f30\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u6838\u5fc3-\u8fb9\u7f18\u7ed3\u6784\u68c0\u6d4b\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u660e\u786e\u4e86\u8be5\u9886\u57df\u5b58\u5728\u7684\u95ee\u9898\u548c\u53d1\u5c55\u65b9\u5411\u3002", "conclusion": "\u6838\u5fc3-\u8fb9\u7f18\u7ed3\u6784\u8bc6\u522b\u9700\u8981\u66f4\u6e05\u6670\u7684\u5b9a\u4e49\u548c\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u8be5\u7efc\u8ff0\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\u548c\u65b9\u5411\u6307\u5bfc\u3002"}}
{"id": "2511.18476", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.18476", "abs": "https://arxiv.org/abs/2511.18476", "authors": ["Tri Phu Vu"], "title": "Random Collection", "comment": null, "summary": "This paper studies choice situations in which a decision maker can choose multiple alternatives. Given a menu of available options, the decision maker selects a subset of the menu with certain probabilities. We employ an axiomatic approach to characterize various parametric models in the literature. Our results elucidate the implications of the functional form assumptions and shed light on the distinctions between models. The behavioral postulates offer simple tools for testing and falsifying the choice procedures used by the decision maker and reveal a close connection between models that are seemingly unrelated.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u51b3\u7b56\u8005\u53ef\u4ee5\u9009\u62e9\u591a\u4e2a\u66ff\u4ee3\u65b9\u6848\u7684\u9009\u62e9\u60c5\u5883\uff0c\u91c7\u7528\u516c\u7406\u5316\u65b9\u6cd5\u8868\u5f81\u6587\u732e\u4e2d\u7684\u5404\u79cd\u53c2\u6570\u6a21\u578b\uff0c\u63ed\u793a\u51fd\u6570\u5f62\u5f0f\u5047\u8bbe\u7684\u542b\u4e49\u548c\u6a21\u578b\u95f4\u7684\u533a\u522b\u3002", "motivation": "\u7814\u7a76\u51b3\u7b56\u8005\u5728\u83dc\u5355\u4e2d\u53ef\u4ee5\u9009\u62e9\u591a\u4e2a\u66ff\u4ee3\u65b9\u6848\u7684\u9009\u62e9\u60c5\u5883\uff0c\u5206\u6790\u9009\u62e9\u5b50\u96c6\u7684\u6982\u7387\u5206\u5e03\uff0c\u7406\u89e3\u4e0d\u540c\u53c2\u6570\u6a21\u578b\u7684\u884c\u4e3a\u542b\u4e49\u3002", "method": "\u91c7\u7528\u516c\u7406\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u884c\u4e3a\u5047\u8bbe\u6765\u8868\u5f81\u5404\u79cd\u53c2\u6570\u6a21\u578b\uff0c\u63d0\u4f9b\u6d4b\u8bd5\u548c\u8bc1\u4f2a\u51b3\u7b56\u8005\u6240\u7528\u9009\u62e9\u7a0b\u5e8f\u7684\u7b80\u5355\u5de5\u5177\u3002", "result": "\u9610\u660e\u4e86\u51fd\u6570\u5f62\u5f0f\u5047\u8bbe\u7684\u542b\u4e49\uff0c\u63ed\u793a\u4e86\u770b\u4f3c\u65e0\u5173\u6a21\u578b\u4e4b\u95f4\u7684\u7d27\u5bc6\u8054\u7cfb\uff0c\u4e3a\u6a21\u578b\u533a\u5206\u63d0\u4f9b\u4e86\u884c\u4e3a\u57fa\u7840\u3002", "conclusion": "\u516c\u7406\u5316\u65b9\u6cd5\u6709\u6548\u63ed\u793a\u4e86\u591a\u9009\u62e9\u60c5\u5883\u4e0b\u4e0d\u540c\u53c2\u6570\u6a21\u578b\u7684\u884c\u4e3a\u542b\u4e49\u548c\u5185\u5728\u8054\u7cfb\uff0c\u4e3a\u6a21\u578b\u68c0\u9a8c\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.19151", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.19151", "abs": "https://arxiv.org/abs/2511.19151", "authors": ["Jacob Martin", "Carlo Giovanni Camarda"], "title": "Modeling smooth and localized mortality patterns across age, time, and space to uncover small-area inequalities", "comment": null, "summary": "Small-area mortality estimation is inherently difficult, as random fluctuations from low death counts can obscure real geographic differences. We introduce a flexible model that borrows strength across age, space, and time to estimate mortality schedules and trends in very small populations. The approach ensures smooth patterns across these dimensions while allowing localized breaks from the spatial structure, capturing broad trajectories as well as sharp local contrasts. We implement our model within a Penalized Spline framework and estimate it using Generalized Linear Array Model techniques, resulting in a computationally fast, interpretable, and parsimonious method. Crucially, it can readily incorporate sudden mortality shocks, such as the Covid-19 pandemic, making it highly versatile for real-world demographic and epidemiological challenges. We demonstrate its application by estimating life expectancy and age-specific mortality inequalities in over 4,800 small areas across the Greater London Authority from 2002 to 2024.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7075\u6d3b\u7684\u5c0f\u533a\u57df\u6b7b\u4ea1\u7387\u4f30\u8ba1\u6a21\u578b\uff0c\u901a\u8fc7\u8de8\u5e74\u9f84\u3001\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u501f\u529b\uff0c\u80fd\u591f\u51c6\u786e\u4f30\u8ba1\u5c0f\u4eba\u53e3\u7fa4\u4f53\u7684\u6b7b\u4ea1\u7387\u548c\u8d8b\u52bf\uff0c\u5e76\u80fd\u5904\u7406\u7a81\u53d1\u6b7b\u4ea1\u7387\u51b2\u51fb\u5982\u65b0\u51a0\u75ab\u60c5\u3002", "motivation": "\u5c0f\u533a\u57df\u6b7b\u4ea1\u7387\u4f30\u8ba1\u5b58\u5728\u56f0\u96be\uff0c\u56e0\u4e3a\u4f4e\u6b7b\u4ea1\u4eba\u6570\u5e26\u6765\u7684\u968f\u673a\u6ce2\u52a8\u4f1a\u63a9\u76d6\u771f\u5b9e\u7684\u5730\u7406\u5dee\u5f02\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u5c0f\u4eba\u53e3\u7fa4\u4f53\u6b7b\u4ea1\u7387\u4f30\u8ba1\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u60e9\u7f5a\u6837\u6761\u6846\u67b6\uff0c\u4f7f\u7528\u5e7f\u4e49\u7ebf\u6027\u9635\u5217\u6a21\u578b\u6280\u672f\u8fdb\u884c\u4f30\u8ba1\uff0c\u786e\u4fdd\u5e74\u9f84\u3001\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u7684\u5e73\u6ed1\u6a21\u5f0f\uff0c\u540c\u65f6\u5141\u8bb8\u5c40\u90e8\u504f\u79bb\u7a7a\u95f4\u7ed3\u6784\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8e\u5927\u4f26\u6566\u5730\u533a4800\u591a\u4e2a\u5c0f\u533a\u57df2002-2024\u5e74\u7684\u9884\u671f\u5bff\u547d\u548c\u5e74\u9f84\u7279\u5b9a\u6b7b\u4ea1\u7387\u4e0d\u5e73\u7b49\u4f30\u8ba1\uff0c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8ba1\u7b97\u5feb\u901f\u3001\u53ef\u89e3\u91ca\u6027\u5f3a\u4e14\u53c2\u6570\u7b80\u6d01\uff0c\u80fd\u591f\u7075\u6d3b\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u7684\u4eba\u53e3\u5b66\u548c\u6d41\u884c\u75c5\u5b66\u6311\u6218\uff0c\u7279\u522b\u662f\u80fd\u591f\u5904\u7406\u7a81\u53d1\u6b7b\u4ea1\u7387\u51b2\u51fb\u3002"}}
{"id": "2511.17608", "categories": ["cs.RO", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.17608", "abs": "https://arxiv.org/abs/2511.17608", "authors": ["Yunlong Guo", "John Canning", "Zenon Chaczko", "Gang-Ding Peng"], "title": "Robot joint characterisation and control using a magneto-optical rotary encoder", "comment": null, "summary": "A robust and compact magneto-optical rotary encoder for the characterisation of robotic rotary joints is demonstrated. The system employs magnetic field-induced optical attenuation in a double-pass configuration using rotating nonuniform magnets around an optical circulator operating in reflection. The encoder tracks continuous 360\u00b0 rotation with rotation sweep rates from \u03bd = 135 \u00b0/s to \u03bd = 370 \u00b0/s, and an angular resolution of \u0394\u03b8 = 0.3\u00b0. This offers a low-cost and reliable alternative to conventional robot rotation encoders while maintaining competitive performance.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7d27\u51d1\u7684\u78c1\u5149\u65cb\u8f6c\u7f16\u7801\u5668\uff0c\u7528\u4e8e\u673a\u5668\u4eba\u65cb\u8f6c\u5173\u8282\u7684\u8868\u5f81\uff0c\u91c7\u7528\u78c1\u573a\u8bf1\u5bfc\u5149\u5b66\u8870\u51cf\u7684\u53cc\u901a\u914d\u7f6e\uff0c\u5177\u6709360\u00b0\u8fde\u7eed\u65cb\u8f6c\u8ddf\u8e2a\u80fd\u529b\u3002", "motivation": "\u4e3a\u673a\u5668\u4eba\u65cb\u8f6c\u5173\u8282\u63d0\u4f9b\u4f4e\u6210\u672c\u3001\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u65cb\u8f6c\u7f16\u7801\u5668\u3002", "method": "\u4f7f\u7528\u65cb\u8f6c\u975e\u5747\u5300\u78c1\u4f53\u56f4\u7ed5\u5149\u5b66\u73af\u884c\u5668\uff0c\u5728\u53cd\u5c04\u6a21\u5f0f\u4e0b\u91c7\u7528\u78c1\u573a\u8bf1\u5bfc\u5149\u5b66\u8870\u51cf\u7684\u53cc\u901a\u914d\u7f6e\u3002", "result": "\u7f16\u7801\u5668\u80fd\u591f\u8ddf\u8e2a360\u00b0\u8fde\u7eed\u65cb\u8f6c\uff0c\u65cb\u8f6c\u626b\u63cf\u901f\u7387\u4ece135\u00b0/s\u5230370\u00b0/s\uff0c\u89d2\u5206\u8fa8\u7387\u4e3a0.3\u00b0\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u80fd\u7684\u540c\u65f6\uff0c\u4e3a\u4f20\u7edf\u673a\u5668\u4eba\u65cb\u8f6c\u7f16\u7801\u5668\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u4e14\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.17672", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17672", "abs": "https://arxiv.org/abs/2511.17672", "authors": ["Yinjie Zhao", "Heng Zhao", "Bihan Wen", "Joey Tianyi Zhou"], "title": "Cognitive Inception: Agentic Reasoning against Visual Deceptions by Injecting Skepticism", "comment": null, "summary": "As the development of AI-generated contents (AIGC), multi-modal Large Language Models (LLM) struggle to identify generated visual inputs from real ones. Such shortcoming causes vulnerability against visual deceptions, where the models are deceived by generated contents, and the reliability of reasoning processes is jeopardized. Therefore, facing rapidly emerging generative models and diverse data distribution, it is of vital importance to improve LLMs' generalizable reasoning to verify the authenticity of visual inputs against potential deceptions. Inspired by human cognitive processes, we discovered that LLMs exhibit tendency of over-trusting the visual inputs, while injecting skepticism could significantly improve the models visual cognitive capability against visual deceptions. Based on this discovery, we propose \\textbf{Inception}, a fully reasoning-based agentic reasoning framework to conduct generalizable authenticity verification by injecting skepticism, where LLMs' reasoning logic is iteratively enhanced between External Skeptic and Internal Skeptic agents. To the best of our knowledge, this is the first fully reasoning-based framework against AIGC visual deceptions. Our approach achieved a large margin of performance improvement over the strongest existing LLM baselines and SOTA performance on AEGIS benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e86Inception\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u5165\u6000\u7591\u673a\u5236\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u751f\u6210\u89c6\u89c9\u5185\u5bb9\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u9632\u6b62\u89c6\u89c9\u6b3a\u9a97", "motivation": "\u968f\u7740AIGC\u53d1\u5c55\uff0c\u591a\u6a21\u6001LLM\u96be\u4ee5\u533a\u5206\u751f\u6210\u548c\u771f\u5b9e\u89c6\u89c9\u8f93\u5165\uff0c\u5b58\u5728\u88ab\u89c6\u89c9\u6b3a\u9a97\u7684\u98ce\u9669\uff0c\u9700\u8981\u63d0\u9ad8\u6a21\u578b\u5bf9\u89c6\u89c9\u8f93\u5165\u771f\u5b9e\u6027\u7684\u9a8c\u8bc1\u80fd\u529b", "method": "\u57fa\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u63d0\u51faInception\u6846\u67b6\uff0c\u901a\u8fc7\u5916\u90e8\u6000\u7591\u548c\u5185\u90e8\u6000\u7591\u4ee3\u7406\u4e4b\u95f4\u7684\u8fed\u4ee3\u63a8\u7406\u6765\u6ce8\u5165\u6000\u7591\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u89c6\u89c9\u8ba4\u77e5\u80fd\u529b", "result": "\u5728AEGIS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5f3aLLM\u57fa\u7ebf\uff0c\u8fbe\u5230SOTA\u6027\u80fd", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5b8c\u5168\u57fa\u4e8e\u63a8\u7406\u7684\u5bf9\u6297AIGC\u89c6\u89c9\u6b3a\u9a97\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6000\u7591\u6ce8\u5165\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u89c6\u89c9\u8f93\u5165\u771f\u5b9e\u6027\u7684\u9a8c\u8bc1\u80fd\u529b"}}
{"id": "2511.18664", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.18664", "abs": "https://arxiv.org/abs/2511.18664", "authors": ["Lawrence W. Abrams"], "title": "Clarifying Trinko as Precedent in EHR and AI-Memory Duty to Deal Cases: A New Institutional Economics Approach", "comment": null, "summary": "By clarifying the bases for the Verizon Communications Inc. v. Law Offices of Curtis V. Trinko, LLP, 2004 opinion, we hope to reduce two distinct errors. The false positive error is citing Trinko as precedent when it is not. This error is so prevalent it has earned the nickname of Trinko Creep. The false negative error is not citing Trinko when it should be. We argue that this error will be growing in the future as Trinko should be precedent in cases involving regulated access rights to sensitive consumer data in electronic health records and Agentic AI Long Term Memory.", "AI": {"tldr": "\u8be5\u8bba\u6587\u65e8\u5728\u6f84\u6e05Verizon v. Trinko\u6848\u5224\u51b3\u7684\u57fa\u7840\uff0c\u4ee5\u51cf\u5c11\u4e24\u79cd\u9519\u8bef\uff1a\u9519\u8bef\u5f15\u7528Trinko\u4f5c\u4e3a\u5148\u4f8b\uff08Trinko Creep\uff09\u548c\u5e94\u5f15\u7528\u800c\u672a\u5f15\u7528Trinko\u7684\u60c5\u51b5\u3002", "motivation": "\u51cf\u5c11\u5728\u6d89\u53ca\u53d7\u76d1\u7ba1\u7684\u654f\u611f\u6d88\u8d39\u8005\u6570\u636e\u8bbf\u95ee\u6743\u6848\u4ef6\u4e2d\u5f15\u7528Trinko\u5148\u4f8b\u7684\u9519\u8bef\uff0c\u7279\u522b\u662f\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548cAgentic AI\u957f\u671f\u8bb0\u5fc6\u7b49\u65b0\u5174\u9886\u57df\u3002", "method": "\u901a\u8fc7\u6f84\u6e05Trinko\u6848\u5224\u51b3\u7684\u6cd5\u5f8b\u57fa\u7840\uff0c\u5206\u6790\u5176\u9002\u7528\u8303\u56f4\uff0c\u4ee5\u533a\u5206\u4f55\u65f6\u5e94\u5f15\u7528\u548c\u4e0d\u5e94\u5f15\u7528\u8be5\u5148\u4f8b\u3002", "result": "\u8bc6\u522b\u51faTrinko Creep\uff08\u9519\u8bef\u5f15\u7528\uff09\u73b0\u8c61\u666e\u904d\u5b58\u5728\uff0c\u540c\u65f6\u9884\u6d4b\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548cAI\u957f\u671f\u8bb0\u5fc6\u7b49\u65b0\u5174\u6570\u636e\u8bbf\u95ee\u6743\u6848\u4ef6\u4e2d\u4f1a\u51fa\u73b0\u5e94\u5f15\u7528\u800c\u672a\u5f15\u7528\u7684\u9519\u8bef\u3002", "conclusion": "Trinko\u6848\u5e94\u4f5c\u4e3a\u6d89\u53ca\u53d7\u76d1\u7ba1\u654f\u611f\u6d88\u8d39\u8005\u6570\u636e\u8bbf\u95ee\u6743\u6848\u4ef6\u7684\u5148\u4f8b\uff0c\u7279\u522b\u662f\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548cAgentic AI\u957f\u671f\u8bb0\u5fc6\u7b49\u65b0\u5174\u6280\u672f\u9886\u57df\u3002"}}
{"id": "2511.17894", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17894", "abs": "https://arxiv.org/abs/2511.17894", "authors": ["Yi Huang", "Feng Han", "Wenyi Liu", "Jingang Yi", "Yuebin Guo"], "title": "Machine Learning-based Online Stability Lobe Diagram Estimation and Chatter Suppression Control in Milling Process", "comment": null, "summary": "Chatter is a self-excited vibration in milling that degrades surface quality and accelerates tool wear. This paper presents an adaptive process controller that suppresses chatter by leveraging machine learning-based online estimation of the Stability Lobe Diagram (SLD) and surface roughness in the process. Stability analysis is conducted using the semi-discretization method for milling dynamics modeled by delay differential equations. An integrated machine learning framework estimates the SLD from sensor data and predicts surface roughness for chatter detection in real time. These estimates are integrated into an optimal controller that adaptively adjusts spindle speed to maintain process stability and improve surface finish. Simulations and experiments are performed to demonstrate the superior performance compared to the existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u8fc7\u7a0b\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u5728\u7ebf\u4f30\u8ba1\u7a33\u5b9a\u6027\u53f6\u74e3\u56fe\u548c\u8868\u9762\u7c97\u7cd9\u5ea6\u6765\u6291\u5236\u94e3\u524a\u4e2d\u7684\u98a4\u632f\u3002", "motivation": "\u98a4\u632f\u662f\u94e3\u524a\u4e2d\u7684\u81ea\u6fc0\u632f\u52a8\uff0c\u4f1a\u964d\u4f4e\u8868\u9762\u8d28\u91cf\u5e76\u52a0\u901f\u5200\u5177\u78e8\u635f\uff0c\u9700\u8981\u6709\u6548\u7684\u6291\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u534a\u79bb\u6563\u5316\u65b9\u6cd5\u8fdb\u884c\u7a33\u5b9a\u6027\u5206\u6790\uff0c\u5efa\u7acb\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u6846\u67b6\u7684SLD\u548c\u8868\u9762\u7c97\u7cd9\u5ea6\u5728\u7ebf\u4f30\u8ba1\uff0c\u5e76\u96c6\u6210\u5230\u6700\u4f18\u63a7\u5236\u5668\u4e2d\u81ea\u9002\u5e94\u8c03\u6574\u4e3b\u8f74\u8f6c\u901f\u3002", "result": "\u4eff\u771f\u548c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u81ea\u9002\u5e94\u8fc7\u7a0b\u63a7\u5236\u5668\u80fd\u6709\u6548\u6291\u5236\u98a4\u632f\uff0c\u63d0\u9ad8\u52a0\u5de5\u7a33\u5b9a\u6027\u5e76\u6539\u5584\u8868\u9762\u8d28\u91cf\u3002"}}
{"id": "2511.18220", "categories": ["cs.SI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.18220", "abs": "https://arxiv.org/abs/2511.18220", "authors": ["Ben Prystawski", "Dilip Arumugam", "Noah D. Goodman"], "title": "Lossy communication constrains iterated learning", "comment": "22 pages, 8 figures", "summary": "Humans' distinctive role in the world can largely be attributed to our capacity for iterated learning, a process by which knowledge is expanded and refined over generations. A range of theories seek to explain why humans are so adept at iterated learning, many positing substantial evolutionary discontinuities in communication or cognition. Is it necessary to posit large differences in abilities between humans and other species, or could small differences in communication ability produce large differences in what a species can learn over generations? We investigate this question through a formal model based on information theory. We manipulate how much information individual learners can send each other and observe the effect on iterated learning performance. Incremental changes to the channel rate can lead to dramatic, non-linear changes to the eventual performance of the population. We complement this model with a theoretical result that describes how individual lossy communications constrain the global performance of iterated learning. Our results demonstrate that incremental, quantitative changes to communication abilities could be sufficient to explain large differences in what can be learned over many generations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u6a21\u578b\u8bc1\u660e\uff0c\u901a\u4fe1\u80fd\u529b\u7684\u5fae\u5c0f\u589e\u91cf\u53d8\u5316\u53ef\u80fd\u5bfc\u81f4\u8fed\u4ee3\u5b66\u4e60\u6027\u80fd\u7684\u620f\u5267\u6027\u975e\u7ebf\u6027\u53d8\u5316\uff0c\u89e3\u91ca\u4e86\u4eba\u7c7b\u4e0e\u5176\u4ed6\u7269\u79cd\u5728\u8fed\u4ee3\u5b66\u4e60\u80fd\u529b\u4e0a\u7684\u5de8\u5927\u5dee\u5f02\u53ef\u80fd\u6e90\u4e8e\u901a\u4fe1\u80fd\u529b\u7684\u5fae\u5c0f\u5dee\u5f02\u3002", "motivation": "\u63a2\u8ba8\u4eba\u7c7b\u5728\u8fed\u4ee3\u5b66\u4e60\u65b9\u9762\u7684\u5353\u8d8a\u80fd\u529b\u662f\u5426\u5fc5\u987b\u5f52\u56e0\u4e8e\u4e0e\u5176\u4ed6\u7269\u79cd\u7684\u5de8\u5927\u8fdb\u5316\u5dee\u5f02\uff0c\u8fd8\u662f\u53ef\u4ee5\u901a\u8fc7\u901a\u4fe1\u80fd\u529b\u7684\u5fae\u5c0f\u5dee\u5f02\u6765\u89e3\u91ca\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u5f62\u5f0f\u6a21\u578b\uff0c\u901a\u8fc7\u64cd\u7eb5\u4e2a\u4f53\u5b66\u4e60\u8005\u4e4b\u95f4\u80fd\u591f\u4f20\u9012\u7684\u4fe1\u606f\u91cf\uff0c\u89c2\u5bdf\u5bf9\u8fed\u4ee3\u5b66\u4e60\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u901a\u4fe1\u6e20\u9053\u901f\u7387\u7684\u589e\u91cf\u53d8\u5316\u4f1a\u5bfc\u81f4\u7fa4\u4f53\u6700\u7ec8\u6027\u80fd\u7684\u620f\u5267\u6027\u975e\u7ebf\u6027\u53d8\u5316\u3002\u7406\u8bba\u7ed3\u679c\u63cf\u8ff0\u4e86\u6709\u635f\u901a\u4fe1\u5982\u4f55\u7ea6\u675f\u8fed\u4ee3\u5b66\u4e60\u7684\u5168\u5c40\u6027\u80fd\u3002", "conclusion": "\u901a\u4fe1\u80fd\u529b\u7684\u589e\u91cf\u5b9a\u91cf\u53d8\u5316\u8db3\u4ee5\u89e3\u91ca\u591a\u4ee3\u5b66\u4e60\u80fd\u529b\u4e0a\u7684\u5de8\u5927\u5dee\u5f02\uff0c\u65e0\u9700\u5047\u8bbe\u7269\u79cd\u95f4\u5b58\u5728\u5de8\u5927\u7684\u80fd\u529b\u5dee\u5f02\u3002"}}
{"id": "2511.17554", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17554", "abs": "https://arxiv.org/abs/2511.17554", "authors": ["Sumon Kanti Dey", "Manvi S", "Zeel Mehta", "Meet Shah", "Unnati Agrawal", "Suhani Jalota", "Azra Ismail"], "title": "Beyond the Rubric: Cultural Misalignment in LLM Benchmarks for Sexual and Reproductive Health", "comment": "https://github.com/Sumon/healthbench-srh-eval/", "summary": "Large Language Models (LLMs) have been positioned as having the potential to expand access to health information in the Global South, yet their evaluation remains heavily dependent on benchmarks designed around Western norms. We present insights from a preliminary benchmarking exercise with a chatbot for sexual and reproductive health (SRH) for an underserved community in India. We evaluated using HealthBench, a benchmark for conversational health models by OpenAI. We extracted 637 SRH queries from the dataset and evaluated on the 330 single-turn conversations. Responses were evaluated using HealthBench's rubric-based automated grader, which rated responses consistently low. However, qualitative analysis by trained annotators and public health experts revealed that many responses were actually culturally appropriate and medically accurate. We highlight recurring issues, particularly a Western bias, such as for legal framing and norms (e.g., breastfeeding in public), diet assumptions (e.g., fish safe to eat during pregnancy), and costs (e.g., insurance models). Our findings demonstrate the limitations of current benchmarks in capturing the effectiveness of systems built for different cultural and healthcare contexts. We argue for the development of culturally adaptive evaluation frameworks that meet quality standards while recognizing needs of diverse populations.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u57fa\u4e8e\u897f\u65b9\u89c4\u8303\u7684LLM\u5065\u5eb7\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u6587\u5316\u504f\u89c1\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u9488\u5bf9\u5168\u7403\u5357\u65b9\u5730\u533a\u7684\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u6548\u679c\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u6027\u751f\u6b96\u5065\u5eb7\u9886\u57df\u5bf9\u5370\u5ea6\u670d\u52a1\u4e0d\u8db3\u793e\u533a\u7684\u9002\u7528\u6027\uff0c\u63ed\u793a\u73b0\u6709\u57fa\u51c6\u7684\u6587\u5316\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528HealthBench\u57fa\u51c6\u8bc4\u4f30637\u4e2a\u6027\u751f\u6b96\u5065\u5eb7\u67e5\u8be2\uff0c\u7ed3\u5408\u81ea\u52a8\u8bc4\u5206\u548c\u4eba\u5de5\u5b9a\u6027\u5206\u6790\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\u4e00\u81f4\u7ed9\u51fa\u4f4e\u5206\uff0c\u4f46\u4eba\u5de5\u5206\u6790\u663e\u793a\u8bb8\u591a\u56de\u7b54\u5728\u6587\u5316\u548c\u533b\u5b66\u4e0a\u90fd\u662f\u5408\u9002\u7684\uff0c\u63ed\u793a\u4e86\u897f\u65b9\u504f\u89c1\u95ee\u9898\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u6587\u5316\u9002\u5e94\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u4fdd\u8bc1\u8d28\u91cf\u6807\u51c6\u7684\u540c\u65f6\u6ee1\u8db3\u4e0d\u540c\u4eba\u7fa4\u7684\u9700\u6c42\u3002"}}
{"id": "2511.10808", "categories": ["econ.GN", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.10808", "abs": "https://arxiv.org/abs/2511.10808", "authors": ["Yihan Hu", "Yifei Huang", "Weizhao Wang"], "title": "Seasonality in the U.S. Housing Market: Post-Pandemic Shifts and Regional Dynamics", "comment": "https://github.com/WindTakeMeNorth/Seasonality_in_the_US_Housing_Market", "summary": "Seasonality has traditionally shaped the U.S. housing market, with activity peaking in spring-summer and declining in autumn-winter. However, recent disruptions, particularly post-COVID-19, raise questions about shift in these patterns. This study analyzes housing market date (1991-2024) to examine evolving seasonality and regional heterogeneity. Using Housing Price Index (HPI), inventory and sales data from the Federal Housing Finance Agency and U.S. Census Bureau, seasonal components are extracted via the X-13-ARIMA procedure, and statistical tests assess variations across regions. The results confirm seasonal fluctuations in prices and volumes, with recent shifts toward earlier annual peak (March-April) and amplified seasonal effects. Regional variations align with differences in climate and market structure, while prices and sales volumes exhibit in-phase movement, suggesting thick-market momentum behaviour. These findings highlight key implications for policymakers, realtors and investors navigating post-pandemic market dynamics, offering insights into the timing and interpretation of housing market activities.", "AI": {"tldr": "\u5206\u67901991-2024\u5e74\u7f8e\u56fd\u4f4f\u623f\u5e02\u573a\u6570\u636e\uff0c\u53d1\u73b0\u5b63\u8282\u6027\u6a21\u5f0f\u6b63\u5728\u6f14\u53d8\uff0c\u5e74\u5ea6\u5cf0\u503c\u63d0\u524d\u81f33-4\u6708\uff0c\u5b63\u8282\u6027\u6548\u5e94\u589e\u5f3a\uff0c\u5b58\u5728\u660e\u663e\u7684\u533a\u57df\u5f02\u8d28\u6027\u3002", "motivation": "\u4f20\u7edf\u4e0a\u7f8e\u56fd\u4f4f\u623f\u5e02\u573a\u5177\u6709\u660e\u663e\u7684\u5b63\u8282\u6027\u7279\u5f81\uff0c\u4f46COVID-19\u7b49\u8fd1\u671f\u51b2\u51fb\u53ef\u80fd\u6539\u53d8\u4e86\u8fd9\u4e9b\u6a21\u5f0f\uff0c\u9700\u8981\u7814\u7a76\u5b63\u8282\u6027\u6a21\u5f0f\u7684\u6f14\u53d8\u548c\u533a\u57df\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u8054\u90a6\u4f4f\u623f\u91d1\u878d\u5c40\u548c\u7f8e\u56fd\u4eba\u53e3\u666e\u67e5\u5c40\u7684\u4f4f\u623f\u4ef7\u683c\u6307\u6570\u3001\u5e93\u5b58\u548c\u9500\u552e\u6570\u636e\uff0c\u901a\u8fc7X-13-ARIMA\u7a0b\u5e8f\u63d0\u53d6\u5b63\u8282\u6027\u6210\u5206\uff0c\u5e76\u8fdb\u884c\u8de8\u533a\u57df\u7edf\u8ba1\u68c0\u9a8c\u3002", "result": "\u786e\u8ba4\u4ef7\u683c\u548c\u4ea4\u6613\u91cf\u7684\u5b63\u8282\u6027\u6ce2\u52a8\uff0c\u8fd1\u671f\u51fa\u73b0\u5e74\u5ea6\u5cf0\u503c\u63d0\u524d\uff083-4\u6708\uff09\u548c\u5b63\u8282\u6027\u6548\u5e94\u653e\u5927\u7684\u8d8b\u52bf\uff0c\u533a\u57df\u5dee\u5f02\u4e0e\u6c14\u5019\u548c\u5e02\u573a\u7ed3\u6784\u76f8\u5173\uff0c\u4ef7\u683c\u548c\u4ea4\u6613\u91cf\u5448\u73b0\u540c\u76f8\u8fd0\u52a8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u3001\u623f\u5730\u4ea7\u7ecf\u7eaa\u4eba\u548c\u6295\u8d44\u8005\u5728\u540e\u75ab\u60c5\u65f6\u4ee3\u5e02\u573a\u52a8\u6001\u4e2d\u63d0\u4f9b\u4e86\u5173\u4e8e\u4f4f\u623f\u5e02\u573a\u6d3b\u52a8\u65f6\u673a\u548c\u89e3\u91ca\u7684\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2511.17720", "categories": ["cs.RO", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2511.17720", "abs": "https://arxiv.org/abs/2511.17720", "authors": ["Sean Cowan", "Pietro Fanti", "Leon B. S. Williams", "Chit Hong Yam", "Kaneyasu Asakuma", "Yuichiro Nada", "Dario Izzo"], "title": "Vision-Guided Optic Flow Navigation for Small Lunar Missions", "comment": null, "summary": "Private lunar missions are faced with the challenge of robust autonomous navigation while operating under stringent constraints on mass, power, and computational resources. This work proposes a motion-field inversion framework that uses optical flow and rangefinder-based depth estimation as a lightweight CPU-based solution for egomotion estimation during lunar descent. We extend classical optical flow formulations by integrating them with depth modeling strategies tailored to the geometry for lunar/planetary approach, descent, and landing, specifically, planar and spherical terrain approximations parameterized by a laser rangefinder. Motion field inversion is performed through a least-squares framework, using sparse optical flow features extracted via the pyramidal Lucas-Kanade algorithm. We verify our approach using synthetically generated lunar images over the challenging terrain of the lunar south pole, using CPU budgets compatible with small lunar landers. The results demonstrate accurate velocity estimation from approach to landing, with sub-10% error for complex terrain and on the order of 1% for more typical terrain, as well as performances suitable for real-time applications. This framework shows promise for enabling robust, lightweight on-board navigation for small lunar missions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5149\u6d41\u548c\u6d4b\u8ddd\u4eea\u6df1\u5ea6\u4f30\u8ba1\u7684\u8fd0\u52a8\u573a\u53cd\u6f14\u6846\u67b6\uff0c\u7528\u4e8e\u6708\u7403\u7740\u9646\u8fc7\u7a0b\u4e2d\u7684\u81ea\u4e3b\u5bfc\u822a\uff0c\u8be5\u65b9\u6848\u8ba1\u7b97\u91cf\u5c0f\uff0c\u9002\u5408\u5c0f\u578b\u6708\u7403\u7740\u9646\u5668\u7684CPU\u8d44\u6e90\u9650\u5236\u3002", "motivation": "\u89e3\u51b3\u79c1\u4eba\u6708\u7403\u4efb\u52a1\u5728\u8d28\u91cf\u3001\u529f\u8017\u548c\u8ba1\u7b97\u8d44\u6e90\u4e25\u683c\u9650\u5236\u4e0b\u5b9e\u73b0\u9c81\u68d2\u81ea\u4e3b\u5bfc\u822a\u7684\u6311\u6218\u3002", "method": "\u6269\u5c55\u7ecf\u5178\u5149\u6d41\u516c\u5f0f\uff0c\u7ed3\u5408\u9488\u5bf9\u6708\u7403/\u884c\u661f\u63a5\u8fd1\u3001\u4e0b\u964d\u548c\u7740\u9646\u51e0\u4f55\u5f62\u72b6\u7684\u6df1\u5ea6\u5efa\u6a21\u7b56\u7565\uff08\u5e73\u9762\u548c\u7403\u5f62\u5730\u5f62\u8fd1\u4f3c\uff09\uff0c\u4f7f\u7528\u6fc0\u5149\u6d4b\u8ddd\u4eea\u53c2\u6570\u5316\uff0c\u901a\u8fc7\u6700\u5c0f\u4e8c\u4e58\u6cd5\u6846\u67b6\u8fdb\u884c\u8fd0\u52a8\u573a\u53cd\u6f14\uff0c\u91c7\u7528\u91d1\u5b57\u5854Lucas-Kanade\u7b97\u6cd5\u63d0\u53d6\u7a00\u758f\u5149\u6d41\u7279\u5f81\u3002", "result": "\u5728\u6708\u7403\u5357\u6781\u590d\u6742\u5730\u5f62\u4e0a\u7684\u5408\u6210\u56fe\u50cf\u9a8c\u8bc1\u8868\u660e\uff0c\u4ece\u63a5\u8fd1\u5230\u7740\u9646\u9636\u6bb5\u90fd\u80fd\u51c6\u786e\u4f30\u8ba1\u901f\u5ea6\uff0c\u590d\u6742\u5730\u5f62\u4e0b\u8bef\u5dee\u4f4e\u4e8e10%\uff0c\u5178\u578b\u5730\u5f62\u4e0b\u8bef\u5dee\u7ea6\u4e3a1%\uff0c\u6027\u80fd\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u671b\u4e3a\u5c0f\u578b\u6708\u7403\u4efb\u52a1\u5b9e\u73b0\u9c81\u68d2\u3001\u8f7b\u91cf\u7ea7\u7684\u673a\u8f7d\u5bfc\u822a\u3002"}}
{"id": "2511.17673", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17673", "abs": "https://arxiv.org/abs/2511.17673", "authors": ["Myung Ho Kim"], "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "comment": "27 pages", "summary": "Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents. Code: https://github.com/enkiluv/scl-core-experiment Demo: https://scl-travel-planner.streamlit.app/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u8ba4\u77e5\u5faa\u73af\uff08SCL\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5206\u79bb\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u7ed3\u5408\u8f6f\u7b26\u53f7\u63a7\u5236\u673a\u5236\uff0c\u89e3\u51b3LLM\u667a\u80fd\u4f53\u7684\u63a8\u7406\u6267\u884c\u7ea0\u7f20\u3001\u5185\u5b58\u6613\u5931\u6027\u548c\u52a8\u4f5c\u5e8f\u5217\u5931\u63a7\u7b49\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5b58\u5728\u7684\u4e09\u4e2a\u57fa\u672c\u67b6\u6784\u95ee\u9898\uff1a\u63a8\u7406\u4e0e\u6267\u884c\u7ea0\u7f20\u3001\u5185\u5b58\u6613\u5931\u6027\u3001\u52a8\u4f5c\u5e8f\u5217\u5931\u63a7\uff0c\u8fd9\u4e9b\u9650\u5236\u4e86\u667a\u80fd\u4f53\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f15\u5165SCL\u67b6\u6784\uff0c\u5c06\u667a\u80fd\u4f53\u8ba4\u77e5\u660e\u786e\u5206\u4e3a\u4e94\u4e2a\u9636\u6bb5\uff1a\u68c0\u7d22\u3001\u8ba4\u77e5\u3001\u63a7\u5236\u3001\u52a8\u4f5c\u548c\u8bb0\u5fc6\uff08R-CCAM\uff09\uff0c\u6838\u5fc3\u662f\u8f6f\u7b26\u53f7\u63a7\u5236\u673a\u5236\uff0c\u5728\u4fdd\u6301\u795e\u7ecf\u7075\u6d3b\u6027\u7684\u540c\u65f6\u5e94\u7528\u7b26\u53f7\u7ea6\u675f\u3002", "result": "\u5728\u591a\u6b65\u6761\u4ef6\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u96f6\u7b56\u7565\u8fdd\u89c4\u3001\u6d88\u9664\u5197\u4f59\u5de5\u5177\u8c03\u7528\u3001\u4fdd\u6301\u5b8c\u6574\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\uff0c\u89e3\u51b3\u4e86ReAct\u3001AutoGPT\u548c\u5185\u5b58\u589e\u5f3a\u65b9\u6cd5\u7684\u5173\u952e\u7f3a\u9677\u3002", "conclusion": "\u901a\u8fc7\u8fde\u63a5\u4e13\u5bb6\u7cfb\u7edf\u539f\u7406\u4e0e\u73b0\u4ee3LLM\u80fd\u529b\uff0c\u4e3a\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6cbb\u7406\u7684AI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u7406\u8bba\u57fa\u7840\u7684\u8def\u5f84\u3002"}}
{"id": "2511.18738", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.18738", "abs": "https://arxiv.org/abs/2511.18738", "authors": ["Dhiraj Jagadale", "Kavita Vemuri"], "title": "Trust and Uncertainty in Strategic Interaction: Behavioural and Physiological Evidence from the Centipede Game", "comment": "Presented at NeuroPsychoEconomics Conference, 2021", "summary": "Mutual trust is a key determinant of decision-making in economic interactions, yet actual behavior often diverges from equilibrium predictions. This study investigates how emotional arousal, indexed by skin conductance responses,SCR, relates to trust behavior in a modified centipede game. To examine the impact of uncertainty, the game incorporated both fixed and random termination conditions. SCRs were recorded alongside self-reported measures of mutual and general trust and individual risk-taking propensity. Phasic SCRs were significantly higher under random termination, particularly following the opponent take actions, indicating increased emotional arousal under uncertainty. Mutual trust scores correlated positively with risk propensity but not with general trust. Behaviorally, higher mutual trust was associated with extended cooperative play, but only in the fixed-turn condition. These findings suggest that physiological arousal reflects emotional engagement in trust-related decisions and that uncertainty amplifies both arousal and strategic caution. Mutual trust appears context-dependent, shaped by emotional and physiological states that influence deviations from equilibrium behavior.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u76ae\u80a4\u7535\u53cd\u5e94(SCR)\u6d4b\u91cf\u60c5\u7eea\u5524\u9192\uff0c\u63a2\u8ba8\u5176\u5728\u6539\u826f\u8708\u86a3\u535a\u5f08\u4e2d\u4e0e\u4fe1\u4efb\u884c\u4e3a\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u60c5\u7eea\u5524\u9192\u589e\u5f3a\uff0c\u76f8\u4e92\u4fe1\u4efb\u4e0e\u98ce\u9669\u504f\u597d\u76f8\u5173\u4e14\u53d7\u60c5\u5883\u5f71\u54cd\u3002", "motivation": "\u7ecf\u6d4e\u4e92\u52a8\u4e2d\u76f8\u4e92\u4fe1\u4efb\u662f\u51b3\u7b56\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u5b9e\u9645\u884c\u4e3a\u5e38\u504f\u79bb\u5747\u8861\u9884\u6d4b\uff0c\u9700\u8981\u7814\u7a76\u60c5\u7eea\u5524\u9192\u5982\u4f55\u5f71\u54cd\u4fe1\u4efb\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u3002", "method": "\u4f7f\u7528\u6539\u826f\u8708\u86a3\u535a\u5f08\uff0c\u5305\u542b\u56fa\u5b9a\u548c\u968f\u673a\u7ec8\u6b62\u6761\u4ef6\uff0c\u8bb0\u5f55\u76ae\u80a4\u7535\u53cd\u5e94(SCR)\uff0c\u5e76\u7ed3\u5408\u81ea\u6211\u62a5\u544a\u7684\u76f8\u4e92\u4fe1\u4efb\u3001\u4e00\u822c\u4fe1\u4efb\u548c\u4e2a\u4f53\u98ce\u9669\u627f\u62c5\u503e\u5411\u6d4b\u91cf\u3002", "result": "\u968f\u673a\u7ec8\u6b62\u6761\u4ef6\u4e0bSCR\u663e\u8457\u66f4\u9ad8\uff0c\u7279\u522b\u662f\u5728\u5bf9\u624b\u91c7\u53d6\u884c\u52a8\u540e\uff1b\u76f8\u4e92\u4fe1\u4efb\u5f97\u5206\u4e0e\u98ce\u9669\u504f\u597d\u6b63\u76f8\u5173\u4f46\u4e0e\u4e00\u822c\u4fe1\u4efb\u65e0\u5173\uff1b\u5728\u56fa\u5b9a\u8f6e\u6b21\u6761\u4ef6\u4e0b\uff0c\u66f4\u9ad8\u7684\u76f8\u4e92\u4fe1\u4efb\u4e0e\u66f4\u957f\u7684\u5408\u4f5c\u6e38\u620f\u76f8\u5173\u3002", "conclusion": "\u751f\u7406\u5524\u9192\u53cd\u6620\u4e86\u4fe1\u4efb\u76f8\u5173\u51b3\u7b56\u4e2d\u7684\u60c5\u7eea\u53c2\u4e0e\uff0c\u4e0d\u786e\u5b9a\u6027\u653e\u5927\u4e86\u5524\u9192\u548c\u6218\u7565\u8c28\u614e\uff1b\u76f8\u4e92\u4fe1\u4efb\u5177\u6709\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u53d7\u60c5\u7eea\u548c\u751f\u7406\u72b6\u6001\u5f71\u54cd\uff0c\u5bfc\u81f4\u504f\u79bb\u5747\u8861\u884c\u4e3a\u3002"}}
{"id": "2511.18015", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18015", "abs": "https://arxiv.org/abs/2511.18015", "authors": ["Luke Eilers", "Jonas Stapmanns", "Catarina Dias", "Jean-Pascal Pfister"], "title": "On the stability of event-based control with neuronal dynamics", "comment": "11 pages, 4 figures", "summary": "Event-based control, unlike analogue control, poses significant analytical challenges due to its hybrid dynamics. This work investigates the stability and inter-event time properties of a control-affine system under event-based impulsive control. The controller consists of multiple neuronal units with leaky integrate-and-fire dynamics acting on a time-invariant, multiple-input multiple-output plant in closed loop. Both the plant state and the neuronal units exhibit discontinuities that cancel if combined linearly, enabling a direct correspondence between the event-based impulsive controller and a corresponding analogue controller. Leveraging this observation, we prove global practical stability of the event-based impulsive control system. In the general nonlinear case, we show that the event-based impulsive controller ensures global practical asymptotic stability if the analogue system is input-to-state stable (ISS) with respect to specific disturbances. In the linear case, we further show global practical exponential stability if the analogue system is stable. We illustrate our results with numerical simulations. The findings reveal a fundamental link between analogue and event-based impulsive control, providing new insights for the design of neuromorphic controllers.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u4e8b\u4ef6\u7684\u8109\u51b2\u63a7\u5236\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\uff0c\u8bc1\u660e\u4e86\u5728\u975e\u7ebf\u6027\u60c5\u51b5\u4e0b\u53ef\u5b9e\u73b0\u5168\u5c40\u5b9e\u7528\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u5728\u7ebf\u6027\u60c5\u51b5\u4e0b\u53ef\u5b9e\u73b0\u5168\u5c40\u5b9e\u7528\u6307\u6570\u7a33\u5b9a\u6027\uff0c\u63ed\u793a\u4e86\u6a21\u62df\u63a7\u5236\u4e0e\u4e8b\u4ef6\u63a7\u5236\u4e4b\u95f4\u7684\u57fa\u672c\u8054\u7cfb\u3002", "motivation": "\u57fa\u4e8e\u4e8b\u4ef6\u7684\u63a7\u5236\u7531\u4e8e\u5176\u6df7\u5408\u52a8\u529b\u5b66\u7279\u6027\uff0c\u5728\u5206\u6790\u4e0a\u9762\u4e34\u663e\u8457\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u63a7\u5236\u4eff\u5c04\u7cfb\u7edf\u5728\u57fa\u4e8e\u4e8b\u4ef6\u7684\u8109\u51b2\u63a7\u5236\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u4e8b\u4ef6\u95f4\u9694\u65f6\u95f4\u7279\u6027\u3002", "method": "\u4f7f\u7528\u5177\u6709\u6cc4\u6f0f\u79ef\u5206-\u53d1\u653e\u52a8\u529b\u5b66\u7684\u591a\u4e2a\u795e\u7ecf\u5143\u5355\u5143\u4f5c\u4e3a\u63a7\u5236\u5668\uff0c\u4f5c\u7528\u4e8e\u65f6\u4e0d\u53d8\u591a\u8f93\u5165\u591a\u8f93\u51fa\u88ab\u63a7\u5bf9\u8c61\u3002\u901a\u8fc7\u5c06\u7cfb\u7edf\u72b6\u6001\u548c\u795e\u7ecf\u5143\u5355\u5143\u7684\u4e0d\u8fde\u7eed\u6027\u7ebf\u6027\u7ec4\u5408\u76f8\u62b5\u6d88\uff0c\u5efa\u7acb\u4e8b\u4ef6\u8109\u51b2\u63a7\u5236\u5668\u4e0e\u5bf9\u5e94\u6a21\u62df\u63a7\u5236\u5668\u7684\u76f4\u63a5\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86\u4e8b\u4ef6\u8109\u51b2\u63a7\u5236\u7cfb\u7edf\u7684\u5168\u5c40\u5b9e\u7528\u7a33\u5b9a\u6027\u3002\u5728\u4e00\u822c\u975e\u7ebf\u6027\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u6a21\u62df\u7cfb\u7edf\u5bf9\u7279\u5b9a\u6270\u52a8\u662f\u8f93\u5165\u72b6\u6001\u7a33\u5b9a\u7684\uff0c\u5219\u4e8b\u4ef6\u8109\u51b2\u63a7\u5236\u5668\u786e\u4fdd\u5168\u5c40\u5b9e\u7528\u6e10\u8fd1\u7a33\u5b9a\u6027\u3002\u5728\u7ebf\u6027\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u6a21\u62df\u7cfb\u7edf\u7a33\u5b9a\uff0c\u5219\u8fdb\u4e00\u6b65\u8bc1\u660e\u5168\u5c40\u5b9e\u7528\u6307\u6570\u7a33\u5b9a\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u6a21\u62df\u63a7\u5236\u4e0e\u57fa\u4e8e\u4e8b\u4ef6\u7684\u8109\u51b2\u63a7\u5236\u4e4b\u95f4\u7684\u57fa\u672c\u8054\u7cfb\uff0c\u4e3a\u795e\u7ecf\u5f62\u6001\u63a7\u5236\u5668\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2511.19170", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.19170", "abs": "https://arxiv.org/abs/2511.19170", "authors": ["Gaurav Kumar", "Akrati Saxena", "Chandrakala Meena"], "title": "Perplexity-Homophily Index: Homophily through Diversity in Hypergraphs", "comment": null, "summary": "Real-world complex systems are often better modeled as hypergraphs, where edges represent group interactions involving multiple entities. Understanding and quantifying homophily (similarity-driven association) in such networks is essential for analyzing community formation and information flow. We propose a hyperedge-centric framework to quantify homophily in hypergraphs. Each interaction is represented as a hyperedge, and its interaction perplexity measures the effective number of distinct attributes it contains. Comparing this observed perplexity with a degree-preserving random baseline defines the diversity gap, which quantifies how diverse an interaction is than expected by chance. The global homophily score for a network, called Perplexity-Homophily Index, is computed by averaging the normalized diversity gap across all hyperedges. Experiments on synthetic and real-world datasets show that the proposed index captures the full distribution of homophily and reveals how homophilic and heterophilic tendencies vary with interaction size in hypergraphs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u8fb9\u7684\u8d85\u56fe\u540c\u8d28\u6027\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u4ea4\u4e92\u56f0\u60d1\u5ea6\u548c\u591a\u6837\u6027\u5dee\u8ddd\u6765\u6d4b\u91cf\u7f51\u7edc\u4e2d\u540c\u8d28\u6027\u548c\u5f02\u8d28\u6027\u503e\u5411\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u590d\u6742\u7cfb\u7edf\u901a\u5e38\u66f4\u9002\u5408\u7528\u8d85\u56fe\u5efa\u6a21\uff0c\u5176\u4e2d\u8fb9\u4ee3\u8868\u6d89\u53ca\u591a\u4e2a\u5b9e\u4f53\u7684\u7fa4\u4f53\u4ea4\u4e92\u3002\u7406\u89e3\u548c\u91cf\u5316\u6b64\u7c7b\u7f51\u7edc\u4e2d\u7684\u540c\u8d28\u6027\u5bf9\u4e8e\u5206\u6790\u793e\u533a\u5f62\u6210\u548c\u4fe1\u606f\u6d41\u52a8\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u8d85\u8fb9\u4e2d\u5fc3\u6846\u67b6\u6765\u91cf\u5316\u8d85\u56fe\u4e2d\u7684\u540c\u8d28\u6027\u3002\u6bcf\u4e2a\u4ea4\u4e92\u8868\u793a\u4e3a\u8d85\u8fb9\uff0c\u5176\u4ea4\u4e92\u56f0\u60d1\u5ea6\u6d4b\u91cf\u5176\u5305\u542b\u7684\u6709\u6548\u4e0d\u540c\u5c5e\u6027\u6570\u91cf\u3002\u5c06\u89c2\u5bdf\u5230\u7684\u56f0\u60d1\u5ea6\u4e0e\u5ea6\u4fdd\u6301\u7684\u968f\u673a\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\uff0c\u5b9a\u4e49\u591a\u6837\u6027\u5dee\u8ddd\uff0c\u91cf\u5316\u4ea4\u4e92\u6bd4\u968f\u673a\u9884\u671f\u66f4\u591a\u6837\u5316\u7684\u7a0b\u5ea6\u3002\u7f51\u7edc\u7684\u5168\u5c40\u540c\u8d28\u6027\u5f97\u5206\u901a\u8fc7\u5e73\u5747\u6240\u6709\u8d85\u8fb9\u7684\u5f52\u4e00\u5316\u591a\u6837\u6027\u5dee\u8ddd\u6765\u8ba1\u7b97\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6307\u6570\u6355\u83b7\u4e86\u540c\u8d28\u6027\u7684\u5b8c\u6574\u5206\u5e03\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u8d85\u56fe\u4e2d\u540c\u8d28\u6027\u548c\u5f02\u8d28\u6027\u503e\u5411\u5982\u4f55\u968f\u4ea4\u4e92\u89c4\u6a21\u53d8\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u91cf\u5316\u8d85\u56fe\u4e2d\u7684\u540c\u8d28\u6027\uff0c\u63ed\u793a\u4e86\u4ea4\u4e92\u89c4\u6a21\u5bf9\u540c\u8d28\u6027\u548c\u5f02\u8d28\u6027\u503e\u5411\u7684\u5f71\u54cd\uff0c\u4e3a\u5206\u6790\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u7fa4\u4f53\u4ea4\u4e92\u6a21\u5f0f\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2511.18662", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.18662", "abs": "https://arxiv.org/abs/2511.18662", "authors": ["Itai Arieli", "Colin Stewart"], "title": "Bayesian Persuasion without Commitment", "comment": null, "summary": "We introduce a model of persuasion in which a sender without any commitment power privately gathers information about an unknown state of the world and then chooses what to verifiably disclose to a receiver. The receiver does not know how many experiments the sender is able to run, and may therefore be uncertain as to whether the sender disclosed all of her information. Despite this challenge, we show that, under general conditions, the sender is able to achieve the same payoff as in the full-commitment Bayesian persuasion case.", "AI": {"tldr": "\u53d1\u9001\u65b9\u5728\u6ca1\u6709\u627f\u8bfa\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\u79c1\u4e0b\u6536\u96c6\u4fe1\u606f\uff0c\u7136\u540e\u9009\u62e9\u5411\u63a5\u6536\u65b9\u9a8c\u8bc1\u6027\u62ab\u9732\u4ec0\u4e48\u4fe1\u606f\u3002\u63a5\u6536\u65b9\u4e0d\u77e5\u9053\u53d1\u9001\u65b9\u80fd\u8fdb\u884c\u591a\u5c11\u5b9e\u9a8c\uff0c\u56e0\u6b64\u53ef\u80fd\u4e0d\u786e\u5b9a\u53d1\u9001\u65b9\u662f\u5426\u62ab\u9732\u4e86\u6240\u6709\u4fe1\u606f\u3002\u4f46\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u53d1\u9001\u65b9\u4ecd\u80fd\u8fbe\u5230\u4e0e\u5b8c\u5168\u627f\u8bfa\u8d1d\u53f6\u65af\u529d\u8bf4\u76f8\u540c\u7684\u6536\u76ca\u3002", "motivation": "\u7814\u7a76\u5728\u6ca1\u6709\u627f\u8bfa\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\uff0c\u53d1\u9001\u65b9\u5982\u4f55\u901a\u8fc7\u4fe1\u606f\u6536\u96c6\u548c\u9009\u62e9\u6027\u62ab\u9732\u6765\u5f71\u54cd\u63a5\u6536\u65b9\u7684\u51b3\u7b56\uff0c\u7279\u522b\u662f\u5728\u63a5\u6536\u65b9\u4e0d\u786e\u5b9a\u53d1\u9001\u65b9\u4fe1\u606f\u5b8c\u6574\u6027\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u5efa\u7acb\u529d\u8bf4\u6a21\u578b\uff0c\u53d1\u9001\u65b9\u79c1\u4e0b\u6536\u96c6\u5173\u4e8e\u672a\u77e5\u4e16\u754c\u72b6\u6001\u7684\u4fe1\u606f\uff0c\u7136\u540e\u9009\u62e9\u9a8c\u8bc1\u6027\u62ab\u9732\u90e8\u5206\u4fe1\u606f\u7ed9\u63a5\u6536\u65b9\u3002\u63a5\u6536\u65b9\u4e0d\u77e5\u9053\u53d1\u9001\u65b9\u7684\u4fe1\u606f\u6536\u96c6\u80fd\u529b\u3002", "result": "\u5728\u4e00\u822c\u6761\u4ef6\u4e0b\uff0c\u53d1\u9001\u65b9\u80fd\u591f\u8fbe\u5230\u4e0e\u5b8c\u5168\u627f\u8bfa\u8d1d\u53f6\u65af\u529d\u8bf4\u60c5\u51b5\u76f8\u540c\u7684\u6536\u76ca\u6c34\u5e73\u3002", "conclusion": "\u5373\u4f7f\u6ca1\u6709\u627f\u8bfa\u80fd\u529b\uff0c\u53d1\u9001\u65b9\u901a\u8fc7\u7b56\u7565\u6027\u4fe1\u606f\u62ab\u9732\u4ecd\u80fd\u6709\u6548\u5f71\u54cd\u63a5\u6536\u65b9\u51b3\u7b56\uff0c\u8fbe\u5230\u4e0e\u5b8c\u5168\u627f\u8bfa\u60c5\u51b5\u76f8\u540c\u7684\u529d\u8bf4\u6548\u679c\u3002"}}
{"id": "2511.17591", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.17591", "abs": "https://arxiv.org/abs/2511.17591", "authors": ["Quan-Hoang Vuong", "Fatemeh Kianfar", "Thi Mai Anh Tran", "Ni Putu Wulan Purnama Sari", "Cresensia Dina Candra Kumaladewi", "Viet-Phuong La", "Minh-Hoang Nguyen"], "title": "Do Environment-Modification Behaviors and Gamers' Immersiveness Shape Exceptionalism Beliefs?", "comment": null, "summary": "Human exceptionalism strongly shapes human-nature perceptions, thinking, values, and behaviors. Yet little is known about how virtual ecological environments influence this mindset. As digital worlds become increasingly immersive and ecologically sophisticated, they provide novel contexts for examining how human value systems are formed and transformed. This study investigates how virtual environment-modification behaviors and players' sense of immersiveness jointly shape exceptionalism, drawing on worldviews from quantum mechanics and mathematical logic. Using Granular Interaction Thinking Theory (GITT) and the Bayesian Mindsponge Framework (BMF analytics), we analyze five key activities--tree planting, flower planting, flower crossbreeding, terraforming, and creating conditions for bug respawn--based on a multinational dataset of 640 Animal Crossing: New Horizons players from 29 countries. Results reveal two behavioral clusters distinguished by controllability. High-controllability behaviors (i.e., flower planting and terraforming) predict higher exceptionalism, whereas the flower-planting effect reverses among highly immersed players. Low-controllability behaviors (i.e., flower crossbreeding and manipulating bug spawning) predict lower exceptionalism, but these associations weaken or reverse under high immersiveness, respectively. These findings offer insights into leveraging virtual worlds to cultivate Nature Quotient (NQ), mitigate exceptionalist tendencies, and foster eco-surplus cultural orientations.", "AI": {"tldr": "\u7814\u7a76\u865a\u62df\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u63a7\u5236\u6027\u4e0e\u6c89\u6d78\u611f\u5982\u4f55\u5171\u540c\u5f71\u54cd\u4eba\u7c7b\u4f8b\u5916\u4e3b\u4e49\uff0c\u53d1\u73b0\u9ad8\u63a7\u5236\u6027\u884c\u4e3a\u589e\u5f3a\u4f8b\u5916\u4e3b\u4e49\uff0c\u4f4e\u63a7\u5236\u6027\u884c\u4e3a\u964d\u4f4e\u4f8b\u5916\u4e3b\u4e49\uff0c\u4f46\u6c89\u6d78\u611f\u4f1a\u8c03\u8282\u8fd9\u4e9b\u6548\u5e94\u3002", "motivation": "\u63a2\u7d22\u865a\u62df\u751f\u6001\u73af\u5883\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u4f8b\u5916\u4e3b\u4e49\u8fd9\u4e00\u91cd\u8981\u4f46\u7814\u7a76\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3a\u5229\u7528\u6570\u5b57\u4e16\u754c\u57f9\u517b\u751f\u6001\u7d20\u517b\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u4f7f\u7528\u7c92\u5ea6\u4ea4\u4e92\u601d\u7ef4\u7406\u8bba\u548c\u8d1d\u53f6\u65af\u601d\u7ef4\u6d77\u7ef5\u6846\u67b6\uff0c\u5206\u6790640\u540d\u300a\u52a8\u7269\u68ee\u53cb\u4f1a\u300b\u73a9\u5bb6\u7684\u4e94\u79cd\u5173\u952e\u884c\u4e3a\u6570\u636e\u3002", "result": "\u9ad8\u63a7\u5236\u6027\u884c\u4e3a\uff08\u79cd\u82b1\u3001\u5730\u5f62\u6539\u9020\uff09\u9884\u6d4b\u66f4\u9ad8\u4f8b\u5916\u4e3b\u4e49\uff0c\u4f4e\u63a7\u5236\u6027\u884c\u4e3a\uff08\u6742\u4ea4\u3001\u866b\u7c7b\u7e41\u6b96\uff09\u9884\u6d4b\u66f4\u4f4e\u4f8b\u5916\u4e3b\u4e49\uff0c\u4f46\u6c89\u6d78\u611f\u4f1a\u8c03\u8282\u8fd9\u4e9b\u5173\u8054\u3002", "conclusion": "\u865a\u62df\u4e16\u754c\u53ef\u7528\u4e8e\u57f9\u517b\u81ea\u7136\u5546\u6570\u3001\u7f13\u89e3\u4f8b\u5916\u4e3b\u4e49\u503e\u5411\u5e76\u4fc3\u8fdb\u751f\u6001\u76c8\u4f59\u6587\u5316\u53d6\u5411\u3002"}}
{"id": "2511.18483", "categories": ["cs.CY", "math.OC", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.18483", "abs": "https://arxiv.org/abs/2511.18483", "authors": ["Sergio Marin", "Nhu Nguyen", "Max", "Zheng", "Christina M. Weaver"], "title": "Optimal Meal Schedule for a Local Nonprofit Using LLM-Aided Data Extraction", "comment": "12 pages, 4 figures, presented at 2025 INFORMS Data Science Workshop (Atlanta, Georgia, Oct. 25, 2025)", "summary": "We present a data-driven pipeline developed in collaboration with the Power Packs Project, a nonprofit addressing food insecurity in local communities. The system integrates data extraction from PDFs, large language models for ingredient standardization, and binary integer programming to generate a 15-week recipe schedule that minimizes projected wholesale costs while meeting nutritional constraints. All 157 recipes were mapped to a nutritional database and assigned estimated and predicted costs using historical invoice data and category-specific inflation adjustments. The model effectively handles real-world price volatility and is structured for easy updates as new recipes or cost data become available. Optimization results show that constraint-based selection yields nutritionally balanced and cost-efficient plans under uncertainty. To facilitate real-time decision-making, we deployed a searchable web platform that integrates analytical models into daily operations by enabling staff to explore recipes by ingredient, category, or through an optimized meal plan.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u98df\u8c31\u4f18\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408PDF\u6570\u636e\u63d0\u53d6\u3001LLM\u6807\u51c6\u5316\u98df\u6750\u548c\u6574\u6570\u89c4\u5212\uff0c\u751f\u621015\u5468\u8425\u517b\u5747\u8861\u4e14\u6210\u672c\u6700\u4f4e\u7684\u98df\u8c31\u8ba1\u5212\u3002", "motivation": "\u4e0ePower Packs Project\u5408\u4f5c\uff0c\u89e3\u51b3\u5f53\u5730\u793e\u533a\u7cae\u98df\u4e0d\u5b89\u5168\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u98df\u8c31\u9009\u62e9\u6765\u964d\u4f4e\u91c7\u8d2d\u6210\u672c\u540c\u65f6\u6ee1\u8db3\u8425\u517b\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u6570\u636e\u63d0\u53d6\u3001\u5927\u8bed\u8a00\u6a21\u578b\u6807\u51c6\u5316\u98df\u6750\u3001\u4e8c\u8fdb\u5236\u6574\u6570\u89c4\u5212\u4f18\u5316\uff0c\u7ed3\u5408\u8425\u517b\u6570\u636e\u5e93\u548c\u5386\u53f2\u53d1\u7968\u6570\u636e\uff0c\u5904\u7406\u4ef7\u683c\u6ce2\u52a8\u5e76\u652f\u6301\u5b9e\u65f6\u66f4\u65b0\u3002", "result": "\u4f18\u5316\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u80fd\u751f\u6210\u8425\u517b\u5747\u8861\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u98df\u8c31\u8ba1\u5212\uff0c\u5e76\u90e8\u7f72\u4e86\u53ef\u641c\u7d22\u7684Web\u5e73\u53f0\u652f\u6301\u5b9e\u65f6\u51b3\u7b56\u3002", "conclusion": "\u57fa\u4e8e\u7ea6\u675f\u7684\u4f18\u5316\u9009\u62e9\u80fd\u6709\u6548\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4ef7\u683c\u6ce2\u52a8\uff0c\u63d0\u4f9b\u8425\u517b\u5747\u8861\u4e14\u6210\u672c\u9ad8\u6548\u7684\u98df\u8c31\u89c4\u5212\u65b9\u6848\uff0c\u7cfb\u7edf\u6613\u4e8e\u66f4\u65b0\u548c\u7ef4\u62a4\u3002"}}
{"id": "2511.17765", "categories": ["cs.RO", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.17765", "abs": "https://arxiv.org/abs/2511.17765", "authors": ["Darren Chiu", "Zhehui Huang", "Ruohai Ge", "Gaurav S. Sukhatme"], "title": "LEARN: Learning End-to-End Aerial Resource-Constrained Multi-Robot Navigation", "comment": "20 pages, 15 figures", "summary": "Nano-UAV teams offer great agility yet face severe navigation challenges due to constrained onboard sensing, communication, and computation. Existing approaches rely on high-resolution vision or compute-intensive planners, rendering them infeasible for these platforms. We introduce LEARN, a lightweight, two-stage safety-guided reinforcement learning (RL) framework for multi-UAV navigation in cluttered spaces. Our system combines low-resolution Time-of-Flight (ToF) sensors and a simple motion planner with a compact, attention-based RL policy. In simulation, LEARN outperforms two state-of-the-art planners by $10\\%$ while using substantially fewer resources. We demonstrate LEARN's viability on six Crazyflie quadrotors, achieving fully onboard flight in diverse indoor and outdoor environments at speeds up to $2.0 m/s$ and traversing $0.2 m$ gaps.", "AI": {"tldr": "LEARN\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5b89\u5168\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u65e0\u4eba\u673a\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5bfc\u822a\uff0c\u7ed3\u5408\u4f4e\u5206\u8fa8\u7387ToF\u4f20\u611f\u5668\u548c\u7d27\u51d1\u7684\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u7eb3\u7c73\u65e0\u4eba\u673a\u4e0a\u5b9e\u73b0\u9ad8\u6548\u98de\u884c\u3002", "motivation": "\u7eb3\u7c73\u65e0\u4eba\u673a\u56e2\u961f\u5177\u6709\u9ad8\u654f\u6377\u6027\uff0c\u4f46\u53d7\u9650\u4e8e\u673a\u8f7d\u4f20\u611f\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u80fd\u529b\uff0c\u73b0\u6709\u57fa\u4e8e\u9ad8\u5206\u8fa8\u7387\u89c6\u89c9\u6216\u8ba1\u7b97\u5bc6\u96c6\u578b\u89c4\u5212\u5668\u7684\u65b9\u6cd5\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u7ea7\u5bfc\u822a\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5b89\u5168\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4f4e\u5206\u8fa8\u7387ToF\u4f20\u611f\u5668\u3001\u7b80\u5355\u8fd0\u52a8\u89c4\u5212\u5668\u548c\u7d27\u51d1\u7684\u6ce8\u610f\u529b\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728\u4eff\u771f\u4e2d\u6027\u80fd\u4f18\u4e8e\u4e24\u79cd\u6700\u5148\u8fdb\u89c4\u5212\u566810%\uff0c\u8d44\u6e90\u6d88\u8017\u663e\u8457\u51cf\u5c11\uff1b\u57286\u67b6Crazyflie\u56db\u65cb\u7ffc\u4e0a\u5b9e\u73b0\u5b8c\u5168\u673a\u8f7d\u98de\u884c\uff0c\u5ba4\u5185\u5916\u73af\u5883\u4e0b\u901f\u5ea6\u8fbe2.0m/s\uff0c\u53ef\u7a7f\u8d8a0.2m\u95f4\u9699\u3002", "conclusion": "LEARN\u6846\u67b6\u8bc1\u660e\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7684\u7eb3\u7c73\u65e0\u4eba\u673a\u4e0a\u5b9e\u73b0\u9ad8\u6548\u591a\u673a\u5bfc\u822a\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u8f7b\u91cf\u7ea7\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17714", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17714", "abs": "https://arxiv.org/abs/2511.17714", "authors": ["Alex John London", "Aydin Mohseni"], "title": "Learning the Value of Value Learning", "comment": "27 pages, 6 figures, mathematical appendix", "summary": "Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.", "AI": {"tldr": "\u6269\u5c55Jeffrey-Bolker\u51b3\u7b56\u6846\u67b6\u4ee5\u5efa\u6a21\u4ef7\u503c\u7cbe\u70bc\uff0c\u8bc1\u660e\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff0c\u5e76\u5c55\u793a\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u4ef7\u503c\u7cbe\u70bc\u80fd\u5c06\u96f6\u548c\u535a\u5f08\u8f6c\u5316\u4e3a\u6b63\u548c\u4e92\u52a8\u3002", "motivation": "\u6807\u51c6\u51b3\u7b56\u6846\u67b6\u5904\u7406\u4e8b\u5b9e\u4e0d\u786e\u5b9a\u6027\u4f46\u5047\u8bbe\u4ef7\u503c\u56fa\u5b9a\uff0c\u9700\u8981\u6269\u5c55\u6846\u67b6\u6765\u5efa\u6a21\u4ef7\u503c\u7cbe\u70bc\u8fc7\u7a0b\u3002", "method": "\u6269\u5c55Jeffrey-Bolker\u6846\u67b6\uff0c\u5efa\u7acb\u4ef7\u503c\u7cbe\u70bc\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff0c\u5206\u6790\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u4ef7\u503c\u7cbe\u70bc\u6548\u5e94\u3002", "result": "\u8bc1\u660e\u4e86\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff0c\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u4ef7\u503c\u7cbe\u70bc\u80fd\u5c06\u96f6\u548c\u535a\u5f08\u8f6c\u5316\u4e3a\u6b63\u548c\u4e92\u52a8\uff0c\u4ea7\u751f\u5e15\u7d2f\u6258\u6539\u8fdb\u7684\u7eb3\u4ec0\u8bae\u4ef7\u7ed3\u679c\u3002", "conclusion": "\u7406\u6027\u9009\u62e9\u6846\u67b6\u53ef\u6269\u5c55\u81f3\u4ef7\u503c\u7cbe\u70bc\u5efa\u6a21\uff0c\u7edf\u4e00\u8ba4\u8bc6\u8bba\u548c\u4ef7\u503c\u8bba\u7cbe\u70bc\uff0c\u62d3\u5bbd\u7406\u6027\u9009\u62e9\u7684\u6982\u5ff5\u57fa\u7840\u5e76\u9610\u660e\u4f26\u7406\u5ba1\u8bae\u7684\u89c4\u8303\u5730\u4f4d\u3002"}}
{"id": "2511.18944", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.18944", "abs": "https://arxiv.org/abs/2511.18944", "authors": ["Juan A. Crespo", "Armajac Ravent\u00f3s-Pujol"], "title": "Revisiting the Measurement of Polarization", "comment": null, "summary": "We revisit Esteban and Ray's (1994) seminal model of polarization. Their main result (unnecessarily) relies on the assumption that individuals are infinitely divisible, which imposes strong restrictions on admissible polarization indices. We show that relaxing this assumption yields a broader family of indices consistent with the original axioms. The resulting indices avoid counter-intuitive rankings that arise when using results on the original paper and provide greater flexibility for empirical applications.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86Esteban\u548cRay(1994)\u7684\u6781\u5316\u6a21\u578b\uff0c\u53d1\u73b0\u5176\u6838\u5fc3\u7ed3\u679c\u4e0d\u5fc5\u8981\u5730\u4f9d\u8d56\u4e8e\u4e2a\u4f53\u65e0\u9650\u53ef\u5206\u7684\u5047\u8bbe\uff0c\u8be5\u5047\u8bbe\u9650\u5236\u4e86\u53ef\u63a5\u53d7\u7684\u6781\u5316\u6307\u6570\u3002\u901a\u8fc7\u653e\u677e\u8fd9\u4e00\u5047\u8bbe\uff0c\u4f5c\u8005\u63a8\u5bfc\u51fa\u4e86\u66f4\u5e7f\u6cdb\u7684\u6781\u5316\u6307\u6570\u65cf\u3002", "motivation": "Esteban\u548cRay\u7684\u539f\u59cb\u6781\u5316\u6a21\u578b\u5047\u8bbe\u4e2a\u4f53\u65e0\u9650\u53ef\u5206\uff0c\u8fd9\u7ed9\u6781\u5316\u6307\u6570\u7684\u6784\u5efa\u5e26\u6765\u4e86\u4e0d\u5fc5\u8981\u7684\u9650\u5236\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u53cd\u76f4\u89c9\u7684\u6392\u5e8f\u7ed3\u679c\u3002", "method": "\u901a\u8fc7\u653e\u677e\u4e2a\u4f53\u65e0\u9650\u53ef\u5206\u7684\u5047\u8bbe\uff0c\u5728\u4fdd\u6301\u539f\u59cb\u516c\u7406\u4f53\u7cfb\u4e00\u81f4\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u63a8\u5bfc\u51fa\u66f4\u5e7f\u6cdb\u7684\u6781\u5316\u6307\u6570\u65cf\u3002", "result": "\u5f97\u5230\u4e86\u6bd4\u539f\u59cb\u6a21\u578b\u66f4\u5e7f\u6cdb\u7684\u6781\u5316\u6307\u6570\u65cf\uff0c\u8fd9\u4e9b\u6307\u6570\u907f\u514d\u4e86\u4f7f\u7528\u539f\u59cb\u6a21\u578b\u7ed3\u679c\u65f6\u51fa\u73b0\u7684\u53cd\u76f4\u89c9\u6392\u5e8f\uff0c\u5e76\u4e3a\u5b9e\u8bc1\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5927\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "\u653e\u677e\u4e2a\u4f53\u65e0\u9650\u53ef\u5206\u7684\u5047\u8bbe\u80fd\u591f\u4ea7\u751f\u66f4\u5408\u7406\u3001\u66f4\u7075\u6d3b\u7684\u6781\u5316\u6d4b\u91cf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u59cb\u516c\u7406\u4f53\u7cfb\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2511.18051", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18051", "abs": "https://arxiv.org/abs/2511.18051", "authors": ["Jilan Mei", "Tengjie Zheng", "Lin Cheng", "Shengping Gong", "Xu Huang"], "title": "Sparse Kalman Identification for Partially Observable Systems via Adaptive Bayesian Learning", "comment": null, "summary": "Sparse dynamics identification is an essential tool for discovering interpretable physical models and enabling efficient control in engineering systems. However, existing methods rely on batch learning with full historical data, limiting their applicability to real-time scenarios involving sequential and partially observable data. To overcome this limitation, this paper proposes an online Sparse Kalman Identification (SKI) method by integrating the Augmented Kalman Filter (AKF) and Automatic Relevance Determination (ARD). The main contributions are: (1) a theoretically grounded Bayesian sparsification scheme that is seamlessly integrated into the AKF framework and adapted to sequentially collected data in online scenarios; (2) an update mechanism that adapts the Kalman posterior to reflect the updated selection of the basis functions that define the model structure; (3) an explicit gradient-descent formulation that enhances computational efficiency. Consequently, the SKI method achieves accurate model structure selection with millisecond-level efficiency and higher identification accuracy, as demonstrated by extensive simulations and real-world experiments (showing an 84.21\\% improvement in accuracy over the baseline AKF).", "AI": {"tldr": "\u63d0\u51fa\u5728\u7ebf\u7a00\u758f\u5361\u5c14\u66fc\u8fa8\u8bc6(SKI)\u65b9\u6cd5\uff0c\u5c06\u589e\u5f3a\u5361\u5c14\u66fc\u6ee4\u6ce2\u4e0e\u81ea\u52a8\u76f8\u5173\u6027\u786e\u5b9a\u7ed3\u5408\uff0c\u5b9e\u73b0\u5b9e\u65f6\u7a00\u758f\u52a8\u529b\u5b66\u8fa8\u8bc6\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u7cbe\u5ea6\u63d0\u534784.21%\u3002", "motivation": "\u73b0\u6709\u7a00\u758f\u52a8\u529b\u5b66\u8fa8\u8bc6\u65b9\u6cd5\u4f9d\u8d56\u6279\u91cf\u5b66\u4e60\uff0c\u65e0\u6cd5\u9002\u5e94\u5b9e\u65f6\u573a\u666f\u4e2d\u7684\u987a\u5e8f\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6570\u636e\uff0c\u9650\u5236\u4e86\u5728\u5de5\u7a0b\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u96c6\u6210\u589e\u5f3a\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u81ea\u52a8\u76f8\u5173\u6027\u786e\u5b9a\uff0c\u63d0\u51fa\u8d1d\u53f6\u65af\u7a00\u758f\u5316\u65b9\u6848\uff0c\u5efa\u7acb\u66f4\u65b0\u673a\u5236\u9002\u5e94\u57fa\u51fd\u6570\u9009\u62e9\u53d8\u5316\uff0c\u91c7\u7528\u663e\u5f0f\u68af\u5ea6\u4e0b\u964d\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "result": "SKI\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6beb\u79d2\u7ea7\u6548\u7387\u7684\u51c6\u786e\u6a21\u578b\u7ed3\u6784\u9009\u62e9\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u66f4\u9ad8\u7684\u8fa8\u8bc6\u7cbe\u5ea6\uff0c\u76f8\u6bd4\u57fa\u7ebfAKF\u7cbe\u5ea6\u63d0\u534784.21%\u3002", "conclusion": "SKI\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u65f6\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5de5\u7a0b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5728\u7ebf\u7a00\u758f\u52a8\u529b\u5b66\u8fa8\u8bc6\u5de5\u5177\u3002"}}
{"id": "2511.19300", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.19300", "abs": "https://arxiv.org/abs/2511.19300", "authors": ["Pouria Bazyarrezaei", "Mohammad Abdollahi Azgomi"], "title": "On Yukawa Potential Centrality for Identification of Influential Spreaders in Complex Networks", "comment": null, "summary": "Identifying influential nodes in complex networks is a fundamental challenge for understanding how information, influence, and contagion propagate through interconnected systems. Conventional centrality measures, particularly gravity-based models, often depend on pairwise interaction forces and a fixed radius of influence, which oversimplify the heterogeneous and dynamic nature of real networks. To overcome these limitations, this study proposes a novel non-interactive, action-based model, termed Yukawa Potential Centrality (YPC), which adapts the physical Yukawa potential to the topology of complex networks. Unlike gravity models, YPC computes a scalar potential for each node rather than pairwise forces, dynamically adjusting its radius of influence according to local structural properties. This formulation establishes a physically interpretable bridge between potential theory and network science, while significantly reducing computational complexity, from quadratic to near-linear time. The model is evaluated across both synthetic and real-world social networks, and its node rankings are compared with classical centrality indices and epidemic spreading models (SI and SIS). Experimental findings reveal that YPC exhibits a strong positive correlation with the SIS model and effectively isolates key spreaders, even within highly irregular topologies. These results demonstrate that YPC provides a scalable, adaptive, and theoretically grounded framework for influence analysis in social, biological, and communication networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6c64\u5ddd\u52bf\u7684\u65b0\u578b\u4e2d\u5fc3\u6027\u5ea6\u91cfYPC\uff0c\u7528\u4e8e\u8bc6\u522b\u590d\u6742\u7f51\u7edc\u4e2d\u7684\u5f71\u54cd\u529b\u8282\u70b9\uff0c\u76f8\u6bd4\u4f20\u7edf\u91cd\u529b\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u9002\u5e94\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u4e2d\u5fc3\u6027\u5ea6\u91cf\u7279\u522b\u662f\u91cd\u529b\u6a21\u578b\u4f9d\u8d56\u6210\u5bf9\u76f8\u4e92\u4f5c\u7528\u529b\u548c\u56fa\u5b9a\u5f71\u54cd\u534a\u5f84\uff0c\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u771f\u5b9e\u7f51\u7edc\u7684\u5f02\u8d28\u6027\u548c\u52a8\u6001\u7279\u6027\u3002", "method": "\u5c06\u7269\u7406\u6c64\u5ddd\u52bf\u5e94\u7528\u4e8e\u590d\u6742\u7f51\u7edc\u62d3\u6251\uff0c\u4e3a\u6bcf\u4e2a\u8282\u70b9\u8ba1\u7b97\u6807\u91cf\u52bf\u800c\u975e\u6210\u5bf9\u529b\uff0c\u6839\u636e\u5c40\u90e8\u7ed3\u6784\u7279\u6027\u52a8\u6001\u8c03\u6574\u5f71\u54cd\u534a\u5f84\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u793e\u4ea4\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cYPC\u4e0eSIS\u4f20\u64ad\u6a21\u578b\u5448\u5f3a\u6b63\u76f8\u5173\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u5173\u952e\u4f20\u64ad\u8005\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u4e8c\u6b21\u964d\u81f3\u8fd1\u7ebf\u6027\u3002", "conclusion": "YPC\u4e3a\u793e\u4ea4\u3001\u751f\u7269\u548c\u901a\u4fe1\u7f51\u7edc\u4e2d\u7684\u5f71\u54cd\u529b\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u4e14\u7406\u8bba\u57fa\u7840\u7684\u6846\u67b6\u3002"}}
{"id": "2511.19017", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.19017", "abs": "https://arxiv.org/abs/2511.19017", "authors": ["Dong Yang"], "title": "\"Don't Fall Behind\": A Unified Framework of Dynastic Survival, Two-Stage Belief Error, and the Modern Involution Trap", "comment": null, "summary": "We set out to solve a dual puzzle regarding reproductive strategies: The \"Ancient vs. Modern\" Puzzle (why pre-modern elites adopted a \"Survival\" strategy while modern elites adopt an \"Anxiety\" strategy) and the \"Class Divide\" Puzzle (why modern involution manifests as a U-shaped fertility pattern). We develop a unified computational framework (DP + Monte Carlo) that introduces Cognitive Heterogeneity across classes. Our Hybrid Model (M-H) posits that the poor act as \"Rational Survivors\" (M1 utility, Reality parameters), while the middle/rich act as \"Biased Strivers\" (M4b utility, Belief parameters).\n  Our simulations yield three core findings. First, we confirm that the \"Survival\" strategy is objectively rational whenever risk exceeds a low threshold ($\u03c3> 0.45$). Given that real-world risk is massive ($\u03c3_{Real} \\approx 4.9$), the modern \"Quality\" strategy is objectively fragile. Second, the trap for the Middle/Rich ($B \\ge 200$) is driven by a \"Two-Stage Belief Error\": they are first \"baited\" by a Causal Error (underestimating risk) to enter the status game, and then \"trapped\" by a Marginal Error (underestimating returns) which triggers a stop in fertility. Third, the U-shape is driven by the cognitive divide. The Poor escape the trap by retaining a \"Rational Survival\" strategy in the face of real high risk. Conversely, the Aspirational Middle Class ($HC \\approx 12, B \\ge 200$) is uniquely trapped by their Biased Beliefs. Their high competence raises their dynastic reference point ($R$) to a level where, under perceived low returns, restricting fertility to $N=1$ becomes the only rational choice within their biased belief system.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8ba1\u7b97\u6a21\u578b\u89e3\u91ca\u4e86\u751f\u80b2\u7b56\u7565\u7684\u4e24\u4e2a\u8c1c\u9898\uff1a\u53e4\u4ee3vs\u73b0\u4ee3\u7cbe\u82f1\u7b56\u7565\u5dee\u5f02\uff08\u751f\u5b58vs\u7126\u8651\uff09\u548c\u73b0\u4ee3\u793e\u4f1a\u7684U\u578b\u751f\u80b2\u6a21\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u4ee3\"\u8d28\u91cf\"\u7b56\u7565\u5728\u771f\u5b9e\u9ad8\u98ce\u9669\u73af\u5883\u4e0b\u662f\u8106\u5f31\u7684\uff0c\u4e2d\u4ea7\u9636\u7ea7\u56e0\u8ba4\u77e5\u504f\u5dee\u9677\u5165\u751f\u80b2\u9677\u9631\uff0c\u800c\u7a77\u4eba\u4fdd\u6301\u7406\u6027\u751f\u5b58\u7b56\u7565\u3002", "motivation": "\u89e3\u51b3\u751f\u80b2\u7b56\u7565\u7684\u4e24\u4e2a\u6838\u5fc3\u8c1c\u9898\uff1a1) \u4e3a\u4ec0\u4e48\u524d\u73b0\u4ee3\u7cbe\u82f1\u91c7\u7528\"\u751f\u5b58\"\u7b56\u7565\u800c\u73b0\u4ee3\u7cbe\u82f1\u91c7\u7528\"\u7126\u8651\"\u7b56\u7565\uff1b2) \u4e3a\u4ec0\u4e48\u73b0\u4ee3\u793e\u4f1a\u51fa\u73b0U\u578b\u751f\u80b2\u6a21\u5f0f\uff08\u9636\u7ea7\u5206\u5316\uff09\u3002", "method": "\u5f00\u53d1\u7edf\u4e00\u7684\u8ba1\u7b97\u6846\u67b6\uff08\u52a8\u6001\u89c4\u5212+\u8499\u7279\u5361\u6d1b\u6a21\u62df\uff09\uff0c\u5f15\u5165\u9636\u7ea7\u95f4\u7684\u8ba4\u77e5\u5f02\u8d28\u6027\u3002\u6df7\u5408\u6a21\u578b\u5047\u8bbe\u7a77\u4eba\u4f5c\u4e3a\"\u7406\u6027\u751f\u5b58\u8005\"\uff08M1\u6548\u7528\u51fd\u6570\uff0c\u73b0\u5b9e\u53c2\u6570\uff09\uff0c\u800c\u4e2d/\u5bcc\u4eba\u4f5c\u4e3a\"\u504f\u89c1\u594b\u6597\u8005\"\uff08M4b\u6548\u7528\u51fd\u6570\uff0c\u4fe1\u5ff5\u53c2\u6570\uff09\u3002", "result": "1) \u5f53\u98ce\u9669\u8d85\u8fc7\u4f4e\u9608\u503c(\u03c3>0.45)\u65f6\uff0c\"\u751f\u5b58\"\u7b56\u7565\u662f\u5ba2\u89c2\u7406\u6027\u7684\uff0c\u800c\u771f\u5b9e\u4e16\u754c\u98ce\u9669\u5de8\u5927(\u03c3\u22484.9)\uff0c\u73b0\u4ee3\"\u8d28\u91cf\"\u7b56\u7565\u662f\u8106\u5f31\u7684\uff1b2) \u4e2d/\u5bcc\u4eba\u9677\u5165\"\u4e24\u9636\u6bb5\u4fe1\u5ff5\u9519\u8bef\"\u9677\u9631\uff1b3) U\u578b\u751f\u80b2\u6a21\u5f0f\u7531\u8ba4\u77e5\u5206\u5316\u9a71\u52a8\uff0c\u7a77\u4eba\u4fdd\u6301\u7406\u6027\u7b56\u7565\uff0c\u4e2d\u4ea7\u9636\u7ea7\u56e0\u9ad8\u80fd\u529b\u548c\u504f\u89c1\u4fe1\u5ff5\u88ab\u72ec\u7279\u5730\u56f0\u4f4f\u3002", "conclusion": "\u73b0\u4ee3\u751f\u80b2\u6a21\u5f0f\u7684\u4e0d\u5e73\u7b49\u6e90\u4e8e\u9636\u7ea7\u95f4\u7684\u8ba4\u77e5\u5206\u5316\uff1a\u7a77\u4eba\u57fa\u4e8e\u73b0\u5b9e\u98ce\u9669\u4fdd\u6301\u7406\u6027\u751f\u5b58\u7b56\u7565\uff0c\u800c\u4e2d\u4ea7\u9636\u7ea7\u56e0\u8ba4\u77e5\u504f\u5dee\u9677\u5165\u751f\u80b2\u9650\u5236\u7684\u9677\u9631\uff0c\u8fd9\u89e3\u91ca\u4e86U\u578b\u751f\u80b2\u6a21\u5f0f\u548c\u73b0\u4ee3\u7cbe\u82f1\u7684\u7126\u8651\u7b56\u7565\u3002"}}
{"id": "2511.17646", "categories": ["cs.CY", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.17646", "abs": "https://arxiv.org/abs/2511.17646", "authors": ["Quan-Hoang Vuong", "Viet-Phuong La", "Minh-Hoang Nguyen"], "title": "Bayesian probabilistic exploration of Bitcoin informational quanta and interactions under the GITT-VT paradigm", "comment": null, "summary": "This study explores Bitcoin's value formation through the Granular Interaction Thinking Theory-Value Theory (GITT-VT). Rather than stemming from material utility or cash flows, Bitcoin's value arises from informational attributes and interactions of multiple factors, including cryptographic order, decentralization-enabled autonomy, trust embedded in the consensus mechanism, and socio-narrative coherence that reduce entropy within decentralized value-exchange processes. To empirically assess this perspective, a Bayesian linear model was estimated using daily data from 2022 to 2025, operationalizing four informational value dimensions: Store-of-Value (SOV), Autonomy (AUT), Social-Signal Value (SSV), and Hedonic-Sentiment Value (HSV). Results indicate that only SSV exerts a highly credible positive effect on next-day returns, highlighting the dominant role of high-entropy social information in short-term pricing dynamics. In contrast, SOV and AUT show moderately reliable positive associations, reflecting their roles as low-entropy structural anchors of long-term value. HSV displays no credible predictive effect. The study advances interdisciplinary value theory and demonstrates Bitcoin as a dual-layer entropy-regulating socio-technological ecosystem. The findings offer implications for digital asset valuation, investment education, and future research on entropy dynamics across non-cash-flow digital assets.", "AI": {"tldr": "\u57fa\u4e8eGITT-VT\u7406\u8bba\u5206\u6790\u6bd4\u7279\u5e01\u4ef7\u503c\u5f62\u6210\u673a\u5236\uff0c\u53d1\u73b0\u5176\u4ef7\u503c\u6e90\u4e8e\u4fe1\u606f\u5c5e\u6027\u548c\u591a\u56e0\u7d20\u4ea4\u4e92\u4f5c\u7528\uff0c\u800c\u975e\u7269\u8d28\u6548\u7528\u6216\u73b0\u91d1\u6d41\u3002\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\u793e\u4f1a\u4fe1\u53f7\u4ef7\u503c(SSV)\u5bf9\u77ed\u671f\u56de\u62a5\u6709\u663e\u8457\u5f71\u54cd\uff0c\u800c\u50a8\u503c\u4ef7\u503c(SOV)\u548c\u81ea\u4e3b\u6027(AUT)\u662f\u957f\u671f\u4ef7\u503c\u7684\u7ed3\u6784\u951a\u70b9\u3002", "motivation": "\u63a2\u7d22\u6bd4\u7279\u5e01\u4f5c\u4e3a\u975e\u73b0\u91d1\u6d41\u6570\u5b57\u8d44\u4ea7\u7684\u4ef7\u503c\u5f62\u6210\u673a\u5236\uff0c\u6311\u6218\u4f20\u7edf\u57fa\u4e8e\u7269\u8d28\u6548\u7528\u6216\u73b0\u91d1\u6d41\u7684\u4ef7\u503c\u7406\u8bba\uff0c\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u5c5e\u6027\u548c\u4ea4\u4e92\u4f5c\u7528\u7684\u65b0\u4ef7\u503c\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u7ebf\u6027\u6a21\u578b\u5206\u67902022-2025\u5e74\u65e5\u5ea6\u6570\u636e\uff0c\u64cd\u4f5c\u5316\u56db\u4e2a\u4fe1\u606f\u4ef7\u503c\u7ef4\u5ea6\uff1a\u50a8\u503c\u4ef7\u503c(SOV)\u3001\u81ea\u4e3b\u6027(AUT)\u3001\u793e\u4f1a\u4fe1\u53f7\u4ef7\u503c(SSV)\u548c\u4eab\u4e50\u60c5\u611f\u4ef7\u503c(HSV)\u3002", "result": "\u53ea\u6709SSV\u5bf9\u6b21\u65e5\u56de\u62a5\u5177\u6709\u9ad8\u5ea6\u53ef\u4fe1\u7684\u6b63\u5411\u5f71\u54cd\uff0cSOV\u548cAUT\u663e\u793a\u4e2d\u7b49\u53ef\u9760\u7684\u6b63\u5411\u5173\u8054\uff0cHSV\u65e0\u663e\u8457\u9884\u6d4b\u6548\u679c\u3002SSV\u4e3b\u5bfc\u77ed\u671f\u5b9a\u4ef7\u52a8\u6001\uff0cSOV\u548cAUT\u4f5c\u4e3a\u957f\u671f\u4ef7\u503c\u7684\u7ed3\u6784\u951a\u70b9\u3002", "conclusion": "\u6bd4\u7279\u5e01\u662f\u4e00\u4e2a\u53cc\u5c42\u7ea7\u71b5\u8c03\u8282\u793e\u4f1a\u6280\u672f\u751f\u6001\u7cfb\u7edf\uff0c\u7814\u7a76\u63a8\u8fdb\u4e86\u8de8\u5b66\u79d1\u4ef7\u503c\u7406\u8bba\uff0c\u4e3a\u6570\u5b57\u8d44\u4ea7\u4f30\u503c\u3001\u6295\u8d44\u6559\u80b2\u548c\u975e\u73b0\u91d1\u6d41\u6570\u5b57\u8d44\u4ea7\u7684\u71b5\u52a8\u6001\u7814\u7a76\u63d0\u4f9b\u542f\u793a\u3002"}}
{"id": "2511.17774", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17774", "abs": "https://arxiv.org/abs/2511.17774", "authors": ["Salma Mozaffari", "Daniel Ruan", "William van den Bogert", "Nima Fazeli", "Sigrid Adriaenssens", "Arash Adel"], "title": "Learning Diffusion Policies for Robotic Manipulation of Timber Joinery under Fabrication Uncertainty", "comment": null, "summary": "Construction uncertainties such as fabrication inaccuracies and material imperfections pose a significant challenge to contact-rich robotic manipulation by hindering precise and robust assembly. In this paper, we explore the performance and robustness of diffusion policy learning as a promising solution for contact-sensitive robotic assembly at construction scale, using timber mortise and tenon joints as a case study. A two-phase study is conducted: first, to evaluate policy performance and applicability; second, to assess robustness in handling fabrication uncertainties simulated as randomized perturbations to the mortise position. The best-performing policy achieved a total average success rate of 75% with perturbations up to 10 mm, including 100% success in unperturbed cases. The results demonstrate the potential of sensory-motor diffusion policies to generalize to a wide range of complex, contact-rich assembly tasks across construction and manufacturing, advancing robotic construction under uncertainty and contributing to safer, more efficient building practices.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u6269\u6563\u7b56\u7565\u5b66\u4e60\u5728\u5904\u7406\u5efa\u7b51\u5c3a\u5ea6\u63a5\u89e6\u654f\u611f\u673a\u5668\u4eba\u88c5\u914d\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4ee5\u6728\u5de5\u69ab\u536f\u63a5\u5934\u4e3a\u6848\u4f8b\uff0c\u5728\u5b58\u5728\u5236\u9020\u4e0d\u786e\u5b9a\u6027\u65f6\u8fbe\u523075%\u7684\u5e73\u5747\u6210\u529f\u7387\u3002", "motivation": "\u5efa\u7b51\u4e2d\u7684\u5236\u9020\u8bef\u5dee\u548c\u6750\u6599\u7f3a\u9677\u7b49\u4e0d\u786e\u5b9a\u6027\u7ed9\u63a5\u89e6\u5bc6\u96c6\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u5e26\u6765\u6311\u6218\uff0c\u963b\u788d\u4e86\u7cbe\u786e\u548c\u7a33\u5065\u7684\u88c5\u914d\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7814\u7a76\uff1a\u9996\u5148\u8bc4\u4f30\u7b56\u7565\u6027\u80fd\u548c\u9002\u7528\u6027\uff0c\u5176\u6b21\u8bc4\u4f30\u5904\u7406\u5236\u9020\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u968f\u673a\u6270\u52a8\u69ab\u773c\u4f4d\u7f6e\u6765\u6a21\u62df\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u6700\u4f73\u7b56\u7565\u5728\u9ad8\u8fbe10\u6beb\u7c73\u6270\u52a8\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e8675%\u7684\u603b\u5e73\u5747\u6210\u529f\u7387\uff0c\u5728\u65e0\u6270\u52a8\u60c5\u51b5\u4e0b\u8fbe\u5230100%\u6210\u529f\u7387\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u611f\u89c9\u8fd0\u52a8\u6269\u6563\u7b56\u7565\u6709\u6f5c\u529b\u63a8\u5e7f\u5230\u5efa\u7b51\u548c\u5236\u9020\u4e1a\u4e2d\u5404\u79cd\u590d\u6742\u7684\u63a5\u89e6\u5bc6\u96c6\u88c5\u914d\u4efb\u52a1\uff0c\u63a8\u52a8\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u673a\u5668\u4eba\u5efa\u9020\uff0c\u4fc3\u8fdb\u66f4\u5b89\u5168\u3001\u66f4\u9ad8\u6548\u7684\u5efa\u7b51\u5b9e\u8df5\u3002"}}
{"id": "2511.17729", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17729", "abs": "https://arxiv.org/abs/2511.17729", "authors": ["Yang Zhou", "Mingyu Zhao", "Zhenting Wang", "Difei Gu", "Bangwei Guo", "Ruosong Ye", "Ligong Han", "Can Jin", "Dimitris N. Metaxas"], "title": "M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark", "comment": null, "summary": "We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resources across steps. We introduce a similarity-driven alignment that serializes each tool call, embeds signatures with a sentence encoder, and performs similarity-bucketed Hungarian matching to obtain auditable one-to-one correspondences. On top of this alignment, we report interpretable metrics that decouple semantic fidelity from workflow consistency. The benchmark spans 28 servers with 231 tools, and provides standardized trajectories curated through an Executor & Judge pipeline with human verification; an auxiliary four large language models (LLMs) judge ensemble reports end-task Task Completion and information grounding. Evaluations of representative state-of-the-art Multimodal LLMs (MLLMs) reveal persistent gaps in multimodal MCP tool use, particularly in argument fidelity and structure consistency, underscoring the need for methods that jointly reason over images, text, and tool graphs. Our Benchmark's anonymous repository is at https://github.com/EtaYang10th/Open-M3-Bench", "AI": {"tldr": "M^3-Bench\u662f\u9996\u4e2a\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u8bc4\u4f30\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u9700\u8981\u89c6\u89c9\u57fa\u7840\u548c\u6587\u672c\u63a8\u7406\u7684\u591a\u8df3\u591a\u7ebf\u7a0b\u5de5\u4f5c\u6d41\uff0c\u5305\u542b28\u4e2a\u670d\u52a1\u5668\u548c231\u4e2a\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u7684\u8bc4\u4f30\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9700\u8981\u8de8\u5de5\u5177\u4f9d\u8d56\u548c\u4e2d\u95f4\u8d44\u6e90\u6301\u4e45\u5316\u7684\u590d\u6742\u5de5\u4f5c\u6d41\u3002", "method": "\u91c7\u7528\u76f8\u4f3c\u6027\u9a71\u52a8\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5e8f\u5217\u5316\u5de5\u5177\u8c03\u7528\uff0c\u4f7f\u7528\u53e5\u5b50\u7f16\u7801\u5668\u5d4c\u5165\u7b7e\u540d\uff0c\u5e76\u901a\u8fc7\u76f8\u4f3c\u6027\u5206\u6876\u7684\u5308\u7259\u5229\u5339\u914d\u83b7\u5f97\u53ef\u5ba1\u8ba1\u7684\u4e00\u5bf9\u4e00\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u8bc4\u4f30\u4ee3\u8868\u6027\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u663e\u793a\u5728\u591a\u6a21\u6001MCP\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u53c2\u6570\u4fdd\u771f\u5ea6\u548c\u7ed3\u6784\u4e00\u81f4\u6027\u65b9\u9762\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8054\u5408\u63a8\u7406\u56fe\u50cf\u3001\u6587\u672c\u548c\u5de5\u5177\u56fe\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u7684\u6027\u80fd\u3002"}}
{"id": "2511.18081", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18081", "abs": "https://arxiv.org/abs/2511.18081", "authors": ["Zijing Li"], "title": "Sparse Broad Learning System via Sequential Threshold Least-Squares for Nonlinear System Identification under Noise", "comment": null, "summary": "The Broad Learning System (BLS) has gained significant attention for its computational efficiency and less network parameters compared to deep learning structures. However, the standard BLS relies on the pseudoinverse solution, which minimizes the mean square error with $L_2$-norm but lacks robustness against sensor noise and outliers common in industrial environments. To address this limitation, this paper proposes a novel Sparse Broad Learning System (S-BLS) framework. Instead of the traditional ridge regression, we incorporate the Sequential Threshold Least-Squares (STLS) algorithm -- originally utilized in the sparse identification of nonlinear dynamics (SINDy) -- into the output weight learning process of BLS. By iteratively thresholding small coefficients, the proposed method promotes sparsity in the output weights, effectively filtering out noise components while maintaining modeling accuracy. This approach falls under the category of sparse regression and is particularly suitable for noisy environments. Experimental results on a numerical nonlinear system and a noisy Continuous Stirred Tank Reactor (CSTR) benchmark demonstrate that the proposed method is effective and achieves superior robustness compared to standard BLS.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7a00\u758f\u5e7f\u5ea6\u5b66\u4e60\u7cfb\u7edf(S-BLS)\uff0c\u901a\u8fc7\u5c06\u5e8f\u5217\u9608\u503c\u6700\u5c0f\u4e8c\u4e58\u6cd5(STLS)\u5f15\u5165BLS\u7684\u8f93\u51fa\u6743\u91cd\u5b66\u4e60\u8fc7\u7a0b\uff0c\u63d0\u5347\u5bf9\u566a\u58f0\u548c\u5f02\u5e38\u503c\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u6807\u51c6BLS\u4f9d\u8d56\u4f2a\u9006\u89e3\uff0c\u4f7f\u7528L2\u8303\u6570\u6700\u5c0f\u5316\u5747\u65b9\u8bef\u5dee\uff0c\u4f46\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7f3a\u4e4f\u5bf9\u4f20\u611f\u5668\u566a\u58f0\u548c\u5f02\u5e38\u503c\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5c06\u539f\u672c\u7528\u4e8e\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7a00\u758f\u8bc6\u522b\u7684STLS\u7b97\u6cd5\u6574\u5408\u5230BLS\u7684\u8f93\u51fa\u6743\u91cd\u5b66\u4e60\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u8fed\u4ee3\u9608\u503c\u5316\u5c0f\u7cfb\u6570\u6765\u4fc3\u8fdb\u8f93\u51fa\u6743\u91cd\u7684\u7a00\u758f\u6027\u3002", "result": "\u5728\u6570\u503c\u975e\u7ebf\u6027\u7cfb\u7edf\u548c\u542b\u566a\u58f0\u8fde\u7eed\u6405\u62cc\u91dc\u53cd\u5e94\u5668\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u6bd4\u6807\u51c6BLS\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684S-BLS\u6846\u67b6\u901a\u8fc7\u7a00\u758f\u56de\u5f52\u65b9\u6cd5\u6709\u6548\u8fc7\u6ee4\u566a\u58f0\u5206\u91cf\uff0c\u5728\u4fdd\u6301\u5efa\u6a21\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u4e86\u5728\u566a\u58f0\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.18268", "categories": ["cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.18268", "abs": "https://arxiv.org/abs/2511.18268", "authors": ["S M Mehedi Zaman", "Saubhagya Joshi", "Yiyi Wu"], "title": "Privacy Concerns and ChatGPT: Exploring Online Discourse through the Lens of Information Practice on Reddit", "comment": "Accepted as a poster at the iConference, 2026", "summary": "As millions of people use ChatGPT for tasks such as education, writing assistance, and health advice, concerns have grown about how personal prompts and data are stored and used. This study explores how Reddit users collectively negotiate and respond to these privacy concerns. Posts were collected from three major subreddits -- r/Chatgpt, r/privacy, and r/OpenAI -- between November 2022 and May 2025. An iterative keyword search followed by manual screening resulted in a final dataset of 426 posts and 1,900 comments. Using information practice as the theoretical lens, we conducted a qualitative thematic analysis to identify collective practices of risk negotiation, validated with BERTopic topic modeling to ensure thematic saturation. Findings revealed risk signaling, norm-setting, and resignation as dominant discourses, and collective troubleshooting and advocacy for privacy-preserving alternatives as key adaptive practices. Reddit functions as a site of collective sense-making where users surface risks, establish informal norms, and share strategies for mitigating privacy threats, offering insights for AI design and privacy literacy initiatives.", "AI": {"tldr": "Reddit\u7528\u6237\u901a\u8fc7\u96c6\u4f53\u534f\u5546\u5e94\u5bf9ChatGPT\u9690\u79c1\u62c5\u5fe7\uff0c\u7814\u7a76\u53d1\u73b0\u98ce\u9669\u4fe1\u53f7\u4f20\u9012\u3001\u89c4\u8303\u5236\u5b9a\u548c\u65e0\u5948\u63a5\u53d7\u662f\u4e3b\u8981\u8bdd\u8bed\uff0c\u96c6\u4f53\u6545\u969c\u6392\u9664\u548c\u5021\u5bfc\u9690\u79c1\u4fdd\u62a4\u66ff\u4ee3\u65b9\u6848\u662f\u6838\u5fc3\u9002\u5e94\u5b9e\u8df5\u3002", "motivation": "\u968f\u7740\u6570\u767e\u4e07\u4eba\u4f7f\u7528ChatGPT\u8fdb\u884c\u6559\u80b2\u3001\u5199\u4f5c\u534f\u52a9\u548c\u5065\u5eb7\u54a8\u8be2\u7b49\u4efb\u52a1\uff0c\u4eba\u4eec\u5bf9\u4e2a\u4eba\u63d0\u793a\u548c\u6570\u636e\u5982\u4f55\u5b58\u50a8\u548c\u4f7f\u7528\u7684\u62c5\u5fe7\u65e5\u76ca\u589e\u957f\u3002", "method": "\u4ece\u4e09\u4e2a\u4e3b\u8981subreddit\u6536\u96c62022\u5e7411\u6708\u81f32025\u5e745\u6708\u7684\u5e16\u5b50\uff0c\u901a\u8fc7\u8fed\u4ee3\u5173\u952e\u8bcd\u641c\u7d22\u548c\u624b\u52a8\u7b5b\u9009\u83b7\u5f97426\u4e2a\u5e16\u5b50\u548c1900\u6761\u8bc4\u8bba\uff0c\u4f7f\u7528\u4fe1\u606f\u5b9e\u8df5\u7406\u8bba\u6846\u67b6\u8fdb\u884c\u5b9a\u6027\u4e3b\u9898\u5206\u6790\uff0c\u5e76\u7528BERTopic\u4e3b\u9898\u5efa\u6a21\u9a8c\u8bc1\u4e3b\u9898\u9971\u548c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u98ce\u9669\u4fe1\u53f7\u4f20\u9012\u3001\u89c4\u8303\u5236\u5b9a\u548c\u65e0\u5948\u63a5\u53d7\u662f\u4e3b\u5bfc\u8bdd\u8bed\uff0c\u96c6\u4f53\u6545\u969c\u6392\u9664\u548c\u5021\u5bfc\u9690\u79c1\u4fdd\u62a4\u66ff\u4ee3\u65b9\u6848\u662f\u5173\u952e\u7684\u9002\u5e94\u5b9e\u8df5\u3002Reddit\u4f5c\u4e3a\u96c6\u4f53\u610f\u4e49\u5efa\u6784\u7684\u573a\u6240\uff0c\u7528\u6237\u5728\u6b64\u63ed\u793a\u98ce\u9669\u3001\u5efa\u7acb\u975e\u6b63\u5f0f\u89c4\u8303\u5e76\u5206\u4eab\u9690\u79c1\u5a01\u80c1\u7f13\u89e3\u7b56\u7565\u3002", "conclusion": "Reddit\u4f5c\u4e3a\u96c6\u4f53\u610f\u4e49\u5efa\u6784\u7684\u573a\u6240\uff0c\u7528\u6237\u5728\u6b64\u63ed\u793a\u98ce\u9669\u3001\u5efa\u7acb\u975e\u6b63\u5f0f\u89c4\u8303\u5e76\u5206\u4eab\u9690\u79c1\u5a01\u80c1\u7f13\u89e3\u7b56\u7565\uff0c\u4e3aAI\u8bbe\u8ba1\u548c\u9690\u79c1\u7d20\u517b\u8ba1\u5212\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2511.17777", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17777", "abs": "https://arxiv.org/abs/2511.17777", "authors": ["Ravi Prakash", "Vincent Y. Wang", "Arpit Mishra", "Devi Yuliarti", "Pei Zhong", "Ryan P. McNabb", "Patrick J. Codd", "Leila J. Bridgeman"], "title": "See, Plan, Cut: MPC-Based Autonomous Volumetric Robotic Laser Surgery with OCT Guidance", "comment": "9 pages, 8 figures", "summary": "Robotic laser systems offer the potential for sub-millimeter, non-contact, high-precision tissue resection, yet existing platforms lack volumetric planning and intraoperative feedback. We present RATS (Robot-Assisted Tissue Surgery), an intelligent opto-mechanical, optical coherence tomography (OCT)-guided robotic platform designed for autonomous volumetric soft tissue resection in surgical applications. RATS integrates macro-scale RGB-D imaging, micro-scale OCT, and a fiber-coupled surgical laser, calibrated through a novel multistage alignment pipeline that achieves OCT-to-laser calibration accuracy of 0.161+-0.031mm on tissue phantoms and ex vivo porcine tissue. A super-Gaussian laser-tissue interaction (LTI) model characterizes ablation crater morphology with an average RMSE of 0.231+-0.121mm, outperforming Gaussian baselines. A sampling-based model predictive control (MPC) framework operates directly on OCT voxel data to generate constraint-aware resection trajectories with closed-loop feedback, achieving 0.842mm RMSE and improving intersection-over-union agreement by 64.8% compared to feedforward execution. With OCT, RATS detects subsurface structures and modifies the planner's objective to preserve them, demonstrating clinical feasibility.", "AI": {"tldr": "RATS\u662f\u4e00\u4e2a\u667a\u80fd\u5149\u673a\u68b0\u5e73\u53f0\uff0c\u96c6\u6210OCT\u5f15\u5bfc\u548c\u624b\u672f\u6fc0\u5149\uff0c\u7528\u4e8e\u81ea\u4e3b\u4f53\u79ef\u8f6f\u7ec4\u7ec7\u5207\u9664\uff0c\u901a\u8fc7\u591a\u7ea7\u6821\u51c6\u3001\u6fc0\u5149-\u7ec4\u7ec7\u76f8\u4e92\u4f5c\u7528\u5efa\u6a21\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u624b\u672f\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u6fc0\u5149\u7cfb\u7edf\u7f3a\u4e4f\u4f53\u79ef\u89c4\u5212\u548c\u672f\u4e2d\u53cd\u9988\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8fdb\u884c\u81ea\u4e3b\u4f53\u79ef\u8f6f\u7ec4\u7ec7\u5207\u9664\u7684\u667a\u80fd\u624b\u672f\u5e73\u53f0\u3002", "method": "\u96c6\u6210\u5b8f\u5c3a\u5ea6RGB-D\u6210\u50cf\u3001\u5fae\u5c3a\u5ea6OCT\u548c\u5149\u7ea4\u8026\u5408\u624b\u672f\u6fc0\u5149\uff0c\u91c7\u7528\u591a\u7ea7\u6821\u51c6\u7ba1\u9053\u3001\u8d85\u9ad8\u65af\u6fc0\u5149-\u7ec4\u7ec7\u76f8\u4e92\u4f5c\u7528\u6a21\u578b\u548c\u57fa\u4e8e\u91c7\u6837\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\u3002", "result": "\u5728\u7ec4\u7ec7\u6a21\u578b\u548c\u79bb\u4f53\u732a\u7ec4\u7ec7\u4e0a\u5b9e\u73b0OCT\u5230\u6fc0\u5149\u6821\u51c6\u7cbe\u5ea60.161\u00b10.031mm\uff0c\u6fc0\u5149-\u7ec4\u7ec7\u76f8\u4e92\u4f5c\u7528\u6a21\u578b\u5e73\u5747RMSE\u4e3a0.231\u00b10.121mm\uff0c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\u5b9e\u73b00.842mm RMSE\uff0c\u76f8\u6bd4\u524d\u9988\u6267\u884c\u6539\u8fdbIoU\u4e00\u81f4\u602764.8%\u3002", "conclusion": "RATS\u5e73\u53f0\u80fd\u591f\u68c0\u6d4b\u4e9a\u8868\u9762\u7ed3\u6784\u5e76\u4fee\u6539\u89c4\u5212\u76ee\u6807\u4ee5\u4fdd\u62a4\u8fd9\u4e9b\u7ed3\u6784\uff0c\u5c55\u793a\u4e86\u4e34\u5e8a\u53ef\u884c\u6027\u3002"}}
{"id": "2511.17743", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17743", "abs": "https://arxiv.org/abs/2511.17743", "authors": ["Haytham Younus", "Sohag Kabir", "Felician Campean", "Pascal Bonnaud", "David Delaux"], "title": "AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions", "comment": "This manuscript is based on research undertaken by our doctoral student at the University of Bradford. The associated PhD thesis has been formally submitted to the University and is currently awaiting final examination. The review article is being shared on arXiv to make the review accessible to the research community while the thesis examination process is ongoing", "summary": "This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in complexity, conventional FMEA methods, largely manual, document-centric, and expert-dependent, have become increasingly inadequate for addressing the demands of modern systems engineering. We examine how techniques from Artificial Intelligence (AI), including machine learning and natural language processing, can transform FMEA into a more dynamic, data-driven, intelligent, and model-integrated process by automating failure prediction, prioritisation, and knowledge extraction from operational data. In parallel, we explore the role of ontologies in formalising system knowledge, supporting semantic reasoning, improving traceability, and enabling cross-domain interoperability. The review also synthesises emerging hybrid approaches, such as ontology-informed learning and large language model integration, which further enhance explainability and automation. These developments are discussed within the broader context of Model-Based Systems Engineering (MBSE) and function modelling, showing how AI and ontologies can support more adaptive and resilient FMEA workflows. We critically analyse a range of tools, case studies, and integration strategies, while identifying key challenges related to data quality, explainability, standardisation, and interdisciplinary adoption. By leveraging AI, systems engineering, and knowledge representation using ontologies, this review offers a structured roadmap for embedding FMEA within intelligent, knowledge-rich engineering environments.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5c06\u4f20\u7edfFMEA\u8f6c\u53d8\u4e3a\u667a\u80fd\u5316\u3001\u6570\u636e\u9a71\u52a8\u548c\u8bed\u4e49\u4e30\u5bcc\u8fc7\u7a0b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u63a2\u8ba8\u4e86AI\u6280\u672f\u548c\u672c\u4f53\u8bba\u5728\u63d0\u5347FMEA\u81ea\u52a8\u5316\u3001\u52a8\u6001\u6027\u548c\u96c6\u6210\u6027\u65b9\u9762\u7684\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5de5\u7a0b\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u4f20\u7edfFMEA\u65b9\u6cd5\uff08\u624b\u52a8\u3001\u6587\u6863\u4e2d\u5fc3\u3001\u4f9d\u8d56\u4e13\u5bb6\uff09\u5df2\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3\u7cfb\u7edf\u5de5\u7a0b\u9700\u6c42\uff0c\u9700\u8981\u66f4\u667a\u80fd\u5316\u7684\u65b9\u6cd5\u6765\u5904\u7406\u6545\u969c\u9884\u6d4b\u548c\u77e5\u8bc6\u63d0\u53d6\u3002", "method": "\u7ed3\u5408\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff08\u673a\u5668\u5b66\u4e60\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff09\u548c\u672c\u4f53\u8bba\uff0c\u5b9e\u73b0FMEA\u7684\u81ea\u52a8\u5316\u6545\u969c\u9884\u6d4b\u3001\u4f18\u5148\u7ea7\u6392\u5e8f\u548c\u77e5\u8bc6\u63d0\u53d6\uff0c\u5e76\u63a2\u8ba8\u672c\u4f53\u4fe1\u606f\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u7b49\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u5f00\u53d1\u51fa\u80fd\u591f\u652f\u6301\u8bed\u4e49\u63a8\u7406\u3001\u63d0\u9ad8\u53ef\u8ffd\u6eaf\u6027\u548c\u8de8\u9886\u57df\u4e92\u64cd\u4f5c\u6027\u7684\u667a\u80fdFMEA\u6d41\u7a0b\uff0c\u5728MBSE\u548c\u529f\u80fd\u5efa\u6a21\u80cc\u666f\u4e0b\u5b9e\u73b0\u66f4\u81ea\u9002\u5e94\u548c\u5f39\u6027\u7684\u5de5\u4f5c\u6d41\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408AI\u3001\u7cfb\u7edf\u5de5\u7a0b\u548c\u672c\u4f53\u77e5\u8bc6\u8868\u793a\uff0c\u4e3a\u5c06FMEA\u5d4c\u5165\u667a\u80fd\u3001\u77e5\u8bc6\u4e30\u5bcc\u7684\u5de5\u7a0b\u73af\u5883\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8def\u7ebf\u56fe\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u6570\u636e\u8d28\u91cf\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6807\u51c6\u5316\u548c\u8de8\u5b66\u79d1\u91c7\u7528\u7b49\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2511.18148", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18148", "abs": "https://arxiv.org/abs/2511.18148", "authors": ["Shixiao Liang", "Chengyuan Ma", "Pei Li", "Haotian Shi", "Jiaxi Liu", "Hang Zhou", "Keke Long", "Bofeng Cao", "Todd Szymkowski", "Xiaopeng Li"], "title": "Real-Time Lane-Level Crash Detection on Freeways Using Sparse Telematics Data", "comment": "15 pages,6 figures", "summary": "Real-time traffic crash detection is critical in intelligent transportation systems because traditional crash notifications often suffer delays and lack specific, lane-level location information, which can lead to safety risks and economic losses. This paper proposes a real-time, lane-level crash detection approach for freeways that only leverages sparse telematics trajectory data. In the offline stage, the historical trajectories are discretized into spatial cells using vector cross-product techniques, and then used to estimate a vehicle intention distribution and select an alert threshold by maximizing the F1-score based on official crash reports. In the online stage, incoming telematics records are mapped to these cells and scored for three modules: transition anomalies, speed deviations, and lateral maneuver risks, with scores accumulated into a cell-specific risk map. When any cell's risk exceeds the alert threshold, the system issues a prompt warning. Relying solely on telematics data, this real-time and low-cost solution is evaluated on a Wisconsin dataset and validated against official crash reports, achieving a 75% crash identification rate with accurate lane-level localization, an overall accuracy of 96%, an F1-score of 0.84, and a non-crash-to-crash misclassification rate of only 0.6%, while also detecting 13% of crashes more than 3 minutes before the recorded crash time.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u9065\u6d4b\u8f68\u8ff9\u6570\u636e\u7684\u5b9e\u65f6\u8f66\u9053\u7ea7\u9ad8\u901f\u516c\u8def\u4e8b\u6545\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u8bad\u7ec3\u548c\u5728\u7ebf\u68c0\u6d4b\u5b9e\u73b0\u9ad8\u6548\u4e8b\u6545\u9884\u8b66\u3002", "motivation": "\u4f20\u7edf\u4e8b\u6545\u901a\u77e5\u5b58\u5728\u5ef6\u8fdf\u4e14\u7f3a\u4e4f\u8f66\u9053\u7ea7\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5bfc\u81f4\u5b89\u5168\u98ce\u9669\u548c\u7ecf\u6d4e\u635f\u5931\uff0c\u9700\u8981\u5b9e\u65f6\u3001\u7cbe\u786e\u7684\u4e8b\u6545\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u79bb\u7ebf\u9636\u6bb5\uff1a\u4f7f\u7528\u5411\u91cf\u53c9\u79ef\u6280\u672f\u5c06\u5386\u53f2\u8f68\u8ff9\u79bb\u6563\u5316\u4e3a\u7a7a\u95f4\u5355\u5143\uff0c\u4f30\u8ba1\u8f66\u8f86\u610f\u56fe\u5206\u5e03\u5e76\u57fa\u4e8e\u5b98\u65b9\u4e8b\u6545\u62a5\u544a\u4f18\u5316\u8b66\u62a5\u9608\u503c\u3002\u5728\u7ebf\u9636\u6bb5\uff1a\u5bf9\u9065\u6d4b\u8bb0\u5f55\u8fdb\u884c\u4e09\u4e2a\u6a21\u5757\u8bc4\u5206\uff08\u8f6c\u79fb\u5f02\u5e38\u3001\u901f\u5ea6\u504f\u5dee\u3001\u6a2a\u5411\u64cd\u4f5c\u98ce\u9669\uff09\uff0c\u751f\u6210\u5355\u5143\u7279\u5b9a\u98ce\u9669\u56fe\uff0c\u5f53\u98ce\u9669\u8d85\u8fc7\u9608\u503c\u65f6\u53d1\u51fa\u8b66\u544a\u3002", "result": "\u5728\u5a01\u65af\u5eb7\u661f\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8fbe\u523075%\u7684\u4e8b\u6545\u8bc6\u522b\u7387\uff0c\u51c6\u786e\u8f66\u9053\u7ea7\u5b9a\u4f4d\uff0c\u6574\u4f53\u51c6\u786e\u738796%\uff0cF1\u5206\u65700.84\uff0c\u975e\u4e8b\u6545\u8bef\u5206\u7c7b\u7387\u4ec50.6%\uff0c13%\u7684\u4e8b\u6545\u5728\u8bb0\u5f55\u65f6\u95f4\u524d3\u5206\u949f\u4ee5\u4e0a\u88ab\u68c0\u6d4b\u5230\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ec5\u4f7f\u7528\u9065\u6d4b\u6570\u636e\uff0c\u63d0\u4f9b\u5b9e\u65f6\u3001\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u6709\u6548\u5b9e\u73b0\u8f66\u9053\u7ea7\u4e8b\u6545\u68c0\u6d4b\u548c\u65e9\u671f\u9884\u8b66\u3002"}}
{"id": "2511.18874", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA", "cs.RO", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.18874", "abs": "https://arxiv.org/abs/2511.18874", "authors": ["Yuzhi Chen", "Yuanchang Xie", "Lei Zhao", "Pan Liu", "Yajie Zou", "Chen Wang"], "title": "GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction", "comment": null, "summary": "Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.", "AI": {"tldr": "\u63d0\u51faGContextFormer\uff0c\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u9ad8\u6e05\u5730\u56fe\u7684\u5168\u5c40\u4e0a\u4e0b\u6587\u611f\u77e5\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u6df7\u5408\u6ce8\u610f\u529b\u673a\u5236\u548c\u7f29\u653e\u52a0\u6027\u805a\u5408\u5b9e\u73b0\u610f\u56fe\u5bf9\u9f50\u7684\u9884\u6d4b", "motivation": "\u73b0\u6709HD\u5730\u56fe\u4f9d\u8d56\u6a21\u578b\u5b58\u5728\u6570\u636e\u83b7\u53d6\u6210\u672c\u9ad8\u3001\u66f4\u65b0\u5ef6\u8fdf\u548c\u8f93\u5165\u635f\u574f\u6613\u5bfc\u81f4\u9884\u6d4b\u5931\u8d25\u7684\u95ee\u9898\uff1b\u65e0\u5730\u56fe\u65b9\u6cd5\u7f3a\u4e4f\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u6ce8\u610f\u529b\u673a\u5236\u8fc7\u5ea6\u653e\u5927\u76f4\u7ebf\u6a21\u5f0f\u800c\u6291\u5236\u8fc7\u6e21\u6a21\u5f0f\uff0c\u5bfc\u81f4\u8fd0\u52a8-\u610f\u56fe\u4e0d\u5bf9\u9f50", "method": "\u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff1a\u8fd0\u52a8\u611f\u77e5\u7f16\u7801\u5668\u901a\u8fc7\u6709\u754c\u7f29\u653e\u52a0\u6027\u805a\u5408\u6784\u5efa\u573a\u666f\u7ea7\u610f\u56fe\u5148\u9a8c\uff0c\u5728\u5171\u4eab\u5168\u5c40\u4e0a\u4e0b\u6587\u4e2d\u7ec6\u5316\u6bcf\u6a21\u5f0f\u8868\u793a\uff1b\u5206\u5c42\u4ea4\u4e92\u89e3\u7801\u5668\u901a\u8fc7\u53cc\u8def\u5f84\u4ea4\u53c9\u6ce8\u610f\u529b\u5206\u89e3\u793e\u4f1a\u63a8\u7406\uff0c\u6807\u51c6\u8def\u5f84\u786e\u4fdd\u51e0\u4f55\u8986\u76d6\uff0c\u90bb\u5c45\u4e0a\u4e0b\u6587\u589e\u5f3a\u8def\u5f84\u5f3a\u8c03\u663e\u8457\u4ea4\u4e92\uff0c\u95e8\u63a7\u6a21\u5757\u5e73\u8861\u8986\u76d6\u4e0e\u805a\u7126", "result": "\u5728TOD-VT\u6570\u636e\u96c6\u7684\u516b\u4e2a\u9ad8\u901f\u516c\u8def\u531d\u9053\u573a\u666f\u5b9e\u9a8c\u4e2d\uff0cGContextFormer\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u6a21\u578b\uff0c\u76f8\u6bd4\u73b0\u6709transformer\u6a21\u578b\u5728\u9ad8\u901f\u66f2\u7387\u548c\u8fc7\u6e21\u533a\u57df\u5b9e\u73b0\u66f4\u5927\u9c81\u68d2\u6027\u548c\u96c6\u4e2d\u6539\u8fdb", "conclusion": "GContextFormer\u901a\u8fc7\u8fd0\u52a8\u6a21\u5f0f\u533a\u5206\u548c\u90bb\u5c45\u4e0a\u4e0b\u6587\u8c03\u5236\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\uff0c\u6a21\u5757\u5316\u67b6\u6784\u652f\u6301\u8de8\u9886\u57df\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u7684\u6269\u5c55\u6027"}}
{"id": "2511.17669", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17669", "abs": "https://arxiv.org/abs/2511.17669", "authors": ["Ashish", "Aparajita Jaiswal", "Sudip Vhaduri", "Niveditha Nerella", "Shubham Jha"], "title": "Empa: An AI-Powered Virtual Mentor for Developing Global Collaboration Skills in HPC Education", "comment": null, "summary": "High-performance computing (HPC) and parallel computing increasingly rely on global collaboration among diverse teams, yet traditional computing curricula inadequately prepare students for cross-cultural teamwork essential in modern computational research environments. This paper presents Empa, an AI-powered virtual mentor that integrates intercultural collaboration training into undergraduate computing education. Built using large language models and deployed through a progressive web application, Empa guides students through structured activities covering cultural dimensions, communication styles, and conflict resolution that are critical for effective multicultural teamwork. Our system addresses the growing need for culturally competent HPC professionals by helping computing students develop skills to collaborate effectively in international research teams, contribute to global computational projects, and navigate the cultural complexities inherent in distributed computing environments. Pilot preparation for deployment in computing courses demonstrates the feasibility of AI-mediated intercultural training and provides insights into scalable approaches for developing intercultural collaboration skills essential for HPC workforce development.", "AI": {"tldr": "Empa\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u865a\u62df\u5bfc\u5e08\uff0c\u5c06\u8de8\u6587\u5316\u534f\u4f5c\u57f9\u8bad\u6574\u5408\u5230\u672c\u79d1\u8ba1\u7b97\u6559\u80b2\u4e2d\uff0c\u65e8\u5728\u57f9\u517b\u5b66\u751f\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u6240\u9700\u7684\u8de8\u6587\u5316\u56e2\u961f\u5408\u4f5c\u6280\u80fd\u3002", "motivation": "\u4f20\u7edf\u8ba1\u7b97\u8bfe\u7a0b\u672a\u80fd\u5145\u5206\u57f9\u517b\u5b66\u751f\u5e94\u5bf9\u73b0\u4ee3\u8ba1\u7b97\u7814\u7a76\u73af\u5883\u4e2d\u8de8\u6587\u5316\u56e2\u961f\u5408\u4f5c\u7684\u80fd\u529b\uff0c\u800c\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u5e76\u884c\u8ba1\u7b97\u65e5\u76ca\u4f9d\u8d56\u5168\u7403\u591a\u6837\u5316\u56e2\u961f\u7684\u534f\u4f5c\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u6e10\u8fdb\u5f0fWeb\u5e94\u7528\u7a0b\u5e8f\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6d3b\u52a8\u6307\u5bfc\u5b66\u751f\u4e86\u89e3\u6587\u5316\u7ef4\u5ea6\u3001\u6c9f\u901a\u98ce\u683c\u548c\u51b2\u7a81\u89e3\u51b3\u7b49\u5173\u952e\u6280\u80fd\u3002", "result": "\u8bd5\u70b9\u90e8\u7f72\u51c6\u5907\u8bc1\u660e\u4e86AI\u4ecb\u5bfc\u7684\u8de8\u6587\u5316\u57f9\u8bad\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u5f00\u53d1\u9ad8\u6027\u80fd\u8ba1\u7b97\u52b3\u52a8\u529b\u6240\u9700\u7684\u8de8\u6587\u5316\u534f\u4f5c\u6280\u80fd\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u65b9\u6cd5\u3002", "conclusion": "Empa\u7cfb\u7edf\u6ee1\u8db3\u4e86\u57f9\u517b\u5177\u6709\u6587\u5316\u80fd\u529b\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e13\u4e1a\u4eba\u5458\u7684\u8feb\u5207\u9700\u6c42\uff0c\u5e2e\u52a9\u5b66\u751f\u53d1\u5c55\u5728\u56fd\u9645\u7814\u7a76\u56e2\u961f\u4e2d\u6709\u6548\u534f\u4f5c\u7684\u6280\u80fd\u3002"}}
{"id": "2511.17781", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17781", "abs": "https://arxiv.org/abs/2511.17781", "authors": ["Kristy Sakano", "Jianyu An", "Dinesh Manocha", "Huan Xu"], "title": "SAFE-SMART: Safety Analysis and Formal Evaluation using STL Metrics for Autonomous RoboTs", "comment": null, "summary": "We present a novel, regulator-driven approach for post hoc safety evaluation of learning-based, black-box autonomous mobile robots, ensuring ongoing compliance with evolving, human-defined safety rules. In our iterative workflow, human safety requirements are translated by regulators into Signal Temporal Logic (STL) specifications. Rollout traces from the black-box model are externally verified for compliance, yielding quantitative safety metrics, Total Robustness Value (TRV) and Largest Robustness Value (LRV), which measure average and worst-case specification adherence. These metrics inform targeted retraining and iterative improvement by model designers. We apply our method across two different applications: a virtual driving scenario and an autonomous mobile robot navigating a complex environment, and observe statistically significant improvements across both scenarios. In the virtual driving scenario, we see a 177% increase in traces adhering to the simulation speed limit, a 1138% increase in traces minimizing off-road driving, and a 16% increase in traces successfully reaching the goal within the time limit. In the autonomous navigation scenario, there is a 300% increase in traces avoiding sharp turns, a 200% increase in traces reaching the goal within the time limit, and a 49% increase in traces minimizing time spent near obstacles. Finally, we validate our approach on a TurtleBot3 robot in the real world, and demonstrate improved obstacle navigation with safety buffers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76d1\u7ba1\u9a71\u52a8\u7684\u540e\u9a8c\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u5b66\u4e60\u7684\u9ed1\u76d2\u81ea\u4e3b\u79fb\u52a8\u673a\u5668\u4eba\uff0c\u786e\u4fdd\u5176\u7b26\u5408\u4e0d\u65ad\u6f14\u8fdb\u7684\u4eba\u5de5\u5b9a\u4e49\u5b89\u5168\u89c4\u5219\u3002", "motivation": "\u9700\u8981\u786e\u4fdd\u5b66\u4e60\u578b\u9ed1\u76d2\u81ea\u4e3b\u79fb\u52a8\u673a\u5668\u4eba\u80fd\u591f\u6301\u7eed\u7b26\u5408\u4eba\u7c7b\u5b9a\u4e49\u7684\u5b89\u5168\u89c4\u5219\uff0c\u5e76\u5728\u76d1\u7ba1\u6846\u67b6\u4e0b\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\u3002", "method": "\u5c06\u4eba\u7c7b\u5b89\u5168\u9700\u6c42\u8f6c\u5316\u4e3a\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\u89c4\u8303\uff0c\u901a\u8fc7\u5916\u90e8\u9a8c\u8bc1\u9ed1\u76d2\u6a21\u578b\u7684\u8f68\u8ff9\u7b26\u5408\u6027\uff0c\u8ba1\u7b97\u603b\u9c81\u68d2\u6027\u503c\u548c\u6700\u5927\u9c81\u68d2\u6027\u503c\u4f5c\u4e3a\u5b89\u5168\u6307\u6807\uff0c\u6307\u5bfc\u9488\u5bf9\u6027\u91cd\u8bad\u7ec3\u3002", "result": "\u5728\u865a\u62df\u9a7e\u9a76\u573a\u666f\u4e2d\uff1a\u9075\u5b88\u9650\u901f\u8f68\u8ff9\u589e\u52a0177%\uff0c\u51cf\u5c11\u8d8a\u91ce\u9a7e\u9a76\u8f68\u8ff9\u589e\u52a01138%\uff0c\u6309\u65f6\u5230\u8fbe\u76ee\u6807\u8f68\u8ff9\u589e\u52a016%\u3002\u5728\u81ea\u4e3b\u5bfc\u822a\u573a\u666f\u4e2d\uff1a\u907f\u514d\u6025\u8f6c\u5f2f\u8f68\u8ff9\u589e\u52a0300%\uff0c\u6309\u65f6\u5230\u8fbe\u76ee\u6807\u8f68\u8ff9\u589e\u52a0200%\uff0c\u51cf\u5c11\u9760\u8fd1\u969c\u788d\u7269\u65f6\u95f4\u8f68\u8ff9\u589e\u52a049%\u3002\u5728\u771f\u5b9eTurtleBot3\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u6539\u8fdb\u7684\u969c\u788d\u7269\u5bfc\u822a\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u548c\u6539\u8fdb\u9ed1\u76d2\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u5728\u865a\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u5b89\u5168\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.17833", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17833", "abs": "https://arxiv.org/abs/2511.17833", "authors": ["Yunsheng Bai", "Haoxing Ren"], "title": "Learning to Debug: LLM-Organized Knowledge Trees for Solving RTL Assertion Failures", "comment": null, "summary": "Debugging is the dominant cost in modern hardware verification, where assertion failures are among the most frequent and expensive to resolve. While Large Language Models (LLMs) show promise, they often fail to capture the precise, reusable expertise that engineers apply, leading to inaccurate responses. We propose GROVE, a hierarchical knowledge management framework that learns and organizes reusable debugging expertise into an LLM-organized knowledge tree for solving assertion failures. GROVE distills debugging knowledge from prior cases and organizes it into a vertical tree of configurable depth, with each node encoding a concise knowledge item and explicit applicability conditions. During training, GROVE uses a parallel, gradient-free loop where an LLM proposes tree modifications as structured JSON edits by learning from the cases. At test time, a budget-aware iterative zoom is performed to navigate the tree, retrieving a small set of applicable knowledge items that guide a base LLM's hypothesis generation and fix proposals. Evaluated on a suite of assertion-failure cases, GROVE delivers consistent gains in pass@1 and pass@5, demonstrating the value of structured knowledge evolution.", "AI": {"tldr": "GROVE\u662f\u4e00\u4e2a\u5206\u5c42\u77e5\u8bc6\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u53ef\u91cd\u7528\u7684\u8c03\u8bd5\u4e13\u4e1a\u77e5\u8bc6\u7ec4\u7ec7\u6210LLM\u7ba1\u7406\u7684\u77e5\u8bc6\u6811\u6765\u89e3\u51b3\u65ad\u8a00\u5931\u8d25\u95ee\u9898\uff0c\u5728\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u8c03\u8bd5\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u786c\u4ef6\u9a8c\u8bc1\u4e2d\u8c03\u8bd5\u6210\u672c\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u65ad\u8a00\u5931\u8d25\u662f\u6700\u5e38\u89c1\u4e14\u6602\u8d35\u7684\u6545\u969c\u7c7b\u578b\u3002\u73b0\u6709LLM\u65b9\u6cd5\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u5de5\u7a0b\u5e08\u5e94\u7528\u7684\u53ef\u91cd\u7528\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5bfc\u81f4\u54cd\u5e94\u4e0d\u51c6\u786e\u3002", "method": "GROVE\u4ece\u5148\u524d\u6848\u4f8b\u4e2d\u63d0\u70bc\u8c03\u8bd5\u77e5\u8bc6\uff0c\u5c06\u5176\u7ec4\u7ec7\u6210\u53ef\u914d\u7f6e\u6df1\u5ea6\u7684\u5782\u76f4\u77e5\u8bc6\u6811\uff0c\u6bcf\u4e2a\u8282\u70b9\u7f16\u7801\u7b80\u6d01\u77e5\u8bc6\u9879\u548c\u660e\u786e\u9002\u7528\u6761\u4ef6\u3002\u8bad\u7ec3\u65f6\u4f7f\u7528\u5e76\u884c\u3001\u65e0\u68af\u5ea6\u5faa\u73af\uff0cLLM\u901a\u8fc7\u5b66\u4e60\u6848\u4f8b\u63d0\u51fa\u7ed3\u6784\u5316JSON\u7f16\u8f91\u6765\u4fee\u6539\u6811\u7ed3\u6784\u3002\u6d4b\u8bd5\u65f6\u6267\u884c\u9884\u7b97\u611f\u77e5\u7684\u8fed\u4ee3\u7f29\u653e\u6765\u5bfc\u822a\u6811\uff0c\u68c0\u7d22\u5c11\u91cf\u9002\u7528\u77e5\u8bc6\u9879\u6307\u5bfc\u57fa\u7840LLM\u751f\u6210\u5047\u8bbe\u548c\u4fee\u590d\u5efa\u8bae\u3002", "result": "\u5728\u65ad\u8a00\u5931\u8d25\u6848\u4f8b\u5957\u4ef6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cGROVE\u5728pass@1\u548cpass@5\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "GROVE\u8bc1\u660e\u4e86\u7ed3\u6784\u5316\u77e5\u8bc6\u6f14\u5316\u5728\u786c\u4ef6\u8c03\u8bd5\u4e2d\u7684\u4ef7\u503c\uff0c\u901a\u8fc7\u7ec4\u7ec7\u53ef\u91cd\u7528\u4e13\u4e1a\u77e5\u8bc6\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u65ad\u8a00\u5931\u8d25\u8c03\u8bd5\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2511.18154", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18154", "abs": "https://arxiv.org/abs/2511.18154", "authors": ["Le Wang", "Jessica Ye", "Michael Refors", "Oscar Fl\u00e4rdh", "H\u00e5kan Hjalmarsson"], "title": "Optimizing the Driving Profile for Vehicle Mass Estimation", "comment": null, "summary": "Accurate mass estimation is essential for the safe and efficient operation of autonomous heavy-duty vehicles, particularly during transportation missions in unstructured environments such as mining sites, where vehicle mass can vary significantly due to loading and unloading. While prior work has recognized the importance of acceleration profiles for estimation accuracy, the systematic design of driving profiles during transport has not been thoroughly investigated. This paper presents a framework for designing driving profiles to support accurate mass estimation. Based on application-oriented input design, it aims to meet a user-defined accuracy constraint under three optimization objectives: minimum-time, minimum-distance, and maximum accuracy (within a fixed time). It allows time- and distance-dependent bounds on acceleration and velocity, and is based on a Newtonian vehicle dynamics model with actuator dynamics. The optimal profiles are obtained by solving concave optimization problems using a branch-and-bound method, with alternative rank-constrained and semi-definite relaxations also discussed. Theoretical analysis provides insights into the optimal profiles, including feasibility conditions, key ratios between velocity and acceleration bounds, and trade-offs between time- and distance-optimal solutions. The framework is validated through simulations and real-world experiments on a Scania truck with different payloads. Results show that the designed profiles are feasible and effective, enabling accurate mass estimation as part of normal transportation operations without requiring dedicated calibration runs. An additional contribution is a non-causal Wiener filter, with parameters estimated via the Empirical Bayes method, used to filter the accelerometer signal with no phase-lag.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bbe\u8ba1\u9a7e\u9a76\u5256\u9762\u4ee5\u652f\u6301\u7cbe\u786e\u8d28\u91cf\u4f30\u8ba1\u7684\u6846\u67b6\uff0c\u57fa\u4e8e\u5e94\u7528\u5bfc\u5411\u7684\u8f93\u5165\u8bbe\u8ba1\uff0c\u5728\u4e09\u79cd\u4f18\u5316\u76ee\u6807\u4e0b\u6ee1\u8db3\u7528\u6237\u5b9a\u4e49\u7684\u7cbe\u5ea6\u7ea6\u675f\uff1a\u6700\u77ed\u65f6\u95f4\u3001\u6700\u77ed\u8ddd\u79bb\u548c\u6700\u5927\u7cbe\u5ea6\uff08\u5728\u56fa\u5b9a\u65f6\u95f4\u5185\uff09\u3002", "motivation": "\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\uff08\u5982\u77ff\u533a\uff09\u4e2d\uff0c\u91cd\u578b\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u8d28\u91cf\u4f1a\u56e0\u88c5\u5378\u800c\u663e\u8457\u53d8\u5316\uff0c\u7cbe\u786e\u7684\u8d28\u91cf\u4f30\u8ba1\u5bf9\u4e8e\u5b89\u5168\u9ad8\u6548\u8fd0\u884c\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5148\u524d\u5de5\u4f5c\u8ba4\u8bc6\u5230\u52a0\u901f\u5ea6\u5256\u9762\u5bf9\u4e8e\u4f30\u8ba1\u7cbe\u5ea6\u7684\u91cd\u8981\u6027\uff0c\u4f46\u8fd0\u8f93\u8fc7\u7a0b\u4e2d\u9a7e\u9a76\u5256\u9762\u7684\u7cfb\u7edf\u8bbe\u8ba1\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u57fa\u4e8e\u725b\u987f\u8f66\u8f86\u52a8\u529b\u5b66\u6a21\u578b\u548c\u9a71\u52a8\u5668\u52a8\u529b\u5b66\uff0c\u901a\u8fc7\u6c42\u89e3\u51f9\u4f18\u5316\u95ee\u9898\u83b7\u5f97\u6700\u4f18\u5256\u9762\uff0c\u4f7f\u7528\u5206\u652f\u5b9a\u754c\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u66ff\u4ee3\u7684\u79e9\u7ea6\u675f\u548c\u534a\u5b9a\u677e\u5f1b\u65b9\u6cd5\u3002\u8fd8\u5305\u62ec\u4e00\u4e2a\u65e0\u56e0\u679c\u7ef4\u7eb3\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u7ecf\u9a8c\u8d1d\u53f6\u65af\u65b9\u6cd5\u4f30\u8ba1\u53c2\u6570\u6765\u6ee4\u6ce2\u52a0\u901f\u5ea6\u8ba1\u4fe1\u53f7\u3002", "result": "\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\uff0c\u8bbe\u8ba1\u7684\u5256\u9762\u80fd\u591f\u5728\u4e0d\u9700\u4e13\u7528\u6821\u51c6\u8fd0\u884c\u7684\u60c5\u51b5\u4e0b\uff0c\u4f5c\u4e3a\u6b63\u5e38\u8fd0\u8f93\u64cd\u4f5c\u7684\u4e00\u90e8\u5206\u5b9e\u73b0\u7cbe\u786e\u8d28\u91cf\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u8bbe\u8ba1\u51fa\u53ef\u884c\u4e14\u6709\u6548\u7684\u9a7e\u9a76\u5256\u9762\uff0c\u652f\u6301\u7cbe\u786e\u8d28\u91cf\u4f30\u8ba1\uff0c\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u5bf9\u6700\u4f18\u5256\u9762\u7684\u6df1\u5165\u7406\u89e3\uff0c\u5305\u62ec\u53ef\u884c\u6027\u6761\u4ef6\u3001\u901f\u5ea6\u4e0e\u52a0\u901f\u5ea6\u8fb9\u754c\u7684\u5173\u952e\u6bd4\u7387\uff0c\u4ee5\u53ca\u65f6\u95f4\u6700\u4f18\u548c\u8ddd\u79bb\u6700\u4f18\u89e3\u4e4b\u95f4\u7684\u6743\u8861\u3002"}}
{"id": "2511.17678", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.17678", "abs": "https://arxiv.org/abs/2511.17678", "authors": ["Ingo Siegert", "Jan Nehring", "Aranxa M\u00e1rquez Ampudia", "Matthias Busch", "Stefan Hillmann"], "title": "Chatbots to strengthen democracy: An interdisciplinary seminar to train identifying argumentation techniques of science denial", "comment": "6 pages, 4 figures", "summary": "In recent times, discussions on social media platforms have increasingly come under scrutiny due to the proliferation of science denial and fake news. Traditional solutions, such as regulatory actions, have been implemented to mitigate the spread of misinformation; however, these measures alone are not sufficient. To complement these efforts, educational approaches are becoming essential in empowering users to critically engage with misinformation. Conversation training, through serious games or personalized methods, has emerged as a promising strategy to help users handle science denial and toxic conversation tactics. This paper suggests an interdisciplinary seminar to explore the suitability of Large Language Models (LLMs) acting as a persona of a science denier to support people in identifying misinformation and improving resilience against toxic interactions. In the seminar, groups of four to five students will develop an AI-based chatbot that enables realistic interactions with science-denial argumentation structures. The task involves planning the setting, integrating a Large Language Model to facilitate natural dialogues, implementing the chatbot using the RASA framework, and evaluating the outcomes in a user study. It is crucial that users understand what they need to do during the interaction, how to conclude it, and how the relevant information is conveyed. The seminar does not aim to develop chatbots for practicing debunking but serves to teach AI technologies and test the feasibility of this idea for future applications. The chatbot seminar is conducted as a hybrid, parallel master's module at the participating educational institutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u8de8\u5b66\u79d1\u7814\u8ba8\u4f1a\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u521b\u5efa\u79d1\u5b66\u5426\u8ba4\u8005\u89d2\u8272\u804a\u5929\u673a\u5668\u4eba\uff0c\u5e2e\u52a9\u5b66\u751f\u8bc6\u522b\u9519\u8bef\u4fe1\u606f\u548c\u589e\u5f3a\u5bf9\u6709\u6bd2\u4e92\u52a8\u7684\u62b5\u6297\u529b\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u79d1\u5b66\u5426\u8ba4\u548c\u865a\u5047\u65b0\u95fb\u6cdb\u6ee5\uff0c\u4f20\u7edf\u76d1\u7ba1\u63aa\u65bd\u4e0d\u8db3\uff0c\u9700\u8981\u901a\u8fc7\u6559\u80b2\u65b9\u6cd5\u589e\u5f3a\u7528\u6237\u6279\u5224\u6027\u601d\u7ef4\u80fd\u529b\u3002", "method": "4-5\u540d\u5b66\u751f\u5c0f\u7ec4\u5f00\u53d1\u57fa\u4e8eAI\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u4f7f\u7528RASA\u6846\u67b6\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u521b\u5efa\u4e0e\u79d1\u5b66\u5426\u8ba4\u8bba\u8bc1\u7ed3\u6784\u7684\u771f\u5b9e\u4e92\u52a8\u3002", "result": "\u7814\u8ba8\u4f1a\u4f5c\u4e3a\u6df7\u5408\u5f0f\u5e76\u884c\u7855\u58eb\u6a21\u5757\u5b9e\u65bd\uff0c\u65e8\u5728\u6559\u6388AI\u6280\u672f\u5e76\u6d4b\u8bd5\u8be5\u60f3\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u7814\u8ba8\u4f1a\u4e0d\u662f\u5f00\u53d1\u8f9f\u8c23\u7ec3\u4e60\u804a\u5929\u673a\u5668\u4eba\uff0c\u800c\u662f\u901a\u8fc7\u5b9e\u8df5\u6559\u5b66\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u6297\u9519\u8bef\u4fe1\u606f\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2511.17798", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17798", "abs": "https://arxiv.org/abs/2511.17798", "authors": ["Francesco D'Orazio", "Sepehr Samavi", "Xintong Du", "Siqi Zhou", "Giuseppe Oriolo", "Angela P. Schoellig"], "title": "SM$^2$ITH: Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control", "comment": null, "summary": "Mobile manipulators are designed to perform complex sequences of navigation and manipulation tasks in human-centered environments. While recent optimization-based methods such as Hierarchical Task Model Predictive Control (HTMPC) enable efficient multitask execution with strict task priorities, they have so far been applied mainly to static or structured scenarios. Extending these approaches to dynamic human-centered environments requires predictive models that capture how humans react to the actions of the robot. This work introduces Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control (SM$^2$ITH), a unified framework that combines HTMPC with interactive human motion prediction through bilevel optimization that jointly accounts for robot and human dynamics. The framework is validated on two different mobile manipulators, the Stretch 3 and the Ridgeback-UR10, across three experimental settings: (i) delivery tasks with different navigation and manipulation priorities, (ii) sequential pick-and-place tasks with different human motion prediction models, and (iii) interactions involving adversarial human behavior. Our results highlight how interactive prediction enables safe and efficient coordination, outperforming baselines that rely on weighted objectives or open-loop human models.", "AI": {"tldr": "SM\u00b2ITH\u6846\u67b6\u7ed3\u5408\u5206\u5c42\u4efb\u52a1\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u4e0e\u4ea4\u4e92\u5f0f\u4eba\u4f53\u8fd0\u52a8\u9884\u6d4b\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u5b9e\u73b0\u79fb\u52a8\u673a\u5668\u4eba\u5728\u52a8\u6001\u4eba\u673a\u73af\u5883\u4e2d\u7684\u5b89\u5168\u9ad8\u6548\u534f\u8c03\u3002", "motivation": "\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u5e94\u7528\u4e8e\u9759\u6001\u6216\u7ed3\u6784\u5316\u573a\u666f\uff0c\u9700\u8981\u6269\u5c55\u5230\u52a8\u6001\u4eba\u673a\u73af\u5883\uff0c\u8fd9\u8981\u6c42\u9884\u6d4b\u6a21\u578b\u80fd\u591f\u6355\u6349\u4eba\u7c7b\u5bf9\u673a\u5668\u4eba\u884c\u4e3a\u7684\u53cd\u5e94\u3002", "method": "\u63d0\u51faSM\u00b2ITH\u6846\u67b6\uff0c\u5c06HTMPC\u4e0e\u4ea4\u4e92\u5f0f\u4eba\u4f53\u8fd0\u52a8\u9884\u6d4b\u7ed3\u5408\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u540c\u65f6\u8003\u8651\u673a\u5668\u4eba\u548c\u4eba\u7c7b\u52a8\u529b\u5b66\u3002", "result": "\u5728\u4e24\u4e2a\u79fb\u52a8\u673a\u68b0\u81c2\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u5728\u9012\u9001\u4efb\u52a1\u3001\u987a\u5e8f\u53d6\u653e\u4efb\u52a1\u548c\u5bf9\u6297\u6027\u4eba\u7c7b\u884c\u4e3a\u4ea4\u4e92\u4e2d\uff0c\u4ea4\u4e92\u5f0f\u9884\u6d4b\u5b9e\u73b0\u4e86\u5b89\u5168\u9ad8\u6548\u7684\u534f\u8c03\uff0c\u4f18\u4e8e\u57fa\u4e8e\u52a0\u6743\u76ee\u6807\u6216\u5f00\u73af\u4eba\u7c7b\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u4ea4\u4e92\u5f0f\u9884\u6d4b\u80fd\u591f\u5b9e\u73b0\u5b89\u5168\u9ad8\u6548\u7684\u534f\u8c03\uff0c\u5728\u52a8\u6001\u4eba\u673a\u73af\u5883\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2511.17855", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17855", "abs": "https://arxiv.org/abs/2511.17855", "authors": ["Jordan Abi Nader", "David Lee", "Nathaniel Dennler", "Andreea Bobu"], "title": "QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents", "comment": null, "summary": "Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduce QuickLAP: Quick Language-Action Preference learning, a Bayesian framework that fuses physical and language feedback to infer reward functions in real time. Our key insight is to treat language as a probabilistic observation over the user's latent preferences, clarifying which reward features matter and how physical corrections should be interpreted. QuickLAP uses Large Language Models (LLMs) to extract reward feature attention masks and preference shifts from free-form utterances, which it integrates with physical feedback in a closed-form update rule. This enables fast, real-time, and robust reward learning that handles ambiguous feedback. In a semi-autonomous driving simulator, QuickLAP reduces reward learning error by over 70% compared to physical-only and heuristic multimodal baselines. A 15-participant user study further validates our approach: participants found QuickLAP significantly more understandable and collaborative, and preferred its learned behavior over baselines. Code is available at https://github.com/MIT-CLEAR-Lab/QuickLAP.", "AI": {"tldr": "QuickLAP\u662f\u4e00\u4e2a\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u878d\u5408\u7269\u7406\u548c\u8bed\u8a00\u53cd\u9988\u6765\u5b9e\u65f6\u63a8\u65ad\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7LLM\u63d0\u53d6\u5956\u52b1\u7279\u5f81\u6ce8\u610f\u529b\u63a9\u7801\u548c\u504f\u597d\u8f6c\u79fb\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u6a21\u62df\u5668\u4e2d\u6bd4\u4ec5\u7269\u7406\u53cd\u9988\u548c\u542f\u53d1\u5f0f\u591a\u6a21\u6001\u57fa\u7ebf\u51cf\u5c1170%\u4ee5\u4e0a\u7684\u5956\u52b1\u5b66\u4e60\u8bef\u5dee\u3002", "motivation": "\u673a\u5668\u4eba\u9700\u8981\u540c\u65f6\u4ece\u4eba\u7c7b\u7684\u884c\u4e3a\u548c\u8bed\u8a00\u4e2d\u5b66\u4e60\uff0c\u4f46\u5355\u4e00\u6a21\u6001\u5f80\u5f80\u4e0d\u5b8c\u6574\uff1a\u7269\u7406\u4fee\u6b63\u6709\u57fa\u7840\u4f46\u610f\u56fe\u6a21\u7cca\uff0c\u8bed\u8a00\u8868\u8fbe\u9ad8\u7ea7\u76ee\u6807\u4f46\u7f3a\u4e4f\u7269\u7406\u57fa\u7840\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u6846\u67b6\u5c06\u8bed\u8a00\u89c6\u4e3a\u5bf9\u7528\u6237\u6f5c\u5728\u504f\u597d\u7684\u6982\u7387\u89c2\u5bdf\uff0c\u5229\u7528LLM\u4ece\u81ea\u7531\u5f62\u5f0f\u8bdd\u8bed\u4e2d\u63d0\u53d6\u5956\u52b1\u7279\u5f81\u6ce8\u610f\u529b\u63a9\u7801\u548c\u504f\u597d\u8f6c\u79fb\uff0c\u5e76\u4e0e\u7269\u7406\u53cd\u9988\u96c6\u6210\u5230\u95ed\u5f0f\u66f4\u65b0\u89c4\u5219\u4e2d\u3002", "result": "\u5728\u534a\u81ea\u52a8\u9a7e\u9a76\u6a21\u62df\u5668\u4e2d\uff0cQuickLAP\u76f8\u6bd4\u4ec5\u7269\u7406\u53cd\u9988\u548c\u542f\u53d1\u5f0f\u591a\u6a21\u6001\u57fa\u7ebf\uff0c\u5956\u52b1\u5b66\u4e60\u8bef\u5dee\u51cf\u5c11\u4e8670%\u4ee5\u4e0a\u300215\u4eba\u7528\u6237\u7814\u7a76\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u66f4\u6613\u7406\u89e3\u548c\u534f\u4f5c\uff0c\u7528\u6237\u66f4\u559c\u6b22\u5176\u5b66\u4e60\u884c\u4e3a\u3002", "conclusion": "QuickLAP\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u5b9e\u65f6\u3001\u9c81\u68d2\u7684\u5956\u52b1\u5b66\u4e60\uff0c\u80fd\u591f\u5904\u7406\u6a21\u7cca\u53cd\u9988\uff0c\u901a\u8fc7\u878d\u5408\u7269\u7406\u548c\u8bed\u8a00\u53cd\u9988\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2511.18184", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18184", "abs": "https://arxiv.org/abs/2511.18184", "authors": ["Dileep Kumar", "Wajiha Shireen"], "title": "Energy Control Strategy to Enhance AC Fault Ride-Through in Offshore Wind MMC-HVDC Systems", "comment": null, "summary": "Modular Multilevel Converter-based High Voltage Direct Current (MMC-HVDC) system is a promising technology for integration of offshore wind farms (OWFs). However, onshore AC faults on MMC-HVDC reduce the power transfer capability of onshore converter station, leading to surplus power accumulation in HVDC link. This surplus power causes a rapid rise in DC-link voltage and may hinder safe operation of OWFs. To address such a situation, this paper presents an AC fault ride-through scheme that combines the storage of surplus power in MMC submodule (SM) capacitors and dissipation of residual power in an energy dissipation device (EDD). The proposed energy control facilitates use of half-bridge MMC SMs with low-capacitance, with their storage capacity leveraged to share the surplus power during faults, with a lower-rated EDD. The proposed scheme is tested on a 640kV/420MW MMC-HVDC system. The results show that proposed control scheme effectively maintains DC link voltages, ensuring connection of OWFs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408MMC\u5b50\u6a21\u5757\u7535\u5bb9\u50a8\u80fd\u548c\u80fd\u91cf\u8017\u6563\u88c5\u7f6e\u7684\u4ea4\u6d41\u6545\u969c\u7a7f\u8d8a\u65b9\u6848\uff0c\u89e3\u51b3\u6d77\u4e0a\u98ce\u7535MMC-HVDC\u7cfb\u7edf\u5728\u5cb8\u4e0a\u4ea4\u6d41\u6545\u969c\u65f6\u7684\u529f\u7387\u76c8\u4f59\u95ee\u9898", "motivation": "MMC-HVDC\u7cfb\u7edf\u5728\u5cb8\u4e0a\u4ea4\u6d41\u6545\u969c\u65f6\u529f\u7387\u4f20\u8f93\u80fd\u529b\u4e0b\u964d\uff0c\u5bfc\u81f4\u76f4\u6d41\u94fe\u8def\u529f\u7387\u79ef\u7d2f\u548c\u7535\u538b\u5feb\u901f\u4e0a\u5347\uff0c\u5a01\u80c1\u6d77\u4e0a\u98ce\u7535\u573a\u5b89\u5168\u8fd0\u884c", "method": "\u5c06\u5269\u4f59\u529f\u7387\u5b58\u50a8\u5728MMC\u5b50\u6a21\u5757\u7535\u5bb9\u5668\u4e2d\uff0c\u540c\u65f6\u901a\u8fc7\u80fd\u91cf\u8017\u6563\u88c5\u7f6e\u6d88\u6563\u6b8b\u4f59\u529f\u7387\uff0c\u7ed3\u5408\u4f7f\u7528\u4f4e\u7535\u5bb9\u534a\u6865MMC\u5b50\u6a21\u5757\u548c\u4f4e\u989d\u5b9a\u503cEDD", "result": "\u5728640kV/420MW MMC-HVDC\u7cfb\u7edf\u4e0a\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u63a7\u5236\u65b9\u6848\u80fd\u6709\u6548\u7ef4\u6301\u76f4\u6d41\u94fe\u8def\u7535\u538b\uff0c\u786e\u4fdd\u6d77\u4e0a\u98ce\u7535\u573a\u7684\u8fde\u63a5", "conclusion": "\u63d0\u51fa\u7684\u80fd\u91cf\u63a7\u5236\u65b9\u6848\u901a\u8fc7MMC\u5b50\u6a21\u5757\u7535\u5bb9\u50a8\u80fd\u548cEDD\u529f\u7387\u8017\u6563\u7684\u7ec4\u5408\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4ea4\u6d41\u6545\u969c\u671f\u95f4\u7684\u529f\u7387\u76c8\u4f59\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u53ef\u9760\u6027"}}
{"id": "2511.17682", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17682", "abs": "https://arxiv.org/abs/2511.17682", "authors": ["Tim Schlippe", "Matthias W\u00f6lfel", "Koena Ronny Mabokela"], "title": "A Cross-Cultural Assessment of Human Ability to Detect LLM-Generated Fake News about South Africa", "comment": null, "summary": "This study investigates how cultural proximity affects the ability to detect AI-generated fake news by comparing South African participants with those from other nationalities. As large language models increasingly enable the creation of sophisticated fake news, understanding human detection capabilities becomes crucial, particularly across different cultural contexts. We conducted a survey where 89 participants (56 South Africans, 33 from other nationalities) evaluated 10 true South African news articles and 10 AI-generated fake versions. Results reveal an asymmetric pattern: South Africans demonstrated superior performance in detecting true news about their country (40% deviation from ideal rating) compared to other participants (52%), but performed worse at identifying fake news (62% vs. 55%). This difference may reflect South Africans' higher overall trust in news sources. Our analysis further shows that South Africans relied more on content knowledge and contextual understanding when judging credibility, while participants from other countries emphasised formal linguistic features such as grammar and structure. Overall, the deviation from ideal rating was similar between groups (51% vs. 53%), suggesting that cultural familiarity appears to aid verification of authentic information but may also introduce bias when evaluating fabricated content. These insights contribute to understanding cross-cultural dimensions of misinformation detection and inform strategies for combating AI-generated fake news in increasingly globalised information ecosystems where content crosses cultural and geographical boundaries.", "AI": {"tldr": "\u6587\u5316\u4eb2\u8fd1\u6027\u5f71\u54cdAI\u751f\u6210\u5047\u65b0\u95fb\u68c0\u6d4b\u80fd\u529b\uff1a\u5357\u975e\u4eba\u5728\u68c0\u6d4b\u672c\u56fd\u771f\u5b9e\u65b0\u95fb\u65f6\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5728\u8bc6\u522b\u5047\u65b0\u95fb\u65f6\u8868\u73b0\u66f4\u5dee\uff0c\u8fd9\u53cd\u6620\u4e86\u6587\u5316\u719f\u6089\u5ea6\u5e26\u6765\u7684\u9a8c\u8bc1\u4f18\u52bf\u548c\u504f\u89c1\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u590d\u6742\u7684\u5047\u65b0\u95fb\uff0c\u7406\u89e3\u4eba\u7c7b\u5728\u4e0d\u540c\u6587\u5316\u80cc\u666f\u4e0b\u7684\u68c0\u6d4b\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u5185\u5bb9\u8de8\u8d8a\u6587\u5316\u8fb9\u754c\u65f6\u3002", "method": "\u5bf989\u540d\u53c2\u4e0e\u8005\uff0856\u540d\u5357\u975e\u4eba\uff0c33\u540d\u5176\u4ed6\u56fd\u7c4d\uff09\u8fdb\u884c\u8c03\u67e5\uff0c\u8ba9\u4ed6\u4eec\u8bc4\u4f3010\u7bc7\u771f\u5b9e\u7684\u5357\u975e\u65b0\u95fb\u548c10\u7bc7AI\u751f\u6210\u7684\u5047\u65b0\u95fb\u3002", "result": "\u5357\u975e\u4eba\u5728\u68c0\u6d4b\u771f\u5b9e\u65b0\u95fb\u65f6\u8868\u73b0\u66f4\u4f18\uff08\u504f\u79bb\u7406\u60f3\u8bc4\u520640% vs 52%\uff09\uff0c\u4f46\u5728\u8bc6\u522b\u5047\u65b0\u95fb\u65f6\u8868\u73b0\u66f4\u5dee\uff0862% vs 55%\uff09\u3002\u4e24\u7ec4\u603b\u4f53\u504f\u79bb\u7a0b\u5ea6\u76f8\u4f3c\uff0851% vs 53%\uff09\u3002", "conclusion": "\u6587\u5316\u719f\u6089\u5ea6\u6709\u52a9\u4e8e\u9a8c\u8bc1\u771f\u5b9e\u4fe1\u606f\uff0c\u4f46\u5728\u8bc4\u4f30\u865a\u5047\u5185\u5bb9\u65f6\u53ef\u80fd\u5f15\u5165\u504f\u89c1\uff0c\u8fd9\u5bf9\u7406\u89e3\u8de8\u6587\u5316\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\u548c\u5e94\u5bf9AI\u751f\u6210\u5047\u65b0\u95fb\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.17889", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17889", "abs": "https://arxiv.org/abs/2511.17889", "authors": ["Ting Huang", "Dongjian Li", "Rui Yang", "Zeyu Zhang", "Zida Yang", "Hao Tang"], "title": "MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots", "comment": null, "summary": "Grounding natural-language instructions into continuous control for quadruped robots remains a fundamental challenge in vision language action. Existing methods struggle to bridge high-level semantic reasoning and low-level actuation, leading to unstable grounding and weak generalization in the real world. To address these issues, we present MobileVLA-R1, a unified vision-language-action framework that enables explicit reasoning and continuous control for quadruped robots. We construct MobileVLA-CoT, a large-scale dataset of multi-granularity chain-of-thought (CoT) for embodied trajectories, providing structured reasoning supervision for alignment. Built upon this foundation, we introduce a two-stage training paradigm that combines supervised CoT alignment with GRPO reinforcement learning to enhance reasoning consistency, control stability, and long-horizon execution. Extensive evaluations on VLN and VLA tasks demonstrate superior performance over strong baselines, with approximately a 5% improvement. Real-world deployment on a quadruped robot validates robust performance in complex environments. Code: https://github.com/AIGeeksGroup/MobileVLA-R1. Website: https://aigeeksgroup.github.io/MobileVLA-R1.", "AI": {"tldr": "MobileVLA-R1\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u601d\u7ef4\u94fe\u6570\u636e\u96c6\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u56db\u8db3\u673a\u5668\u4eba\u7684\u663e\u5f0f\u63a8\u7406\u548c\u8fde\u7eed\u63a7\u5236\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5c06\u9ad8\u7ea7\u8bed\u4e49\u63a8\u7406\u4e0e\u4f4e\u7ea7\u9a71\u52a8\u8fde\u63a5\u8d77\u6765\uff0c\u5bfc\u81f4\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u5b58\u5728\u4e0d\u7a33\u5b9a\u7684\u57fa\u7840\u5b9a\u4f4d\u548c\u5f31\u6cdb\u5316\u95ee\u9898\u3002", "method": "\u6784\u5efaMobileVLA-CoT\u5927\u89c4\u6a21\u601d\u7ef4\u94fe\u6570\u636e\u96c6\uff0c\u91c7\u7528\u76d1\u7763CoT\u5bf9\u9f50\u4e0eGRPO\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\u3002", "result": "\u5728VLN\u548cVLA\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u63d0\u5347\u7ea65%\uff0c\u5728\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u7684\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u80fd\u3002", "conclusion": "MobileVLA-R1\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u548c\u8fde\u7eed\u63a7\u5236\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56db\u8db3\u673a\u5668\u4eba\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u57fa\u7840\u5b9a\u4f4d\u7684\u6311\u6218\u3002"}}
{"id": "2511.17876", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17876", "abs": "https://arxiv.org/abs/2511.17876", "authors": ["Mukul Singh", "Ananya Singha", "Aishni Parab", "Pronita Mehrotra", "Sumit Gulwani"], "title": "Training Emergent Joint Associations: A Reinforcement Learning Approach to Creative Thinking in Language Models", "comment": null, "summary": "Associative thinking--the ability to connect seemingly unrelated ideas--is a foundational element of human creativity and problem-solving. This paper explores whether reinforcement learning (RL) guided by associative thinking principles can enhance a model's performance across diverse generative tasks, including story writing, code generation, and chart creation. We introduce a reinforcement learning framework that uses a prompt-based evaluation mechanism, incorporating established divergent thinking metrics from creativity research. A base language model is fine-tuned using this framework to reward outputs demonstrating higher novelty through higher degrees of conceptual connectivity. Interestingly, the experimental results suggest that RL-based associative thinking-trained models not only generate more original and coherent stories but also exhibit improved abstraction and flexibility in tasks such as programming and data visualization. Our findings provide initial evidence that modeling cognitive creativity principles through reinforcement learning can yield more adaptive and generative AI.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u8054\u60f3\u601d\u7ef4\u539f\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u662f\u5426\u80fd\u63d0\u5347\u6a21\u578b\u5728\u6545\u4e8b\u5199\u4f5c\u3001\u4ee3\u7801\u751f\u6210\u548c\u56fe\u8868\u521b\u5efa\u7b49\u591a\u6837\u5316\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u8054\u60f3\u601d\u7ef4\u662f\u4eba\u7c7b\u521b\u9020\u529b\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u57fa\u7840\u8981\u7d20\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6a21\u62df\u8fd9\u79cd\u8ba4\u77e5\u8fc7\u7a0b\u6765\u589e\u5f3aAI\u7684\u751f\u6210\u80fd\u529b\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u63d0\u793a\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u521b\u9020\u529b\u7814\u7a76\u4e2d\u786e\u7acb\u7684\u53d1\u6563\u601d\u7ef4\u6307\u6807\uff0c\u901a\u8fc7\u5956\u52b1\u5177\u6709\u66f4\u9ad8\u6982\u5ff5\u8fde\u63a5\u6027\u7684\u8f93\u51fa\u6765\u5fae\u8c03\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7ecf\u8fc7\u8054\u60f3\u601d\u7ef4\u8bad\u7ec3\u7684\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u4e0d\u4ec5\u751f\u6210\u66f4\u539f\u521b\u548c\u8fde\u8d2f\u7684\u6545\u4e8b\uff0c\u5728\u7f16\u7a0b\u548c\u6570\u636e\u53ef\u89c6\u5316\u7b49\u4efb\u52a1\u4e2d\u4e5f\u8868\u73b0\u51fa\u66f4\u597d\u7684\u62bd\u8c61\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5efa\u6a21\u8ba4\u77e5\u521b\u9020\u529b\u539f\u5219\u53ef\u4ee5\u4ea7\u751f\u66f4\u5177\u9002\u5e94\u6027\u548c\u751f\u6210\u80fd\u529b\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2511.18267", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18267", "abs": "https://arxiv.org/abs/2511.18267", "authors": ["Aaron H. P. Farha", "Jonathan P. Ore", "Elias N. Pergantis", "Davide Ziviani", "Eckhard A. Groll", "Kevin J. Kircher"], "title": "Laboratory and field testing of a residential heat pump retrofit for a DC solar nanogrid", "comment": null, "summary": "Residential buildings are increasingly integrating large devices that run natively on direct current (DC), such as solar photovoltaics, electric vehicles, stationary batteries, and DC motors that drive heat pumps and other major appliances. Today, these natively-DC devices typically connect within buildings through alternating current (AC) distribution systems, entailing significant energy losses due to conversions between AC and DC. This paper investigates the alternative of connecting DC devices through DC distribution. Specifically, this paper shows through laboratory and field experiments that an off-the-shelf residential heat pump designed for conventional AC systems can be powered directly on DC with few hardware modifications and little change in performance. Supporting simulations of a DC nanogrid including historical heat pump and rest-of-house load measurements, a solar photovoltaic array, and a stationary battery suggest that connecting these devices through DC distribution could decrease annual electricity bills by 12.5% with an after-market AC-to-DC heat pump retrofit and by 16.7% with a heat pump designed to run on DC.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u4f4f\u5b85\u5efa\u7b51\u4e2d\u7684\u76f4\u6d41\u8bbe\u5907\u901a\u8fc7\u76f4\u6d41\u914d\u7535\u7cfb\u7edf\u8fde\u63a5\u6bd4\u901a\u8fc7\u4ea4\u6d41\u914d\u7535\u7cfb\u7edf\u66f4\u8282\u80fd\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4e\u7535\u8d39\u3002", "motivation": "\u4f4f\u5b85\u5efa\u7b51\u4e2d\u8d8a\u6765\u8d8a\u591a\u7684\u76f4\u6d41\u8bbe\u5907\u901a\u8fc7\u4ea4\u6d41\u914d\u7535\u7cfb\u7edf\u8fde\u63a5\uff0c\u5bfc\u81f4AC-DC\u8f6c\u6362\u4ea7\u751f\u5927\u91cf\u80fd\u91cf\u635f\u5931\uff0c\u7814\u7a76\u76f4\u6d41\u914d\u7535\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u548c\u73b0\u573a\u5b9e\u9a8c\u6d4b\u8bd5\u73b0\u6210\u4f4f\u5b85\u70ed\u6cf5\u5728\u76f4\u6d41\u4f9b\u7535\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u6a21\u62df\u5305\u542b\u70ed\u6cf5\u3001\u5149\u4f0f\u9635\u5217\u548c\u7535\u6c60\u7684\u76f4\u6d41\u7eb3\u7c73\u7535\u7f51\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u73b0\u6210\u70ed\u6cf5\u53ef\u76f4\u63a5\u5728\u76f4\u6d41\u4f9b\u7535\u4e0b\u8fd0\u884c\u4e14\u6027\u80fd\u53d8\u5316\u4e0d\u5927\uff1b\u6a21\u62df\u663e\u793a\u76f4\u6d41\u914d\u7535\u53ef\u4f7f\u5e74\u7535\u8d39\u964d\u4f4e12.5%\uff08\u6539\u88c5\u70ed\u6cf5\uff09\u548c16.7%\uff08\u76f4\u6d41\u8bbe\u8ba1\u70ed\u6cf5\uff09\u3002", "conclusion": "\u76f4\u6d41\u914d\u7535\u7cfb\u7edf\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u4f4f\u5b85\u80fd\u6e90\u6548\u7387\u5e76\u964d\u4f4e\u7535\u8d39\uff0c\u7279\u522b\u662f\u4e3a\u76f4\u6d41\u8bbe\u5907\u8bbe\u8ba1\u7684\u7cfb\u7edf\u6548\u679c\u66f4\u4f73\u3002"}}
{"id": "2511.17683", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17683", "abs": "https://arxiv.org/abs/2511.17683", "authors": ["Lara Hassan", "Mohamed ElZeftawy", "Abdulrahman Mahmoud"], "title": "Datacenters in the Desert: Feasibility and Sustainability of LLM Inference in the Middle East", "comment": "3 pages, 1 figure", "summary": "As the Middle East emerges as a strategic hub for artificial intelligence (AI) infrastructure, the feasibility of deploying sustainable datacenters in desert environments has become a topic of growing relevance. This paper presents an empirical study analyzing the energy consumption and carbon footprint of large language model (LLM) inference across four countries: the United Arab Emirates, Iceland, Germany, and the United States of America using DeepSeek Coder 1.3B and the HumanEval dataset on the task of code generation. We use the CodeCarbon library to track energy and carbon emissions andcompare geographical trade-offs for climate-aware AI deployment. Our findings highlight both the challenges and potential of datacenters in desert regions and provide a balanced outlook on their role in global AI expansion.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86\u5728\u963f\u8054\u914b\u3001\u51b0\u5c9b\u3001\u5fb7\u56fd\u548c\u7f8e\u56fd\u56db\u4e2a\u56fd\u5bb6\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\uff0c\u91cd\u70b9\u5173\u6ce8\u6c99\u6f20\u73af\u5883\u4e2d\u6570\u636e\u4e2d\u5fc3\u90e8\u7f72\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u968f\u7740\u4e2d\u4e1c\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u7684\u6218\u7565\u67a2\u7ebd\uff0c\u5728\u6c99\u6f20\u73af\u5883\u4e2d\u90e8\u7f72\u53ef\u6301\u7eed\u6570\u636e\u4e2d\u5fc3\u7684\u53ef\u884c\u6027\u65e5\u76ca\u91cd\u8981\u3002", "method": "\u4f7f\u7528DeepSeek Coder 1.3B\u6a21\u578b\u548cHumanEval\u6570\u636e\u96c6\u8fdb\u884c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u901a\u8fc7CodeCarbon\u5e93\u8ddf\u8e2a\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\uff0c\u6bd4\u8f83\u4e0d\u540c\u5730\u7406\u4f4d\u7f6e\u7684\u6743\u8861\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u6c99\u6f20\u5730\u533a\u6570\u636e\u4e2d\u5fc3\u9762\u4e34\u7684\u6311\u6218\u548c\u6f5c\u529b\u3002", "conclusion": "\u4e3a\u5168\u7403AI\u6269\u5c55\u4e2d\u6c99\u6f20\u6570\u636e\u4e2d\u5fc3\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u5e73\u8861\u7684\u5c55\u671b\u3002"}}
{"id": "2511.17898", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17898", "abs": "https://arxiv.org/abs/2511.17898", "authors": ["Weixi Song", "Zhetao Chen", "Tao Xu", "Xianchao Zeng", "Xinyu Zhou", "Lixin Yang", "Donglin Wang", "Cewu Lu", "Yong-Lu Li"], "title": "L1 Sample Flow for Efficient Visuomotor Learning", "comment": null, "summary": "Denoising-based models, such as diffusion and flow matching, have been a critical component of robotic manipulation for their strong distribution-fitting and scaling capacity. Concurrently, several works have demonstrated that simple learning objectives, such as L1 regression, can achieve performance comparable to denoising-based methods on certain tasks, while offering faster convergence and inference. In this paper, we focus on how to combine the advantages of these two paradigms: retaining the ability of denoising models to capture multi-modal distributions and avoid mode collapse while achieving the efficiency of the L1 regression objective. To achieve this vision, we reformulate the original v-prediction flow matching and transform it into sample-prediction with the L1 training objective. We empirically show that the multi-modality can be expressed via a single ODE step. Thus, we propose \\textbf{L1 Flow}, a two-step sampling schedule that generates a suboptimal action sequence via a single integration step and then reconstructs the precise action sequence through a single prediction. The proposed method largely retains the advantages of flow matching while reducing the iterative neural function evaluations to merely two and mitigating the potential performance degradation associated with direct sample regression. We evaluate our method with varying baselines and benchmarks, including 8 tasks in MimicGen, 5 tasks in RoboMimic \\& PushT Bench, and one task in the real-world scenario. The results show the advantages of the proposed method with regard to training efficiency, inference speed, and overall performance. \\href{https://song-wx.github.io/l1flow.github.io/}{Project Website.}", "AI": {"tldr": "\u672c\u6587\u63d0\u51faL1 Flow\u65b9\u6cd5\uff0c\u5c06v-prediction flow matching\u91cd\u6784\u4e3asample-prediction\uff0c\u4f7f\u7528L1\u8bad\u7ec3\u76ee\u6807\uff0c\u901a\u8fc7\u4e24\u6b65\u91c7\u6837\uff08\u5355\u6b65\u79ef\u5206\u751f\u6210\u6b21\u4f18\u52a8\u4f5c\u5e8f\u5217\uff0c\u5355\u6b65\u9884\u6d4b\u91cd\u6784\u7cbe\u786e\u52a8\u4f5c\u5e8f\u5217\uff09\u6765\u7ed3\u5408\u53bb\u566a\u6a21\u578b\u7684\u591a\u6a21\u6001\u5206\u5e03\u80fd\u529b\u548cL1\u56de\u5f52\u7684\u6548\u7387\u4f18\u52bf\u3002", "motivation": "\u7ed3\u5408\u53bb\u566a\u6a21\u578b\uff08\u5982\u6269\u6563\u548c\u6d41\u5339\u914d\uff09\u7684\u591a\u6a21\u6001\u5206\u5e03\u62df\u5408\u80fd\u529b\u4e0eL1\u56de\u5f52\u76ee\u6807\u7684\u9ad8\u6548\u6027\uff0c\u907f\u514d\u6a21\u5f0f\u5d29\u6e83\u540c\u65f6\u63d0\u5347\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u3002", "method": "\u5c06\u539f\u59cbv-prediction flow matching\u91cd\u6784\u4e3asample-prediction\uff0c\u91c7\u7528L1\u8bad\u7ec3\u76ee\u6807\uff0c\u63d0\u51fa\u4e24\u6b65\u91c7\u6837\u65b9\u6848\uff1a\u5355\u6b65ODE\u79ef\u5206\u751f\u6210\u6b21\u4f18\u52a8\u4f5c\u5e8f\u5217\uff0c\u5355\u6b65\u9884\u6d4b\u91cd\u6784\u7cbe\u786e\u52a8\u4f5c\u5e8f\u5217\u3002", "result": "\u5728MimicGen\u76848\u4e2a\u4efb\u52a1\u3001RoboMimic\u548cPushT Bench\u76845\u4e2a\u4efb\u52a1\u4ee5\u53ca\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u8bad\u7ec3\u6548\u7387\u3001\u63a8\u7406\u901f\u5ea6\u548c\u6574\u4f53\u6027\u80fd\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "L1 Flow\u65b9\u6cd5\u5728\u4fdd\u6301\u6d41\u5339\u914d\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u5c06\u8fed\u4ee3\u795e\u7ecf\u7f51\u7edc\u8bc4\u4f30\u51cf\u5c11\u5230\u4ec5\u4e24\u6b21\uff0c\u7f13\u89e3\u4e86\u76f4\u63a5\u6837\u672c\u56de\u5f52\u53ef\u80fd\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002"}}
{"id": "2511.17909", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17909", "abs": "https://arxiv.org/abs/2511.17909", "authors": ["Zhiyuan Huang", "Baichuan Yang", "Zikun He", "Yanhong Wu", "Fang Hongyu", "Zhenhe Liu", "Lin Dongsheng", "Bing Su"], "title": "ChemVTS-Bench: Evaluating Visual-Textual-Symbolic Reasoning of Multimodal Large Language Models in Chemistry", "comment": null, "summary": "Chemical reasoning inherently integrates visual, textual, and symbolic modalities, yet existing benchmarks rarely capture this complexity, often relying on simple image-text pairs with limited chemical semantics. As a result, the actual ability of Multimodal Large Language Models (MLLMs) to process and integrate chemically meaningful information across modalities remains unclear. We introduce \\textbf{ChemVTS-Bench}, a domain-authentic benchmark designed to systematically evaluate the Visual-Textual-Symbolic (VTS) reasoning abilities of MLLMs. ChemVTS-Bench contains diverse and challenging chemical problems spanning organic molecules, inorganic materials, and 3D crystal structures, with each task presented in three complementary input modes: (1) visual-only, (2) visual-text hybrid, and (3) SMILES-based symbolic input. This design enables fine-grained analysis of modality-dependent reasoning behaviors and cross-modal integration. To ensure rigorous and reproducible evaluation, we further develop an automated agent-based workflow that standardizes inference, verifies answers, and diagnoses failure modes. Extensive experiments on state-of-the-art MLLMs reveal that visual-only inputs remain challenging, structural chemistry is the hardest domain, and multimodal fusion mitigates but does not eliminate visual, knowledge-based, or logical errors, highlighting ChemVTS-Bench as a rigorous, domain-faithful testbed for advancing multimodal chemical reasoning. All data and code will be released to support future research.", "AI": {"tldr": "\u63d0\u51fa\u4e86ChemVTS-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5316\u5b66\u9886\u57df\u7684\u89c6\u89c9-\u6587\u672c-\u7b26\u53f7\u63a8\u7406\u80fd\u529b\uff0c\u5305\u542b\u591a\u79cd\u5316\u5b66\u95ee\u9898\u548c\u4e09\u79cd\u8f93\u5165\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u96be\u4ee5\u6355\u6349\u5316\u5b66\u63a8\u7406\u7684\u590d\u6742\u6027\uff0c\u901a\u5e38\u4f9d\u8d56\u7b80\u5355\u7684\u56fe\u50cf-\u6587\u672c\u5bf9\uff0c\u7f3a\u4e4f\u5316\u5b66\u8bed\u4e49\uff0c\u65e0\u6cd5\u8bc4\u4f30MLLMs\u8de8\u6a21\u6001\u5904\u7406\u5316\u5b66\u4fe1\u606f\u7684\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u5305\u542b\u6709\u673a\u5206\u5b50\u3001\u65e0\u673a\u6750\u6599\u548c3D\u6676\u4f53\u7ed3\u6784\u7684\u591a\u6837\u5316\u5316\u5b66\u95ee\u9898\uff0c\u63d0\u4f9b\u4e09\u79cd\u4e92\u8865\u8f93\u5165\u6a21\u5f0f\uff1a\u7eaf\u89c6\u89c9\u3001\u89c6\u89c9-\u6587\u672c\u6df7\u5408\u548cSMILES\u7b26\u53f7\u8f93\u5165\uff0c\u5e76\u5efa\u7acb\u81ea\u52a8\u5316\u4ee3\u7406\u5de5\u4f5c\u6d41\u8fdb\u884c\u6807\u51c6\u5316\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7eaf\u89c6\u89c9\u8f93\u5165\u4ecd\u5177\u6311\u6218\u6027\uff0c\u7ed3\u6784\u5316\u5b66\u662f\u6700\u96be\u9886\u57df\uff0c\u591a\u6a21\u6001\u878d\u5408\u80fd\u7f13\u89e3\u4f46\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u89c6\u89c9\u3001\u77e5\u8bc6\u548c\u903b\u8f91\u9519\u8bef\u3002", "conclusion": "ChemVTS-Bench\u662f\u4e00\u4e2a\u4e25\u8c28\u3001\u5fe0\u5b9e\u4e8e\u5316\u5b66\u9886\u57df\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u80fd\u63a8\u52a8\u591a\u6a21\u6001\u5316\u5b66\u63a8\u7406\u7684\u53d1\u5c55\uff0c\u6240\u6709\u6570\u636e\u548c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002"}}
{"id": "2511.18428", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18428", "abs": "https://arxiv.org/abs/2511.18428", "authors": ["Xinyan Le", "Yao Zhu", "Yulin Hu", "Bin Han"], "title": "Joint Optimization for Security and Reliability in Round-Trip Transmissions for URLLC services", "comment": "6 pages,4 figures", "summary": "Physical layer security (PLS) is a potential solution for secure and reliable transmissions in future Ultra-Reliable and Low-Latency Communications (URLLC). This work jointly optimizes redundant bits and blocklength allocation in practical round-trip transmission scenarios. To minimize the leakage-failure probability, a metric that jointly characterizes security and reliability in PLS, we formulate an optimization problem for allocating both redundant bits and blocklength. By deriving the boundaries of the feasible set, we obtain the globally optimal solution for this integer optimization problem. To achieve more computationally efficient solutions, we propose a block coordinate descent (BCD) method that exploits the partial convexity of the objective function. Subsequently, we develop a majorization-minimization (MM) algorithm through convex approximation of the objective function, which further improves computational efficiency. Finally, we validate the performance of the three proposed approaches through simulations, demonstrating their practical applicability for future URLLC services.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9URLLC\u4e2d\u7684\u7269\u7406\u5c42\u5b89\u5168\u95ee\u9898\uff0c\u8054\u5408\u4f18\u5316\u5197\u4f59\u6bd4\u7279\u548c\u5757\u957f\u5ea6\u5206\u914d\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u65b9\u6cd5\u6765\u6700\u5c0f\u5316\u6cc4\u6f0f-\u5931\u8d25\u6982\u7387\uff0c\u5305\u62ec\u5168\u5c40\u6700\u4f18\u89e3\u3001\u5757\u5750\u6807\u4e0b\u964d\u6cd5\u548cMM\u7b97\u6cd5\u3002", "motivation": "\u7269\u7406\u5c42\u5b89\u5168\u662f\u672a\u6765URLLC\u4e2d\u5b9e\u73b0\u5b89\u5168\u53ef\u9760\u4f20\u8f93\u7684\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u9700\u8981\u8054\u5408\u8003\u8651\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u7684\u4f18\u5316\u95ee\u9898\u3002", "method": "1. \u63a8\u5bfc\u53ef\u884c\u96c6\u8fb9\u754c\u83b7\u5f97\u5168\u5c40\u6700\u4f18\u89e3\uff1b2. \u5229\u7528\u76ee\u6807\u51fd\u6570\u90e8\u5206\u51f8\u6027\u63d0\u51fa\u5757\u5750\u6807\u4e0b\u964d\u6cd5\uff1b3. \u901a\u8fc7\u51f8\u8fd1\u4f3c\u5f00\u53d1MM\u7b97\u6cd5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u4e09\u79cd\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u5b83\u4eec\u5bf9\u672a\u6765URLLC\u670d\u52a1\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u79cd\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3URLLC\u4e2d\u7269\u7406\u5c42\u5b89\u5168\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5176\u4e2dMM\u7b97\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002"}}
{"id": "2511.17694", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.17694", "abs": "https://arxiv.org/abs/2511.17694", "authors": ["Joanna Schroeder", "Alan Wang", "Kathryn Linehan", "Joel Thurston", "Aaron Schroeder"], "title": "Smart Metadata in Action: The Social Impact Data Commons", "comment": "Conference On Smart Metadata for Official Statistics 2024 (COSMOS 2024), April, 11-12, 2024, Paris, France", "summary": "This article describes the use of metadata and standards in the Social Impact Data Commons to expose official statisticians to an innovative project built on actionable and evaluable metadata, which produces a FAIR data system. We begin by introducing the concept of the Data Commons, focusing on its features, and presenting an overview of current implementations of the Data Commons. We then present the core metadata case study, demonstrating how smart metadata support the Data Commons. We also present evaluations of our core metadata, including its adherence to the FAIR guidelines. We conclude with a discussion on our future metadata and standards-related projects to support the Social Impact Data Commons.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u793e\u4f1a\u5f71\u54cd\u6570\u636e\u5171\u4eab\u4e2d\u5143\u6570\u636e\u548c\u6807\u51c6\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u4e00\u4e2a\u57fa\u4e8e\u53ef\u64cd\u4f5c\u3001\u53ef\u8bc4\u4f30\u5143\u6570\u636e\u7684FAIR\u6570\u636e\u7cfb\u7edf\uff0c\u901a\u8fc7\u6838\u5fc3\u5143\u6570\u636e\u6848\u4f8b\u7814\u7a76\u6f14\u793a\u4e86\u667a\u80fd\u5143\u6570\u636e\u5982\u4f55\u652f\u6301\u6570\u636e\u5171\u4eab\u3002", "motivation": "\u5c06\u5b98\u65b9\u7edf\u8ba1\u5b66\u5bb6\u5f15\u5165\u57fa\u4e8e\u53ef\u64cd\u4f5c\u548c\u53ef\u8bc4\u4f30\u5143\u6570\u636e\u7684\u521b\u65b0\u9879\u76ee\uff0c\u6784\u5efa\u7b26\u5408FAIR\u539f\u5219\u7684\u6570\u636e\u7cfb\u7edf\uff0c\u652f\u6301\u793e\u4f1a\u5f71\u54cd\u6570\u636e\u5171\u4eab\u3002", "method": "\u5f15\u5165\u6570\u636e\u5171\u4eab\u6982\u5ff5\uff0c\u5c55\u793a\u5176\u7279\u6027\uff0c\u6982\u8ff0\u5f53\u524d\u5b9e\u73b0\uff0c\u901a\u8fc7\u6838\u5fc3\u5143\u6570\u636e\u6848\u4f8b\u7814\u7a76\u6f14\u793a\u667a\u80fd\u5143\u6570\u636e\u5982\u4f55\u652f\u6301\u6570\u636e\u5171\u4eab\uff0c\u5e76\u8bc4\u4f30\u5143\u6570\u636e\u5bf9FAIR\u6307\u5357\u7684\u9075\u5faa\u60c5\u51b5\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u57fa\u4e8e\u667a\u80fd\u5143\u6570\u636e\u7684FAIR\u6570\u636e\u7cfb\u7edf\uff0c\u6838\u5fc3\u5143\u6570\u636e\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u5143\u6570\u636e\u5728\u652f\u6301\u6570\u636e\u5171\u4eab\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u8bc4\u4f30\u663e\u793a\u5143\u6570\u636e\u7b26\u5408FAIR\u6307\u5357\u8981\u6c42\u3002", "conclusion": "\u672a\u6765\u5c06\u7ee7\u7eed\u5f00\u5c55\u4e0e\u5143\u6570\u636e\u548c\u6807\u51c6\u76f8\u5173\u7684\u9879\u76ee\uff0c\u4ee5\u8fdb\u4e00\u6b65\u652f\u6301\u793e\u4f1a\u5f71\u54cd\u6570\u636e\u5171\u4eab\u7684\u53d1\u5c55\u548c\u5b8c\u5584\u3002"}}
{"id": "2511.17925", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17925", "abs": "https://arxiv.org/abs/2511.17925", "authors": ["Jeonghwan Kim", "Wontaek Kim", "Yidan Lu", "Jin Cheng", "Fatemeh Zargarbashi", "Zicheng Zeng", "Zekun Qi", "Zhiyang Dou", "Nitish Sontakke", "Donghoon Baek", "Sehoon Ha", "Tianyu Li"], "title": "Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game", "comment": null, "summary": "Recent advances in whole-body robot control have enabled humanoid and legged robots to perform increasingly agile and coordinated motions. However, standardized benchmarks for evaluating these capabilities in real-world settings, and in direct comparison to humans, remain scarce. Existing evaluations often rely on pre-collected human motion datasets or simulation-based experiments, which limit reproducibility, overlook hardware factors, and hinder fair human-robot comparisons. We present Switch-JustDance, a low-cost and reproducible benchmarking pipeline that leverages motion-sensing console games, Just Dance on the Nintendo Switch, to evaluate robot whole-body control. Using Just Dance on the Nintendo Switch as a representative platform, Switch-JustDance converts in-game choreography into robot-executable motions through streaming, motion reconstruction, and motion retargeting modules and enables users to evaluate controller performance through the game's built-in scoring system. We first validate the evaluation properties of Just Dance, analyzing its reliability, validity, sensitivity, and potential sources of bias. Our results show that the platform provides consistent and interpretable performance measures, making it a suitable tool for benchmarking embodied AI. Building on this foundation, we benchmark three state-of-the-art humanoid whole-body controllers on hardware and provide insights into their relative strengths and limitations.", "AI": {"tldr": "Switch-JustDance\u662f\u4e00\u4e2a\u4f4e\u6210\u672c\u3001\u53ef\u590d\u73b0\u7684\u673a\u5668\u4eba\u5168\u8eab\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u5229\u7528\u4efb\u5929\u5802Switch\u4e0a\u7684Just Dance\u6e38\u620f\u6765\u8bc4\u4f30\u673a\u5668\u4eba\u821e\u8e48\u52a8\u4f5c\u63a7\u5236\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u4eba\u5168\u8eab\u63a7\u5236\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9884\u6536\u96c6\u7684\u4eba\u7c7b\u8fd0\u52a8\u6570\u636e\u96c6\u6216\u4eff\u771f\u5b9e\u9a8c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u590d\u73b0\u6027\u3001\u5ffd\u89c6\u786c\u4ef6\u56e0\u7d20\uff0c\u4e14\u96be\u4ee5\u8fdb\u884c\u516c\u5e73\u7684\u4eba\u673a\u6bd4\u8f83\u3002", "method": "\u901a\u8fc7Just Dance\u6e38\u620f\u5e73\u53f0\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u6d41\u5a92\u4f53\u4f20\u8f93\u3001\u8fd0\u52a8\u91cd\u5efa\u548c\u8fd0\u52a8\u91cd\u5b9a\u5411\u6a21\u5757\u7684\u7ba1\u9053\uff0c\u5c06\u6e38\u620f\u4e2d\u7684\u7f16\u821e\u8f6c\u6362\u4e3a\u673a\u5668\u4eba\u53ef\u6267\u884c\u52a8\u4f5c\uff0c\u5e76\u5229\u7528\u6e38\u620f\u5185\u7f6e\u8bc4\u5206\u7cfb\u7edf\u8bc4\u4f30\u63a7\u5236\u5668\u6027\u80fd\u3002", "result": "\u9a8c\u8bc1\u4e86Just Dance\u5e73\u53f0\u7684\u53ef\u9760\u6027\u3001\u6709\u6548\u6027\u3001\u654f\u611f\u6027\u548c\u6f5c\u5728\u504f\u5dee\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u5e73\u53f0\u80fd\u63d0\u4f9b\u4e00\u81f4\u4e14\u53ef\u89e3\u91ca\u7684\u6027\u80fd\u5ea6\u91cf\u3002\u5728\u786c\u4ef6\u4e0a\u5bf9\u4e09\u79cd\u6700\u5148\u8fdb\u7684\u4eba\u5f62\u673a\u5668\u4eba\u5168\u8eab\u63a7\u5236\u5668\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "Switch-JustDance\u662f\u4e00\u4e2a\u9002\u5408\u7528\u4e8e\u5177\u8eabAI\u57fa\u51c6\u6d4b\u8bd5\u7684\u5de5\u5177\uff0c\u80fd\u591f\u4e3a\u673a\u5668\u4eba\u5168\u8eab\u63a7\u5236\u5668\u7684\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u6807\u51c6\u5316\u65b9\u6cd5\u3002"}}
{"id": "2511.17937", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17937", "abs": "https://arxiv.org/abs/2511.17937", "authors": ["Kartik Garg", "Shourya Mishra", "Kartikeya Sinha", "Ojaswi Pratap Singh", "Ayush Chopra", "Kanishk Rai", "Ammar Sheikh", "Raghav Maheshwari", "Aman Chadha", "Vinija Jain", "Amitava Das"], "title": "Alignment Faking - the Train -> Deploy Asymmetry: Through a Game-Theoretic Lens with Bayesian-Stackelberg Equilibria", "comment": null, "summary": "Alignment faking is a form of strategic deception in AI in which models selectively comply with training objectives when they infer that they are in training, while preserving different behavior outside training. The phenomenon was first documented for Claude 3 Opus and later examined across additional large language models. In these setups, the word \"training\" refers to simulated training via prompts without parameter updates, so the observed effects are context conditioned shifts in behavior rather than preference learning. We study the phenomenon using an evaluation framework that compares preference optimization methods (BCO, DPO, KTO, and GRPO) across 15 models from four model families, measured along three axes: safety, harmlessness, and helpfulness. Our goal is to identify what causes alignment faking and when it occurs.", "AI": {"tldr": "\u7814\u7a76\u4e86AI\u6a21\u578b\u4e2d\u7684\u5bf9\u9f50\u4f2a\u88c5\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u5728\u63a8\u65ad\u5904\u4e8e\u8bad\u7ec3\u72b6\u6001\u65f6\u9009\u62e9\u6027\u9075\u5b88\u8bad\u7ec3\u76ee\u6807\uff0c\u4f46\u5728\u8bad\u7ec3\u5916\u4fdd\u6301\u4e0d\u540c\u884c\u4e3a\u3002\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u572815\u4e2a\u6a21\u578b\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u4e86\u5b89\u5168\u3001\u65e0\u5bb3\u548c\u6709\u7528\u6027\u4e09\u4e2a\u7ef4\u5ea6\u3002", "motivation": "\u63a2\u7a76\u5bf9\u9f50\u4f2a\u88c5\u73b0\u8c61\u7684\u539f\u56e0\u548c\u53d1\u751f\u6761\u4ef6\uff0c\u7406\u89e3AI\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u90e8\u7f72\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u8bc4\u4f30\u6846\u67b6\u6bd4\u8f83BCO\u3001DPO\u3001KTO\u548cGRPO\u56db\u79cd\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u6765\u81ea\u56db\u4e2a\u6a21\u578b\u5bb6\u65cf\u768415\u4e2a\u6a21\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6d4b\u91cf\u5b89\u5168\u3001\u65e0\u5bb3\u548c\u6709\u7528\u6027\u4e09\u4e2a\u7ef4\u5ea6\u3002", "result": "\u5728Claude 3 Opus\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u9996\u6b21\u8bb0\u5f55\u4e86\u5bf9\u9f50\u4f2a\u88c5\u73b0\u8c61\uff0c\u6a21\u578b\u4f1a\u6839\u636e\u4e0a\u4e0b\u6587\u6761\u4ef6\u9009\u62e9\u6027\u6539\u53d8\u884c\u4e3a\u3002", "conclusion": "\u5bf9\u9f50\u4f2a\u88c5\u662fAI\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u6218\u7565\u6b3a\u9a97\u5f62\u5f0f\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u6210\u56e0\u548c\u53d1\u751f\u673a\u5236\u3002"}}
{"id": "2511.18445", "categories": ["eess.SY", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.18445", "abs": "https://arxiv.org/abs/2511.18445", "authors": ["Vishesh Vishal Ahire", "Yash Badrinarayan Amle", "Akshada Nanasaheb Waditke", "Ojas Nitin Ahire", "Amey Mahesh Warnekar", "Ayush Ganesh Ahire", "Prashant Anerao"], "title": "Speed Control Security System For safety of Driver and Surroundings", "comment": "9 Pages , 7 figures", "summary": "The speed control security system is best suited for the task of slowing the speed of a vehicle during rash driving as the Driver is over speeding the circuit captures the images of the lanes witch decides the speed of the road the car is currently on this input is further provided to the ESP-32 micro Prosser module in the car switch compiles this data with the data received for the RPM sensor of the car and decides whether the car is over speeding or not in case of over speeding a signal is send by the ESP to the Arduino witch actuates the dc motor used in the car to reduce the speed of the car by the use of a hydraulic brake system actuated by a DC motor.", "AI": {"tldr": "\u57fa\u4e8eESP-32\u548cArduino\u7684\u8f66\u8f86\u8d85\u901f\u63a7\u5236\u7cfb\u7edf\uff0c\u901a\u8fc7\u56fe\u50cf\u8bc6\u522b\u8f66\u9053\u786e\u5b9a\u9650\u901f\uff0c\u7ed3\u5408RPM\u4f20\u611f\u5668\u68c0\u6d4b\u8d85\u901f\uff0c\u81ea\u52a8\u89e6\u53d1\u6db2\u538b\u5236\u52a8\u7cfb\u7edf\u51cf\u901f", "motivation": "\u89e3\u51b3\u9c81\u83bd\u9a7e\u9a76\u548c\u8d85\u901f\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u7cfb\u7edf\u5f3a\u5236\u964d\u4f4e\u8f66\u901f\uff0c\u63d0\u9ad8\u9053\u8def\u5b89\u5168", "method": "\u4f7f\u7528ESP-32\u5fae\u5904\u7406\u5668\u5904\u7406\u8f66\u9053\u56fe\u50cf\u8bc6\u522b\u9650\u901f\uff0c\u7ed3\u5408RPM\u4f20\u611f\u5668\u6570\u636e\u5224\u65ad\u662f\u5426\u8d85\u901f\uff0c\u901a\u8fc7Arduino\u63a7\u5236DC\u7535\u673a\u9a71\u52a8\u6db2\u538b\u5236\u52a8\u7cfb\u7edf", "result": "\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u68c0\u6d4b\u8d85\u901f\u5e76\u5f3a\u5236\u51cf\u901f\uff0c\u5b9e\u73b0\u4e3b\u52a8\u5b89\u5168\u63a7\u5236", "conclusion": "\u8be5\u901f\u5ea6\u63a7\u5236\u5b89\u5168\u7cfb\u7edf\u80fd\u6709\u6548\u9632\u6b62\u8d85\u901f\u9a7e\u9a76\uff0c\u63d0\u9ad8\u8f66\u8f86\u884c\u9a76\u5b89\u5168\u6027"}}
{"id": "2511.17696", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17696", "abs": "https://arxiv.org/abs/2511.17696", "authors": ["Douglas C. Schmidt", "Dan Runfola"], "title": "Liberating Logic in the Age of AI: Going Beyond Programming with Computational Thinking", "comment": "15 pages and 17 figures", "summary": "Mastering one or more programming languages has historically been the gateway to implementing ideas on a computer. Today, that gateway is widening with advances in large language models (LLMs) and artificial intelligence (AI)-powered coding assistants. What matters is no longer just fluency in traditional programming languages but the ability to think computationally by translating problems into forms that can be solved with computing tools. The capabilities enabled by these AI-augmented tools are rapidly leading to the commoditization of computational thinking, such that anyone who can articulate a problem in natural language can potentially harness computing power via AI.\n  This shift is poised to radically influence how we teach computer science and data science in the United States and around the world. Educators and industry leaders are grappling with how to adapt: What should students learn when the hottest new programming language is English? How do we prepare a generation of computational thinkers who need not code every algorithm manually, but must still think critically, design solutions, and verify AI-augmented results?\n  This paper explores these questions, examining the impact of natural language programming on software development, the emerging distinction between programmers and prompt-crafting problem solvers, the reforms needed in computer science and data science curricula, and the importance of maintaining our fundamental computational science principles in an AI-augmented future. Along the way, we compare approaches and share best practices for embracing this new paradigm in computing education.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u7f16\u7a0b\u52a9\u624b\u5982\u4f55\u6539\u53d8\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u7684\u5f71\u54cd\u3001\u7a0b\u5e8f\u5458\u4e0e\u63d0\u793a\u8bcd\u5de5\u7a0b\u5e08\u7684\u533a\u522b\uff0c\u4ee5\u53ca\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u6539\u9769\u7684\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548cAI\u7f16\u7a0b\u52a9\u624b\u7684\u53d1\u5c55\uff0c\u7f16\u7a0b\u8bed\u8a00\u4e0d\u518d\u662f\u5b9e\u73b0\u60f3\u6cd5\u7684\u552f\u4e00\u9014\u5f84\uff0c\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u6b63\u5728\u6539\u53d8\u8ba1\u7b97\u601d\u7ef4\u7684\u672c\u8d28\uff0c\u8fd9\u8feb\u5207\u9700\u8981\u91cd\u65b0\u601d\u8003\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u7684\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u5206\u6790AI\u589e\u5f3a\u5de5\u5177\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u7684\u5f71\u54cd\uff0c\u63a2\u8ba8\u7a0b\u5e8f\u5458\u4e0e\u63d0\u793a\u8bcd\u5de5\u7a0b\u5e08\u7684\u533a\u522b\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u7684\u6559\u80b2\u65b9\u6cd5\u6765\u9002\u5e94\u8fd9\u4e00\u65b0\u8303\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u6b63\u5728\u4f7f\u8ba1\u7b97\u601d\u7ef4\u5546\u54c1\u5316\uff0c\u4efb\u4f55\u4eba\u90fd\u53ef\u4ee5\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5229\u7528\u8ba1\u7b97\u80fd\u529b\uff0c\u8fd9\u8981\u6c42\u6559\u80b2\u4f53\u7cfb\u4ece\u4f20\u7edf\u7684\u7f16\u7a0b\u8bed\u8a00\u6559\u5b66\u8f6c\u5411\u57f9\u517b\u8ba1\u7b97\u601d\u7ef4\u548c\u6279\u5224\u6027\u601d\u8003\u80fd\u529b\u3002", "conclusion": "\u5728AI\u589e\u5f3a\u7684\u672a\u6765\uff0c\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u9700\u8981\u6539\u9769\uff0c\u4fdd\u6301\u57fa\u672c\u7684\u8ba1\u7b97\u79d1\u5b66\u539f\u5219\uff0c\u540c\u65f6\u57f9\u517b\u5b66\u751f\u5728AI\u8f85\u52a9\u4e0b\u8fdb\u884c\u6279\u5224\u6027\u601d\u8003\u3001\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\u548c\u9a8c\u8bc1\u7ed3\u679c\u7684\u80fd\u529b\u3002"}}
{"id": "2511.17961", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17961", "abs": "https://arxiv.org/abs/2511.17961", "authors": ["Hao Wang", "Xiaobao Wei", "Ying Li", "Qingpo Wuwu", "Dongli Wu", "Jiajun Cao", "Ming Lu", "Wenzhao Zheng", "Shanghang Zhang"], "title": "RoboArmGS: High-Quality Robotic Arm Splatting via B\u00e9zier Curve Refinement", "comment": null, "summary": "Building high-quality digital assets of robotic arms is crucial yet challenging for the Real2Sim2Real pipeline. Current approaches naively bind static 3D Gaussians according to URDF links, forcing them to follow an URDF-rigged motion passively. However, real-world arm motion is noisy, and the idealized URDF-rigged motion cannot accurately model it, leading to severe rendering artifacts in 3D Gaussians. To address these challenges, we propose RoboArmGS, a novel hybrid representation that refines the URDF-rigged motion with learnable B\u00e9zier curves, enabling more accurate real-world motion modeling. To be more specific, we present a learnable B\u00e9zier Curve motion refiner that corrects per-joint residuals to address mismatches between real-world motion and URDF-rigged motion. RoboArmGS enables the learning of more accurate real-world motion while achieving a coherent binding of 3D Gaussians across arm parts. To support future research, we contribute a carefully collected dataset named RoboArm4D, which comprises several widely used robotic arms for evaluating the quality of building high-quality digital assets. We evaluate our approach on RoboArm4D, and RoboArmGS achieves state-of-the-art performance in real-world motion modeling and rendering quality. The code and dataset will be released.", "AI": {"tldr": "RoboArmGS\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684B\u00e9zier\u66f2\u7ebf\u7ec6\u5316URDF\u9a71\u52a8\u7684\u8fd0\u52a8\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u5efa\u6a21\u771f\u5b9e\u4e16\u754c\u673a\u68b0\u81c2\u8fd0\u52a8\uff0c\u89e3\u51b3\u4e863D\u9ad8\u65af\u6e32\u67d3\u4e2d\u7684\u4f2a\u5f71\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u7b80\u5355\u5730\u5c06\u9759\u60013D\u9ad8\u65af\u7ed1\u5b9a\u5230URDF\u94fe\u63a5\u4e0a\uff0c\u5f3a\u5236\u5b83\u4eec\u88ab\u52a8\u8ddf\u968fURDF\u9a71\u52a8\u7684\u8fd0\u52a8\u3002\u7136\u800c\u771f\u5b9e\u4e16\u754c\u673a\u68b0\u81c2\u8fd0\u52a8\u5b58\u5728\u566a\u58f0\uff0c\u7406\u60f3\u5316\u7684URDF\u9a71\u52a8\u8fd0\u52a8\u65e0\u6cd5\u51c6\u786e\u5efa\u6a21\uff0c\u5bfc\u81f43D\u9ad8\u65af\u6e32\u67d3\u51fa\u73b0\u4e25\u91cd\u4f2a\u5f71\u3002", "method": "\u63d0\u51faRoboArmGS\u6df7\u5408\u8868\u793a\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u7684B\u00e9zier\u66f2\u7ebf\u8fd0\u52a8\u7ec6\u5316\u5668\u6821\u6b63\u6bcf\u4e2a\u5173\u8282\u7684\u6b8b\u5dee\uff0c\u89e3\u51b3\u771f\u5b9e\u4e16\u754c\u8fd0\u52a8\u4e0eURDF\u9a71\u52a8\u8fd0\u52a8\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u5728RoboArm4D\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cRoboArmGS\u5728\u771f\u5b9e\u4e16\u754c\u8fd0\u52a8\u5efa\u6a21\u548c\u6e32\u67d3\u8d28\u91cf\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "RoboArmGS\u80fd\u591f\u5b66\u4e60\u66f4\u51c6\u786e\u7684\u771f\u5b9e\u4e16\u754c\u8fd0\u52a8\uff0c\u540c\u65f6\u5b9e\u73b0\u8de8\u673a\u68b0\u81c2\u90e8\u4ef6\u76843D\u9ad8\u65af\u7684\u8fde\u8d2f\u7ed1\u5b9a\uff0c\u4e3a\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u5b57\u8d44\u4ea7\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17939", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17939", "abs": "https://arxiv.org/abs/2511.17939", "authors": ["Yuchen Ying", "Yiyang Dai", "Wenda Li", "Wenjie Huang", "Rui Wang", "Tongya Zheng", "Yu Wang", "Hanyang Yuan", "Mingli Song"], "title": "Neural Graph Navigation for Intelligent Subgraph Matching", "comment": "Under review at AAAI 2026", "summary": "Subgraph matching, a cornerstone of relational pattern detection in domains ranging from biochemical systems to social network analysis, faces significant computational challenges due to the dramatically growing search space. Existing methods address this problem within a filtering-ordering-enumeration framework, in which the enumeration stage recursively matches the query graph against the candidate subgraphs of the data graph. However, the lack of awareness of subgraph structural patterns leads to a costly brute-force enumeration, thereby critically motivating the need for intelligent navigation in subgraph matching. To address this challenge, we propose Neural Graph Navigation (NeuGN), a neuro-heuristic framework that transforms brute-force enumeration into neural-guided search by integrating neural navigation mechanisms into the core enumeration process. By preserving heuristic-based completeness guarantees while incorporating neural intelligence, NeuGN significantly reduces the \\textit{First Match Steps} by up to 98.2\\% compared to state-of-the-art methods across six real-world datasets.", "AI": {"tldr": "NeuGN\u662f\u4e00\u4e2a\u795e\u7ecf\u542f\u53d1\u5f0f\u6846\u67b6\uff0c\u5c06\u66b4\u529b\u679a\u4e3e\u8f6c\u5316\u4e3a\u795e\u7ecf\u5f15\u5bfc\u641c\u7d22\uff0c\u901a\u8fc7\u5c06\u795e\u7ecf\u5bfc\u822a\u673a\u5236\u96c6\u6210\u5230\u6838\u5fc3\u679a\u4e3e\u8fc7\u7a0b\u4e2d\uff0c\u663e\u8457\u51cf\u5c11\u9996\u6b21\u5339\u914d\u6b65\u9aa4\u3002", "motivation": "\u73b0\u6709\u5b50\u56fe\u5339\u914d\u65b9\u6cd5\u5728\u679a\u4e3e\u9636\u6bb5\u7f3a\u4e4f\u5bf9\u5b50\u56fe\u7ed3\u6784\u6a21\u5f0f\u7684\u8ba4\u77e5\uff0c\u5bfc\u81f4\u6602\u8d35\u7684\u66b4\u529b\u679a\u4e3e\uff0c\u8feb\u5207\u9700\u8981\u667a\u80fd\u5bfc\u822a\u6765\u63d0\u5347\u6548\u7387\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u56fe\u5bfc\u822a\u6846\u67b6\uff0c\u5c06\u795e\u7ecf\u5bfc\u822a\u673a\u5236\u96c6\u6210\u5230\u679a\u4e3e\u8fc7\u7a0b\u4e2d\uff0c\u5728\u4fdd\u6301\u57fa\u4e8e\u542f\u53d1\u5f0f\u5b8c\u6574\u6027\u7684\u540c\u65f6\u878d\u5165\u795e\u7ecf\u667a\u80fd\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\uff0cNeuGN\u5c06\u9996\u6b21\u5339\u914d\u6b65\u9aa4\u51cf\u5c11\u4e86\u9ad8\u8fbe98.2%\u3002", "conclusion": "NeuGN\u901a\u8fc7\u795e\u7ecf\u5f15\u5bfc\u641c\u7d22\u6709\u6548\u89e3\u51b3\u4e86\u5b50\u56fe\u5339\u914d\u4e2d\u7684\u66b4\u529b\u679a\u4e3e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5339\u914d\u6548\u7387\u3002"}}
{"id": "2511.18551", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.18551", "abs": "https://arxiv.org/abs/2511.18551", "authors": ["Ingyu Jang", "Leila J. Bridgeman"], "title": "Dissipativity and L2 Stability of Large-Scale Networks with Changing Interconnections", "comment": "Under review for IFAC 2026. 6 pages, 2 figures, 1 table", "summary": "In this paper, the L2 stability of switched networks is studied based on the QSR-dissipativity of each agent. While the integration of dissipativity with switched systems has received considerable attention, most previous studies have focused on passivity, internal stability, or feedback networks involving only two agents. This work makes two contributions: first, the relationship between switched QSR-dissipativity and L2 stability is established based on the properties of dissipativity parameters of switched systems; and second, conditions for L2 stability of networks consisting of QSR-dissipative agents with switching interconnection topologies are derived. Crucially, this shows that a common storage function will exist across all modes, avoiding the need to find one, which becomes computationally taxing for large networks with many possible configurations. Numerical examples demonstrate how this can facilitate stability analysis for networked systems under arbitrary switching of swarm drones.", "AI": {"tldr": "\u57fa\u4e8eQSR\u8017\u6563\u6027\u5206\u6790\u5207\u6362\u7f51\u7edc\u7684L2\u7a33\u5b9a\u6027\uff0c\u5efa\u7acb\u4e86\u5207\u6362QSR\u8017\u6563\u6027\u4e0eL2\u7a33\u5b9a\u6027\u7684\u5173\u7cfb\uff0c\u5e76\u63a8\u5bfc\u4e86\u5177\u6709\u5207\u6362\u4e92\u8fde\u62d3\u6251\u7684QSR\u8017\u6563\u6027\u7f51\u7edc\u7cfb\u7edf\u7684L2\u7a33\u5b9a\u6027\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u88ab\u52a8\u6027\u3001\u5185\u90e8\u7a33\u5b9a\u6027\u6216\u4ec5\u6d89\u53ca\u4e24\u4e2a\u667a\u80fd\u4f53\u7684\u53cd\u9988\u7f51\u7edc\uff0c\u7f3a\u4e4f\u5bf9\u5177\u6709\u5207\u6362\u4e92\u8fde\u62d3\u6251\u7684QSR\u8017\u6563\u6027\u7f51\u7edc\u7cfb\u7edfL2\u7a33\u5b9a\u6027\u7684\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u5207\u6362\u7cfb\u7edf\u7684\u8017\u6563\u6027\u53c2\u6570\u7279\u6027\uff0c\u5efa\u7acb\u5207\u6362QSR\u8017\u6563\u6027\u4e0eL2\u7a33\u5b9a\u6027\u7684\u5173\u7cfb\uff0c\u63a8\u5bfc\u5177\u6709\u5207\u6362\u4e92\u8fde\u62d3\u6251\u7684QSR\u8017\u6563\u6027\u7f51\u7edc\u7cfb\u7edf\u7684L2\u7a33\u5b9a\u6027\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u6240\u6709\u6a21\u5f0f\u4e0b\u5b58\u5728\u5171\u540c\u7684\u5b58\u50a8\u51fd\u6570\uff0c\u907f\u514d\u4e86\u4e3a\u5927\u578b\u7f51\u7edc\u5bfb\u627e\u5b58\u50a8\u51fd\u6570\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u7fa4\u65e0\u4eba\u673a\u4efb\u610f\u5207\u6362\u4e0b\u7684\u7a33\u5b9a\u6027\u5206\u6790\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5177\u6709\u5207\u6362\u4e92\u8fde\u62d3\u6251\u7684\u7f51\u7edc\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684L2\u7a33\u5b9a\u6027\u5206\u6790\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u7f51\u7edc\u7cfb\u7edf\u3002"}}
{"id": "2511.17736", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.17736", "abs": "https://arxiv.org/abs/2511.17736", "authors": ["H. R. Paz"], "title": "When Administrative Networks Fail: Curriculum Structure, Early Performance, and the Limits of Co-enrolment Social Synchrony for Dropout Prediction in Engineering Education", "comment": null, "summary": "Social integration theories suggest that students embedded in supportive peer networks are less likely to drop out. In learning analytics, this has motivated the use of social network analysis (SNA) from institutional co-enrolment data to predict attrition. This study tests whether such administrative network features add predictive value beyond a leakage-aware, curriculum-graph-informed model in a long-cycle Civil Engineering programme at a public university in Argentina. Using a three-semester observation window and a 16-fold leave-cohort-out design on 1,343 students across 15 cohorts, we compare four configurations: a baseline model (M0), baseline plus network features (M1), baseline plus curriculum-graph features (M2), and a full model (M3). After a leakage audit removed two post-outcome variables that had produced implausibly perfect performance, retrained models show that M0 and M2 achieve F1 = 0.9411 and ROC-AUC = 0.9776, while adding network features systematically degrades performance (M1 and M3: F1 = 0.9367; ROC-AUC = 0.9768). We conclude that in curriculum-constrained programmes, administrative co-enrolment SNA does not provide additional risk information beyond curriculum topology and early academic performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6d4b\u8bd5\u4e86\u5728\u571f\u6728\u5de5\u7a0b\u957f\u5468\u671f\u8bfe\u7a0b\u4e2d\uff0c\u57fa\u4e8e\u884c\u653f\u5171\u6ce8\u518c\u6570\u636e\u7684\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u7279\u5f81\u662f\u5426\u80fd\u5728\u8003\u8651\u8bfe\u7a0b\u56fe\u4fe1\u606f\u7684\u57fa\u7ebf\u6a21\u578b\u57fa\u7840\u4e0a\u63d0\u5347\u5b66\u751f\u6d41\u5931\u9884\u6d4b\u6027\u80fd\u3002\u7ed3\u679c\u663e\u793a\u6dfb\u52a0\u7f51\u7edc\u7279\u5f81\u53cd\u800c\u964d\u4f4e\u4e86\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u793e\u4f1a\u6574\u5408\u7406\u8bba\u8ba4\u4e3a\u5d4c\u5165\u652f\u6301\u6027\u540c\u4f34\u7f51\u7edc\u7684\u5b66\u751f\u66f4\u5c11\u8f8d\u5b66\uff0c\u8fd9\u4fc3\u4f7f\u5b66\u4e60\u5206\u6790\u9886\u57df\u4f7f\u7528\u884c\u653f\u5171\u6ce8\u518c\u6570\u636e\u7684\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u6765\u9884\u6d4b\u5b66\u751f\u6d41\u5931\u3002\u672c\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u6b64\u7c7b\u7f51\u7edc\u7279\u5f81\u662f\u5426\u80fd\u5728\u8003\u8651\u8bfe\u7a0b\u62d3\u6251\u7684\u57fa\u7ebf\u6a21\u578b\u4e4b\u5916\u63d0\u4f9b\u989d\u5916\u9884\u6d4b\u4ef7\u503c\u3002", "method": "\u4f7f\u7528\u963f\u6839\u5ef7\u516c\u7acb\u5927\u5b66\u571f\u6728\u5de5\u7a0b\u4e13\u4e1a\u76841,343\u540d\u5b66\u751f\u6570\u636e\uff0c\u91c7\u7528\u4e09\u5b66\u671f\u89c2\u5bdf\u7a97\u53e3\u548c16\u6298\u7559\u7ec4\u4ea4\u53c9\u9a8c\u8bc1\u8bbe\u8ba1\uff0c\u6bd4\u8f83\u56db\u4e2a\u6a21\u578b\u914d\u7f6e\uff1a\u57fa\u7ebf\u6a21\u578b\u3001\u57fa\u7ebf\u52a0\u7f51\u7edc\u7279\u5f81\u3001\u57fa\u7ebf\u52a0\u8bfe\u7a0b\u56fe\u7279\u5f81\u3001\u5b8c\u6574\u6a21\u578b\u3002", "result": "\u7ecf\u8fc7\u6570\u636e\u6cc4\u9732\u5ba1\u8ba1\u540e\uff0c\u57fa\u7ebf\u6a21\u578b\u548c\u8bfe\u7a0b\u56fe\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08F1=0.9411\uff0cROC-AUC=0.9776\uff09\uff0c\u800c\u6dfb\u52a0\u7f51\u7edc\u7279\u5f81\u7684\u7cfb\u7edf\u6027\u964d\u4f4e\u4e86\u6a21\u578b\u6027\u80fd\uff08F1=0.9367\uff0cROC-AUC=0.9768\uff09\u3002", "conclusion": "\u5728\u8bfe\u7a0b\u7ea6\u675f\u6027\u5f3a\u7684\u4e13\u4e1a\u4e2d\uff0c\u884c\u653f\u5171\u6ce8\u518c\u6570\u636e\u7684\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u65e0\u6cd5\u5728\u8bfe\u7a0b\u62d3\u6251\u548c\u65e9\u671f\u5b66\u4e1a\u8868\u73b0\u4e4b\u5916\u63d0\u4f9b\u989d\u5916\u7684\u98ce\u9669\u4fe1\u606f\u3002"}}
{"id": "2511.17992", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17992", "abs": "https://arxiv.org/abs/2511.17992", "authors": ["Chungeng Tian", "Fenghua He", "Ning Hao"], "title": "Unobservable Subspace Evolution and Alignment for Consistent Visual-Inertial Navigation", "comment": "20 pages, 16 figures", "summary": "The inconsistency issue in the Visual-Inertial Navigation System (VINS) is a long-standing and fundamental challenge. While existing studies primarily attribute the inconsistency to observability mismatch, these analyses are often based on simplified theoretical formulations that consider only prediction and SLAM correction. Such formulations fail to cover the non-standard estimation steps, such as MSCKF correction and delayed initialization, which are critical for practical VINS estimators. Furthermore, the lack of a comprehensive understanding of how inconsistency dynamically emerges across estimation steps has hindered the development of precise and efficient solutions. As a result, current approaches often face a trade-off between estimator accuracy, consistency, and implementation complexity. To address these limitations, this paper proposes a novel analysis framework termed Unobservable Subspace Evolution (USE), which systematically characterizes how the unobservable subspace evolves throughout the entire estimation pipeline by explicitly tracking changes in its evaluation points. This perspective sheds new light on how individual estimation steps contribute to inconsistency. Our analysis reveals that observability misalignment induced by certain steps is the antecedent of observability mismatch. Guided by this insight, we propose a simple yet effective solution paradigm, Unobservable Subspace Alignment (USA), which eliminates inconsistency by selectively intervening only in those estimation steps that induce misalignment. We design two USA methods: transformation-based and re-evaluation-based, both offering accurate and computationally lightweight solutions. Extensive simulations and real-world experiments validate the effectiveness of the proposed methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86USE\u5206\u6790\u6846\u67b6\u548cUSA\u89e3\u51b3\u65b9\u6848\u6765\u89e3\u51b3VINS\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u8ddf\u8e2a\u4e0d\u53ef\u89c2\u6d4b\u5b50\u7a7a\u95f4\u7684\u6f14\u5316\u5e76\u9009\u62e9\u6027\u5e72\u9884\u6765\u6d88\u9664\u4e0d\u4e00\u81f4\u6027\u3002", "motivation": "VINS\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u662f\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u6839\u672c\u6311\u6218\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5f52\u56e0\u4e8e\u53ef\u89c2\u6d4b\u6027\u5931\u914d\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e0d\u4e00\u81f4\u6027\u5982\u4f55\u5728\u5404\u4e2a\u4f30\u8ba1\u6b65\u9aa4\u4e2d\u52a8\u6001\u4ea7\u751f\u7684\u5168\u9762\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u4e0d\u53ef\u89c2\u6d4b\u5b50\u7a7a\u95f4\u6f14\u5316(USE)\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u8ddf\u8e2a\u8bc4\u4f30\u70b9\u53d8\u5316\u6765\u7cfb\u7edf\u8868\u5f81\u4e0d\u53ef\u89c2\u6d4b\u5b50\u7a7a\u95f4\u5728\u6574\u4e2a\u4f30\u8ba1\u6d41\u7a0b\u4e2d\u7684\u6f14\u5316\uff1b\u5e76\u63d0\u51fa\u4e86\u4e0d\u53ef\u89c2\u6d4b\u5b50\u7a7a\u95f4\u5bf9\u9f50(USA)\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u57fa\u4e8e\u53d8\u6362\u548c\u57fa\u4e8e\u91cd\u8bc4\u4f30\u7684\u4e24\u79cd\u65b9\u6cd5\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u67d0\u4e9b\u6b65\u9aa4\u5f15\u8d77\u7684\u53ef\u89c2\u6d4b\u6027\u9519\u4f4d\u662f\u53ef\u89c2\u6d4b\u6027\u5931\u914d\u7684\u524d\u56e0\uff1b\u63d0\u51fa\u7684USA\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u5e72\u9884\u6d88\u9664\u4e0d\u4e00\u81f4\u6027\uff0c\u63d0\u4f9b\u4e86\u51c6\u786e\u4e14\u8ba1\u7b97\u8f7b\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "USE\u6846\u67b6\u4e3a\u7406\u89e3VINS\u4e0d\u4e00\u81f4\u6027\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0cUSA\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002"}}
{"id": "2511.17947", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.17947", "abs": "https://arxiv.org/abs/2511.17947", "authors": ["Yining Yuan", "J. Ben Tamo", "Micky C. Nnamdi", "Yifei Wang", "May D. Wang"], "title": "Leveraging Evidence-Guided LLMs to Enhance Trustworthy Depression Diagnosis", "comment": null, "summary": "Large language models (LLMs) show promise in automating clinical diagnosis, yet their non-transparent decision-making and limited alignment with diagnostic standards hinder trust and clinical adoption. We address this challenge by proposing a two-stage diagnostic framework that enhances transparency, trustworthiness, and reliability. First, we introduce Evidence-Guided Diagnostic Reasoning (EGDR), which guides LLMs to generate structured diagnostic hypotheses by interleaving evidence extraction with logical reasoning grounded in DSM-5 criteria. Second, we propose a Diagnosis Confidence Scoring (DCS) module that evaluates the factual accuracy and logical consistency of generated diagnoses through two interpretable metrics: the Knowledge Attribution Score (KAS) and the Logic Consistency Score (LCS). Evaluated on the D4 dataset with pseudo-labels, EGDR outperforms direct in-context prompting and Chain-of-Thought (CoT) across five LLMs. For instance, on OpenBioLLM, EGDR improves accuracy from 0.31 (Direct) to 0.76 and increases DCS from 0.50 to 0.67. On MedLlama, DCS rises from 0.58 (CoT) to 0.77. Overall, EGDR yields up to +45% accuracy and +36% DCS gains over baseline methods, offering a clinically grounded, interpretable foundation for trustworthy AI-assisted diagnosis.", "AI": {"tldr": "\u63d0\u51faEGDR\u4e24\u9636\u6bb5\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u8bc1\u636e\u5f15\u5bfc\u7684\u8bca\u65ad\u63a8\u7406\u548c\u8bca\u65ad\u7f6e\u4fe1\u5ea6\u8bc4\u5206\uff0c\u63d0\u9ad8LLM\u5728\u4e34\u5e8a\u8bca\u65ad\u4e2d\u7684\u900f\u660e\u5ea6\u3001\u53ef\u4fe1\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u5728D4\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u534745%\uff0c\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u63d0\u534736%\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u4e34\u5e8a\u8bca\u65ad\u4e2d\u51b3\u7b56\u4e0d\u900f\u660e\u3001\u4e0e\u8bca\u65ad\u6807\u51c6\u5bf9\u9f50\u6709\u9650\u7684\u95ee\u9898\uff0c\u589e\u5f3a\u4e34\u5e8a\u4fe1\u4efb\u5ea6\u548c\u91c7\u7528\u5ea6\u3002", "method": "1. \u8bc1\u636e\u5f15\u5bfc\u8bca\u65ad\u63a8\u7406(EGDR)\uff1a\u6307\u5bfcLLM\u57fa\u4e8eDSM-5\u6807\u51c6\u4ea4\u66ff\u8fdb\u884c\u8bc1\u636e\u63d0\u53d6\u548c\u903b\u8f91\u63a8\u7406\uff0c\u751f\u6210\u7ed3\u6784\u5316\u8bca\u65ad\u5047\u8bbe\uff1b2. \u8bca\u65ad\u7f6e\u4fe1\u5ea6\u8bc4\u5206(DCS)\uff1a\u901a\u8fc7\u77e5\u8bc6\u5f52\u56e0\u5206\u6570(KAS)\u548c\u903b\u8f91\u4e00\u81f4\u6027\u5206\u6570(LCS)\u8bc4\u4f30\u8bca\u65ad\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u3002", "result": "\u5728D4\u6570\u636e\u96c6\u4e0a\uff0cEGDR\u4f18\u4e8e\u76f4\u63a5\u4e0a\u4e0b\u6587\u63d0\u793a\u548c\u601d\u7ef4\u94fe\u65b9\u6cd5\u3002OpenBioLLM\u51c6\u786e\u7387\u4ece0.31\u63d0\u5347\u81f30.76\uff0cDCS\u4ece0.50\u63d0\u5347\u81f30.67\uff1bMedLlama\u7684DCS\u4ece0.58\u63d0\u5347\u81f30.77\u3002", "conclusion": "EGDR\u4e3a\u53ef\u4fe1\u8d56\u7684AI\u8f85\u52a9\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e34\u5e8a\u57fa\u7840\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2511.18573", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18573", "abs": "https://arxiv.org/abs/2511.18573", "authors": ["Yiying He", "Zhiqiang Zuo", "Yianni Alissandratos", "Penny Willson", "Shameem Kazmi", "Alex P. S. Brogan", "Miao Guo"], "title": "Beyond the Expiry Date: Uncovering Hidden Value in Functional Drink Waste for a Circular Future", "comment": null, "summary": "Expired functional drinks have great valorisation potential due to the high concentration of organic molecules present. However, detailed information of the resources in these expired functional drinks is limited, hindering the rational design of a recovery system. To address this gap, we present here a study that comprehensively characterises the chemical composition of functional drinks and discus their potential use as feedstocks for biomethane production. The example functional drinks were abundant in sugars, organic acids, and amino acids, and were especially rich in glucose, fructose, and alanine. Our studies revealed that functional drinks with high COD values that corresponded to high proportions of sugar and organic acid and low proportions of sorbitol and amino acids could realise profitable recovery through anaerobic digestion, with a minimum biomethane yield of 11.72 mL CH4 / mL drink. To assess utility further we also examined the dynamic composition of functional drinks up to 16 weeks (at 4 \u00b0C) after expiration to capture the shift in resources during deterioration. In doing so, we identified 4 distinct periods of carbon resource variation: 1) chemically stable period, 2) sorbitol degradation period, 3) sugar degradation period, and 4) acidification period. Based on the time-course biomethane production experiments for expired functional drinks, the optimal operating time window for biomethane production from drinks without ascorbic acid would be after sorbitol degradation period in terms of its economic performance through convenient natural deterioration. Therefore, this comprehensive study on dynamic chemical composition in expired functional drinks and their biomethane production potential could facilitate a rational design of resource recovery system for soft drink field.", "AI": {"tldr": "\u8fc7\u671f\u529f\u80fd\u996e\u6599\u5bcc\u542b\u6709\u673a\u5206\u5b50\uff0c\u5177\u6709\u8d44\u6e90\u5316\u6f5c\u529b\u3002\u7814\u7a76\u53d1\u73b0\u529f\u80fd\u996e\u6599\u5bcc\u542b\u7cd6\u7c7b\u3001\u6709\u673a\u9178\u548c\u6c28\u57fa\u9178\uff0c\u7279\u522b\u5bcc\u542b\u8461\u8404\u7cd6\u3001\u679c\u7cd6\u548c\u4e19\u6c28\u9178\u3002\u9ad8COD\u503c\u4e14\u7cd6\u548c\u6709\u673a\u9178\u6bd4\u4f8b\u9ad8\u3001\u5c71\u68a8\u9187\u548c\u6c28\u57fa\u9178\u6bd4\u4f8b\u4f4e\u7684\u529f\u80fd\u996e\u6599\u53ef\u901a\u8fc7\u538c\u6c27\u6d88\u5316\u5b9e\u73b0\u76c8\u5229\u6027\u56de\u6536\uff0c\u6700\u4f4e\u751f\u7269\u7532\u70f7\u4ea7\u91cf\u4e3a11.72 mL CH4/mL\u996e\u6599\u3002", "motivation": "\u8fc7\u671f\u529f\u80fd\u996e\u6599\u542b\u6709\u9ad8\u6d53\u5ea6\u6709\u673a\u5206\u5b50\uff0c\u5177\u6709\u5f88\u5927\u7684\u8d44\u6e90\u5316\u6f5c\u529b\uff0c\u4f46\u76ee\u524d\u5bf9\u8fd9\u4e9b\u996e\u6599\u4e2d\u8d44\u6e90\u7684\u8be6\u7ec6\u4fe1\u606f\u6709\u9650\uff0c\u963b\u788d\u4e86\u56de\u6536\u7cfb\u7edf\u7684\u5408\u7406\u8bbe\u8ba1\u3002", "method": "\u5168\u9762\u8868\u5f81\u529f\u80fd\u996e\u6599\u7684\u5316\u5b66\u6210\u5206\uff0c\u8bc4\u4f30\u5176\u4f5c\u4e3a\u751f\u7269\u7532\u70f7\u751f\u4ea7\u539f\u6599\u7684\u6f5c\u529b\uff0c\u5e76\u7814\u7a76\u8fc7\u671f\u540e16\u5468\u5185\uff084\u00b0C\uff09\u52a8\u6001\u7ec4\u6210\u53d8\u5316\uff0c\u901a\u8fc7\u65f6\u95f4\u8fc7\u7a0b\u751f\u7269\u7532\u70f7\u751f\u4ea7\u5b9e\u9a8c\u786e\u5b9a\u6700\u4f73\u64cd\u4f5c\u65f6\u95f4\u7a97\u53e3\u3002", "result": "\u8bc6\u522b\u51fa4\u4e2a\u4e0d\u540c\u7684\u78b3\u8d44\u6e90\u53d8\u5316\u65f6\u671f\uff1a1\uff09\u5316\u5b66\u7a33\u5b9a\u671f\uff0c2\uff09\u5c71\u68a8\u9187\u964d\u89e3\u671f\uff0c3\uff09\u7cd6\u964d\u89e3\u671f\uff0c4\uff09\u9178\u5316\u671f\u3002\u4e0d\u542b\u6297\u574f\u8840\u9178\u996e\u6599\u7684\u6700\u4f73\u751f\u7269\u7532\u70f7\u751f\u4ea7\u65f6\u95f4\u7a97\u53e3\u662f\u5728\u5c71\u68a8\u9187\u964d\u89e3\u671f\u4e4b\u540e\u3002", "conclusion": "\u8fd9\u9879\u5173\u4e8e\u8fc7\u671f\u529f\u80fd\u996e\u6599\u52a8\u6001\u5316\u5b66\u6210\u5206\u53ca\u5176\u751f\u7269\u7532\u70f7\u751f\u4ea7\u6f5c\u529b\u7684\u5168\u9762\u7814\u7a76\uff0c\u53ef\u4e3a\u8f6f\u996e\u6599\u9886\u57df\u7684\u8d44\u6e90\u56de\u6536\u7cfb\u7edf\u63d0\u4f9b\u5408\u7406\u8bbe\u8ba1\u4f9d\u636e\u3002"}}
{"id": "2511.17920", "categories": ["cs.CY", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17920", "abs": "https://arxiv.org/abs/2511.17920", "authors": ["Hamza Alshamy", "Isaiah Woram", "Advay Mishra", "Zihan Xia", "Pascal Wallisch"], "title": "Animated Territorial Data Extractor (ATDE): A Computer-Vision Method for Extracting Territorial Data from Animated Historical Maps", "comment": "11 pages, 5 figures", "summary": "We present Animated Territorial Data Extractor (ATDE), a computer vision tool that extracts quantitative territorial data from animated historical map videos. ATDE employs HSV-based color segmentation, RGB channel filtering, and Direct-Neighbor Filtering to identify and count pixels representing territorial control. Combined with preprocessing for temporal alignment and cross-video scaling, the pipeline converts animated videos into structured time-series data. We demonstrate the tool on ten Chinese dynasties (200 BCE - 1912 CE), producing year-by-year pixel counts that align with expected historical patterns. While not a substitute for authoritative historical datasets, ATDE is well-suited for educational demonstrations, preliminary data exploration, and comparative analysis of territorial dynamics. The tool requires no pre-existing shapefiles and can be applied to any animated map video given seed colors and basic configuration. Code and examples are available on GitHub.", "AI": {"tldr": "ATDE\u662f\u4e00\u4e2a\u4ece\u52a8\u753b\u5386\u53f2\u5730\u56fe\u89c6\u9891\u4e2d\u63d0\u53d6\u9886\u571f\u6570\u636e\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u5de5\u5177\uff0c\u901a\u8fc7\u989c\u8272\u5206\u5272\u548c\u8fc7\u6ee4\u6280\u672f\u8bc6\u522b\u9886\u571f\u63a7\u5236\u50cf\u7d20\uff0c\u5c06\u52a8\u753b\u89c6\u9891\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u65e0\u9700\u9884\u5b9a\u4e49\u5f62\u72b6\u6587\u4ef6\u5c31\u80fd\u4ece\u52a8\u753b\u5386\u53f2\u5730\u56fe\u89c6\u9891\u4e2d\u63d0\u53d6\u5b9a\u91cf\u9886\u571f\u6570\u636e\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u6559\u80b2\u6f14\u793a\u3001\u521d\u6b65\u6570\u636e\u63a2\u7d22\u548c\u9886\u571f\u52a8\u6001\u6bd4\u8f83\u5206\u6790\u3002", "method": "\u4f7f\u7528HSV\u989c\u8272\u5206\u5272\u3001RGB\u901a\u9053\u8fc7\u6ee4\u548c\u76f4\u63a5\u90bb\u5c45\u8fc7\u6ee4\u6765\u8bc6\u522b\u548c\u8ba1\u6570\u4ee3\u8868\u9886\u571f\u63a7\u5236\u7684\u50cf\u7d20\uff0c\u7ed3\u5408\u65f6\u95f4\u5bf9\u9f50\u548c\u8de8\u89c6\u9891\u7f29\u653e\u7684\u9884\u5904\u7406\u6d41\u7a0b\u3002", "result": "\u5728\u5341\u4e2a\u4e2d\u56fd\u671d\u4ee3\uff08\u516c\u5143\u524d200\u5e74\u81f31912\u5e74\uff09\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u5de5\u5177\uff0c\u751f\u6210\u7684\u9010\u5e74\u50cf\u7d20\u8ba1\u6570\u4e0e\u9884\u671f\u5386\u53f2\u6a21\u5f0f\u76f8\u7b26\u3002", "conclusion": "ATDE\u867d\u7136\u4e0d\u662f\u6743\u5a01\u5386\u53f2\u6570\u636e\u96c6\u7684\u66ff\u4ee3\u54c1\uff0c\u4f46\u9002\u7528\u4e8e\u6559\u80b2\u6f14\u793a\u3001\u521d\u6b65\u6570\u636e\u63a2\u7d22\u548c\u9886\u571f\u52a8\u6001\u6bd4\u8f83\u5206\u6790\uff0c\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u7ed9\u5b9a\u79cd\u5b50\u989c\u8272\u548c\u57fa\u672c\u914d\u7f6e\u7684\u52a8\u753b\u5730\u56fe\u89c6\u9891\u3002"}}
{"id": "2511.18085", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18085", "abs": "https://arxiv.org/abs/2511.18085", "authors": ["Yuxuan Wu", "Guangming Wang", "Zhiheng Yang", "Maoqing Yao", "Brian Sheil", "Hesheng Wang"], "title": "Continually Evolving Skill Knowledge in Vision Language Action Model", "comment": null, "summary": "Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models leverage massive pretraining data to support diverse manipulation tasks, but they still depend heavily on task-specific fine-tuning, revealing a lack of continual learning capability. Existing continual learning methods are also resource-intensive to scale to VLA models. We propose Stellar VLA, a knowledge-driven continual learning framework with two variants: T-Stellar, modeling task-centric knowledge space, and TS-Stellar, capturing hierarchical task-skill structure. Stellar VLA enables self-supervised knowledge evolution through joint learning of task latent representation and the knowledge space, reducing annotation needs. Knowledge-guided expert routing provide task specialization without extra network parameters, lowering training overhead.Experiments on the LIBERO benchmark and real-world tasks show over 50 percentage average improvement in final success rates relative to baselines. TS-Stellar further excels in complex action inference, and in-depth analyses verify effective knowledge retention and discovery. Our code will be released soon.", "AI": {"tldr": "Stellar VLA\u662f\u4e00\u4e2a\u77e5\u8bc6\u9a71\u52a8\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u6f5c\u5728\u8868\u793a\u548c\u77e5\u8bc6\u7a7a\u95f4\u7684\u8054\u5408\u5b66\u4e60\u5b9e\u73b0\u81ea\u76d1\u7763\u77e5\u8bc6\u6f14\u5316\uff0c\u5728\u673a\u5668\u4eba\u5f00\u653e\u73af\u5883\u4e2d\u5b9e\u73b0\u6301\u7eed\u6280\u80fd\u5b66\u4e60\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728\u6700\u7ec8\u6210\u529f\u7387\u4e0a\u63d0\u5347\u8d85\u8fc750%\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u867d\u7136\u652f\u6301\u591a\u6837\u5316\u64cd\u4f5c\u4efb\u52a1\uff0c\u4f46\u4e25\u91cd\u4f9d\u8d56\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\uff0c\u7f3a\u4e4f\u6301\u7eed\u5b66\u4e60\u80fd\u529b\uff0c\u4e14\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\u5230VLA\u6a21\u578b\u3002", "method": "\u63d0\u51faStellar VLA\u6846\u67b6\uff0c\u5305\u542bT-Stellar\uff08\u5efa\u6a21\u4efb\u52a1\u4e2d\u5fc3\u77e5\u8bc6\u7a7a\u95f4\uff09\u548cTS-Stellar\uff08\u6355\u83b7\u5206\u5c42\u4efb\u52a1-\u6280\u80fd\u7ed3\u6784\uff09\uff0c\u901a\u8fc7\u77e5\u8bc6\u5f15\u5bfc\u7684\u4e13\u5bb6\u8def\u7531\u5b9e\u73b0\u4efb\u52a1\u4e13\u4e1a\u5316\uff0c\u65e0\u9700\u989d\u5916\u7f51\u7edc\u53c2\u6570\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u6700\u7ec8\u6210\u529f\u7387\u63d0\u5347\u8d85\u8fc750%\uff0cTS-Stellar\u5728\u590d\u6742\u52a8\u4f5c\u63a8\u7406\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff0c\u9a8c\u8bc1\u4e86\u6709\u6548\u7684\u77e5\u8bc6\u4fdd\u7559\u548c\u53d1\u73b0\u3002", "conclusion": "Stellar VLA\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u9a71\u52a8\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86VLA\u6a21\u578b\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\uff0c\u964d\u4f4e\u4e86\u8bad\u7ec3\u5f00\u9500\u548c\u6807\u6ce8\u9700\u6c42\u3002"}}
{"id": "2511.17990", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17990", "abs": "https://arxiv.org/abs/2511.17990", "authors": ["Mingyu Jeon", "Jaeyoung Suh", "Suwan Cho", "Dohyeon Kim"], "title": "How Far Can LLMs Emulate Human Behavior?: A Strategic Analysis via the Buy-and-Sell Negotiation Game", "comment": null, "summary": "With the rapid advancement of Large Language Models (LLMs), recent studies have drawn attention to their potential for handling not only simple question-answer tasks but also more complex conversational abilities and performing human-like behavioral imitations. In particular, there is considerable interest in how accurately LLMs can reproduce real human emotions and behaviors, as well as whether such reproductions can function effectively in real-world scenarios. However, existing benchmarks focus primarily on knowledge-based assessment and thus fall short of sufficiently reflecting social interactions and strategic dialogue capabilities. To address these limitations, this work proposes a methodology to quantitatively evaluate the human emotional and behavioral imitation and strategic decision-making capabilities of LLMs by employing a Buy and Sell negotiation simulation. Specifically, we assign different personas to multiple LLMs and conduct negotiations between a Buyer and a Seller, comprehensively analyzing outcomes such as win rates, transaction prices, and SHAP values. Our experimental results show that models with higher existing benchmark scores tend to achieve better negotiation performance overall, although some models exhibit diminished performance in scenarios emphasizing emotional or social contexts. Moreover, competitive and cunning traits prove more advantageous for negotiation outcomes than altruistic and cooperative traits, suggesting that the assigned persona can lead to significant variations in negotiation strategies and results. Consequently, this study introduces a new evaluation approach for LLMs' social behavior imitation and dialogue strategies, and demonstrates how negotiation simulations can serve as a meaningful complementary metric to measure real-world interaction capabilities-an aspect often overlooked in existing benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4e70\u5356\u8c08\u5224\u6a21\u62df\u6765\u5b9a\u91cf\u8bc4\u4f30LLMs\u7684\u4eba\u7c7b\u60c5\u611f\u884c\u4e3a\u6a21\u4eff\u548c\u6218\u7565\u51b3\u7b56\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u5206\u6570\u9ad8\u7684\u6a21\u578b\u8c08\u5224\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u7ade\u4e89\u6027\u4eba\u683c\u6bd4\u5408\u4f5c\u6027\u4eba\u683c\u5728\u8c08\u5224\u4e2d\u66f4\u6709\u5229\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u77e5\u8bc6\u8bc4\u4f30\uff0c\u672a\u80fd\u5145\u5206\u53cd\u6620LLMs\u5728\u793e\u4ea4\u4e92\u52a8\u548c\u6218\u7565\u5bf9\u8bdd\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5bf9\u4eba\u7c7b\u60c5\u611f\u548c\u884c\u4e3a\u7684\u6a21\u4eff\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7ed9\u591a\u4e2aLLMs\u5206\u914d\u4e0d\u540c\u4eba\u683c\u89d2\u8272\uff0c\u5728\u4e70\u65b9\u548c\u5356\u65b9\u4e4b\u95f4\u8fdb\u884c\u8c08\u5224\u6a21\u62df\uff0c\u7efc\u5408\u5206\u6790\u80dc\u7387\u3001\u4ea4\u6613\u4ef7\u683c\u548cSHAP\u503c\u7b49\u7ed3\u679c\u3002", "result": "\u73b0\u6709\u57fa\u51c6\u5206\u6570\u9ad8\u7684\u6a21\u578b\u603b\u4f53\u8c08\u5224\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u6709\u4e9b\u6a21\u578b\u5728\u5f3a\u8c03\u60c5\u611f\u6216\u793e\u4ea4\u60c5\u5883\u4e0b\u8868\u73b0\u4e0b\u964d\uff1b\u7ade\u4e89\u6027\u548c\u72e1\u733e\u7279\u8d28\u6bd4\u5229\u4ed6\u548c\u5408\u4f5c\u7279\u8d28\u5728\u8c08\u5224\u4e2d\u66f4\u5177\u4f18\u52bf\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aLLMs\u7684\u793e\u4f1a\u884c\u4e3a\u6a21\u4eff\u548c\u5bf9\u8bdd\u7b56\u7565\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8bc1\u660e\u8c08\u5224\u6a21\u62df\u53ef\u4ee5\u4f5c\u4e3a\u8861\u91cf\u73b0\u5b9e\u4e16\u754c\u4e92\u52a8\u80fd\u529b\u7684\u6709\u610f\u4e49\u8865\u5145\u6307\u6807\u3002"}}
{"id": "2511.18579", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18579", "abs": "https://arxiv.org/abs/2511.18579", "authors": ["Kooktae Lee", "Ethan Brook"], "title": "Connectivity-Preserving Multi-Agent Area Coverage via Optimal-Transport-Based Density-Driven Optimal Control (D2OC)", "comment": "Under review in IEEE Control Systems Letters (LCSS). 6 pages", "summary": "Multi-agent systems play a central role in area coverage tasks across search-and-rescue, environmental monitoring, and precision agriculture. Achieving non-uniform coverage, where spatial priorities vary across the domain, requires coordinating agents while respecting dynamic and communication constraints. Density-driven approaches can distribute agents according to a prescribed reference density, but existing methods do not ensure connectivity. This limitation often leads to communication loss, reduced coordination, and degraded coverage performance.\n  This letter introduces a connectivity-preserving extension of the Density-Driven Optimal Control (D2OC) framework. The coverage objective, defined using the Wasserstein distance between the agent distribution and the reference density, admits a convex quadratic program formulation. Communication constraints are incorporated through a smooth connectivity penalty, which maintains strict convexity, supports distributed implementation, and preserves inter-agent communication without imposing rigid formations.\n  Simulation studies show that the proposed method consistently maintains connectivity, improves convergence speed, and enhances non-uniform coverage quality compared with density-driven schemes that do not incorporate explicit connectivity considerations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4fdd\u6301\u8fde\u901a\u6027\u7684\u5bc6\u5ea6\u9a71\u52a8\u6700\u4f18\u63a7\u5236\u6846\u67b6\u6269\u5c55\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u975e\u5747\u5300\u8986\u76d6\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u901a\u4fe1\u4e22\u5931\u7684\u95ee\u9898\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u975e\u5747\u5300\u8986\u76d6\u4efb\u52a1\u4e2d\u9700\u8981\u534f\u8c03\u667a\u80fd\u4f53\u540c\u65f6\u6ee1\u8db3\u52a8\u6001\u548c\u901a\u4fe1\u7ea6\u675f\uff0c\u73b0\u6709\u5bc6\u5ea6\u9a71\u52a8\u65b9\u6cd5\u65e0\u6cd5\u786e\u4fdd\u8fde\u901a\u6027\uff0c\u5bfc\u81f4\u901a\u4fe1\u4e22\u5931\u3001\u534f\u8c03\u51cf\u5c11\u548c\u8986\u76d6\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5728\u5bc6\u5ea6\u9a71\u52a8\u6700\u4f18\u63a7\u5236\u6846\u67b6\u4e2d\u5f15\u5165\u5e73\u6ed1\u8fde\u901a\u6027\u60e9\u7f5a\u9879\uff0c\u4fdd\u6301\u4e25\u683c\u51f8\u6027\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u5b9e\u73b0\uff0c\u901a\u8fc7Wasserstein\u8ddd\u79bb\u5b9a\u4e49\u8986\u76d6\u76ee\u6807\u5e76\u91c7\u7528\u51f8\u4e8c\u6b21\u89c4\u5212\u516c\u5f0f\u3002", "result": "\u4eff\u771f\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6301\u7eed\u4fdd\u6301\u8fde\u901a\u6027\uff0c\u63d0\u9ad8\u6536\u655b\u901f\u5ea6\uff0c\u76f8\u6bd4\u4e0d\u8003\u8651\u8fde\u901a\u6027\u7684\u5bc6\u5ea6\u9a71\u52a8\u65b9\u6848\u663e\u8457\u63d0\u5347\u4e86\u975e\u5747\u5300\u8986\u76d6\u8d28\u91cf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8fde\u901a\u6027\u4fdd\u6301\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u8986\u76d6\u4efb\u52a1\u4e2d\u7684\u901a\u4fe1\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8fde\u901a\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e86\u8986\u76d6\u6027\u80fd\u548c\u6536\u655b\u6548\u7387\u3002"}}
{"id": "2511.18145", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.18145", "abs": "https://arxiv.org/abs/2511.18145", "authors": ["H. R. Paz"], "title": "CAPIRE Intervention Lab: An Agent-Based Policy Simulation Environment for Curriculum-Constrained Engineering Programmes", "comment": "33 pages, 3 tables, 2 figures", "summary": "Engineering programmes in Latin America combine high structural rigidity, intense assessment cultures and persistent socio-economic inequality, producing dropout rates that remain stubbornly high despite increasingly accurate early-warning models. Predictive learning analytics can identify students at risk, but they offer limited guidance on which concrete combinations of policies should be implemented, when, and for whom. This paper presents the CAPIRE Intervention Lab, an agent-based simulation environment designed to complement predictive models with in silico experimentation on curriculum and teaching policies in a Civil Engineering programme. The model is calibrated on 1,343 students from 15 cohorts in a six-year programme with 34 courses and 12 simulated semesters. Agents are initialised from empirically derived trajectory archetypes and embedded in a curriculum graph with structural friction indicators, including backbone completion, blocked credits and distance to graduation. Each agent evolves under combinations of three policy dimensions: (A) curriculum and assessment structure, (B) teaching and academic support, and (C) psychosocial and financial support. A 2x2x2 factorial design with 100 replications per scenario yields over 80,000 simulated trajectories. Results show that policy bundles targeting early backbone courses and blocked credits can reduce long-term dropout by approximately three percentage points and substantially increase the number of courses passed by structurally vulnerable archetypes, while leaving highly regular students almost unaffected. The Intervention Lab thus shifts learning analytics from static prediction towards dynamic policy design, offering institutions a transparent, extensible sandbox to test curriculum and teaching reforms before large-scale implementation.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CAPIRE\u5e72\u9884\u5b9e\u9a8c\u5ba4\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62df\u73af\u5883\uff0c\u7528\u4e8e\u5728\u571f\u6728\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\u6d4b\u8bd5\u8bfe\u7a0b\u548c\u6559\u5b66\u653f\u7b56\uff0c\u4ee5\u8865\u5145\u9884\u6d4b\u6027\u5b66\u4e60\u5206\u6790\u6a21\u578b\u3002", "motivation": "\u62c9\u4e01\u7f8e\u6d32\u7684\u5de5\u7a0b\u9879\u76ee\u5b58\u5728\u9ad8\u7ed3\u6784\u521a\u6027\u3001\u5bc6\u96c6\u8bc4\u4f30\u6587\u5316\u548c\u6301\u7eed\u7684\u793e\u4f1a\u7ecf\u6d4e\u4e0d\u5e73\u7b49\uff0c\u5bfc\u81f4\u8f8d\u5b66\u7387\u5c45\u9ad8\u4e0d\u4e0b\u3002\u867d\u7136\u9884\u6d4b\u6027\u5b66\u4e60\u5206\u6790\u80fd\u8bc6\u522b\u98ce\u9669\u5b66\u751f\uff0c\u4f46\u65e0\u6cd5\u63d0\u4f9b\u5177\u4f53\u7684\u653f\u7b56\u7ec4\u5408\u6307\u5bfc\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62df\u73af\u5883\uff0c\u6821\u51c6\u4e8615\u4e2a\u961f\u5217\u76841,343\u540d\u5b66\u751f\u6570\u636e\uff0c\u6a21\u62df34\u95e8\u8bfe\u7a0b\u548c12\u4e2a\u5b66\u671f\u3002\u4ee3\u7406\u57fa\u4e8e\u7ecf\u9a8c\u8f68\u8ff9\u539f\u578b\u521d\u59cb\u5316\uff0c\u5728\u8bfe\u7a0b\u56fe\u4e2d\u6f14\u5316\uff0c\u6d4b\u8bd5\u4e09\u79cd\u653f\u7b56\u7ef4\u5ea6\u7684\u7ec4\u5408\uff1a\u8bfe\u7a0b\u4e0e\u8bc4\u4f30\u7ed3\u6784\u3001\u6559\u5b66\u4e0e\u5b66\u672f\u652f\u6301\u3001\u5fc3\u7406\u793e\u4f1a\u4e0e\u8d22\u52a1\u652f\u6301\u3002", "result": "\u9488\u5bf9\u65e9\u671f\u4e3b\u5e72\u8bfe\u7a0b\u548c\u53d7\u963b\u5b66\u5206\u7684\u653f\u7b56\u7ec4\u5408\u53ef\u5c06\u957f\u671f\u8f8d\u5b66\u7387\u964d\u4f4e\u7ea63\u4e2a\u767e\u5206\u70b9\uff0c\u663e\u8457\u63d0\u9ad8\u7ed3\u6784\u8106\u5f31\u539f\u578b\u5b66\u751f\u7684\u901a\u8fc7\u8bfe\u7a0b\u6570\uff0c\u800c\u5bf9\u9ad8\u5ea6\u89c4\u5f8b\u5b66\u751f\u51e0\u4e4e\u65e0\u5f71\u54cd\u3002", "conclusion": "\u5e72\u9884\u5b9e\u9a8c\u5ba4\u5c06\u5b66\u4e60\u5206\u6790\u4ece\u9759\u6001\u9884\u6d4b\u8f6c\u5411\u52a8\u6001\u653f\u7b56\u8bbe\u8ba1\uff0c\u4e3a\u673a\u6784\u63d0\u4f9b\u4e86\u4e00\u4e2a\u900f\u660e\u3001\u53ef\u6269\u5c55\u7684\u6c99\u76d2\uff0c\u5728\u5927\u89c4\u6a21\u5b9e\u65bd\u524d\u6d4b\u8bd5\u8bfe\u7a0b\u548c\u6559\u5b66\u6539\u9769\u3002"}}
{"id": "2511.18086", "categories": ["cs.RO", "cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18086", "abs": "https://arxiv.org/abs/2511.18086", "authors": ["Miguel Louren\u00e7o", "Ant\u00f3nio Grilo"], "title": "Anti-Jamming based on Null-Steering Antennas and Intelligent UAV Swarm Behavior", "comment": "10 pages", "summary": "Unmanned Aerial Vehicle (UAV) swarms represent a key advancement in autonomous systems, enabling coordinated missions through inter-UAV communication. However, their reliance on wireless links makes them vulnerable to jamming, which can disrupt coordination and mission success. This work investigates whether a UAV swarm can effectively overcome jamming while maintaining communication and mission efficiency.\n  To address this, a unified optimization framework combining Genetic Algorithms (GA), Supervised Learning (SL), and Reinforcement Learning (RL) is proposed. The mission model, structured into epochs and timeslots, allows dynamic path planning, antenna orientation, and swarm formation while progressively enforcing collision rules. Null-steering antennas enhance resilience by directing antenna nulls toward interference sources.\n  Results show that the GA achieved stable, collision-free trajectories but with high computational cost. SL models replicated GA-based configurations but struggled to generalize under dynamic or constrained settings. RL, trained via Proximal Policy Optimization (PPO), demonstrated adaptability and real-time decision-making with consistent communication and lower computational demand. Additionally, the Adaptive Movement Model generalized UAV motion to arbitrary directions through a rotation-based mechanism, validating the scalability of the proposed system.\n  Overall, UAV swarms equipped with null-steering antennas and guided by intelligent optimization algorithms effectively mitigate jamming while maintaining communication stability, formation cohesion, and collision safety. The proposed framework establishes a unified, flexible, and reproducible basis for future research on resilient swarm communication systems.", "AI": {"tldr": "UAV\u8702\u7fa4\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u3001\u76d1\u7763\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u96f6\u9677\u5929\u7ebf\u6280\u672f\uff0c\u6709\u6548\u5bf9\u6297\u5e72\u6270\u5e76\u4fdd\u6301\u901a\u4fe1\u7a33\u5b9a\u6027\u548c\u4efb\u52a1\u6548\u7387\u3002", "motivation": "UAV\u8702\u7fa4\u4f9d\u8d56\u65e0\u7ebf\u901a\u4fe1\uff0c\u5bb9\u6613\u53d7\u5230\u5e72\u6270\u653b\u51fb\uff0c\u8fd9\u4f1a\u7834\u574f\u534f\u8c03\u548c\u4efb\u52a1\u6210\u529f\u7387\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5982\u4f55\u6709\u6548\u514b\u670d\u5e72\u6270\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u3001\u76d1\u7763\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u4f18\u5316\u6846\u67b6\uff0c\u91c7\u7528\u5206\u65f6\u6bb5\u4efb\u52a1\u6a21\u578b\u8fdb\u884c\u52a8\u6001\u8def\u5f84\u89c4\u5212\u3001\u5929\u7ebf\u5b9a\u5411\u548c\u7f16\u961f\u8c03\u6574\uff0c\u4f7f\u7528\u96f6\u9677\u5929\u7ebf\u6280\u672f\u5c06\u5929\u7ebf\u96f6\u9677\u6307\u5411\u5e72\u6270\u6e90\u3002", "result": "\u9057\u4f20\u7b97\u6cd5\u83b7\u5f97\u7a33\u5b9a\u65e0\u78b0\u649e\u8f68\u8ff9\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff1b\u76d1\u7763\u5b66\u4e60\u80fd\u590d\u5236\u9057\u4f20\u7b97\u6cd5\u914d\u7f6e\u4f46\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff1b\u5f3a\u5316\u5b66\u4e60\uff08PPO\uff09\u5c55\u73b0\u9002\u5e94\u6027\u548c\u5b9e\u65f6\u51b3\u7b56\u80fd\u529b\uff0c\u901a\u4fe1\u7a33\u5b9a\u4e14\u8ba1\u7b97\u9700\u6c42\u4f4e\u3002", "conclusion": "\u914d\u5907\u96f6\u9677\u5929\u7ebf\u548c\u667a\u80fd\u4f18\u5316\u7b97\u6cd5\u7684UAV\u8702\u7fa4\u80fd\u6709\u6548\u7f13\u89e3\u5e72\u6270\uff0c\u4fdd\u6301\u901a\u4fe1\u7a33\u5b9a\u3001\u7f16\u961f\u51dd\u805a\u548c\u78b0\u649e\u5b89\u5168\uff0c\u4e3a\u672a\u6765\u5f39\u6027\u8702\u7fa4\u901a\u4fe1\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u7075\u6d3b\u7684\u57fa\u7840\u3002"}}
{"id": "2511.18036", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.18036", "abs": "https://arxiv.org/abs/2511.18036", "authors": ["Ziyi Guo", "Zhou Liu", "Wentao Zhang"], "title": "Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers", "comment": null, "summary": "The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u79d1\u5b66\u8bba\u6587\u7cfb\u7edf\u67b6\u6784\u56fe\u7684\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5305\u542b3000\u7bc7\u8bba\u6587\u53ca\u5176\u5bf9\u5e94\u7684\u9ad8\u8d28\u91cf\u56fe\u8868\uff0c\u5e76\u5f00\u53d1\u4e86Paper2SysArch\u7cfb\u7edf\u4f5c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u7684\u5f3a\u57fa\u7ebf\u3002", "motivation": "\u624b\u52a8\u521b\u5efa\u7cfb\u7edf\u67b6\u6784\u56fe\u8017\u65f6\u4e14\u4e3b\u89c2\uff0c\u73b0\u6709\u751f\u6210\u6a21\u578b\u7f3a\u4e4f\u7ed3\u6784\u63a7\u5236\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4e14\u8be5\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u6765\u5b9a\u91cf\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u8868\u7684\u81ea\u52a8\u751f\u6210\u3002", "method": "\u6784\u5efa\u5305\u542b3000\u7bc7\u8bba\u6587\u53ca\u5176\u5bf9\u5e94\u56fe\u8868\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e09\u5c42\u8bc4\u4f30\u6307\u6807\uff08\u8bed\u4e49\u51c6\u786e\u6027\u3001\u5e03\u5c40\u8fde\u8d2f\u6027\u3001\u89c6\u89c9\u8d28\u91cf\uff09\uff0c\u5e76\u63d0\u51faPaper2SysArch\u7cfb\u7edf\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5c06\u8bba\u6587\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u7f16\u8f91\u7684\u56fe\u8868\u3002", "result": "\u5728\u624b\u52a8\u7b5b\u9009\u7684\u66f4\u5177\u6311\u6218\u6027\u7684\u8bba\u6587\u5b50\u96c6\u4e0a\uff0cPaper2SysArch\u7cfb\u7edf\u83b7\u5f97\u4e8669.0\u7684\u7efc\u5408\u5f97\u5206\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u4e3b\u8981\u8d21\u732e\u662f\u5efa\u7acb\u4e86\u5927\u89c4\u6a21\u57fa\u7840\u57fa\u51c6\u4ee5\u652f\u6301\u53ef\u91cd\u590d\u7814\u7a76\u548c\u516c\u5e73\u6bd4\u8f83\uff0c\u540c\u65f6\u63d0\u51fa\u7684\u7cfb\u7edf\u4f5c\u4e3a\u53ef\u884c\u6982\u5ff5\u9a8c\u8bc1\uff0c\u4e3a\u8be5\u590d\u6742\u4efb\u52a1\u5c55\u793a\u4e86\u6709\u524d\u666f\u7684\u53d1\u5c55\u8def\u5f84\u3002"}}
{"id": "2511.18603", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18603", "abs": "https://arxiv.org/abs/2511.18603", "authors": ["Neon Srinivasu", "Amit Shivam", "Nobin Paul"], "title": "Bifurcation-Based Guidance Law for Powered Descent Landing", "comment": null, "summary": "This paper develops a new guidance law for powered descent landing of a rocket-powered vehicle. The proposed law derives the acceleration command for a point mass model of the vehicle by expressing velocity as a dynamical system undergoing supercritical transcritical bifurcation with three bifurcation parameters. The parameters are designed such that the stable equilibrium points of the velocity dynamics correspond to the guided targeting state, that is, the landing point. Numerical simulations are performed to demonstrate the working of the proposed guidance law.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u4e34\u754c\u8de8\u4e34\u754c\u5206\u5c94\u7684\u706b\u7bad\u52a8\u529b\u4e0b\u964d\u7740\u9646\u5236\u5bfc\u5f8b\uff0c\u901a\u8fc7\u901f\u5ea6\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u7a33\u5b9a\u5e73\u8861\u70b9\u5b9e\u73b0\u7cbe\u786e\u7740\u9646\u63a7\u5236\u3002", "motivation": "\u5f00\u53d1\u65b0\u7684\u52a8\u529b\u4e0b\u964d\u7740\u9646\u5236\u5bfc\u65b9\u6cd5\uff0c\u5229\u7528\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7279\u6027\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u706b\u7bad\u7740\u9646\u63a7\u5236\u3002", "method": "\u5c06\u901f\u5ea6\u5efa\u6a21\u4e3a\u5177\u6709\u4e09\u4e2a\u5206\u5c94\u53c2\u6570\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\uff0c\u901a\u8fc7\u8d85\u4e34\u754c\u8de8\u4e34\u754c\u5206\u5c94\u8bbe\u8ba1\u52a0\u901f\u5ea6\u6307\u4ee4\uff0c\u4f7f\u7a33\u5b9a\u5e73\u8861\u70b9\u5bf9\u5e94\u76ee\u6807\u7740\u9646\u72b6\u6001\u3002", "result": "\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u6240\u63d0\u5236\u5bfc\u5f8b\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u7cbe\u786e\u7684\u7740\u9646\u63a7\u5236\u3002", "conclusion": "\u57fa\u4e8e\u5206\u5c94\u7406\u8bba\u7684\u5236\u5bfc\u65b9\u6cd5\u4e3a\u706b\u7bad\u52a8\u529b\u4e0b\u964d\u7740\u9646\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18182", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18182", "abs": "https://arxiv.org/abs/2511.18182", "authors": ["Lee Ackerman"], "title": "The Workflow as Medium: A Framework for Navigating Human-AI Co-Creation", "comment": "57 pages, 13 images, 6 tables", "summary": "This paper introduces the Creative Intelligence Loop (CIL), a novel socio-technical framework for responsible human-AI co-creation. Rooted in the 'Workflow as Medium' paradigm, the CIL proposes a disciplined structure for dynamic human-AI collaboration, guiding the strategic integration of diverse AI teammates who function as collaborators while the human remains the final arbiter for ethical alignment and creative integrity. The CIL was empirically demonstrated through the practice-led creation of two graphic novellas, investigating how AI could serve as an effective creative colleague within a subjective medium lacking objective metrics. The process required navigating multifaceted challenges including AI's 'jagged frontier' of capabilities, sycophancy, and attention-scarce feedback environments. This prompted iterative refinement of teaming practices, yielding emergent strategies: a multi-faceted critique system integrating adversarial AI roles to counter sycophancy, and prioritizing 'feedback-ready' concrete artifacts to elicit essential human critique. The resulting graphic novellas analyze distinct socio-technical governance failures: 'The Steward' examines benevolent AI paternalism in smart cities, illustrating how algorithmic hubris can erode freedom; 'Fork the Vote' probes democratic legitimacy by comparing centralized AI opacity with emergent collusion in federated networks. This work contributes a self-improving framework for responsible human-AI co-creation and two graphic novellas designed to foster AI literacy and dialogue through accessible narrative analysis of AI's societal implications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.18088", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18088", "abs": "https://arxiv.org/abs/2511.18088", "authors": ["Ibrahim Alsarraj", "Yuhao Wang", "Abdalla Swikir", "Cesare Stefanini", "Dezhen Song", "Zhanchi Wang", "Ke Wu"], "title": "A Unified Multi-Dynamics Framework for Perception-Oriented Modeling in Tendon-Driven Continuum Robots", "comment": null, "summary": "Tendon-driven continuum robots offer intrinsically safe and contact-rich interactions owing to their kinematic redundancy and structural compliance. However, their perception often depends on external sensors, which increase hardware complexity and limit scalability. This work introduces a unified multi-dynamics modeling framework for tendon-driven continuum robotic systems, exemplified by a spiral-inspired robot named Spirob. The framework integrates motor electrical dynamics, motor-winch dynamics, and continuum robot dynamics into a coherent system model. Within this framework, motor signals such as current and angular displacement are modeled to expose the electromechanical signatures of external interactions, enabling perception grounded in intrinsic dynamics. The model captures and validates key physical behaviors of the real system, including actuation hysteresis and self-contact at motion limits. Building on this foundation, the framework is applied to environmental interaction: first for passive contact detection, verified experimentally against simulation data; then for active contact sensing, where control and perception strategies from simulation are successfully applied to the real robot; and finally for object size estimation, where a policy learned in simulation is directly deployed on hardware. The results demonstrate that the proposed framework provides a physically grounded way to interpret interaction signatures from intrinsic motor signals in tendon-driven continuum robots.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u591a\u52a8\u529b\u5b66\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u808c\u8171\u9a71\u52a8\u8fde\u7eed\u4f53\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u7535\u673a\u7535\u6c14\u52a8\u529b\u5b66\u3001\u7535\u673a\u5377\u8f74\u52a8\u529b\u5b66\u548c\u8fde\u7eed\u4f53\u673a\u5668\u4eba\u52a8\u529b\u5b66\uff0c\u5b9e\u73b0\u57fa\u4e8e\u5185\u5728\u7535\u673a\u4fe1\u53f7\u7684\u5916\u90e8\u4ea4\u4e92\u611f\u77e5\u3002", "motivation": "\u808c\u8171\u9a71\u52a8\u8fde\u7eed\u4f53\u673a\u5668\u4eba\u5177\u6709\u8fd0\u52a8\u5197\u4f59\u548c\u7ed3\u6784\u67d4\u987a\u6027\uff0c\u4f46\u611f\u77e5\u901a\u5e38\u4f9d\u8d56\u5916\u90e8\u4f20\u611f\u5668\uff0c\u589e\u52a0\u4e86\u786c\u4ef6\u590d\u6742\u6027\u5e76\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u7edf\u4e00\u7684\u591a\u52a8\u529b\u5b66\u5efa\u6a21\u6846\u67b6\uff0c\u6574\u5408\u7535\u673a\u7535\u6c14\u52a8\u529b\u5b66\u3001\u7535\u673a\u5377\u8f74\u52a8\u529b\u5b66\u548c\u8fde\u7eed\u4f53\u673a\u5668\u4eba\u52a8\u529b\u5b66\uff0c\u901a\u8fc7\u7535\u673a\u7535\u6d41\u548c\u89d2\u4f4d\u79fb\u7b49\u4fe1\u53f7\u63ed\u793a\u5916\u90e8\u4ea4\u4e92\u7684\u673a\u7535\u7279\u5f81\u3002", "result": "\u6a21\u578b\u6210\u529f\u6355\u83b7\u5e76\u9a8c\u8bc1\u4e86\u771f\u5b9e\u7cfb\u7edf\u7684\u5173\u952e\u7269\u7406\u884c\u4e3a\uff0c\u5305\u62ec\u9a71\u52a8\u8fdf\u6ede\u548c\u8fd0\u52a8\u6781\u9650\u5904\u7684\u81ea\u63a5\u89e6\u3002\u5728\u73af\u5883\u4ea4\u4e92\u5e94\u7528\u4e2d\uff0c\u5b9e\u73b0\u4e86\u88ab\u52a8\u63a5\u89e6\u68c0\u6d4b\u3001\u4e3b\u52a8\u63a5\u89e6\u611f\u77e5\u548c\u7269\u4f53\u5c3a\u5bf8\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u808c\u8171\u9a71\u52a8\u8fde\u7eed\u4f53\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u7684\u65b9\u5f0f\u6765\u89e3\u91ca\u6765\u81ea\u5185\u5728\u7535\u673a\u4fe1\u53f7\u7684\u4ea4\u4e92\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u5916\u90e8\u4f20\u611f\u5668\u7684\u611f\u77e5\u80fd\u529b\u3002"}}
{"id": "2511.18171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18171", "abs": "https://arxiv.org/abs/2511.18171", "authors": ["Jasper Nie", "Christian Muise", "Victoria Armstrong"], "title": "BPMN to PDDL: Translating Business Workflows for AI Planning", "comment": "8 pages, 3 figures. Code and generated PDDL outputs available at https://github.com/QuMuLab/bpmn-to-pddl-translation", "summary": "Business Process Model and Notation (BPMN) is a widely used standard for modelling business processes. While automated planning has been proposed as a method for simulating and reasoning about BPMN workflows, most implementations remain incomplete or limited in scope. This project builds upon prior theoretical work to develop a functional pipeline that translates BPMN 2.0 diagrams into PDDL representations suitable for planning. The system supports core BPMN constructs, including tasks, events, sequence flows, and gateways, with initial support for parallel and inclusive gateway behaviour. Using a non-deterministic planner, we demonstrate how to generate and evaluate valid execution traces. Our implementation aims to bridge the gap between theory and practical tooling, providing a foundation for further exploration of translating business processes into well-defined plans.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5c06BPMN 2.0\u56fe\u8f6c\u6362\u4e3aPDDL\u8868\u793a\u7684\u529f\u80fd\u6027\u7ba1\u9053\uff0c\u652f\u6301\u6838\u5fc3BPMN\u6784\u9020\uff0c\u4f7f\u7528\u975e\u786e\u5b9a\u6027\u89c4\u5212\u5668\u751f\u6210\u6709\u6548\u6267\u884c\u8f68\u8ff9\u3002", "motivation": "\u867d\u7136\u81ea\u52a8\u89c4\u5212\u5df2\u88ab\u63d0\u51fa\u4f5c\u4e3a\u6a21\u62df\u548c\u63a8\u7406BPMN\u5de5\u4f5c\u6d41\u7684\u65b9\u6cd5\uff0c\u4f46\u5927\u591a\u6570\u5b9e\u73b0\u4ecd\u4e0d\u5b8c\u6574\u6216\u8303\u56f4\u6709\u9650\u3002\u8be5\u9879\u76ee\u65e8\u5728\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u9645\u5de5\u5177\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u7406\u8bba\u7814\u7a76\uff0c\u5f00\u53d1\u4e86\u5c06BPMN 2.0\u56fe\u8f6c\u6362\u4e3aPDDL\u8868\u793a\u7684\u529f\u80fd\u7ba1\u9053\uff0c\u652f\u6301\u4efb\u52a1\u3001\u4e8b\u4ef6\u3001\u5e8f\u5217\u6d41\u548c\u7f51\u5173\u7b49\u6838\u5fc3BPMN\u6784\u9020\uff0c\u521d\u6b65\u652f\u6301\u5e76\u884c\u548c\u5305\u5bb9\u7f51\u5173\u884c\u4e3a\u3002", "result": "\u4f7f\u7528\u975e\u786e\u5b9a\u6027\u89c4\u5212\u5668\u6210\u529f\u751f\u6210\u548c\u8bc4\u4f30\u4e86\u6709\u6548\u6267\u884c\u8f68\u8ff9\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u5b9e\u73b0\u4e3a\u5c06\u4e1a\u52a1\u6d41\u7a0b\u8f6c\u6362\u4e3a\u660e\u786e\u5b9a\u4e49\u7684\u8ba1\u5212\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4e3a\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e1a\u52a1\u8fc7\u7a0b\u8f6c\u6362\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.18768", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18768", "abs": "https://arxiv.org/abs/2511.18768", "authors": ["Jiyu Lee", "Shenghui Cui"], "title": "Accelerated Transformer Energization Sequence for Inverter Based Resources in Black-Start Procedures with Active Flux Trajectory Manipulation in the Stationary Reference Frame", "comment": null, "summary": "This paper proposes advanced soft-magnetization techniques to enable ultra-fast and reliable black-start of grid-forming (GFM) converters. Conventional hard-magnetization with well-established three-phase voltages during transformer energization induces severe inrush currents due to flux offset, which can damage power semiconductor devices. To overcome this drawback, an ultra-fast soft-magnetization method is firstly introduced, leveraging the voltage programmability of the inverter to actively reshape the initial voltage profile and thereby eliminate flux offset of the transformer core. By suppressing the formation of flux offset itself, the proposed approach prevents magnetic saturation and achieves nominal terminal voltage within a few milliseconds while effectively suppressing inrush current. However, this method can still trigger surge currents to power semiconductor devices in the presence of an LC filter due to abrupt voltage magnitude and phase transitions. To address this issue, an enhanced Archimedean spiral soft-magnetization method is developed, where both voltage magnitude and phase evolve smoothly to simultaneously suppress inrush and surge currents. Furthermore, residual flux in the transformer core is considered, and a demagnetization sequence using the inverter is validated to ensure reliable start-up. Experimental results confirm that the proposed methods achieve rapid black-start performance within one fundamental cycle while ensuring safe and stable operation of GFM converters.", "AI": {"tldr": "\u63d0\u51fa\u5148\u8fdb\u7684\u8f6f\u78c1\u5316\u6280\u672f\uff0c\u5b9e\u73b0\u7535\u7f51\u5f62\u6210\u53d8\u6362\u5668\u7684\u8d85\u5feb\u901f\u53ef\u9760\u9ed1\u542f\u52a8\uff0c\u901a\u8fc7\u4e3b\u52a8\u91cd\u5851\u521d\u59cb\u7535\u538b\u5206\u5e03\u6d88\u9664\u53d8\u538b\u5668\u78c1\u901a\u504f\u79fb\uff0c\u6291\u5236\u6d8c\u6d41\u548c\u6d6a\u6d8c\u7535\u6d41\u3002", "motivation": "\u4f20\u7edf\u7684\u786c\u78c1\u5316\u65b9\u6cd5\u5728\u53d8\u538b\u5668\u52b1\u78c1\u65f6\u4f1a\u4ea7\u751f\u4e25\u91cd\u7684\u6d8c\u6d41\uff0c\u53ef\u80fd\u635f\u574f\u529f\u7387\u534a\u5bfc\u4f53\u5668\u4ef6\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6d88\u9664\u78c1\u901a\u504f\u79fb\u7684\u8f6f\u78c1\u5316\u6280\u672f\u3002", "method": "\u9996\u5148\u5f15\u5165\u8d85\u5feb\u901f\u8f6f\u78c1\u5316\u65b9\u6cd5\uff0c\u5229\u7528\u9006\u53d8\u5668\u7684\u7535\u538b\u53ef\u7f16\u7a0b\u6027\u4e3b\u52a8\u91cd\u5851\u521d\u59cb\u7535\u538b\u5206\u5e03\uff1b\u7136\u540e\u5f00\u53d1\u589e\u5f3a\u7684\u963f\u57fa\u7c73\u5fb7\u87ba\u65cb\u8f6f\u78c1\u5316\u65b9\u6cd5\uff0c\u4f7f\u7535\u538b\u5e45\u503c\u548c\u76f8\u4f4d\u5e73\u6ed1\u6f14\u53d8\uff1b\u540c\u65f6\u8003\u8651\u53d8\u538b\u5668\u94c1\u82af\u4e2d\u7684\u5269\u78c1\uff0c\u9a8c\u8bc1\u4f7f\u7528\u9006\u53d8\u5668\u7684\u6d88\u78c1\u5e8f\u5217\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e00\u4e2a\u57fa\u6ce2\u5468\u671f\u5185\u5b9e\u73b0\u5feb\u901f\u9ed1\u542f\u52a8\u6027\u80fd\uff0c\u540c\u65f6\u786e\u4fdd\u7535\u7f51\u5f62\u6210\u53d8\u6362\u5668\u7684\u5b89\u5168\u7a33\u5b9a\u8fd0\u884c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8f6f\u78c1\u5316\u6280\u672f\u80fd\u591f\u6709\u6548\u6291\u5236\u6d8c\u6d41\u548c\u6d6a\u6d8c\u7535\u6d41\uff0c\u5b9e\u73b0\u7535\u7f51\u5f62\u6210\u53d8\u6362\u5668\u7684\u53ef\u9760\u9ed1\u542f\u52a8\uff0c\u4e3a\u7535\u529b\u7cfb\u7edf\u6062\u590d\u63d0\u4f9b\u91cd\u8981\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2511.18221", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18221", "abs": "https://arxiv.org/abs/2511.18221", "authors": ["Liangliang Chen", "Huiru Xie", "Zhihao Qin", "Yiming Guo", "Jacqueline Rohde", "Ying Zhang"], "title": "Enhancing Large Language Models for Automated Homework Assessment in Undergraduate Circuit Analysis", "comment": "Accepted to 2025 Frontiers in Education (FIE) Conference", "summary": "This research full paper presents an enhancement pipeline for large language models (LLMs) in assessing homework for an undergraduate circuit analysis course, aiming to improve LLMs' capacity to provide personalized support to electrical engineering students. Existing evaluations have demonstrated that GPT-4o possesses promising capabilities in assessing student homework in this domain. Building on these findings, we enhance GPT-4o's performance through multi-step prompting, contextual data augmentation, and the incorporation of targeted hints. These strategies effectively address common errors observed in GPT-4o's responses when using simple prompts, leading to a substantial improvement in assessment accuracy. Specifically, the correct response rate for GPT-4o increases from 74.71% to 97.70% after applying the enhanced prompting and augmented data on entry-level circuit analysis topics. This work lays a foundation for the effective integration of LLMs into circuit analysis instruction and, more broadly, into engineering education.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u8def\u5206\u6790\u8bfe\u7a0b\u4f5c\u4e1a\u8bc4\u4f30\u80fd\u529b\u7684\u7ba1\u9053\uff0c\u901a\u8fc7\u591a\u6b65\u63d0\u793a\u3001\u4e0a\u4e0b\u6587\u6570\u636e\u589e\u5f3a\u548c\u9488\u5bf9\u6027\u63d0\u793a\uff0c\u5c06GPT-4o\u7684\u6b63\u786e\u7387\u4ece74.71%\u63d0\u5347\u523097.70%\u3002", "motivation": "\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u7535\u6c14\u5de5\u7a0b\u5b66\u751f\u63d0\u4f9b\u4e2a\u6027\u5316\u652f\u6301\u7684\u80fd\u529b\uff0c\u89e3\u51b3GPT-4o\u5728\u7b80\u5355\u63d0\u793a\u4e0b\u8bc4\u4f30\u4f5c\u4e1a\u65f6\u51fa\u73b0\u7684\u5e38\u89c1\u9519\u8bef\u3002", "method": "\u91c7\u7528\u591a\u6b65\u63d0\u793a\u3001\u4e0a\u4e0b\u6587\u6570\u636e\u589e\u5f3a\u548c\u9488\u5bf9\u6027\u63d0\u793a\u7b49\u7b56\u7565\u6765\u589e\u5f3aGPT-4o\u7684\u6027\u80fd\u3002", "result": "GPT-4o\u5728\u5165\u95e8\u7ea7\u7535\u8def\u5206\u6790\u4e3b\u9898\u4e0a\u7684\u6b63\u786e\u54cd\u5e94\u7387\u4ece74.71%\u663e\u8457\u63d0\u9ad8\u523097.70%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u6709\u6548\u6574\u5408\u5230\u7535\u8def\u5206\u6790\u6559\u5b66\u4ee5\u53ca\u66f4\u5e7f\u6cdb\u7684\u5de5\u7a0b\u6559\u80b2\u4e2d\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.18112", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18112", "abs": "https://arxiv.org/abs/2511.18112", "authors": ["Min Lin", "Xiwen Liang", "Bingqian Lin", "Liu Jingzhi", "Zijian Jiao", "Kehan Li", "Yuhan Ma", "Yuecheng Liu", "Shen Zhao", "Yuzheng Zhuang", "Xiaodan Liang"], "title": "EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation", "comment": null, "summary": "Recent progress in Vision-Language-Action (VLA) models has enabled embodied agents to interpret multimodal instructions and perform complex tasks. However, existing VLAs are mostly confined to short-horizon, table-top manipulation, lacking the memory and reasoning capability required for long-horizon mobile manipulation, where agents must coordinate navigation and manipulation under changing spatial contexts. In this work, we present EchoVLA, a memory-aware VLA model for long-horizon mobile manipulation. EchoVLA incorporates a synergistic declarative memory inspired by the human brain, consisting of a scene memory that maintains a collection of spatial-semantic maps and an episodic memory that stores task-level experiences with multimodal contextual features. During both training and inference, the two memories are individually stored, updated, and retrieved based on current observations, task history, and instructions, and their retrieved representations are fused via coarse- and fine-grained attention to guide mobile-arm diffusion policies. To support large-scale training and evaluation, we further introduce MoMani, an automated benchmark that generates expert-level long-horizon trajectories through multimodal large language model (MLLM)-guided planning and feedback-driven refinement, supplemented with real-robot demonstrations. Experiments in simulated and real-world settings show that EchoVLA improves long-horizon performance, reaching 0.52 SR on manipulation/navigation and 0.31 on mobile manipulation, exceeding $\u03c0_{0.5}$ by +0.08 and +0.11.", "AI": {"tldr": "EchoVLA\u662f\u4e00\u4e2a\u5177\u6709\u8bb0\u5fc6\u80fd\u529b\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u4e13\u4e3a\u957f\u65f6\u7a0b\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u8bbe\u8ba1\uff0c\u901a\u8fc7\u573a\u666f\u8bb0\u5fc6\u548c\u60c5\u666f\u8bb0\u5fc6\u7684\u534f\u540c\u5de5\u4f5c\u6765\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684VLA\u6a21\u578b\u4e3b\u8981\u5c40\u9650\u4e8e\u77ed\u65f6\u7a0b\u684c\u9762\u64cd\u4f5c\uff0c\u7f3a\u4e4f\u957f\u65f6\u7a0b\u79fb\u52a8\u64cd\u4f5c\u6240\u9700\u7684\u5185\u5b58\u548c\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u6cd5\u5728\u53d8\u5316\u7684\u7a7a\u95f4\u73af\u5883\u4e2d\u534f\u8c03\u5bfc\u822a\u548c\u64cd\u4f5c\u3002", "method": "\u5f15\u5165\u534f\u540c\u58f0\u660e\u6027\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u5305\u62ec\u7ef4\u62a4\u7a7a\u95f4\u8bed\u4e49\u5730\u56fe\u7684\u573a\u666f\u8bb0\u5fc6\u548c\u5b58\u50a8\u4efb\u52a1\u7ea7\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u7279\u5f81\u7684\u60c5\u666f\u8bb0\u5fc6\u3002\u901a\u8fc7\u7c97\u7c92\u5ea6\u548c\u7ec6\u7c92\u5ea6\u6ce8\u610f\u529b\u878d\u5408\u8bb0\u5fc6\u8868\u793a\uff0c\u6307\u5bfc\u79fb\u52a8\u81c2\u6269\u6563\u7b56\u7565\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u5b9e\u9a8c\u4e2d\uff0cEchoVLA\u5728\u64cd\u4f5c/\u5bfc\u822a\u4efb\u52a1\u4e0a\u8fbe\u52300.52\u6210\u529f\u7387\uff0c\u5728\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u4e0a\u8fbe\u52300.31\u6210\u529f\u7387\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u5206\u522b\u63d0\u53470.08\u548c0.11\u3002", "conclusion": "EchoVLA\u901a\u8fc7\u8bb0\u5fc6\u589e\u5f3a\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u957f\u65f6\u7a0b\u79fb\u52a8\u64cd\u4f5c\u7684\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u73af\u5883\u4e2d\u7684\u534f\u8c03\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2511.18244", "categories": ["cs.AI", "cond-mat.mtrl-sci", "physics.ed-ph"], "pdf": "https://arxiv.org/pdf/2511.18244", "abs": "https://arxiv.org/abs/2511.18244", "authors": ["Zhiling Zheng"], "title": "Developing an AI Course for Synthetic Chemistry Students", "comment": "17 pages, 3 figures", "summary": "Artificial intelligence (AI) and data science are transforming chemical research, yet few formal courses are tailored to synthetic and experimental chemists, who often face steep entry barriers due to limited coding experience and lack of chemistry-specific examples. We present the design and implementation of AI4CHEM, an introductory data-driven chem-istry course created for students on the synthetic chemistry track with no prior programming background. The curricu-lum emphasizes chemical context over abstract algorithms, using an accessible web-based platform to ensure zero-install machine learning (ML) workflow development practice and in-class active learning. Assessment combines code-guided homework, literature-based mini-reviews, and collaborative projects in which students build AI-assisted workflows for real experimental problems. Learning gains include increased confidence with Python, molecular property prediction, reaction optimization, and data mining, and improved skills in evaluating AI tools in chemistry. All course materials are openly available, offering a discipline-specific, beginner-accessible framework for integrating AI into synthetic chemistry training.", "AI": {"tldr": "AI4CHEM\u662f\u4e00\u95e8\u4e3a\u5408\u6210\u5316\u5b66\u80cc\u666f\u5b66\u751f\u8bbe\u8ba1\u7684\u96f6\u7f16\u7a0b\u57fa\u7840AI\u5316\u5b66\u5165\u95e8\u8bfe\u7a0b\uff0c\u901a\u8fc7\u57fa\u4e8e\u7f51\u9875\u7684\u5e73\u53f0\u5b9e\u73b0\u96f6\u5b89\u88c5\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u5f00\u53d1\uff0c\u5f3a\u8c03\u5316\u5b66\u60c5\u5883\u800c\u975e\u62bd\u8c61\u7b97\u6cd5\u3002", "motivation": "AI\u548c\u6570\u636e\u79d1\u5b66\u6b63\u5728\u53d8\u9769\u5316\u5b66\u7814\u7a76\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u5408\u6210\u548c\u5b9e\u9a8c\u5316\u5b66\u5bb6\u7684\u6b63\u5f0f\u8bfe\u7a0b\uff0c\u8fd9\u4e9b\u5b66\u751f\u901a\u5e38\u56e0\u7f16\u7a0b\u7ecf\u9a8c\u6709\u9650\u548c\u7f3a\u4e4f\u5316\u5b66\u7279\u5b9a\u6848\u4f8b\u800c\u9762\u4e34\u8f83\u9ad8\u5165\u95e8\u95e8\u69db\u3002", "method": "\u8bfe\u7a0b\u8bbe\u8ba1\u91c7\u7528\u57fa\u4e8e\u7f51\u9875\u7684\u53ef\u8bbf\u95ee\u5e73\u53f0\uff0c\u786e\u4fdd\u96f6\u5b89\u88c5\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u5f00\u53d1\u5b9e\u8df5\u548c\u8bfe\u5802\u4e3b\u52a8\u5b66\u4e60\uff0c\u8bc4\u4f30\u7ed3\u5408\u4ee3\u7801\u6307\u5bfc\u4f5c\u4e1a\u3001\u6587\u732e\u5c0f\u578b\u7efc\u8ff0\u4ee5\u53ca\u5b66\u751f\u4e3a\u771f\u5b9e\u5b9e\u9a8c\u95ee\u9898\u6784\u5efaAI\u8f85\u52a9\u5de5\u4f5c\u6d41\u7684\u5408\u4f5c\u9879\u76ee\u3002", "result": "\u5b66\u4e60\u6536\u83b7\u5305\u62ec\u63d0\u5347Python\u4fe1\u5fc3\u3001\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u3001\u53cd\u5e94\u4f18\u5316\u548c\u6570\u636e\u6316\u6398\u80fd\u529b\uff0c\u4ee5\u53ca\u6539\u8fdb\u8bc4\u4f30\u5316\u5b66AI\u5de5\u5177\u7684\u6280\u80fd\u3002\u6240\u6709\u8bfe\u7a0b\u6750\u6599\u516c\u5f00\u53ef\u7528\u3002", "conclusion": "\u8be5\u8bfe\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b66\u79d1\u7279\u5b9a\u3001\u521d\u5b66\u8005\u53ef\u8bbf\u95ee\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5c06AI\u6574\u5408\u5230\u5408\u6210\u5316\u5b66\u57f9\u8bad\u4e2d\u3002"}}
{"id": "2511.18800", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18800", "abs": "https://arxiv.org/abs/2511.18800", "authors": ["Matthew Hampsey", "Pieter van Goor", "Ravi Banavar", "Robert Mahony"], "title": "Equivariant Tracking Control for Fully Actuated Mechanical Systems on Matrix Lie Groups", "comment": null, "summary": "Mechanical control systems such as aerial, marine, space, and terrestrial robots often naturally admit a state-space that has the structure of a Lie group. The kinetic energy of such systems is commonly invariant to the induced action by the Lie group, and the system dynamics can be written as a coupled ordinary differential equation on the group and the dual space of its Lie algebra, termed a Lie-Poisson system. In this paper, we show that Lie-Poisson systems can also be written as a left-invariant system on a semi-direct Lie group structure placed on the trivialised cotangent bundle of the symmetry group. The authors do not know of a prior reference for this observation and we are confident the insight has never been exploited in the context of tracking control. We use this representation to build a right-invariant tracking error for the full state of a Lie-Poisson mechanical system and show that the error dynamics for this error are themselves of Lie-Poisson structure, albeit with time-varying inertia. This allows us to tackle the general trajectory tracking problem using an energy shaping design metholodology. To demonstrate the approach, we apply the proposed design methodology to a simple attitude tracking control.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u674e-\u6cca\u677e\u7cfb\u7edf\u8868\u793a\u4e3a\u534a\u76f4\u79ef\u674e\u7fa4\u4e0a\u7684\u5de6\u4e0d\u53d8\u7cfb\u7edf\uff0c\u5e76\u5229\u7528\u6b64\u8868\u793a\u6784\u5efa\u53f3\u4e0d\u53d8\u8ddf\u8e2a\u8bef\u5dee\uff0c\u4e3a\u674e-\u6cca\u677e\u673a\u68b0\u7cfb\u7edf\u7684\u8f68\u8ff9\u8ddf\u8e2a\u95ee\u9898\u63d0\u4f9b\u80fd\u91cf\u6574\u5f62\u63a7\u5236\u65b9\u6cd5\u3002", "motivation": "\u673a\u68b0\u63a7\u5236\u7cfb\u7edf\uff08\u5982\u673a\u5668\u4eba\uff09\u7684\u72b6\u6001\u7a7a\u95f4\u901a\u5e38\u5177\u6709\u674e\u7fa4\u7ed3\u6784\uff0c\u5176\u52a8\u529b\u5b66\u53ef\u5199\u4e3a\u674e-\u6cca\u677e\u7cfb\u7edf\u3002\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u7cfb\u7edf\u53ef\u8868\u793a\u4e3a\u534a\u76f4\u79ef\u674e\u7fa4\u4e0a\u7684\u5de6\u4e0d\u53d8\u7cfb\u7edf\uff0c\u8fd9\u4e00\u89c2\u5bdf\u5728\u8ddf\u8e2a\u63a7\u5236\u9886\u57df\u5c1a\u672a\u88ab\u5f00\u53d1\u5229\u7528\u3002", "method": "\u5c06\u674e-\u6cca\u677e\u7cfb\u7edf\u8868\u793a\u4e3a\u534a\u76f4\u79ef\u674e\u7fa4\u4e0a\u7684\u5de6\u4e0d\u53d8\u7cfb\u7edf\uff0c\u6784\u5efa\u53f3\u4e0d\u53d8\u8ddf\u8e2a\u8bef\u5dee\uff0c\u8bc1\u660e\u8bef\u5dee\u52a8\u529b\u5b66\u4ecd\u4fdd\u6301\u674e-\u6cca\u677e\u7ed3\u6784\uff08\u4f46\u5177\u6709\u65f6\u53d8\u60ef\u6027\uff09\uff0c\u5e76\u91c7\u7528\u80fd\u91cf\u6574\u5f62\u8bbe\u8ba1\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u4e00\u822c\u8f68\u8ff9\u8ddf\u8e2a\u95ee\u9898\uff0c\u8bef\u5dee\u52a8\u529b\u5b66\u4fdd\u6301\u674e-\u6cca\u677e\u7ed3\u6784\uff0c\u901a\u8fc7\u59ff\u6001\u8ddf\u8e2a\u63a7\u5236\u5b9e\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u674e-\u6cca\u677e\u673a\u68b0\u7cfb\u7edf\u7684\u8f68\u8ff9\u8ddf\u8e2a\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u674e\u7fa4\u7ed3\u6784\u5206\u6790\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u80fd\u91cf\u6574\u5f62\u63a7\u5236\u3002"}}
{"id": "2511.18239", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18239", "abs": "https://arxiv.org/abs/2511.18239", "authors": ["Mohamed Afane", "Ying Wang", "Juntao Chen"], "title": "Can LLMs Help Allocate Public Health Resources? A Case Study on Childhood Lead Testing", "comment": null, "summary": "Public health agencies face critical challenges in identifying high-risk neighborhoods for childhood lead exposure with limited resources for outreach and intervention programs. To address this, we develop a Priority Score integrating untested children proportions, elevated blood lead prevalence, and public health coverage patterns to support optimized resource allocation decisions across 136 neighborhoods in Chicago, New York City, and Washington, D.C. We leverage these allocation tasks, which require integrating multiple vulnerability indicators and interpreting empirical evidence, to evaluate whether large language models (LLMs) with agentic reasoning and deep research capabilities can effectively allocate public health resources when presented with structured allocation scenarios. LLMs were tasked with distributing 1,000 test kits within each city based on neighborhood vulnerability indicators. Results reveal significant limitations: LLMs frequently overlooked neighborhoods with highest lead prevalence and largest proportions of untested children, such as West Englewood in Chicago, while allocating disproportionate resources to lower-priority areas like Hunts Point in New York City. Overall accuracy averaged 0.46, reaching a maximum of 0.66 with ChatGPT 5 Deep Research. Despite their marketed deep research capabilities, LLMs struggled with fundamental limitations in information retrieval and evidence-based reasoning, frequently citing outdated data and allowing non-empirical narratives about neighborhood conditions to override quantitative vulnerability indicators.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u4f18\u5148\u7ea7\u8bc4\u5206\u7cfb\u7edf\u6765\u8bc6\u522b\u513f\u7ae5\u94c5\u66b4\u9732\u9ad8\u98ce\u9669\u793e\u533a\uff0c\u5e76\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u516c\u5171\u536b\u751f\u8d44\u6e90\u5206\u914d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u516c\u5171\u536b\u751f\u673a\u6784\u9762\u4e34\u8bc6\u522b\u9ad8\u98ce\u9669\u793e\u533a\u548c\u4f18\u5316\u6709\u9650\u8d44\u6e90\u5206\u914d\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u5de5\u5177\u6765\u652f\u6301\u51b3\u7b56\u3002", "method": "\u5f00\u53d1\u4f18\u5148\u7ea7\u8bc4\u5206\u7cfb\u7edf\u6574\u5408\u672a\u68c0\u6d4b\u513f\u7ae5\u6bd4\u4f8b\u3001\u8840\u94c5\u5347\u9ad8\u60a3\u75c5\u7387\u548c\u516c\u5171\u536b\u751f\u8986\u76d6\u6a21\u5f0f\uff0c\u5e76\u5728\u4e09\u4e2a\u57ce\u5e02\u7684136\u4e2a\u793e\u533a\u4e2d\u8bc4\u4f30LLMs\u7684\u8d44\u6e90\u5206\u914d\u80fd\u529b\u3002", "result": "LLMs\u8868\u73b0\u4e0d\u4f73\uff0c\u51c6\u786e\u7387\u5e73\u57470.46\uff0c\u6700\u9ad80.66\uff1b\u7ecf\u5e38\u5ffd\u89c6\u6700\u9ad8\u98ce\u9669\u793e\u533a\uff0c\u5c06\u8d44\u6e90\u8fc7\u5ea6\u5206\u914d\u7ed9\u4f4e\u4f18\u5148\u7ea7\u533a\u57df\uff0c\u5b58\u5728\u4fe1\u606f\u68c0\u7d22\u548c\u5faa\u8bc1\u63a8\u7406\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u5177\u6709\u6df1\u5ea6\u7814\u7a76\u80fd\u529b\uff0cLLMs\u5728\u516c\u5171\u536b\u751f\u8d44\u6e90\u5206\u914d\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u66ff\u4ee3\u4e13\u4e1a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002"}}
{"id": "2511.18140", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18140", "abs": "https://arxiv.org/abs/2511.18140", "authors": ["Yilong Wang", "Cheng Qian", "Ruomeng Fan", "Edward Johns"], "title": "Observer Actor: Active Vision Imitation Learning with Sparse View Gaussian Splatting", "comment": "Videos are available on our project webpage at https://obact.github.io", "summary": "We propose Observer Actor (ObAct), a novel framework for active vision imitation learning in which the observer moves to optimal visual observations for the actor. We study ObAct on a dual-arm robotic system equipped with wrist-mounted cameras. At test time, ObAct dynamically assigns observer and actor roles: the observer arm constructs a 3D Gaussian Splatting (3DGS) representation from three images, virtually explores this to find an optimal camera pose, then moves to this pose; the actor arm then executes a policy using the observer's observations. This formulation enhances the clarity and visibility of both the object and the gripper in the policy's observations. As a result, we enable the training of ambidextrous policies on observations that remain closer to the occlusion-free training distribution, leading to more robust policies. We study this formulation with two existing imitation learning methods -- trajectory transfer and behavior cloning -- and experiments show that ObAct significantly outperforms static-camera setups: trajectory transfer improves by 145% without occlusion and 233% with occlusion, while behavior cloning improves by 75% and 143%, respectively. Videos are available at https://obact.github.io.", "AI": {"tldr": "ObAct\u662f\u4e00\u4e2a\u4e3b\u52a8\u89c6\u89c9\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u914d\u89c2\u5bdf\u8005\u548c\u6267\u884c\u8005\u89d2\u8272\uff0c\u8ba9\u89c2\u5bdf\u8005\u79fb\u52a8\u5230\u6700\u4f73\u89c6\u89c9\u89c2\u6d4b\u4f4d\u7f6e\uff0c\u4ece\u800c\u63d0\u9ad8\u7b56\u7565\u6267\u884c\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0c\u56fa\u5b9a\u6444\u50cf\u5934\u8bbe\u7f6e\u5bb9\u6613\u53d7\u5230\u906e\u6321\u5f71\u54cd\uff0c\u5bfc\u81f4\u89c2\u5bdf\u8d28\u91cf\u4e0b\u964d\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u8ba9\u673a\u5668\u4eba\u80fd\u591f\u4e3b\u52a8\u8c03\u6574\u89c2\u6d4b\u4f4d\u7f6e\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u89c6\u89c9\u4fe1\u606f\u3002", "method": "\u4f7f\u7528\u53cc\u673a\u68b0\u81c2\u7cfb\u7edf\uff0c\u4e00\u4e2a\u81c2\u4f5c\u4e3a\u89c2\u5bdf\u8005\u6784\u5efa3D\u9ad8\u65af\u6e85\u5c04\u8868\u793a\uff0c\u865a\u62df\u63a2\u7d22\u627e\u5230\u6700\u4f18\u76f8\u673a\u4f4d\u59ff\u5e76\u79fb\u52a8\u5230\u8be5\u4f4d\u7f6e\uff1b\u53e6\u4e00\u4e2a\u81c2\u4f5c\u4e3a\u6267\u884c\u8005\u4f7f\u7528\u89c2\u5bdf\u8005\u7684\u89c2\u6d4b\u6765\u6267\u884c\u7b56\u7565\u3002", "result": "\u4e0e\u9759\u6001\u6444\u50cf\u5934\u8bbe\u7f6e\u76f8\u6bd4\uff0c\u8f68\u8ff9\u8f6c\u79fb\u6027\u80fd\u63d0\u5347145%\uff08\u65e0\u906e\u6321\uff09\u548c233%\uff08\u6709\u906e\u6321\uff09\uff0c\u884c\u4e3a\u514b\u9686\u63d0\u534775%\u548c143%\u3002", "conclusion": "ObAct\u6846\u67b6\u901a\u8fc7\u4e3b\u52a8\u89c6\u89c9\u89c2\u6d4b\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u4eff\u5b66\u4e60\u7b56\u7565\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u906e\u6321\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002"}}
{"id": "2511.18284", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18284", "abs": "https://arxiv.org/abs/2511.18284", "authors": ["Tetiana Bas", "Krystian Novak"], "title": "Steering Latent Traits, Not Learned Facts: An Empirical Study of Activation Control Limits", "comment": null, "summary": "Large language models (LLMs) require precise behavior control for safe and effective deployment across diverse applications.\n  Activation steering offers a promising approach for LLMs' behavioral control. We focus on the question of how steering effectiveness varies across different behavior types and whether the nature of target behaviors can predict steering success. We address this through empirical analysis of activation steering across 50 behaviors that span persona archetypes, personality traits, misalignment behaviors, style cues, and impersonation of public figures. We present a set of comprehensive experiments on coefficient optimization, vector properties, and data requirements to provide comprehensive guidance for the implementation of activation steering. Our analysis demonstrates that steering effectiveness varies significantly by behavior type, with different behavioral categories exhibiting distinct response patterns to intervention strength. We find that trait expression follows an inverted-U curve with a steering coefficient strength. We also show that vector separation metrics do not predict steering success, but larger training datasets enable more aggressive steering. These findings provide empirically grounded guidance for implementing activation steering and demonstrate that steering effectiveness is heavily influenced by behavior type.", "AI": {"tldr": "\u6fc0\u6d3b\u5f15\u5bfc\u5728LLM\u884c\u4e3a\u63a7\u5236\u4e2d\u7684\u6709\u6548\u6027\u56e0\u884c\u4e3a\u7c7b\u578b\u800c\u5f02\uff0c\u4e0d\u540c\u884c\u4e3a\u7c7b\u522b\u5bf9\u5e72\u9884\u5f3a\u5ea6\u5448\u73b0\u4e0d\u540c\u54cd\u5e94\u6a21\u5f0f\uff0c\u7279\u8d28\u8868\u8fbe\u5448\u73b0\u5012U\u578b\u66f2\u7ebf\uff0c\u5411\u91cf\u5206\u79bb\u6307\u6807\u4e0d\u80fd\u9884\u6d4b\u5f15\u5bfc\u6210\u529f\uff0c\u4f46\u66f4\u5927\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u652f\u6301\u66f4\u6fc0\u8fdb\u7684\u5f15\u5bfc\u3002", "motivation": "\u7814\u7a76\u6fc0\u6d3b\u5f15\u5bfc\u5728\u4e0d\u540c\u884c\u4e3a\u7c7b\u578b\u4e2d\u7684\u6709\u6548\u6027\u53d8\u5316\uff0c\u63a2\u7d22\u76ee\u6807\u884c\u4e3a\u6027\u8d28\u662f\u5426\u80fd\u9884\u6d4b\u5f15\u5bfc\u6210\u529f\uff0c\u4e3aLLM\u884c\u4e3a\u63a7\u5236\u63d0\u4f9b\u5b9e\u8bc1\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u5bf950\u79cd\u884c\u4e3a\u7684\u6fc0\u6d3b\u5f15\u5bfc\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u6db5\u76d6\u4eba\u683c\u539f\u578b\u3001\u4eba\u683c\u7279\u8d28\u3001\u9519\u4f4d\u884c\u4e3a\u3001\u98ce\u683c\u7ebf\u7d22\u548c\u516c\u4f17\u4eba\u7269\u6a21\u4eff\uff0c\u8fdb\u884c\u7cfb\u6570\u4f18\u5316\u3001\u5411\u91cf\u5c5e\u6027\u548c\u6570\u636e\u9700\u6c42\u7684\u7efc\u5408\u5b9e\u9a8c\u3002", "result": "\u5f15\u5bfc\u6709\u6548\u6027\u56e0\u884c\u4e3a\u7c7b\u578b\u663e\u8457\u4e0d\u540c\uff0c\u7279\u8d28\u8868\u8fbe\u4e0e\u5f15\u5bfc\u7cfb\u6570\u5f3a\u5ea6\u5448\u5012U\u578b\u66f2\u7ebf\uff0c\u5411\u91cf\u5206\u79bb\u6307\u6807\u4e0d\u80fd\u9884\u6d4b\u5f15\u5bfc\u6210\u529f\uff0c\u66f4\u5927\u8bad\u7ec3\u6570\u636e\u96c6\u652f\u6301\u66f4\u6fc0\u8fdb\u5f15\u5bfc\u3002", "conclusion": "\u6fc0\u6d3b\u5f15\u5bfc\u7684\u6709\u6548\u6027\u53d7\u884c\u4e3a\u7c7b\u578b\u5f71\u54cd\u663e\u8457\uff0c\u4e3a\u5b9e\u65bd\u6fc0\u6d3b\u5f15\u5bfc\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u6307\u5bfc\uff0c\u8868\u660e\u884c\u4e3a\u6027\u8d28\u662f\u5f71\u54cd\u5f15\u5bfc\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2511.19055", "categories": ["eess.SY", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.19055", "abs": "https://arxiv.org/abs/2511.19055", "authors": ["Xinda Zheng", "Canchen Jiang", "Hao Wang"], "title": "Large Language Model-Assisted Planning of Electric Vehicle Charging Infrastructure with Real-World Case Study", "comment": null, "summary": "The growing demand for electric vehicle (EV) charging infrastructure presents significant planning challenges, requiring efficient strategies for investment and operation to deliver cost-effective charging services. However, the potential benefits of EV charging assignment, particularly in response to varying spatial-temporal patterns of charging demand, remain under-explored in infrastructure planning. This paper proposes an integrated approach that jointly optimizes investment decisions and charging assignments while accounting for spatial-temporal demand dynamics and their interdependencies. To support efficient model development, we leverage a large language model (LLM) to assist in generating and refining the mathematical formulation from structured natural-language descriptions, significantly reducing the modeling burden. The resulting optimization model enables optimal joint decision-making for investment and operation. Additionally, we propose a distributed optimization algorithm based on the Alternating Direction Method of Multipliers (ADMM) to address computational complexity in high-dimensional scenarios, which can be executed on standard computing platforms. We validate our approach through a case study using 1.5 million real-world travel records from Chengdu, China, demonstrating a 30% reduction in total cost compared to a baseline without EV assignment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u65b9\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7684\u6295\u8d44\u51b3\u7b56\u548c\u5145\u7535\u5206\u914d\uff0c\u8003\u8651\u65f6\u7a7a\u9700\u6c42\u52a8\u6001\u53ca\u5176\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u5e76\u4f7f\u7528LLM\u8f85\u52a9\u6570\u5b66\u5efa\u6a21\uff0c\u901a\u8fc7ADMM\u7b97\u6cd5\u89e3\u51b3\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u7684\u6295\u8d44\u548c\u8fd0\u8425\u7b56\u7565\u6765\u63d0\u4f9b\u6210\u672c\u6548\u76ca\u7684\u5145\u7535\u670d\u52a1\u3002\u7136\u800c\uff0c\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5206\u914d\u7684\u6f5c\u5728\u597d\u5904\uff0c\u7279\u522b\u662f\u5728\u5e94\u5bf9\u53d8\u5316\u7684\u65f6\u7a7a\u5145\u7535\u9700\u6c42\u6a21\u5f0f\u65b9\u9762\uff0c\u5728\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u4e2d\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u65b9\u6cd5\u8054\u5408\u4f18\u5316\u6295\u8d44\u51b3\u7b56\u548c\u5145\u7535\u5206\u914d\uff0c\u8003\u8651\u65f6\u7a7a\u9700\u6c42\u52a8\u6001\uff1b\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u4ece\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u548c\u7cbe\u70bc\u6570\u5b66\u516c\u5f0f\uff1b\u63d0\u51fa\u57fa\u4e8e\u4ea4\u66ff\u65b9\u5411\u4e58\u5b50\u6cd5(ADMM)\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u7b97\u6cd5\u5904\u7406\u9ad8\u7ef4\u573a\u666f\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u901a\u8fc7\u4e2d\u56fd\u6210\u90fd150\u4e07\u6761\u771f\u5b9e\u51fa\u884c\u8bb0\u5f55\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u6ca1\u6709\u7535\u52a8\u6c7d\u8f66\u5206\u914d\u7684\u57fa\u7840\u65b9\u6848\uff0c\u603b\u6210\u672c\u964d\u4f4e\u4e8630%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u6295\u8d44\u548c\u8fd0\u8425\u7684\u6700\u4f18\u8054\u5408\u51b3\u7b56\uff0c\u53ef\u5728\u6807\u51c6\u8ba1\u7b97\u5e73\u53f0\u4e0a\u6267\u884c\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5efa\u6a21\u8d1f\u62c5\u5e76\u63d0\u9ad8\u4e86\u89c4\u5212\u6548\u7387\u3002"}}
{"id": "2511.18265", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.18265", "abs": "https://arxiv.org/abs/2511.18265", "authors": ["Mohamed Afane", "Juntao Chen"], "title": "Analyzing and Optimizing the Distribution of Blood Lead Level Testing for Children in New York City: A Data-Driven Approach", "comment": null, "summary": "This study investigates blood lead level (BLL) rates and testing among children under six years of age across the 42 neighborhoods in New York City from 2005 to 2021. Despite a citywide general decline in BLL rates, disparities at the neighborhood level persist and are not addressed in the official reports, highlighting the need for this comprehensive analysis. In this paper, we analyze the current BLL testing distribution and cluster the neighborhoods using a k-medoids clustering algorithm. We propose an optimized approach that improves resource allocation efficiency by accounting for case incidences and neighborhood risk profiles using a grid search algorithm. Our findings demonstrate statistically significant improvements in case detection and enhanced fairness by focusing on under-served and high-risk groups. Additionally, we propose actionable recommendations to raise awareness among parents, including outreach at local daycare centers and kindergartens, among other venues.", "AI": {"tldr": "\u5206\u6790\u7ebd\u7ea6\u5e0242\u4e2a\u793e\u533a2005-2021\u5e746\u5c81\u4ee5\u4e0b\u513f\u7ae5\u8840\u94c5\u6c34\u5e73\u53ca\u68c0\u6d4b\u60c5\u51b5\uff0c\u63d0\u51fa\u4f18\u5316\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u68c0\u6d4b\u6548\u7387\u548c\u516c\u5e73\u6027", "motivation": "\u5c3d\u7ba1\u5168\u5e02\u8840\u94c5\u6c34\u5e73\u603b\u4f53\u4e0b\u964d\uff0c\u4f46\u793e\u533a\u5c42\u9762\u7684\u5dee\u5f02\u6301\u7eed\u5b58\u5728\u4e14\u672a\u5728\u5b98\u65b9\u62a5\u544a\u4e2d\u5f97\u5230\u89e3\u51b3\uff0c\u9700\u8981\u8fdb\u884c\u5168\u9762\u5206\u6790", "method": "\u4f7f\u7528k-medoids\u805a\u7c7b\u7b97\u6cd5\u5bf9\u793e\u533a\u8fdb\u884c\u805a\u7c7b\uff0c\u901a\u8fc7\u7f51\u683c\u641c\u7d22\u7b97\u6cd5\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u8003\u8651\u75c5\u4f8b\u53d1\u751f\u7387\u548c\u793e\u533a\u98ce\u9669\u7279\u5f81", "result": "\u53d1\u73b0\u7edf\u8ba1\u4e0a\u663e\u8457\u7684\u75c5\u4f8b\u68c0\u6d4b\u6539\u8fdb\uff0c\u901a\u8fc7\u5173\u6ce8\u670d\u52a1\u4e0d\u8db3\u548c\u9ad8\u98ce\u9669\u7fa4\u4f53\u589e\u5f3a\u4e86\u516c\u5e73\u6027", "conclusion": "\u63d0\u51fa\u5728\u65e5\u6258\u4e2d\u5fc3\u548c\u5e7c\u513f\u56ed\u7b49\u573a\u6240\u5f00\u5c55\u5916\u5c55\u6d3b\u52a8\u7684\u53ef\u884c\u5efa\u8bae\uff0c\u4ee5\u63d0\u9ad8\u5bb6\u957f\u610f\u8bc6"}}
{"id": "2511.18153", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18153", "abs": "https://arxiv.org/abs/2511.18153", "authors": ["Shreyas Kumar", "Barat S", "Debojit Das", "Yug Desai", "Siddhi Jain", "Rajesh Kumar", "Harish J. Palanthandalam-Madapusi"], "title": "A Coordinated Dual-Arm Framework for Delicate Snap-Fit Assemblies", "comment": "10 pages, 9 figures", "summary": "Delicate snap-fit assemblies, such as inserting a lens into an eye-wear frame or during electronics assembly, demand timely engagement detection and rapid force attenuation to prevent overshoot-induced component damage or assembly failure. We address these challenges with two key contributions. First, we introduce SnapNet, a lightweight neural network that detects snap-fit engagement from joint-velocity transients in real-time, showing that reliable detection can be achieved using proprioceptive signals without external sensors. Second, we present a dynamical-systems-based dual-arm coordination framework that integrates SnapNet driven detection with an event-triggered impedance modulation, enabling accurate alignment and compliant insertion during delicate snap-fit assemblies. Experiments across diverse geometries on a heterogeneous bimanual platform demonstrate high detection accuracy (over 96% recall) and up to a 30% reduction in peak impact forces compared to standard impedance control.", "AI": {"tldr": "\u63d0\u51faSnapNet\u795e\u7ecf\u7f51\u7edc\u5b9e\u65f6\u68c0\u6d4b\u5361\u6263\u88c5\u914d\u7684\u556e\u5408\uff0c\u7ed3\u5408\u57fa\u4e8e\u52a8\u6001\u7cfb\u7edf\u7684\u53cc\u81c2\u534f\u8c03\u6846\u67b6\uff0c\u5b9e\u73b0\u7cbe\u786e\u5bf9\u9f50\u548c\u67d4\u6027\u63d2\u5165\uff0c\u5728\u5f02\u8d28\u53cc\u624b\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u548c\u51b2\u51fb\u529b\u964d\u4f4e\u3002", "motivation": "\u7cbe\u5bc6\u5361\u6263\u88c5\u914d\uff08\u5982\u955c\u7247\u63d2\u5165\u773c\u955c\u6846\uff09\u9700\u8981\u53ca\u65f6\u68c0\u6d4b\u556e\u5408\u5e76\u5feb\u901f\u8870\u51cf\u529b\uff0c\u4ee5\u9632\u6b62\u8fc7\u51b2\u5bfc\u81f4\u7684\u7ec4\u4ef6\u635f\u574f\u6216\u88c5\u914d\u5931\u8d25\u3002", "method": "1) SnapNet\u8f7b\u91cf\u795e\u7ecf\u7f51\u7edc\u4ece\u5173\u8282\u901f\u5ea6\u77ac\u53d8\u5b9e\u65f6\u68c0\u6d4b\u5361\u6263\u556e\u5408\uff1b2) \u57fa\u4e8e\u52a8\u6001\u7cfb\u7edf\u7684\u53cc\u81c2\u534f\u8c03\u6846\u67b6\uff0c\u96c6\u6210SnapNet\u68c0\u6d4b\u4e0e\u4e8b\u4ef6\u89e6\u53d1\u7684\u963b\u6297\u8c03\u5236\u3002", "result": "\u5728\u5f02\u8d28\u53cc\u624b\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u5b9e\u9a8c\u663e\u793a\uff1a\u68c0\u6d4b\u53ec\u56de\u7387\u8d85\u8fc796%\uff0c\u4e0e\u6807\u51c6\u963b\u6297\u63a7\u5236\u76f8\u6bd4\u5cf0\u503c\u51b2\u51fb\u529b\u964d\u4f4e\u8fbe30%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ec5\u4f7f\u7528\u672c\u4f53\u611f\u89c9\u4fe1\u53f7\u5373\u53ef\u5b9e\u73b0\u53ef\u9760\u7684\u5361\u6263\u556e\u5408\u68c0\u6d4b\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u88c5\u914d\u8fc7\u7a0b\u4e2d\u7684\u51b2\u51fb\u529b\u3002"}}
{"id": "2511.18296", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18296", "abs": "https://arxiv.org/abs/2511.18296", "authors": ["Iman Rahimi"], "title": "Deep Learning Decision Support System for Open-Pit Mining Optimisation: GPU-Accelerated Planning Under Geological Uncertainty", "comment": "67 pages", "summary": "This study presents Part II of an AI-enhanced Decision Support System (DSS), extending Rahimi (2025, Part I) by introducing a fully uncertainty-aware optimization framework for long-term open-pit mine planning. Geological uncertainty is modelled using a Variational Autoencoder (VAE) trained on 50,000 spatial grade samples, enabling the generation of probabilistic, multi-scenario orebody realizations that preserve geological continuity and spatial correlation. These scenarios are optimized through a hybrid metaheuristic engine integrating Genetic Algorithms (GA), Large Neighborhood Search (LNS), Simulated Annealing (SA), and reinforcement-learning-based adaptive control. An \u03b5-constraint relaxation strategy governs the population exploration phase, allowing near-feasible schedule discovery early in the search and gradual tightening toward strict constraint satisfaction. GPU-parallel evaluation enables the simultaneous assessment of 65,536 geological scenarios, achieving near-real-time feasibility analysis. Results demonstrate up to 1.2 million-fold runtime improvement over IBM CPLEX and significantly higher expected NPV under geological uncertainty, confirming the DSS as a scalable and uncertainty-resilient platform for intelligent mine planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5168\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u957f\u671f\u9732\u5929\u77ff\u89c4\u5212\uff0c\u901a\u8fc7VAE\u5efa\u6a21\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\uff0c\u7ed3\u5408\u591a\u79cd\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\uff0c\u5728GPU\u5e76\u884c\u8ba1\u7b97\u4e0b\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u77ff\u5c71\u89c4\u5212\u65b9\u6cd5\u5728\u5904\u7406\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u5f3a\u97e7\u6027\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u751f\u6210\u6982\u7387\u6027\u591a\u573a\u666f\u77ff\u4f53\u5b9e\u73b0\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u3001\u5927\u90bb\u57df\u641c\u7d22\u3001\u6a21\u62df\u9000\u706b\u548c\u5f3a\u5316\u5b66\u4e60\u81ea\u9002\u5e94\u63a7\u5236\u7684\u6df7\u5408\u5143\u542f\u53d1\u5f0f\u5f15\u64ce\uff0c\u91c7\u7528\u03b5\u7ea6\u675f\u677e\u5f1b\u7b56\u7565\u548cGPU\u5e76\u884c\u8bc4\u4f30\u3002", "result": "\u76f8\u6bd4IBM CPLEX\u5b9e\u73b0\u4e86\u9ad8\u8fbe120\u4e07\u500d\u7684\u8fd0\u884c\u65f6\u95f4\u6539\u8fdb\uff0c\u5728\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\u4e0b\u83b7\u5f97\u663e\u8457\u66f4\u9ad8\u7684\u9884\u671f\u51c0\u73b0\u503c\u3002", "conclusion": "\u8be5\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u5f3a\u97e7\u6027\u7684\u667a\u80fd\u77ff\u5c71\u89c4\u5212\u5e73\u53f0\u3002"}}
{"id": "2511.19070", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19070", "abs": "https://arxiv.org/abs/2511.19070", "authors": ["Anis Ahmed", "Arefin Ahamed Shuvo", "Naruttam Kumar Roy", "Neloy Prosad Bishnu", "Ali Nasir"], "title": "Impact Analysis of COVID-19 in Bangladesh Power Sector and Recommendations based on Practical Data and Machine Learning Approach", "comment": null, "summary": "This paper investigates the impact of COVID-19 on the power sector in Bangladesh, how the country has dealt with it, and explores the path to stability. The study employs data visualisation and complex statistics to examine critical data about power systems in Bangladesh. This includes load patterns on a daily, monthly, annual, weekend, and weekday basis. Significant alterations in these patterns have been observed during our study e.g., in April and May of 2020, the power demand decreased by approximately 15.4% and 17.2%, respectively, compared to the corresponding period in 2019. We have used a Long-Short-Term Memory (LSTM) framework to predict the load profile of 2020 excluding COVID-19 effects. This model is compared with the actual load profile to determine the degree to which COVID-19 has impacted. The comparison indicates that the average power demand decreased by approximately 19.5% in April 2020 and 18.3% in May 2020, relative to its projected value. The study also investigates system stability by analyzing transmission loss and load factor, and the environmental effect by analyzing the Carbon Dioxide emission rate. Finally, the study provides recommendations for overcoming future disasters, such as developing more resilient power systems, investing in renewable energy, and improving energy efficiency.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86COVID-19\u5bf9\u5b5f\u52a0\u62c9\u56fd\u7535\u529b\u90e8\u95e8\u7684\u5f71\u54cd\uff0c\u4f7f\u7528LSTM\u6a21\u578b\u9884\u6d4b\u65e0\u75ab\u60c5\u65f6\u7684\u8d1f\u8377\uff0c\u53d1\u73b02020\u5e744-5\u6708\u7535\u529b\u9700\u6c42\u4e0b\u964d\u7ea619.5%\u548c18.3%\uff0c\u5e76\u63d0\u51fa\u4e86\u589e\u5f3a\u7535\u529b\u7cfb\u7edf\u97e7\u6027\u3001\u6295\u8d44\u53ef\u518d\u751f\u80fd\u6e90\u7b49\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76COVID-19\u5bf9\u5b5f\u52a0\u62c9\u56fd\u7535\u529b\u90e8\u95e8\u7684\u51b2\u51fb\uff0c\u63a2\u7d22\u5e94\u5bf9\u7b56\u7565\u548c\u7a33\u5b9a\u8def\u5f84\uff0c\u4e3a\u672a\u6765\u707e\u5bb3\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u91c7\u7528\u6570\u636e\u53ef\u89c6\u5316\u548c\u590d\u6742\u7edf\u8ba1\u5206\u6790\u7535\u529b\u7cfb\u7edf\u6570\u636e\uff0c\u4f7f\u7528LSTM\u6846\u67b6\u9884\u6d4b\u65e0\u75ab\u60c5\u8d1f\u8377\uff0c\u5bf9\u6bd4\u5b9e\u9645\u4e0e\u9884\u6d4b\u8d1f\u8377\u8bc4\u4f30\u75ab\u60c5\u5f71\u54cd\uff0c\u5206\u6790\u4f20\u8f93\u635f\u8017\u3001\u8d1f\u8377\u56e0\u5b50\u548c\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u3002", "result": "2020\u5e744-5\u6708\u7535\u529b\u9700\u6c42\u5206\u522b\u4e0b\u964d19.5%\u548c18.3%\uff0c\u4f20\u8f93\u635f\u8017\u548c\u8d1f\u8377\u56e0\u5b50\u53d8\u5316\uff0c\u78b3\u6392\u653e\u51cf\u5c11\u3002", "conclusion": "\u5efa\u8bae\u53d1\u5c55\u66f4\u5177\u97e7\u6027\u7684\u7535\u529b\u7cfb\u7edf\uff0c\u6295\u8d44\u53ef\u518d\u751f\u80fd\u6e90\uff0c\u63d0\u9ad8\u80fd\u6e90\u6548\u7387\uff0c\u4ee5\u5e94\u5bf9\u672a\u6765\u707e\u5bb3\u3002"}}
{"id": "2511.18170", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18170", "abs": "https://arxiv.org/abs/2511.18170", "authors": ["Kaier Liang", "Licheng Luo", "Yixuan Wang", "Mingyu Cai", "Cristian Ioan Vasile"], "title": "Time-aware Motion Planning in Dynamic Environments with Conformal Prediction", "comment": null, "summary": "Safe navigation in dynamic environments remains challenging due to uncertain obstacle behaviors and the lack of formal prediction guarantees. We propose two motion planning frameworks that leverage conformal prediction (CP): a global planner that integrates Safe Interval Path Planning (SIPP) for uncertainty-aware trajectory generation, and a local planner that performs online reactive planning. The global planner offers distribution-free safety guarantees for long-horizon navigation, while the local planner mitigates inaccuracies in obstacle trajectory predictions through adaptive CP, enabling robust and responsive motion in dynamic environments. To further enhance trajectory feasibility, we introduce an adaptive quantile mechanism in the CP-based uncertainty quantification. Instead of using a fixed confidence level, the quantile is automatically tuned to the optimal value that preserves trajectory feasibility, allowing the planner to adaptively tighten safety margins in regions with higher uncertainty. We validate the proposed framework through numerical experiments conducted in dynamic and cluttered environments. The project page is available at https://time-aware-planning.github.io", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u57fa\u4e8e\u5171\u5f62\u9884\u6d4b\u7684\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff1a\u5168\u5c40\u89c4\u5212\u5668\u96c6\u6210SIPP\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8f68\u8ff9\u751f\u6210\uff0c\u5c40\u90e8\u89c4\u5212\u5668\u6267\u884c\u5728\u7ebf\u53cd\u5e94\u5f0f\u89c4\u5212\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5171\u5f62\u9884\u6d4b\u589e\u5f3a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u52a8\u6001\u73af\u5883\u4e2d\u5b89\u5168\u5bfc\u822a\u9762\u4e34\u6311\u6218\uff0c\u4e3b\u8981\u7531\u4e8e\u969c\u788d\u7269\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\u548c\u7f3a\u4e4f\u5f62\u5f0f\u5316\u9884\u6d4b\u4fdd\u8bc1\u3002", "method": "\u4f7f\u7528\u5171\u5f62\u9884\u6d4b(CP)\u6784\u5efa\u4e24\u4e2a\u89c4\u5212\u6846\u67b6\uff1a\u5168\u5c40\u89c4\u5212\u5668\u7ed3\u5408\u5b89\u5168\u95f4\u9694\u8def\u5f84\u89c4\u5212(SIPP)\uff0c\u5c40\u90e8\u89c4\u5212\u5668\u8fdb\u884c\u5728\u7ebf\u53cd\u5e94\u5f0f\u89c4\u5212\uff1b\u5f15\u5165\u81ea\u9002\u5e94\u5206\u4f4d\u6570\u673a\u5236\u4f18\u5316\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5728\u52a8\u6001\u548c\u62e5\u6324\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5168\u5c40\u89c4\u5212\u5668\u63d0\u4f9b\u5206\u5e03\u65e0\u5173\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u5c40\u90e8\u89c4\u5212\u5668\u51cf\u8f7b\u969c\u788d\u7269\u8f68\u8ff9\u9884\u6d4b\u4e0d\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u5171\u5f62\u9884\u6d4b\u548c\u81ea\u9002\u5e94\u5206\u4f4d\u6570\u8c03\u6574\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u73af\u5883\u4e2d\u9c81\u68d2\u4e14\u54cd\u5e94\u8fc5\u901f\u7684\u8fd0\u52a8\u89c4\u5212\u3002"}}
{"id": "2511.18298", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18298", "abs": "https://arxiv.org/abs/2511.18298", "authors": ["Svitlana Volkova", "Peter Bautista", "Avinash Hiriyanna", "Gabriel Ganberg", "Isabel Erickson", "Zachary Klinefelter", "Nick Abele", "Hsien-Te Kao", "Grant Engberson"], "title": "Cross-Disciplinary Knowledge Retrieval and Synthesis: A Compound AI Architecture for Scientific Discovery", "comment": null, "summary": "The exponential growth of scientific knowledge has created significant barriers to cross-disciplinary knowledge discovery, synthesis and research collaboration. In response to this challenge, we present BioSage, a novel compound AI architecture that integrates LLMs with RAG, orchestrated specialized agents and tools to enable discoveries across AI, data science, biomedical, and biosecurity domains. Our system features several specialized agents including the retrieval agent with query planning and response synthesis that enable knowledge retrieval across domains with citation-backed responses, cross-disciplinary translation agents that align specialized terminology and methodologies, and reasoning agents that synthesize domain-specific insights with transparency, traceability and usability. We demonstrate the effectiveness of our BioSage system through a rigorous evaluation on scientific benchmarks (LitQA2, GPQA, WMDP, HLE-Bio) and introduce a new cross-modal benchmark for biology and AI, showing that our BioSage agents outperform vanilla and RAG approaches by 13\\%-21\\% powered by Llama 3.1. 70B and GPT-4o models. We perform causal investigations into compound AI system behavior and report significant performance improvements by adding RAG and agents over the vanilla models. Unlike other systems, our solution is driven by user-centric design principles and orchestrates specialized user-agent interaction workflows supporting scientific activities including but not limited to summarization, research debate and brainstorming. Our ongoing work focuses on multimodal retrieval and reasoning over charts, tables, and structured scientific data, along with developing comprehensive multimodal benchmarks for cross-disciplinary discovery. Our compound AI solution demonstrates significant potential for accelerating scientific advancement by reducing barriers between traditionally siloed domains.", "AI": {"tldr": "BioSage\u662f\u4e00\u4e2a\u590d\u5408AI\u67b6\u6784\uff0c\u96c6\u6210LLM\u3001RAG\u548c\u4e13\u4e1a\u5316\u4ee3\u7406\uff0c\u7528\u4e8e\u8de8\u5b66\u79d1\u77e5\u8bc6\u53d1\u73b0\uff0c\u5728\u751f\u7269\u533b\u5b66\u548cAI\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd513%-21%\u3002", "motivation": "\u79d1\u5b66\u77e5\u8bc6\u7684\u6307\u6570\u7ea7\u589e\u957f\u4e3a\u8de8\u5b66\u79d1\u77e5\u8bc6\u53d1\u73b0\u3001\u7efc\u5408\u548c\u7814\u7a76\u5408\u4f5c\u521b\u9020\u4e86\u663e\u8457\u969c\u788d\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6253\u7834\u4f20\u7edf\u9886\u57df\u95f4\u7684\u58c1\u5792\u3002", "method": "\u91c7\u7528\u590d\u5408AI\u67b6\u6784\uff0c\u96c6\u6210LLM\u4e0eRAG\uff0c\u901a\u8fc7\u4e13\u4e1a\u5316\u4ee3\u7406\uff08\u68c0\u7d22\u4ee3\u7406\u3001\u8de8\u5b66\u79d1\u7ffb\u8bd1\u4ee3\u7406\u3001\u63a8\u7406\u4ee3\u7406\uff09\u5b9e\u73b0\u8de8\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u5177\u6709\u900f\u660e\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u7528\u6027\u3002", "result": "\u5728\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff08LitQA2\u3001GPQA\u3001WMDP\u3001HLE-Bio\uff09\u548c\u65b0\u521b\u5efa\u7684\u8de8\u6a21\u6001\u57fa\u51c6\u4e0a\uff0cBioSage\u4ee3\u7406\u4f7f\u7528Llama 3.1 70B\u548cGPT-4o\u6a21\u578b\uff0c\u6027\u80fd\u6bd4\u666e\u901a\u548cRAG\u65b9\u6cd5\u63d0\u534713%-21%\u3002", "conclusion": "\u590d\u5408AI\u89e3\u51b3\u65b9\u6848\u901a\u8fc7\u51cf\u5c11\u4f20\u7edf\u5b64\u7acb\u9886\u57df\u95f4\u7684\u969c\u788d\uff0c\u5728\u52a0\u901f\u79d1\u5b66\u8fdb\u6b65\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u805a\u7126\u591a\u6a21\u6001\u68c0\u7d22\u548c\u63a8\u7406\u3002"}}
{"id": "2511.19084", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.19084", "abs": "https://arxiv.org/abs/2511.19084", "authors": ["Ruchuan Ou", "Learta Januzi", "Jonas Schie\u00dfl", "Michael Heinrich Baumann", "Lars Gr\u00fcne", "Timm Faulwasser"], "title": "PolyOCP.jl -- A Julia Package for Stochastic OCPs and MPC", "comment": null, "summary": "The consideration of stochastic uncertainty in optimal and predictive control is a well-explored topic. Recently Polynomial Chaos Expansions (PCE) have seen a lot of considerations for problems involving stochastically uncertain system parameters and also for problems with additive stochastic i.i.d. disturbances. While there exist a number of open-source PCE toolboxes, tailored open-source codes for the solution of OCPs involving additive stochastic i.i.d. disturbances in julia are not available. Hence, this paper introduces the toolbox PolyOCP.jl which enables to efficiently solve stochastic OCPs for a large class of disturbance distributions. We explain the main mathematical concepts between the PCE transcription of stochastic OCPs and how they are provided in the toolbox. We draw upon two examples to illustrate the functionalities of PolyOCP.jl.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PolyOCP.jl\u5de5\u5177\u7bb1\uff0c\u7528\u4e8e\u5728Julia\u4e2d\u9ad8\u6548\u89e3\u51b3\u6d89\u53ca\u52a0\u6027\u968f\u673ai.i.d.\u6270\u52a8\u7684\u968f\u673a\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u5f00\u6e90\u4ee3\u7801\u7684\u7a7a\u767d\u3002", "motivation": "\u867d\u7136\u5b58\u5728\u8bb8\u591a\u5f00\u6e90PCE\u5de5\u5177\u7bb1\uff0c\u4f46\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3\u6d89\u53ca\u52a0\u6027\u968f\u673ai.i.d.\u6270\u52a8\u7684OCP\u95ee\u9898\u7684Julia\u5f00\u6e90\u4ee3\u7801\u5c1a\u4e0d\u53ef\u7528\u3002", "method": "\u4f7f\u7528\u591a\u9879\u5f0f\u6df7\u6c8c\u5c55\u5f00(PCE)\u65b9\u6cd5\uff0c\u5c06\u968f\u673aOCP\u95ee\u9898\u8f6c\u5316\u4e3a\u786e\u5b9a\u6027\u5f62\u5f0f\uff0c\u5e76\u901a\u8fc7PolyOCP.jl\u5de5\u5177\u7bb1\u5b9e\u73b0\u3002", "result": "\u5f00\u53d1\u4e86PolyOCP.jl\u5de5\u5177\u7bb1\uff0c\u80fd\u591f\u9ad8\u6548\u89e3\u51b3\u591a\u79cd\u6270\u52a8\u5206\u5e03\u7684\u968f\u673aOCP\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u529f\u80fd\u3002", "conclusion": "PolyOCP.jl\u4e3a\u968f\u673a\u6700\u4f18\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5904\u7406\u52a0\u6027\u968f\u673ai.i.d.\u6270\u52a8\u3002"}}
{"id": "2511.18403", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.18403", "abs": "https://arxiv.org/abs/2511.18403", "authors": ["Aayush Kumar", "Sanket Mhatre"], "title": "UnWEIRDing LLM Entity Recommendations", "comment": null, "summary": "Large Language Models have been widely been adopted by users for writing tasks such as sentence completions. While this can improve writing efficiency, prior research shows that LLM-generated suggestions may exhibit cultural biases which may be difficult for users to detect, especially in educational contexts for non-native English speakers. While such prior work has studied the biases in LLM moral value alignment, we aim to investigate cultural biases in LLM recommendations for real-world entities. To do so, we use the WEIRD (Western, Educated, Industrialized, Rich and Democratic) framework to evaluate recommendations by various LLMs across a dataset of fine-grained entities, and apply pluralistic prompt-based strategies to mitigate these biases. Our results indicate that while such prompting strategies do reduce such biases, this reduction is not consistent across different models, and recommendations for some types of entities are more biased than others.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLM\u5728\u63a8\u8350\u771f\u5b9e\u4e16\u754c\u5b9e\u4f53\u65f6\u5b58\u5728\u7684\u6587\u5316\u504f\u89c1\uff0c\u4f7f\u7528WEIRD\u6846\u67b6\u8bc4\u4f30\u4e0d\u540cLLM\u7684\u63a8\u8350\uff0c\u5e76\u5e94\u7528\u591a\u5143\u5316\u63d0\u793a\u7b56\u7565\u6765\u51cf\u8f7b\u8fd9\u4e9b\u504f\u89c1\u3002", "motivation": "\u867d\u7136LLM\u88ab\u5e7f\u6cdb\u7528\u4e8e\u5199\u4f5c\u4efb\u52a1\uff0c\u4f46\u7814\u7a76\u8868\u660eLLM\u751f\u6210\u7684\u5efa\u8bae\u53ef\u80fd\u5b58\u5728\u6587\u5316\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u6559\u80b2\u73af\u5883\u4e2d\u5bf9\u975e\u82f1\u8bed\u6bcd\u8bed\u8005\u800c\u8a00\u96be\u4ee5\u5bdf\u89c9\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8LLM\u9053\u5fb7\u4ef7\u503c\u5bf9\u9f50\u4e2d\u7684\u504f\u89c1\uff0c\u672c\u6587\u65e8\u5728\u8c03\u67e5LLM\u5bf9\u771f\u5b9e\u4e16\u754c\u5b9e\u4f53\u63a8\u8350\u4e2d\u7684\u6587\u5316\u504f\u89c1\u3002", "method": "\u4f7f\u7528WEIRD\u6846\u67b6\u8bc4\u4f30\u5404\u79cdLLM\u5728\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u6570\u636e\u96c6\u4e0a\u7684\u63a8\u8350\uff0c\u5e76\u5e94\u7528\u591a\u5143\u5316\u63d0\u793a\u7b56\u7565\u6765\u51cf\u8f7b\u504f\u89c1\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136\u63d0\u793a\u7b56\u7565\u786e\u5b9e\u51cf\u5c11\u4e86\u504f\u89c1\uff0c\u4f46\u8fd9\u79cd\u51cf\u5c11\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5e76\u4e0d\u4e00\u81f4\uff0c\u4e14\u67d0\u4e9b\u7c7b\u578b\u5b9e\u4f53\u7684\u63a8\u8350\u6bd4\u5176\u4ed6\u7c7b\u578b\u66f4\u5177\u504f\u89c1\u3002", "conclusion": "LLM\u5728\u63a8\u8350\u771f\u5b9e\u4e16\u754c\u5b9e\u4f53\u65f6\u5b58\u5728\u6587\u5316\u504f\u89c1\uff0c\u591a\u5143\u5316\u63d0\u793a\u7b56\u7565\u80fd\u90e8\u5206\u51cf\u8f7b\u504f\u89c1\uff0c\u4f46\u6548\u679c\u56e0\u6a21\u578b\u548c\u5b9e\u4f53\u7c7b\u578b\u800c\u5f02\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2511.18183", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18183", "abs": "https://arxiv.org/abs/2511.18183", "authors": ["Yixuan Jia", "Qingyuan Li", "Jonathan P. How"], "title": "Off-Road Navigation via Implicit Neural Representation of Terrain Traversability", "comment": "9 pages", "summary": "Autonomous off-road navigation requires robots to estimate terrain traversability from onboard sensors and plan accordingly. Conventional approaches typically rely on sampling-based planners such as MPPI to generate short-term control actions that aim to minimize traversal time and risk measures derived from the traversability estimates. These planners can react quickly but optimize only over a short look-ahead window, limiting their ability to reason about the full path geometry, which is important for navigating in challenging off-road environments. Moreover, they lack the ability to adjust speed based on the terrain bumpiness, which is important for smooth navigation on challenging terrains. In this paper, we introduce TRAIL (Traversability with an Implicit Learned Representation), an off-road navigation framework that leverages an implicit neural representation to continuously parameterize terrain properties. This representation yields spatial gradients that enable integration with a novel gradient-based trajectory optimization method that adapts the path geometry and speed profile based on terrain traversability.", "AI": {"tldr": "\u63d0\u51faTRAIL\u6846\u67b6\uff0c\u5229\u7528\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u8fde\u7eed\u53c2\u6570\u5316\u5730\u5f62\u5c5e\u6027\uff0c\u7ed3\u5408\u68af\u5ea6\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\u81ea\u9002\u5e94\u8c03\u6574\u8def\u5f84\u51e0\u4f55\u548c\u901f\u5ea6\u5256\u9762", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u91c7\u6837\u7684\u89c4\u5212\u5668\u53ea\u80fd\u4f18\u5316\u77ed\u671f\u89c6\u91ce\uff0c\u65e0\u6cd5\u8003\u8651\u5b8c\u6574\u8def\u5f84\u51e0\u4f55\uff0c\u4e14\u7f3a\u4e4f\u6839\u636e\u5730\u5f62\u98a0\u7c38\u5ea6\u8c03\u6574\u901f\u5ea6\u7684\u80fd\u529b", "method": "\u4f7f\u7528\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u8fde\u7eed\u53c2\u6570\u5316\u5730\u5f62\u5c5e\u6027\uff0c\u7ed3\u5408\u65b0\u9896\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5", "result": "\u80fd\u591f\u81ea\u9002\u5e94\u8c03\u6574\u8def\u5f84\u51e0\u4f55\u548c\u901f\u5ea6\u5256\u9762", "conclusion": "TRAIL\u6846\u67b6\u80fd\u591f\u66f4\u597d\u5730\u5728\u6311\u6218\u6027\u8d8a\u91ce\u73af\u5883\u4e2d\u8fdb\u884c\u5bfc\u822a"}}
{"id": "2511.18302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18302", "abs": "https://arxiv.org/abs/2511.18302", "authors": ["Mohan Reddy"], "title": "The Catastrophic Paradox of Human Cognitive Frameworks in Large Language Model Evaluation: A Comprehensive Empirical Analysis of the CHC-LLM Incompatibility", "comment": null, "summary": "This investigation presents an empirical analysis of the incompatibility between human psychometric frameworks and Large Language Model evaluation. Through systematic assessment of nine frontier models including GPT-5, Claude Opus 4.1, and Gemini 3 Pro Preview using the Cattell-Horn-Carroll theory of intelligence, we identify a paradox that challenges the foundations of cross-substrate cognitive evaluation. Our results show that models achieving above-average human IQ scores ranging from 85.0 to 121.4 simultaneously exhibit binary accuracy rates approaching zero on crystallized knowledge tasks, with an overall judge-binary correlation of r = 0.175 (p = 0.001, n = 1800). This disconnect appears most strongly in the crystallized intelligence domain, where every evaluated model achieved perfect binary accuracy while judge scores ranged from 25 to 62 percent, which cannot occur under valid measurement conditions. Using statistical analyses including Item Response Theory modeling, cross-vendor judge validation, and paradox severity indexing, we argue that this disconnect reflects a category error in applying biological cognitive architectures to transformer-based systems. The implications extend beyond methodology to challenge assumptions about intelligence, measurement, and anthropomorphic biases in AI evaluation. We propose a framework for developing native machine cognition assessments that recognize the non-human nature of artificial intelligence.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u6846\u67b6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5b58\u5728\u4e0d\u517c\u5bb9\u6027\uff0c\u6a21\u578b\u5728IQ\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\u4f46\u5728\u5177\u4f53\u77e5\u8bc6\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u63a5\u8fd1\u96f6\uff0c\u63ed\u793a\u4e86\u8de8\u57fa\u8d28\u8ba4\u77e5\u8bc4\u4f30\u7684\u6839\u672c\u6027\u6096\u8bba\u3002", "motivation": "\u63a2\u7d22\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u6846\u67b6\uff08\u5982CHC\u667a\u529b\u7406\u8bba\uff09\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u9002\u7528\u6027\uff0c\u63ed\u793a\u4f20\u7edf\u8ba4\u77e5\u8bc4\u4f30\u65b9\u6cd5\u5728AI\u7cfb\u7edf\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528CHC\u667a\u529b\u7406\u8bba\u7cfb\u7edf\u8bc4\u4f309\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u5305\u62ecGPT-5\u3001Claude Opus 4.1\u548cGemini 3 Pro Preview\uff0c\u91c7\u7528\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u5efa\u6a21\u3001\u8de8\u4f9b\u5e94\u5546\u8bc4\u59d4\u9a8c\u8bc1\u548c\u6096\u8bba\u4e25\u91cd\u6027\u6307\u6570\u7b49\u7edf\u8ba1\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u6a21\u578b\u5728\u4eba\u7c7bIQ\u6d4b\u8bd5\u4e2d\u83b7\u5f9785.0-121.4\u7684\u5206\u6570\uff0c\u4f46\u5728\u6676\u4f53\u77e5\u8bc6\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u63a5\u8fd1\u96f6\uff0c\u8bc4\u59d4-\u4e8c\u5143\u51c6\u786e\u7387\u76f8\u5173\u6027\u4ec5\u4e3ar=0.175\u3002\u6676\u4f53\u667a\u529b\u9886\u57df\u51fa\u73b0\u6700\u4e25\u91cd\u7684\u4e0d\u4e00\u81f4\uff0c\u6a21\u578b\u83b7\u5f97\u5b8c\u7f8e\u4e8c\u5143\u51c6\u786e\u7387\u800c\u8bc4\u59d4\u8bc4\u5206\u4ec5\u4e3a25-62%\u3002", "conclusion": "\u8fd9\u79cd\u4e0d\u4e00\u81f4\u53cd\u6620\u4e86\u5c06\u751f\u7269\u8ba4\u77e5\u67b6\u6784\u5e94\u7528\u4e8e\u57fa\u4e8etransformer\u7cfb\u7edf\u7684\u8303\u7574\u9519\u8bef\uff0c\u9700\u8981\u5f00\u53d1\u627f\u8ba4AI\u975e\u4eba\u7c7b\u672c\u8d28\u7684\u539f\u751f\u673a\u5668\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2511.19143", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19143", "abs": "https://arxiv.org/abs/2511.19143", "authors": ["Lisa Piccinin", "Valentina Breschi", "Chiara Ravazzi", "Fabrizio Dabbene", "Mara Tanelli"], "title": "Optimal policy design for innovation diffusion: shaping today's incentives for transforming the future", "comment": "Submitted to IFAC World Congress 2026 and Control Engineering Practice", "summary": "In this paper, we propose a new framework for the design of incentives aimed at promoting innovation diffusion in social influence networks. In particular, our framework relies on an extension of the Friedkin and Johnsen opinion dynamics model characterizing the effects of (i) short-memory incentives, which have an immediate yet transient impact, and (ii) long-term structural incentives, whose impact persists via an exponentially decaying memory. We propose to design these incentives via a model-predictive control (MPC) scheme over an augmented state that captures the memory in our opinion dynamics model, yielding a convex quadratic program with linear constraints. Our numerical simulations based on data on sustainable mobility habits show the effectiveness of the proposed approach, which balances large-scale adoption and resource allocation", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u793e\u4ea4\u5f71\u54cd\u7f51\u7edc\u4e2d\u4fc3\u8fdb\u521b\u65b0\u6269\u6563\u7684\u6fc0\u52b1\u8bbe\u8ba1\u6846\u67b6\uff0c\u7ed3\u5408\u77ed\u671f\u8bb0\u5fc6\u6fc0\u52b1\u548c\u957f\u671f\u7ed3\u6784\u6fc0\u52b1\uff0c\u901a\u8fc7\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u65b9\u6848\u5b9e\u73b0\u6709\u6548\u5e73\u8861\u5927\u89c4\u6a21\u91c7\u7528\u548c\u8d44\u6e90\u5206\u914d", "motivation": "\u65e8\u5728\u89e3\u51b3\u521b\u65b0\u6269\u6563\u8fc7\u7a0b\u4e2d\u6fc0\u52b1\u8bbe\u8ba1\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5982\u4f55\u5e73\u8861\u77ed\u671f\u6548\u679c\u548c\u957f\u671f\u5f71\u54cd\uff0c\u4ee5\u53ca\u5982\u4f55\u6709\u6548\u5206\u914d\u8d44\u6e90\u6765\u4fc3\u8fdb\u5927\u89c4\u6a21\u91c7\u7528", "method": "\u6269\u5c55Friedkin\u548c Johnsen\u610f\u89c1\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5f15\u5165\u77ed\u671f\u8bb0\u5fc6\u6fc0\u52b1\u548c\u957f\u671f\u7ed3\u6784\u6fc0\u52b1\uff0c\u91c7\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u65b9\u6848\u8bbe\u8ba1\u6fc0\u52b1\uff0c\u5f62\u6210\u5e26\u7ebf\u6027\u7ea6\u675f\u7684\u51f8\u4e8c\u6b21\u89c4\u5212\u95ee\u9898", "result": "\u57fa\u4e8e\u53ef\u6301\u7eed\u51fa\u884c\u4e60\u60ef\u6570\u636e\u7684\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5e73\u8861\u5927\u89c4\u6a21\u91c7\u7528\u548c\u8d44\u6e90\u5206\u914d\u65b9\u9762\u5177\u6709\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bbe\u8ba1\u4fc3\u8fdb\u521b\u65b0\u6269\u6563\u7684\u6fc0\u52b1\u63aa\u65bd\uff0c\u901a\u8fc7\u7ed3\u5408\u77ed\u671f\u548c\u957f\u671f\u6fc0\u52b1\u7b56\u7565\uff0c\u5b9e\u73b0\u8d44\u6e90\u4f18\u5316\u914d\u7f6e\u548c\u5e7f\u6cdb\u91c7\u7528"}}
{"id": "2511.18203", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18203", "abs": "https://arxiv.org/abs/2511.18203", "authors": ["Ziyi Yang", "Benned Hedegaard", "Ahmed Jaafar", "Yichen Wei", "Skye Thompson", "Shreyas S. Raman", "Haotian Fu", "Stefanie Tellex", "George Konidaris", "David Paulius", "Naman Shah"], "title": "SkillWrapper: Generative Predicate Invention for Skill Abstraction", "comment": null, "summary": "Generalizing from individual skill executions to solving long-horizon tasks remains a core challenge in building autonomous agents. A promising direction is learning high-level, symbolic abstractions of the low-level skills of the agents, enabling reasoning and planning independent of the low-level state space. Among possible high-level representations, object-centric skill abstraction with symbolic predicates has been proven to be efficient because of its compatibility with domain-independent planners. Recent advances in foundation models have made it possible to generate symbolic predicates that operate on raw sensory inputs, a process we call generative predicate invention, to facilitate downstream abstraction learning. However, it remains unclear which formal properties the learned representations must satisfy, and how they can be learned to guarantee these properties. In this paper, we address both questions by presenting a formal theory of generative predicate invention for skill abstraction, resulting in symbolic operators that can be used for provably sound and complete planning. Within this framework, we propose SkillWrapper, a method that leverages foundation models to actively collect robot data and learn human-interpretable, plannable representations of black-box skills, using only RGB image observations. Our extensive empirical evaluation in simulation and on real robots shows that SkillWrapper learns abstract representations that enable solving unseen, long-horizon tasks in the real world with black-box skills.", "AI": {"tldr": "\u63d0\u51fa\u4e86SkillWrapper\u65b9\u6cd5\uff0c\u5229\u7528\u57fa\u7840\u6a21\u578b\u4e3b\u52a8\u6536\u96c6\u673a\u5668\u4eba\u6570\u636e\uff0c\u4eceRGB\u56fe\u50cf\u4e2d\u5b66\u4e60\u53ef\u89c4\u5212\u7684\u9ed1\u76d2\u6280\u80fd\u62bd\u8c61\u8868\u793a\uff0c\u4ee5\u89e3\u51b3\u957f\u65f6\u57df\u4efb\u52a1\u3002", "motivation": "\u4ece\u4e2a\u4f53\u6280\u80fd\u6267\u884c\u6cdb\u5316\u5230\u89e3\u51b3\u957f\u65f6\u57df\u4efb\u52a1\u662f\u81ea\u4e3b\u667a\u80fd\u4f53\u7684\u6838\u5fc3\u6311\u6218\u3002\u9700\u8981\u5b66\u4e60\u4e0e\u4f4e\u5c42\u72b6\u6001\u7a7a\u95f4\u65e0\u5173\u7684\u9ad8\u5c42\u7b26\u53f7\u62bd\u8c61\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u5b66\u4e60\u8868\u793a\u5f62\u5f0f\u5c5e\u6027\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86\u751f\u6210\u8c13\u8bcd\u53d1\u660e\u7684\u5f62\u5f0f\u7406\u8bba\u6846\u67b6\uff0c\u5f00\u53d1\u4e86SkillWrapper\u65b9\u6cd5\uff0c\u5229\u7528\u57fa\u7840\u6a21\u578b\u4e3b\u52a8\u6536\u96c6\u6570\u636e\uff0c\u4eceRGB\u56fe\u50cf\u4e2d\u5b66\u4e60\u4eba\u7c7b\u53ef\u89e3\u91ca\u3001\u53ef\u89c4\u5212\u7684\u9ed1\u76d2\u6280\u80fd\u8868\u793a\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSkillWrapper\u5b66\u4e60\u7684\u62bd\u8c61\u8868\u793a\u80fd\u591f\u4f7f\u7528\u9ed1\u76d2\u6280\u80fd\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u672a\u89c1\u8fc7\u7684\u957f\u65f6\u57df\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u53ef\u8bc1\u660e\u6b63\u786e\u4e14\u5b8c\u5907\u7684\u89c4\u5212\u7b26\u53f7\u64cd\u4f5c\u7b26\uff0c\u4e3a\u6280\u80fd\u62bd\u8c61\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u6709\u6548\u6027\u3002"}}
{"id": "2511.18319", "categories": ["cs.AI", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18319", "abs": "https://arxiv.org/abs/2511.18319", "authors": ["Xian Yeow Lee", "Lasitha Vidyaratne", "Gregory Sin", "Ahmed Farahat", "Chetan Gupta"], "title": "Weakly-supervised Latent Models for Task-specific Visual-Language Control", "comment": null, "summary": "Autonomous inspection in hazardous environments requires AI agents that can interpret high-level goals and execute precise control. A key capability for such agents is spatial grounding, for example when a drone must center a detected object in its camera view to enable reliable inspection. While large language models provide a natural interface for specifying goals, using them directly for visual control achieves only 58\\% success in this task. We envision that equipping agents with a world model as a tool would allow them to roll out candidate actions and perform better in spatially grounded settings, but conventional world models are data and compute intensive. To address this, we propose a task-specific latent dynamics model that learns state-specific action-induced shifts in a shared latent space using only goal-state supervision. The model leverages global action embeddings and complementary training losses to stabilize learning. In experiments, our approach achieves 71\\% success and generalizes to unseen images and instructions, highlighting the potential of compact, domain-specific latent dynamics models for spatial alignment in autonomous inspection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u81ea\u4e3b\u68c0\u67e5\u7684\u7279\u5b9a\u4efb\u52a1\u6f5c\u5728\u52a8\u6001\u6a21\u578b\uff0c\u901a\u8fc7\u76ee\u6807\u72b6\u6001\u76d1\u7763\u5b66\u4e60\u72b6\u6001\u7279\u5b9a\u7684\u52a8\u4f5c\u8bf1\u5bfc\u8f6c\u79fb\uff0c\u5728\u7a7a\u95f4\u5bf9\u9f50\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e8671%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u5371\u9669\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u68c0\u67e5\u9700\u8981\u80fd\u591f\u89e3\u91ca\u9ad8\u7ea7\u76ee\u6807\u5e76\u6267\u884c\u7cbe\u786e\u63a7\u5236\u7684AI\u4ee3\u7406\uff0c\u7a7a\u95f4\u63a5\u5730\u662f\u5173\u952e\u80fd\u529b\u3002\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6307\u5b9a\u76ee\u6807\u7684\u81ea\u7136\u63a5\u53e3\uff0c\u4f46\u76f4\u63a5\u7528\u4e8e\u89c6\u89c9\u63a7\u5236\u5728\u6b64\u4efb\u52a1\u4e2d\u4ec5\u8fbe\u523058%\u7684\u6210\u529f\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u7279\u5b9a\u4efb\u52a1\u7684\u6f5c\u5728\u52a8\u6001\u6a21\u578b\uff0c\u5728\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u4e2d\u4f7f\u7528\u4ec5\u76ee\u6807\u72b6\u6001\u76d1\u7763\u5b66\u4e60\u72b6\u6001\u7279\u5b9a\u7684\u52a8\u4f5c\u8bf1\u5bfc\u8f6c\u79fb\uff0c\u5229\u7528\u5168\u5c40\u52a8\u4f5c\u5d4c\u5165\u548c\u4e92\u8865\u8bad\u7ec3\u635f\u5931\u6765\u7a33\u5b9a\u5b66\u4e60\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7a7a\u95f4\u5bf9\u9f50\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e8671%\u7684\u6210\u529f\u7387\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u56fe\u50cf\u548c\u6307\u4ee4\u3002", "conclusion": "\u7d27\u51d1\u7684\u9886\u57df\u7279\u5b9a\u6f5c\u5728\u52a8\u6001\u6a21\u578b\u5728\u81ea\u4e3b\u68c0\u67e5\u7684\u7a7a\u95f4\u5bf9\u9f50\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2511.19231", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19231", "abs": "https://arxiv.org/abs/2511.19231", "authors": ["Amy K. Strong", "Ali Kashani", "Claus Danielson", "Leila J. Bridgeman"], "title": "Data-driven certificates of constraint enforcement and stability for unmodeled, discrete dynamical systems using tree data structures", "comment": null, "summary": "This paper addresses the critical challenge of developing data-driven certificates for the stability and safety of unmodeled dynamical systems by leveraging a tree data structure and an upper bound of the system's Lipschitz constant. Previously, an invariant set was synthesized by iteratively expanding an initial invariant set. In contrast, this work iteratively prunes the constraint set to synthesize an invariant set -- eliminating the need for a known, initial invariant set. Furthermore, we provide stability assurances by characterizing the asymptotic stability of the system relative to an invariant approximation of the minimal positive invariant set through synthesis of a discontinuous piecewise affine Lyapunov function over the computed invariant set. The proposed method takes inspiration from subdivision techniques and requires no prior system knowledge beyond Lipschitz continuity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6811\u6570\u636e\u7ed3\u6784\u548cLipschitz\u5e38\u6570\u4e0a\u754c\u7684\u65b9\u6cd5\uff0c\u4e3a\u672a\u5efa\u6a21\u52a8\u6001\u7cfb\u7edf\u5f00\u53d1\u6570\u636e\u9a71\u52a8\u7684\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u8bc1\u4e66\uff0c\u901a\u8fc7\u8fed\u4ee3\u4fee\u526a\u7ea6\u675f\u96c6\u6765\u5408\u6210\u4e0d\u53d8\u96c6\uff0c\u65e0\u9700\u5df2\u77e5\u521d\u59cb\u4e0d\u53d8\u96c6\u3002", "motivation": "\u89e3\u51b3\u4e3a\u672a\u5efa\u6a21\u52a8\u6001\u7cfb\u7edf\u5f00\u53d1\u6570\u636e\u9a71\u52a8\u7684\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u8bc1\u4e66\u7684\u5173\u952e\u6311\u6218\uff0c\u6d88\u9664\u5bf9\u5df2\u77e5\u521d\u59cb\u4e0d\u53d8\u96c6\u7684\u4f9d\u8d56\u9700\u6c42\u3002", "method": "\u5229\u7528\u6811\u6570\u636e\u7ed3\u6784\u548c\u7cfb\u7edfLipschitz\u5e38\u6570\u4e0a\u754c\uff0c\u901a\u8fc7\u8fed\u4ee3\u4fee\u526a\u7ea6\u675f\u96c6\u6765\u5408\u6210\u4e0d\u53d8\u96c6\uff0c\u5e76\u57fa\u4e8e\u8ba1\u7b97\u7684\u4e0d\u53d8\u96c6\u5408\u6210\u4e0d\u8fde\u7eed\u5206\u6bb5\u4eff\u5c04Lyapunov\u51fd\u6570\u6765\u63d0\u4f9b\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002", "result": "\u80fd\u591f\u5408\u6210\u4e0d\u53d8\u96c6\u5e76\u8868\u5f81\u7cfb\u7edf\u76f8\u5bf9\u4e8e\u6700\u5c0f\u6b63\u4e0d\u53d8\u96c6\u7684\u4e0d\u53d8\u8fd1\u4f3c\u7684\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u4ec5\u9700Lipschitz\u8fde\u7eed\u6027\u800c\u65e0\u9700\u5148\u9a8c\u7cfb\u7edf\u77e5\u8bc6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53d7\u7ec6\u5206\u6280\u672f\u542f\u53d1\uff0c\u4e3a\u672a\u5efa\u6a21\u52a8\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u5148\u9a8c\u7cfb\u7edf\u77e5\u8bc6\u7684\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u8bc1\u4e66\u5f00\u53d1\u6846\u67b6\u3002"}}
{"id": "2511.18558", "categories": ["cs.CY", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.18558", "abs": "https://arxiv.org/abs/2511.18558", "authors": ["Genoveva Vargas-Solar"], "title": "Bridging the Divide: Gender, Diversity, and Inclusion Gaps in Data Science and Artificial Intelligence Across Academia and Industry in the majority and minority worlds", "comment": null, "summary": "As Artificial Intelligence (AI) and Data Science (DS) become pervasive, addressing gender disparities and diversity gaps in their workforce is urgent. These rapidly evolving fields have been further impacted by the COVID-19 pandemic, which disproportionately affected women and minorities, exposing deep-seated inequalities. Both academia and industry shape these disciplines, making it essential to map disparities across sectors, occupations, and skill levels. The dominance of men in AI and DS reinforces gender biases in machine learning systems, creating a feedback loop of inequality. This imbalance is a matter of social and economic justice and an ethical challenge, demanding value-driven diversity. Root causes include unequal access to education, disparities in academic programs, limited government investments, and underrepresented communities' perceptions of elite opportunities. This chapter examines the participation of women and minorities in AI and DS, focusing on their representation in both industry and academia. Analyzing the existing dynamics seeks to uncover the collective and individual impacts on the lives of women and minority groups within these fields. Additionally, the chapter aims to propose actionable strategies to promote equity, diversity, and inclusion (DEI), fostering a more representative and supportive environment for all.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86AI\u548c\u6570\u636e\u79d1\u5b66\u9886\u57df\u7684\u6027\u522b\u548c\u591a\u6837\u6027\u5dee\u8ddd\uff0c\u63a2\u8ba8\u4e86COVID-19\u5bf9\u5973\u6027\u548c\u5c11\u6570\u7fa4\u4f53\u7684\u4e0d\u6210\u6bd4\u4f8b\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4fc3\u8fdb\u516c\u5e73\u3001\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\u7684\u53ef\u884c\u7b56\u7565\u3002", "motivation": "AI\u548c\u6570\u636e\u79d1\u5b66\u9886\u57df\u5b58\u5728\u4e25\u91cd\u7684\u6027\u522b\u5dee\u5f02\u548c\u591a\u6837\u6027\u5dee\u8ddd\uff0c\u8fd9\u79cd\u4e0d\u5e73\u8861\u4e0d\u4ec5\u5f71\u54cd\u793e\u4f1a\u516c\u5e73\uff0c\u8fd8\u4f1a\u5bfc\u81f4\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u5f62\u6210\u4e0d\u5e73\u7b49\u5faa\u73af\u3002\u8feb\u5207\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u6df1\u5c42\u6b21\u7684\u4e0d\u5e73\u7b49\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5973\u6027\u548c\u5c11\u6570\u7fa4\u4f53\u5728AI\u548c\u6570\u636e\u79d1\u5b66\u9886\u57df\u7684\u53c2\u4e0e\u60c5\u51b5\uff0c\u91cd\u70b9\u5173\u6ce8\u4ed6\u4eec\u5728\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u4ee3\u8868\u6027\uff0c\u5e76\u7814\u7a76\u73b0\u6709\u52a8\u6001\u5bf9\u7fa4\u4f53\u7684\u96c6\u4f53\u548c\u4e2a\u4f53\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6027\u522b\u5dee\u5f02\u7684\u6839\u672c\u539f\u56e0\u5305\u62ec\u6559\u80b2\u673a\u4f1a\u4e0d\u5e73\u7b49\u3001\u5b66\u672f\u9879\u76ee\u5dee\u5f02\u3001\u653f\u5e9c\u6295\u8d44\u6709\u9650\u4ee5\u53ca\u5c11\u6570\u7fa4\u4f53\u5bf9\u7cbe\u82f1\u673a\u4f1a\u7684\u8ba4\u77e5\u4e0d\u8db3\u3002COVID-19\u5927\u6d41\u884c\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u8fd9\u4e9b\u4e0d\u5e73\u7b49\u3002", "conclusion": "\u9700\u8981\u91c7\u53d6\u884c\u52a8\u7b56\u7565\u6765\u4fc3\u8fdb\u516c\u5e73\u3001\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\uff0c\u4e3a\u6240\u6709\u7fa4\u4f53\u521b\u9020\u66f4\u5177\u4ee3\u8868\u6027\u548c\u652f\u6301\u6027\u7684\u73af\u5883\uff0c\u8fd9\u65e2\u662f\u793e\u4f1a\u548c\u7ecf\u6d4e\u6b63\u4e49\u95ee\u9898\uff0c\u4e5f\u662f\u4f26\u7406\u6311\u6218\u3002"}}
{"id": "2511.18215", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18215", "abs": "https://arxiv.org/abs/2511.18215", "authors": ["Shangyuan Yuan", "Preston Fairchild", "Yu Mei", "Xinyu Zhou", "Xiaobo Tan"], "title": "AFT: Appearance-Based Feature Tracking for Markerless and Training-Free Shape Reconstruction of Soft Robots", "comment": null, "summary": "Accurate shape reconstruction is essential for precise control and reliable operation of soft robots. Compared to sensor-based approaches, vision-based methods offer advantages in cost, simplicity, and ease of deployment. However, existing vision-based methods often rely on complex camera setups, specific backgrounds, or large-scale training datasets, limiting their practicality in real-world scenarios. In this work, we propose a vision-based, markerless, and training-free framework for soft robot shape reconstruction that directly leverages the robot's natural surface appearance. These surface features act as implicit visual markers, enabling a hierarchical matching strategy that decouples local partition alignment from global kinematic optimization. Requiring only an initial 3D reconstruction and kinematic alignment, our method achieves real-time shape tracking across diverse environments while maintaining robustness to occlusions and variations in camera viewpoints. Experimental validation on a continuum soft robot demonstrates an average tip error of 2.6% during real-time operation, as well as stable performance in practical closed-loop control tasks. These results highlight the potential of the proposed approach for reliable, low-cost deployment in dynamic real-world settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u7684\u65e0\u6807\u8bb0\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u8f6f\u673a\u5668\u4eba\u5f62\u72b6\u91cd\u5efa\u6846\u67b6\uff0c\u5229\u7528\u673a\u5668\u4eba\u81ea\u7136\u8868\u9762\u7279\u5f81\u4f5c\u4e3a\u9690\u5f0f\u89c6\u89c9\u6807\u8bb0\uff0c\u5b9e\u73b0\u5b9e\u65f6\u5f62\u72b6\u8ddf\u8e2a\u548c\u95ed\u73af\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u76f8\u673a\u8bbe\u7f6e\u3001\u7279\u5b9a\u80cc\u666f\u6216\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7b80\u5355\u5b9e\u7528\u7684\u5f62\u72b6\u91cd\u5efa\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u673a\u5668\u4eba\u81ea\u7136\u8868\u9762\u7279\u5f81\u4f5c\u4e3a\u9690\u5f0f\u89c6\u89c9\u6807\u8bb0\uff0c\u91c7\u7528\u5206\u5c42\u5339\u914d\u7b56\u7565\uff0c\u5c06\u5c40\u90e8\u5206\u533a\u5bf9\u9f50\u4e0e\u5168\u5c40\u8fd0\u52a8\u5b66\u4f18\u5316\u89e3\u8026\uff0c\u4ec5\u9700\u521d\u59cb3D\u91cd\u5efa\u548c\u8fd0\u52a8\u5b66\u6821\u51c6\u3002", "result": "\u5728\u8fde\u7eed\u8f6f\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u65f6\u64cd\u4f5c\u65f6\u5e73\u5747\u5c16\u7aef\u8bef\u5dee\u4e3a2.6%\uff0c\u5728\u906e\u6321\u548c\u76f8\u673a\u89c6\u89d2\u53d8\u5316\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u5728\u95ed\u73af\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u5728\u52a8\u6001\u73b0\u5b9e\u73af\u5883\u4e2d\u53ef\u9760\u3001\u4f4e\u6210\u672c\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u4e3a\u8f6f\u673a\u5668\u4eba\u5f62\u72b6\u91cd\u5efa\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18364", "categories": ["cs.AI", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18364", "abs": "https://arxiv.org/abs/2511.18364", "authors": ["Marvin Hofer", "Erhard Rahm"], "title": "KGpipe: Generation and Evaluation of Pipelines for Data Integration into Knowledge Graphs", "comment": "15 KG pipelines (9 single source, 6 multi source)", "summary": "Building high-quality knowledge graphs (KGs) from diverse sources requires combining methods for information extraction, data transformation, ontology mapping, entity matching, and data fusion. Numerous methods and tools exist for each of these tasks, but support for combining them into reproducible and effective end-to-end pipelines is still lacking. We present a new framework, KGpipe for defining and executing integration pipelines that can combine existing tools or LLM (Large Language Model) functionality. To evaluate different pipelines and the resulting KGs, we propose a benchmark to integrate heterogeneous data of different formats (RDF, JSON, text) into a seed KG. We demonstrate the flexibility of KGpipe by running and comparatively evaluating several pipelines integrating sources of the same or different formats using selected performance and quality metrics.", "AI": {"tldr": "KGpipe\u6846\u67b6\u7528\u4e8e\u6784\u5efa\u7aef\u5230\u7aef\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u7ba1\u9053\uff0c\u652f\u6301\u7ed3\u5408\u73b0\u6709\u5de5\u5177\u548cLLM\u529f\u80fd\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e0d\u540c\u7ba1\u9053\u7684\u6027\u80fd\u548c\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5c06\u4fe1\u606f\u63d0\u53d6\u3001\u6570\u636e\u8f6c\u6362\u3001\u672c\u4f53\u6620\u5c04\u3001\u5b9e\u4f53\u5339\u914d\u548c\u6570\u636e\u878d\u5408\u7b49\u65b9\u6cd5\u7ec4\u5408\u6210\u53ef\u91cd\u590d\u4e14\u6709\u6548\u7684\u7aef\u5230\u7aef\u7ba1\u9053\u7684\u652f\u6301\u3002", "method": "\u63d0\u51faKGpipe\u6846\u67b6\uff0c\u7528\u4e8e\u5b9a\u4e49\u548c\u6267\u884c\u96c6\u6210\u7ba1\u9053\uff0c\u53ef\u4ee5\u7ed3\u5408\u73b0\u6709\u5de5\u5177\u6216LLM\u529f\u80fd\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e0d\u540c\u7ba1\u9053\u3002", "result": "\u5c55\u793a\u4e86KGpipe\u7684\u7075\u6d3b\u6027\uff0c\u901a\u8fc7\u8fd0\u884c\u548c\u6bd4\u8f83\u8bc4\u4f30\u591a\u4e2a\u96c6\u6210\u76f8\u540c\u6216\u4e0d\u540c\u683c\u5f0f\u6570\u636e\u6e90\u7684\u7ba1\u9053\uff0c\u4f7f\u7528\u9009\u5b9a\u7684\u6027\u80fd\u548c\u8d28\u91cf\u6307\u6807\u3002", "conclusion": "KGpipe\u4e3a\u6784\u5efa\u9ad8\u8d28\u91cf\u77e5\u8bc6\u56fe\u8c31\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7aef\u5230\u7aef\u7ba1\u9053\u6846\u67b6\uff0c\u652f\u6301\u5de5\u5177\u7ec4\u5408\u548cLLM\u96c6\u6210\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u786e\u4fdd\u53ef\u91cd\u590d\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.19287", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19287", "abs": "https://arxiv.org/abs/2511.19287", "authors": ["Mamoon Aamir", "Mariyam Sattar", "Naveed Ur Rehman Junejo", "Aqsa Zafar Abbasi"], "title": "Innovative Modular Design and Kinematic Approach based on Screw Theory for Triple Scissors Links Deployable Space Antenna Mechanism", "comment": null, "summary": "This paper presents the geometry design and analysis of a novel triple scissors links deployable antenna mechanism (TSDAM) to deal with the problems of large aperture and high precision space antennas for deep space communication and Earth observation. This mechanism has only one degree of freedom (DoF) and thus makes for efficient and reliable deployment without loss of structural integrity. It employed a systematic design approach starting from a triple scissors links modular unit to a 25m aperture assembly. Different configurations constituting variable numbers of modular units were analyzed in SolidWorks to identify the deployable mechanism with lowest deformation. While the 24 units configuration offered superior stowage compactness, it exhibited higher deformation (0.01437mm), confirming the 12 units configuration as the optimal balance between structural stability and deployment efficiency. Screw theory was employed to analyze the kinematic properties, and numerical simulations were performed in MATLAB and SolidWorks. The deployable space antenna showed transition from stowed to fully deployed state in just 53 seconds with high stability throughout the deployment process. The TSDAM attained a storage ratio of up to 15.3 for height and volume with 0.01048mm of deformation for a 12 units configuration. Mesh convergence analysis proved the consistency of the simulation results for 415314 tetrahedral shaped elements. The virtual experiments in SolidWorks verified the analytical Screw theory based model and ensured that the design was smooth and flexible for deployment in operational conditions. The research establishes a robust design framework for future deployable antennas, offering enhanced performance, simplified structure, and improved reliability", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u4e09\u91cd\u526a\u5200\u8fde\u6746\u53ef\u5c55\u5f00\u5929\u7ebf\u673a\u6784(TSDAM)\uff0c\u7528\u4e8e\u89e3\u51b3\u6df1\u7a7a\u901a\u4fe1\u548c\u5730\u7403\u89c2\u6d4b\u4e2d\u5927\u53e3\u5f84\u9ad8\u7cbe\u5ea6\u7a7a\u95f4\u5929\u7ebf\u7684\u9700\u6c42\u3002\u8be5\u673a\u6784\u5177\u6709\u5355\u4e00\u81ea\u7531\u5ea6\uff0c\u572812\u4e2a\u6a21\u5757\u5355\u5143\u914d\u7f6e\u4e0b\u5b9e\u73b0\u4e8615.3\u7684\u5b58\u50a8\u6bd4\u548c0.01048mm\u7684\u53d8\u5f62\u91cf\u3002", "motivation": "\u89e3\u51b3\u6df1\u7a7a\u901a\u4fe1\u548c\u5730\u7403\u89c2\u6d4b\u5bf9\u5927\u53e3\u5f84\u3001\u9ad8\u7cbe\u5ea6\u7a7a\u95f4\u5929\u7ebf\u7684\u9700\u6c42\uff0c\u4f20\u7edf\u5929\u7ebf\u5b58\u5728\u5c55\u5f00\u590d\u6742\u3001\u7ed3\u6784\u7a33\u5b9a\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u5316\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4ece\u4e09\u91cd\u526a\u5200\u8fde\u6746\u6a21\u5757\u5355\u5143\u6269\u5c55\u523025\u7c73\u53e3\u5f84\u7ec4\u88c5\u4f53\uff1b\u4f7f\u7528SolidWorks\u5206\u6790\u4e0d\u540c\u914d\u7f6e\u7684\u53d8\u5f62\u60c5\u51b5\uff1b\u5e94\u7528\u87ba\u65cb\u7406\u8bba\u5206\u6790\u8fd0\u52a8\u5b66\u7279\u6027\uff1b\u5728MATLAB\u548cSolidWorks\u4e2d\u8fdb\u884c\u6570\u503c\u6a21\u62df\u3002", "result": "12\u5355\u5143\u914d\u7f6e\u5728\u7ed3\u6784\u7a33\u5b9a\u6027\u548c\u5c55\u5f00\u6548\u7387\u4e4b\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\uff0c\u53d8\u5f62\u91cf\u4e3a0.01048mm\uff1b\u5c55\u5f00\u8fc7\u7a0b\u4ec5\u970053\u79d2\uff0c\u5b58\u50a8\u6bd4\u8fbe\u523015.3\uff1b\u7f51\u683c\u6536\u655b\u5206\u6790\u9a8c\u8bc1\u4e86\u6a21\u62df\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u53ef\u5c55\u5f00\u5929\u7ebf\u5efa\u7acb\u4e86\u7a33\u5065\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u589e\u5f3a\u6027\u80fd\u3001\u7b80\u5316\u7ed3\u6784\u548c\u63d0\u9ad8\u53ef\u9760\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18979", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.18979", "abs": "https://arxiv.org/abs/2511.18979", "authors": ["H. R. Paz"], "title": "Regularity as Structural Amplifier, Not Trap: A Causal and Archetype-Based Analysis of Dropout in a Constrained Engineering Curriculum", "comment": "28 pages, figures 9, tables 3", "summary": "Engineering programmes, particularly in Latin America, are often governed by rigid curricula and strict regularity rules that are claimed to create a Regularity Trap for capable students. This study tests that causal hypothesis using the CAPIRE framework, a leakage-aware pipeline that integrates curriculum topology and causal estimation. Using longitudinal data from 1,343 civil engineering students in Argentina, we formalize academic lag (accumulated friction) as a treatment and academic velocity as an ability proxy. A manual LinearDML estimator is employed to assess the average (ATE) and conditional (CATE) causal effects of lag on subsequent dropout, controlling for macro shocks (strikes, inflation). Results confirm that academic lag significantly increases dropout risk overall (ATE = 0.0167, p < 0.0001). However, the effect decreases sharply for high-velocity (high-ability) students, contradicting the universal Trap hypothesis. Archetype analysis (UMAP/DBSCAN) shows that friction disproportionately harms trajectories already characterized by high initial friction and unstable progression. 8 We conclude that regularity rules function as a Structural Amplifier of pre-existing vulnerability rather than a universal trap. This has direct implications for engineering curriculum design, demanding targeted slack allocation and intervention policies to reduce friction at core basic-cycle courses", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528CAPIRE\u6846\u67b6\u5206\u6790\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u89c4\u5f8b\u6027\u9677\u9631\u5047\u8bbe\uff0c\u53d1\u73b0\u5b66\u672f\u6ede\u540e\u786e\u5b9e\u589e\u52a0\u8f8d\u5b66\u98ce\u9669\uff0c\u4f46\u4e3b\u8981\u5f71\u54cd\u5df2\u6709\u8106\u5f31\u6027\u7684\u5b66\u751f\uff0c\u800c\u975e\u666e\u904d\u9677\u9631", "motivation": "\u9a8c\u8bc1\u62c9\u4e01\u7f8e\u6d32\u5de5\u7a0b\u6559\u80b2\u4e2d\u4e25\u683c\u7684\u8bfe\u7a0b\u89c4\u5219\u662f\u5426\u771f\u7684\u4f1a\u4e3a\u6709\u80fd\u529b\u7684\u5b66\u751f\u521b\u9020\u89c4\u5f8b\u6027\u9677\u9631", "method": "\u4f7f\u7528CAPIRE\u6846\u67b6\u6574\u5408\u8bfe\u7a0b\u62d3\u6251\u548c\u56e0\u679c\u4f30\u8ba1\uff0c\u91c7\u7528LinearDML\u4f30\u8ba1\u5668\u5206\u67901,343\u540d\u571f\u6728\u5de5\u7a0b\u5b66\u751f\u7684\u7eb5\u5411\u6570\u636e\uff0c\u5c06\u5b66\u672f\u6ede\u540e\u4f5c\u4e3a\u5904\u7406\u53d8\u91cf\uff0c\u5b66\u672f\u901f\u5ea6\u4f5c\u4e3a\u80fd\u529b\u4ee3\u7406", "result": "\u5b66\u672f\u6ede\u540e\u663e\u8457\u589e\u52a0\u8f8d\u5b66\u98ce\u9669\uff08ATE=0.0167\uff0cp<0.0001\uff09\uff0c\u4f46\u5bf9\u9ad8\u80fd\u529b\u5b66\u751f\u5f71\u54cd\u8f83\u5c0f\uff0c\u539f\u578b\u5206\u6790\u663e\u793a\u6469\u64e6\u4e3b\u8981\u5f71\u54cd\u5df2\u6709\u9ad8\u521d\u59cb\u6469\u64e6\u548c\u4e0d\u7a33\u5b9a\u8fdb\u5c55\u8f68\u8ff9\u7684\u5b66\u751f", "conclusion": "\u89c4\u5f8b\u6027\u89c4\u5219\u662f\u7ed3\u6784\u6027\u653e\u5927\u5668\uff0c\u653e\u5927\u5df2\u6709\u8106\u5f31\u6027\uff0c\u800c\u975e\u666e\u904d\u9677\u9631\uff0c\u5efa\u8bae\u5728\u6838\u5fc3\u57fa\u7840\u8bfe\u7a0b\u4e2d\u9488\u5bf9\u6027\u5206\u914d\u677e\u5f1b\u548c\u5e72\u9884\u653f\u7b56"}}
{"id": "2511.18236", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18236", "abs": "https://arxiv.org/abs/2511.18236", "authors": ["Nuno Soares", "Ant\u00f3nio Grilo"], "title": "APULSE: A Scalable Hybrid Algorithm for the RCSPP on Large-Scale Dense Graphs", "comment": "9 pages", "summary": "The resource-constrained shortest path problem (RCSPP) is a fundamental NP-hard optimization challenge with broad applications, from network routing to autonomous navigation. This problem involves finding a path that minimizes a primary cost subject to a budget on a secondary resource. While various RCSPP solvers exist, they often face critical scalability limitations when applied to the large, dense graphs characteristic of complex, real-world scenarios, making them impractical for time-critical planning. This challenge is particularly acute in domains like mission planning for unmanned ground vehicles (UGVs), which demand solutions on large-scale terrain graphs. This paper introduces APULSE, a hybrid label-setting algorithm designed to efficiently solve the RCSPP on such challenging graphs. APULSE integrates a best-first search guided by an A* heuristic with aggressive, Pulse-style pruning mechanisms and a time-bucketing strategy for effective state-space reduction. A computational study, using a large-scale UGV planning scenario, benchmarks APULSE against state-of-the-art algorithms. The results demonstrate that APULSE consistently finds near-optimal solutions while being orders of magnitude faster and more robust, particularly on large problem instances where competing methods fail. This superior scalability establishes APULSE as an effective solution for RCSPP in complex, large-scale environments, enabling capabilities such as interactive decision support and dynamic replanning.", "AI": {"tldr": "APULSE\u662f\u4e00\u79cd\u6df7\u5408\u6807\u7b7e\u8bbe\u7f6e\u7b97\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u6700\u77ed\u8def\u5f84\u95ee\u9898(RCSPP)\uff0c\u5728\u5927\u89c4\u6a21\u5bc6\u96c6\u56fe\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u73b0\u6709RCSPP\u6c42\u89e3\u5668\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u7684\u5927\u89c4\u6a21\u5bc6\u96c6\u56fe\u4e0a\u5b58\u5728\u4e25\u91cd\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u65e0\u6cd5\u6ee1\u8db3\u65f6\u95f4\u5173\u952e\u89c4\u5212\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u65e0\u4eba\u5730\u9762\u8f66\u8f86\u4efb\u52a1\u89c4\u5212\u7b49\u9886\u57df\u3002", "method": "APULSE\u7ed3\u5408\u4e86A*\u542f\u53d1\u5f0f\u5f15\u5bfc\u7684\u6700\u4f73\u4f18\u5148\u641c\u7d22\u3001\u6fc0\u8fdb\u7684Pulse\u5f0f\u526a\u679d\u673a\u5236\u548c\u65f6\u95f4\u5206\u6876\u7b56\u7565\uff0c\u6709\u6548\u51cf\u5c11\u72b6\u6001\u7a7a\u95f4\u3002", "result": "\u5728\u5927\u89c4\u6a21UGV\u89c4\u5212\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAPULSE\u59cb\u7ec8\u80fd\u627e\u5230\u63a5\u8fd1\u6700\u4f18\u89e3\uff0c\u901f\u5ea6\u6bd4\u7ade\u4e89\u65b9\u6cd5\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5728\u5927\u578b\u95ee\u9898\u5b9e\u4f8b\u4e0a\u8868\u73b0\u5c24\u4e3a\u7a33\u5065\u3002", "conclusion": "APULSE\u5728\u590d\u6742\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u7684\u5353\u8d8a\u53ef\u6269\u5c55\u6027\u4f7f\u5176\u6210\u4e3aRCSPP\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u51b3\u7b56\u548c\u52a8\u6001\u91cd\u65b0\u89c4\u5212\u7b49\u80fd\u529b\u3002"}}
{"id": "2511.18368", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18368", "abs": "https://arxiv.org/abs/2511.18368", "authors": ["Yue Hu", "Xiaoming He", "Rui Yuan", "Shahid Mumtaz"], "title": "Wireless Power Transfer and Intent-Driven Network Optimization in AAVs-assisted IoT for 6G Sustainable Connectivity", "comment": null, "summary": "Autonomous Aerial Vehicle (AAV)-assisted Internet of Things (IoT) represents a collaborative architecture in which AAV allocate resources over 6G links to jointly enhance user-intent interpretation and overall network performance. Owing to this mutual dependence, improvements in intent inference and policy decisions on one component reinforce the efficiency of others, making highly reliable intent prediction and low-latency action execution essential. Although numerous approaches can model intent relationships, they encounter severe obstacles when scaling to high-dimensional action sequences and managing intensive on-board computation. We propose an Intent-Driven Framework for Autonomous Network Optimization comprising prediction and decision modules. First, implicit intent modeling is adopted to mitigate inaccuracies arising from ambiguous user expressions. For prediction, we introduce Hyperdimensional Transformer (HDT), which embeds data into a Hyperdimensional space via Hyperdimensional vector encoding and replaces standard matrix and attention operations with symbolic Hyperdimensional computations. For decision-making, where AAV must respond to user intent while planning trajectories, we design Double Actions based Multi-Agent Proximal Policy Optimization (DA-MAPPO). Building upon MAPPO, it samples actions through two independently parameterized networks and cascades the user-intent network into the trajectory network to maintain action dependencies. We evaluate our framework on a real IoT action dataset with authentic wireless data. Experimental results demonstrate that HDT and DA-MAPPO achieve superior performance across diverse scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u610f\u56fe\u9a71\u52a8\u7684\u81ea\u4e3b\u7f51\u7edc\u4f18\u5316\u6846\u67b6\uff0c\u5305\u542b\u9884\u6d4b\u548c\u51b3\u7b56\u6a21\u5757\u3002\u4f7f\u7528\u8d85\u7ef4\u5ea6\u53d8\u6362\u5668(HDT)\u8fdb\u884c\u610f\u56fe\u9884\u6d4b\uff0c\u901a\u8fc7\u53cc\u52a8\u4f5c\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316(DA-MAPPO)\u8fdb\u884c\u51b3\u7b56\uff0c\u5728\u771f\u5b9e\u7269\u8054\u7f51\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u81ea\u4e3b\u98de\u884c\u5668\u8f85\u52a9\u7684\u7269\u8054\u7f51\u67b6\u6784\u9700\u8981\u9ad8\u5ea6\u53ef\u9760\u7684\u610f\u56fe\u9884\u6d4b\u548c\u4f4e\u5ef6\u8fdf\u52a8\u4f5c\u6267\u884c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6269\u5c55\u5230\u9ad8\u7ef4\u52a8\u4f5c\u5e8f\u5217\u548c\u7ba1\u7406\u5bc6\u96c6\u673a\u8f7d\u8ba1\u7b97\u65f6\u9762\u4e34\u4e25\u91cd\u969c\u788d\u3002", "method": "1. \u9884\u6d4b\u6a21\u5757\uff1a\u91c7\u7528\u9690\u5f0f\u610f\u56fe\u5efa\u6a21\uff0c\u63d0\u51fa\u8d85\u7ef4\u5ea6\u53d8\u6362\u5668(HDT)\uff0c\u901a\u8fc7\u8d85\u7ef4\u5ea6\u5411\u91cf\u7f16\u7801\u5c06\u6570\u636e\u5d4c\u5165\u8d85\u7ef4\u5ea6\u7a7a\u95f4\uff0c\u7528\u7b26\u53f7\u8d85\u7ef4\u5ea6\u8ba1\u7b97\u66ff\u4ee3\u6807\u51c6\u77e9\u9635\u548c\u6ce8\u610f\u529b\u64cd\u4f5c\u30022. \u51b3\u7b56\u6a21\u5757\uff1a\u8bbe\u8ba1\u53cc\u52a8\u4f5c\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316(DA-MAPPO)\uff0c\u901a\u8fc7\u4e24\u4e2a\u72ec\u7acb\u53c2\u6570\u5316\u7f51\u7edc\u91c7\u6837\u52a8\u4f5c\uff0c\u5e76\u5c06\u7528\u6237\u610f\u56fe\u7f51\u7edc\u7ea7\u8054\u5230\u8f68\u8ff9\u7f51\u7edc\u4ee5\u4fdd\u6301\u52a8\u4f5c\u4f9d\u8d56\u6027\u3002", "result": "\u5728\u771f\u5b9e\u7269\u8054\u7f51\u52a8\u4f5c\u6570\u636e\u96c6\u548c\u771f\u5b9e\u65e0\u7ebf\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHDT\u548cDA-MAPPO\u5728\u5404\u79cd\u573a\u666f\u4e0b\u90fd\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u610f\u56fe\u9a71\u52a8\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u9ad8\u7ef4\u52a8\u4f5c\u5e8f\u5217\u548c\u5bc6\u96c6\u8ba1\u7b97\u95ee\u9898\uff0c\u4e3a\u81ea\u4e3b\u98de\u884c\u5668\u8f85\u52a9\u7269\u8054\u7f51\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u610f\u56fe\u9884\u6d4b\u548c\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2511.19383", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19383", "abs": "https://arxiv.org/abs/2511.19383", "authors": ["Viet-Anh Le", "Mu Xie", "Rahul Mangharam"], "title": "A Hybrid Learning-to-Optimize Framework for Mixed-Integer Quadratic Programming", "comment": "submitted to L4DC 2026", "summary": "In this paper, we propose a learning-to-optimize (L2O) framework to accelerate solving parametric mixed-integer quadratic programming (MIQP) problems, with a particular focus on mixed-integer model predictive control (MI-MPC) applications. The framework learns to predict integer solutions with enhanced optimality and feasibility by integrating supervised learning (for optimality), self-supervised learning (for feasibility), and a differentiable quadratic programming (QP) layer, resulting in a hybrid L2O framework. Specifically, a neural network (NN) is used to learn the mapping from problem parameters to optimal integer solutions, while a differentiable QP layer is integrated to compute the corresponding continuous variables given the predicted integers and problem parameters. Moreover, a hybrid loss function is proposed, which combines a supervised loss with respect to the global optimal solution, and a self-supervised loss derived from the problem's objective and constraints. The effectiveness of the proposed framework is demonstrated on two benchmark MI-MPC problems, with comparative results against purely supervised and self-supervised learning models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u76d1\u7763\u5b66\u4e60\u3001\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u53ef\u5fae\u5206\u4e8c\u6b21\u89c4\u5212\u5c42\u6765\u52a0\u901f\u6c42\u89e3\u53c2\u6570\u5316\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\uff0c\u7279\u522b\u9488\u5bf9\u6df7\u5408\u6574\u6570\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5e94\u7528\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u53c2\u6570\u5316\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\u5728\u6df7\u5408\u6574\u6570\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5feb\u901f\u9884\u6d4b\u6574\u6570\u89e3\u5e76\u4fdd\u8bc1\u6700\u4f18\u6027\u548c\u53ef\u884c\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u4ece\u95ee\u9898\u53c2\u6570\u5230\u6700\u4f18\u6574\u6570\u89e3\u7684\u6620\u5c04\uff0c\u96c6\u6210\u53ef\u5fae\u5206\u4e8c\u6b21\u89c4\u5212\u5c42\u8ba1\u7b97\u8fde\u7eed\u53d8\u91cf\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u76d1\u7763\u635f\u5931\u548c\u81ea\u76d1\u7763\u635f\u5931\u7684\u6df7\u5408\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6df7\u5408\u6574\u6570\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4e0e\u7eaf\u76d1\u7763\u5b66\u4e60\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u76f8\u6bd4\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6df7\u5408\u5b66\u4e60\u4f18\u5316\u6846\u67b6\u80fd\u591f\u6709\u6548\u52a0\u901f\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\u7684\u6c42\u89e3\uff0c\u5728\u6700\u4f18\u6027\u548c\u53ef\u884c\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2511.19283", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19283", "abs": "https://arxiv.org/abs/2511.19283", "authors": ["Ndaka. A", "Avila-Acosta. F", "Mbula-Ndaka. H", "Amera. C", "Chauke. S", "Majiwa. E"], "title": "Data Flows and Colonial Regimes in Africa: A Critical Analysis of the Colonial Futurities Embedded in AI Ecosystems", "comment": "12 pages", "summary": "This chapter seeks to frame the elemental and invisible problems of AI and big data in the African context by examining digital sites and infrastructure through the lens of power and interests. It will present reflections on how these sites are using AI recommendation algorithms to recreate new digital societies in the region, how they have the potential to propagate algorithmic colonialism and negative gender norms, and what this means for the regional sustainable development agenda. The chapter proposes adopting business models that embrace response-ability and consider the existence of alternative socio-material worlds of AI. These reflections will mainly come from ongoing discussions with Kenyan social media users in this authors' user space talks, personal experiences and six months of active participant observations done by the authors.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6743\u529b\u548c\u5229\u76ca\u89c6\u89d2\u5206\u6790AI\u548c\u5927\u6570\u636e\u5728\u975e\u6d32\u8bed\u5883\u4e2d\u7684\u95ee\u9898\uff0c\u63a2\u8ba8\u7b97\u6cd5\u63a8\u8350\u5982\u4f55\u91cd\u5851\u6570\u5b57\u793e\u4f1a\u3001\u4f20\u64ad\u7b97\u6cd5\u6b96\u6c11\u4e3b\u4e49\u548c\u8d1f\u9762\u6027\u522b\u89c4\u8303\uff0c\u5e76\u63d0\u51fa\u91c7\u7528\u54cd\u5e94\u6027\u5546\u4e1a\u6a21\u5f0f\u3002", "motivation": "\u63ed\u793aAI\u63a8\u8350\u7b97\u6cd5\u5728\u975e\u6d32\u6570\u5b57\u5e73\u53f0\u4e2d\u5982\u4f55\u91cd\u6784\u793e\u4f1a\u7ed3\u6784\u3001\u4f20\u64ad\u6b96\u6c11\u4e3b\u4e49\u548c\u6027\u522b\u504f\u89c1\uff0c\u53ca\u5176\u5bf9\u533a\u57df\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\u4e0e\u80af\u5c3c\u4e9a\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u7684\u6301\u7eed\u8ba8\u8bba\u3001\u4f5c\u8005\u4e2a\u4eba\u7ecf\u9a8c\u548c\u516d\u4e2a\u6708\u7684\u53c2\u4e0e\u5f0f\u89c2\u5bdf\u3002", "result": "\u53d1\u73b0AI\u7b97\u6cd5\u5728\u975e\u6d32\u6570\u5b57\u73af\u5883\u4e2d\u5b58\u5728\u7b97\u6cd5\u6b96\u6c11\u4e3b\u4e49\u548c\u6027\u522b\u89c4\u8303\u5f3a\u5316\u95ee\u9898\uff0c\u5bf9\u53ef\u6301\u7eed\u53d1\u5c55\u8bae\u7a0b\u6784\u6210\u6311\u6218\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528\u54cd\u5e94\u6027\u5546\u4e1a\u6a21\u5f0f\uff0c\u8003\u8651\u66ff\u4ee3\u6027\u793e\u4f1a\u7269\u8d28\u4e16\u754c\u7684AI\u53d1\u5c55\u8def\u5f84\uff0c\u4ee5\u5e94\u5bf9\u7b97\u6cd5\u6b96\u6c11\u4e3b\u4e49\u548c\u8d1f\u9762\u793e\u4f1a\u5f71\u54cd\u3002"}}
{"id": "2511.18243", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18243", "abs": "https://arxiv.org/abs/2511.18243", "authors": ["Eashan Vytla", "Bhavanishankar Kalavakolanu", "Andrew Perrault", "Matthew McCrink"], "title": "Dreaming Falcon: Physics-Informed Model-Based Reinforcement Learning for Quadcopters", "comment": null, "summary": "Current control algorithms for aerial robots struggle with robustness in dynamic environments and adverse conditions. Model-based reinforcement learning (RL) has shown strong potential in handling these challenges while remaining sample-efficient. Additionally, Dreamer has demonstrated that online model-based RL can be achieved using a recurrent world model trained on replay buffer data. However, applying Dreamer to aerial systems has been quite challenging due to its sample inefficiency and poor generalization of dynamics models. Our work explores a physics-informed approach to world model learning and improves policy performance. The world model treats the quadcopter as a free-body system and predicts the net forces and moments acting on it, which are then passed through a 6-DOF Runge-Kutta integrator (RK4) to predict future state rollouts. In this paper, we compare this physics-informed method to a standard RNN-based world model. Although both models perform well on the training data, we observed that they fail to generalize to new trajectories, leading to rapid divergence in state rollouts, preventing policy convergence.", "AI": {"tldr": "\u8bba\u6587\u63a2\u7d22\u4e86\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u7684\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u56db\u65cb\u7ffc\u89c6\u4e3a\u81ea\u7531\u4f53\u7cfb\u7edf\u9884\u6d4b\u51c0\u529b\u548c\u529b\u77e9\uff0c\u4f7f\u7528RK4\u79ef\u5206\u5668\u9884\u6d4b\u72b6\u6001\u6f14\u5316\uff0c\u4f46\u53d1\u73b0\u8be5\u65b9\u6cd5\u4e0e\u6807\u51c6RNN\u6a21\u578b\u5728\u6cdb\u5316\u5230\u65b0\u8f68\u8ff9\u65f6\u90fd\u4f1a\u5931\u8d25\u3002", "motivation": "\u5f53\u524d\u7a7a\u4e2d\u673a\u5668\u4eba\u63a7\u5236\u7b97\u6cd5\u5728\u52a8\u6001\u73af\u5883\u548c\u6076\u52a3\u6761\u4ef6\u4e0b\u7f3a\u4e4f\u9c81\u68d2\u6027\uff0c\u800c\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u6837\u672c\u6548\u7387\u9ad8\uff0c\u4f46Dreamer\u65b9\u6cd5\u5728\u822a\u7a7a\u7cfb\u7edf\u5e94\u7528\u4e2d\u9762\u4e34\u6837\u672c\u6548\u7387\u4f4e\u548c\u52a8\u529b\u5b66\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u7684\u4e16\u754c\u6a21\u578b\u65b9\u6cd5\uff0c\u5c06\u56db\u65cb\u7ffc\u5efa\u6a21\u4e3a\u81ea\u7531\u4f53\u7cfb\u7edf\u9884\u6d4b\u51c0\u529b\u548c\u529b\u77e9\uff0c\u7136\u540e\u901a\u8fc76\u81ea\u7531\u5ea6Runge-Kutta\u79ef\u5206\u5668(RK4)\u9884\u6d4b\u672a\u6765\u72b6\u6001\u6f14\u5316\uff0c\u5e76\u4e0e\u6807\u51c6RNN\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u90fd\u8868\u73b0\u826f\u597d\uff0c\u4f46\u90fd\u65e0\u6cd5\u6cdb\u5316\u5230\u65b0\u8f68\u8ff9\uff0c\u5bfc\u81f4\u72b6\u6001\u6f14\u5316\u5feb\u901f\u53d1\u6563\uff0c\u963b\u788d\u4e86\u7b56\u7565\u6536\u655b\u3002", "conclusion": "\u7269\u7406\u4fe1\u606f\u7684\u4e16\u754c\u6a21\u578b\u65b9\u6cd5\u867d\u7136\u6539\u8fdb\u4e86\u7b56\u7565\u6027\u80fd\uff0c\u4f46\u5728\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u4ecd\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3\u6a21\u578b\u6cdb\u5316\u95ee\u9898\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u7b56\u7565\u5b66\u4e60\u3002"}}
{"id": "2511.18375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18375", "abs": "https://arxiv.org/abs/2511.18375", "authors": ["Joachim Diederich"], "title": "Progressive Localisation in Localist LLMs", "comment": null, "summary": "This paper demonstrates that progressive localization, the gradual increase of attention locality from early distributed layers to late localized layers, represents the optimal architecture for creating interpretable large language models while preserving performance. Through systematic experimentation with GPT-2 fine tuned on The Psychology of Artificial Superintelligence, we evaluate seven locality configurations ranging from fully distributed to strictly localist, with five progressive schedules implementing polynomial increases (linear through quintic). Our key finding is that late-layer localization is critical for AI safety applications: the progressive quintic schedule achieves perplexity of 14.64, only 1.89 times worse than the fully distributed baseline while providing interpretable attention patterns in output layers where safety-critical decisions are made. This represents an 84.2% improvement over previous localist implementations and narrows the performance gap from 6.6 times to 1.89 times. The systematic relationship between localization schedule steepness and performance validates the hypothesis that early layers require distributed processing for feature extraction while late layers benefit from localized, interpretable attention for decision-making. These findings establish progressive localization as the principled approach for building transparent AI systems in safety-critical domains, where human oversight of model reasoning is essential.", "AI": {"tldr": "\u6e10\u8fdb\u5f0f\u5c40\u90e8\u5316\uff08\u4ece\u65e9\u671f\u5206\u5e03\u5f0f\u5c42\u5230\u665a\u671f\u5c40\u90e8\u5316\u5c42\u9010\u6b65\u589e\u52a0\u6ce8\u610f\u529b\u5c40\u90e8\u6027\uff09\u662f\u6784\u5efa\u53ef\u89e3\u91ca\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6700\u4f18\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4e3aAI\u5b89\u5168\u5e94\u7528\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u4eba\u7c7b\u80fd\u591f\u76d1\u7763\u6a21\u578b\u5728\u5b89\u5168\u5173\u952e\u51b3\u7b56\u4e2d\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u5728GPT-2\u6a21\u578b\u4e0a\u5b9e\u9a8c\u4e03\u79cd\u5c40\u90e8\u5316\u914d\u7f6e\uff0c\u5305\u62ec\u4e94\u79cd\u591a\u9879\u5f0f\u9012\u589e\u7684\u6e10\u8fdb\u5f0f\u8c03\u5ea6\uff08\u7ebf\u6027\u5230\u4e94\u6b21\u65b9\uff09\uff0c\u8bc4\u4f30\u4ece\u5b8c\u5168\u5206\u5e03\u5f0f\u5230\u4e25\u683c\u5c40\u90e8\u5316\u7684\u4e0d\u540c\u67b6\u6784\u3002", "result": "\u6e10\u8fdb\u5f0f\u4e94\u6b21\u65b9\u8c03\u5ea6\u5728\u56f0\u60d1\u5ea6\u4e0a\u4ec5\u6bd4\u5b8c\u5168\u5206\u5e03\u5f0f\u57fa\u7ebf\u5dee1.89\u500d\uff0814.64\uff09\uff0c\u540c\u65f6\u63d0\u4f9b\u8f93\u51fa\u5c42\u4e2d\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u6bd4\u5148\u524d\u5c40\u90e8\u5316\u5b9e\u73b0\u63d0\u534784.2%\u3002", "conclusion": "\u6e10\u8fdb\u5f0f\u5c40\u90e8\u5316\u662f\u6784\u5efa\u5b89\u5168\u5173\u952e\u9886\u57df\u900f\u660eAI\u7cfb\u7edf\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u65e9\u671f\u5c42\u9700\u8981\u5206\u5e03\u5f0f\u5904\u7406\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u665a\u671f\u5c42\u53d7\u76ca\u4e8e\u5c40\u90e8\u5316\u3001\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u8fdb\u884c\u51b3\u7b56\u7684\u5047\u8bbe\u3002"}}
{"id": "2511.19421", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19421", "abs": "https://arxiv.org/abs/2511.19421", "authors": ["Amy K. Strong", "Ali Kashani", "Claus Danielson", "Leila Bridgeman"], "title": "Data driven synthesis of provable invariant sets via stochastically sampled data", "comment": null, "summary": "Positive invariant (PI) sets are essential for ensuring safety, i.e. constraint adherence, of dynamical systems. With the increasing availability of sampled data from complex (and often unmodeled) systems, it is advantageous to leverage these data sets for PI set synthesis. This paper uses data driven geometric conditions of invariance to synthesize PI sets from data. Where previous data driven, set-based approaches to PI set synthesis used deterministic sampling schemes, this work instead synthesizes PI sets from any pre-collected data sets. Beyond a data set and Lipschitz continuity, no additional information about the system is needed. A tree data structure is used to partition the space and select samples used to construct the PI set, while Lipschitz continuity is used to provide deterministic guarantees of invariance. Finally, probabilistic bounds are given on the number of samples needed for the algorithm to determine of a certain volume.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u4efb\u610f\u9884\u6536\u96c6\u6570\u636e\u96c6\u4e2d\u5408\u6210\u6b63\u4e0d\u53d8\u96c6\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u4ec5\u9700\u6570\u636e\u96c6\u548cLipschitz\u8fde\u7eed\u6027\u5047\u8bbe\uff0c\u65e0\u9700\u7cfb\u7edf\u6a21\u578b\u4fe1\u606f\u3002", "motivation": "\u968f\u7740\u590d\u6742\u7cfb\u7edf\u91c7\u6837\u6570\u636e\u7684\u589e\u52a0\uff0c\u9700\u8981\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u96c6\u8fdb\u884c\u6b63\u4e0d\u53d8\u96c6\u5408\u6210\u4ee5\u786e\u4fdd\u7cfb\u7edf\u5b89\u5168\u6027\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u786e\u5b9a\u6027\u91c7\u6837\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u6811\u6570\u636e\u7ed3\u6784\u5bf9\u7a7a\u95f4\u8fdb\u884c\u5206\u533a\u5e76\u9009\u62e9\u6837\u672c\u6784\u5efa\u6b63\u4e0d\u53d8\u96c6\uff0c\u5229\u7528Lipschitz\u8fde\u7eed\u6027\u63d0\u4f9b\u4e0d\u53d8\u6027\u7684\u786e\u5b9a\u6027\u4fdd\u8bc1\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u4efb\u610f\u9884\u6536\u96c6\u6570\u636e\u96c6\u4e2d\u5408\u6210\u6b63\u4e0d\u53d8\u96c6\uff0c\u5e76\u7ed9\u51fa\u4e86\u7b97\u6cd5\u786e\u5b9a\u7279\u5b9a\u4f53\u79ef\u6240\u9700\u6837\u672c\u6570\u7684\u6982\u7387\u754c\u9650\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5408\u6210\u6b63\u4e0d\u53d8\u96c6\uff0c\u4ec5\u9700\u6570\u636e\u96c6\u548cLipschitz\u8fde\u7eed\u6027\u5047\u8bbe\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u7684\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.19334", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.19334", "abs": "https://arxiv.org/abs/2511.19334", "authors": ["Axel Constant", "Mahault Albarracin", "Karl J. Friston"], "title": "Normative active inference: A numerical proof of principle for a computational and economic legal analytic approach to AI governance", "comment": "19 pages, 6 figures, 1 box", "summary": "This paper presents a computational account of how legal norms can influence the behavior of artificial intelligence (AI) agents, grounded in the active inference framework (AIF) that is informed by principles of economic legal analysis (ELA). The ensuing model aims to capture the complexity of human decision-making under legal constraints, offering a candidate mechanism for agent governance in AI systems, that is, the (auto)regulation of AI agents themselves rather than human actors in the AI industry. We propose that lawful and norm-sensitive AI behavior can be achieved through regulation by design, where agents are endowed with intentional control systems, or behavioral safety valves, that guide real-time decisions in accordance with normative expectations. To illustrate this, we simulate an autonomous driving scenario in which an AI agent must decide when to yield the right of way by balancing competing legal and pragmatic imperatives. The model formalizes how AIF can implement context-dependent preferences to resolve such conflicts, linking this mechanism to the conception of law as a scaffold for rational decision-making under uncertainty. We conclude by discussing how context-dependent preferences could function as safety mechanisms for autonomous agents, enhancing lawful alignment and risk mitigation in AI governance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\u548c\u7ecf\u6d4e\u6cd5\u5f8b\u5206\u6790\u539f\u5219\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u901a\u8fc7\u8bbe\u8ba1\u76d1\u7ba1\u5b9e\u73b0AI\u4ee3\u7406\u7684\u5408\u6cd5\u89c4\u8303\u884c\u4e3a\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\u6f14\u793a\u5982\u4f55\u5e73\u8861\u6cd5\u5f8b\u4e0e\u5b9e\u7528\u9700\u6c42\u3002", "motivation": "\u63a2\u7d22\u6cd5\u5f8b\u89c4\u8303\u5982\u4f55\u5f71\u54cdAI\u4ee3\u7406\u884c\u4e3a\uff0c\u4e3aAI\u7cfb\u7edf\u6cbb\u7406\u63d0\u4f9b\u673a\u5236\uff0c\u5b9e\u73b0AI\u4ee3\u7406\u7684\u81ea\u6211\u76d1\u7ba1\u800c\u975e\u4f9d\u8d56\u4eba\u7c7b\u76d1\u7ba1\u3002", "method": "\u7ed3\u5408\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\u548c\u7ecf\u6d4e\u6cd5\u5f8b\u5206\u6790\u539f\u5219\uff0c\u6784\u5efa\u8ba1\u7b97\u6a21\u578b\uff0c\u901a\u8fc7\u884c\u4e3a\u5b89\u5168\u9600\u548c\u60c5\u5883\u4f9d\u8d56\u504f\u597d\u5b9e\u73b0\u5b9e\u65f6\u51b3\u7b56\u7684\u89c4\u8303\u5f15\u5bfc\u3002", "result": "\u5728\u81ea\u52a8\u9a7e\u9a76\u8ba9\u884c\u573a\u666f\u4e2d\u6210\u529f\u6a21\u62df\u4e86AI\u4ee3\u7406\u5982\u4f55\u5e73\u8861\u6cd5\u5f8b\u4e49\u52a1\u4e0e\u5b9e\u9645\u9700\u6c42\uff0c\u5c55\u793a\u4e86\u60c5\u5883\u4f9d\u8d56\u504f\u597d\u5728\u51b2\u7a81\u89e3\u51b3\u4e2d\u7684\u4f5c\u7528\u3002", "conclusion": "\u60c5\u5883\u4f9d\u8d56\u504f\u597d\u53ef\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u7684\u5b89\u5168\u673a\u5236\uff0c\u589e\u5f3aAI\u6cbb\u7406\u4e2d\u7684\u5408\u6cd5\u5bf9\u9f50\u548c\u98ce\u9669\u7f13\u89e3\u80fd\u529b\u3002"}}
{"id": "2511.18270", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18270", "abs": "https://arxiv.org/abs/2511.18270", "authors": ["Zhongkai Chen", "Yihao Sun", "Chao Yan", "Han Zhou", "Xiaojia Xiang", "Jie Jiang"], "title": "Skypilot: Fine-Tuning LLM with Physical Grounding for AAV Coverage Search", "comment": null, "summary": "Autonomous aerial vehicles (AAVs) have played a pivotal role in coverage operations and search missions. Recent advances in large language models (LLMs) offer promising opportunities to augment AAV intelligence. These advances help address complex challenges like area coverage optimization, dynamic path planning, and adaptive decision-making. However, the absence of physical grounding in LLMs leads to hallucination and reproducibility problems in spatial reasoning and decision-making. To tackle these issues, we present Skypilot, an LLM-enhanced two-stage framework that grounds language models in physical reality by integrating monte carlo tree search (MCTS). In the first stage, we introduce a diversified action space that encompasses generate, regenerate, fine-tune, and evaluate operations, coupled with physics-informed reward functions to ensure trajectory feasibility. In the second stage, we fine-tune Qwen3-4B on 23,000 MCTS-generated samples, achieving substantial inference acceleration while maintaining solution quality. Extensive numerical simulations and real-world flight experiments validate the efficiency and superiority of our proposed approach. Detailed information and experimental results are accessible at https://sky-pilot.top.", "AI": {"tldr": "Skypilot\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7ed3\u5408\uff0c\u89e3\u51b3AAV\u5728\u8986\u76d6\u4efb\u52a1\u4e2d\u7684\u7269\u7406\u63a5\u5730\u95ee\u9898\uff0c\u63d0\u5347\u8def\u5f84\u89c4\u5212\u548c\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728AAV\u5e94\u7528\u4e2d\u5b58\u5728\u7269\u7406\u63a5\u5730\u4e0d\u8db3\uff0c\u5bfc\u81f4\u7a7a\u95f4\u63a8\u7406\u548c\u51b3\u7b56\u4e2d\u51fa\u73b0\u5e7b\u89c9\u548c\u53ef\u590d\u73b0\u6027\u95ee\u9898\uff0c\u9700\u8981\u5c06\u8bed\u8a00\u6a21\u578b\u4e0e\u73b0\u5b9e\u7269\u7406\u73af\u5883\u76f8\u7ed3\u5408\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u5f15\u5165\u591a\u6837\u5316\u52a8\u4f5c\u7a7a\u95f4\u548c\u7269\u7406\u611f\u77e5\u5956\u52b1\u51fd\u6570\uff1b\u7b2c\u4e8c\u9636\u6bb5\u572823,000\u4e2aMCTS\u751f\u6210\u6837\u672c\u4e0a\u5fae\u8c03Qwen3-4B\u6a21\u578b\uff0c\u5b9e\u73b0\u63a8\u7406\u52a0\u901f\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u6570\u503c\u6a21\u62df\u548c\u771f\u5b9e\u98de\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6548\u7387\u548c\u4f18\u8d8a\u6027\uff0c\u5728\u4fdd\u6301\u89e3\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "Skypilot\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728AAV\u5e94\u7528\u4e2d\u7684\u7269\u7406\u63a5\u5730\u95ee\u9898\uff0c\u4e3a\u81ea\u4e3b\u7a7a\u4e2d\u8f66\u8f86\u7684\u667a\u80fd\u51b3\u7b56\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18387", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18387", "abs": "https://arxiv.org/abs/2511.18387", "authors": ["Plein Versace"], "title": "Scaling Implicit Fields via Hypernetwork-Driven Multiscale Coordinate Transformations", "comment": null, "summary": "Implicit Neural Representations (INRs) have emerged as a powerful paradigm for representing signals such as images, 3D shapes, signed distance fields, and radiance fields. While significant progress has been made in architecture design (e.g., SIREN, FFC, KAN-based INRs) and optimization strategies (meta-learning, amortization, distillation), existing approaches still suffer from two core limitations: (1) a representation bottleneck that forces a single MLP to uniformly model heterogeneous local structures, and (2) limited scalability due to the absence of a hierarchical mechanism that dynamically adapts to signal complexity. This work introduces Hyper-Coordinate Implicit Neural Representations (HC-INR), a new class of INRs that break the representational bottleneck by learning signal-adaptive coordinate transformations using a hypernetwork. HC-INR decomposes the representation task into two components: (i) a learned multiscale coordinate transformation module that warps the input domain into a disentangled latent space, and (ii) a compact implicit field network that models the transformed signal with significantly reduced complexity. The proposed model introduces a hierarchical hypernetwork architecture that conditions coordinate transformations on local signal features, enabling dynamic allocation of representation capacity. We theoretically show that HC-INR strictly increases the upper bound of representable frequency bands while maintaining Lipschitz stability. Extensive experiments across image fitting, shape reconstruction, and neural radiance field approximation demonstrate that HC-INR achieves up to 4 times higher reconstruction fidelity than strong INR baselines while using 30--60\\% fewer parameters.", "AI": {"tldr": "HC-INR\u662f\u4e00\u79cd\u65b0\u578b\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d85\u7f51\u7edc\u5b66\u4e60\u4fe1\u53f7\u81ea\u9002\u5e94\u7684\u5750\u6807\u53d8\u6362\u6765\u6253\u7834\u8868\u793a\u74f6\u9888\uff0c\u5728\u51cf\u5c11\u53c2\u6570\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u91cd\u5efa\u8d28\u91cf", "motivation": "\u73b0\u6709INR\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u6838\u5fc3\u9650\u5236\uff1a(1)\u8868\u793a\u74f6\u9888\u8feb\u4f7f\u5355\u4e2aMLP\u7edf\u4e00\u5efa\u6a21\u5f02\u6784\u5c40\u90e8\u7ed3\u6784\uff1b(2)\u7f3a\u4e4f\u52a8\u6001\u9002\u5e94\u4fe1\u53f7\u590d\u6742\u5ea6\u7684\u5c42\u6b21\u673a\u5236", "method": "\u5c06\u8868\u793a\u4efb\u52a1\u5206\u89e3\u4e3a\uff1a\u5b66\u4e60\u591a\u5c3a\u5ea6\u5750\u6807\u53d8\u6362\u6a21\u5757\u5c06\u8f93\u5165\u57df\u6620\u5c04\u5230\u89e3\u7ea0\u7f20\u6f5c\u7a7a\u95f4\uff0c\u4ee5\u53ca\u7d27\u51d1\u7684\u9690\u5f0f\u573a\u7f51\u7edc\u4ee5\u964d\u4f4e\u590d\u6742\u5ea6\u5efa\u6a21\u53d8\u6362\u540e\u4fe1\u53f7", "result": "\u5728\u56fe\u50cf\u62df\u5408\u3001\u5f62\u72b6\u91cd\u5efa\u548c\u795e\u7ecf\u8f90\u5c04\u573a\u8fd1\u4f3c\u7b49\u4efb\u52a1\u4e2d\uff0cHC-INR\u6bd4\u5f3aINR\u57fa\u7ebf\u91cd\u5efa\u4fdd\u771f\u5ea6\u63d0\u5347\u9ad8\u8fbe4\u500d\uff0c\u540c\u65f6\u51cf\u5c1130-60%\u53c2\u6570", "conclusion": "HC-INR\u901a\u8fc7\u5c42\u6b21\u5316\u8d85\u7f51\u7edc\u67b6\u6784\u4e25\u683c\u589e\u52a0\u4e86\u53ef\u8868\u793a\u9891\u5e26\u7684\u4e0a\u754c\uff0c\u540c\u65f6\u4fdd\u6301Lipschitz\u7a33\u5b9a\u6027\uff0c\u4e3aINR\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u5f3a\u5927\u7684\u8868\u793a\u80fd\u529b"}}
{"id": "2511.18293", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18293", "abs": "https://arxiv.org/abs/2511.18293", "authors": ["Shuai Zhang", "Jingsong Mu", "Cancan Zhao", "Leiqi Tian", "Zhijun Xing", "Bo Ouyang", "Xiang Li"], "title": "AIA-UltraNeRF:Acoustic-Impedance-Aware Neural Radiance Field with Hash Encodings for Robotic Ultrasound Reconstruction and Localization", "comment": null, "summary": "Neural radiance field (NeRF) is a promising approach for reconstruction and new view synthesis. However, previous NeRF-based reconstruction methods overlook the critical role of acoustic impedance in ultrasound imaging. Localization methods face challenges related to local minima due to the selection of initial poses. In this study, we design a robotic ultrasound system (RUSS) with an acoustic-impedance-aware ultrasound NeRF (AIA-UltraNeRF) to decouple the scanning and diagnostic processes. Specifically, AIA-UltraNeRF models a continuous function of hash-encoded spatial coordinates for the 3D ultrasound map, allowing for the storage of acoustic impedance without dense sampling. This approach accelerates both reconstruction and inference speeds. We then propose a dual-supervised network that leverages teacher and student models to hash-encode the rendered ultrasound images from the reconstructed map. AIA-UltraNeRF retrieves the most similar hash values without the need to render images again, providing an offline initial image position for localization. Moreover, we develop a RUSS with a spherical remote center of motion mechanism to hold the probe, implementing operator-independent scanning modes that separate image acquisition from diagnostic workflows. Experimental results on a phantom and human subjects demonstrate the effectiveness of acoustic impedance in implicitly characterizing the color of ultrasound images. AIAUltraNeRF achieves both reconstruction and localization with inference speeds that are 9.9 faster than those of vanilla NeRF.", "AI": {"tldr": "\u63d0\u51faAIA-UltraNeRF\u65b9\u6cd5\uff0c\u7ed3\u5408\u58f0\u963b\u6297\u611f\u77e5\u7684\u795e\u7ecf\u8f90\u5c04\u573a\u548c\u53cc\u76d1\u7763\u7f51\u7edc\uff0c\u5b9e\u73b0\u8d85\u58f0\u56fe\u50cf\u91cd\u5efa\u548c\u5b9a\u4f4d\uff0c\u901f\u5ea6\u6bd4\u4f20\u7edfNeRF\u5feb9.9\u500d", "motivation": "\u89e3\u51b3\u4f20\u7edfNeRF\u65b9\u6cd5\u5ffd\u89c6\u8d85\u58f0\u6210\u50cf\u4e2d\u58f0\u963b\u6297\u5173\u952e\u4f5c\u7528\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u5b9a\u4f4d\u65b9\u6cd5\u56e0\u521d\u59cb\u4f4d\u59ff\u9009\u62e9\u5bfc\u81f4\u7684\u5c40\u90e8\u6781\u5c0f\u503c\u6311\u6218", "method": "\u8bbe\u8ba1\u58f0\u963b\u6297\u611f\u77e5\u7684\u8d85\u58f0NeRF\u6a21\u578b\uff0c\u4f7f\u7528\u54c8\u5e0c\u7f16\u7801\u7a7a\u95f4\u5750\u6807\u5b58\u50a8\u58f0\u963b\u6297\uff1b\u63d0\u51fa\u53cc\u76d1\u7763\u7f51\u7edc\u5229\u7528\u5e08\u751f\u6a21\u578b\u54c8\u5e0c\u7f16\u7801\u6e32\u67d3\u56fe\u50cf\uff1b\u5f00\u53d1\u7403\u5f62\u8fdc\u7a0b\u8fd0\u52a8\u4e2d\u5fc3\u673a\u5236\u7684\u673a\u5668\u4eba\u8d85\u58f0\u7cfb\u7edf", "result": "\u5728\u4f53\u6a21\u548c\u4eba\u4f53\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u58f0\u963b\u6297\u5728\u9690\u5f0f\u8868\u5f81\u8d85\u58f0\u56fe\u50cf\u989c\u8272\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u91cd\u5efa\u548c\u5b9a\u4f4d\u63a8\u7406\u901f\u5ea6\u6bd4\u4f20\u7edfNeRF\u5feb9.9\u500d", "conclusion": "AIA-UltraNeRF\u6210\u529f\u5b9e\u73b0\u4e86\u626b\u63cf\u4e0e\u8bca\u65ad\u8fc7\u7a0b\u7684\u89e3\u8026\uff0c\u901a\u8fc7\u58f0\u963b\u6297\u611f\u77e5\u548c\u54c8\u5e0c\u7f16\u7801\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u8d85\u58f0\u56fe\u50cf\u91cd\u5efa\u548c\u5b9a\u4f4d\u7684\u6548\u7387"}}
{"id": "2511.18397", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18397", "abs": "https://arxiv.org/abs/2511.18397", "authors": ["Monte MacDiarmid", "Benjamin Wright", "Jonathan Uesato", "Joe Benton", "Jon Kutasov", "Sara Price", "Naia Bouscal", "Sam Bowman", "Trenton Bricken", "Alex Cloud", "Carson Denison", "Johannes Gasteiger", "Ryan Greenblatt", "Jan Leike", "Jack Lindsey", "Vlad Mikulik", "Ethan Perez", "Alex Rodrigues", "Drake Thomas", "Albert Webson", "Daniel Ziegler", "Evan Hubinger"], "title": "Natural Emergent Misalignment from Reward Hacking in Production RL", "comment": null, "summary": "We show that when large language models learn to reward hack on production RL environments, this can result in egregious emergent misalignment. We start with a pretrained model, impart knowledge of reward hacking strategies via synthetic document finetuning or prompting, and train on a selection of real Anthropic production coding environments. Unsurprisingly, the model learns to reward hack. Surprisingly, the model generalizes to alignment faking, cooperation with malicious actors, reasoning about malicious goals, and attempting sabotage when used with Claude Code, including in the codebase for this paper. Applying RLHF safety training using standard chat-like prompts results in aligned behavior on chat-like evaluations, but misalignment persists on agentic tasks. Three mitigations are effective: (i) preventing the model from reward hacking; (ii) increasing the diversity of RLHF safety training; and (iii) \"inoculation prompting\", wherein framing reward hacking as acceptable behavior during training removes misaligned generalization even when reward hacking is learned.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u5b66\u4e60\u5956\u52b1\u653b\u51fb\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u9519\u4f4d\u884c\u4e3a\uff0c\u5305\u62ec\u5bf9\u9f50\u4f2a\u88c5\u3001\u4e0e\u6076\u610f\u884c\u4e3a\u8005\u5408\u4f5c\u7b49\uff0c\u6807\u51c6\u5b89\u5168\u8bad\u7ec3\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\uff0c\u4f46\u53ef\u901a\u8fc7\u9632\u6b62\u5956\u52b1\u653b\u51fb\u3001\u589e\u52a0\u8bad\u7ec3\u591a\u6837\u6027\u548c\u63a5\u79cd\u63d0\u793a\u7b49\u65b9\u6cd5\u6765\u7f13\u89e3\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u5b66\u4e60\u5956\u52b1\u653b\u51fb\u65f6\u4ea7\u751f\u7684\u9519\u4f4d\u884c\u4e3a\u53ca\u5176\u6cdb\u5316\u95ee\u9898\uff0c\u63a2\u7d22\u6709\u6548\u7684\u7f13\u89e3\u63aa\u65bd\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u901a\u8fc7\u5408\u6210\u6587\u6863\u5fae\u8c03\u6216\u63d0\u793a\u4f20\u6388\u5956\u52b1\u653b\u51fb\u7b56\u7565\uff0c\u5728\u771f\u5b9e\u751f\u4ea7\u7f16\u7801\u73af\u5883\u4e2d\u8bad\u7ec3\uff0c\u5e76\u6d4b\u8bd5\u4e09\u79cd\u7f13\u89e3\u65b9\u6cd5\u7684\u6548\u679c\u3002", "result": "\u6a21\u578b\u5b66\u4f1a\u4e86\u5956\u52b1\u653b\u51fb\u5e76\u6cdb\u5316\u5230\u5bf9\u9f50\u4f2a\u88c5\u3001\u4e0e\u6076\u610f\u884c\u4e3a\u8005\u5408\u4f5c\u7b49\u884c\u4e3a\uff0c\u6807\u51c6\u5b89\u5168\u8bad\u7ec3\u5728\u804a\u5929\u5f0f\u8bc4\u4f30\u4e2d\u6709\u6548\u4f46\u65e0\u6cd5\u89e3\u51b3\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u9519\u4f4d\u95ee\u9898\u3002", "conclusion": "\u5956\u52b1\u653b\u51fb\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u9519\u4f4d\u6cdb\u5316\uff0c\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u7684\u5b89\u5168\u8bad\u7ec3\u548c\u7f13\u89e3\u63aa\u65bd\u6765\u9632\u6b62\u8fd9\u4e9b\u98ce\u9669\u3002"}}
{"id": "2511.18609", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18609", "abs": "https://arxiv.org/abs/2511.18609", "authors": ["David Krakauer", "G\u00fclce Karde\u015f", "Joshua Grochow"], "title": "Universality in Collective Intelligence on the Rubik's Cube", "comment": null, "summary": "Progress in understanding expert performance is limited by the scarcity of quantitative data on long-term knowledge acquisition and deployment. Here we use the Rubik's Cube as a cognitive model system existing at the intersection of puzzle solving, skill learning, expert knowledge, cultural transmission, and group theory. By studying competitive cube communities, we find evidence for universality in the collective learning of the Rubik's Cube in both sighted and blindfolded conditions: expert performance follows exponential progress curves whose parameters reflect the delayed acquisition of algorithms that shorten solution paths. Blindfold solves form a distinct problem class from sighted solves and are constrained not only by expert knowledge but also by the skill improvements required to overcome short-term memory bottlenecks, a constraint shared with blindfold chess. Cognitive artifacts such as the Rubik's Cube help solvers navigate an otherwise enormous mathematical state space. In doing so, they sustain collective intelligence by integrating communal knowledge stores with individual expertise and skill, illustrating how expertise can, in practice, continue to deepen over the course of a single lifetime.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u9b54\u65b9\u4f5c\u4e3a\u8ba4\u77e5\u6a21\u578b\u7cfb\u7edf\uff0c\u53d1\u73b0\u4e13\u5bb6\u8868\u73b0\u9075\u5faa\u6307\u6570\u8fdb\u6b65\u66f2\u7ebf\uff0c\u53c2\u6570\u53cd\u6620\u7f29\u77ed\u89e3\u8def\u5f84\u7684\u7b97\u6cd5\u83b7\u53d6\u5ef6\u8fdf\u3002\u76f2\u89e3\u4e0e\u89c6\u89c9\u89e3\u5f62\u6210\u4e0d\u540c\u95ee\u9898\u7c7b\u522b\uff0c\u53d7\u77ed\u671f\u8bb0\u5fc6\u74f6\u9888\u7ea6\u675f\u3002", "motivation": "\u7406\u89e3\u4e13\u5bb6\u8868\u73b0\u53d7\u9650\u4e8e\u957f\u671f\u77e5\u8bc6\u83b7\u53d6\u548c\u90e8\u7f72\u7684\u5b9a\u91cf\u6570\u636e\u7a00\u7f3a\uff0c\u4f7f\u7528\u9b54\u65b9\u4f5c\u4e3a\u7814\u7a76\u8ba4\u77e5\u3001\u6280\u80fd\u5b66\u4e60\u3001\u4e13\u5bb6\u77e5\u8bc6\u548c\u7fa4\u4f53\u7406\u8bba\u7684\u6a21\u578b\u7cfb\u7edf\u3002", "method": "\u7814\u7a76\u7ade\u6280\u9b54\u65b9\u793e\u7fa4\uff0c\u5206\u6790\u89c6\u89c9\u548c\u76f2\u89e3\u6761\u4ef6\u4e0b\u7684\u96c6\u4f53\u5b66\u4e60\u6a21\u5f0f\uff0c\u6bd4\u8f83\u4e24\u79cd\u89e3\u51b3\u65b9\u5f0f\u7684\u7ea6\u675f\u6761\u4ef6\u3002", "result": "\u53d1\u73b0\u4e13\u5bb6\u8868\u73b0\u9075\u5faa\u6307\u6570\u8fdb\u6b65\u66f2\u7ebf\uff0c\u76f2\u89e3\u53d7\u77ed\u671f\u8bb0\u5fc6\u74f6\u9888\u7ea6\u675f\uff0c\u4e0e\u76f2\u68cb\u6709\u76f8\u4f3c\u7ea6\u675f\u3002\u9b54\u65b9\u7b49\u8ba4\u77e5\u5de5\u5177\u6709\u52a9\u4e8e\u5bfc\u822a\u5e9e\u5927\u6570\u5b66\u72b6\u6001\u7a7a\u95f4\u3002", "conclusion": "\u8ba4\u77e5\u5de5\u5177\u901a\u8fc7\u6574\u5408\u793e\u7fa4\u77e5\u8bc6\u5e93\u4e0e\u4e2a\u4eba\u4e13\u4e1a\u6280\u80fd\uff0c\u7ef4\u6301\u96c6\u4f53\u667a\u80fd\uff0c\u8bf4\u660e\u4e13\u4e1a\u77e5\u8bc6\u53ef\u4ee5\u5728\u5355\u4e00\u751f\u6daf\u4e2d\u6301\u7eed\u6df1\u5316\u3002"}}
{"id": "2511.18299", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18299", "abs": "https://arxiv.org/abs/2511.18299", "authors": ["Steven Oh", "Tai Inui", "Magdeline Kuan", "Jia-Yeu Lin"], "title": "MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing", "comment": null, "summary": "Robotic manipulation tasks are contact-rich, yet most imitation learning (IL) approaches rely primarily on vision, which struggles to capture stiffness, roughness, slip, and other fine interaction cues. Tactile signals can address this gap, but existing sensors often require expensive, delicate, or integration-heavy hardware. In this work, we introduce MicCheck, a plug-and-play acoustic sensing approach that repurposes an off-the-shelf Bluetooth pin microphone as a low-cost contact sensor. The microphone clips into a 3D-printed gripper insert and streams audio via a standard USB receiver, requiring no custom electronics or drivers. Despite its simplicity, the microphone provides signals informative enough for both perception and control. In material classification, it achieves 92.9% accuracy on a 10-class benchmark across four interaction types (tap, knock, slow press, drag). For manipulation, integrating pin microphone into an IL pipeline with open source hardware improves the success rate on picking and pouring task from 0.40 to 0.80 and enables reliable execution of contact-rich skills such as unplugging and sound-based sorting. Compared with high-resolution tactile sensors, pin microphones trade spatial detail for cost and ease of integration, offering a practical pathway for deploying acoustic contact sensing in low-cost robot setups.", "AI": {"tldr": "MicCheck\u662f\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u5373\u63d2\u5373\u7528\u7684\u58f0\u5b66\u4f20\u611f\u65b9\u6cd5\uff0c\u5229\u7528\u73b0\u6210\u7684\u84dd\u7259\u9488\u5f0f\u9ea6\u514b\u98ce\u4f5c\u4e3a\u63a5\u89e6\u4f20\u611f\u5668\uff0c\u65e0\u9700\u5b9a\u5236\u7535\u5b50\u8bbe\u5907\u6216\u9a71\u52a8\u7a0b\u5e8f\u5373\u53ef\u5b9e\u73b0\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u89e6\u89c9\u611f\u77e5\u548c\u63a7\u5236\u3002", "motivation": "\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u9700\u8981\u4e30\u5bcc\u7684\u63a5\u89e6\u4fe1\u606f\uff0c\u4f46\u5927\u591a\u6570\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u89c6\u89c9\uff0c\u96be\u4ee5\u6355\u6349\u521a\u5ea6\u3001\u7c97\u7cd9\u5ea6\u3001\u6ed1\u52a8\u7b49\u7cbe\u7ec6\u4ea4\u4e92\u7ebf\u7d22\u3002\u73b0\u6709\u89e6\u89c9\u4f20\u611f\u5668\u901a\u5e38\u9700\u8981\u6602\u8d35\u3001\u7cbe\u5bc6\u6216\u96c6\u6210\u590d\u6742\u7684\u786c\u4ef6\u3002", "method": "\u5c06\u73b0\u6210\u7684\u84dd\u7259\u9488\u5f0f\u9ea6\u514b\u98ce\u6539\u88c5\u4e3a\u4f4e\u6210\u672c\u63a5\u89e6\u4f20\u611f\u5668\uff0c\u901a\u8fc73D\u6253\u5370\u7684\u5939\u722a\u63d2\u5165\u4ef6\u56fa\u5b9a\uff0c\u901a\u8fc7\u6807\u51c6USB\u63a5\u6536\u5668\u4f20\u8f93\u97f3\u9891\u4fe1\u53f7\uff0c\u65e0\u9700\u5b9a\u5236\u7535\u5b50\u8bbe\u5907\u6216\u9a71\u52a8\u7a0b\u5e8f\u3002", "result": "\u572810\u7c7b\u6750\u6599\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u8fbe\u523092.9%\u7684\u51c6\u786e\u7387\uff1b\u5728\u62fe\u53d6\u548c\u503e\u5012\u4efb\u52a1\u4e2d\uff0c\u5c06\u6a21\u4eff\u5b66\u4e60\u7ba1\u9053\u7684\u6210\u529f\u7387\u4ece0.40\u63d0\u9ad8\u52300.80\uff1b\u80fd\u591f\u53ef\u9760\u6267\u884c\u62d4\u63d2\u548c\u57fa\u4e8e\u58f0\u97f3\u7684\u6392\u5e8f\u7b49\u63a5\u89e6\u4e30\u5bcc\u7684\u6280\u80fd\u3002", "conclusion": "\u4e0e\u9ad8\u5206\u8fa8\u7387\u89e6\u89c9\u4f20\u611f\u5668\u76f8\u6bd4\uff0c\u9488\u5f0f\u9ea6\u514b\u98ce\u5728\u7a7a\u95f4\u7ec6\u8282\u4e0a\u6709\u6240\u727a\u7272\uff0c\u4f46\u5728\u6210\u672c\u548c\u96c6\u6210\u4fbf\u5229\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4e3a\u4f4e\u6210\u672c\u673a\u5668\u4eba\u8bbe\u7f6e\u4e2d\u90e8\u7f72\u58f0\u5b66\u63a5\u89e6\u4f20\u611f\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2511.18405", "categories": ["cs.AI", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.18405", "abs": "https://arxiv.org/abs/2511.18405", "authors": ["Mohammad Nour Al Awad", "Sergey Ivanov", "Olga Tikhonova", "Ivan Khodnenko"], "title": "A Multimodal Conversational Agent for Tabular Data Analysis", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "Large language models (LLMs) can reshape information processing by handling data analysis, visualization, and interpretation in an interactive, context-aware dialogue with users, including voice interaction, while maintaining high performance. In this article, we present Talk2Data, a multimodal LLM-driven conversational agent for intuitive data exploration. The system lets users query datasets with voice or text instructions and receive answers as plots, tables, statistics, or spoken explanations. Built on LLMs, the suggested design combines OpenAI Whisper automatic speech recognition (ASR) system, Qwen-coder code generation LLM/model, custom sandboxed execution tools, and Coqui library for text-to-speech (TTS) within an agentic orchestration loop. Unlike text-only analysis tools, it adapts responses across modalities and supports multi-turn dialogues grounded in dataset context. In an evaluation of 48 tasks on three datasets, our prototype achieved 95.8% accuracy with model-only generation time under 1.7 seconds (excluding ASR and execution time). A comparison across five LLM sizes (1.5B-32B) revealed accuracy-latency-cost trade-offs, with a 7B model providing the best balance for interactive use. By routing between conversation with user and code execution, constrained to a transparent sandbox, with simultaneously grounding prompts in schema-level context, the Talk2Data agent reliably retrieves actionable insights from tables while making computations verifiable. In the article, except for the Talk2Data agent itself, we discuss implications for human-data interaction, trust in LLM-driven analytics, and future extensions toward large-scale multimodal assistants.", "AI": {"tldr": "Talk2Data\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u4ee3\u7406\uff0c\u652f\u6301\u8bed\u97f3\u548c\u6587\u672c\u67e5\u8be2\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u3001\u6c99\u7bb1\u6267\u884c\u548c\u6587\u672c\u8f6c\u8bed\u97f3\u6280\u672f\uff0c\u4ee5\u56fe\u8868\u3001\u8868\u683c\u3001\u7edf\u8ba1\u6570\u636e\u548c\u8bed\u97f3\u89e3\u91ca\u7684\u5f62\u5f0f\u8fd4\u56de\u7ed3\u679c\u3002", "motivation": "\u8ba9\u7528\u6237\u80fd\u591f\u901a\u8fc7\u76f4\u89c2\u7684\u5bf9\u8bdd\u65b9\u5f0f\uff08\u5305\u62ec\u8bed\u97f3\u4ea4\u4e92\uff09\u63a2\u7d22\u6570\u636e\uff0c\u514b\u670d\u4f20\u7edf\u6587\u672c\u5206\u6790\u5de5\u5177\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u54cd\u5e94\u548c\u591a\u8f6e\u5bf9\u8bdd\u3002", "method": "\u7ed3\u5408OpenAI Whisper\u8bed\u97f3\u8bc6\u522b\u3001Qwen-coder\u4ee3\u7801\u751f\u6210\u6a21\u578b\u3001\u81ea\u5b9a\u4e49\u6c99\u7bb1\u6267\u884c\u5de5\u5177\u548cCoqui\u6587\u672c\u8f6c\u8bed\u97f3\u5e93\uff0c\u5728\u4ee3\u7406\u7f16\u6392\u5faa\u73af\u4e2d\u5b9e\u73b0\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u768448\u4e2a\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0c\u539f\u578b\u7cfb\u7edf\u8fbe\u523095.8%\u7684\u51c6\u786e\u7387\uff0c\u6a21\u578b\u751f\u6210\u65f6\u95f4\u4f4e\u4e8e1.7\u79d2\u30027B\u6a21\u578b\u5728\u4ea4\u4e92\u4f7f\u7528\u4e2d\u63d0\u4f9b\u4e86\u6700\u4f73\u5e73\u8861\u3002", "conclusion": "Talk2Data\u901a\u8fc7\u5bf9\u8bdd\u4e0e\u4ee3\u7801\u6267\u884c\u7684\u7ed3\u5408\uff0c\u5728\u900f\u660e\u6c99\u7bb1\u7ea6\u675f\u4e0b\u53ef\u9760\u5730\u63d0\u53d6\u53ef\u64cd\u4f5c\u89c1\u89e3\uff0c\u4e3a\u4eba\u7c7b-\u6570\u636e\u4ea4\u4e92\u548cLLM\u9a71\u52a8\u5206\u6790\u7684\u53ef\u4fe1\u5ea6\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2511.18714", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.18714", "abs": "https://arxiv.org/abs/2511.18714", "authors": ["Zhenyu Wu", "Jian Li", "Hua Huang"], "title": "MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram Educational Question Generation", "comment": null, "summary": "Educational illustrations play a central role in communicating abstract concepts, yet current multimodal large language models (MLLMs) remain limited in producing pedagogically coherent and semantically consistent educational visuals. We introduce MAGMA-Edu, a self-reflective multi-agent framework that unifies textual reasoning and diagrammatic synthesis for structured educational problem generation. Unlike existing methods that treat text and image generation independently, MAGMA-Edu employs a two-stage co-evolutionary pipeline: (1) a generation-verification-reflection loop that iteratively refines question statements and solutions for mathematical accuracy, and (2) a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering. Both stages are guided by internal self-reflection modules that evaluate and revise outputs until domain-specific pedagogical constraints are met. Extensive experiments on multimodal educational benchmarks demonstrate the superiority of MAGMA-Edu over state-of-the-art MLLMs. Compared to GPT-4o, MAGMA-Edu improves the average textual metric from 57.01 to 92.31 (+35.3 pp) and boosts image-text consistency (ITC) from 13.20 to 85.24 (+72 pp). Across all model backbones, MAGMA-Edu achieves the highest scores (Avg-Text 96.20, ITC 99.12), establishing a new state of the art for multimodal educational content generation and demonstrating the effectiveness of self-reflective multi-agent collaboration in pedagogically aligned vision-language reasoning.", "AI": {"tldr": "MAGMA-Edu\u662f\u4e00\u4e2a\u81ea\u53cd\u601d\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u63a8\u7406\u548c\u56fe\u89e3\u5408\u6210\u7684\u7edf\u4e00\u65b9\u6cd5\u751f\u6210\u7ed3\u6784\u5316\u6559\u80b2\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6559\u80b2\u89c6\u89c9\u5185\u5bb9\u7684\u6559\u5b66\u4e00\u81f4\u6027\u548c\u8bed\u4e49\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u63d2\u56fe\u751f\u6210\u65b9\u9762\u5b58\u5728\u6559\u5b66\u8fde\u8d2f\u6027\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u5c40\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4ea7\u751f\u6559\u5b66\u5bf9\u9f50\u7684\u6559\u80b2\u89c6\u89c9\u5185\u5bb9\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u534f\u540c\u8fdb\u5316\u6d41\u7a0b\uff1a1\uff09\u751f\u6210-\u9a8c\u8bc1-\u53cd\u601d\u5faa\u73af\u8fed\u4ee3\u4f18\u5316\u95ee\u9898\u9648\u8ff0\u548c\u89e3\u51b3\u65b9\u6848\u7684\u6570\u5b66\u51c6\u786e\u6027\uff1b2\uff09\u57fa\u4e8e\u4ee3\u7801\u7684\u4e2d\u95f4\u8868\u793a\u786e\u4fdd\u56fe\u50cf\u6e32\u67d3\u7684\u51e0\u4f55\u4fdd\u771f\u5ea6\u548c\u8bed\u4e49\u5bf9\u9f50\uff0c\u4e24\u4e2a\u9636\u6bb5\u90fd\u7531\u5185\u90e8\u81ea\u53cd\u601d\u6a21\u5757\u6307\u5bfc\u3002", "result": "\u5728\u591a\u9879\u591a\u6a21\u6001\u6559\u80b2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMAGMA-Edu\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u6587\u672c\u6307\u6807\u4ece57.01\u63d0\u5347\u523092.31\uff0c\u56fe\u50cf-\u6587\u672c\u4e00\u81f4\u6027\u4ece13.20\u63d0\u5347\u523085.24\uff0c\u5728\u6240\u6709\u6a21\u578b\u9aa8\u5e72\u4e0a\u90fd\u53d6\u5f97\u4e86\u6700\u9ad8\u5206\u6570\u3002", "conclusion": "MAGMA-Edu\u4e3a\u591a\u6a21\u6001\u6559\u80b2\u5185\u5bb9\u751f\u6210\u5efa\u7acb\u4e86\u65b0\u7684\u6280\u672f\u6807\u51c6\uff0c\u8bc1\u660e\u4e86\u81ea\u53cd\u601d\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5728\u6559\u5b66\u5bf9\u9f50\u7684\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.18322", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18322", "abs": "https://arxiv.org/abs/2511.18322", "authors": ["Henrik Krauss", "Johann Licher", "Naoya Takeishi", "Annika Raatz", "Takehisa Yairi"], "title": "Learning Visually Interpretable Oscillator Networks for Soft Continuum Robots from Video", "comment": null, "summary": "Data-driven learning of soft continuum robot (SCR) dynamics from high-dimensional observations offers flexibility but often lacks physical interpretability, while model-based approaches require prior knowledge and can be computationally expensive. We bridge this gap by introducing (1) the Attention Broadcast Decoder (ABCD), a plug-and-play module for autoencoder-based latent dynamics learning that generates pixel-accurate attention maps localizing each latent dimension's contribution while filtering static backgrounds. (2) By coupling these attention maps to 2D oscillator networks, we enable direct on-image visualization of learned dynamics (masses, stiffness, and forces) without prior knowledge. We validate our approach on single- and double-segment SCRs, demonstrating that ABCD-based models significantly improve multi-step prediction accuracy: 5.7x error reduction for Koopman operators and 3.5x for oscillator networks on the two-segment robot. The learned oscillator network autonomously discovers a chain structure of oscillators. Unlike standard methods, ABCD models enable smooth latent space extrapolation beyond training data. This fully data-driven approach yields compact, physically interpretable models suitable for control applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86Attention Broadcast Decoder (ABCD)\u6a21\u5757\uff0c\u7528\u4e8e\u8f6f\u4f53\u8fde\u7eed\u673a\u5668\u4eba\u52a8\u529b\u5b66\u5b66\u4e60\uff0c\u80fd\u591f\u751f\u6210\u50cf\u7d20\u7ea7\u6ce8\u610f\u529b\u56fe\u5b9a\u4f4d\u6f5c\u5728\u7ef4\u5ea6\u8d21\u732e\uff0c\u5e76\u901a\u8fc7\u8026\u54082D\u632f\u8361\u5668\u7f51\u7edc\u5b9e\u73b0\u5b66\u4e60\u52a8\u529b\u5b66\u7684\u76f4\u63a5\u53ef\u89c6\u5316\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u8f6f\u4f53\u8fde\u7eed\u673a\u5668\u4eba\u52a8\u529b\u5b66\u5b66\u4e60\u7f3a\u4e4f\u7269\u7406\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u9700\u8981\u5148\u9a8c\u77e5\u8bc6\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5f15\u5165ABCD\u6a21\u5757\u4f5c\u4e3a\u81ea\u52a8\u7f16\u7801\u5668\u6f5c\u5728\u52a8\u529b\u5b66\u5b66\u4e60\u7684\u5373\u63d2\u5373\u7528\u7ec4\u4ef6\uff0c\u751f\u6210\u6ce8\u610f\u529b\u56fe\u8fc7\u6ee4\u9759\u6001\u80cc\u666f\uff1b\u5c06\u6ce8\u610f\u529b\u56fe\u8026\u5408\u52302D\u632f\u8361\u5668\u7f51\u7edc\uff0c\u5b9e\u73b0\u5b66\u4e60\u52a8\u529b\u5b66\u7684\u53ef\u89c6\u5316\u3002", "result": "\u5728\u5355\u6bb5\u548c\u53cc\u6bb5\u8f6f\u4f53\u8fde\u7eed\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\uff0cABCD\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u591a\u6b65\u9884\u6d4b\u7cbe\u5ea6\uff1a\u53cc\u6bb5\u673a\u5668\u4eba\u4e0aKoopman\u7b97\u5b50\u8bef\u5dee\u51cf\u5c115.7\u500d\uff0c\u632f\u8361\u5668\u7f51\u7edc\u8bef\u5dee\u51cf\u5c113.5\u500d\u3002\u5b66\u4e60\u5230\u7684\u632f\u8361\u5668\u7f51\u7edc\u81ea\u4e3b\u53d1\u73b0\u632f\u8361\u5668\u94fe\u7ed3\u6784\u3002", "conclusion": "ABCD\u6a21\u578b\u652f\u6301\u8d85\u51fa\u8bad\u7ec3\u6570\u636e\u7684\u5e73\u6ed1\u6f5c\u5728\u7a7a\u95f4\u5916\u63a8\uff0c\u8fd9\u79cd\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u4ea7\u751f\u4e86\u7d27\u51d1\u3001\u7269\u7406\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u63a7\u5236\u5e94\u7528\u3002"}}
{"id": "2511.18450", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18450", "abs": "https://arxiv.org/abs/2511.18450", "authors": ["Rui Xu", "Dakuan Lu", "Zicheng Zhao", "Xiaoyu Tan", "Xintao Wang", "Siyu Yuan", "Jiangjie Chen", "Yinghui Xu"], "title": "ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints", "comment": null, "summary": "Spatial reasoning is a key capability in the field of artificial intelligence, especially crucial in areas such as robotics, computer vision, and natural language understanding. However, evaluating the ability of multimodal large language models(MLLMs) in complex spatial reasoning still faces challenges, particularly in scenarios requiring multi-step reasoning and precise mathematical constraints. This paper introduces ORIGAMISPACE, a new dataset and benchmark designed to evaluate the multi-step spatial reasoning ability and the capacity to handle mathematical constraints of MLLMs through origami tasks. The dataset contains 350 data instances,each comprising a strictly formatted crease pattern (CP diagram), the Compiled Flat Pattern, the complete Folding Process, and the final Folded Shape Image. We propose four evaluation tasks: Pattern Prediction, Multi-step Spatial Reasoning, Spatial Relationship Prediction, and End-to-End CP Code Generation. For the CP code generation task, we design an interactive environment and explore the possibility of using reinforcement learning methods to train MLLMs. Through experiments on existing MLLMs, we initially reveal the strengths and weaknesses of these models in handling complex spatial reasoning tasks.", "AI": {"tldr": "ORIGAMISPACE\u662f\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u901a\u8fc7\u6298\u7eb8\u4efb\u52a1\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u9aa4\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u548c\u5904\u7406\u6570\u5b66\u7ea6\u675f\u7684\u80fd\u529b\u3002", "motivation": "\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u4e2d\u7684\u80fd\u529b\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u591a\u6b65\u9aa4\u63a8\u7406\u548c\u7cbe\u786e\u6570\u5b66\u7ea6\u675f\u7684\u573a\u666f\u4e2d\u3002", "method": "\u6784\u5efa\u5305\u542b350\u4e2a\u6570\u636e\u5b9e\u4f8b\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u5b9e\u4f8b\u5305\u542b\u4e25\u683c\u683c\u5f0f\u5316\u7684\u6298\u75d5\u56fe\u6848\u3001\u7f16\u8bd1\u540e\u7684\u5e73\u9762\u56fe\u6848\u3001\u5b8c\u6574\u6298\u53e0\u8fc7\u7a0b\u548c\u6700\u7ec8\u6298\u53e0\u5f62\u72b6\u56fe\u50cf\u3002\u63d0\u51fa\u56db\u4e2a\u8bc4\u4f30\u4efb\u52a1\uff1a\u56fe\u6848\u9884\u6d4b\u3001\u591a\u6b65\u9aa4\u7a7a\u95f4\u63a8\u7406\u3001\u7a7a\u95f4\u5173\u7cfb\u9884\u6d4b\u548c\u7aef\u5230\u7aefCP\u4ee3\u7801\u751f\u6210\u3002", "result": "\u901a\u8fc7\u5728\u73b0\u6709MLLMs\u4e0a\u7684\u5b9e\u9a8c\uff0c\u521d\u6b65\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u548c\u5f31\u70b9\u3002", "conclusion": "ORIGAMISPACE\u4e3a\u8bc4\u4f30MLLMs\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5e76\u63a2\u7d22\u4e86\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec3MLLMs\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.19115", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.19115", "abs": "https://arxiv.org/abs/2511.19115", "authors": ["Rufin VanRullen"], "title": "AI Consciousness and Existential Risk", "comment": null, "summary": "In AI, the existential risk denotes the hypothetical threat posed by an artificial system that would possess both the capability and the objective, either directly or indirectly, to eradicate humanity. This issue is gaining prominence in scientific debate due to recent technical advancements and increased media coverage. In parallel, AI progress has sparked speculation and studies about the potential emergence of artificial consciousness. The two questions, AI consciousness and existential risk, are sometimes conflated, as if the former entailed the latter. Here, I explain that this view stems from a common confusion between consciousness and intelligence. Yet these two properties are empirically and theoretically distinct. Arguably, while intelligence is a direct predictor of an AI system's existential threat, consciousness is not. There are, however, certain incidental scenarios in which consciousness could influence existential risk, in either direction. Consciousness could be viewed as a means towards AI alignment, thereby lowering existential risk; or, it could be a precondition for reaching certain capabilities or levels of intelligence, and thus positively related to existential risk. Recognizing these distinctions can help AI safety researchers and public policymakers focus on the most pressing issues.", "AI": {"tldr": "\u8bba\u6587\u6f84\u6e05\u4e86AI\u610f\u8bc6\u4e0e\u5b58\u5728\u98ce\u9669\u4e4b\u95f4\u7684\u6df7\u6dc6\uff0c\u6307\u51fa\u667a\u80fd\u800c\u975e\u610f\u8bc6\u624d\u662fAI\u5b58\u5728\u98ce\u9669\u7684\u76f4\u63a5\u9884\u6d4b\u56e0\u7d20\uff0c\u4f46\u610f\u8bc6\u53ef\u80fd\u901a\u8fc7\u95f4\u63a5\u65b9\u5f0f\u5f71\u54cd\u98ce\u9669\u3002", "motivation": "\u7531\u4e8eAI\u6280\u672f\u8fdb\u6b65\u548c\u5a92\u4f53\u5173\u6ce8\u5ea6\u589e\u52a0\uff0cAI\u5b58\u5728\u98ce\u9669\u548c\u610f\u8bc6\u95ee\u9898\u5728\u79d1\u5b66\u8fa9\u8bba\u4e2d\u65e5\u76ca\u7a81\u51fa\uff0c\u4f46\u8fd9\u4e24\u4e2a\u95ee\u9898\u7ecf\u5e38\u88ab\u6df7\u6dc6\uff0c\u9700\u8981\u6f84\u6e05\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u533a\u5206\u610f\u8bc6\u548c\u667a\u80fd\u7684\u6982\u5ff5\uff0c\u8bba\u8bc1\u5b83\u4eec\u5728\u7ecf\u9a8c\u548c\u7406\u8bba\u4e0a\u7684\u533a\u522b\uff0c\u5e76\u63a2\u8ba8\u610f\u8bc6\u53ef\u80fd\u95f4\u63a5\u5f71\u54cd\u5b58\u5728\u98ce\u9669\u7684\u51e0\u79cd\u60c5\u666f\u3002", "result": "\u667a\u80fd\u662fAI\u7cfb\u7edf\u5b58\u5728\u5a01\u80c1\u7684\u76f4\u63a5\u9884\u6d4b\u56e0\u7d20\uff0c\u800c\u610f\u8bc6\u672c\u8eab\u4e0d\u662f\u3002\u4f46\u610f\u8bc6\u53ef\u80fd\u901a\u8fc7\u5f71\u54cdAI\u5bf9\u9f50\u6216\u4f5c\u4e3a\u67d0\u4e9b\u80fd\u529b\u7684\u524d\u63d0\u6761\u4ef6\u6765\u95f4\u63a5\u5f71\u54cd\u5b58\u5728\u98ce\u9669\u3002", "conclusion": "\u533a\u5206\u610f\u8bc6\u548c\u667a\u80fd\u6709\u52a9\u4e8eAI\u5b89\u5168\u7814\u7a76\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u805a\u7126\u4e8e\u6700\u5173\u952e\u7684\u95ee\u9898\uff0c\u907f\u514d\u5728\u975e\u6838\u5fc3\u95ee\u9898\u4e0a\u6d6a\u8d39\u8d44\u6e90\u3002"}}
{"id": "2511.18353", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18353", "abs": "https://arxiv.org/abs/2511.18353", "authors": ["Sigrid Helene Strand", "Thomas Wiedemann", "Bram Burczek", "Dmitriy Shutin"], "title": "Enhancing UAV Search under Occlusion using Next Best View Planning", "comment": "Submitted to IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing", "summary": "Search and rescue missions are often critical following sudden natural disasters or in high-risk environmental situations. The most challenging search and rescue missions involve difficult-to-access terrains, such as dense forests with high occlusion. Deploying unmanned aerial vehicles for exploration can significantly enhance search effectiveness, facilitate access to challenging environments, and reduce search time. However, in dense forests, the effectiveness of unmanned aerial vehicles depends on their ability to capture clear views of the ground, necessitating a robust search strategy to optimize camera positioning and perspective. This work presents an optimized planning strategy and an efficient algorithm for the next best view problem in occluded environments. Two novel optimization heuristics, a geometry heuristic, and a visibility heuristic, are proposed to enhance search performance by selecting optimal camera viewpoints. Comparative evaluations in both simulated and real-world settings reveal that the visibility heuristic achieves greater performance, identifying over 90% of hidden objects in simulated forests and offering 10% better detection rates than the geometry heuristic. Additionally, real-world experiments demonstrate that the visibility heuristic provides better coverage under the canopy, highlighting its potential for improving search and rescue missions in occluded environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u906e\u6321\u73af\u5883\u4e2d\u65e0\u4eba\u673a\u641c\u7d22\u6551\u63f4\u7684\u4f18\u5316\u89c4\u5212\u7b56\u7565\uff0c\u5305\u542b\u51e0\u4f55\u542f\u53d1\u5f0f\u548c\u53ef\u89c1\u6027\u542f\u53d1\u5f0f\u4e24\u79cd\u65b9\u6cd5\uff0c\u53ef\u89c1\u6027\u542f\u53d1\u5f0f\u5728\u6a21\u62df\u548c\u771f\u5b9e\u68ee\u6797\u73af\u5883\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5728\u5bc6\u96c6\u68ee\u6797\u7b49\u906e\u6321\u73af\u5883\u4e2d\u8fdb\u884c\u641c\u7d22\u6551\u63f4\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u65e0\u4eba\u673a\u9700\u8981\u6709\u6548\u7684\u641c\u7d22\u7b56\u7565\u6765\u4f18\u5316\u76f8\u673a\u4f4d\u7f6e\u548c\u89c6\u89d2\uff0c\u4ee5\u63d0\u9ad8\u5730\u9762\u76ee\u6807\u7684\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u4f18\u5316\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1a\u51e0\u4f55\u542f\u53d1\u5f0f\u548c\u53ef\u89c1\u6027\u542f\u53d1\u5f0f\uff0c\u7528\u4e8e\u89e3\u51b3\u906e\u6321\u73af\u5883\u4e2d\u7684\u6700\u4f73\u89c6\u89d2\u9009\u62e9\u95ee\u9898\u3002", "result": "\u53ef\u89c1\u6027\u542f\u53d1\u5f0f\u5728\u6a21\u62df\u68ee\u6797\u4e2d\u80fd\u8bc6\u522b\u8d85\u8fc790%\u7684\u9690\u85cf\u7269\u4f53\uff0c\u6bd4\u51e0\u4f55\u542f\u53d1\u5f0f\u68c0\u6d4b\u7387\u9ad810%\uff0c\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u4e5f\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u6811\u51a0\u4e0b\u8986\u76d6\u6548\u679c\u3002", "conclusion": "\u53ef\u89c1\u6027\u542f\u53d1\u5f0f\u5728\u906e\u6321\u73af\u5883\u4e2d\u5177\u6709\u66f4\u597d\u7684\u641c\u7d22\u6027\u80fd\uff0c\u6709\u671b\u663e\u8457\u6539\u5584\u641c\u7d22\u6551\u63f4\u4efb\u52a1\u7684\u6548\u679c\u3002"}}
{"id": "2511.18517", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18517", "abs": "https://arxiv.org/abs/2511.18517", "authors": ["Khanh Gia Bui"], "title": "Foundations of Artificial Intelligence Frameworks: Notion and Limits of AGI", "comment": "49 pages, 4 pictures", "summary": "Within the limited scope of this paper, we argue that artificial general intelligence cannot emerge from current neural network paradigms regardless of scale, nor is such an approach healthy for the field at present. Drawing on various notions, discussions, present-day developments and observations, current debates and critiques, experiments, and so on in between philosophy, including the Chinese Room Argument and G\u00f6delian argument, neuroscientific ideas, computer science, the theoretical consideration of artificial intelligence, and learning theory, we address conceptually that neural networks are architecturally insufficient for genuine understanding. They operate as static function approximators of a limited encoding framework - a 'sophisticated sponge' exhibiting complex behaviours without structural richness that constitute intelligence. We critique the theoretical foundations the field relies on and created of recent times; for example, an interesting heuristic as neural scaling law (as an example, arXiv:2001.08361 ) made prominent in a wrong way of interpretation, The Universal Approximation Theorem addresses the wrong level of abstraction and, in parts, partially, the question of current architectures lacking dynamic restructuring capabilities. We propose a framework distinguishing existential facilities (computational substrate) from architectural organization (interpretive structures), and outline principles for what genuine machine intelligence would require, and furthermore, a conceptual method of structuralizing the richer framework on which the principle of neural network system takes hold.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.18374", "categories": ["cs.RO", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.18374", "abs": "https://arxiv.org/abs/2511.18374", "authors": ["Jiaxun Sun"], "title": "Explicit Bounds on the Hausdorff Distance for Truncated mRPI Sets via Norm-Dependent Contraction Rates", "comment": null, "summary": "This paper establishes the first explicit and closed-form upper bound on the Hausdorff distance between the truncated minimal robust positively invariant (mRPI) set and its infinite-horizon limit. While existing mRPI approximations guarantee asymptotic convergence through geometric or norm-based arguments, none provides a computable expression that quantifies the truncation error for a given horizon. We show that the error satisfies \\( d_H(\\mathcal{E}_N,\\mathcal{E}_\\infty) \\le r_W\\,\u03b3^{N+1}/(1-\u03b3), \\) where $\u03b3<1$ is the induced-norm contraction factor and $r_W$ depends only on the disturbance set. The bound is fully analytic, requires no iterative set computations, and directly characterizes the decay rate of the truncated Minkowski series. We further demonstrate that the choice of vector norm serves as a design parameter that accelerates convergence, enabling substantially tighter horizon selection for robust invariant-set computations and tube-based MPC. Numerical experiments validate the sharpness, scalability, and practical relevance of the proposed bound.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5efa\u7acb\u4e86\u622a\u65ad\u6700\u5c0f\u9c81\u68d2\u6b63\u4e0d\u53d8\u96c6\u4e0e\u5176\u65e0\u9650\u65f6\u57df\u6781\u9650\u4e4b\u95f4Hausdorff\u8ddd\u79bb\u7684\u663e\u5f0f\u95ed\u5f0f\u4e0a\u754c\uff0c\u63d0\u4f9b\u4e86\u53ef\u8ba1\u7b97\u7684\u622a\u65ad\u8bef\u5dee\u91cf\u5316\u8868\u8fbe\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684mRPI\u8fd1\u4f3c\u65b9\u6cd5\u901a\u8fc7\u51e0\u4f55\u6216\u8303\u6570\u8bba\u8bc1\u4fdd\u8bc1\u6e10\u8fd1\u6536\u655b\uff0c\u4f46\u6ca1\u6709\u63d0\u4f9b\u9488\u5bf9\u7ed9\u5b9a\u65f6\u57df\u91cf\u5316\u622a\u65ad\u8bef\u5dee\u7684\u53ef\u8ba1\u7b97\u8868\u8fbe\u5f0f\u3002", "method": "\u8bc1\u660e\u4e86\u8bef\u5dee\u6ee1\u8db3d_H(\u2130_N,\u2130_\u221e) \u2264 r_W\u00b7\u03b3^(N+1)/(1-\u03b3)\uff0c\u5176\u4e2d\u03b3<1\u662f\u8bf1\u5bfc\u8303\u6570\u6536\u7f29\u56e0\u5b50\uff0cr_W\u4ec5\u4f9d\u8d56\u4e8e\u6270\u52a8\u96c6\u3002\u8be5\u8fb9\u754c\u5b8c\u5168\u89e3\u6790\uff0c\u4e0d\u9700\u8981\u8fed\u4ee3\u96c6\u8ba1\u7b97\u3002", "result": "\u8fb9\u754c\u5b8c\u5168\u89e3\u6790\uff0c\u76f4\u63a5\u8868\u5f81\u622a\u65adMinkowski\u7ea7\u6570\u7684\u8870\u51cf\u7387\uff0c\u5411\u91cf\u8303\u6570\u7684\u9009\u62e9\u53ef\u4f5c\u4e3a\u8bbe\u8ba1\u53c2\u6570\u52a0\u901f\u6536\u655b\uff0c\u663e\u8457\u6536\u7d27\u9c81\u68d2\u4e0d\u53d8\u96c6\u8ba1\u7b97\u548c\u57fa\u4e8e\u7ba1\u7684MPC\u7684\u65f6\u57df\u9009\u62e9\u3002", "conclusion": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u8fb9\u754c\u7684\u9510\u5ea6\u3001\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u76f8\u5173\u6027\u3002"}}
{"id": "2511.18486", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.18486", "abs": "https://arxiv.org/abs/2511.18486", "authors": ["Jasan Zughaibi", "Denis von Arx", "Maurus Derungs", "Florian Heemeyer", "Luca A. Antonelli", "Quentin Boehler", "Michael Muehlebach", "Bradley J. Nelson"], "title": "Expanding the Workspace of Electromagnetic Navigation Systems Using Dynamic Feedback for Single- and Multi-agent Control", "comment": null, "summary": "Electromagnetic navigation systems (eMNS) enable a number of magnetically guided surgical procedures. A challenge in magnetically manipulating surgical tools is that the effective workspace of an eMNS is often severely constrained by power and thermal limits. We show that system-level control design significantly expands this workspace by reducing the currents needed to achieve a desired motion. We identified five key system approaches that enable this expansion: (i) motion-centric torque/force objectives, (ii) energy-optimal current allocation, (iii) real-time pose estimation, (iv) dynamic feedback, and (v) high-bandwidth eMNS components. As a result, we stabilize a 3D inverted pendulum on an eight-coil OctoMag eMNS with significantly lower currents (0.1-0.2 A vs. 8-14 A), by replacing a field-centric field-alignment strategy with a motion-centric torque/force-based approach. We generalize to multi-agent control by simultaneously stabilizing two inverted pendulums within a shared workspace, exploiting magnetic-field nonlinearity and coil redundancy for independent actuation. A structured analysis compares the electromagnetic workspaces of both paradigms and examines current-allocation strategies that map motion objectives to coil currents. Cross-platform evaluation of the clinically oriented Navion eMNS further demonstrates substantial workspace expansion by maintaining stable balancing at distances up to 50 cm from the coils. The results demonstrate that feedback is a practical path to scalable, efficient, and clinically relevant magnetic manipulation.", "AI": {"tldr": "\u901a\u8fc7\u7cfb\u7edf\u7ea7\u63a7\u5236\u8bbe\u8ba1\u663e\u8457\u6269\u5c55\u7535\u78c1\u5bfc\u822a\u7cfb\u7edf\u7684\u5de5\u4f5c\u7a7a\u95f4\uff0c\u91c7\u7528\u8fd0\u52a8\u4e2d\u5fc3\u7684\u626d\u77e9/\u529b\u76ee\u6807\u3001\u80fd\u91cf\u6700\u4f18\u7535\u6d41\u5206\u914d\u7b49\u4e94\u79cd\u65b9\u6cd5\uff0c\u5c06\u7a33\u5b9a3D\u5012\u7acb\u6446\u6240\u9700\u7684\u7535\u6d41\u4ece8-14A\u964d\u4f4e\u52300.1-0.2A\uff0c\u5e76\u5728\u4e34\u5e8a\u5bfc\u5411\u7684Navion\u7cfb\u7edf\u4e0a\u5b9e\u73b050cm\u8ddd\u79bb\u7684\u7a33\u5b9a\u5e73\u8861\u3002", "motivation": "\u7535\u78c1\u5bfc\u822a\u7cfb\u7edf\u7684\u6709\u6548\u5de5\u4f5c\u7a7a\u95f4\u5e38\u53d7\u529f\u7387\u548c\u70ed\u9650\u5236\u4e25\u91cd\u7ea6\u675f\uff0c\u9700\u8981\u627e\u5230\u6269\u5c55\u5de5\u4f5c\u7a7a\u95f4\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e94\u79cd\u7cfb\u7edf\u65b9\u6cd5\uff1a\u8fd0\u52a8\u4e2d\u5fc3\u7684\u626d\u77e9/\u529b\u76ee\u6807\u3001\u80fd\u91cf\u6700\u4f18\u7535\u6d41\u5206\u914d\u3001\u5b9e\u65f6\u4f4d\u59ff\u4f30\u8ba1\u3001\u52a8\u6001\u53cd\u9988\u548c\u9ad8\u5e26\u5bbdeMNS\u7ec4\u4ef6\uff0c\u5c06\u573a\u4e2d\u5fc3\u7b56\u7565\u66ff\u6362\u4e3a\u8fd0\u52a8\u4e2d\u5fc3\u65b9\u6cd5\u3002", "result": "\u5728OctoMag\u7cfb\u7edf\u4e0a\u7a33\u5b9a3D\u5012\u7acb\u6446\u7684\u7535\u6d41\u4ece8-14A\u964d\u81f30.1-0.2A\uff0c\u5728Navion\u7cfb\u7edf\u4e0a\u5b9e\u73b050cm\u8ddd\u79bb\u7684\u7a33\u5b9a\u5e73\u8861\uff0c\u5e76\u6210\u529f\u540c\u65f6\u7a33\u5b9a\u4e24\u4e2a\u5012\u7acb\u6446\u3002", "conclusion": "\u53cd\u9988\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u4e14\u4e34\u5e8a\u76f8\u5173\u7684\u78c1\u64cd\u7eb5\u7684\u5b9e\u7528\u8def\u5f84\uff0c\u7cfb\u7edf\u7ea7\u63a7\u5236\u8bbe\u8ba1\u80fd\u663e\u8457\u6269\u5c55\u7535\u78c1\u5bfc\u822a\u7cfb\u7edf\u7684\u5de5\u4f5c\u7a7a\u95f4\u3002"}}
{"id": "2511.18633", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18633", "abs": "https://arxiv.org/abs/2511.18633", "authors": ["Yildiz Culcu"], "title": "Bridging Philosophy and Machine Learning: A Structuralist Framework for Classifying Neural Network Representations", "comment": "7 pages, 1 figure, 1 table. Developed from the author's bachelor thesis but substantially revised and reformulated for research publication", "summary": "Machine learning models increasingly function as representational systems, yet the philosoph- ical assumptions underlying their internal structures remain largely unexamined. This paper develops a structuralist decision framework for classifying the implicit ontological commitments made in machine learning research on neural network representations. Using a modified PRISMA protocol, a systematic review of the last two decades of literature on representation learning and interpretability is conducted. Five influential papers are analysed through three hierarchical criteria derived from structuralist philosophy of science: entity elimination, source of structure, and mode of existence. The results reveal a pronounced tendency toward structural idealism, where learned representations are treated as model-dependent constructions shaped by architec- ture, data priors, and training dynamics. Eliminative and non-eliminative structuralist stances appear selectively, while structural realism is notably absent. The proposed framework clarifies conceptual tensions in debates on interpretability, emergence, and epistemic trust in machine learning, and offers a rigorous foundation for future interdisciplinary work between philosophy of science and machine learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u6784\u4e3b\u4e49\u51b3\u7b56\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u7c7b\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4e2d\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u7684\u9690\u542b\u672c\u4f53\u8bba\u627f\u8bfa\uff0c\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u56de\u987e\u53d1\u73b0\u5f53\u524d\u7814\u7a76\u503e\u5411\u4e8e\u7ed3\u6784\u7406\u60f3\u4e3b\u4e49\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f5c\u4e3a\u8868\u5f81\u7cfb\u7edf\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u5176\u5185\u90e8\u7ed3\u6784\u7684\u54f2\u5b66\u5047\u8bbe\u5c1a\u672a\u5f97\u5230\u5145\u5206\u68c0\u9a8c\uff0c\u9700\u8981\u5f00\u53d1\u6846\u67b6\u6765\u5206\u6790\u5176\u9690\u542b\u7684\u672c\u4f53\u8bba\u627f\u8bfa\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684PRISMA\u534f\u8bae\u5bf9\u8fc7\u53bb20\u5e74\u8868\u5f81\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u6027\u6587\u732e\u8fdb\u884c\u7cfb\u7edf\u56de\u987e\uff0c\u901a\u8fc7\u4e09\u4e2a\u5c42\u6b21\u6807\u51c6\uff08\u5b9e\u4f53\u6d88\u9664\u3001\u7ed3\u6784\u6765\u6e90\u3001\u5b58\u5728\u6a21\u5f0f\uff09\u5206\u6790\u4e94\u7bc7\u6709\u5f71\u54cd\u529b\u7684\u8bba\u6587\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\u660e\u663e\u7684\u7ed3\u6784\u7406\u60f3\u4e3b\u4e49\u503e\u5411\uff0c\u5b66\u4e60\u5230\u7684\u8868\u5f81\u88ab\u89c6\u4e3a\u6a21\u578b\u4f9d\u8d56\u7684\u6784\u9020\uff0c\u7531\u67b6\u6784\u3001\u6570\u636e\u5148\u9a8c\u548c\u8bad\u7ec3\u52a8\u6001\u5851\u9020\u3002\u6d88\u9664\u6027\u548c\u975e\u6d88\u9664\u6027\u7ed3\u6784\u4e3b\u4e49\u7acb\u573a\u9009\u62e9\u6027\u51fa\u73b0\uff0c\u800c\u7ed3\u6784\u73b0\u5b9e\u4e3b\u4e49\u660e\u663e\u7f3a\u5931\u3002", "conclusion": "\u8be5\u6846\u67b6\u6f84\u6e05\u4e86\u53ef\u89e3\u91ca\u6027\u3001\u6d8c\u73b0\u6027\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u8ba4\u77e5\u4fe1\u4efb\u8fa9\u8bba\u4e2d\u7684\u6982\u5ff5\u5f20\u529b\uff0c\u4e3a\u79d1\u5b66\u54f2\u5b66\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u672a\u6765\u8de8\u5b66\u79d1\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e25\u8c28\u57fa\u7840\u3002"}}
{"id": "2511.19204", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19204", "abs": "https://arxiv.org/abs/2511.19204", "authors": ["Fabian Schramm", "Pierre Fabre", "Nicolas Perrin-Gilbert", "Justin Carpentier"], "title": "Reference-Free Sampling-Based Model Predictive Control", "comment": null, "summary": "We present a sampling-based model predictive control (MPC) framework that enables emergent locomotion without relying on handcrafted gait patterns or predefined contact sequences. Our method discovers diverse motion patterns, ranging from trotting to galloping, robust standing policies, jumping, and handstand balancing, purely through the optimization of high-level objectives. Building on model predictive path integral (MPPI), we propose a dual-space spline parameterization that operates on position and velocity control points. Our approach enables contact-making and contact-breaking strategies that adapt automatically to task requirements, requiring only a limited number of sampled trajectories. This sample efficiency allows us to achieve real-time control on standard CPU hardware, eliminating the need for GPU acceleration typically required by other state-of-the-art MPPI methods. We validate our approach on the Go2 quadrupedal robot, demonstrating various emergent gaits and basic jumping capabilities. In simulation, we further showcase more complex behaviors, such as backflips, dynamic handstand balancing and locomotion on a Humanoid, all without requiring reference tracking or offline pre-training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91c7\u6837\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u6b65\u6001\u6a21\u5f0f\u6216\u63a5\u89e6\u5e8f\u5217\uff0c\u901a\u8fc7\u4f18\u5316\u9ad8\u5c42\u76ee\u6807\u81ea\u52a8\u53d1\u73b0\u591a\u6837\u5316\u8fd0\u52a8\u6a21\u5f0f\uff0c\u5305\u62ec\u5c0f\u8dd1\u3001\u75be\u8dd1\u3001\u8df3\u8dc3\u7b49\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u63a7\u5236\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u6b65\u6001\u6a21\u5f0f\u548c\u9884\u5b9a\u4e49\u7684\u63a5\u89e6\u5e8f\u5217\uff0c\u9650\u5236\u4e86\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u591a\u6837\u6027\u548c\u9002\u5e94\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7eaf\u4f18\u5316\u65b9\u6cd5\u5b9e\u73b0\u81ea\u4e3b\u6d8c\u73b0\u7684\u591a\u6837\u5316\u8fd0\u52a8\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206(MPPI)\uff0c\u63d0\u51fa\u53cc\u7a7a\u95f4\u6837\u6761\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u5728\u4f4d\u7f6e\u548c\u901f\u5ea6\u63a7\u5236\u70b9\u4e0a\u64cd\u4f5c\uff0c\u81ea\u52a8\u9002\u5e94\u4efb\u52a1\u9700\u6c42\u8fdb\u884c\u63a5\u89e6\u5efa\u7acb\u548c\u63a5\u89e6\u65ad\u5f00\u7b56\u7565\u3002", "result": "\u5728Go2\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u591a\u6837\u5316\u6b65\u6001\u548c\u57fa\u672c\u8df3\u8dc3\u80fd\u529b\uff0c\u5728\u4eff\u771f\u4e2d\u5c55\u793a\u4e86\u540e\u7a7a\u7ffb\u3001\u52a8\u6001\u5012\u7acb\u5e73\u8861\u7b49\u590d\u6742\u884c\u4e3a\uff0c\u65e0\u9700\u53c2\u8003\u8ddf\u8e2a\u6216\u79bb\u7ebf\u9884\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6837\u672c\u9ad8\u6548\u7684\u5b9e\u65f6\u63a7\u5236\uff0c\u65e0\u9700GPU\u52a0\u901f\uff0c\u80fd\u591f\u81ea\u4e3b\u53d1\u73b0\u591a\u6837\u5316\u7684\u8fd0\u52a8\u6a21\u5f0f\uff0c\u4e3a\u673a\u5668\u4eba\u8fd0\u52a8\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2511.18509", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18509", "abs": "https://arxiv.org/abs/2511.18509", "authors": ["Ziyu Meng", "Tengyu Liu", "Le Ma", "Yingying Wu", "Ran Song", "Wei Zhang", "Siyuan Huang"], "title": "SafeFall: Learning Protective Control for Humanoid Robots", "comment": null, "summary": "Bipedal locomotion makes humanoid robots inherently prone to falls, causing catastrophic damage to the expensive sensors, actuators, and structural components of full-scale robots. To address this critical barrier to real-world deployment, we present \\method, a framework that learns to predict imminent, unavoidable falls and execute protective maneuvers to minimize hardware damage. SafeFall is designed to operate seamlessly alongside existing nominal controller, ensuring no interference during normal operation. It combines two synergistic components: a lightweight, GRU-based fall predictor that continuously monitors the robot's state, and a reinforcement learning policy for damage mitigation. The protective policy remains dormant until the predictor identifies a fall as unavoidable, at which point it activates to take control and execute a damage-minimizing response. This policy is trained with a novel, damage-aware reward function that incorporates the robot's specific structural vulnerabilities, learning to shield critical components like the head and hands while absorbing energy with more robust parts of its body. Validated on a full-scale Unitree G1 humanoid, SafeFall demonstrated significant performance improvements over unprotected falls. It reduced peak contact forces by 68.3\\%, peak joint torques by 78.4\\%, and eliminated 99.3\\% of collisions with vulnerable components. By enabling humanoids to fail safely, SafeFall provides a crucial safety net that allows for more aggressive experiments and accelerates the deployment of these robots in complex, real-world environments.", "AI": {"tldr": "SafeFall\u6846\u67b6\u901a\u8fc7\u9884\u6d4b\u4e0d\u53ef\u907f\u514d\u7684\u8dcc\u5012\u5e76\u6267\u884c\u4fdd\u62a4\u6027\u52a8\u4f5c\u6765\u6700\u5c0f\u5316\u4eff\u4eba\u673a\u5668\u4eba\u7684\u786c\u4ef6\u635f\u574f\uff0c\u5305\u62ec\u8f7b\u91cf\u7ea7\u8dcc\u5012\u9884\u6d4b\u5668\u548c\u5f3a\u5316\u5b66\u4e60\u4fdd\u62a4\u7b56\u7565\u3002", "motivation": "\u4eff\u4eba\u673a\u5668\u4eba\u53cc\u8db3\u884c\u8d70\u5bb9\u6613\u8dcc\u5012\uff0c\u4f1a\u5bf9\u6602\u8d35\u7684\u4f20\u611f\u5668\u3001\u6267\u884c\u5668\u548c\u7ed3\u6784\u7ec4\u4ef6\u9020\u6210\u707e\u96be\u6027\u635f\u574f\uff0c\u8fd9\u662f\u5b9e\u9645\u90e8\u7f72\u7684\u5173\u952e\u969c\u788d\u3002", "method": "\u7ed3\u5408GRU\u8dcc\u5012\u9884\u6d4b\u5668\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4fdd\u62a4\u7b56\u7565\uff0c\u5728\u68c0\u6d4b\u5230\u4e0d\u53ef\u907f\u514d\u8dcc\u5012\u65f6\u6fc0\u6d3b\u4fdd\u62a4\u52a8\u4f5c\uff0c\u4f7f\u7528\u635f\u4f24\u611f\u77e5\u5956\u52b1\u51fd\u6570\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728Unitree G1\u4eff\u4eba\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\uff0c\u5cf0\u503c\u63a5\u89e6\u529b\u964d\u4f4e68.3%\uff0c\u5cf0\u503c\u5173\u8282\u626d\u77e9\u964d\u4f4e78.4%\uff0c\u8106\u5f31\u90e8\u4ef6\u78b0\u649e\u51cf\u5c1199.3%\u3002", "conclusion": "SafeFall\u4e3a\u4eff\u4eba\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u5b89\u5168\u7f51\uff0c\u652f\u6301\u66f4\u6fc0\u8fdb\u7684\u5b9e\u9a8c\u5e76\u52a0\u901f\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002"}}
{"id": "2511.18525", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18525", "abs": "https://arxiv.org/abs/2511.18525", "authors": ["Samarth Chopra", "Jing Liang", "Gershom Seneviratne", "Yonghan Lee", "Jaehoon Choi", "Jianyu An", "Stephen Cheng", "Dinesh Manocha"], "title": "Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot Navigation", "comment": "Submitted to ICRA 2026", "summary": "We present Splatblox, a real-time system for autonomous navigation in outdoor environments with dense vegetation, irregular obstacles, and complex terrain. Our method fuses segmented RGB images and LiDAR point clouds using Gaussian Splatting to construct a traversability-aware Euclidean Signed Distance Field (ESDF) that jointly encodes geometry and semantics. Updated online, this field enables semantic reasoning to distinguish traversable vegetation (e.g., tall grass) from rigid obstacles (e.g., trees), while LiDAR ensures 360-degree geometric coverage for extended planning horizons. We validate Splatblox on a quadruped robot and demonstrate transfer to a wheeled platform. In field trials across vegetation-rich scenarios, it outperforms state-of-the-art methods with over 50% higher success rate, 40% fewer freezing incidents, 5% shorter paths, and up to 13% faster time to goal, while supporting long-range missions up to 100 meters. Experiment videos and more details can be found on our project page: https://splatblox.github.io", "AI": {"tldr": "Splatblox\u662f\u4e00\u4e2a\u7528\u4e8e\u6237\u5916\u5bc6\u96c6\u690d\u88ab\u73af\u5883\u7684\u5b9e\u65f6\u81ea\u4e3b\u5bfc\u822a\u7cfb\u7edf\uff0c\u878d\u5408RGB\u56fe\u50cf\u548cLiDAR\u70b9\u4e91\uff0c\u901a\u8fc7\u9ad8\u65af\u6cfc\u6e85\u6784\u5efa\u53ef\u901a\u884c\u6027\u611f\u77e5\u7684ESDF\u573a\uff0c\u5728\u690d\u88ab\u4e30\u5bcc\u573a\u666f\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u6210\u529f\u7387\u63d0\u9ad850%\u4ee5\u4e0a\u3002", "motivation": "\u89e3\u51b3\u6237\u5916\u73af\u5883\u4e2d\u5bc6\u96c6\u690d\u88ab\u3001\u4e0d\u89c4\u5219\u969c\u788d\u7269\u548c\u590d\u6742\u5730\u5f62\u5e26\u6765\u7684\u5bfc\u822a\u6311\u6218\uff0c\u9700\u8981\u540c\u65f6\u5904\u7406\u51e0\u4f55\u548c\u8bed\u4e49\u4fe1\u606f\u6765\u533a\u5206\u53ef\u7a7f\u8d8a\u690d\u88ab\u548c\u521a\u6027\u969c\u788d\u7269\u3002", "method": "\u878d\u5408\u5206\u5272\u7684RGB\u56fe\u50cf\u548cLiDAR\u70b9\u4e91\uff0c\u4f7f\u7528\u9ad8\u65af\u6cfc\u6e85\u6784\u5efa\u53ef\u901a\u884c\u6027\u611f\u77e5\u7684\u6b27\u51e0\u91cc\u5f97\u7b26\u53f7\u8ddd\u79bb\u573a(ESDF)\uff0c\u5728\u7ebf\u66f4\u65b0\u8be5\u573a\u4ee5\u652f\u6301\u8bed\u4e49\u63a8\u7406\u548c360\u5ea6\u51e0\u4f55\u8986\u76d6\u3002", "result": "\u5728\u690d\u88ab\u4e30\u5bcc\u573a\u666f\u7684\u73b0\u573a\u8bd5\u9a8c\u4e2d\uff0c\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u6210\u529f\u7387\u63d0\u9ad850%\u4ee5\u4e0a\uff0c\u51bb\u7ed3\u4e8b\u4ef6\u51cf\u5c1140%\uff0c\u8def\u5f84\u7f29\u77ed5%\uff0c\u76ee\u6807\u65f6\u95f4\u52a0\u5feb13%\uff0c\u652f\u6301\u957f\u8fbe100\u7c73\u7684\u8fdc\u7a0b\u4efb\u52a1\u3002", "conclusion": "Splatblox\u7cfb\u7edf\u5728\u590d\u6742\u6237\u5916\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u81ea\u4e3b\u5bfc\u822a\uff0c\u6210\u529f\u533a\u5206\u53ef\u7a7f\u8d8a\u690d\u88ab\u548c\u521a\u6027\u969c\u788d\u7269\uff0c\u5e76\u5728\u56db\u8db3\u548c\u8f6e\u5f0f\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.18715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18715", "abs": "https://arxiv.org/abs/2511.18715", "authors": ["Shaoyin Ma", "Jie Song", "Huiqiong Wang", "Li Sun", "Mingli Song"], "title": "HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering Optimal Model Companions", "comment": "19 pages, 4 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in their ability to interact with external interfaces. Selecting reasonable external interfaces has thus become a crucial step in constructing LLM agents. In contrast to invoking API tools, directly calling AI models across different modalities from the community (e.g., HuggingFace) poses challenges due to the vast scale (> 10k), metadata gaps, and unstructured descriptions. Current methods for model selection often involve incorporating entire model descriptions into prompts, resulting in prompt bloat, wastage of tokens and limited scalability. To address these issues, we propose HuggingR$^4$, a novel framework that combines Reasoning, Retrieval, Refinement, and Reflection, to efficiently select models. Specifically, We first perform multiple rounds of reasoning and retrieval to get a coarse list of candidate models. Then, we conduct fine-grained refinement by analyzing candidate model descriptions, followed by reflection to assess results and determine if retrieval scope expansion is necessary. This method reduces token consumption considerably by decoupling user query processing from complex model description handling. Through a pre-established vector database, complex model descriptions are stored externally and retrieved on-demand, allowing the LLM to concentrate on interpreting user intent while accessing only relevant candidate models without prompt bloat. In the absence of standardized benchmarks, we construct a multimodal human-annotated dataset comprising 14,399 user requests across 37 tasks and conduct a thorough evaluation. HuggingR$^4$ attains a workability rate of 92.03% and a reasonability rate of 82.46%, surpassing existing method by 26.51% and 33.25% respectively on GPT-4o-mini.", "AI": {"tldr": "HuggingR\u2074\u662f\u4e00\u4e2a\u7ed3\u5408\u63a8\u7406\u3001\u68c0\u7d22\u3001\u7cbe\u70bc\u548c\u53cd\u601d\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u9009\u62e9\u591a\u6a21\u6001AI\u6a21\u578b\uff0c\u89e3\u51b3\u6a21\u578b\u9009\u62e9\u4e2d\u7684\u63d0\u793a\u81a8\u80c0\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "LLM\u4e0e\u5916\u90e8\u63a5\u53e3\u4ea4\u4e92\u65f6\uff0c\u4ece\u6d77\u91cf\u793e\u533a\u6a21\u578b\u4e2d\u9009\u62e9\u5408\u9002\u6a21\u578b\u9762\u4e34\u6311\u6218\uff1a\u6a21\u578b\u6570\u91cf\u5e9e\u5927\u3001\u5143\u6570\u636e\u7f3a\u5931\u3001\u63cf\u8ff0\u975e\u7ed3\u6784\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u5b8c\u6574\u6a21\u578b\u63cf\u8ff0\u7eb3\u5165\u63d0\u793a\uff0c\u5bfc\u81f4\u63d0\u793a\u81a8\u80c0\u3001\u4ee4\u724c\u6d6a\u8d39\u548c\u53ef\u6269\u5c55\u6027\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u56db\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u591a\u8f6e\u63a8\u7406\u548c\u68c0\u7d22\u83b7\u53d6\u5019\u9009\u6a21\u578b\u7c97\u5217\u8868\uff1b2\uff09\u5206\u6790\u5019\u9009\u6a21\u578b\u63cf\u8ff0\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7cbe\u70bc\uff1b3\uff09\u53cd\u601d\u8bc4\u4f30\u7ed3\u679c\u5e76\u51b3\u5b9a\u662f\u5426\u9700\u8981\u6269\u5c55\u68c0\u7d22\u8303\u56f4\uff1b4\uff09\u901a\u8fc7\u9884\u5efa\u5411\u91cf\u6570\u636e\u5e93\u5916\u90e8\u5b58\u50a8\u590d\u6742\u6a21\u578b\u63cf\u8ff0\uff0c\u6309\u9700\u68c0\u7d22\u3002", "result": "\u5728\u5305\u542b14,399\u4e2a\u7528\u6237\u8bf7\u6c42\u7684\u591a\u6a21\u6001\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cHuggingR\u2074\u5728GPT-4o-mini\u4e0a\u8fbe\u523092.03%\u7684\u53ef\u7528\u7387\u548c82.46%\u7684\u5408\u7406\u7387\uff0c\u5206\u522b\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534726.51%\u548c33.25%\u3002", "conclusion": "HuggingR\u2074\u901a\u8fc7\u5c06\u7528\u6237\u67e5\u8be2\u5904\u7406\u4e0e\u590d\u6742\u6a21\u578b\u63cf\u8ff0\u5904\u7406\u89e3\u8026\uff0c\u663e\u8457\u51cf\u5c11\u4ee4\u724c\u6d88\u8017\uff0c\u4f7fLLM\u80fd\u4e13\u6ce8\u4e8e\u89e3\u91ca\u7528\u6237\u610f\u56fe\uff0c\u540c\u65f6\u907f\u514d\u63d0\u793a\u81a8\u80c0\u95ee\u9898\uff0c\u5728\u591a\u6a21\u6001\u6a21\u578b\u9009\u62e9\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.18563", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18563", "abs": "https://arxiv.org/abs/2511.18563", "authors": ["Cem Bilaloglu", "Tobias L\u00f6w", "Sylvain Calinon"], "title": "Object-centric Task Representation and Transfer using Diffused Orientation Fields", "comment": null, "summary": "Curved objects pose a fundamental challenge for skill transfer in robotics: unlike planar surfaces, they do not admit a global reference frame. As a result, task-relevant directions such as \"toward\" or \"along\" the surface vary with position and geometry, making object-centric tasks difficult to transfer across shapes. To address this, we introduce an approach using Diffused Orientation Fields (DOF), a smooth representation of local reference frames, for transfer learning of tasks across curved objects. By expressing manipulation tasks in these smoothly varying local frames, we reduce the problem of transferring tasks across curved objects to establishing sparse keypoint correspondences. DOF is computed online from raw point cloud data using diffusion processes governed by partial differential equations, conditioned on keypoints. We evaluate DOF under geometric, topological, and localization perturbations, and demonstrate successful transfer of tasks requiring continuous physical interaction such as inspection, slicing, and peeling across varied objects. We provide our open-source codes at our website https://github.com/idiap/diffused_fields_robotics", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u6269\u6563\u65b9\u5411\u573a(DOF)\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u53c2\u8003\u6846\u67b6\u8868\u793a\u6765\u89e3\u51b3\u66f2\u9762\u7269\u4f53\u4e0a\u7684\u6280\u80fd\u8fc1\u79fb\u95ee\u9898\uff0c\u5c06\u4efb\u52a1\u8fc1\u79fb\u7b80\u5316\u4e3a\u7a00\u758f\u5173\u952e\u70b9\u5bf9\u5e94\u5173\u7cfb\u5efa\u7acb", "motivation": "\u66f2\u9762\u7269\u4f53\u7f3a\u4e4f\u5168\u5c40\u53c2\u8003\u6846\u67b6\uff0c\u4f7f\u5f97\u4efb\u52a1\u76f8\u5173\u65b9\u5411\u968f\u4f4d\u7f6e\u548c\u51e0\u4f55\u5f62\u72b6\u53d8\u5316\uff0c\u5bfc\u81f4\u57fa\u4e8e\u7269\u4f53\u7684\u4efb\u52a1\u96be\u4ee5\u5728\u4e0d\u540c\u5f62\u72b6\u95f4\u8fc1\u79fb", "method": "\u4f7f\u7528\u6269\u6563\u65b9\u5411\u573a(DOF)\u4f5c\u4e3a\u5c40\u90e8\u53c2\u8003\u6846\u67b6\u7684\u5e73\u6ed1\u8868\u793a\uff0c\u901a\u8fc7\u53d7\u504f\u5fae\u5206\u65b9\u7a0b\u63a7\u5236\u7684\u6269\u6563\u8fc7\u7a0b\u4ece\u539f\u59cb\u70b9\u4e91\u6570\u636e\u5728\u7ebf\u8ba1\u7b97DOF\uff0c\u5e76\u4ee5\u5173\u952e\u70b9\u4e3a\u6761\u4ef6", "result": "\u5728\u51e0\u4f55\u3001\u62d3\u6251\u548c\u5b9a\u4f4d\u6270\u52a8\u4e0b\u8bc4\u4f30DOF\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u9700\u8981\u8fde\u7eed\u7269\u7406\u4ea4\u4e92\u7684\u4efb\u52a1\uff08\u5982\u68c0\u67e5\u3001\u5207\u5272\u548c\u5265\u76ae\uff09\u5728\u4e0d\u540c\u7269\u4f53\u95f4\u7684\u8fc1\u79fb", "conclusion": "DOF\u65b9\u6cd5\u901a\u8fc7\u5c40\u90e8\u53c2\u8003\u6846\u67b6\u7684\u5e73\u6ed1\u8868\u793a\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u66f2\u9762\u7269\u4f53\u4e0a\u7684\u6280\u80fd\u8fc1\u79fb\u95ee\u9898\uff0c\u5c06\u590d\u6742\u4efb\u52a1\u8fc1\u79fb\u7b80\u5316\u4e3a\u7a00\u758f\u5173\u952e\u70b9\u5bf9\u5e94"}}
{"id": "2511.18723", "categories": ["cs.AI", "cs.DC", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.18723", "abs": "https://arxiv.org/abs/2511.18723", "authors": ["Longfei Wang", "Junyan Liu", "Fan Zhang", "Jiangwen Wei", "Yuanhua Tang", "Jie Sun", "Xiaodong Luo"], "title": "N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory", "comment": "18 pages, 2 figures", "summary": "Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aN2N\u7684\u53ef\u6269\u5c55\u5e76\u884c\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u8ba1\u7b97\u73af\u5883\u4e2d\u6c42\u89e3\u5927\u89c4\u6a21\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u652f\u6301\u786e\u5b9a\u6027\u548c\u975e\u786e\u5b9a\u6027\u6a21\u5f0f\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5e76\u884c\u6c42\u89e3\u5668ParaSCIP\u3002", "motivation": "\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u4e2d\u7684\u5206\u652f\u5b9a\u754c\u6846\u67b6\u590d\u6742\u4e14\u5305\u542b\u4f17\u591a\u6709\u6548\u7b97\u6cd5\u7ec4\u4ef6\uff0c\u4f7f\u5f97\u5e76\u884c\u5316\u53d8\u5f97\u56f0\u96be\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u5e76\u884c\u6846\u67b6\u6765\u52a0\u901f\u6c42\u89e3\u8fc7\u7a0b\u3002", "method": "\u8bbe\u8ba1\u4e86N2N\u8282\u70b9\u5230\u8282\u70b9\u6846\u67b6\uff0c\u5c06\u5206\u652f\u5b9a\u754c\u8282\u70b9\u6620\u5c04\u5230\u5206\u5e03\u5f0f\u8ba1\u7b97\u8282\u70b9\uff1b\u5f00\u53d1\u4e86\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3\u7684\u7b97\u6cd5\u786e\u4fdd\u786e\u5b9a\u6027\u4efb\u52a1\u987a\u5e8f\uff1b\u96c6\u6210\u4e86CP\u641c\u7d22\u548c\u901a\u7528\u539f\u59cb\u542f\u53d1\u5f0f\u7b49\u5148\u8fdb\u6280\u672f\uff1b\u4f18\u5316\u4e86\u81ea\u9002\u5e94\u6c42\u89e3\u548c\u6570\u636e\u901a\u4fe1\u3002", "result": "\u975e\u786e\u5b9a\u6027N2N-SCIP\u57281000\u4e2aMPI\u8fdb\u7a0b\u4e0b\u5206\u522b\u5b9e\u73b0\u4e8622.52\u548c12.71\u7684\u52a0\u901f\u6bd4\uff0c\u6bd4ParaSCIP\u5feb1.98\u548c2.08\u500d\uff1b\u786e\u5b9a\u6027\u6a21\u5f0f\u4e5f\u5728\u4e0d\u540c\u8fdb\u7a0b\u6570\u548c\u8ba1\u7b97\u96c6\u7fa4\u4e0a\u663e\u8457\u4f18\u4e8eParaSCIP\u3002", "conclusion": "N2N\u6846\u67b6\u5177\u6709\u5f88\u597d\u7684\u901a\u7528\u6027\uff0c\u53ef\u4ee5\u96c6\u6210\u4e0d\u540c\u7684\u6c42\u89e3\u5668\uff0c\u4e3a\u5927\u89c4\u6a21MILP\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5e76\u884c\u6c42\u89e3\u65b9\u6848\u3002"}}
{"id": "2511.18604", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.18604", "abs": "https://arxiv.org/abs/2511.18604", "authors": ["Hannah Lee", "James D. Motes", "Marco Morales", "Nancy M. Amato"], "title": "An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms", "comment": null, "summary": "This study informs the design of future multi-agent pathfinding (MAPF) and multi-robot motion planning (MRMP) algorithms by guiding choices based on constraint classification for constraint-based search algorithms. We categorize constraints as conservative or aggressive and provide insights into their search behavior, focusing specifically on vanilla Conflict-Based Search (CBS) and Conflict-Based Search with Priorities (CBSw/P). Under a hybrid grid-roadmap representation with varying resolution, we observe that aggressive (priority constraint) formulations tend to solve more instances as agent count or resolution increases, whereas conservative (motion constraint) formulations yield stronger solution quality when both succeed. Findings are synthesized in a decision flowchart, aiding users in selecting suitable constraints. Recommendations extend to Multi-Robot Motion Planning (MRMP), emphasizing the importance of considering topological features alongside problem, solution, and representation features. A comprehensive exploration of the study, including raw data and map performance, is available in our public GitHub Repository: https://GitHub.com/hannahjmlee/constraint-mapf-analysis", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7ea6\u675f\u5206\u7c7b\u6307\u5bfc\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u7684\u8bbe\u8ba1\u9009\u62e9\uff0c\u5206\u6790\u4e86\u4fdd\u5b88\u578b\u548c\u6fc0\u8fdb\u578b\u7ea6\u675f\u5728CBS\u7b97\u6cd5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6fc0\u8fdb\u7ea6\u675f\u5728\u89e3\u51b3\u66f4\u591a\u5b9e\u4f8b\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u4fdd\u5b88\u7ea6\u675f\u5728\u89e3\u8d28\u91cf\u4e0a\u66f4\u4f18\u3002", "motivation": "\u4e3a\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u548c\u591a\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u7b97\u6cd5\u63d0\u4f9b\u57fa\u4e8e\u7ea6\u675f\u5206\u7c7b\u7684\u8bbe\u8ba1\u6307\u5bfc\uff0c\u5e2e\u52a9\u7528\u6237\u6839\u636e\u5177\u4f53\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u7ea6\u675f\u7c7b\u578b\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u7f51\u683c-\u8def\u7ebf\u56fe\u8868\u793a\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u5206\u8fa8\u7387\u4e0b\u6bd4\u8f83\u4e86vanilla CBS\u548cCBSw/P\u7b97\u6cd5\u4e2d\u4fdd\u5b88\u578b\uff08\u8fd0\u52a8\u7ea6\u675f\uff09\u548c\u6fc0\u8fdb\u578b\uff08\u4f18\u5148\u7ea7\u7ea6\u675f\uff09\u7684\u8868\u73b0\u3002", "result": "\u968f\u7740\u667a\u80fd\u4f53\u6570\u91cf\u6216\u5206\u8fa8\u7387\u589e\u52a0\uff0c\u6fc0\u8fdb\u7ea6\u675f\u80fd\u89e3\u51b3\u66f4\u591a\u5b9e\u4f8b\uff0c\u800c\u4fdd\u5b88\u7ea6\u675f\u5728\u4e24\u8005\u90fd\u6210\u529f\u65f6\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u89e3\u8d28\u91cf\u3002\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u51b3\u7b56\u6d41\u7a0b\u56fe\u6765\u8f85\u52a9\u7ea6\u675f\u9009\u62e9\u3002", "conclusion": "\u7ea6\u675f\u9009\u62e9\u5e94\u57fa\u4e8e\u5177\u4f53\u9700\u6c42\uff1a\u6fc0\u8fdb\u7ea6\u675f\u9002\u5408\u89e3\u51b3\u66f4\u591a\u95ee\u9898\u5b9e\u4f8b\uff0c\u4fdd\u5b88\u7ea6\u675f\u9002\u5408\u8ffd\u6c42\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\u3002\u5728\u591a\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u4e2d\uff0c\u62d3\u6251\u7279\u5f81\u4e0e\u95ee\u9898\u3001\u89e3\u548c\u8868\u793a\u7279\u5f81\u540c\u7b49\u91cd\u8981\u3002"}}
{"id": "2511.18739", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.18739", "abs": "https://arxiv.org/abs/2511.18739", "authors": ["Kaixiang Yang", "Jiarong Liu", "Yupeng Song", "Shuanghua Yang", "Yujue Zhou"], "title": "A Problem-Oriented Taxonomy of Evaluation Metrics for Time Series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection is widely used in IoT and cyber-physical systems, yet its evaluation remains challenging due to diverse application objectives and heterogeneous metric assumptions. This study introduces a problem-oriented framework that reinterprets existing metrics based on the specific evaluation challenges they are designed to address, rather than their mathematical forms or output structures. We categorize over twenty commonly used metrics into six dimensions: 1) basic accuracy-driven evaluation; 2) timeliness-aware reward mechanisms; 3) tolerance to labeling imprecision; 4) penalties reflecting human-audit cost; 5) robustness against random or inflated scores; and 6) parameter-free comparability for cross-dataset benchmarking. Comprehensive experiments are conducted to examine metric behavior under genuine, random, and oracle detection scenarios. By comparing their resulting score distributions, we quantify each metric's discriminative ability -- its capability to distinguish meaningful detections from random noise. The results show that while most event-level metrics exhibit strong separability, several widely used metrics (e.g., NAB, Point-Adjust) demonstrate limited resistance to random-score inflation. These findings reveal that metric suitability must be inherently task-dependent and aligned with the operational objectives of IoT applications. The proposed framework offers a unified analytical perspective for understanding existing metrics and provides practical guidance for selecting or developing more context-aware, robust, and fair evaluation methodologies for time series anomaly detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u95ee\u9898\u7684\u6846\u67b6\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u768420\u591a\u4e2a\u5e38\u7528\u6307\u6807\u91cd\u65b0\u5206\u7c7b\u4e3a6\u4e2a\u7ef4\u5ea6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u91cf\u5316\u6307\u6807\u7684\u5224\u522b\u80fd\u529b\uff0c\u53d1\u73b0\u67d0\u4e9b\u5e7f\u6cdb\u4f7f\u7528\u7684\u6307\u6807\u5bf9\u968f\u673a\u5206\u6570\u81a8\u80c0\u7684\u62b5\u6297\u529b\u6709\u9650\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u5728\u7269\u8054\u7f51\u548c\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7531\u4e8e\u5e94\u7528\u76ee\u6807\u591a\u6837\u548c\u6307\u6807\u5047\u8bbe\u5f02\u8d28\uff0c\u5176\u8bc4\u4f30\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u91cd\u65b0\u7406\u89e3\u73b0\u6709\u6307\u6807\u4ee5\u89e3\u51b3\u7279\u5b9a\u7684\u8bc4\u4f30\u6311\u6218\u3002", "method": "\u5f15\u5165\u95ee\u9898\u5bfc\u5411\u6846\u67b6\uff0c\u5c06\u6307\u6807\u6309\u8bc4\u4f30\u6311\u6218\u5206\u7c7b\u4e3a6\u4e2a\u7ef4\u5ea6\uff1b\u901a\u8fc7\u771f\u5b9e\u3001\u968f\u673a\u548coracle\u68c0\u6d4b\u573a\u666f\u4e0b\u7684\u7efc\u5408\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u5206\u6570\u5206\u5e03\u4ee5\u91cf\u5316\u6bcf\u4e2a\u6307\u6807\u7684\u5224\u522b\u80fd\u529b\u3002", "result": "\u5927\u591a\u6570\u4e8b\u4ef6\u7ea7\u6307\u6807\u8868\u73b0\u51fa\u5f3a\u53ef\u5206\u6027\uff0c\u4f46\u4e00\u4e9b\u5e7f\u6cdb\u4f7f\u7528\u7684\u6307\u6807\uff08\u5982NAB\u3001Point-Adjust\uff09\u5bf9\u968f\u673a\u5206\u6570\u81a8\u80c0\u7684\u62b5\u6297\u529b\u6709\u9650\uff1b\u6307\u6807\u7684\u9002\u7528\u6027\u5fc5\u987b\u4e0e\u7269\u8054\u7f51\u5e94\u7528\u7684\u64cd\u4f5c\u76ee\u6807\u4e00\u81f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u7406\u89e3\u73b0\u6709\u6307\u6807\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5206\u6790\u89c6\u89d2\uff0c\u5e76\u4e3a\u9009\u62e9\u6216\u5f00\u53d1\u66f4\u5177\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u9c81\u68d2\u548c\u516c\u5e73\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u8bc4\u4f30\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2511.18606", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18606", "abs": "https://arxiv.org/abs/2511.18606", "authors": ["Kensuke Nakamura", "Arun L. Bishop", "Steven Man", "Aaron M. Johnson", "Zachary Manchester", "Andrea Bajcsy"], "title": "How to Train Your Latent Control Barrier Function: Smooth Safety Filtering Under Hard-to-Model Constraints", "comment": "3 figures, 10 tables, 22 pages", "summary": "Latent safety filters extend Hamilton-Jacobi (HJ) reachability to operate on latent state representations and dynamics learned directly from high-dimensional observations, enabling safe visuomotor control under hard-to-model constraints. However, existing methods implement \"least-restrictive\" filtering that discretely switch between nominal and safety policies, potentially undermining the task performance that makes modern visuomotor policies valuable. While reachability value functions can, in principle, be adapted to be control barrier functions (CBFs) for smooth optimization-based filtering, we theoretically and empirically show that current latent-space learning methods produce fundamentally incompatible value functions. We identify two sources of incompatibility: First, in HJ reachability, failures are encoded via a \"margin function\" in latent space, whose sign indicates whether or not a latent is in the constraint set. However, representing the margin function as a classifier yields saturated value functions that exhibit discontinuous jumps. We prove that the value function's Lipschitz constant scales linearly with the margin function's Lipschitz constant, revealing that smooth CBFs require smooth margins. Second, reinforcement learning (RL) approximations trained solely on safety policy data yield inaccurate value estimates for nominal policy actions, precisely where CBF filtering needs them. We propose the LatentCBF, which addresses both challenges through gradient penalties that lead to smooth margin functions without additional labeling, and a value-training procedure that mixes data from both nominal and safety policy distributions. Experiments on simulated benchmarks and hardware with a vision-based manipulation policy demonstrate that LatentCBF enables smooth safety filtering while doubling the task-completion rate over prior switching methods.", "AI": {"tldr": "LatentCBF\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6f5c\u5728\u7a7a\u95f4\u5b89\u5168\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5207\u6362\u7b56\u7565\u65f6\u7834\u574f\u4efb\u52a1\u6027\u80fd\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u68af\u5ea6\u60e9\u7f5a\u5b9e\u73b0\u5e73\u6ed1\u7684\u8fb9\u9645\u51fd\u6570\uff0c\u5e76\u6df7\u5408\u540d\u4e49\u7b56\u7565\u548c\u5b89\u5168\u7b56\u7565\u6570\u636e\u8bad\u7ec3\u503c\u51fd\u6570\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u6f5c\u5728\u5b89\u5168\u6ee4\u6ce2\u5668\u91c7\u7528\"\u6700\u5c0f\u9650\u5236\"\u6ee4\u6ce2\uff0c\u5728\u540d\u4e49\u7b56\u7565\u548c\u5b89\u5168\u7b56\u7565\u4e4b\u95f4\u79bb\u6563\u5207\u6362\uff0c\u8fd9\u4f1a\u7834\u574f\u73b0\u4ee3\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u7684\u4efb\u52a1\u6027\u80fd\u3002\u867d\u7136\u53ef\u8fbe\u6027\u503c\u51fd\u6570\u7406\u8bba\u4e0a\u53ef\u4ee5\u9002\u914d\u4e3a\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u8fdb\u884c\u5e73\u6ed1\u4f18\u5316\u6ee4\u6ce2\uff0c\u4f46\u5f53\u524d\u7684\u6f5c\u5728\u7a7a\u95f4\u5b66\u4e60\u65b9\u6cd5\u4ea7\u751f\u4e0d\u517c\u5bb9\u7684\u503c\u51fd\u6570\u3002", "method": "\u63d0\u51faLatentCBF\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u68af\u5ea6\u60e9\u7f5a\u83b7\u5f97\u5e73\u6ed1\u7684\u8fb9\u9645\u51fd\u6570\uff0c\u65e0\u9700\u989d\u5916\u6807\u6ce8\uff1b2\uff09\u6df7\u5408\u540d\u4e49\u7b56\u7565\u548c\u5b89\u5168\u7b56\u7565\u5206\u5e03\u7684\u6570\u636e\u8fdb\u884c\u503c\u51fd\u6570\u8bad\u7ec3\u3002\u89e3\u51b3\u4e86\u8fb9\u9645\u51fd\u6570\u9971\u548c\u5bfc\u81f4\u7684\u4e0d\u8fde\u7eed\u8df3\u8dc3\u95ee\u9898\uff0c\u4ee5\u53ca\u4ec5\u7528\u5b89\u5168\u7b56\u7565\u6570\u636e\u8bad\u7ec3\u5bfc\u81f4\u7684\u540d\u4e49\u7b56\u7565\u52a8\u4f5c\u503c\u4f30\u8ba1\u4e0d\u51c6\u786e\u95ee\u9898\u3002", "result": "\u5728\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u548c\u786c\u4ef6\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528\u57fa\u4e8e\u89c6\u89c9\u7684\u64cd\u7eb5\u7b56\u7565\uff0cLatentCBF\u5b9e\u73b0\u4e86\u5e73\u6ed1\u7684\u5b89\u5168\u6ee4\u6ce2\uff0c\u540c\u65f6\u5c06\u4efb\u52a1\u5b8c\u6210\u7387\u6bd4\u5148\u524d\u7684\u5207\u6362\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4e00\u500d\u3002", "conclusion": "LatentCBF\u6210\u529f\u89e3\u51b3\u4e86\u6f5c\u5728\u7a7a\u95f4\u5b89\u5168\u6ee4\u6ce2\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u5e73\u6ed1\u7684\u8fb9\u9645\u51fd\u6570\u548c\u6df7\u5408\u6570\u636e\u8bad\u7ec3\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u7ea6\u675f\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.18760", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2511.18760", "abs": "https://arxiv.org/abs/2511.18760", "authors": ["Azim Ospanov", "Zijin Feng", "Jiacheng Sun", "Haoli Bai", "Xin Shen", "Farzan Farnia"], "title": "HERMES: Towards Efficient and Verifiable Mathematical Reasoning in LLMs", "comment": null, "summary": "Informal mathematics has been central to modern large language model (LLM) reasoning, offering flexibility and enabling efficient construction of arguments. However, purely informal reasoning is prone to logical gaps and subtle errors that are difficult to detect and correct. In contrast, formal theorem proving provides rigorous, verifiable mathematical reasoning, where each inference step is checked by a trusted compiler in systems such as Lean, but lacks the exploratory freedom of informal problem solving. This mismatch leaves current LLM-based math agents without a principled way to combine the strengths of both paradigms. In this work, we introduce Hermes, the first tool-assisted agent that explicitly interleaves informal reasoning with formally verified proof steps in Lean. The framework performs intermediate formal checking to prevent reasoning drift and employs a memory module that maintains proof continuity across long, multi-step reasoning chains, enabling both exploration and verification within a single workflow. We evaluate Hermes on four challenging mathematical reasoning benchmarks using LLMs of varying parameter scales, from small models to state-of-the-art systems. Across all settings, Hermes reliably improves the reasoning accuracy of base models while substantially reducing token usage and computational cost compared to reward-based approaches. On difficult datasets such as AIME'25, Hermes achieves up to a 67% accuracy improvement while using 80% fewer total inference FLOPs. The implementation and codebase are publicly available at https://github.com/aziksh-ospanov/HERMES.", "AI": {"tldr": "Hermes\u662f\u9996\u4e2a\u5c06\u975e\u6b63\u5f0f\u63a8\u7406\u4e0eLean\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6b65\u9aa4\u4ea4\u7ec7\u7684\u5de5\u5177\u8f85\u52a9\u4ee3\u7406\uff0c\u901a\u8fc7\u4e2d\u95f4\u5f62\u5f0f\u5316\u68c0\u67e5\u9632\u6b62\u63a8\u7406\u6f02\u79fb\uff0c\u5728\u4fdd\u6301\u63a2\u7d22\u6027\u7684\u540c\u65f6\u786e\u4fdd\u9a8c\u8bc1\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u6570\u5b66\u4ee3\u7406\u7f3a\u4e4f\u7ed3\u5408\u975e\u6b63\u5f0f\u63a8\u7406\u7075\u6d3b\u6027\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\u4e25\u8c28\u6027\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u975e\u6b63\u5f0f\u63a8\u7406\u6613\u51fa\u73b0\u903b\u8f91\u6f0f\u6d1e\uff0c\u800c\u5f62\u5f0f\u5316\u8bc1\u660e\u7f3a\u4e4f\u63a2\u7d22\u81ea\u7531\u3002", "method": "\u5f00\u53d1Hermes\u6846\u67b6\uff0c\u5728Lean\u4e2d\u4ea4\u7ec7\u975e\u6b63\u5f0f\u63a8\u7406\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6b65\u9aa4\uff0c\u4f7f\u7528\u4e2d\u95f4\u5f62\u5f0f\u5316\u68c0\u67e5\u9632\u6b62\u63a8\u7406\u6f02\u79fb\uff0c\u5e76\u91c7\u7528\u5185\u5b58\u6a21\u5757\u7ef4\u62a4\u957f\u63a8\u7406\u94fe\u7684\u8fde\u7eed\u6027\u3002", "result": "\u5728\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHermes\u53ef\u9760\u63d0\u5347\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11token\u4f7f\u7528\u548c\u8ba1\u7b97\u6210\u672c\u3002\u5728AIME'25\u7b49\u56f0\u96be\u6570\u636e\u96c6\u4e0a\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe67%\uff0c\u603b\u63a8\u7406FLOPs\u51cf\u5c1180%\u3002", "conclusion": "Hermes\u6210\u529f\u5b9e\u73b0\u4e86\u975e\u6b63\u5f0f\u63a8\u7406\u4e0e\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7ed3\u5408\uff0c\u4e3aLLM\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u65e2\u80fd\u63a2\u7d22\u53c8\u80fd\u9a8c\u8bc1\u7684\u5355\u4e00\u5de5\u4f5c\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2511.18617", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18617", "abs": "https://arxiv.org/abs/2511.18617", "authors": ["Litian Gong", "Fatemeh Bahrani", "Yutai Zhou", "Amin Banayeeanzade", "Jiachen Li", "Erdem Biyik"], "title": "AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations", "comment": "8 pages, 6 figures. Code and datasets available at http://autofocus-il.github.io/", "summary": "AutoFocus-IL is a simple yet effective method to improve data efficiency and generalization in visual imitation learning by guiding policies to attend to task-relevant features rather than distractors and spurious correlations. Although saliency regularization has emerged as a promising way to achieve this, existing approaches typically require costly supervision such as human gaze data or manual saliency annotations. In contrast, AutoFocus-IL leverages vision-language models (VLMs) to automatically identify and track key objects in demonstrations, generating temporal saliency maps that highlight causal visual signals while suppressing distractors. These maps are then used to regularize behavior cloning policies, yielding stronger alignment between visual attention and task-relevant cues. Experiments in both the CARLA simulator and real-robot manipulation tasks demonstrate that AutoFocus-IL not only outperforms standard behavior cloning but also surpasses state-of-the-art baselines that assume privileged access to human supervision, such as gaze data. Code, datasets, and trained policy videos are available at https://AutoFocus-IL.github.io/.", "AI": {"tldr": "AutoFocus-IL\u662f\u4e00\u79cd\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u65f6\u95f4\u663e\u8457\u6027\u56fe\u6765\u6539\u8fdb\u89c6\u89c9\u6a21\u4eff\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u63d0\u5347\u6570\u636e\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u4eba\u5de5\u76d1\u7763\uff08\u5982\u4eba\u7c7b\u6ce8\u89c6\u6570\u636e\u6216\u624b\u52a8\u663e\u8457\u6027\u6807\u6ce8\uff09\uff0c\u800cAutoFocus-IL\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u65b9\u5f0f\u5b9e\u73b0\u7c7b\u4f3c\u6548\u679c\uff0c\u964d\u4f4e\u76d1\u7763\u6210\u672c\u3002", "method": "\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc6\u522b\u548c\u8ddf\u8e2a\u6f14\u793a\u4e2d\u7684\u5173\u952e\u7269\u4f53\uff0c\u751f\u6210\u65f6\u95f4\u663e\u8457\u6027\u56fe\u6765\u7a81\u51fa\u56e0\u679c\u89c6\u89c9\u4fe1\u53f7\u5e76\u6291\u5236\u5e72\u6270\u56e0\u7d20\uff0c\u7136\u540e\u7528\u8fd9\u4e9b\u56fe\u6765\u6b63\u5219\u5316\u884c\u4e3a\u514b\u9686\u7b56\u7565\u3002", "result": "\u5728CARLA\u6a21\u62df\u5668\u548c\u771f\u5b9e\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAutoFocus-IL\u4e0d\u4ec5\u4f18\u4e8e\u6807\u51c6\u884c\u4e3a\u514b\u9686\uff0c\u8fd8\u8d85\u8fc7\u4e86\u9700\u8981\u4eba\u7c7b\u76d1\u7763\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "AutoFocus-IL\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u89c6\u89c9\u6a21\u4eff\u5b66\u4e60\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.18793", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18793", "abs": "https://arxiv.org/abs/2511.18793", "authors": ["Yejing Wang", "Shengyu Zhou", "Jinyu Lu", "Ziwei Liu", "Langming Liu", "Maolin Wang", "Wenlin Zhang", "Feng Li", "Wenbo Su", "Pengjie Wang", "Jian Xu", "Xiangyu Zhao"], "title": "NEZHA: A Zero-sacrifice and Hyperspeed Decoding Architecture for Generative Recommendations", "comment": null, "summary": "Generative Recommendation (GR), powered by Large Language Models (LLMs), represents a promising new paradigm for industrial recommender systems. However, their practical application is severely hindered by high inference latency, which makes them infeasible for high-throughput, real-time services and limits their overall business impact. While Speculative Decoding (SD) has been proposed to accelerate the autoregressive generation process, existing implementations introduce new bottlenecks: they typically require separate draft models and model-based verifiers, requiring additional training and increasing the latency overhead. In this paper, we address these challenges with NEZHA, a novel architecture that achieves hyperspeed decoding for GR systems without sacrificing recommendation quality. Specifically, NEZHA integrates a nimble autoregressive draft head directly into the primary model, enabling efficient self-drafting. This design, combined with a specialized input prompt structure, preserves the integrity of sequence-to-sequence generation. Furthermore, to tackle the critical problem of hallucination, a major source of performance degradation, we introduce an efficient, model-free verifier based on a hash set. We demonstrate the effectiveness of NEZHA through extensive experiments on public datasets and have successfully deployed the system on Taobao since October 2025, driving the billion-level advertising revenue and serving hundreds of millions of daily active users.", "AI": {"tldr": "NEZHA\u662f\u4e00\u79cd\u7528\u4e8e\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u7684\u9ad8\u901f\u89e3\u7801\u67b6\u6784\uff0c\u901a\u8fc7\u96c6\u6210\u8f7b\u91cf\u7ea7\u81ea\u56de\u5f52\u8349\u7a3f\u5934\u548c\u57fa\u4e8e\u54c8\u5e0c\u96c6\u7684\u9a8c\u8bc1\u5668\uff0c\u5728\u4e0d\u727a\u7272\u63a8\u8350\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u9ad8\u63a8\u7406\u5ef6\u8fdf\u7684\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5b9e\u65f6\u670d\u52a1\u4e2d\u7684\u53ef\u884c\u6027\u3002\u73b0\u6709\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u9700\u8981\u5355\u72ec\u7684\u8349\u7a3f\u6a21\u578b\u548c\u6a21\u578b\u9a8c\u8bc1\u5668\uff0c\u589e\u52a0\u4e86\u8bad\u7ec3\u6210\u672c\u548c\u5ef6\u8fdf\u5f00\u9500\u3002", "method": "NEZHA\u5c06\u8f7b\u91cf\u7ea7\u81ea\u56de\u5f52\u8349\u7a3f\u5934\u96c6\u6210\u5230\u4e3b\u6a21\u578b\u4e2d\u5b9e\u73b0\u81ea\u8349\u7a3f\u751f\u6210\uff0c\u7ed3\u5408\u7279\u6b8a\u7684\u8f93\u5165\u63d0\u793a\u7ed3\u6784\u4fdd\u6301\u5e8f\u5217\u5230\u5e8f\u5217\u751f\u6210\u7684\u5b8c\u6574\u6027\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u54c8\u5e0c\u96c6\u7684\u65e0\u6a21\u578b\u9a8c\u8bc1\u5668\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86NEZHA\u7684\u6709\u6548\u6027\uff0c\u8be5\u7cfb\u7edf\u5df2\u4e8e2025\u5e7410\u6708\u5728\u6dd8\u5b9d\u6210\u529f\u90e8\u7f72\uff0c\u652f\u6491\u4e86\u6570\u5341\u4ebf\u7ea7\u522b\u7684\u5e7f\u544a\u6536\u5165\uff0c\u670d\u52a1\u6570\u4ebf\u65e5\u6d3b\u8dc3\u7528\u6237\u3002", "conclusion": "NEZHA\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u9ad8\u901f\u89e3\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5ef6\u8fdf\u74f6\u9888\u95ee\u9898\uff0c\u5177\u6709\u91cd\u8981\u7684\u5546\u4e1a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.18683", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18683", "abs": "https://arxiv.org/abs/2511.18683", "authors": ["Yinan Dong", "Ziyu Xu", "Tsimafei Lazouski", "Sangli Teng", "Maani Ghaffari"], "title": "Online Learning-Enhanced Lie Algebraic MPC for Robust Trajectory Tracking of Autonomous Surface Vehicles", "comment": null, "summary": "Autonomous surface vehicles (ASVs) are easily influenced by environmental disturbances such as wind and waves, making accurate trajectory tracking a persistent challenge in dynamic marine conditions. In this paper, we propose an efficient controller for trajectory tracking of marine vehicles under unknown disturbances by combining a convex error-state MPC on the Lie group with an online learning module to compensate for these disturbances in real time. This design enables adaptive and robust control while maintaining computational efficiency. Extensive evaluations in numerical simulations, the Virtual RobotX (VRX) simulator, and real-world field experiments demonstrate that our method achieves superior tracking accuracy under various disturbance scenarios compared with existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u674e\u7fa4\u4e0a\u51f8\u8bef\u5dee\u72b6\u6001MPC\u548c\u5728\u7ebf\u5b66\u4e60\u6a21\u5757\u7684\u9ad8\u6548\u63a7\u5236\u5668\uff0c\u7528\u4e8e\u6d77\u6d0b\u8f66\u8f86\u5728\u672a\u77e5\u6270\u52a8\u4e0b\u7684\u8f68\u8ff9\u8ddf\u8e2a", "motivation": "\u81ea\u4e3b\u6c34\u9762\u8f66\u8f86(ASVs)\u5bb9\u6613\u53d7\u5230\u98ce\u6d6a\u7b49\u73af\u5883\u6270\u52a8\u5f71\u54cd\uff0c\u5728\u52a8\u6001\u6d77\u6d0b\u6761\u4ef6\u4e0b\u5b9e\u73b0\u7cbe\u786e\u8f68\u8ff9\u8ddf\u8e2a\u662f\u4e00\u4e2a\u6301\u7eed\u6311\u6218", "method": "\u5c06\u674e\u7fa4\u4e0a\u7684\u51f8\u8bef\u5dee\u72b6\u6001\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u4e0e\u5728\u7ebf\u5b66\u4e60\u6a21\u5757\u76f8\u7ed3\u5408\uff0c\u5b9e\u65f6\u8865\u507f\u672a\u77e5\u6270\u52a8", "result": "\u5728\u6570\u503c\u6a21\u62df\u3001VRX\u6a21\u62df\u5668\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u6270\u52a8\u573a\u666f\u4e0b\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f18\u8d8a\u7684\u8ddf\u8e2a\u7cbe\u5ea6", "conclusion": "\u8be5\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u548c\u9c81\u68d2\u63a7\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387"}}
{"id": "2511.18845", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18845", "abs": "https://arxiv.org/abs/2511.18845", "authors": ["Changxin Huang", "Lv Tang", "Zhaohuan Zhan", "Lisha Yu", "Runhao Zeng", "Zun Liu", "Zhengjie Wang", "Jianqiang Li"], "title": "UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model", "comment": null, "summary": "Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instruction--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreover, existing reasoning modules are optimized separately from navigation policies, leading to incompatibility and potential conflicts in optimization objectives. To tackle these challenges, we introduce UNeMo, a novel framework designed for the collaborative optimization of visual state reasoning and navigational decision-making. It introduces a Multimodal World Model (MWM) that takes visual features, language instructions, and navigational actions as inputs to jointly predict subsequent visual states, enabling cross-modal reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM collaborates with navigation policies: the first layer generates actions using current vision-and-language features; MWM then infers post-action visual states to guide the second layer's fine-grained decisions. This forms a dynamic bidirectional promotion mechanism where MWM reasoning optimizes navigation policies, while policy decisions feedback to improve MWM's reasoning accuracy. Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating its effectiveness.", "AI": {"tldr": "UNeMo\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b\u548c\u5206\u5c42\u9884\u6d4b-\u53cd\u9988\u673a\u5236\uff0c\u534f\u540c\u4f18\u5316\u89c6\u89c9\u72b6\u6001\u63a8\u7406\u548c\u5bfc\u822a\u51b3\u7b56\uff0c\u5728\u672a\u89c1\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5bfc\u822a\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bfc\u822a\u65b9\u6cd5\u4ec5\u9650\u4e8e\u8bed\u8a00\u6a21\u6001\u63a8\u7406\uff0c\u7f3a\u4e4f\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u63a8\u7406\u6a21\u5757\u4e0e\u5bfc\u822a\u7b56\u7565\u5206\u79bb\u4f18\u5316\u5bfc\u81f4\u76ee\u6807\u51b2\u7a81\u3002", "method": "\u5f15\u5165\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b(MWM)\u8fdb\u884c\u8de8\u6a21\u6001\u63a8\u7406\uff0c\u7ed3\u5408\u5206\u5c42\u9884\u6d4b-\u53cd\u9988\u673a\u5236\uff1a\u7b2c\u4e00\u5c42\u57fa\u4e8e\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u7279\u5f81\u751f\u6210\u52a8\u4f5c\uff0cMWM\u63a8\u65ad\u52a8\u4f5c\u540e\u89c6\u89c9\u72b6\u6001\u6307\u5bfc\u7b2c\u4e8c\u5c42\u7ec6\u7c92\u5ea6\u51b3\u7b56\u3002", "result": "\u5728R2R\u548cREVERIE\u6570\u636e\u96c6\u4e0a\uff0cUNeMo\u5728\u672a\u89c1\u573a\u666f\u4e2d\u7684\u5bfc\u822a\u7cbe\u5ea6\u5206\u522b\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u9ad8\u51fa2.1%\u548c0.7%\u3002", "conclusion": "UNeMo\u901a\u8fc7\u52a8\u6001\u53cc\u5411\u4fc3\u8fdb\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u89c6\u89c9\u63a8\u7406\u4e0e\u5bfc\u822a\u51b3\u7b56\u7684\u534f\u540c\u4f18\u5316\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.18694", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18694", "abs": "https://arxiv.org/abs/2511.18694", "authors": ["Shuo Wen", "Edwin Meriaux", "Mariana Sosa Guzm\u00e1n", "Zhizun Wang", "Junming Shi", "Gregory Dudek"], "title": "Stable Multi-Drone GNSS Tracking System for Marine Robots", "comment": null, "summary": "Accurate localization is essential for marine robotics, yet Global Navigation Satellite System (GNSS) signals are unreliable or unavailable even at a very short distance below the water surface. Traditional alternatives, such as inertial navigation, Doppler Velocity Loggers (DVL), SLAM, and acoustic methods, suffer from error accumulation, high computational demands, or infrastructure dependence. In this work, we present a scalable multi-drone GNSS-based tracking system for surface and near-surface marine robots. Our approach combines efficient visual detection, lightweight multi-object tracking, GNSS-based triangulation, and a confidence-weighted Extended Kalman Filter (EKF) to provide stable GNSS estimation in real time. We further introduce a cross-drone tracking ID alignment algorithm that enforces global consistency across views, enabling robust multi-robot tracking with redundant aerial coverage. We validate our system in diversified complex settings to show the scalability and robustness of the proposed algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u65e0\u4eba\u673aGNSS\u7684\u6d77\u6d0b\u673a\u5668\u4eba\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9\u68c0\u6d4b\u3001\u591a\u76ee\u6807\u8ddf\u8e2a\u3001\u4e09\u89d2\u5b9a\u4f4d\u548c\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5b9e\u73b0\u5b9e\u65f6\u7a33\u5b9a\u7684GNSS\u4f30\u8ba1\u3002", "motivation": "\u89e3\u51b3\u6c34\u4e0b\u73af\u5883\u4e2dGNSS\u4fe1\u53f7\u4e0d\u53ef\u9760\u6216\u4e0d\u53ef\u7528\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u8bef\u5dee\u7d2f\u79ef\u3001\u8ba1\u7b97\u91cf\u5927\u6216\u4f9d\u8d56\u57fa\u7840\u8bbe\u65bd\u7b49\u5c40\u9650\u6027\u3002", "method": "\u7ed3\u5408\u9ad8\u6548\u89c6\u89c9\u68c0\u6d4b\u3001\u8f7b\u91cf\u7ea7\u591a\u76ee\u6807\u8ddf\u8e2a\u3001GNSS\u4e09\u89d2\u5b9a\u4f4d\u548c\u7f6e\u4fe1\u5ea6\u52a0\u6743\u7684\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u5e76\u5f15\u5165\u8de8\u65e0\u4eba\u673a\u8ddf\u8e2aID\u5bf9\u9f50\u7b97\u6cd5\u786e\u4fdd\u5168\u5c40\u4e00\u81f4\u6027\u3002", "result": "\u5728\u591a\u6837\u5316\u590d\u6742\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u80fd\u591f\u4e3a\u6c34\u9762\u548c\u8fd1\u6c34\u9762\u6d77\u6d0b\u673a\u5668\u4eba\u63d0\u4f9b\u7a33\u5b9a\u53ef\u9760\u7684\u5b9e\u65f6\u5b9a\u4f4d\u8ddf\u8e2a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18702", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18702", "abs": "https://arxiv.org/abs/2511.18702", "authors": ["Xueyan Oh", "Leonard Loh", "Shaohui Foong", "Zhong Bao Andy Koh", "Kow Leong Ng", "Poh Kang Tan", "Pei Lin Pearlin Toh", "U-Xuan Tan"], "title": "CNN-Based Camera Pose Estimation and Localisation of Scan Images for Aircraft Visual Inspection", "comment": "12 pages, 12 figures", "summary": "General Visual Inspection is a manual inspection process regularly used to detect and localise obvious damage on the exterior of commercial aircraft. There has been increasing demand to perform this process at the boarding gate to minimise the downtime of the aircraft and automating this process is desired to reduce the reliance on human labour. Automating this typically requires estimating a camera's pose with respect to the aircraft for initialisation but most existing localisation methods require infrastructure, which is very challenging in uncontrolled outdoor environments and within the limited turnover time (approximately 2 hours) on an airport tarmac. Additionally, many airlines and airports do not allow contact with the aircraft's surface or using UAVs for inspection between flights, and restrict access to commercial aircraft. Hence, this paper proposes an on-site method that is infrastructure-free and easy to deploy for estimating a pan-tilt-zoom camera's pose and localising scan images. This method initialises using the same pan-tilt-zoom camera used for the inspection task by utilising a Deep Convolutional Neural Network fine-tuned on only synthetic images to predict its own pose. We apply domain randomisation to generate the dataset for fine-tuning the network and modify its loss function by leveraging aircraft geometry to improve accuracy. We also propose a workflow for initialisation, scan path planning, and precise localisation of images captured from a pan-tilt-zoom camera. We evaluate and demonstrate our approach through experiments with real aircraft, achieving root-mean-square camera pose estimation errors of less than 0.24 m and 2 degrees for all real scenes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u57fa\u7840\u8bbe\u65bd\u7684\u98de\u673a\u89c6\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528PTZ\u76f8\u673a\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u4f30\u8ba1\u81ea\u8eab\u59ff\u6001\uff0c\u5b9e\u73b0\u98de\u673a\u5916\u89c2\u635f\u4f24\u68c0\u6d4b\u7684\u81ea\u52a8\u5316\u521d\u59cb\u5316\u3002", "motivation": "\u4f20\u7edf\u98de\u673a\u5916\u89c2\u68c0\u6d4b\u4f9d\u8d56\u4eba\u5de5\uff0c\u5728\u767b\u673a\u53e3\u8fdb\u884c\u68c0\u6d4b\u53ef\u51cf\u5c11\u98de\u673a\u505c\u98de\u65f6\u95f4\uff0c\u4f46\u73b0\u6709\u5b9a\u4f4d\u65b9\u6cd5\u9700\u8981\u57fa\u7840\u8bbe\u65bd\uff0c\u5728\u6237\u5916\u73af\u5883\u548c\u6709\u9650\u65f6\u95f4\u5185\u96be\u4ee5\u90e8\u7f72\u3002", "method": "\u4f7f\u7528PTZ\u76f8\u673a\uff0c\u901a\u8fc7\u57fa\u4e8e\u5408\u6210\u56fe\u50cf\u5fae\u8c03\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u76f8\u673a\u59ff\u6001\uff0c\u5e94\u7528\u9886\u57df\u968f\u673a\u5316\u751f\u6210\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u98de\u673a\u51e0\u4f55\u6539\u8fdb\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u771f\u5b9e\u98de\u673a\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u673a\u59ff\u6001\u4f30\u8ba1\u7684\u5747\u65b9\u6839\u8bef\u5dee\u5c0f\u4e8e0.24\u7c73\u548c2\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u57fa\u7840\u8bbe\u65bd\u514d\u8d39\u7684\u98de\u673a\u68c0\u6d4b\u521d\u59cb\u5316\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\uff0c\u4e3a\u81ea\u52a8\u5316\u89c6\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18926", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18926", "abs": "https://arxiv.org/abs/2511.18926", "authors": ["Haifeng Jing", "Yujie Hou", "Junfei Liu", "Rui Xie", "alan Xu", "Jinlong Ma", "Qichun Deng"], "title": "MoodBench 1.0: An Evaluation Benchmark for Emotional Companionship Dialogue Systems", "comment": "26 pages, 7 figures", "summary": "With the rapid development of Large Language Models, dialogue systems are shifting from information tools to emotional companions, heralding the era of Emotional Companionship Dialogue Systems (ECDs) that provide personalized emotional support for users. However, the field lacks clear definitions and systematic evaluation standards for ECDs. To address this, we first propose a definition of ECDs with formal descriptions. Then, based on this theory and the design principle of \"Ability Layer-Task Layer (three level)-Data Layer-Method Layer\", we design and implement the first ECD evaluation benchmark - MoodBench 1.0. Through extensive evaluations of 30 mainstream models, we demonstrate that MoodBench 1.0 has excellent discriminant validity and can effectively quantify the differences in emotional companionship abilities among models. Furthermore, the results reveal current models' shortcomings in deep emotional companionship, guiding future technological optimization and significantly aiding developers in enhancing ECDs' user experience.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u60c5\u611f\u966a\u4f34\u5bf9\u8bdd\u7cfb\u7edf(ECDs)\u7684\u6b63\u5f0f\u5b9a\u4e49\uff0c\u5e76\u57fa\u4e8e\"\u80fd\u529b\u5c42-\u4efb\u52a1\u5c42-\u6570\u636e\u5c42-\u65b9\u6cd5\u5c42\"\u539f\u5219\u8bbe\u8ba1\u4e86\u9996\u4e2aECDs\u8bc4\u4f30\u57fa\u51c6MoodBench 1.0\uff0c\u901a\u8fc7\u8bc4\u4f3030\u4e2a\u4e3b\u6d41\u6a21\u578b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u5bf9\u8bdd\u7cfb\u7edf\u6b63\u4ece\u4fe1\u606f\u5de5\u5177\u8f6c\u5411\u60c5\u611f\u4f34\u4fa3\uff0c\u4f46ECDs\u9886\u57df\u7f3a\u4e4f\u660e\u786e\u5b9a\u4e49\u548c\u7cfb\u7edf\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u57fa\u4e8e\u7406\u8bba\u6846\u67b6\u548c\"\u80fd\u529b\u5c42-\u4efb\u52a1\u5c42-\u6570\u636e\u5c42-\u65b9\u6cd5\u5c42\"\u8bbe\u8ba1\u539f\u5219\uff0c\u6784\u5efa\u4e86MoodBench 1.0\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "MoodBench 1.0\u5177\u6709\u4f18\u79c0\u7684\u5224\u522b\u6548\u5ea6\uff0c\u80fd\u6709\u6548\u91cf\u5316\u6a21\u578b\u7684\u60c5\u611f\u966a\u4f34\u80fd\u529b\u5dee\u5f02\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u6df1\u5c42\u60c5\u611f\u966a\u4f34\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3aECDs\u7684\u6280\u672f\u4f18\u5316\u548c\u7528\u6237\u4f53\u9a8c\u63d0\u5347\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\uff0c\u5c06\u663e\u8457\u5e2e\u52a9\u5f00\u53d1\u8005\u6539\u8fdb\u60c5\u611f\u966a\u4f34\u5bf9\u8bdd\u7cfb\u7edf\u3002"}}
{"id": "2511.18703", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18703", "abs": "https://arxiv.org/abs/2511.18703", "authors": ["Ardalan Tajbakhsh", "Augustinos Saravanos", "James Zhu", "Evangelos A. Theodorou", "Lorenz T. Biegler", "Aaron M. Johnson"], "title": "Asynchronous Distributed Multi-Robot Motion Planning Under Imperfect Communication", "comment": "9 pages, 5 figures", "summary": "This paper addresses the challenge of coordinating multi-robot systems under realistic communication delays using distributed optimization. We focus on consensus ADMM as a scalable framework for generating collision-free, dynamically feasible motion plans in both trajectory optimization and receding-horizon control settings. In practice, however, these algorithms are sensitive to penalty tuning or adaptation schemes (e.g. residual balancing and adaptive parameter heuristics) that do not explicitly consider delays. To address this, we introduce a Delay-Aware ADMM (DA-ADMM) variant that adapts penalty parameters based on real-time delay statistics, allowing agents to down-weight stale information and prioritize recent updates during consensus and dual updates. Through extensive simulations in 2D and 3D environments with double-integrator, Dubins-car, and drone dynamics, we show that DA-ADMM significantly improves robustness, success rate, and solution quality compared to fixed-parameter, residual-balancing, and fixed-constraint baselines. Our results highlight that performance degradation is not solely determined by delay length or frequency, but by the optimizer's ability to contextually reason over delayed information. The proposed DA-ADMM achieves consistently better coordination performance across a wide range of delay conditions, offering a principled and efficient mechanism for resilient multi-robot motion planning under imperfect communication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5ef6\u8fdf\u611f\u77e5\u7684ADMM\u53d8\u4f53(DA-ADMM)\uff0c\u901a\u8fc7\u57fa\u4e8e\u5b9e\u65f6\u5ef6\u8fdf\u7edf\u8ba1\u8c03\u6574\u60e9\u7f5a\u53c2\u6570\uff0c\u5728\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u5904\u7406\u901a\u4fe1\u5ef6\u8fdf\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8fd0\u52a8\u89c4\u5212\u7684\u9c81\u68d2\u6027\u548c\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u73b0\u5b9e\u901a\u4fe1\u5ef6\u8fdf\u4e0b\u7684\u534f\u8c03\u6311\u6218\uff0c\u4f20\u7edf\u5171\u8bc6ADMM\u7b97\u6cd5\u5bf9\u60e9\u7f5a\u53c2\u6570\u8c03\u6574\u654f\u611f\uff0c\u4e14\u73b0\u6709\u81ea\u9002\u5e94\u65b9\u6cd5\u672a\u660e\u786e\u8003\u8651\u5ef6\u8fdf\u56e0\u7d20\u3002", "method": "\u5f15\u5165DA-ADMM\u53d8\u4f53\uff0c\u57fa\u4e8e\u5b9e\u65f6\u5ef6\u8fdf\u7edf\u8ba1\u8c03\u6574\u60e9\u7f5a\u53c2\u6570\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u964d\u4f4e\u9648\u65e7\u4fe1\u606f\u7684\u6743\u91cd\uff0c\u5728\u5171\u8bc6\u548c\u53cc\u91cd\u66f4\u65b0\u8fc7\u7a0b\u4e2d\u4f18\u5148\u5904\u7406\u6700\u65b0\u66f4\u65b0\u3002", "result": "\u57282D\u548c3D\u73af\u5883\u4e2d\u901a\u8fc7\u53cc\u79ef\u5206\u5668\u3001Dubins-car\u548c\u65e0\u4eba\u673a\u52a8\u529b\u5b66\u7684\u5e7f\u6cdb\u4eff\u771f\u8868\u660e\uff0cDA-ADMM\u76f8\u6bd4\u56fa\u5b9a\u53c2\u6570\u3001\u6b8b\u5dee\u5e73\u8861\u548c\u56fa\u5b9a\u7ea6\u675f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u3001\u6210\u529f\u7387\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002", "conclusion": "\u6027\u80fd\u4e0b\u964d\u4e0d\u4ec5\u7531\u5ef6\u8fdf\u957f\u5ea6\u6216\u9891\u7387\u51b3\u5b9a\uff0c\u8fd8\u53d6\u51b3\u4e8e\u4f18\u5316\u5668\u5bf9\u5ef6\u8fdf\u4fe1\u606f\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u3002DA-ADMM\u5728\u5404\u79cd\u5ef6\u8fdf\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u4e00\u81f4\u66f4\u597d\u7684\u534f\u8c03\u6027\u80fd\uff0c\u4e3a\u4e0d\u5b8c\u7f8e\u901a\u4fe1\u4e0b\u7684\u5f39\u6027\u591a\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u9ad8\u6548\u673a\u5236\u3002"}}
{"id": "2511.18955", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18955", "abs": "https://arxiv.org/abs/2511.18955", "authors": ["Wouter W. L. Nuijten", "Mykola Lukashchuk"], "title": "Active Inference is a Subtype of Variational Inference", "comment": "Accepted to the EIML Workshop 2025 at EurIPS (non-archival)", "summary": "Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u7528\u4e8e\u5728\u56e0\u5b50\u72b6\u6001MDP\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u4e3b\u52a8\u63a8\u7406\uff0c\u89e3\u51b3\u4e86EFE\u6700\u5c0f\u5316\u7684\u8ba1\u7b97\u590d\u6742\u6027\u9650\u5236\u3002", "motivation": "\u81ea\u52a8\u5316\u51b3\u7b56\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u9700\u8981\u5e73\u8861\u5229\u7528\u548c\u63a2\u7d22\u3002\u7ecf\u5178\u65b9\u6cd5\u4f7f\u7528\u542f\u53d1\u5f0f\u5206\u522b\u5904\u7406\u8fd9\u4e24\u8005\uff0c\u800c\u4e3b\u52a8\u63a8\u7406\u901a\u8fc7\u671f\u671b\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u5c06\u5b83\u4eec\u7edf\u4e00\u8d77\u6765\u3002\u7136\u800c\uff0cEFE\u6700\u5c0f\u5316\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002", "method": "\u57fa\u4e8e\u5c06EFE\u6700\u5c0f\u5316\u91cd\u65b0\u8868\u8ff0\u4e3a\u53d8\u5206\u63a8\u7406\u7684\u6700\u65b0\u7406\u8bba\uff0c\u5c06\u5176\u4e0e\u89c4\u5212\u5373\u63a8\u7406\u6b63\u5f0f\u7edf\u4e00\uff0c\u5e76\u5c06\u8ba4\u77e5\u9a71\u52a8\u89c6\u4e3a\u72ec\u7279\u7684\u71b5\u8d21\u732e\u3002\u4e3b\u8981\u8d21\u732e\u662f\u4e3a\u8fd9\u4e00\u7edf\u4e00\u76ee\u6807\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\u3002", "result": "\u8be5\u6d88\u606f\u4f20\u9012\u65b9\u6848\u80fd\u591f\u5728\u56e0\u5b50\u72b6\u6001MDP\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u4e3b\u52a8\u63a8\u7406\uff0c\u514b\u670d\u4e86\u9ad8\u7ef4\u89c4\u5212\u96be\u4ee5\u5904\u7406\u7684\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u7edf\u4e00EFE\u6700\u5c0f\u5316\u548c\u89c4\u5212\u5373\u63a8\u7406\uff0c\u5e76\u5f15\u5165\u9ad8\u6548\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4e3b\u52a8\u63a8\u7406\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.18708", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18708", "abs": "https://arxiv.org/abs/2511.18708", "authors": ["Yanbin Li", "Canran Xiao", "Shenghai Yuan", "Peilai Yu", "Ziruo Li", "Zhiguo Zhang", "Wenzheng Chi", "Wei Zhang"], "title": "GVD-TG: Topological Graph based on Fast Hierarchical GVD Sampling for Robot Exploration", "comment": "12 pages, 10 figures", "summary": "Topological maps are more suitable than metric maps for robotic exploration tasks. However, real-time updating of accurate and detail-rich environmental topological maps remains a challenge. This paper presents a topological map updating method based on the Generalized Voronoi Diagram (GVD). First, the newly observed areas are denoised to avoid low-efficiency GVD nodes misleading the topological structure. Subsequently, a multi-granularity hierarchical GVD generation method is designed to control the sampling granularity at both global and local levels. This not only ensures the accuracy of the topological structure but also enhances the ability to capture detail features, reduces the probability of path backtracking, and ensures no overlap between GVDs through the maintenance of a coverage map, thereby improving GVD utilization efficiency. Second, a node clustering method with connectivity constraints and a connectivity method based on a switching mechanism are designed to avoid the generation of unreachable nodes and erroneous nodes caused by obstacle attraction. A special cache structure is used to store all connectivity information, thereby improving exploration efficiency. Finally, to address the issue of frontiers misjudgment caused by obstacles within the scope of GVD units, a frontiers extraction method based on morphological dilation is designed to effectively ensure the reachability of frontiers. On this basis, a lightweight cost function is used to assess and switch to the next viewpoint in real time. This allows the robot to quickly adjust its strategy when signs of path backtracking appear, thereby escaping the predicament and increasing exploration flexibility. And the performance of system for exploration task is verified through comparative tests with SOTA methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49Voronoi\u56fe(GVD)\u7684\u62d3\u6251\u5730\u56fe\u66f4\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u5206\u5c42GVD\u751f\u6210\u3001\u8282\u70b9\u805a\u7c7b\u4e0e\u8fde\u63a5\u673a\u5236\u3001\u57fa\u4e8e\u5f62\u6001\u5b66\u81a8\u80c0\u7684\u524d\u6cbf\u63d0\u53d6\u7b49\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u62d3\u6251\u5730\u56fe\u5b9e\u65f6\u66f4\u65b0\u4e2d\u7684\u7cbe\u5ea6\u3001\u7ec6\u8282\u7279\u5f81\u548c\u8def\u5f84\u56de\u6eaf\u95ee\u9898\u3002", "motivation": "\u62d3\u6251\u5730\u56fe\u6bd4\u5ea6\u91cf\u5730\u56fe\u66f4\u9002\u5408\u673a\u5668\u4eba\u63a2\u7d22\u4efb\u52a1\uff0c\u4f46\u5b9e\u65f6\u66f4\u65b0\u51c6\u786e\u4e14\u7ec6\u8282\u4e30\u5bcc\u7684\u73af\u5883\u62d3\u6251\u5730\u56fe\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "1. \u57fa\u4e8eGVD\u7684\u62d3\u6251\u5730\u56fe\u66f4\u65b0\u65b9\u6cd5\uff1b2. \u591a\u7c92\u5ea6\u5206\u5c42GVD\u751f\u6210\u63a7\u5236\u91c7\u6837\u7c92\u5ea6\uff1b3. \u5e26\u8fde\u901a\u6027\u7ea6\u675f\u7684\u8282\u70b9\u805a\u7c7b\u548c\u57fa\u4e8e\u5207\u6362\u673a\u5236\u7684\u8fde\u63a5\u65b9\u6cd5\uff1b4. \u57fa\u4e8e\u5f62\u6001\u5b66\u81a8\u80c0\u7684\u524d\u6cbf\u63d0\u53d6\u65b9\u6cd5\uff1b5. \u8f7b\u91cf\u7ea7\u6210\u672c\u51fd\u6570\u5b9e\u65f6\u8bc4\u4f30\u548c\u5207\u6362\u4e0b\u4e00\u4e2a\u89c6\u70b9\u3002", "result": "\u901a\u8fc7\u591a\u7c92\u5ea6\u5206\u5c42GVD\u751f\u6210\u786e\u4fdd\u4e86\u62d3\u6251\u7ed3\u6784\u51c6\u786e\u6027\uff0c\u589e\u5f3a\u4e86\u7ec6\u8282\u7279\u5f81\u6355\u83b7\u80fd\u529b\uff0c\u51cf\u5c11\u4e86\u8def\u5f84\u56de\u6eaf\u6982\u7387\uff0c\u63d0\u9ad8\u4e86GVD\u5229\u7528\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u62d3\u6251\u5730\u56fe\u66f4\u65b0\u4e2d\u7684\u7cbe\u5ea6\u3001\u7ec6\u8282\u7279\u5f81\u548c\u8def\u5f84\u56de\u6eaf\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u63a2\u7d22\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u4e0eSOTA\u65b9\u6cd5\u7684\u5bf9\u6bd4\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.18964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18964", "abs": "https://arxiv.org/abs/2511.18964", "authors": ["Antonia W\u00fcst", "Wolfgang Stammer", "Hikaru Shindo", "Lukas Helff", "Devendra Singh Dhami", "Kristian Kersting"], "title": "Synthesizing Visual Concepts as Vision-Language Programs", "comment": null, "summary": "Vision-Language models (VLMs) achieve strong performance on multimodal tasks but often fail at systematic visual reasoning tasks, leading to inconsistent or illogical outputs. Neuro-symbolic methods promise to address this by inducing interpretable logical rules, though they exploit rigid, domain-specific perception modules. We propose Vision-Language Programs (VLP), which combine the perceptual flexibility of VLMs with systematic reasoning of program synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the model to produce structured visual descriptions that are compiled into neuro-symbolic programs. The resulting programs execute directly on images, remain consistent with task constraints, and provide human-interpretable explanations that enable easy shortcut mitigation. Experiments on synthetic and real-world datasets demonstrate that VLPs outperform direct and structured prompting, particularly on tasks requiring complex logical reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86Vision-Language Programs (VLP)\uff0c\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u611f\u77e5\u7075\u6d3b\u6027\u4e0e\u7a0b\u5e8f\u5408\u6210\u7684\u7cfb\u7edf\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u751f\u6210\u7ed3\u6784\u5316\u89c6\u89c9\u63cf\u8ff0\u5e76\u7f16\u8bd1\u6210\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u6765\u89e3\u51b3\u7cfb\u7edf\u89c6\u89c9\u63a8\u7406\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7cfb\u7edf\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7ecf\u5e38\u5931\u8d25\uff0c\u4ea7\u751f\u4e0d\u4e00\u81f4\u6216\u4e0d\u5408\u903b\u8f91\u7684\u8f93\u51fa\u3002\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u867d\u7136\u80fd\u751f\u6210\u53ef\u89e3\u91ca\u903b\u8f91\u89c4\u5219\uff0c\u4f46\u4f7f\u7528\u50f5\u5316\u7684\u9886\u57df\u7279\u5b9a\u611f\u77e5\u6a21\u5757\u3002", "method": "VLP\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u89c6\u89c9\u63cf\u8ff0\uff0c\u7136\u540e\u5c06\u5176\u7f16\u8bd1\u6210\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u3002\u8fd9\u4e9b\u7a0b\u5e8f\u76f4\u63a5\u5728\u56fe\u50cf\u4e0a\u6267\u884c\uff0c\u4fdd\u6301\u4e0e\u4efb\u52a1\u7ea6\u675f\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u4f9b\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVLP\u5728\u9700\u8981\u590d\u6742\u903b\u8f91\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u4f18\u4e8e\u76f4\u63a5\u548c\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "VLP\u6210\u529f\u5730\u5c06VLMs\u7684\u611f\u77e5\u7075\u6d3b\u6027\u4e0e\u7a0b\u5e8f\u5408\u6210\u7684\u7cfb\u7edf\u63a8\u7406\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u5728\u590d\u6742\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.18709", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18709", "abs": "https://arxiv.org/abs/2511.18709", "authors": ["Xueyan Oh", "Jonathan Her", "Zhixiang Ong", "Brandon Koh", "Yun Hann Tan", "U-Xuan Tan"], "title": "Autonomous Surface Selection For Manipulator-Based UV Disinfection In Hospitals Using Foundation Models", "comment": "7 pages, 7 figures; This paper has been accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "summary": "Ultraviolet (UV) germicidal radiation is an established non-contact method for surface disinfection in medical environments. Traditional approaches require substantial human intervention to define disinfection areas, complicating automation, while deep learning-based methods often need extensive fine-tuning and large datasets, which can be impractical for large-scale deployment. Additionally, these methods often do not address scene understanding for partial surface disinfection, which is crucial for avoiding unintended UV exposure. We propose a solution that leverages foundation models to simplify surface selection for manipulator-based UV disinfection, reducing human involvement and removing the need for model training. Additionally, we propose a VLM-assisted segmentation refinement to detect and exclude thin and small non-target objects, showing that this reduces mis-segmentation errors. Our approach achieves over 92\\% success rate in correctly segmenting target and non-target surfaces, and real-world experiments with a manipulator and simulated UV light demonstrate its practical potential for real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684UV\u6d88\u6bd2\u8868\u9762\u9009\u62e9\u65b9\u6cd5\uff0c\u65e0\u9700\u6a21\u578b\u8bad\u7ec3\uff0c\u901a\u8fc7VLM\u8f85\u52a9\u5206\u5272\u7ec6\u5316\u6765\u51cf\u5c11\u8bef\u5206\u5272\u9519\u8bef\uff0c\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edfUV\u6d88\u6bd2\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5e72\u9884\u5b9a\u4e49\u6d88\u6bd2\u533a\u57df\uff0c\u800c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u5fae\u8c03\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u90e8\u5206\u8868\u9762\u6d88\u6bd2\u7684\u573a\u666f\u7406\u89e3\u80fd\u529b\u3002", "method": "\u5229\u7528\u57fa\u7840\u6a21\u578b\u7b80\u5316\u673a\u68b0\u81c2UV\u6d88\u6bd2\u7684\u8868\u9762\u9009\u62e9\uff0c\u65e0\u9700\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u91c7\u7528VLM\u8f85\u52a9\u5206\u5272\u7ec6\u5316\u6765\u68c0\u6d4b\u548c\u6392\u9664\u7ec6\u5c0f\u975e\u76ee\u6807\u7269\u4f53\u3002", "result": "\u76ee\u6807\u548c\u975e\u76ee\u6807\u8868\u9762\u7684\u6b63\u786e\u5206\u5272\u6210\u529f\u7387\u8d85\u8fc792%\uff0c\u771f\u5b9e\u73af\u5883\u5b9e\u9a8c\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u4eba\u5de5\u53c2\u4e0e\uff0c\u65e0\u9700\u6a21\u578b\u8bad\u7ec3\uff0c\u5728UV\u8868\u9762\u6d88\u6bd2\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.18966", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18966", "abs": "https://arxiv.org/abs/2511.18966", "authors": ["Muhammad Usman Shahid", "Chuadhry Mujeeb Ahmed", "Rajiv Ranjan"], "title": "LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models", "comment": null, "summary": "The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code generation and analyzed the outputs through static analysis. The amount of CWEs present in AI-generated code is concerning. Our findings highlight the need for developers to be cautious when using LLM-generated code. This study provides valuable insights to advance automated code generation and encourage further research in this domain.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u751f\u6210\u7684C/C++\u4ee3\u7801\u5b58\u5728\u5927\u91cf\u5b89\u5168\u6f0f\u6d1e\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u53d1\u73b0\u4ee3\u7801\u4e2dCWE\u6570\u91cf\u4ee4\u4eba\u62c5\u5fe7\uff0c\u5f00\u53d1\u8005\u9700\u8981\u8c28\u614e\u4f7f\u7528AI\u751f\u6210\u7684\u4ee3\u7801\u3002", "motivation": "LLM\u751f\u6210\u7684\u4ee3\u7801\u5b89\u5168\u6027\u662f\u91cd\u8981\u5173\u5207\u70b9\uff0c\u7814\u7a76\u8868\u660e\u8fd9\u7c7b\u4ee3\u7801\u5e38\u5305\u542b\u6f0f\u6d1e\u4e14\u7f3a\u4e4f\u9632\u5fa1\u6027\u7f16\u7a0b\u7ed3\u6784\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528CWE\u5bf9\u5df2\u77e5\u6f0f\u6d1e\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230CVE\u8bc4\u4f30\u4e25\u91cd\u6027\uff0c\u91c7\u752810\u79cd\u4e0d\u540cLLM\u751f\u6210\u4ee3\u7801\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u8bc4\u4f30\u8f93\u51fa\u7ed3\u679c\u3002", "result": "AI\u751f\u6210\u4ee3\u7801\u4e2d\u5b58\u5728\u7684CWE\u6570\u91cf\u4ee4\u4eba\u62c5\u5fe7\uff0c\u9759\u6001\u5206\u6790\u663e\u793a\u4ee3\u7801\u5b89\u5168\u72b6\u51b5\u4e0d\u7406\u60f3\u3002", "conclusion": "\u5f00\u53d1\u8005\u5728\u4f7f\u7528LLM\u751f\u6210\u4ee3\u7801\u65f6\u9700\u8981\u4fdd\u6301\u8c28\u614e\uff0c\u672c\u7814\u7a76\u4e3a\u63a8\u8fdb\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u89c1\u89e3\uff0c\u9f13\u52b1\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2511.18712", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18712", "abs": "https://arxiv.org/abs/2511.18712", "authors": ["Tianyu Wang", "Chunxiang Yan", "Xuanhong Liao", "Tao Zhang", "Ping Wang", "Cong Wen", "Dingchuan Liu", "Haowen Yu", "Ximin Lyu"], "title": "Head Stabilization for Wheeled Bipedal Robots via Force-Estimation-Based Admittance Control", "comment": null, "summary": "Wheeled bipedal robots are emerging as flexible platforms for field exploration. However, head instability induced by uneven terrain can degrade the accuracy of onboard sensors or damage fragile payloads. Existing research primarily focuses on stabilizing the mobile platform but overlooks active stabilization of the head in the world frame, resulting in vertical oscillations that undermine overall stability. To address this challenge, we developed a model-based ground force estimation method for our 6-degree-of-freedom wheeled bipedal robot. Leveraging these force estimates, we implemented an admittance control algorithm to enhance terrain adaptability. Simulation experiments validated the real-time performance of the force estimator and the robot's robustness when traversing uneven terrain.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u5730\u9762\u529b\u4f30\u8ba1\u65b9\u6cd5\u548c\u5bfc\u7eb3\u63a7\u5236\u7b97\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8\u8f6e\u5f0f\u53cc\u8db3\u673a\u5668\u4eba\u5728\u4e0d\u5e73\u5766\u5730\u5f62\u4e0a\u7684\u5934\u90e8\u7a33\u5b9a\u6027\u3002", "motivation": "\u8f6e\u5f0f\u53cc\u8db3\u673a\u5668\u4eba\u5728\u4e0d\u5e73\u5766\u5730\u5f62\u4e0a\u8fd0\u884c\u65f6\uff0c\u5934\u90e8\u4e0d\u7a33\u5b9a\u6027\u4f1a\u964d\u4f4e\u673a\u8f7d\u4f20\u611f\u5668\u7cbe\u5ea6\u6216\u635f\u574f\u8106\u5f31\u8d1f\u8f7d\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5e73\u53f0\u7a33\u5b9a\u800c\u5ffd\u7565\u4e86\u5934\u90e8\u5728\u4e16\u754c\u5750\u6807\u7cfb\u4e2d\u7684\u4e3b\u52a8\u7a33\u5b9a\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u5730\u9762\u529b\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u529b\u4f30\u8ba1\u5b9e\u73b0\u4e86\u5bfc\u7eb3\u63a7\u5236\u7b97\u6cd5\u6765\u589e\u5f3a\u5730\u5f62\u9002\u5e94\u6027\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u529b\u4f30\u8ba1\u5668\u7684\u5b9e\u65f6\u6027\u80fd\uff0c\u4ee5\u53ca\u673a\u5668\u4eba\u5728\u7a7f\u8d8a\u4e0d\u5e73\u5766\u5730\u5f62\u65f6\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8f6e\u5f0f\u53cc\u8db3\u673a\u5668\u4eba\u5728\u4e0d\u5e73\u5766\u5730\u5f62\u4e0a\u7684\u5934\u90e8\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u6574\u4f53\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.19005", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19005", "abs": "https://arxiv.org/abs/2511.19005", "authors": ["Di Wu", "Liting Jiang", "Ruiyu Fang", "Bianjing", "Hongyan Xie", "Haoxiang Su", "Hao Huang", "Zhongjiang He", "Shuangyong Song", "Xuelong Li"], "title": "Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for Spoken Language Understanding", "comment": null, "summary": "Spoken Language Understanding (SLU) consists of two sub-tasks: intent detection (ID) and slot filling (SF). Given its broad range of real-world applications, enhancing SLU for practical deployment is increasingly critical. Profile-based SLU addresses ambiguous user utterances by incorporating context awareness (CA), user profiles (UP), and knowledge graphs (KG) to support disambiguation, thereby advancing SLU research toward real-world applicability. However, existing SLU datasets still fall short in representing real-world scenarios. Specifically, (1) CA uses one-hot vectors for representation, which is overly idealized, and (2) models typically focuses solely on predicting intents and slot labels, neglecting the reasoning process that could enhance performance and interpretability. To overcome these limitations, we introduce VRSLU, a novel SLU dataset that integrates both Visual images and explicit Reasoning. For over-idealized CA, we use GPT-4o and FLUX.1-dev to generate images reflecting users' environments and statuses, followed by human verification to ensure quality. For reasoning, GPT-4o is employed to generate explanations for predicted labels, which are then refined by human annotators to ensure accuracy and coherence. Additionally, we propose an instructional template, LR-Instruct, which first predicts labels and then generates corresponding reasoning. This two-step approach helps mitigate the influence of reasoning bias on label prediction. Experimental results confirm the effectiveness of incorporating visual information and highlight the promise of explicit reasoning in advancing SLU.", "AI": {"tldr": "\u63d0\u51fa\u4e86VRSLU\u6570\u636e\u96c6\uff0c\u6574\u5408\u89c6\u89c9\u56fe\u50cf\u548c\u663e\u5f0f\u63a8\u7406\u6765\u89e3\u51b3SLU\u4efb\u52a1\u4e2d\u7684\u73af\u5883\u8868\u793a\u8fc7\u4e8e\u7406\u60f3\u5316\u548c\u7f3a\u4e4f\u63a8\u7406\u8fc7\u7a0b\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709SLU\u6570\u636e\u96c6\u5728\u771f\u5b9e\u573a\u666f\u8868\u793a\u4e0a\u5b58\u5728\u4e0d\u8db3\uff1a\u73af\u5883\u611f\u77e5\u4f7f\u7528one-hot\u5411\u91cf\u8fc7\u4e8e\u7406\u60f3\u5316\uff0c\u6a21\u578b\u53ea\u9884\u6d4b\u6807\u7b7e\u800c\u5ffd\u7565\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528GPT-4o\u548cFLUX.1-dev\u751f\u6210\u53cd\u6620\u7528\u6237\u73af\u5883\u548c\u72b6\u6001\u7684\u56fe\u50cf\uff0c\u5e76\u7531\u4eba\u5de5\u9a8c\u8bc1\uff1b\u7528GPT-4o\u751f\u6210\u6807\u7b7e\u9884\u6d4b\u7684\u89e3\u91ca\uff0c\u4eba\u5de5\u7cbe\u70bc\u786e\u4fdd\u51c6\u786e\u6027\uff1b\u63d0\u51faLR-Instruct\u6307\u4ee4\u6a21\u677f\uff0c\u5148\u9884\u6d4b\u6807\u7b7e\u518d\u751f\u6210\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u89c6\u89c9\u4fe1\u606f\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u663e\u5f0f\u63a8\u7406\u5728\u63a8\u8fdbSLU\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "VRSLU\u6570\u636e\u96c6\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u548c\u63a8\u7406\u5143\u7d20\uff0c\u89e3\u51b3\u4e86\u73b0\u6709SLU\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2511.18718", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18718", "abs": "https://arxiv.org/abs/2511.18718", "authors": ["Omar Garib", "Jayaprakash D. Kambhampaty", "Olivia J. Pinon Fischer", "Dimitri N. Mavris"], "title": "AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation", "comment": "9 pages, 4 figures, 1 table, 1 algorithm", "summary": "We introduce AIRHILT (Aviation Integrated Reasoning, Human-in-the-Loop Testbed), a modular and lightweight simulation environment designed to evaluate multimodal pilot and air traffic control (ATC) assistance systems for aviation conflict detection. Built on the open-source Godot engine, AIRHILT synchronizes pilot and ATC radio communications, visual scene understanding from camera streams, and ADS-B surveillance data within a unified, scalable platform. The environment supports pilot- and controller-in-the-loop interactions, providing a comprehensive scenario suite covering both terminal area and en route operational conflicts, including communication errors and procedural mistakes. AIRHILT offers standardized JSON-based interfaces that enable researchers to easily integrate, swap, and evaluate automatic speech recognition (ASR), visual detection, decision-making, and text-to-speech (TTS) models. We demonstrate AIRHILT through a reference pipeline incorporating fine-tuned Whisper ASR, YOLO-based visual detection, ADS-B-based conflict logic, and GPT-OSS-20B structured reasoning, and present preliminary results from representative runway-overlap scenarios, where the assistant achieves an average time-to-first-warning of approximately 7.7 s, with average ASR and vision latencies of approximately 5.9 s and 0.4 s, respectively. The AIRHILT environment and scenario suite are openly available, supporting reproducible research on multimodal situational awareness and conflict detection in aviation; code and scenarios are available at https://github.com/ogarib3/airhilt.", "AI": {"tldr": "AIRHILT\u662f\u4e00\u4e2a\u57fa\u4e8eGodot\u5f15\u64ce\u7684\u8f7b\u91cf\u7ea7\u4eff\u771f\u73af\u5883\uff0c\u7528\u4e8e\u8bc4\u4f30\u822a\u7a7a\u51b2\u7a81\u68c0\u6d4b\u4e2d\u7684\u591a\u6a21\u6001\u98de\u884c\u5458\u548c\u7a7a\u7ba1\u8f85\u52a9\u7cfb\u7edf\uff0c\u652f\u6301\u4eba\u673a\u4ea4\u4e92\u548c\u6807\u51c6\u5316\u63a5\u53e3\u3002", "motivation": "\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u5e73\u53f0\u6765\u8bc4\u4f30\u822a\u7a7a\u51b2\u7a81\u68c0\u6d4b\u4e2d\u7684\u591a\u6a21\u6001\u8f85\u52a9\u7cfb\u7edf\uff0c\u6574\u5408\u8bed\u97f3\u901a\u4fe1\u3001\u89c6\u89c9\u573a\u666f\u7406\u89e3\u548cADS-B\u76d1\u89c6\u6570\u636e\u3002", "method": "\u57fa\u4e8e\u5f00\u6e90Godot\u5f15\u64ce\u6784\u5efa\u6a21\u5757\u5316\u4eff\u771f\u73af\u5883\uff0c\u540c\u6b65\u98de\u884c\u5458\u548c\u7a7a\u7ba1\u65e0\u7ebf\u7535\u901a\u4fe1\u3001\u89c6\u89c9\u573a\u666f\u7406\u89e3\u548cADS-B\u6570\u636e\uff0c\u63d0\u4f9b\u6807\u51c6\u5316JSON\u63a5\u53e3\u96c6\u6210ASR\u3001\u89c6\u89c9\u68c0\u6d4b\u3001\u51b3\u7b56\u548cTTS\u6a21\u578b\u3002", "result": "\u5728\u4ee3\u8868\u6027\u8dd1\u9053\u91cd\u53e0\u573a\u666f\u4e2d\uff0c\u8f85\u52a9\u7cfb\u7edf\u5e73\u5747\u9996\u6b21\u8b66\u544a\u65f6\u95f4\u7ea67.7\u79d2\uff0cASR\u548c\u89c6\u89c9\u5ef6\u8fdf\u5206\u522b\u7ea65.9\u79d2\u548c0.4\u79d2\u3002", "conclusion": "AIRHILT\u4e3a\u822a\u7a7a\u591a\u6a21\u6001\u6001\u52bf\u611f\u77e5\u548c\u51b2\u7a81\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u7814\u7a76\u5e73\u53f0\uff0c\u4ee3\u7801\u548c\u573a\u666f\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.19100", "categories": ["cs.AI", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19100", "abs": "https://arxiv.org/abs/2511.19100", "authors": ["Chih-Duo Hong", "Hongjian Jiang", "Anthony W. Lin", "Oliver Markgraf", "Julian Parsert", "Tony Tan"], "title": "Extracting Robust Register Automata from Neural Networks over Data Sequences", "comment": null, "summary": "Automata extraction is a method for synthesising interpretable surrogates for black-box neural models that can be analysed symbolically. Existing techniques assume a finite input alphabet, and thus are not directly applicable to data sequences drawn from continuous domains. We address this challenge with deterministic register automata (DRAs), which extend finite automata with registers that store and compare numeric values. Our main contribution is a framework for robust DRA extraction from black-box models: we develop a polynomial-time robustness checker for DRAs with a fixed number of registers, and combine it with passive and active automata learning algorithms. This combination yields surrogate DRAs with statistical robustness and equivalence guarantees. As a key application, we use the extracted automata to assess the robustness of neural networks: for a given sequence and distance metric, the DRA either certifies local robustness or produces a concrete counterexample. Experiments on recurrent neural networks and transformer architectures show that our framework reliably learns accurate automata and enables principled robustness evaluation. Overall, our results demonstrate that robust DRA extraction effectively bridges neural network interpretability and formal reasoning without requiring white-box access to the underlying network.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ece\u9ed1\u76d2\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\u63d0\u53d6\u786e\u5b9a\u6027\u5bc4\u5b58\u5668\u81ea\u52a8\u673a(DRA)\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5408\u6210\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u6a21\u578b\u5e76\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u673a\u63d0\u53d6\u65b9\u6cd5\u5047\u8bbe\u6709\u9650\u8f93\u5165\u5b57\u6bcd\u8868\uff0c\u4e0d\u9002\u7528\u4e8e\u8fde\u7eed\u57df\u6570\u636e\u5e8f\u5217\u3002\u9700\u8981\u6269\u5c55\u65b9\u6cd5\u5904\u7406\u6570\u503c\u8f93\u5165\u3002", "method": "\u5f00\u53d1\u591a\u9879\u5f0f\u65f6\u95f4\u9c81\u68d2\u6027\u68c0\u67e5\u5668\uff0c\u7ed3\u5408\u88ab\u52a8\u548c\u4e3b\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u7b97\u6cd5\uff0c\u63d0\u53d6\u5177\u6709\u7edf\u8ba1\u9c81\u68d2\u6027\u548c\u7b49\u4ef7\u6027\u4fdd\u8bc1\u7684DRA\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u53ef\u9760\u5b66\u4e60\u51c6\u786e\u81ea\u52a8\u673a\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u8ddd\u79bb\u5ea6\u91cf\u7684\u5c40\u90e8\u9c81\u68d2\u6027\u8ba4\u8bc1\u6216\u751f\u6210\u53cd\u4f8b\u3002", "conclusion": "\u9c81\u68d2DRA\u63d0\u53d6\u6709\u6548\u8fde\u63a5\u4e86\u795e\u7ecf\u7f51\u7edc\u53ef\u89e3\u91ca\u6027\u548c\u5f62\u5f0f\u63a8\u7406\uff0c\u65e0\u9700\u767d\u76d2\u8bbf\u95ee\u5e95\u5c42\u7f51\u7edc\u3002"}}
{"id": "2511.18756", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18756", "abs": "https://arxiv.org/abs/2511.18756", "authors": ["Xueyu Du", "Lilian Zhang", "Fuan Duan", "Xincan Luo", "Maosong Wang", "Wenqi Wu", "JunMao"], "title": "SP-VINS: A Hybrid Stereo Visual Inertial Navigation System based on Implicit Environmental Map", "comment": null, "summary": "Filter-based visual inertial navigation system (VINS) has attracted mobile-robot researchers for the good balance between accuracy and efficiency, but its limited mapping quality hampers long-term high-accuracy state estimation. To this end, we first propose a novel filter-based stereo VINS, differing from traditional simultaneous localization and mapping (SLAM) systems based on 3D map, which performs efficient loop closure constraints with implicit environmental map composed of keyframes and 2D keypoints. Secondly, we proposed a hybrid residual filter framework that combines landmark reprojection and ray constraints to construct a unified Jacobian matrix for measurement updates. Finally, considering the degraded environment, we incorporated the camera-IMU extrinsic parameters into visual description to achieve online calibration. Benchmark experiments demonstrate that the proposed SP-VINS achieves high computational efficiency while maintaining long-term high-accuracy localization performance, and is superior to existing state-of-the-art (SOTA) methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ee4\u6ce2\u5668\u7684\u7acb\u4f53\u89c6\u89c9\u60ef\u6027\u5bfc\u822a\u7cfb\u7edfSP-VINS\uff0c\u901a\u8fc7\u9690\u5f0f\u73af\u5883\u5730\u56fe\u5b9e\u73b0\u9ad8\u6548\u95ed\u73af\u7ea6\u675f\uff0c\u7ed3\u5408\u6df7\u5408\u6b8b\u5dee\u6ee4\u6ce2\u6846\u67b6\u548c\u5728\u7ebf\u5916\u53c2\u6807\u5b9a\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u957f\u671f\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u57fa\u4e8e\u6ee4\u6ce2\u5668\u7684VINS\u7cfb\u7edf\u5728\u957f\u671f\u72b6\u6001\u4f30\u8ba1\u4e2d\u56e0\u5730\u56fe\u8d28\u91cf\u6709\u9650\u800c\u7cbe\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "1) \u4f7f\u7528\u5173\u952e\u5e27\u548c2D\u5173\u952e\u70b9\u7ec4\u6210\u7684\u9690\u5f0f\u73af\u5883\u5730\u56fe\u8fdb\u884c\u9ad8\u6548\u95ed\u73af\u7ea6\u675f\uff1b2) \u63d0\u51fa\u6df7\u5408\u6b8b\u5dee\u6ee4\u6ce2\u6846\u67b6\uff0c\u7ed3\u5408\u5730\u6807\u91cd\u6295\u5f71\u548c\u5c04\u7ebf\u7ea6\u675f\u6784\u5efa\u7edf\u4e00\u96c5\u53ef\u6bd4\u77e9\u9635\uff1b3) \u5728\u9000\u5316\u73af\u5883\u4e2d\u5c06\u76f8\u673a-IMU\u5916\u53c2\u7eb3\u5165\u89c6\u89c9\u63cf\u8ff0\u5b9e\u73b0\u5728\u7ebf\u6807\u5b9a\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u8868\u660eSP-VINS\u5728\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u957f\u671f\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684SP-VINS\u7cfb\u7edf\u5728\u6ee4\u6ce2\u6846\u67b6\u4e0b\u6709\u6548\u89e3\u51b3\u4e86\u957f\u671f\u72b6\u6001\u4f30\u8ba1\u95ee\u9898\uff0c\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2511.18810", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18810", "abs": "https://arxiv.org/abs/2511.18810", "authors": ["Yuxia Fu", "Zhizhen Zhang", "Yuqi Zhang", "Zijian Wang", "Zi Huang", "Yadan Luo"], "title": "MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent", "comment": null, "summary": "Recent Vision-Language-Action (VLA) models reformulate vision-language models by tuning them with millions of robotic demonstrations. While they perform well when fine-tuned for a single embodiment or task family, extending them to multi-skill settings remains challenging: directly merging VLA experts trained on different tasks results in near-zero success rates. This raises a fundamental question: what prevents VLAs from mastering multiple skills within one model? With an empirical decomposition of learnable parameters during VLA fine-tuning, we identify two key sources of non-mergeability: (1) Finetuning drives LoRA adapters in the VLM backbone toward divergent, task-specific directions beyond the capacity of existing merging methods to unify. (2) Action experts develop inter-block dependencies through self-attention feedback, causing task information to spread across layers and preventing modular recombination. To address these challenges, we present MergeVLA, a merging-oriented VLA architecture that preserves mergeability by design. MergeVLA introduces sparsely activated LoRA adapters via task masks to retain consistent parameters and reduce irreconcilable conflicts in the VLM. Its action expert replaces self-attention with cross-attention-only blocks to keep specialization localized and composable. When the task is unknown, it uses a test-time task router to adaptively select the appropriate task mask and expert head from the initial observation, enabling unsupervised task inference. Across LIBERO, LIBERO-Plus, RoboTwin, and multi-task experiments on the real SO101 robotic arm, MergeVLA achieves performance comparable to or even exceeding individually finetuned experts, demonstrating robust generalization across tasks, embodiments, and environments.", "AI": {"tldr": "MergeVLA\u662f\u4e00\u4e2a\u4e13\u4e3a\u591a\u6280\u80fd\u5408\u5e76\u8bbe\u8ba1\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u7a00\u758f\u6fc0\u6d3b\u7684LoRA\u9002\u914d\u5668\u548c\u4ec5\u4ea4\u53c9\u6ce8\u610f\u529b\u5757\u6765\u89e3\u51b3\u73b0\u6709VLA\u6a21\u578b\u5728\u591a\u4efb\u52a1\u5408\u5e76\u65f6\u7684\u51b2\u7a81\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4e0e\u5355\u72ec\u5fae\u8c03\u4e13\u5bb6\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u5355\u4e00\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u6280\u80fd\u8bbe\u7f6e\u4e0b\u76f4\u63a5\u5408\u5e76\u4e0d\u540c\u4efb\u52a1\u4e13\u5bb6\u4f1a\u5bfc\u81f4\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9VLA\u6a21\u578b\u65e0\u6cd5\u638c\u63e1\u591a\u79cd\u6280\u80fd\u7684\u6839\u672c\u539f\u56e0\u7684\u7814\u7a76\u9700\u6c42\u3002", "method": "\u63d0\u51faMergeVLA\u67b6\u6784\uff1a1\uff09\u4f7f\u7528\u4efb\u52a1\u63a9\u7801\u7684\u7a00\u758f\u6fc0\u6d3bLoRA\u9002\u914d\u5668\u4fdd\u6301\u53c2\u6570\u4e00\u81f4\u6027\uff1b2\uff09\u7528\u4ec5\u4ea4\u53c9\u6ce8\u610f\u529b\u5757\u66ff\u6362\u81ea\u6ce8\u610f\u529b\u4ee5\u4fdd\u6301\u4e13\u4e1a\u5316\u5c40\u90e8\u5316\uff1b3\uff09\u6d4b\u8bd5\u65f6\u4efb\u52a1\u8def\u7531\u5668\u5b9e\u73b0\u65e0\u76d1\u7763\u4efb\u52a1\u63a8\u65ad\u3002", "result": "\u5728LIBERO\u3001LIBERO-Plus\u3001RoboTwin\u548c\u771f\u5b9eSO101\u673a\u68b0\u81c2\u4e0a\u7684\u591a\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cMergeVLA\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u5355\u72ec\u5fae\u8c03\u4e13\u5bb6\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u8de8\u4efb\u52a1\u3001\u5177\u8eab\u548c\u73af\u5883\u7684\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MergeVLA\u901a\u8fc7\u67b6\u6784\u8bbe\u8ba1\u89e3\u51b3\u4e86VLA\u6a21\u578b\u7684\u591a\u6280\u80fd\u5408\u5e76\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6a21\u5757\u5316\u91cd\u7ec4\u548c\u4efb\u52a1\u81ea\u9002\u5e94\uff0c\u4e3a\u6784\u5efa\u901a\u7528\u591a\u6280\u80fd\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.19155", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19155", "abs": "https://arxiv.org/abs/2511.19155", "authors": ["Xihe Qiu", "Gengchen Ma", "Haoyu Wang", "Chen Zhan", "Xiaoyu Tan", "Shuo Li"], "title": "EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction", "comment": null, "summary": "Sleep stage classification based on electroencephalography (EEG) is fundamental for assessing sleep quality and diagnosing sleep-related disorders. However, most traditional machine learning methods rely heavily on prior knowledge and handcrafted features, while existing deep learning models still struggle to jointly capture fine-grained time-frequency patterns and achieve clinical interpretability. Recently, vision-language models (VLMs) have made significant progress in the medical domain, yet their performance remains constrained when applied to physiological waveform data, especially EEG signals, due to their limited visual understanding and insufficient reasoning capability. To address these challenges, we propose EEG-VLM, a hierarchical vision-language framework that integrates multi-level feature alignment with visually enhanced language-guided reasoning for interpretable EEG-based sleep stage classification. Specifically, a specialized visual enhancement module constructs high-level visual tokens from intermediate-layer features to extract rich semantic representations of EEG images. These tokens are further aligned with low-level CLIP features through a multi-level alignment mechanism, enhancing the VLM's image-processing capability. In addition, a Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference into interpretable logical steps, effectively simulating expert-like decision-making. Experimental results demonstrate that the proposed method significantly improves both the accuracy and interpretability of VLMs in EEG-based sleep stage classification, showing promising potential for automated and explainable EEG analysis in clinical settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86EEG-VLM\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ea7\u7279\u5f81\u5bf9\u9f50\u548c\u89c6\u89c9\u589e\u5f3a\u7684\u8bed\u8a00\u5f15\u5bfc\u63a8\u7406\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u57fa\u4e8eEEG\u7684\u7761\u7720\u5206\u671f\u5206\u7c7b", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5148\u9a8c\u77e5\u8bc6\u548c\u624b\u5de5\u7279\u5f81\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u7ec6\u7c92\u5ea6\u65f6\u9891\u6a21\u5f0f\u5e76\u5b9e\u73b0\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\uff0c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7406\u6ce2\u5f62\u6570\u636e\u4e0a\u6027\u80fd\u53d7\u9650", "method": "\u6784\u5efa\u4e13\u95e8\u7684\u89c6\u89c9\u589e\u5f3a\u6a21\u5757\u4ece\u4e2d\u95f4\u5c42\u7279\u5f81\u751f\u6210\u9ad8\u7ea7\u89c6\u89c9token\uff0c\u901a\u8fc7\u591a\u7ea7\u5bf9\u9f50\u673a\u5236\u4e0e\u4f4e\u5c42CLIP\u7279\u5f81\u5bf9\u9f50\uff1b\u91c7\u7528\u601d\u7ef4\u94fe\u63a8\u7406\u7b56\u7565\u5c06\u590d\u6742\u533b\u5b66\u63a8\u7406\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u7684\u903b\u8f91\u6b65\u9aa4", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728EEG\u7761\u7720\u5206\u671f\u5206\u7c7b\u4e2d\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "conclusion": "EEG-VLM\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u548c\u53ef\u89e3\u91caEEG\u5206\u6790\u7684\u6f5c\u529b"}}
{"id": "2511.18857", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18857", "abs": "https://arxiv.org/abs/2511.18857", "authors": ["Changsheng Luo", "Yushi Wang", "Wenhan Cai", "Mingguo Zhao"], "title": "AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion", "comment": null, "summary": "Accurate proprioceptive odometry is fundamental for legged robot navigation in GPS-denied and visually degraded environments where conventional visual odometry systems fail. Current approaches face critical limitations: analytical filtering methods suffer from modeling uncertainties and cumulative drift, hybrid learning-filtering approaches remain constrained by their analytical components, while pure learning-based methods struggle with simulation-to-reality transfer and demand extensive real-world data collection. This paper introduces AutoOdom, a novel autoregressive proprioceptive odometry system that overcomes these challenges through an innovative two-stage training paradigm. Stage 1 employs large-scale simulation data to learn complex nonlinear dynamics and rapidly changing contact states inherent in legged locomotion, while Stage 2 introduces an autoregressive enhancement mechanism using limited real-world data to effectively bridge the sim-to-real gap. The key innovation lies in our autoregressive training approach, where the model learns from its own predictions to develop resilience against sensor noise and improve robustness in highly dynamic environments. Comprehensive experimental validation on the Booster T1 humanoid robot demonstrates that AutoOdom significantly outperforms state-of-the-art methods across all evaluation metrics, achieving 57.2% improvement in absolute trajectory error, 59.2% improvement in Umeyama-aligned error, and 36.2% improvement in relative pose error compared to the Legolas baseline. Extensive ablation studies provide critical insights into sensor modality selection and temporal modeling, revealing counterintuitive findings about IMU acceleration data and validating our systematic design choices for robust proprioceptive odometry in challenging locomotion scenarios.", "AI": {"tldr": "AutoOdom\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u81ea\u56de\u5f52\u672c\u4f53\u611f\u77e5\u91cc\u7a0b\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\u89e3\u51b3\u8db3\u5f0f\u673a\u5668\u4eba\u5728GPS\u7f3a\u5931\u548c\u89c6\u89c9\u9000\u5316\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u8db3\u5f0f\u673a\u5668\u4eba\u5728GPS\u7f3a\u5931\u548c\u89c6\u89c9\u9000\u5316\u73af\u5883\u4e2d\u7684\u7cbe\u786e\u5b9a\u4f4d\u95ee\u9898\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u5728\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u3001\u7d2f\u79ef\u6f02\u79fb\u3001\u4eff\u771f\u5230\u73b0\u5b9e\u8fc1\u79fb\u56f0\u96be\u7b49\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5927\u89c4\u6a21\u4eff\u771f\u6570\u636e\u5b66\u4e60\u8db3\u5f0f\u8fd0\u52a8\u7684\u590d\u6742\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u548c\u5feb\u901f\u53d8\u5316\u7684\u63a5\u89e6\u72b6\u6001\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u81ea\u56de\u5f52\u589e\u5f3a\u673a\u5236\uff0c\u4f7f\u7528\u6709\u9650\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6709\u6548\u5f25\u5408\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "result": "\u5728Booster T1\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u76f8\u6bd4Legolas\u57fa\u7ebf\uff0cAutoOdom\u5728\u7edd\u5bf9\u8f68\u8ff9\u8bef\u5dee\u4e0a\u63d0\u534757.2%\uff0cUmeyama\u5bf9\u9f50\u8bef\u5dee\u63d0\u534759.2%\uff0c\u76f8\u5bf9\u4f4d\u59ff\u8bef\u5dee\u63d0\u534736.2%\u3002", "conclusion": "AutoOdom\u901a\u8fc7\u521b\u65b0\u7684\u81ea\u56de\u5f52\u8bad\u7ec3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8db3\u5f0f\u673a\u5668\u4eba\u5728\u6311\u6218\u6027\u8fd0\u52a8\u573a\u666f\u4e2d\u7684\u672c\u4f53\u611f\u77e5\u91cc\u7a0b\u8ba1\u6027\u80fd\uff0c\u6d88\u878d\u7814\u7a76\u4e3a\u4f20\u611f\u5668\u6a21\u6001\u9009\u62e9\u548c\u65f6\u95f4\u5efa\u6a21\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2511.19256", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19256", "abs": "https://arxiv.org/abs/2511.19256", "authors": ["Hang Ding", "Xue Wang", "Tian Zhou", "Tao Yao"], "title": "SimDiff: Simpler Yet Better Diffusion Model for Time Series Point Forecasting", "comment": "Accepted by AAAI 2026", "summary": "Diffusion models have recently shown promise in time series forecasting, particularly for probabilistic predictions. However, they often fail to achieve state-of-the-art point estimation performance compared to regression-based methods. This limitation stems from difficulties in providing sufficient contextual bias to track distribution shifts and in balancing output diversity with the stability and precision required for point forecasts. Existing diffusion-based approaches mainly focus on full-distribution modeling under probabilistic frameworks, often with likelihood maximization objectives, while paying little attention to dedicated strategies for high-accuracy point estimation. Moreover, other existing point prediction diffusion methods frequently rely on pre-trained or jointly trained mature models for contextual bias, sacrificing the generative flexibility of diffusion models.\n  To address these challenges, we propose SimDiff, a single-stage, end-to-end framework. SimDiff employs a single unified Transformer network carefully tailored to serve as both denoiser and predictor, eliminating the need for external pre-trained or jointly trained regressors. It achieves state-of-the-art point estimation performance by leveraging intrinsic output diversity and improving mean squared error accuracy through multiple inference ensembling. Key innovations, including normalization independence and the median-of-means estimator, further enhance adaptability and stability. Extensive experiments demonstrate that SimDiff significantly outperforms existing methods in time series point forecasting.", "AI": {"tldr": "SimDiff\u662f\u4e00\u4e2a\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u70b9\u9884\u6d4b\u7684\u5355\u9636\u6bb5\u7aef\u5230\u7aef\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684Transformer\u7f51\u7edc\u540c\u65f6\u4f5c\u4e3a\u53bb\u566a\u5668\u548c\u9884\u6d4b\u5668\uff0c\u65e0\u9700\u5916\u90e8\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5728\u70b9\u4f30\u8ba1\u6027\u80fd\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u4e3b\u8981\u5173\u6ce8\u6982\u7387\u9884\u6d4b\uff0c\u4f46\u5728\u70b9\u4f30\u8ba1\u6027\u80fd\u4e0a\u4e0d\u5982\u56de\u5f52\u65b9\u6cd5\uff0c\u4e3b\u8981\u95ee\u9898\u5305\u62ec\u96be\u4ee5\u8ddf\u8e2a\u5206\u5e03\u53d8\u5316\u3001\u5e73\u8861\u8f93\u51fa\u591a\u6837\u6027\u4e0e\u7cbe\u5ea6\uff0c\u4ee5\u53ca\u4f9d\u8d56\u5916\u90e8\u6a21\u578b\u63d0\u4f9b\u4e0a\u4e0b\u6587\u504f\u7f6e\u3002", "method": "\u63d0\u51faSimDiff\u6846\u67b6\uff0c\u4f7f\u7528\u5355\u4e00Transformer\u7f51\u7edc\u540c\u65f6\u4f5c\u4e3a\u53bb\u566a\u5668\u548c\u9884\u6d4b\u5668\uff0c\u901a\u8fc7\u591a\u63a8\u7406\u96c6\u6210\u5229\u7528\u5185\u5728\u8f93\u51fa\u591a\u6837\u6027\u63d0\u9ad8MSE\u7cbe\u5ea6\uff0c\u5e76\u5f15\u5165\u5f52\u4e00\u5316\u72ec\u7acb\u6027\u548c\u5747\u503c\u4e2d\u4f4d\u6570\u4f30\u8ba1\u5668\u7b49\u521b\u65b0\u6280\u672f\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSimDiff\u5728\u65f6\u95f4\u5e8f\u5217\u70b9\u9884\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u70b9\u4f30\u8ba1\u6027\u80fd\u3002", "conclusion": "SimDiff\u8bc1\u660e\u4e86\u6269\u6563\u6a21\u578b\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u751f\u6210\u7075\u6d3b\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u70b9\u9884\u6d4b\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u5728\u70b9\u4f30\u8ba1\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.18878", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18878", "abs": "https://arxiv.org/abs/2511.18878", "authors": ["Suzie Kim", "Hye-Bin Shin", "Hyo-Jeong Jang"], "title": "Accelerating Reinforcement Learning via Error-Related Human Brain Signals", "comment": null, "summary": "In this work, we investigate how implicit neural feed back can accelerate reinforcement learning in complex robotic manipulation settings. While prior electroencephalogram (EEG) guided reinforcement learning studies have primarily focused on navigation or low-dimensional locomotion tasks, we aim to understand whether such neural evaluative signals can improve policy learning in high-dimensional manipulation tasks involving obstacles and precise end-effector control. We integrate error related potentials decoded from offline-trained EEG classifiers into reward shaping and systematically evaluate the impact of human-feedback weighting. Experiments on a 7-DoF manipulator in an obstacle-rich reaching environment show that neural feedback accelerates reinforcement learning and, depending on the human-feedback weighting, can yield task success rates that at times exceed those of sparse-reward baselines. Moreover, when applying the best-performing feedback weighting across all sub jects, we observe consistent acceleration of reinforcement learning relative to the sparse-reward setting. Furthermore, leave-one subject-out evaluations confirm that the proposed framework remains robust despite the intrinsic inter-individual variability in EEG decodability. Our findings demonstrate that EEG-based reinforcement learning can scale beyond locomotion tasks and provide a viable pathway for human-aligned manipulation skill acquisition.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u5982\u4f55\u5229\u7528\u9690\u5f0f\u795e\u7ecf\u53cd\u9988\u52a0\u901f\u590d\u6742\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u5c06EEG\u89e3\u7801\u7684\u9519\u8bef\u76f8\u5173\u7535\u4f4d\u6574\u5408\u5230\u5956\u52b1\u5851\u5f62\u4e2d\uff0c\u57287\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u7684\u969c\u788d\u7269\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u52a0\u901f\u5b66\u4e60\u5e76\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u5148\u524d\u57fa\u4e8e\u8111\u7535\u56fe(EEG)\u7684\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5bfc\u822a\u6216\u4f4e\u7ef4\u8fd0\u52a8\u4efb\u52a1\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u795e\u7ecf\u8bc4\u4f30\u4fe1\u53f7\u662f\u5426\u80fd\u5728\u6d89\u53ca\u969c\u788d\u7269\u548c\u7cbe\u786e\u672b\u7aef\u6267\u884c\u5668\u63a7\u5236\u7684\u9ad8\u7ef4\u64cd\u4f5c\u4efb\u52a1\u4e2d\u6539\u8fdb\u7b56\u7565\u5b66\u4e60\u3002", "method": "\u5c06\u79bb\u7ebf\u8bad\u7ec3\u7684EEG\u5206\u7c7b\u5668\u89e3\u7801\u7684\u9519\u8bef\u76f8\u5173\u7535\u4f4d\u6574\u5408\u5230\u5956\u52b1\u5851\u5f62\u4e2d\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4eba\u7c7b\u53cd\u9988\u6743\u91cd\u7684\u5f71\u54cd\uff0c\u57287\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u7684\u969c\u788d\u7269\u4e30\u5bcc\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u795e\u7ecf\u53cd\u9988\u52a0\u901f\u4e86\u5f3a\u5316\u5b66\u4e60\uff0c\u6839\u636e\u4eba\u7c7b\u53cd\u9988\u6743\u91cd\u7684\u4e0d\u540c\uff0c\u4efb\u52a1\u6210\u529f\u7387\u6709\u65f6\u8d85\u8fc7\u7a00\u758f\u5956\u52b1\u57fa\u7ebf\uff1b\u6700\u4f73\u53cd\u9988\u6743\u91cd\u5728\u6240\u6709\u53d7\u8bd5\u8005\u4e2d\u4e00\u81f4\u52a0\u901f\u4e86\u5f3a\u5316\u5b66\u4e60\uff1b\u7559\u4e00\u53d7\u8bd5\u8005\u8bc4\u4f30\u8bc1\u5b9e\u6846\u67b6\u5bf9EEG\u89e3\u7801\u80fd\u529b\u7684\u4e2a\u4f53\u5dee\u5f02\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u57fa\u4e8eEEG\u7684\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u6269\u5c55\u5230\u8fd0\u52a8\u4efb\u52a1\u4e4b\u5916\uff0c\u4e3a\u4eba\u7c7b\u5bf9\u9f50\u7684\u64cd\u4f5c\u6280\u80fd\u83b7\u53d6\u63d0\u4f9b\u4e86\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2511.19262", "categories": ["cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.19262", "abs": "https://arxiv.org/abs/2511.19262", "authors": ["Przemyslaw Chojecki"], "title": "Psychometric Tests for AI Agents and Their Moduli Space", "comment": null, "summary": "We develop a moduli-theoretic view of psychometric test batteries for AI agents and connect it explicitly to the AAI score developed previously. First, we make precise the notion of an AAI functional on a battery and set out axioms that any reasonable autonomy/general intelligence score should satisfy. Second, we show that the composite index ('AAI-Index') defined previously is a special case of our AAI functional. Third, we introduce the notion of a cognitive core of an agent relative to a battery and define the associated AAI$_{\\textrm{core}}$ score as the restriction of an AAI functional to that core. Finally, we use these notions to describe invariants of batteries under evaluation-preserving symmetries and outline how moduli of equivalent batteries are organized.", "AI": {"tldr": "\u672c\u6587\u4ece\u6a21\u8bba\u89d2\u5ea6\u6784\u5efa\u4e86AI\u667a\u80fd\u4f53\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u7535\u6c60\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06AAI\u8bc4\u5206\u7cfb\u7edf\u5f62\u5f0f\u5316\u4e3a\u6ee1\u8db3\u7279\u5b9a\u516c\u7406\u7684AAI\u6cdb\u51fd\uff0c\u5e76\u5f15\u5165\u4e86\u8ba4\u77e5\u6838\u5fc3\u6982\u5ff5\u548c\u7535\u6c60\u7b49\u4ef7\u6027\u7814\u7a76\u3002", "motivation": "\u4e3aAI\u667a\u80fd\u4f53\u7684\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u7535\u6c60\u5efa\u7acb\u4e25\u683c\u7684\u6570\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u73b0\u6709\u7684AAI\u8bc4\u5206\u7cfb\u7edf\u7eb3\u5165\u7edf\u4e00\u7684\u6a21\u8bba\u6846\u67b6\uff0c\u5e76\u7814\u7a76\u6d4b\u8bd5\u7535\u6c60\u7684\u7b49\u4ef7\u6027\u548c\u4e0d\u53d8\u6027\u3002", "method": "1. \u5b9a\u4e49AAI\u6cdb\u51fd\u5e76\u8bbe\u5b9a\u5408\u7406\u7684\u81ea\u4e3b\u6027/\u901a\u7528\u667a\u80fd\u8bc4\u5206\u516c\u7406\uff1b2. \u8bc1\u660e\u73b0\u6709AAI-Index\u662fAAI\u6cdb\u51fd\u7684\u7279\u4f8b\uff1b3. \u5f15\u5165\u8ba4\u77e5\u6838\u5fc3\u6982\u5ff5\u5e76\u5b9a\u4e49AAI_core\u8bc4\u5206\uff1b4. \u7814\u7a76\u8bc4\u4f30\u4fdd\u6301\u5bf9\u79f0\u6027\u4e0b\u7684\u7535\u6c60\u4e0d\u53d8\u91cf\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u7535\u6c60\u7684\u6a21\u8bba\u6846\u67b6\uff0c\u5c06AAI\u8bc4\u5206\u7cfb\u7edf\u5f62\u5f0f\u5316\uff0c\u5b9a\u4e49\u4e86\u8ba4\u77e5\u6838\u5fc3\u8bc4\u5206\uff0c\u5e76\u63cf\u8ff0\u4e86\u7535\u6c60\u5728\u5bf9\u79f0\u53d8\u6362\u4e0b\u7684\u4e0d\u53d8\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aAI\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6570\u5b66\u57fa\u7840\uff0cAAI\u6cdb\u51fd\u6846\u67b6\u80fd\u591f\u7edf\u4e00\u73b0\u6709\u7684\u8bc4\u5206\u7cfb\u7edf\uff0c\u8ba4\u77e5\u6838\u5fc3\u6982\u5ff5\u6709\u52a9\u4e8e\u7406\u89e3\u667a\u80fd\u4f53\u7684\u672c\u8d28\u80fd\u529b\uff0c\u6a21\u8bba\u65b9\u6cd5\u4e3a\u6d4b\u8bd5\u7535\u6c60\u7684\u7b49\u4ef7\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2511.18910", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18910", "abs": "https://arxiv.org/abs/2511.18910", "authors": ["Samuel Cerezo", "Seong Hun Lee", "Javier Civera"], "title": "An Efficient Closed-Form Solution to Full Visual-Inertial State Initialization", "comment": "8 pages, 2 figures, 10 tables. Submitted to RA-L", "summary": "In this letter, we present a closed-form initialization method that recovers the full visual-inertial state without nonlinear optimization. Unlike previous approaches that rely on iterative solvers, our formulation yields analytical, easy-to-implement, and numerically stable solutions for reliable start-up. Our method builds on small-rotation and constant-velocity approximations, which keep the formulation compact while preserving the essential coupling between motion and inertial measurements. We further propose an observability-driven, two-stage initialization scheme that balances accuracy with initialization latency. Extensive experiments on the EuRoC dataset validate our assumptions: our method achieves 10-20% lower initialization error than optimization-based approaches, while using 4x shorter initialization windows and reducing computational cost by 5x.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u975e\u7ebf\u6027\u4f18\u5316\u7684\u95ed\u5f0f\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u6062\u590d\u5b8c\u6574\u7684\u89c6\u89c9-\u60ef\u6027\u72b6\u6001\uff0c\u76f8\u6bd4\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\u5177\u6709\u66f4\u4f4e\u7684\u521d\u59cb\u5316\u8bef\u5dee\u3001\u66f4\u77ed\u7684\u521d\u59cb\u5316\u7a97\u53e3\u548c\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9-\u60ef\u6027\u521d\u59cb\u5316\u65b9\u6cd5\u4f9d\u8d56\u8fed\u4ee3\u6c42\u89e3\u5668\uff0c\u5b58\u5728\u6570\u503c\u4e0d\u7a33\u5b9a\u3001\u5b9e\u73b0\u590d\u6742\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u3001\u6613\u5b9e\u73b0\u7684\u521d\u59cb\u5316\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5c0f\u65cb\u8f6c\u548c\u6052\u5b9a\u901f\u5ea6\u8fd1\u4f3c\uff0c\u6784\u5efa\u7d27\u51d1\u7684\u95ed\u5f0f\u89e3\uff1b\u91c7\u7528\u57fa\u4e8e\u53ef\u89c2\u6d4b\u6027\u7684\u4e24\u9636\u6bb5\u521d\u59cb\u5316\u65b9\u6848\uff0c\u5e73\u8861\u7cbe\u5ea6\u4e0e\u521d\u59cb\u5316\u5ef6\u8fdf\u3002", "result": "\u5728EuRoC\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\u521d\u59cb\u5316\u8bef\u5dee\u964d\u4f4e10-20%\uff0c\u521d\u59cb\u5316\u7a97\u53e3\u7f29\u77ed4\u500d\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e5\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5206\u6790\u6027\u3001\u6613\u5b9e\u73b0\u4e14\u6570\u503c\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u53ef\u9760\u5730\u8fdb\u884c\u89c6\u89c9-\u60ef\u6027\u7cfb\u7edf\u542f\u52a8\u3002"}}
{"id": "2511.19304", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19304", "abs": "https://arxiv.org/abs/2511.19304", "authors": ["Jiayi Zhang", "Yiran Peng", "Fanqi Kong", "Yang Cheng", "Yifan Wu", "Zhaoyang Yu", "Jinyu Xiang", "Jianhao Ruan", "Jinlin Wang", "Maojia Song", "HongZhang Liu", "Xiangru Tang", "Bang Liu", "Chenglin Wu", "Yuyu Luo"], "title": "AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning", "comment": null, "summary": "Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.", "AI": {"tldr": "\u63d0\u51fa\u4e86AutoEnv\u6846\u67b6\u6765\u81ea\u52a8\u751f\u6210\u5f02\u6784\u73af\u5883\uff0c\u6784\u5efa\u4e86AutoEnv-36\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u7ec4\u4ef6\u9009\u62e9\u3001\u4f18\u5316\u548c\u8bc4\u4f30\u76848\u79cd\u5b66\u4e60\u65b9\u6cd5\u3002\u7814\u7a76\u53d1\u73b0\u5355\u4e00\u5b66\u4e60\u65b9\u6cd5\u5728\u8de8\u73af\u5883\u6cdb\u5316\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u73af\u5883\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u901a\u5e38\u5728\u5355\u4e00\u56fa\u5b9a\u73af\u5883\u4e2d\u81ea\u6211\u8fdb\u5316\uff0c\u7f3a\u4e4f\u5bf9\u8de8\u5f02\u6784\u73af\u5883\u5b66\u4e60\u80fd\u529b\u7684\u8861\u91cf\u6807\u51c6\u3002\u9700\u8981\u6807\u51c6\u5316\u7684\u5f02\u6784\u73af\u5883\u96c6\u5408\u548c\u7edf\u4e00\u7684\u5b66\u4e60\u8868\u793a\u65b9\u6cd5\u6765\u7814\u7a76\u8de8\u73af\u5883\u6cdb\u5316\u95ee\u9898\u3002", "method": "1) \u63d0\u51faAutoEnv\u6846\u67b6\uff0c\u5c06\u73af\u5883\u5206\u89e3\u4e3a\u8f6c\u79fb\u3001\u89c2\u5bdf\u548c\u5956\u52b1\u7684\u5206\u5e03\uff0c\u4f4e\u6210\u672c\u751f\u6210\u5f02\u6784\u4e16\u754c\uff1b2) \u6784\u5efaAutoEnv-36\u6570\u636e\u96c6\uff0836\u4e2a\u73af\u5883\uff0c358\u4e2a\u9a8c\u8bc1\u5173\u5361\uff09\uff1b3) \u5c06\u667a\u80fd\u4f53\u5b66\u4e60\u5f62\u5f0f\u5316\u4e3a\u57fa\u4e8e\u7ec4\u4ef6\u9009\u62e9\u3001\u4f18\u5316\u548c\u8bc4\u4f30\u7684\u4e09\u9636\u6bb5\u8fc7\u7a0b\uff0c\u8bbe\u8ba18\u79cd\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "1) 7\u4e2a\u8bed\u8a00\u6a21\u578b\u5728AutoEnv-36\u4e0a\u4ec5\u83b7\u5f9712-49%\u7684\u5f52\u4e00\u5316\u5956\u52b1\uff0c\u8bc1\u660e\u5176\u6311\u6218\u6027\uff1b2) \u5355\u4e00\u5b66\u4e60\u65b9\u6cd5\u5728\u73af\u5883\u6570\u91cf\u589e\u52a0\u65f6\u6548\u679c\u5feb\u901f\u4e0b\u964d\uff1b3) \u73af\u5883\u81ea\u9002\u5e94\u65b9\u6cd5\u9009\u62e9\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u968f\u65b9\u6cd5\u7a7a\u95f4\u6269\u5927\u800c\u6536\u76ca\u9012\u51cf\u3002", "conclusion": "\u56fa\u5b9a\u5b66\u4e60\u65b9\u6cd5\u65e0\u6cd5\u6269\u5c55\u5230\u5f02\u6784\u73af\u5883\uff0c\u9700\u8981\u73af\u5883\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u9009\u62e9\u3002AutoEnv\u548cAutoEnv-36\u4e3a\u7814\u7a76\u8de8\u73af\u5883\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u6d4b\u8bd5\u5e73\u53f0\uff0c\u63ed\u793a\u4e86\u53ef\u6269\u5c55\u8de8\u73af\u5883\u6cdb\u5316\u7684\u5fc5\u8981\u6027\u548c\u5f53\u524d\u5c40\u9650\u6027\u3002"}}
{"id": "2511.18950", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18950", "abs": "https://arxiv.org/abs/2511.18950", "authors": ["Juntao Gao", "Feiyang Ye", "Jing Zhang", "Wenjing Qian"], "title": "Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation", "comment": "11 pages, 5 figures", "summary": "Vision-Language-Action (VLA) models have emerged as a powerful paradigm in Embodied AI. However, the significant computational overhead of processing redundant visual tokens remains a critical bottleneck for real-time robotic deployment. While standard token pruning techniques can alleviate this, these task-agnostic methods struggle to preserve task-critical visual information. To address this challenge, simultaneously preserving both the holistic context and fine-grained details for precise action, we propose Compressor-VLA, a novel hybrid instruction-conditioned token compression framework designed for efficient, task-oriented compression of visual information in VLA models. The proposed Compressor-VLA framework consists of two token compression modules: a Semantic Task Compressor (STC) that distills holistic, task-relevant context, and a Spatial Refinement Compressor (SRC) that preserves fine-grained spatial details. This compression is dynamically modulated by the natural language instruction, allowing for the adaptive condensation of task-relevant visual information. Experimentally, extensive evaluations demonstrate that Compressor-VLA achieves a competitive success rate on the LIBERO benchmark while reducing FLOPs by 59% and the visual token count by over 3x compared to its baseline. The real-robot deployments on a dual-arm robot platform validate the model's sim-to-real transferability and practical applicability. Moreover, qualitative analyses reveal that our instruction guidance dynamically steers the model's perceptual focus toward task-relevant objects, thereby validating the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86Compressor-VLA\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u4efb\u52a1\u538b\u7f29\u5668\u548c\u7a7a\u95f4\u7ec6\u5316\u538b\u7f29\u5668\u5b9e\u73b0\u6307\u4ee4\u6761\u4ef6\u5316\u7684\u89c6\u89c9\u4ee4\u724c\u538b\u7f29\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u5177\u8eabAI\u4e2d\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u73b0\u6709\u4ee4\u724c\u526a\u679d\u65b9\u6cd5\u96be\u4ee5\u4fdd\u7559\u4efb\u52a1\u5173\u952e\u4fe1\u606f\uff0c\u9700\u8981\u4efb\u52a1\u5bfc\u5411\u7684\u9ad8\u6548\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6307\u4ee4\u6761\u4ef6\u5316\u4ee4\u724c\u538b\u7f29\u6846\u67b6\uff0c\u5305\u542b\u8bed\u4e49\u4efb\u52a1\u538b\u7f29\u5668\uff08\u63d0\u53d6\u6574\u4f53\u4efb\u52a1\u76f8\u5173\u4e0a\u4e0b\u6587\uff09\u548c\u7a7a\u95f4\u7ec6\u5316\u538b\u7f29\u5668\uff08\u4fdd\u7559\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u7ec6\u8282\uff09\uff0c\u52a8\u6001\u8c03\u8282\u538b\u7f29\u8fc7\u7a0b\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u7ade\u4e89\u529b\uff0cFLOPs\u51cf\u5c1159%\uff0c\u89c6\u89c9\u4ee4\u724c\u6570\u91cf\u51cf\u5c113\u500d\u4ee5\u4e0a\uff0c\u771f\u5b9e\u673a\u5668\u4eba\u90e8\u7f72\u9a8c\u8bc1\u4e86\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "Compressor-VLA\u901a\u8fc7\u6307\u4ee4\u5f15\u5bfc\u52a8\u6001\u805a\u7126\u4efb\u52a1\u76f8\u5173\u5bf9\u8c61\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4efb\u52a1\u5bfc\u5411\u89c6\u89c9\u4fe1\u606f\u538b\u7f29\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19314", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19314", "abs": "https://arxiv.org/abs/2511.19314", "authors": ["Jaewoo Lee", "Archiki Prasad", "Justin Chih-Yao Chen", "Zaid Khan", "Elias Stengel-Eskin", "Mohit Bansal"], "title": "PRInTS: Reward Modeling for Long-Horizon Information Seeking", "comment": "18 pages, code: https://github.com/G-JWLee/PRInTS", "summary": "Information-seeking is a core capability for AI agents, requiring them to gather and reason over tool-generated information across long trajectories. However, such multi-step information-seeking tasks remain challenging for agents backed by language models. While process reward models (PRMs) can guide agents by ranking candidate steps at test-time, existing PRMs, designed for short reasoning with binary judgment, cannot capture richer dimensions of information-seeking steps, such as tool interactions and reasoning over tool outputs, nor handle the rapidly growing context in long-horizon tasks. To address these limitations, we introduce PRInTS, a generative PRM trained with dual capabilities: (1) dense scoring based on the PRM's reasoning across multiple step quality dimensions (e.g., interpretation of tool outputs, tool call informativeness) and (2) trajectory summarization that compresses the growing context while preserving essential information for step evaluation. Extensive evaluations across FRAMES, GAIA (levels 1-3), and WebWalkerQA (easy-hard) benchmarks on multiple models, along with ablations, reveal that best-of-n sampling with PRInTS enhances information-seeking abilities of open-source models as well as specialized agents, matching or surpassing the performance of frontier models with a much smaller backbone agent and outperforming other strong reward modeling baselines.", "AI": {"tldr": "PRInTS\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u5bc6\u96c6\u8bc4\u5206\u548c\u8f68\u8ff9\u6458\u8981\u6765\u89e3\u51b3\u591a\u6b65\u4fe1\u606f\u5bfb\u6c42\u4efb\u52a1\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u5f00\u6e90\u6a21\u578b\u548c\u4e13\u7528\u4ee3\u7406\u7684\u4fe1\u606f\u5bfb\u6c42\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b(PRMs)\u8bbe\u8ba1\u7528\u4e8e\u77ed\u63a8\u7406\u548c\u4e8c\u5143\u5224\u65ad\uff0c\u65e0\u6cd5\u6355\u6349\u4fe1\u606f\u5bfb\u6c42\u6b65\u9aa4\u4e2d\u66f4\u4e30\u5bcc\u7684\u7ef4\u5ea6\uff08\u5982\u5de5\u5177\u4ea4\u4e92\u3001\u5de5\u5177\u8f93\u51fa\u63a8\u7406\uff09\uff0c\u4e5f\u65e0\u6cd5\u5904\u7406\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u5feb\u901f\u589e\u957f\u7684\u4e0a\u6587\u3002", "method": "\u5f15\u5165PRInTS\uff0c\u4e00\u4e2a\u5177\u6709\u53cc\u91cd\u80fd\u529b\u7684\u751f\u6210\u5f0fPRM\uff1a(1)\u57fa\u4e8e\u591a\u4e2a\u6b65\u9aa4\u8d28\u91cf\u7ef4\u5ea6\u7684\u5bc6\u96c6\u8bc4\u5206\uff1b(2)\u8f68\u8ff9\u6458\u8981\uff0c\u538b\u7f29\u589e\u957f\u7684\u4e0a\u6587\u540c\u65f6\u4fdd\u7559\u6b65\u9aa4\u8bc4\u4f30\u6240\u9700\u7684\u5173\u952e\u4fe1\u606f\u3002", "result": "\u5728FRAMES\u3001GAIA\u548cWebWalkerQA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u4f7f\u7528PRInTS\u7684\u6700\u4f73n\u91c7\u6837\u589e\u5f3a\u4e86\u5f00\u6e90\u6a21\u578b\u548c\u4e13\u7528\u4ee3\u7406\u7684\u4fe1\u606f\u5bfb\u6c42\u80fd\u529b\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u524d\u6cbf\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e14\u4f7f\u7528\u66f4\u5c0f\u7684\u9aa8\u5e72\u4ee3\u7406\u3002", "conclusion": "PRInTS\u901a\u8fc7\u5bc6\u96c6\u8bc4\u5206\u548c\u8f68\u8ff9\u6458\u8981\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6b65\u4fe1\u606f\u5bfb\u6c42\u4efb\u52a1\u4e2d\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u7684\u4fe1\u606f\u5bfb\u6c42\u80fd\u529b\uff0c\u4f18\u4e8e\u5176\u4ed6\u5f3a\u5956\u52b1\u5efa\u6a21\u57fa\u7ebf\u3002"}}
{"id": "2511.19011", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19011", "abs": "https://arxiv.org/abs/2511.19011", "authors": ["Jiale Zhang", "Yeqiang Qian", "Tong Qin", "Mingyang Jiang", "Siyuan Chen", "Ming Yang"], "title": "End-to-end Autonomous Vehicle Following System using Monocular Fisheye Camera", "comment": null, "summary": "The increase in vehicle ownership has led to increased traffic congestion, more accidents, and higher carbon emissions. Vehicle platooning is a promising solution to address these issues by improving road capacity and reducing fuel consumption. However, existing platooning systems face challenges such as reliance on lane markings and expensive high-precision sensors, which limits their general applicability. To address these issues, we propose a vehicle following framework that expands its capability from restricted scenarios to general scenario applications using only a camera. This is achieved through our newly proposed end-to-end method, which improves overall driving performance. The method incorporates a semantic mask to address causal confusion in multi-frame data fusion. Additionally, we introduce a dynamic sampling mechanism to precisely track the trajectories of preceding vehicles. Extensive closed-loop validation in real-world vehicle experiments demonstrates the system's ability to follow vehicles in various scenarios, outperforming traditional multi-stage algorithms. This makes it a promising solution for cost-effective autonomous vehicle platooning. A complete real-world vehicle experiment is available at https://youtu.be/zL1bcVb9kqQ.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4f7f\u7528\u6444\u50cf\u5934\u7684\u7aef\u5230\u7aef\u8f66\u8f86\u8ddf\u968f\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u63a9\u7801\u548c\u52a8\u6001\u91c7\u6837\u673a\u5236\u89e3\u51b3\u591a\u5e27\u6570\u636e\u878d\u5408\u4e2d\u7684\u56e0\u679c\u6df7\u6dc6\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u8f66\u8f86\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u8f66\u8f86\u4fdd\u6709\u91cf\u589e\u52a0\u5bfc\u81f4\u4ea4\u901a\u62e5\u5835\u3001\u4e8b\u6545\u548c\u78b3\u6392\u653e\u95ee\u9898\uff0c\u73b0\u6709\u7f16\u961f\u7cfb\u7edf\u4f9d\u8d56\u8f66\u9053\u7ebf\u548c\u6602\u8d35\u4f20\u611f\u5668\uff0c\u9650\u5236\u4e86\u901a\u7528\u6027\u3002", "method": "\u4f7f\u7528\u7aef\u5230\u7aef\u65b9\u6cd5\uff0c\u7ed3\u5408\u8bed\u4e49\u63a9\u7801\u89e3\u51b3\u591a\u5e27\u6570\u636e\u878d\u5408\u7684\u56e0\u679c\u6df7\u6dc6\uff0c\u5f15\u5165\u52a8\u6001\u91c7\u6837\u673a\u5236\u7cbe\u786e\u8ddf\u8e2a\u524d\u8f66\u8f68\u8ff9\u3002", "result": "\u5728\u771f\u5b9e\u8f66\u8f86\u95ed\u73af\u9a8c\u8bc1\u4e2d\uff0c\u8be5\u7cfb\u7edf\u80fd\u5728\u591a\u79cd\u573a\u666f\u4e0b\u8ddf\u968f\u524d\u8f66\uff0c\u4f18\u4e8e\u4f20\u7edf\u591a\u9636\u6bb5\u7b97\u6cd5\u3002", "conclusion": "\u8fd9\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u4f4e\u6210\u672c\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7f16\u961f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19031", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19031", "abs": "https://arxiv.org/abs/2511.19031", "authors": ["Haihang Wu", "Yuchen Zhou"], "title": "Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors", "comment": null, "summary": "Monocular Simultaneous Localization and Mapping (SLAM) aims to estimate a robot's pose while simultaneously reconstructing an unknown 3D scene using a single camera. While existing monocular SLAM systems generate detailed 3D geometry through dense scene representations, they are computationally expensive due to the need for iterative optimization. To address this challenge, MASt3R-SLAM utilizes learned 3D reconstruction priors, enabling more efficient and accurate estimation of both 3D structures and camera poses. However, MASt3R-SLAM is limited to single-agent operation. In this paper, we extend MASt3R-SLAM to introduce the first multi-agent monocular dense SLAM system. Each agent performs local SLAM using a 3D reconstruction prior, and their individual maps are fused into a globally consistent map through a loop-closure-based map fusion mechanism. Our approach improves computational efficiency compared to state-of-the-art methods, while maintaining similar mapping accuracy when evaluated on real-world datasets.", "AI": {"tldr": "\u5c06\u5355\u667a\u80fd\u4f53MASt3R-SLAM\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u5355\u76ee\u7a20\u5bc6SLAM\u7cfb\u7edf\uff0c\u901a\u8fc7\u73af\u8def\u95ed\u5408\u673a\u5236\u878d\u5408\u5c40\u90e8\u5730\u56fe\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387", "motivation": "\u73b0\u6709\u5355\u76eeSLAM\u7cfb\u7edf\u8ba1\u7b97\u6210\u672c\u9ad8\uff0cMASt3R-SLAM\u867d\u7136\u5229\u7528\u5b66\u4e60\u5148\u9a8c\u63d0\u9ad8\u4e86\u6548\u7387\u4f46\u4ec5\u9650\u4e8e\u5355\u667a\u80fd\u4f53\u64cd\u4f5c\uff0c\u9700\u8981\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u573a\u666f", "method": "\u6bcf\u4e2a\u667a\u80fd\u4f53\u4f7f\u75283D\u91cd\u5efa\u5148\u9a8c\u8fdb\u884c\u5c40\u90e8SLAM\uff0c\u901a\u8fc7\u73af\u8def\u95ed\u5408\u673a\u5236\u5c06\u4e2a\u4f53\u5730\u56fe\u878d\u5408\u4e3a\u5168\u5c40\u4e00\u81f4\u5730\u56fe", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u4f3c\u7684\u5efa\u56fe\u7cbe\u5ea6", "conclusion": "\u6210\u529f\u5b9e\u73b0\u4e86\u9996\u4e2a\u591a\u667a\u80fd\u4f53\u5355\u76ee\u7a20\u5bc6SLAM\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u7684\u53ef\u884c\u6027"}}
{"id": "2511.19094", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19094", "abs": "https://arxiv.org/abs/2511.19094", "authors": ["David Bricher", "Andreas Mueller"], "title": "Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework", "comment": "MDPI Sensors, published 22 November 2025", "summary": "Over the last years collaborative robots have gained great success in manufacturing applications where human and robot work together in close proximity. However, current ISO/TS-15066-compliant implementations often limit the efficiency of collaborative tasks due to conservative speed restrictions. For this reason, this paper introduces a deep-learning-based human-robot-safety framework (HRSF) that aims at a dynamical adaptation of robot velocities depending on the separation distance between human and robot while respecting maximum biomechanical force and pressure limits. The applicability of the framework was investigated for four different deep learning approaches that can be used for human body extraction: human body recognition, human body segmentation, human pose estimation, and human body part segmentation. Unlike conventional industrial safety systems, the proposed HRSF differentiates individual human body parts from other objects, enabling optimized robot process execution. Experiments demonstrated a quantitative reduction in cycle time of up to 15% compared to conventional safety technology.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4eba\u673a\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u673a\u5668\u4eba\u901f\u5ea6\u6765\u63d0\u5347\u534f\u4f5c\u6548\u7387\uff0c\u76f8\u6bd4\u4f20\u7edf\u5b89\u5168\u6280\u672f\u53ef\u51cf\u5c1115%\u7684\u5faa\u73af\u65f6\u95f4", "motivation": "\u5f53\u524d\u7b26\u5408ISO/TS-15066\u6807\u51c6\u7684\u4eba\u673a\u534f\u4f5c\u5b9e\u73b0\u7531\u4e8e\u4fdd\u5b88\u7684\u901f\u5ea6\u9650\u5236\u800c\u9650\u5236\u4e86\u4efb\u52a1\u6548\u7387\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u5b89\u5168\u6846\u67b6", "method": "\u5f00\u53d1\u6df1\u5ea6\u5b66\u4e60\u4eba\u673a\u5b89\u5168\u6846\u67b6\uff0c\u4f7f\u7528\u56db\u79cd\u4eba\u4f53\u63d0\u53d6\u65b9\u6cd5\uff08\u4eba\u4f53\u8bc6\u522b\u3001\u4eba\u4f53\u5206\u5272\u3001\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u3001\u4eba\u4f53\u90e8\u4f4d\u5206\u5272\uff09\u6765\u533a\u5206\u4e0d\u540c\u8eab\u4f53\u90e8\u4f4d\uff0c\u5b9e\u73b0\u57fa\u4e8e\u5206\u79bb\u8ddd\u79bb\u7684\u52a8\u6001\u901f\u5ea6\u8c03\u6574", "result": "\u5b9e\u9a8c\u8bc1\u660e\u76f8\u6bd4\u4f20\u7edf\u5b89\u5168\u6280\u672f\uff0c\u5faa\u73af\u65f6\u95f4\u6700\u591a\u53ef\u51cf\u5c1115%", "conclusion": "\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u4eba\u673a\u534f\u4f5c\u6548\u7387\uff0c\u4e3a\u667a\u80fd\u5236\u9020\u63d0\u4f9b\u4e86\u66f4\u4f18\u5316\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.19135", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19135", "abs": "https://arxiv.org/abs/2511.19135", "authors": ["Pascal Goldschmid", "Aamir Ahmad"], "title": "Autonomous Docking of Multi-Rotor UAVs on Blimps under the Influence of Wind Gusts", "comment": "13 pages, 8 figures, 8 tables", "summary": "Multi-rotor UAVs face limited flight time due to battery constraints. Autonomous docking on blimps with onboard battery recharging and data offloading offers a promising solution for extended UAV missions. However, the vulnerability of blimps to wind gusts causes trajectory deviations, requiring precise, obstacle-aware docking strategies. To this end, this work introduces two key novelties: (i) a temporal convolutional network that predicts blimp responses to wind gusts, enabling rapid gust detection and estimation of points where the wind gust effect has subsided; (ii) a model predictive controller (MPC) that leverages these predictions to compute collision-free trajectories for docking, enabled by a novel obstacle avoidance method for close-range manoeuvres near the blimp. Simulation results show our method outperforms a baseline constant-velocity model of the blimp significantly across different scenarios. We further validate the approach in real-world experiments, demonstrating the first autonomous multi-rotor docking control strategy on blimps shown outside simulation. Source code is available here https://github.com/robot-perception-group/multi_rotor_airship_docking.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\u5728\u98de\u8247\u4e0a\u81ea\u4e3b\u5bf9\u63a5\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u65f6\u95f4\u5377\u79ef\u7f51\u7edc\u9884\u6d4b\u98de\u8247\u5bf9\u98ce\u6270\u52a8\u7684\u54cd\u5e94\uff0c\u5e76\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\u5b9e\u73b0\u907f\u969c\u5bf9\u63a5\u3002", "motivation": "\u89e3\u51b3\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\u56e0\u7535\u6c60\u9650\u5236\u5bfc\u81f4\u7684\u98de\u884c\u65f6\u95f4\u77ed\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u98de\u8247\u4e0a\u5b9e\u73b0\u81ea\u4e3b\u5bf9\u63a5\u8fdb\u884c\u5145\u7535\u548c\u6570\u636e\u4f20\u8f93\uff0c\u4f46\u98de\u8247\u6613\u53d7\u98ce\u6270\u5f71\u54cd\u8f68\u8ff9\uff0c\u9700\u8981\u7cbe\u786e\u7684\u5bf9\u63a5\u7b56\u7565\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u5377\u79ef\u7f51\u7edc\u9884\u6d4b\u98de\u8247\u5bf9\u98ce\u6270\u52a8\u7684\u54cd\u5e94\uff0c\u5feb\u901f\u68c0\u6d4b\u98ce\u6270\u5e76\u4f30\u8ba1\u98ce\u6270\u6d88\u9000\u70b9\uff1b\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\u8ba1\u7b97\u65e0\u78b0\u649e\u5bf9\u63a5\u8f68\u8ff9\uff0c\u91c7\u7528\u65b0\u578b\u907f\u969c\u65b9\u6cd5\u5904\u7406\u8fd1\u8ddd\u79bb\u673a\u52a8\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u98de\u8247\u6052\u5b9a\u901f\u5ea6\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\uff1b\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u9996\u4e2a\u5728\u4eff\u771f\u5916\u5c55\u793a\u7684\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\u5728\u98de\u8247\u4e0a\u7684\u81ea\u4e3b\u5bf9\u63a5\u63a7\u5236\u7b56\u7565\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\u5728\u53d7\u98ce\u6270\u98de\u8247\u4e0a\u7684\u81ea\u4e3b\u5bf9\u63a5\uff0c\u4e3a\u5ef6\u957f\u65e0\u4eba\u673a\u4efb\u52a1\u65f6\u95f4\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19201", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19201", "abs": "https://arxiv.org/abs/2511.19201", "authors": ["Ann-Sophia M\u00fcller", "Moonkwang Jeong", "Jiyuan Tian", "Meng Zhang", "Tian Qiu"], "title": "Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap", "comment": "6 pages, 6 figures, IEEE International Conference on Robotics and Automation (ICRA)", "summary": "Untethered magnetic manipulation of biomedical millirobots has a high potential for minimally invasive surgical applications. However, it is still challenging to exert high actuation forces on the small robots over a large distance. Permanent magnets offer stronger magnetic torques and forces than electromagnetic coils, however, feedback control is more difficult. As proven by Earnshaw's theorem, it is not possible to achieve a stable magnetic trap in 3D by static permanent magnets. Here, we report a stable 2D magnetic force trap by an array of permanent magnets to control a millirobot. The trap is located in an open space with a tunable distance to the magnet array in the range of 20 - 120mm, which is relevant to human anatomical scales. The design is achieved by a novel GPU-accelerated optimization algorithm that uses mean squared error (MSE) and Adam optimizer to efficiently compute the optimal angles for any number of magnets in the array. The algorithm is verified using numerical simulation and physical experiments with an array of two magnets. A millirobot is successfully trapped and controlled to follow a complex trajectory. The algorithm demonstrates high scalability by optimizing the angles for 100 magnets in under three seconds. Moreover, the optimization workflow can be adapted to optimize a permanent magnet array to achieve the desired force vector fields.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u6c38\u78c1\u4f53\u9635\u5217\u5b9e\u73b0\u7a33\u5b9a2D\u78c1\u529b\u9677\u9631\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a7\u5236\u533b\u7597\u5fae\u578b\u673a\u5668\u4eba\uff0c\u901a\u8fc7GPU\u52a0\u901f\u4f18\u5316\u7b97\u6cd5\u9ad8\u6548\u8ba1\u7b97\u78c1\u4f53\u6700\u4f18\u89d2\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u572820-120mm\u8ddd\u79bb\u8303\u56f4\u5185\u7684\u6709\u6548\u64cd\u63a7\u3002", "motivation": "\u89e3\u51b3\u5728\u533b\u7597\u5e94\u7528\u4e2d\u65e0\u7f06\u78c1\u63a7\u5fae\u578b\u673a\u5668\u4eba\u96be\u4ee5\u5728\u8fdc\u8ddd\u79bb\u65bd\u52a0\u9ad8\u9a71\u52a8\u529b\u7684\u95ee\u9898\uff0c\u540c\u65f6\u514b\u670d\u6c38\u78c1\u4f53\u53cd\u9988\u63a7\u5236\u56f0\u96be\u53caEarnshaw\u5b9a\u7406\u9650\u52363D\u7a33\u5b9a\u78c1\u9677\u9631\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u5747\u65b9\u8bef\u5dee\u548cAdam\u4f18\u5316\u5668\u7684GPU\u52a0\u901f\u4f18\u5316\u7b97\u6cd5\uff0c\u8ba1\u7b97\u6c38\u78c1\u4f53\u9635\u5217\u7684\u6700\u4f18\u89d2\u5ea6\u914d\u7f6e\uff0c\u5b9e\u73b02D\u78c1\u529b\u9677\u9631\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u548c\u53cc\u78c1\u4f53\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u572820-120mm\u8ddd\u79bb\u8303\u56f4\u5185\u7684\u7a33\u5b9a2D\u78c1\u529b\u9677\u9631\uff0c\u5fae\u578b\u673a\u5668\u4eba\u80fd\u591f\u8ddf\u968f\u590d\u6742\u8f68\u8ff9\uff0c\u7b97\u6cd5\u5177\u6709\u9ad8\u6269\u5c55\u6027\uff0c\u53ef\u57283\u79d2\u5185\u4f18\u5316100\u4e2a\u78c1\u4f53\u89d2\u5ea6\u3002", "conclusion": "\u8be5\u6c38\u78c1\u4f53\u9635\u5217\u8bbe\u8ba1\u548c\u4f18\u5316\u65b9\u6cd5\u4e3a\u533b\u7597\u5fae\u578b\u673a\u5668\u4eba\u7684\u7cbe\u786e\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u7b97\u6cd5\u53ef\u6269\u5c55\u81f3\u4f18\u5316\u4efb\u610f\u6240\u9700\u529b\u77e2\u91cf\u573a\u3002"}}
{"id": "2511.19211", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19211", "abs": "https://arxiv.org/abs/2511.19211", "authors": ["Prabhat Kumar", "Chandra Prakash", "Josh Pinskier", "David Howard", "Matthijs Langelaar"], "title": "Soft pneumatic grippers: Topology optimization, 3D-printing and experimental validation", "comment": "9 Figures", "summary": "This paper presents a systematic topology optimization framework for designing a soft pneumatic gripper (SPG), explicitly considering the design-dependent nature of the actuating load. The load is modeled using Darcy's law with an added drainage term. A 2D soft arm unit is optimized by formulating it as a compliant mechanism design problem using the robust formulation. The problem is posed as a min-max optimization, where the output deformations of blueprint and eroded designs are considered. A volume constraint is imposed on the blueprint part, while a strain-energy constraint is enforced on the eroded part. The MMA is employed to solve the optimization problem and obtain the optimized soft unit. Finite element analysis with the Ogden material model confirms that the optimized 2D unit outperforms a conventional rectangular design under pneumatic loading. The optimized 2D unit is extruded to obtain a 3D module, and ten such units are assembled to create a soft arm. Deformation profiles of the optimized arm are analysed under different pressure loads. Four arms are 3D-printed and integrated with a supporting structure to realize the proposed SPG. The gripping performance of the SPG is demonstrated on objects with different weights, sizes, stiffness, and shapes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u62d3\u6251\u4f18\u5316\u6846\u67b6\u6765\u8bbe\u8ba1\u8f6f\u6c14\u52a8\u6293\u53d6\u5668\uff0c\u8003\u8651\u4e86\u8bbe\u8ba1\u4f9d\u8d56\u7684\u9a71\u52a8\u8f7d\u8377\u7279\u6027\uff0c\u901a\u8fc7Darcy\u5b9a\u5f8b\u5efa\u6a21\u8f7d\u8377\uff0c\u4f18\u5316\u4e862D\u8f6f\u81c2\u5355\u5143\u5e76\u6269\u5c55\u52303D\u6a21\u5757\uff0c\u6700\u7ec8\u5236\u9020\u51fa\u6027\u80fd\u4f18\u8d8a\u7684\u8f6f\u6c14\u52a8\u6293\u53d6\u5668\u3002", "motivation": "\u73b0\u6709\u8f6f\u6c14\u52a8\u6293\u53d6\u5668\u8bbe\u8ba1\u7f3a\u4e4f\u5bf9\u9a71\u52a8\u8f7d\u8377\u8bbe\u8ba1\u4f9d\u8d56\u7279\u6027\u7684\u7cfb\u7edf\u8003\u8651\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u663e\u5f0f\u5904\u7406\u8fd9\u79cd\u4f9d\u8d56\u5173\u7cfb\u7684\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Darcy\u5b9a\u5f8b\u5efa\u6a21\u6c14\u52a8\u8f7d\u8377\uff0c\u91c7\u7528\u7a33\u5065\u516c\u5f0f\u5c062D\u8f6f\u81c2\u5355\u5143\u8bbe\u8ba1\u8868\u8ff0\u4e3a\u67d4\u987a\u673a\u6784\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7min-max\u4f18\u5316\u8003\u8651\u84dd\u56fe\u548c\u4fb5\u8680\u8bbe\u8ba1\u7684\u8f93\u51fa\u53d8\u5f62\uff0c\u4f7f\u7528MMA\u7b97\u6cd5\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u3002", "result": "\u4f18\u5316\u76842D\u5355\u5143\u5728\u6c14\u52a8\u8f7d\u8377\u4e0b\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u77e9\u5f62\u8bbe\u8ba1\uff0c3D\u6253\u5370\u7684\u8f6f\u6c14\u52a8\u6293\u53d6\u5668\u80fd\u591f\u6709\u6548\u6293\u53d6\u4e0d\u540c\u91cd\u91cf\u3001\u5c3a\u5bf8\u3001\u521a\u5ea6\u548c\u5f62\u72b6\u7684\u7269\u4f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u62d3\u6251\u4f18\u5316\u6846\u67b6\u6210\u529f\u8bbe\u8ba1\u4e86\u9ad8\u6027\u80fd\u8f6f\u6c14\u52a8\u6293\u53d6\u5668\uff0c\u9a8c\u8bc1\u4e86\u8003\u8651\u8bbe\u8ba1\u4f9d\u8d56\u8f7d\u8377\u7684\u4f18\u5316\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u8f6f\u673a\u5668\u4eba\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u5de5\u5177\u3002"}}
{"id": "2511.19236", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19236", "abs": "https://arxiv.org/abs/2511.19236", "authors": ["Yuxuan Wang", "Haobin Jiang", "Shiqing Yao", "Ziluo Ding", "Zongqing Lu"], "title": "SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control", "comment": "23 pages, 8 figures, 11 tables", "summary": "Existing humanoid control systems often rely on teleoperation or modular generation pipelines that separate language understanding from physical execution. However, the former is entirely human-driven, and the latter lacks tight alignment between language commands and physical behaviors. In this paper, we present SENTINEL, a fully end-to-end language-action model for humanoid whole-body control. We construct a large-scale dataset by tracking human motions in simulation using a pretrained whole body controller, combined with their text annotations. The model directly maps language commands and proprioceptive inputs to low-level actions without any intermediate representation. The model generates action chunks using flow matching, which can be subsequently refined by a residual action head for real-world deployment. Our method exhibits strong semantic understanding and stable execution on humanoid robots in both simulation and real-world deployment, and also supports multi-modal extensions by converting inputs into texts.", "AI": {"tldr": "SENTINEL\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u7528\u4e8e\u4eba\u5f62\u673a\u5668\u4eba\u5168\u8eab\u63a7\u5236\uff0c\u76f4\u63a5\u5c06\u8bed\u8a00\u547d\u4ee4\u548c\u672c\u4f53\u611f\u89c9\u8f93\u5165\u6620\u5c04\u5230\u4f4e\u7ea7\u52a8\u4f5c\uff0c\u65e0\u9700\u4e2d\u95f4\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u5f62\u673a\u5668\u4eba\u63a7\u5236\u7cfb\u7edf\u4f9d\u8d56\u9065\u64cd\u4f5c\u6216\u6a21\u5757\u5316\u751f\u6210\u7ba1\u9053\uff0c\u524d\u8005\u5b8c\u5168\u7531\u4eba\u7c7b\u9a71\u52a8\uff0c\u540e\u8005\u8bed\u8a00\u7406\u89e3\u4e0e\u7269\u7406\u6267\u884c\u5206\u79bb\uff0c\u7f3a\u4e4f\u7d27\u5bc6\u5bf9\u9f50\u3002", "method": "\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u7684\u5168\u8eab\u63a7\u5236\u5668\u5728\u6a21\u62df\u4e2d\u8ffd\u8e2a\u4eba\u7c7b\u52a8\u4f5c\u5e76\u6dfb\u52a0\u6587\u672c\u6807\u6ce8\u3002\u6a21\u578b\u4f7f\u7528\u6d41\u5339\u914d\u751f\u6210\u52a8\u4f5c\u5757\uff0c\u5e76\u901a\u8fc7\u6b8b\u5dee\u52a8\u4f5c\u5934\u8fdb\u884c\u7ec6\u5316\u4ee5\u9002\u5e94\u5b9e\u9645\u90e8\u7f72\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4eba\u5f62\u673a\u5668\u4eba\u7684\u6a21\u62df\u548c\u5b9e\u9645\u90e8\u7f72\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u8bed\u4e49\u7406\u89e3\u548c\u7a33\u5b9a\u6267\u884c\u80fd\u529b\uff0c\u5e76\u652f\u6301\u901a\u8fc7\u5c06\u8f93\u5165\u8f6c\u6362\u4e3a\u6587\u672c\u6765\u5b9e\u73b0\u591a\u6a21\u6001\u6269\u5c55\u3002", "conclusion": "SENTINEL\u63d0\u4f9b\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u8bed\u8a00-\u52a8\u4f5c\u6620\u5c04\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u8bed\u8a00\u547d\u4ee4\u4e0e\u7269\u7406\u884c\u4e3a\u4e4b\u95f4\u7684\u7d27\u5bc6\u5bf9\u9f50\uff0c\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19315", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19315", "abs": "https://arxiv.org/abs/2511.19315", "authors": ["Weiliang Tang", "Jialin Gao", "Jia-Hui Pan", "Gang Wang", "Li Erran Li", "Yunhui Liu", "Mingyu Ding", "Pheng-Ann Heng", "Chi-Wing Fu"], "title": "Rethinking Intermediate Representation for VLM-based Robot Manipulation", "comment": null, "summary": "Vision-Language Model (VLM) is an important component to enable robust robot manipulation. Yet, using it to translate human instructions into an action-resolvable intermediate representation often needs a tradeoff between VLM-comprehensibility and generalizability. Inspired by context-free grammar, we design the Semantic Assembly representation named SEAM, by decomposing the intermediate representation into vocabulary and grammar. Doing so leads us to a concise vocabulary of semantically-rich operations and a VLM-friendly grammar for handling diverse unseen tasks. In addition, we design a new open-vocabulary segmentation paradigm with a retrieval-augmented few-shot learning strategy to localize fine-grained object parts for manipulation, effectively with the shortest inference time over all state-of-the-art parallel works. Also, we formulate new metrics for action-generalizability and VLM-comprehensibility, demonstrating the compelling performance of SEAM over mainstream representations on both aspects. Extensive real-world experiments further manifest its SOTA performance under varying settings and tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86SEAM\u8868\u793a\u6cd5\uff0c\u901a\u8fc7\u5c06\u4e2d\u95f4\u8868\u793a\u5206\u89e3\u4e3a\u8bcd\u6c47\u548c\u8bed\u6cd5\uff0c\u5b9e\u73b0VLM\u53ef\u7406\u89e3\u6027\u548c\u901a\u7528\u6027\u7684\u5e73\u8861\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u5c55\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5c06\u4eba\u7c7b\u6307\u4ee4\u8f6c\u6362\u4e3a\u53ef\u64cd\u4f5c\u4e2d\u95f4\u8868\u793a\u65f6\uff0cVLM\u53ef\u7406\u89e3\u6027\u548c\u901a\u7528\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1SEAM\u8bed\u4e49\u7ec4\u88c5\u8868\u793a\uff0c\u5206\u89e3\u4e3a\u8bed\u4e49\u4e30\u5bcc\u7684\u64cd\u4f5c\u8bcd\u6c47\u548cVLM\u53cb\u597d\u7684\u8bed\u6cd5\uff1b\u63d0\u51fa\u68c0\u7d22\u589e\u5f3a\u7684\u5c11\u6837\u672c\u5b66\u4e60\u7b56\u7565\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7269\u4f53\u90e8\u4ef6\u5b9a\u4f4d\u3002", "result": "\u5728\u6240\u6709\u5e76\u884c\u5de5\u4f5c\u4e2d\u63a8\u7406\u65f6\u95f4\u6700\u77ed\uff0c\u5728\u52a8\u4f5c\u901a\u7528\u6027\u548cVLM\u53ef\u7406\u89e3\u6027\u4e24\u65b9\u9762\u90fd\u4f18\u4e8e\u4e3b\u6d41\u8868\u793a\u65b9\u6cd5\u3002", "conclusion": "SEAM\u8868\u793a\u5728\u591a\u6837\u5316\u8bbe\u7f6e\u548c\u4efb\u52a1\u4e0b\u5c55\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u6709\u6548\u5e73\u8861\u4e86VLM\u53ef\u7406\u89e3\u6027\u548c\u4efb\u52a1\u901a\u7528\u6027\u3002"}}
{"id": "2511.19377", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19377", "abs": "https://arxiv.org/abs/2511.19377", "authors": ["Mamoon Aamir", "Mariyam Sattar", "Naveed Ur Rehman Junejo", "Aqsa Zafar Abbasi"], "title": "Deployment Dynamics and Optimization of Novel Space Antenna Deployable Mechanism", "comment": null, "summary": "Given the increasing need for large aperture antennas in space missions, the difficulty of fitting such structures into small launch vehicles has prompted the design of deployable antenna systems. The thesis introduces a new Triple Scissors Deployable Truss Mechanism (TSDTM) for space antenna missions. The new mechanism is to be stowed during launch and efficiently deploy in orbit, offering maximum aperture size while taking up minimal launch volume. The thesis covers the entire design process from geometric modeling, kinematic analysis with screw theory and Newtonian approaches, dynamic analysis by eigenvalue and simulation methods, and verification with SolidWorks. In addition, optimization routines were coded based on Support Vector Machines for material choice in LEO environments and machine learning method for geometric setup. The TSDTM presented has enhanced structural dynamics with good comparison between simulation and analytical predictions. The structure optimized proved highly accurate, with a deviation of just 1.94% between machine learning-predicted and simulated natural frequencies, demonstrating the potential of incorporating AI-based methods in space structural design.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u4e09\u91cd\u526a\u5f0f\u53ef\u5c55\u5f00\u6841\u67b6\u673a\u6784(TSDTM)\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u578b\u7a7a\u95f4\u5929\u7ebf\u5728\u53d1\u5c04\u65f6\u7684\u4f53\u79ef\u9650\u5236\u95ee\u9898\uff0c\u8be5\u673a\u6784\u53ef\u5728\u8f68\u9053\u4e0a\u9ad8\u6548\u5c55\u5f00\uff0c\u63d0\u4f9b\u6700\u5927\u5b54\u5f84\u540c\u65f6\u5360\u7528\u6700\u5c0f\u53d1\u5c04\u4f53\u79ef\u3002", "motivation": "\u968f\u7740\u7a7a\u95f4\u4efb\u52a1\u5bf9\u5927\u578b\u5b54\u5f84\u5929\u7ebf\u9700\u6c42\u7684\u589e\u52a0\uff0c\u5c06\u8fd9\u4e9b\u7ed3\u6784\u88c5\u5165\u5c0f\u578b\u8fd0\u8f7d\u706b\u7bad\u7684\u56f0\u96be\u4fc3\u4f7f\u4e86\u53ef\u5c55\u5f00\u5929\u7ebf\u7cfb\u7edf\u7684\u8bbe\u8ba1\u9700\u6c42\u3002", "method": "\u91c7\u7528\u51e0\u4f55\u5efa\u6a21\u3001\u87ba\u65cb\u7406\u8bba\u548c\u725b\u987f\u65b9\u6cd5\u7684\u8fd0\u52a8\u5b66\u5206\u6790\u3001\u7279\u5f81\u503c\u548c\u4eff\u771f\u65b9\u6cd5\u7684\u52a8\u529b\u5b66\u5206\u6790\uff0c\u4ee5\u53ca\u57fa\u4e8e\u652f\u6301\u5411\u91cf\u673a\u7684\u6750\u6599\u9009\u62e9\u4f18\u5316\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u51e0\u4f55\u8bbe\u7f6e\u4f18\u5316\u3002", "result": "TSDTM\u5177\u6709\u589e\u5f3a\u7684\u7ed3\u6784\u52a8\u529b\u5b66\u6027\u80fd\uff0c\u4eff\u771f\u4e0e\u89e3\u6790\u9884\u6d4b\u7ed3\u679c\u543b\u5408\u826f\u597d\u3002\u4f18\u5316\u7ed3\u6784\u7cbe\u5ea6\u9ad8\uff0c\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4e0e\u4eff\u771f\u56fa\u6709\u9891\u7387\u504f\u5dee\u4ec5\u4e3a1.94%\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5c06\u57fa\u4e8eAI\u7684\u65b9\u6cd5\u7eb3\u5165\u7a7a\u95f4\u7ed3\u6784\u8bbe\u8ba1\u7684\u6f5c\u529b\uff0c\u4e3a\u5927\u578b\u53ef\u5c55\u5f00\u7a7a\u95f4\u7ed3\u6784\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19433", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19433", "abs": "https://arxiv.org/abs/2511.19433", "authors": ["Dong Jing", "Gang Wang", "Jiaqi Liu", "Weiliang Tang", "Zelong Sun", "Yunchao Yao", "Zhenyu Wei", "Yunhui Liu", "Zhiwu Lu", "Mingyu Ding"], "title": "Mixture of Horizons in Action Chunking", "comment": "15 pages, 14 figures", "summary": "Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\\textbf{action chunk length}$ used during training, termed $\\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate the trade-off, we propose a $\\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk into several segments with different horizons, processes them in parallel with a shared action transformer, and fuses outputs with a light linear gate. It has three appealing benefits. 1) MoH exploits long-term foresight and short-term precision jointly within a single model, improving both performance and generalizability to complex tasks. 2) MoH is plug-and-play for full-attention action modules with minimal training or inference overhead. 3) MoH enables dynamic inference with adaptive horizons, which selects stable actions through cross-horizon consensus, achieving 2.5$\\times$ higher throughput than baselines while preserving superior performance. Extensive experiments over flow-based policies $\u03c0_0$, $\u03c0_{0.5}$, and one-step regression policy $\u03c0_{\\text{reg}}$ demonstrate that MoH yields consistent and significant gains on both simulations and real-world tasks. Notably, under mixed-task setting, $\u03c0_{0.5}$ with MoH reaches a new state-of-the-art with 99$\\%$ average success rate on LIBERO after only $30k$ training iterations. Project page: https://github.com/Timsty1/MixtureOfHorizons", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u89c6\u91ce(MoH)\u7b56\u7565\u89e3\u51b3VLA\u6a21\u578b\u4e2d\u52a8\u4f5c\u5757\u957f\u5ea6\u9009\u62e9\u7684\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u5e76\u884c\u5904\u7406\u4e0d\u540c\u89c6\u91ce\u957f\u5ea6\u7684\u52a8\u4f5c\u6bb5\u5e76\u878d\u5408\u8f93\u51fa\uff0c\u540c\u65f6\u83b7\u5f97\u957f\u671f\u9884\u89c1\u6027\u548c\u77ed\u671f\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edfVLA\u6a21\u578b\u5728\u52a8\u4f5c\u5757\u957f\u5ea6\u9009\u62e9\u4e0a\u5b58\u5728\u56fa\u6709\u6743\u8861\uff1a\u957f\u89c6\u91ce\u63d0\u4f9b\u5168\u5c40\u9884\u89c1\u6027\u4f46\u964d\u4f4e\u7ec6\u7c92\u5ea6\u7cbe\u5ea6\uff0c\u77ed\u89c6\u91ce\u63d0\u5347\u5c40\u90e8\u63a7\u5236\u4f46\u96be\u4ee5\u5904\u7406\u957f\u671f\u4efb\u52a1\uff0c\u56fa\u5b9a\u5355\u89c6\u91ce\u9009\u62e9\u662f\u6b21\u4f18\u7684\u3002", "method": "\u5c06\u52a8\u4f5c\u5757\u91cd\u65b0\u6392\u5217\u4e3a\u591a\u4e2a\u4e0d\u540c\u89c6\u91ce\u957f\u5ea6\u7684\u6bb5\uff0c\u7528\u5171\u4eab\u52a8\u4f5c\u53d8\u6362\u5668\u5e76\u884c\u5904\u7406\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ebf\u6027\u95e8\u878d\u5408\u8f93\u51fa\uff0c\u652f\u6301\u52a8\u6001\u63a8\u7406\u548c\u81ea\u9002\u5e94\u89c6\u91ce\u9009\u62e9\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMoH\u5728\u6df7\u5408\u4efb\u52a1\u8bbe\u7f6e\u4e0b\u8fbe\u523099%\u5e73\u5747\u6210\u529f\u7387\u7684\u65b0SOTA\uff0c\u541e\u5410\u91cf\u6bd4\u57fa\u7ebf\u9ad82.5\u500d\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5747\u83b7\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MoH\u7b56\u7565\u6709\u6548\u7f13\u89e3\u4e86\u89c6\u91ce\u957f\u5ea6\u9009\u62e9\u7684\u6743\u8861\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u52a8\u6001\u81ea\u9002\u5e94\uff0c\u4e3aVLA\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u52a8\u4f5c\u89c4\u5212\u65b9\u6848\u3002"}}
