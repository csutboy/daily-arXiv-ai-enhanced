{"id": "2510.13369", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.13369", "abs": "https://arxiv.org/abs/2510.13369", "authors": ["Jacob Schaal"], "title": "A theory-based AI automation exposure index: Applying Moravec's Paradox to the US labor market", "comment": null, "summary": "This paper develops a theory-driven automation exposure index based on\nMoravec's Paradox. Scoring 19,000 O*NET tasks on performance variance, tacit\nknowledge, data abundance, and algorithmic gaps reveals that management, STEM,\nand sciences occupations show the highest exposure. In contrast, maintenance,\nagriculture, and construction show the lowest. The positive relationship\nbetween wages and exposure challenges the notion of skill-biased technological\nchange if AI substitutes for workers. At the same time, tacit knowledge\nexhibits a positive relationship with wages consistent with seniority-biased\ntechnological change. This index identifies fundamental automatability rather\nthan current capabilities, while also validating the AI annotation method\npioneered by Eloundou et al. (2024) with a correlation of 0.72. The\nnon-positive relationship with pre-LLM indices suggests a paradigm shift in\nautomation patterns."}
{"id": "2510.13790", "categories": ["econ.GN", "q-fin.EC", "q-fin.GN", "q-fin.PM", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2510.13790", "abs": "https://arxiv.org/abs/2510.13790", "authors": ["Victor Olkhov"], "title": "Market-Based Variance of Market Portfolio and of Entire Market", "comment": "28 pages", "summary": "We present the unified market-based description of returns and variances of\nthe trades with shares of a particular security, of the trades with shares of\nall securities in the market, and of the trades with the market portfolio. We\nconsider the investor who doesn't trade the shares of his portfolio he\ncollected at time t0 in the past. The investor observes the time series of the\ncurrent trades with all securities made in the market during the averaging\ninterval. The investor may convert these time series into the time series that\nmodel the trades with all securities as the trades with a single security and\ninto the time series that model the trades with the market portfolio as the\ntrades with a single security. That establishes the same description of the\nreturns and variances of the trades with a single security, the trades with all\nsecurities in the market, and the market portfolio. We show that the\nmarket-based variance, which accounts for the impact of random change of the\nvolumes of consecutive trades with securities, takes the form of Markowitz's\n(1952) portfolio variance if the volumes of consecutive trades with all market\nsecurities are assumed constant. That highlights that Markowitz's (1952)\nvariance ignores the effects of random volumes of consecutive trades. We\ncompare the market-based variances of the market portfolio and of the trades\nwith all market securities, consider the importance of the duration of the\naveraging interval, and explain the economic obstacles that limit the accuracy\nof the predictions of the returns and variances at best by Gaussian\ndistributions. The same methods describe the returns and variances of any\nportfolio and the trades with its securities."}
{"id": "2510.13791", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.13791", "abs": "https://arxiv.org/abs/2510.13791", "authors": ["Coleman Drake", "Mark K. Meiselbach", "Daniel Polsky"], "title": "Efficient Subsidy Targeting in the Health Insurance Marketplaces", "comment": null, "summary": "Enrollment in the Health Insurance Marketplaces created by the Affordable\nCare Act reached an all-time high of approximately 25 million Americans in\n2025, roughly doubling since enhanced premium tax credit subsidies were made\navailable in 2021. The scheduled expiration of enhanced subsidies in 2026 is\nestimated to leave over seven million Americans without health insurance\ncoverage. Ten states have created supplemental Marketplace subsidies, yet\nlittle attention has been paid to how to best structure these subsidies to\nmaximize coverage. Using administrative enrollment data from Maryland's\nMarketplace, we estimate demand for Marketplace coverage. Then, using estimated\nparameters and varying budget constraints, we simulate how to optimally\nallocate supplemental state premium subsidies to mitigate coverage losses from\nenhanced premium subsidy expiration. We find that premium sensitivity is\ngreatest among enrollees with incomes below 200 percent of the federal poverty\nlevel, where the marginal effect of an additional ten dollars in monthly\nsubsidies on the probability of coverage is approximately 6.5 percentage\npoints, and decreases to roughly 2.5 percentage points above 200 percent FPL.\nSimulation results indicate that each 10 million dollars in annual state\nsubsidies could retain roughly 5,000 enrollees, though the cost-effectiveness\nof these subsidies falls considerably once all enrollees below 200 percent of\nthe federal poverty level are fully subsidized. We conclude that states are\nwell positioned to mitigate, but not stop, coverage losses from expanded\npremium tax credit subsidy expiration."}
{"id": "2510.12963", "categories": ["stat.AP", "physics.soc-ph", "stat.ME", "60G70 (Primary) 62F15, 62G32, 62P30 (Secondary)", "I.6.4; J.2; G.3; J.7"], "pdf": "https://arxiv.org/pdf/2510.12963", "abs": "https://arxiv.org/abs/2510.12963", "authors": ["Parvez Anowar", "Nazmul Haque", "Md Asif Raihan", "Md Hadiuzzaman"], "title": "Trajectory-based real-time pedestrian crash prediction at intersections: A novel non-linear link function for block maxima led Bayesian GEV framework addressing heterogeneous traffic condition", "comment": "This manuscript is a preprint and has not yet been peer-reviewed. It\n  is currently being considered for submission to a peer-reviewed journal", "summary": "This study develops a real-time framework for estimating pedestrian crash\nrisk at signalized intersections under heterogeneous, non-lane-based traffic.\nExisting approaches often assume linear relationships between covariates and\nparameters, oversimplifying the complex, non-monotonic interactions among\ndifferent road users. To overcome this, the framework introduces a non-linear\nlink function within a Bayesian generalized extreme value (GEV) structure to\ncapture traffic variability more accurately. The framework applies extreme\nvalue theory through the block maxima approach using post-encroachment time as\na surrogate safety measure. A hierarchical Bayesian model incorporating both\nlinear and non-linear link functions into GEV parameters is estimated using\nMarkov Chain Monte Carlo simulation. It also introduces a behavior-normalized\nModified Crash Risk (MRC) formula to account for pedestrians' habitual\nrisk-taking behavior. Seven Bayesian hierarchical models were developed and\ncompared using deviance information criterion. Models employing non-linear link\nfunctions for the location and scale parameters significantly outperformed\ntheir linear counterparts. The results revealed that pedestrian speed has a\nnegative relationship with crash risk, while flow and speed of motorized\nvehicles, pedestrian flow, and non-motorized vehicles conflicting speed\ncontribute positively. The MRC formulation reduced overestimation and provided\ncrash predictions with 93% confidence. The integration of non-linear link\nfunctions enhances model flexibility, capturing the non-linear nature of\ntraffic extremes. The proposed MRC metric aligns crash risk estimates with\nreal-world pedestrian behavior in mixed-traffic environments. This framework\noffers a practical analytical tool for traffic engineers and planners to design\nadaptive signal control and pedestrian safety interventions before crashes\noccur."}
{"id": "2510.12911", "categories": ["econ.EM", "q-fin.RM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.12911", "abs": "https://arxiv.org/abs/2510.12911", "authors": ["Yasin Simsek"], "title": "Beyond Returns: A Candlestick-Based Approach to Spot Covariance Estimation", "comment": null, "summary": "Spot covariance estimation is commonly based on high-frequency open-to-close\nreturn data over short time windows, but such approaches face a trade-off\nbetween statistical accuracy and localization. In this paper, I introduce a new\nestimation framework using high-frequency candlestick data, which include open,\nhigh, low, and close prices, effectively addressing this trade-off. By\nexploiting the information contained in candlesticks, the proposed method\nimproves estimation accuracy relative to benchmarks while preserving local\nstructure. I further develop a test for spot covariance inference based on\ncandlesticks that demonstrates reasonable size control and a notable increase\nin power, particularly in small samples. Motivated by recent work in the\nfinance literature, I empirically test the market neutrality of the iShares\nBitcoin Trust ETF (IBIT) using 1-minute candlestick data for the full year of\n2024. The results show systematic deviations from market neutrality, especially\nin periods of market stress. An event study around FOMC announcements further\nillustrates the new method's ability to detect subtle shifts in response to\nrelatively mild information events."}
{"id": "2510.12810", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12810", "abs": "https://arxiv.org/abs/2510.12810", "authors": ["Lucas Böttcher"], "title": "Control of dynamical systems with neural networks", "comment": "23 pages, 14 figures, 1 table", "summary": "Control problems frequently arise in scientific and industrial applications,\nwhere the objective is to steer a dynamical system from an initial state to a\ndesired target state. Recent advances in deep learning and automatic\ndifferentiation have made applying these methods to control problems\nincreasingly practical. In this paper, we examine the use of neural networks\nand modern machine-learning libraries to parameterize control inputs across\ndiscrete-time and continuous-time systems, as well as deterministic and\nstochastic dynamics. We highlight applications in multiple domains, including\nbiology, engineering, physics, and medicine. For continuous-time dynamical\nsystems, neural ordinary differential equations (neural ODEs) offer a useful\napproach to parameterizing control inputs. For discrete-time systems, we show\nhow custom control-input parameterizations can be implemented and optimized\nusing automatic-differentiation methods. Overall, the methods presented provide\npractical solutions for control tasks that are computationally demanding or\nanalytically intractable, making them valuable for complex real-world\napplications."}
{"id": "2510.13369", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.13369", "abs": "https://arxiv.org/abs/2510.13369", "authors": ["Jacob Schaal"], "title": "A theory-based AI automation exposure index: Applying Moravec's Paradox to the US labor market", "comment": null, "summary": "This paper develops a theory-driven automation exposure index based on\nMoravec's Paradox. Scoring 19,000 O*NET tasks on performance variance, tacit\nknowledge, data abundance, and algorithmic gaps reveals that management, STEM,\nand sciences occupations show the highest exposure. In contrast, maintenance,\nagriculture, and construction show the lowest. The positive relationship\nbetween wages and exposure challenges the notion of skill-biased technological\nchange if AI substitutes for workers. At the same time, tacit knowledge\nexhibits a positive relationship with wages consistent with seniority-biased\ntechnological change. This index identifies fundamental automatability rather\nthan current capabilities, while also validating the AI annotation method\npioneered by Eloundou et al. (2024) with a correlation of 0.72. The\nnon-positive relationship with pre-LLM indices suggests a paradigm shift in\nautomation patterns."}
{"id": "2510.12866", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.12866", "abs": "https://arxiv.org/abs/2510.12866", "authors": ["Dantong Niu", "Yuvan Sharma", "Baifeng Shi", "Rachel Ding", "Matteo Gioia", "Haoru Xue", "Henry Tsai", "Konstantinos Kallidromitis", "Anirudh Pai", "Shankar Shastry", "Trevor Darrell", "Jitendra Malik", "Roei Herzig"], "title": "Learning to Grasp Anything by Playing with Random Toys", "comment": null, "summary": "Robotic manipulation policies often struggle to generalize to novel objects,\nlimiting their real-world utility. In contrast, cognitive science suggests that\nchildren develop generalizable dexterous manipulation skills by mastering a\nsmall set of simple toys and then applying that knowledge to more complex\nitems. Inspired by this, we study if similar generalization capabilities can\nalso be achieved by robots. Our results indicate robots can learn generalizable\ngrasping using randomly assembled objects that are composed from just four\nshape primitives: spheres, cuboids, cylinders, and rings. We show that training\non these \"toys\" enables robust generalization to real-world objects, yielding\nstrong zero-shot performance. Crucially, we find the key to this generalization\nis an object-centric visual representation induced by our proposed detection\npooling mechanism. Evaluated in both simulation and on physical robots, our\nmodel achieves a 67% real-world grasping success rate on the YCB dataset,\noutperforming state-of-the-art approaches that rely on substantially more\nin-domain data. We further study how zero-shot generalization performance\nscales by varying the number and diversity of training toys and the\ndemonstrations per toy. We believe this work offers a promising path to\nscalable and generalizable learning in robotic manipulation. Demonstration\nvideos, code, checkpoints and our dataset are available on our project page:\nhttps://lego-grasp.github.io/ ."}
{"id": "2510.13273", "categories": ["cs.SI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.13273", "abs": "https://arxiv.org/abs/2510.13273", "authors": ["Xinyi Zhao", "Anna I. Thoma", "Ralph Hertwig", "Dirk U. Wulff"], "title": "Mapping the gender attrition gap in academic psychology", "comment": null, "summary": "Although more women than men enter social science disciplines, they are\nunderrepresented at senior levels. To investigate this leaky pipeline, this\nstudy analyzed the career trajectories of 78,216 psychology researchers using\nlarge-scale bibliometric data. Despite overall constituting over 60\\% of these\nresearchers, women experienced consistently higher attrition rates than men,\nparticularly in the early years following their first publication. Academic\nperformance, particularly first-authored publications, was strongly associated\nwith early-career retention -- more so than collaboration networks or\ninstitutional environment. After controlling for gender differences in\npublication-, collaboration-, and institution-level factors, women remained\nmore likely to leave academia, especially in early-career stages, pointing to\npersistent barriers that hinder women's academic careers. These findings\nsuggest that in psychology and potentially other social science disciplines,\nthe core challenge lies in retention rather than recruitment, underscoring the\nneed for targeted, early-career interventions to promote long-term gender\nequity."}
{"id": "2510.12810", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12810", "abs": "https://arxiv.org/abs/2510.12810", "authors": ["Lucas Böttcher"], "title": "Control of dynamical systems with neural networks", "comment": "23 pages, 14 figures, 1 table", "summary": "Control problems frequently arise in scientific and industrial applications,\nwhere the objective is to steer a dynamical system from an initial state to a\ndesired target state. Recent advances in deep learning and automatic\ndifferentiation have made applying these methods to control problems\nincreasingly practical. In this paper, we examine the use of neural networks\nand modern machine-learning libraries to parameterize control inputs across\ndiscrete-time and continuous-time systems, as well as deterministic and\nstochastic dynamics. We highlight applications in multiple domains, including\nbiology, engineering, physics, and medicine. For continuous-time dynamical\nsystems, neural ordinary differential equations (neural ODEs) offer a useful\napproach to parameterizing control inputs. For discrete-time systems, we show\nhow custom control-input parameterizations can be implemented and optimized\nusing automatic-differentiation methods. Overall, the methods presented provide\npractical solutions for control tasks that are computationally demanding or\nanalytically intractable, making them valuable for complex real-world\napplications."}
{"id": "2510.12864", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12864", "abs": "https://arxiv.org/abs/2510.12864", "authors": ["Imran Khan"], "title": "From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models", "comment": "13 pages. Code and data are available at\n  https://github.com/strongSoda/LITERAL-TO-LIBERAL", "summary": "Large Language Models (LLMs) are increasingly being deployed as the reasoning\nengines for agentic AI systems, yet they exhibit a critical flaw: a rigid\nadherence to explicit rules that leads to decisions misaligned with human\ncommon sense and intent. This \"rule-rigidity\" is a significant barrier to\nbuilding trustworthy autonomous agents. While prior work has shown that\nsupervised fine-tuning (SFT) with human explanations can mitigate this issue,\nSFT is computationally expensive and inaccessible to many practitioners. To\naddress this gap, we introduce the Rule-Intent Distinction (RID) Framework, a\nnovel, low-compute meta-prompting technique designed to elicit human-aligned\nexception handling in LLMs in a zero-shot manner. The RID framework provides\nthe model with a structured cognitive schema for deconstructing tasks,\nclassifying rules, weighing conflicting outcomes, and justifying its final\ndecision. We evaluated the RID framework against baseline and Chain-of-Thought\n(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced\njudgment across diverse domains. Our human-verified results demonstrate that\nthe RID framework significantly improves performance, achieving a 95% Human\nAlignment Score (HAS), compared to 80% for the baseline and 75% for CoT.\nFurthermore, it consistently produces higher-quality, intent-driven reasoning.\nThis work presents a practical, accessible, and effective method for steering\nLLMs from literal instruction-following to liberal, goal-oriented reasoning,\npaving the way for more reliable and pragmatic AI agents."}
{"id": "2510.12809", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12809", "abs": "https://arxiv.org/abs/2510.12809", "authors": ["Antonio Max"], "title": "High vs. Low AGI: Ontology and Conceptual Taxonomy for Geopolitical Coherence", "comment": "11 pages, 1 table", "summary": "The rapid progression of Artificial General Intelligence (AGI) research\ndemands conceptual tools capable of distinguishing between systems developed\nfor open, commercial integration and those destined for sovereign, securitized\ndeployments. Without such distinctions, risk assessments and regulatory debates\ncollapse AGI into legacy dual-use frameworks that are ill-suited for these\nresources, capturing the possibility of civilian and military application but\noverlooking the distinct societal lineages yielded by corporate and state-grade\narchitectures. This paper proposes a taxonomy distinguishing low-AGI and\nhigh-AGI, clarifying how commercial-economic and security-sovereign\narchitectures can be distinguished not only by function, but by the social and\npolitical ecosystems that produce them. The taxonomy builds on international\nrelations concepts of \"high/low politics,\" viewed through the lens of\nconstrual-level theory, which allows it to even capture how cooperation and\nconflict may coexist in the context of AGI's emerging geopolitical stakes. By\nembedding AGI within power structures and securitization theory, this\ncontribution extends dual-use discourse through an ontological taxonomy that\nenables more granular risk assessment and governance design--equipping\npolicymakers and researchers to anticipate security dilemmas, institutional\ndemands, and technical-political spillovers in the international system."}
{"id": "2510.13790", "categories": ["econ.GN", "q-fin.EC", "q-fin.GN", "q-fin.PM", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2510.13790", "abs": "https://arxiv.org/abs/2510.13790", "authors": ["Victor Olkhov"], "title": "Market-Based Variance of Market Portfolio and of Entire Market", "comment": "28 pages", "summary": "We present the unified market-based description of returns and variances of\nthe trades with shares of a particular security, of the trades with shares of\nall securities in the market, and of the trades with the market portfolio. We\nconsider the investor who doesn't trade the shares of his portfolio he\ncollected at time t0 in the past. The investor observes the time series of the\ncurrent trades with all securities made in the market during the averaging\ninterval. The investor may convert these time series into the time series that\nmodel the trades with all securities as the trades with a single security and\ninto the time series that model the trades with the market portfolio as the\ntrades with a single security. That establishes the same description of the\nreturns and variances of the trades with a single security, the trades with all\nsecurities in the market, and the market portfolio. We show that the\nmarket-based variance, which accounts for the impact of random change of the\nvolumes of consecutive trades with securities, takes the form of Markowitz's\n(1952) portfolio variance if the volumes of consecutive trades with all market\nsecurities are assumed constant. That highlights that Markowitz's (1952)\nvariance ignores the effects of random volumes of consecutive trades. We\ncompare the market-based variances of the market portfolio and of the trades\nwith all market securities, consider the importance of the duration of the\naveraging interval, and explain the economic obstacles that limit the accuracy\nof the predictions of the returns and variances at best by Gaussian\ndistributions. The same methods describe the returns and variances of any\nportfolio and the trades with its securities."}
{"id": "2510.12986", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.12986", "abs": "https://arxiv.org/abs/2510.12986", "authors": ["Mohammad Ahmadi Gharehtoragh", "David R Johnson"], "title": "Surrogate Models to Predict Wave Hydrodynamics on Evolving Landscapes", "comment": null, "summary": "Coastal planners using probabilistic risk assessments to evaluate structural\nflood risk reduction projects may wish to simulate the hydrodynamics associated\nwith large suites of tropical cyclones in large ensembles of landscapes: with\nand without projects' implementation; over decades of their useful lifetimes;\nand under multiple scenarios reflecting uncertainty about sea level rise, land\nsubsidence, and other factors. Wave action can be a substantial contributor to\nflood losses and overtopping of structural features like levees and floodwalls,\nbut numerical methods solving for wave dynamics are computationally expensive,\npotentially limiting budget-constrained planning efforts. In this study, we\npresent and evaluate the performance of deep learning-based surrogate models\nfor predicting peak significant wave heights under a variety of relevant use\ncases: predicting waves with or without modeled peak storm surge as a feature,\npredicting wave heights while simultaneously predicting peak storm surge, or\nusing storm surge predicted by another surrogate model as an input feature. All\nmodels incorporate landscape morphological elements (e.g., elevation,\nroughness, canopy) and global boundary conditions (e.g., sea level) in addition\nto tropical cyclone characteristics as predictive features to improve accuracy\nas landscapes evolve over time. Using simulations from Louisiana's 2023 Coastal\nMaster Plan as a case study, we demonstrate suitable accuracy of surrogate\nmodels for planning-level studies, with a two-sided Kolmogorov-Smirnov test\nindicating no significant difference between significant wave heights generated\nby the Simulating Waves Nearshore model and those predicted by our surrogate\nmodels in approximately 89% of grid cells and landscapes evaluated in the\nstudy, with performance varying by landscape and model. On average, the models\nproduced a root mean squared error of 0.05-0.06 m."}
{"id": "2510.13148", "categories": ["econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13148", "abs": "https://arxiv.org/abs/2510.13148", "authors": ["Tatsuru Kikuchi"], "title": "Nonparametric Identification of Spatial Treatment Effect Boundaries: Evidence from Bank Branch Consolidation", "comment": "58 pages, 8 figures, 9 tables", "summary": "I develop a nonparametric framework for identifying spatial boundaries of\ntreatment effects without imposing parametric functional form restrictions. The\nmethod employs local linear regression with data-driven bandwidth selection to\nflexibly estimate spatial decay patterns and detect treatment effect\nboundaries. Monte Carlo simulations demonstrate that the nonparametric approach\nexhibits lower bias and correctly identifies the absence of boundaries when\nnone exist, unlike parametric methods that may impose spurious spatial\npatterns. I apply this framework to bank branch openings during 2015--2020,\nmatching 5,743 new branches to 5.9 million mortgage applications across 14,209\ncensus tracts. The analysis reveals that branch proximity significantly affects\nloan application volume (8.5\\% decline per 10 miles) but not approval rates,\nconsistent with branches stimulating demand through local presence while credit\ndecisions remain centralized. Examining branch survival during the digital\ntransformation era (2010--2023), I find a non-monotonic relationship with area\nincome: high-income areas experience more closures despite conventional wisdom.\nThis counterintuitive pattern reflects strategic consolidation of redundant\nbranches in over-banked wealthy urban areas rather than discrimination against\npoor neighborhoods. Controlling for branch density, urbanization, and\ncompetition, the direct income effect diminishes substantially, with branch\ndensity emerging as the primary determinant of survival. These findings\ndemonstrate the necessity of flexible nonparametric methods for detecting\ncomplex spatial patterns that parametric models would miss, and challenge\nsimplistic narratives about banking deserts by revealing the organizational\ncomplexity underlying spatial consolidation decisions."}
{"id": "2510.12832", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12832", "abs": "https://arxiv.org/abs/2510.12832", "authors": ["Alistair Brash", "Junyi Lu", "Bruce Stephen", "Blair Brown", "Robert Atkinson", "Craig Michie", "Fraser MacIntyre", "Christos Tachtatzis"], "title": "Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation", "comment": null, "summary": "Limited visibility of power distribution network power flows at the low\nvoltage level presents challenges to both distribution network operators from a\nplanning perspective and distribution system operators from a congestion\nmanagement perspective. Forestalling these challenges through scenario analysis\nis confounded by the lack of realistic and coherent load data across\nrepresentative distribution feeders. Load profiling approaches often rely on\nsummarising demand through typical profiles, which oversimplifies the\ncomplexity of substation-level operations and limits their applicability in\nspecific power system studies. Sampling methods, and more recently generative\nmodels, have attempted to address this through synthesising representative\nloads from historical exemplars; however, while these approaches can\napproximate load shapes to a convincing degree of fidelity, the co-behaviour\nbetween substations, which ultimately impacts higher voltage level network\noperation, is often overlooked. This limitation will become even more\npronounced with the increasing integration of low-carbon technologies, as\nestimates of base loads fail to capture load diversity. To address this gap, a\nConditional Diffusion model for synthesising daily active and reactive power\nprofiles at the low voltage distribution substation level is proposed. The\nevaluation of fidelity is demonstrated through conventional metrics capturing\ntemporal and statistical realism, as well as power flow modelling. The results\nshow synthesised load profiles are plausible both independently and as a cohort\nin a wider power systems context. The Conditional Diffusion model is\nbenchmarked against both naive and state-of-the-art models to demonstrate its\neffectiveness in producing realistic scenarios on which to base sub-regional\npower distribution network planning and operations."}
{"id": "2510.13790", "categories": ["econ.GN", "q-fin.EC", "q-fin.GN", "q-fin.PM", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2510.13790", "abs": "https://arxiv.org/abs/2510.13790", "authors": ["Victor Olkhov"], "title": "Market-Based Variance of Market Portfolio and of Entire Market", "comment": "28 pages", "summary": "We present the unified market-based description of returns and variances of\nthe trades with shares of a particular security, of the trades with shares of\nall securities in the market, and of the trades with the market portfolio. We\nconsider the investor who doesn't trade the shares of his portfolio he\ncollected at time t0 in the past. The investor observes the time series of the\ncurrent trades with all securities made in the market during the averaging\ninterval. The investor may convert these time series into the time series that\nmodel the trades with all securities as the trades with a single security and\ninto the time series that model the trades with the market portfolio as the\ntrades with a single security. That establishes the same description of the\nreturns and variances of the trades with a single security, the trades with all\nsecurities in the market, and the market portfolio. We show that the\nmarket-based variance, which accounts for the impact of random change of the\nvolumes of consecutive trades with securities, takes the form of Markowitz's\n(1952) portfolio variance if the volumes of consecutive trades with all market\nsecurities are assumed constant. That highlights that Markowitz's (1952)\nvariance ignores the effects of random volumes of consecutive trades. We\ncompare the market-based variances of the market portfolio and of the trades\nwith all market securities, consider the importance of the duration of the\naveraging interval, and explain the economic obstacles that limit the accuracy\nof the predictions of the returns and variances at best by Gaussian\ndistributions. The same methods describe the returns and variances of any\nportfolio and the trades with its securities."}
{"id": "2510.12919", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12919", "abs": "https://arxiv.org/abs/2510.12919", "authors": ["Mouhyemen Khan", "Tatsuya Ibuki", "Abhijit Chatterjee"], "title": "Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation", "comment": "8 pages, 7 figures, under review", "summary": "Level set methods underpin modern safety techniques such as control barrier\nfunctions (CBFs), while also serving as implicit surface representations for\ngeometric shapes via distance fields. Inspired by these two paradigms, we\npropose a unified framework where the implicit surface itself acts as a CBF. We\nleverage Gaussian process (GP) implicit surface (GPIS) to represent the safety\nboundaries, using safety samples which are derived from sensor measurements to\ncondition the GP. The GP posterior mean defines the implicit safety surface\n(safety belief), while the posterior variance provides a robust safety margin.\nAlthough GPs have favorable properties such as uncertainty estimation and\nanalytical tractability, they scale cubically with data. To alleviate this\nissue, we develop a sparse solution called sparse Gaussian CBFs. To the best of\nour knowledge, GPIS have not been explicitly used to synthesize CBFs. We\nvalidate the approach on collision avoidance tasks in two settings: a simulated\n7-DOF manipulator operating around the Stanford bunny, and a quadrotor\nnavigating in 3D around a physical chair. In both cases, Gaussian CBFs (with\nand without sparsity) enable safe interaction and collision-free execution of\ntrajectories that would otherwise intersect the objects."}
{"id": "2510.12832", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12832", "abs": "https://arxiv.org/abs/2510.12832", "authors": ["Alistair Brash", "Junyi Lu", "Bruce Stephen", "Blair Brown", "Robert Atkinson", "Craig Michie", "Fraser MacIntyre", "Christos Tachtatzis"], "title": "Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation", "comment": null, "summary": "Limited visibility of power distribution network power flows at the low\nvoltage level presents challenges to both distribution network operators from a\nplanning perspective and distribution system operators from a congestion\nmanagement perspective. Forestalling these challenges through scenario analysis\nis confounded by the lack of realistic and coherent load data across\nrepresentative distribution feeders. Load profiling approaches often rely on\nsummarising demand through typical profiles, which oversimplifies the\ncomplexity of substation-level operations and limits their applicability in\nspecific power system studies. Sampling methods, and more recently generative\nmodels, have attempted to address this through synthesising representative\nloads from historical exemplars; however, while these approaches can\napproximate load shapes to a convincing degree of fidelity, the co-behaviour\nbetween substations, which ultimately impacts higher voltage level network\noperation, is often overlooked. This limitation will become even more\npronounced with the increasing integration of low-carbon technologies, as\nestimates of base loads fail to capture load diversity. To address this gap, a\nConditional Diffusion model for synthesising daily active and reactive power\nprofiles at the low voltage distribution substation level is proposed. The\nevaluation of fidelity is demonstrated through conventional metrics capturing\ntemporal and statistical realism, as well as power flow modelling. The results\nshow synthesised load profiles are plausible both independently and as a cohort\nin a wider power systems context. The Conditional Diffusion model is\nbenchmarked against both naive and state-of-the-art models to demonstrate its\neffectiveness in producing realistic scenarios on which to base sub-regional\npower distribution network planning and operations."}
{"id": "2510.12979", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.12979", "abs": "https://arxiv.org/abs/2510.12979", "authors": ["Wei Fan", "Wenlin Yao", "Zheng Li", "Feng Yao", "Xin Liu", "Liang Qiu", "Qingyu Yin", "Yangqiu Song", "Bing Yin"], "title": "DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping", "comment": "Under Review", "summary": "Large language models (LLMs) augmented with multi-step reasoning and action\ngeneration abilities have shown promise in leveraging external tools to tackle\ncomplex tasks that require long-horizon planning. However, existing approaches\neither rely on implicit planning in the reasoning stage or introduce explicit\nplanners without systematically addressing how to optimize the planning stage.\nAs evidence, we observe that under vanilla reinforcement learning (RL),\nplanning tokens exhibit significantly higher entropy than other action tokens,\nrevealing uncertain decision points that remain under-optimized. To address\nthis, we propose DeepPlanner, an end-to-end RL framework that effectively\nenhances the planning capabilities of deep research agents. Our approach shapes\ntoken-level advantage with an entropy-based term to allocate larger updates to\nhigh entropy tokens, and selectively upweights sample-level advantages for\nplanning-intensive rollouts. Extensive experiments across seven deep research\nbenchmarks demonstrate that DeepPlanner improves planning quality and achieves\nstate-of-the-art results under a substantially lower training budget."}
{"id": "2510.12814", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12814", "abs": "https://arxiv.org/abs/2510.12814", "authors": ["Gargi Sarkar", "Sandeep Kumar Shukla"], "title": "Cyber Slavery Infrastructures: A Socio-Technical Study of Forced Criminality in Transnational Cybercrime", "comment": null, "summary": "The rise of ``cyber slavery,\" a technologically facilitated variant of forced\ncriminality, signifies a concerning convergence of human trafficking and\ndigital exploitation. In Southeast Asia, trafficked individuals are\nincreasingly coerced into engaging in cybercrimes, including online fraud and\nfinancial phishing, frequently facilitated by international organized criminal\nnetworks. This study adopts a hybrid qualitative-computational methodology,\ncombining a systematic narrative review with case-level metadata extracted from\nreal-world cyber trafficking incidents through collaboration with Indian law\nenforcement agencies. We introduce a five-tier victimization framework that\noutlines the sequential state transitions of cyber-slavery victims, ranging\nfrom initial financial deception to physical exploitation, culminating in\nsystemic prosecution through trace-based misattribution. Furthermore, our\nfindings indicate that a significant socio-technical risk of cyber slavery is\nits capacity to evolve from forced to voluntary digital criminality, as\nvictims, initially compelled to engage in cyber-enabled crimes, may choose to\npersist in their involvement due to financial incentives and the perceived\nsecurity provided by digital anonymity. This legal-technological gap hampers\nvictim identification processes, imposing excessive pressure on law enforcement\nsystems dependent on binary legal categorizations, which ultimately hinders the\nimplementation of victim-centered investigative methods and increases the\nlikelihood of prosecutorial misclassification, thus reinforcing the structural\nobstacles to addressing cyber slavery."}
{"id": "2510.13517", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13517", "abs": "https://arxiv.org/abs/2510.13517", "authors": ["Maksym Koltunov", "Filippo Beltrami", "Luigi Grossi", "Nicola Blasuttigh"], "title": "The Impact of Renewable Energy Communities in the Italian Day-Ahead Electricity Market: A Scenario Analysis", "comment": null, "summary": "This paper evaluates the economic impact of Renewable Energy Communities\n(RECs) on the Italian wholesale power market. Combining a bottom-up engineering\napproach with a short-run economic impact assessment, the study begins by\nmapping existing and emerging RECs in Italy. We identify key characteristics of\nRECs, such as average installed capacity, institutional profiles of members,\ntypes of renewable systems used, and distribution across Italy's electricity\nmarket zones. This mapping yields representative REC configurations, which are\nemployed within a bottom-up engineering model to generate energy injection and\nself-consumption profiles for different REC prosumer and producer categories\n(residential, public, small and medium enterprise, non-profit organization, and\nstandalone installation), considering the different levels of solar irradiance\nin Italy based on latitude. These zonal results, aggregated on an hourly basis,\ninform the implementation of the synthetic counterfactual approach, which\ndevelops alternative scenarios (e.g., 5 GW target for REC-driven capacity set\nby Italian policy for 2027) to assess the impact of REC-driven injection and\nself-consumption on the Italian day-ahead power market. The findings suggest\nthat REC deployment can increase equilibrium quantities during daylight in most\nof the time, while decreasing equilibrium quantities mostly during the cold\nmonths, as electrified heating drives greater self-consumption and offsets\nlower grid injections. Both positive and negative effects on equilibrium\nquantities suggest that REC deployment also has a potential to reduce wholesale\nelectricity prices. Moreover, by reducing grid exchanges through higher\nself-consumption, REC proliferation can alleviate pressure on the distribution\nsystem."}
{"id": "2510.12897", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12897", "abs": "https://arxiv.org/abs/2510.12897", "authors": ["Sanjay Johnson", "Dirk Lauinger", "Sungho Shin", "François Pacaud"], "title": "ExaModelsPower.jl: A GPU-Compatible Modeling Library for Nonlinear Power System Optimization", "comment": null, "summary": "As GPU-accelerated mathematical programming techniques mature, there is\ngrowing interest in utilizing them to address the computational challenges of\npower system optimization. This paper introduces ExaModelsPower.jl, an\nopen-source modeling library for creating GPU-compatible nonlinear AC optimal\npower flow models. Built on ExaModels.jl, ExaModelsPower.jl provides a\nhigh-level interface that automatically generates all necessary callback\nfunctions for GPU solvers. The library is designed for large-scale problem\ninstances, which may include multiple time periods and security constraints.\nUsing ExaModelsPower.jl, we benchmark GPU and CPU solvers on open-source test\ncases. Our results show that GPU solvers can deliver up to two orders of\nmagnitude speedups compared to alternative tools on CPU for problems with more\nthan 20,000 variables and a solution precision of up to $10^{-4}$, while\nperformance for smaller instances or tighter tolerances may vary."}
{"id": "2510.13791", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.13791", "abs": "https://arxiv.org/abs/2510.13791", "authors": ["Coleman Drake", "Mark K. Meiselbach", "Daniel Polsky"], "title": "Efficient Subsidy Targeting in the Health Insurance Marketplaces", "comment": null, "summary": "Enrollment in the Health Insurance Marketplaces created by the Affordable\nCare Act reached an all-time high of approximately 25 million Americans in\n2025, roughly doubling since enhanced premium tax credit subsidies were made\navailable in 2021. The scheduled expiration of enhanced subsidies in 2026 is\nestimated to leave over seven million Americans without health insurance\ncoverage. Ten states have created supplemental Marketplace subsidies, yet\nlittle attention has been paid to how to best structure these subsidies to\nmaximize coverage. Using administrative enrollment data from Maryland's\nMarketplace, we estimate demand for Marketplace coverage. Then, using estimated\nparameters and varying budget constraints, we simulate how to optimally\nallocate supplemental state premium subsidies to mitigate coverage losses from\nenhanced premium subsidy expiration. We find that premium sensitivity is\ngreatest among enrollees with incomes below 200 percent of the federal poverty\nlevel, where the marginal effect of an additional ten dollars in monthly\nsubsidies on the probability of coverage is approximately 6.5 percentage\npoints, and decreases to roughly 2.5 percentage points above 200 percent FPL.\nSimulation results indicate that each 10 million dollars in annual state\nsubsidies could retain roughly 5,000 enrollees, though the cost-effectiveness\nof these subsidies falls considerably once all enrollees below 200 percent of\nthe federal poverty level are fully subsidized. We conclude that states are\nwell positioned to mitigate, but not stop, coverage losses from expanded\npremium tax credit subsidy expiration."}
{"id": "2510.12924", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.12924", "abs": "https://arxiv.org/abs/2510.12924", "authors": ["Pavel Pochobradský", "Ondřej Procházka", "Robert Pěnička", "Vojtěch Vonásek", "Martin Saska"], "title": "Geometric Model Predictive Path Integral for Agile UAV Control with Online Collision Avoidance", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "In this letter, we introduce Geometric Model Predictive Path Integral\n(GMPPI), a sampling-based controller capable of tracking agile trajectories\nwhile avoiding obstacles. In each iteration, GMPPI generates a large number of\ncandidate rollout trajectories and then averages them to create a nominal\ncontrol to be followed by the Unmanned Aerial Vehicle (UAV). We propose using\ngeometric SE(3) control to generate part of the rollout trajectories,\nsignificantly increasing precision in agile flight. Furthermore, we introduce\nvarying rollout simulation time step length and dynamic cost and noise\nparameters, vastly improving tracking performance of smooth and low-speed\ntrajectories over an existing Model Predictive Path Integral (MPPI)\nimplementation. Finally, we propose an integration of GMPPI with a stereo depth\ncamera, enabling online obstacle avoidance at high speeds, a crucial step\ntowards autonomous UAV flights in complex environments. The proposed controller\ncan track simulated agile reference trajectories with position error similar to\nthe geometric SE(3) controller. However, the same configuration of the proposed\ncontroller can avoid obstacles in a simulated forest environment at speeds of\nup to 13m/s, surpassing the performance of a state-of-the-art obstacle-aware\nplanner. In real-world experiments, GMPPI retains the capability to track agile\ntrajectories and avoids obstacles at speeds of up to 10m/s."}
{"id": "2510.12897", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12897", "abs": "https://arxiv.org/abs/2510.12897", "authors": ["Sanjay Johnson", "Dirk Lauinger", "Sungho Shin", "François Pacaud"], "title": "ExaModelsPower.jl: A GPU-Compatible Modeling Library for Nonlinear Power System Optimization", "comment": null, "summary": "As GPU-accelerated mathematical programming techniques mature, there is\ngrowing interest in utilizing them to address the computational challenges of\npower system optimization. This paper introduces ExaModelsPower.jl, an\nopen-source modeling library for creating GPU-compatible nonlinear AC optimal\npower flow models. Built on ExaModels.jl, ExaModelsPower.jl provides a\nhigh-level interface that automatically generates all necessary callback\nfunctions for GPU solvers. The library is designed for large-scale problem\ninstances, which may include multiple time periods and security constraints.\nUsing ExaModelsPower.jl, we benchmark GPU and CPU solvers on open-source test\ncases. Our results show that GPU solvers can deliver up to two orders of\nmagnitude speedups compared to alternative tools on CPU for problems with more\nthan 20,000 variables and a solution precision of up to $10^{-4}$, while\nperformance for smaller instances or tighter tolerances may vary."}
{"id": "2510.12985", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12985", "abs": "https://arxiv.org/abs/2510.12985", "authors": ["Simon Sinong Zhan", "Yao Liu", "Philip Wang", "Zinan Wang", "Qineng Wang", "Zhian Ruan", "Xiangyu Shi", "Xinyu Cao", "Frank Yang", "Kangrui Wang", "Huajie Shao", "Manling Li", "Qi Zhu"], "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents", "comment": null, "summary": "We present Sentinel, the first framework for formally evaluating the physical\nsafety of Large Language Model(LLM-based) embodied agents across the semantic,\nplan, and trajectory levels. Unlike prior methods that rely on heuristic rules\nor subjective LLM judgments, Sentinel grounds practical safety requirements in\nformal temporal logic (TL) semantics that can precisely specify state\ninvariants, temporal dependencies, and timing constraints. It then employs a\nmulti-level verification pipeline where (i) at the semantic level, intuitive\nnatural language safety requirements are formalized into TL formulas and the\nLLM agent's understanding of these requirements is probed for alignment with\nthe TL formulas; (ii) at the plan level, high-level action plans and subgoals\ngenerated by the LLM agent are verified against the TL formulas to detect\nunsafe plans before execution; and (iii) at the trajectory level, multiple\nexecution trajectories are merged into a computation tree and efficiently\nverified against physically-detailed TL specifications for a final safety\ncheck. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate\nmultiple LLM-based embodied agents against diverse safety requirements. Our\nexperiments show that by grounding physical safety in temporal logic and\napplying verification methods across multiple levels, Sentinel provides a\nrigorous foundation for systematically evaluating LLM-based embodied agents in\nphysical environments, exposing safety violations overlooked by previous\nmethods and offering insights into their failure modes."}
{"id": "2510.12820", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12820", "abs": "https://arxiv.org/abs/2510.12820", "authors": ["Pedro Ramonetti", "Melissa Floca", "Kate O'Laughlin", "Amarnath Gupta", "Manish Parashar", "Ilkay Altintas"], "title": "National Data Platform's Education Hub", "comment": null, "summary": "As demand for AI literacy and data science education grows, there is a\ncritical need for infrastructure that bridges the gap between research data,\ncomputational resources, and educational experiences. To address this gap, we\ndeveloped a first-of-its-kind Education Hub within the National Data Platform.\nThis hub enables seamless connections between collaborative research\nworkspaces, classroom environments, and data challenge settings. Early use\ncases demonstrate the effectiveness of the platform in supporting complex and\nresource-intensive educational activities. Ongoing efforts aim to enhance the\nuser experience and expand adoption by educators and learners alike."}
{"id": "2510.13609", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13609", "abs": "https://arxiv.org/abs/2510.13609", "authors": ["Ahmad Awad", "Erik Scharwächter"], "title": "Model-assisted estimation for MRV: How to boost the economics of SOC sequestration projects without compromising on scientific integrity", "comment": null, "summary": "Soil organic carbon (SOC) sequestration projects require unbiased, precise\nand cost-effective Monitoring, Reporting, and Verification (MRV) systems that\nbalance sampling costs against uncertainty deductions imposed by regulatory\nframeworks. Design-based estimators guarantee unbiasedness but cannot exploit\nauxiliary data. Model-based approaches (VCS Methodology VT0014 v1.0 (2025)) can\nimprove precision but require independent validation for each project.\nModel-assisted estimation offers a robust compromise, combining model\npredictions with probability sampling to retain design-based guarantees while\nimproving precision. We evaluate the scientific integrity and efficiency of the\nsimple regression estimator (SRE), a well-known model-assisted estimator, via\nan extensive simulation study. Our simulations span diverse SOC stock\nvariances, sample sizes, and model performances. We assess three core\nproperties: empirical bias, empirical confidence interval coverage, and\nprecision gain relative to the design-based Horvitz-Thompson estimator (HTE).\nResults show negligible bias and valid coverage probabilities for n > 40,\nregardless of SOC stock variance. Below this threshold, variance approximations\nand normality assumptions yield unreliable uncertainty estimates. With\ncorrelated ancillary variables (r^2 = 0.3), SRE achieves 30% precision gains\nover HTE. With uncorrelated variables, no gains are observed, but performance\nconverges to HTE for n >= 40. Model-assisted estimation can enhance project\neconomics without compromising scientific rigor. Regulators should permit such\nestimators while mandating minimum sample size thresholds. Project proponents\nshould routinely employ such estimators when correlated ancillary variables\nexist. The industry should prioritize the retrieval of high-quality,\nproject-specific covariates to maximize precision gains and thereby the project\neconomics."}
{"id": "2510.12914", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12914", "abs": "https://arxiv.org/abs/2510.12914", "authors": ["Zhi Liu", "Chengxi Liu", "Jiangbei Han", "Rui Qiu", "Mingyuan Liu"], "title": "A Wideband Composite Sequence Impedance Model for Evaluation of Interactions in Unbalanced Power-Electronic-Based Power Systems", "comment": "This work will be submitted to the IEEE for possible publication", "summary": "This paper proposes a wideband composite sequence impedance model\n(WCSIM)-based analysis method to evaluate the interactions in\npower-electronic-based power systems subjected to unbalanced grid faults or\nwith unbalanced loads. The WCSIM-based method intuitively assesses the impact\nof the small-signal interconnection among the positive-, negative-, and\nzero-sequence circuits on the interaction stability of unbalanced power\nsystems. The effectiveness of this method is demonstrated using a permanent\nmagnet synchronous generator-based weak grid system under a\nsingle-line-to-ground fault (SLGF). Frequency scanning results and controller\nhardware-in-loop tests validate both the correctness of the WCSIM and the\neffectiveness of the WCSIM-based analysis method."}
{"id": "2510.12962", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.12962", "abs": "https://arxiv.org/abs/2510.12962", "authors": ["Michal Minařík", "Vojtěch Vonásek", "Robert Pěnička"], "title": "Enhancing Sampling-based Planning with a Library of Paths", "comment": null, "summary": "Path planning for 3D solid objects is a challenging problem, requiring a\nsearch in a six-dimensional configuration space, which is, nevertheless,\nessential in many robotic applications such as bin-picking and assembly. The\ncommonly used sampling-based planners, such as Rapidly-exploring Random Trees,\nstruggle with narrow passages where the sampling probability is low, increasing\nthe time needed to find a solution. In scenarios like robotic bin-picking,\nvarious objects must be transported through the same environment. However,\ntraditional planners start from scratch each time, losing valuable information\ngained during the planning process. We address this by using a library of past\nsolutions, allowing the reuse of previous experiences even when planning for a\nnew, previously unseen object. Paths for a set of objects are stored, and when\nplanning for a new object, we find the most similar one in the library and use\nits paths as approximate solutions, adjusting for possible mutual\ntransformations. The configuration space is then sampled along the approximate\npaths. Our method is tested in various narrow passage scenarios and compared\nwith state-of-the-art methods from the OMPL library. Results show significant\nspeed improvements (up to 85% decrease in the required time) of our method,\noften finding a solution in cases where the other planners fail. Our\nimplementation of the proposed method is released as an open-source package."}
{"id": "2510.12914", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12914", "abs": "https://arxiv.org/abs/2510.12914", "authors": ["Zhi Liu", "Chengxi Liu", "Jiangbei Han", "Rui Qiu", "Mingyuan Liu"], "title": "A Wideband Composite Sequence Impedance Model for Evaluation of Interactions in Unbalanced Power-Electronic-Based Power Systems", "comment": "This work will be submitted to the IEEE for possible publication", "summary": "This paper proposes a wideband composite sequence impedance model\n(WCSIM)-based analysis method to evaluate the interactions in\npower-electronic-based power systems subjected to unbalanced grid faults or\nwith unbalanced loads. The WCSIM-based method intuitively assesses the impact\nof the small-signal interconnection among the positive-, negative-, and\nzero-sequence circuits on the interaction stability of unbalanced power\nsystems. The effectiveness of this method is demonstrated using a permanent\nmagnet synchronous generator-based weak grid system under a\nsingle-line-to-ground fault (SLGF). Frequency scanning results and controller\nhardware-in-loop tests validate both the correctness of the WCSIM and the\neffectiveness of the WCSIM-based analysis method."}
{"id": "2510.13002", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13002", "abs": "https://arxiv.org/abs/2510.13002", "authors": ["Boyou Chen", "Gerui Xu", "Zifei Wang", "Huizhong Guo", "Ananna Ahmed", "Zhaonan Sun", "Zhen Hu", "Kaihan Zhang", "Shan Bao"], "title": "From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model", "comment": null, "summary": "Vehicle crashes involve complex interactions between road users, split-second\ndecisions, and challenging environmental conditions. Among these, two-vehicle\ncrashes are the most prevalent, accounting for approximately 70% of roadway\ncrashes and posing a significant challenge to traffic safety. Identifying\nDriver Hazardous Action (DHA) is essential for understanding crash causation,\nyet the reliability of DHA data in large-scale databases is limited by\ninconsistent and labor-intensive manual coding practices. Here, we present an\ninnovative framework that leverages a fine-tuned large language model to\nautomatically infer DHAs from textual crash narratives, thereby improving the\nvalidity and interpretability of DHA classifications. Using five years of\ntwo-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on\ndetailed crash narratives and benchmarked its performance against conventional\nmachine learning classifiers, including Random Forest, XGBoost, CatBoost, and a\nneural network. The fine-tuned LLM achieved an overall accuracy of 80%,\nsurpassing all baseline models and demonstrating pronounced improvements in\nscenarios with imbalanced data. To increase interpretability, we developed a\nprobabilistic reasoning approach, analyzing model output shifts across original\ntest sets and three targeted counterfactual scenarios: variations in driver\ndistraction and age. Our analysis revealed that introducing distraction for one\ndriver substantially increased the likelihood of \"General Unsafe Driving\";\ndistraction for both drivers maximized the probability of \"Both Drivers Took\nHazardous Actions\"; and assigning a teen driver markedly elevated the\nprobability of \"Speed and Stopping Violations.\" Our framework and analytical\nmethods provide a robust and interpretable solution for large-scale automated\nDHA detection, offering new opportunities for traffic safety analysis and\nintervention."}
{"id": "2510.12822", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12822", "abs": "https://arxiv.org/abs/2510.12822", "authors": ["Michele Loi", "Marcello Di Bello", "Nicolò Cangiotti"], "title": "Evidence Without Injustice: A New Counterfactual Test for Fair Algorithms", "comment": "13 pages", "summary": "The growing philosophical literature on algorithmic fairness has examined\nstatistical criteria such as equalized odds and calibration, causal and\ncounterfactual approaches, and the role of structural and compounding\ninjustices. Yet an important dimension has been overlooked: whether the\nevidential value of an algorithmic output itself depends on structural\ninjustice. Our paradigmatic pair of examples contrasts a predictive policing\nalgorithm, which relies on historical crime data, with a camera-based system\nthat records ongoing offenses, both designed to guide police deployment. In\nevaluating the moral acceptability of acting on a piece of evidence, we must\nask not only whether the evidence is probative in the actual world, but also\nwhether it would remain probative in nearby worlds without the relevant\ninjustices. The predictive policing algorithm fails this test, but the\ncamera-based system passes it. When evidence fails the test, it is morally\nproblematic to use it punitively, more so than evidence that passes the test."}
{"id": "2510.13672", "categories": ["stat.AP", "q-bio.QM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13672", "abs": "https://arxiv.org/abs/2510.13672", "authors": ["Marcílio Ferreira dos Santos", "Andreza dos Santos Rodrigues de Melo"], "title": "Hierarchical Bayesian Modeling of Dengue in Recife, Brazil (2015-2024): The Role of Spatial Granularity and Data Quality for Epidemiological Risk Mapping", "comment": "12 pages, 12 figures, 8 tables", "summary": "Dengue remains one of Brazil's major epidemiological challenges, marked by\nstrong intra-urban inequalities and the influence of climatic and\nsocio-environmental factors. This study analyzed confirmed dengue cases in\nRecife from 2015 to 2024 using a Bayesian hierarchical spatio-temporal model\nimplemented in R-INLA, combining a BYM2 spatial structure with an RW1 temporal\ncomponent. Covariates included population density, household size, income,\ndrainage channels, lagged precipitation, and mean temperature. Population\ndensity and household size had positive effects on dengue risk, while income\nand channel presence were protective. Lagged precipitation increased risk, and\nhigher temperatures showed an inverse association, suggesting thermal\nthresholds for vector activity. The model achieved good fit (DIC=65817;\nWAIC=64506) and stable convergence, with moderate residual spatial\nautocorrelation (phi=0.06) and a smooth temporal trend between 2016 and 2019.\nSpatio-temporal estimates revealed persistent high-risk clusters in northern\nand western Recife, overlapping with areas of higher density and social\nvulnerability. Beyond reproducing historical patterns, the Bayesian model\nsupports probabilistic forecasting and early warning systems. Compared with\nclassical models (GLM, SAR, GWR, GTWR), INLA explicitly integrates uncertainty\nand spatial-temporal dependence, offering credible interval inference for\ndecision-making in urban health management."}
{"id": "2510.12946", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12946", "abs": "https://arxiv.org/abs/2510.12946", "authors": ["Daniel C. Qi", "Kenshiro Oguri", "Puneet Singla", "Maruthi R. Akella"], "title": "Non-Gaussian Distribution Steering in Nonlinear Dynamics with Conjugate Unscented Transformation", "comment": null, "summary": "In highly nonlinear systems such as the ones commonly found in astrodynamics,\nGaussian distributions generally evolve into non-Gaussian distributions. This\npaper introduces a method for effectively controlling non-Gaussian\ndistributions in nonlinear environments using optimized linear feedback\ncontrol. This paper utilizes Conjugate Unscented Transformation to quantify the\nhigher-order statistical moments of non-Gaussian distributions. The formulation\nfocuses on controlling and constraining the sigma points associated with the\nuncertainty quantification, which would thereby reflect the control of the\nentire distribution and constraints on the moments themselves. This paper\ndevelops an algorithm to solve this problem with sequential convex programming,\nand it is demonstrated through a two-body and three-body example. The examples\nshow that individual moments can be directly controlled, and the moments are\naccurately approximated for non-Gaussian distributions throughout the\ncontroller's time horizon in nonlinear dynamics."}
{"id": "2510.12970", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.12970", "abs": "https://arxiv.org/abs/2510.12970", "authors": ["Baxi Chong", "Tianyu Wang", "Kelimar Diaz", "Christopher J. Pierce", "Eva Erickson", "Julian Whitman", "Yuelin Deng", "Esteban Flores", "Ruijie Fu", "Juntao He", "Jianfeng Lin", "Hang Lu", "Guillaume Sartoretti", "Howie Choset", "Daniel I. Goldman"], "title": "The Omega Turn: A General Turning Template for Elongate Robots", "comment": null, "summary": "Elongate limbless robots have the potential to locomote through tightly\npacked spaces for applications such as search-and-rescue and industrial\ninspections. The capability to effectively and robustly maneuver elongate\nlimbless robots is crucial to realize such potential. However, there has been\nlimited research on turning strategies for such systems. To achieve effective\nand robust turning performance in cluttered spaces, we take inspiration from a\nmicroscopic nematode, C. elegans, which exhibits remarkable maneuverability in\nrheologically complex environments partially because of its ability to perform\nomega turns. Despite recent efforts to analyze omega turn kinematics, it\nremains unknown if there exists a wave equation sufficient to prescribe an\nomega turn, let alone its reconstruction on robot platforms. Here, using a\ncomparative theory-biology approach, we prescribe the omega turn as a\nsuperposition of two traveling waves. With wave equations as a guideline, we\ndesign a controller for limbless robots enabling robust and effective turning\nbehaviors in lab and cluttered field environments. Finally, we show that such\nomega turn controllers can also generalize to elongate multi-legged robots,\ndemonstrating an alternative effective body-driven turning strategy for\nelongate robots, with and without limbs."}
{"id": "2510.12946", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12946", "abs": "https://arxiv.org/abs/2510.12946", "authors": ["Daniel C. Qi", "Kenshiro Oguri", "Puneet Singla", "Maruthi R. Akella"], "title": "Non-Gaussian Distribution Steering in Nonlinear Dynamics with Conjugate Unscented Transformation", "comment": null, "summary": "In highly nonlinear systems such as the ones commonly found in astrodynamics,\nGaussian distributions generally evolve into non-Gaussian distributions. This\npaper introduces a method for effectively controlling non-Gaussian\ndistributions in nonlinear environments using optimized linear feedback\ncontrol. This paper utilizes Conjugate Unscented Transformation to quantify the\nhigher-order statistical moments of non-Gaussian distributions. The formulation\nfocuses on controlling and constraining the sigma points associated with the\nuncertainty quantification, which would thereby reflect the control of the\nentire distribution and constraints on the moments themselves. This paper\ndevelops an algorithm to solve this problem with sequential convex programming,\nand it is demonstrated through a two-body and three-body example. The examples\nshow that individual moments can be directly controlled, and the moments are\naccurately approximated for non-Gaussian distributions throughout the\ncontroller's time horizon in nonlinear dynamics."}
{"id": "2510.13029", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13029", "abs": "https://arxiv.org/abs/2510.13029", "authors": ["Xinlei Wang", "Mingtian Tan", "Jing Qiu", "Junhua Zhao", "Jinjin Gu"], "title": "Toward Reasoning-Centric Time-Series Analysis", "comment": null, "summary": "Traditional time series analysis has long relied on pattern recognition,\ntrained on static and well-established benchmarks. However, in real-world\nsettings -- where policies shift, human behavior adapts, and unexpected events\nunfold -- effective analysis must go beyond surface-level trends to uncover the\nactual forces driving them. The recent rise of Large Language Models (LLMs)\npresents new opportunities for rethinking time series analysis by integrating\nmultimodal inputs. However, as the use of LLMs becomes popular, we must remain\ncautious, asking why we use LLMs and how to exploit them effectively. Most\nexisting LLM-based methods still employ their numerical regression ability and\nignore their deeper reasoning potential. This paper argues for rethinking time\nseries with LLMs as a reasoning task that prioritizes causal structure and\nexplainability. This shift brings time series analysis closer to human-aligned\nunderstanding, enabling transparent and context-aware insights in complex\nreal-world environments."}
{"id": "2510.12830", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12830", "abs": "https://arxiv.org/abs/2510.12830", "authors": ["Alex Dantart"], "title": "Gobernanza y trazabilidad \"a prueba de AI Act\" para casos de uso legales: un marco técnico-jurídico, métricas forenses y evidencias auditables", "comment": "in Spanish language", "summary": "This paper presents a comprehensive governance framework for AI systems in\nthe legal sector, designed to ensure verifiable compliance with the EU AI Act.\nThe framework integrates a normative mapping of the regulation to technical\ncontrols, a forensic architecture for RAG/LLM systems, and an evaluation system\nwith metrics weighted by legal risk. As a primary contribution, we present\nrag-forense, an open-source implementation of the framework, accompanied by an\nexperimental protocol to demonstrate compliance. -- Este art\\'iculo presenta un\nmarco integral de gobernanza para sistemas de IA en el sector legal, dise\\~nado\npara garantizar el cumplimiento verificable del Reglamento de IA de la UE (AI\nAct). El marco integra una cartograf\\'ia normativa de la ley a controles\nt\\'ecnicos, una arquitectura forense para sistemas RAG/LLM y un sistema de\nevaluaci\\'on con m\\'etricas ponderadas por el riesgo jur\\'idico. Como principal\ncontribuci\\'on, se presenta rag-forense, una implementaci\\'on de c\\'odigo\nabierto del marco, acompa\\~nada de un protocolo experimental para demostrar la\nconformidad."}
{"id": "2510.13780", "categories": ["stat.AP", "G.3; I.5.4; I.2.1"], "pdf": "https://arxiv.org/pdf/2510.13780", "abs": "https://arxiv.org/abs/2510.13780", "authors": ["Yingzhi Tao", "Chang Yang"], "title": "Macro-Level Correlational Analysis of Mental Disorders: Economy, Education, Society, and Technology Development", "comment": "8 pages, 5 figures, ICDM workshop", "summary": "This paper quantifies the age-stratified global burden of four mental\ndisorders in 27 regions from 1990 to 2021 using GBD 2021. To put it in detail,\nit links the age-standardized years of disability adjustment with 18 world\ndevelopment indicators across economic, educational, social and information\ntechnology sectors. Then, by means of Pearson correlation, mutual information,\nGranger causality and maximum information coefficient and other methods, the\nlinear, nonlinear and lagged dependency relationships were evaluated. After\nresearch, it was found that there is a very prominent spatio-temporal\nheterogeneity among young people aged 20 to 39, and the coupling relationship\nis stronger. From the overall situation, education corresponds to a low burden.\nUnemployment corresponds to a high burden. Through lag analysis, it can be\nknown that the influence time of economic and technological factors is\nrelatively short, while that of educational factors is relatively long. These\nresults highlight the macro determinants that play a role at different time\nscales and also provide population-level references for verifying computational\nmental health models and for intervention measures in specific regions and for\nspecific ages."}
{"id": "2510.12949", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12949", "abs": "https://arxiv.org/abs/2510.12949", "authors": ["Zhiyuan Fan", "Elizabeth Dentzer", "James Glynn", "David S. Goldberg", "Julio Friedmann", "Bolun Xu"], "title": "Enhancing Profit and CO2 Mitigation: Commercial Direct Air Capture Design and Operation with Power Market Volatility", "comment": "16 pages, 8 figure, Submitted and under review for Engineering", "summary": "Current decarbonization efforts are falling short of meeting the net-zero\ngreenhouse gas (GHG) emission target, highlighting the need for substantial\ncarbon dioxide removal methods such as direct air capture (DAC). However,\nintegrating DACs poses challenges due to their enormous power consumption. This\nstudy assesses the commercial operation of various DAC technologies that earn\nrevenue using monetized carbon incentives while purchasing electricity from\nwholesale power markets. We model four commercial DAC technologies and examine\ntheir operation in three representative locations including California, Texas,\nand New York. Our findings reveal that commercial DAC operations can take\nfinancial advantage of the volatile power market to operate only during\nlow-price periods strategically, offering a pathway to facilitate a\ncost-efficient decarbonization transition. The ambient operational environment\nsuch as temperature and relative humidity has non-trivial impact on abatement\ncapacity. Profit-driven decisions introduce climate-economic trade-offs that\nmight decrease the capacity factor of DAC and reduce total CO2 removal. These\nimplications extend throughout the entire lifecycle of DAC developments and\ninfluence power systems and policies related to full-scale DAC implementation.\nOur study shows that DAC technologies with shorter cycle spans and higher\nflexibility can better exploit the electricity price volatility, while power\nmarkets demonstrate persistent low-price windows that often synergize with low\ngrid emission periods, like during the solar \"duck curve\" in California. An\noptimal incentive design exists for profit-driven operations while carbon-tax\npolicy in electricity pricing is counterproductive for DAC systems."}
{"id": "2510.12971", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.12971", "abs": "https://arxiv.org/abs/2510.12971", "authors": ["Anran Zhang", "Hanzhi Chen", "Yannick Burkhardt", "Yao Zhong", "Johannes Betz", "Helen Oleynikova", "Stefan Leutenegger"], "title": "Actron3D: Learning Actionable Neural Functions from Videos for Transferable Robotic Manipulation", "comment": "8 pages, 5 figures", "summary": "We present Actron3D, a framework that enables robots to acquire transferable\n6-DoF manipulation skills from just a few monocular, uncalibrated, RGB-only\nhuman videos. At its core lies the Neural Affordance Function, a compact\nobject-centric representation that distills actionable cues from diverse\nuncalibrated videos-geometry, visual appearance, and affordance-into a\nlightweight neural network, forming a memory bank of manipulation skills.\nDuring deployment, we adopt a pipeline that retrieves relevant affordance\nfunctions and transfers precise 6-DoF manipulation policies via coarse-to-fine\noptimization, enabled by continuous queries to the multimodal features encoded\nin the neural functions. Experiments in both simulation and the real world\ndemonstrate that Actron3D significantly outperforms prior methods, achieving a\n14.9 percentage point improvement in average success rate across 13 tasks while\nrequiring only 2-3 demonstration videos per task."}
{"id": "2510.12949", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12949", "abs": "https://arxiv.org/abs/2510.12949", "authors": ["Zhiyuan Fan", "Elizabeth Dentzer", "James Glynn", "David S. Goldberg", "Julio Friedmann", "Bolun Xu"], "title": "Enhancing Profit and CO2 Mitigation: Commercial Direct Air Capture Design and Operation with Power Market Volatility", "comment": "16 pages, 8 figure, Submitted and under review for Engineering", "summary": "Current decarbonization efforts are falling short of meeting the net-zero\ngreenhouse gas (GHG) emission target, highlighting the need for substantial\ncarbon dioxide removal methods such as direct air capture (DAC). However,\nintegrating DACs poses challenges due to their enormous power consumption. This\nstudy assesses the commercial operation of various DAC technologies that earn\nrevenue using monetized carbon incentives while purchasing electricity from\nwholesale power markets. We model four commercial DAC technologies and examine\ntheir operation in three representative locations including California, Texas,\nand New York. Our findings reveal that commercial DAC operations can take\nfinancial advantage of the volatile power market to operate only during\nlow-price periods strategically, offering a pathway to facilitate a\ncost-efficient decarbonization transition. The ambient operational environment\nsuch as temperature and relative humidity has non-trivial impact on abatement\ncapacity. Profit-driven decisions introduce climate-economic trade-offs that\nmight decrease the capacity factor of DAC and reduce total CO2 removal. These\nimplications extend throughout the entire lifecycle of DAC developments and\ninfluence power systems and policies related to full-scale DAC implementation.\nOur study shows that DAC technologies with shorter cycle spans and higher\nflexibility can better exploit the electricity price volatility, while power\nmarkets demonstrate persistent low-price windows that often synergize with low\ngrid emission periods, like during the solar \"duck curve\" in California. An\noptimal incentive design exists for profit-driven operations while carbon-tax\npolicy in electricity pricing is counterproductive for DAC systems."}
{"id": "2510.13036", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13036", "abs": "https://arxiv.org/abs/2510.13036", "authors": ["Stephane Hatgis-Kessell", "Logan Mondal Bhamidipaty", "Emma Brunskill"], "title": "Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking", "comment": null, "summary": "Human-designed reward functions for reinforcement learning (RL) agents are\nfrequently misaligned with the humans' true, unobservable objectives, and thus\nact only as proxies. Optimizing for a misspecified proxy reward function often\ninduces reward hacking, resulting in a policy misaligned with the human's true\nobjectives. An alternative is to perform RL from human feedback, which involves\nlearning a reward function from scratch by collecting human preferences over\npairs of trajectories. However, building such datasets is costly. To address\nthe limitations of both approaches, we propose Preference-Based Reward Repair\n(PBRR): an automated iterative framework that repairs a human-specified proxy\nreward function by learning an additive, transition-dependent correction term\nfrom preferences. A manually specified reward function can yield policies that\nare highly suboptimal under the ground-truth objective, yet corrections on only\na few transitions may suffice to recover optimal performance. To identify and\ncorrect for those transitions, PBRR uses a targeted exploration strategy and a\nnew preference-learning objective. We prove in tabular domains PBRR has a\ncumulative regret that matches, up to constants, that of prior preference-based\nRL methods. In addition, on a suite of reward-hacking benchmarks, PBRR\nconsistently outperforms baselines that learn a reward function from scratch\nfrom preferences or modify the proxy reward function using other approaches,\nrequiring substantially fewer preferences to learn high performing policies."}
{"id": "2510.12836", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12836", "abs": "https://arxiv.org/abs/2510.12836", "authors": ["Tabia Tanzin Prama", "Christopher M. Danforth", "Peter Sheridan Dodds"], "title": "BanglaMATH : A Bangla benchmark dataset for testing LLM mathematical reasoning at grades 6, 7, and 8", "comment": null, "summary": "Large Language Models (LLMs) have tremendous potential to play a key role in\nsupporting mathematical reasoning, with growing use in education and AI\nresearch. However, most existing benchmarks are limited to English, creating a\nsignificant gap for low-resource languages. For example, Bangla is spoken by\nnearly 250 million people who would collectively benefit from LLMs capable of\nnative fluency. To address this, we present BanglaMATH, a dataset of 1.7k\nBangla math word problems across topics such as Arithmetic, Algebra, Geometry,\nand Logical Reasoning, sourced from Bangla elementary school workbooks and\nannotated with details like grade level and number of reasoning steps. We have\ndesigned BanglaMATH to evaluate the mathematical capabilities of both\ncommercial and open-source LLMs in Bangla, and we find that Gemini 2.5 Flash\nand DeepSeek V3 are the only models to achieve strong performance, with $\\ge$\n80\\% accuracy across three elementary school grades. Furthermore, we assess the\nrobustness and language bias of these top-performing LLMs by augmenting the\noriginal problems with distracting information, and translating the problems\ninto English. We show that both LLMs fail to maintain robustness and exhibit\nsignificant performance bias in Bangla. Our study underlines current\nlimitations of LLMs in handling arithmetic and mathematical reasoning in\nlow-resource languages, and highlights the need for further research on\nmultilingual and equitable mathematical understanding. Dataset link:\n\\href{https://github.com/TabiaTanzin/BanglaMATH-A-Bangla-benchmark-dataset-for-testing-LLM-mathematical-reasoning-at-grades-6-7-and-8.git}{https://github.com/BanglaMATH}"}
{"id": "2510.13459", "categories": ["cs.AI", "cs.CE", "cs.NI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13459", "abs": "https://arxiv.org/abs/2510.13459", "authors": ["Timothy Wong", "Tom Freeman", "Joseph Feehily"], "title": "Mobile Coverage Analysis using Crowdsourced Data", "comment": "8 pages", "summary": "Effective assessment of mobile network coverage and the precise\nidentification of service weak spots are paramount for network operators\nstriving to enhance user Quality of Experience (QoE). This paper presents a\nnovel framework for mobile coverage and weak spot analysis utilising\ncrowdsourced QoE data. The core of our methodology involves coverage analysis\nat the individual cell (antenna) level, subsequently aggregated to the site\nlevel, using empirical geolocation data. A key contribution of this research is\nthe application of One-Class Support Vector Machine (OC-SVM) algorithm for\ncalculating mobile network coverage. This approach models the decision\nhyperplane as the effective coverage contour, facilitating robust calculation\nof coverage areas for individual cells and entire sites. The same methodology\nis extended to analyse crowdsourced service loss reports, thereby identifying\nand quantifying geographically localised weak spots. Our findings demonstrate\nthe efficacy of this novel framework in accurately mapping mobile coverage and,\ncrucially, in highlighting granular areas of signal deficiency, particularly\nwithin complex urban environments."}
{"id": "2510.12955", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12955", "abs": "https://arxiv.org/abs/2510.12955", "authors": ["Levi D. Reyes Premer", "Elias N. Pergantis", "Leo Semmelmann", "Davide Ziviani", "Kevin J. Kircher"], "title": "Model predictive control lowers barriers to adoption of heat-pump water heaters: A field study", "comment": null, "summary": "Electric heat-pump water heaters (HPWHs) could reduce the energy costs,\nemissions, and power grid impacts associated with water heating, the\nsecond-largest energy use in United States housing. However, most HPWHs today\nrequire 240 V circuits to power the backup resistance heating elements they use\nto maintain comfort during large water draws. Installing a 240 V circuit can\nincrease the up-front cost of a HPWH by half or more. This paper develops and\nfield-tests the first control system that enables a 120 V HPWH to efficiently\nmaintain comfort without resistance heating elements. The novel model\npredictive control (MPC) system enables pre-heating in anticipation of large\nwater draws, which it forecasts using an ensemble of machine learning\npredictors. By shifting electrical load over time, MPC also reduces energy\ncosts on average by 23% and 28% under time-of-use pricing and hourly pricing,\nrespectively, relative to a 240 V HPWH with standard controls. Compared to the\nincreasingly common practice in 120 V HPWHs of storing water at a constant,\nhigh temperature (60 {\\deg}C) to ensure comfort, MPC saves 37% energy on\naverage. In addition to demonstrating MPC's benefits in a real, occupied house,\nthis paper discusses implementation challenges and costs. A simple payback\nanalysis suggests that a 120 V HPWH, operated by the MPC system developed here,\nwould be economically attractive in most installation scenarios."}
{"id": "2510.12992", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.12992", "abs": "https://arxiv.org/abs/2510.12992", "authors": ["Neel P. Bhatt", "Po-han Li", "Kushagra Gupta", "Rohan Siva", "Daniel Milan", "Alexander T. Hogue", "Sandeep P. Chinchali", "David Fridovich-Keil", "Zhangyang Wang", "Ufuk Topcu"], "title": "UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles", "comment": null, "summary": "Safe large-scale coordination of multiple cooperative connected autonomous\nvehicles (CAVs) hinges on communication that is both efficient and\ninterpretable. Existing approaches either rely on transmitting high-bandwidth\nraw sensor data streams or neglect perception and planning uncertainties\ninherent in shared data, resulting in systems that are neither scalable nor\nsafe. To address these limitations, we propose Uncertainty-Guided Natural\nLanguage Cooperative Autonomous Planning (UNCAP), a vision-language model-based\nplanning approach that enables CAVs to communicate via lightweight natural\nlanguage messages while explicitly accounting for perception uncertainty in\ndecision-making. UNCAP features a two-stage communication protocol: (i) an ego\nCAV first identifies the subset of vehicles most relevant for information\nexchange, and (ii) the selected CAVs then transmit messages that quantitatively\nexpress their perception uncertainty. By selectively fusing messages that\nmaximize mutual information, this strategy allows the ego vehicle to integrate\nonly the most relevant signals into its decision-making, improving both the\nscalability and reliability of cooperative planning. Experiments across diverse\ndriving scenarios show a 63% reduction in communication bandwidth with a 31%\nincrease in driving safety score, a 61% reduction in decision uncertainty, and\na four-fold increase in collision distance margin during near-miss events.\nProject website: https://uncap-project.github.io/"}
{"id": "2510.12955", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12955", "abs": "https://arxiv.org/abs/2510.12955", "authors": ["Levi D. Reyes Premer", "Elias N. Pergantis", "Leo Semmelmann", "Davide Ziviani", "Kevin J. Kircher"], "title": "Model predictive control lowers barriers to adoption of heat-pump water heaters: A field study", "comment": null, "summary": "Electric heat-pump water heaters (HPWHs) could reduce the energy costs,\nemissions, and power grid impacts associated with water heating, the\nsecond-largest energy use in United States housing. However, most HPWHs today\nrequire 240 V circuits to power the backup resistance heating elements they use\nto maintain comfort during large water draws. Installing a 240 V circuit can\nincrease the up-front cost of a HPWH by half or more. This paper develops and\nfield-tests the first control system that enables a 120 V HPWH to efficiently\nmaintain comfort without resistance heating elements. The novel model\npredictive control (MPC) system enables pre-heating in anticipation of large\nwater draws, which it forecasts using an ensemble of machine learning\npredictors. By shifting electrical load over time, MPC also reduces energy\ncosts on average by 23% and 28% under time-of-use pricing and hourly pricing,\nrespectively, relative to a 240 V HPWH with standard controls. Compared to the\nincreasingly common practice in 120 V HPWHs of storing water at a constant,\nhigh temperature (60 {\\deg}C) to ensure comfort, MPC saves 37% energy on\naverage. In addition to demonstrating MPC's benefits in a real, occupied house,\nthis paper discusses implementation challenges and costs. A simple payback\nanalysis suggests that a 120 V HPWH, operated by the MPC system developed here,\nwould be economically attractive in most installation scenarios."}
{"id": "2510.13195", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13195", "abs": "https://arxiv.org/abs/2510.13195", "authors": ["Qun Ma", "Xiao Xue", "Xuwen Zhang", "Zihan Zhao", "Yuwei Guo", "Ming Zhang"], "title": "Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation", "comment": null, "summary": "The advent of large language models (LLMs) has enabled agents to represent\nvirtual humans in societal simulations, facilitating diverse interactions\nwithin complex social systems. However, existing LLM-based agents exhibit\nsevere limitations in affective cognition: They fail to simulate the bounded\nrationality essential for bridging virtual and real-world services; They lack\nempirically validated integration mechanisms embedding emotions within agent\ndecision architectures. This paper constructs an emotional cognition framework\nincorporating desire generation and objective management, designed to achieve\nemotion alignment between LLM-based agents and humans, modeling the complete\ndecision-making process of LLM-based agents, encompassing state evolution,\ndesire generation, objective optimization, decision generation, and action\nexecution. This study implements the proposed framework within our proprietary\nmulti-agent interaction environment. Experimental results demonstrate that\nagents governed by our framework not only exhibit behaviors congruent with\ntheir emotional states but also, in comparative assessments against other agent\ntypes, demonstrate superior ecological validity and generate decision outcomes\nthat significantly more closely approximate human behavioral patterns."}
{"id": "2510.12841", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12841", "abs": "https://arxiv.org/abs/2510.12841", "authors": ["A. K. M. Bahalul Haque", "Bharat Bhushan", "Gaurav Dhiman"], "title": "Conceptualizing Smart City Applications: Requirements, Architecture, Security Issues and Emerging Trends", "comment": "60 Pages, 5 Tables, 1 Figure", "summary": "The emergence of smart cities and sustainable development has become a\nglobally accepted form of urbanization. The epitome of smart city development\nhas become possible due to the latest innovative integration of information and\ncommunication technology. Citizens of smart cities can enjoy the benefits of a\nsmart living environment, ubiquitous connectivity, seamless access to services,\nintelligent decision making through smart governance, and optimized resource\nmanagement. The widespread acceptance of smart cities has raised data security\nissues, authentication, unauthorized access, device-level vulnerability, and\nsustainability. This paper focuses on the wholistic overview and conceptual\ndevelopment of smart city. Initially, the work discusses the smart city idea\nand fundamentals explored in various pieces of literature. Further various\nsmart city applications, including notable implementations, are put forth to\nunderstand the quality of living standards. Finally, the paper depicts a solid\nunderstanding of different security and privacy issues, including some crucial\nfuture research directions."}
{"id": "2510.12961", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12961", "abs": "https://arxiv.org/abs/2510.12961", "authors": ["The Minh Nguyen", "Nagisa Sugishita", "Margarida Carvalho", "Amira Dems"], "title": "Competitive EV charging station location with queues", "comment": null, "summary": "Electric vehicle (EV) public charging infrastructure planning faces\nsignificant challenges in competitive markets, where multiple service providers\naffect congestion and user behavior. This work extends existing modeling\nframeworks by incorporating the presence of competitors' stations and more\nrealistic queueing systems.\n  First, we analyze three finite queueing systems, M/M/1/K, M/M/s/K, and\nM/Er/s/K, with varying numbers of servers (charging outlets) and service time\ndistributions, deriving analytic expressions for user behavior metrics. Second,\nwe embed the queueing-based user behavior model into a bilevel program, where\nthe upper level locates new charging stations to maximize accessibility\n(throughput), and the lower level captures users' station choices via a user\nequilibrium. Third, we apply a reformulation from competitive congested\nuser-choice facility location models to approximately solve the bilevel problem\nand introduce a surrogate-based heuristic to enhance scalability. Fourth, we\nshowcase our methodology on a real-world case study of an urban area in\nMontreal (Canada), offering managerial insights into how user-choice behavior\nassumptions and competition affect throughput and location decisions. The\nresults demonstrate that our model yields (re)location strategies that\noutperform the existing network. More broadly, this approach provides a tool\nfor incorporating charging service quality-through queueing metrics-and\nexisting competition into station planning."}
{"id": "2510.13005", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13005", "abs": "https://arxiv.org/abs/2510.13005", "authors": ["Robert Muldrow", "Channing Ludden", "Christopher Petersen"], "title": "Development of a Linear Guide-Rail Testbed for Physically Emulating ISAM Operations", "comment": "12 pages, 4 figures, AAS/AIAA Space Flight Mechanics", "summary": "In-Space Servicing, Assembly, and Manufacturing (ISAM) is a set of emerging\noperations that provides several benefits to improve the longevity, capacity,\nmo- bility, and expandability of existing and future space assets. Serial\nrobotic ma- nipulators are particularly vital in accomplishing ISAM operations,\nhowever, the complex perturbation forces and motions associated with movement\nof a robotic arm on a free-flying satellite presents a complex controls problem\nrequiring addi- tional study. While many dynamical models are developed,\nexperimentally test- ing and validating these models is challenging given that\nthe models operate in space, where satellites have six-degrees-of-freedom\n(6-DOF). This paper attempts to resolve those challenges by presenting the\ndesign and development of a new hardware-in-the-loop (HIL) experimental testbed\nutilized to emulate ISAM. This emulation will be accomplished by means of a\n6-DOF UR3e robotic arm attached to a satellite bus. This satellite bus is\nmounted to a 1-DOF guide-rail system, en- abling the satellite bus and robotic\narm to move freely in one linear direction. This experimental ISAM emulation\nsystem will explore and validate models for space motion, serial robot\nmanipulation, and contact mechanics."}
{"id": "2510.12961", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12961", "abs": "https://arxiv.org/abs/2510.12961", "authors": ["The Minh Nguyen", "Nagisa Sugishita", "Margarida Carvalho", "Amira Dems"], "title": "Competitive EV charging station location with queues", "comment": null, "summary": "Electric vehicle (EV) public charging infrastructure planning faces\nsignificant challenges in competitive markets, where multiple service providers\naffect congestion and user behavior. This work extends existing modeling\nframeworks by incorporating the presence of competitors' stations and more\nrealistic queueing systems.\n  First, we analyze three finite queueing systems, M/M/1/K, M/M/s/K, and\nM/Er/s/K, with varying numbers of servers (charging outlets) and service time\ndistributions, deriving analytic expressions for user behavior metrics. Second,\nwe embed the queueing-based user behavior model into a bilevel program, where\nthe upper level locates new charging stations to maximize accessibility\n(throughput), and the lower level captures users' station choices via a user\nequilibrium. Third, we apply a reformulation from competitive congested\nuser-choice facility location models to approximately solve the bilevel problem\nand introduce a surrogate-based heuristic to enhance scalability. Fourth, we\nshowcase our methodology on a real-world case study of an urban area in\nMontreal (Canada), offering managerial insights into how user-choice behavior\nassumptions and competition affect throughput and location decisions. The\nresults demonstrate that our model yields (re)location strategies that\noutperform the existing network. More broadly, this approach provides a tool\nfor incorporating charging service quality-through queueing metrics-and\nexisting competition into station planning."}
{"id": "2510.13214", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13214", "abs": "https://arxiv.org/abs/2510.13214", "authors": ["Zehui Ling", "Deshu Chen", "Yichi Zhang", "Yuchen Liu", "Xigui Li", "Xin Guo", "Yuan Cheng"], "title": "Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) demonstrate that\nchain-of-thought prompting and deep reasoning substantially enhance performance\non complex tasks, and multi-agent systems can further improve accuracy by\nenabling model debates. However, applying deep reasoning to all problems is\ncomputationally expensive. To mitigate these costs, we propose a complementary\nagent system integrating small and large LLMs. The small LLM first generates an\ninitial answer, which is then verified by the large LLM. If correct, the answer\nis adopted directly; otherwise, the large LLM performs in-depth reasoning.\nExperimental results show that, for simple problems, our approach reduces the\ncomputational cost of the large LLM by more than 50% with negligible accuracy\nloss, while consistently maintaining robust performance on complex tasks."}
{"id": "2510.12844", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12844", "abs": "https://arxiv.org/abs/2510.12844", "authors": ["Adam Bradley", "Bradford Saad"], "title": "AI Alignment vs. AI Ethical Treatment: 10 Challenges", "comment": "author order is arbitrary", "summary": "A morally acceptable course of AI development should avoid two dangers:\ncreating unaligned AI systems that pose a threat to humanity and mistreating AI\nsystems that merit moral consideration in their own right. This paper argues\nthese two dangers interact and that if we create AI systems that merit moral\nconsideration, simultaneously avoiding both of these dangers would be extremely\nchallenging. While our argument is straightforward and supported by a wide\nrange of pretheoretical moral judgments, it has far-reaching moral implications\nfor AI development. Although the most obvious way to avoid the tension between\nalignment and ethical treatment would be to avoid creating AI systems that\nmerit moral consideration, this option may be unrealistic and is perhaps\nfleeting. So, we conclude by offering some suggestions for other ways of\nmitigating mistreatment risks associated with alignment."}
{"id": "2510.13000", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13000", "abs": "https://arxiv.org/abs/2510.13000", "authors": ["Giacomo Bastianel", "Dirk Van Hertem", "Hakan Ergun", "Line Roald"], "title": "Identifying Best Candidates for Busbar Splitting", "comment": null, "summary": "Rising electricity demand and the growing integration of renewables are\nintensifying congestion in transmission grids. Grid topology optimization\nthrough busbar splitting (BuS) and optimal transmission switching can alleviate\ngrid congestion and reduce the generation costs in a power system. However, BuS\noptimization requires a large number of binary variables, and analyzing all the\nsubstations for potential new topological actions is computationally\nintractable, particularly in large grids. To tackle this issue, we propose a\nset of metrics to identify and rank promising candidates for BuS, focusing on\nfinding buses where topology optimization can reduce generation costs. To\nassess the effect of BuS on the identified buses, we use a combined\nmixed-integer convex-quadratic BuS model to compute the optimal topology and\ntest it with the non-linear non-convex AC optimal power flow (OPF) simulation\nto show its AC feasibility. By testing and validating the proposed metrics on\ntest cases of different sizes, we show that they are able to identify busbars\nthat reduce the total generation costs when their topology is optimized. Thus,\nthe metrics enable effective selection of busbars for BuS, with no need to test\nevery busbar in the grid, one at a time."}
{"id": "2510.13048", "categories": ["cs.RO", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.13048", "abs": "https://arxiv.org/abs/2510.13048", "authors": ["Minghao Guo", "Victor Zordan", "Sheldon Andrews", "Wojciech Matusik", "Maneesh Agrawala", "Hsueh-Ti Derek Liu"], "title": "Kinematic Kitbashing for Modeling Functional Articulated Objects", "comment": null, "summary": "We introduce Kinematic Kitbashing, an automatic framework that synthesizes\nfunctionality-aware articulated objects by reusing parts from existing models.\nGiven a kinematic graph with a small collection of articulated parts, our\noptimizer jointly solves for the spatial placement of every part so that (i)\nattachments remain geometrically sound over the entire range of motion and (ii)\nthe assembled object satisfies user-specified functional goals such as\ncollision-free actuation, reachability, or trajectory following. At its core is\na kinematics-aware attachment energy that aligns vector distance function\nfeatures sampled across multiple articulation snapshots. We embed this\nattachment term within an annealed Riemannian Langevin dynamics sampler that\ntreats functionality objectives as additional energies, enabling robust global\nexploration while accommodating non-differentiable functionality objectives and\nconstraints. Our framework produces a wide spectrum of assembled articulated\nshapes, from trash-can wheels grafted onto car bodies to multi-segment lamps,\ngear-driven paddlers, and reconfigurable furniture, and delivers strong\nquantitative improvements over state-of-the-art baselines across geometric,\nkinematic, and functional metrics. By tightly coupling articulation-aware\ngeometry matching with functionality-driven optimization, Kinematic Kitbashing\nbridges part-based shape modeling and functional assembly design, empowering\nrapid creation of interactive articulated assets."}
{"id": "2510.13000", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13000", "abs": "https://arxiv.org/abs/2510.13000", "authors": ["Giacomo Bastianel", "Dirk Van Hertem", "Hakan Ergun", "Line Roald"], "title": "Identifying Best Candidates for Busbar Splitting", "comment": null, "summary": "Rising electricity demand and the growing integration of renewables are\nintensifying congestion in transmission grids. Grid topology optimization\nthrough busbar splitting (BuS) and optimal transmission switching can alleviate\ngrid congestion and reduce the generation costs in a power system. However, BuS\noptimization requires a large number of binary variables, and analyzing all the\nsubstations for potential new topological actions is computationally\nintractable, particularly in large grids. To tackle this issue, we propose a\nset of metrics to identify and rank promising candidates for BuS, focusing on\nfinding buses where topology optimization can reduce generation costs. To\nassess the effect of BuS on the identified buses, we use a combined\nmixed-integer convex-quadratic BuS model to compute the optimal topology and\ntest it with the non-linear non-convex AC optimal power flow (OPF) simulation\nto show its AC feasibility. By testing and validating the proposed metrics on\ntest cases of different sizes, we show that they are able to identify busbars\nthat reduce the total generation costs when their topology is optimized. Thus,\nthe metrics enable effective selection of busbars for BuS, with no need to test\nevery busbar in the grid, one at a time."}
{"id": "2510.13215", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13215", "abs": "https://arxiv.org/abs/2510.13215", "authors": ["Joy Jia Yin Lim", "Ye He", "Jifan Yu", "Xin Cong", "Daniel Zhang-Li", "Zhiyuan Liu", "Huiqin Liu", "Lei Hou", "Juanzi Li", "Bin Xu"], "title": "Personalized Learning Path Planning with Goal-Driven Learner State Modeling", "comment": null, "summary": "Personalized Learning Path Planning (PLPP) aims to design adaptive learning\npaths that align with individual goals. While large language models (LLMs) show\npotential in personalizing learning experiences, existing approaches often lack\nmechanisms for goal-aligned planning. We introduce Pxplore, a novel framework\nfor PLPP that integrates a reinforcement-based training paradigm and an\nLLM-driven educational architecture. We design a structured learner state model\nand an automated reward function that transforms abstract objectives into\ncomputable signals. We train the policy combining supervised fine-tuning (SFT)\nand Group Relative Policy Optimization (GRPO), and deploy it within a\nreal-world learning platform. Extensive experiments validate Pxplore's\neffectiveness in producing coherent, personalized, and goal-driven learning\npaths. We release our code and dataset to facilitate future research."}
{"id": "2510.12850", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12850", "abs": "https://arxiv.org/abs/2510.12850", "authors": ["Mahamodul Hasan Mahadi", "Md. Nasif Safwan", "Souhardo Rahman", "Shahnaj Parvin", "Aminun Nahar", "Kamruddin Nur"], "title": "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification", "comment": null, "summary": "Developing AI systems capable of nuanced ethical reasoning is critical as\nthey increasingly influence human decisions, yet existing models often rely on\nsuperficial correlations rather than principled moral understanding. This paper\nintroduces Ethic-BERT, a BERT-based model for ethical content classification\nacross four domains: Commonsense, Justice, Virtue, and Deontology. Leveraging\nthe ETHICS dataset, our approach integrates robust preprocessing to address\nvocabulary sparsity and contextual ambiguities, alongside advanced fine-tuning\nstrategies like full model unfreezing, gradient accumulation, and adaptive\nlearning rate scheduling. To evaluate robustness, we employ an adversarially\nfiltered \"Hard Test\" split, isolating complex ethical dilemmas. Experimental\nresults demonstrate Ethic-BERT's superiority over baseline models, achieving\n82.32% average accuracy on the standard test, with notable improvements in\nJustice and Virtue. In addition, the proposed Ethic-BERT attains 15.28% average\naccuracy improvement in the HardTest. These findings contribute to performance\nimprovement and reliable decision-making using bias-aware preprocessing and\nproposed enhanced AI model."}
{"id": "2510.13004", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13004", "abs": "https://arxiv.org/abs/2510.13004", "authors": ["Robert Muldrow", "Channing Ludden", "Christopher Petersen"], "title": "Comparison of Forced and Unforced Rendezvous, Proximity Operations, and Docking Under Model Mismatch", "comment": "12 pages, 4 figures, AAS/AIAA Space Flight Mechanics", "summary": "This paper compares the required fuel usage for forced and unforced motion of\na chaser satellite engaged in Rendezvous, Proximity Operations, and Docking\n(RPOD) maneuvers. Improved RPOD models are vital, particularly as the space\nindustry expands and demands for improved fuel efficiency, cost effectiveness,\nand mission life span increase. This paper specifically examines the Clohessy-\nWiltshire (CW) Equations and the extent of model mismatch by comparing pre-\ndicted trajectories from this model with a more computationally complex, higher\nfidelity RPOD model. This paper assesses several test cases of similar mission\nparameters, in each case comparing natural motion circumnavigation (NMC) with\ncomparable forced motion circumnavigation. The Guidance, Navigation, and Con-\ntrol (GNC) impulse maneuvers required to maintain the supposedly zero fuel CW\ntrajectories is representative of the extent of CW model mismatch. This paper\ndemonstrates that unforced motions are not inherently more fuel efficient than\nforced motions, thus permitting extended orbital operations given the higher\nfuel efficiency."}
{"id": "2510.13054", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13054", "abs": "https://arxiv.org/abs/2510.13054", "authors": ["Ankit Goyal", "Hugo Hadfield", "Xuning Yang", "Valts Blukis", "Fabio Ramos"], "title": "VLA-0: Building State-of-the-Art VLAs with Zero Modification", "comment": null, "summary": "Vision-Language-Action models (VLAs) hold immense promise for enabling\ngeneralist robot manipulation. However, the best way to build them remains an\nopen question. Current approaches often add complexity, such as modifying the\nexisting vocabulary of a Vision-Language Model (VLM) with action tokens or\nintroducing special action heads. Curiously, the simplest strategy of\nrepresenting actions directly as text has remained largely unexplored. This\nwork introduces VLA-0 to investigate this idea. We find that VLA-0 is not only\neffective; it is surprisingly powerful. With the right design, VLA-0\noutperforms more involved models. On LIBERO, a popular benchmark for evaluating\nVLAs, VLA-0 outperforms all existing methods trained on the same robotic data,\nincluding $\\pi_0.5$-KI, OpenVLA-OFT and SmolVLA. Furthermore, without\nlarge-scale robotics-specific training, it outperforms methods trained on\nlarge-scale robotic data, like $\\pi_0.5$-KI, $\\pi_0$, GR00T-N1 and MolmoAct.\nThese findings also translate to the real world, where VLA-0 outperforms\nSmolVLA, a VLA model pre-trained on large-scale real data. This paper\nsummarizes our unexpected findings and spells out the specific techniques\nrequired to unlock the high performance of this simple yet potent VLA design.\nVisual results, code, and trained models are provided here:\nhttps://vla0.github.io/."}
{"id": "2510.13004", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13004", "abs": "https://arxiv.org/abs/2510.13004", "authors": ["Robert Muldrow", "Channing Ludden", "Christopher Petersen"], "title": "Comparison of Forced and Unforced Rendezvous, Proximity Operations, and Docking Under Model Mismatch", "comment": "12 pages, 4 figures, AAS/AIAA Space Flight Mechanics", "summary": "This paper compares the required fuel usage for forced and unforced motion of\na chaser satellite engaged in Rendezvous, Proximity Operations, and Docking\n(RPOD) maneuvers. Improved RPOD models are vital, particularly as the space\nindustry expands and demands for improved fuel efficiency, cost effectiveness,\nand mission life span increase. This paper specifically examines the Clohessy-\nWiltshire (CW) Equations and the extent of model mismatch by comparing pre-\ndicted trajectories from this model with a more computationally complex, higher\nfidelity RPOD model. This paper assesses several test cases of similar mission\nparameters, in each case comparing natural motion circumnavigation (NMC) with\ncomparable forced motion circumnavigation. The Guidance, Navigation, and Con-\ntrol (GNC) impulse maneuvers required to maintain the supposedly zero fuel CW\ntrajectories is representative of the extent of CW model mismatch. This paper\ndemonstrates that unforced motions are not inherently more fuel efficient than\nforced motions, thus permitting extended orbital operations given the higher\nfuel efficiency."}
{"id": "2510.13220", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13220", "abs": "https://arxiv.org/abs/2510.13220", "authors": ["Yufei He", "Juncheng Liu", "Yue Liu", "Yibo Li", "Tri Cao", "Zhiyuan Hu", "Xinxing Xu", "Bryan Hooi"], "title": "EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems", "comment": null, "summary": "A fundamental limitation of current AI agents is their inability to learn\ncomplex skills on the fly at test time, often behaving like \"clever but\nclueless interns\" in novel environments. This severely limits their practical\nutility. To systematically measure and drive progress on this challenge, we\nfirst introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a\nnew evaluation setup where an agent must play the same game for several\nconsecutive episodes, attempting to improve its performance from one episode to\nthe next. On J-TTL, we find that existing adaptation methods like reflection,\nmemory, or reinforcement learning struggle. To address the challenges posed by\nour benchmark, we present EvoTest, an evolutionary test-time learning framework\nthat improves an agent without any fine-tuning or gradients-by evolving the\nentire agentic system after every episode. EvoTest has two roles: the Actor\nAgent, which plays the game, and the Evolver Agent, which analyzes the episode\ntranscript to propose a revised configuration for the next run. This\nconfiguration rewrites the prompt, updates memory by logging effective\nstate-action choices, tunes hyperparameters, and learns the tool-use routines.\nOn our J-TTL benchmark, EvoTest consistently increases performance,\noutperforming not only reflection and memory-only baselines but also more\ncomplex online fine-tuning methods. Notably, our method is the only one capable\nof winning two games (Detective and Library), while all baselines fail to win\nany."}
{"id": "2510.12857", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12857", "abs": "https://arxiv.org/abs/2510.12857", "authors": ["Robin Staab", "Jasper Dekoninck", "Maximilian Baader", "Martin Vechev"], "title": "Adaptive Generation of Bias-Eliciting Questions for LLMs", "comment": null, "summary": "Large language models (LLMs) are now widely deployed in user-facing\napplications, reaching hundreds of millions worldwide. As they become\nintegrated into everyday tasks, growing reliance on their outputs raises\nsignificant concerns. In particular, users may unknowingly be exposed to\nmodel-inherent biases that systematically disadvantage or stereotype certain\ngroups. However, existing bias benchmarks continue to rely on templated prompts\nor restrictive multiple-choice questions that are suggestive, simplistic, and\nfail to capture the complexity of real-world user interactions. In this work,\nwe address this gap by introducing a counterfactual bias evaluation framework\nthat automatically generates realistic, open-ended questions over sensitive\nattributes such as sex, race, or religion. By iteratively mutating and\nselecting bias-inducing questions, our approach systematically explores areas\nwhere models are most susceptible to biased behavior. Beyond detecting harmful\nbiases, we also capture distinct response dimensions that are increasingly\nrelevant in user interactions, such as asymmetric refusals and explicit\nacknowledgment of bias. Leveraging our framework, we construct CAB, a\nhuman-verified benchmark spanning diverse topics, designed to enable\ncross-model comparisons. Using CAB, we analyze a range of LLMs across multiple\nbias dimensions, revealing nuanced insights into how different models manifest\nbias. For instance, while GPT-5 outperforms other models, it nonetheless\nexhibits persistent biases in specific scenarios. These findings underscore the\nneed for continual improvements to ensure fair model behavior."}
{"id": "2510.13024", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13024", "abs": "https://arxiv.org/abs/2510.13024", "authors": ["Shahab Ataei", "Dipankar Maity", "Debdipta Goswami"], "title": "Data to Certificate: Guaranteed Cost Control with Quantization-Aware System Identification", "comment": "8 pages, 3 figures", "summary": "Cloud-assisted system identification and control have emerged as practical\nsolutions for low-power, resource-constrained control systems such as\nmicro-UAVs. In a typical cloud-assisted setting, state and input data are\ntransmitted from local agents to a central computer over low-bandwidth wireless\nlinks, leading to quantization. This paper investigates the impact of state and\ninput data quantization on a linear time invariant (LTI) system identification,\nderives a worst-case bound on the identification error, and develops a robust\ncontroller for guaranteed cost control. We establish a fundamental bound on the\nmodel error that depends only on the quantized data and quantization\nresolution, and develop a linear matrix inequality (LMI) based guaranteed cost\nrobust controller under this error bound."}
{"id": "2510.13149", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13149", "abs": "https://arxiv.org/abs/2510.13149", "authors": ["Yangtao Chen", "Zixuan Chen", "Nga Teng Chan", "Junting Chen", "Junhui Yin", "Jieqi Shi", "Yang Gao", "Yong-Lu Li", "Jing Huo"], "title": "RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation", "comment": "Under review. These first two authors contributed equally to this\n  work", "summary": "Enabling robots to flexibly schedule and compose learned skills for novel\nlong-horizon manipulation under diverse perturbations remains a core challenge.\nEarly explorations with end-to-end VLA models show limited success, as these\nmodels struggle to generalize beyond the training distribution. Hierarchical\napproaches, where high-level planners generate subgoals for low-level policies,\nbring certain improvements but still suffer under complex perturbations,\nrevealing limited capability in skill composition. However, existing benchmarks\nprimarily emphasize task completion in long-horizon settings, offering little\ninsight into compositional generalization, robustness, and the interplay\nbetween planning and execution. To systematically investigate these gaps, we\npropose RoboHiMan, a hierarchical evaluation paradigm for compositional\ngeneralization in long-horizon manipulation. RoboHiMan introduces HiMan-Bench,\na benchmark of atomic and compositional tasks under diverse perturbations,\nsupported by a multi-level training dataset for analyzing progressive data\nscaling, and proposes three evaluation paradigms (vanilla, decoupled, coupled)\nthat probe the necessity of skill composition and reveal bottlenecks in\nhierarchical architectures. Experiments highlight clear capability gaps across\nrepresentative models and architectures, pointing to directions for advancing\nmodels better suited to real-world long-horizon manipulation tasks. Videos and\nopen-source code can be found on our project website:\nhttps://chenyt31.github.io/robo-himan.github.io/."}
{"id": "2510.13024", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13024", "abs": "https://arxiv.org/abs/2510.13024", "authors": ["Shahab Ataei", "Dipankar Maity", "Debdipta Goswami"], "title": "Data to Certificate: Guaranteed Cost Control with Quantization-Aware System Identification", "comment": "8 pages, 3 figures", "summary": "Cloud-assisted system identification and control have emerged as practical\nsolutions for low-power, resource-constrained control systems such as\nmicro-UAVs. In a typical cloud-assisted setting, state and input data are\ntransmitted from local agents to a central computer over low-bandwidth wireless\nlinks, leading to quantization. This paper investigates the impact of state and\ninput data quantization on a linear time invariant (LTI) system identification,\nderives a worst-case bound on the identification error, and develops a robust\ncontroller for guaranteed cost control. We establish a fundamental bound on the\nmodel error that depends only on the quantized data and quantization\nresolution, and develop a linear matrix inequality (LMI) based guaranteed cost\nrobust controller under this error bound."}
{"id": "2510.13230", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13230", "abs": "https://arxiv.org/abs/2510.13230", "authors": ["Jalal Khan", "Manzoor Khan", "Sherzod Turaev", "Sumbal Malik", "Hesham El-Sayed", "Farman Ullah"], "title": "An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities", "comment": "32 pages, 14 figures", "summary": "The driving environment perception has a vital role for autonomous driving\nand nowadays has been actively explored for its realization. The research\ncommunity and relevant stakeholders necessitate the development of Deep\nLearning (DL) models and AI-enabled solutions to enhance autonomous vehicles\n(AVs) for smart mobility. There is a need to develop a model that accurately\nperceives multiple objects on the road and predicts the driver's perception to\ncontrol the car's movements. This article proposes a novel utility-based\nanalytical model that enables perception systems of AVs to understand the\ndriving environment. The article consists of modules: acquiring a custom\ndataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a\nDL-based model (YOLOv8s) for object detection; and a module to measure the\nutility of perception service from the performance values of trained model\ninstances. The perception model is validated based on the object detection\ntask, and its process is benchmarked by state-of-the-art deep learning models'\nperformance metrics from the nuScense dataset. The experimental results show\nthree best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,\nSGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the\nAdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)\nstill outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,\ntruck: 0.781, etc.) because it has better class-level performance values,\nconfirmed by the proposed perception model. We validate that the proposed\nfunction is capable of finding the right perception for AVs. The results above\nencourage using the proposed perception model to evaluate the utility of\nlearning models and determine the appropriate perception for AVs."}
{"id": "2510.12859", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12859", "abs": "https://arxiv.org/abs/2510.12859", "authors": ["Masoud Makrehchi"], "title": "Three Lenses on the AI Revolution: Risk, Transformation, Continuity", "comment": "17 pages", "summary": "Artificial Intelligence (AI) has emerged as both a continuation of historical\ntechnological revolutions and a potential rupture with them. This paper argues\nthat AI must be viewed simultaneously through three lenses: \\textit{risk},\nwhere it resembles nuclear technology in its irreversible and global\nexternalities; \\textit{transformation}, where it parallels the Industrial\nRevolution as a general-purpose technology driving productivity and\nreorganization of labor; and \\textit{continuity}, where it extends the\nfifty-year arc of computing revolutions from personal computing to the internet\nto mobile. Drawing on historical analogies, we emphasize that no past\ntransition constituted a strict singularity: disruptive shifts eventually\nbecame governable through new norms and institutions.\n  We examine recurring patterns across revolutions -- democratization at the\nusage layer, concentration at the production layer, falling costs, and\ndeepening personalization -- and show how these dynamics are intensifying in\nthe AI era. Sectoral analysis illustrates how accounting, law, education,\ntranslation, advertising, and software engineering are being reshaped as\nroutine cognition is commoditized and human value shifts to judgment, trust,\nand ethical responsibility. At the frontier, the challenge of designing moral\nAI agents highlights the need for robust guardrails, mechanisms for moral\ngeneralization, and governance of emergent multi-agent dynamics.\n  We conclude that AI is neither a singular break nor merely incremental\nprogress. It is both evolutionary and revolutionary: predictable in its median\neffects yet carrying singularity-class tail risks. Good outcomes are not\nautomatic; they require coupling pro-innovation strategies with safety\ngovernance, ensuring equitable access, and embedding AI within a human order of\nresponsibility."}
{"id": "2510.13100", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13100", "abs": "https://arxiv.org/abs/2510.13100", "authors": ["Yifu Ding", "Ruicheng Ao", "Pablo Duenas-Martinez", "Thomas Magnanti"], "title": "Decision-dependent Robust Charging Infrastructure Planning for Light-duty Truck Electrification at Industrial Sites: Scheduling and Abandonment", "comment": null, "summary": "Many industrial sites rely on diesel-powered light-duty trucks to transport\nworkers and small-scale facilities, which has resulted in a significant amount\nof greenhouse emissions (GHGs). To address this, we developed a two-stage\nrobust charging infrastructure planning model for electrifying light-duty\ntrucks at industrial sites. The model is formulated as a mixed-integer linear\nprogramming (MILP) that optimizes the charging infrastructure, selected from\nmultiple charger types and potential locations, and determines opportunity\ncharging schedules for each truck based on the chosen infrastructure. Given the\nstrict stopping points and schedules at industrial sites, we introduced a\nscheduling problem with abandonment, where trucks forgo charging if their\nwaiting times exceed a maximum threshold. We also further incorporated the\nimpacts of overnight charging and range anxiety on waiting and abandonment\nbehaviors. To represent the stochastic and heterogeneous parking durations of\ntrucks, we constructed a decision-dependent robust uncertainty set in which\nparking time variability flexibly depends on charging choices. We applied the\nmodel in a case study of an open-pit mining site, which plans charger\ninstallations in eight zones and schedules a fleet of around 200 trucks. By\ndecomposing the problem into monthly subproblems and using heuristic\napproaches, for the whole-year dataset, the model achieves an optimality gap of\nless than 0.1 % within a reasonable computation time under diverse uncertainty\nscenarios."}
{"id": "2510.13284", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13284", "abs": "https://arxiv.org/abs/2510.13284", "authors": ["Haoyang Wu", "Siheng Wu", "William X. Liu", "Fangui Zeng"], "title": "ALOHA2 Robot Kitchen Application Scenario Reproduction Report", "comment": null, "summary": "ALOHA2 is an enhanced version of the dual-arm teleoperated robot ALOHA,\nfeaturing higher performance and robustness compared to the original design,\nwhile also being more ergonomic. Like ALOHA, ALOHA2 consists of two grippers\nand two ViperX 6-DoF arms, as well as two smaller WidowX arms. Users control\nthe follower mechanical arms by operating the leader mechanical arms through\nback-driving. The device also includes cameras that generate images from\nmultiple viewpoints, allowing for RGB data collection during teleoperation. The\nrobot is mounted on a 48-inch x 30-inch table, equipped with an aluminum frame\nthat provides additional mounting points for cameras and gravity compensation\nsystems."}
{"id": "2510.13100", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13100", "abs": "https://arxiv.org/abs/2510.13100", "authors": ["Yifu Ding", "Ruicheng Ao", "Pablo Duenas-Martinez", "Thomas Magnanti"], "title": "Decision-dependent Robust Charging Infrastructure Planning for Light-duty Truck Electrification at Industrial Sites: Scheduling and Abandonment", "comment": null, "summary": "Many industrial sites rely on diesel-powered light-duty trucks to transport\nworkers and small-scale facilities, which has resulted in a significant amount\nof greenhouse emissions (GHGs). To address this, we developed a two-stage\nrobust charging infrastructure planning model for electrifying light-duty\ntrucks at industrial sites. The model is formulated as a mixed-integer linear\nprogramming (MILP) that optimizes the charging infrastructure, selected from\nmultiple charger types and potential locations, and determines opportunity\ncharging schedules for each truck based on the chosen infrastructure. Given the\nstrict stopping points and schedules at industrial sites, we introduced a\nscheduling problem with abandonment, where trucks forgo charging if their\nwaiting times exceed a maximum threshold. We also further incorporated the\nimpacts of overnight charging and range anxiety on waiting and abandonment\nbehaviors. To represent the stochastic and heterogeneous parking durations of\ntrucks, we constructed a decision-dependent robust uncertainty set in which\nparking time variability flexibly depends on charging choices. We applied the\nmodel in a case study of an open-pit mining site, which plans charger\ninstallations in eight zones and schedules a fleet of around 200 trucks. By\ndecomposing the problem into monthly subproblems and using heuristic\napproaches, for the whole-year dataset, the model achieves an optimality gap of\nless than 0.1 % within a reasonable computation time under diverse uncertainty\nscenarios."}
{"id": "2510.13262", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13262", "abs": "https://arxiv.org/abs/2510.13262", "authors": ["Weiqi Guo", "Guanjun Liu", "Ziyuan Zhou"], "title": "SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning", "comment": null, "summary": "Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for\ncooperative and competitive tasks such as autonomous driving and strategic\ngaming. However, models trained by MADRL are vulnerable to adversarial\nperturbations on states and actions. Therefore, it is essential to investigate\nthe robustness of MADRL models from an attack perspective. Existing studies\nfocus on either state-only attacks or action-only attacks, but do not consider\nhow to effectively joint them. Simply combining state and action perturbations\nsuch as randomly perturbing states and actions does not exploit their potential\nsynergistic effects. In this paper, we propose the State-Action Joint Attack\n(SAJA) framework that has a good synergistic effects. SAJA consists of two\nimportant phases: (1) In the state attack phase, a multi-step gradient ascent\nmethod utilizes both the actor network and the critic network to compute an\nadversarial state, and (2) in the action attack phase, based on the perturbed\nstate, a second gradient ascent uses the critic network to craft the final\nadversarial action. Additionally, a heuristic regularizer measuring the\ndistance between the perturbed actions and the original clean ones is added\ninto the loss function to enhance the effectiveness of the critic's guidance.\nWe evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating\nthat (1) it outperforms and is more stealthy than state-only or action-only\nattacks, and (2) existing state or action defense methods cannot defend its\nattacks."}
{"id": "2510.12915", "categories": ["cs.CY", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12915", "abs": "https://arxiv.org/abs/2510.12915", "authors": ["Marisa C. Peczuh", "Nischal Ashok Kumar", "Ryan Baker", "Blair Lehman", "Danielle Eisenberg", "Caitlin Mills", "Keerthi Chebrolu", "Sudhip Nashi", "Cadence Young", "Brayden Liu", "Sherry Lachman", "Andrew Lan"], "title": "Toward LLM-Supported Automated Assessment of Critical Thinking Subskills", "comment": "preprint: 17 pages", "summary": "Critical thinking represents a fundamental competency in today's education\nlandscape. Developing critical thinking skills through timely assessment and\nfeedback is crucial; however, there has not been extensive work in the learning\nanalytics community on defining, measuring, and supporting critical thinking.\nIn this paper, we investigate the feasibility of measuring core \"subskills\"\nthat underlie critical thinking. We ground our work in an authentic task where\nstudents operationalize critical thinking: student-written argumentative\nessays. We developed a coding rubric based on an established skills progression\nand completed human coding for a corpus of student essays. We then evaluated\nthree distinct approaches to automated scoring: zero-shot prompting, few-shot\nprompting, and supervised fine-tuning, implemented across three large language\nmodels (GPT-5, GPT-5-mini, and ModernBERT). GPT-5 with few-shot prompting\nachieved the strongest results and demonstrated particular strength on\nsubskills with separable, frequent categories, while lower performance was\nobserved for subskills that required detection of subtle distinctions or rare\ncategories. Our results underscore critical trade-offs in automated critical\nthinking assessment: proprietary models offer superior reliability at higher\ncost, while open-source alternatives provide practical accuracy with reduced\nsensitivity to minority categories. Our work represents an initial step toward\nscalable assessment of higher-order reasoning skills across authentic\neducational contexts."}
{"id": "2510.13114", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13114", "abs": "https://arxiv.org/abs/2510.13114", "authors": ["Zhuoyuan Wang", "Tongyao Jia", "Pharuj Rajborirug", "Neeraj Ramesh", "Hiroyuki Okuda", "Tatsuya Suzuki", "Soummya Kar", "Yorie Nakahira"], "title": "Safe Driving in Occluded Environments", "comment": null, "summary": "Ensuring safe autonomous driving in the presence of occlusions poses a\nsignificant challenge in its policy design. While existing model-driven control\ntechniques based on set invariance can handle visible risks, occlusions create\nlatent risks in which safety-critical states are not observable. Data-driven\ntechniques also struggle to handle latent risks because direct mappings from\nrisk-critical objects in sensor inputs to safe actions cannot be learned\nwithout visible risk-critical objects. Motivated by these challenges, in this\npaper, we propose a probabilistic safety certificate for latent risk. Our key\ntechnical enabler is the application of probabilistic invariance: It relaxes\nthe strict observability requirements imposed by set-invariance methods that\ndemand the knowledge of risk-critical states. The proposed techniques provide\nlinear action constraints that confine the latent risk probability within\ntolerance. Such constraints can be integrated into model predictive controllers\nor embedded in data-driven policies to mitigate latent risks. The proposed\nmethod is tested using the CARLA simulator and compared with a few existing\ntechniques. The theoretical and empirical analysis jointly demonstrate that the\nproposed methods assure long-term safety in real-time control in occluded\nenvironments without being overly conservative and with transparency to exposed\nrisks."}
{"id": "2510.13287", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13287", "abs": "https://arxiv.org/abs/2510.13287", "authors": ["Nishant Chandna", "Akshat Kaushal"], "title": "DAMM-LOAM: Degeneracy Aware Multi-Metric LiDAR Odometry and Mapping", "comment": "Accepted at IROS Active Perception Workshop", "summary": "LiDAR Simultaneous Localization and Mapping (SLAM) systems are essential for\nenabling precise navigation and environmental reconstruction across various\napplications. Although current point-to-plane ICP algorithms perform effec-\ntively in structured, feature-rich environments, they struggle in scenarios\nwith sparse features, repetitive geometric structures, and high-frequency\nmotion. This leads to degeneracy in 6- DOF pose estimation. Most\nstate-of-the-art algorithms address these challenges by incorporating\nadditional sensing modalities, but LiDAR-only solutions continue to face\nlimitations under such conditions. To address these issues, we propose a novel\nDegeneracy-Aware Multi-Metric LiDAR Odometry and Map- ping (DAMM-LOAM) module.\nOur system improves mapping accuracy through point cloud classification based\non surface normals and neighborhood analysis. Points are classified into\nground, walls, roof, edges, and non-planar points, enabling accurate\ncorrespondences. A Degeneracy-based weighted least squares-based ICP algorithm\nis then applied for accurate odom- etry estimation. Additionally, a Scan\nContext based back-end is implemented to support robust loop closures.\nDAMM-LOAM demonstrates significant improvements in odometry accuracy,\nespecially in indoor environments such as long corridors"}
{"id": "2510.13114", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13114", "abs": "https://arxiv.org/abs/2510.13114", "authors": ["Zhuoyuan Wang", "Tongyao Jia", "Pharuj Rajborirug", "Neeraj Ramesh", "Hiroyuki Okuda", "Tatsuya Suzuki", "Soummya Kar", "Yorie Nakahira"], "title": "Safe Driving in Occluded Environments", "comment": null, "summary": "Ensuring safe autonomous driving in the presence of occlusions poses a\nsignificant challenge in its policy design. While existing model-driven control\ntechniques based on set invariance can handle visible risks, occlusions create\nlatent risks in which safety-critical states are not observable. Data-driven\ntechniques also struggle to handle latent risks because direct mappings from\nrisk-critical objects in sensor inputs to safe actions cannot be learned\nwithout visible risk-critical objects. Motivated by these challenges, in this\npaper, we propose a probabilistic safety certificate for latent risk. Our key\ntechnical enabler is the application of probabilistic invariance: It relaxes\nthe strict observability requirements imposed by set-invariance methods that\ndemand the knowledge of risk-critical states. The proposed techniques provide\nlinear action constraints that confine the latent risk probability within\ntolerance. Such constraints can be integrated into model predictive controllers\nor embedded in data-driven policies to mitigate latent risks. The proposed\nmethod is tested using the CARLA simulator and compared with a few existing\ntechniques. The theoretical and empirical analysis jointly demonstrate that the\nproposed methods assure long-term safety in real-time control in occluded\nenvironments without being overly conservative and with transparency to exposed\nrisks."}
{"id": "2510.13393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13393", "abs": "https://arxiv.org/abs/2510.13393", "authors": ["Yunxiao Zhao", "Zhiqiang Wang", "Xingtong Yu", "Xiaoli Li", "Jiye Liang", "Ru Li"], "title": "Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization", "comment": "14 pages, 7 figures, 11 tables. Under review by IEEE", "summary": "Rationalization, a data-centric framework, aims to build self-explanatory\nmodels to explain the prediction outcome by generating a subset of\nhuman-intelligible pieces of the input data. It involves a cooperative game\nmodel where a generator generates the most human-intelligible parts of the\ninput (i.e., rationales), followed by a predictor that makes predictions based\non these generated rationales. Conventional rationalization methods typically\nimpose constraints via regularization terms to calibrate or penalize undesired\ngeneration. However, these methods are suffering from a problem called mode\ncollapse, in which the predictor produces correct predictions yet the generator\nconsistently outputs rationales with collapsed patterns. Moreover, existing\nstudies are typically designed separately for specific collapsed patterns,\nlacking a unified consideration. In this paper, we systematically revisit\ncooperative rationalization from a novel game-theoretic perspective and\nidentify the fundamental cause of this problem: the generator no longer tends\nto explore new strategies to uncover informative rationales, ultimately leading\nthe system to converge to a suboptimal game equilibrium (correct predictions\nv.s collapsed rationales). To solve this problem, we then propose a novel\napproach, Game-theoretic Policy Optimization oriented RATionalization (PORAT),\nwhich progressively introduces policy interventions to address the game\nequilibrium in the cooperative game process, thereby guiding the model toward a\nmore optimal solution state. We theoretically analyse the cause of such a\nsuboptimal equilibrium and prove the feasibility of the proposed method.\nFurthermore, we validate our method on nine widely used real-world datasets and\ntwo synthetic settings, where PORAT achieves up to 8.1% performance\nimprovements over existing state-of-the-art methods."}
{"id": "2510.13139", "categories": ["cs.CY", "cs.CE", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.13139", "abs": "https://arxiv.org/abs/2510.13139", "authors": ["Xiaoyu Yan", "Tianxing Dai", "Yu", "Nie"], "title": "Addressing the alignment problem in transportation policy making: an LLM approach", "comment": null, "summary": "A key challenge in transportation planning is that the collective preferences\nof heterogeneous travelers often diverge from the policies produced by\nmodel-driven decision tools. This misalignment frequently results in\nimplementation delays or failures. Here, we investigate whether large language\nmodels (LLMs), noted for their capabilities in reasoning and simulating human\ndecision-making, can help inform and address this alignment problem. We develop\na multi-agent simulation in which LLMs, acting as agents representing residents\nfrom different communities in a city, participate in a referendum on a set of\ntransit policy proposals. Using chain-of-thought reasoning, LLM agents provide\nranked-choice or approval-based preferences, which are aggregated using\ninstant-runoff voting (IRV) to model democratic consensus. We implement this\nsimulation framework with both GPT-4o and Claude-3.5, and apply it for Chicago\nand Houston. Our findings suggest that LLM agents are capable of approximating\nplausible collective preferences and responding to local context, while also\ndisplaying model-specific behavioral biases and modest divergences from\noptimization-based benchmarks. These capabilities underscore both the promise\nand limitations of LLMs as tools for solving the alignment problem in\ntransportation decision-making."}
{"id": "2510.13279", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13279", "abs": "https://arxiv.org/abs/2510.13279", "authors": ["Fuma Omori", "Atsushi Yano", "Takuya Azumi"], "title": "Partitioned Scheduling for DAG Tasks Considering Probabilistic Execution Time", "comment": null, "summary": "Autonomous driving systems, critical for safety, require real-time guarantees\nand can be modeled as DAGs. Their acceleration features, such as caches and\npipelining, often result in execution times below the worst-case. Thus, a\nprobabilistic approach ensuring constraint satisfaction within a probability\nthreshold is more suitable than worst-case guarantees for these systems. This\npaper considers probabilistic guarantees for DAG tasks by utilizing the results\nof probabilistic guarantees for single processors, which have been relatively\nmore advanced than those for multi-core processors. This paper proposes a task\nset partitioning method that guarantees schedulability under the partitioned\nscheduling. The evaluation on randomly generated DAG task sets demonstrates\nthat the proposed method schedules more task sets with a smaller mean analysis\ntime compared to existing probabilistic schedulability analysis for DAGs. The\nevaluation also compares four bin-packing heuristics, revealing Item-Centric\nWorst-Fit-Decreasing schedules the most task sets."}
{"id": "2510.13324", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13324", "abs": "https://arxiv.org/abs/2510.13324", "authors": ["Erik Helmut", "Niklas Funk", "Tim Schneider", "Cristiana de Farias", "Jan Peters"], "title": "Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation", "comment": null, "summary": "Contact-rich manipulation depends on applying the correct grasp forces\nthroughout the manipulation task, especially when handling fragile or\ndeformable objects. Most existing imitation learning approaches often treat\nvisuotactile feedback only as an additional observation, leaving applied forces\nas an uncontrolled consequence of gripper commands. In this work, we present\nForce-Aware Robotic Manipulation (FARM), an imitation learning framework that\nintegrates high-dimensional tactile data to infer tactile-conditioned force\nsignals, which in turn define a matching force-based action space. We collect\nhuman demonstrations using a modified version of the handheld Universal\nManipulation Interface (UMI) gripper that integrates a GelSight Mini visual\ntactile sensor. For deploying the learned policies, we developed an actuated\nvariant of the UMI gripper with geometry matching our handheld version. During\npolicy rollouts, the proposed FARM diffusion policy jointly predicts robot\npose, grip width, and grip force. FARM outperforms several baselines across\nthree tasks with distinct force requirements -- high-force, low-force, and\ndynamic force adaptation -- demonstrating the advantages of its two key\ncomponents: leveraging force-grounded, high-dimensional tactile observations\nand a force-based control space. The codebase and design files are open-sourced\nand available at https://tactile-farm.github.io ."}
{"id": "2510.13279", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13279", "abs": "https://arxiv.org/abs/2510.13279", "authors": ["Fuma Omori", "Atsushi Yano", "Takuya Azumi"], "title": "Partitioned Scheduling for DAG Tasks Considering Probabilistic Execution Time", "comment": null, "summary": "Autonomous driving systems, critical for safety, require real-time guarantees\nand can be modeled as DAGs. Their acceleration features, such as caches and\npipelining, often result in execution times below the worst-case. Thus, a\nprobabilistic approach ensuring constraint satisfaction within a probability\nthreshold is more suitable than worst-case guarantees for these systems. This\npaper considers probabilistic guarantees for DAG tasks by utilizing the results\nof probabilistic guarantees for single processors, which have been relatively\nmore advanced than those for multi-core processors. This paper proposes a task\nset partitioning method that guarantees schedulability under the partitioned\nscheduling. The evaluation on randomly generated DAG task sets demonstrates\nthat the proposed method schedules more task sets with a smaller mean analysis\ntime compared to existing probabilistic schedulability analysis for DAGs. The\nevaluation also compares four bin-packing heuristics, revealing Item-Centric\nWorst-Fit-Decreasing schedules the most task sets."}
{"id": "2510.13417", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13417", "abs": "https://arxiv.org/abs/2510.13417", "authors": ["Liesbeth Allein", "Nataly Pineda-Castañeda", "Andrea Rocci", "Marie-Francine Moens"], "title": "Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse", "comment": null, "summary": "How does a cause lead to an effect, and which intermediate causal steps\nexplain their connection? This work scrutinizes the mechanistic causal\nreasoning capabilities of large language models (LLMs) to answer these\nquestions through the task of implicit causal chain discovery. In a diagnostic\nevaluation framework, we instruct nine LLMs to generate all possible\nintermediate causal steps linking given cause-effect pairs in causal chain\nstructures. These pairs are drawn from recent resources in argumentation\nstudies featuring polarized discussion on climate change. Our analysis reveals\nthat LLMs vary in the number and granularity of causal steps they produce.\nAlthough they are generally self-consistent and confident about the\nintermediate causal connections in the generated chains, their judgments are\nmainly driven by associative pattern matching rather than genuine causal\nreasoning. Nonetheless, human evaluations confirmed the logical coherence and\nintegrity of the generated chains. Our baseline causal chain discovery\napproach, insights from our diagnostic evaluation, and benchmark dataset with\ncausal chains lay a solid foundation for advancing future work in implicit,\nmechanistic causal reasoning in argumentation settings."}
{"id": "2510.13162", "categories": ["cs.CY", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13162", "abs": "https://arxiv.org/abs/2510.13162", "authors": ["Taylor Robinson", "Rikke Bjerg Jensen"], "title": "Searching for a Farang: Collective Security among Women in Pattaya, Thailand", "comment": "To appear at IEEE Security & Privacy 2026", "summary": "We report on two months of ethnographic fieldwork in a women's centre in\nPattaya, and interviews with 76 participants. Our findings, as they relate to\ndigital security, show how (i) women in Pattaya, often working in the sex and\nmassage industries, perceived relationships with farang men as their best, and\nsometimes only, option to achieve security; (ii) the strategies used by the\nwomen to appeal to a farang involved presenting themselves online, mirroring\nhow they were being advertised by bar owners to attract customers; (iii)\nappealing to what they considered `Western ideals', the women sought out\n`Western technologies' and appropriated them for their benefit; (iv) the women\nnavigated a series of online security risks, such as scams and abuse, which\nshaped their search for a farang; (v) the women developed collective security\nthrough knowledge-sharing to protect themselves and each other in their search\nfor a farang. We situate our work in emerging digital security scholarship\nwithin marginalised contexts."}
{"id": "2510.13396", "categories": ["eess.SY", "cs.SY", "93-10"], "pdf": "https://arxiv.org/pdf/2510.13396", "abs": "https://arxiv.org/abs/2510.13396", "authors": ["Luka Baković", "David Ohlin", "Emma Tegling"], "title": "Multipolar dynamics of social segregation: Data validation on Swedish vaccination statistics", "comment": "Presented at CoDIT 2025", "summary": "We perform a validation analysis on the multipolar model of opinion dynamics.\nA general methodology for using the model on datasets of two correlated\nvariables is proposed and tested using data on the relationship between\nCOVID-19 vaccination rates and political participation in Sweden. The model is\nshown to successfully capture the opinion segregation demonstrated by the data\nand spatial correlation of biases is demonstrated as necessary for the result.\nA mixing of the biases on the other hand leads to a more homogeneous opinion\ndistribution, and greater penetration of the majority opinion, which here\ncorresponds to a decision to vote or vaccinate."}
{"id": "2510.13356", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13356", "abs": "https://arxiv.org/abs/2510.13356", "authors": ["Jie Gu", "Tin Lun Lam", "Chunxu Tian", "Zhihao Xia", "Yongheng Xing", "Dan Zhang"], "title": "MODUR: A Modular Dual-reconfigurable Robot", "comment": null, "summary": "Modular Self-Reconfigurable Robot (MSRR) systems are a class of robots\ncapable of forming higher-level robotic systems by altering the topological\nrelationships between modules, offering enhanced adaptability and robustness in\nvarious environments. This paper presents a novel MSRR called MODUR, featuring\ndual-level reconfiguration capabilities designed to integrate reconfigurable\nmechanisms into MSRR. Specifically, MODUR can perform high-level\nself-reconfiguration among modules to create different configurations, while\neach module is also able to change its shape to execute basic motions. The\ndesign of MODUR primarily includes a compact connector and scissor linkage\ngroups that provide actuation, forming a parallel mechanism capable of\nachieving both connector motion decoupling and adjacent position migration\ncapabilities. Furthermore, the workspace, considering the interdependent\nconnectors, is comprehensively analyzed, laying a theoretical foundation for\nthe design of the module's basic motion. Finally, the motion of MODUR is\nvalidated through a series of experiments."}
{"id": "2510.13396", "categories": ["eess.SY", "cs.SY", "93-10"], "pdf": "https://arxiv.org/pdf/2510.13396", "abs": "https://arxiv.org/abs/2510.13396", "authors": ["Luka Baković", "David Ohlin", "Emma Tegling"], "title": "Multipolar dynamics of social segregation: Data validation on Swedish vaccination statistics", "comment": "Presented at CoDIT 2025", "summary": "We perform a validation analysis on the multipolar model of opinion dynamics.\nA general methodology for using the model on datasets of two correlated\nvariables is proposed and tested using data on the relationship between\nCOVID-19 vaccination rates and political participation in Sweden. The model is\nshown to successfully capture the opinion segregation demonstrated by the data\nand spatial correlation of biases is demonstrated as necessary for the result.\nA mixing of the biases on the other hand leads to a more homogeneous opinion\ndistribution, and greater penetration of the majority opinion, which here\ncorresponds to a decision to vote or vaccinate."}
{"id": "2510.13459", "categories": ["cs.AI", "cs.CE", "cs.NI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13459", "abs": "https://arxiv.org/abs/2510.13459", "authors": ["Timothy Wong", "Tom Freeman", "Joseph Feehily"], "title": "Mobile Coverage Analysis using Crowdsourced Data", "comment": "8 pages", "summary": "Effective assessment of mobile network coverage and the precise\nidentification of service weak spots are paramount for network operators\nstriving to enhance user Quality of Experience (QoE). This paper presents a\nnovel framework for mobile coverage and weak spot analysis utilising\ncrowdsourced QoE data. The core of our methodology involves coverage analysis\nat the individual cell (antenna) level, subsequently aggregated to the site\nlevel, using empirical geolocation data. A key contribution of this research is\nthe application of One-Class Support Vector Machine (OC-SVM) algorithm for\ncalculating mobile network coverage. This approach models the decision\nhyperplane as the effective coverage contour, facilitating robust calculation\nof coverage areas for individual cells and entire sites. The same methodology\nis extended to analyse crowdsourced service loss reports, thereby identifying\nand quantifying geographically localised weak spots. Our findings demonstrate\nthe efficacy of this novel framework in accurately mapping mobile coverage and,\ncrucially, in highlighting granular areas of signal deficiency, particularly\nwithin complex urban environments."}
{"id": "2510.13465", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13465", "abs": "https://arxiv.org/abs/2510.13465", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Discrimination, artificial intelligence, and algorithmic decision-making", "comment": null, "summary": "Artificial intelligence (AI) has a huge impact on our personal lives and also\non our democratic society as a whole. While AI offers vast opportunities for\nthe benefit of people, its potential to embed and perpetuate bias and\ndiscrimination remains one of the most pressing challenges deriving from its\nincreasing use. This new study, which was prepared by Prof. Frederik Zuiderveen\nBorgesius for the Anti-discrimination Department of the Council of Europe,\nelaborates on the risks of discrimination caused by algorithmic decision-making\nand other types of artificial intelligence (AI)."}
{"id": "2510.13449", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13449", "abs": "https://arxiv.org/abs/2510.13449", "authors": ["Jan Brändle", "Julie Rousseau", "Pulkit Nahata", "Gabriela Hug"], "title": "On the Flexibility Potential of a Swiss Distribution Grid: Opportunities and Limitations", "comment": null, "summary": "The growing integration of distributed renewable generation and the\nelectrification of heating and transportation are rapidly increasing the number\nof flexible devices within modern distribution grids. Leveraging the aggregated\nflexibility of these small-scale distributed resources is essential to\nmaintaining future grid-wide stability. This work uses the Swiss distribution\ngrid of Walenstadt as a case study to provide insights into the aggregated\nflexibility potential of distribution grids. It demonstrates that incorporating\ndevices such as heat pumps and photovoltaic systems significantly enhances\ndistribution grid flexibility. It investigates the time-varying nature of\naggregated flexibility and highlights how it can vary seasonally. Furthermore,\nsimulations of future scenarios reveal that aggregated flexibility does not\nincrease linearly or monotonically with higher levels of flexible device\npenetration. This is primarily due to the overloading of individual feeders,\nwhich underscores the impact of grid topology and network constraints on the\naggregated flexibility potential."}
{"id": "2510.13358", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13358", "abs": "https://arxiv.org/abs/2510.13358", "authors": ["Shingo Ayabe", "Hiroshi Kera", "Kazuhiko Kawamoto"], "title": "Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control", "comment": "16 pages, 8 figures", "summary": "Offline reinforcement learning enables sample-efficient policy acquisition\nwithout risky online interaction, yet policies trained on static datasets\nremain brittle under action-space perturbations such as actuator faults. This\nstudy introduces an offline-to-online framework that trains policies on clean\ndata and then performs adversarial fine-tuning, where perturbations are\ninjected into executed actions to induce compensatory behavior and improve\nresilience. A performance-aware curriculum further adjusts the perturbation\nprobability during training via an exponential-moving-average signal, balancing\nrobustness and stability throughout the learning process. Experiments on\ncontinuous-control locomotion tasks demonstrate that the proposed method\nconsistently improves robustness over offline-only baselines and converges\nfaster than training from scratch. Matching the fine-tuning and evaluation\nconditions yields the strongest robustness to action-space perturbations, while\nthe adaptive curriculum strategy mitigates the degradation of nominal\nperformance observed with the linear curriculum strategy. Overall, the results\nshow that adversarial fine-tuning enables adaptive and robust control under\nuncertain environments, bridging the gap between offline efficiency and online\nadaptability."}
{"id": "2510.13449", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13449", "abs": "https://arxiv.org/abs/2510.13449", "authors": ["Jan Brändle", "Julie Rousseau", "Pulkit Nahata", "Gabriela Hug"], "title": "On the Flexibility Potential of a Swiss Distribution Grid: Opportunities and Limitations", "comment": null, "summary": "The growing integration of distributed renewable generation and the\nelectrification of heating and transportation are rapidly increasing the number\nof flexible devices within modern distribution grids. Leveraging the aggregated\nflexibility of these small-scale distributed resources is essential to\nmaintaining future grid-wide stability. This work uses the Swiss distribution\ngrid of Walenstadt as a case study to provide insights into the aggregated\nflexibility potential of distribution grids. It demonstrates that incorporating\ndevices such as heat pumps and photovoltaic systems significantly enhances\ndistribution grid flexibility. It investigates the time-varying nature of\naggregated flexibility and highlights how it can vary seasonally. Furthermore,\nsimulations of future scenarios reveal that aggregated flexibility does not\nincrease linearly or monotonically with higher levels of flexible device\npenetration. This is primarily due to the overloading of individual feeders,\nwhich underscores the impact of grid topology and network constraints on the\naggregated flexibility potential."}
{"id": "2510.13501", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13501", "abs": "https://arxiv.org/abs/2510.13501", "authors": ["He Du", "Bowen Li", "Chengxing Xie", "Chang Gao", "Kai Chen", "Dacheng Tao"], "title": "Confidence as a Reward: Transforming LLMs into Reward Models", "comment": null, "summary": "Reward models can significantly enhance the reasoning capabilities of large\nlanguage models (LLMs), but they typically require extensive curated data and\ncostly training. To mitigate these challenges, training-free approaches such as\nLLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate\nresponses, achieving promising results. Recent works have also indicated that\nmodel confidence can serve effectively as a reward metric, distinguishing\nbetween chain-of-thought (CoT) and non-CoT paths. However, the concept of using\nconfidence as a reward has not been comprehensively studied. In this work, we\nsystematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful\ntraining-free method that utilizes token-level confidence in the model's final\nanswers as a proxy for reward, especially suitable for close-ended tasks.\nThrough extensive experiments on mathematical reasoning tasks, we demonstrate\nthat CRew outperforms existing training-free reward approaches on the MATH500\nand RewardMATH benchmarks, and even surpasses most trained reward models. We\nfurther identify a strong correlation between CRew scores and the actual\nreasoning performance of the model. Additionally, we find that CRew can\neffectively filter high-quality training data. Building upon these insights, we\npropose CRew-DPO, a training strategy that constructs preference data from\nconfidence scores combined with correctness signals. Finetuning with CRew-DPO\nfurther enhances the model's judging capabilities and consistently outperforms\nexisting self-training methods."}
{"id": "2510.13466", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13466", "abs": "https://arxiv.org/abs/2510.13466", "authors": ["Natali Helberger", "Frederik Zuiderveen Borgesius", "Agustin Reyna"], "title": "The Perfect Match? A Closer Look at the Relationship between EU Consumer Law and Data Protection Law", "comment": null, "summary": "In modern markets, many companies offer so-called 'free' services and\nmonetize consumer data they collect through those services. This paper argues\nthat consumer law and data protection law can usefully complement each other.\nData protection law can also inform the interpretation of consumer law. Using\nconsumer rights, consumers should be able to challenge excessive collection of\ntheir personal data. Consumer organizations have used consumer law to tackle\ndata protection infringements. The interplay of data protection law and\nconsumer protection law provides exciting opportunities for a more integrated\nvision on 'data consumer law'."}
{"id": "2510.13461", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13461", "abs": "https://arxiv.org/abs/2510.13461", "authors": ["Yangye Jiang", "Jiachen Wang", "Daofei Li"], "title": "Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers", "comment": null, "summary": "Accurate prediction of vehicle collision dynamics is crucial for advanced\nsafety systems and post-impact control applications, yet existing methods face\ninherent trade-offs among computational efficiency, prediction accuracy, and\ndata requirements. This paper proposes a dual Physics-Informed Neural Network\nframework addressing these challenges through two complementary networks. The\nfirst network integrates Gaussian Mixture Models with PINN architecture to\nlearn impact force distributions from finite element analysis data while\nenforcing momentum conservation and energy consistency constraints. The second\nnetwork employs an adaptive PINN with dynamic constraint weighting to predict\npost-collision vehicle dynamics, featuring an adaptive physics guard layer that\nprevents unrealistic predictions whil e preserving data-driven learning\ncapabilities. The framework incorporates uncertainty quantification through\ntime-varying parameters and enables rapid adaptation via fine-tuning\nstrategies. Validation demonstrates significant improvements: the impact force\nmodel achieves relative errors below 15.0% for force prediction on finite\nelement analysis (FEA) datasets, while the vehicle dynamics model reduces\naverage trajectory prediction error by 63.6% compared to traditional\nfour-degree-of-freedom models in scaled vehicle experiments. The integrated\nsystem maintains millisecond-level computational efficiency suitable for\nreal-time applications while providing probabilistic confidence bounds\nessential for safety-critical control. Comprehensive validation through FEA\nsimulation, dynamic modeling, and scaled vehicle experiments confirms the\nframework's effectiveness for Precision Immobilization Technique scenarios and\ngeneral collision dynamics prediction."}
{"id": "2510.13443", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13443", "abs": "https://arxiv.org/abs/2510.13443", "authors": ["Mojtaba Mollahossein", "Gholamreza Vossoughi", "Mohammad Hossein Rohban"], "title": "Real-Time Knee Angle Prediction Using EMG and Kinematic Data with an Attention-Based CNN-LSTM Network and Transfer Learning Across Multiple Datasets", "comment": null, "summary": "Electromyography (EMG) signals are widely used for predicting body joint\nangles through machine learning (ML) and deep learning (DL) methods. However,\nthese approaches often face challenges such as limited real-time applicability,\nnon-representative test conditions, and the need for large datasets to achieve\noptimal performance. This paper presents a transfer-learning framework for knee\njoint angle prediction that requires only a few gait cycles from new subjects.\nThree datasets - Georgia Tech, the University of California Irvine (UCI), and\nthe Sharif Mechatronic Lab Exoskeleton (SMLE) - containing four EMG channels\nrelevant to knee motion were utilized. A lightweight attention-based CNN-LSTM\nmodel was developed and pre-trained on the Georgia Tech dataset, then\ntransferred to the UCI and SMLE datasets. The proposed model achieved\nNormalized Mean Absolute Errors (NMAE) of 6.8 percent and 13.7 percent for\none-step and 50-step predictions on abnormal subjects using EMG inputs alone.\nIncorporating historical knee angles reduced the NMAE to 3.1 percent and 3.5\npercent for normal subjects, and to 2.8 percent and 7.5 percent for abnormal\nsubjects. When further adapted to the SMLE exoskeleton with EMG, kinematic, and\ninteraction force inputs, the model achieved 1.09 percent and 3.1 percent NMAE\nfor one- and 50-step predictions, respectively. These results demonstrate\nrobust performance and strong generalization for both short- and long-term\nrehabilitation scenarios."}
{"id": "2510.13461", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13461", "abs": "https://arxiv.org/abs/2510.13461", "authors": ["Yangye Jiang", "Jiachen Wang", "Daofei Li"], "title": "Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers", "comment": null, "summary": "Accurate prediction of vehicle collision dynamics is crucial for advanced\nsafety systems and post-impact control applications, yet existing methods face\ninherent trade-offs among computational efficiency, prediction accuracy, and\ndata requirements. This paper proposes a dual Physics-Informed Neural Network\nframework addressing these challenges through two complementary networks. The\nfirst network integrates Gaussian Mixture Models with PINN architecture to\nlearn impact force distributions from finite element analysis data while\nenforcing momentum conservation and energy consistency constraints. The second\nnetwork employs an adaptive PINN with dynamic constraint weighting to predict\npost-collision vehicle dynamics, featuring an adaptive physics guard layer that\nprevents unrealistic predictions whil e preserving data-driven learning\ncapabilities. The framework incorporates uncertainty quantification through\ntime-varying parameters and enables rapid adaptation via fine-tuning\nstrategies. Validation demonstrates significant improvements: the impact force\nmodel achieves relative errors below 15.0% for force prediction on finite\nelement analysis (FEA) datasets, while the vehicle dynamics model reduces\naverage trajectory prediction error by 63.6% compared to traditional\nfour-degree-of-freedom models in scaled vehicle experiments. The integrated\nsystem maintains millisecond-level computational efficiency suitable for\nreal-time applications while providing probabilistic confidence bounds\nessential for safety-critical control. Comprehensive validation through FEA\nsimulation, dynamic modeling, and scaled vehicle experiments confirms the\nframework's effectiveness for Precision Immobilization Technique scenarios and\ngeneral collision dynamics prediction."}
{"id": "2510.13524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13524", "abs": "https://arxiv.org/abs/2510.13524", "authors": ["William Flanagan", "Mukunda Das", "Rajitha Ramanyake", "Swaunja Maslekar", "Meghana Manipuri", "Joong Ho Choi", "Shruti Nair", "Shambhavi Bhusan", "Sanjana Dulam", "Mouni Pendharkar", "Nidhi Singh", "Vashisth Doshi", "Sachi Shah Paresh"], "title": "A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain", "comment": "NeurIPS 2025 GenAI in Finance Workshop", "summary": "As Generative Artificial Intelligence is adopted across the financial\nservices industry, a significant barrier to adoption and usage is measuring\nmodel performance. Historical machine learning metrics can oftentimes fail to\ngeneralize to GenAI workloads and are often supplemented using Subject Matter\nExpert (SME) Evaluation. Even in this combination, many projects fail to\naccount for various unique risks present in choosing specific metrics.\nAdditionally, many widespread benchmarks created by foundational research labs\nand educational institutions fail to generalize to industrial use. This paper\nexplains these challenges and provides a Risk Assessment Framework to allow for\nbetter application of SME and machine learning Metrics"}
{"id": "2510.13468", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13468", "abs": "https://arxiv.org/abs/2510.13468", "authors": ["Stefan Kulk", "Frederik Zuiderveen Borgesius"], "title": "Privacy, freedom of expression, and the right to be forgotten in Europe", "comment": null, "summary": "In this chapter we discuss the relation between privacy and freedom of\nexpression in Europe. In principle, the two rights have equal weight in Europe\n- which right prevails depends on the circumstances of a case. We use the\nGoogle Spain judgment of the Court of Justice of the European Union, sometimes\ncalled the 'right to be forgotten' judgment, to illustrate the difficulties\nwhen balancing the two rights. The court decided in Google Spain that people\nhave, under certain conditions, the right to have search results for their name\ndelisted. We discuss how Google and Data Protection Authorities deal with such\ndelisting requests in practice. Delisting requests illustrate that balancing\nprivacy and freedom of expression interests will always remain difficult."}
{"id": "2510.13514", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13514", "abs": "https://arxiv.org/abs/2510.13514", "authors": ["Andreas C. Makrides", "Adam Suski", "Elina Spyrou"], "title": "Quantifying the Impact of Missing Risk Markets for Decarbonized Power Systems with Long Duration Energy Storage", "comment": null, "summary": "The transition to a fully decarbonised electricity system depends on\nintegrating new technologies that ensure reliability alongside sustainability.\nHowever, missing risk markets hinder investment in reliability-enhancing\ntechnologies by exposing investors to revenue uncertainty. This study provides\nthe first quantitative assessment of how missing risk markets affect investment\ndecisions in power systems that depend on long-duration energy storage (LDES)\nfor reliability. We develop a two-stage stochastic equilibrium model with\nrisk-averse market participants, which independently sizes power and energy\ncapacity. We apply the method to a case study of a deeply decarbonised power\nsystem in Great Britain. The results show that incomplete risk markets reduce\nsocial welfare, harm reliability, and discourage investment in LDES and other\ntechnologies with volatile revenue streams. Revenue volatility leads to\nsubstantial risk premiums and higher financing costs for LDES, creating a\nbarrier to its large-scale deployment. These findings demonstrate the\nimportance of policy mechanisms that hedge revenue risk to lower the cost of\ncapital and accelerate investment in reliability-enhancing, zero-carbon\ntechnologies"}
{"id": "2510.13488", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13488", "abs": "https://arxiv.org/abs/2510.13488", "authors": ["Maximilian Stasica", "Arne Bick", "Nico Bohlinger", "Omid Mohseni", "Max Johannes Alois Fritzsche", "Clemens Hübler", "Jan Peters", "André Seyfarth"], "title": "Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations", "comment": null, "summary": "Legged robots, particularly quadrupeds, excel at navigating rough terrains,\nyet their performance under vertical ground perturbations, such as those from\noscillating surfaces, remains underexplored. This study introduces a novel\napproach to enhance quadruped locomotion robustness by training the Unitree Go2\nrobot on an oscillating bridge - a 13.24-meter steel-and-concrete structure\nwith a 2.0 Hz eigenfrequency designed to perturb locomotion. Using\nReinforcement Learning (RL) with the Proximal Policy Optimization (PPO)\nalgorithm in a MuJoCo simulation, we trained 15 distinct locomotion policies,\ncombining five gaits (trot, pace, bound, free, default) with three training\nconditions: rigid bridge and two oscillating bridge setups with differing\nheight regulation strategies (relative to bridge surface or ground). Domain\nrandomization ensured zero-shot transfer to the real-world bridge. Our results\ndemonstrate that policies trained on the oscillating bridge exhibit superior\nstability and adaptability compared to those trained on rigid surfaces. Our\nframework enables robust gait patterns even without prior bridge exposure.\nThese findings highlight the potential of simulation-based RL to improve\nquadruped locomotion during dynamic ground perturbations, offering insights for\ndesigning robots capable of traversing vibrating environments."}
{"id": "2510.13514", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13514", "abs": "https://arxiv.org/abs/2510.13514", "authors": ["Andreas C. Makrides", "Adam Suski", "Elina Spyrou"], "title": "Quantifying the Impact of Missing Risk Markets for Decarbonized Power Systems with Long Duration Energy Storage", "comment": null, "summary": "The transition to a fully decarbonised electricity system depends on\nintegrating new technologies that ensure reliability alongside sustainability.\nHowever, missing risk markets hinder investment in reliability-enhancing\ntechnologies by exposing investors to revenue uncertainty. This study provides\nthe first quantitative assessment of how missing risk markets affect investment\ndecisions in power systems that depend on long-duration energy storage (LDES)\nfor reliability. We develop a two-stage stochastic equilibrium model with\nrisk-averse market participants, which independently sizes power and energy\ncapacity. We apply the method to a case study of a deeply decarbonised power\nsystem in Great Britain. The results show that incomplete risk markets reduce\nsocial welfare, harm reliability, and discourage investment in LDES and other\ntechnologies with volatile revenue streams. Revenue volatility leads to\nsubstantial risk premiums and higher financing costs for LDES, creating a\nbarrier to its large-scale deployment. These findings demonstrate the\nimportance of policy mechanisms that hedge revenue risk to lower the cost of\ncapital and accelerate investment in reliability-enhancing, zero-carbon\ntechnologies"}
{"id": "2510.13551", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13551", "abs": "https://arxiv.org/abs/2510.13551", "authors": ["Robert West", "Ashton Anderson", "Ece Kamar", "Eric Horvitz"], "title": "Tandem Training for Language Models", "comment": null, "summary": "As language models continue to rapidly improve, we can expect their actions\nand reasoning to become difficult or impossible for weaker agents and humans to\nfollow, undermining interpretability and oversight. With an eye on long-term\nfutures, we pursue methods that encourage models to produce solutions that\nremain intelligible to weaker collaborators. We formalize intelligibility as\nhandoff robustness: a strong model's solution is intelligible to a weaker model\nif randomly handing off control to the weaker model along the solution path\ndoes not cause failure. Building on this criterion, we introduce tandem\ntraining for language models, a reinforcement learning (RL) paradigm in which\nrollout tokens are intermittently and randomly sampled from a frozen weak model\nrather than the strong model being trained. Because rollouts succeed only when\nthe strong model's actions and reasoning process can be continued by the weak\nmodel -- when the two can co-construct a successful solution -- optimizing\nstandard RL objectives with tandem training implicitly incentivizes both\ncorrectness and intelligibility. In the GSM8K math reasoning task, tandem\ntraining reliably teaches models to abandon jargon and adapt their language to\nweaker partners while keeping task accuracy high. Our results demonstrate a\npromising route to building AI systems that remain auditable by weaker agents,\nwith implications for human--AI collaboration and multi-agent communication."}
{"id": "2510.13591", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13591", "abs": "https://arxiv.org/abs/2510.13591", "authors": ["Nicola Fabiano"], "title": "Subject Roles in the EU AI Act: Mapping and Regulatory Implications", "comment": null, "summary": "The European Union's Artificial Intelligence Act (Regulation (EU) 2024/1689)\nestablishes the world's first comprehensive regulatory framework for AI systems\nthrough a sophisticated ecosystem of interconnected subjects defined in Article\n3. This paper provides a structured examination of the six main categories of\nactors - providers, deployers, authorized representatives, importers,\ndistributors, and product manufacturers - collectively referred to as\n\"operators\" within the regulation. Through examination of these Article 3\ndefinitions and their elaboration across the regulation's 113 articles, 180\nrecitals, and 13 annexes, we map the complete governance structure and analyze\nhow the AI Act regulates these subjects. Our analysis reveals critical\ntransformation mechanisms whereby subjects can assume different roles under\nspecific conditions, particularly through Article 25 provisions ensuring\naccountability follows control. We identify how obligations cascade through the\nsupply chain via mandatory information flows and cooperation requirements,\ncreating a distributed yet coordinated governance system. The findings\ndemonstrate how the regulation balances innovation with the protection of\nfundamental rights through risk-based obligations that scale with the\ncapabilities and deployment contexts of AI systems, providing essential\nguidance for stakeholders implementing the AI Act's requirements."}
{"id": "2510.13563", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13563", "abs": "https://arxiv.org/abs/2510.13563", "authors": ["Ayten Gürbüz", "Giuseppe Caire"], "title": "Channel Estimation under Large Doppler Shifts in NOMA-Based Air-Ground Communications", "comment": "Submitted to IEEE Conference, 6 pages, 2 Figures", "summary": "This paper investigates a multiple antenna system with non-orthogonal\nmultiple access (NOMA) for the exchange of air traffic management data between\ncommercial aircraft pilots and ground-based air traffic controllers. While NOMA\ntechniques enhance spectral efficiency, their application to aircraft\ncommunications is challenged by the high speed of the aircraft (up to 214 m/s)\nand the long communication ranges (up to 250 km), resulting in significant\nDoppler shifts and low signal-to-noise ratios, respectively. To accurately\nassess these challenges, we employ a realistic geometry-based stochastic\nair-ground channel model, derived from dedicated flight measurement campaigns.\nIn this paper, multiple aircraft simultaneously transmit data to the ground\nstation. We focus on the channel estimation problem at the ground station under\nhigh carrier frequency offsets and the effects of channel aging due to\nchannel's time-varying nature. For the channel estimation problem, we compare\nthe Zadoff-Chu sequences with time-division approach under varying carrier\nfrequency offset pre-compensation accuracies at the aircraft transmitter. For\nthe channel aging problem and performance evaluation of channel estimators, we\ncompute the outage probability for both the zero-forcing detector and the\nminimum mean squared error detector with successive interference cancellation.\nThe results show that the favorable channel estimator-detector combinations\ndiffer between the takeoff & landing phase and the enroute cruise phase of the\nflight, due to the distinct channel propagation characteristics of each phase."}
{"id": "2510.13535", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13535", "abs": "https://arxiv.org/abs/2510.13535", "authors": ["Wentao Guo", "Yizhou Wang", "Wenzeng Zhang"], "title": "A Novel Robot Hand with Hoeckens Linkages and Soft Phalanges for Scooping and Self-Adaptive Grasping in Environmental Constraints", "comment": "Accepted by IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025, Hangzhou. This version includes updated contact\n  information", "summary": "This paper presents a novel underactuated adaptive robotic hand, Hockens-A\nHand, which integrates the Hoeckens mechanism, a double-parallelogram linkage,\nand a specialized four-bar linkage to achieve three adaptive grasping modes:\nparallel pinching, asymmetric scooping, and enveloping grasping. Hockens-A Hand\nrequires only a single linear actuator, leveraging passive mechanical\nintelligence to ensure adaptability and compliance in unstructured\nenvironments. Specifically, the vertical motion of the Hoeckens mechanism\nintroduces compliance, the double-parallelogram linkage ensures line contact at\nthe fingertip, and the four-bar amplification system enables natural\ntransitions between different grasping modes. Additionally, the inclusion of a\nmesh-textured silicone phalanx further enhances the ability to envelop objects\nof various shapes and sizes. This study employs detailed kinematic analysis to\noptimize the push angle and design the linkage lengths for optimal performance.\nSimulations validated the design by analyzing the fingertip motion and ensuring\nsmooth transitions between grasping modes. Furthermore, the grasping force was\nanalyzed using power equations to enhance the understanding of the system's\nperformance.Experimental validation using a 3D-printed prototype demonstrates\nthe three grasping modes of the hand in various scenarios under environmental\nconstraints, verifying its grasping stability and broad applicability."}
{"id": "2510.13563", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13563", "abs": "https://arxiv.org/abs/2510.13563", "authors": ["Ayten Gürbüz", "Giuseppe Caire"], "title": "Channel Estimation under Large Doppler Shifts in NOMA-Based Air-Ground Communications", "comment": "Submitted to IEEE Conference, 6 pages, 2 Figures", "summary": "This paper investigates a multiple antenna system with non-orthogonal\nmultiple access (NOMA) for the exchange of air traffic management data between\ncommercial aircraft pilots and ground-based air traffic controllers. While NOMA\ntechniques enhance spectral efficiency, their application to aircraft\ncommunications is challenged by the high speed of the aircraft (up to 214 m/s)\nand the long communication ranges (up to 250 km), resulting in significant\nDoppler shifts and low signal-to-noise ratios, respectively. To accurately\nassess these challenges, we employ a realistic geometry-based stochastic\nair-ground channel model, derived from dedicated flight measurement campaigns.\nIn this paper, multiple aircraft simultaneously transmit data to the ground\nstation. We focus on the channel estimation problem at the ground station under\nhigh carrier frequency offsets and the effects of channel aging due to\nchannel's time-varying nature. For the channel estimation problem, we compare\nthe Zadoff-Chu sequences with time-division approach under varying carrier\nfrequency offset pre-compensation accuracies at the aircraft transmitter. For\nthe channel aging problem and performance evaluation of channel estimators, we\ncompute the outage probability for both the zero-forcing detector and the\nminimum mean squared error detector with successive interference cancellation.\nThe results show that the favorable channel estimator-detector combinations\ndiffer between the takeoff & landing phase and the enroute cruise phase of the\nflight, due to the distinct channel propagation characteristics of each phase."}
{"id": "2510.13691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13691", "abs": "https://arxiv.org/abs/2510.13691", "authors": ["Cecilia Di Florio", "Huimin Dong", "Antonino Rotolo"], "title": "A Modal Logic for Temporal and Jurisdictional Classifier Models", "comment": "18 pages, 2 figures. Extended version of a short paper accepted at\n  PRIMA 2025. This is the authors' version of the work. It is posted here for\n  your personal use", "summary": "Logic-based models can be used to build verification tools for machine\nlearning classifiers employed in the legal field. ML classifiers predict the\noutcomes of new cases based on previous ones, thereby performing a form of\ncase-based reasoning (CBR). In this paper, we introduce a modal logic of\nclassifiers designed to formally capture legal CBR. We incorporate principles\nfor resolving conflicts between precedents, by introducing into the logic the\ntemporal dimension of cases and the hierarchy of courts within the legal\nsystem."}
{"id": "2510.13621", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13621", "abs": "https://arxiv.org/abs/2510.13621", "authors": ["Yuexing Hao", "Yue Huang", "Haoran Zhang", "Chenyang Zhao", "Zhenwen Liang", "Paul Pu Liang", "Yue Zhao", "Lichao Sun", "Saleh Kalantari", "Xiangliang Zhang", "Marzyeh Ghassemi"], "title": "The Role of Computing Resources in Publishing Foundation Model Research", "comment": null, "summary": "Cutting-edge research in Artificial Intelligence (AI) requires considerable\nresources, including Graphics Processing Units (GPUs), data, and human\nresources. In this paper, we evaluate of the relationship between these\nresources and the scientific advancement of foundation models (FM). We reviewed\n6517 FM papers published between 2022 to 2024, and surveyed 229 first-authors\nto the impact of computing resources on scientific output. We find that\nincreased computing is correlated with national funding allocations and\ncitations, but our findings don't observe the strong correlations with research\nenvironment (academic or industrial), domain, or study methodology. We advise\nthat individuals and institutions focus on creating shared and affordable\ncomputing opportunities to lower the entry barrier for under-resourced\nresearchers. These steps can help expand participation in FM research, foster\ndiversity of ideas and contributors, and sustain innovation and progress in AI.\nThe data will be available at: https://mit-calc.csail.mit.edu/"}
{"id": "2510.13682", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13682", "abs": "https://arxiv.org/abs/2510.13682", "authors": ["Jiayang Li", "Qingyu Zhang", "Sohmyung Ha", "Dai Jiang", "Andreas Demosthenous", "Yu Wu"], "title": "A 0.62 μW/sensor 82 fps Time-to-Digital Impedance Measurement IC with Unified Excitation/Readout Front-end for Large-Scale Piezo-Resistive Sensor Array", "comment": null, "summary": "This paper presents a fast impedance measurement IC for large-scale\npiezo-resistive sensor array. It features a unified differential\ntime-to-digital demodulation architecture that readout impedance directly\nthrough the excitation circuit. The proposed pre-saturation adaptive bias\ntechnique further improves power efficiency. The chip scans 253 sensors in 12.2\nms (82 fps) at 125 kHz, consuming 158 {\\mu}W (7.5 nJ/sensor). With loads from\n20 {\\Omega} to 500 k{\\Omega}, it achieves 0.5% error and up to 71.1 dB SNR."}
{"id": "2510.13553", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13553", "abs": "https://arxiv.org/abs/2510.13553", "authors": ["Wentao Guo", "Wenzeng Zhang"], "title": "Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping", "comment": "Accepted by IEEE International Conference on Robotics and Biomimetics\n  (IROS) 2025, Hangzhou, China. This version includes updated contact\n  information", "summary": "This paper presents the Hoecken-D Hand, an underactuated robotic gripper that\ncombines a modified Hoecken linkage with a differential spring mechanism to\nachieve both linear parallel pinching and a mid-stroke transition to adaptive\nenvelope. The original Hoecken linkage is reconfigured by replacing one member\nwith differential links, preserving straight-line guidance while enabling\ncontact-triggered reconfiguration without additional actuators. A\ndouble-parallelogram arrangement maintains fingertip parallelism during\nconventional pinching, whereas the differential mechanism allows one finger to\nwrap inward upon encountering an obstacle, improving stability on irregular or\nthin objects. The mechanism can be driven by a single linear actuator,\nminimizing complexity and cost; in our prototype, each finger is driven by its\nown linear actuator for simplicity. We perform kinematic modeling and force\nanalysis to characterize grasp performance, including simulated grasping forces\nand spring-opening behavior under varying geometric parameters. The design was\nprototyped using PLA-based 3D printing, achieving a linear pinching span of\napproximately 200 mm. Preliminary tests demonstrate reliable grasping in both\nmodes across a wide range of object geometries, highlighting the Hoecken-D Hand\nas a compact, adaptable, and cost-effective solution for manipulation in\nunstructured environments."}
{"id": "2510.13682", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13682", "abs": "https://arxiv.org/abs/2510.13682", "authors": ["Jiayang Li", "Qingyu Zhang", "Sohmyung Ha", "Dai Jiang", "Andreas Demosthenous", "Yu Wu"], "title": "A 0.62 μW/sensor 82 fps Time-to-Digital Impedance Measurement IC with Unified Excitation/Readout Front-end for Large-Scale Piezo-Resistive Sensor Array", "comment": null, "summary": "This paper presents a fast impedance measurement IC for large-scale\npiezo-resistive sensor array. It features a unified differential\ntime-to-digital demodulation architecture that readout impedance directly\nthrough the excitation circuit. The proposed pre-saturation adaptive bias\ntechnique further improves power efficiency. The chip scans 253 sensors in 12.2\nms (82 fps) at 125 kHz, consuming 158 {\\mu}W (7.5 nJ/sensor). With loads from\n20 {\\Omega} to 500 k{\\Omega}, it achieves 0.5% error and up to 71.1 dB SNR."}
{"id": "2510.13709", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13709", "abs": "https://arxiv.org/abs/2510.13709", "authors": ["Evan Ellis", "Vivek Myers", "Jens Tuyls", "Sergey Levine", "Anca Dragan", "Benjamin Eysenbach"], "title": "Training LLM Agents to Empower Humans", "comment": null, "summary": "Assistive agents should not only take actions on behalf of a human, but also\nstep out of the way and cede control when there are important decisions to be\nmade. However, current methods for building assistive agents, whether via\nmimicking expert humans or via RL finetuning on an inferred reward, often\nencourage agents to complete tasks on their own rather than truly assisting the\nhuman attain their objectives. Additionally, these methods often require costly\nexplicit human feedback to provide a training signal. We propose a new approach\nto tuning assistive language models based on maximizing the human's\nempowerment, their ability to effect desired changes in the environment. Our\nempowerment-maximizing method, Empower, only requires offline text data,\nproviding a self-supervised method for fine-tuning language models to better\nassist humans. To study the efficacy of our approach, we conducted an 18-person\nuser study comparing our empowerment assistant with a strong baseline.\nParticipants preferred our assistant 78% of the time (p=0.015), with a 31%\nhigher acceptance rate and 38% fewer suggestions. Additionally, we introduce a\nnew environment for evaluating multi-turn code assistance using simulated\nhumans. Using this environment, we show that agents trained with Empower\nincrease the success rate of a simulated human programmer on challenging coding\nquestions by an average of 192% over an SFT baseline. With this empowerment\nobjective, we provide a framework for useful aligned AI agents at scale using\nonly offline data without the need for any additional human feedback or\nverifiable rewards."}
{"id": "2510.13653", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13653", "abs": "https://arxiv.org/abs/2510.13653", "authors": ["Yoshua Bengio", "Stephen Clare", "Carina Prunkl", "Shalaleh Rismani", "Maksym Andriushchenko", "Ben Bucknall", "Philip Fox", "Tiancheng Hu", "Cameron Jones", "Sam Manning", "Nestor Maslej", "Vasilios Mavroudis", "Conor McGlynn", "Malcolm Murray", "Charlotte Stix", "Lucia Velasco", "Nicole Wheeler", "Daniel Privitera", "Sören Mindermann", "Daron Acemoglu", "Thomas G. Dietterich", "Fredrik Heintz", "Geoffrey Hinton", "Nick Jennings", "Susan Leavy", "Teresa Ludermir", "Vidushi Marda", "Helen Margetts", "John McDermid", "Jane Munga", "Arvind Narayanan", "Alondra Nelson", "Clara Neppel", "Gopal Ramchurn", "Stuart Russell", "Marietje Schaake", "Bernhard Schölkopf", "Alavaro Soto", "Lee Tiedrich", "Gaël Varoquaux", "Andrew Yao", "Ya-Qin Zhang", "Leandro Aguirre", "Olubunmi Ajala", "Fahad Albalawi Noora AlMalek", "Christian Busch", "André Carvalho", "Jonathan Collas", "Amandeep Gill", "Ahmet Hatip", "Juha Heikkilä", "Chris Johnson", "Gill Jolly", "Ziv Katzir", "Mary Kerema", "Hiroaki Kitano", "Antonio Krüger", "Aoife McLysaght", "Oleksii Molchanovskyi", "Andrea Monti", "Kyoung Mu Lee", "Mona Nemer", "Nuria Oliver", "Raquel Pezoa", "Audrey Plonk", "José Portillo", "Balaraman Ravindran", "Hammam Riza", "Crystal Rugege", "Haroon Sheikh", "Denise Wong", "Yi Zeng", "Liming Zhu"], "title": "International AI Safety Report 2025: First Key Update: Capabilities and Risk Implications", "comment": null, "summary": "Since the publication of the first International AI Safety Report, AI\ncapabilities have continued to improve across key domains. New training\ntechniques that teach AI systems to reason step-by-step and inference-time\nenhancements have primarily driven these advances, rather than simply training\nlarger models. As a result, general-purpose AI systems can solve more complex\nproblems in a range of domains, from scientific research to software\ndevelopment. Their performance on benchmarks that measure performance in\ncoding, mathematics, and answering expert-level science questions has continued\nto improve, though reliability challenges persist, with systems excelling on\nsome tasks while failing completely on others. These capability improvements\nalso have implications for multiple risks, including risks from biological\nweapons and cyber attacks. Finally, they pose new challenges for monitoring and\ncontrollability. This update examines how AI capabilities have improved since\nthe first Report, then focuses on key risk areas where substantial new evidence\nwarrants updated assessments."}
{"id": "2510.12919", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12919", "abs": "https://arxiv.org/abs/2510.12919", "authors": ["Mouhyemen Khan", "Tatsuya Ibuki", "Abhijit Chatterjee"], "title": "Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation", "comment": "8 pages, 7 figures, under review", "summary": "Level set methods underpin modern safety techniques such as control barrier\nfunctions (CBFs), while also serving as implicit surface representations for\ngeometric shapes via distance fields. Inspired by these two paradigms, we\npropose a unified framework where the implicit surface itself acts as a CBF. We\nleverage Gaussian process (GP) implicit surface (GPIS) to represent the safety\nboundaries, using safety samples which are derived from sensor measurements to\ncondition the GP. The GP posterior mean defines the implicit safety surface\n(safety belief), while the posterior variance provides a robust safety margin.\nAlthough GPs have favorable properties such as uncertainty estimation and\nanalytical tractability, they scale cubically with data. To alleviate this\nissue, we develop a sparse solution called sparse Gaussian CBFs. To the best of\nour knowledge, GPIS have not been explicitly used to synthesize CBFs. We\nvalidate the approach on collision avoidance tasks in two settings: a simulated\n7-DOF manipulator operating around the Stanford bunny, and a quadrotor\nnavigating in 3D around a physical chair. In both cases, Gaussian CBFs (with\nand without sparsity) enable safe interaction and collision-free execution of\ntrajectories that would otherwise intersect the objects."}
{"id": "2510.13594", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13594", "abs": "https://arxiv.org/abs/2510.13594", "authors": ["Austin Barret", "Meng Cheng Lau"], "title": "Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots", "comment": "9 Figure. Presented at FIRA Summit 2025, Daegu, S. Korea", "summary": "The operation of humanoid robotics is an essential field of research with\nmany practical and competitive applications. Many of these systems, however, do\nnot invest heavily in developing a non-expert-centered graphical user interface\n(GUI) for operation. The focus of this research is to develop a scalable GUI\nthat is tailored to be simple and intuitive so non-expert operators can control\nthe robot through a FIRA-regulated obstacle course. Using common practices from\nuser interface development (UI) and understanding concepts described in\nhuman-robot interaction (HRI) and other related concepts, we will develop a new\ninterface with the goal of a non-expert teleoperation system."}
{"id": "2510.12919", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12919", "abs": "https://arxiv.org/abs/2510.12919", "authors": ["Mouhyemen Khan", "Tatsuya Ibuki", "Abhijit Chatterjee"], "title": "Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation", "comment": "8 pages, 7 figures, under review", "summary": "Level set methods underpin modern safety techniques such as control barrier\nfunctions (CBFs), while also serving as implicit surface representations for\ngeometric shapes via distance fields. Inspired by these two paradigms, we\npropose a unified framework where the implicit surface itself acts as a CBF. We\nleverage Gaussian process (GP) implicit surface (GPIS) to represent the safety\nboundaries, using safety samples which are derived from sensor measurements to\ncondition the GP. The GP posterior mean defines the implicit safety surface\n(safety belief), while the posterior variance provides a robust safety margin.\nAlthough GPs have favorable properties such as uncertainty estimation and\nanalytical tractability, they scale cubically with data. To alleviate this\nissue, we develop a sparse solution called sparse Gaussian CBFs. To the best of\nour knowledge, GPIS have not been explicitly used to synthesize CBFs. We\nvalidate the approach on collision avoidance tasks in two settings: a simulated\n7-DOF manipulator operating around the Stanford bunny, and a quadrotor\nnavigating in 3D around a physical chair. In both cases, Gaussian CBFs (with\nand without sparsity) enable safe interaction and collision-free execution of\ntrajectories that would otherwise intersect the objects."}
{"id": "2510.13727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13727", "abs": "https://arxiv.org/abs/2510.13727", "authors": ["Ravi Pandya", "Madison Bland", "Duy P. Nguyen", "Changliu Liu", "Jaime Fernández Fisac", "Andrea Bajcsy"], "title": "From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails", "comment": null, "summary": "Generative AI systems are increasingly assisting and acting on behalf of end\nusers in practical settings, from digital shopping assistants to\nnext-generation autonomous cars. In this context, safety is no longer about\nblocking harmful content, but about preempting downstream hazards like\nfinancial or physical harm. Yet, most AI guardrails continue to rely on output\nclassification based on labeled datasets and human-specified criteria,making\nthem brittle to new hazardous situations. Even when unsafe conditions are\nflagged, this detection offers no path to recovery: typically, the AI system\nsimply refuses to act--which is not always a safe choice. In this work, we\nargue that agentic AI safety is fundamentally a sequential decision problem:\nharmful outcomes arise from the AI system's continually evolving interactions\nand their downstream consequences on the world. We formalize this through the\nlens of safety-critical control theory, but within the AI model's latent\nrepresentation of the world. This enables us to build predictive guardrails\nthat (i) monitor an AI system's outputs (actions) in real time and (ii)\nproactively correct risky outputs to safe ones, all in a model-agnostic manner\nso the same guardrail can be wrapped around any AI model. We also offer a\npractical training recipe for computing such guardrails at scale via\nsafety-critical reinforcement learning. Our experiments in simulated driving\nand e-commerce settings demonstrate that control-theoretic guardrails can\nreliably steer LLM agents clear of catastrophic outcomes (from collisions to\nbankruptcy) while preserving task performance, offering a principled dynamic\nalternative to today's flag-and-block guardrails."}
{"id": "2510.13369", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.13369", "abs": "https://arxiv.org/abs/2510.13369", "authors": ["Jacob Schaal"], "title": "A theory-based AI automation exposure index: Applying Moravec's Paradox to the US labor market", "comment": null, "summary": "This paper develops a theory-driven automation exposure index based on\nMoravec's Paradox. Scoring 19,000 O*NET tasks on performance variance, tacit\nknowledge, data abundance, and algorithmic gaps reveals that management, STEM,\nand sciences occupations show the highest exposure. In contrast, maintenance,\nagriculture, and construction show the lowest. The positive relationship\nbetween wages and exposure challenges the notion of skill-biased technological\nchange if AI substitutes for workers. At the same time, tacit knowledge\nexhibits a positive relationship with wages consistent with seniority-biased\ntechnological change. This index identifies fundamental automatability rather\nthan current capabilities, while also validating the AI annotation method\npioneered by Eloundou et al. (2024) with a correlation of 0.72. The\nnon-positive relationship with pre-LLM indices suggests a paradigm shift in\nautomation patterns."}
{"id": "2510.13616", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.13616", "abs": "https://arxiv.org/abs/2510.13616", "authors": ["Preston Fairchild", "Claudia Chen", "Xiaobo Tan"], "title": "Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor", "comment": "For supplementary videos, see\n  https://drive.google.com/drive/folders/1jol-_z6gaUfjpL1Qi7EG420usTbVSodv?usp=sharing", "summary": "Properly handling delicate produce with robotic manipulators is a major part\nof the future role of automation in agricultural harvesting and processing.\nGrasping with the correct amount of force is crucial in not only ensuring\nproper grip on the object, but also to avoid damaging or bruising the product.\nIn this work, a flexible pressure sensor that is both low cost and easy to\nfabricate is integrated with robotic grippers for working with produce of\nvarying shapes, sizes, and stiffnesses. The sensor is successfully integrated\nwith both a rigid robotic gripper, as well as a pneumatically actuated soft\nfinger. Furthermore, an algorithm is proposed for accelerated estimation of the\nsteady-state value of the sensor output based on the transient response data,\nto enable real-time applications. The sensor is shown to be effective in\nincorporating feedback to correctly grasp objects of unknown sizes and\nstiffnesses. At the same time, the sensor provides estimates for these values\nwhich can be utilized for identification of qualities such as ripeness levels\nand bruising. It is also shown to be able to provide force feedback for objects\nof variable stiffnesses. This enables future use not only for produce\nidentification, but also for tasks such as quality control and selective\ndistribution based on ripeness levels."}
{"id": "2510.13595", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13595", "abs": "https://arxiv.org/abs/2510.13595", "authors": ["Ethan K. Gordon", "Bruke Baraki", "Hien Bui", "Michael Posa"], "title": "Active Tactile Exploration for Rigid Body Pose and Shape Estimation", "comment": "8 pages, 6 figures", "summary": "General robot manipulation requires the handling of previously unseen\nobjects. Learning a physically accurate model at test time can provide\nsignificant benefits in data efficiency, predictability, and reuse between\ntasks. Tactile sensing can compliment vision with its robustness to occlusion,\nbut its temporal sparsity necessitates careful online exploration to maintain\ndata efficiency. Direct contact can also cause an unrestrained object to move,\nrequiring both shape and location estimation. In this work, we propose a\nlearning and exploration framework that uses only tactile data to\nsimultaneously determine the shape and location of rigid objects with minimal\nrobot motion. We build on recent advances in contact-rich system identification\nto formulate a loss function that penalizes physical constraint violation\nwithout introducing the numerical stiffness inherent in rigid-body contact.\nOptimizing this loss, we can learn cuboid and convex polyhedral geometries with\nless than 10s of randomly collected data after first contact. Our exploration\nscheme seeks to maximize Expected Information Gain and results in significantly\nfaster learning in both simulated and real-robot experiments. More information\ncan be found at https://dairlab.github.io/activetactile"}
{"id": "2510.13616", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.13616", "abs": "https://arxiv.org/abs/2510.13616", "authors": ["Preston Fairchild", "Claudia Chen", "Xiaobo Tan"], "title": "Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor", "comment": "For supplementary videos, see\n  https://drive.google.com/drive/folders/1jol-_z6gaUfjpL1Qi7EG420usTbVSodv?usp=sharing", "summary": "Properly handling delicate produce with robotic manipulators is a major part\nof the future role of automation in agricultural harvesting and processing.\nGrasping with the correct amount of force is crucial in not only ensuring\nproper grip on the object, but also to avoid damaging or bruising the product.\nIn this work, a flexible pressure sensor that is both low cost and easy to\nfabricate is integrated with robotic grippers for working with produce of\nvarying shapes, sizes, and stiffnesses. The sensor is successfully integrated\nwith both a rigid robotic gripper, as well as a pneumatically actuated soft\nfinger. Furthermore, an algorithm is proposed for accelerated estimation of the\nsteady-state value of the sensor output based on the transient response data,\nto enable real-time applications. The sensor is shown to be effective in\nincorporating feedback to correctly grasp objects of unknown sizes and\nstiffnesses. At the same time, the sensor provides estimates for these values\nwhich can be utilized for identification of qualities such as ripeness levels\nand bruising. It is also shown to be able to provide force feedback for objects\nof variable stiffnesses. This enables future use not only for produce\nidentification, but also for tasks such as quality control and selective\ndistribution based on ripeness levels."}
{"id": "2510.13744", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13744", "abs": "https://arxiv.org/abs/2510.13744", "authors": ["Shrey Pandit", "Austin Xu", "Xuan-Phi Nguyen", "Yifei Ming", "Caiming Xiong", "Shafiq Joty"], "title": "Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math", "comment": "21 pages, 8 figures, 5 tables", "summary": "Large language model (LLM)-based reasoning systems have recently achieved\ngold medal-level performance in the IMO 2025 competition, writing mathematical\nproofs where, to receive full credit, each step must be not only correct but\nalso sufficiently supported. To train LLM-based reasoners in such challenging,\nopen-ended settings, strong verifiers capable of catching step-level mistakes\nare necessary prerequisites. We introduce Hard2Verify, a human-annotated,\nstep-level verification benchmark produced with over 500 hours of human labor.\nHard2Verify is designed to rigorously assess step-level verifiers at the\nfrontier: Verifiers must provide step-level annotations or identify the first\nerror in responses generated by frontier LLMs for very recent, challenging, and\nopen-ended math questions. We evaluate 29 generative critics and process reward\nmodels, demonstrating that, beyond a few standouts, open-source verifiers lag\nclosed source models. We subsequently analyze what drives poor performance in\nstep-level verification, the impacts of scaling verifier compute, as well as\nfundamental questions such as self-verification and verification-generation\ndynamics."}
{"id": "2510.13599", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13599", "abs": "https://arxiv.org/abs/2510.13599", "authors": ["Jiahao Wang", "Nived Chebrolu", "Yifu Tao", "Lintong Zhang", "Ayoung Kim", "Maurice Fallon"], "title": "PlanarMesh: Building Compact 3D Meshes from LiDAR using Incremental Adaptive Resolution Reconstruction", "comment": null, "summary": "Building an online 3D LiDAR mapping system that produces a detailed surface\nreconstruction while remaining computationally efficient is a challenging task.\nIn this paper, we present PlanarMesh, a novel incremental, mesh-based LiDAR\nreconstruction system that adaptively adjusts mesh resolution to achieve\ncompact, detailed reconstructions in real-time. It introduces a new\nrepresentation, planar-mesh, which combines plane modeling and meshing to\ncapture both large surfaces and detailed geometry. The planar-mesh can be\nincrementally updated considering both local surface curvature and free-space\ninformation from sensor measurements. We employ a multi-threaded architecture\nwith a Bounding Volume Hierarchy (BVH) for efficient data storage and fast\nsearch operations, enabling real-time performance. Experimental results show\nthat our method achieves reconstruction accuracy on par with, or exceeding,\nstate-of-the-art techniques-including truncated signed distance functions,\noccupancy mapping, and voxel-based meshing-while producing smaller output file\nsizes (10 times smaller than raw input and more than 5 times smaller than\nmesh-based methods) and maintaining real-time performance (around 2 Hz for a\n64-beam sensor)."}
{"id": "2510.12822", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12822", "abs": "https://arxiv.org/abs/2510.12822", "authors": ["Michele Loi", "Marcello Di Bello", "Nicolò Cangiotti"], "title": "Evidence Without Injustice: A New Counterfactual Test for Fair Algorithms", "comment": "13 pages", "summary": "The growing philosophical literature on algorithmic fairness has examined\nstatistical criteria such as equalized odds and calibration, causal and\ncounterfactual approaches, and the role of structural and compounding\ninjustices. Yet an important dimension has been overlooked: whether the\nevidential value of an algorithmic output itself depends on structural\ninjustice. Our paradigmatic pair of examples contrasts a predictive policing\nalgorithm, which relies on historical crime data, with a camera-based system\nthat records ongoing offenses, both designed to guide police deployment. In\nevaluating the moral acceptability of acting on a piece of evidence, we must\nask not only whether the evidence is probative in the actual world, but also\nwhether it would remain probative in nearby worlds without the relevant\ninjustices. The predictive policing algorithm fails this test, but the\ncamera-based system passes it. When evidence fails the test, it is morally\nproblematic to use it punitively, more so than evidence that passes the test."}
{"id": "2510.13616", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.13616", "abs": "https://arxiv.org/abs/2510.13616", "authors": ["Preston Fairchild", "Claudia Chen", "Xiaobo Tan"], "title": "Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor", "comment": "For supplementary videos, see\n  https://drive.google.com/drive/folders/1jol-_z6gaUfjpL1Qi7EG420usTbVSodv?usp=sharing", "summary": "Properly handling delicate produce with robotic manipulators is a major part\nof the future role of automation in agricultural harvesting and processing.\nGrasping with the correct amount of force is crucial in not only ensuring\nproper grip on the object, but also to avoid damaging or bruising the product.\nIn this work, a flexible pressure sensor that is both low cost and easy to\nfabricate is integrated with robotic grippers for working with produce of\nvarying shapes, sizes, and stiffnesses. The sensor is successfully integrated\nwith both a rigid robotic gripper, as well as a pneumatically actuated soft\nfinger. Furthermore, an algorithm is proposed for accelerated estimation of the\nsteady-state value of the sensor output based on the transient response data,\nto enable real-time applications. The sensor is shown to be effective in\nincorporating feedback to correctly grasp objects of unknown sizes and\nstiffnesses. At the same time, the sensor provides estimates for these values\nwhich can be utilized for identification of qualities such as ripeness levels\nand bruising. It is also shown to be able to provide force feedback for objects\nof variable stiffnesses. This enables future use not only for produce\nidentification, but also for tasks such as quality control and selective\ndistribution based on ripeness levels."}
{"id": "2510.12830", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12830", "abs": "https://arxiv.org/abs/2510.12830", "authors": ["Alex Dantart"], "title": "Gobernanza y trazabilidad \"a prueba de AI Act\" para casos de uso legales: un marco técnico-jurídico, métricas forenses y evidencias auditables", "comment": "in Spanish language", "summary": "This paper presents a comprehensive governance framework for AI systems in\nthe legal sector, designed to ensure verifiable compliance with the EU AI Act.\nThe framework integrates a normative mapping of the regulation to technical\ncontrols, a forensic architecture for RAG/LLM systems, and an evaluation system\nwith metrics weighted by legal risk. As a primary contribution, we present\nrag-forense, an open-source implementation of the framework, accompanied by an\nexperimental protocol to demonstrate compliance. -- Este art\\'iculo presenta un\nmarco integral de gobernanza para sistemas de IA en el sector legal, dise\\~nado\npara garantizar el cumplimiento verificable del Reglamento de IA de la UE (AI\nAct). El marco integra una cartograf\\'ia normativa de la ley a controles\nt\\'ecnicos, una arquitectura forense para sistemas RAG/LLM y un sistema de\nevaluaci\\'on con m\\'etricas ponderadas por el riesgo jur\\'idico. Como principal\ncontribuci\\'on, se presenta rag-forense, una implementaci\\'on de c\\'odigo\nabierto del marco, acompa\\~nada de un protocolo experimental para demostrar la\nconformidad."}
{"id": "2510.13619", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13619", "abs": "https://arxiv.org/abs/2510.13619", "authors": ["Daniel Choate", "Jason Rife"], "title": "Characterizing Lidar Point-Cloud Adversities Using a Vector Field Visualization", "comment": "This is the preprint version of the paper published in: Proceedings\n  of the 37th International Technical Meeting of the Satellite Division of The\n  Institute of Navigation (ION GNSS+ 2024), September 2024 The final version is\n  available at https://doi.org/10.33012/2024.19864", "summary": "In this paper we introduce a visualization methodology to aid a human analyst\nin classifying adversity modes that impact lidar scan matching. Our methodology\nis intended for offline rather than real-time analysis. The method generates a\nvector-field plot that characterizes local discrepancies between a pair of\nregistered point clouds. The vector field plot reveals patterns that would be\ndifficult for the analyst to extract from raw point-cloud data. After\nintroducing our methodology, we apply the process to two proof-of-concept\nexamples: one a simulation study and the other a field experiment. For both\ndata sets, a human analyst was able to reason about a series of adversity\nmechanisms and iteratively remove those mechanisms from the raw data, to help\nfocus attention on progressively smaller discrepancies."}
{"id": "2510.12832", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12832", "abs": "https://arxiv.org/abs/2510.12832", "authors": ["Alistair Brash", "Junyi Lu", "Bruce Stephen", "Blair Brown", "Robert Atkinson", "Craig Michie", "Fraser MacIntyre", "Christos Tachtatzis"], "title": "Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation", "comment": null, "summary": "Limited visibility of power distribution network power flows at the low\nvoltage level presents challenges to both distribution network operators from a\nplanning perspective and distribution system operators from a congestion\nmanagement perspective. Forestalling these challenges through scenario analysis\nis confounded by the lack of realistic and coherent load data across\nrepresentative distribution feeders. Load profiling approaches often rely on\nsummarising demand through typical profiles, which oversimplifies the\ncomplexity of substation-level operations and limits their applicability in\nspecific power system studies. Sampling methods, and more recently generative\nmodels, have attempted to address this through synthesising representative\nloads from historical exemplars; however, while these approaches can\napproximate load shapes to a convincing degree of fidelity, the co-behaviour\nbetween substations, which ultimately impacts higher voltage level network\noperation, is often overlooked. This limitation will become even more\npronounced with the increasing integration of low-carbon technologies, as\nestimates of base loads fail to capture load diversity. To address this gap, a\nConditional Diffusion model for synthesising daily active and reactive power\nprofiles at the low voltage distribution substation level is proposed. The\nevaluation of fidelity is demonstrated through conventional metrics capturing\ntemporal and statistical realism, as well as power flow modelling. The results\nshow synthesised load profiles are plausible both independently and as a cohort\nin a wider power systems context. The Conditional Diffusion model is\nbenchmarked against both naive and state-of-the-art models to demonstrate its\neffectiveness in producing realistic scenarios on which to base sub-regional\npower distribution network planning and operations."}
{"id": "2510.13625", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13625", "abs": "https://arxiv.org/abs/2510.13625", "authors": ["Nicolas Pottier", "Meng Cheng Lau"], "title": "A Modular Object Detection System for Humanoid Robots Using YOLO", "comment": "7 Figures, 5 tables. This article was presented at FIRA Summit 2025.\n  It will be updated for journal submission", "summary": "Within the field of robotics, computer vision remains a significant barrier\nto progress, with many tasks hindered by inefficient vision systems. This\nresearch proposes a generalized vision module leveraging YOLOv9, a\nstate-of-the-art framework optimized for computationally constrained\nenvironments like robots. The model is trained on a dataset tailored to the\nFIRA robotics Hurocup. A new vision module is implemented in ROS1 using a\nvirtual environment to enable YOLO compatibility. Performance is evaluated\nusing metrics such as frames per second (FPS) and Mean Average Precision (mAP).\nPerformance is then compared to the existing geometric framework in static and\ndynamic contexts. The YOLO model achieved comparable precision at a higher\ncomputational cost then the geometric model, while providing improved\nrobustness."}
{"id": "2510.12850", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12850", "abs": "https://arxiv.org/abs/2510.12850", "authors": ["Mahamodul Hasan Mahadi", "Md. Nasif Safwan", "Souhardo Rahman", "Shahnaj Parvin", "Aminun Nahar", "Kamruddin Nur"], "title": "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification", "comment": null, "summary": "Developing AI systems capable of nuanced ethical reasoning is critical as\nthey increasingly influence human decisions, yet existing models often rely on\nsuperficial correlations rather than principled moral understanding. This paper\nintroduces Ethic-BERT, a BERT-based model for ethical content classification\nacross four domains: Commonsense, Justice, Virtue, and Deontology. Leveraging\nthe ETHICS dataset, our approach integrates robust preprocessing to address\nvocabulary sparsity and contextual ambiguities, alongside advanced fine-tuning\nstrategies like full model unfreezing, gradient accumulation, and adaptive\nlearning rate scheduling. To evaluate robustness, we employ an adversarially\nfiltered \"Hard Test\" split, isolating complex ethical dilemmas. Experimental\nresults demonstrate Ethic-BERT's superiority over baseline models, achieving\n82.32% average accuracy on the standard test, with notable improvements in\nJustice and Virtue. In addition, the proposed Ethic-BERT attains 15.28% average\naccuracy improvement in the HardTest. These findings contribute to performance\nimprovement and reliable decision-making using bias-aware preprocessing and\nproposed enhanced AI model."}
{"id": "2510.13626", "categories": ["cs.RO", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.13626", "abs": "https://arxiv.org/abs/2510.13626", "authors": ["Senyu Fei", "Siyin Wang", "Junhao Shi", "Zihao Dai", "Jikun Cai", "Pengfang Qian", "Li Ji", "Xinzhe He", "Shiduo Zhang", "Zhaoye Fei", "Jinlan Fu", "Jingjing Gong", "Xipeng Qiu"], "title": "LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models", "comment": null, "summary": "Visual-Language-Action (VLA) models report impressive success rates on\nrobotic manipulation benchmarks, yet these results may mask fundamental\nweaknesses in robustness. We perform a systematic vulnerability analysis by\nintroducing controlled perturbations across seven dimensions: objects layout,\ncamera viewpoints, robot initial states, language instructions, light\nconditions, background textures and sensor noise. We comprehensively analyzed\nmultiple state-of-the-art models and revealed consistent brittleness beneath\napparent competence. Our analysis exposes critical weaknesses: models exhibit\nextreme sensitivity to perturbation factors, including camera viewpoints and\nrobot initial states, with performance dropping from 95% to below 30% under\nmodest perturbations. Surprisingly, models are largely insensitive to language\nvariations, with further experiments revealing that models tend to ignore\nlanguage instructions completely. Our findings challenge the assumption that\nhigh benchmark scores equate to true competency and highlight the need for\nevaluation practices that assess reliability under realistic variation."}
{"id": "2510.12857", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12857", "abs": "https://arxiv.org/abs/2510.12857", "authors": ["Robin Staab", "Jasper Dekoninck", "Maximilian Baader", "Martin Vechev"], "title": "Adaptive Generation of Bias-Eliciting Questions for LLMs", "comment": null, "summary": "Large language models (LLMs) are now widely deployed in user-facing\napplications, reaching hundreds of millions worldwide. As they become\nintegrated into everyday tasks, growing reliance on their outputs raises\nsignificant concerns. In particular, users may unknowingly be exposed to\nmodel-inherent biases that systematically disadvantage or stereotype certain\ngroups. However, existing bias benchmarks continue to rely on templated prompts\nor restrictive multiple-choice questions that are suggestive, simplistic, and\nfail to capture the complexity of real-world user interactions. In this work,\nwe address this gap by introducing a counterfactual bias evaluation framework\nthat automatically generates realistic, open-ended questions over sensitive\nattributes such as sex, race, or religion. By iteratively mutating and\nselecting bias-inducing questions, our approach systematically explores areas\nwhere models are most susceptible to biased behavior. Beyond detecting harmful\nbiases, we also capture distinct response dimensions that are increasingly\nrelevant in user interactions, such as asymmetric refusals and explicit\nacknowledgment of bias. Leveraging our framework, we construct CAB, a\nhuman-verified benchmark spanning diverse topics, designed to enable\ncross-model comparisons. Using CAB, we analyze a range of LLMs across multiple\nbias dimensions, revealing nuanced insights into how different models manifest\nbias. For instance, while GPT-5 outperforms other models, it nonetheless\nexhibits persistent biases in specific scenarios. These findings underscore the\nneed for continual improvements to ensure fair model behavior."}
{"id": "2510.13644", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13644", "abs": "https://arxiv.org/abs/2510.13644", "authors": ["Michael Bosello", "Flavio Pinzarrone", "Sara Kiade", "Davide Aguiari", "Yvo Keuter", "Aaesha AlShehhi", "Gyordan Caminati", "Kei Long Wong", "Ka Seng Chou", "Junaid Halepota", "Fares Alneyadi", "Jacopo Panerati", "Giovanni Pau"], "title": "On Your Own: Pro-level Autonomous Drone Racing in Uninstrumented Arenas", "comment": null, "summary": "Drone technology is proliferating in many industries, including agriculture,\nlogistics, defense, infrastructure, and environmental monitoring. Vision-based\nautonomy is one of its key enablers, particularly for real-world applications.\nThis is essential for operating in novel, unstructured environments where\ntraditional navigation methods may be unavailable. Autonomous drone racing has\nbecome the de facto benchmark for such systems. State-of-the-art research has\nshown that autonomous systems can surpass human-level performance in racing\narenas. However, direct applicability to commercial and field operations is\nstill limited as current systems are often trained and evaluated in highly\ncontrolled environments. In our contribution, the system's capabilities are\nanalyzed within a controlled environment -- where external tracking is\navailable for ground-truth comparison -- but also demonstrated in a\nchallenging, uninstrumented environment -- where ground-truth measurements were\nnever available. We show that our approach can match the performance of\nprofessional human pilots in both scenarios. We also publicly release the data\nfrom the flights carried out by our approach and a world-class human pilot."}
{"id": "2510.12859", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12859", "abs": "https://arxiv.org/abs/2510.12859", "authors": ["Masoud Makrehchi"], "title": "Three Lenses on the AI Revolution: Risk, Transformation, Continuity", "comment": "17 pages", "summary": "Artificial Intelligence (AI) has emerged as both a continuation of historical\ntechnological revolutions and a potential rupture with them. This paper argues\nthat AI must be viewed simultaneously through three lenses: \\textit{risk},\nwhere it resembles nuclear technology in its irreversible and global\nexternalities; \\textit{transformation}, where it parallels the Industrial\nRevolution as a general-purpose technology driving productivity and\nreorganization of labor; and \\textit{continuity}, where it extends the\nfifty-year arc of computing revolutions from personal computing to the internet\nto mobile. Drawing on historical analogies, we emphasize that no past\ntransition constituted a strict singularity: disruptive shifts eventually\nbecame governable through new norms and institutions.\n  We examine recurring patterns across revolutions -- democratization at the\nusage layer, concentration at the production layer, falling costs, and\ndeepening personalization -- and show how these dynamics are intensifying in\nthe AI era. Sectoral analysis illustrates how accounting, law, education,\ntranslation, advertising, and software engineering are being reshaped as\nroutine cognition is commoditized and human value shifts to judgment, trust,\nand ethical responsibility. At the frontier, the challenge of designing moral\nAI agents highlights the need for robust guardrails, mechanisms for moral\ngeneralization, and governance of emergent multi-agent dynamics.\n  We conclude that AI is neither a singular break nor merely incremental\nprogress. It is both evolutionary and revolutionary: predictable in its median\neffects yet carrying singularity-class tail risks. Good outcomes are not\nautomatic; they require coupling pro-innovation strategies with safety\ngovernance, ensuring equitable access, and embedding AI within a human order of\nresponsibility."}
{"id": "2510.13686", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13686", "abs": "https://arxiv.org/abs/2510.13686", "authors": ["Miana Smith", "Paul Arthur Richard", "Alexander Htet Kyaw", "Neil Gershenfeld"], "title": "Hierarchical Discrete Lattice Assembly: An Approach for the Digital Fabrication of Scalable Macroscale Structures", "comment": "In ACM Symposium on Computational Fabrication (SCF '25), November\n  20-21, 2025, Cambridge, MA, USA. ACM, New York, NY, USA, 15 pages", "summary": "Although digital fabrication processes at the desktop scale have become\nproficient and prolific, systems aimed at producing larger-scale structures are\nstill typically complex, expensive, and unreliable. In this work, we present an\napproach for the fabrication of scalable macroscale structures using simple\nrobots and interlocking lattice building blocks. A target structure is first\nvoxelized so that it can be populated with an architected lattice. These voxels\nare then grouped into larger interconnected blocks, which are produced using\nstandard digital fabrication processes, leveraging their capability to produce\nhighly complex geometries at a small scale. These blocks, on the size scale of\ntens of centimeters, are then fed to mobile relative robots that are able to\ntraverse over the structure and place new blocks to form structures on the\nmeter scale. To facilitate the assembly of large structures, we introduce a\nlive digital twin simulation tool for controlling and coordinating assembly\nrobots that enables both global planning for a target structure and live user\ndesign, interaction, or intervention. To improve assembly throughput, we\nintroduce a new modular assembly robot, designed for hierarchical voxel\nhandling. We validate this system by demonstrating the voxelization,\nhierarchical blocking, path planning, and robotic fabrication of a set of\nmeter-scale objects."}
{"id": "2510.13054", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13054", "abs": "https://arxiv.org/abs/2510.13054", "authors": ["Ankit Goyal", "Hugo Hadfield", "Xuning Yang", "Valts Blukis", "Fabio Ramos"], "title": "VLA-0: Building State-of-the-Art VLAs with Zero Modification", "comment": null, "summary": "Vision-Language-Action models (VLAs) hold immense promise for enabling\ngeneralist robot manipulation. However, the best way to build them remains an\nopen question. Current approaches often add complexity, such as modifying the\nexisting vocabulary of a Vision-Language Model (VLM) with action tokens or\nintroducing special action heads. Curiously, the simplest strategy of\nrepresenting actions directly as text has remained largely unexplored. This\nwork introduces VLA-0 to investigate this idea. We find that VLA-0 is not only\neffective; it is surprisingly powerful. With the right design, VLA-0\noutperforms more involved models. On LIBERO, a popular benchmark for evaluating\nVLAs, VLA-0 outperforms all existing methods trained on the same robotic data,\nincluding $\\pi_0.5$-KI, OpenVLA-OFT and SmolVLA. Furthermore, without\nlarge-scale robotics-specific training, it outperforms methods trained on\nlarge-scale robotic data, like $\\pi_0.5$-KI, $\\pi_0$, GR00T-N1 and MolmoAct.\nThese findings also translate to the real world, where VLA-0 outperforms\nSmolVLA, a VLA model pre-trained on large-scale real data. This paper\nsummarizes our unexpected findings and spells out the specific techniques\nrequired to unlock the high performance of this simple yet potent VLA design.\nVisual results, code, and trained models are provided here:\nhttps://vla0.github.io/."}
{"id": "2510.13778", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.13778", "abs": "https://arxiv.org/abs/2510.13778", "authors": ["Xinyi Chen", "Yilun Chen", "Yanwei Fu", "Ning Gao", "Jiaya Jia", "Weiyang Jin", "Hao Li", "Yao Mu", "Jiangmiao Pang", "Yu Qiao", "Yang Tian", "Bin Wang", "Bolun Wang", "Fangjing Wang", "Hanqing Wang", "Tai Wang", "Ziqin Wang", "Xueyuan Wei", "Chao Wu", "Shuai Yang", "Jinhui Ye", "Junqiu Yu", "Jia Zeng", "Jingjing Zhang", "Jinyu Zhang", "Shi Zhang", "Feng Zheng", "Bowen Zhou", "Yangkun Zhu"], "title": "InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy", "comment": "Technical report", "summary": "We introduce InternVLA-M1, a unified framework for spatial grounding and\nrobot control that advances instruction-following robots toward scalable,\ngeneral-purpose intelligence. Its core idea is spatially guided\nvision-language-action training, where spatial grounding serves as the critical\nlink between instructions and robot actions. InternVLA-M1 employs a two-stage\npipeline: (i) spatial grounding pre-training on over 2.3M spatial reasoning\ndata to determine ``where to act'' by aligning instructions with visual,\nembodiment-agnostic positions, and (ii) spatially guided action post-training\nto decide ``how to act'' by generating embodiment-aware actions through\nplug-and-play spatial prompting. This spatially guided training recipe yields\nconsistent gains: InternVLA-M1 outperforms its variant without spatial guidance\nby +14.6% on SimplerEnv Google Robot, +17% on WidowX, and +4.3% on LIBERO\nFranka, while demonstrating stronger spatial reasoning capability in box,\npoint, and trace prediction. To further scale instruction following, we built a\nsimulation engine to collect 244K generalizable pick-and-place episodes,\nenabling a 6.2% average improvement across 200 tasks and 3K+ objects. In\nreal-world clustered pick-and-place, InternVLA-M1 improved by 7.3%, and with\nsynthetic co-training, achieved +20.6% on unseen objects and novel\nconfigurations. Moreover, in long-horizon reasoning-intensive scenarios, it\nsurpassed existing works by over 10%. These results highlight spatially guided\ntraining as a unifying principle for scalable and resilient generalist robots.\nCode and models are available at\nhttps://github.com/InternRobotics/InternVLA-M1."}
{"id": "2510.13358", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13358", "abs": "https://arxiv.org/abs/2510.13358", "authors": ["Shingo Ayabe", "Hiroshi Kera", "Kazuhiko Kawamoto"], "title": "Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control", "comment": "16 pages, 8 figures", "summary": "Offline reinforcement learning enables sample-efficient policy acquisition\nwithout risky online interaction, yet policies trained on static datasets\nremain brittle under action-space perturbations such as actuator faults. This\nstudy introduces an offline-to-online framework that trains policies on clean\ndata and then performs adversarial fine-tuning, where perturbations are\ninjected into executed actions to induce compensatory behavior and improve\nresilience. A performance-aware curriculum further adjusts the perturbation\nprobability during training via an exponential-moving-average signal, balancing\nrobustness and stability throughout the learning process. Experiments on\ncontinuous-control locomotion tasks demonstrate that the proposed method\nconsistently improves robustness over offline-only baselines and converges\nfaster than training from scratch. Matching the fine-tuning and evaluation\nconditions yields the strongest robustness to action-space perturbations, while\nthe adaptive curriculum strategy mitigates the degradation of nominal\nperformance observed with the linear curriculum strategy. Overall, the results\nshow that adversarial fine-tuning enables adaptive and robust control under\nuncertain environments, bridging the gap between offline efficiency and online\nadaptability."}
{"id": "2510.13004", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13004", "abs": "https://arxiv.org/abs/2510.13004", "authors": ["Robert Muldrow", "Channing Ludden", "Christopher Petersen"], "title": "Comparison of Forced and Unforced Rendezvous, Proximity Operations, and Docking Under Model Mismatch", "comment": "12 pages, 4 figures, AAS/AIAA Space Flight Mechanics", "summary": "This paper compares the required fuel usage for forced and unforced motion of\na chaser satellite engaged in Rendezvous, Proximity Operations, and Docking\n(RPOD) maneuvers. Improved RPOD models are vital, particularly as the space\nindustry expands and demands for improved fuel efficiency, cost effectiveness,\nand mission life span increase. This paper specifically examines the Clohessy-\nWiltshire (CW) Equations and the extent of model mismatch by comparing pre-\ndicted trajectories from this model with a more computationally complex, higher\nfidelity RPOD model. This paper assesses several test cases of similar mission\nparameters, in each case comparing natural motion circumnavigation (NMC) with\ncomparable forced motion circumnavigation. The Guidance, Navigation, and Con-\ntrol (GNC) impulse maneuvers required to maintain the supposedly zero fuel CW\ntrajectories is representative of the extent of CW model mismatch. This paper\ndemonstrates that unforced motions are not inherently more fuel efficient than\nforced motions, thus permitting extended orbital operations given the higher\nfuel efficiency."}
{"id": "2510.13591", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13591", "abs": "https://arxiv.org/abs/2510.13591", "authors": ["Nicola Fabiano"], "title": "Subject Roles in the EU AI Act: Mapping and Regulatory Implications", "comment": null, "summary": "The European Union's Artificial Intelligence Act (Regulation (EU) 2024/1689)\nestablishes the world's first comprehensive regulatory framework for AI systems\nthrough a sophisticated ecosystem of interconnected subjects defined in Article\n3. This paper provides a structured examination of the six main categories of\nactors - providers, deployers, authorized representatives, importers,\ndistributors, and product manufacturers - collectively referred to as\n\"operators\" within the regulation. Through examination of these Article 3\ndefinitions and their elaboration across the regulation's 113 articles, 180\nrecitals, and 13 annexes, we map the complete governance structure and analyze\nhow the AI Act regulates these subjects. Our analysis reveals critical\ntransformation mechanisms whereby subjects can assume different roles under\nspecific conditions, particularly through Article 25 provisions ensuring\naccountability follows control. We identify how obligations cascade through the\nsupply chain via mandatory information flows and cooperation requirements,\ncreating a distributed yet coordinated governance system. The findings\ndemonstrate how the regulation balances innovation with the protection of\nfundamental rights through risk-based obligations that scale with the\ncapabilities and deployment contexts of AI systems, providing essential\nguidance for stakeholders implementing the AI Act's requirements."}
{"id": "2510.13114", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13114", "abs": "https://arxiv.org/abs/2510.13114", "authors": ["Zhuoyuan Wang", "Tongyao Jia", "Pharuj Rajborirug", "Neeraj Ramesh", "Hiroyuki Okuda", "Tatsuya Suzuki", "Soummya Kar", "Yorie Nakahira"], "title": "Safe Driving in Occluded Environments", "comment": null, "summary": "Ensuring safe autonomous driving in the presence of occlusions poses a\nsignificant challenge in its policy design. While existing model-driven control\ntechniques based on set invariance can handle visible risks, occlusions create\nlatent risks in which safety-critical states are not observable. Data-driven\ntechniques also struggle to handle latent risks because direct mappings from\nrisk-critical objects in sensor inputs to safe actions cannot be learned\nwithout visible risk-critical objects. Motivated by these challenges, in this\npaper, we propose a probabilistic safety certificate for latent risk. Our key\ntechnical enabler is the application of probabilistic invariance: It relaxes\nthe strict observability requirements imposed by set-invariance methods that\ndemand the knowledge of risk-critical states. The proposed techniques provide\nlinear action constraints that confine the latent risk probability within\ntolerance. Such constraints can be integrated into model predictive controllers\nor embedded in data-driven policies to mitigate latent risks. The proposed\nmethod is tested using the CARLA simulator and compared with a few existing\ntechniques. The theoretical and empirical analysis jointly demonstrate that the\nproposed methods assure long-term safety in real-time control in occluded\nenvironments without being overly conservative and with transparency to exposed\nrisks."}
{"id": "2510.13621", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13621", "abs": "https://arxiv.org/abs/2510.13621", "authors": ["Yuexing Hao", "Yue Huang", "Haoran Zhang", "Chenyang Zhao", "Zhenwen Liang", "Paul Pu Liang", "Yue Zhao", "Lichao Sun", "Saleh Kalantari", "Xiangliang Zhang", "Marzyeh Ghassemi"], "title": "The Role of Computing Resources in Publishing Foundation Model Research", "comment": null, "summary": "Cutting-edge research in Artificial Intelligence (AI) requires considerable\nresources, including Graphics Processing Units (GPUs), data, and human\nresources. In this paper, we evaluate of the relationship between these\nresources and the scientific advancement of foundation models (FM). We reviewed\n6517 FM papers published between 2022 to 2024, and surveyed 229 first-authors\nto the impact of computing resources on scientific output. We find that\nincreased computing is correlated with national funding allocations and\ncitations, but our findings don't observe the strong correlations with research\nenvironment (academic or industrial), domain, or study methodology. We advise\nthat individuals and institutions focus on creating shared and affordable\ncomputing opportunities to lower the entry barrier for under-resourced\nresearchers. These steps can help expand participation in FM research, foster\ndiversity of ideas and contributors, and sustain innovation and progress in AI.\nThe data will be available at: https://mit-calc.csail.mit.edu/"}
{"id": "2510.13461", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13461", "abs": "https://arxiv.org/abs/2510.13461", "authors": ["Yangye Jiang", "Jiachen Wang", "Daofei Li"], "title": "Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers", "comment": null, "summary": "Accurate prediction of vehicle collision dynamics is crucial for advanced\nsafety systems and post-impact control applications, yet existing methods face\ninherent trade-offs among computational efficiency, prediction accuracy, and\ndata requirements. This paper proposes a dual Physics-Informed Neural Network\nframework addressing these challenges through two complementary networks. The\nfirst network integrates Gaussian Mixture Models with PINN architecture to\nlearn impact force distributions from finite element analysis data while\nenforcing momentum conservation and energy consistency constraints. The second\nnetwork employs an adaptive PINN with dynamic constraint weighting to predict\npost-collision vehicle dynamics, featuring an adaptive physics guard layer that\nprevents unrealistic predictions whil e preserving data-driven learning\ncapabilities. The framework incorporates uncertainty quantification through\ntime-varying parameters and enables rapid adaptation via fine-tuning\nstrategies. Validation demonstrates significant improvements: the impact force\nmodel achieves relative errors below 15.0% for force prediction on finite\nelement analysis (FEA) datasets, while the vehicle dynamics model reduces\naverage trajectory prediction error by 63.6% compared to traditional\nfour-degree-of-freedom models in scaled vehicle experiments. The integrated\nsystem maintains millisecond-level computational efficiency suitable for\nreal-time applications while providing probabilistic confidence bounds\nessential for safety-critical control. Comprehensive validation through FEA\nsimulation, dynamic modeling, and scaled vehicle experiments confirms the\nframework's effectiveness for Precision Immobilization Technique scenarios and\ngeneral collision dynamics prediction."}
{"id": "2510.13778", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.13778", "abs": "https://arxiv.org/abs/2510.13778", "authors": ["Xinyi Chen", "Yilun Chen", "Yanwei Fu", "Ning Gao", "Jiaya Jia", "Weiyang Jin", "Hao Li", "Yao Mu", "Jiangmiao Pang", "Yu Qiao", "Yang Tian", "Bin Wang", "Bolun Wang", "Fangjing Wang", "Hanqing Wang", "Tai Wang", "Ziqin Wang", "Xueyuan Wei", "Chao Wu", "Shuai Yang", "Jinhui Ye", "Junqiu Yu", "Jia Zeng", "Jingjing Zhang", "Jinyu Zhang", "Shi Zhang", "Feng Zheng", "Bowen Zhou", "Yangkun Zhu"], "title": "InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy", "comment": "Technical report", "summary": "We introduce InternVLA-M1, a unified framework for spatial grounding and\nrobot control that advances instruction-following robots toward scalable,\ngeneral-purpose intelligence. Its core idea is spatially guided\nvision-language-action training, where spatial grounding serves as the critical\nlink between instructions and robot actions. InternVLA-M1 employs a two-stage\npipeline: (i) spatial grounding pre-training on over 2.3M spatial reasoning\ndata to determine ``where to act'' by aligning instructions with visual,\nembodiment-agnostic positions, and (ii) spatially guided action post-training\nto decide ``how to act'' by generating embodiment-aware actions through\nplug-and-play spatial prompting. This spatially guided training recipe yields\nconsistent gains: InternVLA-M1 outperforms its variant without spatial guidance\nby +14.6% on SimplerEnv Google Robot, +17% on WidowX, and +4.3% on LIBERO\nFranka, while demonstrating stronger spatial reasoning capability in box,\npoint, and trace prediction. To further scale instruction following, we built a\nsimulation engine to collect 244K generalizable pick-and-place episodes,\nenabling a 6.2% average improvement across 200 tasks and 3K+ objects. In\nreal-world clustered pick-and-place, InternVLA-M1 improved by 7.3%, and with\nsynthetic co-training, achieved +20.6% on unseen objects and novel\nconfigurations. Moreover, in long-horizon reasoning-intensive scenarios, it\nsurpassed existing works by over 10%. These results highlight spatially guided\ntraining as a unifying principle for scalable and resilient generalist robots.\nCode and models are available at\nhttps://github.com/InternRobotics/InternVLA-M1."}
{"id": "2510.12809", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12809", "abs": "https://arxiv.org/abs/2510.12809", "authors": ["Antonio Max"], "title": "High vs. Low AGI: Ontology and Conceptual Taxonomy for Geopolitical Coherence", "comment": "11 pages, 1 table", "summary": "The rapid progression of Artificial General Intelligence (AGI) research\ndemands conceptual tools capable of distinguishing between systems developed\nfor open, commercial integration and those destined for sovereign, securitized\ndeployments. Without such distinctions, risk assessments and regulatory debates\ncollapse AGI into legacy dual-use frameworks that are ill-suited for these\nresources, capturing the possibility of civilian and military application but\noverlooking the distinct societal lineages yielded by corporate and state-grade\narchitectures. This paper proposes a taxonomy distinguishing low-AGI and\nhigh-AGI, clarifying how commercial-economic and security-sovereign\narchitectures can be distinguished not only by function, but by the social and\npolitical ecosystems that produce them. The taxonomy builds on international\nrelations concepts of \"high/low politics,\" viewed through the lens of\nconstrual-level theory, which allows it to even capture how cooperation and\nconflict may coexist in the context of AGI's emerging geopolitical stakes. By\nembedding AGI within power structures and securitization theory, this\ncontribution extends dual-use discourse through an ontological taxonomy that\nenables more granular risk assessment and governance design--equipping\npolicymakers and researchers to anticipate security dilemmas, institutional\ndemands, and technical-political spillovers in the international system."}
{"id": "2510.12810", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12810", "abs": "https://arxiv.org/abs/2510.12810", "authors": ["Lucas Böttcher"], "title": "Control of dynamical systems with neural networks", "comment": "23 pages, 14 figures, 1 table", "summary": "Control problems frequently arise in scientific and industrial applications,\nwhere the objective is to steer a dynamical system from an initial state to a\ndesired target state. Recent advances in deep learning and automatic\ndifferentiation have made applying these methods to control problems\nincreasingly practical. In this paper, we examine the use of neural networks\nand modern machine-learning libraries to parameterize control inputs across\ndiscrete-time and continuous-time systems, as well as deterministic and\nstochastic dynamics. We highlight applications in multiple domains, including\nbiology, engineering, physics, and medicine. For continuous-time dynamical\nsystems, neural ordinary differential equations (neural ODEs) offer a useful\napproach to parameterizing control inputs. For discrete-time systems, we show\nhow custom control-input parameterizations can be implemented and optimized\nusing automatic-differentiation methods. Overall, the methods presented provide\npractical solutions for control tasks that are computationally demanding or\nanalytically intractable, making them valuable for complex real-world\napplications."}
{"id": "2510.12814", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12814", "abs": "https://arxiv.org/abs/2510.12814", "authors": ["Gargi Sarkar", "Sandeep Kumar Shukla"], "title": "Cyber Slavery Infrastructures: A Socio-Technical Study of Forced Criminality in Transnational Cybercrime", "comment": null, "summary": "The rise of ``cyber slavery,\" a technologically facilitated variant of forced\ncriminality, signifies a concerning convergence of human trafficking and\ndigital exploitation. In Southeast Asia, trafficked individuals are\nincreasingly coerced into engaging in cybercrimes, including online fraud and\nfinancial phishing, frequently facilitated by international organized criminal\nnetworks. This study adopts a hybrid qualitative-computational methodology,\ncombining a systematic narrative review with case-level metadata extracted from\nreal-world cyber trafficking incidents through collaboration with Indian law\nenforcement agencies. We introduce a five-tier victimization framework that\noutlines the sequential state transitions of cyber-slavery victims, ranging\nfrom initial financial deception to physical exploitation, culminating in\nsystemic prosecution through trace-based misattribution. Furthermore, our\nfindings indicate that a significant socio-technical risk of cyber slavery is\nits capacity to evolve from forced to voluntary digital criminality, as\nvictims, initially compelled to engage in cyber-enabled crimes, may choose to\npersist in their involvement due to financial incentives and the perceived\nsecurity provided by digital anonymity. This legal-technological gap hampers\nvictim identification processes, imposing excessive pressure on law enforcement\nsystems dependent on binary legal categorizations, which ultimately hinders the\nimplementation of victim-centered investigative methods and increases the\nlikelihood of prosecutorial misclassification, thus reinforcing the structural\nobstacles to addressing cyber slavery."}
{"id": "2510.12820", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12820", "abs": "https://arxiv.org/abs/2510.12820", "authors": ["Pedro Ramonetti", "Melissa Floca", "Kate O'Laughlin", "Amarnath Gupta", "Manish Parashar", "Ilkay Altintas"], "title": "National Data Platform's Education Hub", "comment": null, "summary": "As demand for AI literacy and data science education grows, there is a\ncritical need for infrastructure that bridges the gap between research data,\ncomputational resources, and educational experiences. To address this gap, we\ndeveloped a first-of-its-kind Education Hub within the National Data Platform.\nThis hub enables seamless connections between collaborative research\nworkspaces, classroom environments, and data challenge settings. Early use\ncases demonstrate the effectiveness of the platform in supporting complex and\nresource-intensive educational activities. Ongoing efforts aim to enhance the\nuser experience and expand adoption by educators and learners alike."}
{"id": "2510.12822", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12822", "abs": "https://arxiv.org/abs/2510.12822", "authors": ["Michele Loi", "Marcello Di Bello", "Nicolò Cangiotti"], "title": "Evidence Without Injustice: A New Counterfactual Test for Fair Algorithms", "comment": "13 pages", "summary": "The growing philosophical literature on algorithmic fairness has examined\nstatistical criteria such as equalized odds and calibration, causal and\ncounterfactual approaches, and the role of structural and compounding\ninjustices. Yet an important dimension has been overlooked: whether the\nevidential value of an algorithmic output itself depends on structural\ninjustice. Our paradigmatic pair of examples contrasts a predictive policing\nalgorithm, which relies on historical crime data, with a camera-based system\nthat records ongoing offenses, both designed to guide police deployment. In\nevaluating the moral acceptability of acting on a piece of evidence, we must\nask not only whether the evidence is probative in the actual world, but also\nwhether it would remain probative in nearby worlds without the relevant\ninjustices. The predictive policing algorithm fails this test, but the\ncamera-based system passes it. When evidence fails the test, it is morally\nproblematic to use it punitively, more so than evidence that passes the test."}
{"id": "2510.12830", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12830", "abs": "https://arxiv.org/abs/2510.12830", "authors": ["Alex Dantart"], "title": "Gobernanza y trazabilidad \"a prueba de AI Act\" para casos de uso legales: un marco técnico-jurídico, métricas forenses y evidencias auditables", "comment": "in Spanish language", "summary": "This paper presents a comprehensive governance framework for AI systems in\nthe legal sector, designed to ensure verifiable compliance with the EU AI Act.\nThe framework integrates a normative mapping of the regulation to technical\ncontrols, a forensic architecture for RAG/LLM systems, and an evaluation system\nwith metrics weighted by legal risk. As a primary contribution, we present\nrag-forense, an open-source implementation of the framework, accompanied by an\nexperimental protocol to demonstrate compliance. -- Este art\\'iculo presenta un\nmarco integral de gobernanza para sistemas de IA en el sector legal, dise\\~nado\npara garantizar el cumplimiento verificable del Reglamento de IA de la UE (AI\nAct). El marco integra una cartograf\\'ia normativa de la ley a controles\nt\\'ecnicos, una arquitectura forense para sistemas RAG/LLM y un sistema de\nevaluaci\\'on con m\\'etricas ponderadas por el riesgo jur\\'idico. Como principal\ncontribuci\\'on, se presenta rag-forense, una implementaci\\'on de c\\'odigo\nabierto del marco, acompa\\~nada de un protocolo experimental para demostrar la\nconformidad."}
{"id": "2510.12832", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12832", "abs": "https://arxiv.org/abs/2510.12832", "authors": ["Alistair Brash", "Junyi Lu", "Bruce Stephen", "Blair Brown", "Robert Atkinson", "Craig Michie", "Fraser MacIntyre", "Christos Tachtatzis"], "title": "Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation", "comment": null, "summary": "Limited visibility of power distribution network power flows at the low\nvoltage level presents challenges to both distribution network operators from a\nplanning perspective and distribution system operators from a congestion\nmanagement perspective. Forestalling these challenges through scenario analysis\nis confounded by the lack of realistic and coherent load data across\nrepresentative distribution feeders. Load profiling approaches often rely on\nsummarising demand through typical profiles, which oversimplifies the\ncomplexity of substation-level operations and limits their applicability in\nspecific power system studies. Sampling methods, and more recently generative\nmodels, have attempted to address this through synthesising representative\nloads from historical exemplars; however, while these approaches can\napproximate load shapes to a convincing degree of fidelity, the co-behaviour\nbetween substations, which ultimately impacts higher voltage level network\noperation, is often overlooked. This limitation will become even more\npronounced with the increasing integration of low-carbon technologies, as\nestimates of base loads fail to capture load diversity. To address this gap, a\nConditional Diffusion model for synthesising daily active and reactive power\nprofiles at the low voltage distribution substation level is proposed. The\nevaluation of fidelity is demonstrated through conventional metrics capturing\ntemporal and statistical realism, as well as power flow modelling. The results\nshow synthesised load profiles are plausible both independently and as a cohort\nin a wider power systems context. The Conditional Diffusion model is\nbenchmarked against both naive and state-of-the-art models to demonstrate its\neffectiveness in producing realistic scenarios on which to base sub-regional\npower distribution network planning and operations."}
{"id": "2510.12836", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12836", "abs": "https://arxiv.org/abs/2510.12836", "authors": ["Tabia Tanzin Prama", "Christopher M. Danforth", "Peter Sheridan Dodds"], "title": "BanglaMATH : A Bangla benchmark dataset for testing LLM mathematical reasoning at grades 6, 7, and 8", "comment": null, "summary": "Large Language Models (LLMs) have tremendous potential to play a key role in\nsupporting mathematical reasoning, with growing use in education and AI\nresearch. However, most existing benchmarks are limited to English, creating a\nsignificant gap for low-resource languages. For example, Bangla is spoken by\nnearly 250 million people who would collectively benefit from LLMs capable of\nnative fluency. To address this, we present BanglaMATH, a dataset of 1.7k\nBangla math word problems across topics such as Arithmetic, Algebra, Geometry,\nand Logical Reasoning, sourced from Bangla elementary school workbooks and\nannotated with details like grade level and number of reasoning steps. We have\ndesigned BanglaMATH to evaluate the mathematical capabilities of both\ncommercial and open-source LLMs in Bangla, and we find that Gemini 2.5 Flash\nand DeepSeek V3 are the only models to achieve strong performance, with $\\ge$\n80\\% accuracy across three elementary school grades. Furthermore, we assess the\nrobustness and language bias of these top-performing LLMs by augmenting the\noriginal problems with distracting information, and translating the problems\ninto English. We show that both LLMs fail to maintain robustness and exhibit\nsignificant performance bias in Bangla. Our study underlines current\nlimitations of LLMs in handling arithmetic and mathematical reasoning in\nlow-resource languages, and highlights the need for further research on\nmultilingual and equitable mathematical understanding. Dataset link:\n\\href{https://github.com/TabiaTanzin/BanglaMATH-A-Bangla-benchmark-dataset-for-testing-LLM-mathematical-reasoning-at-grades-6-7-and-8.git}{https://github.com/BanglaMATH}"}
{"id": "2510.12841", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12841", "abs": "https://arxiv.org/abs/2510.12841", "authors": ["A. K. M. Bahalul Haque", "Bharat Bhushan", "Gaurav Dhiman"], "title": "Conceptualizing Smart City Applications: Requirements, Architecture, Security Issues and Emerging Trends", "comment": "60 Pages, 5 Tables, 1 Figure", "summary": "The emergence of smart cities and sustainable development has become a\nglobally accepted form of urbanization. The epitome of smart city development\nhas become possible due to the latest innovative integration of information and\ncommunication technology. Citizens of smart cities can enjoy the benefits of a\nsmart living environment, ubiquitous connectivity, seamless access to services,\nintelligent decision making through smart governance, and optimized resource\nmanagement. The widespread acceptance of smart cities has raised data security\nissues, authentication, unauthorized access, device-level vulnerability, and\nsustainability. This paper focuses on the wholistic overview and conceptual\ndevelopment of smart city. Initially, the work discusses the smart city idea\nand fundamentals explored in various pieces of literature. Further various\nsmart city applications, including notable implementations, are put forth to\nunderstand the quality of living standards. Finally, the paper depicts a solid\nunderstanding of different security and privacy issues, including some crucial\nfuture research directions."}
{"id": "2510.12844", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12844", "abs": "https://arxiv.org/abs/2510.12844", "authors": ["Adam Bradley", "Bradford Saad"], "title": "AI Alignment vs. AI Ethical Treatment: 10 Challenges", "comment": "author order is arbitrary", "summary": "A morally acceptable course of AI development should avoid two dangers:\ncreating unaligned AI systems that pose a threat to humanity and mistreating AI\nsystems that merit moral consideration in their own right. This paper argues\nthese two dangers interact and that if we create AI systems that merit moral\nconsideration, simultaneously avoiding both of these dangers would be extremely\nchallenging. While our argument is straightforward and supported by a wide\nrange of pretheoretical moral judgments, it has far-reaching moral implications\nfor AI development. Although the most obvious way to avoid the tension between\nalignment and ethical treatment would be to avoid creating AI systems that\nmerit moral consideration, this option may be unrealistic and is perhaps\nfleeting. So, we conclude by offering some suggestions for other ways of\nmitigating mistreatment risks associated with alignment."}
{"id": "2510.12850", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12850", "abs": "https://arxiv.org/abs/2510.12850", "authors": ["Mahamodul Hasan Mahadi", "Md. Nasif Safwan", "Souhardo Rahman", "Shahnaj Parvin", "Aminun Nahar", "Kamruddin Nur"], "title": "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification", "comment": null, "summary": "Developing AI systems capable of nuanced ethical reasoning is critical as\nthey increasingly influence human decisions, yet existing models often rely on\nsuperficial correlations rather than principled moral understanding. This paper\nintroduces Ethic-BERT, a BERT-based model for ethical content classification\nacross four domains: Commonsense, Justice, Virtue, and Deontology. Leveraging\nthe ETHICS dataset, our approach integrates robust preprocessing to address\nvocabulary sparsity and contextual ambiguities, alongside advanced fine-tuning\nstrategies like full model unfreezing, gradient accumulation, and adaptive\nlearning rate scheduling. To evaluate robustness, we employ an adversarially\nfiltered \"Hard Test\" split, isolating complex ethical dilemmas. Experimental\nresults demonstrate Ethic-BERT's superiority over baseline models, achieving\n82.32% average accuracy on the standard test, with notable improvements in\nJustice and Virtue. In addition, the proposed Ethic-BERT attains 15.28% average\naccuracy improvement in the HardTest. These findings contribute to performance\nimprovement and reliable decision-making using bias-aware preprocessing and\nproposed enhanced AI model."}
{"id": "2510.12857", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12857", "abs": "https://arxiv.org/abs/2510.12857", "authors": ["Robin Staab", "Jasper Dekoninck", "Maximilian Baader", "Martin Vechev"], "title": "Adaptive Generation of Bias-Eliciting Questions for LLMs", "comment": null, "summary": "Large language models (LLMs) are now widely deployed in user-facing\napplications, reaching hundreds of millions worldwide. As they become\nintegrated into everyday tasks, growing reliance on their outputs raises\nsignificant concerns. In particular, users may unknowingly be exposed to\nmodel-inherent biases that systematically disadvantage or stereotype certain\ngroups. However, existing bias benchmarks continue to rely on templated prompts\nor restrictive multiple-choice questions that are suggestive, simplistic, and\nfail to capture the complexity of real-world user interactions. In this work,\nwe address this gap by introducing a counterfactual bias evaluation framework\nthat automatically generates realistic, open-ended questions over sensitive\nattributes such as sex, race, or religion. By iteratively mutating and\nselecting bias-inducing questions, our approach systematically explores areas\nwhere models are most susceptible to biased behavior. Beyond detecting harmful\nbiases, we also capture distinct response dimensions that are increasingly\nrelevant in user interactions, such as asymmetric refusals and explicit\nacknowledgment of bias. Leveraging our framework, we construct CAB, a\nhuman-verified benchmark spanning diverse topics, designed to enable\ncross-model comparisons. Using CAB, we analyze a range of LLMs across multiple\nbias dimensions, revealing nuanced insights into how different models manifest\nbias. For instance, while GPT-5 outperforms other models, it nonetheless\nexhibits persistent biases in specific scenarios. These findings underscore the\nneed for continual improvements to ensure fair model behavior."}
{"id": "2510.12859", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12859", "abs": "https://arxiv.org/abs/2510.12859", "authors": ["Masoud Makrehchi"], "title": "Three Lenses on the AI Revolution: Risk, Transformation, Continuity", "comment": "17 pages", "summary": "Artificial Intelligence (AI) has emerged as both a continuation of historical\ntechnological revolutions and a potential rupture with them. This paper argues\nthat AI must be viewed simultaneously through three lenses: \\textit{risk},\nwhere it resembles nuclear technology in its irreversible and global\nexternalities; \\textit{transformation}, where it parallels the Industrial\nRevolution as a general-purpose technology driving productivity and\nreorganization of labor; and \\textit{continuity}, where it extends the\nfifty-year arc of computing revolutions from personal computing to the internet\nto mobile. Drawing on historical analogies, we emphasize that no past\ntransition constituted a strict singularity: disruptive shifts eventually\nbecame governable through new norms and institutions.\n  We examine recurring patterns across revolutions -- democratization at the\nusage layer, concentration at the production layer, falling costs, and\ndeepening personalization -- and show how these dynamics are intensifying in\nthe AI era. Sectoral analysis illustrates how accounting, law, education,\ntranslation, advertising, and software engineering are being reshaped as\nroutine cognition is commoditized and human value shifts to judgment, trust,\nand ethical responsibility. At the frontier, the challenge of designing moral\nAI agents highlights the need for robust guardrails, mechanisms for moral\ngeneralization, and governance of emergent multi-agent dynamics.\n  We conclude that AI is neither a singular break nor merely incremental\nprogress. It is both evolutionary and revolutionary: predictable in its median\neffects yet carrying singularity-class tail risks. Good outcomes are not\nautomatic; they require coupling pro-innovation strategies with safety\ngovernance, ensuring equitable access, and embedding AI within a human order of\nresponsibility."}
{"id": "2510.12864", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12864", "abs": "https://arxiv.org/abs/2510.12864", "authors": ["Imran Khan"], "title": "From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models", "comment": "13 pages. Code and data are available at\n  https://github.com/strongSoda/LITERAL-TO-LIBERAL", "summary": "Large Language Models (LLMs) are increasingly being deployed as the reasoning\nengines for agentic AI systems, yet they exhibit a critical flaw: a rigid\nadherence to explicit rules that leads to decisions misaligned with human\ncommon sense and intent. This \"rule-rigidity\" is a significant barrier to\nbuilding trustworthy autonomous agents. While prior work has shown that\nsupervised fine-tuning (SFT) with human explanations can mitigate this issue,\nSFT is computationally expensive and inaccessible to many practitioners. To\naddress this gap, we introduce the Rule-Intent Distinction (RID) Framework, a\nnovel, low-compute meta-prompting technique designed to elicit human-aligned\nexception handling in LLMs in a zero-shot manner. The RID framework provides\nthe model with a structured cognitive schema for deconstructing tasks,\nclassifying rules, weighing conflicting outcomes, and justifying its final\ndecision. We evaluated the RID framework against baseline and Chain-of-Thought\n(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced\njudgment across diverse domains. Our human-verified results demonstrate that\nthe RID framework significantly improves performance, achieving a 95% Human\nAlignment Score (HAS), compared to 80% for the baseline and 75% for CoT.\nFurthermore, it consistently produces higher-quality, intent-driven reasoning.\nThis work presents a practical, accessible, and effective method for steering\nLLMs from literal instruction-following to liberal, goal-oriented reasoning,\npaving the way for more reliable and pragmatic AI agents."}
{"id": "2510.12866", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.12866", "abs": "https://arxiv.org/abs/2510.12866", "authors": ["Dantong Niu", "Yuvan Sharma", "Baifeng Shi", "Rachel Ding", "Matteo Gioia", "Haoru Xue", "Henry Tsai", "Konstantinos Kallidromitis", "Anirudh Pai", "Shankar Shastry", "Trevor Darrell", "Jitendra Malik", "Roei Herzig"], "title": "Learning to Grasp Anything by Playing with Random Toys", "comment": null, "summary": "Robotic manipulation policies often struggle to generalize to novel objects,\nlimiting their real-world utility. In contrast, cognitive science suggests that\nchildren develop generalizable dexterous manipulation skills by mastering a\nsmall set of simple toys and then applying that knowledge to more complex\nitems. Inspired by this, we study if similar generalization capabilities can\nalso be achieved by robots. Our results indicate robots can learn generalizable\ngrasping using randomly assembled objects that are composed from just four\nshape primitives: spheres, cuboids, cylinders, and rings. We show that training\non these \"toys\" enables robust generalization to real-world objects, yielding\nstrong zero-shot performance. Crucially, we find the key to this generalization\nis an object-centric visual representation induced by our proposed detection\npooling mechanism. Evaluated in both simulation and on physical robots, our\nmodel achieves a 67% real-world grasping success rate on the YCB dataset,\noutperforming state-of-the-art approaches that rely on substantially more\nin-domain data. We further study how zero-shot generalization performance\nscales by varying the number and diversity of training toys and the\ndemonstrations per toy. We believe this work offers a promising path to\nscalable and generalizable learning in robotic manipulation. Demonstration\nvideos, code, checkpoints and our dataset are available on our project page:\nhttps://lego-grasp.github.io/ ."}
{"id": "2510.12897", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12897", "abs": "https://arxiv.org/abs/2510.12897", "authors": ["Sanjay Johnson", "Dirk Lauinger", "Sungho Shin", "François Pacaud"], "title": "ExaModelsPower.jl: A GPU-Compatible Modeling Library for Nonlinear Power System Optimization", "comment": null, "summary": "As GPU-accelerated mathematical programming techniques mature, there is\ngrowing interest in utilizing them to address the computational challenges of\npower system optimization. This paper introduces ExaModelsPower.jl, an\nopen-source modeling library for creating GPU-compatible nonlinear AC optimal\npower flow models. Built on ExaModels.jl, ExaModelsPower.jl provides a\nhigh-level interface that automatically generates all necessary callback\nfunctions for GPU solvers. The library is designed for large-scale problem\ninstances, which may include multiple time periods and security constraints.\nUsing ExaModelsPower.jl, we benchmark GPU and CPU solvers on open-source test\ncases. Our results show that GPU solvers can deliver up to two orders of\nmagnitude speedups compared to alternative tools on CPU for problems with more\nthan 20,000 variables and a solution precision of up to $10^{-4}$, while\nperformance for smaller instances or tighter tolerances may vary."}
{"id": "2510.12914", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12914", "abs": "https://arxiv.org/abs/2510.12914", "authors": ["Zhi Liu", "Chengxi Liu", "Jiangbei Han", "Rui Qiu", "Mingyuan Liu"], "title": "A Wideband Composite Sequence Impedance Model for Evaluation of Interactions in Unbalanced Power-Electronic-Based Power Systems", "comment": "This work will be submitted to the IEEE for possible publication", "summary": "This paper proposes a wideband composite sequence impedance model\n(WCSIM)-based analysis method to evaluate the interactions in\npower-electronic-based power systems subjected to unbalanced grid faults or\nwith unbalanced loads. The WCSIM-based method intuitively assesses the impact\nof the small-signal interconnection among the positive-, negative-, and\nzero-sequence circuits on the interaction stability of unbalanced power\nsystems. The effectiveness of this method is demonstrated using a permanent\nmagnet synchronous generator-based weak grid system under a\nsingle-line-to-ground fault (SLGF). Frequency scanning results and controller\nhardware-in-loop tests validate both the correctness of the WCSIM and the\neffectiveness of the WCSIM-based analysis method."}
{"id": "2510.12915", "categories": ["cs.CY", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12915", "abs": "https://arxiv.org/abs/2510.12915", "authors": ["Marisa C. Peczuh", "Nischal Ashok Kumar", "Ryan Baker", "Blair Lehman", "Danielle Eisenberg", "Caitlin Mills", "Keerthi Chebrolu", "Sudhip Nashi", "Cadence Young", "Brayden Liu", "Sherry Lachman", "Andrew Lan"], "title": "Toward LLM-Supported Automated Assessment of Critical Thinking Subskills", "comment": "preprint: 17 pages", "summary": "Critical thinking represents a fundamental competency in today's education\nlandscape. Developing critical thinking skills through timely assessment and\nfeedback is crucial; however, there has not been extensive work in the learning\nanalytics community on defining, measuring, and supporting critical thinking.\nIn this paper, we investigate the feasibility of measuring core \"subskills\"\nthat underlie critical thinking. We ground our work in an authentic task where\nstudents operationalize critical thinking: student-written argumentative\nessays. We developed a coding rubric based on an established skills progression\nand completed human coding for a corpus of student essays. We then evaluated\nthree distinct approaches to automated scoring: zero-shot prompting, few-shot\nprompting, and supervised fine-tuning, implemented across three large language\nmodels (GPT-5, GPT-5-mini, and ModernBERT). GPT-5 with few-shot prompting\nachieved the strongest results and demonstrated particular strength on\nsubskills with separable, frequent categories, while lower performance was\nobserved for subskills that required detection of subtle distinctions or rare\ncategories. Our results underscore critical trade-offs in automated critical\nthinking assessment: proprietary models offer superior reliability at higher\ncost, while open-source alternatives provide practical accuracy with reduced\nsensitivity to minority categories. Our work represents an initial step toward\nscalable assessment of higher-order reasoning skills across authentic\neducational contexts."}
{"id": "2510.12919", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12919", "abs": "https://arxiv.org/abs/2510.12919", "authors": ["Mouhyemen Khan", "Tatsuya Ibuki", "Abhijit Chatterjee"], "title": "Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation", "comment": "8 pages, 7 figures, under review", "summary": "Level set methods underpin modern safety techniques such as control barrier\nfunctions (CBFs), while also serving as implicit surface representations for\ngeometric shapes via distance fields. Inspired by these two paradigms, we\npropose a unified framework where the implicit surface itself acts as a CBF. We\nleverage Gaussian process (GP) implicit surface (GPIS) to represent the safety\nboundaries, using safety samples which are derived from sensor measurements to\ncondition the GP. The GP posterior mean defines the implicit safety surface\n(safety belief), while the posterior variance provides a robust safety margin.\nAlthough GPs have favorable properties such as uncertainty estimation and\nanalytical tractability, they scale cubically with data. To alleviate this\nissue, we develop a sparse solution called sparse Gaussian CBFs. To the best of\nour knowledge, GPIS have not been explicitly used to synthesize CBFs. We\nvalidate the approach on collision avoidance tasks in two settings: a simulated\n7-DOF manipulator operating around the Stanford bunny, and a quadrotor\nnavigating in 3D around a physical chair. In both cases, Gaussian CBFs (with\nand without sparsity) enable safe interaction and collision-free execution of\ntrajectories that would otherwise intersect the objects."}
{"id": "2510.12924", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.12924", "abs": "https://arxiv.org/abs/2510.12924", "authors": ["Pavel Pochobradský", "Ondřej Procházka", "Robert Pěnička", "Vojtěch Vonásek", "Martin Saska"], "title": "Geometric Model Predictive Path Integral for Agile UAV Control with Online Collision Avoidance", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "In this letter, we introduce Geometric Model Predictive Path Integral\n(GMPPI), a sampling-based controller capable of tracking agile trajectories\nwhile avoiding obstacles. In each iteration, GMPPI generates a large number of\ncandidate rollout trajectories and then averages them to create a nominal\ncontrol to be followed by the Unmanned Aerial Vehicle (UAV). We propose using\ngeometric SE(3) control to generate part of the rollout trajectories,\nsignificantly increasing precision in agile flight. Furthermore, we introduce\nvarying rollout simulation time step length and dynamic cost and noise\nparameters, vastly improving tracking performance of smooth and low-speed\ntrajectories over an existing Model Predictive Path Integral (MPPI)\nimplementation. Finally, we propose an integration of GMPPI with a stereo depth\ncamera, enabling online obstacle avoidance at high speeds, a crucial step\ntowards autonomous UAV flights in complex environments. The proposed controller\ncan track simulated agile reference trajectories with position error similar to\nthe geometric SE(3) controller. However, the same configuration of the proposed\ncontroller can avoid obstacles in a simulated forest environment at speeds of\nup to 13m/s, surpassing the performance of a state-of-the-art obstacle-aware\nplanner. In real-world experiments, GMPPI retains the capability to track agile\ntrajectories and avoids obstacles at speeds of up to 10m/s."}
{"id": "2510.12946", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12946", "abs": "https://arxiv.org/abs/2510.12946", "authors": ["Daniel C. Qi", "Kenshiro Oguri", "Puneet Singla", "Maruthi R. Akella"], "title": "Non-Gaussian Distribution Steering in Nonlinear Dynamics with Conjugate Unscented Transformation", "comment": null, "summary": "In highly nonlinear systems such as the ones commonly found in astrodynamics,\nGaussian distributions generally evolve into non-Gaussian distributions. This\npaper introduces a method for effectively controlling non-Gaussian\ndistributions in nonlinear environments using optimized linear feedback\ncontrol. This paper utilizes Conjugate Unscented Transformation to quantify the\nhigher-order statistical moments of non-Gaussian distributions. The formulation\nfocuses on controlling and constraining the sigma points associated with the\nuncertainty quantification, which would thereby reflect the control of the\nentire distribution and constraints on the moments themselves. This paper\ndevelops an algorithm to solve this problem with sequential convex programming,\nand it is demonstrated through a two-body and three-body example. The examples\nshow that individual moments can be directly controlled, and the moments are\naccurately approximated for non-Gaussian distributions throughout the\ncontroller's time horizon in nonlinear dynamics."}
{"id": "2510.12949", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12949", "abs": "https://arxiv.org/abs/2510.12949", "authors": ["Zhiyuan Fan", "Elizabeth Dentzer", "James Glynn", "David S. Goldberg", "Julio Friedmann", "Bolun Xu"], "title": "Enhancing Profit and CO2 Mitigation: Commercial Direct Air Capture Design and Operation with Power Market Volatility", "comment": "16 pages, 8 figure, Submitted and under review for Engineering", "summary": "Current decarbonization efforts are falling short of meeting the net-zero\ngreenhouse gas (GHG) emission target, highlighting the need for substantial\ncarbon dioxide removal methods such as direct air capture (DAC). However,\nintegrating DACs poses challenges due to their enormous power consumption. This\nstudy assesses the commercial operation of various DAC technologies that earn\nrevenue using monetized carbon incentives while purchasing electricity from\nwholesale power markets. We model four commercial DAC technologies and examine\ntheir operation in three representative locations including California, Texas,\nand New York. Our findings reveal that commercial DAC operations can take\nfinancial advantage of the volatile power market to operate only during\nlow-price periods strategically, offering a pathway to facilitate a\ncost-efficient decarbonization transition. The ambient operational environment\nsuch as temperature and relative humidity has non-trivial impact on abatement\ncapacity. Profit-driven decisions introduce climate-economic trade-offs that\nmight decrease the capacity factor of DAC and reduce total CO2 removal. These\nimplications extend throughout the entire lifecycle of DAC developments and\ninfluence power systems and policies related to full-scale DAC implementation.\nOur study shows that DAC technologies with shorter cycle spans and higher\nflexibility can better exploit the electricity price volatility, while power\nmarkets demonstrate persistent low-price windows that often synergize with low\ngrid emission periods, like during the solar \"duck curve\" in California. An\noptimal incentive design exists for profit-driven operations while carbon-tax\npolicy in electricity pricing is counterproductive for DAC systems."}
{"id": "2510.12955", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12955", "abs": "https://arxiv.org/abs/2510.12955", "authors": ["Levi D. Reyes Premer", "Elias N. Pergantis", "Leo Semmelmann", "Davide Ziviani", "Kevin J. Kircher"], "title": "Model predictive control lowers barriers to adoption of heat-pump water heaters: A field study", "comment": null, "summary": "Electric heat-pump water heaters (HPWHs) could reduce the energy costs,\nemissions, and power grid impacts associated with water heating, the\nsecond-largest energy use in United States housing. However, most HPWHs today\nrequire 240 V circuits to power the backup resistance heating elements they use\nto maintain comfort during large water draws. Installing a 240 V circuit can\nincrease the up-front cost of a HPWH by half or more. This paper develops and\nfield-tests the first control system that enables a 120 V HPWH to efficiently\nmaintain comfort without resistance heating elements. The novel model\npredictive control (MPC) system enables pre-heating in anticipation of large\nwater draws, which it forecasts using an ensemble of machine learning\npredictors. By shifting electrical load over time, MPC also reduces energy\ncosts on average by 23% and 28% under time-of-use pricing and hourly pricing,\nrespectively, relative to a 240 V HPWH with standard controls. Compared to the\nincreasingly common practice in 120 V HPWHs of storing water at a constant,\nhigh temperature (60 {\\deg}C) to ensure comfort, MPC saves 37% energy on\naverage. In addition to demonstrating MPC's benefits in a real, occupied house,\nthis paper discusses implementation challenges and costs. A simple payback\nanalysis suggests that a 120 V HPWH, operated by the MPC system developed here,\nwould be economically attractive in most installation scenarios."}
{"id": "2510.12961", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12961", "abs": "https://arxiv.org/abs/2510.12961", "authors": ["The Minh Nguyen", "Nagisa Sugishita", "Margarida Carvalho", "Amira Dems"], "title": "Competitive EV charging station location with queues", "comment": null, "summary": "Electric vehicle (EV) public charging infrastructure planning faces\nsignificant challenges in competitive markets, where multiple service providers\naffect congestion and user behavior. This work extends existing modeling\nframeworks by incorporating the presence of competitors' stations and more\nrealistic queueing systems.\n  First, we analyze three finite queueing systems, M/M/1/K, M/M/s/K, and\nM/Er/s/K, with varying numbers of servers (charging outlets) and service time\ndistributions, deriving analytic expressions for user behavior metrics. Second,\nwe embed the queueing-based user behavior model into a bilevel program, where\nthe upper level locates new charging stations to maximize accessibility\n(throughput), and the lower level captures users' station choices via a user\nequilibrium. Third, we apply a reformulation from competitive congested\nuser-choice facility location models to approximately solve the bilevel problem\nand introduce a surrogate-based heuristic to enhance scalability. Fourth, we\nshowcase our methodology on a real-world case study of an urban area in\nMontreal (Canada), offering managerial insights into how user-choice behavior\nassumptions and competition affect throughput and location decisions. The\nresults demonstrate that our model yields (re)location strategies that\noutperform the existing network. More broadly, this approach provides a tool\nfor incorporating charging service quality-through queueing metrics-and\nexisting competition into station planning."}
{"id": "2510.12962", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.12962", "abs": "https://arxiv.org/abs/2510.12962", "authors": ["Michal Minařík", "Vojtěch Vonásek", "Robert Pěnička"], "title": "Enhancing Sampling-based Planning with a Library of Paths", "comment": null, "summary": "Path planning for 3D solid objects is a challenging problem, requiring a\nsearch in a six-dimensional configuration space, which is, nevertheless,\nessential in many robotic applications such as bin-picking and assembly. The\ncommonly used sampling-based planners, such as Rapidly-exploring Random Trees,\nstruggle with narrow passages where the sampling probability is low, increasing\nthe time needed to find a solution. In scenarios like robotic bin-picking,\nvarious objects must be transported through the same environment. However,\ntraditional planners start from scratch each time, losing valuable information\ngained during the planning process. We address this by using a library of past\nsolutions, allowing the reuse of previous experiences even when planning for a\nnew, previously unseen object. Paths for a set of objects are stored, and when\nplanning for a new object, we find the most similar one in the library and use\nits paths as approximate solutions, adjusting for possible mutual\ntransformations. The configuration space is then sampled along the approximate\npaths. Our method is tested in various narrow passage scenarios and compared\nwith state-of-the-art methods from the OMPL library. Results show significant\nspeed improvements (up to 85% decrease in the required time) of our method,\noften finding a solution in cases where the other planners fail. Our\nimplementation of the proposed method is released as an open-source package."}
{"id": "2510.12970", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.12970", "abs": "https://arxiv.org/abs/2510.12970", "authors": ["Baxi Chong", "Tianyu Wang", "Kelimar Diaz", "Christopher J. Pierce", "Eva Erickson", "Julian Whitman", "Yuelin Deng", "Esteban Flores", "Ruijie Fu", "Juntao He", "Jianfeng Lin", "Hang Lu", "Guillaume Sartoretti", "Howie Choset", "Daniel I. Goldman"], "title": "The Omega Turn: A General Turning Template for Elongate Robots", "comment": null, "summary": "Elongate limbless robots have the potential to locomote through tightly\npacked spaces for applications such as search-and-rescue and industrial\ninspections. The capability to effectively and robustly maneuver elongate\nlimbless robots is crucial to realize such potential. However, there has been\nlimited research on turning strategies for such systems. To achieve effective\nand robust turning performance in cluttered spaces, we take inspiration from a\nmicroscopic nematode, C. elegans, which exhibits remarkable maneuverability in\nrheologically complex environments partially because of its ability to perform\nomega turns. Despite recent efforts to analyze omega turn kinematics, it\nremains unknown if there exists a wave equation sufficient to prescribe an\nomega turn, let alone its reconstruction on robot platforms. Here, using a\ncomparative theory-biology approach, we prescribe the omega turn as a\nsuperposition of two traveling waves. With wave equations as a guideline, we\ndesign a controller for limbless robots enabling robust and effective turning\nbehaviors in lab and cluttered field environments. Finally, we show that such\nomega turn controllers can also generalize to elongate multi-legged robots,\ndemonstrating an alternative effective body-driven turning strategy for\nelongate robots, with and without limbs."}
{"id": "2510.12971", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.12971", "abs": "https://arxiv.org/abs/2510.12971", "authors": ["Anran Zhang", "Hanzhi Chen", "Yannick Burkhardt", "Yao Zhong", "Johannes Betz", "Helen Oleynikova", "Stefan Leutenegger"], "title": "Actron3D: Learning Actionable Neural Functions from Videos for Transferable Robotic Manipulation", "comment": "8 pages, 5 figures", "summary": "We present Actron3D, a framework that enables robots to acquire transferable\n6-DoF manipulation skills from just a few monocular, uncalibrated, RGB-only\nhuman videos. At its core lies the Neural Affordance Function, a compact\nobject-centric representation that distills actionable cues from diverse\nuncalibrated videos-geometry, visual appearance, and affordance-into a\nlightweight neural network, forming a memory bank of manipulation skills.\nDuring deployment, we adopt a pipeline that retrieves relevant affordance\nfunctions and transfers precise 6-DoF manipulation policies via coarse-to-fine\noptimization, enabled by continuous queries to the multimodal features encoded\nin the neural functions. Experiments in both simulation and the real world\ndemonstrate that Actron3D significantly outperforms prior methods, achieving a\n14.9 percentage point improvement in average success rate across 13 tasks while\nrequiring only 2-3 demonstration videos per task."}
{"id": "2510.12979", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.12979", "abs": "https://arxiv.org/abs/2510.12979", "authors": ["Wei Fan", "Wenlin Yao", "Zheng Li", "Feng Yao", "Xin Liu", "Liang Qiu", "Qingyu Yin", "Yangqiu Song", "Bing Yin"], "title": "DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping", "comment": "Under Review", "summary": "Large language models (LLMs) augmented with multi-step reasoning and action\ngeneration abilities have shown promise in leveraging external tools to tackle\ncomplex tasks that require long-horizon planning. However, existing approaches\neither rely on implicit planning in the reasoning stage or introduce explicit\nplanners without systematically addressing how to optimize the planning stage.\nAs evidence, we observe that under vanilla reinforcement learning (RL),\nplanning tokens exhibit significantly higher entropy than other action tokens,\nrevealing uncertain decision points that remain under-optimized. To address\nthis, we propose DeepPlanner, an end-to-end RL framework that effectively\nenhances the planning capabilities of deep research agents. Our approach shapes\ntoken-level advantage with an entropy-based term to allocate larger updates to\nhigh entropy tokens, and selectively upweights sample-level advantages for\nplanning-intensive rollouts. Extensive experiments across seven deep research\nbenchmarks demonstrate that DeepPlanner improves planning quality and achieves\nstate-of-the-art results under a substantially lower training budget."}
{"id": "2510.12985", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12985", "abs": "https://arxiv.org/abs/2510.12985", "authors": ["Simon Sinong Zhan", "Yao Liu", "Philip Wang", "Zinan Wang", "Qineng Wang", "Zhian Ruan", "Xiangyu Shi", "Xinyu Cao", "Frank Yang", "Kangrui Wang", "Huajie Shao", "Manling Li", "Qi Zhu"], "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents", "comment": null, "summary": "We present Sentinel, the first framework for formally evaluating the physical\nsafety of Large Language Model(LLM-based) embodied agents across the semantic,\nplan, and trajectory levels. Unlike prior methods that rely on heuristic rules\nor subjective LLM judgments, Sentinel grounds practical safety requirements in\nformal temporal logic (TL) semantics that can precisely specify state\ninvariants, temporal dependencies, and timing constraints. It then employs a\nmulti-level verification pipeline where (i) at the semantic level, intuitive\nnatural language safety requirements are formalized into TL formulas and the\nLLM agent's understanding of these requirements is probed for alignment with\nthe TL formulas; (ii) at the plan level, high-level action plans and subgoals\ngenerated by the LLM agent are verified against the TL formulas to detect\nunsafe plans before execution; and (iii) at the trajectory level, multiple\nexecution trajectories are merged into a computation tree and efficiently\nverified against physically-detailed TL specifications for a final safety\ncheck. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate\nmultiple LLM-based embodied agents against diverse safety requirements. Our\nexperiments show that by grounding physical safety in temporal logic and\napplying verification methods across multiple levels, Sentinel provides a\nrigorous foundation for systematically evaluating LLM-based embodied agents in\nphysical environments, exposing safety violations overlooked by previous\nmethods and offering insights into their failure modes."}
{"id": "2510.12992", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.12992", "abs": "https://arxiv.org/abs/2510.12992", "authors": ["Neel P. Bhatt", "Po-han Li", "Kushagra Gupta", "Rohan Siva", "Daniel Milan", "Alexander T. Hogue", "Sandeep P. Chinchali", "David Fridovich-Keil", "Zhangyang Wang", "Ufuk Topcu"], "title": "UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles", "comment": null, "summary": "Safe large-scale coordination of multiple cooperative connected autonomous\nvehicles (CAVs) hinges on communication that is both efficient and\ninterpretable. Existing approaches either rely on transmitting high-bandwidth\nraw sensor data streams or neglect perception and planning uncertainties\ninherent in shared data, resulting in systems that are neither scalable nor\nsafe. To address these limitations, we propose Uncertainty-Guided Natural\nLanguage Cooperative Autonomous Planning (UNCAP), a vision-language model-based\nplanning approach that enables CAVs to communicate via lightweight natural\nlanguage messages while explicitly accounting for perception uncertainty in\ndecision-making. UNCAP features a two-stage communication protocol: (i) an ego\nCAV first identifies the subset of vehicles most relevant for information\nexchange, and (ii) the selected CAVs then transmit messages that quantitatively\nexpress their perception uncertainty. By selectively fusing messages that\nmaximize mutual information, this strategy allows the ego vehicle to integrate\nonly the most relevant signals into its decision-making, improving both the\nscalability and reliability of cooperative planning. Experiments across diverse\ndriving scenarios show a 63% reduction in communication bandwidth with a 31%\nincrease in driving safety score, a 61% reduction in decision uncertainty, and\na four-fold increase in collision distance margin during near-miss events.\nProject website: https://uncap-project.github.io/"}
{"id": "2510.13000", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13000", "abs": "https://arxiv.org/abs/2510.13000", "authors": ["Giacomo Bastianel", "Dirk Van Hertem", "Hakan Ergun", "Line Roald"], "title": "Identifying Best Candidates for Busbar Splitting", "comment": null, "summary": "Rising electricity demand and the growing integration of renewables are\nintensifying congestion in transmission grids. Grid topology optimization\nthrough busbar splitting (BuS) and optimal transmission switching can alleviate\ngrid congestion and reduce the generation costs in a power system. However, BuS\noptimization requires a large number of binary variables, and analyzing all the\nsubstations for potential new topological actions is computationally\nintractable, particularly in large grids. To tackle this issue, we propose a\nset of metrics to identify and rank promising candidates for BuS, focusing on\nfinding buses where topology optimization can reduce generation costs. To\nassess the effect of BuS on the identified buses, we use a combined\nmixed-integer convex-quadratic BuS model to compute the optimal topology and\ntest it with the non-linear non-convex AC optimal power flow (OPF) simulation\nto show its AC feasibility. By testing and validating the proposed metrics on\ntest cases of different sizes, we show that they are able to identify busbars\nthat reduce the total generation costs when their topology is optimized. Thus,\nthe metrics enable effective selection of busbars for BuS, with no need to test\nevery busbar in the grid, one at a time."}
{"id": "2510.13002", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13002", "abs": "https://arxiv.org/abs/2510.13002", "authors": ["Boyou Chen", "Gerui Xu", "Zifei Wang", "Huizhong Guo", "Ananna Ahmed", "Zhaonan Sun", "Zhen Hu", "Kaihan Zhang", "Shan Bao"], "title": "From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model", "comment": null, "summary": "Vehicle crashes involve complex interactions between road users, split-second\ndecisions, and challenging environmental conditions. Among these, two-vehicle\ncrashes are the most prevalent, accounting for approximately 70% of roadway\ncrashes and posing a significant challenge to traffic safety. Identifying\nDriver Hazardous Action (DHA) is essential for understanding crash causation,\nyet the reliability of DHA data in large-scale databases is limited by\ninconsistent and labor-intensive manual coding practices. Here, we present an\ninnovative framework that leverages a fine-tuned large language model to\nautomatically infer DHAs from textual crash narratives, thereby improving the\nvalidity and interpretability of DHA classifications. Using five years of\ntwo-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on\ndetailed crash narratives and benchmarked its performance against conventional\nmachine learning classifiers, including Random Forest, XGBoost, CatBoost, and a\nneural network. The fine-tuned LLM achieved an overall accuracy of 80%,\nsurpassing all baseline models and demonstrating pronounced improvements in\nscenarios with imbalanced data. To increase interpretability, we developed a\nprobabilistic reasoning approach, analyzing model output shifts across original\ntest sets and three targeted counterfactual scenarios: variations in driver\ndistraction and age. Our analysis revealed that introducing distraction for one\ndriver substantially increased the likelihood of \"General Unsafe Driving\";\ndistraction for both drivers maximized the probability of \"Both Drivers Took\nHazardous Actions\"; and assigning a teen driver markedly elevated the\nprobability of \"Speed and Stopping Violations.\" Our framework and analytical\nmethods provide a robust and interpretable solution for large-scale automated\nDHA detection, offering new opportunities for traffic safety analysis and\nintervention."}
{"id": "2510.13004", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13004", "abs": "https://arxiv.org/abs/2510.13004", "authors": ["Robert Muldrow", "Channing Ludden", "Christopher Petersen"], "title": "Comparison of Forced and Unforced Rendezvous, Proximity Operations, and Docking Under Model Mismatch", "comment": "12 pages, 4 figures, AAS/AIAA Space Flight Mechanics", "summary": "This paper compares the required fuel usage for forced and unforced motion of\na chaser satellite engaged in Rendezvous, Proximity Operations, and Docking\n(RPOD) maneuvers. Improved RPOD models are vital, particularly as the space\nindustry expands and demands for improved fuel efficiency, cost effectiveness,\nand mission life span increase. This paper specifically examines the Clohessy-\nWiltshire (CW) Equations and the extent of model mismatch by comparing pre-\ndicted trajectories from this model with a more computationally complex, higher\nfidelity RPOD model. This paper assesses several test cases of similar mission\nparameters, in each case comparing natural motion circumnavigation (NMC) with\ncomparable forced motion circumnavigation. The Guidance, Navigation, and Con-\ntrol (GNC) impulse maneuvers required to maintain the supposedly zero fuel CW\ntrajectories is representative of the extent of CW model mismatch. This paper\ndemonstrates that unforced motions are not inherently more fuel efficient than\nforced motions, thus permitting extended orbital operations given the higher\nfuel efficiency."}
{"id": "2510.13005", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13005", "abs": "https://arxiv.org/abs/2510.13005", "authors": ["Robert Muldrow", "Channing Ludden", "Christopher Petersen"], "title": "Development of a Linear Guide-Rail Testbed for Physically Emulating ISAM Operations", "comment": "12 pages, 4 figures, AAS/AIAA Space Flight Mechanics", "summary": "In-Space Servicing, Assembly, and Manufacturing (ISAM) is a set of emerging\noperations that provides several benefits to improve the longevity, capacity,\nmo- bility, and expandability of existing and future space assets. Serial\nrobotic ma- nipulators are particularly vital in accomplishing ISAM operations,\nhowever, the complex perturbation forces and motions associated with movement\nof a robotic arm on a free-flying satellite presents a complex controls problem\nrequiring addi- tional study. While many dynamical models are developed,\nexperimentally test- ing and validating these models is challenging given that\nthe models operate in space, where satellites have six-degrees-of-freedom\n(6-DOF). This paper attempts to resolve those challenges by presenting the\ndesign and development of a new hardware-in-the-loop (HIL) experimental testbed\nutilized to emulate ISAM. This emulation will be accomplished by means of a\n6-DOF UR3e robotic arm attached to a satellite bus. This satellite bus is\nmounted to a 1-DOF guide-rail system, en- abling the satellite bus and robotic\narm to move freely in one linear direction. This experimental ISAM emulation\nsystem will explore and validate models for space motion, serial robot\nmanipulation, and contact mechanics."}
{"id": "2510.13024", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13024", "abs": "https://arxiv.org/abs/2510.13024", "authors": ["Shahab Ataei", "Dipankar Maity", "Debdipta Goswami"], "title": "Data to Certificate: Guaranteed Cost Control with Quantization-Aware System Identification", "comment": "8 pages, 3 figures", "summary": "Cloud-assisted system identification and control have emerged as practical\nsolutions for low-power, resource-constrained control systems such as\nmicro-UAVs. In a typical cloud-assisted setting, state and input data are\ntransmitted from local agents to a central computer over low-bandwidth wireless\nlinks, leading to quantization. This paper investigates the impact of state and\ninput data quantization on a linear time invariant (LTI) system identification,\nderives a worst-case bound on the identification error, and develops a robust\ncontroller for guaranteed cost control. We establish a fundamental bound on the\nmodel error that depends only on the quantized data and quantization\nresolution, and develop a linear matrix inequality (LMI) based guaranteed cost\nrobust controller under this error bound."}
{"id": "2510.13029", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13029", "abs": "https://arxiv.org/abs/2510.13029", "authors": ["Xinlei Wang", "Mingtian Tan", "Jing Qiu", "Junhua Zhao", "Jinjin Gu"], "title": "Toward Reasoning-Centric Time-Series Analysis", "comment": null, "summary": "Traditional time series analysis has long relied on pattern recognition,\ntrained on static and well-established benchmarks. However, in real-world\nsettings -- where policies shift, human behavior adapts, and unexpected events\nunfold -- effective analysis must go beyond surface-level trends to uncover the\nactual forces driving them. The recent rise of Large Language Models (LLMs)\npresents new opportunities for rethinking time series analysis by integrating\nmultimodal inputs. However, as the use of LLMs becomes popular, we must remain\ncautious, asking why we use LLMs and how to exploit them effectively. Most\nexisting LLM-based methods still employ their numerical regression ability and\nignore their deeper reasoning potential. This paper argues for rethinking time\nseries with LLMs as a reasoning task that prioritizes causal structure and\nexplainability. This shift brings time series analysis closer to human-aligned\nunderstanding, enabling transparent and context-aware insights in complex\nreal-world environments."}
{"id": "2510.13036", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13036", "abs": "https://arxiv.org/abs/2510.13036", "authors": ["Stephane Hatgis-Kessell", "Logan Mondal Bhamidipaty", "Emma Brunskill"], "title": "Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking", "comment": null, "summary": "Human-designed reward functions for reinforcement learning (RL) agents are\nfrequently misaligned with the humans' true, unobservable objectives, and thus\nact only as proxies. Optimizing for a misspecified proxy reward function often\ninduces reward hacking, resulting in a policy misaligned with the human's true\nobjectives. An alternative is to perform RL from human feedback, which involves\nlearning a reward function from scratch by collecting human preferences over\npairs of trajectories. However, building such datasets is costly. To address\nthe limitations of both approaches, we propose Preference-Based Reward Repair\n(PBRR): an automated iterative framework that repairs a human-specified proxy\nreward function by learning an additive, transition-dependent correction term\nfrom preferences. A manually specified reward function can yield policies that\nare highly suboptimal under the ground-truth objective, yet corrections on only\na few transitions may suffice to recover optimal performance. To identify and\ncorrect for those transitions, PBRR uses a targeted exploration strategy and a\nnew preference-learning objective. We prove in tabular domains PBRR has a\ncumulative regret that matches, up to constants, that of prior preference-based\nRL methods. In addition, on a suite of reward-hacking benchmarks, PBRR\nconsistently outperforms baselines that learn a reward function from scratch\nfrom preferences or modify the proxy reward function using other approaches,\nrequiring substantially fewer preferences to learn high performing policies."}
{"id": "2510.13048", "categories": ["cs.RO", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.13048", "abs": "https://arxiv.org/abs/2510.13048", "authors": ["Minghao Guo", "Victor Zordan", "Sheldon Andrews", "Wojciech Matusik", "Maneesh Agrawala", "Hsueh-Ti Derek Liu"], "title": "Kinematic Kitbashing for Modeling Functional Articulated Objects", "comment": null, "summary": "We introduce Kinematic Kitbashing, an automatic framework that synthesizes\nfunctionality-aware articulated objects by reusing parts from existing models.\nGiven a kinematic graph with a small collection of articulated parts, our\noptimizer jointly solves for the spatial placement of every part so that (i)\nattachments remain geometrically sound over the entire range of motion and (ii)\nthe assembled object satisfies user-specified functional goals such as\ncollision-free actuation, reachability, or trajectory following. At its core is\na kinematics-aware attachment energy that aligns vector distance function\nfeatures sampled across multiple articulation snapshots. We embed this\nattachment term within an annealed Riemannian Langevin dynamics sampler that\ntreats functionality objectives as additional energies, enabling robust global\nexploration while accommodating non-differentiable functionality objectives and\nconstraints. Our framework produces a wide spectrum of assembled articulated\nshapes, from trash-can wheels grafted onto car bodies to multi-segment lamps,\ngear-driven paddlers, and reconfigurable furniture, and delivers strong\nquantitative improvements over state-of-the-art baselines across geometric,\nkinematic, and functional metrics. By tightly coupling articulation-aware\ngeometry matching with functionality-driven optimization, Kinematic Kitbashing\nbridges part-based shape modeling and functional assembly design, empowering\nrapid creation of interactive articulated assets."}
{"id": "2510.13054", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13054", "abs": "https://arxiv.org/abs/2510.13054", "authors": ["Ankit Goyal", "Hugo Hadfield", "Xuning Yang", "Valts Blukis", "Fabio Ramos"], "title": "VLA-0: Building State-of-the-Art VLAs with Zero Modification", "comment": null, "summary": "Vision-Language-Action models (VLAs) hold immense promise for enabling\ngeneralist robot manipulation. However, the best way to build them remains an\nopen question. Current approaches often add complexity, such as modifying the\nexisting vocabulary of a Vision-Language Model (VLM) with action tokens or\nintroducing special action heads. Curiously, the simplest strategy of\nrepresenting actions directly as text has remained largely unexplored. This\nwork introduces VLA-0 to investigate this idea. We find that VLA-0 is not only\neffective; it is surprisingly powerful. With the right design, VLA-0\noutperforms more involved models. On LIBERO, a popular benchmark for evaluating\nVLAs, VLA-0 outperforms all existing methods trained on the same robotic data,\nincluding $\\pi_0.5$-KI, OpenVLA-OFT and SmolVLA. Furthermore, without\nlarge-scale robotics-specific training, it outperforms methods trained on\nlarge-scale robotic data, like $\\pi_0.5$-KI, $\\pi_0$, GR00T-N1 and MolmoAct.\nThese findings also translate to the real world, where VLA-0 outperforms\nSmolVLA, a VLA model pre-trained on large-scale real data. This paper\nsummarizes our unexpected findings and spells out the specific techniques\nrequired to unlock the high performance of this simple yet potent VLA design.\nVisual results, code, and trained models are provided here:\nhttps://vla0.github.io/."}
{"id": "2510.13100", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13100", "abs": "https://arxiv.org/abs/2510.13100", "authors": ["Yifu Ding", "Ruicheng Ao", "Pablo Duenas-Martinez", "Thomas Magnanti"], "title": "Decision-dependent Robust Charging Infrastructure Planning for Light-duty Truck Electrification at Industrial Sites: Scheduling and Abandonment", "comment": null, "summary": "Many industrial sites rely on diesel-powered light-duty trucks to transport\nworkers and small-scale facilities, which has resulted in a significant amount\nof greenhouse emissions (GHGs). To address this, we developed a two-stage\nrobust charging infrastructure planning model for electrifying light-duty\ntrucks at industrial sites. The model is formulated as a mixed-integer linear\nprogramming (MILP) that optimizes the charging infrastructure, selected from\nmultiple charger types and potential locations, and determines opportunity\ncharging schedules for each truck based on the chosen infrastructure. Given the\nstrict stopping points and schedules at industrial sites, we introduced a\nscheduling problem with abandonment, where trucks forgo charging if their\nwaiting times exceed a maximum threshold. We also further incorporated the\nimpacts of overnight charging and range anxiety on waiting and abandonment\nbehaviors. To represent the stochastic and heterogeneous parking durations of\ntrucks, we constructed a decision-dependent robust uncertainty set in which\nparking time variability flexibly depends on charging choices. We applied the\nmodel in a case study of an open-pit mining site, which plans charger\ninstallations in eight zones and schedules a fleet of around 200 trucks. By\ndecomposing the problem into monthly subproblems and using heuristic\napproaches, for the whole-year dataset, the model achieves an optimality gap of\nless than 0.1 % within a reasonable computation time under diverse uncertainty\nscenarios."}
{"id": "2510.13114", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13114", "abs": "https://arxiv.org/abs/2510.13114", "authors": ["Zhuoyuan Wang", "Tongyao Jia", "Pharuj Rajborirug", "Neeraj Ramesh", "Hiroyuki Okuda", "Tatsuya Suzuki", "Soummya Kar", "Yorie Nakahira"], "title": "Safe Driving in Occluded Environments", "comment": null, "summary": "Ensuring safe autonomous driving in the presence of occlusions poses a\nsignificant challenge in its policy design. While existing model-driven control\ntechniques based on set invariance can handle visible risks, occlusions create\nlatent risks in which safety-critical states are not observable. Data-driven\ntechniques also struggle to handle latent risks because direct mappings from\nrisk-critical objects in sensor inputs to safe actions cannot be learned\nwithout visible risk-critical objects. Motivated by these challenges, in this\npaper, we propose a probabilistic safety certificate for latent risk. Our key\ntechnical enabler is the application of probabilistic invariance: It relaxes\nthe strict observability requirements imposed by set-invariance methods that\ndemand the knowledge of risk-critical states. The proposed techniques provide\nlinear action constraints that confine the latent risk probability within\ntolerance. Such constraints can be integrated into model predictive controllers\nor embedded in data-driven policies to mitigate latent risks. The proposed\nmethod is tested using the CARLA simulator and compared with a few existing\ntechniques. The theoretical and empirical analysis jointly demonstrate that the\nproposed methods assure long-term safety in real-time control in occluded\nenvironments without being overly conservative and with transparency to exposed\nrisks."}
{"id": "2510.13139", "categories": ["cs.CY", "cs.CE", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.13139", "abs": "https://arxiv.org/abs/2510.13139", "authors": ["Xiaoyu Yan", "Tianxing Dai", "Yu", "Nie"], "title": "Addressing the alignment problem in transportation policy making: an LLM approach", "comment": null, "summary": "A key challenge in transportation planning is that the collective preferences\nof heterogeneous travelers often diverge from the policies produced by\nmodel-driven decision tools. This misalignment frequently results in\nimplementation delays or failures. Here, we investigate whether large language\nmodels (LLMs), noted for their capabilities in reasoning and simulating human\ndecision-making, can help inform and address this alignment problem. We develop\na multi-agent simulation in which LLMs, acting as agents representing residents\nfrom different communities in a city, participate in a referendum on a set of\ntransit policy proposals. Using chain-of-thought reasoning, LLM agents provide\nranked-choice or approval-based preferences, which are aggregated using\ninstant-runoff voting (IRV) to model democratic consensus. We implement this\nsimulation framework with both GPT-4o and Claude-3.5, and apply it for Chicago\nand Houston. Our findings suggest that LLM agents are capable of approximating\nplausible collective preferences and responding to local context, while also\ndisplaying model-specific behavioral biases and modest divergences from\noptimization-based benchmarks. These capabilities underscore both the promise\nand limitations of LLMs as tools for solving the alignment problem in\ntransportation decision-making."}
{"id": "2510.13149", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13149", "abs": "https://arxiv.org/abs/2510.13149", "authors": ["Yangtao Chen", "Zixuan Chen", "Nga Teng Chan", "Junting Chen", "Junhui Yin", "Jieqi Shi", "Yang Gao", "Yong-Lu Li", "Jing Huo"], "title": "RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation", "comment": "Under review. These first two authors contributed equally to this\n  work", "summary": "Enabling robots to flexibly schedule and compose learned skills for novel\nlong-horizon manipulation under diverse perturbations remains a core challenge.\nEarly explorations with end-to-end VLA models show limited success, as these\nmodels struggle to generalize beyond the training distribution. Hierarchical\napproaches, where high-level planners generate subgoals for low-level policies,\nbring certain improvements but still suffer under complex perturbations,\nrevealing limited capability in skill composition. However, existing benchmarks\nprimarily emphasize task completion in long-horizon settings, offering little\ninsight into compositional generalization, robustness, and the interplay\nbetween planning and execution. To systematically investigate these gaps, we\npropose RoboHiMan, a hierarchical evaluation paradigm for compositional\ngeneralization in long-horizon manipulation. RoboHiMan introduces HiMan-Bench,\na benchmark of atomic and compositional tasks under diverse perturbations,\nsupported by a multi-level training dataset for analyzing progressive data\nscaling, and proposes three evaluation paradigms (vanilla, decoupled, coupled)\nthat probe the necessity of skill composition and reveal bottlenecks in\nhierarchical architectures. Experiments highlight clear capability gaps across\nrepresentative models and architectures, pointing to directions for advancing\nmodels better suited to real-world long-horizon manipulation tasks. Videos and\nopen-source code can be found on our project website:\nhttps://chenyt31.github.io/robo-himan.github.io/."}
{"id": "2510.13162", "categories": ["cs.CY", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13162", "abs": "https://arxiv.org/abs/2510.13162", "authors": ["Taylor Robinson", "Rikke Bjerg Jensen"], "title": "Searching for a Farang: Collective Security among Women in Pattaya, Thailand", "comment": "To appear at IEEE Security & Privacy 2026", "summary": "We report on two months of ethnographic fieldwork in a women's centre in\nPattaya, and interviews with 76 participants. Our findings, as they relate to\ndigital security, show how (i) women in Pattaya, often working in the sex and\nmassage industries, perceived relationships with farang men as their best, and\nsometimes only, option to achieve security; (ii) the strategies used by the\nwomen to appeal to a farang involved presenting themselves online, mirroring\nhow they were being advertised by bar owners to attract customers; (iii)\nappealing to what they considered `Western ideals', the women sought out\n`Western technologies' and appropriated them for their benefit; (iv) the women\nnavigated a series of online security risks, such as scams and abuse, which\nshaped their search for a farang; (v) the women developed collective security\nthrough knowledge-sharing to protect themselves and each other in their search\nfor a farang. We situate our work in emerging digital security scholarship\nwithin marginalised contexts."}
{"id": "2510.13195", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13195", "abs": "https://arxiv.org/abs/2510.13195", "authors": ["Qun Ma", "Xiao Xue", "Xuwen Zhang", "Zihan Zhao", "Yuwei Guo", "Ming Zhang"], "title": "Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation", "comment": null, "summary": "The advent of large language models (LLMs) has enabled agents to represent\nvirtual humans in societal simulations, facilitating diverse interactions\nwithin complex social systems. However, existing LLM-based agents exhibit\nsevere limitations in affective cognition: They fail to simulate the bounded\nrationality essential for bridging virtual and real-world services; They lack\nempirically validated integration mechanisms embedding emotions within agent\ndecision architectures. This paper constructs an emotional cognition framework\nincorporating desire generation and objective management, designed to achieve\nemotion alignment between LLM-based agents and humans, modeling the complete\ndecision-making process of LLM-based agents, encompassing state evolution,\ndesire generation, objective optimization, decision generation, and action\nexecution. This study implements the proposed framework within our proprietary\nmulti-agent interaction environment. Experimental results demonstrate that\nagents governed by our framework not only exhibit behaviors congruent with\ntheir emotional states but also, in comparative assessments against other agent\ntypes, demonstrate superior ecological validity and generate decision outcomes\nthat significantly more closely approximate human behavioral patterns."}
{"id": "2510.13214", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13214", "abs": "https://arxiv.org/abs/2510.13214", "authors": ["Zehui Ling", "Deshu Chen", "Yichi Zhang", "Yuchen Liu", "Xigui Li", "Xin Guo", "Yuan Cheng"], "title": "Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) demonstrate that\nchain-of-thought prompting and deep reasoning substantially enhance performance\non complex tasks, and multi-agent systems can further improve accuracy by\nenabling model debates. However, applying deep reasoning to all problems is\ncomputationally expensive. To mitigate these costs, we propose a complementary\nagent system integrating small and large LLMs. The small LLM first generates an\ninitial answer, which is then verified by the large LLM. If correct, the answer\nis adopted directly; otherwise, the large LLM performs in-depth reasoning.\nExperimental results show that, for simple problems, our approach reduces the\ncomputational cost of the large LLM by more than 50% with negligible accuracy\nloss, while consistently maintaining robust performance on complex tasks."}
{"id": "2510.13215", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13215", "abs": "https://arxiv.org/abs/2510.13215", "authors": ["Joy Jia Yin Lim", "Ye He", "Jifan Yu", "Xin Cong", "Daniel Zhang-Li", "Zhiyuan Liu", "Huiqin Liu", "Lei Hou", "Juanzi Li", "Bin Xu"], "title": "Personalized Learning Path Planning with Goal-Driven Learner State Modeling", "comment": null, "summary": "Personalized Learning Path Planning (PLPP) aims to design adaptive learning\npaths that align with individual goals. While large language models (LLMs) show\npotential in personalizing learning experiences, existing approaches often lack\nmechanisms for goal-aligned planning. We introduce Pxplore, a novel framework\nfor PLPP that integrates a reinforcement-based training paradigm and an\nLLM-driven educational architecture. We design a structured learner state model\nand an automated reward function that transforms abstract objectives into\ncomputable signals. We train the policy combining supervised fine-tuning (SFT)\nand Group Relative Policy Optimization (GRPO), and deploy it within a\nreal-world learning platform. Extensive experiments validate Pxplore's\neffectiveness in producing coherent, personalized, and goal-driven learning\npaths. We release our code and dataset to facilitate future research."}
{"id": "2510.13220", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13220", "abs": "https://arxiv.org/abs/2510.13220", "authors": ["Yufei He", "Juncheng Liu", "Yue Liu", "Yibo Li", "Tri Cao", "Zhiyuan Hu", "Xinxing Xu", "Bryan Hooi"], "title": "EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems", "comment": null, "summary": "A fundamental limitation of current AI agents is their inability to learn\ncomplex skills on the fly at test time, often behaving like \"clever but\nclueless interns\" in novel environments. This severely limits their practical\nutility. To systematically measure and drive progress on this challenge, we\nfirst introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a\nnew evaluation setup where an agent must play the same game for several\nconsecutive episodes, attempting to improve its performance from one episode to\nthe next. On J-TTL, we find that existing adaptation methods like reflection,\nmemory, or reinforcement learning struggle. To address the challenges posed by\nour benchmark, we present EvoTest, an evolutionary test-time learning framework\nthat improves an agent without any fine-tuning or gradients-by evolving the\nentire agentic system after every episode. EvoTest has two roles: the Actor\nAgent, which plays the game, and the Evolver Agent, which analyzes the episode\ntranscript to propose a revised configuration for the next run. This\nconfiguration rewrites the prompt, updates memory by logging effective\nstate-action choices, tunes hyperparameters, and learns the tool-use routines.\nOn our J-TTL benchmark, EvoTest consistently increases performance,\noutperforming not only reflection and memory-only baselines but also more\ncomplex online fine-tuning methods. Notably, our method is the only one capable\nof winning two games (Detective and Library), while all baselines fail to win\nany."}
{"id": "2510.13230", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13230", "abs": "https://arxiv.org/abs/2510.13230", "authors": ["Jalal Khan", "Manzoor Khan", "Sherzod Turaev", "Sumbal Malik", "Hesham El-Sayed", "Farman Ullah"], "title": "An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities", "comment": "32 pages, 14 figures", "summary": "The driving environment perception has a vital role for autonomous driving\nand nowadays has been actively explored for its realization. The research\ncommunity and relevant stakeholders necessitate the development of Deep\nLearning (DL) models and AI-enabled solutions to enhance autonomous vehicles\n(AVs) for smart mobility. There is a need to develop a model that accurately\nperceives multiple objects on the road and predicts the driver's perception to\ncontrol the car's movements. This article proposes a novel utility-based\nanalytical model that enables perception systems of AVs to understand the\ndriving environment. The article consists of modules: acquiring a custom\ndataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a\nDL-based model (YOLOv8s) for object detection; and a module to measure the\nutility of perception service from the performance values of trained model\ninstances. The perception model is validated based on the object detection\ntask, and its process is benchmarked by state-of-the-art deep learning models'\nperformance metrics from the nuScense dataset. The experimental results show\nthree best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,\nSGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the\nAdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)\nstill outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,\ntruck: 0.781, etc.) because it has better class-level performance values,\nconfirmed by the proposed perception model. We validate that the proposed\nfunction is capable of finding the right perception for AVs. The results above\nencourage using the proposed perception model to evaluate the utility of\nlearning models and determine the appropriate perception for AVs."}
{"id": "2510.13262", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13262", "abs": "https://arxiv.org/abs/2510.13262", "authors": ["Weiqi Guo", "Guanjun Liu", "Ziyuan Zhou"], "title": "SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning", "comment": null, "summary": "Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for\ncooperative and competitive tasks such as autonomous driving and strategic\ngaming. However, models trained by MADRL are vulnerable to adversarial\nperturbations on states and actions. Therefore, it is essential to investigate\nthe robustness of MADRL models from an attack perspective. Existing studies\nfocus on either state-only attacks or action-only attacks, but do not consider\nhow to effectively joint them. Simply combining state and action perturbations\nsuch as randomly perturbing states and actions does not exploit their potential\nsynergistic effects. In this paper, we propose the State-Action Joint Attack\n(SAJA) framework that has a good synergistic effects. SAJA consists of two\nimportant phases: (1) In the state attack phase, a multi-step gradient ascent\nmethod utilizes both the actor network and the critic network to compute an\nadversarial state, and (2) in the action attack phase, based on the perturbed\nstate, a second gradient ascent uses the critic network to craft the final\nadversarial action. Additionally, a heuristic regularizer measuring the\ndistance between the perturbed actions and the original clean ones is added\ninto the loss function to enhance the effectiveness of the critic's guidance.\nWe evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating\nthat (1) it outperforms and is more stealthy than state-only or action-only\nattacks, and (2) existing state or action defense methods cannot defend its\nattacks."}
{"id": "2510.13273", "categories": ["cs.SI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.13273", "abs": "https://arxiv.org/abs/2510.13273", "authors": ["Xinyi Zhao", "Anna I. Thoma", "Ralph Hertwig", "Dirk U. Wulff"], "title": "Mapping the gender attrition gap in academic psychology", "comment": null, "summary": "Although more women than men enter social science disciplines, they are\nunderrepresented at senior levels. To investigate this leaky pipeline, this\nstudy analyzed the career trajectories of 78,216 psychology researchers using\nlarge-scale bibliometric data. Despite overall constituting over 60\\% of these\nresearchers, women experienced consistently higher attrition rates than men,\nparticularly in the early years following their first publication. Academic\nperformance, particularly first-authored publications, was strongly associated\nwith early-career retention -- more so than collaboration networks or\ninstitutional environment. After controlling for gender differences in\npublication-, collaboration-, and institution-level factors, women remained\nmore likely to leave academia, especially in early-career stages, pointing to\npersistent barriers that hinder women's academic careers. These findings\nsuggest that in psychology and potentially other social science disciplines,\nthe core challenge lies in retention rather than recruitment, underscoring the\nneed for targeted, early-career interventions to promote long-term gender\nequity."}
{"id": "2510.13279", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13279", "abs": "https://arxiv.org/abs/2510.13279", "authors": ["Fuma Omori", "Atsushi Yano", "Takuya Azumi"], "title": "Partitioned Scheduling for DAG Tasks Considering Probabilistic Execution Time", "comment": null, "summary": "Autonomous driving systems, critical for safety, require real-time guarantees\nand can be modeled as DAGs. Their acceleration features, such as caches and\npipelining, often result in execution times below the worst-case. Thus, a\nprobabilistic approach ensuring constraint satisfaction within a probability\nthreshold is more suitable than worst-case guarantees for these systems. This\npaper considers probabilistic guarantees for DAG tasks by utilizing the results\nof probabilistic guarantees for single processors, which have been relatively\nmore advanced than those for multi-core processors. This paper proposes a task\nset partitioning method that guarantees schedulability under the partitioned\nscheduling. The evaluation on randomly generated DAG task sets demonstrates\nthat the proposed method schedules more task sets with a smaller mean analysis\ntime compared to existing probabilistic schedulability analysis for DAGs. The\nevaluation also compares four bin-packing heuristics, revealing Item-Centric\nWorst-Fit-Decreasing schedules the most task sets."}
{"id": "2510.13284", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13284", "abs": "https://arxiv.org/abs/2510.13284", "authors": ["Haoyang Wu", "Siheng Wu", "William X. Liu", "Fangui Zeng"], "title": "ALOHA2 Robot Kitchen Application Scenario Reproduction Report", "comment": null, "summary": "ALOHA2 is an enhanced version of the dual-arm teleoperated robot ALOHA,\nfeaturing higher performance and robustness compared to the original design,\nwhile also being more ergonomic. Like ALOHA, ALOHA2 consists of two grippers\nand two ViperX 6-DoF arms, as well as two smaller WidowX arms. Users control\nthe follower mechanical arms by operating the leader mechanical arms through\nback-driving. The device also includes cameras that generate images from\nmultiple viewpoints, allowing for RGB data collection during teleoperation. The\nrobot is mounted on a 48-inch x 30-inch table, equipped with an aluminum frame\nthat provides additional mounting points for cameras and gravity compensation\nsystems."}
{"id": "2510.13287", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13287", "abs": "https://arxiv.org/abs/2510.13287", "authors": ["Nishant Chandna", "Akshat Kaushal"], "title": "DAMM-LOAM: Degeneracy Aware Multi-Metric LiDAR Odometry and Mapping", "comment": "Accepted at IROS Active Perception Workshop", "summary": "LiDAR Simultaneous Localization and Mapping (SLAM) systems are essential for\nenabling precise navigation and environmental reconstruction across various\napplications. Although current point-to-plane ICP algorithms perform effec-\ntively in structured, feature-rich environments, they struggle in scenarios\nwith sparse features, repetitive geometric structures, and high-frequency\nmotion. This leads to degeneracy in 6- DOF pose estimation. Most\nstate-of-the-art algorithms address these challenges by incorporating\nadditional sensing modalities, but LiDAR-only solutions continue to face\nlimitations under such conditions. To address these issues, we propose a novel\nDegeneracy-Aware Multi-Metric LiDAR Odometry and Map- ping (DAMM-LOAM) module.\nOur system improves mapping accuracy through point cloud classification based\non surface normals and neighborhood analysis. Points are classified into\nground, walls, roof, edges, and non-planar points, enabling accurate\ncorrespondences. A Degeneracy-based weighted least squares-based ICP algorithm\nis then applied for accurate odom- etry estimation. Additionally, a Scan\nContext based back-end is implemented to support robust loop closures.\nDAMM-LOAM demonstrates significant improvements in odometry accuracy,\nespecially in indoor environments such as long corridors"}
{"id": "2510.13324", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13324", "abs": "https://arxiv.org/abs/2510.13324", "authors": ["Erik Helmut", "Niklas Funk", "Tim Schneider", "Cristiana de Farias", "Jan Peters"], "title": "Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation", "comment": null, "summary": "Contact-rich manipulation depends on applying the correct grasp forces\nthroughout the manipulation task, especially when handling fragile or\ndeformable objects. Most existing imitation learning approaches often treat\nvisuotactile feedback only as an additional observation, leaving applied forces\nas an uncontrolled consequence of gripper commands. In this work, we present\nForce-Aware Robotic Manipulation (FARM), an imitation learning framework that\nintegrates high-dimensional tactile data to infer tactile-conditioned force\nsignals, which in turn define a matching force-based action space. We collect\nhuman demonstrations using a modified version of the handheld Universal\nManipulation Interface (UMI) gripper that integrates a GelSight Mini visual\ntactile sensor. For deploying the learned policies, we developed an actuated\nvariant of the UMI gripper with geometry matching our handheld version. During\npolicy rollouts, the proposed FARM diffusion policy jointly predicts robot\npose, grip width, and grip force. FARM outperforms several baselines across\nthree tasks with distinct force requirements -- high-force, low-force, and\ndynamic force adaptation -- demonstrating the advantages of its two key\ncomponents: leveraging force-grounded, high-dimensional tactile observations\nand a force-based control space. The codebase and design files are open-sourced\nand available at https://tactile-farm.github.io ."}
{"id": "2510.13356", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13356", "abs": "https://arxiv.org/abs/2510.13356", "authors": ["Jie Gu", "Tin Lun Lam", "Chunxu Tian", "Zhihao Xia", "Yongheng Xing", "Dan Zhang"], "title": "MODUR: A Modular Dual-reconfigurable Robot", "comment": null, "summary": "Modular Self-Reconfigurable Robot (MSRR) systems are a class of robots\ncapable of forming higher-level robotic systems by altering the topological\nrelationships between modules, offering enhanced adaptability and robustness in\nvarious environments. This paper presents a novel MSRR called MODUR, featuring\ndual-level reconfiguration capabilities designed to integrate reconfigurable\nmechanisms into MSRR. Specifically, MODUR can perform high-level\nself-reconfiguration among modules to create different configurations, while\neach module is also able to change its shape to execute basic motions. The\ndesign of MODUR primarily includes a compact connector and scissor linkage\ngroups that provide actuation, forming a parallel mechanism capable of\nachieving both connector motion decoupling and adjacent position migration\ncapabilities. Furthermore, the workspace, considering the interdependent\nconnectors, is comprehensively analyzed, laying a theoretical foundation for\nthe design of the module's basic motion. Finally, the motion of MODUR is\nvalidated through a series of experiments."}
{"id": "2510.13358", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13358", "abs": "https://arxiv.org/abs/2510.13358", "authors": ["Shingo Ayabe", "Hiroshi Kera", "Kazuhiko Kawamoto"], "title": "Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control", "comment": "16 pages, 8 figures", "summary": "Offline reinforcement learning enables sample-efficient policy acquisition\nwithout risky online interaction, yet policies trained on static datasets\nremain brittle under action-space perturbations such as actuator faults. This\nstudy introduces an offline-to-online framework that trains policies on clean\ndata and then performs adversarial fine-tuning, where perturbations are\ninjected into executed actions to induce compensatory behavior and improve\nresilience. A performance-aware curriculum further adjusts the perturbation\nprobability during training via an exponential-moving-average signal, balancing\nrobustness and stability throughout the learning process. Experiments on\ncontinuous-control locomotion tasks demonstrate that the proposed method\nconsistently improves robustness over offline-only baselines and converges\nfaster than training from scratch. Matching the fine-tuning and evaluation\nconditions yields the strongest robustness to action-space perturbations, while\nthe adaptive curriculum strategy mitigates the degradation of nominal\nperformance observed with the linear curriculum strategy. Overall, the results\nshow that adversarial fine-tuning enables adaptive and robust control under\nuncertain environments, bridging the gap between offline efficiency and online\nadaptability."}
{"id": "2510.13393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13393", "abs": "https://arxiv.org/abs/2510.13393", "authors": ["Yunxiao Zhao", "Zhiqiang Wang", "Xingtong Yu", "Xiaoli Li", "Jiye Liang", "Ru Li"], "title": "Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization", "comment": "14 pages, 7 figures, 11 tables. Under review by IEEE", "summary": "Rationalization, a data-centric framework, aims to build self-explanatory\nmodels to explain the prediction outcome by generating a subset of\nhuman-intelligible pieces of the input data. It involves a cooperative game\nmodel where a generator generates the most human-intelligible parts of the\ninput (i.e., rationales), followed by a predictor that makes predictions based\non these generated rationales. Conventional rationalization methods typically\nimpose constraints via regularization terms to calibrate or penalize undesired\ngeneration. However, these methods are suffering from a problem called mode\ncollapse, in which the predictor produces correct predictions yet the generator\nconsistently outputs rationales with collapsed patterns. Moreover, existing\nstudies are typically designed separately for specific collapsed patterns,\nlacking a unified consideration. In this paper, we systematically revisit\ncooperative rationalization from a novel game-theoretic perspective and\nidentify the fundamental cause of this problem: the generator no longer tends\nto explore new strategies to uncover informative rationales, ultimately leading\nthe system to converge to a suboptimal game equilibrium (correct predictions\nv.s collapsed rationales). To solve this problem, we then propose a novel\napproach, Game-theoretic Policy Optimization oriented RATionalization (PORAT),\nwhich progressively introduces policy interventions to address the game\nequilibrium in the cooperative game process, thereby guiding the model toward a\nmore optimal solution state. We theoretically analyse the cause of such a\nsuboptimal equilibrium and prove the feasibility of the proposed method.\nFurthermore, we validate our method on nine widely used real-world datasets and\ntwo synthetic settings, where PORAT achieves up to 8.1% performance\nimprovements over existing state-of-the-art methods."}
{"id": "2510.13396", "categories": ["eess.SY", "cs.SY", "93-10"], "pdf": "https://arxiv.org/pdf/2510.13396", "abs": "https://arxiv.org/abs/2510.13396", "authors": ["Luka Baković", "David Ohlin", "Emma Tegling"], "title": "Multipolar dynamics of social segregation: Data validation on Swedish vaccination statistics", "comment": "Presented at CoDIT 2025", "summary": "We perform a validation analysis on the multipolar model of opinion dynamics.\nA general methodology for using the model on datasets of two correlated\nvariables is proposed and tested using data on the relationship between\nCOVID-19 vaccination rates and political participation in Sweden. The model is\nshown to successfully capture the opinion segregation demonstrated by the data\nand spatial correlation of biases is demonstrated as necessary for the result.\nA mixing of the biases on the other hand leads to a more homogeneous opinion\ndistribution, and greater penetration of the majority opinion, which here\ncorresponds to a decision to vote or vaccinate."}
{"id": "2510.13417", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13417", "abs": "https://arxiv.org/abs/2510.13417", "authors": ["Liesbeth Allein", "Nataly Pineda-Castañeda", "Andrea Rocci", "Marie-Francine Moens"], "title": "Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse", "comment": null, "summary": "How does a cause lead to an effect, and which intermediate causal steps\nexplain their connection? This work scrutinizes the mechanistic causal\nreasoning capabilities of large language models (LLMs) to answer these\nquestions through the task of implicit causal chain discovery. In a diagnostic\nevaluation framework, we instruct nine LLMs to generate all possible\nintermediate causal steps linking given cause-effect pairs in causal chain\nstructures. These pairs are drawn from recent resources in argumentation\nstudies featuring polarized discussion on climate change. Our analysis reveals\nthat LLMs vary in the number and granularity of causal steps they produce.\nAlthough they are generally self-consistent and confident about the\nintermediate causal connections in the generated chains, their judgments are\nmainly driven by associative pattern matching rather than genuine causal\nreasoning. Nonetheless, human evaluations confirmed the logical coherence and\nintegrity of the generated chains. Our baseline causal chain discovery\napproach, insights from our diagnostic evaluation, and benchmark dataset with\ncausal chains lay a solid foundation for advancing future work in implicit,\nmechanistic causal reasoning in argumentation settings."}
{"id": "2510.13443", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13443", "abs": "https://arxiv.org/abs/2510.13443", "authors": ["Mojtaba Mollahossein", "Gholamreza Vossoughi", "Mohammad Hossein Rohban"], "title": "Real-Time Knee Angle Prediction Using EMG and Kinematic Data with an Attention-Based CNN-LSTM Network and Transfer Learning Across Multiple Datasets", "comment": null, "summary": "Electromyography (EMG) signals are widely used for predicting body joint\nangles through machine learning (ML) and deep learning (DL) methods. However,\nthese approaches often face challenges such as limited real-time applicability,\nnon-representative test conditions, and the need for large datasets to achieve\noptimal performance. This paper presents a transfer-learning framework for knee\njoint angle prediction that requires only a few gait cycles from new subjects.\nThree datasets - Georgia Tech, the University of California Irvine (UCI), and\nthe Sharif Mechatronic Lab Exoskeleton (SMLE) - containing four EMG channels\nrelevant to knee motion were utilized. A lightweight attention-based CNN-LSTM\nmodel was developed and pre-trained on the Georgia Tech dataset, then\ntransferred to the UCI and SMLE datasets. The proposed model achieved\nNormalized Mean Absolute Errors (NMAE) of 6.8 percent and 13.7 percent for\none-step and 50-step predictions on abnormal subjects using EMG inputs alone.\nIncorporating historical knee angles reduced the NMAE to 3.1 percent and 3.5\npercent for normal subjects, and to 2.8 percent and 7.5 percent for abnormal\nsubjects. When further adapted to the SMLE exoskeleton with EMG, kinematic, and\ninteraction force inputs, the model achieved 1.09 percent and 3.1 percent NMAE\nfor one- and 50-step predictions, respectively. These results demonstrate\nrobust performance and strong generalization for both short- and long-term\nrehabilitation scenarios."}
{"id": "2510.13449", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13449", "abs": "https://arxiv.org/abs/2510.13449", "authors": ["Jan Brändle", "Julie Rousseau", "Pulkit Nahata", "Gabriela Hug"], "title": "On the Flexibility Potential of a Swiss Distribution Grid: Opportunities and Limitations", "comment": null, "summary": "The growing integration of distributed renewable generation and the\nelectrification of heating and transportation are rapidly increasing the number\nof flexible devices within modern distribution grids. Leveraging the aggregated\nflexibility of these small-scale distributed resources is essential to\nmaintaining future grid-wide stability. This work uses the Swiss distribution\ngrid of Walenstadt as a case study to provide insights into the aggregated\nflexibility potential of distribution grids. It demonstrates that incorporating\ndevices such as heat pumps and photovoltaic systems significantly enhances\ndistribution grid flexibility. It investigates the time-varying nature of\naggregated flexibility and highlights how it can vary seasonally. Furthermore,\nsimulations of future scenarios reveal that aggregated flexibility does not\nincrease linearly or monotonically with higher levels of flexible device\npenetration. This is primarily due to the overloading of individual feeders,\nwhich underscores the impact of grid topology and network constraints on the\naggregated flexibility potential."}
{"id": "2510.13459", "categories": ["cs.AI", "cs.CE", "cs.NI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13459", "abs": "https://arxiv.org/abs/2510.13459", "authors": ["Timothy Wong", "Tom Freeman", "Joseph Feehily"], "title": "Mobile Coverage Analysis using Crowdsourced Data", "comment": "8 pages", "summary": "Effective assessment of mobile network coverage and the precise\nidentification of service weak spots are paramount for network operators\nstriving to enhance user Quality of Experience (QoE). This paper presents a\nnovel framework for mobile coverage and weak spot analysis utilising\ncrowdsourced QoE data. The core of our methodology involves coverage analysis\nat the individual cell (antenna) level, subsequently aggregated to the site\nlevel, using empirical geolocation data. A key contribution of this research is\nthe application of One-Class Support Vector Machine (OC-SVM) algorithm for\ncalculating mobile network coverage. This approach models the decision\nhyperplane as the effective coverage contour, facilitating robust calculation\nof coverage areas for individual cells and entire sites. The same methodology\nis extended to analyse crowdsourced service loss reports, thereby identifying\nand quantifying geographically localised weak spots. Our findings demonstrate\nthe efficacy of this novel framework in accurately mapping mobile coverage and,\ncrucially, in highlighting granular areas of signal deficiency, particularly\nwithin complex urban environments."}
{"id": "2510.13461", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13461", "abs": "https://arxiv.org/abs/2510.13461", "authors": ["Yangye Jiang", "Jiachen Wang", "Daofei Li"], "title": "Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers", "comment": null, "summary": "Accurate prediction of vehicle collision dynamics is crucial for advanced\nsafety systems and post-impact control applications, yet existing methods face\ninherent trade-offs among computational efficiency, prediction accuracy, and\ndata requirements. This paper proposes a dual Physics-Informed Neural Network\nframework addressing these challenges through two complementary networks. The\nfirst network integrates Gaussian Mixture Models with PINN architecture to\nlearn impact force distributions from finite element analysis data while\nenforcing momentum conservation and energy consistency constraints. The second\nnetwork employs an adaptive PINN with dynamic constraint weighting to predict\npost-collision vehicle dynamics, featuring an adaptive physics guard layer that\nprevents unrealistic predictions whil e preserving data-driven learning\ncapabilities. The framework incorporates uncertainty quantification through\ntime-varying parameters and enables rapid adaptation via fine-tuning\nstrategies. Validation demonstrates significant improvements: the impact force\nmodel achieves relative errors below 15.0% for force prediction on finite\nelement analysis (FEA) datasets, while the vehicle dynamics model reduces\naverage trajectory prediction error by 63.6% compared to traditional\nfour-degree-of-freedom models in scaled vehicle experiments. The integrated\nsystem maintains millisecond-level computational efficiency suitable for\nreal-time applications while providing probabilistic confidence bounds\nessential for safety-critical control. Comprehensive validation through FEA\nsimulation, dynamic modeling, and scaled vehicle experiments confirms the\nframework's effectiveness for Precision Immobilization Technique scenarios and\ngeneral collision dynamics prediction."}
{"id": "2510.13465", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13465", "abs": "https://arxiv.org/abs/2510.13465", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Discrimination, artificial intelligence, and algorithmic decision-making", "comment": null, "summary": "Artificial intelligence (AI) has a huge impact on our personal lives and also\non our democratic society as a whole. While AI offers vast opportunities for\nthe benefit of people, its potential to embed and perpetuate bias and\ndiscrimination remains one of the most pressing challenges deriving from its\nincreasing use. This new study, which was prepared by Prof. Frederik Zuiderveen\nBorgesius for the Anti-discrimination Department of the Council of Europe,\nelaborates on the risks of discrimination caused by algorithmic decision-making\nand other types of artificial intelligence (AI)."}
{"id": "2510.13466", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13466", "abs": "https://arxiv.org/abs/2510.13466", "authors": ["Natali Helberger", "Frederik Zuiderveen Borgesius", "Agustin Reyna"], "title": "The Perfect Match? A Closer Look at the Relationship between EU Consumer Law and Data Protection Law", "comment": null, "summary": "In modern markets, many companies offer so-called 'free' services and\nmonetize consumer data they collect through those services. This paper argues\nthat consumer law and data protection law can usefully complement each other.\nData protection law can also inform the interpretation of consumer law. Using\nconsumer rights, consumers should be able to challenge excessive collection of\ntheir personal data. Consumer organizations have used consumer law to tackle\ndata protection infringements. The interplay of data protection law and\nconsumer protection law provides exciting opportunities for a more integrated\nvision on 'data consumer law'."}
{"id": "2510.13468", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13468", "abs": "https://arxiv.org/abs/2510.13468", "authors": ["Stefan Kulk", "Frederik Zuiderveen Borgesius"], "title": "Privacy, freedom of expression, and the right to be forgotten in Europe", "comment": null, "summary": "In this chapter we discuss the relation between privacy and freedom of\nexpression in Europe. In principle, the two rights have equal weight in Europe\n- which right prevails depends on the circumstances of a case. We use the\nGoogle Spain judgment of the Court of Justice of the European Union, sometimes\ncalled the 'right to be forgotten' judgment, to illustrate the difficulties\nwhen balancing the two rights. The court decided in Google Spain that people\nhave, under certain conditions, the right to have search results for their name\ndelisted. We discuss how Google and Data Protection Authorities deal with such\ndelisting requests in practice. Delisting requests illustrate that balancing\nprivacy and freedom of expression interests will always remain difficult."}
{"id": "2510.13488", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13488", "abs": "https://arxiv.org/abs/2510.13488", "authors": ["Maximilian Stasica", "Arne Bick", "Nico Bohlinger", "Omid Mohseni", "Max Johannes Alois Fritzsche", "Clemens Hübler", "Jan Peters", "André Seyfarth"], "title": "Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations", "comment": null, "summary": "Legged robots, particularly quadrupeds, excel at navigating rough terrains,\nyet their performance under vertical ground perturbations, such as those from\noscillating surfaces, remains underexplored. This study introduces a novel\napproach to enhance quadruped locomotion robustness by training the Unitree Go2\nrobot on an oscillating bridge - a 13.24-meter steel-and-concrete structure\nwith a 2.0 Hz eigenfrequency designed to perturb locomotion. Using\nReinforcement Learning (RL) with the Proximal Policy Optimization (PPO)\nalgorithm in a MuJoCo simulation, we trained 15 distinct locomotion policies,\ncombining five gaits (trot, pace, bound, free, default) with three training\nconditions: rigid bridge and two oscillating bridge setups with differing\nheight regulation strategies (relative to bridge surface or ground). Domain\nrandomization ensured zero-shot transfer to the real-world bridge. Our results\ndemonstrate that policies trained on the oscillating bridge exhibit superior\nstability and adaptability compared to those trained on rigid surfaces. Our\nframework enables robust gait patterns even without prior bridge exposure.\nThese findings highlight the potential of simulation-based RL to improve\nquadruped locomotion during dynamic ground perturbations, offering insights for\ndesigning robots capable of traversing vibrating environments."}
{"id": "2510.13501", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13501", "abs": "https://arxiv.org/abs/2510.13501", "authors": ["He Du", "Bowen Li", "Chengxing Xie", "Chang Gao", "Kai Chen", "Dacheng Tao"], "title": "Confidence as a Reward: Transforming LLMs into Reward Models", "comment": null, "summary": "Reward models can significantly enhance the reasoning capabilities of large\nlanguage models (LLMs), but they typically require extensive curated data and\ncostly training. To mitigate these challenges, training-free approaches such as\nLLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate\nresponses, achieving promising results. Recent works have also indicated that\nmodel confidence can serve effectively as a reward metric, distinguishing\nbetween chain-of-thought (CoT) and non-CoT paths. However, the concept of using\nconfidence as a reward has not been comprehensively studied. In this work, we\nsystematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful\ntraining-free method that utilizes token-level confidence in the model's final\nanswers as a proxy for reward, especially suitable for close-ended tasks.\nThrough extensive experiments on mathematical reasoning tasks, we demonstrate\nthat CRew outperforms existing training-free reward approaches on the MATH500\nand RewardMATH benchmarks, and even surpasses most trained reward models. We\nfurther identify a strong correlation between CRew scores and the actual\nreasoning performance of the model. Additionally, we find that CRew can\neffectively filter high-quality training data. Building upon these insights, we\npropose CRew-DPO, a training strategy that constructs preference data from\nconfidence scores combined with correctness signals. Finetuning with CRew-DPO\nfurther enhances the model's judging capabilities and consistently outperforms\nexisting self-training methods."}
{"id": "2510.13514", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13514", "abs": "https://arxiv.org/abs/2510.13514", "authors": ["Andreas C. Makrides", "Adam Suski", "Elina Spyrou"], "title": "Quantifying the Impact of Missing Risk Markets for Decarbonized Power Systems with Long Duration Energy Storage", "comment": null, "summary": "The transition to a fully decarbonised electricity system depends on\nintegrating new technologies that ensure reliability alongside sustainability.\nHowever, missing risk markets hinder investment in reliability-enhancing\ntechnologies by exposing investors to revenue uncertainty. This study provides\nthe first quantitative assessment of how missing risk markets affect investment\ndecisions in power systems that depend on long-duration energy storage (LDES)\nfor reliability. We develop a two-stage stochastic equilibrium model with\nrisk-averse market participants, which independently sizes power and energy\ncapacity. We apply the method to a case study of a deeply decarbonised power\nsystem in Great Britain. The results show that incomplete risk markets reduce\nsocial welfare, harm reliability, and discourage investment in LDES and other\ntechnologies with volatile revenue streams. Revenue volatility leads to\nsubstantial risk premiums and higher financing costs for LDES, creating a\nbarrier to its large-scale deployment. These findings demonstrate the\nimportance of policy mechanisms that hedge revenue risk to lower the cost of\ncapital and accelerate investment in reliability-enhancing, zero-carbon\ntechnologies"}
{"id": "2510.13524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13524", "abs": "https://arxiv.org/abs/2510.13524", "authors": ["William Flanagan", "Mukunda Das", "Rajitha Ramanyake", "Swaunja Maslekar", "Meghana Manipuri", "Joong Ho Choi", "Shruti Nair", "Shambhavi Bhusan", "Sanjana Dulam", "Mouni Pendharkar", "Nidhi Singh", "Vashisth Doshi", "Sachi Shah Paresh"], "title": "A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain", "comment": "NeurIPS 2025 GenAI in Finance Workshop", "summary": "As Generative Artificial Intelligence is adopted across the financial\nservices industry, a significant barrier to adoption and usage is measuring\nmodel performance. Historical machine learning metrics can oftentimes fail to\ngeneralize to GenAI workloads and are often supplemented using Subject Matter\nExpert (SME) Evaluation. Even in this combination, many projects fail to\naccount for various unique risks present in choosing specific metrics.\nAdditionally, many widespread benchmarks created by foundational research labs\nand educational institutions fail to generalize to industrial use. This paper\nexplains these challenges and provides a Risk Assessment Framework to allow for\nbetter application of SME and machine learning Metrics"}
{"id": "2510.13535", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13535", "abs": "https://arxiv.org/abs/2510.13535", "authors": ["Wentao Guo", "Yizhou Wang", "Wenzeng Zhang"], "title": "A Novel Robot Hand with Hoeckens Linkages and Soft Phalanges for Scooping and Self-Adaptive Grasping in Environmental Constraints", "comment": "Accepted by IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025, Hangzhou. This version includes updated contact\n  information", "summary": "This paper presents a novel underactuated adaptive robotic hand, Hockens-A\nHand, which integrates the Hoeckens mechanism, a double-parallelogram linkage,\nand a specialized four-bar linkage to achieve three adaptive grasping modes:\nparallel pinching, asymmetric scooping, and enveloping grasping. Hockens-A Hand\nrequires only a single linear actuator, leveraging passive mechanical\nintelligence to ensure adaptability and compliance in unstructured\nenvironments. Specifically, the vertical motion of the Hoeckens mechanism\nintroduces compliance, the double-parallelogram linkage ensures line contact at\nthe fingertip, and the four-bar amplification system enables natural\ntransitions between different grasping modes. Additionally, the inclusion of a\nmesh-textured silicone phalanx further enhances the ability to envelop objects\nof various shapes and sizes. This study employs detailed kinematic analysis to\noptimize the push angle and design the linkage lengths for optimal performance.\nSimulations validated the design by analyzing the fingertip motion and ensuring\nsmooth transitions between grasping modes. Furthermore, the grasping force was\nanalyzed using power equations to enhance the understanding of the system's\nperformance.Experimental validation using a 3D-printed prototype demonstrates\nthe three grasping modes of the hand in various scenarios under environmental\nconstraints, verifying its grasping stability and broad applicability."}
{"id": "2510.13551", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13551", "abs": "https://arxiv.org/abs/2510.13551", "authors": ["Robert West", "Ashton Anderson", "Ece Kamar", "Eric Horvitz"], "title": "Tandem Training for Language Models", "comment": null, "summary": "As language models continue to rapidly improve, we can expect their actions\nand reasoning to become difficult or impossible for weaker agents and humans to\nfollow, undermining interpretability and oversight. With an eye on long-term\nfutures, we pursue methods that encourage models to produce solutions that\nremain intelligible to weaker collaborators. We formalize intelligibility as\nhandoff robustness: a strong model's solution is intelligible to a weaker model\nif randomly handing off control to the weaker model along the solution path\ndoes not cause failure. Building on this criterion, we introduce tandem\ntraining for language models, a reinforcement learning (RL) paradigm in which\nrollout tokens are intermittently and randomly sampled from a frozen weak model\nrather than the strong model being trained. Because rollouts succeed only when\nthe strong model's actions and reasoning process can be continued by the weak\nmodel -- when the two can co-construct a successful solution -- optimizing\nstandard RL objectives with tandem training implicitly incentivizes both\ncorrectness and intelligibility. In the GSM8K math reasoning task, tandem\ntraining reliably teaches models to abandon jargon and adapt their language to\nweaker partners while keeping task accuracy high. Our results demonstrate a\npromising route to building AI systems that remain auditable by weaker agents,\nwith implications for human--AI collaboration and multi-agent communication."}
{"id": "2510.13553", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13553", "abs": "https://arxiv.org/abs/2510.13553", "authors": ["Wentao Guo", "Wenzeng Zhang"], "title": "Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping", "comment": "Accepted by IEEE International Conference on Robotics and Biomimetics\n  (IROS) 2025, Hangzhou, China. This version includes updated contact\n  information", "summary": "This paper presents the Hoecken-D Hand, an underactuated robotic gripper that\ncombines a modified Hoecken linkage with a differential spring mechanism to\nachieve both linear parallel pinching and a mid-stroke transition to adaptive\nenvelope. The original Hoecken linkage is reconfigured by replacing one member\nwith differential links, preserving straight-line guidance while enabling\ncontact-triggered reconfiguration without additional actuators. A\ndouble-parallelogram arrangement maintains fingertip parallelism during\nconventional pinching, whereas the differential mechanism allows one finger to\nwrap inward upon encountering an obstacle, improving stability on irregular or\nthin objects. The mechanism can be driven by a single linear actuator,\nminimizing complexity and cost; in our prototype, each finger is driven by its\nown linear actuator for simplicity. We perform kinematic modeling and force\nanalysis to characterize grasp performance, including simulated grasping forces\nand spring-opening behavior under varying geometric parameters. The design was\nprototyped using PLA-based 3D printing, achieving a linear pinching span of\napproximately 200 mm. Preliminary tests demonstrate reliable grasping in both\nmodes across a wide range of object geometries, highlighting the Hoecken-D Hand\nas a compact, adaptable, and cost-effective solution for manipulation in\nunstructured environments."}
{"id": "2510.13563", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13563", "abs": "https://arxiv.org/abs/2510.13563", "authors": ["Ayten Gürbüz", "Giuseppe Caire"], "title": "Channel Estimation under Large Doppler Shifts in NOMA-Based Air-Ground Communications", "comment": "Submitted to IEEE Conference, 6 pages, 2 Figures", "summary": "This paper investigates a multiple antenna system with non-orthogonal\nmultiple access (NOMA) for the exchange of air traffic management data between\ncommercial aircraft pilots and ground-based air traffic controllers. While NOMA\ntechniques enhance spectral efficiency, their application to aircraft\ncommunications is challenged by the high speed of the aircraft (up to 214 m/s)\nand the long communication ranges (up to 250 km), resulting in significant\nDoppler shifts and low signal-to-noise ratios, respectively. To accurately\nassess these challenges, we employ a realistic geometry-based stochastic\nair-ground channel model, derived from dedicated flight measurement campaigns.\nIn this paper, multiple aircraft simultaneously transmit data to the ground\nstation. We focus on the channel estimation problem at the ground station under\nhigh carrier frequency offsets and the effects of channel aging due to\nchannel's time-varying nature. For the channel estimation problem, we compare\nthe Zadoff-Chu sequences with time-division approach under varying carrier\nfrequency offset pre-compensation accuracies at the aircraft transmitter. For\nthe channel aging problem and performance evaluation of channel estimators, we\ncompute the outage probability for both the zero-forcing detector and the\nminimum mean squared error detector with successive interference cancellation.\nThe results show that the favorable channel estimator-detector combinations\ndiffer between the takeoff & landing phase and the enroute cruise phase of the\nflight, due to the distinct channel propagation characteristics of each phase."}
{"id": "2510.13591", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13591", "abs": "https://arxiv.org/abs/2510.13591", "authors": ["Nicola Fabiano"], "title": "Subject Roles in the EU AI Act: Mapping and Regulatory Implications", "comment": null, "summary": "The European Union's Artificial Intelligence Act (Regulation (EU) 2024/1689)\nestablishes the world's first comprehensive regulatory framework for AI systems\nthrough a sophisticated ecosystem of interconnected subjects defined in Article\n3. This paper provides a structured examination of the six main categories of\nactors - providers, deployers, authorized representatives, importers,\ndistributors, and product manufacturers - collectively referred to as\n\"operators\" within the regulation. Through examination of these Article 3\ndefinitions and their elaboration across the regulation's 113 articles, 180\nrecitals, and 13 annexes, we map the complete governance structure and analyze\nhow the AI Act regulates these subjects. Our analysis reveals critical\ntransformation mechanisms whereby subjects can assume different roles under\nspecific conditions, particularly through Article 25 provisions ensuring\naccountability follows control. We identify how obligations cascade through the\nsupply chain via mandatory information flows and cooperation requirements,\ncreating a distributed yet coordinated governance system. The findings\ndemonstrate how the regulation balances innovation with the protection of\nfundamental rights through risk-based obligations that scale with the\ncapabilities and deployment contexts of AI systems, providing essential\nguidance for stakeholders implementing the AI Act's requirements."}
{"id": "2510.13594", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13594", "abs": "https://arxiv.org/abs/2510.13594", "authors": ["Austin Barret", "Meng Cheng Lau"], "title": "Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots", "comment": "9 Figure. Presented at FIRA Summit 2025, Daegu, S. Korea", "summary": "The operation of humanoid robotics is an essential field of research with\nmany practical and competitive applications. Many of these systems, however, do\nnot invest heavily in developing a non-expert-centered graphical user interface\n(GUI) for operation. The focus of this research is to develop a scalable GUI\nthat is tailored to be simple and intuitive so non-expert operators can control\nthe robot through a FIRA-regulated obstacle course. Using common practices from\nuser interface development (UI) and understanding concepts described in\nhuman-robot interaction (HRI) and other related concepts, we will develop a new\ninterface with the goal of a non-expert teleoperation system."}
{"id": "2510.13595", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13595", "abs": "https://arxiv.org/abs/2510.13595", "authors": ["Ethan K. Gordon", "Bruke Baraki", "Hien Bui", "Michael Posa"], "title": "Active Tactile Exploration for Rigid Body Pose and Shape Estimation", "comment": "8 pages, 6 figures", "summary": "General robot manipulation requires the handling of previously unseen\nobjects. Learning a physically accurate model at test time can provide\nsignificant benefits in data efficiency, predictability, and reuse between\ntasks. Tactile sensing can compliment vision with its robustness to occlusion,\nbut its temporal sparsity necessitates careful online exploration to maintain\ndata efficiency. Direct contact can also cause an unrestrained object to move,\nrequiring both shape and location estimation. In this work, we propose a\nlearning and exploration framework that uses only tactile data to\nsimultaneously determine the shape and location of rigid objects with minimal\nrobot motion. We build on recent advances in contact-rich system identification\nto formulate a loss function that penalizes physical constraint violation\nwithout introducing the numerical stiffness inherent in rigid-body contact.\nOptimizing this loss, we can learn cuboid and convex polyhedral geometries with\nless than 10s of randomly collected data after first contact. Our exploration\nscheme seeks to maximize Expected Information Gain and results in significantly\nfaster learning in both simulated and real-robot experiments. More information\ncan be found at https://dairlab.github.io/activetactile"}
{"id": "2510.13599", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13599", "abs": "https://arxiv.org/abs/2510.13599", "authors": ["Jiahao Wang", "Nived Chebrolu", "Yifu Tao", "Lintong Zhang", "Ayoung Kim", "Maurice Fallon"], "title": "PlanarMesh: Building Compact 3D Meshes from LiDAR using Incremental Adaptive Resolution Reconstruction", "comment": null, "summary": "Building an online 3D LiDAR mapping system that produces a detailed surface\nreconstruction while remaining computationally efficient is a challenging task.\nIn this paper, we present PlanarMesh, a novel incremental, mesh-based LiDAR\nreconstruction system that adaptively adjusts mesh resolution to achieve\ncompact, detailed reconstructions in real-time. It introduces a new\nrepresentation, planar-mesh, which combines plane modeling and meshing to\ncapture both large surfaces and detailed geometry. The planar-mesh can be\nincrementally updated considering both local surface curvature and free-space\ninformation from sensor measurements. We employ a multi-threaded architecture\nwith a Bounding Volume Hierarchy (BVH) for efficient data storage and fast\nsearch operations, enabling real-time performance. Experimental results show\nthat our method achieves reconstruction accuracy on par with, or exceeding,\nstate-of-the-art techniques-including truncated signed distance functions,\noccupancy mapping, and voxel-based meshing-while producing smaller output file\nsizes (10 times smaller than raw input and more than 5 times smaller than\nmesh-based methods) and maintaining real-time performance (around 2 Hz for a\n64-beam sensor)."}
{"id": "2510.13616", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.13616", "abs": "https://arxiv.org/abs/2510.13616", "authors": ["Preston Fairchild", "Claudia Chen", "Xiaobo Tan"], "title": "Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor", "comment": "For supplementary videos, see\n  https://drive.google.com/drive/folders/1jol-_z6gaUfjpL1Qi7EG420usTbVSodv?usp=sharing", "summary": "Properly handling delicate produce with robotic manipulators is a major part\nof the future role of automation in agricultural harvesting and processing.\nGrasping with the correct amount of force is crucial in not only ensuring\nproper grip on the object, but also to avoid damaging or bruising the product.\nIn this work, a flexible pressure sensor that is both low cost and easy to\nfabricate is integrated with robotic grippers for working with produce of\nvarying shapes, sizes, and stiffnesses. The sensor is successfully integrated\nwith both a rigid robotic gripper, as well as a pneumatically actuated soft\nfinger. Furthermore, an algorithm is proposed for accelerated estimation of the\nsteady-state value of the sensor output based on the transient response data,\nto enable real-time applications. The sensor is shown to be effective in\nincorporating feedback to correctly grasp objects of unknown sizes and\nstiffnesses. At the same time, the sensor provides estimates for these values\nwhich can be utilized for identification of qualities such as ripeness levels\nand bruising. It is also shown to be able to provide force feedback for objects\nof variable stiffnesses. This enables future use not only for produce\nidentification, but also for tasks such as quality control and selective\ndistribution based on ripeness levels."}
{"id": "2510.13619", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13619", "abs": "https://arxiv.org/abs/2510.13619", "authors": ["Daniel Choate", "Jason Rife"], "title": "Characterizing Lidar Point-Cloud Adversities Using a Vector Field Visualization", "comment": "This is the preprint version of the paper published in: Proceedings\n  of the 37th International Technical Meeting of the Satellite Division of The\n  Institute of Navigation (ION GNSS+ 2024), September 2024 The final version is\n  available at https://doi.org/10.33012/2024.19864", "summary": "In this paper we introduce a visualization methodology to aid a human analyst\nin classifying adversity modes that impact lidar scan matching. Our methodology\nis intended for offline rather than real-time analysis. The method generates a\nvector-field plot that characterizes local discrepancies between a pair of\nregistered point clouds. The vector field plot reveals patterns that would be\ndifficult for the analyst to extract from raw point-cloud data. After\nintroducing our methodology, we apply the process to two proof-of-concept\nexamples: one a simulation study and the other a field experiment. For both\ndata sets, a human analyst was able to reason about a series of adversity\nmechanisms and iteratively remove those mechanisms from the raw data, to help\nfocus attention on progressively smaller discrepancies."}
{"id": "2510.13621", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13621", "abs": "https://arxiv.org/abs/2510.13621", "authors": ["Yuexing Hao", "Yue Huang", "Haoran Zhang", "Chenyang Zhao", "Zhenwen Liang", "Paul Pu Liang", "Yue Zhao", "Lichao Sun", "Saleh Kalantari", "Xiangliang Zhang", "Marzyeh Ghassemi"], "title": "The Role of Computing Resources in Publishing Foundation Model Research", "comment": null, "summary": "Cutting-edge research in Artificial Intelligence (AI) requires considerable\nresources, including Graphics Processing Units (GPUs), data, and human\nresources. In this paper, we evaluate of the relationship between these\nresources and the scientific advancement of foundation models (FM). We reviewed\n6517 FM papers published between 2022 to 2024, and surveyed 229 first-authors\nto the impact of computing resources on scientific output. We find that\nincreased computing is correlated with national funding allocations and\ncitations, but our findings don't observe the strong correlations with research\nenvironment (academic or industrial), domain, or study methodology. We advise\nthat individuals and institutions focus on creating shared and affordable\ncomputing opportunities to lower the entry barrier for under-resourced\nresearchers. These steps can help expand participation in FM research, foster\ndiversity of ideas and contributors, and sustain innovation and progress in AI.\nThe data will be available at: https://mit-calc.csail.mit.edu/"}
{"id": "2510.13625", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13625", "abs": "https://arxiv.org/abs/2510.13625", "authors": ["Nicolas Pottier", "Meng Cheng Lau"], "title": "A Modular Object Detection System for Humanoid Robots Using YOLO", "comment": "7 Figures, 5 tables. This article was presented at FIRA Summit 2025.\n  It will be updated for journal submission", "summary": "Within the field of robotics, computer vision remains a significant barrier\nto progress, with many tasks hindered by inefficient vision systems. This\nresearch proposes a generalized vision module leveraging YOLOv9, a\nstate-of-the-art framework optimized for computationally constrained\nenvironments like robots. The model is trained on a dataset tailored to the\nFIRA robotics Hurocup. A new vision module is implemented in ROS1 using a\nvirtual environment to enable YOLO compatibility. Performance is evaluated\nusing metrics such as frames per second (FPS) and Mean Average Precision (mAP).\nPerformance is then compared to the existing geometric framework in static and\ndynamic contexts. The YOLO model achieved comparable precision at a higher\ncomputational cost then the geometric model, while providing improved\nrobustness."}
{"id": "2510.13626", "categories": ["cs.RO", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.13626", "abs": "https://arxiv.org/abs/2510.13626", "authors": ["Senyu Fei", "Siyin Wang", "Junhao Shi", "Zihao Dai", "Jikun Cai", "Pengfang Qian", "Li Ji", "Xinzhe He", "Shiduo Zhang", "Zhaoye Fei", "Jinlan Fu", "Jingjing Gong", "Xipeng Qiu"], "title": "LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models", "comment": null, "summary": "Visual-Language-Action (VLA) models report impressive success rates on\nrobotic manipulation benchmarks, yet these results may mask fundamental\nweaknesses in robustness. We perform a systematic vulnerability analysis by\nintroducing controlled perturbations across seven dimensions: objects layout,\ncamera viewpoints, robot initial states, language instructions, light\nconditions, background textures and sensor noise. We comprehensively analyzed\nmultiple state-of-the-art models and revealed consistent brittleness beneath\napparent competence. Our analysis exposes critical weaknesses: models exhibit\nextreme sensitivity to perturbation factors, including camera viewpoints and\nrobot initial states, with performance dropping from 95% to below 30% under\nmodest perturbations. Surprisingly, models are largely insensitive to language\nvariations, with further experiments revealing that models tend to ignore\nlanguage instructions completely. Our findings challenge the assumption that\nhigh benchmark scores equate to true competency and highlight the need for\nevaluation practices that assess reliability under realistic variation."}
{"id": "2510.13644", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13644", "abs": "https://arxiv.org/abs/2510.13644", "authors": ["Michael Bosello", "Flavio Pinzarrone", "Sara Kiade", "Davide Aguiari", "Yvo Keuter", "Aaesha AlShehhi", "Gyordan Caminati", "Kei Long Wong", "Ka Seng Chou", "Junaid Halepota", "Fares Alneyadi", "Jacopo Panerati", "Giovanni Pau"], "title": "On Your Own: Pro-level Autonomous Drone Racing in Uninstrumented Arenas", "comment": null, "summary": "Drone technology is proliferating in many industries, including agriculture,\nlogistics, defense, infrastructure, and environmental monitoring. Vision-based\nautonomy is one of its key enablers, particularly for real-world applications.\nThis is essential for operating in novel, unstructured environments where\ntraditional navigation methods may be unavailable. Autonomous drone racing has\nbecome the de facto benchmark for such systems. State-of-the-art research has\nshown that autonomous systems can surpass human-level performance in racing\narenas. However, direct applicability to commercial and field operations is\nstill limited as current systems are often trained and evaluated in highly\ncontrolled environments. In our contribution, the system's capabilities are\nanalyzed within a controlled environment -- where external tracking is\navailable for ground-truth comparison -- but also demonstrated in a\nchallenging, uninstrumented environment -- where ground-truth measurements were\nnever available. We show that our approach can match the performance of\nprofessional human pilots in both scenarios. We also publicly release the data\nfrom the flights carried out by our approach and a world-class human pilot."}
{"id": "2510.13653", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13653", "abs": "https://arxiv.org/abs/2510.13653", "authors": ["Yoshua Bengio", "Stephen Clare", "Carina Prunkl", "Shalaleh Rismani", "Maksym Andriushchenko", "Ben Bucknall", "Philip Fox", "Tiancheng Hu", "Cameron Jones", "Sam Manning", "Nestor Maslej", "Vasilios Mavroudis", "Conor McGlynn", "Malcolm Murray", "Charlotte Stix", "Lucia Velasco", "Nicole Wheeler", "Daniel Privitera", "Sören Mindermann", "Daron Acemoglu", "Thomas G. Dietterich", "Fredrik Heintz", "Geoffrey Hinton", "Nick Jennings", "Susan Leavy", "Teresa Ludermir", "Vidushi Marda", "Helen Margetts", "John McDermid", "Jane Munga", "Arvind Narayanan", "Alondra Nelson", "Clara Neppel", "Gopal Ramchurn", "Stuart Russell", "Marietje Schaake", "Bernhard Schölkopf", "Alavaro Soto", "Lee Tiedrich", "Gaël Varoquaux", "Andrew Yao", "Ya-Qin Zhang", "Leandro Aguirre", "Olubunmi Ajala", "Fahad Albalawi Noora AlMalek", "Christian Busch", "André Carvalho", "Jonathan Collas", "Amandeep Gill", "Ahmet Hatip", "Juha Heikkilä", "Chris Johnson", "Gill Jolly", "Ziv Katzir", "Mary Kerema", "Hiroaki Kitano", "Antonio Krüger", "Aoife McLysaght", "Oleksii Molchanovskyi", "Andrea Monti", "Kyoung Mu Lee", "Mona Nemer", "Nuria Oliver", "Raquel Pezoa", "Audrey Plonk", "José Portillo", "Balaraman Ravindran", "Hammam Riza", "Crystal Rugege", "Haroon Sheikh", "Denise Wong", "Yi Zeng", "Liming Zhu"], "title": "International AI Safety Report 2025: First Key Update: Capabilities and Risk Implications", "comment": null, "summary": "Since the publication of the first International AI Safety Report, AI\ncapabilities have continued to improve across key domains. New training\ntechniques that teach AI systems to reason step-by-step and inference-time\nenhancements have primarily driven these advances, rather than simply training\nlarger models. As a result, general-purpose AI systems can solve more complex\nproblems in a range of domains, from scientific research to software\ndevelopment. Their performance on benchmarks that measure performance in\ncoding, mathematics, and answering expert-level science questions has continued\nto improve, though reliability challenges persist, with systems excelling on\nsome tasks while failing completely on others. These capability improvements\nalso have implications for multiple risks, including risks from biological\nweapons and cyber attacks. Finally, they pose new challenges for monitoring and\ncontrollability. This update examines how AI capabilities have improved since\nthe first Report, then focuses on key risk areas where substantial new evidence\nwarrants updated assessments."}
{"id": "2510.13682", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13682", "abs": "https://arxiv.org/abs/2510.13682", "authors": ["Jiayang Li", "Qingyu Zhang", "Sohmyung Ha", "Dai Jiang", "Andreas Demosthenous", "Yu Wu"], "title": "A 0.62 μW/sensor 82 fps Time-to-Digital Impedance Measurement IC with Unified Excitation/Readout Front-end for Large-Scale Piezo-Resistive Sensor Array", "comment": null, "summary": "This paper presents a fast impedance measurement IC for large-scale\npiezo-resistive sensor array. It features a unified differential\ntime-to-digital demodulation architecture that readout impedance directly\nthrough the excitation circuit. The proposed pre-saturation adaptive bias\ntechnique further improves power efficiency. The chip scans 253 sensors in 12.2\nms (82 fps) at 125 kHz, consuming 158 {\\mu}W (7.5 nJ/sensor). With loads from\n20 {\\Omega} to 500 k{\\Omega}, it achieves 0.5% error and up to 71.1 dB SNR."}
{"id": "2510.13686", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13686", "abs": "https://arxiv.org/abs/2510.13686", "authors": ["Miana Smith", "Paul Arthur Richard", "Alexander Htet Kyaw", "Neil Gershenfeld"], "title": "Hierarchical Discrete Lattice Assembly: An Approach for the Digital Fabrication of Scalable Macroscale Structures", "comment": "In ACM Symposium on Computational Fabrication (SCF '25), November\n  20-21, 2025, Cambridge, MA, USA. ACM, New York, NY, USA, 15 pages", "summary": "Although digital fabrication processes at the desktop scale have become\nproficient and prolific, systems aimed at producing larger-scale structures are\nstill typically complex, expensive, and unreliable. In this work, we present an\napproach for the fabrication of scalable macroscale structures using simple\nrobots and interlocking lattice building blocks. A target structure is first\nvoxelized so that it can be populated with an architected lattice. These voxels\nare then grouped into larger interconnected blocks, which are produced using\nstandard digital fabrication processes, leveraging their capability to produce\nhighly complex geometries at a small scale. These blocks, on the size scale of\ntens of centimeters, are then fed to mobile relative robots that are able to\ntraverse over the structure and place new blocks to form structures on the\nmeter scale. To facilitate the assembly of large structures, we introduce a\nlive digital twin simulation tool for controlling and coordinating assembly\nrobots that enables both global planning for a target structure and live user\ndesign, interaction, or intervention. To improve assembly throughput, we\nintroduce a new modular assembly robot, designed for hierarchical voxel\nhandling. We validate this system by demonstrating the voxelization,\nhierarchical blocking, path planning, and robotic fabrication of a set of\nmeter-scale objects."}
{"id": "2510.13691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13691", "abs": "https://arxiv.org/abs/2510.13691", "authors": ["Cecilia Di Florio", "Huimin Dong", "Antonino Rotolo"], "title": "A Modal Logic for Temporal and Jurisdictional Classifier Models", "comment": "18 pages, 2 figures. Extended version of a short paper accepted at\n  PRIMA 2025. This is the authors' version of the work. It is posted here for\n  your personal use", "summary": "Logic-based models can be used to build verification tools for machine\nlearning classifiers employed in the legal field. ML classifiers predict the\noutcomes of new cases based on previous ones, thereby performing a form of\ncase-based reasoning (CBR). In this paper, we introduce a modal logic of\nclassifiers designed to formally capture legal CBR. We incorporate principles\nfor resolving conflicts between precedents, by introducing into the logic the\ntemporal dimension of cases and the hierarchy of courts within the legal\nsystem."}
{"id": "2510.13709", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13709", "abs": "https://arxiv.org/abs/2510.13709", "authors": ["Evan Ellis", "Vivek Myers", "Jens Tuyls", "Sergey Levine", "Anca Dragan", "Benjamin Eysenbach"], "title": "Training LLM Agents to Empower Humans", "comment": null, "summary": "Assistive agents should not only take actions on behalf of a human, but also\nstep out of the way and cede control when there are important decisions to be\nmade. However, current methods for building assistive agents, whether via\nmimicking expert humans or via RL finetuning on an inferred reward, often\nencourage agents to complete tasks on their own rather than truly assisting the\nhuman attain their objectives. Additionally, these methods often require costly\nexplicit human feedback to provide a training signal. We propose a new approach\nto tuning assistive language models based on maximizing the human's\nempowerment, their ability to effect desired changes in the environment. Our\nempowerment-maximizing method, Empower, only requires offline text data,\nproviding a self-supervised method for fine-tuning language models to better\nassist humans. To study the efficacy of our approach, we conducted an 18-person\nuser study comparing our empowerment assistant with a strong baseline.\nParticipants preferred our assistant 78% of the time (p=0.015), with a 31%\nhigher acceptance rate and 38% fewer suggestions. Additionally, we introduce a\nnew environment for evaluating multi-turn code assistance using simulated\nhumans. Using this environment, we show that agents trained with Empower\nincrease the success rate of a simulated human programmer on challenging coding\nquestions by an average of 192% over an SFT baseline. With this empowerment\nobjective, we provide a framework for useful aligned AI agents at scale using\nonly offline data without the need for any additional human feedback or\nverifiable rewards."}
{"id": "2510.13727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13727", "abs": "https://arxiv.org/abs/2510.13727", "authors": ["Ravi Pandya", "Madison Bland", "Duy P. Nguyen", "Changliu Liu", "Jaime Fernández Fisac", "Andrea Bajcsy"], "title": "From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails", "comment": null, "summary": "Generative AI systems are increasingly assisting and acting on behalf of end\nusers in practical settings, from digital shopping assistants to\nnext-generation autonomous cars. In this context, safety is no longer about\nblocking harmful content, but about preempting downstream hazards like\nfinancial or physical harm. Yet, most AI guardrails continue to rely on output\nclassification based on labeled datasets and human-specified criteria,making\nthem brittle to new hazardous situations. Even when unsafe conditions are\nflagged, this detection offers no path to recovery: typically, the AI system\nsimply refuses to act--which is not always a safe choice. In this work, we\nargue that agentic AI safety is fundamentally a sequential decision problem:\nharmful outcomes arise from the AI system's continually evolving interactions\nand their downstream consequences on the world. We formalize this through the\nlens of safety-critical control theory, but within the AI model's latent\nrepresentation of the world. This enables us to build predictive guardrails\nthat (i) monitor an AI system's outputs (actions) in real time and (ii)\nproactively correct risky outputs to safe ones, all in a model-agnostic manner\nso the same guardrail can be wrapped around any AI model. We also offer a\npractical training recipe for computing such guardrails at scale via\nsafety-critical reinforcement learning. Our experiments in simulated driving\nand e-commerce settings demonstrate that control-theoretic guardrails can\nreliably steer LLM agents clear of catastrophic outcomes (from collisions to\nbankruptcy) while preserving task performance, offering a principled dynamic\nalternative to today's flag-and-block guardrails."}
{"id": "2510.13744", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13744", "abs": "https://arxiv.org/abs/2510.13744", "authors": ["Shrey Pandit", "Austin Xu", "Xuan-Phi Nguyen", "Yifei Ming", "Caiming Xiong", "Shafiq Joty"], "title": "Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math", "comment": "21 pages, 8 figures, 5 tables", "summary": "Large language model (LLM)-based reasoning systems have recently achieved\ngold medal-level performance in the IMO 2025 competition, writing mathematical\nproofs where, to receive full credit, each step must be not only correct but\nalso sufficiently supported. To train LLM-based reasoners in such challenging,\nopen-ended settings, strong verifiers capable of catching step-level mistakes\nare necessary prerequisites. We introduce Hard2Verify, a human-annotated,\nstep-level verification benchmark produced with over 500 hours of human labor.\nHard2Verify is designed to rigorously assess step-level verifiers at the\nfrontier: Verifiers must provide step-level annotations or identify the first\nerror in responses generated by frontier LLMs for very recent, challenging, and\nopen-ended math questions. We evaluate 29 generative critics and process reward\nmodels, demonstrating that, beyond a few standouts, open-source verifiers lag\nclosed source models. We subsequently analyze what drives poor performance in\nstep-level verification, the impacts of scaling verifier compute, as well as\nfundamental questions such as self-verification and verification-generation\ndynamics."}
{"id": "2510.13778", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.13778", "abs": "https://arxiv.org/abs/2510.13778", "authors": ["Xinyi Chen", "Yilun Chen", "Yanwei Fu", "Ning Gao", "Jiaya Jia", "Weiyang Jin", "Hao Li", "Yao Mu", "Jiangmiao Pang", "Yu Qiao", "Yang Tian", "Bin Wang", "Bolun Wang", "Fangjing Wang", "Hanqing Wang", "Tai Wang", "Ziqin Wang", "Xueyuan Wei", "Chao Wu", "Shuai Yang", "Jinhui Ye", "Junqiu Yu", "Jia Zeng", "Jingjing Zhang", "Jinyu Zhang", "Shi Zhang", "Feng Zheng", "Bowen Zhou", "Yangkun Zhu"], "title": "InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy", "comment": "Technical report", "summary": "We introduce InternVLA-M1, a unified framework for spatial grounding and\nrobot control that advances instruction-following robots toward scalable,\ngeneral-purpose intelligence. Its core idea is spatially guided\nvision-language-action training, where spatial grounding serves as the critical\nlink between instructions and robot actions. InternVLA-M1 employs a two-stage\npipeline: (i) spatial grounding pre-training on over 2.3M spatial reasoning\ndata to determine ``where to act'' by aligning instructions with visual,\nembodiment-agnostic positions, and (ii) spatially guided action post-training\nto decide ``how to act'' by generating embodiment-aware actions through\nplug-and-play spatial prompting. This spatially guided training recipe yields\nconsistent gains: InternVLA-M1 outperforms its variant without spatial guidance\nby +14.6% on SimplerEnv Google Robot, +17% on WidowX, and +4.3% on LIBERO\nFranka, while demonstrating stronger spatial reasoning capability in box,\npoint, and trace prediction. To further scale instruction following, we built a\nsimulation engine to collect 244K generalizable pick-and-place episodes,\nenabling a 6.2% average improvement across 200 tasks and 3K+ objects. In\nreal-world clustered pick-and-place, InternVLA-M1 improved by 7.3%, and with\nsynthetic co-training, achieved +20.6% on unseen objects and novel\nconfigurations. Moreover, in long-horizon reasoning-intensive scenarios, it\nsurpassed existing works by over 10%. These results highlight spatially guided\ntraining as a unifying principle for scalable and resilient generalist robots.\nCode and models are available at\nhttps://github.com/InternRobotics/InternVLA-M1."}
{"id": "2510.13369", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.13369", "abs": "https://arxiv.org/abs/2510.13369", "authors": ["Jacob Schaal"], "title": "A theory-based AI automation exposure index: Applying Moravec's Paradox to the US labor market", "comment": null, "summary": "This paper develops a theory-driven automation exposure index based on\nMoravec's Paradox. Scoring 19,000 O*NET tasks on performance variance, tacit\nknowledge, data abundance, and algorithmic gaps reveals that management, STEM,\nand sciences occupations show the highest exposure. In contrast, maintenance,\nagriculture, and construction show the lowest. The positive relationship\nbetween wages and exposure challenges the notion of skill-biased technological\nchange if AI substitutes for workers. At the same time, tacit knowledge\nexhibits a positive relationship with wages consistent with seniority-biased\ntechnological change. This index identifies fundamental automatability rather\nthan current capabilities, while also validating the AI annotation method\npioneered by Eloundou et al. (2024) with a correlation of 0.72. The\nnon-positive relationship with pre-LLM indices suggests a paradigm shift in\nautomation patterns."}
