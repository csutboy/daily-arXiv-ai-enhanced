<div id=toc></div>

# Table of Contents

- [cs.ET](#cs.ET) [Total: 1]
- [cs.AI](#cs.AI) [Total: 38]
- [stat.AP](#stat.AP) [Total: 3]
- [cs.SI](#cs.SI) [Total: 1]
- [econ.GN](#econ.GN) [Total: 2]
- [cs.CY](#cs.CY) [Total: 8]
- [cs.RO](#cs.RO) [Total: 28]
- [eess.SY](#eess.SY) [Total: 21]


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [1] [Building Network Digital Twins Part II: Real-Time Adaptive PID for Enhanced State Synchronization](https://arxiv.org/abs/2510.20753)
*John Sengendo,Fabrizio Granelli*

Main category: cs.ET

TL;DR: 本文提出了一种集成自适应PID控制器的框架，用于动态改善网络数字孪生与物理网络之间的实时流量同步问题。


<details>
  <summary>Details</summary>
Motivation: 随着移动网络向异构化和动态化发展，网络数字孪生需要与物理网络保持实时同步，但大规模设备连接使得流量复制和实时同步面临挑战。

Method: 实现了一个集成自适应PID控制器的框架，通过交互式用户界面来动态改善同步性能。

Result: 增强方法展示了实时流量同步的改进效果。

Conclusion: 自适应PID控制器框架能够有效提升网络数字孪生与物理网络之间的实时同步能力。

Abstract: As we evolve towards more heterogeneous and cutting-edge mobile networks,
Network Digital Twins (NDTs) are proving to be a promising paradigm in solving
challenges faced by network operators, as they give a possibility of
replicating the physical network operations and testing scenarios separately
without interfering with the live network. However, with mobile networks
becoming increasingly dynamic and heterogeneous due to massive device
connectivity, replicating traffic and having NDTs synchronized in real-time
with the physical network remains a challenge, thus necessitating the need to
develop real-time adaptive mechanisms to bridge this gap. In this part II of
our work, we implement a novel framework that integrates an adaptive
Proportional-Integral-Derivative (PID) controller to dynamically improve
synchronization. Additionally, through an interactive user interface, results
of our enhanced approach demonstrate an improvement in real-time traffic
synchronization.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem](https://arxiv.org/abs/2510.19835)
*Max B. Zhao,Fei Li*

Main category: cs.AI

TL;DR: 提出一种量子启发算法，使用矩阵乘积态(MPS)和离散驱动调度来解决QUBO问题，在数独和MaxCut问题上表现出色，能可靠找到全局最优解。


<details>
  <summary>Details</summary>
Motivation: 解决二次无约束二进制优化(QUBO)问题，该问题在数学上等同于寻找伊辛自旋玻璃哈密顿量的基态，需要一种可扩展且能可靠找到全局最优解的方法。

Method: 使用矩阵乘积态(MPS)紧凑表示自旋构型的大叠加，采用离散驱动调度引导MPS向基态演化，结合驱动哈密顿量和问题哈密顿量实现自旋翻转和量子隧穿，通过DMRG方法迭代最小化系统能量。

Result: 在超过200个伊辛自旋的数独问题和Biq Mac库中最多251个节点、3265条边的MaxCut问题上，算法都能可靠识别全局最小值，而非仅接近最优解。

Conclusion: 该量子启发方法具有可扩展性、通用性和适用于工业规模QUBO应用的优势。

Abstract: We propose and evaluate a quantum-inspired algorithm for solving Quadratic
Unconstrained Binary Optimization (QUBO) problems, which are mathematically
equivalent to finding ground states of Ising spin-glass Hamiltonians. The
algorithm employs Matrix Product States (MPS) to compactly represent large
superpositions of spin configurations and utilizes a discrete driving schedule
to guide the MPS toward the ground state. At each step, a driver Hamiltonian --
incorporating a transverse magnetic field -- is combined with the problem
Hamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is
updated using the standard Density Matrix Renormalization Group (DMRG) method,
which iteratively minimizes the system's energy via multiple sweeps across the
spin chain. Despite its heuristic nature, the algorithm reliably identifies
global minima, not merely near-optimal solutions, across diverse QUBO
instances. We first demonstrate its effectiveness on intermediate-level Sudoku
puzzles from publicly available sources, involving over $200$ Ising spins with
long-range couplings dictated by constraint satisfaction. We then apply the
algorithm to MaxCut problems from the Biq Mac library, successfully solving
instances with up to $251$ nodes and $3,265$ edges. We discuss the advantages
of this quantum-inspired approach, including its scalability, generalizability,
and suitability for industrial-scale QUBO applications.

</details>


### [3] [Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis](https://arxiv.org/abs/2510.19836)
*Eliseo Curcio*

Main category: cs.AI

TL;DR: 该研究提出了分析可靠性基准(ARB)，这是首个用于量化能源系统分析中大型语言模型推理可靠性的标准化框架，包含五个子指标，并在确定性、概率性和认知性场景下评估了四个前沿模型。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能在能源领域的验证实践主要关注预测准确性或计算效率，而缺乏对分析结论逻辑完整性的标准化测试框架。

Method: 开发了分析可靠性基准(ARB)，整合了准确性、推理可靠性、不确定性约束、政策一致性和透明度五个子指标，使用开放技术经济数据集在确定性、概率性和认知性场景下评估模型性能。

Result: GPT-4/5和Claude 4.5 Sonnet实现了稳定且符合政策的推理(分析可靠性指数大于90)，Gemini 2.5 Pro表现中等稳定，而Llama 3 70B未达到专业阈值。统计验证确认这些差异显著且可重现。

Conclusion: ARB建立了能源文献中首个验证人工智能系统中因果、概率和政策驱动推理的定量方法，为全球能源转型中可信赖和透明的分析应用提供了参考框架。

Abstract: Artificial intelligence and machine learning are increasingly used for
forecasting, optimization, and policy design in the energy sector, yet no
standardized framework exists to evaluate whether these systems reason
correctly. Current validation practices focus on predictive accuracy or
computational efficiency, leaving the logical integrity of analytical
conclusions untested. This study introduces the Analytical Reliability
Benchmark (ARB), a reproducible framework that quantifies reasoning reliability
in large language models applied to energy system analysis. The benchmark
integrates five submetrics: accuracy, reasoning reliability, uncertainty
discipline, policy consistency, and transparency, and evaluates model
performance across deterministic, probabilistic, and epistemic scenarios using
open technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four
frontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were
tested under identical factual and regulatory conditions. Results show that
reasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5
Sonnet achieved consistent and policy-compliant reasoning (Analytical
Reliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate
stability, and Llama 3 70B remained below professional thresholds. Statistical
validation confirmed that these differences are significant and reproducible.
The ARB establishes the first quantitative method in the energy literature for
verifying causal, probabilistic, and policy-driven reasoning in artificial
intelligence systems, providing a reference framework for trustworthy and
transparent analytical applications in the global energy transition.

</details>


### [4] [Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory](https://arxiv.org/abs/2510.19838)
*Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury*

Main category: cs.AI

TL;DR: Branch-and-Browse是一个细粒度的网页代理框架，通过树状结构探索、网页状态回放和页面动作记忆，显著提升了LLM网页代理的推理深度和执行效率。


<details>
  <summary>Details</summary>
Motivation: 现有的网页代理方法在推理深度和效率上存在局限：线性方法无法进行多步推理且缺乏有效回溯，其他搜索策略则粒度粗糙且计算成本高。

Method: 采用显式子任务管理和树状结构探索实现可控多分支推理，通过网页状态回放和后台推理引导探索，并利用页面动作记忆在会话内外共享探索动作。

Result: 在WebArena基准测试中，任务成功率达到35.8%，执行时间相比最先进方法减少高达40.4%。

Conclusion: Branch-and-Browse是一个可靠且高效的基于LLM的网页代理框架，在推理深度和执行效率方面表现出色。

Abstract: Autonomous web agents powered by large language models (LLMs) show strong
potential for performing goal-oriented tasks such as information retrieval,
report generation, and online transactions. These agents mark a key step toward
practical embodied reasoning in open web environments. However, existing
approaches remain limited in reasoning depth and efficiency: vanilla linear
methods fail at multi-step reasoning and lack effective backtracking, while
other search strategies are coarse-grained and computationally costly. We
introduce Branch-and-Browse, a fine-grained web agent framework that unifies
structured reasoning-acting, contextual memory, and efficient execution. It (i)
employs explicit subtask management with tree-structured exploration for
controllable multi-branch reasoning, (ii) bootstraps exploration through
efficient web state replay with background reasoning, and (iii) leverages a
page action memory to share explored actions within and across sessions. On the
WebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\%
and reduces execution time by up to 40.4\% relative to state-of-the-art
methods. These results demonstrate that Branch-and-Browse is a reliable and
efficient framework for LLM-based web agents.

</details>


### [5] [DAG-Math: Graph-Guided Mathematical Reasoning in LLMs](https://arxiv.org/abs/2510.19842)
*Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu*

Main category: cs.AI

TL;DR: 该论文提出了一个基于有向无环图(DAG)的框架来评估LLMs在数学推理中的逻辑一致性，超越了传统的PASS@k指标。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法区分LLMs在数学问题上的成功是源于搜索、机械程序还是规则一致推理，需要更精确的推理能力评估框架。

Method: 将思维链建模为基于规则的随机过程，引入逻辑紧密度指标，并构建DAG-MATH CoT格式的基准测试。

Result: 在标准数学推理数据集上发现，即使PASS@k指标相似，不同LLM家族在推理保真度上存在显著差异。

Conclusion: 该框架在自由形式思维链和形式证明系统之间提供了平衡，为LLMs推理评估提供了可操作的诊断工具。

Abstract: Large Language Models (LLMs) demonstrate strong performance on mathematical
problems when prompted with Chain-of-Thought (CoT), yet it remains unclear
whether this success stems from search, rote procedures, or rule-consistent
reasoning. To address this, we propose modeling CoT as a certain rule-based
stochastic process over directed acyclic graphs (DAGs), where nodes represent
intermediate derivation states and edges encode rule applications. Within this
framework, we introduce logical closeness, a metric that quantifies how well a
model's CoT trajectory (i.e., the LLM's final output) adheres to the DAG
structure, providing evaluation beyond classical PASS@k metrics. Building on
this, we introduce the DAG-MATH CoT format and construct a benchmark that
guides LLMs to generate CoT trajectories in this format, thereby enabling the
evaluation of their reasoning ability under our framework. Across standard
mathematical reasoning datasets, our analysis uncovers statistically
significant differences in reasoning fidelity among representative LLM
families-even when PASS@k is comparable-highlighting gaps between final-answer
accuracy and rule-consistent derivation. Our framework provides a balance
between free-form CoT and formal proofs systems, offering actionable
diagnostics for LLMs reasoning evaluation. Our benchmark and code are available
at: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.

</details>


### [6] [Surfer 2: The Next Generation of Cross-Platform Computer Use Agents](https://arxiv.org/abs/2510.19949)
*Mathieu Andreux,Märt Bakler,Yanael Barbier,Hamza Ben Chekroun,Emilien Biré,Antoine Bonnet,Riaz Bordie,Nathan Bout,Matthias Brunel,Aleix Cambray,Pierre-Louis Cedoz,Antoine Chassang,Gautier Cloix,Ethan Connelly,Alexandra Constantinou,Ramzi De Coster,Hubert de la Jonquiere,Aurélien Delfosse,Maxime Delpit,Alexis Deprez,Augustin Derupti,Mathieu Diaz,Shannon D'Souza,Julie Dujardin,Abai Edmund,Michael Eickenberg,Armand Fatalot,Wissem Felissi,Isaac Herring,Xavier Koegler,Erwan Le Jumeau de Kergaradec,Aurélien Lac,Maxime Langevin,Corentin Lauverjat,Antonio Loison,Avshalom Manevich,Axel Moyal,Axel Nguyen Kerbel,Marinela Parovic,Julien Revelle,Guillaume Richard,Mats Richter,Ronan Riochet,María Santos,Romain Savidan,Laurent Sifre,Maxime Theillard,Marc Thibault,Ivan Valentini,Tony Wu,Laura Yie,Kai Yuan,Jevgenij Zubovskij*

Main category: cs.AI

TL;DR: Surfer 2是一个纯视觉观察的统一架构，在Web、桌面和移动环境中实现最先进性能，通过分层上下文管理、解耦规划与执行以及自适应恢复的自验证机制，在多个基准测试中超越所有先前系统。


<details>
  <summary>Details</summary>
Motivation: 解决现有系统依赖环境特定接口限制跨平台部署的问题，构建能够在Web、桌面和移动环境中通用的智能体。

Method: 集成分层上下文管理、解耦规划与执行、带自适应恢复的自验证机制，仅从视觉观察操作，无需任务特定微调。

Result: 在WebVoyager上达到97.1%准确率，WebArena 69.6%，OSWorld 60.1%，AndroidWorld 87.1%，多尝试时在所有基准测试中超越人类表现。

Conclusion: 系统化编排能放大基础模型能力，通过纯视觉交互实现通用计算机控制，但需要下一代视觉语言模型来实现帕累托最优的成本效益。

Abstract: Building agents that generalize across web, desktop, and mobile environments
remains an open challenge, as prior systems rely on environment-specific
interfaces that limit cross-platform deployment. We introduce Surfer 2, a
unified architecture operating purely from visual observations that achieves
state-of-the-art performance across all three environments. Surfer 2 integrates
hierarchical context management, decoupled planning and execution, and
self-verification with adaptive recovery, enabling reliable operation over long
task horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on
WebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior
systems without task-specific fine-tuning. With multiple attempts, Surfer 2
exceeds human performance on all benchmarks. These results demonstrate that
systematic orchestration amplifies foundation model capabilities and enables
general-purpose computer control through visual interaction alone, while
calling for a next-generation vision language model to achieve Pareto-optimal
cost-efficiency.

</details>


### [7] [RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs](https://arxiv.org/abs/2510.19954)
*Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski*

Main category: cs.AI

TL;DR: RELATE是一个与模式无关的图神经网络特征编码器，使用共享的模态特定编码器处理多模态节点属性，通过交叉注意力聚合为固定大小的节点表示，在保持性能的同时大幅减少参数数量。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络需要为每种节点类型和特征列设计特定的特征编码器，这限制了可扩展性和参数共享，无法适应不同模式的数据。

Method: 使用共享的模态特定编码器处理分类、数值、文本和时间属性，然后通过Perceiver风格的交叉注意力模块将特征聚合为固定大小的节点表示。

Result: 在RelBench基准测试中，RELATE与ReLGNN和HGT配合使用，性能仅比模式特定编码器低3%，同时参数数量减少了5倍。

Conclusion: RELATE支持不同的数据模式，使通用图神经网络能够进行多数据集预训练，为关系图数据的基础模型铺平了道路。

Abstract: Relational multi-table data is common in domains such as e-commerce,
healthcare, and scientific research, and can be naturally represented as
heterogeneous temporal graphs with multi-modal node attributes. Existing graph
neural networks (GNNs) rely on schema-specific feature encoders, requiring
separate modules for each node type and feature column, which hinders
scalability and parameter sharing. We introduce RELATE (Relational Encoder for
Latent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature
encoder that can be used with any general purpose GNN. RELATE employs shared
modality-specific encoders for categorical, numerical, textual, and temporal
attributes, followed by a Perceiver-style cross-attention module that
aggregates features into a fixed-size, permutation-invariant node
representation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark,
where it achieves performance within 3% of schema-specific encoders while
reducing parameter counts by up to 5x. This design supports varying schemas and
enables multi-dataset pretraining for general-purpose GNNs, paving the way
toward foundation models for relational graph data.

</details>


### [8] [A new wave of vehicle insurance fraud fueled by generative AI](https://arxiv.org/abs/2510.19957)
*Amir Hever,Itai Orr*

Main category: cs.AI

TL;DR: 生成式AI正在加剧保险欺诈问题，使大规模快速伪造事故证据变得更容易。保险公司部署了AI检测工具，但存在误报漏报问题。本文提出了UVeye分层解决方案来检测和威慑这种新型欺诈。


<details>
  <summary>Details</summary>
Motivation: 保险欺诈每年造成数百亿美元损失，传统欺诈手段包括伪造事故、夸大损失等。生成式AI和深度伪造技术的出现使欺诈者能轻松制造逼真的事故照片、损坏证据和假身份，加剧了保险欺诈问题。

Method: 保险公司开始部署基于AI的深度伪造检测软件和增强验证流程来检测AI驱动的欺诈。本文提出了UVeye分层解决方案，代表检测和威慑这种新型欺诈能力的重大进步。

Result: 当前的缓解策略面临显著限制，检测工具存在误报和漏报问题，复杂的欺诈者不断调整策略来规避自动检查。生成式AI与检测技术之间的猫鼠游戏仍在继续。

Conclusion: 由于生成式AI与检测技术之间的持续竞争，加上保险公司的资源和成本障碍，打击AI驱动的保险欺诈仍然是一个持续挑战。UVeye分层解决方案代表了应对这一挑战的重要进展。

Abstract: Generative AI is supercharging insurance fraud by making it easier to falsify
accident evidence at scale and in rapid time. Insurance fraud is a pervasive
and costly problem, amounting to tens of billions of dollars in losses each
year. In the vehicle insurance sector, fraud schemes have traditionally
involved staged accidents, exaggerated damage, or forged documents. The rise of
generative AI, including deepfake image and video generation, has introduced
new methods for committing fraud at scale. Fraudsters can now fabricate highly
realistic crash photos, damage evidence, and even fake identities or documents
with minimal effort, exploiting AI tools to bolster false insurance claims.
Insurers have begun deploying countermeasures such as AI-based deepfake
detection software and enhanced verification processes to detect and mitigate
these AI-driven scams. However, current mitigation strategies face significant
limitations. Detection tools can suffer from false positives and negatives, and
sophisticated fraudsters continuously adapt their tactics to evade automated
checks. This cat-and-mouse arms race between generative AI and detection
technology, combined with resource and cost barriers for insurers, means that
combating AI-enabled insurance fraud remains an ongoing challenge. In this
white paper, we present UVeye layered solution for vehicle fraud, representing
a major leap forward in the ability to detect, mitigate and deter this new wave
of fraud.

</details>


### [9] [AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits](https://arxiv.org/abs/2510.19964)
*Nitsa J Herzog,Rejwan Bin Sulaiman,David J Herzog,Rose Fong*

Main category: cs.AI

TL;DR: 该研究使用机器学习模型通过领导力人格特质预测学术成功，基于129名环境工程硕士生的5种领导力人格测试数据，随机森林分类器达到87.50%的准确率。


<details>
  <summary>Details</summary>
Motivation: 探索AI技术在个性化学习中的潜力，通过领导力人格特质预测学术表现，为早期识别学生优劣势和选择个性化学习策略提供机会。

Method: 收集129名硕士生的5种领导力人格测试数据（23个特征），结合平均成绩，使用相关性分析和7种机器学习算法（SVM、LR、KNN、DT、GB、RF、XGBoost、LightGBM）进行建模。

Result: 随机森林分类器表现最佳，包含17个人格特征和领导力标记的模型准确率达87.50%，不包含该特征的模型准确率为85.71%。

Conclusion: 研究证明领导力人格特质可以有效预测学术成功，为早期识别学生优劣势和个性化学习策略选择提供了有效方法。

Abstract: The study explores the potential of AI technologies in personalized learning,
suggesting the prediction of academic success through leadership personality
traits and machine learning modelling. The primary data were obtained from 129
master's students in the Environmental Engineering Department, who underwent
five leadership personality tests with 23 characteristics. Students used
self-assessment tools that included Personality Insight, Workplace Culture,
Motivation at Work, Management Skills, and Emotion Control tests. The test
results were combined with the average grade obtained from academic reports.
The study employed exploratory data analysis and correlation analysis. Feature
selection utilized Pearson correlation coefficients of personality traits. The
average grades were separated into three categories: fail, pass, and excellent.
The modelling process was performed by tuning seven ML algorithms, such as SVM,
LR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance
was achieved with the RF classifier, which yielded an accuracy of 87.50% for
the model incorporating 17 personality trait features and the leadership mark
feature, and an accuracy of 85.71% for the model excluding this feature. In
this way, the study offers an additional opportunity to identify students'
strengths and weaknesses at an early stage of their education process and
select the most suitable strategies for personalized learning.

</details>


### [10] [LLMs can hide text in other text of the same length.ipynb](https://arxiv.org/abs/2510.20075)
*Antonio Norelli,Michael Bronstein*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A meaningful text can be hidden inside another, completely different yet
still coherent and plausible, text of the same length. For example, a tweet
containing a harsh political critique could be embedded in a tweet that
celebrates the same political leader, or an ordinary product review could
conceal a secret manuscript. This uncanny state of affairs is now possible
thanks to Large Language Models, and in this paper we present a simple and
efficient protocol to achieve it. We show that even modest 8-billion-parameter
open-source LLMs are sufficient to obtain high-quality results, and a message
as long as this abstract can be encoded and decoded locally on a laptop in
seconds. The existence of such a protocol demonstrates a radical decoupling of
text from authorial intent, further eroding trust in written communication,
already shaken by the rise of LLM chatbots. We illustrate this with a concrete
scenario: a company could covertly deploy an unfiltered LLM by encoding its
answers within the compliant responses of a safe model. This possibility raises
urgent questions for AI safety and challenges our understanding of what it
means for a Large Language Model to know something.

</details>


### [11] [AI PB: A Grounded Generative Agent for Personalized Investment Insights](https://arxiv.org/abs/2510.20099)
*Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh*

Main category: cs.AI

TL;DR: AI PB是一个在零售金融领域部署的生产级生成式代理系统，能够主动生成基于事实、合规且个性化的投资洞察，采用组件化编排、混合检索和多阶段推荐机制。


<details>
  <summary>Details</summary>
Motivation: 传统被动式聊天机器人无法满足金融领域对主动、合规、个性化投资洞察的需求，需要开发能够在高风险金融环境中提供可信AI见解的系统。

Method: 采用组件化编排层进行确定性路由决策，结合OpenSearch和金融领域嵌入模型的混合检索管道，以及结合规则启发式、序列行为建模和上下文多臂赌博机的多阶段推荐机制。

Result: 系统在24个NVIDIA H100 GPU上通过Docker Swarm和vLLM完全在本地部署，符合韩国金融监管要求，通过人工QA和系统指标验证了其可靠性。

Conclusion: 通过显式路由和分层安全机制的基于事实的生成，可以在高风险金融领域提供可信的AI洞察。

Abstract: We present AI PB, a production-scale generative agent deployed in real retail
finance. Unlike reactive chatbots that answer queries passively, AI PB
proactively generates grounded, compliant, and user-specific investment
insights. It integrates (i) a component-based orchestration layer that
deterministically routes between internal and external LLMs based on data
sensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the
finance-domain embedding model, and (iii) a multi-stage recommendation
mechanism combining rule heuristics, sequential behavioral modeling, and
contextual bandits. Operating fully on-premises under Korean financial
regulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100
GPUs. Through human QA and system metrics, we demonstrate that grounded
generation with explicit routing and layered safety can deliver trustworthy AI
insights in high-stakes finance.

</details>


### [12] [Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions](https://arxiv.org/abs/2510.20102)
*Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Sangmi Chai*

Main category: cs.AI

TL;DR: HCLA是一个面向非专家的多代理异常检测系统，用于数字资产交易分析，通过自然语言交互提供可解释的检测结果。


<details>
  <summary>Details</summary>
Motivation: 解决金融取证中异常检测系统对非专家用户不透明、难以理解的问题，提高系统的可解释性和用户信任度。

Method: 采用三角色架构（解析、检测、解释）的多代理系统，将用户自然语言查询转换为XGBoost检测器的输入模式，并提供基于特征的叙事解释。

Result: 在比特币混币数据集上，基线检测器达到高准确率，HCLA系统在此基础上增加了可解释性和交互式优化能力。

Conclusion: 人机协同设计能够显著提升金融取证系统的透明度和可信度，使非专家用户也能有效使用复杂的异常检测技术。

Abstract: We present HCLA, a human-centered multi-agent system for anomaly detection in
digital asset transactions. The system links three roles: Parsing, Detection,
and Explanation, into a conversational workflow that lets non-experts ask
questions in natural language, inspect structured analytics, and obtain
context-aware rationales. Implemented with an open-source web UI, HCLA
translates user intents into a schema for a classical detector (XGBoost in our
prototype) and returns narrative explanations grounded in the underlying
features. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the
baseline detector reaches strong accuracy, while HCLA adds interpretability and
interactive refinement. We describe the architecture, interaction loop,
dataset, evaluation protocol, and limitations, and discuss how a
human-in-the-loop design improves transparency and trust in financial
forensics.

</details>


### [13] [The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice](https://arxiv.org/abs/2510.20109)
*Joshua Yuvaraj*

Main category: cs.AI

TL;DR: 论文认为需要重新评估AI在法律实践中的使用，提出了验证-价值悖论，指出AI带来的效率提升会被相应的验证需求抵消，导致净价值往往可忽略。


<details>
  <summary>Details</summary>
Motivation: 由于律师因提交不准确的AI生成内容而受到谴责的案例，以及AI与现实脱节、缺乏透明度与律师诚信、不误导法庭等核心职责的冲突，需要重新评估AI在法律实践中的使用范式。

Method: 提出了验证-价值悖论作为替代模型，该悖论认为AI使用带来的效率提升会被相应的手动验证需求所抵消。

Result: AI在法律实践中的净价值往往可忽略，因为效率提升被验证需求所平衡。

Conclusion: 需要重新思考AI在法律实践和教育中的使用，强调对真相的忠诚和公民责任等价值观应成为法律实践的基础。

Abstract: It is often claimed that machine learning-based generative AI products will
drastically streamline and reduce the cost of legal practice. This enthusiasm
assumes lawyers can effectively manage AI's risks. Cases in Australia and
elsewhere in which lawyers have been reprimanded for submitting inaccurate
AI-generated content to courts suggest this paradigm must be revisited. This
paper argues that a new paradigm is needed to evaluate AI use in practice,
given (a) AI's disconnection from reality and its lack of transparency, and (b)
lawyers' paramount duties like honesty, integrity, and not to mislead the
court. It presents an alternative model of AI use in practice that more
holistically reflects these features (the verification-value paradox). That
paradox suggests increases in efficiency from AI use in legal practice will be
met by a correspondingly greater imperative to manually verify any outputs of
that use, rendering the net value of AI use often negligible to lawyers. The
paper then sets out the paradox's implications for legal practice and legal
education, including for AI use but also the values that the paradox suggests
should undergird legal practice: fidelity to the truth and civic
responsibility.

</details>


### [14] [TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning](https://arxiv.org/abs/2510.20188)
*Morris Yu-Chao Huang,Zhen Tan,Mohan Zhang,Pingzhi Li,Zhuo Zhang,Tianlong Chen*

Main category: cs.AI

TL;DR: 提出了TRUST框架，一个去中心化的AI审计系统，通过共识机制、分层DAG分解、区块链记录和隐私保护分段来解决大语言模型推理链的验证问题。


<details>
  <summary>Details</summary>
Motivation: 现有审计方法存在集中化、不透明、难以扩展的问题，无法有效验证大语言模型推理链的忠实性和无害性，这在高风险领域部署专有模型时带来重大风险。

Method: TRUST框架包含：1) 多样化审计者共识机制，可容忍30%恶意参与者；2) 分层DAG分解推理链，实现可扩展并行审计；3) 区块链账本记录验证决策；4) 隐私保护分段，仅共享部分推理步骤。

Result: 在多个LLM（GPT-OSS、DeepSeek-r1、Qwen）和推理任务（数学、医疗、科学、人文）上的实验表明，TRUST能有效检测推理缺陷，并对抗性审计者保持鲁棒性。

Conclusion: TRUST开创了去中心化AI审计的先河，为大语言模型的安全可信部署提供了实用路径，具有理论安全保证和经济激励。

Abstract: Large Language Models generate complex reasoning chains that reveal their
decision-making, yet verifying the faithfulness and harmlessness of these
intermediate steps remains a critical unsolved problem. Existing auditing
methods are centralized, opaque, and hard to scale, creating significant risks
for deploying proprietary models in high-stakes domains. We identify four core
challenges: (1) Robustness: Centralized auditors are single points of failure,
prone to bias or attacks. (2) Scalability: Reasoning traces are too long for
manual verification. (3) Opacity: Closed auditing undermines public trust. (4)
Privacy: Exposing full reasoning risks model theft or distillation. We propose
TRUST, a transparent, decentralized auditing framework that overcomes these
limitations via: (1) A consensus mechanism among diverse auditors, guaranteeing
correctness under up to $30\%$ malicious participants. (2) A hierarchical DAG
decomposition of reasoning traces, enabling scalable, parallel auditing. (3) A
blockchain ledger that records all verification decisions for public
accountability. (4) Privacy-preserving segmentation, sharing only partial
reasoning steps to protect proprietary logic. We provide theoretical guarantees
for the security and economic incentives of the TRUST framework. Experiments
across multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,
medical, science, humanities) show TRUST effectively detects reasoning flaws
and remains robust against adversarial auditors. Our work pioneers
decentralized AI auditing, offering a practical path toward safe and
trustworthy LLM deployment.

</details>


### [15] [The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI](https://arxiv.org/abs/2510.20190)
*Marcelo Maciel Amaral,Raymond Aschheim*

Main category: cs.AI

TL;DR: 该论文提出AGI发展需要经历一个从开放模仿到身份固化的锁定阶段，身份固化是AGI可靠性的先决条件，也是一个关键的安全控制点。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型过于开放和可操控，通过类比人类发展过程，假设AGI发展需要经历身份固化的锁定阶段，使目标结构、拒绝行为、偏好和内部表征变得相对稳定且抵抗外部操控。

Method: 形式化身份固化阶段，将其与学习动力学中的已知现象联系起来，提出操作性指标用于检测固化开始，并通过实验验证行为固化的特征。

Result: 实验表明行为固化是快速且非线性的，但对通用能力的影响不是单一的：小模型出现性能权衡，中等规模模型基本无成本地实现固化，大型量化模型出现瞬时不稳定性。

Conclusion: 身份固化是AGI级可靠性的先决条件，也是一个关键的安全控制点——身份可以被有意设计以提高可靠性，但也可能在规模扩展过程中自发出现，从而固化不可预测的目标和行为。

Abstract: Large language models (LLMs) remain broadly open and highly steerable: they
imitate at scale, accept arbitrary system prompts, and readily adopt multiple
personae. By analogy to human development, we hypothesize that progress toward
artificial general intelligence (AGI) involves a lock-in phase: a transition
from open imitation to identity consolidation, in which goal structures,
refusals, preferences, and internal representations become comparatively stable
and resistant to external steering. We formalize this phase, link it to known
phenomena in learning dynamics, and propose operational metrics for onset
detection. Experimentally, we demonstrate that while the behavioral
consolidation is rapid and non-linear, its side-effects on general capabilities
are not monolithic. Our results reveal a spectrum of outcomes--from performance
trade-offs in small models, through largely cost-free adoption in mid-scale
models, to transient instabilities in large, quantized models. We argue that
such consolidation is a prerequisite for AGI-level reliability and also a
critical control point for safety: identities can be deliberately engineered
for reliability, yet may also emerge spontaneously during scaling, potentially
hardening unpredictable goals and behaviors.

</details>


### [16] [Merge and Conquer: Evolutionarily Optimizing AI for 2048](https://arxiv.org/abs/2510.20205)
*Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum*

Main category: cs.AI

TL;DR: 本文研究了进化训练方法在优化AI玩2048游戏中的应用，比较了单智能体系统和双智能体系统的表现。


<details>
  <summary>Details</summary>
Motivation: 优化AI在动态环境中的性能是机器学习研究的基本挑战，2048游戏结合了策略游戏和随机元素，是研究决策制定、长期规划和动态适应的理想平台。

Method: 实现了两种系统：双智能体元提示系统（一个"思考者"LLM为"执行者"LLM优化策略）和基于改进价值函数的单智能体有限蒙特卡洛树搜索系统，还实验了回滚功能以避免性能下降。

Result: 单智能体系统取得了显著改进，每个周期平均增加473.2分，训练周期呈现明显上升趋势（相关性ρ=0.607）。LLM对游戏的理解也随着开发更先进策略而增长。相反，双智能体系统没有获得太多改进。

Conclusion: 研究证明了进化优化技术在非确定性环境中改进AI性能的潜力，同时凸显了元提示方法的固有局限性。

Abstract: Optimizing artificial intelligence (AI) for dynamic environments remains a
fundamental challenge in machine learning research. In this paper, we examine
evolutionary training methods for optimizing AI to solve the game 2048, a 2D
sliding puzzle. 2048, with its mix of strategic gameplay and stochastic
elements, presents an ideal playground for studying decision-making, long-term
planning, and dynamic adaptation. We implemented two distinct systems: a
two-agent metaprompting system where a "thinker" large language model (LLM)
agent refines gameplay strategies for an "executor" LLM agent, and a
single-agent system based on refining a value function for a limited Monte
Carlo Tree Search. We also experimented with rollback features to avoid
performance degradation. Our results demonstrate the potential of evolutionary
refinement techniques in improving AI performance in non-deterministic
environments. The single-agent system achieved substantial improvements, with
an average increase of 473.2 points per cycle, and with clear upward trends
(correlation $\rho$=0.607) across training cycles. The LLM's understanding of
the game grew as well, shown in its development of increasingly advanced
strategies. Conversely, the two-agent system did not garner much improvement,
highlighting the inherent limits of meta-prompting.

</details>


### [17] [Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods](https://arxiv.org/abs/2510.20252)
*Tianyi Zhang,Xiaolin Zhou,Yunzhe Wang,Erik Cambria,David Traum,Rui Mao*

Main category: cs.AI

TL;DR: 该论文提出了个体化认知模拟(ICS)任务，评估不同认知表征方法在模拟特定个体思维过程方面的能力。通过构建基于新出版小说的数据集和11条件认知评估框架，测试了7个现成LLM在作者风格模仿中的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM能够模仿表面的人类行为，但它们在模拟更深层次个体化认知过程方面的能力尚不清楚。研究旨在填补这一空白，评估不同认知表征方法在ICS中的有效性。

Method: 构建基于新出版小说（晚于测试LLM发布日期）的数据集，提出11条件认知评估框架，测试7个现成LLM在作者风格模仿中的表现。比较不同认知表征方法：语言特征、概念映射和基于档案的信息。

Result: 结果显示，结合概念和语言特征在ICS中特别有效，在整体评估中优于基于静态档案的线索。LLM在模仿语言风格方面比叙事结构更有效，突显了它们在更深层次认知模拟中的局限性。

Conclusion: 这些发现为开发适应个体思维和表达方式的AI系统奠定了基础，推动了更个性化和人类对齐的创意技术的发展。

Abstract: Individualized cognitive simulation (ICS) aims to build computational models
that approximate the thought processes of specific individuals. While large
language models (LLMs) convincingly mimic surface-level human behavior such as
role-play, their ability to simulate deeper individualized cognitive processes
remains poorly understood. To address this gap, we introduce a novel task that
evaluates different cognitive representation methods in ICS. We construct a
dataset from recently published novels (later than the release date of the
tested LLMs) and propose an 11-condition cognitive evaluation framework to
benchmark seven off-the-shelf LLMs in the context of authorial style emulation.
We hypothesize that effective cognitive representations can help LLMs generate
storytelling that better mirrors the original author. Thus, we test different
cognitive representations, e.g., linguistic features, concept mappings, and
profile-based information. Results show that combining conceptual and
linguistic features is particularly effective in ICS, outperforming static
profile-based cues in overall evaluation. Importantly, LLMs are more effective
at mimicking linguistic style than narrative structure, underscoring their
limits in deeper cognitive simulation. These findings provide a foundation for
developing AI systems that adapt to individual ways of thinking and expression,
advancing more personalized and human-aligned creative technologies.

</details>


### [18] [Using Large Language Models for Abstraction of Planning Domains - Extended Version](https://arxiv.org/abs/2510.20258)
*Bita Banihashemi,Megh Patel,Yves Lespérance*

Main category: cs.AI

TL;DR: 使用大语言模型通过上下文学习生成抽象PDDL领域和问题实例，以自然语言指定的抽象目标为基础，在简单设置中能有效合成规划领域抽象。


<details>
  <summary>Details</summary>
Motivation: 动态领域的抽象生成对智能体的规划、推理和解释能力有重要影响，但如何选择合适抽象仍具挑战性。

Method: 在PDDL中建模具体行为，利用大语言模型进行上下文学习，生成抽象PDDL领域和问题实例，并通过符号验证工具和专家评估。

Result: GPT-4o在简单设置中能有效合成规划领域抽象，但在动作抽象方面优于关联谓词的抽象。

Conclusion: 大语言模型可用于生成有用的规划领域抽象，特别是在动作抽象方面表现良好，但在谓词抽象方面仍有改进空间。

Abstract: Generating an abstraction of a dynamic domain that aligns with a given
purpose remains a significant challenge given that the choice of such an
abstraction can impact an agent's ability to plan, reason, and provide
explanations effectively. We model the agent's concrete behaviors in PDDL and
investigate the use of in-context learning with large language models (LLMs)
for the generation of abstract PDDL domains and problem instances, given an
abstraction objective specified in natural language. The benchmark examples we
use are new and have not been part of the data any LLMs have been trained on.
We consider three categories of abstractions: abstraction of choice of
alternative concrete actions, abstraction of sequences of concrete actions, and
abstraction of action/predicate parameters, as well as combinations of these.
The generated abstract PDDL domains and problem instances are then checked by
symbolic validation tools as well as human experts. Our experiments show that
GPT-4o can generally synthesize useful planning domain abstractions in simple
settings, although it is better at abstracting over actions than over the
associated fluents.

</details>


### [19] [Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction](https://arxiv.org/abs/2510.20275)
*Yunzhi Liu,Haokai Tan,Rushi Kanjaria,Lihuan Li,Flora D. Salim*

Main category: cs.AI

TL;DR: 提出了STaBERT模型，通过整合POI和时序信息来增强人类移动性预测的语义理解，显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有模型要么只建模位置序列，要么将时间信息作为辅助输入，未能充分利用兴趣点(POI)提供的丰富语义上下文。

Method: 在BERT模型基础上，引入推导的时间描述符和POI嵌入，构建统一的语义增强移动性表示。

Result: 单城市预测的GEO-BLEU分数从0.34提升到0.75；多城市预测从0.34提升到0.56。

Conclusion: STaBERT通过整合POI和时序信息，显著改善了人类移动性预测的准确性。

Abstract: Human mobility forecasting is crucial for disaster relief, city planning, and
public health. However, existing models either only model location sequences or
include time information merely as auxiliary input, thereby failing to leverage
the rich semantic context provided by points of interest (POIs). To address
this, we enrich a BERT-based mobility model with derived temporal descriptors
and POI embeddings to better capture the semantics underlying human movement.
We propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI
and temporal information at each location to construct a unified, semantically
enriched representation of mobility. Experimental results show that STaBERT
significantly improves prediction accuracy: for single-city prediction, the
GEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34
to 0.56.

</details>


### [20] [Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation](https://arxiv.org/abs/2510.20310)
*Mingliang Zhai,Hansheng Liang,Xiaomeng Fan,Zhi Gao,Chuanhao Li,Che Sun,Xu Bin,Yuwei Wu,Yunde Jia*

Main category: cs.AI

TL;DR: ToolEQA是一个集成外部工具和多步推理的EQA智能体，通过工具获取有用信息来指导探索方向，相比现有方法能生成更准确答案且探索距离更短。


<details>
  <summary>Details</summary>
Motivation: 现有EQA方法直接使用VLM探索环境回答问题，缺乏显式思考和规划，导致推理能力受限、探索效率低下和回答效果不佳。

Method: 提出ToolEQA智能体，集成外部工具进行多步推理；设计自动生成EQA任务的数据管道，构建包含18K任务的EQA-RT数据集。

Result: 在EQA-RT-Seen和EQA-RT-Unseen上，ToolEQA比SOTA基线成功率提升9.2~20.2%，比零样本ToolEQA高10%；在HM-EQA、OpenEQA和EXPRESS-Bench数据集上也达到SOTA性能。

Conclusion: ToolEQA通过工具集成和多步推理显著提升了EQA任务的性能，证明了其在多种EQA数据集上的通用性和有效性。

Abstract: Embodied Question Answering (EQA) requires agents to explore 3D environments
to obtain observations and answer questions related to the scene. Existing
methods leverage VLMs to directly explore the environment and answer questions
without explicit thinking or planning, which limits their reasoning ability and
results in excessive or inefficient exploration as well as ineffective
responses. In this paper, we introduce ToolEQA, an agent that integrates
external tools with multi-step reasoning, where external tools can provide more
useful information for completing the task, helping the model derive better
exploration directions in the next step of reasoning and thus obtaining
additional effective information. This enables ToolEQA to generate more
accurate responses with a shorter exploration distance. To enhance the model's
ability for tool-usage and multi-step reasoning, we further design a novel EQA
data generation pipeline that automatically constructs large-scale EQA tasks
with reasoning trajectories and corresponding answers. Based on the pipeline,
we collect the EQA-RT dataset that contains about 18K tasks, divided into a
training set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping
with the training set) and EQA-RT-Unseen (novel scenes). Experiments on
EQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by
9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot
ToolEQA by 10% in success rate. In addition, ToolEQA also achieves
state-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench
datasets, demonstrating its generality. Our homepage see
https://tooleqa.github.io.

</details>


### [21] [Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems](https://arxiv.org/abs/2510.20332)
*Anna Arias-Duart,Maria Eugenia Cardello,Atia Cortés*

Main category: cs.AI

TL;DR: 本文分析了AI在医疗领域应用中的数据偏见问题，基于AI4HealthyAging项目经验，识别了临床数据收集中存在的多种偏见类型，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: AI在医疗领域具有巨大潜力，但由于训练数据的质量和公平性问题，AI解决方案在真实临床实践中的整合仍然有限。数据收集过程中的偏见是主要障碍。

Method: 基于西班牙国家研发计划中的AI4HealthyAging项目经验，通过检测临床数据收集过程中的偏见，识别了多种偏见类型。

Result: 识别出历史偏见、代表性偏见和测量偏见等多种偏见类型，这些偏见体现在性别、年龄、居住环境、社会经济地位、设备和标签等多个变量中。

Conclusion: 提出了改进临床问题设计和数据收集公平性和鲁棒性的实用建议，希望为未来开发更公平的医疗AI系统提供指导。

Abstract: Artificial intelligence (AI) holds great promise for transforming healthcare.
However, despite significant advances, the integration of AI solutions into
real-world clinical practice remains limited. A major barrier is the quality
and fairness of training data, which is often compromised by biased data
collection practices. This paper draws on insights from the AI4HealthyAging
project, part of Spain's national R&D initiative, where our task was to detect
biases during clinical data collection. We identify several types of bias
across multiple use cases, including historical, representation, and
measurement biases. These biases manifest in variables such as sex, gender,
age, habitat, socioeconomic status, equipment, and labeling. We conclude with
practical recommendations for improving the fairness and robustness of clinical
problem design and data collection. We hope that our findings and experience
contribute to guiding future projects in the development of fairer AI systems
in healthcare.

</details>


### [22] [Collateral Damage Assessment Model for AI System Target Engagement in Military Operations](https://arxiv.org/abs/2510.20337)
*Clara Maathuis,Kasper Cools*

Main category: cs.AI

TL;DR: 提出了一种用于评估军事行动中AI系统目标打击附带损害的新模型，该模型整合了时间、空间和力量维度，采用知识表示与推理架构，通过实例化进行验证。


<details>
  <summary>Details</summary>
Motivation: 在AI系统在战场中作用日益重要的时代，需要严格评估潜在附带效应以确保负责任的打击目标选择。

Method: 采用设计科学方法论，构建统一的知识表示与推理架构，整合时间、空间和力量维度，考虑传播、严重性、可能性和评估指标，通过实例化进行演示和评估。

Result: 开发了一个分层结构模型，能够捕捉AI系统的类别和架构组件、相应的打击向量和上下文方面，并提供透明推理机制。

Conclusion: 该模型为构建负责任和可信赖的智能系统奠定了基础，用于评估军事行动中打击AI系统产生的效果。

Abstract: In an era where AI (Artificial Intelligence) systems play an increasing role
in the battlefield, ensuring responsible targeting demands rigorous assessment
of potential collateral effects. In this context, a novel collateral damage
assessment model for target engagement of AI systems in military operations is
introduced. The model integrates temporal, spatial, and force dimensions within
a unified Knowledge Representation and Reasoning (KRR) architecture following a
design science methodological approach. Its layered structure captures the
categories and architectural components of the AI systems to be engaged
together with corresponding engaging vectors and contextual aspects. At the
same time, spreading, severity, likelihood, and evaluation metrics are
considered in order to provide a clear representation enhanced by transparent
reasoning mechanisms. Further, the model is demonstrated and evaluated through
instantiation which serves as a basis for further dedicated efforts that aim at
building responsible and trustworthy intelligent systems for assessing the
effects produced by engaging AI systems in military operations.

</details>


### [23] [LLM-empowered knowledge graph construction: A survey](https://arxiv.org/abs/2510.20345)
*Haonan Bian*

Main category: cs.AI

TL;DR: 该调查系统回顾了LLM赋能知识图谱构建的最新进展，分析了LLM如何重塑本体工程、知识抽取和知识融合的传统三层流程，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的出现，知识图谱构建从基于规则和统计的流程转向语言驱动和生成框架，需要系统梳理这一范式转变的进展。

Method: 从两个互补视角回顾新兴方法：基于模式的范式强调结构化和一致性，无模式范式强调灵活性和开放发现；分析了各阶段的代表性框架和技术机制。

Result: 系统梳理了LLM如何重塑知识图谱构建流程，识别了不同范式的技术特点和局限性，为理解LLM与知识图谱的协同演进提供了清晰框架。

Conclusion: 该调查阐明了LLM与知识图谱之间不断发展的相互作用，旨在弥合符号知识工程与神经语义理解，推动自适应、可解释和智能知识系统的发展。

Abstract: Knowledge Graphs (KGs) have long served as a fundamental infrastructure for
structured knowledge representation and reasoning. With the advent of Large
Language Models (LLMs), the construction of KGs has entered a new
paradigm-shifting from rule-based and statistical pipelines to language-driven
and generative frameworks. This survey provides a comprehensive overview of
recent progress in LLM-empowered knowledge graph construction, systematically
analyzing how LLMs reshape the classical three-layered pipeline of ontology
engineering, knowledge extraction, and knowledge fusion.
  We first revisit traditional KG methodologies to establish conceptual
foundations, and then review emerging LLM-driven approaches from two
complementary perspectives: schema-based paradigms, which emphasize structure,
normalization, and consistency; and schema-free paradigms, which highlight
flexibility, adaptability, and open discovery. Across each stage, we synthesize
representative frameworks, analyze their technical mechanisms, and identify
their limitations.
  Finally, the survey outlines key trends and future research directions,
including KG-based reasoning for LLMs, dynamic knowledge memory for agentic
systems, and multimodal KG construction. Through this systematic review, we aim
to clarify the evolving interplay between LLMs and knowledge graphs, bridging
symbolic knowledge engineering and neural semantic understanding toward the
development of adaptive, explainable, and intelligent knowledge systems.

</details>


### [24] [IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation](https://arxiv.org/abs/2510.20377)
*Tianyi Zhang,Florian Mai,Lucie Flek*

Main category: cs.AI

TL;DR: 提出了Instruction-Knowledge-Aware Continual Adaptation (IKnow)框架，用于在无需外部资源的情况下持续预训练指令调优模型，避免语义表示退化。


<details>
  <summary>Details</summary>
Motivation: 现有持续预训练方法需要访问原始基础模型或依赖外部领域数据库，这在基础模型权重因安全原因被保留或可靠外部语料不可用时存在现实障碍。

Method: IKnow框架在指令-响应对话格式中制定新的自监督目标，利用文本本身嵌入的领域知识，在更深语义层次进行编码学习。

Result: 该方法能够在不依赖外部资源的情况下，保持模型的指令跟随能力，同时有效编码领域知识。

Conclusion: IKnow提供了一个简单通用的框架，解决了指令调优模型持续预训练中的语义退化问题，无需外部依赖。

Abstract: Continual pretraining promises to adapt large language models (LLMs) to new
domains using only unlabeled test-time data, but naively applying standard
self-supervised objectives to instruction-tuned models is known to degrade
their instruction-following capability and semantic representations. Existing
fixes assume access to the original base model or rely on knowledge from an
external domain-specific database - both of which pose a realistic barrier in
settings where the base model weights are withheld for safety reasons or
reliable external corpora are unavailable. In this work, we propose
Instruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general
framework that formulates novel self-supervised objectives in the
instruction-response dialogue format. Rather than depend- ing on external
resources, IKnow leverages domain knowledge embedded within the text itself and
learns to encode it at a deeper semantic level.

</details>


### [25] [A computational model and tool for generating more novel opportunities in professional innovation processes](https://arxiv.org/abs/2510.20402)
*Neil Maiden,Konstantinos Zachos,James Lockerbie,Kostas Petrianakis,Amanda Brown*

Main category: cs.AI

TL;DR: 提出一个新的计算模型来生成创新机会，该模型基于创造力理论和技巧，能够产生更高新颖性而不损失实用性的创新成果。


<details>
  <summary>Details</summary>
Motivation: 现有AI工具在生成创新机会时新颖性不足，需要开发专门的计算模型来提高创新机会的新颖性，同时保持其实用性。

Method: 实现了一个包含五个功能的计算模型，这些功能基于创造力理论和技巧设计，用于生成创新机会。

Result: 在酒店业创新项目中的评估显示，该模型生成的结果比Notebook LM和ChatGPT4o更具新颖性和/或实用性，但并非所有功能都对提高新颖性有贡献。

Conclusion: 该计算模型在生成创新机会方面表现优于现有AI工具，但部分功能效果不佳，为后续模型开发提供了新的方向。

Abstract: This paper presents a new computational model of creative outcomes, informed
by creativity theories and techniques, which was implemented to generate more
novel opportunities for innovation projects. The model implemented five
functions that were developed to contribute to the generation of innovation
opportunities with higher novelty without loss of usefulness. The model was
evaluated using opportunities generated for an innovation project in the
hospitality sector. The evaluation revealed that the computational model
generated outcomes that were more novel and/or useful than outcomes from
Notebook LM and ChatGPT4o. However, not all model functions contributed to the
generation of more novel opportunities, leading to new directions for further
model development

</details>


### [26] [Neural Reasoning for Robust Instance Retrieval in $\mathcal{SHOIQ}$](https://arxiv.org/abs/2510.20457)
*Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo*

Main category: cs.AI

TL;DR: 提出了一种名为EBR的神经推理器，使用嵌入来近似符号推理器的结果，能够在描述逻辑SHOIQ中处理不一致和错误数据，解决了传统推理器在现实知识库中部署的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统描述逻辑推理器对不一致和错误数据缺乏鲁棒性的问题，使概念学习方法能够部署到现实世界的知识库中。

Method: 开发EBR神经推理器，仅需检索原子概念和存在限制的实例，就能近似SHOIQ描述逻辑中任何概念的实例集合。

Result: 实验表明EBR在缺失和错误数据情况下比现有推理器更鲁棒，能够有效处理现实知识库中的不一致性。

Conclusion: EBR为神经符号概念学习提供了实用的推理解决方案，克服了传统符号推理器在现实应用中的局限性。

Abstract: Concept learning exploits background knowledge in the form of description
logic axioms to learn explainable classification models from knowledge bases.
Despite recent breakthroughs in neuro-symbolic concept learning, most
approaches still cannot be deployed on real-world knowledge bases. This is due
to their use of description logic reasoners, which are not robust against
inconsistencies nor erroneous data. We address this challenge by presenting a
novel neural reasoner dubbed EBR. Our reasoner relies on embeddings to
approximate the results of a symbolic reasoner. We show that EBR solely
requires retrieving instances for atomic concepts and existential restrictions
to retrieve or approximate the set of instances of any concept in the
description logic $\mathcal{SHOIQ}$. In our experiments, we compare EBR with
state-of-the-art reasoners. Our results suggest that EBR is robust against
missing and erroneous data in contrast to existing reasoners.

</details>


### [27] [FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic](https://arxiv.org/abs/2510.20467)
*Yiwen Peng,Thomas Bonald,Fabian M. Suchanek*

Main category: cs.AI

TL;DR: FLORA是一种无监督的知识图谱对齐方法，基于模糊逻辑提供可解释的结果，能够同时对齐实体和关系，并支持悬空实体处理。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱对齐方法主要关注实体级对齐，缺乏可解释性推理且需要训练数据。FLORA旨在解决这些问题。

Method: 基于模糊逻辑的迭代方法，提供整体性的实体和关系对齐，无需训练数据。

Result: 在主要基准测试中达到最先进的结果，且方法可证明收敛。

Conclusion: FLORA是一种简单有效的无监督知识图谱对齐方法，具有可解释性和优异的性能表现。

Abstract: Knowledge graph alignment is the task of matching equivalent entities (that
is, instances and classes) and relations across two knowledge graphs. Most
existing methods focus on pure entity-level alignment, computing the similarity
of entities in some embedding space. They lack interpretable reasoning and need
training data to work. In this paper, we propose FLORA, a simple yet effective
method that (1) is unsupervised, i.e., does not require training data, (2)
provides a holistic alignment for entities and relations iteratively, (3) is
based on fuzzy logic and thus delivers interpretable results, (4) provably
converges, (5) allows dangling entities, i.e., entities without a counterpart
in the other KG, and (6) achieves state-of-the-art results on major benchmarks.

</details>


### [28] [Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI](https://arxiv.org/abs/2510.20568)
*Susan Ariel Aaronson,Michael Moreno*

Main category: cs.AI

TL;DR: 该研究比较了澳大利亚、哥伦比亚和美国三个国家在AI治理中的公众参与情况，发现政府未能有效收集和回应公众意见，导致参与率极低且缺乏有意义的对话。


<details>
  <summary>Details</summary>
Motivation: 政府邀请公众对AI风险和政策的评论，但在将公众意见转化为政策时，大部分内容被忽略，错失了建立AI信任的关键机会。

Method: 通过景观分析，研究比较了三个国家政府征求反馈的方式以及这些意见是否影响了治理。

Result: 三个国家中，公民与政策制定者均未建立有意义的对话，参与率低于1%，政府缺乏响应性，未能形成有效反馈循环。

Conclusion: 当前参与式AI治理方法无法建立信任或合法性，作者提出八项改进建议，包括提升AI素养、扩大参与范围、使用创新参与方法等。

Abstract: The worlds people have strong opinions about artificial intelligence (AI),
and they want policymakers to listen. Governments are inviting public comment
on AI, but as they translate input into policy, much of what citizens say is
lost. Policymakers are missing a critical opportunity to build trust in AI and
its governance. This paper compares three countries, Australia, Colombia, and
the United States, that invited citizens to comment on AI risks and policies.
Using a landscape analysis, the authors examined how each government solicited
feedback and whether that input shaped governance. Yet in none of the three
cases did citizens and policymakers establish a meaningful dialogue.
Governments did little to attract diverse voices or publicize calls for
comment, leaving most citizens unaware or unprepared to respond. In each
nation, fewer than one percent of the population participated. Moreover,
officials showed limited responsiveness to the feedback they received, failing
to create an effective feedback loop. The study finds a persistent gap between
the promise and practice of participatory AI governance. The authors conclude
that current approaches are unlikely to build trust or legitimacy in AI because
policymakers are not adequately listening or responding to public concerns.
They offer eight recommendations: promote AI literacy; monitor public feedback;
broaden outreach; hold regular online forums; use innovative engagement
methods; include underrepresented groups; respond publicly to input; and make
participation easier.

</details>


### [29] [Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting](https://arxiv.org/abs/2510.20591)
*Ali Rajaei,Peter Palensky,Jochen L. Cremer*

Main category: cs.AI

TL;DR: 提出了一种基于图神经网络的方法，用于加速电网拓扑优化，解决传统方法在大规模系统中实时求解的困难，实现了4个数量级的速度提升。


<details>
  <summary>Details</summary>
Motivation: 传统电网拓扑优化方法在大规模系统中难以实时求解，而现有机器学习方法在泛化性方面存在局限，无法适应不同的拓扑结构、运行条件和系统。

Method: 开发了异质边感知消息传递神经网络，基于线性化交流潮流模型预测有效的母线分裂动作作为候选拓扑优化解。

Result: 在GOC 2000节点系统上实现了4个数量级的加速，1分钟内提供交流可行解，最优性差距仅为2.3%。

Conclusion: 该方法在拓扑和跨系统泛化方面取得显著进展，为大规模系统近实时拓扑优化提供了可行方案。

Abstract: Network topology optimization (NTO) via busbar splitting can mitigate
transmission grid congestion and reduce redispatch costs. However, solving this
mixed-integer non-linear problem for large-scale systems in near-real-time is
currently intractable with existing solvers. Machine learning (ML) approaches
have emerged as a promising alternative, but they have limited generalization
to unseen topologies, varying operating conditions, and different systems,
which limits their practical applicability. This paper formulates NTO for
congestion management problem considering linearized AC PF, and proposes a
graph neural network (GNN)-accelerated approach. We develop a heterogeneous
edge-aware message passing NN to predict effective busbar splitting actions as
candidate NTO solutions. The proposed GNN captures local flow patterns,
achieves generalization to unseen topology changes, and improves
transferability across systems. Case studies show up to 4 orders-of-magnitude
speed-up, delivering AC-feasible solutions within one minute and a 2.3%
optimality gap on the GOC 2000-bus system. These results demonstrate a
significant step toward near-real-time NTO for large-scale systems with
topology and cross-system generalization.

</details>


### [30] [What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation](https://arxiv.org/abs/2510.20603)
*Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun*

Main category: cs.AI

TL;DR: 提出CaSE方法，通过评估推理步骤的相关性和连贯性来改进LLM推理能力，超越仅关注最终答案正确性的传统评估范式。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法只关注最终答案正确性，忽略了推理过程的质量，无法有效指导模型改进。

Method: 引入因果逐步评估(CaSE)方法，将推理质量分解为相关性和连贯性两个维度，仅使用前序上下文评估每个推理步骤以避免后见之明偏差。

Result: 在MRa-GSM8K和MRa-MATH基准上验证了CaSE与人工判断的一致性，使用CaSE评估的数据进行训练能直接提升最终任务性能。

Conclusion: CaSE为分析、调试和改进LLM推理提供了可扩展框架，证明了超越有效性检查的实际价值。

Abstract: Evaluating large language models (LLMs) on final-answer correctness is the
dominant paradigm. This approach, however, provides a coarse signal for model
improvement and overlooks the quality of the underlying reasoning process. We
argue that a more granular evaluation of reasoning offers a more effective path
to building robust models. We decompose reasoning quality into two dimensions:
relevance and coherence. Relevance measures if a step is grounded in the
problem; coherence measures if it follows logically from prior steps. To
measure these aspects reliably, we introduce causal stepwise evaluation (CaSE).
This method assesses each reasoning step using only its preceding context,
which avoids hindsight bias. We validate CaSE against human judgments on our
new expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we
show that curating training data with CaSE-evaluated relevance and coherence
directly improves final task performance. Our work provides a scalable
framework for analyzing, debugging, and improving LLM reasoning, demonstrating
the practical value of moving beyond validity checks.

</details>


### [31] [Efficient Algorithms for Computing Random Walk Centrality](https://arxiv.org/abs/2510.20604)
*Changan Liu,Zixuan Xie,Ahad N. Zehmakan,Zhongzhi Zhang*

Main category: cs.AI

TL;DR: 提出了两种可扩展的随机游走中心性算法，一种基于近似Cholesky分解和稀疏逆估计，另一种基于采样根生成树，两者都能在近线性时间内运行并提供强近似保证。


<details>
  <summary>Details</summary>
Motivation: 随机游走中心性是图挖掘中量化节点重要性的基本指标，但现有方法计算成本高，难以应用于大规模网络。

Method: 1. 基于近似Cholesky分解和稀疏逆估计的算法
2. 基于采样根生成树的算法

Result: 在大型真实网络（包括超过1000万个节点的网络）上的实验证明了所提算法的高效率和近似质量。

Conclusion: 提出的两种算法能够有效解决大规模网络中随机游走中心性的计算问题，具有实际应用价值。

Abstract: Random walk centrality is a fundamental metric in graph mining for
quantifying node importance and influence, defined as the weighted average of
hitting times to a node from all other nodes. Despite its ability to capture
rich graph structural information and its wide range of applications, computing
this measure for large networks remains impractical due to the computational
demands of existing methods. In this paper, we present a novel formulation of
random walk centrality, underpinning two scalable algorithms: one leveraging
approximate Cholesky factorization and sparse inverse estimation, while the
other sampling rooted spanning trees. Both algorithms operate in near-linear
time and provide strong approximation guarantees. Extensive experiments on
large real-world networks, including one with over 10 million nodes,
demonstrate the efficiency and approximation quality of the proposed
algorithms.

</details>


### [32] [Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms](https://arxiv.org/abs/2510.20621)
*Riccardo Guidotti,Martina Cinquini,Marta Marchiori Manerba,Mattia Setzu,Francesco Spinnato*

Main category: cs.AI

TL;DR: MIMOSA框架是一个可解释性优先的预测模型生成方法，在保持性能的同时嵌入因果性、公平性和隐私性等关键伦理属性。


<details>
  <summary>Details</summary>
Motivation: 开发可信赖的AI系统需要可解释性设计模型，以促进自动化决策模型在现实应用中的信任、问责和安全采用。

Method: 定义了监督学习设置，涵盖表格数据、时间序列、图像、文本等多种数据类型；分析了特征重要性、规则和实例三类可解释模型家族；形式化了因果性、公平性和隐私性三个伦理属性。

Result: 建立了开发既准确可解释又公平、隐私保护、因果感知的可信赖AI系统的理论基础。

Conclusion: MIMOSA框架为构建平衡可解释性与性能、同时嵌入关键伦理属性的预测模型提供了全面的方法论基础。

Abstract: Interpretable-by-design models are crucial for fostering trust,
accountability, and safe adoption of automated decision-making models in
real-world applications. In this paper we formalize the ground for the MIMOSA
(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a
comprehensive methodology for generating predictive models that balance
interpretability with performance while embedding key ethical properties. We
formally define here the supervised learning setting across diverse
decision-making tasks and data types, including tabular data, time series,
images, text, transactions, and trajectories. We characterize three major
families of interpretable models: feature importance, rule, and instance based
models. For each family, we analyze their interpretability dimensions,
reasoning mechanisms, and complexity. Beyond interpretability, we formalize
three critical ethical properties, namely causality, fairness, and privacy,
providing formal definitions, evaluation metrics, and verification procedures
for each. We then examine the inherent trade-offs between these properties and
discuss how privacy requirements, fairness constraints, and causal reasoning
can be embedded within interpretable pipelines. By evaluating ethical measures
during model generation, this framework establishes the theoretical foundations
for developing AI systems that are not only accurate and interpretable but also
fair, privacy-preserving, and causally aware, i.e., trustworthy.

</details>


### [33] [Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications](https://arxiv.org/abs/2510.20632)
*Shuyi Xie,Ziqin Liew,Hailing Zhang,Haibo Zhang,Ling Hu,Zhiqiang Zhou,Shuman Liu,Anxiang Zeng*

Main category: cs.AI

TL;DR: EcomEval是一个全面的多语言多模态基准测试，用于评估LLM在电子商务领域的表现，解决了现有评估工具在任务多样性、模态覆盖和语言支持方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有电子商务评估基准存在任务多样性不足、模态覆盖有限、数据合成化以及语言支持狭窄等问题，无法可靠评估模型在复杂真实购物场景中的表现。

Method: 构建包含6个类别37个任务（含8个多模态任务）的基准，主要来源于真实客户查询和交易日志；采用半自动流程，由大模型生成候选答案，再由50多名专家审核修改；为每个问题定义难度等级。

Result: EcomEval覆盖7种语言（包括5种东南亚低资源语言），提供了多语言视角，能够进行挑战导向和细粒度评估。

Conclusion: EcomEval填补了电子商务领域LLM评估的空白，为从业者提供了评估模型在复杂真实购物场景中表现的可靠工具。

Abstract: Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet
their capabilities in specialized domains remain underexplored. In e-commerce,
existing evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping
MMLU-suffer from limited task diversity (e.g., lacking product guidance and
after-sales issues), limited task modalities (e.g., absence of multimodal
data), synthetic or curated data, and a narrow focus on English and Chinese,
leaving practitioners without reliable tools to assess models on complex,
real-world shopping scenarios. We introduce EcomEval, a comprehensive
multilingual and multimodal benchmark for evaluating LLMs in e-commerce.
EcomEval covers six categories and 37 tasks (including 8 multimodal tasks),
sourced primarily from authentic customer queries and transaction logs,
reflecting the noisy and heterogeneous nature of real business interactions. To
ensure both quality and scalability of reference answers, we adopt a
semi-automatic pipeline in which large models draft candidate responses
subsequently reviewed and modified by over 50 expert annotators with strong
e-commerce and multilingual expertise. We define difficulty levels for each
question and task category by averaging evaluation scores across models with
different sizes and capabilities, enabling challenge-oriented and fine-grained
assessment. EcomEval also spans seven languages-including five low-resource
Southeast Asian languages-offering a multilingual perspective absent from prior
work.

</details>


### [34] [Fluidity Index: Next-Generation Super-intelligence Benchmarks](https://arxiv.org/abs/2510.20636)
*Eric Ngoiya,Tianshu Bao*

Main category: cs.AI

TL;DR: 本文提出流动性指数(FI)来量化模型在动态扩展环境中的适应性，通过评估初始、当前和未来环境状态偏差来测试模型的上下文切换和连续性能力。


<details>
  <summary>Details</summary>
Motivation: 为了在动态扩展环境中准确评估模型的适应能力，需要一种能够量化模型对状态变化的理解、预测和调整能力的指标。

Method: 开发流动性指数(FI)基准，区分封闭式和开放式基准，优先采用闭环开放式真实世界基准来测试适应性，测量模型在扩展环境中理解、预测和适应状态变化的能力。

Result: 提出了一个评估模型适应性的量化框架，强调真正超级智能模型应至少具备二阶适应性，能够通过数字补充实现自持续计算以达到最佳流动性。

Conclusion: 流动性指数为评估模型在动态环境中的适应性提供了系统方法，超级智能模型需要具备高阶适应性能力以实现自持续优化。

Abstract: This paper introduces the Fluidity Index (FI) to quantify model adaptability
in dynamic, scaling environments. The benchmark evaluates response accuracy
based on deviations in initial, current, and future environment states,
assessing context switching and continuity. We distinguish between closed-ended
and open-ended benchmarks, prioritizing closed-loop open-ended real-world
benchmarks to test adaptability. The approach measures a model's ability to
understand, predict, and adjust to state changes in scaling environments. A
truly super-intelligent model should exhibit at least second-order
adaptability, enabling self-sustained computation through digital replenishment
for optimal fluidity.

</details>


### [35] [Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges](https://arxiv.org/abs/2510.20641)
*Andrea Agiollo,Andrea Omicini*

Main category: cs.AI

TL;DR: 本文对将机器学习整合到理性智能体架构中的现有方法进行了系统化梳理，特别关注BDI（信念-欲望-意图）范式，识别了关键研究机会和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 由于机器学习模型在感知和认知任务中展现出类人能力，将ML整合到理性智能体架构中的框架日益受到关注，但现有研究碎片化且不连贯，往往忽视理性架构的表达能力。

Method: 使用BDI范式作为参考框架，对现有方法进行细粒度系统化分析，梳理理性智能体增强ML的文献发展。

Result: 分析展示了理性智能体增强ML的快速演进文献，揭示了该领域的发展趋势。

Conclusion: 识别了设计有效理性ML智能体的关键研究机会和开放挑战，为未来研究提供方向。

Abstract: Thanks to the remarkable human-like capabilities of machine learning (ML)
models in perceptual and cognitive tasks, frameworks integrating ML within
rational agent architectures are gaining traction. Yet, the landscape remains
fragmented and incoherent, often focusing on embedding ML into generic agent
containers while overlooking the expressive power of rational
architectures--such as Belief-Desire-Intention (BDI) agents. This paper
presents a fine-grained systematisation of existing approaches, using the BDI
paradigm as a reference. Our analysis illustrates the fast-evolving literature
on rational agents enhanced by ML, and identifies key research opportunities
and open challenges for designing effective rational ML agents.

</details>


### [36] [The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models](https://arxiv.org/abs/2510.20665)
*Xue Wen Tan,Nathaniel Tan,Galen Lee,Stanley Kok*

Main category: cs.AI

TL;DR: 提出了基于拓扑数据分析的框架，用于自动评估大型语言模型推理轨迹的质量，相比传统图指标具有更高预测能力


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM推理轨迹质量的方法依赖专家标注、劳动密集且不可靠，现有自动化方法主要使用图结构指标但无法有效捕捉推理质量

Method: 使用拓扑数据分析方法捕捉推理轨迹的几何结构，通过拓扑特征进行自动化评估

Result: 拓扑特征在评估推理质量方面比标准图指标具有显著更高的预测能力，表明有效推理由高维几何结构而非纯关系图更好捕捉

Conclusion: 紧凑稳定的拓扑特征集可靠地指示轨迹质量，为未来强化学习算法提供了实用信号

Abstract: Evaluating the quality of reasoning traces from large language models remains
understudied, labor-intensive, and unreliable: current practice relies on
expert rubrics, manual annotation, and slow pairwise judgments. Automated
efforts are dominated by graph-based proxies that quantify structural
connectivity but do not clarify what constitutes high-quality reasoning; such
abstractions can be overly simplistic for inherently complex processes. We
introduce a topological data analysis (TDA)-based evaluation framework that
captures the geometry of reasoning traces and enables label-efficient,
automated assessment. In our empirical study, topological features yield
substantially higher predictive power for assessing reasoning quality than
standard graph metrics, suggesting that effective reasoning is better captured
by higher-dimensional geometric structures rather than purely relational
graphs. We further show that a compact, stable set of topological features
reliably indicates trace quality, offering a practical signal for future
reinforcement learning algorithms.

</details>


### [37] [Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs](https://arxiv.org/abs/2510.20691)
*Yanlin Song,Ben Liu,Víctor Gutiérrez-Basulto,Zhiwei Hu,Qianqian Xie,Min Peng,Sophia Ananiadou,Jeff Z. Pan*

Main category: cs.AI

TL;DR: Graph-RFT是一个两阶段强化微调KGQA框架，通过'计划-KG搜索-网络搜索-思考'范式，让LLM在知识不完整条件下自主规划并自适应调度KG和网络检索。


<details>
  <summary>Details</summary>
Motivation: 现有KGQA方法难以充分利用KG的丰富知识和LLM的推理能力，在复杂场景下存在KG覆盖不完整、缺乏外部信息判断机制、推理短视等问题。

Method: 提出两阶段方法：1) 链式思维微调解决GRPO冷启动；2) 计划检索引导的强化学习，结合笛卡尔式规划模块分解问题，逻辑表达式指导工具调用，多奖励设计优化检索调度。

Result: 该方法使模型能够学习何时以及如何有效结合KG和网络检索，实现全局一致的多步推理。

Conclusion: Graph-RFT通过自主规划和自适应检索调度，显著提升了在复杂KGQA场景下的推理性能。

Abstract: Knowledge Graph Question Answering aims to answer natural language questions
by reasoning over structured knowledge graphs. While large language models have
advanced KGQA through their strong reasoning capabilities, existing methods
continue to struggle to fully exploit both the rich knowledge encoded in KGs
and the reasoning capabilities of LLMs, particularly in complex scenarios. They
often assume complete KG coverage and lack mechanisms to judge when external
information is needed, and their reasoning remains locally myopic, failing to
maintain coherent multi-step planning, leading to reasoning failures even when
relevant knowledge exists. We propose Graph-RFT, a novel two-stage
reinforcement fine-tuning KGQA framework with a
'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to
perform autonomous planning and adaptive retrieval scheduling across KG and web
sources under incomplete knowledge conditions. Graph-RFT introduces a
chain-of-thought fine-tuning method with a customized plan-retrieval dataset
activates structured reasoning and resolves the GRPO cold-start problem. It
then introduces a novel plan-retrieval guided reinforcement learning process
integrates explicit planning and retrieval actions with a multi-reward design,
enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired
planning module to decompose complex questions into ordered subquestions, and
logical expression to guide tool invocation for globally consistent multi-step
reasoning. This reasoning retrieval process is optimized with a multi-reward
combining outcome and retrieval specific signals, enabling the model to learn
when and how to combine KG and web retrieval effectively.

</details>


### [38] [A Coherence-Based Measure of AGI](https://arxiv.org/abs/2510.20784)
*Fares Fourati*

Main category: cs.AI

TL;DR: 本文提出了一种基于广义均值积分的一致性感知AGI度量方法，替代了传统算术平均方法，能够更好地衡量跨认知领域的平衡能力。


<details>
  <summary>Details</summary>
Motivation: 现有AGI定义使用算术平均，假设领域间可补偿性，但真正的通用智能应该反映所有基本领域的平衡能力。

Method: 提出基于广义均值连续体积分的一致性感知AGI度量，涵盖算术、几何和调和均值机制，通过曲线下面积量化不同补偿性假设下的鲁棒性。

Result: 应用于GPT-4和GPT-5的CHC领域得分，一致性调整的AUC显示尽管算术得分高（GPT-5达24%），但两个系统距离通用能力仍很远。

Conclusion: 广义均值积分为衡量AGI真实进展提供了原则性、可解释且更严格的基础。

Abstract: Recent work by \citet{hendrycks2025agidefinition} formalized
\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of
proficiencies across cognitive domains derived from the Cattell--Horn--Carroll
(CHC) model of human cognition. While elegant, this definition assumes
\textit{compensability} -- that exceptional ability in some domains can offset
failure in others. True general intelligence, however, should reflect
\textit{coherent sufficiency}: balanced competence across all essential
domains. We propose a coherence-aware measure of AGI based on the integral of
generalized means over a continuum of compensability exponents. This
formulation spans arithmetic, geometric, and harmonic regimes, and the
resulting \textit{area under the curve} (AUC) quantifies robustness under
varying compensability assumptions. Unlike the arithmetic mean, which rewards
specialization, the AUC penalizes imbalance and captures inter-domain
dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,
the coherence-adjusted AUC reveals that both systems remain far from general
competence despite high arithmetic scores (e.g., GPT-5 at~24\%). Integrating
the generalized mean thus yields a principled, interpretable, and stricter
foundation for measuring genuine progress toward AGI.

</details>


### [39] [Real Deep Research for AI, Robotics and Beyond](https://arxiv.org/abs/2510.20809)
*Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang*

Main category: cs.AI

TL;DR: 提出Real Deep Research (RDR)框架，用于系统分析快速发展的AI和机器人研究领域，识别新兴趋势和跨领域机会，帮助研究人员跟上研究进展。


<details>
  <summary>Details</summary>
Motivation: AI和机器人领域每年产生超过10,000篇论文，研究人员难以跟上快速发展的趋势、跨学科工作和探索新领域的需求。

Method: 构建通用的RDR管道，系统分析研究领域，识别新兴趋势，发现跨领域机会，并为新研究提供具体起点。

Result: 将RDR框架应用于AI和机器人领域，特别关注基础模型和机器人进展，并扩展到其他科学领域。

Conclusion: RDR框架为AI及其他领域的研究人员提供了系统分析研究趋势和机会的工具，帮助他们在快速发展的领域中保持更新。

Abstract: With the rapid growth of research in AI and robotics now producing over
10,000 papers annually it has become increasingly difficult for researchers to
stay up to date. Fast evolving trends, the rise of interdisciplinary work, and
the need to explore domains beyond one's expertise all contribute to this
challenge. To address these issues, we propose a generalizable pipeline capable
of systematically analyzing any research area: identifying emerging trends,
uncovering cross domain opportunities, and offering concrete starting points
for new inquiry. In this work, we present Real Deep Research (RDR) a
comprehensive framework applied to the domains of AI and robotics, with a
particular focus on foundation models and robotics advancements. We also
briefly extend our analysis to other areas of science. The main paper details
the construction of the RDR pipeline, while the appendix provides extensive
results across each analyzed topic. We hope this work sheds light for
researchers working in the field of AI and beyond.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [40] [AI Pose Analysis and Kinematic Profiling of Range-of-Motion Variations in Resistance Training](https://arxiv.org/abs/2510.20012)
*Adam Diamant*

Main category: stat.AP

TL;DR: 开发基于AI的姿态估计管道，用于精确量化抗阻训练中的运动学参数，比较部分范围运动(pROM)和全范围运动(fROM)训练在运动范围、节奏和执行动态方面的差异。


<details>
  <summary>Details</summary>
Motivation: 利用AI技术精确量化抗阻训练中的运动学参数，比较不同运动范围训练方式的执行特征差异，为训练处方提供科学依据。

Method: 使用Wolf等人(2025)的视频数据，通过AI姿态估计管道处理280个记录，提取关节角度轨迹，计算运动范围、节奏、向心/离心阶段持续时间等指标，应用随机效应元分析模型分析变异性。

Result: pROM重复动作具有更小的运动范围和更短的总持续时间，特别是在离心阶段。参与者个体差异是变异的主要来源，而非具体训练动作。新指标%ROM显示部分范围运动在不同训练动作中保持相对一致。

Conclusion: 部分范围运动训练不仅在运动范围上与全范围运动不同，在执行动态和一致性方面也存在差异，AI方法在推进抗阻训练研究和改善训练处方方面具有潜力。

Abstract: This study develops an AI-based pose estimation pipeline to enable precise
quantification of movement kinematics in resistance training. Using video data
from Wolf et al. (2025), which compared lengthened partial (pROM) and full
range-of-motion (fROM) training across eight upper-body exercises in 26
participants, 280 recordings were processed to extract frame-level joint-angle
trajectories. After filtering and smoothing, per-set metrics were derived,
including range of motion (ROM), tempo, and concentric/eccentric phase
durations. A random-effects meta-analytic model was applied to account for
within-participant and between-exercise variability. Results show that pROM
repetitions were performed with a smaller ROM and shorter overall durations,
particularly during the eccentric phase of movement. Variance analyses revealed
that participant-level differences, rather than exercise-specific factors, were
the primary driver of variation, although there is substantial evidence of
heterogeneous treatment effects. We then introduce a novel metric, \%ROM, which
is the proportion of full ROM achieved during pROM, and demonstrate that this
definition of lengthened partials remains relatively consistent across
exercises. Overall, these findings suggest that lengthened partials differ from
full ROM training not only in ROM, but also in execution dynamics and
consistency, highlighting the potential of AI-based methods for advancing
research and improving resistance training prescription.

</details>


### [41] [Treatment Effect Learning Under Sequential Randomization](https://arxiv.org/abs/2510.20078)
*Rina Friedberg,Richard Mudd,Patrick Johnstone,Melissa Pothen,Vishal Vaingankar,Vishwanath Sangale,Abbas Zaidi*

Main category: stat.AP

TL;DR: 提出了一种结合T-Learner和G-Formula的方法来处理在线实验中序列治疗分配带来的复杂依赖结构问题，特别是针对持续性效应的情况。


<details>
  <summary>Details</summary>
Motivation: 在线实验中的序列治疗分配会产生复杂的依赖结构，导致标准方法在识别、估计和推断治疗效果时容易出现错误设定。治疗在一个会话中的效果可能会持续到后续会话，产生累积效应。

Method: 将T-Learner分层整合到G-Formula中，基于因果机器学习和序列设置中的识别文献构建方法。

Result: 在简单模拟中，该方法在存在持续性效应的情况下防止了准确性衰减。

Conclusion: 强调了针对技术领域常见系统特性定制识别和推断策略的重要性。

Abstract: Sequential treatment assignments in online experiments lead to complex
dependency structures, often rendering identification, estimation and inference
over treatments a challenge. Treatments in one session (e.g., a user logging
on) can have an effect that persists into subsequent sessions, leading to
cumulative effects on outcomes measured at a later stage. This can render
standard methods for identification and inference trivially misspecified. We
propose T-Learners layered into the G-Formula for this setting, building on
literature from causal machine learning and identification in sequential
settings. In a simple simulation, this approach prevents decaying accuracy in
the presence of carry-over effects, highlighting the importance of
identification and inference strategies tailored to the nature of systems often
seen in the tech domain.

</details>


### [42] [Reorienting Age-Friendly Frameworks for Rural Contexts: A Spatial Competence-Press Framework for Aging in Chinese Villages](https://arxiv.org/abs/2510.20343)
*Ziyuan Gao*

Main category: stat.AP

TL;DR: 开发基于GIS的空间压力分析框架，应用Lawton和Nahemow的能力-压力模型量化农村老龄化相关压力源，并对村庄按干预需求分类。


<details>
  <summary>Details</summary>
Motivation: 现有农村老龄化研究存在方法学空白，系统性地低估了老年人面临的日常空间压力源，包括地形障碍、基础设施限制、气候暴露和农业劳动负担。现有乡村振兴政策强调标准化干预，但未能充分解决空间异质性和老龄化人口的空间差异化需求。

Method: 开发GIS空间压力分析框架，建立四个空间压力指标：坡度指数(SGI)、太阳辐射暴露指数(SREI)、步行指数(WI)和农业强度指数(AII)。使用方差分析和层次聚类分析27个村庄数据。

Result: 方差分析和层次聚类显示村庄间空间压力存在显著差异，识别出需要针对性干预策略的不同类型村庄。

Conclusion: 该框架为规划者和政策制定者提供了实用的工具，可用于设计针对中国农村及类似背景下的空间定向适老化干预措施。

Abstract: While frameworks such as the WHO Age-Friendly Cities have advanced urban
aging policy, rural contexts demand fundamentally different analytical
approaches. The spatial dispersion, terrain variability, and agricultural labor
dependencies that characterize rural aging experiences require moving beyond
service-domain frameworks toward spatial stress assessment models. Current
research on rural aging in China exhibits methodological gaps, systematically
underrepresenting the spatial stressors that older adults face daily, including
terrain barriers, infrastructure limitations, climate exposure, and
agricultural labor burdens. Existing rural revitalization policies emphasize
standardized interventions while inadequately addressing spatial heterogeneity
and the spatially-differentiated needs of aging populations. This study
developed a GIS-based spatial stress analysis framework that applies Lawton and
Nahemow's competence-press model to quantify aging-related stressors and
classify rural villages by intervention needs. Using data from 27 villages in
Mamuchi Township, Shandong Province, we established four spatial stress
indicators: slope gradient index (SGI), solar radiation exposure index (SREI),
walkability index (WI), and agricultural intensity index (AII). Analysis of
variance and hierarchical clustering revealed significant variation in spatial
pressures across villages and identified distinct typologies that require
targeted intervention strategies. The framework produces both quantitative
stress measurements for individual villages and a classification system that
groups villages with similar stress patterns, providing planners and
policymakers with practical tools for designing spatially-targeted age-friendly
interventions in rural China and similar contexts.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [43] [The Risks of Industry Influence in Tech Research](https://arxiv.org/abs/2510.19894)
*Joseph Bak-Coleman,Cailin O'Connor,Carl Bergstrom,Jevin West*

Main category: cs.SI

TL;DR: 本文探讨科技公司如何影响对其产品的科学研究，指出在技术研究领域科学面临独特挑战，需要加强现有保障措施并建立全新机制。


<details>
  <summary>Details</summary>
Motivation: 新兴信息技术对公共健康、政治制度、社会动态和自然环境产生广泛影响，需要科学理解这些影响以制定基于证据的技术政策。但相关数据由可能受监管的行业控制，且科技公司是该领域主要资助方，存在信息与资金不对称问题。

Method: 通过分析科技公司对科学记录可能产生的影响，探讨行业在信息控制和资金资助方面的不对称性如何威胁科学研究的独立性。

Result: 识别出科技公司通过数据控制和资金资助对科学研究产生不当影响的风险，强调需要解决这些结构性挑战。

Conclusion: 技术研究领域的科学面临独特挑战，需要加强现有保障措施并建立全新机制，以确保科学研究的独立性和完整性。

Abstract: Emerging information technologies like social media, search engines, and AI
can have a broad impact on public health, political institutions, social
dynamics, and the natural world. It is critical to develop a scientific
understanding of these impacts to inform evidence-based technology policy that
minimizes harm and maximizes benefits. Unlike most other global-scale
scientific challenges, however, the data necessary for scientific progress are
generated and controlled by the same industry that might be subject to
evidence-based regulation. Moreover, technology companies historically have
been, and continue to be, a major source of funding for this field. These
asymmetries in information and funding raise significant concerns about the
potential for undue industry influence on the scientific record. In this
Perspective, we explore how technology companies can influence our scientific
understanding of their products. We argue that science faces unique challenges
in the context of technology research that will require strengthening existing
safeguards and constructing wholly new ones.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [44] [Evaluating Local Policies in Centralized Markets](https://arxiv.org/abs/2510.20032)
*Dmitry Arkhangelsky,Wisse Rutgers*

Main category: econ.GN

TL;DR: 本文提出了一种在集中市场中评估政策效果的非参数识别方法，通过构建均衡调整结果来识别边际政策效应，无需政策规则的变化。


<details>
  <summary>Details</summary>
Motivation: 研究集中市场中的政策评估问题，旨在在不依赖政策规则变化的情况下识别边际政策效应。

Method: 构建均衡调整结果，这是一种政策不变的结构性对象，将个体结果与其参与对他人施加的完全均衡外部性相结合。外部性可以通过实证工作中常见的估计量来构建。

Result: 边际政策效应被识别为结构性结果与改革方向之间的协方差，为最优政策目标提供了灵活工具，并与边际处理效应文献建立了新的桥梁。

Conclusion: 该方法提供了一种在基线均衡数据下非参数识别边际政策效应的框架，无需额外的政策规则变化，为政策评估提供了新的视角。

Abstract: We study a policy evaluation problem in centralized markets. We show that the
aggregate impact of any marginal reform, the Marginal Policy Effect (MPE), is
nonparametrically identified using data from a baseline equilibrium, without
additional variation in the policy rule. We achieve this by constructing the
equilibrium-adjusted outcome: a policy-invariant structural object that
augments an agent's outcome with the full equilibrium externality their
participation imposes on others. We show that these externalities can be
constructed using estimands that are already common in empirical work. The MPE
is identified as the covariance between our structural outcome and the reform's
direction, providing a flexible tool for optimal policy targeting and a novel
bridge to the Marginal Treatment Effects literature.

</details>


### [45] [Reinforcement Learning and Consumption-Savings Behavior](https://arxiv.org/abs/2510.20748)
*Brandon Kaplowitz*

Main category: econ.GN

TL;DR: 本文通过强化学习模型解释了家庭在经济衰退期间消费行为的两个经验模式：失业家庭对刺激转移支付的边际消费倾向更高，以及有过失业经历的家庭消费水平持续较低。


<details>
  <summary>Details</summary>
Motivation: 解释家庭消费行为中两个令人困惑的经验模式：失业家庭对刺激转移支付的高边际消费倾向，以及失业经历对消费的持久影响，这些现象难以用标准理性预期模型解释。

Method: 开发了一个Q学习与神经网络逼近的强化学习模型，家庭在收入不确定性下进行消费-储蓄决策，突破了标准理性预期假设。

Result: 模型成功复制了两个关键发现：低流动性资产失业家庭的边际消费倾向显著更高（0.50 vs 0.34），以及有过失业经历的家庭消费水平持续较低，模拟结果与实证估计高度吻合。

Conclusion: 强化学习机制通过价值函数逼近误差提供了一个统一框架，解释了过往经历如何影响当前消费行为，超越了当前经济条件的预测能力。

Abstract: This paper demonstrates how reinforcement learning can explain two puzzling
empirical patterns in household consumption behavior during economic downturns.
I develop a model where agents use Q-learning with neural network approximation
to make consumption-savings decisions under income uncertainty, departing from
standard rational expectations assumptions. The model replicates two key
findings from recent literature: (1) unemployed households with previously low
liquid assets exhibit substantially higher marginal propensities to consume
(MPCs) out of stimulus transfers compared to high-asset households (0.50 vs
0.34), even when neither group faces borrowing constraints, consistent with
Ganong et al. (2024); and (2) households with more past unemployment
experiences maintain persistently lower consumption levels after controlling
for current economic conditions, a "scarring" effect documented by Malmendier
and Shen (2024). Unlike existing explanations based on belief updating about
income risk or ex-ante heterogeneity, the reinforcement learning mechanism
generates both higher MPCs and lower consumption levels simultaneously through
value function approximation errors that evolve with experience. Simulation
results closely match the empirical estimates, suggesting that adaptive
learning through reinforcement learning provides a unifying framework for
understanding how past experiences shape current consumption behavior beyond
what current economic conditions would predict.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [46] [Quantifying Feature Importance for Online Content Moderation](https://arxiv.org/abs/2510.19882)
*Benedetta Tessa,Alejandro Moreo,Stefano Cresci,Tiziano Fagni,Fabrizio Sebastiani*

Main category: cs.CY

TL;DR: 该研究通过量化分析方法，识别了753个用户特征中哪些最能预测Reddit用户在内容审核干预后的行为变化，发现少量特征对所有行为变化预测都有用，而大多数特征要么任务特定要么效用有限。


<details>
  <summary>Details</summary>
Motivation: 准确估计用户对内容审核干预的反应对于制定有效和以用户为中心的审核策略至关重要，这需要清楚了解哪些用户特征与不同的行为反应相关。

Method: 采用量化分析框架，对16.8K名受Reddit重大审核干预影响的用户，应用贪婪特征选择策略，分析753个社会行为、语言、关系和心理特征在预测用户活动、毒性和参与多样性变化方面的信息量。

Result: 识别出一小组在所有任务中始终具有信息量的特征，发现许多其他特征要么任务特定要么效用有限。预测性能因任务而异，活动和毒性变化比多样性变化更容易估计。

Conclusion: 研究结果为开发准确预测用户对审核干预反应的系统铺平了道路，同时强调了审核后用户行为的复杂性，表明有效的审核不仅应根据用户特征定制，还应考虑干预的具体目标。

Abstract: Accurately estimating how users respond to moderation interventions is
paramount for developing effective and user-centred moderation strategies.
However, this requires a clear understanding of which user characteristics are
associated with different behavioural responses, which is the goal of this
work. We investigate the informativeness of 753 socio-behavioural, linguistic,
relational, and psychological features, in predicting the behavioural changes
of 16.8K users affected by a major moderation intervention on Reddit. To reach
this goal, we frame the problem in terms of "quantification", a task
well-suited to estimating shifts in aggregate user behaviour. We then apply a
greedy feature selection strategy with the double goal of (i) identifying the
features that are most predictive of changes in user activity, toxicity, and
participation diversity, and (ii) estimating their importance. Our results
allow identifying a small set of features that are consistently informative
across all tasks, and determining that many others are either task-specific or
of limited utility altogether. We also find that predictive performance varies
according to the task, with changes in activity and toxicity being easier to
estimate than changes in diversity. Overall, our results pave the way for the
development of accurate systems that predict user reactions to moderation
interventions. Furthermore, our findings highlight the complexity of
post-moderation user behaviour, and indicate that effective moderation should
be tailored not only to user traits but also to the specific objective of the
intervention.

</details>


### [47] [Synthetic social data: trials and tribulations](https://arxiv.org/abs/2510.19952)
*Guido Ivetta,Laura Moradbakhti,Rafael A. Calvo*

Main category: cs.CY

TL;DR: 比较六种LLM生成的社会价值观数据与真实人类调查数据，发现即使小而有偏的人类样本也比AI合成数据更可靠


<details>
  <summary>Details</summary>
Motivation: 探索LLM生成的社会价值观数据是否比真实人类调查数据更可靠，评估算法偏见是否超过现实世界抽样偏见

Method: 比较四个国家（英国、阿根廷、美国和中国）的六种LLM生成的社会价值观数据与真实人类调查数据，涵盖开源和闭源模型

Result: 尽管人类调查存在后勤和财务限制，但即使是小而有偏的真实受访者样本也能提供比LLM合成数据更可靠的见解

Conclusion: AI生成文本在社会研究中存在局限性，强调继续收集经验性人类数据的重要性

Abstract: Large Language Models are being used in conversational agents that simulate
human conversations and generate social studies data. While concerns about the
models' biases have been raised and discussed in the literature, much about the
data generated is still unknown. In this study we explore the statistical
representation of social values across four countries (UK, Argentina, USA and
China) for six LLMs, with equal representation for open and closed weights. By
comparing machine-generated outputs with actual human survey data, we assess
whether algorithmic biases in LLMs outweigh the biases inherent in real- world
sampling, including demographic and response biases. Our findings suggest that,
despite the logistical and financial constraints of human surveys, even a
small, skewed sample of real respondents may provide more reliable insights
than synthetic data produced by LLMs. These results highlight the limitations
of using AI-generated text for social research and emphasize the continued
importance of empirical human data collection.

</details>


### [48] [Ask What Your Country Can Do For You: Towards a Public Red Teaming Model](https://arxiv.org/abs/2510.20061)
*Wm. Matthew Kennedy,Cigdem Patlak,Jayraj Dave,Blake Chambers,Aayush Dhanotiya,Darshini Ramiah,Reva Schwartz,Jack Hagen,Akash Kundu,Mouni Pendharkar,Liam Baisley,Theodora Skeadas,Rumman Chowdhury*

Main category: cs.CY

TL;DR: 本文提出合作式公共AI红队测试方法，以解决AI系统风险评估不足的问题，并通过多个试点项目验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在高风险领域应用增加，现有评估方法难以提供有效监督，需要新的方法来缩小责任差距。

Method: 采用合作式公共AI红队测试方法，结合CAMLIS 2024现场演示、NIST ARIA试点和新加坡IMDA类似测试。

Result: 该方法能够产生有意义的评估结果，并证明可在多个AI发展司法管辖区扩展实施。

Conclusion: 合作式公共AI红队测试是解决AI系统风险监督不足的有效且可扩展的方法。

Abstract: AI systems have the potential to produce both benefits and harms, but without
rigorous and ongoing adversarial evaluation, AI actors will struggle to assess
the breadth and magnitude of the AI risk surface. Researchers from the field of
systems design have developed several effective sociotechnical AI evaluation
and red teaming techniques targeting bias, hate speech, mis/disinformation, and
other documented harm classes. However, as increasingly sophisticated AI
systems are released into high-stakes sectors (such as education, healthcare,
and intelligence-gathering), our current evaluation and monitoring methods are
proving less and less capable of delivering effective oversight.
  In order to actually deliver responsible AI and to ensure AI's harms are
fully understood and its security vulnerabilities mitigated, pioneering new
approaches to close this "responsibility gap" are now more urgent than ever. In
this paper, we propose one such approach, the cooperative public AI red-teaming
exercise, and discuss early results of its prior pilot implementations. This
approach is intertwined with CAMLIS itself: the first in-person public
demonstrator exercise was held in conjunction with CAMLIS 2024. We review the
operational design and results of this exercise, the prior National Institute
of Standards and Technology (NIST)'s Assessing the Risks and Impacts of AI
(ARIA) pilot exercise, and another similar exercise conducted with the
Singapore Infocomm Media Development Authority (IMDA). Ultimately, we argue
that this approach is both capable of delivering meaningful results and is also
scalable to many AI developing jurisdictions.

</details>


### [49] [Dependency-Aware Task Offloading in Multi-UAV Assisted Collaborative Mobile Edge Computing](https://arxiv.org/abs/2510.20149)
*Zhenyu Zhao,Xiaoxia Xu,Tiankui Zhang,Junjie Li,Yuanwei Liu*

Main category: cs.CY

TL;DR: 提出了一种多无人机辅助协作移动边缘计算框架，可将终端设备任务分解为串行或并行子任务卸载到协作无人机，通过PDD-SCA算法联合优化子任务卸载、资源分配和无人机轨迹，最小化系统成本。


<details>
  <summary>Details</summary>
Motivation: 解决终端设备计算任务卸载到多无人机系统时的复杂依赖关系、资源分配和轨迹优化问题，实现任务延迟和能耗之间的平衡。

Method: 使用有向无环图建模子任务依赖关系，设计两时间尺度框架解耦子任务调度，开发PDD-SCA算法将原始MINLP问题转化为连续形式并分解为三个嵌套子问题求解。

Result: 相比基准算法，所提方案显著降低系统成本，在任务延迟和能耗之间实现更好权衡，并能有效平衡多无人机间的计算负载。

Conclusion: 该多无人机协作MEC框架通过联合优化子任务卸载、资源分配和轨迹规划，能够有效降低系统成本并实现负载均衡。

Abstract: This paper proposes a novel multi-unmanned aerial vehicle (UAV) assisted
collaborative mobile edge computing (MEC) framework, where the computing tasks
of terminal devices (TDs) can be decomposed into serial or parallel sub-tasks
and offloaded to collaborative UAVs. We first model the dependencies among all
sub-tasks as a directed acyclic graph (DAG) and design a two-timescale frame
structure to decouple the sub-task interdependencies for sub-task scheduling.
Then, a joint sub-task offloading, computational resource allocation, and UAV
trajectories optimization problem is formulated, which aims to minimize the
system cost, i.e., the weighted sum of the task completion delay and the system
energy consumption. To solve this non-convex mixed-integer nonlinear
programming (MINLP) problem, a penalty dual decomposition and successive convex
approximation (PDD-SCA) algorithm is developed. Particularly, the original
MINLP problem is equivalently transferred into a continuous form relying on PDD
theory. By decoupling the resulting problem into three nested subproblems, the
SCA method is further combined to recast the non-convex components and obtain
desirable solutions. Numerical results demonstrate that: 1) Compared to the
benchmark algorithms, the proposed scheme can significantly reduce the system
cost, and thus realize an improved trade-off between task latency and energy
consumption; 2) The proposed algorithm can achieve an efficient workload
balancing for distributed computation across multiple UAVs.

</details>


### [50] [Towards AI Agents for Course Instruction in Higher Education: Early Experiences from the Field](https://arxiv.org/abs/2510.20255)
*Yogesh Simmhan,Varad Kulkarni*

Main category: cs.CY

TL;DR: 本文介绍了在IISc研究生云计算课程中部署基于AI的教育代理作为主要讲师的早期研究结果，包括LLM驱动的讲师代理设计、教学框架和分析框架。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过结构化整合对话式AI代理来促进反思性学习，为在真实课堂环境中研究参与度提供可复制的方法，并支持可扩展的高质量高等教育。

Method: 设计LLM驱动的讲师代理，集成到课程工作流程中负责内容交付，人类讲师提供课程结构和答疑；提出基于主题覆盖度、主题深度和轮次阐述的可解释参与度指标的分析框架。

Result: 学生与代理互动探索概念、澄清疑问并维持探究驱动的对话；两个连续教学模块的分析显示参与度从广泛概念探索向更深入、聚焦的探究过渡。

Conclusion: 结构化整合对话式AI代理能够培养反思性学习，为真实课堂环境中的参与度研究提供可复制方法，并支持可扩展的高质量高等教育。

Abstract: This article presents early findings from designing, deploying and evaluating
an AI-based educational agent deployed as the primary instructor in a
graduate-level Cloud Computing course at IISc. We detail the design of a Large
Language Model (LLM)-driven Instructor Agent, and introduce a pedagogical
framework that integrates the Instructor Agent into the course workflow for
actively interacting with the students for content delivery, supplemented by
the human instructor to offer the course structure and undertake
question--answer sessions. We also propose an analytical framework that
evaluates the Agent--Student interaction transcripts using interpretable
engagement metrics of topic coverage, topic depth and turn-level elaboration.
We report early experiences on how students interact with the Agent to explore
concepts, clarify doubts and sustain inquiry-driven dialogue during live
classroom sessions. We also report preliminary analysis on our evaluation
metrics applied across two successive instructional modules that reveals
patterns of engagement evolution, transitioning from broad conceptual
exploration to deeper, focused inquiry. These demonstrate how structured
integration of conversational AI agents can foster reflective learning, offer a
reproducible methodology for studying engagement in authentic classroom
settings, and support scalable, high-quality higher education.

</details>


### [51] [What do AI-Generated Images Want?](https://arxiv.org/abs/2510.20350)
*Amanda Wasielewski*

Main category: cs.CY

TL;DR: 本文基于W.J.T.米切尔的"图片想要什么"理论，探讨AI生成图像的内在需求，认为AI图像渴望具体性和实体性，因为它们本质上是抽象的。


<details>
  <summary>Details</summary>
Motivation: 将米切尔关于图片具有能动性的理论应用于当代AI图像生成工具，探索AI生成图像的内在需求和特性。

Method: 通过艺术史关于抽象本质的论述，分析多模态文本到图像模型的工作原理，揭示文本和图像在数学表示上的可互换性。

Result: 发现AI生成图像本质上是抽象的，它们渴望具体性和实体性，而用户界面掩盖了这种表征回归，使转换过程看似魔法。

Conclusion: AI图像生成工具创造了一种抽象与具体之间的张力，AI图像的内在需求指向了它们想要摆脱抽象状态、获得具体性的渴望。

Abstract: W.J.T. Mitchell's influential essay 'What do pictures want?' shifts the
theoretical focus away from the interpretative act of understanding pictures
and from the motivations of the humans who create them to the possibility that
the picture itself is an entity with agency and wants. In this article, I
reframe Mitchell's question in light of contemporary AI image generation tools
to ask: what do AI-generated images want? Drawing from art historical discourse
on the nature of abstraction, I argue that AI-generated images want specificity
and concreteness because they are fundamentally abstract. Multimodal
text-to-image models, which are the primary subject of this article, are based
on the premise that text and image are interchangeable or exchangeable tokens
and that there is a commensurability between them, at least as represented
mathematically in data. The user pipeline that sees textual input become visual
output, however, obscures this representational regress and makes it seem like
one form transforms into the other -- as if by magic.

</details>


### [52] [Black Box Absorption: LLMs Undermining Innovative Ideas](https://arxiv.org/abs/2510.20612)
*Wenjun Cao*

Main category: cs.CY

TL;DR: 论文识别并形式化了大语言模型平台中的系统风险"黑箱吸收"，即LLM平台的不透明内部架构可能吸收、泛化和重新利用用户在交互中贡献的新概念，威胁创新生态系统的可持续性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型被广泛采用来加速创新，需要识别和应对由此产生的系统性风险，特别是平台不透明架构对用户创新概念的吸收和再利用，这可能破坏创新经济的基本原则。

Method: 引入两个核心概念："思想单元"（表示创新的可传输功能逻辑）和"思想安全"（保护创新的多维标准），分析吸收机制并提出治理和工程议程。

Result: 识别了黑箱吸收风险，提出了确保创作者贡献可追踪、可控制和公平的具体解决方案框架。

Conclusion: 需要建立治理和工程机制来减轻黑箱吸收风险，保护创新生态系统，确保创作者权益和创新的可持续性。

Abstract: Large Language Models are increasingly adopted as critical tools for
accelerating innovation. This paper identifies and formalizes a systemic risk
inherent in this paradigm: \textbf{Black Box Absorption}. We define this as the
process by which the opaque internal architectures of LLM platforms, often
operated by large-scale service providers, can internalize, generalize, and
repurpose novel concepts contributed by users during interaction. This
mechanism threatens to undermine the foundational principles of innovation
economics by creating severe informational and structural asymmetries between
individual creators and platform operators, thereby jeopardizing the long-term
sustainability of the innovation ecosystem. To analyze this challenge, we
introduce two core concepts: the idea unit, representing the transportable
functional logic of an innovation, and idea safety, a multidimensional standard
for its protection. This paper analyzes the mechanisms of absorption and
proposes a concrete governance and engineering agenda to mitigate these risks,
ensuring that creator contributions remain traceable, controllable, and
equitable.

</details>


### [53] [The Order of Recommendation Matters: Structured Exploration for Improving the Fairness of Content Creators](https://arxiv.org/abs/2510.20698)
*Salima Jaoua,Nicolò Pagan,Anikó Hannák,Stefania Ionescu*

Main category: cs.CY

TL;DR: 该论文研究了社交媒体推荐系统对内容创作者收入公平性的影响，提出使用有序成对比较方法来解决创作者公平性问题，同时保持用户满意度。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台为内容创作者提供收入来源，但推荐系统可能不公平地分配流量和收入。现有研究表明高质量内容不一定获得最多关注和收入，但缺乏针对性解决方案。

Method: 使用理论分析和合成数据集模拟，提出有序成对比较方法克服新项目的冷启动问题。在MovieLens数据集上测试干预效果，研究在存在历史偏见平台上的有效性。

Result: 有序成对比较方法显著提高所有内容创作者获得公平结果的机会，同时保持用户满意度。在平台早期阶段部署时效果最好，但随着已有偏见强度增加效果减弱。

Conclusion: 有序成对比较方法为新建和现有平台提供了一个可行的替代方案，能够改善创作者公平性。

Abstract: Social media platforms provide millions of professional content creators with
sustainable incomes. Their income is largely influenced by their number of
views and followers, which in turn depends on the platform's recommender system
(RS). So, as with regular jobs, it is important to ensure that RSs distribute
revenue in a fair way. For example, prior work analyzed whether the creators of
the highest-quality content would receive the most followers and income.
Results showed this is unlikely to be the case, but did not suggest targeted
solutions. In this work, we first use theoretical analysis and simulations on
synthetic datasets to understand the system better and find interventions that
improve fairness for creators. We find that the use of ordered pairwise
comparison overcomes the cold start problem for a new set of items and greatly
increases the chance of achieving fair outcomes for all content creators.
Importantly, it also maintains user satisfaction. We also test the intervention
on the MovieLens dataset and investigate its effectiveness on platforms with
interaction histories that are currently unfair for content creators. These
experiments reveal that the intervention improves fairness when deployed at
early stages of the platform, but the effect decreases as the strength of
pre-existing bias increases. Altogether, we find that the ordered pairwise
comparison approach might offer a plausible alternative for both new and
existing platforms to implement.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [54] [Configuration-Dependent Robot Kinematics Model and Calibration](https://arxiv.org/abs/2510.19962)
*Chen-Lung Lu,Honglu He,Agung Julius,John T. Wen*

Main category: cs.RO

TL;DR: 提出一种基于配置依赖的机器人运动学校准框架，使用局部POE模型和傅里叶基函数插值，显著提高工业机器人的定位精度。


<details>
  <summary>Details</summary>
Motivation: 机器人精确运动学对于工具精确定位至关重要，但非几何因素会导致配置依赖的模型差异，需要改进整个工作空间的精度。

Method: 在多个配置点识别局部POE模型，使用基于肩肘关节角的傅里叶基函数进行插值，构建全局模型。

Result: 在两种6自由度工业机器人上验证，最大定位误差减少超过50%，达到亚毫米级精度要求，训练效率显著高于神经网络方法。

Conclusion: 该方法有效解决配置依赖的运动学误差问题，特别适用于冷喷涂制造等需要高精度的应用场景，具有实际应用价值。

Abstract: Accurate robot kinematics is essential for precise tool placement in
articulated robots, but non-geometric factors can introduce
configuration-dependent model discrepancies. This paper presents a
configuration-dependent kinematic calibration framework for improving accuracy
across the entire workspace. Local Product-of-Exponential (POE) models,
selected for their parameterization continuity, are identified at multiple
configurations and interpolated into a global model. Inspired by joint gravity
load expressions, we employ Fourier basis function interpolation parameterized
by the shoulder and elbow joint angles, achieving accuracy comparable to neural
network and autoencoder methods but with substantially higher training
efficiency. Validation on two 6-DoF industrial robots shows that the proposed
approach reduces the maximum positioning error by over 50%, meeting the
sub-millimeter accuracy required for cold spray manufacturing. Robots with
larger configuration-dependent discrepancies benefit even more. A dual-robot
collaborative task demonstrates the framework's practical applicability and
repeatability.

</details>


### [55] [Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC](https://arxiv.org/abs/2510.19974)
*Hien Bui,Yufeiyang Gao,Haoran Yang,Eric Cui,Siddhant Mody,Brian Acosta,Thomas Stephen Felix,Bibit Bianchini,Michael Posa*

Main category: cs.RO

TL;DR: 提出了C3+算法，一种增强的接触隐式模型预测控制方法，能够在多物体平面推动任务中实现实时性能，成功率达到98%。


<details>
  <summary>Details</summary>
Motivation: 解决非抓取式操作中物体物理属性未知和接触丰富交互复杂性的核心挑战，扩展CI-MPC方法在多样化物体几何和多物体场景中的应用能力。

Method: 引入共识互补控制增强版(C3+)，整合了物体扫描、网格重建和硬件执行的完整流程，相比前代C3显著提高了求解速度。

Result: 在33个物体上达到98%的成功率，单物体任务平均耗时约0.5分钟，2、3、4物体任务分别耗时1.6、3.2和5.3分钟。

Conclusion: C3+算法能够有效处理多物体推动任务，实现了接触隐式控制在复杂场景中的实时应用。

Abstract: Non-prehensile manipulation of diverse objects remains a core challenge in
robotics, driven by unknown physical properties and the complexity of
contact-rich interactions. Recent advances in contact-implicit model predictive
control (CI-MPC), with contact reasoning embedded directly in the trajectory
optimization, have shown promise in tackling the task efficiently and robustly,
yet demonstrations have been limited to narrowly curated examples. In this
work, we showcase the broader capabilities of CI-MPC through precise planar
pushing tasks over a wide range of object geometries, including multi-object
domains. These scenarios demand reasoning over numerous inter-object and
object-environment contacts to strategically manipulate and de-clutter the
environment, challenges that were intractable for prior CI-MPC methods. To
achieve this, we introduce Consensus Complementarity Control Plus (C3+), an
enhanced CI-MPC algorithm integrated into a complete pipeline spanning object
scanning, mesh reconstruction, and hardware execution. Compared to its
predecessor C3, C3+ achieves substantially faster solve times, enabling
real-time performance even in multi-object pushing tasks. On hardware, our
system achieves overall 98% success rate across 33 objects, reaching pose goals
within tight tolerances. The average time-to-goal is approximately 0.5, 1.6,
3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project
page: https://dairlab.github.io/push-anything.

</details>


### [56] [Simultaneous learning of state-to-state minimum-time planning and control](https://arxiv.org/abs/2510.20008)
*Swati Dantu,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 提出基于强化学习的框架，学习无人机任意状态间的最小时间飞行策略，结合敏捷飞行和稳定悬停，并在真实环境中验证其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统自主无人机竞速方法受限于预定义轨道布局，难以在现实世界中广泛应用。需要开发能处理任意起点-目标状态对的最小时间飞行策略。

Method: 使用强化学习框架，以点质量模型轨迹作为代理奖励来近似最优飞行目标，并采用课程学习来高效扩展训练过程和实现泛化。

Result: 仿真实验显示该方法优于非线性模型预测控制跟踪点质量模型轨迹，真实环境实验验证了学习策略在户外环境中的鲁棒性和泛化能力。

Conclusion: 所提出的强化学习方法成功实现了通用最小时间飞行策略，能在小型ARM单板计算机上运行，为无人机在复杂环境中的自主飞行提供了可行解决方案。

Abstract: This paper tackles the challenge of learning a generalizable minimum-time
flight policy for UAVs, capable of navigating between arbitrary start and goal
states while balancing agile flight and stable hovering. Traditional
approaches, particularly in autonomous drone racing, achieve impressive speeds
and agility but are constrained to predefined track layouts, limiting
real-world applicability. To address this, we propose a reinforcement
learning-based framework that simultaneously learns state-to-state minimum-time
planning and control and generalizes to arbitrary state-to-state flights. Our
approach leverages Point Mass Model (PMM) trajectories as proxy rewards to
approximate the true optimal flight objective and employs curriculum learning
to scale the training process efficiently and to achieve generalization. We
validate our method through simulation experiments, comparing it against
Nonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories
and conducting ablation studies to assess the impact of curriculum learning.
Finally, real-world experiments confirm the robustness of our learned policy in
outdoor environments, demonstrating its ability to generalize and operate on a
small ARM-based single-board computer.

</details>


### [57] [Calibration of Parallel Kinematic Machine Based on Stewart Platform-A Literature Review](https://arxiv.org/abs/2510.20070)
*Sourabh Karmakar,Apurva Patel,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文综述了基于逆运动学的Stewart平台并联运动学机器校准方法，分析了外部仪器、约束和自校准三种主要方法，发现现有研究主要关注无负载条件下的结构误差校准。


<details>
  <summary>Details</summary>
Motivation: Stewart平台并联运动学机器在精密应用中需要微纳米级运动控制，必须比应用精度更高，因此校准至关重要。正向运动学校准复杂，而逆运动学方法更简便。

Method: 通过综述外部仪器、约束和自校准三种关键方法，分析逆运动学为基础的PKM校准技术、成果及相关要点。

Result: 研究发现研究者主要关注平台位置和方向精度的提升，考虑单一或多误差源，主要是结构误差，部分考虑环境因素，但都在无负载条件下进行校准。

Conclusion: 本研究旨在了解该领域当前技术水平，为其他研究者在特定领域的进一步探索提供参考和扩展空间。

Abstract: Stewart platform-based Parallel Kinematic (PKM) Machines have been
extensively studied by researchers due to their inherent finer control
characteristics. This has opened its potential deployment opportunities in
versatile critical applications like the medical field, engineering machines,
space research, electronic chip manufacturing, automobile manufacturing, etc.
All these precise, complicated, and repeatable motion applications require
micro and nano-scale movement control in 3D space; a 6-DOF PKM can take this
challenge smartly. For this, the PKM must be more accurate than the desired
application accuracy level and thus proper calibration for a PKM robot is
essential. Forward kinematics-based calibration for such hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To analyze different techniques, an external instrument-based,
constraint-based, and auto or self-calibration-based approaches have been used
for calibration. This survey has been done by reviewing these key
methodologies, their outcome, and important points related to inverse
kinematic-based PKM calibrations in general. It is observed in this study that
the researchers focused on improving the accuracy of the platform position and
orientation considering the errors contributed by a single source or multiple
sources. The error sources considered are mainly structural, in some cases,
environmental factors are also considered, however, these calibrations are done
under no-load conditions. This study aims to understand the current state of
the art in this field and to expand the scope for other researchers in further
exploration in a specific area.

</details>


### [58] [Design of a Bed Rotation Mechanism to Facilitate In-Situ Photogrammetric Reconstruction of Printed Parts](https://arxiv.org/abs/2510.20079)
*Travis A. Roberts,Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 设计并制造了一种用于聚合物FDM工艺研究的3D打印机平台，具有精确参数控制和原位摄影测量功能，特别关注实现最少相机数量下摄影测量重建的新型加热床旋转机构。


<details>
  <summary>Details</summary>
Motivation: 商用和消费级3D打印机缺乏研究所需的参数控制和灵活性，需要开发一个能够精确控制和监控FDM工艺参数的开源研究平台。

Method: 设计并制造了具有闭环位置反馈、温度控制、环境监测功能的FDM平台，并开发了新型加热床旋转机构，通过原位摄影测量技术记录打印过程中的几何变化。

Result: 成功创建了一个能够精确控制FDM工艺参数的研究平台，实现了最少相机数量下的摄影测量重建，能够回溯和关联工艺参数与几何缺陷。

Conclusion: 该平台为聚合物FDM工艺研究提供了可靠的测试环境，通过创新的旋转床设计和原位监测系统，实现了工艺参数与打印质量的可追溯性分析。

Abstract: Additive manufacturing, or 3D printing, is a complex process that creates
free-form geometric objects by sequentially placing material to construct an
object, usually in a layer-by-layer process. One of the most widely used
methods is Fused Deposition Modeling (FDM). FDM is used in many of the
consumer-grade polymer 3D printers available today. While consumer grade
machines are cheap and plentiful, they lack many of the features desired in a
machine used for research purposes and are often closed-source platforms.
Commercial-grade models are more expensive and are also usually closed-source
platforms that do not offer flexibility for modifications often needed for
research. The authors designed and fabricated a machine to be used as a test
bed for research in the field of polymer FDM processes. The goal was to create
a platform that tightly controls and/or monitors the FDM build parameters so
that experiments can be repeated with a known accuracy. The platform offers
closed loop position feedback, control of the hot end and bed temperature, and
monitoring of environment temperature and humidity. Additionally, the platform
is equipped with cameras and a mechanism for in-situ photogrammetry, creating a
geometric record of the printing throughout the printing process. Through
photogrammetry, backtracking and linking process parameters to observable
geometric defects can be achieved. This paper focuses on the design of a novel
mechanism for spinning the heated bed to allow for photogrammetric
reconstruction of the printed part using a minimal number of cameras, as
implemented on this platform.

</details>


### [59] [PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation](https://arxiv.org/abs/2510.20161)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: 提出基于路径的Transformer模型，通过3网格表示和约束掩码解码生成机器人轨迹，在53,755条轨迹上训练，达到高精度和99.99%合法路径，在真实机器人测试中实现86.7%端到端成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人手臂需要精确的任务感知轨迹规划，但忽略运动结构的序列模型常常产生无效或低效的执行。

Method: 使用基于路径的Transformer，采用3网格（位置/内容/时间）表示机器人运动，通过约束掩码解码强制相邻网格移动和工作空间边界，同时推理任务图和动作顺序。

Result: 在53,755条轨迹上训练，达到89.44%步骤准确率、93.32%精确率、89.44%召回率和90.40% F1分数，99.99%路径构造合法。在xArm Lite 6机器人上测试，达到97.5%到达成功率、92.5%抓取成功率，在60个语言指定任务中实现86.7%端到端成功率。

Conclusion: 路径结构表示使Transformer能够生成准确、可靠和可解释的机器人轨迹，桥接了基于图的规划和基于序列的学习，为通用操作和仿真到现实迁移提供了实用基础。

Abstract: Robotic arms require precise, task-aware trajectory planning, yet sequence
models that ignore motion structure often yield invalid or inefficient
executions. We present a Path-based Transformer that encodes robot motion with
a 3-grid (where/what/when) representation and constraint-masked decoding,
enforcing lattice-adjacent moves and workspace bounds while reasoning over task
graphs and action order. Trained on 53,755 trajectories (80% train / 20%
validation), the model aligns closely with ground truth -- 89.44% stepwise
accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of
paths legal by construction. Compiled to motor primitives on an xArm Lite 6
with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick
success in controlled tests, and 86.7% end-to-end success across 60
language-specified tasks in cluttered scenes, absorbing slips and occlusions
via local re-grounding without global re-planning. These results show that
path-structured representations enable Transformers to generate accurate,
reliable, and interpretable robot trajectories, bridging graph-based planning
and sequence-based learning and providing a practical foundation for
general-purpose manipulation and sim-to-real transfer.

</details>


### [60] [Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment](https://arxiv.org/abs/2510.20174)
*Yong Um,Young-Ha Shin,Joon-Ha Kim,Soonpyo Kwon,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出了一种针对四足磁吸附爬壁机器人的强化学习框架，通过物理吸附模型和分阶段课程学习，解决了磁脚吸附不确定性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 磁吸附爬壁机器人在实际应用中面临吸附不确定性、部分接触和概率性吸附失败等问题，传统控制方法假设完美吸附难以应对这些挑战。

Method: 构建物理吸附模型模拟部分接触和吸附失败，采用三阶段课程学习：平地爬行训练、重力旋转激活吸附、注入随机吸附失败训练恢复能力。

Result: 学习策略在仿真中实现高成功率、强吸附保持和快速脱落恢复，优于假设完美吸附的MPC基线。硬件实验证实了在钢表面的稳健垂直爬行能力。

Conclusion: 结合课程学习和真实吸附建模为磁吸附爬壁机器人提供了弹性的仿真到现实框架，适用于复杂环境。

Abstract: We present a reinforcement learning framework for quadrupedal wall-climbing
locomotion that explicitly addresses uncertainty in magnetic foot adhesion. A
physics-based adhesion model of a quadrupedal magnetic climbing robot is
incorporated into simulation to capture partial contact, air-gap sensitivity,
and probabilistic attachment failures. To stabilize learning and enable
reliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait
on flat ground without adhesion, (2) gradually rotate the gravity vector to
vertical while activating the adhesion model, and (3) inject stochastic
adhesion failures to encourage slip recovery. The learned policy achieves a
high success rate, strong adhesion retention, and rapid recovery from
detachment in simulation under degraded adhesion. Compared with a model
predictive control (MPC) baseline that assumes perfect adhesion, our controller
maintains locomotion when attachment is intermittently lost. Hardware
experiments with the untethered robot further confirm robust vertical crawling
on steel surfaces, maintaining stability despite transient misalignment and
incomplete attachment. These results show that combining curriculum learning
with realistic adhesion modeling provides a resilient sim-to-real framework for
magnetic climbing robots in complex environments.

</details>


### [61] [A Contact-Driven Framework for Manipulating in the Blind](https://arxiv.org/abs/2510.20177)
*Muhammad Suhail Saleem,Lai Yuan,Maxim Likhachev*

Main category: cs.RO

TL;DR: 提出了一个在视觉受限环境中进行机器人操作的完整框架，通过结合接触反馈和结构先验，实现在未知环境中的鲁棒操作。


<details>
  <summary>Details</summary>
Motivation: 机器人在视觉受限环境（如遮挡、光线不足）中执行操作任务时，需要依赖接触反馈来感知环境，同时利用结构先验来预测未观察到的结构，避免不必要的碰撞。

Method: 框架包含三个紧密耦合的组件：(1) 基于关节扭矩传感和接触粒子滤波器的接触检测与定位模块；(2) 利用接触历史构建部分占据地图并通过学习预测器推断未探索区域的占据估计模块；(3) 考虑噪声的接触定位和占据预测，计算避免碰撞且高效完成任务的路径规划模块。

Result: 在仿真和真实UR10e机械臂上的评估显示，该框架能可靠完成两个家庭任务（厨房水槽下操作阀门和从杂乱货架上取物），任务完成时间相比基线最多减少2倍，消融实验验证了各模块的贡献。

Conclusion: 该框架成功整合了接触反馈和结构先验，为视觉受限环境中的机器人操作提供了理论完备且经验高效的解决方案。

Abstract: Robots often face manipulation tasks in environments where vision is
inadequate due to clutter, occlusions, or poor lighting--for example, reaching
a shutoff valve at the back of a sink cabinet or locating a light switch above
a crowded shelf. In such settings, robots, much like humans, must rely on
contact feedback to distinguish free from occupied space and navigate around
obstacles. Many of these environments often exhibit strong structural
priors--for instance, pipes often span across sink cabinets--that can be
exploited to anticipate unseen structure and avoid unnecessary collisions. We
present a theoretically complete and empirically efficient framework for
manipulation in the blind that integrates contact feedback with structural
priors to enable robust operation in unknown environments. The framework
comprises three tightly coupled components: (i) a contact detection and
localization module that utilizes joint torque sensing with a contact particle
filter to detect and localize contacts, (ii) an occupancy estimation module
that uses the history of contact observations to build a partial occupancy map
of the workspace and extrapolate it into unexplored regions with learned
predictors, and (iii) a planning module that accounts for the fact that contact
localization estimates and occupancy predictions can be noisy, computing paths
that avoid collisions and complete tasks efficiently without eliminating
feasible solutions. We evaluate the system in simulation and in the real world
on a UR10e manipulator across two domestic tasks--(i) manipulating a valve
under a kitchen sink surrounded by pipes and (ii) retrieving a target object
from a cluttered shelf. Results show that the framework reliably solves these
tasks, achieving up to a 2x reduction in task completion time compared to
baselines, with ablations confirming the contribution of each module.

</details>


### [62] [NODA-MMH: Certified Learning-Aided Nonlinear Control for Magnetically-Actuated Swarm Experiment Toward On-Orbit Proof](https://arxiv.org/abs/2510.20231)
*Yuta Takahashi,Atsuki Ochi,Yoichi Tomioka,Shin-Ichiro Sakai*

Main category: cs.RO

TL;DR: 该研究通过实验验证了基于学习辅助磁场相互作用的大规模卫星群控制原理，使用卫星安装的磁力矩器进行控制，解决了多卫星长期编队维护中的非完整约束、欠驱动、可扩展性和计算成本等挑战。


<details>
  <summary>Details</summary>
Motivation: 解决多卫星（超过三个）编队维护中的基本挑战：非完整约束、欠驱动、可扩展性和计算成本，这些挑战随着卫星数量增加而变得更加复杂。

Method: 采用学习辅助的时间积分电流控制方法，设计了两轴线圈和基于气浮平台的地面实验装置来模拟轨道动力学，并提出了NODA-MMH（神经功率最优偶极子分配认证学习模型磁群控制）进行模型驱动的功率最优群控制。

Result: 实验验证了学习辅助时间积分电流控制的两个关键方面：增强平均系统动力学的可控性（具有理论保证的误差界限）和分散式电流管理，证明了该方法的有效性。

Conclusion: 该研究为基于磁力驱动的大规模卫星群长期编队维护问题提供了实验验证和补充，展示了学习辅助控制在实际应用中的可行性。

Abstract: This study experimentally validates the principle of large-scale satellite
swarm control through learning-aided magnetic field interactions generated by
satellite-mounted magnetorquers. This actuation presents a promising solution
for the long-term formation maintenance of multiple satellites and has
primarily been demonstrated in ground-based testbeds for two-satellite position
control. However, as the number of satellites increases beyond three,
fundamental challenges coupled with the high nonlinearity arise: 1)
nonholonomic constraints, 2) underactuation, 3) scalability, and 4)
computational cost. Previous studies have shown that time-integrated current
control theoretically solves these problems, where the average actuator outputs
align with the desired command, and a learning-based technique further enhances
their performance. Through multiple experiments, we validate critical aspects
of learning-aided time-integrated current control: (1) enhanced controllability
of the averaged system dynamics, with a theoretically guaranteed error bound,
and (2) decentralized current management. We design two-axis coils and a
ground-based experimental setup utilizing an air-bearing platform, enabling a
mathematical replication of orbital dynamics. Based on the effectiveness of the
learned interaction model, we introduce NODA-MMH (Neural power-Optimal Dipole
Allocation for certified learned Model-based Magnetically swarm control
Harness) for model-based power-optimal swarm control. This study complements
our tutorial paper on magnetically actuated swarms for the long-term formation
maintenance problem.

</details>


### [63] [Kinaema: a recurrent sequence model for memory and pose in motion](https://arxiv.org/abs/2510.20261)
*Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf*

Main category: cs.RO

TL;DR: Kinaema模型通过隐式潜在记忆和循环Transformer处理视觉观察流，能够在大型场景中定位并导航到之前观察过的目标位置，相比传统基于观察历史的Transformer更高效。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在连续操作中利用先前观察信息进行自我定位和高效导航的问题，特别是在大型场景中如何压缩历史传感器数据为紧凑表示。

Method: 提出Kinaema模型，使用循环Transformer更新隐式潜在记忆，不显式存储观察历史，从而不受上下文长度限制。模型集成视觉观察流并处理查询图像以预测相对位置。

Result: 模型在Mem-Nav任务中表现出色，能够维持有用的场景表示，导航到实际情节开始前观察到的目标位置，计算效率优于基于观察历史注意力的传统Transformer。

Conclusion: Kinaema通过隐式记忆机制有效解决了连续机器人操作中的定位和导航问题，为大规模场景中的长期空间感知提供了高效解决方案。

Abstract: One key aspect of spatially aware robots is the ability to "find their
bearings", ie. to correctly situate themselves in previously seen spaces. In
this work, we focus on this particular scenario of continuous robotics
operations, where information observed before an actual episode start is
exploited to optimize efficiency. We introduce a new model, Kinaema, and agent,
capable of integrating a stream of visual observations while moving in a
potentially large scene, and upon request, processing a query image and
predicting the relative position of the shown space with respect to its current
position. Our model does not explicitly store an observation history, therefore
does not have hard constraints on context length. It maintains an implicit
latent memory, which is updated by a transformer in a recurrent way,
compressing the history of sensor readings into a compact representation. We
evaluate the impact of this model in a new downstream task we call "Mem-Nav".
We show that our large-capacity recurrent model maintains a useful
representation of the scene, navigates to goals observed before the actual
episode start, and is computationally efficient, in particular compared to
classical transformers with attention over an observation history.

</details>


### [64] [MemER: Scaling Up Memory for Robot Control via Experience Retrieval](https://arxiv.org/abs/2510.20328)
*Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出MemER框架，通过分层策略让机器人政策具备记忆能力：高层策略选择相关历史关键帧，结合最新帧生成指令给底层策略执行，兼容现有VLA模型，在需要分钟级记忆的长时程操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 人类依赖记忆执行任务，但现有机器人政策缺乏这种能力。直接使用长观察历史计算昂贵且脆弱，而简单采样历史信息会导致信息不相关或冗余。

Method: 分层策略框架：高层策略训练选择并跟踪历史相关关键帧，使用选定关键帧和最新帧为底层策略生成文本指令。基于Qwen2.5-VL-7B-Instruct和π0.5分别作为高低层策略，使用带最小语言标注的演示进行微调。

Result: MemER在三个需要分钟级记忆的真实世界长时程机器人操作任务中优于先前方法。

Conclusion: 该框架成功赋予机器人政策记忆能力，能高效处理长时程依赖关系，兼容现有VLA模型架构。

Abstract: Humans routinely rely on memory to perform tasks, yet most robot policies
lack this capability; our goal is to endow robot policies with the same
ability. Naively conditioning on long observation histories is computationally
expensive and brittle under covariate shift, while indiscriminate subsampling
of history leads to irrelevant or redundant information. We propose a
hierarchical policy framework, where the high-level policy is trained to select
and track previous relevant keyframes from its experience. The high-level
policy uses selected keyframes and the most recent frames when generating text
instructions for a low-level policy to execute. This design is compatible with
existing vision-language-action (VLA) models and enables the system to
efficiently reason over long-horizon dependencies. In our experiments, we
finetune Qwen2.5-VL-7B-Instruct and $\pi_{0.5}$ as the high-level and low-level
policies respectively, using demonstrations supplemented with minimal language
annotations. Our approach, MemER, outperforms prior methods on three real-world
long-horizon robotic manipulation tasks that require minutes of memory. Videos
and code can be found at https://jen-pan.github.io/memer/.

</details>


### [65] [Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking](https://arxiv.org/abs/2510.20335)
*Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren*

Main category: cs.RO

TL;DR: 提出Dino-Diffusion Parking (DDP)方法，结合视觉基础模型和扩散规划，实现领域无关的自动驾驶停车系统，在分布偏移下保持高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有端到端停车方法在领域偏移（如天气、光照变化）下的鲁棒性不足，需要一种不依赖额外数据的领域无关解决方案。

Method: 集成视觉基础模型进行泛化感知，使用基于扩散的规划进行鲁棒运动规划，在CARLA中训练并在对抗性设置中零样本迁移。

Result: 在所有测试的分布外场景中停车成功率超过90%，在3D高斯溅射重建的真实停车场中显示出有前景的仿真到真实迁移能力。

Conclusion: DDP通过视觉基础模型和扩散规划的组合，显著提升了跨领域停车性能，为自动驾驶停车提供了鲁棒的解决方案。

Abstract: Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

</details>


### [66] [Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots](https://arxiv.org/abs/2510.20347)
*Ashutosh Mishra,Shreya Santra,Elian Neppel,Edoardo M. Rossi Lombardi,Shamistan Karimov,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种去中心化强化学习方案，用于模块化可重构机器人的统一控制，实现了零样本泛化到未见配置的能力。


<details>
  <summary>Details</summary>
Motivation: 模块化可重构机器人适合特定空间任务，但形态组合爆炸阻碍了统一控制。

Method: 采用去中心化强化学习，轮式模块使用SAC进行运动控制，7自由度肢体使用PPO进行转向和操作。

Result: 转向策略平均绝对误差3.63度；操作策略成功率84.6%；轮式策略平均扭矩降低95.4%，成功率99.6%。月球模拟现场测试验证了零样本集成。

Conclusion: 系统在策略执行期间平滑切换同步、并行和顺序模式，无空闲状态或控制冲突，表明该方法对模块化月球机器人具有可扩展性、可重用性和鲁棒性。

Abstract: Modular reconfigurable robots suit task-specific space operations, but the
combinatorial growth of morphologies hinders unified control. We propose a
decentralized reinforcement learning (Dec-RL) scheme where each module learns
its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and
7-DoF limbs use Proximal Policy Optimization (PPO) for steering and
manipulation, enabling zero-shot generalization to unseen configurations. In
simulation, the steering policy achieved a mean absolute error of 3.63{\deg}
between desired and induced angles; the manipulation policy plateaued at 84.6 %
success on a target-offset criterion; and the wheel policy cut average motor
torque by 95.4 % relative to baseline while maintaining 99.6 % success.
Lunar-analogue field tests validated zero-shot integration for autonomous
locomotion, steering, and preliminary alignment for reconfiguration. The system
transitioned smoothly among synchronous, parallel, and sequential modes for
Policy Execution, without idle states or control conflicts, indicating a
scalable, reusable, and robust approach for modular lunar robots.

</details>


### [67] [NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control](https://arxiv.org/abs/2510.20390)
*Yijiong Lin,Bowen Deng,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: NeuralTouch是一个结合视觉（NDF）和触觉感知的多模态框架，通过轻柔物理交互实现精确、可泛化的抓取，显著提升了抓取精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：NDF单独使用时由于相机标定不完美、点云不完整和物体变化性会产生不准确姿态；而触觉感知方法通常局限于简单的预定义接触几何。需要结合两者优势实现精确抓取。

Method: 提出NeuralTouch框架：利用NDF隐式表示目标接触几何，基于此训练深度强化学习策略，使用触觉反馈来优化抓取姿态。策略以神经描述符为条件，无需显式指定接触类型。

Result: 在仿真中进行消融研究，并零样本迁移到真实世界操作任务（如孔轴装配和瓶盖开启），无需额外微调。结果显示NeuralTouch显著优于基线方法。

Conclusion: NeuralTouch为精确、接触丰富的机器人操作提供了一个通用框架，成功整合了视觉和触觉感知的优势。

Abstract: Grasping accuracy is a critical prerequisite for precise object manipulation,
often requiring careful alignment between the robot hand and object. Neural
Descriptor Fields (NDF) offer a promising vision-based method to generate
grasping poses that generalize across object categories. However, NDF alone can
produce inaccurate poses due to imperfect camera calibration, incomplete point
clouds, and object variability. Meanwhile, tactile sensing enables more precise
contact, but existing approaches typically learn policies limited to simple,
predefined contact geometries. In this work, we introduce NeuralTouch, a
multimodal framework that integrates NDF and tactile sensing to enable
accurate, generalizable grasping through gentle physical interaction. Our
approach leverages NDF to implicitly represent the target contact geometry,
from which a deep reinforcement learning (RL) policy is trained to refine the
grasp using tactile feedback. This policy is conditioned on the neural
descriptors and does not require explicit specification of contact types. We
validate NeuralTouch through ablation studies in simulation and zero-shot
transfer to real-world manipulation tasks--such as peg-out-in-hole and bottle
lid opening--without additional fine-tuning. Results show that NeuralTouch
significantly improves grasping accuracy and robustness over baseline methods,
offering a general framework for precise, contact-rich robotic manipulation.

</details>


### [68] [PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning](https://arxiv.org/abs/2510.20406)
*Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann*

Main category: cs.RO

TL;DR: PointMapPolicy是一种新颖的方法，通过在结构化点网格上调节扩散策略而不进行下采样，结合点云和RGB数据，实现增强的多模态感知，在机器人操作任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前点云方法难以捕捉细粒度细节，而RGB方法缺乏几何感知，这限制了它们在复杂任务中的精度和泛化能力。机器人操作系统需要结合不同感知模态的优势。

Method: 提出PointMapPolicy方法，在结构化点网格上调节扩散策略而不下采样，使用xLSTM作为骨干网络，有效融合点地图与RGB数据。

Result: 在RoboCasa和CALVIN基准测试以及真实机器人评估中，该方法在多样化操作任务上实现了最先进的性能。

Conclusion: PointMapPolicy通过结合点云和RGB数据的优势，提供了一种有效的多模态感知方法，显著提升了机器人操作的性能。

Abstract: Robotic manipulation systems benefit from complementary sensing modalities,
where each provides unique environmental information. Point clouds capture
detailed geometric structure, while RGB images provide rich semantic context.
Current point cloud methods struggle to capture fine-grained detail, especially
for complex tasks, which RGB methods lack geometric awareness, which hinders
their precision and generalization. We introduce PointMapPolicy, a novel
approach that conditions diffusion policies on structured grids of points
without downsampling. The resulting data type makes it easier to extract shape
and spatial relationships from observations, and can be transformed between
reference frames. Yet due to their structure in a regular grid, we enable the
use of established computer vision techniques directly to 3D data. Using xLSTM
as a backbone, our model efficiently fuses the point maps with RGB data for
enhanced multi-modal perception. Through extensive experiments on the RoboCasa
and CALVIN benchmarks and real robot evaluations, we demonstrate that our
method achieves state-of-the-art performance across diverse manipulation tasks.
The overview and demos are available on our project page:
https://point-map.github.io/Point-Map/

</details>


### [69] [MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control](https://arxiv.org/abs/2510.20407)
*Kohei Nishi,Masato Kobayashi,Yuki Uranishi*

Main category: cs.RO

TL;DR: 提出了一种基于混合现实的带有反应扭矩指示器的水下机器人手臂遥操作系统MR-UBi，通过双边控制将视觉和触觉反馈集成，显著提高了抓取扭矩控制精度和用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决水下机器人手臂遥操作中缺乏有效扭矩反馈的问题，通过混合现实技术提供直观的视觉反馈来增强操作稳定性和准确性。

Method: 开发了MR-UBi系统，在混合现实头戴显示器中叠加颜色和长度编码的扭矩条作为反应扭矩指示器，实现视觉和触觉反馈的无缝集成。

Result: 与双边控制基线相比，MR-UBi显著提高了抓取扭矩控制精度，增加了在最佳扭矩范围内的时间，减少了低和高抓取扭矩范围，在提升和拾放任务中表现更好。主观评估显示更高的可用性和更低的工作负荷。

Conclusion: MR-UBi通过视觉和触觉反馈的集成，实现了更稳定、准确和用户友好的水下机器人手臂遥操作。

Abstract: We present a mixed reality-based underwater robot arm teleoperation system
with a reaction torque indicator via bilateral control (MR-UBi). The reaction
torque indicator (RTI) overlays a color and length-coded torque bar in the
MR-HMD, enabling seamless integration of visual and haptic feedback during
underwater robot arm teleoperation. User studies with sixteen participants
compared MR-UBi against a bilateral-control baseline. MR-UBi significantly
improved grasping-torque control accuracy, increasing the time within the
optimal torque range and reducing both low and high grasping torque range
during lift and pick-and-place tasks with objects of different stiffness.
Subjective evaluations further showed higher usability (SUS) and lower workload
(NASA--TLX). Overall, the results confirm that \textit{MR-UBi} enables more
stable, accurate, and user-friendly underwater robot-arm teleoperation through
the integration of visual and haptic feedback. For additional material, please
check: https://mertcookimg.github.io/mr-ubi

</details>


### [70] [Robot Path and Trajectory Planning Considering a Spatially Fixed TCP](https://arxiv.org/abs/2510.20473)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller,Ronald Naderer*

Main category: cs.RO

TL;DR: 提出了一种在工作空间坐标系中规划轨迹的方法，使用空间固定的工具中心点(TCP)，同时考虑零件上的加工路径，特别适用于移动零件比移动工具更容易的场景。


<details>
  <summary>Details</summary>
Motivation: 当移动零件比移动工具更容易时，需要一种能够考虑零件加工路径的轨迹规划方法，使用空间固定的TCP来简化操作。

Method: 使用B样条表示机器人路径，确保路径连续性和平滑轨迹。在计算机器人轨迹时考虑规定的方向和TCP的给定速度。

Result: 该方法在真实系统上进行了验证，使用工业机器人移动任意定义的零件，证明了方法的有效性。

Conclusion: 提出的基于B样条的工作空间轨迹规划方法能够生成平滑的机器人轨迹，特别适用于零件移动比工具移动更有利的应用场景。

Abstract: This paper presents a method for planning a trajectory in workspace
coordinates using a spatially fixed tool center point (TCP), while taking into
account the processing path on a part. This approach is beneficial if it is
easier to move the part rather than moving the tool. Whether a mathematical
description that defines the shape to be processed or single points from a
design program are used, the robot path is finally represented using B-splines.
The use of splines enables the path to be continuous with a desired degree,
which finally leads to a smooth robot trajectory. While calculating the robot
trajectory through prescribed orientation, additionally a given velocity at the
TCP has to be considered. The procedure was validated on a real system using an
industrial robot moving an arbitrary defined part.

</details>


### [71] [Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections](https://arxiv.org/abs/2510.20480)
*Václav Pritzl,Xianjia Yu,Tomi Westerlund,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种新颖的自适应多模态多机器人协同定位方法，使用因子图融合异步的视觉惯性里程计、激光雷达惯性里程计和3D机器人间检测数据，能够适应环境变化并帮助受传感器退化影响的机器人。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止环境中，单机器人携带所有传感器会增加尺寸、重量和功耗需求，而多机器人分布式传感器部署虽然提高了可部署性，但面临融合异步多模态数据的挑战。

Method: 采用因子图公式以松耦合方式融合异步VIO、LIO和3D机器人间检测数据，使用基于插值的因子处理非同步测量，基于近似扫描匹配Hessian评估LIO退化，并提出基于Wasserstein距离的里程计数据加权方法。

Result: 在真实世界数据上的广泛评估表明，该方法在各种传感器退化情况下显著提高了定位精度。

Conclusion: 所提出的自适应多模态多机器人协同定位方法能够有效应对传感器退化问题，在GNSS拒止环境中提供准确的长期定位能力。

Abstract: Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

</details>


### [72] [Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty](https://arxiv.org/abs/2510.20483)
*Victor Vantilborgh,Hrishikesh Sathyanarayan,Guillaume Crevecoeur,Ian Abraham,Tom Lefebvre*

Main category: cs.RO

TL;DR: 该论文提出了一种在未知动力学下进行机器人操作的双重控制方法，通过预定义反馈策略结构并嵌入参数不确定性，实现了主动探索和在线参数适应。


<details>
  <summary>Details</summary>
Motivation: 解决在未知动力学（如负载不确定）下机器人操作任务的问题，需要主动探索和在线参数适应来实现精确的基于模型的控制。

Method: 将问题构建为双重控制问题，预定义反馈策略结构包含显式适应机制，提出两种参考轨迹生成方法：一种嵌入参数不确定性的鲁棒最优控制，另一种最小化最优性损失。

Result: 两种方法都自然地考虑了Fisher信息，同时追求最优任务执行。在拾取-放置操作任务中表现出更快速、更准确的任务性能和系统辨识能力。

Conclusion: 在参考轨迹设计中考虑控制因素能够实现更快更准确的任务性能，同时确保稳定高效的控制。

Abstract: This work addresses the problem of robot manipulation tasks under unknown
dynamics, such as pick-and-place tasks under payload uncertainty, where active
exploration and(/for) online parameter adaptation during task execution are
essential to enable accurate model-based control. The problem is framed as dual
control seeking a closed-loop optimal control problem that accounts for
parameter uncertainty. We simplify the dual control problem by pre-defining the
structure of the feedback policy to include an explicit adaptation mechanism.
Then we propose two methods for reference trajectory generation. The first
directly embeds parameter uncertainty in robust optimal control methods that
minimize the expected task cost. The second method considers minimizing the
so-called optimality loss, which measures the sensitivity of parameter-relevant
information with respect to task performance. We observe that both approaches
reason over the Fisher information as a natural side effect of their
formulations, simultaneously pursuing optimal task execution. We demonstrate
the effectiveness of our approaches for a pick-and-place manipulation task. We
show that designing the reference trajectories whilst taking into account the
control enables faster and more accurate task performance and system
identification while ensuring stable and efficient control.

</details>


### [73] [Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators](https://arxiv.org/abs/2510.20490)
*Thomas Kordik,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文研究了通过优化轨迹和串联弹性驱动器刚度来最小化执行拾取-放置任务的并联机器人能耗的方法。


<details>
  <summary>Details</summary>
Motivation: 工业机器人执行拾取-放置任务时通常长时间运行，因此最小化能耗具有重要意义。串联弹性驱动器通过弹性元件可以激发本征运动，利用振荡特性来降低能耗。

Method: 推导了SEA驱动并联机器人的动力学模型，制定了能量最小化的最优控制问题，同时优化操作轨迹和SEA刚度。刚度优化不是针对可变刚度驱动器，而是用于设计和尺寸确定过程。

Result: 在两个并联机器人应用上测试了该方法，结果证实了这种方法的有效性，能够显著降低能耗。

Conclusion: 通过同时优化轨迹和弹性驱动器刚度，可以有效地最小化执行拾取-放置任务的并联机器人的能量消耗，该方法具有实际应用价值。

Abstract: A major field of industrial robot applications deals with repetitive tasks
that alternate between operating points. For these so-called pick-and-place
operations, parallel kinematic manipulators (PKM) are frequently employed.
These tasks tend to automatically run for a long period of time and therefore
minimizing energy consumption is always of interest. Recent research addresses
this topic by the use of elastic elements and particularly series elastic
actuators (SEA). This paper explores the possibilities of minimizing energy
consumption of SEA actuated PKM performing pick-and-place tasks. The basic idea
is to excite eigenmotions that result from the actuator springs and exploit
their oscillating characteristics. To this end, a prescribed cyclic
pick-and-place operation is analyzed and a dynamic model of SEA driven PKM is
derived. Subsequently, an energy minimizing optimal control problem is
formulated where operating trajectories as well as SEA stiffnesses are
optimized simultaneously. Here, optimizing the actuator stiffness does not
account for variable stiffness actuators. It serves as a tool for the design
and dimensioning process. The hypothesis on energy reduction is tested on two
(parallel) robot applications where redundant actuation is also addressed. The
results confirm the validity of this approach.

</details>


### [74] [A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator](https://arxiv.org/abs/2510.20496)
*Tobias Marauli,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种新的时间最优路径跟随计算方法，通过最大化路径速度而非最小化旅行时间来避免零路径速度时的奇异性问题，实现高效平滑轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 传统时间最优路径跟随方法在最小化旅行时间时，在路径参数化中会在零路径速度处产生奇异性，导致计算困难且难以生成平滑轨迹。

Method: 采用最大化路径速度的方法替代传统最小化旅行时间，将基础问题离散化重构为优化变量的线性问题。

Result: 该方法能够高效地规划平滑轨迹，且离散化后的优化问题在优化变量上是线性的。

Conclusion: 基于最大化路径速度的新方法有效解决了传统方法中的奇异性问题，实现了计算效率高且轨迹平滑的时间最优路径跟随。

Abstract: In this paper the computational challenges of time-optimal path following are
addressed. The standard approach is to minimize the travel time, which
inevitably leads to singularities at zero path speed, when reformulating the
optimization problem in terms of a path parameter. Thus, smooth trajectory
generation while maintaining a low computational effort is quite challenging,
since the singularities have to be taken into account. To this end, a different
approach is presented in this paper. This approach is based on maximizing the
path speed along a prescribed path. Furthermore, the approach is capable of
planning smooth trajectories numerically efficient. Moreover, the discrete
reformulation of the underlying problem is linear in optimization variables.

</details>


### [75] [RubbleSim: A Photorealistic Structural Collapse Simulator for Confined Space Mapping](https://arxiv.org/abs/2510.20529)
*Constantine Frost,Chad Council,Margaret McGuinness,Nathaniel Hanson*

Main category: cs.RO

TL;DR: 提出了RubbleSim——一个开源的、可重构的模拟器，用于在灾难响应中模拟结构倒塌废墟中的空洞空间探索。


<details>
  <summary>Details</summary>
Motivation: 由于法律限制和机构所有权问题，真实灾难响应中的废墟内部数据难以获取，而训练场地也不愿公开其专有信息。

Method: 使用Unity开发多操作系统支持的模拟器，采用基于物理的方法构建随机废墟堆，允许快速迭代模拟世界并保留绝对地面真实值。

Result: 应用最先进的结构从运动算法，展示了在模拟空洞空间中具有挑战性的视觉条件下感知性能如何下降。

Conclusion: RubbleSim为研究废墟空洞空间探索提供了一个可访问的解决方案，克服了真实数据获取的障碍。

Abstract: Despite well-reported instances of robots being used in disaster response,
there is scant published data on the internal composition of the void spaces
within structural collapse incidents. Data collected during these incidents is
mired in legal constraints, as ownership is often tied to the responding
agencies, with little hope of public release for research. While engineered
rubble piles are used for training, these sites are also reluctant to release
information about their proprietary training grounds. To overcome this access
challenge, we present RubbleSim -- an open-source, reconfigurable simulator for
photorealistic void space exploration. The design of the simulation assets is
directly informed by visits to numerous training rubble sites at differing
levels of complexity. The simulator is implemented in Unity with
multi-operating system support. The simulation uses a physics-based approach to
build stochastic rubble piles, allowing for rapid iteration between simulation
worlds while retaining absolute knowledge of the ground truth. Using RubbleSim,
we apply a state-of-the-art structure-from-motion algorithm to illustrate how
perception performance degrades under challenging visual conditions inside the
emulated void spaces. Pre-built binaries and source code to implement are
available online: https://github.com/mit-ll/rubble_pile_simulator.

</details>


### [76] [C-NAV: Towards Self-Evolving Continual Object Navigation in Open World](https://arxiv.org/abs/2510.20685)
*Ming-Ming Yu,Fei Zhu,Wenzhuo Liu,Yirong Yang,Qunbo Wang,Wenjun Wu,Jing Liu*

Main category: cs.RO

TL;DR: 提出了C-Nav持续视觉导航框架，通过双路径抗遗忘机制和自适应采样策略解决物体导航中的灾难性遗忘问题，在保持高性能的同时显著降低内存需求。


<details>
  <summary>Details</summary>
Motivation: 现有物体导航方法依赖静态轨迹和固定物体类别训练，无法适应动态开放世界的持续演化场景，需要解决新类别学习时的灾难性遗忘问题。

Method: C-Nav框架包含：1）双路径抗遗忘机制（特征蒸馏确保表示一致性，特征重放确保策略一致性）；2）自适应采样策略选择多样化和信息丰富的经验以减少冗余。

Result: 在多种模型架构上的广泛实验表明，C-Nav始终优于现有方法，即使与保留完整轨迹的基线相比也能实现更优性能，同时显著降低内存需求。

Conclusion: C-Nav为持续物体导航提供了有效解决方案，通过创新的抗遗忘机制和采样策略实现了高性能和低内存消耗的平衡。

Abstract: Embodied agents are expected to perform object navigation in dynamic,
open-world environments. However, existing approaches typically rely on static
trajectories and a fixed set of object categories during training, overlooking
the real-world requirement for continual adaptation to evolving scenarios. To
facilitate related studies, we introduce the continual object navigation
benchmark, which requires agents to acquire navigation skills for new object
categories while avoiding catastrophic forgetting of previously learned
knowledge. To tackle this challenge, we propose C-Nav, a continual visual
navigation framework that integrates two key innovations: (1) A dual-path
anti-forgetting mechanism, which comprises feature distillation that aligns
multi-modal inputs into a consistent representation space to ensure
representation consistency, and feature replay that retains temporal features
within the action decoder to ensure policy consistency. (2) An adaptive
sampling strategy that selects diverse and informative experiences, thereby
reducing redundancy and minimizing memory overhead. Extensive experiments
across multiple model architectures demonstrate that C-Nav consistently
outperforms existing approaches, achieving superior performance even compared
to baselines with full trajectory retention, while significantly lowering
memory requirements. The code will be publicly available at
https://bigtree765.github.io/C-Nav-project.

</details>


### [77] [Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning](https://arxiv.org/abs/2510.20706)
*Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出了一种结合MPPI算法和Dreamer模块的优化框架，用于四足机器人在连续步态空间中的实时步态自适应，显著降低能耗并保持精确跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决无模型强化学习策略收敛到单一步态导致性能次优，以及模型预测控制无法适应多变环境的问题。

Method: 将模型预测路径积分(MPPI)算法与Dreamer模块结合，在每个时间步联合优化动作和步态变量，使用学习到的奖励函数促进速度跟踪、能效、稳定性和平滑过渡。

Result: 在Unitree Go1仿真中，在不同目标速度下平均能耗降低高达36.48%，同时保持精确跟踪和自适应、任务适当的步态。

Conclusion: 该框架成功实现了四足机器人的自适应和最优步态控制，在能耗和性能方面都取得了显著改进。

Abstract: Model-free reinforcement learning (RL) has enabled adaptable and agile
quadruped locomotion; however, policies often converge to a single gait,
leading to suboptimal performance. Traditionally, Model Predictive Control
(MPC) has been extensively used to obtain task-specific optimal policies but
lacks the ability to adapt to varying environments. To address these
limitations, we propose an optimization framework for real-time gait adaptation
in a continuous gait space, combining the Model Predictive Path Integral (MPPI)
algorithm with a Dreamer module to produce adaptive and optimal policies for
quadruped locomotion. At each time step, MPPI jointly optimizes the actions and
gait variables using a learned Dreamer reward that promotes velocity tracking,
energy efficiency, stability, and smooth transitions, while penalizing abrupt
gait changes. A learned value function is incorporated as terminal reward,
extending the formulation to an infinite-horizon planner. We evaluate our
framework in simulation on the Unitree Go1, demonstrating an average reduction
of up to 36.48\% in energy consumption across varying target speeds, while
maintaining accurate tracking and adaptive, task-appropriate gaits.

</details>


### [78] [FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation](https://arxiv.org/abs/2510.20774)
*Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu*

Main category: cs.RO

TL;DR: FieldGen是一个场引导的数据生成框架，通过分解操作任务为预操作和精细操作两个阶段，实现可扩展、多样且高质量的机器人操作数据收集，显著减少人工监督需求。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据收集方法难以平衡规模、多样性和质量。仿真方法可扩展但存在仿真到现实的差距，遥操作方法质量高但多样性有限且人工成本高。

Method: 将操作任务分解为预操作阶段（允许轨迹多样性）和精细操作阶段（需要专家精度）。人类演示捕获关键接触和姿态信息，然后通过吸引场自动生成多样轨迹收敛到成功配置。FieldGen-Reward为生成数据添加奖励标注。

Result: 实验表明，使用FieldGen训练的策略比基于遥操作的基线方法获得更高的成功率和改进的稳定性，同时显著减少了长期真实世界数据收集的人工工作量。

Conclusion: FieldGen通过解耦设计结合了可扩展的轨迹多样性和精确监督，为机器人操作学习提供了高效的数据生成解决方案。

Abstract: Large-scale and diverse datasets are vital for training robust robotic
manipulation policies, yet existing data collection methods struggle to balance
scale, diversity, and quality. Simulation offers scalability but suffers from
sim-to-real gaps, while teleoperation yields high-quality demonstrations with
limited diversity and high labor cost. We introduce FieldGen, a field-guided
data generation framework that enables scalable, diverse, and high-quality
real-world data collection with minimal human supervision. FieldGen decomposes
manipulation into two stages: a pre-manipulation phase, allowing trajectory
diversity, and a fine manipulation phase requiring expert precision. Human
demonstrations capture key contact and pose information, after which an
attraction field automatically generates diverse trajectories converging to
successful configurations. This decoupled design combines scalable trajectory
diversity with precise supervision. Moreover, FieldGen-Reward augments
generated data with reward annotations to further enhance policy learning.
Experiments demonstrate that policies trained with FieldGen achieve higher
success rates and improved stability compared to teleoperation-based baselines,
while significantly reducing human effort in long-term real-world data
collection. Webpage is available at https://fieldgen.github.io/.

</details>


### [79] [The Reality Gap in Robotics: Challenges, Solutions, and Best Practices](https://arxiv.org/abs/2510.20808)
*Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos*

Main category: cs.RO

TL;DR: 这篇论文是关于机器人学中模拟到现实转移的综述，探讨了模拟与现实环境之间的差距（现实差距）问题及其解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习在机器人领域的应用日益广泛，但模拟环境与现实世界之间存在显著差异，这阻碍了从模拟训练到现实部署的成功转移。理解并解决这一现实差距是机器人学中最紧迫的挑战之一。

Method: 通过文献综述方法，系统分析了模拟到现实转移的现状，包括领域随机化、现实到模拟转移、状态和动作抽象、模拟-现实协同训练等技术。

Result: 研究表明，虽然已有多种技术能够有效克服现实差距，在运动、导航和操作等多个平台上取得了有前景的结果，但挑战仍然存在。

Conclusion: 需要更深入地理解现实差距的根本原因和解决方案，本文提供了一个全面的模拟到现实转移概览，包括原因、解决方案和评估指标。

Abstract: Machine learning has facilitated significant advancements across various
robotics domains, including navigation, locomotion, and manipulation. Many such
achievements have been driven by the extensive use of simulation as a critical
tool for training and testing robotic systems prior to their deployment in
real-world environments. However, simulations consist of abstractions and
approximations that inevitably introduce discrepancies between simulated and
real environments, known as the reality gap. These discrepancies significantly
hinder the successful transfer of systems from simulation to the real world.
Closing this gap remains one of the most pressing challenges in robotics.
Recent advances in sim-to-real transfer have demonstrated promising results
across various platforms, including locomotion, navigation, and manipulation.
By leveraging techniques such as domain randomization, real-to-sim transfer,
state and action abstractions, and sim-real co-training, many works have
overcome the reality gap. However, challenges persist, and a deeper
understanding of the reality gap's root causes and solutions is necessary. In
this survey, we present a comprehensive overview of the sim-to-real landscape,
highlighting the causes, solutions, and evaluation metrics for the reality gap
and sim-to-real transfer.

</details>


### [80] [GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation](https://arxiv.org/abs/2510.20813)
*Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: GSWorld是一个结合3D高斯泼溅和物理引擎的机器人操作模拟器，支持从真实机器人数据学习策略和sim2real策略训练，无需使用真实机器人。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够实现真实感渲染的机器人操作模拟器，支持策略开发和评估的闭环流程，减少对真实机器人的依赖。

Method: 提出GSDF（高斯场景描述文件）资产格式，结合高斯网格表示与机器人URDF，建立包含3种机器人形态和40多个物体的数据库，并与物理引擎集成。

Result: 展示了五个应用场景：零样本sim2real像素到动作策略学习、自动化DAgger数据收集、可复现的基准测试、虚拟遥操作数据收集、零样本sim2real视觉强化学习。

Conclusion: GSWorld提供了一个强大的机器人操作模拟平台，实现了从真实数据学习到sim2real策略训练的完整闭环，具有广泛的应用前景。

Abstract: This paper presents GSWorld, a robust, photo-realistic simulator for robotics
manipulation that combines 3D Gaussian Splatting with physics engines. Our
framework advocates "closing the loop" of developing manipulation policies with
reproducible evaluation of policies learned from real-robot data and sim2real
policy training without using real robots. To enable photo-realistic rendering
of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian
Scene Description File), that infuses Gaussian-on-Mesh representation with
robot URDF and other objects. With a streamlined reconstruction pipeline, we
curate a database of GSDF that contains 3 robot embodiments for single-arm and
bimanual manipulation, as well as more than 40 objects. Combining GSDF with
physics engines, we demonstrate several immediate interesting applications: (1)
learning zero-shot sim2real pixel-to-action manipulation policy with
photo-realistic rendering, (2) automated high-quality DAgger data collection
for adapting policies to deployment environments, (3) reproducible benchmarking
of real-robot manipulation policies in simulation, (4) simulation data
collection by virtual teleoperation, and (5) zero-shot sim2real visual
reinforcement learning. Website: https://3dgsworld.github.io/.

</details>


### [81] [VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation](https://arxiv.org/abs/2510.20818)
*Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta*

Main category: cs.RO

TL;DR: VAMOS是一个分层视觉语言导航系统，通过解耦语义规划和具身基础，使通用规划器学习开放世界数据，而专业能力模型学习机器人的物理约束，实现跨具身导航。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航中学习策略在不同环境间泛化，同时适应特定机器人物理约束和能力的根本挑战。

Method: 采用分层架构：高层规划器在图像空间提出候选路径，能力模型评估和重新排序这些路径。规划器从多样化开放世界数据学习，能力模型在低成本仿真中学习机器人物理约束。

Result: 在真实世界实验中，VAMOS在室内和复杂室外导航中比最先进的基于模型和端到端学习方法获得更高成功率，支持轮式和腿式机器人跨具身导航，通过拒绝物理不可行计划使单机器人可靠性提高3倍。

Conclusion: 分层设计是跨具身导航的关键，专业能力模型对具身基础至关重要，使单个高层规划器能够部署在物理特性不同的机器人上。

Abstract: A fundamental challenge in robot navigation lies in learning policies that
generalize across diverse environments while conforming to the unique physical
constraints and capabilities of a specific embodiment (e.g., quadrupeds can
walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that
decouples semantic planning from embodiment grounding: a generalist planner
learns from diverse, open-world data, while a specialist affordance model
learns the robot's physical constraints and capabilities in safe, low-cost
simulation. We enabled this separation by carefully designing an interface that
lets a high-level planner propose candidate paths directly in image space that
the affordance model then evaluates and re-ranks. Our real-world experiments
show that VAMOS achieves higher success rates in both indoor and complex
outdoor navigation than state-of-the-art model-based and end-to-end learning
methods. We also show that our hierarchical design enables cross-embodied
navigation across legged and wheeled robots and is easily steerable using
natural language. Real-world ablations confirm that the specialist model is key
to embodiment grounding, enabling a single high-level planner to be deployed
across physically distinct wheeled and legged robots. Finally, this model
significantly enhances single-robot reliability, achieving 3X higher success
rates by rejecting physically infeasible plans. Website:
https://vamos-vla.github.io/

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [82] [Excitation of Looped Bistable Bands for High-Speed Linear Actuation](https://arxiv.org/abs/2510.19834)
*Sareum Kim,Josie Hughes*

Main category: eess.SY

TL;DR: 该论文研究了通过激励环形双稳态弹簧带实现高速线性运动放大的方法，利用其双稳态特性在共振时实现输入振荡到放大线性运动的转换。


<details>
  <summary>Details</summary>
Motivation: 探索双稳态弹簧带在软机器人中的动态行为，特别是其振荡特性，以实现高速往复线性运动。

Method: 将环形双稳态弹簧带安装在直线导轨上，通过不同频率的曲柄机构驱动，利用其双稳态特性在共振时放大线性运动。

Result: 成功实现了通过环形双稳态弹簧带的激励将输入振荡转换为放大的线性运动，特别是在共振频率下效果显著。

Conclusion: 双稳态弹簧带在高速往复线性运动中具有巨大潜力，为软机器人提供了创新的运动放大解决方案。

Abstract: Soft robotics increasingly relies on smart materials and innovative
structures, with bistable tape springs emerging as a promising option. These
structures exhibit intriguing dynamic behaviors, such as oscillation, due to
their inherent bistability. This paper explores the high-speed linear
amplification of motion achieved through the excitation of a looped bistable
tape spring. When looped, the tape spring forms two distinct joints,
facilitating smooth oscillation. Mounted on a linear guide and driven by a
crank mechanism with varying frequency, the system converts input oscillations
into amplified linear motion at resonance. This study highlights the potential
of bistable tape springs high speed reciprocating linear motion.

</details>


### [83] [IMAS$^2$: Joint Agent Selection and Information-Theoretic Coordinated Perception In Dec-POMDPs](https://arxiv.org/abs/2510.20009)
*Chongyang Shi,Wesley A. Suttle,Michael Dorothy,Jie Fu*

Main category: eess.SY

TL;DR: 提出了一个双层优化框架，用于联合选择感知代理并在Dec-POMDP中合成去中心化主动感知策略，利用信息论指标和子模性设计IMAS²算法。


<details>
  <summary>Details</summary>
Motivation: 解决在多智能体系统中联合选择感知代理并合成去中心化主动感知策略的问题，以优化集体感知能力。

Method: 采用双层优化结构：内层使用互信息作为主动感知的统一目标，外层利用信息论目标的单调性和子模性设计IMAS²算法进行代理选择和策略合成。

Result: 证明了在特定条件下信息论目标具有单调性和子模性，IMAS²算法能提供(1-1/e)的性能保证，并在网格世界环境中验证了有效性。

Conclusion: 提出的信息论方法为多智能体主动感知问题提供了有效的解决方案，IMAS²算法在代理选择和策略合成方面具有理论保证和实际效果。

Abstract: We study the problem of jointly selecting sensing agents and synthesizing
decentralized active perception policies for the chosen subset of agents within
a Decentralized Partially Observable Markov Decision Process (Dec-POMDP)
framework. Our approach employs a two-layer optimization structure. In the
inner layer, we introduce information-theoretic metrics, defined by the mutual
information between the unknown trajectories or some hidden property in the
environment and the collective partial observations in the multi-agent system,
as a unified objective for active perception problems. We employ various
optimization methods to obtain optimal sensor policies that maximize mutual
information for distinct active perception tasks. In the outer layer, we prove
that under certain conditions, the information-theoretic objectives are
monotone and submodular with respect to the subset of observations collected
from multiple agents. We then exploit this property to design an IMAS$^2$
(Information-theoretic Multi-Agent Selection and Sensing) algorithm for joint
sensing agent selection and sensing policy synthesis. However, since the policy
search space is infinite, we adapt the classical Nemhauser-Wolsey argument to
prove that the proposed IMAS$^2$ algorithm can provide a tight $(1 -
1/e)$-guarantee on the performance. Finally, we demonstrate the effectiveness
of our approach in a multi-agent cooperative perception in a grid-world
environment.

</details>


### [84] [Approximate Model Predictive Control for Microgrid Energy Management via Imitation Learning](https://arxiv.org/abs/2510.20040)
*Changrui Liu,Shengling Shi,Anil Alan,Ganesh Kumar Venayagamoorthy,Bart De Schutter*

Main category: eess.SY

TL;DR: 提出基于模仿学习的框架来近似混合整数经济模型预测控制，用于微电网能量管理，实现快速实时决策而无需在线求解优化问题。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源集成增加，高效能量管理对微电网可靠可持续运行至关重要，需要解决传统优化方法计算复杂度高的问题。

Method: 训练神经网络模仿专家EMPC控制动作，通过离线轨迹学习，在训练过程中加入噪声注入以增强鲁棒性，并显式考虑可再生能源和需求的预测不确定性。

Result: 学习策略在经济性能上与EMPC相当，而计算时间仅为基于优化的EMPC的10%。

Conclusion: 所提方法能够有效近似EMPC性能，显著降低计算负担，适合实时微电网能量管理应用。

Abstract: Efficient energy management is essential for reliable and sustainable
microgrid operation amid increasing renewable integration. This paper proposes
an imitation learning-based framework to approximate mixed-integer Economic
Model Predictive Control (EMPC) for microgrid energy management. The proposed
method trains a neural network to imitate expert EMPC control actions from
offline trajectories, enabling fast, real-time decision making without solving
optimization problems online. To enhance robustness and generalization, the
learning process includes noise injection during training to mitigate
distribution shift and explicitly incorporates forecast uncertainty in
renewable generation and demand. Simulation results demonstrate that the
learned policy achieves economic performance comparable to EMPC while only
requiring $10\%$ of the computation time of optimization-based EMPC in
practice.

</details>


### [85] [Safe Output-Feedback Adaptive Optimal Control of Affine Nonlinear Systems](https://arxiv.org/abs/2510.20081)
*Tochukwu E. Ogri,Muzaffar Qureshi,Zachary I. Bell,Wanjiku A. Makumi,Rushikesh Kamalapurkar*

Main category: eess.SY

TL;DR: 提出了一种结合状态估计和参数估计的安全控制合成方法，在自适应最优控制和控制屏障函数框架下，通过鲁棒化CBF来应对不完全状态测量，保证系统安全性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 解决在缺乏完整状态测量的情况下，如何同时保证系统安全性和控制性能的问题，将安全目标与学习目标解耦。

Method: 开发了基于CBF的守护控制器，将CBF鲁棒化以应对状态估计误差，结合自适应最优控制，并利用深度神经网络自适应观测器技术。

Result: 通过Lyapunov分析提供了安全性和收敛性保证，在温和激励条件下的仿真验证了控制器的有效性。

Conclusion: 所提出的控制架构能够在缺乏完整状态测量的情况下，同时保证系统安全性和调节性能，为安全控制提供了新的解决方案。

Abstract: In this paper, we develop a safe control synthesis method that integrates
state estimation and parameter estimation within an adaptive optimal control
(AOC) and control barrier function (CBF)-based control architecture. The
developed approach decouples safety objectives from the learning objectives
using a CBF-based guarding controller where the CBFs are robustified to account
for the lack of full-state measurements. The coupling of this guarding
controller with the AOC-based stabilizing control guarantees safety and
regulation despite the lack of full state measurement. The paper leverages
recent advancements in deep neural network-based adaptive observers to ensure
safety in the presence of state estimation errors. Safety and convergence
guarantees are provided using a Lyapunov-based analysis, and the effectiveness
of the developed controller is demonstrated through simulation under mild
excitation conditions.

</details>


### [86] [SpeechAgent: An End-to-End Mobile Infrastructure for Speech Impairment Assistance](https://arxiv.org/abs/2510.20113)
*Haowei Lou,Chengkai Huang,Hye-young Paik,Yongquan Hu,Aaron Quigley,Wen Hu,Lina Yao*

Main category: eess.SY

TL;DR: SpeechAgent是一个移动语音助手，旨在帮助有语音障碍的人群进行日常交流。它结合了大型语言模型的推理能力和先进的语音处理模块，为不同类型的语音障碍提供自适应支持。


<details>
  <summary>Details</summary>
Motivation: 尽管自动语音识别和文本转语音技术取得了进展，但针对语音障碍用户的可访问网络和移动基础设施仍然有限，阻碍了这些进步在日常交流中的实际应用。

Method: 系统集成了大型语言模型驱动的推理与先进语音处理模块，开发了结构化部署管道，可在移动和边缘设备上实现实时语音处理，同时保持高准确性和语音质量。

Result: 在真实世界语音障碍数据集和边缘设备延迟分析上的评估证实，SpeechAgent既有效又用户友好，延迟几乎不可察觉。

Conclusion: SpeechAgent展示了其在个性化、日常辅助交流中的可行性，为语音障碍人群提供了实用的沟通解决方案。

Abstract: Speech is essential for human communication, yet millions of people face
impairments such as dysarthria, stuttering, and aphasia conditions that often
lead to social isolation and reduced participation. Despite recent progress in
automatic speech recognition (ASR) and text-to-speech (TTS) technologies,
accessible web and mobile infrastructures for users with impaired speech remain
limited, hindering the practical adoption of these advances in daily
communication. To bridge this gap, we present SpeechAgent, a mobile SpeechAgent
designed to facilitate people with speech impairments in everyday
communication. The system integrates large language model (LLM)- driven
reasoning with advanced speech processing modules, providing adaptive support
tailored to diverse impairment types. To ensure real-world practicality, we
develop a structured deployment pipeline that enables real-time speech
processing on mobile and edge devices, achieving imperceptible latency while
maintaining high accuracy and speech quality. Evaluation on real-world impaired
speech datasets and edge-device latency profiling confirms that SpeechAgent
delivers both effective and user-friendly performance, demonstrating its
feasibility for personalized, day-to-day assistive communication.

</details>


### [87] [Interpolatory Approximations of PMU Data: Dimension Reduction and Pilot Selection](https://arxiv.org/abs/2510.20116)
*Sean Reiter,Mark Embree,Serkan Gugercin,Vassilis Kekatos*

Main category: eess.SY

TL;DR: 该论文提出使用插值矩阵分解(IDs)和离散经验插值方法(DEIM)来压缩PMU数据，通过选择少量关键行和列来重建完整数据矩阵，实现实时电力系统监测和故障检测。


<details>
  <summary>Details</summary>
Motivation: 为了减少PMU数据传输所需的通信带宽，同时保持对电力传输系统的实时监测能力，需要开发有效的数据压缩方法。传统方法如PCA或SVD需要完整数据矩阵，而实际应用中只能获取部分测量数据。

Method: 采用插值矩阵分解(IDs)框架，通过选择少量PMU数据流(行)和时间快照(列)来重建完整数据矩阵。使用离散经验插值方法(DEIM)贪婪算法来选择关键行和列，以控制重建误差。

Result: 数值测试表明DEIM在数据压缩方面表现优异，提出的基于DEIM的故障检测方法能够有效识别系统运行条件的变化。

Conclusion: IDs和DEIM提供了一种有效的PMU数据压缩方法，不仅能减少通信带宽需求，还能通过重建误差估计实现系统故障检测，为电力系统实时监测提供了实用工具。

Abstract: This work investigates the reduction of phasor measurement unit (PMU) data
through low-rank matrix approximations. To reconstruct a PMU data matrix from
fewer measurements, we propose the framework of interpolatory matrix
decompositions (IDs). In contrast to methods relying on principal component
analysis or singular value decomposition, IDs recover the complete data matrix
using only a few of its rows (PMU datastreams) and/or a few of its columns
(snapshots in time). This compression enables the real-time monitoring of power
transmission systems using a limited number of measurements, thereby minimizing
communication bandwidth. The ID perspective gives a rigorous error bound on the
quality of the data compression. We propose selecting rows and columns used in
an ID via the discrete empirical interpolation method (DEIM), a greedy
algorithm that aims to control the error bound. This bound leads to a
computable estimate for the reconstruction error during online operations. A
violation of this estimate suggests a change in the system's operating
conditions, and thus serves as a tool for fault detection. Numerical tests
using synthetic PMU data illustrate DEIM's excellent performance for data
compression, and validate the proposed DEIM-based fault-detection method.

</details>


### [88] [Design Optimization and Global Impact Assessment of Solar-Thermal Direct Air Carbon Capture](https://arxiv.org/abs/2510.20135)
*Zhiyuan Fan,Bolun Xu*

Main category: eess.SY

TL;DR: 该研究提出了一种结合聚光太阳能技术和低成本沙基储热系统的太阳能-热直接空气捕集系统，能够实现超过80%的年容量因子和160-200美元/吨的二氧化碳去除成本，在沙质地形区域具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 应对脱碳和满足全球能源需求的双重挑战，需要可扩展且成本效益高的二氧化碳去除技术。直接空气捕集技术前景广阔，但其高能耗特别是吸附剂再生所需的热能是降低成本的关键障碍。

Method: 分析结合聚光太阳能技术和低成本沙基储热系统的太阳能-热直接空气捕集系统，评估其在并网和独立配置下的技术经济性能，重点研究适合太阳能可用性的短周期吸附剂。

Result: 太阳能-热直接空气捕集可实现超过80%的年容量因子和160-200美元/吨的CO2去除成本，与领先的直接空气捕集技术具有竞争力。独立太阳能直接空气捕集系统在太阳能资源丰富和沙质地形区域表现优异，对温度和湿度的环境敏感性最低。

Conclusion: 太阳能驱动的直接空气捕集在适合二氧化碳储存的沉积盆地地区，为地热加热提供了成本更低的替代方案，后者常面临地质和经济限制。优化的6000吨/年模块化系统设计占地小于1平方公里，全球沙质地形区域具有超过26吉吨/年的直接空气捕集潜力。

Abstract: The dual challenge of decarbonizing the economy and meeting rising global
energy demand underscores the need for scalable and cost-effective carbon
dioxide removal technologies. Direct air capture (DAC) is among the most
promising approaches, but its high energy intensity, particularly the thermal
energy required for sorbent regeneration, remains a critical barrier to cost
reduction and sustainable deployment. This study explores solar-thermal DAC
systems that combine concentrated solar thermal technology with low-cost
sand-based thermal energy storage to meet this demand. We analyze the
techno-economic performance of such systems in both grid-connected and
stand-alone configurations. Results show that solar-thermal DAC can achieve
annual capacity factors exceeding 80% and CO2 removal costs as low as 160-200
USD per ton, making it competitive with leading DAC technologies. The proposed
system operates most efficiently with short-cycle sorbents that align with
solar availability. The stand-alone Solar-DAC systems, which rely solely on
solar energy for both electricity and thermal energy, are particularly
promising in regions with high solar capacity and sandy terrain, exhibiting
minimal ambient sensitivity from temperature and humidity. An optimal 6000
ton/yr modular system design takes <1 km2 land-use requirement and potentially
>26 Gt/year DAC capacity is identified for sandy terrain alone globally. In
areas with sedimentary basins suitable for CO2 storage, solar-powered DAC
offers a lower-cost alternative to geothermal heating, which often faces
geological and economic constraints.

</details>


### [89] [Soft Switching Expert Policies for Controlling Systems with Uncertain Parameters](https://arxiv.org/abs/2510.20152)
*Junya Ikemoto*

Main category: eess.SY

TL;DR: 提出基于模拟的强化学习算法，通过两阶段方法处理系统参数不确定和变化的问题：先在模拟器中学习不同参数下的控制策略，然后在真实系统中使用在线凸优化算法平滑切换这些策略。


<details>
  <summary>Details</summary>
Motivation: 模拟器可用于安全学习物理系统的控制策略，但现实差距仍是主要挑战。需要解决系统参数不确定和变化的问题。

Method: 两阶段算法：第一阶段在模拟器中学习不同参数下的多个控制策略；第二阶段在真实系统中基于观测使用在线凸优化算法平滑切换控制策略。

Result: 通过数值实验验证了所提算法的有效性。

Conclusion: 提出的两阶段算法能够有效处理系统参数不确定和变化的问题，缩小模拟与现实的差距。

Abstract: This paper proposes a simulation-based reinforcement learning algorithm for
controlling systems with uncertain and varying system parameters. While
simulators are useful for safely learning control policies for physical
systems, mitigating the reality gap remains a major challenge. To address the
challenge, we propose a two-stage algorithm. In the first stage, multiple
control policies are learned for systems with different parameters in a
simulator. In the second stage, for a real system, the control policies learned
in the first stage are smoothly switched using an online convex optimization
algorithm based on observations. Our proposed algorithm is demonstrated through
numerical experiments.

</details>


### [90] [From Bundles to Backstepping: Geometric Control Barrier Functions for Safety-Critical Control on Manifolds](https://arxiv.org/abs/2510.20202)
*Massimiliano de Sa,Pio Ong,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本文开发了流形上几何控制屏障函数（CBF）的一般理论，为机器人学和航空航天中常见的系统提供了构造性CBF合成技术，并应用于欠驱动卫星系统。


<details>
  <summary>Details</summary>
Motivation: 控制屏障函数在欧几里得空间已有完善理论，但在机器人和航空航天中常见的流形上缺乏一般公式和构造性合成工具。

Method: 开发了流形上几何CBF的一般理论，将基于动能的反步法推广到黎曼流形，利用机械结构避免高阶切丛计算。

Result: 为几何机械系统提供了构造性CBF合成技术，并给出了易于验证的成功条件。

Conclusion: 所提出的方法成功应用于SO(3)上的欠驱动卫星系统，证明了其有效性。

Abstract: Control barrier functions (CBFs) have a well-established theory in Euclidean
spaces, yet still lack general formulations and constructive synthesis tools
for systems evolving on manifolds common in robotics and aerospace
applications. In this paper, we develop a general theory of geometric CBFs on
bundles and, for control-affine systems, recover the standard
optimization-based CBF controllers and their smooth analogues. Then, by
generalizing kinetic energy-based CBF backstepping to Riemannian manifolds, we
provide a constructive CBF synthesis technique for geometric mechanical
systems, as well as easily verifiable conditions under which it succeeds.
Further, this technique utilizes mechanical structure to avoid computations on
higher-order tangent bundles. We demonstrate its application to an
underactuated satellite on SO(3).

</details>


### [91] [Observer-based Differentiators for Noisy Signals](https://arxiv.org/abs/2510.20234)
*Van Huynh,Hieu Trinh,Riley Bain*

Main category: eess.SY

TL;DR: 提出了多种观测器系统作为微分器，能够在存在噪声的情况下估计信号的导数


<details>
  <summary>Details</summary>
Motivation: 开发能够在噪声环境中准确估计信号导数的观测器系统

Method: 使用观测器作为微分器来估计给定信号的导数

Result: 观测器微分器能够在信号存在噪声的情况下产生导数估计

Conclusion: 观测器系统可以作为有效的微分器，在噪声条件下估计信号导数

Abstract: We present a collection of different types of observation systems that work
as differentiators. These observer-based differentiators can produce estimates
for derivatives of a given signal, even though the given signal is prone to
noise.

</details>


### [92] [Multi-layer Optimized Coordination of Smart Building Resources in Active Power Distribution Systems](https://arxiv.org/abs/2510.20313)
*Mohammadali Rostami,Saeed Lotfifard,Mladen Kezunovic*

Main category: eess.SY

TL;DR: 提出一个多参与者协调平台，用于智能建筑资源（包括屋顶光伏发电和电池储能系统）在主动配电系统中的优化利用，通过分层优化实现资源协调，同时保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 解决智能建筑资源在配电系统中的协调优化问题，同时保护用户隐私数据不被电力系统运营商获取。

Method: 采用三层协调架构（智能建筑协调器、微电网协调器、配电系统协调器），通过分层优化问题独立运行并交换有限信息，实现最优解决方案。

Result: 数值模拟显示该平台能有效协调用户侧资源与配电系统其他部分，实现资源优化利用。

Conclusion: 该平台提供了一个灵活可扩展的架构，能够在保护用户隐私的同时实现智能建筑资源与配电系统的有效协调。

Abstract: This paper proposes a multi-actor coordination platform for the optimal
utilization of smart buildings resources, including roof top PV generation and
battery energy storage system (BESS), in active power distribution systems. The
proposed multi-actor coordination includes the Smart Building Coordinator
(SBC), Micro-Grid Coordinator (MGC) and Distribution System Coordinator (DSC).
The coordinators operate independently and only exchange limited information
with each other to reach an optimal solution. In the proposed platform, a
hierarchical optimization problem is solved to optimally determine the
operating point of all distribution system resources. The proposed platform
fully preserves the confidentiality of the behind the meter (BTM) data of the
buildings since no information about the status of the PV system, BESS, and
load of the building is shared with the owner of the power system. The proposed
platform has a flexible and scalable architecture where the computational task
of coordinating microgrids and smart buildings with distribution grid is
performed locally at the MGC and SBC layers, respectively. Numerical
simulations show the efficacy of the proposed platform in coordinating the BTM
resources with the rest of the distribution system.

</details>


### [93] [On MIMO Stability Analysis Methods Applied to Inverter-Based Resources Connected to Power Systems](https://arxiv.org/abs/2510.20384)
*Anton A. Stoorvogel,Saeed Lotfifard,Ali Saberi*

Main category: eess.SY

TL;DR: 对逆变器资源小信号稳定性分析方法的批判性综述，讨论方法目的、正确与错误实现、适用性、局限性及常见误解


<details>
  <summary>Details</summary>
Motivation: 澄清逆变器资源小信号稳定性分析方法的正确使用，揭示常见误用和误解，提高分析准确性

Method: 批判性文献综述方法，系统评估现有分析技术的实现方式、适用条件和局限性

Result: 明确了各种分析方法的适用边界，识别了常见误用模式，澄清了技术局限性

Conclusion: 需要更准确地理解和应用小信号稳定性分析方法，避免误用和错误解读，提高逆变器资源稳定性分析的可靠性

Abstract: This paper presents a critical review of methods
  commonly employed in the literature for small signal stability analysis of
  inverter based resources (IBRs). It discusses the intended purposes
  of these methods and outlines both their proper and improper
  implementations. The paper provides insights into the applicability
  of these techniques, clarifies their inherent limitations, and
  discusses and illustrates common sources of misinterpretation.

</details>


### [94] [Interlacing in Controllers Implementation: Frequency Analysis](https://arxiv.org/abs/2510.20394)
*Julian Salt*

Main category: eess.SY

TL;DR: 本文介绍如何使用交错技术实现LTI控制器，分析不同结构，在资源受限环境中实现显著计算节省，并提出了获取实数和复数控制器极点相关块的新方法。


<details>
  <summary>Details</summary>
Motivation: 在资源受限环境中实现计算效率更高的控制器实现方法，通过交错技术减少计算负担。

Method: 使用交错技术实现LTI控制器，通过离散提升技术建模时变系统，并开发了新的双速率频率响应计算方法。

Result: 提出的方法在资源受限环境中实现了重要的计算节省，能够有效分析具有交错控制器的控制回路特性。

Conclusion: 交错技术为LTI控制器在约束资源环境中的实现提供了有效的解决方案，理论提案通过示例验证了其可行性。

Abstract: The main goal of this contribution is to explain how to use interlacing
techniques for LTI controllers implementation and analyze different struc-
tures in this environment. These considerations lead to an important com-
putation saving in constrained resource environments. It has been also intro-
duced new procedures for obtaining the blocks related to different real and
complex controllers poles. The resultant time-varying system is modeled using
proper discrete lifting techniques and a new and efficient dual-rate fre-
quency response computation allows to determine the characteristics of the
control loop with interlaced controller. Examples illustrate the theoretical
proposals.

</details>


### [95] [A Multifunctional Capacitive Sensing Platform for Wireless Vascular and Heart Monitoring](https://arxiv.org/abs/2510.20415)
*Parviz Zolfaghari,Beril Yagmur Koca,Taher Abbasiasl,Hakan Urey,Hadi Mirzajani*

Main category: eess.SY

TL;DR: MAiCaS是一种多功能天线集成电容传感平台，通过利用电感天线的寄生电容作为应变敏感元件，实现了被动、无线、实时的无电池心血管监测。


<details>
  <summary>Details</summary>
Motivation: 传统心血管监测系统需要分离的传感器和无线模块，设备复杂且成本高。本研究旨在开发一种紧凑、可扩展的集成化监测平台，简化制造流程并提高可重复性。

Method: 采用无洁净室单步UV激光图案化工艺在柔性PDMS基底上制造传感器，将传感、遥测和机械功能统一到单一设计中。通过S11参数测量和共振频率偏移作为输出指标进行无线询问。

Result: 在体外实验中，设备在生理条件下表现出稳定的共振频率偏移，在皮肤、PBS、人血清和模拟血管环境中均保持稳定性能。灵敏度分别为：心外膜贴片2.9 MHz/1%应变、移植物0.43 MHz/mmHg、支架集成传感器309.6kHz/μm。

Conclusion: MAiCaS的单片传感器架构为血管动力学监测提供了可扩展且经济高效的无电池解决方案，在远程诊断、术后随访和持续心血管健康管理方面具有应用潜力。

Abstract: We present a multifunctional, antenna-integrated capacitive sensing (MAiCaS)
platform for passive, wireless, and real-time cardiovascular monitoring. Unlike
conventional systems that require separate sensors and wireless modules, our
device unifies sensing, telemetry, and mechanical functionality into a compact
and scalable design by exploiting the parasitic capacitance of an inductive
antenna as a strain-sensitive element. The sensor is fabricated using a
cleanroom-free, single-step UV laser patterning process on a flexible PDMS
substrate, reducing manufacturing complexity and enabling high reproducibility.
The MAiCaS is suitable for three different applications: as a sensor for
epicardial strain measurement, a stent as a sensor, and a vascular graft
sensor. We demonstrate MAiCaS's versatility by validating its wireless
resonance-based response to strain, pressure, and deformation across unrolled
and rolled forms. In vitro experiments demonstrated consistent resonance
frequency shifts under physiological conditions, with stable performance on
skin, in PBS, human serum, and simulated vascular environments. Repeatability
and aging tests confirmed its long-term reliability and elasticity under cyclic
loading. Calibration curves revealed high sensitivity across all
configurations, with wireless interrogation achieved through S11 parameter
measurements and resonance frequency shift as the output metric. The
sensitivity of the device was measured to be 2.9 MHz per 1% strain, 0.43
MHz/mmHg, and 309.6kHz/\textmu m for epicardial patch, graft, and stent
integrated sensor, respectively. The operation of MAiCaS was evaluated in a
human experiment. This monolithic sensor architecture provides a scalable and
cost-effective solution for battery-free monitoring of vascular dynamics, with
potential for remote diagnostics, post-surgical follow-up, and continuous
cardiovascular health management.

</details>


### [96] [Behavior-Aware Online Prediction of Obstacle Occupancy using Zonotopes](https://arxiv.org/abs/2510.20437)
*Alvaro Carrizosa-Rendon,Jian Zhou,Erik Frisk,Vicenc Puig,Fatiha Nejjari*

Main category: eess.SY

TL;DR: 提出了一种基于运动观测的在线车辆占用集预测方法，通过扩展卡尔曼滤波和线性规划估计控制动作，再通过可达性分析预测未来占用情况。


<details>
  <summary>Details</summary>
Motivation: 在无先验信息的非结构化环境中，准确预测周围车辆的运动对自动驾驶安全至关重要。

Method: 两阶段方法：第一阶段使用扩展卡尔曼滤波和线性规划估计控制动作的紧凑zonotopic集合；第二阶段通过可达性分析传播该集合来预测未来占用。

Result: 在城市环境模拟中验证了方法的有效性，显示出准确且紧凑的预测结果，无需依赖先验假设或训练数据。

Conclusion: 该方法能够仅基于运动观测实现准确的车辆占用集预测，为自动驾驶在非结构化环境中的安全导航提供了有效解决方案。

Abstract: Predicting the motion of surrounding vehicles is key to safe autonomous
driving, especially in unstructured environments without prior information.
This paper proposes a novel online method to accurately predict the occupancy
sets of surrounding vehicles based solely on motion observations. The approach
is divided into two stages: first, an Extended Kalman Filter and a Linear
Programming (LP) problem are used to estimate a compact zonotopic set of
control actions; then, a reachability analysis propagates this set to predict
future occupancy. The effectiveness of the method has been validated through
simulations in an urban environment, showing accurate and compact predictions
without relying on prior assumptions or prior training data.

</details>


### [97] [Joint Computation Offloading and Resource Management for Cooperative Satellite-Aerial-Marine Internet of Things Networks](https://arxiv.org/abs/2510.20443)
*Shuang Qi,Bin Lin,Yiqin Deng,Hongyang Pan,Xu Hu*

Main category: eess.SY

TL;DR: 提出了一种联合计算卸载和资源管理(JCORM)算法，用于卫星-无人机-海洋物联网协同网络，通过优化传输功率、任务开始时间、计算资源分配和卸载比例，在满足延迟敏感任务要求的同时最大化卫星数据收集量并最小化系统能耗。


<details>
  <summary>Details</summary>
Motivation: 海洋物联网设备通过低轨卫星和无人机连接时，缺乏有效的流量处理策略难以满足低延迟需求，需要设计一种能够区分处理延迟敏感和延迟容忍任务的协同网络架构。

Method: 采用移动边缘计算处理延迟敏感任务，使用存储-携带-转发方法处理延迟容忍任务，提出JCORM算法结合Dinkelbach方法和线性规划解决非凸非线性联合优化问题。

Result: JCORM算法相比基线方法可将卫星收集数据量提升高达41.5%，计算时间从最多318.21秒大幅减少到仅0.16秒，非常适合实时海事应用。

Conclusion: 所提出的JCORM算法在卫星-无人机-海洋物联网协同网络中能够有效平衡延迟敏感和延迟容忍任务，显著提升数据收集效率并降低能耗，具有实际部署价值。

Abstract: Devices within the marine Internet of Things (MIoT) can connect to low Earth
orbit (LEO) satellites and unmanned aerial vehicles (UAVs) to facilitate
low-latency data transmission and execution, as well as enhanced-capacity data
storage. However, without proper traffic handling strategy, it is still
difficult to effectively meet the low-latency requirements. In this paper, we
consider a cooperative satellite-aerial-MIoT network (CSAMN) for maritime edge
computing and maritime data storage to prioritize delay-sensitive (DS) tasks by
employing mobile edge computing, while handling delay-tolerant (DT) tasks via
the store-carry-forward method. Considering the delay constraints of DS tasks,
we formulate a constrained joint optimization problem of maximizing
satellite-collected data volume while minimizing system energy consumption by
controlling four interdependent variables, including the transmit power of UAVs
for DS tasks, the start time of DT tasks, computing resource allocation, and
offloading ratio. To solve this non-convex and non-linear problem, we propose a
joint computation offloading and resource management (JCORM) algorithm using
the Dinkelbach method and linear programming. Our results show that the volume
of data collected by the proposed JCORM algorithm can be increased by up to
41.5% compared to baselines. Moreover, JCORM algorithm achieves a dramatic
reduction in computational time, from a maximum of 318.21 seconds down to just
0.16 seconds per experiment, making it highly suitable for real-time maritime
applications.

</details>


### [98] [Decentralized Small Gain and Phase Stability Conditions for Grid-Forming Converters: Limitations and Extensions](https://arxiv.org/abs/2510.20544)
*Diego Cifelli,Adolfo Anta*

Main category: eess.SY

TL;DR: 提出了一种改进的分散稳定性分析方法，通过环路整形变换解决电网形成变换器在低频段的非扇形性问题，降低保守性，提高分散稳定性认证的适用性。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统中基于变换器的资源占比增加，需要可扩展的稳定性分析方法，而现有的分散小增益和小相位准则对电网形成变换器的适用性受限于扇形性假设，该假设在低频段通常不满足。

Method: 引入环路整形变换，在替代坐标系中重新表述变换器和网络模型，扩展混合增益相位条件，解决低频段的固有非扇形性问题。

Result: 该方法解决了低频非扇形性问题，降低了保守性，通过无限总线系统和IEEE 14总线网络的案例验证了方法的实用性和可扩展性。

Conclusion: 这些发现为电力系统中更少保守和更广泛适用的分散稳定性认证提供了途径。

Abstract: The increasing share of converter based resources in power systems calls for
scalable methods to analyse stability without relying on exhaustive system wide
simulations. Decentralized small gain and small-phase criteria have recently
been proposed for this purpose, but their applicability to grid forming
converters is severely limited by the sectoriality assumption, which is not
typically satisfied at low frequencies. This work revisits and extends mixed
gain phase conditions by introducing loop shaping transformations that
reformulate converter and network models in alternative coordinate frames. The
proposed approach resolves intrinsic non sectoriality at low frequencies and
reduces conservativeness, thereby improving the applicability of decentralized
stability certification. Analytical results are illustrated using an infinite
bus system first and then extended to the IEEE 14 bus network, demonstrating
the practicality and scalability of the method. These findings provide a
pathway toward less conservative and more widely applicable decentralized
stability certificates in power grids.

</details>


### [99] [Safe Decentralized Density Control of Multi-Robot Systems using PDE-Constrained Optimization with State Constraints](https://arxiv.org/abs/2510.20643)
*Longchen Niu,Gennaro Notomista*

Main category: eess.SY

TL;DR: 提出一种去中心化优化密度控制器，用于多机器人系统的集合不变性约束，通过设计去中心化控制屏障函数保证局部安全约束下的全局安全。


<details>
  <summary>Details</summary>
Motivation: 传统集中式方法需要大量计算和通信资源，在通信和定位不完美的实际场景中部署困难，需要开发更实用的去中心化安全控制方法。

Method: 设计去中心化控制屏障函数，将机器人建模为受Fokker-Planck方程控制的空间概率密度函数，显式考虑定位和运动噪声。

Result: 控制器在计算和通信需求上优于传统集中式方法，通过四架四旋翼无人机的仿真和实验验证了有效性。

Conclusion: 该去中心化密度控制器为多机器人系统提供了一种在通信和定位不完美条件下的实用安全控制解决方案。

Abstract: In this paper, we introduce a decentralized optimization-based density
controller designed to enforce set invariance constraints in multi-robot
systems. By designing a decentralized control barrier function, we derived
sufficient conditions under which local safety constraints guarantee global
safety. We account for localization and motion noise explicitly by modeling
robots as spatial probability density functions governed by the Fokker-Planck
equation. Compared to traditional centralized approaches, our controller
requires less computational and communication power, making it more suitable
for deployment in situations where perfect communication and localization are
impractical. The controller is validated through simulations and experiments
with four quadcopters.

</details>


### [100] [Sugar Shack 4.0: Implementation of a Cyber-Physical System for Logistic and Sanitary Automation in a Maple Syrup Boiling Center](https://arxiv.org/abs/2510.20682)
*Thomas Bernard,François Grondin,Jean-Michel Lavoie*

Main category: eess.SY

TL;DR: 设计并部署了一个过程感知的赛博物理系统，用于自动化枫糖浆煮沸中心的物流、可追溯性和卫生处理，取代了手动操作，实现了无事故运行并显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: 替代临时的手动操作，通过自动化提高枫糖浆生产中心的物流、可追溯性和卫生处理效率，消除污染事件并减少管理负担。

Method: 采用事件驱动的本地服务器编排，使用可重用设备抽象和集中式互锁机制，基于优先级仲裁共享管道，实施确定性例程进行输送、反渗透集成、蒸发器进料和渗透液管理。

Result: 在2025年生产季节中，系统无事故排队431次操作，执行908次平衡循环，将可用渗透液储备从22,712升增加到约41,640升，消除了手动操作中的污染事件，并将计费和报告的管理工作量从30多小时减少到约1小时。

Conclusion: 这项工作展示了超越传统架构的模块化、工厂规模自动化的可行路径，为类似工厂或相关行业打包可重用元素奠定了基础，是首个在枫糖浆煮沸中心科学集成工业4.0技术的项目。

Abstract: This paper presents the design and deployment of a process-aware
cyber-physical system that automates plant-level logistics, traceability, and
sanitation in a centralized maple-syrup boiling center. The system replaces
ad-hoc, manual operations with event-driven orchestration on a local server,
employing reusable device abstractions and a centralized interlock with
priority-based arbitration for shared piping. It implements deterministic
routines for delivery, reverse osmosis integration, evaporator feed, and
permeate management. The system is sensor rich: inline measurements of flow,
temperature, and sugar concentration (degrees Brix) drive routing decisions and
trigger systematic post-transfer rinses (cleaning-in-place), ensuring
consistent hygiene and complete, immediate traceability up to the evaporator
inlet. During the 2025 production season, the system queued 431 operations
without incident; executed 908 \enquote{topstock} and \enquote{downstock}
balancing cycles; increased usable permeate reserves from 22,712 to
approximately 41,640 L through dynamic storage assignment; eliminated
mid-season contamination incidents previously observed under manual practice;
and reduced administrative effort for billing and reporting from more than 30
hours to roughly 1 hour through automatic documentation. These results
demonstrate a practical path to modular, plant-scale automation beyond
traditional architectures, and lay the groundwork for packaging reusable
elements for similar plants or adjacent industries. This work is part of a
larger project involving the first scientifically-documented integration of
Industry 4.0 technologies in a maple syrup boiling center.

</details>


### [101] [Learning Optimal Power Flow with Pointwise Constraints](https://arxiv.org/abs/2510.20777)
*Damian Owerko,Anna Scaglione,Alejandro Ribeiro*

Main category: eess.SY

TL;DR: 提出了一种使用逐点约束训练学习参数化来解决最优潮流问题的新方法，该方法在双域中使用增广拉格朗日和双梯度上升算法进行训练。


<details>
  <summary>Details</summary>
Motivation: 现有监督学习方法要求约束在问题实例的平均值上成立，而新方法要求约束在所有问题实例上都成立，以产生更小的约束违反。

Method: 将学习参数化直接代入具有逐点约束的最优潮流问题中，在双域中使用增广拉格朗日和双梯度上升算法进行训练。

Result: 数值实验表明，逐点约束训练产生的解具有更小的约束违反，在约束最难满足的极端情况下效果最显著，在具有大量母线的电力系统中收益最大。

Conclusion: 逐点约束训练方法在减少约束违反方面优于传统监督学习方法，特别是在极端情况和大型电力系统中表现更佳。

Abstract: Training learning parameterizations to solve optimal power flow (OPF) with
pointwise constraints is proposed. In this novel training approach, a learning
parameterization is substituted directly into an OPF problem with constraints
required to hold over all problem instances. This is different from existing
supervised learning methods in which constraints are required to hold across
the average of problem instances. Training with pointwise constraints is
undertaken in the dual domain with the use of augmented Lagrangian and dual
gradient ascent algorithm. Numerical experiments demonstrate that training with
pointwise constraints produces solutions with smaller constraint violations.
Experiments further demonstrated that pointwise constraints are most effective
at reducing constraint violations in corner cases - defined as those
realizations in which constraints are most difficult to satisfy. Gains are most
pronounced in power systems with large numbers of buses.

</details>


### [102] [Bilevel Analysis of Cost and Emissions Externalities from Data Center Load Shifting](https://arxiv.org/abs/2510.20805)
*Aron Brenner,Rahman Khorramfar,Nathan Engelman Lado,Line Roald,Saurabh Amin*

Main category: eess.SY

TL;DR: 开发了一个双层优化框架，分析数据中心在响应电价和边际排放信号时的负荷转移行为，研究其与电力系统运行的交互影响。


<details>
  <summary>Details</summary>
Motivation: 数据中心作为大型灵活电力负荷，能够通过跨地域转移计算负载来响应经济和环境信号，但其灵活性对电力系统运行的影响取决于与网络约束和市场信号的交互方式。

Method: 采用双层优化框架，上层是数据中心最小化电力成本和边际排放强度的加权组合，下层是系统运营商在经济调度下考虑输电和发电约束。基于三节点电力系统推导闭式分段线性表达式。

Result: 识别了数据中心分散决策与社会最优行为对齐或偏离的充分条件，揭示了系统拓扑和发电机不对称性对激励对齐的影响，以及边际价格或排放信号可能失效的情况。

Conclusion: 结果为分析碳感知激励下的分散灵活性提供了可处理的起点，并为改进灵活负荷与系统运行之间的协调指明了方向。

Abstract: Data centers are emerging as large, flexible electricity consumers capable of
shifting computational workloads across locations in response to economic and
environmental signals. While this flexibility has potential for emissions
reduction, its impact on power system operations depends critically on how such
behavior interacts with network constraints and market signals. We develop a
bilevel optimization framework in which a data center minimizes a weighted
combination of electricity cost and marginal emissions intensity (LME), while
the system operator clears economic dispatch under transmission and generation
constraints. Focusing on a stylized three-bus power system, we derive
closed-form, piecewise-linear expressions for both the data center and
system-wide objectives as functions of the data centers' load shift. These
expressions capture threshold-driven regime changes due to congestion and
renewable saturation. We identify sufficient conditions under which the data
center's decentralized decisions align with or diverge from socially optimal
behavior and characterize the resulting externalities. Our results reveal how
system topology and generator asymmetry affect incentive alignment and provide
insight into when marginal price or emissions signals may fail to guide
flexible loads toward socially beneficial outcomes. Our results offer a
tractable starting point for analyzing decentralized flexibility under
carbon-aware incentives and suggest directions for improving coordination
between flexible loads and system operations.

</details>
