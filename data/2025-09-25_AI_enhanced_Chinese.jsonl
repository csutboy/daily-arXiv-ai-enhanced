{"id": "2509.19413", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.19413", "abs": "https://arxiv.org/abs/2509.19413", "authors": ["Ayusha Fayyaz", "Zoltan Bartha"], "title": "Research and development as a driver of innovation and economic growth; case of developing economies", "comment": null, "summary": "The goal of this research is to uncover the channels through which research\nand development (R&D) impacts economic growth in developing countries. The\nstudy employed nine variables from three broader categories in the World\nEconomic Forum database, each covering 32 countries from the\nlower-middle-income group for the year 2019. The theoretical framework is based\non the R&D ecosystem, which includes components such as Institutions, Human\ncapital, Capital market, R&D, and Innovation. Each of these components can\ncontribute to the economic development of the country. Using Structural\nEquation Modelling (SEM), we build a path diagram to visualize and confirm a\npotential relationship between the components. R&D features had a positive\nimpact on innovation (regression weight estimate: +0.34, p = 0.001), as did\ncapital market institutions (regression weight estimate: +0.12, p = 0.007), but\nneither had a significant impact on growth. According to the Schumpeterian\ninstitutional interpretation, R&D and innovation efforts may not lead to\nsustained growth in middle-income countries. We find no significant connection\nbetween innovation performance and economic growth. This suggests that while\nR&D and capital markets may contribute to innovation through entrepreneurship,\nthis contribution is not impactful enough to drive economic growth in\ndeveloping countries. Our findings provide further evidence of the\nmiddle-income trap.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u5206\u679032\u4e2a\u4e2d\u4f4e\u6536\u5165\u56fd\u5bb6\uff0c\u53d1\u73b0\u7814\u53d1\u548c\u8d44\u672c\u5e02\u573a\u5bf9\u521b\u65b0\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u4f46\u521b\u65b0\u4e0e\u7ecf\u6d4e\u589e\u957f\u4e4b\u95f4\u6ca1\u6709\u663e\u8457\u8054\u7cfb\uff0c\u652f\u6301\u4e86\u4e2d\u7b49\u6536\u5165\u9677\u9631\u7406\u8bba\u3002", "motivation": "\u63ed\u793a\u7814\u53d1\u5bf9\u53d1\u5c55\u4e2d\u56fd\u5bb6\u7ecf\u6d4e\u589e\u957f\u7684\u5f71\u54cd\u6e20\u9053\uff0c\u9a8c\u8bc1\u7814\u53d1\u751f\u6001\u7cfb\u7edf\u5404\u7ec4\u6210\u90e8\u5206\uff08\u5236\u5ea6\u3001\u4eba\u529b\u8d44\u672c\u3001\u8d44\u672c\u5e02\u573a\u3001\u7814\u53d1\u3001\u521b\u65b0\uff09\u5bf9\u7ecf\u6d4e\u53d1\u5c55\u7684\u8d21\u732e\u8def\u5f84\u3002", "method": "\u4f7f\u7528\u4e16\u754c\u7ecf\u6d4e\u8bba\u575b\u6570\u636e\u5e93\u76849\u4e2a\u53d8\u91cf\uff0c\u6db5\u76d632\u4e2a\u4e2d\u4f4e\u6536\u5165\u56fd\u5bb62019\u5e74\u6570\u636e\uff0c\u91c7\u7528\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u6784\u5efa\u8def\u5f84\u56fe\u5206\u6790\u5404\u53d8\u91cf\u95f4\u5173\u7cfb\u3002", "result": "\u7814\u53d1\u5bf9\u521b\u65b0\u6709\u663e\u8457\u6b63\u5411\u5f71\u54cd\uff08\u56de\u5f52\u6743\u91cd+0.34\uff0cp=0.001\uff09\uff0c\u8d44\u672c\u5e02\u573a\u5236\u5ea6\u5bf9\u521b\u65b0\u4e5f\u6709\u6b63\u5411\u5f71\u54cd\uff08+0.12\uff0cp=0.007\uff09\uff0c\u4f46\u4e24\u8005\u5bf9\u7ecf\u6d4e\u589e\u957f\u5747\u65e0\u663e\u8457\u5f71\u54cd\uff0c\u521b\u65b0\u8868\u73b0\u4e0e\u7ecf\u6d4e\u589e\u957f\u4e4b\u95f4\u4e5f\u65e0\u663e\u8457\u5173\u8054\u3002", "conclusion": "\u7814\u53d1\u548c\u8d44\u672c\u5e02\u573a\u867d\u80fd\u4fc3\u8fdb\u521b\u65b0\uff0c\u4f46\u8fd9\u79cd\u8d21\u732e\u4e0d\u8db3\u4ee5\u63a8\u52a8\u53d1\u5c55\u4e2d\u56fd\u5bb6\u7ecf\u6d4e\u589e\u957f\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u4e2d\u7b49\u6536\u5165\u9677\u9631\u63d0\u4f9b\u4e86\u8fdb\u4e00\u6b65\u8bc1\u636e\u3002"}}
{"id": "2509.19416", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.19416", "abs": "https://arxiv.org/abs/2509.19416", "authors": ["Zoltan Bartha"], "title": "Changes in varieties of capitalism within the OECD between 2010 and 2020", "comment": null, "summary": "This study aims to reveal different varieties of capitalism and to uncover\nnew patterns of development that emerged between 2010 and 2020. A hybrid model\nis applied that quantifies three pillars of development (Future - F, Outside -\nO, Inside - I) using supply-side and demand-side indicators that measure norms,\ninstitutions, and policies. Investigating 34 OECD members, this study describes\nfive varieties of capitalism: traditional, dualistic, government-led, open\nmarket-based, and human capital-based models. It is suggested that the most\nsignificant cut-off point in the development of OECD economies in this period\nwas along the green growth dimension, where European countries with a tradition\nin coordinated markets outperform the rest. Using Israel and Estonia as an\nexample, it is also suggested that institutional and policy changes that\nenhance the quality of governance and make coordination more effective are the\nway out of the middle-income trap.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793a2010-2020\u5e74\u95f4\u8d44\u672c\u4e3b\u4e49\u7684\u4e0d\u540c\u53d8\u4f53\u548c\u65b0\u53d1\u5c55\u6a21\u5f0f\uff0c\u901a\u8fc7\u6df7\u5408\u6a21\u578b\u91cf\u5316\u53d1\u5c55\u7684\u4e09\u4e2a\u652f\u67f1\uff08\u672a\u6765\u3001\u5916\u90e8\u3001\u5185\u90e8\uff09\uff0c\u8bc6\u522b\u51faOECD\u56fd\u5bb6\u7684\u4e94\u79cd\u8d44\u672c\u4e3b\u4e49\u7c7b\u578b\uff0c\u5e76\u53d1\u73b0\u7eff\u8272\u589e\u957f\u662f\u91cd\u8981\u5206\u754c\u70b9\u3002", "motivation": "\u63ed\u793a2010-2020\u5e74\u95f4OECD\u56fd\u5bb6\u8d44\u672c\u4e3b\u4e49\u53d1\u5c55\u7684\u65b0\u6a21\u5f0f\u548c\u53d8\u4f53\uff0c\u63a2\u7d22\u4e2d\u7b49\u6536\u5165\u9677\u9631\u7684\u89e3\u51b3\u8def\u5f84\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6a21\u578b\uff0c\u4f7f\u7528\u4f9b\u7ed9\u4fa7\u548c\u9700\u6c42\u4fa7\u6307\u6807\u91cf\u5316\u53d1\u5c55\u7684\u4e09\u4e2a\u652f\u67f1\uff08F-O-I\uff09\uff0c\u5bf934\u4e2aOECD\u6210\u5458\u56fd\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u79cd\u8d44\u672c\u4e3b\u4e49\u7c7b\u578b\uff1a\u4f20\u7edf\u578b\u3001\u4e8c\u5143\u578b\u3001\u653f\u5e9c\u4e3b\u5bfc\u578b\u3001\u5f00\u653e\u5e02\u573a\u578b\u548c\u4eba\u529b\u8d44\u672c\u578b\uff1b\u53d1\u73b0\u6b27\u6d32\u534f\u8c03\u5e02\u573a\u7ecf\u6d4e\u4f53\u5728\u7eff\u8272\u589e\u957f\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff1b\u4ee5\u8272\u5217\u548c\u7231\u6c99\u5c3c\u4e9a\u6848\u4f8b\u663e\u793a\u5236\u5ea6\u653f\u7b56\u6539\u9769\u53ef\u5e2e\u52a9\u6446\u8131\u4e2d\u7b49\u6536\u5165\u9677\u9631\u3002", "conclusion": "\u5236\u5ea6\u653f\u7b56\u6539\u9769\u63d0\u5347\u6cbb\u7406\u8d28\u91cf\u548c\u534f\u8c03\u6709\u6548\u6027\u662f\u6446\u8131\u4e2d\u7b49\u6536\u5165\u9677\u9631\u7684\u5173\u952e\u8def\u5f84\uff0c\u7eff\u8272\u589e\u957f\u7ef4\u5ea6\u662fOECD\u7ecf\u6d4e\u53d1\u5c55\u7684\u91cd\u8981\u5206\u754c\u70b9\u3002"}}
{"id": "2509.19556", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.19556", "abs": "https://arxiv.org/abs/2509.19556", "authors": ["Wei Li", "Kashi Kafle", "Anna Josephson"], "title": "Gender and Agricultural Commercialization in Sub-Saharan Africa: Evidence from Three Panel Surveys", "comment": null, "summary": "Agricultural commercialization is often promoted as a key driver of\ndevelopment in Sub-Saharan Africa, yet its benefits may not extend equally to\nall farmers. Using longitudinal household data from the LSMS-ISA and a two-way\nMundlak fixed effects estimator, we examine the relationship between farmers'\ngender and agricultural commercialization in Ethiopia, Nigeria, and Tanzania.\nIn Ethiopia and Nigeria, women-headed households and those with a higher share\nof women-managed land face substantial disadvantages in market engagement,\nparticularly in households oriented towards self-consumption. Interestingly, in\nboth countries, women-headed households that do engage in sales are more likely\nto sell to market buyers and less likely to sell to individual buyers compared\nto men-headed households. In contrast, in Tanzania, the negative associations\nbetween gender and commercialization are weaker and less robust across\noutcomes. Overall, these findings demonstrate that gender gaps in\ncommercialization are highly context-specific rather than universal,\nhighlighting the need for country-tailored policies that address the\ninstitutional and market constraints faced by women farmers.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u9762\u677f\u6570\u636e\u548c\u56fa\u5b9a\u6548\u5e94\u6a21\u578b\u5206\u6790\u57c3\u585e\u4fc4\u6bd4\u4e9a\u3001\u5c3c\u65e5\u5229\u4e9a\u548c\u5766\u6851\u5c3c\u4e9a\u4e09\u56fd\u519c\u6237\u6027\u522b\u4e0e\u519c\u4e1a\u5546\u4e1a\u5316\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u6027\u522b\u5dee\u8ddd\u5177\u6709\u9ad8\u5ea6\u60c5\u5883\u7279\u5f02\u6027\u3002", "motivation": "\u63a2\u8ba8\u519c\u4e1a\u5546\u4e1a\u5316\u5728\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u7684\u53d1\u5c55\u4f5c\u7528\u662f\u5426\u5bf9\u6240\u6709\u519c\u6c11\u5e73\u7b49\uff0c\u7279\u522b\u5173\u6ce8\u6027\u522b\u5dee\u5f02\u3002", "method": "\u4f7f\u7528LSMS-ISA\u7eb5\u5411\u5bb6\u5ead\u6570\u636e\u548c\u53cc\u5411Mundlak\u56fa\u5b9a\u6548\u5e94\u4f30\u8ba1\u5668\uff0c\u5206\u6790\u4e09\u56fd\u6570\u636e\u3002", "result": "\u5728\u57c3\u585e\u4fc4\u6bd4\u4e9a\u548c\u5c3c\u65e5\u5229\u4e9a\uff0c\u5973\u6027\u6237\u4e3b\u5bb6\u5ead\u9762\u4e34\u663e\u8457\u7684\u5e02\u573a\u53c2\u4e0e\u52a3\u52bf\uff0c\u4f46\u5728\u5766\u6851\u5c3c\u4e9a\u8fd9\u79cd\u8d1f\u9762\u5173\u8054\u8f83\u5f31\u4e14\u4e0d\u7a33\u5065\u3002", "conclusion": "\u6027\u522b\u5546\u4e1a\u5316\u5dee\u8ddd\u5177\u6709\u9ad8\u5ea6\u60c5\u5883\u7279\u5f02\u6027\uff0c\u9700\u8981\u9488\u5bf9\u5404\u56fd\u7684\u5236\u5ea6\u7ea6\u675f\u5236\u5b9a\u5dee\u5f02\u5316\u653f\u7b56\u3002"}}
{"id": "2509.20203", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.20203", "abs": "https://arxiv.org/abs/2509.20203", "authors": ["Leah Costlow", "Rachel Gilbert", "William A. Masters", "Flaminia Ortenzi", "Ty Beal", "Ashish Deo", "Widya Sutiyo", "Sutamara Noor", "Wendy Gonzalez"], "title": "Healthy diets are affordable but often displaced by other foods in Indonesia", "comment": null, "summary": "New methods for modeling least-cost diets that meet nutritional requirements\nfor health have emerged as important tools for informing nutrition policy and\nprogramming around the world. This study develops a three-step approach using\ncost of healthy diet to inform targeted nutrition programming in Indonesia. We\ncombine detailed retail prices and household survey data from Indonesia to\ndescribe how reported consumption and expenditure patterns across all levels of\nhousehold income diverge from least cost healthy diets using items from nearby\nmarkets. In this analysis, we examine regional price variations, identify\nhouseholds with insufficient income for healthy diets, and analyze the nutrient\nadequacy of reported consumption patterns. We find that household food spending\nwas sufficient to meet national dietary guidelines using the least expensive\nlocally available items for over 98% of Indonesians, but almost all households\nconsume substantial quantities of discretionary foods and mixed dishes while\nconsuming too little energy from fruits, vegetables, and legumes, nuts, and\nseeds. Households with higher incomes have higher nutrient adequacy and are\ncloser to meeting local dietary guidelines, but still fall short of\nrecommendations. These findings shed new light on how actual food demand\ndiffers from least-cost healthy diets, due to factors other than affordability,\nsuch as taste, convenience, and aspirations shaped by marketing and other\nsociocultural influences.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u4e09\u6b65\u6cd5\uff0c\u5229\u7528\u5065\u5eb7\u996e\u98df\u6210\u672c\u4e3a\u5370\u5ea6\u5c3c\u897f\u4e9a\u7684\u8425\u517b\u89c4\u5212\u63d0\u4f9b\u4fe1\u606f\uff0c\u53d1\u73b0\u5c3d\u7ba198%\u7684\u5370\u5c3c\u5bb6\u5ead\u6709\u8db3\u591f\u6536\u5165\u8d2d\u4e70\u5065\u5eb7\u996e\u98df\uff0c\u4f46\u5b9e\u9645\u6d88\u8d39\u6a21\u5f0f\u4e0e\u8425\u517b\u6307\u5357\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u5f00\u53d1\u65b0\u7684\u6700\u4f4e\u6210\u672c\u5065\u5eb7\u996e\u98df\u5efa\u6a21\u65b9\u6cd5\uff0c\u4e3a\u5168\u7403\u8425\u517b\u653f\u7b56\u548c\u89c4\u5212\u63d0\u4f9b\u91cd\u8981\u5de5\u5177\uff0c\u7279\u522b\u5173\u6ce8\u5370\u5ea6\u5c3c\u897f\u4e9a\u7684\u8425\u517b\u89c4\u5212\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u8be6\u7ec6\u96f6\u552e\u4ef7\u683c\u548c\u5bb6\u5ead\u8c03\u67e5\u6570\u636e\u7684\u4e09\u6b65\u6cd5\uff1a\u5206\u6790\u533a\u57df\u4ef7\u683c\u5dee\u5f02\u3001\u8bc6\u522b\u6536\u5165\u4e0d\u8db3\u5bb6\u5ead\u3001\u5206\u6790\u62a5\u544a\u6d88\u8d39\u6a21\u5f0f\u7684\u8425\u517b\u5145\u8db3\u6027\u3002", "result": "98%\u7684\u5370\u5c3c\u5bb6\u5ead\u98df\u54c1\u652f\u51fa\u8db3\u4ee5\u901a\u8fc7\u6700\u4fbf\u5b9c\u7684\u672c\u5730\u53ef\u7528\u98df\u54c1\u6ee1\u8db3\u56fd\u5bb6\u996e\u98df\u6307\u5357\uff0c\u4f46\u51e0\u4e4e\u6240\u6709\u5bb6\u5ead\u90fd\u6d88\u8d39\u5927\u91cf\u975e\u5fc5\u9700\u98df\u54c1\uff0c\u6c34\u679c\u3001\u852c\u83dc\u3001\u8c46\u7c7b\u548c\u575a\u679c\u6444\u5165\u4e0d\u8db3\u3002", "conclusion": "\u5b9e\u9645\u98df\u54c1\u9700\u6c42\u4e0e\u6700\u4f4e\u6210\u672c\u5065\u5eb7\u996e\u98df\u7684\u5dee\u5f02\u4e0d\u4ec5\u6e90\u4e8e\u53ef\u8d1f\u62c5\u6027\uff0c\u8fd8\u53d7\u5230\u53e3\u5473\u3001\u4fbf\u5229\u6027\u4ee5\u53ca\u8425\u9500\u548c\u793e\u4f1a\u6587\u5316\u5f71\u54cd\u5f62\u6210\u7684\u671f\u671b\u7b49\u56e0\u7d20\u5f71\u54cd\u3002"}}
{"id": "2509.19452", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19452", "abs": "https://arxiv.org/abs/2509.19452", "authors": ["Alessandro Saviolo", "Jeffrey Mao", "Giuseppe Loianno"], "title": "HUNT: High-Speed UAV Navigation and Tracking in Unstructured Environments via Instantaneous Relative Frames", "comment": null, "summary": "Search and rescue operations require unmanned aerial vehicles to both\ntraverse unknown unstructured environments at high speed and track targets once\ndetected. Achieving both capabilities under degraded sensing and without global\nlocalization remains an open challenge. Recent works on relative navigation\nhave shown robust tracking by anchoring planning and control to a visible\ndetected object, but cannot address navigation when no target is in the field\nof view. We present HUNT (High-speed UAV Navigation and Tracking), a real-time\nframework that unifies traversal, acquisition, and tracking within a single\nrelative formulation. HUNT defines navigation objectives directly from onboard\ninstantaneous observables such as attitude, altitude, and velocity, enabling\nreactive high-speed flight during search. Once a target is detected, the same\nperception-control pipeline transitions seamlessly to tracking. Outdoor\nexperiments in dense forests, container compounds, and search-and-rescue\noperations with vehicles and mannequins demonstrate robust autonomy where\nglobal methods fail.", "AI": {"tldr": "HUNT\u662f\u4e00\u4e2a\u5b9e\u65f6\u6846\u67b6\uff0c\u5c06\u65e0\u4eba\u673a\u7684\u9ad8\u901f\u7a7f\u8d8a\u3001\u76ee\u6807\u83b7\u53d6\u548c\u8ddf\u8e2a\u7edf\u4e00\u5728\u76f8\u5bf9\u5bfc\u822a\u6846\u67b6\u4e0b\uff0c\u80fd\u591f\u5728\u6ca1\u6709\u5168\u5c40\u5b9a\u4f4d\u548c\u4f20\u611f\u5668\u964d\u7ea7\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u81ea\u4e3b\u641c\u7d22\u6551\u63f4\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u5728\u672a\u77e5\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u9ad8\u901f\u7a7f\u8d8a\u548c\u8ddf\u8e2a\u76ee\u6807\u7684\u53cc\u91cd\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u4f20\u611f\u5668\u964d\u7ea7\u4e14\u6ca1\u6709\u5168\u5c40\u5b9a\u4f4d\u7684\u6311\u6218\u6027\u573a\u666f\u4e0b\u3002", "method": "\u57fa\u4e8e\u76f8\u5bf9\u5bfc\u822a\u65b9\u6cd5\uff0c\u5c06\u5bfc\u822a\u76ee\u6807\u76f4\u63a5\u5b9a\u4e49\u4e3a\u673a\u8f7d\u77ac\u65f6\u89c2\u6d4b\u503c\uff08\u59ff\u6001\u3001\u9ad8\u5ea6\u3001\u901f\u5ea6\uff09\uff0c\u5b9e\u73b0\u641c\u7d22\u9636\u6bb5\u7684\u53cd\u5e94\u5f0f\u9ad8\u901f\u98de\u884c\uff0c\u68c0\u6d4b\u5230\u76ee\u6807\u540e\u65e0\u7f1d\u5207\u6362\u5230\u8ddf\u8e2a\u6a21\u5f0f\u3002", "result": "\u5728\u5bc6\u96c6\u68ee\u6797\u3001\u96c6\u88c5\u7bb1\u573a\u5730\u548c\u641c\u6551\u64cd\u4f5c\u7b49\u771f\u5b9e\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u6237\u5916\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u5728\u5168\u5c40\u65b9\u6cd5\u5931\u6548\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9c81\u68d2\u7684\u81ea\u4e3b\u6027\u3002", "conclusion": "HUNT\u6846\u67b6\u6210\u529f\u5730\u5c06\u7a7f\u8d8a\u3001\u83b7\u53d6\u548c\u8ddf\u8e2a\u529f\u80fd\u7edf\u4e00\u5728\u5355\u4e00\u76f8\u5bf9\u8868\u8ff0\u4e2d\uff0c\u4e3a\u65e0\u4eba\u673a\u5728\u6311\u6218\u6027\u73af\u5883\u4e2d\u7684\u641c\u7d22\u6551\u63f4\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19500", "categories": ["stat.AP", "62"], "pdf": "https://arxiv.org/pdf/2509.19500", "abs": "https://arxiv.org/abs/2509.19500", "authors": ["Lee Kennedy-Shaffer"], "title": "One Person, How Many Votes? Demographic Distortions in United States Elections", "comment": "28 pages, 3 figures, 1 table", "summary": "Representative democracy in the United States relies on election systems that\ntransmit votes into representatives in three key bodies: the two chambers of\nthe federal legislature (House of Representatives and Senate) and the Electoral\nCollege, which selects the President and Vice-President. This happens through a\nprocess of re-weighting based on geographic units (congressional districts and\nstates) that can introduce substantial distortion. In this paper, I propose\nquantitative measures of this distortion that can be applied to demographic\ngroups, using Census data, to assess and visualize these distortive effects.\nThese include the absolute weight of votes under these systems and the excess\npopulation represented in the bodies through the distortions. Visualizing these\nmetrics from 2000 -- 2020 shows persistent malapportionment in key demographic\ncategories. White (non-Hispanic) residents, residents of rural areas, and\nowner-occupied households are overrepresented in the Senate and Electoral\nCollege; Black and Hispanic people, urban dwellers, and renter-occupied\nhouseholds are underrepresented. For urban residents, this underrepresentation\nis the equivalent of 25 million fewer residents in the Senate and nearly 5\nmillion in the Electoral College. I discuss implications for further research\non the effects of these distortions and their interactions with other features\nof the electoral system.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u91cf\u5316\u7f8e\u56fd\u9009\u4e3e\u7cfb\u7edf\u4e2d\u5730\u7406\u5355\u4f4d\u91cd\u52a0\u6743\u8fc7\u7a0b\u5bfc\u81f4\u7684\u4eba\u53e3\u4ee3\u8868\u6027\u626d\u66f2\u7684\u6d4b\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc72000-2020\u5e74\u6570\u636e\u53ef\u89c6\u5316\u663e\u793a\u767d\u4eba\u548c\u519c\u6751\u5c45\u6c11\u5728\u53c2\u8bae\u9662\u548c\u9009\u4e3e\u4eba\u56e2\u4e2d\u8fc7\u5ea6\u4ee3\u8868\uff0c\u800c\u9ed1\u4eba\u548c\u57ce\u5e02\u5c45\u6c11\u5219\u4ee3\u8868\u6027\u4e0d\u8db3\u3002", "motivation": "\u7f8e\u56fd\u4ee3\u8bae\u5236\u6c11\u4e3b\u901a\u8fc7\u5730\u7406\u5355\u4f4d\uff08\u56fd\u4f1a\u9009\u533a\u548c\u5dde\uff09\u5c06\u9009\u7968\u8f6c\u6362\u4e3a\u4ee3\u8868\u7684\u8fc7\u7a0b\u53ef\u80fd\u5f15\u5165\u4e25\u91cd\u626d\u66f2\uff0c\u9700\u8981\u91cf\u5316\u8bc4\u4f30\u8fd9\u79cd\u626d\u66f2\u5bf9\u4eba\u53e3\u7fa4\u4f53\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u4eba\u53e3\u666e\u67e5\u6570\u636e\uff0c\u63d0\u51fa\u7edd\u5bf9\u6295\u7968\u6743\u91cd\u548c\u8d85\u989d\u4eba\u53e3\u4ee3\u8868\u6027\u7b49\u91cf\u5316\u6307\u6807\u6765\u6d4b\u91cf\u9009\u4e3e\u7cfb\u7edf\u7684\u626d\u66f2\u6548\u5e94\uff0c\u5e76\u5bf92000-2020\u5e74\u6570\u636e\u8fdb\u884c\u53ef\u89c6\u5316\u5206\u6790\u3002", "result": "\u5206\u6790\u663e\u793a\u767d\u79cd\u4eba\uff08\u975e\u897f\u73ed\u7259\u88d4\uff09\u3001\u519c\u6751\u5c45\u6c11\u548c\u81ea\u6709\u4f4f\u623f\u5bb6\u5ead\u5728\u53c2\u8bae\u9662\u548c\u9009\u4e3e\u4eba\u56e2\u4e2d\u8fc7\u5ea6\u4ee3\u8868\uff1b\u9ed1\u4eba\u3001\u897f\u73ed\u7259\u88d4\u3001\u57ce\u5e02\u5c45\u6c11\u548c\u79df\u623f\u5bb6\u5ead\u4ee3\u8868\u6027\u4e0d\u8db3\u3002\u57ce\u5e02\u5c45\u6c11\u4ee3\u8868\u6027\u4e0d\u8db3\u76f8\u5f53\u4e8e\u53c2\u8bae\u9662\u4e2d\u51cf\u5c112500\u4e07\u5c45\u6c11\uff0c\u9009\u4e3e\u4eba\u56e2\u4e2d\u51cf\u5c11\u8fd1500\u4e07\u5c45\u6c11\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u9009\u4e3e\u7cfb\u7edf\u4e2d\u6301\u7eed\u5b58\u5728\u7684\u4ee3\u8868\u6027\u626d\u66f2\u95ee\u9898\uff0c\u4e3a\u7814\u7a76\u8fd9\u4e9b\u626d\u66f2\u6548\u5e94\u53ca\u5176\u4e0e\u9009\u4e3e\u7cfb\u7edf\u5176\u4ed6\u7279\u5f81\u7684\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.19642", "categories": ["cs.ET", "physics.optics"], "pdf": "https://arxiv.org/pdf/2509.19642", "abs": "https://arxiv.org/abs/2509.19642", "authors": ["Yuanhao Liang", "James Wang", "Kaiwen Xue", "Xinyi Ren", "Ran Yin", "Shaoyuan Ou", "Lian Zhou", "Yuan Li", "Tobias Heuser", "Niels Heermeier", "Ian Christen", "James A. Lott", "Stephan Reitzenstein", "Mengjie Yu", "Zaijun Chen"], "title": "High Clockrate Free-space Optical In-Memory Computing", "comment": "16 pages, 5 figures (main); 8 pages, 3 figures (Supplementary\n  Information)", "summary": "The ability to process and act on data in real time is increasingly critical\nfor applications ranging from autonomous vehicles, three-dimensional\nenvironmental sensing and remote robotics. However, the deployment of deep\nneural networks (DNNs) in edge devices is hindered by the lack of\nenergy-efficient scalable computing hardware. Here, we introduce a fanout\nspatial time-of-flight optical neural network (FAST-ONN) that calculates\nbillions of convolutions per second with ultralow latency and power\nconsumption. This is enabled by the combination of high-speed dense arrays of\nvertical-cavity surface-emitting lasers (VCSELs) for input modulation with\nspatial light modulators of high pixel counts for in-memory weighting. In a\nthree-dimensional optical system, parallel differential readout allows signed\nweight values accurate inference in a single shot. The performance is\nbenchmarked with feature extraction in You-Only-Look-Once (YOLO) for\nconvolution at 100 million frames per second (MFPS), and in-system backward\npropagation training with photonic reprogrammability. The VCSEL transmitters\nare implementable in any free-space optical computing systems to improve the\nclockrate to over gigahertz. The high scalability in device counts and channel\nparallelism enables a new avenue to scale up free space computing hardware.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFAST-ONN\u7684\u6247\u51fa\u7a7a\u95f4\u98de\u884c\u65f6\u95f4\u5149\u5b66\u795e\u7ecf\u7f51\u7edc\uff0c\u80fd\u591f\u5728\u8d85\u4f4e\u5ef6\u8fdf\u548c\u529f\u8017\u4e0b\u5b9e\u73b0\u6bcf\u79d2\u6570\u5341\u4ebf\u6b21\u5377\u79ef\u8ba1\u7b97\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u3001\u4e09\u7ef4\u73af\u5883\u611f\u77e5\u548c\u8fdc\u7a0b\u673a\u5668\u4eba\u7b49\u5e94\u7528\u5bf9\u5b9e\u65f6\u6570\u636e\u5904\u7406\u9700\u6c42\u7684\u589e\u957f\uff0c\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u53d7\u5230\u80fd\u6548\u548c\u53ef\u6269\u5c55\u8ba1\u7b97\u786c\u4ef6\u7684\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u578b\u9ad8\u6548\u8ba1\u7b97\u67b6\u6784\u3002", "method": "\u91c7\u7528\u9ad8\u901f\u5bc6\u96c6\u5782\u76f4\u8154\u9762\u53d1\u5c04\u6fc0\u5149\u5668\u9635\u5217\u8fdb\u884c\u8f93\u5165\u8c03\u5236\uff0c\u7ed3\u5408\u9ad8\u50cf\u7d20\u7a7a\u95f4\u5149\u8c03\u5236\u5668\u5b9e\u73b0\u5185\u5b58\u5185\u6743\u91cd\u8ba1\u7b97\uff0c\u901a\u8fc7\u4e09\u7ef4\u5149\u5b66\u7cfb\u7edf\u548c\u5e76\u884c\u5dee\u5206\u8bfb\u51fa\u6280\u672f\u5b9e\u73b0\u5e26\u7b26\u53f7\u6743\u91cd\u7684\u5355\u6b21\u51c6\u786e\u63a8\u7406\u3002", "result": "\u5728YOLO\u7279\u5f81\u63d0\u53d6\u4e2d\u5b9e\u73b0\u4e861\u4ebf\u5e27/\u79d2\u7684\u5377\u79ef\u901f\u5ea6\uff0c\u652f\u6301\u7cfb\u7edf\u5185\u53cd\u5411\u4f20\u64ad\u8bad\u7ec3\u548c\u5149\u5b50\u53ef\u91cd\u7f16\u7a0b\u6027\uff0cVCSEL\u53d1\u5c04\u5668\u53ef\u5c06\u65f6\u949f\u9891\u7387\u63d0\u5347\u81f3\u5343\u5146\u8d6b\u5179\u7ea7\u522b\u3002", "conclusion": "\u8be5\u6280\u672f\u901a\u8fc7\u5668\u4ef6\u6570\u91cf\u548c\u901a\u9053\u5e76\u884c\u6027\u7684\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u81ea\u7531\u7a7a\u95f4\u8ba1\u7b97\u786c\u4ef6\u7684\u89c4\u6a21\u5316\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u6709\u671b\u63a8\u52a8\u5149\u5b66\u8ba1\u7b97\u5728\u8fb9\u7f18\u8bbe\u5907\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2509.19497", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19497", "abs": "https://arxiv.org/abs/2509.19497", "authors": ["Italo Alberto do Nascimento Sousa", "Jorge Machado", "Jose Carlos Vaz"], "title": "Generative AI as a catalyst for democratic Innovation: Enhancing citizen engagement in participatory budgeting", "comment": "19 pages, VI International Meeting on Participation, Democracy and\n  Public Policies", "summary": "This research examines the role of Generative Artificial Intelligence (AI) in\nenhancing citizen engagement in participatory budgeting. In response to\nchallenges like declining civic participation and increased societal\npolarization, the study explores how online political participation can\nstrengthen democracy and promote social equity. By integrating Generative AI\ninto public consultation platforms, the research aims to improve citizen\nproposal formulation and foster effective dialogue between citizens and\ngovernment. It assesses the capacities governments need to implement\nAI-enhanced participatory tools, considering technological dependencies and\nvulnerabilities. Analyzing technological structures, actors, interests, and\nstrategies, the study contributes to understanding how technological\nadvancements can reshape participatory institutions to better facilitate\ncitizen involvement. Ultimately, the research highlights how Generative AI can\ntransform participatory institutions, promoting inclusive, democratic\nengagement and empowering citizens.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u63d0\u5347\u516c\u6c11\u53c2\u4e0e\u5f0f\u9884\u7b97\u4e2d\u7684\u4f5c\u7528\uff0c\u65e8\u5728\u901a\u8fc7AI\u6280\u672f\u6539\u5584\u516c\u6c11\u63d0\u6848\u5236\u5b9a\u548c\u653f\u5e9c-\u516c\u6c11\u5bf9\u8bdd\uff0c\u4fc3\u8fdb\u6c11\u4e3b\u53c2\u4e0e\u548c\u793e\u4f1a\u516c\u5e73\u3002", "motivation": "\u5e94\u5bf9\u516c\u6c11\u53c2\u4e0e\u5ea6\u4e0b\u964d\u548c\u793e\u4f1a\u4e24\u6781\u5206\u5316\u7684\u6311\u6218\uff0c\u63a2\u7d22\u5728\u7ebf\u653f\u6cbb\u53c2\u4e0e\u5982\u4f55\u52a0\u5f3a\u6c11\u4e3b\u548c\u4fc3\u8fdb\u793e\u4f1a\u516c\u5e73\u3002", "method": "\u901a\u8fc7\u5c06\u751f\u6210\u5f0fAI\u6574\u5408\u5230\u516c\u5171\u54a8\u8be2\u5e73\u53f0\uff0c\u5206\u6790\u6280\u672f\u7ed3\u6784\u3001\u53c2\u4e0e\u8005\u3001\u5229\u76ca\u548c\u7b56\u7565\uff0c\u8bc4\u4f30\u653f\u5e9c\u5b9e\u65bdAI\u589e\u5f3a\u53c2\u4e0e\u5de5\u5177\u6240\u9700\u7684\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u751f\u6210\u5f0fAI\u80fd\u591f\u6539\u5584\u516c\u6c11\u63d0\u6848\u5236\u5b9a\uff0c\u4fc3\u8fdb\u6709\u6548\u7684\u653f\u5e9c-\u516c\u6c11\u5bf9\u8bdd\uff0c\u4f46\u9700\u8981\u8003\u8651\u6280\u672f\u4f9d\u8d56\u6027\u548c\u8106\u5f31\u6027\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u80fd\u591f\u91cd\u5851\u53c2\u4e0e\u5f0f\u5236\u5ea6\uff0c\u4fc3\u8fdb\u5305\u5bb9\u6027\u6c11\u4e3b\u53c2\u4e0e\uff0c\u8d4b\u4e88\u516c\u6c11\u66f4\u591a\u6743\u529b\uff0c\u4f46\u9700\u8981\u5e73\u8861\u6280\u672f\u4f18\u52bf\u4e0e\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2509.19911", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2509.19911", "abs": "https://arxiv.org/abs/2509.19911", "authors": ["Alain Hecq", "Ivan Ricardo", "Ines Wilms"], "title": "Decomposing Co-Movements in Matrix-Valued Time Series: A Pseudo-Structural Reduced-Rank Approach", "comment": null, "summary": "We propose a pseudo-structural framework for analyzing contemporaneous\nco-movements in reduced-rank matrix autoregressive (RRMAR) models. Unlike\nconventional vector-autoregressive (VAR) models that would discard the matrix\nstructure, our formulation preserves it, enabling a decomposition of\nco-movements into three interpretable components: row-specific,\ncolumn-specific, and joint (row-column) interactions across the matrix-valued\ntime series. Our estimator admits standard asymptotic inference and we propose\na BIC-type criterion for the joint selection of the reduced ranks and the\nautoregressive lag order. We validate the method's finite-sample performance in\nterms of estimation accuracy, coverage and rank selection in simulation\nexperiments, including cases of rank misspecification. We illustrate the\nmethod's practical usefelness in identifying co-movement structures in two\nempirical applications: U.S. state-level coincident and leading indicators, and\ncross-country macroeconomic indicators.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f2a\u7ed3\u6784\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u964d\u79e9\u77e9\u9635\u81ea\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u540c\u671f\u5171\u52a8\u5173\u7cfb\uff0c\u901a\u8fc7\u4fdd\u7559\u77e9\u9635\u7ed3\u6784\u5c06\u5171\u52a8\u5206\u89e3\u4e3a\u4e09\u4e2a\u53ef\u89e3\u91ca\u6210\u5206\u3002", "motivation": "\u4f20\u7edfVAR\u6a21\u578b\u4f1a\u4e22\u5f03\u77e9\u9635\u7ed3\u6784\uff0c\u65e0\u6cd5\u6709\u6548\u5206\u6790\u77e9\u9635\u503c\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u590d\u6742\u5171\u52a8\u5173\u7cfb\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u4fdd\u7559\u77e9\u9635\u7ed3\u6784\u5e76\u5206\u89e3\u5171\u52a8\u6210\u5206\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u964d\u79e9\u77e9\u9635\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5c06\u5171\u52a8\u5206\u89e3\u4e3a\u884c\u7279\u5b9a\u3001\u5217\u7279\u5b9a\u548c\u884c\u5217\u4ea4\u4e92\u4e09\u4e2a\u6210\u5206\uff0c\u63d0\u51faBIC\u7c7b\u51c6\u5219\u8fdb\u884c\u79e9\u548c\u6ede\u540e\u9636\u6570\u7684\u8054\u5408\u9009\u62e9\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728\u4f30\u8ba1\u7cbe\u5ea6\u3001\u8986\u76d6\u7387\u548c\u79e9\u9009\u62e9\u65b9\u9762\u7684\u6709\u9650\u6837\u672c\u6027\u80fd\uff0c\u5e76\u5728\u7f8e\u56fd\u5dde\u7ea7\u6307\u6807\u548c\u8de8\u56fd\u5b8f\u89c2\u7ecf\u6d4e\u6307\u6807\u4e24\u4e2a\u5b9e\u8bc1\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u77e9\u9635\u503c\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5171\u52a8\u7ed3\u6784\uff0c\u4e3a\u7ecf\u6d4e\u6307\u6807\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2509.19472", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19472", "abs": "https://arxiv.org/abs/2509.19472", "authors": ["Brendan Gould", "Akash Harapanahalli", "Samuel Coogan"], "title": "Automatic and Scalable Safety Verification using Interval Reachability with Subspace Sampling", "comment": "6 pages, 3 figures. Updated to correct a small error in the dynamics\n  presented in equation (12)", "summary": "Interval refinement is a technique for reducing the conservatism of\ntraditional interval based reachability methods by lifting the system to a\nhigher dimension using new auxiliary variables and exploiting the introduced\nstructure through a refinement procedure. We present a novel, efficiently\nscaling, automatic refinement strategy based on a subspace sampling argument\nand motivated by reducing the number of interval operations through sparsity.\nUnlike previous methods, we guarantee that refined bounds shrink as additional\nauxiliary variables are added. This additionally encourages automation of the\nlifting phase by allowing larger groups of auxiliary variables to be\nconsidered. We implement our strategy in JAX, a high-performance computational\ntoolkit for Python and demonstrate its efficacy on several examples, including\nregulating a multi-agent platoon to the origin while avoiding an obstacle.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b50\u7a7a\u95f4\u91c7\u6837\u7684\u9ad8\u6548\u81ea\u52a8\u533a\u95f4\u7ec6\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u53d8\u91cf\u548c\u5229\u7528\u7a00\u758f\u6027\u6765\u51cf\u5c11\u533a\u95f4\u8fd0\u7b97\u6b21\u6570\uff0c\u4fdd\u8bc1\u7ec6\u5316\u8fb9\u754c\u968f\u8f85\u52a9\u53d8\u91cf\u589e\u52a0\u800c\u7f29\u5c0f", "motivation": "\u51cf\u5c11\u4f20\u7edf\u533a\u95f4\u53ef\u8fbe\u6027\u65b9\u6cd5\u7684\u4fdd\u5b88\u6027\uff0c\u901a\u8fc7\u63d0\u5347\u7cfb\u7edf\u7ef4\u5ea6\u5e76\u5229\u7528\u5f15\u5165\u7684\u7ed3\u6784\u8fdb\u884c\u7ec6\u5316\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u63d0\u5347\u8fc7\u7a0b", "method": "\u57fa\u4e8e\u5b50\u7a7a\u95f4\u91c7\u6837\u8bba\u8bc1\u7684\u81ea\u52a8\u7ec6\u5316\u7b56\u7565\uff0c\u5728JAX\u4e2d\u5b9e\u73b0\uff0c\u5229\u7528\u7a00\u758f\u6027\u51cf\u5c11\u533a\u95f4\u8fd0\u7b97\uff0c\u4fdd\u8bc1\u7ec6\u5316\u8fb9\u754c\u968f\u8f85\u52a9\u53d8\u91cf\u589e\u52a0\u800c\u6536\u7f29", "result": "\u5728\u591a\u4e2a\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u591a\u667a\u80fd\u4f53\u7f16\u961f\u907f\u969c\u63a7\u5236\u95ee\u9898", "conclusion": "\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u591f\u9ad8\u6548\u6269\u5c55\uff0c\u81ea\u52a8\u5b9e\u73b0\u533a\u95f4\u7ec6\u5316\uff0c\u4e3a\u533a\u95f4\u53ef\u8fbe\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u5de5\u5177"}}
{"id": "2509.19456", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19456", "abs": "https://arxiv.org/abs/2509.19456", "authors": ["Krisztian Balog", "ChengXiang Zhai"], "title": "The Indispensable Role of User Simulation in the Pursuit of AGI", "comment": "Accepted for publication in Communications of the ACM", "summary": "Progress toward Artificial General Intelligence (AGI) faces significant\nbottlenecks, particularly in rigorously evaluating complex interactive systems\nand acquiring the vast interaction data needed for training adaptive agents.\nThis paper posits that user simulation -- creating computational agents that\nmimic human interaction with AI systems -- is not merely a useful tool, but is\na critical catalyst required to overcome these bottlenecks and accelerate AGI\ndevelopment. We argue that realistic simulators provide the necessary\nenvironments for scalable evaluation, data generation for interactive learning,\nand fostering the adaptive capabilities central to AGI. Therefore, research\ninto user simulation technology and intelligent task agents are deeply\nsynergistic and must advance hand-in-hand. This article elaborates on the\ncritical role of user simulation for AGI, explores the interdisciplinary nature\nof building realistic simulators, identifies key challenges including those\nposed by large language models, and proposes a future research agenda.", "AI": {"tldr": "\u7528\u6237\u6a21\u62df\u662f\u514b\u670dAGI\u53d1\u5c55\u74f6\u9888\u7684\u5173\u952e\u50ac\u5316\u5242\uff0c\u4e3a\u53ef\u6269\u5c55\u8bc4\u4f30\u3001\u4ea4\u4e92\u5b66\u4e60\u6570\u636e\u751f\u6210\u548c\u81ea\u9002\u5e94\u80fd\u529b\u57f9\u517b\u63d0\u4f9b\u5fc5\u8981\u73af\u5883", "motivation": "AGI\u53d1\u5c55\u9762\u4e34\u590d\u6742\u4ea4\u4e92\u7cfb\u7edf\u8bc4\u4f30\u548c\u5927\u91cf\u4ea4\u4e92\u6570\u636e\u83b7\u53d6\u7684\u74f6\u9888\uff0c\u9700\u8981\u7528\u6237\u6a21\u62df\u6280\u672f\u6765\u52a0\u901f\u7a81\u7834", "method": "\u901a\u8fc7\u521b\u5efa\u6a21\u62df\u4eba\u7c7b\u4e0eAI\u7cfb\u7edf\u4ea4\u4e92\u7684\u8ba1\u7b97\u4ee3\u7406\uff0c\u6784\u5efa\u73b0\u5b9e\u6a21\u62df\u5668\u6765\u652f\u6301AGI\u5f00\u53d1", "result": "\u7528\u6237\u6a21\u62df\u6280\u672f\u4e0e\u667a\u80fd\u4efb\u52a1\u4ee3\u7406\u5177\u6709\u6df1\u5ea6\u534f\u540c\u6548\u5e94\uff0c\u5fc5\u987b\u540c\u6b65\u63a8\u8fdb", "conclusion": "\u7528\u6237\u6a21\u62df\u5bf9AGI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8de8\u5b66\u79d1\u5408\u4f5c\u89e3\u51b3\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7684\u65b0\u95ee\u9898"}}
{"id": "2509.19630", "categories": ["cs.SI", "05C82, 05C20, 05C22, 68Q25, 93A14", "F.2.2; G.2.2; C.2.4"], "pdf": "https://arxiv.org/pdf/2509.19630", "abs": "https://arxiv.org/abs/2509.19630", "authors": ["Nnamdi Daniel Aghanya"], "title": "Heaven & Hell: One-Step Hub Consensus", "comment": "GUDraBIT Technical Report TR-2025-01. Suggested cross-lists: math.DS,\n  eess.SY, cs.MA", "summary": "Many networked systems require a central authority to enforce a global\nconfiguration against local peer influence. We study influence dynamics on\nfinite weighted directed graphs with a distinguished hub node and binary vertex\nstates ('Glory' or 'Gnash'). We give a sharp, local, and efficiently checkable\ncriterion that guarantees global convergence to Glory in a single synchronous\nupdate from any initial state. At each non-hub vertex, the incoming weight from\nthe hub must at least match the total incoming weight from all other nodes.\nSpecialising in uniform hub broadcasts, the exact threshold equals the maximum\nnon-hub incoming weight over all vertices, and we prove this threshold is\ntight. We extend the result to a tau-biased update rule and to asynchronous\n(Gauss-Seidel) schedules, where a single pass still suffices under the same\ndomination hypothesis. Machine-checked proofs in Coq accompany all theorems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7f51\u7edc\u7cfb\u7edf\u4e2d\u4e2d\u5fc3\u8282\u70b9\u5982\u4f55\u901a\u8fc7\u6743\u91cd\u4f18\u52bf\u786e\u4fdd\u5168\u5c40\u6536\u655b\u5230\u7279\u5b9a\u72b6\u6001\uff08Glory\uff09\uff0c\u7ed9\u51fa\u4e86\u4e00\u4e2a\u53ef\u9ad8\u6548\u68c0\u67e5\u7684\u5c40\u90e8\u51c6\u5219\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u9608\u503c\u662f\u7d27\u7684\u3002", "motivation": "\u8bb8\u591a\u7f51\u7edc\u7cfb\u7edf\u9700\u8981\u4e2d\u592e\u6743\u5a01\u6765\u5bf9\u6297\u5c40\u90e8\u5bf9\u7b49\u5f71\u54cd\u4ee5\u5f3a\u5236\u6267\u884c\u5168\u5c40\u914d\u7f6e\u3002\u672c\u6587\u7814\u7a76\u5728\u5177\u6709\u4e2d\u5fc3\u8282\u70b9\u7684\u6709\u9650\u52a0\u6743\u6709\u5411\u56fe\u4e0a\u7684\u5f71\u54cd\u52a8\u6001\u3002", "method": "\u4f7f\u7528\u5e26\u6709\u4e2d\u5fc3\u8282\u70b9\u7684\u6709\u9650\u52a0\u6743\u6709\u5411\u56fe\u6a21\u578b\uff0c\u9876\u70b9\u72b6\u6001\u4e3a\u4e8c\u5143\uff08Glory\u6216Gnash\uff09\u3002\u63d0\u51fa\u4e00\u4e2a\u5c16\u9510\u3001\u5c40\u90e8\u4e14\u53ef\u9ad8\u6548\u68c0\u67e5\u7684\u51c6\u5219\uff1a\u5728\u6bcf\u4e2a\u975e\u4e2d\u5fc3\u9876\u70b9\u5904\uff0c\u6765\u81ea\u4e2d\u5fc3\u7684\u4f20\u5165\u6743\u91cd\u5fc5\u987b\u81f3\u5c11\u7b49\u4e8e\u6765\u81ea\u6240\u6709\u5176\u4ed6\u8282\u70b9\u7684\u603b\u4f20\u5165\u6743\u91cd\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u5747\u5300\u4e2d\u5fc3\u5e7f\u64ad\u60c5\u51b5\u4e0b\uff0c\u7cbe\u786e\u9608\u503c\u7b49\u4e8e\u6240\u6709\u9876\u70b9\u4e2d\u6700\u5927\u7684\u975e\u4e2d\u5fc3\u4f20\u5165\u6743\u91cd\uff0c\u4e14\u8be5\u9608\u503c\u662f\u7d27\u7684\u3002\u7ed3\u679c\u6269\u5c55\u5230tau\u504f\u7f6e\u66f4\u65b0\u89c4\u5219\u548c\u5f02\u6b65\u8c03\u5ea6\u3002", "conclusion": "\u5728\u4e2d\u5fc3\u652f\u914d\u5047\u8bbe\u4e0b\uff0c\u5355\u6b21\u540c\u6b65\u66f4\u65b0\u5373\u53ef\u4fdd\u8bc1\u4ece\u4efb\u4f55\u521d\u59cb\u72b6\u6001\u5168\u5c40\u6536\u655b\u5230Glory\u72b6\u6001\uff0c\u6240\u6709\u5b9a\u7406\u90fd\u6709Coq\u673a\u5668\u9a8c\u8bc1\u8bc1\u660e\u3002"}}
{"id": "2509.19591", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2509.19591", "abs": "https://arxiv.org/abs/2509.19591", "authors": ["Ricardo Alonzo Fernandez Salguero"], "title": "An Analysis of Monetary Policy Evidence and Theory through Meta-Analyses", "comment": null, "summary": "This paper offers a synthesis of the empirical literature on the effects of\nmonetary policy. Using the findings from an extensive collection of\nmeta-analyses, it evaluates the effectiveness of conventional and\nunconventional monetary policy instruments on key macroeconomic variables such\nas output, inflation, capital flows, and the exchange rate. The aggregated\nevidence reveals a systematic gap between the effects reported in primary\nstudies and the actual magnitude of these effects, once corrected for\npublication bias and methodological heterogeneity. The findings suggest that,\nwhile monetary policy is a relevant tool, its power to modulate the business\ncycle has been consistently overestimated in the literature. Contextual factors\n- such as the degree of financial development, the exchange rate regime,\ncentral bank independence, and crisis conditions - that modulate the\ntransmission of monetary policy are identified. In particular, it is found that\npublication bias systematically favors statistically significant results\nconsistent with predominant theory, which artificially inflates the perception\nof effectiveness. By correcting these distortions, a picture of monetary policy\nemerges with more modest, uncertain effects and considerable lags, which has\nprofound implications for macroeconomic theory and the practice of economic\npolicy.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9\u8d27\u5e01\u653f\u7b56\u5b9e\u8bc1\u6587\u732e\u7684\u5143\u5206\u6790\u53d1\u73b0\uff0c\u8d27\u5e01\u653f\u7b56\u7684\u6548\u679c\u5728\u6587\u732e\u4e2d\u88ab\u7cfb\u7edf\u6027\u9ad8\u4f30\uff0c\u5b9e\u9645\u6548\u679c\u6bd4\u62a5\u9053\u7684\u8981\u66f4\u6e29\u548c\u3001\u4e0d\u786e\u5b9a\u4e14\u5b58\u5728\u6ede\u540e\u6027\u3002", "motivation": "\u8bc4\u4f30\u4f20\u7edf\u548c\u975e\u4f20\u7edf\u8d27\u5e01\u653f\u7b56\u5de5\u5177\u5bf9\u4ea7\u51fa\u3001\u901a\u80c0\u3001\u8d44\u672c\u6d41\u52a8\u548c\u6c47\u7387\u7b49\u5b8f\u89c2\u7ecf\u6d4e\u53d8\u91cf\u7684\u5b9e\u9645\u6709\u6548\u6027\uff0c\u7ea0\u6b63\u6587\u732e\u4e2d\u7684\u53d1\u8868\u504f\u8bef\u548c\u65b9\u6cd5\u5f02\u8d28\u6027\u3002", "method": "\u4f7f\u7528\u5e7f\u6cdb\u7684\u5143\u5206\u6790\u96c6\u5408\uff0c\u5bf9\u8d27\u5e01\u653f\u7b56\u5f71\u54cd\u7684\u5b9e\u8bc1\u6587\u732e\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff0c\u6821\u6b63\u53d1\u8868\u504f\u8bef\u548c\u65b9\u6cd5\u5f02\u8d28\u6027\u3002", "result": "\u53d1\u73b0\u8d27\u5e01\u653f\u7b56\u867d\u7136\u76f8\u5173\uff0c\u4f46\u5176\u8c03\u8282\u7ecf\u6d4e\u5468\u671f\u7684\u80fd\u529b\u88ab\u6587\u732e\u7cfb\u7edf\u6027\u9ad8\u4f30\uff1b\u53d1\u8868\u504f\u8bef\u503e\u5411\u4e8e\u652f\u6301\u4e0e\u4e3b\u6d41\u7406\u8bba\u4e00\u81f4\u7684\u663e\u8457\u7ed3\u679c\uff1b\u91d1\u878d\u53d1\u5c55\u7a0b\u5ea6\u3001\u6c47\u7387\u5236\u5ea6\u3001\u592e\u884c\u72ec\u7acb\u6027\u548c\u5371\u673a\u6761\u4ef6\u7b49\u60c5\u5883\u56e0\u7d20\u4f1a\u8c03\u8282\u8d27\u5e01\u653f\u7b56\u4f20\u5bfc\u3002", "conclusion": "\u901a\u8fc7\u6821\u6b63\u626d\u66f2\u540e\uff0c\u8d27\u5e01\u653f\u7b56\u5448\u73b0\u51fa\u66f4\u6e29\u548c\u3001\u4e0d\u786e\u5b9a\u4e14\u5b58\u5728\u6ede\u540e\u6027\u7684\u6548\u679c\uff0c\u8fd9\u5bf9\u5b8f\u89c2\u7ecf\u6d4e\u7406\u8bba\u548c\u7ecf\u6d4e\u653f\u7b56\u5b9e\u8df5\u5177\u6709\u6df1\u8fdc\u5f71\u54cd\u3002"}}
{"id": "2509.19454", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19454", "abs": "https://arxiv.org/abs/2509.19454", "authors": ["Jason Chen", "I-Chun Arthur Liu", "Gaurav Sukhatme", "Daniel Seita"], "title": "ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation", "comment": null, "summary": "Training robust bimanual manipulation policies via imitation learning\nrequires demonstration data with broad coverage over robot poses, contacts, and\nscene contexts. However, collecting diverse and precise real-world\ndemonstrations is costly and time-consuming, which hinders scalability. Prior\nworks have addressed this with data augmentation, typically for either\neye-in-hand (wrist camera) setups with RGB inputs or for generating novel\nimages without paired actions, leaving augmentation for eye-to-hand\n(third-person) RGB-D training with new action labels less explored. In this\npaper, we propose Synthetic Robot Pose Generation for RGB-D Bimanual Data\nAugmentation (ROPA), an offline imitation learning data augmentation method\nthat fine-tunes Stable Diffusion to synthesize third-person RGB and RGB-D\nobservations of novel robot poses. Our approach simultaneously generates\ncorresponding joint-space action labels while employing constrained\noptimization to enforce physical consistency through appropriate\ngripper-to-object contact constraints in bimanual scenarios. We evaluate our\nmethod on 5 simulated and 3 real-world tasks. Our results across 2625\nsimulation trials and 300 real-world trials demonstrate that ROPA outperforms\nbaselines and ablations, showing its potential for scalable RGB and RGB-D data\naugmentation in eye-to-hand bimanual manipulation. Our project website is\navailable at: https://ropaaug.github.io/.", "AI": {"tldr": "ROPA\u662f\u4e00\u79cd\u7528\u4e8e\u53cc\u624b\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03Stable Diffusion\u6765\u5408\u6210\u7b2c\u4e09\u4eba\u79f0\u89c6\u89d2\u7684RGB\u548cRGB-D\u89c2\u6d4b\u6570\u636e\uff0c\u540c\u65f6\u751f\u6210\u5bf9\u5e94\u7684\u5173\u8282\u7a7a\u95f4\u52a8\u4f5c\u6807\u7b7e\uff0c\u5e76\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u786e\u4fdd\u7269\u7406\u4e00\u81f4\u6027\u3002", "motivation": "\u53cc\u624b\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u6a21\u4eff\u5b66\u4e60\u9700\u8981\u5927\u91cf\u591a\u6837\u5316\u7684\u6f14\u793a\u6570\u636e\uff0c\u4f46\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u4e14\u8017\u65f6\u3002\u73b0\u6709\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u624b\u8155\u6444\u50cf\u5934\u6216\u4ec5\u751f\u6210\u56fe\u50cf\u800c\u4e0d\u5305\u542b\u52a8\u4f5c\u6807\u7b7e\uff0c\u7f3a\u4e4f\u9488\u5bf9\u7b2c\u4e09\u4eba\u79f0RGB-D\u8bad\u7ec3\u6570\u636e\u7684\u6709\u6548\u589e\u5f3a\u65b9\u6cd5\u3002", "method": "\u63d0\u51faROPA\u65b9\u6cd5\uff0c\u79bb\u7ebf\u5fae\u8c03Stable Diffusion\u6765\u5408\u6210\u65b0\u7684\u673a\u5668\u4eba\u59ff\u6001\u7684\u7b2c\u4e09\u4eba\u79f0RGB\u548cRGB-D\u89c2\u6d4b\u6570\u636e\uff0c\u540c\u65f6\u751f\u6210\u5bf9\u5e94\u7684\u52a8\u4f5c\u6807\u7b7e\uff0c\u5e76\u4f7f\u7528\u7ea6\u675f\u4f18\u5316\u6765\u786e\u4fdd\u6293\u53d6\u5668\u4e0e\u7269\u4f53\u63a5\u89e6\u7684\u7269\u7406\u4e00\u81f4\u6027\u3002", "result": "\u57285\u4e2a\u6a21\u62df\u4efb\u52a1\u548c3\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c2625\u6b21\u6a21\u62df\u8bd5\u9a8c\u548c300\u6b21\u771f\u5b9e\u4e16\u754c\u8bd5\u9a8c\u8868\u660e\uff0cROPA\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u548c\u6d88\u878d\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7b2c\u4e09\u4eba\u79f0\u53cc\u624b\u673a\u5668\u4eba\u64cd\u4f5c\u4e2dRGB\u548cRGB-D\u6570\u636e\u589e\u5f3a\u7684\u53ef\u6269\u5c55\u6f5c\u529b\u3002", "conclusion": "ROPA\u65b9\u6cd5\u4e3a\u53cc\u624b\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u6a21\u4eff\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u79bb\u7ebf\u6570\u636e\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6570\u636e\u7684\u591a\u6837\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5177\u6709\u5f88\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.19652", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2509.19652", "abs": "https://arxiv.org/abs/2509.19652", "authors": ["Xiaoyang Song", "Wenbo Sun", "Metin Kayitmazbatir", "Jionghua", "Jin"], "title": "Quality-Ensured In-Situ Process Monitoring with Deep Canonical Correlation Analysis", "comment": null, "summary": "This paper proposes a deep learning-based approach for in-situ process\nmonitoring that captures nonlinear relationships between in-control\nhigh-dimensional process signature signals and offline product quality data.\nSpecifically, we introduce a Deep Canonical Correlation Analysis (DCCA)-based\nframework that enables the joint feature extraction and correlation analysis of\nmulti-modal data sources, such as optical emission spectra and CT scan images,\nwhich are collected in advanced manufacturing processes. This unified framework\nfacilitates online quality monitoring by learning quality-oriented\nrepresentations without requiring labeled defective samples and avoids the\nnon-normality issues that often degrade traditional control chart-based\nmonitoring techniques. We provide theoretical guarantees for the method's\nstability and convergence and validate its effectiveness and practical\napplicability through simulation experiments and a real-world case study on\nDirect Metal Deposition (DMD) additive manufacturing.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5178\u578b\u76f8\u5173\u5206\u6790\uff08DCCA\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5148\u8fdb\u5236\u9020\u8fc7\u7a0b\u4e2d\u7684\u5728\u7ebf\u8d28\u91cf\u76d1\u63a7\uff0c\u80fd\u591f\u8054\u5408\u63d0\u53d6\u591a\u6a21\u6001\u6570\u636e\u7684\u7279\u5f81\u5e76\u5206\u6790\u5176\u76f8\u5173\u6027\uff0c\u65e0\u9700\u7f3a\u9677\u6837\u672c\u6807\u7b7e\u5373\u53ef\u5b66\u4e60\u8d28\u91cf\u5bfc\u5411\u7684\u8868\u5f81\u3002", "motivation": "\u4f20\u7edf\u63a7\u5236\u56fe\u76d1\u63a7\u6280\u672f\u5e38\u56e0\u975e\u6b63\u6001\u6027\u95ee\u9898\u800c\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u9700\u8981\u6807\u8bb0\u7684\u7f3a\u9677\u6837\u672c\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6355\u6349\u9ad8\u7ef4\u8fc7\u7a0b\u7279\u5f81\u4fe1\u53f7\u4e0e\u79bb\u7ebf\u4ea7\u54c1\u8d28\u91cf\u6570\u636e\u4e4b\u95f4\u975e\u7ebf\u6027\u5173\u7cfb\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5178\u578b\u76f8\u5173\u5206\u6790\uff08DCCA\uff09\u6846\u67b6\uff0c\u8054\u5408\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u6e90\uff08\u5982\u5149\u5b66\u53d1\u5c04\u5149\u8c31\u548cCT\u626b\u63cf\u56fe\u50cf\uff09\uff0c\u5b9e\u73b0\u7279\u5f81\u63d0\u53d6\u548c\u76f8\u5173\u6027\u5206\u6790\u7684\u7edf\u4e00\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u548c\u76f4\u63a5\u91d1\u5c5e\u6c89\u79ef\uff08DMD\uff09\u589e\u6750\u5236\u9020\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684DCCA\u6846\u67b6\u4e3a\u5148\u8fdb\u5236\u9020\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5728\u7ebf\u8d28\u91cf\u76d1\u63a7\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u975e\u7ebf\u6027\u5173\u7cfb\u5e76\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.19890", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.19890", "abs": "https://arxiv.org/abs/2509.19890", "authors": ["Natalia Stanusch", "Raziye Buse Cetin", "Salvatore Romano", "Miazia Schueler", "Meret Baumgartner", "Bastian August", "Alexandra Rosca"], "title": "DSA, AIA, and LLMs: Approaches to conceptualizing and auditing moderation in LLM-based chatbots across languages and interfaces in the electoral contexts", "comment": null, "summary": "The integration of Large Language Models (LLMs) into chatbot-like search\nengines poses new challenges for governing, assessing, and scrutinizing the\ncontent output by these online entities, especially in light of the Digital\nService Act (DSA). In what follows, we first survey the regulation landscape in\nwhich we can situate LLM-based chatbots and the notion of moderation. Second,\nwe outline the methodological approaches to our study: a mixed-methods audit\nacross chatbots, languages, and elections. We investigated Copilot, ChatGPT,\nand Gemini across ten languages in the context of the 2024 European\nParliamentary Election and the 2024 US Presidential Election. Despite the\nuncertainty in regulatory frameworks, we propose a set of solutions on how to\nsituate, study, and evaluate chatbot moderation.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u96c6\u6210\u5230\u7c7b\u804a\u5929\u673a\u5668\u4eba\u641c\u7d22\u5f15\u64ce\u4e2d\u5e26\u6765\u7684\u76d1\u7ba1\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u300a\u6570\u5b57\u670d\u52a1\u6cd5\u6848\u300b\uff08DSA\uff09\u80cc\u666f\u4e0b\u3002\u7814\u7a76\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u5ba1\u8ba1\uff0c\u5206\u6790\u4e86Copilot\u3001ChatGPT\u548cGemini\u57282024\u5e74\u6b27\u6d32\u8bae\u4f1a\u9009\u4e3e\u548c\u7f8e\u56fd\u603b\u7edf\u9009\u4e3e\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u76d1\u7ba1\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740LLMs\u5728\u641c\u7d22\u5f15\u64ce\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u4f55\u6709\u6548\u76d1\u7ba1\u3001\u8bc4\u4f30\u548c\u5ba1\u67e5\u8fd9\u4e9b\u5728\u7ebf\u5b9e\u4f53\u8f93\u51fa\u7684\u5185\u5bb9\u6210\u4e3a\u65b0\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728DSA\u6cd5\u89c4\u6846\u67b6\u4e0b\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u5ba1\u8ba1\uff0c\u8de8\u804a\u5929\u673a\u5668\u4eba\u3001\u8bed\u8a00\u548c\u9009\u4e3e\u8fdb\u884c\u591a\u7ef4\u5ea6\u7814\u7a76\u3002\u5177\u4f53\u8c03\u67e5\u4e86Copilot\u3001ChatGPT\u548cGemini\u5728\u5341\u79cd\u8bed\u8a00\u73af\u5883\u4e0b\uff0c\u9488\u5bf92024\u5e74\u6b27\u6d32\u8bae\u4f1a\u9009\u4e3e\u548c2024\u5e74\u7f8e\u56fd\u603b\u7edf\u9009\u4e3e\u7684\u8868\u73b0\u3002", "result": "\u5c3d\u7ba1\u76d1\u7ba1\u6846\u67b6\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u7814\u7a76\u63ed\u793a\u4e86LLM\u804a\u5929\u673a\u5668\u4eba\u5728\u9009\u4e3e\u76f8\u5173\u5185\u5bb9\u5ba1\u6838\u65b9\u9762\u7684\u73b0\u72b6\u548c\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u5957\u5173\u4e8e\u5982\u4f55\u5b9a\u4f4d\u3001\u7814\u7a76\u548c\u8bc4\u4f30\u804a\u5929\u673a\u5668\u4eba\u5185\u5bb9\u5ba1\u6838\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u76d1\u7ba1\u63d0\u4f9b\u4e86\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2509.19945", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2509.19945", "abs": "https://arxiv.org/abs/2509.19945", "authors": ["Nathalie Gimenes", "Tonghui Qi", "Sorawoot Srisuma"], "title": "Identification and Estimation of Seller Risk Aversion in Ascending Auctions", "comment": null, "summary": "How sellers choose reserve prices is central to auction theory, and the\noptimal reserve price depends on the seller's risk attitude. Numerous studies\nhave found that observed reserve prices lie below the optimal level implied by\nrisk-neutral sellers, while the theoretical literature suggests that\nrisk-averse sellers can rationalize these empirical findings. In this paper, we\ndevelop an econometric model of ascending auctions with a risk-averse seller\nunder independent private values. We provide primitive conditions for the\nidentification of the Arrow-Pratt measures of risk aversion and an estimator\nfor these measures that is consistent and converges in distribution to a normal\ndistribution at the parametric rate under standard regularity conditions. A\nMonte Carlo study demonstrates good finite-sample performance of the estimator,\nand we illustrate the approach using data from foreclosure real estate auctions\nin S\\~{a}o Paulo.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u98ce\u9669\u538c\u6076\u5356\u5bb6\u7684\u5347\u5e8f\u62cd\u5356\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u6a21\u578b\uff0c\u8bc6\u522b\u5e76\u4f30\u8ba1\u4e86Arrow-Pratt\u98ce\u9669\u538c\u6076\u5ea6\u91cf\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u4e86\u4f30\u8ba1\u5668\u7684\u826f\u597d\u6027\u80fd\uff0c\u5e76\u5e94\u7528\u4e8e\u5723\u4fdd\u7f57\u6b62\u8d4e\u623f\u5730\u4ea7\u62cd\u5356\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u53d1\u73b0\u89c2\u5bdf\u5230\u7684\u4fdd\u7559\u4ef7\u683c\u4f4e\u4e8e\u98ce\u9669\u4e2d\u6027\u5356\u5bb6\u7406\u8bba\u4e0a\u7684\u6700\u4f18\u6c34\u5e73\uff0c\u800c\u7406\u8bba\u6587\u732e\u8868\u660e\u98ce\u9669\u538c\u6076\u5356\u5bb6\u53ef\u4ee5\u89e3\u91ca\u8fd9\u4e9b\u5b9e\u8bc1\u53d1\u73b0\u3002", "method": "\u5f00\u53d1\u4e86\u72ec\u7acb\u79c1\u4eba\u4ef7\u503c\u4e0b\u98ce\u9669\u538c\u6076\u5356\u5bb6\u7684\u5347\u5e8f\u62cd\u5356\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86Arrow-Pratt\u98ce\u9669\u538c\u6076\u5ea6\u91cf\u7684\u8bc6\u522b\u6761\u4ef6\uff0c\u5e76\u6784\u5efa\u4e86\u5177\u6709\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\u7684\u4f30\u8ba1\u5668\u3002", "result": "\u8499\u7279\u5361\u6d1b\u7814\u7a76\u663e\u793a\u4f30\u8ba1\u5668\u5728\u6709\u9650\u6837\u672c\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u5723\u4fdd\u7f57\u6b62\u8d4e\u623f\u5730\u4ea7\u62cd\u5356\u6570\u636e\u7684\u5e94\u7528\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u8bc1\u7814\u7a76\u98ce\u9669\u538c\u6076\u5356\u5bb6\u5728\u62cd\u5356\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u89e3\u91ca\u89c2\u5bdf\u5230\u7684\u4fdd\u7559\u4ef7\u683c\u4f4e\u4e8e\u7406\u8bba\u6700\u4f18\u6c34\u5e73\u7684\u5b9e\u8bc1\u73b0\u8c61\u3002"}}
{"id": "2509.19477", "categories": ["eess.SY", "cs.RO", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.19477", "abs": "https://arxiv.org/abs/2509.19477", "authors": ["Abhinav Sinha", "Rohit V. Nanavati"], "title": "Robust Near-Optimal Nonlinear Target Enclosing Guidance", "comment": null, "summary": "This paper proposes a nonlinear optimal guidance law that enables a pursuer\nto enclose a target within arbitrary geometric patterns, which extends beyond\nconventional circular encirclement. The design operates using only relative\nstate measurements and formulates a target enclosing guidance law in which the\nvehicle's lateral acceleration serves as the steering control, making it\nwell-suited for aerial vehicles with turning constraints. Our approach\ngeneralizes and extends existing guidance strategies that are limited to target\nencirclement and provides a degree of optimality. At the same time, the exact\ninformation of the target's maneuver is unnecessary during the design. The\nguidance law is developed within the framework of a state-dependent Riccati\nequation (SDRE), thereby providing a systematic way to handle nonlinear\ndynamics through a pseudo-linear representation to design locally optimal\nfeedback guidance commands through state-dependent weighting matrices. While\nSDRE ensures near-optimal performance in the absence of strong disturbances, we\nfurther augment the design to incorporate an integral sliding mode manifold to\ncompensate when disturbances push the system away from the nominal trajectory,\nand demonstrate that the design provides flexibility in the sense that the\n(possibly time-varying) stand-off curvature could also be treated as unknown.\nSimulations demonstrate the efficacy of the proposed approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u7ebf\u6027\u6700\u4f18\u5236\u5bfc\u5f8b\uff0c\u4f7f\u8ffd\u8e2a\u5668\u80fd\u591f\u5728\u4efb\u610f\u51e0\u4f55\u56fe\u6848\u5185\u5305\u56f4\u76ee\u6807\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u5706\u5f62\u5305\u56f4\u3002\u8be5\u65b9\u6cd5\u4ec5\u4f7f\u7528\u76f8\u5bf9\u72b6\u6001\u6d4b\u91cf\uff0c\u901a\u8fc7\u72b6\u6001\u4f9d\u8d56Riccati\u65b9\u7a0b\uff08SDRE\uff09\u6846\u67b6\u8bbe\u8ba1\u5236\u5bfc\u5f8b\uff0c\u5e76\u52a0\u5165\u79ef\u5206\u6ed1\u6a21\u6d41\u5f62\u4ee5\u8865\u507f\u6270\u52a8\u3002", "motivation": "\u6269\u5c55\u73b0\u6709\u4ec5\u9650\u4e8e\u76ee\u6807\u5305\u56f4\u7684\u5236\u5bfc\u7b56\u7565\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u51e0\u4f55\u56fe\u6848\u5305\u56f4\u80fd\u529b\uff0c\u540c\u65f6\u4e0d\u9700\u8981\u76ee\u6807\u7684\u7cbe\u786e\u673a\u52a8\u4fe1\u606f\uff0c\u9002\u7528\u4e8e\u5177\u6709\u8f6c\u5411\u7ea6\u675f\u7684\u98de\u884c\u5668\u3002", "method": "\u57fa\u4e8e\u72b6\u6001\u4f9d\u8d56Riccati\u65b9\u7a0b\uff08SDRE\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u4f2a\u7ebf\u6027\u8868\u793a\u5904\u7406\u975e\u7ebf\u6027\u52a8\u529b\u5b66\uff0c\u8bbe\u8ba1\u5c40\u90e8\u6700\u4f18\u53cd\u9988\u5236\u5bfc\u6307\u4ee4\u3002\u52a0\u5165\u79ef\u5206\u6ed1\u6a21\u6d41\u5f62\u6765\u8865\u507f\u6270\u52a8\u5f71\u54cd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u591f\u5b9e\u73b0\u4efb\u610f\u51e0\u4f55\u56fe\u6848\u7684\u76ee\u6807\u5305\u56f4\uff0c\u5e76\u5728\u5b58\u5728\u6270\u52a8\u65f6\u4fdd\u6301\u9c81\u68d2\u6027\u80fd\u3002", "conclusion": "\u8be5\u5236\u5bfc\u5f8b\u4e3a\u975e\u7ebf\u6027\u76ee\u6807\u5305\u56f4\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u7075\u6d3b\u6027\u3001\u6700\u4f18\u6027\u548c\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u98de\u884c\u5668\u5e94\u7528\u3002"}}
{"id": "2509.19464", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19464", "abs": "https://arxiv.org/abs/2509.19464", "authors": ["Shripad Vilasrao Deshmukh", "Will Schwarzer", "Scott Niekum"], "title": "Evaluation-Aware Reinforcement Learning", "comment": "9 pages, under submission", "summary": "Policy evaluation is often a prerequisite for deploying safety- and\nperformance-critical systems. Existing evaluation approaches frequently suffer\nfrom high variance due to limited data and long-horizon tasks, or high bias due\nto unequal support or inaccurate environmental models. We posit that these\nchallenges arise, in part, from the standard reinforcement learning (RL)\nparadigm of policy learning without explicit consideration of evaluation. As an\nalternative, we propose evaluation-aware reinforcement learning (EvA-RL), in\nwhich a policy is trained to maximize expected return while simultaneously\nminimizing expected evaluation error under a given value prediction scheme --\nin other words, being \"easy\" to evaluate. We formalize a framework for EvA-RL\nand design an instantiation that enables accurate policy evaluation,\nconditioned on a small number of rollouts in an assessment environment that can\nbe different than the deployment environment. However, our theoretical analysis\nand empirical results show that there is often a tradeoff between evaluation\naccuracy and policy performance when using a fixed value-prediction scheme\nwithin EvA-RL. To mitigate this tradeoff, we extend our approach to co-learn an\nassessment-conditioned state-value predictor alongside the policy. Empirical\nresults across diverse discrete and continuous action domains demonstrate that\nEvA-RL can substantially reduce evaluation error while maintaining competitive\nreturns. This work lays the foundation for a broad new class of RL methods that\ntreat reliable evaluation as a first-class principle during training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8bc4\u4f30\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff08EvA-RL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u540c\u65f6\u4f18\u5316\u7b56\u7565\u6027\u80fd\u548c\u8bc4\u4f30\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4f20\u7edfRL\u65b9\u6cd5\u5728\u7b56\u7565\u8bc4\u4f30\u65f6\u9762\u4e34\u7684\u9ad8\u65b9\u5dee\u548c\u9ad8\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u9ad8\u65b9\u5dee\uff08\u6570\u636e\u6709\u9650\u3001\u957f\u65f6\u7a0b\u4efb\u52a1\uff09\u548c\u9ad8\u504f\u5dee\uff08\u652f\u6301\u5ea6\u4e0d\u5747\u3001\u73af\u5883\u6a21\u578b\u4e0d\u51c6\u786e\uff09\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u6e90\u4e8e\u6807\u51c6RL\u8303\u5f0f\u5728\u8bad\u7ec3\u65f6\u672a\u660e\u786e\u8003\u8651\u8bc4\u4f30\u9700\u6c42\u3002", "method": "\u63d0\u51faEvA-RL\u6846\u67b6\uff0c\u8bad\u7ec3\u7b56\u7565\u540c\u65f6\u6700\u5927\u5316\u671f\u671b\u56de\u62a5\u548c\u6700\u5c0f\u5316\u8bc4\u4f30\u8bef\u5dee\uff1b\u8bbe\u8ba1\u4e86\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\uff0c\u652f\u6301\u5728\u8bc4\u4f30\u73af\u5883\uff08\u53ef\u4e0e\u90e8\u7f72\u73af\u5883\u4e0d\u540c\uff09\u4e2d\u4f7f\u7528\u5c11\u91cf\u8f68\u8ff9\u8fdb\u884c\u51c6\u786e\u8bc4\u4f30\uff1b\u8fdb\u4e00\u6b65\u6269\u5c55\u65b9\u6cd5\u5171\u540c\u5b66\u4e60\u8bc4\u4f30\u6761\u4ef6\u72b6\u6001\u503c\u9884\u6d4b\u5668\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cEvA-RL\u80fd\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u56de\u62a5\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8bc4\u4f30\u8bef\u5dee\uff1b\u5728\u79bb\u6563\u548c\u8fde\u7eed\u52a8\u4f5c\u9886\u57df\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "EvA-RL\u4e3aRL\u65b9\u6cd5\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u5c06\u53ef\u9760\u8bc4\u4f30\u4f5c\u4e3a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u9996\u8981\u539f\u5219\uff0c\u4e3a\u5b89\u5168\u6027\u548c\u6027\u80fd\u5173\u952e\u7cfb\u7edf\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u57fa\u7840\u3002"}}
{"id": "2509.19857", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2509.19857", "abs": "https://arxiv.org/abs/2509.19857", "authors": ["Xiaoxiao Liang", "Tianlong Fan", "Linyuan L\u00fc"], "title": "Deterministic Frequency--Domain Inference of Network Topology and Hidden Components via Structure--Behavior Scaling", "comment": "This work has been submitted to the Communications Physics for\n  possible publication", "summary": "Hidden interactions and components in complex systems-ranging from covert\nactors in terrorist networks to unobserved brain regions and molecular\nregulators-often manifest only through indirect behavioral signals. Inferring\nthe underlying network structure from such partial observations remains a\nfundamental challenge, particularly under nonlinear dynamics. We uncover a\nrobust linear relationship between the spectral strength of a node's behavioral\ntime series under evolutionary game dynamics and its structural degree, $S\n\\propto k$, a structural-behavioral scaling that holds across network types and\nscales, revealing a universal correspondence between local connectivity and\ndynamic energy. Leveraging this insight, we develop a deterministic,\nfrequency-domain inference framework based on the discrete Fourier transform\n(DFT) that reconstructs network topology directly from payoff sequences-without\nprior knowledge of the network or internal node strategies-by selectively\nperturbing node dynamics. The framework simultaneously localizes individual\nhidden nodes or identifies all edges connected to multiple hidden nodes, and\nestimates tight bounds on the number of hidden nodes. Extensive experiments on\nsynthetic and real-world networks demonstrate that our method consistently\noutperforms state-of-the-art baselines in both topology reconstruction and\nhidden component detection. Moreover, it scales efficiently to large networks,\noffering robustness to stochastic fluctuations and overcoming the size\nlimitations of existing techniques. Our work establishes a principled\nconnection between local dynamic observables and global structural inference,\nenabling accurate topology recovery in complex systems with hidden elements.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u4e86\u4e00\u4e2a\u7ed3\u6784-\u884c\u4e3a\u6807\u5ea6\u5173\u7cfb\uff1a\u8282\u70b9\u5728\u6f14\u5316\u535a\u5f08\u52a8\u529b\u5b66\u4e0b\u7684\u884c\u4e3a\u65f6\u95f4\u5e8f\u5217\u8c31\u5f3a\u5ea6\u4e0e\u5176\u7ed3\u6784\u5ea6\u6210\u6b63\u6bd4\uff08S \u221d k\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u7684\u786e\u5b9a\u6027\u9891\u7387\u57df\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u4e2d\u91cd\u5efa\u7f51\u7edc\u62d3\u6251\u548c\u68c0\u6d4b\u9690\u85cf\u8282\u70b9\u3002", "motivation": "\u590d\u6742\u7cfb\u7edf\u4e2d\u9690\u85cf\u7684\u76f8\u4e92\u4f5c\u7528\u548c\u7ec4\u4ef6\uff08\u5982\u6050\u6016\u7f51\u7edc\u4e2d\u7684\u9690\u853d\u53c2\u4e0e\u8005\u3001\u672a\u89c2\u6d4b\u7684\u8111\u533a\u57df\u548c\u5206\u5b50\u8c03\u8282\u5668\uff09\u901a\u5e38\u53ea\u80fd\u901a\u8fc7\u95f4\u63a5\u884c\u4e3a\u4fe1\u53f7\u663e\u73b0\u3002\u4ece\u8fd9\u79cd\u90e8\u5206\u89c2\u6d4b\u4e2d\u63a8\u65ad\u5e95\u5c42\u7f51\u7edc\u7ed3\u6784\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4e0b\u3002", "method": "\u5229\u7528\u53d1\u73b0\u7684\u7ed3\u6784-\u884c\u4e3a\u6807\u5ea6\u5173\u7cfb\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u7684\u786e\u5b9a\u6027\u9891\u7387\u57df\u63a8\u7406\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u6270\u52a8\u8282\u70b9\u52a8\u529b\u5b66\uff0c\u76f4\u63a5\u4ece\u6536\u76ca\u5e8f\u5217\u91cd\u5efa\u7f51\u7edc\u62d3\u6251\uff0c\u65e0\u9700\u5148\u9a8c\u7f51\u7edc\u77e5\u8bc6\u6216\u5185\u90e8\u8282\u70b9\u7b56\u7565\u4fe1\u606f\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u7f51\u7edc\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u62d3\u6251\u91cd\u5efa\u548c\u9690\u85cf\u7ec4\u4ef6\u68c0\u6d4b\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u6269\u5c55\u5230\u5927\u578b\u7f51\u7edc\uff0c\u5bf9\u968f\u673a\u6ce2\u52a8\u5177\u6709\u9c81\u68d2\u6027\uff0c\u514b\u670d\u4e86\u73b0\u6709\u6280\u672f\u7684\u89c4\u6a21\u9650\u5236\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u5c40\u90e8\u52a8\u6001\u53ef\u89c2\u6d4b\u91cf\u4e0e\u5168\u5c40\u7ed3\u6784\u63a8\u65ad\u4e4b\u95f4\u7684\u539f\u5219\u6027\u8054\u7cfb\uff0c\u4f7f\u5f97\u5728\u5177\u6709\u9690\u85cf\u5143\u7d20\u7684\u590d\u6742\u7cfb\u7edf\u4e2d\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u7684\u62d3\u6251\u6062\u590d\u3002"}}
{"id": "2509.19823", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2509.19823", "abs": "https://arxiv.org/abs/2509.19823", "authors": ["H\u00e9ctor Hermida-Rivera"], "title": "A Simple Characterization of Qualified Majority Voting Rules", "comment": null, "summary": "This note characterizes every qualified majority voting rule with a quota $q$\nstrictly greater than half of the voter set in environments with just two\nalternatives through anonymity, responsiveness, and $q$-neutrality. Crucially,\nthe latter imposes independence of the labels of the alternatives only for all\npreference profiles in which some alternative is strictly top-ranked by at\nleast $q$ voters. Thus, this note generalizes May's (1952, Theorem, p.~682)\nwell-known axiomatic characterization of the simple majority voting rule to\nqualified majority voting rules with a quota $q$ strictly greater than half of\nthe voter set. In doing so, it shows that these qualified majority voting rules\nare precisely distinguished by their \"degree\" of neutrality.", "AI": {"tldr": "\u672c\u6587\u5bf9\u914d\u989d\u4e25\u683c\u5927\u4e8e\u9009\u6c11\u6570\u4e00\u534a\u7684\u5408\u683c\u591a\u6570\u6295\u7968\u89c4\u5219\u8fdb\u884c\u4e86\u516c\u7406\u5316\u523b\u753b\uff0c\u901a\u8fc7\u533f\u540d\u6027\u3001\u54cd\u5e94\u6027\u548cq-\u4e2d\u7acb\u6027\u4e09\u4e2a\u516c\u7406\uff0c\u5c06May(1952)\u5bf9\u7b80\u5355\u591a\u6570\u89c4\u5219\u7684\u7ecf\u5178\u523b\u753b\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684\u5408\u683c\u591a\u6570\u89c4\u5219\u3002", "motivation": "May(1952)\u7684\u7ecf\u5178\u5b9a\u7406\u53ea\u523b\u753b\u4e86\u7b80\u5355\u591a\u6570\u89c4\u5219\uff0c\u672c\u6587\u65e8\u5728\u5c06\u8fd9\u4e00\u7ed3\u679c\u63a8\u5e7f\u5230\u914d\u989d\u4e25\u683c\u5927\u4e8e\u9009\u6c11\u6570\u4e00\u534a\u7684\u5408\u683c\u591a\u6570\u6295\u7968\u89c4\u5219\uff0c\u63ed\u793a\u8fd9\u4e9b\u89c4\u5219\u53ef\u4ee5\u901a\u8fc7\u5176\"\u4e2d\u7acb\u6027\u7a0b\u5ea6\"\u6765\u7cbe\u786e\u533a\u5206\u3002", "method": "\u4f7f\u7528\u516c\u7406\u5316\u65b9\u6cd5\uff0c\u5728\u53ea\u6709\u4e24\u4e2a\u5907\u9009\u65b9\u6848\u7684\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u516c\u7406\u6765\u523b\u753b\u5408\u683c\u591a\u6570\u6295\u7968\u89c4\u5219\uff1a\u533f\u540d\u6027\uff08\u6240\u6709\u9009\u6c11\u5e73\u7b49\uff09\u3001\u54cd\u5e94\u6027\uff08\u89c4\u5219\u5bf9\u504f\u597d\u53d8\u5316\u654f\u611f\uff09\u548cq-\u4e2d\u7acb\u6027\uff08\u5728\u81f3\u5c11\u6709q\u4e2a\u9009\u6c11\u4e25\u683c\u504f\u597d\u67d0\u4e2a\u65b9\u6848\u65f6\u4fdd\u6301\u65b9\u6848\u6807\u7b7e\u72ec\u7acb\u6027\uff09\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u6bcf\u4e2a\u914d\u989dq\u4e25\u683c\u5927\u4e8e\u9009\u6c11\u6570\u4e00\u534a\u7684\u5408\u683c\u591a\u6570\u6295\u7968\u89c4\u5219\u90fd\u53ef\u4ee5\u901a\u8fc7\u533f\u540d\u6027\u3001\u54cd\u5e94\u6027\u548cq-\u4e2d\u7acb\u6027\u8fd9\u4e09\u4e2a\u516c\u7406\u6765\u552f\u4e00\u523b\u753b\u3002", "conclusion": "\u672c\u6587\u7684\u5de5\u4f5c\u5c06May\u7684\u7ecf\u5178\u5b9a\u7406\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684\u6295\u7968\u89c4\u5219\u7c7b\u522b\uff0c\u8868\u660e\u5408\u683c\u591a\u6570\u89c4\u5219\u53ef\u4ee5\u901a\u8fc7\u5176\u4e2d\u7acb\u6027\u7684\"\u7a0b\u5ea6\"\u6765\u7cbe\u786e\u533a\u5206\uff0c\u8fd9\u4e3a\u7406\u89e3\u4e0d\u540c\u591a\u6570\u89c4\u5219\u7684\u6027\u8d28\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u3002"}}
{"id": "2509.19460", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19460", "abs": "https://arxiv.org/abs/2509.19460", "authors": ["Yifan Ye", "Jun Cen", "Jing Chen", "Zhihe Lu"], "title": "Self-evolved Imitation Learning in Simulated World", "comment": null, "summary": "Imitation learning has been a trend recently, yet training a generalist agent\nacross multiple tasks still requires large-scale expert demonstrations, which\nare costly and labor-intensive to collect. To address the challenge of limited\nsupervision, we propose Self-Evolved Imitation Learning (SEIL), a framework\nthat progressively improves a few-shot model through simulator interactions.\nThe model first attempts tasksin the simulator, from which successful\ntrajectories are collected as new demonstrations for iterative refinement. To\nenhance the diversity of these demonstrations, SEIL employs dual-level\naugmentation: (i) Model-level, using an Exponential Moving Average (EMA) model\nto collaborate with the primary model, and (ii) Environment-level, introducing\nslight variations in initial object positions. We further introduce a\nlightweight selector that filters complementary and informative trajectories\nfrom the generated pool to ensure demonstration quality. These curated samples\nenable the model to achieve competitive performance with far fewer training\nexamples. Extensive experiments on the LIBERO benchmark show that SEIL achieves\na new state-of-the-art performance in few-shot imitation learning scenarios.\nCode is available at https://github.com/Jasper-aaa/SEIL.git.", "AI": {"tldr": "SEIL\u662f\u4e00\u79cd\u81ea\u6f14\u5316\u7684\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u5668\u4ea4\u4e92\u9010\u6b65\u6539\u8fdb\u5c11\u6837\u672c\u6a21\u578b\uff0c\u4f7f\u7528\u53cc\u7ea7\u589e\u5f3a\u548c\u8f7b\u91cf\u7ea7\u9009\u62e9\u5668\u6765\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u4e13\u5bb6\u6f14\u793a\u7684\u4f9d\u8d56\u3002", "motivation": "\u89e3\u51b3\u6a21\u4eff\u5b66\u4e60\u4e2d\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u6f14\u793a\u7684\u9ad8\u6210\u672c\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u591a\u4efb\u52a1\u901a\u7528\u667a\u80fd\u4f53\u8bad\u7ec3\u4e2d\uff0c\u4e13\u5bb6\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u6602\u4e14\u52b3\u52a8\u5bc6\u96c6\u3002", "method": "\u63d0\u51faSEIL\u6846\u67b6\uff1a1\uff09\u6a21\u578b\u5728\u6a21\u62df\u5668\u4e2d\u5c1d\u8bd5\u4efb\u52a1\uff0c\u6536\u96c6\u6210\u529f\u8f68\u8ff9\u4f5c\u4e3a\u65b0\u6f14\u793a\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff1b2\uff09\u91c7\u7528\u53cc\u7ea7\u589e\u5f3a\u7b56\u7565\uff08\u6a21\u578b\u7ea7EMA\u534f\u4f5c\u548c\u73af\u5883\u7ea7\u521d\u59cb\u4f4d\u7f6e\u53d8\u5316\uff09\uff1b3\uff09\u4f7f\u7528\u8f7b\u91cf\u7ea7\u9009\u62e9\u5668\u7b5b\u9009\u4e92\u8865\u4fe1\u606f\u8f68\u8ff9\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSEIL\u5728\u5c11\u6837\u672c\u6a21\u4eff\u5b66\u4e60\u573a\u666f\u4e0b\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7528\u66f4\u5c11\u7684\u8bad\u7ec3\u6837\u672c\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u8868\u73b0\u3002", "conclusion": "SEIL\u6846\u67b6\u6709\u6548\u51cf\u5c11\u4e86\u6a21\u4eff\u5b66\u4e60\u5bf9\u5927\u89c4\u6a21\u4e13\u5bb6\u6f14\u793a\u7684\u4f9d\u8d56\uff0c\u901a\u8fc7\u81ea\u6f14\u5316\u548c\u667a\u80fd\u8f68\u8ff9\u9009\u62e9\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5c11\u6837\u672c\u5b66\u4e60\u3002"}}
{"id": "2509.20083", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2509.20083", "abs": "https://arxiv.org/abs/2509.20083", "authors": ["Robert Bajons", "Lucas Kook"], "title": "Rethinking player evaluation in sports: Goals above expectation and beyond", "comment": null, "summary": "A popular quantitative approach to evaluating player performance in sports\ninvolves comparing an observed outcome to the expected outcome ignoring player\ninvolvement, which is estimated using statistical or machine learning methods.\nIn soccer, for instance, goals above expectation (GAX) of a player measure how\noften shots of this player led to a goal compared to the model-derived expected\noutcome of the shots. Typically, sports data analysts rely on flexible machine\nlearning models, which are capable of handling complex nonlinear effects and\nfeature interactions, but fail to provide valid statistical inference due to\nfinite-sample bias and slow convergence rates. In this paper, we close this gap\nby presenting a framework for player evaluation with metrics derived from\ndifferences in actual and expected outcomes using flexible machine learning\nalgorithms, which nonetheless allows for valid frequentist inference. We first\nshow that the commonly used metrics are directly related to Rao's score test in\nparametric regression models for the expected outcome. Motivated by this\nfinding and recent developments in double machine learning, we then propose the\nuse of residualized versions of the original metrics. For GAX, the\nresidualization step corresponds to an additional regression predicting whether\na given player would take the shot under the circumstances described by the\nfeatures. We further relate metrics in the proposed framework to\nplayer-specific effect estimates in interpretable semiparametric regression\nmodels, allowing us to infer directional effects, e.g., to determine players\nthat have a positive impact on the outcome. Our primary use case are GAX in\nsoccer. We further apply our framework to evaluate goal-stopping ability of\ngoalkeepers, shooting skill in basketball, quarterback passing skill in\nAmerican football, and injury-proneness of soccer players.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u673a\u5668\u5b66\u4e60\u7684\u7403\u5458\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6b8b\u5dee\u5316\u5904\u7406\u539f\u59cb\u6307\u6807\uff0c\u5728\u4fdd\u6301\u7075\u6d3b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f18\u52bf\u7684\u540c\u65f6\u5b9e\u73b0\u6709\u6548\u7684\u7edf\u8ba1\u63a8\u65ad\u3002", "motivation": "\u73b0\u6709\u4f53\u80b2\u6570\u636e\u5206\u6790\u4e2d\u4f7f\u7528\u7684\u7075\u6d3b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u867d\u7136\u80fd\u5904\u7406\u590d\u6742\u975e\u7ebf\u6027\u6548\u5e94\uff0c\u4f46\u65e0\u6cd5\u63d0\u4f9b\u6709\u6548\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u5b58\u5728\u6709\u9650\u6837\u672c\u504f\u5dee\u548c\u6536\u655b\u901f\u5ea6\u6162\u7684\u95ee\u9898\u3002", "method": "\u5c06\u5e38\u7528\u6307\u6807\u4e0eRao\u5f97\u5206\u68c0\u9a8c\u5173\u8054\uff0c\u57fa\u4e8e\u53cc\u673a\u5668\u5b66\u4e60\u63d0\u51fa\u6b8b\u5dee\u5316\u7248\u672c\u6307\u6807\uff0c\u5c06\u6307\u6807\u4e0e\u53ef\u89e3\u91ca\u534a\u53c2\u6570\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u7403\u5458\u7279\u5b9a\u6548\u5e94\u4f30\u8ba1\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u6846\u67b6\u6210\u529f\u5e94\u7528\u4e8e\u8db3\u7403\u7684GAX\u6307\u6807\u3001\u5b88\u95e8\u5458\u6251\u6551\u80fd\u529b\u3001\u7bee\u7403\u6295\u7bee\u6280\u80fd\u3001\u7f8e\u5f0f\u8db3\u7403\u56db\u5206\u536b\u4f20\u7403\u6280\u80fd\u548c\u8db3\u7403\u8fd0\u52a8\u5458\u4f24\u75c5\u503e\u5411\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7075\u6d3b\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u4e3a\u7403\u5458\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.19996", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19996", "abs": "https://arxiv.org/abs/2509.19996", "authors": ["Emilio Cruciani", "Roberto Verdecchia"], "title": "Choosing to Be Green: Advancing Green AI via Dynamic Model Selection", "comment": "2nd Workshop on Green-Aware Artificial Intelligence (Green-Aware\n  2025). 9 pages, 1 figure", "summary": "Artificial Intelligence is increasingly pervasive across domains, with ever\nmore complex models delivering impressive predictive performance. This fast\ntechnological advancement however comes at a concerning environmental cost,\nwith state-of-the-art models - particularly deep neural networks and large\nlanguage models - requiring substantial computational resources and energy. In\nthis work, we present the intuition of Green AI dynamic model selection, an\napproach based on dynamic model selection that aims at reducing the\nenvironmental footprint of AI by selecting the most sustainable model while\nminimizing potential accuracy loss. Specifically, our approach takes into\naccount the inference task, the environmental sustainability of available\nmodels, and accuracy requirements to dynamically choose the most suitable\nmodel. Our approach presents two different methods, namely Green AI dynamic\nmodel cascading and Green AI dynamic model routing. We demonstrate the\neffectiveness of our approach via a proof of concept empirical example based on\na real-world dataset. Our results show that Green AI dynamic model selection\ncan achieve substantial energy savings (up to ~25%) while substantially\nretaining the accuracy of the most energy greedy solution (up to ~95%). As\nconclusion, our preliminary findings highlight the potential that hybrid,\nadaptive model selection strategies withhold to mitigate the energy demands of\nmodern AI systems without significantly compromising accuracy requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u6a21\u578b\u9009\u62e9\u7684Green AI\u65b9\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u9009\u62e9\u6700\u53ef\u6301\u7eed\u7684\u6a21\u578b\u6765\u51cf\u5c11AI\u7684\u73af\u5883\u8db3\u8ff9\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u51c6\u786e\u7387\u635f\u5931\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u5feb\u901f\u53d1\u5c55\uff0c\u7279\u522b\u662f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u548c\u80fd\u6e90\uff0c\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u73af\u5883\u6210\u672c\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Green AI\u52a8\u6001\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\uff0c\u5305\u62ec\u52a8\u6001\u6a21\u578b\u7ea7\u8054\u548c\u52a8\u6001\u6a21\u578b\u8def\u7531\u4e24\u79cd\u5177\u4f53\u65b9\u6cd5\uff0c\u7efc\u5408\u8003\u8651\u63a8\u7406\u4efb\u52a1\u3001\u6a21\u578b\u73af\u5883\u53ef\u6301\u7eed\u6027\u548c\u51c6\u786e\u7387\u8981\u6c42\u6765\u52a8\u6001\u9009\u62e9\u6700\u5408\u9002\u7684\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u96c6\u7684\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u53ef\u5b9e\u73b0\u9ad8\u8fbe\u7ea625%\u7684\u80fd\u6e90\u8282\u7ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u8017\u80fd\u89e3\u51b3\u65b9\u6848\u7ea695%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u521d\u6b65\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6df7\u5408\u81ea\u9002\u5e94\u6a21\u578b\u9009\u62e9\u7b56\u7565\u5177\u6709\u5728\u4e0d\u663e\u8457\u5f71\u54cd\u51c6\u786e\u7387\u8981\u6c42\u7684\u524d\u63d0\u4e0b\u7f13\u89e3\u73b0\u4ee3AI\u7cfb\u7edf\u80fd\u6e90\u9700\u6c42\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.19484", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19484", "abs": "https://arxiv.org/abs/2509.19484", "authors": ["Brendan Gould", "Akash Harapanahalli", "Samuel Coogan"], "title": "linrax: A JAX Compatible, Simplex Method Linear Program Solver", "comment": "8 pages, 3 figures", "summary": "We present linrax, the first simplex based linear program (LP) solver\ncompatible with the JAX ecosystem. In many control algorithms, LPs are often\nautomatically generated and frequently solved either offline or online in the\ncontrol loop. This motivates the design of linrax, which is especially suited\nfor compilation into a complex JAX-based pipeline as a subroutine. We discuss\nthe challenges associated with implementing a general purpose LP solver under\nstrict design requirements from JAX. Notably, we can solve general problems\nwhich may include dependent constraints-something not possible with existing\nJAX-compatible LP solvers that use first-order techniques and may fail to\nconverge. We demonstrate the utility of linrax through several examples,\nincluding a robust control synthesis pipeline for a nonlinear vehicle model\nusing automatic differentiation through a LP-based reachable set framework.", "AI": {"tldr": "linrax\u662f\u9996\u4e2a\u57fa\u4e8e\u5355\u7eaf\u5f62\u6cd5\u7684\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u5668\uff0c\u517c\u5bb9JAX\u751f\u6001\u7cfb\u7edf\uff0c\u7279\u522b\u9002\u5408\u4f5c\u4e3a\u5b50\u7a0b\u5e8f\u7f16\u8bd1\u5230\u590d\u6742\u7684JAX\u7ba1\u9053\u4e2d\u3002", "motivation": "\u5728\u63a7\u5236\u7b97\u6cd5\u4e2d\uff0c\u7ebf\u6027\u89c4\u5212\u7ecf\u5e38\u88ab\u81ea\u52a8\u751f\u6210\u5e76\u5728\u63a7\u5236\u5faa\u73af\u4e2d\u9891\u7e41\u6c42\u89e3\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u591f\u96c6\u6210\u5230JAX\u751f\u6001\u7cfb\u7edf\u7684LP\u6c42\u89e3\u5668\u3002", "method": "\u4f7f\u7528\u5355\u7eaf\u5f62\u6cd5\u5b9e\u73b0\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u5668\uff0c\u80fd\u591f\u5904\u7406\u5305\u542b\u4f9d\u8d56\u7ea6\u675f\u7684\u4e00\u822c\u95ee\u9898\uff0c\u514b\u670d\u73b0\u6709JAX\u517c\u5bb9\u6c42\u89e3\u5668\u4f7f\u7528\u4e00\u9636\u6280\u672f\u53ef\u80fd\u4e0d\u6536\u655b\u7684\u5c40\u9650\u6027\u3002", "result": "linrax\u80fd\u591f\u6210\u529f\u89e3\u51b3\u4e00\u822c\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u5305\u62ec\u4f9d\u8d56\u7ea6\u675f\u7684\u60c5\u51b5\uff0c\u5e76\u901a\u8fc7\u975e\u7ebf\u6027\u8f66\u8f86\u6a21\u578b\u7684\u9c81\u68d2\u63a7\u5236\u5408\u6210\u7ba1\u9053\u7b49\u793a\u4f8b\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "linrax\u586b\u8865\u4e86JAX\u751f\u6001\u7cfb\u7edf\u4e2d\u901a\u7528\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u5668\u7684\u7a7a\u767d\uff0c\u4e3a\u63a7\u5236\u7b97\u6cd5\u548c\u5176\u4ed6\u9700\u8981LP\u6c42\u89e3\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19489", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19489", "abs": "https://arxiv.org/abs/2509.19489", "authors": ["Robert Nowak"], "title": "Estimating the Self-Consistency of LLMs", "comment": "5 pages", "summary": "Systems often repeat the same prompt to large language models (LLMs) and\naggregate responses to improve reliability. This short note analyzes an\nestimator of the self-consistency of LLMs and the tradeoffs it induces under a\nfixed compute budget $B=mn$, where $m$ is the number of prompts sampled from\nthe task distribution and $n$ is the number of repeated LLM calls per prompt;\nthe resulting analysis favors a rough split $m,n\\propto\\sqrt{B}$.", "AI": {"tldr": "\u5206\u6790LLM\u81ea\u4e00\u81f4\u6027\u4f30\u8ba1\u5668\u53ca\u5176\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u6743\u8861\uff0c\u5efa\u8baem\u548cn\u4e0eB\u7684\u5e73\u65b9\u6839\u6210\u6bd4\u4f8b\u5206\u914d", "motivation": "\u7cfb\u7edf\u901a\u5e38\u91cd\u590d\u76f8\u540c\u63d0\u793a\u7ed9LLM\u5e76\u805a\u5408\u54cd\u5e94\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u9700\u8981\u5206\u6790\u81ea\u4e00\u81f4\u6027\u4f30\u8ba1\u5668\u53ca\u5176\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u6700\u4f18\u5206\u914d", "method": "\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97B=mn\u4e0b\u5206\u6790\u81ea\u4e00\u81f4\u6027\u4f30\u8ba1\u5668\uff0c\u5176\u4e2dm\u662f\u4efb\u52a1\u5206\u5e03\u4e2d\u91c7\u6837\u7684\u63d0\u793a\u6570\uff0cn\u662f\u6bcf\u4e2a\u63d0\u793a\u7684\u91cd\u590dLLM\u8c03\u7528\u6b21\u6570", "result": "\u5206\u6790\u8868\u660e\u6700\u4f18\u5206\u914d\u662fm\u548cn\u4e0eB\u7684\u5e73\u65b9\u6839\u6210\u6bd4\u4f8b\uff0c\u5373m,n\u221d\u221aB", "conclusion": "\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0c\u4e3a\u4e86\u6700\u5927\u5316LLM\u54cd\u5e94\u7684\u53ef\u9760\u6027\uff0c\u5e94\u8be5\u5c06\u63d0\u793a\u91c7\u6837\u6570\u548c\u91cd\u590d\u8c03\u7528\u6b21\u6570\u5927\u81f4\u6309\u8ba1\u7b97\u9884\u7b97\u7684\u5e73\u65b9\u6839\u8fdb\u884c\u5206\u914d"}}
{"id": "2509.20000", "categories": ["econ.TH", "econ.EM"], "pdf": "https://arxiv.org/pdf/2509.20000", "abs": "https://arxiv.org/abs/2509.20000", "authors": ["Galiya Klinkova", "Michael Grabinski"], "title": "Business Cycles explained by Instability", "comment": null, "summary": "Business cycles (a periodic change of e.g. GDP over five to ten years) exist,\nbut a proper explanation for it is still lacking. Here we extend the well-known\nNAIRU (non-accelerating inflation rate of unemployment) model, resulting in a\nset of differ-ential equations. However, the solution is marginal stable.\nTherefore we find a nat-ural sinusoidal oscillation of inflation and\nunemployment just as observed in busi-ness cycles. When speculation is present,\nthe instability becomes more severe. So we present for the first time a\nmathematical explanation for business cycles. The steering of central banks by\nsetting interest rates to keep inflation stable and low needs an overhaul. One\nhas to distinguish between real monetary instability and the one caused\nnaturally by business cycles.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6269\u5c55NAIRU\u6a21\u578b\uff0c\u7528\u5fae\u5206\u65b9\u7a0b\u7ec4\u89e3\u91ca\u4e86\u7ecf\u6d4e\u5468\u671f\u7684\u81ea\u7136\u6b63\u5f26\u632f\u8361\u73b0\u8c61\uff0c\u5e76\u6307\u51fa\u6295\u673a\u884c\u4e3a\u4f1a\u52a0\u5267\u4e0d\u7a33\u5b9a\u6027\uff0c\u4e3a\u7ecf\u6d4e\u5468\u671f\u63d0\u4f9b\u4e86\u6570\u5b66\u89e3\u91ca\u3002", "motivation": "\u7ecf\u6d4e\u5468\u671f\uff08\u5982GDP\u76845-10\u5e74\u5468\u671f\u6027\u53d8\u5316\uff09\u5b58\u5728\u4f46\u7f3a\u4e4f\u5408\u7406\u89e3\u91ca\uff0c\u9700\u8981\u5efa\u7acb\u6570\u5b66\u6a21\u578b\u6765\u89e3\u91ca\u8fd9\u4e00\u73b0\u8c61\u3002", "method": "\u6269\u5c55\u8457\u540d\u7684NAIRU\uff08\u975e\u52a0\u901f\u901a\u8d27\u81a8\u80c0\u5931\u4e1a\u7387\uff09\u6a21\u578b\uff0c\u6784\u5efa\u4e00\u7ec4\u5fae\u5206\u65b9\u7a0b\u6765\u5206\u6790\u7ecf\u6d4e\u5468\u671f\u3002", "result": "\u6a21\u578b\u89e3\u5448\u73b0\u8fb9\u9645\u7a33\u5b9a\u6027\uff0c\u81ea\u7136\u4ea7\u751f\u901a\u8d27\u81a8\u80c0\u548c\u5931\u4e1a\u7387\u7684\u6b63\u5f26\u632f\u8361\uff0c\u4e0e\u5b9e\u9645\u89c2\u5bdf\u5230\u7684\u7ecf\u6d4e\u5468\u671f\u4e00\u81f4\uff1b\u6295\u673a\u884c\u4e3a\u4f1a\u52a0\u5267\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u9996\u6b21\u4e3a\u7ecf\u6d4e\u5468\u671f\u63d0\u4f9b\u6570\u5b66\u89e3\u91ca\uff0c\u6307\u51fa\u592e\u884c\u901a\u8fc7\u5229\u7387\u8c03\u63a7\u901a\u80c0\u7684\u653f\u7b56\u9700\u8981\u6539\u9769\uff0c\u9700\u533a\u5206\u771f\u5b9e\u8d27\u5e01\u4e0d\u7a33\u5b9a\u6027\u548c\u7ecf\u6d4e\u5468\u671f\u81ea\u7136\u5f15\u8d77\u7684\u4e0d\u7a33\u5b9a\u6027\u3002"}}
{"id": "2509.19463", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19463", "abs": "https://arxiv.org/abs/2509.19463", "authors": ["Doncey Albin", "Daniel McGann", "Miles Mena", "Annika Thomas", "Harel Biggie", "Xuefei Sun", "Steve McGuire", "Jonathan P. How", "Christoffer Heckman"], "title": "CU-Multi: A Dataset for Multi-Robot Collaborative Perception", "comment": "8 pages, 11 figures", "summary": "A central challenge for multi-robot systems is fusing independently gathered\nperception data into a unified representation. Despite progress in\nCollaborative SLAM (C-SLAM), benchmarking remains hindered by the scarcity of\ndedicated multi-robot datasets. Many evaluations instead partition single-robot\ntrajectories, a practice that may only partially reflect true multi-robot\noperations and, more critically, lacks standardization, leading to results that\nare difficult to interpret or compare across studies. While several multi-robot\ndatasets have recently been introduced, they mostly contain short trajectories\nwith limited inter-robot overlap and sparse intra-robot loop closures. To\novercome these limitations, we introduce CU-Multi, a dataset collected over\nmultiple days at two large outdoor sites on the University of Colorado Boulder\ncampus. CU-Multi comprises four synchronized runs with aligned start times and\ncontrolled trajectory overlap, replicating the distinct perspectives of a robot\nteam. It includes RGB-D sensing, RTK GPS, semantic LiDAR, and refined\nground-truth odometry. By combining overlap variation with dense semantic\nannotations, CU-Multi provides a strong foundation for reproducible evaluation\nin multi-robot collaborative perception tasks.", "AI": {"tldr": "CU-Multi\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u673a\u5668\u4eba\u6570\u636e\u96c6\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u540c\u6b65\u8fd0\u884c\u3001\u8f68\u8ff9\u91cd\u53e0\u63a7\u5236\u548c\u4e30\u5bcc\u4f20\u611f\u5668\u6570\u636e\u3002", "motivation": "\u5f53\u524d\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u611f\u77e5\u6570\u636e\u878d\u5408\u9762\u4e34\u57fa\u51c6\u6d4b\u8bd5\u56f0\u96be\uff0c\u73b0\u6709\u6570\u636e\u96c6\u8981\u4e48\u901a\u8fc7\u5206\u5272\u5355\u673a\u5668\u4eba\u8f68\u8ff9\u6a21\u62df\uff08\u4e0d\u771f\u5b9e\uff09\uff0c\u8981\u4e48\u8f68\u8ff9\u77ed\u3001\u91cd\u53e0\u6709\u9650\u3002\u9700\u8981\u6807\u51c6\u5316\u7684\u591a\u673a\u5668\u4eba\u6570\u636e\u96c6\u6765\u652f\u6301\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u3002", "method": "\u5728\u79d1\u7f57\u62c9\u591a\u5927\u5b66\u535a\u5c14\u5fb7\u5206\u6821\u4e24\u4e2a\u5927\u578b\u5ba4\u5916\u573a\u5730\u6536\u96c6\u591a\u5929\u6570\u636e\uff0c\u5305\u542b\u56db\u4e2a\u540c\u6b65\u8fd0\u884c\u7684\u673a\u5668\u4eba\uff0c\u5177\u6709\u5bf9\u9f50\u7684\u8d77\u59cb\u65f6\u95f4\u548c\u63a7\u5236\u7684\u8f68\u8ff9\u91cd\u53e0\uff0c\u63d0\u4f9bRGB-D\u4f20\u611f\u3001RTK GPS\u3001\u8bed\u4e49LiDAR\u548c\u7cbe\u70bc\u7684\u91cc\u7a0b\u8ba1\u771f\u503c\u3002", "result": "\u521b\u5efa\u4e86CU-Multi\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u7ed3\u5408\u91cd\u53e0\u53d8\u5316\u548c\u5bc6\u96c6\u8bed\u4e49\u6807\u6ce8\uff0c\u4e3a\u591a\u673a\u5668\u4eba\u534f\u4f5c\u611f\u77e5\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u8bc4\u4f30\u7684\u57fa\u7840\u3002", "conclusion": "CU-Multi\u514b\u670d\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6807\u51c6\u5316\u7684\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u652f\u6301\u3002"}}
{"id": "2509.20050", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.20050", "abs": "https://arxiv.org/abs/2509.20050", "authors": ["Alex Amadori", "Eva Behrens", "Gabriel Alfour", "Andrea Miotti"], "title": "The three main doctrines on the future of AI", "comment": null, "summary": "This paper develops a taxonomy of expert perspectives on the risks and likely\nconsequences of artificial intelligence, with particular focus on Artificial\nGeneral Intelligence (AGI) and Artificial Superintelligence (ASI). Drawing from\nprimary sources, we identify three predominant doctrines: (1) The dominance\ndoctrine, which predicts that the first actor to create sufficiently advanced\nAI will attain overwhelming strategic superiority sufficient to cheaply\nneutralize its opponents' defenses; (2) The extinction doctrine, which\nanticipates that humanity will likely lose control of ASI, leading to the\nextinction of the human species or its permanent disempowerment; (3) The\nreplacement doctrine, which forecasts that AI will automate a large share of\ntasks currently performed by humans, but will not be so transformative as to\nfundamentally reshape or bring an end to human civilization. We examine the\nassumptions and arguments underlying each doctrine, including expectations\naround the pace of AI progress and the feasibility of maintaining advanced AI\nunder human control. While the boundaries between doctrines are sometimes\nporous and many experts hedge across them, this taxonomy clarifies the core\naxes of disagreement over the anticipated scale and nature of the consequences\nof AI development.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u98ce\u9669\u7684\u4e13\u5bb6\u89c2\u70b9\u5206\u7c7b\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u901a\u7528\u4eba\u5de5\u667a\u80fd\u548c\u8d85\u7ea7\u4eba\u5de5\u667a\u80fd\u7684\u98ce\u9669\u4e0e\u540e\u679c\u3002\u8bc6\u522b\u4e86\u4e09\u79cd\u4e3b\u8981\u5b66\u8bf4\uff1a\u4e3b\u5bfc\u5b66\u8bf4\u3001\u706d\u7edd\u5b66\u8bf4\u548c\u66ff\u4ee3\u5b66\u8bf4\u3002", "motivation": "\u6f84\u6e05\u4e13\u5bb6\u5bf9AI\u53d1\u5c55\u540e\u679c\u9884\u671f\u4e2d\u7684\u6838\u5fc3\u5206\u6b67\u8f74\uff0c\u4e3a\u7406\u89e3AI\u98ce\u9669\u7684\u4e0d\u540c\u89c2\u70b9\u63d0\u4f9b\u7cfb\u7edf\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u539f\u59cb\u8d44\u6599\u5206\u6790\uff0c\u8bc6\u522b\u548c\u5206\u7c7b\u4e13\u5bb6\u89c2\u70b9\uff0c\u8003\u5bdf\u6bcf\u79cd\u5b66\u8bf4\u7684\u5047\u8bbe\u548c\u8bba\u8bc1\uff0c\u5305\u62ec\u5bf9AI\u8fdb\u5c55\u901f\u5ea6\u548c\u4eba\u7c7b\u63a7\u5236\u53ef\u884c\u6027\u7684\u9884\u671f\u3002", "result": "\u5efa\u7acb\u4e86\u5305\u542b\u4e09\u79cd\u4e3b\u8981\u5b66\u8bf4\u7684\u5206\u7c7b\u4f53\u7cfb\uff1a\u4e3b\u5bfc\u5b66\u8bf4\uff08\u9884\u6d4b\u9996\u4e2a\u521b\u9020\u5148\u8fdbAI\u7684\u884c\u4e3a\u4f53\u5c06\u83b7\u5f97\u6218\u7565\u4f18\u52bf\uff09\u3001\u706d\u7edd\u5b66\u8bf4\uff08\u9884\u6d4b\u4eba\u7c7b\u5c06\u5931\u53bb\u5bf9ASI\u7684\u63a7\u5236\u5bfc\u81f4\u706d\u7edd\uff09\u548c\u66ff\u4ee3\u5b66\u8bf4\uff08\u9884\u6d4bAI\u5c06\u81ea\u52a8\u5316\u4eba\u7c7b\u4efb\u52a1\u4f46\u4e0d\u4f1a\u7ec8\u7ed3\u6587\u660e\uff09\u3002", "conclusion": "\u867d\u7136\u5b66\u8bf4\u8fb9\u754c\u6709\u65f6\u6a21\u7cca\u4e14\u4e13\u5bb6\u89c2\u70b9\u5b58\u5728\u4ea4\u53c9\uff0c\u4f46\u8be5\u5206\u7c7b\u6cd5\u660e\u786e\u4e86AI\u53d1\u5c55\u9884\u671f\u540e\u679c\u89c4\u6a21\u548c\u6027\u8d28\u65b9\u9762\u7684\u6838\u5fc3\u5206\u6b67\u8f74\uff0c\u4e3a\u7406\u89e3\u548c\u8ba8\u8bbaAI\u98ce\u9669\u63d0\u4f9b\u4e86\u6e05\u6670\u6846\u67b6\u3002"}}
{"id": "2509.19516", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19516", "abs": "https://arxiv.org/abs/2509.19516", "authors": ["Jinshui Zhang", "Stefan M Goetz"], "title": "Four-Transistor Bipolar Series-Parallel Module Structure for Cascaded Bridge and Modular Multilevel Circuits", "comment": null, "summary": "With their great scalability and flexibility, cascaded-bridge and modular\nmultilevel converters have enabled a variety of energy applications, such as\noffshore wind power, high-voltage dc power transmission, power-quality\nmanagement, and cutting-edge medical instrumentation. The incorporation of\nparallel connectivity between modules equips systems with advantages such as\nsensorless balancing, switched-capacitor energy exchange, and reduced\nimpedance. However, existing topologies require many individual switches --\neight transistors per module. Efforts to use fewer switches, instead, have\npreviously compromised their functionality. We propose a new module topology,\nnamed the direction-selective parallel (DiSeP) structure, which requires only\nfour transistors per module -- the same as an H bridge -- but can achieve\nbidirectional equilibration, bipolar module output, and inter-module\nswitched-capacitor features.\n  This topology is highly attractive for existing converters with cascaded\nbridge elements, as the addition of only four diodes enables key features such\nas sensorless balancing and inter-module energy exchange. Thus, the module can\noutcompete H bridges in their applications, as it adds parallel modes without\nany additional transistors. Compared to double-H bridges (CH2B), it saves as\nmany as half of the transistors.\n  We elaborate on its working principles and key design considerations. We\nvalidate our theories on an experimental prototype with six modules. This\nprototype attains a total voltage harmonic distortion plus noise (THD+N) of\n10.3% and a peak efficiency of 96.3%. Furthermore, the modules achieve\nautonomous sensorless balancing under open-loop control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiSeP\u7684\u65b0\u578b\u6a21\u5757\u62d3\u6251\u7ed3\u6784\uff0c\u4ec5\u97004\u4e2a\u6676\u4f53\u7ba1\u5373\u53ef\u5b9e\u73b0\u53cc\u5411\u5747\u8861\u3001\u53cc\u6781\u6a21\u5757\u8f93\u51fa\u548c\u6a21\u5757\u95f4\u5f00\u5173\u7535\u5bb9\u529f\u80fd\uff0c\u76f8\u6bd4\u4f20\u7edf\u7ed3\u6784\u8282\u7701\u4e00\u534a\u6676\u4f53\u7ba1", "motivation": "\u73b0\u6709\u7ea7\u8054\u6865\u548c\u6a21\u5757\u5316\u591a\u7535\u5e73\u8f6c\u6362\u5668\u9700\u8981\u6bcf\u4e2a\u6a21\u57578\u4e2a\u6676\u4f53\u7ba1\uff0c\u867d\u7136\u5177\u6709\u5e76\u884c\u8fde\u63a5\u4f18\u52bf\u4f46\u6210\u672c\u9ad8\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u51cf\u5c11\u5f00\u5173\u6570\u91cf\u53c8\u4e0d\u727a\u7272\u529f\u80fd\u7684\u65b0\u62d3\u6251", "method": "\u8bbe\u8ba1\u65b9\u5411\u9009\u62e9\u6027\u5e76\u884c(DiSeP)\u7ed3\u6784\uff0c\u5728H\u6865\u57fa\u7840\u4e0a\u4ec5\u589e\u52a04\u4e2a\u4e8c\u6781\u7ba1\u5373\u53ef\u5b9e\u73b0\u5e76\u884c\u6a21\u5f0f\uff0c\u652f\u6301\u4f20\u611f\u5668\u65e0\u5e73\u8861\u548c\u6a21\u5757\u95f4\u80fd\u91cf\u4ea4\u6362", "result": "\u5b9e\u9a8c\u539f\u578b\u663e\u793a\u603b\u7535\u538b\u8c10\u6ce2\u5931\u771f\u52a0\u566a\u58f0\u4e3a10.3%\uff0c\u5cf0\u503c\u6548\u7387\u8fbe96.3%\uff0c\u6a21\u5757\u5728\u5f00\u73af\u63a7\u5236\u4e0b\u5b9e\u73b0\u81ea\u4e3b\u4f20\u611f\u5668\u65e0\u5e73\u8861", "conclusion": "DiSeP\u62d3\u6251\u5728\u4fdd\u6301\u529f\u80fd\u5b8c\u6574\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u6676\u4f53\u7ba1\u6570\u91cf\uff0c\u4e3a\u7ea7\u8054\u6865\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5177\u7ade\u4e89\u529b\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.19517", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.19517", "abs": "https://arxiv.org/abs/2509.19517", "authors": ["Sai Teja Reddy Adapala"], "title": "Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning", "comment": null, "summary": "The scaling of Large Language Models (LLMs) has exposed a critical gap\nbetween their performance on static benchmarks and their fragility in dynamic,\ninformation-rich environments. While models excel at isolated tasks, the\ncomputational limits that govern their reasoning under cognitive load remain\npoorly understood. In this work, we introduce a formal theory of computational\ncognitive load, positing that extraneous, task-irrelevant information (Context\nSaturation) and interference from task-switching (Attentional Residue) are key\nmechanisms that degrade performance. We designed the Interleaved Cognitive\nEvaluation (ICE), a deconfounded benchmark to systematically manipulate these\nload factors on challenging multi-hop reasoning tasks. A comprehensive study (N\n= 10 replications per item across 200 questions) revealed significant\nperformance variations across five instruction-tuned models. Smaller\nopen-source architectures (Llama-3-8B-Instruct, Mistral-7B-Instruct-v0.2)\nexhibited baseline brittleness, achieving 0% accuracy (SEM = 0.0) across all\nconditions, including clean controls, on this high-intrinsic-load task. In\ncontrast, Gemini-2.0-Flash-001 showed partial resilience, achieving 85%\naccuracy in control conditions, with a statistically significant degradation\nunder context saturation ($\\beta = -0.003$ per % load, $p < 0.001$). These\nfindings provide preliminary evidence that cognitive load is a key contributor\nto reasoning failures, supporting theories of hallucination-as-guessing under\nuncertainty. We conclude that dynamic, cognitive-aware stress testing, as\nexemplified by the ICE benchmark, is essential for evaluating the true\nresilience and safety of advanced AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u8ba1\u7b97\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\uff0c\u5e76\u901a\u8fc7ICE\u57fa\u51c6\u6d4b\u8bd5\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u4fe1\u606f\u4e30\u5bcc\u73af\u5883\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u4e3b\u8981\u53d7\u4e0a\u4e0b\u6587\u9971\u548c\u548c\u6ce8\u610f\u529b\u6b8b\u7559\u7684\u5f71\u54cd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u52a8\u6001\u4fe1\u606f\u4e30\u5bcc\u73af\u5883\u4e2d\u7684\u8106\u5f31\u6027\u5b58\u5728\u5173\u952e\u5dee\u8ddd\uff0c\u8ba1\u7b97\u9650\u5236\u5bf9\u8ba4\u77e5\u8d1f\u8377\u4e0b\u63a8\u7406\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5f15\u5165\u8ba1\u7b97\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\uff0c\u8bbe\u8ba1ICE\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\u64cd\u7eb5\u4e0a\u4e0b\u6587\u9971\u548c\u548c\u6ce8\u610f\u529b\u6b8b\u7559\u56e0\u7d20\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e0a\u8fdb\u884c\u5168\u9762\u7814\u7a76\u3002", "result": "\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u5728\u6240\u6709\u6761\u4ef6\u4e0b\u51c6\u786e\u7387\u4e3a0%\uff0c\u800cGemini-2.0-Flash-001\u5728\u63a7\u5236\u6761\u4ef6\u4e0b\u8fbe\u523085%\u51c6\u786e\u7387\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u9971\u548c\u6761\u4ef6\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u8ba4\u77e5\u8d1f\u8377\u662f\u5bfc\u81f4\u63a8\u7406\u5931\u8d25\u7684\u5173\u952e\u56e0\u7d20\uff0c\u52a8\u6001\u7684\u8ba4\u77e5\u611f\u77e5\u538b\u529b\u6d4b\u8bd5\u5bf9\u4e8e\u8bc4\u4f30\u5148\u8fdbAI\u7cfb\u7edf\u7684\u771f\u5b9e\u97e7\u6027\u548c\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.19473", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.19473", "abs": "https://arxiv.org/abs/2509.19473", "authors": ["Adarsh Salagame", "Henry Noyes", "Alireza Ramezani", "Eric Sihite", "Arash Kalantari"], "title": "Crater Observing Bio-inspired Rolling Articulator (COBRA)", "comment": null, "summary": "NASA aims to establish a sustainable human basecamp on the Moon as a stepping\nstone for future missions to Mars and beyond. The discovery of water ice on the\nMoon's craters located in permanently shadowed regions, which can provide\ndrinking water, oxygen, and rocket fuel, is therefore of critical importance.\nHowever, current methods to access lunar ice deposits are limited. While rovers\nhave been used to explore the lunar surface for decades, they face significant\nchallenges in navigating harsh terrains, such as permanently shadowed craters,\ndue to the high risk of immobilization. This report introduces COBRA (Crater\nObserving Bio-inspired Rolling Articulator), a multi-modal snake-style robot\ndesigned to overcome mobility challenges in Shackleton Crater's rugged\nenvironment. COBRA combines slithering and tumbling locomotion to adapt to\nvarious crater terrains. In snake mode, it uses sidewinding to traverse flat or\nlow inclined surfaces, while in tumbling mode, it forms a circular barrel by\nlinking its head and tail, enabling rapid movement with minimal energy on steep\nslopes. Equipped with an onboard computer, stereo camera, inertial measurement\nunit, and joint encoders, COBRA facilitates real-time data collection and\nautonomous operation. This paper highlights COBRAs robustness and efficiency in\nnavigating extreme terrains through both simulations and experimental\nvalidation.", "AI": {"tldr": "COBRA\u662f\u4e00\u79cd\u591a\u6a21\u6001\u86c7\u5f62\u673a\u5668\u4eba\uff0c\u4e13\u4e3a\u5728\u6708\u7403\u6c99\u514b\u5c14\u987f\u9668\u77f3\u5751\u7684\u6076\u52a3\u5730\u5f62\u4e2d\u5bfc\u822a\u800c\u8bbe\u8ba1\uff0c\u7ed3\u5408\u6ed1\u884c\u548c\u7ffb\u6eda\u4e24\u79cd\u8fd0\u52a8\u6a21\u5f0f\u6765\u9002\u5e94\u4e0d\u540c\u5730\u5f62\u6761\u4ef6\u3002", "motivation": "NASA\u8ba1\u5212\u5728\u6708\u7403\u5efa\u7acb\u53ef\u6301\u7eed\u7684\u4eba\u7c7b\u57fa\u5730\uff0c\u9700\u8981\u83b7\u53d6\u6c38\u4e45\u9634\u5f71\u533a\u57df\u7684\u6c34\u51b0\u8d44\u6e90\u3002\u73b0\u6709\u6708\u7403\u8f66\u5728\u9668\u77f3\u5751\u7b49\u6076\u52a3\u5730\u5f62\u4e2d\u79fb\u52a8\u56f0\u96be\uff0c\u5b58\u5728\u88ab\u56f0\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u578b\u79fb\u52a8\u673a\u5668\u4eba\u3002", "method": "COBRA\u91c7\u7528\u86c7\u5f62\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u5177\u6709\u4e24\u79cd\u8fd0\u52a8\u6a21\u5f0f\uff1a\u86c7\u6a21\u5f0f\u7528\u4e8e\u5e73\u5766\u6216\u7f13\u5761\u5730\u5f62\u7684\u4fa7\u5411\u6ed1\u884c\uff0c\u7ffb\u6eda\u6a21\u5f0f\u901a\u8fc7\u8fde\u63a5\u5934\u5c3e\u5f62\u6210\u5706\u7b52\u72b6\u7ed3\u6784\uff0c\u5728\u9661\u5761\u4e0a\u5b9e\u73b0\u9ad8\u6548\u6eda\u52a8\u3002\u673a\u5668\u4eba\u914d\u5907\u673a\u8f7d\u8ba1\u7b97\u673a\u3001\u7acb\u4f53\u76f8\u673a\u3001\u60ef\u6027\u6d4b\u91cf\u5355\u5143\u548c\u5173\u8282\u7f16\u7801\u5668\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0cCOBRA\u5728\u6781\u7aef\u5730\u5f62\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u9c81\u68d2\u6027\u548c\u79fb\u52a8\u6548\u7387\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u6c99\u514b\u5c14\u987f\u9668\u77f3\u5751\u7684\u590d\u6742\u73af\u5883\u3002", "conclusion": "COBRA\u591a\u6a21\u6001\u79fb\u52a8\u7b56\u7565\u4e3a\u89e3\u51b3\u6708\u7403\u6c38\u4e45\u9634\u5f71\u533a\u57df\u63a2\u6d4b\u7684\u79fb\u52a8\u6311\u6218\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u6708\u7403\u8d44\u6e90\u52d8\u63a2\u4efb\u52a1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.20153", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20153", "abs": "https://arxiv.org/abs/2509.20153", "authors": ["Nicola Fabiano"], "title": "Affective Computing and Emotional Data: Challenges and Implications in Privacy Regulations, The AI Act, and Ethics in Large Language Models", "comment": null, "summary": "This paper examines the integration of emotional intelligence into artificial\nintelligence systems, with a focus on affective computing and the growing\ncapabilities of Large Language Models (LLMs), such as ChatGPT and Claude, to\nrecognize and respond to human emotions. Drawing on interdisciplinary research\nthat combines computer science, psychology, and neuroscience, the study\nanalyzes foundational neural architectures - CNNs for processing facial\nexpressions and RNNs for sequential data, such as speech and text - that enable\nemotion recognition. It examines the transformation of human emotional\nexperiences into structured emotional data, addressing the distinction between\nexplicit emotional data collected with informed consent in research settings\nand implicit data gathered passively through everyday digital interactions.\nThat raises critical concerns about lawful processing, AI transparency, and\nindividual autonomy over emotional expressions in digital environments. The\npaper explores implications across various domains, including healthcare,\neducation, and customer service, while addressing challenges of cultural\nvariations in emotional expression and potential biases in emotion recognition\nsystems across different demographic groups. From a regulatory perspective, the\npaper examines emotional data in the context of the GDPR and the EU AI Act\nframeworks, highlighting how emotional data may be considered sensitive\npersonal data that requires robust safeguards, including purpose limitation,\ndata minimization, and meaningful consent mechanisms.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5c06\u60c5\u5546\u6574\u5408\u5230\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\uff0c\u91cd\u70b9\u5173\u6ce8\u60c5\u611f\u8ba1\u7b97\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u53ca\u54cd\u5e94\u4eba\u7c7b\u60c5\u7eea\u7684\u80fd\u529b\uff0c\u5206\u6790\u4e86\u60c5\u611f\u6570\u636e\u5904\u7406\u7684\u795e\u7ecf\u67b6\u6784\u3001\u4f26\u7406\u95ee\u9898\u548c\u76d1\u7ba1\u6846\u67b6\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u65e5\u76ca\u80fd\u591f\u8bc6\u522b\u548c\u54cd\u5e94\u4eba\u7c7b\u60c5\u7eea\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u5c06\u60c5\u5546\u6574\u5408\u5230AI\u4e2d\uff0c\u540c\u65f6\u89e3\u51b3\u60c5\u611f\u6570\u636e\u5904\u7406\u4e2d\u7684\u4f26\u7406\u3001\u9690\u79c1\u548c\u76d1\u7ba1\u6311\u6218\u3002", "method": "\u91c7\u7528\u8de8\u5b66\u79d1\u7814\u7a76\u65b9\u6cd5\uff0c\u7ed3\u5408\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u5fc3\u7406\u5b66\u548c\u795e\u7ecf\u79d1\u5b66\uff0c\u5206\u6790CNN\u5904\u7406\u9762\u90e8\u8868\u60c5\u548cRNN\u5904\u7406\u8bed\u97f3\u6587\u672c\u7b49\u5e8f\u5217\u6570\u636e\u7684\u795e\u7ecf\u67b6\u6784\uff0c\u5e76\u7814\u7a76\u60c5\u611f\u6570\u636e\u4ece\u4eba\u7c7b\u4f53\u9a8c\u5230\u7ed3\u6784\u5316\u6570\u636e\u7684\u8f6c\u5316\u8fc7\u7a0b\u3002", "result": "\u8bc6\u522b\u4e86\u60c5\u611fAI\u5728\u533b\u7597\u3001\u6559\u80b2\u3001\u5ba2\u670d\u7b49\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u6587\u5316\u5dee\u5f02\u3001\u7cfb\u7edf\u504f\u89c1\u4ee5\u53ca\u60c5\u611f\u6570\u636e\u4f5c\u4e3a\u654f\u611f\u4e2a\u4eba\u6570\u636e\u9700\u8981\u4e25\u683c\u4fdd\u62a4\u7684\u95ee\u9898\u3002", "conclusion": "\u60c5\u611fAI\u7684\u53d1\u5c55\u9700\u8981\u5728\u6280\u672f\u521b\u65b0\u4e0e\u4f26\u7406\u76d1\u7ba1\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0cGDPR\u548c\u6b27\u76dfAI\u6cd5\u6848\u4e3a\u60c5\u611f\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u6846\u67b6\uff0c\u5f3a\u8c03\u76ee\u7684\u9650\u5236\u3001\u6570\u636e\u6700\u5c0f\u5316\u548c\u6709\u610f\u4e49\u7684\u540c\u610f\u673a\u5236\u7b49\u4fdd\u62a4\u63aa\u65bd\u3002"}}
{"id": "2509.19612", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19612", "abs": "https://arxiv.org/abs/2509.19612", "authors": ["Yifan Dong", "Ge Chen", "Junjie Qin"], "title": "Federated Aggregation of Demand Flexibility", "comment": "Longer version of a paper to be submitted to IEEE Transactions on\n  Smart Grid", "summary": "This paper proposes a federated framework for demand flexibility aggregation\nto support grid operations. Unlike existing geometric methods that rely on a\nstatic, pre-defined base set as the geometric template for aggregation, our\nframework establishes a true federated process by enabling the collaborative\noptimization of this base set without requiring the participants sharing\nsensitive data with the aggregator. Specifically, we first formulate the base\nset optimization problem as a bilevel program. Using optimal solution\nfunctions, we then reformulate the bilevel program into a single-level,\nunconstrained learning task. By exploiting the decomposable structure of the\noverall gradient, we further design a decentralized gradient-based algorithm to\nsolve this learning task. The entire framework, encompassing base set\noptimization, aggregation, and disaggregation, operates by design without\nexchanging raw user data. Numerical results demonstrate that our proposed\nframework unlocks substantially more flexibility than the approaches with\nstatic base sets, thus providing a promising framework for efficient and\nprivacy-enhanced approaches to coordinate demand flexibility at scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u90a6\u6846\u67b6\u7528\u4e8e\u9700\u6c42\u7075\u6d3b\u6027\u805a\u5408\u4ee5\u652f\u6301\u7535\u7f51\u8fd0\u8425\uff0c\u901a\u8fc7\u534f\u4f5c\u4f18\u5316\u57fa\u7840\u96c6\u800c\u4e0d\u9700\u8981\u53c2\u4e0e\u8005\u5171\u4eab\u654f\u611f\u6570\u636e\uff0c\u76f8\u6bd4\u9759\u6001\u57fa\u7840\u96c6\u65b9\u6cd5\u80fd\u91ca\u653e\u66f4\u591a\u7075\u6d3b\u6027\u3002", "motivation": "\u73b0\u6709\u51e0\u4f55\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u9884\u5b9a\u4e49\u7684\u57fa\u7840\u96c6\u4f5c\u4e3a\u805a\u5408\u6a21\u677f\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u8054\u90a6\u8fc7\u7a0b\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u771f\u6b63\u7684\u8054\u90a6\u6846\u67b6\uff0c\u5141\u8bb8\u534f\u4f5c\u4f18\u5316\u57fa\u7840\u96c6\u800c\u65e0\u9700\u5171\u4eab\u654f\u611f\u6570\u636e\u3002", "method": "\u9996\u5148\u5c06\u57fa\u7840\u96c6\u4f18\u5316\u95ee\u9898\u8868\u8ff0\u4e3a\u53cc\u5c42\u89c4\u5212\uff0c\u7136\u540e\u4f7f\u7528\u6700\u4f18\u89e3\u51fd\u6570\u5c06\u5176\u91cd\u65b0\u8868\u8ff0\u4e3a\u5355\u5c42\u65e0\u7ea6\u675f\u5b66\u4e60\u4efb\u52a1\uff0c\u5229\u7528\u6574\u4f53\u68af\u5ea6\u7684\u53ef\u5206\u89e3\u7ed3\u6784\u8bbe\u8ba1\u53bb\u4e2d\u5fc3\u5316\u68af\u5ea6\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u6bd4\u9759\u6001\u57fa\u7840\u96c6\u65b9\u6cd5\u91ca\u653e\u4e86\u663e\u8457\u66f4\u591a\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u534f\u8c03\u9700\u6c42\u7075\u6d3b\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u589e\u5f3a\u9690\u79c1\u7684\u6709\u524d\u666f\u65b9\u6cd5\uff0c\u6574\u4e2a\u6846\u67b6\u5728\u8bbe\u8ba1\u4e0a\u65e0\u9700\u4ea4\u6362\u539f\u59cb\u7528\u6237\u6570\u636e\u3002"}}
{"id": "2509.19524", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19524", "abs": "https://arxiv.org/abs/2509.19524", "authors": ["Ramy ElMallah", "Krish Chhajer", "Chi-Guhn Lee"], "title": "Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation", "comment": "Accepted to the CoRL 2025 Eval&Deploy Workshop", "summary": "Robot learning papers typically report a single binary success rate (SR),\nwhich obscures where a policy succeeds or fails along a multi-step manipulation\ntask. We argue that subgoal-level reporting should become routine: for each\ntrajectory, a vector of per-subgoal SRs that makes partial competence visible\n(e.g., grasp vs. pour). We propose a blueprint for StepEval, a cost-aware\nplug-in evaluation framework that utilizes vision-language models (VLMs) as\nautomated judges of subgoal outcomes from recorded images or videos. Rather\nthan proposing new benchmarks or APIs, our contribution is to outline design\nprinciples for a scalable, community-driven open-source project. In StepEval,\nthe primary artifact for policy evaluation is the per-subgoal SR vector;\nhowever, other quantities (e.g., latency or cost estimates) are also considered\nfor framework-optimization diagnostics to help the community tune evaluation\nefficiency and accuracy when ground-truth subgoal success labels are available.\nWe discuss how such a framework can remain model-agnostic, support single- or\nmulti-view inputs, and be lightweight enough to adopt across labs. The intended\ncontribution is a shared direction: a minimal, extensible seed that invites\nopen-source contributions, so that scoring the steps, not just the final goal,\nbecomes a standard and reproducible practice.", "AI": {"tldr": "\u63d0\u51faStepEval\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5224\u65ad\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5b50\u76ee\u6807\u5b8c\u6210\u60c5\u51b5\uff0c\u66ff\u4ee3\u5355\u4e00\u6210\u529f\u7387\u62a5\u544a\uff0c\u5b9e\u73b0\u66f4\u7ec6\u7c92\u5ea6\u7684\u6027\u80fd\u8bc4\u4f30", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u5b66\u4e60\u8bba\u6587\u4ec5\u62a5\u544a\u5355\u4e00\u6210\u529f\u7387\uff0c\u65e0\u6cd5\u663e\u793a\u591a\u6b65\u9aa4\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5404\u5b50\u76ee\u6807\u7684\u5b8c\u6210\u60c5\u51b5\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u8bb0\u5f55\u56fe\u50cf\u6216\u89c6\u9891\u5224\u65ad\u5b50\u76ee\u6807\u5b8c\u6210\u72b6\u6001\uff0c\u751f\u6210\u6bcf\u4e2a\u5b50\u76ee\u6807\u7684\u6210\u529f\u7387\u5411\u91cf", "result": "\u63d0\u51fa\u53ef\u6269\u5c55\u7684\u5f00\u6e90\u6846\u67b6\u8bbe\u8ba1\u539f\u5219\uff0c\u652f\u6301\u6a21\u578b\u65e0\u5173\u3001\u5355/\u591a\u89c6\u89d2\u8f93\u5165\uff0c\u4fbf\u4e8e\u5b9e\u9a8c\u5ba4\u95f4\u91c7\u7528", "conclusion": "StepEval\u6846\u67b6\u65e8\u5728\u63a8\u52a8\u793e\u533a\u5efa\u7acb\u6807\u51c6\u5316\u3001\u53ef\u590d\u73b0\u7684\u5b50\u76ee\u6807\u8bc4\u4f30\u5b9e\u8df5\uff0c\u4f7f\u6b65\u9aa4\u7ea7\u8bc4\u4f30\u6210\u4e3a\u5e38\u89c4\u62a5\u544a\u5185\u5bb9"}}
{"id": "2509.19480", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19480", "abs": "https://arxiv.org/abs/2509.19480", "authors": ["Noriaki Hirose", "Catherine Glossop", "Dhruv Shah", "Sergey Levine"], "title": "OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation", "comment": "9 pages, 7 figures, 6 tables", "summary": "Humans can flexibly interpret and compose different goal specifications, such\nas language instructions, spatial coordinates, or visual references, when\nnavigating to a destination. In contrast, most existing robotic navigation\npolicies are trained on a single modality, limiting their adaptability to\nreal-world scenarios where different forms of goal specification are natural\nand complementary. In this work, we present a training framework for robotic\nfoundation models that enables omni-modal goal conditioning for vision-based\nnavigation. Our approach leverages a high-capacity vision-language-action (VLA)\nbackbone and trains with three primary goal modalities: 2D poses, egocentric\nimages, and natural language, as well as their combinations, through a\nrandomized modality fusion strategy. This design not only expands the pool of\nusable datasets but also encourages the policy to develop richer geometric,\nsemantic, and visual representations. The resulting model, OmniVLA, achieves\nstrong generalization to unseen environments, robustness to scarce modalities,\nand the ability to follow novel natural language instructions. We demonstrate\nthat OmniVLA outperforms specialist baselines across modalities and offers a\nflexible foundation for fine-tuning to new modalities and tasks. We believe\nOmniVLA provides a step toward broadly generalizable and flexible navigation\npolicies, and a scalable path for building omni-modal robotic foundation\nmodels. We present videos showcasing OmniVLA performance and will release its\ncheckpoints and training code on our project page.", "AI": {"tldr": "\u63d0\u51fa\u4e86OmniVLA\u8bad\u7ec3\u6846\u67b6\uff0c\u5b9e\u73b0\u673a\u5668\u4eba\u5bfc\u822a\u7684\u591a\u6a21\u6001\u76ee\u6807\u6761\u4ef6\u5316\uff0c\u4f7f\u7528\u8bed\u8a00\u3001\u56fe\u50cf\u548c\u4f4d\u59ff\u7b49\u591a\u79cd\u76ee\u6807\u6a21\u6001\uff0c\u901a\u8fc7\u968f\u673a\u878d\u5408\u7b56\u7565\u63d0\u5347\u6cdb\u5316\u80fd\u529b", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u5bfc\u822a\u7b56\u7565\u901a\u5e38\u53ea\u9488\u5bf9\u5355\u4e00\u6a21\u6001\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u800c\u4eba\u7c7b\u80fd\u591f\u7075\u6d3b\u7406\u89e3\u591a\u79cd\u76ee\u6807\u89c4\u8303", "method": "\u4f7f\u7528\u9ad8\u5bb9\u91cf\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u9aa8\u5e72\u7f51\u7edc\uff0c\u8bad\u7ec3\u65f6\u878d\u54082D\u4f4d\u59ff\u3001\u81ea\u4e2d\u5fc3\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u4e09\u79cd\u4e3b\u8981\u76ee\u6807\u6a21\u6001\uff0c\u91c7\u7528\u968f\u673a\u6a21\u6001\u878d\u5408\u7b56\u7565", "result": "OmniVLA\u6a21\u578b\u5728\u672a\u89c1\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u5bf9\u7a00\u7f3a\u6a21\u6001\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u9075\u5faa\u65b0\u7684\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u4f18\u4e8e\u5404\u6a21\u6001\u7684\u4e13\u5bb6\u57fa\u7ebf", "conclusion": "OmniVLA\u4e3a\u6784\u5efa\u5e7f\u6cdb\u6cdb\u5316\u548c\u7075\u6d3b\u7684\u5bfc\u822a\u7b56\u7565\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\uff0c\u4e3a\u6784\u5efa\u591a\u6a21\u6001\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u8def\u5f84"}}
{"id": "2509.19590", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19590", "abs": "https://arxiv.org/abs/2509.19590", "authors": ["Nathanael Jo", "Ashia Wilson"], "title": "What Does Your Benchmark Really Measure? A Framework for Robust Inference of AI Capabilities", "comment": null, "summary": "Evaluations of generative models on benchmark data are now ubiquitous, and\ntheir outcomes critically shape public and scientific expectations of AI's\ncapabilities. Yet growing skepticism surrounds their reliability. How can we\nknow that a reported accuracy genuinely reflects a model's true performance?\nEvaluations are often presented as simple measurements, but in reality they are\ninferences: to treat benchmark scores as evidence of capability is already to\nassume a theory of what capability is and how it manifests in a test. We make\nthis step explicit by proposing a principled framework for evaluation as\ninference: begin from a theory of capability, and then derive methods for\nestimating it. This perspective, familiar in fields such as psychometrics, has\nnot yet become commonplace in AI evaluation. As a proof of concept, we address\na central challenge that undermines reliability: sensitivity to perturbations.\nAfter formulating a model of ability, we introduce methods that infer ability\nwhile accounting for uncertainty from sensitivity and finite samples, including\nan adaptive algorithm that significantly reduces sample complexity. Together,\nthese contributions lay the groundwork for more reliable and trustworthy\nestimates of AI capabilities as measured through benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06AI\u8bc4\u4f30\u89c6\u4e3a\u63a8\u7406\u7684\u6846\u67b6\uff0c\u5f3a\u8c03\u57fa\u51c6\u6d4b\u8bd5\u5206\u6570\u5e94\u57fa\u4e8e\u5bf9\u80fd\u529b\u7684\u7406\u8bba\u5047\u8bbe\uff0c\u5e76\u9488\u5bf9\u654f\u611f\u6027\u6270\u52a8\u95ee\u9898\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u53d7\u5230\u8d28\u7591\uff0c\u57fa\u51c6\u6d4b\u8bd5\u5206\u6570\u5f80\u5f80\u88ab\u7b80\u5355\u89c6\u4e3a\u6d4b\u91cf\u7ed3\u679c\uff0c\u4f46\u5b9e\u9645\u4e0a\u5b83\u4eec\u662f\u57fa\u4e8e\u5bf9\u80fd\u529b\u7406\u8bba\u7684\u63a8\u65ad\u3002", "method": "\u63d0\u51fa\u4e86\u8bc4\u4f30\u5373\u63a8\u7406\u7684\u6846\u67b6\uff0c\u4ece\u80fd\u529b\u7406\u8bba\u51fa\u53d1\u63a8\u5bfc\u4f30\u8ba1\u65b9\u6cd5\uff1b\u9488\u5bf9\u654f\u611f\u6027\u6270\u52a8\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684\u80fd\u529b\u63a8\u65ad\u65b9\u6cd5\uff0c\u5305\u62ec\u663e\u8457\u964d\u4f4e\u6837\u672c\u590d\u6742\u5ea6\u7684\u81ea\u9002\u5e94\u7b97\u6cd5\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u83b7\u5f97\u66f4\u53ef\u9760\u3001\u53ef\u4fe1\u7684AI\u80fd\u529b\u4f30\u8ba1\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8bc4\u4f30\u5e94\u660e\u786e\u57fa\u4e8e\u80fd\u529b\u7406\u8bba\uff0c\u8be5\u7814\u7a76\u4e3aAI\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u4e25\u8c28\u7684\u63a8\u7406\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2509.19784", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19784", "abs": "https://arxiv.org/abs/2509.19784", "authors": ["Jin Chen", "Jesus Bautista Villar", "Bayu Jayawardhana", "Hector Garcia de Marina"], "title": "Dispersion Formation Control: from Geometry to Distribution", "comment": "8 pages, 4 figures", "summary": "We introduce and develop the concept of dispersion formation control,\nbridging a gap between shape-assembly studies in physics and biology and\nformation control theory. In current formation control studies, the control\nobjectives typically focus on achieving desired local geometric properties,\nsuch as inter-agent distances, bearings, or relative positions. In contrast,\nour dispersion formation control approach enables agents to directly regulate\nthe dispersion of their spatial distribution, a global variable associated with\na covariance matrix. Specifically, we introduce the notion of covariance\nsimilarity to define the target spatial dispersion of agents. Building on this\nframework, we propose two control strategies: a centralized approach to\nillustrate the key ideas, and a distributed approach that enables agents to\ncontrol the global dispersion but using only local information. Our stability\nanalysis demonstrates that both strategies ensure exponential convergence of\nthe agents' distribution to the desired dispersion. Notably, controlling a\nglobal variable rather than multiple local ones enhances the resiliency of the\nsystem, particularly against malfunctioning agents. Simulations validate the\neffectiveness of the proposed dispersion formation control.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5206\u6563\u5f62\u6210\u63a7\u5236\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u76f4\u63a5\u8c03\u8282\u667a\u80fd\u4f53\u7a7a\u95f4\u5206\u5e03\u7684\u79bb\u6563\u5ea6\uff08\u5168\u5c40\u53d8\u91cf\uff09\u6765\u5f25\u8865\u7269\u7406\u548c\u751f\u7269\u5b66\u4e2d\u5f62\u72b6\u7ec4\u88c5\u7814\u7a76\u4e0e\u5f62\u6210\u63a7\u5236\u7406\u8bba\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524d\u5f62\u6210\u63a7\u5236\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5b9e\u73b0\u671f\u671b\u7684\u5c40\u90e8\u51e0\u4f55\u7279\u6027\uff08\u5982\u667a\u80fd\u4f53\u95f4\u8ddd\u79bb\u3001\u65b9\u4f4d\u6216\u76f8\u5bf9\u4f4d\u7f6e\uff09\uff0c\u800c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u76f4\u63a5\u8c03\u63a7\u667a\u80fd\u4f53\u7a7a\u95f4\u5206\u5e03\u79bb\u6563\u5ea6\u7684\u5168\u5c40\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u534f\u65b9\u5dee\u76f8\u4f3c\u6027\u6982\u5ff5\u6765\u5b9a\u4e49\u76ee\u6807\u7a7a\u95f4\u79bb\u6563\u5ea6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u63a7\u5236\u7b56\u7565\uff1a\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u7528\u4e8e\u8bf4\u660e\u6838\u5fc3\u601d\u60f3\uff0c\u5206\u5e03\u5f0f\u65b9\u6cd5\u4f7f\u667a\u80fd\u4f53\u4ec5\u4f7f\u7528\u5c40\u90e8\u4fe1\u606f\u5c31\u80fd\u63a7\u5236\u5168\u5c40\u79bb\u6563\u5ea6\u3002", "result": "\u7a33\u5b9a\u6027\u5206\u6790\u8868\u660e\u4e24\u79cd\u7b56\u7565\u90fd\u80fd\u786e\u4fdd\u667a\u80fd\u4f53\u5206\u5e03\u4ee5\u6307\u6570\u901f\u5ea6\u6536\u655b\u5230\u671f\u671b\u79bb\u6563\u5ea6\uff0c\u4e14\u63a7\u5236\u5168\u5c40\u53d8\u91cf\u76f8\u6bd4\u63a7\u5236\u591a\u4e2a\u5c40\u90e8\u53d8\u91cf\u589e\u5f3a\u4e86\u7cfb\u7edf\u5bf9\u6545\u969c\u667a\u80fd\u4f53\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u4eff\u771f\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u5206\u6563\u5f62\u6210\u63a7\u5236\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8c03\u63a7\u5168\u5c40\u79bb\u6563\u5ea6\u53d8\u91cf\u63d0\u9ad8\u4e86\u5f62\u6210\u63a7\u5236\u7cfb\u7edf\u7684\u7a33\u5065\u6027\u3002"}}
{"id": "2509.19566", "categories": ["cs.AI", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2509.19566", "abs": "https://arxiv.org/abs/2509.19566", "authors": ["George Hong", "Daniel Trejo Banos"], "title": "Nano Bio-Agents (NBA): Small Language Model Agents for Genomics", "comment": null, "summary": "We investigate the application of Small Language Models (<10 billion\nparameters) for genomics question answering via agentic framework to address\nhallucination issues and computational cost challenges. The Nano Bio-Agent\n(NBA) framework we implemented incorporates task decomposition, tool\norchestration, and API access into well-established systems such as NCBI and\nAlphaGenome. Results show that SLMs combined with such agentic framework can\nachieve comparable and in many cases superior performance versus existing\napproaches utilising larger models, with our best model-agent combination\nachieving 98% accuracy on the GeneTuring benchmark. Notably, small 3-10B\nparameter models consistently achieve 85-97% accuracy while requiring much\nlower computational resources than conventional approaches. This demonstrates\npromising potential for efficiency gains, cost savings, and democratization of\nML-powered genomics tools while retaining highly robust and accurate\nperformance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08<100\u4ebf\u53c2\u6570\uff09\u901a\u8fc7\u667a\u80fd\u4f53\u6846\u67b6\u8fdb\u884c\u57fa\u56e0\u7ec4\u95ee\u7b54\uff0c\u4ee5\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u548c\u8ba1\u7b97\u6210\u672c\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u4e2d\u5b58\u5728\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u5f00\u53d1\u4e86Nano Bio-Agent\u6846\u67b6\uff0c\u7ed3\u5408\u4efb\u52a1\u5206\u89e3\u3001\u5de5\u5177\u7f16\u6392\u548cAPI\u8bbf\u95ee\uff08\u5982NCBI\u548cAlphaGenome\u7cfb\u7edf\uff09\uff0c\u5c06\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4e13\u4e1a\u5de5\u5177\u96c6\u6210\u3002", "result": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff083-100\u4ebf\u53c2\u6570\uff09\u5728GeneTuring\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523085-97%\u7684\u51c6\u786e\u7387\uff0c\u6700\u4f73\u7ec4\u5408\u8fbe\u523098%\u51c6\u786e\u7387\uff0c\u6027\u80fd\u4f18\u4e8e\u4f7f\u7528\u66f4\u5927\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u667a\u80fd\u4f53\u6846\u67b6\u5728\u57fa\u56e0\u7ec4\u5b66\u9886\u57df\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u4e14\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u4fc3\u8fdbML\u9a71\u52a8\u7684\u57fa\u56e0\u7ec4\u5b66\u5de5\u5177\u7684\u666e\u53ca\u3002"}}
{"id": "2509.19486", "categories": ["cs.RO", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.19486", "abs": "https://arxiv.org/abs/2509.19486", "authors": ["Kieran S. Lachmansingh", "Jos\u00e9 R. Gonz\u00e1lez-Estrada", "Ryan E. Grant", "Matthew K. X. J. Pan"], "title": "Supercomputing for High-speed Avoidance and Reactive Planning in Robots", "comment": "8 pages, 3 figures", "summary": "This paper presents SHARP (Supercomputing for High-speed Avoidance and\nReactive Planning), a proof-of-concept study demonstrating how high-performance\ncomputing (HPC) can enable millisecond-scale responsiveness in robotic control.\nWhile modern robots face increasing demands for reactivity in human--robot\nshared workspaces, onboard processors are constrained by size, power, and cost.\nOffloading to HPC offers massive parallelism for trajectory planning, but its\nfeasibility for real-time robotics remains uncertain due to network latency and\njitter. We evaluate SHARP in a stress-test scenario where a 7-DOF manipulator\nmust dodge high-speed foam projectiles. Using a parallelized multi-goal A*\nsearch implemented with MPI on both local and remote HPC clusters, the system\nachieves mean planning latencies of 22.9 ms (local) and 30.0 ms (remote, ~300\nkm away), with avoidance success rates of 84% and 88%, respectively. These\nresults show that when round-trip latency remains within the\ntens-of-milliseconds regime, HPC-side computation is no longer the bottleneck,\nenabling avoidance well below human reaction times. The SHARP results motivate\nhybrid control architectures: low-level reflexes remain onboard for safety,\nwhile bursty, high-throughput planning tasks are offloaded to HPC for\nscalability. By reporting per-stage timing and success rates, this study\nprovides a reproducible template for assessing real-time feasibility of\nHPC-driven robotics. Collectively, SHARP reframes HPC offloading as a viable\npathway toward dependable, reactive robots in dynamic environments.", "AI": {"tldr": "SHARP\u7814\u7a76\u8bc1\u660e\uff0c\u901a\u8fc7\u5c06\u673a\u5668\u4eba\u8f68\u8ff9\u89c4\u5212\u4efb\u52a1\u5378\u8f7d\u5230\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u96c6\u7fa4\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6beb\u79d2\u7ea7\u54cd\u5e94\uff0c\u4f7f7\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u80fd\u591f\u8eb2\u907f\u9ad8\u901f\u6ce1\u6cab\u5f39\u4e38\uff0c\u5e73\u5747\u89c4\u5212\u5ef6\u8fdf\u4f4e\u81f322.9-30.0\u6beb\u79d2\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u4eba\u5728\u4eba\u673a\u5171\u4eab\u5de5\u4f5c\u7a7a\u95f4\u4e2d\u5bf9\u53cd\u5e94\u6027\u8981\u6c42\u8d8a\u6765\u8d8a\u9ad8\uff0c\u4f46\u673a\u8f7d\u5904\u7406\u5668\u53d7\u9650\u4e8e\u5c3a\u5bf8\u3001\u529f\u7387\u548c\u6210\u672c\u3002HPC\u5378\u8f7d\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u5e76\u884c\u8ba1\u7b97\u80fd\u529b\uff0c\u4f46\u5176\u5728\u5b9e\u65f6\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u4ecd\u4e0d\u786e\u5b9a\u3002", "method": "\u4f7f\u7528MPI\u5728\u672c\u5730\u548c\u8fdc\u7a0bHPC\u96c6\u7fa4\u4e0a\u5b9e\u73b0\u5e76\u884c\u5316\u591a\u76ee\u6807A*\u641c\u7d22\u7b97\u6cd5\uff0c\u57287\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u8eb2\u907f\u9ad8\u901f\u6ce1\u6cab\u5f39\u4e38\u7684\u5e94\u529b\u6d4b\u8bd5\u573a\u666f\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u5e73\u5747\u89c4\u5212\u5ef6\u8fdf\uff1a\u672c\u573022.9\u6beb\u79d2\uff0c\u8fdc\u7a0b\uff08300\u516c\u91cc\u5916\uff0930.0\u6beb\u79d2\uff0c\u907f\u969c\u6210\u529f\u7387\u5206\u522b\u4e3a84%\u548c88%\u3002\u5f53\u5f80\u8fd4\u5ef6\u8fdf\u4fdd\u6301\u5728\u6570\u5341\u6beb\u79d2\u8303\u56f4\u5185\u65f6\uff0cHPC\u4fa7\u8ba1\u7b97\u4e0d\u518d\u662f\u74f6\u9888\u3002", "conclusion": "SHARP\u7ed3\u679c\u8868\u660eHPC\u5378\u8f7d\u662f\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u9760\u3001\u53cd\u5e94\u6027\u673a\u5668\u4eba\u7684\u53ef\u884c\u9014\u5f84\uff0c\u652f\u6301\u6df7\u5408\u63a7\u5236\u67b6\u6784\uff1a\u4f4e\u7ea7\u53cd\u5c04\u4fdd\u6301\u673a\u8f7d\u4ee5\u786e\u4fdd\u5b89\u5168\uff0c\u800c\u7a81\u53d1\u6027\u9ad8\u541e\u5410\u91cf\u89c4\u5212\u4efb\u52a1\u5378\u8f7d\u5230HPC\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2509.19824", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19824", "abs": "https://arxiv.org/abs/2509.19824", "authors": ["Sabin Diaconescu", "Florin Stoican", "Bogdan D. Ciubotaru", "Sorin Olaru"], "title": "Zonotope-Based Elastic Tube Model Predictive Control", "comment": null, "summary": "Tube-based Model Predictive Control (MPC) is a widely adopted robust control\nframework for constrained linear systems under additive disturbance. The paper\nis focused on reducing the numerical complexity associated with the tube\nparameterization, described as a sequence of elastically-scaled zonotopic sets.\nA new class of scaled-zonotope inclusion conditions is proposed, alleviating\nthe need for a priori specification of certain set-containment constraints and\nachieving significant reductions in complexity. A comprehensive complexity\nanalysis is provided for both the polyhedral and the zonotopic setting,\nillustrating the trade-off between an enlarged domain of attraction and the\nrequired computational effort. The proposed approach is validated through\nextensive numerical experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f29\u653ezonotope\u5305\u542b\u6761\u4ef6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u57fa\u4e8e\u7ba1\u9053\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u6570\u503c\u590d\u6742\u5ea6\uff0c\u901a\u8fc7\u5f39\u6027\u7f29\u653ezonotopic\u96c6\u5408\u7684\u53c2\u6570\u5316\u65b9\u6cd5\u51cf\u5c11\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "\u57fa\u4e8e\u7ba1\u9053\u7684MPC\u5728\u7ea6\u675f\u7ebf\u6027\u7cfb\u7edf\u63a7\u5236\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4f20\u7edf\u7684\u7ba1\u53c2\u6570\u5316\u65b9\u6cd5\u5b58\u5728\u8f83\u9ad8\u7684\u6570\u503c\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u9700\u8981\u7b80\u5316\u8ba1\u7b97\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u5e8f\u5217\u5316\u5f39\u6027\u7f29\u653ezonotopic\u96c6\u5408\u7684\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u63d0\u51fa\u65b0\u7684\u7f29\u653ezonotope\u5305\u542b\u6761\u4ef6\uff0c\u907f\u514d\u9884\u5148\u6307\u5b9a\u67d0\u4e9b\u96c6\u5408\u5305\u542b\u7ea6\u675f\u3002", "result": "\u901a\u8fc7\u590d\u6742\u6027\u5206\u6790\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5438\u5f15\u57df\u6269\u5927\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u964d\u4f4e\u4e86\u57fa\u4e8e\u7ba1\u9053MPC\u7684\u6570\u503c\u590d\u6742\u5ea6\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2509.19521", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19521", "abs": "https://arxiv.org/abs/2509.19521", "authors": ["Najeeb Ahmed Bhuiyan", "M. Nasimul Huq", "Sakib H. Chowdhury", "Rahul Mangharam"], "title": "A Bimanual Gesture Interface for ROS-Based Mobile Manipulators Using TinyML and Sensor Fusion", "comment": "12 pages, 11 figures", "summary": "Gesture-based control for mobile manipulators faces persistent challenges in\nreliability, efficiency, and intuitiveness. This paper presents a dual-hand\ngesture interface that integrates TinyML, spectral analysis, and sensor fusion\nwithin a ROS framework to address these limitations. The system uses left-hand\ntilt and finger flexion, captured using accelerometer and flex sensors, for\nmobile base navigation, while right-hand IMU signals are processed through\nspectral analysis and classified by a lightweight neural network. This pipeline\nenables TinyML-based gesture recognition to control a 7-DOF Kinova Gen3\nmanipulator. By supporting simultaneous navigation and manipulation, the\nframework improves efficiency and coordination compared to sequential methods.\nKey contributions include a bimanual control architecture, real-time low-power\ngesture recognition, robust multimodal sensor fusion, and a scalable ROS-based\nimplementation. The proposed approach advances Human-Robot Interaction (HRI)\nfor industrial automation, assistive robotics, and hazardous environments,\noffering a cost-effective, open-source solution with strong potential for\nreal-world deployment and further optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u624b\u673a\u52bf\u63a7\u5236\u7684\u79fb\u52a8\u673a\u68b0\u81c2\u7cfb\u7edf\uff0c\u901a\u8fc7\u96c6\u6210TinyML\u3001\u9891\u8c31\u5206\u6790\u548c\u4f20\u611f\u5668\u878d\u5408\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u540c\u65f6\u5bfc\u822a\u548c\u64cd\u4f5c\u529f\u80fd", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u624b\u52bf\u7684\u79fb\u52a8\u673a\u68b0\u81c2\u63a7\u5236\u5728\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u76f4\u89c2\u6027\u65b9\u9762\u7684\u6301\u7eed\u6311\u6218", "method": "\u91c7\u7528\u53cc\u624b\u673a\u52bf\u754c\u9762\uff0c\u5de6\u624b\u503e\u659c\u548c\u624b\u6307\u5f2f\u66f2\u7528\u4e8e\u79fb\u52a8\u57fa\u5ea7\u5bfc\u822a\uff0c\u53f3\u624bIMU\u4fe1\u53f7\u901a\u8fc7\u9891\u8c31\u5206\u6790\u548c\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u63a7\u52367\u81ea\u7531\u5ea6Kinova Gen3\u673a\u68b0\u81c2", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u652f\u6301\u540c\u65f6\u5bfc\u822a\u548c\u64cd\u4f5c\u7684\u6846\u67b6\uff0c\u76f8\u6bd4\u987a\u5e8f\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u534f\u8c03\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4eba\u673a\u4ea4\u4e92\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u3001\u8f85\u52a9\u673a\u5668\u4eba\u548c\u5371\u9669\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u3001\u5f00\u6e90\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u548c\u8fdb\u4e00\u6b65\u4f18\u5316\u7684\u5f3a\u5927\u6f5c\u529b"}}
{"id": "2509.19832", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19832", "abs": "https://arxiv.org/abs/2509.19832", "authors": ["Zicheng Huang", "Wangzhi Zhou", "Yuanqiu Mo"], "title": "An early termination strategy for the distributed biased min-consensus protocol under disturbances", "comment": "paper accepted to IEEE ICNSC 2025", "summary": "The distributed biased min-consensus (DBMC) protocol is an iterative scheme\nthat solves the shortest path problem asymptotically, requiring only local\ninformation exchange between neighboring nodes. By appropriately designing the\ngain function, prior work [1] proposed a DBMC-based system that ensures\nconvergence within a pre-specified time interval. However, this guarantee\nassumes the absence of disturbances. In this paper, we study the DBMC-based\nsystem under disturbances affecting the edge weights. We first establish\nrigorous error bounds on the resulting state estimates. Building on this\nanalysis, we then propose a practical early termination strategy to prevent\npotential singularities, specifically, unbounded gain, that may arise in the\npresence of disturbances, while still ensuring that the shortest paths are\ncorrectly identified.Simulations are performed to validate and illustrate the\ntheoretical results.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5b58\u5728\u8fb9\u6743\u91cd\u6270\u52a8\u60c5\u51b5\u4e0b\u7684\u5206\u5e03\u5f0f\u504f\u7f6e\u6700\u5c0f\u5171\u8bc6\uff08DBMC\uff09\u534f\u8bae\uff0c\u63d0\u51fa\u4e86\u8bef\u5dee\u754c\u9650\u5206\u6790\u548c\u5b9e\u7528\u7684\u63d0\u524d\u7ec8\u6b62\u7b56\u7565\u4ee5\u9632\u6b62\u6f5c\u5728\u5947\u5f02\u6027\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u63d0\u51fa\u4e86\u57fa\u4e8eDBMC\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u9884\u5b9a\u65f6\u95f4\u95f4\u9694\u5185\u786e\u4fdd\u6536\u655b\uff0c\u4f46\u8fd9\u4e00\u4fdd\u8bc1\u5047\u8bbe\u4e0d\u5b58\u5728\u6270\u52a8\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u5728\u8fb9\u6743\u91cd\u53d7\u5230\u6270\u52a8\u65f6DBMC\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u9996\u5148\u5efa\u7acb\u4e86\u72b6\u6001\u4f30\u8ba1\u7684\u4e25\u683c\u8bef\u5dee\u754c\u9650\uff0c\u7136\u540e\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u63d0\u524d\u7ec8\u6b62\u7b56\u7565\uff0c\u4ee5\u9632\u6b62\u5728\u5b58\u5728\u6270\u52a8\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u5947\u5f02\u6027\uff08\u5982\u65e0\u754c\u589e\u76ca\uff09\uff0c\u540c\u65f6\u786e\u4fdd\u6b63\u786e\u8bc6\u522b\u6700\u77ed\u8def\u5f84\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u548c\u8bf4\u660e\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5b58\u5728\u6270\u52a8\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u6709\u6548\u5de5\u4f5c\u3002", "conclusion": "\u672c\u6587\u4e3aDBMC\u7cfb\u7edf\u5728\u6270\u52a8\u73af\u5883\u4e0b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u786e\u4fdd\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6b63\u786e\u6027\u3002"}}
{"id": "2509.19623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19623", "abs": "https://arxiv.org/abs/2509.19623", "authors": ["Xutao Mao", "Tao Liu", "Hongying Zan"], "title": "SteinerSQL: Graph-Guided Mathematical Reasoning for Text-to-SQL Generation", "comment": "Accept in Non-archival EMNLP 2025 MathNLP", "summary": "Large Language Models (LLMs) struggle with complex Text-to-SQL queries that\ndemand both sophisticated mathematical reasoning and intricate schema\nnavigation. Existing methods often tackle these challenges in isolation,\ncreating a fractured reasoning process that compromises logical and structural\ncorrectness. To resolve this, we introduce SteinerSQL, a framework that unifies\nthese dual challenges into a single, graph-centric optimization problem.\nSteinerSQL operates in three stages: mathematical decomposition to identify\nrequired tables (terminals), optimal reasoning scaffold construction via a\nSteiner tree problem, and multi-level validation to ensure correctness. On the\nchallenging LogicCat and Spider2.0-Lite benchmarks, SteinerSQL establishes a\nnew state-of-the-art with 36.10% and 40.04% execution accuracy, respectively,\nusing Gemini-2.5-Pro. Beyond accuracy, SteinerSQL presents a new, unified\nparadigm for Text-to-SQL, paving the way for more robust and principled\nsolutions to complex reasoning tasks.", "AI": {"tldr": "SteinerSQL\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u590d\u6742\u7684Text-to-SQL\u67e5\u8be2\u4e2d\u7684\u6570\u5b66\u63a8\u7406\u548c\u6a21\u5f0f\u5bfc\u822a\u6311\u6218\u8f6c\u5316\u4e3a\u56fe\u4f18\u5316\u95ee\u9898\uff0c\u5728LogicCat\u548cSpider2.0-Lite\u57fa\u51c6\u4e0a\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b64\u7acb\u5904\u7406\u590d\u6742Text-to-SQL\u67e5\u8be2\u4e2d\u7684\u6570\u5b66\u63a8\u7406\u548c\u6a21\u5f0f\u5bfc\u822a\u6311\u6218\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u788e\u7247\u5316\uff0c\u5f71\u54cd\u903b\u8f91\u548c\u7ed3\u6784\u6b63\u786e\u6027\u3002", "method": "SteinerSQL\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a\u6570\u5b66\u5206\u89e3\u8bc6\u522b\u6240\u9700\u8868\u683c\uff08\u7ec8\u7aef\uff09\u3001\u901a\u8fc7Steiner\u6811\u95ee\u9898\u6784\u5efa\u6700\u4f18\u63a8\u7406\u652f\u67b6\u3001\u591a\u7ea7\u9a8c\u8bc1\u786e\u4fdd\u6b63\u786e\u6027\u3002", "result": "\u5728LogicCat\u548cSpider2.0-Lite\u57fa\u51c6\u4e0a\uff0c\u4f7f\u7528Gemini-2.5-Pro\u5206\u522b\u8fbe\u523036.10%\u548c40.04%\u7684\u6267\u884c\u51c6\u786e\u7387\uff0c\u521b\u4e0b\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "SteinerSQL\u4e3aText-to-SQL\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u7edf\u4e00\u8303\u5f0f\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u5f00\u8f9f\u4e86\u66f4\u7a33\u5065\u548c\u539f\u5219\u6027\u7684\u89e3\u51b3\u65b9\u6848\u8def\u5f84\u3002"}}
{"id": "2509.19522", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19522", "abs": "https://arxiv.org/abs/2509.19522", "authors": ["Fabio Coelho", "Joao Victor T. Borges", "Paulo Padrao", "Jose Fuentes", "Ramon R. Costa", "Liu Hsu", "Leonardo Bobadilla"], "title": "Bioinspired SLAM Approach for Unmanned Surface Vehicle", "comment": null, "summary": "This paper presents OpenRatSLAM2, a new version of OpenRatSLAM - a\nbioinspired SLAM framework based on computational models of the rodent\nhippocampus. OpenRatSLAM2 delivers low-computation-cost visual-inertial based\nSLAM, suitable for GPS-denied environments. Our contributions include a\nROS2-based architecture, experimental results on new waterway datasets, and\ninsights into system parameter tuning. This work represents the first known\napplication of RatSLAM on USVs. The estimated trajectory was compared with\nground truth data using the Hausdorff distance. The results show that the\nalgorithm can generate a semimetric map with an error margin acceptable for\nmost robotic applications.", "AI": {"tldr": "OpenRatSLAM2\u662f\u4e00\u4e2a\u57fa\u4e8e\u556e\u9f7f\u52a8\u7269\u6d77\u9a6c\u4f53\u8ba1\u7b97\u6a21\u578b\u7684\u751f\u7269\u542f\u53d1\u5f0fSLAM\u6846\u67b6\u65b0\u7248\u672c\uff0c\u63d0\u4f9b\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u89c6\u89c9-\u60ef\u6027SLAM\uff0c\u9002\u7528\u4e8eGPS\u62d2\u6b62\u73af\u5883\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u65e0\u4eba\u6c34\u9762\u8247\uff08USVs\uff09\u7684\u4f4e\u6210\u672cSLAM\u7cfb\u7edf\uff0c\u89e3\u51b3GPS\u62d2\u6b62\u73af\u5883\u4e0b\u7684\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u95ee\u9898\u3002", "method": "\u91c7\u7528ROS2\u67b6\u6784\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u60ef\u6027\u4f20\u611f\u5668\u6570\u636e\uff0c\u57fa\u4e8e\u751f\u7269\u542f\u53d1\u5f0f\u7b97\u6cd5\u8fdb\u884cSLAM\uff0c\u4f7f\u7528Hausdorff\u8ddd\u79bb\u4e0e\u5730\u9762\u771f\u503c\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u9a8c\u8bc1\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u751f\u6210\u534a\u5ea6\u91cf\u5730\u56fe\uff0c\u8bef\u5dee\u8303\u56f4\u5728\u5927\u591a\u6570\u673a\u5668\u4eba\u5e94\u7528\u53ef\u63a5\u53d7\u8303\u56f4\u5185\uff0c\u662fRatSLAM\u5728USV\u4e0a\u7684\u9996\u6b21\u5df2\u77e5\u5e94\u7528\u3002", "conclusion": "OpenRatSLAM2\u5728USV\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\uff0c\u4e3aGPS\u62d2\u6b62\u73af\u5883\u4e0b\u7684\u673a\u5668\u4eba\u5bfc\u822a\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19855", "categories": ["eess.SY", "cs.AI", "cs.NI", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19855", "abs": "https://arxiv.org/abs/2509.19855", "authors": ["Jiewei Chen", "Xiumei Deng", "Zehui Xiong", "Shaoyong Guo", "Xuesong Qiu", "Ping Wang", "Dusit Niyato"], "title": "CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks", "comment": "Submitted to IEEE for review", "summary": "The increasing demand for intelligent mobile applications has made\nmulti-agent collaboration with Transformer-based large language models (LLMs)\nessential in mobile edge computing (MEC) networks. However, training LLMs in\nsuch environments remains challenging due to heavy computation, high end-to-end\nlatency, and limited model generalization. We introduce CollaPipe, a hybrid\ndistributed learning framework that integrates collaborative pipeline\nparallelism with federated aggregation to support self-evolving intelligent\nnetworks. In CollaPipe, the encoder part is adaptively partitioned into\nvariable-sized segments and deployed across mobile devices for\npipeline-parallel training, while the decoder is deployed on edge servers to\nhandle generative tasks. Then we perform global model update via federated\naggregation. To enhance training efficiency, we formulate a joint optimization\nproblem that adaptively allocates model segments, micro-batches, bandwidth, and\ntransmission power. We derive and use a closed-form convergence bound to design\nan Dynamic Segment Scheduling and Resource Allocation (DSSDA) algorithm based\non Lyapunov optimization, ensuring system stability under long-term\nconstraints. Extensive experiments on downstream tasks with Transformer and\nBERT models show that CollaPipe improves computation efficiency by up to\n15.09%, reduces end-to-end latency by at least 48.98%, and cuts single device\nmemory usage by more than half, enabling online learning in heterogeneous and\ndynamic communication environments.", "AI": {"tldr": "CollaPipe\u662f\u4e00\u4e2a\u6df7\u5408\u5206\u5e03\u5f0f\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u534f\u4f5c\u6d41\u6c34\u7ebf\u5e76\u884c\u548c\u8054\u90a6\u805a\u5408\uff0c\u7528\u4e8e\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\u4e2d\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "motivation": "\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\u4e2d\u667a\u80fd\u5e94\u7528\u9700\u6c42\u589e\u957f\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u9762\u4e34\u8ba1\u7b97\u91cf\u5927\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u9ad8\u548c\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faCollaPipe\u6846\u67b6\uff1a\u7f16\u7801\u5668\u81ea\u9002\u5e94\u5206\u533a\u90e8\u7f72\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u8fdb\u884c\u6d41\u6c34\u7ebf\u5e76\u884c\u8bad\u7ec3\uff0c\u89e3\u7801\u5668\u90e8\u7f72\u5728\u8fb9\u7f18\u670d\u52a1\u5668\u5904\u7406\u751f\u6210\u4efb\u52a1\uff0c\u901a\u8fc7\u8054\u90a6\u805a\u5408\u8fdb\u884c\u5168\u5c40\u6a21\u578b\u66f4\u65b0\u3002\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u674e\u96c5\u666e\u8bfa\u592b\u4f18\u5316\u7684\u52a8\u6001\u5206\u6bb5\u8c03\u5ea6\u548c\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793aCollaPipe\u8ba1\u7b97\u6548\u7387\u63d0\u534715.09%\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e48.98%\uff0c\u5355\u8bbe\u5907\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u4e00\u534a\u4ee5\u4e0a\uff0c\u652f\u6301\u5f02\u6784\u52a8\u6001\u901a\u4fe1\u73af\u5883\u4e2d\u7684\u5728\u7ebf\u5b66\u4e60\u3002", "conclusion": "CollaPipe\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8\u8fb9\u7f18\u73af\u5883\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u5ef6\u8fdf\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u3002"}}
{"id": "2509.19681", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19681", "abs": "https://arxiv.org/abs/2509.19681", "authors": ["Anisha Garg", "Engin Tekin", "Yash More", "David Bick", "Nishit Neema", "Ganesh Venkatesh"], "title": "Calibrated Reasoning: An Explanatory Verifier for Dynamic and Efficient Problem-Solving", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop: Efficient Reasoning", "summary": "Advanced test-time computing strategies are essential for scaling reasoning\nmodels, but their effectiveness is capped by the models' poor self-evaluation.\nWe propose a pairwise Explanatory Verifier, trained via reinforcement learning\n(GRPO), that produces calibrated confidence scores and associated natural\nlanguage reasoning for generated solutions. Our verifier improves the accuracy\nand efficiency of test-time strategies like best-of-n and self-reflection.\nCrucially, it excels at identifying challenging failure modes, such as when\nboth candidate solutions are identically incorrect, succeeding where standard\nmethods like majority voting fail.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6210\u5bf9\u89e3\u91ca\u9a8c\u8bc1\u5668\uff0c\u901a\u8fc7\u751f\u6210\u6821\u51c6\u7684\u7f6e\u4fe1\u5206\u6570\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6765\u6539\u5584\u63a8\u7406\u6a21\u578b\u7684\u81ea\u8bc4\u4f30\u80fd\u529b\uff0c\u4ece\u800c\u63d0\u9ad8\u6d4b\u8bd5\u65f6\u7b56\u7565\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u63a8\u7406\u6a21\u578b\u7684\u81ea\u8bc4\u4f30\u80fd\u529b\u8f83\u5dee\uff0c\u9650\u5236\u4e86\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u9700\u8981\u66f4\u597d\u7684\u9a8c\u8bc1\u673a\u5236\u6765\u8bc6\u522b\u9519\u8bef\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08GRPO\uff09\u8bad\u7ec3\u6210\u5bf9\u89e3\u91ca\u9a8c\u8bc1\u5668\uff0c\u751f\u6210\u6821\u51c6\u7684\u7f6e\u4fe1\u5206\u6570\u548c\u76f8\u5173\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u3002", "result": "\u9a8c\u8bc1\u5668\u663e\u8457\u63d0\u9ad8\u4e86best-of-n\u548c\u81ea\u53cd\u601d\u7b49\u6d4b\u8bd5\u65f6\u7b56\u7565\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u8bc6\u522b\u4e24\u4e2a\u5019\u9009\u89e3\u90fd\u9519\u8bef\u7b49\u56f0\u96be\u5931\u8d25\u6a21\u5f0f\u65f6\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u65b9\u6cd5\uff08\u5982\u591a\u6570\u6295\u7968\uff09\u5931\u8d25\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u6210\u529f\u8bc6\u522b\u9519\u8bef\uff0c\u4e3a\u63a8\u7406\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2509.19525", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19525", "abs": "https://arxiv.org/abs/2509.19525", "authors": ["James Avtges", "Jake Ketchum", "Millicent Schlafly", "Helena Young", "Taekyoung Kim", "Allison Pinosky", "Ryan L. Truby", "Todd D. Murphey"], "title": "Real-Time Reinforcement Learning for Dynamic Tasks with a Parallel Soft Robot", "comment": "Published at IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025", "summary": "Closed-loop control remains an open challenge in soft robotics. The nonlinear\nresponses of soft actuators under dynamic loading conditions limit the use of\nanalytic models for soft robot control. Traditional methods of controlling soft\nrobots underutilize their configuration spaces to avoid nonlinearity,\nhysteresis, large deformations, and the risk of actuator damage. Furthermore,\nepisodic data-driven control approaches such as reinforcement learning (RL) are\ntraditionally limited by sample efficiency and inconsistency across\ninitializations. In this work, we demonstrate RL for reliably learning control\npolicies for dynamic balancing tasks in real-time single-shot hardware\ndeployments. We use a deformable Stewart platform constructed using parallel,\n3D-printed soft actuators based on motorized handed shearing auxetic (HSA)\nstructures. By introducing a curriculum learning approach based on expanding\nneighborhoods of a known equilibrium, we achieve reliable single-deployment\nbalancing at arbitrary coordinates. In addition to benchmarking the performance\nof model-based and model-free methods, we demonstrate that in a single\ndeployment, Maximum Diffusion RL is capable of learning dynamic balancing after\nhalf of the actuators are effectively disabled, by inducing buckling and by\nbreaking actuators with bolt cutters. Training occurs with no prior data, in as\nfast as 15 minutes, with performance nearly identical to the fully-intact\nplatform. Single-shot learning on hardware facilitates soft robotic systems\nreliably learning in the real world and will enable more diverse and capable\nsoft robots.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5355\u6b21\u90e8\u7f72\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u8f6f\u673a\u5668\u4eba\u52a8\u6001\u5e73\u8861\u4efb\u52a1\uff0c\u80fd\u591f\u572815\u5206\u949f\u5185\u5b8c\u6210\u8bad\u7ec3\uff0c\u5e76\u5c55\u793a\u4e86\u5bf9\u90e8\u5206\u6267\u884c\u5668\u5931\u6548\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u8f6f\u673a\u5668\u4eba\u7684\u975e\u7ebf\u6027\u54cd\u5e94\u548c\u52a8\u6001\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u7684\u63a7\u5236\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u975e\u7ebf\u6027\u3001\u8fdf\u6ede\u548c\u5927\u53d8\u5f62\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u548c\u521d\u59cb\u5316\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u7535\u673a\u9a71\u52a8\u624b\u6027\u526a\u5207\u62c9\u80c0\u7ed3\u6784\u76843D\u6253\u5370\u8f6f\u6267\u884c\u5668\u6784\u5efa\u53d8\u5f62Stewart\u5e73\u53f0\uff0c\u91c7\u7528\u57fa\u4e8e\u5df2\u77e5\u5e73\u8861\u70b9\u6269\u5c55\u90bb\u57df\u7684\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e94\u7528\u6700\u5927\u6269\u6563\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u5728\u5355\u6b21\u90e8\u7f72\u4e2d\u5b9e\u73b0\u4e86\u4efb\u610f\u5750\u6807\u7684\u52a8\u6001\u5e73\u8861\uff0c\u5373\u4f7f\u4e00\u534a\u6267\u884c\u5668\u88ab\u7834\u574f\uff08\u901a\u8fc7\u5f2f\u66f2\u548c\u5207\u5272\uff09\u540e\u4ecd\u80fd\u5b66\u4e60\u5e73\u8861\u63a7\u5236\uff0c\u8bad\u7ec3\u65f6\u95f4\u4ec5\u970015\u5206\u949f\uff0c\u6027\u80fd\u4e0e\u5b8c\u6574\u5e73\u53f0\u51e0\u4e4e\u76f8\u540c\u3002", "conclusion": "\u5355\u6b21\u786c\u4ef6\u5b66\u4e60\u4f7f\u8f6f\u673a\u5668\u4eba\u7cfb\u7edf\u80fd\u591f\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u53ef\u9760\u5b66\u4e60\uff0c\u5c06\u4fc3\u8fdb\u66f4\u591a\u6837\u5316\u548c\u80fd\u529b\u66f4\u5f3a\u7684\u8f6f\u673a\u5668\u4eba\u53d1\u5c55\u3002"}}
{"id": "2509.19859", "categories": ["eess.SY", "cs.FL", "cs.SC", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19859", "abs": "https://arxiv.org/abs/2509.19859", "authors": ["Ratnangshu Das", "Shubham Sawarkar", "Pushpak Jagtap"], "title": "Scalable and Approximation-free Symbolic Control for Unknown Euler-Lagrange Systems", "comment": null, "summary": "We propose a novel symbolic control framework for enforcing temporal logic\nspecifications in Euler-Lagrange systems that addresses the key limitations of\ntraditional abstraction-based approaches. Unlike existing methods that require\nexact system models and provide guarantees only at discrete sampling instants,\nour approach relies only on bounds on system parameters and input constraints,\nand ensures correctness for the full continuous-time trajectory. The framework\ncombines scalable abstraction of a simplified virtual system with a\nclosed-form, model-free controller that guarantees trajectories satisfy the\noriginal specification while respecting input bounds and remaining robust to\nunknown but bounded disturbances. We provide feasibility conditions for the\nconstruction of confinement regions and analyze the trade-off between\nefficiency and conservatism. Case studies on pendulum dynamics, a two-link\nmanipulator, and multi-agent systems, including hardware experiments,\ndemonstrate that the proposed approach ensures both correctness and safety\nwhile significantly reducing computational time and memory requirements. These\nresults highlight its scalability and practicality for real-world robotic\nsystems where precise models are unavailable and continuous-time guarantees are\nessential.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7b26\u53f7\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6b27\u62c9-\u62c9\u683c\u6717\u65e5\u7cfb\u7edf\u4e2d\u5f3a\u5236\u6267\u884c\u65f6\u5e8f\u903b\u8f91\u89c4\u8303\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u57fa\u4e8e\u62bd\u8c61\u65b9\u6cd5\u7684\u5173\u952e\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u7cbe\u786e\u7684\u7cfb\u7edf\u6a21\u578b\u4e14\u4ec5\u5728\u79bb\u6563\u91c7\u6837\u65f6\u523b\u63d0\u4f9b\u4fdd\u8bc1\uff0c\u800c\u5b9e\u9645\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7cbe\u786e\u6a21\u578b\u4e0d\u53ef\u7528\u4e14\u9700\u8981\u8fde\u7eed\u65f6\u95f4\u4fdd\u8bc1\u3002", "method": "\u7ed3\u5408\u7b80\u5316\u865a\u62df\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u62bd\u8c61\u4e0e\u95ed\u5f0f\u3001\u65e0\u6a21\u578b\u63a7\u5236\u5668\uff0c\u4ec5\u4f9d\u8d56\u7cfb\u7edf\u53c2\u6570\u8fb9\u754c\u548c\u8f93\u5165\u7ea6\u675f\uff0c\u786e\u4fdd\u5168\u8fde\u7eed\u65f6\u95f4\u8f68\u8ff9\u7684\u6b63\u786e\u6027\u3002", "result": "\u5728\u6446\u52a8\u529b\u5b66\u3001\u4e24\u8fde\u6746\u673a\u68b0\u81c2\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\uff08\u5305\u62ec\u786c\u4ef6\u5b9e\u9a8c\uff09\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u786e\u4fdd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u548c\u5185\u5b58\u9700\u6c42\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7cbe\u786e\u6a21\u578b\u4e0d\u53ef\u7528\u4e14\u9700\u8981\u8fde\u7eed\u65f6\u95f4\u4fdd\u8bc1\u7684\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u7cfb\u7edf\u3002"}}
{"id": "2509.19736", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19736", "abs": "https://arxiv.org/abs/2509.19736", "authors": ["Cheng Qian", "Zuxin Liu", "Akshara Prabhakar", "Jielin Qiu", "Zhiwei Liu", "Haolin Chen", "Shirley Kokane", "Heng Ji", "Weiran Yao", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "UserRL: Training Interactive User-Centric Agent via Reinforcement Learning", "comment": "28 Pages, 15 Figures, 6 Tables; Built upon latest UserBench release:\n  arXiv:2507.22034", "summary": "Reinforcement learning (RL) has shown promise in training agentic models that\nmove beyond static benchmarks to engage in dynamic, multi-turn interactions.\nYet, the ultimate value of such agents lies in their ability to assist users, a\nsetting where diversity and dynamics of user interaction pose challenges. In\nthis work, we propose UserRL, a unified framework for training and evaluating\nuser-centric abilities through standardized gym environments paired with\nsimulated users. We systematically vary turn-level reward assignment and\ntrajectory-level score calculation to analyze how different formulations affect\nlearning under the GRPO algorithm. Our experiments across Qwen3 models reveal\nthree key findings: (i) SFT cold start is critical for unlocking initial\ninteraction ability and enabling sustained RL improvements; (ii) deliberate\ntrajectory scoring yields more efficient and effective multi-turn interactions;\nand (iii) while stronger simulated users (e.g., GPT-4o) facilitates training,\nopen-source simulators (e.g., Qwen3-32B) remain a cost-effective and\ntransferable option. Together, these results highlight that careful design of\nreward shaping and user simulation choice is as crucial as model scale, and\nestablish UserRL as a practical pathway for developing robust user-centric\nagentic models. All codes and data are public for future research.", "AI": {"tldr": "UserRL\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u51c6\u5316gym\u73af\u5883\u548c\u6a21\u62df\u7528\u6237\u6765\u8bad\u7ec3\u548c\u8bc4\u4f30\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u667a\u80fd\u4f53\u80fd\u529b\uff0c\u7814\u7a76\u53d1\u73b0\u5956\u52b1\u5851\u9020\u548c\u7528\u6237\u6a21\u62df\u9009\u62e9\u5bf9\u5f00\u53d1\u7a33\u5065\u7684\u7528\u6237\u4e2d\u5fc3\u667a\u80fd\u4f53\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u8bad\u7ec3\u667a\u80fd\u4f53\u6a21\u578b\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u8fd9\u7c7b\u667a\u80fd\u4f53\u7684\u6700\u7ec8\u4ef7\u503c\u5728\u4e8e\u534f\u52a9\u7528\u6237\u7684\u80fd\u529b\uff0c\u800c\u7528\u6237\u4ea4\u4e92\u7684\u591a\u6837\u6027\u548c\u52a8\u6001\u6027\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51faUserRL\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u5730\u53d8\u5316\u56de\u5408\u7ea7\u5956\u52b1\u5206\u914d\u548c\u8f68\u8ff9\u7ea7\u5206\u6570\u8ba1\u7b97\uff0c\u5206\u6790\u4e0d\u540c\u516c\u5f0f\u5728GRPO\u7b97\u6cd5\u4e0b\u5bf9\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u5728Qwen3\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u4e09\u4e2a\u5173\u952e\u53d1\u73b0\uff1a(i)SFT\u51b7\u542f\u52a8\u5bf9\u89e3\u9501\u521d\u59cb\u4ea4\u4e92\u80fd\u529b\u548c\u5b9e\u73b0\u6301\u7eedRL\u6539\u8fdb\u81f3\u5173\u91cd\u8981\uff1b(ii)\u6709\u610f\u7684\u8f68\u8ff9\u8bc4\u5206\u80fd\u4ea7\u751f\u66f4\u9ad8\u6548\u7684\u591a\u8f6e\u4ea4\u4e92\uff1b(iii)\u867d\u7136\u66f4\u5f3a\u7684\u6a21\u62df\u7528\u6237\u6709\u52a9\u4e8e\u8bad\u7ec3\uff0c\u4f46\u5f00\u6e90\u6a21\u62df\u5668\u662f\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u53ef\u8fc1\u79fb\u7684\u9009\u62e9\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u5956\u52b1\u5851\u9020\u548c\u7528\u6237\u6a21\u62df\u9009\u62e9\u4e0e\u6a21\u578b\u89c4\u6a21\u540c\u7b49\u91cd\u8981\uff0cUserRL\u4e3a\u5f00\u53d1\u7a33\u5065\u7684\u7528\u6237\u4e2d\u5fc3\u667a\u80fd\u4f53\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2509.19541", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19541", "abs": "https://arxiv.org/abs/2509.19541", "authors": ["Xuan Cao", "Yuxin Wu", "Michael L. Whittaker"], "title": "Autonomous Elemental Characterization Enabled by a Low Cost Robotic Platform Built Upon a Generalized Software Architecture", "comment": null, "summary": "Despite the rapidly growing applications of robots in industry, the use of\nrobots to automate tasks in scientific laboratories is less prolific due to\nlack of generalized methodologies and high cost of hardware. This paper focuses\non the automation of characterization tasks necessary for reducing cost while\nmaintaining generalization, and proposes a software architecture for building\nrobotic systems in scientific laboratory environment. A dual-layer (Socket.IO\nand ROS) action server design is the basic building block, which facilitates\nthe implementation of a web-based front end for user-friendly operations and\nthe use of ROS Behavior Tree for convenient task planning and execution. A\nrobotic platform for automating mineral and material sample characterization is\nbuilt upon the architecture, with an open source, low-cost three-axis computer\nnumerical control gantry system serving as the main robot. A handheld laser\ninduced breakdown spectroscopy (LIBS) analyzer is integrated with a 3D printed\nadapter, enabling automated 2D chemical mapping. We demonstrate the utility of\nautomated chemical mapping by scanning of the surface of a spodumene-bearing\npegmatite core sample with a 1071-point dense hyperspectral map acquired at a\nrate of 1520 bits per second. Automated LIBS scanning enables controlled\nchemical quantification in the laboratory that complements field-based\nmeasurements acquired with the same handheld device, linking resource\nexploration and processing steps in the supply chain for lithium-based battery\nmaterials.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u73af\u5883\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u8f6f\u4ef6\u67b6\u6784\uff0c\u901a\u8fc7\u53cc\u5c42\u7684Socket.IO\u548cROS\u52a8\u4f5c\u670d\u52a1\u5668\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8eWeb\u7684\u524d\u7aef\u7528\u6237\u754c\u9762\u548cROS\u884c\u4e3a\u6811\u7684\u4efb\u52a1\u89c4\u5212\u6267\u884c\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u7528\u4e8e\u77ff\u7269\u6750\u6599\u6837\u54c1\u8868\u5f81\u7684\u81ea\u52a8\u5316\u673a\u5668\u4eba\u5e73\u53f0\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u4eba\u5728\u5de5\u4e1a\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5728\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u4e2d\u7684\u81ea\u52a8\u5316\u4efb\u52a1\u5e94\u7528\u8f83\u5c11\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u901a\u7528\u65b9\u6cd5\u548c\u786c\u4ef6\u6210\u672c\u9ad8\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u964d\u4f4e\u6210\u672c\u7684\u901a\u7528\u81ea\u52a8\u5316\u8868\u5f81\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u7684Socket.IO\u548cROS\u52a8\u4f5c\u670d\u52a1\u5668\u67b6\u6784\uff0c\u7ed3\u5408\u57fa\u4e8eWeb\u7684\u524d\u7aef\u754c\u9762\u548cROS\u884c\u4e3a\u6811\u8fdb\u884c\u4efb\u52a1\u89c4\u5212\u3002\u6784\u5efa\u4e86\u4e00\u4e2a\u5f00\u6e90\u4f4e\u6210\u672c\u7684\u4e09\u8f74CNC\u9f99\u95e8\u7cfb\u7edf\u4f5c\u4e3a\u4e3b\u8981\u673a\u5668\u4eba\uff0c\u96c6\u6210\u624b\u6301LIBS\u5206\u6790\u4eea\u8fdb\u884c\u81ea\u52a8\u53162D\u5316\u5b66\u6620\u5c04\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u542b\u9502\u8f89\u77f3\u4f1f\u6676\u5ca9\u5ca9\u5fc3\u6837\u54c1\u8868\u9762\u76841071\u70b9\u9ad8\u5149\u8c31\u6620\u5c04\uff0c\u91c7\u96c6\u901f\u7387\u4e3a1520\u6bd4\u7279/\u79d2\uff0c\u8bc1\u660e\u4e86\u81ea\u52a8\u5316LIBS\u626b\u63cf\u5728\u5b9e\u9a8c\u5ba4\u4e2d\u8fdb\u884c\u53d7\u63a7\u5316\u5b66\u91cf\u5316\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u81ea\u52a8\u5316LIBS\u626b\u63cf\u80fd\u591f\u8865\u5145\u73b0\u573a\u6d4b\u91cf\uff0c\u8fde\u63a5\u9502\u57fa\u7535\u6c60\u6750\u6599\u4f9b\u5e94\u94fe\u4e2d\u7684\u8d44\u6e90\u52d8\u63a2\u548c\u52a0\u5de5\u6b65\u9aa4\uff0c\u4e3a\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u901a\u7528\u7684\u673a\u5668\u4eba\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19869", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.19869", "abs": "https://arxiv.org/abs/2509.19869", "authors": ["Teruki Kato", "Ryotaro Shima", "Kenji Kashima"], "title": "Modeling and Control of Deep Sign-Definite Dynamics with Application to Hybrid Powertrain Control", "comment": "Submitted to Automatica", "summary": "Deep learning is increasingly used for complex, large-scale systems where\nfirst-principles modeling is difficult. However, standard deep learning models\noften fail to enforce physical structure or preserve convexity in downstream\ncontrol, leading to physically inconsistent predictions and discontinuous\ninputs owing to nonconvexity. We introduce sign constraints--sign restrictions\non Jacobian entries--that unify monotonicity, positivity, and\nsign-definiteness; additionally, we develop model-construction methods that\nenforce them, together with a control-synthesis procedure. In particular, we\ndesign exactly linearizable deep models satisfying these constraints and\nformulate model predictive control as a convex quadratic program, which yields\na unique optimizer and a Lipschitz continuous control law. On a two-tank system\nand a hybrid powertrain, the proposed approach improves prediction accuracy and\nproduces smoother control inputs than existing methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u7b26\u53f7\u7ea6\u675f\u6765\u786e\u4fdd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7269\u7406\u4e00\u81f4\u6027\u548c\u51f8\u6027\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u6539\u8fdb\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u9884\u6d4b\u7cbe\u5ea6\u548c\u63a7\u5236\u8f93\u5165\u5e73\u6ed1\u6027\u3002", "motivation": "\u6807\u51c6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u590d\u6742\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u5f80\u5f80\u65e0\u6cd5\u5f3a\u5236\u6267\u884c\u7269\u7406\u7ed3\u6784\u6216\u4fdd\u6301\u4e0b\u6e38\u63a7\u5236\u7684\u51f8\u6027\uff0c\u5bfc\u81f4\u7269\u7406\u4e0d\u4e00\u81f4\u7684\u9884\u6d4b\u548c\u975e\u51f8\u6027\u5f15\u8d77\u7684\u4e0d\u8fde\u7eed\u8f93\u5165\u3002", "method": "\u5f15\u5165\u7b26\u53f7\u7ea6\u675f\uff08Jacobian\u77e9\u9635\u5143\u7d20\u7684\u7b26\u53f7\u9650\u5236\uff09\uff0c\u5f00\u53d1\u4e86\u5f3a\u5236\u6267\u884c\u8fd9\u4e9b\u7ea6\u675f\u7684\u6a21\u578b\u6784\u5efa\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6ee1\u8db3\u7ea6\u675f\u7684\u7cbe\u786e\u7ebf\u6027\u5316\u6df1\u5ea6\u6a21\u578b\uff0c\u5c06\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u8868\u8ff0\u4e3a\u51f8\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\u3002", "result": "\u5728\u4e24\u6c34\u7bb1\u7cfb\u7edf\u548c\u6df7\u5408\u52a8\u529b\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u5e76\u4ea7\u751f\u4e86\u66f4\u5e73\u6ed1\u7684\u63a7\u5236\u8f93\u5165\u3002", "conclusion": "\u7b26\u53f7\u7ea6\u675f\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u7edf\u4e00\u5355\u8c03\u6027\u3001\u6b63\u6027\u548c\u7b26\u53f7\u786e\u5b9a\u6027\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u5728\u7269\u7406\u7cfb\u7edf\u63a7\u5236\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8df5\u4f18\u52bf\u3002"}}
{"id": "2509.19762", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19762", "abs": "https://arxiv.org/abs/2509.19762", "authors": ["Yuanxin Wang", "Pawel Filipczuk", "Anisha Garg", "Amaan Dhada", "Mohammad Hassanpour", "David Bick", "Ganesh Venkatesh"], "title": "The Conductor and the Engine: A Path Towards Co-Designed Reasoning", "comment": null, "summary": "Modern LLM reasoning relies on extensive test-time computation, driven by\ninternal model training and external agentic orchestration. However, this\nsynergy is often inefficient, as model verbosity and poor instruction following\nlead to wasted compute. We analyze this capability-cost trade-off and introduce\nan optimized reasoning workflow (\\cepo) that empowers smaller open-source\nmodels to outperform models multiple times their size. We will open-source this\nworkflow to enable further research. Our work demonstrates a clear path toward\nco-designing orchestration frameworks with the underlying model capabilities to\nunlock powerful reasoning in small-to-medium sized models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u63a8\u7406\u5de5\u4f5c\u6d41\u7a0b\uff08cepo\uff09\uff0c\u901a\u8fc7\u51cf\u5c11\u6a21\u578b\u5197\u4f59\u548c\u6539\u5584\u6307\u4ee4\u9075\u5faa\uff0c\u4f7f\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\u80fd\u591f\u8d85\u8d8a\u89c4\u6a21\u66f4\u5927\u7684\u6a21\u578b\u3002", "motivation": "\u73b0\u4ee3LLM\u63a8\u7406\u4f9d\u8d56\u4e8e\u5927\u91cf\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\uff0c\u4f46\u6a21\u578b\u5197\u4f59\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u5dee\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u4f18\u5316\u80fd\u529b\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u5f15\u5165cepo\u4f18\u5316\u63a8\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u7f16\u6392\u6846\u67b6\u4e0e\u5e95\u5c42\u6a21\u578b\u80fd\u529b\uff0c\u51cf\u5c11\u6a21\u578b\u5197\u4f59\u548c\u6539\u5584\u6307\u4ee4\u9075\u5faa\u3002", "result": "\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\u80fd\u591f\u8d85\u8d8a\u89c4\u6a21\u66f4\u5927\u7684\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5728\u4e2d\u5c0f\u578b\u6a21\u578b\u4e2d\u5b9e\u73b0\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u7684\u6e05\u6670\u8def\u5f84\u3002", "conclusion": "\u5de5\u4f5c\u6d41\u7a0b\u5c06\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u534f\u540c\u8bbe\u8ba1\u7f16\u6392\u6846\u67b6\u4e0e\u6a21\u578b\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.19545", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19545", "abs": "https://arxiv.org/abs/2509.19545", "authors": ["Min Dai", "Aaron D. Ames"], "title": "RoMoCo: Robotic Motion Control Toolbox for Reduced-Order Model-Based Locomotion on Bipedal and Humanoid Robots", "comment": null, "summary": "We present RoMoCo, an open-source C++ toolbox for the synthesis and\nevaluation of reduced-order model-based planners and whole-body controllers for\nbipedal and humanoid robots. RoMoCo's modular architecture unifies\nstate-of-the-art planners and whole-body locomotion controllers under a\nconsistent API, enabling rapid prototyping and reproducible benchmarking. By\nleveraging reduced-order models for platform-agnostic gait generation, RoMoCo\nenables flexible controller design across diverse robots. We demonstrate its\nversatility and performance through extensive simulations on the Cassie,\nUnitree H1, and G1 robots, and validate its real-world efficacy with hardware\nexperiments on the Cassie and G1 humanoids.", "AI": {"tldr": "RoMoCo\u662f\u4e00\u4e2a\u5f00\u6e90\u7684C++\u5de5\u5177\u7bb1\uff0c\u7528\u4e8e\u5408\u6210\u548c\u8bc4\u4f30\u57fa\u4e8e\u964d\u9636\u6a21\u578b\u7684\u8db3\u5f0f\u548c\u4eba\u5f62\u673a\u5668\u4eba\u89c4\u5212\u5668\u548c\u5168\u8eab\u63a7\u5236\u5668\u3002", "motivation": "\u7edf\u4e00\u6700\u5148\u8fdb\u7684\u89c4\u5212\u5668\u548c\u5168\u8eab\u8fd0\u52a8\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u652f\u6301\u8de8\u4e0d\u540c\u673a\u5668\u4eba\u7684\u7075\u6d3b\u63a7\u5236\u5668\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5229\u7528\u964d\u9636\u6a21\u578b\u8fdb\u884c\u5e73\u53f0\u65e0\u5173\u7684\u6b65\u6001\u751f\u6210\uff0c\u63d0\u4f9b\u4e00\u81f4\u7684API\u63a5\u53e3\u3002", "result": "\u5728Cassie\u3001Unitree H1\u548cG1\u673a\u5668\u4eba\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u4eff\u771f\u9a8c\u8bc1\uff0c\u5e76\u5728Cassie\u548cG1\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u8fdb\u884c\u4e86\u786c\u4ef6\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "RoMoCo\u5c55\u793a\u4e86\u5176\u591a\u529f\u80fd\u6027\u548c\u9ad8\u6027\u80fd\uff0c\u662f\u4e00\u4e2a\u6709\u6548\u7684\u673a\u5668\u4eba\u8fd0\u52a8\u63a7\u5236\u5de5\u5177\u7bb1\u3002"}}
{"id": "2509.19970", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.19970", "abs": "https://arxiv.org/abs/2509.19970", "authors": ["Andr\u00e9 Fonte", "Pedro Santos", "Paulo Oliveira"], "title": "Control and Navigation of a 2-D Electric Rocket", "comment": null, "summary": "This work addresses the control and navigation of a simulated two-dimensional\nelectric rocket. The model provides a simplified framework that neglects\nactuator dynamics and aerodynamic effects while capturing the complexities of\nunderactuation and state coupling. Trajectory tracking is achieved through a\nmodularized and layered control architecture, with employement of a Linear\nQuadratic Regulator (LQR) and Lyapunov theory. Full-state estimation is\nachieved through Kalman filtering techniques, part of the navigation module.\nThe solutions are thoroughly evaluated in a custom-built MATLAB/Simulink\ntestbed, simulating real-world conditions while maintaining a simplified setup.\nThe results reveal limitations along the lateral axis, whose resolution is\nsuggested for future work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u62df\u4e8c\u7ef4\u7535\u52a8\u706b\u7bad\u7684\u63a7\u5236\u4e0e\u5bfc\u822a\u65b9\u6cd5\uff0c\u91c7\u7528\u6a21\u5757\u5316\u5206\u5c42\u63a7\u5236\u67b6\u6784\uff0c\u7ed3\u5408LQR\u548cLyapunov\u7406\u8bba\u5b9e\u73b0\u8f68\u8ff9\u8ddf\u8e2a\uff0c\u4f7f\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u8fdb\u884c\u5168\u72b6\u6001\u4f30\u8ba1\uff0c\u5e76\u5728MATLAB/Simulink\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4e8c\u7ef4\u7535\u52a8\u706b\u7bad\u7684\u63a7\u5236\u4e0e\u5bfc\u822a\u95ee\u9898\uff0c\u5efa\u7acb\u4e00\u4e2a\u7b80\u5316\u7684\u6846\u67b6\u6765\u6355\u6349\u6b20\u9a71\u52a8\u548c\u72b6\u6001\u8026\u5408\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u5ffd\u7565\u6267\u884c\u5668\u52a8\u529b\u5b66\u548c\u7a7a\u6c14\u52a8\u529b\u5b66\u6548\u5e94\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u5206\u5c42\u63a7\u5236\u67b6\u6784\uff0c\u4f7f\u7528\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668\uff08LQR\uff09\u548cLyapunov\u7406\u8bba\u5b9e\u73b0\u8f68\u8ff9\u8ddf\u8e2a\uff0c\u901a\u8fc7\u5361\u5c14\u66fc\u6ee4\u6ce2\u6280\u672f\u8fdb\u884c\u5168\u72b6\u6001\u4f30\u8ba1\uff0c\u5e76\u5728\u81ea\u5b9a\u4e49\u7684MATLAB/Simulink\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u4eff\u771f\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u63a7\u5236\u4e0e\u5bfc\u822a\u65b9\u6848\u5728\u6a21\u62df\u73af\u5883\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u6a2a\u5411\u8f74\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u5b9e\u73b0\u4e86\u4e8c\u7ef4\u7535\u52a8\u706b\u7bad\u7684\u6a21\u62df\u63a7\u5236\u4e0e\u5bfc\u822a\uff0c\u9a8c\u8bc1\u4e86\u6a21\u5757\u5316\u5206\u5c42\u63a7\u5236\u67b6\u6784\u7684\u6709\u6548\u6027\uff0c\u4f46\u6a2a\u5411\u8f74\u7684\u63a7\u5236\u95ee\u9898\u9700\u8981\u4f5c\u4e3a\u672a\u6765\u5de5\u4f5c\u7684\u91cd\u70b9\u89e3\u51b3\u3002"}}
{"id": "2509.19783", "categories": ["cs.AI", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.19783", "abs": "https://arxiv.org/abs/2509.19783", "authors": ["Jiexi Xu"], "title": "Agentic Metacognition: Designing a \"Self-Aware\" Low-Code Agent for Failure Prediction and Human Handoff", "comment": "7 pages, 2 tables", "summary": "The inherent non-deterministic nature of autonomous agents, particularly\nwithin low-code/no-code (LCNC) environments, presents significant reliability\nchallenges. Agents can become trapped in unforeseen loops, generate inaccurate\noutputs, or encounter unrecoverable failures, leading to user frustration and a\nbreakdown of trust. This report proposes a novel architectural pattern to\naddress these issues: the integration of a secondary, \"metacognitive\" layer\nthat actively monitors the primary LCNC agent. Inspired by human introspection,\nthis layer is designed to predict impending task failures based on a defined\nset of triggers, such as excessive latency or repetitive actions. Upon\npredicting a failure, the metacognitive agent proactively initiates a human\nhandoff, providing the user with a clear summary of the agent's \"thought\nprocess\" and a detailed explanation of why it could not proceed. An empirical\nanalysis of a prototype system demonstrates that this approach significantly\nincreases the overall task success rate. However, this performance gain comes\nwith a notable increase in computational overhead. The findings reframe human\nhandoffs not as an admission of defeat but as a core design feature that\nenhances system resilience, improves user experience, and builds trust by\nproviding transparency into the agent's internal state. The report discusses\nthe practical and ethical implications of this approach and identifies key\ndirections for future research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4f4e\u4ee3\u7801/\u65e0\u4ee3\u7801\u73af\u5883\u4e2d\u96c6\u6210\"\u5143\u8ba4\u77e5\"\u5c42\u6765\u76d1\u63a7\u81ea\u4e3b\u4ee3\u7406\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u4efb\u52a1\u5931\u8d25\u5e76\u4e3b\u52a8\u53d1\u8d77\u4eba\u5de5\u4ea4\u63a5\u6765\u63d0\u9ad8\u7cfb\u7edf\u53ef\u9760\u6027\u3002", "motivation": "\u81ea\u4e3b\u4ee3\u7406\u5728\u4f4e\u4ee3\u7801/\u65e0\u4ee3\u7801\u73af\u5883\u4e2d\u7684\u975e\u786e\u5b9a\u6027\u7279\u6027\u5bfc\u81f4\u53ef\u9760\u6027\u6311\u6218\uff0c\u5982\u9677\u5165\u5faa\u73af\u3001\u751f\u6210\u9519\u8bef\u8f93\u51fa\u6216\u4e0d\u53ef\u6062\u590d\u6545\u969c\uff0c\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u548c\u4fe1\u4efb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6b21\u7ea7\u5143\u8ba4\u77e5\u5c42\u6765\u4e3b\u52a8\u76d1\u63a7\u4e3b\u4ee3\u7406\uff0c\u57fa\u4e8e\u5ef6\u8fdf\u8fc7\u957f\u6216\u91cd\u590d\u52a8\u4f5c\u7b49\u89e6\u53d1\u5668\u9884\u6d4b\u4efb\u52a1\u5931\u8d25\uff0c\u5e76\u542f\u52a8\u4eba\u5de5\u4ea4\u63a5\u6d41\u7a0b\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u7684\u5b9e\u8bc1\u5206\u6790\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u660e\u663e\u589e\u52a0\u3002", "conclusion": "\u5c06\u4eba\u5de5\u4ea4\u63a5\u91cd\u65b0\u5b9a\u4e49\u4e3a\u589e\u5f3a\u7cfb\u7edf\u97e7\u6027\u3001\u6539\u5584\u7528\u6237\u4f53\u9a8c\u548c\u5efa\u7acb\u4fe1\u4efb\u7684\u6838\u5fc3\u8bbe\u8ba1\u7279\u5f81\uff0c\u800c\u975e\u5931\u8d25\u8868\u73b0\u3002"}}
{"id": "2509.19555", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19555", "abs": "https://arxiv.org/abs/2509.19555", "authors": ["Sankalp Agrawal", "Junwon Seo", "Kensuke Nakamura", "Ran Tian", "Andrea Bajcsy"], "title": "AnySafe: Adapting Latent Safety Filters at Runtime via Safety Constraint Parameterization in the Latent Space", "comment": null, "summary": "Recent works have shown that foundational safe control methods, such as\nHamilton-Jacobi (HJ) reachability analysis, can be applied in the latent space\nof world models. While this enables the synthesis of latent safety filters for\nhard-to-model vision-based tasks, they assume that the safety constraint is\nknown a priori and remains fixed during deployment, limiting the safety\nfilter's adaptability across scenarios. To address this, we propose\nconstraint-parameterized latent safety filters that can adapt to user-specified\nsafety constraints at runtime. Our key idea is to define safety constraints by\nconditioning on an encoding of an image that represents a constraint, using a\nlatent-space similarity measure. The notion of similarity to failure is aligned\nin a principled way through conformal calibration, which controls how closely\nthe system may approach the constraint representation. The parameterized safety\nfilter is trained entirely within the world model's imagination, treating any\nimage seen by the model as a potential test-time constraint, thereby enabling\nruntime adaptation to arbitrary safety constraints. In simulation and hardware\nexperiments on vision-based control tasks with a Franka manipulator, we show\nthat our method adapts at runtime by conditioning on the encoding of\nuser-specified constraint images, without sacrificing performance. Video\nresults can be found on https://any-safe.github.io", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ea6\u675f\u53c2\u6570\u5316\u7684\u6f5c\u5728\u5b89\u5168\u8fc7\u6ee4\u5668\uff0c\u80fd\u591f\u5728\u8fd0\u884c\u65f6\u6839\u636e\u7528\u6237\u6307\u5b9a\u7684\u5b89\u5168\u7ea6\u675f\u8fdb\u884c\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5b89\u5168\u7ea6\u675f\u56fa\u5b9a\u4e0d\u53d8\u7684\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u7684\u6f5c\u5728\u5b89\u5168\u8fc7\u6ee4\u5668\u65b9\u6cd5\u5047\u8bbe\u5b89\u5168\u7ea6\u675f\u662f\u9884\u5148\u5df2\u77e5\u4e14\u56fa\u5b9a\u7684\uff0c\u8fd9\u9650\u5236\u4e86\u5b89\u5168\u8fc7\u6ee4\u5668\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u9002\u5e94\u6027\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u5b9e\u65f6\u9002\u5e94\u4efb\u610f\u5b89\u5168\u7ea6\u675f\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u7ea6\u675f\u56fe\u50cf\u7684\u7f16\u7801\u6765\u5b9a\u4e49\u5b89\u5168\u7ea6\u675f\uff0c\u5e76\u5229\u7528\u6f5c\u5728\u7a7a\u95f4\u76f8\u4f3c\u6027\u5ea6\u91cf\u3002\u901a\u8fc7\u4fdd\u5f62\u6821\u51c6\u6765\u5bf9\u9f50\u6545\u969c\u76f8\u4f3c\u6027\u6982\u5ff5\uff0c\u63a7\u5236\u7cfb\u7edf\u63a5\u8fd1\u7ea6\u675f\u8868\u793a\u7684\u7a0b\u5ea6\u3002\u5b89\u5168\u8fc7\u6ee4\u5668\u5b8c\u5168\u5728\u4e16\u754c\u6a21\u578b\u7684\u60f3\u8c61\u7a7a\u95f4\u4e2d\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u57fa\u4e8e\u89c6\u89c9\u7684\u63a7\u5236\u4efb\u52a1\u4eff\u771f\u548c\u786c\u4ef6\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u901a\u8fc7\u6761\u4ef6\u5316\u7528\u6237\u6307\u5b9a\u7684\u7ea6\u675f\u56fe\u50cf\u7f16\u7801\u5728\u8fd0\u884c\u65f6\u8fdb\u884c\u81ea\u9002\u5e94\uff0c\u4e14\u4e0d\u727a\u7272\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ea6\u675f\u53c2\u6570\u5316\u6f5c\u5728\u5b89\u5168\u8fc7\u6ee4\u5668\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u8fd0\u884c\u65f6\u5bf9\u4efb\u610f\u5b89\u5168\u7ea6\u675f\u7684\u9002\u5e94\uff0c\u4e3a\u57fa\u4e8e\u89c6\u89c9\u7684\u590d\u6742\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u5b89\u5168\u4fdd\u969c\u65b9\u6848\u3002"}}
{"id": "2509.20071", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.20071", "abs": "https://arxiv.org/abs/2509.20071", "authors": ["Ali Azarbahram", "Shenyu Liu", "Gian Paolo Incremona"], "title": "Distributed Koopman Operator Learning from Sequential Observations", "comment": null, "summary": "This paper presents a distributed Koopman operator learning framework for\nmodeling unknown nonlinear dynamics using sequential observations from multiple\nagents. Each agent estimates a local Koopman approximation based on lifted data\nand collaborates over a communication graph to reach exponential consensus on a\nconsistent distributed approximation. The approach supports distributed\ncomputation under asynchronous and resource-constrained sensing. Its\nperformance is demonstrated through simulation results, validating convergence\nand predictive accuracy under sensing-constrained scenarios and limited\ncommunication.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u5f0fKoopman\u7b97\u5b50\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53\u5e8f\u5217\u89c2\u6d4b\u6570\u636e\u5efa\u6a21\u672a\u77e5\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf", "motivation": "\u89e3\u51b3\u5728\u5f02\u6b65\u548c\u8d44\u6e90\u53d7\u9650\u611f\u77e5\u6761\u4ef6\u4e0b\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5bf9\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7684\u5206\u5e03\u5f0f\u5efa\u6a21\u95ee\u9898", "method": "\u6bcf\u4e2a\u667a\u80fd\u4f53\u57fa\u4e8e\u63d0\u5347\u6570\u636e\u4f30\u8ba1\u5c40\u90e8Koopman\u8fd1\u4f3c\uff0c\u901a\u8fc7\u901a\u4fe1\u56fe\u534f\u4f5c\u8fbe\u6210\u6307\u6570\u4e00\u81f4\u6027\u5206\u5e03\u5f0f\u8fd1\u4f3c", "result": "\u4eff\u771f\u9a8c\u8bc1\u4e86\u5728\u611f\u77e5\u53d7\u9650\u548c\u901a\u4fe1\u53d7\u9650\u573a\u666f\u4e0b\u7684\u6536\u655b\u6027\u548c\u9884\u6d4b\u7cbe\u5ea6", "conclusion": "\u8be5\u6846\u67b6\u652f\u6301\u5206\u5e03\u5f0f\u8ba1\u7b97\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u6709\u6548\u5b9e\u73b0\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u5efa\u6a21"}}
{"id": "2509.19800", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19800", "abs": "https://arxiv.org/abs/2509.19800", "authors": ["Donghwan Lee", "Hyukjun Yang", "Bum Geun Park"], "title": "Analysis of approximate linear programming solution to Markov decision problem with log barrier function", "comment": null, "summary": "There are two primary approaches to solving Markov decision problems (MDPs):\ndynamic programming based on the Bellman equation and linear programming (LP).\nDynamic programming methods are the most widely used and form the foundation of\nboth classical and modern reinforcement learning (RL). By contrast, LP-based\nmethods have been less commonly employed, although they have recently gained\nattention in contexts such as offline RL. The relative underuse of the LP-based\nmethods stems from the fact that it leads to an inequality-constrained\noptimization problem, which is generally more challenging to solve effectively\ncompared with Bellman-equation-based methods. The purpose of this paper is to\nestablish a theoretical foundation for solving LP-based MDPs in a more\neffective and practical manner. Our key idea is to leverage the log-barrier\nfunction, widely used in inequality-constrained optimization, to transform the\nLP formulation of the MDP into an unconstrained optimization problem. This\nreformulation enables approximate solutions to be obtained easily via gradient\ndescent. While the method may appear simple, to the best of our knowledge, a\nthorough theoretical interpretation of this approach has not yet been\ndeveloped. This paper aims to bridge this gap.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5bf9\u6570\u969c\u788d\u51fd\u6570\u5c06\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u68af\u5ea6\u4e0b\u964d\u80fd\u591f\u6709\u6548\u6c42\u89e3\u3002", "motivation": "\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u5728\u89e3\u51b3\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u95ee\u9898\u65f6\u4f7f\u7528\u8f83\u5c11\uff0c\u4e3b\u8981\u56e0\u4e3a\u5176\u5bfc\u81f4\u7684\u4e0d\u7b49\u5f0f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u6bd4\u57fa\u4e8e\u8d1d\u5c14\u66fc\u65b9\u7a0b\u7684\u65b9\u6cd5\u66f4\u96be\u6c42\u89e3\u3002\u672c\u6587\u65e8\u5728\u4e3aLP-based MDPs\u5efa\u7acb\u66f4\u6709\u6548\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5229\u7528\u4e0d\u7b49\u5f0f\u7ea6\u675f\u4f18\u5316\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u5bf9\u6570\u969c\u788d\u51fd\u6570\uff0c\u5c06MDP\u7684LP\u8868\u8ff0\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u4ece\u800c\u53ef\u4ee5\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u83b7\u5f97\u8fd1\u4f3c\u89e3\u3002", "result": "\u8be5\u65b9\u6cd5\u867d\u7136\u770b\u4f3c\u7b80\u5355\uff0c\u4f46\u63d0\u4f9b\u4e86\u5bf9LP-based MDPs\u6c42\u89e3\u7684\u7406\u8bba\u89e3\u91ca\u548c\u5b9e\u7528\u6846\u67b6\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86\u5bf9\u6570\u969c\u788d\u51fd\u6570\u5728LP-based MDPs\u4e2d\u5e94\u7528\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u4e3a\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.19571", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.19571", "abs": "https://arxiv.org/abs/2509.19571", "authors": ["Sacha Morin", "Kumaraditya Gupta", "Mahtab Sandhu", "Charlie Gauthier", "Francesco Argenziano", "Kirsty Ellis", "Liam Paull"], "title": "Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action", "comment": "Project page:\n  https://montrealrobotics.ca/agentic-scene-policies.github.io/", "summary": "Executing open-ended natural language queries is a core problem in robotics.\nWhile recent advances in imitation learning and vision-language-actions models\n(VLAs) have enabled promising end-to-end policies, these models struggle when\nfaced with complex instructions and new scenes. An alternative is to design an\nexplicit scene representation as a queryable interface between the robot and\nthe world, using query results to guide downstream motion planning. In this\nwork, we present Agentic Scene Policies (ASP), an agentic framework that\nleverages the advanced semantic, spatial, and affordance-based querying\ncapabilities of modern scene representations to implement a capable\nlanguage-conditioned robot policy. ASP can execute open-vocabulary queries in a\nzero-shot manner by explicitly reasoning about object affordances in the case\nof more complex skills. Through extensive experiments, we compare ASP with VLAs\non tabletop manipulation problems and showcase how ASP can tackle room-level\nqueries through affordance-guided navigation, and a scaled-up scene\nrepresentation. (Project page:\nhttps://montrealrobotics.ca/agentic-scene-policies.github.io/)", "AI": {"tldr": "ASP\u662f\u4e00\u4e2a\u57fa\u4e8e\u573a\u666f\u8868\u793a\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u3001\u7a7a\u95f4\u548c\u529f\u80fd\u67e5\u8be2\u80fd\u529b\u5b9e\u73b0\u8bed\u8a00\u6761\u4ef6\u673a\u5668\u4eba\u7b56\u7565\uff0c\u80fd\u591f\u96f6\u6837\u672c\u6267\u884c\u5f00\u653e\u8bcd\u6c47\u67e5\u8be2\uff0c\u5e76\u5728\u590d\u6742\u6280\u80fd\u4e2d\u663e\u5f0f\u63a8\u7406\u7269\u4f53\u529f\u80fd\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u6267\u884c\u5f00\u653e\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7aef\u5230\u7aef\u7b56\u7565\u5728\u5904\u7406\u590d\u6742\u6307\u4ee4\u548c\u65b0\u573a\u666f\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u8bbe\u8ba1\u663e\u5f0f\u573a\u666f\u8868\u793a\u4f5c\u4e3a\u673a\u5668\u4eba\u4e0e\u4e16\u754c\u4e4b\u95f4\u7684\u53ef\u67e5\u8be2\u63a5\u53e3\u3002", "method": "\u63d0\u51faAgentic Scene Policies (ASP)\u6846\u67b6\uff0c\u5229\u7528\u73b0\u4ee3\u573a\u666f\u8868\u793a\u7684\u9ad8\u7ea7\u8bed\u4e49\u3001\u7a7a\u95f4\u548c\u529f\u80fd\u67e5\u8be2\u80fd\u529b\uff0c\u901a\u8fc7\u67e5\u8be2\u7ed3\u679c\u6307\u5bfc\u4e0b\u6e38\u8fd0\u52a8\u89c4\u5212\uff0c\u5728\u590d\u6742\u6280\u80fd\u4e2d\u663e\u5f0f\u63a8\u7406\u7269\u4f53\u529f\u80fd\u3002", "result": "\u5728\u684c\u9762\u64cd\u4f5c\u95ee\u9898\u4e0a\u4e0eVLAs\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u6bd4\u8f83\uff0c\u5c55\u793aASP\u80fd\u591f\u901a\u8fc7\u529f\u80fd\u5f15\u5bfc\u5bfc\u822a\u5904\u7406\u623f\u95f4\u7ea7\u67e5\u8be2\uff0c\u5e76\u6269\u5c55\u573a\u666f\u8868\u793a\u89c4\u6a21\u3002", "conclusion": "ASP\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u573a\u666f\u8868\u793a\u548c\u529f\u80fd\u63a8\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u6267\u884c\u95ee\u9898\uff0c\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.20100", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.20100", "abs": "https://arxiv.org/abs/2509.20100", "authors": ["Yankai Wang", "Ti Chen"], "title": "Koopman-Operator-Based Model Predictive Control for Drag-free Satellite", "comment": null, "summary": "This paper presents a data-driven modelling method for nonlinear dynamics of\ndrag-free satellite based on Koopman operator theory, and a model predictive\ncontroller is designed based on the identified model. The nonlinear dynamics of\ndrag-free satellite are identified and controlled based on Sparse\nIdentification of Nonlinear Dynamics (SINDy). Using the manually constructed\nnonlinear function dictionary as observables, the system approximation is\nobtained by SINDy algorithm, and a linear Model Predictive Control (MPC)\ncontroller is designed for test mass capture based on the SINDy model. Finally,\nthe effectiveness of MPC control is verified by numerical examples.", "AI": {"tldr": "\u57fa\u4e8eKoopman\u7b97\u5b50\u7406\u8bba\u548cSINDy\u65b9\u6cd5\u7684\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u65b9\u6cd5\u7528\u4e8e\u65e0\u963b\u529b\u536b\u661f\u975e\u7ebf\u6027\u52a8\u529b\u5b66\uff0c\u5e76\u8bbe\u8ba1\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\u8fdb\u884c\u6d4b\u8bd5\u8d28\u91cf\u6355\u83b7\u63a7\u5236", "motivation": "\u65e0\u963b\u529b\u536b\u661f\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u5efa\u6a21\u548c\u63a7\u5236\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u975e\u7ebf\u6027\u7279\u6027\uff0c\u9700\u8981\u5f00\u53d1\u6570\u636e\u9a71\u52a8\u7684\u5efa\u6a21\u548c\u63a7\u5236\u65b9\u6cd5", "method": "\u4f7f\u7528\u624b\u52a8\u6784\u5efa\u7684\u975e\u7ebf\u6027\u51fd\u6570\u5b57\u5178\u4f5c\u4e3a\u53ef\u89c2\u6d4b\u91cf\uff0c\u901a\u8fc7SINDy\u7b97\u6cd5\u83b7\u5f97\u7cfb\u7edf\u8fd1\u4f3c\uff0c\u5e76\u57fa\u4e8eSINDy\u6a21\u578b\u8bbe\u8ba1\u7ebf\u6027MPC\u63a7\u5236\u5668", "result": "\u901a\u8fc7\u6570\u503c\u7b97\u4f8b\u9a8c\u8bc1\u4e86MPC\u63a7\u5236\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u65e0\u963b\u529b\u536b\u661f\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u5efa\u6a21\u548c\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u9a71\u52a8\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.19839", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19839", "abs": "https://arxiv.org/abs/2509.19839", "authors": ["Huizhen Shu", "Xuying Li", "Zhuo Li"], "title": "LatentGuard: Controllable Latent Steering for Robust Refusal of Attacks and Reliable Response Generation", "comment": "9-page NeurIPS 2025 preprint including 3 figures and 1 table, with\n  additional appendix material. Prepared using the NeurIPS 2025 preprint\n  template and compiled with pdfLaTeX. All references are included via the\n  provided .bbl file. Figures are in PDF format. No external supplementary\n  files. All necessary style files and images are included", "summary": "Achieving robust safety alignment in large language models (LLMs) while\npreserving their utility remains a fundamental challenge. Existing approaches\noften struggle to balance comprehensive safety with fine-grained\ncontrollability at the representation level. We introduce LATENTGUARD, a novel\nthree-stage framework that combines behavioral alignment with supervised latent\nspace control for interpretable and precise safety steering. Our approach\nbegins by fine-tuning an LLM on rationalized datasets containing both\nreasoning-enhanced refusal responses to adversarial prompts and\nreasoning-enhanced normal responses to benign queries, establishing robust\nbehavioral priors across both safety-critical and utility-preserving scenarios.\nWe then train a structured variational autoencoder (VAE) on intermediate MLP\nactivations, supervised by multi-label annotations including attack types,\nattack methods, and benign indicators. This supervision enables the VAE to\nlearn disentangled latent representations that capture distinct adversarial\ncharacteristics while maintaining semantic interpretability. Through targeted\nmanipulation of learned latent dimensions, LATENTGUARD achieves selective\nrefusal behavior, effectively blocking harmful requests while preserving\nhelpfulness for legitimate use cases. Experiments on Qwen3-8B demonstrate\nsignificant improvements in both safety controllability and response\ninterpretability without compromising utility. Cross-architecture validation on\nMistral-7B confirms the generalizability of our latent steering approach,\nshowing consistent effectiveness across different model families. Our results\nsuggest that structured representation-level intervention offers a promising\npathway toward building safer yet practical LLM systems.", "AI": {"tldr": "LATENTGUARD\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u7ed3\u5408\u884c\u4e3a\u5bf9\u9f50\u548c\u76d1\u7763\u6f5c\u7a7a\u95f4\u63a7\u5236\uff0c\u5728\u4fdd\u6301\u8bed\u8a00\u6a21\u578b\u5b9e\u7528\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u7cbe\u786e\u7684\u5b89\u5168\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u8868\u793a\u5c42\u9762\u5e73\u8861\u5168\u9762\u5b89\u5168\u6027\u548c\u7ec6\u7c92\u5ea6\u53ef\u63a7\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u786e\u4fdd\u5b89\u5168\u53c8\u4e0d\u635f\u5bb3\u5b9e\u7528\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1\uff09\u5728\u5305\u542b\u63a8\u7406\u589e\u5f3a\u62d2\u7edd\u54cd\u5e94\u548c\u6b63\u5e38\u54cd\u5e94\u7684\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u6a21\u578b\uff1b2\uff09\u8bad\u7ec3\u7ed3\u6784\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u89e3\u7f20\u7684\u6f5c\u8868\u793a\uff1b3\uff09\u901a\u8fc7\u6f5c\u7ef4\u5ea6\u64cd\u4f5c\u5b9e\u73b0\u9009\u62e9\u6027\u62d2\u7edd\u884c\u4e3a\u3002", "result": "\u5728Qwen3-8B\u4e0a\u5b9e\u9a8c\u663e\u793a\u5b89\u5168\u53ef\u63a7\u6027\u548c\u54cd\u5e94\u53ef\u89e3\u91ca\u6027\u663e\u8457\u63d0\u5347\uff0c\u5728Mistral-7B\u4e0a\u7684\u8de8\u67b6\u6784\u9a8c\u8bc1\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u3002", "conclusion": "\u7ed3\u6784\u5316\u8868\u793a\u7ea7\u5e72\u9884\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u5b9e\u7528\u7684LLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2509.19573", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19573", "abs": "https://arxiv.org/abs/2509.19573", "authors": ["Zachary Olkin", "Kejun Li", "William D. Compton", "Aaron D. Ames"], "title": "Chasing Stability: Humanoid Running via Control Lyapunov Function Guided Reinforcement Learning", "comment": "Submitted to ICRA 2026", "summary": "Achieving highly dynamic behaviors on humanoid robots, such as running,\nrequires controllers that are both robust and precise, and hence difficult to\ndesign. Classical control methods offer valuable insight into how such systems\ncan stabilize themselves, but synthesizing real-time controllers for nonlinear\nand hybrid dynamics remains challenging. Recently, reinforcement learning (RL)\nhas gained popularity for locomotion control due to its ability to handle these\ncomplex dynamics. In this work, we embed ideas from nonlinear control theory,\nspecifically control Lyapunov functions (CLFs), along with optimized dynamic\nreference trajectories into the reinforcement learning training process to\nshape the reward. This approach, CLF-RL, eliminates the need to handcraft and\ntune heuristic reward terms, while simultaneously encouraging certifiable\nstability and providing meaningful intermediate rewards to guide learning. By\ngrounding policy learning in dynamically feasible trajectories, we expand the\nrobot's dynamic capabilities and enable running that includes both flight and\nsingle support phases. The resulting policy operates reliably on a treadmill\nand in outdoor environments, demonstrating robustness to disturbances applied\nto the torso and feet. Moreover, it achieves accurate global reference tracking\nutilizing only on-board sensors, making a critical step toward integrating\nthese dynamic motions into a full autonomy stack.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u975e\u7ebf\u6027\u63a7\u5236\u7406\u8bba\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff08CLF-RL\uff09\uff0c\u7528\u4e8e\u4eba\u5f62\u673a\u5668\u4eba\u7684\u52a8\u6001\u8fd0\u52a8\u63a7\u5236\uff0c\u7279\u522b\u662f\u8dd1\u6b65\u884c\u4e3a\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u63a7\u5236Lyapunov\u51fd\u6570\u548c\u4f18\u5316\u52a8\u6001\u53c2\u8003\u8f68\u8ff9\u6765\u5851\u9020\u5956\u52b1\u51fd\u6570\uff0c\u907f\u514d\u4e86\u624b\u52a8\u8bbe\u8ba1\u542f\u53d1\u5f0f\u5956\u52b1\u9879\u7684\u9700\u8981\u3002", "motivation": "\u8bbe\u8ba1\u4eba\u5f62\u673a\u5668\u4eba\u52a8\u6001\u884c\u4e3a\uff08\u5982\u8dd1\u6b65\uff09\u7684\u63a7\u5236\u5668\u65e2\u9700\u8981\u9c81\u68d2\u6027\u53c8\u9700\u8981\u7cbe\u786e\u6027\uff0c\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u975e\u7ebf\u6027\u6df7\u5408\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u5b9e\u65f6\u63a7\u5236\u95ee\u9898\u3002\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u80fd\u5904\u7406\u590d\u6742\u52a8\u529b\u5b66\uff0c\u4f46\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\u3002", "method": "CLF-RL\u65b9\u6cd5\u5c06\u63a7\u5236Lyapunov\u51fd\u6570\uff08CLF\uff09\u548c\u4f18\u5316\u7684\u52a8\u6001\u53c2\u8003\u8f68\u8ff9\u5d4c\u5165\u5230\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u57fa\u4e8e\u52a8\u6001\u53ef\u884c\u8f68\u8ff9\u7684\u7b56\u7565\u5b66\u4e60\uff0c\u6269\u5c55\u673a\u5668\u4eba\u7684\u52a8\u6001\u80fd\u529b\uff0c\u5b9e\u73b0\u5305\u542b\u98de\u884c\u548c\u5355\u652f\u6491\u9636\u6bb5\u7684\u8dd1\u6b65\u8fd0\u52a8\u3002", "result": "\u751f\u6210\u7684\u7b56\u7565\u5728\u8dd1\u6b65\u673a\u548c\u5ba4\u5916\u73af\u5883\u4e2d\u53ef\u9760\u8fd0\u884c\uff0c\u5bf9\u8eaf\u5e72\u548c\u811a\u90e8\u65bd\u52a0\u7684\u5e72\u6270\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u4ec5\u4f7f\u7528\u677f\u8f7d\u4f20\u611f\u5668\u5c31\u80fd\u5b9e\u73b0\u51c6\u786e\u7684\u5168\u5c40\u53c2\u8003\u8ddf\u8e2a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u73b0\u52a8\u6001\u8fd0\u52a8\u96c6\u6210\u5230\u5b8c\u6574\u81ea\u4e3b\u5806\u6808\u8fc8\u51fa\u4e86\u5173\u952e\u4e00\u6b65\uff0c\u8bc1\u660e\u4e86\u7ed3\u5408\u63a7\u5236\u7406\u8bba\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.20306", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.20306", "abs": "https://arxiv.org/abs/2509.20306", "authors": ["Jaejeong Park", "Mahmoud Elfar", "Cody Fleming", "Yasser Shoukry"], "title": "Certified Learning-Enabled Noise-Aware Motion Planning for Urban Air Mobility", "comment": "16 pages, 10 figures", "summary": "Urban Air Mobility (UAM) has emerged as a promising solution to alleviate\nurban congestion and transportation challenges. Nevertheless, the noise\ngenerated by eVTOL aircrafts poses a significant barrier to public acceptance\nand regulatory approval, potentially limiting the operational scope and\nscalability of UAM systems. Hence, the successful adoption of UAM systems\nhinges on the ability to predict generated noise levels, and further develop\nmotion planning strategies that comply with community-level noise regulations\nwhile maintaining operational efficiency. To this end, this paper proposes a\nnovel noise-aware motion planning framework for UAM systems that ensures\ncompliance with noise regulations. We first develop a certifiable neural\nnetwork model to accurately predict eVTOL noise propagation patterns in urban\nenvironments, providing provable bounds on its correctness. To achieve a\ndesired level of accuracy, we propose an active sampling strategy to\nefficiently build the dataset used to train and test the noise model. Next, we\ndevelop a noise-aware motion planning algorithm that utilizes the noise model\nto generate eVTOL trajectories that guarantee compliance with community noise\nregulations. The algorithm exploits the monotonic structure of the noise model\nto efficiently sample the configuration space, ensuring that the generated\ntrajectories are both noise-compliant and operationally efficient. We\ndemonstrate the effectiveness of the proposed framework through a number of\nexperiments for Vahana eVTOLs. The results show that the framework can generate\nnoise-compliant flight plans for a fleet of eVTOLs that adhere to community\nnoise regulations while optimizing operational efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a\u7cfb\u7edf\u7684\u566a\u58f0\u611f\u77e5\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u8ba4\u8bc1\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9884\u6d4beVTOL\u566a\u58f0\u4f20\u64ad\uff0c\u5e76\u5f00\u53d1\u566a\u58f0\u611f\u77e5\u8fd0\u52a8\u89c4\u5212\u7b97\u6cd5\u751f\u6210\u7b26\u5408\u793e\u533a\u566a\u58f0\u6cd5\u89c4\u7684\u8f68\u8ff9\u3002", "motivation": "\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a\u7cfb\u7edf\u9762\u4e34eVTOL\u98de\u673a\u566a\u58f0\u5bf9\u516c\u4f17\u63a5\u53d7\u5ea6\u548c\u76d1\u7ba1\u6279\u51c6\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9884\u6d4b\u566a\u58f0\u6c34\u5e73\u5e76\u786e\u4fdd\u7b26\u5408\u566a\u58f0\u6cd5\u89c4\u7684\u8fd0\u52a8\u89c4\u5212\u7b56\u7565\u3002", "method": "\u5f00\u53d1\u53ef\u8ba4\u8bc1\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9884\u6d4beVTOL\u566a\u58f0\u4f20\u64ad\u6a21\u5f0f\uff1b\u63d0\u51fa\u4e3b\u52a8\u91c7\u6837\u7b56\u7565\u6784\u5efa\u8bad\u7ec3\u6570\u636e\u96c6\uff1b\u5229\u7528\u566a\u58f0\u6a21\u578b\u7684\u5355\u8c03\u7ed3\u6784\u5f00\u53d1\u566a\u58f0\u611f\u77e5\u8fd0\u52a8\u89c4\u5212\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4e3aeVTOL\u673a\u961f\u751f\u6210\u7b26\u5408\u793e\u533a\u566a\u58f0\u6cd5\u89c4\u7684\u98de\u884c\u8ba1\u5212\uff0c\u540c\u65f6\u4f18\u5316\u8fd0\u884c\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u566a\u58f0\u611f\u77e5\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3UAM\u7cfb\u7edf\u7684\u566a\u58f0\u5408\u89c4\u6027\u95ee\u9898\uff0c\u4e3a\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a\u7684\u89c4\u6a21\u5316\u53d1\u5c55\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2509.19925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19925", "abs": "https://arxiv.org/abs/2509.19925", "authors": ["Ajeet Kumar Singh", "Rajsabi Surya", "Anurag Tripathi", "Santanu Choudhury", "Sudhir Bisane"], "title": "CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain", "comment": null, "summary": "As enterprises increasingly integrate cloud-based large language models\n(LLMs) such as ChatGPT and Gemini into their legal document workflows,\nprotecting sensitive contractual information - including Personally\nIdentifiable Information (PII) and commercially sensitive clauses - has emerged\nas a critical challenge. In this work, we propose CON-QA, a hybrid\nprivacy-preserving framework designed specifically for secure question\nanswering over enterprise contracts, effectively combining local and\ncloud-hosted LLMs. The CON-QA framework operates through three stages: (i)\nsemantic query decomposition and query-aware document chunk retrieval using a\nlocally deployed LLM analysis, (ii) anonymization of detected sensitive\nentities via a structured one-to-many mapping scheme, ensuring semantic\ncoherence while preventing cross-session entity inference attacks, and (iii)\nanonymized response generation by a cloud-based LLM, with accurate\nreconstruction of the original answer locally using a session-consistent\nmany-to-one reverse mapping. To rigorously evaluate CON-QA, we introduce\nCUAD-QA, a corpus of 85k question-answer pairs generated over 510 real-world\nCUAD contract documents, encompassing simple, complex, and summarization-style\nqueries. Empirical evaluations, complemented by detailed human assessments,\nconfirm that CON-QA effectively maintains both privacy and utility, preserves\nanswer quality, maintains fidelity to legal clause semantics, and significantly\nmitigates privacy risks, demonstrating its practical suitability for secure,\nenterprise-level contract documents.", "AI": {"tldr": "CON-QA\u662f\u4e00\u4e2a\u6df7\u5408\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u4f01\u4e1a\u5408\u540c\u7684\u5b89\u5168\u95ee\u7b54\uff0c\u7ed3\u5408\u672c\u5730\u548c\u4e91\u7aefLLM\u6765\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u3002", "motivation": "\u4f01\u4e1a\u8d8a\u6765\u8d8a\u591a\u5730\u5c06\u57fa\u4e8e\u4e91\u7684LLM\u96c6\u6210\u5230\u6cd5\u5f8b\u6587\u6863\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4fdd\u62a4\u654f\u611f\u5408\u540c\u4fe1\u606f\uff08\u5982PII\u548c\u5546\u4e1a\u654f\u611f\u6761\u6b3e\uff09\u5df2\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002", "method": "CON-QA\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u8fd0\u4f5c\uff1a\u8bed\u4e49\u67e5\u8be2\u5206\u89e3\u548c\u67e5\u8be2\u611f\u77e5\u6587\u6863\u5757\u68c0\u7d22\u3001\u654f\u611f\u5b9e\u4f53\u533f\u540d\u5316\u3001\u533f\u540d\u5316\u54cd\u5e94\u751f\u6210\u548c\u539f\u59cb\u7b54\u6848\u91cd\u5efa\u3002", "result": "\u7ecf\u9a8c\u8bc4\u4f30\u548c\u8be6\u7ec6\u4eba\u5de5\u8bc4\u4f30\u8bc1\u5b9eCON-QA\u6709\u6548\u7ef4\u62a4\u9690\u79c1\u548c\u6548\u7528\uff0c\u4fdd\u6301\u7b54\u6848\u8d28\u91cf\uff0c\u7ef4\u62a4\u6cd5\u5f8b\u6761\u6b3e\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u663e\u8457\u51cf\u8f7b\u9690\u79c1\u98ce\u9669\u3002", "conclusion": "CON-QA\u5c55\u793a\u4e86\u5176\u5728\u5b89\u5168\u3001\u4f01\u4e1a\u7ea7\u5408\u540c\u6587\u6863\u4e2d\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002"}}
{"id": "2509.19579", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19579", "abs": "https://arxiv.org/abs/2509.19579", "authors": ["Chad R. Samuelson", "Abigail Austin", "Seth Knoop", "Blake Romrell", "Gabriel R. Slade", "Timothy W. McLain", "Joshua G. Mangelson"], "title": "Terra: Hierarchical Terrain-Aware 3D Scene Graph for Task-Agnostic Outdoor Mapping", "comment": null, "summary": "Outdoor intelligent autonomous robotic operation relies on a sufficiently\nexpressive map of the environment. Classical geometric mapping methods retain\nessential structural environment information, but lack a semantic understanding\nand organization to allow high-level robotic reasoning. 3D scene graphs (3DSGs)\naddress this limitation by integrating geometric, topological, and semantic\nrelationships into a multi-level graph-based map. Outdoor autonomous operations\ncommonly rely on terrain information either due to task-dependence or the\ntraversability of the robotic platform. We propose a novel approach that\ncombines indoor 3DSG techniques with standard outdoor geometric mapping and\nterrain-aware reasoning, producing terrain-aware place nodes and hierarchically\norganized regions for outdoor environments. Our method generates a\ntask-agnostic metric-semantic sparse map and constructs a 3DSG from this map\nfor downstream planning tasks, all while remaining lightweight for autonomous\nrobotic operation. Our thorough evaluation demonstrates our 3DSG method\nperforms on par with state-of-the-art camera-based 3DSG methods in object\nretrieval and surpasses them in region classification while remaining memory\nefficient. We demonstrate its effectiveness in diverse robotic tasks of object\nretrieval and region monitoring in both simulation and real-world environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5ba4\u51853D\u573a\u666f\u56fe\u6280\u672f\u4e0e\u6237\u5916\u51e0\u4f55\u6620\u5c04\u548c\u5730\u5f62\u611f\u77e5\u63a8\u7406\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u751f\u6210\u5730\u5f62\u611f\u77e5\u7684\u5730\u70b9\u8282\u70b9\u548c\u5c42\u6b21\u5316\u7ec4\u7ec7\u7684\u533a\u57df\uff0c\u4e3a\u6237\u5916\u73af\u5883\u6784\u5efa\u8f7b\u91cf\u7ea7\u76843D\u573a\u666f\u56fe\u3002", "motivation": "\u6237\u5916\u667a\u80fd\u81ea\u4e3b\u673a\u5668\u4eba\u64cd\u4f5c\u9700\u8981\u73af\u5883\u7684\u5730\u56fe\u8868\u8fbe\uff0c\u4f20\u7edf\u51e0\u4f55\u5730\u56fe\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\uff0c\u800c3D\u573a\u666f\u56fe\u80fd\u591f\u6574\u5408\u51e0\u4f55\u3001\u62d3\u6251\u548c\u8bed\u4e49\u5173\u7cfb\uff0c\u4f46\u9700\u8981\u7ed3\u5408\u6237\u5916\u5730\u5f62\u4fe1\u606f\u6765\u652f\u6301\u673a\u5668\u4eba\u63a8\u7406\u3002", "method": "\u7ed3\u5408\u5ba4\u51853D\u573a\u666f\u56fe\u6280\u672f\u4e0e\u6807\u51c6\u6237\u5916\u51e0\u4f55\u6620\u5c04\u548c\u5730\u5f62\u611f\u77e5\u63a8\u7406\uff0c\u751f\u6210\u4efb\u52a1\u65e0\u5173\u7684\u5ea6\u91cf\u8bed\u4e49\u7a00\u758f\u5730\u56fe\uff0c\u5e76\u4ece\u4e2d\u6784\u5efa3D\u573a\u666f\u56fe\u7528\u4e8e\u4e0b\u6e38\u89c4\u5212\u4efb\u52a1\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u7269\u4f53\u68c0\u7d22\u65b9\u9762\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u76f8\u673a\u76843D\u573a\u666f\u56fe\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u533a\u57df\u5206\u7c7b\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u540c\u65f6\u4fdd\u6301\u5185\u5b58\u9ad8\u6548\u3002\u5728\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u7269\u4f53\u68c0\u7d22\u548c\u533a\u57df\u76d1\u6d4b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c063D\u573a\u666f\u56fe\u6280\u672f\u6269\u5c55\u5230\u6237\u5916\u73af\u5883\uff0c\u7ed3\u5408\u5730\u5f62\u611f\u77e5\u63a8\u7406\uff0c\u4e3a\u6237\u5916\u81ea\u4e3b\u673a\u5668\u4eba\u64cd\u4f5c\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u4e14\u8868\u8fbe\u80fd\u529b\u5f3a\u7684\u5730\u56fe\u8868\u793a\u3002"}}
{"id": "2509.20314", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY", "math.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.20314", "abs": "https://arxiv.org/abs/2509.20314", "authors": ["Abhinav Sinha", "Dwaipayan Mukherjee", "Shashi Ranjan Kumar"], "title": "On Robustness of Consensus over Pseudo-Undirected Path Graphs", "comment": null, "summary": "Consensus over networked agents is typically studied using undirected or\ndirected communication graphs. Undirected graphs enforce symmetry in\ninformation exchange, leading to convergence to the average of initial states,\nwhile directed graphs permit asymmetry but make consensus dependent on root\nnodes and their influence. Both paradigms impose inherent restrictions on\nachievable consensus values and network robustness. This paper introduces a\ntheoretical framework for achieving consensus over a class of network\ntopologies, termed pseudo-undirected graphs, which retains bidirectional\nconnectivity between node pairs but allows the corresponding edge weights to\ndiffer, including the possibility of negative values under bounded conditions.\nThe resulting Laplacian is generally non-symmetric, yet it guarantees consensus\nunder connectivity assumptions, to expand the solution space, which enables the\nsystem to achieve a stable consensus value that can lie outside the convex hull\nof the initial state set. We derive admissibility bounds for negative weights\nfor a pseudo-undirected path graph, and show an application in the simultaneous\ninterception of a moving target.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f2a\u65e0\u5411\u56fe\u7684\u7406\u8bba\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u5171\u8bc6\u7b97\u6cd5\u7684\u89e3\u7a7a\u95f4\uff0c\u5141\u8bb8\u8fb9\u6743\u91cd\u4e0d\u5bf9\u79f0\u751a\u81f3\u4e3a\u8d1f\u503c\uff0c\u4ece\u800c\u80fd\u591f\u5b9e\u73b0\u8d85\u51fa\u521d\u59cb\u72b6\u6001\u51f8\u5305\u7684\u5171\u8bc6\u503c\u3002", "motivation": "\u4f20\u7edf\u65e0\u5411\u56fe\u548c\u6709\u5411\u56fe\u5728\u5171\u8bc6\u7b97\u6cd5\u4e2d\u5b58\u5728\u56fa\u6709\u5c40\u9650\u6027\uff1a\u65e0\u5411\u56fe\u5f3a\u5236\u4fe1\u606f\u4ea4\u6362\u5bf9\u79f0\u6027\uff0c\u53ea\u80fd\u6536\u655b\u5230\u521d\u59cb\u72b6\u6001\u7684\u5e73\u5747\u503c\uff1b\u6709\u5411\u56fe\u5141\u8bb8\u4e0d\u5bf9\u79f0\u4f46\u4f9d\u8d56\u6839\u8282\u70b9\u4e14\u7f51\u7edc\u9c81\u68d2\u6027\u53d7\u9650\u3002\u9700\u8981\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u6765\u6269\u5c55\u5171\u8bc6\u7b97\u6cd5\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u5f15\u5165\u4f2a\u65e0\u5411\u56fe\u6982\u5ff5\uff0c\u4fdd\u6301\u8282\u70b9\u95f4\u7684\u53cc\u5411\u8fde\u901a\u6027\u4f46\u5141\u8bb8\u5bf9\u5e94\u8fb9\u6743\u91cd\u4e0d\u540c\uff0c\u5305\u62ec\u5728\u6709\u9650\u6761\u4ef6\u4e0b\u5141\u8bb8\u8d1f\u6743\u91cd\u3002\u6784\u5efa\u7684\u975e\u5bf9\u79f0\u62c9\u666e\u62c9\u65af\u77e9\u9635\u5728\u8fde\u901a\u6027\u5047\u8bbe\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u5171\u8bc6\u6536\u655b\u3002", "result": "\u63a8\u5bfc\u4e86\u4f2a\u65e0\u5411\u8def\u5f84\u56fe\u4e2d\u8d1f\u6743\u91cd\u7684\u53ef\u5bb9\u8bb8\u8fb9\u754c\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u80fd\u591f\u8fbe\u5230\u8d85\u51fa\u521d\u59cb\u72b6\u6001\u51f8\u5305\u7684\u7a33\u5b9a\u5171\u8bc6\u503c\u3002\u5c55\u793a\u4e86\u5728\u79fb\u52a8\u76ee\u6807\u540c\u65f6\u62e6\u622a\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u4f2a\u65e0\u5411\u56fe\u6846\u67b6\u7a81\u7834\u4e86\u4f20\u7edf\u5171\u8bc6\u7b97\u6cd5\u7684\u9650\u5236\uff0c\u6269\u5c55\u4e86\u89e3\u7a7a\u95f4\uff0c\u4e3a\u66f4\u7075\u6d3b\u7684\u5206\u5e03\u5f0f\u63a7\u5236\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.20021", "categories": ["cs.AI", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20021", "abs": "https://arxiv.org/abs/2509.20021", "authors": ["Tongtong Feng", "Xin Wang", "Yu-Gang Jiang", "Wenwu Zhu"], "title": "Embodied AI: From LLMs to World Models", "comment": "Accepted by IEEE CASM", "summary": "Embodied Artificial Intelligence (AI) is an intelligent system paradigm for\nachieving Artificial General Intelligence (AGI), serving as the cornerstone for\nvarious applications and driving the evolution from cyberspace to physical\nsystems. Recent breakthroughs in Large Language Models (LLMs) and World Models\n(WMs) have drawn significant attention for embodied AI. On the one hand, LLMs\nempower embodied AI via semantic reasoning and task decomposition, bringing\nhigh-level natural language instructions and low-level natural language actions\ninto embodied cognition. On the other hand, WMs empower embodied AI by building\ninternal representations and future predictions of the external world,\nfacilitating physical law-compliant embodied interactions. As such, this paper\ncomprehensively explores the literature in embodied AI from basics to advances,\ncovering both LLM driven and WM driven works. In particular, we first present\nthe history, key technologies, key components, and hardware systems of embodied\nAI, as well as discuss its development via looking from unimodal to multimodal\nangle. We then scrutinize the two burgeoning fields of embodied AI, i.e.,\nembodied AI with LLMs/multimodal LLMs (MLLMs) and embodied AI with WMs,\nmeticulously delineating their indispensable roles in end-to-end embodied\ncognition and physical laws-driven embodied interactions. Building upon the\nabove advances, we further share our insights on the necessity of the joint\nMLLM-WM driven embodied AI architecture, shedding light on its profound\nsignificance in enabling complex tasks within physical worlds. In addition, we\nexamine representative applications of embodied AI, demonstrating its wide\napplicability in real-world scenarios. Last but not least, we point out future\nresearch directions of embodied AI that deserve further investigation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5177\u8eab\u4eba\u5de5\u667a\u80fd\uff08Embodied AI\uff09\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u4e16\u754c\u6a21\u578b\uff08WMs\uff09\u5728\u5177\u8eabAI\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u8054\u5408MLLM-WM\u67b6\u6784\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u5177\u8eabAI\u662f\u5b9e\u73b0\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u7684\u91cd\u8981\u8303\u5f0f\uff0c\u8fd1\u5e74\u6765LLMs\u548cWMs\u7684\u7a81\u7834\u4e3a\u5177\u8eabAI\u5e26\u6765\u4e86\u65b0\u7684\u53d1\u5c55\u673a\u9047\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u8be5\u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\u548c\u672a\u6765\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4ece\u57fa\u7840\u5230\u524d\u6cbf\u5168\u9762\u5206\u6790\u5177\u8eabAI\u7684\u53d1\u5c55\u5386\u7a0b\u3001\u5173\u952e\u6280\u672f\u3001\u6838\u5fc3\u7ec4\u4ef6\u548c\u786c\u4ef6\u7cfb\u7edf\uff0c\u7279\u522b\u5173\u6ce8LLM\u9a71\u52a8\u548cWM\u9a71\u52a8\u7684\u5177\u8eabAI\u7814\u7a76\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u5177\u8eabAI\u4ece\u5355\u6a21\u6001\u5230\u591a\u6a21\u6001\u7684\u53d1\u5c55\u8def\u5f84\uff0c\u9610\u660e\u4e86LLMs\u5728\u8bed\u4e49\u63a8\u7406\u548c\u4efb\u52a1\u5206\u89e3\u3001WMs\u5728\u4e16\u754c\u8868\u793a\u548c\u7269\u7406\u89c4\u5f8b\u9884\u6d4b\u65b9\u9762\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u4e86\u8054\u5408MLLM-WM\u9a71\u52a8\u7684\u5177\u8eabAI\u67b6\u6784\u662f\u5b9e\u73b0\u590d\u6742\u7269\u7406\u4e16\u754c\u4efb\u52a1\u7684\u5173\u952e\u65b9\u5411\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u95ee\u9898\u3002"}}
{"id": "2509.19597", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.19597", "abs": "https://arxiv.org/abs/2509.19597", "authors": ["Sander Tonkens", "Nikhil Uday Shinde", "Azra Begzadi\u0107", "Michael C. Yip", "Jorge Cort\u00e9s", "Sylvia L. Herbert"], "title": "From Space to Time: Enabling Adaptive Safety with Learned Value Functions via Disturbance Recasting", "comment": "The first three authors contributed equally. This work has been\n  accepted for publication at the Conference on Robot Learning", "summary": "The widespread deployment of autonomous systems in safety-critical\nenvironments such as urban air mobility hinges on ensuring reliable,\nperformant, and safe operation under varying environmental conditions. One such\napproach, value function-based safety filters, minimally modifies a nominal\ncontroller to ensure safety. Recent advances leverage offline learned value\nfunctions to scale these safety filters to high-dimensional systems. However,\nthese methods assume detailed priors on all possible sources of model mismatch,\nin the form of disturbances in the environment -- information that is rarely\navailable in real world settings. Even in well-mapped environments like urban\ncanyons or industrial sites, drones encounter complex, spatially-varying\ndisturbances arising from payload-drone interaction, turbulent airflow, and\nother environmental factors. We introduce SPACE2TIME, which enables safe and\nadaptive deployment of offline-learned safety filters under unknown,\nspatially-varying disturbances. The key idea is to reparameterize spatial\nvariations in disturbance as temporal variations, enabling the use of\nprecomputed value functions during online operation. We validate SPACE2TIME on\na quadcopter through extensive simulations and hardware experiments,\ndemonstrating significant improvement over baselines.", "AI": {"tldr": "SPACE2TIME\u662f\u4e00\u79cd\u5b89\u5168\u8fc7\u6ee4\u5668\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u4e86\u89e3\u7a7a\u95f4\u53d8\u5316\u6270\u52a8\u7684\u60c5\u51b5\u4e0b\uff0c\u5b89\u5168\u5730\u90e8\u7f72\u79bb\u7ebf\u5b66\u4e60\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4ef7\u503c\u51fd\u6570\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\u5047\u8bbe\u5df2\u77e5\u6240\u6709\u53ef\u80fd\u7684\u6a21\u578b\u4e0d\u5339\u914d\u6e90\uff08\u5982\u73af\u5883\u6270\u52a8\uff09\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u8fd9\u79cd\u4fe1\u606f\u5f88\u5c11\u53ef\u7528\u3002\u65e0\u4eba\u673a\u5728\u590d\u6742\u73af\u5883\u4e2d\u4f1a\u9047\u5230\u7a7a\u95f4\u53d8\u5316\u7684\u6270\u52a8\uff0c\u5982\u8f7d\u8377-\u65e0\u4eba\u673a\u4ea4\u4e92\u3001\u6e4d\u6d41\u7b49\u3002", "method": "SPACE2TIME\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5c06\u6270\u52a8\u7684\u7a7a\u95f4\u53d8\u5316\u91cd\u65b0\u53c2\u6570\u5316\u4e3a\u65f6\u95f4\u53d8\u5316\uff0c\u4ece\u800c\u5728\u5728\u7ebf\u64cd\u4f5c\u671f\u95f4\u80fd\u591f\u4f7f\u7528\u9884\u8ba1\u7b97\u7684\u4ef7\u503c\u51fd\u6570\u3002", "result": "\u901a\u8fc7\u5728\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u7684\u4eff\u771f\u548c\u786c\u4ef6\u5b9e\u9a8c\u9a8c\u8bc1\uff0cSPACE2TIME\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u672a\u77e5\u3001\u7a7a\u95f4\u53d8\u5316\u6270\u52a8\u73af\u5883\u4e0b\u5b89\u5168\u90e8\u7f72\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.20330", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.20330", "abs": "https://arxiv.org/abs/2509.20330", "authors": ["Filippos Fotiadis", "Quentin Rommel", "Gregory Falco", "Ufuk Topcu"], "title": "Adversarial Pursuits in Cislunar Space", "comment": "17 pages, 9 figures", "summary": "Cislunar space is becoming a critical domain for future lunar and\ninterplanetary missions, yet its remoteness, sparse infrastructure, and\nunstable dynamics create single points of failure. Adversaries in cislunar\norbits can exploit these vulnerabilities to pursue and jam co-located\ncommunication relays, potentially severing communications between lunar\nmissions and the Earth. We study a pursuit-evasion scenario between two\nspacecraft in a cislunar orbit, where the evader must avoid a pursuer-jammer\nwhile remaining close to its nominal trajectory. We model the evader-pursuer\ninteraction as a zero-sum adversarial differential game cast in the circular\nrestricted three-body problem. This formulation incorporates critical aspects\nof cislunar orbital dynamics, including autonomous adjustment of the reference\norbit phasing to enable aggressive evading maneuvers, and shaping of the\nevader's cost with the orbit's stable and unstable manifolds. We solve the\nresulting nonlinear game locally using a continuous-time differential dynamic\nprogramming variant, which iteratively applies linear-quadratic approximations\nto the Hamilton-Jacobi-Isaacs equation. We simulate the evader's behavior\nagainst both a worst-case and a linear-quadratic pursuer. Our results pave the\nway for securing future missions in cislunar space against emerging cyber\nthreats.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5730\u6708\u7a7a\u95f4\u4e2d\u7684\u8ffd\u9003\u535a\u5f08\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u4f53\u95ee\u9898\u7684\u5bf9\u6297\u6027\u5fae\u5206\u535a\u5f08\u6a21\u578b\uff0c\u7528\u4e8e\u4fdd\u62a4\u6708\u7403\u4efb\u52a1\u901a\u4fe1\u514d\u53d7\u654c\u65b9\u822a\u5929\u5668\u7684\u5e72\u6270\u548c\u8ffd\u51fb\u3002", "motivation": "\u5730\u6708\u7a7a\u95f4\u5bf9\u672a\u6765\u7684\u6708\u7403\u548c\u661f\u9645\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u504f\u8fdc\u6027\u3001\u57fa\u7840\u8bbe\u65bd\u7a00\u758f\u548c\u4e0d\u7a33\u5b9a\u52a8\u529b\u5b66\u7279\u6027\u5bb9\u6613\u9020\u6210\u5355\u70b9\u6545\u969c\u3002\u654c\u65b9\u53ef\u4ee5\u5229\u7528\u8fd9\u4e9b\u6f0f\u6d1e\u8ffd\u51fb\u548c\u5e72\u6270\u901a\u4fe1\u4e2d\u7ee7\u5668\uff0c\u5207\u65ad\u6708\u7403\u4efb\u52a1\u4e0e\u5730\u7403\u7684\u901a\u4fe1\u3002", "method": "\u5c06\u8ffd\u9003\u95ee\u9898\u5efa\u6a21\u4e3a\u96f6\u548c\u5bf9\u6297\u6027\u5fae\u5206\u535a\u5f08\uff0c\u91c7\u7528\u5706\u5f62\u9650\u5236\u6027\u4e09\u4f53\u95ee\u9898\u6846\u67b6\u3002\u65b9\u6cd5\u5305\u62ec\u81ea\u4e3b\u8c03\u6574\u53c2\u8003\u8f68\u9053\u76f8\u4f4d\u4ee5\u5b9e\u73b0\u6fc0\u8fdb\u89c4\u907f\u673a\u52a8\uff0c\u5229\u7528\u8f68\u9053\u7684\u7a33\u5b9a\u548c\u4e0d\u7a33\u5b9a\u6d41\u5f62\u6765\u5851\u9020\u9003\u9038\u8005\u7684\u6210\u672c\u51fd\u6570\uff0c\u5e76\u4f7f\u7528\u8fde\u7eed\u65f6\u95f4\u5fae\u5206\u52a8\u6001\u89c4\u5212\u53d8\u4f53\u6c42\u89e3\u975e\u7ebf\u6027\u535a\u5f08\u3002", "result": "\u6a21\u62df\u4e86\u9003\u9038\u8005\u5bf9\u6297\u6700\u574f\u60c5\u51b5\u548c\u7ebf\u6027\u4e8c\u6b21\u8ffd\u51fb\u8005\u7684\u884c\u4e3a\u3002\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u5730\u6708\u7a7a\u95f4\u4efb\u52a1\u514d\u53d7\u65b0\u5174\u7f51\u7edc\u5a01\u80c1\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4fdd\u62a4\u672a\u6765\u5730\u6708\u7a7a\u95f4\u4efb\u52a1\u514d\u53d7\u7f51\u7edc\u5a01\u80c1\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u63d0\u51fa\u7684\u535a\u5f08\u8bba\u6846\u67b6\u80fd\u591f\u5e94\u5bf9\u5730\u6708\u8f68\u9053\u4e2d\u7684\u52a8\u6001\u5bf9\u6297\u573a\u666f\u3002"}}
{"id": "2509.20067", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20067", "abs": "https://arxiv.org/abs/2509.20067", "authors": ["Wenliang Li", "Rui Yan", "Xu Zhang", "Li Chen", "Hongji Zhu", "Jing Zhao", "Junjun Li", "Mengru Li", "Wei Cao", "Zihang Jiang", "Wei Wei", "Kun Zhang", "Shaohua Kevin Zhou"], "title": "MACD: Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM", "comment": null, "summary": "Large language models (LLMs) have demonstrated notable potential in medical\napplications, yet they face substantial challenges in handling complex\nreal-world clinical diagnoses using conventional prompting methods. Current\nprompt engineering and multi-agent approaches typically optimize isolated\ninferences, neglecting the accumulation of reusable clinical experience. To\naddress this, this study proposes a novel Multi-Agent Clinical Diagnosis (MACD)\nframework, which allows LLMs to self-learn clinical knowledge via a multi-agent\npipeline that summarizes, refines, and applies diagnostic insights. It mirrors\nhow physicians develop expertise through experience, enabling more focused and\naccurate diagnosis on key disease-specific cues. We further extend it to a\nMACD-human collaborative workflow, where multiple LLM-based diagnostician\nagents engage in iterative consultations, supported by an evaluator agent and\nhuman oversight for cases where agreement is not reached. Evaluated on 4,390\nreal-world patient cases across seven diseases using diverse open-source LLMs\n(Llama-3.1 8B/70B, DeepSeek-R1-Distill-Llama 70B), MACD significantly improves\nprimary diagnostic accuracy, outperforming established clinical guidelines with\ngains up to 22.3% (MACD). On the subset of the data, it achieves performance on\npar with or exceeding that of human physicians (up to 16% improvement over\nphysicians-only diagnosis). Additionally, on the MACD-human workflow, it\nachieves an 18.6% improvement compared to physicians-only diagnosis. Moreover,\nself-learned knowledge exhibits strong cross-model stability, transferability,\nand model-specific personalization, while the system can generate traceable\nrationales, enhancing explainability. Consequently, this work presents a\nscalable self-learning paradigm for LLM-assisted diagnosis, bridging the gap\nbetween the intrinsic knowledge of LLMs and real-world clinical practice.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u4e34\u5e8a\u8bca\u65ad\u6846\u67b6MACD\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u8ba9LLM\u81ea\u6211\u5b66\u4e60\u4e34\u5e8a\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u57284390\u4e2a\u771f\u5b9e\u75c5\u4f8b\u4e0a\u8868\u73b0\u4f18\u4e8e\u4e34\u5e8a\u6307\u5357\u548c\u4eba\u7c7b\u533b\u751f\u3002", "motivation": "\u4f20\u7edf\u63d0\u793a\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u8bca\u65ad\u65f6\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f18\u5316\u5b64\u7acb\u63a8\u7406\u800c\u5ffd\u7565\u4e86\u53ef\u91cd\u7528\u4e34\u5e8a\u7ecf\u9a8c\u7684\u79ef\u7d2f\u3002", "method": "\u63d0\u51faMACD\u6846\u67b6\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff08\u603b\u7ed3\u3001\u63d0\u70bc\u3001\u5e94\u7528\u8bca\u65ad\u89c1\u89e3\uff09\u8ba9LLM\u81ea\u6211\u5b66\u4e60\u4e34\u5e8a\u77e5\u8bc6\uff0c\u5e76\u6269\u5c55\u5230MACD-\u4eba\u7c7b\u534f\u4f5c\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u4e03\u79cd\u75be\u75c5\u76844390\u4e2a\u75c5\u4f8b\u4e0a\uff0cMACD\u663e\u8457\u63d0\u9ad8\u4e3b\u8981\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u6700\u9ad8\u63d0\u534722.3%\uff0c\u5728\u67d0\u4e9b\u5b50\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u4eba\u7c7b\u533b\u751f\uff08\u6700\u9ad816%\u63d0\u5347\uff09\uff0cMACD-\u4eba\u7c7b\u5de5\u4f5c\u6d41\u76f8\u6bd4\u7eaf\u533b\u751f\u8bca\u65ad\u63d0\u534718.6%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aLLM\u8f85\u52a9\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u81ea\u6211\u5b66\u4e60\u8303\u5f0f\uff0c\u5f25\u5408\u4e86LLM\u5185\u5728\u77e5\u8bc6\u4e0e\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.19610", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19610", "abs": "https://arxiv.org/abs/2509.19610", "authors": ["Qingxi Meng", "Emiliano Flores", "Carlos Quintero-Pe\u00f1a", "Peizhu Qian", "Zachary Kingston", "Shannan K. Hamlin", "Vaibhav Unhelkar", "Lydia E. Kavraki"], "title": "Look as You Leap: Planning Simultaneous Motion and Perception for High-DOF Robots", "comment": "16 pages, 10 figures, under review", "summary": "In this work, we address the problem of planning robot motions for a\nhigh-degree-of-freedom (DoF) robot that effectively achieves a given perception\ntask while the robot and the perception target move in a dynamic environment.\nAchieving navigation and perception tasks simultaneously is challenging, as\nthese objectives often impose conflicting requirements. Existing methods that\ncompute motion under perception constraints fail to account for obstacles, are\ndesigned for low-DoF robots, or rely on simplified models of perception.\nFurthermore, in dynamic real-world environments, robots must replan and react\nquickly to changes and directly evaluating the quality of perception (e.g.,\nobject detection confidence) is often expensive or infeasible at runtime. This\nproblem is especially important in human-centered environments such as homes\nand hospitals, where effective perception is essential for safe and reliable\noperation. To address these challenges, we propose a GPU-parallelized\nperception-score-guided probabilistic roadmap planner with a neural surrogate\nmodel (PS-PRM). The planner explicitly incorporates the estimated quality of a\nperception task into motion planning for high-DoF robots. Our method uses a\nlearned model to approximate perception scores and leverages GPU parallelism to\nenable efficient online replanning in dynamic settings. We demonstrate that our\nplanner, evaluated on high-DoF robots, outperforms baseline methods in both\nstatic and dynamic environments in both simulation and real-robot experiments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGPU\u5e76\u884c\u5316\u7684\u611f\u77e5\u8bc4\u5206\u5f15\u5bfc\u6982\u7387\u8def\u7ebf\u56fe\u89c4\u5212\u5668\uff08PS-PRM\uff09\uff0c\u7528\u4e8e\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8fd0\u52a8\u89c4\u5212\uff0c\u540c\u65f6\u8003\u8651\u611f\u77e5\u4efb\u52a1\u8d28\u91cf\u3002", "motivation": "\u5728\u52a8\u6001\u73af\u5883\u4e2d\uff0c\u673a\u5668\u4eba\u9700\u8981\u540c\u65f6\u5b8c\u6210\u5bfc\u822a\u548c\u611f\u77e5\u4efb\u52a1\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4e0d\u8003\u8651\u969c\u788d\u7269\uff0c\u8981\u4e48\u53ea\u9002\u7528\u4e8e\u4f4e\u81ea\u7531\u5ea6\u673a\u5668\u4eba\uff0c\u6216\u8005\u4f7f\u7528\u7b80\u5316\u7684\u611f\u77e5\u6a21\u578b\u3002\u5728\u4eba\u7c7b\u4e2d\u5fc3\u73af\u5883\u4e2d\uff0c\u6709\u6548\u7684\u611f\u77e5\u5bf9\u4e8e\u5b89\u5168\u53ef\u9760\u64cd\u4f5c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u5b66\u4e60\u7684\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u6a21\u578b\u6765\u8fd1\u4f3c\u611f\u77e5\u8bc4\u5206\uff0c\u5e76\u5229\u7528GPU\u5e76\u884c\u5316\u5b9e\u73b0\u9ad8\u6548\u7684\u5728\u7ebf\u91cd\u89c4\u5212\u3002PS-PRM\u89c4\u5212\u5668\u5c06\u611f\u77e5\u4efb\u52a1\u8d28\u91cf\u4f30\u8ba1\u663e\u5f0f\u5730\u7eb3\u5165\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u89c4\u5212\u4e2d\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9759\u6001\u548c\u52a8\u6001\u73af\u5883\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u63d0\u51fa\u7684PS-PRM\u89c4\u5212\u5668\u80fd\u591f\u6709\u6548\u89e3\u51b3\u52a8\u6001\u73af\u5883\u4e2d\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u7684\u611f\u77e5\u5f15\u5bfc\u8fd0\u52a8\u89c4\u5212\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u611f\u77e5\u8d28\u91cf\u548c\u8fd0\u52a8\u6548\u7387\u7684\u5e73\u8861\u3002"}}
{"id": "2509.20338", "categories": ["eess.SY", "cs.AI", "cs.MA", "cs.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2509.20338", "abs": "https://arxiv.org/abs/2509.20338", "authors": ["Umer Siddique", "Abhinav Sinha", "Yongcan Cao"], "title": "Adaptive Event-Triggered Policy Gradient for Multi-Agent Reinforcement Learning", "comment": null, "summary": "Conventional multi-agent reinforcement learning (MARL) methods rely on\ntime-triggered execution, where agents sample and communicate actions at fixed\nintervals. This approach is often computationally expensive and\ncommunication-intensive. To address this limitation, we propose ET-MAPG\n(Event-Triggered Multi-Agent Policy Gradient reinforcement learning), a\nframework that jointly learns an agent's control policy and its\nevent-triggering policy. Unlike prior work that decouples these mechanisms,\nET-MAPG integrates them into a unified learning process, enabling agents to\nlearn not only what action to take but also when to execute it. For scenarios\nwith inter-agent communication, we introduce AET-MAPG, an attention-based\nvariant that leverages a self-attention mechanism to learn selective\ncommunication patterns. AET-MAPG empowers agents to determine not only when to\ntrigger an action but also with whom to communicate and what information to\nexchange, thereby optimizing coordination. Both methods can be integrated with\nany policy gradient MARL algorithm. Extensive experiments across diverse MARL\nbenchmarks demonstrate that our approaches achieve performance comparable to\nstate-of-the-art, time-triggered baselines while significantly reducing both\ncomputational load and communication overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86ET-MAPG\u548cAET-MAPG\u4e24\u79cd\u4e8b\u4ef6\u89e6\u53d1\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u63a7\u5236\u7b56\u7565\u548c\u4e8b\u4ef6\u89e6\u53d1\u7b56\u7565\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u91c7\u7528\u65f6\u95f4\u89e6\u53d1\u6267\u884c\uff0c\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\u9ad8\u6602\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002", "method": "ET-MAPG\u7edf\u4e00\u5b66\u4e60\u63a7\u5236\u7b56\u7565\u548c\u4e8b\u4ef6\u89e6\u53d1\u7b56\u7565\uff1bAET-MAPG\u5f15\u5165\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u9009\u62e9\u6027\u901a\u4fe1\u3002\u4e24\u79cd\u65b9\u6cd5\u53ef\u4e0e\u4efb\u4f55\u7b56\u7565\u68af\u5ea6MARL\u7b97\u6cd5\u96c6\u6210\u3002", "result": "\u5728\u591a\u79cdMARL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u89e6\u53d1\u57fa\u7ebf\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d1f\u8f7d\u548c\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "\u4e8b\u4ef6\u89e6\u53d1\u673a\u5236\u662f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u6709\u6548\u4f18\u5316\u7b56\u7565\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u6548\u7387\u3002"}}
{"id": "2509.20095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20095", "abs": "https://arxiv.org/abs/2509.20095", "authors": ["Aymeric Vellinger", "Nemanja Antonic", "Elio Tuci"], "title": "From Pheromones to Policies: Reinforcement Learning for Engineered Biological Swarms", "comment": "Contribution to the 9th International Symposium on Swarm Behavior and\n  Bio-Inspired Robotics 2025", "summary": "Swarm intelligence emerges from decentralised interactions among simple\nagents, enabling collective problem-solving. This study establishes a\ntheoretical equivalence between pheromone-mediated aggregation in \\celeg\\ and\nreinforcement learning (RL), demonstrating how stigmergic signals function as\ndistributed reward mechanisms. We model engineered nematode swarms performing\nforaging tasks, showing that pheromone dynamics mathematically mirror\ncross-learning updates, a fundamental RL algorithm. Experimental validation\nwith data from literature confirms that our model accurately replicates\nempirical \\celeg\\ foraging patterns under static conditions. In dynamic\nenvironments, persistent pheromone trails create positive feedback loops that\nhinder adaptation by locking swarms into obsolete choices. Through\ncomputational experiments in multi-armed bandit scenarios, we reveal that\nintroducing a minority of exploratory agents insensitive to pheromones restores\ncollective plasticity, enabling rapid task switching. This behavioural\nheterogeneity balances exploration-exploitation trade-offs, implementing\nswarm-level extinction of outdated strategies. Our results demonstrate that\nstigmergic systems inherently encode distributed RL processes, where\nenvironmental signals act as external memory for collective credit assignment.\nBy bridging synthetic biology with swarm robotics, this work advances\nprogrammable living systems capable of resilient decision-making in volatile\nenvironments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u79c0\u4e3d\u9690\u6746\u7ebf\u866b\u4fe1\u606f\u7d20\u4ecb\u5bfc\u7684\u805a\u96c6\u884c\u4e3a\u4e0e\u5f3a\u5316\u5b66\u4e60\u4e4b\u95f4\u7684\u7406\u8bba\u7b49\u4ef7\u6027\uff0c\u63ed\u793a\u4e86\u4fe1\u606f\u7d20\u52a8\u6001\u5982\u4f55\u6570\u5b66\u4e0a\u53cd\u6620\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u8ba1\u7b97\u5b9e\u9a8c\u5c55\u793a\u4e86\u63a2\u7d22\u6027\u4e2a\u4f53\u5982\u4f55\u6062\u590d\u7fa4\u4f53\u9002\u5e94\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u7406\u89e3\u7fa4\u4f53\u667a\u80fd\u5982\u4f55\u901a\u8fc7\u5206\u6563\u7684\u7b80\u5355\u4e2a\u4f53\u4ea4\u4e92\u5b9e\u73b0\u96c6\u4f53\u95ee\u9898\u89e3\u51b3\uff0c\u7279\u522b\u662f\u63a2\u7d22\u4fe1\u606f\u7d20\u4fe1\u53f7\u5982\u4f55\u4f5c\u4e3a\u5206\u5e03\u5f0f\u5956\u52b1\u673a\u5236\uff0c\u4ee5\u53ca\u5982\u4f55\u5c06\u5408\u6210\u751f\u7269\u5b66\u4e0e\u7fa4\u4f53\u673a\u5668\u4eba\u5b66\u7ed3\u5408\u6765\u5f00\u53d1\u80fd\u591f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u884c\u5f39\u6027\u51b3\u7b56\u7684\u53ef\u7f16\u7a0b\u751f\u547d\u7cfb\u7edf\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5efa\u7acb\u5de5\u7a0b\u5316\u7ebf\u866b\u7fa4\u4f53\u7684\u89c5\u98df\u4efb\u52a1\u6a21\u578b\uff0c\u5c06\u4fe1\u606f\u7d20\u52a8\u6001\u4e0e\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4ea4\u53c9\u5b66\u4e60\u66f4\u65b0\u8fdb\u884c\u6570\u5b66\u6620\u5c04\uff0c\u4f7f\u7528\u6587\u732e\u6570\u636e\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5e76\u5728\u591a\u81c2\u8001\u864e\u673a\u573a\u666f\u4e2d\u8fdb\u884c\u8ba1\u7b97\u5b9e\u9a8c\u6765\u7814\u7a76\u63a2\u7d22-\u5229\u7528\u6743\u8861\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\u6a21\u578b\u80fd\u591f\u51c6\u786e\u590d\u73b0\u9759\u6001\u6761\u4ef6\u4e0b\u7684\u7ebf\u866b\u89c5\u98df\u6a21\u5f0f\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u6301\u4e45\u7684\u4fe1\u606f\u7d20\u8f68\u8ff9\u4f1a\u963b\u788d\u9002\u5e94\u6027\uff0c\u4f46\u5f15\u5165\u5bf9\u4fe1\u606f\u7d20\u4e0d\u654f\u611f\u7684\u63a2\u7d22\u6027\u4e2a\u4f53\u53ef\u4ee5\u6062\u590d\u96c6\u4f53\u53ef\u5851\u6027\uff0c\u5b9e\u73b0\u5feb\u901f\u4efb\u52a1\u5207\u6362\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\u4fe1\u606f\u7d20\u7cfb\u7edf\u56fa\u6709\u5730\u7f16\u7801\u4e86\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u73af\u5883\u4fe1\u53f7\u4f5c\u4e3a\u96c6\u4f53\u4fe1\u7528\u5206\u914d\u7684\u5916\u90e8\u8bb0\u5fc6\uff0c\u8fd9\u9879\u5de5\u4f5c\u63a8\u8fdb\u4e86\u80fd\u591f\u5728\u6613\u53d8\u73af\u5883\u4e2d\u8fdb\u884c\u5f39\u6027\u51b3\u7b56\u7684\u53ef\u7f16\u7a0b\u751f\u547d\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.19626", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19626", "abs": "https://arxiv.org/abs/2509.19626", "authors": ["Ryan Punamiya", "Dhruv Patel", "Patcharapong Aphiwetsa", "Pranav Kuppili", "Lawrence Y. Zhu", "Simar Kareer", "Judy Hoffman", "Danfei Xu"], "title": "EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data", "comment": "Accepted at 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025) and Oral at Conference on Robot Learning (CoRL 2025)", "summary": "Egocentric human experience data presents a vast resource for scaling up\nend-to-end imitation learning for robotic manipulation. However, significant\ndomain gaps in visual appearance, sensor modalities, and kinematics between\nhuman and robot impede knowledge transfer. This paper presents EgoBridge, a\nunified co-training framework that explicitly aligns the policy latent spaces\nbetween human and robot data using domain adaptation. Through a measure of\ndiscrepancy on the joint policy latent features and actions based on Optimal\nTransport (OT), we learn observation representations that not only align\nbetween the human and robot domain but also preserve the action-relevant\ninformation critical for policy learning. EgoBridge achieves a significant\nabsolute policy success rate improvement by 44% over human-augmented\ncross-embodiment baselines in three real-world single-arm and bimanual\nmanipulation tasks. EgoBridge also generalizes to new objects, scenes, and\ntasks seen only in human data, where baselines fail entirely. Videos and\nadditional information can be found at https://ego-bridge.github.io", "AI": {"tldr": "EgoBridge\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u534f\u540c\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u5bf9\u9f50\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u6570\u636e\u7684\u7b56\u7565\u6f5c\u5728\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u5229\u7528\u4eba\u7c7b\u81ea\u6211\u4e2d\u5fc3\u4f53\u9a8c\u6570\u636e\u6269\u5c55\u7aef\u5230\u7aef\u6a21\u4eff\u5b66\u4e60\uff0c\u4f46\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u4e4b\u95f4\u5b58\u5728\u89c6\u89c9\u5916\u89c2\u3001\u4f20\u611f\u5668\u6a21\u6001\u548c\u8fd0\u52a8\u5b66\u7684\u663e\u8457\u9886\u57df\u5dee\u8ddd\uff0c\u963b\u788d\u4e86\u77e5\u8bc6\u8fc1\u79fb\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\uff08OT\uff09\u7684\u8054\u5408\u7b56\u7565\u6f5c\u5728\u7279\u5f81\u548c\u52a8\u4f5c\u5dee\u5f02\u5ea6\u91cf\uff0c\u5b66\u4e60\u65e2\u80fd\u5728\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u9886\u57df\u95f4\u5bf9\u9f50\u53c8\u80fd\u4fdd\u7559\u7b56\u7565\u5b66\u4e60\u5173\u952e\u52a8\u4f5c\u76f8\u5173\u4fe1\u606f\u7684\u89c2\u5bdf\u8868\u793a\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u5355\u81c2\u548c\u53cc\u624b\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0cEgoBridge\u76f8\u6bd4\u4eba\u7c7b\u589e\u5f3a\u7684\u8de8\u5177\u8eab\u57fa\u7ebf\u5b9e\u73b0\u4e8644%\u7684\u7edd\u5bf9\u7b56\u7565\u6210\u529f\u7387\u63d0\u5347\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u4ec5\u5728\u4eba\u7c7b\u6570\u636e\u4e2d\u51fa\u73b0\u7684\u65b0\u7269\u4f53\u3001\u573a\u666f\u548c\u4efb\u52a1\u3002", "conclusion": "EgoBridge\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4eba\u7c7b-\u673a\u5668\u4eba\u9886\u57df\u5dee\u8ddd\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4ece\u4eba\u7c7b\u6570\u636e\u5230\u673a\u5668\u4eba\u7b56\u7565\u7684\u77e5\u8bc6\u8fc1\u79fb\uff0c\u5728\u590d\u6742\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.20355", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.20355", "abs": "https://arxiv.org/abs/2509.20355", "authors": ["Chih-Yuan Chiu"], "title": "Approximately Optimal Toll Design for Efficiency and Equity in Arc-Based Traffic Assignment Models", "comment": null, "summary": "Congestion pricing policies have emerged as promising traffic management\ntools to alleviate traffic congestion caused by travelers' selfish routing\nbehaviors. The core principle behind deploying tolls is to impose monetary\ncosts on frequently overcrowded routes, to incentivize self-interested\ntravelers to select less easily congested routes. Recent literature has focused\non toll design based on arc-based traffic assignment models (TAMs), which\ncharacterize commuters as traveling through a traffic network by successively\nselecting an outgoing arc from every intermediate node along their journey.\nHowever, existing tolling mechanisms predicated on arc-based TAMs often target\nthe design of a single congestion-minimizing toll, ignoring crucial fairness\nconsiderations, such as the financial impact of high congestion fees on\nlow-income travelers. To address these shortcomings, in this paper, we pose the\ndual considerations of efficiency and equity in traffic routing as bilevel\noptimization problems. Since such problems are in general computationally\nintractable to solve precisely, we construct a linear program approximation by\nintroducing a polytope approximation for the set of all tolls that induce\ncongestion-minimizing traffic flow patterns. Finally, we provide numerical\nresults that validate our theoretical conclusions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8003\u8651\u6548\u7387\u548c\u516c\u5e73\u6027\u7684\u53cc\u5c42\u4f18\u5316\u95ee\u9898\u6765\u89e3\u51b3\u4ea4\u901a\u62e5\u5835\u5b9a\u4ef7\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u9762\u4f53\u8fd1\u4f3c\u65b9\u6cd5\u6784\u5efa\u7ebf\u6027\u89c4\u5212\u8fd1\u4f3c\uff0c\u5e76\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u8bba\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5f27\u7684\u4ea4\u901a\u5206\u914d\u6a21\u578b\u7684\u62e5\u5835\u5b9a\u4ef7\u673a\u5236\u901a\u5e38\u53ea\u5173\u6ce8\u8bbe\u8ba1\u5355\u4e00\u7684\u6700\u5c0f\u5316\u62e5\u5835\u6536\u8d39\uff0c\u5ffd\u7565\u4e86\u4f4e\u6536\u5165\u65c5\u884c\u8005\u9762\u4e34\u9ad8\u62e5\u5835\u8d39\u7528\u7684\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u5c06\u6548\u7387\u548c\u516c\u5e73\u6027\u7684\u53cc\u91cd\u8003\u8651\u6784\u5efa\u4e3a\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff0c\u5f15\u5165\u591a\u9762\u4f53\u8fd1\u4f3c\u6765\u8fd1\u4f3c\u6240\u6709\u80fd\u8bf1\u5bfc\u6700\u5c0f\u5316\u62e5\u5835\u4ea4\u901a\u6d41\u6a21\u5f0f\u7684\u6536\u8d39\u96c6\u5408\uff0c\u6784\u5efa\u7ebf\u6027\u89c4\u5212\u8fd1\u4f3c\u3002", "result": "\u63d0\u4f9b\u4e86\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u7406\u8bba\u7ed3\u8bba\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u4ea4\u901a\u6548\u7387\u548c\u516c\u5e73\u6027\u3002", "conclusion": "\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u548c\u591a\u9762\u4f53\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u62e5\u5835\u5b9a\u4ef7\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u4e3a\u4ea4\u901a\u7ba1\u7406\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.20102", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20102", "abs": "https://arxiv.org/abs/2509.20102", "authors": ["Tong Nie", "Yuewen Mei", "Yihong Tang", "Junlin He", "Jie Sun", "Haotian Shi", "Wei Ma", "Jian Sun"], "title": "Steerable Adversarial Scenario Generation through Test-Time Preference Alignment", "comment": null, "summary": "Adversarial scenario generation is a cost-effective approach for safety\nassessment of autonomous driving systems. However, existing methods are often\nconstrained to a single, fixed trade-off between competing objectives such as\nadversariality and realism. This yields behavior-specific models that cannot be\nsteered at inference time, lacking the efficiency and flexibility to generate\ntailored scenarios for diverse training and testing requirements. In view of\nthis, we reframe the task of adversarial scenario generation as a\nmulti-objective preference alignment problem and introduce a new framework\nnamed \\textbf{S}teerable \\textbf{A}dversarial scenario \\textbf{GE}nerator\n(SAGE). SAGE enables fine-grained test-time control over the trade-off between\nadversariality and realism without any retraining. We first propose\nhierarchical group-based preference optimization, a data-efficient offline\nalignment method that learns to balance competing objectives by decoupling hard\nfeasibility constraints from soft preferences. Instead of training a fixed\nmodel, SAGE fine-tunes two experts on opposing preferences and constructs a\ncontinuous spectrum of policies at inference time by linearly interpolating\ntheir weights. We provide theoretical justification for this framework through\nthe lens of linear mode connectivity. Extensive experiments demonstrate that\nSAGE not only generates scenarios with a superior balance of adversariality and\nrealism but also enables more effective closed-loop training of driving\npolicies. Project page: https://tongnie.github.io/SAGE/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5f15\u5bfc\u7684\u5bf9\u6297\u573a\u666f\u751f\u6210\u6846\u67b6SAGE\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\u5b9e\u73b0\u5bf9\u6297\u6027\u548c\u771f\u5b9e\u6027\u7684\u7075\u6d3b\u6743\u8861\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5728\u63a8\u7406\u65f6\u63a7\u5236\u573a\u666f\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u6297\u573a\u666f\u751f\u6210\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u5355\u4e00\u56fa\u5b9a\u7684\u76ee\u6807\u6743\u8861\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u65e0\u6cd5\u6ee1\u8db3\u591a\u6837\u5316\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u5206\u7ec4\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u786c\u53ef\u884c\u6027\u7ea6\u675f\u548c\u8f6f\u504f\u597d\u6765\u5e73\u8861\u7ade\u4e89\u76ee\u6807\u3002\u8bad\u7ec3\u4e24\u4e2a\u504f\u597d\u76f8\u53cd\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u7ebf\u6027\u63d2\u503c\u6743\u91cd\u6784\u5efa\u8fde\u7eed\u7b56\u7565\u8c31\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSAGE\u4e0d\u4ec5\u80fd\u751f\u6210\u5bf9\u6297\u6027\u548c\u771f\u5b9e\u6027\u5e73\u8861\u66f4\u597d\u7684\u573a\u666f\uff0c\u8fd8\u80fd\u66f4\u6709\u6548\u5730\u8fdb\u884c\u9a7e\u9a76\u7b56\u7565\u7684\u95ed\u73af\u8bad\u7ec3\u3002", "conclusion": "SAGE\u6846\u67b6\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u9ad8\u6548\u7684\u5bf9\u6297\u573a\u666f\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2509.19636", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.19636", "abs": "https://arxiv.org/abs/2509.19636", "authors": ["Mahmoud Ali", "Hassan Jardali", "Youwei Yu", "Durgakant Pushp", "Lantao Liu"], "title": "Minimalistic Autonomous Stack for High-Speed Time-Trial Racing", "comment": "The data associated with this paper is available at\n  https://doi.org/10.5281/zenodo.17187680", "summary": "Autonomous racing has seen significant advancements, driven by competitions\nsuch as the Indy Autonomous Challenge (IAC) and the Abu Dhabi Autonomous Racing\nLeague (A2RL). However, developing an autonomous racing stack for a full-scale\ncar is often constrained by limited access to dedicated test tracks,\nrestricting opportunities for real-world validation. While previous work\ntypically requires extended development cycles and significant track time, this\npaper introduces a minimalistic autonomous racing stack for high-speed\ntime-trial racing that emphasizes rapid deployment and efficient system\nintegration with minimal on-track testing. The proposed stack was validated on\nreal speedways, achieving a top speed of 206 km/h within just 11 hours'\npractice run on the track with 325 km in total. Additionally, we present the\nsystem performance analysis, including tracking accuracy, vehicle dynamics, and\nsafety considerations, offering insights for teams seeking to rapidly develop\nand deploy an autonomous racing stack with limited track access.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6781\u7b80\u4e3b\u4e49\u7684\u9ad8\u901f\u8ba1\u65f6\u8d5b\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u5806\u6808\uff0c\u5f3a\u8c03\u5feb\u901f\u90e8\u7f72\u548c\u9ad8\u6548\u7cfb\u7edf\u96c6\u6210\uff0c\u4ec5\u9700\u6700\u5c11\u8d5b\u9053\u6d4b\u8bd5\u3002\u5728\u771f\u5b9e\u8d5b\u9053\u4e0a\u9a8c\u8bc1\uff0c\u4ec5\u752811\u5c0f\u65f6\u8d5b\u9053\u7ec3\u4e60\u5c31\u8fbe\u5230206\u516c\u91cc/\u5c0f\u65f6\u6700\u9ad8\u901f\u5ea6\u3002", "motivation": "\u5168\u5c3a\u5bf8\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u5f00\u53d1\u5e38\u53d7\u9650\u4e8e\u4e13\u7528\u6d4b\u8bd5\u8d5b\u9053\u8bbf\u95ee\u56f0\u96be\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u957f\u5f00\u53d1\u5468\u671f\u548c\u5927\u91cf\u8d5b\u9053\u65f6\u95f4\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6709\u9650\u8d5b\u9053\u8bbf\u95ee\u6761\u4ef6\u4e0b\u7684\u5feb\u901f\u5f00\u53d1\u90e8\u7f72\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6781\u7b80\u4e3b\u4e49\u8bbe\u8ba1\u7406\u5ff5\u7684\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u5806\u6808\uff0c\u4e13\u6ce8\u4e8e\u9ad8\u6548\u7cfb\u7edf\u96c6\u6210\u548c\u5feb\u901f\u90e8\u7f72\uff0c\u6700\u5c0f\u5316\u5b9e\u5730\u6d4b\u8bd5\u9700\u6c42\u3002", "result": "\u5728\u771f\u5b9e\u8d5b\u9053\u4e0a\u9a8c\u8bc1\u6210\u529f\uff0c\u4ec5\u752811\u5c0f\u65f6\u8d5b\u9053\u7ec3\u4e60\uff08\u603b\u91cc\u7a0b325\u516c\u91cc\uff09\u5c31\u5b9e\u73b0\u4e86206\u516c\u91cc/\u5c0f\u65f6\u7684\u6700\u9ad8\u901f\u5ea6\u3002\u63d0\u4f9b\u4e86\u5305\u62ec\u8ddf\u8e2a\u7cbe\u5ea6\u3001\u8f66\u8f86\u52a8\u529b\u5b66\u548c\u5b89\u5168\u8003\u8651\u5728\u5185\u7684\u7cfb\u7edf\u6027\u80fd\u5206\u6790\u3002", "conclusion": "\u8be5\u5806\u6808\u4e3a\u53d7\u9650\u4e8e\u8d5b\u9053\u8bbf\u95ee\u7684\u56e2\u961f\u63d0\u4f9b\u4e86\u5feb\u901f\u5f00\u53d1\u548c\u90e8\u7f72\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u5806\u6808\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5728\u6709\u9650\u6d4b\u8bd5\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.20105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20105", "abs": "https://arxiv.org/abs/2509.20105", "authors": ["Venkat Margapuri", "Garik Kazanjian", "Naren Kosaraju"], "title": "PEPS: Quantum-Inspired Reinforcement Learning for Coherent Reasoning Traces in LLMs", "comment": null, "summary": "Large Language Models (LLMs) often struggle with maintaining coherent\nmulti-step reasoning traces, particularly in tasks that require a structured\nlogical flow. This work introduces a quantum-inspired approach to address the\nchallenge by incorporating a fidelity-based reward derived from Projected\nEntangled Pair States (PEPS) into Proximal Policy Optimization. Unlike prior\napproaches that use direct supervision or contrastive objectives, the proposed\nmethod guides learning through structural consistency, offering a novel\napproach to enforce global coherence in generated reasoning traces. The\nproposed framework is evaluated using multiple coherence-determining metrics on\ndiverse datasets such as GSM8K, StrategyQA, and EntailmentBank spanning\narithmetic, intuitive, and entailment-based reasoning. Results show that the\nproposed quantum-inspired approach offers significant improvements over\nsupervised, contrastive, and pretrained baseline approaches, highlighting the\neffectiveness of quantum-inspired fidelity as a foundation to improve reasoning\ntrace coherence in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u542f\u53d1\u7684\u4fdd\u771f\u5ea6\u5956\u52b1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6295\u5f71\u7ea0\u7f20\u5bf9\u6001(PEPS)\u7ed3\u5408\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff0c\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8fde\u8d2f\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u96be\u4ee5\u4fdd\u6301\u8fde\u8d2f\u7684\u903b\u8f91\u6d41\u7a0b\uff0c\u73b0\u6709\u65b9\u6cd5\u5982\u76f4\u63a5\u76d1\u7763\u6216\u5bf9\u6bd4\u76ee\u6807\u65e0\u6cd5\u6709\u6548\u786e\u4fdd\u5168\u5c40\u4e00\u81f4\u6027\u3002", "method": "\u5c06\u91cf\u5b50\u542f\u53d1\u7684\u4fdd\u771f\u5ea6\u5956\u52b1\uff08\u6e90\u81ea\u6295\u5f71\u7ea0\u7f20\u5bf9\u6001PEPS\uff09\u6574\u5408\u5230\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u4e2d\uff0c\u901a\u8fc7\u7ed3\u6784\u4e00\u81f4\u6027\u6765\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u5728GSM8K\u3001StrategyQA\u548cEntailmentBank\u7b49\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u7b97\u672f\u3001\u76f4\u89c9\u548c\u8574\u542b\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u76d1\u7763\u5b66\u4e60\u3001\u5bf9\u6bd4\u5b66\u4e60\u548c\u9884\u8bad\u7ec3\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u91cf\u5b50\u542f\u53d1\u7684\u4fdd\u771f\u5ea6\u65b9\u6cd5\u4e3a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u7684\u8fde\u8d2f\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2509.19658", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19658", "abs": "https://arxiv.org/abs/2509.19658", "authors": ["Youngju Yoo", "Jiaheng Hu", "Yifeng Zhu", "Bo Liu", "Qiang Liu", "Roberto Mart\u00edn-Mart\u00edn", "Peter Stone"], "title": "RoboSSM: Scalable In-context Imitation Learning via State-Space Models", "comment": "8 pages, 11 figures", "summary": "In-context imitation learning (ICIL) enables robots to learn tasks from\nprompts consisting of just a handful of demonstrations. By eliminating the need\nfor parameter updates at deployment time, this paradigm supports few-shot\nadaptation to novel tasks. However, recent ICIL methods rely on Transformers,\nwhich have computational limitations and tend to underperform when handling\nlonger prompts than those seen during training. In this work, we introduce\nRoboSSM, a scalable recipe for in-context imitation learning based on\nstate-space models (SSM). Specifically, RoboSSM replaces Transformers with\nLonghorn -- a state-of-the-art SSM that provides linear-time inference and\nstrong extrapolation capabilities, making it well-suited for long-context\nprompts. We evaluate our approach on the LIBERO benchmark and compare it\nagainst strong Transformer-based ICIL baselines. Experiments show that RoboSSM\nextrapolates effectively to varying numbers of in-context demonstrations,\nyields high performance on unseen tasks, and remains robust in long-horizon\nscenarios. These results highlight the potential of SSMs as an efficient and\nscalable backbone for ICIL. Our code is available at\nhttps://github.com/youngjuY/RoboSSM.", "AI": {"tldr": "RoboSSM\u662f\u4e00\u79cd\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u7684\u53ef\u6269\u5c55\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528Longhorn SSM\u66ff\u4ee3Transformer\u6765\u89e3\u51b3\u8ba1\u7b97\u9650\u5236\u548c\u957f\u63d0\u793a\u6027\u80fd\u4e0b\u964d\u95ee\u9898", "motivation": "\u73b0\u6709\u7684\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56Transformer\uff0c\u4f46Transformer\u5b58\u5728\u8ba1\u7b97\u9650\u5236\uff0c\u4e14\u5728\u8bad\u7ec3\u65f6\u672a\u89c1\u8fc7\u7684\u957f\u63d0\u793a\u4e0b\u8868\u73b0\u4e0d\u4f73", "method": "\u7528Longhorn SSM\u66ff\u4ee3Transformer\uff0cLonghorn\u662f\u4e00\u79cd\u5148\u8fdb\u7684SSM\uff0c\u63d0\u4f9b\u7ebf\u6027\u65f6\u95f4\u63a8\u7406\u548c\u5f3a\u5927\u7684\u5916\u63a8\u80fd\u529b\uff0c\u7279\u522b\u9002\u5408\u957f\u4e0a\u4e0b\u6587\u63d0\u793a", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRoboSSM\u80fd\u6709\u6548\u5916\u63a8\u5230\u4e0d\u540c\u6570\u91cf\u7684\u4e0a\u4e0b\u6587\u6f14\u793a\uff0c\u5728\u672a\u89c1\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u957f\u65f6\u57df\u573a\u666f\u4e2d\u4fdd\u6301\u9c81\u68d2\u6027", "conclusion": "SSM\u6709\u6f5c\u529b\u6210\u4e3aICIL\u7684\u9ad8\u6548\u53ef\u6269\u5c55\u9aa8\u5e72\u7f51\u7edc\uff0c\u4e3a\u4e0a\u4e0b\u6587\u6a21\u4eff\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84"}}
{"id": "2509.20138", "categories": ["cs.AI", "68Q60, 68T20"], "pdf": "https://arxiv.org/pdf/2509.20138", "abs": "https://arxiv.org/abs/2509.20138", "authors": ["Wieger Wesselink", "Kees Huizing", "Huub van de Wetering"], "title": "Formal Verification of Minimax Algorithms", "comment": "12 pages", "summary": "Using the Dafny verification system, we formally verify a range of minimax\nsearch algorithms, including variations with alpha-beta pruning and\ntransposition tables. For depth-limited search with transposition tables, we\nintroduce a witness-based correctness criterion and apply it to two\nrepresentative algorithms. All verification artifacts, including proofs and\nPython implementations, are publicly available.", "AI": {"tldr": "\u4f7f\u7528Dafny\u9a8c\u8bc1\u7cfb\u7edf\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e86\u4e00\u7cfb\u5217\u6781\u5c0f\u6781\u5927\u641c\u7d22\u7b97\u6cd5\uff0c\u5305\u62ec\u5e26alpha-beta\u526a\u679d\u548c\u7f6e\u6362\u8868\u7684\u53d8\u4f53\u3002\u5bf9\u4e8e\u5e26\u7f6e\u6362\u8868\u7684\u6df1\u5ea6\u9650\u5236\u641c\u7d22\uff0c\u5f15\u5165\u4e86\u57fa\u4e8e\u89c1\u8bc1\u7684\u6b63\u786e\u6027\u6807\u51c6\u5e76\u5e94\u7528\u4e8e\u4e24\u4e2a\u4ee3\u8868\u6027\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u786e\u4fdd\u6781\u5c0f\u6781\u5927\u641c\u7d22\u7b97\u6cd5\uff08\u7279\u522b\u662f\u5e26\u4f18\u5316\u6280\u672f\u7684\u53d8\u4f53\uff09\u7684\u6b63\u786e\u6027\uff0c\u9700\u8981\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u6765\u63d0\u4f9b\u6570\u5b66\u4e0a\u7684\u4fdd\u8bc1\u3002", "method": "\u4f7f\u7528Dafny\u9a8c\u8bc1\u7cfb\u7edf\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u4e3a\u5e26alpha-beta\u526a\u679d\u548c\u7f6e\u6362\u8868\u7684\u6781\u5c0f\u6781\u5927\u641c\u7d22\u7b97\u6cd5\u5efa\u7acb\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u7279\u522b\u662f\u4e3a\u6df1\u5ea6\u9650\u5236\u641c\u7d22\u5f15\u5165\u57fa\u4e8e\u89c1\u8bc1\u7684\u6b63\u786e\u6027\u6807\u51c6\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86\u591a\u4e2a\u6781\u5c0f\u6781\u5927\u641c\u7d22\u7b97\u6cd5\u7684\u6b63\u786e\u6027\uff0c\u5305\u62ec\u5e26\u4f18\u5316\u6280\u672f\u7684\u53d8\u4f53\uff0c\u6240\u6709\u9a8c\u8bc1\u5de5\u4ef6\uff08\u8bc1\u660e\u548cPython\u5b9e\u73b0\uff09\u90fd\u5df2\u516c\u5f00\u53ef\u7528\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4f7f\u7528\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u9a8c\u8bc1\u641c\u7d22\u7b97\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u6e38\u620fAI\u548c\u641c\u7d22\u7b97\u6cd5\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6b63\u786e\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2509.19672", "categories": ["cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2509.19672", "abs": "https://arxiv.org/abs/2509.19672", "authors": ["Dongzhe Zheng", "Wenjie Mei"], "title": "Memory-Augmented Potential Field Theory: A Framework for Adaptive Control in Non-Convex Domains", "comment": "Accepted by NeurIPS 2025", "summary": "Stochastic optimal control methods often struggle in complex non-convex\nlandscapes, frequently becoming trapped in local optima due to their inability\nto learn from historical trajectory data. This paper introduces\nMemory-Augmented Potential Field Theory, a unified mathematical framework that\nintegrates historical experience into stochastic optimal control. Our approach\ndynamically constructs memory-based potential fields that identify and encode\nkey topological features of the state space, enabling controllers to\nautomatically learn from past experiences and adapt their optimization\nstrategy. We provide a theoretical analysis showing that memory-augmented\npotential fields possess non-convex escape properties, asymptotic convergence\ncharacteristics, and computational efficiency. We implement this theoretical\nframework in a Memory-Augmented Model Predictive Path Integral (MPPI)\ncontroller that demonstrates significantly improved performance in challenging\nnon-convex environments. The framework represents a generalizable approach to\nexperience-based learning within control systems (especially robotic dynamics),\nenhancing their ability to navigate complex state spaces without requiring\nspecialized domain knowledge or extensive offline training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8bb0\u5fc6\u589e\u5f3a\u52bf\u573a\u7406\u8bba\uff0c\u901a\u8fc7\u6574\u5408\u5386\u53f2\u7ecf\u9a8c\u5230\u968f\u673a\u6700\u4f18\u63a7\u5236\u4e2d\uff0c\u89e3\u51b3\u590d\u6742\u975e\u51f8\u73af\u5883\u4e2d\u7684\u5c40\u90e8\u6700\u4f18\u9677\u9631\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u968f\u673a\u6700\u4f18\u63a7\u5236\u5728\u590d\u6742\u975e\u51f8\u73af\u5883\u4e2d\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u5386\u53f2\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u5b66\u4e60\u3002", "method": "\u5f00\u53d1\u4e86\u8bb0\u5fc6\u589e\u5f3a\u52bf\u573a\u7406\u8bba\u6846\u67b6\uff0c\u52a8\u6001\u6784\u5efa\u57fa\u4e8e\u8bb0\u5fc6\u7684\u52bf\u573a\u6765\u8bc6\u522b\u72b6\u6001\u7a7a\u95f4\u7684\u5173\u952e\u62d3\u6251\u7279\u5f81\uff0c\u5e76\u5b9e\u73b0\u4e86\u8bb0\u5fc6\u589e\u5f3a\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\u5668\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u975e\u51f8\u9003\u9038\u7279\u6027\u3001\u6e10\u8fd1\u6536\u655b\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u6311\u6218\u6027\u975e\u51f8\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u63a7\u5236\u7cfb\u7edf\uff08\u7279\u522b\u662f\u673a\u5668\u4eba\u52a8\u529b\u5b66\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u7684\u57fa\u4e8e\u7ecf\u9a8c\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u5728\u590d\u6742\u72b6\u6001\u7a7a\u95f4\u4e2d\u5bfc\u822a\u7684\u80fd\u529b\uff0c\u65e0\u9700\u4e13\u95e8\u9886\u57df\u77e5\u8bc6\u6216\u5927\u91cf\u79bb\u7ebf\u8bad\u7ec3\u3002"}}
{"id": "2509.20175", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.20175", "abs": "https://arxiv.org/abs/2509.20175", "authors": ["Lorenzo Giusti", "Ole Anton Werner", "Riccardo Taiello", "Matilde Carvalho Costa", "Emre Tosun", "Andrea Protani", "Marc Molina", "Rodrigo Lopes de Almeida", "Paolo Cacace", "Diogo Reis Santos", "Luigi Serio"], "title": "Federation of Agents: A Semantics-Aware Communication Fabric for Large-Scale Agentic AI", "comment": "18 pages, 4 figures", "summary": "We present Federation of Agents (FoA), a distributed orchestration framework\nthat transforms static multi-agent coordination into dynamic, capability-driven\ncollaboration. FoA introduces Versioned Capability Vectors (VCVs):\nmachine-readable profiles that make agent capabilities searchable through\nsemantic embeddings, enabling agents to advertise their capabilities, cost, and\nlimitations. Our aarchitecturecombines three key innovations: (1) semantic\nrouting that matches tasks to agents over sharded HNSW indices while enforcing\noperational constraints through cost-biased optimization, (2) dynamic task\ndecomposition where compatible agents collaboratively break down complex tasks\ninto DAGs of subtasks through consensus-based merging, and (3) smart clustering\nthat groups agents working on similar subtasks into collaborative channels for\nk-round refinement before synthesis. Built on top of MQTT,s publish-subscribe\nsemantics for scalable message passing, FoA achieves sub-linear complexity\nthrough hierarchical capability matching and efficient index maintenance.\nEvaluation on HealthBench shows 13x improvements over single-model baselines,\nwith clustering-enhanced laboration particularly effective for complex\nreasoning tasks requiring multiple perspectives. The system scales horizontally\nwhile maintaining consistent performance, demonstrating that semantic\norchestration with structured collaboration can unlock the collective\nintelligence of heterogeneous federations of AI agents.", "AI": {"tldr": "FoA\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u7248\u672c\u5316\u80fd\u529b\u5411\u91cf\u5b9e\u73b0\u52a8\u6001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u5728HealthBench\u4e0a\u76f8\u6bd4\u5355\u6a21\u578b\u57fa\u7ebf\u63d0\u534713\u500d\u6027\u80fd", "motivation": "\u5c06\u9759\u6001\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u8f6c\u53d8\u4e3a\u52a8\u6001\u7684\u3001\u57fa\u4e8e\u80fd\u529b\u7684\u534f\u4f5c\uff0c\u91ca\u653e\u5f02\u6784AI\u667a\u80fd\u4f53\u8054\u90a6\u7684\u96c6\u4f53\u667a\u80fd", "method": "\u7ed3\u5408\u8bed\u4e49\u8def\u7531\u3001\u52a8\u6001\u4efb\u52a1\u5206\u89e3\u548c\u667a\u80fd\u805a\u7c7b\u4e09\u5927\u521b\u65b0\uff1a1\uff09\u8bed\u4e49\u8def\u7531\u901a\u8fc7HNSW\u7d22\u5f15\u5339\u914d\u4efb\u52a1\u4e0e\u667a\u80fd\u4f53\uff1b2\uff09\u52a8\u6001\u4efb\u52a1\u5206\u89e3\u8ba9\u517c\u5bb9\u667a\u80fd\u4f53\u534f\u4f5c\u5206\u89e3\u590d\u6742\u4efb\u52a1\uff1b3\uff09\u667a\u80fd\u805a\u7c7b\u5c06\u76f8\u4f3c\u5b50\u4efb\u52a1\u7684\u667a\u80fd\u4f53\u5206\u7ec4\u8fdb\u884c\u591a\u8f6e\u4f18\u5316", "result": "\u5728HealthBench\u8bc4\u4f30\u4e2d\u663e\u793a\u6bd4\u5355\u6a21\u578b\u57fa\u7ebf\u63d0\u534713\u500d\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9700\u8981\u591a\u89c6\u89d2\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff0c\u805a\u7c7b\u589e\u5f3a\u7684\u534f\u4f5c\u6548\u679c\u663e\u8457", "conclusion": "\u57fa\u4e8eMQTT\u53d1\u5e03-\u8ba2\u9605\u8bed\u4e49\u7684FoA\u6846\u67b6\u901a\u8fc7\u5c42\u6b21\u5316\u80fd\u529b\u5339\u914d\u548c\u9ad8\u6548\u7d22\u5f15\u7ef4\u62a4\u5b9e\u73b0\u4e9a\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u8bc1\u660e\u8bed\u4e49\u7f16\u6392\u4e0e\u7ed3\u6784\u5316\u534f\u4f5c\u80fd\u591f\u91ca\u653e\u5f02\u6784AI\u667a\u80fd\u4f53\u8054\u90a6\u7684\u96c6\u4f53\u667a\u80fd"}}
{"id": "2509.19688", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.19688", "abs": "https://arxiv.org/abs/2509.19688", "authors": ["Devesh Nath", "Haoran Yin", "Glen Chou"], "title": "Formal Safety Verification and Refinement for Generative Motion Planners via Certified Local Stabilization", "comment": "10 pages, 12 figures", "summary": "We present a method for formal safety verification of learning-based\ngenerative motion planners. Generative motion planners (GMPs) offer advantages\nover traditional planners, but verifying the safety and dynamic feasibility of\ntheir outputs is difficult since neural network verification (NNV) tools scale\nonly to a few hundred neurons, while GMPs often contain millions. To preserve\nGMP expressiveness while enabling verification, our key insight is to imitate\nthe GMP by stabilizing references sampled from the GMP with a small neural\ntracking controller and then applying NNV to the closed-loop dynamics. This\nyields reachable sets that rigorously certify closed-loop safety, while the\ncontroller enforces dynamic feasibility. Building on this, we construct a\nlibrary of verified GMP references and deploy them online in a way that\nimitates the original GMP distribution whenever it is safe to do so, improving\nsafety without retraining. We evaluate across diverse planners, including\ndiffusion, flow matching, and vision-language models, improving safety in\nsimulation (on ground robots and quadcopters) and on hardware\n(differential-drive robot).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u751f\u6210\u8fd0\u52a8\u89c4\u5212\u5668\u7684\u5f62\u5f0f\u5316\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c0f\u578b\u795e\u7ecf\u8ddf\u8e2a\u63a7\u5236\u5668\u7a33\u5b9aGMP\u751f\u6210\u7684\u53c2\u8003\u8f68\u8ff9\uff0c\u7136\u540e\u5bf9\u95ed\u73af\u52a8\u529b\u5b66\u5e94\u7528\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\uff0c\u4ece\u800c\u5728\u4fdd\u6301GMP\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u6027\u4fdd\u8bc1\u3002", "motivation": "\u751f\u6210\u8fd0\u52a8\u89c4\u5212\u5668(GMPs)\u76f8\u6bd4\u4f20\u7edf\u89c4\u5212\u5668\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u7531\u4e8e\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u5de5\u5177\u53ea\u80fd\u5904\u7406\u51e0\u767e\u4e2a\u795e\u7ecf\u5143\uff0c\u800cGMPs\u901a\u5e38\u5305\u542b\u6570\u767e\u4e07\u4e2a\u795e\u7ecf\u5143\uff0c\u9a8c\u8bc1\u5176\u8f93\u51fa\u7684\u5b89\u5168\u6027\u548c\u52a8\u6001\u53ef\u884c\u6027\u975e\u5e38\u56f0\u96be\u3002", "method": "\u901a\u8fc7\u4eceGMP\u91c7\u6837\u53c2\u8003\u8f68\u8ff9\uff0c\u7528\u5c0f\u578b\u795e\u7ecf\u8ddf\u8e2a\u63a7\u5236\u5668\u8fdb\u884c\u7a33\u5b9a\uff0c\u7136\u540e\u5bf9\u95ed\u73af\u52a8\u529b\u5b66\u5e94\u7528\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\uff0c\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u53ef\u8fbe\u96c6\u3002\u6784\u5efa\u9a8c\u8bc1GMP\u53c2\u8003\u5e93\uff0c\u5728\u7ebf\u90e8\u7f72\u65f6\u5c3d\u53ef\u80fd\u6a21\u4eff\u539f\u59cbGMP\u5206\u5e03\u3002", "result": "\u5728\u591a\u79cd\u89c4\u5212\u5668\uff08\u5305\u62ec\u6269\u6563\u6a21\u578b\u3001\u6d41\u5339\u914d\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5728\u4eff\u771f\uff08\u5730\u9762\u673a\u5668\u4eba\u548c\u56db\u65cb\u7ffc\uff09\u548c\u786c\u4ef6\uff08\u5dee\u901f\u9a71\u52a8\u673a\u5668\u4eba\uff09\u4e0a\u90fd\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301GMP\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u5b9e\u73b0\u5f62\u5f0f\u5316\u5b89\u5168\u9a8c\u8bc1\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u63d0\u9ad8\u5b89\u5168\u6027\uff0c\u4e3a\u5b66\u4e60\u578b\u8fd0\u52a8\u89c4\u5212\u5668\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2509.20218", "categories": ["cs.AI", "cs.AR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.20218", "abs": "https://arxiv.org/abs/2509.20218", "authors": ["Mohamed Manzour", "Catherine M. Elias", "Omar M. Shehata", "Rub\u00e9n Izquierdo", "Miguel \u00c1ngel Sotelo"], "title": "Design Insights and Comparative Evaluation of a Hardware-Based Cooperative Perception Architecture for Lane Change Prediction", "comment": null, "summary": "Research on lane change prediction has gained attention in the last few\nyears. Most existing works in this area have been conducted in simulation\nenvironments or with pre-recorded datasets, these works often rely on\nsimplified assumptions about sensing, communication, and traffic behavior that\ndo not always hold in practice. Real-world deployments of lane-change\nprediction systems are relatively rare, and when they are reported, the\npractical challenges, limitations, and lessons learned are often\nunder-documented. This study explores cooperative lane-change prediction\nthrough a real hardware deployment in mixed traffic and shares the insights\nthat emerged during implementation and testing. We highlight the practical\nchallenges we faced, including bottlenecks, reliability issues, and operational\nconstraints that shaped the behavior of the system. By documenting these\nexperiences, the study provides guidance for others working on similar\npipelines.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u771f\u5b9e\u786c\u4ef6\u90e8\u7f72\u63a2\u7d22\u4e86\u534f\u540c\u8f66\u9053\u53d8\u6362\u9884\u6d4b\uff0c\u5206\u4eab\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u7684\u6311\u6218\u548c\u7ecf\u9a8c\u6559\u8bad\u3002", "motivation": "\u73b0\u6709\u8f66\u9053\u53d8\u6362\u9884\u6d4b\u7814\u7a76\u5927\u591a\u57fa\u4e8e\u4eff\u771f\u73af\u5883\u6216\u9884\u5f55\u6570\u636e\u96c6\uff0c\u4f9d\u8d56\u7b80\u5316\u7684\u5047\u8bbe\uff0c\u800c\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u76f8\u5bf9\u7f55\u89c1\u4e14\u5b9e\u8df5\u7ecf\u9a8c\u4e0d\u8db3\u3002", "method": "\u5728\u6df7\u5408\u4ea4\u901a\u73af\u5883\u4e2d\u8fdb\u884c\u771f\u5b9e\u786c\u4ef6\u90e8\u7f72\uff0c\u5b9e\u73b0\u534f\u540c\u8f66\u9053\u53d8\u6362\u9884\u6d4b\u7cfb\u7edf\u3002", "result": "\u8bc6\u522b\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u74f6\u9888\u3001\u53ef\u9760\u6027\u95ee\u9898\u548c\u64cd\u4f5c\u7ea6\u675f\u7b49\u6311\u6218\uff0c\u8fd9\u4e9b\u56e0\u7d20\u5f71\u54cd\u4e86\u7cfb\u7edf\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u8bb0\u5f55\u8fd9\u4e9b\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u4e3a\u7c7b\u4f3c\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.19696", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19696", "abs": "https://arxiv.org/abs/2509.19696", "authors": ["Noah Geiger", "Tamim Asfour", "Neville Hogan", "Johannes Lachner"], "title": "Diffusion-Based Impedance Learning for Contact-Rich Manipulation Tasks", "comment": "15 pages, 12 figures", "summary": "Learning methods excel at motion generation in the information domain but are\nnot primarily designed for physical interaction in the energy domain. Impedance\nControl shapes physical interaction but requires task-aware tuning by selecting\nfeasible impedance parameters. We present Diffusion-Based Impedance Learning, a\nframework that combines both domains. A Transformer-based Diffusion Model with\ncross-attention to external wrenches reconstructs a simulated Zero-Force\nTrajectory (sZFT). This captures both translational and rotational task-space\nbehavior. For rotations, we introduce a novel SLERP-based quaternion noise\nscheduler that ensures geometric consistency. The reconstructed sZFT is then\npassed to an energy-based estimator that updates stiffness and damping\nparameters. A directional rule is applied that reduces impedance along non task\naxes while preserving rigidity along task directions. Training data were\ncollected for a parkour scenario and robotic-assisted therapy tasks using\nteleoperation with Apple Vision Pro. With only tens of thousands of samples,\nthe model achieved sub-millimeter positional accuracy and sub-degree rotational\naccuracy. Its compact model size enabled real-time torque control and\nautonomous stiffness adaptation on a KUKA LBR iiwa robot. The controller\nachieved smooth parkour traversal within force and velocity limits and 30/30\nsuccess rates for cylindrical, square, and star peg insertions without any\npeg-specific demonstrations in the training data set. All code for the\nTransformer-based Diffusion Model, the robot controller, and the Apple Vision\nPro telemanipulation framework is publicly available. These results mark an\nimportant step towards Physical AI, fusing model-based control for physical\ninteraction with learning-based methods for trajectory generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86Diffusion-Based Impedance Learning\u6846\u67b6\uff0c\u7ed3\u5408\u5b66\u4e60\u65b9\u6cd5\u548c\u963b\u6297\u63a7\u5236\uff0c\u901a\u8fc7Transformer-based Diffusion\u6a21\u578b\u91cd\u5efa\u6a21\u62df\u96f6\u529b\u8f68\u8ff9\uff0c\u5b9e\u73b0\u5b9e\u65f6\u626d\u77e9\u63a7\u5236\u548c\u81ea\u4e3b\u521a\u5ea6\u9002\u5e94\u3002", "motivation": "\u5b66\u4e60\u65b9\u6cd5\u64c5\u957f\u8fd0\u52a8\u751f\u6210\u4f46\u4e0d\u9002\u5408\u7269\u7406\u4ea4\u4e92\uff0c\u963b\u6297\u63a7\u5236\u9700\u8981\u4efb\u52a1\u611f\u77e5\u8c03\u53c2\u3002\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\uff0c\u5b9e\u73b0\u7269\u7406AI\u7684\u878d\u5408\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u5904\u7406\u5916\u90e8\u529b\u77e9\uff0c\u91cd\u5efa\u6a21\u62df\u96f6\u529b\u8f68\u8ff9\u3002\u5f15\u5165SLERP-based\u56db\u5143\u6570\u566a\u58f0\u8c03\u5ea6\u5668\u4fdd\u8bc1\u51e0\u4f55\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u80fd\u91cf\u57fa\u4f30\u8ba1\u5668\u66f4\u65b0\u521a\u5ea6\u548c\u963b\u5c3c\u53c2\u6570\u3002", "result": "\u5728KUKA LBR iiwa\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e9a\u6beb\u7c73\u4f4d\u7f6e\u7cbe\u5ea6\u548c\u4e9a\u5ea6\u65cb\u8f6c\u7cbe\u5ea6\u3002\u6210\u529f\u5b8c\u6210\u5706\u67f1\u3001\u65b9\u5f62\u548c\u661f\u5f62\u5b54\u63d2\u5165\u4efb\u52a1\uff0c30/30\u6210\u529f\u7387\u3002\u6a21\u578b\u7d27\u51d1\uff0c\u652f\u6301\u5b9e\u65f6\u63a7\u5236\u3002", "conclusion": "\u8fd9\u662f\u8fc8\u5411\u7269\u7406AI\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u5c06\u57fa\u4e8e\u6a21\u578b\u7684\u7269\u7406\u4ea4\u4e92\u63a7\u5236\u4e0e\u57fa\u4e8e\u5b66\u4e60\u7684\u8f68\u8ff9\u751f\u6210\u65b9\u6cd5\u878d\u5408\uff0c\u6240\u6709\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2509.20082", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.20082", "abs": "https://arxiv.org/abs/2509.20082", "authors": ["Surov Maksim"], "title": "Orbital Stabilization and Time Synchronization of Unstable Periodic Motions in Underactuated Robots", "comment": null, "summary": "This paper presents a control methodology for achieving orbital stabilization\nwith simultaneous time synchronization of periodic trajectories in\nunderactuated robotic systems. The proposed approach extends the classical\ntransverse linearization framework to explicitly incorporate\ntime-desynchronization dynamics. To stabilize the resulting extended transverse\ndynamics, we employ a combination of time-varying LQR and sliding-mode control.\nThe theoretical results are validated experimentally through the implementation\nof both centralized and decentralized control strategies on a group of six\nButterfly robots.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6b20\u9a71\u52a8\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u8f68\u9053\u7a33\u5b9a\u6027\u548c\u65f6\u95f4\u540c\u6b65\u7684\u5468\u671f\u6027\u8f68\u8ff9\u63a7\u5236\u3002\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u7ecf\u5178\u7684\u6a2a\u5411\u7ebf\u6027\u5316\u6846\u67b6\uff0c\u660e\u786e\u7eb3\u5165\u4e86\u65f6\u95f4\u5931\u540c\u6b65\u52a8\u6001\uff0c\u5e76\u91c7\u7528\u65f6\u53d8LQR\u548c\u6ed1\u6a21\u63a7\u5236\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u6765\u7a33\u5b9a\u6269\u5c55\u7684\u6a2a\u5411\u52a8\u6001\u3002", "motivation": "\u9488\u5bf9\u6b20\u9a71\u52a8\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u5468\u671f\u6027\u8f68\u8ff9\u63a7\u5236\u4e2d\u540c\u65f6\u5b9e\u73b0\u8f68\u9053\u7a33\u5b9a\u548c\u65f6\u95f4\u540c\u6b65\u7684\u9700\u6c42\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u65f6\u95f4\u540c\u6b65\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u5904\u7406\u8f68\u9053\u7a33\u5b9a\u548c\u65f6\u95f4\u540c\u6b65\u7684\u63a7\u5236\u7b56\u7565\u3002", "method": "\u6269\u5c55\u7ecf\u5178\u6a2a\u5411\u7ebf\u6027\u5316\u6846\u67b6\u4ee5\u5305\u542b\u65f6\u95f4\u5931\u540c\u6b65\u52a8\u6001\uff0c\u91c7\u7528\u65f6\u53d8LQR\u548c\u6ed1\u6a21\u63a7\u5236\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u6765\u7a33\u5b9a\u6269\u5c55\u7684\u6a2a\u5411\u52a8\u6001\uff0c\u5e76\u5728\u516d\u53f0\u8774\u8776\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e86\u96c6\u4e2d\u5f0f\u548c\u5206\u6563\u5f0f\u63a7\u5236\u7b56\u7565\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u516d\u53f0\u8774\u8776\u673a\u5668\u4eba\u7cfb\u7edf\u4e0a\u6210\u529f\u5b9e\u73b0\u4e86\u5468\u671f\u6027\u8f68\u8ff9\u7684\u8f68\u9053\u7a33\u5b9a\u6027\u548c\u65f6\u95f4\u540c\u6b65\u63a7\u5236\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u63a7\u5236\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u63a7\u5236\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6b20\u9a71\u52a8\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u5468\u671f\u6027\u8f68\u8ff9\u63a7\u5236\u95ee\u9898\uff0c\u5728\u5b9e\u73b0\u8f68\u9053\u7a33\u5b9a\u7684\u540c\u65f6\u4fdd\u8bc1\u65f6\u95f4\u540c\u6b65\uff0c\u4e3a\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u534f\u8c03\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.20270", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.20270", "abs": "https://arxiv.org/abs/2509.20270", "authors": ["Xingjian Kang", "Linda Vorberg", "Andreas Maier", "Alexander Katzmann", "Oliver Taubmann"], "title": "Scan-do Attitude: Towards Autonomous CT Protocol Management using a Large Language Model Agent", "comment": null, "summary": "Managing scan protocols in Computed Tomography (CT), which includes adjusting\nacquisition parameters or configuring reconstructions, as well as selecting\npostprocessing tools in a patient-specific manner, is time-consuming and\nrequires clinical as well as technical expertise. At the same time, we observe\nan increasing shortage of skilled workforce in radiology. To address this\nissue, a Large Language Model (LLM)-based agent framework is proposed to assist\nwith the interpretation and execution of protocol configuration requests given\nin natural language or a structured, device-independent format, aiming to\nimprove the workflow efficiency and reduce technologists' workload. The agent\ncombines in-context-learning, instruction-following, and structured toolcalling\nabilities to identify relevant protocol elements and apply accurate\nmodifications. In a systematic evaluation, experimental results indicate that\nthe agent can effectively retrieve protocol components, generate device\ncompatible protocol definition files, and faithfully implement user requests.\nDespite demonstrating feasibility in principle, the approach faces limitations\nregarding syntactic and semantic validity due to lack of a unified device API,\nand challenges with ambiguous or complex requests. In summary, the findings\nshow a clear path towards LLM-based agents for supporting scan protocol\nmanagement in CT imaging.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u8f85\u52a9\u8ba1\u7b97\u673a\u65ad\u5c42\u626b\u63cf\uff08CT\uff09\u4e2d\u626b\u63cf\u534f\u8bae\u7684\u81ea\u7136\u8bed\u8a00\u914d\u7f6e\u7ba1\u7406\uff0c\u65e8\u5728\u63d0\u9ad8\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\u5e76\u51cf\u8f7b\u6280\u672f\u4eba\u5458\u8d1f\u62c5\u3002", "motivation": "CT\u626b\u63cf\u534f\u8bae\u7ba1\u7406\uff08\u5305\u62ec\u8c03\u6574\u91c7\u96c6\u53c2\u6570\u3001\u914d\u7f6e\u91cd\u5efa\u7b97\u6cd5\u548c\u9009\u62e9\u540e\u5904\u7406\u5de5\u5177\uff09\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u4e34\u5e8a\u548c\u6280\u672f\u77e5\u8bc6\uff0c\u540c\u65f6\u653e\u5c04\u5b66\u9886\u57df\u9762\u4e34\u719f\u7ec3\u52b3\u52a8\u529b\u77ed\u7f3a\u95ee\u9898\u3002", "method": "\u5f00\u53d1LLM-based\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u6307\u4ee4\u8ddf\u968f\u548c\u7ed3\u6784\u5316\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff0c\u8bc6\u522b\u76f8\u5173\u534f\u8bae\u5143\u7d20\u5e76\u5e94\u7528\u7cbe\u786e\u4fee\u6539\uff0c\u751f\u6210\u8bbe\u5907\u517c\u5bb9\u7684\u534f\u8bae\u5b9a\u4e49\u6587\u4ef6\u3002", "result": "\u7cfb\u7edf\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u667a\u80fd\u4f53\u80fd\u6709\u6548\u68c0\u7d22\u534f\u8bae\u7ec4\u4ef6\u3001\u751f\u6210\u8bbe\u5907\u517c\u5bb9\u534f\u8bae\u6587\u4ef6\u5e76\u5fe0\u5b9e\u6267\u884c\u7528\u6237\u8bf7\u6c42\uff0c\u8bc1\u660e\u4e86\u6280\u672f\u53ef\u884c\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u9762\u4e34\u7f3a\u4e4f\u7edf\u4e00\u8bbe\u5907API\u5bfc\u81f4\u7684\u8bed\u6cd5\u8bed\u4e49\u6709\u6548\u6027\u9650\u5236\uff0c\u4ee5\u53ca\u5904\u7406\u6a21\u7cca\u590d\u6742\u8bf7\u6c42\u7684\u6311\u6218\uff0c\u4f46\u7814\u7a76\u7ed3\u679c\u4e3a\u57fa\u4e8eLLM\u7684CT\u626b\u63cf\u534f\u8bae\u7ba1\u7406\u667a\u80fd\u4f53\u6307\u660e\u4e86\u6e05\u6670\u7684\u53d1\u5c55\u8def\u5f84\u3002"}}
{"id": "2509.19712", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19712", "abs": "https://arxiv.org/abs/2509.19712", "authors": ["Liquan Wang", "Jiangjie Bian", "Eric Heiden", "Animesh Garg"], "title": "TopoCut: Learning Multi-Step Cutting with Spectral Rewards and Discrete Diffusion Policies", "comment": null, "summary": "Robotic manipulation tasks involving cutting deformable objects remain\nchallenging due to complex topological behaviors, difficulties in perceiving\ndense object states, and the lack of efficient evaluation methods for cutting\noutcomes. In this paper, we introduce TopoCut, a comprehensive benchmark for\nmulti-step robotic cutting tasks that integrates a cutting environment and\ngeneralized policy learning. TopoCut is built upon three core components: (1)\nWe introduce a high-fidelity simulation environment based on a particle-based\nelastoplastic solver with compliant von Mises constitutive models, augmented by\na novel damage-driven topology discovery mechanism that enables accurate\ntracking of multiple cutting pieces. (2) We develop a comprehensive reward\ndesign that integrates the topology discovery with a pose-invariant spectral\nreward model based on Laplace-Beltrami eigenanalysis, facilitating consistent\nand robust assessment of cutting quality. (3) We propose an integrated policy\nlearning pipeline, where a dynamics-informed perception module predicts\ntopological evolution and produces particle-wise, topology-aware embeddings to\nsupport PDDP (Particle-based Score-Entropy Discrete Diffusion Policy) for\ngoal-conditioned policy learning. Extensive experiments demonstrate that\nTopoCut supports trajectory generation, scalable learning, precise evaluation,\nand strong generalization across diverse object geometries, scales, poses, and\ncutting goals.", "AI": {"tldr": "TopoCut\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6b65\u9aa4\u673a\u5668\u4eba\u5207\u5272\u4efb\u52a1\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u5305\u542b\u9ad8\u4fdd\u771f\u4eff\u771f\u73af\u5883\u3001\u7efc\u5408\u5956\u52b1\u8bbe\u8ba1\u548c\u96c6\u6210\u7b56\u7565\u5b66\u4e60\u7ba1\u9053\uff0c\u65e8\u5728\u89e3\u51b3\u53ef\u53d8\u5f62\u7269\u4f53\u5207\u5272\u4e2d\u7684\u62d3\u6251\u884c\u4e3a\u590d\u6742\u6027\u3001\u611f\u77e5\u56f0\u96be\u548c\u8bc4\u4f30\u6311\u6218\u3002", "motivation": "\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u673a\u5668\u4eba\u5207\u5272\u4efb\u52a1\u9762\u4e34\u62d3\u6251\u884c\u4e3a\u590d\u6742\u3001\u5bc6\u96c6\u7269\u4f53\u72b6\u6001\u611f\u77e5\u56f0\u96be\u4ee5\u53ca\u7f3a\u4e4f\u9ad8\u6548\u5207\u5272\u7ed3\u679c\u8bc4\u4f30\u65b9\u6cd5\u7b49\u6311\u6218\u3002", "method": "1\uff09\u57fa\u4e8e\u7c92\u5b50\u5f39\u5851\u6027\u6c42\u89e3\u5668\u7684\u9ad8\u4fdd\u771f\u4eff\u771f\u73af\u5883\uff0c\u914d\u5907\u635f\u4f24\u9a71\u52a8\u7684\u62d3\u6251\u53d1\u73b0\u673a\u5236\uff1b2\uff09\u7ed3\u5408\u62d3\u6251\u53d1\u73b0\u548c\u62c9\u666e\u62c9\u65af-\u8d1d\u5c14\u7279\u62c9\u7c73\u7279\u5f81\u5206\u6790\u7684\u59ff\u6001\u4e0d\u53d8\u8c31\u5956\u52b1\u6a21\u578b\uff1b3\uff09\u96c6\u6210\u7b56\u7565\u5b66\u4e60\u7ba1\u9053\uff0c\u5305\u62ec\u52a8\u6001\u611f\u77e5\u6a21\u5757\u548c\u57fa\u4e8e\u7c92\u5b50\u7684\u5f97\u5206\u71b5\u79bb\u6563\u6269\u6563\u7b56\u7565\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cTopoCut\u652f\u6301\u8f68\u8ff9\u751f\u6210\u3001\u53ef\u6269\u5c55\u5b66\u4e60\u3001\u7cbe\u786e\u8bc4\u4f30\uff0c\u5e76\u5728\u4e0d\u540c\u7269\u4f53\u51e0\u4f55\u5f62\u72b6\u3001\u5c3a\u5ea6\u3001\u59ff\u6001\u548c\u5207\u5272\u76ee\u6807\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "TopoCut\u4e3a\u89e3\u51b3\u53ef\u53d8\u5f62\u7269\u4f53\u5207\u5272\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u5e73\u53f0\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u62d3\u6251\u53d8\u5316\u5e76\u5b9e\u73b0\u7cbe\u786e\u7684\u5207\u5272\u8d28\u91cf\u8bc4\u4f30\u3002"}}
{"id": "2509.19725", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19725", "abs": "https://arxiv.org/abs/2509.19725", "authors": ["Naveed D. Riaziat", "Joseph Chen", "Axel Krieger", "Jeremy D. Brown"], "title": "Towards Autonomous Robotic Electrosurgery via Thermal Imaging", "comment": "Accepted for publication in the proceedings of the 2025 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025)", "summary": "Electrosurgery is a surgical technique that can improve tissue cutting by\nreducing cutting force and bleeding. However, electrosurgery adds a risk of\nthermal injury to surrounding tissue. Expert surgeons estimate desirable\ncutting velocities based on experience but have no quantifiable reference to\nindicate if a particular velocity is optimal. Furthermore, prior demonstrations\nof autonomous electrosurgery have primarily used constant tool velocity, which\nis not robust to changes in electrosurgical tissue characteristics, power\nsettings, or tool type. Thermal imaging feedback provides information that can\nbe used to reduce thermal injury while balancing cutting force by controlling\ntool velocity. We introduce Thermography for Electrosurgical Rate Modulation\nvia Optimization (ThERMO) to autonomously reduce thermal injury while balancing\ncutting force by intelligently controlling tool velocity. We demonstrate ThERMO\nin tissue phantoms and compare its performance to the constant velocity\napproach. Overall, ThERMO improves cut success rate by a factor of three and\ncan reduce peak cutting force by a factor of two. ThERMO responds to varying\nenvironmental disturbances, reduces damage to tissue, and completes cutting\ntasks that would otherwise result in catastrophic failure for the constant\nvelocity approach.", "AI": {"tldr": "ThERMO\u7cfb\u7edf\u901a\u8fc7\u70ed\u6210\u50cf\u53cd\u9988\u667a\u80fd\u63a7\u5236\u7535\u5916\u79d1\u624b\u672f\u5de5\u5177\u901f\u5ea6\uff0c\u5728\u51cf\u5c11\u70ed\u635f\u4f24\u7684\u540c\u65f6\u5e73\u8861\u5207\u5272\u529b\uff0c\u76f8\u6bd4\u6052\u5b9a\u901f\u5ea6\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u5207\u5272\u6210\u529f\u7387\u5e76\u964d\u4f4e\u5cf0\u503c\u5207\u5272\u529b\u3002", "motivation": "\u7535\u5916\u79d1\u624b\u672f\u867d\u7136\u80fd\u51cf\u5c11\u5207\u5272\u529b\u548c\u51fa\u8840\uff0c\u4f46\u5b58\u5728\u70ed\u635f\u4f24\u98ce\u9669\u3002\u4e13\u5bb6\u4f9d\u8d56\u7ecf\u9a8c\u4f30\u8ba1\u5207\u5272\u901f\u5ea6\uff0c\u7f3a\u4e4f\u91cf\u5316\u53c2\u8003\u3002\u73b0\u6709\u81ea\u4e3b\u7535\u5916\u79d1\u624b\u672f\u4e3b\u8981\u4f7f\u7528\u6052\u5b9a\u5de5\u5177\u901f\u5ea6\uff0c\u65e0\u6cd5\u9002\u5e94\u7ec4\u7ec7\u7279\u6027\u3001\u529f\u7387\u8bbe\u7f6e\u6216\u5de5\u5177\u7c7b\u578b\u7684\u53d8\u5316\u3002", "method": "\u63d0\u51faThERMO\uff08\u57fa\u4e8e\u4f18\u5316\u7684\u70ed\u6210\u50cf\u7535\u5916\u79d1\u901f\u7387\u8c03\u5236\uff09\u7cfb\u7edf\uff0c\u5229\u7528\u70ed\u6210\u50cf\u53cd\u9988\u4fe1\u606f\uff0c\u901a\u8fc7\u667a\u80fd\u63a7\u5236\u5de5\u5177\u901f\u5ea6\u6765\u51cf\u5c11\u70ed\u635f\u4f24\u5e76\u5e73\u8861\u5207\u5272\u529b\u3002", "result": "\u5728\u7ec4\u7ec7\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0cThERMO\u5c06\u5207\u5272\u6210\u529f\u7387\u63d0\u9ad8\u4e86\u4e09\u500d\uff0c\u5cf0\u503c\u5207\u5272\u529b\u964d\u4f4e\u4e86\u4e00\u534a\u3002\u7cfb\u7edf\u80fd\u54cd\u5e94\u73af\u5883\u5e72\u6270\uff0c\u51cf\u5c11\u7ec4\u7ec7\u635f\u4f24\uff0c\u5b8c\u6210\u6052\u5b9a\u901f\u5ea6\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u707e\u96be\u6027\u5931\u8d25\u7684\u5207\u5272\u4efb\u52a1\u3002", "conclusion": "ThERMO\u7cfb\u7edf\u901a\u8fc7\u70ed\u6210\u50cf\u53cd\u9988\u7684\u667a\u80fd\u901f\u5ea6\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7535\u5916\u79d1\u624b\u672f\u7684\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u81ea\u4e3b\u7535\u5916\u79d1\u624b\u672f\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19732", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19732", "abs": "https://arxiv.org/abs/2509.19732", "authors": ["Kyo Kutsuzawa", "Mitsuhiro Hayashibe"], "title": "Simultaneous estimation of contact position and tool shape with high-dimensional parameters using force measurements and particle filtering", "comment": "Accepted to The International Journal of Robotics Research (IJRR)", "summary": "Estimating the contact state between a grasped tool and the environment is\nessential for performing contact tasks such as assembly and object\nmanipulation. Force signals are valuable for estimating the contact state, as\nthey can be utilized even when the contact location is obscured by the tool.\nPrevious studies proposed methods for estimating contact positions using\nforce/torque signals; however, most methods require the geometry of the tool\nsurface to be known. Although several studies have proposed methods that do not\nrequire the tool shape, these methods require considerable time for estimation\nor are limited to tools with low-dimensional shape parameters. Here, we propose\na method for simultaneously estimating the contact position and tool shape,\nwhere the tool shape is represented by a grid, which is high-dimensional (more\nthan 1000 dimensional). The proposed method uses a particle filter in which\neach particle has individual tool shape parameters, thereby to avoid directly\nhandling a high-dimensional parameter space. The proposed method is evaluated\nthrough simulations and experiments using tools with curved shapes on a plane.\nConsequently, the proposed method can estimate the shape of the tool\nsimultaneously with the contact positions, making the contact-position\nestimation more accurate.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u65f6\u4f30\u8ba1\u63a5\u89e6\u4f4d\u7f6e\u548c\u5de5\u5177\u5f62\u72b6\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u7f51\u683c\u8868\u793a\u9ad8\u7ef4\u5de5\u5177\u5f62\u72b6\uff0c\u901a\u8fc7\u7c92\u5b50\u6ee4\u6ce2\u5668\u907f\u514d\u76f4\u63a5\u5904\u7406\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u9700\u8981\u5df2\u77e5\u5de5\u5177\u8868\u9762\u51e0\u4f55\u5f62\u72b6\uff0c\u800c\u65e0\u9700\u5de5\u5177\u5f62\u72b6\u7684\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u5927\u91cf\u4f30\u8ba1\u65f6\u95f4\uff0c\u8981\u4e48\u4ec5\u9650\u4e8e\u4f4e\u7ef4\u5f62\u72b6\u53c2\u6570\u7684\u5de5\u5177\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5904\u7406\u9ad8\u7ef4\u5de5\u5177\u5f62\u72b6\u7684\u540c\u65f6\u4f30\u8ba1\u63a5\u89e6\u4f4d\u7f6e\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7c92\u5b50\u6ee4\u6ce2\u5668\uff0c\u6bcf\u4e2a\u7c92\u5b50\u5177\u6709\u72ec\u7acb\u7684\u5de5\u5177\u5f62\u72b6\u53c2\u6570\uff0c\u5de5\u5177\u5f62\u72b6\u7528\u7f51\u683c\u8868\u793a\uff08\u8d85\u8fc71000\u7ef4\uff09\uff0c\u907f\u514d\u4e86\u76f4\u63a5\u5904\u7406\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u540c\u65f6\u4f30\u8ba1\u5de5\u5177\u5f62\u72b6\u548c\u63a5\u89e6\u4f4d\u7f6e\uff0c\u63d0\u9ad8\u4e86\u63a5\u89e6\u4f4d\u7f6e\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u9ad8\u7ef4\u5de5\u5177\u5f62\u72b6\u7684\u540c\u65f6\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u63a5\u89e6\u72b6\u6001\u4f30\u8ba1\u7684\u7cbe\u5ea6\uff0c\u4e3a\u88c5\u914d\u548c\u7269\u4f53\u64cd\u4f5c\u7b49\u63a5\u89e6\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2509.19734", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19734", "abs": "https://arxiv.org/abs/2509.19734", "authors": ["Akshay Jaitly", "Jon Arrizabalaga", "Guanrui Li"], "title": "Trajectory Planning Using Safe Ellipsoidal Corridors as Projections of Orthogonal Trust Regions", "comment": null, "summary": "Planning collision free trajectories in complex environments remains a core\nchallenge in robotics. Existing corridor based planners which rely on\ndecomposition of the free space into collision free subsets scale poorly with\nenvironmental complexity and require explicit allocations of time windows to\ntrajectory segments. We introduce a new trajectory parameterization that\nrepresents trajectories in a nonconvex collision free corridor as being in a\nconvex cartesian product of balls. This parameterization allows us to decouple\nproblem size from geometric complexity of the solution and naturally avoids\nexplicit time allocation by allowing trajectories to evolve continuously inside\nellipsoidal corridors. Building on this representation, we formulate the\nOrthogonal Trust Region Problem (Orth-TRP), a specialized convex program with\nseparable block constraints, and develop a solver that exploits this parallel\nstructure and the unique structure of each parallel subproblem for efficient\noptimization. Experiments on a quadrotor trajectory planning benchmark show\nthat our approach produces smoother trajectories and lower runtimes than\nstate-of-the-art corridor based planners, especially in highly complicated\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f68\u8ff9\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u5c06\u975e\u51f8\u65e0\u78b0\u649e\u8d70\u5eca\u8868\u793a\u4e3a\u51f8\u7403\u4f53\u7b1b\u5361\u5c14\u79ef\uff0c\u4ece\u800c\u89e3\u8026\u95ee\u9898\u89c4\u6a21\u4e0e\u51e0\u4f55\u590d\u6742\u5ea6\uff0c\u907f\u514d\u663e\u5f0f\u65f6\u95f4\u5206\u914d\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684Orthogonal Trust Region Problem\u6c42\u89e3\u5668\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8d70\u5eca\u7684\u89c4\u5212\u5668\u5728\u590d\u6742\u73af\u5883\u4e2d\u6269\u5c55\u6027\u5dee\uff0c\u9700\u8981\u663e\u5f0f\u5206\u914d\u65f6\u95f4\u7a97\u53e3\u7ed9\u8f68\u8ff9\u6bb5\uff0c\u9650\u5236\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u51f8\u7403\u4f53\u7b1b\u5361\u5c14\u79ef\u53c2\u6570\u5316\u8f68\u8ff9\uff0c\u6784\u5efaOrthogonal Trust Region Problem\uff08Orth-TRP\uff09\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u5f00\u53d1\u4e13\u95e8\u6c42\u89e3\u5668\u5229\u7528\u5e76\u884c\u7ed3\u6784\u548c\u5b50\u95ee\u9898\u7279\u6027\u8fdb\u884c\u9ad8\u6548\u4f18\u5316\u3002", "result": "\u5728\u56db\u65cb\u7ffc\u8f68\u8ff9\u89c4\u5212\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6bd4\u6700\u5148\u8fdb\u7684\u8d70\u5eca\u89c4\u5212\u5668\u4ea7\u751f\u66f4\u5e73\u6ed1\u7684\u8f68\u8ff9\u548c\u66f4\u4f4e\u7684\u8fd0\u884c\u65f6\u95f4\uff0c\u5c24\u5176\u5728\u9ad8\u5ea6\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8f68\u8ff9\u53c2\u6570\u5316\u548c\u4f18\u5316\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u73af\u5883\u4e2d\u7684\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2509.19752", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19752", "abs": "https://arxiv.org/abs/2509.19752", "authors": ["Rushuai Yang", "Hangxing Wei", "Ran Zhang", "Zhiyuan Feng", "Xiaoyu Chen", "Tong Li", "Chuheng Zhang", "Li Zhao", "Jiang Bian", "Xiu Su", "Yi Chen"], "title": "Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training", "comment": null, "summary": "Vision-language-action (VLA) models have shown strong generalization across\ntasks and embodiments; however, their reliance on large-scale human\ndemonstrations limits their scalability owing to the cost and effort of manual\ndata collection. Reinforcement learning (RL) offers a potential alternative to\ngenerate demonstrations autonomously, yet conventional RL algorithms often\nstruggle on long-horizon manipulation tasks with sparse rewards. In this paper,\nwe propose a modified diffusion policy optimization algorithm to generate\nhigh-quality and low-variance trajectories, which contributes to a diffusion\nRL-powered VLA training pipeline. Our algorithm benefits from not only the high\nexpressiveness of diffusion models to explore complex and diverse behaviors but\nalso the implicit regularization of the iterative denoising process to yield\nsmooth and consistent demonstrations. We evaluate our approach on the LIBERO\nbenchmark, which includes 130 long-horizon manipulation tasks, and show that\nthe generated trajectories are smoother and more consistent than both human\ndemonstrations and those from standard Gaussian RL policies. Further, training\na VLA model exclusively on the diffusion RL-generated data achieves an average\nsuccess rate of 81.9%, which outperforms the model trained on human data by\n+5.3% and that on Gaussian RL-generated data by +12.6%. The results highlight\nour diffusion RL as an effective alternative for generating abundant,\nhigh-quality, and low-variance demonstrations for VLA models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6269\u6563\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u4f4e\u65b9\u5dee\u7684\u8f68\u8ff9\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6269\u6563\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684VLA\u8bad\u7ec3\u7ba1\u9053\u3002\u8be5\u65b9\u6cd5\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u751f\u6210\u7684\u8f68\u8ff9\u6bd4\u4eba\u7c7b\u6f14\u793a\u548c\u6807\u51c6\u9ad8\u65afRL\u7b56\u7565\u66f4\u5e73\u6ed1\u4e00\u81f4\u3002", "motivation": "VLA\u6a21\u578b\u4f9d\u8d56\u5927\u89c4\u6a21\u4eba\u7c7b\u6f14\u793a\uff0c\u4f46\u4eba\u5de5\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u4f20\u7edfRL\u7b97\u6cd5\u5728\u7a00\u758f\u5956\u52b1\u7684\u957f\u65f6\u7a0b\u64cd\u4f5c\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6539\u8fdb\u7684\u6269\u6563\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u7684\u9ad8\u8868\u8fbe\u80fd\u529b\u63a2\u7d22\u590d\u6742\u591a\u6837\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u53bb\u566a\u8fc7\u7a0b\u7684\u9690\u5f0f\u6b63\u5219\u5316\u4ea7\u751f\u5e73\u6ed1\u4e00\u81f4\u7684\u6f14\u793a\u3002\u6784\u5efa\u6269\u6563RL\u9a71\u52a8\u7684VLA\u8bad\u7ec3\u7ba1\u9053\u3002", "result": "\u5728\u5305\u542b130\u4e2a\u957f\u65f6\u7a0b\u64cd\u4f5c\u4efb\u52a1\u7684LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6269\u6563RL\u751f\u6210\u7684\u8f68\u8ff9\u6bd4\u4eba\u7c7b\u6f14\u793a\u548c\u9ad8\u65afRL\u7b56\u7565\u66f4\u5e73\u6ed1\u4e00\u81f4\u3002\u4ec5\u4f7f\u7528\u6269\u6563RL\u751f\u6210\u6570\u636e\u8bad\u7ec3\u7684VLA\u6a21\u578b\u5e73\u5747\u6210\u529f\u7387\u8fbe\u523081.9%\uff0c\u6bd4\u4eba\u7c7b\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u9ad85.3%\uff0c\u6bd4\u9ad8\u65afRL\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u9ad812.6%\u3002", "conclusion": "\u6269\u6563RL\u662f\u751f\u6210\u4e30\u5bcc\u3001\u9ad8\u8d28\u91cf\u3001\u4f4e\u65b9\u5deeVLA\u6a21\u578b\u6f14\u793a\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3aVLA\u6a21\u578b\u7684\u89c4\u6a21\u5316\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2509.19804", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19804", "abs": "https://arxiv.org/abs/2509.19804", "authors": ["Sowoo Lee", "Dongyun Kang", "Jaehyun Park", "Hae-Won Park"], "title": "DynaFlow: Dynamics-embedded Flow Matching for Physically Consistent Motion Generation from State-only Demonstrations", "comment": "8 pages", "summary": "This paper introduces DynaFlow, a novel framework that embeds a\ndifferentiable simulator directly into a flow matching model. By generating\ntrajectories in the action space and mapping them to dynamically feasible state\ntrajectories via the simulator, DynaFlow ensures all outputs are physically\nconsistent by construction. This end-to-end differentiable architecture enables\ntraining on state-only demonstrations, allowing the model to simultaneously\ngenerate physically consistent state trajectories while inferring the\nunderlying action sequences required to produce them. We demonstrate the\neffectiveness of our approach through quantitative evaluations and showcase its\nreal-world applicability by deploying the generated actions onto a physical Go1\nquadruped robot. The robot successfully reproduces diverse gait present in the\ndataset, executes long-horizon motions in open-loop control and translates\ninfeasible kinematic demonstrations into dynamically executable, stylistic\nbehaviors. These hardware experiments validate that DynaFlow produces\ndeployable, highly effective motions on real-world hardware from state-only\ndemonstrations, effectively bridging the gap between kinematic data and\nreal-world execution.", "AI": {"tldr": "DynaFlow\u662f\u4e00\u4e2a\u5c06\u53ef\u5fae\u5206\u6a21\u62df\u5668\u5d4c\u5165\u6d41\u5339\u914d\u6a21\u578b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u52a8\u4f5c\u7a7a\u95f4\u751f\u6210\u8f68\u8ff9\u5e76\u901a\u8fc7\u6a21\u62df\u5668\u6620\u5c04\u5230\u52a8\u6001\u53ef\u884c\u7684\u72b6\u6001\u8f68\u8ff9\uff0c\u786e\u4fdd\u6240\u6709\u8f93\u51fa\u5728\u6784\u9020\u4e0a\u7269\u7406\u4e00\u81f4\u3002", "motivation": "\u89e3\u51b3\u4ece\u4ec5\u72b6\u6001\u6f14\u793a\u751f\u6210\u7269\u7406\u4e00\u81f4\u8f68\u8ff9\u7684\u95ee\u9898\uff0c\u5f25\u5408\u8fd0\u52a8\u5b66\u6570\u636e\u4e0e\u73b0\u5b9e\u4e16\u754c\u6267\u884c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u67b6\u6784\uff0c\u5c06\u53ef\u5fae\u5206\u6a21\u62df\u5668\u76f4\u63a5\u5d4c\u5165\u6d41\u5339\u914d\u6a21\u578b\uff0c\u5728\u52a8\u4f5c\u7a7a\u95f4\u751f\u6210\u8f68\u8ff9\u5e76\u6620\u5c04\u5230\u72b6\u6001\u7a7a\u95f4\u3002", "result": "\u5728\u7269\u7406Go1\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u6210\u529f\u90e8\u7f72\uff0c\u91cd\u73b0\u6570\u636e\u96c6\u4e2d\u7684\u591a\u79cd\u6b65\u6001\uff0c\u6267\u884c\u957f\u65f6\u7a0b\u5f00\u73af\u63a7\u5236\uff0c\u5c06\u4e0d\u53ef\u884c\u7684\u8fd0\u52a8\u5b66\u6f14\u793a\u8f6c\u6362\u4e3a\u52a8\u6001\u53ef\u6267\u884c\u7684\u98ce\u683c\u5316\u884c\u4e3a\u3002", "conclusion": "DynaFlow\u80fd\u591f\u4ece\u4ec5\u72b6\u6001\u6f14\u793a\u751f\u6210\u53ef\u90e8\u7f72\u7684\u6709\u6548\u52a8\u4f5c\uff0c\u6709\u6548\u8fde\u63a5\u8fd0\u52a8\u5b66\u6570\u636e\u4e0e\u73b0\u5b9e\u4e16\u754c\u6267\u884c\u3002"}}
{"id": "2509.19851", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19851", "abs": "https://arxiv.org/abs/2509.19851", "authors": ["Benjamin Bogenberger", "Oliver Harrison", "Orrin Dahanaggamaarachchi", "Lukas Brunke", "Jingxing Qian", "Siqi Zhou", "Angela P. Schoellig"], "title": "Where Did I Leave My Glasses? Open-Vocabulary Semantic Exploration in Real-World Semi-Static Environments", "comment": null, "summary": "Robots deployed in real-world environments, such as homes, must not only\nnavigate safely but also understand their surroundings and adapt to environment\nchanges. To perform tasks efficiently, they must build and maintain a semantic\nmap that accurately reflects the current state of the environment. Existing\nresearch on semantic exploration largely focuses on static scenes without\npersistent object-level instance tracking. A consistent map is, however,\ncrucial for real-world robotic applications where objects in the environment\ncan be removed, reintroduced, or shifted over time. In this work, to close this\ngap, we propose an open-vocabulary, semantic exploration system for semi-static\nenvironments. Our system maintains a consistent map by building a probabilistic\nmodel of object instance stationarity, systematically tracking semi-static\nchanges, and actively exploring areas that have not been visited for a\nprolonged period of time. In addition to active map maintenance, our approach\nleverages the map's semantic richness with LLM-based reasoning for\nopen-vocabulary object-goal navigation. This enables the robot to search more\nefficiently by prioritizing contextually relevant areas. We evaluate our\napproach across multiple real-world semi-static environments. Our system\ndetects 95% of map changes on average, improving efficiency by more than 29% as\ncompared to random and patrol baselines. Overall, our approach achieves a\nmapping precision within 2% of a fully rebuilt map while requiring\nsubstantially less exploration and further completes object goal navigation\ntasks about 14% faster than the next-best tested strategy (coverage\npatrolling). A video of our work can be found at\nhttp://tiny.cc/sem-explor-semi-static .", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u63a2\u7d22\u7cfb\u7edf\uff0c\u7528\u4e8e\u534a\u9759\u6001\u73af\u5883\u4e2d\u7684\u673a\u5668\u4eba\u5bfc\u822a\u548c\u5730\u56fe\u7ef4\u62a4\uff0c\u901a\u8fc7\u6982\u7387\u6a21\u578b\u8ddf\u8e2a\u7269\u4f53\u5b9e\u4f8b\u7684\u9759\u6001\u6027\uff0c\u5e76\u5229\u7528LLM\u63a8\u7406\u8fdb\u884c\u9ad8\u6548\u76ee\u6807\u5bfc\u822a\u3002", "motivation": "\u73b0\u6709\u8bed\u4e49\u63a2\u7d22\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u573a\u666f\uff0c\u7f3a\u4e4f\u5bf9\u73af\u5883\u4e2d\u7269\u4f53\u79fb\u52a8\u3001\u79fb\u9664\u548c\u91cd\u65b0\u5f15\u5165\u7b49\u53d8\u5316\u7684\u6301\u7eed\u8ddf\u8e2a\u80fd\u529b\uff0c\u800c\u4e00\u81f4\u7684\u5730\u56fe\u5bf9\u4e8e\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6784\u5efa\u7269\u4f53\u5b9e\u4f8b\u9759\u6001\u6027\u7684\u6982\u7387\u6a21\u578b\uff0c\u7cfb\u7edf\u8ddf\u8e2a\u534a\u9759\u6001\u53d8\u5316\uff0c\u4e3b\u52a8\u63a2\u7d22\u957f\u65f6\u95f4\u672a\u8bbf\u95ee\u533a\u57df\uff0c\u5e76\u5229\u7528LLM\u63a8\u7406\u8fdb\u884c\u5f00\u653e\u8bcd\u6c47\u76ee\u6807\u5bfc\u822a\u3002", "result": "\u7cfb\u7edf\u5e73\u5747\u68c0\u6d4b\u523095%\u7684\u5730\u56fe\u53d8\u5316\uff0c\u6548\u7387\u6bd4\u968f\u673a\u548c\u5de1\u903b\u57fa\u7ebf\u63d0\u9ad829%\u4ee5\u4e0a\uff0c\u5730\u56fe\u7cbe\u5ea6\u4e0e\u5b8c\u5168\u91cd\u5efa\u5730\u56fe\u76f8\u5dee\u4e0d\u52302%\uff0c\u76ee\u6807\u5bfc\u822a\u4efb\u52a1\u5b8c\u6210\u901f\u5ea6\u6bd4\u6b21\u4f18\u7b56\u7565\u5feb\u7ea614%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u7ef4\u62a4\u534a\u9759\u6001\u73af\u5883\u4e2d\u7684\u8bed\u4e49\u5730\u56fe\uff0c\u663e\u8457\u63d0\u9ad8\u673a\u5668\u4eba\u5bfc\u822a\u6548\u7387\u548c\u73af\u5883\u9002\u5e94\u6027\uff0c\u4e3a\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19972", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19972", "abs": "https://arxiv.org/abs/2509.19972", "authors": ["Albina Klepach", "Egor E. Nuzhin", "Alexey A. Tsukanov", "Nikolay V. Brilliantov"], "title": "An effective control of large systems of active particles: An application to evacuation problem", "comment": null, "summary": "Manipulation of large systems of active particles is a serious challenge\nacross diverse domains, including crowd management, control of robotic swarms,\nand coordinated material transport. The development of advanced control\nstrategies for complex scenarios is hindered, however, by the lack of\nscalability and robustness of the existing methods, in particular, due to the\nneed of an individual control for each agent. One possible solution involves\ncontrolling a system through a leader or a group of leaders, which other agents\ntend to follow. Using such an approach we develop an effective control strategy\nfor a leader, combining reinforcement learning (RL) with artificial forces\nacting on the system. To describe the guidance of active particles by a leader\nwe introduce the generalized Vicsek model. This novel method is then applied to\nthe problem of the effective evacuation by a robot-rescuer (leader) of large\ngroups of people from hazardous places. We demonstrate, that while a\nstraightforward application of RL yields suboptimal results, even for advanced\narchitectures, our approach provides a robust and efficient evacuation\nstrategy. The source code supporting this study is publicly available at:\nhttps://github.com/cinemere/evacuation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4e0e\u4eba\u5de5\u529b\u7684\u9886\u5bfc\u8005\u63a7\u5236\u7b56\u7565\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u4e3b\u52a8\u7c92\u5b50\u7cfb\u7edf\u7684\u6709\u6548\u758f\u6563\u63a7\u5236", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u573a\u666f\u4e0b\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u9700\u8981\u5bf9\u6bcf\u4e2a\u667a\u80fd\u4f53\u8fdb\u884c\u5355\u72ec\u63a7\u5236\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u9ad8\u7ea7\u63a7\u5236\u7b56\u7565\u7684\u53d1\u5c55", "method": "\u5f15\u5165\u5e7f\u4e49Vicsek\u6a21\u578b\u63cf\u8ff0\u9886\u5bfc\u8005\u5bf9\u4e3b\u52a8\u7c92\u5b50\u7684\u5f15\u5bfc\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4e0e\u4eba\u5de5\u529b\u5f00\u53d1\u6709\u6548\u7684\u9886\u5bfc\u8005\u63a7\u5236\u7b56\u7565", "result": "\u8be5\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u6551\u63f4\u5458\u758f\u6563\u4eba\u7fa4\u7684\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u76f8\u6bd4\u76f4\u63a5\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u9ad8\u6548\u7684\u758f\u6563\u7b56\u7565", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u4e3b\u52a8\u7c92\u5b50\u7cfb\u7edf\u7684\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u7d27\u6025\u758f\u6563\u7b49\u590d\u6742\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.19853", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19853", "abs": "https://arxiv.org/abs/2509.19853", "authors": ["BinXu Wu", "TengFei Zhang", "Chen Yang", "JiaHao Wen", "HaoCheng Li", "JingTian Ma", "Zhen Chen", "JingYuan Wang"], "title": "SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process", "comment": null, "summary": "Multi-stage sequential (MSS) robotic manipulation tasks are prevalent and\ncrucial in robotics. They often involve state ambiguity, where visually similar\nobservations correspond to different actions. We present SAGE, a state-aware\nguided imitation learning framework that models tasks as a Hidden Markov\nDecision Process (HMDP) to explicitly capture latent task stages and resolve\nambiguity. We instantiate the HMDP with a state transition network that infers\nhidden states, and a state-aware action policy that conditions on both\nobservations and hidden states to produce actions, thereby enabling\ndisambiguation across task stages. To reduce manual annotation effort, we\npropose a semi-automatic labeling pipeline combining active learning and soft\nlabel interpolation. In real-world experiments across multiple complex MSS\ntasks with state ambiguity, SAGE achieved 100% task success under the standard\nevaluation protocol, markedly surpassing the baselines. Ablation studies\nfurther show that such performance can be maintained with manual labeling for\nonly about 13% of the states, indicating its strong effectiveness.", "AI": {"tldr": "SAGE\u662f\u4e00\u4e2a\u72b6\u6001\u611f\u77e5\u7684\u5f15\u5bfc\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u9636\u6bb5\u987a\u5e8f\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u72b6\u6001\u6a21\u7cca\u95ee\u9898\uff0c\u901a\u8fc7\u9690\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u4efb\u52a1\u9636\u6bb5\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86100%\u7684\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u591a\u9636\u6bb5\u987a\u5e8f\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u666e\u904d\u5b58\u5728\u72b6\u6001\u6a21\u7cca\u95ee\u9898\uff0c\u5373\u89c6\u89c9\u76f8\u4f3c\u7684\u89c2\u5bdf\u5bf9\u5e94\u4e0d\u540c\u7684\u52a8\u4f5c\uff0c\u9700\u8981\u663e\u5f0f\u6355\u6349\u6f5c\u5728\u4efb\u52a1\u9636\u6bb5\u6765\u89e3\u51b3\u6a21\u7cca\u6027\u3002", "method": "\u5c06\u4efb\u52a1\u5efa\u6a21\u4e3a\u9690\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5305\u542b\u72b6\u6001\u8f6c\u79fb\u7f51\u7edc\u63a8\u65ad\u9690\u85cf\u72b6\u6001\uff0c\u4ee5\u53ca\u72b6\u6001\u611f\u77e5\u52a8\u4f5c\u7b56\u7565\u57fa\u4e8e\u89c2\u5bdf\u548c\u9690\u85cf\u72b6\u6001\u751f\u6210\u52a8\u4f5c\uff1b\u63d0\u51fa\u534a\u81ea\u52a8\u6807\u6ce8\u6d41\u7a0b\u7ed3\u5408\u4e3b\u52a8\u5b66\u4e60\u548c\u8f6f\u6807\u7b7e\u63d2\u503c\u3002", "result": "\u5728\u591a\u4e2a\u5177\u6709\u72b6\u6001\u6a21\u7cca\u6027\u7684\u590d\u6742\u591a\u9636\u6bb5\u987a\u5e8f\u4efb\u52a1\u4e2d\uff0cSAGE\u5728\u6807\u51c6\u8bc4\u4f30\u534f\u8bae\u4e0b\u5b9e\u73b0\u4e86100%\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\uff1b\u6d88\u878d\u7814\u7a76\u663e\u793a\u4ec5\u9700\u624b\u52a8\u6807\u6ce8\u7ea613%\u7684\u72b6\u6001\u5373\u53ef\u7ef4\u6301\u6027\u80fd\u3002", "conclusion": "SAGE\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u4efb\u52a1\u9636\u6bb5\u6709\u6548\u89e3\u51b3\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u72b6\u6001\u6a21\u7cca\u95ee\u9898\uff0c\u5177\u6709\u9ad8\u6210\u529f\u7387\u548c\u4f4e\u6807\u6ce8\u9700\u6c42\u7684\u4f18\u52bf\u3002"}}
{"id": "2509.19892", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19892", "abs": "https://arxiv.org/abs/2509.19892", "authors": ["Keyu Wang", "Bingcong Lu", "Zhengxue Cheng", "Hengdi Zhang", "Li Song"], "title": "D3Grasp: Diverse and Deformable Dexterous Grasping for General Objects", "comment": null, "summary": "Achieving diverse and stable dexterous grasping for general and deformable\nobjects remains a fundamental challenge in robotics, due to high-dimensional\naction spaces and uncertainty in perception. In this paper, we present D3Grasp,\na multimodal perception-guided reinforcement learning framework designed to\nenable Diverse and Deformable Dexterous Grasping. We firstly introduce a\nunified multimodal representation that integrates visual and tactile perception\nto robustly grasp common objects with diverse properties. Second, we propose an\nasymmetric reinforcement learning architecture that exploits privileged\ninformation during training while preserving deployment realism, enhancing both\ngeneralization and sample efficiency. Third, we meticulously design a training\nstrategy to synthesize contact-rich, penetration-free, and kinematically\nfeasible grasps with enhanced adaptability to deformable and contact-sensitive\nobjects. Extensive evaluations confirm that D3Grasp delivers highly robust\nperformance across large-scale and diverse object categories, and substantially\nadvances the state of the art in dexterous grasping for deformable and\ncompliant objects, even under perceptual uncertainty and real-world\ndisturbances. D3Grasp achieves an average success rate of 95.1% in real-world\ntrials,outperforming prior methods on both rigid and deformable objects\nbenchmarks.", "AI": {"tldr": "D3Grasp\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u611f\u77e5\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u591a\u6837\u5316\u548c\u7a33\u5b9a\u7684\u7075\u5de7\u6293\u53d6\uff0c\u7279\u522b\u9488\u5bf9\u53ef\u53d8\u5f62\u7269\u4f53\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u8bd5\u9a8c\u4e2d\u8fbe\u523095.1%\u7684\u5e73\u5747\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u548c\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u901a\u7528\u548c\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u591a\u6837\u7a33\u5b9a\u7075\u5de7\u6293\u53d6\u3002", "method": "1\uff09\u5f15\u5165\u7edf\u4e00\u7684\u591a\u6a21\u6001\u8868\u793a\u6574\u5408\u89c6\u89c9\u548c\u89e6\u89c9\u611f\u77e5\uff1b2\uff09\u63d0\u51fa\u975e\u5bf9\u79f0\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\u5229\u7528\u7279\u6743\u4fe1\u606f\uff1b3\uff09\u8bbe\u8ba1\u8bad\u7ec3\u7b56\u7565\u5408\u6210\u63a5\u89e6\u4e30\u5bcc\u3001\u65e0\u7a7f\u900f\u4e14\u8fd0\u52a8\u5b66\u53ef\u884c\u7684\u6293\u53d6\u3002", "result": "\u5728\u5927\u89c4\u6a21\u591a\u6837\u5316\u7269\u4f53\u7c7b\u522b\u4e0a\u8868\u73b0\u51fa\u9ad8\u5ea6\u9c81\u68d2\u6027\uff0c\u5728\u53ef\u53d8\u5f62\u548c\u67d4\u987a\u7269\u4f53\u7075\u5de7\u6293\u53d6\u65b9\u9762\u663e\u8457\u63a8\u8fdb\u4e86\u6280\u672f\u524d\u6cbf\uff0c\u771f\u5b9e\u4e16\u754c\u8bd5\u9a8c\u5e73\u5747\u6210\u529f\u738795.1%\u3002", "conclusion": "D3Grasp\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7075\u5de7\u6293\u53d6\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u771f\u5b9e\u4e16\u754c\u5e72\u6270\u4e0b\u8868\u73b0\u51fa\u4f18\u5f02\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u521a\u6027\u548c\u53ef\u53d8\u5f62\u7269\u4f53\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2509.20109", "categories": ["cs.RO", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.20109", "abs": "https://arxiv.org/abs/2509.20109", "authors": ["Pengxiang Li", "Yinan Zheng", "Yue Wang", "Huimin Wang", "Hang Zhao", "Jingjing Liu", "Xianyuan Zhan", "Kun Zhan", "Xianpeng Lang"], "title": "Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving", "comment": null, "summary": "End-to-End (E2E) solutions have emerged as a mainstream approach for\nautonomous driving systems, with Vision-Language-Action (VLA) models\nrepresenting a new paradigm that leverages pre-trained multimodal knowledge\nfrom Vision-Language Models (VLMs) to interpret and interact with complex\nreal-world environments. However, these methods remain constrained by the\nlimitations of imitation learning, which struggles to inherently encode\nphysical rules during training. Existing approaches often rely on complex\nrule-based post-refinement, employ reinforcement learning that remains largely\nlimited to simulation, or utilize diffusion guidance that requires\ncomputationally expensive gradient calculations. To address these challenges,\nwe introduce ReflectDrive, a novel learning-based framework that integrates a\nreflection mechanism for safe trajectory generation via discrete diffusion. We\nfirst discretize the two-dimensional driving space to construct an action\ncodebook, enabling the use of pre-trained Diffusion Language Models for\nplanning tasks through fine-tuning. Central to our approach is a safety-aware\nreflection mechanism that performs iterative self-correction without gradient\ncomputation. Our method begins with goal-conditioned trajectory generation to\nmodel multi-modal driving behaviors. Based on this, we apply local search\nmethods to identify unsafe tokens and determine feasible solutions, which then\nserve as safe anchors for inpainting-based regeneration. Evaluated on the\nNAVSIM benchmark, ReflectDrive demonstrates significant advantages in\nsafety-critical trajectory generation, offering a scalable and reliable\nsolution for autonomous driving systems.", "AI": {"tldr": "ReflectDrive\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u6563\u6269\u6563\u548c\u53cd\u5c04\u673a\u5236\u5b9e\u73b0\u5b89\u5168\u8f68\u8ff9\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709VLA\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u96be\u4ee5\u7f16\u7801\u7269\u7406\u89c4\u5219\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u65b9\u6cd5\u53d7\u9650\u4e8e\u6a21\u4eff\u5b66\u4e60\u7684\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u7f16\u7801\u7269\u7406\u89c4\u5219\uff0c\u901a\u5e38\u9700\u8981\u590d\u6742\u7684\u540e\u5904\u7406\u89c4\u5219\u6216\u8ba1\u7b97\u6602\u8d35\u7684\u68af\u5ea6\u8ba1\u7b97\u3002", "method": "\u9996\u5148\u5c06\u4e8c\u7ef4\u9a7e\u9a76\u7a7a\u95f4\u79bb\u6563\u5316\u6784\u5efa\u52a8\u4f5c\u7801\u672c\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6269\u6563\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u89c4\u5212\uff1b\u6838\u5fc3\u662f\u5b89\u5168\u611f\u77e5\u7684\u53cd\u5c04\u673a\u5236\uff0c\u901a\u8fc7\u5c40\u90e8\u641c\u7d22\u8bc6\u522b\u4e0d\u5b89\u5168\u6807\u8bb0\u5e76\u786e\u5b9a\u53ef\u884c\u89e3\uff0c\u4f5c\u4e3a\u57fa\u4e8e\u4fee\u590d\u7684\u518d\u751f\u6210\u7684\u5b89\u5168\u951a\u70b9\u3002", "result": "\u5728NAVSIM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReflectDrive\u5728\u5b89\u5168\u5173\u952e\u8f68\u8ff9\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19916", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19916", "abs": "https://arxiv.org/abs/2509.19916", "authors": ["Zijun Che", "Yinghong Zhang", "Shengyi Liang", "Boyu Zhou", "Jun Ma", "Jinni Zhou"], "title": "GUIDE: A Diffusion-Based Autonomous Robot Exploration Framework Using Global Graph Inference", "comment": null, "summary": "Autonomous exploration in structured and complex indoor environments remains\na challenging task, as existing methods often struggle to appropriately model\nunobserved space and plan globally efficient paths. To address these\nlimitations, we propose GUIDE, a novel exploration framework that\nsynergistically combines global graph inference with diffusion-based\ndecision-making. We introduce a region-evaluation global graph representation\nthat integrates both observed environmental data and predictions of unexplored\nareas, enhanced by a region-level evaluation mechanism to prioritize reliable\nstructural inferences while discounting uncertain predictions. Building upon\nthis enriched representation, a diffusion policy network generates stable,\nforesighted action sequences with significantly reduced denoising steps.\nExtensive simulations and real-world deployments demonstrate that GUIDE\nconsistently outperforms state-of-the-art methods, achieving up to 18.3% faster\ncoverage completion and a 34.9% reduction in redundant movements.", "AI": {"tldr": "GUIDE\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u81ea\u4e3b\u63a2\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5168\u5c40\u56fe\u63a8\u7406\u548c\u6269\u6563\u51b3\u7b56\u6765\u89e3\u51b3\u7ed3\u6784\u5316\u5ba4\u5185\u73af\u5883\u4e2d\u63a2\u7d22\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u8986\u76d6\u5b8c\u6210\u548c\u66f4\u5c11\u7684\u5197\u4f59\u79fb\u52a8\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5efa\u6a21\u672a\u89c2\u5bdf\u7a7a\u95f4\u548c\u89c4\u5212\u5168\u5c40\u9ad8\u6548\u8def\u5f84\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u7ed3\u6784\u5316\u590d\u6742\u5ba4\u5185\u73af\u5883\u4e2d\u3002", "method": "\u63d0\u51fa\u533a\u57df\u8bc4\u4f30\u5168\u5c40\u56fe\u8868\u793a\uff0c\u6574\u5408\u89c2\u6d4b\u6570\u636e\u548c\u672a\u63a2\u7d22\u533a\u57df\u9884\u6d4b\uff0c\u91c7\u7528\u6269\u6563\u7b56\u7565\u7f51\u7edc\u751f\u6210\u7a33\u5b9a\u7684\u524d\u77bb\u6027\u52a8\u4f5c\u5e8f\u5217\u3002", "result": "\u5728\u4eff\u771f\u548c\u5b9e\u9645\u90e8\u7f72\u4e2d\uff0cGUIDE\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5b9e\u73b0\u4e8618.3%\u7684\u66f4\u5feb\u8986\u76d6\u5b8c\u6210\u548c34.9%\u7684\u5197\u4f59\u79fb\u52a8\u51cf\u5c11\u3002", "conclusion": "GUIDE\u6846\u67b6\u901a\u8fc7\u5168\u5c40\u56fe\u63a8\u7406\u548c\u6269\u6563\u51b3\u7b56\u7684\u534f\u540c\u4f5c\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u4e3b\u63a2\u7d22\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2509.19954", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19954", "abs": "https://arxiv.org/abs/2509.19954", "authors": ["Pinhao Song", "Yurui Du", "Ophelie Saussus", "Sofie De Schrijver", "Irene Caprara", "Peter Janssen", "Renaud Detry"], "title": "Robot Trajectron V2: A Probabilistic Shared Control Framework for Navigation", "comment": "26 pages, 20 figures", "summary": "We propose a probabilistic shared-control solution for navigation, called\nRobot Trajectron V2 (RT-V2), that enables accurate intent prediction and safe,\neffective assistance in human-robot interaction. RT-V2 jointly models a user's\nlong-term behavioral patterns and their noisy, low-dimensional control signals\nby combining a prior intent model with a posterior update that accounts for\nreal-time user input and environmental context. The prior captures the\nmultimodal and history-dependent nature of user intent using recurrent neural\nnetworks and conditional variational autoencoders, while the posterior\nintegrates this with uncertain user commands to infer desired actions. We\nconduct extensive experiments to validate RT-V2 across synthetic benchmarks,\nhuman-computer interaction studies with keyboard input, and brain-machine\ninterface experiments with non-human primates. Results show that RT-V2\noutperforms the state of the art in intent estimation, provides safe and\nefficient navigation support, and adequately balances user autonomy with\nassistive intervention. By unifying probabilistic modeling, reinforcement\nlearning, and safe optimization, RT-V2 offers a principled and generalizable\napproach to shared control for diverse assistive technologies.", "AI": {"tldr": "RT-V2\u662f\u4e00\u4e2a\u6982\u7387\u5171\u4eab\u63a7\u5236\u5bfc\u822a\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u5408\u5148\u9a8c\u610f\u56fe\u6a21\u578b\u548c\u540e\u9a8c\u66f4\u65b0\u6765\u51c6\u786e\u9884\u6d4b\u7528\u6237\u610f\u56fe\u5e76\u63d0\u4f9b\u5b89\u5168\u6709\u6548\u7684\u4eba\u673a\u4ea4\u4e92\u8f85\u52a9", "motivation": "\u89e3\u51b3\u4eba\u673a\u4ea4\u4e92\u4e2d\u610f\u56fe\u9884\u6d4b\u4e0d\u51c6\u786e\u3001\u8f85\u52a9\u63a7\u5236\u4e0d\u5b89\u5168\u4e0d\u9ad8\u6548\u7684\u95ee\u9898\uff0c\u5e73\u8861\u7528\u6237\u81ea\u4e3b\u6027\u548c\u8f85\u52a9\u5e72\u9884", "method": "\u7ed3\u5408\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548c\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5efa\u7acb\u591a\u6a21\u6001\u5386\u53f2\u4f9d\u8d56\u7684\u5148\u9a8c\u610f\u56fe\u6a21\u578b\uff0c\u901a\u8fc7\u540e\u9a8c\u66f4\u65b0\u6574\u5408\u5b9e\u65f6\u7528\u6237\u8f93\u5165\u548c\u73af\u5883\u4e0a\u4e0b\u6587\uff0c\u4f7f\u7528\u6982\u7387\u5efa\u6a21\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u5b89\u5168\u4f18\u5316\u7edf\u4e00\u65b9\u6cd5", "result": "\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u3001\u4eba\u673a\u952e\u76d8\u4ea4\u4e92\u5b9e\u9a8c\u548c\u8111\u673a\u63a5\u53e3\u5b9e\u9a8c\u4e2d\uff0cRT-V2\u5728\u610f\u56fe\u4f30\u8ba1\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u63d0\u4f9b\u5b89\u5168\u9ad8\u6548\u7684\u5bfc\u822a\u652f\u6301", "conclusion": "RT-V2\u4e3a\u591a\u6837\u5316\u8f85\u52a9\u6280\u672f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u548c\u53ef\u63a8\u5e7f\u7684\u5171\u4eab\u63a7\u5236\u65b9\u6cd5"}}
{"id": "2509.20253", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20253", "abs": "https://arxiv.org/abs/2509.20253", "authors": ["Jinhao Chai", "Anqing Jiang", "Hao Jiang", "Shiyi Mu", "Zichong Gu", "Shugong Xu"], "title": "AnchDrive: Bootstrapping Diffusion Policies with Hybrid Trajectory Anchors for End-to-End Driving", "comment": "IWACIII 2025", "summary": "End-to-end multi-modal planning has become a transformative paradigm in\nautonomous driving, effectively addressing behavioral multi-modality and the\ngeneralization challenge in long-tail scenarios. We propose AnchDrive, a\nframework for end-to-end driving that effectively bootstraps a diffusion policy\nto mitigate the high computational cost of traditional generative models.\nRather than denoising from pure noise, AnchDrive initializes its planner with a\nrich set of hybrid trajectory anchors. These anchors are derived from two\ncomplementary sources: a static vocabulary of general driving priors and a set\nof dynamic, context-aware trajectories. The dynamic trajectories are decoded in\nreal-time by a Transformer that processes dense and sparse perceptual features.\nThe diffusion model then learns to refine these anchors by predicting a\ndistribution of trajectory offsets, enabling fine-grained refinement. This\nanchor-based bootstrapping design allows for efficient generation of diverse,\nhigh-quality trajectories. Experiments on the NAVSIM benchmark confirm that\nAnchDrive sets a new state-of-the-art and shows strong gen?eralizability", "AI": {"tldr": "AnchDrive\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u8f68\u8ff9\u951a\u70b9\u5f15\u5bfc\u6269\u6563\u7b56\u7565\uff0c\u6709\u6548\u964d\u4f4e\u751f\u6210\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u5728NAVSIM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u7aef\u5230\u7aef\u591a\u6a21\u6001\u89c4\u5212\u4e2d\u7684\u884c\u4e3a\u591a\u6a21\u6001\u6027\u548c\u957f\u5c3e\u573a\u666f\u6cdb\u5316\u6311\u6218\uff0c\u540c\u65f6\u964d\u4f4e\u4f20\u7edf\u751f\u6210\u6a21\u578b\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u8f68\u8ff9\u951a\u70b9\u7684\u6269\u6563\u7b56\u7565\uff1a\u4f7f\u7528\u9759\u6001\u9a7e\u9a76\u5148\u9a8c\u548c\u52a8\u6001\u4e0a\u4e0b\u6587\u611f\u77e5\u8f68\u8ff9\u4f5c\u4e3a\u951a\u70b9\uff0c\u901a\u8fc7Transformer\u89e3\u7801\u52a8\u6001\u8f68\u8ff9\uff0c\u6269\u6563\u6a21\u578b\u5b66\u4e60\u9884\u6d4b\u8f68\u8ff9\u504f\u79fb\u5206\u5e03\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4f18\u5316\u3002", "result": "\u5728NAVSIM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8e\u951a\u70b9\u7684\u5f15\u5bfc\u8bbe\u8ba1\u80fd\u591f\u9ad8\u6548\u751f\u6210\u591a\u6837\u5316\u3001\u9ad8\u8d28\u91cf\u7684\u8f68\u8ff9\uff0c\u4e3a\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19958", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19958", "abs": "https://arxiv.org/abs/2509.19958", "authors": ["Alexander Spiridonov", "Jan-Nico Zaech", "Nikolay Nikolov", "Luc Van Gool", "Danda Pani Paudel"], "title": "Generalist Robot Manipulation beyond Action Labeled Data", "comment": "Accepted at Conference on Robot Learning 2025", "summary": "Recent advances in generalist robot manipulation leverage pre-trained\nVision-Language Models (VLMs) and large-scale robot demonstrations to tackle\ndiverse tasks in a zero-shot manner. A key challenge remains: scaling\nhigh-quality, action-labeled robot demonstration data, which existing methods\nrely on for robustness and generalization. To address this, we propose a method\nthat benefits from videos without action labels - featuring humans and/or\nrobots in action - enhancing open-vocabulary performance and enabling\ndata-efficient learning of new tasks. Our method extracts dense, dynamic 3D\npoint clouds at the hand or gripper location and uses a proposed 3D dynamics\npredictor for self-supervision. This predictor is then tuned to an action\npredictor using a smaller labeled dataset for action alignment. We show that\nour method not only learns from unlabeled human and robot demonstrations -\nimproving downstream generalist robot policies - but also enables robots to\nlearn new tasks without action labels (i.e., out-of-action generalization) in\nboth real-world and simulated settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u65e0\u52a8\u4f5c\u6807\u7b7e\u89c6\u9891\uff08\u5305\u542b\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u52a8\u4f5c\uff09\u6765\u589e\u5f3a\u673a\u5668\u4eba\u64cd\u4f5c\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u5bc6\u96c6\u52a8\u60013D\u70b9\u4e91\u548c\u4f7f\u75283D\u52a8\u6001\u9884\u6d4b\u5668\u8fdb\u884c\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u51cf\u5c11\u5bf9\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u89e3\u51b3\u901a\u7528\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u9ad8\u8d28\u91cf\u52a8\u4f5c\u6807\u6ce8\u6570\u636e\u96be\u4ee5\u83b7\u53d6\u7684\u6311\u6218\uff0c\u5229\u7528\u5927\u91cf\u65e0\u6807\u7b7e\u89c6\u9891\u6570\u636e\u63d0\u5347\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u548c\u6570\u636e\u6548\u7387\u3002", "method": "\u63d0\u53d6\u624b\u90e8\u6216\u5939\u722a\u4f4d\u7f6e\u7684\u5bc6\u96c6\u52a8\u60013D\u70b9\u4e91\uff0c\u8bbe\u8ba13D\u52a8\u6001\u9884\u6d4b\u5668\u8fdb\u884c\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u7136\u540e\u7528\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u5fae\u8c03\u4e3a\u52a8\u4f5c\u9884\u6d4b\u5668\u5b9e\u73b0\u52a8\u4f5c\u5bf9\u9f50\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u4ece\u65e0\u6807\u7b7e\u7684\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u6f14\u793a\u4e2d\u5b66\u4e60\uff0c\u63d0\u5347\u4e0b\u6e38\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u6027\u80fd\uff0c\u5e76\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5728\u65e0\u52a8\u4f5c\u6807\u7b7e\u60c5\u51b5\u4e0b\u5b66\u4e60\u65b0\u4efb\u52a1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7a81\u7834\u4e86\u4f20\u7edf\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u4e3a\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u6570\u636e\u5229\u7528\u65b9\u5f0f\uff0c\u5728\u771f\u5b9e\u548c\u4eff\u771f\u73af\u5883\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.20009", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20009", "abs": "https://arxiv.org/abs/2509.20009", "authors": ["Simon Sch\u00e4fer", "Bassam Alrifaee", "Ehsan Hashemi"], "title": "Lidar-based Tracking of Traffic Participants with Sensor Nodes in Existing Urban Infrastructure", "comment": "21 pages, 9 figures, this work was submitted to Wileys'Advanced\n  Intelligent Systems for review", "summary": "This paper presents a lidar-only state estimation and tracking framework,\nalong with a roadside sensing unit for integration with existing urban\ninfrastructure. Urban deployments demand scalable, real-time tracking\nsolutions, yet traditional remote sensing remains costly and computationally\nintensive, especially under perceptually degraded conditions. Our sensor node\ncouples a single lidar with an edge computing unit and runs a computationally\nefficient, GPU-free observer that simultaneously estimates object state, class,\ndimensions, and existence probability. The pipeline performs: (i) state updates\nvia an extended Kalman filter, (ii) dimension estimation using a 1D\ngrid-map/Bayesian update, (iii) class updates via a lookup table driven by the\nmost probable footprint, and (iv) existence estimation from track age and\nbounding-box consistency. Experiments in dynamic urban-like scenes with diverse\ntraffic participants demonstrate real-time performance and high precision: The\ncomplete end-to-end pipeline finishes within \\SI{100}{\\milli\\second} for\n\\SI{99.88}{\\%} of messages, with an excellent detection rate. Robustness is\nfurther confirmed under simulated wind and sensor vibration. These results\nindicate that reliable, real-time roadside tracking is feasible on CPU-only\nedge hardware, enabling scalable, privacy-friendly deployments within existing\ncity infrastructure. The framework integrates with existing poles, traffic\nlights, and buildings, reducing deployment costs and simplifying large-scale\nurban rollouts and maintenance efforts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6fc0\u5149\u96f7\u8fbe\u7684\u8def\u8fb9\u72b6\u6001\u4f30\u8ba1\u4e0e\u8ddf\u8e2a\u6846\u67b6\uff0c\u7ed3\u5408\u8fb9\u7f18\u8ba1\u7b97\u5355\u5143\uff0c\u5b9e\u73b0\u5b9e\u65f6\u3001\u53ef\u6269\u5c55\u7684\u57ce\u5e02\u57fa\u7840\u8bbe\u65bd\u96c6\u6210\u89e3\u51b3\u65b9\u6848", "motivation": "\u57ce\u5e02\u90e8\u7f72\u9700\u8981\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u8ddf\u8e2a\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4f20\u7edf\u8fdc\u7a0b\u4f20\u611f\u6210\u672c\u9ad8\u4e14\u8ba1\u7b97\u5bc6\u96c6\uff0c\u7279\u522b\u662f\u5728\u611f\u77e5\u9000\u5316\u6761\u4ef6\u4e0b", "method": "\u4f7f\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u8fdb\u884c\u72b6\u6001\u66f4\u65b0\uff0c1D\u7f51\u683c\u56fe/\u8d1d\u53f6\u65af\u66f4\u65b0\u8fdb\u884c\u5c3a\u5bf8\u4f30\u8ba1\uff0c\u67e5\u627e\u8868\u9a71\u52a8\u5206\u7c7b\u66f4\u65b0\uff0c\u57fa\u4e8e\u8ddf\u8e2a\u65f6\u95f4\u548c\u8fb9\u754c\u6846\u4e00\u81f4\u6027\u8fdb\u884c\u5b58\u5728\u6982\u7387\u4f30\u8ba1", "result": "\u5728\u52a8\u6001\u57ce\u5e02\u573a\u666f\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u6027\u80fd\u548c\u9ad8\u7cbe\u5ea6\uff1a\u5b8c\u6574\u7aef\u5230\u7aef\u7ba1\u905399.88%\u7684\u6d88\u606f\u5728100\u6beb\u79d2\u5185\u5b8c\u6210\uff0c\u68c0\u6d4b\u7387\u4f18\u79c0\uff0c\u5728\u6a21\u62df\u98ce\u548c\u4f20\u611f\u5668\u632f\u52a8\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027", "conclusion": "\u53ef\u9760\u7684\u5b9e\u65f6\u8def\u8fb9\u8ddf\u8e2a\u5728\u4ec5CPU\u7684\u8fb9\u7f18\u786c\u4ef6\u4e0a\u53ef\u884c\uff0c\u53ef\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u9690\u79c1\u53cb\u597d\u7684\u57ce\u5e02\u57fa\u7840\u8bbe\u65bd\u90e8\u7f72"}}
{"id": "2509.20036", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20036", "abs": "https://arxiv.org/abs/2509.20036", "authors": ["Yinzhao Dong", "Ji Ma", "Liu Zhao", "Wanyue Li", "Peng Lu"], "title": "MARG: MAstering Risky Gap Terrains for Legged Robots with Elevation Mapping", "comment": null, "summary": "Deep Reinforcement Learning (DRL) controllers for quadrupedal locomotion have\ndemonstrated impressive performance on challenging terrains, allowing robots to\nexecute complex skills such as climbing, running, and jumping. However,\nexisting blind locomotion controllers often struggle to ensure safety and\nefficient traversal through risky gap terrains, which are typically highly\ncomplex, requiring robots to perceive terrain information and select\nappropriate footholds during locomotion accurately. Meanwhile, existing\nperception-based controllers still present several practical limitations,\nincluding a complex multi-sensor deployment system and expensive computing\nresource requirements. This paper proposes a DRL controller named MAstering\nRisky Gap Terrains (MARG), which integrates terrain maps and proprioception to\ndynamically adjust the action and enhance the robot's stability in these tasks.\nDuring the training phase, our controller accelerates policy optimization by\nselectively incorporating privileged information (e.g., center of mass,\nfriction coefficients) that are available in simulation but unmeasurable\ndirectly in real-world deployments due to sensor limitations. We also designed\nthree foot-related rewards to encourage the robot to explore safe footholds.\nMore importantly, a terrain map generation (TMG) model is proposed to reduce\nthe drift existing in mapping and provide accurate terrain maps using only one\nLiDAR, providing a foundation for zero-shot transfer of the learned policy. The\nexperimental results indicate that MARG maintains stability in various risky\nterrain tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMARG\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\uff0c\u7528\u4e8e\u56db\u8db3\u673a\u5668\u4eba\u5728\u5371\u9669\u95f4\u9699\u5730\u5f62\u4e0a\u7684\u5b89\u5168\u9ad8\u6548\u8fd0\u52a8\u3002", "motivation": "\u73b0\u6709\u7684\u76f2\u8fd0\u52a8\u63a7\u5236\u5668\u5728\u5371\u9669\u95f4\u9699\u5730\u5f62\u4e0a\u96be\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\u548c\u9ad8\u6548\u6027\uff0c\u800c\u57fa\u4e8e\u611f\u77e5\u7684\u63a7\u5236\u5668\u53c8\u5b58\u5728\u591a\u4f20\u611f\u5668\u90e8\u7f72\u590d\u6742\u548c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\u7684\u95ee\u9898\u3002", "method": "MARG\u63a7\u5236\u5668\u6574\u5408\u5730\u5f62\u56fe\u548c\u672c\u4f53\u611f\u77e5\u6765\u52a8\u6001\u8c03\u6574\u52a8\u4f5c\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u4f7f\u7528\u4eff\u771f\u4e2d\u7684\u7279\u6743\u4fe1\u606f\u52a0\u901f\u7b56\u7565\u4f18\u5316\uff0c\u8bbe\u8ba1\u4e86\u4e09\u4e2a\u8db3\u90e8\u76f8\u5173\u5956\u52b1\u6765\u9f13\u52b1\u63a2\u7d22\u5b89\u5168\u843d\u811a\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86\u4ec5\u4f7f\u7528\u4e00\u4e2aLiDAR\u7684\u5730\u5f62\u56fe\u751f\u6210\u6a21\u578b\u6765\u51cf\u5c11\u6620\u5c04\u6f02\u79fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMARG\u5728\u5404\u79cd\u5371\u9669\u5730\u5f62\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u7a33\u5b9a\u6027\u3002", "conclusion": "MARG\u63a7\u5236\u5668\u901a\u8fc7\u6574\u5408\u5730\u5f62\u611f\u77e5\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u5728\u590d\u6742\u95f4\u9699\u5730\u5f62\u4e0a\u7684\u96f6\u6837\u672c\u7b56\u7565\u8fc1\u79fb\u548c\u7a33\u5b9a\u8fd0\u52a8\u3002"}}
{"id": "2509.20070", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20070", "abs": "https://arxiv.org/abs/2509.20070", "authors": ["Abraham George", "Amir Barati Farimani"], "title": "LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs", "comment": "9 pages, 5 figures, 4 tables. Submitted to ICRA 2026", "summary": "We present LLM Trainer, a fully automated pipeline that leverages the world\nknowledge of Large Language Models (LLMs) to transform a small number of human\ndemonstrations (as few as one) into a large robot dataset for imitation\nlearning. Our approach decomposes demonstration generation into two steps: (1)\noffline demonstration annotation that extracts keyframes, salient objects, and\npose-object relations; and (2) online keypose retargeting that adapts those\nkeyframes to a new scene, given an initial observation. Using these modified\nkeypoints, our system warps the original demonstration to generate a new\ntrajectory, which is then executed, and the resulting demo, if successful, is\nsaved. Because the annotation is reusable across scenes, we use Thompson\nsampling to optimize the annotation, significantly improving generation success\nrate. We evaluate our method on a range of tasks, and find that our data\nannotation method consistently outperforms expert-engineered baselines. We\nfurther show an ensemble policy that combines the optimized LLM feed-forward\nplan with a learned feedback imitation learning controller. Finally, we\ndemonstrate hardware feasibility on a Franka Emika Panda robot. For additional\nmaterials and demonstration videos, please see the project website:\nhttps://sites.google.com/andrew.cmu.edu/llm-trainer", "AI": {"tldr": "LLM Trainer\u662f\u4e00\u4e2a\u5168\u81ea\u52a8\u7ba1\u9053\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e16\u754c\u77e5\u8bc6\uff0c\u5c06\u5c11\u91cf\u4eba\u7c7b\u6f14\u793a\uff08\u5c11\u81f3\u4e00\u4e2a\uff09\u8f6c\u5316\u4e3a\u5927\u89c4\u6a21\u673a\u5668\u4eba\u6570\u636e\u96c6\u7528\u4e8e\u6a21\u4eff\u5b66\u4e60\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u79bb\u7ebf\u6f14\u793a\u6ce8\u91ca\u548c\u5728\u7ebf\u5173\u952e\u59ff\u52bf\u91cd\u5b9a\u5411\u6765\u751f\u6210\u65b0\u8f68\u8ff9\uff0c\u5e76\u901a\u8fc7Thompson\u91c7\u6837\u4f18\u5316\u6ce8\u91ca\u4ee5\u63d0\u9ad8\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u6a21\u4eff\u5b66\u4e60\u4e2d\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6f14\u793a\u6570\u636e\u7684\u95ee\u9898\uff0c\u5229\u7528LLM\u7684\u77e5\u8bc6\u6765\u51cf\u5c11\u5bf9\u4eba\u5de5\u6f14\u793a\u7684\u4f9d\u8d56\uff0c\u5b9e\u73b0\u4ece\u5c11\u91cf\u6f14\u793a\u81ea\u52a8\u751f\u6210\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u3002", "method": "1) \u79bb\u7ebf\u6f14\u793a\u6ce8\u91ca\uff1a\u63d0\u53d6\u5173\u952e\u5e27\u3001\u663e\u8457\u7269\u4f53\u548c\u59ff\u52bf-\u7269\u4f53\u5173\u7cfb\uff1b2) \u5728\u7ebf\u5173\u952e\u59ff\u52bf\u91cd\u5b9a\u5411\uff1a\u6839\u636e\u521d\u59cb\u89c2\u5bdf\u5c06\u5173\u952e\u5e27\u9002\u914d\u5230\u65b0\u573a\u666f\uff1b3) \u4f7f\u7528Thompson\u91c7\u6837\u4f18\u5316\u6ce8\u91ca\uff1b4) \u7ed3\u5408\u524d\u9988\u89c4\u5212\u548c\u53cd\u9988\u6a21\u4eff\u5b66\u4e60\u63a7\u5236\u5668\u7684\u96c6\u6210\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u7684\u6570\u636e\u6ce8\u91ca\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u4e13\u5bb6\u8bbe\u8ba1\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5728Franka Emika Panda\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u786c\u4ef6\u53ef\u884c\u6027\u3002", "conclusion": "LLM Trainer\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5229\u7528LLM\u7684\u4e16\u754c\u77e5\u8bc6\u4ece\u5c11\u91cf\u6f14\u793a\u751f\u6210\u5927\u89c4\u6a21\u673a\u5668\u4eba\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u4eff\u5b66\u4e60\u7684\u6548\u7387\u548c\u6210\u529f\u7387\u3002"}}
{"id": "2509.20077", "categories": ["cs.RO", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.20077", "abs": "https://arxiv.org/abs/2509.20077", "authors": ["Xun Li", "Rodrigo Santa Cruz", "Mingze Xi", "Hu Zhang", "Madhawa Perera", "Ziwei Wang", "Ahalya Ravendran", "Brandon J. Matthews", "Feng Xu", "Matt Adcock", "Dadong Wang", "Jiajun Liu"], "title": "Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic Reasoning and Robotic Task Planning", "comment": null, "summary": "To enable robots to comprehend high-level human instructions and perform\ncomplex tasks, a key challenge lies in achieving comprehensive scene\nunderstanding: interpreting and interacting with the 3D environment in a\nmeaningful way. This requires a smart map that fuses accurate geometric\nstructure with rich, human-understandable semantics. To address this, we\nintroduce the 3D Queryable Scene Representation (3D QSR), a novel framework\nbuilt on multimedia data that unifies three complementary 3D representations:\n(1) 3D-consistent novel view rendering and segmentation from panoptic\nreconstruction, (2) precise geometry from 3D point clouds, and (3) structured,\nscalable organization via 3D scene graphs. Built on an object-centric design,\nthe framework integrates with large vision-language models to enable semantic\nqueryability by linking multimodal object embeddings, and supporting\nobject-level retrieval of geometric, visual, and semantic information. The\nretrieved data are then loaded into a robotic task planner for downstream\nexecution. We evaluate our approach through simulated robotic task planning\nscenarios in Unity, guided by abstract language instructions and using the\nindoor public dataset Replica. Furthermore, we apply it in a digital duplicate\nof a real wet lab environment to test QSR-supported robotic task planning for\nemergency response. The results demonstrate the framework's ability to\nfacilitate scene understanding and integrate spatial and semantic reasoning,\neffectively translating high-level human instructions into precise robotic task\nplanning in complex 3D environments.", "AI": {"tldr": "3D Queryable Scene Representation (3D QSR) \u662f\u4e00\u4e2a\u65b0\u9896\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u4e09\u79cd\u4e92\u8865\u76843D\u8868\u793a\u65b9\u6cd5\uff0c\u5b9e\u73b0\u673a\u5668\u4eba\u5bf9\u590d\u67423D\u73af\u5883\u7684\u5168\u9762\u573a\u666f\u7406\u89e3\uff0c\u5c06\u9ad8\u7ea7\u4eba\u7c7b\u6307\u4ee4\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u673a\u5668\u4eba\u80fd\u591f\u7406\u89e3\u9ad8\u7ea7\u4eba\u7c7b\u6307\u4ee4\u5e76\u6267\u884c\u590d\u6742\u4efb\u52a1\uff0c\u9700\u8981\u5b9e\u73b0\u5168\u9762\u7684\u573a\u666f\u7406\u89e3\uff1a\u4ee5\u6709\u610f\u4e49\u7684\u65b9\u5f0f\u89e3\u91ca\u548c\u4ea4\u4e923D\u73af\u5883\u3002\u8fd9\u9700\u8981\u4e00\u4e2a\u667a\u80fd\u5730\u56fe\uff0c\u5c06\u7cbe\u786e\u7684\u51e0\u4f55\u7ed3\u6784\u4e0e\u4e30\u5bcc\u7684\u4eba\u7c7b\u53ef\u7406\u89e3\u8bed\u4e49\u76f8\u878d\u5408\u3002", "method": "\u57fa\u4e8e\u591a\u5a92\u4f53\u6570\u636e\u6784\u5efa3D QSR\u6846\u67b6\uff0c\u7edf\u4e00\u4e09\u79cd3D\u8868\u793a\uff1a(1) \u5168\u666f\u91cd\u5efa\u76843D\u4e00\u81f4\u65b0\u89c6\u89d2\u6e32\u67d3\u548c\u5206\u5272\uff0c(2) 3D\u70b9\u4e91\u7684\u7cbe\u786e\u51e0\u4f55\u7ed3\u6784\uff0c(3) 3D\u573a\u666f\u56fe\u7684\u7ed3\u6784\u5316\u7ec4\u7ec7\u3002\u91c7\u7528\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\uff0c\u4e0e\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u901a\u8fc7\u94fe\u63a5\u591a\u6a21\u6001\u5bf9\u8c61\u5d4c\u5165\u5b9e\u73b0\u8bed\u4e49\u53ef\u67e5\u8be2\u6027\u3002", "result": "\u5728Unity\u6a21\u62df\u7684\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u573a\u666f\u4e2d\u4f7f\u7528Replica\u5ba4\u5185\u516c\u5171\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5728\u771f\u5b9e\u6e7f\u5b9e\u9a8c\u5ba4\u7684\u6570\u5b57\u526f\u672c\u4e2d\u6d4b\u8bd5\u7d27\u6025\u54cd\u5e94\u573a\u666f\u3002\u7ed3\u679c\u8868\u660e\u6846\u67b6\u80fd\u591f\u4fc3\u8fdb\u573a\u666f\u7406\u89e3\uff0c\u6574\u5408\u7a7a\u95f4\u548c\u8bed\u4e49\u63a8\u7406\uff0c\u6709\u6548\u5c06\u9ad8\u7ea7\u4eba\u7c7b\u6307\u4ee4\u8f6c\u5316\u4e3a\u590d\u67423D\u73af\u5883\u4e2d\u7684\u7cbe\u786e\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u3002", "conclusion": "3D QSR\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u7efc\u5408\u573a\u666f\u7406\u89e3\uff0c\u4e3a\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u4e2d\u6267\u884c\u9ad8\u7ea7\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5728\u771f\u5b9e\u5e94\u7528\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.20081", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20081", "abs": "https://arxiv.org/abs/2509.20081", "authors": ["Jose E. Maese", "Luis Merino", "Fernando Caballero"], "title": "DB-TSDF: Directional Bitmask-based Truncated Signed Distance Fields for Efficient Volumetric Mapping", "comment": null, "summary": "This paper presents a high-efficiency, CPU-only volumetric mapping framework\nbased on a Truncated Signed Distance Field (TSDF). The system incrementally\nfuses raw LiDAR point-cloud data into a voxel grid using a directional\nbitmask-based integration scheme, producing dense and consistent TSDF\nrepresentations suitable for real-time 3D reconstruction. A key feature of the\napproach is that the processing time per point-cloud remains constant,\nregardless of the voxel grid resolution, enabling high resolution mapping\nwithout sacrificing runtime performance. In contrast to most recent TSDF/ESDF\nmethods that rely on GPU acceleration, our method operates entirely on CPU,\nachieving competitive results in speed. Experiments on real-world open datasets\ndemonstrate that the generated maps attain accuracy on par with contemporary\nmapping techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTSDF\u7684\u9ad8\u6548CPU\u4e13\u7528\u4f53\u7d20\u5efa\u56fe\u6846\u67b6\uff0c\u901a\u8fc7\u65b9\u5411\u6027\u4f4d\u63a9\u7801\u96c6\u6210\u65b9\u6848\u5b9e\u73b0\u5b9e\u65f63D\u91cd\u5efa\uff0c\u5904\u7406\u65f6\u95f4\u4e0e\u4f53\u7d20\u7f51\u683c\u5206\u8fa8\u7387\u65e0\u5173", "motivation": "\u73b0\u6709TSDF/ESDF\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56GPU\u52a0\u901f\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728CPU\u4e0a\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd\u7684\u9ad8\u5206\u8fa8\u7387\u5b9e\u65f6\u5efa\u56fe\u65b9\u6848", "method": "\u4f7f\u7528\u622a\u65ad\u7b26\u53f7\u8ddd\u79bb\u573a(TSDF)\uff0c\u901a\u8fc7\u65b9\u5411\u6027\u4f4d\u63a9\u7801\u96c6\u6210\u65b9\u6848\u5c06LiDAR\u70b9\u4e91\u6570\u636e\u589e\u91cf\u878d\u5408\u5230\u4f53\u7d20\u7f51\u683c\u4e2d", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5f00\u653e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u7684\u5730\u56fe\u7cbe\u5ea6\u4e0e\u5f53\u4ee3\u5efa\u56fe\u6280\u672f\u76f8\u5f53\uff0c\u5904\u7406\u65f6\u95f4\u4fdd\u6301\u6052\u5b9a", "conclusion": "\u8be5CPU\u4e13\u7528\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u727a\u7272\u8fd0\u884c\u65f6\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u5efa\u56fe\uff0c\u4e3a\u5b9e\u65f63D\u91cd\u5efa\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.20084", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20084", "abs": "https://arxiv.org/abs/2509.20084", "authors": ["Guillermo Gil", "Jose Antonio Cobano", "Luis Merino", "Fernando Caballero"], "title": "C-3TO: Continuous 3D Trajectory Optimization on Neural Euclidean Signed Distance Fields", "comment": "9 pages, 5 figures, submitted to ICRA 2026", "summary": "This paper introduces a novel framework for continuous 3D trajectory\noptimization in cluttered environments, leveraging online neural Euclidean\nSigned Distance Fields (ESDFs). Unlike prior approaches that rely on\ndiscretized ESDF grids with interpolation, our method directly optimizes smooth\ntrajectories represented by fifth-order polynomials over a continuous neural\nESDF, ensuring precise gradient information throughout the entire trajectory.\nThe framework integrates a two-stage nonlinear optimization pipeline that\nbalances efficiency, safety and smoothness. Experimental results demonstrate\nthat C-3TO produces collision-aware and dynamically feasible trajectories.\nMoreover, its flexibility in defining local window sizes and optimization\nparameters enables straightforward adaptation to diverse user's needs without\ncompromising performance. By combining continuous trajectory parameterization\nwith a continuously updated neural ESDF, C-3TO establishes a robust and\ngeneralizable foundation for safe and efficient local replanning in aerial\nrobotics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5728\u7ebf\u795e\u7ecfESDF\u7684\u8fde\u7eed3D\u8f68\u8ff9\u4f18\u5316\u6846\u67b6C-3TO\uff0c\u901a\u8fc7\u8fde\u7eed\u795e\u7ecfESDF\u76f4\u63a5\u4f18\u5316\u4e94\u9636\u591a\u9879\u5f0f\u8f68\u8ff9\uff0c\u786e\u4fdd\u7cbe\u786e\u68af\u5ea6\u4fe1\u606f\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u5b89\u5168\u3001\u5e73\u6ed1\u7684\u8f68\u8ff9\u89c4\u5212\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u79bb\u6563\u5316ESDF\u7f51\u683c\u548c\u63d2\u503c\uff0c\u65e0\u6cd5\u63d0\u4f9b\u7cbe\u786e\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u8f68\u8ff9\u4f18\u5316\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u76f4\u63a5\u4f18\u5316\u8fde\u7eed\u8f68\u8ff9\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u975e\u7ebf\u6027\u4f18\u5316\u6d41\u7a0b\uff0c\u4f7f\u7528\u4e94\u9636\u591a\u9879\u5f0f\u8868\u793a\u8fde\u7eed\u8f68\u8ff9\uff0c\u5728\u8fde\u7eed\u795e\u7ecfESDF\u4e0a\u8fdb\u884c\u76f4\u63a5\u4f18\u5316\uff0c\u5e73\u8861\u6548\u7387\u3001\u5b89\u5168\u6027\u548c\u5e73\u6ed1\u6027\u3002", "result": "C-3TO\u80fd\u591f\u751f\u6210\u78b0\u649e\u611f\u77e5\u4e14\u52a8\u6001\u53ef\u884c\u7684\u8f68\u8ff9\uff0c\u901a\u8fc7\u7075\u6d3b\u5b9a\u4e49\u5c40\u90e8\u7a97\u53e3\u5927\u5c0f\u548c\u4f18\u5316\u53c2\u6570\uff0c\u53ef\u9002\u5e94\u4e0d\u540c\u7528\u6237\u9700\u6c42\u800c\u4e0d\u5f71\u54cd\u6027\u80fd\u3002", "conclusion": "\u7ed3\u5408\u8fde\u7eed\u8f68\u8ff9\u53c2\u6570\u5316\u548c\u8fde\u7eed\u66f4\u65b0\u7684\u795e\u7ecfESDF\uff0cC-3TO\u4e3a\u7a7a\u4e2d\u673a\u5668\u4eba\u5b89\u5168\u9ad8\u6548\u7684\u5c40\u90e8\u91cd\u89c4\u5212\u5efa\u7acb\u4e86\u9c81\u68d2\u4e14\u53ef\u63a8\u5e7f\u7684\u57fa\u7840\u3002"}}
{"id": "2509.20093", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20093", "abs": "https://arxiv.org/abs/2509.20093", "authors": ["Venkat Margapuri", "Garik Kazanjian", "Naren Kosaraju"], "title": "Hybrid Safety Verification of Multi-Agent Systems using $\u03c8$-Weighted CBFs and PAC Guarantees", "comment": null, "summary": "This study proposes a hybrid safety verification framework for closed-loop\nmulti-agent systems under bounded stochastic disturbances. The proposed\napproach augments control barrier functions with a novel $\\psi$-weighted\nformulation that encodes directional control alignment between agents into the\nsafety constraints. Deterministic admissibility is combined with empirical\nvalidation via Monte Carlo rollouts, and a PAC-style guarantee is derived based\non margin-aware safety violations to provide a probabilistic safety\ncertificate. The results from the experiments conducted under different bounded\nstochastic disturbances validate the feasibility of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6709\u754c\u968f\u673a\u6270\u52a8\u4e0b\u95ed\u73af\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6df7\u5408\u5b89\u5168\u9a8c\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u4e0e\u65b9\u5411\u63a7\u5236\u5bf9\u9f50\u7f16\u7801\uff0c\u63d0\u4f9b\u6982\u7387\u5b89\u5168\u4fdd\u8bc1\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6709\u754c\u968f\u673a\u6270\u52a8\u4e0b\u7684\u5b89\u5168\u9a8c\u8bc1\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u7ed3\u5408\u786e\u5b9a\u6027\u5206\u6790\u548c\u6982\u7387\u4fdd\u8bc1\u6765\u786e\u4fdd\u7cfb\u7edf\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u786e\u5b9a\u6027\u53ef\u5bb9\u8bb8\u6027\u5206\u6790\uff1b2\uff09\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6eda\u52a8\u7684\u7ecf\u9a8c\u9a8c\u8bc1\uff1b3\uff09\u57fa\u4e8e\u8fb9\u754c\u611f\u77e5\u5b89\u5168\u8fdd\u89c4\u7684PAC\u5f0f\u6982\u7387\u4fdd\u8bc1\u3002", "result": "\u5728\u4e0d\u540c\u6709\u754c\u968f\u673a\u6270\u52a8\u4e0b\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u6709\u6548\u63d0\u4f9b\u7cfb\u7edf\u7684\u6982\u7387\u5b89\u5168\u8bc1\u4e66\u3002", "conclusion": "\u8be5\u6df7\u5408\u5b89\u5168\u9a8c\u8bc1\u6846\u67b6\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6709\u754c\u968f\u673a\u6270\u52a8\u4e0b\u7684\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u9a8c\u8bc1\u3002"}}
{"id": "2509.20219", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20219", "abs": "https://arxiv.org/abs/2509.20219", "authors": ["Sicong Liu", "Jianhui Liu", "Fang Chen", "Wenjian Yang", "Juan Yi", "Yu Zheng", "Zheng Wang", "Wanchao Chi", "Chaoyang Song"], "title": "A Biomimetic Vertebraic Soft Robotic Tail for High-Speed, High-Force Dynamic Maneuvering", "comment": "20 pages, 11 figures, 4 tables. Submitted Under Review", "summary": "Robotic tails can enhance the stability and maneuverability of mobile robots,\nbut current designs face a trade-off between the power of rigid systems and the\nsafety of soft ones. Rigid tails generate large inertial effects but pose risks\nin unstructured environments, while soft tails lack sufficient speed and force.\nWe present a Biomimetic Vertebraic Soft Robotic (BVSR) tail that resolves this\nchallenge through a compliant pneumatic body reinforced by a passively jointed\nvertebral column inspired by musculoskeletal structures. This hybrid design\ndecouples load-bearing and actuation, enabling high-pressure actuation (up to 6\nbar) for superior dynamics while preserving compliance. A dedicated kinematic\nand dynamic model incorporating vertebral constraints is developed and\nvalidated experimentally. The BVSR tail achieves angular velocities above\n670{\\deg}/s and generates inertial forces and torques up to 5.58 N and 1.21 Nm,\nindicating over 200% improvement compared to non-vertebraic designs.\nDemonstrations on rapid cart stabilization, obstacle negotiation, high-speed\nsteering, and quadruped integration confirm its versatility and practical\nutility for agile robotic platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4eff\u751f\u690e\u4f53\u8f6f\u4f53\u673a\u5668\u4eba\u5c3e\u5df4\uff0c\u901a\u8fc7\u7ed3\u5408\u521a\u6027\u690e\u4f53\u548c\u8f6f\u4f53\u6c14\u52a8\u9a71\u52a8\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u521a\u6027\u5c3e\u5df4\u5b89\u5168\u6027\u5dee\u548c\u8f6f\u4f53\u5c3e\u5df4\u52a8\u529b\u4e0d\u8db3\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u5c3e\u5df4\u8bbe\u8ba1\u9762\u4e34\u521a\u6027\u7cfb\u7edf\u52a8\u529b\u5f3a\u4f46\u5b89\u5168\u6027\u5dee\u4e0e\u8f6f\u4f53\u7cfb\u7edf\u5b89\u5168\u4f46\u52a8\u529b\u4e0d\u8db3\u7684\u6743\u8861\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4ea7\u751f\u5f3a\u5927\u60ef\u6027\u6548\u5e94\u53c8\u80fd\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u5b89\u5168\u5de5\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4eff\u751f\u690e\u4f53\u8f6f\u4f53\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u5c06\u67d4\u6027\u6c14\u52a8\u8eab\u4f53\u4e0e\u88ab\u52a8\u5173\u8282\u690e\u67f1\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u8d1f\u8f7d\u627f\u8f7d\u548c\u9a71\u52a8\u7684\u89e3\u8026\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u690e\u4f53\u7ea6\u675f\u7684\u4e13\u7528\u8fd0\u52a8\u5b66\u548c\u52a8\u529b\u5b66\u6a21\u578b\u3002", "result": "BVSR\u5c3e\u5df4\u8fbe\u5230670\u00b0/s\u4ee5\u4e0a\u7684\u89d2\u901f\u5ea6\uff0c\u4ea7\u751f\u9ad8\u8fbe5.58N\u7684\u60ef\u6027\u529b\u548c1.21Nm\u7684\u626d\u77e9\uff0c\u76f8\u6bd4\u975e\u690e\u4f53\u8bbe\u8ba1\u6027\u80fd\u63d0\u5347\u8d85\u8fc7200%\uff0c\u5728\u5feb\u901f\u63a8\u8f66\u7a33\u5b9a\u3001\u969c\u788d\u7269\u7a7f\u8d8a\u3001\u9ad8\u901f\u8f6c\u5411\u548c\u56db\u8db3\u673a\u5668\u4eba\u96c6\u6210\u7b49\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8fd9\u79cd\u6df7\u5408\u8bbe\u8ba1\u4e3a\u654f\u6377\u673a\u5668\u4eba\u5e73\u53f0\u63d0\u4f9b\u4e86\u591a\u529f\u80fd\u6027\u548c\u5b9e\u7528\u4ef7\u503c\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u521a\u6027\u5c3e\u5df4\u548c\u8f6f\u4f53\u5c3e\u5df4\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2509.20229", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20229", "abs": "https://arxiv.org/abs/2509.20229", "authors": ["Angelos Plastropoulos", "Nicolas P. Avdelidis", "Argyrios Zolotas"], "title": "Techno-Economic analysis for Smart Hangar inspection operations through Sensing and Localisation at scale", "comment": null, "summary": "The accuracy, resilience, and affordability of localisation are fundamental\nto autonomous robotic inspection within aircraft maintenance and overhaul (MRO)\nhangars. Hangars typically feature tall ceilings and are often made of\nmaterials such as metal. Due to its nature, it is considered a GPS-denied\nenvironment, with extensive multipath effects and stringent operational\nconstraints that collectively create a uniquely challenging environment. This\npersistent gap highlights the need for domain-specific comparative studies,\nincluding rigorous cost, accuracy, and integration assessments, to inform a\nreliable and scalable deployment of a localisation system in the Smart Hangar.\nThis paper presents the first techno-economic roadmap that benchmarks motion\ncapture (MoCap), ultra-wideband (UWB), and a ceiling-mounted camera network\nacross three operational scenarios: robot localisation, asset tracking, and\nsurface defect detection within a 40x50 m hangar bay. A dual-layer optimisation\nfor camera selection and positioning framework is introduced, which couples\nmarket-based camera-lens selection with an optimisation solver, producing\ncamera layouts that minimise hardware while meeting accuracy targets. The\nroadmap equips MRO planners with an actionable method to balance accuracy,\ncoverage, and budget, demonstrating that an optimised vision architecture has\nthe potential to unlock robust and cost-effective sensing for next-generation\nSmart Hangars.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u6280\u672f\u7ecf\u6d4e\u8def\u7ebf\u56fe\uff0c\u572840x50\u7c73\u673a\u5e93\u73af\u5883\u4e2d\u5bf9\u8fd0\u52a8\u6355\u6349\u3001\u8d85\u5bbd\u5e26\u548c\u5929\u82b1\u677f\u6444\u50cf\u5934\u7f51\u7edc\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u53cc\u5c42\u6b21\u4f18\u5316\u6846\u67b6\u6765\u4f18\u5316\u6444\u50cf\u5934\u9009\u62e9\u548c\u5e03\u5c40\u3002", "motivation": "\u98de\u673a\u7ef4\u62a4\u673a\u5e93\u4f5c\u4e3aGPS\u62d2\u6b62\u73af\u5883\uff0c\u5b58\u5728\u4e25\u91cd\u7684\u591a\u5f84\u6548\u5e94\u548c\u64cd\u4f5c\u9650\u5236\uff0c\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u9886\u57df\u7684\u6bd4\u8f83\u7814\u7a76\u6765\u6307\u5bfc\u53ef\u9760\u3001\u53ef\u6269\u5c55\u7684\u5b9a\u4f4d\u7cfb\u7edf\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u6b21\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u5e02\u573a\u5316\u7684\u6444\u50cf\u5934-\u955c\u5934\u9009\u62e9\u548c\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u751f\u6210\u6700\u5c0f\u5316\u786c\u4ef6\u6210\u672c\u540c\u65f6\u6ee1\u8db3\u7cbe\u5ea6\u76ee\u6807\u7684\u6444\u50cf\u5934\u5e03\u5c40\u65b9\u6848\u3002", "result": "\u4f18\u5316\u7684\u89c6\u89c9\u67b6\u6784\u80fd\u591f\u4e3a\u65b0\u4e00\u4ee3\u667a\u80fd\u673a\u5e93\u63d0\u4f9b\u7a33\u5065\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u611f\u77e5\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u8def\u7ebf\u56fe\u4e3aMRO\u89c4\u5212\u8005\u63d0\u4f9b\u4e86\u5e73\u8861\u7cbe\u5ea6\u3001\u8986\u76d6\u8303\u56f4\u548c\u9884\u7b97\u7684\u53ef\u64cd\u4f5c\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u4f18\u5316\u89c6\u89c9\u67b6\u6784\u5728\u667a\u80fd\u673a\u5e93\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.20263", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20263", "abs": "https://arxiv.org/abs/2509.20263", "authors": ["Bingjie Chen", "Zihan Wang", "Zhe Han", "Guoping Pan", "Yi Cheng", "Houde Liu"], "title": "HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms", "comment": null, "summary": "Traditional IK methods for redundant humanoid manipulators emphasize\nend-effector (EE) tracking, frequently producing configurations that are valid\nmechanically but not human-like. We present Human-Like Inverse Kinematics\n(HL-IK), a lightweight IK framework that preserves EE tracking while shaping\nwhole-arm configurations to appear human-like, without full-body sensing at\nruntime. The key idea is a learned elbow prior: using large-scale human motion\ndata retargeted to the robot, we train a FiLM-modulated spatio-temporal\nattention network (FiSTA) to predict the next-step elbow pose from the EE\ntarget and a short history of EE-elbow states.This prediction is incorporated\nas a small residual alongside EE and smoothness terms in a standard\nLevenberg-Marquardt optimizer, making HL-IK a drop-in addition to numerical IK\nstacks. Over 183k simulation steps, HL-IK reduces arm-similarity position and\ndirection error by 30.6% and 35.4% on average, and by 42.2% and 47.4% on the\nmost challenging trajectories. Hardware teleoperation on a robot distinct from\nsimulation further confirms the gains in anthropomorphism. HL-IK is simple to\nintegrate, adaptable across platforms via our pipeline, and adds minimal\ncomputation, enabling human-like motions for humanoid robots. Project page:\nhttps://hl-ik.github.io/", "AI": {"tldr": "\u63d0\u51faHL-IK\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u8098\u90e8\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u4fdd\u6301\u672b\u7aef\u6267\u884c\u5668\u8ddf\u8e2a\u7684\u540c\u65f6\u751f\u6210\u7c7b\u4eba\u624b\u81c2\u914d\u7f6e\uff0c\u65e0\u9700\u8fd0\u884c\u65f6\u5168\u8eab\u611f\u77e5", "motivation": "\u4f20\u7edfIK\u65b9\u6cd5\u867d\u7136\u80fd\u5b9e\u73b0\u673a\u68b0\u6709\u6548\u7684\u914d\u7f6e\uff0c\u4f46\u751f\u6210\u7684\u59ff\u6001\u7f3a\u4e4f\u4eba\u7c7b\u81ea\u7136\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u4ea7\u751f\u7c7b\u4eba\u8fd0\u52a8\u7684\u65b9\u6cd5", "method": "\u4f7f\u7528FiLM\u8c03\u5236\u65f6\u7a7a\u6ce8\u610f\u529b\u7f51\u7edc(FiSTA)\u4ece\u5927\u89c4\u6a21\u4eba\u7c7b\u8fd0\u52a8\u6570\u636e\u4e2d\u5b66\u4e60\u8098\u90e8\u5148\u9a8c\uff0c\u5c06\u9884\u6d4b\u7ed3\u679c\u4f5c\u4e3a\u6b8b\u5dee\u9879\u6574\u5408\u5230Levenberg-Marquardt\u4f18\u5316\u5668\u4e2d", "result": "\u572818.3\u4e07\u6b21\u4eff\u771f\u4e2d\uff0c\u624b\u81c2\u76f8\u4f3c\u6027\u4f4d\u7f6e\u548c\u65b9\u5411\u8bef\u5dee\u5e73\u5747\u51cf\u5c1130.6%\u548c35.4%\uff0c\u6700\u5177\u6311\u6218\u6027\u8f68\u8ff9\u4e0a\u51cf\u5c1142.2%\u548c47.4%", "conclusion": "HL-IK\u6613\u4e8e\u96c6\u6210\uff0c\u8de8\u5e73\u53f0\u9002\u5e94\u6027\u5f3a\uff0c\u8ba1\u7b97\u5f00\u9500\u5c0f\uff0c\u80fd\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u5b9e\u73b0\u7c7b\u4eba\u8fd0\u52a8"}}
{"id": "2509.20286", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20286", "abs": "https://arxiv.org/abs/2509.20286", "authors": ["Georgios Tziafas", "Jiayun Zhang", "Hamidreza Kasaei"], "title": "Parse-Augment-Distill: Learning Generalizable Bimanual Visuomotor Policies from Single Human Video", "comment": null, "summary": "Learning visuomotor policies from expert demonstrations is an important\nfrontier in modern robotics research, however, most popular methods require\ncopious efforts for collecting teleoperation data and struggle to generalize\nout-ofdistribution. Scaling data collection has been explored through\nleveraging human videos, as well as demonstration augmentation techniques. The\nlatter approach typically requires expensive simulation rollouts and trains\npolicies with synthetic image data, therefore introducing a sim-to-real gap. In\nparallel, alternative state representations such as keypoints have shown great\npromise for category-level generalization. In this work, we bring these avenues\ntogether in a unified framework: PAD (Parse-AugmentDistill), for learning\ngeneralizable bimanual policies from a single human video. Our method relies on\nthree steps: (a) parsing a human video demo into a robot-executable\nkeypoint-action trajectory, (b) employing bimanual task-and-motion-planning to\naugment the demonstration at scale without simulators, and (c) distilling the\naugmented trajectories into a keypoint-conditioned policy. Empirically, we\nshowcase that PAD outperforms state-ofthe-art bimanual demonstration\naugmentation works relying on image policies with simulation rollouts, both in\nterms of success rate and sample/cost efficiency. We deploy our framework in\nsix diverse real-world bimanual tasks such as pouring drinks, cleaning trash\nand opening containers, producing one-shot policies that generalize in unseen\nspatial arrangements, object instances and background distractors.\nSupplementary material can be found in the project webpage\nhttps://gtziafas.github.io/PAD_project/.", "AI": {"tldr": "PAD\u6846\u67b6\u901a\u8fc7\u89e3\u6790\u4eba\u7c7b\u89c6\u9891\u3001\u4efb\u52a1\u8fd0\u52a8\u89c4\u5212\u589e\u5f3a\u548c\u8f68\u8ff9\u84b8\u998f\uff0c\u4ece\u5355\u4e2a\u4eba\u7c7b\u89c6\u9891\u5b66\u4e60\u53ef\u6cdb\u5316\u7684\u53cc\u624b\u64cd\u4f5c\u7b56\u7565\uff0c\u65e0\u9700\u6a21\u62df\u5668\u4e14\u80fd\u5904\u7406\u672a\u89c1\u573a\u666f\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u9065\u64cd\u4f5c\u6570\u636e\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u6a21\u62df\u5230\u771f\u5b9e\u5dee\u8ddd\u5927\u7684\u95ee\u9898\uff0c\u5229\u7528\u4eba\u7c7b\u89c6\u9891\u548c\u5173\u952e\u70b9\u8868\u793a\u5b9e\u73b0\u9ad8\u6548\u53cc\u624b\u7b56\u7565\u5b66\u4e60\u3002", "method": "\u4e09\u6b65\u9aa4\uff1a\u89e3\u6790\u4eba\u7c7b\u89c6\u9891\u4e3a\u673a\u5668\u4eba\u53ef\u6267\u884c\u7684\u5173\u952e\u70b9-\u52a8\u4f5c\u8f68\u8ff9\uff1b\u4f7f\u7528\u53cc\u624b\u4efb\u52a1\u8fd0\u52a8\u89c4\u5212\u8fdb\u884c\u5927\u89c4\u6a21\u6f14\u793a\u589e\u5f3a\uff1b\u5c06\u589e\u5f3a\u8f68\u8ff9\u84b8\u998f\u4e3a\u5173\u952e\u70b9\u6761\u4ef6\u7b56\u7565\u3002", "result": "\u5728\u516d\u79cd\u771f\u5b9e\u4e16\u754c\u53cc\u624b\u4efb\u52a1\u4e2d\uff0cPAD\u5728\u6210\u529f\u7387\u548c\u6837\u672c\u6548\u7387\u4e0a\u4f18\u4e8e\u4f9d\u8d56\u56fe\u50cf\u7b56\u7565\u548c\u6a21\u62df\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u7a7a\u95f4\u5e03\u5c40\u3001\u7269\u4f53\u5b9e\u4f8b\u548c\u80cc\u666f\u5e72\u6270\u3002", "conclusion": "PAD\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u5355\u4e2a\u4eba\u7c7b\u89c6\u9891\u5b66\u4e60\u53ef\u6cdb\u5316\u7684\u53cc\u624b\u7b56\u7565\uff0c\u907f\u514d\u4e86\u6a21\u62df\u5230\u771f\u5b9e\u7684\u5dee\u8ddd\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.20297", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20297", "abs": "https://arxiv.org/abs/2509.20297", "authors": ["Remo Steiner", "Alexander Millane", "David Tingdahl", "Clemens Volk", "Vikram Ramasamy", "Xinjie Yao", "Peter Du", "Soha Pouya", "Shiwei Sheng"], "title": "mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies", "comment": "Accepted to CoRL 2025 Workshop RemembeRL", "summary": "End-to-end learning of robot control policies, structured as neural networks,\nhas emerged as a promising approach to robotic manipulation. To complete many\ncommon tasks, relevant objects are required to pass in and out of a robot's\nfield of view. In these settings, spatial memory - the ability to remember the\nspatial composition of the scene - is an important competency. However,\nbuilding such mechanisms into robot learning systems remains an open research\nproblem. We introduce mindmap (Spatial Memory in Deep Feature Maps for 3D\nAction Policies), a 3D diffusion policy that generates robot trajectories based\non a semantic 3D reconstruction of the environment. We show in simulation\nexperiments that our approach is effective at solving tasks where\nstate-of-the-art approaches without memory mechanisms struggle. We release our\nreconstruction system, training code, and evaluation tasks to spur research in\nthis direction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86mindmap\u65b9\u6cd5\uff0c\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e493D\u91cd\u5efa\u76843D\u6269\u6563\u7b56\u7565\uff0c\u7528\u4e8e\u89e3\u51b3\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u7a7a\u95f4\u8bb0\u5fc6\u95ee\u9898\u3002", "motivation": "\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0c\u76f8\u5173\u7269\u4f53\u9700\u8981\u9891\u7e41\u8fdb\u51fa\u673a\u5668\u4eba\u89c6\u91ce\uff0c\u56e0\u6b64\u7a7a\u95f4\u8bb0\u5fc6\u80fd\u529b\u5bf9\u4e8e\u5b8c\u6210\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u673a\u5668\u4eba\u5b66\u4e60\u7cfb\u7edf\u4e2d\u6784\u5efa\u6709\u6548\u7684\u7a7a\u95f4\u8bb0\u5fc6\u673a\u5236\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u7684\u7814\u7a76\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86mindmap\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd3D\u6269\u6563\u7b56\u7565\uff0c\u57fa\u4e8e\u73af\u5883\u7684\u8bed\u4e493D\u91cd\u5efa\u6765\u751f\u6210\u673a\u5668\u4eba\u8f68\u8ff9\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6df1\u5ea6\u7279\u5f81\u56fe\u5b9e\u73b0\u7a7a\u95f4\u8bb0\u5fc6\u529f\u80fd\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89e3\u51b3\u90a3\u4e9b\u7f3a\u4e4f\u8bb0\u5fc6\u673a\u5236\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7684\u4efb\u52a1\u65b9\u9762\u975e\u5e38\u6709\u6548\u3002", "conclusion": "mindmap\u65b9\u6cd5\u4e3a\u89e3\u51b3\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u7a7a\u95f4\u8bb0\u5fc6\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4f5c\u8005\u53d1\u5e03\u4e86\u91cd\u5efa\u7cfb\u7edf\u3001\u8bad\u7ec3\u4ee3\u7801\u548c\u8bc4\u4f30\u4efb\u52a1\u4ee5\u4fc3\u8fdb\u8be5\u65b9\u5411\u7684\u7814\u7a76\u3002"}}
{"id": "2509.20322", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.20322", "abs": "https://arxiv.org/abs/2509.20322", "authors": ["Shaofeng Yin", "Yanjie Ze", "Hong-Xing Yu", "C. Karen Liu", "Jiajun Wu"], "title": "VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation", "comment": "Website: https://visualmimic.github.io", "summary": "Humanoid loco-manipulation in unstructured environments demands tight\nintegration of egocentric perception and whole-body control. However, existing\napproaches either depend on external motion capture systems or fail to\ngeneralize across diverse tasks. We introduce VisualMimic, a visual sim-to-real\nframework that unifies egocentric vision with hierarchical whole-body control\nfor humanoid robots. VisualMimic combines a task-agnostic low-level keypoint\ntracker -- trained from human motion data via a teacher-student scheme -- with\na task-specific high-level policy that generates keypoint commands from visual\nand proprioceptive input. To ensure stable training, we inject noise into the\nlow-level policy and clip high-level actions using human motion statistics.\nVisualMimic enables zero-shot transfer of visuomotor policies trained in\nsimulation to real humanoid robots, accomplishing a wide range of\nloco-manipulation tasks such as box lifting, pushing, football dribbling, and\nkicking. Beyond controlled laboratory settings, our policies also generalize\nrobustly to outdoor environments. Videos are available at:\nhttps://visualmimic.github.io .", "AI": {"tldr": "VisualMimic\u662f\u4e00\u4e2a\u89c6\u89c9\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u6846\u67b6\uff0c\u5c06\u81ea\u6211\u4e2d\u5fc3\u89c6\u89c9\u4e0e\u5206\u5c42\u5168\u8eab\u63a7\u5236\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5916\u90e8\u8fd0\u52a8\u6355\u6349\u7cfb\u7edf\uff0c\u8981\u4e48\u65e0\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u6cdb\u5316\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6574\u5408\u81ea\u6211\u4e2d\u5fc3\u611f\u77e5\u548c\u5168\u8eab\u63a7\u5236\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u4efb\u52a1\u65e0\u5173\u7684\u4f4e\u7ea7\u5173\u952e\u70b9\u8ddf\u8e2a\u5668\uff08\u901a\u8fc7\u5e08\u751f\u65b9\u6848\u4ece\u4eba\u7c7b\u8fd0\u52a8\u6570\u636e\u8bad\u7ec3\uff09\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u9ad8\u7ea7\u7b56\u7565\uff08\u4ece\u89c6\u89c9\u548c\u672c\u4f53\u611f\u53d7\u8f93\u5165\u751f\u6210\u5173\u952e\u70b9\u547d\u4ee4\uff09\uff0c\u901a\u8fc7\u6ce8\u5165\u566a\u58f0\u548c\u52a8\u4f5c\u88c1\u526a\u786e\u4fdd\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "\u5b9e\u73b0\u4e86\u4ece\u6a21\u62df\u5230\u771f\u5b9e\u4eba\u5f62\u673a\u5668\u4eba\u7684\u96f6\u6837\u672c\u8fc1\u79fb\uff0c\u5b8c\u6210\u4e86\u4e3e\u7bb1\u3001\u63a8\u7bb1\u3001\u8db3\u7403\u8fd0\u7403\u548c\u8e22\u7403\u7b49\u591a\u79cd\u8fd0\u52a8\u64cd\u4f5c\u4efb\u52a1\uff0c\u5e76\u5728\u5ba4\u5916\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "VisualMimic\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u7684\u6311\u6218\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.20333", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20333", "abs": "https://arxiv.org/abs/2509.20333", "authors": ["Srikrishna Bangalore Raghu", "Alessandro Roncone"], "title": "BBoE: Leveraging Bundle of Edges for Kinodynamic Bidirectional Motion Planning", "comment": "8 Pages, 7 Figures", "summary": "In this work, we introduce BBoE, a bidirectional, kinodynamic, sampling-based\nmotion planner that consistently and quickly finds low-cost solutions in\nenvironments with varying obstacle clutter. The algorithm combines exploration\nand exploitation while relying on precomputed robot state traversals, resulting\nin efficient convergence towards the goal. Our key contributions include: i) a\nstrategy to navigate through obstacle-rich spaces by sorting and sequencing\npreprocessed forward propagations; and ii) BBoE, a robust bidirectional\nkinodynamic planner that utilizes this strategy to produce fast and feasible\nsolutions. The proposed framework reduces planning time, diminishes solution\ncost and increases success rate in comparison to previous approaches.", "AI": {"tldr": "BBoE\u662f\u4e00\u79cd\u53cc\u5411\u3001\u8fd0\u52a8\u52a8\u529b\u5b66\u7684\u91c7\u6837\u8fd0\u52a8\u89c4\u5212\u5668\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u969c\u788d\u7269\u5bc6\u5ea6\u7684\u73af\u5883\u4e2d\u5feb\u901f\u627e\u5230\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u8fd0\u52a8\u89c4\u5212\u5668\u5728\u969c\u788d\u7269\u5bc6\u96c6\u73af\u5883\u4e2d\u96be\u4ee5\u5feb\u901f\u627e\u5230\u53ef\u884c\u4e14\u4f4e\u6210\u672c\u7684\u8def\u5f84\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89c4\u5212\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u63a2\u7d22\u548c\u5229\u7528\u7b56\u7565\uff0c\u4f9d\u8d56\u9884\u8ba1\u7b97\u7684\u673a\u5668\u4eba\u72b6\u6001\u904d\u5386\uff0c\u901a\u8fc7\u6392\u5e8f\u548c\u5e8f\u5217\u5316\u9884\u5904\u7406\u7684\u524d\u5411\u4f20\u64ad\u6765\u5bfc\u822a\u969c\u788d\u7269\u4e30\u5bcc\u7a7a\u95f4\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0cBBoE\u51cf\u5c11\u4e86\u89c4\u5212\u65f6\u95f4\uff0c\u964d\u4f4e\u4e86\u89e3\u51b3\u65b9\u6848\u6210\u672c\uff0c\u63d0\u9ad8\u4e86\u6210\u529f\u7387\u3002", "conclusion": "BBoE\u662f\u4e00\u4e2a\u9c81\u68d2\u7684\u53cc\u5411\u8fd0\u52a8\u52a8\u529b\u5b66\u89c4\u5212\u5668\uff0c\u80fd\u591f\u4ea7\u751f\u5feb\u901f\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
