<div id=toc></div>

# Table of Contents

- [econ.TH](#econ.TH) [Total: 2]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.RO](#cs.RO) [Total: 25]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CY](#cs.CY) [Total: 11]
- [eess.SY](#eess.SY) [Total: 14]
- [stat.AP](#stat.AP) [Total: 3]
- [cs.AI](#cs.AI) [Total: 47]


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [1] [Optimal allocations with distortion risk measures and mixed risk attitudes](https://arxiv.org/abs/2510.18236)
*Mario Ghossoub,Qinghua Ren,Ruodu Wang*

Main category: econ.TH

TL;DR: 研究具有异质风险态度的经济体中帕累托最优风险分担问题，使用失真风险度量建模偏好，发现相似风险态度的代理人最优风险分担方式不同（风险厌恶者同单调，风险寻求者反单调）。


<details>
  <summary>Details</summary>
Motivation: 研究在代理人具有不同风险态度（风险厌恶和风险寻求）的经济体中，如何实现帕累托最优的风险分担，探索异质风险偏好下的最优分配结构。

Method: 基于同单调和反单调改进结果，将n个代理人问题简化为代表性风险厌恶和风险寻求代理人之间的两代理人问题，使用失真风险度量的下卷积进行表征。

Result: 建立了最优分配存在的充要条件，识别了下卷积产生无界值的情况。当存在性失败时，在非负分配约束下分析问题，并在分段线性失真函数和伯努利型风险下显式刻画最优解。

Conclusion: 最优分配结构由风险厌恶与风险寻求行为的相对强度决定，这与直觉相符，揭示了异质风险态度下风险分担的基本规律。

Abstract: We study Pareto-optimal risk sharing in economies with heterogeneous
attitudes toward risk, where agents' preferences are modeled by distortion risk
measures. Building on comonotonic and counter-monotonic improvement results, we
show that agents with similar attitudes optimally share risks comonotonically
(risk-averse) or counter-monotonically (risk-seeking). We show how the general
$n$-agent problem can be reduced to a two-agent formulation between
representative risk-averse and risk-seeking agents, characterized by the
infimal convolution of their distortion risk measures. Within this two-agent
framework, we establish necessary and sufficient conditions for the existence
of optimal allocations, and we identify when the infimal convolution yields an
unbounded value. When existence fails, we analyze the problem under nonnegative
allocation constraints, and we characterize optima explicitly, under
piecewise-linear distortion functions and Bernoulli-type risks. Our findings
suggest that the optimal allocation structure is governed by the relative
strength of risk aversion versus risk seeking behavior, as intuition would
suggest.

</details>


### [2] [Teacher transfers: equalizing deficits across schools](https://arxiv.org/abs/2510.18708)
*Debasis Mishra,Soumendu Sarkar,Arunava Sen,Jay Sethuraman,Sonal Yadav*

Main category: econ.TH

TL;DR: 该论文研究了印度《免费义务教育权利法案》中教师重新部署问题，提出了一个两阶段算法来找到洛伦兹占优的教师转移后短缺向量，并证明该算法对教师是策略证明的。


<details>
  <summary>Details</summary>
Motivation: 印度《免费义务教育权利法案》要求通过将教师从过剩学校重新部署到短缺学校来实现学生-教师比例目标，需要设计有效的教师转移机制。

Method: 建立教师转移模型，教师可选择留在原校或转移到可接受学校，提出两阶段算法来找到洛伦兹占优的转移后短缺向量。

Result: 证明存在一个转移方案，其转移后短缺向量洛伦兹占优于所有可达的转移后短缺向量，且该算法对教师是策略证明的。

Conclusion: 提出的两阶段算法能够有效实现教师重新部署目标，确保公平性并防止教师策略性行为。

Abstract: The Right to Free and Compulsory Education Act (2009) (RTE) of the Government
of India prescribes student-teacher ratios for state-run schools. One method
advocated by the Act to achieve its goals is the redeployment of teachers from
surplus to deficit (in teacher strength) schools. We consider a model where
teachers can either remain in their initially assigned schools or be
transferred to a deficit school in their acceptable set. The planner's
objective is specified in terms of the post-transfer deficit vector that can be
achieved. We show that there exists a transfer whose post-transfer deficit
vector Lorenz dominates all achievable post-transfer deficit vectors. We
provide a two-stage algorithm to derive the Lorenz-dominant post-transfer
deficit vector, and show that this algorithm is strategy-proof for teachers.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [3] [Parental environment and student achievement: Does a Matthew effect exist?](https://arxiv.org/abs/2510.18481)
*Gaëlle Aymeric,Emmanuelle Lavaine,Brice Magdalou*

Main category: econ.GN

TL;DR: 研究父母环境（教育水平和投资）对8-15岁学生数学、文学和英语成绩的因果影响，发现父母环境对学业成绩有持续正面影响，但马太效应在不同学科表现不同。


<details>
  <summary>Details</summary>
Motivation: 探究父母环境对学生学业成绩的因果影响，区分持续效应和马太效应（父母环境影响随年龄增长的变化）。

Method: 使用2016-2019年马德里社区8-15岁所有儿童的新数据库，分析父母教育水平和投资对不同学科成绩的影响。

Result: 父母环境对所有学科都有持续正面影响；马太效应在数学中随年龄减弱，在文学中呈钟形曲线，在英语中持续增强。

Conclusion: 父母环境对学业成绩有重要影响，但马太效应因学科而异，外语学习的社会维度更为突出。

Abstract: This paper investigates the causal impact of the parental environment on the
student's academic performance in mathematics, literature and English (as a
foreign language), using a new database covering all children aged 8 to 15 of
the Madrid community, from 2016 to 2019. Parental environment refers here to
the parents' level of education (i.e. the skills they acquired before bringing
up their children), and parental investment (the effort made by parents to
bring up their children). We distinguish the persistent effect of the parental
environment from the so-called Matthew effect, which describes a possible
tendency for the impact of the parental environment to increase as the child
grows up. Whatever the subject (mathematics, literature or English), our
results are in line with most studies concerning the persistent effect: a
favourable parental environment goes hand in hand with better results for the
children. As regards the Matthew effect, the results differ between subjects:
while the impact of the parental environment tends to diminish from the age of
8 to 15 in mathematics, it forms a bell curve in literature (first increasing,
then decreasing) and increases steadily in English. This result, which is
encouraging for mathematics and even literature, confirms the social dimension
involved in learning a foreign language compared to more academic subjects.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [4] [Studying the Effects of Robot Intervention on School Shooters in Virtual Reality](https://arxiv.org/abs/2510.17948)
*Christopher A McClurg,Alan R Wagner*

Main category: cs.RO

TL;DR: 虚拟现实研究表明，自主机器人通过预测校园枪手行动并进行战略干扰，可将受害者数量减少46.6%，但引发校园环境中使用机器人的伦理问题。


<details>
  <summary>Details</summary>
Motivation: 研究机器人在高风险场景中干预校园枪击事件的潜力，特别是通过分散枪手注意力来减少伤亡。

Method: 使用虚拟现实模拟，150名大学生扮演校园枪手角色。机器人预测枪手移动并战略定位干扰，测试不同接近策略（激进vs被动）和干扰方法（无提示、警笛灯光、警笛灯光加烟雾）。

Result: 激进且高干扰的机器人（使用警笛、灯光和烟雾）相比无机器人控制组，受害者数量减少了46.6%。

Conclusion: 机器人干预在提高校园安全方面具有潜力，但引发了在校园环境中使用机器人的紧迫伦理问题。

Abstract: We advance the understanding of robotic intervention in high-risk scenarios
by examining their potential to distract and impede a school shooter. To
evaluate this concept, we conducted a virtual reality study with 150 university
participants role-playing as a school shooter. Within the simulation, an
autonomous robot predicted the shooter's movements and positioned itself
strategically to interfere and distract. The strategy the robot used to
approach the shooter was manipulated -- either moving directly in front of the
shooter (aggressive) or maintaining distance (passive) -- and the distraction
method, ranging from no additional cues (low), to siren and lights (medium), to
siren, lights, and smoke to impair visibility (high). An aggressive,
high-distraction robot reduced the number of victims by 46.6% relative to a
no-robot control. This outcome underscores both the potential of robotic
intervention to enhance safety and the pressing ethical questions surrounding
their use in school environments.

</details>


### [5] [RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies](https://arxiv.org/abs/2510.17950)
*Adina Yakefu,Bin Xie,Chongyang Xu,Enwen Zhang,Erjin Zhou,Fan Jia,Haitao Yang,Haoqiang Fan,Haowei Zhang,Hongyang Peng,Jing Tan,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Qinglun Zhang,Ruitao Zhang,Saike Huang,Shen Cheng,Shuaicheng Liu,Tiancai Wang,Tiezhen Wang,Wei Sun,Wenbin Tang,Yajun Wei,Yang Chen,Youqiang Gui,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yunhuan Yang,Yutong Guo,Ze Chen,Zhengyuan Du,Ziheng Zhang,Ziming Liu,Ziwei Yan*

Main category: cs.RO

TL;DR: 构建RoboChallenge在线评估系统，用于大规模测试机器人控制算法，特别是VLA模型，并利用初始基准Table30对最新VLA模型进行调研。


<details>
  <summary>Details</summary>
Motivation: 学习型算法（尤其是VLA模型）需要大规模评估，即在大量任务上测试大量模型，但实现可扩展性和可复现性具有挑战性。

Method: 构建RoboChallenge在线评估系统，采用初始基准Table30对最新VLA模型进行测试和调研。

Result: 开发了在线评估系统，并对最新VLA模型进行了初步调研。

Conclusion: RoboChallenge系统为机器人控制算法的大规模评估提供了可行方案，有助于推动VLA模型的发展。

Abstract: Testing on real machines is indispensable for robotic control algorithms. In
the context of learning-based algorithms, especially VLA models, demand for
large-scale evaluation, i.e. testing a large number of models on a large number
of tasks, is becoming increasingly urgent. However, doing this right is highly
non-trivial, especially when scalability and reproducibility is taken into
account. In this report, we describe our methodology for constructing
RoboChallenge, an online evaluation system to test robotic control algorithms,
and our survey of recent state-of-the-art VLA models using our initial
benchmark Table30.

</details>


### [6] [Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints](https://arxiv.org/abs/2510.18002)
*Junli Ren,Junfeng Long,Tao Huang,Huayi Wang,Zirui Wang,Feiyu Jia,Wentao Zhang,Jingbo Wang,Ping Luo,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出了一种用于人形机器人自主守门的强化学习框架，通过集成人类运动先验和对抗训练，实现了自然、动态的全身运动控制。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人守门面临的两个关键挑战：生成自然的类人全身运动，以及在相同响应时间内覆盖更广的防守范围。

Method: 使用端到端强化学习策略，通过对抗训练方案将基于感知输入的多个人类运动先验集成到RL训练中。

Result: 在真实世界实验中，人形机器人成功实现了敏捷、自主和自然的快速移动球拦截，并展示了在球逃脱和抓取等任务上的泛化能力。

Conclusion: 为机器人与移动物体之间的高度动态交互提供了实用且可扩展的解决方案，推动了自适应和逼真机器人行为的发展。

Abstract: We present a reinforcement learning framework for autonomous goalkeeping with
humanoid robots in real-world scenarios. While prior work has demonstrated
similar capabilities on quadrupedal platforms, humanoid goalkeeping introduces
two critical challenges: (1) generating natural, human-like whole-body motions,
and (2) covering a wider guarding range with an equivalent response time.
Unlike existing approaches that rely on separate teleoperation or fixed motion
tracking for whole-body control, our method learns a single end-to-end RL
policy, enabling fully autonomous, highly dynamic, and human-like robot-object
interactions. To achieve this, we integrate multiple human motion priors
conditioned on perceptual inputs into the RL training via an adversarial
scheme. We demonstrate the effectiveness of our method through real-world
experiments, where the humanoid robot successfully performs agile, autonomous,
and naturalistic interceptions of fast-moving balls. In addition to
goalkeeping, we demonstrate the generalization of our approach through tasks
such as ball escaping and grabbing. Our work presents a practical and scalable
solution for enabling highly dynamic interactions between robots and moving
objects, advancing the field toward more adaptive and lifelike robotic
behaviors.

</details>


### [7] [MOFM-Nav: On-Manifold Ordering-Flexible Multi-Robot Navigation](https://arxiv.org/abs/2510.18063)
*Bin-Bin Hu,Weijia Yao,Ming Cao*

Main category: cs.RO

TL;DR: 提出了一种用于多机器人在n维欧几里得空间中m维流形上导航的协调引导向量场算法，解决了流形参数强耦合问题，实现了灵活空间排序的协调运动。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在m维流形上导航时，由于流形参数强耦合导致的协调控制困难，特别是当使用非欧几里得度量进行灵活空间排序协调时面临的挑战。

Method: 首先识别可行的辅助向量解耦流形参数，然后重新设计协调引导向量场算法，将m个流形参数作为虚拟坐标，通过机器人与其时变邻居及虚拟目标机器人共享虚拟坐标来实现协调。

Result: 通过大量仿真验证了算法在不同初始位置、高维流形和机器人故障情况下的灵活性、适应性和鲁棒性。

Conclusion: 所提出的算法有效解决了流形参数耦合问题，实现了多机器人在流形上的灵活排序协调导航，具有消除奇点和全局收敛的优势。

Abstract: This paper addresses the problem of multi-robot navigation where robots
maneuver on a desired \(m\)-dimensional (i.e., \(m\)-D) manifold in the
$n$-dimensional Euclidean space, and maintain a {\it flexible spatial
ordering}. We consider $ m\geq 2$, and the multi-robot coordination is achieved
via non-Euclidean metrics. However, since the $m$-D manifold can be
characterized by the zero-level sets of $n$ implicit functions, the last $m$
entries of the GVF propagation term become {\it strongly coupled} with the
partial derivatives of these functions if the auxiliary vectors are not
appropriately chosen. These couplings not only influence the on-manifold
maneuvering of robots, but also pose significant challenges to the further
design of the ordering-flexible coordination via non-Euclidean metrics.
  To tackle this issue, we first identify a feasible solution of auxiliary
vectors such that the last $m$ entries of the propagation term are effectively
decoupled to be the same constant. Then, we redesign the coordinated GVF (CGVF)
algorithm to {\it boost} the advantages of singularities elimination and global
convergence by treating $m$ manifold parameters as additional $m$ virtual
coordinates. Furthermore, we enable the on-manifold ordering-flexible motion
coordination by allowing each robot to share $m$ virtual coordinates with its
time-varying neighbors and a virtual target robot, which {\it circumvents} the
possible complex calculation if Euclidean metrics were used instead. Finally,
we showcase the proposed algorithm's flexibility, adaptability, and robustness
through extensive simulations with different initial positions,
higher-dimensional manifolds, and robot breakdown, respectively.

</details>


### [8] [R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations](https://arxiv.org/abs/2510.18085)
*Connor Mattson,Varun Raveendra,Ellen Novoseller,Nicholas Waytowich,Vernon J. Lawhern,Daniel S. Brown*

Main category: cs.RO

TL;DR: 提出R2BC方法，通过轮询行为克隆让单个操作员能够通过顺序的单智能体演示来训练多机器人系统，无需在联合多智能体动作空间中进行演示。


<details>
  <summary>Details</summary>
Motivation: 模仿学习是教授机器人的自然方式，但在多智能体系统中，特别是当单个人类需要为协作机器人团队提供演示时，相关研究较少。

Method: R2BC方法允许人类操作员一次遥控一个智能体，通过顺序的单智能体演示逐步教授多智能体行为，避免了联合多智能体动作空间的演示需求。

Result: 在四个多智能体模拟任务中，R2BC方法匹配甚至超越了基于特权同步演示的oracle行为克隆方法的性能，并在两个物理机器人任务中成功部署。

Conclusion: R2BC是一种有效的多机器人系统训练方法，能够通过简单的单智能体演示实现复杂多智能体行为的教学。

Abstract: Imitation Learning (IL) is a natural way for humans to teach robots,
particularly when high-quality demonstrations are easy to obtain. While IL has
been widely applied to single-robot settings, relatively few studies have
addressed the extension of these methods to multi-agent systems, especially in
settings where a single human must provide demonstrations to a team of
collaborating robots. In this paper, we introduce and study Round-Robin
Behavior Cloning (R2BC), a method that enables a single human operator to
effectively train multi-robot systems through sequential, single-agent
demonstrations. Our approach allows the human to teleoperate one agent at a
time and incrementally teach multi-agent behavior to the entire system, without
requiring demonstrations in the joint multi-agent action space. We show that
R2BC methods match, and in some cases surpass, the performance of an oracle
behavior cloning approach trained on privileged synchronized demonstrations
across four multi-agent simulated tasks. Finally, we deploy R2BC on two
physical robot tasks trained using real human demonstrations.

</details>


### [9] [ANGEL: A Novel Gripper for Versatile and Light-touch Fruit Harvesting](https://arxiv.org/abs/2510.18127)
*Dharmik Patel,Antonio Rafael Vazquez Pantoja,Jiuzhou Lei,Kiju Lee,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出一种受拉绳启发的线驱动软抓取器，用于水果采摘，具有适应不同尺寸水果和轻柔抓取的特点。


<details>
  <summary>Details</summary>
Motivation: 水果采摘主要是劳动密集型过程，现有刚性或真空驱动抓取器需要复杂机械设计或高能耗，而现有包裹式抓取器缺乏对不同尺寸水果的适应性。

Method: 采用3D打印TPU材料制作带有集成钢丝的口袋结构，通过伺服驱动线缆控制实现收缩抓取，利用电机反馈实现自主抓取力调节。

Result: 在有效尺寸范围内的番茄采摘中，实现了0%的即时损伤率和5天后低于9%的瘀伤率。

Conclusion: 该抓取器结构轻量、组件少，降低了机械复杂性和成本，适合水果采摘应用。

Abstract: Fruit harvesting remains predominantly a labor-intensive process, motivating
the development of research for robotic grippers. Conventional rigid or
vacuum-driven grippers require complex mechanical design or high energy
consumption. Current enveloping-based fruit harvesting grippers lack
adaptability to fruits of different sizes. This paper introduces a
drawstring-inspired, cable-driven soft gripper for versatile and gentle fruit
harvesting. The design employs 3D-printed Thermoplastic Polyurethane (TPU)
pockets with integrated steel wires that constrict around the fruit when
actuated, distributing pressure uniformly to minimize bruising and allow
versatility to fruits of varying sizes. The lightweight structure, which
requires few components, reduces mechanical complexity and cost compared to
other grippers. Actuation is achieved through servo-driven cable control, while
motor feedback provides autonomous grip adjustment with tunable grip strength.
Experimental validation shows that, for tomatoes within the gripper's effective
size range, harvesting was achieved with a 0% immediate damage rate and a
bruising rate of less than 9% after five days, reinforcing the gripper's
suitability for fruit harvesting.

</details>


### [10] [Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning](https://arxiv.org/abs/2510.18137)
*Hrishikesh Sathyanarayan,Victor Vantilborgh,Ian Abraham*

Main category: cs.RO

TL;DR: 研究数据集效用，发现接触数据对机器人学习很重要，提出基于Fisher信息度量的数据筛选方法，证明少量但信息丰富的数据比大量数据更有效。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人学习中数据集的效用问题，特别是接触数据的重要性，因为接触包含了对机器人学习至关重要的信息。

Method: 提出接触感知的目标函数，从姿态和接触数据中学习物体动力学和形状，使用接触感知的Fisher信息度量来评估和筛选接触数据的价值。

Result: 基于信息度量筛选的缩减数据集能改善学习任务并使学习过程更确定，少量但信息丰富的数据能加速学习，特别是对于接触交互。

Conclusion: 更多数据不一定更好，精心筛选的接触数据能更有效地促进机器人学习，提出的度量方法可为接触数据筛选提供指导。

Abstract: In this paper, we investigate the utility of datasets and whether more data
or the 'right' data is advantageous for robot learning. In particular, we are
interested on quantifying the utility of contact-based data as contact holds
significant information for robot learning. Our approach derives a
contact-aware objective function for learning object dynamics and shape from
pose and contact data. We show that the contact-aware Fisher-information metric
can be used to rank and curate contact-data based on how informative data is
for learning. In addition, we find that selecting a reduced dataset based on
this ranking improves the learning task while also making learning a
deterministic process. Interestingly, our results show that more data is not
necessarily advantageous, and rather, less but informative data can accelerate
learning, especially depending on the contact interactions. Last, we show how
our metric can be used to provide initial guidance on data curation for
contact-based robot learning.

</details>


### [11] [MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation](https://arxiv.org/abs/2510.18316)
*Chengshu Li,Mengdi Xu,Arpit Bahety,Hang Yin,Yunfan Jiang,Huang Huang,Josiah Wong,Sujay Garlanka,Cem Gokmen,Ruohan Zhang,Weiyu Liu,Jiajun Wu,Roberto Martín-Martín,Li Fei-Fei*

Main category: cs.RO

TL;DR: MoMaGen是一个用于多步骤双手移动操作的数据生成框架，通过约束优化方法解决基座放置和相机定位问题，能够从单一演示生成多样化数据集，显著减少真实世界数据收集需求。


<details>
  <summary>Details</summary>
Motivation: 从大规模人类演示中学习对机器人训练有效，但收集多步骤双手移动操作数据成本高昂且耗时。现有自动化数据生成方法在移动场景中存在基座放置和相机定位两个关键挑战。

Method: 将数据生成建模为约束优化问题，强制执行硬约束（如可达性）同时平衡软约束（如导航期间的可见性），为多步骤双手移动操作提供原则性数据生成框架。

Result: 在四个多步骤双手移动操作任务上评估，MoMaGen生成的数据集比现有方法更多样化，能够从单一源演示训练成功的模仿学习策略，仅需40个真实世界演示即可微调部署到物理机器人硬件。

Conclusion: MoMaGen为解决多步骤双手移动操作的数据生成挑战提供了有效框架，显著减少了对昂贵人类演示数据的依赖，实现了从模拟到真实世界的成功迁移。

Abstract: Imitation learning from large-scale, diverse human demonstrations has proven
effective for training robots, but collecting such data is costly and
time-consuming. This challenge is amplified for multi-step bimanual mobile
manipulation, where humans must teleoperate both a mobile base and two
high-degree-of-freedom arms. Prior automated data generation frameworks have
addressed static bimanual manipulation by augmenting a few human demonstrations
in simulation, but they fall short for mobile settings due to two key
challenges: (1) determining base placement to ensure reachability, and (2)
positioning the camera to provide sufficient visibility for visuomotor
policies. To address these issues, we introduce MoMaGen, which formulates data
generation as a constrained optimization problem that enforces hard constraints
(e.g., reachability) while balancing soft constraints (e.g., visibility during
navigation). This formulation generalizes prior approaches and provides a
principled foundation for future methods. We evaluate MoMaGen on four
multi-step bimanual mobile manipulation tasks and show that it generates
significantly more diverse datasets than existing methods. Leveraging this
diversity, MoMaGen can train successful imitation learning policies from a
single source demonstration, and these policies can be fine-tuned with as few
as 40 real-world demonstrations to achieve deployment on physical robotic
hardware. More details are available at our project page: momagen.github.io.

</details>


### [12] [MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning](https://arxiv.org/abs/2510.18337)
*Wenhui Huang,Changhe Chen,Han Qi,Chen Lv,Yilun Du,Heng Yang*

Main category: cs.RO

TL;DR: MoTVLA是一种基于混合变换器的视觉-语言-动作模型，通过集成快慢推理与行为策略学习，解决了现有方法中语言可操控性不足或推理延迟高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在机器人学习中面临两个挑战：当不使用生成的推理作为条件时，语言可操控性有限；或者当引入推理时，推理延迟显著增加。

Method: MoTVLA结合了预训练VLM的通用智能（作为通才）和领域专家（第二个变换器），后者生成领域特定的快速推理（如机器人运动分解），并通过将动作专家基于分解的运动指令来学习多样化行为。

Result: 在自然语言处理基准、机器人仿真环境和真实世界实验中的广泛评估证实了MoTVLA在快慢推理和操作任务性能方面的优越性。

Conclusion: MoTVLA通过集成快慢统一推理与行为策略学习，显著提高了语言可操控性和策略执行效率，在多个评估场景中表现出色。

Abstract: Integrating visual-language instructions into visuomotor policies is gaining
momentum in robot learning for enhancing open-world generalization. Despite
promising advances, existing approaches face two challenges: limited language
steerability when no generated reasoning is used as a condition, or significant
inference latency when reasoning is incorporated.In this work, we introduce
MoTVLA, a mixture-of-transformers (MoT)-based vision-language-action (VLA)
model that integrates fast-slow unified reasoning with behavior policy
learning. MoTVLA preserves the general intelligence of pre-trained VLMs
(serving as the generalist) for tasks such as perception, scene understanding,
and semantic planning, while incorporating a domain expert, a second
transformer that shares knowledge with the pretrained VLM, to generate
domain-specific fast reasoning (e.g., robot motion decomposition), thereby
improving policy execution efficiency. By conditioning the action expert on
decomposed motion instructions, MoTVLA can learn diverse behaviors and
substantially improve language steerability. Extensive evaluations across
natural language processing benchmarks, robotic simulation environments, and
real-world experiments confirm the superiority of MoTVLA in both fast-slow
reasoning and manipulation task performance.

</details>


### [13] [Coverage-Recon: Coordinated Multi-Drone Image Sampling with Online Map Feedback](https://arxiv.org/abs/2510.18347)
*Muhammad Hanif,Reiji Terunuma,Takumi Sumino,Kelvin Cheng,Takeshi Hatanaka*

Main category: cs.RO

TL;DR: 提出Coverage-Recon算法，通过在线地图反馈改进多无人机协同3D重建质量，结合QP覆盖控制和NeuralRecon实时重建


<details>
  <summary>Details</summary>
Motivation: 实现高质量3D重建需要从多视角捕获关键点图像，而实时重建算法的发展使得能够在飞行中提供即时反馈来指导无人机运动

Method: 使用基于QP的角度感知覆盖控制器协调无人机运动，通过NeuralRecon算法实时生成3D网格，将网格变化作为重建不确定性指标来更新覆盖控制的重要性指数

Result: 仿真和实验验证表明，相比传统方法，引入在线地图反馈能产生更完整和准确的3D重建结果

Conclusion: Coverage-Recon算法通过集成在线地图反馈，有效提升了多无人机协同3D地图重建的质量和完整性

Abstract: This article addresses collaborative 3D map reconstruction using multiple
drones. Achieving high-quality reconstruction requires capturing images of
keypoints within the target scene from diverse viewing angles, and coverage
control offers an effective framework to meet this requirement. Meanwhile,
recent advances in real-time 3D reconstruction algorithms make it possible to
render an evolving map during flight, enabling immediate feedback to guide
drone motion. Building on this, we present Coverage-Recon, a novel coordinated
image sampling algorithm that integrates online map feedback to improve
reconstruction quality on-the-fly. In Coverage-Recon, the coordinated motion of
drones is governed by a Quadratic Programming (QP)-based angle-aware coverage
controller, which ensures multi-viewpoint image capture while enforcing safety
constraints. The captured images are processed in real time by the NeuralRecon
algorithm to generate an evolving 3D mesh. Mesh changes across the scene are
interpreted as indicators of reconstruction uncertainty and serve as feedback
to update the importance index of the coverage control as the map evolves. The
effectiveness of Coverage-Recon is validated through simulation and
experiments, demonstrating both qualitatively and quantitatively that
incorporating online map feedback yields more complete and accurate 3D
reconstructions than conventional methods. Project page:
https://htnk-lab.github.io/coverage-recon/

</details>


### [14] [PGTT: Phase-Guided Terrain Traversal for Perceptive Legged Locomotion](https://arxiv.org/abs/2510.18348)
*Alexandros Ntagkas,Chairi Kiourt,Konstantinos Chatzilygeroudis*

Main category: cs.RO

TL;DR: PGTT是一种感知增强的深度强化学习方法，通过奖励塑形而非动作先验来引导步态结构，在复杂地形上实现更鲁棒的四足机器人运动控制。


<details>
  <summary>Details</summary>
Motivation: 现有感知强化学习方法存在局限性：要么使用振荡器或逆运动学步态先验，这会约束动作空间、增加策略优化偏差并降低跨机器人形态的适应性；要么采用"盲"控制方法，难以预测后腿地形且对噪声敏感。

Method: 提出PGTT方法，通过奖励塑形而非动作先验来实施步态结构，使用三次Hermite样条编码腿部相位，根据局部高度图统计调整摆动高度，并添加摆动相位接触惩罚，策略直接在关节空间操作以支持形态无关部署。

Result: 在MuJoCo模拟器中训练，PGTT在推力干扰下成功率中位数比次优方法高7.5%，在离散障碍物上高9%，速度跟踪性能相当，收敛速度比强端到端基线快约2倍。在Unitree Go2和ANYmal-C机器人上验证有效。

Conclusion: 地形自适应、相位引导的奖励塑形是实现跨平台鲁棒感知运动控制的简单通用机制。

Abstract: State-of-the-art perceptive Reinforcement Learning controllers for legged
robots either (i) impose oscillator or IK-based gait priors that constrain the
action space, add bias to the policy optimization and reduce adaptability
across robot morphologies, or (ii) operate "blind", which struggle to
anticipate hind-leg terrain, and are brittle to noise. In this paper, we
propose Phase-Guided Terrain Traversal (PGTT), a perception-aware deep-RL
approach that overcomes these limitations by enforcing gait structure purely
through reward shaping, thereby reducing inductive bias in policy learning
compared to oscillator/IK-conditioned action priors. PGTT encodes per-leg phase
as a cubic Hermite spline that adapts swing height to local heightmap
statistics and adds a swing-phase contact penalty, while the policy acts
directly in joint space supporting morphology-agnostic deployment. Trained in
MuJoCo (MJX) on procedurally generated stair-like terrains with curriculum and
domain randomization, PGTT achieves the highest success under push disturbances
(median +7.5% vs. the next best method) and on discrete obstacles (+9%), with
comparable velocity tracking, and converging to an effective policy roughly 2x
faster than strong end-to-end baselines. We validate PGTT on a Unitree Go2
using a real-time LiDAR elevation-to-heightmap pipeline, and we report
preliminary results on ANYmal-C obtained with the same hyperparameters. These
findings indicate that terrain-adaptive, phase-guided reward shaping is a
simple and general mechanism for robust perceptive locomotion across platforms.

</details>


### [15] [MMRHP: A Miniature Mixed-Reality HIL Platform for Auditable Closed-Loop Evaluation](https://arxiv.org/abs/2510.18371)
*Mingxin Li,Haibo Hu,Jinghuai Deng,Yuchen Xi,Xinhong Chen,Jianping Wang*

Main category: cs.RO

TL;DR: MMRHP是一个微型混合现实硬件在环平台，通过系统化测试流程和统一的时空测量核心，将自动驾驶系统测试从功能演示提升到严谨的定量分析。


<details>
  <summary>Details</summary>
Motivation: 现有微型硬件在环平台缺乏支持严谨定量分析的系统化框架，限制了其作为科学评估工具的价值。

Method: 提出三阶段测试流程面向SOTIF标准，设计实现以统一时空测量核心为中心的硬件在环平台，确保物理运动和系统时序的一致可追溯量化。

Result: 平台验证显示空间精度达到10.27毫米RMSE，闭环延迟基线约45毫秒。Autoware案例研究发现40毫秒注入延迟时出现关键性能悬崖。

Conclusion: 结构化流程与提供统一时空基准的平台相结合，能够实现自动驾驶系统可重现、可解释的定量闭环评估。

Abstract: Validation of autonomous driving systems requires a trade-off between test
fidelity, cost, and scalability. While miniaturized hardware-in-the-loop (HIL)
platforms have emerged as a promising solution, a systematic framework
supporting rigorous quantitative analysis is generally lacking, limiting their
value as scientific evaluation tools. To address this challenge, we propose
MMRHP, a miniature mixed-reality HIL platform that elevates miniaturized
testing from functional demonstration to rigorous, reproducible quantitative
analysis. The core contributions are threefold. First, we propose a systematic
three-phase testing process oriented toward the Safety of the Intended
Functionality(SOTIF)standard, providing actionable guidance for identifying the
performance limits and triggering conditions of otherwise correctly functioning
systems. Second, we design and implement a HIL platform centered around a
unified spatiotemporal measurement core to support this process, ensuring
consistent and traceable quantification of physical motion and system timing.
Finally, we demonstrate the effectiveness of this solution through
comprehensive experiments. The platform itself was first validated, achieving a
spatial accuracy of 10.27 mm RMSE and a stable closed-loop latency baseline of
approximately 45 ms. Subsequently, an in-depth Autoware case study leveraged
this validated platform to quantify its performance baseline and identify a
critical performance cliff at an injected latency of 40 ms. This work shows
that a structured process, combined with a platform offering a unified
spatio-temporal benchmark, enables reproducible, interpretable, and
quantitative closed-loop evaluation of autonomous driving systems.

</details>


### [16] [Biomechanically consistent real-time action recognition for human-robot interaction](https://arxiv.org/abs/2510.18373)
*Wanchen Li,Kahina Chalabi,Sabbah Maxime,Thomas Bousquet,Robin Passama,Sofiane Ramdani,Andrea Cherubini,Vincent Bonnet*

Main category: cs.RO

TL;DR: 提出了一种基于2D摄像头的实时工业动作识别框架，使用关节角度而非关节中心位置，结合Transformer网络实现实时动作识别，在未见过的测试对象上达到88%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多依赖关节中心位置且为离线处理，缺乏对传感器位置、人体姿态和个体差异的鲁棒性，需要开发实时且鲁棒的工业动作识别系统。

Method: 使用完整的关节运动学估计流程，结合时间平滑的Transformer网络，利用生物力学先验（关节角度）进行实时动作识别。

Result: 在11名受试者的数据集上评估，优于最佳基线模型，达到88%准确率，对未面对摄像头的受试者表现出良好泛化能力，并通过机器人实时交互实验验证实用性。

Conclusion: 基于关节角度的方法具有传感器和姿态无关性，在工业环境中实现了鲁棒的实时动作识别，展示了实际应用价值。

Abstract: This paper presents a novel framework for real-time human action recognition
in industrial contexts, using standard 2D cameras. We introduce a complete
pipeline for robust and real-time estimation of human joint kinematics, input
to a temporally smoothed Transformer-based network, for action recognition. We
rely on a new dataset including 11 subjects performing various actions, to
evaluate our approach. Unlike most of the literature that relies on joint
center positions (JCP) and is offline, ours uses biomechanical prior, eg. joint
angles, for fast and robust real-time recognition. Besides, joint angles make
the proposed method agnostic to sensor and subject poses as well as to
anthropometric differences, and ensure robustness across environments and
subjects. Our proposed learning model outperforms the best baseline model,
running also in real-time, along various metrics. It achieves 88% accuracy and
shows great generalization ability, for subjects not facing the cameras.
Finally, we demonstrate the robustness and usefulness of our technique, through
an online interaction experiment, with a simulated robot controlled in
real-time via the recognized actions.

</details>


### [17] [MPC-based motion planning for non-holonomic systems in non-convex domains](https://arxiv.org/abs/2510.18402)
*Matthias Lorenzen,Teodoro Alamo,Martina Mammarella,Fabrizio Dabbene*

Main category: cs.RO

TL;DR: 提出一种用于非完整系统和非凸约束的输出跟踪模型预测控制(MPC)方法，保证在现实假设下收敛到目标点


<details>
  <summary>Details</summary>
Motivation: 现有MPC理论主要针对完整系统和凸约束，而实际机器人运动规划涉及非完整系统和非凸约束，缺乏理论保证

Method: 设计新颖的MPC公式，考虑非完整系统特性和非凸约束条件

Result: 提出的方法能够保证在可验证的现实假设下收敛到期望目标

Conclusion: 该工作填补了非完整系统和非凸约束下MPC理论保证的空白，为实际机器人运动规划提供了理论支撑

Abstract: Motivated by the application of using model predictive control (MPC) for
motion planning of autonomous mobile robots, a form of output tracking MPC for
non-holonomic systems and with non-convex constraints is studied. Although the
advantages of using MPC for motion planning have been demonstrated in several
papers, in most of the available fundamental literature on output tracking MPC
it is assumed, often implicitly, that the model is holonomic and generally the
state or output constraints must be convex. Thus, in application-oriented
publications, empirical results dominate and the topic of proving completeness,
in particular under which assumptions the target is always reached, has
received comparatively little attention. To address this gap, we present a
novel MPC formulation that guarantees convergence to the desired target under
realistic assumptions, which can be verified in relevant real-world scenarios.

</details>


### [18] [Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning](https://arxiv.org/abs/2510.18518)
*Fang Nan,Hao Ma,Qinghua Guan,Josie Hughes,Michael Muehlebach,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种在线模型强化学习算法，可直接在真实世界中训练复杂机器人系统，相比模型无关方法显著提高了样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统的sim-to-real方法依赖大量离线仿真，存在模拟数据偏差问题。本文旨在直接在真实世界中高效学习控制策略。

Method: 从实时交互数据构建动力学模型，基于学习到的模型指导策略更新，采用在线学习分析推导性能保证。

Result: 在液压挖掘臂和软体机器人臂上验证，相比模型无关方法样本效率显著提升，数小时内达到可比性能，且能适应动态变化。

Conclusion: 该方法为挑战性控制任务提供了高效可靠的在线机器人学习途径。

Abstract: We present an online model-based reinforcement learning algorithm suitable
for controlling complex robotic systems directly in the real world. Unlike
prevailing sim-to-real pipelines that rely on extensive offline simulation and
model-free policy optimization, our method builds a dynamics model from
real-time interaction data and performs policy updates guided by the learned
dynamics model. This efficient model-based reinforcement learning scheme
significantly reduces the number of samples to train control policies, enabling
direct training on real-world rollout data. This significantly reduces the
influence of bias in the simulated data, and facilitates the search for
high-performance control policies. We adopt online learning analysis to derive
sublinear regret bounds under standard stochastic online optimization
assumptions, providing formal guarantees on performance improvement as more
interaction data are collected. Experimental evaluations were performed on a
hydraulic excavator arm and a soft robot arm, where the algorithm demonstrates
strong sample efficiency compared to model-free reinforcement learning methods,
reaching comparable performance within hours. Robust adaptation to shifting
dynamics was also observed when the payload condition was randomized. Our
approach paves the way toward efficient and reliable on-robot learning for a
broad class of challenging control tasks.

</details>


### [19] [EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval](https://arxiv.org/abs/2510.18546)
*Zebin Yang,Sunjian Zheng,Tong Xie,Tianshi Xu,Bo Yu,Fan Wang,Jie Tang,Shaoshan Liu,Meng Li*

Main category: cs.RO

TL;DR: EfficientNav 提出了一种基于小型语言模型的零样本物体导航方法，通过语义感知内存检索和离散内存缓存技术，在保持高性能的同时大幅降低计算延迟。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型的物体导航方法依赖云端巨型模型，无法在本地设备部署。直接使用小型语言模型会因模型容量限制导致性能显著下降，且导航地图的长提示会导致高规划延迟。

Method: 提出语义感知内存检索来修剪导航地图中的冗余信息，帮助小型语言模型更好地理解环境；采用离散内存缓存和基于注意力的内存聚类来高效保存和重用KV缓存，减少规划延迟。

Result: 在HM3D基准测试中，相比基于GPT-4的基线方法，EfficientNav实现了11.1%的成功率提升，同时实现了6.7倍的实时延迟降低和4.7倍的端到端延迟降低。

Conclusion: EfficientNav成功实现了在本地设备上高效运行基于语言模型的零样本物体导航，在性能和延迟方面均优于基于云端大型语言模型的方法。

Abstract: Object-goal navigation (ObjNav) tasks an agent with navigating to the
location of a specific object in an unseen environment. Embodied agents
equipped with large language models (LLMs) and online constructed navigation
maps can perform ObjNav in a zero-shot manner. However, existing agents heavily
rely on giant LLMs on the cloud, e.g., GPT-4, while directly switching to small
LLMs, e.g., LLaMA3.2-11b, suffer from significant success rate drops due to
limited model capacity for understanding complex navigation maps, which
prevents deploying ObjNav on local devices. At the same time, the long prompt
introduced by the navigation map description will cause high planning latency
on local devices. In this paper, we propose EfficientNav to enable on-device
efficient LLM-based zero-shot ObjNav. To help the smaller LLMs better
understand the environment, we propose semantics-aware memory retrieval to
prune redundant information in navigation maps. To reduce planning latency, we
propose discrete memory caching and attention-based memory clustering to
efficiently save and re-use the KV cache. Extensive experimental results
demonstrate that EfficientNav achieves 11.1% improvement in success rate on
HM3D benchmark over GPT-4-based baselines, and demonstrates 6.7x real-time
latency reduction and 4.7x end-to-end latency reduction over GPT-4 planner. Our
code will be released soon.

</details>


### [20] [Flexbee: A Grasping and Perching UAV Based on Soft Vector-Propulsion Nozzle](https://arxiv.org/abs/2510.18558)
*Yue Wang,Lixian Zhang,Yimin Zhu,Yangguang Liu,Xuwei Yang*

Main category: cs.RO

TL;DR: 设计了一种新型抓取和栖息无人机Flexbee，集成了软体矢量推进喷嘴，实现了飞行、抓取和栖息功能的统一，具有解耦控制、高结构复用性和强适应性。


<details>
  <summary>Details</summary>
Motivation: 传统无人机通常将飞行、抓取和栖息功能分开设计，导致系统复杂且效率低下。Flexbee旨在通过软体矢量推进喷嘴将这些功能集成到四个推进器中，提高结构效率和适应性。

Method: 开发了Flexbee的动力学模型，通过等效力矩模型的线性化解决了非线性耦合问题，并采用分层控制策略设计两种操作模式的控制器。

Result: 通过飞行、抓取和栖息实验验证了Flexbee的运动学能力和控制策略的有效性，展示了其在多种操作模式下的性能。

Conclusion: Flexbee成功实现了飞行、抓取和栖息功能的集成，证明了软体矢量推进喷嘴在无人机设计中的可行性和优势，为未来多功能无人机开发提供了新思路。

Abstract: The aim of this paper is to design a new type of grasping and perching
unmanned aerial vehicle (UAV), called Flexbee, which features a soft
vector-propulsion nozzle (SVPN). Compared to previous UAVs, Flexbee integrates
flight, grasping, and perching functionalities into the four SVPNs. This
integration offers advantages including decoupled position and attitude
control, high structural reuse, and strong adaptability strong adaptability for
grasping and perching. A dynamics model of Flexbee has been developed, and the
nonlinear coupling issue of the moment has been resolved through linearization
of the equivalent moment model. A hierarchical control strategy was used to
design controllers for the two operational modes of Flexbee. Finally, flight,
grasping, and perching experiments were conducted to validate Flexbee's
kinematic capabilities and the effectiveness of the control strategy.

</details>


### [21] [Quadrupeds for Planetary Exploration: Field Testing Control Algorithms on an Active Volcano](https://arxiv.org/abs/2510.18600)
*Shubham Vyas,Franek Stark,Rohit Kumar,Hannah Isermann,Jonas Haack,Mihaela Popescu,Jakob Middelberg,Dennis Mronga,Frank Kirchner*

Main category: cs.RO

TL;DR: 在意大利武尔卡诺火山进行的四足机器人实地实验，验证了用于月球和火星表面模拟环境的新型自适应最优控制算法。


<details>
  <summary>Details</summary>
Motivation: 扩展行星探索任务的能力，让腿式机器人能够穿越比轮式探测器更困难的地形，如跳过地面裂缝或在崎岖地形中移动。

Method: 在武尔卡诺火山进行实地实验，采用新开发的自适应最优控制算法，测试四足机器人在高保真模拟环境中的运动能力。

Result: 成功验证了状态自适应最优控制算法在模拟月球和火星表面环境中的有效性。

Conclusion: 腿式机器人能够显著增强未来行星探索任务的能力，特别是在困难地形中的移动性能。

Abstract: Missions such as the Ingenuity helicopter have shown the advantages of using
novel locomotion modes to increase the scientific return of planetary
exploration missions. Legged robots can further expand the reach and capability
of future planetary missions by traversing more difficult terrain than wheeled
rovers, such as jumping over cracks on the ground or traversing rugged terrain
with boulders. To develop and test algorithms for using quadruped robots, the
AAPLE project was carried out at DFKI. As part of the project, we conducted a
series of field experiments on the Volcano on the Aeolian island of Vulcano, an
active stratovolcano near Sicily, Italy. The experiments focused on validating
newly developed state-of-the-art adaptive optimal control algorithms for
quadrupedal locomotion in a high-fidelity analog environment for Lunar and
Martian surfaces. This paper presents the technical approach, test plan,
software architecture, field deployment strategy, and evaluation results from
the Vulcano campaign.

</details>


### [22] [A Compositional Paradigm for Foundation Models: Towards Smarter Robotic Agents](https://arxiv.org/abs/2510.18608)
*Luigi Quarantiello,Elia Piccoli,Jack Bell,Malio Li,Giacomo Carfì,Eric Nuertey Coleman,Gerlando Gramaglia,Lanpei Li,Mauro Madeddu,Irene Testa,Vincenzo Lomonaco*

Main category: cs.RO

TL;DR: 应用持续学习和组合性原则来增强基础模型的灵活性和适应性


<details>
  <summary>Details</summary>
Motivation: 基础模型在处理动态现实场景时存在适应性问题，需要重新训练整个模型

Method: 提出将持续学习和组合性原则应用于基础模型

Result: 未在摘要中明确说明具体结果

Conclusion: 持续学习和组合性原则有助于开发更灵活、高效和智能的AI解决方案

Abstract: The birth of Foundation Models brought unprecedented results in a wide range
of tasks, from language to vision, to robotic control. These models are able to
process huge quantities of data, and can extract and develop rich
representations, which can be employed across different domains and modalities.
However, they still have issues in adapting to dynamic, real-world scenarios
without retraining the entire model from scratch. In this work, we propose the
application of Continual Learning and Compositionality principles to foster the
development of more flexible, efficient and smart AI solutions.

</details>


### [23] [Least Restrictive Hyperplane Control Barrier Functions](https://arxiv.org/abs/2510.18643)
*Mattias Trende,Petter Ögren*

Main category: cs.RO

TL;DR: 提出了一种优化控制屏障函数(CBF)和控制器的方法，通过同时优化CBF和控制器来获得最不保守的安全约束，而不是先选择CBF再选择控制器。


<details>
  <summary>Details</summary>
Motivation: 传统CBF方法在处理复杂形状不安全区域时往往需要保守近似，这可能导致过度限制的控制动作。现有方法先选择CBF再选择控制器，而本文认为保守约束只有在阻止我们做想做的事情时才成为问题。

Method: 同时优化CBF和控制器，找到最不限制的超平面CBF，并提供CBF族的平滑参数化方法。在具有加速度约束的双积分器动态系统中验证，处理任意形状的静态和动态障碍物。

Result: 开发了最不限制超平面CBF方法，能够在保证安全性的同时最大化控制自由度，相比传统保守CBF方法具有更好的性能。

Conclusion: 通过同时优化CBF和控制器，可以获得更接近期望控制的安全控制策略，同时保持CBF提供的安全保证，为解决复杂形状不安全区域的安全控制问题提供了有效方法。

Abstract: Control Barrier Functions (CBFs) can provide provable safety guarantees for
dynamic systems. However, finding a valid CBF for a system of interest is often
non-trivial, especially if the shape of the unsafe region is complex and the
CBFs are of higher order. A common solution to this problem is to make a
conservative approximation of the unsafe region in the form of a
line/hyperplane, and use the corresponding conservative Hyperplane-CBF when
deciding on safe control actions. In this letter, we note that conservative
constraints are only a problem if they prevent us from doing what we want.
Thus, instead of first choosing a CBF and then choosing a safe control with
respect to the CBF, we optimize over a combination of CBFs and safe controls to
get as close as possible to our desired control, while still having the safety
guarantee provided by the CBF. We call the corresponding CBF the least
restrictive Hyperplane-CBF. Finally, we also provide a way of creating a smooth
parameterization of the CBF-family for the optimization, and illustrate the
approach on a double integrator dynamical system with acceleration constraints,
moving through a group of arbitrarily shaped static and moving obstacles.

</details>


### [24] [Towards An Adaptive Locomotion Strategy For Quadruped Rovers: Quantifying When To Slide Or Walk On Planetary Slopes](https://arxiv.org/abs/2510.18678)
*Alberto Sanchez-Delgado,João Carlos Virgolino Soares,David Omar Al Tawil,Alessia Li Noce,Matteo Villa,Victor Barasuol,Paolo Arena,Claudio Semini*

Main category: cs.RO

TL;DR: 比较四足机器人在不同坡度、摩擦条件和速度下的行走与躯干滑动两种运动方式的运输成本，旨在确定两种策略切换的阈值条件。


<details>
  <summary>Details</summary>
Motivation: 传统腿式运动在松散倾斜表面（如陨石坑壁和洞穴斜坡）上可能效率低下且危险，需要开发更高效的自适应运动策略。

Method: 结合Isaac Sim中的物理仿真和ANSYS-Rocky中的粒子交互验证，分析行走与滑动两种运动方式的运输成本。

Result: 通过识别行走和滑动运输成本曲线的交点，定义了触发两种策略转换的阈值条件。

Conclusion: 这项研究为行星腿式漫游车的自适应运动策略开发迈出了初步步骤。

Abstract: Legged rovers provide enhanced mobility compared to wheeled platforms,
enabling navigation on steep and irregular planetary terrains. However,
traditional legged locomotion might be energetically inefficient and
potentially dangerous to the rover on loose and inclined surfaces, such as
crater walls and cave slopes. This paper introduces a preliminary study that
compares the Cost of Transport (CoT) of walking and torso-based sliding
locomotion for quadruped robots across different slopes, friction conditions
and speed levels. By identifying intersections between walking and sliding CoT
curves, we aim to define threshold conditions that may trigger transitions
between the two strategies. The methodology combines physics-based simulations
in Isaac Sim with particle interaction validation in ANSYS-Rocky. Our results
represent an initial step towards adaptive locomotion strategies for planetary
legged rovers.

</details>


### [25] [Event-Grounding Graph: Unified Spatio-Temporal Scene Graph from Robotic Observations](https://arxiv.org/abs/2510.18697)
*Phuoc Nguyen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 提出了事件基础图（EGG）框架，将事件交互与场景空间特征关联起来，使机器人能够感知、推理和响应复杂的时空查询


<details>
  <summary>Details</summary>
Motivation: 当前语义场景表示方法缺乏空间特征与动态事件之间的连接，限制了机器人对环境理解的完整性

Method: 开发了事件基础图（EGG）框架，将事件交互与场景空间特征进行关联

Result: 使用真实机器人数据的实验表明，EGG能够检索相关信息并准确响应关于环境和事件的人类查询

Conclusion: EGG框架有效连接了空间特征和动态事件，提升了机器人的场景理解和响应能力，相关代码和数据集已开源

Abstract: A fundamental aspect for building intelligent autonomous robots that can
assist humans in their daily lives is the construction of rich environmental
representations. While advances in semantic scene representations have enriched
robotic scene understanding, current approaches lack a connection between
spatial features and dynamic events; e.g., connecting the blue mug to the event
washing a mug. In this work, we introduce the event-grounding graph (EGG), a
framework grounding event interactions to spatial features of a scene. This
representation allows robots to perceive, reason, and respond to complex
spatio-temporal queries. Experiments using real robotic data demonstrate EGG's
capability to retrieve relevant information and respond accurately to human
inquiries concerning the environment and events within. Furthermore, the EGG
framework's source code and evaluation dataset are released as open-source at:
https://github.com/aalto-intelligent-robotics/EGG.

</details>


### [26] [Sharing the Load: Distributed Model-Predictive Control for Precise Multi-Rover Cargo Transport](https://arxiv.org/abs/2510.18766)
*Alexander Krawciw,Sven Lilge,Luka Antonyshyn,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 开发了一种用于多车辆货物运输的分布式模型预测控制器，通过共享地图实现车辆间相对定位，无需GNSS或直接观测，在10公里以上驾驶测试中保持间距误差在20厘米内。


<details>
  <summary>Details</summary>
Motivation: 自主货物运输中，多机器人团队比单个大型机器人更具操作灵活性，但需要精确的车辆间距和路径跟踪能力。

Method: 基于激光雷达教学重复的精确路径跟踪，开发分布式MPC控制器，使用共享地图进行机器人相对定位，无需GNSS或直接观测。

Result: 分布式MPC与集中式MPC性能相当，在2-3辆车的车队中实时运行，在各种条件下能将最大间距保持在目标值的20厘米内。

Conclusion: 分布式计算提供的操作灵活性使其非常适合实际部署，分布式MPC方法在实时性方面表现良好。

Abstract: For autonomous cargo transportation, teams of mobile robots can provide more
operational flexibility than a single large robot. In these scenarios,
precision in both inter-vehicle distance and path tracking is key. With this
motivation, we develop a distributed model-predictive controller (MPC) for
multi-vehicle cargo operations that builds on the precise path-tracking of
lidar teach and repeat. To carry cargo, a following vehicle must maintain a
Euclidean distance offset from a lead vehicle regardless of the path curvature.
Our approach uses a shared map to localize the robots relative to each other
without GNSS or direct observations. We compare our approach to a centralized
MPC and a baseline approach that directly measures the inter-vehicle distance.
The distributed MPC shows equivalent nominal performance to the more complex
centralized MPC. Using a direct measurement of the relative distance between
the leader and follower shows improved tracking performance in close-range
scenarios but struggles with long-range offsets. The operational flexibility
provided by distributing the computation makes it well suited for real
deployments. We evaluate four types of convoyed path trackers with over 10 km
of driving in a coupled convoy. With convoys of two and three rovers, the
proposed distributed MPC method works in real-time to allow map-based convoying
to maintain maximum spacing within 20 cm of the target in various conditions.

</details>


### [27] [MADR: MPC-guided Adversarial DeepReach](https://arxiv.org/abs/2510.18845)
*Ryan Teoh,Sander Tonkens,William Sharpless,Aijia Yang,Zeyuan Feng,Somil Bansal,Sylvia Herbert*

Main category: cs.RO

TL;DR: 提出了MADR框架，结合MPC引导和对抗性深度学习方法，用于近似两人零和微分博弈的值函数，解决了高维Hamilton-Jacobi可达性分析的计算难题。


<details>
  <summary>Details</summary>
Motivation: 传统Hamilton-Jacobi可达性分析面临维度灾难，而基于物理信息的深度学习方法收敛缓慢且不准确。现有方法仅限于单玩家问题和简单博弈，需要一种能处理两人零和微分博弈的通用框架。

Method: MADR框架结合模型预测控制(MPC)引导和对抗性深度学习方法，通过丰富自监督过程的正则监督来近似两人零和微分博弈的值函数，生成双方最优策略和最坏情况鲁棒安全策略。

Result: 在多种高维模拟和真实机器人代理上测试，MADR显著优于现有最优基线方法，在仿真中表现优异，在硬件实验中产生令人印象深刻的结果。

Conclusion: MADR提供了一个通用框架，能够鲁棒地近似两人零和微分博弈的值函数，有效解决了高维可达性分析的计算挑战，在复杂动态系统和博弈中表现出色。

Abstract: Hamilton-Jacobi (HJ) Reachability offers a framework for generating safe
value functions and policies in the face of adversarial disturbance, but is
limited by the curse of dimensionality. Physics-informed deep learning is able
to overcome this infeasibility, but itself suffers from slow and inaccurate
convergence, primarily due to weak PDE gradients and the complexity of
self-supervised learning. A few works, recently, have demonstrated that
enriching the self-supervision process with regular supervision (based on the
nature of the optimal control problem), greatly accelerates convergence and
solution quality, however, these have been limited to single player problems
and simple games. In this work, we introduce MADR: MPC-guided Adversarial
DeepReach, a general framework to robustly approximate the two-player, zero-sum
differential game value function. In doing so, MADR yields the corresponding
optimal strategies for both players in zero-sum games as well as safe policies
for worst-case robustness. We test MADR on a multitude of high-dimensional
simulated and real robotic agents with varying dynamics and games, finding that
our approach significantly out-performs state-of-the-art baselines in
simulation and produces impressive results in hardware.

</details>


### [28] [Online Object-Level Semantic Mapping for Quadrupeds in Real-World Environments](https://arxiv.org/abs/2510.18776)
*Emad Razavi,Angelo Bratta,João Carlos Virgolino Soares,Carmine Recchiuto,Claudio Semini*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人的在线语义对象映射系统，将传感器检测转换为全局地图中的命名对象，实现跨帧的持久对象实例关联。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在真实室内环境中运行时，需要将传感器检测结果整合为可查询的语义对象地图，支持规划器使用。

Method: 集成距离几何与相机检测，在帧内合并共位检测，跨帧关联重复检测形成持久对象实例，对象在视野外仍保留在图中。

Result: 系统输出紧凑的对象层（包含类别、位姿和置信度），与占用地图集成，在机器人测试中视角变化时保持稳定。

Conclusion: 成功开发了能够稳定运行的四足机器人语义对象映射系统，为机器人规划提供了可靠的环境语义信息。

Abstract: We present an online semantic object mapping system for a quadruped robot
operating in real indoor environments, turning sensor detections into named
objects in a global map. During a run, the mapper integrates range geometry
with camera detections, merges co-located detections within a frame, and
associates repeated detections into persistent object instances across frames.
Objects remain in the map when they are out of view, and repeated sightings
update the same instance rather than creating duplicates. The output is a
compact object layer that can be queried (class, pose, and confidence), is
integrated with the occupancy map and readable by a planner. In on-robot tests,
the layer remained stable across viewpoint changes.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [29] [Multiplex Networks Provide Structural Pathways for Social Contagion in Rural Social Networks](https://arxiv.org/abs/2510.18280)
*Yongren Shi,Edo Airoldi,Nicholas A. Christakis*

Main category: cs.SI

TL;DR: 本文提出了一种新的网络扭矩指标，用于量化多层社交网络中不同关系层对关键传播路径的贡献，并通过实验验证了特定关系类型（如亲密友谊）在促进健康行为传播中的重要作用。


<details>
  <summary>Details</summary>
Motivation: 人类社交网络本质上是多层的，包含重叠的关系层。不同层可能具有不同的结构特性和人际动态，并可能相互作用形成复杂的相互依赖的社会传播路径。这给理解行为扩散和设计有效的基于网络的干预措施带来了根本性问题。

Method: 使用110个洪都拉斯农村社区的社交网络数据，包含11种名称生成器，并进行了外生干预实验。采用新的统计框架评估特定网络层如何改变全局连通性并支持三种实验引入的健康实践传播。

Result: 结果显示特定关系类型（如亲密友谊）特别能够实现非重叠的传播路径，在村庄层面放大了行为改变。例如，由最亲密朋友支持的非冗余路径可以增加对新生儿喂养不当知识的正确认知，并增强对父亲参与产后护理的态度。

Conclusion: 非重叠的多层社交联系在传统组织的社会系统中与社会传播和社会凝聚力相关，特定关系类型在促进健康行为传播中发挥着关键作用。

Abstract: Human social networks are inherently multiplex, comprising overlapping layers
of relationships. Different layers may have distinct structural properties and
interpersonal dynamics, but also may interact to form complex interdependent
pathways for social contagion. This poses a fundamental problem in
understanding behavioral diffusion and in devising effective network-based
interventions. Here, we introduce a new conceptualization of how much each
network layer contributes to critical contagion pathways and quantify it using
a novel metric, network torque. We exploit data regarding sociocentric maps of
110 rural Honduran communities using a battery of 11 name generators and an
experiment involving an exogenous intervention. Using a novel statistical
framework, we assess the extent to which specific network layers alter global
connectivity and support the spread of three experimentally introduced health
practices. The results show that specific relationship types - such as close
friendships - particularly enable non-overlapping diffusion pathways,
amplifying behavioral change at the village level. For instance, non-redundant
pathways enabled by closest friends can increase the adoption of correct
knowledge about feeding newborns inappropriate chupones and enhance attitudes
regarding fathers' involvement in postpartum care. Non-overlapping multiplex
social ties are relevant to social contagion and social coherence in
traditionally organized social systems.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [30] [Does GenAI Rewrite How We Write? An Empirical Study on Two-Million Preprints](https://arxiv.org/abs/2510.17882)
*Minfeng Qi,Zhongmin Cao,Qin Wang,Ningran Li,Tianqing Zhu*

Main category: cs.CY

TL;DR: 通过对210万篇预印本的分析发现，LLMs加速了提交和修订周期，略微增加了语言复杂性，不成比例地扩展了AI相关主题，计算密集型领域受益更多。LLMs更多是选择性催化剂而非普遍颠覆者。


<details>
  <summary>Details</summary>
Motivation: 预印本库已成为学术交流核心基础设施，LLMs可能改变论文写作方式，但系统性的实证证据有限，需要填补这一研究空白。

Method: 使用多级分析框架，整合中断时间序列模型、合作与生产力指标、语言分析和主题建模，分析2016-2025年四个主要预印本库的210万篇论文。

Result: LLMs加速了提交和修订周期，略微增加了语言复杂性，AI相关主题显著扩展，计算密集型领域受益更多。

Conclusion: LLMs更多是选择性催化剂而非普遍颠覆者，放大现有优势并扩大学科鸿沟，需要建立保护信任、公平和问责的治理框架。

Abstract: Preprint repositories become central infrastructures for scholarly
communication. Their expansion transforms how research is circulated and
evaluated before journal publication. Generative large language models (LLMs)
introduce a further potential disruption by altering how manuscripts are
written. While speculation abounds, systematic evidence of whether and how LLMs
reshape scientific publishing remains limited.
  This paper addresses the gap through a large-scale analysis of more than 2.1
million preprints spanning 2016--2025 (115 months) across four major
repositories (i.e., arXiv, bioRxiv, medRxiv, SocArXiv). We introduce a
multi-level analytical framework that integrates interrupted time-series
models, collaboration and productivity metrics, linguistic profiling, and topic
modeling to assess changes in volume, authorship, style, and disciplinary
orientation. Our findings reveal that LLMs have accelerated submission and
revision cycles, modestly increased linguistic complexity, and
disproportionately expanded AI-related topics, while computationally intensive
fields benefit more than others. These results show that LLMs act less as
universal disruptors than as selective catalysts, amplifying existing strengths
and widening disciplinary divides. By documenting these dynamics, the paper
provides the first empirical foundation for evaluating the influence of
generative AI on academic publishing and highlights the need for governance
frameworks that preserve trust, fairness, and accountability in an AI-enabled
research ecosystem.

</details>


### [31] [Are LLMs Court-Ready? Evaluating Frontier Models on Indian Legal Reasoning](https://arxiv.org/abs/2510.17900)
*Kush Juvekar,Arghya Bhattacharya,Sai Khadloya,Utkarsh Saxena*

Main category: cs.CY

TL;DR: 该研究创建了印度首个基于法律考试的LLM评估框架，使用印度公共法律考试作为基准，评估LLM在印度法律环境中的能力表现。


<details>
  <summary>Details</summary>
Motivation: 缺乏针对特定司法管辖区的LLM法律能力评估框架，需要建立印度本土化的评估标准来衡量LLM在法律工作流程中的适用性。

Method: 使用印度国家和州级法律考试的客观题目构建多年基准，在真实考试条件下评估开放和前沿LLM；同时进行律师评分的配对盲审研究，评估长篇答案质量。

Result: 前沿LLM系统能够通过历史分数线，在客观考试中达到或超过顶尖考生水平，但在长篇推理方面无人超越人类顶尖考生。评估发现三个可靠性问题：程序/格式合规性、引用规范、法庭适当表达和结构。

Conclusion: LLM可在法律检查、法规一致性、法规和判例查找方面提供帮助，但在法庭特定文件起草、程序和救济策略、权威与例外协调以及伦理判断等方面仍需人类主导。

Abstract: Large language models (LLMs) are entering legal workflows, yet we lack a
jurisdiction-specific framework to assess their baseline competence therein. We
use India's public legal examinations as a transparent proxy. Our multi-year
benchmark assembles objective screens from top national and state exams and
evaluates open and frontier LLMs under real-world exam conditions. To probe
beyond multiple-choice questions, we also include a lawyer-graded,
paired-blinded study of long-form answers from the Supreme Court's
Advocate-on-Record exam. This is, to our knowledge, the first exam-grounded,
India-specific yardstick for LLM court-readiness released with datasets and
protocols. Our work shows that while frontier systems consistently clear
historical cutoffs and often match or exceed recent top-scorer bands on
objective exams, none surpasses the human topper on long-form reasoning. Grader
notes converge on three reliability failure modes: procedural or format
compliance, authority or citation discipline, and forum-appropriate voice and
structure. These findings delineate where LLMs can assist (checks,
cross-statute consistency, statute and precedent lookups) and where human
leadership remains essential: forum-specific drafting and filing, procedural
and relief strategy, reconciling authorities and exceptions, and ethical,
accountable judgment.

</details>


### [32] [Interpretability Framework for LLMs in Undergraduate Calculus](https://arxiv.org/abs/2510.17910)
*Sagnik Dakshit,Sushmita Sinha Roy*

Main category: cs.CY

TL;DR: 提出了一个用于分析LLM在数学教育中推理过程的解释性框架，通过微积分问题评估模型解决方案的质量、可靠性和教学有效性。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法主要关注最终答案准确性，忽视了推理过程的质量。LLM在数学教育中的应用需要评估其解决方案的可靠性、教学有效性和概念清晰度。

Method: 结合推理流程提取、语义标记操作分解和提示消融分析，使用推理复杂性、短语敏感性和鲁棒性等结构化指标，在真实大学微积分考试上评估模型行为。

Result: 发现LLM经常生成语法流畅但概念有缺陷的解决方案，推理模式对提示措辞和输入变化敏感。

Conclusion: 该框架能够对推理失败进行细粒度诊断，支持课程对齐，并为可解释AI辅助反馈工具的设计提供信息，为AI在STEM学习环境中的透明和负责任部署奠定基础。

Abstract: Large Language Models (LLMs) are increasingly being used in education, yet
their correctness alone does not capture the quality, reliability, or
pedagogical validity of their problem-solving behavior, especially in
mathematics, where multistep logic, symbolic reasoning, and conceptual clarity
are critical. Conventional evaluation methods largely focus on final answer
accuracy and overlook the reasoning process. To address this gap, we introduce
a novel interpretability framework for analyzing LLM-generated solutions using
undergraduate calculus problems as a representative domain. Our approach
combines reasoning flow extraction and decomposing solutions into semantically
labeled operations and concepts with prompt ablation analysis to assess input
salience and output stability. Using structured metrics such as reasoning
complexity, phrase sensitivity, and robustness, we evaluated the model behavior
on real Calculus I to III university exams. Our findings revealed that LLMs
often produce syntactically fluent yet conceptually flawed solutions, with
reasoning patterns sensitive to prompt phrasing and input variation. This
framework enables fine-grained diagnosis of reasoning failures, supports
curriculum alignment, and informs the design of interpretable AI-assisted
feedback tools. This is the first study to offer a structured, quantitative,
and pedagogically grounded framework for interpreting LLM reasoning in
mathematics education, laying the foundation for the transparent and
responsible deployment of AI in STEM learning environments.

</details>


### [33] [MoveOD: Synthesizing Origin-Destination Commute Distribution from U.S. Census Data](https://arxiv.org/abs/2510.18858)
*Rishav Sen,Abhishek Dubey,Ayan Mukhopadhyay,Samitha Samaranayake,Aron Laszka*

Main category: cs.CY

TL;DR: MOVEOD是一个开源管道，通过整合五种公共数据源，为美国任何县生成高分辨率的通勤起点-终点(OD)流量数据，包含精细的空间和时间维度。


<details>
  <summary>Details</summary>
Motivation: 高分辨率OD表对交通应用至关重要，但除少数数据丰富的城市外，这类数据很少可用。需要一种方法为美国各地生成准确的通勤OD数据。

Method: 结合ACS出发时间和旅行时间分布、LODES居住地-工作地流量、县几何形状、OpenStreetMap道路网络信息以及OSM和微软的建筑足迹，使用约束采样和整数规划方法协调数据集。

Result: 在田纳西州汉密尔顿县演示了该框架，在几分钟内生成约15万条合成行程，并用于基准测试经典和基于学习的车辆路径算法。

Conclusion: MOVEOD是一个端到端的自动化系统，用户只需提供县和年份即可在美国各地轻松应用，并可适应具有类似人口普查数据集的其他国家。

Abstract: High-resolution origin-destination (OD) tables are essential for a wide
spectrum of transportation applications, from modeling traffic and signal
timing optimization to congestion pricing and vehicle routing. However, outside
a handful of data rich cities, such data is rarely available. We introduce
MOVEOD, an open-source pipeline that synthesizes public data into commuter OD
flows with fine-grained spatial and temporal departure times for any county in
the United States. MOVEOD combines five open data sources: American Community
Survey (ACS) departure time and travel time distributions, Longitudinal
Employer-Household Dynamics (LODES) residence-to-workplace flows, county
geometries, road network information from OpenStreetMap (OSM), and building
footprints from OSM and Microsoft, into a single OD dataset. We use a
constrained sampling and integer-programming method to reconcile the OD dataset
with data from ACS and LODES. Our approach involves: (1) matching commuter
totals per origin zone, (2) aligning workplace destinations with employment
distributions, and (3) calibrating travel durations to ACS-reported commute
times. This ensures the OD data accurately reflects commuting patterns. We
demonstrate the framework on Hamilton County, Tennessee, where we generate
roughly 150,000 synthetic trips in minutes, which we feed into a benchmark
suite of classical and learning-based vehicle-routing algorithms. The MOVEOD
pipeline is an end-to-end automated system, enabling users to easily apply it
across the United States by giving only a county and a year; and it can be
adapted to other countries with comparable census datasets. The source code and
a lightweight browser interface are publicly available.

</details>


### [34] [Attracting Commercial Artificial Intelligence Firms to Support National Security through Collaborative Contracts](https://arxiv.org/abs/2510.17931)
*Andrew Bowne*

Main category: cs.CY

TL;DR: 商业AI公司对国防部作为客户感兴趣，但传统合同法律和采购框架是主要障碍。研究提出最优买家理论来解释商业决策因素，并建议利用其他交易授权等现有合同法律来匹配商业偏好和机器学习生命周期。


<details>
  <summary>Details</summary>
Motivation: 了解商业AI公司决定与国防部合作或回避国防市场的原因，特别是合同法律和采购框架作为主要障碍的影响。

Method: 基于社会交换理论提出最优买家理论框架，通过对参与者的访谈来解释AI行业对合同和国防部作为客户的看法、意见和偏好。

Result: 研究发现商业AI公司实际上将国防部视为有吸引力的客户，但这种吸引力受到传统合同法律和采购实践的阻碍。公司更倾向于与其业务和技术考虑一致的合同。

Conclusion: 商业AI公司被与其业务和技术考虑一致的合同所吸引。研究开发了利用现有合同法律（主要是其他交易授权）的最佳实践，以使合同实践与商业偏好和机器学习开发部署生命周期保持一致。

Abstract: Unlike other military technologies driven by national security needs and
developed with federal funding, AI is predominantly funded and advanced by
commercial industry for civilian applications. However, there is a lack of
understanding of the reasons commercial AI firms decide to work with the DoD or
choose to abstain from the defence market. This thesis argues that the contract
law and procurement framework are among the most significant obstacles. This
research indicates that the commercial AI industry actually views the DoD as an
attractive customer. However, this attraction is despite the obstacles
presented by traditional contract law and procurement practices used to solicit
and award contracts. Drawing on social exchange theory, this thesis introduces
a theoretical framework, optimal buyer theory, to understand the factors that
influence a commercial decision to engage with the DoD. Interviews from a
sample of the participants explain why the AI industry holds such perceptions,
opinions, and preferences about contracts generally and the DoD, specifically,
in its role as a customer. This thesis concludes that commercial AI firms are
attracted to contracts that are consistent with their business and technology
considerations. Additionally, it develops best practices for leveraging
existing contract law, primarily other transaction authority, to align
contracting practices with commercial preferences and the machine learning
development and deployment lifecycle.

</details>


### [35] [The Integration of Artificial Intelligence in Undergraduate Medical Education in Spain: Descriptive Analysis and International Perspectives](https://arxiv.org/abs/2510.17938)
*Ana Enériz Janeiro,Karina Pitombeira Pereira,Julio Mayol,Javier Crespo,Fernando Carballo,Juan B. Cabello,Manel Ramos-Casals,Bibiana Pérez Corbacho,Juan Turnes*

Main category: cs.CY

TL;DR: 西班牙医学学位中AI整合程度研究：52所大学中仅19.2%提供AI课程，69.2%无相关内容，课程多为选修且学分占比低（平均1.17%），存在明显地域差异。


<details>
  <summary>Details</summary>
Motivation: 评估西班牙医学课程中AI整合现状，尽管有国际建议，但此前缺乏系统性评估，以了解未来医疗专业人员的AI能力培养情况。

Method: 横断面研究（2025年7-9月），分析西班牙官方医学学位大学的课程和机构文件，使用描述性统计识别2025-2026学年AI相关课程和能力。

Result: 52所大学中10所（19.2%）提供AI课程，36所（69.2%）无相关内容；课程多为选修（3-6学分），仅哈恩大学有必修课；安达卢西亚领先（55.5%），部分地区无AI培训。

Conclusion: 西班牙医学学位AI整合处于起步阶段，零散且不均衡，学分权重低；有限的培训量和选修课主导限制了未来医生在AI日益普及的医疗环境中的准备；建议建立最低标准和全国监测指标。

Abstract: AI is transforming medical practice and redefining the competencies that
future healthcare professionals need to master. Despite international
recommendations, the integration of AI into Medicine curricula in Spain had not
been systematically evaluated until now. A cross-sectional study
(July-September 2025) including Spanish universities offering the official
degree in Medicine, according to the 'Register of Universities, Centers and
Degrees (Registro de Universidades, Centros y T\'itulos RUCT)'. Curricula and
publicly available institutional documentation were reviewed to identify
courses and competencies related to AI in the 2025-2026 academic year. The
analysis was performed using descriptive statistics. Of the 52 universities
analyzed, ten (19.2%) offer specific AI courses, whereas 36 (69.2%) include no
related content. Most of the identified courses are elective, with a credit
load ranging from three to six ECTS, representing on average 1.17% of the total
360 credits of the degree. The University of Ja\'en is the only institution
offering a compulsory course with AI content. The territorial analysis reveals
marked disparities: Andalusia leads with 55.5% of its universities
incorporating AI training, while several communities lack any initiative in
this area. The integration of AI into the medical degree in Spain is incipient,
fragmented, and uneven, with a low weight in ECTS. The limited training load
and predominance of elective courses restrict the preparation of future
physicians to practice in a healthcare environment increasingly mediated by AI.
The findings support the establishment of minimum standards and national
monitoring of indicators.

</details>


### [36] [Trust in foundation models and GenAI: A geographic perspective](https://arxiv.org/abs/2510.17942)
*Grant McKenzie,Krzysztof Janowicz,Carsten Kessler*

Main category: cs.CY

TL;DR: 该论文探讨了地理AI中信任的概念，将信任分为三种类型：训练数据的认知信任、模型功能的操作信任和模型开发者的人际信任，并讨论了地理应用中的挑战和解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着大规模预训练模型在地理领域的应用日益广泛，特别是在关键决策中的依赖增加，信任成为一个重要但复杂的概念，需要在地理背景下进行深入分析。

Method: 通过概念分析框架，将信任分类为三种类型，并探讨每种信任类型在地理应用中的具体含义和挑战。

Result: 提出了地理AI中信任的三维分类框架，识别了文化背景、数据异质性和空间关系等地理特定因素对信任的影响，以及偏见、透明度和伦理责任等挑战。

Conclusion: 强调需要进一步透明度、偏见缓解和区域知情政策，为研究人员、从业者和政策制定者提供了理解生成式地理AI中信任的概念起点。

Abstract: Large-scale pre-trained machine learning models have reshaped our
understanding of artificial intelligence across numerous domains, including our
own field of geography. As with any new technology, trust has taken on an
important role in this discussion. In this chapter, we examine the multifaceted
concept of trust in foundation models, particularly within a geographic
context. As reliance on these models increases and they become relied upon for
critical decision-making, trust, while essential, has become a fractured
concept. Here we categorize trust into three types: epistemic trust in the
training data, operational trust in the model's functionality, and
interpersonal trust in the model developers. Each type of trust brings with it
unique implications for geographic applications. Topics such as cultural
context, data heterogeneity, and spatial relationships are fundamental to the
spatial sciences and play an important role in developing trust. The chapter
continues with a discussion of the challenges posed by different forms of
biases, the importance of transparency and explainability, and ethical
responsibilities in model development. Finally, the novel perspective of
geographic information scientists is emphasized with a call for further
transparency, bias mitigation, and regionally-informed policies. Simply put,
this chapter aims to provide a conceptual starting point for researchers,
practitioners, and policy-makers to better understand trust in (generative)
GeoAI.

</details>


### [37] [Integrating Generative AI into LMS: Reshaping Learning and Instructional Design](https://arxiv.org/abs/2510.18026)
*Xinran Zhu,Liam Magee,Peg Mischler*

Main category: cs.CY

TL;DR: 论文主张学习管理系统应从静态内容库转变为动态生态系统，通过生成式AI培养高阶思维和有意义的人机互动。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI重塑专业实践，教育需要重新思考如何培养学生适应人机共同构建知识的未来，而学习管理系统作为教育实践核心必须进化。

Method: 提出两个指导原则：从内容传递转向培养高阶思维，以及实现与AI的有意义互动；通过CheckIT Learning案例研究展示这些原则的实践应用。

Result: 展示了如何将生成式AI整合到学习管理系统中，支持探究、协作和反思性知识构建，培养批判性、有意图和社会中介的AI互动。

Conclusion: 在AI驱动的世界中需要教育技术合作伙伴关系，负责任的教育AI整合需要研究人员、教育工作者和技术专家之间的持续合作，确保伦理、教学基础和认知知情的创新。

Abstract: Education in the era of generative AI faces a pivotal transformation. As AI
systems reshape professional practices-from software development to creative
design-educators must reconsider how to prepare students for a future where
humans and machines co-construct knowledge. While tools like ChatGPT and Claude
automate tasks and personalize learning, their educational potential depends on
how meaningfully they are integrated into learning environments. This paper
argues that Learning Management Systems (LMSs), as the core of educational
practice, must evolve from static content repositories into dynamic ecosystems
that cultivate higher-order thinking and meaningful human-AI interaction. We
propose two guiding principles for integrating generative AI into LMSs. First,
From Content Delivery to Fostering Higher-Order Thinking, emphasizing AI's role
in supporting inquiry, collaboration, and reflective knowledge building.
Second, Toward Meaningful Interaction with AI, highlighting the design of
learning environments that nurture critical, intentional, and socially mediated
engagement with AI. Drawing on a case study of CheckIT Learning, we illustrate
how these principles can translate into practice. We conclude with the need for
Edtech partnerships in an AI-powered world, underscoring that responsible AI
integration in education requires sustained collaboration among researchers,
educators, and technologists to ensure ethical, pedagogically grounded, and
cognitively informed innovation.

</details>


### [38] [Prompt-to-Primal Teaching](https://arxiv.org/abs/2510.18050)
*Euzeli dos Santos*

Main category: cs.CY

TL;DR: P2P教学法将AI提示驱动探索与第一性原理推理结合，教师引导学生在课堂中验证、挑战和重构AI回答，提升AI素养和工程推理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型对有基础知识的学生很有效，但可能误导缺乏背景知识的学生，需要一种教学方法来平衡AI工具的使用与基础知识的建立。

Method: P2P教学法：学生生成AI提示作为课堂探究起点，教师引导学生通过物理和数学基本定律验证、挑战和重构AI回答。

Result: 两个学期不同学生群体的结果表明，P2P教学框架在提升AI素养和工程推理方面具有教学有效性。

Conclusion: P2P教学法通过结合AI工具与第一性原理推理，促进了自我反思发展、AI输出的批判性评估以及核心工程原理的概念基础知识的建立。

Abstract: This paper introduces Prompt-to-Primal (P2P) Teaching, an AI-integrated
instructional approach that links prompt-driven exploration with
first-principles reasoning, guided and moderated by the instructor within the
classroom setting. In P2P teaching, student-generated AI prompts serve as entry
points for inquiry and initial discussions in class, while the instructor
guides learners to validate, challenge, and reconstruct AI responses through
fundamental physical and mathematical laws. The approach encourages
self-reflective development, critical evaluation of AI outputs, and conceptual
foundational knowledge of the core engineering principles. A large language
model (LLM) can be a highly effective tool for those who already possess
foundational knowledge of a subject; however, it may also mislead students who
lack sufficient background in the subject matter. Results from two student
cohorts across different semesters suggest the pedagogical effectiveness of the
P2P teaching framework in enhancing both AI literacy and engineering reasoning.

</details>


### [39] [The Cost-Benefit of Interdisciplinarity in AI for Mental Health](https://arxiv.org/abs/2510.18581)
*Katerina Drakos,Eva Paraschou,Simay Toplu,Line Harder Clemmensen,Christoph Lütge,Nicole Nadine Lønfeldt,Sneha Das*

Main category: cs.CY

TL;DR: 本文探讨了AI心理健康聊天机器人中跨学科合作的成本效益权衡，强调需要整合技术、医疗、伦理和法律专家来确保价值对齐并符合AI法案的高风险要求。


<details>
  <summary>Details</summary>
Motivation: 当前大多数AI心理健康聊天机器人依赖有限的学科输入，未能整合整个生命周期的专业知识，这影响了其效果和合规性。

Method: 通过分析跨学科合作在AI心理健康聊天机器人生命周期各阶段的重要性，提出实践建议和现有框架来平衡挑战与收益。

Result: 研究发现，在技术、医疗、伦理和法律等领域专家的全面参与对确保AI心理健康聊天机器人的价值对齐和合规性至关重要。

Conclusion: 跨学科合作是开发有效且合规的AI心理健康聊天机器人的关键，需要平衡其挑战与收益，并利用现有框架指导实践。

Abstract: Artificial intelligence has been introduced as a way to improve access to
mental health support. However, most AI mental health chatbots rely on a
limited range of disciplinary input, and fail to integrate expertise across the
chatbot's lifecycle. This paper examines the cost-benefit trade-off of
interdisciplinary collaboration in AI mental health chatbots. We argue that
involving experts from technology, healthcare, ethics, and law across key
lifecycle phases is essential to ensure value-alignment and compliance with the
high-risk requirements of the AI Act. We also highlight practical
recommendations and existing frameworks to help balance the challenges and
benefits of interdisciplinarity in mental health chatbots.

</details>


### [40] [Integrating Large Language Models and Evaluating Student Outcomes in an Introductory Computer Science Course](https://arxiv.org/abs/2510.18806)
*Annapurna Vadaparty,David H. Smith IV,Samvrit Srinath,Mounika Padala,Christine Alvarado,Jamie Gorson Benario,Daniel Zingaro,Leo Porter*

Main category: cs.CY

TL;DR: 该论文设计并评估了一个将大语言模型(LLM)作为学习工具整合到CS1课程中的新教学模式，发现学生考试成绩与传统课程相似，开放式项目在LLM环境下特别有价值，学生普遍认为LLM工具有帮助但担心过度依赖。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型特别是针对编码调优的LLM在传统CS1课程作业中表现出色，这要求CS1课程必须改变教学内容和评估方式，需要研究LLM工具如何影响学生的学习成果。

Method: 在一所大型研究型大学设计并实施新的CS1-LLM课程，采用LLM作为学生学习工具，通过评估分数和问卷调查来评价学生成果和感知。

Result: 1) 学生考试成绩结果(包括不同人口统计群体间的差异)与传统无LLM整合课程基本相似；2) 大型开放式项目在LLM环境下特别有价值；3) 学生普遍认为LLM工具有帮助，但部分学生担心过度依赖工具。

Conclusion: LLM可以成功整合到CS1课程中作为学习工具，不会显著影响学生考试成绩，开放式项目在这种环境下效果更好，但需要注意学生对工具过度依赖的担忧。

Abstract: Generative AI (GenAI) models have broad implications for education in
general, impacting the foundations of what we teach and how we assess. This is
especially true in computing, where LLMs tuned for coding have demonstrated
shockingly good performance on the types of assignments historically used in
introductory CS (CS1) courses. As a result, CS1 courses will need to change
what skills are taught and how they are assessed. Computing education
researchers have begun to study student use of LLMs, but there remains much to
be understood about the ways that these tools affect student outcomes. In this
paper, we present the design and evaluation of a new CS1 course at a large
research-intensive university that integrates the use of LLMs as a learning
tool for students. We describe the design principles used to create our new
CS1-LLM course, our new course objectives, and evaluation of student outcomes
and perceptions throughout the course as measured by assessment scores and
surveys. Our findings suggest that 1) student exam performance outcomes,
including differences among demographic groups, are largely similar to
historical outcomes for courses without integration of LLM tools, 2) large,
open-ended projects may be particularly valuable in an LLM context, and 3)
students predominantly found the LLM tools helpful, although some had concerns
regarding over-reliance on the tools.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [41] [LLM Assisted Alpha Fairness for 6 GHz WiFi and NR_U Coexistence: An Agentic Orchestrator for Throughput, Energy, and SLA](https://arxiv.org/abs/2510.17814)
*Qun Wang,Yingzhou Lu,Guiran Liu,Binrong Zhu,Yang Liu*

Main category: eess.SY

TL;DR: 提出了一种基于LLM的智能控制器，用于6GHz频段Wi-Fi和5G NR-U的共存管理，通过分离策略制定和执行，在保证安全性的同时提升能效。


<details>
  <summary>Details</summary>
Motivation: 解决6GHz免授权频段中Wi-Fi和5G NR-U在LBT规则下的共存问题，需要平衡吞吐量、能耗和服务质量，同时确保系统安全和可审计。

Method: 设计了一个代理控制器，在每个调度周期开始时收集遥测数据，使用LLM生成可解释的控制参数（公平性指数、信道占空比限制等），然后通过确定性优化器计算可行的α-公平分配。

Result: 在6GHz仿真环境中，LLM辅助策略显著提升了能效，一个LLM模型在适度吞吐量损失下降低了35.3%的总能耗，另一个模型实现了最佳综合权衡，吞吐量提升3.5%，能效提升12.2%。

Conclusion: 研究表明，透明、策略级的LLM指导可以安全地改进无线共存性能，为6GHz频段的多技术共存提供了有效的解决方案。

Abstract: Unlicensed 6GHz is becoming a primary workhorse for high-capacity access,
with Wi-Fi and 5G NR-U competing for the same channels under listen-before-talk
(LBT) rules. Operating in this regime requires decisions that jointly trade
throughput, energy, and service-level objectives while remaining safe and
auditable. We present an agentic controller that separates {policy} from
{execution}. At the start of each scheduling epoch the agent summarizes
telemetry (per-channel busy and baseline LBT failure; per-user CQI, backlog,
latency, battery, priority, and power mode) and invokes a large language model
(LLM) to propose a small set of interpretable knobs: a fairness index \alpha,
per-channel duty-cycle caps for Wi-Fi/NR-U, and class weights. A deterministic
optimizer then enforces feasibility and computes an \alpha-fair allocation that
internalizes LBT losses and energy cost; malformed or unsafe policies are
clamped and fall back to a rule baseline. In a 6GHz simulator with two 160MHz
channels and mixed Wi-Fi/NR-U users, LLM-assisted policies consistently improve
energy efficiency while keeping throughput competitive with a strong rule
baseline. One LLM lowers total energy by 35.3% at modest throughput loss, and
another attains the best overall trade-off, finishing with higher total bits
(+3.5%) and higher bits/J (+12.2%) than the baseline. We release code,
per-epoch logs, and plotting utilities to reproduce all figures and numbers,
illustrating how transparent, policy-level LLM guidance can safely improve
wireless coexistence.

</details>


### [42] [Towards the True Switching-ON of Transistors](https://arxiv.org/abs/2510.17815)
*Wucheng Ying,Jinwei Qi,Hui Zhao,Ameer Janabi,Hui Li,Biao Zhao,Teng Long*

Main category: eess.SY

TL;DR: 提出统一的第一性原理范式解释晶体管开关现象，显著改进开关能量损耗预测模型精度


<details>
  <summary>Details</summary>
Motivation: 晶体管开关行为影响能源损耗、碳排放等关键指标，但现有理解碎片化，无法用物理定律解释，阻碍可持续解决方案发展

Method: 建立统一的第一性原理范式，揭示开关现象的物理起源和机制

Result: 提出的Eon预测模型误差从34.41-80.05%降至0.88-11.60%，平均提升17倍精度

Conclusion: 建立了教科书级的基础理论，将晶体管开关理解从经验性转变为第一性原理分析，推动跨学科可持续发展研究

Abstract: Transistors are core component across all domains of electrical and
electronic engineering (EEE), such as data centers, electrified transportation,
robotics, renewables and grid applications, etc. Transistors' switching
behavior governs energy loss, carbon emissions, cooling demand, water use,
lifetime, material use and cost etc. throughout EEE. Despite near a century
since the transistor's invention, the understanding of transistor switching
remains fragmented: switching is treated as a black box relying on observed
waveforms, cannot be explained using physical laws alone, and is not integrated
into circuit theory. This forms one of the most critical barriers to
recognizing the true physical boundaries, prohibiting more sustainable
solutions. For example, the conventional Eon prediction model, derived from the
conventional switching analysis, exhibits significant prediction errors
(ranging from 34.41% to 80.05%). Here we present a unified first-principles
paradigm to explain the switching phenomena. Using this paradigm, we revealed
the physical origins and mechanisms of switching-ON phenomena across scenarios,
and derived the proposed Eon prediction model, with error ranging from 0.88% to
11.60%, achieving a 17-fold average improvement. These results demonstrate the
unprecedented power of the proposed paradigm: textbook-level foundations are
established, transforming the fundamental understanding of transistor switching
from empirical to first-principles analysis, and simultaneously stimulating
follow-up research and applications for sustainable development across
disciplines.

</details>


### [43] [Introducing Coherent-Control Koopman to Reservoir Scale Porous Media Flow Studies](https://arxiv.org/abs/2510.17857)
*Dimitrios Voulanas,Eduardo Gildin*

Main category: eess.SY

TL;DR: CCKM在具有控制策略突变的复杂预测场景中，比DMDc和Hybrid B-only方法表现更稳定和准确，特别是在分布外和分布内控制变化情况下。


<details>
  <summary>Details</summary>
Motivation: 为大规模地下系统（如地质CO2封存和水驱管理）的实时控制和优化开发准确稳健的代理模型。

Method: 比较CCKM与DMDc和Hybrid B-only方法在两种代表性场景下的性能：(i)分布外的关井和重启案例，(ii)分布内的井底压力降压案例。

Result: 只有CCKM在两种场景下都保持稳定性和准确性，达到亚巴平均绝对误差和亚百分比Frobenius范数百分比变化误差，而DMDc在控制瞬变期间出现大的非物理误差。

Conclusion: 严格的控制一致性对于可靠的代理建模至关重要，特别是在控制策略突然变化的情况下。CCKM框架可广泛应用于实时储层优化，并集成到现有优化和监测工作流中。

Abstract: Accurate and robust surrogate modeling is essential for the real time control
and optimization of large-scale subsurface systems, such as geological CO2
storage and waterflood management. This study investigates the limits of
classical Dynamic Mode Decomposition with control (DMDc) in replicating
pressure and water saturation dynamics under challenging prediction scenarios.
We benchmark CCKM against DMDc and a Hybrid B-only surrogate that reuses DMDcs
bottom B (same step feed through), showing that only CCKM remains stable and
accurate under regime shifts. Two representative cases are considered: (i) an
out of distribution shut in and restart case, and (ii) an in distribution
bottom hole pressure (BHP) drawdown. Results show that only CCKM consistently
maintains stability and accuracy across both scenarios, achieving sub bar mean
absolute error and sub percent Frobenius norm percent change error even under
regime shifts, while DMDc exhibit large unphysical errors during control
transients. The findings demonstrate that strict control coherence is critical
for reliable surrogate modeling, particularly in settings with abrupt changes
in control strategy. The proposed framework is broadly applicable to real time
reservoir optimization and can be integrated seamlessly into existing
optimization and monitoring workflows, enabling fast and trustworthy decision
support in the presence of both expected and unexpected actuation regimes.

</details>


### [44] [Mixed Monotonicity Reachability Analysis of Neural ODE: A Trade-Off Between Tightness and Efficiency](https://arxiv.org/abs/2510.17859)
*Abdelrahman Sayed Sayed,Pierre-Jean Meyer,Mohamed Ghazel*

Main category: eess.SY

TL;DR: 提出了一种基于区间和混合单调性的神经ODE可达性分析方法，通过将神经ODE嵌入混合单调系统，提供高效但保守的过近似可达集计算。


<details>
  <summary>Details</summary>
Motivation: 神经ODE是强大的连续时间机器学习模型，但由于缺乏适配的可达性分析工具，其验证仍然具有挑战性。

Method: 利用连续时间混合单调性技术，通过同胚性质利用初始集及其边界的几何结构，实现高效边界传播。在TIRA中实现了单步、增量和基于边界的方法。

Result: 与CORA的zonotopes和NNV2.0星集表示相比，该方法提供了可靠且计算高效的过近似，在紧密度和效率之间取得平衡。

Conclusion: 将混合单调性应用于神经ODE可达性分析为轻量级形式分析开辟了新途径，特别适合高维、实时和安全关键应用。

Abstract: Neural ordinary differential equations (neural ODE) are powerful
continuous-time machine learning models for depicting the behavior of complex
dynamical systems, but their verification remains challenging due to limited
reachability analysis tools adapted to them. We propose a novel interval-based
reachability method that leverages continuous-time mixed monotonicity
techniques for dynamical systems to compute an over-approximation for the
neural ODE reachable sets. By exploiting the geometric structure of full
initial sets and their boundaries via the homeomorphism property, our approach
ensures efficient bound propagation. By embedding neural ODE dynamics into a
mixed monotone system, our interval-based reachability approach, implemented in
TIRA with single-step, incremental, and boundary-based approaches, provides
sound and computationally efficient over-approximations compared with CORA's
zonotopes and NNV2.0 star set representations, while trading tightness for
efficiency. This trade-off makes our method particularly suited for
high-dimensional, real-time, and safety-critical applications. Applying mixed
monotonicity to neural ODE reachability analysis paves the way for lightweight
formal analysis by leveraging the symmetric structure of monotone embeddings
and the geometric simplicity of interval boxes, opening new avenues for
scalable verification aligned with the symmetry and geometry of neural
representations. This novel approach is illustrated on two numerical examples
of a spiral system and a fixed-point attractor system modeled as a neural ODE.

</details>


### [45] [DMTrack: Deformable State-Space Modeling for UAV Multi-Object Tracking with Kalman Fusion and Uncertainty-Aware Association](https://arxiv.org/abs/2510.17860)
*Zenghuang Fu,Xiaofeng Han,Mingda Jia,Jin ming Yang,Qi Zeng,Muyang Zahng,Changwei Wang,Weiliang Meng,Xiaopeng Zhang*

Main category: eess.SY

TL;DR: DMTrack是一个针对无人机多目标跟踪的变形运动跟踪框架，通过DeformMamba动态聚合历史运动状态、MotionGate融合卡尔曼和Mamba预测、以及不确定性感知关联策略，在高速和非线性运动场景下实现最先进的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 无人机多目标跟踪面临物体运动不可预测、频繁遮挡和外观线索有限等挑战，传统运动模型难以捕捉线性和非线性动态，导致轨迹估计不可靠和身份切换问题。

Method: 提出DMTrack框架，包含三个关键组件：DeformMamba（变形状态空间预测器）、MotionGate（轻量级门控模块）和不确定性感知关联策略，无需外观模型。

Result: 在VisDrone-MOT和UAVDT基准测试中，DMTrack在身份一致性和跟踪精度方面达到最先进性能，特别是在高速和非线性运动场景下表现优异。

Conclusion: 该方法无需外观模型，保持竞争性效率，突显了其在鲁棒无人机跟踪中的实用性。

Abstract: Multi-object tracking (MOT) from unmanned aerial vehicles (UAVs) presents
unique challenges due to unpredictable object motion, frequent occlusions, and
limited appearance cues inherent to aerial viewpoints. These issues are further
exacerbated by abrupt UAV movements, leading to unreliable trajectory
estimation and identity switches. Conventional motion models, such as Kalman
filters or static sequence encoders, often fall short in capturing both linear
and non-linear dynamics under such conditions. To tackle these limitations, we
propose DMTrack, a deformable motion tracking framework tailored for UAV-based
MOT. Our DMTrack introduces three key components: DeformMamba, a deformable
state-space predictor that dynamically aggregates historical motion states for
adaptive trajectory modeling; MotionGate, a lightweight gating module that
fuses Kalman and Mamba predictions based on motion context and uncertainty; and
an uncertainty-aware association strategy that enhances identity preservation
by aligning motion trends with prediction confidence. Extensive experiments on
the VisDrone-MOT and UAVDT benchmarks demonstrate that our DMTrack achieves
state-of-the-art performance in identity consistency and tracking accuracy,
particularly under high-speed and non-linear motion. Importantly, our method
operates without appearance models and maintains competitive efficiency,
highlighting its practicality for robust UAV-based tracking.

</details>


### [46] [Quantum-Driven State-Reduction for Reliable UAV Trajectory Optimization in Low-Altitude Networks](https://arxiv.org/abs/2510.17861)
*Zeeshan Kaleem,Muhammad Afaq,Chau Yuen,Octavia A. Dobre,John M. Cioffi*

Main category: eess.SY

TL;DR: 提出了一种基于图压缩量子启发式布局的框架，用于无人机辅助低空无线网络中的可靠性驱动轨迹优化，通过量子退火压缩路点图，使用Q学习解决马尔可夫决策过程，实现稳定收敛和低中断率。


<details>
  <summary>Details</summary>
Motivation: 解决无人机辅助低空无线网络中轨迹优化的复杂性问题，需要在保持链路质量的同时减少控制状态空间，并考虑无人机运动学和飞行走廊约束。

Method: 使用概率量子退火压缩密集路点图，保留干扰感知的质心；将问题建模为优先级感知的马尔可夫决策过程，采用epsilon-greedy离策略Q学习进行求解。

Result: 与基线方案相比，GC-QAP实现了稳定收敛和低中断率，同时显著降低了计算成本。

Conclusion: GC-QAP框架为无人机轨迹优化提供了一种高效可靠的解决方案，避免了复杂连续动作强化学习方法的高计算成本问题。

Abstract: This letter introduces a Graph-Condensed Quantum-Inspired Placement (GC-QAP)
framework for reliability-driven trajectory optimization in Uncrewed Aerial
Vehicle (UAV) assisted low-altitude wireless networks. The dense waypoint graph
is condensed using probabilistic quantum-annealing to preserve
interference-aware centroids while reducing the control state space and
maintaining link-quality. The resulting problem is formulated as a
priority-aware Markov decision process and solved using epsilon-greedy
off-policy Q-learning, considering UAV kinematic and flight corridor
constraints. Unlike complex continuous-action reinforcement learning
approaches, GC-QAP achieves stable convergence and low outage with
substantially and lower computational cost compared to baseline schemes.

</details>


### [47] [Epistemology-Inspired Bayesian Games for Distributed IoT Uplink Power Control](https://arxiv.org/abs/2510.17870)
*Nirmal D. Wickramasinghe,John Dooley,Dirk Pesch,Indrakshi Dey*

Main category: eess.SY

TL;DR: 提出了一种基于认知贝叶斯博弈的轻量级分布式上行链路功率控制方法，用于解决密集物联网网络中CSI不完整和干扰严重的问题。


<details>
  <summary>Details</summary>
Motivation: 大量物联网设备同时上行传输给网关带来严重干扰和能耗问题，但设备缺乏邻居CSI信息且无法支持集中式MEC或复杂ML协调，需要轻量级分布式控制方案。

Method: 采用认知贝叶斯博弈框架，节点运行认知信念更新来估计对手策略，使用指数-伽马SINR模型和高阶效用矩（方差、偏度、峰度），计算复杂度为O(N²S²N)。

Result: 在SINR阈值为-18dB时，覆盖率达到约60%且仅需约55%最大发射功率；在-27dB阈值下，中速率设备实现全覆盖且仅需小于0.1%最大功率；在80%干扰下，四阶矩策略将平均功率从52%降至20%。

Conclusion: 该方法为密集分布式物联网网络在现实不确定性条件下提供了一条计算轻量、原理清晰的路径，实现最优功率分配和更高网络覆盖。

Abstract: Massive number of simultaneous Internet of Things (IoT) uplinks strain
gateways with interference and energy limits, yet devices often lack neighbors'
Channel State Information (CSI) and cannot sustain centralized Mobile Edge
Computing (MEC) or heavy Machine Learning (ML) coordination. Classical Bayesian
solvers help with uncertainty but become intractable as users and strategies
grow, making lightweight, distributed control essential. In this paper, we
introduce the first-ever, novel epistemic Bayesian game for uplink power
control under incomplete CSI that operates while suppressing interference among
multiple uplink channels from distributed IoT devices firing at the same time.
Nodes run inter-/intra-epistemic belief updates over opponents' strategies,
replacing exhaustive expected-utility tables with conditional belief
hierarchies. Using an exponential-Gamma SINR model and higher-order utility
moments (variance, skewness, kurtosis), the scheme remains computationally lean
with a single-round upper bound of $O\!\left(N^{2} S^{2N}\right)$. Precise
power control and stronger coverage amid realistic interference: with channel
magnitude equal to $1$ and a signal-to-interference-plus-noise ratio (SINR)
threshold of $-18$ dB, coverage reaches approximately $60\%$ at approximately
$55\%$ of the maximum transmit power; mid-rate devices with a threshold of
$-27$ dB achieve full coverage with less than $0.1\%$ of the maximum transmit
power.Under $80\%$ interference, a fourth-moment policy cuts average power from
approximately $52\%$ to approximately $20\%$ of the maximum transmit power with
comparable outage, outperforming expectation-only baselines. These results
highlight a principled, computationally lean path to optimal power allocation
and higher network coverage under real-world uncertainty within dense,
distributed IoT networks.

</details>


### [48] [DRL-Based Resource Allocation for Energy-Efficient IRS-Assisted UAV Spectrum Sharing Systems](https://arxiv.org/abs/2510.17877)
*Yiheng Wang*

Main category: eess.SY

TL;DR: 提出了一种基于深度强化学习的IRS辅助无人机频谱共享系统，通过联合优化波束成形、子载波分配、IRS相位和无人机轨迹来最大化次级网络能效


<details>
  <summary>Details</summary>
Motivation: 实现更节能和频谱高效的IRS辅助无人机无线通信，解决频谱共享系统中的能效优化问题

Method: 采用基于演员-评论家框架的深度强化学习方法，处理高度非凸、时间耦合的混合连续离散优化问题

Result: 实验显示所提方法相比多个基准方案显著提高了能效，证明了该方法的有效性和移动性下的鲁棒性

Conclusion: 所提出的DRL方法能够有效解决IRS辅助无人机频谱共享系统的能效优化问题，具有显著性能提升

Abstract: Intelligent reflecting surface (IRS) assisted unmanned aerial vehicle (UAV)
systems provide a new paradigm for reconfigurable and flexible wireless
communications. To enable more energy efficient and spectrum efficient IRS
assisted UAV wireless communications, this paper introduces a novel
IRS-assisted UAV enabled spectrum sharing system with orthogonal frequency
division multiplexing (OFDM). The goal is to maximize the energy efficiency
(EE) of the secondary network by jointly optimizing the beamforming, subcarrier
allocation, IRS phase shifts, and the UAV trajectory subject to practical
transmit power and passive reflection constraints as well as UAV physical
limitations. A physically grounded propulsion-energy model is adopted, with its
tight upper bound used to form a tractable EE lower bound for the spectrum
sharing system. To handle highly non convex, time coupled optimization problems
with a mixed continuous and discrete policy space, we develop a deep
reinforcement learning (DRL) approach based on the actor critic framework.
Extended experiments show the significant EE improvement of the proposed
DRL-based approach compared to several benchmark schemes, thus demonstrating
the effectiveness and robustness of the proposed approach with mobility.

</details>


### [49] [An Exact Quantile-Energy Equality for Terminal Halfspaces in Linear-Gaussian Control with a Discrete-Time Companion, KL/Schrodinger Links, and High-Precision Validation](https://arxiv.org/abs/2510.17945)
*Sandro Andric*

Main category: eess.SY

TL;DR: 该论文证明了线性高斯系统中终端半空间的最小二次控制能量与正态分位数间隙平方之间的精确等式关系，并提供了离散时间版本和实际应用。


<details>
  <summary>Details</summary>
Motivation: 研究终端半空间事件的最小控制能量问题，旨在建立控制能量与统计量之间的精确数学关系，为控制系统设计提供理论依据。

Method: 使用线性高斯系统模型，通过格拉姆矩阵、柯西-施瓦茨不等式和高斯等周不等式等经典工具，推导出最小能量与正态分位数间隙的精确等式，并构造匹配滤波器控制策略。

Result: 证明了最小二次控制能量等于正态分位数间隙平方除以两倍的可控性-噪声比，且该最小值可通过匹配滤波器控制实现。

Conclusion: 该研究提供了一个紧凑的综合框架和设计就绪的转换器，虽然使用了经典工具，但终端半空间的显式分位数-能量等式及其离散时间对应关系在现有文献中未被记录。

Abstract: We prove an exact equality between the minimal quadratic control energy and
the squared normal-quantile gap for terminal halfspaces in linear-Gaussian
systems with additive control and quadratic effort $E(u) = \tfrac12\!\int
u^\top M u\,dt$ where $M = B^\top\Sigma^{-1}B$. For terminal halfspace events,
the minimal energy equals the squared normal-quantile gap divided by twice a
controllability-to-noise ratio $R_T^2(w)=(w^\top W_c^M w)/(w^\top V_T w)$ and
is attained by a matched-filter control. We provide an exact zero-order-hold
discrete-time companion via block exponentials, relate the result to
minimum-energy control, Gaussian isoperimetry, risk-sensitive/KL control, and
Schrodinger bridges, and validate to high precision with Monte Carlo. We state
assumptions, singular-$M$ handling, and edge cases. The statement is a compact
synthesis and design-ready translator, not a universal principle. Novelty:
while the ingredients (Gramians, Cauchy-Schwarz, Gaussian isoperimetry) are
classical, to our knowledge the explicit quantile-energy equality with a
constructive matched-filter achiever for terminal halfspaces, and its
discrete-time companion, are not recorded together in the cited literature.

</details>


### [50] [Urban Air Mobility: A Review of Recent Advances in Communication, Management, and Sustainability](https://arxiv.org/abs/2510.18235)
*Zhitong He,Zijing Wang,Lingxi Li*

Main category: eess.SY

TL;DR: 这篇论文综述了2020年以来城市空中交通(UAM)在通信、管理和可持续性三个关键领域的最新研究进展，并指出了实现可扩展、可持续UAM生态系统的关键技术里程碑。


<details>
  <summary>Details</summary>
Motivation: UAM为解决城市拥堵、改善可达性和推进环境可持续性提供了变革性方法，但需要整合通信、管理和可持续性三个紧密关联的领域来实现这一愿景。

Method: 通过回顾和综合这三个领域的最新研究，比较最先进的解决方案，分析技术发展趋势。

Result: 识别了动态频谱分配、低空信道特性、新型空中交通控制概念、能源高效推进系统、集成充电基础设施等关键技术进展。

Conclusion: 实现可扩展、可持续的UAM生态系统需要通信、管理和可持续性三个领域的协同发展，并达到特定的技术和基础设施里程碑。

Abstract: Urban Air Mobility (UAM) offers a transformative approach to addressing urban
congestion, improving accessibility, and advancing environmental
sustainability. Rapid progress has emerged in three tightly linked domains
since 2020: (1) Communication, where dynamic spectrum allocation and
low-altitude channel characterization support reliable air-ground data
exchange; (2) UAM management, with novel air-traffic control concepts for
dense, largely autonomous urban airspace; and (3) Sustainability, driven by
energy-efficient propulsion, integrated charging infrastructure, and holistic
environmental assessment. This paper reviews and synthesizes the latest
research across these areas, compares the state-of-the-art solutions, and
outlines the technological and infrastructural milestones that are critical to
realizing a scalable, sustainable UAM ecosystem.

</details>


### [51] [Distributed Allocation and Resource Scheduling Algorithms Resilient to Link Failure](https://arxiv.org/abs/2510.18273)
*Mohammadreza Doostmohammadian,Sergio Pequito*

Main category: eess.SY

TL;DR: 提出了一种弹性分布式资源分配算法，能够在网络连接中断、链路故障和通信延迟的情况下保证约束可行性和最优性能。


<details>
  <summary>Details</summary>
Motivation: 现实网络经常遭受链路故障、数据包丢失和通信延迟，而传统分布式资源分配方法需要可靠的通信连接，这在实际应用中难以保证。

Method: 基于图论和网络渗透理论，设计了一种弹性分布式资源分配算法，能够在仅需均匀连接网络的情况下工作，无需持续连接性。

Result: 算法在所有时间保证约束可行性，在存在异构时间延迟和大量链路故障的情况下仍能收敛到最优解。

Conclusion: 该算法显著提高了分布式资源分配在实际网络环境中的可靠性，特别适用于移动多智能体系统等连接不稳定的场景。

Abstract: Distributed resource allocation (DRA) is fundamental to modern networked
systems, spanning applications from economic dispatch in smart grids to CPU
scheduling in data centers. Conventional DRA approaches require reliable
communication, yet real-world networks frequently suffer from link failures,
packet drops, and communication delays due to environmental conditions, network
congestion, and security threats.
  We introduce a novel resilient DRA algorithm that addresses these critical
challenges, and our main contributions are as follows: (1) guaranteed
constraint feasibility at all times, ensuring resource-demand balance even
during algorithm termination or network disruption; (2) robust convergence
despite sector-bound nonlinearities at nodes/links, accommodating practical
constraints like quantization and saturation; and (3) optimal performance under
merely uniformly-connected networks, eliminating the need for continuous
connectivity.
  Unlike existing approaches that require persistent network connectivity and
provide only asymptotic feasibility, our graph-theoretic solution leverages
network percolation theory to maintain performance during intermittent
disconnections. This makes it particularly valuable for mobile multi-agent
systems where nodes frequently move out of communication range. Theoretical
analysis and simulations demonstrate that our algorithm converges to optimal
solutions despite heterogeneous time delays and substantial link failures,
significantly advancing the reliability of distributed resource allocation in
practical network environments.

</details>


### [52] [Sliding-Mode Control Strategies for PMSM speed control: A Comprehensive Review, Taxonomy and Research Gaps](https://arxiv.org/abs/2510.18420)
*Abdullah Ajasa,Mubarak Badamasi Aremu,Ali Nasir*

Main category: eess.SY

TL;DR: 本文对2020-2025年间基于滑模控制的永磁同步电机速度控制方法进行了全面综述和分类，分析了200多项研究，揭示了从传统不连续滑模控制向自适应、高阶和数据驱动框架的演变趋势。


<details>
  <summary>Details</summary>
Motivation: 永磁同步电机在高性能驱动系统中应用广泛，但非线性、负载扰动和参数不确定性给控制带来挑战。滑模控制是可靠策略，但自适应、分数阶和智能变种的快速扩散使近期文献碎片化，需要系统梳理。

Method: 对200多项研究进行系统分析和分类，按照控制阶数、滑模面设计、扰动观测器集成、优化方法和智能增强进行分类，定量总结发表趋势、主导混合结构和应用领域。

Result: 综述揭示了从传统不连续滑模控制向自适应、高阶和数据驱动框架的清晰演变，这些框架在保持鲁棒性的同时减轻了抖振问题。

Conclusion: 识别了硬件验证、能效评估和实时调谐策略方面的持续研究空白，建立的分类法和批判性综合为研究人员提供了连贯参考，并为后续统一基准和比较仿真研究奠定了概念基础。

Abstract: Permanent Magnet Synchronous Motors (PMSMs) are widely employed in
high-performance drive systems due to their high efficiency, power density, and
precise dynamic behavior. However, nonlinearities, load disturbances, and
parameter uncertainties present persistent challenges to control. Sliding-Mode
Control (SMC) remains one of the most reliable strategies for high-performance
PMSM drives. Yet, the rapid proliferation of adaptive, fractional-order, and
intelligent variants has fragmented recent literature. This paper presents a
comprehensive review and taxonomy of SMC-based PMSM speed-control methods
published between 2020 and 2025. More than 200 studies are systematically
analyzed and classified according to control order, surface design,
disturbance-observer integration, optimization approach, and intelligent
augmentation. Trends in publication activity, dominant hybrid structures, and
application domains are quantitatively summarized. The review reveals a clear
evolution from conventional discontinuous SMC toward adaptive, higher-order,
and data-driven frameworks that mitigate chattering while preserving
robustness. Persistent research gaps are identified in hardware validation,
energy-efficiency assessment, and real-time tuning strategies. The taxonomy and
critical synthesis provided herein establish a coherent reference for
researchers and form the conceptual foundation for the companion paper (Part
II), which delivers a unified benchmark and comparative simulation study of
representative SMC designs.

</details>


### [53] [Quantifying Security for Networked Control Systems: A Review](https://arxiv.org/abs/2510.18645)
*Sribalaji C. Anand,Anh Tung Nguyen,André M. H. Teixeira,Henrik Sandberg,Karl H. Johansson*

Main category: eess.SY

TL;DR: 该论文综述了网络控制系统(NCSs)的脆弱性评估方法和缓解策略，强调概率风险指标的重要性，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 网络控制系统在关键基础设施中至关重要，确保这些大规模系统对网络攻击的弹性运行对社会福祉至关重要。过去二十年研究主要集中在量化NCSs的脆弱性指标上。

Method: 提供对NCSs脆弱性评估方法和相应缓解策略的全面概述，特别强调使用概率风险指标来建模具有不完全过程知识的对手攻击下的脆弱性。

Result: 系统梳理了网络控制系统脆弱性量化和缓解策略的研究进展，为相关领域提供了综合性的分析框架。

Conclusion: 论文总结了现有研究成果，并指出了未来研究的几个有前景的方向，包括进一步完善概率风险指标和开发更有效的缓解策略。

Abstract: Networked Control Systems (NCSs) are integral in critical infrastructures
such as power grids, transportation networks, and production systems. Ensuring
the resilient operation of these large-scale NCSs against cyber-attacks is
crucial for societal well-being. Over the past two decades, extensive research
has been focused on developing metrics to quantify the vulnerabilities of NCSs
against attacks. Once the vulnerabilities are quantified, mitigation strategies
can be employed to enhance system resilience. This article provides a
comprehensive overview of methods developed for assessing NCS vulnerabilities
and the corresponding mitigation strategies. Furthermore, we emphasize the
importance of probabilistic risk metrics to model vulnerabilities under
adversaries with imperfect process knowledge. The article concludes by
outlining promising directions for future research.

</details>


### [54] [$\ell_1$-Based Adaptive Identification under Quantized Observations with Applications](https://arxiv.org/abs/2510.18738)
*Xin Zheng,Yifei Jin,Yujing Liu,Lei Guo*

Main category: eess.SY

TL;DR: 提出了一种基于ℓ₁范数的自适应识别算法，专门用于量化观测数据，无需传统持续激励条件即可实现参数估计的全局收敛。


<details>
  <summary>Details</summary>
Motivation: 量化观测在工程和社会科学中广泛应用，基于ℓ₁范数的算法对异常值具有鲁棒性，但结合量化观测的自适应识别方法研究不足。

Method: 开发了一种新的ℓ₁基自适应识别算法，专门针对量化观测设计，不依赖持续激励条件。

Result: 证明了参数估计能全局收敛到真实值，平均遗憾随数据量增加渐近消失，在司法量刑问题中表现出优越性能。

Conclusion: 新算法在量化观测场景下具有理论保证和实际应用价值，在真实数据应用中展现了优越性能和实用意义。

Abstract: Quantized observations are ubiquitous in a wide range of applications across
engineering and the social sciences, and algorithms based on the $\ell_1$-norm
are well recognized for their robustness to outliers compared with their
$\ell_2$-based counterparts. Nevertheless, adaptive identification methods that
integrate quantized observations with $\ell_1$-optimization remain largely
underexplored. Motivated by this gap, we develop a novel $\ell_1$-based
adaptive identification algorithm specifically designed for quantized
observations. Without relying on the traditional persistent excitation
condition, we establish global convergence of the parameter estimates to their
true values and show that the average regret asymptotically vanishes as the
data size increases. Finally, we apply our new identification algorithm to a
judicial sentencing problem using real-world data, which demonstrates its
superior performance and practical significance.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [55] [Finding the Sweet Spot: Optimal Data Augmentation Ratio for Imbalanced Credit Scoring Using ADASYN](https://arxiv.org/abs/2510.18252)
*Luis H. Chia*

Main category: stat.AP

TL;DR: 本研究系统评估了信用评分中数据增强的最佳比例，发现ADASYN方法以1倍乘数（少数类翻倍）达到最优性能，最佳类别不平衡比例为6.6:1，而非常用的1:1平衡。


<details>
  <summary>Details</summary>
Motivation: 信用评分模型面临严重的类别不平衡问题（违约率通常低于10%），现有SMOTE和ADASYN等数据增强技术缺乏对最佳增强比例的经验依据，从业者通常默认使用1:1平衡比例。

Method: 使用Give Me Some Credit数据集（97,243个观测值，7%违约率），系统评估10种数据增强场景，比较SMOTE、BorderlineSMOTE和ADASYN在不同乘数（1x、2x、3x）下的表现，使用XGBoost训练模型并在29,173个真实测试集上评估，通过1,000次bootstrap测试评估统计显著性。

Result: ADASYN 1x增强（少数类翻倍）达到最优性能，AUC为0.6778，Gini系数为0.3557，相比基线分别显著提升0.77%和3.00%。更高的乘数（2x和3x）导致性能下降，3x时AUC下降0.48%。最佳类别不平衡比例为6.6:1。

Conclusion: 本研究首次为信用评分中的数据增强提供了最佳"甜点"的经验证据，推翻了常用的1:1平衡实践，为行业从业者和研究者提供了实用的不平衡数据集处理指南。

Abstract: Credit scoring models face a critical challenge: severe class imbalance, with
default rates typically below 10%, which hampers model learning and predictive
performance. While synthetic data augmentation techniques such as SMOTE and
ADASYN have been proposed to address this issue, the optimal augmentation ratio
remains unclear, with practitioners often defaulting to full balancing (1:1
ratio) without empirical justification.
  This study systematically evaluates 10 data augmentation scenarios using the
Give Me Some Credit dataset (97,243 observations, 7% default rate), comparing
SMOTE, BorderlineSMOTE, and ADASYN at different multiplication factors (1x, 2x,
3x). All models were trained using XGBoost and evaluated on a held-out test set
of 29,173 real observations. Statistical significance was assessed using
bootstrap testing with 1,000 iterations.
  Key findings reveal that ADASYN with 1x multiplication (doubling the minority
class) achieved optimal performance with AUC of 0.6778 and Gini coefficient of
0.3557, representing statistically significant improvements of +0.77% and
+3.00% respectively (p = 0.017, bootstrap test). Higher multiplication factors
(2x and 3x) resulted in performance degradation, with 3x showing a -0.48%
decrease in AUC, suggesting a "law of diminishing returns" for synthetic
oversampling. The optimal class imbalance ratio was found to be 6.6:1
(majority:minority), contradicting the common practice of balancing to 1:1.
  This work provides the first empirical evidence of an optimal "sweet spot"
for data augmentation in credit scoring, with practical guidelines for industry
practitioners and researchers working with imbalanced datasets. While
demonstrated on a single representative dataset, the methodology provides a
reproducible framework for determining optimal augmentation ratios in other
imbalanced domains.

</details>


### [56] [Distributional regression for seasonal data: an application to river flows](https://arxiv.org/abs/2510.18639)
*Samuel Perreault,Silvana M. Pesenti,Daniyal Shahzad*

Main category: stat.AP

TL;DR: 提出了一个建模框架来估计环境变量的完整日分布，作为时间的函数，补充传统极端值方法，同时捕捉季节变化和长期趋势。


<details>
  <summary>Details</summary>
Motivation: 传统保险风险评估方法主要关注罕见极端事件，但无法捕捉环境变量的完整动态，包括中等和频繁的损失事件。需要一种能够同时考虑季节变化和长期趋势的分布建模方法。

Method: 采用受GAMLSS启发的框架，将分布参数建模为仅依赖于年内时间的解释变量的函数，忽略时间序列依赖性以简化模型，同时解决相关推断挑战。

Result: 将该框架应用于加拿大不列颠哥伦比亚省弗雷泽河三个水文站的日河流流量数据，分析了2021年初冬的弗雷泽河洪水事件。

Conclusion: 提出的分布建模框架能够有效捕捉环境变量的完整动态，包括季节变化和长期趋势，为保险风险评估提供了更全面的工具。

Abstract: Risk assessment in casualty insurance, such as flood risk, traditionally
relies on extreme-value methods that emphasizes rare events. These approaches
are well-suited for characterizing tail risk, but do not capture the broader
dynamics of environmental variables such as moderate or frequent loss events.
To complement these methods, we propose a modelling framework for estimating
the full (daily) distribution of environmental variables as a function of time,
that is a distributional version of typical climatological summary statistics,
thereby incorporating both seasonal variation and gradual long-term changes.
Aside from the time trend, to capture seasonal variation our approach
simultaneously estimates the distribution for each instant of the seasonal
cycle, without explicitly modelling the temporal dependence present in the
data. To do so, we adopt a framework inspired by GAMLSS (Generalized Additive
Models for Location, Scale, and Shape), where the parameters of the
distribution vary over the seasonal cycle as a function of explanatory
variables depending only on the time of year, and not on the past values of the
process under study. Ignoring the temporal dependence in the seasonal variation
greatly simplifies the modelling but poses inference challenges that we clarify
and overcome.
  We apply our framework to daily river flow data from three hydrometric
stations along the Fraser River in British Columbia, Canada, and analyse the
flood of the Fraser River in early winter of 2021.

</details>


### [57] [Comparison of Simulation-Guided Design to Closed-Form Power Calculations in Planning a Cluster Randomized Trial with Covariate-Constrained Randomization: A Case Study in Rural Chad](https://arxiv.org/abs/2510.18818)
*Jay JH Park,Rebecca K. Metcalfe,Nathaniel Dyrkton,Yichen Yan,Shomoita Alam,Kevin Phelan,Ibrahim Sana,Susan Shepherd*

Main category: stat.AP

TL;DR: 该研究比较了使用协变量约束随机化的嵌套整群随机试验的模拟规划与传统功效计算，发现传统方法在复杂设计下可能产生误导，而模拟方法能更准确地评估试验功效。


<details>
  <summary>Details</summary>
Motivation: 传统整群随机试验设计依赖闭式公式进行功效计算，但在使用协变量约束随机化和嵌套数据结构时，传统方法的实用性有限，可能导致不准确的试验规划。

Method: 以OptiMAx-Chad研究为案例，生成了100万次使用协变量约束随机化的健康区域分配，平衡基线村庄特征，并比较模拟方法与使用WHO推荐ICC值的传统功效计算。

Result: 传统计算显示在达到一定整群规模后功效趋于稳定，而模拟方法显示功效随整群规模增加而持续提升，且使用WHO推荐ICC值时无法达到目标功效。

Conclusion: 对于具有协变量约束随机化和多层嵌套数据结构的复杂整群随机试验，传统闭式公式规划可能产生误导，模拟方法能改善试验规划质量。

Abstract: Current practices for designing cluster-randomized trials (cRCTs) typically
rely on closed-form formulas for power calculations. For cRCTs using
covariate-constrained randomization, the utility of conventional calculations
might be limited, particularly when data is nested. We compared
simulation-based planning of a nested cRCT using covariate-constrained
randomization to conventional power calculations using OptiMAx-Chad as a case
study. OptiMAx-Chad will examine the impact of embedding mass distribution of
small-quantity lipid-based nutrient supplements within an expanded programme on
immunization on first-dose measles-containing vaccine (MCV1) coverage among
children aged 12-24 months in rural villages in Ngouri. Within the 12 health
areas to be randomized, a random subset of villages will be selected for
outcome collection. 1,000,000 assignments of health areas with different
possible village selections were generated using covariate-constrained
randomization to balance baseline village characteristics. The empirically
estimated intracluster correlation coefficient (ICC) and the World Health
Organization (WHO) recommended values of 1/3 and 1/6 were considered. The
desired operating characteristics were 80% power at 0.05 one-sided type I error
rate. Using conventional calculations target power for a realistic treatment
effect could not be achieved with the WHO recommended values. Conventional
calculations also showed a plateau in power after a certain cluster size. Our
simulations matched the design of OptiMAx-Chad with covariate adjustment and
random selection, and showed that power did not plateau. Instead, power
increased with increasing cluster size. Planning complex cRCTs with covariate
constrained randomization and a multi-nested data structure with conventional
closed-form formulas can be misleading. Simulations can improve the planning of
cRCTs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [58] [AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI](https://arxiv.org/abs/2510.18170)
*Manik Rana,Calissa Man,Anotida Expected Msiiwa,Jeffrey Paine,Kevin Zhu,Sunishchal Dev,Vasu Sharma,Ahan M R*

Main category: cs.AI

TL;DR: 提出了AgentChangeBench基准，专门评估工具增强语言模型代理在对话中目标变化时的适应能力，包含四个互补指标来衡量效果、可靠性、效率和适应延迟。


<details>
  <summary>Details</summary>
Motivation: 现实世界多轮交互中目标变化是常见特征，但现有代理基准主要评估静态目标或一次性工具使用，缺乏对动态目标适应能力的系统评估。

Method: 开发了包含2,835个任务序列和五个用户角色的基准框架，在三个企业领域（如航空预订、零售等）中触发现实的工作流程变化点，通过四个指标进行形式化评估。

Result: 评估发现前沿模型在目标变化适应能力上存在显著差异：GPT-4o在航空预订变化中达到92.2%恢复率，而Gemini降至48.6%；零售任务参数有效性接近完美但冗余率超过80%，揭示了主要效率问题。

Conclusion: 高原始准确率并不代表在动态目标下的鲁棒性，明确测量恢复时间和冗余度对于评估代理在现实企业环境中的韧性至关重要，AgentChangeBench为诊断和改进代理韧性提供了可复现的测试平台。

Abstract: Goal changes are a defining feature of real world multi-turn interactions,
yet current agent benchmarks primarily evaluate static objectives or one-shot
tool use. We introduce AgentChangeBench, a benchmark explicitly designed to
measure how tool augmented language model agents adapt to mid dialogue goal
shifts across three enterprise domains. Our framework formalizes evaluation
through four complementary metrics: Task Success Rate (TSR) for effectiveness,
Tool Use Efficiency (TUE) for reliability, Tool Call Redundancy Rate (TCRR) for
wasted effort, and Goal-Shift Recovery Time (GSRT) for adaptation latency.
AgentChangeBench comprises 2,835 task sequences and five user personas, each
designed to trigger realistic shift points in ongoing workflows. Using this
setup, we evaluate several frontier models and uncover sharp contrasts obscured
by traditional $\text{pass}@k$ scores: for example, GPT-4o reaches $92.2\%$
recovery on airline booking shifts while Gemini collapses to $48.6\%$, and
retail tasks show near perfect parameter validity yet redundancy rates above
$80\%$, revealing major inefficiencies. These findings demonstrate that high
raw accuracy does not imply robustness under dynamic goals, and that explicit
measurement of recovery time and redundancy is essential. AgentChangeBench
establishes a reproducible testbed for diagnosing and improving agent
resilience in realistic enterprise settings.

</details>


### [59] [Activation Manifold Projection: Liberating Task-Specific Behaviors from LLM Architectures](https://arxiv.org/abs/2510.17902)
*Al Kari*

Main category: cs.AI

TL;DR: CAST框架通过在学习激活流形之间建立非线性映射，实现了LoRA适配器在不同LLM架构间的零样本迁移，解决了架构锁定问题。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法（如LoRA）导致学到的任务特定行为被锁定在源模型架构中，现有迁移方法通过对齐权重空间，这种方法脆弱且间接。

Method: CAST框架将预训练的LoRA视为冻结的"行为内核"，学习轻量级双向投影头，在目标模型的激活流和源模型的潜在空间之间进行转换，无需任务特定数据。

Result: 在Llama-2和Mistral等异构模型家族间的迁移实验中，CAST转换的适配器性能达到在目标模型上完全重新训练LoRA的85-95%，优于当前权重空间迁移技术。

Conclusion: CAST建立了一种新的模型互操作性标准，能够真正实现标准LoRA适配器的零样本迁移，有效将学习技能与源架构解耦。

Abstract: The proliferation of Large Language Model (LLM) architectures presents a
fundamental challenge: valuable, task-specific behaviors learned through
fine-tuning methods like Low-Rank Adaptation (LoRA) are effectively trapped
within their source model's architecture, herein referred to architectural
lock-in. Existing transfer methods attempt to bridge this gap by aligning the
static weight spaces of models, a brittle and indirect approach that relies on
tenuous correlations between parameter geometries. This paper introduces a
fundamentally different and more direct paradigm: the Cartridge Activation
Space Transfer (CAST), a novel framework that liberates LoRA-encoded behaviors
by learning a direct, nonlinear mapping between the activation manifolds, the
geometric structures formed by the model's internal neuron activations, of two
distinct LLM architectures. CAST treats a pre-trained LoRA as a frozen
"behavioral kernel." It learns a set of lightweight, bidirectional projection
heads that translate the target model's activation stream into the source
model's latent space, apply the frozen kernel, and project the result back.
This process, trained on a general text corpus without any task-specific data,
effectively decouples the learned skill from the source architecture. We
demonstrate that CAST enables true "zero-shot" translation of any standard LoRA
adapter. Our experiments, including transfers between heterogeneous model
families like Llama-2 and Mistral, show that CAST-translated adapters achieve
85-95\% of the performance of a LoRA fully retrained on the target model,
quantitatively outperforming current weight-space transfer techniques and
establishing a new state-of-the-art in model interoperability.

</details>


### [60] [Beyond More Context: Retrieval Diversity Boosts Multi-Turn Intent Understanding](https://arxiv.org/abs/2510.17940)
*Zhiming Lin*

Main category: cs.AI

TL;DR: 提出了一种多样性感知检索框架，在固定token预算下通过选择多样化的上下文示例来提升LLM意图理解能力，在MultiWOZ 2.4和SGD数据集上显著提高了联合目标准确率。


<details>
  <summary>Details</summary>
Motivation: 现实部署中面临严格的token预算和嘈杂上下文，现有检索管道强调相关性但忽略了集合层面的多样性以及更多上下文或示例顺序等混淆因素。

Method: 开发了多样性感知检索框架，选择上下文示例以平衡意图覆盖和语言多样性，并将此选择与标准LLM解码器集成；评估采用预算匹配提示和随机化位置。

Result: 在MultiWOZ 2.4和SGD上，该方法在相同token预算下实现了联合目标准确率的显著提升，超越了强大的LLM/DST基线，在K=4到7范围内保持一致的改进，延迟适中。

Conclusion: 研究分离并验证了检索中内容多样性的影响，为构建准确、预算受限的多轮意图系统提供了一个简单、可部署的选择原则。

Abstract: Multi turn intent understanding is central to task oriented chatbots, yet
real deployments face tight token budgets and noisy contexts, and most
retrieval pipelines emphasize relevance while overlooking set level diversity
and confounds such as more context or exemplar order. We ask whether retrieval
diversity, rather than longer prompts, systematically improves LLM intent
understanding under fixed budgets. We present a diversity aware retrieval
framework that selects in context exemplars to balance intent coverage and
linguistic variety, and integrates this selection with standard LLM decoders;
the evaluation enforces budget matched prompts and randomized positions, and
includes sensitivity analyses over exemplar count, diversity strength, and
backbone size. On MultiWOZ 2.4 and SGD, the approach achieves strong gains in
Joint Goal Accuracy under equal token budgets, surpassing strong LLM/DST
baselines, with consistent improvements across K from 4 to 7 and moderate
latency. Overall, the study isolates and validates the impact of content
diversity in retrieval and offers a simple, deployable selection principle for
building accurate, budget constrained multi turn intent systems.

</details>


### [61] [LLM-Based Multi-Agent System for Simulating and Analyzing Marketing and Consumer Behavior](https://arxiv.org/abs/2510.18155)
*Man-Lin Chu,Lucian Terhorst,Kadin Reed,Tom Ni,Weiwei Chen,Rongyu Lin*

Main category: cs.AI

TL;DR: 提出了一个基于大语言模型的多智能体模拟框架，用于模拟消费者决策和社会动态，为营销策略提供低成本预实施测试。


<details>
  <summary>Details</summary>
Motivation: 传统的事后分析和基于规则的智能体模型难以捕捉人类行为和社会互动的复杂性，需要更有效的营销策略测试工具。

Method: 利用大语言模型在沙盒环境中构建多智能体模拟框架，智能体可以交互、表达内部推理、形成习惯和做出购买决策，无需预定义规则。

Result: 在价格折扣营销场景中，系统提供了可操作的策略测试结果，并揭示了传统方法无法捕捉的新兴社会模式。

Conclusion: 该方法为营销人员提供了一个可扩展、低风险的预实施测试工具，减少了对耗时的事后评估的依赖，降低了营销活动表现不佳的风险。

Abstract: Simulating consumer decision-making is vital for designing and evaluating
marketing strategies before costly real-world deployment. However, post-event
analyses and rule-based agent-based models (ABMs) struggle to capture the
complexity of human behavior and social interaction. We introduce an
LLM-powered multi-agent simulation framework that models consumer decisions and
social dynamics. Building on recent advances in large language model simulation
in a sandbox environment, our framework enables generative agents to interact,
express internal reasoning, form habits, and make purchasing decisions without
predefined rules. In a price-discount marketing scenario, the system delivers
actionable strategy-testing outcomes and reveals emergent social patterns
beyond the reach of conventional methods. This approach offers marketers a
scalable, low-risk tool for pre-implementation testing, reducing reliance on
time-intensive post-event evaluations and lowering the risk of underperforming
campaigns.

</details>


### [62] [FABRIC: Framework for Agent-Based Realistic Intelligence Creation](https://arxiv.org/abs/2510.17995)
*Abhigya Verma,Seganrasan Subramanian,Nandhakumar Kandasamy,Naman Gupta*

Main category: cs.AI

TL;DR: 提出了一个仅使用LLM合成智能体数据的统一框架，无需人工监督，可生成包含任务规范、工具定义、策略伪代码、自然语言交互和执行轨迹的完整交互记录。


<details>
  <summary>Details</summary>
Motivation: 收集智能体数据需要人类标注，成本高、耗时且难以扩展，因此需要一种可扩展的合成数据生成方法。

Method: 采用模块化流水线生成符合严格语法和语义约束的交互记录，支持单任务、多任务和多轮交互，结合约束生成格式、JSON模式验证和基于评判的过滤来确保质量。

Result: 框架能够生成机器可解析且输入、输出和工具调用之间保持忠实对齐的高质量合成数据。

Conclusion: 该框架为手动收集提供了可复现的、仅使用LLM的替代方案，推动了能够进行鲁棒工具使用的智能体LLM的发展。

Abstract: Large language models (LLMs) are increasingly deployed as agents, expected to
decompose goals, invoke tools, and verify results in dynamic environments.
Realizing these capabilities requires access to agentic data-structured
interaction records that couple user intents with tool specifications,
argument-grounded calls, and verifiable execution traces. However, collecting
such data from human annotators is costly, time-consuming, and difficult to
scale. We present a unified framework for synthesizing agentic data using only
LLMs, without any human-in-the-loop supervision. This framework decomposes
generation into modular pipelines that produce complete interaction records
spanning task specifications, tool definitions, policy pseudocode, natural
language exchanges, and execution traces. Records conform to strict syntactic
and semantic constraints, ensuring machine-parseability and faithful alignment
across inputs, outputs, and tool calls. Beyond single tasks, there is support
for both multi-task and multi-turn agent interactions, enabling the
construction of datasets that reflect the full spectrum of tool-use
competencies. To ensure quality and consistency, the framework integrates
constrained generation formats, JSON-schema validation, and judge-based
filtering. This paper formalizes the schema for agentic records, details the
prompt design principles that guide generation, and introduces scalable
pipelines for high-quality synthetic data. By providing a reproducible,
LLM-only alternative to manual collection, hence advancing the development of
agentic LLMs capable of robust tool use.

</details>


### [63] [OPTAGENT: Optimizing Multi-Agent LLM Interactions Through Verbal Reinforcement Learning for Enhanced Reasoning](https://arxiv.org/abs/2510.18032)
*Zhenyu Bi,Meng Lu,Yang Li,Swastik Roy,Weijie Guan,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: 提出了一种多智能体口头强化学习算法，通过动态构建和优化协作结构来提升多智能体推理能力，在多种推理任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统要么采用预定义结构，要么依赖多数投票或圆桌辩论，这会压制正确但非主导的智能体贡献。作者假设有效的智能体通信对多智能体推理至关重要。

Method: 提出多智能体口头强化学习算法，定义动作空间和反馈机制来评估辩论过程中的通信鲁棒性和连贯性，最终通过所有智能体的多数投票做出决策。

Result: 在数学推理、创意写作、科学推理和数值排序等任务上的评估表明，该方法显著优于单智能体提示方法和最先进的多智能体框架。

Conclusion: 动态优化多智能体协作结构能够有效提升复杂推理任务的性能，验证了智能体通信质量在多智能体系统中的重要性。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning capabilities in
mathematical and scientific tasks. To enhance complex reasoning, multi-agent
systems have been proposed to harness the collective intelligence of LLM
agents. However, existing collaboration structures are either predefined or
rely on majority voting or round-table debates, which can suppress correct but
less dominant agent contributions. Recent approaches model multi-agent systems
as graph networks but optimize purely for agent performance, neglecting the
quality of interactions. We hypothesize that effective agent communication is
crucial for multi-agent reasoning and that debating quality plays a significant
role. To address this, we propose $\ours$, a multi-agent verbal reinforcement
learning algorithm that dynamically constructs and refines multi-agent
collaboration structures. Our method defines action spaces and a feedback
mechanism that evaluates communication robustness and coherence throughout the
debate. The final decision is achieved through a majority vote over all the
agents. We assess $\ours$ on various reasoning tasks, including mathematical
reasoning, creative writing, scientific reasoning, and numerical sorting.
Results demonstrate that our approach significantly outperforms single-agent
prompting methods and state-of-the-art multi-agent frameworks on diverse tasks.

</details>


### [64] [Subject-Event Ontology Without Global Time: Foundations and Execution Semantics](https://arxiv.org/abs/2510.18040)
*Alexander Boldachev*

Main category: cs.AI

TL;DR: 提出了一种基于主体-事件的本体论形式化方法，用于在没有全局时间的条件下建模复杂动态系统，通过声明式数据流机制确保确定性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂动态系统建模中对全局时间的依赖问题，支持分布式系统、微服务架构和多方视角场景中的事件建模。

Method: 基于九个公理（A1-A9）的形式化方法，包括事件作为固定行为、基于happens-before的因果顺序、模型作为认知过滤器等核心原则，并通过boldsea系统实现可执行本体。

Result: 开发了boldsea系统作为可执行本体的工作流引擎，理论构造在BSL语言中实现，确保了历史单调性、因果无环性和可追溯性。

Conclusion: 该形式化方法为没有全局时间的复杂系统提供了可行的建模框架，特别适用于分布式系统、微服务架构和多方视角场景。

Abstract: A formalization of a subject-event ontology is proposed for modeling complex
dynamic systems without reliance on global time. Key principles: (1) event as
an act of fixation - a subject discerns and fixes changes according to models
(conceptual templates) available to them; (2) causal order via happens-before -
the order of events is defined by explicit dependencies, not timestamps; (3)
making the ontology executable via a declarative dataflow mechanism, ensuring
determinism; (4) models as epistemic filters - a subject can only fix what
falls under its known concepts and properties; (5) presumption of truth - the
declarative content of an event is available for computation from the moment of
fixation, without external verification. The formalization includes nine axioms
(A1-A9), ensuring the correctness of executable ontologies: monotonicity of
history (I1), acyclicity of causality (I2), traceability (I3). Special
attention is given to the model-based approach (A9): event validation via
schemas, actor authorization, automatic construction of causal chains (W3)
without global time. Practical applicability is demonstrated on the boldsea
system - a workflow engine for executable ontologies, where the theoretical
constructs are implemented in BSL (Boldsea Semantic Language). The
formalization is applicable to distributed systems, microservice architectures,
DLT platforms, and multiperspectivity scenarios (conflicting facts from
different subjects).

</details>


### [65] [CompactPrompt: A Unified Pipeline for Prompt Data Compression in LLM Workflows](https://arxiv.org/abs/2510.18043)
*Joong Ho Choi,Jiayang Zhao,Jeel Shah,Ritvika Sonawane,Vedant Singh,Avani Appalla,Will Flanagan,Filipe Condessa*

Main category: cs.AI

TL;DR: CompactPrompt是一个端到端流水线，通过硬提示压缩和轻量级文件级数据压缩，将LLM代理工作流中的总令牌使用量和推理成本降低高达60%，同时保持输出质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代理工作流中运行时成本高昂，需要处理冗长的提示和丰富的数据流，因此需要降低运行成本。

Method: 结合硬提示压缩和轻量级文件级数据压缩：使用自信息评分和基于依赖关系的短语分组修剪低信息令牌；对文档中的重复文本模式应用n-gram缩写，对数值列应用统一量化。

Result: 在TAT-QA和FinQA等基准数据集上，总令牌使用量和推理成本降低高达60%，输出质量保持良好（Claude-3.5-Sonnet和GPT-4.1-Mini的准确率下降小于5%）。

Conclusion: CompactPrompt为更精简的生成式AI流水线奠定了基础，能够可视化实时压缩决策并量化成本-性能权衡。

Abstract: Large Language Models (LLMs) deliver powerful reasoning and generation
capabilities but incur substantial run-time costs when operating in agentic
workflows that chain together lengthy prompts and process rich data streams. We
introduce CompactPrompt, an end-to-end pipeline that merges hard prompt
compression with lightweight file-level data compression. CompactPrompt first
prunes low-information tokens from prompts using self-information scoring and
dependency-based phrase grouping. In parallel, it applies n-gram abbreviation
to recurrent textual patterns in attached documents and uniform quantization to
numerical columns, yielding compact yet semantically faithful representations.
Integrated into standard LLM agents, CompactPrompt reduces total token usage
and inference cost by up to 60% on benchmark dataset like TAT-QA and FinQA,
while preserving output quality (Results in less than 5% accuracy drop for
Claude-3.5-Sonnet, and GPT-4.1-Mini) CompactPrompt helps visualize real-time
compression decisions and quantify cost-performance trade-offs, laying the
groundwork for leaner generative AI pipelines.

</details>


### [66] [Planned Diffusion](https://arxiv.org/abs/2510.18087)
*Daniel Israel,Tian Jin,Ellie Cheng,Guy Van den Broeck,Aditya Grover,Suvinay Subramanian,Michael Carbin*

Main category: cs.AI

TL;DR: Planned diffusion是一种结合自回归和扩散模型的混合方法，通过两阶段生成（先自回归规划，后扩散并行生成）来优化文本生成的速度-质量权衡。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型推理中生成速度与输出质量之间的权衡问题，自回归模型质量高但速度慢，扩散模型可并行但需要多次迭代。

Method: 两阶段方法：1）自回归规划阶段，将输出分解为独立的小片段；2）扩散生成阶段，并行生成这些片段。

Result: 在AlpacaEval测试中，相比纯自回归生成实现了1.27x到1.81x的加速，仅损失0.87%到5.4%的胜率，达到了Pareto最优权衡。

Conclusion: Planned diffusion扩展了速度-质量的Pareto边界，提供了更灵活的质量-延迟权衡控制，是高质量快速文本生成的实用路径。

Abstract: A central challenge in large language model inference is the trade-off
between generation speed and output quality. Autoregressive models produce
high-quality text but generate tokens sequentially. Diffusion models can
generate tokens in parallel but often need many iterations to match the same
quality. We propose planned diffusion, a hybrid method that combines the
strengths of both paradigms. Planned diffusion works in two stages: first, the
model creates a short autoregressive plan that breaks the output into smaller,
independent spans. Second, the model generates these spans simultaneously using
diffusion. This approach expands the speed-quality Pareto frontier and provides
a practical path to faster, high-quality text generation. On AlpacaEval, a
suite of 805 instruction-following prompts, planned diffusion achieves
Pareto-optimal trade-off between quality and latency, achieving 1.27x to 1.81x
speedup over autoregressive generation with only 0.87\% to 5.4\% drop in win
rate, respectively. Our sensitivity analysis shows that the planning mechanism
of planned diffusion is minimal and reliable, and simple runtime knobs exist to
provide flexible control of the quality-latency trade-off.

</details>


### [67] [SMaRT: Select, Mix, and ReinvenT -- A Strategy Fusion Framework for LLM-Driven Reasoning and Planning](https://arxiv.org/abs/2510.18095)
*Nikhil Verma,Manasa Bharadwaj,Wonjun Jang,Harmanpreet Singh,Yixiao Wang,Homa Fashandi,Chul Lee*

Main category: cs.AI

TL;DR: SMaRT框架通过融合多种推理策略来提升LLM在复杂任务中的性能，解决了单一策略方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一策略提示，缺乏不同推理方法的协同效应，需要能够融合多种策略的框架来最大化性能并确保鲁棒性。

Method: 引入SMaRT框架，使用LLM作为智能集成器而非仅仅评估器，通过选择、混合和重新发明策略来无缝整合多样化的推理方法。

Result: 在推理、规划和顺序决策等基准测试中，SMaRT在解决方案质量、约束遵循和性能指标方面持续优于最先进的基线方法。

Conclusion: 这项工作通过开创跨策略校准的新范式，重新定义了LLM驱动的决策，为推理系统解锁了优越结果并推进了自我精化方法的边界。

Abstract: Large Language Models (LLMs) have redefined complex task automation with
exceptional generalization capabilities. Despite these advancements,
state-of-the-art methods rely on single-strategy prompting, missing the synergy
of diverse reasoning approaches. No single strategy excels universally,
highlighting the need for frameworks that fuse strategies to maximize
performance and ensure robustness. We introduce the Select, Mix, and ReinvenT
(SMaRT) framework, an innovative strategy fusion approach designed to overcome
this constraint by creating balanced and efficient solutions through the
seamless integration of diverse reasoning strategies. Unlike existing methods,
which employ LLMs merely as evaluators, SMaRT uses them as intelligent
integrators, unlocking the "best of all worlds" across tasks. Extensive
empirical evaluations across benchmarks in reasoning, planning, and sequential
decision-making highlight the robustness and adaptability of SMaRT. The
framework consistently outperforms state-of-the-art baselines in solution
quality, constraint adherence, and performance metrics. This work redefines
LLM-driven decision-making by pioneering a new paradigm in cross-strategy
calibration, unlocking superior outcomes for reasoning systems and advancing
the boundaries of self-refining methodologies.

</details>


### [68] [Measuring Reasoning in LLMs: a New Dialectical Angle](https://arxiv.org/abs/2510.18134)
*Soheil Abbasloo*

Main category: cs.AI

TL;DR: 提出SIEV框架，基于辩证法评估语言模型的推理过程而非仅关注答案正确性，揭示即使基准测试饱和的先进模型也存在显著推理缺陷


<details>
  <summary>Details</summary>
Motivation: 当前评估主要奖励模型的正确答案，但正确性本身无法揭示产生答案的推理过程。推理应是动态轨迹，观点在其中互动、冲突并演变为深刻见解

Method: 借鉴辩证法传统（正题、反题、合题），构建SIEV结构化框架，评估模型解决矛盾、整合不同观点和进行高阶推理的能力

Result: SIEV框架在GSM和MMLU等饱和基准上发现了最先进模型的显著推理缺陷，例如GPT-5-chat在GSM上损失超过40分（满分100）

Conclusion: 采用过程导向、哲学基础的方法能够对LLM推理进行更深入、严谨和区分性的评估

Abstract: What does it truly mean for a language model to "reason"? Most current
evaluations and benchmarks reward models' correct standalone answers--but
correctness alone reveals little about the process that produced them. In this
work, we explore a different perspective: reasoning is not a static chain of
steps, but a dynamic trajectory where ideas interact, clash, and evolve into
deeper insights. To capture this dynamic, we draw on a well-established
philosophical tradition: \textit{dialectics}, where reasoning unfolds through
thesis, antithesis, and synthesis. Building on this, we present SIEV, a
structured framework that evaluates reasoning of LLMs through dialectics.
Unlike conventional evaluations, SIEV assesses not only the conclusion a model
reaches, but how it gets there: its ability to resolve tension, integrate
distinct ideas, and synthesize higher-order reasoning. This lens uncovers
significant reasoning gaps in state-of-the-art models even under saturated
benchmarks like GSM and MMLU. For instance, GPT-5-chat, a recent model, loses
over 40 points (out of 100) when evaluated with SIEV on GSM. Our findings
highlight that adopting a process-oriented, philosophically grounded approach
enables a deeper, more rigorous, and more discriminative assessment of LLM
reasoning.

</details>


### [69] [Learning from Generalization Patterns: An Evaluation-Driven Approach to Enhanced Data Augmentation for Fine-Tuning Small Language Models](https://arxiv.org/abs/2510.18143)
*Huan Song,Deeksha Razdan,Yiyue Qian,Arijit Ghosh Chowdhury,Parth Patwa,Aman Chadha,Shinan Zhang,Sharlina Keshava,Hannah Marlowe*

Main category: cs.AI

TL;DR: PaDA-Agent是一种评估驱动的数据增强方法，通过发现验证数据中的失败模式并制定针对性策略，来提升小型语言模型在领域特定任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在部署成本和延迟方面具有优势，但在复杂领域特定任务上的准确性往往落后于大型模型。虽然有监督微调可以弥补这一差距，但需要大量手动数据准备和迭代优化工作。

Method: 提出PaDA-Agent（模式引导数据增强代理），通过评估发现验证数据中的失败模式，并制定针对性的数据增强策略，直接减少泛化差距。

Result: 实验结果显示，该方法在Llama 3.2 1B Instruct模型微调上显著优于最先进的基于LLM的数据增强方法。

Conclusion: PaDA-Agent提供了一种有效的数据增强方法，能够显著提升小型语言模型在领域特定任务上的性能，同时减少手动工作量。

Abstract: Small Language Models (SLMs) offer compelling advantages in deployment cost
and latency, but their accuracy often lags behind larger models, particularly
for complex domain-specific tasks. While supervised fine-tuning can help bridge
this performance gap, it requires substantial manual effort in data preparation
and iterative optimization. We present PaDA-Agent (Pattern-guided Data
Augmentation Agent), an evaluation-driven approach that streamlines the data
augmentation process for SLMs through coordinated operations. Unlike
state-of-the-art approaches that focus on model training errors only and
generating error-correcting samples, PaDA-Agent discovers failure patterns from
the validation data via evaluations and drafts targeted data augmentation
strategies aiming to directly reduce the generalization gap. Our experimental
results demonstrate significant improvements over state-of-the-art LLM-based
data augmentation approaches for Llama 3.2 1B Instruct model fine-tuning.

</details>


### [70] [Annotating the Chain-of-Thought: A Behavior-Labeled Dataset for AI Safety](https://arxiv.org/abs/2510.18154)
*Antonio-Gabriel Chacón Menke,Phan Xuan Tan,Eiji Kamioka*

Main category: cs.AI

TL;DR: 提出了一个句子级标注数据集，用于在LLM推理过程中基于激活的安全行为监控，填补了现有数据集仅整体标注推理的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本推理步骤的安全监控方法可能遗漏细微的有害模式，且可能被隐藏不安全推理的模型规避，需要更细粒度的安全行为监控。

Method: 构建包含句子级安全行为标注（如安全关切表达、用户意图推测）的数据集，并从中提取用于检测和影响这些行为的引导向量。

Result: 展示了该数据集的实用性，通过提取的表征能够在模型激活中检测和引导安全行为。

Conclusion: 激活级技术有潜力改善推理过程中的安全监督，为AI安全监控提供了新方法。

Abstract: Recent work has highlighted the importance of monitoring chain-of-thought
reasoning for AI safety; however, current approaches that analyze textual
reasoning steps can miss subtle harmful patterns and may be circumvented by
models that hide unsafe reasoning. We present a sentence-level labeled dataset
that enables activation-based monitoring of safety behaviors during LLM
reasoning. Our dataset contains reasoning sequences with sentence-level
annotations of safety behaviors such as expression of safety concerns or
speculation on user intent, which we use to extract steering vectors for
detecting and influencing these behaviors within model activations. The dataset
fills a key gap in safety research: while existing datasets label reasoning
holistically, effective application of steering vectors for safety monitoring
could be improved by identifying precisely when specific behaviors occur within
reasoning chains. We demonstrate the dataset's utility by extracting
representations that both detect and steer safety behaviors in model
activations, showcasing the potential of activation-level techniques for
improving safety oversight on reasoning.
  Content Warning: This paper discusses AI safety in the context of harmful
prompts and may contain references to potentially harmful content.

</details>


### [71] [Saber: An Efficient Sampling with Adaptive Acceleration and Backtracking Enhanced Remasking for Diffusion Language Model](https://arxiv.org/abs/2510.18165)
*Yihong Dong,Zhaoyu Ma,Xue Jiang,Zhiyuan Fan,Jiaru Qian,Yongmin Li,Jianha Xiao,Zhi Jin,Rongyu Cao,Binhua Li,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: 提出Saber算法，一种无需训练的新型采样方法，用于扩散语言模型在代码生成任务中平衡推理速度与输出质量。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在代码生成中存在推理速度与输出质量的关键权衡问题，减少采样步骤通常导致性能灾难性下降。

Method: Saber算法基于两个关键洞察：1）随着代码上下文的建立可以自适应加速；2）需要回溯机制来反转生成的标记。

Result: 在多个主流代码生成基准测试中，Saber相比主流DLM采样方法平均提升Pass@1准确率1.9%，同时实现平均251.4%的推理加速。

Conclusion: 通过利用DLM的固有优势，该工作显著缩小了与自回归模型在代码生成方面的性能差距。

Abstract: Diffusion language models (DLMs) are emerging as a powerful and promising
alternative to the dominant autoregressive paradigm, offering inherent
advantages in parallel generation and bidirectional context modeling. However,
the performance of DLMs on code generation tasks, which have stronger
structural constraints, is significantly hampered by the critical trade-off
between inference speed and output quality. We observed that accelerating the
code generation process by reducing the number of sampling steps usually leads
to a catastrophic collapse in performance. In this paper, we introduce
efficient Sampling with Adaptive acceleration and Backtracking Enhanced
Remasking (i.e., Saber), a novel training-free sampling algorithm for DLMs to
achieve better inference speed and output quality in code generation.
Specifically, Saber is motivated by two key insights in the DLM generation
process: 1) it can be adaptively accelerated as more of the code context is
established; 2) it requires a backtracking mechanism to reverse the generated
tokens. Extensive experiments on multiple mainstream code generation benchmarks
show that Saber boosts Pass@1 accuracy by an average improvement of 1.9% over
mainstream DLM sampling methods, meanwhile achieving an average 251.4%
inference speedup. By leveraging the inherent advantages of DLMs, our work
significantly narrows the performance gap with autoregressive models in code
generation.

</details>


### [72] [Local Coherence or Global Validity? Investigating RLVR Traces in Math Domains](https://arxiv.org/abs/2510.18176)
*Soumya Rani Samineni,Durgesh Kalwar,Vardaan Gangal,Siddhant Bhambri,Subbarao Kambhampati*

Main category: cs.AI

TL;DR: RLVR方法在LLM后训练中通常均匀处理所有token，缺乏对token级优势的考量。研究发现RL后训练提高了推理轨迹的局部一致性，但不一定产生有效或正确的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法主要基于最终答案正确性评估性能，但声称RL后训练能改善推理轨迹。这促使研究RL后训练对未直接激励的中间token的影响。

Method: 使用GRPO算法和Qwen-2.5-0.5B模型在GSM8K数据集上进行实验，引入基于一阶逻辑的轨迹一致性度量来评估推理步骤的一致性。

Result: RL后训练总体上提高了轨迹一致性，在基础模型失败但RL模型成功的问题上改进最显著。RL增强了局部一致性，但不一定产生有效或正确的解决方案。

Conclusion: 声称RL改善推理的主张需要谨慎对待，因为改进的轨迹一致性可能不会转化为完全有效的数学证明，局部一致性的提升不能保证最终答案正确性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR)-based post-training of
Large Language Models (LLMs) has been shown to improve accuracy on reasoning
tasks and continues to attract significant attention. Existing RLVR methods,
however, typically treat all tokens uniformly without accounting for
token-level advantages. These methods primarily evaluate performance based on
final answer correctness or Pass@K accuracy, and yet make claims about RL
post-training leading to improved reasoning traces. This motivates our
investigation into the effect of RL post-training on intermediate tokens which
are not directly incentivized. To study this, we design an experimental setup
using the GRPO algorithm with Qwen-2.5-0.5B model on the GSM8K dataset. We
introduce trace coherence, a First-Order Logic (FOL)-based measure to capture
the consistency of reasoning steps by identifying errors in the traces. We
distinguish between trace validity and trace coherence, noting that the former
implies logical soundness while the latter measures local coherence via lack of
errors. Our results show that RL post-training overall improves trace coherence
with the most significant gains on problems where the base model fails but the
RL model succeeds. Surprisingly, RL enhances local coherence without
necessarily producing valid or correct solutions. This highlights a crucial
distinction: improved local coherence in reasoning steps does not guarantee
final answer correctness. We argue that claims of improved reasoning via RL
must be examined with care, as these may be based on improved trace coherence,
which may not translate into fully valid mathematical proofs.

</details>


### [73] [FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo](https://arxiv.org/abs/2510.18193)
*Keivan Shariatmadar,Ahmad Osman,Ramin Ray,Usman Dildar,Kisam Kim*

Main category: cs.AI

TL;DR: FST.ai 2.0是一个可解释的AI生态系统，用于支持跆拳道比赛和训练中的实时决策，通过姿态识别、不确定性建模和可视化解释来提高裁判决策的公平性和透明度。


<details>
  <summary>Details</summary>
Motivation: 解决奥林匹克和残奥会格斗运动中公平、透明和可解释决策的挑战，提升裁判、教练和运动员在跆拳道比赛和训练中的决策支持。

Method: 集成基于姿态的动作识别（使用图卷积网络）、通过置信集进行认知不确定性建模、可视化解释叠加层，以及支持人机协作的交互式仪表板。

Result: 在比赛数据上的实验验证显示，决策审查时间减少了85%，裁判对AI辅助决策的信任度达到93%。

Conclusion: 该框架建立了一个透明且可扩展的管道，用于可信赖的数据驱动裁判和运动员评估，代表了在体育中实现公平、负责任和以人为本的AI的一步。

Abstract: Fair, transparent, and explainable decision-making remains a critical
challenge in Olympic and Paralympic combat sports. This paper presents
\emph{FST.ai 2.0}, an explainable AI ecosystem designed to support referees,
coaches, and athletes in real time during Taekwondo competitions and training.
The system integrates {pose-based action recognition} using graph convolutional
networks (GCNs), {epistemic uncertainty modeling} through credal sets, and
{explainability overlays} for visual decision support. A set of {interactive
dashboards} enables human--AI collaboration in referee evaluation, athlete
performance analysis, and Para-Taekwondo classification. Beyond automated
scoring, FST.ai~2.0 incorporates modules for referee training, fairness
monitoring, and policy-level analytics within the World Taekwondo ecosystem.
Experimental validation on competition data demonstrates an {85\% reduction in
decision review time} and {93\% referee trust} in AI-assisted decisions. The
framework thus establishes a transparent and extensible pipeline for
trustworthy, data-driven officiating and athlete assessment. By bridging
real-time perception, explainable inference, and governance-aware design,
FST.ai~2.0 represents a step toward equitable, accountable, and human-aligned
AI in sports.

</details>


### [74] [A Definition of AGI](https://arxiv.org/abs/2510.18212)
*Dan Hendrycks,Dawn Song,Christian Szegedy,Honglak Lee,Yarin Gal,Erik Brynjolfsson,Sharon Li,Andy Zou,Lionel Levine,Bo Han,Jie Fu,Ziwei Liu,Jinwoo Shin,Kimin Lee,Mantas Mazeika,Long Phan,George Ingebretsen,Adam Khoja,Cihang Xie,Olawale Salaudeen,Matthias Hein,Kevin Zhao,Alexander Pan,David Duvenaud,Bo Li,Steve Omohundro,Gabriel Alfour,Max Tegmark,Kevin McGrew,Gary Marcus,Jaan Tallinn,Eric Schmidt,Yoshua Bengio*

Main category: cs.AI

TL;DR: 该论文提出了一个可量化的AGI评估框架，基于Cattell-Horn-Carroll认知理论将通用智能分解为10个核心认知领域，并应用人类心理测量工具来评估AI系统。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏对人工通用智能(AGI)的具体定义，难以衡量当前专用AI与人类水平认知之间的差距，需要建立一个可量化的评估框架。

Method: 基于Cattell-Horn-Carroll认知理论，将通用智能分解为10个核心认知领域，并采用已建立的人类心理测量工具来评估AI系统的认知能力。

Result: 应用该框架发现当代AI模型具有高度"锯齿状"的认知特征，在知识密集型领域表现出色，但在基础认知机制（特别是长期记忆存储）方面存在严重缺陷。GPT-4得分为27%，GPT-5为58%。

Conclusion: 该框架能够具体量化AI系统的AGI水平，既显示了快速进展，也揭示了在实现AGI之前仍存在的显著差距。

Abstract: The lack of a concrete definition for Artificial General Intelligence (AGI)
obscures the gap between today's specialized AI and human-level cognition. This
paper introduces a quantifiable framework to address this, defining AGI as
matching the cognitive versatility and proficiency of a well-educated adult. To
operationalize this, we ground our methodology in Cattell-Horn-Carroll theory,
the most empirically validated model of human cognition. The framework dissects
general intelligence into ten core cognitive domains-including reasoning,
memory, and perception-and adapts established human psychometric batteries to
evaluate AI systems. Application of this framework reveals a highly "jagged"
cognitive profile in contemporary models. While proficient in
knowledge-intensive domains, current AI systems have critical deficits in
foundational cognitive machinery, particularly long-term memory storage. The
resulting AGI scores (e.g., GPT-4 at 27%, GPT-5 at 58%) concretely quantify
both rapid progress and the substantial gap remaining before AGI.

</details>


### [75] [ssToken: Self-modulated and Semantic-aware Token Selection for LLM Fine-tuning](https://arxiv.org/abs/2510.18250)
*Xiaohan Qin,Xiaoxing Wang,Ning Liao,Cancheng Zhang,Xiangdong Zhang,Mingquan Feng,Jingzhi Wang,Junchi Yan*

Main category: cs.AI

TL;DR: 提出ssToken方法，通过自调制损失差异和语义感知注意力机制进行token级数据选择，无需额外参考模型，在保持训练效率的同时提升SFT性能


<details>
  <summary>Details</summary>
Motivation: 现有token级选择方法需要额外参考模型且仅依赖损失信息，无法很好保留语义重要但损失不显著的token

Method: 使用历史模型计算token损失差异作为自调制信号，结合注意力机制估计语义重要性，实现自适应token选择

Result: 实验显示自调制选择和语义感知选择单独使用均优于全数据微调，两者结合进一步超越现有token级选择方法

Conclusion: ssToken通过自调制和语义感知的token选择实现了协同增益，在多个模型家族和规模上均取得性能提升

Abstract: Data quality plays a critical role in enhancing supervised fine-tuning (SFT)
for large language models (LLMs), and token-level data selection has emerged as
a promising direction for its fine-grained nature. Despite their strong
empirical performance, existing token-level selection methods share two key
limitations: (1) requiring training or accessing an additional reference model,
and (2) relying solely on loss information for token selection, which cannot
well preserve semantically important tokens that are not favored by loss-based
metrics. To address these challenges, we propose ssToken, a Self-modulated and
Semantic-aware Token Selection approach. ssToken leverages readily accessible
history models to compute the per-token loss difference with the current model,
which serves as a self-modulated signal that enables the model to adaptively
select tokens along its optimization trajectory, rather than relying on excess
loss from an offline-trained reference model as in prior works. We further
introduce a semantic-aware, attention-based token importance estimation metric,
orthogonal to loss-based selection and providing complementary semantic
information for more effective filtering. Extensive experiments across
different model families and scales demonstrate that both self-modulated
selection and semantic-aware selection alone outperform full-data fine-tuning,
while their integration--ssToken--achieves synergistic gains and further
surpasses prior token-level selection methods, delivering performance
improvements while maintaining training efficiency.

</details>


### [76] [Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning](https://arxiv.org/abs/2510.18254)
*Sion Weatherhead,Flora Salim,Aaron Belbasis*

Main category: cs.AI

TL;DR: 当前大语言模型的'反思'功能在开放但受规则约束的任务中效果有限，无法像人类那样进行目标驱动的主动监控和约束敏感的错误修复。


<details>
  <summary>Details</summary>
Motivation: 研究当前大语言模型的'反思'能力是否与人类反思推理功能等价，特别是在开放但受规则约束的任务中。

Method: 在八个前沿模型上测试一个简单的现实世界任务：生成有效的科学测试项目，然后在自我批评后进行修订。

Result: 首次尝试表现差（平均约1个有效项目），反思后只有适度提升（也约1个）。第二次尝试经常重复相同的约束违反，表明'纠正收益'主要来自偶然产生有效项目而非错误检测和原则性修复。

Conclusion: 当前LLM的'反思'缺乏人类那种主动、目标驱动的监控机制，可靠性能需要外部结构来强制执行约束。

Abstract: Humans do not just find mistakes after the fact -- we often catch them
mid-stream because 'reflection' is tied to the goal and its constraints.
Today's large language models produce reasoning tokens and 'reflective' text,
but is it functionally equivalent with human reflective reasoning? Prior work
on closed-ended tasks -- with clear, external 'correctness' signals -- can make
'reflection' look effective while masking limits in self-correction. We
therefore test eight frontier models on a simple, real-world task that is
open-ended yet rule-constrained, with auditable success criteria: to produce
valid scientific test items, then revise after considering their own critique.
First-pass performance is poor (often zero valid items out of 4 required; mean
$\approx$ 1), and reflection yields only modest gains (also $\approx$ 1).
Crucially, the second attempt frequently repeats the same violation of
constraint, indicating 'corrective gains' arise largely from chance production
of a valid item rather than error detection and principled,
constraint-sensitive repair. Performance before and after reflection
deteriorates as open-endedness increases, and models marketed for 'reasoning'
show no advantage. Our results suggest that current LLM 'reflection' lacks
functional evidence of the active, goal-driven monitoring that helps humans
respect constraints even on a first pass. Until such mechanisms are
instantiated in the model itself, reliable performance requires external
structure that enforces constraints.

</details>


### [77] [Genesis: Evolving Attack Strategies for LLM Web Agent Red-Teaming](https://arxiv.org/abs/2510.18314)
*Zheng Zhang,Jiarui He,Yuchen Cai,Deheng Ye,Peilin Zhao,Ruili Feng,Hao Wang*

Main category: cs.AI

TL;DR: Genesis是一个针对网络代理攻击的新型框架，通过遗传算法和混合策略表示生成对抗性注入，动态发现有效攻击策略并持续优化攻击效果。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型代理在复杂网络任务中的广泛应用，虽然提高了生产力但也带来了新的安全风险。现有红队方法主要依赖手动构建的攻击策略或离线训练的静态模型，难以捕捉网络代理的行为模式，无法适应多样化环境。

Method: 提出Genesis框架，包含三个模块：攻击者（使用遗传算法和混合策略表示生成对抗性注入）、评分器（评估目标网络代理的响应）、策略师（从交互日志中动态发现有效策略并构建持续增长的战略库）。

Result: 在各种网络任务上的广泛实验表明，该框架能够发现新颖策略，并始终优于现有的攻击基线方法。

Conclusion: Genesis框架通过动态策略发现和持续优化的方式，有效解决了网络代理攻击中的泛化问题，为网络代理安全研究提供了新思路。

Abstract: As large language model (LLM) agents increasingly automate complex web tasks,
they boost productivity while simultaneously introducing new security risks.
However, relevant studies on web agent attacks remain limited. Existing
red-teaming approaches mainly rely on manually crafted attack strategies or
static models trained offline. Such methods fail to capture the underlying
behavioral patterns of web agents, making it difficult to generalize across
diverse environments. In web agent attacks, success requires the continuous
discovery and evolution of attack strategies. To this end, we propose Genesis,
a novel agentic framework composed of three modules: Attacker, Scorer, and
Strategist. The Attacker generates adversarial injections by integrating the
genetic algorithm with a hybrid strategy representation. The Scorer evaluates
the target web agent's responses to provide feedback. The Strategist
dynamically uncovers effective strategies from interaction logs and compiles
them into a continuously growing strategy library, which is then re-deployed to
enhance the Attacker's effectiveness. Extensive experiments across various web
tasks show that our framework discovers novel strategies and consistently
outperforms existing attack baselines.

</details>


### [78] [Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning](https://arxiv.org/abs/2510.18318)
*Aaron Bell,Amit Aides,Amr Helmy,Arbaaz Muslim,Aviad Barzilai,Aviv Slobodkin,Bolous Jaber,David Schottlander,George Leifman,Joydeep Paul,Mimi Sun,Nadav Sherman,Natalie Williams,Per Bjornsson,Roy Lee,Ruth Alcantara,Thomas Turnbull,Tomer Shekel,Vered Silverman,Yotam Gigi,Adam Boulanger,Alex Ottenwess,Ali Ahmadalipour,Anna Carter,Charles Elliott,David Andre,Elad Aharoni,Gia Jung,Hassler Thurston,Jacob Bien,Jamie McPike,Juliet Rothenberg,Kartik Hegde,Kel Markert,Kim Philipp Jablonski,Luc Houriez,Monica Bharel,Phing VanLee,Reuven Sayag,Sebastian Pilarski,Shelley Cazares,Shlomi Pasternak,Siduo Jiang,Stone Jiang,Thomas Colthurst,Yang Chen,Yehonathan Refael,Yochai Blau,Yuval Carny,Yael Maguire,Avinatan Hassidim,James Manyika,Tim Thelin,Genady Beryozkin,Gautam Prasad,Luke Barrington,Yossi Matias,Niv Efron,Shravya Shetty*

Main category: cs.AI

TL;DR: Earth AI是一个地理空间AI模型家族，通过多领域基础模型和Gemini驱动的推理引擎，解决地理空间数据分析的挑战。


<details>
  <summary>Details</summary>
Motivation: 地理空间数据量大、多样且分辨率、时间尺度和稀疏性各异，给深入分析和解释带来重大挑战。

Method: 基于三个关键领域（全球尺度影像、人口、环境）的基础模型，结合Gemini驱动的智能推理引擎和多模型联合推理代理。

Result: 基准测试显示基础模型具有强大能力和新颖功能，多模型协同使用可提供互补价值并解锁更优预测能力。在真实危机场景基准测试中，代理能够提供关键及时的洞察。

Conclusion: Earth AI能够有效弥合原始地理空间数据与可操作理解之间的差距，为地球洞察提供新方法。

Abstract: Geospatial data offers immense potential for understanding our planet.
However, the sheer volume and diversity of this data along with its varied
resolutions, timescales, and sparsity pose significant challenges for thorough
analysis and interpretation. This paper introduces Earth AI, a family of
geospatial AI models and agentic reasoning that enables significant advances in
our ability to unlock novel and profound insights into our planet. This
approach is built upon foundation models across three key domains--Planet-scale
Imagery, Population, and Environment--and an intelligent Gemini-powered
reasoning engine. We present rigorous benchmarks showcasing the power and novel
capabilities of our foundation models and validate that when used together,
they provide complementary value for geospatial inference and their synergies
unlock superior predictive capabilities. To handle complex, multi-step queries,
we developed a Gemini-powered agent that jointly reasons over our multiple
foundation models along with large geospatial data sources and tools. On a new
benchmark of real-world crisis scenarios, our agent demonstrates the ability to
deliver critical and timely insights, effectively bridging the gap between raw
geospatial data and actionable understanding.

</details>


### [79] [ShortcutBreaker: Low-Rank Noisy Bottleneck with Global Perturbation Attention for Multi-Class Unsupervised Anomaly Detection](https://arxiv.org/abs/2510.18342)
*Peng Tang,Xiaoxiao Yan,Xiaobin Hu,Yuning Cui,Donghao Luo,Jiangning Zhang,Pengcheng Xu,Jinlong Peng,Qingdong He,Feiyue Huang,Song Xue,Tobias Lasser*

Main category: cs.AI

TL;DR: 提出了ShortcutBreaker框架，通过低秩噪声瓶颈和全局扰动注意力机制解决多类无监督异常检测中的身份捷径问题，在四个基准数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 多类无监督异常检测需要统一模型处理多个类别，但现有Transformer架构存在身份捷径问题，即直接复制输入到输出，导致正常和异常样本的重构误差差异缩小，难以区分。

Method: 1. 基于矩阵秩不等式设计低秩噪声瓶颈，将高维特征投影到低秩潜在空间，防止平凡身份复制；2. 利用ViT的全局建模能力，引入全局扰动注意力防止解码器中的信息捷径。

Result: 在四个基准数据集上取得优异性能：MVTec-AD(99.8%)、ViSA(98.9%)、Real-IAD(90.6%)和Universal Medical(87.8%)的图像级AUROC，均优于先前方法。

Conclusion: ShortcutBreaker通过有效解决身份捷径问题，在多类无监督异常检测任务中实现了卓越性能，为统一模型开发提供了有效解决方案。

Abstract: Multi-class unsupervised anomaly detection (MUAD) has garnered growing
research interest, as it seeks to develop a unified model for anomaly detection
across multiple classes, i.e., eliminating the need to train separate models
for distinct objects and thereby saving substantial computational resources.
Under the MUAD setting, while advanced Transformer-based architectures have
brought significant performance improvements, identity shortcuts persist: they
directly copy inputs to outputs, narrowing the gap in reconstruction errors
between normal and abnormal cases, and thereby making the two harder to
distinguish. Therefore, we propose ShortcutBreaker, a novel unified
feature-reconstruction framework for MUAD tasks, featuring two key innovations
to address the issue of shortcuts. First, drawing on matrix rank inequality, we
design a low-rank noisy bottleneck (LRNB) to project highdimensional features
into a low-rank latent space, and theoretically demonstrate its capacity to
prevent trivial identity reproduction. Second, leveraging ViTs global modeling
capability instead of merely focusing on local features, we incorporate a
global perturbation attention to prevent information shortcuts in the decoders.
Extensive experiments are performed on four widely used anomaly detection
benchmarks, including three industrial datasets (MVTec-AD, ViSA, and Real-IAD)
and one medical dataset (Universal Medical). The proposed method achieves a
remarkable image-level AUROC of 99.8%, 98.9%, 90.6%, and 87.8% on these four
datasets, respectively, consistently outperforming previous MUAD methods across
different scenarios.

</details>


### [80] [Memory-Augmented State Machine Prompting: A Novel LLM Agent Framework for Real-Time Strategy Games](https://arxiv.org/abs/2510.18395)
*Runnan Qi,Yanan Ni,Lumin Jiang,Zongyuan Li,Kuihua Huang,Xian Guo*

Main category: cs.AI

TL;DR: 提出Memory-Augmented State Machine Prompting (MASMP)框架，通过状态机提示和记忆机制解决LLM在实时策略游戏中的幻觉和决策碎片化问题，在星际争霸II中达到60%胜率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中LLM代理在实时策略游戏中存在的幻觉问题和决策碎片化问题，统一结构化动作与长期战术连贯性。

Method: 结合自然语言驱动的状态机架构（模拟有限状态机和行为树）和轻量级记忆模块（保存战略变量如战术、优先级单位）。

Result: 在星际争霸II实验中，MASMP对最强内置AI（Lv7）达到60%胜率，远超基线方法（0%）。案例研究显示该方法保持了LLM的语义理解能力，同时通过严格的状态-动作映射解决了"知行差距"问题。

Conclusion: 该工作为在复杂决策中结合神经和符号AI建立了新范式，实现了可解释性和类似FSM的可靠性。

Abstract: This paper proposes Memory-Augmented State Machine Prompting (MASMP), a novel
framework for LLM agents in real-time strategy games. Addressing key challenges
like hallucinations and fragmented decision-making in existing approaches,
MASMP integrates state machine prompting with memory mechanisms to unify
structured actions with long-term tactical coherence. The framework features:
(1) a natural language-driven state machine architecture that guides LLMs to
emulate finite state machines and behavior trees through prompts, and (2) a
lightweight memory module preserving strategic variables (e.g., tactics,
priority units) across decision cycles. Experiments in StarCraft II demonstrate
MASMP's 60% win rate against the hardest built-in AI (Lv7), vastly
outperforming baselines (0%). Case studies reveal the method retains LLMs'
semantic comprehension while resolving the "Knowing-Doing Gap" through strict
state-action mapping, achieving both interpretability and FSM-like reliability.
This work establishes a new paradigm for combining neural and symbolic AI in
complex decision-making.

</details>


### [81] [Heterogeneous Adversarial Play in Interactive Environments](https://arxiv.org/abs/2510.18407)
*Manjie Xu,Xinyi Yang,Jiayu Zhan,Wei Liang,Chi Zhang,Yixin Zhu*

Main category: cs.AI

TL;DR: 提出Heterogeneous Adversarial Play (HAP)框架，通过对抗性自动课程学习实现教师-学生协同进化，解决传统自博弈在非对称学习场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统自博弈方法依赖智能体对称性，在零和竞争环境中有效，但无法适应开放式的非对称学习场景。人类教学系统展示了非对称教学框架的优势，需要将其机制操作化到人工智能系统中。

Method: HAP将师生互动形式化为极小极大优化，任务生成教师和问题解决学生通过对抗动态协同进化。建立双向反馈系统，教师根据实时学习者表现重新校准任务复杂度。

Result: 在多任务学习领域的实验验证表明，该框架达到最先进基线的性能水平，同时生成的课程提高了人工智能代理和人类受试者的学习效率。

Conclusion: HAP框架成功实现了非对称自适应教学机制在人工智能系统中的操作化，为开放式学习提供了有效的自动课程生成方法。

Abstract: Self-play constitutes a fundamental paradigm for autonomous skill
acquisition, whereby agents iteratively enhance their capabilities through
self-directed environmental exploration. Conventional self-play frameworks
exploit agent symmetry within zero-sum competitive settings, yet this approach
proves inadequate for open-ended learning scenarios characterized by inherent
asymmetry. Human pedagogical systems exemplify asymmetric instructional
frameworks wherein educators systematically construct challenges calibrated to
individual learners' developmental trajectories. The principal challenge
resides in operationalizing these asymmetric, adaptive pedagogical mechanisms
within artificial systems capable of autonomously synthesizing appropriate
curricula without predetermined task hierarchies. Here we present Heterogeneous
Adversarial Play (HAP), an adversarial Automatic Curriculum Learning framework
that formalizes teacher-student interactions as a minimax optimization wherein
task-generating instructor and problem-solving learner co-evolve through
adversarial dynamics. In contrast to prevailing ACL methodologies that employ
static curricula or unidirectional task selection mechanisms, HAP establishes a
bidirectional feedback system wherein instructors continuously recalibrate task
complexity in response to real-time learner performance metrics. Experimental
validation across multi-task learning domains demonstrates that our framework
achieves performance parity with SOTA baselines while generating curricula that
enhance learning efficacy in both artificial agents and human subjects.

</details>


### [82] [Deep Learning-Based Control Optimization for Glass Bottle Forming](https://arxiv.org/abs/2510.18412)
*Mattia Pujatti,Andrea Di Luca,Nicola Peghini,Federico Monegaglia,Marco Cristoforetti*

Main category: cs.AI

TL;DR: 提出基于深度学习的控制算法，用于优化玻璃瓶制造中的成型过程，通过神经网络预测参数变化效果并确定最佳机器设置。


<details>
  <summary>Details</summary>
Motivation: 在玻璃瓶制造中，精确控制成型机器对于确保质量和减少缺陷至关重要。

Method: 使用实际生产数据训练神经网络，通过专门设计的反演机制识别实现所需玻璃料滴特性的最优机器设置。

Result: 在多个生产线的历史数据集上的实验结果显示，该方法取得了有希望的结果。

Conclusion: 深度学习在玻璃制造过程控制中具有增强工艺稳定性、减少浪费和提高产品一致性的潜力。

Abstract: In glass bottle manufacturing, precise control of forming machines is
critical for ensuring quality and minimizing defects. This study presents a
deep learning-based control algorithm designed to optimize the forming process
in real production environments. Using real operational data from active
manufacturing plants, our neural network predicts the effects of parameter
changes based on the current production setup. Through a specifically designed
inversion mechanism, the algorithm identifies the optimal machine settings
required to achieve the desired glass gob characteristics. Experimental results
on historical datasets from multiple production lines show that the proposed
method yields promising outcomes, suggesting potential for enhanced process
stability, reduced waste, and improved product consistency. These results
highlight the potential of deep learning to process control in glass
manufacturing.

</details>


### [83] [Med-VRAgent: A Framework for Medical Visual Reasoning-Enhanced Agents](https://arxiv.org/abs/2510.18424)
*Guangfu Guo,Xiaoqian Lu,Yue Feng*

Main category: cs.AI

TL;DR: 提出Med-VRAgent框架，结合视觉引导、自我奖励和蒙特卡洛树搜索，解决医学视觉语言模型中的幻觉、模糊描述等问题，并通过PPO微调进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型存在幻觉、模糊描述、逻辑不一致和定位能力差等问题，需要改进其医学视觉推理能力。

Method: 基于视觉引导和自我奖励范式，结合蒙特卡洛树搜索构建Med-VRAgent框架，并使用PPO目标对VLM进行微调。

Result: 在多个医学VQA基准测试中表现优于现有方法。

Conclusion: Med-VRAgent框架有效提升了医学视觉语言模型的推理能力，解决了幻觉等关键问题。

Abstract: Visual Language Models (VLMs) achieve promising results in medical reasoning
but struggle with hallucinations, vague descriptions, inconsistent logic and
poor localization. To address this, we propose a agent framework named Medical
Visual Reasoning Agent (\textbf{Med-VRAgent}). The approach is based on Visual
Guidance and Self-Reward paradigms and Monte Carlo Tree Search (MCTS). By
combining the Visual Guidance with tree search, Med-VRAgent improves the
medical visual reasoning capabilities of VLMs. We use the trajectories
collected by Med-VRAgent as feedback to further improve the performance by
fine-tuning the VLMs with the proximal policy optimization (PPO) objective.
Experiments on multiple medical VQA benchmarks demonstrate that our method
outperforms existing approaches.

</details>


### [84] [Automated urban waterlogging assessment and early warning through a mixture of foundation models](https://arxiv.org/abs/2510.18425)
*Chenxu Zhang,Fuxiang Huang,Lei Zhang*

Main category: cs.AI

TL;DR: UWAssess是一个基于基础模型的框架，通过监控图像自动识别积水区域并生成结构化评估报告，解决了传统人工监测方法的不足。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧导致城市内涝问题日益严重，现有监测方法依赖人工报告，无法提供及时全面的评估。

Method: 采用半监督微调策略和思维链提示策略，释放基础模型在数据稀缺下游任务中的潜力，结合多个基础模型的协作框架。

Result: 在视觉基准测试中感知性能显著提升，GPT评估确认能够生成准确描述积水范围、深度、风险和影响的可靠文本报告。

Conclusion: 该框架实现了从感知到生成的监测模式转变，为智能可扩展系统奠定了基础，支持城市管理、灾害响应和气候韧性建设。

Abstract: With climate change intensifying, urban waterlogging poses an increasingly
severe threat to global public safety and infrastructure. However, existing
monitoring approaches rely heavily on manual reporting and fail to provide
timely and comprehensive assessments. In this study, we present Urban
Waterlogging Assessment (UWAssess), a foundation model-driven framework that
automatically identifies waterlogged areas in surveillance images and generates
structured assessment reports. To address the scarcity of labeled data, we
design a semi-supervised fine-tuning strategy and a chain-of-thought (CoT)
prompting strategy to unleash the potential of the foundation model for
data-scarce downstream tasks. Evaluations on challenging visual benchmarks
demonstrate substantial improvements in perception performance. GPT-based
evaluations confirm the ability of UWAssess to generate reliable textual
reports that accurately describe waterlogging extent, depth, risk and impact.
This dual capability enables a shift of waterlogging monitoring from perception
to generation, while the collaborative framework of multiple foundation models
lays the groundwork for intelligent and scalable systems, supporting urban
management, disaster response and climate resilience.

</details>


### [85] [AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library](https://arxiv.org/abs/2510.18428)
*Minwei Kong,Ao Qu,Xiaotong Guo,Wenbin Ouyang,Chonghe Jiang,Han Zheng,Yining Ma,Dingyi Zhuang,Yuhan Tang,Junyi Li,Hai Wang,Cathy Wu,Jinhua Zhao*

Main category: cs.AI

TL;DR: AlphaOPT是一个自改进的经验库系统，让LLM能够从有限演示和求解器反馈中学习优化建模，无需标注推理轨迹或参数更新。


<details>
  <summary>Details</summary>
Motivation: 优化建模在行业中至关重要但难以自动化，现有LLM方法要么依赖脆弱的提示工程，要么需要昂贵的重新训练且泛化能力有限。

Method: 采用持续两阶段循环：库学习阶段从失败尝试中提取求解器验证的结构化见解；库演化阶段诊断检索偏差并改进存储见解的适用条件。

Result: 实验显示AlphaOPT随数据增加稳步改进（从100到300训练项，准确率从65%升至72%），在仅使用答案训练时在OptiBench数据集上比最强基线高出7.7%。

Conclusion: AlphaOPT能够高效地从有限演示中学习，通过更新库而非模型权重实现持续扩展，并使知识显式化和可解释。

Abstract: Optimization modeling enables critical decisions across industries but
remains difficult to automate: informal language must be mapped to precise
mathematical formulations and executable solver code. Prior LLM approaches
either rely on brittle prompting or costly retraining with limited
generalization. We present AlphaOPT, a self-improving experience library that
enables an LLM to learn from limited demonstrations (even answers alone,
without gold-standard programs) and solver feedback - without annotated
reasoning traces or parameter updates. AlphaOPT operates in a continual
two-phase cycle: (i) a Library Learning phase that reflects on failed attempts,
extracting solver-verified, structured insights as {taxonomy, condition,
explanation, example}; and (ii) a Library Evolution phase that diagnoses
retrieval misalignments and refines the applicability conditions of stored
insights, improving transfer across tasks. This design (1) learns efficiently
from limited demonstrations without curated rationales, (2) expands continually
without costly retraining by updating the library rather than model weights,
and (3) makes knowledge explicit and interpretable for human inspection and
intervention. Experiments show that AlphaOPT steadily improves with more data
(65% to 72% from 100 to 300 training items) and surpasses the strongest
baseline by 7.7% on the out-of-distribution OptiBench dataset when trained only
on answers. Code and data are available at:
https://github.com/Minw913/AlphaOPT.

</details>


### [86] [PlanU: Large Language Model Decision Making through Planning under Uncertainty](https://arxiv.org/abs/2510.18442)
*Ziwei Deng,Mian Deng,Chenjing Liang,Zeming Gao,Chennan Ma,Chenxing Lin,Haipeng Zhang,Songzhu Mei,Cheng Wang,Siqi Shen*

Main category: cs.AI

TL;DR: PlanU是一种基于LLM的规划方法，通过在蒙特卡洛树搜索中建模不确定性来解决LLM决策中的不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: LLM在不确定性下的决策任务中表现不佳，特别是在随机环境中规划行动时。现有方法要么只处理LLM不确定性而忽略环境不确定性，要么不适合多步决策任务。

Method: PlanU将MCTS中每个节点的回报建模为分位数分布，使用一组分位数表示回报分布。引入了带有好奇心的上置信界分数来平衡树搜索中的探索与利用。

Result: 通过大量实验验证了PlanU在不确定性下基于LLM的决策任务中的有效性。

Conclusion: PlanU成功解决了LLM决策中的不确定性挑战，特别是在随机环境中的多步决策任务。

Abstract: Large Language Models (LLMs) are increasingly being explored across a range
of decision-making tasks. However, LLMs sometimes struggle with decision-making
tasks under uncertainty that are relatively easy for humans, such as planning
actions in stochastic environments. The adoption of LLMs for decision-making is
impeded by uncertainty challenges, such as LLM uncertainty and environmental
uncertainty. LLM uncertainty arises from the stochastic sampling process
inherent to LLMs. Most LLM-based Decision-Making (LDM) approaches address LLM
uncertainty through multiple reasoning chains or search trees. However, these
approaches overlook environmental uncertainty, which leads to poor performance
in environments with stochastic state transitions. Some recent LDM approaches
deal with uncertainty by forecasting the probability of unknown variables.
However, they are not designed for multi-step decision-making tasks that
require interaction with the environment. To address uncertainty in LLM
decision-making, we introduce PlanU, an LLM-based planning method that captures
uncertainty within Monte Carlo Tree Search (MCTS). PlanU models the return of
each node in the MCTS as a quantile distribution, which uses a set of quantiles
to represent the return distribution. To balance exploration and exploitation
during tree search, PlanU introduces an Upper Confidence Bounds with Curiosity
(UCC) score which estimates the uncertainty of MCTS nodes. Through extensive
experiments, we demonstrate the effectiveness of PlanU in LLM-based
decision-making tasks under uncertainty.

</details>


### [87] [CircuitSeer: Mining High-Quality Data by Probing Mathematical Reasoning Circuits in LLMs](https://arxiv.org/abs/2510.18470)
*Shaobo Wang,Yongliang Miao,Yuancheng Liu,and Qianli Ma,Ning Liao,Linfeng Zhang*

Main category: cs.AI

TL;DR: CircuitSeer是一种基于模型内部注意力机制的数据选择方法，通过识别关键推理电路来选择高质量训练数据，在仅使用10%数据的情况下能超越全数据集训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法依赖昂贵的外部模型或不透明的启发式方法，而本文转向利用模型内部机制来评估数据质量。

Method: 发现复杂推理任务会激活稀疏的专用注意力头形成核心推理电路，CircuitSeer通过量化数据对这些关键电路的影响来衡量推理复杂度。

Result: 在4个模型和9个数据集上的实验显示，CircuitSeer显著优于现有方法。使用仅10%数据训练的Qwen2.5-Math-7B在平均Pass@1上比全数据集训练高出1.4个百分点。

Conclusion: CircuitSeer证明了利用模型内部机制进行数据选择的有效性，为高效训练大规模语言模型提供了新思路。

Abstract: Large language models (LLMs) have demonstrated impressive reasoning
capabilities, but scaling their performance often relies on massive reasoning
datasets that are computationally expensive to train on. Existing data
selection methods aim to curate smaller, high-quality subsets but often rely on
costly external models or opaque heuristics. In this work, we shift the focus
from external heuristics to the model's internal mechanisms. We find that
complex reasoning tasks consistently activate a sparse, specialized subset of
attention heads, forming core reasoning circuits. Building on this insight, we
propose CircuitSeer, a novel data selection method that quantifies the
reasoning complexity of data by measuring its influence on these crucial
circuits. Extensive experiments on 4 models and 9 datasets demonstrate
CircuitSeer's superiority. Notably, fine-tuning Qwen2.5-Math-7B on just 10% of
data selected by our method achieves a 1.4-point gain in average Pass@1 over
training on the full dataset, highlighting its efficiency and effectiveness.

</details>


### [88] [Probabilistic Modeling of Intentions in Socially Intelligent LLM Agents](https://arxiv.org/abs/2510.18476)
*Feifan Xia,Yuyang Fang,Defang Li,Yantong Xie,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang*

Main category: cs.AI

TL;DR: 提出了一个用于多轮社交对话中LLM智能体的概率意图建模框架，通过维护对伙伴潜在意图的信念分布来提升对话策略适应性。


<details>
  <summary>Details</summary>
Motivation: 在多轮社交对话中，LLM智能体需要理解伙伴的潜在意图以实现更有效的交互，现有方法缺乏对意图不确定性的建模。

Method: 框架维护伙伴潜在意图的信念分布，从上下文先验初始化，并在每轮对话后通过似然估计动态更新，为策略提供额外上下文基础。

Result: 在SOTOPIA环境中的初步实验显示：相比Qwen2.5-7B基线，总体得分在SOTOPIA-All上提升9.0%，在SOTOPIA-Hard上提升4.1%，甚至略微超过直接观察伙伴意图的oracle智能体。

Conclusion: 概率意图建模有助于开发具有社会智能的LLM智能体，能够有效处理对话中的不确定性并提升交互质量。

Abstract: We present a probabilistic intent modeling framework for large language model
(LLM) agents in multi-turn social dialogue. The framework maintains a belief
distribution over a partner's latent intentions, initialized from contextual
priors and dynamically updated through likelihood estimation after each
utterance. The evolving distribution provides additional contextual grounding
for the policy, enabling adaptive dialogue strategies under uncertainty.
Preliminary experiments in the SOTOPIA environment show consistent
improvements: the proposed framework increases the Overall score by 9.0% on
SOTOPIA-All and 4.1% on SOTOPIA-Hard compared with the Qwen2.5-7B baseline, and
slightly surpasses an oracle agent that directly observes partner intentions.
These early results suggest that probabilistic intent modeling can contribute
to the development of socially intelligent LLM agents.

</details>


### [89] [LAFA: Agentic LLM-Driven Federated Analytics over Decentralized Data Sources](https://arxiv.org/abs/2510.18477)
*Haichao Ji,Zibo Wang,Yifei Zhu,Meng han,Dan Wang,Zhu Han*

Main category: cs.AI

TL;DR: LAFA是首个将基于LLM代理的数据分析与联邦分析(FA)相结合的系统，通过分层多代理架构将自然语言查询转换为优化的可执行FA工作流，在保护隐私的同时支持自然语言输入。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM代理的分析框架假设集中式数据访问，缺乏隐私保护；而联邦分析(FA)支持隐私保护计算但需要结构化查询。需要结合两者优势，在保护隐私的同时支持自然语言输入。

Method: 提出分层多代理架构：粗粒度规划器分解复杂查询为子查询，细粒度规划器将子查询映射为FA操作的有向无环图(DAG)，优化代理重写和合并多个DAG以消除冗余操作。

Result: 实验表明LAFA持续优于基线提示策略，实现了更高的执行计划成功率，并显著减少了资源密集型的FA操作。

Conclusion: 这项工作为在FA设置中支持自然语言输入的隐私保护、LLM驱动的分析建立了实用基础。

Abstract: Large Language Models (LLMs) have shown great promise in automating data
analytics tasks by interpreting natural language queries and generating
multi-operation execution plans. However, existing LLM-agent-based analytics
frameworks operate under the assumption of centralized data access, offering
little to no privacy protection. In contrast, federated analytics (FA) enables
privacy-preserving computation across distributed data sources, but lacks
support for natural language input and requires structured, machine-readable
queries. In this work, we present LAFA, the first system that integrates
LLM-agent-based data analytics with FA. LAFA introduces a hierarchical
multi-agent architecture that accepts natural language queries and transforms
them into optimized, executable FA workflows. A coarse-grained planner first
decomposes complex queries into sub-queries, while a fine-grained planner maps
each subquery into a Directed Acyclic Graph of FA operations using prior
structural knowledge. To improve execution efficiency, an optimizer agent
rewrites and merges multiple DAGs, eliminating redundant operations and
minimizing computational and communicational overhead. Our experiments
demonstrate that LAFA consistently outperforms baseline prompting strategies by
achieving higher execution plan success rates and reducing resource-intensive
FA operations by a substantial margin. This work establishes a practical
foundation for privacy-preserving, LLM-driven analytics that supports natural
language input in the FA setting.

</details>


### [90] [StarBench: A Turn-Based RPG Benchmark for Agentic Multimodal Decision-Making and Information Seeking](https://arxiv.org/abs/2510.18483)
*Haoran Zhang,Chenhao Zhu,Sicong Guo,Hanzhe Guo,Haiming Li,Donglin Yu*

Main category: cs.AI

TL;DR: StarBench是一个基于《崩坏：星穹铁道》的回合制RPG基准测试，评估视觉语言模型在像素到动作的多模态决策和主动信息寻求两个人类能力方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在真实客户端中实现人类式游戏（将原始截图映射到时间一致的低级动作，同时决定何时寻求指导）仍是一个开放挑战。

Method: StarBench在八个战斗任务和两种控制模式下进行标准化评估：直接控制（仅接收截图并输出低级操作）和工具辅助控制（允许使用检测器和OCR输出）。还包括询问或行动诊断，测量代理选择请求指导的时机和影响。

Result: 结果显示在直接控制模式下感知到控制的保真度存在显著差距，而明智的信息寻求与改进的成功率相关。

Conclusion: StarBench为真实客户端游戏中的主动信息寻求和多模态决策提供了可复现的衡量标准。

Abstract: Human players do more than press buttons: they ground what they see on screen
into precise keyboard-mouse actions and, when stuck, they seek information
before trying again. We ask whether current vision-language models (VLMs) can
do the same. Despite encouraging results under simplified control or tool
scaffolds, human-like play in a real client - mapping raw screenshots to
temporally coherent low-level actions while deciding when to ask for guidance -
remains an open challenge. We introduce StarBench, a turn-based RPG benchmark
derived from Honkai: Star Rail that targets these two human-like competencies:
multimodal decision-making from pixels to actions and agentic information
seeking. StarBench standardizes evaluation across eight combat tasks and two
regimes with shared tasks and metrics: (i) direct control, where agents receive
only screenshots and must emit low-level primitives (click and keypress) with
no semantic hints; and (ii) tool-assisted control, where higher-level intents
can be mapped to primitives by detectors and OCR outputs provide optional
textualized observations to ease UI grounding. To mirror human practice,
StarBench also includes an ask-or-act diagnostic that measures whether and when
agents choose to request brief guidance before proceeding, and how that choice
affects subsequent performance. We report reference baselines for contemporary
VLMs and a human reference. Results expose sizable gaps in
perception-to-control fidelity in the direct regime, while showing that
judicious information seeking correlates with improved success, establishing
StarBench as a reproducible yardstick for agentic information seeking and
multimodal decision-making in real-client play.

</details>


### [91] [AndroidControl-Curated: Revealing the True Potential of GUI Agents through Benchmark Purification](https://arxiv.org/abs/2510.18488)
*Ho Fai Leung,Xiaoyan Xi,Fei Zuo*

Main category: cs.AI

TL;DR: 研究发现现有GUI代理基准测试AndroidControl存在缺陷，通过改进创建AndroidControl-Curated基准，使SOTA模型在复杂任务上的成功率从60%提升至75%。同时开发了仅需少量数据和计算资源的Magma-R1-3B模型，性能可与大200倍的模型媲美。


<details>
  <summary>Details</summary>
Motivation: 解决现有虚拟助手依赖刚性API的问题，以及GUI代理因基准测试缺陷而被低估性能的问题，推动设备端GUI代理的实际部署。

Method: 识别AndroidControl基准的模糊性和事实错误，通过严格净化流程改进为AndroidControl-Curated基准；使用仅2.4k精选样本和60小时H20 GPU训练Magma-R1-3B模型。

Result: 在改进后的基准上，SOTA模型在复杂任务上的成功率从约60%提升至近75%；Magma-R1-3B模型虽小200倍，但性能与Qwen3-VL-235B相当。

Conclusion: 设备端GUI代理的实际能力被低估，通过改进基准测试和高效模型训练，证明了GUI代理已接近实际部署水平，为开发稳健的设备端虚拟助手提供了新路径。

Abstract: On-device virtual assistants like Siri and Google Assistant are increasingly
pivotal, yet their capabilities are hamstrung by a reliance on rigid,
developer-dependent APIs. GUI agents offer a powerful, API-independent
alternative, but their adoption is hindered by the perception of poor
performance, as even the best models (e.g. Qwen3-VL-235B) scores are capped at
around 60% on benchmarks like AndroidControl, far from viability for real-world
use. Our research reveals that issue lies not only with the models but with the
benchmarks themselves. We identified notable shortcomings in AndroidControl,
including ambiguities and factual errors, which systematically underrates agent
capabilities. To address this critical oversight, we enhanced AndroidControl
into AndroidControl-Curated, a refined version of the benchmark improved
through a rigorous purification pipeline. On this enhanced benchmark,
state-of-the-art models achieve success rates nearing 75% on complex tasks (15%
improvement), reflecting that on-device GUI agents are actually closer to
practical deployment than previously thought. We introduce our new SOTA model,
Magma-R1- 3B, post-trained on just 2.4k curated samples using 60 hours of an
H20 GPU (approximately $60). Despite being 200 times smaller in parameters,
this model delivers performance comparable to Qwen3- VL-235B. We release both
AndroidControl-Curated benchmark and Magma-R1 model to the research community,
encouraging adoption of this enhanced benchmark to better reflect model
capabilities and accelerate the development of robust, on-device virtual
assistants.

</details>


### [92] [Crucible: Quantifying the Potential of Control Algorithms through LLM Agents](https://arxiv.org/abs/2510.18491)
*Lianchen Jia,Chaoyang Li,Qian Houde,Tianchi Huang,Jiangchuan Liu,Lifeng Sun*

Main category: cs.AI

TL;DR: 提出了Crucible框架，使用LLM驱动的多级专家模拟来评估算法的调优潜力，并定义了量化指标来系统评估不同算法的可调优空间。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注算法在理想或默认配置下的性能，忽略了调优潜力的关键方面，而生产环境中的控制算法通常需要领域专家针对特定场景进行参数和逻辑调优。

Method: 采用LLM驱动的多级专家模拟方法，通过模拟不同领域专家的调优过程来评估算法的调优潜力，并定义了形式化的量化指标。

Result: 在从经典控制任务到复杂计算机系统的广泛案例研究中验证了Crucible的有效性，并在真实部署中验证了其发现，结果显示Crucible能够系统量化不同算法的可调优空间。

Conclusion: Crucible为算法分析和设计提供了新的维度，最终能够带来性能改进，为算法调优潜力评估提供了系统化的解决方案。

Abstract: Control algorithms in production environments typically require domain
experts to tune their parameters and logic for specific scenarios. However,
existing research predominantly focuses on algorithmic performance under ideal
or default configurations, overlooking the critical aspect of Tuning Potential.
To bridge this gap, we introduce Crucible, an agent that employs an LLM-driven,
multi-level expert simulation to turn algorithms and defines a formalized
metric to quantitatively evaluate their Tuning Potential. We demonstrate
Crucible's effectiveness across a wide spectrum of case studies, from classic
control tasks to complex computer systems, and validate its findings in a
real-world deployment. Our experimental results reveal that Crucible
systematically quantifies the tunable space across different algorithms.
Furthermore, Crucible provides a new dimension for algorithm analysis and
design, which ultimately leads to performance improvements. Our code is
available at https://github.com/thu-media/Crucible.

</details>


### [93] [Counterfactual Reasoning for Steerable Pluralistic Value Alignment of Large Language Models](https://arxiv.org/abs/2510.18526)
*Hanze Guo,Jing Yao,Xiao Zhou,Xiaoyuan Yi,Xing Xie*

Main category: cs.AI

TL;DR: 提出了COUPLE框架，通过结构因果模型和反事实推理来解决大语言模型与多元人类价值观对齐的挑战，特别是在处理价值观复杂性和可引导性方面。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多元文化应用中的普及，需要超越平均原则（如HHH）与多元人类价值观对齐。现有方法难以处理价值观的相互依赖关系和优先级控制。

Method: 提出COUPLE框架，使用结构因果模型建模价值观间的复杂依赖关系和优先级，并通过反事实推理生成符合特定价值目标的输出。

Result: 在两个不同价值体系的数据集上评估，COUPLE在多种价值目标类型上都优于其他基线方法。

Conclusion: COUPLE通过显式因果建模有效解决了价值观对齐中的复杂性和可引导性问题，同时提供了更好的可解释性。

Abstract: As large language models (LLMs) become increasingly integrated into
applications serving users across diverse cultures, communities and
demographics, it is critical to align LLMs with pluralistic human values beyond
average principles (e.g., HHH). In psychological and social value theories such
as Schwartz's Value Theory, pluralistic values are represented by multiple
value dimensions paired with various priorities. However, existing methods
encounter two challenges when aligning with such fine-grained value objectives:
1) they often treat multiple values as independent and equally important,
ignoring their interdependence and relative priorities (value complexity); 2)
they struggle to precisely control nuanced value priorities, especially those
underrepresented ones (value steerability). To handle these challenges, we
propose COUPLE, a COUnterfactual reasoning framework for PLuralistic valuE
alignment. It introduces a structural causal model (SCM) to feature complex
interdependency and prioritization among features, as well as the causal
relationship between high-level value dimensions and behaviors. Moreover, it
applies counterfactual reasoning to generate outputs aligned with any desired
value objectives. Benefitting from explicit causal modeling, COUPLE also
provides better interpretability. We evaluate COUPLE on two datasets with
different value systems and demonstrate that COUPLE advances other baselines
across diverse types of value objectives.

</details>


### [94] [Physics-guided Emulators Reveal Resilience and Fragility under Operational Latencies and Outages](https://arxiv.org/abs/2510.18535)
*Sarth Dubey,Subimal Ghosh,Udit Bhatia*

Main category: cs.AI

TL;DR: 开发了一个可操作的GloFAS洪水预报模拟器，结合长短时记忆网络和松弛水量平衡约束，在数据延迟或缺失时仍能保持稳定性能。


<details>
  <summary>Details</summary>
Motivation: 当前水文洪水预报模型大多在理想数据条件下评估，强调准确性而非操作韧性。需要开发在输入数据延迟、缺失或不一致时仍能保持稳定的可靠预报系统。

Method: 使用长短时记忆网络耦合松弛水量平衡约束来保持物理一致性，设计了五种架构来模拟从完整数据到数据延迟和中断的各种信息可用性场景。在美国和印度5000多个流域进行训练和测试。

Result: 模拟器成功复制了GloFAS的水文核心功能，在信息质量下降时性能平滑退化。在不同水文气候和管理制度间的迁移产生了降低但仍保持物理一致性的性能。

Conclusion: 该框架将操作稳健性确立为水文机器学习可测量的属性，推进了可靠实时预报系统的设计，定义了在数据稀缺和人类影响下泛化的极限。

Abstract: Reliable hydrologic and flood forecasting requires models that remain stable
when input data are delayed, missing, or inconsistent. However, most advances
in rainfall-runoff prediction have been evaluated under ideal data conditions,
emphasizing accuracy rather than operational resilience. Here, we develop an
operationally ready emulator of the Global Flood Awareness System (GloFAS) that
couples long- and short-term memory networks with a relaxed water-balance
constraint to preserve physical coherence. Five architectures span a continuum
of information availability: from complete historical and forecast forcings to
scenarios with data latency and outages, allowing systematic evaluation of
robustness. Trained in minimally managed catchments across the United States
and tested in more than 5,000 basins, including heavily regulated rivers in
India, the emulator reproduces the hydrological core of GloFAS and degrades
smoothly as information quality declines. Transfer across contrasting
hydroclimatic and management regimes yields reduced yet physically consistent
performance, defining the limits of generalization under data scarcity and
human influence. The framework establishes operational robustness as a
measurable property of hydrological machine learning and advances the design of
reliable real-time forecasting systems.

</details>


### [95] [SOCIA-Nabla: Textual Gradient Meets Multi-Agent Orchestration for Automated Simulator Generation](https://arxiv.org/abs/2510.18551)
*Yuncheng Hua,Sion Weatherhead,Mehdi Jafari,Hao Xue,Flora D. Salim*

Main category: cs.AI

TL;DR: SOCIA-Nabla是一个端到端的智能体框架，将模拟器构建视为代码实例优化，通过文本计算图中的LLM驱动智能体和损失驱动循环实现代码合成、执行、评估和修复。


<details>
  <summary>Details</summary>
Motivation: 将脆弱的提示管道转换为可重现、约束感知的模拟器代码生成，实现跨领域和模拟粒度的扩展。

Method: 在文本计算图中嵌入专门的LLM驱动智能体作为图节点，工作流管理器执行损失驱动循环：代码合成→执行→评估→代码修复，优化器执行文本梯度下降(TGD)。

Result: 在三个CPS任务（用户建模、口罩采用和个人移动性）中达到最先进的整体准确率。

Conclusion: 通过统一多智能体编排与损失对齐的优化视角，SOCIA-Nabla实现了可扩展的模拟器代码生成，最小化专家工作量并保持代码作为可训练对象。

Abstract: In this paper, we present SOCIA-Nabla, an end-to-end, agentic framework that
treats simulator construction asinstance optimization over code within a
textual computation graph. Specialized LLM-driven agents are embedded as graph
nodes, and a workflow manager executes a loss-driven loop: code synthesis ->
execution -> evaluation -> code repair. The optimizer performs Textual-Gradient
Descent (TGD), while human-in-the-loop interaction is reserved for task-spec
confirmation, minimizing expert effort and keeping the code itself as the
trainable object. Across three CPS tasks, i.e., User Modeling, Mask Adoption,
and Personal Mobility, SOCIA-Nabla attains state-of-the-art overall accuracy.
By unifying multi-agent orchestration with a loss-aligned optimization view,
SOCIA-Nabla converts brittle prompt pipelines into reproducible,
constraint-aware simulator code generation that scales across domains and
simulation granularities. This work is under review, and we will release the
code soon.

</details>


### [96] [Extracting alignment data in open models](https://arxiv.org/abs/2510.18554)
*Federico Barbero,Xiangming Gu,Christopher A. Choquette-Choo,Chawin Sitawarin,Matthew Jagielski,Itay Yona,Petar Veličković,Ilia Shumailov,Jamie Hayes*

Main category: cs.AI

TL;DR: 研究表明可以从后训练模型中提取大量对齐训练数据，这些数据可用于改进模型的长上下文推理、安全性、指令遵循和数学能力。使用嵌入模型比传统字符串匹配方法能更有效地识别语义相似性。


<details>
  <summary>Details</summary>
Motivation: 揭示从后训练模型中提取对齐数据的可能性，暴露可能被忽视的数据提取风险，并探讨蒸馏实践的下游影响。

Method: 使用高质量嵌入模型测量字符串间的语义相似性，而非传统的近似字符串匹配方法，从后训练模型（如SFT或RL）中提取训练数据。

Result: 嵌入模型方法比字符串匹配多发现10倍的可提取数据，提取的数据可用于训练基础模型，恢复相当部分的原始性能。

Conclusion: 模型容易重现后训练阶段使用的数据，蒸馏实践可被视为间接在模型原始数据集上训练，这暴露了提取对齐数据的风险。

Abstract: In this work, we show that it is possible to extract significant amounts of
alignment training data from a post-trained model -- useful to steer the model
to improve certain capabilities such as long-context reasoning, safety,
instruction following, and maths. While the majority of related work on
memorisation has focused on measuring success of training data extraction
through string matching, we argue that embedding models are better suited for
our specific goals. Distances measured through a high quality embedding model
can identify semantic similarities between strings that a different metric such
as edit distance will struggle to capture. In fact, in our investigation,
approximate string matching would have severely undercounted (by a conservative
estimate of $10\times$) the amount of data that can be extracted due to trivial
artifacts that deflate the metric. Interestingly, we find that models readily
regurgitate training data that was used in post-training phases such as SFT or
RL. We show that this data can be then used to train a base model, recovering a
meaningful amount of the original performance. We believe our work exposes a
possibly overlooked risk towards extracting alignment data. Finally, our work
opens up an interesting discussion on the downstream effects of distillation
practices: since models seem to be regurgitating aspects of their training set,
distillation can therefore be thought of as indirectly training on the model's
original dataset.

</details>


### [97] [QuantEvolve: Automating Quantitative Strategy Discovery through Multi-Agent Evolutionary Framework](https://arxiv.org/abs/2510.18569)
*Junhyeog Yun,Hyoun Jun Lee,Insu Jeon*

Main category: cs.AI

TL;DR: QuantEvolve是一个结合质量-多样性优化和假设驱动策略生成的进化框架，用于自动化开发适应动态市场和个性化投资需求的量化交易策略。


<details>
  <summary>Details</summary>
Motivation: 动态市场中自动化开发量化交易策略具有挑战性，现有方法难以在探索广阔策略空间的同时保持多样性，而个性化投资解决方案的需求日益增长。

Method: 采用进化框架，结合质量-多样性优化和假设驱动的多智能体系统，通过特征映射（策略类型、风险特征、换手率、收益特性等）维护多样化有效策略集。

Result: 实证结果显示QuantEvolve优于传统基准方法，能够产生适应市场机制变化和个性化投资需求的多样化、复杂策略。

Conclusion: QuantEvolve框架有效解决了量化策略开发的挑战，发布了进化策略数据集以支持未来研究。

Abstract: Automating quantitative trading strategy development in dynamic markets is
challenging, especially with increasing demand for personalized investment
solutions. Existing methods often fail to explore the vast strategy space while
preserving the diversity essential for robust performance across changing
market conditions. We present QuantEvolve, an evolutionary framework that
combines quality-diversity optimization with hypothesis-driven strategy
generation. QuantEvolve employs a feature map aligned with investor
preferences, such as strategy type, risk profile, turnover, and return
characteristics, to maintain a diverse set of effective strategies. It also
integrates a hypothesis-driven multi-agent system to systematically explore the
strategy space through iterative generation and evaluation. This approach
produces diverse, sophisticated strategies that adapt to both market regime
shifts and individual investment needs. Empirical results show that QuantEvolve
outperforms conventional baselines, validating its effectiveness. We release a
dataset of evolved strategies to support future research.

</details>


### [98] [VAR: Visual Attention Reasoning via Structured Search and Backtracking](https://arxiv.org/abs/2510.18619)
*Wei Cai,Jian Zhao,Yuchen Yuan,Tianle Zhang,Ming Zhu,Haichuan Tang,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 提出VAR框架，通过结构化搜索和回溯机制解决MLLM的幻觉问题，在多个基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型的高幻觉倾向和脆弱的线性推理问题，提升复杂任务中的表现

Method: 将推理重构为结构化搜索过程，包含可追溯的证据基础和基于搜索的思维链生成，采用多维度奖励函数进行语义和几何自验证

Result: VAR-7B模型在幻觉和安全基准测试中创下新纪录，显著超越开源模型，与领先专有系统性能相当

Conclusion: VAR框架通过结构化搜索和自验证机制有效减少幻觉，为MLLM提供更可靠的推理能力

Abstract: Multimodal Large Language Models (MLLMs), despite their advances, are
hindered by their high hallucination tendency and heavy reliance on brittle,
linear reasoning processes, leading to failures in complex tasks. To address
these limitations, we introduce Visual Attention Reasoning (VAR), a novel
framework that recasts grounded reasoning as a structured search over a
reasoning trajectory space. VAR decomposes the reasoning process into two key
stages: traceable evidence grounding and search-based chain-of-thought (CoT)
generation, which incorporates a backtracking mechanism for self-correction.
The search is guided by a multi-faceted reward function with semantic and
geometric self-verification components, which penalize outputs that are not
faithfully grounded in the visual input. We provide a theoretical analysis for
our search strategy, validating its capability to find the correct solution
with high probability. Experimental results show that our 7B model, VAR-7B,
sets a new state-of-the-art on a comprehensive suite of hallucination and
safety benchmarks, significantly outperforming existing open-source models and
demonstrating competitive performance against leading proprietary systems.

</details>


### [99] [Leveraging Association Rules for Better Predictions and Better Explanations](https://arxiv.org/abs/2510.18628)
*Gilles Audemard,Sylvie Coste-Marquis,Pierre Marquis,Mehdi Sabiri,Nicolas Szczepanski*

Main category: cs.AI

TL;DR: 提出了一种结合数据和知识的分类方法，通过数据挖掘获取关联规则来提升树基模型的预测性能，并改善解释任务。


<details>
  <summary>Details</summary>
Motivation: 传统分类方法可能无法充分利用数据中的知识，需要结合数据挖掘得到的关联规则来提升模型性能和解释能力。

Method: 使用数据挖掘从数据中推导关联规则（可能包含否定），将这些规则融入决策树和随机森林等树基模型，用于分类任务和生成更一般的溯因解释。

Result: 实验表明，该方法能提高树基模型的预测性能，并生成更简洁的解释。

Conclusion: 结合数据挖掘得到的关联规则可以有效提升树基分类模型的预测性能和解释质量。

Abstract: We present a new approach to classification that combines data and knowledge.
In this approach, data mining is used to derive association rules (possibly
with negations) from data. Those rules are leveraged to increase the predictive
performance of tree-based models (decision trees and random forests) used for a
classification task. They are also used to improve the corresponding
explanation task through the generation of abductive explanations that are more
general than those derivable without taking such rules into account.
Experiments show that for the two tree-based models under consideration,
benefits can be offered by the approach in terms of predictive performance and
in terms of explanation sizes.

</details>


### [100] [Comparative Expressivity for Structured Argumentation Frameworks with Uncertain Rules and Premises](https://arxiv.org/abs/2510.18631)
*Carlo Proietti,Antonio Yuste-Ginel*

Main category: cs.AI

TL;DR: 本文研究了形式论证中定性不确定性的建模，比较了抽象和结构化模型的表达能力，提出了新的表达能力概念，并给出了负面和正面的表达能力结果。


<details>
  <summary>Details</summary>
Motivation: 在形式论证中建模定性不确定性对于实际应用和理论理解都很重要，但现有工作主要关注抽象模型。本文旨在研究这些抽象模型的合理实例化。

Method: 将论证的不确定性基于其组成部分（规则和前提），引入处理抽象和结构化形式主义的表达能力概念，比较抽象和结构化论证模型的表达能力。

Result: 提出了负面和正面的表达能力结果，影响了不完整抽象论证框架及其依赖扩展（抽象侧）和ASPIC+（结构化侧）。

Conclusion: 通过将论证不确定性基于其组成部分，为抽象模型提供了合理的实例化，并建立了抽象和结构化模型在表达能力上的比较框架。

Abstract: Modelling qualitative uncertainty in formal argumentation is essential both
for practical applications and theoretical understanding. Yet, most of the
existing works focus on \textit{abstract} models for arguing with uncertainty.
Following a recent trend in the literature, we tackle the open question of
studying plausible instantiations of these abstract models. To do so, we ground
the uncertainty of arguments in their components, structured within rules and
premises. Our main technical contributions are: i) the introduction of a notion
of expressivity that can handle abstract and structured formalisms, and ii) the
presentation of both negative and positive expressivity results, comparing the
expressivity of abstract and structured models of argumentation with
uncertainty. These results affect incomplete abstract argumentation frameworks,
and their extension with dependencies, on the abstract side, and ASPIC+, on the
structured side.

</details>


### [101] [Query Decomposition for RAG: Balancing Exploration-Exploitation](https://arxiv.org/abs/2510.18633)
*Roxana Petcu,Kenton Murray,Daniel Khashabi,Evangelos Kanoulas,Maarten de Rijke,Dawn Lawrie,Kevin Duh*

Main category: cs.AI

TL;DR: 本文提出了一种基于多臂老虎机框架的检索增强生成系统，通过动态选择信息最丰富的子查询来平衡检索的广度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统中在复杂用户请求分解时面临的关键权衡：既要充分检索相关文档，又要避免过多噪声和计算成本。

Method: 将查询分解和文档检索建模为利用-探索问题，使用各种老虎机学习方法动态选择最信息丰富的子查询，利用排名信息和人工判断估计文档相关性。

Result: 使用排名信息和人工判断估计文档相关性，实现了文档级精度35%的提升，α-nDCG指标15%的增长，并在长文本生成任务上表现更好。

Conclusion: 基于老虎机学习的动态子查询选择方法能有效平衡检索的广度和效率，显著提升RAG系统的性能。

Abstract: Retrieval-augmented generation (RAG) systems address complex user requests by
decomposing them into subqueries, retrieving potentially relevant documents for
each, and then aggregating them to generate an answer. Efficiently selecting
informative documents requires balancing a key trade-off: (i) retrieving
broadly enough to capture all the relevant material, and (ii) limiting
retrieval to avoid excessive noise and computational cost. We formulate query
decomposition and document retrieval in an exploitation-exploration setting,
where retrieving one document at a time builds a belief about the utility of a
given sub-query and informs the decision to continue exploiting or exploring an
alternative. We experiment with a variety of bandit learning methods and
demonstrate their effectiveness in dynamically selecting the most informative
sub-queries. Our main finding is that estimating document relevance using rank
information and human judgments yields a 35% gain in document-level precision,
15% increase in {\alpha}-nDCG, and better performance on the downstream task of
long-form generation.

</details>


### [102] [Sherlock Your Queries: Learning to Ask the Right Questions for Dialogue-Based Retrieval](https://arxiv.org/abs/2510.18659)
*Dong Yun,Marco Schouten,Dim Papadopoulos*

Main category: cs.AI

TL;DR: SherlockLLM是一个基于强化学习的对话驱动检索框架，通过生成二进制问题序列来高效缩小搜索空间，解决用户查询模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 信息检索中用户查询通常具有模糊性，现有对话式检索系统缺乏明确的提问策略来高效澄清用户意图。

Method: 使用强化学习训练代理生成二进制问题序列，无需大规模标注对话数据，能够学习最优提问策略。

Result: 在结构化任务中表现与强基线相当，接近二分搜索的理论最优；在非结构化任务中显著优于基线方法。

Conclusion: SherlockLLM是一个鲁棒高效的解决方案，能够学习高度有效的信息寻求对话策略。

Abstract: User queries in information retrieval are often ambiguous, making it
challenging for systems to identify a user's target from a single query. While
recent dialogue-based interactive retrieval systems can clarify user intent,
they are inefficient as they often lack an explicit strategy to ask the most
informative questions. To address this limitation, we propose SherlockLLM, a
dialogue-driven retrieval framework that learns an optimal questioning strategy
via Reinforcement Learning (RL) and avoids the need for large-scale annotated
dialogue data. In our framework, an agent is trained to generate a sequence of
binary questions to efficiently narrow down the search space. To validate our
approach, we introduce a benchmark with both structured and unstructured tasks.
Experimental results show that SherlockLLM is a robust and efficient solution.
On the structured tasks, its performance matches strong baselines and
approaches the theoretical optimal defined by binary search. On the challenging
unstructured task, our agent significantly outperforms these baselines,
showcasing its ability to learn a highly effective information-seeking dialogue
policy.

</details>


### [103] [Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation](https://arxiv.org/abs/2510.18751)
*Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh*

Main category: cs.AI

TL;DR: ALGOS系统结合遥感图像理解和严重程度估计，用于有害藻华监测，通过GeoSAM辅助人工评估和微调视觉语言模型，在分割和严重程度估计方面表现稳健。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧了有害藻华的发生，传统监测方法劳动密集且覆盖范围有限，需要可扩展的AI驱动解决方案。

Method: 集成GeoSAM辅助人工评估进行高质量分割掩码整理，并在NASA的蓝藻聚集手动标签数据集上微调视觉语言模型进行严重程度预测。

Result: ALGOS在分割和严重程度级别估计方面都实现了稳健性能。

Conclusion: 该系统为实用和自动化的蓝藻监测系统铺平了道路。

Abstract: Climate change is intensifying the occurrence of harmful algal bloom (HAB),
particularly cyanobacteria, which threaten aquatic ecosystems and human health
through oxygen depletion, toxin release, and disruption of marine biodiversity.
Traditional monitoring approaches, such as manual water sampling, remain
labor-intensive and limited in spatial and temporal coverage. Recent advances
in vision-language models (VLMs) for remote sensing have shown potential for
scalable AI-driven solutions, yet challenges remain in reasoning over imagery
and quantifying bloom severity. In this work, we introduce ALGae Observation
and Segmentation (ALGOS), a segmentation-and-reasoning system for HAB
monitoring that combines remote sensing image understanding with severity
estimation. Our approach integrates GeoSAM-assisted human evaluation for
high-quality segmentation mask curation and fine-tunes vision language model on
severity prediction using the Cyanobacteria Aggregated Manual Labels (CAML)
from NASA. Experiments demonstrate that ALGOS achieves robust performance on
both segmentation and severity-level estimation, paving the way toward
practical and automated cyanobacterial monitoring systems.

</details>


### [104] [Decoding Funded Research: Comparative Analysis of Topic Models and Uncovering the Effect of Gender and Geographic Location](https://arxiv.org/abs/2510.18803)
*Shirin Tavakoli Kafiabad,Andrea Schiffauerova,Ashkan Ebadi*

Main category: cs.AI

TL;DR: 本文通过比较LDA、STM和BERTopic三种主题建模方法，分析加拿大NSERC 18年的研究提案，发现BERTopic在识别细粒度主题方面表现最佳，并开发了COFFEE算法解决BERTopic的协变量分析问题。


<details>
  <summary>Details</summary>
Motivation: 优化国家科学投资需要了解研究趋势演变及人口地理因素影响，特别是在关注公平、多样性和包容性的背景下。

Method: 分析NSERC 2005-2022年研究提案，比较LDA、STM和BERTopic三种主题建模方法，并开发COFFEE算法用于BERTopic的协变量效应估计。

Result: 所有模型都能有效识别核心科学领域，但BERTopic在识别细粒度、连贯和新兴主题（如人工智能）方面表现更优；协变量分析揭示了省级研究专业化和基于性别的主题模式。

Conclusion: 研究结果为资助机构制定更公平有效的资助策略提供了实证基础，有助于提升科学生态系统的效率。

Abstract: Optimizing national scientific investment requires a clear understanding of
evolving research trends and the demographic and geographical forces shaping
them, particularly in light of commitments to equity, diversity, and inclusion.
This study addresses this need by analyzing 18 years (2005-2022) of research
proposals funded by the Natural Sciences and Engineering Research Council of
Canada (NSERC). We conducted a comprehensive comparative evaluation of three
topic modelling approaches: Latent Dirichlet Allocation (LDA), Structural Topic
Modelling (STM), and BERTopic. We also introduced a novel algorithm, named
COFFEE, designed to enable robust covariate effect estimation for BERTopic.
This advancement addresses a significant gap, as BERTopic lacks a native
function for covariate analysis, unlike the probabilistic STM. Our findings
highlight that while all models effectively delineate core scientific domains,
BERTopic outperformed by consistently identifying more granular, coherent, and
emergent themes, such as the rapid expansion of artificial intelligence.
Additionally, the covariate analysis, powered by COFFEE, confirmed distinct
provincial research specializations and revealed consistent gender-based
thematic patterns across various scientific disciplines. These insights offer a
robust empirical foundation for funding organizations to formulate more
equitable and impactful funding strategies, thereby enhancing the effectiveness
of the scientific ecosystem.

</details>
