{"id": "2601.16274", "categories": ["econ.EM", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2601.16274", "abs": "https://arxiv.org/abs/2601.16274", "authors": ["Alessio Brini", "Ekaterina Seregina"], "title": "A Nonlinear Target-Factor Model with Attention Mechanism for Mixed-Frequency Data", "comment": "64 pages, 7 figures", "summary": "We propose Mixed-Panels-Transformer Encoder (MPTE), a novel framework for estimating factor models in panel datasets with mixed frequencies and nonlinear signals. Traditional factor models rely on linear signal extraction and require homogeneous sampling frequencies, limiting their applicability to modern high-dimensional datasets where variables are observed at different temporal resolutions. Our approach leverages Transformer-style attention mechanisms to enable context-aware signal construction through flexible, data-dependent weighting schemes that replace fixed linear combinations with adaptive reweighting based on similarity and relevance. We extend classical principal component analysis (PCA) to accommodate general temporal and cross-sectional attention matrices, allowing the model to learn how to aggregate information across frequencies without manual alignment or pre-specified weights. For linear activation functions, we establish consistency and asymptotic normality of factor and loading estimators, showing that our framework nests Target PCA as a special case while providing efficiency gains through transfer learning across auxiliary datasets. The nonlinear extension uses a Transformer architecture to capture complex hierarchical interactions while preserving the theoretical foundations. In simulations, MPTE demonstrates superior performance in nonlinear environments, and in an empirical application to 13 macroeconomic forecasting targets using a selected set of 48 monthly and quarterly series from the FRED-MD and FRED-QD databases, our method achieves competitive performance against established benchmarks. We further analyze attention patterns and systematically ablate model components to assess variable importance and temporal dependence. The resulting patterns highlight which indicators and horizons are most influential for forecasting."}
{"id": "2601.16613", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.16613", "abs": "https://arxiv.org/abs/2601.16613", "authors": ["Kim Christensen", "Ulrich Hounyo", "Mark Podolskij"], "title": "Is the diurnal pattern sufficient to explain intraday variation in volatility? A nonparametric assessment", "comment": null, "summary": "In this paper, we propose a nonparametric way to test the hypothesis that time-variation in intraday volatility is caused solely by a deterministic and recurrent diurnal pattern. We assume that noisy high-frequency data from a discretely sampled jump-diffusion process are available. The test is then based on asset returns, which are deflated by the seasonal component and therefore homoskedastic under the null. To construct our test statistic, we extend the concept of pre-averaged bipower variation to a general Itô semimartingale setting via a truncation device. We prove a central limit theorem for this statistic and construct a positive semi-definite estimator of the asymptotic covariance matrix. The $t$-statistic (after pre-averaging and jump-truncation) diverges in the presence of stochastic volatility and has a standard normal distribution otherwise. We show that replacing the true diurnal factor with a model-free jump- and noise-robust estimator does not affect the asymptotic theory. A Monte Carlo simulation also shows this substitution has no discernable impact in finite samples. The test is, however, distorted by small infinite-activity price jumps. To improve inference, we propose a new bootstrap approach, which leads to almost correctly sized tests of the null hypothesis. We apply the developed framework to a large cross-section of equity high-frequency data and find that the diurnal pattern accounts for a rather significant fraction of intraday variation in volatility, but important sources of heteroskedasticity remain present in the data."}
{"id": "2601.16668", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.16668", "abs": "https://arxiv.org/abs/2601.16668", "authors": ["Kim Christensen", "Mark Podolskij", "Nopporn Thamrongrat", "Bezirgen Veliyev"], "title": "Inference from high-frequency data: A subsampling approach", "comment": null, "summary": "In this paper, we show how to estimate the asymptotic (conditional) covariance matrix, which appears in central limit theorems in high-frequency estimation of asset return volatility. We provide a recipe for the estimation of this matrix by subsampling; an approach that computes rescaled copies of the original statistic based on local stretches of high-frequency data, and then it studies the sampling variation of these. We show that our estimator is consistent both in frictionless markets and models with additive microstructure noise. We derive a rate of convergence for it and are also able to determine an optimal rate for its tuning parameters (e.g., the number of subsamples). Subsampling does not require an extra set of estimators to do inference, which renders it trivial to implement. As a variance-covariance matrix estimator, it has the attractive feature that it is positive semi-definite by construction. Moreover, the subsampler is to some extent automatic, as it does not exploit explicit knowledge about the structure of the asymptotic covariance. It therefore tends to adapt to the problem at hand and be robust against misspecification of the noise process. As such, this paper facilitates assessment of the sampling errors inherent in high-frequency estimation of volatility. We highlight the finite sample properties of the subsampler in a Monte Carlo study, while some initial empirical work demonstrates its use to draw feasible inference about volatility in financial markets."}
{"id": "2601.16865", "categories": ["econ.EM", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.16865", "abs": "https://arxiv.org/abs/2601.16865", "authors": ["Rowan Cherodian", "Guy Tchuente"], "title": "Distributional Instruments: Identification and Estimation with Quantile Least Squares", "comment": null, "summary": "We study instrumental-variable designs where policy reforms strongly shift the distribution of an endogenous variable but only weakly move its mean. We formalize this by introducing distributional relevance: instruments may be purely distributional. Within a triangular model, distributional relevance suffices for nonparametric identification of average structural effects via a control function. We then propose Quantile Least Squares (Q-LS), which aggregates conditional quantiles of X given Z into an optimal mean-square predictor and uses this projection as an instrument in a linear IV estimator. We establish consistency, asymptotic normality, and the validity of standard 2SLS variance formulas, and we discuss regularization across quantiles. Monte Carlo designs show that Q-LS delivers well-centered estimates and near-correct size when mean-based 2SLS suffers from weak instruments. In Health and Retirement Study data, Q-LS exploits Medicare Part D-induced distributional shifts in out-of-pocket risk to sharpen estimates of its effects on depression."}
{"id": "2601.16340", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2601.16340", "abs": "https://arxiv.org/abs/2601.16340", "authors": ["Zhentao Yu", "Jiaqi Ding", "Guorong Wu", "Quefeng Li"], "title": "Matrix-Response Generalized Linear Mixed Model with Applications to Longitudinal Brain Images", "comment": null, "summary": "Longitudinal brain imaging data facilitate the monitoring of structural and functional alterations in individual brains across time, offering essential understanding of dynamic neurobiological mechanisms. Such data improve sensitivity for detecting early biomarkers of disease progression and enhance the evaluation of intervention effects. While recent matrix-response regression models can relate static brain networks to external predictors, there remain few statistical methods for longitudinal brain networks, especially those derived from high-dimensional imaging data. We introduce a matrix-response generalized linear mixed model that accommodates longitudinal brain networks and identifies edges whose connectivity is influenced by external predictors. An efficient Monte Carlo Expectation-Maximization algorithm is developed for parameter estimation. Extensive simulations demonstrate effective identification of covariate-related network components and accurate parameter estimation. We further demonstrate the usage of the proposed method through applications to diffusion tensor imaging (DTI) and functional MRI (fMRI) datasets."}
{"id": "2601.16398", "categories": ["cs.CY", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.16398", "abs": "https://arxiv.org/abs/2601.16398", "authors": ["Hannah Cyberey", "Yangfeng Ji", "David Evans"], "title": "White-Box Sensitivity Auditing with Steering Vectors", "comment": null, "summary": "Algorithmic audits are essential tools for examining systems for properties required by regulators or desired by operators. Current audits of large language models (LLMs) primarily rely on black-box evaluations that assess model behavior only through input-output testing. These methods are limited to tests constructed in the input space, often generated by heuristics. In addition, many socially relevant model properties (e.g., gender bias) are abstract and difficult to measure through text-based inputs alone. To address these limitations, we propose a white-box sensitivity auditing framework for LLMs that leverages activation steering to conduct more rigorous assessments through model internals. Our auditing method conducts internal sensitivity tests by manipulating key concepts relevant to the model's intended function for the task. We demonstrate its application to bias audits in four simulated high-stakes LLM decision tasks. Our method consistently reveals substantial dependence on protected attributes in model predictions, even in settings where standard black-box evaluations suggest little or no bias. Our code is openly available at https://github.com/hannahxchen/llm-steering-audit"}
{"id": "2601.16280", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16280", "abs": "https://arxiv.org/abs/2601.16280", "authors": ["Donghao Huang", "Gauri Malwe", "Zhaoxia Wang"], "title": "When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems", "comment": "Accepted for publication in 2026 The 9th International Conference on Artificial Intelligence and Big Data (ICAIBD 2026)", "summary": "Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems."}
{"id": "2601.16233", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16233", "abs": "https://arxiv.org/abs/2601.16233", "authors": ["Akseli Kangaslahti", "Davin Choo", "Lingkai Kong", "Milind Tambe", "Alastair van Heerden", "Cheryl Johnson"], "title": "Policy-Embedded Graph Expansion: Networked HIV Testing with Diffusion-Driven Network Samples", "comment": null, "summary": "HIV is a retrovirus that attacks the human immune system and can lead to death without proper treatment. In collaboration with the WHO and Wits University, we study how to improve the efficiency of HIV testing with the goal of eventual deployment, directly supporting progress toward UN Sustainable Development Goal 3.3. While prior work has demonstrated the promise of intelligent algorithms for sequential, network-based HIV testing, existing approaches rely on assumptions that are impractical in our real-world implementations. Here, we study sequential testing on incrementally revealed disease networks and introduce Policy-Embedded Graph Expansion (PEGE), a novel framework that directly embeds a generative distribution over graph expansions into the decision-making policy rather than attempting explicit topological reconstruction. We further propose Dynamics-Driven Branching (DDB), a diffusion-based graph expansion model that supports decision making in PEGE and is designed for data-limited settings where forest structures arise naturally, as in our real-world referral process. Experiments on real HIV transmission networks show that the combined approach (PEGE + DDB) consistently outperforms existing baselines (e.g., 13% improvement in discounted reward and 9% more HIV detections with 25% of the population tested) and explore key tradeoffs that drive decision quality."}
{"id": "2601.16233", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16233", "abs": "https://arxiv.org/abs/2601.16233", "authors": ["Akseli Kangaslahti", "Davin Choo", "Lingkai Kong", "Milind Tambe", "Alastair van Heerden", "Cheryl Johnson"], "title": "Policy-Embedded Graph Expansion: Networked HIV Testing with Diffusion-Driven Network Samples", "comment": null, "summary": "HIV is a retrovirus that attacks the human immune system and can lead to death without proper treatment. In collaboration with the WHO and Wits University, we study how to improve the efficiency of HIV testing with the goal of eventual deployment, directly supporting progress toward UN Sustainable Development Goal 3.3. While prior work has demonstrated the promise of intelligent algorithms for sequential, network-based HIV testing, existing approaches rely on assumptions that are impractical in our real-world implementations. Here, we study sequential testing on incrementally revealed disease networks and introduce Policy-Embedded Graph Expansion (PEGE), a novel framework that directly embeds a generative distribution over graph expansions into the decision-making policy rather than attempting explicit topological reconstruction. We further propose Dynamics-Driven Branching (DDB), a diffusion-based graph expansion model that supports decision making in PEGE and is designed for data-limited settings where forest structures arise naturally, as in our real-world referral process. Experiments on real HIV transmission networks show that the combined approach (PEGE + DDB) consistently outperforms existing baselines (e.g., 13% improvement in discounted reward and 9% more HIV detections with 25% of the population tested) and explore key tradeoffs that drive decision quality."}
{"id": "2601.16347", "categories": ["stat.AP", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.16347", "abs": "https://arxiv.org/abs/2601.16347", "authors": ["Erika McPhillips", "Hyeongseong Lee", "Xiangyu Xie", "Kathy Baylis", "Chris Funk", "Mengyang Gu"], "title": "Long-Term Probabilistic Forecast of Vegetation Conditions Using Climate Attributes in the Four Corners Region", "comment": null, "summary": "Weather conditions can drastically alter the state of crops and rangelands, and in turn, impact the incomes and food security of individuals worldwide. Satellite-based remote sensing offers an effective way to monitor vegetation and climate variables on regional and global scales. The annual peak Normalized Difference Vegetation Index (NDVI), derived from satellite observations, is closely associated with crop development, rangeland biomass, and vegetation growth. Although various machine learning methods have been developed to forecast NDVI over short time ranges, such as one-month-ahead predictions, long-term forecasting approaches, such as one-year-ahead predictions of vegetation conditions, are not yet available. To fill this gap, we develop a two-phase machine learning model to forecast the one-year-ahead peak NDVI over high-resolution grids, using the Four Corners region of the Southwestern United States as a testbed. In phase one, we identify informative climate attributes, including precipitation and maximum vapor pressure deficit, and develop the generalized parallel Gaussian process that captures the relationship between climate attributes and NDVI. In phase two, we forecast these climate attributes using historical data at least one year before the NDVI prediction month, which then serve as inputs to forecast the peak NDVI at each spatial grid. We developed open-source tools that outperform alternative methods for both gross NDVI and grid-based NDVI one-year forecasts, providing information that can help farmers and ranchers make actionable plans a year in advance."}
{"id": "2601.16513", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.16513", "abs": "https://arxiv.org/abs/2601.16513", "authors": ["Melissa Wilfley", "Mengting Ai", "Madelyn Rose Sanfilippo"], "title": "Competing Visions of Ethical AI: A Case Study of OpenAI", "comment": "iConference 2026", "summary": "Introduction. AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Method. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment' and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assembled from public documentation. Analysis. Qualitative content analysis of ethical themes combined inductively derived and deductively applied codes. Quantitative analysis leveraged computational content analysis methods via NLP to model topics and quantify changes in rhetoric over time. Visualizations report aggregate results. For reproducible results, we have released our code at https://github.com/famous-blue-raincoat/AI_Ethics_Discourse. Results. Results indicate that safety and risk discourse dominate OpenAI's public communication and documentation, without applying academic and advocacy ethics frameworks or vocabularies. Conclusions. Implications for governance are presented, along with discussion of ethics-washing practices in industry."}
{"id": "2601.16286", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.16286", "abs": "https://arxiv.org/abs/2601.16286", "authors": ["Varun Chillara", "Dylan Kline", "Christopher Alvares", "Evan Wooten", "Huan Yang", "Shlok Khetan", "Cade Bauer", "Tré Guillory", "Tanishka Shah", "Yashodhara Dhariwal", "Volodymyr Pavlov", "George Popstefanov"], "title": "SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems", "comment": null, "summary": "Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.\n  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.\n  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable."}
{"id": "2601.16236", "categories": ["cs.SI", "cs.DM", "math.PR", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.16236", "abs": "https://arxiv.org/abs/2601.16236", "authors": ["G. Exarchakos", "R. van der Hofstad", "O. Nagy", "M. Pandey"], "title": "Bringing order to network centrality measures", "comment": "24 pages", "summary": "We introduce a quantitative method to compare arbitrary pairs of graph centrality measures, based on the ordering of vertices induced by them. The proposed method is conceptually simple, mathematically elegant, and allows for a quantitative restatement of many conjectures that were previously cumbersome to formalize. Moreover, it produces an approximation scheme useful for network scientists. We explore some of these uses and formulate new conjectures that are of independent interest."}
{"id": "2601.16236", "categories": ["cs.SI", "cs.DM", "math.PR", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.16236", "abs": "https://arxiv.org/abs/2601.16236", "authors": ["G. Exarchakos", "R. van der Hofstad", "O. Nagy", "M. Pandey"], "title": "Bringing order to network centrality measures", "comment": "24 pages", "summary": "We introduce a quantitative method to compare arbitrary pairs of graph centrality measures, based on the ordering of vertices induced by them. The proposed method is conceptually simple, mathematically elegant, and allows for a quantitative restatement of many conjectures that were previously cumbersome to formalize. Moreover, it produces an approximation scheme useful for network scientists. We explore some of these uses and formulate new conjectures that are of independent interest."}
{"id": "2601.16837", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2601.16837", "abs": "https://arxiv.org/abs/2601.16837", "authors": ["Edoardo Otranto", "Luca Scaffidi Domianello"], "title": "Spillovers and Co-movements in Multivariate Volatility: A Vector Multiplicative Error Model", "comment": "24 pages, 4 figures", "summary": "Recent developments in financial time series focus on modeling volatility across multiple assets or indices in a multivariate framework, accounting for potential interactions such as spillover effects. Furthermore, the increasing integration of global financial markets provides a similar dynamics (referred to as comovement). In this context, we introduce a novel model for volatility vectors within the Multiplicative Error Model (MEM) class. This framework accommodates both spillover and co-movement effects through a distinct latent component. By adopting a specific parameterization, the model remains computationally feasible even for high-dimensional volatility vectors. To reduce the number of unknown coefficients, we propose a simple model-based clustering procedure. We illustrate the effectiveness of the proposed approach through an empirical application to 29 assets of the Dow Jones Industrial Average index, providing insight into volatility spillovers and shared market dynamics. Comparative analysis against alternative vector MEMs, including a fully parameterized version of the proposed model, demonstrates its superior or at least comparable performance across multiple evaluation criteria."}
{"id": "2601.16926", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.16926", "abs": "https://arxiv.org/abs/2601.16926", "authors": ["Shashank Prakash", "Ranjitha Prasad", "Avinash Agarwal"], "title": "Nishpaksh: TEC Standard-Compliant Framework for Fairness Auditing and Certification of AI Models", "comment": "Accepted and presented at 2026 18th International Conference on COMmunication Systems and NETworks (COMSNETS)", "summary": "The growing reliance on Artificial Intelligence (AI) models in high-stakes decision-making systems, particularly within emerging telecom and 6G applications, underscores the urgent need for transparent and standardized fairness assessment frameworks. While global toolkits such as IBM AI Fairness 360 and Microsoft Fairlearn have advanced bias detection, they often lack alignment with region-specific regulatory requirements and national priorities. To address this gap, we propose Nishpaksh, an indigenous fairness evaluation tool that operationalizes the Telecommunication Engineering Centre (TEC) Standard for the Evaluation and Rating of Artificial Intelligence Systems. Nishpaksh integrates survey-based risk quantification, contextual threshold determination, and quantitative fairness evaluation into a unified, web-based dashboard. The tool employs vectorized computation, reactive state management, and certification-ready reporting to enable reproducible, audit-grade assessments, thereby addressing a critical post-standardization implementation need. Experimental validation on the COMPAS dataset demonstrates Nishpaksh's effectiveness in identifying attribute-specific bias and generating standardized fairness scores compliant with the TEC framework. The system bridges the gap between research-oriented fairness methodologies and regulatory AI governance in India, marking a significant step toward responsible and auditable AI deployment within critical infrastructure like telecommunications."}
{"id": "2601.16344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16344", "abs": "https://arxiv.org/abs/2601.16344", "authors": ["Fan Nie", "Junlin Wang", "Harper Hua", "Federico Bianchi", "Yongchan Kwon", "Zhenting Qi", "Owen Queen", "Shang Zhu", "James Zou"], "title": "DSGym: A Holistic Framework for Evaluating and Training Data Science Agents", "comment": null, "summary": "Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context."}
{"id": "2601.16280", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16280", "abs": "https://arxiv.org/abs/2601.16280", "authors": ["Donghao Huang", "Gauri Malwe", "Zhaoxia Wang"], "title": "When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems", "comment": "Accepted for publication in 2026 The 9th International Conference on Artificial Intelligence and Big Data (ICAIBD 2026)", "summary": "Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems."}
{"id": "2601.16372", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16372", "abs": "https://arxiv.org/abs/2601.16372", "authors": ["Hyunuk Shin", "Hojin Kim", "Chanyoung Lee", "Yeon-Chang Lee", "David Yoon Suk Kang"], "title": "Improving the Accuracy of Community Detection on Signed Networks via Community Refinement and Contrastive Learning", "comment": null, "summary": "Community detection (CD) on signed networks is crucial for understanding how positive and negative relations jointly shape network structure. However, existing CD methods often yield inconsistent communities due to noisy or conflicting edge signs. In this paper, we propose ReCon, a model-agnostic post-processing framework that progressively refines community structures through four iterative steps: (1) structural refinement, (2) boundary refinement, (3) contrastive learning, and (4) clustering. Extensive experiments on eighteen synthetic and four real-world networks using four CD methods demonstrate that ReCon consistently enhances community detection accuracy, serving as an effective and easily integrable solution for reliable CD across diverse network properties."}
{"id": "2601.16932", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2601.16932", "abs": "https://arxiv.org/abs/2601.16932", "authors": ["Hyojung Jang", "Peter M. Graffy", "Benjamin W. Barrett", "Daniel E. Horton", "Jennifer L. Chan", "Abel N. Kho"], "title": "Identifying heat-related diagnoses in emergency department visits among adults in Chicago: a heat-wide association study", "comment": null, "summary": "Extreme heat is an escalating public health concern. Although prior studies have examined heat-health associations, their reliance on restricted diagnoses and diagnostic categories misses or misclassifies heat-related illness. We conducted a heat-wide association study to identify acute-care diagnoses associated with extreme heat in Chicago, Illinois. Using 916,904 acute-care visits -- including emergency department and urgent care encounters -- among 372,140 adults across five healthcare systems from 2011-2023, we applied a two-stage analytic approach: quasi-Poisson regression to screen 1,803 diagnosis codes for heat-related risks, followed by distributed lag non-linear models in a time-stratified case-crossover design to refine the list of heat-related diagnoses and estimate same-day and short-term cumulative odds ratios of acute-care visits during extreme heat versus reference temperature. We observed same-day increases in visits for heat illness, volume depletion, hypotension, edema, acute kidney failure, and multiple injuries. By analyzing the full diagnostic spectrum of acute-care services, this study comprehensively characterizes heat-associated morbidity, reinforcing and advancing existing literature."}
{"id": "2601.16930", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.16930", "abs": "https://arxiv.org/abs/2601.16930", "authors": ["Javed I. Khan", "Sharmila Rahman Prithula"], "title": "In Quest of an Extensible Multi-Level Harm Taxonomy for Adversarial AI: Heart of Security, Ethical Risk Scoring and Resilience Analytics", "comment": "Manuscript accepted for presentation at the 12th International Conference on Computational Science and Computational Intelligence (CSCI 2025), Las Vegas, NV, USA, December 2025. Proceedings to be published by Springer Nature (2026)", "summary": "Harm is invoked everywhere from cybersecurity, ethics, risk analysis, to adversarial AI, yet there exists no systematic or agreed upon list of harms, and the concept itself is rarely defined with the precision required for serious analysis. Current discourse relies on vague, under specified notions of harm, rendering nuanced, structured, and qualitative assessment effectively impossible. This paper challenges that gap directly. We introduce a structured and expandable taxonomy of harms, grounded in an ensemble of contemporary ethical theories, that makes harm explicit, enumerable, and analytically tractable. The proposed framework identifies 66+ distinct harm types, systematically organized into two overarching domains human and nonhuman, and eleven major categories, each explicitly aligned with eleven dominant ethical theories. While extensible by design, the upper levels are intentionally stable. Beyond classification, we introduce a theory-aware taxonomy of victim entities and formalize normative harm attributes, including reversibility and duration that materially alter ethical severity. Together, these contributions transform harm from a rhetorical placeholder into an operational object of analysis, enabling rigorous ethical reasoning and long term safety evaluation of AI systems and other sociotechnical domains where harm is a first order concern."}
{"id": "2601.16479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16479", "abs": "https://arxiv.org/abs/2601.16479", "authors": ["Hongjia Wu", "Shuai Zhou", "Hongxin Zhang", "Wei Chen"], "title": "Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs", "comment": null, "summary": "While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an \"expert bottleneck\" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy."}
{"id": "2601.16286", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.16286", "abs": "https://arxiv.org/abs/2601.16286", "authors": ["Varun Chillara", "Dylan Kline", "Christopher Alvares", "Evan Wooten", "Huan Yang", "Shlok Khetan", "Cade Bauer", "Tré Guillory", "Tanishka Shah", "Yashodhara Dhariwal", "Volodymyr Pavlov", "George Popstefanov"], "title": "SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems", "comment": null, "summary": "Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.\n  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.\n  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable."}
{"id": "2601.16457", "categories": ["cs.SI", "cs.IR", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.16457", "abs": "https://arxiv.org/abs/2601.16457", "authors": ["Junning Zhao", "Kazutoshi Sasahara", "Yu Chen"], "title": "Segregation Before Polarization: How Recommendation Strategies Shape Echo Chamber Pathways", "comment": "13 pages, 5 figures for main text; 7 pages, 6 figures for supplementary materials", "summary": "Social media platforms facilitate echo chambers through feedback loops between user preferences and recommendation algorithms. While algorithmic homogeneity is well-documented, the distinct evolutionary pathways driven by content-based versus link-based recommendations remain unclear. Using an extended dynamic Bounded Confidence Model (BCM), we show that content-based algorithms--unlike their link-based counterparts--steer social networks toward a segregation-before-polarization (SbP) pathway. Along this trajectory, structural segregation precedes opinion divergence, accelerating individual isolation while delaying but ultimately intensifying collective polarization. Furthermore, we reveal a paradox in information sharing: Reposting increases the number of connections in the network, yet it simultaneously reinforces echo chambers because it amplifies small, latent opinion differences that would otherwise remain inconsequential. These findings suggest that mitigating polarization requires stage-dependent algorithmic interventions, shifting from content-centric to structure-centric strategies as networks evolve."}
{"id": "2601.16865", "categories": ["econ.EM", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.16865", "abs": "https://arxiv.org/abs/2601.16865", "authors": ["Rowan Cherodian", "Guy Tchuente"], "title": "Distributional Instruments: Identification and Estimation with Quantile Least Squares", "comment": null, "summary": "We study instrumental-variable designs where policy reforms strongly shift the distribution of an endogenous variable but only weakly move its mean. We formalize this by introducing distributional relevance: instruments may be purely distributional. Within a triangular model, distributional relevance suffices for nonparametric identification of average structural effects via a control function. We then propose Quantile Least Squares (Q-LS), which aggregates conditional quantiles of X given Z into an optimal mean-square predictor and uses this projection as an instrument in a linear IV estimator. We establish consistency, asymptotic normality, and the validity of standard 2SLS variance formulas, and we discuss regularization across quantiles. Monte Carlo designs show that Q-LS delivers well-centered estimates and near-correct size when mean-based 2SLS suffers from weak instruments. In Health and Retirement Study data, Q-LS exploits Medicare Part D-induced distributional shifts in out-of-pocket risk to sharpen estimates of its effects on depression."}
{"id": "2601.16529", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.16529", "abs": "https://arxiv.org/abs/2601.16529", "authors": ["Dongshen Peng", "Yi Wang", "Carl Preiksaitis", "Christian Rose"], "title": "SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care", "comment": "11 pages, 5 figures", "summary": "Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\\%. Models showed higher vulnerability to imaging requests (38.8\\%) than opioid prescriptions (25.0\\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification."}
{"id": "2601.16344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16344", "abs": "https://arxiv.org/abs/2601.16344", "authors": ["Fan Nie", "Junlin Wang", "Harper Hua", "Federico Bianchi", "Yongchan Kwon", "Zhenting Qi", "Owen Queen", "Shang Zhu", "James Zou"], "title": "DSGym: A Holistic Framework for Evaluating and Training Data Science Agents", "comment": null, "summary": "Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context."}
{"id": "2601.16549", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16549", "abs": "https://arxiv.org/abs/2601.16549", "authors": ["Meet Raval", "Tejul Pandit", "Dhvani Upadhyay"], "title": "LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification", "comment": "9 pages, 5 figures, 3 tables, paper accepted in AAIML'26 conference", "summary": "The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study."}
{"id": "2601.16372", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16372", "abs": "https://arxiv.org/abs/2601.16372", "authors": ["Hyunuk Shin", "Hojin Kim", "Chanyoung Lee", "Yeon-Chang Lee", "David Yoon Suk Kang"], "title": "Improving the Accuracy of Community Detection on Signed Networks via Community Refinement and Contrastive Learning", "comment": null, "summary": "Community detection (CD) on signed networks is crucial for understanding how positive and negative relations jointly shape network structure. However, existing CD methods often yield inconsistent communities due to noisy or conflicting edge signs. In this paper, we propose ReCon, a model-agnostic post-processing framework that progressively refines community structures through four iterative steps: (1) structural refinement, (2) boundary refinement, (3) contrastive learning, and (4) clustering. Extensive experiments on eighteen synthetic and four real-world networks using four CD methods demonstrate that ReCon consistently enhances community detection accuracy, serving as an effective and easily integrable solution for reliable CD across diverse network properties."}
{"id": "2601.16649", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16649", "abs": "https://arxiv.org/abs/2601.16649", "authors": ["Amin Rakhsha", "Thomas Hehn", "Pietro Mazzaglia", "Fabio Valerio Massoli", "Arash Behboodi", "Tribhuvanesh Orekondy"], "title": "LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents", "comment": null, "summary": "Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models."}
{"id": "2601.16398", "categories": ["cs.CY", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.16398", "abs": "https://arxiv.org/abs/2601.16398", "authors": ["Hannah Cyberey", "Yangfeng Ji", "David Evans"], "title": "White-Box Sensitivity Auditing with Steering Vectors", "comment": null, "summary": "Algorithmic audits are essential tools for examining systems for properties required by regulators or desired by operators. Current audits of large language models (LLMs) primarily rely on black-box evaluations that assess model behavior only through input-output testing. These methods are limited to tests constructed in the input space, often generated by heuristics. In addition, many socially relevant model properties (e.g., gender bias) are abstract and difficult to measure through text-based inputs alone. To address these limitations, we propose a white-box sensitivity auditing framework for LLMs that leverages activation steering to conduct more rigorous assessments through model internals. Our auditing method conducts internal sensitivity tests by manipulating key concepts relevant to the model's intended function for the task. We demonstrate its application to bias audits in four simulated high-stakes LLM decision tasks. Our method consistently reveals substantial dependence on protected attributes in model predictions, even in settings where standard black-box evaluations suggest little or no bias. Our code is openly available at https://github.com/hannahxchen/llm-steering-audit"}
{"id": "2601.16685", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16685", "abs": "https://arxiv.org/abs/2601.16685", "authors": ["Suzhong Fu", "Jingqi Dong", "Xuan Ding", "Rui Sun", "Yiming Yang", "Shuguang Cui", "Zhen Li"], "title": "AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning", "comment": null, "summary": "Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice."}
{"id": "2601.16457", "categories": ["cs.SI", "cs.IR", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.16457", "abs": "https://arxiv.org/abs/2601.16457", "authors": ["Junning Zhao", "Kazutoshi Sasahara", "Yu Chen"], "title": "Segregation Before Polarization: How Recommendation Strategies Shape Echo Chamber Pathways", "comment": "13 pages, 5 figures for main text; 7 pages, 6 figures for supplementary materials", "summary": "Social media platforms facilitate echo chambers through feedback loops between user preferences and recommendation algorithms. While algorithmic homogeneity is well-documented, the distinct evolutionary pathways driven by content-based versus link-based recommendations remain unclear. Using an extended dynamic Bounded Confidence Model (BCM), we show that content-based algorithms--unlike their link-based counterparts--steer social networks toward a segregation-before-polarization (SbP) pathway. Along this trajectory, structural segregation precedes opinion divergence, accelerating individual isolation while delaying but ultimately intensifying collective polarization. Furthermore, we reveal a paradox in information sharing: Reposting increases the number of connections in the network, yet it simultaneously reinforces echo chambers because it amplifies small, latent opinion differences that would otherwise remain inconsequential. These findings suggest that mitigating polarization requires stage-dependent algorithmic interventions, shifting from content-centric to structure-centric strategies as networks evolve."}
{"id": "2601.16725", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16725", "abs": "https://arxiv.org/abs/2601.16725", "authors": ["Meituan LongCat Team", "Anchun Gui", "Bei Li", "Bingyang Tao", "Bole Zhou", "Borun Chen", "Chao Zhang", "Chao Zhang", "Chen Gao", "Chen Zhang", "Chengcheng Han", "Chenhui Yang", "Chuyu Zhang", "Cong Chen", "Cunguang Wang", "Daoru Pan", "Defei Bu", "Dengchang Zhao", "Di Xiu", "Dishan Liu", "Dongyu Ru", "Dunwei Tu", "Fan Wu", "Fengcheng Yuan", "Fengcun Li", "Gang Xu", "Guanyu Wu", "Guoyuan Lin", "Haibin Wang", "Hansi Yang", "Hao Yang", "Haonan Yan", "Haoxiang Ma", "Haoxing Wen", "Hongyan Hao", "Hongyin Tang", "Hongyu Zang", "Hongzhi Ni", "Hui Su", "Jiacheng Zhang", "Jiahong Zhou", "Jiahuan Li", "Jiaming Wang", "Jian Yang", "Jianfei Zhang", "Jianhao Xu", "Jianing Wang", "Jiapeng Zhu", "Jiaqi Sun", "Jiarong Shi", "Jiarui Zhao", "Jingang Wang", "Jinluan Yang", "Jinrui Ding", "Jinwei Xiao", "Jiyuan He", "Juncan Xu", "Kefeng Zhang", "Keheng Wang", "Li Wei", "Lianhui Ma", "Lin Qiu", "Lingbing Kong", "Lingchuan Liu", "Linsen Guo", "Mengshen Zhu", "Mengxia Shen", "Mingyang Zhu", "Peiguang Li", "Peng Pei", "Pengcheng Jia", "Pengtao Zhang", "Peng Zhao", "Qi Gu", "Qiong Huang", "Qiyuan Duan", "Quanchi Weng", "Rongxiang Weng", "Rongzhi Zhang", "Rumei Li", "Shanglin Lei", "Shengnan An", "Shijun Dai", "Shuaikang Liu", "Shuang Zhou", "Shuo Wang", "Songyuan Zhao", "Tao Liang", "Tianhao Hu", "Tianze Chen", "Wei Liu", "Wei Shi", "Wei Wang", "Weifeng Tang", "Wenjie Shi", "Wenlong Zhu", "Wentao Chen", "Wentao Shi", "Xi Su", "Xiangcheng Liu", "Xiandi Ma", "Xiangyu Xi", "Xiangyuan Liu", "Xiangzhou Huang", "Xiao Liu", "Xiaodong Cai", "Xiaolong Chen", "Xiaowei Shi", "Xiaoyu Li", "Xin Chen", "Xingchen Liu", "Xuan Huang", "Xuezhi Cao", "Xunliang Cai", "Yan Chen", "Yang Bai", "Yang Liu", "Yang Yang", "Yang Zheng", "Yaoming Wang", "Yaoming Zhu", "Yaqi Huo", "Yanyu Chen", "Yaorui Shi", "Yerui Sun", "Yi Zhang", "Yihao Chen", "Yi-Kai Zhang", "Yifan Lu", "Yifan Zhao", "Yitao Zhai", "Yongjing Yin", "Yongwei Zhou", "Youshao Xiao", "Yuchuan Dai", "Yuchen Xie", "Yuchen Yu", "Yufei Zhang", "Yuhuai Wei", "Yulei Qian", "Yunfan Liang", "Yunke Zhao", "Yuwei Jiang", "Yuxin Bian", "Yuxin Chen", "Yuxin Liu", "Yue Xu", "Yueqing Sun", "Zeyang Yu", "Zhao Yang", "Zhengsheng Huang", "Zhengyu Chen", "Zhijian Liu", "Zhikang Xia", "Zhimin Lin", "Zhiyuan Yao", "Zhuofan Chen", "Zhuowen Han", "Zijian Zhang", "Ziran Li", "Ziwen Wang", "Ziyuan Zhuang"], "title": "LongCat-Flash-Thinking-2601 Technical Report", "comment": null, "summary": "We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking."}
{"id": "2601.16479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16479", "abs": "https://arxiv.org/abs/2601.16479", "authors": ["Hongjia Wu", "Shuai Zhou", "Hongxin Zhang", "Wei Chen"], "title": "Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs", "comment": null, "summary": "While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an \"expert bottleneck\" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy."}
{"id": "2601.16806", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.16806", "abs": "https://arxiv.org/abs/2601.16806", "authors": ["Lu Yihe", "Barbara Webb"], "title": "An Efficient Insect-inspired Approach for Visual Point-goal Navigation", "comment": null, "summary": "In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations."}
{"id": "2601.16513", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.16513", "abs": "https://arxiv.org/abs/2601.16513", "authors": ["Melissa Wilfley", "Mengting Ai", "Madelyn Rose Sanfilippo"], "title": "Competing Visions of Ethical AI: A Case Study of OpenAI", "comment": "iConference 2026", "summary": "Introduction. AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Method. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment' and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assembled from public documentation. Analysis. Qualitative content analysis of ethical themes combined inductively derived and deductively applied codes. Quantitative analysis leveraged computational content analysis methods via NLP to model topics and quantify changes in rhetoric over time. Visualizations report aggregate results. For reproducible results, we have released our code at https://github.com/famous-blue-raincoat/AI_Ethics_Discourse. Results. Results indicate that safety and risk discourse dominate OpenAI's public communication and documentation, without applying academic and advocacy ethics frameworks or vocabularies. Conclusions. Implications for governance are presented, along with discussion of ethics-washing practices in industry."}
{"id": "2601.16853", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.16853", "abs": "https://arxiv.org/abs/2601.16853", "authors": ["Ian B. de Haan", "Peter van der Putten", "Max van Duijn"], "title": "Reasoning Promotes Robustness in Theory of Mind Tasks", "comment": "14 pages, 2 figures", "summary": "Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs."}
{"id": "2601.16529", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.16529", "abs": "https://arxiv.org/abs/2601.16529", "authors": ["Dongshen Peng", "Yi Wang", "Carl Preiksaitis", "Christian Rose"], "title": "SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care", "comment": "11 pages, 5 figures", "summary": "Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\\%. Models showed higher vulnerability to imaging requests (38.8\\%) than opioid prescriptions (25.0\\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification."}
{"id": "2601.16863", "categories": ["cs.AI", "cs.LG", "cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16863", "abs": "https://arxiv.org/abs/2601.16863", "authors": ["Tims Pecerskis", "Aivars Smirnovs"], "title": "Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation", "comment": null, "summary": "This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent."}
{"id": "2601.16549", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16549", "abs": "https://arxiv.org/abs/2601.16549", "authors": ["Meet Raval", "Tejul Pandit", "Dhvani Upadhyay"], "title": "LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification", "comment": "9 pages, 5 figures, 3 tables, paper accepted in AAIML'26 conference", "summary": "The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study."}
{"id": "2601.16886", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16886", "abs": "https://arxiv.org/abs/2601.16886", "authors": ["Chi Yu", "Hongyu Yuan", "Zhiyi Duan"], "title": "MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion", "comment": null, "summary": "Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods."}
{"id": "2601.16649", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16649", "abs": "https://arxiv.org/abs/2601.16649", "authors": ["Amin Rakhsha", "Thomas Hehn", "Pietro Mazzaglia", "Fabio Valerio Massoli", "Arash Behboodi", "Tribhuvanesh Orekondy"], "title": "LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents", "comment": null, "summary": "Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models."}
{"id": "2601.16909", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16909", "abs": "https://arxiv.org/abs/2601.16909", "authors": ["Lei You", "Lele Cao", "Iryna Gurevych"], "title": "Preventing the Collapse of Peer Review Requires Verification-First AI", "comment": null, "summary": "This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation."}
{"id": "2601.16685", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16685", "abs": "https://arxiv.org/abs/2601.16685", "authors": ["Suzhong Fu", "Jingqi Dong", "Xuan Ding", "Rui Sun", "Yiming Yang", "Shuguang Cui", "Zhen Li"], "title": "AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning", "comment": null, "summary": "Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice."}
{"id": "2601.16964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16964", "abs": "https://arxiv.org/abs/2601.16964", "authors": ["Mohamed Amine Ferrag", "Abderrahmane Lakas", "Merouane Debbah"], "title": "AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems", "comment": "16 pages", "summary": "The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive"}
{"id": "2601.16725", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16725", "abs": "https://arxiv.org/abs/2601.16725", "authors": ["Meituan LongCat Team", "Anchun Gui", "Bei Li", "Bingyang Tao", "Bole Zhou", "Borun Chen", "Chao Zhang", "Chao Zhang", "Chen Gao", "Chen Zhang", "Chengcheng Han", "Chenhui Yang", "Chuyu Zhang", "Cong Chen", "Cunguang Wang", "Daoru Pan", "Defei Bu", "Dengchang Zhao", "Di Xiu", "Dishan Liu", "Dongyu Ru", "Dunwei Tu", "Fan Wu", "Fengcheng Yuan", "Fengcun Li", "Gang Xu", "Guanyu Wu", "Guoyuan Lin", "Haibin Wang", "Hansi Yang", "Hao Yang", "Haonan Yan", "Haoxiang Ma", "Haoxing Wen", "Hongyan Hao", "Hongyin Tang", "Hongyu Zang", "Hongzhi Ni", "Hui Su", "Jiacheng Zhang", "Jiahong Zhou", "Jiahuan Li", "Jiaming Wang", "Jian Yang", "Jianfei Zhang", "Jianhao Xu", "Jianing Wang", "Jiapeng Zhu", "Jiaqi Sun", "Jiarong Shi", "Jiarui Zhao", "Jingang Wang", "Jinluan Yang", "Jinrui Ding", "Jinwei Xiao", "Jiyuan He", "Juncan Xu", "Kefeng Zhang", "Keheng Wang", "Li Wei", "Lianhui Ma", "Lin Qiu", "Lingbing Kong", "Lingchuan Liu", "Linsen Guo", "Mengshen Zhu", "Mengxia Shen", "Mingyang Zhu", "Peiguang Li", "Peng Pei", "Pengcheng Jia", "Pengtao Zhang", "Peng Zhao", "Qi Gu", "Qiong Huang", "Qiyuan Duan", "Quanchi Weng", "Rongxiang Weng", "Rongzhi Zhang", "Rumei Li", "Shanglin Lei", "Shengnan An", "Shijun Dai", "Shuaikang Liu", "Shuang Zhou", "Shuo Wang", "Songyuan Zhao", "Tao Liang", "Tianhao Hu", "Tianze Chen", "Wei Liu", "Wei Shi", "Wei Wang", "Weifeng Tang", "Wenjie Shi", "Wenlong Zhu", "Wentao Chen", "Wentao Shi", "Xi Su", "Xiangcheng Liu", "Xiandi Ma", "Xiangyu Xi", "Xiangyuan Liu", "Xiangzhou Huang", "Xiao Liu", "Xiaodong Cai", "Xiaolong Chen", "Xiaowei Shi", "Xiaoyu Li", "Xin Chen", "Xingchen Liu", "Xuan Huang", "Xuezhi Cao", "Xunliang Cai", "Yan Chen", "Yang Bai", "Yang Liu", "Yang Yang", "Yang Zheng", "Yaoming Wang", "Yaoming Zhu", "Yaqi Huo", "Yanyu Chen", "Yaorui Shi", "Yerui Sun", "Yi Zhang", "Yihao Chen", "Yi-Kai Zhang", "Yifan Lu", "Yifan Zhao", "Yitao Zhai", "Yongjing Yin", "Yongwei Zhou", "Youshao Xiao", "Yuchuan Dai", "Yuchen Xie", "Yuchen Yu", "Yufei Zhang", "Yuhuai Wei", "Yulei Qian", "Yunfan Liang", "Yunke Zhao", "Yuwei Jiang", "Yuxin Bian", "Yuxin Chen", "Yuxin Liu", "Yue Xu", "Yueqing Sun", "Zeyang Yu", "Zhao Yang", "Zhengsheng Huang", "Zhengyu Chen", "Zhijian Liu", "Zhikang Xia", "Zhimin Lin", "Zhiyuan Yao", "Zhuofan Chen", "Zhuowen Han", "Zijian Zhang", "Ziran Li", "Ziwen Wang", "Ziyuan Zhuang"], "title": "LongCat-Flash-Thinking-2601 Technical Report", "comment": null, "summary": "We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking."}
{"id": "2601.16965", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16965", "abs": "https://arxiv.org/abs/2601.16965", "authors": ["Riyang Bao", "Cheng Yang", "Dazhou Yu", "Zhexiang Tang", "Gengchen Mai", "Liang Zhao"], "title": "Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts", "comment": "15pages, 4 figures", "summary": "Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows."}
{"id": "2601.16806", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.16806", "abs": "https://arxiv.org/abs/2601.16806", "authors": ["Lu Yihe", "Barbara Webb"], "title": "An Efficient Insect-inspired Approach for Visual Point-goal Navigation", "comment": null, "summary": "In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations."}
{"id": "2601.16967", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.16967", "abs": "https://arxiv.org/abs/2601.16967", "authors": ["Bernes Lorier Atabonfack", "Ahmed Tahiru Issah", "Mohammed Hardi Abdul Baaki", "Clemence Ingabire", "Tolulope Olusuyi", "Maruf Adewole", "Udunna C. Anazodo", "Timothy X Brown"], "title": "Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians", "comment": "Accepted at the MIRASOL Workshop at MICCAI 2025. To appear in Lecture Notes in Computer Science (LNCS)", "summary": "In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments."}
{"id": "2601.16853", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.16853", "abs": "https://arxiv.org/abs/2601.16853", "authors": ["Ian B. de Haan", "Peter van der Putten", "Max van Duijn"], "title": "Reasoning Promotes Robustness in Theory of Mind Tasks", "comment": "14 pages, 2 figures", "summary": "Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs."}
{"id": "2601.16233", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16233", "abs": "https://arxiv.org/abs/2601.16233", "authors": ["Akseli Kangaslahti", "Davin Choo", "Lingkai Kong", "Milind Tambe", "Alastair van Heerden", "Cheryl Johnson"], "title": "Policy-Embedded Graph Expansion: Networked HIV Testing with Diffusion-Driven Network Samples", "comment": null, "summary": "HIV is a retrovirus that attacks the human immune system and can lead to death without proper treatment. In collaboration with the WHO and Wits University, we study how to improve the efficiency of HIV testing with the goal of eventual deployment, directly supporting progress toward UN Sustainable Development Goal 3.3. While prior work has demonstrated the promise of intelligent algorithms for sequential, network-based HIV testing, existing approaches rely on assumptions that are impractical in our real-world implementations. Here, we study sequential testing on incrementally revealed disease networks and introduce Policy-Embedded Graph Expansion (PEGE), a novel framework that directly embeds a generative distribution over graph expansions into the decision-making policy rather than attempting explicit topological reconstruction. We further propose Dynamics-Driven Branching (DDB), a diffusion-based graph expansion model that supports decision making in PEGE and is designed for data-limited settings where forest structures arise naturally, as in our real-world referral process. Experiments on real HIV transmission networks show that the combined approach (PEGE + DDB) consistently outperforms existing baselines (e.g., 13% improvement in discounted reward and 9% more HIV detections with 25% of the population tested) and explore key tradeoffs that drive decision quality."}
{"id": "2601.16863", "categories": ["cs.AI", "cs.LG", "cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16863", "abs": "https://arxiv.org/abs/2601.16863", "authors": ["Tims Pecerskis", "Aivars Smirnovs"], "title": "Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation", "comment": null, "summary": "This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent."}
{"id": "2601.16372", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16372", "abs": "https://arxiv.org/abs/2601.16372", "authors": ["Hyunuk Shin", "Hojin Kim", "Chanyoung Lee", "Yeon-Chang Lee", "David Yoon Suk Kang"], "title": "Improving the Accuracy of Community Detection on Signed Networks via Community Refinement and Contrastive Learning", "comment": null, "summary": "Community detection (CD) on signed networks is crucial for understanding how positive and negative relations jointly shape network structure. However, existing CD methods often yield inconsistent communities due to noisy or conflicting edge signs. In this paper, we propose ReCon, a model-agnostic post-processing framework that progressively refines community structures through four iterative steps: (1) structural refinement, (2) boundary refinement, (3) contrastive learning, and (4) clustering. Extensive experiments on eighteen synthetic and four real-world networks using four CD methods demonstrate that ReCon consistently enhances community detection accuracy, serving as an effective and easily integrable solution for reliable CD across diverse network properties."}
{"id": "2601.16886", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16886", "abs": "https://arxiv.org/abs/2601.16886", "authors": ["Chi Yu", "Hongyu Yuan", "Zhiyi Duan"], "title": "MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion", "comment": null, "summary": "Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods."}
{"id": "2601.16926", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.16926", "abs": "https://arxiv.org/abs/2601.16926", "authors": ["Shashank Prakash", "Ranjitha Prasad", "Avinash Agarwal"], "title": "Nishpaksh: TEC Standard-Compliant Framework for Fairness Auditing and Certification of AI Models", "comment": "Accepted and presented at 2026 18th International Conference on COMmunication Systems and NETworks (COMSNETS)", "summary": "The growing reliance on Artificial Intelligence (AI) models in high-stakes decision-making systems, particularly within emerging telecom and 6G applications, underscores the urgent need for transparent and standardized fairness assessment frameworks. While global toolkits such as IBM AI Fairness 360 and Microsoft Fairlearn have advanced bias detection, they often lack alignment with region-specific regulatory requirements and national priorities. To address this gap, we propose Nishpaksh, an indigenous fairness evaluation tool that operationalizes the Telecommunication Engineering Centre (TEC) Standard for the Evaluation and Rating of Artificial Intelligence Systems. Nishpaksh integrates survey-based risk quantification, contextual threshold determination, and quantitative fairness evaluation into a unified, web-based dashboard. The tool employs vectorized computation, reactive state management, and certification-ready reporting to enable reproducible, audit-grade assessments, thereby addressing a critical post-standardization implementation need. Experimental validation on the COMPAS dataset demonstrates Nishpaksh's effectiveness in identifying attribute-specific bias and generating standardized fairness scores compliant with the TEC framework. The system bridges the gap between research-oriented fairness methodologies and regulatory AI governance in India, marking a significant step toward responsible and auditable AI deployment within critical infrastructure like telecommunications."}
{"id": "2601.16909", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16909", "abs": "https://arxiv.org/abs/2601.16909", "authors": ["Lei You", "Lele Cao", "Iryna Gurevych"], "title": "Preventing the Collapse of Peer Review Requires Verification-First AI", "comment": null, "summary": "This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation."}
{"id": "2601.16926", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.16926", "abs": "https://arxiv.org/abs/2601.16926", "authors": ["Shashank Prakash", "Ranjitha Prasad", "Avinash Agarwal"], "title": "Nishpaksh: TEC Standard-Compliant Framework for Fairness Auditing and Certification of AI Models", "comment": "Accepted and presented at 2026 18th International Conference on COMmunication Systems and NETworks (COMSNETS)", "summary": "The growing reliance on Artificial Intelligence (AI) models in high-stakes decision-making systems, particularly within emerging telecom and 6G applications, underscores the urgent need for transparent and standardized fairness assessment frameworks. While global toolkits such as IBM AI Fairness 360 and Microsoft Fairlearn have advanced bias detection, they often lack alignment with region-specific regulatory requirements and national priorities. To address this gap, we propose Nishpaksh, an indigenous fairness evaluation tool that operationalizes the Telecommunication Engineering Centre (TEC) Standard for the Evaluation and Rating of Artificial Intelligence Systems. Nishpaksh integrates survey-based risk quantification, contextual threshold determination, and quantitative fairness evaluation into a unified, web-based dashboard. The tool employs vectorized computation, reactive state management, and certification-ready reporting to enable reproducible, audit-grade assessments, thereby addressing a critical post-standardization implementation need. Experimental validation on the COMPAS dataset demonstrates Nishpaksh's effectiveness in identifying attribute-specific bias and generating standardized fairness scores compliant with the TEC framework. The system bridges the gap between research-oriented fairness methodologies and regulatory AI governance in India, marking a significant step toward responsible and auditable AI deployment within critical infrastructure like telecommunications."}
{"id": "2601.16930", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.16930", "abs": "https://arxiv.org/abs/2601.16930", "authors": ["Javed I. Khan", "Sharmila Rahman Prithula"], "title": "In Quest of an Extensible Multi-Level Harm Taxonomy for Adversarial AI: Heart of Security, Ethical Risk Scoring and Resilience Analytics", "comment": "Manuscript accepted for presentation at the 12th International Conference on Computational Science and Computational Intelligence (CSCI 2025), Las Vegas, NV, USA, December 2025. Proceedings to be published by Springer Nature (2026)", "summary": "Harm is invoked everywhere from cybersecurity, ethics, risk analysis, to adversarial AI, yet there exists no systematic or agreed upon list of harms, and the concept itself is rarely defined with the precision required for serious analysis. Current discourse relies on vague, under specified notions of harm, rendering nuanced, structured, and qualitative assessment effectively impossible. This paper challenges that gap directly. We introduce a structured and expandable taxonomy of harms, grounded in an ensemble of contemporary ethical theories, that makes harm explicit, enumerable, and analytically tractable. The proposed framework identifies 66+ distinct harm types, systematically organized into two overarching domains human and nonhuman, and eleven major categories, each explicitly aligned with eleven dominant ethical theories. While extensible by design, the upper levels are intentionally stable. Beyond classification, we introduce a theory-aware taxonomy of victim entities and formalize normative harm attributes, including reversibility and duration that materially alter ethical severity. Together, these contributions transform harm from a rhetorical placeholder into an operational object of analysis, enabling rigorous ethical reasoning and long term safety evaluation of AI systems and other sociotechnical domains where harm is a first order concern."}
{"id": "2601.16964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16964", "abs": "https://arxiv.org/abs/2601.16964", "authors": ["Mohamed Amine Ferrag", "Abderrahmane Lakas", "Merouane Debbah"], "title": "AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems", "comment": "16 pages", "summary": "The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive"}
{"id": "2601.16965", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16965", "abs": "https://arxiv.org/abs/2601.16965", "authors": ["Riyang Bao", "Cheng Yang", "Dazhou Yu", "Zhexiang Tang", "Gengchen Mai", "Liang Zhao"], "title": "Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts", "comment": "15pages, 4 figures", "summary": "Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows."}
{"id": "2601.16967", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.16967", "abs": "https://arxiv.org/abs/2601.16967", "authors": ["Bernes Lorier Atabonfack", "Ahmed Tahiru Issah", "Mohammed Hardi Abdul Baaki", "Clemence Ingabire", "Tolulope Olusuyi", "Maruf Adewole", "Udunna C. Anazodo", "Timothy X Brown"], "title": "Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians", "comment": "Accepted at the MIRASOL Workshop at MICCAI 2025. To appear in Lecture Notes in Computer Science (LNCS)", "summary": "In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments."}
{"id": "2601.16347", "categories": ["stat.AP", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.16347", "abs": "https://arxiv.org/abs/2601.16347", "authors": ["Erika McPhillips", "Hyeongseong Lee", "Xiangyu Xie", "Kathy Baylis", "Chris Funk", "Mengyang Gu"], "title": "Long-Term Probabilistic Forecast of Vegetation Conditions Using Climate Attributes in the Four Corners Region", "comment": null, "summary": "Weather conditions can drastically alter the state of crops and rangelands, and in turn, impact the incomes and food security of individuals worldwide. Satellite-based remote sensing offers an effective way to monitor vegetation and climate variables on regional and global scales. The annual peak Normalized Difference Vegetation Index (NDVI), derived from satellite observations, is closely associated with crop development, rangeland biomass, and vegetation growth. Although various machine learning methods have been developed to forecast NDVI over short time ranges, such as one-month-ahead predictions, long-term forecasting approaches, such as one-year-ahead predictions of vegetation conditions, are not yet available. To fill this gap, we develop a two-phase machine learning model to forecast the one-year-ahead peak NDVI over high-resolution grids, using the Four Corners region of the Southwestern United States as a testbed. In phase one, we identify informative climate attributes, including precipitation and maximum vapor pressure deficit, and develop the generalized parallel Gaussian process that captures the relationship between climate attributes and NDVI. In phase two, we forecast these climate attributes using historical data at least one year before the NDVI prediction month, which then serve as inputs to forecast the peak NDVI at each spatial grid. We developed open-source tools that outperform alternative methods for both gross NDVI and grid-based NDVI one-year forecasts, providing information that can help farmers and ranchers make actionable plans a year in advance."}
