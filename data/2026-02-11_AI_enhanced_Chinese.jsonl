{"id": "2602.09202", "categories": ["cs.CY", "cs.AI", "cs.HC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.09202", "abs": "https://arxiv.org/abs/2602.09202", "authors": ["Branislav Radeljic"], "title": "Genocide by Algorithm in Gaza: Artificial Intelligence, Countervailing Responsibility, and the Corruption of Public Discourse", "comment": null, "summary": "The accelerating militarization of artificial intelligence has transformed the ethics, politics, and governance of warfare. This article interrogates how AI-driven targeting systems function as epistemic infrastructures that classify, legitimize, and execute violence, using Israel's conduct in Gaza as a paradigmatic case. Through the lens of responsibility, the article examines three interrelated dimensions: (a) political responsibility, exploring how states exploit AI to accelerate warfare while evading accountability; (b) professional responsibility, addressing the complicity of technologists, engineers, and defense contractors in the weaponization of data; and (c) personal responsibility, probing the moral agency of individuals who participate in or resist algorithmic governance. This is complemented by an examination of the position and influence of those participating in public discourse, whose narratives often obscure or normalize AI-enabled violence. The Gaza case reveals AI not as a neutral instrument but as an active participant in the reproduction of colonial hierarchies and the normalization of atrocity. Ultimately, the paper calls for a reframing of technological agency and accountability in the age of automated warfare. It concludes that confronting algorithmic violence demands a democratization of AI ethics, one that resists technocratic fatalism and centers the lived realities of those most affected by high-tech militarism.", "AI": {"tldr": "\u672c\u6587\u4ee5\u52a0\u6c99\u51b2\u7a81\u4e3a\u4f8b\uff0c\u5206\u6790AI\u76ee\u6807\u7cfb\u7edf\u5982\u4f55\u4f5c\u4e3a\u8ba4\u77e5\u57fa\u7840\u8bbe\u65bd\u5206\u7c7b\u3001\u5408\u6cd5\u5316\u548c\u6267\u884c\u66b4\u529b\uff0c\u63a2\u8ba8\u653f\u6cbb\u3001\u4e13\u4e1a\u548c\u4e2a\u4eba\u4e09\u4e2a\u7ef4\u5ea6\u7684\u8d23\u4efb\u95ee\u9898\uff0c\u63ed\u793aAI\u5728\u6b96\u6c11\u7b49\u7ea7\u518d\u751f\u4ea7\u4e2d\u7684\u4f5c\u7528\uff0c\u547c\u5401\u6c11\u4e3b\u5316AI\u4f26\u7406\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u519b\u4e8b\u5316\u52a0\u901f\u6539\u53d8\u4e86\u6218\u4e89\u7684\u4f26\u7406\u3001\u653f\u6cbb\u548c\u6cbb\u7406\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8AI\u9a71\u52a8\u7684\u76ee\u6807\u7cfb\u7edf\u5982\u4f55\u4f5c\u4e3a\u8ba4\u77e5\u57fa\u7840\u8bbe\u65bd\u8fd0\u4f5c\uff0c\u4ee5\u4ee5\u8272\u5217\u5728\u52a0\u6c99\u7684\u884c\u52a8\u4e3a\u5178\u578b\u6848\u4f8b\uff0c\u5206\u6790AI\u5728\u66b4\u529b\u6267\u884c\u4e2d\u7684\u89d2\u8272\u53ca\u5176\u8d23\u4efb\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u8d23\u4efb\u89c6\u89d2\u5206\u6790\u4e09\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u7ef4\u5ea6\uff1a\u653f\u6cbb\u8d23\u4efb\uff08\u56fd\u5bb6\u5982\u4f55\u5229\u7528AI\u52a0\u901f\u6218\u4e89\u5e76\u9003\u907f\u95ee\u8d23\uff09\u3001\u4e13\u4e1a\u8d23\u4efb\uff08\u6280\u672f\u4e13\u5bb6\u548c\u56fd\u9632\u627f\u5305\u5546\u5728\u6570\u636e\u6b66\u5668\u5316\u4e2d\u7684\u5171\u8c0b\uff09\u3001\u4e2a\u4eba\u8d23\u4efb\uff08\u53c2\u4e0e\u6216\u62b5\u6297\u7b97\u6cd5\u6cbb\u7406\u7684\u4e2a\u4f53\u9053\u5fb7\u80fd\u52a8\u6027\uff09\u3002\u7ed3\u5408\u516c\u5171\u8bdd\u8bed\u53c2\u4e0e\u8005\u7684\u7acb\u573a\u548c\u5f71\u54cd\u529b\u5206\u6790\u3002", "result": "\u52a0\u6c99\u6848\u4f8b\u63ed\u793aAI\u4e0d\u662f\u4e2d\u6027\u5de5\u5177\uff0c\u800c\u662f\u6b96\u6c11\u7b49\u7ea7\u518d\u751f\u4ea7\u548c\u66b4\u884c\u6b63\u5e38\u5316\u7684\u79ef\u6781\u53c2\u4e0e\u8005\u3002AI\u4f26\u7406\u8bdd\u8bed\u5f80\u5f80\u63a9\u76d6\u6216\u6b63\u5e38\u5316AI\u9a71\u52a8\u7684\u66b4\u529b\uff0c\u9700\u8981\u91cd\u65b0\u6784\u5efa\u6280\u672f\u80fd\u52a8\u6027\u548c\u95ee\u8d23\u6846\u67b6\u3002", "conclusion": "\u9762\u5bf9\u7b97\u6cd5\u66b4\u529b\u9700\u8981\u6c11\u4e3b\u5316AI\u4f26\u7406\uff0c\u62b5\u5236\u6280\u672f\u5b98\u50da\u7684\u5bbf\u547d\u8bba\uff0c\u4ee5\u53d7\u9ad8\u79d1\u6280\u519b\u4e8b\u4e3b\u4e49\u5f71\u54cd\u6700\u6df1\u7684\u7fa4\u4f53\u7684\u751f\u6d3b\u73b0\u5b9e\u4e3a\u4e2d\u5fc3\u3002\u5fc5\u987b\u91cd\u65b0\u6784\u5efa\u81ea\u52a8\u5316\u6218\u4e89\u65f6\u4ee3\u7684\u6280\u672f\u80fd\u52a8\u6027\u548c\u95ee\u8d23\u673a\u5236\u3002"}}
{"id": "2602.09239", "categories": ["cs.CY", "cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09239", "abs": "https://arxiv.org/abs/2602.09239", "authors": ["Shijing He", "Yaxiong Lei", "Xiao Zhan", "Ruba Abu-Salma", "Jose Such"], "title": "\"These cameras are just like the Eye of Sauron\": A Sociotechnical Threat Model for AI-Driven Smart Home Devices as Perceived by UK-Based Domestic Workers", "comment": "Paper accepted for presentation at Symposium on Usable Security and Privacy (USEC) 2026", "summary": "The growing adoption of AI-driven smart home devices has introduced new privacy risks for domestic workers (DWs), who are frequently monitored in employers' homes while also using smart devices in their own households. We conducted semi-structured interviews with 18 UK-based DWs and performed a human-centered threat modeling analysis of their experiences through the lens of Communication Privacy Management (CPM). Our findings extend existing threat models beyond abstract adversaries and single-household contexts by showing how AI analytics, residual data logs, and cross-household data flows shaped the privacy risks faced by participants. In employer-controlled homes, AI-enabled features and opaque, agency-mediated employment arrangements intensified surveillance and constrained participants' ability to negotiate privacy boundaries. In their own homes, participants had greater control as device owners but still faced challenges, including gendered administrative roles, opaque AI functionalities, and uncertainty around data retention. We synthesize these insights into a sociotechnical threat model that identifies DW agencies as institutional adversaries and maps AI-driven privacy risks across interconnected households, and we outline social and practical implications for strengthening DW privacy and agency.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8bbf\u8c0818\u540d\u82f1\u56fd\u5bb6\u653f\u5de5\u4eba\uff0c\u4ece\u6c9f\u901a\u9690\u79c1\u7ba1\u7406\u7406\u8bba\u89c6\u89d2\u5206\u6790AI\u667a\u80fd\u5bb6\u5c45\u8bbe\u5907\u5e26\u6765\u7684\u9690\u79c1\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u8de8\u5bb6\u5ead\u6570\u636e\u6d41\u52a8\u548c\u673a\u6784\u4e2d\u4ecb\u96c7\u4f63\u5b89\u6392\u5982\u4f55\u52a0\u5267\u5bb6\u653f\u5de5\u4eba\u7684\u9690\u79c1\u5a01\u80c1\u3002", "motivation": "\u968f\u7740AI\u667a\u80fd\u5bb6\u5c45\u8bbe\u5907\u7684\u666e\u53ca\uff0c\u5bb6\u653f\u5de5\u4eba\u5728\u96c7\u4e3b\u5bb6\u4e2d\u88ab\u76d1\u63a7\u7684\u540c\u65f6\uff0c\u5728\u81ea\u5df1\u5bb6\u4e2d\u4e5f\u4f7f\u7528\u667a\u80fd\u8bbe\u5907\uff0c\u9762\u4e34\u72ec\u7279\u7684\u8de8\u5bb6\u5ead\u9690\u79c1\u98ce\u9669\u3002\u73b0\u6709\u5a01\u80c1\u6a21\u578b\u672a\u80fd\u5145\u5206\u6db5\u76d6\u8fd9\u79cd\u5177\u4f53\u60c5\u5883\u4e0b\u7684\u9690\u79c1\u6311\u6218\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u6cd5\uff0c\u8bbf\u95ee18\u540d\u82f1\u56fd\u5bb6\u653f\u5de5\u4eba\uff0c\u5e76\u7ed3\u5408\u6c9f\u901a\u9690\u79c1\u7ba1\u7406\u7406\u8bba\u8fdb\u884c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5a01\u80c1\u5efa\u6a21\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u5728\u96c7\u4e3b\u5bb6\u4e2d\uff0cAI\u529f\u80fd\u548c\u4e2d\u4ecb\u673a\u6784\u5b89\u6392\u52a0\u5267\u4e86\u76d1\u63a7\u5e76\u9650\u5236\u4e86\u9690\u79c1\u8fb9\u754c\u8c08\u5224\u80fd\u529b\uff1b\u5728\u81ea\u5df1\u5bb6\u4e2d\uff0c\u867d\u7136\u4f5c\u4e3a\u8bbe\u5907\u6240\u6709\u8005\u6709\u66f4\u591a\u63a7\u5236\u6743\uff0c\u4f46\u4ecd\u9762\u4e34\u6027\u522b\u5316\u884c\u653f\u89d2\u8272\u3001AI\u529f\u80fd\u4e0d\u900f\u660e\u548c\u6570\u636e\u4fdd\u7559\u4e0d\u786e\u5b9a\u6027\u7b49\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u793e\u4f1a\u6280\u672f\u5a01\u80c1\u6a21\u578b\uff0c\u5c06\u5bb6\u653f\u673a\u6784\u8bc6\u522b\u4e3a\u5236\u5ea6\u6027\u5bf9\u624b\uff0c\u5e76\u7ed8\u5236\u4e86\u8de8\u4e92\u8054\u5bb6\u5ead\u7684AI\u9a71\u52a8\u9690\u79c1\u98ce\u9669\u56fe\uff0c\u4e3a\u52a0\u5f3a\u5bb6\u653f\u5de5\u4eba\u7684\u9690\u79c1\u548c\u81ea\u4e3b\u6743\u63d0\u4f9b\u4e86\u793e\u4f1a\u548c\u5b9e\u8df5\u5efa\u8bae\u3002"}}
{"id": "2602.09246", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09246", "abs": "https://arxiv.org/abs/2602.09246", "authors": ["Luis Chamba-Eras", "Oscar Miguel Cumbicus Pineda", "Edison Leonardo Coronel Romero", "Jessica Katherine Gaona Alvarado", "Luis Rodrigo Barba Guam\u00e1n"], "title": "Marco IA593: Modelo de Gobernanza, \u00c9tica y Estrategia para la Integraci\u00f3n de la Inteligencia Artificial en la Educaci\u00f3n Superior del Ecuador", "comment": "in Spanish language", "summary": "The integration of Artificial Intelligence (AI) into Higher Education Institutions (HEIs) in Ecuador is not a technological option but a strategic imperative to prevent institutional obsolescence and academic irrelevance in Latin America. This paper presents the IA593 Framework, a governance, ethics, and operational model designed for the Universidad Nacional de Loja (UNL) and scalable as a reference for the Ecuadorian higher education system. The current context reveals a critical urgency: the Latin American Artificial Intelligence Index 2025 classifies Ecuador as a late awakening adopter, exposing severe structural gaps, including R and D investment of only 0.44 percent of GDP and a marginal contribution to global AI scientific output. Although a National Strategy for the Promotion of AI exists and calls for multisectoral governance, universities still lack internal regulations governing the use of Generative AI, placing academic integrity and data privacy at risk. The IA593 Framework addresses this challenge through five interconnected pillars aligned with the FATE principles of Fairness, Accountability, Transparency, and Ethics and UNESCO recommendations on AI ethics: Transversal Governance, Teaching and Training, Research, Outreach, and Management. This framework enables HEIs to move from passive technology consumption toward a sovereign and critical adoption of AI, ensuring compliance with national academic regulations and positioning UNL as a key actor in reducing the digital divide and brain drain in Ecuador.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faIA593\u6846\u67b6\uff0c\u4e00\u4e2a\u9488\u5bf9\u5384\u74dc\u591a\u5c14\u9ad8\u7b49\u6559\u80b2\u673a\u6784\u7684AI\u6cbb\u7406\u3001\u4f26\u7406\u548c\u8fd0\u8425\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u8be5\u56fd\u5728AI\u91c7\u7528\u65b9\u9762\u7684\u7ed3\u6784\u6027\u5dee\u8ddd\uff0c\u4fc3\u8fdb\u4ece\u88ab\u52a8\u6280\u672f\u6d88\u8d39\u5411\u4e3b\u6743\u548c\u6279\u5224\u6027AI\u91c7\u7528\u7684\u8f6c\u53d8\u3002", "motivation": "\u5384\u74dc\u591a\u5c14\u5728\u62c9\u4e01\u7f8e\u6d32AI\u6307\u6570\u4e2d\u88ab\u5217\u4e3a\"\u8fdf\u9192\u91c7\u7eb3\u8005\"\uff0c\u5b58\u5728\u4e25\u91cd\u7684\u7ed3\u6784\u6027\u5dee\u8ddd\uff1a\u7814\u53d1\u6295\u8d44\u4ec5\u5360GDP\u76840.44%\uff0c\u5bf9\u5168\u7403AI\u79d1\u5b66\u4ea7\u51fa\u8d21\u732e\u5fae\u4e4e\u5176\u5fae\u3002\u867d\u7136\u5b58\u5728\u56fd\u5bb6AI\u4fc3\u8fdb\u6218\u7565\uff0c\u4f46\u5927\u5b66\u7f3a\u4e4f\u7ba1\u7406\u751f\u6210\u5f0fAI\u4f7f\u7528\u7684\u5185\u90e8\u89c4\u5b9a\uff0c\u5371\u53ca\u5b66\u672f\u8bda\u4fe1\u548c\u6570\u636e\u9690\u79c1\u3002", "method": "\u63d0\u51faIA593\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u652f\u67f1\uff1a\u6a2a\u5411\u6cbb\u7406\u3001\u6559\u5b66\u4e0e\u57f9\u8bad\u3001\u7814\u7a76\u3001\u5916\u5c55\u548c\u7ba1\u7406\u3002\u8be5\u6846\u67b6\u4e0eFATE\u539f\u5219\uff08\u516c\u5e73\u6027\u3001\u95ee\u8d23\u5236\u3001\u900f\u660e\u5ea6\u548c\u4f26\u7406\uff09\u4ee5\u53ca\u8054\u5408\u56fd\u6559\u79d1\u6587\u7ec4\u7ec7\u7684AI\u4f26\u7406\u5efa\u8bae\u4fdd\u6301\u4e00\u81f4\u3002", "result": "IA593\u6846\u67b6\u4e3a\u5384\u74dc\u591a\u5c14\u9ad8\u7b49\u6559\u80b2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u53c2\u8003\u6a21\u578b\uff0c\u4f7f\u9ad8\u7b49\u6559\u80b2\u673a\u6784\u80fd\u591f\u4ece\u88ab\u52a8\u6280\u672f\u6d88\u8d39\u8f6c\u5411\u4e3b\u6743\u548c\u6279\u5224\u6027\u7684AI\u91c7\u7528\uff0c\u786e\u4fdd\u7b26\u5408\u56fd\u5bb6\u5b66\u672f\u6cd5\u89c4\uff0c\u5e76\u5e2e\u52a9\u51cf\u5c11\u6570\u5b57\u9e3f\u6c9f\u548c\u4eba\u624d\u6d41\u5931\u3002", "conclusion": "\u5c06AI\u6574\u5408\u5230\u5384\u74dc\u591a\u5c14\u9ad8\u7b49\u6559\u80b2\u673a\u6784\u4e0d\u662f\u6280\u672f\u9009\u62e9\u800c\u662f\u6218\u7565\u5fc5\u8981\uff0cIA593\u6846\u67b6\u4e3a\u89e3\u51b3\u8be5\u56fdAI\u91c7\u7528\u7684\u7ed3\u6784\u6027\u6311\u6218\u63d0\u4f9b\u4e86\u5177\u4f53\u8def\u5f84\uff0c\u6709\u52a9\u4e8e\u9632\u6b62\u673a\u6784\u8fc7\u65f6\u548c\u5b66\u672f\u65e0\u5173\u6027\uff0c\u540c\u65f6\u4fc3\u8fdb\u8d1f\u8d23\u4efb\u7684AI\u6cbb\u7406\u3002"}}
{"id": "2602.09299", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09299", "abs": "https://arxiv.org/abs/2602.09299", "authors": ["Sai Krishna Tammali", "Vinaya Kumar", "Marc B\u00f6hlen"], "title": "Synthetic Reflections on Resource Extraction", "comment": "20 pages, 5 figures, HCII prepublication", "summary": "This paper describes how AI models can be augmented and adapted to produce interpretation of landscapes. We describe the technical framework of a Sentinel-2 satellite asset interpretation pipeline that combines statistical operations, human judgement, and generative AI models to create succinct commentaries on industrial mining sites across the planet, documenting a past shared between people and AI systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7ed3\u5408\u7edf\u8ba1\u64cd\u4f5c\u3001\u4eba\u7c7b\u5224\u65ad\u548c\u751f\u6210\u5f0fAI\u7684\u6846\u67b6\uff0c\u5229\u7528Sentinel-2\u536b\u661f\u6570\u636e\u751f\u6210\u5de5\u4e1a\u91c7\u77ff\u573a\u7684\u666f\u89c2\u89e3\u8bfb", "motivation": "\u63a2\u7d22\u5982\u4f55\u589e\u5f3a\u548c\u8c03\u6574AI\u6a21\u578b\u4ee5\u4ea7\u751f\u666f\u89c2\u89e3\u8bfb\uff0c\u8bb0\u5f55\u4eba\u7c7b\u4e0eAI\u7cfb\u7edf\u4e4b\u95f4\u7684\u5171\u540c\u5386\u53f2", "method": "\u5f00\u53d1Sentinel-2\u536b\u661f\u8d44\u4ea7\u89e3\u8bfb\u6d41\u7a0b\uff0c\u7ed3\u5408\u7edf\u8ba1\u64cd\u4f5c\u3001\u4eba\u7c7b\u5224\u65ad\u548c\u751f\u6210\u5f0fAI\u6a21\u578b", "result": "\u521b\u5efa\u4e86\u80fd\u591f\u4e3a\u5168\u7403\u5de5\u4e1a\u91c7\u77ff\u573a\u751f\u6210\u7b80\u6d01\u8bc4\u8bba\u7684AI\u7cfb\u7edf", "conclusion": "AI\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u591a\u6a21\u6001\u65b9\u6cd5\u589e\u5f3a\u4ee5\u4ea7\u751f\u6709\u610f\u4e49\u7684\u666f\u89c2\u89e3\u8bfb\uff0c\u4e3a\u4eba\u7c7b-AI\u534f\u4f5c\u8bb0\u5f55\u73af\u5883\u5386\u53f2\u63d0\u4f9b\u65b0\u9014\u5f84"}}
{"id": "2602.09112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09112", "abs": "https://arxiv.org/abs/2602.09112", "authors": ["Russ Webb", "Jason Ramapuram"], "title": "A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation", "comment": null, "summary": "What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \\$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\\% accuracy while GPT-5 has 95\\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood.", "AI": {"tldr": "Cadmus\u7cfb\u7edf\uff1a\u7528\u5c0f\u6a21\u578b\u5b8c\u6210\u771f\u5b9e\u7a0b\u5e8f\u7684\u7814\u7a76\u5e73\u53f0\uff0c\u6210\u672c\u4f4e\u4e8e200\u7f8e\u5143\uff0c\u7528\u4e8e\u7814\u7a76\u7a0b\u5e8f\u8865\u5168\u3001\u5206\u5e03\u5916\u8868\u793a\u3001\u5f52\u7eb3\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\uff0c\u63d0\u4f9b\u5bf9\u8bad\u7ec3\u5206\u5e03\u548c\u6a21\u578b\u68c0\u67e5\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u3002", "motivation": "\u5f53\u524d\u7a0b\u5e8f\u5408\u6210\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b58\u5728\u5206\u5e03\u5185\u5916\u8bc6\u522b\u56f0\u96be\u3001\u5fae\u8c03\u6548\u679c\u4e0d\u660e\u3001\u5206\u8bcd\u5f71\u54cd\u4e0d\u6e05\u3001\u8ba1\u7b97\u5b58\u50a8\u6210\u672c\u9ad8\u7b49\u95ee\u9898\u3002\u9700\u8981\u4e00\u4e2a\u5c0f\u578b\u3001\u53ef\u63a7\u3001\u900f\u660e\u7684\u7cfb\u7edf\u6765\u7814\u7a76\u7a0b\u5e8f\u5b8c\u6210\u548c\u76f8\u5173\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u5f00\u53d1Cadmus\u7cfb\u7edf\uff0c\u5305\u542b\u6574\u6570\u865a\u62df\u673a\u3001\u591a\u6837\u5316\u771f\u5b9e\u7a0b\u5e8f\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u6210\u672c\u4f4e\u4e8e200\u7f8e\u5143\u7684\u81ea\u56de\u5f52Transformer\u6a21\u578b\u3002\u7cfb\u7edf\u63d0\u4f9b\u5bf9\u8bad\u7ec3\u5206\u5e03\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u548c\u6a21\u578b\u68c0\u67e5\u80fd\u529b\u3002", "result": "Cadmus\u6a21\u578b\u5728\u5b8c\u6210\u6574\u6570\u7b97\u672f\u7a0b\u5e8f\u4efb\u52a1\u4e0a\u8fbe\u5230100%\u51c6\u786e\u7387\uff0c\u4f18\u4e8eGPT-5\u768495%\u3002\u540c\u65f6\u63ed\u793aGPT-5\u5728\u89e3\u51b3\u76f8\u540c\u4efb\u52a1\u65f6\u5f15\u5165\u4e86\u672a\u77e5\u5148\u9a8c\uff0c\u8fd9\u5728\u5927\u6a21\u578b\u7814\u7a76\u4e2d\u53ef\u80fd\u6210\u4e3a\u6df7\u6dc6\u56e0\u7d20\u3002", "conclusion": "\u5c0f\u578b\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u5177\u6709\u7814\u7a76\u4ef7\u503c\uff0c\u63d0\u4f9b\u900f\u660e\u5ea6\u548c\u53ef\u63a7\u6027\uff0c\u9002\u5408\u7814\u7a76\u7a0b\u5e8f\u5b8c\u6210\u3001\u5206\u5e03\u5916\u8868\u793a\u3001\u5f52\u7eb3\u63a8\u7406\u7b49\u8bfe\u9898\uff0c\u800c\u5927\u6a21\u578b\u4e2d\u7684\u672a\u77e5\u5148\u9a8c\u53ef\u80fd\u5f71\u54cd\u67d0\u4e9b\u9700\u8981\u5b8c\u5168\u7406\u89e3\u8bad\u7ec3\u96c6\u4e0e\u4efb\u52a1\u5173\u7cfb\u7684\u7814\u7a76\u3002"}}
{"id": "2602.09382", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.09382", "abs": "https://arxiv.org/abs/2602.09382", "authors": ["Donald W. K. Andrews", "Ming Li", "Yapeng Zheng"], "title": "Initial-Condition-Robust Inference in Autoregressive Models", "comment": null, "summary": "This paper considers confidence intervals (CIs) for the autoregressive (AR) parameter in an AR model with an AR parameter that may be close or equal to one. Existing CIs rely on the assumption of a stationary or fixed initial condition to obtain correct asymptotic coverage and good finite sample coverage. When this assumption fails, their coverage can be quite poor. In this paper, we introduce a new CI for the AR parameter whose coverage probability is completely robust to the initial condition, both asymptotically and in finite samples. This CI pays only a small price in terms of its length when the initial condition is stationary or fixed. The new CI also is robust to conditional heteroskedasticity of the errors.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5bf9\u521d\u59cb\u6761\u4ef6\u5b8c\u5168\u7a33\u5065\u7684\u81ea\u56de\u5f52\u53c2\u6570\u7f6e\u4fe1\u533a\u95f4\uff0c\u65e0\u8bba\u521d\u59cb\u6761\u4ef6\u662f\u5e73\u7a33\u3001\u56fa\u5b9a\u8fd8\u662f\u975e\u5e73\u7a33\uff0c\u90fd\u80fd\u4fdd\u8bc1\u6e10\u8fd1\u548c\u6709\u9650\u6837\u672c\u8986\u76d6\u6982\u7387", "motivation": "\u73b0\u6709\u81ea\u56de\u5f52\u53c2\u6570\u7f6e\u4fe1\u533a\u95f4\u4f9d\u8d56\u4e8e\u5e73\u7a33\u6216\u56fa\u5b9a\u521d\u59cb\u6761\u4ef6\u7684\u5047\u8bbe\uff0c\u5f53\u8fd9\u4e9b\u5047\u8bbe\u4e0d\u6210\u7acb\u65f6\uff0c\u8986\u76d6\u6982\u7387\u4f1a\u53d8\u5f97\u5f88\u5dee\u3002\u9700\u8981\u4e00\u79cd\u5bf9\u521d\u59cb\u6761\u4ef6\u5b8c\u5168\u7a33\u5065\u7684\u7f6e\u4fe1\u533a\u95f4\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u56de\u5f52\u53c2\u6570\u7f6e\u4fe1\u533a\u95f4\u6784\u9020\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5bf9\u521d\u59cb\u6761\u4ef6\u5b8c\u5168\u7a33\u5065\uff0c\u540c\u65f6\u4e5f\u80fd\u5904\u7406\u6761\u4ef6\u5f02\u65b9\u5dee\u8bef\u5dee", "result": "\u65b0\u7f6e\u4fe1\u533a\u95f4\u5728\u521d\u59cb\u6761\u4ef6\u4e3a\u5e73\u7a33\u6216\u56fa\u5b9a\u65f6\u4ec5\u4ed8\u51fa\u5f88\u5c0f\u7684\u957f\u5ea6\u4ee3\u4ef7\uff0c\u4f46\u5728\u521d\u59cb\u6761\u4ef6\u5047\u8bbe\u4e0d\u6210\u7acb\u65f6\u4ecd\u80fd\u4fdd\u6301\u6b63\u786e\u7684\u8986\u76d6\u6982\u7387", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u521d\u59cb\u6761\u4ef6\u5b8c\u5168\u7a33\u5065\u7684\u81ea\u56de\u5f52\u53c2\u6570\u7f6e\u4fe1\u533a\u95f4\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u521d\u59cb\u6761\u4ef6\u5047\u8bbe\u4e0d\u6210\u7acb\u65f6\u8986\u76d6\u6982\u7387\u5dee\u7684\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2602.09289", "categories": ["cs.SI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09289", "abs": "https://arxiv.org/abs/2602.09289", "authors": ["Christine de Kock", "Eduard Hovy"], "title": "Triggered: A Statistical Analysis of Environmental Influences on Extremist Groups", "comment": null, "summary": "Online extremist communities operate within a wider information ecosystem shaped by real-world events, news coverage, and cross-community interaction. We adopt a systems perspective to examine these influences using seven years of data from two ideologically distinct extremist forums (Stormfront and Incels) and a mainstream reference community (r/News). We ask three questions: how extremist violence impacts community behaviour; whether news coverage of political entities predicts shifts in conversation dynamics; and whether linguistic diffusion occurs between mainstream and extremist spaces and across extremist ideologies. Methodologically, we combine counterfactual synthesis to estimate event-level impacts with vector autoregression and Granger causality analyses to model ongoing relationships among news signals, behavioural outcomes, and cross-community language change. Across analyses, our results indicate that Stormfront and r/News appear to be more reactive to external stimuli, while Incels demonstrates less cross-community linguistic influence and less responsiveness to news and violent events. These findings underscore that extremist communities are not homogeneous, but differ in how tightly they are coupled to the surrounding information ecosystem.", "AI": {"tldr": "\u7814\u7a76\u91c7\u7528\u7cfb\u7edf\u89c6\u89d2\u5206\u6790\u6781\u7aef\u4e3b\u4e49\u793e\u533a\u4e0e\u4e3b\u6d41\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\u7684\u4e92\u52a8\u5173\u7cfb\uff0c\u53d1\u73b0\u4e0d\u540c\u6781\u7aef\u4e3b\u4e49\u793e\u533a\u5bf9\u5916\u90e8\u523a\u6fc0\u7684\u53cd\u5e94\u7a0b\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u6781\u7aef\u4e3b\u4e49\u793e\u533a\u5e76\u975e\u5b64\u7acb\u5b58\u5728\uff0c\u800c\u662f\u53d7\u5230\u73b0\u5b9e\u4e16\u754c\u4e8b\u4ef6\u3001\u65b0\u95fb\u62a5\u9053\u548c\u8de8\u793e\u533a\u4e92\u52a8\u7684\u5f71\u54cd\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u8fd9\u4e9b\u5916\u90e8\u56e0\u7d20\u5982\u4f55\u5851\u9020\u6781\u7aef\u4e3b\u4e49\u793e\u533a\u7684\u884c\u4e3a\u548c\u8bed\u8a00\u52a8\u6001\u3002", "method": "\u4f7f\u75287\u5e74\u6570\u636e\u5bf9\u6bd4\u4e24\u4e2a\u610f\u8bc6\u5f62\u6001\u4e0d\u540c\u7684\u6781\u7aef\u4e3b\u4e49\u8bba\u575b(Stormfront\u548cIncels)\u548c\u4e00\u4e2a\u4e3b\u6d41\u53c2\u8003\u793e\u533a(r/News)\u3002\u7ed3\u5408\u53cd\u4e8b\u5b9e\u5408\u6210\u4f30\u8ba1\u4e8b\u4ef6\u7ea7\u5f71\u54cd\uff0c\u91c7\u7528\u5411\u91cf\u81ea\u56de\u5f52\u548c\u683c\u5170\u6770\u56e0\u679c\u5206\u6790\u5efa\u6a21\u65b0\u95fb\u4fe1\u53f7\u3001\u884c\u4e3a\u7ed3\u679c\u548c\u8de8\u793e\u533a\u8bed\u8a00\u53d8\u5316\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "Stormfront\u548cr/News\u5bf9\u5916\u90e8\u523a\u6fc0\u53cd\u5e94\u66f4\u654f\u611f\uff0c\u800cIncels\u793e\u533a\u8868\u73b0\u51fa\u8f83\u5c11\u7684\u8de8\u793e\u533a\u8bed\u8a00\u5f71\u54cd\uff0c\u5bf9\u65b0\u95fb\u548c\u66b4\u529b\u4e8b\u4ef6\u7684\u53cd\u5e94\u4e5f\u8f83\u5f31\u3002\u6781\u7aef\u4e3b\u4e49\u793e\u533a\u5e76\u975e\u540c\u8d28\uff0c\u5b83\u4eec\u4e0e\u5468\u56f4\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\u7684\u8026\u5408\u7a0b\u5ea6\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u6781\u7aef\u4e3b\u4e49\u793e\u533a\u4e0e\u4e3b\u6d41\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\u7684\u4e92\u52a8\u6a21\u5f0f\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8fd9\u79cd\u5f02\u8d28\u6027\u5bf9\u7406\u89e3\u548c\u5e72\u9884\u6781\u7aef\u4e3b\u4e49\u793e\u533a\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.09267", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.09267", "abs": "https://arxiv.org/abs/2602.09267", "authors": ["Fanny Dupont", "Marianne Marcoux", "Nigel E. Hussey", "Jackie Dawson", "Marie Auger-M\u00e9th\u00e9"], "title": "Estimating the distance at which narwhal $(\\textit{Monodon monoceros})$ respond to disturbance: a penalized threshold hidden Markov model", "comment": "22 pages", "summary": "Understanding behavioural responses to disturbances is vital for wildlife conservation. For example, in the Arctic, the decrease in sea ice has opened new shipping routes, increasing the need for impact assessments that quantify the distance at which marine mammals react to vessel presence. This information can then guide targeted mitigation policies, such as vessel slow-down regulations and delineation of avoidance areas. Using telemetry data to determine distances linked to deviations from normal behaviour requires advanced statistical models, such as threshold hidden Markov models (THMMs). While these are powerful tools, they do not assess whether the estimated threshold reflects a meaningful behavioural shift. We introduce a lasso-penalized THMM that builds on computationally efficient methods to impose penalties on HMMs and present a new, efficient penalized quasi-restricted maximum-likelihood estimator. Our framework is capable of estimating thresholds and assessing whether the disturbance effects are meaningful. With simulations, we demonstrate that our lasso method effectively shrinks spurious threshold effects towards zero. When applied to narwhal $\\textit{(Monodon monoceros)}$ movement data, our analysis suggests that narwhal react to vessels up to 4 kilometres away by decreasing movement persistence and spending more time in deeper waters (average maximum depth of 356m). Overall, we provide a broadly applicable framework for quantifying behavioural responses to stimuli, with applications ranging from determining reaction thresholds to disturbance to estimating the distances at which terrestrial species, such as elephants, detect water.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5e26lasso\u60e9\u7f5a\u7684\u9608\u503c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff0c\u7528\u4e8e\u91cf\u5316\u91ce\u751f\u52a8\u7269\u5bf9\u5e72\u6270\u7684\u884c\u4e3a\u53cd\u5e94\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u6709\u610f\u4e49\u7684\u9608\u503c\u6548\u5e94\u5e76\u5e94\u7528\u4e8e\u5317\u6781\u72ec\u89d2\u9cb8\u5bf9\u8239\u8236\u7684\u53cd\u5e94\u5206\u6790\u3002", "motivation": "\u5317\u6781\u6d77\u51b0\u51cf\u5c11\u5bfc\u81f4\u65b0\u822a\u8fd0\u8def\u7ebf\u5f00\u653e\uff0c\u9700\u8981\u8bc4\u4f30\u8239\u8236\u5bf9\u6d77\u6d0b\u54fa\u4e73\u52a8\u7269\u7684\u5f71\u54cd\u8ddd\u79bb\uff0c\u4ee5\u5236\u5b9a\u9488\u5bf9\u6027\u7f13\u89e3\u653f\u7b56\u3002\u73b0\u6709\u9608\u503c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u867d\u80fd\u4f30\u8ba1\u9608\u503c\uff0c\u4f46\u65e0\u6cd5\u5224\u65ad\u8be5\u9608\u503c\u662f\u5426\u53cd\u6620\u6709\u610f\u4e49\u7684\u884c\u4e3a\u53d8\u5316\u3002", "method": "\u63d0\u51falasso\u60e9\u7f5a\u7684\u9608\u503c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff0c\u57fa\u4e8e\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u6cd5\u5bf9HMM\u65bd\u52a0\u60e9\u7f5a\uff0c\u5e76\u5f00\u53d1\u65b0\u7684\u60e9\u7f5a\u51c6\u9650\u5236\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u3002\u8be5\u6846\u67b6\u80fd\u540c\u65f6\u4f30\u8ba1\u9608\u503c\u5e76\u8bc4\u4f30\u5e72\u6270\u6548\u5e94\u662f\u5426\u663e\u8457\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u663e\u793alasso\u65b9\u6cd5\u80fd\u6709\u6548\u5c06\u865a\u5047\u9608\u503c\u6548\u5e94\u6536\u7f29\u81f3\u96f6\u3002\u5e94\u7528\u4e8e\u72ec\u89d2\u9cb8\u8fd0\u52a8\u6570\u636e\u5206\u6790\u8868\u660e\uff0c\u72ec\u89d2\u9cb8\u57284\u516c\u91cc\u5916\u5c31\u5bf9\u8239\u8236\u4ea7\u751f\u53cd\u5e94\uff1a\u964d\u4f4e\u8fd0\u52a8\u6301\u7eed\u6027\u5e76\u66f4\u591a\u65f6\u95f4\u5f85\u5728\u6df1\u6c34\u533a\uff08\u5e73\u5747\u6700\u5927\u6df1\u5ea6356\u7c73\uff09\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e7f\u6cdb\u9002\u7528\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u751f\u7269\u5bf9\u523a\u6fc0\u7684\u884c\u4e3a\u53cd\u5e94\uff0c\u5e94\u7528\u8303\u56f4\u5305\u62ec\u786e\u5b9a\u5e72\u6270\u53cd\u5e94\u9608\u503c\u3001\u4f30\u8ba1\u9646\u5730\u7269\u79cd\uff08\u5982\u5927\u8c61\uff09\u63a2\u6d4b\u6c34\u6e90\u7684\u8ddd\u79bb\u7b49\u3002"}}
{"id": "2602.09636", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.09636", "abs": "https://arxiv.org/abs/2602.09636", "authors": ["Kimon Kieslich", "Sophie Morosoli", "Nicholas Diakopoulos", "Natali Helberger"], "title": "Trade-Offs in Deploying Legal AI: Insights from a Public Opinion Study to Guide AI Risk Management", "comment": null, "summary": "Generative AI tools are increasingly used for legal tasks, including legal research, drafting documents, and even for legal decision-making. As for other purposes, the use of GenAI in the legal domain comes with various risks and benefits that needs to be properly managed to ensure implementation in a way that serves public values and protect human rights. While the EU mandates risk assessment and audits before market introduction for some use cases (e.g., use by judges for administration of justice) other use cases do not fall under the AI Acts' high-risk classifications (e.g., use by citizens for legal consultation or drafting documents). Further, current risk management practices prioritize expert judgment on risk factor identification and prioritization without a corresponding legal requirement to consult with affected communities. Seeing the societal importance of the legal sector and the potentially transformative impact of GenAI in this sector, the acceptability and legitimacy of GenAI solutions also depends on public perceptions and a better understanding of the risks and benefits citizens associated with the use of AI in the legal sector. As a response, this papers presents data from a representative sample of German citizens (n=488) outlining citizens' perspectives on the use of GenAI for two legal tasks: legal consultation and legal mediation. Concretely, we i) systematically map risks and benefit factors for both legal tasks, ii) describe predictors that influence risk acceptance of the use of GenAI for those tasks, and iii) highlight emerging trade-off themes that citizens engage in when weighing up risk acceptability. Our results provides an empirical overview of citizens' concerns regarding risk management of GenAI for the legal domain, foregrounding critical themes that complement current risk assessment procedures.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5fb7\u56fd\u516c\u6c11\u8c03\u67e5\u6570\u636e\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u5728\u6cd5\u5f8b\u54a8\u8be2\u548c\u8c03\u89e3\u4efb\u52a1\u4e2d\u7684\u98ce\u9669\u4e0e\u6536\u76ca\uff0c\u8bc6\u522b\u4e86\u5f71\u54cd\u98ce\u9669\u63a5\u53d7\u5ea6\u7684\u9884\u6d4b\u56e0\u7d20\u548c\u6743\u8861\u4e3b\u9898\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u6b27\u76dfAI\u6cd5\u6848\u4ec5\u5bf9\u90e8\u5206\u9ad8\u98ce\u9669\u7528\u4f8b\uff08\u5982\u6cd5\u5b98\u4f7f\u7528\uff09\u8981\u6c42\u98ce\u9669\u8bc4\u4f30\u548c\u5ba1\u8ba1\uff0c\u800c\u516c\u6c11\u6cd5\u5f8b\u54a8\u8be2\u7b49\u7528\u4f8b\u5219\u4e0d\u53d7\u6b64\u7ea6\u675f\u3002\u5f53\u524d\u98ce\u9669\u7ba1\u7406\u5b9e\u8df5\u4e3b\u8981\u4f9d\u8d56\u4e13\u5bb6\u5224\u65ad\uff0c\u7f3a\u4e4f\u5bf9\u53d7\u5f71\u54cd\u793e\u533a\u7684\u54a8\u8be2\u3002\u9274\u4e8e\u6cd5\u5f8b\u90e8\u95e8\u7684\u793e\u4f1a\u91cd\u8981\u6027\u4ee5\u53ca\u751f\u6210\u5f0fAI\u53ef\u80fd\u5e26\u6765\u7684\u53d8\u9769\u6027\u5f71\u54cd\uff0c\u516c\u4f17\u5bf9AI\u6cd5\u5f8b\u5e94\u7528\u7684\u8ba4\u77e5\u548c\u98ce\u9669\u6536\u76ca\u7406\u89e3\u5bf9\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u63a5\u53d7\u6027\u548c\u5408\u6cd5\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u5fb7\u56fd\u516c\u6c11\u4ee3\u8868\u6027\u6837\u672c\u8c03\u67e5\uff08n=488\uff09\uff0c\u7cfb\u7edf\u5206\u6790\u516c\u6c11\u5bf9\u751f\u6210\u5f0fAI\u5728\u4e24\u9879\u6cd5\u5f8b\u4efb\u52a1\uff08\u6cd5\u5f8b\u54a8\u8be2\u548c\u6cd5\u5f8b\u8c03\u89e3\uff09\u4e2d\u7684\u770b\u6cd5\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u7cfb\u7edf\u6620\u5c04\u4e24\u9879\u4efb\u52a1\u7684\u98ce\u9669\u548c\u6536\u76ca\u56e0\u7d20\uff1b2\uff09\u63cf\u8ff0\u5f71\u54cd\u8fd9\u4e9b\u4efb\u52a1\u4e2d\u751f\u6210\u5f0fAI\u4f7f\u7528\u98ce\u9669\u63a5\u53d7\u5ea6\u7684\u9884\u6d4b\u56e0\u7d20\uff1b3\uff09\u7a81\u51fa\u516c\u6c11\u5728\u6743\u8861\u98ce\u9669\u53ef\u63a5\u53d7\u6027\u65f6\u6d89\u53ca\u7684\u6743\u8861\u4e3b\u9898\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u516c\u6c11\u5bf9\u6cd5\u5f8b\u9886\u57df\u751f\u6210\u5f0fAI\u98ce\u9669\u7ba1\u7406\u62c5\u5fe7\u7684\u5b9e\u8bc1\u6982\u89c8\uff0c\u7a81\u51fa\u4e86\u8865\u5145\u5f53\u524d\u98ce\u9669\u8bc4\u4f30\u7a0b\u5e8f\u7684\u5173\u952e\u4e3b\u9898\u3002\u5177\u4f53\u53d1\u73b0\u4e86\u516c\u6c11\u5bf9\u6cd5\u5f8b\u54a8\u8be2\u548c\u8c03\u89e3\u4efb\u52a1\u4e2dAI\u4f7f\u7528\u7684\u98ce\u9669\u548c\u6536\u76ca\u56e0\u7d20\u7684\u7cfb\u7edf\u8ba4\u77e5\uff0c\u8bc6\u522b\u4e86\u5f71\u54cd\u98ce\u9669\u63a5\u53d7\u5ea6\u7684\u5173\u952e\u9884\u6d4b\u53d8\u91cf\uff0c\u5e76\u63ed\u793a\u4e86\u516c\u6c11\u5728\u6743\u8861\u98ce\u9669\u53ef\u63a5\u53d7\u6027\u65f6\u8003\u8651\u7684\u6743\u8861\u4e3b\u9898\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9e\u8bc1\u6570\u636e\u63ed\u793a\u4e86\u516c\u6c11\u5bf9\u6cd5\u5f8b\u9886\u57df\u751f\u6210\u5f0fAI\u5e94\u7528\u7684\u62c5\u5fe7\u548c\u6743\u8861\u8003\u91cf\uff0c\u4e3a\u5f53\u524d\u4e3b\u8981\u4f9d\u8d56\u4e13\u5bb6\u5224\u65ad\u7684\u98ce\u9669\u8bc4\u4f30\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8865\u5145\u89c6\u89d2\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728AI\u6cd5\u5f8b\u5e94\u7528\u7684\u98ce\u9669\u7ba1\u7406\u4e2d\u7eb3\u5165\u516c\u4f17\u89c6\u89d2\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u786e\u4fdd\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u63a5\u53d7\u6027\u548c\u5408\u6cd5\u6027\uff0c\u66f4\u597d\u5730\u670d\u52a1\u4e8e\u516c\u5171\u4ef7\u503c\u548c\u4eba\u6743\u4fdd\u62a4\u3002"}}
{"id": "2602.09121", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09121", "abs": "https://arxiv.org/abs/2602.09121", "authors": ["R\u00e9mi Grzeczkowicz", "Eric Soriano", "Ali Janati", "Miyu Zhang", "Gerard Comas-Quiles", "Victor Carballo Araruna", "Aneesh Jonelagadda"], "title": "Uncertainty-Aware Multimodal Emotion Recognition through Dirichlet Parameterization", "comment": "8 pages, 3 figures", "summary": "In this work, we present a lightweight and privacy-preserving Multimodal Emotion Recognition (MER) framework designed for deployment on edge devices. To demonstrate framework's versatility, our implementation uses three modalities - speech, text and facial imagery. However, the system is fully modular, and can be extended to support other modalities or tasks. Each modality is processed through a dedicated backbone optimized for inference efficiency: Emotion2Vec for speech, a ResNet-based model for facial expressions, and DistilRoBERTa for text. To reconcile uncertainty across modalities, we introduce a model- and task-agnostic fusion mechanism grounded in Dempster-Shafer theory and Dirichlet evidence. Operating directly on model logits, this approach captures predictive uncertainty without requiring additional training or joint distribution estimation, making it broadly applicable beyond emotion recognition. Validation on five benchmark datasets (eNTERFACE05, MEAD, MELD, RAVDESS and CREMA-D) show that our method achieves competitive accuracy while remaining computationally efficient and robust to ambiguous or missing inputs. Overall, the proposed framework emphasizes modularity, scalability, and real-world feasibility, paving the way toward uncertainty-aware multimodal systems for healthcare, human-computer interaction, and other emotion-informed applications.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u9690\u79c1\u4fdd\u62a4\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\uff0c\u4f7f\u7528\u8bed\u97f3\u3001\u6587\u672c\u548c\u9762\u90e8\u56fe\u50cf\u4e09\u79cd\u6a21\u6001\uff0c\u5f15\u5165\u57fa\u4e8eDempster-Shafer\u7406\u8bba\u548cDirichlet\u8bc1\u636e\u7684\u6a21\u578b\u4e0e\u4efb\u52a1\u65e0\u5173\u878d\u5408\u673a\u5236\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7ade\u4e89\u6027\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u7684\u8f7b\u91cf\u7ea7\u9690\u79c1\u4fdd\u62a4\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6846\u67b6\uff0c\u89e3\u51b3\u73b0\u5b9e\u90e8\u7f72\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u95ee\u9898\uff0c\u4e3a\u533b\u7597\u4fdd\u5065\u3001\u4eba\u673a\u4ea4\u4e92\u7b49\u60c5\u611f\u611f\u77e5\u5e94\u7528\u63d0\u4f9b\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u6a21\u6001\uff1a\u8bed\u97f3\uff08Emotion2Vec\uff09\u3001\u9762\u90e8\u8868\u60c5\uff08ResNet-based\uff09\u3001\u6587\u672c\uff08DistilRoBERTa\uff09\uff0c\u6bcf\u4e2a\u6a21\u6001\u6709\u4e13\u7528\u4f18\u5316\u9aa8\u5e72\u7f51\u7edc\u3002\u5f15\u5165\u57fa\u4e8eDempster-Shafer\u7406\u8bba\u548cDirichlet\u8bc1\u636e\u7684\u6a21\u578b\u4e0e\u4efb\u52a1\u65e0\u5173\u878d\u5408\u673a\u5236\uff0c\u76f4\u63a5\u5728\u6a21\u578blogits\u4e0a\u64cd\u4f5c\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u8054\u5408\u5206\u5e03\u4f30\u8ba1\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08eNTERFACE05, MEAD, MELD, RAVDESS, CREMA-D\uff09\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u8fbe\u5230\u7ade\u4e89\u6027\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u5bf9\u6a21\u7cca\u6216\u7f3a\u5931\u8f93\u5165\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5f3a\u8c03\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u6027\u548c\u73b0\u5b9e\u53ef\u884c\u6027\uff0c\u4e3a\u533b\u7597\u4fdd\u5065\u3001\u4eba\u673a\u4ea4\u4e92\u7b49\u60c5\u611f\u611f\u77e5\u5e94\u7528\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u591a\u6a21\u6001\u7cfb\u7edf\u94fa\u5e73\u9053\u8def\uff0c\u878d\u5408\u673a\u5236\u5177\u6709\u8d85\u8d8a\u60c5\u611f\u8bc6\u522b\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2602.09543", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.09543", "abs": "https://arxiv.org/abs/2602.09543", "authors": ["Hana Kapadia", "Arun Kumar Rajasekaran"], "title": "Shifting landscape of disability and development in India: Analysis from historical trends to future predictions 2001-2031", "comment": null, "summary": "This study delves into the causes and trends of disability-related health burdens across Indian states. Through multiple Disability-Adjusted Life Years (DALY) types (covering communicable diseases, noncommunicable diseases, and injuries), gender disparities, and Human Development Index (HDI) values, these disability trends were evaluated. The data for this study was compiled from censuses, health research organisations, and data centres, among various other sources. We built regression models and used them to analyze trends across past decades and make projections for 2031. Our regression results show a strong inverse relationship between communicable disease DALYs and HDI. In other words, ongoing improvements in development and infrastructure significantly reduced communicable disease DALYs. In contrast, noncommunicable DALYs did not decrease despite rising HDI. And lastly, injury DALYs showed moderate declines with higher HDI, which reflects improvements in healthcare and safety systems. Gender analysis showed male overrepresentation among people with disabilities. These results from our study support that there is a need to shift public health focus toward chronic diseases and address gender disparities in disability outcomes.", "AI": {"tldr": "\u5370\u5ea6\u5404\u90a6\u6b8b\u75be\u76f8\u5173\u5065\u5eb7\u8d1f\u62c5\u7684\u539f\u56e0\u4e0e\u8d8b\u52bf\u5206\u6790\uff1a\u7814\u7a76\u53d1\u73b0\u4f20\u67d3\u75c5DALY\u4e0eHDI\u5448\u5f3a\u8d1f\u76f8\u5173\uff0c\u975e\u4f20\u67d3\u6027\u75be\u75c5DALY\u672a\u968fHDI\u4e0a\u5347\u800c\u4e0b\u964d\uff0c\u4f24\u5bb3DALY\u9002\u5ea6\u4e0b\u964d\uff0c\u7537\u6027\u5728\u6b8b\u75be\u4eba\u53e3\u4e2d\u6bd4\u4f8b\u8fc7\u9ad8", "motivation": "\u7814\u7a76\u5370\u5ea6\u5404\u90a6\u6b8b\u75be\u76f8\u5173\u5065\u5eb7\u8d1f\u62c5\u7684\u539f\u56e0\u548c\u8d8b\u52bf\uff0c\u901a\u8fc7\u591a\u79cdDALY\u7c7b\u578b\uff08\u4f20\u67d3\u75c5\u3001\u975e\u4f20\u67d3\u75c5\u3001\u4f24\u5bb3\uff09\u3001\u6027\u522b\u5dee\u5f02\u548c\u4eba\u7c7b\u53d1\u5c55\u6307\u6570\u6765\u8bc4\u4f30\u6b8b\u75be\u8d8b\u52bf\uff0c\u4e3a\u516c\u5171\u536b\u751f\u653f\u7b56\u63d0\u4f9b\u4f9d\u636e", "method": "\u4f7f\u7528\u6765\u81ea\u4eba\u53e3\u666e\u67e5\u3001\u5065\u5eb7\u7814\u7a76\u673a\u6784\u548c\u6570\u636e\u4e2d\u5fc3\u7684\u6570\u636e\uff0c\u5efa\u7acb\u56de\u5f52\u6a21\u578b\u5206\u6790\u8fc7\u53bb\u51e0\u5341\u5e74\u7684\u8d8b\u52bf\uff0c\u5e76\u5bf92031\u5e74\u8fdb\u884c\u9884\u6d4b", "result": "\u4f20\u67d3\u75c5DALY\u4e0eHDI\u5448\u5f3a\u8d1f\u76f8\u5173\uff08\u53d1\u5c55\u6539\u5584\u663e\u8457\u964d\u4f4e\u4f20\u67d3\u75c5\u8d1f\u62c5\uff09\uff1b\u975e\u4f20\u67d3\u75c5DALY\u672a\u968fHDI\u4e0a\u5347\u800c\u4e0b\u964d\uff1b\u4f24\u5bb3DALY\u968fHDI\u4e0a\u5347\u9002\u5ea6\u4e0b\u964d\uff08\u53cd\u6620\u533b\u7597\u548c\u5b89\u5168\u7cfb\u7edf\u6539\u5584\uff09\uff1b\u6027\u522b\u5206\u6790\u663e\u793a\u7537\u6027\u5728\u6b8b\u75be\u4eba\u53e3\u4e2d\u6bd4\u4f8b\u8fc7\u9ad8", "conclusion": "\u516c\u5171\u536b\u751f\u91cd\u70b9\u9700\u8981\u8f6c\u5411\u6162\u6027\u75be\u75c5\uff0c\u5e76\u89e3\u51b3\u6b8b\u75be\u7ed3\u679c\u4e2d\u7684\u6027\u522b\u5dee\u5f02\u95ee\u9898"}}
{"id": "2602.09632", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.09632", "abs": "https://arxiv.org/abs/2602.09632", "authors": ["Dorota M\u0142ynarczyk", "Gabriel Calvo", "Francisco Palmi-Perales", "Carmen Armero", "Virgilio G\u00f3mez-Rubio", "Ana de la Torre-Garc\u00eda", "Ricardo Bayona Salvador"], "title": "Bayesian network approach to building an affective module for a driver behavioural model", "comment": null, "summary": "This paper focuses on the affective component of a driver behavioural model (DBM). This component specifically models some drivers' mental states such as mental load and active fatigue, which may affect driving performance. We have used Bayesian networks (BNs) to explore the dependencies between various relevant random variables and assess the probability that a driver is in a particular mental state based on their physiological and demographic conditions. Through this approach, our goal is to improve our understanding of driver behaviour in dynamic environments, with potential applications in traffic safety and autonomous vehicle technologies.", "AI": {"tldr": "\u4f7f\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\u5efa\u6a21\u9a7e\u9a76\u5458\u5fc3\u7406\u72b6\u6001\uff08\u5fc3\u7406\u8d1f\u8377\u548c\u4e3b\u52a8\u75b2\u52b3\uff09\u5bf9\u9a7e\u9a76\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u751f\u7406\u548c\u4eba\u53e3\u7edf\u8ba1\u53d8\u91cf\u8bc4\u4f30\u5fc3\u7406\u72b6\u6001\u6982\u7387", "motivation": "\u9a7e\u9a76\u5458\u5fc3\u7406\u72b6\u6001\uff08\u5982\u5fc3\u7406\u8d1f\u8377\u548c\u4e3b\u52a8\u75b2\u52b3\uff09\u4f1a\u5f71\u54cd\u9a7e\u9a76\u8868\u73b0\uff0c\u9700\u8981\u5efa\u7acb\u6a21\u578b\u6765\u7406\u89e3\u8fd9\u4e9b\u56e0\u7d20\u5bf9\u9a7e\u9a76\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4ee5\u63d0\u9ad8\u4ea4\u901a\u5b89\u5168\u548c\u81ea\u52a8\u9a7e\u9a76\u6280\u672f", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\u63a2\u7d22\u76f8\u5173\u968f\u673a\u53d8\u91cf\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u57fa\u4e8e\u9a7e\u9a76\u5458\u7684\u751f\u7406\u548c\u4eba\u53e3\u7edf\u8ba1\u6761\u4ef6\u8bc4\u4f30\u5176\u5904\u4e8e\u7279\u5b9a\u5fc3\u7406\u72b6\u6001\u7684\u6982\u7387", "result": "\u5efa\u7acb\u4e86\u9a7e\u9a76\u5458\u884c\u4e3a\u6a21\u578b\u7684\u60c5\u611f\u7ec4\u4ef6\uff0c\u80fd\u591f\u8bc4\u4f30\u9a7e\u9a76\u5458\u5fc3\u7406\u72b6\u6001\u6982\u7387\uff0c\u4e3a\u7406\u89e3\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9a7e\u9a76\u884c\u4e3a\u63d0\u4f9b\u4e86\u6846\u67b6", "conclusion": "\u8d1d\u53f6\u65af\u7f51\u7edc\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5efa\u6a21\u9a7e\u9a76\u5458\u5fc3\u7406\u72b6\u6001\uff0c\u8be5\u6a21\u578b\u5bf9\u63d0\u9ad8\u4ea4\u901a\u5b89\u5168\u548c\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c"}}
{"id": "2602.09678", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09678", "abs": "https://arxiv.org/abs/2602.09678", "authors": ["Nicholas Caputo"], "title": "Administrative Law's Fourth Settlement: AI and the Capability-Accountability Trap", "comment": "67 pages", "summary": "Since 1887, administrative law has navigated a \"capability-accountability trap\": technological change forces government to become more sophisticated, but sophistication renders agencies opaque to generalist overseers like the courts and Congress. The law's response--substituting procedural review for substantive oversight--has produced a sedimentary accretion of requirements that ossify capacity without ensuring democratic control. This Article argues that the Supreme Court's post-Loper Bright retrenchment is best understood as an effort to shrink administration back to comprehensible size in response to this complexification. But reducing complexity in this way sacrifices capability precisely when climate change, pandemics, and AI risks demand more sophisticated governance.\n  AI offers a different path. Unlike many prior administrative technologies that increased opacity alongside capacity, AI can help build \"scrutability\" in government, translating technical complexity into accessible terms, surfacing the assumptions that matter for oversight, and enabling substantive verification of agency reasoning. This Article proposes three doctrinal innovations within administrative law to realize this potential: a Model and System Dossier (documenting model purpose, evaluation, monitoring, and versioning) extending the administrative record to AI decision-making; a material-model-change trigger specifying when AI updates require new process; and a \"deference to audit\" standard that rewards agencies for auditable evaluation of their AI tools. The result is a framework for what this Article calls the \"Fourth Settlement,\" administrative law that escapes the capability-accountability trap by preserving capability while restoring comprehensible oversight of administration.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u884c\u653f\u6cd5\u81ea1887\u5e74\u4ee5\u6765\u9677\u5165\"\u80fd\u529b-\u95ee\u8d23\u9677\u9631\"\uff1a\u6280\u672f\u8fdb\u6b65\u4f7f\u653f\u5e9c\u66f4\u590d\u6742\uff0c\u4f46\u590d\u6742\u6027\u5bfc\u81f4\u673a\u6784\u5bf9\u6cd5\u9662\u548c\u56fd\u4f1a\u4e0d\u900f\u660e\u3002\u6700\u9ad8\u6cd5\u9662\u5728Loper Bright\u6848\u540e\u7684\u6536\u7f29\u65e8\u5728\u7f29\u5c0f\u884c\u653f\u89c4\u6a21\u4ee5\u5e94\u5bf9\u590d\u6742\u6027\uff0c\u4f46\u8fd9\u727a\u7272\u4e86\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3001\u75ab\u60c5\u548cAI\u98ce\u9669\u6240\u9700\u7684\u80fd\u529b\u3002AI\u63d0\u4f9b\u4e86\u4e0d\u540c\u8def\u5f84\uff0c\u901a\u8fc7\u5efa\u7acb\"\u53ef\u5ba1\u67e5\u6027\"\u6765\u540c\u65f6\u4fdd\u6301\u80fd\u529b\u548c\u95ee\u8d23\uff0c\u672c\u6587\u63d0\u51fa\u4e09\u9879\u5236\u5ea6\u521b\u65b0\u5b9e\u73b0\"\u7b2c\u56db\u548c\u89e3\"\u3002", "motivation": "\u884c\u653f\u6cd5\u957f\u671f\u9762\u4e34\"\u80fd\u529b-\u95ee\u8d23\u9677\u9631\"\uff1a\u6280\u672f\u8fdb\u6b65\u4f7f\u653f\u5e9c\u673a\u6784\u66f4\u590d\u6742\uff0c\u4f46\u590d\u6742\u6027\u5bfc\u81f4\u5bf9\u6cd5\u9662\u548c\u56fd\u4f1a\u7b49\u76d1\u7763\u673a\u6784\u4e0d\u900f\u660e\u3002\u4f20\u7edf\u89e3\u51b3\u65b9\u6848\uff08\u7a0b\u5e8f\u5ba1\u67e5\u66ff\u4ee3\u5b9e\u8d28\u76d1\u7763\uff09\u5bfc\u81f4\u8981\u6c42\u5c42\u5c42\u53e0\u52a0\uff0c\u56fa\u5316\u4e86\u80fd\u529b\u5374\u672a\u786e\u4fdd\u6c11\u4e3b\u63a7\u5236\u3002\u6700\u9ad8\u6cd5\u9662\u8fd1\u671f\u6536\u7f29\u884c\u653f\u89c4\u6a21\u7684\u505a\u6cd5\u727a\u7272\u4e86\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3001\u75ab\u60c5\u548cAI\u98ce\u9669\u6240\u9700\u7684\u80fd\u529b\u3002AI\u63d0\u4f9b\u4e86\u7a81\u7834\u8fd9\u4e00\u56f0\u5883\u7684\u65b0\u53ef\u80fd\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e09\u9879\u884c\u653f\u6cd5\u5236\u5ea6\u521b\u65b0\uff1a1) \u6a21\u578b\u4e0e\u7cfb\u7edf\u6863\u6848\uff0c\u5c06\u884c\u653f\u8bb0\u5f55\u6269\u5c55\u5230AI\u51b3\u7b56\uff0c\u8bb0\u5f55\u6a21\u578b\u76ee\u7684\u3001\u8bc4\u4f30\u3001\u76d1\u63a7\u548c\u7248\u672c\uff1b2) \u91cd\u5927\u6a21\u578b\u53d8\u66f4\u89e6\u53d1\u673a\u5236\uff0c\u89c4\u5b9aAI\u66f4\u65b0\u4f55\u65f6\u9700\u8981\u65b0\u7a0b\u5e8f\uff1b3) \"\u5ba1\u8ba1\u5c0a\u91cd\"\u6807\u51c6\uff0c\u5956\u52b1\u673a\u6784\u5bf9\u5176AI\u5de5\u5177\u8fdb\u884c\u53ef\u5ba1\u8ba1\u8bc4\u4f30\u3002\u8fd9\u4e9b\u521b\u65b0\u65e8\u5728\u5229\u7528AI\u5efa\u7acb\"\u53ef\u5ba1\u67e5\u6027\"\uff0c\u5c06\u6280\u672f\u590d\u6742\u6027\u8f6c\u5316\u4e3a\u53ef\u7406\u89e3\u672f\u8bed\u3002", "result": "\u901a\u8fc7AI\u5efa\u7acb\"\u53ef\u5ba1\u67e5\u6027\"\uff0c\u884c\u653f\u6cd5\u53ef\u4ee5\u540c\u65f6\u4fdd\u6301\u653f\u5e9c\u80fd\u529b\u548c\u6c11\u4e3b\u95ee\u8d23\u3002\u63d0\u51fa\u7684\u4e09\u9879\u5236\u5ea6\u521b\u65b0\u6784\u6210\u4e86\"\u7b2c\u56db\u548c\u89e3\"\u6846\u67b6\uff0c\u4f7f\u884c\u653f\u6cd5\u80fd\u591f\u6446\u8131\u957f\u671f\u5b58\u5728\u7684\"\u80fd\u529b-\u95ee\u8d23\u9677\u9631\"\uff0c\u5728\u4fdd\u6301\u5e94\u5bf9\u590d\u6742\u6311\u6218\u6240\u9700\u80fd\u529b\u7684\u540c\u65f6\uff0c\u6062\u590d\u5bf9\u884c\u653f\u7684\u53ef\u7406\u89e3\u76d1\u7763\u3002", "conclusion": "AI\u63d0\u4f9b\u4e86\u7a81\u7834\u884c\u653f\u6cd5\"\u80fd\u529b-\u95ee\u8d23\u9677\u9631\"\u7684\u65b0\u8def\u5f84\u3002\u4e0e\u4ee5\u5f80\u589e\u52a0\u4e0d\u900f\u660e\u6027\u7684\u6280\u672f\u4e0d\u540c\uff0cAI\u53ef\u4ee5\u5e2e\u52a9\u5efa\u7acb\"\u53ef\u5ba1\u67e5\u6027\"\uff0c\u5c06\u6280\u672f\u590d\u6742\u6027\u8f6c\u5316\u4e3a\u53ef\u7406\u89e3\u672f\u8bed\u3002\u901a\u8fc7\u4e09\u9879\u5236\u5ea6\u521b\u65b0\uff0c\u884c\u653f\u6cd5\u53ef\u4ee5\u5b9e\u73b0\"\u7b2c\u56db\u548c\u89e3\"\uff0c\u5728\u4fdd\u6301\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3001\u75ab\u60c5\u548cAI\u98ce\u9669\u6240\u9700\u80fd\u529b\u7684\u540c\u65f6\uff0c\u6062\u590d\u6c11\u4e3b\u95ee\u8d23\u548c\u76d1\u7763\u3002"}}
{"id": "2602.09138", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09138", "abs": "https://arxiv.org/abs/2602.09138", "authors": ["Haitao Jiang", "Lin Ge", "Hengrui Cai", "Rui Song"], "title": "PABU: Progress-Aware Belief Update for Efficient LLM Agents", "comment": null, "summary": "Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round and decides whether the newly encountered interaction should be stored, conditioning future decisions only on the retained subset. Across eight environments in the AgentGym benchmark, and using identical training trajectories, PABU achieves an 81.0% task completion rate, outperforming previous State of the art (SoTA) models with full-history belief by 23.9%. Additionally, PABU's progress-oriented action selection improves efficiency, reducing the average number of interaction steps to 9.5, corresponding to a 26.9% reduction. Ablation studies show that both explicit progress prediction and selective retention are necessary for robust belief learning and performance gains.", "AI": {"tldr": "PABU\u662f\u4e00\u79cd\u57fa\u4e8e\u4efb\u52a1\u8fdb\u5ea6\u7684\u4fe1\u5ff5\u72b6\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u4efb\u52a1\u8fdb\u5ea6\u548c\u9009\u62e9\u6027\u4fdd\u7559\u5386\u53f2\u4fe1\u606f\uff0c\u51cf\u5c11LLM\u667a\u80fd\u4f53\u4e2d\u7684\u5197\u4f59\u52a8\u4f5c\u548c\u63a8\u7406\u6210\u672c\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u901a\u5e38\u57fa\u4e8e\u5b8c\u6574\u7684\u52a8\u4f5c-\u89c2\u5bdf\u5386\u53f2\u6765\u51b3\u7b56\uff0c\u8fd9\u4f1a\u5f15\u5165\u4efb\u52a1\u65e0\u5173\u4fe1\u606f\uff0c\u5bfc\u81f4\u5197\u4f59\u52a8\u4f5c\u548c\u66f4\u9ad8\u7684\u63a8\u7406\u6210\u672c\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7d27\u51d1\u7684\u72b6\u6001\u8868\u793a\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u63d0\u51faProgress-Aware Belief Update (PABU)\u6846\u67b6\uff1a1) \u663e\u5f0f\u5efa\u6a21\u4efb\u52a1\u8fdb\u5ea6\uff0c\u9884\u6d4b\u76f8\u5bf9\u8fdb\u5c55\uff1b2) \u9009\u62e9\u6027\u4fdd\u7559\u5386\u53f2\u4ea4\u4e92\u4fe1\u606f\uff1b3) \u4ec5\u57fa\u4e8e\u4fdd\u7559\u7684\u5b50\u96c6\u8fdb\u884c\u672a\u6765\u51b3\u7b56\u3002", "result": "\u5728AgentGym\u57fa\u51c6\u6d4b\u8bd5\u76848\u4e2a\u73af\u5883\u4e2d\uff0cPABU\u5b9e\u73b0\u4e8681.0%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u6bd4\u57fa\u4e8e\u5b8c\u6574\u5386\u53f2\u7684SOTA\u6a21\u578b\u9ad8\u51fa23.9%\u3002\u5e73\u5747\u4ea4\u4e92\u6b65\u9aa4\u51cf\u5c11\u52309.5\u6b65\uff0c\u964d\u4f4e\u4e8626.9%\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\u8fdb\u5ea6\u9884\u6d4b\u548c\u9009\u62e9\u6027\u4fdd\u7559\u90fd\u662f\u5fc5\u8981\u7684\u3002", "conclusion": "PABU\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u4efb\u52a1\u8fdb\u5ea6\u548c\u9009\u62e9\u6027\u4fe1\u606f\u4fdd\u7559\uff0c\u6709\u6548\u51cf\u5c11\u4e86LLM\u667a\u80fd\u4f53\u4e2d\u7684\u5197\u4f59\u52a8\u4f5c\u548c\u63a8\u7406\u6210\u672c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6548\u7387\u3002"}}
{"id": "2602.09618", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.09618", "abs": "https://arxiv.org/abs/2602.09618", "authors": ["Caimeng Wang", "Li Chong", "Dongxu Liu", "Xu Min", "Jianhui Bu"], "title": "UniShare: A Unified Framework for Joint Video and Receiver Recommendation in Social Sharing", "comment": null, "summary": "Sharing behavior on short-video platforms constitutes a complex ternary interaction among the user (sharer), the video (content), and the receiver. Traditional industrial solutions often decouple this into two independent tasks: video recommendation (predicting share probability) and receiver recommendation (predicting whom to share with), leading to suboptimal performance due to isolated modeling and inadequate information utilization. To address this, we propose UniShare, a novel unified framework for joint sharing prediction on both video and receiver recommendation. UniShare models the share probability through an enhanced representation learning module that incorporates pre-trained GNN and multi-modal embeddings, alongside explicit bilateral interest and relationship matching. A key innovation is our joint training paradigm, which leverages signals from both tasks to mutually enhance each other, mitigating data sparsity and improving bilateral satisfaction. We also introduce K-Share, a large-scale real-world dataset constructed from Kuaishou platform logs to support research in this domain. Extensive offline experiments demonstrate that UniShare significantly outperforms strong baselines on both tasks. Furthermore, online A/B testing on the Kuaishou platform confirms its effectiveness, achieving significant improvements in key metrics including the number of shares (+1.95%) and receiver reply rate (+0.482%).", "AI": {"tldr": "UniShare\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u77ed\u89c6\u9891\u5206\u4eab\u9884\u6d4b\u6846\u67b6\uff0c\u540c\u65f6\u4f18\u5316\u89c6\u9891\u63a8\u8350\u548c\u63a5\u6536\u8005\u63a8\u8350\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u548c\u589e\u5f3a\u8868\u5f81\u5b66\u4e60\u63d0\u5347\u5206\u4eab\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u5de5\u4e1a\u89e3\u51b3\u65b9\u6848\u5c06\u77ed\u89c6\u9891\u5206\u4eab\u884c\u4e3a\u5206\u89e3\u4e3a\u89c6\u9891\u63a8\u8350\uff08\u9884\u6d4b\u5206\u4eab\u6982\u7387\uff09\u548c\u63a5\u6536\u8005\u63a8\u8350\uff08\u9884\u6d4b\u5206\u4eab\u5bf9\u8c61\uff09\u4e24\u4e2a\u72ec\u7acb\u4efb\u52a1\uff0c\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\uff0c\u56e0\u4e3a\u5b64\u7acb\u5efa\u6a21\u548c\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u3002", "method": "\u63d0\u51faUniShare\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u8868\u5f81\u5b66\u4e60\u6a21\u5757\uff08\u7ed3\u5408\u9884\u8bad\u7ec3GNN\u548c\u591a\u6a21\u6001\u5d4c\u5165\uff09\u548c\u663e\u5f0f\u53cc\u8fb9\u5174\u8da3\u5173\u7cfb\u5339\u914d\u6765\u5efa\u6a21\u5206\u4eab\u6982\u7387\u3002\u5173\u952e\u521b\u65b0\u662f\u8054\u5408\u8bad\u7ec3\u8303\u5f0f\uff0c\u5229\u7528\u4e24\u4e2a\u4efb\u52a1\u7684\u4fe1\u53f7\u76f8\u4e92\u589e\u5f3a\uff0c\u7f13\u89e3\u6570\u636e\u7a00\u758f\u6027\u5e76\u63d0\u5347\u53cc\u8fb9\u6ee1\u610f\u5ea6\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u663e\u793aUniShare\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u3002\u5728\u5feb\u624b\u5e73\u53f0\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u8bc1\u5b9e\u5176\u6709\u6548\u6027\uff0c\u5173\u952e\u6307\u6807\u663e\u8457\u63d0\u5347\uff1a\u5206\u4eab\u6570\u91cf(+1.95%)\u548c\u63a5\u6536\u8005\u56de\u590d\u7387(+0.482%)\u3002", "conclusion": "UniShare\u901a\u8fc7\u7edf\u4e00\u5efa\u6a21\u77ed\u89c6\u9891\u5206\u4eab\u7684\u590d\u6742\u4e09\u5143\u4ea4\u4e92\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u89e3\u8026\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.10039", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.10039", "abs": "https://arxiv.org/abs/2602.10039", "authors": ["Gaurab Pokharel", "Sanmay Das", "Patrick J. Fowler"], "title": "Budgeting Discretion: Theory and Evidence on Street-Level Decision-Making", "comment": null, "summary": "Street-level bureaucrats, such as caseworkers and border guards routinely face the dilemma of whether to follow rigid policy or exercise discretion based on professional judgement. However, frequent overrides threaten consistency and introduce bias, explaining why bureaucracies often ration discretion as a finite resource. While prior work models discretion as a static cost-benefit tradeoff, we lack a principled model of how discretion should be rationed over time under real operational constraints.\n  We formalize discretion as a dynamic allocation problem in which an agent receives stochastic opportunities to improve upon a default policy and must spend a limited override budget K over a finite horizon T. We show that overrides follow a dynamic threshold rule: use discretion only when the opportunity exceeds a time and budget-dependent cutoff. Our main theoretical contribution identifies a behavioral invariance: for location-scale families of improvement distributions, the rate at which an optimal agent exercises discretion is independent of the scale of potential gains and depends only on the distribution's shape (e.g., tail heaviness).\n  This result implies systematic differences in discretionary \"policy personality.\" When gains are fat-tailed, optimal agents are patient, conserving discretion for outliers. When gains are thin-tailed, agents spend more routinely. We illustrate these implications using data from a homelessness services system. Discretionary overrides track operational constraints: they are higher at the start of the workweek, suppressed on weekends when intake is offline, and shift with short-run housing capacity. These results suggest that discretion can be both procedurally constrained and welfare-improving when treated as an explicitly budgeted resource, providing a foundation for auditing override patterns and designing decision-support systems.", "AI": {"tldr": "\u8bba\u6587\u5c06\u81ea\u7531\u88c1\u91cf\u6743\u5efa\u6a21\u4e3a\u52a8\u6001\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u6700\u4f18\u51b3\u7b56\u9075\u5faa\u52a8\u6001\u9608\u503c\u89c4\u5219\uff0c\u5e76\u53d1\u73b0\u884c\u4e3a\u4e0d\u53d8\u6027\uff1a\u6700\u4f18\u88c1\u91cf\u7387\u4ec5\u53d6\u51b3\u4e8e\u6536\u76ca\u5206\u5e03\u7684\u5f62\u72b6\u800c\u975e\u89c4\u6a21\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06\u81ea\u7531\u88c1\u91cf\u6743\u89c6\u4e3a\u9759\u6001\u7684\u6210\u672c\u6548\u76ca\u6743\u8861\uff0c\u7f3a\u4e4f\u5728\u73b0\u5b9e\u64cd\u4f5c\u7ea6\u675f\u4e0b\u5982\u4f55\u968f\u65f6\u95f4\u5408\u7406\u5206\u914d\u81ea\u7531\u88c1\u91cf\u6743\u7684\u539f\u5219\u6027\u6a21\u578b\u3002\u8857\u5934\u5b98\u50da\u7ecf\u5e38\u9762\u4e34\u9075\u5faa\u521a\u6027\u653f\u7b56\u8fd8\u662f\u884c\u4f7f\u4e13\u4e1a\u5224\u65ad\u7684\u56f0\u5883\uff0c\u4f46\u9891\u7e41\u7684\u88c1\u91cf\u4f1a\u5a01\u80c1\u4e00\u81f4\u6027\u5e76\u5f15\u5165\u504f\u89c1\u3002", "method": "\u5c06\u81ea\u7531\u88c1\u91cf\u6743\u5f62\u5f0f\u5316\u4e3a\u52a8\u6001\u5206\u914d\u95ee\u9898\uff1a\u4ee3\u7406\u5728\u6709\u9650\u65f6\u95f4T\u5185\u6536\u5230\u968f\u673a\u6539\u8fdb\u673a\u4f1a\uff0c\u62e5\u6709\u6709\u9650\u8986\u76d6\u9884\u7b97K\u3002\u8bc1\u660e\u6700\u4f18\u51b3\u7b56\u9075\u5faa\u52a8\u6001\u9608\u503c\u89c4\u5219\uff0c\u5e76\u8bc6\u522b\u884c\u4e3a\u4e0d\u53d8\u6027\uff1a\u5bf9\u4e8e\u4f4d\u7f6e\u5c3a\u5ea6\u5206\u5e03\u65cf\uff0c\u6700\u4f18\u88c1\u91cf\u7387\u72ec\u7acb\u4e8e\u6f5c\u5728\u6536\u76ca\u7684\u89c4\u6a21\uff0c\u4ec5\u53d6\u51b3\u4e8e\u5206\u5e03\u5f62\u72b6\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u5dee\u5f02\uff1a\u5f53\u6536\u76ca\u5448\u539a\u5c3e\u5206\u5e03\u65f6\uff0c\u6700\u4f18\u4ee3\u7406\u4fdd\u6301\u8010\u5fc3\uff0c\u4e3a\u5f02\u5e38\u503c\u4fdd\u7559\u88c1\u91cf\u6743\uff1b\u5f53\u6536\u76ca\u5448\u8584\u5c3e\u5206\u5e03\u65f6\uff0c\u4ee3\u7406\u66f4\u5e38\u89c4\u5730\u4f7f\u7528\u88c1\u91cf\u6743\u3002\u901a\u8fc7\u65e0\u5bb6\u53ef\u5f52\u8005\u670d\u52a1\u7cfb\u7edf\u6570\u636e\u9a8c\u8bc1\uff1a\u88c1\u91cf\u8986\u76d6\u4e0e\u64cd\u4f5c\u7ea6\u675f\u4e00\u81f4\uff0c\u5728\u5de5\u4f5c\u5468\u5f00\u59cb\u65f6\u8f83\u9ad8\uff0c\u5468\u672b\u8f83\u4f4e\uff0c\u5e76\u968f\u77ed\u671f\u4f4f\u623f\u5bb9\u91cf\u53d8\u5316\u3002", "conclusion": "\u5c06\u81ea\u7531\u88c1\u91cf\u6743\u4f5c\u4e3a\u660e\u786e\u9884\u7b97\u8d44\u6e90\u7ba1\u7406\uff0c\u65e2\u80fd\u7a0b\u5e8f\u7ea6\u675f\u53c8\u80fd\u63d0\u9ad8\u798f\u5229\uff0c\u4e3a\u5ba1\u8ba1\u8986\u76d6\u6a21\u5f0f\u548c\u8bbe\u8ba1\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.09159", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.09159", "abs": "https://arxiv.org/abs/2602.09159", "authors": ["Yichen Wu", "Yujin Oh", "Sangjoon Park", "Kailong Fan", "Dania Daye", "Hana Farzaneh", "Xiang Li", "Raul Uppot", "Quanzheng Li"], "title": "CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective", "comment": "9 pages, 3 figures", "summary": "Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines.", "AI": {"tldr": "CoMMa\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u533b\u7597\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u76ee\u6807\u534f\u8c03\u4e13\u79d1\u533b\u751f\u5904\u7406\u5206\u533a\u8bc1\u636e\uff0c\u4f7f\u7528\u786e\u5b9a\u6027\u5d4c\u5165\u6295\u5f71\u8fdb\u884c\u8d21\u732e\u611f\u77e5\u4fe1\u7528\u5206\u914d\uff0c\u5728\u80bf\u7624\u5b66\u51b3\u7b56\u652f\u6301\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u5904\u7406\u9700\u8981\u52a8\u6001\u3001\u5f02\u6784\u60a3\u8005\u6570\u636e\u63a8\u7406\u7684\u80bf\u7624\u5b66\u51b3\u7b56\u652f\u6301\u4efb\u52a1\u65f6\uff0c\u5927\u591a\u4f9d\u8d56\u57fa\u4e8e\u968f\u673a\u53d9\u4e8b\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u8bc1\u636e\u5f52\u56e0\u548c\u6570\u5b66\u57fa\u7840\uff0c\u5bfc\u81f4\u51b3\u7b56\u8def\u5f84\u4e0d\u591f\u7a33\u5b9a\u548c\u53ef\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u8d21\u732e\u611f\u77e5\u533b\u7597\u591a\u667a\u80fd\u4f53(CoMMa)\u6846\u67b6\uff1a1) \u4e13\u79d1\u533b\u751f\u5728\u5206\u533a\u8bc1\u636e\u4e0a\u64cd\u4f5c\uff1b2) \u901a\u8fc7\u535a\u5f08\u8bba\u76ee\u6807\u8fdb\u884c\u534f\u8c03\uff1b3) \u4f7f\u7528\u786e\u5b9a\u6027\u5d4c\u5165\u6295\u5f71\u8fd1\u4f3c\u8d21\u732e\u611f\u77e5\u4fe1\u7528\u5206\u914d\uff1b4) \u901a\u8fc7\u4f30\u8ba1\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u8fb9\u9645\u6548\u7528\u5b9e\u73b0\u660e\u786e\u7684\u8bc1\u636e\u5f52\u56e0\u3002", "result": "\u5728\u591a\u79cd\u80bf\u7624\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u771f\u5b9e\u4e16\u754c\u591a\u5b66\u79d1\u80bf\u7624\u59d4\u5458\u4f1a\u6570\u636e\u96c6\uff09\u4e2d\uff0cCoMMa\u6bd4\u6570\u636e\u96c6\u4e2d\u5316\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002", "conclusion": "CoMMa\u901a\u8fc7\u8d21\u732e\u611f\u77e5\u4fe1\u7528\u5206\u914d\u673a\u5236\uff0c\u4e3a\u533b\u7597\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u3001\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u4e14\u7a33\u5b9a\u7684\u51b3\u7b56\u8def\u5f84\uff0c\u5728\u80bf\u7624\u5b66\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.09997", "categories": ["cs.SI", "q-bio.NC", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.09997", "abs": "https://arxiv.org/abs/2602.09997", "authors": ["Lucas Gautheron", "Raja Marjieh", "Dalton C. Conley", "Seth Frey", "Hannah Rubin", "Mike D. Schneider", "Ofer Tchernichovski", "Nori Jacoby"], "title": "Popularity Feedback Constrains Innovation in Cultural Markets", "comment": null, "summary": "Real-world creative processes ranging from art to science rely on social feedback-loops between selection and creation. Yet, the effects of popularity feedback on collective creativity remain poorly understood. We investigate how popularity ratings influence cultural dynamics in a large-scale online experiment where participants ($N = 1\\,008$) iteratively \\textit{select} images from evolving markets and \\textit{produce} their own modifications. Results show that exposing the popularity of images reduces cultural diversity and slows innovation, delaying aesthetic improvements. These findings are mediated by alterations of both selection and creation. During selection, popularity information triggers cumulative advantage, with participants preferentially building upon popular images, reducing diversity. During creation, participants make less disruptive changes, and are more likely to expand existing visual patterns. Feedback loops in cultural markets thus not only shape selection, but also, directly or indirectly, the form and direction of cultural innovation.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\uff0c\u5728\u521b\u610f\u5e02\u573a\u4e2d\u66b4\u9732\u6d41\u884c\u5ea6\u4fe1\u606f\u4f1a\u964d\u4f4e\u6587\u5316\u591a\u6837\u6027\u3001\u51cf\u7f13\u521b\u65b0\u901f\u5ea6\uff0c\u5e76\u5ef6\u8fdf\u5ba1\u7f8e\u6539\u8fdb\uff0c\u8fd9\u4e3b\u8981\u901a\u8fc7\u5f71\u54cd\u9009\u62e9\u548c\u521b\u9020\u4e24\u4e2a\u73af\u8282\u5b9e\u73b0\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u521b\u610f\u8fc7\u7a0b\uff08\u4ece\u827a\u672f\u5230\u79d1\u5b66\uff09\u4f9d\u8d56\u4e8e\u9009\u62e9\u548c\u521b\u9020\u4e4b\u95f4\u7684\u793e\u4f1a\u53cd\u9988\u5faa\u73af\uff0c\u4f46\u6d41\u884c\u5ea6\u53cd\u9988\u5bf9\u96c6\u4f53\u521b\u9020\u529b\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7a76\u6d41\u884c\u5ea6\u8bc4\u7ea7\u5982\u4f55\u5f71\u54cd\u6587\u5316\u52a8\u6001\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u5728\u7ebf\u5b9e\u9a8c\uff08N=1008\uff09\uff0c\u53c2\u4e0e\u8005\u4ece\u4e0d\u65ad\u6f14\u5316\u7684\u5e02\u573a\u4e2d\u9009\u62e9\u56fe\u50cf\uff0c\u5e76\u5236\u4f5c\u81ea\u5df1\u7684\u4fee\u6539\u7248\u672c\uff0c\u7814\u7a76\u6bd4\u8f83\u4e86\u66b4\u9732\u4e0e\u4e0d\u66b4\u9732\u56fe\u50cf\u6d41\u884c\u5ea6\u4fe1\u606f\u7684\u60c5\u51b5\u3002", "result": "\u66b4\u9732\u56fe\u50cf\u6d41\u884c\u5ea6\u4fe1\u606f\u4f1a\u964d\u4f4e\u6587\u5316\u591a\u6837\u6027\u5e76\u51cf\u7f13\u521b\u65b0\uff0c\u5ef6\u8fdf\u5ba1\u7f8e\u6539\u8fdb\u3002\u5728\u9009\u62e9\u73af\u8282\uff0c\u6d41\u884c\u5ea6\u4fe1\u606f\u5f15\u53d1\u7d2f\u79ef\u4f18\u52bf\u6548\u5e94\uff0c\u53c2\u4e0e\u8005\u503e\u5411\u4e8e\u57fa\u4e8e\u6d41\u884c\u56fe\u50cf\u8fdb\u884c\u521b\u4f5c\uff1b\u5728\u521b\u9020\u73af\u8282\uff0c\u53c2\u4e0e\u8005\u505a\u51fa\u7684\u6539\u53d8\u66f4\u5c11\u98a0\u8986\u6027\uff0c\u66f4\u503e\u5411\u4e8e\u6269\u5c55\u73b0\u6709\u89c6\u89c9\u6a21\u5f0f\u3002", "conclusion": "\u6587\u5316\u5e02\u573a\u4e2d\u7684\u53cd\u9988\u5faa\u73af\u4e0d\u4ec5\u5f71\u54cd\u9009\u62e9\uff0c\u8fd8\u76f4\u63a5\u6216\u95f4\u63a5\u5730\u5851\u9020\u6587\u5316\u521b\u65b0\u7684\u5f62\u5f0f\u548c\u65b9\u5411\u3002\u6d41\u884c\u5ea6\u4fe1\u606f\u53ef\u80fd\u5bf9\u96c6\u4f53\u521b\u9020\u529b\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u964d\u4f4e\u591a\u6837\u6027\u548c\u521b\u65b0\u901f\u5ea6\u3002"}}
{"id": "2602.09286", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09286", "abs": "https://arxiv.org/abs/2602.09286", "authors": ["Hanjing Shi", "Dominic DiFranzo"], "title": "Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities", "comment": null, "summary": "Oversight for agentic AI is often discussed as a single goal (\"human control\"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium.\n  Using topic modeling in a shared comparison space, a coarse-grained oversight-theme abstraction, engagement-weighted salience, and divergence tests, we show the communities are strongly separable (JSD =0.418, cosine =0.372, permutation $p=0.0005$). Across both communities, \"human control\" is an anchor term, but its operational meaning diverges: r/OpenClaw} emphasizes execution guardrails and recovery (action-risk), while r/Moltbook} emphasizes identity, legitimacy, and accountability in public interaction (meaning-risk). The resulting distinction offers a portable lens for designing and evaluating oversight mechanisms that match agent role, rather than applying one-size-fits-all control policies.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5206\u6790Reddit\u4e0a\u4e24\u4e2aAI\u4ee3\u7406\u76f8\u5173\u793e\u533a(r/OpenClaw\u548cr/Moltbook)\uff0c\u53d1\u73b0\u4e0d\u540c\u793e\u4f1a\u6280\u672f\u89d2\u8272\u5bf9\"\u4eba\u7c7b\u63a7\u5236\"\u7684\u7406\u89e3\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u89d2\u8272\u5339\u914d\u7684\u76d1\u7763\u673a\u5236\u8bbe\u8ba1\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u5173\u4e8eAI\u4ee3\u7406\u76d1\u7763\u7684\u8ba8\u8bba\u5f80\u5f80\u5c06\"\u4eba\u7c7b\u63a7\u5236\"\u89c6\u4e3a\u5355\u4e00\u76ee\u6807\uff0c\u4f46\u65e9\u671f\u91c7\u7528\u53ef\u80fd\u4ea7\u751f\u89d2\u8272\u7279\u5b9a\u7684\u671f\u671b\u3002\u9700\u8981\u7406\u89e3\u4e0d\u540c\u793e\u4f1a\u6280\u672f\u89d2\u8272\u5982\u4f55\u5f62\u6210\u4e0d\u540c\u7684\u76d1\u7763\u671f\u671b\u3002", "method": "\u6bd4\u8f83\u5206\u67902026\u5e741-2\u6708\u4e24\u4e2a\u6d3b\u8dc3\u7684Reddit\u793e\u533a\uff1ar/OpenClaw\uff08\u90e8\u7f72\u548c\u8fd0\u8425\uff09\u548cr/Moltbook\uff08\u4ee3\u7406\u4e2d\u5fc3\u793e\u4ea4\u4e92\u52a8\uff09\u3002\u4f7f\u7528\u4e3b\u9898\u5efa\u6a21\u3001\u5171\u4eab\u6bd4\u8f83\u7a7a\u95f4\u3001\u7c97\u7c92\u5ea6\u76d1\u7763\u4e3b\u9898\u62bd\u8c61\u3001\u53c2\u4e0e\u5ea6\u52a0\u6743\u663e\u8457\u6027\u548c\u5206\u6b67\u6d4b\u8bd5\u7b49\u65b9\u6cd5\u3002", "result": "\u4e24\u4e2a\u793e\u533a\u5728\u76d1\u7763\u671f\u671b\u4e0a\u5f3a\u70c8\u53ef\u5206\uff08JSD=0.418\uff0c\u4f59\u5f26\u76f8\u4f3c\u5ea6=0.372\uff0c\u7f6e\u6362\u68c0\u9a8cp=0.0005\uff09\u3002\u867d\u7136\"\u4eba\u7c7b\u63a7\u5236\"\u90fd\u662f\u951a\u5b9a\u672f\u8bed\uff0c\u4f46\u5176\u64cd\u4f5c\u542b\u4e49\u4e0d\u540c\uff1ar/OpenClaw\u5f3a\u8c03\u6267\u884c\u62a4\u680f\u548c\u6062\u590d\uff08\u884c\u52a8\u98ce\u9669\uff09\uff0cr/Moltbook\u5f3a\u8c03\u8eab\u4efd\u3001\u5408\u6cd5\u6027\u548c\u516c\u5171\u4e92\u52a8\u4e2d\u7684\u95ee\u8d23\uff08\u610f\u4e49\u98ce\u9669\uff09\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u9700\u8981\u6839\u636eAI\u4ee3\u7406\u7684\u5177\u4f53\u89d2\u8272\u8bbe\u8ba1\u5339\u914d\u7684\u76d1\u7763\u673a\u5236\uff0c\u800c\u4e0d\u662f\u91c7\u7528\u4e00\u5200\u5207\u7684\u63a7\u5236\u7b56\u7565\u3002\u8fd9\u79cd\u533a\u5206\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u79fb\u690d\u7684\u89c6\u89d2\uff0c\u7528\u4e8e\u8bbe\u8ba1\u548c\u8bc4\u4f30\u4e0e\u4ee3\u7406\u89d2\u8272\u76f8\u5339\u914d\u7684\u76d1\u7763\u673a\u5236\u3002"}}
{"id": "2602.09163", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09163", "abs": "https://arxiv.org/abs/2602.09163", "authors": ["Xingjian Zhang", "Sophia Moylan", "Ziyang Xiong", "Qiaozhu Mei", "Yichen Luo", "Jiaqi W. Ma"], "title": "FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases", "comment": null, "summary": "Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to evaluate AI agents on end-to-end agentic ontology curation from scientific literature. Given only a gene symbol, agents must search and read from a corpus of 16,898 full-text papers to produce structured annotations: Gene Ontology terms describing function, expression patterns, and historical synonyms linking decades of nomenclature. The benchmark includes 7,397 expert-curated annotations across 100 genes drawn from FlyBase, the Drosophila (fruit fly) knowledge base. We evaluate four baseline agent architectures: memorization, fixed pipeline, single-agent, and multi-agent. We find that architectural choices significantly impact performance, with multi-agent designs outperforming simpler alternatives, yet scaling backbone models yields diminishing returns. All baselines leave substantial room for improvement. Our analysis surfaces several findings to guide future development; for example, agents primarily use retrieval to confirm parametric knowledge rather than discover new information. We hope FlyBench will drive progress on retrieval-augmented scientific reasoning, a capability with broad applications across scientific domains.", "AI": {"tldr": "FlyBench\u662f\u4e00\u4e2a\u8bc4\u4f30AI\u667a\u80fd\u4f53\u4ece\u79d1\u5b66\u6587\u732e\u4e2d\u8fdb\u884c\u7aef\u5230\u7aef\u672c\u4f53\u8bba\u7b56\u5c55\u7684\u57fa\u51c6\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u57fa\u4e8e\u57fa\u56e0\u7b26\u53f7\u641c\u7d22\u548c\u9605\u8bfb16,898\u7bc7\u5168\u6587\u8bba\u6587\uff0c\u751f\u6210\u7ed3\u6784\u5316\u6ce8\u91ca\uff0c\u5305\u62ec\u57fa\u56e0\u672c\u4f53\u8bba\u672f\u8bed\u3001\u8868\u8fbe\u6a21\u5f0f\u548c\u5386\u53f2\u540c\u4e49\u8bcd\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6216\u5173\u7cfb\u63d0\u53d6\u7b49\u5b64\u7acb\u5b50\u4efb\u52a1\uff0c\u65e0\u6cd5\u6355\u6349\u79d1\u5b66\u77e5\u8bc6\u5e93\u7ef4\u62a4\u6240\u9700\u7684\u7aef\u5230\u7aef\u7b56\u5c55\u5de5\u4f5c\u6d41\u7a0b\uff0c\u9700\u8981\u8bc4\u4f30AI\u667a\u80fd\u4f53\u5728\u5b9e\u9645\u79d1\u5b66\u6587\u732e\u7b56\u5c55\u4e2d\u7684\u7efc\u5408\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b7,397\u4e2a\u4e13\u5bb6\u7b56\u5c55\u6ce8\u91ca\u7684\u57fa\u51c6\uff0c\u6db5\u76d6100\u4e2a\u57fa\u56e0\uff0c\u4eceFlyBase\uff08\u679c\u8747\u77e5\u8bc6\u5e93\uff09\u63d0\u53d6\u3002\u8bc4\u4f30\u56db\u79cd\u57fa\u7ebf\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u8bb0\u5fc6\u5316\u3001\u56fa\u5b9a\u6d41\u6c34\u7ebf\u3001\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u4ece16,898\u7bc7\u5168\u6587\u8bba\u6587\u4e2d\u641c\u7d22\u548c\u9605\u8bfb\u4fe1\u606f\u3002", "result": "\u67b6\u6784\u9009\u62e9\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u4f18\u4e8e\u7b80\u5355\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u6269\u5c55\u9aa8\u5e72\u6a21\u578b\u5e26\u6765\u7684\u6536\u76ca\u9012\u51cf\u3002\u6240\u6709\u57fa\u7ebf\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\uff0c\u5206\u6790\u53d1\u73b0\u667a\u80fd\u4f53\u4e3b\u8981\u4f7f\u7528\u68c0\u7d22\u6765\u786e\u8ba4\u53c2\u6570\u77e5\u8bc6\u800c\u975e\u53d1\u73b0\u65b0\u4fe1\u606f\u3002", "conclusion": "FlyBench\u5c06\u63a8\u52a8\u68c0\u7d22\u589e\u5f3a\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\uff0c\u8fd9\u79cd\u80fd\u529b\u5728\u79d1\u5b66\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\uff0c\u4e3a\u672a\u6765AI\u667a\u80fd\u4f53\u5728\u79d1\u5b66\u6587\u732e\u7b56\u5c55\u65b9\u9762\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2602.10001", "categories": ["cs.SI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10001", "abs": "https://arxiv.org/abs/2602.10001", "authors": ["Chenyi Li", "Raja Marjieh", "Haoyu Hu", "Mark Steyvers", "Katherine M. Collins", "Ilia Sucholutsky", "Nori Jacoby"], "title": "Human-AI Synergy Supports Collective Creative Search", "comment": null, "summary": "Generative AI is increasingly transforming creativity into a hybrid human-artificial process, but its impact on the quality and diversity of creative output remains unclear. We study collective creativity using a controlled word-guessing task that balances open-endedness with an objective measure of task performance. Participants attempt to infer a hidden target word, scored based on the semantic similarity of their guesses to the target, while also observing the best guess from previous players. We compare performance and outcome diversity across human-only, AI-only, and hybrid human-AI groups. Hybrid groups achieve the highest performance while preserving high diversity of guesses. Within hybrid groups, both humans and AI agents systematically adjust their strategies relative to single-agent conditions, suggesting higher-order interaction effects, whereby agents adapt to each other's presence. Although some performance benefits can be reproduced through collaboration between heterogeneous AI systems, human-AI collaboration remains superior, underscoring complementary roles in collective creativity.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5355\u8bcd\u731c\u6d4b\u4efb\u52a1\u6bd4\u8f83\u4eba\u7c7b\u3001AI\u53ca\u6df7\u5408\u56e2\u961f\u7684\u521b\u9020\u8868\u73b0\uff0c\u53d1\u73b0\u6df7\u5408\u56e2\u961f\u8868\u73b0\u6700\u4f73\u4e14\u4fdd\u6301\u9ad8\u591a\u6837\u6027\uff0c\u4eba\u7c7b\u4e0eAI\u5b58\u5728\u9ad8\u9636\u4e92\u52a8\u6548\u5e94\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5c06\u521b\u9020\u529b\u8f6c\u53d8\u4e3a\u6df7\u5408\u4eba\u673a\u8fc7\u7a0b\uff0c\u4f46\u5176\u5bf9\u521b\u610f\u8f93\u51fa\u8d28\u91cf\u548c\u591a\u6837\u6027\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7814\u7a76\u96c6\u4f53\u521b\u9020\u529b\u4e2d\u4eba\u673a\u534f\u4f5c\u7684\u6548\u679c\u3002", "method": "\u91c7\u7528\u53d7\u63a7\u5355\u8bcd\u731c\u6d4b\u4efb\u52a1\uff0c\u5e73\u8861\u5f00\u653e\u6027\u4e0e\u5ba2\u89c2\u6027\u80fd\u6307\u6807\u3002\u53c2\u4e0e\u8005\u63a8\u65ad\u9690\u85cf\u76ee\u6807\u8bcd\uff0c\u6839\u636e\u731c\u6d4b\u4e0e\u76ee\u6807\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8bc4\u5206\uff0c\u540c\u65f6\u89c2\u5bdf\u524d\u73a9\u5bb6\u7684\u6700\u4f73\u731c\u6d4b\u3002\u6bd4\u8f83\u7eaf\u4eba\u7c7b\u3001\u7eafAI\u548c\u6df7\u5408\u4eba\u673a\u4e09\u7ec4\u7684\u8868\u73b0\u548c\u7ed3\u679c\u591a\u6837\u6027\u3002", "result": "\u6df7\u5408\u7ec4\u8868\u73b0\u6700\u4f73\u4e14\u4fdd\u6301\u9ad8\u731c\u6d4b\u591a\u6837\u6027\u3002\u5728\u6df7\u5408\u7ec4\u4e2d\uff0c\u4eba\u7c7b\u548cAI\u90fd\u76f8\u5bf9\u4e8e\u5355\u667a\u80fd\u4f53\u6761\u4ef6\u7cfb\u7edf\u8c03\u6574\u7b56\u7565\uff0c\u8868\u660e\u5b58\u5728\u9ad8\u9636\u4e92\u52a8\u6548\u5e94\u3002\u867d\u7136\u5f02\u8d28AI\u7cfb\u7edf\u534f\u4f5c\u80fd\u91cd\u73b0\u90e8\u5206\u6027\u80fd\u4f18\u52bf\uff0c\u4f46\u4eba\u673a\u534f\u4f5c\u4ecd\u66f4\u4f18\u8d8a\u3002", "conclusion": "\u4eba\u673a\u534f\u4f5c\u5728\u96c6\u4f53\u521b\u9020\u529b\u4e2d\u5177\u6709\u4e92\u8865\u4f5c\u7528\uff0c\u6df7\u5408\u56e2\u961f\u80fd\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u540c\u65f6\u4fdd\u6301\u9ad8\u591a\u6837\u6027\uff0c\u7a81\u663e\u4e86\u4eba\u7c7b\u4e0eAI\u5728\u521b\u610f\u8fc7\u7a0b\u4e2d\u7684\u534f\u540c\u4ef7\u503c\u3002"}}
{"id": "2602.09340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09340", "abs": "https://arxiv.org/abs/2602.09340", "authors": ["Yang Ba", "Mohammad Sadeq Abolhasani", "Michelle V Mancenido", "Rong Pan"], "title": "Measuring Dataset Diversity from a Geometric Perspective", "comment": null, "summary": "Diversity can be broadly defined as the presence of meaningful variation across elements, which can be viewed from multiple perspectives, including statistical variation and geometric structural richness in the dataset. Existing diversity metrics, such as feature-space dispersion and metric-space magnitude, primarily capture distributional variation or entropy, while largely neglecting the geometric structure of datasets. To address this gap, we introduce a framework based on topological data analysis (TDA) and persistence landscapes (PLs) to extract and quantify geometric features from data. This approach provides a theoretically grounded means of measuring diversity beyond entropy, capturing the rich geometric and structural properties of datasets. Through extensive experiments across diverse modalities, we demonstrate that our proposed PLs-based diversity metric (PLDiv) is powerful, reliable, and interpretable, directly linking data diversity to its underlying geometry and offering a foundational tool for dataset construction, augmentation, and evaluation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790(TDA)\u548c\u6301\u4e45\u6027\u666f\u89c2(PLs)\u7684\u51e0\u4f55\u591a\u6837\u6027\u5ea6\u91cf\u6846\u67b6PLDiv\uff0c\u8d85\u8d8a\u4f20\u7edf\u71b5\u5ea6\u91cf\uff0c\u6355\u6349\u6570\u636e\u96c6\u51e0\u4f55\u7ed3\u6784", "motivation": "\u73b0\u6709\u591a\u6837\u6027\u5ea6\u91cf\u4e3b\u8981\u5173\u6ce8\u7edf\u8ba1\u53d8\u5f02\u548c\u5206\u5e03\u71b5\uff0c\u5ffd\u7565\u4e86\u6570\u636e\u96c6\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u6355\u6349\u51e0\u4f55\u7279\u5f81\u7684\u7406\u8bba\u57fa\u7840\u65b9\u6cd5", "method": "\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u548c\u6301\u4e45\u6027\u666f\u89c2\u6846\u67b6\uff0c\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u548c\u91cf\u5316\u51e0\u4f55\u7279\u5f81\uff0c\u63d0\u51faPLDiv\u5ea6\u91cf", "result": "PLDiv\u5728\u591a\u79cd\u6a21\u6001\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u3001\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u76f4\u63a5\u5173\u8054\u6570\u636e\u591a\u6837\u6027\u4e0e\u5176\u5e95\u5c42\u51e0\u4f55\u7ed3\u6784", "conclusion": "PLDiv\u4e3a\u6570\u636e\u96c6\u6784\u5efa\u3001\u589e\u5f3a\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u57fa\u7840\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8a\u71b5\u7684\u51e0\u4f55\u591a\u6837\u6027\u5ea6\u91cf"}}
{"id": "2602.09341", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09341", "abs": "https://arxiv.org/abs/2602.09341", "authors": ["Wei Yang", "Shixuan Li", "Heng Ping", "Peiyu Zhang", "Paul Bogdan", "Jesse Thomason"], "title": "Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge", "comment": null, "summary": "Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge.", "AI": {"tldr": "AgentAuditor\uff1a\u7528\u63a8\u7406\u6811\u8def\u5f84\u641c\u7d22\u66ff\u4ee3\u591a\u6570\u6295\u7968\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u5c40\u90e8\u9a8c\u8bc1\u89e3\u51b3\u667a\u80fd\u4f53\u95f4\u7684\u51b2\u7a81\uff0c\u7ed3\u5408ACPO\u8bad\u7ec3\u63d0\u5347\u5c11\u6570\u6b63\u786e\u9009\u62e9\u7684\u8bc6\u522b\u80fd\u529b", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5927\u591a\u4f7f\u7528\u591a\u6570\u6295\u7968\u805a\u5408\u667a\u80fd\u4f53\u8f93\u51fa\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e22\u5f03\u4e86\u63a8\u7406\u8f68\u8ff9\u7684\u8bc1\u636e\u7ed3\u6784\uff0c\u4e14\u5728\u667a\u80fd\u4f53\u5b58\u5728\u76f8\u5173\u504f\u89c1\u5e76\u6536\u655b\u5230\u76f8\u540c\u9519\u8bef\u63a8\u7406\u65f6\uff08\u5171\u8bc6\u5e7b\u89c9\uff09\u8868\u73b0\u8106\u5f31", "method": "1. \u5f15\u5165AgentAuditor\u6846\u67b6\uff0c\u7528\u63a8\u7406\u6811\u8def\u5f84\u641c\u7d22\u66ff\u4ee3\u6295\u7968\uff0c\u663e\u5f0f\u8868\u793a\u667a\u80fd\u4f53\u8f68\u8ff9\u95f4\u7684\u5171\u8bc6\u4e0e\u5206\u6b67\uff1b2. \u5728\u5173\u952e\u5206\u6b67\u70b9\u6bd4\u8f83\u63a8\u7406\u5206\u652f\uff0c\u5c06\u5168\u5c40\u88c1\u51b3\u8f6c\u5316\u4e3a\u5c40\u90e8\u9a8c\u8bc1\uff1b3. \u63d0\u51fa\u53cd\u5171\u8bc6\u504f\u597d\u4f18\u5316\uff08ACPO\uff09\uff0c\u5728\u591a\u6570\u5931\u8d25\u6848\u4f8b\u4e0a\u8bad\u7ec3\u88c1\u51b3\u5668\uff0c\u5956\u52b1\u57fa\u4e8e\u8bc1\u636e\u7684\u5c11\u6570\u9009\u62e9\u800c\u975e\u6d41\u884c\u9519\u8bef", "result": "\u57285\u4e2a\u6d41\u884c\u8bbe\u7f6e\u4e2d\uff0cAgentAuditor\u76f8\u6bd4\u591a\u6570\u6295\u7968\u5e26\u6765\u9ad8\u8fbe5%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347\uff0c\u76f8\u6bd4\u4f7f\u7528LLM-as-Judge\u63d0\u5347\u9ad8\u8fbe3%", "conclusion": "AgentAuditor\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e0e\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u65e0\u5173\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u63a8\u7406\u5206\u6b67\u548c\u5c40\u90e8\u9a8c\u8bc1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5171\u8bc6\u5e7b\u89c9\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u51c6\u786e\u6027"}}
{"id": "2602.09343", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09343", "abs": "https://arxiv.org/abs/2602.09343", "authors": ["Michail S. Alexiou", "J. Sukarno Mertoguno"], "title": "Not-in-Perspective: Towards Shielding Google's Perspective API Against Adversarial Negation Attacks", "comment": null, "summary": "The rise of cyberbullying in social media platforms involving toxic comments has escalated the need for effective ways to monitor and moderate online interactions. Existing solutions of automated toxicity detection systems, are based on a machine or deep learning algorithms. However, statistics-based solutions are generally prone to adversarial attacks that contain logic based modifications such as negation in phrases and sentences. In that regard, we present a set of formal reasoning-based methodologies that wrap around existing machine learning toxicity detection systems. Acting as both pre-processing and post-processing steps, our formal reasoning wrapper helps alleviating the negation attack problems and significantly improves the accuracy and efficacy of toxicity scoring. We evaluate different variations of our wrapper on multiple machine learning models against a negation adversarial dataset. Experimental results highlight the improvement of hybrid (formal reasoning and machine-learning) methods against various purely statistical solutions.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5f62\u5f0f\u63a8\u7406\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u6bd2\u6027\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u6297\u5426\u5b9a\u653b\u51fb\u7684\u80fd\u529b", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e2d\u7f51\u7edc\u6b3a\u51cc\u548c\u6709\u6bd2\u8bc4\u8bba\u65e5\u76ca\u4e25\u91cd\uff0c\u73b0\u6709\u57fa\u4e8e\u7edf\u8ba1\u7684\u673a\u5668\u5b66\u4e60\u6bd2\u6027\u68c0\u6d4b\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u5305\u542b\u5426\u5b9a\u903b\u8f91\u7684\u5bf9\u6297\u653b\u51fb", "method": "\u5f00\u53d1\u5f62\u5f0f\u63a8\u7406\u5305\u88c5\u5668\uff0c\u4f5c\u4e3a\u9884\u5904\u7406\u548c\u540e\u5904\u7406\u6b65\u9aa4\uff0c\u5305\u88f9\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6bd2\u6027\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4e13\u95e8\u5904\u7406\u5426\u5b9a\u653b\u51fb\u95ee\u9898", "result": "\u5728\u5426\u5b9a\u5bf9\u6297\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u6df7\u5408\u65b9\u6cd5\u76f8\u6bd4\u7eaf\u7edf\u8ba1\u89e3\u51b3\u65b9\u6848\u663e\u8457\u63d0\u9ad8\u4e86\u6bd2\u6027\u8bc4\u5206\u7684\u51c6\u786e\u6027\u548c\u6709\u6548\u6027", "conclusion": "\u5f62\u5f0f\u63a8\u7406\u4e0e\u673a\u5668\u5b66\u4e60\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u5426\u5b9a\u653b\u51fb\u95ee\u9898\uff0c\u63d0\u5347\u6bd2\u6027\u68c0\u6d4b\u7cfb\u7edf\u7684\u9c81\u68d2\u6027"}}
{"id": "2602.09347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09347", "abs": "https://arxiv.org/abs/2602.09347", "authors": ["Jana G. Delfino", "Jason L. Granstedt", "Frank W. Samuelson", "Robert Ochs", "Krishna Juluru"], "title": "Image Quality in the Era of Artificial Intelligence", "comment": "16 pages, 3 figures", "summary": "Artificial intelligence (AI) is being deployed within radiology at a rapid pace. AI has proven an excellent tool for reconstructing and enhancing images that appear sharper, smoother, and more detailed, can be acquired more quickly, and allowing clinicians to review them more rapidly. However, incorporation of AI also introduces new failure modes and can exacerbate the disconnect between perceived quality of an image and information content of that image. Understanding the limitations of AI-enabled image reconstruction and enhancement is critical for safe and effective use of the technology. Hence, the purpose of this communication is to bring awareness to limitations when AI is used to reconstruct or enhance a radiological image, with the goal of enabling users to reap benefits of the technology while minimizing risks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8AI\u5728\u653e\u5c04\u5b66\u56fe\u50cf\u91cd\u5efa\u4e0e\u589e\u5f3a\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u65e8\u5728\u5e2e\u52a9\u7528\u6237\u5b89\u5168\u6709\u6548\u5730\u4f7f\u7528\u8be5\u6280\u672f", "motivation": "AI\u5728\u653e\u5c04\u5b66\u4e2d\u5feb\u901f\u90e8\u7f72\uff0c\u867d\u7136\u80fd\u63d0\u9ad8\u56fe\u50cf\u8d28\u91cf\u548c\u5904\u7406\u901f\u5ea6\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u52a0\u5267\u4e86\u56fe\u50cf\u611f\u77e5\u8d28\u91cf\u4e0e\u4fe1\u606f\u5185\u5bb9\u4e4b\u95f4\u7684\u8131\u8282\u3002\u7406\u89e3AI\u56fe\u50cf\u91cd\u5efa\u548c\u589e\u5f3a\u7684\u5c40\u9650\u6027\u5bf9\u4e8e\u5b89\u5168\u6709\u6548\u4f7f\u7528\u8be5\u6280\u672f\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u662f\u4e00\u7bc7\u901a\u4fe1/\u7efc\u8ff0\u6587\u7ae0\uff0c\u901a\u8fc7\u5206\u6790AI\u5728\u653e\u5c04\u5b66\u56fe\u50cf\u5904\u7406\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\uff0c\u63d0\u51fa\u5bf9AI\u56fe\u50cf\u91cd\u5efa\u548c\u589e\u5f3a\u6280\u672f\u5c40\u9650\u6027\u7684\u7cfb\u7edf\u6027\u8ba4\u8bc6\u3002", "result": "\u6587\u7ae0\u6307\u51faAI\u867d\u7136\u80fd\u4ea7\u751f\u66f4\u6e05\u6670\u3001\u66f4\u5e73\u6ed1\u3001\u66f4\u8be6\u7ec6\u7684\u56fe\u50cf\uff0c\u5e76\u52a0\u5feb\u83b7\u53d6\u548c\u5ba1\u67e5\u901f\u5ea6\uff0c\u4f46\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u5931\u8d25\u98ce\u9669\uff0c\u53ef\u80fd\u5bfc\u81f4\u56fe\u50cf\u611f\u77e5\u8d28\u91cf\u4e0e\u5b9e\u9645\u4fe1\u606f\u5185\u5bb9\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u3002", "conclusion": "\u9700\u8981\u63d0\u9ad8\u5bf9AI\u56fe\u50cf\u91cd\u5efa\u548c\u589e\u5f3a\u6280\u672f\u5c40\u9650\u6027\u7684\u8ba4\u8bc6\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u5728\u4eab\u53d7\u6280\u672f\u76ca\u5904\u7684\u540c\u65f6\u6700\u5c0f\u5316\u98ce\u9669\uff0c\u786e\u4fdd\u5b89\u5168\u6709\u6548\u5730\u5e94\u7528AI\u4e8e\u653e\u5c04\u5b66\u5b9e\u8df5\u3002"}}
{"id": "2602.09443", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09443", "abs": "https://arxiv.org/abs/2602.09443", "authors": ["Yun Luo", "Futing Wang", "Qianjia Cheng", "Fangchen Yu", "Haodi Lei", "Jianhao Yan", "Chenxi Li", "Jiacheng Chen", "Yufeng Zhao", "Haiyuan Wan", "Yuchen Zhang", "Shenghe Zheng", "Junchi Yao", "Qingyang Zhang", "Haonan He", "Wenxuan Zeng", "Li Sheng", "Chengxing Xie", "Yuxin Zuo", "Yizhuo Li", "Yulun Wu", "Rui Huang", "Dongzhan Zhou", "Kai Chen", "Yu Qiao", "Lei Bai", "Yu Cheng", "Ning Ding", "Bowen Zhou", "Peng Ye", "Ganqu Cui"], "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads", "comment": null, "summary": "The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative, containing essential constraints, such as boundary conditions and spatial symmetries, that are absent from the text. To bridge this visual-logical gap, we introduce P1-VL, a family of open-source vision-language models engineered for advanced scientific reasoning. Our method harmonizes Curriculum Reinforcement Learning, which employs progressive difficulty expansion to stabilize post-training, with Agentic Augmentation, enabling iterative self-verification at inference. Evaluated on HiPhO, a rigorous benchmark of 13 exams from 2024-2025, our flagship P1-VL-235B-A22B becomes the first open-source Vision-Language Model (VLM) to secure 12 gold medals and achieves the state-of-the-art performance in the open-source models. Our agent-augmented system achieves the No.2 overall rank globally, trailing only Gemini-3-Pro. Beyond physics, P1-VL demonstrates remarkable scientific reasoning capacity and generalizability, establishing significant leads over base models in STEM benchmarks. By open-sourcing P1-VL, we provide a foundational step toward general-purpose physical intelligence to better align visual perceptions with abstract physical laws for machine scientific discovery.", "AI": {"tldr": "P1-VL\u662f\u4e00\u4e2a\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\uff0c\u4e13\u4e3a\u9ad8\u7ea7\u79d1\u5b66\u63a8\u7406\u8bbe\u8ba1\uff0c\u5728\u7269\u7406\u5965\u6797\u5339\u514b\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u5f00\u6e90\u6a21\u578b\u6700\u4f73\u6027\u80fd\uff0c\u5168\u7403\u6392\u540d\u7b2c\u4e8c\uff0c\u4ec5\u6b21\u4e8eGemini-3-Pro\u3002", "motivation": "\u4ece\u7b26\u53f7\u64cd\u4f5c\u5230\u79d1\u5b66\u7ea7\u63a8\u7406\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5173\u952e\u524d\u6cbf\uff0c\u7269\u7406\u4f5c\u4e3a\u8fde\u63a5\u62bd\u8c61\u903b\u8f91\u4e0e\u7269\u7406\u73b0\u5b9e\u7684\u6d4b\u8bd5\u951a\u70b9\u3002\u7269\u7406\u8981\u6c42\u6a21\u578b\u4fdd\u6301\u4e0e\u5b87\u5b99\u5b9a\u5f8b\u7684\u4e00\u81f4\u6027\uff0c\u8fd9\u9700\u8981\u591a\u6a21\u6001\u611f\u77e5\u5c06\u62bd\u8c61\u903b\u8f91\u4e0e\u73b0\u5b9e\u8054\u7cfb\u8d77\u6765\u3002\u5728\u5965\u6797\u5339\u514b\u7ea7\u522b\uff0c\u56fe\u8868\u901a\u5e38\u662f\u6784\u6210\u6027\u7684\u800c\u975e\u8bf4\u660e\u6027\u7684\uff0c\u5305\u542b\u6587\u672c\u4e2d\u7f3a\u5931\u7684\u5173\u952e\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u5f15\u5165P1-VL\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\uff0c\u7ed3\u5408\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\uff08\u91c7\u7528\u6e10\u8fdb\u96be\u5ea6\u6269\u5c55\u7a33\u5b9a\u540e\u8bad\u7ec3\uff09\u548c\u4ee3\u7406\u589e\u5f3a\uff08\u5728\u63a8\u7406\u65f6\u5b9e\u73b0\u8fed\u4ee3\u81ea\u6211\u9a8c\u8bc1\uff09\u3002", "result": "\u5728HiPhO\u57fa\u51c6\u6d4b\u8bd5\uff0813\u4e2a2024-2025\u5e74\u8003\u8bd5\uff09\u4e2d\uff0c\u65d7\u8230\u6a21\u578bP1-VL-235B-A22B\u6210\u4e3a\u9996\u4e2a\u83b7\u5f9712\u679a\u91d1\u724c\u7684\u5f00\u6e90VLM\uff0c\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002\u4ee3\u7406\u589e\u5f3a\u7cfb\u7edf\u5168\u7403\u6392\u540d\u7b2c\u4e8c\uff0c\u4ec5\u6b21\u4e8eGemini-3-Pro\u3002\u5728STEM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5f00\u6e90P1-VL\uff0c\u4e3a\u5b9e\u73b0\u901a\u7528\u7269\u7406\u667a\u80fd\u63d0\u4f9b\u4e86\u57fa\u7840\u6027\u6b65\u9aa4\uff0c\u66f4\u597d\u5730\u5c06\u89c6\u89c9\u611f\u77e5\u4e0e\u62bd\u8c61\u7269\u7406\u5b9a\u5f8b\u5bf9\u9f50\uff0c\u4fc3\u8fdb\u673a\u5668\u79d1\u5b66\u53d1\u73b0\u3002\u6a21\u578b\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u548c\u6cdb\u5316\u6027\u3002"}}
{"id": "2602.09463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09463", "abs": "https://arxiv.org/abs/2602.09463", "authors": ["Furong Jia", "Ling Dai", "Wenjin Deng", "Fan Zhang", "Chen Hu", "Daxin Jiang", "Yu Liu"], "title": "SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning", "comment": null, "summary": "Large Vision-Language Models (LVLMs) have demonstrated strong reasoning capabilities in geo-localization, yet they often struggle in real-world scenarios where visual cues are sparse, long-tailed, and highly ambiguous. Previous approaches, bound by internal knowledge, often fail to provide verifiable results, yielding confident but ungrounded predictions when faced with confounded evidence. To address these challenges, we propose SpotAgent, a framework that formalizes geo-localization into an agentic reasoning process that leverages expert-level reasoning to synergize visual interpretation with tool-assisted verification. SpotAgent actively explores and verifies visual cues by leveraging external tools (e.g., web search, maps) through a ReAct diagram. We introduce a 3-stage post-training pipeline starting with a Supervised Fine-Tuning (SFT) stage for basic alignment, followed by an Agentic Cold Start phase utilizing high-quality trajectories synthesized via a Multi-Agent framework, aiming to instill tool-calling expertise. Subsequently, the model's reasoning capabilities are refined through Reinforcement Learning. We propose a Spatially-Aware Dynamic Filtering strategy to enhance the efficiency of the RL stage by prioritizing learnable samples based on spatial difficulty. Extensive experiments on standard benchmarks demonstrate that SpotAgent achieves state-of-the-art performance, effectively mitigating hallucinations while delivering precise and verifiable geo-localization.", "AI": {"tldr": "SpotAgent\u662f\u4e00\u4e2a\u7528\u4e8e\u5730\u7406\u5b9a\u4f4d\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u89e3\u91ca\u548c\u5de5\u5177\u8f85\u52a9\u9a8c\u8bc1\u6765\u89e3\u51b3\u7a00\u758f\u3001\u957f\u5c3e\u548c\u6a21\u7cca\u89c6\u89c9\u7ebf\u7d22\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u7cbe\u51c6\u5b9a\u4f4d\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5730\u7406\u5b9a\u4f4d\u4e2d\u9762\u4e34\u89c6\u89c9\u7ebf\u7d22\u7a00\u758f\u3001\u957f\u5c3e\u5206\u5e03\u548c\u9ad8\u5ea6\u6a21\u7cca\u7684\u95ee\u9898\uff0c\u4e14\u53d7\u9650\u4e8e\u5185\u90e8\u77e5\u8bc6\uff0c\u7ecf\u5e38\u4ea7\u751f\u81ea\u4fe1\u4f46\u65e0\u6839\u636e\u7684\u9884\u6d4b\uff0c\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "\u63d0\u51faSpotAgent\u6846\u67b6\uff0c\u5c06\u5730\u7406\u5b9a\u4f4d\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u4f53\u63a8\u7406\u8fc7\u7a0b\uff0c\u901a\u8fc7ReAct\u56fe\u5229\u7528\u5916\u90e8\u5de5\u5177\uff08\u5982\u7f51\u7edc\u641c\u7d22\u3001\u5730\u56fe\uff09\u8fdb\u884c\u4e3b\u52a8\u63a2\u7d22\u548c\u9a8c\u8bc1\u3002\u91c7\u7528\u4e09\u9636\u6bb5\u540e\u8bad\u7ec3\u6d41\u7a0b\uff1a\u76d1\u7763\u5fae\u8c03\u5bf9\u9f50\u57fa\u7840\u80fd\u529b\u3001\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5408\u6210\u9ad8\u8d28\u91cf\u8f68\u8ff9\u7684\u667a\u80fd\u4f53\u51b7\u542f\u52a8\u9636\u6bb5\u3001\u4ee5\u53ca\u901a\u8fc7\u7a7a\u95f4\u611f\u77e5\u52a8\u6001\u8fc7\u6ee4\u7b56\u7565\u4f18\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSpotAgent\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\uff0c\u63d0\u4f9b\u7cbe\u786e\u4e14\u53ef\u9a8c\u8bc1\u7684\u5730\u7406\u5b9a\u4f4d\u7ed3\u679c\u3002", "conclusion": "SpotAgent\u901a\u8fc7\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\u7ed3\u5408\u89c6\u89c9\u89e3\u91ca\u548c\u5de5\u5177\u8f85\u52a9\u9a8c\u8bc1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5730\u7406\u5b9a\u4f4d\u4e2d\u7684\u7a00\u758f\u89c6\u89c9\u7ebf\u7d22\u548c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09485", "abs": "https://arxiv.org/abs/2602.09485", "authors": ["Yizhi Wang", "Linan Yue", "Min-Ling Zhang"], "title": "Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models", "comment": null, "summary": "Long chains of thought (Long CoTs) are widely employed in multimodal reasoning models to tackle complex tasks by capturing detailed visual information. However, these Long CoTs are often excessively lengthy and contain redundant reasoning steps, which can hinder inference efficiency. Compressing these long CoTs is a natural solution, yet existing approaches face two major challenges: (1) they may compromise the integrity of visual-textual reasoning by removing essential alignment cues, and (2) the compression process lacks explainability, making it difficult to discern which information is critical. To address these problems, we propose XMCC, an eXplainable Multimodal CoT Compressor that formulates compression as a sequential decision-making process optimized via reinforcement learning. XMCC can effectively shorten reasoning trajectories while preserving key reasoning steps and answer correctness, and simultaneously generates natural-language explanations for its compression decisions. Extensive experiments on representative multimodal reasoning benchmarks demonstrate that XMCC not only reduces reasoning length but also provides explainable explanations, validating its effectiveness.", "AI": {"tldr": "XMCC\uff1a\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5c06\u538b\u7f29\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5728\u7f29\u77ed\u63a8\u7406\u8f68\u8ff9\u7684\u540c\u65f6\u4fdd\u6301\u5173\u952e\u63a8\u7406\u6b65\u9aa4\u548c\u7b54\u6848\u6b63\u786e\u6027\uff0c\u5e76\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "motivation": "\u957f\u601d\u7ef4\u94fe\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5f80\u5f80\u8fc7\u4e8e\u5197\u957f\u4e14\u5305\u542b\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\uff0c\u5f71\u54cd\u63a8\u7406\u6548\u7387\u3002\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u53ef\u80fd\u7834\u574f\u89c6\u89c9-\u6587\u672c\u63a8\u7406\u7684\u5b8c\u6574\u6027\uff0c\u79fb\u9664\u5173\u952e\u5bf9\u9f50\u7ebf\u7d22\uff1b2) \u538b\u7f29\u8fc7\u7a0b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u8bc6\u522b\u54ea\u4e9b\u4fe1\u606f\u662f\u5173\u952e\u7684\u3002", "method": "\u63d0\u51faXMCC\uff08\u53ef\u89e3\u91ca\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u538b\u7f29\u5668\uff09\uff0c\u5c06\u538b\u7f29\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u7f29\u77ed\u63a8\u7406\u8f68\u8ff9\uff0c\u540c\u65f6\u4fdd\u7559\u5173\u952e\u63a8\u7406\u6b65\u9aa4\u548c\u7b54\u6848\u6b63\u786e\u6027\uff0c\u5e76\u4e3a\u538b\u7f29\u51b3\u7b56\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "\u5728\u4ee3\u8868\u6027\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cXMCC\u4e0d\u4ec5\u51cf\u5c11\u4e86\u63a8\u7406\u957f\u5ea6\uff0c\u8fd8\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u8bf4\u660e\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "XMCC\u89e3\u51b3\u4e86\u957f\u601d\u7ef4\u94fe\u538b\u7f29\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u4fdd\u6301\u63a8\u7406\u5b8c\u6574\u6027\u548c\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u9ad8\u6548\u4e14\u900f\u660e\u7684\u591a\u6a21\u6001\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09489", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09489", "abs": "https://arxiv.org/abs/2602.09489", "authors": ["Lars Henry Berge Olsen", "Dennis Christensen"], "title": "Computing Conditional Shapley Values Using Tabular Foundation Models", "comment": null, "summary": "Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation.", "AI": {"tldr": "TabPFN\u7b49\u8868\u683c\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u9ad8\u6548\u8ba1\u7b97Shapley\u503c\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u65f6\u95f4\u5927\u5e45\u51cf\u5c11\u3002", "motivation": "Shapley\u503c\u662f\u89e3\u91ca\u6027AI\u7684\u6838\u5fc3\u5de5\u5177\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u5c24\u5176\u5728\u7279\u5f81\u76f8\u5173\u65f6\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6761\u4ef6\u671f\u671b\u7684\u8fd1\u4f3c\u8ba1\u7b97\uff0c\u8981\u4e48\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u79ef\u5206\uff0c\u8981\u4e48\u901a\u8fc7\u56de\u5f52\u3002\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u56e0\u9700\u8981\u4e3a\u6bcf\u4e2a\u6761\u4ef6\u671f\u671b\u91cd\u65b0\u8bad\u7ec3\u800c\u8ba1\u7b97\u8017\u65f6\u8fc7\u957f\u3002", "method": "\u4f7f\u7528TabPFN\u7b49\u591a\u79cd\u8868\u683c\u57fa\u7840\u6a21\u578b\u53d8\u4f53\u8ba1\u7b97Shapley\u503c\uff0c\u5229\u7528\u5176\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u8fd1\u4f3c\u6bcf\u4e2a\u6761\u4ef6\u671f\u671b\u3002\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0cTabPFN\u8868\u73b0\u6700\u4f73\uff1b\u5373\u4f7f\u5728\u4e0d\u5360\u4f18\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u4ec5\u7565\u900a\u4e8e\u6700\u4f73\u65b9\u6cd5\uff0c\u4f46\u8fd0\u884c\u65f6\u95f4\u4ec5\u4e3a\u5176\u4ed6\u65b9\u6cd5\u7684\u51e0\u5206\u4e4b\u4e00\u3002", "conclusion": "\u8868\u683c\u57fa\u7840\u6a21\u578b\u4e3aShapley\u503c\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u53ef\u901a\u8fc7\u4e13\u95e8\u9002\u914d\u8fdb\u4e00\u6b65\u63d0\u5347\u6761\u4ef6Shapley\u503c\u4f30\u8ba1\u7684\u6027\u80fd\u3002"}}
{"id": "2602.09533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09533", "abs": "https://arxiv.org/abs/2602.09533", "authors": ["Masanari Oi", "Mahiro Ukai", "Masahiro Kaneko", "Naoaki Okazaki", "Nakamasa Inoue"], "title": "Autoregressive Direct Preference Optimization", "comment": null, "summary": "Direct preference optimization (DPO) has emerged as a promising approach for aligning large language models (LLMs) with human preferences. However, the widespread reliance on the response-level Bradley-Terry (BT) model may limit its full potential, as the reference and learnable models are assumed to be autoregressive only after deriving the objective function. Motivated by this limitation, we revisit the theoretical foundations of DPO and propose a novel formulation that explicitly introduces the autoregressive assumption prior to applying the BT model. By reformulating and extending DPO, we derive a novel variant, termed Autoregressive DPO (ADPO), that explicitly integrates autoregressive modeling into the preference optimization framework. Without violating the theoretical foundations, the derived loss takes an elegant form: it shifts the summation operation in the DPO objective outside the log-sigmoid function. Furthermore, through theoretical analysis of ADPO, we show that there exist two length measures to be considered when designing DPO-based algorithms: the token length $\u03bc$ and the feedback length $\u03bc$'. To the best of our knowledge, we are the first to explicitly distinguish these two measures and analyze their implications for preference optimization in LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u56de\u5f52DPO\uff08ADPO\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u81ea\u56de\u5f52\u5047\u8bbe\u660e\u786e\u5f15\u5165Bradley-Terry\u6a21\u578b\u4e4b\u524d\uff0c\u6539\u8fdb\u4e86\u4f20\u7edf\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709DPO\u65b9\u6cd5\u5e7f\u6cdb\u4f9d\u8d56\u54cd\u5e94\u7ea7\u7684Bradley-Terry\u6a21\u578b\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u9650\u5236\u4e86\u5176\u6f5c\u529b\uff0c\u56e0\u4e3a\u53c2\u8003\u6a21\u578b\u548c\u53ef\u5b66\u4e60\u6a21\u578b\u4ec5\u5728\u63a8\u5bfc\u76ee\u6807\u51fd\u6570\u540e\u624d\u88ab\u5047\u8bbe\u4e3a\u81ea\u56de\u5f52\u7684\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u5c40\u9650\u6027\u9700\u8981\u91cd\u65b0\u5ba1\u89c6DPO\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6DPO\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u5728\u5e94\u7528Bradley-Terry\u6a21\u578b\u4e4b\u524d\u660e\u786e\u5f15\u5165\u81ea\u56de\u5f52\u5047\u8bbe\u7684\u65b0\u516c\u5f0f\u3002\u901a\u8fc7\u91cd\u65b0\u8868\u8ff0\u548c\u6269\u5c55DPO\uff0c\u63a8\u5bfc\u51fa\u540d\u4e3a\u81ea\u56de\u5f52DPO\uff08ADPO\uff09\u7684\u65b0\u53d8\u4f53\uff0c\u5c06\u81ea\u56de\u5f52\u5efa\u6a21\u660e\u786e\u96c6\u6210\u5230\u504f\u597d\u4f18\u5316\u6846\u67b6\u4e2d\u3002", "result": "\u63a8\u5bfc\u51fa\u7684\u635f\u5931\u51fd\u6570\u5177\u6709\u4f18\u96c5\u7684\u5f62\u5f0f\uff1a\u5c06DPO\u76ee\u6807\u4e2d\u7684\u6c42\u548c\u64cd\u4f5c\u79fb\u5230log-sigmoid\u51fd\u6570\u4e4b\u5916\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u53d1\u73b0\uff0c\u5728\u8bbe\u8ba1\u57fa\u4e8eDPO\u7684\u7b97\u6cd5\u65f6\u9700\u8981\u8003\u8651\u4e24\u4e2a\u957f\u5ea6\u5ea6\u91cf\uff1a\u6807\u8bb0\u957f\u5ea6\u03bc\u548c\u53cd\u9988\u957f\u5ea6\u03bc'\u3002", "conclusion": "ADPO\u901a\u8fc7\u66f4\u65e9\u5730\u5f15\u5165\u81ea\u56de\u5f52\u5047\u8bbe\u6539\u8fdb\u4e86DPO\u6846\u67b6\uff0c\u9996\u6b21\u660e\u786e\u533a\u5206\u4e86\u6807\u8bb0\u957f\u5ea6\u548c\u53cd\u9988\u957f\u5ea6\u8fd9\u4e24\u4e2a\u91cd\u8981\u5ea6\u91cf\uff0c\u4e3aLLMs\u7684\u504f\u597d\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u5b8c\u6574\u7684\u7406\u8bba\u5206\u6790\u3002"}}
{"id": "2602.09597", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09597", "abs": "https://arxiv.org/abs/2602.09597", "authors": ["Martin Bauw"], "title": "Detecting radar targets swarms in range profiles with a partially complex-valued neural network", "comment": null, "summary": "Correctly detecting radar targets is usually challenged by clutter and waveform distortion. An additional difficulty stems from the relative proximity of several targets, the latter being perceived as a single target in the worst case, or influencing each other's detection thresholds. The negative impact of targets proximity notably depends on the range resolution defined by the radar parameters and the adaptive threshold adopted. This paper addresses the matter of targets detection in radar range profiles containing multiple targets with varying proximity and distorted echoes. Inspired by recent contributions in the radar and signal processing literature, this work proposes partially complex-valued neural networks as an adaptive range profile processing. Simulated datasets are generated and experiments are conducted to compare a common pulse compression approach with a simple neural network partially defined by complex-valued parameters. Whereas the pulse compression processes one pulse length at a time, the neural network put forward is a generative architecture going through the entire received signal in one go to generate a complete detection profile.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u90e8\u5206\u590d\u503c\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u96f7\u8fbe\u8ddd\u79bb\u5256\u9762\uff0c\u89e3\u51b3\u591a\u76ee\u6807\u8fd1\u8ddd\u79bb\u5e72\u6270\u548c\u56de\u6ce2\u5931\u771f\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u8109\u51b2\u538b\u7f29\u65b9\u6cd5\u80fd\u4e00\u6b21\u6027\u5904\u7406\u6574\u4e2a\u63a5\u6536\u4fe1\u53f7\u3002", "motivation": "\u96f7\u8fbe\u76ee\u6807\u68c0\u6d4b\u9762\u4e34\u6742\u6ce2\u3001\u6ce2\u5f62\u5931\u771f\u4ee5\u53ca\u591a\u4e2a\u76ee\u6807\u76f8\u5bf9\u63a5\u8fd1\u7684\u6311\u6218\u3002\u76ee\u6807\u63a5\u8fd1\u4f1a\u76f8\u4e92\u5f71\u54cd\u68c0\u6d4b\u9608\u503c\uff0c\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u4f1a\u88ab\u89c6\u4e3a\u5355\u4e2a\u76ee\u6807\u3002\u8fd9\u79cd\u8d1f\u9762\u5f71\u54cd\u53d6\u51b3\u4e8e\u96f7\u8fbe\u53c2\u6570\u5b9a\u4e49\u7684\u8ddd\u79bb\u5206\u8fa8\u7387\u548c\u81ea\u9002\u5e94\u9608\u503c\u3002", "method": "\u53d7\u96f7\u8fbe\u548c\u4fe1\u53f7\u5904\u7406\u9886\u57df\u6700\u65b0\u7814\u7a76\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4f7f\u7528\u90e8\u5206\u590d\u503c\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u81ea\u9002\u5e94\u8ddd\u79bb\u5256\u9762\u5904\u7406\u65b9\u6cd5\u3002\u91c7\u7528\u751f\u6210\u5f0f\u67b6\u6784\uff0c\u80fd\u591f\u4e00\u6b21\u6027\u5904\u7406\u6574\u4e2a\u63a5\u6536\u4fe1\u53f7\uff0c\u751f\u6210\u5b8c\u6574\u7684\u68c0\u6d4b\u5256\u9762\uff0c\u800c\u4f20\u7edf\u8109\u51b2\u538b\u7f29\u65b9\u6cd5\u4e00\u6b21\u53ea\u80fd\u5904\u7406\u4e00\u4e2a\u8109\u51b2\u957f\u5ea6\u3002", "result": "\u901a\u8fc7\u751f\u6210\u6a21\u62df\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u5e38\u89c1\u7684\u8109\u51b2\u538b\u7f29\u65b9\u6cd5\u4e0e\u7b80\u5355\u7684\u90e8\u5206\u590d\u503c\u53c2\u6570\u795e\u7ecf\u7f51\u7edc\u3002\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u66f4\u6709\u6548\u5730\u5904\u7406\u591a\u76ee\u6807\u8fd1\u8ddd\u79bb\u60c5\u51b5\u548c\u5931\u771f\u56de\u6ce2\u3002", "conclusion": "\u90e8\u5206\u590d\u503c\u795e\u7ecf\u7f51\u7edc\u4e3a\u96f7\u8fbe\u8ddd\u79bb\u5256\u9762\u5904\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5904\u7406\u591a\u4e2a\u76ee\u6807\u8fd1\u8ddd\u79bb\u5e72\u6270\u548c\u56de\u6ce2\u5931\u771f\u7684\u590d\u6742\u573a\u666f\uff0c\u76f8\u6bd4\u4f20\u7edf\u8109\u51b2\u538b\u7f29\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6574\u4f53\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2602.09620", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.09620", "abs": "https://arxiv.org/abs/2602.09620", "authors": ["Jorge Fandinno", "Pedro Cabalar", "Philipp Wanko", "Torsten Schaub"], "title": "FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints", "comment": null, "summary": "Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format.", "AI": {"tldr": "FLINGO\u8bed\u8a00\u6269\u5c55\u4e86\u7ea6\u675fASP\uff0c\u5c06ASP\u7684\u6570\u503c\u5c5e\u6027\u8868\u8fbe\u80fd\u529b\uff08\u5982\u9ed8\u8ba4\u503c\u3001\u672a\u5b9a\u4e49\u3001\u975e\u786e\u5b9a\u6027\u8d4b\u503c\u548c\u805a\u5408\u503c\uff09\u6574\u5408\u5230\u6570\u503c\u7ea6\u675f\u4e2d\uff0c\u5e76\u63d0\u4f9b\u4e86\u5230\u6807\u51c6CASP\u7684\u7ffb\u8bd1\u3002", "motivation": "\u5f53\u524d\u7ea6\u675fASP\uff08CASP\uff09\u4e2d\u6570\u503c\u7ea6\u675f\u7684\u8868\u8fbe\u65b9\u5f0f\u66f4\u63a5\u8fd1\u540e\u7aef\u6570\u503c\u5904\u7406\u5668\u7684\u8bed\u4e49\uff0c\u800c\u4e22\u5931\u4e86ASP\u4e2d\u6570\u503c\u5c5e\u6027\u7684\u4e30\u5bcc\u8868\u8fbe\u80fd\u529b\uff0c\u5982\u9ed8\u8ba4\u503c\u3001\u672a\u5b9a\u4e49\u72b6\u6001\u3001\u975e\u786e\u5b9a\u6027\u8d4b\u503c\u548c\u805a\u5408\u503c\u7b49\u529f\u80fd\u3002", "method": "\u63d0\u51faFLINGO\u8bed\u8a00\u548c\u5de5\u5177\uff0c\u5c06ASP\u7684\u6570\u503c\u5c5e\u6027\u8868\u8fbe\u80fd\u529b\u6574\u5408\u5230\u6570\u503c\u7ea6\u675f\u4e2d\uff0c\u5e76\u8bbe\u8ba1\u4eceFLINGO\u8bed\u6cd5\u5230\u6807\u51c6CASP\u7a0b\u5e8f\uff08\u9075\u5faaCLINGCON\u8f93\u5165\u683c\u5f0f\uff09\u7684\u7ffb\u8bd1\u65b9\u6cd5\u3002", "result": "\u5f00\u53d1\u4e86FLINGO\u8bed\u8a00\uff0c\u80fd\u591f\u4fdd\u6301ASP\u4e2d\u6570\u503c\u5c5e\u6027\u7684\u4e30\u5bcc\u8868\u8fbe\u80fd\u529b\uff0c\u540c\u65f6\u652f\u6301\u6570\u503c\u7ea6\u675f\u5904\u7406\uff0c\u5e76\u901a\u8fc7\u7ffb\u8bd1\u673a\u5236\u5b9e\u73b0\u4e0e\u73b0\u6709CASP\u6c42\u89e3\u5668\u7684\u517c\u5bb9\u3002", "conclusion": "FLINGO\u6210\u529f\u5730\u5c06ASP\u7684\u6570\u503c\u8868\u8fbe\u80fd\u529b\u4e0eCASP\u7684\u7ea6\u675f\u5904\u7406\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u81ea\u7136\u548c\u5f3a\u5927\u7684\u5efa\u6a21\u8bed\u8a00\u3002"}}
{"id": "2602.09653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09653", "abs": "https://arxiv.org/abs/2602.09653", "authors": ["Shiwei Lyu", "Xidong Wang", "Lei Liu", "Hao Zhu", "Chaohe Zhang", "Jian Wang", "Jinjie Gu", "Benyou Wang", "Yue Shen"], "title": "ClinAlign: Scaling Healthcare Alignment from Clinician Preference", "comment": null, "summary": "Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B parameter model that activates only 3B parameters at inference trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\u89e3\u51b3LLM\u533b\u7597\u8f93\u51fa\u4e0e\u4e34\u5e8a\u504f\u597d\u5bf9\u9f50\u95ee\u9898\uff1a1) \u521b\u5efa\u533b\u751f\u9a8c\u8bc1\u7684\u504f\u597d\u6570\u636e\u96c6HealthRubrics\uff1b2) \u63d0\u70bc\u4e3a\u53ef\u91cd\u7528\u4e34\u5e8a\u539f\u5219HealthPrinciples\uff0c\u7528\u4e8e\u79bb\u7ebf\u5bf9\u9f50\u548c\u63a8\u7406\u65f6\u81ea\u6211\u4fee\u6b63\uff0c\u5c0f\u6a21\u578b\u6027\u80fd\u8d85\u8d8a\u5927\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u4e13\u5bb6\u7ea7\u533b\u7597\u77e5\u8bc6\uff0c\u4f46\u5176\u5f00\u653e\u8f93\u51fa\u4e0e\u7ec6\u7c92\u5ea6\u4e34\u5e8a\u504f\u597d\u7684\u5bf9\u9f50\u4ecd\u7136\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7c97\u7c92\u5ea6\u76ee\u6807\u6216\u4e0d\u53ef\u9760\u7684\u81ea\u52a8\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u4e13\u4e1a\u6307\u5357\u57fa\u7840\u3002", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u6784\u5efaHealthRubrics\u6570\u636e\u96c6\uff087,034\u4e2a\u533b\u751f\u9a8c\u8bc1\u7684\u504f\u597d\u793a\u4f8b\uff09\uff0c\u533b\u751f\u4f18\u5316LLM\u8349\u62df\u7684\u8bc4\u5206\u6807\u51c6\uff1b2) \u63d0\u70bc\u4e3aHealthPrinciples\uff08119\u4e2a\u53ef\u91cd\u7528\u4e34\u5e8a\u539f\u5219\uff09\uff0c\u7528\u4e8e\u79bb\u7ebf\u5bf9\u9f50\uff08\u4e3a\u672a\u6807\u6ce8\u67e5\u8be2\u5408\u6210\u8bc4\u5206\u6807\u51c6\uff09\u548c\u63a8\u7406\u65f6\u5f15\u5bfc\u81ea\u6211\u4fee\u6b63\u3002", "result": "\u4ec5\u6fc0\u6d3b30B\u53c2\u6570\u4e2d3B\u53c2\u6570\u7684\u6a21\u578b\u5728HealthBench-Hard\u4e0a\u8fbe\u523033.4%\uff0c\u8d85\u8d8aDeepseek-R1\u548co3\u7b49\u66f4\u5927\u6a21\u578b\uff0c\u5efa\u7acb\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u4e34\u5e8a\u5bf9\u9f50\u57fa\u51c6\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u533b\u751f\u9a8c\u8bc1\u7684\u8bc4\u5206\u6807\u51c6\u548c\u53ef\u91cd\u7528\u4e34\u5e8a\u539f\u5219\uff0c\u5b9e\u73b0\u4e86LLM\u533b\u7597\u8f93\u51fa\u4e0e\u4e34\u5e8a\u504f\u597d\u7684\u6709\u6548\u5bf9\u9f50\uff0c\u5c0f\u6a21\u578b\u4e5f\u80fd\u8fbe\u5230\u8d85\u8d8a\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u4e34\u5e8a\u5bf9\u9f50\u63d0\u4f9b\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09794", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09794", "abs": "https://arxiv.org/abs/2602.09794", "authors": ["Jiaquan Zhang", "Chaoning Zhang", "Shuxu Chen", "Xudong Wang", "Zhenzhen Huang", "Pengcheng Zheng", "Shuai Yuan", "Sheng Zheng", "Qigan Sun", "Jie Zou", "Lik-Hang Lee", "Yang Yang"], "title": "GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis", "comment": "23pages", "summary": "Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks.", "AI": {"tldr": "GHS-TDA\u901a\u8fc7\u6784\u5efa\u5168\u5c40\u5047\u8bbe\u56fe\u548c\u591a\u5c3a\u5ea6\u62d3\u6251\u5206\u6790\uff0c\u89e3\u51b3\u4f20\u7edf\u601d\u7ef4\u94fe\u65b9\u6cd5\u4e2d\u9519\u8bef\u4f20\u64ad\u548c\u7f3a\u4e4f\u7ed3\u6784\u5316\u5206\u6790\u7684\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u601d\u7ef4\u94fe\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u6027\u5c40\u9650\uff1a1) \u63a8\u7406\u8fc7\u7a0b\u5bf9\u65e9\u671f\u51b3\u7b56\u9ad8\u5ea6\u654f\u611f\uff0c\u4e00\u65e6\u51fa\u73b0\u521d\u59cb\u9519\u8bef\u4f1a\u4f20\u64ad\u653e\u5927\u4e14\u96be\u4ee5\u4fee\u6b63\uff1b2) \u7f3a\u4e4f\u7ed3\u6784\u5316\u5206\u6790\u6280\u672f\u6765\u8fc7\u6ee4\u5197\u4f59\u63a8\u7406\u548c\u63d0\u53d6\u5173\u952e\u7279\u5f81\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u4e0d\u7a33\u5b9a\u4e14\u53ef\u89e3\u91ca\u6027\u6709\u9650\u3002", "method": "\u63d0\u51faGHS-TDA\u65b9\u6cd5\uff1a1) \u6784\u5efa\u8bed\u4e49\u4e30\u5bcc\u7684\u5168\u5c40\u5047\u8bbe\u56fe\uff0c\u805a\u5408\u3001\u5bf9\u9f50\u548c\u534f\u8c03\u591a\u4e2a\u5019\u9009\u63a8\u7406\u8def\u5f84\uff0c\u63d0\u4f9b\u5168\u5c40\u4fee\u6b63\u8def\u5f84\uff1b2) \u5e94\u7528\u57fa\u4e8e\u6301\u4e45\u540c\u8c03\u7684\u62d3\u6251\u6570\u636e\u5206\u6790\uff0c\u6355\u83b7\u7a33\u5b9a\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784\uff0c\u53bb\u9664\u5197\u4f59\u548c\u4e0d\u4e00\u81f4\uff0c\u63d0\u53d6\u66f4\u53ef\u9760\u7684\u63a8\u7406\u9aa8\u67b6\u3002", "result": "GHS-TDA\u901a\u8fc7\u8054\u5408\u5229\u7528\u63a8\u7406\u591a\u6837\u6027\u548c\u62d3\u6251\u7a33\u5b9a\u6027\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u6536\u655b\uff0c\u4ea7\u751f\u9ad8\u7f6e\u4fe1\u5ea6\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GHS-TDA\u901a\u8fc7\u5168\u5c40\u534f\u8c03\u548c\u62d3\u6251\u5206\u6790\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u601d\u7ef4\u94fe\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09798", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09798", "abs": "https://arxiv.org/abs/2602.09798", "authors": ["Matteo Cardellini", "Enrico Giunchiglia"], "title": "Symbolic Pattern Temporal Numeric Planning with Intermediate Conditions and Effects", "comment": "Under review at the Artificial Intelligence Journal", "summary": "Recently, a Symbolic Pattern Planning (SPP) approach was proposed for numeric planning where a pattern (i.e., a finite sequence of actions) suggests a causal order between actions. The pattern is then encoded in a SMT formula whose models correspond to valid plans. If the suggestion by the pattern is inaccurate and no valid plan can be found, the pattern is extended until it contains the causal order of actions in a valid plan, making the approach complete. In this paper, we extend the SPP approach to the temporal planning with Intermediate Conditions and Effects (ICEs) fragment, where $(i)$ actions are durative (and thus can overlap over time) and have conditions/effects which can be checked/applied at any time during an action's execution, and $(ii)$ one can specify plan's conditions/effects that must be checked/applied at specific times during the plan execution. Experimental results show that our SPP planner Patty $(i)$ outperforms all other planners in the literature in the majority of temporal domains without ICEs, $(ii)$ obtains comparable results with the SoTA search planner for ICS in literature domains with ICEs, and $(iii)$ outperforms the same planner in a novel domain based on a real-world application.", "AI": {"tldr": "\u5c06\u7b26\u53f7\u6a21\u5f0f\u89c4\u5212\uff08SPP\uff09\u65b9\u6cd5\u6269\u5c55\u5230\u5177\u6709\u4e2d\u95f4\u6761\u4ef6\u548c\u6548\u679c\uff08ICEs\uff09\u7684\u65f6\u95f4\u89c4\u5212\u9886\u57df\uff0c\u5f00\u53d1\u4e86Patty\u89c4\u5212\u5668\uff0c\u5728\u591a\u4e2a\u65f6\u95f4\u89c4\u5212\u9886\u57df\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u7b26\u53f7\u6a21\u5f0f\u89c4\u5212\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u6570\u503c\u89c4\u5212\uff0c\u9700\u8981\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u65f6\u95f4\u89c4\u5212\u9886\u57df\uff0c\u7279\u522b\u662f\u652f\u6301\u52a8\u4f5c\u91cd\u53e0\u548c\u4e2d\u95f4\u6761\u4ef6/\u6548\u679c\u7684\u65f6\u95f4\u89c4\u5212\u7247\u6bb5\u3002", "method": "\u5c06SPP\u65b9\u6cd5\u6269\u5c55\u5230\u65f6\u95f4\u89c4\u5212ICEs\u7247\u6bb5\uff1a1\uff09\u652f\u6301\u6301\u7eed\u52a8\u4f5c\uff08\u53ef\u91cd\u53e0\u6267\u884c\uff09\uff1b2\uff09\u652f\u6301\u5728\u52a8\u4f5c\u6267\u884c\u671f\u95f4\u4efb\u610f\u65f6\u95f4\u68c0\u67e5/\u5e94\u7528\u6761\u4ef6\u6548\u679c\uff1b3\uff09\u652f\u6301\u5728\u8ba1\u5212\u6267\u884c\u7279\u5b9a\u65f6\u95f4\u68c0\u67e5/\u5e94\u7528\u6761\u4ef6\u6548\u679c\uff1b4\uff09\u4f7f\u7528\u6a21\u5f0f\u6269\u5c55\u673a\u5236\u786e\u4fdd\u5b8c\u5907\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1\uff09\u5728\u65e0ICEs\u7684\u65f6\u95f4\u89c4\u5212\u9886\u57df\uff0cPatty\u4f18\u4e8e\u6240\u6709\u73b0\u6709\u89c4\u5212\u5668\uff1b2\uff09\u5728\u6709ICEs\u7684\u6587\u732e\u9886\u57df\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u641c\u7d22\u89c4\u5212\u5668\u6027\u80fd\u76f8\u5f53\uff1b3\uff09\u5728\u57fa\u4e8e\u771f\u5b9e\u5e94\u7528\u7684\u65b0\u9886\u57df\uff0c\u4f18\u4e8e\u76f8\u540c\u89c4\u5212\u5668\u3002", "conclusion": "\u6210\u529f\u5c06SPP\u65b9\u6cd5\u6269\u5c55\u5230\u65f6\u95f4\u89c4\u5212ICEs\u7247\u6bb5\uff0c\u5f00\u53d1\u7684Patty\u89c4\u5212\u5668\u5728\u591a\u4e2a\u65f6\u95f4\u89c4\u5212\u9886\u57df\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u7279\u522b\u662f\u5728\u771f\u5b9e\u5e94\u7528\u573a\u666f\u4e2d\u663e\u793a\u51fa\u4f18\u52bf\u3002"}}
{"id": "2602.09802", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09802", "abs": "https://arxiv.org/abs/2602.09802", "authors": ["Manon Reusens", "Sofie Goethals", "Toon Calders", "David Martens"], "title": "Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice.", "AI": {"tldr": "LLM\u5728\u4e3b\u89c2\u51b3\u7b56\u4efb\u52a1\u4e2d\uff08\u5982\u65c5\u884c\u52a9\u624b\uff09\u80fd\u751f\u6210\u6709\u610f\u4e49\u7684\u652f\u4ed8\u610f\u613f\u4f30\u8ba1\uff0c\u4f46\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u901a\u5e38\u9ad8\u4f30\u4eba\u7c7b\u652f\u4ed8\u610f\u613f\uff0c\u7279\u522b\u662f\u5728\u6602\u8d35\u9009\u9879\u6216\u5546\u52a1\u89d2\u8272\u4e0b\u3002", "motivation": "\u7814\u7a76LLM\u5728\u4e3b\u89c2\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u65c5\u884c\u52a9\u624b\u7b49\u5e94\u7528\u4e2d\uff0cLLM\u9700\u8981\u4e3a\u7528\u6237\u505a\u51fa\u4e3b\u89c2\u9009\u62e9\uff0c\u800c\u8fd9\u7c7b\u9009\u62e9\u6ca1\u6709\u5ba2\u89c2\u6b63\u786e\u7b54\u6848\u3002\u9700\u8981\u8bc4\u4f30LLM\u7684\u51b3\u7b56\u8d28\u91cf\u5e76\u4e0e\u4eba\u7c7b\u57fa\u51c6\u6bd4\u8f83\u3002", "method": "\u5728\u65c5\u884c\u52a9\u624b\u60c5\u5883\u4e2d\u5411LLM\u5448\u73b0\u9009\u62e9\u56f0\u5883\uff0c\u4f7f\u7528\u591a\u9879logit\u6a21\u578b\u5206\u6790\u54cd\u5e94\u4ee5\u63a8\u5bfc\u9690\u542b\u652f\u4ed8\u610f\u613f\u4f30\u8ba1\uff0c\u7136\u540e\u4e0e\u7ecf\u6d4e\u5b66\u6587\u732e\u4e2d\u7684\u4eba\u7c7b\u57fa\u51c6\u503c\u6bd4\u8f83\u3002\u7814\u7a76\u4e0d\u540c\u8bbe\u7f6e\uff1a\u57fa\u7ebf\u3001\u7528\u6237\u5386\u53f2\u9009\u62e9\u4fe1\u606f\u3001\u89d2\u8272\u63d0\u793a\u7b49\u3002", "result": "\u8f83\u5927LLM\u80fd\u751f\u6210\u6709\u610f\u4e49\u7684WTP\u503c\uff0c\u4f46\u5728\u5c5e\u6027\u5c42\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff1b\u603b\u4f53\u503e\u5411\u4e8e\u9ad8\u4f30\u4eba\u7c7bWTP\uff0c\u7279\u522b\u662f\u5f53\u5f15\u5165\u6602\u8d35\u9009\u9879\u6216\u5546\u52a1\u5bfc\u5411\u89d2\u8272\u65f6\uff1b\u57fa\u4e8e\u5148\u524d\u5bf9\u4fbf\u5b9c\u9009\u9879\u504f\u597d\u7684\u6761\u4ef6\u8bbe\u5b9a\u80fd\u4ea7\u751f\u66f4\u63a5\u8fd1\u4eba\u7c7b\u57fa\u51c6\u7684\u4f30\u503c\u3002", "conclusion": "LLM\u5728\u4e3b\u89c2\u51b3\u7b56\u652f\u6301\u4e2d\u65e2\u6709\u6f5c\u529b\u4e5f\u6709\u5c40\u9650\uff0c\u5b9e\u9645\u90e8\u7f72\u65f6\u9700\u8981\u4ed4\u7ec6\u7684\u6a21\u578b\u9009\u62e9\u3001\u63d0\u793a\u8bbe\u8ba1\u548c\u7528\u6237\u8868\u5f81\uff0c\u4ee5\u786e\u4fdd\u51b3\u7b56\u8d28\u91cf\u3002"}}
{"id": "2602.09813", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09813", "abs": "https://arxiv.org/abs/2602.09813", "authors": ["Dexun Li", "Sidney Tio", "Pradeep Varakantham"], "title": "Efficient Unsupervised Environment Design through Hierarchical Policy Representation Learning", "comment": null, "summary": "Unsupervised Environment Design (UED) has emerged as a promising approach to developing general-purpose agents through automated curriculum generation. Popular UED methods focus on Open-Endedness, where teacher algorithms rely on stochastic processes for infinite generation of useful environments. This assumption becomes impractical in resource-constrained scenarios where teacher-student interaction opportunities are limited. To address this challenge, we introduce a hierarchical Markov Decision Process (MDP) framework for environment design. Our framework features a teacher agent that leverages student policy representations derived from discovered evaluation environments, enabling it to generate training environments based on the student's capabilities. To improve efficiency, we incorporate a generative model that augments the teacher's training dataset with synthetic data, reducing the need for teacher-student interactions. In experiments across several domains, we show that our method outperforms baseline approaches while requiring fewer teacher-student interactions in a single episode. The results suggest the applicability of our approach in settings where training opportunities are limited.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42MDP\u6846\u67b6\u7528\u4e8e\u73af\u5883\u8bbe\u8ba1\uff0c\u901a\u8fc7\u6559\u5e08\u4ee3\u7406\u5229\u7528\u5b66\u751f\u7b56\u7565\u8868\u793a\u751f\u6210\u8bad\u7ec3\u73af\u5883\uff0c\u7ed3\u5408\u751f\u6210\u6a21\u578b\u51cf\u5c11\u5e08\u751f\u4ea4\u4e92\u9700\u6c42\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e2d\u5b9e\u73b0\u9ad8\u6548\u8bfe\u7a0b\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u968f\u673a\u8fc7\u7a0b\u65e0\u9650\u751f\u6210\u73af\u5883\uff0c\u8fd9\u5728\u5e08\u751f\u4ea4\u4e92\u673a\u4f1a\u6709\u9650\u7684\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e2d\u4e0d\u5207\u5b9e\u9645\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8bfe\u7a0b\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5206\u5c42MDP\u6846\u67b6\uff0c\u6559\u5e08\u4ee3\u7406\u5229\u7528\u4ece\u8bc4\u4f30\u73af\u5883\u4e2d\u63d0\u53d6\u7684\u5b66\u751f\u7b56\u7565\u8868\u793a\u6765\u751f\u6210\u8bad\u7ec3\u73af\u5883\uff1b\u7ed3\u5408\u751f\u6210\u6a21\u578b\u589e\u5f3a\u6559\u5e08\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u51cf\u5c11\u5e08\u751f\u4ea4\u4e92\u9700\u6c42\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u5728\u5355\u6b21\u8bad\u7ec3\u4e2d\u9700\u8981\u66f4\u5c11\u7684\u5e08\u751f\u4ea4\u4e92\uff0c\u8bc1\u660e\u5728\u8bad\u7ec3\u673a\u4f1a\u6709\u9650\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5c42MDP\u6846\u67b6\u901a\u8fc7\u9ad8\u6548\u5229\u7528\u5b66\u751f\u80fd\u529b\u4fe1\u606f\u548c\u751f\u6210\u6a21\u578b\u589e\u5f3a\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff0c\u4e3a\u6709\u9650\u4ea4\u4e92\u673a\u4f1a\u4e0b\u7684\u8bfe\u7a0b\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.09937", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09937", "abs": "https://arxiv.org/abs/2602.09937", "authors": ["Taeyoon Kim", "Woohyeok Park", "Hoyeong Yun", "Kyungyong Lee"], "title": "Why Do AI Agents Systematically Fail at Cloud Root Cause Analysis?", "comment": null, "summary": "Failures in large-scale cloud systems incur substantial financial losses, making automated Root Cause Analysis (RCA) essential for operational stability. Recent efforts leverage Large Language Model (LLM) agents to automate this task, yet existing systems exhibit low detection accuracy even with capable models, and current evaluation frameworks assess only final answer correctness without revealing why the agent's reasoning failed. This paper presents a process level failure analysis of LLM-based RCA agents. We execute the full OpenRCA benchmark across five LLM models, producing 1,675 agent runs, and classify observed failures into 12 pitfall types across intra-agent reasoning, inter-agent communication, and agent-environment interaction. Our analysis reveals that the most prevalent pitfalls, notably hallucinated data interpretation and incomplete exploration, persist across all models regardless of capability tier, indicating that these failures originate from the shared agent architecture rather than from individual model limitations. Controlled mitigation experiments further show that prompt engineering alone cannot resolve the dominant pitfalls, whereas enriching the inter-agent communication protocol reduces communication-related failures by up to 15 percentage points. The pitfall taxonomy and diagnostic methodology developed in this work provide a foundation for designing more reliable autonomous agents for cloud RCA.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u57fa\u4e8eLLM\u7684\u4e91\u7cfb\u7edf\u6839\u56e0\u5206\u6790(RCA)\u4ee3\u7406\u8fdb\u884c\u4e86\u8fc7\u7a0b\u7ea7\u6545\u969c\u5206\u6790\uff0c\u8bc6\u522b\u51fa12\u79cd\u9677\u9631\u7c7b\u578b\uff0c\u53d1\u73b0\u4e3b\u8981\u95ee\u9898\u6e90\u4e8e\u5171\u4eab\u7684\u4ee3\u7406\u67b6\u6784\u800c\u975e\u5355\u4e2a\u6a21\u578b\u9650\u5236\uff0c\u63d0\u793a\u5de5\u7a0b\u65e0\u6cd5\u89e3\u51b3\u4e3b\u5bfc\u9677\u9631\uff0c\u4f46\u6539\u8fdb\u901a\u4fe1\u534f\u8bae\u53ef\u51cf\u5c1115%\u7684\u901a\u4fe1\u76f8\u5173\u6545\u969c\u3002", "motivation": "\u5927\u89c4\u6a21\u4e91\u7cfb\u7edf\u6545\u969c\u5bfc\u81f4\u91cd\u5927\u7ecf\u6d4e\u635f\u5931\uff0c\u9700\u8981\u81ea\u52a8\u5316\u6839\u56e0\u5206\u6790(RCA)\u3002\u73b0\u6709LLM\u4ee3\u7406\u7cfb\u7edf\u68c0\u6d4b\u51c6\u786e\u7387\u4f4e\uff0c\u4e14\u5f53\u524d\u8bc4\u4f30\u6846\u67b6\u53ea\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\uff0c\u65e0\u6cd5\u63ed\u793a\u4ee3\u7406\u63a8\u7406\u5931\u8d25\u7684\u539f\u56e0\u3002", "method": "\u5bf9\u57fa\u4e8eLLM\u7684RCA\u4ee3\u7406\u8fdb\u884c\u8fc7\u7a0b\u7ea7\u6545\u969c\u5206\u6790\uff1a\u5728\u4e94\u4e2aLLM\u6a21\u578b\u4e0a\u6267\u884c\u5b8c\u6574\u7684OpenRCA\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ea7\u751f1,675\u6b21\u4ee3\u7406\u8fd0\u884c\uff0c\u5c06\u89c2\u5bdf\u5230\u7684\u6545\u969c\u5206\u7c7b\u4e3a12\u79cd\u9677\u9631\u7c7b\u578b\uff08\u5305\u62ec\u4ee3\u7406\u5185\u63a8\u7406\u3001\u4ee3\u7406\u95f4\u901a\u4fe1\u548c\u4ee3\u7406-\u73af\u5883\u4ea4\u4e92\uff09\u3002", "result": "\u5206\u6790\u663e\u793a\u6700\u666e\u904d\u7684\u9677\u9631\uff08\u7279\u522b\u662f\u5e7b\u89c9\u6570\u636e\u89e3\u91ca\u548c\u4e0d\u5b8c\u6574\u63a2\u7d22\uff09\u5728\u6240\u6709\u6a21\u578b\u4e2d\u6301\u7eed\u5b58\u5728\uff0c\u65e0\u8bba\u6a21\u578b\u80fd\u529b\u5c42\u7ea7\u5982\u4f55\uff0c\u8868\u660e\u8fd9\u4e9b\u6545\u969c\u6e90\u4e8e\u5171\u4eab\u4ee3\u7406\u67b6\u6784\u800c\u975e\u5355\u4e2a\u6a21\u578b\u9650\u5236\u3002\u7f13\u89e3\u5b9e\u9a8c\u8868\u660e\u63d0\u793a\u5de5\u7a0b\u65e0\u6cd5\u89e3\u51b3\u4e3b\u5bfc\u9677\u9631\uff0c\u4f46\u4e30\u5bcc\u4ee3\u7406\u95f4\u901a\u4fe1\u534f\u8bae\u53ef\u5c06\u901a\u4fe1\u76f8\u5173\u6545\u969c\u51cf\u5c11\u6700\u591a15\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u672c\u6587\u5f00\u53d1\u7684\u9677\u9631\u5206\u7c7b\u548c\u8bca\u65ad\u65b9\u6cd5\u4e3a\u8bbe\u8ba1\u66f4\u53ef\u9760\u7684\u4e91RCA\u81ea\u4e3b\u4ee3\u7406\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u4e3b\u8981\u6545\u969c\u6e90\u4e8e\u4ee3\u7406\u67b6\u6784\u8bbe\u8ba1\uff0c\u800c\u975e\u6a21\u578b\u80fd\u529b\u9650\u5236\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u6539\u8fdb\u4ee3\u7406\u67b6\u6784\u800c\u975e\u4ec5\u4f9d\u8d56\u63d0\u793a\u5de5\u7a0b\u3002"}}
{"id": "2602.09945", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09945", "abs": "https://arxiv.org/abs/2602.09945", "authors": ["Jinsong Liu", "Yuhang Jiang", "Ramayya Krishnan", "Rema Padman", "Yiye Zhang", "Jiang Bian"], "title": "Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning", "comment": null, "summary": "Clinical decision support requires not only correct answers but also clinically valid reasoning. We propose Differential Reasoning Learning (DRL), a framework that improves clinical agents by learning from reasoning discrepancies. From reference reasoning rationales (e.g., physician-authored clinical rationale, clinical guidelines, or outputs from more capable models) and the agent's free-form chain-of-thought (CoT), DRL extracts reasoning graphs as directed acyclic graphs (DAGs) and performs a clinically weighted graph edit distance (GED)-based discrepancy analysis. An LLM-as-a-judge aligns semantically equivalent nodes and diagnoses discrepancies between graphs. These graph-level discrepancy diagnostics are converted into natural-language instructions and stored in a Differential Reasoning Knowledge Base (DR-KB). At inference, we retrieve top-$k$ instructions via Retrieval-Augmented Generation (RAG) to augment the agent prompt and patch likely logic gaps. Evaluation on open medical question answering (QA) benchmarks and a Return Visit Admissions (RVA) prediction task from internal clinical data demonstrates gains over baselines, improving both final-answer accuracy and reasoning fidelity. Ablation studies confirm gains from infusing reference reasoning rationales and the top-$k$ retrieval strategy. Clinicians' review of the output provides further assurance of the approach. Together, results suggest that DRL supports more reliable clinical decision-making in complex reasoning scenarios and offers a practical mechanism for deployment under limited token budgets.", "AI": {"tldr": "DRL\u6846\u67b6\u901a\u8fc7\u5206\u6790\u63a8\u7406\u5dee\u5f02\u6765\u6539\u8fdb\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\uff0c\u4f7f\u7528\u56fe\u7f16\u8f91\u8ddd\u79bb\u6bd4\u8f83\u53c2\u8003\u63a8\u7406\u4e0e\u6a21\u578b\u63a8\u7406\uff0c\u6784\u5efa\u5dee\u5f02\u77e5\u8bc6\u5e93\u5e76\u901a\u8fc7RAG\u68c0\u7d22\u6307\u4ee4\u6765\u4fee\u8865\u63a8\u7406\u6f0f\u6d1e\u3002", "motivation": "\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e0d\u4ec5\u9700\u8981\u6b63\u786e\u7b54\u6848\uff0c\u8fd8\u9700\u8981\u4e34\u5e8a\u6709\u6548\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u573a\u666f\u4e2d\u53ef\u80fd\u5b58\u5728\u903b\u8f91\u6f0f\u6d1e\uff0c\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u8bc6\u522b\u548c\u4fee\u8865\u8fd9\u4e9b\u63a8\u7406\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u5dee\u5f02\u63a8\u7406\u5b66\u4e60(DRL)\u6846\u67b6\uff1a1) \u5c06\u53c2\u8003\u63a8\u7406\uff08\u533b\u751f\u4e34\u5e8a\u63a8\u7406\u3001\u4e34\u5e8a\u6307\u5357\u6216\u66f4\u5f3a\u6a21\u578b\u8f93\u51fa\uff09\u548c\u4ee3\u7406\u7684\u81ea\u7531\u5f62\u5f0f\u94fe\u5f0f\u63a8\u7406\u8f6c\u6362\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff1b2) \u4f7f\u7528\u4e34\u5e8a\u52a0\u6743\u7684\u56fe\u7f16\u8f91\u8ddd\u79bb\u8fdb\u884c\u5dee\u5f02\u5206\u6790\uff1b3) LLM\u4f5c\u4e3a\u88c1\u5224\u5bf9\u9f50\u8bed\u4e49\u7b49\u4ef7\u8282\u70b9\uff1b4) \u6784\u5efa\u5dee\u5f02\u63a8\u7406\u77e5\u8bc6\u5e93(DR-KB)\uff1b5) \u63a8\u7406\u65f6\u901a\u8fc7RAG\u68c0\u7d22top-k\u6307\u4ee4\u589e\u5f3a\u63d0\u793a\u3002", "result": "\u5728\u5f00\u653e\u533b\u5b66QA\u57fa\u51c6\u548c\u5185\u90e8\u4e34\u5e8a\u6570\u636e\u7684\u8fd4\u9662\u9884\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u548c\u63a8\u7406\u4fdd\u771f\u5ea6\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u53c2\u8003\u63a8\u7406\u6ce8\u5165\u548ctop-k\u68c0\u7d22\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u4e34\u5e8a\u533b\u751f\u8bc4\u5ba1\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u3002", "conclusion": "DRL\u652f\u6301\u5728\u590d\u6742\u63a8\u7406\u573a\u666f\u4e2d\u8fdb\u884c\u66f4\u53ef\u9760\u7684\u4e34\u5e8a\u51b3\u7b56\uff0c\u4e3a\u6709\u9650token\u9884\u7b97\u4e0b\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u673a\u5236\uff0c\u80fd\u591f\u6539\u5584\u4e34\u5e8a\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2602.10004", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10004", "abs": "https://arxiv.org/abs/2602.10004", "authors": ["Junda Wang", "Zhichao Yang", "Dongxu Zhang", "Sanjit Singh Batra", "Robert E. Tillman"], "title": "ESTAR: Early-Stopping Token-Aware Reasoning For Efficient Inference", "comment": null, "summary": "Large reasoning models (LRMs) achieve state-of-the-art performance by generating long chains-of-thought, but often waste computation on redundant reasoning after the correct answer has already been reached. We introduce Early-Stopping for Token-Aware Reasoning (ESTAR), which detects and reduces such reasoning redundancy to improve efficiency without sacrificing accuracy. Our method combines (i) a trajectory-based classifier that identifies when reasoning can be safely stopped, (ii) supervised fine-tuning to teach LRMs to propose self-generated <stop> signals, and (iii) <stop>-aware reinforcement learning that truncates rollouts at self-generated stop points with compute-aware rewards. Experiments on four reasoning datasets show that ESTAR reduces reasoning length by about 3.7x (from 4,799 to 1,290) while preserving accuracy (74.9% vs. 74.2%), with strong cross-domain generalization. These results highlight early stopping as a simple yet powerful mechanism for improving reasoning efficiency in LRMs.", "AI": {"tldr": "ESTAR\u65b9\u6cd5\u901a\u8fc7\u65e9\u671f\u505c\u6b62\u673a\u5236\u68c0\u6d4b\u63a8\u7406\u5197\u4f59\uff0c\u5c06\u63a8\u7406\u957f\u5ea6\u51cf\u5c113.7\u500d\uff08\u4ece4799\u964d\u81f31290\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u7387\uff0874.9% vs 74.2%\uff09\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u751f\u6210\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u83b7\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u4f46\u7ecf\u5e38\u5728\u5df2\u7ecf\u5f97\u51fa\u6b63\u786e\u7b54\u6848\u540e\u7ee7\u7eed\u5197\u4f59\u63a8\u7406\uff0c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u51cf\u5c11\u8fd9\u79cd\u63a8\u7406\u5197\u4f59\uff0c\u63d0\u9ad8\u6548\u7387\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002", "method": "ESTAR\u65b9\u6cd5\u7ed3\u5408\u4e09\u4e2a\u7ec4\u4ef6\uff1a1\uff09\u57fa\u4e8e\u8f68\u8ff9\u7684\u5206\u7c7b\u5668\u8bc6\u522b\u4f55\u65f6\u53ef\u4ee5\u5b89\u5168\u505c\u6b62\u63a8\u7406\uff1b2\uff09\u76d1\u7763\u5fae\u8c03\u6559\u5bfcLRM\u63d0\u51fa\u81ea\u751f\u6210\u7684<stop>\u4fe1\u53f7\uff1b3\uff09<stop>\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u81ea\u751f\u6210\u7684\u505c\u6b62\u70b9\u622a\u65adrollout\uff0c\u5e76\u4f7f\u7528\u8ba1\u7b97\u611f\u77e5\u7684\u5956\u52b1\u3002", "result": "\u5728\u56db\u4e2a\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cESTAR\u5c06\u63a8\u7406\u957f\u5ea6\u51cf\u5c11\u7ea63.7\u500d\uff08\u4ece4799\u964d\u81f31290\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u7387\uff0874.9% vs 74.2%\uff09\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u65e9\u671f\u505c\u6b62\u662f\u4e00\u79cd\u7b80\u5355\u800c\u5f3a\u5927\u7684\u673a\u5236\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002ESTAR\u65b9\u6cd5\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10009", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10009", "abs": "https://arxiv.org/abs/2602.10009", "authors": ["Sean Memery", "Kartic Subr"], "title": "Discovering High Level Patterns from Simulation Traces", "comment": null, "summary": "Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u7136\u8bed\u8a00\u5f15\u5bfc\u7684\u65b9\u6cd5\uff0c\u4ece\u8be6\u7ec6\u4eff\u771f\u65e5\u5fd7\u4e2d\u53d1\u73b0\u7c97\u7c92\u5ea6\u6a21\u5f0f\uff08\u5982\"\u521a\u4f53\u78b0\u649e\"\u3001\"\u7a33\u5b9a\u652f\u6491\"\u7b49\uff09\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u80fd\u66f4\u597d\u5730\u8fdb\u884c\u7269\u7406\u7cfb\u7edf\u63a8\u7406\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u7269\u7406\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u4ece\u89c2\u6d4b\u6570\u636e\u5b66\u4e60\u800c\u975e\u57fa\u4e8e\u4eff\u771f\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u4eff\u771f\u8f68\u8ff9\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u4f46\u53ef\u6269\u5c55\u6027\u5dee\uff0c\u56e0\u4e3a\u4eff\u771f\u8f68\u8ff9\u5305\u542b\u5927\u91cf\u7ec6\u7c92\u5ea6\u6570\u503c\u548c\u8bed\u4e49\u6570\u636e\u3002", "method": "\u63d0\u51fa\u81ea\u7136\u8bed\u8a00\u5f15\u5bfc\u7684\u65b9\u6cd5\uff0c\u4ece\u8be6\u7ec6\u4eff\u771f\u65e5\u5fd7\u4e2d\u53d1\u73b0\u7c97\u7c92\u5ea6\u6a21\u5f0f\u3002\u5408\u6210\u5728\u4eff\u771f\u65e5\u5fd7\u4e0a\u8fd0\u884c\u7684\u7a0b\u5e8f\uff0c\u5c06\u5176\u6620\u5c04\u5230\u4e00\u7cfb\u5217\u9ad8\u7ea7\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u521b\u5efa\u4eff\u771f\u65e5\u5fd7\u7684\u6ce8\u91ca\u8868\u793a\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u7269\u7406\u57fa\u51c6\u6d4b\u8bd5\u8bc1\u660e\uff0c\u8fd9\u79cd\u6ce8\u91ca\u8868\u793a\u66f4\u9002\u5408\u81ea\u7136\u8bed\u8a00\u5bf9\u7269\u7406\u7cfb\u7edf\u7684\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u4f7f\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4ece\u81ea\u7136\u8bed\u8a00\u6307\u5b9a\u7684\u76ee\u6807\u751f\u6210\u6709\u6548\u7684\u5956\u52b1\u7a0b\u5e8f\uff0c\u53ef\u7528\u4e8e\u89c4\u5212\u6216\u76d1\u7763\u5b66\u4e60\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u4ece\u4eff\u771f\u65e5\u5fd7\u4e2d\u63d0\u53d6\u7c97\u7c92\u5ea6\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u7269\u7406\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u7269\u7406\u63a8\u7406\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.10063", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10063", "abs": "https://arxiv.org/abs/2602.10063", "authors": ["Tianyi Jiang", "Arctanx An", "Hengyi Feng", "Naixin Zhai", "Haodong Li", "Xiaomin Yu", "Jiahui Liu", "Hanwen Du", "Shuo Zhang", "Zhi Yang", "Jie Huang", "Yuhua Li", "Yongxin Ni", "Huacan Wang", "Ronghao Chen"], "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes", "comment": null, "summary": "Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\\% and 4.72\\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at \\href{https://github.com/QuantaAlpha/chain-of-mindset}{https://github.com/QuantaAlpha/chain-of-mindset}.", "AI": {"tldr": "\u63d0\u51faChain of Mindset (CoM)\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u534f\u8c03\u56db\u79cd\u4e0d\u540c\u601d\u7ef4\u6a21\u5f0f\uff08\u7a7a\u95f4\u3001\u6536\u655b\u3001\u53d1\u6563\u3001\u7b97\u6cd5\uff09\u6765\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\"\u5355\u4e00\u601d\u7ef4\u9677\u9631\"\uff0c\u5728\u6574\u4e2a\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u56fa\u5b9a\u601d\u7ef4\u6a21\u5f0f\uff0c\u800c\u4eba\u7c7b\u89e3\u51b3\u95ee\u9898\u65f6\u4f1a\u6839\u636e\u95ee\u9898\u4e0d\u540c\u9636\u6bb5\u52a8\u6001\u5207\u6362\u4e0d\u540c\u601d\u7ef4\u6a21\u5f0f\u3002\u8fd9\u79cd\u5c40\u9650\u6027\u963b\u788d\u4e86\u6a21\u578b\u8fbe\u5230\u66f4\u9ad8\u667a\u80fd\u6c34\u5e73\u3002", "method": "\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684CoM\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u56db\u79cd\u529f\u80fd\u5f02\u6784\u7684\u601d\u7ef4\u6a21\u5f0f\uff1a\u7a7a\u95f4\u601d\u7ef4\uff08\u7a7a\u95f4\u63a8\u7406\uff09\u3001\u6536\u655b\u601d\u7ef4\uff08\u903b\u8f91\u63a8\u5bfc\uff09\u3001\u53d1\u6563\u601d\u7ef4\uff08\u521b\u610f\u751f\u6210\uff09\u548c\u7b97\u6cd5\u601d\u7ef4\uff08\u7ed3\u6784\u5316\u8ba1\u7b97\uff09\u3002\u901a\u8fc7\u5143\u4ee3\u7406\u52a8\u6001\u9009\u62e9\u6700\u4f18\u601d\u7ef4\u6a21\u5f0f\uff0c\u5e76\u4f7f\u7528\u53cc\u5411\u4e0a\u4e0b\u6587\u95e8\u63a7\u8fc7\u6ee4\u8de8\u6a21\u5757\u4fe1\u606f\u6d41\u3002", "result": "\u5728\u6570\u5b66\u3001\u4ee3\u7801\u751f\u6210\u3001\u79d1\u5b66QA\u548c\u7a7a\u95f4\u63a8\u7406\u7b49\u516d\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCoM\u5728Qwen3-VL-32B-Instruct\u548cGemini-2.0-Flash\u4e0a\u5206\u522b\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u53474.96%\u548c4.72%\u7684\u603b\u4f53\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6548\u7387\u5e73\u8861\u3002", "conclusion": "CoM\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u534f\u8c03\u591a\u79cd\u601d\u7ef4\u6a21\u5f0f\uff0c\u7a81\u7834\u4e86\u73b0\u6709LLM\u63a8\u7406\u65b9\u6cd5\u7684\u5355\u4e00\u601d\u7ef4\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u63a5\u8fd1\u4eba\u7c7b\u95ee\u9898\u89e3\u51b3\u7684\u667a\u80fd\u63a8\u7406\u65b9\u5f0f\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2602.10085", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10085", "abs": "https://arxiv.org/abs/2602.10085", "authors": ["Richard Bornemann", "Pierluigi Vito Amadori", "Antoine Cully"], "title": "CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs", "comment": "Preprint", "summary": "Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain limited to refining rewards for pre-defined tasks. To address this limitation, we introduce Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP), a novel framework leveraging Foundation Models (FM) to open-endedly expand and refine a hierarchical skill archive, structured as a directed graph of executable reward functions in code. We show that a goal-conditioned agent trained exclusively on the rewards generated by the discovered SHARP skills learns to solve increasingly long-horizon goals in the Craftax environment. When composed by a high-level FM-based planner, the discovered skills enable a single goal-conditioned agent to solve complex, long-horizon tasks, outperforming both pretrained agents and task-specific expert policies by over $134$% on average. We will open-source our code and provide additional videos $\\href{https://sites.google.com/view/code-sharp/homepage}{here}$.", "AI": {"tldr": "CODE-SHARP \u662f\u4e00\u4e2a\u5229\u7528\u57fa\u7840\u6a21\u578b\u81ea\u52a8\u53d1\u73b0\u548c\u6f14\u5316\u5206\u5c42\u6280\u80fd\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u5f62\u5f0f\u7684\u5956\u52b1\u51fd\u6570\u6784\u5efa\u6280\u80fd\u56fe\u8c31\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u3002", "motivation": "\u5f00\u653e\u5f0f\u7684\u6280\u80fd\u53d1\u73b0\u662f\u4eba\u5de5\u667a\u80fd\u7684\u91cd\u5927\u6311\u6218\u3002\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\uff0c\u8fd9\u5728\u6280\u80fd\u96c6\u5408\u672a\u77e5\u7684\u5f00\u653e\u5f0f\u573a\u666f\u4e2d\u4e0d\u53ef\u884c\u3002\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u4e3a\u9884\u5b9a\u4e49\u4efb\u52a1\u4f18\u5316\u5956\u52b1\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u5f00\u653e\u5f0f\u6280\u80fd\u53d1\u73b0\u3002", "method": "\u63d0\u51fa CODE-SHARP \u6846\u67b6\uff0c\u5229\u7528\u57fa\u7840\u6a21\u578b\u5f00\u653e\u5f0f\u5730\u6269\u5c55\u548c\u4f18\u5316\u5206\u5c42\u6280\u80fd\u6863\u6848\u3002\u6280\u80fd\u6863\u6848\u4ee5\u6709\u5411\u56fe\u5f62\u5f0f\u7ec4\u7ec7\uff0c\u5305\u542b\u53ef\u6267\u884c\u7684\u4ee3\u7801\u5956\u52b1\u51fd\u6570\u3002\u901a\u8fc7\u76ee\u6807\u6761\u4ef6\u667a\u80fd\u4f53\u8bad\u7ec3\uff0c\u7ed3\u5408\u9ad8\u5c42\u57fa\u7840\u6a21\u578b\u89c4\u5212\u5668\u7ec4\u5408\u6280\u80fd\u3002", "result": "\u5728 Craftax \u73af\u5883\u4e2d\uff0c\u4ec5\u4f7f\u7528\u53d1\u73b0\u7684 SHARP \u6280\u80fd\u5956\u52b1\u8bad\u7ec3\u7684\u76ee\u6807\u6761\u4ef6\u667a\u80fd\u4f53\u80fd\u591f\u89e3\u51b3\u8d8a\u6765\u8d8a\u957f\u65f6\u7a0b\u7684\u76ee\u6807\u3002\u7ec4\u5408\u6280\u80fd\u540e\uff0c\u5355\u4e2a\u667a\u80fd\u4f53\u80fd\u591f\u89e3\u51b3\u590d\u6742\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u5e73\u5747\u6027\u80fd\u8d85\u8fc7\u9884\u8bad\u7ec3\u667a\u80fd\u4f53\u548c\u4efb\u52a1\u7279\u5b9a\u4e13\u5bb6\u7b56\u7565 134%\u3002", "conclusion": "CODE-SHARP \u6210\u529f\u5b9e\u73b0\u4e86\u5f00\u653e\u5f0f\u6280\u80fd\u53d1\u73b0\uff0c\u901a\u8fc7\u57fa\u7840\u6a21\u578b\u81ea\u52a8\u751f\u6210\u548c\u6f14\u5316\u5206\u5c42\u6280\u80fd\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u4e3a\u5f00\u653e\u5f0f\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.10090", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10090", "abs": "https://arxiv.org/abs/2602.10090", "authors": ["Zhaoyang Wang", "Canwen Xu", "Boyi Liu", "Yite Wang", "Siwei Han", "Zhewei Yao", "Huaxiu Yao", "Yuxiong He"], "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning", "comment": "41 pages", "summary": "Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model.", "AI": {"tldr": "\u63d0\u51faAgent World Model (AWM)\u5408\u6210\u73af\u5883\u751f\u6210\u7ba1\u9053\uff0c\u521b\u5efa1000\u4e2a\u4ee3\u7801\u9a71\u52a8\u3001\u6570\u636e\u5e93\u652f\u6301\u7684\u73af\u5883\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u8bad\u7ec3\u53d7\u9650\u4e8e\u7f3a\u4e4f\u591a\u6837\u53ef\u9760\u7684\u73af\u5883\uff0c\u9700\u8981\u89e3\u51b3\u73af\u5883\u7a00\u7f3a\u95ee\u9898\u4ee5\u652f\u6301\u591a\u8f6e\u4ea4\u4e92\u5de5\u5177\u4f7f\u7528\u4efb\u52a1\u3002", "method": "\u5f00\u53d1AWM\u5408\u6210\u73af\u5883\u751f\u6210\u7ba1\u9053\uff0c\u521b\u5efa1000\u4e2a\u4ee3\u7801\u9a71\u52a8\u3001\u6570\u636e\u5e93\u652f\u6301\u7684\u73af\u5883\uff0c\u6bcf\u4e2a\u73af\u5883\u5e73\u574735\u4e2a\u5de5\u5177\uff0c\u63d0\u4f9b\u9ad8\u8d28\u91cf\u89c2\u6d4b\u548c\u53ef\u9760\u72b6\u6001\u8f6c\u6362\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ec5\u5728\u5408\u6210\u73af\u5883\u4e2d\u8bad\u7ec3\u7684\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\uff0c\u4f18\u4e8e\u5728\u57fa\u51c6\u7279\u5b9a\u73af\u5883\u4e2d\u8bad\u7ec3\u3002", "conclusion": "AWM\u5408\u6210\u73af\u5883\u7ba1\u9053\u4e3a\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u5e76\u5b9e\u73b0\u826f\u597d\u6cdb\u5316\u6027\u80fd\u3002"}}
