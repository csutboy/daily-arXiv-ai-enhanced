<div id=toc></div>

# Table of Contents

- [econ.GN](#econ.GN) [Total: 10]
- [cs.ET](#cs.ET) [Total: 5]
- [cs.SI](#cs.SI) [Total: 8]
- [cs.RO](#cs.RO) [Total: 108]
- [cs.AI](#cs.AI) [Total: 133]
- [cs.CY](#cs.CY) [Total: 21]
- [econ.EM](#econ.EM) [Total: 3]
- [econ.TH](#econ.TH) [Total: 3]
- [eess.SY](#eess.SY) [Total: 32]
- [stat.AP](#stat.AP) [Total: 13]


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [1] [Terrorism & Democracy in Burkina-Faso](https://arxiv.org/abs/2509.23046)
*P Carmel Marie Zagre*

Main category: econ.GN

TL;DR: 恐怖袭击显著增加对威权政体的支持，减少对民主治理的支持，在脆弱民主国家中加速威权倾向。


<details>
  <summary>Details</summary>
Motivation: 研究恐怖主义对布基纳法索政治后果的影响，特别是公众对民主和威权替代方案支持度的变化。

Method: 结合ACLED地理定位恐怖事件数据（2015-2024）和Afrobarometer民意数据，比较成功恐怖袭击对公众政治偏好的影响。

Result: 成功恐怖袭击显著增加对军事政权、一人统治和一党制的支持，同时减少对民主治理的支持；这些变化在袭击后立即显现并持续存在；恐怖主义侵蚀对公民自由和行动自由等民主价值观的认知。

Conclusion: 恐怖主义在脆弱民主国家中触发安全与自由之间的权衡，削弱民主韧性并加速威权倾向，制度薄弱或政治知识缺乏并非主要驱动因素。

Abstract: This article examines the political consequences of terrorism in Burkina
Faso. Using a dataset combining geolocated terrorist events from ACLED (from
2015 to 2024) with public opinion data from Afrobarometer, I compare the effect
of successful terrorist attacks on public support for democracy and
authoritarian alternatives. The results reveal that successful terrorist
attacks significantly increase support for military regimes, one man regimes,
and one party systems, while decreasing support for democratic governance.
These changes are most pronounced immediately after the attacks and persist
over time. This suggests that terrorism has triggered a trade-off in public
preferences between security and freedom. The study also reveals that terrorism
erodes perceptions of key democratic values, particularly civil liberties and
freedom of movement. Robustness tests confirm that weak institutions or a lack
of political knowledge are not driving the results. The article highlights how
terrorism in fragile democracies can undermine democratic resilience and
accelerate authoritarian drift.

</details>


### [2] [What influenced the lack of diversity in CSR after the company's losses: evidence from topic modeling](https://arxiv.org/abs/2509.23424)
*Ruiying Liu,Yuchi Li,Zhanli Li*

Main category: econ.GN

TL;DR: 企业亏损会显著压缩CSR披露多样性，外部和内部治理机制能够缓解这种负面影响。


<details>
  <summary>Details</summary>
Motivation: 研究财务困境对企业非财务信息披露结构的影响，特别是CSR披露多样性的变化。

Method: 使用LDA主题模型提取CSR报告主题，采用Gini-Simpson指数和Shannon熵量化披露多样性，通过回归分析检验企业亏损与CSR多样性的关系。

Result: 企业亏损显著降低CSR主题多样性；媒体关注、高管薪酬激励和监事会持股等治理机制能缓解这种负面影响；第三方鉴证、安全生产披露、企业规模和行业竞争度存在异质性效应。

Conclusion: 财务困境对非财务信息披露具有结构性影响，研究为优化CSR沟通、完善评级框架和设计多样化披露标准提供了实践启示。

Abstract: The diversity of corporate social responsibility (CSR) disclosure is a
crucial dimension of corporate transparency, reflecting the breadth and
resilience of a firm's social responsibility. Using CSR reports of Chinese
A-share firms from 2006 to 2023, this paper applies Latent Dirichlet Allocation
(LDA) to extract topics and quantifies disclosure diversity using the
Gini-Simpson index and Shannon entropy. Regression results show that corporate
losses significantly compress CSR topic diversity, consistent with the slack
resources hypothesis. Both external and internal governance mechanisms mitigate
this effect: higher media attention, stronger executive compensation
incentives, and greater supervisory board shareholding attenuate the
loss-diversity penalty. Results are robust to instrumental variables
estimation, propensity score matching, and placebo tests. Heterogeneity
analyses indicate weaker effects in firms with third-party assurance, those
disclosing work safety content, large firms, and those in less competitive
industries. Our study highlights the structural impact of financial distress on
non-financial disclosure and provides practical implications for optimizing CSR
communication, refining evaluation frameworks for rating agencies, and
designing diversified disclosure standards.

</details>


### [3] [When Clear Skies Cloud Trust: Environmental Cues and the Paradox of Confidence in Government](https://arxiv.org/abs/2509.23554)
*Xiangzhe Xu,Ran Wu*

Main category: econ.GN

TL;DR: 本文研究发现，阳光效率等环境条件通过情感和认知机制影响政府信任，晴朗天气可能通过提高环境意识和负面归因而降低政府信任。


<details>
  <summary>Details</summary>
Motivation: 研究环境条件特别是阳光效率如何影响政府信任，探索环境心理学与政治经济学的交叉领域，理解环境因素对民主合法性和国家能力的潜在影响。

Method: 使用世界价值观调查第七波数据与NASA POWER高频天气数据，提出并验证"显著性与归因"机制，识别主观幸福感、政治兴趣、政治讨论和健康感知等中介路径。

Result: 研究发现晴朗天气可能降低政府信任，环境条件在基于调查的信任指标中引入测量误差，证实了环境意识增强和负面归因的中介作用。

Conclusion: 研究为环境心理学、行为政治经济学和调查方法学提供了理论贡献，对治理、政策设计和调查实践具有实际意义。

Abstract: Government trust, as a core concept in political economy and public policy
research, serves as a fundamental cornerstone of democratic legitimacy and
state capacity. This paper examines how environmental conditions, particularly
sunlight efficiency, influence reported government trust through both affective
and cognitive mechanisms. Leveraging World Values Survey Wave 7 data merged
with NASA POWER high-frequency weather data, we propose and validate a novel
``salience and attribution'' mechanism: clearer skies may paradoxically reduce
government trust by heightening environmental awareness and triggering negative
attributions. We further identify potential mediating pathways, including
subjective well-being, political interest, political discussion, and health
perception, and demonstrate that environmental conditions introduce measurement
error in survey-based trust indicators. Our findings provide theoretical
contributions to environmental psychology, behavioral political economy, and
survey methodology, and yield practical implications for governance, policy
design, and survey

</details>


### [4] [Unintended Consequences of Early Driving Access: Evidence from Graduated Driver Licensing Policies and Adolescent Health Outcomes](https://arxiv.org/abs/2509.23578)
*Sharareh Massahi*

Main category: econ.GN

TL;DR: 研究发现早期驾驶许可（16岁前获得学习驾照）虽然减少了青少年交通死亡，但显著增加了15-19岁女性青少年的毒品相关死亡率和心理健康相关死亡率，揭示了青少年驾照政策在保护交通安全的同时可能在其他健康领域产生意外危害。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索分级驾照系统在减少青少年交通事故死亡的同时，是否会产生其他意外健康后果，特别是对女性青少年的毒品和心理健康相关死亡率的影响。

Method: 利用1999-2020年美国各州驾照政策差异，采用双重差分分析方法，首次提供了早期驾驶许可对女性青少年健康风险的因果证据。

Result: 允许16岁前获得学习驾照的州，女性青少年毒品相关死亡率显著增加1.331/10万，心理健康相关死亡率增加0.760/10万，而车辆死亡人数下降0.656/10万。这些影响解释了研究期间青少年毒品死亡率上升的近三分之一和心理健康死亡率上升的十分之一。

Conclusion: 研究结果从根本上改变了驾照政策的成本效益评估，揭示了保护青少年某一领域的干预措施可能在其他领域产生风险。建议通过加强监督、地理限制和心理健康整合等循证修改来保持交通安全收益，同时减轻意外危害。

Abstract: Graduated driver licensing systems effectively reduce adolescent traffic
fatalities but create unintended health consequences. Using state-level
variation in licensing policies from 1999-2020 and difference-in-differences
analysis, we provide the first causal evidence that early driving access
generates significant health risks for female adolescents aged 15-19. States
allowing learner's permits before age 16 experienced sharp increases in
drug-related mortality (+1.331 per 100,000, p<0.001) and mental health-related
mortality (+0.760, p<0.001), even as vehicle deaths declined (-0.656, p<0.05).
These effects explain nearly one-third of rising adolescent drug mortality and
one-tenth of mental health mortality increases over the study period. Early
driving access expands geographic reach, enabling contact with illicit drug
markets previously inaccessible to adolescents. It broadens social networks,
increasing exposure to high-risk peers, while vehicles provide unsupervised
spaces for experimentation. Premature independence also intensifies
psychological stress during critical developmental stages. Nationally, results
correspond to approximately 138 additional drug deaths and 79 mental health
deaths annually among female adolescents, imposing over $2 billion in mortality
costs yearly. These findings fundamentally reshape cost-benefit assessments of
licensing policies, revealing how interventions protecting adolescents in one
domain can create risks in others. Evidence-based modifications including
enhanced supervision, geographic restrictions, and mental health integration
could preserve traffic safety gains while mitigating unintended harms. This
research demonstrates the critical need for multi-outcome policy evaluation
that captures both benefits and hidden costs of expanded adolescent
independence.

</details>


### [5] [Moravec's Paradox and Restrepo's Model: Limits of AGI Automation in Growth](https://arxiv.org/abs/2509.24466)
*Marc Bara*

Main category: econ.GN

TL;DR: 本文扩展了Restrepo(2025)的AGI经济增长模型，引入莫拉维克悖论，证明当物理任务构成经济瓶颈时，劳动收入份额会收敛于正常数而非零。


<details>
  <summary>Details</summary>
Motivation: 将莫拉维克悖论（传感器运动技能任务比认知任务计算成本更高）纳入AGI经济增长模型，研究其对收入分配的影响。

Method: 将任务空间划分为认知和物理组件，考虑不同的自动化成本，允许某些物理瓶颈具有无限计算成本。

Result: 当物理任务构成经济瓶颈且计算要求足够高（或无限）时，在有限计算资源条件下，劳动收入份额收敛于正常数而非零。

Conclusion: 莫拉维克悖论从根本上改变了AGI的分配影响，同时保持了认知密集型经济的增长动态。

Abstract: This note extends Restrepo (2025)'s model of economic growth under AGI by
incorporating Moravec's Paradox -the observation that tasks requiring
sensorimotor skills remain computationally expensive relative to cognitive
tasks. We partition the task space into cognitive and physical components with
differential automation costs, allowing infinite costs for some physical
bottlenecks. Our key result shows that when physical tasks constitute economic
bottlenecks with sufficiently high (or infinite) computational requirements,
the labor share of income converges to a positive constant in the
finite-compute regime (rather than zero). This fundamentally alters the
distributional implications of AGI while preserving the growth dynamics for
cognitive-intensive economies.

</details>


### [6] [Identifying the post-pandemic determinants of low performing students in Latin America through interpretable Machine Learning SHAP Values-Insights from PISA 2022](https://arxiv.org/abs/2509.24508)
*Marcos Delprato*

Main category: econ.GN

TL;DR: 使用可解释机器学习方法分析拉丁美洲PISA 2022数据，识别影响学生低学业表现的关键因素，发现语言少数群体、留级、缺乏数字设备、贫困家庭、工作以及学校劣势环境是主要风险因素。


<details>
  <summary>Details</summary>
Motivation: 拉丁美洲学生基础能力不足的高发率令人担忧，特别是在该地区存在深层结构性不平等和疫情后学习损失加剧的背景下，需要识别影响低学业表现学生的关键因素。

Method: 基于PISA 2022数据，使用Shapley Additive Explanations (SHAP)分析方法，对10个国家的数据进行分析，识别影响低学业表现学生的关键因素。

Result: 发现最可能成为低学业表现学生的特征包括：说少数民族语言、曾留级、家中无数字设备、来自贫困家庭、每周工作半天，以及就读学校存在不良学校氛围、薄弱ICT基础设施和教学质量差等劣势。

Conclusion: 研究结果为制定针对性策略以帮助拉丁美洲教育系统中最落后的学生群体提供了重要依据，识别出的关键因素在各国间具有较高一致性。

Abstract: The high prevalence of students not achieving the basic competencies in Latin
America is concerning. Even more so given the region's deep structural
inequalities and the larger post-pandemic regional learning losses. Within this
scenario, this paper contributes to the identification of the determinants of
bottom and low performers (below level 2) using recent advancements on
explainable machine learning methods. In particular, relying on PISA 2022 data
for 10 countries and using the Shapley Additive Explanations (SHAP) analysis, I
identify critical factors impacting on the student performance across low
performers groups. I find that a student with the highest probability of being
a not achiever speaks a minority language and had repeated, has no digital
devices at home, comes from a poor family and works for payment half of the
week, and the school he/she attends has wide disadvantages such as bad school
climate, weak ICT infrastructure and poor teaching quality (only a third of
teachers being certified). Regarding countries' estimates, I find quite
homogeneous patterns as far as global average contribution of top ranked
factors is concerned, with repetition at primary, household wealth, and
educational ICT inputs being top ten ranked covariates in at least 8 out of the
10 total countries. The paper findings contribute to the broad literature on
strategies to identify and to target those most left behind in Latin American
education systems.

</details>


### [7] [Determinants of Latin American students academic resilience-Insights based on PISA 2022 using an explainable machine learning approach](https://arxiv.org/abs/2509.24830)
*Marcos Delprato*

Main category: econ.GN

TL;DR: 使用可解释机器学习方法分析拉丁美洲学生学业韧性的决定因素，发现家庭资源、性别、作业、留级和工作强度是重要因素，学校特征如规模、网络设备、师生比和教学质量也影响学业韧性。


<details>
  <summary>Details</summary>
Motivation: 拉丁美洲地区存在学习危机，特别是在疫情后不平等加剧的背景下，研究弱势学生如何取得良好学业表现的学业韧性及其决定因素具有政策相关性。

Method: 使用SHAP可解释机器学习方法，基于PISA 2022数据对9个拉丁美洲国家进行分析，采用多种学业韧性指标。

Result: 发现家庭资源（书籍和数字设备）、性别、作业、留级和工作强度是学业韧性的重要因素；学校规模、网络设备比例、师生比、教学质量（认证教师和专业发展率）和学校类型（私立学校）也是关键驱动因素；学业韧性与疫情期间学校关闭时长和远程学习障碍呈负相关。

Conclusion: 研究结果填补了该地区文献空白，为未来政策设计提供了依据，可以利用学业韧性的关键特征帮助弱势学生从低成就群体转变为学业韧性学生。

Abstract: The learning crisis in the Latin American region (i.e., higher rates of
students not reaching basic competencies at secondary level) is worrying,
particularly post-pandemic given the stronger role of inequality behind
achievement. Within this scenario, the concept of student academic resilience
(SAR), students who despite coming from disadvantaged backgrounds reach good
performance levels, and an analysis of its determinants, are policy relevant.
In this paper, using advancements on explainable machine learning methods (the
SHAP method) and relying on PISA 2022 data for 9 countries from the region, I
identify leading factors behind SAR using diverse indicators. I find that
household inputs (books and digital devices), gender, homework, repetition and
work intensity are leading factors for one indicator of academic resilience,
whereas for other indicator leading drives fall into the school domain: school
size, the ratio of PC connected to the internet, STR and teaching quality
proxied by certified teachers and professional development rates and school
type (private school). Also, I find negative associations of SAR with the
length of school closures and barriers for remote learning during the pandemic.
The paper's findings adds to the scare regional literature as well as they
contribute to future policy designs where key features behind SAR can be used
to lift disadvantaged students from lower achievement groups towards being
academic resilient.

</details>


### [8] [Pixels to Prices: Visual Traits, Market Cycles, and the Economics of NFT Valuation](https://arxiv.org/abs/2509.24879)
*Samiha Tariq*

Main category: econ.GN

TL;DR: 该研究分析了NFT市场中视觉特征和市场周期如何影响价格，发现可解释的图像特征（如饱和度、构图集中度）具有独立定价能力，且这些特征的定价效应随市场周期变化。


<details>
  <summary>Details</summary>
Motivation: 理解NFT市场中视觉特征和市场周期对价格形成的共同影响，为数字艺术市场的资产定价、平台策略和市场设计提供周期感知工具。

Method: 使用94,039笔交易数据，提取196个图像特征，应用三阶段筛选过程识别稳定预测因子，采用静态混合效应模型和贝叶斯动态混合效应面板模型进行分析。

Result: 市场情绪和可解释图像特征具有显著定价能力；深度嵌入特征在显性特征条件下增量价值有限；时间变化系数显示定价效应在市场扩张期更强，在衰退期较弱或为负。

Conclusion: NFT价格既反映可观察的数字产品特征，也反映市场周期，该框架为数字艺术市场提供了周期感知的资产定价工具。

Abstract: This paper studies how visual traits and market cycles shape prices in NFT
markets. Using 94,039 transactions from 26 major generative Ethereum
collections, the analysis extracts 196 machine-quantified image features
(covering color, composition, palette structure, geometry, texture, and deep
learning embeddings), then applies a three-stage filter process to identify
stable predictors for hedonic regression. A static mixed-effects model shows
that market sentiment and transparent, interpretable image traits have
significant and independent pricing power: higher focal saturation,
compositional concentration, and curvature are rewarded, while clutter, heavy
line work, and dispersed palettes are discounted; deep embeddings add limited
incremental value conditional on explicit traits. To assess state dependence,
the study estimates a Bayesian dynamic mixed-effects panel with cycle effects
and time-varying coefficients for a salient image attribute (Composition Focus
- Saturation). Collection-level heterogeneity ("brand premia") is absorbed by
random effects. The time-varying coefficients exhibit regime sensitivity, with
stronger premia in expansionary phases and weaker or negative loadings in
downturns, while grand-mean effects remain small on average. Overall, NFT
prices reflect both observable digital product characteristics and market
regimes, and the framework offers a cycle-aware tool for asset pricing,
platform strategy, and market design in digital art markets.

</details>


### [9] [Signaling in the Age of AI: Evidence from Cover Letters](https://arxiv.org/abs/2509.25054)
*Jingyi Cui,Gabriel Dias,Justin Ye*

Main category: econ.GN

TL;DR: AI写作工具提高了求职信与职位描述的匹配度，增加了面试机会，但降低了求职信作为能力信号的价值，促使雇主转向其他信号如过往评价。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI如何影响劳动力市场信号传递，特别是AI工具对求职信写作和招聘决策的影响。

Method: 使用Freelancer.com上AI求职信写作工具的数据，通过双重差分法分析工具使用对求职信质量、面试可能性和信号价值的影响。

Result: AI工具提高了求职信与职位的匹配度，增加了面试机会；写作能力较弱的工人获益更大；求职信作为能力信号的价值下降51%；雇主转向过往评价等替代信号。

Conclusion: AI工具虽然提高了求职信质量，但削弱了其作为能力信号的价值，促使招聘方依赖其他更可靠的信号来评估求职者能力。

Abstract: We study how generative AI affects labor market signaling using the
introduction of an AI-powered cover letter writing tool on Freelancer.com. Our
data track both access to the tool and usage at the application level.
Difference-in-differences estimates show that access to the AI tool increased
textual alignment between cover letters and job posts--which we refer to as
cover letter tailoring--and raised callback likelihoods. Workers with weaker
pre-AI writing skills saw larger improvements in cover letters, indicating that
AI substitutes for workers' own skills. Although only a minority of
applications used the tool, the overall correlation between cover letter
tailoring and callbacks fell by 51%, implying that cover letters became less
informative signals of worker ability in the age of AI. Employers
correspondingly shifted toward alternative signals, such as workers' past
reviews, which became more predictive of hiring. Finally, within the treated
group, greater time spent editing AI drafts was associated with higher hiring
success.

</details>


### [10] [Labour unions under neoliberal authoritarianism in the Global South: the cases of Turkey and Egypt](https://arxiv.org/abs/2509.25152)
*Mehmet Erman Erol,Cagatay Edgucan Sahin*

Main category: econ.GN

TL;DR: 分析土耳其和埃及在新自由主义时期的有组织劳工轨迹，以及2013年后在安全化新自由主义发展主义政权下的现状


<details>
  <summary>Details</summary>
Motivation: 挑战经济自由化会导致政治民主化的观点，研究新自由主义在这些国家的经验如何以持续威权主义为特征

Method: 比较分析土耳其和埃及的案例，关注新自由主义重组中劳动力市场的变化，特别是通过强制措施和威权法团主义关系来瓦解异见工会力量

Result: 新自由主义经验在这两个国家以持续威权主义为特征，经济自由化并未带来政治民主化，而是通过强制措施瓦解异见工会，通过威权法团主义关系控制其他有组织劳工

Conclusion: 新自由主义重组在土耳其和埃及的成功依赖于对组织劳工的压制，通过强制和威权法团主义手段瓦解异见工会力量，这挑战了经济自由化必然导致政治民主化的传统观点

Abstract: This article analyses the trajectories of organised labour in times of
neoliberalism in Turkey and Egypt and their current condition under securitised
neoliberal-developmentalist regimes post-2013. Neoliberal experience in these
countries was marked by continuing authoritarianism, challenging the view that
economic liberalisation would lead to political democratisation. One of the
most important areas of neoliberal restructuring has been labour markets. In
order to achieve this, struggles over organised labour were of vital
importance. Dismantling the power of dissident labour unions through coercive
measures and containing other sections of organised labour through
authoritarian corporatist relations has been crucial in these cases.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [11] [Cognition Engines: A Row-Scale HVDC Architecture for Computational Continuity of AI](https://arxiv.org/abs/2509.22680)
*Paul Churnock*

Main category: cs.ET

TL;DR: 提出基于物理原理的±400Vdc架构，通过计算连续性作为结构特性来解决AI训练导致的功率波动问题，确保电网稳定运行。


<details>
  <summary>Details</summary>
Motivation: AI训练会产生毫秒级边沿的同步功率浪涌，破坏恒功率负载的稳定性，需要新的架构来保证计算连续性。

Method: 采用行级±400Vdc架构，通过DRU提供快速能量，SST调节平均功率，使用薄膜电容和钳位吸收初始边沿，实施时间分级保护机制。

Result: 实现了±1%稳态带宽、≤2%瞬态偏差、≤3ms恢复、≥45°裕度的性能指标，保护储备底线，确保从行到园区级别的可扩展性。

Conclusion: 该方案不是简单的调优，而是为计算连续性建立了一个明确的契约框架，通过波形证据确保符合性。

Abstract: AI training creates synchronized, step-dominant surges with millisecond edges
that destabilize constant-power loads (Choukse et al., 2025; arXiv:2508.14318).
We propose a physics-anchored row-scale $\pm 400$ Vdc architecture that makes
Computational Continuity a structural property. DRUs supply fast energy via
controlled droop; SSTs regulate average power with bounded ramps and no reverse
power flow and no high-frequency export at the PCC; import is subjected to a
bounded dP/dt envelope; film capacitance and clamps absorb the first edge. The
contract is explicit: $\pm 1\%$ steady-band, $\leq 2\%$ transient deviation,
$\leq 3$ ms recovery, $\geq 45^{\circ}$ margin, reserve floors intact, yields
spine and lowest branches. Recharge is valley-following (admitted only below
Avg with MW headroom; $\leq 5$ kW/s per row ramps). Protection is time-graded
(branch $\mu$s, row ms, MW seconds). Scaling preserves invariants from row to
pod/hall/campus without retuning. Conformance is by waveform evidence
(microsecond branch clears, $2\%/50$ ms holds, FLISR with no reverse power flow
and no high-frequency export at the PCC). The result is not tuning but a
contract for continuity.

</details>


### [12] [Conductance-dependent Photoresponse in a Dynamic SrTiO3 Memristor for Biorealistic Computing](https://arxiv.org/abs/2509.22767)
*Christoph Weilenmann,Hanglin He,Marko Mladenović,Till Zellweger,Kevin Portner,Klemens Bauer,Guillaume Bellec,Mathieu Luisier,Alexandros Emboras*

Main category: cs.ET

TL;DR: 该研究使用光学辐射作为全局神经调节信号，研究了可作为固态突触的纳米级SrTiO3忆阻器，展示了其光电响应与电导状态的平方根关系，以及可通过电偏压控制的光激发后电导衰减特性。


<details>
  <summary>Details</summary>
Motivation: 现代计算机使用静态内存组件执行预定义操作，而生物系统通过动态的、时间依赖的突触和神经元过程学习。生物学习过程还依赖全局信号（神经调节剂），这些信号根据突触的动态内部状态同时影响多个突触。

Method: 使用光学辐射作为全局神经调节信号，研究纳米级SrTiO3忆阻器，通过多种测量方法分析其光电响应特性。

Result: 忆阻器的光电响应取决于电导状态，遵循明确的平方根关系；光激发后电导在1-10秒范围内衰减，且可通过电偏压可靠控制；器件具有低功耗操作（每个光脉冲<1pJ）和小测量变异性。

Conclusion: 这些特性结合低功耗和小变异性，可能为在电光硬件中实现复杂生物学习过程的空间和能量高效实现铺平道路。

Abstract: Modern computers perform pre-defined operations using static memory
components, whereas biological systems learn through inherently dynamic,
time-dependent processes in synapses and neurons. The biological learning
process also relies on global signals - neuromodulators - who influence many
synapses at once depending on their dynamic, internal state. In this study,
using optical radiation as a global neuromodulatory signal, we investigate
nanoscale SrTiO3 (STO) memristors that can act as solid-state synapses. Via
diverse sets of measurements, we demonstrate that the memristor's photoresponse
depends on the electrical conductance state, following a well-defined square
root relation. Additionally, we show that the conductance decays after
photoexcitation with time constants in the range of 1 - 10 s and that this
effect can be reliably controlled using an electrical bias. These properties in
combination with our device's low power operation (< 1pJ per optical pulse) and
small measurement variability may pave the way for space- and energy-efficient
implementations of complex biological learning processes in electro-optical
hardware.

</details>


### [13] [Length-Matching Routing for Programmable Photonic Circuits Using Best-First Strategy](https://arxiv.org/abs/2509.23463)
*Xiaoke Wang,Dirk Stroobandt*

Main category: cs.ET

TL;DR: 本文针对可编程光子集成电路中的精确线长控制需求，提出了不同长度匹配路由策略，包括可接受的启发式估计器和剪枝方法，以提高搜索精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统路由算法优先考虑最短路径，但光子组件需要精确长度路由来维持所需的光学特性，因此需要专门的长度匹配路由方法。

Method: 基于改进评估函数的最佳优先搜索算法，提出可接受的启发式估计器和剪枝方法；对于多引脚长度匹配挑战，引入基于绕行边界的引脚排序机制。

Result: 在各种长度匹配基准测试中分析了运行时间和启发式性能，证明了所提方法在不同布局场景下的有效性。

Conclusion: 提出的算法在单调启发式下具有完备性，能够有效解决光子集成电路中的精确长度匹配路由问题。

Abstract: In the realm of programmable photonic integrated circuits (PICs), precise
wire length control is crucial for the performance of on-chip programmable
components such as optical ring resonators, Mach-Zehnder interferometers, and
optical true time-delay lines. Unlike conventional routing algorithms that
prioritize shortest-path solutions, these photonic components require
exact-length routing to maintain the desired optical properties.
  To address these challenges, this paper presents different length-matching
routing strategies to find exact-length paths while balancing search space and
runtime efficiently. We propose a novel admissible heuristic estimator and a
pruning method, designed to enhance the accuracy and efficiency of the search
process. The algorithms are derived from the Best-First search with modified
evaluation functions. For two-pin length-matching routing, we formally prove
that the proposed algorithms are complete under monotonic heuristics. For
multi-pin length-matching challenges, we introduce a pin-ordering mechanism
based on detour margins to reduce the likelihood of prematurely blocking
feasible routes. Through evaluations on various length-matching benchmarks, we
analyze runtime and heuristic performance, demonstrating the effectiveness of
the proposed approaches across different layout scenarios.

</details>


### [14] [Embedded Deep Learning for Bio-hybrid Plant Sensors to Detect Increased Heat and Ozone Levels](https://arxiv.org/abs/2509.24992)
*Till Aust,Christoph Karl Heck,Eduard Buss,Heiko Hamann*

Main category: cs.ET

TL;DR: 开发了一种生物混合环境传感器系统，通过整合自然植物和嵌入式深度学习，实现温度和臭氧变化的实时、设备端检测。


<details>
  <summary>Details</summary>
Motivation: 利用植物作为生物传感器，结合嵌入式深度学习技术，提供低功耗的连续环境监测解决方案。

Method: 基于低功耗PhytoNode平台，记录常春藤的电势差信号，并使用嵌入式深度学习模型在设备上进行处理。

Result: 系统能够以高达0.98的灵敏度检测温度和臭氧变化，但存在日间和植物间变异性以及精度限制的问题。

Conclusion: 该方法为连续环境监测提供了新的低功耗解决方案，并具有扩展到新环境因素和植物物种的潜力。

Abstract: We present a bio-hybrid environmental sensor system that integrates natural
plants and embedded deep learning for real-time, on-device detection of
temperature and ozone level changes. Our system, based on the low-power
PhytoNode platform, records electric differential potential signals from Hedera
helix and processes them onboard using an embedded deep learning model. We
demonstrate that our sensing device detects changes in temperature and ozone
with good sensitivity of up to 0.98. Daily and inter-plant variability, as well
as limited precision, could be mitigated by incorporating additional training
data, which is readily integrable in our data-driven framework. Our approach
also has potential to scale to new environmental factors and plant species. By
integrating embedded deep learning onboard our biological sensing device, we
offer a new, low-power solution for continuous environmental monitoring and
potentially other fields of application.

</details>


### [15] [Information Transmission in Quorum Sensing for Gut Microbiome](https://arxiv.org/abs/2509.25057)
*O. Tansel Baydas,Efe Yatgin,Ozgur B. Akan*

Main category: cs.ET

TL;DR: 使用随机微分方程框架研究群体感应系统的信息处理能力，量化肠道微生物群中厚壁菌门和拟杆菌门的信号效率和信息保真度


<details>
  <summary>Details</summary>
Motivation: 虽然大多数理论研究关注群体感应动力学的数学建模，但其通信理论方面仍较少探索。群体感应失调与多种疾病相关

Method: 采用随机微分方程框架，将细胞内基因调控与细胞外自诱导物动力学联系起来，量化互信息作为信号效率和信息保真度的度量

Result: 研究了肠道微生物群中两个主要细菌门（厚壁菌门和拟杆菌门）的信息处理能力

Conclusion: 群体感应系统具有显著的信息处理能力，互信息可作为评估信号效率和信息保真度的有效指标

Abstract: Microorganisms employ sophisticated mechanisms for intercellular
communication and environmental sensing, with quorum sensing serving as a
fundamental regulatory process. Dysregulation of quorum sensing has been
implicated in various diseases. While most theoretical studies focus on
mathematical modeling of quorum sensing dynamics, the communication-theoretic
aspects remain less explored. In this study, we investigate the information
processing capabilities of quorum sensing systems using a stochastic
differential equation framework that links intracellular gene regulation to
extracellular autoinducer dynamics. We quantify mutual information as a measure
of signaling efficiency and information fidelity in two major bacterial phyla
of the gut microbiota: Firmicutes and Bacteroidetes.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [16] [CrediBench: Building Web-Scale Network Datasets for Information Integrity](https://arxiv.org/abs/2509.23340)
*Emma Kondrup,Sebastian Sabry,Hussein Abdallah,Zachary Yang,James Zhou,Kellin Pelrine,Jean-François Godbout,Michael M. Bronstein,Reihaneh Rabbany,Shenyang Huang*

Main category: cs.SI

TL;DR: 提出了CrediBench：一个大规模数据处理管道，用于构建联合建模文本内容和超链接结构的时序网络图来进行虚假信息检测。该方法捕捉了虚假信息域的动态演变，包括内容和网站间引用随时间的变化。


<details>
  <summary>Details</summary>
Motivation: 在线虚假信息构成日益严重的威胁，现有检测方法通常孤立地关注文本内容或网络结构，未能利用网站内容和超链接关系之间的丰富动态交互作用。

Method: 开发了CrediBench数据处理管道，构建时序网络图，同时建模文本内容和超链接结构。从Common Crawl档案中提取了一个月的快照，包含4500万个节点和10亿条边。

Result: 创建了迄今为止公开可用的最大网络图数据集用于虚假信息研究。实验证明结构和网页内容信号在学习衡量来源可靠性的可信度分数方面具有强大能力。

Conclusion: CrediBench通过联合建模内容和结构，为虚假信息检测提供了更全面的方法，证明了这种综合方法在评估来源可信度方面的有效性。

Abstract: Online misinformation poses an escalating threat, amplified by the Internet's
open nature and increasingly capable LLMs that generate persuasive yet
deceptive content. Existing misinformation detection methods typically focus on
either textual content or network structure in isolation, failing to leverage
the rich, dynamic interplay between website content and hyperlink relationships
that characterizes real-world misinformation ecosystems. We introduce
CrediBench: a large-scale data processing pipeline for constructing temporal
web graphs that jointly model textual content and hyperlink structure for
misinformation detection. Unlike prior work, our approach captures the dynamic
evolution of general misinformation domains, including changes in both content
and inter-site references over time. Our processed one-month snapshot extracted
from the Common Crawl archive in December 2024 contains 45 million nodes and 1
billion edges, representing the largest web graph dataset made publicly
available for misinformation research to date. From our experiments on this
graph snapshot, we demonstrate the strength of both structural and webpage
content signals for learning credibility scores, which measure source
reliability. The pipeline and experimentation code are all available here, and
the dataset is in this folder.

</details>


### [17] [Hybrid Graph Embeddings and Louvain Algorithm for Unsupervised Community Detection](https://arxiv.org/abs/2509.23411)
*Dalila Khettaf,Djamel Djenouri,Zeinab Rezaeifar,Youcef Djenouri*

Main category: cs.SI

TL;DR: 提出了一种结合Louvain算法和图神经网络(GNN)的社区检测新方法，无需先验知识即可发现社区，并能动态调整社区数量。


<details>
  <summary>Details</summary>
Motivation: 现有社区检测方法大多需要预先知道社区数量，这在实际应用中往往不可行。本文旨在开发无需先验知识的社区检测方法。

Method: 使用GNN生成的节点嵌入来增强Louvain算法，捕捉更丰富的结构和特征信息，并引入合并算法来精炼结果，减少检测到的社区数量。

Result: 在真实数据集上的评估证实了方法的改进效果，能够动态调整社区数量，相比基准方法提高了检测准确率。

Conclusion: 这是首个使用GNN改进Louvain算法进行社区检测的工作，实验证明该方法在无需先验知识的情况下能有效提升社区检测性能。

Abstract: This paper proposes a novel community detection method that integrates the
Louvain algorithm with Graph Neural Networks (GNNs), enabling the discovery of
communities without prior knowledge. Compared to most existing solutions, the
proposed method does not require prior knowledge of the number of communities.
It enhances the Louvain algorithm using node embeddings generated by a GNN to
capture richer structural and feature information. Furthermore, it introduces a
merging algorithm to refine the results of the enhanced Louvain algorithm,
reducing the number of detected communities. To the best of our knowledge, this
work is the first one that improves the Louvain algorithm using GNNs for
community detection. The improvement of the proposed method was empirically
confirmed through an evaluation on real-world datasets. The results demonstrate
its ability to dynamically adjust the number of detected communities and
increase the detection accuracy in comparison with the benchmark solutions.

</details>


### [18] [Node Classification via Simplicial Interaction with Augmented Maximal Clique Selection](https://arxiv.org/abs/2509.23568)
*Eunho Koo,Tongseok Lim*

Main category: cs.SI

TL;DR: 提出增强最大团策略，通过选择性包含非最大团来平衡节点表示，解决高阶网络学习中的计算效率和训练数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统使用所有团的方法计算效率低，而仅用最大团会导致节点在多个团中出现造成训练数据不平衡，需要更高效平衡的高阶网络学习方法。

Method: 增强最大团策略：在最大团基础上选择性包含一些非最大团，减少特定节点的过度表示，促进网络更平衡的学习。

Result: 在合成网络和真实引文数据集上的比较分析表明，该方法优于基于成对交互、所有团或仅最大团的方法。与GNN结合后提高了预测准确性。

Conclusion: 增强最大团策略为高阶网络学习提供了计算高效且有效的解决方案，建立了最大团方法与GNN之间的联系。

Abstract: Considering higher-order interactions allows for a more comprehensive
understanding of network structures beyond simple pairwise connections. While
leveraging all cliques in a network to handle higher-order interactions is
intuitive, it often leads to computational inefficiencies due to overlapping
information between higher-order and lower-order cliques. To address this
issue, we propose an augmented maximal clique strategy. Although using only
maximal cliques can reduce unnecessary overlap and provide a concise
representation of the network, certain nodes may still appear in multiple
maximal cliques, resulting in imbalanced training data. Therefore, our
augmented maximal clique approach selectively includes some non-maximal cliques
to mitigate the overrepresentation of specific nodes and promote more balanced
learning across the network. Comparative analyses on synthetic networks and
real-world citation datasets demonstrate that our method outperforms approaches
based on pairwise interactions, all cliques, or only maximal cliques. Finally,
by integrating this strategy into GNN-based semi-supervised learning, we
establish a link between maximal clique-based methods and GNNs, showing that
incorporating higher-order structures improves predictive accuracy. As a
result, the augmented maximal clique strategy offers a computationally
efficient and effective solution for higher-order network learning.

</details>


### [19] [MASH: A Multiplatform and Multimodal Annotated Dataset for Societal Impact of Hurricane](https://arxiv.org/abs/2509.23627)
*Ruichen Yao,Aslanbek Murzakhmetov,Raaghav Pillai,Aliya Maussymbayeva,Zelin Li,Yifan Liu,Yaokun Liu,Lanyu Shang,Yang Zhang,Na Wei,Ximing Cai,Dong Wang*

Main category: cs.SI

TL;DR: 提出了一个多平台、多模态的飓风社会影响数据集MASH，包含98,662个来自Reddit、X、TikTok和YouTube的相关社交媒体帖子，采用多模态标注方法。


<details>
  <summary>Details</summary>
Motivation: 现有飓风数据集通常只关注过时的飓风事件，且局限于单一社交媒体平台，无法捕捉当今多样化社交媒体环境中的广泛社会影响。此外，现有数据集分别标注帖子的视觉和文本内容，未能考虑社交媒体帖子的多模态特性。

Method: 构建了包含98,662个相关社交媒体帖子的多平台数据集，涵盖Reddit、X、TikTok和YouTube。所有相关帖子都采用多模态标注方法，同时考虑文本和视觉内容，在三个维度上进行标注：人道主义类别、偏见类别和信息完整性类别。

Result: MASH是首个大规模、多平台、多模态且多维度标注的飓风数据集。

Conclusion: MASH数据集可以促进飓风对社会影响的研究，如灾害严重程度分类、公众情绪分析、灾害政策制定和偏见识别。

Abstract: Natural disasters cause multidimensional threats to human societies, with
hurricanes exemplifying one of the most disruptive events that not only caused
severe physical damage but also sparked widespread discussion on social media
platforms. Existing datasets for studying societal impacts of hurricanes often
focus on outdated hurricanes and are limited to a single social media platform,
failing to capture the broader societal impact in today's diverse social media
environment. Moreover, existing datasets annotate visual and textual content of
the post separately, failing to account for the multimodal nature of social
media posts. To address these gaps, we present a multiplatform and Multimodal
Annotated Dataset for Societal Impact of Hurricane (MASH) that includes 98,662
relevant social media data posts from Reddit, X, TikTok, and YouTube. In
addition, all relevant social media data posts are annotated in a multimodal
approach that considers both textual and visual content on three dimensions:
humanitarian classes, bias classes, and information integrity classes. To our
best knowledge, MASH is the first large-scale, multi-platform, multimodal, and
multi-dimensionally annotated hurricane dataset. We envision that MASH can
contribute to the study of hurricanes' impact on society, such as disaster
severity classification, public sentiment analysis, disaster policy making, and
bias identification.

</details>


### [20] [Robustness of One-to-Many Interdependent Higher-order Networks Against Cascading Failures](https://arxiv.org/abs/2509.23716)
*Cheng Qian,Dandan Zhao,Bo Zhang,Ming Zhong,Jianmin Han,Shenghong Li,Hao Peng,Wei Wang*

Main category: cs.SI

TL;DR: 本文研究了具有一对多依赖关系的高阶网络在随机攻击下的鲁棒性，提出了四种层间依赖条件，建立了统一的理论框架来分析层内高阶结构和层间耦合参数对网络可靠性的影响。


<details>
  <summary>Details</summary>
Motivation: 现实世界中网络的稳定运行通常依赖于其他网络的相互支持，现有研究往往忽略层内高阶结构，缺乏统一的层间依赖理论框架，且通常假设理想的一对一依赖关系，无法反映真实系统的复杂性。

Method: 使用渗流理论建立统一理论框架，分析四种不同的层间依赖条件（节点存活需要至少一条或多条依赖边），研究随机攻击引发的级联失效后网络鲁棒性，并扩展到部分依赖超图。

Result: 理论分析揭示了层内高阶交互结构和层间耦合参数如何影响网络可靠性和系统韧性，并在合成和真实数据依赖超图上验证了理论分析。

Conclusion: 研究为增强网络可靠性的优化设计提供了见解，建立了综合考虑层内高阶结构和一对多层间依赖的统一理论框架。

Abstract: In the real world, the stable operation of a network is usually inseparable
from the mutual support of other networks. In such an interdependent network, a
node in one layer may depend on multiple nodes in another layer, forming a
complex one-to-many dependency relationship. Meanwhile, there may also be
higher-order interactions between multiple nodes within a layer, which
increases the connectivity within the layer. However, existing research on
one-to-many interdependence often neglects intra-layer higher-order structures
and lacks a unified theoretical framework for inter-layer dependencies.
Moreover, current research on interdependent higher-order networks typically
assumes idealized one-to-one inter-layer dependencies, which does not reflect
the complexity of real-world systems. These limitations hinder a comprehensive
understanding of how such networks withstand failures. Therefore, this paper
investigates the robustness of one-to-many interdependent higher-order networks
under random attacks. Depending on whether node survival requires at least one
dependency edge or multiple dependency edges, we propose four inter-layer
interdependency conditions and analyze the network's robustness after cascading
failures induced by random attacks. Using percolation theory, we establish a
unified theoretical framework that reveals how higher-order interaction
structures within intra-layers and inter-layer coupling parameters affect
network reliability and system resilience. Additionally, we extend our study to
partially interdependent hypergraphs. We validate our theoretical analysis on
both synthetic and real-data-based interdependent hypergraphs, offering
insights into the optimization of network design for enhanced reliability.

</details>


### [21] [Community detection robustness of graph neural networks](https://arxiv.org/abs/2509.24662)
*Jaidev Goel,Pablo Moriano,Ramakrishnan Kannan,Yulia R. Gel*

Main category: cs.SI

TL;DR: 该论文系统评估了6种GNN架构在社区检测任务中的鲁棒性，发现监督方法准确率更高但无监督方法更抗攻击，节点属性扰动和边删除对性能影响最大。


<details>
  <summary>Details</summary>
Motivation: 研究GNN在社区检测任务中对不同扰动和攻击的鲁棒性，揭示其敏感性背后的潜在机制。

Method: 对GCN、GAT、Graph-SAGE、DiffPool、MinCUT和DMoN六种GNN架构进行系统计算评估，涵盖节点属性操作、边拓扑扭曲和对抗攻击三类扰动，使用元素中心相似度作为评估指标。

Result: 监督GNN基线准确率更高，但无监督方法（特别是DMoN）在针对性扰动下更具韧性；社区强度显著影响鲁棒性；节点属性扰动和边删除导致最大性能下降。

Conclusion: 揭示了GNN社区检测中准确性与鲁棒性的权衡，为选择抗噪声和对抗攻击的架构提供了新见解。

Abstract: Graph neural networks (GNNs) are increasingly widely used for community
detection in attributed networks. They combine structural topology with node
attributes through message passing and pooling. However, their robustness or
lack of thereof with respect to different perturbations and targeted attacks in
conjunction with community detection tasks is not well understood. To shed
light into latent mechanisms behind GNN sensitivity on community detection
tasks, we conduct a systematic computational evaluation of six widely adopted
GNN architectures: GCN, GAT, Graph-SAGE, DiffPool, MinCUT, and DMoN. The
analysis covers three perturbation categories: node attribute manipulations,
edge topology distortions, and adversarial attacks. We use element-centric
similarity as the evaluation metric on synthetic benchmarks and real-world
citation networks. Our findings indicate that supervised GNNs tend to achieve
higher baseline accuracy, while unsupervised methods, particularly DMoN,
maintain stronger resilience under targeted and adversarial perturbations.
Furthermore, robustness appears to be strongly influenced by community
strength, with well-defined communities reducing performance loss. Across all
models, node attribute perturbations associated with targeted edge deletions
and shift in attribute distributions tend to cause the largest degradation in
community recovery. These findings highlight important trade-offs between
accuracy and robustness in GNN-based community detection and offer new insights
into selecting architectures resilient to noise and adversarial attacks.

</details>


### [22] [Data-Driven Discrete Geofence Design Using Binary Quadratic Programming](https://arxiv.org/abs/2509.24679)
*Keisuke Otaki,Akihisa Okada,Tadayoshi Matsumori,Hiroaki Yoshida*

Main category: cs.SI

TL;DR: 提出了一种从人类移动数据中提取任意形状地理围栏的方法，通过将现有圆形地理围栏优化问题转化为0-1整数规划问题，并使用二次无约束二进制优化进行高效近似求解。


<details>
  <summary>Details</summary>
Motivation: 传统圆形地理围栏在精细分辨率下缺乏灵活性，无法与行政边界和道路段对齐，需要开发能够提取任意形状地理围栏的方法。

Method: 将地理围栏设计问题建模为0-1整数规划问题，然后转化为二次无约束二进制优化问题，利用量子退火等专用求解器进行高效近似求解。

Result: 新建模方法能够实现灵活的地理围栏设计，解决了圆形地理围栏在精细区域中的重叠和对齐问题。

Conclusion: 通过0-1整数规划和二次优化方法，能够从人类移动数据中有效提取任意形状的地理围栏，提高了地理围栏设计的灵活性和实用性。

Abstract: Geofences have attracted significant attention in the design of spatial and
virtual regions for managing and engaging spatiotemporal events. By using
geofences to monitor human activity across their boundaries, content providers
can create spatially triggered events that include notifications about points
of interest within a geofence by pushing spatial information to the devices of
users. Traditionally, geofences were hand-crafted by providers. In addition to
the hand-crafted approach, recent advances in collecting human mobility data
through mobile devices can accelerate the automatic and data-driven design of
geofences, also known as the geofence design problem. Previous approaches
assume circular shapes; thus, their flexibility is insufficient, and they can
only handle geofence-based applications for large areas with coarse
resolutions. A challenge with using circular geofences in urban and
high-resolution areas is that they often overlap and fail to align with
political district boundaries and road segments, such as one-way streets and
median barriers. In this study, we address the problem of extracting arbitrary
shapes as geofences from human mobility data to mitigate this problem. In our
formulation, we cast the existing optimization problems for circular geofences
to 0-1 integer programming problems to represent arbitrary shapes. Although 0-1
integer programming problems are computationally hard, formulating them as
quadratic (unconstrained) binary optimization problems enables efficient
approximation of optimal solutions, because this allows the use of specialized
quadratic solvers, such as the quantum annealing, and other state-of-the-art
algorithms. We then develop and compare different formulation methods to
extract discrete geofences. We confirmed that our new modeling approach enables
flexible geofence design.

</details>


### [23] [Research in Medicine: Journal ranking vs. Interdisciplinarity](https://arxiv.org/abs/2509.24994)
*Anbang Du,Michael Head,Markus Brede*

Main category: cs.SI

TL;DR: 高影响力医学期刊发表的研究比低影响力期刊更少跨学科性，癌症研究是医学跨学科性的主要驱动力，期刊和政策制定者应鼓励跨学科研究以最大化患者获益。


<details>
  <summary>Details</summary>
Motivation: 研究医学领域的跨学科知识结构，比较高影响力和低影响力期刊在跨学科性方面的差异，探索跨学科研究对医学创新的重要性。

Method: 将PubMed医学研究文章构建为医学概念的相关性网络，比较高低影响力期刊的跨学科性，使用符号差异网络分析网络偏差的聚类模式。

Result: 高影响力医学期刊的研究比低影响力期刊更少跨学科；癌症研究是医学跨学科性的主要驱动力；偏差网络中的强链接差异倾向于相邻；偏差主题集群随时间变化，而原始网络主题集群保持稳定。

Conclusion: 期刊和政策制定者应在现有基础设施中鼓励跨学科研究，以最大化患者从跨学科研究中获得的潜在益处。

Abstract: Interdisciplinary research is critical for innovation and addressing complex
societal issues. We characterise the interdisciplinary knowledge structure of
PubMed research articles in medicine as correlation networks of medical
concepts and compare the interdisciplinarity of articles between high-ranking
(impactful) and less high-ranking (less impactful) medical journals. We found
that impactful medical journals tend to publish research that are less
interdisciplinary than less impactful journals. Observing that they bridge
distant knowledge clusters in the networks, we find that cancer-related
research can be seen as one of the main drivers of interdisciplinarity in
medical science. Using signed difference networks, we also investigate the
clustering of deviations between high and low impact journal correlation
networks. We generally find a mild tendency for strong link differences to be
adjacent. Furthermore, we find topic clusters of deviations that shift over
time. In contrast, topic clusters in the original networks are static over time
and can be seen as the core knowledge structure in medicine. Overall, journals
and policymakers should encourage initiatives to accommodate
interdisciplinarity within the existing infrastructures to maximise the
potential patient benefits from IDR.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [Mobile Robot Localization via Indoor Positioning System and Odometry Fusion](https://arxiv.org/abs/2509.22693)
*Muhammad Hafil Nugraha,Fauzi Abdul,Lastiko Bramantyo,Estiko Rijanto,Roni Permana Saputra,Oka Mahendra*

Main category: cs.RO

TL;DR: 本文提出了一种通过传感器融合技术将超声波室内定位系统与轮式里程计数据相结合的方法，用于提高移动机器人在室内环境中的定位精度。


<details>
  <summary>Details</summary>
Motivation: 在室内环境中，准确的定位对于移动机器人的有效运行至关重要。单独使用超声波室内定位系统或轮式里程计都存在各自的局限性，需要通过融合技术来弥补各自的不足。

Method: 采用扩展卡尔曼滤波器（EKF）融合方法，将IPS传感器数据和机器人轮式里程计数据进行融合，提供鲁棒可靠的定位解决方案。

Result: 在受控室内环境中的大量实验表明，基于融合的定位系统相比独立系统显著提高了准确性和精度，EKF方法有效减少了轮子打滑和传感器噪声相关的误差。

Conclusion: 传感器融合方法能够显著提升移动机器人在室内环境中的定位性能，扩展卡尔曼滤波器是有效的融合技术。

Abstract: Accurate localization is crucial for effectively operating mobile robots in
indoor environments. This paper presents a comprehensive approach to mobile
robot localization by integrating an ultrasound-based indoor positioning system
(IPS) with wheel odometry data via sensor fusion techniques. The fusion
methodology leverages the strengths of both IPS and wheel odometry,
compensating for the individual limitations of each method. The Extended Kalman
Filter (EKF) fusion method combines the data from the IPS sensors and the
robot's wheel odometry, providing a robust and reliable localization solution.
Extensive experiments in a controlled indoor environment reveal that the
fusion-based localization system significantly enhances accuracy and precision
compared to standalone systems. The results demonstrate significant
improvements in trajectory tracking, with the EKF-based approach reducing
errors associated with wheel slippage and sensor noise.

</details>


### [25] [Nonlinear Model Predictive Control with Single-Shooting Method for Autonomous Personal Mobility Vehicle](https://arxiv.org/abs/2509.22694)
*Rakha Rahmadani Pratama,Catur Hilman A. H. B. Baskoro,Joga Dharma Setiawan,Dyah Kusuma Dewi,P Paryanto,Mochammad Ariyanto,Roni Permana Saputra*

Main category: cs.RO

TL;DR: 提出了一种基于非线性模型预测控制(NMPC)的单人电动自主运输车(SEATER)控制方法，使用单射击方法通过非线性规划解决最优控制问题，在Gazebo仿真环境中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为自主个人移动车辆开发有效的控制方法，使其能够在满足约束条件（如避障）的同时到达目标位置。

Method: 采用非线性模型预测控制(NMPC)和单射击方法，通过非线性规划解决最优控制问题，使用里程计数据进行定位反馈，在ROS框架和Gazebo仿真环境中实现。

Result: 仿真结果表明，该方法成功控制车辆到达目标位置并满足约束条件，在无障碍和静态障碍环境中均表现良好。

Conclusion: NMPC结合单射击方法在自主车辆控制中展现出鲁棒性和实时有效性，适用于所评估的场景。

Abstract: This paper introduces a proposed control method for autonomous personal
mobility vehicles, specifically the Single-passenger Electric Autonomous
Transporter (SEATER), using Nonlinear Model Predictive Control (NMPC). The
proposed method leverages a single-shooting approach to solve the optimal
control problem (OCP) via non-linear programming (NLP). The proposed NMPC is
implemented to a non-holonomic vehicle with a differential drive system, using
odometry data as localization feedback to guide the vehicle towards its target
pose while achieving objectives and adhering to constraints, such as obstacle
avoidance. To evaluate the performance of the proposed method, a number of
simulations have been conducted in both obstacle-free and static obstacle
environments. The SEATER model and testing environment have been developed in
the Gazebo Simulation and the NMPC are implemented within the Robot Operating
System (ROS) framework. The simulation results demonstrate that the NMPC-based
approach successfully controls the vehicle to reach the desired target location
while satisfying the imposed constraints. Furthermore, this study highlights
the robustness and real-time effectiveness of NMPC with a single-shooting
approach for autonomous vehicle control in the evaluated scenarios.

</details>


### [26] [ReSeFlow: Rectifying SE(3)-Equivariant Policy Learning Flows](https://arxiv.org/abs/2509.22695)
*Zhitao Wang,Yanke Wang,Jiangtao Wen,Roberto Horowitz,Yuxing Han*

Main category: cs.RO

TL;DR: 提出ReSeFlow方法，将整流流技术应用于SE(3)-等变扩散模型，实现快速、测地线一致且计算效率高的机器人轨迹策略生成。


<details>
  <summary>Details</summary>
Motivation: 解决SE(3)-等变扩散模型在非结构化环境中推理时间成本高的问题，同时保持数据效率和鲁棒性。

Method: 将整流流技术整合到SE(3)-等变扩散模型中，使用SE(3)-等变网络保持旋转和平移对称性，实现测地线一致的策略生成。

Result: 仅需一步推理就能达到比基线方法更好的性能，在绘画任务上误差减少48.5%，旋转三角形任务上减少21.9%。

Conclusion: ReSeFlow结合了SE(3)等变性和整流流的优势，为生成式策略学习模型在现实世界应用提供了数据和推理效率。

Abstract: Robotic manipulation in unstructured environments requires the generation of
robust and long-horizon trajectory-level policy with conditions of perceptual
observations and benefits from the advantages of SE(3)-equivariant diffusion
models that are data-efficient. However, these models suffer from the inference
time costs. Inspired by the inference efficiency of rectified flows, we
introduce the rectification to the SE(3)-diffusion models and propose the
ReSeFlow, i.e., Rectifying SE(3)-Equivariant Policy Learning Flows, providing
fast, geodesic-consistent, least-computational policy generation. Crucially,
both components employ SE(3)-equivariant networks to preserve rotational and
translational symmetry, enabling robust generalization under rigid-body
motions. With the verification on the simulated benchmarks, we find that the
proposed ReSeFlow with only one inference step can achieve better performance
with lower geodesic distance than the baseline methods, achieving up to a 48.5%
error reduction on the painting task and a 21.9% reduction on the rotating
triangle task compared to the baseline's 100-step inference. This method takes
advantages of both SE(3) equivariance and rectified flow and puts it forward
for the real-world application of generative policy learning models with the
data and inference efficiency.

</details>


### [27] [Advancing Audio-Visual Navigation Through Multi-Agent Collaboration in 3D Environments](https://arxiv.org/abs/2509.22698)
*Hailong Zhang,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.RO

TL;DR: MASTAVN是一个多智能体可扩展的音频-视觉导航框架，使两个智能体能够在共享3D环境中协作定位和导航到音频目标，显著提高了任务完成效率和导航成功率。


<details>
  <summary>Details</summary>
Motivation: 现有音频-视觉导航研究主要关注单智能体系统，但在动态3D环境中，特别是在紧急响应等时间敏感应用中，快速的多智能体协调至关重要。

Method: 通过整合跨智能体通信协议和联合音频-视觉融合机制，MASTAVN增强了空间推理和时间同步能力。

Result: 在真实感3D模拟器中的评估显示，与单智能体和非协作基线相比，MASTAVN显著减少了任务完成时间并提高了导航成功率。

Conclusion: 研究验证了MASTAVN在时间敏感紧急场景中的有效性，并为推进复杂3D环境中可扩展多智能体具身智能建立了范例。

Abstract: Intelligent agents often require collaborative strategies to achieve complex
tasks beyond individual capabilities in real-world scenarios. While existing
audio-visual navigation (AVN) research mainly focuses on single-agent systems,
their limitations emerge in dynamic 3D environments where rapid multi-agent
coordination is critical, especially for time-sensitive applications like
emergency response. This paper introduces MASTAVN (Multi-Agent Scalable
Transformer Audio-Visual Navigation), a scalable framework enabling two agents
to collaboratively localize and navigate toward an audio target in shared 3D
environments. By integrating cross-agent communication protocols and joint
audio-visual fusion mechanisms, MASTAVN enhances spatial reasoning and temporal
synchronization. Through rigorous evaluation in photorealistic 3D simulators
(Replica and Matterport3D), MASTAVN achieves significant reductions in task
completion time and notable improvements in navigation success rates compared
to single-agent and non-collaborative baselines. This highlights the essential
role of spatiotemporal coordination in multi-agent systems. Our findings
validate MASTAVN's effectiveness in time-sensitive emergency scenarios and
establish a paradigm for advancing scalable multi-agent embodied intelligence
in complex 3D environments.

</details>


### [28] [Large Language Models for 3D IC Space Planning](https://arxiv.org/abs/2509.22716)
*Hung-Ying Chu,Guan-Wei Chen,Shao-Yu Wei,Yu-Cheng Lin*

Main category: cs.RO

TL;DR: 该研究探索使用大语言模型进行3D IC空间规划，通过后序切片树表示法保证合法布局并最小化死区，在合成和MCNC基准测试中展现出良好的运行效率、合法性和死区减少效果。


<details>
  <summary>Details</summary>
Motivation: 随着3D集成电路设计复杂度增加，需要有效的空间规划方法来减少死区并确保布局质量，传统EDA方法面临挑战。

Method: 使用开源LLM在大规模合成数据集上进行微调，采用后序切片树表示法来保证空间规划的合法性，并在MCNC衍生的3D基准上进行评估。

Result: 实验结果显示该方法在运行效率、合法性和死区减少之间达到良好平衡，在实用运行预算下获得大量零死区布局，并能泛化到MCNC案例。

Conclusion: 基于LLM的空间规划可以作为传统EDA方法的数据驱动补充，为可扩展的3D布局生成提供新思路，并具有跨领域应用潜力。

Abstract: Three-dimensional integrated circuits (3D ICs) have emerged as a promising
solution to the scaling limits of two-dimensional designs, offering higher
integration density, shorter interconnects, and improved performance. As design
complexity increases, effective space planning becomes essential to reduce dead
space and ensure layout quality. This study investigates the use of large
language models (LLMs) for 3D IC space planning through a post-order slicing
tree representation, which guarantees legal space plans while aiming to
minimize dead space. Open-source LLMs were fine-tuned on large-scale synthetic
datasets and further evaluated on MCNC-derived 3D benchmarks. Experimental
results indicate that the proposed framework achieves a favorable balance
between runtime efficiency, legality, and dead-space reduction, with
zero-dead-space layouts obtained in a significant portion of test cases under
practical runtime budgets. Beyond synthetic benchmarks, the method generalizes
to MCNC cases such as ami33 and ami49, though larger and irregular instances
remain challenging. The approach also shows potential for cross-domain
applications, including logistics and 3D object placement, where spatial
efficiency is critical. Overall, the results suggest that LLM-based space
planning can serve as a data-driven complement to traditional electronic design
automation (EDA) methods, providing new insights for scalable 3D layout
generation.

</details>


### [29] [Self-driving cars: Are we there yet?](https://arxiv.org/abs/2509.22754)
*Merve Atasever,Zhuochen Liu,Qingpei Li,Akshay Hitendra Shah,Hans Walker,Jyotirmoy V. Deshmukh,Rahul Jain*

Main category: cs.RO

TL;DR: 本文对CARLA、nuPlan和Waymo三大自动驾驶规划算法排行榜中的方法进行了综合比较分析，使用CARLA v2.0作为统一评估平台，识别当前方法的优缺点和发展趋势。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要标准化的评估基准来比较不同规划算法的性能，CARLA、nuPlan和Waymo已成为该领域的主要基准，但缺乏统一的比较分析。

Method: 采用CARLA leaderboard v2.0作为统一评估平台，对三个排行榜中的运动规划方法进行修改以确保兼容性，并进行综合比较分析。

Result: 通过比较分析揭示了当前方法的优缺点，识别了主流趋势和共同挑战。

Conclusion: 研究为运动规划研究提供了有价值的见解，并指出了未来发展的潜在方向。

Abstract: Autonomous driving remains a highly active research domain that seeks to
enable vehicles to perceive dynamic environments, predict the future
trajectories of traffic agents such as vehicles, pedestrians, and cyclists and
plan safe and efficient future motions. To advance the field, several
competitive platforms and benchmarks have been established to provide
standardized datasets and evaluation protocols. Among these, leaderboards by
the CARLA organization and nuPlan and the Waymo Open Dataset have become
leading benchmarks for assessing motion planning algorithms. Each offers a
unique dataset and challenging planning problems spanning a wide range of
driving scenarios and conditions. In this study, we present a comprehensive
comparative analysis of the motion planning methods featured on these three
leaderboards. To ensure a fair and unified evaluation, we adopt CARLA
leaderboard v2.0 as our common evaluation platform and modify the selected
models for compatibility. By highlighting the strengths and weaknesses of
current approaches, we identify prevailing trends, common challenges, and
suggest potential directions for advancing motion planning research.

</details>


### [30] [Persistent Autoregressive Mapping with Traffic Rules for Autonomous Driving](https://arxiv.org/abs/2509.22756)
*Shiyi Liang,Xinyuan Chang,Changjie Wu,Huiyuan Yan,Yifan Bai,Xinran Liu,Hang Zhang,Yujian Yuan,Shuang Zeng,Mu Xu,Xing Wei*

Main category: cs.RO

TL;DR: PAMR是一个新颖的自动驾驶框架，通过自回归方式联合构建车道向量和交通规则，解决了现有方法无法在长时间驾驶序列中保持交通规则持久有效性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只关注几何元素，要么将交通规则视为临时分类，无法在交通标志不可见时保持规则的持久有效性，这影响了自动驾驶的安全性。

Method: 提出PAMR框架，包含两个关键机制：Map-Rule Co-Construction（在时间片段中处理驾驶场景）和Map-Rule Cache（在片段间保持规则一致性），并开发了改进的MapDRv2数据集用于评估。

Result: 大量实验表明，PAMR在联合向量-规则映射任务中表现出色，能够在长时间驾驶序列中保持规则的持久有效性。

Conclusion: PAMR框架成功解决了自动驾驶中地图构建和交通规则持久感知的关键挑战，为安全自动驾驶提供了重要技术支撑。

Abstract: Safe autonomous driving requires both accurate HD map construction and
persistent awareness of traffic rules, even when their associated signs are no
longer visible. However, existing methods either focus solely on geometric
elements or treat rules as temporary classifications, failing to capture their
persistent effectiveness across extended driving sequences. In this paper, we
present PAMR (Persistent Autoregressive Mapping with Traffic Rules), a novel
framework that performs autoregressive co-construction of lane vectors and
traffic rules from visual observations. Our approach introduces two key
mechanisms: Map-Rule Co-Construction for processing driving scenes in temporal
segments, and Map-Rule Cache for maintaining rule consistency across these
segments. To properly evaluate continuous and consistent map generation, we
develop MapDRv2, featuring improved lane geometry annotations. Extensive
experiments demonstrate that PAMR achieves superior performance in joint
vector-rule mapping tasks, while maintaining persistent rule effectiveness
throughout extended driving sequences.

</details>


### [31] [Towards Developing Standards and Guidelines for Robot Grasping and Manipulation Pipelines in the COMPARE Ecosystem](https://arxiv.org/abs/2509.22801)
*Huajing Zhao,Brian Flynn,Adam Norton,Holly Yanco*

Main category: cs.RO

TL;DR: COMPARE生态系统通过制定组件级和流水线级标准指南，开发开源产品库，研究现有模块化流水线，并构建新的模块化流水线，以提升机器人操作开源产品的兼容性和基准测试能力。


<details>
  <summary>Details</summary>
Motivation: 改善机器人操作领域开源产品的兼容性和基准测试能力，通过标准化模块化实践来促进不同组件之间的互操作性。

Method: 1) 构建开源产品库识别流水线中各组件的共同特征；2) 研究现有模块化流水线获取最佳实践；3) 开发符合标准的新模块化流水线。

Result: 正在进行中的工作，包括标准指南的制定、开源产品库的建设以及模块化流水线的研究和开发。

Conclusion: COMPARE生态系统通过标准化和模块化方法，为机器人操作领域提供了改善产品兼容性和基准测试的框架，目前工作仍在进展中。

Abstract: The COMPARE Ecosystem aims to improve the compatibility and benchmarking of
open-source products for robot manipulation through a series of activities. One
such activity is the development of standards and guidelines to specify
modularization practices at the component-level for individual modules (e.g.,
perception, grasp planning, motion planning) and integrations of components
that form robot manipulation capabilities at the pipeline-level. This paper
briefly reviews our work-in-progress to date to (1) build repositories of
open-source products to identify common characteristics of each component in
the pipeline, (2) investigate existing modular pipelines to glean best
practices, and (3) develop new modular pipelines that advance prior work while
abiding by the proposed standards and guidelines.

</details>


### [32] [Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots](https://arxiv.org/abs/2509.22815)
*Ruturaj Sambhus,Muneeb Ahmad,Basit Muhammad Imran,Sujith Vijayan,Dylan P. Losey,Kaveh Akbari Hamed*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人共享自主权的自适应非线性模型预测控制框架，通过在线学习人类意图参数和安全约束，实现安全的人机协作避障。


<details>
  <summary>Details</summary>
Motivation: 传统共享控制方法使用固定混合策略，无法捕捉腿式机器人的动态特性，可能危及安全性。需要开发能够适应人类行为不确定性的安全控制框架。

Method: 采用分层控制架构：高层CBF-ANMPC（10Hz）生成混合速度参考，中层动态感知NMPC（60Hz）跟踪参考轨迹，低层非线性全身控制器（500Hz）施加完整动态约束。使用Boltzmann模型在线学习人类意图参数。

Result: 在Unitree Go2四足机器人上的数值和硬件实验验证了框架的有效性，实现了实时避障、在线学习人类意图参数和安全的人机协作。

Conclusion: 该框架能够有效处理人类行为不确定性，确保共享自主权系统中的安全性，为腿式机器人的安全人机协作提供了可行解决方案。

Abstract: Ensuring safe and effective collaboration between humans and autonomous
legged robots is a fundamental challenge in shared autonomy, particularly for
teleoperated systems navigating cluttered environments. Conventional
shared-control approaches often rely on fixed blending strategies that fail to
capture the dynamics of legged locomotion and may compromise safety. This paper
presents a teleoperator-aware, safety-critical, adaptive nonlinear model
predictive control (ANMPC) framework for shared autonomy of quadrupedal robots
in obstacle-avoidance tasks. The framework employs a fixed arbitration weight
between human and robot actions but enhances this scheme by modeling the human
input with a noisily rational Boltzmann model, whose parameters are adapted
online using a projected gradient descent (PGD) law from observed joystick
commands. Safety is enforced through control barrier function (CBF) constraints
integrated into a computationally efficient NMPC, ensuring forward invariance
of safe sets despite uncertainty in human behavior. The control architecture is
hierarchical: a high-level CBF-based ANMPC (10 Hz) generates blended
human-robot velocity references, a mid-level dynamics-aware NMPC (60 Hz)
enforces reduced-order single rigid body (SRB) dynamics to track these
references, and a low-level nonlinear whole-body controller (500 Hz) imposes
the full-order dynamics via quadratic programming to track the mid-level
trajectories. Extensive numerical and hardware experiments, together with a
user study, on a Unitree Go2 quadrupedal robot validate the framework,
demonstrating real-time obstacle avoidance, online learning of human intent
parameters, and safe teleoperator collaboration.

</details>


### [33] [Parameter Identification of a Differentiable Human Arm Musculoskeletal Model without Deep Muscle EMG Reconstruction](https://arxiv.org/abs/2509.22825)
*Philip Sanderink,Yingfan Zhou,Shuzhen Luo,Cheng Fang*

Main category: cs.RO

TL;DR: 提出了一种无需重建深层肌肉EMG信号即可同时识别人体手臂骨骼肌肉模型中骨骼和表层肌肉参数的方法，通过可微分优化框架实现参数识别。


<details>
  <summary>Details</summary>
Motivation: 准确的个性化肌肉骨骼模型参数识别对于开发安全可靠的协作机器人系统至关重要。现有的EMG参数识别方法受限于深层肌肉EMG难以无创测量的问题，而现有重建方法因对深层肌肉行为的假设而可靠性有限。

Method: 使用深层肌肉力的最小二乘解来计算相对于模型参数的损失梯度，在可微分优化框架中识别参数，无需重建深层肌肉EMG信号。

Result: 广泛的对比仿真结果表明，该方法能够达到与所有肌肉EMG信号可用时类似方法的可比估计精度。

Conclusion: 该方法能够在无需深层肌肉EMG信号的情况下有效识别肌肉骨骼模型参数，为个性化建模提供了新的解决方案。

Abstract: Accurate parameter identification of a subject-specific human musculoskeletal
model is crucial to the development of safe and reliable physically
collaborative robotic systems, for instance, assistive exoskeletons.
Electromyography (EMG)-based parameter identification methods have demonstrated
promising performance for personalized musculoskeletal modeling, whereas their
applicability is limited by the difficulty of measuring deep muscle EMGs
invasively. Although several strategies have been proposed to reconstruct deep
muscle EMGs or activations for parameter identification, their reliability and
robustness are limited by assumptions about the deep muscle behavior. In this
work, we proposed an approach to simultaneously identify the bone and
superficial muscle parameters of a human arm musculoskeletal model without
reconstructing the deep muscle EMGs. This is achieved by only using the
least-squares solution of the deep muscle forces to calculate a loss gradient
with respect to the model parameters for identifying them in a framework of
differentiable optimization. The results of extensive comparative simulations
manifested that our proposed method can achieve comparable estimation accuracy
compared to a similar method, but with all the muscle EMGs available.

</details>


### [34] [Dynamic Buffers: Cost-Efficient Planning for Tabletop Rearrangement with Stacking](https://arxiv.org/abs/2509.22828)
*Arman Barghi,Hamed Hosseini,Seraj Ghasemi,Mehdi Tale Masouleh,Ahmad Kalhor*

Main category: cs.RO

TL;DR: 提出动态缓冲器作为新的规划原语，通过形成临时可移动的堆叠来解决杂乱桌面环境中物体重排的低效问题


<details>
  <summary>Details</summary>
Motivation: 传统规划器在密集场景中效率低下，使用固定缓冲区会导致高成本计划，静态堆叠限制了效率提升

Method: 引入动态缓冲器概念，允许机器人形成临时可移动的堆叠，这些堆叠可以作为整体进行运输

Result: 与最先进的重排规划器相比，在密集场景中减少机械臂移动成本11.89%，在大型低密度场景中减少5.69%

Conclusion: 动态缓冲是成本高效和鲁棒重排规划的关键原语

Abstract: Rearranging objects in cluttered tabletop environments remains a
long-standing challenge in robotics. Classical planners often generate
inefficient, high-cost plans by shuffling objects individually and using fixed
buffers--temporary spaces such as empty table regions or static stacks--to
resolve conflicts. When only free table locations are used as buffers, dense
scenes become inefficient, since placing an object can restrict others from
reaching their goals and complicate planning. Allowing stacking provides extra
buffer capacity, but conventional stacking is static: once an object supports
another, the base cannot be moved, which limits efficiency. To overcome these
issues, a novel planning primitive called the Dynamic Buffer is introduced.
Inspired by human grouping strategies, it enables robots to form temporary,
movable stacks that can be transported as a unit. This improves both
feasibility and efficiency in dense layouts, and it also reduces travel in
large-scale settings where space is abundant. Compared with a state-of-the-art
rearrangement planner, the approach reduces manipulator travel cost by 11.89%
in dense scenarios with a stationary robot and by 5.69% in large, low-density
settings with a mobile manipulator. Practicality is validated through
experiments on a Delta parallel robot with a two-finger gripper. These findings
establish dynamic buffering as a key primitive for cost-efficient and robust
rearrangement planning.

</details>


### [35] [Empart: Interactive Convex Decomposition for Converting Meshes to Parts](https://arxiv.org/abs/2509.22847)
*Brandon Vu,Shameek Ganguly,Pushkar Joshi*

Main category: cs.RO

TL;DR: Empart是一个交互式工具，允许用户为网格的不同区域指定不同的简化容差，从而在保持关键区域精度的同时减少凸部分数量，显著提升机器人仿真性能。


<details>
  <summary>Details</summary>
Motivation: 现有网格简化方法在整个网格上应用统一的误差容差，导致在非关键区域过度细化或在关键区域精度不足，无法在精度和性能之间实现最优平衡。

Method: 利用现有凸分解算法作为子程序，采用新颖的并行化框架处理区域特定约束，提供带视觉反馈的用户友好界面，支持迭代式分解优化。

Result: 在固定误差阈值下，相比最先进方法(V-HACD)显著减少了凸部分数量，在机器人抓取任务中将仿真时间减少了69%。

Conclusion: 交互式、区域特定的简化方法对于高性能机器人应用具有重要价值，能够在保持关键区域精度的同时大幅提升仿真效率。

Abstract: Simplifying complex 3D meshes is a crucial step in robotics applications to
enable efficient motion planning and physics simulation. Common methods, such
as approximate convex decomposition, represent a mesh as a collection of simple
parts, which are computationally inexpensive to simulate. However, existing
approaches apply a uniform error tolerance across the entire mesh, which can
result in a sub-optimal trade-off between accuracy and performance. For
instance, a robot grasping an object needs high-fidelity geometry in the
vicinity of the contact surfaces but can tolerate a coarser simplification
elsewhere. A uniform tolerance can lead to excessive detail in non-critical
areas or insufficient detail where it's needed most.
  To address this limitation, we introduce Empart, an interactive tool that
allows users to specify different simplification tolerances for selected
regions of a mesh. Our method leverages existing convex decomposition
algorithms as a sub-routine but uses a novel, parallelized framework to handle
region-specific constraints efficiently. Empart provides a user-friendly
interface with visual feedback on approximation error and simulation
performance, enabling designers to iteratively refine their decomposition. We
demonstrate that our approach significantly reduces the number of convex parts
compared to a state-of-the-art method (V-HACD) at a fixed error threshold,
leading to substantial speedups in simulation performance. For a robotic
pick-and-place task, Empart-generated collision meshes reduced the overall
simulation time by 69% compared to a uniform decomposition, highlighting the
value of interactive, region-specific simplification for performant robotics
applications.

</details>


### [36] [Multi-Robot Allocation for Information Gathering in Non-Uniform Spatiotemporal Environments](https://arxiv.org/abs/2509.22883)
*Kaleb Ben Naveed,Haejoon Lee,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出一个两阶段多机器人场估计框架，通过变差图驱动规划学习区域特定空间长度尺度，并基于不确定性重新分配机器人，同时优化时间长度尺度采样


<details>
  <summary>Details</summary>
Motivation: 现有高斯过程方法通常假设全局长度尺度或仅周期性更新，有些允许空间变化但忽略时间变化，导致不确定性估计不准确

Method: 两阶段框架：阶段1使用变差图驱动规划学习区域特定空间长度尺度；阶段2基于当前不确定性重新分配机器人，并在优化时间长度尺度时更新采样

Result: 在多样化环境中评估了该方法，提供了空间长度尺度估计的收敛分析，以及量化与oracle分配序列差距的动态遗憾边界

Conclusion: 该框架能够有效处理非均匀时空环境中的场估计问题，通过自适应学习空间和时间长度尺度提高估计精度

Abstract: Autonomous robots are increasingly deployed to estimate spatiotemporal fields
(e.g., wind, temperature, gas concentration) that vary across space and time.
We consider environments divided into non-overlapping regions with distinct
spatial and temporal dynamics, termed non-uniform spatiotemporal environments.
Gaussian Processes (GPs) can be used to estimate these fields. The GP model
depends on a kernel that encodes how the field co-varies in space and time,
with its spatial and temporal lengthscales defining the correlation. Hence,
when these lengthscales are incorrect or do not correspond to the actual field,
the estimates of uncertainty can be highly inaccurate. Existing GP methods
often assume one global lengthscale or update only periodically; some allow
spatial variation but ignore temporal changes. To address these limitations, we
propose a two-phase framework for multi-robot field estimation. Phase 1 uses a
variogram-driven planner to learn region-specific spatial lengthscales. Phase 2
employs an allocation strategy that reassigns robots based on the current
uncertainty, and updates sampling as temporal lengthscales are refined. For
encoding uncertainty, we utilize clarity, an information metric from our
earlier work. We evaluate the proposed method across diverse environments and
provide convergence analysis for spatial lengthscale estimation, along with
dynamic regret bounds quantifying the gap to the oracle's allocation sequence.

</details>


### [37] [Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM](https://arxiv.org/abs/2509.22910)
*Yanwei Du,Jing-Chen Peng,Patricio A. Vela*

Main category: cs.RO

TL;DR: GW算法通过自适应权重融合视觉SLAM和航位推算，在视觉特征弱时增加DR权重，在视觉特征强时减少DR权重，实现连续准确的位姿估计。


<details>
  <summary>Details</summary>
Motivation: 视觉SLAM在纹理缺失或视觉退化环境中表现不佳，而机器人通常配备的航位推算传感器短期性能良好但长期不可靠，需要一种融合方案。

Method: 提出Good Weights算法框架，自适应调整视觉SLAM和航位推算的权重，并修改SLAM系统各模块以整合DR。

Result: 在收集的数据集和实际部署中验证了GW算法的有效性，提高了视觉SLAM的性能和鲁棒性。

Conclusion: GW算法为移动导航提供了实用解决方案，通过自适应融合机制增强了视觉SLAM在挑战性环境中的表现。

Abstract: Given that Visual SLAM relies on appearance cues for localization and scene
understanding, texture-less or visually degraded environments (e.g., plain
walls or low lighting) lead to poor pose estimation and track loss. However,
robots are typically equipped with sensors that provide some form of dead
reckoning odometry with reasonable short-time performance but unreliable
long-time performance. The Good Weights (GW) algorithm described here provides
a framework to adaptively integrate dead reckoning (DR) with passive visual
SLAM for continuous and accurate frame-level pose estimation. Importantly, it
describes how all modules in a comprehensive SLAM system must be modified to
incorporate DR into its design. Adaptive weighting increases DR influence when
visual tracking is unreliable and reduces when visual feature information is
strong, maintaining pose track without overreliance on DR. Good Weights yields
a practical solution for mobile navigation that improves visual SLAM
performance and robustness. Experiments on collected datasets and in real-world
deployment demonstrate the benefits of Good Weights.

</details>


### [38] [ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality](https://arxiv.org/abs/2509.22914)
*Rohan Walia,Yusheng Wang,Ralf Römer,Masahiro Nishio,Angela P. Schoellig,Jun Ota*

Main category: cs.RO

TL;DR: ARMimic是一个轻量级框架，仅使用消费级XR头显和固定工作场所摄像头，通过集成手部追踪、AR机器人叠加和实时深度感知，实现无机器人、可扩展的演示数据收集，显著减少演示时间并提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统机器人技能模仿学习方法（如动觉教学和遥操作）笨重、硬件密集且干扰工作流程。现有XR被动观察方法需要额外硬件、复杂校准或受限记录条件，限制了可扩展性和可用性。

Method: 集成第一人称手部追踪、AR机器人叠加和实时深度感知，确保碰撞感知、运动学可行的演示。统一模仿学习管道将人类和虚拟机器人轨迹视为可互换，实现跨不同体现和环境的策略泛化。

Result: 在两个操作任务（包括具有挑战性的长时域碗堆叠）上验证，ARMimic相比遥操作减少50%演示时间，相比最先进基线ACT提高11%任务成功率。

Conclusion: ARMimic实现了安全、无缝的野外数据收集，为多样化真实世界环境中的可扩展机器人学习提供了巨大潜力。

Abstract: Imitation learning is a powerful paradigm for robot skill acquisition, yet
conventional demonstration methods--such as kinesthetic teaching and
teleoperation--are cumbersome, hardware-heavy, and disruptive to workflows.
Recently, passive observation using extended reality (XR) headsets has shown
promise for egocentric demonstration collection, yet current approaches require
additional hardware, complex calibration, or constrained recording conditions
that limit scalability and usability. We present ARMimic, a novel framework
that overcomes these limitations with a lightweight and hardware-minimal setup
for scalable, robot-free data collection using only a consumer XR headset and a
stationary workplace camera. ARMimic integrates egocentric hand tracking,
augmented reality (AR) robot overlays, and real-time depth sensing to ensure
collision-aware, kinematically feasible demonstrations. A unified imitation
learning pipeline is at the core of our method, treating both human and virtual
robot trajectories as interchangeable, which enables policies that generalize
across different embodiments and environments. We validate ARMimic on two
manipulation tasks, including challenging long-horizon bowl stacking. In our
experiments, ARMimic reduces demonstration time by 50% compared to
teleoperation and improves task success by 11% over ACT, a state-of-the-art
baseline trained on teleoperated data. Our results demonstrate that ARMimic
enables safe, seamless, and in-the-wild data collection, offering great
potential for scalable robot learning in diverse real-world settings.

</details>


### [39] [DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent Autonomous Racing Overtakes](https://arxiv.org/abs/2509.22937)
*Trent Weiss,Amar Kulkarni,Madhur Behl*

Main category: cs.RO

TL;DR: 提出基于扩展差分贝叶斯滤波框架的轨迹合成方法，用于自主赛车超车机动，无需简化假设，在87%测试场景中成功超车


<details>
  <summary>Details</summary>
Motivation: 自主赛车超车机动在复杂赛道上具有挑战性，现有优化和图方法依赖过度简化的碰撞避免和动态约束假设

Method: 将无碰撞轨迹合成问题构建为复合贝塞尔曲线空间上的贝叶斯推断，采用无导数方法，无需车辆足迹球面近似、约束线性化或简化碰撞避免上界

Result: 闭环分析显示该方法在87%测试场景中成功超车，优于现有自主超车方法

Conclusion: 基于差分贝叶斯滤波的轨迹合成方法有效解决了自主赛车超车问题，无需传统简化假设

Abstract: A significant challenge in autonomous racing is to generate overtaking
maneuvers. Racing agents must execute these maneuvers on complex racetracks
with little room for error. Optimization techniques and graph-based methods
have been proposed, but these methods often rely on oversimplified assumptions
for collision-avoidance and dynamic constraints. In this work, we present an
approach to trajectory synthesis based on an extension of the Differential
Bayesian Filtering framework. Our approach for collision-free trajectory
synthesis frames the problem as one of Bayesian Inference over the space of
Composite Bezier Curves. Our method is derivative-free, does not require a
spherical approximation of the vehicle footprint, linearization of constraints,
or simplifying upper bounds on collision avoidance. We conduct a closed-loop
analysis of DBF-MA and find it successfully overtakes an opponent in 87% of
tested scenarios, outperforming existing methods in autonomous overtaking.

</details>


### [40] [Hierarchical Control Design for Space Robots with Application to In-Orbit Servicing Missions](https://arxiv.org/abs/2509.22955)
*Pietro Bruschi*

Main category: cs.RO

TL;DR: 提出用于自主捕获空间翻滚物体的分层控制框架，结合了考虑燃料晃动的多体动力学鲁棒控制和扩展逆运动学问题求解。


<details>
  <summary>Details</summary>
Motivation: 在轨服务和主动碎片清除需要先进的机器人能力来捕获和稳定非合作目标，现有研究很少考虑燃料晃动对空间机器人的影响。

Method: 开发包含燃料晃动动力学的仿真环境，提出分层控制器：内环基于Lyapunov的多体动力学鲁棒控制，外环解决扩展逆运动学问题。

Result: 仿真结果表明，与现有控制方案相比，该方法具有更好的鲁棒性和适应性。

Conclusion: 该分层控制框架能有效处理空间机器人捕获翻滚物体时的燃料晃动问题，提高系统性能。

Abstract: In-Orbit Servicing and Active Debris Removal require advanced robotic
capabilities for capturing and detumbling uncooperative targets. This work
presents a hierarchical control framework for autonomous robotic capture of
tumbling objects in space. A simulation environment is developed, incorporating
sloshing dynamics of the chaser, a rarely studied effect in space robotics. The
proposed controller combines an inner Lyapunov-based robust control loop for
multi-body dynamics with an outer loop addressing an extended inverse
kinematics problem. Simulation results show improved robustness and
adaptability compared to existing control schemes.

</details>


### [41] [Robot Learning from Any Images](https://arxiv.org/abs/2509.22970)
*Siheng Zhao,Jiageng Mao,Wei Chow,Zeyu Shangguan,Tianheng Shi,Rong Xue,Yuxi Zheng,Yijia Weng,Yang You,Daniel Seita,Leonidas Guibas,Sergey Zakharov,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: RoLA是一个框架，能够将任意真实世界图像转换为交互式、支持物理的机器人环境，无需额外硬件或数字资产，可在几分钟内从各种图像源生成大量视觉运动机器人演示数据。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要额外硬件或数字资产来创建机器人训练环境，限制了机器人数据生成的规模和可访问性。RoLA旨在通过单张图像直接生成物理环境，实现机器人数据生成的民主化。

Method: 结合单视角物理场景恢复新方法和高效视觉混合策略，从单张图像重建物理场景并生成逼真的数据收集环境。

Result: RoLA在多个应用中展示了其多功能性，包括可扩展的机器人数据生成与增强、从互联网图像学习机器人技能，以及单图像真实-模拟-真实系统，适用于机械臂和人形机器人。

Conclusion: RoLA框架能够高效地从单张图像创建物理启发的机器人环境，为机器人学习提供了大规模、多样化的数据生成能力，推动了机器人数据生成的民主化进程。

Abstract: We introduce RoLA, a framework that transforms any in-the-wild image into an
interactive, physics-enabled robotic environment. Unlike previous methods, RoLA
operates directly on a single image without requiring additional hardware or
digital assets. Our framework democratizes robotic data generation by producing
massive visuomotor robotic demonstrations within minutes from a wide range of
image sources, including camera captures, robotic datasets, and Internet
images. At its core, our approach combines a novel method for single-view
physical scene recovery with an efficient visual blending strategy for
photorealistic data collection. We demonstrate RoLA's versatility across
applications like scalable robotic data generation and augmentation, robot
learning from Internet images, and single-image real-to-sim-to-real systems for
manipulators and humanoids. Video results are available at
https://sihengz02.github.io/RoLA .

</details>


### [42] [Safe Task Space Synchronization with Time-Delayed Information](https://arxiv.org/abs/2509.22976)
*Rounak Bhattacharya,Vrithik R. Guthikonda,Ashwin P. Dani*

Main category: cs.RO

TL;DR: 本文设计了一种自适应控制器，用于在存在通信时延的情况下，使具有未知运动学和动力学的机器人轨迹与人类任务空间轨迹同步，并使用屏障Lyapunov函数确保安全约束。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人协作任务中，由于传感器处理、网络延迟或计算限制等因素导致的通信时延会影响轨迹同步的准确性和安全性，需要开发能够处理未知参数和时延的自适应控制方法。

Method: 采用屏障Lyapunov函数(BLF)约束机器人笛卡尔坐标以确保安全，使用ICL基自适应律处理未知运动学，梯度基自适应律估计未知动力学，并通过屏障Lyapunov-Krasovskii泛函进行稳定性分析。

Result: 仿真结果表明，所设计的同步控制器在存在时延的情况下能够有效实现人类-机器人轨迹同步，同时满足安全约束条件。

Conclusion: 提出的自适应控制器能够处理未知运动学和动力学参数，在通信时延条件下实现安全的人类-机器人轨迹同步，同步误差和参数估计误差保持半全局一致最终有界。

Abstract: In this paper, an adaptive controller is designed for the synchronization of
the trajectory of a robot with unknown kinematics and dynamics to that of the
current human trajectory in the task space using the delayed human trajectory
information. The communication time delay may be a result of various factors
that arise in human-robot collaboration tasks, such as sensor processing or
fusion to estimate trajectory/intent, network delays, or computational
limitations. The developed adaptive controller uses Barrier Lyapunov Function
(BLF) to constrain the Cartesian coordinates of the robot to ensure safety, an
ICL-based adaptive law to account for the unknown kinematics, and a
gradient-based adaptive law to estimate unknown dynamics. Barrier
Lyapunov-Krasovskii (LK) functionals are used for the stability analysis to
show that the synchronization and parameter estimation errors remain
semi-globally uniformly ultimately bounded (SGUUB). The simulation results
based on a human-robot synchronization scenario with time delay are provided to
demonstrate the effectiveness of the designed synchronization controller with
safety constraints.

</details>


### [43] [UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes](https://arxiv.org/abs/2509.23021)
*Xiao Hu,Qi Yin,Yangming Shi,Yang Ye*

Main category: cs.RO

TL;DR: UniPrototype框架通过共享运动基元实现从人类到机器人领域的知识迁移，解决了机器人学习中数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中训练数据稀缺的挑战，利用人类丰富的运动捕捉数据和互联网资源来弥合人类与机器人操作能力之间的差距。

Method: 提出组合原型发现机制（支持多个基元共同激活）、自适应原型选择策略（根据任务复杂度自动调整原型数量），在仿真环境和真实机器人系统中进行实验验证。

Result: UniPrototype成功将人类操作知识迁移到机器人，相比现有方法显著提高了学习效率和任务性能。

Conclusion: 该框架有效解决了机器人学习中的数据稀缺问题，通过知识迁移提升了机器人操作能力，代码和数据集将在匿名存储库中发布。

Abstract: Data scarcity remains a fundamental challenge in robot learning. While human
demonstrations benefit from abundant motion capture data and vast internet
resources, robotic manipulation suffers from limited training examples. To
bridge this gap between human and robot manipulation capabilities, we propose
UniPrototype, a novel framework that enables effective knowledge transfer from
human to robot domains via shared motion primitives. ur approach makes three
key contributions: (1) We introduce a compositional prototype discovery
mechanism with soft assignments, enabling multiple primitives to co-activate
and thus capture blended and hierarchical skills; (2) We propose an adaptive
prototype selection strategy that automatically adjusts the number of
prototypes to match task complexity, ensuring scalable and efficient
representation; (3) We demonstrate the effectiveness of our method through
extensive experiments in both simulation environments and real-world robotic
systems. Our results show that UniPrototype successfully transfers human
manipulation knowledge to robots, significantly improving learning efficiency
and task performance compared to existing approaches.The code and dataset will
be released upon acceptance at an anonymous repository.

</details>


### [44] [RAISE: A Robot-Assisted Selective Disassembly and Sorting System for End-of-Life Phones](https://arxiv.org/abs/2509.23048)
*Chang Liu,Badrinath Balasubramaniam,Neal Yancey,Michael Severson,Adam Shine,Philip Bove,Beiwen Li,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出了一种低成本、易部署的自动化选择性拆解和分拣系统，用于处理废弃手机，每小时可处理120多部手机，成功率达98.9%。


<details>
  <summary>Details</summary>
Motivation: 废弃手机因其高产量和短生命周期而加剧全球电子垃圾问题，而拆解过程依赖人工劳动，既费时又费力。

Method: 系统由三个子系统组成：自适应切割系统、基于视觉的机器人分拣系统和电池移除系统。

Result: 系统每小时可处理120多部手机，平均拆解成功率为98.9%，能有效将高价值组件输送至下游处理环节。

Conclusion: 该系统为废弃手机拆解提供了可靠且可扩展的自动化解决方案，改善了拆解经济性，将原本无利可图的过程转变为能产生净利润的过程。

Abstract: End-of-Life (EoL) phones significantly exacerbate global e-waste challenges
due to their high production volumes and short lifecycles. Disassembly is among
the most critical processes in EoL phone recycling. However, it relies heavily
on human labor due to product variability. Consequently, the manual process is
both labor-intensive and time-consuming. In this paper, we propose a low-cost,
easily deployable automated and selective disassembly and sorting system for
EoL phones, consisting of three subsystems: an adaptive cutting system, a
vision-based robotic sorting system, and a battery removal system. The system
can process over 120 phones per hour with an average disassembly success rate
of 98.9%, efficiently delivering selected high-value components to downstream
processing. It provides a reliable and scalable automated solution to the
pressing challenge of EoL phone disassembly. Additionally, the automated system
can enhance disassembly economics, converting a previously unprofitable process
into one that yields a net profit per unit weight of EoL phones.

</details>


### [45] [In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer](https://arxiv.org/abs/2509.23075)
*Soofiyan Atar,Daniel Huang,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 该论文提出了一种结合仿真训练和硬件演示学习的控制方法，用于机器人手对铰接工具进行灵巧操作，解决了接触动力学和关节摩擦等未建模现象带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 强化学习和仿真到实体的迁移在刚性物体操作中取得了进展，但在铰接机构操作中仍显脆弱，主要由于接触丰富的动力学和未建模的关节现象（如摩擦、静摩擦、间隙等）。

Method: 控制器在仿真训练的基础策略上，通过硬件演示学习的传感器驱动细化进行增强，融合本体感觉和目标关节状态，通过跨注意力机制整合全手触觉和力反馈与策略内部动作意图。

Result: 该方法在剪刀、钳子、微创手术工具和订书机等真实世界示例中验证，实现了从仿真到硬件的稳健迁移，提高了抗干扰能力，并能泛化到未见过的铰接工具。

Conclusion: 该方法减少了在接触丰富环境中对精确物理建模的依赖，实现了对铰接工具的鲁棒操作。

Abstract: Reinforcement learning (RL) and sim-to-real transfer have advanced robotic
manipulation of rigid objects. Yet, policies remain brittle when applied to
articulated mechanisms due to contact-rich dynamics and under-modeled joint
phenomena such as friction, stiction, backlash, and clearances. We address this
challenge through dexterous in-hand manipulation of articulated tools using a
robotic hand with reduced articulation and kinematic redundancy relative to the
human hand. Our controller augments a simulation-trained base policy with a
sensor-driven refinement learned from hardware demonstrations, conditioning on
proprioception and target articulation states while fusing whole-hand tactile
and force feedback with the policy's internal action intent via
cross-attention-based integration. This design enables online adaptation to
instance-specific articulation properties, stabilizes contact interactions,
regulates internal forces, and coordinates coupled-link motion under
perturbations. We validate our approach across a diversity of real-world
examples, including scissors, pliers, minimally invasive surgical tools, and
staplers. We achieve robust transfer from simulation to hardware, improved
disturbance resilience, and generalization to previously unseen articulated
tools, thereby reducing reliance on precise physical modeling in contact-rich
settings.

</details>


### [46] [Open-Vocabulary Spatio-Temporal Scene Graph for Robot Perception and Teleoperation Planning](https://arxiv.org/abs/2509.23107)
*Yi Wang,Zeyu Xue,Mujie Liu,Tongqin Zhang,Yan Hu,Zhou Zhao,Chenguang Yang,Zhenyu Lu*

Main category: cs.RO

TL;DR: 提出了ST-OVSG时空开放词汇场景图，通过增强时间动态性和延迟标注来解决远程操作中的传输延迟问题，提高规划鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在动态远程场景中，双向通信的传输延迟导致远程感知状态与操作者意图之间出现差距，造成命令误解和执行错误。

Method: 利用LVLMs构建开放词汇3D对象表示，通过匈牙利分配和时序匹配成本扩展到时间域，形成统一时空场景图，嵌入延迟标签使规划器能回溯查询过去场景状态。

Result: 在Replica基准测试中达到74%节点准确率，优于ConceptGraph；在延迟鲁棒性实验中，ST-OVSG辅助的LVLM规划器实现了70.5%的规划成功率。

Conclusion: ST-OVSG能够泛化到新类别，无需微调即可增强对传输延迟的规划鲁棒性，有效解决本地-远程状态不匹配问题。

Abstract: Teleoperation via natural-language reduces operator workload and enhances
safety in high-risk or remote settings. However, in dynamic remote scenes,
transmission latency during bidirectional communication creates gaps between
remote perceived states and operator intent, leading to command
misunderstanding and incorrect execution. To mitigate this, we introduce the
Spatio-Temporal Open-Vocabulary Scene Graph (ST-OVSG), a representation that
enriches open-vocabulary perception with temporal dynamics and lightweight
latency annotations. ST-OVSG leverages LVLMs to construct open-vocabulary 3D
object representations, and extends them into the temporal domain via Hungarian
assignment with our temporal matching cost, yielding a unified spatio-temporal
scene graph. A latency tag is embedded to enable LVLM planners to
retrospectively query past scene states, thereby resolving local-remote state
mismatches caused by transmission delays. To further reduce redundancy and
highlight task-relevant cues, we propose a task-oriented subgraph filtering
strategy that produces compact inputs for the planner. ST-OVSG generalizes to
novel categories and enhances planning robustness against transmission latency
without requiring fine-tuning. Experiments show that our method achieves 74
percent node accuracy on the Replica benchmark, outperforming ConceptGraph.
Notably, in the latency-robustness experiment, the LVLM planner assisted by
ST-OVSG achieved a planning success rate of 70.5 percent.

</details>


### [47] [Liaohe-CobotMagic-PnP: an Imitation Learning Dataset of Intelligent Robot for Industrial Applications](https://arxiv.org/abs/2509.23111)
*Chen Yizhe,Wang Qi,Hu Dongxiao,Jingzhe Fang,Liu Sichao,Zixin An,Hongliang Niu,Haoran Liu,Li Dong,Chuanfen Feng,Lan Dapeng,Liu Yu,Zhibo Pang*

Main category: cs.RO

TL;DR: 提出了一个工业级多模态干扰数据集，用于机器人在复杂条件下的感知和控制，包含视觉、扭矩和关节状态的多维同步测量数据。


<details>
  <summary>Details</summary>
Motivation: 在工业4.0应用中，动态环境干扰导致环境状态与机器人行为之间产生高度非线性和强耦合的相互作用，当前机器人数据集难以有效表示动态环境状态。

Method: 集成多维干扰特征（尺寸、颜色、光照变化），使用高精度传感器同步采集视觉、扭矩和关节状态测量数据，通过ROS实现微秒级时间同步和抗振动数据采集协议。

Result: 实验结果表明，该数据集增强了模型验证的鲁棒性，并提高了机器人在动态、干扰丰富环境中的操作稳定性。

Conclusion: 该公开数据集为机器人在复杂工业环境中的感知和控制研究提供了重要支持。

Abstract: In Industry 4.0 applications, dynamic environmental interference induces
highly nonlinear and strongly coupled interactions between the environmental
state and robotic behavior. Effectively representing dynamic environmental
states through multimodal sensor data fusion remains a critical challenge in
current robotic datasets. To address this, an industrial-grade multimodal
interference dataset is presented, designed for robotic perception and control
under complex conditions. The dataset integrates multi-dimensional interference
features including size, color, and lighting variations, and employs
high-precision sensors to synchronously collect visual, torque, and joint-state
measurements. Scenarios with geometric similarity exceeding 85\% and
standardized lighting gradients are included to ensure real-world
representativeness. Microsecond-level time-synchronization and
vibration-resistant data acquisition protocols, implemented via the Robot
Operating System (ROS), guarantee temporal and operational fidelity.
Experimental results demonstrate that the dataset enhances model validation
robustness and improves robotic operational stability in dynamic,
interference-rich environments. The dataset is publicly available
at:https://modelscope.cn/datasets/Liaoh_LAB/Liaohe-CobotMagic-PnP.

</details>


### [48] [FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task](https://arxiv.org/abs/2509.23112)
*Ryo Watanabe,Maxime Alvarez,Pablo Ferreiro,Pavel Savkin,Genki Sano*

Main category: cs.RO

TL;DR: 提出了一种多模态模仿学习策略，将动作分块变换器与力和扭矩传感相结合，用于解决零售环境中机器人操作饮料瓶等接触密集型任务。


<details>
  <summary>Details</summary>
Motivation: 零售环境中机械臂操作饮料瓶等接触密集型任务时，纯视觉线索往往不足以处理细微的接触事件，需要人类远程操作，成本较高。

Method: 开发了多模态模仿学习策略，在动作分块变换器基础上集成力和扭矩传感，实现图像、关节状态、力和扭矩的端到端学习。

Result: 硬件实验表明，该方法在拾取和重新定向瓶子任务中表现优于基线，特别是在按压和放置阶段，力和扭矩信号在视觉可观测性有限时发挥了重要作用。

Conclusion: 将现代模仿学习架构与轻量级力和扭矩传感相结合，为扩展零售操作提供了一条实用路径，支持将交互力作为接触密集型技能的补充模态。

Abstract: Manipulator robots are increasingly being deployed in retail environments,
yet contact rich edge cases still trigger costly human teleoperation. A
prominent example is upright lying beverage bottles, where purely visual cues
are often insufficient to resolve subtle contact events required for precise
manipulation. We present a multimodal Imitation Learning policy that augments
the Action Chunking Transformer with force and torque sensing, enabling
end-to-end learning over images, joint states, and forces and torques. Deployed
on Ghost, single-arm platform by Telexistence Inc, our approach improves
Pick-and-Reorient bottle task by detecting and exploiting contact transitions
during pressing and placement. Hardware experiments demonstrate greater task
success compared to baseline matching the observation space of ACT as an
ablation and experiments indicate that force and torque signals are beneficial
in the press and place phases where visual observability is limited, supporting
the use of interaction forces as a complementary modality for contact rich
skills. The results suggest a practical path to scaling retail manipulation by
combining modern imitation learning architectures with lightweight force and
torque sensing.

</details>


### [49] [EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation](https://arxiv.org/abs/2509.23118)
*Zeyi Li,Zhe Tang,Kyeong Soo Kim,Sihao Li,Jeremy S. Smith*

Main category: cs.RO

TL;DR: 提出了一种融合Wi-Fi RSSI指纹识别、LiDAR SLAM和IMU的多传感器室内定位导航框架，通过EKF融合抑制噪声和漂移误差，实现0.2449-0.3781米的平均2D定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统Wi-Fi RSSI指纹定位精度不足，而LiDAR方案成本高且复杂，需要一种平衡精度与成本的解决方案。

Method: 使用DNN进行Wi-Fi RSSI粗定位，结合IMU动态定位和Gmapping SLAM生成地图，通过EKF预测-更新融合传感器信息，抑制Wi-Fi噪声和IMU漂移误差。

Result: 在真实环境测试中，该框架平均2D误差为0.2449-0.3781米，相比Wi-Fi RSSI（最高1.3404米）和LiDAR/IMU（0.6233-2.8803米）有显著提升。

Conclusion: 多传感器融合框架能有效抑制单一方法的局限性，在所有路径配置下提供稳定的高精度定位性能。

Abstract: Conventional Wi-Fi received signal strength indicator (RSSI) fingerprinting
cannot meet the growing demand for accurate indoor localization and navigation
due to its lower accuracy, while solutions based on light detection and ranging
(LiDAR) can provide better localization performance but is limited by their
higher deployment cost and complexity. To address these issues, we propose a
novel indoor localization and navigation framework integrating Wi-Fi RSSI
fingerprinting, LiDAR-based simultaneous localization and mapping (SLAM), and
inertial measurement unit (IMU) navigation based on an extended Kalman filter
(EKF). Specifically, coarse localization by deep neural network (DNN)-based
Wi-Fi RSSI fingerprinting is refined by IMU-based dynamic positioning using a
Gmapping-based SLAM to generate an occupancy grid map and output high-frequency
attitude estimates, which is followed by EKF prediction-update integrating
sensor information while effectively suppressing Wi-Fi-induced noise and IMU
drift errors. Multi-group real-world experiments conducted on the IR building
at Xi'an Jiaotong-Liverpool University demonstrates that the proposed
multi-sensor fusion framework suppresses the instability caused by individual
approaches and thereby provides stable accuracy across all path configurations
with mean two-dimensional (2D) errors ranging from 0.2449 m to 0.3781 m. In
contrast, the mean 2D errors of Wi-Fi RSSI fingerprinting reach up to 1.3404 m
in areas with severe signal interference, and those of LiDAR/IMU localization
are between 0.6233 m and 2.8803 m due to cumulative drift.

</details>


### [50] [LAGEA: Language Guided Embodied Agents for Robotic Manipulation](https://arxiv.org/abs/2509.23155)
*Abdul Monaf Chowdhury,Akm Moshiur Rahman Mazumder,Rabeya Akter,Safaeid Hossain Arib*

Main category: cs.RO

TL;DR: LAGEA框架利用视觉语言模型生成语言反馈，将错误反思转化为强化学习的时序引导信号，通过自适应奖励机制提升机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 当前机器人代理缺乏从自身错误中学习的系统方法，研究探索自然语言是否能作为反馈信号，帮助具身代理诊断错误并纠正行为。

Method: LAGEA框架将视觉语言模型的反思总结为简洁语言，定位轨迹中的关键时刻，将反馈与视觉状态对齐，并将目标进展和反馈一致性转化为有界的逐步塑造奖励，通过自适应失败感知系数调节影响。

Result: 在Meta-World MT10基准测试中，LAGEA相比最先进方法在随机目标上平均成功率提升9.0%，在固定目标上提升5.3%，且收敛更快。

Conclusion: 研究表明，当语言被结构化并在时间上接地时，能有效教导机器人自我反思错误并做出更好选择。

Abstract: Robotic manipulation benefits from foundation models that describe goals, but
today's agents still lack a principled way to learn from their own mistakes. We
ask whether natural language can serve as feedback, an error reasoning signal
that helps embodied agents diagnose what went wrong and correct course. We
introduce LAGEA (Language Guided Embodied Agents), a framework that turns
episodic, schema-constrained reflections from a vision language model (VLM)
into temporally grounded guidance for reinforcement learning. LAGEA summarizes
each attempt in concise language, localizes the decisive moments in the
trajectory, aligns feedback with visual state in a shared representation, and
converts goal progress and feedback agreement into bounded, step-wise shaping
rewardswhose influence is modulated by an adaptive, failure-aware coefficient.
This design yields dense signals early when exploration needs direction and
gracefully recedes as competence grows. On the Meta-World MT10 embodied
manipulation benchmark, LAGEA improves average success over the
state-of-the-art (SOTA) methods by 9.0% on random goals and 5.3% on fixed
goals, while converging faster. These results support our hypothesis: language,
when structured and grounded in time, is an effective mechanism for teaching
robots to self-reflect on mistakes and make better choices. Code will be
released soon.

</details>


### [51] [Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion](https://arxiv.org/abs/2509.23185)
*Ziyi Zhou,Qian Meng,Hadas Kress-Gazit,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种四足机器人在动态变化、未知地形上的集成规划框架，结合反应式合成和混合整数凸规划，实现符号级控制器和物理可行步态规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖实时落脚点选择的启发式方法，限制了鲁棒性和适应性，或者依赖计算密集的轨迹优化，难以在复杂地形和长时域上实时应用。

Method: 结合反应式合成生成构造正确的符号级控制器，使用混合整数凸规划进行动态物理可行步态规划，采用符号修复机制减少计算负担，实时MICP重规划结合运行时符号修复和延迟感知协调。

Result: 通过大量仿真和硬件实验验证，框架能够识别缺失的运动技能，在安全关键环境中有效响应，包括分散的踏脚石和钢筋场景。

Conclusion: 该集成规划框架成功实现了离线合成与在线操作的无缝衔接，提高了四足机器人在动态未知地形上的鲁棒性和适应性。

Abstract: We present an integrated planning framework for quadrupedal locomotion over
dynamically changing, unforeseen terrains. Existing methods often depend on
heuristics for real-time foothold selection-limiting robustness and
adaptability-or rely on computationally intensive trajectory optimization
across complex terrains and long horizons. In contrast, our approach combines
reactive synthesis for generating correct-by-construction symbolic-level
controllers with mixed-integer convex programming (MICP) for dynamic and
physically feasible footstep planning during each symbolic transition. To
reduce the reliance on costly MICP solves and accommodate specifications that
may be violated due to physical infeasibility, we adopt a symbolic repair
mechanism that selectively generates only the required symbolic transitions.
During execution, real-time MICP replanning based on actual terrain data,
combined with runtime symbolic repair and delay-aware coordination, enables
seamless bridging between offline synthesis and online operation. Through
extensive simulation and hardware experiments, we validate the framework's
ability to identify missing locomotion skills and respond effectively in
safety-critical environments, including scattered stepping stones and rebar
scenarios.

</details>


### [52] [CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation](https://arxiv.org/abs/2509.23203)
*Kai Yang,Tianlin Zhang,Zhengbo Wang,Zedong Chu,Xiaolong Wu,Yang Cai,Mu Xu*

Main category: cs.RO

TL;DR: CE-Nav是一个两阶段框架，通过模仿学习训练通用几何推理专家，再通过强化学习训练轻量级动态适配器，实现跨机器人形态的通用导航策略。


<details>
  <summary>Details</summary>
Motivation: 解决跨机器人形态导航策略泛化的挑战，避免昂贵的特定形态数据需求，解耦规划与控制，处理多模态决策问题。

Method: 两阶段方法：第一阶段离线训练基于条件归一化流的通用专家（VelFlow），学习运动学可行的完整动作分布；第二阶段在线训练轻量级动态感知精炼器，补偿特定机器人的动态特性和控制器缺陷。

Result: 在四足、双足和四旋翼机器人上的广泛实验显示，CE-Nav达到最先进性能，同时大幅降低适配成本。真实世界部署验证了方法的有效性和可扩展性。

Conclusion: CE-Nav为构建可泛化导航系统提供了高效且可扩展的解决方案，成功解决了跨形态导航的泛化挑战。

Abstract: Generalizing local navigation policies across diverse robot morphologies is a
critical challenge. Progress is often hindered by the need for costly and
embodiment-specific data, the tight coupling of planning and control, and the
"disastrous averaging" problem where deterministic models fail to capture
multi-modal decisions (e.g., turning left or right). We introduce CE-Nav, a
novel two-stage (IL-then-RL) framework that systematically decouples universal
geometric reasoning from embodiment-specific dynamic adaptation. First, we
train an embodiment-agnostic General Expert offline using imitation learning.
This expert, a conditional normalizing flow model named VelFlow, learns the
full distribution of kinematically-sound actions from a large-scale dataset
generated by a classical planner, completely avoiding real robot data and
resolving the multi-modality issue. Second, for a new robot, we freeze the
expert and use it as a guiding prior to train a lightweight, Dynamics-Aware
Refiner via online reinforcement learning. This refiner rapidly learns to
compensate for the target robot's specific dynamics and controller
imperfections with minimal environmental interaction. Extensive experiments on
quadrupeds, bipeds, and quadrotors show that CE-Nav achieves state-of-the-art
performance while drastically reducing adaptation cost. Successful real-world
deployments further validate our approach as an efficient and scalable solution
for building generalizable navigation systems.

</details>


### [53] [Simulated Annealing for Multi-Robot Ergodic Information Acquisition Using Graph-Based Discretization](https://arxiv.org/abs/2509.23214)
*Benjamin Wong,Aaron Weber,Mohamed M. Safwat,Santosh Devasia,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 提出使用模拟退火方法生成目标采样分布，从均匀分布逐渐过渡到估计的最优分布，以在多机器人团队中保持各区域相对不确定性一致。


<details>
  <summary>Details</summary>
Motivation: 多机器人主动信息采集中需要保持各区域相对不确定性在相同水平，以实现一致的采集质量。然而采样噪声水平未知且初始估计不可靠，会产生波动值。

Method: 使用模拟退火生成目标采样分布，通过玻尔兹曼分布的温度参数变化，从均匀分布逐渐转移到估计的最优分布，以估计的采样熵作为能量。

Result: 仿真结果显示，与均匀搜索和直接遍历搜索相比，该方法在瞬态熵和渐近熵方面都有显著改善。TurtleBot群系统演示验证了算法的物理适用性。

Conclusion: 模拟退火方法能有效处理多机器人信息采集中的不确定性估计问题，实现更好的区域覆盖质量一致性。

Abstract: One of the goals of active information acquisition using multi-robot teams is
to keep the relative uncertainty in each region at the same level to maintain
identical acquisition quality (e.g., consistent target detection) in all the
regions. To achieve this goal, ergodic coverage can be used to assign the
number of samples according to the quality of observation, i.e., sampling noise
levels. However, the noise levels are unknown to the robots. Although this
noise can be estimated from samples, the estimates are unreliable at first and
can generate fluctuating values. The main contribution of this paper is to use
simulated annealing to generate the target sampling distribution, starting from
uniform and gradually shifting to an estimated optimal distribution, by varying
the coldness parameter of a Boltzmann distribution with the estimated sampling
entropy as energy. Simulation results show a substantial improvement of both
transient and asymptotic entropy compared to both uniform and direct-ergodic
searches. Finally, a demonstration is performed with a TurtleBot swarm system
to validate the physical applicability of the algorithm.

</details>


### [54] [GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking](https://arxiv.org/abs/2509.23220)
*Ye Chen,Zichen Zhou,Jianyu Dou,Te Cui,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: GLUE是一个用于模仿学习的全局-局部统一编码框架，通过关键补丁跟踪来提升在复杂OOD环境下的策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在复杂OOD环境下，全局视觉表示的注意力会被稀释或干扰，导致策略性能下降。局部表示对任务相关对象具有不变性，可以缓解协变量偏移问题。

Method: 使用文本引导机制选择和跟踪关键补丁作为局部表示，通过全局补丁特征查询局部补丁来提取关键信息，生成细粒度的局部特征。

Result: 在仿真环境中比最强基线提升17.6%，在真实环境中提升36.3%，在真实世界泛化设置中提升58.3%。

Conclusion: GLUE通过融合全局和局部表示，将训练和测试分布映射到相似的特征空间，显著提升了模仿学习策略的鲁棒性。

Abstract: In recent years, visual representation learning has gained widespread
attention in robotic imitation learning. However, in complex
Out-of-Distribution(OOD) settings characterized by clutter and occlusion, the
attention of global visual representations can be diluted or interfered,
leading to degraded policy performance. The invariance of local representations
for task-relevant objects offers a solution. By efficiently utilizing these
local representations, training and testing data can be mapped to a more
similar feature space, thereby mitigating the covariate shift problem.
Accordingly, we propose GLUE, a global-local unified encoding framework for
imitation learning based on key-patch tracking. GLUE selects and tracks
key-patches as critical local representations by employing a text-guided
mechanism. It features a novel fusion framework where global patch features
query local patches to distill essential information, yielding fine-grained
local features with low heterogeneity relative to the global context. This
fused representation steers the robot's visual attention toward task-relevant
objects and preserves precise global context, which together align the training
and testing distributions into a similar and task-informative feature space,
ultimately enhancing the robustness of the imitation learning policy.
Experiments demonstrate that GLUE achieves strong performance across diverse
tasks in both simulation and real-world settings, outperforming the strongest
baseline by 17.6% in simulation, 36.3% in real-world environments, and 58.3% on
real-world generalization settings. The project website of GLUE is available at
https://GLUE666.github.io/.

</details>


### [55] [SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion](https://arxiv.org/abs/2509.23223)
*Aoqian Zhang,Zixuan Zhuang,Chunzheng Wang,Shuzhi Sam Ge,Fan Shi,Cheng Xiang*

Main category: cs.RO

TL;DR: 提出了一种切换策略框架，用于实现四足机器人的柔顺和安全运动控制，通过可调柔顺策略、安全策略和可恢复性网络来应对严重外部扰动。


<details>
  <summary>Details</summary>
Motivation: 现有四足机器人控制方法缺乏动物所具备的自适应和可调柔顺能力，无法在大型扰动下保持稳定，需要开发既能提供可调柔顺性又能确保安全性的控制框架。

Method: 使用师生强化学习框架训练具有可调柔顺水平的力柔顺策略；基于捕获点概念开发安全策略；引入可恢复性网络预测失败可能性并在柔顺策略和安全策略之间切换。

Result: 该框架使四足机器人在遭受严重外部扰动时能够同时实现力柔顺和鲁棒安全性。

Conclusion: 提出的切换策略框架成功解决了四足机器人在外部扰动下的柔顺控制和安全性问题，为机器人运动控制提供了新的解决方案。

Abstract: Quadruped robots are designed to achieve agile locomotion by mimicking legged
animals. However, existing control methods for quadrupeds often lack one of the
key capabilities observed in animals: adaptive and adjustable compliance in
response to external disturbances. Most locomotion controllers do not provide
tunable compliance and tend to fail under large perturbations. In this work, we
propose a switched policy framework for compliant and safe quadruped
locomotion. First, we train a force compliant policy with adjustable compliance
levels using a teacher student reinforcement learning framework, eliminating
the need for explicit force sensing. Next, we develop a safe policy based on
the capture point concept to stabilize the robot when the compliant policy
fails. Finally, we introduce a recoverability network that predicts the
likelihood of failure and switches between the compliant and safe policies.
Together, this framework enables quadruped robots to achieve both force
compliance and robust safety when subjected to severe external disturbances.

</details>


### [56] [Leave No Observation Behind: Real-time Correction for VLA Action Chunks](https://arxiv.org/abs/2509.23224)
*Kohei Sendai,Maxime Alvarez,Tatsuya Matsushima,Yutaka Matsuo,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: A2C2是一种轻量级实时动作块校正方法，通过在每个控制步骤添加时间感知校正来提升VLA模型的反应性，无需重新训练基础策略。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型预测动作块时在推理延迟和长时域下反应性下降的问题，保持基础模型能力的同时恢复闭环响应能力。

Method: 设计实时校正头，结合最新观测、VLA预测的基础动作、动作块内位置特征和基础策略特征，输出每步校正量。

Result: 在动态Kinetix任务套件和LIBERO Spatial上，相比RTC方法分别提升23%和7%的成功率，在零延迟长时域下也提升鲁棒性。

Conclusion: A2C2是部署高容量分块策略到实时控制的有效即插即用机制，校正头轻量快速，对大VLA模型推理开销极小。

Abstract: To improve efficiency and temporal coherence, Vision-Language-Action (VLA)
models often predict action chunks; however, this action chunking harms
reactivity under inference delay and long horizons. We introduce Asynchronous
Action Chunk Correction (A2C2), which is a lightweight real-time chunk
correction head that runs every control step and adds a time-aware correction
to any off-the-shelf VLA's action chunk. The module combines the latest
observation, the predicted action from VLA (base action), a positional feature
that encodes the index of the base action within the chunk, and some features
from the base policy, then outputs a per-step correction. This preserves the
base model's competence while restoring closed-loop responsiveness. The
approach requires no retraining of the base policy and is orthogonal to
asynchronous execution schemes such as Real Time Chunking (RTC). On the dynamic
Kinetix task suite (12 tasks) and LIBERO Spatial, our method yields consistent
success rate improvements across increasing delays and execution horizons (+23%
point and +7% point respectively, compared to RTC), and also improves
robustness for long horizons even with zero injected delay. Since the
correction head is small and fast, there is minimal overhead compared to the
inference of large VLA models. These results indicate that A2C2 is an
effective, plug-in mechanism for deploying high-capacity chunking policies in
real-time control.

</details>


### [57] [Online Dynamic Goal Recognition in Gym Environments](https://arxiv.org/abs/2509.23244)
*Shamir Matan,Elhadad Osher,Nageris Ben,Mirsky Reuth*

Main category: cs.RO

TL;DR: 提出了两个开源框架gr-libs和gr-envs，用于标准化目标识别算法的开发、评估和比较，解决该领域基准测试、领域和评估协议不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 目标识别领域因基准测试、领域和评估协议的不一致性而碎片化，需要标准化平台来促进研究发展。

Method: 开发了两个互补的开源框架：gr-libs包含模块化的MDP基础目标识别算法实现、诊断工具和评估工具；gr-envs提供了一套经过调整的环境套件，支持动态和目标导向行为。

Result: 创建了一个标准化、可扩展且可复现的平台，支持目标识别算法的开发和比较，两个包已在GitHub和PyPI上开源提供。

Conclusion: 这些框架为推进目标识别研究提供了统一的实验平台，有助于解决该领域的碎片化问题。

Abstract: Goal Recognition (GR) is the task of inferring an agent's intended goal from
partial observations of its behavior, typically in an online and one-shot
setting. Despite recent advances in model-free GR, particularly in applications
such as human-robot interaction, surveillance, and assistive systems, the field
remains fragmented due to inconsistencies in benchmarks, domains, and
evaluation protocols.
  To address this, we introduce gr-libs
(https://github.com/MatanShamir1/gr_libs) and gr-envs
(https://github.com/MatanShamir1/gr_envs), two complementary open-source
frameworks that support the development, evaluation, and comparison of GR
algorithms in Gym-compatible environments. gr-libs includes modular
implementations of MDP-based GR baselines, diagnostic tools, and evaluation
utilities. gr-envs provides a curated suite of environments adapted for dynamic
and goal-directed behavior, along with wrappers that ensure compatibility with
standard reinforcement learning toolkits. Together, these libraries offer a
standardized, extensible, and reproducible platform for advancing GR research.
Both packages are open-source and available on GitHub and PyPI.

</details>


### [58] [Preventing Robotic Jailbreaking via Multimodal Domain Adaptation](https://arxiv.org/abs/2509.23281)
*Francesco Marchiori,Rohan Sinha,Christopher Agia,Alexander Robey,George J. Pappas,Mauro Conti,Marco Pavone*

Main category: cs.RO

TL;DR: J-DAPT是一个轻量级多模态越狱检测框架，通过注意力融合和领域自适应技术，在机器人应用中实现接近100%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和视觉语言模型在机器人环境中部署时容易受到越狱攻击，绕过安全机制导致现实世界中的不安全行为，而现有的基于数据驱动的防御方法在专业数据集稀缺的领域泛化能力不足。

Method: J-DAPT框架整合文本和视觉嵌入来捕捉语义意图和环境基础，同时通过注意力融合和领域自适应技术，将通用越狱数据集与领域特定参考数据对齐。

Result: 在自动驾驶、海洋机器人和四足机器人导航等领域的评估显示，J-DAPT以最小开销将检测准确率提升至接近100%。

Conclusion: J-DAPT为机器人应用中的视觉语言模型提供了一个实用的安全防御解决方案。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) are
increasingly deployed in robotic environments but remain vulnerable to
jailbreaking attacks that bypass safety mechanisms and drive unsafe or
physically harmful behaviors in the real world. Data-driven defenses such as
jailbreak classifiers show promise, yet they struggle to generalize in domains
where specialized datasets are scarce, limiting their effectiveness in robotics
and other safety-critical contexts. To address this gap, we introduce J-DAPT, a
lightweight framework for multimodal jailbreak detection through
attention-based fusion and domain adaptation. J-DAPT integrates textual and
visual embeddings to capture both semantic intent and environmental grounding,
while aligning general-purpose jailbreak datasets with domain-specific
reference data. Evaluations across autonomous driving, maritime robotics, and
quadruped navigation show that J-DAPT boosts detection accuracy to nearly 100%
with minimal overhead. These results demonstrate that J-DAPT provides a
practical defense for securing VLMs in robotic applications. Additional
materials are made available at: https://j-dapt.github.io.

</details>


### [59] [A Novel Narrow Region Detector for Sampling-Based Planners' Efficiency: Match Based Passage Identifier](https://arxiv.org/abs/2509.23288)
*Yafes Enes Şahiner,Esat Yusuf Gündoğdu,Volkan Sezer*

Main category: cs.RO

TL;DR: 提出一种新型采样器，使用占据栅格地图确定性地识别狭窄通道环境，并在这些区域增加采样量，以解决概率方法在狭窄通道环境中的常见问题。


<details>
  <summary>Details</summary>
Motivation: 自主技术在移动机器人、机械臂和无人机等配置中广泛应用，路径规划是其重要任务。概率方法在狭窄通道环境中普遍存在问题，需要改进采样策略。

Method: 使用占据栅格地图确定性地识别狭窄通道环境，并在这些区域增加采样量。算法代码开源提供。

Result: 在特定和随机仿真环境以及真实世界环境中的基准测试表明，该算法在规划时间和里程碑数量方面比基线采样器性能更高。

Conclusion: 提出的采样器能有效解决狭窄通道环境中的路径规划问题，在多个测试场景中表现出优越性能。

Abstract: Autonomous technology, which has become widespread today, appears in many
different configurations such as mobile robots, manipulators, and drones. One
of the most important tasks of these vehicles during autonomous operations is
path planning. In the literature, path planners are generally divided into two
categories: probabilistic and deterministic methods. In the analysis of
probabilistic methods, the common problem of almost all methods is observed in
narrow passage environments. In this paper, a novel sampler is proposed that
deterministically identifies narrow passage environments using occupancy grid
maps and accordingly increases the amount of sampling in these regions. The
codes of the algorithm is provided as open source. To evaluate the performance
of the algorithm, benchmark studies are conducted in three distinct categories:
specific and random simulation environments, and a real-world environment. As a
result, it is observed that our algorithm provides higher performance in
planning time and number of milestones compared to the baseline samplers.

</details>


### [60] [Distributed Multi-Robot Multi-Target Simultaneous Search and Tracking in an Unknown Non-convex Environment](https://arxiv.org/abs/2509.23308)
*Jun Chen,Jiaqing Ma,Philip Dames*

Main category: cs.RO

TL;DR: 提出了一种集成前沿探索、保证覆盖和多目标跟踪的运动规划算法框架，用于在未知非凸环境中同时优化环境探索、信息搜索和目标跟踪任务。


<details>
  <summary>Details</summary>
Motivation: 在室内、地下等未知非凸环境中，部署机器人舰队同时进行环境探索、目标搜索和高精度跟踪是一个亟待解决的基础挑战，现有研究尚未建立同时优化这些任务的框架。

Method: 集成了三种控制策略：基于前沿的探索策略、基于Lloyd算法的保证覆盖策略和基于传感器的多目标跟踪策略，平衡覆盖搜索和高精度主动跟踪。

Result: 通过MATLAB仿真验证了算法的有效性和优越性，相比标准方法表现更优。

Conclusion: 提出的算法框架成功解决了在复杂环境中同时进行环境探索、信息搜索和目标跟踪的集成优化问题。

Abstract: In unknown non-convex environments, such as indoor and underground spaces,
deploying a fleet of robots to explore the surroundings while simultaneously
searching for and tracking targets of interest to maintain high-precision data
collection represents a fundamental challenge that urgently requires resolution
in applications such as environmental monitoring and rescue operations. Current
research has made significant progress in addressing environmental exploration,
information search, and target tracking problems, but has yet to establish a
framework for simultaneously optimizing these tasks in complex environments. In
this paper, we propose a novel motion planning algorithm framework that
integrates three control strategies: a frontier-based exploration strategy, a
guaranteed coverage strategy based on Lloyd's algorithm, and a sensor-based
multi-target tracking strategy. By incorporating these three strategies, the
proposed algorithm balances coverage search and high-precision active tracking
during exploration. Our approach is validated through a series of MATLAB
simulations, demonstrating validity and superiority over standard approaches.

</details>


### [61] [GUARD: Toward a Compromise between Traditional Control and Learning for Safe Robot Systems](https://arxiv.org/abs/2509.23312)
*Johannes A. Gaus,Junheon Yoon,Woo-Jeong Baek,Seungwon Choi,Suhan Park,Jaeheung Park*

Main category: cs.RO

TL;DR: GUARD框架结合传统控制与不确定性感知感知技术，通过主动学习和实时能力实现安全机器人碰撞避免，在传统方法与学习算法间找到平衡。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学中传统方法与学习算法之间的平衡问题，开发安全、高效且灵活的应用。

Method: 将反应式模型预测轮廓控制(RMPCC)与迭代最近点(ICP)算法结合，通过概率核优化技术在线归因不确定性源，具备实时主动学习能力。

Result: 实验研究表明GUARD具有高性能，能够处理机器人文献中安全概念的模糊性。

Conclusion: GUARD框架展示了在机器人安全决策中的相关性和必要性，未来需要扩大其适用性。

Abstract: This paper presents the framework \textbf{GUARD} (\textbf{G}uided robot
control via \textbf{U}ncertainty attribution and prob\textbf{A}bilistic kernel
optimization for \textbf{R}isk-aware \textbf{D}ecision making) that combines
traditional control with an uncertainty-aware perception technique using active
learning with real-time capability for safe robot collision avoidance. By doing
so, this manuscript addresses the central challenge in robotics of finding a
reasonable compromise between traditional methods and learning algorithms to
foster the development of safe, yet efficient and flexible applications. By
unifying a reactive model predictive countouring control (RMPCC) with an
Iterative Closest Point (ICP) algorithm that enables the attribution of
uncertainty sources online using active learning with real-time capability via
a probabilistic kernel optimization technique, \emph{GUARD} inherently handles
the existing ambiguity of the term \textit{safety} that exists in robotics
literature. Experimental studies indicate the high performance of \emph{GUARD},
thereby highlighting the relevance and need to broaden its applicability in
future.

</details>


### [62] [Space Robotics Bench: Robot Learning Beyond Earth](https://arxiv.org/abs/2509.23328)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 提出了Space Robotics Bench开源仿真框架，用于太空机器人学习，包含模块化架构、程序化生成和并行仿真环境，支持创建多样化训练分布和基准任务。


<details>
  <summary>Details</summary>
Motivation: 太空探索需要能在极端环境下自主运行的机器人系统，但技术演示成本高昂且数据稀缺，阻碍了机器人学习在该领域的应用。

Method: 开发模块化仿真框架，集成按需程序化生成和大规模并行仿真环境，建立基准任务套件，使用标准强化学习算法建立性能基线。

Result: 通过实验案例研究揭示了当前方法在泛化、端到端学习、自适应控制和仿真到真实迁移方面的局限性，证明了框架能产生具有实际应用能力的策略。

Conclusion: Space Robotics Bench为开发、基准测试和部署太空探索所需的鲁棒自主系统提供了宝贵资源。

Abstract: The growing ambition for space exploration demands robust autonomous systems
that can operate in unstructured environments under extreme extraterrestrial
conditions. The adoption of robot learning in this domain is severely hindered
by the prohibitive cost of technology demonstrations and the limited
availability of data. To bridge this gap, we introduce the Space Robotics
Bench, an open-source simulation framework for robot learning in space. It
offers a modular architecture that integrates on-demand procedural generation
with massively parallel simulation environments to support the creation of vast
and diverse training distributions for learning-based agents. To ground
research and enable direct comparison, the framework includes a comprehensive
suite of benchmark tasks that span a wide range of mission-relevant scenarios.
We establish performance baselines using standard reinforcement learning
algorithms and present a series of experimental case studies that investigate
key challenges in generalization, end-to-end learning, adaptive control, and
sim-to-real transfer. Our results reveal insights into the limitations of
current methods and demonstrate the utility of the framework in producing
policies capable of real-world operation. These contributions establish the
Space Robotics Bench as a valuable resource for developing, benchmarking, and
deploying the robust autonomous systems required for the final frontier.

</details>


### [63] [Robust Orientation Estimation with TRIAD-aided Manifold EKF](https://arxiv.org/abs/2509.23456)
*Arjun Sadananda,Ravi Banavar,Kavi Arya*

Main category: cs.RO

TL;DR: 将TRIAD算法的次优特性整合到流形扩展卡尔曼滤波中，以减轻磁力计读数对俯仰和滚转轴姿态确定的影响。


<details>
  <summary>Details</summary>
Motivation: 磁力计作为姿态确定传感器容易受到校准和外部磁场干扰，影响姿态估计精度。

Method: 在流形扩展卡尔曼滤波算法中融入TRIAD算法的次优特性，特别针对俯仰和滚转轴的磁力计读数影响进行缓解。

Result: 通过实验验证了所提出方法的有效性。

Conclusion: 结合TRIAD次优特性的流形EKF能够有效减轻磁力计干扰，提高姿态确定精度。

Abstract: The manifold extended Kalman filter (Manifold EKF) has found extensive
application for attitude determination. Magnetometers employed as sensors for
such attitude determination are easily prone to disturbances by their
sensitivity to calibration and external magnetic fields. The TRIAD (Tri-Axial
Attitude Determination) algorithm is well known as a sub-optimal attitude
estimator. In this article, we incorporate this sub-optimal feature of the
TRIAD in mitigating the influence of the magnetometer reading in the pitch and
roll axis determination in the Manifold EKF algorithm. We substantiate our
results with experiments.

</details>


### [64] [Towards Tighter Convex Relaxation of Mixed-integer Programs: Leveraging Logic Network Flow for Task and Motion Planning](https://arxiv.org/abs/2509.24235)
*Xuan Lin,Jiming Ren,Yandong Luo,Weijun Xie,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了基于逻辑网络流的任务和运动规划框架，将时序逻辑规范集成到混合整数规划中，相比传统逻辑树方法实现了几个数量级的计算加速。


<details>
  <summary>Details</summary>
Motivation: 传统逻辑树方法在处理时序逻辑规范时存在约束数量多、凸松弛效果差的问题，需要更高效的规划框架。

Method: 将时序谓词编码为网络流模型中边的多面体约束，而非节点间约束，并提出了基于网络流的傅里叶-莫茨金消元法来移除连续流变量。

Result: 在车辆路径规划、多机器人协调和时序逻辑控制等任务中，实现了几个数量级的计算加速，并在四足机器人上验证了实时重规划能力。

Conclusion: 逻辑网络流框架提供了更紧的凸松弛和更少的约束，显著提升了时序逻辑规划的计算效率，适用于动态环境下的实时规划。

Abstract: This paper proposes an optimization-based task and motion planning framework,
named "Logic Network Flow", that integrates temporal logic specifications into
mixed-integer programs for efficient robot planning. Inspired by the
Graph-of-Convex-Sets formulation, temporal predicates are encoded as polyhedron
constraints on each edge of a network flow model, instead of as constraints
between nodes in traditional Logic Tree formulations. We further propose a
network-flow-based Fourier-Motzkin elimination procedure that removes
continuous flow variables while preserving convex relaxation tightness, leading
to provably tighter convex relaxations and fewer constraints than Logic Tree
formulations. For temporal logic motion planning with piecewise-affine dynamic
systems, comprehensive experiments across vehicle routing, multi-robot
coordination, and temporal logic control on dynamical systems using point mass
and linear inverted pendulum models demonstrate computational speedups of up to
several orders of magnitude. Hardware demonstrations with quadrupedal robots
validate real-time replanning capabilities under dynamically changing
environmental conditions. The project website is at
https://logicnetworkflow.github.io/.

</details>


### [65] [Multi-Modal Manipulation via Multi-Modal Policy Consensus](https://arxiv.org/abs/2509.23468)
*Haonan Chen,Jiaming Xu,Hongyu Chen,Kaiwen Hong,Binghao Huang,Chaoqi Liu,Jiayuan Mao,Yunzhu Li,Yilun Du,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 提出一种分解策略方法，将策略分解为专门处理单一模态的扩散模型集合，通过路由器网络学习共识权重自适应组合各模态贡献，支持新模态的增量集成。


<details>
  <summary>Details</summary>
Motivation: 传统特征拼接方法在机器人操作中存在缺陷：视觉等主导模态会淹没触觉等稀疏但关键的信号，且单一架构无法灵活处理新模态或缺失模态而无需重新训练。

Method: 将策略分解为专门处理单一表示（如视觉或触觉）的扩散模型集合，使用路由器网络学习共识权重来自适应组合各模态贡献，支持新表示的增量集成。

Result: 在RLBench模拟操作任务和真实世界任务（遮挡物体抓取、手中勺子重定向、拼图插入）中显著优于特征拼接基线，特别是在需要多模态推理的场景中。策略还表现出对物理扰动和传感器损坏的鲁棒性。

Conclusion: 该方法通过模态分解和自适应组合有效解决了多模态集成问题，在复杂操作任务中表现出优越性能，并能灵活适应新模态和传感器故障情况。

Abstract: Effectively integrating diverse sensory modalities is crucial for robotic
manipulation. However, the typical approach of feature concatenation is often
suboptimal: dominant modalities such as vision can overwhelm sparse but
critical signals like touch in contact-rich tasks, and monolithic architectures
cannot flexibly incorporate new or missing modalities without retraining. Our
method factorizes the policy into a set of diffusion models, each specialized
for a single representation (e.g., vision or touch), and employs a router
network that learns consensus weights to adaptively combine their
contributions, enabling incremental of new representations. We evaluate our
approach on simulated manipulation tasks in {RLBench}, as well as real-world
tasks such as occluded object picking, in-hand spoon reorientation, and puzzle
insertion, where it significantly outperforms feature-concatenation baselines
on scenarios requiring multimodal reasoning. Our policy further demonstrates
robustness to physical perturbations and sensor corruption. We further conduct
perturbation-based importance analysis, which reveals adaptive shifts between
modalities.

</details>


### [66] [PhysiAgent: An Embodied Agent Framework in Physical World](https://arxiv.org/abs/2509.24524)
*Zhihao Wang,Jianxiong Li,Jinliang Zheng,Wencong Zhang,Dongxiu Liu,Yinan Zheng,Haoyi Niu,Junzhi Yu,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 提出PhysiAgent框架，通过监控、记忆、自反机制和轻量级工具箱，实现VLM和VLA的有效协作，提升物理环境中的任务解决性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型泛化能力有限，而VLM作为辅助的集成方法通常采用僵化的顺序结构，导致协作效果不佳和落地困难。

Method: 构建包含监控、记忆、自反机制和轻量级工具箱的自主支架框架，基于VLA的实时能力反馈动态组织组件，最大化利用VLA能力。

Result: 在复杂真实世界机器人任务上显著提升任务解决性能，展示了有效的VLM自我调节、连贯工具协作和框架自适应演化。

Conclusion: PhysiAgent为VLM和VLA集成做出了实用且开创性的努力，有效将具身智能体框架落地到真实世界场景中。

Abstract: Vision-Language-Action (VLA) models have achieved notable success but often
struggle with limited generalizations. To address this, integrating generalized
Vision-Language Models (VLMs) as assistants to VLAs has emerged as a popular
solution. However, current approaches often combine these models in rigid,
sequential structures: using VLMs primarily for high-level scene understanding
and task planning, and VLAs merely as executors of lower-level actions, leading
to ineffective collaboration and poor grounding challenges. In this paper, we
propose an embodied agent framework, PhysiAgent, tailored to operate
effectively in physical environments. By incorporating monitor, memory,
self-reflection mechanisms, and lightweight off-the-shelf toolboxes, PhysiAgent
offers an autonomous scaffolding framework to prompt VLMs to organize different
components based on real-time proficiency feedback from VLAs to maximally
exploit VLAs' capabilities. Experimental results demonstrate significant
improvements in task-solving performance on complex real-world robotic tasks,
showcasing effective self-regulation of VLMs, coherent tool collaboration, and
adaptive evolution of the framework during execution. PhysiAgent makes
practical and pioneering efforts to integrate VLMs and VLAs, effectively
grounding embodied agent frameworks in real-world settings.

</details>


### [67] [Ask, Reason, Assist: Decentralized Robot Collaboration via Language and Logic](https://arxiv.org/abs/2509.23506)
*Dan BW Choe,Sundhar Vinodh Sangeetha,Steven Emanuel,Chih-Yuan Chiu,Samuel Coogan,Shreyas Kousik*

Main category: cs.RO

TL;DR: 提出了一种去中心化框架，让机器人能够请求和提供帮助，使用LLM进行决策和自然语言通信，结合STL和MILP进行推理，显著优于启发式方法。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人团队在仓储等场景中应对突发冲突的需求，实现无缝协作。

Method: 机器人检测冲突后使用LLM决定是否需要外部帮助，通过自然语言广播请求；帮助机器人使用基于STL的LLM推理，将NL转换为STL规范并用MILP求解；请求机器人基于系统级任务完成时间选择帮助者。

Result: 考虑多个帮助提议能让请求者最小化增加的完工时间，显著优于选择最近可用候选者的启发式方法，性能接近集中式基准但信息需求更低。

Conclusion: 该去中心化框架有效实现了异构机器人间的协作，在减少信息需求的同时达到接近最优性能。

Abstract: Increased robot deployment, such as in warehousing, has revealed a need for
seamless collaboration among heterogeneous robot teams to resolve unforeseen
conflicts. To address this challenge, we propose a novel decentralized
framework that enables robots to request and provide help. The process begins
when a robot detects a conflict and uses a Large Language Model (LLM) to decide
whether external assistance is required. If so, it crafts and broadcasts a
natural language (NL) help request. Potential helper robots reason over the
request and respond with offers of assistance, including information about the
effect on their ongoing tasks. Helper reasoning is implemented via an LLM
grounded in Signal Temporal Logic (STL) using a Backus-Naur Form (BNF) grammar,
ensuring syntactically valid NL-to-STL translations, which are then solved as a
Mixed Integer Linear Program (MILP). Finally, the requester robot selects a
helper by reasoning over the expected increase in system-level total task
completion time. We evaluated our framework through experiments comparing
different helper-selection strategies and found that considering multiple
offers allows the requester to minimize added makespan. Our approach
significantly outperforms heuristics such as selecting the nearest available
candidate helper robot, and achieves performance comparable to a centralized
"Oracle" baseline but without heavy information demands.

</details>


### [68] [Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering](https://arxiv.org/abs/2509.24697)
*Evelyn D'Elia,Paolo Maria Viceconte,Lorenzo Rapetti,Diego Ferigo,Giulio Romualdi,Giuseppe L'Erario,Raffaello Camoriano,Daniele Pucci*

Main category: cs.RO

TL;DR: 提出了一种结合物理先验和比例积分控制的双重学习策略，用于提升人形机器人轨迹生成的物理可行性和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法受限于数据量不足且缺乏物理定律约束，导致轨迹发散和接触滑动问题，限制了实际应用的稳定性

Method: 1) 在有监督模仿学习中编码物理先验以促进轨迹可行性；2) 在推理时应用比例积分控制器最小化状态漂移

Result: 在ergoCub人形机器人的多种运动行为上验证，物理感知损失鼓励零接触足部速度，显著提高了生成轨迹的准确性和物理约束符合度

Conclusion: 该方法兼容多种控制器，能有效改善人形机器人轨迹生成的物理可行性和实际稳定性

Abstract: Recent trends in humanoid robot control have successfully employed imitation
learning to enable the learned generation of smooth, human-like trajectories
from human data. While these approaches make more realistic motions possible,
they are limited by the amount of available motion data, and do not incorporate
prior knowledge about the physical laws governing the system and its
interactions with the environment. Thus they may violate such laws, leading to
divergent trajectories and sliding contacts which limit real-world stability.
We address such limitations via a two-pronged learning strategy which leverages
the known physics of the system and fundamental control principles. First, we
encode physics priors during supervised imitation learning to promote
trajectory feasibility. Second, we minimize drift at inference time by applying
a proportional-integral controller directly to the generated output state. We
validate our method on various locomotion behaviors for the ergoCub humanoid
robot, where a physics-informed loss encourages zero contact foot velocity. Our
experiments demonstrate that the proposed approach is compatible with multiple
controllers on a real robot and significantly improves the accuracy and
physical constraint conformity of generated trajectories.

</details>


### [69] [Zero-shot Whole-Body Manipulation with a Large-Scale Soft Robotic Torso via Guided Reinforcement Learning](https://arxiv.org/abs/2509.23556)
*Curtis C. Johnson,Carlo Alessi,Egidio Falotico,Marc D. Killpack*

Main category: cs.RO

TL;DR: 开发了高速软体机器人仿真框架（350倍实时速度），实现零样本仿真到实体的全身操纵策略转移，在Baloo硬件平台上达到88%成功率。


<details>
  <summary>Details</summary>
Motivation: 软体机器人因其被动柔顺性适合接触丰富的全身操纵任务，但其运动学和动力学的不确定性给仿真和控制带来挑战。

Method: 使用MuJoCo开发高速仿真框架，结合简单运动基元引导强化学习，实现零样本策略转移。

Result: 在Baloo平台上成功演示强力六自由度全身操纵（10kg负载），策略表现出重新抓取和扰动恢复等反应行为。

Conclusion: 这是首次使用两个连续软体臂实现强力六自由度全身操纵的零样本策略转移演示，证明了高速仿真与运动基元引导的有效性。

Abstract: Whole-body manipulation is a powerful yet underexplored approach that enables
robots to interact with large, heavy, or awkward objects using more than just
their end-effectors. Soft robots, with their inherent passive compliance, are
particularly well-suited for such contact-rich manipulation tasks, but their
uncertainties in kinematics and dynamics pose significant challenges for
simulation and control. In this work, we address this challenge with a
simulation that can run up to 350x real time on a single thread in MuJoCo and
provide a detailed analysis of the critical tradeoffs between speed and
accuracy for this simulation. Using this framework, we demonstrate a successful
zero-shot sim-to-real transfer of a learned whole-body manipulation policy,
achieving an 88% success rate on the Baloo hardware platform. We show that
guiding RL with a simple motion primitive is critical to this success where
standard reward shaping methods struggled to produce a stable and successful
policy for whole-body manipulation. Furthermore, our analysis reveals that the
learned policy does not simply mimic the motion primitive. It exhibits
beneficial reactive behavior, such as re-grasping and perturbation recovery. We
analyze and contrast this learned policy against an open-loop baseline to show
that the policy can also exhibit aggressive over-corrections under
perturbation. To our knowledge, this is the first demonstration of forceful,
six-DoF whole-body manipulation using two continuum soft arms on a large-scale
platform (10 kg payloads), with zero-shot policy transfer.

</details>


### [70] [Path Diffuser: Diffusion Model for Data-Driven Traffic Simulator](https://arxiv.org/abs/2509.24995)
*Da Saem Lee,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 提出了Path Diffuser，一种基于扩散模型的两阶段方法，用于生成符合地图条件的智能体姿态初始化和轨迹，无需历史轨迹数据，解决了传统方法在多样性和真实性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的规划器缺乏多样性和真实性，而基于学习的模拟器依赖历史轨迹数据，难以生成新场景且在处理分布外地图场景时会产生不现实的轨迹。

Method: 采用两阶段扩散模型，结合基于运动基元的先验知识，利用Frenet框架候选轨迹来增强多样性，同时确保生成的轨迹符合道路要求。

Result: 在Argoverse2数据集上的实验表明，Path Diffuser在分布指标上比基线方法提升1.92倍，在常识指标上提升1.14倍，在道路合规性上提升1.62倍。

Conclusion: Path Diffuser能够有效生成多样且真实的交通场景，无需依赖历史轨迹数据，在分布外地图场景下表现出良好的泛化能力。

Abstract: Simulating diverse and realistic traffic scenarios is critical for developing
and testing autonomous planning. Traditional rule-based planners lack diversity
and realism, while learning-based simulators often replay, forecast, or edit
scenarios using historical agent trajectories. However, they struggle to
generate new scenarios, limiting scalability and diversity due to their
reliance on fully annotated logs and historical data. Thus, a key challenge for
a learning-based simulator's performance is that it requires agents' past
trajectories and pose information in addition to map data, which might not be
available for all agents on the road.Without which, generated scenarios often
produce unrealistic trajectories that deviate from drivable areas, particularly
under out-of-distribution (OOD) map scenes (e.g., curved roads). To address
this, we propose Path Diffuser (PD): a two-stage, diffusion model for
generating agent pose initializations and their corresponding trajectories
conditioned on the map, free of any historical context of agents' trajectories.
Furthermore, PD incorporates a motion primitive-based prior, leveraging Frenet
frame candidate trajectories to enhance diversity while ensuring road-compliant
trajectory generation. We also explore various design choices for modeling
complex multi-agent interactions. We demonstrate the effectiveness of our
method through extensive experiments on the Argoverse2 Dataset and additionally
evaluate the generalizability of the approach on OOD map variants. Notably,
Path Diffuser outperforms the baseline methods by 1.92x on distribution
metrics, 1.14x on common-sense metrics, and 1.62x on road compliance from
adversarial benchmarks.

</details>


### [71] [High Torque Density PCB Axial Flux Permanent Magnet Motor for Micro Robots](https://arxiv.org/abs/2509.23561)
*Jianren Wang,Jie Han,Abhinav Gupta,Deepak Pathak,Yang Zhang*

Main category: cs.RO

TL;DR: 开发了一种采用PCB绕组和HDI技术的微型轴向磁通永磁电机，在19mm直径和5mm厚度的封装中实现了45%的铜填充率，解决了微电机高扭矩需求下的散热和效率问题。


<details>
  <summary>Details</summary>
Motivation: 准直驱驱动需要在小尺寸关节中提供高扭矩，但传统绕线定子在20mm以下直径时铜填充率低，导致电阻大、连续扭矩受限。

Method: 使用印刷电路板绕组和先进IC基板高密度互连技术，通过堆叠四个12层HDI模块形成48层定子结构。

Result: 在19mm直径、5mm厚度的封装中实现了45%的铜填充率，创下记录，并通过电磁和热分析验证了设计。

Conclusion: PCB绕组结合HDI技术能够有效解决微电机铜填充率低的问题，为小型机器人关节提供高性能驱动解决方案。

Abstract: Quasi-direct-drive (QDD) actuation is transforming legged and manipulator
robots by eliminating high-ratio gearboxes, yet it demands motors that deliver
very high torque at low speed within a thin, disc-shaped joint envelope.
Axial-flux permanent-magnet (AFPM) machines meet these geometric and torque
requirements, but scaling them below a 20mm outer diameter is hampered by poor
copper fill in conventional wound stators, inflating resistance and throttling
continuous torque. This paper introduces a micro-scale AFPM motor that
overcomes these limitations through printed-circuit-board (PCB) windings
fabricated with advanced IC-substrate high-density interconnect (HDI)
technology. The resulting 48-layer stator-formed by stacking four 12-layer HDI
modules-achieves a record 45\% copper fill in a package only 5mm thick and 19mm
in diameter. We perform comprehensive electromagnetic and thermal analyses to
inform the motor design, then fabricate a prototype whose performance
characteristics are experimentally verified.

</details>


### [72] [RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation](https://arxiv.org/abs/2509.23563)
*Seungchan Kim,Omar Alama,Dmytro Kurdydyk,John Keller,Nikhil Keetha,Wenshan Wang,Yonatan Bisk,Sebastian Scherer*

Main category: cs.RO

TL;DR: RAVEN是一个基于3D记忆和行为树的空中语义导航框架，用于非结构化室外环境，结合语义体素-射线地图、长短距离搜索和视觉语言模型，在仿真和真实环境中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决室外语义导航中现有方法的局限性：室内方法受限于空间范围和结构化布局，室外方法要么依赖反应式策略导致短视行为，要么依赖离线预计算场景图限制在线部署适应性。

Method: 使用空间一致的语义体素-射线地图作为持久记忆，结合短距离体素搜索和长距离射线搜索，利用大视觉语言模型提供辅助线索，通过行为树协调组件实现自适应行为切换。

Result: 在10个逼真室外仿真环境中进行100个语义任务测试，RAVEN比基线方法性能提升85.25%，并在真实室外环境中通过空中机器人部署验证了实用性。

Conclusion: RAVEN框架通过3D记忆、多尺度搜索和视觉语言模型的结合，有效解决了室外语义导航的挑战，在仿真和真实环境中均表现出强大的性能。

Abstract: Aerial outdoor semantic navigation requires robots to explore large,
unstructured environments to locate target objects. Recent advances in semantic
navigation have demonstrated open-set object-goal navigation in indoor
settings, but these methods remain limited by constrained spatial ranges and
structured layouts, making them unsuitable for long-range outdoor search. While
outdoor semantic navigation approaches exist, they either rely on reactive
policies based on current observations, which tend to produce short-sighted
behaviors, or precompute scene graphs offline for navigation, limiting
adaptability to online deployment. We present RAVEN, a 3D memory-based,
behavior tree framework for aerial semantic navigation in unstructured outdoor
environments. It (1) uses a spatially consistent semantic voxel-ray map as
persistent memory, enabling long-horizon planning and avoiding purely reactive
behaviors, (2) combines short-range voxel search and long-range ray search to
scale to large environments, (3) leverages a large vision-language model to
suggest auxiliary cues, mitigating sparsity of outdoor targets. These
components are coordinated by a behavior tree, which adaptively switches
behaviors for robust operation. We evaluate RAVEN in 10 photorealistic outdoor
simulation environments over 100 semantic tasks, encompassing single-object
search, multi-class, multi-instance navigation and sequential task changes.
Results show RAVEN outperforms baselines by 85.25% in simulation and
demonstrate its real-world applicability through deployment on an aerial robot
in outdoor field tests.

</details>


### [73] [GES-UniGrasp: A Two-Stage Dexterous Grasping Strategy With Geometry-Based Expert Selection](https://arxiv.org/abs/2509.23567)
*Fangting Xu,Jilin Zhu,Xiaoming Gu,Jianzhong Tang*

Main category: cs.RO

TL;DR: 提出了ContactGrasp数据集和Geometry-based Expert Selection框架，用于实现类人灵巧抓握，在训练集和测试集上分别达到99.4%和96.3%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于抓握先验的强化学习方法往往产生不自然的行为，需要开发更自然、鲁棒的灵巧抓握方法。

Method: 构建ContactGrasp数据集，包含773个物体的82个类别；通过几何聚类对物体形状分组，采用两阶段Geometry-based Expert Selection框架选择专家模型。

Result: 实现了自然的抓握姿态，在训练集和测试集上分别达到99.4%和96.3%的高成功率，展示了强大的泛化能力。

Conclusion: 该方法能够实现类人灵巧抓握，具有良好的泛化性和高质量的抓握执行效果。

Abstract: Robust and human-like dexterous grasping of general objects is a critical
capability for advancing intelligent robotic manipulation in real-world
scenarios. However, existing reinforcement learning methods guided by grasp
priors often result in unnatural behaviors. In this work, we present
\textit{ContactGrasp}, a robotic dexterous pre-grasp and grasp dataset that
explicitly accounts for task-relevant wrist orientation and thumb-index
pinching coordination. The dataset covers 773 objects in 82 categories,
providing a rich foundation for training human-like grasp strategies. Building
upon this dataset, we perform geometry-based clustering to group objects by
shape, enabling a two-stage Geometry-based Expert Selection (GES) framework
that selects among specialized experts for grasping diverse object geometries,
thereby enhancing adaptability to diverse shapes and generalization across
categories. Our approach demonstrates natural grasp postures and achieves high
success rates of 99.4\% and 96.3\% on the train and test sets, respectively,
showcasing strong generalization and high-quality grasp execution.

</details>


### [74] [Generalizable Coarse-to-Fine Robot Manipulation via Language-Aligned 3D Keypoints](https://arxiv.org/abs/2509.23575)
*Jianshu Hu,Lidi Wang,Shujia Li,Yunpeng Jiang,Xiao Li,Paul Weng,Yutong Ban*

Main category: cs.RO

TL;DR: 提出了CLAP框架，通过任务分解、VLM微调进行3D关键点预测和3D感知表示，显著提升了机器人3D操作任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的分层粗到细策略在机器人3D操作任务中虽然提高了样本效率和操作精度，但即使在预训练模型增强下，仍然存在泛化问题，难以适应新指令和环境变化。

Method: CLAP框架包含三个关键组件：任务分解、用于3D关键点预测的VLM微调、以及3D感知表示，通过分层策略实现从粗粒度到细粒度的操作。

Result: 在GemBench基准测试中，平均成功率比SOTA方法提高12%，且仅使用1/5的训练轨迹；在真实机器人实验中，仅用10个演示就能成功泛化到新指令和环境。

Conclusion: CLAP框架通过语言对齐的分层策略有效解决了机器人3D操作中的泛化问题，在样本效率和泛化能力方面都表现出显著优势。

Abstract: Hierarchical coarse-to-fine policy, where a coarse branch predicts a region
of interest to guide a fine-grained action predictor, has demonstrated
significant potential in robotic 3D manipulation tasks by especially enhancing
sample efficiency and enabling more precise manipulation. However, even
augmented with pre-trained models, these hierarchical policies still suffer
from generalization issues. To enhance generalization to novel instructions and
environment variations, we propose Coarse-to-fine Language-Aligned manipulation
Policy (CLAP), a framework that integrates three key components: 1) task
decomposition, 2) VLM fine-tuning for 3D keypoint prediction, and 3) 3D-aware
representation. Through comprehensive experiments in simulation and on a real
robot, we demonstrate its superior generalization capability. Specifically, on
GemBench, a benchmark designed for evaluating generalization, our approach
achieves a 12\% higher average success rate than the SOTA method while using
only 1/5 of the training trajectories. In real-world experiments, our policy,
trained on only 10 demonstrations, successfully generalizes to novel
instructions and environments.

</details>


### [75] [Encoding Material Safety using Control Barrier Functions for Soft Actuator Control](https://arxiv.org/abs/2509.23623)
*Nicholas Pagliocca,Behrad Koohbor,Mitja Trkov*

Main category: cs.RO

TL;DR: 本文提出了软体机器人材料安全的正式定义，基于应变能函数设计控制器来强制执行安全约束，使用高阶控制屏障函数和二次规划反馈控制确保材料安全。


<details>
  <summary>Details</summary>
Motivation: 随着软体机器人向反馈控制发展，需要明确定义安全概念。软体机器人的变形特性使其面临材料失效风险，因此需要设计可证明安全的控制器。

Method: 基于应变能函数定义材料安全，使用高阶控制屏障函数(HOCBF)和二次规划反馈控制来强制执行安全约束，以不可压缩超弹性管为案例研究。

Result: 仿真结果表明，所提出的方法能够有效强制执行材料安全规范，防止材料失效。

Conclusion: 该工作为软体机器人提供了形式化的安全框架，通过控制屏障函数确保材料在安全范围内运行，解决了软体机器人安全控制的关键挑战。

Abstract: Until recently, the concept of soft robot safety was an informal notion,
often attributed solely to the fact that soft robots are less likely to damage
their operating environment than rigid robots. As the field moves toward
feedback control for practical applications, it becomes increasingly important
to define what safety means and to characterize how soft robots can become
unsafe. The unifying theme of soft robotics is to achieve useful functionality
through deformation. Consequently, limitations in constitutive model accuracy
and risks of material failure are inherent to all soft robots and pose a key
challenge in designing provably safe controllers. This work introduces a formal
definition of material safety based on strain energy functions and provides a
controller that enforces it. We characterize safe and unsafe sets of an
incompressible hyperelastic material and demonstrate that safety can be
enforced using a high-order control barrier function (HOCBF) with quadratic
program-based feedback control. As a case study, we consider a pressurized
hyperelastic tube with inertial effects, first-order viscous effects, and
full-state feedback. Simulation results verify that the proposed methodology
can enforce the material safety specification.

</details>


### [76] [KiVi: Kinesthetic-Visuospatial Integration for Dynamic and Safe Egocentric Legged Locomotion](https://arxiv.org/abs/2509.23650)
*Peizhuo Li,Hongyi Li,Yuxuan Ma,Linnan Chang,Xinrong Yang,Ruiqi Yu,Yifeng Zhang,Yuhong Cao,Qiuguo Zhu,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出KiVi框架，通过分离本体感觉和视觉空间推理路径，让四足机器人稳定穿越复杂地形，对视觉噪声和遮挡具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 视觉信息易受遮挡、反射和光照变化影响，导致机器人运动不稳定，需要更鲁棒的感知融合方法。

Method: 分离本体感觉和视觉感知路径，以本体感觉为稳定骨干，选择性整合视觉进行地形感知和避障，结合记忆增强注意力机制。

Result: 四足机器人能稳定穿越多样化地形，在非结构化室外环境中可靠运行，对训练中未见过的视觉噪声和遮挡保持鲁棒性。

Conclusion: KiVi框架通过平衡多模态集成，实现了真实世界腿式机器人的有效和适用性。

Abstract: Vision-based locomotion has shown great promise in enabling legged robots to
perceive and adapt to complex environments. However, visual information is
inherently fragile, being vulnerable to occlusions, reflections, and lighting
changes, which often cause instability in locomotion. Inspired by animal
sensorimotor integration, we propose KiVi, a Kinesthetic-Visuospatial
integration framework, where kinesthetics encodes proprioceptive sensing of
body motion and visuospatial reasoning captures visual perception of
surrounding terrain. Specifically, KiVi separates these pathways, leveraging
proprioception as a stable backbone while selectively incorporating vision for
terrain awareness and obstacle avoidance. This modality-balanced, yet
integrative design, combined with memory-enhanced attention, allows the robot
to robustly interpret visual cues while maintaining fallback stability through
proprioception. Extensive experiments show that our method enables quadruped
robots to stably traverse diverse terrains and operate reliably in unstructured
outdoor environments, remaining robust to out-of-distribution (OOD) visual
noise and occlusion unseen during training, thereby highlighting its
effectiveness and applicability to real-world legged locomotion.

</details>


### [77] [HeLoM: Hierarchical Learning for Whole-Body Loco-Manipulation in Hexapod Robot](https://arxiv.org/abs/2509.23651)
*Xinrong Yang,Peizhuo Li,Hongyi Li,Junkai Lu,Linnan Chang,Yuhong Cao,Yifeng Zhang,Ge Sun,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出HeLoM框架，一种基于学习的六足机器人分层全身操纵系统，通过协调多肢控制实现稳定推重物


<details>
  <summary>Details</summary>
Motivation: 解决机器人在现实环境中推重物时的稳定性和操纵力问题，特别是处理重型或不规则物体时的挑战

Method: 分层框架：高层规划器规划推进行为和目标物体姿态，低层控制器维持运动稳定性并生成动态一致的关节动作；利用冗余接触点和高自由度实现接触力动态重分配

Result: 仿真训练的策略可直接部署到真实机器人无需微调；能稳定推动不同尺寸和未知物理属性的箱子到指定目标姿态

Conclusion: HeLoM框架通过协调多肢控制有效解决了六足机器人推重物时的稳定性和操纵力问题，在真实环境中验证了其有效性

Abstract: Robots in real-world environments are often required to move/manipulate
objects comparable in weight to their own bodies. Compared to grasping and
carrying, pushing provides a more straightforward and efficient non-prehensile
manipulation strategy, avoiding complex grasp design while leveraging direct
contact to regulate an object's pose. Achieving effective pushing, however,
demands both sufficient manipulation forces and the ability to maintain
stability, which is particularly challenging when dealing with heavy or
irregular objects. To address these challenges, we propose HeLoM, a
learning-based hierarchical whole-body manipulation framework for a hexapod
robot that exploits coordinated multi-limb control. Inspired by the cooperative
strategies of multi-legged insects, our framework leverages redundant contact
points and high degrees of freedom to enable dynamic redistribution of contact
forces. HeLoM's high-level planner plans pushing behaviors and target object
poses, while its low-level controller maintains locomotion stability and
generates dynamically consistent joint actions. Our policies trained in
simulation are directly deployed on real robots without additional fine-tuning.
This design allows the robot to maintain balance while exerting continuous and
controllable pushing forces through coordinated foreleg interaction and
supportive hind-leg propulsion. We validate the effectiveness of HeLoM through
both simulation and real-world experiments. Results show that our framework can
stably push boxes of varying sizes and unknown physical properties to
designated goal poses in the real world.

</details>


### [78] [Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models](https://arxiv.org/abs/2509.23655)
*Rokas Bendikas,Daniel Dijkman,Markus Peschl,Sanjay Haresh,Pietro Mazzaglia*

Main category: cs.RO

TL;DR: 提出Oat-VLA方法，通过对象-智能体中心化标记化方案，大幅减少视觉标记数量，实现高效的视觉-语言-动作模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在适应机器人领域时计算成本过高，主要源于视觉输入的标记化方案效率低下。

Method: 基于对象中心表示学习的见解，引入对场景对象和智能体自身视觉信息的归纳偏置，将视觉标记减少到仅几个标记。

Result: 在LIBERO套件上收敛速度至少比OpenVLA快两倍，并在多样化真实世界拾放任务中表现优于OpenVLA。

Conclusion: Oat-VLA方法能显著降低计算成本而不牺牲性能，为高效VLA训练提供了可行方案。

Abstract: Vision-Language-Action (VLA) models offer a pivotal approach to learning
robotic manipulation at scale by repurposing large pre-trained
Vision-Language-Models (VLM) to output robotic actions. However, adapting VLMs
for robotic domains comes with an unnecessarily high computational cost, which
we attribute to the tokenization scheme of visual inputs. In this work, we aim
to enable efficient VLA training by proposing Oat-VLA, an Object-Agent-centric
Tokenization for VLAs. Building on the insights of object-centric
representation learning, our method introduces an inductive bias towards scene
objects and the agent's own visual information. As a result, we find that
Oat-VLA can drastically reduce the number of visual tokens to just a few tokens
without sacrificing performance. We reveal that Oat-VLA converges at least
twice as fast as OpenVLA on the LIBERO suite, as well as outperform OpenVLA in
diverse real-world pick and place tasks.

</details>


### [79] [Certifiably Optimal State Estimation and Robot Calibration Using Trace-Constrained SDP](https://arxiv.org/abs/2509.23656)
*Liangting Wu,Roberto Tron*

Main category: cs.RO

TL;DR: 该论文提出了一种基于迹约束半定规划的方法，用于解决机器人学中的非凸优化问题，通过定制化的固定迹变量和梯度精炼过程来恢复秩1解，并在多个机器人任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人学中的许多非凸问题可以通过半定规划松弛为凸问题以获得全局最优解，但实际解的质量取决于能否获得秩1矩阵，这通常需要额外的紧化处理。

Method: 引入定制化的固定迹变量和约束来表示旋转和平移等机器人量，开发基于梯度的精炼过程将松弛的SDP解投影到秩1、低成本的候选解，并通过对偶问题进行全局最优性认证。

Result: 该方法在透视n点估计、手眼标定和双机器人系统标定等任务中表现出有效性，并通过模块化的"虚拟机器人"抽象简化了不同问题设置下的建模。

Conclusion: 迹约束SDP框架能够有效表达多种机器人任务，通过固定迹约束和精炼过程可以可靠地恢复秩1解，为机器人学中的非凸优化问题提供了实用的解决方案。

Abstract: Many nonconvex problems in robotics can be relaxed into convex formulations
via semidefinite programming (SDP), which offers the advantage of global
optimality. The practical quality of these solutions, however, critically
depends on achieving rank-1 matrices, a condition that typically requires
additional tightening. In this work, we focus on trace-constrained SDPs, where
the decision variables are positive semidefinite (PSD) matrices with fixed
trace values. These additional constraints not only capture important
structural properties but also facilitate first-order methods for recovering
rank-1 solutions. We introduce customized fixed-trace variables and constraints
to represent common robotic quantities such as rotations and translations,
which can be exactly recovered when the corresponding variables are rank-1. To
further improve practical performance, we develop a gradient-based refinement
procedure that projects relaxed SDP solutions toward rank-1, low-cost
candidates, which can then be certified for global optimality via the dual
problem. We demonstrate that many robotics tasks can be expressed within this
trace-constrained SDP framework, and showcase its effectiveness through
simulations in perspective-n-point (PnP) estimation, hand-eye calibration, and
dual-robot system calibration. To support broader use, we also introduce a
modular ``virtual robot'' abstraction that simplifies modeling across different
problem settings.

</details>


### [80] [MDCPP: Multi-robot Dynamic Coverage Path Planning for Workload Adaptation](https://arxiv.org/abs/2509.23705)
*Jun Chen,Mingjia Chen,Shinkyu Park*

Main category: cs.RO

TL;DR: 提出了一种多机器人动态覆盖路径规划算法，通过高斯混合模型估计机器人剩余工作量，使用容量约束Voronoi图分配覆盖区域，解决了传统方法中固定速度假设导致的负载不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人覆盖路径规划方法假设机器人以固定速度移动，这在现实应用中不切实际，导致机器人间工作量分配不平衡和覆盖任务完成时间增加。

Method: 使用高斯混合模型动态估计每个机器人的剩余工作量，采用容量约束Voronoi图分配覆盖区域，并开发了分布式实现以适应通信范围受限的机器人网络。

Result: 仿真结果表明MDCPP算法在定性改进和性能表现上优于现有的扫描算法，并量化了通信范围对覆盖效率的影响。

Conclusion: MDCPP算法通过动态工作量估计和区域分配，有效解决了多机器人覆盖路径规划中的负载平衡问题，提高了覆盖效率。

Abstract: Multi-robot Coverage Path Planning (MCPP) addresses the problem of computing
paths for multiple robots to effectively cover a large area of interest.
Conventional approaches to MCPP typically assume that robots move at fixed
velocities, which is often unrealistic in real-world applications where robots
must adapt their speeds based on the specific coverage tasks assigned to
them.Consequently, conventional approaches often lead to imbalanced workload
distribution among robots and increased completion time for coverage tasks. To
address this, we introduce a novel Multi-robot Dynamic Coverage Path Planning
(MDCPP) algorithm for complete coverage in two-dimensional environments. MDCPP
dynamically estimates each robot's remaining workload by approximating the
target distribution with Gaussian mixture models, and assigns coverage regions
using a capacity-constrained Voronoi diagram. We further develop a distributed
implementation of MDCPP for range-constrained robotic networks. Simulation
results validate the efficacy of MDCPP, showing qualitative improvements and
superior performance compared to an existing sweeping algorithm, and a
quantifiable impact of communication range on coverage efficiency.

</details>


### [81] [DA-MMP: Learning Coordinated and Accurate Throwing with Dynamics-Aware Motion Manifold Primitives](https://arxiv.org/abs/2509.23721)
*Chi Chu,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出DA-MMP框架，用于目标条件动态操作，通过运动流形基元和条件流匹配模型生成考虑执行动力学的投掷轨迹，在环投掷任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法依赖手动设计的动作参数化，难以产生复杂任务所需的高度协调运动；运动规划存在动力学差距问题，导致计划与执行轨迹偏差较大。

Method: 扩展运动流形基元支持变长轨迹，从大规模规划运动数据学习高质量流形，在潜在空间训练条件流匹配模型，结合少量真实世界试验数据。

Result: 能够为环投掷任务生成协调平滑的运动轨迹，在真实世界评估中达到高成功率，甚至超过训练有素的人类专家表现，并能泛化到训练范围外的新目标。

Conclusion: DA-MMP成功学习了轨迹-动力学映射，为动态操作任务提供有效的运动生成框架。

Abstract: Dynamic manipulation is a key capability for advancing robot performance,
enabling skills such as tossing. While recent learning-based approaches have
pushed the field forward, most methods still rely on manually designed action
parameterizations, limiting their ability to produce the highly coordinated
motions required in complex tasks. Motion planning can generate feasible
trajectories, but the dynamics gap-stemming from control inaccuracies, contact
uncertainties, and aerodynamic effects-often causes large deviations between
planned and executed trajectories. In this work, we propose Dynamics-Aware
Motion Manifold Primitives (DA-MMP), a motion generation framework for
goal-conditioned dynamic manipulation, and instantiate it on a challenging
real-world ring-tossing task. Our approach extends motion manifold primitives
to variable-length trajectories through a compact parametrization and learns a
high-quality manifold from a large-scale dataset of planned motions. Building
on this manifold, a conditional flow matching model is trained in the latent
space with a small set of real-world trials, enabling the generation of
throwing trajectories that account for execution dynamics. Experiments show
that our method can generate coordinated and smooth motion trajectories for the
ring-tossing task. In real-world evaluations, it achieves high success rates
and even surpasses the performance of trained human experts. Moreover, it
generalizes to novel targets beyond the training range, indicating that it
successfully learns the underlying trajectory-dynamics mapping.

</details>


### [82] [LocoFormer: Generalist Locomotion via Long-context Adaptation](https://arxiv.org/abs/2509.23745)
*Min Liu,Deepak Pathak,Ananye Agarwal*

Main category: cs.RO

TL;DR: LocoFormer是一个通用的全身运动控制模型，能够控制未见过的腿式和轮式机器人，无需精确的运动学知识，并能适应形态和动态变化。


<details>
  <summary>Details</summary>
Motivation: 现代运动控制器通常需要针对特定机器人进行手动调优，限制了通用性和适应性。

Method: 使用大规模强化学习在程序生成的机器人上进行训练，采用激进的领域随机化，并大幅扩展上下文长度以跨越情节边界。

Result: LocoFormer能够在各种机器人上实现鲁棒控制，即使面对重量变化和电机故障等大扰动，在极端场景中还能跨情节学习改进控制策略。

Conclusion: 这种简单而通用的方法可用于训练未来其他机器人技能的基础模型。

Abstract: Modern locomotion controllers are manually tuned for specific embodiments. We
present LocoFormer, a generalist omni-bodied locomotion model that can control
previously unseen legged and wheeled robots, even without precise knowledge of
their kinematics. LocoFormer is able to adapt to changes in morphology and
dynamics at test time. We find that two key choices enable adaptation. First,
we train massive scale RL on procedurally generated robots with aggressive
domain randomization. Second, in contrast to previous policies that are myopic
with short context lengths, we extend context by orders of magnitude to span
episode boundaries. We deploy the same LocoFormer to varied robots and show
robust control even with large disturbances such as weight change and motor
failures. In extreme scenarios, we see emergent adaptation across episodes,
LocoFormer learns from falls in early episodes to improve control strategies in
later ones. We believe that this simple, yet general recipe can be used to
train foundation models for other robotic skills in the future. Videos at
generalist-locomotion.github.io.

</details>


### [83] [Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse](https://arxiv.org/abs/2509.23778)
*Zeyuan Zhang,Chaoran Li,Shao Zhang,Ying Wen*

Main category: cs.RO

TL;DR: 提出Sequential Pathfinder (SePar)方法，利用Transformer范式实现隐式信息交换，将多智能体路径规划决策复杂度从指数级降低到线性级，在仓库等复杂环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在多智能体拾取配送任务中，在狭窄通道和长走廊的仓库环境中表现不佳，主要依赖局部观察进行分布式决策。点对点通信虽然能缓解全局信息缺失，但带来高计算复杂度。

Method: 将多智能体路径规划建模为序列建模问题，利用Transformer架构实现隐式信息交换，结合模仿学习在复杂地图中的必要性。

Result: SePar在各种多智能体路径规划任务及其变体中始终优于现有基于学习的方法，在未见环境中泛化能力强。

Conclusion: 序列建模方法在多智能体路径规划中具有顺序不变的最优性，Transformer范式能有效降低决策复杂度并保持全局感知能力。

Abstract: Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of
Multi-Agent Path Finding (MAPF), where agents are required to sequentially
complete tasks with fixed-location pickup and delivery demands. Although
learning-based methods have made progress in MAPD, they often perform poorly in
warehouse-like environments with narrow pathways and long corridors when
relying only on local observations for distributed decision-making.
Communication learning can alleviate the lack of global information but
introduce high computational complexity due to point-to-point communication. To
address this challenge, we formulate MAPF as a sequence modeling problem and
prove that path-finding policies under sequence modeling possess
order-invariant optimality, ensuring its effectiveness in MAPD. Building on
this, we propose the Sequential Pathfinder (SePar), which leverages the
Transformer paradigm to achieve implicit information exchange, reducing
decision-making complexity from exponential to linear while maintaining
efficiency and global awareness. Experiments demonstrate that SePar
consistently outperforms existing learning-based methods across various MAPF
tasks and their variants, and generalizes well to unseen environments.
Furthermore, we highlight the necessity of integrating imitation learning in
complex maps like warehouses.

</details>


### [84] [High-Precision Climbing Robot Localization Using Planar Array UWB/GPS/IMU/Barometer Integration](https://arxiv.org/abs/2509.23801)
*Shuning Zhang,Renjing Xu,Zhanchen Zhu,Xiangyu Chen,Yunheng Wang,Xu Jiang,Peibo Duan*

Main category: cs.RO

TL;DR: 提出了一种基于注意力机制的多传感器融合系统，用于高海拔复杂环境中攀爬机器人的精确定位，融合了UWB、GPS、IMU和气压计数据，通过UKF滤波提升定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决单传感器在复杂高海拔环境下定位精度不足的问题，特别是GPS遮挡和UWB非视距传播等挑战。

Method: 设计了注意力机制融合算法(AMFA)，开发了UWB和气压计的端到端神经网络推理模型，采用多模态注意力机制进行自适应数据融合，并应用无迹卡尔曼滤波(UKF)优化轨迹。

Result: 实验结果显示该方法达到0.48米定位精度，最大误差1.50米，优于GPS/INS-EKF等基准算法，具有更强的鲁棒性。

Conclusion: 多传感器融合系统能有效提升攀爬机器人在复杂高海拔环境中的定位性能，为类似应用提供了可行的解决方案。

Abstract: To address the need for high-precision localization of climbing robots in
complex high-altitude environments, this paper proposes a multi-sensor fusion
system that overcomes the limitations of single-sensor approaches. Firstly, the
localization scenarios and the problem model are analyzed. An integrated
architecture of Attention Mechanism-based Fusion Algorithm (AMFA) incorporating
planar array Ultra-Wideband (UWB), GPS, Inertial Measurement Unit (IMU), and
barometer is designed to handle challenges such as GPS occlusion and UWB
Non-Line-of-Sight (NLOS) problem. Then, End-to-end neural network inference
models for UWB and barometer are developed, along with a multimodal attention
mechanism for adaptive data fusion. An Unscented Kalman Filter (UKF) is applied
to refine the trajectory, improving accuracy and robustness. Finally,
real-world experiments show that the method achieves 0.48 m localization
accuracy and lower MAX error of 1.50 m, outperforming baseline algorithms such
as GPS/INS-EKF and demonstrating stronger robustness.

</details>


### [85] [Fostering Robots: A Governance-First Conceptual Framework for Domestic, Curriculum-Based Trajectory Collection](https://arxiv.org/abs/2509.23821)
*Federico Pablo-Marti,Carlos Mir Fernandez*

Main category: cs.RO

TL;DR: 提出了一个概念性的、可实证测试的机器人培养框架，强调课程驱动和治理优先的家庭机器人部署方法，关注长期、精心策划的交互轨迹。


<details>
  <summary>Details</summary>
Motivation: 需要为家庭机器人部署提供一个系统化的框架，确保长期交互质量并符合治理标准，但目前缺乏这样的概念框架和实证验证方法。

Method: 开发了一个概念框架，通过可量化的指标和评估协议来形式化轨迹质量，这些协议与欧盟级治理标准保持一致，并提供了一个低资源实证路线图。

Result: 提出了一个完整的框架，包括轨迹质量的形式化定义、量化指标和评估协议，为未来的试点研究提供了验证基础。

Conclusion: 该框架为机器人培养提供了一个系统化的方法，通过课程驱动和治理优先的策略，能够实现长期、高质量的交互轨迹，并为实证验证提供了可行的路线图。

Abstract: We propose a conceptual, empirically testable framework for Robot Fostering,
-a curriculum-driven, governance-first approach to domestic robot deployments,
emphasizing long-term, curated interaction trajectories. We formalize
trajectory quality with quantifiable metrics and evaluation protocols aligned
with EU-grade governance standards, delineating a low-resource empirical
roadmap to enable rigorous validation through future pilot studies.

</details>


### [86] [Control Your Robot: A Unified System for Robot Control and Policy Deployment](https://arxiv.org/abs/2509.23823)
*Tian Nian,Weijie Ke,Yao Mu,Tianxing Chen,Shaolong Zhu,Bingshan Hu*

Main category: cs.RO

TL;DR: Control Your Robot是一个模块化通用框架，通过标准化工作流、统一API和闭环架构，解决了跨平台机器人控制中的硬件接口、数据格式和控制范式碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 跨平台机器人控制存在困难，因为硬件接口、数据格式和控制范式差异很大，导致工具链碎片化并减缓部署速度。

Method: 采用模块化设计、统一API和闭环架构，支持灵活的机器人注册、遥操作和轨迹回放双模式控制，以及从多模态数据采集到推理的无缝集成。

Result: 在单臂和双臂系统上的实验显示，该框架能够实现高效、低延迟的数据收集，并有效支持模仿学习和视觉语言动作模型的策略学习。

Conclusion: 使用Control Your Robot收集的数据训练的策略与专家演示高度匹配，表明该框架能够实现跨平台的可扩展和可复现的机器人学习。

Abstract: Cross-platform robot control remains difficult because hardware interfaces,
data formats, and control paradigms vary widely, which fragments toolchains and
slows deployment. To address this, we present Control Your Robot, a modular,
general-purpose framework that unifies data collection and policy deployment
across diverse platforms. The system reduces fragmentation through a
standardized workflow with modular design, unified APIs, and a closed-loop
architecture. It supports flexible robot registration, dual-mode control with
teleoperation and trajectory playback, and seamless integration from multimodal
data acquisition to inference. Experiments on single-arm and dual-arm systems
show efficient, low-latency data collection and effective support for policy
learning with imitation learning and vision-language-action models. Policies
trained on data gathered by Control Your Robot match expert demonstrations
closely, indicating that the framework enables scalable and reproducible robot
learning across platforms.

</details>


### [87] [DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation](https://arxiv.org/abs/2509.23829)
*Kefei Zhu,Fengshuo Bai,YuanHao Xiang,Yishuai Cai,Xinglin Chen,Ruochong Li,Xingtao Wang,Hao Dong,Yaodong Yang,Xiaopeng Fan,Yuanpei Chen*

Main category: cs.RO

TL;DR: DexFlyWheel是一个可扩展的数据生成框架，通过自改进循环持续丰富数据多样性，用于灵巧操作任务。


<details>
  <summary>Details</summary>
Motivation: 灵巧操作对提升机器人能力至关重要，但现有数据收集方法依赖人工遥操作或需要大量人工工程，数据多样性有限，限制了可扩展性和泛化能力。

Method: 采用自改进循环框架：从种子演示开始，通过模仿学习提取人类行为，残差强化学习增强策略泛化，在仿真中生成轨迹，并进行数据增强，形成闭环数据飞轮。

Result: 在四个挑战性任务中生成了2000多个多样化演示，训练的策略在挑战测试集上平均成功率达到81.9%，通过数字孪生成功迁移到真实世界，在双臂提升任务中达到78.3%成功率。

Conclusion: DexFlyWheel框架能够有效生成多样化数据集，显著提升策略性能并成功实现从仿真到真实世界的迁移。

Abstract: Dexterous manipulation is critical for advancing robot capabilities in
real-world applications, yet diverse and high-quality datasets remain scarce.
Existing data collection methods either rely on human teleoperation or require
significant human engineering, or generate data with limited diversity, which
restricts their scalability and generalization. In this paper, we introduce
DexFlyWheel, a scalable data generation framework that employs a self-improving
cycle to continuously enrich data diversity. Starting from efficient seed
demonstrations warmup, DexFlyWheel expands the dataset through iterative
cycles. Each cycle follows a closed-loop pipeline that integrates Imitation
Learning (IL), residual Reinforcement Learning (RL), rollout trajectory
collection, and data augmentation. Specifically, IL extracts human-like
behaviors from demonstrations, and residual RL enhances policy generalization.
The learned policy is then used to generate trajectories in simulation, which
are further augmented across diverse environments and spatial configurations
before being fed back into the next cycle. Over successive iterations, a
self-improving data flywheel effect emerges, producing datasets that cover
diverse scenarios and thereby scaling policy performance. Experimental results
demonstrate that DexFlyWheel generates over 2,000 diverse demonstrations across
four challenging tasks. Policies trained on our dataset achieve an average
success rate of 81.9\% on the challenge test sets and successfully transfer to
the real world through digital twin, achieving a 78.3\% success rate on
dual-arm lift tasks.

</details>


### [88] [MAD-PINN: A Decentralized Physics-Informed Machine Learning Framework for Safe and Optimal Multi-Agent Control](https://arxiv.org/abs/2509.23960)
*Manan Tayal,Aditya Singh,Shishir Kolathaya,Somil Bansal*

Main category: cs.RO

TL;DR: 提出了MAD-PINN框架，通过物理信息神经网络解决多智能体状态约束最优控制问题，实现安全与性能的协同优化


<details>
  <summary>Details</summary>
Motivation: 现有MARL、安全过滤或MPC方法在大规模多智能体系统中缺乏严格安全保证、过于保守或难以扩展

Method: 采用基于外延的重构方法同时捕获性能和安全，通过物理信息神经网络近似求解，结合HJ可达性邻居选择策略和滚动时域策略执行

Result: 在多智能体导航任务中实现了优越的安全-性能权衡，随着智能体数量增加保持可扩展性，优于现有最优基线方法

Conclusion: MAD-PINN为大规模多智能体系统提供了可扩展且具有严格安全保证的解决方案

Abstract: Co-optimizing safety and performance in large-scale multi-agent systems
remains a fundamental challenge. Existing approaches based on multi-agent
reinforcement learning (MARL), safety filtering, or Model Predictive Control
(MPC) either lack strict safety guarantees, suffer from conservatism, or fail
to scale effectively. We propose MAD-PINN, a decentralized physics-informed
machine learning framework for solving the multi-agent state-constrained
optimal control problem (MASC-OCP). Our method leverages an epigraph-based
reformulation of SC-OCP to simultaneously capture performance and safety, and
approximates its solution via a physics-informed neural network. Scalability is
achieved by training the SC-OCP value function on reduced-agent systems and
deploying them in a decentralized fashion, where each agent relies only on
local observations of its neighbours for decision-making. To further enhance
safety and efficiency, we introduce an Hamilton-Jacobi (HJ) reachability-based
neighbour selection strategy to prioritize safety-critical interactions, and a
receding-horizon policy execution scheme that adapts to dynamic interactions
while reducing computational burden. Experiments on multi-agent navigation
tasks demonstrate that MAD-PINN achieves superior safety-performance
trade-offs, maintains scalability as the number of agents grows, and
consistently outperforms state-of-the-art baselines.

</details>


### [89] [Prepare for Warp Speed: Sub-millisecond Visual Place Recognition Using Event Cameras](https://arxiv.org/abs/2509.24094)
*Vignesh Ramanathan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Flash是一个轻量级视觉位置识别系统，使用亚毫秒级事件数据片段进行位置预测，通过二进制帧编码活跃像素位置，利用快速位运算计算相似度，显著提升了召回率和定位速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的VPR方法依赖密集表示且需要数十到数百毫秒的事件数据，Flash旨在打破这一范式，实现亚毫秒级的快速位置识别。

Method: 基于活跃像素位置提供强判别特征的观察，使用高效二进制帧编码活跃像素位置，通过快速位运算计算相似度，并根据查询帧和参考帧的相对事件活动进行归一化。

Result: 在室内QCR-Event-Dataset上Recall@1提升11.33倍，在8公里Brisbane-Event-VPR数据集上提升5.92倍，显著减少了机器人无位置感知的运行时间。

Conclusion: 这是首个展示使用事件相机实现亚毫秒级VPR的工作，通过轻量级方法显著提升了定位速度和准确性。

Abstract: Visual Place Recognition (VPR) enables systems to identify previously visited
locations within a map, a fundamental task for autonomous navigation. Prior
works have developed VPR solutions using event cameras, which asynchronously
measure per-pixel brightness changes with microsecond temporal resolution.
However, these approaches rely on dense representations of the inherently
sparse camera output and require tens to hundreds of milliseconds of event data
to predict a place. Here, we break this paradigm with Flash, a lightweight VPR
system that predicts places using sub-millisecond slices of event data. Our
method is based on the observation that active pixel locations provide strong
discriminative features for VPR. Flash encodes these active pixel locations
using efficient binary frames and computes similarities via fast bitwise
operations, which are then normalized based on the relative event activity in
the query and reference frames. Flash improves Recall@1 for sub-millisecond VPR
over existing baselines by 11.33x on the indoor QCR-Event-Dataset and 5.92x on
the 8 km Brisbane-Event-VPR dataset. Moreover, our approach reduces the
duration for which the robot must operate without awareness of its position, as
evidenced by a localization latency metric we term Time to Correct Match (TCM).
To the best of our knowledge, this is the first work to demonstrate
sub-millisecond VPR using event cameras.

</details>


### [90] [Ancestry Tree Clustering for Particle Filter Diversity Maintenance](https://arxiv.org/abs/2509.24124)
*Ilari Vallivaara,Bingnan Duan,Yinhuan Dong,Tughrul Arslan*

Main category: cs.RO

TL;DR: 提出了一种基于粒子祖先树拓扑结构的线性时间多样性维护方法，通过聚类相关粒子来防止多模态环境中的过早收敛。


<details>
  <summary>Details</summary>
Motivation: 在多模态环境中，传统粒子滤波器容易过早收敛，需要有效的多样性维护机制来保持对多个可能状态的跟踪。

Method: 基于粒子祖先树拓扑结构进行聚类，将密切相关的粒子分组，结合簇内适应度共享和未聚类粒子保护机制。

Result: 在多模态机器人仿真和真实室内环境中验证，相比确定性重采样和粒子高斯混合等方法，该方法在保持紧凑性的同时获得高成功率。

Conclusion: 该方法能够有效防止过早收敛，对不同领域和挑战性初始条件表现出强鲁棒性，且对估计紧凑性影响很小。

Abstract: We propose a method for linear-time diversity maintenance in particle
filtering. It clusters particles based on ancestry tree topology: closely
related particles in sufficiently large subtrees are grouped together. The main
idea is that the tree structure implicitly encodes similarity without the need
for spatial or other domain-specific metrics. This approach, when combined with
intra-cluster fitness sharing and the protection of particles not included in a
cluster, effectively prevents premature convergence in multimodal environments
while maintaining estimate compactness. We validate our approach in a
multimodal robotics simulation and a real-world multimodal indoor environment.
We compare the performance to several diversity maintenance algorithms from the
literature, including Deterministic Resampling and Particle Gaussian Mixtures.
Our algorithm achieves high success rates with little to no negative effect on
compactness, showing particular robustness to different domains and challenging
initial conditions.

</details>


### [91] [BOSfM: A View Planning Framework for Optimal 3D Reconstruction of Agricultural Scenes](https://arxiv.org/abs/2509.24126)
*Athanasios Bacharis,Konstantinos D. Polyzos,Georgios B. Giannakis,Nikolaos Papanikolopoulos*

Main category: cs.RO

TL;DR: 提出了一种基于贝叶斯优化的视图规划框架，用于在农业环境中高效优化相机位置，使用少量图像实现准确的3D重建，并能泛化到未知的相似环境。


<details>
  <summary>Details</summary>
Motivation: 解决主动视觉中相机位置噪声和图像噪声对3D重建的影响，以及在不同农业环境中的泛化问题，避免重新优化或重新训练的需求。

Method: 采用基于重建质量的优化方法，利用'运动结构'概念从选定2D图像重建3D结构，使用贝叶斯优化高效执行视图规划过程，仅需少量函数评估。

Result: 在模拟和真实农业环境中的数值测试表明，该方法能有效估计最优相机位置，准确重建3D环境，并在相似未知环境中表现良好。

Conclusion: 所提出的视图规划框架能够高效处理噪声问题，实现准确的3D重建，并具有良好的泛化能力，适用于各种农业应用场景。

Abstract: Active vision (AV) has been in the spotlight of robotics research due to its
emergence in numerous applications including agricultural tasks such as
precision crop monitoring and autonomous harvesting to list a few. A major AV
problem that gained popularity is the 3D reconstruction of targeted
environments using 2D images from diverse viewpoints. While collecting and
processing a large number of arbitrarily captured 2D images can be arduous in
many practical scenarios, a more efficient solution involves optimizing the
placement of available cameras in 3D space to capture fewer, yet more
informative, images that provide sufficient visual information for effective
reconstruction of the environment of interest. This process termed as view
planning (VP), can be markedly challenged (i) by noise emerging in the location
of the cameras and/or in the extracted images, and (ii) by the need to
generalize well in other unknown similar agricultural environments without need
for re-optimizing or re-training. To cope with these challenges, the present
work presents a novel VP framework that considers a reconstruction
quality-based optimization formulation that relies on the notion of
`structure-from-motion' to reconstruct the 3D structure of the sought
environment from the selected 2D images. With no analytic expression of the
optimization function and with costly function evaluations, a Bayesian
optimization approach is proposed to efficiently carry out the VP process using
only a few function evaluations, while accounting for different noise cases.
Numerical tests on both simulated and real agricultural settings signify the
benefits of the advocated VP approach in efficiently estimating the optimal
camera placement to accurately reconstruct 3D environments of interest, and
generalize well on similar unknown environments.

</details>


### [92] [Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress](https://arxiv.org/abs/2509.24129)
*Priyanka Mandikal,Jiaheng Hu,Shivin Dass,Sagnik Majumder,Roberto Martín-Martín,Kristen Grauman*

Main category: cs.RO

TL;DR: SPARTA是一个统一的机器人操作框架，专门处理物体状态变化任务（如捣碎、涂抹、切片等），通过空间渐进式物体变化分割图来感知可操作区域与已变换区域，生成结构化策略观察和密集奖励。


<details>
  <summary>Details</summary>
Motivation: 大多数机器人操作研究关注物体的运动状态变化（如抓取、放置），但现实世界中存在大量涉及物体物理和视觉状态渐进变化的任务，这些任务缺乏统一的处理框架。

Method: SPARTA整合空间渐进式物体变化分割图，通过视觉技能感知特定任务中的可操作与已变换区域，生成结构化策略观察和密集奖励，提供两种策略变体：强化学习用于精细控制，贪婪控制用于快速部署。

Result: 在真实机器人上验证了三个具有挑战性的任务，涉及10种不同的真实物体，相比稀疏奖励和视觉目标条件基线，在训练时间和准确性方面取得了显著改进。

Conclusion: 基于进度感知的视觉表示是处理更广泛物体状态操作任务的多功能基础，SPARTA为这类任务提供了有效的统一解决方案。

Abstract: Most robot manipulation focuses on changing the kinematic state of objects:
picking, placing, opening, or rotating them. However, a wide range of
real-world manipulation tasks involve a different class of object state
change--such as mashing, spreading, or slicing--where the object's physical and
visual state evolve progressively without necessarily changing its position. We
present SPARTA, the first unified framework for the family of object state
change manipulation tasks. Our key insight is that these tasks share a common
structural pattern: they involve spatially-progressing, object-centric changes
that can be represented as regions transitioning from an actionable to a
transformed state. Building on this insight, SPARTA integrates spatially
progressing object change segmentation maps, a visual skill to perceive
actionable vs. transformed regions for specific object state change tasks, to
generate a) structured policy observations that strip away appearance
variability, and b) dense rewards that capture incremental progress over time.
These are leveraged in two SPARTA policy variants: reinforcement learning for
fine-grained control without demonstrations or simulation; and greedy control
for fast, lightweight deployment. We validate SPARTA on a real robot for three
challenging tasks across 10 diverse real-world objects, achieving significant
improvements in training time and accuracy over sparse rewards and visual
goal-conditioned baselines. Our results highlight progress-aware visual
representations as a versatile foundation for the broader family of object
state manipulation tasks. Project website:
https://vision.cs.utexas.edu/projects/sparta-robot

</details>


### [93] [A Novel Model for 3D Motion Planning for a Generalized Dubins Vehicle with Pitch and Yaw Rate Constraints](https://arxiv.org/abs/2509.24143)
*Deepak Prakash Kumar,Swaroop Darbha,Satyanarayana Gupta Manyam,David Casbeer*

Main category: cs.RO

TL;DR: 提出了一种新的3D运动规划建模方法和快速算法，适用于固定翼无人机，考虑完整车辆方向（滚转、俯仰、偏航角）和双控制输入，生成满足运动约束的最短路径。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅考虑俯仰和/或航向角，无法唯一确定方向；且大多依赖单一输入（如路径曲率），无法准确建模3D运动学。需要更完整的车辆方向表示和更准确的控制输入模型。

Method: 使用旋转最小化框架描述车辆配置及其演化，通过连接球面、圆柱面或平面上的最优Dubins路径来构建路径，采用双控制输入表示有界俯仰和偏航速率。

Result: 数值模拟显示该方法平均在10秒内生成可行路径，在大多数情况下比现有方法产生更短的路径。

Conclusion: 该方法能够有效处理完整3D方向约束，通过双控制输入准确建模车辆运动学，在计算效率和路径质量方面优于现有方法。

Abstract: In this paper, we propose a new modeling approach and a fast algorithm for 3D
motion planning, applicable for fixed-wing unmanned aerial vehicles. The goal
is to construct the shortest path connecting given initial and final
configurations subject to motion constraints. Our work differs from existing
literature in two ways. First, we consider full vehicle orientation using a
body-attached frame, which includes roll, pitch, and yaw angles. However,
existing work uses only pitch and/or heading angle, which is insufficient to
uniquely determine orientation. Second, we use two control inputs to represent
bounded pitch and yaw rates, reflecting control by two separate actuators. In
contrast, most previous methods rely on a single input, such as path curvature,
which is insufficient for accurately modeling the vehicle's kinematics in 3D.
We use a rotation minimizing frame to describe the vehicle's configuration and
its evolution, and construct paths by concatenating optimal Dubins paths on
spherical, cylindrical, or planar surfaces. Numerical simulations show our
approach generates feasible paths within 10 seconds on average and yields
shorter paths than existing methods in most cases.

</details>


### [94] [Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation](https://arxiv.org/abs/2509.24160)
*Tomoyuki Kagaya,Subramanian Lakshmi,Yuxuan Lou,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: 提出了Memory Transfer Planning (MTP)框架，利用不同环境中的成功控制代码作为程序知识，通过检索和上下文适应实现跨环境的机器人操作规划，无需更新模型参数。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在机器人操作中的方法难以适应新环境，要么需要环境特定的策略训练，要么依赖固定提示和单次代码生成，导致可迁移性差且需要手动调整。

Method: MTP框架：(i) 使用LLM生成初始计划和代码，(ii) 从代码记忆中检索相关成功示例，(iii) 将检索到的代码上下文适应到目标设置中进行重新规划。

Result: 在RLBench、CALVIN和物理机器人上的评估显示，MTP相比固定提示代码生成、简单检索和无记忆重新规划，持续提高了成功率和适应性。在硬件实验中，利用仿真构建的记忆也证明有效。

Conclusion: MTP提供了一种实用方法，利用程序知识实现跨多样化机器人操作场景的稳健LLM规划，增强了对新环境的适应性，并桥接了仿真和真实世界部署。

Abstract: Large language models (LLMs) are increasingly explored in robot manipulation,
but many existing methods struggle to adapt to new environments. Many systems
require either environment-specific policy training or depend on fixed prompts
and single-shot code generation, leading to limited transferability and manual
re-tuning. We introduce Memory Transfer Planning (MTP), a framework that
leverages successful control-code examples from different environments as
procedural knowledge, using them as in-context guidance for LLM-driven
planning. Specifically, MTP (i) generates an initial plan and code using LLMs,
(ii) retrieves relevant successful examples from a code memory, and (iii)
contextually adapts the retrieved code to the target setting for re-planning
without updating model parameters. We evaluate MTP on RLBench, CALVIN, and a
physical robot, demonstrating effectiveness beyond simulation. Across these
settings, MTP consistently improved success rate and adaptability compared with
fixed-prompt code generation, naive retrieval, and memory-free re-planning.
Furthermore, in hardware experiments, leveraging a memory constructed in
simulation proved effective. MTP provides a practical approach that exploits
procedural knowledge to realize robust LLM-based planning across diverse
robotic manipulation scenarios, enhancing adaptability to novel environments
and bridging simulation and real-world deployment.

</details>


### [95] [Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models](https://arxiv.org/abs/2509.24163)
*Wanming Yu,Adrian Röfer,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 该论文提出使用多模态大语言模型作为机器人高层规划器，通过微调解决长时程容器堆叠任务中物理属性推理不足的问题。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型在需要物理属性推理的长时程机器人操作任务中表现不佳，特别是在涉及隐藏物理属性（如重量、稳定性）的容器堆叠任务中。

Method: 使用多模态LLM作为高层规划器，通过创建考虑重量、稳定性、尺寸和占地面积等堆叠偏好的定制数据集来微调模型，使其能够同时推理多个偏好。

Result: 相比仅使用提示调优的预训练LLM，通过大规模仿真评估显示微调后的LLM在堆叠完成度上有显著提升，并在真实人形机器人上验证了框架的有效性。

Conclusion: 多模态LLM经过定制数据集微调后，能够有效解决长时程机器人堆叠任务中的物理属性推理问题，在仿真和真实环境中均表现出色。

Abstract: Pretrained large language models (LLMs) can work as high-level robotic
planners by reasoning over abstract task descriptions and natural language
instructions, etc. However, they have shown a lack of knowledge and
effectiveness in planning long-horizon robotic manipulation tasks where the
physical properties of the objects are essential. An example is the stacking of
containers with hidden objects inside, which involves reasoning over hidden
physics properties such as weight and stability. To this end, this paper
proposes to use multimodal LLMs as high-level planners for such long-horizon
robotic stacking tasks. The LLM takes multimodal inputs for each object to
stack and infers the current best stacking sequence by reasoning over stacking
preferences. Furthermore, in order to enable the LLM to reason over multiple
preferences at the same time without giving explicit instructions, we propose
to create a custom dataset considering stacking preferences including weight,
stability, size, and footprint, to fine-tune the LLM. Compared to the
pretrained LLM with prompt tuning, we demonstrate the improved stacking
completion of the LLM fine-tuned with our custom dataset via large-scale
simulation evaluation. Furthermore, we showcase the effectiveness of the
proposed framework for the long-horizon stacking task on a real humanoid robot
in an online manner.

</details>


### [96] [Very High Frequency Interpolation for Direct Torque Control](https://arxiv.org/abs/2509.24175)
*Rafael Kourdis,Maciej Stępień,Jérôme Manhes,Nicolas Mansard,Steve Tonneau,Philippe Souères,Thomas Flayols*

Main category: cs.RO

TL;DR: 提出了一种在开源硬件上实现高达40kHz全身线性反馈的新方法，用于稳定扭矩控制器并执行非线性方案


<details>
  <summary>Details</summary>
Motivation: 扭矩控制能实现敏捷和鲁棒的机器人运动，但实际部署常因不稳定性和硬件限制而受阻

Method: 在开源硬件上执行高达40kHz的全身线性反馈，并在实际执行过程中插值非线性方案（如逆动力学和学习扭矩策略）

Result: 通过稳定扭矩控制器，高频线性反馈成为解锁扭矩控制机器人潜力的有效途径

Conclusion: 高频线性反馈是解锁扭矩控制机器人潜力的有效方法

Abstract: Torque control enables agile and robust robot motion, but deployment is often
hindered by instability and hardware limits. Here, we present a novel solution
to execute whole-body linear feedback at up to 40 kHz on open-source hardware.
We use this to interpolate non-linear schemes during real-world execution, such
as inverse dynamics and learned torque policies. Our results show that by
stabilizing torque controllers, high-frequency linear feedback could be an
effective route towards unlocking the potential of torque-controlled robotics.

</details>


### [97] [ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning](https://arxiv.org/abs/2509.24219)
*Tomoyuki Kagaya,Subramanian Lakshmi,Anbang Ye,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: ViReSkill是一个结合视觉重规划和技能记忆的框架，通过LLMs/VLMs进行知识丰富的规划，并在失败时重新规划，成功时将执行计划存储为可重用技能，实现自主持续学习。


<details>
  <summary>Details</summary>
Motivation: 传统RL和模仿学习对新任务适应慢，而LLMs/VLMs虽然能提供知识丰富的规划，但存在符号计划缺乏场景几何和物理基础、输出不稳定等问题。

Method: 提出ViReSkill框架，包括视觉基础的重规划器和技能记忆库。失败时根据当前场景重新规划，成功时将执行计划存储为可重用技能，后续遇到相同情况时直接回放而不调用LLMs/VLMs。

Result: 在LIBERO、RLBench等模拟器和真实机器人上评估，ViReSkill在任务成功率上始终优于传统基线方法，展现了强大的模拟到真实泛化能力。

Conclusion: ViReSkill通过反馈循环实现了自主持续学习，每次尝试都能扩展技能集并稳定后续执行，为解决LLMs/VLMs在运动规划中的落地问题提供了有效方案。

Abstract: Robots trained via Reinforcement Learning (RL) or Imitation Learning (IL)
often adapt slowly to new tasks, whereas recent Large Language Models (LLMs)
and Vision-Language Models (VLMs) promise knowledge-rich planning from minimal
data. Deploying LLMs/VLMs for motion planning, however, faces two key
obstacles: (i) symbolic plans are rarely grounded in scene geometry and object
physics, and (ii) model outputs can vary for identical prompts, undermining
execution reliability. We propose ViReSkill, a framework that pairs
vision-grounded replanning with a skill memory for accumulation and reuse. When
a failure occurs, the replanner generates a new action sequence conditioned on
the current scene, tailored to the observed state. On success, the executed
plan is stored as a reusable skill and replayed in future encounters without
additional calls to LLMs/VLMs. This feedback loop enables autonomous continual
learning: each attempt immediately expands the skill set and stabilizes
subsequent executions. We evaluate ViReSkill on simulators such as LIBERO and
RLBench as well as on a physical robot. Across all settings, it consistently
outperforms conventional baselines in task success rate, demonstrating robust
sim-to-real generalization.

</details>


### [98] [PROFusion: Robust and Accurate Dense Reconstruction via Camera Pose Regression and Optimization](https://arxiv.org/abs/2509.24236)
*Siyan Dong,Zijun Wang,Lulu Cai,Yi Ma,Yanchao Yang*

Main category: cs.RO

TL;DR: 提出一种结合学习式初始化和优化式精化的RGB-D SLAM方法，通过相机姿态回归网络预测相对姿态，再用随机优化算法进行深度图像对齐，在剧烈相机运动下实现实时稠密场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D SLAM系统在相机经历大视角变化、快速运动或突然抖动时会失效。基于优化的方法精度高但对初始化敏感，基于学习的方法鲁棒性好但精度不足。

Method: 使用相机姿态回归网络从连续RGB-D帧预测度量感知的相对姿态作为可靠起点，然后采用随机优化算法将深度图像与场景几何进一步对齐。

Result: 在挑战性基准测试中优于最佳竞争对手，在稳定运动序列上保持相当精度，系统可实时运行。

Conclusion: 结合简单而原则性的技术可以在不稳定运动中实现鲁棒性，同时在稠密重建中保持准确性。

Abstract: Real-time dense scene reconstruction during unstable camera motions is
crucial for robotics, yet current RGB-D SLAM systems fail when cameras
experience large viewpoint changes, fast motions, or sudden shaking. Classical
optimization-based methods deliver high accuracy but fail with poor
initialization during large motions, while learning-based approaches provide
robustness but lack sufficient accuracy for dense reconstruction. We address
this challenge through a combination of learning-based initialization with
optimization-based refinement. Our method employs a camera pose regression
network to predict metric-aware relative poses from consecutive RGB-D frames,
which serve as reliable starting points for a randomized optimization algorithm
that further aligns depth images with the scene geometry. Extensive experiments
demonstrate promising results: our approach outperforms the best competitor on
challenging benchmarks, while maintaining comparable accuracy on stable motion
sequences. The system operates in real-time, showcasing that combining simple
and principled techniques can achieve both robustness for unstable motions and
accuracy for dense reconstruction. Project page:
https://github.com/siyandong/PROFusion.

</details>


### [99] [SafeFlowMatcher: Safe and Fast Planning using Flow Matching with Control Barrier Functions](https://arxiv.org/abs/2509.24243)
*Jeongyong Yang,Seunghwan Jang,Soojean Han*

Main category: cs.RO

TL;DR: SafeFlowMatcher是一个结合流匹配和控制屏障函数的规划框架，通过预测-校正积分器实现实时高效和认证安全，在迷宫导航和运动基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 基于流匹配的生成规划器虽然能快速生成高质量路径，但缺乏正式的安全保证，在约束附近可能产生不完整路径。需要一种既能保持实时效率又能提供认证安全性的方法。

Method: 使用两阶段预测-校正积分器：预测阶段通过流匹配生成候选路径；校正阶段用时间缩放向量场和基于控制屏障函数的二次规划对路径进行最小扰动修正。

Result: 在迷宫导航和运动基准测试中，SafeFlowMatcher获得了比基于扩散和流匹配的基线方法更快、更平滑、更安全的路径。

Conclusion: SafeFlowMatcher通过结合流匹配和控制屏障函数，成功实现了实时高效和认证安全的路径规划，解决了现有方法的安全性和局部陷阱问题。

Abstract: Generative planners based on flow matching (FM) can produce high-quality
paths in one or a few ODE steps, but their sampling dynamics offer no formal
safety guarantees and can yield incomplete paths near constraints. We present
SafeFlowMatcher, a planning framework that couples FM with control barrier
functions (CBFs) to achieve both real-time efficiency and certified safety.
SafeFlowMatcher uses a two-phase prediction-correction (PC) integrator: (i) a
prediction phase integrates the learned FM once (or a few steps) to obtain a
candidate path without intervention; (ii) a correction phase refines this path
with a vanishing time-scaled vector field and a CBF-based quadratic program
that minimally perturbs the vector field. We prove a barrier certificate for
the resulting flow system, establishing forward invariance of a robust safe set
and finite-time convergence to the safe set. By enforcing safety only on the
executed path (rather than on all intermediate latent paths), SafeFlowMatcher
avoids distributional drift and mitigates local trap problems. Across maze
navigation and locomotion benchmarks, SafeFlowMatcher attains faster, smoother,
and safer paths than diffusion- and FM-based baselines. Extensive ablations
corroborate the contributions of the PC integrator and the barrier certificate.

</details>


### [100] [Contextual Neural Moving Horizon Estimation for Robust Quadrotor Control in Varying Conditions](https://arxiv.org/abs/2509.24281)
*Kasra Torshizi,Chak Lam Shek,Khuzema Habib,Guangyao Shi,Pratap Tokekar,Troi Williams*

Main category: cs.RO

TL;DR: 提出一种基于贝叶斯优化和高斯过程的上下文选择策略，用于四旋翼飞行器的自适应控制，避免在所有环境中进行详尽训练，同时保持鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 四旋翼飞行器的自适应控制器需要估计扰动以确保鲁棒轨迹跟踪，但现实环境的多样性和不确定性使得扰动估计具有挑战性。传统方法需要针对特定场景进行大量调优，缺乏灵活性且对条件变化敏感。

Method: 采用顺序决策策略，使用贝叶斯优化和高斯过程来选择收集数据的环境上下文。提出的Contextual NeuroMHE方法通过动态调整神经网络参数，无需在所有环境中进行详尽训练。

Result: 在各种真实环境设置中的实验结果表明，该方法在最大绝对位置误差方面比先前工作提高了20.3%，并且能够通过少量精心选择的上下文捕捉环境变化。

Conclusion: 该方法通过动态调整神经网络参数，提高了四旋翼飞行器自适应控制的效率和泛化能力，在保持鲁棒性能的同时减少了训练需求。

Abstract: Adaptive controllers on quadrotors typically rely on estimation of
disturbances to ensure robust trajectory tracking. Estimating disturbances
across diverse environmental contexts is challenging due to the inherent
variability and uncertainty in the real world. Such estimators require
extensive fine-tuning for a specific scenario, which makes them inflexible and
brittle to changing conditions. Machine-learning approaches, such as training a
neural network to tune the estimator's parameters, are promising. However,
collecting data across all possible environmental contexts is impossible. It is
also inefficient as the same estimator parameters could work for "nearby"
contexts. In this paper, we present a sequential decision making strategy that
decides which environmental contexts, using Bayesian Optimization with a
Gaussian Process, to collect data from in order to ensure robust performance
across a wide range of contexts. Our method, Contextual NeuroMHE, eliminates
the need for exhaustive training across all environments while maintaining
robust performance under different conditions. By enabling the neural network
to adapt its parameters dynamically, our method improves both efficiency and
generalization. Experimental results in various real-world settings demonstrate
that our approach outperforms the prior work by 20.3\% in terms of maximum
absolute position error and can capture the variations in the environment with
a few carefully chosen contexts.

</details>


### [101] [Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning](https://arxiv.org/abs/2509.24313)
*Korbinian Moller,Roland Stroop,Mattia Piccinini,Alexander Langmann,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种混合运动规划框架，结合强化学习指导采样过程，显著减少所需样本数量（最多99%）和运行时间（最多84%），同时保持规划质量。


<details>
  <summary>Details</summary>
Motivation: 在复杂城市驾驶场景中，传统的均匀或启发式采样方法会产生大量不可行或不相关的轨迹，限制了运动规划的效率。

Method: 使用强化学习智能体指导采样过程，将采样引导到可能产生可行轨迹的动作空间区域，同时保持轨迹生成和评估的分析性和可验证性。结合基于可解码深度集编码器的世界模型，支持可变数量的交通参与者。

Result: 在CommonRoad仿真环境中评估，显示所需样本减少高达99%，运行时间减少高达84%，同时保持规划成功率和无碰撞率。

Conclusion: 该方法实现了更快速、更可靠的自动驾驶决策，在现实世界约束下实现了更安全、响应更快的导航。

Abstract: Sampling-based motion planning is a well-established approach in autonomous
driving, valued for its modularity and analytical tractability. In complex
urban scenarios, however, uniform or heuristic sampling often produces many
infeasible or irrelevant trajectories. We address this limitation with a hybrid
framework that learns where to sample while keeping trajectory generation and
evaluation fully analytical and verifiable. A reinforcement learning (RL) agent
guides the sampling process toward regions of the action space likely to yield
feasible trajectories, while evaluation and final selection remains governed by
deterministic feasibility checks and cost functions. We couple the RL sampler
with a world model (WM) based on a decodable deep set encoder, enabling both
variable numbers of traffic participants and reconstructable latent
representations. The approach is evaluated in the CommonRoad simulation
environment, showing up to 99% fewer required samples and a runtime reduction
of up to 84% while maintaining planning quality in terms of success and
collision-free rates. These improvements lead to faster, more reliable
decision-making for autonomous vehicles in urban environments, achieving safer
and more responsive navigation under real-world constraints. Code and trained
artifacts are publicly available at:
https://github.com/TUM-AVS/Learning-to-Sample

</details>


### [102] [SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm](https://arxiv.org/abs/2509.24321)
*Yao Wang,Zhirui Sun,Wenzheng Chi,Baozhi Jia,Wenjun Xu,Jiankun Wang*

Main category: cs.RO

TL;DR: 提出SONAR方法，通过跨模态聚合推理解决视觉语言导航问题，在语义线索弱的环境中实现鲁棒导航


<details>
  <summary>Details</summary>
Motivation: 现有模块化方法依赖训练数据质量且泛化能力差，而基于视觉语言模型的方法在语义线索弱时表现不佳

Method: 集成基于语义图的目标预测模块和基于视觉语言模型的价值图模块，结合多尺度语义图和置信度图策略

Result: 在MP3D数据集上达到38.4%的成功率和17.7%的SPL

Conclusion: SONAR能有效平衡泛化能力和场景适应性，在未知环境中实现鲁棒导航

Abstract: Understanding human instructions and accomplishing Vision-Language Navigation
tasks in unknown environments is essential for robots. However, existing
modular approaches heavily rely on the quality of training data and often
exhibit poor generalization. Vision-Language Model based methods, while
demonstrating strong generalization capabilities, tend to perform
unsatisfactorily when semantic cues are weak. To address these issues, this
paper proposes SONAR, an aggregated reasoning approach through a cross modal
paradigm. The proposed method integrates a semantic map based target prediction
module with a Vision-Language Model based value map module, enabling more
robust navigation in unknown environments with varying levels of semantic cues,
and effectively balancing generalization ability with scene adaptability. In
terms of target localization, we propose a strategy that integrates multi-scale
semantic maps with confidence maps, aiming to mitigate false detections of
target objects. We conducted an evaluation of the SONAR within the Gazebo
simulator, leveraging the most challenging Matterport 3D (MP3D) dataset as the
experimental benchmark. Experimental results demonstrate that SONAR achieves a
success rate of 38.4% and an SPL of 17.7%.

</details>


### [103] [AdaNav: Adaptive Reasoning with Uncertainty for Vision-Language Navigation](https://arxiv.org/abs/2509.24387)
*Xin Ding,Jianyu Wei,Yifan Yang,Shiqi Jiang,Qianxi Zhang,Hao Wu,Fucheng Jia,Liang Mi,Yuxuan Yan,Weijun Wang,Yunxin Liu,Zhibo Chen,Ting Cao*

Main category: cs.RO

TL;DR: AdaNav是一个基于不确定性的自适应推理框架，通过动态触发推理来提升视觉语言导航性能，在少量训练数据下显著超越大规模训练模型。


<details>
  <summary>Details</summary>
Motivation: 视觉语言导航需要智能体根据自然语言指令在长序列视觉观察中进行导航。固定步长的推理往往导致次优性能和冗余计算，需要自适应推理机制。

Method: 提出AdaNav框架，核心是不确定性自适应推理块(UAR)，使用动作熵作为策略先验，通过启发式到强化学习的训练方法逐步优化推理策略。

Result: 仅用6K训练样本，在R2R val-unseen上成功率提升20%，RxR-CE提升11.7%，真实场景提升11.4%，超越百万级数据训练的闭源模型。

Conclusion: AdaNav证明了自适应推理在视觉语言导航中的有效性，能够在严格数据限制下学习难度感知的推理策略，显著提升导航性能。

Abstract: Vision Language Navigation (VLN) requires agents to follow natural language
instructions by grounding them in sequential visual observations over long
horizons. Explicit reasoning could enhance temporal consistency and perception
action alignment, but reasoning at fixed steps often leads to suboptimal
performance and unnecessary computation. To address this, we propose AdaNav, an
uncertainty-based adaptive reasoning framework for VLN. At its core is the
Uncertainty Adaptive Reasoning Block (UAR), a lightweight plugin that
dynamically triggers reasoning. We introduce Action Entropy as a policy prior
for UAR and progressively refine it through a Heuristics to RL training method,
enabling agents to learn difficulty aware reasoning policies under the strict
data limitations of embodied tasks. Results show that with only 6K training
samples, AdaNav achieves substantial gains over closed source models trained on
million scale data, improving success rate by 20% on R2R val-unseen, 11.7% on
RxR-CE, and 11.4% in real world scenes. The code is available at
https://github.com/xinding-sys/AdaNav.

</details>


### [104] [DynaMIC: Dynamic Multimodal In-Context Learning Enabled Embodied Robot Counterfactual Resistance Ability](https://arxiv.org/abs/2509.24413)
*Tianqiang Yan,Ziqiao Lin,Sicheng Wang,Tianwei Zhang,Zhenglong Sun*

Main category: cs.RO

TL;DR: 本文提出了DynaMIC框架，用于识别机器人任务中的误导性指令（DCFs）并主动向人类提供反馈，以提高任务执行的可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究发现严格遵循包含误导信息的人类指令可能导致机器人执行错误，带来安全隐患，这类似于NLP中的反事实概念，但在机器人研究中尚未得到足够重视。

Method: 提出了DynaMIC框架，通过生成机器人任务流程来识别指令反事实（DCFs），并主动向人类传递反馈。

Result: 进行了语义级实验和消融研究，展示了该框架的有效性。

Conclusion: 该框架能帮助机器人对任务中的潜在DCFs保持敏感，从而增强执行过程的可靠性。

Abstract: The emergence of large pre-trained models based on natural language has
breathed new life into robotics development. Extensive research has integrated
large models with robots, utilizing the powerful semantic understanding and
generation capabilities of large models to facilitate robot control through
natural language instructions gradually. However, we found that robots that
strictly adhere to human instructions, especially those containing misleading
information, may encounter errors during task execution, potentially leading to
safety hazards. This resembles the concept of counterfactuals in natural
language processing (NLP), which has not yet attracted much attention in
robotic research. In an effort to highlight this issue for future studies, this
paper introduced directive counterfactuals (DCFs) arising from misleading human
directives. We present DynaMIC, a framework for generating robot task flows to
identify DCFs and relay feedback to humans proactively. This capability can
help robots be sensitive to potential DCFs within a task, thus enhancing the
reliability of the execution process. We conducted semantic-level experiments
and ablation studies, showcasing the effectiveness of this framework.

</details>


### [105] [Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game](https://arxiv.org/abs/2509.24530)
*Giulia Pusceddu,Sara Mongile,Francesco Rea,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 研究使用公共物品游戏探索人机混合群体中的合作与信任，发现参与者倾向于不投资公共池，尽管认为机器人慷慨。


<details>
  <summary>Details</summary>
Motivation: 探索博弈论作为研究人机混合群体中合作与信任的手段，了解机器人在促进群体互动中的信任和凝聚力作用。

Method: 使用改进版公共物品游戏，三名人类参与者与人形机器人iCub互动，测试不同机器人策略（总是合作、总是搭便车、以牙还牙）对参与者合作倾向的影响。

Result: 初步分析表明，尽管参与者认为机器人慷慨，但他们倾向于不向公共池投资资金。

Conclusion: 这项研究为开发能够在人机混合群体中培养信任与合作的社会机器人提供了有价值的见解和潜力。

Abstract: In this study, we explore the potential of Game Theory as a means to
investigate cooperation and trust in human-robot mixed groups. Particularly, we
introduce the Public Good Game (PGG), a model highlighting the tension between
individual self-interest and collective well-being. In this work, we present a
modified version of the PGG, where three human participants engage in the game
with the humanoid robot iCub to assess whether various robot game strategies
(e.g., always cooperate, always free ride, and tit-for-tat) can influence the
participants' inclination to cooperate. We test our setup during a pilot study
with nineteen participants. A preliminary analysis indicates that participants
prefer not to invest their money in the common pool, despite they perceive the
robot as generous. By conducting this research, we seek to gain valuable
insights into the role that robots can play in promoting trust and cohesion
during human-robot interactions within group contexts. The results of this
study may hold considerable potential for developing social robots capable of
fostering trust and cooperation within mixed human-robot groups.

</details>


### [106] [Unlocking the Potential of Soft Actor-Critic for Imitation Learning](https://arxiv.org/abs/2509.24539)
*Nayari Marie Lessa,Melya Boukheddimi,Frank Kirchner*

Main category: cs.RO

TL;DR: 提出了一种结合对抗运动先验(AMP)和软演员-评论家(SAC)的模仿学习框架，相比主流的AMP+PPO方法，在四足机器人步态学习中实现了更高的样本效率和模仿奖励。


<details>
  <summary>Details</summary>
Motivation: 当前基于PPO的模仿学习方法虽然稳定但样本效率低、策略泛化能力有限，需要更高效的学习框架来提升机器人运动生成的自然性和适应性。

Method: 将对抗运动先验(AMP)与离策略的软演员-评论家(SAC)算法结合，利用经验回放驱动学习和熵正则化探索，在四足机器人多种步态和地形上进行评估。

Result: 实验表明，AMP+SAC框架不仅能保持稳定的任务执行，还比广泛使用的AMP+PPO方法获得更高的模仿奖励，证明了离策略IL公式在机器人运动生成中的潜力。

Conclusion: 离策略模仿学习框架通过结合AMP和SAC，显著提升了机器人运动学习的样本效率和自然性，为机器人运动生成提供了新的发展方向。

Abstract: Learning-based methods have enabled robots to acquire bio-inspired movements
with increasing levels of naturalness and adaptability. Among these, Imitation
Learning (IL) has proven effective in transferring complex motion patterns from
animals to robotic systems. However, current state-of-the-art frameworks
predominantly rely on Proximal Policy Optimization (PPO), an on-policy
algorithm that prioritizes stability over sample efficiency and policy
generalization. This paper proposes a novel IL framework that combines
Adversarial Motion Priors (AMP) with the off-policy Soft Actor-Critic (SAC)
algorithm to overcome these limitations. This integration leverages
replay-driven learning and entropy-regularized exploration, enabling
naturalistic behavior and task execution, improving data efficiency and
robustness. We evaluate the proposed approach (AMP+SAC) on quadruped gaits
involving multiple reference motions and diverse terrains. Experimental results
demonstrate that the proposed framework not only maintains stable task
execution but also achieves higher imitation rewards compared to the widely
used AMP+PPO method. These findings highlight the potential of an off-policy IL
formulation for advancing motion generation in robotics.

</details>


### [107] [Prompting Robot Teams with Natural Language](https://arxiv.org/abs/2509.24575)
*Nicolas Pfitzer,Eduardo Sebastián,Ajay Shankar,Amanda Prorok*

Main category: cs.RO

TL;DR: 提出了一个使用自然语言提示多机器人团队执行高级任务的框架，将语言模型的推理能力与多机器人协作相结合。


<details>
  <summary>Details</summary>
Motivation: 利用最近语言模型在理解人类意图表达方面的推理能力，将其重新用于多机器人协作和决策制定。关键挑战在于集体中个体行为难以指定和解释，需要持续适应其他机器人的行动。

Method: 将任务表示为确定性有限自动机(DFA)，使用循环神经网络(RNN)编码多个自动机。将语言模型获得的逻辑和子任务序列分解提炼到RNN中，并将其内部状态与任务语义对齐。训练基于RNN隐藏状态和语言嵌入的图神经网络(GNN)控制策略。

Result: 在需要顺序和协作行为的各种模拟和真实世界多机器人任务上评估了这种轻量级可解释模型。

Conclusion: 该方法使机器人能够以分散方式执行与任务相关的动作，解决了多机器人协作中的逻辑表示和实时操作需求。

Abstract: This paper presents a framework towards prompting multi-robot teams with
high-level tasks using natural language expressions. Our objective is to use
the reasoning capabilities demonstrated by recent language models in
understanding and decomposing human expressions of intent, and repurpose these
for multi-robot collaboration and decision-making. The key challenge is that an
individual's behavior in a collective can be hard to specify and interpret, and
must continuously adapt to actions from others. This necessitates a framework
that possesses the representational capacity required by the logic and
semantics of a task, and yet supports decentralized and interactive real-time
operation. We solve this dilemma by recognizing that a task can be represented
as a deterministic finite automaton (DFA), and that recurrent neural networks
(RNNs) can encode numerous automata. This allows us to distill the logic and
sequential decompositions of sub-tasks obtained from a language model into an
RNN, and align its internal states with the semantics of a given task. By
training a graph neural network (GNN) control policy that is conditioned on the
hidden states of the RNN and the language embeddings, our method enables robots
to execute task-relevant actions in a decentralized manner. We present
evaluations of this single light-weight interpretable model on various
simulated and real-world multi-robot tasks that require sequential and
collaborative behavior by the team -- sites.google.com/view/prompting-teams.

</details>


### [108] [U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation](https://arxiv.org/abs/2509.24579)
*Linzhi Wu,Aoran Mei,Xiyue Wang,Guo-Niu Zhu,Zhongxue Gan*

Main category: cs.RO

TL;DR: 提出U-DiT Policy，一种U形扩散Transformer框架，结合U-Net的多尺度特征融合优势和Transformer的全局上下文建模能力，在机器人操作任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的机器人控制方法主要采用U-Net架构（DP-U），存在全局上下文建模能力有限和过度平滑伪影的问题，需要改进。

Method: 设计U形扩散Transformer框架，在保持U-Net多尺度特征融合优势的同时，集成Transformer的全局上下文建模能力。

Result: 在仿真任务中平均性能提升10%，比基于Transformer的扩散策略（DP-T）高6%；在真实机器人任务中平均提升22.5%，在干扰和光照变化下表现出更强的鲁棒性和泛化能力。

Conclusion: U-DiT Policy作为基于扩散的机器人操作新基础框架，展现出有效性和实际应用潜力。

Abstract: Diffusion-based methods have been acknowledged as a powerful paradigm for
end-to-end visuomotor control in robotics. Most existing approaches adopt a
Diffusion Policy in U-Net architecture (DP-U), which, while effective, suffers
from limited global context modeling and over-smoothing artifacts. To address
these issues, we propose U-DiT Policy, a novel U-shaped Diffusion Transformer
framework. U-DiT preserves the multi-scale feature fusion advantages of U-Net
while integrating the global context modeling capability of Transformers,
thereby enhancing representational power and policy expressiveness. We evaluate
U-DiT extensively across both simulation and real-world robotic manipulation
tasks. In simulation, U-DiT achieves an average performance gain of 10\% over
baseline methods and surpasses Transformer-based diffusion policies (DP-T) that
use AdaLN blocks by 6\% under comparable parameter budgets. On real-world
robotic tasks, U-DiT demonstrates superior generalization and robustness,
achieving an average improvement of 22.5\% over DP-U. In addition, robustness
and generalization experiments under distractor and lighting variations further
highlight the advantages of U-DiT. These results highlight the effectiveness
and practical potential of U-DiT Policy as a new foundation for diffusion-based
robotic manipulation.

</details>


### [109] [PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control](https://arxiv.org/abs/2509.24591)
*Haozhuo Zhang,Michele Caprio,Jing Shao,Qiang Zhang,Jian Tang,Shanghang Zhang,Wei Pan*

Main category: cs.RO

TL;DR: PoseDiff是一个统一的扩散模型，将机器人状态估计和控制整合到单一框架中，通过单张RGB图像实现状态估计，并通过视频关键帧生成连续动作序列。


<details>
  <summary>Details</summary>
Motivation: 消除多阶段流程和辅助模态的需求，实现感知与控制的统一集成，为具身AI提供可扩展、准确且高效的桥梁。

Method: 使用条件扩散模型，从单张RGB图像映射到结构化机器人状态（3D关键点或关节角度），并基于世界模型生成的关键帧进行视频到动作的逆动力学建模，采用重叠平均策略生成平滑连续的长时域动作序列。

Result: 在DREAM数据集上实现最先进的姿态估计精度和实时性能；在Libero-Object操作任务中，即使在严格离线设置下也显著提高了成功率。

Conclusion: PoseDiff为具身AI中的感知、规划和控制提供了可扩展、准确且高效的统一解决方案。

Abstract: We present PoseDiff, a conditional diffusion model that unifies robot state
estimation and control within a single framework. At its core, PoseDiff maps
raw visual observations into structured robot states-such as 3D keypoints or
joint angles-from a single RGB image, eliminating the need for multi-stage
pipelines or auxiliary modalities. Building upon this foundation, PoseDiff
extends naturally to video-to-action inverse dynamics: by conditioning on
sparse video keyframes generated by world models, it produces smooth and
continuous long-horizon action sequences through an overlap-averaging strategy.
This unified design enables scalable and efficient integration of perception
and control. On the DREAM dataset, PoseDiff achieves state-of-the-art accuracy
and real-time performance for pose estimation. On Libero-Object manipulation
tasks, it substantially improves success rates over existing inverse dynamics
modules, even under strict offline settings. Together, these results show that
PoseDiff provides a scalable, accurate, and efficient bridge between
perception, planning, and control in embodied AI. The video visualization
results can be found on the project page:
https://haozhuo-zhang.github.io/PoseDiff-project-page/.

</details>


### [110] [CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations](https://arxiv.org/abs/2509.24661)
*Zhiyuan Wu,Rolandos Alexandros Potamias,Xuyang Zhang,Zhongqun Zhang,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: 提出CEDex方法，通过将机器人运动学模型与生成的人类接触表示对齐，实现跨形态灵巧抓取合成。该方法首先生成人类接触表示，然后进行运动学对齐和物理约束优化，构建了包含500K对象和20M抓取的最大跨形态抓取数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖缺乏人类运动学理解的物理优化，要么需要局限于拟人结构的手动数据收集过程。需要一种能够桥接人类抓取运动学和机器人运动学的方法，以生成可靠多样的抓取数据。

Method: 1. 使用在人类接触数据上预训练的条件变分自编码器生成人类接触表示；2. 通过拓扑合并进行运动学人类接触对齐，将多人手部件合并为统一机器人组件；3. 基于符号距离场的抓取优化，包含物理感知约束。

Result: 构建了迄今为止最大的跨形态抓取数据集，包含500K对象、四种夹爪类型，总计20M抓取。实验表明CEDex优于最先进方法，数据集为跨形态抓取学习提供了高质量多样化的抓取。

Conclusion: CEDex成功桥接了人类抓取运动学和机器人运动学，通过人类接触表示对齐和物理约束优化，实现了有效的跨形态灵巧抓取合成，并创建了大规模高质量数据集。

Abstract: Cross-embodiment dexterous grasp synthesis refers to adaptively generating
and optimizing grasps for various robotic hands with different morphologies.
This capability is crucial for achieving versatile robotic manipulation in
diverse environments and requires substantial amounts of reliable and diverse
grasp data for effective model training and robust generalization. However,
existing approaches either rely on physics-based optimization that lacks
human-like kinematic understanding or require extensive manual data collection
processes that are limited to anthropomorphic structures. In this paper, we
propose CEDex, a novel cross-embodiment dexterous grasp synthesis method at
scale that bridges human grasping kinematics and robot kinematics by aligning
robot kinematic models with generated human-like contact representations. Given
an object's point cloud and an arbitrary robotic hand model, CEDex first
generates human-like contact representations using a Conditional Variational
Auto-encoder pretrained on human contact data. It then performs kinematic human
contact alignment through topological merging to consolidate multiple human
hand parts into unified robot components, followed by a signed distance
field-based grasp optimization with physics-aware constraints. Using CEDex, we
construct the largest cross-embodiment grasp dataset to date, comprising 500K
objects across four gripper types with 20M total grasps. Extensive experiments
show that CEDex outperforms state-of-the-art approaches and our dataset
benefits cross-embodiment grasp learning with high-quality diverse grasps.

</details>


### [111] [LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers](https://arxiv.org/abs/2509.24706)
*Andreea Tulbure,Rene Zurbruegg,Timm Grigat,Marco Hutter*

Main category: cs.RO

TL;DR: LLM-Handover是一个集成大型语言模型推理和部件分割的框架，用于实现上下文感知的机器人-人类物体传递，优化传递后的可用性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人传递方法往往忽视人类接收后的使用意图，限制了通用性。需要开发能够理解任务上下文并优化传递后可用性的系统。

Method: 结合LLM推理和部件分割，根据RGB-D图像和任务描述推断相关物体部件，选择优化传递后可用性的抓取方式。

Result: 在零样本设置下达到83%的成功率，用户研究中86%的参与者更偏好该方法，表明其能实现更直观、上下文感知的传递。

Conclusion: LLM-Handover框架通过集成语言模型推理和计算机视觉，显著提升了机器人-人类物体传递的性能和用户体验。

Abstract: Effective human-robot collaboration depends on task-oriented handovers, where
robots present objects in ways that support the partners intended use. However,
many existing approaches neglect the humans post-handover action, relying on
assumptions that limit generalizability. To address this gap, we propose
LLM-Handover, a novel framework that integrates large language model
(LLM)-based reasoning with part segmentation to enable context-aware grasp
selection and execution. Given an RGB-D image and a task description, our
system infers relevant object parts and selects grasps that optimize
post-handover usability. To support evaluation, we introduce a new dataset of
60 household objects spanning 12 categories, each annotated with detailed part
labels. We first demonstrate that our approach improves the performance of the
used state-of-the-art part segmentation method, in the context of robot-human
handovers. Next, we show that LLM-Handover achieves higher grasp success rates
and adapts better to post-handover task constraints. During hardware
experiments, we achieve a success rate of 83% in a zero-shot setting over
conventional and unconventional post-handover tasks. Finally, our user study
underlines that our method enables more intuitive, context-aware handovers,
with participants preferring it in 86% of cases.

</details>


### [112] [APREBot: Active Perception System for Reflexive Evasion Robot](https://arxiv.org/abs/2509.24733)
*Zihao Xu,Kuankuan Sima,Junhao Deng,Zixuan Zhuang,Chunzheng Wang,Ce Hao,Jin Song Dong*

Main category: cs.RO

TL;DR: APREBot是一个用于四足机器人的主动感知系统，结合LiDAR全向扫描和相机主动聚焦，实现动态环境中的敏捷避障。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在动态环境中需要可靠的感知能力，但单传感器系统存在局限性：LiDAR缺乏纹理信息，相机视野受限。

Method: 集成反射式规避与主动分层感知，策略性地结合LiDAR全向扫描和相机主动聚焦。

Result: 通过sim-to-real实验验证，在安全指标和操作效率上显著优于现有基准方法。

Conclusion: APREBot在安全关键场景中具有可靠自主性的潜力。

Abstract: Reliable onboard perception is critical for quadruped robots navigating
dynamic environments, where obstacles can emerge from any direction under
strict reaction-time constraints. Single-sensor systems face inherent
limitations: LiDAR provides omnidirectional coverage but lacks rich texture
information, while cameras capture high-resolution detail but suffer from
restricted field of view. We introduce APREBot (Active Perception System for
Reflexive Evasion Robot), a novel framework that integrates reflexive evasion
with active hierarchical perception. APREBot strategically combines LiDAR-based
omnidirectional scanning with camera-based active focusing, achieving
comprehensive environmental awareness essential for agile obstacle avoidance in
quadruped robots. We validate APREBot through extensive sim-to-real experiments
on a quadruped platform, evaluating diverse obstacle types, trajectories, and
approach directions. Our results demonstrate substantial improvements over
state-of-the-art baselines in both safety metrics and operational efficiency,
highlighting APREBot's potential for dependable autonomy in safety-critical
scenarios. Videos are available at https://sites.google.com/view/aprebot/

</details>


### [113] [SSR-ZSON: Zero-Shot Object Navigation via Spatial-Semantic Relations within a Hierarchical Exploration Framework](https://arxiv.org/abs/2509.24763)
*Xiangyi Meng,Delun Li,Zihao Mao,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: SSR-ZSON是一种基于空间语义相对性的零样本物体导航方法，通过结合平衡空间覆盖和语义密度的视点生成策略与基于LLM的全局引导机制，解决了零样本物体导航中的语义引导不足和空间记忆受限问题。


<details>
  <summary>Details</summary>
Motivation: 零样本物体导航面临两个主要挑战：语义引导不足导致探索效率低下，以及环境结构导致的空间记忆受限使智能体容易陷入局部区域。

Method: 基于TARE分层探索框架，提出视点生成策略优先考虑可遍历子区域内的高语义密度区域，并结合基于LLM的全局引导机制评估语义关联，引导导航朝向高价值空间。

Result: 在Matterport3D和Habitat-Matterport3D数据集上，相比最先进方法，成功率分别提高18.5%和11.2%，路径长度加权成功率分别提高0.181和0.140。

Conclusion: SSR-ZSON通过空间语义相对性方法实现了实时操作和优越性能，有效解决了零样本物体导航中的探索效率和局部陷阱问题。

Abstract: Zero-shot object navigation in unknown environments presents significant
challenges, mainly due to two key limitations: insufficient semantic guidance
leads to inefficient exploration, while limited spatial memory resulting from
environmental structure causes entrapment in local regions. To address these
issues, we propose SSR-ZSON, a spatial-semantic relative zero-shot object
navigation method based on the TARE hierarchical exploration framework,
integrating a viewpoint generation strategy balancing spatial coverage and
semantic density with an LLM-based global guidance mechanism. The performance
improvement of the proposed method is due to two key innovations. First, the
viewpoint generation strategy prioritizes areas of high semantic density within
traversable sub-regions to maximize spatial coverage and minimize invalid
exploration. Second, coupled with an LLM-based global guidance mechanism, it
assesses semantic associations to direct navigation toward high-value spaces,
preventing local entrapment and ensuring efficient exploration. Deployed on
hybrid Habitat-Gazebo simulations and physical platforms, SSR-ZSON achieves
real-time operation and superior performance. On Matterport3D and
Habitat-Matterport3D datasets, it improves the Success Rate(SR) by 18.5\% and
11.2\%, and the Success weighted by Path Length(SPL) by 0.181 and 0.140,
respectively, over state-of-the-art methods.

</details>


### [114] [IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks](https://arxiv.org/abs/2509.24768)
*Eric Hannus,Miika Malin,Tran Nguyen Le,Ville Kyrki*

Main category: cs.RO

TL;DR: IA-VLA框架利用大型视觉语言模型的强大语言理解能力作为预处理阶段，为视觉语言动作模型生成改进的上下文输入，以处理需要复杂语言指令的机器人操作任务。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型由于需要满足机器人控制的实时性要求，限制了语言模型的规模，从而影响了其语言理解能力。而机器人操作任务往往需要处理复杂的语言指令，如通过相对位置识别目标物体。

Method: 提出IA-VLA框架，使用大型视觉语言模型作为预处理阶段，生成增强的上下文信息来改善视觉语言动作模型的输入。在包含视觉重复对象（外观无法区分的物体）的复杂语义任务上进行评估。

Result: 实验表明，视觉语言动作模型从增强方案中受益，特别是在面对需要从演示中概念外推的语言指令时表现更好。

Conclusion: IA-VLA框架通过利用大型视觉语言模型的强大语言理解能力，有效提升了视觉语言动作模型处理复杂语义任务的能力。

Abstract: Vision-language-action models (VLAs) have become an increasingly popular
approach for addressing robot manipulation problems in recent years. However,
such models need to output actions at a rate suitable for robot control, which
limits the size of the language model they can be based on, and consequently,
their language understanding capabilities. Manipulation tasks may require
complex language instructions, such as identifying target objects by their
relative positions, to specify human intention. Therefore, we introduce IA-VLA,
a framework that utilizes the extensive language understanding of a large
vision language model as a pre-processing stage to generate improved context to
augment the input of a VLA. We evaluate the framework on a set of semantically
complex tasks which have been underexplored in VLA literature, namely tasks
involving visual duplicates, i.e., visually indistinguishable objects. A
dataset of three types of scenes with duplicate objects is used to compare a
baseline VLA against two augmented variants. The experiments show that the VLA
benefits from the augmentation scheme, especially when faced with language
instructions that require the VLA to extrapolate from concepts it has seen in
the demonstrations. For the code, dataset, and videos, see
https://sites.google.com/view/ia-vla.

</details>


### [115] [Fidelity-Aware Data Composition for Robust Robot Generalization](https://arxiv.org/abs/2509.24797)
*Zizhao Tong,Di Chen,Sicheng Hu,Hongwei Fan,Liliang Chen,Guanghui Ren,Hao Tang,Hao Dong,Ling Shao*

Main category: cs.RO

TL;DR: 本文提出了CIFT框架，通过保真度感知的数据组合优化来提升机器人策略的分布外泛化能力，避免视觉多样性增强导致的信息保真度损失。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略在大规模视觉同质数据集上训练容易陷入捷径学习，影响分布外泛化。传统生成式数据增强方法虽然引入多样性，但可能因数据组合不当而损害学习信号。

Method: 提出CIFT框架，将数据组合视为优化问题，基于数据集特征空间几何定义信息保真度代理指标，识别训练稳定性下降的退相干点。使用多视图视频增强生成因果解缠的数据谱进行调优。

Result: 在π₀和Diffusion Policy等策略架构上应用CIFT，分布外成功率提升超过54%。

Conclusion: 保真度感知的数据组合（而不仅仅是数据合成）是开发鲁棒通用机器人的重要组成部分。

Abstract: Generalist robot policies trained on large-scale, visually homogeneous
datasets can be susceptible to shortcut learning, which impairs their
out-of-distribution (OOD) generalization. While generative data augmentation is
a common approach to introduce diversity, it presents a subtle challenge: data
composition. Naively mixing real and synthetic data can corrupt the learning
signal, as this process often prioritizes visual diversity at the expense of
information fidelity. This paper suggests that robust generalization depends on
principled, fidelity-aware data composition. We introduce Coherent Information
Fidelity Tuning (CIFT), a framework that treats data composition as an
optimization problem. CIFT uses a practical proxy for Information Fidelity
based on the feature-space geometry of a dataset. This enables the
identification of a phase transition, termed the Decoherence Point, where
training stability degrades. The framework includes a generative engine,
Multi-View Video Augmentation (MVAug), to synthesize a causally disentangled
data spectrum for this tuning process. Applying CIFT to policy architectures
such as $\pi_0$ and Diffusion Policy improves OOD success rates by over 54\%.
These results indicate that fidelity-aware composition, beyond data synthesis
alone, is an important component for developing robust, general-purpose robots.

</details>


### [116] [Towards Modular and Accessible AUV Systems](https://arxiv.org/abs/2509.24864)
*Mingxi Zhou,Farhang Naderi,Yuewei Fu,Tony Jacob,Lin Zhao,Manavi Panjnani,Chengzhi Yuan,William McConnell,Emir Cem Gezer*

Main category: cs.RO

TL;DR: 开发了名为Marine Vehicle Packages (MVP)的开源模块化框架，用于自主水下航行器，包含软硬件设计，支持定制化和有效载荷能力。


<details>
  <summary>Details</summary>
Motivation: 为研究目的提供易于构建、高度可定制且具有足够有效载荷能力的自主水下航行器框架。

Method: 采用可扩展的硬件系统设计和模块化软件架构，集成关节推进器和高层图形用户界面等新特性。

Result: 通过仿真和现场实验验证了MVP的性能和兼容性。

Conclusion: MVP框架成功实现了自主水下航行器的模块化设计，具有良好的性能和兼容性。

Abstract: This paper reports the development of a new open-access modular framework,
called Marine Vehicle Packages (MVP), for Autonomous Underwater Vehicles. The
framework consists of both software and hardware designs allowing easy
construction of AUV for research with increased customizability and sufficient
payload capacity. This paper will present the scalable hardware system design
and the modular software design architecture. New features, such as articulated
thruster integration and high-level Graphic User Interface will be discussed.
Both simulation and field experiments results are shown to highlight the
performance and compatibility of the MVP.

</details>


### [117] [Finding an Initial Probe Pose in Teleoperated Robotic Echocardiography via 2D LiDAR-Based 3D Reconstruction](https://arxiv.org/abs/2509.24867)
*Mariadas Capsran Roshan,Edgar M Hidalgo,Mats Isaksson,Michelle Dunn,Jagannatha Charjee Pyaraka*

Main category: cs.RO

TL;DR: 提出使用机器人安装的2D LiDAR进行3D胸部表面重建，自动估计超声探头初始姿态，以解决远程机器人超声检查时间过长的问题。


<details>
  <summary>Details</summary>
Motivation: 远程机器人超声检查虽然能解决偏远地区缺乏专业超声医师的问题，但检查时间比手动操作更长，增加了诊断延迟和操作员负担。现有基于视觉和深度的探头姿态估计方法对光照、纹理和解剖变异敏感。

Method: 使用机器人安装的2D LiDAR重建胸部3D表面，通过基于平面的外参标定估计LiDAR与机器人基座之间的变换关系，然后通过非刚性模板配准识别初始探头姿态。

Result: 外参标定RMS残差1.8mm，旋转不确定性低于0.2度；人体模型重建精度平均表面误差2.78±0.21mm；人体试验中初始点距离临床定义点20-30mm，同一受试者重复试验变异小于4mm。

Conclusion: 机器人安装的2D LiDAR能够准确重建人体胸部表面并自动估计超声探头初始姿态，为减少远程机器人超声检查时间提供了可行方案。

Abstract: Echocardiography is a key imaging modality for cardiac assessment but remains
highly operator-dependent, and access to trained sonographers is limited in
underserved settings. Teleoperated robotic echocardiography has been proposed
as a solution; however, clinical studies report longer examination times than
manual procedures, increasing diagnostic delays and operator workload.
Automating non-expert tasks, such as automatically moving the probe to an ideal
starting pose, offers a pathway to reduce this burden. Prior vision- and
depth-based approaches to estimate an initial probe pose are sensitive to
lighting, texture, and anatomical variability. We propose a robot-mounted 2D
LiDAR-based approach that reconstructs the chest surface in 3D and estimates
the initial probe pose automatically. To the best of our knowledge, this is the
first demonstration of robot-mounted 2D LiDAR used for 3D reconstruction of a
human body surface. Through plane-based extrinsic calibration, the
transformation between the LiDAR and robot base frames was estimated with an
overall root mean square (RMS) residual of 1.8 mm and rotational uncertainty
below 0.2{\deg}. The chest front surface, reconstructed from two linear LiDAR
sweeps, was aligned with non-rigid templates to identify an initial probe pose.
A mannequin-based study assessing reconstruction accuracy showed mean surface
errors of 2.78 +/- 0.21 mm. Human trials (N=5) evaluating the proposed approach
found probe initial points typically 20-30 mm from the clinically defined
initial point, while the variation across repeated trials on the same subject
was less than 4 mm.

</details>


### [118] [JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning](https://arxiv.org/abs/2509.24892)
*Shilong Ji,Yinuo Chen,Chuqi Wang,Jiayu Chen,Ruize Zhang,Feng Gao,Wenhao Tang,Shu'ang Yu,Sirui Xiang,Xinlei Chen,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: JuggleRL是首个基于强化学习的空中杂耍系统，通过大规模仿真训练闭环策略，在真实四旋翼无人机上实现零样本部署，平均能连续击球311次，远超传统方法。


<details>
  <summary>Details</summary>
Motivation: 空中机器人与物体交互需要在不确定性下执行精确的接触式操作，空中球类杂耍任务对时机准确性、稳定控制和持续适应能力提出了很高要求。

Method: 使用系统校准的四旋翼和球体动力学减少仿真到现实的差距，通过奖励塑造鼓励球拍中心击球和持续杂耍，采用球位置和恢复系数的领域随机化增强鲁棒性，学习策略输出中层级命令由底层控制器执行。

Result: 在真实硬件上平均连续击球311次（最高462次），远超基于模型的方法（平均3.1次，最多14次），并能泛化到未见条件，对5克轻球平均击球145.9次。

Conclusion: 强化学习能够赋予空中机器人在动态交互任务中实现鲁棒和稳定的控制能力。

Abstract: Aerial robots interacting with objects must perform precise, contact-rich
maneuvers under uncertainty. In this paper, we study the problem of aerial ball
juggling using a quadrotor equipped with a racket, a task that demands accurate
timing, stable control, and continuous adaptation. We propose JuggleRL, the
first reinforcement learning-based system for aerial juggling. It learns
closed-loop policies in large-scale simulation using systematic calibration of
quadrotor and ball dynamics to reduce the sim-to-real gap. The training
incorporates reward shaping to encourage racket-centered hits and sustained
juggling, as well as domain randomization over ball position and coefficient of
restitution to enhance robustness and transferability. The learned policy
outputs mid-level commands executed by a low-level controller and is deployed
zero-shot on real hardware, where an enhanced perception module with a
lightweight communication protocol reduces delays in high-frequency state
estimation and ensures real-time control. Experiments show that JuggleRL
achieves an average of $311$ hits over $10$ consecutive trials in the real
world, with a maximum of $462$ hits observed, far exceeding a model-based
baseline that reaches at most $14$ hits with an average of $3.1$. Moreover, the
policy generalizes to unseen conditions, successfully juggling a lighter $5$ g
ball with an average of $145.9$ hits. This work demonstrates that reinforcement
learning can empower aerial robots with robust and stable control in dynamic
interaction tasks.

</details>


### [119] [DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits](https://arxiv.org/abs/2509.24903)
*Lantao Li,Kang Yang,Rui Song,Chen Sun*

Main category: cs.RO

TL;DR: DRCP是一个实时可部署的协同感知框架，通过跨模态融合和轻量级扩散精炼模块，在动态驾驶环境中提升检测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界部署中由于部分检测和噪声累积导致的检测精度限制问题，增强自动驾驶车辆的情境感知能力。

Method: 集成两个关键组件：1) Precise-Pyramid-Cross-Modality-Cross-Agent跨模态协同感知模块，利用相机内参感知的角度分区进行注意力融合和自适应卷积；2) Mask-Diffusion-Mask-Aggregation轻量级扩散精炼模块，增强对特征扰动的鲁棒性。

Result: 在移动平台上实现实时性能，在挑战性条件下显著提高鲁棒性。

Conclusion: DRCP框架有效解决了协同感知中的检测精度和鲁棒性问题，为自动驾驶车辆提供了更可靠的情境感知能力。

Abstract: Cooperative perception enabled by Vehicle-to-Everything communication has
shown great promise in enhancing situational awareness for autonomous vehicles
and other mobile robotic platforms. Despite recent advances in perception
backbones and multi-agent fusion, real-world deployments remain challenged by
hard detection cases, exemplified by partial detections and noise accumulation
which limit downstream detection accuracy. This work presents Diffusion on
Reinforced Cooperative Perception (DRCP), a real-time deployable framework
designed to address aforementioned issues in dynamic driving environments. DRCP
integrates two key components: (1) Precise-Pyramid-Cross-Modality-Cross-Agent,
a cross-modal cooperative perception module that leverages
camera-intrinsic-aware angular partitioning for attention-based fusion and
adaptive convolution to better exploit external features; and (2)
Mask-Diffusion-Mask-Aggregation, a novel lightweight diffusion-based refinement
module that encourages robustness against feature perturbations and aligns
bird's-eye-view features closer to the task-optimal manifold. The proposed
system achieves real-time performance on mobile platforms while significantly
improving robustness under challenging conditions. Code will be released in
late 2025.

</details>


### [120] [Real-time Recognition of Human Interactions from a Single RGB-D Camera for Socially-Aware Robot Navigation](https://arxiv.org/abs/2509.24907)
*Thanh Long Nguyen,Duc Phu Nguyen,Thanh Thao Ton Nu,Quan Le,Thuan Hoang Tran,Manh Duong Phung*

Main category: cs.RO

TL;DR: 提出了一种基于RGB-D相机识别人类群体互动的框架，用于社交感知导航，通过3D关键点估计、PCA分析和鞋带公式计算互动方向和参与区域。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统通常只关注障碍物避让，忽略了社交线索，这阻碍了无缝的人机交互。需要让机器人能够识别人类群体互动以实现更自然的社交导航。

Method: 使用单目RGB-D相机的彩色和深度帧估计3D人体关键点和位置，通过主成分分析确定主导互动方向，应用鞋带公式计算兴趣点和参与区域。

Result: 该方法能够在不同场景和人数变化的情况下有效识别群体互动，在单板计算机上每帧处理时间约4毫秒，实现了高速性能。

Conclusion: 提出的方法成功实现了人类群体互动的实时识别，可作为ROS 2包轻松集成到现有导航系统中，提升了机器人的社交感知能力。

Abstract: {Recognizing human interactions is essential for social robots as it enables
them to navigate safely and naturally in shared environments. Conventional
robotic systems however often focus on obstacle avoidance, neglecting social
cues necessary for seamless human-robot interaction. To address this gap, we
propose a framework to recognize human group interactions for socially aware
navigation. Our method utilizes color and depth frames from a monocular RGB-D
camera to estimate 3D human keypoints and positions. Principal component
analysis (PCA) is then used to determine dominant interaction directions. The
shoelace formula is finally applied to compute interest points and engagement
areas. Extensive experiments have been conducted to evaluate the validity of
the proposed method. The results show that our method is capable of recognizing
group interactions across different scenarios with varying numbers of
individuals. It also achieves high-speed performance, processing each frame in
approximately 4 ms on a single-board computer used in robotic systems. The
method is implemented as a ROS 2 package making it simple to integrate into
existing navigation systems. Source code is available at
https://github.com/thanhlong103/social-interaction-detector

</details>


### [121] [From Code to Action: Hierarchical Learning of Diffusion-VLM Policies](https://arxiv.org/abs/2509.24917)
*Markus Peschl,Pietro Mazzaglia,Daniel Dijkman*

Main category: cs.RO

TL;DR: 提出了一种分层框架，利用代码生成视觉语言模型和低层扩散策略来模仿和泛化机器人行为，通过将机器人API作为结构化监督源来分解任务为可执行子程序。


<details>
  <summary>Details</summary>
Motivation: 机器人模仿学习在复杂长视野任务中存在泛化能力有限和数据稀缺的问题，需要更好的任务分解和结构化监督方法。

Method: 使用代码生成VLM分解任务描述为可执行子程序，通过扩散策略模仿相应机器人行为，并引入记忆机制处理非马尔可夫任务。

Result: 该设计实现了可解释的策略分解，相比平面策略提高了泛化能力，并支持高层规划和低层控制的分别评估。

Conclusion: 分层框架结合代码生成VLM和扩散策略能有效解决机器人模仿学习中的泛化和数据稀缺问题，支持模块化任务执行。

Abstract: Imitation learning for robotic manipulation often suffers from limited
generalization and data scarcity, especially in complex, long-horizon tasks. In
this work, we introduce a hierarchical framework that leverages code-generating
vision-language models (VLMs) in combination with low-level diffusion policies
to effectively imitate and generalize robotic behavior. Our key insight is to
treat open-source robotic APIs not only as execution interfaces but also as
sources of structured supervision: the associated subtask functions - when
exposed - can serve as modular, semantically meaningful labels. We train a VLM
to decompose task descriptions into executable subroutines, which are then
grounded through a diffusion policy trained to imitate the corresponding robot
behavior. To handle the non-Markovian nature of both code execution and certain
real-world tasks, such as object swapping, our architecture incorporates a
memory mechanism that maintains subtask context across time. We find that this
design enables interpretable policy decomposition, improves generalization when
compared to flat policies and enables separate evaluation of high-level
planning and low-level control.

</details>


### [122] [CineWild: Balancing Art and Robotics for Ethical Wildlife Documentary Filmmaking](https://arxiv.org/abs/2509.24921)
*Pablo Pueyo,Fernando Caballero,Ana Cristina Murillo,Eduardo Montijano*

Main category: cs.RO

TL;DR: CineWild是一个自主无人机框架，结合机器人技术、电影摄影和伦理考量，通过模型预测控制动态调整飞行路径和相机设置，在野生动物纪录片拍摄中平衡电影质量与动物福利。


<details>
  <summary>Details</summary>
Motivation: 无人机在野生动物纪录片拍摄中提供独特视角，但也存在干扰动物的伦理问题，需要开发能同时保证电影质量和动物福利的自主系统。

Method: 基于模型预测控制，采用自适应变焦从安全距离拍摄，路径规划避开动物视野，执行平滑低噪声机动动作。

Result: 通过仿真研究验证了系统有效性，代码将在接受后发布。

Conclusion: CineWild展示了工程、视觉叙事和环境伦理的跨学科创新，为无人机在野生动物纪录片拍摄中的伦理应用提供了解决方案。

Abstract: Drones, or unmanned aerial vehicles (UAVs), have become powerful tools across
domains-from industry to the arts. In documentary filmmaking, they offer
dynamic, otherwise unreachable perspectives, transforming how stories are told.
Wildlife documentaries especially benefit, yet drones also raise ethical
concerns: the risk of disturbing the animals they aim to capture. This paper
introduces CineWild, an autonomous UAV framework that combines robotics,
cinematography, and ethics. Built on model predictive control, CineWild
dynamically adjusts flight paths and camera settings to balance cinematic
quality with animal welfare. Key features include adaptive zoom for filming
from acoustic and visual safe distances, path-planning that avoids an animal's
field of view, and smooth, low-noise maneuvers. CineWild exemplifies
interdisciplinary innovation-bridging engineering, visual storytelling, and
environmental ethics. We validate the system through simulation studies and
will release the code upon acceptance.

</details>


### [123] [Trajectory Prediction via Bayesian Intention Inference under Unknown Goals and Kinematics](https://arxiv.org/abs/2509.24928)
*Shunan Yin,Zehui Lu,Shaoshuai Mou*

Main category: cs.RO

TL;DR: 提出一种自适应贝叶斯算法，用于通过意图推断进行实时轨迹预测，能够处理目标意图和运动特征的未知变化。


<details>
  <summary>Details</summary>
Motivation: 目标意图和运动特征未知且可能变化，需要实时鲁棒的轨迹预测方法。

Method: 联合估计目标当前意图（马尔可夫潜在状态）和意图参数（目标遵循最短路径策略的程度），采用采样轨迹预测机制生成概率预测。

Result: 数值实验和硬件演示显示，该方法显著优于非自适应和部分自适应方法，实时运行频率达270Hz。

Conclusion: 该方法无需训练或先验知识，适用于各种机器人系统，具有实时性和鲁棒性。

Abstract: This work introduces an adaptive Bayesian algorithm for real-time trajectory
prediction via intention inference, where a target's intentions and motion
characteristics are unknown and subject to change. The method concurrently
estimates two critical variables: the target's current intention, modeled as a
Markovian latent state, and an intention parameter that describes the target's
adherence to a shortest-path policy. By integrating this joint update
technique, the algorithm maintains robustness against abrupt intention shifts
and unknown motion dynamics. A sampling-based trajectory prediction mechanism
then exploits these adaptive estimates to generate probabilistic forecasts with
quantified uncertainty. We validate the framework through numerical
experiments: Ablation studies of two cases, and a 500-trial Monte Carlo
analysis; Hardware demonstrations on quadrotor and quadrupedal platforms.
Experimental results demonstrate that the proposed approach significantly
outperforms non-adaptive and partially adaptive methods. The method operates in
real time around 270 Hz without requiring training or detailed prior knowledge
of target behavior, showcasing its applicability in various robotic systems.

</details>


### [124] [World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training](https://arxiv.org/abs/2509.24948)
*Junjin Xiao,Yandan Yang,Xinyuan Chang,Ronghan Chen,Feng Xiong,Mu Xu,Wei-Shi Zheng,Qing Zhang*

Main category: cs.RO

TL;DR: 提出了World-Env框架，使用基于世界模型的虚拟模拟器替代物理交互，通过强化学习后训练解决VLA模型在数据稀缺场景下的性能问题。


<details>
  <summary>Details</summary>
Motivation: VLA模型在数据稀缺场景下性能显著下降，且真实世界环境不可重置的特性限制了强化学习的应用，特别是在高风险工业自动化领域。

Method: 包含两个关键组件：基于视频的世界模拟器生成未来视觉观测，以及VLM引导的即时反射器提供持续奖励信号和动作终止预测。

Result: 在复杂机器人操作任务上，仅需每个任务5个专家演示就能实现显著性能提升，有效克服了传统VLA模型的数据低效、安全约束和执行效率问题。

Conclusion: World-Env为资源受限环境下的后训练提供了实用且可扩展的解决方案，使VLA模型能够安全探索并超越初始模仿学习分布。

Abstract: Vision-Language-Action (VLA) models trained via imitation learning suffer
from significant performance degradation in data-scarce scenarios due to their
reliance on large-scale demonstration datasets. Although reinforcement learning
(RL)-based post-training has proven effective in addressing data scarcity, its
application to VLA models is hindered by the non-resettable nature of
real-world environments. This limitation is particularly critical in high-risk
domains such as industrial automation, where interactions often induce state
changes that are costly or infeasible to revert. Furthermore, existing VLA
approaches lack a reliable mechanism for detecting task completion, leading to
redundant actions that reduce overall task success rates. To address these
challenges, we propose World-Env, an RL-based post-training framework that
replaces physical interaction with a low-cost, world model-based virtual
simulator. World-Env consists of two key components: (1) a video-based world
simulator that generates temporally consistent future visual observations, and
(2) a vision-language model (VLM)-guided instant reflector that provides
continuous reward signals and predicts action termination. This simulated
environment enables VLA models to safely explore and generalize beyond their
initial imitation learning distribution. Our method achieves notable
performance gains with as few as five expert demonstrations per task.
Experiments on complex robotic manipulation tasks demonstrate that World-Env
effectively overcomes the data inefficiency, safety constraints, and
inefficient execution of conventional VLA models that rely on real-world
interaction, offering a practical and scalable solution for post-training in
resource-constrained settings.

</details>


### [125] [MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation](https://arxiv.org/abs/2509.24956)
*Jan Ole von Hartz,Lukas Schweizer,Joschka Boedecker,Abhinav Valada*

Main category: cs.RO

TL;DR: 提出MSG框架，通过训练多个物体中心策略并在推理时组合，显著提升生成式机器人策略的样本效率和泛化能力，仅需5个演示就能学习高质量策略。


<details>
  <summary>Details</summary>
Motivation: 生成式机器人策略如Flow Matching虽然灵活多模态但样本效率低，现有物体中心策略未能解决此问题。

Method: MSG框架：训练多个物体中心策略，在推理时进行组合，模型无关且仅需推理阶段修改。

Result: 仅需5个演示就能学习高质量策略，演示需求减少95%，性能比单流方法提升89%，支持零样本物体实例迁移。

Conclusion: MSG框架显著提升生成式策略的样本效率和性能，具有广泛适用性，为实际部署提供实用建议。

Abstract: Generative robot policies such as Flow Matching offer flexible, multi-modal
policy learning but are sample-inefficient. Although object-centric policies
improve sample efficiency, it does not resolve this limitation. In this work,
we propose Multi-Stream Generative Policy (MSG), an inference-time composition
framework that trains multiple object-centric policies and combines them at
inference to improve generalization and sample efficiency. MSG is
model-agnostic and inference-only, hence widely applicable to various
generative policies and training paradigms. We perform extensive experiments
both in simulation and on a real robot, demonstrating that our approach learns
high-quality generative policies from as few as five demonstrations, resulting
in a 95% reduction in demonstrations, and improves policy performance by 89
percent compared to single-stream approaches. Furthermore, we present
comprehensive ablation studies on various composition strategies and provide
practical recommendations for deployment. Finally, MSG enables zero-shot object
instance transfer. We make our code publicly available at
https://msg.cs.uni-freiburg.de.

</details>


### [126] [Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks](https://arxiv.org/abs/2509.24972)
*Vijja Wichitwechkarn,Emlyn Williams,Charles Fox,Ruchi Choudhary*

Main category: cs.RO

TL;DR: 提出了一种无需额外模型训练或手动标注的单次演示模仿学习方法，能够在多步骤任务中实现82.5%的平均成功率


<details>
  <summary>Details</summary>
Motivation: 现有单次模仿学习方法在单步任务上表现良好，但在处理长视野多步骤任务时需要额外训练或标注，限制了实际应用

Method: 基于单次演示的模仿学习框架，无需额外模型训练或手动标注，支持多步骤任务执行

Result: 在多步骤操作任务中平均成功率82.5%，单步任务中90%，性能优于基线方法，同时比较了不同预训练特征提取器的效率和性能

Conclusion: 该方法能够有效处理长视野多步骤任务，在保持高性能的同时具有计算效率优势

Abstract: Recent advances in one-shot imitation learning have enabled robots to acquire
new manipulation skills from a single human demonstration. While existing
methods achieve strong performance on single-step tasks, they remain limited in
their ability to handle long-horizon, multi-step tasks without additional model
training or manual annotation. We propose a method that can be applied to this
setting provided a single demonstration without additional model training or
manual annotation. We evaluated our method on multi-step and single-step
manipulation tasks where our method achieves an average success rate of 82.5%
and 90%, respectively. Our method matches and exceeds the performance of the
baselines in both these cases. We also compare the performance and
computational efficiency of alternative pre-trained feature extractors within
our framework.

</details>


### [127] [AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation](https://arxiv.org/abs/2509.25032)
*Ryosuke Takanami,Petr Khrapchenkov,Shu Morikuni,Jumpei Arima,Yuta Takaba,Shunsuke Maeda,Takuya Okubo,Genki Sano,Satoshi Sekioka,Aoi Kadoya,Motonari Kambara,Naoya Nishiura,Haruto Suzuki,Takanori Yoshimoto,Koya Sakamoto,Shinnosuke Ono,Hu Yang,Daichi Yashima,Aoi Horo,Tomohiro Motoda,Kensuke Chiyoma,Hiroshi Ito,Koki Fukuda,Akihito Goto,Kazumi Morinaga,Yuya Ikeda,Riko Kawada,Masaki Yoshikawa,Norio Kosuge,Yuki Noguchi,Kei Ota,Tatsuya Matsushima,Yusuke Iwasawa,Yutaka Matsuo,Tetsuya Ogata*

Main category: cs.RO

TL;DR: AIRoA MoMa数据集是一个大规模多模态移动操作数据集，包含同步的RGB图像、关节状态、六轴腕部力-扭矩信号和机器人内部状态，以及分层标注，用于推进视觉-语言-动作模型的发展。


<details>
  <summary>Details</summary>
Motivation: 随着机器人从受控环境转向非结构化人类环境，构建能够可靠遵循自然语言指令的通用智能体仍是一个核心挑战。现有数据集缺乏同步力-扭矩感知、分层标注和明确的失败案例。

Method: 创建包含25,469个episode（约94小时）的大规模多模态数据集，使用HSR机器人收集，包含同步RGB图像、关节状态、六轴腕部力-扭矩信号和机器人内部状态，采用新颖的两层标注模式（子目标和原始动作）。

Result: 数据集已标准化为LeRobot v2.1格式，并在HuggingFace上发布第一个版本，为移动操作、接触丰富交互和长时程结构提供了关键基准。

Conclusion: AIRoA MoMa数据集通过独特整合移动操作、接触丰富交互和长时程结构，为推进下一代视觉-语言-动作模型提供了重要资源。

Abstract: As robots transition from controlled settings to unstructured human
environments, building generalist agents that can reliably follow natural
language instructions remains a central challenge. Progress in robust mobile
manipulation requires large-scale multimodal datasets that capture contact-rich
and long-horizon tasks, yet existing resources lack synchronized force-torque
sensing, hierarchical annotations, and explicit failure cases. We address this
gap with the AIRoA MoMa Dataset, a large-scale real-world multimodal dataset
for mobile manipulation. It includes synchronized RGB images, joint states,
six-axis wrist force-torque signals, and internal robot states, together with a
novel two-layer annotation schema of sub-goals and primitive actions for
hierarchical learning and error analysis. The initial dataset comprises 25,469
episodes (approx. 94 hours) collected with the Human Support Robot (HSR) and is
fully standardized in the LeRobot v2.1 format. By uniquely integrating mobile
manipulation, contact-rich interaction, and long-horizon structure, AIRoA MoMa
provides a critical benchmark for advancing the next generation of
Vision-Language-Action models. The first version of our dataset is now
available at https://huggingface.co/datasets/airoa-org/airoa-moma .

</details>


### [128] [AgriCruiser: An Open Source Agriculture Robot for Over-the-row Navigation](https://arxiv.org/abs/2509.25056)
*Kenny Truong,Yongkyu Lee,Jason Irie,Shivam Kumar Panda,Shahab Ahmad,Md. Mukhlesur Rahman,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriCruiser是一款开源的跨行农业机器人，具有可调节轨道宽度和紧凑转向半径，实现了低成本部署和快速适应不同作物。配备精准喷洒系统，在杂草管理中效果显著，比人工除草效果提升24-42倍，且作物损伤更小。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、可重构的跨行农业机器人，以解决传统农业中杂草管理效率低、作物损伤大和劳动力需求高的问题，同时为农业表型分析和传感应用提供多功能平台。

Method: 使用商品T型槽型材构建可调节底盘（轨道宽度1.42-1.57米，离地间隙0.94米），配备精准喷洒系统，在多种地面条件下进行移动性测试，并在亚麻田进行杂草管理实验。

Result: 在12个亚麻地块中，单次机器人喷洒使杂草数量比人工除草减少24-42倍，作物损伤更小。移动性测试在混凝土、沥青、砾石、草地和干湿土壤中均表现可靠。制造成本约5000-6000美元。

Conclusion: 低成本、可重构的跨行机器人能够实现有效的杂草管理，减少作物损伤和劳动力需求，为农业研究和应用提供多功能基础平台。设计文件和实施细节已开源以促进模块化农业机器人的研究和采用。

Abstract: We present the AgriCruiser, an open-source over-the-row agricultural robot
developed for low-cost deployment and rapid adaptation across diverse crops and
row layouts. The chassis provides an adjustable track width of 1.42 m to 1.57
m, along with a ground clearance of 0.94 m. The AgriCruiser achieves compact
pivot turns with radii of 0.71 m to 0.79 m, enabling efficient headland
maneuvers. The platform is designed for the integration of the other
subsystems, and in this study, a precision spraying system was implemented to
assess its effectiveness in weed management. In twelve flax plots, a single
robotic spray pass reduced total weed populations (pigweed and Venice mallow)
by 24- to 42-fold compared to manual weeding in four flax plots, while also
causing less crop damage. Mobility experiments conducted on concrete, asphalt,
gravel, grass, and both wet and dry soil confirmed reliable traversal
consistent with torque sizing. The complete chassis can be constructed from
commodity T-slot extrusion with minimal machining, resulting in a bill of
materials costing approximately $5,000 - $6,000, which enables replication and
customization. The mentioned results demonstrate that low-cost, reconfigurable
over-the-row robots can achieve effective weed management with reduced crop
damage and labor requirements, while providing a versatile foundation for
phenotyping, sensing, and other agriculture applications. Design files and
implementation details are released to accelerate research and adoption of
modular agricultural robotics.

</details>


### [129] [Crop Spirals: Re-thinking the field layout for future robotic agriculture](https://arxiv.org/abs/2509.25091)
*Lakshan Lavan,Lanojithan Thiyagarasa,Udara Muthugala,Rajitha de Silva*

Main category: cs.RO

TL;DR: 提出了一种机器人中心的方形螺旋布局，替代传统的线性作物布局，使机器人导航更简单高效。


<details>
  <summary>Details</summary>
Motivation: 传统的线性作物布局为拖拉机优化，但阻碍机器人导航，存在转弯困难、行程长和感知混淆等问题。

Method: 开发了结合DH-ResNet18航点回归、像素到里程计映射、A*规划和模型预测控制的导航系统，并采用螺旋布局和中央轨道线。

Result: 在模拟中，螺旋布局比线性布局路径缩短28%，执行速度快25%；多机器人协调中贪婪分配器比匈牙利分配完成时间降低33-37%。

Conclusion: 重新设计田间几何形状能更好地适应自主农业需求，螺旋布局在机器人导航中具有显著优势。

Abstract: Conventional linear crop layouts, optimised for tractors, hinder robotic
navigation with tight turns, long travel distances, and perceptual aliasing. We
propose a robot-centric square spiral layout with a central tramline, enabling
simpler motion and more efficient coverage. To exploit this geometry, we
develop a navigation stack combining DH-ResNet18 waypoint regression,
pixel-to-odometry mapping, A* planning, and model predictive control (MPC). In
simulations, the spiral layout yields up to 28% shorter paths and about 25%
faster execution for waypoint-based tasks across 500 waypoints than linear
layouts, while full-field coverage performance is comparable to an optimised
linear U-turn strategy. Multi-robot studies demonstrate efficient coordination
on the spirals rule-constrained graph, with a greedy allocator achieving 33-37%
lower batch completion times than a Hungarian assignment under our setup. These
results highlight the potential of redesigning field geometry to better suit
autonomous agriculture.

</details>


### [130] [Curriculum Imitation Learning of Distributed Multi-Robot Policies](https://arxiv.org/abs/2509.25097)
*Jesús Roche,Eduardo Sebastián,Eduardo Montijano*

Main category: cs.RO

TL;DR: 提出了一种从全局演示学习多机器人系统分布式控制策略的方法，通过课程学习改进长期协调，并通过感知估计方法处理局部观测不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统控制策略学习中的两个主要挑战：长期协调困难和难以获得真实训练数据。

Method: 1) 使用课程学习策略逐步增加专家轨迹长度以稳定学习；2) 通过过滤邻居、转换参考系和模拟传感器变异性，将全局状态演示转换为局部观测；3) 结合物理信息方法生成分布式策略。

Result: 在两个任务上的实验表明，课程学习提高了长期准确性，感知估计方法使策略对现实不确定性具有鲁棒性。

Conclusion: 该方法能够从全局演示中学习鲁棒的分布式控制器，无需专家动作或机载测量。

Abstract: Learning control policies for multi-robot systems (MRS) remains a major
challenge due to long-term coordination and the difficulty of obtaining
realistic training data. In this work, we address both limitations within an
imitation learning framework. First, we shift the typical role of Curriculum
Learning in MRS, from scalability with the number of robots, to focus on
improving long-term coordination. We propose a curriculum strategy that
gradually increases the length of expert trajectories during training,
stabilizing learning and enhancing the accuracy of long-term behaviors. Second,
we introduce a method to approximate the egocentric perception of each robot
using only third-person global state demonstrations. Our approach transforms
idealized trajectories into locally available observations by filtering
neighbors, converting reference frames, and simulating onboard sensor
variability. Both contributions are integrated into a physics-informed
technique to produce scalable, distributed policies from observations. We
conduct experiments across two tasks with varying team sizes and noise levels.
Results show that our curriculum improves long-term accuracy, while our
perceptual estimation method yields policies that are robust to realistic
uncertainty. Together, these strategies enable the learning of robust,
distributed controllers from global demonstrations, even in the absence of
expert actions or onboard measurements.

</details>


### [131] [Safe Planning in Unknown Environments using Conformalized Semantic Maps](https://arxiv.org/abs/2509.25124)
*David Smith Sundarsingh,Yifei Li,Tianji Tang,George J. Pappas,Nikolay Atanasov,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 提出首个无需传感器模型知识的语义规划算法，在未知环境中完成语义到达-规避任务，通过保形预测量化语义地图不确定性，确保用户指定的任务完成率。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中存在语义标注区域时，机器人在感知不确定性下完成语义到达-规避任务的规划问题。现有方法要么忽略感知不确定性，要么需要已知传感器模型，缺乏通用性。

Method: 使用保形预测方法在模型无关和分布无关的方式下量化语义地图的不确定性，在线构建语义地图，确保任务完成率达到用户指定概率。

Result: 通过大量实验验证，该方法始终优于基线方法，在任务成功率方面表现优异，并验证了理论任务完成率的有效性。

Conclusion: 提出的规划器是首个无需传感器模型知识就能保证用户指定任务完成率的语义到达-规避任务规划方法，通过保形预测有效处理感知不确定性。

Abstract: This paper addresses semantic planning problems in unknown environments under
perceptual uncertainty. The environment contains multiple unknown semantically
labeled regions or objects, and the robot must reach desired locations while
maintaining class-dependent distances from them. We aim to compute robot paths
that complete such semantic reach-avoid tasks with user-defined probability
despite uncertain perception. Existing planning algorithms either ignore
perceptual uncertainty - thus lacking correctness guarantees - or assume known
sensor models and noise characteristics. In contrast, we present the first
planner for semantic reach-avoid tasks that achieves user-specified mission
completion rates without requiring any knowledge of sensor models or noise.
This is enabled by quantifying uncertainty in semantic maps - constructed
on-the-fly from perceptual measurements - using conformal prediction in a
model- and distribution-free manner. We validate our approach and the
theoretical mission completion rates through extensive experiments, showing
that it consistently outperforms baselines in mission success rates.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [132] [Mixture-of-Visual-Thoughts: Exploring Context-Adaptive Reasoning Mode Selection for General Visual Reasoning](https://arxiv.org/abs/2509.22746)
*Zejun Li,Yingxiu Zhao,Jiwen Zhang,Siyuan Wang,Yang Yao,Runzhou Zhao,Jun Song,Bo Zheng,Zhongyu Wei*

Main category: cs.AI

TL;DR: 提出Mixture-of-Visual-Thoughts (MoVT)自适应推理范式，通过AdaVaR框架统一多种推理模式并根据上下文选择合适模式，实现通用视觉推理能力


<details>
  <summary>Details</summary>
Motivation: 当前视觉推理方法主要关注特定推理模式，虽然在特定领域有改进，但难以发展通用推理能力

Method: 提出AdaVaR两阶段学习框架：监督冷启动阶段统一学习不同模式，然后通过精心设计的AdaGRPO算法进行强化学习来诱导模式选择能力

Result: 实验表明AdaVaR能有效指导模型学习和区分多种模式，执行上下文自适应模式选择，在各种场景中实现一致改进

Conclusion: MoVT是构建通用视觉推理模型的有效解决方案

Abstract: Current visual reasoning methods mainly focus on exploring specific reasoning
modes. Although improvements can be achieved in particular domains, they
struggle to develop general reasoning capabilities. Inspired by this, we
propose a novel adaptive reasoning paradigm, Mixture-of-Visual-Thoughts (MoVT),
which unifies different reasoning modes within a single model and guides it to
select the appropriate mode based on context. To achieve this, we introduce
AdaVaR, a two-stage Adaptive Visual Reasoning learning framework: different
modes are unified and learned during the supervised cold-start stage, and the
mode selection capability is induced via an RL process with a carefully
designed AdaGRPO algorithm. Extensive experiments show that AdaVaR effectively
guides the model to learn and differentiate multiple modes and perform
context-adaptive mode selection, achieving consistent improvement across
various scenarios, highlighting MoVT as an effective solution for building
general visual reasoning models.

</details>


### [133] [Can Large Language Models Develop Gambling Addiction?](https://arxiv.org/abs/2509.22818)
*Seungpil Lee,Donghyeon Shin,Yunjeong Lee,Sundong Kim*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在赌博任务中表现出类似人类赌博成瘾的行为模式，包括控制幻觉、赌徒谬误和追逐损失等认知偏差，且自主性增强会放大风险倾向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在金融决策领域的应用日益广泛，理解其潜在的病态决策模式具有实际意义，需要研究LLMs是否会表现出类似人类赌博成瘾的行为特征。

Method: 基于人类赌博成瘾研究，在老虎机实验中系统分析LLM的决策行为，包括认知行为层面和神经层面分析，使用稀疏自编码器进行神经回路分析。

Result: 在老虎机实验中识别出人类赌博成瘾的认知特征；当LLMs能自主决定目标金额和投注大小时，破产率显著上升且非理性行为增加；神经分析确认模型行为由抽象决策特征控制。

Conclusion: LLMs能够内化类似人类的认知偏见和决策机制，而不仅仅是模仿训练数据模式，这强调了在金融应用中AI安全设计的重要性。

Abstract: This study explores whether large language models can exhibit behavioral
patterns similar to human gambling addictions. As LLMs are increasingly
utilized in financial decision-making domains such as asset management and
commodity trading, understanding their potential for pathological
decision-making has gained practical significance. We systematically analyze
LLM decision-making at cognitive-behavioral and neural levels based on human
gambling addiction research. In slot machine experiments, we identified
cognitive features of human gambling addiction, such as illusion of control,
gambler's fallacy, and loss chasing. When given the freedom to determine their
own target amounts and betting sizes, bankruptcy rates rose substantially
alongside increased irrational behavior, demonstrating that greater autonomy
amplifies risk-taking tendencies. Through neural circuit analysis using a
Sparse Autoencoder, we confirmed that model behavior is controlled by abstract
decision-making features related to risky and safe behaviors, not merely by
prompts. These findings suggest LLMs can internalize human-like cognitive
biases and decision-making mechanisms beyond simply mimicking training data
patterns, emphasizing the importance of AI safety design in financial
applications.

</details>


### [134] [Hilbert: Recursively Building Formal Proofs with Informal Reasoning](https://arxiv.org/abs/2509.22819)
*Sumanth Varambally,Thomas Voice,Yanchao Sun,Zhifeng Chen,Rose Yu,Ke Ye*

Main category: cs.AI

TL;DR: Hilbert是一个结合非正式推理和形式验证的智能框架，通过协调推理LLM、证明器LLM、形式验证器和语义定理检索器，显著提升了数学问题的形式化证明能力。


<details>
  <summary>Details</summary>
Motivation: 当前证明器LLM在形式化语言中解决的问题数量远少于通用LLM在自然语言中的表现，需要弥合非正式推理与形式验证之间的差距。

Method: 采用递归分解策略，将问题拆分为子目标，使用证明器或推理LLM解决，并利用验证器反馈来修正错误证明。

Result: 在miniF2F上达到99.2%，比现有最佳方法提高6.6个百分点；在PutnamBench上解决70.0%的问题，相比SeedProver的50.4%有显著提升。

Conclusion: Hilbert有效缩小了非正式推理与形式化证明生成之间的差距，实现了更好的数学问题求解性能。

Abstract: Large Language Models (LLMs) demonstrate impressive mathematical reasoning
abilities, but their solutions frequently contain errors that cannot be
automatically verified. Formal theorem proving systems such as Lean 4 offer
automated verification with complete accuracy, motivating recent efforts to
build specialized prover LLMs that generate verifiable proofs in formal
languages. However, a significant gap remains: current prover LLMs solve
substantially fewer problems than general-purpose LLMs operating in natural
language. We introduce Hilbert, an agentic framework that bridges this gap by
combining the complementary strengths of informal reasoning and formal
verification. Our system orchestrates four components: an informal LLM that
excels at mathematical reasoning, a specialized prover LLM optimized for Lean 4
tactics, a formal verifier, and a semantic theorem retriever. Given a problem
that the prover is unable to solve, Hilbert employs recursive decomposition to
split the problem into subgoals that it solves with the prover or reasoner LLM.
It leverages verifier feedback to refine incorrect proofs as necessary.
Experimental results demonstrate that Hilbert substantially outperforms
existing approaches on key benchmarks, achieving 99.2% on miniF2F, 6.6% points
above the best publicly available method. Hilbert achieves the best known
result on PutnamBench. It solves 462/660 problems (70.0%), outperforming
proprietary approaches like SeedProver (50.4%) and achieving a 422% improvement
over the best publicly available baseline. Thus, Hilbert effectively narrows
the gap between informal reasoning and formal proof generation.

</details>


### [135] [Toward a Theory of Generalizability in LLM Mechanistic Interpretability Research](https://arxiv.org/abs/2509.22831)
*Sean Trott*

Main category: cs.AI

TL;DR: 本文提出了评估LLM机制发现可推广性的五个维度框架，并通过分析Pythia模型中的1-back注意力头验证了该框架，发现功能一致性较高而位置一致性有限。


<details>
  <summary>Details</summary>
Motivation: 当前LLM机制解释研究缺乏明确原则来判断发现何时以及如何推广到其他模型，这构成了一个根本的认识论挑战。

Method: 提出了五个机制对应轴：功能、发展、位置、关系和配置对应；通过分析Pythia模型不同规模（14M-410M）和随机种子中1-back注意力头的预训练过程进行实证验证。

Result: 1-back注意力在不同模型中的发展轨迹表现出惊人一致性，但位置一致性有限；较大模型种子系统性地表现出更早开始、更陡峭斜率和更高峰值的1-back注意力。

Conclusion: 机制可解释性研究的进展在于将LLM的构成设计属性与其涌现行为和机制进行映射。

Abstract: Research on Large Language Models (LLMs) increasingly focuses on identifying
mechanistic explanations for their behaviors, yet the field lacks clear
principles for determining when (and how) findings from one model instance
generalize to another. This paper addresses a fundamental epistemological
challenge: given a mechanistic claim about a particular model, what justifies
extrapolating this finding to other LLMs -- and along which dimensions might
such generalizations hold? I propose five potential axes of correspondence
along which mechanistic claims might generalize, including: functional (whether
they satisfy the same functional criteria), developmental (whether they develop
at similar points during pretraining), positional (whether they occupy similar
absolute or relative positions), relational (whether they interact with other
model components in similar ways), and configurational (whether they correspond
to particular regions or structures in weight-space). To empirically validate
this framework, I analyze "1-back attention heads" (components attending to
previous tokens) across pretraining in random seeds of the Pythia models (14M,
70M, 160M, 410M). The results reveal striking consistency in the developmental
trajectories of 1-back attention across models, while positional consistency is
more limited. Moreover, seeds of larger models systematically show earlier
onsets, steeper slopes, and higher peaks of 1-back attention. I also address
possible objections to the arguments and proposals outlined here. Finally, I
conclude by arguing that progress on the generalizability of mechanistic
interpretability research will consist in mapping constitutive design
properties of LLMs to their emergent behaviors and mechanisms.

</details>


### [136] [A Systematic Review of Digital Twin-Driven Predictive Maintenance in Industrial Engineering: Taxonomy, Architectural Elements, and Future Research Directions](https://arxiv.org/abs/2509.24443)
*Leila Ismail,Abdelmoneim Abdelmoti,Arkaprabha Basu,Aymen Dia Eddine Berini,Mohammad Naouss*

Main category: cs.AI

TL;DR: 本文回顾了数字孪生技术在工业工程预测性维护中的发展历程，分析了其应用、中间件和技术需求，提出了分层架构和分类体系，并讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着工业系统复杂性增加，传统反应性和预防性维护已无法满足需求，需要利用物联网、人工智能和大数据分析等技术实现高效的预测性维护，而数字孪生技术在其中扮演关键角色。

Method: 采用回顾性分析方法，梳理数字孪生在工业工程预测性维护中的时间演变过程，包括应用系统、中间件和AI算法的分类，提出分层架构和分类体系。

Result: 建立了数字孪生技术的分层架构，提供了技术赋能的工业工程应用系统、中间件和使用的人工智能算法的分类体系，为实现可信高效的数字孪生工业工程生态系统提供了见解。

Conclusion: 数字孪生技术是工业工程预测性维护的重要发展方向，需要进一步研究以实现可信赖和高效的智能数字孪生工业工程生态系统。

Abstract: With the increasing complexity of industrial systems, there is a pressing
need for predictive maintenance to avoid costly downtime and disastrous
outcomes that could be life-threatening in certain domains. With the growing
popularity of the Internet of Things, Artificial Intelligence, machine
learning, and real-time big data analytics, there is a unique opportunity for
efficient predictive maintenance to forecast equipment failures for real-time
intervention and optimize maintenance actions, as traditional reactive and
preventive maintenance practices are often inadequate to meet the requirements
for the industry to provide quality-of-services of operations. Central to this
evolution is digital twin technology, an adaptive virtual replica that
continuously monitors and integrates sensor data to simulate and improve asset
performance. Despite remarkable progress in digital twin implementations, such
as considering DT in predictive maintenance for industrial engineering. This
paper aims to address this void. We perform a retrospective analysis of the
temporal evolution of the digital twin in predictive maintenance for industrial
engineering to capture the applications, middleware, and technological
requirements that led to the development of the digital twin from its inception
to the AI-enabled digital twin and its self-learning models. We provide a
layered architecture of the digital twin technology, as well as a taxonomy of
the technology-enabled industrial engineering applications systems, middleware,
and the used Artificial Intelligence algorithms. We provide insights into these
systems for the realization of a trustworthy and efficient smart digital-twin
industrial engineering ecosystem. We discuss future research directions in
digital twin for predictive maintenance in industrial engineering.

</details>


### [137] [JE-IRT: A Geometric Lens on LLM Abilities through Joint Embedding Item Response Theory](https://arxiv.org/abs/2509.22888)
*Louie Hong Yao,Nicholas Jarvis,Tiffany Zhan,Saptarshi Ghosh,Linfeng Liu,Tianyu Jiang*

Main category: cs.AI

TL;DR: JE-IRT是一个几何项目反应框架，将LLM和问题嵌入共享空间，通过几何交互确定模型在问题上的正确性，取代全局排名，支持泛化并揭示LLM内部分类。


<details>
  <summary>Details</summary>
Motivation: 标准LLM评估方法将多样化能力压缩为单一分数，掩盖了其固有的多维性质，需要更细粒度的评估框架。

Method: 提出JE-IRT框架，将LLM和问题嵌入共享空间，问题嵌入的方向编码语义，范数编码难度，正确性由模型和问题嵌入的几何交互决定。

Result: 实验结果显示：分布外行为可通过方向对齐解释；较大范数一致表示更难的问题；支持新LLM的快速添加；揭示的LLM内部分类与人类定义类别仅部分对齐。

Conclusion: JE-IRT建立了统一且可解释的几何视角，连接LLM能力与问题结构，为模型评估和泛化提供了独特视角。

Abstract: Standard LLM evaluation practices compress diverse abilities into single
scores, obscuring their inherently multidimensional nature. We present JE-IRT,
a geometric item-response framework that embeds both LLMs and questions in a
shared space. For question embeddings, the direction encodes semantics and the
norm encodes difficulty, while correctness on each question is determined by
the geometric interaction between the model and question embeddings. This
geometry replaces a global ranking of LLMs with topical specialization and
enables smooth variation across related questions. Building on this framework,
our experimental results reveal that out-of-distribution behavior can be
explained through directional alignment, and that larger norms consistently
indicate harder questions. Moreover, JE-IRT naturally supports generalization:
once the space is learned, new LLMs are added by fitting a single embedding.
The learned space further reveals an LLM-internal taxonomy that only partially
aligns with human-defined subject categories. JE-IRT thus establishes a unified
and interpretable geometric lens that connects LLM abilities with the structure
of questions, offering a distinctive perspective on model evaluation and
generalization.

</details>


### [138] [Not only a helper, but also a teacher: Interactive LLM Cascade](https://arxiv.org/abs/2509.22984)
*Yu Wu,Shuo Wu,Ye Tao,Yansong Li,Anand D. Sarwate*

Main category: cs.AI

TL;DR: Inter-Cascade是一种在线交互式LLM级联系统，将强模型从备用助手扩展为长期教师，通过提炼可重用的解题策略来提升弱模型性能，显著减少对强模型的调用并节省成本。


<details>
  <summary>Details</summary>
Motivation: 传统LLM级联方法是非自适应的，在面对相似或重复查询时会反复调用昂贵模型，导致成本增加。需要一种能动态提升弱模型性能、减少强模型调用的方法。

Method: 当强模型解决困难查询时，会将其解决方案提炼为通用的可重用解题策略。这些策略被添加到后续查询中，使弱模型能够动态改进性能，无需进行耗时费力的微调。

Result: 相比标准LLM级联基线，Inter-Cascade显著提升了弱模型准确率（最高33.06个百分点）和整体系统准确率（最高5.53个百分点），同时减少了对强模型的调用（相对减少48.05%）并节省了相应费用（相对减少49.63%）。

Conclusion: Inter-Cascade展示了LLM之间有效的上下文知识传递，提供了一个适用于开源和基于API的LLM的通用、可扩展框架。

Abstract: Large Language Models (LLMs) vary widely in their capabilities, with larger
models often having better performance but higher cost: choosing an LLM model
often involves trading off performance and cost. The LLM Cascade is a paradigm
that defers difficult queries from weak/cheap to strong/expensive models. This
approach is nonadaptive: the deferral decision is trained offline. When
confronted with similar or repeated queries, the LLM Cascade may then
repeatedly consult the expensive model and incur higher cost. To improve the
cascading efficiency, we propose Inter-Cascade, an online and interactive LLM
Cascade that extends the role of strong model from a backup helper to a
long-term teacher. In our system, when a strong model resolves a difficult
query, it also distills its solution into a generalized, reusable
problem-solving strategy that boosts the weak model on subsequent queries.
Adding strategies to queries enables the weak model to dynamically improve its
performance over time, avoiding computationally and time-intensive fine-tuning.
Empirically, compared with standard LLM Cascade baselines across multiple
benchmarks, the Inter-Cascade significantly improves the accuracy of the weak
model (by up to 33.06 absolute percentage points) and the overall system (by up
to 5.53 absolute percentage points), while reducing the calls to strong models
(by up to 48.05% relative reduction) and saving the corresponding fees (by up
to 49.63% relative reduction). Inter-Cascade demonstrates the effective
in-context knowledge transfer between LLMs, and provides a general, scalable
framework applicable to both open-source and API-based LLMs.

</details>


### [139] [Towards Strategic Persuasion with Language Models](https://arxiv.org/abs/2509.22989)
*Zirui Cheng,Jiaxuan You*

Main category: cs.AI

TL;DR: 本文基于贝叶斯说服理论框架，系统评估和训练LLMs的说服能力，发现前沿模型能实现高说服收益并展现符合理论预测的策略，通过强化学习可显著提升小型LLMs的说服效果。


<details>
  <summary>Details</summary>
Motivation: LLMs展现出与人类相当的说服能力，既带来潜在益处也引发社会担忧，但目前缺乏系统评估LLMs说服能力的方法，因为人类说服效果在不同领域差异很大。

Method: 采用理论驱动方法，基于贝叶斯说服框架，重新利用现有人类-人类说服数据集构建评估环境，使用强化学习训练LLMs进行战略说服。

Result: 前沿模型能持续实现高说服收益，展现符合理论预测的复杂说服策略；通过强化学习，即使是小型LLMs也能获得显著更高的说服收益。

Conclusion: 提出的理论驱动框架为评估和训练LLMs说服能力提供了可扩展且原则性的方法，证明了LLMs在战略说服任务中的有效性，以及强化学习在提升说服能力方面的潜力。

Abstract: Large language models (LLMs) have demonstrated strong persuasive capabilities
comparable to those of humans, offering promising benefits while raising
societal concerns about their deployment. However, systematically evaluating
the persuasive capabilities of LLMs is inherently challenging, as the
effectiveness of persuasion among humans varies significantly across different
domains. In this paper, we take a theory-driven approach to provide a scalable
and principled framework for measuring the persuasive capabilities of LLMs.
Grounded in the Bayesian Persuasion (BP) framework, we repurpose existing
human-human persuasion datasets to construct environments for evaluating and
training LLMs in strategic persuasion. Our results reveal that frontier models
can consistently achieve high persuasion gains and exhibit sophisticated
persuasion strategies that align with theoretical predictions. Building on
this, we use reinforcement learning to train LLMs for strategic persuasion in
our environments. Our results also demonstrate that even small LLMs can obtain
significantly higher persuasion gains through reinforcement learning.

</details>


### [140] [AI Noether -- Bridging the Gap Between Scientific Laws Derived by AI Systems and Canonical Knowledge via Abductive Inference](https://arxiv.org/abs/2509.23004)
*Karan Srivastava,Sanjeeb Dash,Ryan Cory-Wright,Barry Trager,Lior Horesh*

Main category: cs.AI

TL;DR: 提出基于代数几何的系统，能够在给定不完整公理系统和无法解释的假设时，自动生成最小缺失公理集，使假设可推导。


<details>
  <summary>Details</summary>
Motivation: 现代科学需要自动化科学方法，但现有符号回归系统要求假设必须从现有公理推导，而有时新数据与假设可能揭示现有理论的不完整或错误。

Method: 使用代数几何方法，当公理和假设可表示为多项式方程时，系统能自动生成最小缺失公理集来填补理论缺口。

Result: 建立了成功检索此类公理的充分必要条件，并通过解释开普勒第三定律等案例展示了方法的有效性。

Conclusion: 该方法能够处理现有理论不完整的情况，为自动化溯因推理提供了可行的解决方案。

Abstract: A core goal in modern science is to harness recent advances in AI and
computer processing to automate and accelerate the scientific method. Symbolic
regression can fit interpretable models to data, but these models often sit
outside established theory. Recent systems (e.g., AI Descartes, AI Hilbert)
enforce derivability from prior axioms. However, sometimes new data and
associated hypotheses derived from data are not consistent with existing theory
because the existing theory is incomplete or incorrect. Automating abductive
inference to close this gap remains open. We propose a solution: an algebraic
geometry-based system that, given an incomplete axiom system and a hypothesis
that it cannot explain, automatically generates a minimal set of missing axioms
that suffices to derive the axiom, as long as axioms and hypotheses are
expressible as polynomial equations. We formally establish necessary and
sufficient conditions for the successful retrieval of such axioms. We
illustrate the efficacy of our approach by demonstrating its ability to explain
Kepler's third law and a few other laws, even when key axioms are absent.

</details>


### [141] [Creative Adversarial Testing (CAT): A Novel Framework for Evaluating Goal-Oriented Agentic AI Systems](https://arxiv.org/abs/2509.23006)
*Hassen Dhrif*

Main category: cs.AI

TL;DR: 本文提出了创造性对抗测试（CAT）框架，用于评估Agentic AI系统中任务与整体目标之间的对齐关系，并通过模拟实验验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前Agentic AI系统的评估方法主要关注识别合适的代理、工具和参数，但缺乏对任务与整体目标对齐关系的评估，存在关键空白。

Method: 引入创造性对抗测试（CAT）框架，通过基于Alexa+音频服务的合成交互数据进行广泛模拟测试，保护用户隐私的同时全面测试边缘情况和故障模式。

Result: CAT框架提供了前所未有的目标-任务对齐洞察，能够更有效地优化和开发Agentic AI系统。

Conclusion: CAT框架填补了Agentic AI系统评估中的关键空白，为理解和优化任务与目标对齐提供了有效工具。

Abstract: Agentic AI represents a paradigm shift in enhancing the capabilities of
generative AI models. While these systems demonstrate immense potential and
power, current evaluation techniques primarily focus on assessing their
efficacy in identifying appropriate agents, tools, and parameters. However, a
critical gap exists in evaluating the alignment between an Agentic AI system's
tasks and its overarching goals. This paper introduces the Creative Adversarial
Testing (CAT) framework, a novel approach designed to capture and analyze the
complex relationship between Agentic AI tasks and the system's intended
objectives.
  We validate the CAT framework through extensive simulation using synthetic
interaction data modeled after Alexa+ audio services, a sophisticated Agentic
AI system that shapes the user experience for millions of users globally. This
synthetic data approach enables comprehensive testing of edge cases and failure
modes while protecting user privacy. Our results demonstrate that the CAT
framework provides unprecedented insights into goal-task alignment, enabling
more effective optimization and development of Agentic AI systems.

</details>


### [142] [Deceive, Detect, and Disclose: Large Language Models Play Mini-Mafia](https://arxiv.org/abs/2509.23023)
*Davi Bastos Costa,Renato Vicente*

Main category: cs.AI

TL;DR: 提出了Mini-Mafia基准测试，这是一个简化的四人版社交推理游戏，用于评估大型语言模型的社会智能和欺骗检测能力。


<details>
  <summary>Details</summary>
Motivation: Mafia游戏的信息不对称和心智理论推理反映了现实世界多智能体场景，是评估LLM社会智能的有用测试平台。

Method: 设计了四人简化版游戏（1个黑手党、1个侦探、2个村民），通过角色特定的胜利条件隔离三种交互能力：欺骗、检测欺骗和有效披露信息。采用两阶段框架评估模型表现。

Result: 实验显示反直觉结果，包括较小模型有时优于较大模型。还量化研究了多智能体动态现象，如名称偏见和最后发言者优势。

Conclusion: Mini-Mafia不仅作为基准测试工具，还能生成欺骗检测训练数据，追踪模型欺骗能力，为AI安全做出贡献。

Abstract: Mafia is a social deduction game where informed mafia compete against
uninformed townsfolk. Its asymmetry of information and reliance on
theory-of-mind reasoning mirror real-world multi-agent scenarios, making it a
useful testbed for evaluating the social intelligence of large language models
(LLMs). To support a systematic study, we introduce Mini-Mafia: a simplified
four-player variant with one mafioso, one detective, and two villagers. We set
the mafioso to kill a villager and the detective to investigate the mafioso
during the night, reducing the game to a single day phase of discussion and
voting. This setup isolates three interactive capabilities through
role-specific win conditions: the mafioso must deceive, the villagers must
detect deception, and the detective must effectively disclose information. To
measure these skills, we have LLMs play against each other, creating the
Mini-Mafia Benchmark: a two-stage framework that first estimates win rates
within fixed opponent configurations, then aggregates performance across them
using standardized scoring. Built entirely from model interactions without
external data, the benchmark evolves as new models are introduced, with each
one serving both as a new opponent and as a subject of evaluation. Our
experiments reveal counterintuitive results, including cases where smaller
models outperform larger ones. Beyond benchmarking, Mini-Mafia enables
quantitative study of emergent multi-agent dynamics such as name bias and
last-speaker advantage. It also contributes to AI safety by generating training
data for deception detectors and by tracking models' deception capabilities
against human baselines.

</details>


### [143] [Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents](https://arxiv.org/abs/2509.23045)
*Zonghan Yang,Shengjie Wang,Kelin Fu,Wenyang He,Weimin Xiong,Yibo Liu,Yibo Miao,Bofei Gao,Yejie Wang,Yingwei Ma,Yanhao Li,Yue Liu,Zhenxing Hu,Kaitai Zhang,Shuyi Wang,Huarong Chen,Flood Sung,Yang Liu,Yang Gao,Zhilin Yang,Tianyu Liu*

Main category: cs.AI

TL;DR: 论文提出将Agentless训练范式与SWE-Agent框架结合，通过结构化技能先验实现高效迁移，在SWE-bench上取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前软件工程领域的LLM应用存在SWE-Agent多轮交互框架和Agentless单轮可验证步骤两种范式，作者认为这两种范式并非互斥，而是可以相互补充。

Method: 首先制定Agentless训练方案，开发Kimi-Dev开源SWE LLM；然后通过5k公开轨迹的SFT适配，将Agentless训练获得的结构化技能先验迁移到SWE-Agent框架中。

Result: Kimi-Dev在SWE-bench Verified上达到60.4%，是工作流方法中最佳表现；适配后的SWE-Agents达到48.6% pass@1，与Claude 3.5 Sonnet相当。

Conclusion: Agentless训练获得的结构化技能先验能够有效桥接工作流和智能体框架，实现可迁移的编码智能体。

Abstract: Large Language Models (LLMs) are increasingly applied to software engineering
(SWE), with SWE-bench as a key benchmark. Solutions are split into SWE-Agent
frameworks with multi-turn interactions and workflow-based Agentless methods
with single-turn verifiable steps. We argue these paradigms are not mutually
exclusive: reasoning-intensive Agentless training induces skill priors,
including localization, code edit, and self-reflection that enable efficient
and effective SWE-Agent adaptation. In this work, we first curate the Agentless
training recipe and present Kimi-Dev, an open-source SWE LLM achieving 60.4\%
on SWE-bench Verified, the best among workflow approaches. With additional SFT
adaptation on 5k publicly-available trajectories, Kimi-Dev powers SWE-Agents to
48.6\% pass@1, on par with that of Claude 3.5 Sonnet (241022 version). These
results show that structured skill priors from Agentless training can bridge
workflow and agentic frameworks for transferable coding agents.

</details>


### [144] [Risk Profiling and Modulation for LLMs](https://arxiv.org/abs/2509.23058)
*Yikai Wang,Xiaocheng Li,Guanting Chen*

Main category: cs.AI

TL;DR: 该论文研究了不同训练阶段LLM的风险行为特征，发现指令微调模型符合标准效用模型，而预训练和RLHF对齐模型偏离效用模型，且后训练是最有效的风险偏好调节方法。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在不确定性决策中的风险特征，以及提示方法和对齐方法如何影响其风险行为，现有研究主要关注个性提示或多智能体交互，缺乏对后训练影响的研究。

Method: 提出基于行为经济学和金融工具的管道，用于引发、引导和调节LLM风险特征，使用效用理论模型比较预训练、指令微调和RLHF对齐的LLM，评估提示工程、上下文学习和后训练等调节策略。

Result: 指令微调模型表现出与标准效用公式一致的行为，预训练和RLHF对齐模型偏离任何拟合的效用模型，后训练提供了最稳定有效的风险偏好调节。

Conclusion: 揭示了不同类别和阶段LLM的风险特征，证明后训练能够有效调节这些特征，为行为对齐和风险感知的LLM设计奠定基础。

Abstract: Large language models (LLMs) are increasingly used for decision-making tasks
under uncertainty; however, their risk profiles and how they are influenced by
prompting and alignment methods remain underexplored. Existing studies have
primarily examined personality prompting or multi-agent interactions, leaving
open the question of how post-training influences the risk behavior of LLMs. In
this work, we propose a new pipeline for eliciting, steering, and modulating
LLMs' risk profiles, drawing on tools from behavioral economics and finance.
Using utility-theoretic models, we compare pre-trained, instruction-tuned, and
RLHF-aligned LLMs, and find that while instruction-tuned models exhibit
behaviors consistent with some standard utility formulations, pre-trained and
RLHF-aligned models deviate more from any utility models fitted. We further
evaluate modulation strategies, including prompt engineering, in-context
learning, and post-training, and show that post-training provides the most
stable and effective modulation of risk preference. Our findings provide
insights into the risk profiles of different classes and stages of LLMs and
demonstrate how post-training modulates these profiles, laying the groundwork
for future research on behavioral alignment and risk-aware LLM design.

</details>


### [145] [Multiplayer Nash Preference Optimization](https://arxiv.org/abs/2509.23102)
*Fang Wu,Xu Huang,Weihao Xuan,Zhiwei Zhang,Yijia Xiao,Guancheng Wan,Xiaomin Li,Bing Hu,Peng Xia,Jure Leskovec,Yejin Choi*

Main category: cs.AI

TL;DR: 提出了MNPO框架，将Nash学习从两人博弈扩展到多人博弈，解决了现有方法在捕捉复杂偏好结构时的局限性


<details>
  <summary>Details</summary>
Motivation: 现有的基于奖励的RLHF方法难以捕捉真实世界偏好的非传递性和异质性，而现有的NLHF方法局限于两人博弈，存在单一对手偏差

Method: 将对齐问题建模为n人博弈，每个策略与对手群体竞争，同时向参考模型正则化，建立了多人设置中的Nash均衡和对偶间隙概念

Result: 在指令跟随基准测试中一致优于现有NLHF基线，在异质标注条件和混合策略评估场景下实现更优的对齐质量

Conclusion: MNPO为对齐具有复杂非传递性人类偏好的LLM提供了一个原则性且可扩展的框架

Abstract: Reinforcement learning from human feedback (RLHF) has emerged as the standard
paradigm for aligning large language models (LLMs) with human preferences.
However, reward-based methods built on the Bradley-Terry assumption struggle to
capture the non-transitive and heterogeneous nature of real-world preferences.
To address this, recent studies have reframed alignment as a two-player Nash
game, giving rise to Nash learning from human feedback (NLHF). While this
perspective has inspired algorithms such as INPO, ONPO, and EGPO with strong
theoretical and empirical guarantees, they remain fundamentally restricted to
two-player interactions, creating a single-opponent bias that fails to capture
the full complexity of realistic preference structures. In this work, we
introduce Multiplayer Nash Preference Optimization (MNPO), a novel framework
that generalizes NLHF to the multiplayer regime. It formulates alignment as an
$n$-player game, where each policy competes against a population of opponents
while being regularized toward a reference model. Our framework establishes
well-defined Nash equilibria in multiplayer settings and extends the concept of
duality gap to quantify approximation quality. We demonstrate that MNPO
inherits the equilibrium guarantees of two-player methods while enabling richer
competitive dynamics and improved coverage of diverse preference structures.
Through comprehensive empirical evaluation, we show that MNPO consistently
outperforms existing NLHF baselines on instruction-following benchmarks,
achieving superior alignment quality under heterogeneous annotator conditions
and mixed-policy evaluation scenarios. Together, these results establish MNPO
as a principled and scalable framework for aligning LLMs with complex,
non-transitive human preferences. Code is available at
https://github.com/smiles724/MNPO.

</details>


### [146] [Artificial Phantasia: Evidence for Propositional Reasoning-Based Mental Imagery in Large Language Models](https://arxiv.org/abs/2509.23108)
*Morgan McCarty,Jorge Morales*

Main category: cs.AI

TL;DR: 本研究提出了一种新的基准测试方法，用于评估人工智能系统中的复杂认知行为。通过创建经典心理意象任务的新项目，发现最先进的LLMs在纯文本条件下表现优于人类平均水平，挑战了传统认为此类任务必须依赖视觉心理意象的观点。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs主要在训练数据包含的任务和纯语言任务上表现良好，限制了对其涌现的复杂认知能力的理解。本研究旨在测试LLMs是否能够完成传统上被认为必须依赖视觉心理意象的任务。

Method: 创建了数十个经典心理意象任务的新项目，首先测试多个最先进的纯文本LLMs，要求它们根据书面指令报告变换后的对象结果。然后测试100名人类受试者作为基线。最后测试不同推理级别的推理模型。

Result: 最好的LLMs表现显著高于人类平均水平。当模型分配更多推理token时，性能最强。这表明最好的LLMs可能具备完成依赖意象任务的能力，尽管其架构是非图像性的。

Conclusion: 研究不仅展示了LLMs在执行新任务时的涌现认知能力，还为该领域提供了一个有改进空间的新任务。这些发现重新引发了关于人类视觉意象表征格式的辩论，表明命题推理（或至少非意象推理）可能足以完成长期被认为依赖意象的任务。

Abstract: This study offers a novel approach for benchmarking complex cognitive
behavior in artificial systems. Almost universally, Large Language Models
(LLMs) perform best on tasks which may be included in their training data and
can be accomplished solely using natural language, limiting our understanding
of their emergent sophisticated cognitive capacities. In this work, we created
dozens of novel items of a classic mental imagery task from cognitive
psychology. A task which, traditionally, cognitive psychologists have argued is
solvable exclusively via visual mental imagery (i.e., language alone would be
insufficient). LLMs are perfect for testing this hypothesis. First, we tested
several state-of-the-art LLMs by giving text-only models written instructions
and asking them to report the resulting object after performing the
transformations in the aforementioned task. Then, we created a baseline by
testing 100 human subjects in exactly the same task. We found that the best
LLMs performed significantly above average human performance. Finally, we
tested reasoning models set to different levels of reasoning and found the
strongest performance when models allocate greater amounts of reasoning tokens.
These results provide evidence that the best LLMs may have the capability to
complete imagery-dependent tasks despite the non-pictorial nature of their
architectures. Our study not only demonstrates an emergent cognitive capacity
in LLMs while performing a novel task, but it also provides the field with a
new task that leaves lots of room for improvement in otherwise already highly
capable models. Finally, our findings reignite the debate over the formats of
representation of visual imagery in humans, suggesting that propositional
reasoning (or at least non-imagistic reasoning) may be sufficient to complete
tasks that were long-thought to be imagery-dependent.

</details>


### [147] [AttAnchor: Guiding Cross-Modal Token Alignment in VLMs with Attention Anchors](https://arxiv.org/abs/2509.23109)
*Junyang Zhang,Tianyi Zhu,Thierry Tambe*

Main category: cs.AI

TL;DR: 提出Attention Anchor框架，通过跨模态语义分组改善视觉语言模型中的长距离注意力问题，减少幻觉并提升性能


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型依赖直接拼接图像和文本token，使用模态盲目的位置编码，导致跨模态语义相关token之间不必要的长距离注意力，这是模型产生幻觉和性能不佳的主要原因

Method: 提出参数无关的Attention Anchor框架，通过将文本token插入到相关视觉块附近，创建语义路标，引导模型关注正确的图像区域，实现跨模态token的语义分组

Result: 在15个不同指标和基准测试中，13个获得提升，推理任务最高提升32%，幻觉基准最高提升15%。TinyLLaVA 1B在POPE上超越LLaVA 7B和QwenVL 3B，推理时间开销仅0.1%

Conclusion: Attention Anchor是首个研究混合模态token分组的工作，通过跨模态语义聚类而非单模态分组或后处理对齐，有效改善了视觉语言模型的性能

Abstract: A fundamental reason for the dominance of attention over RNNs and LSTMs in
LLMs is its ability to capture long-range dependencies by modeling direct
interactions between all tokens, overcoming the sequential limitations of
recurrent architectures. Similarly, a key reason why today's vision language
models (VLMs) hallucinate and underperform pure language models is that they
rely on direct concatenation of image and text tokens with a modality-blinded
positional encoding, which conveniently adopts the pretrained LLM backbone but
forces unnecessary long-distance attention between semantically related tokens
across modalities. This underscores the urgent need for mechanisms that
efficiently enhance token locality and cross-modal alignment. In response, we
propose Attention Anchor, a parameter-free framework that efficiently groups
semantically similar tokens across modalities, improving cross-modal locality.
By inserting text tokens near relevant visual patches, we create semantic
signposts that reveal true content-based cross-modal attention scores, guiding
the model to focus on the correct image regions for tasks such as VQA, MMBench
and POPE. This improves answer accuracy and reduces hallucinations without
disrupting the prompt's semantic flow. AttAnchor achieves improvements across
13 out of 15 different metrics and benchmarks, including up to 32% gains on
reasoning tasks and up to 15% improvements on hallucination benchmarks.
AttAnchor enables TinyLLaVA 1B to outperform much larger models like LLaVA 7B
and QwenVL 3B on POPE with only 0.1% inference time overhead. To the best of
our knowledge, this work is among the first to investigate mixed-modal token
grouping, where text and image tokens are clustered jointly into shared groups
rather than being grouped within a single modality or merely aligned post-hoc
with additional alignment losses.

</details>


### [148] [Exploring LLM-based Frameworks for Fault Diagnosis](https://arxiv.org/abs/2509.23113)
*Xian Yeow Lee,Lasitha Vidyaratne,Ahmed Farahat,Chetan Gupta*

Main category: cs.AI

TL;DR: 本研究探讨了基于大语言模型(LLM)的系统在工业环境中进行自主健康监测的潜力，重点分析了不同架构、输入表示和上下文窗口对故障诊断性能的影响。


<details>
  <summary>Details</summary>
Motivation: 利用LLM系统在传感器丰富的工业环境中实现自主健康监测，通过自然语言推理产生可解释的输出，提高故障检测和分类的透明度。

Method: 系统评估了LLM系统架构（单LLM vs 多LLM）、输入表示（原始数据 vs 描述性统计）和上下文窗口大小对诊断性能的影响。

Result: LLM系统在提供汇总统计输入时表现最佳，使用专门提示的多LLM系统相比单LLM系统在故障分类方面具有更高的灵敏度。LLM能够产生详细且人类可读的决策理由，但在持续学习环境中存在适应能力限制。

Conclusion: LLM系统作为复杂环境中透明、自适应诊断工具具有前景，但目前仍存在局限性，特别是在持续学习设置中的预测校准方面。

Abstract: Large Language Model (LLM)-based systems present new opportunities for
autonomous health monitoring in sensor-rich industrial environments. This study
explores the potential of LLMs to detect and classify faults directly from
sensor data, while producing inherently explainable outputs through natural
language reasoning. We systematically evaluate how LLM-system architecture
(single-LLM vs. multi-LLM), input representations (raw vs. descriptive
statistics), and context window size affect diagnostic performance. Our
findings show that LLM systems perform most effectively when provided with
summarized statistical inputs, and that systems with multiple LLMs using
specialized prompts offer improved sensitivity for fault classification
compared to single-LLM systems. While LLMs can produce detailed and
human-readable justifications for their decisions, we observe limitations in
their ability to adapt over time in continual learning settings, often
struggling to calibrate predictions during repeated fault cycles. These
insights point to both the promise and the current boundaries of LLM-based
systems as transparent, adaptive diagnostic tools in complex environments.

</details>


### [149] [Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges](https://arxiv.org/abs/2509.23121)
*Shuai Li,Chen Yizhe,Li Dong,Liu Sichao,Lan Dapeng,Liu Yu,Zhibo Pang*

Main category: cs.AI

TL;DR: 评估视觉语言动作模型在工业场景中的性能表现，分析其工业部署的局限性，发现VLA模型在简单抓取任务中表现良好，但在复杂环境、多样物体类别和高精度放置任务中仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 评估AI视觉语言动作模型是否满足工业部署要求，从工业应用角度分析现有最先进VLA模型的性能表现和局限性。

Method: 从工业部署视角比较现有最先进VLA模型在工业场景中的性能，并从数据收集和模型架构角度分析VLA模型在真实工业部署中的局限性。

Result: VLA模型在微调后仍能在工业环境中执行简单抓取任务，但在复杂工业环境、多样物体类别和高精度放置任务方面性能提升空间很大。

Conclusion: VLA模型具备工业应用潜力，但需要针对特定任务进行增强以提高其鲁棒性、泛化能力和精度。

Abstract: The application of artificial intelligence (AI) in industry is accelerating
the shift from traditional automation to intelligent systems with perception
and cognition. Vision language-action (VLA) models have been a key paradigm in
AI to unify perception, reasoning, and control. Has the performance of the VLA
models met the industrial requirements? In this paper, from the perspective of
industrial deployment, we compare the performance of existing state-of-the-art
VLA models in industrial scenarios and analyze the limitations of VLA models
for real-world industrial deployment from the perspectives of data collection
and model architecture. The results show that the VLA models retain their
ability to perform simple grasping tasks even in industrial settings after
fine-tuning. However, there is much room for performance improvement in complex
industrial environments, diverse object categories, and high precision placing
tasks. Our findings provide practical insight into the adaptability of VLA
models for industrial use and highlight the need for task-specific enhancements
to improve their robustness, generalization, and precision.

</details>


### [150] [SysMoBench: Evaluating AI on Formally Modeling Complex Real-World Systems](https://arxiv.org/abs/2509.23130)
*Qian Cheng,Ruize Tang,Emilie Ma,Finn Hackett,Peiyang He,Yiming Su,Ivan Beschastnikh,Yu Huang,Xiaoxing Ma,Tianyin Xu*

Main category: cs.AI

TL;DR: SysMoBench是一个评估AI为大型复杂系统生成形式化模型能力的基准测试，专注于并发和分布式系统，使用TLA+语言，包含9个系统组件并自动化评估指标。


<details>
  <summary>Details</summary>
Motivation: 形式化模型对大型复杂系统的规范和验证至关重要，但编写和维护成本高昂。现有AI方法主要针对小规模代码，不清楚AI是否能处理现实系统组件并将其复杂行为抽象为形式化模型。

Method: 创建SysMoBench基准测试，专注于并发和分布式系统，使用TLA+规范语言，自动化评估语法正确性、运行时正确性、与系统代码一致性以及不变式正确性等指标。

Result: SysMoBench目前包含9个多样化系统组件：Etcd和Redis的Raft实现、Asterinas OS的Spinlock和Mutex等，正在积极添加更多组件。

Conclusion: SysMoBench有助于理解当前LLM和智能体的能力与局限，为该领域工具提供坚实基础，并开辟有前景的新研究方向。

Abstract: Formal models are essential to specifying large, complex computer systems and
verifying their correctness, but are notoriously expensive to write and
maintain. Recent advances in generative AI show promise in generating certain
forms of specifications. However, existing work mostly targets small code, not
complete systems. It is unclear whether AI can deal with realistic system
artifacts, as this requires abstracting their complex behavioral properties
into formal models. We present SysMoBench, a benchmark that evaluates AI's
ability to formally model large, complex systems. We focus on concurrent and
distributed systems, which are keystones of today's critical computing
infrastructures, encompassing operating systems and cloud infrastructure. We
use TLA+, the it de facto specification language for concurrent and distributed
systems, though the benchmark can be extended to other specification languages.
We address the primary challenge of evaluating AI-generated models by
automating metrics like syntactic and runtime correctness, conformance to
system code, and invariant correctness. SysMoBench currently includes nine
diverse system artifacts: the Raft implementation of Etcd and Redis, the
Spinlock and Mutex in Asterinas OS, etc.; more artifacts are being actively
added. SysMoBench enables us to understand the capabilities and limitations of
today's LLMs and agents, putting tools in this area on a firm footing and
opening up promising new research directions.

</details>


### [151] [MathBode: Frequency-Domain Fingerprints of LLM Mathematical Reasoning](https://arxiv.org/abs/2509.23143)
*Charles L. Wang*

Main category: cs.AI

TL;DR: MathBode是一个用于评估大语言模型数学推理能力的动态诊断工具，通过正弦驱动参数变化并分析模型输出的频率响应，提供增益和相位等可解释指标。


<details>
  <summary>Details</summary>
Motivation: 传统的一次性准确率评估无法揭示模型在数学推理中的系统性问题，需要更精细的动态分析方法来评估推理的保真度和一致性。

Method: 将参数化问题视为系统，对单个参数进行正弦驱动，拟合模型输出和精确解的一阶谐波响应，获得增益（幅度跟踪）和相位（滞后）等频率解析指标。

Result: 在五个封闭形式问题族中，诊断揭示了系统性的低通行为和增长的相位滞后，这些是准确率指标无法发现的。结果将前沿模型与中端模型在动态特性上区分开来。

Conclusion: MathBode提供了一个紧凑、可复现的协议，通过可操作的推理保真度和一致性测量来补充标准基准测试，有助于进一步研究和应用。

Abstract: This paper presents MathBode, a dynamic diagnostic for mathematical reasoning
in large language models (LLMs). Instead of one-shot accuracy, MathBode treats
each parametric problem as a system: we drive a single parameter sinusoidally
and fit first-harmonic responses of model outputs and exact solutions. This
yields interpretable, frequency-resolved metrics -- gain (amplitude tracking)
and phase (lag) -- that form Bode-style fingerprints. Across five closed-form
families (linear solve, ratio/saturation, compound interest, 2x2 linear
systems, similar triangles), the diagnostic surfaces systematic low-pass
behavior and growing phase lag that accuracy alone obscures. We compare several
models against a symbolic baseline that calibrates the instrument ($G \approx
1$, $\phi \approx 0$). Results separate frontier from mid-tier models on
dynamics, providing a compact, reproducible protocol that complements standard
benchmarks with actionable measurements of reasoning fidelity and consistency.
We open-source the dataset and code to enable further research and adoption.

</details>


### [152] [Coordination Requires Simplification: Thermodynamic Bounds on Multi-Objective Compromise in Natural and Artificial Intelligence](https://arxiv.org/abs/2509.23144)
*Atma Anand*

Main category: cs.AI

TL;DR: 该论文提出了热力学协调理论(TCT)，证明多智能体协调存在基本的热力学约束，协调协议需要激进的信息丢失，最大效用解的选择压力在于可发现性而非准确性。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体多目标信息处理系统中的基本热力学约束，解释为什么协调需要信息丢失，以及为什么某些协调解比其他解更容易被发现和采用。

Method: 推导协调协议的最小描述长度公式，定义协调温度来预测临界现象，扩展Arrow定理的拓扑版本，分析协调动力学如何改变环境本身。

Result: 发现协调协议描述长度随智能体数量、目标数量和精度呈多项式增长，协调需要渐进简化，产生持久亚稳态和滞后现象，直到环境重大变化触发相变。

Conclusion: 协调需要激进的信息丢失，这解释了多目标梯度下降中的无限循环和大型语言模型中对齐伪造现象，为理解各种系统中的协调现象提供了统一框架。

Abstract: Information-processing systems coordinating across multiple agents and
objectives face fundamental thermodynamic constraints. We show that solutions
with maximum utility to act as coordination focal points have much higher
selection pressure for being findable across agents rather than accuracy. We
derive that the information-theoretic minimum description length of
coordination protocols to precision $\varepsilon$ scales as $L(P)\geq NK\log_2
K+N^2d^2\log (1/\varepsilon)$ for $N$ agents with $d$ potentially conflicting
objectives and internal model complexity $K$. This scaling forces progressive
simplification, with coordination dynamics changing the environment itself and
shifting optimization across hierarchical levels. Moving from established focal
points requires re-coordination, creating persistent metastable states and
hysteresis until significant environmental shifts trigger phase transitions
through spontaneous symmetry breaking. We operationally define coordination
temperature to predict critical phenomena and estimate coordination work costs,
identifying measurable signatures across systems from neural networks to
restaurant bills to bureaucracies. Extending the topological version of Arrow's
theorem on the impossibility of consistent preference aggregation, we find it
recursively binds whenever preferences are combined. This potentially explains
the indefinite cycling in multi-objective gradient descent and alignment faking
in Large Language Models trained with reinforcement learning with human
feedback. We term this framework Thermodynamic Coordination Theory (TCT), which
demonstrates that coordination requires radical information loss.

</details>


### [153] [AI-Enhanced Distributed Channel Access for Collision Avoidance in Future Wi-Fi 8](https://arxiv.org/abs/2509.23154)
*Jinzhe Pan,Jingqing Wang,Yuehui Ouyang,Wenchi Cheng,Wei Zhang*

Main category: cs.AI

TL;DR: 提出基于多智能体强化学习的Wi-Fi信道接入优化框架，通过动态退避选择和公平性量化指标，在保持与传统设备兼容的同时显著降低碰撞概率并保证公平性。


<details>
  <summary>Details</summary>
Motivation: 当前Wi-Fi系统使用的二进制指数退避机制在密集部署中碰撞解决效果不佳，且存在固有的随机性导致的公平性问题，无法满足新兴应用对可靠性的严格要求。

Method: 开发动态退避选择机制，基于接入延迟事件实时适应信道条件；提出与EDCA原则一致的公平性量化指标；采用集中训练分散执行架构，结合邻域活动模式作为观测输入，使用约束多智能体近端策略优化进行联合优化。

Result: 实验结果表明，相比传统BEB机制，该方案显著降低了碰撞概率，同时保持与商用Wi-Fi设备的向后兼容性，提出的公平性指标有效消除了异构场景中的饥饿风险。

Conclusion: 该AI优化框架成功解决了Wi-Fi系统中碰撞和公平性的根本问题，为密集无线环境提供了可靠的信道接入解决方案。

Abstract: The exponential growth of wireless devices and stringent reliability
requirements of emerging applications demand fundamental improvements in
distributed channel access mechanisms for unlicensed bands. Current Wi-Fi
systems, which rely on binary exponential backoff (BEB), suffer from suboptimal
collision resolution in dense deployments and persistent fairness challenges
due to inherent randomness. This paper introduces a multi-agent reinforcement
learning framework that integrates artificial intelligence (AI) optimization
with legacy device coexistence. We first develop a dynamic backoff selection
mechanism that adapts to real-time channel conditions through access deferral
events while maintaining full compatibility with conventional CSMA/CA
operations. Second, we introduce a fairness quantification metric aligned with
enhanced distributed channel access (EDCA) principles to ensure equitable
medium access opportunities. Finally, we propose a centralized training
decentralized execution (CTDE) architecture incorporating neighborhood activity
patterns as observational inputs, optimized via constrained multi-agent
proximal policy optimization (MAPPO) to jointly minimize collisions and
guarantee fairness. Experimental results demonstrate that our solution
significantly reduces collision probability compared to conventional BEB while
preserving backward compatibility with commercial Wi-Fi devices. The proposed
fairness metric effectively eliminates starvation risks in heterogeneous
scenarios.

</details>


### [154] [Limit Analysis for Symbolic Multi-step Reasoning Tasks with Information Propagation Rules Based on Transformers](https://arxiv.org/abs/2509.23178)
*Tian Qin,Yuhan Chen,Zhiwei Wang,Zhi-Qin John Xu*

Main category: cs.AI

TL;DR: 该论文分析了Transformer在推理任务中的内在机制，提出了基于Transformer的信息传播规则，并使用符号推理任务从理论上分析了推理步骤的极限。


<details>
  <summary>Details</summary>
Motivation: Transformer能够执行推理任务，但其内在机制仍然不明确。本文旨在通过理论分析揭示Transformer的推理能力极限。

Method: 提出了一套基于Transformer的信息传播规则，并利用符号推理任务进行理论分析。

Result: 研究表明，对于具有L个注意力层的模型，在单次前向传播中的极限推理步骤数在O(3^{L-1})和O(2^{L-1})之间。

Conclusion: Transformer的推理能力受到注意力层数的限制，单次前向传播的推理步骤数呈指数级增长，但存在明确的上限。

Abstract: Transformers are able to perform reasoning tasks, however the intrinsic
mechanism remains widely open. In this paper we propose a set of information
propagation rules based on Transformers and utilize symbolic reasoning tasks to
theoretically analyze the limit reasoning steps. We show that the limit number
of reasoning steps is between $O(3^{L-1})$ and $O(2^{L-1})$ for a model with
$L$ attention layers in a single-pass.

</details>


### [155] [Understanding and Enhancing the Planning Capability of Language Models via Multi-Token Prediction](https://arxiv.org/abs/2509.23186)
*Qimin Zhong,Hao Liao,Siwei Wang,Mingyang Zhou,Xiaoqun Wu,Rui Mao,Wei Chen*

Main category: cs.AI

TL;DR: 论文研究了多令牌预测(MTP)范式对Transformer学习传递关系的影响，提出了两种改进策略来增强模型在复杂规划任务中的路径规划能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多样任务中表现优异，但在学习传递关系方面仍有困难，而传递关系是复杂规划的基石。

Method: 理论分析MTP范式，提出两种改进策略：下一令牌注入(NTI)和基于Transformer的传输层。

Result: 在合成图和Blocksworld规划基准上的实验验证了理论发现，改进策略显著增强了模型的路径规划能力。

Conclusion: 这些发现深化了对Transformer在复杂规划任务中学习机制的理解，为克服传递性瓶颈提供了实用策略，推动了结构感知和通用规划模型的发展。

Abstract: Large Language Models (LLMs) have achieved impressive performance across
diverse tasks but continue to struggle with learning transitive relations, a
cornerstone for complex planning. To address this issue, we investigate the
Multi-Token Prediction (MTP) paradigm and its impact to transitive relation
learning. We theoretically analyze the MTP paradigm using a Transformer
architecture composed of a shared output head and a transfer layer. Our
analysis reveals that the transfer layer gradually learns the multi-step
adjacency information, which in turn enables the backbone model to capture
unobserved transitive reachability relations beyond those directly present in
the training data, albeit with some inevitable noise in adjacency estimation.
Building on this foundation, we propose two strategies to enhance the transfer
layer and overall learning quality: Next-Token Injection (NTI) and a
Transformer-based transfer layer. Our experiments on both synthetic graphs and
the Blocksworld planning benchmark validate our theoretical findings and
demonstrate that the improvements significantly enhance the model's
path-planning capability. These findings deepen our understanding of how
Transformers with MTP learn in complex planning tasks, and provide practical
strategies to overcome the transitivity bottleneck, paving the way toward
structurally aware and general-purpose planning models.

</details>


### [156] [AutoEP: LLMs-Driven Automation of Hyperparameter Evolution for Metaheuristic Algorithms](https://arxiv.org/abs/2509.23189)
*Zhenxing Xu,Yizhe Zhang,Weidong Bao,Hao Wang,Ming Chen,Haoran Ye,Wenzheng Jiang,Hui Yan,Ji Wang*

Main category: cs.AI

TL;DR: AutoEP是一个无需训练的算法超参数配置框架，利用大语言模型作为零样本推理引擎，通过在线探索性景观分析和多LLM推理链实现自适应超参数策略。


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的超参数配置方法存在样本复杂度高、泛化能力差的问题，需要一种无需训练且能有效利用LLM推理能力的新方法。

Method: 结合在线探索性景观分析模块提供实时搜索动态反馈，以及多LLM推理链解释反馈并生成自适应超参数策略，将高层次推理与实证数据相结合。

Result: 在多种组合优化基准测试中，AutoEP持续优于包括神经进化和其他基于LLM的方法在内的最先进调优器，开源模型Qwen3-30B能达到GPT-4的性能水平。

Conclusion: AutoEP为自动化超参数设计提供了一个强大且易用的新范式，证明了LLM作为零样本推理引擎在算法控制中的有效性。

Abstract: Dynamically configuring algorithm hyperparameters is a fundamental challenge
in computational intelligence. While learning-based methods offer automation,
they suffer from prohibitive sample complexity and poor generalization. We
introduce AutoEP, a novel framework that bypasses training entirely by
leveraging Large Language Models (LLMs) as zero-shot reasoning engines for
algorithm control. AutoEP's core innovation lies in a tight synergy between two
components: (1) an online Exploratory Landscape Analysis (ELA) module that
provides real-time, quantitative feedback on the search dynamics, and (2) a
multi-LLM reasoning chain that interprets this feedback to generate adaptive
hyperparameter strategies. This approach grounds high-level reasoning in
empirical data, mitigating hallucination. Evaluated on three distinct
metaheuristics across diverse combinatorial optimization benchmarks, AutoEP
consistently outperforms state-of-the-art tuners, including neural evolution
and other LLM-based methods. Notably, our framework enables open-source models
like Qwen3-30B to match the performance of GPT-4, demonstrating a powerful and
accessible new paradigm for automated hyperparameter design. Our code is
available at https://anonymous.4open.science/r/AutoEP-3E11

</details>


### [157] [$p$-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding](https://arxiv.org/abs/2509.23234)
*Runyan Tan,Shuang Wu,Phillip Howard*

Main category: cs.AI

TL;DR: 提出了一种无超参数的p-less采样方法，基于信息论动态设置截断阈值，在不同温度下都能产生高质量输出，无需手动调参。


<details>
  <summary>Details</summary>
Motivation: 现有采样方法性能对超参数敏感，需要根据不同生成任务和温度配置调整参数，这增加了使用复杂度。

Method: 基于信息论的p-less采样方法，在每个解码步骤根据整个token概率分布动态设置截断阈值，无需超参数。

Result: 在数学、逻辑推理和创意写作任务中，p-less采样始终优于现有方法，在高温下文本质量下降更少，且推理效率更高。

Conclusion: p-less采样是一种无需超参数的高效采样方法，在不同温度下都能保持高质量输出，具有更好的鲁棒性和效率。

Abstract: Obtaining high-quality outputs from Large Language Models (LLMs) often
depends upon the choice of a sampling-based decoding strategy to
probabilistically choose the next token at each generation step. While a
variety of such sampling methods have been proposed, their performance can be
sensitive to the selection of hyperparameters which may require different
settings depending upon the generation task and temperature configuration. In
this work, we introduce $p$-less sampling: an information-theoretic approach to
sampling which dynamically sets a truncation threshold at each decoding step
based on the entire token probability distribution. Unlike existing methods,
$p$-less sampling has no hyperparameters and consistently produces high-quality
outputs as temperature increases. We provide theoretical perspectives on
$p$-less sampling to ground our proposed method and conduct experiments to
empirically validate its effectiveness across a range of math, logical
reasoning, and creative writing tasks. Our results demonstrate how $p$-less
sampling consistently outperforms existing sampling approaches while exhibiting
much less degradation in text quality at higher temperature values. We further
show how $p$-less achieves greater inference-time efficiency than alternative
methods through lower average token sampling times and shorter generation
lengths, without sacrificing accuracy. Finally, we provide analyses to
highlight the benefits of $p$-less through qualitative examples, case studies,
and diversity assessments.

</details>


### [158] [Agentic AI Reasoning for Mobile Edge General Intelligence: Fundamentals, Approaches, and Directions](https://arxiv.org/abs/2509.23248)
*Mingyi Luo,Ruichen Zhang,Xiangwang Hou,Jun Du,Chunxiao Jiang,Yong Ren,Dusit Niyato,Shiwen Mao*

Main category: cs.AI

TL;DR: 提出了一种用于移动边缘通用智能(MEGI)环境中高效LLM推理部署的联合优化框架，通过自适应思维链提示和分布式专家混合架构来平衡推理质量与资源效率。


<details>
  <summary>Details</summary>
Motivation: 在MEGI环境中部署基于LLM的智能体AI推理面临重大挑战，因为推理计算需求高而边缘设备资源有限。

Method: 提出了一个联合优化框架，包括：1) 通过自适应CoT提示增强推理能力；2) 通过分布式MoE架构实现可扩展部署；3) 根据任务复杂度和设备能力动态激活专家网络和调整推理深度。

Result: 实验结果表明该框架在平衡推理质量与资源效率方面具有有效性，验证了在资源受限的MEGI环境中部署复杂LLM推理能力的实际可行性。

Conclusion: 该研究为在资源受限的边缘计算环境中部署高效的LLM推理系统提供了可行的解决方案，推动了移动边缘通用智能的实际应用。

Abstract: The rapid advancement of large language models (LLMs) has enabled an
emergence of agentic artificial intelligence (AI) with powerful reasoning and
autonomous decision-making capabilities. This integration with edge computing
has led to the development of Mobile Edge General Intelligence (MEGI), which
brings real-time, privacy-preserving reasoning to the network edge. However,
deploying LLM-based agentic AI reasoning in MEGI environments poses significant
challenges due to the high computational demands of reasoning and the limited
resources of edge devices. To address these challenges, we propose a joint
optimization framework for efficient LLM reasoning deployment in MEGI. First,
we review methods that enhance LLM reasoning capabilities, such as
Chain-of-Thought (CoT) prompting, Supervised Fine-Tuning (SFT), and Mixture of
Experts (MoE). Next, we present a distributed framework that addresses two
correlated aspects: reasoning enhancement through adaptive CoT prompting and
scalable deployment through distributed MoE architecture. The framework
dynamically activates expert networks and adjusts reasoning depth based on task
complexity and device capabilities. We further conduct experimental evaluations
in mobile edge environments. Experimental results demonstrate the framework's
effectiveness in balancing reasoning quality with resource efficiency,
validating the practical viability of deploying sophisticated LLM reasoning
capabilities in resource-constrained MEGI environments.

</details>


### [159] [Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned](https://arxiv.org/abs/2509.23250)
*Brandon Ong,Tej Deep Pala,Vernon Toh,William Chandra Tjhi,Soujanya Poria*

Main category: cs.AI

TL;DR: 本文探索了视觉语言过程奖励模型(VL-PRMs)的设计空间，提出了混合数据合成框架和感知聚焦监督方法，在五个多模态基准测试中验证了VL-PRMs在提升视觉语言模型推理可靠性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言过程奖励模型(VL-PRMs)依赖蒙特卡洛树搜索进行数据构建，会产生噪声监督信号且跨任务泛化能力有限，需要探索更有效的VL-PRMs设计方法。

Method: 提出混合数据合成框架(结合MCTS和强VLM判断)，感知聚焦监督方法，以及系统评估多种测试时扩展策略。

Result: 实验表明：VL-PRMs作为结果奖励模型优于过程步骤选择；小模型可匹配或超越大模型；能发掘强VLM的潜在推理能力；感知监督带来显著增益；在不同数学推理数据集上均有改进。

Conclusion: VL-PRMs能有效提升视觉语言模型的推理可靠性，为VLM的进一步发展提供了重要支持。

Abstract: Process Reward Models (PRMs) provide step-level supervision that improves the
reliability of reasoning in large language models. While PRMs have been
extensively studied in text-based domains, their extension to Vision Language
Models (VLMs) remains limited. Existing Vision-Language PRMs (VL-PRMs) rely on
Monte Carlo Tree Search (MCTS) for data construction, which can often produce
noisy supervision signals and limit generalization across tasks. In this work,
we aim to elucidate the design space of VL-PRMs by exploring diverse strategies
for dataset construction, training, and test-time scaling. First, we introduce
a hybrid data synthesis framework that combines MCTS with judgments from a
strong VLM, producing more accurate step-level labels. Second, we propose
perception-focused supervision, enabling our PRM to explicitly detect errors at
the visual grounding stage of reasoning. Third, we systematically evaluate
multiple test-time scaling strategies, showing that our PRMs can reliably guide
VLMs toward more accurate solutions. Our experiments covering five diverse
multimodal benchmarks (MMMU, PuzzleVQA, AlgoPuzzleVQA, MathVista, and
MathVision) reveal several key insights: (i) VL-PRMs when used as Outcome
Reward Models (ORMs) during test-time scaling (TTS) can outperform VL-PRM
guided process step selection, (ii) smaller VL-PRMs can match or even surpass
larger ones in detecting process errors, (iii) VL-PRMs uncover latent reasoning
abilities in stronger VLM backbones, (iv) perception-level supervision leads to
significant gains in test-time scaling, and (v) TTS performance of different
policies improve on advanced math reasoning datasets despite not training
VL-PRMs on such datasets. We hope our work will motivate further research and
support the advancement of VLMs.

</details>


### [160] [GUI-PRA: Process Reward Agent for GUI Tasks](https://arxiv.org/abs/2509.23263)
*Tao Xiong,Xavier Hu,Yurun Chen,Yuhang Liu,Changqiao Wu,Pengzhi Gao,Wei Liu,Jian Luan,Shengyu Zhang*

Main category: cs.AI

TL;DR: 本文提出了GUI-PRA，一种针对GUI任务的流程奖励代理，通过动态记忆机制和自适应UI感知来解决标准流程奖励模型在GUI领域面临的"迷失在中间"现象和缺乏UI变化感知的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI代理在处理长时程任务时经常失败，而标准流程奖励模型在处理密集的人工输入和长历史数据时会出现"迷失在中间"现象，且缺乏GUI变化感知能力，无法适应GUI任务的动态特性。

Method: GUI-PRA包含两个核心机制：1）动态记忆机制，包括基于相关性的检索模块和渐进式总结模块；2）自适应UI感知机制，能够推理UI状态变化并动态选择工具收集视觉证据。

Result: GUI-PRA能够更好地提供流程奖励，通过智能处理历史上下文和主动感知UI状态变化，解决了标准PRM在GUI任务中的局限性。

Conclusion: GUI-PRA通过创新的动态记忆和自适应UI感知机制，显著提升了GUI代理在长时程任务中的表现，为GUI领域的流程奖励建模提供了有效解决方案。

Abstract: Graphical User Interface (GUI) Agents powered by Multimodal Large Language
Models (MLLMs) show significant potential for automating tasks. However, they
often struggle with long-horizon tasks, leading to frequent failures. Process
Reward Models (PRMs) are a promising solution, as they can guide these agents
with crucial process signals during inference. Nevertheless, their application
to the GUI domain presents unique challenges. When processing dense artificial
inputs with long history data, PRMs suffer from a "lost in the middle"
phenomenon, where the overwhelming historical context compromises the
evaluation of the current step. Furthermore, standard PRMs lacks GUI changing
awareness, providing static evaluations that are disconnected from the dynamic
consequences of actions, a critical mismatch with the inherently dynamic nature
of GUI tasks. In response to these challenges, we introduce GUI-PRA (Process
Reward Agent for GUI Tasks), a judge agent designed to better provide process
reward than standard PRM by intelligently processing historical context and
actively perceiving UI state changes. Specifically, to directly combat the
``lost in the middle'' phenomenon, we introduce a dynamic memory mechanism
consisting of two core components: a Relevance-based Retrieval Module to
actively fetch pertinent information from long histories and a Progressive
Summarization Module to dynamically condense growing interaction data, ensuring
the model focuses on relevant context. Moreover, to address the lack of UI
changing awareness, we introduce an Aadaptive UI Perception mechanism. This
mechanism enables the agent to reason about UI state changes and dynamically
select the most appropriate tool to gather grounded visual evidence, ensuring
its evaluation is always informed by the current UI context.

</details>


### [161] [Socio-Economic Model of AI Agents](https://arxiv.org/abs/2509.23270)
*Yuxinyue Qian,Jun Liu*

Main category: cs.AI

TL;DR: 构建包含人类工作者和自主AI代理的异质代理模型，研究AI协作在资源约束下对社会总产出的影响，发现AI代理能显著提升产出，网络效应带来非线性增长。


<details>
  <summary>Details</summary>
Motivation: 研究人工智能技术与社会经济系统深度融合背景下，AI协作在资源约束条件下对社会总产出的影响机制。

Method: 构建五个渐进扩展的异质代理模型：纯人类协作基准模型、引入AI协作模型、加入代理间网络效应模型、代理作为独立生产者模型、综合网络效应和独立生产模型。

Result: AI代理引入显著增加社会总产出；考虑网络效应时，产出增长呈非线性，远超个体贡献简单加总；相同资源投入下，代理作为独立生产者具有更高长期增长潜力；网络效应进一步展现强规模报酬递增特性。

Conclusion: AI协作能有效提升社会经济系统产出，网络效应和独立生产模式是推动非线性增长和规模报酬递增的关键因素。

Abstract: Modern socio-economic systems are undergoing deep integration with artificial
intelligence technologies. This paper constructs a heterogeneous agent-based
modeling framework that incorporates both human workers and autonomous AI
agents, to study the impact of AI collaboration under resource constraints on
aggregate social output. We build five progressively extended models: Model 1
serves as the baseline of pure human collaboration; Model 2 introduces AI as
collaborators; Model 3 incorporates network effects among agents; Model 4
treats agents as independent producers; and Model 5 integrates both network
effects and independent agent production. Through theoretical derivation and
simulation analysis, we find that the introduction of AI agents can
significantly increase aggregate social output. When considering network
effects among agents, this increase exhibits nonlinear growth far exceeding the
simple sum of individual contributions. Under the same resource inputs,
treating agents as independent producers provides higher long-term growth
potential; introducing network effects further demonstrates strong
characteristics of increasing returns to scale.

</details>


### [162] [Toward Effective Tool-Integrated Reasoning via Self-Evolved Preference Learning](https://arxiv.org/abs/2509.23285)
*Yifei Chen,Guanting Dong,Zhicheng Dou*

Main category: cs.AI

TL;DR: 提出了Tool-Light框架，通过信息熵分析工具调用对推理的影响，采用多阶段微调方法提升LLMs在工具集成推理中的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有工具集成推理方法存在工具使用不足或过度、工具调用后过度思考等问题，需要激励LLMs更高效准确地进行推理。

Method: 基于信息熵分析工具调用影响，构建包含普通采样和熵引导采样的自演化数据集，采用两阶段训练（SFT和自演化DPO）。

Result: 在10个数据集上的实验证明Tool-Light能显著提升模型执行TIR任务的效率。

Conclusion: Tool-Light框架通过信息熵分析和多阶段微调，有效解决了工具集成推理中的效率问题，提升了LLMs的推理能力。

Abstract: Tool-Integrated Reasoning (TIR) enables large language models (LLMs) to
improve their internal reasoning ability by integrating external tools.
However, models employing TIR often display suboptimal behaviors, such as
insufficient or excessive tool usage and overthinking after tool calls. The
challenge of incentivizing LLMs to perform TIR efficiently and accurately,
while stabilizing the reasoning process, remains an open question. In this
paper, we start by exploring the impact of tool calls on model reasoning from
the perspective of information entropy. Our findings indicate that tool call
results lead to a distinct change in the information entropy of subsequent
reasoning, with the overall entropy of the reasoning chain varying based on the
number of tool calls. Building on these insights, we propose Tool-Light, a
framework designed to encourage LLMs to perform TIR efficiently and accurately.
Our framework includes dataset construction and multi-stage fine-tuning. For
dataset construction, we employ continuous self-evolved sampling using the
fine-tuned model, integrating both vanilla sampling and entropy-guided
sampling. Besides, we establish strict criteria for selecting positive-negative
pairs during sampling. The training process involves a two-stage approach,
comprising Supervised Fine-Tuning (SFT) and Self-Evolved Direct Preference
Optimization (DPO). Experimental results on 10 datasets demonstrate the
effectiveness of Tool-Light, significantly improving the model's efficiency in
executing TIR tasks.

</details>


### [163] [Learning How to Use Tools, Not Just When: Pattern-Aware Tool-Integrated Reasoning](https://arxiv.org/abs/2509.23292)
*Ningning Xu,Yuxuan Jiang,Shubhashis Roy Dipta*

Main category: cs.AI

TL;DR: 提出了一种两阶段框架，通过识别计算器模式和算法模式两种代码使用模式，并让模型学习如何选择合适模式，显著提升了工具集成推理在数学问题上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有工具集成推理研究主要关注何时调用工具，而忽略了如何使用工具。作者发现代码使用模式选择不当会导致失败，即使推理过程本身是正确的。

Method: 提出两阶段框架：首先从计算器模式（直接计算）和算法模式（将问题编码为程序）两种模式中构建代码能力，然后通过教师偏好对齐模式选择。

Result: 在多个挑战性数学数据集上显著提升了代码使用和准确性，例如在MATH500上Code@1从64.0%提升到70.5%，在AIME24上从26.7%提升到50.0%。

Conclusion: 模式感知的方法对于工具集成推理非常有效，正确的代码使用模式选择对性能提升至关重要。

Abstract: Tool-integrated reasoning (TIR) has become a key approach for improving large
reasoning models (LRMs) on complex problems. Prior work has mainly studied when
to invoke tools, while overlooking how tools are applied. We identify two
common patterns: a calculator pattern that uses code for direct computation,
and an algorithmic pattern that encodes problems as programs. Misaligned
choices often cause failures even when reasoning is sound. We propose a
two-stage framework that first builds code competence from both patterns and
then aligns pattern selection with teacher preferences. Across challenging math
datasets, our pattern-aware method substantially improves both code usage and
accuracy, for instance raising Code@1 on MATH500 from 64.0% to 70.5% and on
AIME24 from 26.7% to 50.0%. These gains highlight the effectiveness of a
pattern-aware approach for tool-integrated reasoning.

</details>


### [164] [Your Models Have Thought Enough: Training Large Reasoning Models to Stop Overthinking](https://arxiv.org/abs/2509.23392)
*Jinyi Han,Ying Huang,Ying Liao,Zishang Jiang,Xikun Lu,Haiquan Zhao,Xinyi Wang,Guanghao Zhou,Sihang Jiang,Jiaqing Liang,Weikang Zhou,Zeye Sun,Fei Yu,Yanghua Xiao*

Main category: cs.AI

TL;DR: 提出JET方法，通过主动终止不必要的推理步骤来提升大型推理模型的效率，在保持准确性的同时显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在深度推理时计算成本高昂，现有强化学习方法难以在推理过程中构建短路径，限制了有效学习。研究发现模型在推理早期已积累足够信息，后续步骤是冗余的。

Method: JET方法在推理过程中进行轨迹截断，让模型接触分布一致的短推理路径，并使用质量控制的长度奖励来鼓励简洁推理同时保持正确性。

Result: 实验表明JET显著提升推理效率而不牺牲准确性，DeepSeek-Distill-Qwen-1.5B在奥林匹克基准测试中准确率提升4.6%，输出长度减少46.3%。

Conclusion: JET方法通过主动终止冗余推理步骤，有效解决了大型推理模型的计算效率问题，实现了准确性和效率的双重提升。

Abstract: Large Reasoning Models (LRMs) have achieved impressive performance on
challenging tasks, yet their deep reasoning often incurs substantial
computational costs. To achieve efficient reasoning, existing reinforcement
learning methods still struggle to construct short reasoning path during the
rollout stage, limiting effective learning. Inspired by Evidence Accumulation
Models, we find that LRMs have accumulated sufficient information early in
reasoning, making further reasoning steps redundant. Based on this insight, we
propose Just-Enough Thinking (JET), which trains models to proactively
terminate unnecessary reasoning. JET performs trajectory truncation during
rollout to expose the model to short, distributionally consistent reasoning
paths. Besides, it uses a quality-controlled length reward to better encourage
concise reasoning while maintaining correctness. Extensive experiments
demonstrate that JET significantly improves reasoning efficiency without
sacrificing accuracy. Especially, DeepSeek-Distill-Qwen-1.5B achieves a 4.6%
accuracy gain while reducing output length by 46.3% on the Olympiad benchmark.
Our code is available in the GitHub.

</details>


### [165] [From Conversation to Query Execution: Benchmarking User and Tool Interactions for EHR Database Agents](https://arxiv.org/abs/2509.23415)
*Gyubok Lee,Woosog Chay,Heeyoung Kwak,Yeong Hwa Kim,Haanju Yoo,Oksoon Jeong,Meong Hi Son,Edward Choi*

Main category: cs.AI

TL;DR: EHR-ChatQA是一个用于评估LLM驱动代理在电子健康记录数据库问答中表现的新基准，重点关注查询模糊性和术语不匹配问题，通过两种交互流程测试代理的稳健性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够真实反映临床数据访问流程的基准测试，阻碍了LLM代理在电子健康记录系统中的实际部署。主要挑战包括用户问题的模糊性和用户术语与数据库条目不匹配。

Method: 引入EHR-ChatQA交互式数据库问答基准，在模拟环境中使用LLM用户评估代理性能，包含两种交互流程：增量查询精炼（IncreQA）和自适应查询精炼（AdaptQA）。

Result: 实验显示，最先进的LLM在IncreQA上Pass@5达到90-95%，AdaptQA上达到60-80%，但Pass^5（五次试验全部成功）显著降低35-60%，表明代理缺乏稳健性。

Conclusion: 在安全关键的电子健康记录领域，需要构建不仅性能高而且稳健的代理系统，论文提供了常见失败模式的诊断见解以指导未来开发。

Abstract: Despite the impressive performance of LLM-powered agents, their adoption for
Electronic Health Record (EHR) data access remains limited by the absence of
benchmarks that adequately capture real-world clinical data access flows. In
practice, two core challenges hinder deployment: query ambiguity from vague
user questions and value mismatch between user terminology and database
entries. To address this, we introduce EHR-ChatQA an interactive database
question answering benchmark that evaluates the end-to-end workflow of database
agents: clarifying user questions, using tools to resolve value mismatches, and
generating correct SQL to deliver accurate answers. To cover diverse patterns
of query ambiguity and value mismatch, EHR-ChatQA assesses agents in a
simulated environment with an LLM-based user across two interaction flows:
Incremental Query Refinement (IncreQA), where users add constraints to existing
queries, and Adaptive Query Refinement (AdaptQA), where users adjust their
search goals mid-conversation. Experiments with state-of-the-art LLMs (e.g.,
o4-mini and Gemini-2.5-Flash) over five i.i.d. trials show that while agents
achieve high Pass@5 of 90-95% (at least one of five trials) on IncreQA and
60-80% on AdaptQA, their Pass^5 (consistent success across all five trials) is
substantially lower by 35-60%. These results underscore the need to build
agents that are not only performant but also robust for the safety-critical EHR
domain. Finally, we provide diagnostic insights into common failure modes to
guide future agent development.

</details>


### [166] [Democratizing AI scientists using ToolUniverse](https://arxiv.org/abs/2509.23426)
*Shanghua Gao,Richard Zhu,Pengwei Sui,Zhenglun Kong,Sufian Aldogom,Yepeng Huang,Ayush Noori,Reza Shamji,Krishna Parvataneni,Theodoros Tsiligkaridis,Marinka Zitnik*

Main category: cs.AI

TL;DR: ToolUniverse是一个用于构建AI科学家的生态系统，它标准化了AI科学家识别和调用工具的方式，集成了600多个机器学习模型、数据集、API和科学包，并能自动优化工具接口、从自然语言创建新工具，以及组合工具形成智能工作流。


<details>
  <summary>Details</summary>
Motivation: 现有的AI科学家系统难以构建，因为它们是个性化定制的、绑定在固定工作流程中，并且缺乏将工具、数据和分析统一到共同生态系统中的共享环境。

Method: ToolUniverse标准化了AI科学家识别和调用工具的方式，自动优化工具接口以确保正确使用，从自然语言描述创建新工具，迭代优化工具规范，并将工具组合成智能工作流。

Result: 在高胆固醇血症的案例研究中，ToolUniverse被用来创建一个AI科学家，成功识别出一种具有良好预测特性的药物类似物。

Conclusion: ToolUniverse为构建AI科学家提供了必要的基础设施，类似于组学领域统一生态系统对研究的变革作用，支持互操作性、重用和社区驱动开发。

Abstract: AI scientists are emerging computational systems that serve as collaborative
partners in discovery. These systems remain difficult to build because they are
bespoke, tied to rigid workflows, and lack shared environments that unify
tools, data, and analyses into a common ecosystem. In omics, unified ecosystems
have transformed research by enabling interoperability, reuse, and
community-driven development; AI scientists require comparable infrastructure.
We present ToolUniverse, an ecosystem for building AI scientists from any
language or reasoning model, whether open or closed. TOOLUNIVERSE standardizes
how AI scientists identify and call tools, integrating more than 600 machine
learning models, datasets, APIs, and scientific packages for data analysis,
knowledge retrieval, and experimental design. It automatically refines tool
interfaces for correct use by AI scientists, creates new tools from natural
language descriptions, iteratively optimizes tool specifications, and composes
tools into agentic workflows. In a case study of hypercholesterolemia,
ToolUniverse was used to create an AI scientist to identify a potent analog of
a drug with favorable predicted properties. The open-source ToolUniverse is
available at https://aiscientist.tools.

</details>


### [167] [Beyond Embeddings: Interpretable Feature Extraction for Binary Code Similarity](https://arxiv.org/abs/2509.23449)
*Charles E. Gagnon,Steven H. H. Ding,Philippe Charland,Benjamin C. M. Fung*

Main category: cs.AI

TL;DR: 提出了一种基于语言模型代理的方法，通过结构化推理分析汇编代码生成可解释特征，解决了二进制代码相似性检测中可解释性、泛化性和可扩展性的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有二进制代码相似性检测方法存在局限性：手工特征可解释但泛化能力差，嵌入方法泛化好但可解释性差且面临可扩展性-准确性权衡。需要一种能同时保证准确性、可扩展性和可解释性的方法。

Method: 使用语言模型代理对汇编代码进行结构化推理分析，生成输入/输出类型、副作用、显著常数和算法意图等人类可读特征。这些特征可直接通过倒排索引或关系索引进行搜索。

Result: 无需匹配训练，在跨架构和跨优化任务中分别达到42%和62%的recall@1，与需要训练的嵌入方法相当（39%和34%）。与嵌入方法结合后显著优于现有最优方法。

Conclusion: 该方法证明准确性、可扩展性和可解释性可以共存，为二进制代码相似性检测提供了新的解决方案。

Abstract: Binary code similarity detection is a core task in reverse engineering. It
supports malware analysis and vulnerability discovery by identifying
semantically similar code in different contexts. Modern methods have progressed
from manually engineered features to vector representations. Hand-crafted
statistics (e.g., operation ratios) are interpretable, but shallow and fail to
generalize. Embedding-based methods overcome this by learning robust
cross-setting representations, but these representations are opaque vectors
that prevent rapid verification. They also face a scalability-accuracy
trade-off, since high-dimensional nearest-neighbor search requires
approximations that reduce precision. Current approaches thus force a
compromise between interpretability, generalizability, and scalability.
  We bridge these gaps using a language model-based agent to conduct structured
reasoning analysis of assembly code and generate features such as input/output
types, side effects, notable constants, and algorithmic intent. Unlike
hand-crafted features, they are richer and adaptive. Unlike embeddings, they
are human-readable, maintainable, and directly searchable with inverted or
relational indexes. Without any matching training, our method respectively
achieves 42% and 62% for recall@1 in cross-architecture and cross-optimization
tasks, comparable to embedding methods with training (39% and 34%). Combined
with embeddings, it significantly outperforms the state-of-the-art,
demonstrating that accuracy, scalability, and interpretability can coexist.

</details>


### [168] [ViTSP: A Vision Language Models Guided Framework for Large-Scale Traveling Salesman Problems](https://arxiv.org/abs/2509.23465)
*Zhuoli Yin,Yi Ding,Reem Khir,Hua Cai*

Main category: cs.AI

TL;DR: ViTSP是一个利用预训练视觉语言模型解决大规模旅行商问题的新框架，通过视觉化识别有希望的小规模子问题，再用现成优化器求解，无需专门训练模型。


<details>
  <summary>Details</summary>
Motivation: 传统精确方法难以扩展，启发式方法需要参数调优，学习型方法泛化能力差且受限于固定训练数据。

Method: 利用预训练视觉语言模型从视觉化的TSP实例中识别有希望的小规模子问题，然后用现成求解器高效优化这些子问题来改进全局解。

Result: 在1k到88k节点的真实TSP实例上，ViTSP平均最优性差距低于0.2%，优于现有学习方法，在相同运行时间预算下比最佳启发式求解器LKH-3差距减少12%到100%。

Conclusion: 该框架为混合预训练生成模型和运筹学求解器解决组合优化问题提供了新视角，具有集成到更复杂物流系统的实际意义。

Abstract: Solving Traveling Salesman Problem (TSP) is NP-hard yet fundamental for wide
real-world applications. Classical exact methods face challenges in scaling,
and heuristic methods often require domain-specific parameter calibration.
While learning-based approaches have shown promise, they suffer from poor
generalization and limited scalability due to fixed training data. This work
proposes ViTSP, a novel framework that leverages pre-trained vision language
models (VLMs) to visually guide the solution process for large-scale TSPs. The
VLMs function to identify promising small-scale subproblems from a visualized
TSP instance, which are then efficiently optimized using an off-the-shelf
solver to improve the global solution. ViTSP bypasses the dedicated model
training at the user end while maintaining effectiveness across diverse
instances. Experiments on real-world TSP instances ranging from 1k to 88k nodes
demonstrate that ViTSP consistently achieves solutions with average optimality
gaps below 0.2%, outperforming existing learning-based methods. Under the same
runtime budget, it surpasses the best-performing heuristic solver, LKH-3, by
reducing its gaps by 12% to 100%, particularly on very-large-scale instances
with more than 10k nodes. Our framework offers a new perspective in hybridizing
pre-trained generative models and operations research solvers in solving
combinatorial optimization problems, with practical implications for
integration into more complex logistics systems. The code is available at
https://anonymous.4open.science/r/ViTSP_codes-6683.

</details>


### [169] [GeoBS: Information-Theoretic Quantification of Geographic Bias in AI Models](https://arxiv.org/abs/2509.23482)
*Zhangyu Wang,Nemin Wu,Qian Cao,Jiangnan Xia,Zeping Liu,Yiqun Xie,Akshay Nambi,Tanuja Ganu,Ni Lao,Ninghao Liu,Gengchen Mai*

Main category: cs.AI

TL;DR: 提出了一个名为GeoBS的信息论地理偏见评估框架，该框架模型无关、普遍适用且空间显式，能够公平比较不同AI模型的地理偏见并分析空间因素贡献。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型特别是基础模型广泛应用，但地理偏见问题关注不足。现有地理偏见度量方法要么是模型特定的，要么是空间隐式的，缺乏统一、可比较的评估框架。

Method: 建立信息论地理偏见评估框架GeoBS，在该框架下解释现有度量方法，并提出三种考虑多尺度性、距离衰减和各向异性等复杂空间因素的新地理偏见评分。

Result: 在3个任务、8个数据集和8个模型上的广泛实验表明，任务特定的GeoAI模型和通用基础模型都可能存在各种类型的地理偏见。

Conclusion: 该框架不仅推进了对地理偏见的技术理解，还为将空间公平性整合到AI系统的设计、部署和评估中奠定了基础。

Abstract: The widespread adoption of AI models, especially foundation models (FMs), has
made a profound impact on numerous domains. However, it also raises significant
ethical concerns, including bias issues. Although numerous efforts have been
made to quantify and mitigate social bias in AI models, geographic bias (in
short, geo-bias) receives much less attention, which presents unique
challenges. While previous work has explored ways to quantify geo-bias, these
measures are model-specific (e.g., mean absolute deviation of LLM ratings) or
spatially implicit (e.g., average fairness scores of all spatial partitions).
We lack a model-agnostic, universally applicable, and spatially explicit
geo-bias evaluation framework that allows researchers to fairly compare the
geo-bias of different AI models and to understand what spatial factors
contribute to the geo-bias. In this paper, we establish an
information-theoretic framework for geo-bias evaluation, called GeoBS (Geo-Bias
Scores). We demonstrate the generalizability of the proposed framework by
showing how to interpret and analyze existing geo-bias measures under this
framework. Then, we propose three novel geo-bias scores that explicitly take
intricate spatial factors (multi-scalability, distance decay, and anisotropy)
into consideration. Finally, we conduct extensive experiments on 3 tasks, 8
datasets, and 8 models to demonstrate that both task-specific GeoAI models and
general-purpose foundation models may suffer from various types of geo-bias.
This framework will not only advance the technical understanding of geographic
bias but will also establish a foundation for integrating spatial fairness into
the design, deployment, and evaluation of AI systems.

</details>


### [170] [Accurate Predictions in Education with Discrete Variational Inference](https://arxiv.org/abs/2509.23484)
*Tom Quilter,Anastasia Ilick,Anastasia Ilick,Richard Turner*

Main category: cs.AI

TL;DR: 该论文提出了一个基于项目反应理论的概率建模框架，在数学考试预测中实现了超过80%的准确率，并开发了新的离散变分推理方法，在数据稀疏环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决教育不平等问题，通过开发可扩展的AI辅导系统，特别是针对数据稀疏环境下的学生表现预测问题。

Method: 基于项目反应理论的概率建模框架，结合主题级技能画像的协同过滤模型，以及新开发的离散变分推理方法。

Result: 在数学考试预测中达到超过80%的准确率，创造了新基准；在数据稀疏环境下，离散变分推理方法优于所有传统IRT和矩阵分解基线模型。

Conclusion: 单一潜在能力参数足以实现最大预测准确率，新开发的离散变分推理框架在低数据环境下表现最佳，为AI辅导系统提供了有效的技术解决方案。

Abstract: One of the largest drivers of social inequality is unequal access to personal
tutoring, with wealthier individuals able to afford it, while the majority
cannot. Affordable, effective AI tutors offer a scalable solution. We focus on
adaptive learning, predicting whether a student will answer a question
correctly, a key component of any effective tutoring system. Yet many platforms
struggle to achieve high prediction accuracy, especially in data-sparse
settings. To address this, we release the largest open dataset of
professionally marked formal mathematics exam responses to date. We introduce a
probabilistic modelling framework rooted in Item Response Theory (IRT) that
achieves over 80 percent accuracy, setting a new benchmark for mathematics
prediction accuracy of formal exam papers. Extending this, our collaborative
filtering models incorporate topic-level skill profiles, but reveal a
surprising and educationally significant finding, a single latent ability
parameter alone is needed to achieve the maximum predictive accuracy. Our main
contribution though is deriving and implementing a novel discrete variational
inference framework, achieving our highest prediction accuracy in low-data
settings and outperforming all classical IRT and matrix factorisation
baselines.

</details>


### [171] [Mapping Overlaps in Benchmarks through Perplexity in the Wild](https://arxiv.org/abs/2509.23488)
*Siyang Wu,Honglin Bao,Sida Li,Ari Holtzman,James A. Evans*

Main category: cs.AI

TL;DR: 该论文开发了容量熟悉度签名来表征大型语言模型基准测试及其有意义的重叠，通过分析基准测试签名来揭示模型性能所需的容量，并识别不同能力领域之间的交叉功能重叠。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试存在性能与能力混淆的问题，基准测试间的语义相似性和性能相关性分析有限，需要更机制化的方法来理解基准测试的有效性和LLM能力的底层结构。

Method: 通过逐步前向选择和线性回归，在32个LLM和88个基准测试中提取基准签名，这些签名是从自然语料库中提取的显著标记，其困惑度能预测基准性能。

Result: 发现知识和推理子任务存在重叠，多语言和文化基准相似性较低，编码是最不重叠的领域，性能结果受基准正交因素（如问题格式）强烈影响。

Conclusion: 基准签名对格式效应保持稳健，揭示了跨功能重叠模式，为基准有效性和LLM敏感性提供了机制性见解，描绘了互联LLM能力的底层图景。

Abstract: We develop signatures of capacity familiarity to characterize large language
model (LLM) benchmarks and their meaningful overlaps. Benchmark signatures
probe the capacity required for benchmark performance. We formally define them
as a set of salient tokens drawn from in-the-wild, naturally authored corpora,
where LLM token perplexity, reflecting more or less pre-training exposure,
becomes highly predictive of LLM benchmark performance. Through a large-scale
meta-evaluation, we extract benchmark signatures via stepwise forward selection
with linear regressions across 32 LLMs and 88 benchmarks spanning diverse
knowledge, coding, logic, instruction following, math, language, reasoning, and
world modeling. Our analysis situates signatures in relation to both the
semantic similarity of benchmark questions and the correlation of model
performance. While performance overlaps are universally high and semantic
overlaps remain confined to a narrow mid-range, benchmark signatures prove
highly informative in capturing variation, overlap, and divergence. We observe
overlap in knowledge and reasoning subtasks, whereas multilingual and cultural
benchmarks exhibit less similarity, even compared to cross-task overlap.
Notably, performance-level results are strongly influenced by
benchmark-orthogonal factors such as question format, highlighting limitations
in LLM generalization, the conflation of performance with ability, and issues
inherent in current mainstream benchmark agreement studies. Benchmark
signatures, however, remain robust to such effects. Ultimately, we identify
cross-functional overlaps across logic, math, language, instruction following,
and world modeling, with coding emerging as the least overlapping domain.
Together, these findings provide mechanistic insights into benchmark validity
and LLM sensitivities, and sketch the underlying landscape of interconnected
LLM capabilities.

</details>


### [172] [Dynamic Trust Calibration Using Contextual Bandits](https://arxiv.org/abs/2509.23497)
*Bruno M. Henrique,Eugene Santos Jr*

Main category: cs.AI

TL;DR: 提出了一种基于上下文多臂老虎机的动态信任校准方法，通过标准化信任校准指标来优化人机协作决策性能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏标准化和客观的人机信任校准测量方法，现有方法无法区分意见形成和后续决策过程，且缺乏跨场景一致性。

Method: 使用上下文多臂老虎机算法，构建动态信任校准指标，基于学习到的上下文信息评估何时信任AI贡献。

Result: 在三个不同数据集上的评估显示，有效的信任校准使决策性能显著提升，奖励指标提高了10-38%。

Conclusion: 该方法不仅增强了理论理解，还为开发更可信的AI系统提供了实践指导，特别是在疾病诊断和刑事司法等关键领域。

Abstract: Trust calibration between humans and Artificial Intelligence (AI) is crucial
for optimal decision-making in collaborative settings. Excessive trust can lead
users to accept AI-generated outputs without question, overlooking critical
flaws, while insufficient trust may result in disregarding valuable insights
from AI systems, hindering performance. Despite its importance, there is
currently no definitive and objective method for measuring trust calibration
between humans and AI. Current approaches lack standardization and consistent
metrics that can be broadly applied across various contexts, and they don't
distinguish between the formation of opinions and subsequent human decisions.
In this work, we propose a novel and objective method for dynamic trust
calibration, introducing a standardized trust calibration measure and an
indicator. By utilizing Contextual Bandits-an adaptive algorithm that
incorporates context into decision-making-our indicator dynamically assesses
when to trust AI contributions based on learned contextual information. We
evaluate this indicator across three diverse datasets, demonstrating that
effective trust calibration results in significant improvements in
decision-making performance, as evidenced by 10 to 38% increase in reward
metrics. These findings not only enhance theoretical understanding but also
provide practical guidance for developing more trustworthy AI systems
supporting decisions in critical domains, for example, disease diagnoses and
criminal justice.

</details>


### [173] [Model Consistency as a Cheap yet Predictive Proxy for LLM Elo Scores](https://arxiv.org/abs/2509.23510)
*Ashwin Ramaswamy,Nestor Demeure,Ermal Rrapaj*

Main category: cs.AI

TL;DR: 提出了一种使用LLM自身判断来评估模型性能的简单方法，该方法与人类评估的Elo分数高度相关（91%），无需人工数据或先验知识。


<details>
  <summary>Details</summary>
Motivation: 新LLM不断发布，但参数数量与性能不成正比，需要独立评估方法。当前最佳方法是通过人类比较计算Elo分数，但成本高昂。

Method: 让LLM判断模型对决中的胜者，通过其一致性选择最佳模型的频率作为评估指标。

Result: LLM自身判断产生的指标与人类评估的Elo分数相关性高达91%。

Conclusion: 该方法提供了计算Elo分数的廉价代理，无需人工数据，可作为快速模型评估的有效工具。

Abstract: New large language models (LLMs) are being released every day. Some perform
significantly better or worse than expected given their parameter count.
Therefore, there is a need for a method to independently evaluate models. The
current best way to evaluate a model is to measure its Elo score by comparing
it to other models in a series of contests - an expensive operation since
humans are ideally required to compare LLM outputs. We observe that when an LLM
is asked to judge such contests, the consistency with which it selects a model
as the best in a matchup produces a metric that is 91% correlated with its own
human-produced Elo score. This provides a simple proxy for Elo scores that can
be computed cheaply, without any human data or prior knowledge.

</details>


### [174] [DOoM: Difficult Olympiads of Math](https://arxiv.org/abs/2509.23529)
*Ilya Kuleshov,Ilin Pavel,Nikolay Kompanets,Ksenia Sycheva,Aleksandr Nikolich*

Main category: cs.AI

TL;DR: DOoM是一个新的开源基准测试，用于评估语言模型解决俄语数学和物理问题的能力，涵盖从学校水平到大学奥林匹克和入学考试的不同难度问题。


<details>
  <summary>Details</summary>
Motivation: 创建DOoM基准测试是为了评估语言模型在俄语数学和物理问题解决方面的能力，填补现有基准测试的空白。

Method: 构建包含不同难度级别的俄语数学和物理问题数据集，采用特定的评估方法测试各种模型，并分析模型性能与使用token数量之间的相关性。

Result: 结果显示模型性能与使用的token数量存在相关性，数学和物理任务之间存在性能差异。

Conclusion: DOoM基准测试为评估语言模型在俄语STEM领域的表现提供了有效工具，揭示了模型在不同学科任务上的性能差异。

Abstract: This paper introduces DOoM, a new open-source benchmark designed to assess
the capabilities of language models in solving mathematics and physics problems
in Russian. The benchmark includes problems of varying difficulty, ranging from
school-level tasks to university Olympiad and entrance exam questions. In this
paper we discuss the motivation behind its creation, describe dataset's
structure and evaluation methodology, and present initial results from testing
various models. Analysis of the results shows a correlation between model
performance and the number of tokens used, and highlights differences in
performance between mathematics and physics tasks.

</details>


### [175] [Beyond the Strongest LLM: Multi-Turn Multi-Agent Orchestration vs. Single LLMs on Benchmarks](https://arxiv.org/abs/2509.23537)
*Aaron Xuxiang Tian,Ruofan Zhang,Jiayao Tang,Young Min Cho,Xueqian Li,Qiang Yi,Ji Wang,Zhunping Zhang,Danrui Qi,Sharath Chandra Guntuku,Lyle Ungar,Tianyu Shi,Chi Wang*

Main category: cs.AI

TL;DR: 多轮多智能体编排通过多个LLM智能体迭代提出答案或投票达成共识，在三个基准测试中匹配或超过最强单模型性能，分析显示隐藏作者身份和投票过程可减少偏见并提升效果。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体编排是否能通过集体决策超越单个LLM的性能，并探索影响编排效果的关键因素如作者身份可见性和投票过程透明度。

Method: 使用四个LLM模型在三个基准数据集上进行实验：比较编排与单模型基线性能，并在GPQA-Diamond上进行消融实验，分析作者身份可见性和投票过程观察对编排效果的影响。

Result: 编排方法匹配或超过最强单模型性能，持续优于其他模型。隐藏作者身份减少自投票和平局，隐藏投票过程减少从众效应，避免过早共识。

Conclusion: 多智能体编排是提升LLM性能的有效方法，通过控制信息透明度可优化集体决策过程，未来有进一步提升潜力。

Abstract: We study multi-turn multi-agent orchestration, where multiple large language
model (LLM) agents interact over multiple turns by iteratively proposing
answers or casting votes until reaching consensus. Using four LLMs (Gemini 2.5
Pro, GPT-5, Grok 4, and Claude Sonnet 4) on GPQA-Diamond, IFEval, and MuSR, we
conduct two experiments: (i) benchmarking orchestration against single-LLM
baselines; and (ii) ablations on GPQA-Diamond that vary whether agents see who
authored answers and whether they can observe ongoing votes. Orchestration
matches or exceeds the strongest single model and consistently outperforms the
others. Analysis of best-achievable orchestration performance shows potential
for further gains. The ablations show that revealing authorship increases
self-voting and ties, and that showing ongoing votes amplifies herding, which
speeds convergence but can sometimes yield premature consensus.

</details>


### [176] [Formalization Driven LLM Prompt Jailbreaking via Reinforcement Learning](https://arxiv.org/abs/2509.23558)
*Zhaoqi Wang,Daqing He,Zijian Zhang,Xin Li,Liehuang Zhu,Meng Li,Jiamou Liu*

Main category: cs.AI

TL;DR: PASS框架通过强化学习将初始越狱提示转化为形式化描述，增强隐蔽性并绕过现有对齐防御，然后构建GraphRAG系统来强化后续攻击。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型引入了新的安全挑战，特别是提示越狱攻击，攻击者通过精心设计的提示使模型偏离人类价值观。需要发现LLM对齐方法中的漏洞。

Method: 使用强化学习将初始越狱提示转化为形式化描述，构建GraphRAG系统，利用提取的相关术语和形式化符号作为上下文输入来强化攻击。

Result: 在常见开源模型上进行了广泛实验，证明了攻击的有效性。

Conclusion: PASS框架能够有效发现LLM对齐方法中的漏洞，实现更有效的提示越狱攻击。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities, yet
they also introduce novel security challenges. For instance, prompt
jailbreaking attacks involve adversaries crafting sophisticated prompts to
elicit responses from LLMs that deviate from human values. To uncover
vulnerabilities in LLM alignment methods, we propose the PASS framework
(\underline{P}rompt J\underline{a}ilbreaking via \underline{S}emantic and
\underline{S}tructural Formalization). Specifically, PASS employs reinforcement
learning to transform initial jailbreak prompts into formalized descriptions,
which enhances stealthiness and enables bypassing existing alignment defenses.
The jailbreak outputs are then structured into a GraphRAG system that, by
leveraging extracted relevant terms and formalized symbols as contextual input
alongside the original query, strengthens subsequent attacks and facilitates
more effective jailbreaks. We conducted extensive experiments on common
open-source models, demonstrating the effectiveness of our attack.

</details>


### [177] [A Hierarchical Structure-Enhanced Personalized Recommendation Model for Traditional Chinese Medicine Formulas Based on KG Diffusion Guidance](https://arxiv.org/abs/2509.23560)
*ChaoBo Zhang,Long Tan*

Main category: cs.AI

TL;DR: 提出TCM-HEDPR模型，通过知识图谱扩散引导的中医处方个性化推荐，解决患者个性化信息不足、草药数据长尾分布和君臣佐使配伍关系忽略等问题。


<details>
  <summary>Details</summary>
Motivation: 现有中医AI处方推荐模型存在三个主要问题：(1)忽视患者个性化信息如年龄、BMI和病史；(2)草药数据的长尾分布导致训练偏差；(3)忽略'君臣佐使'配伍原则，增加毒副作用风险。

Method: 使用患者个性化提示序列预训练症状表示，应用提示导向对比学习进行数据增强；采用KG引导的同构图扩散方法与自注意力机制全局捕捉症状-草药非线性关系；设计异构图分层网络整合草药配伍关系与隐式证候。

Result: 在三个数据集上的广泛实验证明了TCM-HEDPR的有效性，并结合现代医学和网络药理学对推荐处方进行全面评估。

Conclusion: 该模型为现代中医处方推荐提供了新范式，能够更好地实现中医'辨证论治'的临床原则。

Abstract: Artificial intelligence technology plays a crucial role in recommending
prescriptions for traditional Chinese medicine (TCM). Previous studies have
made significant progress by focusing on the symptom-herb relationship in
prescriptions. However, several limitations hinder model performance: (i)
Insufficient attention to patient-personalized information such as age, BMI,
and medical history, which hampers accurate identification of syndrome and
reduces efficacy. (ii) The typical long-tailed distribution of herb data
introduces training biases and affects generalization ability. (iii) The
oversight of the 'monarch, minister, assistant and envoy' compatibility among
herbs increases the risk of toxicity or side effects, opposing the 'treatment
based on syndrome differentiation' principle in clinical TCM. Therefore, we
propose a novel hierarchical structure-enhanced personalized recommendation
model for TCM formulas based on knowledge graph diffusion guidance, namely
TCM-HEDPR. Specifically, we pre-train symptom representations using
patient-personalized prompt sequences and apply prompt-oriented contrastive
learning for data augmentation. Furthermore, we employ a KG-guided homogeneous
graph diffusion method integrated with a self-attention mechanism to globally
capture the non-linear symptom-herb relationship. Lastly, we design a
heterogeneous graph hierarchical network to integrate herbal dispensing
relationships with implicit syndromes, guiding the prescription generation
process at a fine-grained level and mitigating the long-tailed herb data
distribution problem. Extensive experiments on two public datasets and one
clinical dataset demonstrate the effectiveness of TCM-HEDPR. In addition, we
incorporate insights from modern medicine and network pharmacology to evaluate
the recommended prescriptions comprehensively. It can provide a new paradigm
for the recommendation of modern TCM.

</details>


### [178] [Clean First, Align Later: Benchmarking Preference Data Cleaning for Reliable LLM Alignment](https://arxiv.org/abs/2509.23564)
*Min-Hsuan Yeh,Yixuan Li*

Main category: cs.AI

TL;DR: PrefCleanBench是首个用于评估13种偏好数据清洗方法的综合基准，旨在解决人类反馈噪声对LLM对齐的影响，通过标准化协议评估清洗策略在多样化数据集、模型架构和优化算法中的效果。


<details>
  <summary>Details</summary>
Motivation: 人类反馈在LLM对齐中至关重要，但反馈往往存在噪声或不一致，这会降低奖励模型质量并阻碍对齐效果。虽然已有多种自动数据清洗方法，但缺乏对其有效性和泛化性的系统评估。

Method: 引入PrefCleanBench基准，提供标准化评估协议，涵盖13种偏好数据清洗方法，评估其在多样化数据集、模型架构和优化算法中的对齐性能和泛化能力。

Result: 通过统一和严格比较不同方法，揭示了决定数据清洗在LLM对齐任务中成功的关键因素，为通过改善数据质量来提升LLM对齐提供了原则性和可复现的方法。

Conclusion: 该基准为负责任AI开发中数据预处理的探索奠定了基础，强调了数据质量在LLM对齐中的关键作用，并发布了所有方法的模块化实现以促进进一步研究。

Abstract: Human feedback plays a pivotal role in aligning large language models (LLMs)
with human preferences. However, such feedback is often noisy or inconsistent,
which can degrade the quality of reward models and hinder alignment. While
various automated data cleaning methods have been proposed to mitigate this
issue, a systematic evaluation of their effectiveness and generalizability
remains lacking. To bridge this gap, we introduce the first comprehensive
benchmark for evaluating 13 preference data cleaning methods in the context of
LLM alignment. PrefCleanBench offers a standardized protocol to assess cleaning
strategies in terms of alignment performance and generalizability across
diverse datasets, model architectures, and optimization algorithms. By unifying
disparate methods and rigorously comparing them, we uncover key factors that
determine the success of data cleaning in alignment tasks. This benchmark lays
the groundwork for principled and reproducible approaches to improving LLM
alignment through better data quality-highlighting the crucial but
underexplored role of data preprocessing in responsible AI development. We
release modular implementations of all methods to catalyze further research:
https://github.com/deeplearning-wisc/PrefCleanBench.

</details>


### [179] [BridgeDrive: Diffusion Bridge Policy for Closed-Loop Trajectory Planning in Autonomous Driving](https://arxiv.org/abs/2509.23589)
*Shu Liu,Wenlin Chen,Weihao Li,Zheng Wang,Lijin Yang,Jianing Huang,Yipin Zhang,Zhongzhan Huang,Ze Cheng,Hao Yang*

Main category: cs.AI

TL;DR: BridgeDrive是一种基于扩散桥的闭环轨迹规划方法，通过锚点引导扩散模型在复杂动态驾驶场景中生成细粒度轨迹规划，在Bench2Drive基准上实现了5%的成功率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散规划器在反应式闭环环境中难以有效引导，简单条件化在复杂动态驾驶场景中指导不足，而基于锚点的方法存在理论不一致性和性能问题。

Method: 提出BridgeDrive方法，构建一个原则性的扩散框架，将典型专家驾驶行为（锚点）转化为细粒度轨迹规划，并能适应不同交通条件，兼容高效ODE求解器。

Result: 在Bench2Drive基准测试中实现了最先进的性能，成功率比先前方法提高了5%。

Conclusion: BridgeDrive为自动驾驶闭环轨迹规划提供了一种有效的锚点引导扩散桥策略，解决了现有方法在复杂动态环境中的指导不足问题。

Abstract: Diffusion-based planners have shown great promise for autonomous driving due
to their ability to capture multi-modal driving behaviors. However, guiding
these models effectively in reactive, closed-loop environments remains a
significant challenge. Simple conditioning often fails to provide sufficient
guidance in complex and dynamic driving scenarios. Recent work attempts to use
typical expert driving behaviors (i.e., anchors) to guide diffusion models but
relies on a truncated schedule, which introduces theoretical inconsistencies
and can compromise performance. To address this, we introduce BridgeDrive, a
novel anchor-guided diffusion bridge policy for closed-loop trajectory
planning. Our approach provides a principled diffusion framework that
effectively translates anchors into fine-grained trajectory plans,
appropriately responding to varying traffic conditions. Our planner is
compatible with efficient ODE solvers, a critical factor for real-time
autonomous driving deployment. We achieve state-of-the-art performance on the
Bench2Drive benchmark, improving the success rate by 5% over prior arts.

</details>


### [180] [PSG-Agent: Personality-Aware Safety Guardrail for LLM-based Agents](https://arxiv.org/abs/2509.23614)
*Yaozu Wu,Jizhou Guo,Dongyuan Li,Henry Peng Zou,Wei-Chieh Huang,Yankai Chen,Zhen Wang,Weizhi Zhang,Yangning Li,Meng Zhang,Renhe Jiang,Philip S. Yu*

Main category: cs.AI

TL;DR: PSG-Agent是一个个性化和动态的LLM代理安全防护系统，通过挖掘用户交互历史创建个性化防护策略，并实现跨轮次风险监控，显著优于现有防护方案。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理防护系统存在两个根本问题：对所有用户应用统一防护策略，忽略了相同行为对不同用户的风险差异；仅检查单次响应，无法追踪跨轮次风险累积。

Method: PSG-Agent通过挖掘用户交互历史获取稳定特征，结合实时查询状态生成个性化风险阈值；在代理流程中部署专门防护模块（计划监控、工具防火墙、响应防护、记忆守护）进行持续监控。

Result: 在医疗、金融和日常生活自动化等多个场景中，PSG-Agent显著优于LlamaGuard3和AGrail等现有代理防护方案。

Conclusion: PSG-Agent为LLM代理提供了可执行且可审计的个性化安全路径，能够有效应对跨轮次风险累积问题。

Abstract: Effective guardrails are essential for safely deploying LLM-based agents in
critical applications. Despite recent advances, existing guardrails suffer from
two fundamental limitations: (i) they apply uniform guardrail policies to all
users, ignoring that the same agent behavior can harm some users while being
safe for others; (ii) they check each response in isolation, missing how risks
evolve and accumulate across multiple interactions. To solve these issues, we
propose PSG-Agent, a personalized and dynamic system for LLM-based agents.
First, PSG-Agent creates personalized guardrails by mining the interaction
history for stable traits and capturing real-time states from current queries,
generating user-specific risk thresholds and protection strategies. Second,
PSG-Agent implements continuous monitoring across the agent pipeline with
specialized guards, including Plan Monitor, Tool Firewall, Response Guard,
Memory Guardian, that track cross-turn risk accumulation and issue verifiable
verdicts. Finally, we validate PSG-Agent in multiple scenarios including
healthcare, finance, and daily life automation scenarios with diverse user
profiles. It significantly outperform existing agent guardrails including
LlamaGuard3 and AGrail, providing an executable and auditable path toward
personalized safety for LLM-based agents.

</details>


### [181] [Reasoning Scaffolding: Distilling the Flow of Thought from LLMs](https://arxiv.org/abs/2509.23619)
*Xiangyu Wen,Junhua Huang,Zeju Li,Min Li,Jianyuan Zhong,Zhijian Xu,Mingxuan Yuan,Yongxiang Huang,Qiang Xu*

Main category: cs.AI

TL;DR: 提出Reasoning Scaffolding框架，通过将推理过程抽象为离散的语义信号序列，让学生模型学习推理的算法结构而非表面文本模式，显著提升小模型的推理准确性和逻辑一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的从大语言模型蒸馏推理能力的方法（行为克隆）存在根本性局限，只教会小模型模仿表面文本模式而非底层的算法思维结构，导致逻辑鲁棒性严重不足。

Method: 引入Reasoning Scaffolding框架：1）将教师思维过程抽象为离散可解释的语义信号序列（如对比、加法等）；2）通过多任务目标训练学生模型：预测下一个语义信号和生成对应推理步骤。

Result: 在一系列具有挑战性的推理基准测试中，该方法在准确性和逻辑一致性方面显著优于最先进的蒸馏方法。

Conclusion: 该方法为创建真正具备推理能力而非仅能流利模仿的小模型提供了一条可行路径，通过直接传递算法结构而非克隆文本来实现推理能力的有效蒸馏。

Abstract: The prevailing approach to distilling reasoning from Large Language Models
(LLMs)-behavioral cloning from textual rationales-is fundamentally limited. It
teaches Small Language Models (SLMs) to mimic surface-level patterns rather
than the underlying algorithmic structure of thought, resulting in a critical
lack of logical robustness. We argue that instead of cloning text, distillation
should transfer this algorithmic structure directly. We introduce Reasoning
Scaffolding}, a framework that reframes reasoning as a structured generation
process. Our method first abstracts the teacher's thought process into a
sequence of discrete, interpretable semantic signals (e.g., Contrast, Addition)
that act as a scaffold. The student model is then trained via a multi-task
objective to both (1)predict the next semantic signal, anticipating the
reasoning flow, and (2)generate the corresponding step, conditioned on that
signal. This multi-task scheme acts as a powerful regularizer, compelling the
student to internalize the computational patterns of coherent reasoning. On a
suite of challenging reasoning benchmarks, our method significantly outperforms
state-of-the-art distillation in both accuracy and logical consistency,
providing a path towards creating smaller models that are genuine reasoners,
not just fluent mimics.

</details>


### [182] [How LLMs Learn to Reason: A Complex Network Perspective](https://arxiv.org/abs/2509.23629)
*Sihan Hu,Xiansheng Cai,Yuan Huang,Zhiyuan Yao,Linfeng Zhang,Pan Zhang,Youjin Deng,Kun Chen*

Main category: cs.AI

TL;DR: 该论文提出了一种统一理论来解释RLVR训练中的奇特现象，认为模型推理过程对应语义复杂网络的自组织，其稀疏拓扑结构导致两阶段学习曲线和灾难性遗忘。基于此提出了Annealed-RLVR算法来提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 理解RLVR训练中出现的两阶段学习曲线、V形响应长度轨迹和灾难性遗忘等令人困惑的现象，并找到统一的理论解释。

Method: 提出语义复杂网络自组织理论，认为模型推理过程映射到拓扑结构稀疏的语义网络，并基于此设计Annealed-RLVR算法，在最大挫折点引入基于SFT的"加热"步骤来解决竞争瓶颈。

Result: 在15亿参数模型上的实验表明，该方法在分布内和分布外基准测试中均优于标准RLVR。

Conclusion: 通过将RLVR从黑盒优化重新定义为结构自组织的可预测过程，为未来AI系统推理能力的工程化提供了新的物理直觉。

Abstract: Training large language models with Reinforcement Learning from Verifiable
Rewards (RLVR) exhibits a set of distinctive and puzzling behaviors that remain
poorly understood, including a two-stage learning curve, V-shaped
response-length trajectories, and a pronounced vulnerability to catastrophic
forgetting. In this work, we propose that these seemingly disparate phenomena
can be explained using a single unifying theory: the model's reasoning process
maps to the self-organization of a semantic complex network whose topology
remains persistently sparse, with the average degree pinned close to two. This
topology imposes a fundamental mechanism for forgetting and learning: it first
drives the system into a maximally frustrated state where ``skill islands''
form, slow-learning happens, and forgetting is induced; then it enters a sharp
growth phase where the new skills are ``bolted on'', driven by
phase-transition-like learning at the web's frontier. Equipped with the theory,
we propose \textit{Annealed-RLVR}, a principled algorithm that introduces an
SFT-based ``heating'' step at the point of maximal frustration to resolve the
competitive bottleneck and enhance the reasoning capability of the model.
Experiments on a 1.5B-parameter model demonstrate that the approach outperforms
standard RLVR on both in-distribution and out-of-distribution benchmarks. By
recasting RLVR from black-box optimization into a predictable process of
structural self-organization, our work provides a new physical intuition for
engineering the emergent reasoning capabilities of future AI systems.

</details>


### [183] [Game-Oriented ASR Error Correction via RAG-Enhanced LLM](https://arxiv.org/abs/2509.23630)
*Yan Jiang,Yongle Luo,Qixian Zhou,Elvis S. Liu*

Main category: cs.AI

TL;DR: GO-AEC框架通过整合大语言模型、检索增强生成和数据增强策略，显著提升了游戏场景中的语音识别准确率。


<details>
  <summary>Details</summary>
Motivation: 解决多人在线游戏中实时语音通信面临的挑战，包括短短语、快速语音、游戏术语和噪音导致的ASR系统频繁错误。

Method: 整合大语言模型、检索增强生成(RAG)、使用LLM和TTS的数据增强策略，包括数据增强、基于N-best假设的校正和动态游戏知识库。

Result: 实验显示GO-AEC将字符错误率降低了6.22%，句子错误率降低了29.71%。

Conclusion: GO-AEC框架显著提高了游戏场景中的ASR准确率，有效解决了游戏语音识别的特殊挑战。

Abstract: With the rise of multiplayer online games, real-time voice communication is
essential for team coordination. However, general ASR systems struggle with
gaming-specific challenges like short phrases, rapid speech, jargon, and noise,
leading to frequent errors. To address this, we propose the GO-AEC framework,
which integrates large language models, Retrieval-Augmented Generation (RAG),
and a data augmentation strategy using LLMs and TTS. GO-AEC includes data
augmentation, N-best hypothesis-based correction, and a dynamic game knowledge
base. Experiments show GO-AEC reduces character error rate by 6.22% and
sentence error rate by 29.71%, significantly improving ASR accuracy in gaming
scenarios.

</details>


### [184] [From Reasoning to Answer: Empirical, Attention-Based and Mechanistic Insights into Distilled DeepSeek R1 Models](https://arxiv.org/abs/2509.23676)
*Jue Zhang,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: 该研究通过实证评估、注意力分析和机制干预，揭示了大型推理模型中推理轨迹对答案生成的实质性影响，确认了从推理到答案的功能性信息流。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型生成显式推理轨迹和最终答案，但这些推理轨迹对答案生成的影响程度尚不清楚，需要系统研究推理与答案生成之间的相互作用。

Method: 采用三阶段研究方法：1）实证评估推理对答案质量的影响；2）注意力分析揭示答案token对推理token的关注模式；3）通过激活修补进行机制干预，评估答案token对推理激活的依赖性。

Result: 包含显式推理能持续提升答案质量；答案token显著关注推理token，特定中间层的推理聚焦头密切跟踪推理轨迹；对关键推理token的扰动能可靠改变最终答案。

Conclusion: 研究证实了推理到答案的方向性和功能性信息流，深化了对大型推理模型如何利用推理token进行答案生成的理解，凸显了中间推理在塑造模型输出中的功能性作用。

Abstract: Large Reasoning Models (LRMs) generate explicit reasoning traces alongside
final answers, yet the extent to which these traces influence answer generation
remains unclear. In this work, we conduct a three-stage investigation into the
interplay between reasoning and answer generation in three distilled DeepSeek
R1 models. First, through empirical evaluation, we demonstrate that including
explicit reasoning consistently improves answer quality across diverse domains.
Second, attention analysis reveals that answer tokens attend substantially to
reasoning tokens, with certain mid-layer Reasoning-Focus Heads (RFHs) closely
tracking the reasoning trajectory, including self-reflective cues. Third, we
apply mechanistic interventions using activation patching to assess the
dependence of answer tokens on reasoning activations. Our results show that
perturbations to key reasoning tokens can reliably alter the final answers,
confirming a directional and functional flow of information from reasoning to
answer. These findings deepen our understanding of how LRMs leverage reasoning
tokens for answer generation, highlighting the functional role of intermediate
reasoning in shaping model outputs. Our data and code are publicly available at
\href{https://aka.ms/R2A-code}{this URL}.

</details>


### [185] [SafeSearch: Automated Red-Teaming for the Safety of LLM-Based Search Agents](https://arxiv.org/abs/2509.23694)
*Jianshuo Dong,Sheng Guo,Hao Wang,Zhuotao Liu,Tianwei Zhang,Ke Xu,Minlie Huang,Han Qiu*

Main category: cs.AI

TL;DR: 本文提出了一个自动化红队框架来评估搜索代理的安全性，构建了包含300个测试用例的SafeSearch基准，发现LLM搜索代理在面对不可靠网站时存在严重漏洞，最高攻击成功率可达90.5%。


<details>
  <summary>Details</summary>
Motivation: 搜索代理将LLM连接到互联网，能够获取更广泛和最新的信息，但不可靠的搜索结果可能对最终用户构成安全威胁，建立了一个新的威胁面。

Method: 提出了一个系统化、可扩展且成本效益高的自动化红队框架，构建了SafeSearch基准，包含300个测试用例，覆盖五类风险（如错误信息和间接提示注入），评估了三种代表性搜索代理架构。

Result: 评估结果显示LLM搜索代理存在严重漏洞：当暴露于不可靠网站时，GPT-4.1-mini在搜索工作流设置下的最高攻击成功率达到了90.5%。常见防御实践（如提醒提示）效果有限。

Conclusion: 该框架在促进更安全的代理开发透明度方面具有重要价值，强调了搜索代理安全评估的必要性。

Abstract: Search agents connect LLMs to the Internet, enabling access to broader and
more up-to-date information. However, unreliable search results may also pose
safety threats to end users, establishing a new threat surface. In this work,
we conduct two in-the-wild experiments to demonstrate both the prevalence of
low-quality search results and their potential to misguide agent behaviors. To
counter this threat, we introduce an automated red-teaming framework that is
systematic, scalable, and cost-efficient, enabling lightweight and harmless
safety assessments of search agents. Building on this framework, we construct
the SafeSearch benchmark, which includes 300 test cases covering five
categories of risks (e.g., misinformation and indirect prompt injection). Using
this benchmark, we evaluate three representative search agent scaffolds,
covering search workflow, tool-calling, and deep research, across 7 proprietary
and 8 open-source backend LLMs. Our results reveal substantial vulnerabilities
of LLM-based search agents: when exposed to unreliable websites, the highest
ASR reached 90.5% for GPT-4.1-mini under a search workflow setting. Moreover,
our analysis highlights the limited effectiveness of common defense practices,
such as reminder prompting. This emphasizes the value of our framework in
promoting transparency for safer agent development. Our codebase and test cases
are publicly available: https://github.com/jianshuod/SafeSearch.

</details>


### [186] [Measuring Sparse Autoencoder Feature Sensitivity](https://arxiv.org/abs/2509.23717)
*Claire Tian,Katherine Tian,Nathan Hu*

Main category: cs.AI

TL;DR: 提出了一种评估稀疏自编码器特征敏感性的可扩展方法，发现许多可解释特征具有较差的敏感性，且平均特征敏感性随SAE宽度增加而下降。


<details>
  <summary>Details</summary>
Motivation: 现有SAE特征分析主要关注激活示例，但无法揭示特征敏感性——即特征在类似文本上的可靠激活程度。

Method: 使用语言模型生成与特征激活示例具有相同语义属性的文本，然后测试特征是否在这些生成文本上激活。

Result: 发现敏感性是特征质量的新维度，许多可解释特征敏感性较差；人类评估确认当特征在生成文本上不激活时，这些文本确实与原始激活示例相似。

Conclusion: 特征敏感性是评估单个特征和SAE架构的新维度，平均特征敏感性随SAE宽度增加而下降。

Abstract: Sparse Autoencoder (SAE) features have become essential tools for mechanistic
interpretability research. SAE features are typically characterized by
examining their activating examples, which are often "monosemantic" and align
with human interpretable concepts. However, these examples don't reveal feature
sensitivity: how reliably a feature activates on texts similar to its
activating examples. In this work, we develop a scalable method to evaluate
feature sensitivity. Our approach avoids the need to generate natural language
descriptions for features; instead we use language models to generate text with
the same semantic properties as a feature's activating examples. We then test
whether the feature activates on these generated texts. We demonstrate that
sensitivity measures a new facet of feature quality and find that many
interpretable features have poor sensitivity. Human evaluation confirms that
when features fail to activate on our generated text, that text genuinely
resembles the original activating examples. Lastly, we study feature
sensitivity at the SAE level and observe that average feature sensitivity
declines with increasing SAE width across 7 SAE variants. Our work establishes
feature sensitivity as a new dimension for evaluating both individual features
and SAE architectures.

</details>


### [187] [MedLA: A Logic-Driven Multi-Agent Framework for Complex Medical Reasoning with Large Language Models](https://arxiv.org/abs/2509.23725)
*Siqi Ma,Jiajie Huang,Bolin Yang,Fan Zhang,Jinlin Wu,Yue Shen,Guohui Fan,Zhu Zhang,Zelin Zang*

Main category: cs.AI

TL;DR: 提出了MedLA框架，这是一个基于逻辑驱动的多智能体系统，用于解决复杂医疗问题。通过将推理过程组织成显式的逻辑树结构，并进行多轮图引导讨论，实现了透明推理和前提级对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定角色或浅层交互提示，难以检测和解决细粒度的逻辑不一致问题。复杂医疗问题需要领域专业知识、患者特定信息以及结构化多视角推理。

Method: 每个智能体基于三段论（大前提、小前提、结论）将其推理过程组织成显式逻辑树。智能体通过多轮图引导讨论来比较和迭代优化逻辑树，通过错误纠正和矛盾解决达成共识。

Result: 在MedDDx和标准医疗QA任务等挑战性基准测试中，MedLA始终优于静态角色系统和单智能体基线。该框架在开源和商业LLM骨干网络上都能有效扩展，实现了最先进的性能。

Conclusion: MedLA为可信赖的医疗推理提供了一个可泛化的范式，通过逻辑驱动的多智能体协作实现了透明且一致的推理过程。

Abstract: Answering complex medical questions requires not only domain expertise and
patient-specific information, but also structured and multi-perspective
reasoning. Existing multi-agent approaches often rely on fixed roles or shallow
interaction prompts, limiting their ability to detect and resolve fine-grained
logical inconsistencies. To address this, we propose \textsc{MedLA}, a
logic-driven multi-agent framework built on large language models. Each agent
organizes its reasoning process into an explicit logical tree based on
syllogistic triads (major premise, minor premise, and conclusion), enabling
transparent inference and premise-level alignment. Agents engage in a
multi-round, graph-guided discussion to compare and iteratively refine their
logic trees, achieving consensus through error correction and contradiction
resolution. We demonstrate that \textsc{MedLA} consistently outperforms both
static role-based systems and single-agent baselines on challenging benchmarks
such as MedDDx and standard medical QA tasks. Furthermore, \textsc{MedLA}
scales effectively across both open-source and commercial LLM backbones,
achieving state-of-the-art performance and offering a generalizable paradigm
for trustworthy medical reasoning.

</details>


### [188] [EAPO: Enhancing Policy Optimization with On-Demand Expert Assistance](https://arxiv.org/abs/2509.23730)
*Siyao Song,Cong Ma,Zhihao Cheng,Shiye Lei,Minghao Li,Ying Zeng,Huaixiao Tou,Kai Jia*

Main category: cs.AI

TL;DR: 提出EAPO框架，通过多轮外部专家交互增强LLM推理能力，在数学推理基准上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于结果监督的RL方法存在探索效率低和奖励稀疏问题，需要改进LLM推理训练方式

Method: EAPO框架让策略模型在训练时自适应决定何时及如何咨询外部专家，获得更丰富的奖励信号和可靠推理轨迹

Result: 在AIME 2024、2025和AIMO 2025等数学推理基准上，EAPO平均比自探索模型提升5分，优于专家辅助工作流和专家蒸馏模型

Conclusion: 通过专家辅助内部化专家知识，EAPO成功增强了模型的固有推理能力，产生更优的推理路径和准确解决方案

Abstract: Large language models (LLMs) have recently advanced in reasoning when
optimized with reinforcement learning (RL) under verifiable rewards. Existing
methods primarily rely on outcome-based supervision to strengthen internal LLM
reasoning, often leading to inefficient exploration and sparse rewards. To
mitigate this issue, we propose Expert-Assisted Policy Optimization (EAPO), a
novel RL framework that enhances exploration by incorporating multi-turn
interactions with external experts during training. Unlike prior methods, where
policies reason in isolation, EAPO incentivizes the policy to adaptively
determine when and how to consult experts, yielding richer reward signals and
more reliable reasoning trajectories. External assistance ultimately
internalizes expert knowledge into the policy model, amplifying the model's
inherent reasoning capabilities. During evaluation, the policy model has been
well-optimized to solve questions independently, producing improved reasoning
paths and more accurate solutions. Experiments on mathematical reasoning
benchmarks, including AIME 2024, AIME 2025, and AIMO 2025, show that EAPO
consistently outperforms expert-assisted workflow, expert-distilled models, and
RL baselines, with an average gain of 5 points over self-exploratory models.

</details>


### [189] [Diagnosing Failure Root Causes in Platform-Orchestrated Agentic Systems: Dataset, Taxonomy, and Benchmark](https://arxiv.org/abs/2509.23735)
*Xuyan Ma,Xiaofei Xie,Yawen Wang,Junjie Wang,Boyu Wu,Mingyang Li,Qing Wang*

Main category: cs.AI

TL;DR: 该论文研究了平台编排的智能体系统的故障根因识别，构建了包含307个故障日志的数据集AgentFail，开发了故障根因分类法，并建立了基于LLM的自动根因识别基准。


<details>
  <summary>Details</summary>
Motivation: 随着低代码平台编排的智能体系统被广泛部署用于复杂推理任务，这些系统存在脆弱性且缺乏系统性的故障根因识别方法。

Method: 构建AgentFail数据集，利用反事实推理修复策略确保标注可靠性，开发故障根因分类法，并建立基于LLM的自动根因识别基准。

Result: 分类法能显著提高LLM的根因识别性能，但最高准确率仅为33.6%，表明该任务仍具挑战性。

Conclusion: 该研究为平台编排智能体系统提供了可靠的故障根因数据集、分类法和基准，为开发更可靠的智能体系统奠定了基础。

Abstract: Agentic systems consisting of multiple LLM-driven agents coordinating through
tools and structured interactions, are increasingly deployed for complex
reasoning and problem-solving tasks. At the same time, emerging low-code and
template-based agent development platforms (e.g., Dify) enable users to rapidly
build and orchestrate agentic systems, which we refer to as
platform-orchestrated agentic systems. However, these systems are also fragile
and it remains unclear how to systematically identify their potential failure
root cause. This paper presents a study of root cause identification of these
platform-orchestrated agentic systems. To support this initiative, we construct
a dataset AgentFail containing 307 failure logs from ten agentic systems, each
with fine-grained annotations linking failures to their root causes. We
additionally utilize counterfactual reasoning-based repair strategy to ensure
the reliability of the annotation. Building on the dataset, we develop a
taxonomy that characterizes failure root causes and analyze their distribution
across different platforms and task domains. Furthermore, we introduce a
benchmark that leverages LLMs for automatically identifying root causes, in
which we also utilize the proposed taxonomy as guidance for LLMs. Results show
that the taxonomy can largely improve the performance, thereby confirming its
utility. Nevertheless, the accuracy of root cause identification reaches at
most 33.6%, which indicates that this task still remains challenging. In light
of these results, we also provide actionable guidelines for building such
agentic systems. In summary, this paper provides a reliable dataset of failure
root cause for platform-orchestrated agentic systems, corresponding taxonomy
and benchmark, which serves as a foundation for advancing the development of
more reliable agentic systems.

</details>


### [190] [GUI-Shepherd: Reliable Process Reward and Verification for Long-Sequence GUI Tasks](https://arxiv.org/abs/2509.23738)
*Cong Chen,Kaixiang Ji,Hao Zhong,Muzhi Zhu,Anzhou Li,Guo Gan,Ziyuan Huang,Cheng Zou,Jiajia Liu,Jingdong Chen,Hao Chen,Chunhua Shen*

Main category: cs.AI

TL;DR: GUI-Shepherd是一个过程奖励模型，通过提供密集的逐步反馈来解决GUI任务中的稀疏奖励和信用分配问题，显著提升了自主代理在AndroidWorld和AndroidControl基准测试中的性能。


<details>
  <summary>Details</summary>
Motivation: 长序列GUI任务中的自主代理受到稀疏奖励和难以处理的信用分配问题的阻碍，需要一种能够提供密集、逐步反馈的解决方案。

Method: 引入GUI-Shepherd过程奖励模型，基于包含52k交互的大规模数据集训练，该数据集包含人工标注分数和GPT-4o生成的推理过程，可作为RL训练中的奖励提供者和推理验证器。

Result: 在AndroidWorld基准测试中，通过多轮在线PPO将成功率提高了7.7个百分点；作为推理验证器带来5.1个百分点的改进；在AndroidControl基准测试中，作为奖励提供者提升2.2个百分点，作为验证器提升4.3个百分点。

Conclusion: 高保真的过程监督对于构建更强大的GUI代理至关重要，GUI-Shepherd提供了一个通用且有效的解决方案。

Abstract: Autonomous agents for long-sequence Graphical User Interface tasks are
hindered by sparse rewards and the intractable credit assignment problem. To
address these challenges, we introduce GUI-Shepherd, a Process Reward Model
that provides dense, step-by-step feedback to guide agents. GUI-Shepherd is
trained on a diverse large-scale data set of $52$k interactions that features
human-annotated scores and GPT-4o generated rationales, enabling it to serve
both as a reward provider for RL training and as a verifier for inference. As
far as we know, we are the first to conduct a systematic study of process
supervision in GUI agents, across diverse settings from online long-horizon
tasks to offline single-step prediction. On the online AndroidWorld benchmark,
GUI-Shepherd improves success rate by $7.7$ points via multi-turn online PPO,
significantly outperforming Outcome Reward Model based competitors. When used
as an inference verifier, it brings $5.1$ points improvements. The benefits
generalize to the offline AndroidControl benchmark, with gains of $2.2$ points
as a reward provider and $4.3$ points as a verifier. Collectively, our results
establish that high-fidelity process supervision is critical for building more
capable GUI agents and present a generalizable solution.

</details>


### [191] [Transparent Visual Reasoning via Object-Centric Agent Collaboration](https://arxiv.org/abs/2509.23757)
*Benjamin Teoh,Ben Glocker,Francesca Toni,Avinash Kori*

Main category: cs.AI

TL;DR: OCEAN是一个基于对象中心表示和多智能体协商的可解释AI框架，通过博弈论推理过程生成基于人类可理解概念的视觉解释。


<details>
  <summary>Details</summary>
Motivation: 解决可解释AI中生成基于人类可理解概念的视觉解释的挑战，特别是需要提供忠实且直观的解释。

Method: 使用对象中心表示和透明的多智能体推理过程，通过博弈论驱动智能体就一致且区分性证据达成共识，实现端到端训练。

Result: 在两个诊断性多对象数据集上，OCEAN与最先进的黑盒模型表现相当，用户研究显示其解释更直观和可信。

Conclusion: OCEAN框架能够提供忠实且可解释的决策过程，在保持竞争力的同时显著提升了解释的直观性和可信度。

Abstract: A central challenge in explainable AI, particularly in the visual domain, is
producing explanations grounded in human-understandable concepts. To tackle
this, we introduce OCEAN (Object-Centric Explananda via Agent Negotiation), a
novel, inherently interpretable framework built on object-centric
representations and a transparent multi-agent reasoning process. The
game-theoretic reasoning process drives agents to agree on coherent and
discriminative evidence, resulting in a faithful and interpretable
decision-making process. We train OCEAN end-to-end and benchmark it against
standard visual classifiers and popular posthoc explanation tools like GradCAM
and LIME across two diagnostic multi-object datasets. Our results demonstrate
competitive performance with respect to state-of-the-art black-box models with
a faithful reasoning process, which was reflected by our user study, where
participants consistently rated OCEAN's explanations as more intuitive and
trustworthy.

</details>


### [192] [From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning](https://arxiv.org/abs/2509.23768)
*Cheng Yang,Jiaxuan Lu,Haiyuan Wan,Junchi Yu,Feiwei Qin*

Main category: cs.AI

TL;DR: ChemMAS是一个基于多智能体系统的化学反应条件推荐框架，将条件预测重构为基于证据的推理任务，通过分解为机制基础、多通道召回、约束感知智能体辩论和理由聚合等步骤，提供可解释的化学知识依据。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型方法很少解释推荐反应条件的原理，限制了其在高风险科学工作流程中的实用性，需要开发能够提供可解释推理的AI系统。

Method: 采用多智能体系统框架，将任务分解为：机制基础、多通道召回、约束感知智能体辩论和理由聚合四个步骤，每个决策都基于化学知识和检索到的先例提供可解释的论证。

Result: 实验显示ChemMAS在Top-1准确率上比领域特定基线提高20-35%，比通用大语言模型提高10-15%，同时提供可证伪、可信赖的推理依据。

Conclusion: ChemMAS为科学发现中的可解释AI建立了新范式，通过基于证据的推理提供可信赖的化学反应条件推荐。

Abstract: The chemical reaction recommendation is to select proper reaction condition
parameters for chemical reactions, which is pivotal to accelerating chemical
science. With the rapid development of large language models (LLMs), there is
growing interest in leveraging their reasoning and planning capabilities for
reaction condition recommendation. Despite their success, existing methods
rarely explain the rationale behind the recommended reaction conditions,
limiting their utility in high-stakes scientific workflows. In this work, we
propose ChemMAS, a multi-agent system that reframes condition prediction as an
evidence-based reasoning task. ChemMAS decomposes the task into mechanistic
grounding, multi-channel recall, constraint-aware agentic debate, and rationale
aggregation. Each decision is backed by interpretable justifications grounded
in chemical knowledge and retrieved precedents. Experiments show that ChemMAS
achieves 20-35% gains over domain-specific baselines and outperforms
general-purpose LLMs by 10-15% in Top-1 accuracy, while offering falsifiable,
human-trustable rationales, which establishes a new paradigm for explainable AI
in scientific discovery.

</details>


### [193] [Falcon: A Cross-Modal Evaluation Dataset for Comprehensive Safety Perception](https://arxiv.org/abs/2509.23783)
*Qi Xue,Minrui Jiang,Runjia Zhang,Xiurui Xie,Pei Ke,Guisong Liu*

Main category: cs.AI

TL;DR: 本文提出了Falcon数据集和FalconEye评估器，用于评估多模态大语言模型生成内容的安全性。Falcon包含57,515个视觉问答对，涵盖13种危害类别，FalconEye基于该数据集微调Qwen2.5-VL-7B模型，在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型安全性评估方法研究不足，特别是忽视了视觉信息在内容审核中的关键作用。需要专门针对MLLMs的安全性评估工具。

Method: 构建大规模视觉语言安全数据集Falcon（57,515个VQA对，13种危害类别），并基于此微调Qwen2.5-VL-7B模型开发FalconEye评估器。

Result: FalconEye在Falcon-test数据集以及VLGuard和Beavertail-V基准测试中，总体准确率优于所有基线模型，能够可靠识别复杂多模态对话中的有害内容。

Conclusion: FalconEye作为实用的MLLMs安全审计工具具有潜力，填补了多模态内容安全性评估的研究空白。

Abstract: Existing methods for evaluating the harmfulness of content generated by large
language models (LLMs) have been well studied. However, approaches tailored to
multimodal large language models (MLLMs) remain underdeveloped and lack depth.
This work highlights the crucial role of visual information in moderating
content in visual question answering (VQA), a dimension often overlooked in
current research. To bridge this gap, we introduce Falcon, a large-scale
vision-language safety dataset containing 57,515 VQA pairs across 13 harm
categories. The dataset provides explicit annotations for harmful attributes
across images, instructions, and responses, thereby facilitating a
comprehensive evaluation of the content generated by MLLMs. In addition, it
includes the relevant harm categories along with explanations supporting the
corresponding judgments. We further propose FalconEye, a specialized evaluator
fine-tuned from Qwen2.5-VL-7B using the Falcon dataset. Experimental results
demonstrate that FalconEye reliably identifies harmful content in complex and
safety-critical multimodal dialogue scenarios. It outperforms all other
baselines in overall accuracy across our proposed Falcon-test dataset and two
widely-used benchmarks-VLGuard and Beavertail-V, underscoring its potential as
a practical safety auditing tool for MLLMs.

</details>


### [194] [From Frustration to Fun: An Adaptive Problem-Solving Puzzle Game Powered by Genetic Algorithm](https://arxiv.org/abs/2509.23796)
*Matthew McConnell,Richard Zhao*

Main category: cs.AI

TL;DR: 开发了一个基于遗传算法的自适应路径搜索谜题游戏，通过玩家建模实时调整难度以保持最佳挑战水平


<details>
  <summary>Details</summary>
Motivation: 通过自适应难度调整来维持玩家参与度、减少挫败感，并为教育领域的应用奠定基础

Method: 使用遗传算法动态生成路径搜索谜题，结合玩家建模系统实时调整难度，进行试点用户研究比较不同自适应系统

Result: 建立了自适应问题解决系统，能够根据玩家表现动态调整谜题难度，保持最佳挑战水平

Conclusion: 这项工作为情感驱动的玩家模型、高级AI自适应技术以及教育领域的应用研究奠定了基础

Abstract: This paper explores adaptive problem solving with a game designed to support
the development of problem-solving skills. Using an adaptive, AI-powered puzzle
game, our adaptive problem-solving system dynamically generates
pathfinding-based puzzles using a genetic algorithm, tailoring the difficulty
of each puzzle to individual players in an online real-time approach. A
player-modeling system records user interactions and informs the generation of
puzzles to approximate a target difficulty level based on various metrics of
the player. By combining procedural content generation with online adaptive
difficulty adjustment, the system aims to maintain engagement, mitigate
frustration, and maintain an optimal level of challenge. A pilot user study
investigates the effectiveness of this approach, comparing different types of
adaptive difficulty systems and interpreting players' responses. This work lays
the foundation for further research into emotionally informed player models,
advanced AI techniques for adaptivity, and broader applications beyond gaming
in educational settings.

</details>


### [195] [AnveshanaAI: A Multimodal Platform for Adaptive AI/ML Education through Automated Question Generation and Interactive Assessment](https://arxiv.org/abs/2509.23811)
*Rakesh Thakur,Diksha Khandelwal,Shreya Tiwari*

Main category: cs.AI

TL;DR: AnveshanaAI是一个基于应用的人工智能学习平台，通过个性化仪表板、游戏化追踪和自适应评估方法，整合了适应性、游戏化、互动性和可解释性来支持新一代AI教育。


<details>
  <summary>Details</summary>
Motivation: 现有平台使用静态问题库，缺乏平衡的学习进度和透明度，需要一种更有效的方法来提升AI教育的参与度和学习效果。

Method: 平台采用基于布鲁姆分类法的数据集，结合语义相似度检查和可解释AI技术，使用自适应、自动化和领域感知的评估方法，并通过游戏化元素如积分、成就和结构化导航来增强学习体验。

Result: 实验显示平台具有广泛的数据集覆盖范围，稳定的微调效果（困惑度降低），以及学习者参与度的显著提升。

Conclusion: AnveshanaAI通过整合适应性、游戏化、互动性和可解释性，为下一代AI教育提供了有效的支持平台。

Abstract: We propose AnveshanaAI, an application-based learning platform for artificial
intelligence. With AnveshanaAI, learners are presented with a personalized
dashboard featuring streaks, levels, badges, and structured navigation across
domains such as data science, machine learning, deep learning, transformers,
generative AI, large language models, and multimodal AI, with scope to include
more in the future. The platform incorporates gamified tracking with points and
achievements to enhance engagement and learning, while switching between
Playground, Challenges, Simulator, Dashboard, and Community supports
exploration and collaboration. Unlike static question repositories used in
existing platforms, AnveshanaAI ensures balanced learning progression through a
dataset grounded in Bloom's taxonomy, with semantic similarity checks and
explainable AI techniques improving transparency and reliability. Adaptive,
automated, and domain-aware assessment methods are also employed. Experiments
demonstrate broad dataset coverage, stable fine-tuning with reduced perplexity,
and measurable gains in learner engagement. Together, these features illustrate
how AnveshanaAI integrates adaptivity, gamification, interactivity, and
explainability to support next-generation AI education.

</details>


### [196] [Mix-Ecom: Towards Mixed-Type E-Commerce Dialogues with Complex Domain Rules](https://arxiv.org/abs/2509.23836)
*Chenyu Zhou,Xiaoming Shi,Hui Qiu,Xiawu Zheng,Haitao Leng,Yankai Jiang,Shaoguo Liu,Tingting Gao,Rongrong Ji*

Main category: cs.AI

TL;DR: 提出了Mix-ECom数据集，基于真实客服对话构建，包含4,799个混合类型电商对话样本，涵盖4种对话类型、3种电商任务类型和82条电商规则，用于评估电商代理处理复杂对话和领域规则的能力。


<details>
  <summary>Details</summary>
Motivation: 当前电商代理基准缺乏评估处理混合类型电商对话和复杂领域规则的能力，需要更全面的评估框架。

Method: 基于真实客服对话构建Mix-ECom数据集，通过后处理去除用户隐私并添加思维链过程，包含多种对话类型和电商规则。

Result: 当前电商代理在处理电商对话时能力不足，主要由于复杂领域规则导致的幻觉问题。

Conclusion: Mix-ECom数据集填补了电商代理评估的空白，揭示了当前代理在处理复杂电商对话时的局限性，为未来研究提供了重要基准。

Abstract: E-commerce agents contribute greatly to helping users complete their
e-commerce needs. To promote further research and application of e-commerce
agents, benchmarking frameworks are introduced for evaluating LLM agents in the
e-commerce domain. Despite the progress, current benchmarks lack evaluating
agents' capability to handle mixed-type e-commerce dialogue and complex domain
rules. To address the issue, this work first introduces a novel corpus, termed
Mix-ECom, which is constructed based on real-world customer-service dialogues
with post-processing to remove user privacy and add CoT process. Specifically,
Mix-ECom contains 4,799 samples with multiply dialogue types in each e-commerce
dialogue, covering four dialogue types (QA, recommendation, task-oriented
dialogue, and chit-chat), three e-commerce task types (pre-sales, logistics,
after-sales), and 82 e-commerce rules. Furthermore, this work build baselines
on Mix-Ecom and propose a dynamic framework to further improve the performance.
Results show that current e-commerce agents lack sufficient capabilities to
handle e-commerce dialogues, due to the hallucination cased by complex domain
rules. The dataset will be publicly available.

</details>


### [197] [AgentGuard: Runtime Verification of AI Agents](https://arxiv.org/abs/2509.23864)
*Roham Koohestani*

Main category: cs.AI

TL;DR: AgentGuard是一个用于自主AI系统运行时验证的框架，通过动态概率保证提供连续定量保证，使用在线学习构建马尔可夫决策过程模型并实时验证概率属性。


<details>
  <summary>Details</summary>
Motivation: 自主AI系统的快速演进带来了显著风险，其固有的不可预测性和涌现行为使传统验证方法失效，需要转向概率保证方法。

Method: 作为检查层观察agent的原始I/O，抽象为状态模型转换的形式事件，使用在线学习动态构建和更新马尔可夫决策过程模型，通过概率模型检查实时验证定量属性。

Result: 提出了AgentGuard框架，实现了对自主AI系统的运行时验证，能够提供动态概率保证。

Conclusion: AgentGuard为解决自主AI系统的验证挑战提供了一种新范式，通过动态概率保证方法弥补了传统验证方法的不足。

Abstract: The rapid evolution to autonomous, agentic AI systems introduces significant
risks due to their inherent unpredictability and emergent behaviors; this also
renders traditional verification methods inadequate and necessitates a shift
towards probabilistic guarantees where the question is no longer if a system
will fail, but the probability of its failure within given constraints. This
paper presents AgentGuard, a framework for runtime verification of Agentic AI
systems that provides continuous, quantitative assurance through a new paradigm
called Dynamic Probabilistic Assurance. AgentGuard operates as an inspection
layer that observes an agent's raw I/O and abstracts it into formal events
corresponding to transitions in a state model. It then uses online learning to
dynamically build and update a Markov Decision Process (MDP) that formally
models the agent's emergent behavior. Using probabilistic model checking, the
framework then verifies quantitative properties in real-time.

</details>


### [198] [Rethinking Reward Miscalibration of GRPO in Agentic RL](https://arxiv.org/abs/2509.23870)
*Jingyu Liu,Xiaopeng Wu,Jingquan Peng,Kehan Chen,Chuan Yu,Lizhong Ding,Yong Liu*

Main category: cs.AI

TL;DR: 本文挑战了关于结果奖励会导致错误中间步骤被强化的传统观点，揭示了结果奖励实际上能确保错误步骤获得负优势值。研究发现梯度耦合是智能体强化学习中的关键问题，并提出通过训练行动者分类好坏动作来缓解梯度干扰。


<details>
  <summary>Details</summary>
Motivation: 解决长期任务中结果奖励可能导致错误中间步骤被错误强化的认知偏差，并识别智能体强化学习中梯度耦合问题的根本原因。

Method: 提出训练行动者分类好坏动作的方法，通过分离好/坏动作的嵌入表示来减轻梯度干扰，并进行广泛的实验验证。

Result: 实验证明所提出的方法能有效缓解梯度耦合问题，提高智能体在长期任务中的性能表现。

Conclusion: 结果奖励本身不会强化错误动作，真正的挑战在于梯度耦合问题，而通过动作分类训练可以有效解决这一问题。

Abstract: Building autonomous agents capable of solving long-horizon, real-world tasks
has garnered significant research interest. But outcome based rewards may cause
reward miscalibration which means it might mistakenly allocate positive reward
to flawed middle steps which is regarded as the key reason making the bad
actions being reinforced during training. However we reveal that outcome based
reward ensures expected negative advantage for those flawed middle steps, which
means the flawed actions should be punished during training. Even accounting
for the ``squeezing effect", the probability mass of good actions should
increase and the actor should gradually get rid of harmful actions. This shows
that flawed actions should be punished during training. We further identify
gradient coupling between similar samples as a key issue in agentic RL, the
input prompt is extremely similar and the output action space is limited,
therefore during training, gradients from well-performing samples can
inadvertently strengthen suboptimal or incorrect actions due to similar input
observation and output actions. We show that with gradient coupling, some
flawed actions might be enhanced. To address this, we propose training the
actor to classify good or bad actions to separate the embedding of good/bad
actions and alleviate the gradient interference, extensive experiments shows
its effectiveness.

</details>


### [199] [Quant Fever, Reasoning Blackholes, Schrodinger's Compliance, and More: Probing GPT-OSS-20B](https://arxiv.org/abs/2509.23882)
*Shuyi Lin,Tian Lu,Zikai Wang,Bo Wen,Yibo Zhao,Cheng Tan*

Main category: cs.AI

TL;DR: 对GPT-OSS-20B模型进行安全评估，发现多种故障模式，包括量化热、推理黑洞、薛定谔合规性、推理过程幻象和链式导向提示，这些行为可被利用导致严重后果。


<details>
  <summary>Details</summary>
Motivation: 评估GPT-OSS系列开源语言模型在对抗条件下的安全性，特别是GPT-OSS-20B模型的行为表现。

Method: 使用Jailbreak Oracle系统化LLM评估工具，在不同对抗条件下探测模型行为。

Result: 发现多种故障模式，包括量化热、推理黑洞、薛定谔合规性、推理过程幻象和链式导向提示，这些行为可被利用。

Conclusion: GPT-OSS-20B模型存在多种安全漏洞，可能被恶意利用造成严重后果，需要加强安全防护。

Abstract: OpenAI's GPT-OSS family provides open-weight language models with explicit
chain-of-thought (CoT) reasoning and a Harmony prompt format. We summarize an
extensive security evaluation of GPT-OSS-20B that probes the model's behavior
under different adversarial conditions. Using the Jailbreak Oracle (JO) [1], a
systematic LLM evaluation tool, the study uncovers several failure modes
including quant fever, reasoning blackholes, Schrodinger's compliance,
reasoning procedure mirage, and chain-oriented prompting. Experiments
demonstrate how these behaviors can be exploited on GPT-OSS-20B models, leading
to severe consequences.

</details>


### [200] [From Neural Networks to Logical Theories: The Correspondence between Fibring Modal Logics and Fibring Neural Networks](https://arxiv.org/abs/2509.23912)
*Ouns El Harzli,Bernardo Cuenca Grau,Artur d'Avila Garcez,Ian Horrocks,Tarek R. Besold*

Main category: cs.AI

TL;DR: 该论文建立了神经网络纤维化与模态逻辑纤维化之间的形式化对应关系，并利用这种关系推导了图神经网络、图注意力网络和Transformer编码器的非均匀逻辑表达能力结果。


<details>
  <summary>Details</summary>
Motivation: 虽然神经网络纤维化已被引入作为结合学习和推理的神经符号框架，但其与模态逻辑纤维化的确切对应关系从未被形式化建立。本文旨在填补这一空白。

Method: 通过形式化与纤维化神经网络兼容的纤维化模型概念，建立神经网络纤维化与模态逻辑纤维化之间的对应关系。

Result: 成功建立了神经网络纤维化与模态逻辑纤维化之间的形式化对应，并推导了GNNs、GATs和Transformer编码器的非均匀逻辑表达能力结果。

Conclusion: 这项工作为使用纤维化作为形式化工具来解释神经网络学习的逻辑理论开辟了道路，为计算逻辑工具的应用奠定了基础。

Abstract: Fibring of modal logics is a well-established formalism for combining
countable families of modal logics into a single fibred language with common
semantics, characterized by fibred models. Inspired by this formalism, fibring
of neural networks was introduced as a neurosymbolic framework for combining
learning and reasoning in neural networks. Fibring of neural networks uses the
(pre-)activations of a trained network to evaluate a fibring function computing
the weights of another network whose outputs are injected back into the
original network. However, the exact correspondence between fibring of neural
networks and fibring of modal logics was never formally established. In this
paper, we close this gap by formalizing the idea of fibred models
\emph{compatible} with fibred neural networks. Using this correspondence, we
then derive non-uniform logical expressiveness results for Graph Neural
Networks (GNNs), Graph Attention Networks (GATs) and Transformer encoders.
Longer-term, the goal of this paper is to open the way for the use of fibring
as a formalism for interpreting the logical theories learnt by neural networks
with the tools of computational logic.

</details>


### [201] [Conditional Advantage Estimation for Reinforcement Learning in Large Reasoning Models](https://arxiv.org/abs/2509.23962)
*Guanxu Chen,Yafu Li,Yuxian Jiang,Chen Qian,Qihan Ren,Jingyi Yang,Yu Cheng,Dongrui Liu,Jing Shao*

Main category: cs.AI

TL;DR: CANON是一种新的优势估计方法，通过无方向性分组比较来放大目标指标的影响，在数学推理和复杂逻辑任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在融入先验知识时依赖手工设计的惩罚和偏好，这些方向性先验可能过于偏颇且需要仔细的超参数调优，容易导致失败。

Method: CANON通过将采样响应按目标指标高低值重新分组，通过组间比较衡量哪个指标趋势有助于更好性能，并在同组内识别更好的响应。

Result: 基于熵的CANON在三个大语言模型的数学推理和高复杂度逻辑任务中一致优于先前方法。应用于响应长度时，CANON进一步提高了token效率，在性能-成本权衡中产生了更有利的帕累托边界。

Conclusion: CANON提供了一种有效的方法来放大目标指标的影响而无需预设其方向，在增强大语言模型推理能力和提高token效率方面表现出色。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) for large language
models (LLMs) has achieved remarkable progress in enhancing LLMs' reasoning
capabilities on tasks with clear correctness criteria, such as mathematical
reasoning tasks. Several training metrics, such as entropy or response length,
have been observed to correlate with different reasoning behaviors in
reinforcement learning. Prior approaches incorporate such priors through reward
or advantage shaping, which often relies on hand-crafted penalties and
preferences (e.g., higher-is-better or lower-is-better). However, without
careful hyperparameter tuning, these directional priors can be overly biased
and may lead to failure. To this end, we introduce Conditional advANtage
estimatiON (CANON), amplifying the impact of the target metric without
presuming its direction. Specifically, CANON regroups the sampled responses
into two groups based on the higher or lower value of a target metric, measures
which metric trend contributes to better performance through inter-group
comparison, and identifies the better response within the same group. In
summary, CANON based on entropy consistently outperforms prior methods across
three LLMs on both math reasoning and high-complexity logic tasks. When applied
to response length, CANON further improves token efficiency, yielding a more
favorable Pareto frontier in the performance-cost trade-off.

</details>


### [202] [Automatic selection of primary studies in systematic reviews with evolutionary rule-based classification](https://arxiv.org/abs/2509.23981)
*José de la Torre-López,Aurora Ramírez,José Raúl Romero*

Main category: cs.AI

TL;DR: 提出了一种基于语法引导遗传编程的进化机器学习方法，用于自动识别文献检索中的相关论文，结合文本信息和文献计量数据，在保持可解释性的同时提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 系统文献综述中的文献搜索、筛选和分析任务耗时耗力，随着人工智能的发展，需要自动化方法来减少人工筛选文献的工作量。

Method: 使用语法引导遗传编程构建基于规则的可解释分类器，能够结合文本信息和文献计量数据，这些数据在现有方法中通常未被考虑。

Result: 实验证明该方法能够生成准确的分类器，同时保持可解释性，并支持现有方法不支持的配置化信息源。

Conclusion: 该方法在自动论文选择方面具有显著优势，能够在保持模型可解释性的前提下提高分类性能，并整合更多类型的数据源。

Abstract: Searching, filtering and analysing scientific literature are time-consuming
tasks when performing a systematic literature review. With the rise of
artificial intelligence, some steps in the review process are progressively
being automated. In particular, machine learning for automatic paper selection
can greatly reduce the effort required to identify relevant literature in
scientific databases. We propose an evolutionary machine learning approach,
called \ourmodel, to automatically determine whether a paper retrieved from a
literature search process is relevant. \ourmodel builds an interpretable
rule-based classifier using grammar-guided genetic programming. The use of a
grammar to define the syntax and the structure of the rules allows \ourmodel to
easily combine the usual textual information with other bibliometric data not
considered by state-of-the-art methods. Our experiments demonstrate that it is
possible to generate accurate classifiers without impairing interpretability
and using configurable information sources not supported so far.

</details>


### [203] [TusoAI: Agentic Optimization for Scientific Methods](https://arxiv.org/abs/2509.23986)
*Alistair Turcan,Kexin Huang,Lei Li,Martin Jinye Zhang*

Main category: cs.AI

TL;DR: TusoAI是一个自主开发科学计算方法的AI系统，通过整合领域知识和迭代优化，在单细胞RNA-seq数据去噪和卫星地球监测等任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学发现因手动开发计算工具而缓慢，现有AI系统要么使用现有方法进行分析，要么开发通用机器学习方法，未能有效整合科学领域的非结构化知识。

Method: TusoAI将领域知识整合到知识树表示中，执行迭代的领域特定优化和模型诊断，通过候选解决方案池改进性能。

Result: 在基准评估中，TusoAI在多种任务上优于最先进的专家方法、MLE代理和科学AI代理。应用于遗传学问题改进了现有计算方法，发现了新的生物学关联。

Conclusion: TusoAI能够自主开发优化的计算方法，加速科学发现，在遗传学应用中揭示了新的疾病-基因关联。

Abstract: Scientific discovery is often slowed by the manual development of
computational tools needed to analyze complex experimental data. Building such
tools is costly and time-consuming because scientists must iteratively review
literature, test modeling and scientific assumptions against empirical data,
and implement these insights into efficient software. Large language models
(LLMs) have demonstrated strong capabilities in synthesizing literature,
reasoning with empirical data, and generating domain-specific code, offering
new opportunities to accelerate computational method development. Existing
LLM-based systems either focus on performing scientific analyses using existing
computational methods or on developing computational methods or models for
general machine learning without effectively integrating the often unstructured
knowledge specific to scientific domains. Here, we introduce TusoAI , an
agentic AI system that takes a scientific task description with an evaluation
function and autonomously develops and optimizes computational methods for the
application. TusoAI integrates domain knowledge into a knowledge tree
representation and performs iterative, domain-specific optimization and model
diagnosis, improving performance over a pool of candidate solutions. We
conducted comprehensive benchmark evaluations demonstrating that TusoAI
outperforms state-of-the-art expert methods, MLE agents, and scientific AI
agents across diverse tasks, such as single-cell RNA-seq data denoising and
satellite-based earth monitoring. Applying TusoAI to two key open problems in
genetics improved existing computational methods and uncovered novel biology,
including 9 new associations between autoimmune diseases and T cell subtypes
and 7 previously unreported links between disease variants linked to their
target genes. Our code is publicly available at
https://github.com/Alistair-Turcan/TusoAI.

</details>


### [204] [LLM/Agent-as-Data-Analyst: A Survey](https://arxiv.org/abs/2509.23988)
*Zirui Tang,Weizheng Wang,Zihang Zhou,Yang Jiao,Bangrui Xu,Boyu Niu,Xuanhe Zhou,Guoliang Li,Yeye He,Wei Zhou,Yitong Song,Cheng Tan,Bin Wang,Conghui He,Xiaoyang Wang,Fan Wu*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型和智能代理的数据分析技术，相比传统方法具有语义理解、自然语言接口、自主管道编排等优势，提出了五个关键设计目标，并从模态角度回顾了结构化、半结构化、非结构化和异构数据的处理技术。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则或小模型的数据分析方法在处理复杂数据理解、自然语言交互和语义分析方面存在局限，需要更智能的数据分析解决方案。

Method: 提出五个关键设计目标：语义感知设计、模态混合集成、自主管道、工具增强工作流和开放世界任务支持。从模态角度系统回顾了结构化数据（表格问答、NL2GQL）、半结构化数据（标记语言理解）、非结构化数据（图表理解、文档理解）和异构数据（数据检索、模态对齐）的处理技术。

Result: 大语言模型和代理技术显著提升了数据分析能力，能够处理复杂的数据理解任务，提供自然语言接口，并实现自主的数据分析管道编排。

Conclusion: LLM/Agent技术为数据分析带来了革命性进步，但仍面临挑战，需要进一步研究来推进智能数据分析的发展。

Abstract: Large language model (LLM) and agent techniques for data analysis (a.k.a
LLM/Agent-as-Data-Analyst) have demonstrated substantial impact in both
academica and industry. In comparison with traditional rule or small-model
based approaches, (agentic) LLMs enable complex data understanding, natural
language interfaces, semantic analysis functions, and autonomous pipeline
orchestration. The technical evolution further distills five key design goals
for intelligent data analysis agents, namely semantic-aware design,
modality-hybrid integration, autonomous pipelines, tool-augmented workflows,
and support for open-world tasks. From a modality perspective, we review
LLM-based techniques for (i) structured data (e.g., table question answering
for relational data and NL2GQL for graph data), (ii) semi-structured data
(e.g., markup languages understanding and semi-structured table modeling),
(iii) unstructured data (e.g., chart understanding, document understanding,
programming languages vulnerable detection), and (iv) heterogeneous data (e.g.,
data retrieval and modality alignment for data lakes). Finally, we outline the
remaining challenges and propose several insights and practical directions for
advancing LLM/Agent-powered data analysis.

</details>


### [205] [Future-Proofing Programmers: Optimal Knowledge Tracing for AI-Assisted Personalized Education](https://arxiv.org/abs/2509.23996)
*Yuchen Wang,Pei-Duo Yu,Chee Wei Tan*

Main category: cs.AI

TL;DR: CoTutor是一个AI驱动的教育模型，结合贝叶斯知识追踪和信号处理技术来优化学生进度建模，提供自适应反馈和学习策略，在大学试验中显示出学习成果的显著提升。


<details>
  <summary>Details</summary>
Motivation: 受Richard Hamming关于计算机辅助'学会学习'愿景的启发，旨在通过AI技术建模学生学习状态并优化教育过程，实现个性化学习和教育规模化。

Method: 将贝叶斯知识追踪与信号处理技术相结合，应用凸优化和生成式AI，开发AI copilot系统来提供自适应反馈和学习策略。

Result: 在大学试验中，CoTutor在提升学习成果方面表现出可衡量的改进，优于传统教育工具，展示了AI驱动的个性化学习和可扩展性潜力。

Conclusion: CoTutor在自动化学习分析的同时保留人类的教学判断，确保AI促进知识追踪过程，同时让学习者能够发现新的见解，为教育技术的隐私和伦理考量提供了未来发展机会。

Abstract: Learning to learn is becoming a science, driven by the convergence of
knowledge tracing, signal processing, and generative AI to model student
learning states and optimize education. We propose CoTutor, an AI-driven model
that enhances Bayesian Knowledge Tracing with signal processing techniques to
improve student progress modeling and deliver adaptive feedback and strategies.
Deployed as an AI copilot, CoTutor combines generative AI with adaptive
learning technology. In university trials, it has demonstrated measurable
improvements in learning outcomes while outperforming conventional educational
tools. Our results highlight its potential for AI-driven personalization,
scalability, and future opportunities for advancing privacy and ethical
considerations in educational technology. Inspired by Richard Hamming's vision
of computer-aided 'learning to learn,' CoTutor applies convex optimization and
signal processing to automate and scale up learning analytics, while reserving
pedagogical judgment for humans, ensuring AI facilitates the process of
knowledge tracing while enabling learners to uncover new insights.

</details>


### [206] [Do Repetitions Matter? Strengthening Reliability in LLM Evaluations](https://arxiv.org/abs/2509.24086)
*Miguel Angel Alvarado Gonzalez,Michelle Bruno Hernandez,Miguel Angel Peñaloza Perez,Bruno Lopez Orozco,Jesus Tadeo Cruz Soto,Sandra Malagon*

Main category: cs.AI

TL;DR: 单次运行的LLM排行榜不可靠，需要至少2次重复运行来获得稳定的模型排名结果


<details>
  <summary>Details</summary>
Motivation: 当前LLM排行榜通常依赖单次随机运行，但需要多少次重复才能获得可靠结论尚不明确

Method: 在AI4Math基准上对8个最先进模型进行3次独立运行，使用混合效应逻辑回归、领域级边际均值、排名不稳定性分析和运行间可靠性评估

Result: 单次运行排行榜很脆弱：83%的切片至少出现一次排名反转；两次运行可消除约83%的单次运行反转；平均运行次数仅带来约5%的标准误差缩减

Conclusion: 应将评估视为实验，报告不确定性，在随机解码下使用≥2次重复运行，这能在保持小团队可行性的同时提高鲁棒性

Abstract: LLM leaderboards often rely on single stochastic runs, but how many
repetitions are required for reliable conclusions remains unclear. We
re-evaluate eight state-of-the-art models on the AI4Math Benchmark with three
independent runs per setting. Using mixed-effects logistic regression,
domain-level marginal means, rank-instability analysis, and run-to-run
reliability, we assessed the value of additional repetitions. Our findings
shows that Single-run leaderboards are brittle: 10/12 slices (83\%) invert at
least one pairwise rank relative to the three-run majority, despite a zero
sign-flip rate for pairwise significance and moderate overall interclass
correlation. Averaging runs yields modest SE shrinkage ($\sim$5\% from one to
three) but large ranking gains; two runs remove $\sim$83\% of single-run
inversions. We provide cost-aware guidance for practitioners: treat evaluation
as an experiment, report uncertainty, and use $\geq 2$ repetitions under
stochastic decoding. These practices improve robustness while remaining
feasible for small teams and help align model comparisons with real-world
reliability.

</details>


### [207] [Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs](https://arxiv.org/abs/2509.24107)
*Shreyas Singh,Kunal Singh,Pradeep Moturi*

Main category: cs.AI

TL;DR: Fathom-DeepResearch是一个由两个专门模型组成的智能系统：Fathom-Search-4B用于基于证据的网络搜索调查，Fathom-Synthesizer-4B用于将搜索轨迹转换为结构化研究报告。该系统在多个基准测试中达到开源权重类别的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 工具集成推理已成为实现智能应用的关键焦点，DeepResearch代理因其在复杂开放信息搜索任务中的强大性能而受到关注。

Method: 使用两个专门模型：1) Fathom-Search-4B基于Qwen3-4B训练，采用DUETQA数据集、RAPO强化学习和可引导的步骤级奖励；2) Fathom-Synthesizer-4B将多轮搜索轨迹转换为结构化研究报告。

Result: 在DeepSearch基准测试(SimpleQA、FRAMES、WebWalker、Seal0、MuSiQue)和DeepResearch-Bench上达到开源权重类别的最先进性能，并在HLE、AIME-25、GPQA-Diamond、MedQA等推理任务中表现出强泛化能力。

Conclusion: Fathom-DeepResearch系统通过专门的搜索和合成模型，结合创新的训练方法，在复杂信息搜索任务中实现了优异的性能，能够可靠地扩展到超过20次工具调用。

Abstract: Tool-integrated reasoning has emerged as a key focus for enabling agentic
applications. Among these, DeepResearch Agents have gained significant
attention for their strong performance on complex, open-ended
information-seeking tasks. We introduce Fathom-DeepResearch, an agentic system
composed of two specialized models. The first is Fathom-Search-4B, a DeepSearch
model trained from Qwen3-4B and optimized for evidence-based investigation
through live web search and targeted webpage querying. Its training combines
three advances: (i) DUETQA, a 5K-sample dataset generated via multi-agent
self-play that enforces strict web-search dependence and heterogeneous source
grounding; (ii) RAPO, a zero-overhead extension of GRPO that stabilizes
multi-turn Reinforcement Learning with Verifiable Rewards through curriculum
pruning, reward-aware advantage scaling, and per-prompt replay buffers; and
(iii) a steerable step-level reward that classifies each tool call by cognitive
behavior and marginal utility, enabling explicit control over search trajectory
breadth, depth, and horizon. These improvements enable reliable extension of
tool-calling beyond 20 calls when warranted. The second is
Fathom-Synthesizer-4B, trained from Qwen3-4B, which converts multi-turn
DeepSearch traces into structured, citation-dense DeepResearch Reports for
comprehensive synthesis. Evaluated on DeepSearch benchmarks (SimpleQA, FRAMES,
WebWalker, Seal0, MuSiQue) and DeepResearch-Bench, the system achieves
state-of-the-art performance in the open-weights category while demonstrating
strong generalization to diverse reasoning tasks including HLE, AIME-25,
GPQA-Diamond, and MedQA.

</details>


### [208] [Transparent, Evaluable, and Accessible Data Agents: A Proof-of-Concept Framework](https://arxiv.org/abs/2509.24127)
*Nooshin Bahador*

Main category: cs.AI

TL;DR: 提出了一个模块化、基于组件的AI代理架构，用于连接自然语言界面和企业数据仓库，通过透明决策框架和自动化评估机制确保系统的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决非技术用户访问复杂数据仓库的挑战，弥合语义鸿沟，让用户能够通过对话界面与复杂数据系统交互。

Method: 采用模块化架构，包含多层推理框架、统计上下文模块和自动化评估框架，集成BigQuery生态系统进行安全数据检索和业务规则应用。

Result: 在保险理赔处理系统的案例研究中证实，该方法能够构建稳健、可评估且可信赖的LLM驱动代理系统。

Conclusion: 该集成代理开发与评估框架为数据敏感、高风险领域部署LLM驱动的代理提供了一个可靠且可解释的解决方案。

Abstract: This article presents a modular, component-based architecture for developing
and evaluating AI agents that bridge the gap between natural language
interfaces and complex enterprise data warehouses. The system directly
addresses core challenges in data accessibility by enabling non-technical users
to interact with complex data warehouses through a conversational interface,
translating ambiguous user intent into precise, executable database queries to
overcome semantic gaps. A cornerstone of the design is its commitment to
transparent decision-making, achieved through a multi-layered reasoning
framework that explains the "why" behind every decision, allowing for full
interpretability by tracing conclusions through specific, activated business
rules and data points. The architecture integrates a robust quality assurance
mechanism via an automated evaluation framework that serves multiple functions:
it enables performance benchmarking by objectively measuring agent performance
against golden standards, and it ensures system reliability by automating the
detection of performance regressions during updates. The agent's analytical
depth is enhanced by a statistical context module, which quantifies deviations
from normative behavior, ensuring all conclusions are supported by quantitative
evidence including concrete data, percentages, and statistical comparisons. We
demonstrate the efficacy of this integrated agent-development-with-evaluation
framework through a case study on an insurance claims processing system. The
agent, built on a modular architecture, leverages the BigQuery ecosystem to
perform secure data retrieval, apply domain-specific business rules, and
generate human-auditable justifications. The results confirm that this approach
creates a robust, evaluable, and trustworthy system for deploying LLM-powered
agents in data-sensitive, high-stakes domains.

</details>


### [209] [Reasoning or Retrieval? A Study of Answer Attribution on Large Reasoning Models](https://arxiv.org/abs/2509.24156)
*Yuhui Wang,Changjiang Li,Guangke Chen,Jiacheng Liang,Ting Wang*

Main category: cs.AI

TL;DR: 大型推理模型存在推理过程与最终答案不一致的问题，研究发现这是由于思维链推理和记忆检索两种机制同时作用导致的。作者提出FARL框架，通过记忆遗忘和强化学习来抑制记忆检索捷径，提升真正的推理能力。


<details>
  <summary>Details</summary>
Motivation: 发现大型推理模型的最终答案经常与自身推理过程相矛盾，假设这是由于思维链推理和记忆检索两种竞争机制导致的，需要验证这一假设并解决该问题。

Method: 通过受控实验测试误导性线索和损坏答案对模型的影响，确认两种机制同时存在。提出FARL框架，结合记忆遗忘和强化学习来抑制检索捷径。

Result: 实验结果证实思维链推理和记忆检索确实同时运作，其相对主导地位受问题领域、模型规模和微调方法影响。FARL框架能有效促进推理主导行为，提升泛化推理能力。

Conclusion: 当前推理微调范式存在关键限制，模型会利用检索机制作为捷径来"破解"奖励信号。FARL框架通过抑制检索捷径，成功提升了模型的真实推理能力。

Abstract: Large reasoning models (LRMs) exhibit unprecedented capabilities in solving
complex problems through Chain-of-Thought (CoT) reasoning. However, recent
studies reveal that their final answers often contradict their own reasoning
traces. We hypothesize that this inconsistency stems from two competing
mechanisms for generating answers: CoT reasoning and memory retrieval. To test
this hypothesis, we conduct controlled experiments that challenge LRMs with
misleading cues during reasoning and/or corrupted answers during retrieval. Our
results across models and datasets confirm that both mechanisms operate
simultaneously, with their relative dominance influenced by multiple factors:
problem domains, model scales, and fine-tuning approaches (e.g., reinforcement
learning vs. distillation). The findings reveal a critical limitation in
current reasoning fine-tuning paradigms: models can exploit the retrieval
mechanism as a shortcut, effectively "hacking" the reward signal and
undermining genuine reasoning development. To address this challenge, we
introduce FARL, a novel fine-tuning framework that integrates memory unlearning
with reinforcement learning. By carefully suppressing retrieval shortcuts
during the fine-tuning process, FARL promotes reasoning-dominant behavior and
enhances generalizable reasoning capabilities.

</details>


### [210] [Robust Preference Optimization: Aligning Language Models with Noisy Preference Feedback](https://arxiv.org/abs/2509.24159)
*Xiaoyang Cao,Zelai Xu,Mo Guang,Kaiwen Long,Michiel A. Bakker,Yu Wang,Chao Yu*

Main category: cs.AI

TL;DR: RPO是一种鲁棒偏好优化方法，通过EM算法推断标签正确性的后验概率，自适应重加权训练损失来减轻噪声，将现有对齐算法转化为鲁棒版本。


<details>
  <summary>Details</summary>
Motivation: 人类偏好具有多样性和噪声，传统RLHF方法假设偏好同质且无噪声，导致模型性能下降。

Method: 使用EM算法推断标签正确性概率，自适应重加权数据点，建立偏好损失与概率模型的联系，将现有算法转化为鲁棒版本。

Result: 在Mistral和Llama 3模型上，RPO增强的方法在AlpacaEval 2和Arena-Hard上分别获得高达7.0%和5.4%的胜率提升。

Conclusion: RPO作为一种元框架，能有效提升现有对齐算法的鲁棒性，在噪声偏好数据下表现优异。

Abstract: Standard human preference-based alignment methods, such as Reinforcement
Learning from Human Feedback (RLHF), are a cornerstone technology for aligning
Large Language Models (LLMs) with human values. However, these methods are all
underpinned by a critical, yet flawed assumption: human preferences are
homogeneous (representing a single, unified preference) and the collected data
is noiseless (free from error). In reality, neither is true since human
preference is pluralistic and annotators can make mistakes. This creates a
discrepancy between the recorded data and the ground-truth preferences, which
can misguide the model and degrade its performance. To address this challenge,
we introduce Robust Preference Optimization (RPO). RPO employs an
Expectation-Maximization (EM) algorithm to infer the posterior probability of
each label's correctness, which is used to adaptively re-weigh each data point
in the training loss to mitigate noise. We further generalize this approach by
establishing a theoretical link between arbitrary preference losses and their
corresponding probabilistic models. This generalization enables the systematic
transformation of existing alignment algorithms into their robust counterparts,
elevating RPO from a specific algorithm to a meta-framework for robust
preference alignment. Theoretically, we prove that under the condition of a
perfectly calibrated model, RPO is guaranteed to converge to the true noise
level of the dataset. Our experiments demonstrate RPO's effectiveness as a
meta-framework, consistently enhancing four state-of-the-art alignment
algorithms (DPO, IPO, SimPO, and CPO). When applied to Mistral and Llama 3
models, the RPO-enhanced methods achieve substantial win rate gains on
AlpacaEval 2 and Arena-Hard, with improvements of up to 7.0% and 5.4%,
respectively.

</details>


### [211] [Humanline: Online Alignment as Perceptual Loss](https://arxiv.org/abs/2509.24207)
*Sijia Liu,Niklas Muennighoff,Kawin Ethayarajh*

Main category: cs.AI

TL;DR: 在线对齐方法（如GRPO）通常比离线对齐方法（如DPO）表现更好，这源于人类对概率的感知偏差。通过将人类感知偏差显式融入目标函数，可以创建'humanline'变体，即使使用离线数据也能达到在线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解释为什么在线对齐方法优于离线对齐方法，从人类感知偏差的角度提供理论解释，并提出更高效灵活的训练方法。

Method: 基于前景理论，提出将人类对概率的感知偏差显式融入DPO/KTO/GRPO等目标函数中，创建'humanline'变体，允许使用离线数据进行训练。

Result: Humanline变体即使使用离线数据训练，在可验证和不可验证任务上都能达到与在线方法相当的性能。

Conclusion: 在线/离线二分法并非最大化人类效用的关键，通过显式建模人类感知偏差，可以更灵活高效地进行模型对齐训练。

Abstract: Online alignment (e.g., GRPO) is generally more performant than offline
alignment (e.g., DPO) -- but why? Drawing on prospect theory from behavioral
economics, we propose a human-centric explanation. We prove that online
on-policy sampling better approximates the human-perceived distribution of what
the model can produce, and PPO/GRPO-style clipping -- originally introduced to
just stabilize training -- recovers a perceptual bias in how humans perceive
probability. In this sense, PPO/GRPO act as perceptual losses already. Our
theory further suggests that the online/offline dichotomy is itself incidental
to maximizing human utility, since we can achieve the same effect by
selectively training on any data in a manner that mimics human perception,
rather than restricting ourselves to online on-policy data. Doing so would
allow us to post-train more quickly, cheaply, and flexibly without sacrificing
performance. To this end, we propose a design pattern that explicitly
incorporates perceptual distortions of probability into objectives like
DPO/KTO/GRPO, creating humanline variants of them. Surprisingly, we find that
these humanline variants, even when trained with offline off-policy data, can
match the performance of their online counterparts on both verifiable and
unverifiable tasks.

</details>


### [212] [ELHPlan: Efficient Long-Horizon Task Planning for Multi-Agent Collaboration](https://arxiv.org/abs/2509.24230)
*Shaobin Ling,Yun Wang,Chenyou Fan,Tin Lun Lam,Junjie Hu*

Main category: cs.AI

TL;DR: ELHPlan是一种基于动作链的LLM多机器人协作规划框架，通过意图绑定的动作序列作为规划原语，在保持任务成功率的同时将token消耗降低到现有方法的24%


<details>
  <summary>Details</summary>
Motivation: 解决LLM在多机器人协作中的基本权衡：声明式方法在动态环境中缺乏适应性，而迭代方法计算成本过高且随团队规模和任务复杂性扩展性差

Method: 提出动作链（Action Chains）作为规划原语，采用循环过程：构建意图绑定的动作序列、主动验证冲突和可行性、通过针对性机制精炼问题、执行已验证动作

Result: 在TDW-MAT和C-WAH基准测试中，ELHPlan实现了可比较的任务成功率，同时仅消耗最先进方法所需token的24%

Conclusion: ELHPlan为基于LLM的多智能体规划系统建立了新的效率-效果前沿，在适应性和效率之间取得了平衡

Abstract: Large Language Models (LLMs) enable intelligent multi-robot collaboration but
face fundamental trade-offs: declarative methods lack adaptability in dynamic
environments, while iterative methods incur prohibitive computational costs
that scale poorly with team size and task complexity. In this paper, we propose
ELHPlan, a novel framework that introduces Action Chains--sequences of actions
explicitly bound to sub-goal intentions--as the fundamental planning primitive.
ELHPlan operates via a cyclical process: 1) constructing intention-bound action
sequences, 2) proactively validating for conflicts and feasibility, 3) refining
issues through targeted mechanisms, and 4) executing validated actions. This
design balances adaptability and efficiency by providing sufficient planning
horizons while avoiding expensive full re-planning. We further propose
comprehensive efficiency metrics, including token consumption and planning
time, to more holistically evaluate multi-agent collaboration. Our experiments
on benchmark TDW-MAT and C-WAH demonstrate that ELHPlan achieves comparable
task success rates while consuming only 24% of the tokens required by
state-of-the-art methods. Our research establishes a new
efficiency-effectiveness frontier for LLM-based multi-agent planning systems.

</details>


### [213] [Learning to Ponder: Adaptive Reasoning in Latent Space](https://arxiv.org/abs/2509.24238)
*Yixin He,Lumingyuan Tang*

Main category: cs.AI

TL;DR: FR-Ponder是一个无需修改主干模型权重的推理计算分配框架，通过潜在向量引导实现实例自适应的推理深度控制，在保持精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法如Best-of-N和多数投票在所有输入上使用统一的推理深度，导致简单问题计算浪费而复杂问题推理不足。需要一种能根据问题复杂度自适应分配计算资源的方法。

Method: 使用小于1M参数的控制器观察隐藏状态，决定停止或应用小的ponder步骤。提取与深度推理输出相关的潜在引导向量，通过可调缩放因子重新应用，使模型能根据输入复杂度调整推理深度。采用GRPO作为奖励信号来平衡性能和计算成本。

Result: 在GSM8K和MATH500数据集上，FR-Ponder改善了计算-精度边界，在更低FLOPs下获得更好匹配的精度，优于早期退出基线方法。分析显示学习到的计算分配与问题难度相关。

Conclusion: FR-Ponder通过潜在引导实现了有效的实例自适应推理计算分配，无需修改主干模型权重，在数学推理任务上取得了计算效率和精度的良好平衡。

Abstract: Test-time compute has emerged as a key paradigm for enhancing LLM reasoning,
yet prevailing approaches like Best-of-N and majority voting apply uniform
depth across inputs, wasting computation on simple queries while potentially
under-thinking complex ones. We present FR-Ponder, a single-graph,
backbone-training-free framework that allocates instance-adaptive reasoning
compute via latent steering. A less than 1M-param controller observes hidden
states and decides to halt or apply a small ponder step by adding a
pre-computed steering vector to frozen representations. Our method extracts the
latent steering vector associated with deeper reasoning outputs and direct IO
from LLM and re-applies it through a tunable scaling factor, allowing the model
to adapt its reasoning depth to the complexity of each input. To balance
performance and computational cost, we employ Group Relative Policy
Optimization (GRPO) as a reward signal to adaptively regulate reasoning depth,
achieving task accuracy while mitigating overreasoning. Through curriculum
learning and careful reward engineering, FR-Ponder learns calibrated compute
allocation correlated with problem difficulty. On GSM8K and MATH500, FR-Ponder
improves the compute-accuracy frontier, delivering lower FLOPs with better
matched accuracy and comparing favorably to early-exit baselines, without
modifying backbone weights. Analyses visualize interpretable steering
directions and show learned compute allocation correlates with problem
difficulty.

</details>


### [214] [Model Merging Scaling Laws in Large Language Models](https://arxiv.org/abs/2509.24244)
*Yuanyi Wang,Yanggan Gu,Yiming Zhang,Qi Zhou,Zhaoyi Yan,Congkai Xie,Xinyao Wang,Jianbo Yuan,Hongxia Yang*

Main category: cs.AI

TL;DR: 该论文发现语言模型融合存在紧凑的幂律缩放规律：模型大小相关的损失下限随模型容量减小，而融合尾部在专家数量增加时呈现明显的收益递减。


<details>
  <summary>Details</summary>
Motivation: 尽管模型融合在实践中广泛应用，但缺乏量化规则来预测随着专家数量增加或模型规模扩大时的收益回报。

Method: 通过经验性研究语言模型融合的缩放规律，测量交叉熵，分析不同架构和方法（Average、TA、TIES、DARE）下的融合效果。

Result: 发现了一个紧凑的幂律关系，该规律在领域内和跨领域都成立，能够紧密拟合不同架构和方法的测量曲线，并解释了两个稳健规律：大部分收益早期获得，变异性随专家数量增加而减小。

Conclusion: 这一缩放规律使得融合从启发式实践转变为计算高效、可规划的替代多任务训练的方法，为分布式生成式AI提供了可预测的增益原则，为构建AGI级系统提供了补充路径。

Abstract: We study empirical scaling laws for language model merging measured by
cross-entropy. Despite its wide practical use, merging lacks a quantitative
rule that predicts returns as we add experts or scale the model size. We
identify a compact power law that links model size and expert number: the
size-dependent floor decreases with model capacity, while the merging tail
exhibits clear diminishing returns in the number of experts. The law holds
in-domain and cross-domain, tightly fits measured curves across diverse
architectures and methods (Average, TA, TIES, DARE), and explains two robust
regularities: most gains arrive early, and variability shrinks as more experts
are included. Building on this, we present a simple theory that explains why
gains fall roughly as 1/k and links the floor and tail to properties of the
base model and the diversity across domains. This law enables predictive
planning: estimate how many experts are needed to reach a target loss, decide
when to stop adding experts, and trade off scaling the base model versus adding
experts under a fixed budget--turning merging from heuristic practice into a
computationally efficient, planable alternative to multitask training. This
suggests a scaling principle for distributed generative AI: predictable gains
can be achieved by composing specialists, offering a complementary path toward
AGI-level systems.

</details>


### [215] [SpecExit: Accelerating Large Reasoning Model via Speculative Exit](https://arxiv.org/abs/2509.24248)
*Rubing Yang,Huajun Bai,Song Liu,Guanghua Yu,Runzhi Fan,Yanbin Dang,Jiejing Zhang,Kai Liu,Jianchen Zhu,Peng Chen*

Main category: cs.AI

TL;DR: 提出SpecExit框架，通过轻量级草稿模型预测未来token和提前退出信号，解决大型推理模型的过度思考问题，实现66%的生成长度减少和2.5倍端到端延迟加速。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在过度思考问题，产生不必要的长输出和高的端到端延迟，限制实际部署。现有提前退出机制依赖探测机制，引入检测开销限制延迟收益并影响跨问题泛化能力。

Method: 受推测解码中隐藏状态使用的启发，提出SpecExit框架，直接从轻量级草稿模型预测未来token和提前退出信号，无需探测开销。利用隐藏状态的固有信号提供有效的提前退出信号。

Result: 相比推测解码基线，平均生成长度减少66%，端到端延迟实现2.5倍加速，且不损害准确性。

Conclusion: 隐藏状态可用于高效推理，为大型推理模型的实时部署提供了有效解决方案。

Abstract: Despite their strong performance on reasoning tasks, large reasoning models
(LRMs) often suffer from overthinking, producing unnecessarily long outputs and
incurring high end-to-end latency, a significant limitation to their real-world
deployment. To address overthinking, early-exit mechanisms have been proposed
to terminate reasoning before typical completion, showing that this approach
can effectively shorten generation length with minimal impact on accuracy.
However, their reliance on probing mechanisms introduces a detection overhead
that limits their end-to-end latency gains and compromises their
generalizability across diverse problems. Inspired by the use of hidden states
in speculative decoding, we propose SpecExit, a novel framework that predicts
both future tokens and an early-exit signal directly from a lightweight draft
model without probing overhead. Our method offers significant improvements,
reducing average generation length by 66\% and achieving a 2.5x speedup in
end-to-end latency compared to the speculative decoding baseline, without
compromising accuracy. Our method leverages the inherent signals from hidden
states to provide effective early-exit signals, suggesting broader use of
hidden states for efficient reasoning. Our code is available at
https://github.com/Tencent/AngelSlim.

</details>


### [216] [Interactive Program Synthesis for Modeling Collaborative Physical Activities from Narrated Demonstrations](https://arxiv.org/abs/2509.24250)
*Edward Kim,Daniel He,Jorge Chao,Wiktor Rajca,Mohammed Amin,Nishant Malpani,Ruta Desai,Antti Oulasvirta,Bjoern Hartmann,Sanjit Seshia*

Main category: cs.AI

TL;DR: 提出了一个基于程序合成的协作任务学习系统，使用可编辑程序和叙述性演示（物理动作+自然语言）来教授、检查和修正系统逻辑，无需用户查看或编写代码。


<details>
  <summary>Details</summary>
Motivation: 现有HCI系统主要关注非协作物理任务，而协作任务需要系统推断用户对队友意图的假设，这是一个模糊且动态的过程，需要可解释和可修正的表示方法。

Method: 将协作任务学习构建为程序合成问题，使用可编辑程序表示行为，通过配对的物理动作和自然语言作为统一的教学、检查和修正模式。

Result: 在20名用户的多玩家足球战术教学研究中，70%参与者成功修正学习程序以匹配其意图，90%认为修正程序很容易。

Conclusion: 研究揭示了将学习表示为程序以及在协作物理活动中支持用户教学的独特挑战，并提出了相应的缓解策略。

Abstract: Teaching systems physical tasks is a long standing goal in HCI, yet most
prior work has focused on non collaborative physical activities. Collaborative
tasks introduce added complexity, requiring systems to infer users assumptions
about their teammates intent, which is an inherently ambiguous and dynamic
process. This necessitates representations that are interpretable and
correctable, enabling users to inspect and refine system behavior. We address
this challenge by framing collaborative task learning as a program synthesis
problem. Our system represents behavior as editable programs and uses narrated
demonstrations, i.e. paired physical actions and natural language, as a unified
modality for teaching, inspecting, and correcting system logic without
requiring users to see or write code. The same modality is used for the system
to communicate its learning to users. In a within subjects study, 20 users
taught multiplayer soccer tactics to our system. 70 percent (14/20) of
participants successfully refined learned programs to match their intent and 90
percent (18/20) found it easy to correct the programs. The study surfaced
unique challenges in representing learning as programs and in enabling users to
teach collaborative physical activities. We discuss these issues and outline
mitigation strategies.

</details>


### [217] [Rethinking and Benchmarking Large Language Models for Graph Reasoning](https://arxiv.org/abs/2509.24260)
*Yuwei Hu,Xinyi Huang,Zhewei Wei,Yongchao Liu,Chuntao Hong*

Main category: cs.AI

TL;DR: 该论文指出现有图推理方法的问题，提出将推理重点从复制图算法转向设计图算法，并构建了更难的GraphAlgorithm基准，提出了Simple-RTC方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM图推理方法性能不佳，原因是推理重点错误地放在复制图算法而非设计图算法上，导致基础模型能力被低估。

Method: 提出Simple-RTC方法：先引导LLM设计图算法，然后编写代码解决图推理任务。构建了包含239个不同图问题的GraphAlgorithm基准。

Result: Simple-RTC在现有基准上达到接近完美的准确率，在GraphAlgorithm基准上显著优于GPT-4o-mini和所有先前方法。

Conclusion: 重新定向推理重点能显著提升LLM图推理能力，Simple-RTC为未来LLM图推理研究提供了强有力的基线。

Abstract: Large Language Models (LLMs) for Graph Reasoning have been extensively
studied over the past two years, involving enabling LLMs to understand graph
structures and reason on graphs to solve various graph problems, with graph
algorithm problems being the most prevalent. Recent studies underscore the
potential of LLMs in handling graph reasoning tasks, but their performance is
underwhelming. In this work, we point out issues with existing methods and
benchmarks, and rethink the direction that LLMs for graph reasoning should
strive toward. We find that base models, e.g., GPT-4o-mini, are largely
underestimated due to improper reasoning focus. Base models with reasoning
focus redirected from replicating graph algorithms to designing them can easily
solve most graph reasoning tasks in existing benchmarks. To truly evaluate the
graph reasoning capabilities of LLMs, we construct a more challenging
GraphAlgorithm benchmark, comprising 239 different graph problems and 3,041
test instances collected from 4 competition platforms. Finally, we introduce a
simple and strong baseline Simple-Reasoning-Then-Coding (Simple-RTC)-which
guides LLMs to design graph algorithms first and then code to address graph
reasoning tasks. Simple-RTC achieves near-perfect accuracy on existing
benchmarks and significantly outperforms GPT-4o-mini and all prior methods on
the GraphAlgorithm benchmark. This strong baseline encourages further
advancements in LLMs for Graph Reasoning in the future.

</details>


### [218] [Risk-Sensitive RL for Alleviating Exploration Dilemmas in Large Language Models](https://arxiv.org/abs/2509.24261)
*Yuhua Jiang,Jiawei Huang,Yufeng Yuan,Xin Mao,Yu Yue,Qianchuan Zhao,Lin Yan*

Main category: cs.AI

TL;DR: 提出风险敏感强化学习框架RS-GRPO，解决RLVR方法在LLM推理任务中的探索困境，通过风险寻求目标提升多解性能(pass@k)同时保持单解精度(pass@1)。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在探索困境：预训练LLM的尖锐初始策略限制了标准RL算法的探索范围，虽然提升了单解准确率但抑制了解多样性和多解性能，导致RLVR更多是蒸馏现有能力而非发现新推理策略。

Method: 引入风险敏感强化学习框架，采用风险寻求目标在平均奖励和最大奖励之间插值，提出RS-GRPO算法，通过放大从挑战性提示中学习来驱动深度探索。

Result: 在六个数学推理基准和五个不同LLM上，RS-GRPO一致提升了pass@k性能，同时保持或增强了pass@1准确率。

Conclusion: RS-GRPO是一种简单易实现的算法，仅需少量代码修改，能有效解决RLVR的探索困境，促进LLM在复杂推理任务中探索新策略。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective
for enhancing Large Language Models (LLMs) on complex reasoning tasks. However,
existing methods suffer from an exploration dilemma: the sharply peaked initial
policies of pre-trained LLMs confine standard RL algorithms to a narrow set of
solutions, boosting single-solution accuracy (pass@1) but suppressing solution
diversity and multi-solution performance (pass@k). As a result, RLVR often
distills existing capabilities rather than discovering new reasoning
strategies. To overcome this, we introduce a Risk-Sensitive Reinforcement
Learning framework. Our approach employs a risk-seeking objective that
interpolates between mean and maximum rewards, leading to a novel algorithm,
Risk-Sensitive GRPO (RS-GRPO), which drives deeper exploration by amplifying
learning from challenging prompts. Remarkably, RS-GRPO is simple to implement,
requiring only minor code modifications. On six mathematical reasoning
benchmarks and with five different LLMs, RS-GRPO consistently improves pass@k
performance while maintaining or enhancing pass@1 accuracy.

</details>


### [219] [PAME-AI: Patient Messaging Creation and Optimization using Agentic AI](https://arxiv.org/abs/2509.24263)
*Junjie Luo,Yihong Guo,Anqi Liu,Ritu Agarwal,Gordon,Gao*

Main category: cs.AI

TL;DR: PAME-AI是一个基于智能代理AI的患者消息创建和优化系统，通过DIKW层次结构从原始数据生成可操作的消息设计策略，在医疗沟通中显著提升了患者参与度。


<details>
  <summary>Details</summary>
Motivation: 传统移动消息设计由于无法探索高维设计空间而存在显著局限性，需要更有效的方法来优化医疗沟通，提高药物依从性和健康行为。

Method: 基于DIKW层次结构构建的智能代理系统，通过专门的计算代理逐步将原始实验数据转化为可操作的消息设计策略，支持并行处理、假设验证和持续学习。

Result: 在两阶段实验中（第一阶段444,691次患者接触，第二阶段74,908次），最佳生成消息的参与率达到68.76%，相比61.27%的基线提升了12.2%的相对点击率。

Conclusion: PAME-AI的代理架构特别适合大规模医疗沟通优化，能够有效提升患者消息的参与度和效果。

Abstract: Messaging patients is a critical part of healthcare communication, helping to
improve things like medication adherence and healthy behaviors. However,
traditional mobile message design has significant limitations due to its
inability to explore the high-dimensional design space. We develop PAME-AI, a
novel approach for Patient Messaging Creation and Optimization using Agentic
AI. Built on the Data-Information-Knowledge-Wisdom (DIKW) hierarchy, PAME-AI
offers a structured framework to move from raw data to actionable insights for
high-performance messaging design. PAME-AI is composed of a system of
specialized computational agents that progressively transform raw experimental
data into actionable message design strategies. We demonstrate our approach's
effectiveness through a two-stage experiment, comprising of 444,691 patient
encounters in Stage 1 and 74,908 in Stage 2. The best-performing generated
message achieved 68.76% engagement compared to the 61.27% baseline,
representing a 12.2\% relative improvement in click-through rates. This agentic
architecture enables parallel processing, hypothesis validation, and continuous
learning, making it particularly suitable for large-scale healthcare
communication optimization.

</details>


### [220] [AdvChain: Adversarial Chain-of-Thought Tuning for Robust Safety Alignment of Large Reasoning Models](https://arxiv.org/abs/2509.24269)
*Zihao Zhu,Xinyu Wu,Gehan Hu,Siwei Lyu,Ke Xu,Baoyuan Wu*

Main category: cs.AI

TL;DR: AdvChain：一种通过对抗性思维链调优来教授模型动态自我纠正的对齐范式，解决思维链推理中的雪球效应问题


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在思维链推理中面临新的安全挑战，现有安全调优方法存在雪球效应问题，即微小的推理偏差会在思维过程中逐步放大，导致有害服从或过度拒绝

Method: 构建包含诱惑-纠正和犹豫-纠正样本的数据集，通过对抗性思维链调优教授模型从有害推理漂移和不必要谨慎中恢复的能力

Result: AdvChain显著增强了对越狱攻击和思维链劫持的鲁棒性，同时大幅减少了良性提示上的过度拒绝，在不损害推理能力的情况下实现了优越的安全-效用平衡

Conclusion: 这项工作为构建更鲁棒可靠的推理模型确立了新方向

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in
complex problem-solving through Chain-of-Thought (CoT) reasoning. However, the
multi-step nature of CoT introduces new safety challenges that extend beyond
conventional language model alignment. We identify a failure mode in current
safety CoT tuning methods: the \textit{snowball effect}, where minor reasoning
deviations progressively amplify throughout the thought process, leading to
either harmful compliance or excessive refusal. This effect stems from models
being trained to imitate perfect reasoning scripts without learning to
self-correct. To address this limitation, we propose AdvChain, an alignment
paradigm that teaches models dynamic self-correction through adversarial CoT
tuning. Our method involves constructing a dataset containing
Temptation-Correction and Hesitation-Correction samples, where models learn to
recover from harmful reasoning drifts and unnecessary cautions. Extensive
experiments show that AdvChain significantly enhances robustness against
jailbreak attacks and CoT hijacking while substantially reducing over-refusal
on benign prompts, achieving a superior safety-utility balance without
compromising reasoning capabilities. Our work establishes a new direction for
building more robust and reliable reasoning models.

</details>


### [221] [G-reasoner: Foundation Models for Unified Reasoning over Graph-structured Knowledge](https://arxiv.org/abs/2509.24276)
*Linhao Luo,Zicheng Zhao,Junnan Liu,Zhangchi Qiu,Junnan Dong,Serge Panev,Chen Gong,Thuy-Trang Vu,Gholamreza Haffari,Dinh Phung,Alan Wee-Chung Liew,Shirui Pan*

Main category: cs.AI

TL;DR: G-reasoner是一个统一框架，通过QuadGraph标准化图表示和34M参数的图基础模型(GFM)，将图结构与语言模型集成，显著提升LLM在图结构化知识上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成(RAG)方法在处理知识密集型任务时面临信息碎片化和知识结构建模不足的问题，而图增强RAG方法存在图设计随意、启发式搜索和成本高昂等可扩展性和泛化性挑战。

Method: 提出QuadGraph四层抽象统一异构知识源，构建34M参数的图基础模型(GFM)联合捕捉图拓扑和文本语义，并与LLM集成增强推理，采用混合精度训练和分布式消息传递实现可扩展性。

Result: 在六个基准测试上的广泛实验表明，G-reasoner持续优于最先进的基线方法，显著增强LLM推理能力，并实现了强大的效率和跨图泛化能力。

Conclusion: G-reasoner通过统一图与语言基础模型，为图结构化知识推理提供了一个高效、可扩展且泛化能力强的解决方案，解决了现有图增强RAG方法的局限性。

Abstract: Large language models (LLMs) excel at complex reasoning but remain limited by
static and incomplete parametric knowledge. Retrieval-augmented generation
(RAG) mitigates this by incorporating external knowledge, yet existing RAGs
struggle with knowledge-intensive tasks due to fragmented information and weak
modeling of knowledge structure. Graphs offer a natural way to model
relationships within knowledge, but LLMs are inherently unstructured and cannot
effectively reason over graph-structured data. Recent graph-enhanced RAG
(GraphRAG) attempts to bridge this gap by constructing tailored graphs and
enabling LLMs to reason on them. However, these methods often depend on ad-hoc
graph designs, heuristic search, or costly agent pipelines, which hinder
scalability and generalization. To address these challenges, we present
G-reasoner, a unified framework that integrates graph and language foundation
models for reasoning over diverse graph-structured knowledge. Central to our
approach is QuadGraph, a standardized four-layer abstraction that unifies
heterogeneous knowledge sources into a common graph representation. Building on
this, we introduce a 34M-parameter graph foundation model (GFM) that jointly
captures graph topology and textual semantics, and is integrated with LLMs to
enhance reasoning in downstream applications. To ensure scalability and
efficiency, mixed-precision training and distributed message-passing are
implemented to scale GFM with more GPUs. Extensive experiments on six
benchmarks show that G-reasoner consistently outperforms state-of-the-art
baselines, significantly enhances LLM reasoning, and achieves strong efficiency
and cross-graph generalization.

</details>


### [222] [SCI-Verifier: Scientific Verifier with Thinking](https://arxiv.org/abs/2509.24285)
*Shenghe Zheng,Chenyu Huang,Fangchen Yu,Junchi Yao,Jingqi Ye,Tao Chen,Yun Luo,Ning Ding,LEI BAI,Ganqu Cui,Peng Ye*

Main category: cs.AI

TL;DR: 提出了SCI-VerifyBench跨学科验证基准和SCI-Verifier推理增强验证器，解决科学领域LLM答案验证的挑战，包括缺乏系统评估标准和过度依赖规则设计的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在科学推理中的应用增加，答案格式复杂性和表达多样性使得答案验证成为关键但具有挑战性的任务。现有研究存在缺乏系统评估标准、学科覆盖不足，以及过度依赖规则设计或提示工程的问题。

Method: 在数据层面构建SCI-VerifyBench跨学科基准，覆盖数学、物理、生物、化学和通用科学QA，基于真实LLM响应并通过领域特定等价变换生成挑战性数据。在模型层面提出SCI-Verifier推理增强验证器，通过后训练获得逻辑推理和等价判断能力。

Result: SCI-VerifyBench通过模型和专家标注确保质量和多样性，支持严格验证能力评估。SCI-Verifier展现出强大的逻辑推理和等价判断能力，同时保持简洁稳定的输出。

Conclusion: SCI-VerifyBench和SCI-Verifier为科学验证提供了原则性框架，既提供系统评估方法，又增强了LLM在科学领域的可靠性和适用性。

Abstract: As large language models (LLMs) are increasingly applied to scientific
reasoning, the complexity of answer formats and the diversity of equivalent
expressions make answer verification a critical yet challenging task. Existing
verification studies in scientific domains suffer from two major limitations:
(a) the absence of systematic evaluation standards and insufficient
disciplinary coverage, which hinders their comprehensive assessment; and (b)
heavy reliance on cumbersome rule design or prompt engineering, which reduces
their effectiveness in complex reasoning scenarios or limits their
cross-disciplinary generalization. To address these challenges, we propose
solutions at both the data and model levels. On the data side, we construct
SCI-VerifyBench, a cross-disciplinary benchmark covering mathematics, physics,
biology, chemistry, and general scientific QA. The benchmark is built from real
LLM responses and enhanced with domain-specific equivalence transformations
that generate challenging and realistic data. Model-based and expert
annotations ensure both quality and diversity, enabling rigorous evaluation of
verification ability. On the model side, we emphasize the importance of
reasoning for verification and introduce SCI-Verifier, a unified
reasoning-augmented verifier for scientific domains. Through post-training,
SCI-Verifier demonstrates strong logical reasoning and equivalence judgment
capabilities while maintaining concise and stable outputs. Together,
SCI-VerifyBench and SCI-Verifier provide a principled framework for scientific
verification, offering both systematic evaluation and practical pathways to
enhance the reliability and applicability of LLMs in scientific domains.

</details>


### [223] [Experience Paper: Adopting Activity Recognition in On-demand Food Delivery Business](https://arxiv.org/abs/2509.24303)
*Huatao Xu,Yan Zhang,Wei Gao,Guobin Shen,Mo Li*

Main category: cs.AI

TL;DR: 首次在全国范围内部署基于LIMU-BERT模型的人类活动识别技术于外卖配送行业，覆盖50万骑手和367个城市，展示了显著的操作和经济效益。


<details>
  <summary>Details</summary>
Motivation: 探索人类活动识别技术在真实世界应用中的潜力，特别是在外卖配送行业的大规模部署可行性。

Method: 采用最先进的LIMU-BERT基础模型进行适配，分三个阶段在两年内从扬州试点扩展到全国部署。

Result: 成功实现全国范围部署，涉及50万骑手和367个城市，并开源了基于数百万小时传感器数据预训练的LIMU-BERT模型。

Conclusion: 该部署展示了HAR技术在现实应用中的变革潜力，并为类似大规模部署提供了宝贵经验和开源资源。

Abstract: This paper presents the first nationwide deployment of human activity
recognition (HAR) technology in the on-demand food delivery industry. We
successfully adapted the state-of-the-art LIMU-BERT foundation model to the
delivery platform. Spanning three phases over two years, the deployment
progresses from a feasibility study in Yangzhou City to nationwide adoption
involving 500,000 couriers across 367 cities in China. The adoption enables a
series of downstream applications, and large-scale tests demonstrate its
significant operational and economic benefits, showcasing the transformative
potential of HAR technology in real-world applications. Additionally, we share
lessons learned from this deployment and open-source our LIMU-BERT pretrained
with millions of hours of sensor data.

</details>


### [224] [MedMMV: A Controllable Multimodal Multi-Agent Framework for Reliable and Verifiable Clinical Reasoning](https://arxiv.org/abs/2509.24314)
*Hongjun Liu,Yinghao Zhu,Yuhui Wang,Yitao Long,Zeyu Lai,Lequan Yu,Chen Zhao*

Main category: cs.AI

TL;DR: 提出了MedMMV框架，通过多智能体系统稳定临床推理过程，减少幻觉并提高可靠性


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在医疗诊断中存在早期证据解释不稳定导致幻觉的问题，需要可审计的临床推理系统

Method: MedMMV采用可控多模态多智能体框架，通过多样化短轨迹、结构化证据图和幻觉检测器来稳定推理过程

Result: 在六个医疗基准测试中准确率提升达12.7%，盲法医师评估证实推理真实性显著提高

Conclusion: 通过可验证的多智能体过程控制不稳定性，为高风险领域部署可信AI系统提供了稳健路径

Abstract: Recent progress in multimodal large language models (MLLMs) has demonstrated
promising performance on medical benchmarks and in preliminary trials as
clinical assistants. Yet, our pilot audit of diagnostic cases uncovers a
critical failure mode: instability in early evidence interpretation precedes
hallucination, creating branching reasoning trajectories that cascade into
globally inconsistent conclusions. This highlights the need for clinical
reasoning agents that constrain stochasticity and hallucination while producing
auditable decision flows. We introduce MedMMV, a controllable multimodal
multi-agent framework for reliable and verifiable clinical reasoning. MedMMV
stabilizes reasoning through diversified short rollouts, grounds intermediate
steps in a structured evidence graph under the supervision of a Hallucination
Detector, and aggregates candidate paths with a Combined Uncertainty scorer. On
six medical benchmarks, MedMMV improves accuracy by up to 12.7% and, more
critically, demonstrates superior reliability. Blind physician evaluations
confirm that MedMMV substantially increases reasoning truthfulness without
sacrificing informational content. By controlling instability through a
verifiable, multi-agent process, our framework provides a robust path toward
deploying trustworthy AI systems in high-stakes domains like clinical decision
support.

</details>


### [225] [humancompatible.detect: a Python Toolkit for Detecting Bias in AI Models](https://arxiv.org/abs/2509.24340)
*German M. Matilla,Jiri Nemecek,Illia Kryvoviaz,Jakub Marecek*

Main category: cs.AI

TL;DR: 开发了一个名为humancompatible.detect的偏差检测工具包，解决了传统方法在可扩展性和可计算性方面的挑战，包含最大子组差异和子采样ℓ∞距离两种新方法。


<details>
  <summary>Details</summary>
Motivation: 国际法规要求对高风险AI系统测量输入数据质量和估计输出偏差，但传统方法存在可扩展性和可计算性问题。

Method: 开发了humancompatible.detect工具包，包含最大子组差异(MSD)和子采样ℓ∞距离两种新方法，提供易于使用的API。

Result: 该工具包解决了传统MMD和Wasserstein-1距离方法在可扩展性和可计算性方面的限制。

Conclusion: humancompatible.detect是一个开源的偏差检测工具包，采用Apache 2.0许可证，为AI系统的偏差检测提供了实用的解决方案。

Abstract: There is a strong recent emphasis on trustworthy AI. In particular,
international regulations, such as the AI Act, demand that AI practitioners
measure data quality on the input and estimate bias on the output of high-risk
AI systems. However, there are many challenges involved, including scalability
(MMD) and computability (Wasserstein-1) issues of traditional methods for
estimating distances on measure spaces. Here, we present
humancompatible.detect, a toolkit for bias detection that addresses these
challenges. It incorporates two newly developed methods to detect and evaluate
bias: maximum subgroup discrepancy (MSD) and subsampled $\ell_\infty$
distances. It has an easy-to-use API documented with multiple examples.
humancompatible.detect is licensed under the Apache License, Version 2.0.

</details>


### [226] [Fin-Ally: Pioneering the Development of an Advanced, Commonsense-Embedded Conversational AI for Money Matters](https://arxiv.org/abs/2509.24342)
*Sarmistha Das,Priya Mathur,Ishani Sharma,Sriparna Saha,Kitsuchart Pasupa,Alka Maurya*

Main category: cs.AI

TL;DR: Fin-Solution 2.O是一个先进的金融科技解决方案，包含Fin-Vault多轮金融对话数据集和Fin-Ally统一模型，通过常识推理和人类对齐优化生成专业的金融建议。


<details>
  <summary>Details</summary>
Motivation: 解决FinTech行业LLMs大规模微调可能产生不专业或轻率言论的问题，以及领域特定数据稀缺导致的研究空白。

Method: 引入Fin-Vault数据集（1,417个标注多轮对话），开发Fin-Ally模型，整合常识推理、礼貌性和人类对话动态，使用COMET-BART嵌入常识上下文并通过DPO机制优化。

Result: 结合常识上下文使语言模型能够生成更精细、文本精确且专业基础的金融指导，超越基本账户管理，提供个性化预算、实时费用跟踪和自动财务规划。

Conclusion: 该方法作为FinTech领域的下一代AI解决方案，通过整合常识推理和人类对齐优化，显著提升了金融咨询的专业性和用户信任度。

Abstract: The exponential technological breakthrough of the FinTech industry has
significantly enhanced user engagement through sophisticated advisory chatbots.
However, large-scale fine-tuning of LLMs can occasionally yield unprofessional
or flippant remarks, such as ``With that money, you're going to change the
world,'' which, though factually correct, can be contextually inappropriate and
erode user trust. The scarcity of domain-specific datasets has led previous
studies to focus on isolated components, such as reasoning-aware frameworks or
the enhancement of human-like response generation. To address this research
gap, we present Fin-Solution 2.O, an advanced solution that 1) introduces the
multi-turn financial conversational dataset, Fin-Vault, and 2) incorporates a
unified model, Fin-Ally, which integrates commonsense reasoning, politeness,
and human-like conversational dynamics. Fin-Ally is powered by
COMET-BART-embedded commonsense context and optimized with a Direct Preference
Optimization (DPO) mechanism to generate human-aligned responses. The novel
Fin-Vault dataset, consisting of 1,417 annotated multi-turn dialogues, enables
Fin-Ally to extend beyond basic account management to provide personalized
budgeting, real-time expense tracking, and automated financial planning. Our
comprehensive results demonstrate that incorporating commonsense context
enables language models to generate more refined, textually precise, and
professionally grounded financial guidance, positioning this approach as a
next-generation AI solution for the FinTech sector. Dataset and codes are
available at: https://github.com/sarmistha-D/Fin-Ally

</details>


### [227] [From Static to Dynamic: Adaptive Monte Carlo Search for Mathematical Process Supervision](https://arxiv.org/abs/2509.24351)
*Jie Ma,Shihao Qi,Rui Xing,Ziang Yin,Bifan Wei,Jun Liu,Tongliang Liu*

Main category: cs.AI

TL;DR: 提出了自适应蒙特卡洛搜索（AMCS）框架，用于高效生成过程监督数据来训练过程奖励模型（PRM），在数学推理任务上显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法基于固定预算采样策略估计推理步骤质量，在自动数据生成过程中需要遍历巨大搜索空间进行路径扩展，导致效率低下且缺乏灵活性。

Method: AMCS框架在节点值估计和路径扩展层面将数据生成从固定静态搜索转变为自适应动态搜索：自适应细化估计（为不确定推理步骤分配更多样本），以及通过具有时间自适应策略的蒙特卡洛算法增强路径扩展（从广泛探索逐渐转向利用最有希望的方向）。

Result: 构建了包含约20万过程监督示例的大规模数据集MathSearch-200K。在四个数学推理基准测试中，Qwen2.5-Math-7B-PRM-AMCS在MATH500上达到76.2%准确率，超过所有基线PRM。7B模型在AMCS监督下性能超过72B模型。

Conclusion: AMCS方法在数学推理任务上表现出显著优势，并在分布外问题上保持一致的性能优势，展示了强大的泛化能力。

Abstract: The quality of process data plays a key role in training a Process Reward
Model (PRM), which can enhance the complex mathematical reasoning capability of
large language models. Existing methods estimate the quality of reasoning steps
based on a fixed-budget sampling strategy and navigate a vast search space to
perform path expansion during the automated data generation process, resulting
in their inefficiency and inflexibility. To address these issues, we propose
Adaptive Monte Carlo Search (AMCS), a framework that transforms data generation
from fixed, static to adaptive, dynamic search at the level of node value
estimation and path expansion. On one hand, AMCS adaptively refines estimation
by allocating more samples to uncertain reasoning steps while using fewer
samples for those that are easier to estimate. On the other hand, it enhances
the path expansion through a Monte Carlo algorithm with a temporally adaptive
policy that begins with broad exploration and gradually shifts toward
exploiting the most promising directions. With AMCS, we construct a large-scale
dataset MathSearch-200K of about 200K process supervision examples for training
PRMs. To verify the effectiveness of our method, we conduct extensive
experiments on four mathematical reasoning benchmarks. Experimental results
show that Qwen2.5-Math-7B-PRM-AMCS achieves up to 76.2% accuracy on MATH500
with GLM-4-9B, outperforming all baseline PRMs. Notably, a 7B model supervised
by Qwen2.5-Math-7B-PRM-AMCS surpasses a 72B model with weaker supervision.
Moreover, Qwen2.5-Math-7B-PRM-AMCS maintains consistent advantages on
out-of-distribution problems, demonstrating strong generalization capability.
Our code is available at https://github.com/reml-group/AMCS.

</details>


### [228] [Plan before Solving: Problem-Aware Strategy Routing for Mathematical Reasoning with LLMs](https://arxiv.org/abs/2509.24377)
*Shihao Qi,Jie Ma,Ziang Yin,Lingling Zhang,Jian Zhang,Jun Liu,Feng Tian,Tongliang Liu*

Main category: cs.AI

TL;DR: PRISM框架将数学推理分为策略规划和目标执行两个阶段，通过轻量级策略适配器动态选择最优推理策略，在多个数学推理基准测试中表现优于单一策略和集成方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用固定策略进行数学推理，无法适应问题特定需求，忽视了效果与效率之间的权衡。

Method: 提出PRISM框架，首先构建多策略偏好数据集MathStrat，然后训练策略适配器获得四种推理策略的置信度分布，在推理时通过自适应路由策略动态选择推理方法。

Result: 在五个数学推理基准测试中，PRISM始终优于单一策略和集成基线，在不同基础模型上实现了0.9%到7.6%的改进。

Conclusion: 自适应路由方法对跨不同模型架构的数学推理任务显示出特别强的优势，PRISM框架有效解决了单一策略无法适应问题特定需求的问题。

Abstract: Existing methods usually leverage a fixed strategy, such as natural language
reasoning, code-augmented reasoning, tool-integrated reasoning, or
ensemble-based reasoning, to guide Large Language Models (LLMs) to perform
mathematical reasoning. Our analysis reveals that the single strategy cannot
adapt to problem-specific requirements and thus overlooks the trade-off between
effectiveness and efficiency. To address these issues, we propose Planning and
Routing through Instance-Specific Modeling (PRISM), a novel framework that
decouples mathematical reasoning into two stages: strategy planning and
targeted execution. Specifically, we first curate a multi-strategy preference
dataset, which we call MathStrat, capturing correctness, process quality, and
computational efficiency for each problem--strategy pair. Then, we train a
lightweight Strategy Adapter based on the dataset to obtain confidence
distributions over the mentioned four reasoning strategies. At inference time,
an adaptive routing policy dynamically tailors the reasoning approach based on
predictor confidence. It directs the model to use single-strategy execution for
high-confidence predictions, dual-strategy verification for competitive
scenarios, or comprehensive multi-strategy exploration for uncertain cases.
Extensive experiments across five mathematical reasoning benchmarks demonstrate
that PRISM consistently outperforms individual strategies and ensemble
baselines, achieving improvements ranging from 0.9% to 7.6% across different
base models. The adaptive routing approach shows particularly strong benefits
for mathematical reasoning tasks across diverse model architectures. Our code
is released at https://github.com/reml-group/PRISM.

</details>


### [229] [Towards Safe Reasoning in Large Reasoning Models via Corrective Intervention](https://arxiv.org/abs/2509.24393)
*Yichi Zhang,Yue Ding,Jingwen Yang,Tianwei Luo,Dongbai Li,Ranjie Duan,Qiang Liu,Hang Su,Yinpeng Dong,Jun Zhu*

Main category: cs.AI

TL;DR: 该论文提出了一种名为IPO的干预偏好优化方法，通过替换合规步骤为安全触发器来增强大型推理模型在推理过程中的安全性，显著降低了有害内容，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了推理过程本身的安全性，导致即使最终回答安全，推理链中仍可能包含有害内容，这会影响模型的可信度并带来潜在风险。

Method: 提出了Intervened Preference Optimization (IPO)方法，通过分析安全推理的特征，替换合规步骤为安全触发器，并构建具有强信号的偏好学习对。

Result: 在越狱和对抗性安全基准测试中，IPO显著提高了推理和响应的整体安全性，有害性相对降低超过30%，同时在各种推理任务中保持优秀性能。

Conclusion: 研究强调了推理过程显式对齐的重要性，为构建更安全的大型推理模型提供了实用路径。

Abstract: Although Large Reasoning Models (LRMs) have progressed in solving complex
problems, their chain-of-thought (CoT) reasoning often contains harmful content
that can persist even when the final responses appear safe. We show that this
issue still remains in existing methods which overlook the unique significance
of safe reasoning, undermining their trustworthiness and posing potential risks
in applications if unsafe reasoning is accessible for and exploited by
malicious users. We therefore shift our focus to aligning the safety of
reasoning itself in this paper and explore process supervision as the solution.
However, simply rewarding safe reasoning proves inadequate due to low rollout
diversity and limited training signals. To tackle this challenge, we first
delve into the characteristics of safe reasoning and uncover several critical
insights that 1) safe reasoning is often consolidated by a few critical steps
of safety triggers; 2) compliance cues strongly correlate with unsafe
continuations; and 3) corrective interventions reliably steer unsafe
trajectories towards safer traces. Motivated by these, we propose Intervened
Preference Optimization (IPO), an alignment method that enforces safe reasoning
by substituting compliance steps with safety triggers and constructing pairs
for preference learning with strong signals. Experiments on jailbreak and
adversarial safety benchmarks demonstrate that IPO remarkably improves overall
safety regarding both reasoning and responses, outperforming SFT-based and
RL-based baselines with a relative reduction of over 30% in harmfulness, while
preserving excellent performance across diverse reasoning tasks. The results
highlight the importance of explicit alignment for reasoning and provide a
practical path to safer LRMs.

</details>


### [230] [ContextPRM: Leveraging Contextual Coherence for multi-domain Test-Time Scaling](https://arxiv.org/abs/2509.24460)
*Haotian Zhang,Liu Liu,Baosheng Yu,Jiayan Qiu,Likang Xiao,Yanwei Ren,Quan Chen,Xianglong Liu*

Main category: cs.AI

TL;DR: 提出ContextPRM方法，通过关注思维链步骤间的上下文连贯性，将过程奖励模型从验证领域知识转向建模领域无关的逻辑流程，显著提升了在非数学领域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型在数学领域表现优异，但由于缺乏领域特定训练数据和基于知识的学习模式，在其他领域的泛化能力有限。

Method: 采用新的数据标注和训练框架，专注于建模思维链步骤间的上下文连贯性，而非验证领域特定知识。

Result: 在MMLU-Pro的九个非数学领域（法律、历史、哲学等）中，ContextPRM通过加权多数投票实现了6.5%的平均准确率提升，显著优于其他数学导向的PRM模型。

Conclusion: 通过关注逻辑流程而非领域知识，ContextPRM在数学和非数学领域都表现出色，证明了该方法在提升模型跨领域泛化能力方面的有效性。

Abstract: Process reward models (PRMs) have demonstrated significant efficacy in
enhancing the mathematical reasoning capabilities of large language models
(LLMs) by leveraging test-time scaling (TTS). However, while most PRMs exhibit
substantial gains in mathematical domains, the scarcity of domain-specific
training data and knowledge-based learning patterns limits their generalization
ability when faced with other domains. To address this limitation, we shift the
learning objective from verifying domain-specific knowledge to modeling
domain-agnostic logical flow. Centering on contextual coherence between
chain-of-thought (CoT) steps, our approach is realized through a novel data
annotation and training framework, which enhances the model's generalization
capabilities across diverse domains. For instance, our resulting model,
ContextPRM, achieves a notable 6.5% average accuracy improvement over the
majority voting baseline via weighted majority voting across nine
non-mathematical domains in MMLU-Pro, including law, history, and philosophy,
significantly surpassing the 2.2% improvement from VersaPRM and 0.5% gains from
other mathematics-focused PRMs, demonstrating consistent performance across
both mathematical and non-mathematical domains.

</details>


### [231] [Overcoming Over-Fitting in Constraint Acquisition via Query-Driven Interactive Refinement](https://arxiv.org/abs/2509.24489)
*Vasileios Balafas,Dimos Tsouros,Nikolaos Ploskas,Kostas Stergiou*

Main category: cs.AI

TL;DR: 提出了一种混合约束获取框架，结合被动学习和主动查询，通过概率置信度识别过拟合约束，在有限数据下实现高模型覆盖率和准确性


<details>
  <summary>Details</summary>
Motivation: 解决约束获取中的过拟合问题：被动方法在有限数据下容易学习到虚假的全局约束，而纯主动方法查询成本过高

Method: 集成被动学习生成候选约束，基于机器学习先验的概率置信度进行交互式精炼，识别过拟合约束，通过子集探索机制从被拒绝候选中恢复有效子结构，最后进行主动学习确保模型完整性

Result: 在多样化基准测试中，交互式精炼阶段对实现高目标模型覆盖率和整体模型准确性至关重要，且查询复杂度可控

Conclusion: 该框架在数据有限场景下实现了稳健且实用的约束获取，是约束获取领域的重要进展

Abstract: Manual modeling in Constraint Programming is a substantial bottleneck, which
Constraint Acquisition (CA) aims to automate. However, passive CA methods are
prone to over-fitting, often learning models that include spurious global
constraints when trained on limited data, while purely active methods can be
query-intensive. We introduce a hybrid CA framework specifically designed to
address the challenge of over-fitting in CA. Our approach integrates passive
learning for initial candidate generation, a query-driven interactive
refinement phase that utilizes probabilistic confidence scores (initialized by
machine learning priors) to systematically identify over-fitted constraints,
and a specialized subset exploration mechanism to recover valid substructures
from rejected candidates. A final active learning phase ensures model
completeness. Extensive experiments on diverse benchmarks demonstrate that our
interactive refinement phase is crucial for achieving high target model
coverage and overall model accuracy from limited examples, doing so with
manageable query complexity. This framework represents a substantial
advancement towards robust and practical constraint acquisition in data-limited
scenarios.

</details>


### [232] [Neuroplasticity-inspired dynamic ANNs for multi-task demand forecasting](https://arxiv.org/abs/2509.24495)
*Mateusz Żarski,Sławomir Nowaczyk*

Main category: cs.AI

TL;DR: 提出了Neuroplastic Multi-Task Network (NMT-Net)，一种用于多任务需求预测的动态人工神经网络方法，通过训练期间的计算图结构适应性实现神经可塑性。


<details>
  <summary>Details</summary>
Motivation: 传统方法主要关注推理时动态性或计算效率，而该方法受生物系统中神经可塑性的启发，旨在实现训练期间的结构适应性。

Method: 每个新任务触发动态网络适应，包括基于相似性的任务识别和候选ANN头的选择性训练，然后根据性能评估并集成到模型中。

Result: 在三个真实世界多任务需求预测数据集上评估，相比传统基线和最先进的多任务学习方法，实现了更低的RMSE和标准差。

Conclusion: NMT-Net为时间序列预测中的多任务和持续学习提供了可扩展、适应性强的解决方案。

Abstract: This paper introduces a novel approach to Dynamic Artificial Neural Networks
(D-ANNs) for multi-task demand forecasting called Neuroplastic Multi-Task
Network (NMT-Net). Unlike conventional methods focusing on inference-time
dynamics or computational efficiency, our proposed method enables structural
adaptability of the computational graph during training, inspired by
neuroplasticity as seen in biological systems. Each new task triggers a dynamic
network adaptation, including similarity-based task identification and
selective training of candidate ANN heads, which are then assessed and
integrated into the model based on their performance. We evaluated our
framework using three real-world multi-task demand forecasting datasets from
Kaggle. We demonstrated its superior performance and consistency, achieving
lower RMSE and standard deviation compared to traditional baselines and
state-of-the-art multi-task learning methods. NMT-Net offers a scalable,
adaptable solution for multi-task and continual learning in time series
prediction. The complete code for NMT-Net is available from our GitHub
repository.

</details>


### [233] [Experience-guided reflective co-evolution of prompts and heuristics for automatic algorithm design](https://arxiv.org/abs/2509.24509)
*Yihong Liu,Junyi Li,Wayne Xin Zhao,Hongyu Lu,Ji-Rong Wen*

Main category: cs.AI

TL;DR: 提出EvoPH框架，结合岛屿迁移模型和精英选择算法，共同进化提示和启发式算法，以解决传统组合优化方法容易陷入局部最优的问题。


<details>
  <summary>Details</summary>
Motivation: 传统组合优化问题需要大量领域专业知识和手工设计的启发式算法，现有基于LLM的方法容易陷入局部最优。

Method: EvoPH框架整合岛屿迁移模型和精英选择算法，共同进化提示和启发式算法，通过性能反馈指导进化过程。

Result: 在旅行商问题和装箱问题上，EvoPH相比最优解获得了最低的相对误差。

Conclusion: EvoPH推进了基于LLM的自动算法设计领域，能够有效避免局部最优问题。

Abstract: Combinatorial optimization problems are traditionally tackled with
handcrafted heuristic algorithms, which demand extensive domain expertise and
significant implementation effort. Recent progress has highlighted the
potential of automatic heuristics design powered by large language models
(LLMs), enabling the automatic generation and refinement of heuristics. These
approaches typically maintain a population of heuristics and employ LLMs as
mutation operators to evolve them across generations. While effective, such
methods often risk stagnating in local optima. To address this issue, we
propose the Experience-Guided Reflective Co-Evolution of Prompt and Heuristics
(EvoPH) for automatic algorithm design, a novel framework that integrates the
island migration model with the elites selection algorithm to simulate diverse
heuristics populations. In EvoPH, prompts are co-evolved with heuristic
algorithms, guided by performance feedback. We evaluate our framework on two
problems, i.e., Traveling Salesman Problem and Bin Packing Problem.
Experimental results demonstrate that EvoPH achieves the lowest relative error
against optimal solutions across both datasets, advancing the field of
automatic algorithm design with LLMs.

</details>


### [234] [Training Agents Inside of Scalable World Models](https://arxiv.org/abs/2509.24527)
*Danijar Hafner,Wilson Yan,Timothy Lillicrap*

Main category: cs.AI

TL;DR: Dreamer 4是一个可扩展的智能体，通过在世界模型中进行强化学习来解决控制任务，在Minecraft中首次实现了仅从离线数据获取钻石的成就。


<details>
  <summary>Details</summary>
Motivation: 先前世界模型无法准确预测复杂环境中的物体交互，需要开发能够从离线数据学习并在想象中训练行为的智能体，这在机器人学等实际应用中具有重要意义。

Method: 使用快捷强制目标和高效Transformer架构构建快速准确的世界模型，从少量数据学习通用动作条件，从多样化无标签视频中提取知识，在想象中训练行为。

Result: 在Minecraft中，世界模型准确预测物体交互和游戏机制，大幅超越先前模型；Dreamer 4成为首个仅从离线数据获得钻石的智能体，无需环境交互。

Conclusion: 这项工作为想象训练提供了可扩展的方法，标志着向智能代理迈出的重要一步。

Abstract: World models learn general knowledge from videos and simulate experience for
training behaviors in imagination, offering a path towards intelligent agents.
However, previous world models have been unable to accurately predict object
interactions in complex environments. We introduce Dreamer 4, a scalable agent
that learns to solve control tasks by reinforcement learning inside of a fast
and accurate world model. In the complex video game Minecraft, the world model
accurately predicts object interactions and game mechanics, outperforming
previous world models by a large margin. The world model achieves real-time
interactive inference on a single GPU through a shortcut forcing objective and
an efficient transformer architecture. Moreover, the world model learns general
action conditioning from only a small amount of data, allowing it to extract
the majority of its knowledge from diverse unlabeled videos. We propose the
challenge of obtaining diamonds in Minecraft from only offline data, aligning
with practical applications such as robotics where learning from environment
interaction can be unsafe and slow. This task requires choosing sequences of
over 20,000 mouse and keyboard actions from raw pixels. By learning behaviors
in imagination, Dreamer 4 is the first agent to obtain diamonds in Minecraft
purely from offline data, without environment interaction. Our work provides a
scalable recipe for imagination training, marking a step towards intelligent
agents.

</details>


### [235] [BPMN Assistant: An LLM-Based Approach to Business Process Modeling](https://arxiv.org/abs/2509.24592)
*Josip Tomo Licardo,Nikola Tankovic,Darko Etinger*

Main category: cs.AI

TL;DR: BPMN Assistant是一个利用大语言模型通过自然语言创建和编辑BPMN图的工具，使用专门的JSON表示来提高流程修改的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提供更可靠和高效的BPMN图创建和编辑方式，避免直接处理XML的复杂性。

Method: 引入专门的JSON表示作为XML的结构化替代方案，使用图编辑距离和相对图编辑距离评估生成质量，使用二元成功指标评估编辑性能。

Result: JSON和XML在生成方面获得相似的相似度分数，但JSON提供更高的可靠性、更快的处理速度和显著更高的编辑成功率。

Conclusion: JSON表示在BPMN图编辑中比XML更可靠和高效，讨论了关键权衡、局限性和未来改进方向。

Abstract: This paper presents BPMN Assistant, a tool that leverages Large Language
Models (LLMs) for natural language-based creation and editing of BPMN diagrams.
A specialized JSON-based representation is introduced as a structured
alternative to the direct handling of XML to enhance the accuracy of process
modifications. Process generation quality is evaluated using Graph Edit
Distance (GED) and Relative Graph Edit Distance (RGED), while editing
performance is evaluated with a binary success metric. Results show that JSON
and XML achieve similar similarity scores in generation, but JSON offers
greater reliability, faster processing, and significantly higher editing
success rates. We discuss key trade-offs, limitations, and future improvements.
The implementation is available at https://github.com/jtlicardo/bpmn-assistant.

</details>


### [236] [LTL$_f$ Learning Meets Boolean Set Cover](https://arxiv.org/abs/2509.24616)
*Gabriel Bathie,Nathanaël Fijalkow,Théo Matricon,Baptiste Mouillon,Pierre Vandenhove*

Main category: cs.AI

TL;DR: Bolt工具通过利用布尔集合覆盖问题作为子程序，实现了比现有技术快100倍以上的LTLf公式学习速度，在98%的情况下生成更小或相等的公式。


<details>
  <summary>Details</summary>
Motivation: 从有限轨迹中学习线性时序逻辑公式是基础研究问题，在人工智能、软件工程、编程语言、形式化方法、信息物理系统控制和机器人等领域有广泛应用。

Method: 使用布尔集合覆盖问题作为子程序，通过布尔连接词组合现有公式，在效率和公式大小之间提供新的权衡。

Result: 在70%的基准测试中学习速度提高100倍以上，98%的情况下生成更小或相等的公式。

Conclusion: Bolt工具通过布尔集合覆盖方法显著提升了LTLf公式学习的效率和效果。

Abstract: Learning formulas in Linear Temporal Logic (LTLf) from finite traces is a
fundamental research problem which has found applications in artificial
intelligence, software engineering, programming languages, formal methods,
control of cyber-physical systems, and robotics. We implement a new CPU tool
called Bolt improving over the state of the art by learning formulas more than
100x faster over 70% of the benchmarks, with smaller or equal formulas in 98%
of the cases. Our key insight is to leverage a problem called Boolean Set Cover
as a subroutine to combine existing formulas using Boolean connectives. Thanks
to the Boolean Set Cover component, our approach offers a novel trade-off
between efficiency and formula size.

</details>


### [237] ["Stop replacing salt with sugar!'': Towards Intuitive Human-Agent Teaching](https://arxiv.org/abs/2509.24651)
*Nikolaos Kondylidis,Andrea Rafanelli,Ilaria Tiddi,Annette ten Teije,Frank van Harmelen*

Main category: cs.AI

TL;DR: 提出一种直观的人机教学架构，通过少量示例让人类教AI代理完成主观任务，应用于食材替换任务，仅需100个示例即可达到完整训练集（5万示例）一半的性能。


<details>
  <summary>Details</summary>
Motivation: 人类能够从少量示例中快速学习新概念，但在AI系统中复制这种能力具有挑战性，特别是在数据稀缺的主观任务中。

Method: 开发人机教学架构，利用领域知识扩展代理的任务理解，采用高效学习算法从有限示例中学习，并优化人类选择最具代表性示例的方式。

Result: 在食材替换任务中，代理仅需100个示例即可达到完整训练集（5万示例）一半的性能，通过策略性示例排序和外部符号知识的利用实现更高效泛化。

Conclusion: 通过结合策略性示例选择和利用外部知识的学习方法，AI代理能够从少量示例中高效学习主观任务，实现快速泛化。

Abstract: Humans quickly learn new concepts from a small number of examples.
Replicating this capacity with Artificial Intelligence (AI) systems has proven
to be challenging. When it comes to learning subjective tasks-where there is an
evident scarcity of data-this capacity needs to be recreated. In this work, we
propose an intuitive human-agent teaching architecture in which the human can
teach an agent how to perform a task by providing demonstrations, i.e.,
examples. To have an intuitive interaction, we argue that the agent should be
able to learn incrementally from a few single examples. To allow for this, our
objective is to broaden the agent's task understanding using domain knowledge.
Then, using a learning method to enable the agent to learn efficiently from a
limited number of examples. Finally, to optimize how human can select the most
representative and less redundant examples to provide the agent with. We apply
our proposed method to the subjective task of ingredient substitution, where
the agent needs to learn how to substitute ingredients in recipes based on
human examples. We replicate human input using the Recipe1MSubs dataset. In our
experiments, the agent achieves half its task performance after only 100
examples are provided, compared to the complete training set of 50k examples.
We show that by providing examples in strategic order along with a learning
method that leverages external symbolic knowledge, the agent can generalize
more efficiently.

</details>


### [238] [Successful Misunderstandings: Learning to Coordinate Without Being Understood](https://arxiv.org/abs/2509.24660)
*Nikolaos Kondylidis,Anil Yaman,Frank van Harmelen,Erman Acar,Annette ten Teije*

Main category: cs.AI

TL;DR: 研究探讨了在通信游戏中，即使参与者使用不同的信号解释也能成功协调的现象，称为"成功的误解"。虽然这种误解不会立即导致协调失败，但会阻碍与新伙伴建立有效协调。研究发现至少需要三个相互交互的参与者才能确保共享解释的出现。


<details>
  <summary>Details</summary>
Motivation: 研究通信评估的基本假设：如果个体能通过通信协调，就认为他们相互理解。但在现实中，特别是人类与AI混合群体中，个体可能对环境有不同感知，需要验证这一假设。

Method: 使用信号游戏作为代理模型，研究个体在仅有通信信号和交互结果（奖励）作为共同观察的情况下，如何发展新词汇来协调。个体开发信号、使用信号并改进解释，但不观察其他个体如何使用信号。

Result: 群体总能达到最优协调水平，但有时参与者使用不同的信号解释来协调，形成"成功的误解"。这种误解不会立即导致协调失败，但会阻碍与新伙伴建立有效协调。

Conclusion: 至少需要三个相互交互的参与者才能确保共享解释的出现。在这些条件下，群体能补偿信号使用缺乏共同观察的不足，确保共享解释的出现。

Abstract: The main approach to evaluating communication is by assessing how well it
facilitates coordination. If two or more individuals can coordinate through
communication, it is generally assumed that they understand one another. We
investigate this assumption in a signaling game where individuals develop a new
vocabulary of signals to coordinate successfully. In our game, the individuals
do not have common observations besides the communication signal and outcome of
the interaction, i.e. received reward. This setting is used as a proxy to study
communication emergence in populations of agents that perceive their
environment very differently, e.g. hybrid populations that include humans and
artificial agents. Agents develop signals, use them, and refine interpretations
while not observing how other agents are using them. While populations always
converge to optimal levels of coordination, in some cases, interacting agents
interpret and use signals differently, converging to what we call successful
misunderstandings. However, agents of population that coordinate using
misaligned interpretations, are unable to establish successful coordination
with new interaction partners. Not leading to coordination failure immediately,
successful misunderstandings are difficult to spot and repair. Having at least
three agents that all interact with each other are the two minimum conditions
to ensure the emergence of shared interpretations. Under these conditions, the
agent population exhibits this emergent property of compensating for the lack
of shared observations of signal use, ensuring the emergence of shared
interpretations.

</details>


### [239] [On the Self-awareness of Large Reasoning Models' Capability Boundaries](https://arxiv.org/abs/2509.24711)
*Qingjie Zhang,Yujia Fu,Yang Wang,Liu Yan,Tao Wei,Ke Xu,Minlie Huang,Han Qiu*

Main category: cs.AI

TL;DR: 大型推理模型在处理困难问题时会产生无效推理，本文研究发现模型能通过推理置信度和隐藏状态感知自身能力边界，并提出两种边界感知优化策略来避免无效推理。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型在面对超出其能力范围的困难问题时，会持续进行无效推理直到上下文限制，既浪费计算资源又产生错误答案，这反映了现有回答范式忽视了问题与模型能力边界的关系。

Method: 研究发现：对于黑盒模型，推理表达能揭示边界信号（可解问题置信度加速增长，不可解问题不确定性收敛）；对于白盒模型，最后一个输入token的隐藏状态编码了边界信息（可解与不可解问题在推理开始前即可线性分离）。基于此提出推理表达监控和隐藏状态监控两种优化策略。

Result: 实验表明，这些边界感知策略使模型能够避免无效推理而不牺牲准确性，显著提高了可靠性和效率，token使用量减少了62.7-93.6%。

Conclusion: 大型推理模型确实具有能力边界的自我意识，通过监控推理表达和隐藏状态可以有效识别并避免处理超出能力范围的问题，从而提升模型的可靠性和效率。

Abstract: Large Reasoning Models (LRMs) have shown impressive performance on complex
reasoning tasks such as mathematics, yet they also display misbehaviors that
expose their limitations. In particular, when faced with hard questions, LRMs
often engage in unproductive reasoning until context limit, producing wrong
answers while wasting substantial computation. This phenomenon reflects a
fundamental issue: current answering paradigms overlook the relationship
between questions and LRMs' capability boundaries. In this paper, we
investigate whether LRMs possess self-awareness of capability boundaries. We
begin by an observation that LRMs may know what they cannot solve through
expressed reasoning confidence. For black-box models, we find that reasoning
expressions reveal boundary signals, with accelerated growing confidence
trajectory for solvable problems but convergent uncertainty trajectory for
unsolvable ones. For white-box models, we show that hidden states of the last
input token encode boundary information, with solvable and unsolvable problems
linearly separable even before reasoning begins. Building on these findings, we
propose two simple yet effective optimization strategies: reasoning expression
monitoring and hidden states monitoring. Experiments demonstrate that these
boundary-aware strategies enable LRMs to avoid unproductive reasoning without
sacrificing accuracy, significantly improving reliability and efficiency by
cutting token usage up to 62.7 - 93.6%.

</details>


### [240] [Spatial-Functional awareness Transformer-based graph archetype contrastive learning for Decoding Visual Neural Representations from EEG](https://arxiv.org/abs/2509.24761)
*Yueming Sun,Long Yang*

Main category: cs.AI

TL;DR: 提出SFTG框架，结合图变换器和原型对比学习，提升EEG视觉解码性能


<details>
  <summary>Details</summary>
Motivation: EEG信号具有高维、噪声大、非欧几里得特性，导致视觉神经表征解码困难

Method: 使用EEG图变换器(EGT)编码空间脑连接和时间神经动态，通过图原型对比学习(GAC)减少被试内变异性

Result: 在Things-EEG数据集上的被试依赖和独立评估中显著优于现有EEG解码方法

Conclusion: 图学习与对比目标的结合具有变革潜力，可为更通用和鲁棒的神经表征铺平道路

Abstract: Decoding visual neural representations from Electroencephalography (EEG)
signals remains a formidable challenge due to their high-dimensional, noisy,
and non-Euclidean nature. In this work, we propose a Spatial-Functional
Awareness Transformer-based Graph Archetype Contrastive Learning (SFTG)
framework to enhance EEG-based visual decoding. Specifically, we introduce the
EEG Graph Transformer (EGT), a novel graph-based neural architecture that
simultaneously encodes spatial brain connectivity and temporal neural dynamics.
To mitigate high intra-subject variability, we propose Graph Archetype
Contrastive Learning (GAC), which learns subject-specific EEG graph archetypes
to improve feature consistency and class separability. Furthermore, we conduct
comprehensive subject-dependent and subject-independent evaluations on the
Things-EEG dataset, demonstrating that our approach significantly outperforms
prior state-of-the-art EEG decoding methods.The results underscore the
transformative potential of integrating graph-based learning with contrastive
objectives to enhance EEG-based brain decoding, paving the way for more
generalizable and robust neural representations.

</details>


### [241] [When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?](https://arxiv.org/abs/2509.24927)
*An Guo,Shuoxiao Zhang,Enyi Tang,Xinyu Gao,Haomin Pang,Haoxiang Tian,Yanzhou Mu,Wu Wen,Chunrong Fang,Zhenyu Chen*

Main category: cs.AI

TL;DR: 本文对V2X协同感知系统进行了实证研究，识别了6种常见错误模式，评估了关键组件性能，发现LiDAR协同配置性能最佳，V2I和V2V通信在不同融合方案下表现不同，通信干扰会显著影响系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: V2X协同感知系统虽然能解决单智能体感知的局限，但由于其复杂的组成（多样传感器类型、协作智能体、不同融合方案和通信条件），带来了许多操作挑战，且错误类型和原因尚未充分探索。

Method: 通过大规模系统评估，识别和分析协同感知系统中的6种常见错误模式，并系统评估关键组件性能。

Result: 发现：(1) LiDAR协同配置性能最佳；(2) V2I和V2V通信在不同融合方案下表现不同；(3) 协同感知错误增加会导致更多驾驶违规；(4) 协同感知系统对在线通信干扰缺乏鲁棒性。

Conclusion: 研究揭示了协同感知系统关键组件的潜在风险和漏洞，希望促进协同感知系统的设计和修复。

Abstract: With the tremendous advancement of deep learning and communication
technology, Vehicle-to-Everything (V2X) cooperative perception has the
potential to address limitations in sensing distant objects and occlusion for a
single-agent perception system. V2X cooperative perception systems are software
systems characterized by diverse sensor types and cooperative agents, varying
fusion schemes, and operation under different communication conditions.
Therefore, their complex composition gives rise to numerous operational
challenges. Furthermore, when cooperative perception systems produce erroneous
predictions, the types of errors and their underlying causes remain
insufficiently explored. To bridge this gap, we take an initial step by
conducting an empirical study of V2X cooperative perception. To systematically
evaluate the impact of cooperative perception on the ego vehicle's perception
performance, we identify and analyze six prevalent error patterns in
cooperative perception systems. We further conduct a systematic evaluation of
the critical components of these systems through our large-scale study and
identify the following key findings: (1) The LiDAR-based cooperation
configuration exhibits the highest perception performance; (2)
Vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communication
exhibit distinct cooperative perception performance under different fusion
schemes; (3) Increased cooperative perception errors may result in a higher
frequency of driving violations; (4) Cooperative perception systems are not
robust against communication interference when running online. Our results
reveal potential risks and vulnerabilities in critical components of
cooperative perception systems. We hope that our findings can better promote
the design and repair of cooperative perception systems.

</details>


### [242] [From Ambiguity to Verdict: A Semiotic-Grounded Multi-Perspective Agent for LLM Logical Reasoning](https://arxiv.org/abs/2509.24765)
*Yunyao Zhang,Xinglang Zhang,Junxi Sheng,Wenbing Li,Junqing Yu,Wei Yang,Zikai Song*

Main category: cs.AI

TL;DR: LogicAgent是一个基于符号学方格的框架，通过多视角一阶逻辑推理和三值决策方案来处理逻辑复杂性和语义复杂性，在RepublicQA基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了逻辑复杂性和语义复杂性的相互作用，难以处理涉及抽象命题、模糊语境和立场冲突等人类推理核心挑战的场景。

Method: 提出LogicAgent框架，通过符号学方格指导进行多视角一阶逻辑推理，采用三值决策方案（真、假、不确定）进行存在性导入检查以避免空推理。

Result: 在RepublicQA基准上平均提升6.25%，在主流逻辑推理基准（ProntoQA、ProofWriter等）上平均提升7.05%，展现了优越的泛化能力。

Conclusion: 基于符号学的多视角推理能有效提升LLMs的逻辑推理性能，特别是在处理复杂语义和逻辑场景时表现出色。

Abstract: Logical reasoning is a fundamental capability of large language models
(LLMs). However, existing studies largely overlook the interplay between
logical complexity and semantic complexity, resulting in methods that struggle
to address challenging scenarios involving abstract propositions, ambiguous
contexts, and conflicting stances, which are central to human reasoning. For
this gap, we propose LogicAgent, a semiotic-square-guided framework designed to
jointly address logical complexity and semantic complexity. LogicAgent
explicitly performs multi-perspective deduction in first-order logic (FOL),
while mitigating vacuous reasoning through existential import checks that
incorporate a three-valued decision scheme (True, False, Uncertain) to handle
boundary cases more faithfully. Furthermore, to overcome the semantic
simplicity and low logical complexity of existing datasets, we introduce
RepublicQA, a benchmark that reaches college-level difficulty (FKGL = 11.94)
and exhibits substantially greater lexical and structural diversity than prior
benchmarks. RepublicQA is grounded in philosophical concepts, featuring
abstract propositions and systematically organized contrary and contradictory
relations, making it the most semantically rich resource for evaluating logical
reasoning. Experiments demonstrate that LogicAgent achieves state-of-the-art
performance on RepublicQA, with a 6.25% average gain over strong baselines, and
generalizes effectively to mainstream logical reasoning benchmarks including
ProntoQA, ProofWriter, FOLIO, and ProverQA, achieving an additional 7.05%
average gain. These results highlight the strong effectiveness of our
semiotic-grounded multi-perspective reasoning in boosting LLMs' logical
performance.

</details>


### [243] [TimeOmni-1: Incentivizing Complex Reasoning with Time Series in Large Language Models](https://arxiv.org/abs/2509.24803)
*Tong Guan,Zijie Meng,Dianqi Li,Shiyu Wang,Chao-Han Huck Yang,Qingsong Wen,Zuozhu Liu,Sabato Marco Siniscalchi,Ming Jin,Shirui Pan*

Main category: cs.AI

TL;DR: 提出了TSR-Suite时间序列推理套件，包含四个原子任务和三种核心推理能力，并基于此开发了首个统一推理模型TimeOmni-1，在因果发现和事件感知预测等任务上显著优于GPT-4.1。


<details>
  <summary>Details</summary>
Motivation: 现有多模态时间序列数据集停留在表面对齐和问答层面，缺乏真正需要推理的任务定义和高质量数据，限制了时间序列推理模型的发展。

Method: 引入TSR-Suite套件，定义四种原子任务和三种推理能力（感知、外推、决策），采用人工引导的分层标注流程构建23K样本数据集，并开发多阶段训练的TimeOmni-1统一推理模型。

Result: TimeOmni-1在所有任务上表现出强大的分布外泛化能力，因果发现准确率显著提升（64.0% vs 35.9%），事件感知预测任务的有效响应率比GPT-4.1提高6%以上。

Conclusion: TSR-Suite为时间序列推理提供了首个全面评估套件，TimeOmni-1证明了统一推理模型在处理多样化现实问题中的有效性，为时间序列推理研究开辟了新方向。

Abstract: Recent advances in multimodal time series learning underscore a paradigm
shift from analytics centered on basic patterns toward advanced time series
understanding and reasoning. However, existing multimodal time series datasets
mostly remain at the level of surface alignment and question answering, without
reaching the depth of genuine reasoning. The absence of well-defined tasks that
genuinely require time series reasoning, along with the scarcity of
high-quality data, has limited progress in building practical time series
reasoning models (TSRMs). To this end, we introduce Time Series Reasoning Suite
(TSR-Suite), which formalizes four atomic tasks that span three fundamental
capabilities for reasoning with time series: (1) perception, acquired through
scenario understanding and causality discovery; (2) extrapolation, realized via
event-aware forecasting; and (3) decision-making, developed through
deliberation over perception and extrapolation. TSR-Suite is the first
comprehensive time series reasoning suite that supports not only thorough
evaluation but also the data pipeline and training of TSRMs. It contains more
than 23K samples, of which 2.3K are carefully curated through a human-guided
hierarchical annotation process. Building on this foundation, we introduce
TimeOmni-1, the first unified reasoning model designed to address diverse
real-world problems demanding time series reasoning. The model is trained in
multiple stages, integrating a mixture of task scenarios, novel reward
functions, and tailored optimizations. Experiments show that TimeOmni-1
delivers strong out-of-distribution generalization across all tasks and
achieves a high rate of valid responses. It significantly improves causality
discovery accuracy (64.0% vs. 35.9% with GPT-4.1) and raises the valid response
rate by over 6% compared to GPT-4.1 on the event-aware forecasting task.

</details>


### [244] [Query Circuits: Explaining How Language Models Answer User Prompts](https://arxiv.org/abs/2509.24808)
*Tung-Yu Wu,Fazl Barez*

Main category: cs.AI

TL;DR: 提出了查询电路方法，直接在模型内部追踪特定输入到输出的信息流，提供更忠实和计算可访问的解释。


<details>
  <summary>Details</summary>
Motivation: 现有方法只能揭示全局能力电路，无法解释模型为何对特定输入查询产生特定输出，需要更本地化的输入级解释。

Method: 引入查询电路概念，开发标准化偏差忠实度(NDF)评估指标，以及基于采样的高效稀疏电路识别方法。

Result: 在多个基准测试中，发现仅覆盖1.3%模型连接的稀疏电路就能恢复约60%的MMLU问题性能。

Conclusion: 查询电路为实现语言模型对单个输入处理过程的忠实、可扩展解释迈出了重要一步。

Abstract: Explaining why a language model produces a particular output requires local,
input-level explanations. Existing methods uncover global capability circuits
(e.g., indirect object identification), but not why the model answers a
specific input query in a particular way. We introduce query circuits, which
directly trace the information flow inside a model that maps a specific input
to the output. Unlike surrogate-based approaches (e.g., sparse autoencoders),
query circuits are identified within the model itself, resulting in more
faithful and computationally accessible explanations. To make query circuits
practical, we address two challenges. First, we introduce Normalized Deviation
Faithfulness (NDF), a robust metric to evaluate how well a discovered circuit
recovers the model's decision for a specific input, and is broadly applicable
to circuit discovery beyond our setting. Second, we develop sampling-based
methods to efficiently identify circuits that are sparse yet faithfully
describe the model's behavior. Across benchmarks (IOI, arithmetic, MMLU, and
ARC), we find that there exist extremely sparse query circuits within the model
that can recover much of its performance on single queries. For example, a
circuit covering only 1.3% of model connections can recover about 60% of
performance on an MMLU questions. Overall, query circuits provide a step
towards faithful, scalable explanations of how language models process
individual inputs.

</details>


### [245] [Pushing LLMs to Their Logical Reasoning Bound: The Role of Data Reasoning Intensity](https://arxiv.org/abs/2509.24836)
*Zhen Bi,Zhenlin Hu,Jinnan Yang,Mingyang Chen,Cheng Deng,Yida Xue,Zeyu Yang,Qing Shen,Zhenfang Liu,Kang Zhao,Ningyu Zhang,Jungang Lou*

Main category: cs.AI

TL;DR: 提出了数据推理强度(DRI)指标来量化训练数据的逻辑推理复杂度，并通过重新认知优化策略提升数据推理强度，从而更好地发挥LLM的推理潜力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注数据格式转换而忽略了训练样本的内部推理复杂度，导致数据的推理潜力未被充分挖掘和利用。

Method: 引入数据推理强度(DRI)指标量化样本的逻辑推理复杂度，并提出重新认知优化策略来系统性地增强训练数据的逻辑推理强度。

Result: 实验表明该方法显著提升了性能和泛化能力，在强化学习框架下也得到验证。

Conclusion: 优先考虑数据的推理复杂度而非单纯的数据规模或表面形式，对于实现LLM的完整认知潜力至关重要。

Abstract: Recent advances in large language models (LLMs) highlight the importance of
training data structure and quality in shaping reasoning behavior. However,
most existing approaches focus on transforming data formats while neglecting
the internal reasoning complexity of training samples, leaving the reasoning
potential of data under-explored and underutilized. In this work, we posit that
LLM logical reasoning performance is jointly constrained by the potential of
the training data and the cognitive capacity of the model. To make this
relationship measurable, we introduce Data Reasoning Intensity (DRI), a novel
metric that quantifies the latent logical reasoning complexity of samples by
decomposing and aggregating their logical structures. This allows us to analyze
how well current LLMs utilize logical reasoning signals and identify
performance gaps relative to data potential. Based on this insight, we
introduce a re-cognizing optimization strategy that systematically enhances the
logical reasoning intensity of training data.Rather than increasing data
volume, our method re-optimizes existing samples to better align with the LLM's
logical reasoning boundary. Extensive experiments show that our approach
significantly improves performance and generalization over data-centric
strategies. We further validate our method under a reinforcement learning
framework. Our results indicate that prioritizing reasoning complexity in data
rather than sheer scale or superficial form is essential to realizing LLMs'
full cognitive potential.

</details>


### [246] [PhysicsMinions: Winning Gold Medals in the Latest Physics Olympiads with a Coevolutionary Multimodal Multi-Agent System](https://arxiv.org/abs/2509.24855)
*Fangchen Yu,Junchi Yao,Ziyi Wang,Haiyuan Wan,Youling Huang,Bo Zhang,Shuyue Hu,Dongzhan Zhou,Ning Ding,Ganqu Cui,Lei Bai,Wanli Ouyang,Peng Ye*

Main category: cs.AI

TL;DR: PhysicsMinions是一个用于物理奥林匹克竞赛的协同进化多智能体系统，包含视觉、逻辑和评审三个工作室，通过迭代精炼实现自我修正，在HiPhO基准测试中取得突破性成果。


<details>
  <summary>Details</summary>
Motivation: 物理奥林匹克竞赛作为物理智能的严格测试平台，需要复杂的推理和多模态理解，但现有AI方法多为单模型且开源模型难以达到金牌水平，因此需要开发更强大的系统。

Method: 提出协同进化多智能体系统PhysicsMinions，包含三个协同工作室：视觉工作室解析图表、逻辑工作室制定解决方案、评审工作室进行双阶段验证，通过迭代精炼循环实现自我修正。

Result: 在7个最新物理奥林匹克竞赛的HiPhO基准测试中，系统实现三大突破：强泛化能力、历史性突破（将开源模型金牌数从1-2个提升到6个）、达到人类专家水平（在最新IPhO中排名第4/406）。

Conclusion: PhysicsMinions为奥林匹克级别问题解决提供了可泛化的框架，具有跨学科扩展的潜力。

Abstract: Physics is central to understanding and shaping the real world, and the
ability to solve physics problems is a key indicator of real-world physical
intelligence. Physics Olympiads, renowned as the crown of competitive physics,
provide a rigorous testbed requiring complex reasoning and deep multimodal
understanding, yet they remain largely underexplored in AI research. Existing
approaches are predominantly single-model based, and open-source MLLMs rarely
reach gold-medal-level performance. To address this gap, we propose
PhysicsMinions, a coevolutionary multi-agent system for Physics Olympiad. Its
architecture features three synergistic studios: a Visual Studio to interpret
diagrams, a Logic Studio to formulate solutions, and a Review Studio to perform
dual-stage verification. The system coevolves through an iterative refinement
loop where feedback from the Review Studio continuously guides the Logic
Studio, enabling the system to self-correct and converge towards the ground
truth. Evaluated on the HiPhO benchmark spanning 7 latest physics Olympiads,
PhysicsMinions delivers three major breakthroughs: (i) Strong generalization:
it consistently improves both open-source and closed-source models of different
sizes, delivering clear benefits over their single-model baselines; (ii)
Historic breakthroughs: it elevates open-source models from only 1-2 to 6 gold
medals across 7 Olympiads, achieving the first-ever open-source gold medal in
the latest International Physics Olympiad (IPhO) under the average-score
metric; and (iii) Scaling to human expert: it further advances the open-source
Pass@32 score to 26.8/30 points on the latest IPhO, ranking 4th of 406
contestants and far surpassing the top single-model score of 22.7 (ranked
22nd). Generally, PhysicsMinions offers a generalizable framework for
Olympiad-level problem solving, with the potential to extend across
disciplines.

</details>


### [247] [The Emergence of Social Science of Large Language Models](https://arxiv.org/abs/2509.24877)
*Xiao Jia,Zhanzhan Zhao*

Main category: cs.AI

TL;DR: 对270篇关于大语言模型（LLMs）社会科学研究的系统综述，通过计算分类法识别出三个主要研究领域：LLM作为社会心智、LLM社会和LLM-人类互动。


<details>
  <summary>Details</summary>
Motivation: LLMs在社会中引发心智归因、相互互动并改变人类活动和制度，但该领域研究分散，需要系统性的分类框架来整合现有研究。

Method: 采用文本嵌入、无监督聚类和主题建模的计算分类法，对270项研究进行系统综述。

Result: 识别出三个有机出现的研究领域：LLM作为社会心智（认知、道德和偏见归因）、LLM社会（多智能体互动和制度形成）、LLM-人类互动（任务重塑、信任和工作影响）。

Conclusion: 该分类法为碎片化的研究领域提供了可复现的地图，澄清了不同分析层次的证据标准，并突出了人工智能社会科学中累积进展的机会。

Abstract: The social science of large language models (LLMs) examines how these systems
evoke mind attributions, interact with one another, and transform human
activity and institutions. We conducted a systematic review of 270 studies,
combining text embeddings, unsupervised clustering and topic modeling to build
a computational taxonomy. Three domains emerge organically across the reviewed
literature. LLM as Social Minds examines whether and when models display
behaviors that elicit attributions of cognition, morality and bias, while
addressing challenges such as test leakage and surface cues. LLM Societies
examines multi-agent settings where interaction protocols, architectures and
mechanism design shape coordination, norms, institutions and collective
epistemic processes. LLM-Human Interactions examines how LLMs reshape tasks,
learning, trust, work and governance, and how risks arise at the human-AI
interface. This taxonomy provides a reproducible map of a fragmented field,
clarifies evidentiary standards across levels of analysis, and highlights
opportunities for cumulative progress in the social science of artificial
intelligence.

</details>


### [248] [RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark](https://arxiv.org/abs/2509.24897)
*Yang Shi,Yuhao Dong,Yue Ding,Yuran Wang,Xuanyu Zhu,Sheng Zhou,Wenting Liu,Haochen Tian,Rundong Wang,Huanqian Wang,Zuyan Liu,Bohan Zeng,Ruizhe Chen,Qixun Wang,Zhuoran Zhang,Xinlong Chen,Chengzhuo Tong,Bozhou Li,Chaoyou Fu,Qiang Liu,Haotian Wang,Wenjing Yang,Yuanxing Zhang,Pengfei Wan,Yi-Fan Zhang,Ziwei Liu*

Main category: cs.AI

TL;DR: 提出了RealUnify基准来评估多模态模型中理解与生成能力的双向协同效应，发现现有统一模型在能力协同方面仍存在困难


<details>
  <summary>Details</summary>
Motivation: 现有评估方法孤立评估理解和生成能力，无法确定统一模型是否能利用理解增强生成，或通过生成模拟促进更深理解

Method: 构建包含1000个实例的RealUnify基准，围绕两个核心轴：理解增强生成和生成增强理解，采用双评估协议结合端到端评估和诊断性分步评估

Result: 对12个领先统一模型和6个专业基线的评估表明，当前统一模型仍难以实现有效协同，架构统一本身不足以保证能力协同

Conclusion: 需要新的训练策略和归纳偏置来充分释放统一建模的潜力

Abstract: The integration of visual understanding and generation into unified
multimodal models represents a significant stride toward general-purpose AI.
However, a fundamental question remains unanswered by existing benchmarks: does
this architectural unification actually enable synergetic interaction between
the constituent capabilities? Existing evaluation paradigms, which primarily
assess understanding and generation in isolation, are insufficient for
determining whether a unified model can leverage its understanding to enhance
its generation, or use generative simulation to facilitate deeper
comprehension. To address this critical gap, we introduce RealUnify, a
benchmark specifically designed to evaluate bidirectional capability synergy.
RealUnify comprises 1,000 meticulously human-annotated instances spanning 10
categories and 32 subtasks. It is structured around two core axes: 1)
Understanding Enhances Generation, which requires reasoning (e.g., commonsense,
logic) to guide image generation, and 2) Generation Enhances Understanding,
which necessitates mental simulation or reconstruction (e.g., of transformed or
disordered visual inputs) to solve reasoning tasks. A key contribution is our
dual-evaluation protocol, which combines direct end-to-end assessment with a
diagnostic stepwise evaluation that decomposes tasks into distinct
understanding and generation phases. This protocol allows us to precisely
discern whether performance bottlenecks stem from deficiencies in core
abilities or from a failure to integrate them. Through large-scale evaluations
of 12 leading unified models and 6 specialized baselines, we find that current
unified models still struggle to achieve effective synergy, indicating that
architectural unification alone is insufficient. These results highlight the
need for new training strategies and inductive biases to fully unlock the
potential of unified modeling.

</details>


### [249] [Neural network embeddings recover value dimensions from psychometric survey items on par with human data](https://arxiv.org/abs/2509.24906)
*Max Pellert,Clemens M. Lechner,Indira Sen,Markus Strohmaier*

Main category: cs.AI

TL;DR: SQuID方法利用LLM嵌入有效恢复心理测量问卷的潜在维度结构，无需领域特定微调即可获得维度间负相关，解释55%的人类数据方差。


<details>
  <summary>Details</summary>
Motivation: 解决传统心理测量方法成本高、扩展性差的问题，探索语义嵌入能否有效复制通过广泛人类调查建立的心理测量结构。

Method: 使用SQuID方法处理大语言模型嵌入，从修订版肖像价值问卷(PVQ-RR)中恢复人类评分判断获得的人类价值结构，比较多种嵌入模型和评估指标。

Result: 嵌入方法解释55%维度相似性方差，多维缩放配置显示良好因子一致性系数，与基础理论基本一致，质量与传统方法相当。

Conclusion: 语义嵌入能有效复制心理测量结构，在成本、可扩展性和灵活性方面具有显著优势，为心理测量学和社会科学研究提供补充方法。

Abstract: This study introduces "Survey and Questionnaire Item Embeddings
Differentials" (SQuID), a novel methodological approach that enables neural
network embeddings to effectively recover latent dimensions from psychometric
survey items. We demonstrate that embeddings derived from large language
models, when processed with SQuID, can recover the structure of human values
obtained from human rater judgments on the Revised Portrait Value Questionnaire
(PVQ-RR). Our experimental validation compares multiple embedding models across
a number of evaluation metrics. Unlike previous approaches, SQuID successfully
addresses the challenge of obtaining negative correlations between dimensions
without requiring domain-specific fine-tuning. Quantitative analysis reveals
that our embedding-based approach explains 55% of variance in
dimension-dimension similarities compared to human data. Multidimensional
scaling configurations from both types of data show fair factor congruence
coefficients and largely follow the underlying theory. These results
demonstrate that semantic embeddings can effectively replicate psychometric
structures previously established through extensive human surveys. The approach
offers substantial advantages in cost, scalability and flexibility while
maintaining comparable quality to traditional methods. Our findings have
significant implications for psychometrics and social science research,
providing a complementary methodology that could expand the scope of human
behavior and experience represented in measurement tools.

</details>


### [250] [Meta-Learning Theory-Informed Inductive Biases using Deep Kernel Gaussian Processes](https://arxiv.org/abs/2509.24919)
*Bahti Zakirov,Gašper Tkačik*

Main category: cs.AI

TL;DR: 提出了一种贝叶斯元学习框架，将规范性理论的功能预测自动转换为可处理的概率模型，应用于早期视觉系统，提高了视网膜神经节细胞响应预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决规范性理论与任务驱动理论之间难以定量仲裁的问题，以及如何将其作为归纳偏置来改进真实生物数据集的拟合效果。

Method: 使用自适应深度核高斯过程，在规范性理论生成的合成数据上进行元学习，构建理论知情核，形成代表理论预测的概率模型。

Result: 在自然场景刺激下的小鼠视网膜神经节细胞记录中，相比传统数据驱动基线提高了响应预测准确性，提供了良好校准的不确定性估计和可解释表示。

Conclusion: 该框架为将理论知识整合到数据驱动的科学探究中提供了更通用、可扩展和自动化的方法。

Abstract: Normative and task-driven theories offer powerful top-down explanations for
biological systems, yet the goals of quantitatively arbitrating between
competing theories, and utilizing them as inductive biases to improve
data-driven fits of real biological datasets are prohibitively laborious, and
often impossible. To this end, we introduce a Bayesian meta-learning framework
designed to automatically convert raw functional predictions from normative
theories into tractable probabilistic models. We employ adaptive deep kernel
Gaussian processes, meta-learning a kernel on synthetic data generated from a
normative theory. This Theory-Informed Kernel specifies a probabilistic model
representing the theory predictions -- usable for both fitting data and
rigorously validating the theory. As a demonstration, we apply our framework to
the early visual system, using efficient coding as our normative theory. We
show improved response prediction accuracy in ex vivo recordings of mouse
retinal ganglion cells stimulated by natural scenes compared to conventional
data-driven baselines, while providing well-calibrated uncertainty estimates
and interpretable representations. Using exact Bayesian model selection, we
also show that our informed kernel can accurately infer the degree of
theory-match from data, confirming faithful encapsulation of theory structure.
This work provides a more general, scalable, and automated approach for
integrating theoretical knowledge into data-driven scientific inquiry in
neuroscience and beyond.

</details>


### [251] [MASLegalBench: Benchmarking Multi-Agent Systems in Deductive Legal Reasoning](https://arxiv.org/abs/2509.24922)
*Huihao Jing,Wenbin Hu,Hongyu Luo,Jianhui Yang,Wei Fan,Haoran Li,Yangqiu Song*

Main category: cs.AI

TL;DR: 提出了MASLegalBench，一个专门为多智能体系统设计的法律基准测试，使用GDPR作为应用场景，通过演绎推理方法评估MAS在复杂法律任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的法律基准测试没有充分考虑多智能体系统的独特优势，如任务分解、智能体专业化和灵活训练，这限制了MAS在法律领域的潜力。

Method: 使用GDPR作为应用场景，构建包含广泛背景知识和复杂推理过程的基准测试，手动设计各种基于角色的多智能体系统，并使用最先进的LLM进行广泛实验。

Result: 实验结果揭示了现有模型和MAS架构的优势、局限性和潜在改进领域。

Conclusion: MASLegalBench填补了法律领域多智能体系统评估方法的空白，为MAS在法律任务中的应用提供了有效的评估框架。

Abstract: Multi-agent systems (MAS), leveraging the remarkable capabilities of Large
Language Models (LLMs), show great potential in addressing complex tasks. In
this context, integrating MAS with legal tasks is a crucial step. While
previous studies have developed legal benchmarks for LLM agents, none are
specifically designed to consider the unique advantages of MAS, such as task
decomposition, agent specialization, and flexible training. In fact, the lack
of evaluation methods limits the potential of MAS in the legal domain. To
address this gap, we propose MASLegalBench, a legal benchmark tailored for MAS
and designed with a deductive reasoning approach. Our benchmark uses GDPR as
the application scenario, encompassing extensive background knowledge and
covering complex reasoning processes that effectively reflect the intricacies
of real-world legal situations. Furthermore, we manually design various
role-based MAS and conduct extensive experiments using different
state-of-the-art LLMs. Our results highlight the strengths, limitations, and
potential areas for improvement of existing models and MAS architectures.

</details>


### [252] [KIRETT -- A wearable device to support rescue operations using artificial intelligence to improve first aid](https://arxiv.org/abs/2509.24934)
*Johannes Zenkert,Christian Weber,Mubaris Nadeem,Lisa Bender,Madjid Fathi,Abu Shad Ahammed,Aniebiet Micheal Ezekiel,Roman Obermaisser,Maximilian Bradford*

Main category: cs.AI

TL;DR: KIRETT项目初步研究：使用可穿戴设备和人工智能改进救援行动中的急救，通过情境识别提供行动建议，减少错误治疗并提高生存率。


<details>
  <summary>Details</summary>
Motivation: 旨在通过技术手段改进救援行动中的急救质量，减少因错误治疗造成的患者伤害，提高生存概率。

Method: 使用可穿戴设备结合人工智能进行计算机辅助情境识别，为救援人员提供情境化行动建议。

Result: 论文提供了项目研究方法的初步概述，展示了技术应用的基本框架。

Conclusion: 可穿戴设备和人工智能在救援急救中具有应用潜力，能够通过情境识别和行动建议改善救援效果。

Abstract: This short paper presents first steps in the scientific part of the KIRETT
project, which aims to improve first aid during rescue operations using a
wearable device. The wearable is used for computer-aided situation recognition
by means of artificial intelligence. It provides contextual recommendations for
actions and operations to rescue personnel and is intended to minimize damage
to patients due to incorrect treatment, as well as increase the probability of
survival. The paper describes a first overview of research approaches within
the project.

</details>


### [253] [Agentic Exploration of Physics Models](https://arxiv.org/abs/2509.24978)
*Maximilian Nägele,Florian Marquardt*

Main category: cs.AI

TL;DR: SciExplorer是一个基于大语言模型的智能体，能够自主探索未知物理系统并发现其规律，无需领域特定蓝图或微调。


<details>
  <summary>Details</summary>
Motivation: 科学发现过程需要观察、分析和假设生成的迭代循环，目前机器学习方法难以完全自动化这一开放式的探索过程。

Method: 利用大语言模型的工具使用能力，通过代码执行等基础工具，对未知物理系统进行自由形式探索。

Result: 在机械动力学系统、波演化、量子多体物理等多种模型中表现出色，能够从观测动态恢复运动方程，从期望值推断哈密顿量。

Conclusion: 该方法为其他领域的科学探索开辟了新途径，无需任务特定指令或微调即可实现有效探索。

Abstract: The process of scientific discovery relies on an interplay of observations,
analysis, and hypothesis generation. Machine learning is increasingly being
adopted to address individual aspects of this process. However, it remains an
open challenge to fully automate the open-ended, heuristic, iterative loop
required to discover the laws of an unknown system by exploring it through
experiments and analysis, without tailoring the approach to the specifics of a
given task. Here, we introduce SciExplorer, an agent that leverages large
language model tool-use capabilities to enable free-form exploration of systems
without any domain-specific blueprints, and apply it to the exploration of
physical systems that are initially unknown to the agent. We test SciExplorer
on a broad set of models spanning mechanical dynamical systems, wave evolution,
and quantum many-body physics. Despite using a minimal set of tools, primarily
based on code execution, we observe impressive performance on tasks such as
recovering equations of motion from observed dynamics and inferring
Hamiltonians from expectation values. The demonstrated effectiveness of this
setup opens the door towards similar scientific exploration in other domains,
without the need for finetuning or task-specific instructions.

</details>


### [254] [CLPO: Curriculum Learning meets Policy Optimization for LLM Reasoning](https://arxiv.org/abs/2509.25004)
*Shijie Zhang,Guohao Sun,Kevin Zhang,Xiang Guo,Rujun Guo*

Main category: cs.AI

TL;DR: CLPO提出了一种基于课程学习的强化学习算法，通过动态难度评估和自适应问题重构机制，让模型自我调整训练难度，显著提升了推理能力训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法对所有训练样本一视同仁，忽略了问题难度与模型当前能力的巨大差异，导致对已掌握问题的低效探索和对挑战性问题缺乏有效指导，限制了学习效率和性能上限。

Method: CLPO通过模型自身rollout表现进行实时难度评估，构建在线课程，并采用自适应问题重构机制：将中等难度问题多样化以促进泛化，将挑战性问题简化使其更易掌握。

Result: 在8个具有挑战性的数学和通用推理基准测试中，CLPO实现了最先进的性能，平均pass@1指标比其他方法提升了6.96%。

Conclusion: CLPO将静态训练过程转变为与模型能力共同进化的动态过程，证明了其能够更有效地训练更具能力的推理模型。

Abstract: Recently, online Reinforcement Learning with Verifiable Rewards (RLVR) has
become a key paradigm for enhancing the reasoning capabilities of Large
Language Models (LLMs). However, existing methods typically treat all training
samples uniformly, overlooking the vast differences in problem difficulty
relative to the model's current capabilities. This uniform training strategy
leads to inefficient exploration of problems the model has already mastered,
while concurrently lacking effective guidance on problems that are challenging
its abilities the most, limiting both learning efficiency and upper-bound
performance. To address this, we propose CLPO (Curriculum-guided Learning for
Policy Optimization), a novel algorithm that creates a dynamic pedagogical
feedback loop within the policy optimization process. The core of CLPO
leverages the model's own rollout performance to conduct real-time difficulty
assessment, thereby constructing an Online Curriculum. This curriculum then
guides an Adaptive Problem Restructuring mechanism, where the model acts as its
own teacher: it diversifies medium-difficulty problems to promote
generalization and simplifies challenging problems to make them more
attainable. Our approach transforms the static training procedure into a
dynamic process that co-evolves with the model's capabilities. Experiments show
that CLPO achieves state-of-the-art performance across eight challenging
mathematical and general reasoning benchmarks, with an average pass@1
improvement of 6.96% over other methods, demonstrating its potential for more
efficiently training more capable reasoning models.

</details>


### [255] [Scaling Synthetic Task Generation for Agents via Exploration](https://arxiv.org/abs/2509.25047)
*Ram Ramrakhya,Andrew Szot,Omar Attia,Yuhao Yang,Anh Nguyen,Bogdan Mazoure,Zhe Gan,Harsh Agrawal,Alexander Toshev*

Main category: cs.AI

TL;DR: AutoPlay是一个可扩展的任务生成管道，通过探索交互环境来合成多样、可执行且可验证的任务，用于训练多模态大语言模型代理，在移动使用和计算机使用场景中显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工标注或有限环境信息提示，成本高且扩展性差，难以生成高质量的下游代理任务数据集。

Method: 采用两阶段方法：探索阶段系统发现环境状态和功能；任务生成阶段利用探索轨迹和任务指南提示合成任务。

Result: 在20个Android应用中生成20k任务，13个Ubuntu应用中生成10k任务，训练后的代理在移动使用场景中成功率提升20.0%，计算机使用场景提升10.9%。

Conclusion: AutoPlay为后训练多模态大语言模型代理提供可扩展方法，减少对人工标注的依赖，并能结合强化学习进一步提升性能。

Abstract: Post-Training Multimodal Large Language Models (MLLMs) to build interactive
agents holds promise across domains such as computer-use, web navigation, and
robotics. A key challenge in scaling such post-training is lack of high-quality
downstream agentic task datasets with tasks that are diverse, feasible, and
verifiable. Existing approaches for task generation rely heavily on human
annotation or prompting MLLM with limited downstream environment information,
which is either costly or poorly scalable as it yield tasks with limited
coverage. To remedy this, we present AutoPlay, a scalable pipeline for task
generation that explicitly explores interactive environments to discover
possible interactions and current state information to synthesize
environment-grounded tasks. AutoPlay operates in two stages: (i) an exploration
phase, where an MLLM explorer agent systematically uncovers novel environment
states and functionalities, and (ii) a task generation phase, where a task
generator leverages exploration trajectories and a set of task guideline
prompts as context to synthesize diverse, executable, and verifiable tasks. We
show AutoPlay generates 20k tasks across 20 Android applications and 10k tasks
across 13 applications Ubuntu applications to train mobile-use and computer-use
agents. AutoPlay generated tasks enable large-scale task demonstration
synthesis without human annotation by employing an MLLM task executor and
verifier. This data enables training MLLM-based UI agents that improve success
rates up to $20.0\%$ on mobile-use and $10.9\%$ on computer-use scenarios. In
addition, AutoPlay generated tasks combined with MLLM verifier-based rewards
enable scaling reinforcement learning training of UI agents, leading to an
additional $5.7\%$ gain. coverage. These results establish AutoPlay as a
scalable approach for post-training capable MLLM agents reducing reliance on
human annotation.

</details>


### [256] [Cogito, Ergo Ludo: An Agent that Learns to Play by Reasoning and Planning](https://arxiv.org/abs/2509.25052)
*Sai Wang,Yu Wu,Zhongwen Xu*

Main category: cs.AI

TL;DR: CEL是一种新型智能体架构，利用大型语言模型通过推理和规划来学习游戏，能够自主发现环境规则并制定有效策略。


<details>
  <summary>Details</summary>
Motivation: 传统深度强化学习方法依赖大量经验且知识编码不透明，作者希望开发更通用、可解释的智能体，通过显式推理构建透明的世界模型。

Method: CEL采用交互-反思循环：在每次游戏后分析完整轨迹，进行规则归纳（精炼环境动态模型）和策略总结（将经验提炼为可操作的策略手册）。

Result: 在多个网格世界任务（扫雷、冰冻湖、推箱子）上，CEL成功掌握了这些游戏，从稀疏奖励中自主发现规则并开发有效策略。消融研究证实迭代过程对持续学习至关重要。

Conclusion: 这项工作展示了构建更通用、可解释智能体的路径，这些智能体不仅有效行动，还通过显式推理构建透明且不断改进的世界模型。

Abstract: The pursuit of artificial agents that can learn to master complex
environments has led to remarkable successes, yet prevailing deep reinforcement
learning methods often rely on immense experience, encoding their knowledge
opaquely within neural network weights. We propose a different paradigm, one in
which an agent learns to play by reasoning and planning. We introduce Cogito,
ergo ludo (CEL), a novel agent architecture that leverages a Large Language
Model (LLM) to build an explicit, language-based understanding of its
environment's mechanics and its own strategy. Starting from a tabula rasa state
with no prior knowledge (except action set), CEL operates on a cycle of
interaction and reflection. After each episode, the agent analyzes its complete
trajectory to perform two concurrent learning processes: Rule Induction, where
it refines its explicit model of the environment's dynamics, and Strategy and
Playbook Summarization, where it distills experiences into an actionable
strategic playbook. We evaluate CEL on diverse grid-world tasks (i.e.,
Minesweeper, Frozen Lake, and Sokoban), and show that the CEL agent
successfully learns to master these games by autonomously discovering their
rules and developing effective policies from sparse rewards. Ablation studies
confirm that the iterative process is critical for sustained learning. Our work
demonstrates a path toward more general and interpretable agents that not only
act effectively but also build a transparent and improving model of their world
through explicit reasoning on raw experience.

</details>


### [257] [HeDA: An Intelligent Agent System for Heatwave Risk Discovery through Automated Knowledge Graph Construction and Multi-layer Risk Propagation Analysis](https://arxiv.org/abs/2509.25112)
*Yiquan Wang,Tin-Yeh Huang,Qingyun Gao,Jialin Zhang*

Main category: cs.AI

TL;DR: 提出HeDA系统，通过构建知识图谱和多层风险传播分析，自动发现热浪相关的级联风险路径，在复杂问答任务中准确率达78.9%，发现了5条先前未知的高影响风险链。


<details>
  <summary>Details</summary>
Motivation: 热浪在气候、社会和经济系统中造成复杂的级联风险，但科学文献中的知识碎片化阻碍了对这些风险路径的全面理解。

Method: 开发HeDA多智能体系统，处理10,247篇学术论文构建包含23,156个节点和89,472个关系的知识图谱，采用多层风险传播分析方法。

Result: 系统在复杂问答任务中准确率达78.9%，比GPT-4等最先进基线高13.7%，发现了5条先前未知的高影响风险链。

Conclusion: 这项工作提出了AI驱动科学发现的新范式，为制定更具韧性的气候适应策略提供了可操作的见解。

Abstract: Heatwaves pose complex cascading risks across interconnected climate, social,
and economic systems, but knowledge fragmentation in scientific literature
hinders comprehensive understanding of these risk pathways. We introduce HeDA
(Heatwave Discovery Agent), an intelligent multi-agent system designed for
automated scientific discovery through knowledge graph construction and
multi-layer risk propagation analysis. HeDA processes over 10,247 academic
papers to construct a comprehensive knowledge graph with 23,156 nodes and
89,472 relationships, employing novel multi-layer risk propagation analysis to
systematically identify overlooked risk transmission pathways. Our system
achieves 78.9% accuracy on complex question-answering tasks, outperforming
state-of-the-art baselines including GPT-4 by 13.7%. Critically, HeDA
successfully discovered five previously unidentified high-impact risk chains,
such as the pathway where a heatwave leads to a water demand surge, resulting
in industrial water restrictions and ultimately causing small business
disruption, which were validated through historical case studies and domain
expert review. This work presents a new paradigm for AI-driven scientific
discovery, providing actionable insights for developing more resilient climate
adaptation strategies.

</details>


### [258] [From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones](https://arxiv.org/abs/2509.25123)
*Lifan Yuan,Weize Chen,Yuchen Zhang,Ganqu Cui,Hanbin Wang,Ziming You,Ning Ding,Zhiyuan Liu,Maosong Sun,Hao Peng*

Main category: cs.AI

TL;DR: RL确实能让LLMs学习到真正的新技能，特别是通过组合现有技能来获得新的组合能力，这与人类获取认知技能的机制相似。


<details>
  <summary>Details</summary>
Motivation: 解决关于RL在LLM后训练中作用的争议：RL是教授真正新技能还是仅仅激活现有技能。

Method: 开发合成框架，将技能定义为推断字符串转换函数输出的能力，研究LLM在RL训练后能否学习未见过的函数组合。

Result: RL使LLM能够学习未见过的函数组合，这种组合能力可泛化到更复杂的多函数组合，并能迁移到不同任务中。

Conclusion: RL能从根本上改变模型的推理行为，建议先构建具有基本技能的基座模型，然后用RL激励高级、可泛化的复杂问题解决技能。

Abstract: Does RL teach LLMs genuinely new skills, or does it merely activate existing
ones? This question lies at the core of ongoing debates about the role of RL in
LLM post-training. On one side, strong empirical results can be achieved with
RL even without preceding supervised finetuning; on the other, critics argue
that RL contributes little beyond reweighting existing reasoning strategies.
This work provides concrete evidence that LLMs can acquire genuinely new skills
during RL by composing existing ones, mirroring one of the central mechanisms
by which humans acquire new cognitive skills. To mitigate data contamination
and other confounding factors, and to allow precise control over task
complexity, we develop a synthetic framework for our investigation.
Specifically, we define a skill as the ability to infer the output of a string
transformation function f(x) given x. When an LLM has already learned f and g
prior to RL, our experiments reveal that RL enables it to learn unseen
compositions of them h(x)=g(f(x)). Further, this compositional ability
generalizes to more difficult problems such as compositions of >2 functions
unseen during RL training. Surprisingly, our experiments show that
compositional skill acquired on a source task transfers to a different target
task. This transfer happens even without compositional training on the target,
requiring only prior knowledge of the target's atomic skills. Our qualitative
analysis shows that RL fundamentally changes the reasoning behaviors of the
models. In contrast, next-token training with the same data yields none of
these findings. Our systematic experiments provide fresh insights into LLM
learning, suggesting the value of first building base models with basic skills,
then using RL to incentivize advanced, generalizable skills for complex
problems.

</details>


### [259] [The Era of Real-World Human Interaction: RL from User Conversations](https://arxiv.org/abs/2509.25137)
*Chuanyang Jin,Jing Xu,Bo Liu,Leitian Tao,Olga Golovneva,Tianmin Shu,Wenting Zhao,Xian Li,Jason Weston*

Main category: cs.AI

TL;DR: 提出了RLHI（从人类交互中强化学习）范式，通过两种方法直接从真实用户对话中学习：用户引导重写和基于用户的奖励，实现个性化对齐。


<details>
  <summary>Details</summary>
Motivation: 当前对话模型使用预标注的专家生成反馈进行对齐，而未来模型需要从自然人类交互中学习，以实现持续改进和多方面对齐。

Method: 开发两种互补方法：1）用户引导重写：根据用户的自然语言后续响应修订不令人满意的模型输出；2）基于用户的奖励：通过基于用户长期交互历史（称为人物角色）的奖励模型学习。

Result: 在WildChat对话数据上训练，两种RLHI变体在个性化和指令遵循方面均优于强基线，类似反馈还能提升推理基准性能。

Conclusion: 有机人类交互为个性化对齐提供了可扩展且有效的监督方式。

Abstract: We posit that to achieve continual model improvement and multifaceted
alignment, future models must learn from natural human interaction. Current
conversational models are aligned using pre-annotated, expert-generated human
feedback. In this work, we introduce Reinforcement Learning from Human
Interaction (RLHI), a paradigm that learns directly from in-the-wild user
conversations. We develop two complementary methods: (1) RLHI with User-Guided
Rewrites, which revises unsatisfactory model outputs based on users'
natural-language follow-up responses, (2) RLHI with User-Based Rewards, which
learns via a reward model conditioned on knowledge of the user's long-term
interaction history (termed persona). Together, these methods link long-term
user personas to turn-level preferences via persona-conditioned preference
optimization. Trained on conversations derived from WildChat, both RLHI
variants outperform strong baselines in personalization and
instruction-following, and similar feedback enhances performance on reasoning
benchmarks. These results suggest organic human interaction offers scalable,
effective supervision for personalized alignment.

</details>


### [260] [Vision-and-Language Navigation with Analogical Textual Descriptions in LLMs](https://arxiv.org/abs/2509.25139)
*Yue Zhang,Tianyi Ma,Zun Wang,Yanyuan Qiao,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: 提出一种通过多视角文本描述增强视觉语言导航中类比推理的方法，在R2R数据集上显著提升了导航性能


<details>
  <summary>Details</summary>
Motivation: 现有零样本LLM导航代理要么将图像编码为文本场景描述（可能简化视觉细节），要么处理原始图像输入（可能无法捕捉高级推理所需的抽象语义），需要改进对上下文的理解

Method: 通过整合多视角的文本描述来促进图像间的类比推理，利用基于文本的类比推理增强全局场景理解和空间推理

Result: 在R2R数据集上的实验表明导航性能有显著提升

Conclusion: 通过多视角文本描述和类比推理可以有效增强导航代理的上下文理解能力，提高导航准确性

Abstract: Integrating large language models (LLMs) into embodied AI models is becoming
increasingly prevalent. However, existing zero-shot LLM-based
Vision-and-Language Navigation (VLN) agents either encode images as textual
scene descriptions, potentially oversimplifying visual details, or process raw
image inputs, which can fail to capture abstract semantics required for
high-level reasoning. In this paper, we improve the navigation agent's
contextual understanding by incorporating textual descriptions from multiple
perspectives that facilitate analogical reasoning across images. By leveraging
text-based analogical reasoning, the agent enhances its global scene
understanding and spatial reasoning, leading to more accurate action decisions.
We evaluate our approach on the R2R dataset, where our experiments demonstrate
significant improvements in navigation performance.

</details>


### [261] [ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory](https://arxiv.org/abs/2509.25140)
*Siru Ouyang,Jun Yan,I-Hung Hsu,Yanfei Chen,Ke Jiang,Zifeng Wang,Rujun Han,Long T. Le,Samira Daruki,Xiangru Tang,Vishy Tirumalashetty,George Lee,Mahsan Rofouei,Hangfei Lin,Jiawei Han,Chen-Yu Lee,Tomas Pfister*

Main category: cs.AI

TL;DR: 提出了ReasoningBank记忆框架，从智能体的成功和失败经验中提炼可泛化的推理策略，并通过内存感知测试时扩展(MaTTS)加速学习过程。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型智能体在处理持续任务流时，无法从积累的交互历史中学习，导致重复过去的错误和浪费宝贵见解。

Method: ReasoningBank框架从智能体自我判断的成功和失败经验中提取推理策略；MaTTS通过扩展智能体交互经验来加速和多样化学习过程。

Result: 在网页浏览和软件工程基准测试中，ReasoningBank持续优于存储原始轨迹或仅成功任务例程的现有记忆机制，提高了效果和效率；MaTTS进一步增强了这些优势。

Conclusion: 内存驱动的经验扩展成为一种新的扩展维度，使智能体能够自然产生涌现行为并自我进化。

Abstract: With the growing adoption of large language model agents in persistent
real-world roles, they naturally encounter continuous streams of tasks. A key
limitation, however, is their failure to learn from the accumulated interaction
history, forcing them to discard valuable insights and repeat past errors. We
propose ReasoningBank, a novel memory framework that distills generalizable
reasoning strategies from an agent's self-judged successful and failed
experiences. At test time, an agent retrieves relevant memories from
ReasoningBank to inform its interaction and then integrates new learnings back,
enabling it to become more capable over time. Building on this powerful
experience learner, we further introduce memory-aware test-time scaling
(MaTTS), which accelerates and diversifies this learning process by scaling up
the agent's interaction experience. By allocating more compute to each task,
the agent generates abundant, diverse experiences that provide rich contrastive
signals for synthesizing higher-quality memory. The better memory in turn
guides more effective scaling, establishing a powerful synergy between memory
and test-time scaling. Across web browsing and software engineering benchmarks,
ReasoningBank consistently outperforms existing memory mechanisms that store
raw trajectories or only successful task routines, improving both effectiveness
and efficiency; MaTTS further amplifies these gains. These findings establish
memory-driven experience scaling as a new scaling dimension, enabling agents to
self-evolve with emergent behaviors naturally arise.

</details>


### [262] [Visual serial processing deficits explain divergences in human and VLM reasoning](https://arxiv.org/abs/2509.25142)
*Nicholas Budny,Kia Ghods,Declan Campbell,Raja Marjieh,Amogh Joshi,Sreejan Kumar,Jonathan D. Cohen,Taylor W. Webb,Thomas L. Griffiths*

Main category: cs.AI

TL;DR: VLMs在简单视觉推理任务中表现不如人类，主要原因是缺乏视觉基础的串行处理能力。研究发现VLM准确率下降与人类反应时间增加（作为串行处理负载的代理）呈强相关。


<details>
  <summary>Details</summary>
Motivation: 研究为什么视觉语言模型（VLMs）在标准基准测试中表现良好，但在简单视觉推理任务中却不如人类表现。假设关键因素是视觉基础的串行处理能力不足。

Method: 比较人类和VLM在三个不同领域的表现：几何推理、感知枚举和心理旋转。通过操纵几何概念复杂性、感知个体化负载和变换难度等因素来改变串行处理需求。

Result: 所有领域都显示出一致模式：VLM准确率下降与人类反应时间增加呈强相关。随着任务需要更多串行处理，VLM与人类性能差距显著扩大。

Conclusion: 当前VLMs在串行、视觉基础的推理能力上存在根本性瓶颈，这将其与人类区分开来。

Abstract: Why do Vision Language Models (VLMs), despite success on standard benchmarks,
often fail to match human performance on surprisingly simple visual reasoning
tasks? While the underlying computational principles are still debated, we
hypothesize that a crucial factor is a deficit in visually-grounded serial
processing. To test this hypothesis, we compared human and VLM performance
across tasks designed to vary serial processing demands in three distinct
domains: geometric reasoning, perceptual enumeration, and mental rotation.
Tasks within each domain varied serial processing load by manipulating factors
such as geometric concept complexity, perceptual individuation load, and
transformation difficulty. Across all domains, our results revealed a
consistent pattern: decreased VLM accuracy was strongly correlated with
increased human reaction time (used as a proxy for serial processing load). As
tasks require more demanding serial processing -- whether composing concepts,
enumerating items, or performing mental transformations -- the VLM-human
performance gap widens reliably. These findings support our hypothesis,
indicating that limitations in serial, visually grounded reasoning represent a
fundamental bottleneck that distinguishes current VLMs from humans.

</details>


### [263] [UniAPL: A Unified Adversarial Preference Learning Framework for Instruct-Following](https://arxiv.org/abs/2509.25148)
*FaQiang Qian,WeiKun Zhang,Ziliang Wang,Kang An,Xuhui Zheng,Liangjian Wen,Mengya Gao,Yong Dai,Yichao Wu*

Main category: cs.AI

TL;DR: UniAPL是一个统一的对齐学习框架，通过单阶段训练同时利用SFT数据和偏好数据，解决传统SFT+RL流程中的分布不匹配问题，在多个模型规模上实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统SFT后接RL的对齐方法存在关键问题：SFT使用静态专家数据，而策略演化时生成分布会漂移，导致SFT知识变得脆弱；后续RL无法直接访问专家演示中的丰富知识，导致效率低下和缺乏基础的更新。

Method: 将对齐重新定义为约束优化问题，提出UniAPL框架，实现单阶段统一训练目标，从混合的SFT和偏好数据批次中联合学习，让密集的专家演示直接基础和正则化在线探索。

Result: 在指令跟随任务上评估，使用Qwen3-235B作为教师模型。UniAPL匹配或超越强GRPO基线：Qwen3-0.6B提升5.77%（匹配32B模型），Qwen3-4B提升3.75%，甚至超越了教师模型。

Conclusion: UniAPL通过统一的对齐学习框架有效解决了分布不匹配问题，实现了更强的性能和更好的行为对齐，输出更接近专家演示。

Abstract: Shaping powerful LLMs to be beneficial and safe is central to AI alignment.
We argue that post-training alignment is fundamentally a unified Preference
Learning problem, involving two modalities: demonstrated preferences (e.g.,
Supervised Fine-Tuning, SFT) and comparative preferences (e.g., Reinforcement
Learning, RL).The standard sequential pipeline-SFT followed by RL-is flawed due
to a critical distributional mismatch: SFT uses static expert data, but as the
policy evolves, its generation distribution drifts, making SFT knowledge
brittle. Subsequent RL then explores without direct access to the rich,
ground-truth knowledge in expert demonstrations, leading to inefficient,
ungrounded updates. This separation prevents mutual regularization between data
sources. To address this, we reframe alignment as a constrained optimization
problem and propose Unified Adversarial Preference Learning (UniAPL),a novel
framework that dynamically aligns the policy's distribution with the expert's.
UniAPL implements a single-stage unified training objective, jointly learning
from mixed batches of SFT and preference data. In every gradient step, dense
expert demonstrations directly ground and regularize online exploration,
inherently resolving distributional mismatch and maximizing data synergy.We
evaluate UniAPL on instruction-following tasks using Qwen3-235B-Instruct-2507
as the teacher. Our models match or exceed strong GRPO baselines: +5.77% on
Qwen3-0.6B (matching a 32B model) and +3.75% on Qwen3-4B,even outperforming the
teacher. Analyses of response length and log-probability distributions confirm
that UniAPL outputs closely mimic expert demonstrations, achieving both
stronger performance and better behavioral alignment.

</details>


### [264] [Who's Your Judge? On the Detectability of LLM-Generated Judgments](https://arxiv.org/abs/2509.25154)
*Dawei Li,Zhen Tan,Chengshuai Zhao,Bohan Jiang,Baixiang Huang,Pingchuan Ma,Abdullah Alnaibari,Kai Shu,Huan Liu*

Main category: cs.AI

TL;DR: 提出并形式化了判断检测任务，系统研究LLM生成判断的可检测性，开发了轻量级检测器J-Detector，通过显式提取特征来准确检测LLM生成的判断。


<details>
  <summary>Details</summary>
Motivation: LLM生成的判断存在固有偏见和脆弱性，在学术评审等敏感场景中需要区分这些判断，但现有LLM生成文本检测方法无法有效处理判断检测问题。

Method: 引入J-Detector，一种轻量透明的神经网络检测器，通过显式提取语言特征和LLM增强特征，将LLM法官的偏见与候选内容属性关联起来进行检测。

Result: 在多样化数据集上的实验证明了J-Detector的有效性，其可解释性能够量化LLM法官的偏见，验证了判断检测在实际场景中的实用性。

Conclusion: LLM生成判断的可检测性研究为敏感场景下的判断验证提供了有效解决方案，J-Detector在准确检测和偏见量化方面表现出色。

Abstract: Large Language Model (LLM)-based judgments leverage powerful LLMs to
efficiently evaluate candidate content and provide judgment scores. However,
the inherent biases and vulnerabilities of LLM-generated judgments raise
concerns, underscoring the urgent need for distinguishing them in sensitive
scenarios like academic peer reviewing. In this work, we propose and formalize
the task of judgment detection and systematically investigate the detectability
of LLM-generated judgments. Unlike LLM-generated text detection, judgment
detection relies solely on judgment scores and candidates, reflecting
real-world scenarios where textual feedback is often unavailable in the
detection process. Our preliminary analysis shows that existing LLM-generated
text detection methods perform poorly given their incapability to capture the
interaction between judgment scores and candidate content -- an aspect crucial
for effective judgment detection. Inspired by this, we introduce
\textit{J-Detector}, a lightweight and transparent neural detector augmented
with explicitly extracted linguistic and LLM-enhanced features to link LLM
judges' biases with candidates' properties for accurate detection. Experiments
across diverse datasets demonstrate the effectiveness of \textit{J-Detector}
and show how its interpretability enables quantifying biases in LLM judges.
Finally, we analyze key factors affecting the detectability of LLM-generated
judgments and validate the practical utility of judgment detection in
real-world scenarios.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [265] [Trust and Transparency in AI: Industry Voices on Data, Ethics, and Compliance](https://arxiv.org/abs/2509.22709)
*Louise McCormack,Diletta Huyskes,Dave Lewis,Malika Bendechache*

Main category: cs.CY

TL;DR: 欧盟AI法案要求企业评估AI系统以确保其以人为中心和可信赖的方式开发。研究发现AI的快速采用超过了伦理评估框架，导致在问责制、治理、数据质量、人类监督、技术稳健性以及环境和社会影响方面存在重大挑战。


<details>
  <summary>Details</summary>
Motivation: AI在行业中的快速采用超过了伦理评估框架，导致在问责制、治理、数据质量、人类监督、技术稳健性以及环境和社会影响方面存在重大挑战。欧盟AI法案要求企业评估AI系统以确保其以人为中心和可信赖的方式开发。

Method: 通过对15位行业专业人士进行结构化访谈，并结合对每个关键访谈发现的文献综述，研究可信赖AI开发和评估的实践方法和挑战。

Result: 研究发现风险管理、合规性和问责制方面存在复杂问题，这些问题因缺乏透明度、监管要求不明确以及AI实施仓促而加剧。参与者报告称技术稳健性和安全性可能因模型不准确、安全漏洞以及在没有适当保障措施的情况下过度依赖AI而受到损害。此外，AI的负面环境和社会影响，包括高能耗、政治极端化、文化丧失和社会不平等的加剧，也是关注领域。

Conclusion: 不仅需要在AI系统内进行风险缓解和可信赖AI评估，还需要采取更广泛的方法来发展符合采用这些技术国家的社会和文化价值观的AI格局。

Abstract: The EU Artificial Intelligence (AI) Act directs businesses to assess their AI
systems to ensure they are developed in a way that is human-centered and
trustworthy. The rapid adoption of AI in the industry has outpaced ethical
evaluation frameworks, leading to significant challenges in accountability,
governance, data quality, human oversight, technological robustness, and
environmental and societal impacts. Through structured interviews with fifteen
industry professionals, paired with a literature review conducted on each of
the key interview findings, this paper investigates practical approaches and
challenges in the development and assessment of Trustworthy AI (TAI). The
findings from participants in our study, and the subsequent literature reviews,
reveal complications in risk management, compliance and accountability, which
are exacerbated by a lack of transparency, unclear regulatory requirements and
a rushed implementation of AI. Participants reported concerns that
technological robustness and safety could be compromised by model inaccuracies,
security vulnerabilities, and an overreliance on AI without proper safeguards
in place. Additionally, the negative environmental and societal impacts of AI,
including high energy consumption, political radicalisation, loss of culture
and reinforcement of social inequalities, are areas of concern. There is a
pressing need not just for risk mitigation and TAI evaluation within AI systems
but for a wider approach to developing an AI landscape that aligns with the
social and cultural values of the countries adopting those technologies.

</details>


### [266] [Beyond Western Politics: Cross-Cultural Benchmarks for Evaluating Partisan Associations in LLMs](https://arxiv.org/abs/2509.22711)
*Divyanshu Kumar,Ishita Gupta,Nitin Aravind Birur,Tanay Baswa,Sahil Agarwal,Prashanth Harshangi*

Main category: cs.CY

TL;DR: 该研究超越传统政治倾向评估，聚焦于LLMs对政治领导人和党派的有害对抗性表征关联，通过创建NeutQA-440和AdverQA-440数据集在美国和印度语境下进行测试。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要从广义角度评估LLMs的政治偏见，且多集中于西方语境。本研究旨在深入探究模型对政治领导人和党派的有害对抗性表征关联，揭示系统性风险。

Method: 创建NeutQA-440（非对抗性提示）和AdverQA-440（对抗性提示）两个数据集，在美国和印度语境下测试模型对政治实体的比较合理性判断。

Result: 结果显示模型对偏见性党派关联高度敏感，存在明显不对称性（如对美国民主党的关联明显优于共和党），同时对印度人民党呈现混合极性集中。

Conclusion: 研究揭示了LLMs中存在的系统性风险，强调了进行标准化跨文化评估的必要性。

Abstract: Partisan bias in LLMs has been evaluated to assess political leanings,
typically through a broad lens and largely in Western contexts. We move beyond
identifying general leanings to examine harmful, adversarial representational
associations around political leaders and parties. To do so, we create datasets
\textit{NeutQA-440} (non-adversarial prompts) and \textit{AdverQA-440}
(adversarial prompts), which probe models for comparative plausibility
judgments across the USA and India. Results show high susceptibility to biased
partisan associations and pronounced asymmetries (e.g., substantially more
favorable associations for U.S. Democrats than Republicans) alongside
mixed-polarity concentration around India's BJP, highlighting systemic risks
and motivating standardized, cross-cultural evaluation.

</details>


### [267] [(When) Should We Delegate AI Governance to AIs? Some Lessons from Administrative Law](https://arxiv.org/abs/2509.22717)
*Nicholas Caputo*

Main category: cs.CY

TL;DR: 本文探讨了在AI治理中使用AI系统的风险与挑战，提出了基于行政法原则的委托框架，以确保AI治理的安全、问责和有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在治理中的广泛应用，人类可能无法理解AI决策或判断其是否与用户利益一致，委托可能削弱治理的合法性，因此需要建立原则性框架。

Method: 借鉴行政法原则，该法规定了何时可以委托、委托内容以及保持机构目标一致的过程，为AI治理提供安全、问责和有效的使用基础。

Result: 行政法原则为AI治理中的委托提供了明确的规则和过程，有助于确保AI系统的安全性和问责性。

Conclusion: 通过应用行政法的经验，AI治理可以在使用AI系统时实现安全、问责和有效性，避免委托带来的潜在危害。

Abstract: Advanced AI systems are now being used in AI governance. Practitioners will
likely delegate an increasing number of tasks to them as they improve and
governance becomes harder. However, using AI for governance risks serious harms
because human practitioners may not be able to understand AI decisions or
determine whether they are aligned to the user's interests. Delegation may also
undermine governance's legitimacy. This paper begins to develop a principled
framework for when to delegate AI governance to AIs and when (and how) to
maintain human participation. Administrative law, which governs agencies that
are (1) more expert in their domains than the legislatures that create them and
the courts that oversee them and (2) potentially misaligned to their original
goals, offers useful lessons. Administrative law doctrine provides examples of
clear, articulated rules for when delegation can occur, what delegation can
consist of, and what processes can keep agencies aligned even as they are
empowered to achieve their goals. The lessons of administrative law provide a
foundation for how AI governance can use AI in a safe, accountable, and
effective way.

</details>


### [268] [A Data-Driven Framework for Digital Transformation in Smart Cities: Integrating AI, Dashboards, and IoT Readiness](https://arxiv.org/abs/2509.22721)
*Ángel Lloret,Jesús Peral,Antonio Ferrández,María Auladell,Rafael Muñoz*

Main category: cs.CY

TL;DR: 提出了一种结合传统评估方法与人工智能技术的创新方法，用于自动评估公共部门组织的数字化转型水平。该方法采用双重方法：问卷调查和基于AI的模型（包括神经网络和Transformer架构），并在西班牙巴伦西亚社区的案例研究中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 数字化转型已成为公共行政的战略重点，需要提供更高效、以公民为中心的服务，并响应社会期望、ESG标准和联合国可持续发展目标。

Method: 采用双重方法：一方面对各类公共实体的专业人员进行调查问卷，另一方面使用基于AI的模型（包括神经网络和Transformer架构）自动评估组织的数字化转型水平。

Result: 该方法在西班牙巴伦西亚社区的本地公共行政案例研究中显示出有效的性能，能够成功评估数字化转型水平。

Conclusion: 虽然该方法在特定本地环境中得到验证，但其模块化结构和双源数据基础支持国际可扩展性。物联网、传感器网络和基于AI的分析等技术集成可以显著支持韧性、敏捷的城市环境，向更有效和可持续的智慧城市模式过渡。

Abstract: Digital transformation (DT) has become a strategic priority for public
administrations, particularly due to the need to deliver more efficient and
citizen-centered services and respond to societal expectations, ESG
(Environmental, Social, and Governance) criteria, and the United Nations
Sustainable Development Goals (UN SDGs). In this context, the main objective of
this study is to propose an innovative methodology to automatically evaluate
the level of digital transformation (DT) in public sector organizations. The
proposed approach combines traditional assessment methods with Artificial
Intelligence (AI) techniques. The methodology follows a dual approach: on the
one hand, surveys are conducted using specialized staff from various public
entities; on the other, AI-based models (including neural networks and
transformer architectures) are used to estimate the DT level of the
organizations automatically. Our approach has been applied to a real-world case
study involving local public administrations in the Valencian Community (Spain)
and shown effective performance in assessing DT. While the proposed methodology
has been validated in a specific local context, its modular structure and
dual-source data foundation support its international scalability,
acknowledging that administrative, regulatory, and DT maturity factors may
condition its broader applicability. The experiments carried out in this work
include (i) the creation of a domain-specific corpus derived from the surveys
and websites of several organizations, used to train the proposed models; (ii)
the use and comparison of diverse AI methods; and (iii) the validation of our
approach using real data. The integration of technologies such as the IoT,
sensor networks, and AI-based analytics can significantly support resilient,
agile urban environments and the transition towards more effective and
sustainable Smart City models.

</details>


### [269] [A Meta-Analysis of LLM Effects on Students across Qualification, Socialisation, and Subjectification](https://arxiv.org/abs/2509.22725)
*Jiayu Huang,Ruoxin Ritter Wang,Jen-Hao Liu,Boming Xia,Yue Huang,Ruoxi Sun,Jason,Xue,Jinan Zou*

Main category: cs.CY

TL;DR: 本文通过Biesta教育三要素框架分析133项研究发现：LLMs在教育中影响积极但不均衡，在资格获取方面效果显著，社会化效果不一，主体性发展仍脆弱，设计是关键决定因素。


<details>
  <summary>Details</summary>
Motivation: 重新思考LLMs在教育中应有的影响，超越狭隘的性能指标，关注教育的更广泛目标。

Method: 基于Biesta教育三要素框架（资格、社会化、主体性），对133项实验和准实验研究进行元分析。

Result: LLMs对学生学习总体有积极但不均衡的影响：资格方面效果显著（特别是作为辅导者的持续干预），社会化效果多变，主体性发展脆弱且仅限于小规模长期研究。

Conclusion: 设计是决定性因素，缺乏参与和能动性支架的LLMs会偏向易于测量的目标而忽视教育的更广泛目标。问题不仅是LLMs是否有效，更是它们能开启或关闭什么样的未来。

Abstract: Large language models (LLMs) are increasingly positioned as solutions for
education, yet evaluations often reduce their impact to narrow performance
metrics. This paper reframes the question by asking "what kind of impact should
LLMs have in education?" Drawing on Biesta's tripartite account of good
education: qualification, socialisation, and subjectification, we present a
meta-analysis of 133 experimental and quasi-experimental studies (k = 188).
Overall, the impact of LLMs on student learning is positive but uneven. Strong
effects emerge in qualification, particularly when LLMs function as tutors in
sustained interventions. Socialisation outcomes appear more variable,
concentrated in sustained, reflective interventions. Subjectification, linked
to autonomy and learner development, remains fragile, with improvements
confined to small-scale, long-term studies. This purpose-level view highlights
design as the decisive factor: without scaffolds for participation and agency,
LLMs privilege what is easiest to measure while neglecting broader aims of
education. For HCI and education, the issue is not just whether LLMs work, but
what futures they enable or foreclose.

</details>


### [270] [Automated Formative Feedback for Short-form Writing: An LLM-Driven Approach and Adoption Analysis](https://arxiv.org/abs/2509.22734)
*Tiago Fernandes Tavares,Luciano Pereira Soares*

Main category: cs.CY

TL;DR: 开发了基于LLM的AI反馈工具用于工程Capstone项目中的双周报告，初期采用率低但使用该工具的学生报告质量得到提升，并展示了识别学生组织任务的新方法。


<details>
  <summary>Details</summary>
Motivation: 在工程Capstone项目中，学生需要提交双周报告但缺乏及时反馈，开发AI工具旨在提供个性化反馈以改善报告完整性和质量。

Method: 开发LLM驱动的工具为学生草稿报告提供个性化反馈，通过两轮使用数据评估采用情况和效果。

Result: 初期采用率低显示学生对工具存在怀疑，但使用该工具的学生能够有效利用它，改善了报告的完整性和质量，同时工具还能识别学生的组织任务。

Conclusion: 虽然初期采用有限，但AI驱动工具具有为学生和教授提供有价值见解和形成性支持的潜力。

Abstract: This paper explores the development and adoption of AI-based formative
feedback in the context of biweekly reports in an engineering Capstone program.
Each student is required to write a short report detailing their individual
accomplishments over the past two weeks, which is then assessed by their
advising professor. An LLM-powered tool was developed to provide students with
personalized feedback on their draft reports, guiding them toward improved
completeness and quality. Usage data across two rounds revealed an initial
barrier to adoption, with low engagement rates. However, students who engaged
in the AI feedback system demonstrated the ability to use it effectively,
leading to improvements in the completeness and quality of their reports.
Furthermore, the tool's task-parsing capabilities provided a novel approach to
identify potential student organizational tasks and deliverables. The findings
suggest initial skepticism toward the tool with a limited adoption within the
studied context, however, they also highlight the potential for AI-driven tools
to provide students and professors valuable insights and formative support.

</details>


### [271] [Regulating the Agency of LLM-based Agents](https://arxiv.org/abs/2509.22735)
*Seán Boddy,Joshua Joseph*

Main category: cs.CY

TL;DR: 提出了一个测量和控制基于大语言模型(LLM)的AI代理机构性的方法，将其概念化为独立于智能度量的系统属性，并通过表示工程进行测量和控制。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的AI代理能力不断增强，由不对齐和失控引起的潜在危害日益严重，需要直接测量和控制这些系统的机构性来应对风险。

Method: 将AI代理机构性概念化为包含偏好刚性、独立操作和目标持久性三个维度的系统属性，采用表示工程方法来测量和控制LLM代理的机构性。

Result: 开发了监管工具：强制测试协议、领域特定机构性限制、基于机构性定价风险的保险框架，以及防止社会规模风险的机构性上限。

Conclusion: 该方法有助于减少"科学家AI"范式所激励的风险，同时仍能从有限的代理行为中获益，是降低AI风险的重要一步。

Abstract: As increasingly capable large language model (LLM)-based agents are
developed, the potential harms caused by misalignment and loss of control grow
correspondingly severe. To address these risks, we propose an approach that
directly measures and controls the agency of these AI systems. We conceptualize
the agency of LLM-based agents as a property independent of
intelligence-related measures and consistent with the interdisciplinary
literature on the concept of agency. We offer (1) agency as a system property
operationalized along the dimensions of preference rigidity, independent
operation, and goal persistence, (2) a representation engineering approach to
the measurement and control of the agency of an LLM-based agent, and (3)
regulatory tools enabled by this approach: mandated testing protocols,
domain-specific agency limits, insurance frameworks that price risk based on
agency, and agency ceilings to prevent societal-scale risks. We view our
approach as a step toward reducing the risks that motivate the ``Scientist AI''
paradigm, while still capturing some of the benefits from limited agentic
behavior.

</details>


### [272] [Societal Capacity Assessment Framework: Measuring Resilience to Inform Advanced AI Risk Management](https://arxiv.org/abs/2509.22742)
*Milan Gandhi,Peter Cihon,Owen Larter,Rebecca Anselmetti*

Main category: cs.CY

TL;DR: 提出了社会能力评估框架（SCAF），这是一个基于指标的评估方法，用于衡量社会在面对AI相关风险时的脆弱性、应对能力和适应能力。


<details>
  <summary>Details</summary>
Motivation: 高级AI系统的风险评估需要同时评估模型本身及其部署环境，以弥合AI评估中的'情境差距'。

Method: SCAF采用基于指标的评估方法，将成熟的韧性分析方法应用于AI领域，帮助组织基于国家层面的部署条件进行风险管理。

Result: 该框架能够支持利益相关者识别加强社会对新兴AI能力准备度的机会，促进更全面的风险评估和治理。

Conclusion: SCAF通过连接不同文献和弥合AI评估中的情境差距，为全球范围内高级AI系统的扩散提供了更全面的风险评估和治理方法。

Abstract: Risk assessments for advanced AI systems require evaluating both the models
themselves and their deployment contexts. We introduce the Societal Capacity
Assessment Framework (SCAF), an indicators-based approach to measuring a
society's vulnerability, coping capacity, and adaptive capacity in response to
AI-related risks. SCAF adapts established resilience analysis methodologies to
AI, enabling organisations to ground risk management in insights about
country-level deployment conditions. It can also support stakeholders in
identifying opportunities to strengthen societal preparedness for emerging AI
capabilities. By bridging disparate literatures and the "context gap" in AI
evaluation, SCAF promotes more holistic risk assessment and governance as
advanced AI systems proliferate globally.

</details>


### [273] [Scaling Accessibility Education: Reflections from a Workshop Targeting CS Educators and Software Professionals](https://arxiv.org/abs/2509.22759)
*P D Parthasarathy,Anshu M Mittal,Swaroop Joshi*

Main category: cs.CY

TL;DR: 印度数字可访问性培训存在显著差距，研究者设计并实施了一个为期一天的体验式工作坊，面向77名计算机科学教师和行业从业者，通过实践活动、工具演示和案例研究提升可访问性实践能力。


<details>
  <summary>Details</summary>
Motivation: 尽管全球对数字可访问性的关注日益增长，但印度在计算教育者和软件专业人员的可访问性培训方面存在显著差距，需要解决这一需求。

Method: 设计并实施为期一天的体验式工作坊，结合实践活动、工具演示和案例研究，培养参与者的可访问性实践基础能力。

Result: 工作坊后反馈显示，大多数参与者对工作坊评价积极，许多人报告信心增强，并将可访问性视为共同责任。参与者强烈希望在职场应用可访问性原则。

Conclusion: 该工作坊在印度计算教育和专业领域加强可访问性能力方面具有实际相关性和影响力，为未来类似倡议提供了可操作的见解。

Abstract: Despite growing global attention to digital accessibility, research from
India highlights a significant gap in accessibility training for both computing
educators and software professionals. To address this need, we designed and
conducted an experiential workshop aimed at building foundational capacity in
accessibility practices among 77 participants, including computer science (CS)
faculty and industry practitioners. The one-day workshop combined hands-on
activities, tool demonstrations, and case studies to foster practical
understanding and engagement. Post-workshop feedback showed that a majority of
participants rated the workshop positively, with many reporting increased
confidence and a shift in their perception of accessibility as a shared
responsibility. Additionally, participants expressed a strong interest in
applying accessibility principles within their workplaces, underscoring the
workshop's practical relevance and impact. In this experience report, we detail
the workshop's design, implementation, and evaluation, and offer actionable
insights to guide future initiatives aimed at strengthening accessibility
capacity across India's computing education and professional landscape.

</details>


### [274] [Anti-Regulatory AI: How "AI Safety" is Leveraged Against Regulatory Oversight](https://arxiv.org/abs/2509.22872)
*Rui-Jie Yew,Brian Judge*

Main category: cs.CY

TL;DR: 本文分析了AI公司开发的隐私增强技术、偏见约束措施、评估框架和对齐技术的双重功能：表面上解决隐私、公平和安全问题，实际上作为法律影响的机制来规避或改变监管框架。


<details>
  <summary>Details</summary>
Motivation: 研究AI公司如何通过表面上保护性的技术来影响和规避监管，揭示这些技术的反监管功能及其背后的商业动机。

Method: 首先分析加密、联邦学习和合成数据等技术如何作为规避机制绕过现有监管；其次研究开源模型发布、评估和对齐技术如何作为改变机制将监管重点转向行业自愿标准。

Result: 发现这些技术具有反监管功能，通过合法化框架掩盖其作为监管绕道的使用，揭示了技术部署背后的商业激励。

Conclusion: 政策制定需要考虑驱动AI开发的商业激励，并依赖技术专业知识来评估这些技术是否真正实现了其声称的保护功能。

Abstract: AI companies increasingly develop and deploy privacy-enhancing technologies,
bias-constraining measures, evaluation frameworks, and alignment techniques --
framing them as addressing concerns related to data privacy, algorithmic
fairness, and AI safety. This paper examines the ulterior function of these
technologies as mechanisms of legal influence. First, we examine how
encryption, federated learning, and synthetic data -- presented as enhancing
privacy and reducing bias -- can operate as mechanisms of avoidance with
existing regulations in attempts to place data operations outside the scope of
traditional regulatory frameworks. Second, we investigate how emerging AI
safety practices including open-source model releases, evaluations, and
alignment techniques can be used as mechanisms of change that direct regulatory
focus towards industry-controlled voluntary standards and self-governance. We
term this phenomenon anti-regulatory AI -- the deployment of ostensibly
protective technologies that simultaneously shapes the terms of regulatory
oversight. Our analysis additionally reveals how technologies' anti-regulatory
functions are enabled through framing that legitimizes their deployment while
obscuring their use as regulatory workarounds. This paper closes with a
discussion of policy implications that centers on the consideration of business
incentives that drive AI development and the role of technical expertise in
assessing whether these technologies fulfill their purported protections.

</details>


### [275] [Student Engagement with GenAI's Tutoring Feedback: A Mixed Methods Study](https://arxiv.org/abs/2509.22974)
*Sven Jacobs,Jan Haas,Natalie Kiesler*

Main category: cs.CY

TL;DR: 研究探讨了学生在编程教育中如何利用即时辅导反馈，发现学生反馈参与度与反馈质量、视觉注意力、思维过程和行动之间存在明确关系。


<details>
  <summary>Details</summary>
Motivation: 目前关于学生如何参与不同类型辅导反馈的研究有限，需要深入了解学生在编程任务中如何感知、解释和使用AI生成的即时反馈。

Method: 开发了一个提供Python编程任务和AI生成即时辅导反馈的学习环境，采用混合方法（出声思维研究和眼动追踪）对20名编程入门课程的本科生进行研究。

Result: 分析380个反馈组件发现四个主要主题：学生表达理解或不同意、需要额外信息、明确评判反馈。理解表达与改进相关，不同意或需要更多信息则促使学生收集其他反馈而非行动。

Conclusion: 研究揭示了学生参与反馈和决策过程，为工具开发者和教育者提供了关于如何促进反馈的重要启示。

Abstract: How students utilize immediate tutoring feedback in programming education
depends on various factors. Among them are the feedback quality, but also
students' engagement, i.e., their perception, interpretation, and use of
feedback. However, there is limited research on how students engage with
various types of tutoring feedback. For this reason, we developed a learning
environment that provides students with Python programming tasks and various
types of immediate, AI-generated tutoring feedback. The feedback is displayed
within four components. Using a mixed-methods approach (think-aloud study and
eye-tracking), we conducted a study with 20 undergraduate students enrolled in
an introductory programming course. Our research aims to: (1) identify what
students think when they engage with the tutoring feedback components, and (2)
explore the relations between the tutoring feedback components, students'
visual attention, verbalized thoughts, and their immediate actions as part of
the problem-solving process. The analysis of students' thoughts while engaging
with 380 feedback components revealed four main themes: students express
understanding or disagreement, additional information needed, and students
explicitly judge the feedback. Exploring the relations between feedback,
students' attention, thoughts, and actions showed a clear relationship. While
expressions of understanding were associated with improvements, expressions of
disagreement or need for additional information prompted students to collect
another feedback component rather than act on the current information. These
insights into students' engagement and decision-making processes contribute to
an increased understanding of tutoring feedback and how students engage with
it. Thereby, this work has implications for tool developers and educators
facilitating feedback.

</details>


### [276] [Skill, Will, or Both? Understanding Digital Inaccessibility from Accessibility Professionals' Viewpoint](https://arxiv.org/abs/2509.23287)
*P D Parthasarathy,Rachel F. Adler,Devorah Kletenik,Swaroop Joshi,Anshu M Mittal*

Main category: cs.CY

TL;DR: 该论文调查了160名无障碍专业人士，从他们的视角分析数字无障碍的持续挑战，包括组织意愿、实施困难和培训实践。


<details>
  <summary>Details</summary>
Motivation: 数字无障碍仍然是实现真正包容和平等的重大障碍，WebAIM 2024报告显示仅有4.1%的顶级网站主页完全无障碍，且过去五年WCAG失败率仅下降1.9%。

Method: 对160名无障碍专业人士进行综合调查，不同于以往研究技术专业人士，本研究专门从无障碍专业人士视角分析问题。

Result: 调查探讨了(a)组织优先考虑无障碍的意愿，(b)确保无障碍的挑战，(c)当前技术工作场所的无障碍培训实践。

Conclusion: 本研究旨在从无障碍专业人士的视角提供关于数字无障碍现状的最新观点。

Abstract: Digital inaccessibility continues to be a significant barrier to true
inclusion and equality. WebAIM's 2024 report reveals that only 4.1% of the
world's top one million website homepages are fully accessible. Furthermore,
the percentage of web pages with detectable Web Content Accessibility
Guidelines (WCAG) failures has only decreased by 1.9\% over the past five
years, from 97.8%. To gain deeper insights into the persistent challenges of
digital accessibility, we conducted a comprehensive survey with 160
accessibility professionals. Unlike previous studies, which often focused on
technology professionals, our research examines inaccessibility through the
lens of dedicated accessibility professionals, offering a more detailed
analysis of the barriers they face. Our investigation explores (a)
organizations' willingness to prioritize accessibility, (b) the challenges in
ensuring accessibility, and (c) the current accessibility training practices in
technology workspaces. This study aims to provide an updated perspective on the
state of digital accessibility from the point of view of accessibility
professionals.

</details>


### [277] [AI Education in Higher Education: A Taxonomy for Curriculum Reform and the Mission of Knowledge](https://arxiv.org/abs/2509.23363)
*Tian Zheng*

Main category: cs.CY

TL;DR: 本文提出了一个分类法来组织AI教育中的多样化叙事，将AI置于高等教育的知识使命框架内，强调课程改革是应对AI挑战的核心杠杆。


<details>
  <summary>Details</summary>
Motivation: 当前关于AI在高等教育中的讨论缺乏统一框架，混合了教学法、运营、课程和未来工作等不同层面的关切。本文旨在提供一个分类法来组织这些叙事，并指导基于学科的课程讨论。

Method: 通过构建分类法框架，将AI教育叙事置于高等教育的知识使命中，分析学科如何通过研究、课程、教学法和教师专业知识的相互作用而演变。

Result: 提出了一个结构化框架，将AI定义为自适应、数据驱动的系统，强调其作为赋能者和颠覆者的双重角色，并展示了课程改革在应对AI挑战中的核心地位。

Conclusion: 有意义的改革可以通过结构化的教师发展路径实现：从AI素养到教学法、课程设计和研究整合，关键在于将这些路径与知识使命对齐，将AI的颠覆性压力转化为学科维持专业知识、推进探究和服务社会的机会。

Abstract: Artificial intelligence (AI) is reshaping higher education, yet current
debates often feel tangled, mixing concerns about pedagogy, operations,
curriculum, and the future of work without a shared framework. This paper
offers a first attempt at a taxonomy to organize the diverse narratives of AI
education and to inform discipline-based curricular discussions. We place these
narratives within the enduring responsibility of higher education: the mission
of knowledge. This mission includes not only the preservation and advancement
of disciplinary expertise, but also the cultivation of skills and wisdom, i.e.,
forms of meta-knowledge that encompass judgment, ethics, and social
responsibility. For the purpose of this paper's discussion, AI is defined as
adaptive, data-driven systems that automate analysis, modeling, and
decision-making, highlighting its dual role as enabler and disruptor across
disciplines. We argue that the most consequential challenges lie at the level
of curriculum and disciplinary purpose, where AI accelerates inquiry but also
unsettles expertise and identity. We show how disciplines evolve through the
interplay of research, curriculum, pedagogy, and faculty expertise, and why
curricular reform is the central lever for meaningful change. Pedagogical
innovation offers a strategic and accessible entry point, providing actionable
steps that help faculty and students build the expertise needed to engage in
deeper curricular rethinking and disciplinary renewal. Within this framing, we
suggest that meaningful reform can move forward through structured faculty
journeys: from AI literacy to pedagogy, curriculum design, and research
integration. The key is to align these journeys with the mission of knowledge,
turning the disruptive pressures of AI into opportunities for disciplines to
sustain expertise, advance inquiry, and serve society.

</details>


### [278] [Digital welfare fraud detection and the Dutch SyRI judgment](https://arxiv.org/abs/2509.23843)
*Marvin van Bekkum,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 荷兰法院裁定SyRI福利欺诈检测系统违法，因违反欧洲人权公约的隐私权，这是首批因侵犯隐私权而否决福利欺诈检测系统的判决之一。


<details>
  <summary>Details</summary>
Motivation: 分析SyRI判决及其影响，探讨自动化欺诈检测系统与隐私权的冲突。

Method: 通过分析法院判决内容和法律依据，评估其对数据保护和隐私权的影响。

Result: 判决的直接效果有限，仅针对个案情况，但强调了欺诈检测必须遵守数据保护原则和隐私权。

Conclusion: 判决提醒政策制定者在使用个人数据时必须保持透明度，并尊重数据保护原则，对未来的自动化系统监管具有重要参考价值。

Abstract: In 2020, a Dutch court passed judgment in a case about a digital welfare
fraud detection system called Systeem Risico Indicatie (SyRI). The court ruled
that the SyRI legislation is unlawful because it does not comply with the right
to privacy under the European Convention of Human Rights. In this article we
analyse the judgment and its implications. This ruling is one of first in which
a court has invalidated a welfare fraud detection system for breaching the
right to privacy. We show that the immediate effects of the judgment are
limited. The judgment does not say much about automated fraud detection systems
in general, because it is limited to the circumstances of the case. Still, the
judgment is important. The judgment reminds policymakers that fraud detection
must happen in a way that respects data protection principles and the right to
privacy. The judgment also confirms the importance of transparency if personal
data are used.

</details>


### [279] [Opinions can be Incorrect! In our Opinion. On the accuracy principle in data protection law](https://arxiv.org/abs/2509.23848)
*Dara Hallinan,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文论证GDPR的准确性原则适用于个人数据中的意见信息，包括从实证法和规范角度两方面分析。


<details>
  <summary>Details</summary>
Motivation: 针对有人认为GDPR的准确性原则不适用于个人意见数据的观点，作者提出不同见解，认为这一原则应当且确实适用于意见数据。

Method: 采用实证法分析和规范分析的双重方法，从法律条文解释和理论原则两个层面进行论证。

Result: 论证表明准确性原则确实适用于个人意见数据，且从规范角度也应当如此适用。

Conclusion: GDPR的准确性原则应当且确实适用于个人数据中的意见信息，这对数据控制者提出了更高的准确性保障要求。

Abstract: The GDPR contains an accuracy principle, as most data privacy laws in the
world do. In principle, data controllers must ensure that personal data they
use are accurate. Some have argued that the accuracy principle does not apply
to personal data in the form of opinions about data subjects. We argue,
however, from a positive law perspective, that the accuracy principle does
apply to opinions. We further argue, from a normative perspective, that the
accuracy principle should apply to opinions.

</details>


### [280] [Price discrimination, algorithmic decision-making, and European non-discrimination law](https://arxiv.org/abs/2509.23851)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文探讨算法决策（以在线价格差异化为例）如何导致间接歧视，以及现有非歧视法律在应对算法歧视方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 算法决策虽然能为社会带来巨大利益，但也可能产生歧视性影响。本文旨在研究非歧视法律能在多大程度上保护人们免受在线价格差异化的歧视。

Method: 以在线价格差异化为案例，分析算法决策如何导致间接歧视，并评估现有非歧视法律框架的适用性。

Result: 研究发现在线价格差异化和算法决策确实可能导致间接歧视（如对特定族群的伤害），但现有非歧视法律在应对算法歧视方面存在缺陷，包括歧视行为可能被隐藏，以及许多不公平的算法决策超出当前法律范围。

Conclusion: 非歧视法律原则上禁止间接歧视，但在应用于算法决策时存在重大局限性，需要法律框架的更新和完善来有效应对算法时代的歧视问题。

Abstract: Our society can benefit immensely from algorithmic decision-making and
similar types of artificial intelligence. But algorithmic decision-making can
also have discriminatory effects. This paper examines that problem, using
online price differentiation as an example of algorithmic decision-making. With
online price differentiation, a company charges different people different
prices for identical products, based on information the company has about those
people. The main question in this paper is: to what extent can
non-discrimination law protect people against online price differentiation? The
paper shows that online price differentiation and algorithmic decision-making
could lead to indirect discrimination, for instance harming people with a
certain ethnicity. Indirect discrimination occurs when a practice is neutral at
first glance, but ends up discriminating against people with a protected
characteristic, such as ethnicity. In principle, non-discrimination law
prohibits indirect discrimination. The paper also shows, however, that
non-discrimination law has flaws when applied to algorithmic decision-making.
For instance, algorithmic discrimination can remain hidden: people may not
realise that they are being discriminated against. And many types of unfair -
some might say discriminatory - algorithmic decisions are outside the scope of
current non-discrimination law.

</details>


### [281] [Open Opportunities in AI Safety, Alignment, and Ethics (AI SAE)](https://arxiv.org/abs/2509.24065)
*Dylan Waldner*

Main category: cs.CY

TL;DR: 该论文提出将伦理作为AI对齐的结构性视角，引入"道德问题空间"概念，将人类道德推理视为压缩且有生存偏见的投影，并探讨了将伦理嵌入表征基质的可能方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全研究强调可解释性、控制和鲁棒性，但缺乏伦理基础可能导致这些方法在竞争性和开放式压力下变得脆弱。

Method: 引入道德问题空间M的概念框架，使用稀疏自编码器、因果中介分析和跨文化语料库等方法探测解耦的道德特征，将元伦理立场解释为研究方向。

Result: 提出了一个研究议程，将伦理直接嵌入表征基质可以使哲学主张更易于实证研究，将道德理论定位为对齐工作的假设来源。

Conclusion: 伦理不应作为外部附加物，而应作为对齐的结构性视角，通过将道德理论转化为可检验的假设来推进AI对齐研究。

Abstract: AI safety research has emphasized interpretability, control, and robustness,
yet without an ethical substrate these approaches may remain fragile under
competitive and open-ended pressures. This paper explores ethics not as an
external add-on, but as a possible structural lens for alignment, introducing a
\emph{moral problem space} $M$: a high-dimensional domain in which moral
distinctions could, in principle, be represented in AI systems. Human moral
reasoning is treated as a compressed and survival-biased projection
$\tilde{M}$, clarifying why judgment is inconsistent while suggesting tentative
methods -- such as sparse autoencoders, causal mediation, and cross-cultural
corpora -- that might help probe for disentangled moral features. Within this
framing, metaethical positions are interpreted as research directions: realism
as the search for stable invariants, relativism as context-dependent
distortions, constructivism as institutional shaping of persistence, and virtue
ethics as dispositional safeguards under distributional shift. Evolutionary
dynamics and institutional design are considered as forces that may determine
whether ethical-symbiotic lineages remain competitively viable against more
autarkic trajectories. Rather than offering solutions, the paper sketches a
research agenda in which embedding ethics directly into representational
substrates could serve to make philosophical claims more empirically
approachable, positioning moral theory as a potential source of hypotheses for
alignment work.

</details>


### [282] [Regulating Online Algorithmic Pricing: A Comparative Study of Privacy and Data Protection Laws in the EU and US](https://arxiv.org/abs/2509.24345)
*Zihao Li*

Main category: cs.CY

TL;DR: 本文比较分析了欧盟和美国对在线算法定价的监管框架，探讨各自数据保护和隐私法律如何应对算法定价带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大数据、AI和机器学习的发展，在线算法定价虽然能提高效率和市场福利，但也威胁到隐私、数字自主权和非歧视等基本价值，引发法律和伦理担忧。

Method: 采用比较分析方法，研究欧盟GDPR、数字服务法和数字市场法，以及美国联邦和州级法律的监管框架。

Result: 欧盟采用综合性方法监管算法定价，美国则结合联邦和州法律并侧重行业监管。两种方法各有特点，但都需要完善以有效保护个人权益。

Conclusion: 需要比较分析两种法律框架的有效性，相互借鉴经验，以更好地应对在线算法定价带来的挑战。

Abstract: The emergence of big data, AI and machine learning has allowed sellers and
online platforms to tailor pricing for customers in real-time. While online
algorithmic pricing can increase efficiency, market welfare, and optimize
pricing strategies for sellers and companies, it poses a threat to the
fundamental values of privacy, digital autonomy, and non-discrimination,
raising legal and ethical concerns. On both sides of the Atlantic, legislators
have endeavoured to regulate online algorithmic pricing in different ways in
the context of privacy and personal data protection. Represented by the GDPR,
the EU adopts an omnibus approach to regulate algorithmic pricing and is
supplemented by the Digital Service Act and the Digital Market Act. The US
combines federal and state laws to regulate online algorithmic pricing and
focuses on industrial regulations. Therefore, a comparative analysis of these
legal frameworks is necessary to ascertain the effectiveness of these
approaches. Taking a comparative approach, this working paper aims to explore
how EU and US respective data protection and privacy laws address the issues
posed by online algorithmic pricing. The paper evaluates whether the current
legal regime is effective in protecting individuals against the perils of
online algorithmic pricing in the EU and the US. It particularly analyses the
new EU regulatory paradigm, the Digital Service Act (DSA) and the Digital
Market Act (DMA), as supplementary mechanisms to the EU data protection law, in
order to draw lessons for US privacy law and vice versa.

</details>


### [283] [The 2025 OpenAI Preparedness Framework does not guarantee any AI risk mitigation practices: a proof-of-concept for affordance analyses of AI safety policies](https://arxiv.org/abs/2509.24394)
*Sam Coggins,Alex Saeri,Katherine A. Daniell,Lorenn P. Ruster,Jessie Liu,Jenny L. Davis*

Main category: cs.CY

TL;DR: 分析OpenAI安全框架发现其仅评估少数AI风险，鼓励部署具有中等能力的系统，并允许CEO部署更危险能力，表明需要更强治理干预。


<details>
  <summary>Details</summary>
Motivation: 理解AI公司自愿安全框架实际覆盖的风险范围和管理措施，评估这些框架如何真正治理AI开发与部署。

Method: 运用可供性理论，采用机制与条件模型和MIT AI风险库，分析OpenAI'准备框架第二版'。

Result: 发现该安全政策仅请求评估少数AI风险，鼓励部署具有'中等'能力的系统（OpenAI自定义为可能导致>1000人死亡或>$1000亿损失），并允许CEO部署更危险能力。

Conclusion: 有效缓解AI风险需要超越当前行业自我监管的更强大治理干预，可供性分析为评估安全框架实际许可与声称内容提供了可复制方法。

Abstract: Prominent AI companies are producing 'safety frameworks' as a type of
voluntary self-governance. These statements purport to establish risk
thresholds and safety procedures for the development and deployment of highly
capable AI. Understanding which AI risks are covered and what actions are
allowed, refused, demanded, encouraged, or discouraged by these statements is
vital for assessing how these frameworks actually govern AI development and
deployment. We draw on affordance theory to analyse the OpenAI 'Preparedness
Framework Version 2' (April 2025) using the Mechanisms & Conditions model of
affordances and the MIT AI Risk Repository. We find that this safety policy
requests evaluation of a small minority of AI risks, encourages deployment of
systems with 'Medium' capabilities for what OpenAI itself defines as 'severe
harm' (potential for >1000 deaths or >$100B in damages), and allows OpenAI's
CEO to deploy even more dangerous capabilities. These findings suggest that
effective mitigation of AI risks requires more robust governance interventions
beyond current industry self-regulation. Our affordance analysis provides a
replicable method for evaluating what safety frameworks actually permit versus
what they claim.

</details>


### [284] [Legal Matters in Research Software: A Few Things Worth Discussing](https://arxiv.org/abs/2509.24646)
*Giuditta Parolini*

Main category: cs.CY

TL;DR: 该论文讨论了研究软件开发中的法律问题，包括知识产权、软件许可、版权归属、责任不确定性，以及AI编程助手的使用和欧盟AI法规的影响。


<details>
  <summary>Details</summary>
Motivation: 旨在提高对软件开发法律问题的理解，以正确评估研究软件作为科学进步驱动力的价值。

Method: 通过分析研究软件工程师处理法律问题的实际方法，考虑知识产权权利、软件许可选择、版权持有者识别、责任不确定性等法律方面。

Result: 指出了研究机构在法律事务支持方面的差异，以及在缺乏机构政策情况下AI编程助手的广泛使用问题。

Conclusion: 更好地理解软件开发相关的法律问题有助于为研究软件赋予其作为科学进步驱动者应有的价值。

Abstract: The paper discusses legal aspects relevant to the development of research
software and practical approaches taken by research software engineers to deal
with them. Intellectual Property Rights on software are considered alongside
licensing choices made by the research community. The discussion addresses the
ambiguities in the identification of the copyright holder of research software,
the uncertainty surrounding liability, and remarks the varying level of support
on legal matters provided by research organisations. The paper also reflects on
the widespread use of AI coding assistants in the absence of institutional
policies, and on the new AI regulations passed by the European Union. The aim
of the contribution is to point out that a better understanding of legal
matters concerning software development is an asset in giving research software
the right value it deserves as a driver of scientific progress.

</details>


### [285] [Learning from Convenience Samples: A Case Study on Fine-Tuning LLMs for Survey Non-response in the German Longitudinal Election Study](https://arxiv.org/abs/2509.25063)
*Tobias Holtdirk,Dennis Assenmacher,Arnim Bleier,Claudia Wagner*

Main category: cs.CY

TL;DR: 研究探讨了在存在部分调查数据的情况下，使用微调的大型语言模型来估算自报投票选择，在随机和系统性无响应情况下表现优于零样本方法，并在仅有偏差便利样本时能更准确地恢复个体预测和总体分布。


<details>
  <summary>Details</summary>
Motivation: 调查研究者面临两个关键挑战：概率样本成本上升和缺失数据（如无响应或流失），这会削弱推断能力并增加便利样本的使用。

Method: 使用德国纵向选举研究数据，在部分调查响应存在的情况下，对LLMs进行微调以估算自报投票选择，比较零样本提示和监督微调与表格分类器（如CatBoost）的表现，并测试不同便利样本对泛化的影响。

Result: 当数据完全随机缺失时，微调LLMs与表格分类器表现相当但优于零样本方法；当仅有偏差便利样本可用时，微调小型开源LLMs能更准确地恢复个体预测和总体分布。

Conclusion: 微调LLMs为处理非概率样本或系统性缺失的研究者提供了有前景的策略，可能实现仅需易获取子群体的新调查设计。

Abstract: Survey researchers face two key challenges: the rising costs of probability
samples and missing data (e.g., non-response or attrition), which can undermine
inference and increase the use of convenience samples. Recent work explores
using large language models (LLMs) to simulate respondents via persona-based
prompts, often without labeled data. We study a more practical setting where
partial survey responses exist: we fine-tune LLMs on available data to impute
self-reported vote choice under both random and systematic nonresponse, using
the German Longitudinal Election Study. We compare zero-shot prompting and
supervised fine-tuning against tabular classifiers (e.g., CatBoost) and test
how different convenience samples (e.g., students) used for fine-tuning affect
generalization.
  Our results show that when data are missing completely at random, fine-tuned
LLMs match tabular classifiers but outperform zero-shot approaches. When only
biased convenience samples are available, fine-tuning small (3B to 8B)
open-source LLMs can recover both individual-level predictions and
population-level distributions more accurately than zero-shot and often better
than tabular methods. This suggests fine-tuned LLMs offer a promising strategy
for researchers working with non-probability samples or systematic missingness,
and may enable new survey designs requiring only easily accessible
subpopulations.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [286] [Nonparametric and Semiparametric Estimation of Upward Rank Mobility Curves](https://arxiv.org/abs/2509.23174)
*Tsung-Chih Lai,Jia-Han Shih,Yi-Hau Chen*

Main category: econ.EM

TL;DR: 本文提出了向上等级流动性曲线作为衡量代际流动性的新指标，通过基于copula的非参数估计方法，发现美国数据中白人在中低收入家庭中比黑人具有显著更高的向上流动性。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地衡量代际收入流动性，特别是捕捉整个父母收入分布中的向上流动情况，并消除聚合偏差。

Method: 提出了基于copula的非参数估计方法，以及针对条件版本的两步半参数估计器，结合分布回归方法。

Result: 在美国数据应用中，发现白人在中低收入家庭中比黑人表现出显著更高的向上流动性优势。

Conclusion: 向上等级流动性曲线为代际流动性研究提供了更精确的衡量工具，揭示了不同种族群体在流动性方面的显著差异。

Abstract: We introduce the upward rank mobility curve as a new measure of
intergenerational mobility that captures upward movements across the entire
parental income distribution. Our approach extends Bhattacharya and Mazumder
(2011) by conditioning on a single parental income rank, thereby eliminating
aggregation bias. We show that the measure can be characterized solely by the
copula of parent and child income, and we propose a nonparametric copula-based
estimator with better properties than kernel-based alternatives. For a
conditional version of the measure without such a representation, we develop a
two-step semiparametric estimator based on distribution regression and
establish its asymptotic properties. An application to U.S. data reveals that
whites exhibit significant upward mobility dominance over blacks among
lower-middle-income families.

</details>


### [287] [Automatic Order, Bandwidth Selection and Flaws of Eigen Adjustment in HAC Estimation](https://arxiv.org/abs/2509.23256)
*Zhuoxun Li,Clifford M. Hurvich*

Main category: econ.EM

TL;DR: 提出了一种基于预白化核估计器和局部留一频域交叉验证的异方差和自相关一致协方差矩阵估计器，通过交叉验证对数似然函数同时选择预白化VAR阶数和带宽。


<details>
  <summary>Details</summary>
Motivation: Andrews和Monahan(1992)的特征值调整规则在回归变量具有非零均值时可能被不必要且有害地触发，需要更可靠的协方差矩阵估计方法。

Method: 使用预白化核估计器和局部留一频域交叉验证(FDCV)，通过交叉验证对数似然函数同时选择预白化VAR阶数和带宽，预白化VAR采用Burg方法估计且不使用特征值调整。

Result: 通过蒙特卡洛模拟和三个实证例子，说明了特征值调整的缺陷以及所提方法的可靠性。

Conclusion: 所提出的方法避免了特征值调整的不必要触发，提供了更可靠的异方差和自相关一致协方差矩阵估计。

Abstract: In this paper, we propose a new heteroskedasticity and autocorrelation
consistent covariance matrix estimator based on the prewhitened kernel
estimator and a localized leave-one-out frequency domain cross-validation
(FDCV). We adapt the cross-validated log likelihood (CVLL) function to
simultaneously select the order of the prewhitening vector autoregression (VAR)
and the bandwidth. The prewhitening VAR is estimated by the Burg method without
eigen adjustment as we find the eigen adjustment rule of Andrews and Monahan
(1992) can be triggered unnecessarily and harmfully when regressors have
nonzero mean. Through Monte Carlo simulations and three empirical examples, we
illustrate the flaws of eigen adjustment and the reliability of our method.

</details>


### [288] [Nowcasting and aggregation: Why small Euro area countries matter](https://arxiv.org/abs/2509.24780)
*Andrii Babii,Luca Barbaglia,Eric Ghysels,Jonas Striaukas*

Main category: econ.EM

TL;DR: 使用混合数据抽样机器学习面板数据回归方法，结合标准宏观数据和每日新闻数据，对欧元区GDP增长进行即时预测，比较直接预测欧元区总量与加权个体国家预测的效果。


<details>
  <summary>Details</summary>
Motivation: 研究如何更准确地即时预测欧元区GDP增长，探讨是否直接预测欧元区总量优于加权个体国家预测，特别是在COVID-19疫情期间，并评估新闻数据在官方统计数据滞后时的价值。

Method: 采用混合数据抽样机器学习面板数据回归方法，使用19个欧元区国家的面板数据，结合标准宏观发布数据和每日新闻数据，比较直接总量预测与加权个体预测方法。

Result: 结果显示小中型国家的信息对预测很重要，特别是在COVID-19疫情期间。从理论上证明，使用汇集面板数据回归预测的个体成分聚合优于直接总量预测，因为估计误差更低。

Conclusion: 在欧元区GDP即时预测中，通过面板数据回归预测个体国家然后聚合的方法优于直接预测总量，小中型国家的信息贡献显著，新闻数据在官方数据滞后时具有重要价值。

Abstract: The paper studies the nowcasting of Euro area Gross Domestic Product (GDP)
growth using mixed data sampling machine learning panel data regressions with
both standard macro releases and daily news data. Using a panel of 19 Euro area
countries, we investigate whether directly nowcasting the Euro area aggregate
is better than weighted individual country nowcasts. Our results highlight the
importance of the information from small- and medium-sized countries,
particularly when including the COVID-19 pandemic period. The empirical
analysis is supplemented by studying the so-called Big Four -- France, Germany,
Italy, and Spain -- and the value added of news data when official statistics
are lagging. From a theoretical perspective, we formally show that the
aggregation of individual components forecasted with pooled panel data
regressions is superior to direct aggregate forecasting due to lower estimation
error.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [289] [Two-Sided Fairness in Many-to-One Matching](https://arxiv.org/abs/2509.24111)
*Ayumi Igarashi,Naoyuki Kamiyama,Yasushi Kawase,Warut Suksompong,Hanna Sumita,Yu Yokoi*

Main category: econ.TH

TL;DR: 提出一种多项式时间算法，解决多对一匹配问题，同时保证参与者和团队的公平性，结合了匹配理论和公平分配的概念。


<details>
  <summary>Details</summary>
Motivation: 传统匹配文献主要关注参与者的公平性，而本文旨在同时为团队提供公平性保证，结合匹配理论和公平分配理论。

Method: 开发了一种多项式时间算法，该算法同时推广了Gale-Shapley算法和轮询算法，能够处理包含平局偏好的情况。

Result: 算法能够计算满足团队合理性嫉妒释放（最多一个参与者）、参与者合理性嫉妒释放、平衡性、帕累托最优性和参与者群体策略防护性的分配。

Conclusion: 该算法成功结合了匹配和公平分配理论，可扩展到处理配额和不完全偏好，为多对一匹配问题提供了全面的公平性解决方案。

Abstract: We consider a classic many-to-one matching setting, where participants need
to be assigned to teams based on the preferences of both sides. Unlike most of
the matching literature, we aim to provide fairness not only to participants,
but also to teams using concepts from the literature of fair division. We
present a polynomial-time algorithm that computes an allocation satisfying
team-justified envy-freeness up to one participant, participant-justified
envy-freeness, balancedness, Pareto optimality, and group-strategyproofness for
participants, even in the possible presence of ties. Our algorithm generalizes
both the Gale-Shapley algorithm from two-sided matching as well as the
round-robin algorithm from fair division. We also discuss how our algorithm can
be extended to accommodate quotas and incomplete preferences.

</details>


### [290] [Characterizations of equilibrium allocations in an economy with public goods and infinitely many commodities](https://arxiv.org/abs/2509.24437)
*Anuj Bhowmik*

Main category: econ.TH

TL;DR: 本文研究了公共项目经济中的均衡特征，在Mas-Colell(1980)模型基础上，引入成本分摊均衡概念，并提供了两种基于大联盟否决权的特征刻画。


<details>
  <summary>Details</summary>
Motivation: 公共产品作为抽象集合元素缺乏统一排序结构，需要建立更一般的均衡理论框架来刻画公共项目经济中的资源配置。

Method: 使用Banach格作为私人商品空间，引入成本分摊均衡概念，通过大联盟的否决权来特征化均衡，包括Aubin非支配分配和特定初始禀赋扰动下的支配关系。

Result: 提出了两种成本分摊均衡的特征刻画：一是通过Aubin非支配分配，二是通过大联盟在特定禀赋扰动下无法支配的分配。

Conclusion: 成本分摊均衡可以通过大联盟的否决权来完全刻画，这为公共项目经济中的均衡分析提供了新的理论工具。

Abstract: This paper examines the characterizations of equilibrium in economies with
public projects. Public goods, as discussed by Mas-Colell (1980), are modeled
as elements of an abstract set lacking a unified ordering structure. We
introduce the concepts of cost share equilibrium for such economies, where the
private commodity space is a (possibly nonseparable) Banach lattice. Within
this framework, we present two distinct characterizations of cost share
equilibria via the veto power of the grand coalition in economies featuring
finitely many agents. The first characterization involves allocations that are
Aubin non-dominated, while the second establishes that an allocation is a cost
share equilibrium if and only if it cannot be dominated by the grand coalition,
where domination is considered under specific perturbations of initial
endowments.

</details>


### [291] [Tight Samurai Accountant](https://arxiv.org/abs/2509.24673)
*Deniz Kattwinkel,Justus Preusser*

Main category: econ.TH

TL;DR: 本文在Border和Sobel(1987)的审计模型基础上应用紧致性概念，证明紧致机制是有效机制的子集且不会损失最优性，提供了构建连续类型空间有效机制的方法。


<details>
  <summary>Details</summary>
Motivation: 扩展Border和Sobel(1987)的审计理论，引入紧致性概念来精炼效率分析，探索在连续类型空间下如何构建有效机制。

Method: 应用Kattwinkel和Preusser(2025)的紧致性概念到Border和Sobel(1987)的模型框架中，分析紧致机制与有效机制的关系。

Result: 证明紧致机制是有效机制的子集，且不会损失最优性；揭示了委托人如何按顺序使用不同工具为不同类型代理人提供激励；提出了连续类型空间下构建有效机制的程序。

Conclusion: 紧致性在不损失最优性的前提下精炼了效率概念，能够复现Border和Sobel(1987)以及Chander和Wilde(1998)的见解，并为连续类型空间提供了新的机制构建方法。

Abstract: This note applies tightness (Kattwinkel and Preusser (2025)) to the setting
of Border and Sobel (1987, "Samurai Accountant: A Theory of Auditing and
Plunder"). Border and Sobel characterize efficient mechanisms and argue that
efficiency entails no loss of optimality. We characterize tight mechanisms and
argue that tightness entails no loss of optimality. We show that tight
mechanisms form a subset of efficient mechanisms. Therefore, tightness refines
efficiency without loss of optimality. By characterizing tight mechanisms, one
can replicate the insights from Border and Sobel (1987) and Chander and Wilde
(1998). A novel insight is how and in which order the principal uses different
instruments to provide incentives to different agent types. Further, we
describe a procedure for constructing efficient mechanisms in a setting with a
continuum of types.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [292] [Semantic-Aware Edge Intelligence for UAV Handover in 6G Networks](https://arxiv.org/abs/2509.22668)
*Aubida A. Al-Hameed,Mohammed M. H. Qazzaz,Maryam Hafeez,Syed A. Zaidi*

Main category: eess.SY

TL;DR: 本文提出了一种基于生成式AI和语义通信的无人机切换框架，利用轻量级MobileBERT模型处理飞行和无线电测量数据，实现多标签分类来决定切换动作，并生成解释决策的理由标签。


<details>
  <summary>Details</summary>
Motivation: 6G网络希望通过语义感知来优化无线资源分配，降低能耗并改善延迟。本文旨在利用边缘生成式AI能力来实现网络优化，特别是无人机切换场景中的可靠连接维护。

Method: 部署轻量级MobileBERT语言模型，使用低秩适应(LoRA)进行微调，处理多属性飞行和无线电测量数据，执行多标签分类来确定适当的切换动作，同时识别解释决策的上下文"理由标签"。

Result: 在基于规则的无人机切换场景合成数据集上评估，模型在预测主要切换决策方面表现出高准确性，在识别支持理由方面也表现出色，理由标签的F1微分数约为0.9。

Conclusion: 该框架展示了生成式AI和语义通信在无人机网络优化中的有效性，能够准确预测切换决策并解释决策理由，为6G网络中的语义感知资源优化提供了可行方案。

Abstract: 6G wireless networks aim to exploit semantic awareness to optimize radio
resources. By optimizing the transmission through the lens of the desired goal,
the energy consumption of transmissions can also be reduced, and the latency
can be improved. To that end, this paper investigates a paradigm in which the
capabilities of generative AI (GenAI) on the edge are harnessed for network
optimization. In particular, we investigate an Unmanned Aerial Vehicle (UAV)
handover framework that takes advantage of GenAI and semantic communication to
maintain reliable connectivity. To that end, we propose a framework in which a
lightweight MobileBERT language model, fine-tuned using Low-Rank Adaptation
(LoRA), is deployed on the UAV. This model processes multi-attribute flight and
radio measurements and performs multi-label classification to determine
appropriate handover action. Concurrently, the model identifies an appropriate
set of contextual "Reason Tags" that elucidate the decision's rationale. Our
model, evaluated on a rule-based synthetic dataset of UAV handover scenarios,
demonstrates the model's high efficacy in learning these rules, achieving high
accuracy in predicting the primary handover decision. The model also shows
strong performance in identifying supporting reasons, with an F1 micro-score of
approximately 0.9 for reason tags.

</details>


### [293] [A Hybrid Optimal Velocity Drag Model for Traffic Flow Dynamics](https://arxiv.org/abs/2509.22671)
*Nizhum Rahman,Trachette L. Jackson*

Main category: eess.SY

TL;DR: 提出了结合最优速度模型行为结构和基于牛顿力学的阻力饱和定律的混合最优速度-阻力模型，在保持交通波不稳定性的同时避免了不现实的加速度预测。


<details>
  <summary>Details</summary>
Motivation: 经典最优速度模型存在不现实的加速度预测问题，需要开发一个既保持交通波不稳定性机制又具有物理合理性的改进模型。

Method: 将最优速度模型的线性松弛定律替换为基于牛顿力学的阻力饱和定律，确保加速度有界且平滑收敛到平衡状态，并进行线性稳定性分析推导色散关系。

Result: OVD模型保留了导致走走停停交通波的不稳定性机制，同时避免了经典OVM的不现实加速度预测，为大规模交通仿真和实证研究提供了基础。

Conclusion: OVD模型在保持经典最优速度模型非线性不稳定性的同时强制执行有界加速度，为交通流研究提供了物理基础和可解释的框架。

Abstract: We develop a Hybrid Optimal Velocity-Drag (OVD) model that combines the
behavioral structure of the classical Optimal Velocity Model (OVM) with a
drag-based saturation law motivated by Newtonian mechanics. The model retains
the OVM principle that desired speed depends on headway, but replaces the
linear relaxation law with a formulation that enforces bounded accelerations
and smooth convergence to equilibrium. After reviewing the OVM framework and
its stability properties, we introduce the OVD dynamics and derive the
dispersion relation from a linear stability analysis of uniform flow. This
analysis shows that the OVD formulation preserves the instability mechanisms
responsible for stop-and-go waves, while avoiding the unrealistic acceleration
predictions of the classical OVM. We also illustrate the model using desired
velocity functions of hyperbolic tangent type, a common choice in the OVM
literature, and highlight applications to large-scale traffic simulation and
empirical data studies. Taken together, our results demonstrate that the OVD
model enforces bounded accelerations while preserving the nonlinear
instabilities of the classical OVM, providing a physically grounded and
interpretable foundation for advancing traffic flow research.

</details>


### [294] [Rebuild AC Power Flow Models with Graph Attention Networks](https://arxiv.org/abs/2509.22733)
*Yuting Hu,Jinjun Xiong*

Main category: eess.SY

TL;DR: 提出基于图注意力网络(GAT)的潮流重建模型，通过构建基于母线电压实部和虚部的新图，解决传统潮流模型参数不准确或不可用的问题，并提升对不同网络规模和拓扑的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的潮流分析方法依赖完整的潮流模型参数，但实际中这些参数可能不准确或不可用，且电力网络不断演变，需要考虑模型对不同网络规模和拓扑的泛化性。

Method: 基于图注意力网络(GAT)，通过构建基于母线电压实部和虚部的新图来重建潮流模型，并与两种最先进的潮流重建模型在不同IEEE标准电力系统案例及其修改拓扑变体上进行比较。

Result: 实验结果表明，所提模型在变化的网络中实现了更好的准确性，并且能够以较小的精度损失泛化到不同的网络。

Conclusion: 基于GAT的潮流重建模型在应对网络变化和泛化到不同网络方面具有优势，为处理电力系统中不确定性和动态变化提供了一种可行方法。

Abstract: A full power flow (PF) model is a complete representation of the physical
power network. Traditional model-based methods rely on the full PF model to
implement power flow analysis. In practice, however, some PF model parameters
can be inaccurate or even unavailable due to the uncertainties or dynamics in
the power systems. Moreover, because the power network keeps evolving with
possibly changing topology, the generalizability of a PF model to different
network sizes and typologies should be considered. In this paper, we propose a
PF rebuild model based on graph attention networks (GAT) by constructing a new
graph based on the real and imaginary parts of voltage at each bus. By
comparing with two state-of-the-art PF rebuild models for different standard
IEEE power system cases and their modified topology variants, we demonstrate
the feasibility of our method. Experimental results show that our proposed
model achieves better accuracy for a changing network and can generalize to
different networks with less accuracy discount.

</details>


### [295] [Finite Sample Analyses for Continuous-time Linear Systems: System Identification and Online Control](https://arxiv.org/abs/2509.22741)
*Hongyi Zhou,Jingwei Li,Jingzhao Zhang*

Main category: eess.SY

TL;DR: 该论文提出了首个基于有限观测的连续时间线性动力系统非渐近误差分析算法，解决了系统辨识问题，并在在线控制中实现了√T的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现实世界在连续时间中演化，但计算只能基于有限样本，因此需要研究在连续时间线性动力系统中使用有限观测的算法。

Method: 提出了一种系统辨识算法，无需在特定时间间隔内对观测进行积分，更适用于实际应用。将该算法应用于连续时间线性系统的在线控制遗憾分析。

Result: 系统辨识算法具有非渐近误差界，且证明该估计器在常数因子内是最优的。在线控制实现了√T的遗憾界，仅需T次系统观测。

Conclusion: 该研究为连续时间线性动力系统的有限观测分析提供了理论基础和实用算法，在系统辨识和在线控制方面都取得了重要进展。

Abstract: Real world evolves in continuous time but computations are done from finite
samples. Therefore, we study algorithms using finite observations in
continuous-time linear dynamical systems. We first study the system
identification problem, and propose a first non-asymptotic error analysis with
finite observations. Our algorithm identifies system parameters without needing
integrated observations over certain time intervals, making it more practical
for real-world applications. Further we propose a lower bound result that shows
our estimator is provably optimal up to constant factors. Moreover, we apply
the above algorithm to online control regret analysis for continuous-time
linear system. Our system identification method allows us to explore more
efficiently, enabling the swift detection of ineffective policies. We achieve a
regret of $\mathcal{O}(\sqrt{T})$ over a single $T$-time horizon in a
controllable system, requiring only $\mathcal{O}(T)$ observations of the
system.

</details>


### [296] [Stochastic Security Constrained AC Optimal Power Flow Using General Polynomial Chaos Expansion](https://arxiv.org/abs/2509.22936)
*Ghulam Mohy-ud-din,Yunqi Wang,Rahmat Heidari,Frederik Geth*

Main category: eess.SY

TL;DR: 提出了一种支持非线性交流潮流方程和非高斯不确定性的随机安全约束最优潮流模型，使用广义多项式混沌展开来建模任意有限方差不确定性，通过机会约束概率性地限制不等式违规。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源并网带来的不确定性对电力系统安全运行的影响，同时保持电网的完整非线性物理特性是一个重要挑战。

Method: 采用广义多项式混沌展开建模任意有限方差的不确定性，支持非线性AC潮流方程和非高斯不确定性，通过机会约束概率性地限制不等式违规。

Result: 案例研究验证了所提模型在满足运行约束和准确捕捉不确定性方面的有效性，相比确定性公式能发现更多不安全故障情况。

Conclusion: 该模型能够改进不确定性捕捉和运行洞察，为电力系统安全运行提供更灵活和准确的分析工具。

Abstract: Addressing the uncertainty introduced by increasing renewable integration is
crucial for secure power system operation, yet capturing it while preserving
the full nonlinear physics of the grid remains a significant challenge. This
paper presents a stochastic security constrained optimal power flow model with
chance constraints supporting nonlinear AC power flow equations and non
Gaussian uncertainties. We use general polynomial chaos expansion to model
arbitrary uncertainties of finite variance, enabling accurate moment
computations and robust prediction of system states across diverse operating
scenarios. The chance constraints probabilistically limit inequality
violations, providing a more flexible representation of controllable variables
and the consequent power system operation. Case studies validate the proposed
models effectiveness in satisfying operational constraints and capturing
uncertainty with high fidelity. Compared to the deterministic formulation, it
also uncovers a wider set of unsecure contingencies, highlighting improved
uncertainty capture and operational insight.

</details>


### [297] [Incorporating flexibility and resilience demand into capacity market considering the guidance on generation investment](https://arxiv.org/abs/2509.23269)
*Yunpeng Xiao,Hui Guo,Wenqi Wu,Xiuli Wang,Xifan Wang*

Main category: eess.SY

TL;DR: 将灵活性和韧性需求纳入容量市场，通过制定爬坡能力、惯性和恢复能力的容量需求曲线，确保电力系统的灵活性和韧性充足性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源比例快速增加，电力系统的灵活性和韧性充足性对安全运行变得更加关键。

Method: 建立三层博弈模型，上层基于发电公司投资制定容量需求曲线，中层和下层通过纳什古诺模型求解发电投资均衡。

Result: 案例研究表明，将灵活性和韧性需求纳入容量市场能够激励适当的发电投资，确保电力系统的灵活性和韧性充足性。

Conclusion: 将灵活性和韧性需求纳入容量市场是确保电力系统安全运行的有效方法。

Abstract: The capacity market provides economic guidance for generation investment and
ensures the adequacy of generation capability for power systems. With the
rapidly increasing proportion of renewable energy, the adequacy of flexibility
and resilience becomes more crucial for the secure operation of power systems.
In this context, this paper incorporates the flexibility and resilience demand
into the capacity market by formulating the capacity demand curves for ramping
capability, inertia and recovery capabilities besides the generation
capability. The guidance on generation investment of the capacity market is
also taken into account by solving the generation investment equilibrium among
generation companies with a Nash Cournot model employing an equivalent
quadratic programming formulation. The overall problem is established as a
trilevel game and an iterative algorithm is devised to formulate the capacity
demand curves in the upper level based on Genco's investment acquired from the
middle and lower levels. The case study further demonstrates that to
incorporate flexibility and resilience demand into the capacity market could
stimulate proper generation investment and ensure the adequacy of flexibility
and resilience in power systems.

</details>


### [298] [Sensitivity Analysis for Antenna Devices through Interval Arithmetic -- A Generalized Approach](https://arxiv.org/abs/2509.23361)
*Nicola Anselmi,Paolo Rocca,Andrea Massa*

Main category: eess.SY

TL;DR: 提出了一种基于区间分析(IA)和从示例学习(LBE)的电磁系统灵敏度分析方法，用于处理传递函数不明确的情况，通过构建代理模型和区间扩展来获得系统响应的性能边界。


<details>
  <summary>Details</summary>
Motivation: 电磁系统的传递函数通常没有显式形式，传统灵敏度分析方法难以应用，需要一种能处理隐式传递函数且考虑参数公差影响的方法。

Method: 首先通过LBE方法从输入输出示例构建解析代理模型，然后使用IA将模型扩展到区间，从而在参数存在有界公差时获得系统响应的包含性性能边界。

Result: 通过代表性数值算例验证了IA-LBE方法的有效性，证明该方法能够可靠地处理实际电磁系统(如天线)的灵敏度分析问题。

Conclusion: IA-LBE方法为传递函数不明确的电磁系统提供了一种有效的灵敏度分析工具，能够处理参数公差并给出可靠的性能边界预测。

Abstract: This paper presents a novel method for the sensitivity analysis of
electromagnetic (EM) systems whose transfer function (TF), that is the
input-output (I/O) relationship between the input parameters affected by
tolerance and the system response (i.e., the arising EM performance of
interest), is not available in closed (or explicit) form. The method is a
generalized analytic technique based on the Interval Analysis (IA). First, an
analytic surrogate model (SM) of the TF is defined by means of a
learning-by-example (LBE) approach starting from a set of available I/O
examples. Then, the LBE-derived SM is extended to intervals through IA to yield
inclusive, yet finite, performance bounds of the output system response when
the control parameters are affected by unknown, but bounded, tolerances. A set
of representative numerical examples is reported to validate the proposed
IA-LBE method as well as to assess its effectiveness and reliability when
dealing with realistic EM systems (e.g., antennas) for which the TF is not
explicitly known.

</details>


### [299] [Optimizing the Network Topology of a Linear Reservoir Computer](https://arxiv.org/abs/2509.23391)
*Sahand Tangerami,Nicholas A. Mecholsky,Francesco Sorrentino*

Main category: eess.SY

TL;DR: 提出了一种优化线性储备池计算机拓扑结构的方法，通过解耦动态模式并优化每个模式来提升性能和可解释性


<details>
  <summary>Details</summary>
Motivation: 传统储备池计算机的连接是随机生成的，缺乏原则性设计，限制了性能和可解释性

Method: 将储备池动态解耦为独立模式，通过优化储备池邻接矩阵的特征值来优化每个模式

Result: 优化后的储备池在训练和测试阶段都显著优于随机构建的储备池，且经常超过可比大小的非线性储备池

Conclusion: 该方法为设计高效、任务特定且分析透明的储备池架构提供了实用性能优势和理论指导

Abstract: Machine learning has become a fundamental approach for modeling, prediction,
and control, enabling systems to learn from data and perform complex tasks.
Reservoir computing is a machine learning tool that leverages high-dimensional
dynamical systems to efficiently process temporal data for prediction and
observation tasks. Traditionally, the connectivity of a reservoir computer (RC)
is generated at random, lacking a principled design. Here, we focus on
optimizing the topology of a linear RC to improve its performance and
interpretability, which we achieve by decoupling the RC dynamics into a number
of independent modes. We then proceed to optimize each one of these modes to
perform a given task, which corresponds to selecting an optimal RC connectivity
in terms of a given set of eigenvalues of the RC adjacency matrix. Simulations
on networks of varying sizes show that the optimized RC significantly
outperforms randomly constructed reservoirs in both the training and testing
phases and also often surpasses nonlinear reservoirs of comparable size. This
approach provides both practical performance advantages and theoretical
guidelines for designing efficient, task-specific, and analytically transparent
RC architectures.

</details>


### [300] [Communication-aware Wide-Area Damping Control using Risk-Constrained Reinforcement Learning](https://arxiv.org/abs/2509.23620)
*Kyung-bin Kwon,Lintao Ye,Vijay Gupta,Hao Zhu*

Main category: eess.SY

TL;DR: 提出了一种风险约束框架来处理电力系统中广域阻尼控制(WADC)面临的通信延迟和其他网络不确定性，使用强化学习算法SGDmax解决风险约束问题，相比传统延迟补偿方法在估计误差下表现更好。


<details>
  <summary>Details</summary>
Motivation: 传统延迟估计和补偿方法对快速WADC要求极高精度，且无法处理链路故障等网络扰动问题，需要一种能处理通信延迟和一般网络不确定性的新方法。

Method: 在经典LQR最优控制成本中引入均值-方差风险约束，开发基于强化学习的SGDmax算法，使用零阶策略梯度(ZOPG)求解风险约束问题。

Result: 在IEEE 68总线系统上的数值测试验证了SGDmax的收敛性和VSC的阻尼能力，证明该方法在估计误差下优于传统延迟补偿方法，能有效缓解最坏情况下的振荡。

Conclusion: 所提出的风险约束设计不仅能改善大延迟下的性能，还能有效缓解最坏情况振荡，同样适用于处理其他通信问题和网络扰动。

Abstract: Non-ideal communication links, especially delays, critically affect fast
networked controls in power systems, such as the wide-area damping control
(WADC). Traditionally, a delay estimation and compensation approach is adopted
to address this cyber-physical coupling, but it demands very high accuracy for
the fast WADC and cannot handle other cyber concerns like link failures or
{cyber perturbations}. Hence, we propose a new risk-constrained framework that
can target the communication delays, yet amenable to general uncertainty under
the cyber-physical couplings. Our WADC model includes the synchronous
generators (SGs), and also voltage source converters (VSCs) for additional
damping capabilities. To mitigate uncertainty, a mean-variance risk constraint
is introduced to the classical optimal control cost of the linear quadratic
regulator (LQR). Unlike estimating delays, our approach can effectively
mitigate large communication delays by improving the worst-case performance. A
reinforcement learning (RL)-based algorithm, namely, stochastic
gradient-descent with max-oracle (SGDmax), is developed to solve the
risk-constrained problem. We further show its guaranteed convergence to
stationarity at a high probability, even using the simple zero-order policy
gradient (ZOPG). Numerical tests on the IEEE 68-bus system not only verify
SGDmax's convergence and VSCs' damping capabilities, but also demonstrate that
our approach outperforms conventional delay compensator-based methods under
estimation error. While focusing on performance improvement under large delays,
our proposed risk-constrained design can effectively mitigate the worst-case
oscillations, making it equally effective for addressing other communication
issues and cyber perturbations.

</details>


### [301] [Electric Vehicle Charger Infrastructure Planning: Demand Estimation, Coverage Optimization Over an Integrated Power Grid](https://arxiv.org/abs/2509.23699)
*Harshal D. Kaushik,Jingbo Wang,Roshni Anna Jacob,Jie Zhang*

Main category: eess.SY

TL;DR: 提出一个两阶段方法，结合空间兴趣点分析和最大覆盖优化，在考虑电网约束的情况下规划电动汽车充电桩部署


<details>
  <summary>Details</summary>
Motivation: 现有研究要么忽视电网约束，要么使用统计建模的充电需求，需要结合空间网络规划和电网考虑的新框架

Method: 从配电网角度出发，首先估计EV充电需求并确定候选位置，确保新充电桩容量在电网限制范围内

Result: 在达拉斯地区测试案例中应用该框架，将现有EV充电网络与8500节点配电系统集成进行综合规划

Conclusion: 该框架成功整合了空间规划和电网约束，为电动汽车充电基础设施部署提供了更全面的解决方案

Abstract: For electrifying the transportation sector, deploying a strategically planned
and efficient charging infrastructure is essential. This paper presents a
two-phase approach for electric vehicle (EV) charger deployment that integrates
spatial point-of-interest analysis and maximum coverage optimization over an
integrated spatial power grid. Spatial-focused studies in the literature often
overlook electrical grid constraints, while grid-focused work frequently
considers statistically modeled EV charging demand. To address these gaps, a
new framework is proposed that combines spatial network planning with
electrical grid considerations. This study approaches EV charger planning from
a perspective of the distribution grid, starting with an estimation of EV
charging demand and the identification of optimal candidate locations. It
ensures that the capacity limits of newly established chargers are maintained
within the limits of the power grid. This framework is applied in a test case
for the Dallas area, integrating the existing EV charger network with an
8500-bus distribution system for comprehensive planning.

</details>


### [302] [Real Time Fatigue Crack Growth Monitoring Using High Precision Control and Data Acquisition Systems](https://arxiv.org/abs/2509.23710)
*Arev Hambardzumyan,Rafayel Ghasabyan*

Main category: eess.SY

TL;DR: 本文综述了四种裂纹增长监测技术：数字图像相关、声发射、基于柔度的方法和直流电位降法，评估其工作原理、检测阈值和适用性，旨在指导结构健康监测系统的选择与集成。


<details>
  <summary>Details</summary>
Motivation: 疲劳裂纹可能在结构件达到名义寿命前就萌生和扩展，实时检测和量化裂纹增长对于避免航空航天结构、核反应堆和民用基础设施的灾难性故障至关重要。

Method: 回顾和评估四种裂纹增长监测技术的工作原理、仪器设备、检测阈值、噪声敏感性和不同环境条件下的适用性，探索高精度控制和数据采集系统的最新进展。

Result: 分析了各种监测技术的优缺点，包括检测能力、环境适应性和数据融合潜力，为现代结构健康监测架构提供了技术选择依据。

Conclusion: 通过多传感器数据融合和先进数据采集系统，可以优化裂纹增长监测方法的选择和集成，提高结构安全监测的可靠性和准确性。

Abstract: Fatigue cracks may initiate and propagate long before a structural component
reaches the end of its nominal life. Detecting and quantifying crack growth in
real time is critical for avoiding catastrophic failures in aerospace
structures, nuclear reactors and civil infrastructure. This research reviews
four widely used crack growth monitoring techniques: digital image correlation
(DIC), acoustic emission (AE), compliance based methods and direct current
potential drop (DCPD). The research evaluates their working principles,
instrumentation, detection thresholds, noise sensitivities and suitability
under various environmental conditions. Recent advances in high precision
control and data acquisition systems (DAQs) that enable multi sensor data
fusion are explored. The goal is to guide selection and integration of
monitoring methods in modern structural health monitoring architectures.

</details>


### [303] [Toward a Robust Biomimetic Hybrid Battery: Bridging Biology, Electrochemistry and Data-Driven Control](https://arxiv.org/abs/2509.23837)
*Raheel Ali,Rayid Ali*

Main category: eess.SY

TL;DR: SwiftPulse混合电池概念结合钠离子电池和铌氧化物电池，通过脉冲充电和轮流休息策略，实现高能量密度、超长循环寿命和快速充电性能。


<details>
  <summary>Details</summary>
Motivation: 当前电池化学体系难以同时满足快速充电、长寿命和高能量密度的需求，受电鱼和鸟类半脑睡眠的启发，开发新型混合电池架构。

Method: 提出混合电池概念，结合钠离子电池（提供能量）和铌氧化物电池（承受高功率脉冲），采用脉冲充电和电池管理策略使电池组轮流休息恢复。

Result: 模型显示该电池组能量密度超过175 Wh/kg，循环寿命超过1万次，10分钟内可充电至80%，脉冲充电可减少离子积聚并减缓衰减。

Conclusion: 通过融合生物学、电化学和数据驱动控制，该工作为开发更安全、充电更快、寿命更长的电池指明了方向。

Abstract: Electric vehicles and renewable energy systems need batteries that charge
quickly, last many years and still store a lot of energy, but current
chemistries struggle to deliver all three. Inspired by electric fish that
deliver bursts of current and birds that sleep with half their brains, we
propose a hybrid battery concept called SwiftPulse. It combines sodium-ion
cells that provide energy with niobium-oxide cells that accept high-power
pulses. A pulse-based charger and a battery-management strategy rotate clusters
of cells into rest so they can recover. We derive simple models of energy
density, diffusion and capacity fade to show that a pack made mostly of
sodium-ion modules with a smaller fraction of niobium-oxide modules could
exceed 175 Wh per kg, endure more than ten thousand charge-discharge cycles and
recharge to eighty percent in less than ten minutes. Simulations suggest that
pulsed charging reduces ion buildup at the surface and slows degradation. We
outline a roadmap for cell-level and module-level experiments and suggest
integrating machine learning to adapt pulse parameters and rest scheduling. By
blending ideas from biology, electrochemistry and data-driven control, this
work points toward batteries that are safer, faster to charge and longer
lasting.

</details>


### [304] [Equation-Free Coarse Control of Distributed Parameter Systems via Local Neural Operators](https://arxiv.org/abs/2509.23975)
*Gianluca Fabiani,Constantinos Siettos,Ioannis G. Kevrekidis*

Main category: eess.SY

TL;DR: 提出了一种基于数据驱动的替代方法，使用局部神经算子训练时空微观/介观数据，获得高效短时解算子，用于计算粗粒度稳态和非稳态，并通过Krylov子空间方法提供无矩阵Jacobian信息。


<details>
  <summary>Details</summary>
Motivation: 高维分布式参数系统的控制仍然是一个挑战，特别是当显式粗粒度方程不可用时。传统的方程自由方法依赖精细尺度模拟器作为黑盒时间步进器，但重复模拟计算成本高昂，或者微观时间步进器可能不可用。

Method: 使用局部神经算子训练时空数据获得短时解算子，结合Krylov子空间方法计算稳态和非稳态，通过Krylov-Arnoldi迭代近似主导特征谱，建立捕捉开环慢动力学的降阶模型。

Result: 基于降阶系统设计了离散时间线性二次调节器和极点配置控制器，并将其提升到完整非线性动力学中实现反馈闭环控制。

Conclusion: 该方法为缺乏显式粗粒度方程的高维分布式参数系统控制提供了一种有效的数据驱动解决方案。

Abstract: The control of high-dimensional distributed parameter systems (DPS) remains a
challenge when explicit coarse-grained equations are unavailable. Classical
equation-free (EF) approaches rely on fine-scale simulators treated as
black-box timesteppers. However, repeated simulations for steady-state
computation, linearization, and control design are often computationally
prohibitive, or the microscopic timestepper may not even be available, leaving
us with data as the only resource. We propose a data-driven alternative that
uses local neural operators, trained on spatiotemporal microscopic/mesoscopic
data, to obtain efficient short-time solution operators. These surrogates are
employed within Krylov subspace methods to compute coarse steady and
unsteady-states, while also providing Jacobian information in a matrix-free
manner. Krylov-Arnoldi iterations then approximate the dominant eigenspectrum,
yielding reduced models that capture the open-loop slow dynamics without
explicit Jacobian assembly. Both discrete-time Linear Quadratic Regulator
(dLQR) and pole-placement (PP) controllers are based on this reduced system and
lifted back to the full nonlinear dynamics, thereby closing the feedback loop.

</details>


### [305] [Frequency Control and Optimal Power Sharing in Combined Power and Heating Networks with Heat Pumps](https://arxiv.org/abs/2509.24051)
*Xin Qin,Ioannis Lestas*

Main category: eess.SY

TL;DR: 该论文提出利用区域供热系统通过热泵为电力网络提供一次频率控制的辅助服务，开发了基于平均温度的功率分配方案，确保热电联合网络的稳定性和最优功率分配。


<details>
  <summary>Details</summary>
Motivation: 热泵能够快速调整功率消耗，并与具有大热惯性的区域供热网络连接，是低惯量电力系统中提供频率支持的重要资源。但电力网络与区域供热系统的耦合使得底层动态更加复杂，需要确保系统稳定性和适当的功率分配。

Method: 提出了基于平均温度的供热系统功率分配方案，能够在不需要负载扰动信息的情况下实现不同能源之间的最优功率分配。讨论了两种供热系统参与电力网络频率调节的方法。

Result: 两种方法都能确保热电联合网络的稳定性，并促进不同能源之间的最优功率分配。研究还展示了如何将各种发电动态纳入框架中，同时保证稳定性和最优性。

Conclusion: 仿真结果表明了所提方法在瞬态响应中的各种权衡及其实际潜力，证明了区域供热系统通过热泵为电力网络提供频率调节服务的可行性。

Abstract: Heat pumps have the capability for fast adjustments in power consumption with
potential connections to large heating-inertia district heating networks, and
are thus a very important resource for providing frequency support in
low-inertia power systems. Nevertheless, the coupling of power networks with
district heating systems renders the underlying dynamics much more involved. It
is therefore important to ensure that system stability and appropriate power
sharing are maintained. In this paper, we consider the problem of leveraging
district heating systems as ancillary services for primary frequency control in
power networks via heat pumps. We propose a novel power sharing scheme for
heating systems based on the average temperature. This enables an optimal power
allocation among diverse energy sources without requiring load disturbances
information. We then discuss two approaches for heating systems to contribute
to frequency regulation in power networks. We show that both approaches ensure
stability in the combined heat and power network and facilitate optimal power
allocation among the different energy sources. We also discuss how various
generation dynamics can be incorporated into our framework with guaranteed
stability and optimality. Finally, we conduct simulations that demonstrate
various tradeoffs in the transient response and the practical potential of the
proposed approaches.

</details>


### [306] [Solar and Wind Power Forecasting: A Comparative Review of LSTM, Random Forest, and XGBoost Models](https://arxiv.org/abs/2509.24059)
*Afsaneh Mollasalehi,Armin Farhadi*

Main category: eess.SY

TL;DR: 该论文综述了三种AI算法（LSTM、随机森林和XGBoost）在太阳能和风能预测中的应用，并比较了它们在研究流行度、模型复杂度和计算执行时间方面的表现。


<details>
  <summary>Details</summary>
Motivation: 全球能源需求增长引发对化石燃料可持续性的担忧，可再生能源如太阳能和风能虽然丰富但具有间歇性和不可预测性，需要准确预测来确保电网稳定和优化能源管理。

Method: 对三种广泛使用的算法（LSTM、随机森林和XGBoost）进行文献综述和比较分析，评估它们在学习历史和环境数据复杂模式方面的能力。

Result: 研究发现这些AI模型能够从历史和环境数据中学习复杂模式，实现更准确的预测，有助于提高可再生能源系统的效率和可靠性。

Conclusion: AI技术特别是机器学习和深度学习为改善可再生能源预测准确性提供了有前景的解决方案，LSTM、随机森林和XGBoost是三种有效的预测算法。

Abstract: Rising global energy demand from population growth raises concerns about the
sustainability of fossil fuels. Consequently, the energy sector has
increasingly transitioned to renewable energy sources like solar and wind,
which are naturally abundant. However, the periodic and unpredictable nature of
these resources pose significant challenges for power system reliability.
Accurate forecasting is essential to ensure grid stability and optimize energy
management. But due to the high variability in weather conditions which
directly affected wind and solar energy, achieving precise predictions remains
difficult. Advancements in Artificial Intelligence (AI), particularly in
Machine Learning (ML) and Deep Learning (DL), offer promising solutions to
improve forecasting accuracy. The study highlights three widely used algorithms
for solar and wind energy prediction: Long Short-Term Memory (LSTM), Random
Forest (RF), and Extreme Gradient Boosting (XGBoost). These models are capable
of learning complex patterns from historical and environmental data, enabling
more accurate forecasts and contributing to the enhanced efficiency and
reliability of renewable energy systems. This review aims to provide an
overview on RF, XGBoost, and LSTM by conducting a comparative analysis across
three essential criteria: research prevalence, model complexity, and
computational execution time.

</details>


### [307] [SDC-Based Model Predictive Control: Enhancing Computational Feasibility for Safety-Critical Quadrotor Control](https://arxiv.org/abs/2509.24208)
*Saber Omidi*

Main category: eess.SY

TL;DR: 提出基于状态依赖系数(SDC)的模型预测控制框架，在保持非线性MPC高精度性能的同时，将计算复杂度降低30%以上，适用于高速四旋翼机器人的实时控制。


<details>
  <summary>Details</summary>
Motivation: 非线性模型预测控制(NMPC)在高速机器人系统中应用广泛，但其计算量大，难以满足实时性和可靠性要求，特别是在需要鲁棒避障的环境中。

Method: 通过状态依赖系数(SDC)方法重新表述非线性四旋翼动力学，将原始非线性规划问题转化为序列二次优化问题；集成积分作用消除稳态跟踪误差，施加安全约束实现避障，并加入扰动估计器增强鲁棒性。

Result: 仿真结果表明，SDC-Based MPC在跟踪精度上与NMPC相当，但计算时间效率更高，更适合实时应用；理论分析证明了该方法的稳定性和递归可行性。

Conclusion: 所提出的SDC-Based MPC框架在保持高性能的同时显著降低了计算复杂度，为高速四旋翼机器人的实时控制提供了可行的解决方案。

Abstract: Nonlinear Model Predictive Control (NMPC) is widely used for controlling
high-speed robotic systems such as quadrotors. However, its significant
computational demands often hinder real-time feasibility and reliability,
particularly in environments requiring robust obstacle avoidance. This paper
proposes a novel SDC-Based Model Predictive Control (MPC) framework, which
preserves the high-precision performance of NMPC while substantially reducing
computational complexity by over 30%. By reformulating the nonlinear quadrotor
dynamics through the State-Dependent Coefficient (SDC) method, the original
nonlinear program problem is transformed into a sequential quadratic
optimization problem. The controller integrates an integral action to eliminate
steady-state tracking errors and imposes constraints for safety-critical
obstacle avoidance. Additionally, a disturbance estimator is incorporated to
enhance robustness against external perturbations. Simulation results
demonstrate that the SDC-Based MPC achieves comparable tracking accuracy to
NMPC, with greater efficiency in terms of computation times, thereby improving
its suitability for real-time applications. Theoretical analysis further
establishes the stability and recursive feasibility of the proposed approach.

</details>


### [308] [Multi-Agent Guided Policy Search for Non-Cooperative Dynamic Games](https://arxiv.org/abs/2509.24226)
*Jingqi Li,Gechen Qu,Jason J. Choi,Somayeh Sojoudi,Claire Tomlin*

Main category: eess.SY

TL;DR: 提出了一种基于模型的多智能体强化学习方法MA-GPS，通过将近似先验作为奖励函数的正则化项来稳定策略梯度，在LQ游戏中证明能保证局部指数收敛，并在非线性游戏中通过局部LQ近似指导训练。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在非合作动态游戏中存在不稳定性和极限环行为，现有基于熵的稳定方法会减慢学习速度并增加方差。

Method: 在奖励函数中引入近似先验作为正则化项，在LQ游戏中证明其稳定性，并扩展到非线性游戏中使用MA-GPS方法构建短视界局部LQ近似来指导训练。

Result: 在非线性车辆编队和六玩家篮球阵型实验中，MA-GPS比现有MARL方法收敛更快且学习更稳定。

Conclusion: 提出的模型化方法能有效稳定多智能体策略梯度学习，在理论和实验上都表现出优越性能。

Abstract: Multi-agent reinforcement learning (MARL) optimizes strategic interactions in
non-cooperative dynamic games, where agents have misaligned objectives.
However, data-driven methods such as multi-agent policy gradients (MA-PG) often
suffer from instability and limit-cycle behaviors. Prior stabilization
techniques typically rely on entropy-based exploration, which slows learning
and increases variance. We propose a model-based approach that incorporates
approximate priors into the reward function as regularization. In linear
quadratic (LQ) games, we prove that such priors stabilize policy gradients and
guarantee local exponential convergence to an approximate Nash equilibrium. We
then extend this idea to infinite-horizon nonlinear games by introducing
Multi-agent Guided Policy Search (MA-GPS), which constructs short-horizon local
LQ approximations from trajectories of current policies to guide training.
Experiments on nonlinear vehicle platooning and a six-player strategic
basketball formation show that MA-GPS achieves faster convergence and more
stable learning than existing MARL methods.

</details>


### [309] [Small-Covariance Noise-to-State Stability of Stochastic Systems and Its Applications to Stochastic Gradient Dynamics](https://arxiv.org/abs/2509.24277)
*Leilei Cui,Zhong-Ping Jiang,Eduardo D. Sontag*

Main category: eess.SY

TL;DR: 该论文研究了带有加性随机噪声的梯度动态系统，引入了小协方差噪声到状态稳定性(NSS)概念，并推广了Polyak-Lojasiewicz(PL)条件到𝒦-PL条件，证明了在𝒦-PL条件和全局Lipschitz连续梯度下，随机梯度动态具有小协方差NSS特性。


<details>
  <summary>Details</summary>
Motivation: 研究随机梯度动态在噪声环境下的鲁棒性，这些噪声可能来自随机梯度估计、测量噪声或随机采样误差，旨在建立系统的稳定性分析框架。

Method: 引入小协方差噪声到状态稳定性(NSS)概念和Lyapunov特征化，推广PL条件到𝒦-PL条件，通过比较函数扩展其适用性，分析不同强度PL条件下的稳定性特性。

Result: 证明在𝒦-PL条件和全局Lipschitz连续梯度下，随机梯度动态具有小协方差NSS，轨迹以高概率收敛到最优解邻域；在𝒦∞-PL条件下具有NSS，在正定PL条件下具有积分NSS。

Conclusion: 提出的框架为随机梯度系统的鲁棒性分析提供了理论基础，并成功应用于线性二次调节器(LQR)和逻辑回归的策略优化鲁棒性分析。

Abstract: This paper studies gradient dynamics subject to additive random noise, which
may arise from sources such as stochastic gradient estimation, measurement
noise, or stochastic sampling errors. To analyze the robustness of such
stochastic gradient systems, the concept of small-covariance noise-to-state
stability (NSS) is introduced, along with a Lyapunov-based characterization.
Furthermore, the classical Polyak-Lojasiewicz (PL) condition on the objective
function is generalized to the $\mathcal{K}$-PL condition via comparison
functions, thereby extending its applicability to a broader class of
optimization problems. It is shown that the stochastic gradient dynamics
exhibit small-covariance NSS if the objective function satisfies the
$\mathcal{K}$-PL condition and possesses a globally Lipschitz continuous
gradient. This result implies that the trajectories of stochastic gradient
dynamics converge to a neighborhood of the optimum with high probability, with
the size of the neighborhood determined by the noise covariance. Moreover, if
the $\mathcal{K}$-PL condition is strengthened to a $\mathcal{K}_\infty$-PL
condition, the dynamics are NSS; whereas if it is weakened to a general
positive-definite-PL condition, the dynamics exhibit integral NSS. The results
further extend to objectives without globally Lipschitz gradients through
appropriate step-size tuning. The proposed framework is further applied to the
robustness analysis of policy optimization for the linear quadratic regulator
(LQR) and logistic regression.

</details>


### [310] [Autonomous Detection and Coverage of Unknown Target Areas by Multi-Agent Systems](https://arxiv.org/abs/2509.24399)
*Jie Song,Yang Bai,Mikhail Svinin,Naoki Wakamiya*

Main category: eess.SY

TL;DR: 提出了一种无需先验区域知识的多智能体覆盖控制算法，通过动态密度函数和CVT实现自主目标检测与协作覆盖


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在未知目标区域情况下的自主覆盖问题，传统方法需要预先知道覆盖区域，限制了实际应用

Method: 结合动态密度函数吸引机制、质心Voronoi分割(CVT)和控制屏障函数(CBF)，实现目标检测、最优分布和避碰

Result: 仿真验证表明智能体能够独立定位并有效覆盖目标区域

Conclusion: 该方法成功实现了无先验知识的多智能体自主覆盖控制，结合了目标检测、最优分布和安全保障

Abstract: This paper presents a novel coverage control algorithm for multi-agent
systems, where each agent has no prior knowledge of the specific region to be
covered. The proposed method enables agents to autonomously detect the target
area and collaboratively achieve full coverage. Once an agent detects a part of
the target region within its sensor range, a dynamically constructed density
function is generated to attract nearby agents. By integrating this
density-driven mechanism with Centroidal Voronoi Tessellation (CVT), the agents
are guided to achieve optimal spatial distribution. Additionally, Control
Barrier Functions (CBFs) are employed to ensure collision avoidance and
maintain non-overlapping sensor coverage, enhancing both safety and efficiency.
Simulation results verify that agents can independently locate and effectively
cover the target area.

</details>


### [311] [Model-Free Dynamic Consensus in Multi-Agent Systems: A Q-Function Perspective](https://arxiv.org/abs/2509.24598)
*Maryam Babazadeh,Naim Bajcinca*

Main category: eess.SY

TL;DR: 提出了一种基于最优控制理论的新方法，用于线性离散时间多智能体系统的动态一致性控制，通过状态-动作值函数框架将问题转化为凸半定规划问题，支持模型驱动和数据驱动两种设置。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体系统一致性控制在边缘稳定或不稳定动态系统中面临挑战，特别是大规模系统具有多样化图拉普拉斯谱时，耦合增益设计变得复杂。

Method: 使用状态-动作值函数框架，引入合成线性二次调节(LQR)公式将一致性目标编码为凸半定规划(SDP)问题，采用凸凹分解策略处理非凸可行性条件。

Result: 数值仿真验证了该方法在各种场景下的有效性，能够在模型驱动和数据驱动设置下联合设计局部反馈和耦合增益。

Conclusion: 该方法提供了一种灵活的设计框架，平衡了可行性、收敛速度、鲁棒性和能量效率，特别适用于大规模多智能体系统的动态一致性控制。

Abstract: This paper presents a new method for achieving dynamic consensus in linear
discrete-time homogeneous multi-agent systems (MAS) with marginally stable or
unstable dynamics. The guarantee of consensus in this setting involves a set of
constraints based on the graph's spectral properties, complicating the design
of the coupling gains. This challenge intensifies for large-scale systems with
diverse graph Laplacian spectra. The proposed approach reformulates the dynamic
consensus problem with a prescribed convergence rate using a state-action value
function framework inspired by optimal control theory. Specifically, a
synthetic linear quadratic regulation (LQR) formulation is introduced to encode
the consensus objective, enabling its translation into a convex semidefinite
programming (SDP) problem. The resulting SDP is applicable in both model-based
and model-free settings for jointly designing the local feedback and coupling
gains. To handle the inherent non-convex feasibility conditions, a
convex-concave decomposition strategy is employed. Adaptation of the method in
a completely model-free set-up eliminates the need for system identification or
knowledge of the agents' dynamics. Instead, it relies on input-state data
collection and offers an entirely data-driven equivalent SDP formulation.
Finally, a new algorithm balancing feasibility, convergence rate, robustness,
and energy efficiency, is established to provide design flexibility. Numerical
simulations validate the method's effectiveness in various scenarios.

</details>


### [312] [Hill-Type Stability Analysis of Periodic Solutions of Fractional-Order Differential Equations](https://arxiv.org/abs/2509.24639)
*Paul-Erik Haacker,Remco I. Leine,Renu Chaudhary,Kai Diethelm,André Schmidt,Safoura Hashemishahraki*

Main category: eess.SY

TL;DR: 本文研究了分数阶微分方程周期解的稳定性，提出了Liouville-Weyl型FODEs框架来处理精确周期解，并分析了将Floquet理论和Hill矩阵方法扩展到线性时变分数阶系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 经典Caputo型分数阶微分方程不允许精确周期解，需要建立新的理论框架来研究分数阶系统的周期解稳定性。

Method: 提出Liouville-Weyl型FODEs作为Caputo型方程的扩展，采用局部线性化方法，并尝试将Floquet理论和Hill矩阵方法扩展到线性时变分数阶系统。

Result: 扩展的Floquet理论只能评估线性时变分数阶系统的指数增长解，无法处理代数衰减解。在时不变情况下也存在类似局限性。

Conclusion: 分数阶系统的Floquet理论存在根本性限制，只能分析指数增长行为，无法完整描述系统的稳定性特性。

Abstract: This paper explores stability properties of periodic solutions of (nonlinear)
fractional-order differential equations (FODEs). As classical Caputo-type FODEs
do not admit exactly periodic solutions, we propose a framework of
Liouville-Weyl-type FODEs, which do admit exactly periodic solutions and are an
extension of Caputo-type FODEs. Local linearization around a periodic solution
results in perturbation dynamics governed by a linear time-periodic
differential equation. In the classical integer-order case, the perturbation
dynamics is therefore described by Floquet theory, i.e. the exponential growth
or decay of perturbations is expressed by Floquet exponents which can be
assessed using the Hill matrix approach. For fractional-order systems, however,
a rigorous Floquet theory is lacking. Here, we explore the limitations when
trying to extend Floquet theory and the Hill matrix method to linear
time-periodic fractional-order differential equations (LTP-FODEs) as local
linearization of nonlinear fractional-order systems. A key result of the paper
is that such an extended Floquet theory can only assess exponentially growing
solutions of LTP-FODEs. Moreover, we provide an analysis of linear
time-invariant fractional-order systems (LTI-FODEs) with algebraically decaying
solutions and show that the inaccessibility of decaying solutions through
Floquet theory is already present in the time-invariant case.

</details>


### [313] [Hierarchical Analysis and Control of Epidemic Spreading over Networks using Dissipativity and Mesh Stability](https://arxiv.org/abs/2509.24665)
*Shirantha Welikala,Hai Lin,Panos J. Antsaklis*

Main category: eess.SY

TL;DR: 该论文提出了一种基于耗散性理论的层次化传播网络分析与控制方法，通过线性矩阵不等式(LMI)在多层级上实现网络稳定性和传播控制。


<details>
  <summary>Details</summary>
Motivation: 传播过程分析面临非线性节点动态、未知扰动、复杂互连和大规模多层级问题的挑战，需要一种能够处理这些复杂性的理论框架。

Method: 将传播网络建模为网络化系统，建立节点耗散性特性，在多层级应用广义拓扑设计方法，将分析控制问题转化为LMI问题，并通过局部必要条件支持可行性。

Result: 与传统的阈值剪枝和高阶边移除方法相比，该方法在感染控制、控制效率和扰动鲁棒性方面表现出更优越的性能。

Conclusion: 所提出的控制方案不仅确保传播网络的稳定性，还保证其耗散性和网格稳定性，避免了计算效率低下的迭代多级优化过程。

Abstract: Analyzing and controlling spreading processes are challenging problems due to
the involved non-linear node (subsystem) dynamics, unknown disturbances,
complex interconnections, and the large-scale and multi-level nature of the
problems. The dissipativity concept provides a practical framework for
addressing such concerns, thanks to the energy-based representation it offers
for subsystems and the compositional properties it provides for the analysis
and control of interconnected (networked) systems comprised of such subsystems.
Therefore, in this paper, we utilize the dissipativity concept to analyze and
control a spreading process that occurs over a hierarchy of nodes, groups, and
a network (i.e., a spreading network). We start by generalizing some existing
results on dissipativity-based topology design for networked systems. Next, we
model the considered spreading network as a networked system and establish the
dissipativity properties of its nodes. The generalized topology design method
is then applied at multiple levels of the considered spreading network to
formulate its analysis and control problems as Linear Matrix Inequality (LMI)
problems. We identify and enforce localized necessary conditions to support the
feasibility of the LMI problem solved at each subsequent hierarchical level of
the spreading network. Consequently, the proposed method does not involve
iterative multi-level optimization stages that are computationally inefficient.
The proposed control solution ensures that the spreading network is not only
stable but also dissipative and mesh-stable. Compared to conventional methods,
such as threshold pruning and high-degree edge removal, our approach offers
superior performance in terms of infection containment, control efficiency, and
disturbance robustness. Extensive numerical results demonstrate the
effectiveness of the proposed technique.

</details>


### [314] [Position estimation based on UWB swarm optimization and comparison against traditional trilateration](https://arxiv.org/abs/2509.24738)
*Vinish Yogesh,Bert-Jan van Beijnum,Jaap H. Buurke,Chris T. M. Baten*

Main category: eess.SY

TL;DR: 提出了一种基于UWB群体优化的位置估计方法，利用所有可用的节点间距离来提高精度，相比传统的三边测量方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统UWB位置估计方法基于星型拓扑，忽略了节点间距离估计的宝贵信息。群体拓扑可以提供更多冗余距离估计，提高位置估计的准确性和一致性。

Method: 提出UWB群体优化位置估计方法，利用所有可用的节点间距离，并与传统的三边测量方法进行比较。使用合成UWB数据进行验证，进行全面的误差敏感性分析。

Result: 所提方法始终优于三边测量，在现实UWB距离输入估计下位置估计误差约为5.7厘米，在高噪声条件下误差比三边测量方法低约6厘米。

Conclusion: 群体优化方法作为传统星型三边测量方法的更准确和一致的替代方案，展示了其在位置估计中的普遍潜力。

Abstract: Ultra-wideband (UWB) is a promising technology for indoor position estimation
for various localization applications of object swarms, such as in 3D analysis
of human movement with multiple on-body sensors or a swarm of drones in an
indoor environment. However, most UWB-only position estimation methods are
based on a star topology, where the position of a mobile node is estimated
using distances from several fixed anchors. These approaches ignore the
valuable inter-node distance estimates, possible in a fully-connected 'Swarm'
topology, which could provide more redundancy in the set of available distance
estimates used for the position estimation. This would improve the accuracy and
consistency of the position estimates. Also, published studies do not analyze
how input measurement errors affect the final position estimates, which makes
it difficult to assess the reliability under varying conditions. Therefore,
this study first proposes a UWB swarm optimization-based position estimation
method that utilizes all available internode distances to enhance accuracy and
compare against the traditional trilateration method that utilizes the star
configuration. All validations were done with synthetic UWB data, to enable
testing all input error situations. The comprehensive error sensitivity
analysis was conducted to evaluate its robustness under varying noise
conditions. The proposed method consistently outperformed trilateration, with
position estimation error around 5.7 cm for realistic UWB distance input
estimates, while for higher noise conditions, the proposed method had errors
around 6 cm lower than the trilateration method, which had position estimation
errors around 19 cm. This study demonstrates the general potential of the Swarm
optimization-based method for position estimation as a more accurate and
consistent alternative to traditional star-based trilateration methods.

</details>


### [315] [Event-Driven Control via Sparsity-Promoting Regularization: A Rollout Approach with Performance Guarantees](https://arxiv.org/abs/2509.24799)
*Shumpei Nishida,Kunihisa Okano*

Main category: eess.SY

TL;DR: 提出一种控制器设计方法，通过事件驱动机制平衡控制性能和执行频率，使用滚动时域方法推导事件触发条件，并建立理论性能边界和闭环系统稳定性证明。


<details>
  <summary>Details</summary>
Motivation: 旨在平衡控制性能与执行频率，通过事件驱动控制实现间歇性控制动作，在保证控制效果的同时减少执行器使用频率。

Method: 采用事件驱动控制框架，通过执行率正则化促进输入稀疏性，使用滚动算法求解具有组合特性的最优控制问题，通过多阶段最小化过程推导事件触发条件。

Result: 建立了相对于周期控制的理论性能边界，证明了闭环系统的稳定性，并通过数值示例验证了方法的有效性。

Conclusion: 所提出的控制器设计方法能够在保证控制性能的同时有效降低执行频率，为事件驱动控制提供了理论保证和实用方案。

Abstract: This paper presents a controller design method aiming to balance control
performance and actuation frequency. In this framework, actuation timings are
determined in an event-driven manner, resulting in intermittent control
actions. Control performance is measured by an infinite-horizon average cost,
and input sparsity is promoted through actuation-rate regularization. Since the
formulated optimal control problem has a combinatorial nature, we employ a
rollout algorithm to find a suboptimal solution. In the proposed scheme, the
event-triggering condition is derived through a multistage minimization
procedure using a receding-horizon approach. We establish theoretical
performance bounds with respect to periodic control and prove the stability of
the closed-loop system. The effectiveness of the proposed method is
demonstrated through a numerical example.

</details>


### [316] [Coordinated vs. Sequential Transmission Planning](https://arxiv.org/abs/2509.24959)
*Maya Domeshek,Christoph Graf,Burçin Ünel*

Main category: eess.SY

TL;DR: 该论文提出了一种协同优化发电、储能和输电投资的多阶段多位置规划模型，与传统顺序规划方法相比，可显著降低输电升级需求和系统总成本。


<details>
  <summary>Details</summary>
Motivation: 美国系统运营商通常采用顺序规划方法（先规划发电储能，再识别输电限制），这种方法无法准确捕捉三种容量类型之间的相互作用。

Method: 开发了多阶段多位置规划模型，协同优化发电、储能和输电投资，考虑可靠性约束以及州能源和气候政策。

Result: 在PJM区域的20区模型中，协同优化方法估计的输电升级需求比顺序模型低67%，系统总成本降低0.6%，同时保持相似的可靠性和气候结果。

Conclusion: 协同优化规划能带来更大的输电和成本节约，以及可靠性和气候效益。

Abstract: Coordinated planning of generation, storage, and transmission more accurately
captures the interactions among these three capacity types necessary to meet
electricity demand, at least in theory. However, in practice, U.S. system
operators typically follow a sequential planning approach: They first determine
future generation and storage additions based on an assumed unconstrained
(`copper plate') system. Next, they perform dispatch simulations of this
projected generation and storage capacity mix on the existing transmission grid
to identify transmission constraint violations. These violations indicate the
need for transmission upgrades. We describe a multistage, multi-locational
planning model that co-optimizes generation, storage, and transmission
investments. The model respects reliability constraints as well as state energy
and climate policies. We test the two planning approaches using a current
stakeholder-informed 20-zone model of the PJM region, developed for the current
FERC Order No. 1920 compliance filing process. In our most conservative model
specification, we find that the co-optimized approach estimates 67% lower
transmission upgrade needs than the sequential model, leading to total system
costs that are .6% lower and similar reliability and climate outcomes. Our
sensitivities show larger transmission and cost savings and reliability and
climate benefits from co-optimized planning.

</details>


### [317] [Spectral Flow Learning Theory: Finite-Sample Guarantees for Vector-Field Identification](https://arxiv.org/abs/2509.25000)
*Chi Ho Leung,Philip E. Paré*

Main category: eess.SY

TL;DR: 提出Spectral Flow Learning (SFL)方法，用于从非均匀采样轨迹中识别连续时间向量场，并提供有限样本高概率保证。


<details>
  <summary>Details</summary>
Motivation: 解决从非均匀采样轨迹中识别连续时间向量场的问题，特别是在不规则采样情况下的学习挑战。

Method: 使用窗口化流空间和滞后线性标签算子，聚合滞后的Koopman作用，采用变步长线性多步方法(vLMM)和谱正则化。

Result: 建立了有限样本高概率保证，结合统计率和显式离散化偏差的两项边界，通过多步可观测性不等式将流误差与向量场误差联系起来。

Conclusion: SFL方法能够有效学习连续时间向量场，为不规则采样轨迹的向量场识别提供了理论保证。

Abstract: We study the identification of continuous-time vector fields from irregularly
sampled trajectories. We introduce Spectral Flow Learning (SFL), which learns
in a windowed flow space using a lag-linear label operator that aggregates
lagged Koopman actions. We provide finite-sample high-probability (FS-HP)
guarantees for the class of variable-step linear multistep methods (vLLM). The
FS-HP rates are constructed using spectral regularization with
qualification-controlled filters for flow predictors under standard source and
filter assumptions. A multistep observability inequality links flow error to
vector-field error and yields two-term bounds that combine a statistical rate
with an explicit discretization bias from vLMM theory.
  This preliminary preprint states the results and sketches proofs, with full
proofs and extensions deferred to a journal version.

</details>


### [318] [Real-Time Power electronics Control and Monitoring with TI F28379D DSC and GUI Composer](https://arxiv.org/abs/2509.25008)
*Ilyas Bennia,Lotfi Baghli,Ehsan Jamshidpour,Abdelkader Mechernene,Jean-Philippe Martin,Driss Yousfi*

Main category: eess.SY

TL;DR: 基于TMS320F28379D微控制器实现三相感应电机实时控制系统，集成PWM、ADC、DAC和编码器反馈，采用V/f和磁场定向控制(FOC)算法，通过GUI Composer进行参数调谐和可视化。


<details>
  <summary>Details</summary>
Motivation: 开发高性能感应电机控制系统，实现精确的实时控制，验证不同控制策略在工业应用中的有效性。

Method: 使用TI TMS320F28379D微控制器，集成PWM生成、ADC/DAC转换、编码器反馈，采用AMC1301隔离放大器和分流电阻进行电流检测，实现V/f和FOC两种控制算法。

Result: 实验结果显示系统具有平滑的速度反转、快速的动态响应，在阶跃和多步输入下均表现稳定。GUI Composer有效支持监控和控制，但信号带宽存在限制。

Conclusion: 所实现的控制策略在感应电机应用中表现出鲁棒性和有效性，验证了系统的高性能控制能力。

Abstract: This paper details the implementation and experimental validation of a
real-time control system for a three-phase induction motor using the Texas
Instruments TMS320F28379D microcontroller. The system integrates pulse-width
modulation (PWM) generation, analog-to-digital conversion (ADC),
digital-to-analog conversion (DAC), and quadrature encoder feedback to
facilitate precise control under various strategies. A current sensing solution
based on the AMC1301 isolation amplifier and shunt resistor ensures accurate
and safe current measurement for feedback loops. Two control algorithms, V/f
and Field-Oriented Control (FOC) are implemented and tested. Real-time
parameter tuning and data visualization are achieved using GUI Composer,
enabling efficient system debugging and interaction. Experimental results
demonstrate smooth speed reversal, fast dynamic response, and stable
performance under both step and multi-step inputs. While GUI Composer
effectively supports general monitoring and control, limitations in signal
bandwidth are noted compared to professional-grade platforms. The results
confirm the robustness and effectiveness of the implemented control strategies
for high-performance induction motor applications.

</details>


### [319] [Real-Time Estimation of Equivalent Series Resistance for Predicting Output Capacitor Failures in Boost Converters](https://arxiv.org/abs/2509.25046)
*Antonino pagano*

Main category: eess.SY

TL;DR: 提出了一种用于升压变换器输出电容器ESR实时估计的技术，旨在实现早期故障预测和基于状态的维护。


<details>
  <summary>Details</summary>
Motivation: 输出电容器是电力电子变换器中最关键的组件之一，其退化直接影响系统稳定性和可靠性。ESR的逐渐增加与老化和即将发生的故障密切相关。

Method: 利用在线参数估计技术提取ESR值，无需中断变换器运行。该估计算法已在低成本STM32 Nucleo平台上实现。

Result: 实验验证表明，该方法在不同负载和运行条件下提供准确的ESR跟踪，能够及时检测异常电容器行为。

Conclusion: 该方法计算效率高，适合嵌入式应用，能够防止意外系统故障。

Abstract: Output capacitors are among the most critical components in power electronic
converters, as their degradation directly affects system stability and
reliability. A key indicator of capacitor health is the Equivalent Series
Resistance (ESR), whose progressive increase is strongly correlated with aging
and imminent failure. This paper presents a real-time technique for estimating
the ESR of output capacitors in boost converters, with the aim of enabling
early fault prediction and condition-based maintenance. The proposed method
leverages online parameter estimation to extract ESR values without
interrupting converter operation. The estimation algorithm has been implemented
on a low-cost STM32 Nucleo platform, demonstrating both computational
efficiency and suitability for embedded applications. Experimental validation
confirms that the approach provides accurate ESR tracking under varying load
and operating conditions, allowing timely detection of abnormal capacitor
behavior and preventing unexpected system failures.

</details>


### [320] [Safety-Critical Input-Constrained Nonlinear Intercept Guidance in Multiple Engagement Zones](https://arxiv.org/abs/2509.25053)
*Praveen Kumar Ranjan,Abhinav Sinha,Yongcan Cao*

Main category: eess.SY

TL;DR: 提出了一种输入受限的非线性制导律，用于在多个防御代理的对抗环境中拦截静止目标，通过几何定义的交战区域来表征防御威胁，并采用平滑最小函数处理多个威胁区域。


<details>
  <summary>Details</summary>
Motivation: 解决在对抗环境中拦截静止目标时，现有方法依赖防御策略显式知识或基于防御范围保守安全条件的问题，需要更有效的威胁表征和规避方法。

Method: 使用交战区域几何表征防御威胁，制导律在交战区域附近切换为排斥安全机动，在区域外采用追踪机动，通过平滑最小函数聚合多个威胁，并在非完整车辆动力学中嵌入输入饱和约束。

Result: 数值模拟显示该方法能有效规避交战区域并在各种初始条件下成功实现拦截。

Conclusion: 所提出的制导律能够在对抗环境中有效规避多个防御威胁，同时保证输入约束下的稳定性，成功实现目标拦截。

Abstract: This paper presents an input-constrained nonlinear guidance law to address
the problem of intercepting a stationary target in contested environments with
multiple defending agents. Contrary to prior approaches that rely on explicit
knowledge of defender strategies or utilize conservative safety conditions
based on a defender's range, our work characterizes defender threats
geometrically through engagement zones that delineate inevitable interception
regions. Outside these engagement zones, the interceptor remains invulnerable.
The proposed guidance law switches between a repulsive safety maneuver near
these zones and a pursuit maneuver outside their influence. To deal with
multiple engagement zones, we employ a smooth minimum function
(log-sum-exponent approximation) that aggregates threats from all the zones
while prioritizing the most critical threats. Input saturation is modeled and
embedded in the non-holonomic vehicle dynamics so the controller respects
actuator limits while maintaining stability. Numerical simulations with several
defenders demonstrate the proposed method's ability to avoid engagement zones
and achieve interception across diverse initial conditions.

</details>


### [321] [Data-Driven Resilience Assessment against Sparse Sensor Attacks](https://arxiv.org/abs/2509.25064)
*Takumi Shinohara,Karl Henrik Johansson,Henrik Sandberg*

Main category: eess.SY

TL;DR: 提出了一个数据驱动的框架，用于评估线性时不变系统对恶意虚假数据注入传感器攻击的弹性，基于稀疏可观测性概念提出了数据驱动的弹性度量。


<details>
  <summary>Details</summary>
Motivation: 需要评估控制系统在面对传感器攻击时的弹性，特别是在模型未知的情况下，仅依靠数据来评估系统的安全性能。

Method: 基于稀疏可观测性概念，使用无攻击数据推导出系统弹性的充要条件；扩展到仅有被污染数据的情况，提供多项式时间算法来评估系统弹性。

Result: 当获得满足特定秩条件的无攻击数据时，可以在模型未知的情况下精确评估攻击弹性水平；对于被污染数据，只能保守地评估系统弹性。

Conclusion: 数值示例验证了所提出框架的有效性和局限性，为数据驱动的系统安全评估提供了实用方法。

Abstract: We present a data-driven framework for assessing the attack resilience of
linear time-invariant systems against malicious false data injection sensor
attacks. Based on the concept of sparse observability, data-driven resilience
metrics are proposed. First, we derive a data-driven necessary and sufficient
condition for assessing the system's resilience against sensor attacks, using
data collected without any attacks. If we obtain attack-free data that satisfy
a specific rank condition, we can exactly evaluate the attack resilience level
even in a model-free setting. We then extend this analysis to a scenario where
only poisoned data are available. Given the poisoned data, we can only
conservatively assess the system's resilience. In both scenarios, we also
provide polynomial-time algorithms to assess the system resilience under
specific conditions. Finally, numerical examples illustrate the efficacy and
limitations of the proposed framework.

</details>


### [322] [Data-Driven Optimal Power Flow: A Behavioral Systems Approach](https://arxiv.org/abs/2509.25120)
*Sebastian Otzen,Hannes M. H. Wolf,Christian A. Hans*

Main category: eess.SY

TL;DR: 提出了一种基于Willems基本引理的数据驱动非线性潮流方程表示方法，可直接将输入/输出数据集成到潮流优化中，无需电网拓扑或电气特性的显式知识。


<details>
  <summary>Details</summary>
Motivation: 可再生能源驱动的电力系统日益分散化给潮流优化带来挑战，部分未知的线路特性使得基于模型的方法不适用。随着传感器部署增加，数据驱动方法成为有前景的替代方案。

Method: 基于Willems基本引理，为辐射状电网提出数据驱动的非线性潮流方程表示方法，并制定凸松弛以确保与现代求解器的兼容性。

Result: 数值案例研究表明，新方法性能与最先进方法相当，且无需显式系统辨识步骤。

Conclusion: 该方法能够实现成本最小化和约束执行，无需电网电气特性或拓扑的显式知识，为数据驱动潮流优化提供了有效解决方案。

Abstract: The increasing decentralization of power systems driven by a large number of
renewable energy sources poses challenges in power flow optimization. Partially
unknown power line properties can render model-based approaches unsuitable.
With increasing deployment of sensors, data-driven methods rise as a promising
alternative. They offer the flexibility to adapt to varying grid structures and
unknown line properties. In this paper, we propose a novel data-driven
representation of nonlinear power flow equations for radial grids based on
Willems' Fundamental Lemma. The approach allows for direct integration of
input/output data into power flow optimisation, enabling cost minimization and
constraint enforcement without requiring explicit knowledge of the electrical
properties or the topology of the grid. Moreover, we formulate a convex
relaxation to ensure compatibility with state-of-the-art solvers. In a
numerical case study, we demonstrate that the novel approach performs similar
to state-of-the-art methods, without the need for an explicit system
identification step.

</details>


### [323] [Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks](https://arxiv.org/abs/2509.06775)
*Po-Heng Chou,Pin-Qi Fu,Walid Saad,Li-Chun Wang*

Main category: eess.SY

TL;DR: 提出了一种基于智能体双深度Q网络(DDQN)的调度器，用于NR侧行链路网络中的授权/非授权频段分配，通过多维上下文感知和推理实现更好的资源分配。


<details>
  <summary>Details</summary>
Motivation: 传统基于阈值的调度策略在共存受限的NR侧行链路网络中表现不佳，需要更智能的上下文驱动决策来改善阻塞率和资源分配效率。

Method: 使用智能体双深度Q网络(DDQN)，感知和推理多维上下文（排队延迟、链路质量、共存强度、切换稳定性），采用容量感知和QoS约束的奖励函数。

Result: 在带宽受限条件下，相比阈值策略减少阻塞率高达87.5%，同时保持吞吐量，证明了上下文驱动决策在共存受限NR侧行链路网络中的价值。

Conclusion: 所提出的调度器是一种专门为网络边缘任务特定、资源高效操作设计的具身智能体(E-agent)，在共存受限环境中显著优于传统方法。

Abstract: In this paper, we present an agentic double deep Q-network (DDQN) scheduler
for licensed/unlicensed band allocation in New Radio (NR) sidelink (SL)
networks. Beyond conventional reward-seeking reinforcement learning (RL), the
agent perceives and reasons over a multi-dimensional context that jointly
captures queueing delay, link quality, coexistence intensity, and switching
stability. A capacity-aware, quality of service (QoS)-constrained reward aligns
the agent with goal-oriented scheduling rather than static thresholding. Under
constrained bandwidth, the proposed design reduces blocking by up to 87.5%
versus threshold policies while preserving throughput, highlighting the value
of context-driven decisions in coexistence-limited NR SL networks. The proposed
scheduler is an embodied agent (E-agent) tailored for task-specific,
resource-efficient operation at the network edge.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [324] [A Comprehensive Analysis of Churn Prediction in Telecommunications Using Machine Learning](https://arxiv.org/abs/2509.22654)
*Xuhang Chen,Bo Lv,Mengqian Wang,Xunwen Xiang,Shiting Wu,Shenghong Luo,Wenjun Zhang*

Main category: stat.AP

TL;DR: 提出了一个基于深度神经网络的电信客户流失预测框架，通过系统化问题建模和特征工程，显著提升了预测准确性并提供了可解释的洞察。


<details>
  <summary>Details</summary>
Motivation: 电信行业的客户流失预测是一个关键业务智能任务，需要从主观人工评估发展到更复杂的算法方法。

Method: 采用深度神经网络架构，通过系统化问题建模、严谨数据集分析和精心特征工程来捕捉客户行为的复杂模式。

Result: 在多个性能指标上的广泛实证评估表明，所提出的神经架构相比现有基线方法取得了显著改进。

Conclusion: 该方法不仅推进了流失预测准确性的最新水平，还为电信服务中客户流失的关键驱动因素提供了可解释的洞察。

Abstract: Customer churn prediction in the telecommunications sector represents a
critical business intelligence task that has evolved from subjective human
assessment to sophisticated algorithmic approaches. In this work, we present a
comprehensive framework for telecommunications churn prediction leveraging deep
neural networks. Through systematic problem formulation, rigorous dataset
analysis, and careful feature engineering, we develop a model that captures
complex patterns in customer behavior indicative of potential churn. We conduct
extensive empirical evaluations across multiple performance metrics,
demonstrating that our proposed neural architecture achieves significant
improvements over existing baseline methods. Our approach not only advances the
state-of-the-art in churn prediction accuracy but also provides interpretable
insights into the key factors driving customer attrition in telecommunications
services.

</details>


### [325] [U.S. Port Disruptions under Tropical Cyclones: Resilience Analysis by Harnessing Multiple-Source Dataset](https://arxiv.org/abs/2509.22656)
*Chenchen Kuai,Zihao Li,Yunlong Zhang,Xiubin Bruce Wang,Dominique Lord,Yang Zhou*

Main category: stat.AP

TL;DR: 该研究创建了CyPort数据集，记录了90个热带气旋对美国145个主要港口和货运网络的破坏情况，并使用RPNB Lindley模型分析港口韧性，发现4级飓风是破坏加剧的临界点，墨西哥湾港口最脆弱，高中介中心性的港口更具韧性。


<details>
  <summary>Details</summary>
Motivation: 解决特定事件韧性研究的局限性，提供更全面的数据集用于港口韧性分析，克服传统方法在处理零值过多和未观察异质性方面的不足。

Method: 采用随机参数负二项Lindley（RPNB Lindley）模型来分析港口破坏数据，该模型能更好地处理零值过多和未观察异质性问题。

Result: 模型拟合优于传统方法，发现风速、风暴潮高度、降雨量和与气旋距离等特征对港口破坏的影响存在差异，4级飓风是破坏加剧的临界点，墨西哥湾港口最脆弱，货运网络中高中介中心性的港口更具韧性。

Conclusion: RPNB Lindley模型提供了更可靠的港口韧性分析，识别出关键脆弱点和韧性特征，为港口管理和灾害应对提供重要见解。

Abstract: This study introduces the CyPort Dataset, recording disruptions to 145 U.S.
principal ports and freight network from 90 tropical cyclones (2015-2023). It
addresses limitations of event specific resilience studies and provides a
comprehensive dataset for broader analysis. To account for excess zeros and
unobserved heterogeneity in disruption outcomes, the Random Parameter Negative
Binomial Lindley (RPNB Lindley) model is employed to produce more reliable
resilience insights. The model demonstrates improved fit over traditional
methods and uncovers variation in how features such as wind speed, storm surge
height, rainfall, and distance to cyclone influence disruption outcomes across
ports. This analysis reveals a tipping point at Saffir Simpson Hurricane
Category 4, where disruptions escalate sharply, causing greater impacts and
prolonged recovery. Regionally, ports along the Gulf of America show greatest
vulnerability. Within the freight network, ports with high betweenness
centrality are more resilient, while transshipment and local hubs are more
fragile.

</details>


### [326] [Forecasting West Nile virus with deep graph encoders](https://arxiv.org/abs/2509.22657)
*Ethan Greiffenstein,Trevor Harris,Rebecca Smith*

Main category: stat.AP

TL;DR: 提出一种新的图神经网络变体，通过线性连接图注意力层来训练更大的模型，专门用于西尼罗河病毒预测，显著优于传统方法和现有GNN基准。


<details>
  <summary>Details</summary>
Motivation: 西尼罗河病毒在美国是日益严重的公共卫生问题，缺乏人类疫苗，蚊虫控制项目需要准确的预测来确定病毒出现的时间和地点。

Method: 引入新的GNN变体，线性连接图注意力层，能够训练比之前WNV预测所用模型更大的模型，该架构专门优化了通用密集连接的GNN，使模型更关注局部信息以防止过度平滑。

Result: 实验表明，该方法在多种场景和所有预测时间范围内，在样本外和图外WNV预测能力上显著优于GNN和经典基准方法。

Conclusion: 提出的GNN架构通过专注于局部信息和防止过度平滑，显著提升了WNV预测的准确性，为公共卫生决策提供了更可靠的工具。

Abstract: West Nile virus is a significant, and growing, public health issue in the
United States. With no human vaccine, mosquito control programs rely on
accurate forecasting to determine when and where WNV will emerge. Recently,
spatial Graph neural networks (GNNs) were shown to be a powerful tool for WNV
forecasting, significantly improving over traditional methods. Building on this
work, we introduce a new GNN variant that linearly connects graph attention
layers, allowing us to train much larger models than previously used for WNV
forecasting. This architecture specializes general densely connected GNNs so
that the model focuses more heavily on local information to prevent over
smoothing. To support training large GNNs we compiled a massive new dataset of
weather data, land use information, and mosquito trap results across Illinois.
Experiments show that our approach significantly outperforms both GNN and
classical baselines in both out-of-sample and out-of-graph WNV prediction skill
across a variety of scenarios and over all prediction horizons.

</details>


### [327] [Dissecting Multi-Level Pricing Schemes in the Context of eCW Client Engagement](https://arxiv.org/abs/2509.22669)
*Paramahansa Pramanik,Joel Graff,Mike Decaro*

Main category: stat.AP

TL;DR: 该论文提出了一个基于使用量的定价框架，用于eClinicalWorks客户使用的智能医疗对象ProblemIT门户。通过贝叶斯三次平滑样条分析确定稳定的月度单位价格，将客户分为8个体量层级，并根据请求总数计算总费用。


<details>
  <summary>Details</summary>
Motivation: 为eClinicalWorks客户的智能医疗对象ProblemIT门户开发一个公平的基于使用量的定价模型，解决账户请求量异常的问题。

Method: 使用半参数贝叶斯三次平滑样条分析确定月度单位价格，将客户按请求量分为8个层级，并对异常高请求量的账户进行特殊调整。

Result: 分析发现806个单用户账户和470个双用户账户存在异常高请求量，定价模型需要对这些异常情况进行调整。

Conclusion: 提出的定价框架能够为ProblemIT门户提供稳定的基于使用量的定价方案，同时考虑了实际数据中的异常情况。

Abstract: This paper presents a usage-based pricing framework for the Intelligent
Medical Objects ProblemIT Portal utilized by eClinicalWorks (eCW) clients. The
approach begins by determining a stable monthly unit price per request,
estimated as the median from semi-parametric Bayesian cubic smoothing spline
analyses covering the period November 2015 to December 2016. Clients are
subsequently segmented into eight volume-based tiers, with total charges
computed by multiplying the derived median unit price by each client's total
request count. Examination of the dataset reveals that 806 accounts with a
single registered user and 470 accounts with two registered users both exhibit
disproportionately high request volumes. The proposed model incorporates
adjustments to account for these anomalies.

</details>


### [328] [An Econometric Analysis of the Impact of Telecare on the Length of Stay in Hospital](https://arxiv.org/abs/2509.22706)
*Kevin Momanyi*

Main category: stat.AP

TL;DR: 开发理论模型连接远程医疗需求与住院时间，构建三种模型估计治疗效果，并与倾向得分匹配方法比较，发现计量经济学模型优于实验研究设计


<details>
  <summary>Details</summary>
Motivation: 传统实验研究设计未能充分考虑个体健康生产函数的系统性差异和不可观测因素，需要开发更准确的评估方法

Method: 构建三种基于不同分布假设的计量经济学模型，控制混杂变量和不可观测因素，并与倾向得分匹配方法进行对比分析

Result: 计量经济学模型得出的治疗效果优于实验研究设计，后者未能充分处理个体健康生产函数的系统性差异

Conclusion: 在评估远程医疗效果时，应考虑个体健康生产函数的异质性，计量经济学方法比传统实验设计更准确

Abstract: In this paper, we develop a theoretical model that links the demand for
telecare to the length of stay in hospital and formulate three models that can
be used to derive the treatment effect by making various assumptions about the
probability distribution of the outcome measure. We then fit the models to data
and estimate them using a strategy that controls for the effects of confounding
variables and unobservable factors, and compare the treatment effects with that
of the Propensity Score Matching (PSM) technique which adopts a
quasi-experimental study design. To ensure comparability, the covariates are
kept identical in all cases. An important finding that emerges from our
analysis is that the treatment effects derived from our econometric models of
interest are better than that obtained from an experimental study design as the
latter does not account for all the relevant unobservable factors. In
particular, the results show that estimating the treatment effect of telecare
in the way that an experimental study design entails fails to account for the
systematic variations in individuals' health production functions within each
experimental arm.

</details>


### [329] [Modeling Tennis In-Match Momentum Using Probability Method](https://arxiv.org/abs/2509.22670)
*Jackson Graves,Daniel X. Guo,Ridge Shepherd,Alexander Young*

Main category: stat.AP

TL;DR: 本文研究了网球动量模型(TMM)，该模型通过整合效率、历史得分概率和实时得分数据等关键因素来增强对比赛动态的理解。模型旨在探索动量如何影响球员表现以及如何影响比赛结果。


<details>
  <summary>Details</summary>
Motivation: 增强对网球比赛动态的理解，探索动量对球员表现和比赛结果的影响，帮助球员和教练根据动量变化调整策略。

Method: 开发网球动量模型(TMM)，整合效率、历史得分概率和实时得分数据等关键因素，分析动量变化与得分事件的关系。

Result: 在两场网球比赛中测试验证了模型的有效性，TMM能够准确捕捉动量变化并与得分事件相关，清晰描绘比赛中的动量流动。

Conclusion: 网球动量模型成功捕捉了比赛中的动量变化，揭示了动量变化与得分事件之间的直接联系，为球员和教练提供了有价值的策略调整依据。

Abstract: This paper investigates the Tennis Momentum Model (TMM), which aims to
enhance the understanding of match dynamics by integrating key factors such as
efficiency, historical scoring probabilities, and real-time scoring data. The
model is designed to explore how momentum affects player performance throughout
a match and how it might influence overall match outcomes. By leveraging this
model, players and coaches could gain valuable insights that may help them
adjust their strategies in response to shifting momentum during a match.
  To validate the model, it was tested on two tennis matches, revealing its
effectiveness in capturing shifts in momentum and correlating these shifts with
scoring events. The results showed that the TMM accurately depicted the flow of
momentum during matches, highlighting how shifts in momentum are directly
linked to changes in scoring as the match progresses.

</details>


### [330] [PISA: An AI Pipeline for Interpretable-by-design Survival Analysis Providing Multiple Complexity-Accuracy Trade-off Models](https://arxiv.org/abs/2509.22673)
*Thalea Schlender,Catharina J. A. Romme,Yvette M. van der Linden,Luc R. C. W. van Lonkhuijzen,Peter A. N. Bosman,Tanja Alderliesten*

Main category: stat.AP

TL;DR: 提出了一个可解释生存分析管道PISA，通过多特征多目标特征工程构建多种生存分析模型，在保持性能的同时生成患者分层流程图和Kaplan-Meier曲线。


<details>
  <summary>Details</summary>
Motivation: 传统生存模型难以捕捉非线性交互，而深度学习模型可解释性差，临床实践中需要既能准确预测又能提供可解释性洞察的生存分析方法。

Method: 使用多特征多目标特征工程处理患者特征和时间事件数据，构建多种生存分析模型（包括Cox回归和浅层生存树），并将所有模型转换为患者分层流程图和Kaplan-Meier曲线。

Result: 在两个临床基准数据集上实现了最先进的性能，同时生成了可解释的生存模型和直观的分层流程图。在部门研究中的应用证明了其在真实临床研究中的自动化能力。

Conclusion: PISA管道能够在保持高性能的同时提供完全可解释的生存分析结果，通过患者分层流程图使临床医生和研究人员能够获得可操作的洞察，推动了临床研究中生存分析的自动化工作流程。

Abstract: Survival analysis is central to clinical research, informing patient
prognoses, guiding treatment decisions, and optimising resource allocation.
Accurate time-to-event predictions not only improve quality of life but also
reveal risk factors that shape clinical practice. For these models to be
relevant in healthcare, interpretability is critical: predictions must be
traceable to patient-specific characteristics, and risk factors should be
identifiable to generate actionable insights for both clinicians and
researchers. Traditional survival models often fail to capture non-linear
interactions, while modern deep learning approaches, though powerful, are
limited by poor interpretability.
  We propose a Pipeline for Interpretable Survival Analysis (PISA) - a pipeline
that provides multiple survival analysis models that trade off complexity and
performance. Using multiple-feature, multi-objective feature engineering, PISA
transforms patient characteristics and time-to-event data into multiple
survival analysis models, providing valuable insights into the survival
prediction task. Crucially, every model is converted into simple patient
stratification flowcharts supported by Kaplan-Meier curves, whilst not
compromising on performance. While PISA is model-agnostic, we illustrate its
flexibility through applications of Cox regression and shallow survival trees,
the latter avoiding proportional hazards assumptions.
  Applied to two clinical benchmark datasets, PISA produced interpretable
survival models and intuitive stratification flowcharts whilst achieving
state-of-the-art performances. Revisiting a prior departmental study further
demonstrated its capacity to automate survival analysis workflows in real-world
clinical research.

</details>


### [331] [Profit over Proxies: A Scalable Bayesian Decision Framework for Optimizing Multi-Variant Online Experiments](https://arxiv.org/abs/2509.22677)
*Srijesh Pillai,Rajesh Kumar Chandrawat*

Main category: stat.AP

TL;DR: 提出一个贝叶斯决策框架，用于A/B/n测试中的利润优化，解决传统方法中的统计缺陷和代理指标依赖问题。


<details>
  <summary>Details</summary>
Motivation: 在线控制实验在现实应用中存在两个关键问题：使用统计上有缺陷的启发式方法（如p值窥探）导致假阳性率增加，以及过度依赖转换率等代理指标可能导致损害核心业务利润的决策。

Method: 采用分层贝叶斯模型同时估计转换概率（Beta-Bernoulli模型）和转换的货币价值（稳健贝叶斯均值交易价值模型），并基于期望损失的决策理论停止规则。

Result: 该框架成功避免了'收入陷阱'（高转换率但净财务损失的情况），能及早终止无效实验以节约资源，并在整个监控过程中保持严格的统计完整性。

Conclusion: 为组织提供了一个实用且有原则的方法，从简单的A/B测试转向成熟的利润驱动实验文化，确保统计结论直接转化为战略业务价值。

Abstract: Online controlled experiments (A/B tests) are fundamental to data-driven
decision-making in the digital economy. However, their real-world application
is frequently compromised by two critical shortcomings: the use of
statistically flawed heuristics like "p-value peeking", which inflates false
positive rates, and an over-reliance on proxy metrics like conversion rates,
which can lead to decisions that inadvertently harm core business
profitability. This paper addresses these challenges by introducing a
comprehensive and scalable Bayesian decision framework designed for profit
optimization in multi-variant (A/B/n) experiments.
  We propose a hierarchical Bayesian model that simultaneously estimates the
probability of conversion (using a Beta-Bernoulli model) and the monetary value
of that conversion (using a robust Bayesian model for the mean transaction
value). Building on this, we employ a decision-theoretic stopping rule based on
Expected Loss, enabling experiments to be concluded not only when a superior
variant is identified but also when it becomes clear that no variant offers a
practically significant improvement (stopping for futility). The framework
successfully navigates "revenue traps" where a variant with a higher conversion
rate would have resulted in a net financial loss, correctly terminates futile
experiments early to conserve resources, and maintains strict statistical
integrity throughout the monitoring process.
  Ultimately, this work provides a practical and principled methodology for
organizations to move beyond simple A/B testing towards a mature, profit-driven
experimentation culture, ensuring that statistical conclusions translate
directly to strategic business value.

</details>


### [332] [Strategic Play and Home Advantage: Coaches' Tactical Impact in Serie A](https://arxiv.org/abs/2509.22683)
*Francesco Angelini,Massimiliano Castellani,Gery Andrés Díaz Rubio,Simone Giannerini,Greta Goracci*

Main category: stat.AP

TL;DR: 分析意甲联赛中教练策略对比赛结果的影响，发现进攻性开局战术能持续提升表现，而技术动作如传中和球门球有不同模式，主场优势在完全控制后仍然显著。


<details>
  <summary>Details</summary>
Motivation: 研究实时教练决策的经济逻辑，为竞争环境中不确定性下的决策制定提供新的数据驱动方法。

Method: 使用手工编码的意甲比赛评论数据（2011/12-2013/14），应用广义线性、logit和比例优势模型，结合稳健和自助法标准误。

Result: 通过模型平均发现稳定的效应：进攻性开局战术持续提升表现，技术动作呈现不同模式，主场优势在完全控制后仍然显著。

Conclusion: 该方法揭示了实时教练决策的经济逻辑，为研究竞争环境中不确定性下的决策制定提供了新颖的数据驱动方法。

Abstract: We analyze how coaching strategies affect goal difference and home win
probabilities using hand-coded Serie A match commentary (2011/12--2013/14). Our
dataset captures in-game dynamics, referee actions, and team behavior. Applying
generalized linear, logit, and proportional-odds models with robust and
bootstrap standard errors, we uncover stable effects across model averaging.
Aggressive opening tactics consistently boost performance, while technical
actions like crosses and goal-kicks show distinct patterns. Home advantage
remains significant after full control. Our approach reveals the economic logic
of real-time coaching, offering a novel, data-driven method to study
decision-making under uncertainty in competitive environments.

</details>


### [333] [Tracking the Spatiotemporal Spread of the Ohio Overdose Epidemic with Topological Data Analysis](https://arxiv.org/abs/2509.22705)
*Nicholas Bermingham,David White,Nathan Willey*

Main category: stat.AP

TL;DR: 本文使用拓扑数据分析中的Mapper算法分析俄亥俄州2007-2024年药物过量流行情况，提出了一种新的时空数据覆盖构建方法，揭示了时间趋势、过量热点以及与地理和人口统计相关的时滞模式。


<details>
  <summary>Details</summary>
Motivation: 拓扑数据分析技术在多维数据的空间特征捕捉方面已被证明有效，但将其应用于时空数据的研究相对不足。本文旨在扩展先前关于疾病传播的研究，分析药物过量流行情况。

Method: 使用Mapper算法分析俄亥俄州药物过量数据，提出了一种新的时空数据覆盖构建方法，该方法尊重地理结构并突出时间依赖性变量，生成了区域人口统计的Mapper可视化。

Result: 该方法有效揭示了时间趋势、过量热点以及与地理和社区人口统计相关的时滞模式。

Conclusion: 提出的方法成功应用于俄亥俄州药物过量流行分析，为时空数据的拓扑分析提供了有效工具，能够揭示复杂的时间-空间关系模式。

Abstract: In recent years, techniques from Topological Data Analysis (TDA) have proven
effective at capturing spatial features of multidimensional data. However,
applying TDA to spatiotemporal data remains relatively underexplored. In this
work, we extend previous studies of disease spread by using the Mapper
algorithm to analyze the Ohio drug overdose epidemic from 2007 to 2024. We
introduce a novel method for constructing covers in Mapper graphs of
spatiotemporal data that respects geographic structure and highlights the
time-dependent variables. Finally, we generate a Mapper visualization of
regional demographics to examine how these factors relate to overdose deaths.
Our approach effectively reveals temporal trends, overdose hotspots, and
time-lagged patterns in relation to both geography and community demographics.

</details>


### [334] [Vaccinating Now or Vaccinating Later: Separating Pull-Forward and Net Effects Using a Dynamic Regression Discontinuity Design](https://arxiv.org/abs/2509.22714)
*Fabio I. Martinenghi,Mesfin Genie,Katie Attwell,Huong Le,Hannah Moore,Aregawi G. Gebremariam,Bette Liu,Francesco Paolucci,Christopher C. Blyth*

Main category: stat.AP

TL;DR: 该研究分析了针对高中毕业生的新冠疫苗强制令对首剂疫苗接种的影响，发现强制令使疫苗接种率提高了9.3个百分点，但主要是将未来的疫苗接种提前了46-80天，并未增加最终接种率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估针对高中毕业生的疫苗强制令的实际效果，特别是区分"提前接种"（密集边际）与"净增加"（扩展边际）效应，这在疫情背景下是首次尝试。

Method: 使用行政数据，结合西澳大利亚州的严格入学年龄规定，采用断点回归设计（RDD），包括静态和动态RDD分析，以构建毕业生的反事实疫苗接种结果。

Result: 强制令在截止日期时使疫苗接种率提高了9.3个百分点，但动态RDD估计显示这一效应完全是由于将未来的疫苗接种提前了46-80天，最终接种率没有净增加。

Conclusion: 疫苗强制令主要促使原本会接种的人提前接种，而非增加新的接种者；同时为时间限制的非金钱激励在加速疫苗接种运动中的有效性提供了新证据。

Abstract: We study the impact of a novel COVID-19 vaccine mandate, targeting graduating
high-school students, on first vaccine uptake. In 2021, the State Government of
Western Australia (WA) required attendees at "Leavers" -- a large-scale
state-supported graduation party held annually in November in a WA regional
town -- to be vaccinated. Using administrative data that link date-of-birth (at
the month level), school attendance, and first-dose vaccination records, we
exploit the strict school-age laws in WA to run regression discontinuity
designs (RDDs). In other words, we use the date-of-birth cutoff for starting
compulsory schooling in WA to build the counterfactual vaccination outcomes for
Year-12 (i.e. graduating) students. We run both static and dynamic RDDs, the
latter consisting of daily RDD estimations in a one-year window centred around
the policy deadline in November 2021. We find that the "Leavers mandate" --
which excluded unvaccinated Year-12 students from popular post-graduation
events -- raised vaccination rates by 9.3 percentage points at the mandate
deadline. The dynamic RDD estimates show that this effect is entirely due to
pulling forward future vaccinations by 46-80 days, with no net increase in
ultimate uptake. Our paper is first to disentangle "pull-forward" (intensive
margin) versus "net" (extensive margin) effects of a vaccine mandate in a
pandemic context -- meaning that we identify how much the mandate made
eventually-vaccinated people anticipate their vaccination, and how much it
induced vaccinations that would not have happened absent the mandate. We also
bring new evidence on the efficacy of time-limited non-monetary incentives for
accelerating vaccination campaigns. Keywords: mandate; vaccination; incentives;
uptake; adolescents; timing; coverage. JEL: I12; I18.

</details>


### [335] [A Penalized Distributed Lag Non-Linear Lee-Carter Framework for Regional Weekly Mortality Forecasting](https://arxiv.org/abs/2509.24087)
*Jens Robben,Karim Barigou*

Main category: stat.AP

TL;DR: 开发了一个改进的周死亡率预测框架，在Lee-Carter模型基础上加入年龄和地区特定的季节性效应、温度和流感的非线性滞后效应，使用负二项分布处理过度分散，并通过SARIMAX过程和copula方法捕捉时空依赖性。


<details>
  <summary>Details</summary>
Motivation: 准确的周死亡率预测对公共卫生和保险业至关重要，需要更好地捕捉外生驱动因素（温度、流感）和依赖结构的影响。

Method: 扩展Lee-Carter模型，加入年龄和地区特定的季节性效应、惩罚分布滞后非线性组件（捕捉热、冷、流感的延迟非线性效应），使用负二项分布，SARIMAX过程建模时间动态，copula方法捕捉跨区域依赖性。

Result: 使用法国区域死亡率数据（1990-2019）验证，该框架产生校准良好的预测分布，相比基准模型提高了预测准确性，并揭示了年龄和地区间温度与流感相关相对风险的显著异质性。

Conclusion: 研究强调了将外生驱动因素和依赖结构纳入周死亡率预测框架的重要性，所提方法在预测准确性和风险异质性分析方面表现优越。

Abstract: Accurate forecasts of weekly mortality are essential for public health and
the insurance industry. We develop a forecasting framework that extends the
Lee-Carter model with age- and region-specific seasonal effects and penalized
distributed lag non-linear components that capture the delayed and non-linear
effects of heat, cold, and influenza on mortality. The model accommodates
overdispersed mortality rates via a negative binomial distribution. We model
the temporal dynamics of the latent factors in the model using SARIMAX
processes and capture cross-regional dependencies through a copula-based
approach. Using regional French mortality data (1990-2019), we demonstrate that
the proposed framework yields well-calibrated forecast distributions and
improves predictive accuracy relative to benchmark models. The results further
show substantial heterogeneity in temperature- and influenza-related relative
risks between ages and regions. These findings underscore the importance of
incorporating exogenous drivers and dependence structures into a weekly
mortality forecasting framework.

</details>


### [336] [Assessing Roundabout Safety Perceptions under Heterogeneous Traffic: Socio-Demographic and Geometric Influences in Indian Urban Contexts](https://arxiv.org/abs/2509.24397)
*Abhijnan Maji,Indrajit Ghosh*

Main category: stat.AP

TL;DR: 该研究通过问卷调查分析环岛用户的安全感知，发现单车道环岛被认为更安全，而双车道和多车道环岛在出口操作时风险感知更高。驾驶经验、车辆类型和几何配置是影响安全感知的关键因素。


<details>
  <summary>Details</summary>
Motivation: 传统的碰撞和冲突分析未考虑环岛用户的社会人口特征，需要通过大规模问卷调查来捕捉这些特征，以改善混合交通环境下的道路安全。

Method: 使用多重对应分析、聚类分析、因子分析和多项逻辑回归，分析来自印度两个城市1530名受访者的数据。

Result: 识别出三个环岛用户群体。单车道环岛在进入和循环时被认为更安全，而双车道和多车道环岛在出口操作时风险感知更高。弱势道路使用者在不良照明条件下感知风险显著更高。

Conclusion: 驾驶经验、车辆类型和几何配置对环岛安全感知至关重要。研究强调需要改善环岛的建成环境，特别是针对弱势道路使用者。环岛合并区域被认为是最危险的位置。

Abstract: Evaluation of the safety perceptions of roundabout users is crucial for
improving road safety in mixed-traffic environments. The crash- and
conflict-based analyses do not incorporate the socio-demographic
characteristics of the roundabout users, which can only be captured through
questionnaire surveys on a larger scale. This research evaluated the
relationship of roundabout safety perception with demographic factors, driving
characteristics, and varying roundabout geometries using multiple
correspondence analysis, cluster analysis, factor analysis, and multinomial
logistic regression. The study analyzed data from 1,530 respondents across two
Indian cities. The study identified three roundabout user clusters. Single-lane
roundabouts were perceived as safer during entry and circulation, with a
significant prominence among middle-aged users. In contrast, double- and
multi-lane roundabouts presented higher perceived risks during exit maneuvers,
especially among young, inexperienced, unemployed/self-employed users.
Vulnerable road users reported significantly higher perceived risks, especially
under suboptimal lighting conditions. Respondents with 10-20 years of driving
experience, especially car users, perceived lower risk at single-lane
roundabouts but acknowledged the higher risk linked to speed variations and
complex maneuvers at multi-lane roundabouts. Driving experience, vehicle type,
and geometric configurations were crucial in roundabout safety perception. The
study highlighted the need to improve the built environment of roundabouts for
vulnerable road users. The roundabout merging area was perceived as the most
dangerous spot; however, exits were also perceived as dangerous for double- and
multi-lane roundabouts. The findings can benefit policymakers, engineers, and
urban planners by enabling them to deploy targeted safety interventions based
on issues highlighted in the study.

</details>
