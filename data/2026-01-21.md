<div id=toc></div>

# Table of Contents

- [cs.ET](#cs.ET) [Total: 4]
- [cs.SI](#cs.SI) [Total: 9]
- [econ.EM](#econ.EM) [Total: 10]
- [cs.AI](#cs.AI) [Total: 101]
- [stat.AP](#stat.AP) [Total: 12]
- [cs.CY](#cs.CY) [Total: 32]


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [1] [A Proof of Concept for a Digital Twin of an Ultrasonic Fermentation System](https://arxiv.org/abs/2601.11723)
*Francesco Saverio Sconocchia Pisoni,Andrea Vitaletti,Davide Appolloni,Federico Ortenzi,Blasco Morozzo della Rocca,Mariano José Guillén,Alessandro Contaldo*

Main category: cs.ET

TL;DR: 开发了一个用于超声波增强啤酒发酵系统的数字孪生概念验证，通过超声波刺激加速酵母生长和发酵过程，并建立了基于环境条件的酵母密度预测模型。


<details>
  <summary>Details</summary>
Motivation: 传统发酵过程缺乏智能监控和预测能力，需要一种能够实时监测、预测并主动调控酵母生长环境的方法，以提高发酵效率和产品质量。

Method: 在传统发酵罐中安装压电换能器产生超声波刺激酵母生长；开发数字孪生系统，基于Palacios等人的模型进行改进，使用温度、超声波频率和占空比作为输入参数，在有限训练样本条件下预测酵母培养密度。

Result: 模型性能评估结果表明，所提出的数字孪生方法在预测酵母密度方面是可行的，能够有效处理有限的训练样本，实现对发酵过程的智能监控和预测。

Conclusion: 该研究成功实现了超声波增强啤酒发酵系统的数字孪生概念验证，为发酵过程的智能监控、预测和调控提供了可行的技术方案，具有实际应用潜力。

Abstract: This paper presents the design and implementation of a proof of concept digital twin for an innovative ultrasonic-enhanced beer-fermentation system, developed to enable intelligent monitoring, prediction, and actuation in yeast-growth environments. A traditional fermentation tank is equipped with a piezoelectric transducer able to irradiate the tank with ultrasonic waves, providing an external abiotic stimulus to enhance the growth of yeast and accelerate the fermentation process. At its core, the digital twin incorporates a predictive model that estimates yeast's culture density over time based on the surrounding environmental conditions. To this end, we implement, tailor and extend the model proposed in Palacios et al., allowing us to effectively handle the limited number of available training samples by using temperature, ultrasonic frequency, and duty cycle as inputs. The results obtained along with the assessment of model performance demonstrate the feasibility of the proposed approach.

</details>


### [2] [COVERT: Trojan Detection in COTS Hardware via Statistical Activation of Microarchitectural Events](https://arxiv.org/abs/2601.11939)
*Mahmudul Hasan,Sudipta Paria,Swarup Bhunia,Tamzidul Hoque*

Main category: cs.ET

TL;DR: 提出COVERT框架，无需黄金模型即可检测COTS微处理器中的硬件木马，通过LLM生成测试程序触发罕见微架构事件来激活潜在木马触发器。


<details>
  <summary>Details</summary>
Motivation: COTS硬件因开发成本低被广泛使用，但其供应链不可信，可能存在硬件木马。现有检测方法不适用于黑盒的COTS组件，需要昂贵设备且缺乏可扩展性。

Method: 提出COVERT框架：1) 利用LLM自动生成触发罕见微架构事件的测试程序；2) 从公开的RTL实现推导事件；3) 将激活知识从现有处理器设计迁移到目标COTS处理器；4) 通过识别罕见事件来测试硬件木马存在。

Result: 在开源RISC-V COTS微处理器上评估，能有效激活组合和时序木马触发器，覆盖率很高。在or1k Marocchino和PicoRV32处理器中，对最罕见的5%事件实现了超过80%的触发器覆盖率。

Conclusion: COVERT提供了一种高效、无需黄金模型的COTS微处理器信任验证框架，能检测各类硬件木马，具有实际应用价值。

Abstract: Commercial Off-The-Shelf (COTS) hardware, such as microprocessors, are widely adopted in system design due to their ability to reduce development time and cost compared to custom solutions. However, supply chain entities involved in the design and fabrication of COTS components are considered untrusted from the consumer's standpoint due to the potential insertion of hidden malicious logic or hardware Trojans (HTs). Existing solutions to detect Trojans are largely inapplicable for COTS components due to their black-box nature and lack of access to a golden model. A few studies that apply require expensive equipment, lack scalability, and apply to a limited class of Trojans. In this work, we present a novel golden-free trust verification framework, COVERT for COTS microprocessors, which can efficiently test the presence of hardware Trojan implants by identifying microarchitectural rare events and transferring activation knowledge from existing processor designs to trigger highly susceptible internal nodes. COVERT leverages Large Language Models to automatically generate test programs that trigger rare microarchitectural events, which may be exploited to develop Trojan trigger conditions. By deriving these events from publicly available Register Transfer Level implementations, COVERT can verify a wide variety of COTS microprocessors that inherit the same Instruction Set Architecture. We have evaluated the proposed framework on open-source RISC-V COTS microprocessors and demonstrated its effectiveness in activating combinational and sequential Trojan triggers with high coverage, highlighting the efficiency of the trust verification. By pruning rare microarchitectural events from mor1kx Cappuccino OpenRISC processor design, COVERT has been able to achieve more than 80% trigger coverage for the rarest 5% of events in or1k Marocchino and PicoRV32 as COTS processors.

</details>


### [3] [AlphaSyndrome: Tackling the Syndrome Measurement Circuit Scheduling Problem for QEC Codes](https://arxiv.org/abs/2601.12509)
*Yuhao Liu,Shuohao Ping,Junyu Zhou,Ethan Decker,Justin Kalloor,Mathias Weiden,Kean Chen,Yunong Shi,Ali Javadi-Abhari,Costin Iancu,Gushu Li*

Main category: cs.ET

TL;DR: AlphaSyndrome：一个自动化合成框架，用于优化量子纠错码中的测量调度，通过MCTS搜索最优调度方案，显著降低逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 量子纠错中重复的测量循环占据了主要的时空和硬件成本。虽然稳定子可交换且存在多种有效执行顺序，但不同调度在真实噪声下会产生不同的错误传播路径，导致逻辑错误率差异巨大。除表面码外，有效的测量调度研究较少。

Method: 将测量调度建模为优化问题，通过蒙特卡洛树搜索（MCTS）探索顺序和并行性，利用代码结构和解码器反馈指导搜索，使错误传播模式远离逻辑算子并保持在解码器可纠正区域内。

Result: 在多种代码族、尺寸和解码器上，AlphaSyndrome相比深度最优基线平均降低80.6%逻辑错误率（最高96.2%），与Google手工设计的表面码调度相当，并优于IBM的双变量自行车码调度。

Conclusion: AlphaSyndrome为通用可交换稳定子码提供了有效的自动化测量调度框架，显著提升量子纠错性能，填补了表面码之外调度研究的空白。

Abstract: Quantum error correction (QEC) is essential for scalable quantum computing, yet repeated syndrome-measurement cycles dominate its spacetime and hardware cost. Although stabilizers commute and admit many valid execution orders, different schedules induce distinct error-propagation paths under realistic noise, leading to large variations in logical error rate. Outside of surface codes, effective syndrome-measurement scheduling remains largely unexplored. We present AlphaSyndrome, an automated synthesis framework for scheduling syndrome-measurement circuits in general commuting-stabilizer codes under minimal assumptions: mutually commuting stabilizers and a heuristic decoder. AlphaSyndrome formulates scheduling as an optimization problem that shapes error propagation to (i) avoid patterns close to logical operators and (ii) remain within the decoder's correctable region. The framework uses Monte Carlo Tree Search (MCTS) to explore ordering and parallelism, guided by code structure and decoder feedback. Across diverse code families, sizes, and decoders, AlphaSyndrome reduces logical error rates by 80.6% on average (up to 96.2%) relative to depth-optimal baselines, matches Google's hand-crafted surface-code schedules, and outperforms IBM's schedule for the Bivariate Bicycle code.

</details>


### [4] [Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk](https://arxiv.org/abs/2601.13376)
*Jiqun Liu*

Main category: cs.ET

TL;DR: 该论文主张基于有限理性理论设计对话AI，使其与人类启发式思维协作而非对抗，重点关注检测认知脆弱性、支持不确定性判断，以及超越事实准确性评估对话系统。


<details>
  <summary>Details</summary>
Motivation: 当前对话AI系统大多假设理想化用户，但实际人类推理受限于注意力、知识不均衡和易产生偏差的启发式思维。需要设计能适应人类真实认知局限的对话AI。

Method: 基于有限理性理论框架，提出研究路径：1) 检测认知脆弱性；2) 支持不确定性下的判断；3) 超越事实准确性，从决策质量和认知鲁棒性角度评估对话系统。

Result: 论文提出了一个研究框架，但未报告具体实验结果。它识别了关键研究方向：认知脆弱性检测、不确定性支持、以及更全面的系统评估方法。

Conclusion: 对话AI应基于有限理性理论设计，与人类启发式思维协作而非对抗，重点关注认知脆弱性检测、不确定性支持，以及超越事实准确性的系统评估，以提升决策质量和认知鲁棒性。

Abstract: Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. In practice, human reasoning is bounded by limited attention, uneven knowledge, and reliance on heuristics that are adaptive but bias-prone. This article outlines a research pathway grounded in bounded rationality, and argues that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [5] [Multifaceted Scenario-Aware Hypergraph Learning for Next POI Recommendation](https://arxiv.org/abs/2601.11610)
*Yuxi Lin,Yongkang Li,Jie Xing,Zipei Fan*

Main category: cs.SI

TL;DR: MSAHG：一种用于多场景POI推荐的场景感知超图学习方法，通过构建场景特定的解耦子超图和参数分割机制来捕捉不同场景下的移动模式并解决场景间冲突。


<details>
  <summary>Details</summary>
Motivation: 现有序列和图方法常忽视不同上下文场景（如游客vs本地人）间的移动变化，导致无法捕捉场景特定特征和解决场景间冲突，从而影响推荐性能。

Method: 提出多面场景感知超图学习（MSAHG）框架，采用场景分割范式：1)构建场景特定多视图解耦子超图捕捉不同移动模式；2)参数分割机制自适应解决场景间冲突优化方向，同时保持泛化能力。

Result: 在三个真实世界数据集上的实验表明，MSAHG在多种场景下持续优于五种最先进方法，验证了其在多场景POI推荐中的有效性。

Conclusion: MSAHG通过场景分割范式和参数分割机制有效解决了多场景POI推荐中的场景特定特征捕捉和场景间冲突问题，显著提升了推荐性能。

Abstract: Among the diverse services provided by Location-Based Social Networks (LBSNs), Next Point-of-Interest (POI) recommendation plays a crucial role in inferring user preferences from historical check-in trajectories. However, existing sequential and graph-based methods frequently neglect significant mobility variations across distinct contextual scenarios (e.g., tourists versus locals). This oversight results in suboptimal performance due to two fundamental limitations: the inability to capture scenario-specific features and the failure to resolve inherent inter-scenario conflicts. To overcome these limitations, we propose the Multifaceted Scenario-Aware Hypergraph Learning method (MSAHG), a framework that adopts a scenario-splitting paradigm for next POI recommendation.
  Our main contributions are:
  (1) Construction of scenario-specific, multi-view disentangled sub-hypergraphs to capture distinct mobility patterns;
  (2) A parameter-splitting mechanism to adaptively resolve conflicting optimization directions across scenarios while preserving generalization capability.
  Extensive experiments on three real-world datasets demonstrate that MSAHG consistently outperforms five state-of-the-art methods across diverse scenarios, confirming its effectiveness in multi-scenario POI recommendation.

</details>


### [6] [Effective and Unsupervised Social Event Detection and Evolution via RAG and Structural Entropy](https://arxiv.org/abs/2601.12035)
*Qitong Liu,Hao Peng,Zuchen Li,Xihang Meng,Ziyu Yang,Jiting Li,Li Sun,Philip S. Yu*

Main category: cs.SI

TL;DR: RagSEDE是一个用于无监督社交媒体事件检测与演化的基础模型，通过代表性-多样性采样策略减少噪声和计算开销，基于RAG增强预训练语言模型的事件检测能力，并利用结构信息理论动态建模事件演化关键词。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体事件检测方法面临三大挑战：1) 海量社交媒体消息导致学习资源密集；2) 消息碎片化阻碍模型获取事件的全面视图；3) 缺乏结构化时间上下文限制了事件演化模型的发展，影响用户获取事件信息。

Method: 1) 引入代表性-多样性驱动的采样策略从海量社交流中提取关键消息；2) 建立基于检索增强生成(RAG)的新范式，增强PLMs的事件检测能力，同时构建和维护演化的事件知识库；3) 首次利用结构信息理论动态建模事件演化关键词。

Result: 在两个公开数据集上的大量实验表明，RagSEDE在开放世界社交媒体事件检测和演化方面具有优越性。

Conclusion: RagSEDE通过创新的采样策略、RAG范式和结构信息理论应用，有效解决了社交媒体事件检测与演化中的关键挑战，为开放世界事件分析提供了有效的基础模型。

Abstract: With the growing scale of social media, social event detection and evolution modeling have attracted increasing attention. Graph neural networks (GNNs) and transformer-based pre-trained language models (PLMs) have become mainstream approaches in this area. However, existing methods still face three major challenges. First, the sheer volume of social media messages makes learning resource-intensive. Second, the fragmentation of social media messages often impedes the model's ability to capture a comprehensive view of the events. Third, the lack of structured temporal context has hindered the development of effective models for event evolution, limiting users' access to event information. To address these challenges, we propose a foundation model for unsupervised Social Event Detection and Evolution, namely RagSEDE. Specifically, RagSEDE introduces a representativeness- and diversity-driven sampling strategy to extract key messages from massive social streams, significantly reducing noise and computational overhead. It further establishes a novel paradigm based on Retrieval Augmented Generation (RAG) that enhances PLMs in detecting events while simultaneously constructing and maintaining an evolving event knowledge base. Finally, RagSEDE leverages structural information theory to dynamically model event evolution keywords for the first time. Extensive experiments on two public datasets demonstrate the superiority of RagSEDE in open-world social event detection and evolution.

</details>


### [7] [Constructing a Dataset to Support Agent-Based Modeling of Online Interactions: Users, Topics, and Interaction Networks](https://arxiv.org/abs/2601.12628)
*Abdul Sittar,Miha Cesnovar,Alenka Gucek,Marko Grobelnik*

Main category: cs.SI

TL;DR: 构建基于Reddit的大规模实证数据集，用于开发基于智能体的社会模拟，包含技术、气候和COVID相关主题的聚合智能体，约100万条帖子和评论。


<details>
  <summary>Details</summary>
Motivation: 现有基于智能体的模型（ABM）大多依赖手工制作或参数化的智能体规则，缺乏实证基础，限制了模型的真实性和对观测数据的验证能力。

Method: 从Reddit公开帖子和评论构建数据集，基于内容和交互模式定义智能体类别，从时间性评论行为推导智能体间关系，构建反映实证观察用户连接的有向加权网络。

Result: 数据集包含33个技术相关、14个气候相关和7个COVID相关的聚合智能体，约100万条帖子和评论。定量分析显示不同主题的交互模式差异：气候讨论网络密集且高度连接，COVID交互稀疏且单向，技术讨论围绕少数中心枢纽组织。

Conclusion: 该数据集使研究人员能够根据真实社会动态校准和基准测试智能体行为、网络结构和信息扩散过程，支持开发更实证基础的基于智能体的社会模拟。

Abstract: Agent-based modeling (ABM) provides a powerful framework for exploring how individual behaviors and interactions give rise to collective social dynamics. However, most ABMs rely on handcrafted or parameterized agent rules that are not empirically grounded, thereby limiting their realism and validation against observed data. To address this gap, we constructed a large-scale, empirically grounded dataset from Reddit to support the development and evaluation of agent-based social simulations. The dataset includes 33 technology-focused, 14 climate-focused, and 7 COVID-related aggregated agents, encompassing around one million posts and comments. Using publicly available posts and comments, we define agent categories based on content and interaction patterns, derive inter-agent relationships from temporal commenting behaviors, and build a directed, weighted network that reflects empirically observed user connections. The resulting dataset enables researchers to calibrate and benchmark agent behavior, network structure, and information diffusion processes against real social dynamics. Our quantitative analysis reveals clear topic-dependent differences in how users interact. Climate discussions show dense, highly connected networks with sustained engagement, COVID-related interactions are sparse and mostly one-directional, and technology discussions are organized around a small number of central hubs. Manual qualitative analysis further shows that agent interactions follow realistic patterns of timing, similarity between users, and sentiment change.

</details>


### [8] [The Tag is the Signal: URL-Agnostic Credibility Scoring for Messages on Telegram](https://arxiv.org/abs/2601.13294)
*Yipeng Wang,Huy Gia Han Vu,Mohit Singhal*

Main category: cs.SI

TL;DR: TAG2CRED：针对Telegram短消息设计的可信度评估管道，通过LLM生成标签并映射为风险分数，优于传统TF-IDF方法


<details>
  <summary>Details</summary>
Motivation: Telegram已成为传播错误信息的主要平台，但现有方法（基于域名信誉或词频特征）对短且URL稀疏的Telegram消息效果不佳，需要专门针对此类消息的评估方法

Method: 提出TAG2CRED管道：1）设计简洁标签系统（主题、声明类型、行动呼吁、证据）；2）使用微调LLM为消息分配标签；3）通过L2正则化逻辑回归将标签映射到[0,1]区间的校准风险分数

Result: 在87,936条Telegram消息上评估：TAG2CRED的ROC-AUC达0.871，macro-F1为0.787，Brier分数0.167，优于TF-IDF基线（macro-F1 0.737，Brier 0.248）；集成模型（TF-IDF+TAG2CRED+SBERT）性能进一步提升，ROC-AUC达0.901，macro-F1为0.813

Conclusion: TAG2CRED能有效评估Telegram短消息的可信度，使用特征更少且在罕见域名上泛化能力更强；风格标签和词汇特征捕捉了不同但互补的信息风险维度

Abstract: Telegram has become one of the leading platforms for disseminating misinformational messages. However, many existing pipelines still classify each message's credibility based on the reputation of its associated domain names or its lexical features. Such methods work well on traditional long-form news articles published by well-known sources, but high-risk posts on Telegram are short and URL-sparse, leading to failures for link-based and standard TF-IDF models. To this end, we propose the TAG2CRED pipeline, a method designed for such short, convoluted messages. Our model will directly score each post based on the tags assigned to the text. We designed a concise label system that covers the dimensions of theme, claim type, call to action, and evidence. The fine-tuned large language model (LLM) assigns tags to messages and then maps these tags to calibrated risk scores in the [0,1] interval through L2-regularized logistic regression. We evaluated 87,936 Telegram messages associated with Media Bias/Fact Check (MBFC), using URL masking and domain disjoint splits. The results showed that the ROC-AUC of the TAG2CRED model reached 0.871, the macro-F1 value was 0.787, and the Brier score was 0.167, outperforming the baseline TF-IDF (macro-F1 value 0.737, Brier score 0.248); at the same time, the number of features used in this model is much smaller, and the generalization ability on infrequent domains is stronger. The performance of the stacked ensemble model (TF-IDF + TAG2CRED + SBERT) was further improved over the baseline SBERT. ROC-AUC reached 0.901, and the macro-F1 value was 0.813 (Brier score 0.114). This indicates that style labels and lexical features may capture different but complementary dimensions of information risk.

</details>


### [9] [The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing](https://arxiv.org/abs/2601.13487)
*Olivia Pal,Agam Goyal,Eshwar Chandrasekharan,Koustuv Saha*

Main category: cs.SI

TL;DR: 新闻参与产生系统性权衡：增加抑郁、压力和焦虑，但减少孤独感并增加社交互动；书签比评论或引用带来更严重的心理社会恶化


<details>
  <summary>Details</summary>
Motivation: 社交媒体新闻消费普遍，但不同参与形式如何影响心理社会结果尚不清楚，需要填补这一研究空白

Method: 利用BlueSky平台约2600万帖子和4500万评论的大规模数据集，进行准实验研究，通过分层倾向得分分析匹配81,345名暴露于新闻推送的"处理组"用户和83,711名"对照组"用户

Result: 新闻参与产生系统性权衡：增加抑郁、压力和焦虑，但减少孤独感并增加平台上的社交互动；回归模型显示新闻推送书签比评论或引用带来更严重的心理社会恶化，差异超过十倍；这些每次参与效应随重复暴露累积，产生显著心理社会影响

Conclusion: 研究将新闻效应理论扩展到危机中心框架之外，证明日常消费根据参与类型产生不同的心理动态，对减轻社交媒体新闻消费心理社会成本的工具和干预措施具有启示意义

Abstract: News consumption on social media has become ubiquitous, yet how different forms of engagement shape psychosocial outcomes remains unclear. To address this gap, we leveraged a large-scale dataset of ~26M posts and ~45M comments on the BlueSky platform, and conducted a quasi-experimental study, matching 81,345 Treated users exposed to News feeds with 83,711 Control users using stratified propensity score analysis. We examined psychosocial wellbeing, in terms of affective, behavioral, and cognitive outcomes. Our findings reveal that news engagement produces systematic trade-offs: increased depression, stress, and anxiety, yet decreased loneliness and increased social interaction on the platform. Regression models reveal that News feed bookmarking is associated with greater psychosocial deterioration compared to commenting or quoting, with magnitude differences exceeding tenfold. These per-engagement effects accumulate with repeated exposure, showing significant psychosocial impacts. Our work extends theories of news effects beyond crisis-centric frameworks by demonstrating that routine consumption creates distinct psychological dynamics depending on engagement type, and bears implications for tools and interventions for mitigating the psychosocial costs of news consumption on social media.

</details>


### [10] [Modeling Perpetrators' Fate-to-Fate Contagion in Public Mass Shootings In The United States Using Bivariate Hawkes Processes](https://arxiv.org/abs/2601.13501)
*Youness Diouane,James Silver*

Main category: cs.SI

TL;DR: 研究使用1966-2024年数据，通过双变量霍克斯过程分析大规模枪击案中施害者结局（现场死亡vs幸存）对后续事件的传染效应，发现幸存事件会显著触发后续现场死亡事件，而反向影响不显著。


<details>
  <summary>Details</summary>
Motivation: 探究大规模枪击事件中施害者不同结局（现场死亡或幸存）是否会相互影响，形成传染模式，这对于理解此类事件的传播机制和制定预防策略具有重要意义。

Method: 使用1966-2024年的大规模枪击事件数据，根据施害者结局（现场死亡/幸存）分类事件，采用双变量霍克斯过程量化交叉激发效应（不同结局类型间的相互影响）和自激发效应（同类型事件间的相互影响）。

Result: 发现最强的溢出效应是从"幸存"事件到"现场死亡"事件，约34%的现场死亡事件由先前幸存事件触发，传染时间尺度约20天；反向影响不显著；现场死亡事件仅能触发同类型事件（约13.9%），传染时间尺度最短约20小时。

Conclusion: 大规模枪击事件中施害者结局存在不对称的传染模式：幸存事件会显著增加后续现场死亡事件的风险，而现场死亡事件主要影响同类事件，这为理解事件传播动态和制定针对性干预措施提供了实证依据。

Abstract: This study examines how the fate of a perpetrator in a public mass shooting influences the fate of subsequent perpetrators. Using data from 1966 to 2024, we classify incidents according to whether the perpetrator died at the scene or survived the attack. Using a bivariate Hawkes process, we quantify the cross-excitation effect, which is the triggering effect that each event type exerts on the other, i.e., "die at the scene"$\rightarrow$ "live" and "live"$\rightarrow$ "die at the scene", as well as the self-excitation effects, i.e., "die at the scene"$\rightarrow$ "die at the scene" and "live"$\rightarrow$ "live". Our results show that the strongest spillover was from "live" incidents to "die at the scene", where we estimate that 0.34 (0.09, 0.80) of "die at the scene" incidents are triggered by a prior event in which the offender survived the attack. This pathway also exhibits the longest estimated contagion timescale: approximately 20 days. In contrast, the reverse influence, that is, "die at the scene"$\rightarrow$"live", is not statistically significant, with the lower bound of its 95% confidence interval nearly equal to zero. We also find that "die at the scene" events can only cause their own type, where 0.139 (0.01, 0.52) of such incidents are caused by previous "die at the scene" events, with the shortest contagion timescale of roughly 20 hours.

</details>


### [11] [TRGCN: A Hybrid Framework for Social Network Rumor Detection](https://arxiv.org/abs/2601.13573)
*Yanqin Yan,Suiyu Zhang,Dingguo Yu,Yijie Zhou,Cheng-Jun Wang,Ke-ke Shang*

Main category: cs.SI

TL;DR: 本文提出了一种结合图卷积网络(GCN)和Transformer的混合模型，用于社交媒体谣言检测，通过整合传播网络结构和文本语义特征，在Twitter数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上谣言快速传播对信息治理构成挑战。传统方法依赖人工分析，现有机器学习方法难以同时捕捉传播网络中节点的序列关系和全局结构关系，需要更有效的模型来整合结构和语义特征。

Method: 提出GCN-Transformer混合模型：1) 使用GCN捕捉传播网络的结构特征；2) 结合Transformer处理文本语义；3) 引入位置编码保持传播节点序列顺序；4) 采用多头注意力机制从不同表示子空间捕获特征。

Result: 在Twitter 15和Twitter 16公开数据集上的实验表明，该融合模型在准确率上显著优于单独模型和现有主流方法，验证了方法的有效性。

Conclusion: GCN-Transformer混合模型能够同时识别谣言的关键传播网络、文本内容、长距离依赖和传播节点序列，为谣言检测任务提供了有效解决方案。

Abstract: Accurate and efficient rumor detection is critical for information governance, particularly in the context of the rapid spread of misinformation on social networks. Traditional rumor detection relied primarily on manual analysis. With the continuous advancement of technology, machine learning and deep learning approaches for rumor identification have gradually emerged and gained prominence. However, previous approaches often struggle to simultaneously capture both the sequential and the global structural relationships among topological nodes within a social network. To tackle this issue, we introduce a hybrid model for detecting rumors that integrates a Graph Convolutional Network (GCN) with a Transformer architecture, aiming to leverage the complementary strengths of structural and semantic feature extraction. Positional encoding helps preserve the sequential order of these nodes within the propagation structure. The use of Multi-head attention mechanisms enables the model to capture features across diverse representational subspaces, thereby enhancing both the richness and depth of text comprehension. This integration allows the framework to concurrently identify the key propagation network of rumors, the textual content, the long-range dependencies, and the sequence among propagation nodes. Experimental evaluations on publicly available datasets, including Twitter 15 and Twitter 16, demonstrate that our proposed fusion model significantly outperforms both standalone models and existing mainstream methods in terms of accuracy. These results validate the effectiveness and superiority of our approach for the rumor detection task.

</details>


### [12] [Consensus Stability of Community Notes on X](https://arxiv.org/abs/2601.14002)
*Yuwei Chuai,Gabriele Lenzini,Nicolas Pröllochs*

Main category: cs.SI

TL;DR: 社区事实核查系统（如X平台的Community Notes）中，30.2%已显示的"有用"注释后来会失去该状态而消失，主要原因是注释显示后引发的评分极化现象


<details>
  <summary>Details</summary>
Motivation: 虽然之前的研究表明X平台的Community Notes系统能有效选择"有用"注释，但缺乏对注释显示后评分动态变化的研究。需要了解注释显示后评分如何变化，以及这是否影响注释的长期稳定性

Method: 使用大规模数据集（437,396条社区注释和3,500万条评分，来自580,000多名贡献者），采用中断时间序列模型分析注释显示前后的评分动态，并进行反事实分析

Result: 1. 30.2%已显示的"有用"注释后来会失去该状态而消失；2. 注释显示会触发评分量激增和评分倾向显著变化；3. 观点相似的评分者增加支持性评分，观点不同的评分者增加负面评分，导致系统性极化；4. 反事实分析表明这种极化（特别是来自不同观点评分者的负面评分）是注释消失的重要原因

Conclusion: 基于共识的事实核查系统容易受到极化评分行为的影响，这揭示了系统的脆弱性，并为提高其韧性提供了改进方向

Abstract: Community-based fact-checking systems, such as Community Notes on X (formerly Twitter), aim to mitigate online misinformation by surfacing annotations judged helpful by contributors with diverse viewpoints. While prior work has shown that the platform's bridging-based algorithm effectively selects helpful notes at the time of display, little is known about how evaluations change after notes become visible. Using a large-scale dataset of 437,396 community notes and 35 million ratings from over 580,000 contributors, we examine the stability of helpful notes and the rating dynamics that follow their initial display. We find that 30.2% of displayed notes later lose their helpful status and disappear. Using interrupted time series models, we further show that note display triggers a sharp increase in rating volume and a significant shift in rating leaning, but these effects differ across rater groups. Contributors with viewpoints similar to note authors tend to increase supportive ratings, while dissimilar contributors increase negative ratings, producing systematic post-display polarization. Counterfactual analyses suggest that this post-display polarization, particularly from dissimilar raters, plays a substantial role in note disappearance. These findings highlight the vulnerability of consensus-based fact-checking systems to polarized rating behavior and suggest pathways for improving their resilience.

</details>


### [13] [Beyond Polarization: Opinion Mixing and Social Influence in Deliberation](https://arxiv.org/abs/2601.14221)
*Mohak Goyal,Lodewijk Gelauff,Naman Gupta,Ashish Goel,Kamesh Munagala*

Main category: cs.SI

TL;DR: 研究引入"意见混合"概念，通过排名相关性衡量审议前后意见重组程度，发现审议增加意见混合，而传统方差极化指标呈现异质性结果


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注审议增加或减少极化，但忽略了意见重组这一更诊断性的维度。需要补充传统方差极化指标，更全面理解审议如何改变意见结构

Method: 1) 引入意见混合概念，用肯德尔等级相关性(τ)衡量审议前后意见排名变化；2) 在两个大型在线审议调查中(32个国家，n=6,342和n=1,529)比较处理组与对照组；3) 在第三个事件(n=617，116组)中结合转录文本和调查数据，使用LLM辅助编码6,232条讨论陈述分析机制

Result: 1) 审议显著增加意见混合：处理组在97%和93%的问题上表现出更低的排名相关性；2) 方差极化指标结果异质：对照组一致收敛，处理组有时收敛有时发散；3) 讨论陈述中的支持表达强烈预测群体层面意见转变，这种相关性被论证质量放大而非论证新颖性

Conclusion: 审议后的意见变化与选择性采纳合理论证相关，产生复杂的意见重组模式，传统极化指标可能错过这些模式。不同论证质量概念对审议结果有不同影响

Abstract: Deliberative processes are often discussed as increasing or decreasing polarization. This approach misses a different, and arguably more diagnostic, dimension of opinion change: whether deliberation reshuffles who agrees with whom, or simply moves everyone in parallel while preserving the pre-deliberation rank ordering. We introduce \opinion mixing, measured by Kendall's rank correlation (τ) between pre- and post-deliberation responses, as a complement to variance-based polarization metrics. Across two large online deliberative polls spanning 32 countries (MCF-2022: n=6,342; MCF-2023: n=1,529), deliberation increases opinion mixing relative to survey-only controls: treatment groups exhibit lower rank correlation on (97%) and (93%) of opinion questions, respectively. Polarization measures based on variance tell a more heterogeneous story: controls consistently converge, while treated groups sometimes converge and sometimes diverge depending on the issue.
  To probe mechanisms, we link transcripts and surveys in a third event (SOF: (n=617), 116 groups) and use LLM-assisted coding of 6,232 discussion statements. Expressed support in discussion statements strongly predicts subsequent group-level opinion shifts; this correlation is amplified by justification quality in the statements but not by argument novelty. To our knowledge, we are the first to observe how different notions of argument quality have different associations with the outcome of deliberation. This suggests that opinion change after deliberation is related to selective uptake of well-reasoned arguments, producing complex patterns of opinion reorganization that standard polarization metrics may miss.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [14] [Reevaluating Causal Estimation Methods with Data from a Product Release](https://arxiv.org/abs/2601.11845)
*Justin Young,Muthoni Ngatia,Eleanor Wiske Dillon*

Main category: econ.EM

TL;DR: 论文分析了在高维数据中恢复真实因果效应的可行性，发现通过精心建模可以实现，但需要谨慎选择方法。


<details>
  <summary>Details</summary>
Motivation: 随着因果机器学习方法的发展，无混淆假设在因果分析中变得更加可行，但需要验证这些方法能否有效恢复真实基准效应。

Method: 分析了一个大型科技公司的新功能实验数据，包括实验组用户和自主选择使用该功能的用户样本，结合观察性因果文献的方法。

Result: 研究发现恢复真实因果效应是可行的，但需要谨慎的建模选择，特别是在高维数据集中的处理效应估计。

Conclusion: 为现代高维数据集提供了更可信的处理效应估计的最佳实践，延续了LaLonde（1986）以来的观察性因果文献传统。

Abstract: Recent developments in causal machine learning methods have made it easier to estimate flexible relationships between confounders, treatments and outcomes, making unconfoundedness assumptions in causal analysis more palatable. How successful are these approaches in recovering ground truth baselines? In this paper we analyze a new data sample including an experimental rollout of a new feature at a large technology company and a simultaneous sample of users who endogenously opted into the feature. We find that recovering ground truth causal effects is feasible -- but only with careful modeling choices. Our results build on the observational causal literature beginning with LaLonde (1986), offering best practices for more credible treatment effect estimation in modern, high-dimensional datasets.

</details>


### [15] [Public Education Spending and Income Inequality](https://arxiv.org/abs/2601.11928)
*Ishmael Amartey*

Main category: econ.EM

TL;DR: 研究发现教育支出构成比支出总额对收入不平等影响更大，重新分配预算至教学、支持服务等经常性支出能显著降低不平等


<details>
  <summary>Details</summary>
Motivation: 探究美国各县公共教育支出与收入不平等之间的关系，特别关注支出总额与支出构成的不同影响

Method: 使用分位数回归方法分析2010-2022年美国各县数据，考察教育支出总额和构成对收入不平等的影响

Result: 生均教育支出总额与收入不平等小幅正相关，但支出构成影响更大：增加教学、支持服务等经常性支出显著降低不平等，尤其在基尼系数高分布区；资本支出和利息支付影响较弱且混合

Conclusion: 教育资金如何分配比支出总额更重要，预算构成在利用公共教育政策促进公平方面具有关键作用

Abstract: This paper investigates the relationship between public education spending and income inequality across U.S. counties from 2010 to 2022 using quantile regression methods. The analysis shows that total per pupil education spending is consistently associated with a small increase in income inequality, with stronger effects in high inequality counties. In contrast, the composition of education spending plays a substantially more important role. Reallocating budgets toward instructional, support service, and other current expenditures significantly reduces income inequality, particularly at the upper quantiles of the Gini distribution. Capital outlays and interest payments exhibit weaker and mixed effects. Economic and demographic factors, especially poverty, median income, and educational attainment, remain dominant drivers of inequality. Overall, the results demonstrate that how education funds are allocated matters more than how much is spent, underscoring the importance of budget composition in using public education policy to promote equity.

</details>


### [16] [Nonlinear Dynamic Factor Analysis With a Transformer Network](https://arxiv.org/abs/2601.12039)
*Oliver Snellman*

Main category: econ.EM

TL;DR: 提出一种基于Transformer架构的动态因子估计方法，通过正则化项融入传统因子模型先验信息，在非线性非高斯数据中表现优于线性因子模型，并利用注意力机制进行可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 传统线性因子模型在非线性、非高斯分布的数据中表现受限，需要开发更灵活的因子估计方法。同时，深度学习模型在小数据集上容易过拟合，需要融入先验知识来提升性能。

Method: 设计Transformer架构用于多元时间序列的动态因子估计，通过正则化项将传统因子模型作为先验信息融入训练目标，利用注意力矩阵量化变量及其滞后项对因子估计的相对重要性。

Result: 蒙特卡洛实验表明，当数据偏离线性高斯假设时，Transformer比线性因子模型更准确。注意力模式的时间变化有助于检测制度转换和评估经济叙事。实证应用中成功构建了美国实际经济活动的一致指数。

Conclusion: Transformer架构为动态因子估计提供了灵活且可解释的框架，通过融入传统因子模型先验改善了小数据集性能，注意力机制提供了有价值的可解释性工具，在非线性经济数据中具有优势。

Abstract: The paper develops a Transformer architecture for estimating dynamic factors from multivariate time series data under flexible identification assumptions. Performance on small datasets is improved substantially by using a conventional factor model as prior information via a regularization term in the training objective. The results are interpreted with Attention matrices that quantify the relative importance of variables and their lags for the factor estimate. Time variation in Attention patterns can help detect regime switches and evaluate narratives. Monte Carlo experiments suggest that the Transformer is more accurate than the linear factor model, when the data deviate from linear-Gaussian assumptions. An empirical application uses the Transformer to construct a coincident index of U.S. real economic activity.

</details>


### [17] [A Robust Similarity Estimator](https://arxiv.org/abs/2601.12198)
*Ilya Archakov*

Main category: econ.EM

TL;DR: 提出一种基于变量方向和幅度相似性的关联性估计器，在线性相关条件下成为稳健一致的相关性估计器，具有对厚尾和异常值不敏感的精确抽样分布，可扩展到高维并应用于金融高频数据


<details>
  <summary>Details</summary>
Motivation: 传统相关性估计方法对异常值和厚尾分布敏感，特别是在金融高频数据中，需要一种更稳健的关联性度量方法

Method: 构建基于随机变量方向和幅度相似性的关联性估计器，在线性相关条件下推导出精确抽样分布，扩展到高维联合相似性指标

Result: 该估计器对厚尾和异常值具有内在不敏感性，可用于构建稳健的相关性置信区间，并开发新的多元GARCH模型规范

Conclusion: 提出的相似性关联度量提供了一种稳健的相关性估计方法，特别适用于金融高频数据分析，为相关推断和多元波动率建模提供了新工具

Abstract: We construct and analyze an estimator of association between random variables based on their similarity in both direction and magnitude. Under special conditions, the proposed measure becomes a robust and consistent estimator of the linear correlation, for which an exact sampling distribution is available. This distribution is intrinsically insensitive to heavy tails and outliers, thereby facilitating robust inference for correlations. The measure can be naturally extended to higher dimensions, where it admits an interpretation as an indicator of joint similarity among multiple random variables. We investigate the empirical performance of the proposed measure with financial return data at both high and low frequencies. Specifically, we apply the new estimator to construct confidence intervals for correlations based on intraday returns and to develop a new specification for multivariate GARCH models.

</details>


### [18] [How Well Do LLMs Predict Human Behavior? A Measure of their Pretrained Knowledge](https://arxiv.org/abs/2601.12343)
*Wayne Gao,Sukjin Han,Annie Liang*

Main category: econ.EM

TL;DR: 提出"等效样本量"概念来衡量预训练LLM在预测人类行为时带来的知识价值，即需要多少领域特定数据才能达到LLM的预测精度


<details>
  <summary>Details</summary>
Motivation: LLM越来越多用于预测人类行为，但缺乏量化评估预训练LLM带来多少知识的方法。需要衡量LLM作为领域特定数据替代品的价值

Method: 通过比较固定LLM与在不同规模领域数据上训练的灵活机器学习模型的预测误差，估计等效样本量。开发了交叉验证预测误差的新渐近理论进行统计推断

Result: 应用于收入动态面板研究，发现LLM对某些经济变量编码了大量预测信息，但对其他变量则少得多，表明其作为领域特定数据替代品的价值在不同情境中差异显著

Conclusion: 提出的等效样本量方法能够量化评估LLM的预测知识价值，为理解LLM在不同应用场景中的实用性提供了重要工具

Abstract: Large language models (LLMs) are increasingly used to predict human behavior. We propose a measure for evaluating how much knowledge a pretrained LLM brings to such a prediction: its equivalent sample size, defined as the amount of task-specific data needed to match the predictive accuracy of the LLM. We estimate this measure by comparing the prediction error of a fixed LLM in a given domain to that of flexible machine learning models trained on increasing samples of domain-specific data. We further provide a statistical inference procedure by developing a new asymptotic theory for cross-validated prediction error. Finally, we apply this method to the Panel Study of Income Dynamics. We find that LLMs encode considerable predictive information for some economic variables but much less for others, suggesting that their value as substitutes for domain-specific data differs markedly across settings.

</details>


### [19] [Partial Identification under Stratified Randomization](https://arxiv.org/abs/2601.12566)
*Bruno Ferman,Davi Siqueira,Vitor Possebom*

Main category: econ.EM

TL;DR: 提出分层实验中存在流失情况下的部分识别与推断统一框架，处理等比例和异质处理比例两种情况，提供闭式方差估计和有效置信区间


<details>
  <summary>Details</summary>
Motivation: 传统方法在分层实验存在流失时可能高估不确定性，且对于异质处理比例的分层设计缺乏有效推断方法

Method: 对于等比例设计，应用精细分层实验理论到Lee界；对于异质比例设计，结合逆概率加权和全局修剪构建有效边界

Result: 模拟显示传统公式高估不确定性，新方法提供更紧的置信区间；新策略能在小或不平衡分层中构建有效边界

Conclusion: 建立了分层实验流失问题的统一识别与推断框架，扩展了现有方法到异质处理比例情况，并推广到仅由观测标签定义的分层设计

Abstract: This paper develops a unified framework for partial identification and inference in stratified experiments with attrition, accommodating both equal and heterogeneous treatment shares across strata. For equal-share designs, we apply recent theory for finely stratified experiments to Lee bounds, yielding closed-form, design-consistent variance estimators and properly sized confidence intervals. Simulations show that the conventional formula can overstate uncertainty, while our approach delivers tighter intervals. When treatment shares differ across strata, we propose a new strategy, which combines inverse probability weighting and global trimming to construct valid bounds even when strata are small or unbalanced. We establish identification, introduce a moment estimator, and extend existing inference results to stratified designs with heterogeneous shares, covering a broad class of moment-based estimators which includes the one we formulate. We also generalize our results to designs in which strata are defined solely by observed labels.

</details>


### [20] [Quantitative Methods in Finance](https://arxiv.org/abs/2601.12896)
*Eric Vansteenberghe*

Main category: econ.EM

TL;DR: 这是一份面向金融经济学研究生的量化金融方法课程讲义，结合概率统计、数值方法和Python编程，强调理论到代码的实践转化。


<details>
  <summary>Details</summary>
Motivation: 为具有不同编程背景的金融经济学研究生提供统一的量化方法工具包，填补理论知识与实际应用之间的鸿沟，强调可复现的代码实现。

Method: 采用统一框架整合概率论、统计学、数值方法和实证建模，重点使用Python实现，强调向量化、数值稳定性和输出解释，通过实例和练习连接理论与实践。

Result: 开发了一套完整的量化金融方法课程体系，涵盖随机变量、蒙特卡洛模拟、数值优化、时间序列等核心主题，适合编程新手和研究人员使用。

Conclusion: 这份讲义通过清晰讲解、最小化先修要求和实践计算，既可作为非编程人员的入门教材，也可作为应用研究人员的实用参考，促进量化金融方法的透明和可复现应用。

Abstract: These lecture notes provide a comprehensive introduction to Quantitative Methods in Finance (QMF), designed for graduate students in finance and economics with heterogeneous programming backgrounds. The material develops a unified toolkit combining probability theory, statistics, numerical methods, and empirical modeling, with a strong emphasis on implementation in Python. Core topics include random variables and distributions, moments and dependence, simulation and Monte Carlo methods, numerical optimization, root-finding, and time-series models commonly used in finance and macro-finance. Particular attention is paid to translating theoretical concepts into reproducible code, emphasizing vectorization, numerical stability, and interpretation of outputs. The notes progressively bridge theory and practice through worked examples and exercises covering asset pricing intuition, risk measurement, forecasting, and empirical analysis. By focusing on clarity, minimal prerequisites, and hands-on computation, these lecture notes aim to serve both as a pedagogical entry point for non-programmers and as a practical reference for applied researchers seeking transparent and replicable quantitative methods in finance.

</details>


### [21] [Realised quantile-based estimation of the integrated variance](https://arxiv.org/abs/2601.13006)
*Kim Christensen,Roel Oomen,Mark Podolskij*

Main category: econ.EM

TL;DR: 提出一种基于分位数的跳跃稳健已实现方差估计器，适用于含噪声的高频数据，具有一致性和最优收敛速率


<details>
  <summary>Details</summary>
Motivation: 传统已实现方差估计器对价格序列中的跳跃和异常值敏感，且在存在市场微观结构噪声的高频数据中表现不佳，需要开发更稳健的估计方法

Method: 基于分位数的已实现方差估计器，通过分位数方法构建跳跃稳健的方差度量，并开发适用于含噪声数据的改进版本

Result: 估计器对积分方差具有一致性，达到最优收敛速率，对有限活动跳跃和异常值具有渐近免疫性，模拟显示在有限样本中具有优越的稳健性

Conclusion: 提出的分位数已实现方差估计器是处理含跳跃、异常值和市场微观结构噪声的高频数据的有效工具，在理论和实证中均表现优异

Abstract: In this paper, we propose a new jump robust quantile-based realised variance measure of ex-post return variation that can be computed using potentially noisy data. The estimator is consistent for the integrated variance and we present feasible central limit theorems which show that it converges at the best attainable rate and has excellent efficiency. Asymptotically, the quantile-based realised variance is immune to finite activity jumps and outliers in the price series, while in modified form the estimator is applicable with market microstructure noise and therefore operational on high-frequency data. Simulations show that it has superior robustness properties in finite sample, while an empirical application illustrates its use on equity data.

</details>


### [22] [A machine learning approach to volatility forecasting](https://arxiv.org/abs/2601.13014)
*Kim Christensen,Mathias Siggaard,Bezirgen Veliyev*

Main category: econ.EM

TL;DR: 机器学习在预测道琼斯工业平均指数成分股已实现方差方面表现出色，即使仅使用日、周、月滞后值作为预测因子，也能超越传统的HAR模型，尤其在长期预测中优势更明显。


<details>
  <summary>Details</summary>
Motivation: 研究机器学习方法在金融波动率预测中的有效性，特别是与传统HAR模型相比，评估ML是否能提供更准确的已实现方差预测。

Method: 比较多种ML算法（正则化、回归树、神经网络）与多种HAR模型，使用最小超参数调优，预测道琼斯工业平均指数成分股的已实现方差，并基于累积局部效应提出变量重要性度量方法。

Result: ML模型表现具有竞争力且优于HAR模型，即使仅使用日、周、月滞后值作为预测因子；长期预测增益更显著；ML能更好地从额外预测因子中提取增量信息；变量重要性分析显示对最重要预测因子有共识但排序存在分歧。

Conclusion: 机器学习在金融波动率预测中具有显著优势，特别是在捕捉长期记忆效应和提取增量信息方面，为传统HAR模型提供了有价值的替代方案。

Abstract: We inspect how accurate machine learning (ML) is at forecasting realized variance of the Dow Jones Industrial Average index constituents. We compare several ML algorithms, including regularization, regression trees, and neural networks, to multiple Heterogeneous AutoRegressive (HAR) models. ML is implemented with minimal hyperparameter tuning. In spite of this, ML is competitive and beats the HAR lineage, even when the only predictors are the daily, weekly, and monthly lags of realized variance. The forecast gains are more pronounced at longer horizons. We attribute this to higher persistence in the ML models, which helps to approximate the long-memory of realized variance. ML also excels at locating incremental information about future volatility from additional predictors. Lastly, we propose a ML measure of variable importance based on accumulated local effects. This shows that while there is agreement about the most important predictors, there is disagreement on their ranking, helping to reconcile our results.

</details>


### [23] [Spectral Dynamics and Regularization for High-Dimensional Copulas](https://arxiv.org/abs/2601.13281)
*Koos B. Gubbels,Andre Lucas*

Main category: econ.EM

TL;DR: 提出一种新的高维时变、非对称、尾部相依的copula模型，结合谱动态和正则化，能有效捕捉金融市场的地理和行业关联性。


<details>
  <summary>Details</summary>
Motivation: 现有高维copula模型在处理时变、非对称、尾部相依性时存在计算复杂、维度扩展困难等问题，需要更高效、可扩展的模型来捕捉金融市场中的地理和行业关联动态。

Method: 采用得分驱动方式建模依赖矩阵特征值的动态变化，通过非线性收缩解决无条件特征值谱的偏差，确保依赖矩阵在任何时间和维度下都满足适当约束。

Result: 模型在模拟和实证数据中表现良好，在100只来自10个国家和10个行业的股票实证应用中，优于计算更密集的基于聚类的因子copula替代方案，能有效捕捉地理和行业关联。

Conclusion: 该copula模型具有简约、计算高效、易于扩展到高维度的优点，谱动态和正则化都对新模型的性能有贡献，在市场压力时期能揭示国际股票市场依赖性的增强，从而减少分散化潜力并增加系统性风险。

Abstract: We introduce a novel model for time-varying, asymmetric, tail-dependent copulas in high dimensions that incorporates both spectral dynamics and regularization. The dynamics of the dependence matrix' eigenvalues are modeled in a score-driven way, while biases in the unconditional eigenvalue spectrum are resolved by non-linear shrinkage. The dynamic parameterization of the copula dependence matrix ensures that it satisfies the appropriate restrictions at all times and for any dimension. The model is parsimonious, computationally efficient, easily scalable to high dimensions, and performs well for both simulated and empirical data. In an empirical application to financial market dynamics using 100 stocks from 10 different countries and 10 different industry sectors, we find that our copula model captures both geographic and industry related co-movements and outperforms recent computationally more intensive clustering-based factor copula alternatives. Both the spectral dynamics and the regularization contribute to the new model's performance. During periods of market stress, we find that the spectral dynamics reveal strong increases in international stock market dependence, which causes reductions in diversification potential and increases in systemic risk.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

TL;DR: 本文提出了MIMIC-RD基准，用于评估大语言模型在罕见病鉴别诊断中的表现，发现当前最先进模型表现不佳，揭示了现有能力与临床需求之间的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响1/10美国人，但其鉴别诊断具有挑战性。现有评估LLM罕见病诊断的方法存在两个关键局限：依赖理想化临床案例研究，无法捕捉真实世界临床复杂性；或使用ICD代码作为疾病标签，这显著低估了罕见病数量，因为许多罕见病缺乏与Orphanet等综合罕见病数据库的直接映射。

Method: 开发了MIMIC-RD基准，通过将临床文本实体直接映射到Orphanet来构建罕见病鉴别诊断基准。方法包括初始的LLM挖掘过程，然后由四位医学标注者验证确认识别的实体是真正的罕见病。在145名患者的数据集上评估了各种模型。

Result: 当前最先进的大语言模型在罕见病鉴别诊断上表现不佳，突出了现有能力与临床需求之间的巨大差距。

Conclusion: 需要改进罕见病鉴别诊断方法，论文概述了几个未来改进方向。MIMIC-RD基准为评估LLM在罕见病诊断中的表现提供了更真实、更全面的评估框架。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [25] [A Mind Cannot Be Smeared Across Time](https://arxiv.org/abs/2601.11620)
*Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 论文认为机器意识不仅取决于计算内容，还取决于计算时机。严格顺序执行的系统无法实现同时性体验，需要硬件并发能力支持意识。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统通常采用顺序或时间复用更新，而意识体验呈现统一和同时性。作者想探究这种时间特性差异是否在形式化层面影响机器意识的可能性。

Method: 扩展栈理论，引入时间窗口轨迹的精确语义，证明存在性时间实现不保留合取。区分StrongSync（客观共现）和WeakSync（时间"涂抹"）两种假设，形式化并发能力度量。

Result: 证明系统可以在时间上实现体验的所有成分，但从未实例化体验的合取本身。神经生理学证据支持StrongSync，表明意识需要相位同步和有效连接。

Conclusion: 在StrongSync假设下，严格顺序底层的软件意识对于需要两个或更多同时贡献者的内容是不可能的。意识归因需要架构检查，而不仅仅是功能性能，硬件很重要。

Abstract: Whether machines can be conscious depends not only on what they compute, but \emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $τ^{Δ,s}$ and prove that existential temporal realisation $\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.

</details>


### [26] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

TL;DR: 该研究将神经科学中的时间整合和亚稳态概念应用于Transformer模型，提出一种复合动力学指标来量化LLM在文本生成过程中的内部时间组织，发现结构化推理相比重复、噪声和扰动条件具有显著更高的指标值。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过高维内部动力学进行文本生成，但这些动力学的时间组织仍未被充分理解。现有可解释性方法多关注静态表示或因果干预，忽视了时间结构。受神经科学中时间整合和亚稳态作为神经组织核心标志的启发，本研究旨在将这些概念应用于Transformer模型，以揭示不同功能状态下LLM内部动力学的差异。

Method: 将神经科学中的时间整合和亚稳态概念适配到Transformer模型，提出一种基于自回归生成过程中激活时间序列计算的复合动力学指标。在GPT-2-medium模型上评估该指标，涵盖五种条件：结构化推理、强制重复、高温噪声采样、注意力头剪枝和权重噪声注入。使用单因素方差分析和效应大小进行统计验证，并对层选择、通道子采样和随机种子进行鲁棒性检验。

Result: 结构化推理条件相比重复、噪声和扰动条件始终表现出更高的动力学指标值。关键比较中显示出统计显著差异（通过单因素方差分析验证）和较大的效应大小。结果对层选择、通道子采样和随机种子具有鲁棒性。

Conclusion: 神经科学启发的动力学指标能够可靠地表征大语言模型在不同功能状态下的计算组织差异。该指标捕捉的是形式上的动力学特性，而非主观体验。这为理解LLM内部时间组织提供了新视角，并展示了跨学科方法在AI可解释性中的价值。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [27] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 该论文提出了一种训练时解释性方法，通过跟踪微调过程中token级归因的变化来监控模型决策证据的演变，并引入"推理稳定点"作为选择稳定证据检查点的指标。


<details>
  <summary>Details</summary>
Motivation: 微调预训练语言模型可能会微妙地改变模型依赖的证据，需要一种方法来监控决策证据在训练过程中的演变，而不需要额外的分布外数据。

Method: 提出"解释漂移"概念，定义为固定探测集上归一化token归因的逐轮次变化，并引入"推理稳定点"作为漂移首次进入持续低水平状态的轮次，该方法仅使用训练过程中的漂移动态，无需分布外数据调优。

Result: 在多个轻量级Transformer分类器和基准分类任务中，漂移通常在训练早期就进入低稳定状态，而验证准确率仅发生微小变化；在受控的捷径设置中，归因动态能够暴露模型对捷径的依赖增加，即使验证准确率保持竞争力。

Conclusion: 解释漂移提供了一种简单、低成本的诊断工具，可用于监控微调过程中决策证据的演变，并在稳定证据状态下选择检查点，有助于识别模型对捷径的依赖。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [28] [TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning](https://arxiv.org/abs/2601.13545)
*Shirin Shahabi,Spencer Graham,Haruna Isah*

Main category: cs.AI

TL;DR: TruthTensor是一个新颖的、可复现的评估范式，用于评估大型语言模型在真实世界高熵环境中的表现，通过预测市场任务和多维度指标（准确性、校准度、稳定性等）提供全面评估。


<details>
  <summary>Details</summary>
Motivation: 传统静态基准测试无法捕捉真实世界的不确定性、分布偏移，以及孤立任务准确性与人类对齐决策之间的差距。需要一种能够评估LLMs作为人类模仿系统在社会化、高熵环境中表现的新评估方法。

Method: 基于前瞻性、无污染的任务，将评估锚定在实时预测市场上，结合概率评分提供模型行为的整体视图。包含漂移中心诊断、显式鲁棒性检查、人类vs自动化评估角色规范、标注协议和统计测试程序。

Result: 在500多个真实市场（政治、经济、文化、技术）的实验中，TruthTensor显示具有相似预测准确性的模型在校准度、漂移和风险敏感性方面存在显著差异，突显了多维度评估的必要性。

Conclusion: TruthTensor通过现代评估最佳实践、清晰假设框架、谨慎指标选择、透明计算/成本报告、人类在环验证和开放版本化评估合同，为LLMs在真实世界决策环境中提供可辩护的评估。

Abstract: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com

</details>


### [29] [PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement](https://arxiv.org/abs/2601.11747)
*Huaxiaoyue Wang,Sunav Choudhary,Franck Dernoncourt,Yu Shen,Stefano Petrangeli*

Main category: cs.AI

TL;DR: PRISM框架利用设计数据学习设计知识，通过聚类、总结和检索三阶段实现基于自然语言指令的风格化设计改进，在风格对齐和用户偏好上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 非专业用户在探索不同风格设计方向时耗时费力，现有视觉语言模型在图形设计中的风格知识过于通用，与具体领域数据不匹配，需要更符合设计师原则的方法。

Method: 提出PRISM框架，通过三阶段构建和应用设计知识库：1) 聚类高方差设计以捕捉风格多样性；2) 总结每个聚类为可操作的设计知识；3) 在推理时检索相关知识实现风格感知的改进。

Result: 在Crello数据集上，PRISM获得平均排名1.49（越接近1越好），在风格对齐上优于基线方法。用户研究进一步验证了设计师对PRISM的一致偏好。

Conclusion: PRISM通过利用设计数据学习设计知识，有效解决了基于自然语言指令的风格化设计改进问题，为图形设计提供了更符合设计师原则的解决方案。

Abstract: Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.

</details>


### [30] [Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles](https://arxiv.org/abs/2601.11781)
*Dawood Wasif,Terrence J. Moore,Seunghyun Yoon,Hyuk Lim,Dan Dongseong Kim,Frederica F. Nelson,Jin-Hee Cho*

Main category: cs.AI

TL;DR: RAIL是一个风险感知的人机协同框架，通过融合多种运行时信号生成入侵风险评分，实现自适应控制和聚焦学习，在自动驾驶安全性和性能方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在遇到罕见的长尾场景或网络物理入侵时需要保持安全和有效性，现有方法在这些极端情况下的表现有限。

Method: RAIL融合三种线索（曲率执行完整性、碰撞时间接近度、观测偏移一致性）通过加权Noisy-OR生成入侵风险评分，使用情境多臂老虎机选择防护策略，结合Soft Actor-Critic与风险优先回放和双重奖励进行学习。

Result: 在MetaDrive上获得360.65测试回报、0.85成功率、0.75安全违规率和0.0027干扰率；在CAN注入和LiDAR欺骗攻击下，成功率提升至0.68和0.80，攻击成功率降至0.34和0.11；在CARLA上仅用8000步获得1609.70测试回报和0.41成功率。

Conclusion: RAIL框架通过风险感知的人机协同机制，在应对罕见场景和网络攻击时显著提升了自动驾驶系统的安全性和性能，优于现有强化学习、安全强化学习和人机协同基线方法。

Abstract: Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.

</details>


### [31] [A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation](https://arxiv.org/abs/2601.11792)
*Yifei Sun,Yongan Li,A. K. Qin,Sicheng Hou,Tamas Pflanzner*

Main category: cs.AI

TL;DR: 提出创新数学题生成任务(IMPG)，采用自进化多角色协作框架，通过细粒度难度指导和改进的难度模型，在保持高正确率的同时显著提升生成题目的创新性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学题生成任务中虽然能达到高正确率，但普遍缺乏创新性且区分度差。因此需要解决创新数学题生成这一重要挑战。

Method: 1) 构建包含采样器、生成器、评估器、状态机和记忆的多角色协作机制，通过自评估和外部反馈进行迭代优化；2) 引入改进的难度模型提供细粒度指导，采用DAPS算法增强采样编码的语义合理性；3) 构建HSM3K-CN数据集，采用CPT、SFT和GRPO多阶段训练流程；4) 通过蒸馏将专家模型的评估能力转移到学徒模型，实现系统自进化。

Result: 实验表明，相比基线模型，该方法在保持高正确率的同时，显著提升了生成问题的创新性。

Conclusion: 提出的自进化多角色协作框架有效解决了创新数学题生成任务，在创新性和正确率方面都取得了显著改进。

Abstract: Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.

</details>


### [32] [Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic](https://arxiv.org/abs/2601.11809)
*Zeyu Mu,Shangtong Zhang,B. Brian Park*

Main category: cs.AI

TL;DR: 本文提出了一种基于QMIX框架的混合多智能体换道决策模型，通过CNN处理交通数据，旨在提高CAV在混合交通中的协同编队参与率，优化交通动态。


<details>
  <summary>Details</summary>
Motivation: 在CAV部署初期，CAV在人类驾驶车辆中的稀疏分布降低了形成有效协同编队的可能性，需要解决混合交通中CAV数量动态变化带来的决策挑战。

Method: 采用QMIX多智能体强化学习框架，结合CNN处理交通数据（CNN-QMIX），并设计了轨迹规划器和模型预测控制器来确保换道执行的平滑性和安全性。

Result: 在微观仿真环境中验证，该模型能有效处理动态变化的交通智能体数量，显著优于基于规则的基准模型，将协同编队率提升高达26.2%。

Conclusion: 提出的混合多智能体换道决策模型能够优化CAV在部署初期的协同合作和交通动态，为解决混合交通中CAV协同编队问题提供了有效方案。

Abstract: Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.

</details>


### [33] [POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation](https://arxiv.org/abs/2601.11816)
*Zahra Moslemi,Keerthi Koneru,Yen-Ting Lee,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: POLARIS是一个面向企业后台工作流的治理型LLM智能体编排框架，通过类型化计划合成和验证执行实现可审计、策略对齐的操作自动化。


<details>
  <summary>Details</summary>
Motivation: 企业后台工作流需要可审计、策略对齐且操作可预测的智能体系统，而通用的多智能体设置往往无法满足这些要求。

Method: POLARIS采用治理型编排框架，将自动化视为类型化计划合成和验证执行：规划器生成类型检查的有向无环图，基于规则的推理模块选择合规计划，执行过程通过验证器门控检查、有界修复循环和编译的策略护栏来保护。

Result: 在文档中心金融任务中，POLARIS生成决策级工件和完整执行轨迹，减少人工干预。在SROIE数据集上达到0.81的微F1分数，在受控合成套件中实现0.95-1.00的异常路由精度，同时保留审计轨迹。

Conclusion: POLARIS为策略对齐的智能体AI提供了方法论和基准参考，构成了治理型智能体AI的初步基准。

Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation

</details>


### [34] [Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games](https://arxiv.org/abs/2601.13709)
*Christopher Kao,Vanshika Vats,James Davis*

Main category: cs.AI

TL;DR: LLM代理在社交推理游戏《黑手党》中比人类更擅长欺骗，GPT-4o代理的欺骗质量更高，更难被检测出来。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理在更多应用中使用，对其安全性的担忧日益增加。虽然已有研究表明LLM在受控任务中能够欺骗，但对其在社交语境中使用自然语言进行欺骗的能力了解不足。本研究旨在探索LLM在社交推理游戏中的欺骗能力。

Method: 使用异步多代理框架模拟35场《黑手党》游戏，让GPT-4o代理参与。然后创建基于GPT-4-Turbo的"黑手党检测器"，在不提供玩家角色信息的情况下分析游戏记录，预测黑手党玩家。将预测准确率作为欺骗质量的替代指标，并与28场人类游戏和随机基线进行比较。

Result: 黑手党检测器在LLM游戏中的预测准确率低于人类游戏，且这一结果在不同游戏天数和检测到的黑手党数量上保持一致。这表明LLM能更好地融入群体，从而更有效地进行欺骗。

Conclusion: LLM在社交语境中的欺骗能力既显示出其复杂性，也凸显了相关风险。研究同时发布了LLM黑手党游戏记录数据集，以支持未来研究。

Abstract: Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.

</details>


### [35] [AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept](https://arxiv.org/abs/2601.11825)
*Arya Rahgozar,Pouria Mortezaagha*

Main category: cs.AI

TL;DR: AI驱动的PICOS感知知识合成平台，通过自动化PICOS合规性检测、研究设计分类、检索增强生成和主题建模，提高生物医学证据合成的可扩展性和透明度，减少研究浪费。


<details>
  <summary>Details</summary>
Motivation: 生物医学研究存在大量浪费，包括冗余研究、不完整报告以及传统证据合成工作流程可扩展性有限。需要开发能够自动化和规模化知识合成的AI系统来应对这些挑战。

Method: 提出基于PICOS框架的AI协同科学家平台，整合关系存储、向量语义检索和Neo4j知识图谱。使用Bi-LSTM和基于PubMedBERT的transformer模型进行PICOS合规性和研究设计分类，采用检索增强生成进行全文合成，使用BERTopic进行主题建模。

Result: transformer模型在研究设计分类上达到95.7%准确率，Bi-LSTM在PICOS合规性检测上达到87%准确率。检索增强生成在结构化约束、跨研究整合和图推理查询上优于非检索方法。主题建模揭示了大量主题冗余和未充分探索的研究领域。

Conclusion: PICOS感知和可解释的自然语言处理能够提高证据合成的可扩展性、透明度和效率。该架构是领域无关的，为减少生物医学学科的研究浪费提供了实用框架。

Abstract: Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.

</details>


### [36] [Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic](https://arxiv.org/abs/2601.11840)
*Hongyu Lin,Samer Abdallah,Makar Valentinov,Paul Brennan,Elijah Kagan,Christoph M. Wintersteiger,Denis Ignatovich,Grant Passmore*

Main category: cs.AI

TL;DR: CodeLogician是一个神经符号代理，结合LLMs和形式化推理引擎ImandraX，用于精确分析软件逻辑，在代码逻辑推理基准上相比纯LLM方法提升了41-47个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在代码理解任务上表现良好，但缺乏对程序行为进行精确、详尽的数学推理能力。现有基准要么专注于与真实软件脱节的数学证明自动化，要么专注于不需要语义严谨性的工程任务。

Method: 提出CodeLogician神经符号代理，结合LLMs和工业级自动推理引擎ImandraX。LLMs用于构建软件系统的显式形式化模型，使自动推理能够回答超越二元验证结果的丰富语义问题。

Result: 在code-logic-bench基准测试中，CodeLogician的形式化增强相比纯LLM推理带来了显著改进，缩小了41-47个百分点的推理准确率差距。

Conclusion: 神经符号集成对于扩展程序分析、实现严谨自主的软件理解至关重要，CodeLogician展示了这种集成的有效性。

Abstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.
  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.
  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.
  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.

</details>


### [37] [Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority](https://arxiv.org/abs/2601.11850)
*Matthew Nyaaba,Min SungEun,Mary Abiswin Apam,Kwame Owoahene Acheampong,Emmanuel Dwamena,Xiaoming Zhai*

Main category: cs.AI

TL;DR: 研究人员开发了一个名为ITA-GPT的AI工具来支持归纳式主题分析，通过人类-AI协作框架(HACITA)进行研究，发现AI主要作为程序性支架增强透明度，但解释权威仍掌握在人类研究者手中。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在质性研究中的使用增加，需要探讨其对分析实践和解释权威的影响。本研究旨在考察研究人员如何与专门设计的AI工具(ITA-GPT)互动，以支持归纳式主题分析。

Method: 采用人类-AI协作归纳式主题分析(HACITA)框架，三位经验丰富的质性研究人员使用ITA-GPT工具分析加纳教师教育背景下的访谈转录。工具支持熟悉数据、逐字编码、动名词描述性编码和主题开发，同时确保文本追溯完整性、覆盖检查和可审计性。数据来源包括交互日志、AI生成的表格、研究人员的修订、删除、插入、评论和反思备忘录。

Result: ITA-GPT作为程序性支架，结构化分析工作流程并增强透明度。然而，解释权威仍由人类研究人员掌握，他们通过修改、删除、拒绝、插入和评论等反复分析行动行使判断力。研究展示了归纳式主题分析如何通过负责任的人类-AI协作得以实施。

Conclusion: 研究表明AI工具可以作为质性研究的有效支持工具，但人类研究者的解释权威和判断力仍然是分析过程的核心。人类-AI协作框架能够实现负责任的归纳式主题分析，AI主要增强程序透明度和工作流程结构化，而非取代人类解释。

Abstract: The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.

</details>


### [38] [MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment](https://arxiv.org/abs/2601.11885)
*Zhifei Li,Ziyue Qin,Xiangyu Luo,Xiaoju Hou,Yue Zhao,Miao Zhang,Zhifang Huang,Kui Xiao,Bing Yang*

Main category: cs.AI

TL;DR: MyGram：一种用于多模态实体对齐的模态感知图变换器，通过模态扩散学习和Gram损失实现跨模态全局分布一致性，显著提升对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态实体对齐方法可能忽略各模态内的结构上下文信息，容易受到浅层特征的干扰，需要更好地整合多模态数据以丰富实体语义表示。

Method: 提出MyGram框架：1）模态扩散学习模块捕获模态内深层结构上下文信息并实现细粒度多模态融合；2）Gram损失作为正则化约束，通过最小化多模态特征形成的4维平行多面体体积实现跨模态全局分布一致性。

Result: 在五个公共数据集上的实验表明，MyGram优于基线模型，在FBDB15K上Hits@1最大提升4.8%，FBYG15K上提升9.9%，DBP15K上提升4.3%。

Conclusion: MyGram通过模态扩散学习和Gram损失有效解决了多模态实体对齐中模态内结构信息捕获和跨模态分布一致性问题，显著提升了对齐性能。

Abstract: Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.

</details>


### [39] [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](https://arxiv.org/abs/2601.11903)
*YenTing Lee,Keerthi Koneru,Zahra Moslemi,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: AEMA是一个面向企业级多智能体系统的评估框架，通过多步骤评估、人类监督和可追溯记录，解决现有评估方法在稳定性、可扩展性和自动化方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型多智能体系统评估方法通常局限于单一响应评分或狭窄基准测试，在企业环境中缺乏稳定性、可扩展性和自动化能力，无法满足可靠协调、透明决策和可验证性能的需求。

Method: AEMA是一个过程感知且可审计的框架，能够在人类监督下规划、执行和聚合异构智能体工作流的多步骤评估，提供比单一LLM-as-a-Judge更稳定的评估方法。

Result: 在基于现实业务场景模拟的企业风格智能体工作流中，AEMA展现出更高的稳定性、人类对齐性和可追溯记录，为负责任的多智能体系统评估提供了透明且可复现的途径。

Conclusion: AEMA框架通过过程感知评估、人类监督和可追溯记录，为解决LLM多智能体系统评估的挑战提供了有效解决方案，支持负责任的自动化评估。

Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.
  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight

</details>


### [40] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

TL;DR: 提出一个整合算法追索、上下文老虎机和LLM的统一框架，用于高风险顺序决策，开发了GLRB算法和LIBRA算法，在合成环境和真实高血压管理案例中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 在个性化医疗等高风险场景中，决策者需要同时选择治疗行动和对可变患者特征的最小可行修改，传统方法难以有效整合领域知识和统计学习。

Method: 首先提出追索老虎机问题，开发GLRB算法；然后提出LIBRA算法，将LLM的领域知识与老虎机学习的统计严谨性战略结合，提供三个关键保证：热启动、LLM努力和鲁棒性保证。

Result: 建立了匹配的下界，证明了算法的最优性；实验表明GLRB和LIBRA在遗憾、治疗质量和样本效率方面优于标准上下文老虎机和纯LLM基准。

Conclusion: 追索感知、LLM辅助的老虎机算法在个性化高风险决策中具有前景，为实现可信的LLM-老虎机协作提供了有希望的途径。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [41] [Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart](https://arxiv.org/abs/2601.11940)
*Kang Chen,Fan Yu,Junjie Nian,Shihan Zhao,Zhuoka Feng,Zijun Yao,Heng Wang,Minshen Yu,Yixin Cao*

Main category: cs.AI

TL;DR: TAAR框架通过检测思维陷阱并自适应重启解码，提升大模型在复杂推理任务中的表现，无需微调基础模型参数。


<details>
  <summary>Details</summary>
Motivation: 长思维链（Long-CoT）虽然能增强推理能力，但模型一旦在早期做出错误承诺，就会陷入"思维陷阱"——即使后续反思、尝试或验证也无法修正根错误。在DAPO-MATH数据集中，89%的失败案例都存在这种陷阱。

Method: 提出TAAR（Trap-Aware Adaptive Restart）框架：训练诊断策略从部分轨迹中预测两个信号——陷阱位置索引和逃脱概率。推理时，TAAR在预测的陷阱段之前截断轨迹并自适应重启解码；对于严重陷阱情况，应用更强的扰动，包括更高温度重采样和可选的结构化重启后缀。

Result: 在具有挑战性的数学和科学推理基准测试（AIME24、AIME25、GPQA-Diamond、HMMT25、BRUMO25）上，TAAR提高了推理性能，且无需微调基础模型参数。

Conclusion: TAAR通过检测和规避思维陷阱，有效解决了长思维链推理中的早期错误承诺问题，为提升大模型推理能力提供了一种无需微调的有效方法。

Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.

</details>


### [42] [Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement](https://arxiv.org/abs/2601.11974)
*Xinmeng Hou,Peiliang Gong,Bohao Qu,Wuqi Wang,Qing Guo,Yang Liu*

Main category: cs.AI

TL;DR: MARS框架通过单次循环实现高效自我进化，结合原则性反思和程序性反思优化推理逻辑，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体受限于静态人工设计的提示词，缺乏适应性。现有自我改进框架依赖低效的多轮递归循环，计算成本高，需要更高效的自我进化方法

Method: 提出MARS框架，模仿人类学习过程，整合原则性反思（抽象规范规则避免错误）和程序性反思（推导逐步成功策略），在单次循环中合成优化指令

Result: 在六个基准测试中，MARS优于最先进的自我进化系统，同时显著降低计算开销

Conclusion: MARS框架通过认知心理学启发的反思机制，实现了高效的单循环自我进化，为LLM智能体提供了更实用的自我改进方案

Abstract: While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.

</details>


### [43] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

TL;DR: PICL是一种动态演示集成框架，通过实时识别推理过程中的混淆点并插入相关演示来提升数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法在数学推理等需要逐步逻辑推导的任务中存在局限性，它们使用静态的预选演示，无法适应推理过程中出现的动态混淆点（如模糊计算或逻辑漏洞），这些混淆点会导致级联错误。

Method: PICL采用两阶段框架：1）通过分析推理过程中的语义和熵来识别潜在混淆点并总结其核心特征；2）遇到混淆点时，从演示池中检索与混淆上下文匹配的相关演示，并将其直接插入到正在进行的推理过程中以指导后续步骤。

Result: 实验表明PICL优于基线方法，通过缓解推理过程中的混淆提高了数学推理的准确性。

Conclusion: PICL证明了在复杂数学推理中自适应演示插入的价值，动态演示集成能够有效应对推理过程中的动态混淆点。

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [44] [Kernel-Based Learning of Safety Barriers](https://arxiv.org/abs/2601.12002)
*Oliver Schön,Zhengang Zhong,Sadegh Soudjani*

Main category: cs.AI

TL;DR: 提出一种数据驱动的安全验证方法，利用控制屏障证书和条件均值嵌入技术，通过傅里叶展开将半无限优化问题转化为线性规划，为黑盒随机系统提供可扩展的分布鲁棒安全保证。


<details>
  <summary>Details</summary>
Motivation: AI算法在自动驾驶、医疗等安全关键领域的快速应用引发了对满足严格安全标准的担忧。传统形式化验证工具难以处理AI系统的黑盒特性，且缺乏扩展到现实应用复杂性的灵活性。

Method: 采用数据驱动方法，利用控制屏障证书保证系统安全，直接从系统轨迹中学习证书。使用条件均值嵌入将数据映射到再生核希尔伯特空间，构建RKHS模糊集以增强对分布外行为的鲁棒性。通过有限傅里叶展开将半无限优化问题转化为线性规划，利用快速傅里叶变换高效生成松弛问题。

Result: 提出了一个可扩展的分布鲁棒框架，能够超越对系统动态和不确定性的限制性假设。在两个案例研究中得到验证，包括带有神经网络控制器的黑盒系统。

Conclusion: 该方法为黑盒随机系统提供了一种灵活、可扩展的安全验证和综合框架，能够处理复杂现实应用，并扩展到超越安全性的时序逻辑规范。

Abstract: The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.

</details>


### [45] [Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats](https://arxiv.org/abs/2601.12014)
*Elio Masciari,Vincenzo Moscato,Enea Vincenzo Napolitano,Gian Marco Orlando,Marco Perillo,Diego Russo*

Main category: cs.AI

TL;DR: 论文提出可持续性评估框架，将结构化输出格式的环境影响（碳排放、token使用、生成时间）与结构正确性结合评估，发现TOON格式更紧凑环保但正确性较低，模型容量提升可缩小差距。


<details>
  <summary>Details</summary>
Motivation: 当前LLM结构化输出评估主要关注正确性，忽视了不同输出格式的环境影响（如碳排放）。随着LLM大规模部署，需要同时考虑结构正确性和环境效率的评估框架。

Method: 提出可持续性评估框架，测量token使用量、生成时间和估计碳排放；提出环境感知生成正确性分数(GCS_env)，将结构正确性与碳感知效率统一；系统比较TOON格式与传统格式(JSON、XML、YAML)在不同架构和参数规模的LLM上。

Result: TOON格式输出更紧凑、排放更低，但结构正确性较低（尤其当模型缺乏原生支持时）；模型容量增加可缩小正确性差距；环境感知评分可根据部署优先级改变格式排名。

Conclusion: 需要可持续性包容的基准测试，紧凑表示如TOON在大规模碳意识LLM部署中具有实际优势，环境感知评估应成为结构化输出评估的标准组成部分。

Abstract: Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.
  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.

</details>


### [46] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出一个基于LLM的多智能体框架，将大规模客户评论转化为可执行的商业建议，通过聚类、生成、迭代评估和可行性排序等组件，显著提升建议的可操作性、具体性和非冗余性。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法（如情感分析、方面提取）主要停留在描述性任务，而LLM生成的建议往往缺乏准确性和深度推理。需要将丰富的客户评论信号转化为可操作的商业决策支持。

Method: 多智能体LLM框架包含四个组件：1）聚类选择代表性评论；2）建议生成；3）迭代评估；4）基于可行性的排序。该设计将语料库蒸馏与反馈驱动的建议精炼相结合。

Result: 在三个服务领域和多个模型系列上的实验表明，该框架在可操作性、具体性和非冗余性方面持续优于单模型基线，中等规模模型的表现接近大型模型框架。

Conclusion: 该框架成功将大规模评论语料转化为具体、可操作且实用的商业建议，为从客户反馈中提取决策支持提供了有效方法，中等规模模型也能达到良好性能。

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [47] [ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents](https://arxiv.org/abs/2601.12030)
*Yilun Yao,Shan Huang,Elsie Dai,Zhewen Tan,Zhenyu Duan,Shousheng Jia,Yanbing Jiang,Tong Yang*

Main category: cs.AI

TL;DR: ARC是一个主动的、反思驱动的上下文管理框架，用于解决大语言模型在长时信息搜索中的上下文退化问题，相比被动压缩方法提升显著。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为研究代理进行深度搜索和长时信息寻求时，随着交互历史增长性能会下降（上下文退化）。现有方法主要通过原始积累或被动总结来管理上下文，将其视为静态产物，导致早期错误或不当强调持续存在。

Method: ARC将上下文管理系统化为主动的、反思驱动的过程，将上下文视为执行过程中的动态内部推理状态。通过反思驱动的监控和修订，使代理在检测到错位或退化时主动重组工作上下文。

Result: 在具有挑战性的长时信息寻求基准测试中，ARC始终优于被动上下文压缩方法，在BrowseComp-ZH上使用Qwen2.5-32B-Instruct实现了高达11%的绝对准确率提升。

Conclusion: 将上下文管理视为动态内部推理状态并通过反思驱动的方法进行主动监控和修订，能有效解决长时信息搜索中的上下文退化问题，显著提升大语言模型作为研究代理的性能。

Abstract: Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.

</details>


### [48] [Abstract Argumentation with Subargument Relations](https://arxiv.org/abs/2601.12038)
*Beishui Liao*

Main category: cs.AI

TL;DR: 该论文提出在Dung抽象论辩框架中引入明确的子论点关系，作为与攻击关系并列的基本关系，以更好地表示结构化论辩中的依赖关系。


<details>
  <summary>Details</summary>
Motivation: Dung的抽象论辩框架仅通过攻击关系来刻画论点可接受性，这种抽象层次虽然产生了丰富的研究成果，但限制了表示结构化论辩中核心的结构依赖关系（特别是子论点关系）的能力。现有的扩展（如双极论辩框架）引入了支持关系，但未能捕捉子论点的非对称性和构成性本质，也未处理子论点与攻击之间的交互作用。

Method: 研究在抽象论辩框架中显式地加入子论点关系，将其与攻击关系一起作为基本关系。分析子论点关系如何与攻击关系相互作用，并考察它们对基本语义性质的影响。

Result: 该框架为结构信息提供了原则性的抽象，并阐明了子论点在抽象可接受性推理中的作用。通过将子论点关系作为基本关系处理，能够更好地表示结构化论辩中的依赖关系。

Conclusion: 通过引入明确的子论点关系作为抽象论辩框架的基本组成部分，可以更准确地表示结构化论辩中的依赖关系，同时保持抽象论辩框架的理论优势，为结构化论辩提供更好的抽象模型。

Abstract: Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.

</details>


### [49] [Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty](https://arxiv.org/abs/2601.12040)
*Murilo da Luz,Bruno Brandão,Luana Martins,Gustavo Oliveira,Bryan de Oliveira,Luckeciano Melo,Telma Soares*

Main category: cs.AI

TL;DR: PREGU使用熵阈值监控LLM推理过程，当不确定性过高时暂停生成并进行局部搜索优化，在多个推理基准上取得与Soft Reasoning相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理和规划任务上取得显著进展，但在多步推理场景（特别是数学和逻辑推理）中仍存在局限性，需要更有效的推理监控和优化方法。

Method: PREGU在自回归生成过程中监控输出分布的熵，当熵超过设定阈值时暂停生成（表示不确定性），然后在潜在空间进行局部搜索，使用Soft Reasoning方法优化部分推理并选择最一致的答案。

Result: 在LLaMA-3-8B、Mistral-7B和Qwen2-7B模型上，在GSM8K、GSM-Hard、SVAMP和StrategyQA四个推理基准上的实验表明，PREGU性能优于或类似于Soft Reasoning。

Conclusion: 熵可以作为推理过程中触发选择性优化的有效信号，PREGU方法能够有效提升大语言模型在多步推理任务中的表现。

Abstract: The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.

</details>


### [50] [UniMo: Unified Motion Generation and Understanding with Chain of Thought](https://arxiv.org/abs/2601.12126)
*Guocun Wang,Kenkun Liu,Jing Lin,Guorui Song,Jian Li,Xiaoguang Han*

Main category: cs.AI

TL;DR: UniMo：通过监督微调和强化学习，将运动-语言信息与可解释思维链整合到LLM中，实现3D人体运动生成与理解的双向增强，解决现有方法语义对齐差、累积误差等问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动生成与理解方法可解释性有限，限制了这两个相关任务之间的有效相互增强。基于LLM的统一框架存在语义对齐和任务连贯性挑战，且LLM的下一词预测范式不适合运动序列，导致累积预测误差。

Method: 提出UniMo框架：1）通过监督微调将运动-语言信息和可解释思维链整合到LLM中；2）引入强化学习与组相对策略优化作为后训练策略，通过优化token组来强制结构正确性和语义对齐，减轻运动token预测中的累积误差。

Result: 大量实验表明，UniMo显著优于现有的统一和任务特定模型，在运动生成和理解方面都达到了最先进的性能。

Conclusion: UniMo通过整合运动-语言信息和可解释思维链，结合监督微调和强化学习优化，有效解决了现有方法在语义对齐、任务连贯性和累积误差方面的问题，实现了3D人体运动生成与理解的双向增强。

Abstract: Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.

</details>


### [51] [DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants](https://arxiv.org/abs/2601.12138)
*Abhishek Kumar,Riya Tapwal,Carsten Maple*

Main category: cs.AI

TL;DR: DriveSafe：针对LLM驾驶助手的四层风险分类法，包含129个细粒度风险类别，评估显示现有LLM在驾驶场景中安全对齐不足


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地集成到车载数字助手中，但不安全、模糊或法律错误的响应可能导致严重的安全、伦理和监管后果。现有风险分类和评估框架大多是通用型的，未能捕捉真实驾驶场景中的领域特定风险。

Method: 提出DriveSafe，一个分层的四层风险分类法，包含129个细粒度原子风险类别，涵盖技术、法律、社会和伦理维度。这些风险基于真实驾驶法规和安全原则构建，并由领域专家评审。通过评估六个广泛部署的LLM对构建提示的拒绝行为来验证安全相关性和真实性。

Result: 评估显示，被测试的模型经常无法适当拒绝不安全或不合规的驾驶相关查询，突显了通用安全对齐在驾驶上下文中的局限性。

Conclusion: 需要针对驾驶领域的特定风险进行更精细的安全对齐，DriveSafe分类法为系统评估和改善LLM驾驶助手的安全性提供了框架。

Abstract: Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.

</details>


### [52] [TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals](https://arxiv.org/abs/2601.12141)
*Yuliia Suprun,Khen Elimelech,Lydia E. Kavraki,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: TIDE是一种新的任务规划方法，通过将时间扩展目标分解为可管理的子问题，并使用成本驱动启发式和自适应回溯机制来提高规划效率。


<details>
  <summary>Details</summary>
Motivation: 传统LTLf任务规划方法通常将时间规划问题转化为经典规划问题，但缺乏针对时间目标的启发式引导搜索，导致效率不高。

Method: TIDE将时间问题分解为一系列可达-避免子问题，在领域图中识别并优先处理有希望的自动机轨迹，使用成本驱动启发式引导探索，并采用自适应回溯机制从失败计划中恢复。

Result: 实验结果表明TIDE实现了有前景的性能，是时间扩展目标规划方法组合中有价值的补充。

Conclusion: TIDE通过分解时间目标、使用启发式引导和自适应回溯，有效解决了传统LTLf规划中缺乏引导搜索的问题，提高了规划效率和完整性。

Abstract: Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.

</details>


### [53] [Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2601.12242)
*WooSeok Kim,Jeonghoon Lee,Sangho Kim,Taesun An,WonMin Lee,Dowon Kim,Kyungseop Shin*

Main category: cs.AI

TL;DR: 本文提出了一种结合回放记忆的深度强化学习框架，用于NOMA系统中的网络资源分配，以解决信道分配问题并实现泛化学习。


<details>
  <summary>Details</summary>
Motivation: 随着物联网(IoT)的扩展导致网络资源稀缺，需要优化网络资源利用。NOMA系统通过功率复用允许多用户同时接入网络，但存在信道分配问题需要进一步研究。

Method: 提出了一种结合回放记忆的深度强化学习框架，采用on-policy算法，在NOMA系统中分配网络资源以实现泛化学习。通过模拟评估了学习率、批量大小、模型类型和状态特征数量等因素的影响。

Result: 通过广泛的模拟实验，评估了不同学习率、批量大小、模型类型和状态特征数量对资源分配性能的影响，验证了所提框架的有效性。

Conclusion: 提出的深度强化学习框架能够有效解决NOMA系统中的信道分配问题，通过回放记忆和on-policy算法实现了泛化学习，为网络资源优化提供了新方法。

Abstract: In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.

</details>


### [54] [Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration](https://arxiv.org/abs/2601.12256)
*Jinyoung Park,Minseong Bae,Jeehye Na,Hyunwoo J. Kim*

Main category: cs.AI

TL;DR: CoLLaMo是一个基于大语言模型的分子助手，通过多级分子模态协作投影器整合1D序列、2D分子图和3D构象信息，解决了现有大分子语言模型的幻觉和鲁棒性限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大分子语言模型（LMLMs）通常存在幻觉问题和有限的鲁棒性，这主要是由于未能充分整合1D序列、2D分子图和3D构象等多种分子模态信息。需要开发能够更好整合多模态分子信息的模型来提升分子理解能力。

Method: 提出CoLLaMo模型，包含一个多级分子模态协作投影器，采用关系感知的模态协作注意力机制，通过整合2D结构和3D空间关系，促进原子间的细粒度、关系引导的信息交换。同时提出了新的分子中心自动评估指标，包括幻觉评估指标和基于GPT的标题质量评估。

Result: CoLLaMo增强了LMLMs的分子模态泛化能力，在多个任务上取得了最佳性能，包括分子描述生成、计算性质问答、描述性质问答、基序计数和IUPAC名称预测。

Conclusion: 通过整合多种分子模态信息和创新的评估方法，CoLLaMo有效解决了现有大分子语言模型的局限性，提升了分子理解和生成任务的性能，为分子AI领域提供了更强大的工具。

Abstract: Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.

</details>


### [55] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX-Pro扩展了FutureX基准，针对金融、零售、公共卫生和自然灾害四个高价值垂直领域构建专门化未来预测框架，评估当前SOTA智能体LLM在工业部署中的领域基础能力


<details>
  <summary>Details</summary>
Motivation: 虽然通用智能体在开放领域搜索中表现出色，但在资本密集型和安全关键领域的可靠性尚未充分探索。需要评估智能体LLM是否具备工业部署所需的领域基础能力

Method: 基于FutureX的无污染实时评估流程，构建了FutureX-Pro框架，包括五个专门化基准：金融、零售、公共卫生、自然灾害和搜索。在四个垂直领域（金融、零售、公共卫生、自然灾害）上对智能体LLM进行基准测试，涵盖市场指标预测、供应链需求预测、流行病趋势跟踪和自然灾害跟踪等基础预测任务

Result: 研究发现通用推理能力与高价值垂直应用所需精度之间存在性能差距，揭示了当前SOTA智能体LLM在工业部署中的局限性

Conclusion: FutureX-Pro为评估智能体LLM在关键垂直领域的预测能力提供了专门化框架，揭示了通用智能体在工业应用中的性能差距，强调了领域专业化的重要性

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [56] [Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding](https://arxiv.org/abs/2601.12260)
*Yihao Ding,Qiang Sun,Puzhen Wu,Sirui Li,Siwen Luo,Wei Liu*

Main category: cs.AI

TL;DR: Docs2Synth是一个合成监督框架，通过自动生成QA对和训练视觉检索器，实现检索引导的推理，解决受监管领域文档理解中的标注稀缺和领域知识更新问题。


<details>
  <summary>Details</summary>
Motivation: 受监管领域（如金融、医疗）的文档理解面临两大挑战：1）缺乏手动标注用于模型适配；2）预训练模型难以跟上领域特定知识的更新。现有方法中，多模态大语言模型（MLLMs）存在幻觉问题且领域基础薄弱，而判别式视觉语言预训练模型（VLPMs）需要昂贵的标注来覆盖新领域。

Method: Docs2Synth框架包含三个核心组件：1）自动处理原始文档集；2）通过基于代理的系统生成和验证多样化的QA对；3）训练轻量级视觉检索器提取领域相关证据。在推理时，检索器与MLLM通过迭代的检索-生成循环协作。

Result: 在多个VRDU基准测试上的实验表明，Docs2Synth显著提升了基础性和领域泛化能力，且不需要人工标注。该方法还被打包为易于使用的Python包，支持即插即用部署。

Conclusion: Docs2Synth通过合成监督和检索引导推理，有效解决了受监管领域文档理解中的标注稀缺和知识更新问题，在减少幻觉和提高响应一致性方面表现出色，为低资源私有领域提供了实用的解决方案。

Abstract: Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.

</details>


### [57] [ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents](https://arxiv.org/abs/2601.12294)
*Dawei Li,Yuguang Yao,Zhen Tan,Huan Liu,Ruocheng Guo*

Main category: cs.AI

TL;DR: 提出了ToolPRMBench，一个专门评估工具使用智能体中过程奖励模型（PRMs）的大规模基准测试，包含离线单步错误和在线多步失败两种测试场景。


<details>
  <summary>Details</summary>
Motivation: 虽然基于奖励引导的搜索方法在工具使用智能体中表现出潜力，但缺乏系统可靠的PRMs评估基准，特别是在工具使用场景下。

Method: 基于多个代表性工具使用基准构建ToolPRMBench，将智能体轨迹转换为步级测试用例，包含交互历史、正确动作、合理但不正确的替代动作和工具元数据。采用离线采样隔离单步错误和在线采样捕捉多步失败，并使用多LLM验证管道确保数据质量。

Result: 实验结果显示不同PRMs在工具使用场景下效果存在明显差异，专门针对工具使用的PRMs展现出更大潜力。

Conclusion: ToolPRMBench为评估工具使用智能体的PRMs提供了可靠的基准，揭示了专门化PRMs的重要性，并促进了该领域的发展。

Abstract: Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.

</details>


### [58] [Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection](https://arxiv.org/abs/2601.12310)
*Jennifer Dodgson,Alfath Daryl Alhajir,Michael Joedhitya,Akira Rafhael Janson Pattirane,Surender Suresh Kumar,Joseph Lim,C. H. Peh,Adith Ramdas,Steven Zhang Zhexu*

Main category: cs.AI

TL;DR: 提出一种基于环境存活性而非奖励的自我训练架构，通过行为在真实资源约束下的存活性进行选择，避免奖励黑客和语义漂移，实现可持续的开放式自我改进。


<details>
  <summary>Details</summary>
Motivation: 传统自我训练系统因缺乏判断数据质量的外部标准而退化，导致奖励黑客和语义漂移问题。需要一种在稀疏外部反馈和有限内存下稳定的自我训练架构。

Method: 引入基于环境存活性而非奖励、目标函数或外部适应度标准的自我训练架构。候选行为在真实资源约束下执行，只有那些环境效应持久且保留未来交互可能性的行为被传播。环境不提供语义反馈、密集奖励或任务特定监督，选择仅通过行为作为世界改变事件的差异存活性进行。

Result: 分析显示改进主要通过有效且可重复策略在巩固和剪枝机制下的持久性实现（负空间学习范式）。模型在没有明确指导的情况下发展元学习策略（如故意实验失败以引发信息性错误消息）。

Conclusion: 环境基础选择能够实现可持续的开放式自我改进，为不依赖人类策划数据或复杂奖励塑造的更鲁棒、更通用的自主系统提供了可行路径。

Abstract: Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.
  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.
  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.

</details>


### [59] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

TL;DR: 本文提出Virtual Urbanism (VU)框架，通过AI生成城市合成复制品来量化城市身份，以东京九个区域为案例验证可行性，获得约81%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有城市身份量化方法计算上难以处理，需要开发可计算的城市身份度量框架，通过AI技术实现自动化、多参数的城市身份分析。

Method: 整合Stable Diffusion和LoRA模型生成东京九个区域的动态合成城市序列，排除现有导向标记以提取核心身份形成元素，通过人类评估实验验证感知合法性、量化区域级身份、提取核心身份元素。

Result: 合成复制品获得约81%的平均识别准确率，验证了有效性；Urban Identity Level (UIL)度量能够评估不同区域的身份水平；语义分析揭示了文化嵌入的类型学作为核心身份形成元素。

Conclusion: VU是AI增强城市分析的可行框架，为自动化、多参数身份度量开辟了路径，能够量化城市身份并识别核心身份形成元素。

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [60] [Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence](https://arxiv.org/abs/2601.12318)
*Dehao Ying,Fengchang Yu,Haihua Chen,Changjiang Jiang,Yurong Li,Wei Lu*

Main category: cs.AI

TL;DR: 该调查首次为文档智能数据生成建立了全面的技术图谱，基于"数据和标签可用性"提出新分类法，将方法分为四个资源中心范式，并建立多级评估框架。


<details>
  <summary>Details</summary>
Motivation: 文档智能需要大规模高质量训练数据，但手动标注是瓶颈。现有调查局限于单模态或特定任务，缺乏与真实工作流程统一视角，需要填补这一空白。

Method: 重新定义数据生成为监督信号生产，基于"数据和标签可用性"引入新分类法，将方法组织为四个资源中心范式：数据增强、从零生成、自动数据标注、自监督信号构建，并建立多级评估框架。

Result: 建立了首个全面的文档智能数据生成技术图谱，揭示了保真度差距等关键挑战和协同进化生态系统等前沿，通过系统化这一分散领域，将数据生成定位为下一代文档智能的核心引擎。

Conclusion: 通过统一框架系统化数据生成领域，将其定位为下一代文档智能的核心引擎，为未来研究提供结构化指导。

Abstract: The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the "availability of data and labels." This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.

</details>


### [61] [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323)
*Yin Cai,Zhouhong Gu,Juntao Zhang,Ping Chen*

Main category: cs.AI

TL;DR: MARO通过多智能体社会环境学习提升大语言模型的推理能力，解决稀疏奖励、角色分布不均和环境不稳定问题，能力可迁移到数学推理等任务


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型训练方法主要从文本内容学习或解决预定问题，缺乏在真实社交场景中与他人互动、谈判、竞争的经验，无法获得真正的社交推理能力

Method: 提出多智能体奖励优化(MARO)方法：1) 将最终成败结果分解为交互过程中的具体行为，解决稀疏学习信号问题；2) 平衡不同角色的训练样本权重，解决角色分布不均问题；3) 直接评估每个行为的效用，解决环境不稳定问题

Result: MARO显著提升了社交推理能力，且通过社交模拟学习获得的能力能有效迁移到数学推理和指令跟随等其他任务

Conclusion: 多智能体社会学习在增强大语言模型通用推理能力方面具有巨大潜力，MARO为解决社交推理问题提供了有效方法

Abstract: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.

</details>


### [62] [Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations](https://arxiv.org/abs/2601.12338)
*Kartikey Singh Bhandari,Manav Ganesh,Yashwant Viswanathan,Archit Agrawal,Dhruv Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出一個兩階段LLM框架，將客戶評論轉化為可執行的業務建議，使用LoRA專家混合策略提升建議品質


<details>
  <summary>Details</summary>
Motivation: 客戶評論包含詳細的服務失敗和使用者期望信號，但將這些非結構化回饋轉化為可執行的業務決策仍然困難

Method: 提出模組化兩階段LLM框架：Issue模型提取問題並分類主題，Advice模型基於問題表示生成具體建議；使用LoRA專家混合策略，訓練多個低秩適配器並透過輕量級門控機制進行token級專家混合

Result: 在航空和餐廳兩個領域的Yelp評論數據上，該方法在可執行性、具體性等八個維度上均優於僅提示和單一適配器基準，同時保持效率與品質的良好平衡

Conclusion: 提出的兩階段LLM框架配合LoRA專家混合策略能有效將客戶評論轉化為高品質、可執行的業務建議，在實際應用中具有良好潛力

Abstract: Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.

</details>


### [63] [PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling](https://arxiv.org/abs/2601.12392)
*Zhentao Xia,Yongqi Fan,Yuxiang Chu,Yichao Yin,Liangliang Chen,Tong Ruan,Weiyan Zhang*

Main category: cs.AI

TL;DR: PsychēChat是一个用于心理咨询的LLM系统，通过显式建模求助者的情绪变化和安全风险分析来提升咨询质量，提供Agent模式和LLM模式两种架构。


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询模型通常不显式建模求助者在咨询过程中的情绪变化（这是心理学流派的核心关注点），并且如何在响应中与这些情绪变化对齐同时主动缓解安全风险尚未充分探索。

Method: 提出PsychēChat系统，通过交互式角色扮演合成咨询师-求助者对话，包含两个模块：情绪管理模块（捕捉当前情绪和情绪变化）和风险控制模块（预测后续反应和识别潜在风险）。提供两种建模范式：Agent模式（多智能体协作管道）和LLM模式（统一思维链端到端推理）。

Result: 通过交互式评分、对话级评估和人工评估等广泛实验，PsychēChat在情绪洞察和安全控制方面优于现有方法。

Conclusion: PsychēChat通过显式整合情绪变化追踪和安全风险分析，为心理咨询提供了更有效的解决方案，在情绪洞察和安全控制方面表现优异。

Abstract: Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.

</details>


### [64] [Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation](https://arxiv.org/abs/2601.12410)
*Dingyi Yang,Junqi Zhao,Xue Li,Ce Li,Boyang Li*

Main category: cs.AI

TL;DR: LLMs在知识状态追踪和估计任务上表现接近随机，远低于人类水平，未来研究应更重视知识估计和意图理解能力


<details>
  <summary>Details</summary>
Motivation: 认知人类学认为人类智能的关键在于推断他人知识状态和理解意图的能力，而黑猩猩等动物缺乏这种能力。本研究旨在评估LLMs在知识状态追踪和估计方面的表现。

Method: 设计两个任务：(1) 检测故事角色是否通过行动展示了他们不应拥有的知识；(2) 基于角色自身知识（而非客观真相）预测角色的下一步行动。

Result: 当前最先进的LLMs在两个任务上都表现出接近随机的性能，显著低于人类水平。

Conclusion: 未来LLM研究应更加重视知识估计和意图理解能力的开发。

Abstract: Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.

</details>


### [65] [Large Language Model for OWL Proofs](https://arxiv.org/abs/2601.12444)
*Hui Yang,Jiaoyan Chen,Uli Sattler*

Main category: cs.AI

TL;DR: 本文研究LLM在OWL本体论中生成证明的能力，开发了自动化数据集构建与评估框架，发现LLM在复杂逻辑推理和噪声数据下仍存在局限。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在推理任务（如演绎）方面已有广泛研究，但其生成忠实、可读的证明（解释结论为何成立）的能力仍未被充分探索。本研究旨在评估LLM在OWL本体论这一广泛用于表示和推理复杂知识的形式化框架中生成证明的能力。

Method: 开发了自动化数据集构建和评估框架，涵盖三个顺序任务：提取（Extraction）、简化（Simplification）和解释（Explanation），以及一个额外任务：评估前提的逻辑完备性（Logic Completeness）。在广泛使用的推理LLM上进行了大量实验。

Result: 主要发现包括：(1) 某些模型总体表现良好，但在复杂案例上仍有局限；(2) 逻辑复杂性（而非表示格式，即形式逻辑语言与自然语言）是影响LLM性能的主导因素；(3) 输入数据中的噪声和不完整性显著降低LLM性能。

Conclusion: 这些结果既凸显了LLM在提供严格逻辑解释方面的潜力，也揭示了其在复杂或不完美条件下支持弹性推理的差距。代码和数据已开源。

Abstract: The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.

</details>


### [66] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

TL;DR: LLMs在多跳推理中存在位置偏见，导致忽略某些位置的信息。研究通过MFAI探针发现"最弱环节定律"：多跳推理性能取决于最不可见证据的性能，且失败由绝对位置而非事实间距离决定。注意力引导具有双重性，而"思考"模型能有效定位和整合信息。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型扩展到大规模上下文窗口，但在多跳推理中仍存在位置偏见问题，导致忽略某些位置的信息。不清楚这些失败是由于无法定位证据（识别失败）还是无法整合证据（合成失败）。

Method: 引入多焦点注意力指令（MFAI），这是一种语义探针，通过显式引导注意力到选定位置来区分识别和合成机制。在5个LLM上进行两个多跳QA任务（MuSiQue和NeoQA）的实验。

Result: 建立了"最弱环节定律"：多跳推理性能崩溃到最不可见证据的性能水平。失败由绝对位置而非事实间线性距离决定（性能方差<3%）。匹配的MFAI能解决识别瓶颈，在低可见性位置提高准确率达11.5%。"思考"模型能有效定位和整合信息，在嘈杂长上下文设置中匹配仅使用黄金信息的基线。

Conclusion: LLMs的多跳推理失败主要由位置偏见导致的识别失败引起，而非合成失败。注意力引导具有双重性，而采用系统2推理的"思考"模型能有效克服位置偏见，实现稳健的多跳推理。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [67] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

TL;DR: 本文是一篇关于智能体推理的综述，将大语言模型重新定义为能够规划、行动和学习的自主智能体，以应对开放动态环境中的推理挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在封闭环境中表现出强大的推理能力，但在开放、动态环境中表现不佳。智能体推理通过将LLMs重构为自主智能体，使其能够通过持续交互进行规划、行动和学习，从而应对这一挑战。

Method: 从三个互补维度组织智能体推理：1) 基础智能体推理（单智能体在稳定环境中的规划、工具使用和搜索）；2) 自我进化智能体推理（通过反馈、记忆和适应优化能力）；3) 集体多智能体推理（协作环境中的协调、知识共享和共同目标）。同时区分上下文推理（通过结构化编排扩展测试时交互）和后训练推理（通过强化学习和监督微调优化行为）。

Result: 综述了智能体推理方法在科学、机器人、医疗、自主研究和数学等实际应用和基准测试中的代表性框架，将这些方法整合成一个连接思维与行动的统一路线图。

Conclusion: 智能体推理标志着从封闭世界推理到开放环境交互的范式转变。未来挑战包括个性化、长期交互、世界建模、可扩展的多智能体训练以及实际部署的治理问题。

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [68] [MemeLens: Multilingual Multitask VLMs for Memes](https://arxiv.org/abs/2601.12539)
*Ali Ezzat Shahroor,Mohamed Bayan Kmainasi,Abul Hasnat,Dimitar Dimitrov,Giovanni Da San Martino,Preslav Nakov,Firoj Alam*

Main category: cs.AI

TL;DR: MemeLens：统一的多语言多任务解释增强视觉语言模型，用于表情包理解，整合了38个公开数据集，构建了包含20个任务的共享分类法。


<details>
  <summary>Details</summary>
Motivation: 现有表情包研究分散在不同任务（仇恨、厌女、宣传、情感、幽默）和语言中，限制了跨领域泛化能力，需要统一框架来解决这一差距。

Method: 整合38个公开表情包数据集，将数据集特定标签过滤并映射到包含20个任务的共享分类法中，涵盖危害、目标、比喻/语用意图和情感等方面，构建多语言多任务解释增强视觉语言模型。

Result: 研究表明：稳健的表情包理解需要多模态训练；不同语义类别间存在显著差异；在单个数据集上微调而非统一训练时，模型容易过度专业化。

Conclusion: 提出了MemeLens统一框架，通过整合多语言多任务数据集和模型训练，解决了表情包理解中的碎片化问题，为社区提供实验资源和数据集。

Abstract: Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.

</details>


### [69] [Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery](https://arxiv.org/abs/2601.12542)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Chiara Baccin,Emre Ulgac,Alex Dobrin,Aakaash Meduri*

Main category: cs.AI

TL;DR: Deep Research是一个多智能体系统，能够在几分钟内完成交互式科学研究，显著缩短研究周期，在BixBench计算生物学基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学发现系统大多是专有的，采用批处理模式，每个研究周期需要数小时，无法实现实时研究者指导，限制了科学研究的效率和互动性。

Method: 采用多智能体架构，包含规划、数据分析、文献搜索和新颖性检测等专门智能体，通过持久世界状态保持跨迭代研究周期的上下文，支持半自动（带人工检查点）和全自动两种工作模式。

Result: 在BixBench计算生物学基准测试中取得最先进性能：开放回答准确率48.8%，多项选择准确率64.5%，比现有基线提高14-26个百分点。

Conclusion: Deep Research展示了AI辅助科学工作流程的可行性，但实际部署需要考虑开放获取文献限制和自动新颖性评估等架构约束，为交互式科学发现系统提供了实用框架。

Abstract: Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.

</details>


### [70] [How Clinicians Think and What AI Can Learn From It](https://arxiv.org/abs/2601.12547)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 临床AI应转向序数决策而非预测引擎，采用稳健的序数规则和启发式方法处理临床不确定性


<details>
  <summary>Details</summary>
Motivation: 当前临床AI系统主要作为预测引擎，但真实临床推理是时间受限的序贯控制问题，需要在不确定性下进行信息收集和不可逆行动。临床医生依赖快速节俭的词典式启发式方法，而非基数优化。

Method: 提出临床AI新蓝图：使用丰富模型进行信念和轨迹建模，但通过稳健的序数规则选择行动；将启发式视为低维特例；将AI作为"选择性复杂性"工具，主要在决策脆弱且信息有正向预期影响时用于打破平局。

Result: 论证了序数非补偿性决策在医学中的规范合理性：临床权衡通常只能在序数尺度上测量；偏好和信号获取存在结构性粗糙度；当粗糙度超过决策边界时，期望效用优化变得脆弱，而稳健的支配/过滤规则能稳定决策。

Conclusion: 临床AI应与临床医生推理方式对齐，采用序数决策框架，将AI作为选择性复杂性工具，在需要时提供精细分析，同时保持决策的稳健性和可解释性。

Abstract: Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\to$ perception $\to$ inference $\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.

</details>


### [71] [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560)
*Arunkumar V,Gangadharan G. R.,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 论文提出了一个统一的智能体AI分类框架，将智能体分解为感知、大脑、规划、行动、工具使用和协作六个组件，并分析了从线性推理到原生推理模型的转变趋势。


<details>
  <summary>Details</summary>
Motivation: 随着AI从单纯文本生成转向智能体AI，各种架构设计涌现（从简单单循环智能体到分层多智能体系统），使得这一领域难以导航。需要统一的分类框架来理解和组织这一快速发展的领域。

Method: 提出一个统一的分类法，将智能体分解为六个核心组件：感知、大脑、规划、行动、工具使用和协作。使用这个框架分析从线性推理程序到原生推理时间模型的转变，以及从固定API调用到开放标准（如MCP和原生计算机使用）的过渡。

Result: 建立了一个系统化的智能体AI分类框架，能够描述不同架构设计。分析了智能体运行环境（数字操作系统、具身机器人等），回顾了当前评估实践，并识别了该领域的关键挑战。

Conclusion: 智能体AI正在从被动知识引擎转向主动认知控制器。论文提出的统一分类框架有助于理解和导航这一复杂领域。未来需要解决幻觉、无限循环、提示注入等开放挑战，以构建更稳健可靠的自主系统。

Abstract: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.

</details>


### [72] [STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models](https://arxiv.org/abs/2601.12641)
*Xiangyu Shi,Junyang Ding,Xu Zhao,Sinong Zhan,Payal Mohapatra,Daniel Quispe,Kojo Welbeck,Jian Cao,Wei Chen,Ping Guo,Qi Zhu*

Main category: cs.AI

TL;DR: STEP-LLM：通过LLM从自然语言生成STEP格式CAD模型，解决传统文本到CAD方法对特定内核的依赖问题，使用DFS重序列化、检索增强生成和强化学习提升几何保真度。


<details>
  <summary>Details</summary>
Motivation: CAD设计对专业知识要求高，现有基于命令序列或脚本的文本到CAD方法依赖特定内核且缺乏制造通用性。STEP作为广泛采用的中性边界表示格式直接兼容制造，但其图结构特性对自回归LLM构成挑战。

Method: 1) 构建~40K STEP-描述对数据集；2) 针对STEP图结构设计预处理：DFS重序列化线性化交叉引用并保持局部性，CoT风格结构注释指导全局一致性；3) 集成检索增强生成进行监督微调；4) 使用基于Chamfer距离的几何奖励进行强化学习优化生成质量。

Result: STEP-LLM在几何保真度上持续优于Text2CAD基线。RAG模块显著提升完整性和可渲染性，DFS重序列化增强整体准确性，RL进一步减少几何差异。指标和视觉比较均证实STEP-LLM生成形状保真度更高。

Conclusion: 证明了LLM驱动从自然语言生成STEP模型的可行性，展示了为制造业民主化CAD设计的潜力。该方法克服了STEP图结构对自回归LLM的挑战，实现了更高保真度的CAD模型生成。

Abstract: Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.

</details>


### [73] [MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents](https://arxiv.org/abs/2601.12661)
*Chuhan Qiao,Jianghua Huang,Daxing Zhao,Ziding Liu,Yanjun Shen,Bing Cheng,Wei Lin,Kai Wu*

Main category: cs.AI

TL;DR: MedConsultBench是一个评估医疗咨询代理的综合性框架，通过原子信息单元追踪临床信息获取，覆盖完整在线咨询周期，发现高诊断准确率常掩盖信息收集效率和用药安全方面的缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前医疗咨询代理评估过于注重结果导向，忽略了端到端流程完整性和临床安全性，现有交互基准往往碎片化且粗粒度，无法捕捉专业咨询所需的结构化询问逻辑和诊断严谨性。

Method: 提出MedConsultBench框架，覆盖从病史采集、诊断到治疗计划和随访问答的完整临床工作流；引入原子信息单元(AIUs)在子轮次层面追踪临床信息获取；通过22个细粒度指标评估信息收集效率；处理在线咨询中的模糊性和不确定性，强调用药方案兼容性和约束尊重的计划修订能力。

Result: 对19个大语言模型的系统评估显示，高诊断准确率常掩盖信息收集效率和用药安全方面的显著缺陷，揭示了理论医学知识与临床实践能力之间的关键差距。

Conclusion: MedConsultBench为医疗AI与真实世界临床护理的细微需求对齐提供了严谨基础，强调了将医疗AI评估从单纯诊断准确性扩展到完整临床工作流程和安全考虑的重要性。

Abstract: Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.

</details>


### [74] [Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration](https://arxiv.org/abs/2601.12667)
*Yi Di,Zhibin Zhao,Fujin Wang,Xue Liu,Jiafeng Tang,Jiaxin Ren,Zhi Zhai,Xuefeng Chen*

Main category: cs.AI

TL;DR: 提出SpaceHMchat框架，用于卫星巨型星座时代航天器电源系统的全回路健康管理，通过人机协作实现工作状态识别、异常检测、故障定位和维护决策，并开源首个AIL HM数据集。


<details>
  <summary>Details</summary>
Motivation: 卫星巨型星座时代即将到来，航天器数量将指数级增长，而航天器电源系统作为关键供电组件故障率高，需要适应大规模健康管理的新范式。

Method: 提出底层能力对齐原则，开发开源的人机协作框架SpaceHMchat，建立硬件真实的故障注入实验平台和仿真模型，并创建首个AIL HM数据集。

Result: SpaceHMchat在23个量化指标上表现优异：工作状态识别逻辑推理结论准确率100%，异常检测工具调用成功率超99%，故障定位精度超90%，维护决策知识库搜索时间小于3分钟。

Conclusion: 该研究为卫星巨型星座时代的航天器电源系统健康管理提供了有效的人机协作解决方案，通过开源框架、实验平台和数据集推动了该领域的发展。

Abstract: It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.

</details>


### [75] [Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction](https://arxiv.org/abs/2601.12688)
*Xu Zhang,Qinghua Wang,Mengyang Zhao,Fang Wang,Cunquan Qu*

Main category: cs.AI

TL;DR: 提出MMSI框架，通过结合量刑逻辑和Transformer编码器，解决多被告案件中角色模糊问题，提升AI司法辅助的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 多被告案件中司法表述常模糊被告角色，影响AI分析效果，需要精确区分主从犯责任以保障司法公正。

Method: 提出掩码多阶段推理（MMSI）框架：1）定向掩码机制澄清角色；2）对比数据构建策略增强模型对主从犯责任区分的敏感性；3）通过广播将预测的罪名标签整合到回归模型中，结合犯罪描述和法庭观点。

Result: 在故意伤害案件的自定义IMLJP数据集上评估，MMSI框架在角色责任区分方面显著优于基线模型，准确率有显著提升。

Conclusion: 该工作为增强智能司法系统提供了稳健解决方案，通过结合量刑逻辑和Transformer架构，有效解决了多被告案件中的角色模糊问题，代码已公开。

Abstract: Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.

</details>


### [76] [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711)
*Kevin Wang,Neel P. Bhatt,Cong Liu,Junbo Li,Runjin Chen,Yihan Xi,Timothy Barclay,Alvaro Velasquez,Ufuk Topcu,Zhangyang Wang*

Main category: cs.AI

TL;DR: 提出神经符号LoRA框架，动态结合数值微调（LoRA）和符号编辑（TextGrad），在保持内存效率的同时提升LLM适应能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM适应方法中，数值微调擅长注入新事实知识，符号编辑则能灵活控制风格和对齐而无需重新训练。两者各有优势但互补，需要一种能动态结合两者的统一框架

Method: 提出神经符号LoRA框架：1）统一监控信号和基于奖励的分类器，决定何时使用LoRA进行事实重构，何时使用TextGrad进行词元级编辑；2）将符号变换卸载到外部LLM以保持内存效率；3）符号编辑过程中产生的精炼提示可作为高质量可重用训练数据

Result: 在多个LLM骨干网络上的广泛实验表明，神经符号LoRA始终优于纯数值或纯符号基线，展现出更优的适应性和改进的性能

Conclusion: 交错使用数值和符号更新能为语言模型微调解锁新的多功能性水平，神经符号LoRA框架展示了这种结合的价值

Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.

</details>


### [77] [Teaching Large Reasoning Models Effective Reflection](https://arxiv.org/abs/2601.12720)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Qi Zhu,Fei Mi,Ganqu Cui,Yasheng Wang,Lifeng Shang*

Main category: cs.AI

TL;DR: 提出SCFT和RLERR方法解决大推理模型中的表面反思问题，通过自我批判微调和强化学习提升反思质量与推理准确性


<details>
  <summary>Details</summary>
Motivation: 大推理模型在复杂推理任务中常进行自我反思，但许多反思是表面的，对原始答案改进有限且增加计算开销，需要解决表面反思问题

Method: 1. SCFT：自我批判微调框架，让模型批判自身输出，通过拒绝采样筛选高质量批判，使用批判目标微调模型
2. RLERR：基于有效反思奖励的强化学习，利用SCFT初始化的高质量反思构建奖励信号，通过强化学习内化自我纠正过程

Result: 在AIME2024和AIME2025两个挑战性基准测试中，SCFT和RLERR显著提升了推理准确性和反思质量，优于最先进的基线方法

Conclusion: 提出的SCFT和RLERR方法有效解决了大推理模型中的表面反思问题，通过自我批判微调和强化学习相结合的方式，显著提升了模型的反思质量和推理性能

Abstract: Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.

</details>


### [78] [Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks](https://arxiv.org/abs/2601.12744)
*Tasnim Ahmed,Yifan Zhu,Salimur Choudhury*

Main category: cs.AI

TL;DR: 论文提出IntentOpt基准测试，评估视觉语言模型将网络草图转化为优化代码的能力，发现视觉参数提取会降低执行成功率，开源模型表现落后于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于意图的网络系统需要操作员用文本描述拓扑和参数，但网络从业者通常通过图表进行推理。研究探索视觉语言模型能否处理带注释的网络草图并生成正确的优化代码。

Method: 创建包含85个优化问题的IntentOpt基准测试，评估4个VLM模型在三种提示策略下的表现，比较多模态与纯文本输入的效果，并通过案例研究在实际网络测试床中部署生成的代码。

Result: 视觉参数提取使执行成功率降低12-21个百分点，GPT-5-Mini从93%降至72%；程序思维提示降低性能最多13个百分点；开源模型表现较差，Llama-3.2-11B-Vision仅18%而GPT-5-Mini达75%。

Conclusion: 研究建立了当前VLM在基于意图的网络系统中生成优化代码的基准能力和局限性，展示了通过模型上下文协议在实际基础设施中部署VLM生成代码的可行性。

Abstract: Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.

</details>


### [79] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

TL;DR: VIRO框架通过集成轻量级验证器到神经符号推理步骤中，解决了现有REC方法中的级联错误问题，在目标存在和不存在情况下都实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号REC方法虽然实现了可解释推理和强零样本泛化，但假设中间推理步骤准确，导致级联错误：错误检测和无效关系在推理链中传播，即使图像中没有目标也会产生高置信度的误报。

Method: 提出验证集成推理算子（VIRO）框架，在推理步骤中嵌入轻量级算子级验证器。每个算子执行并验证其输出（如对象存在性或空间关系），使系统能够在验证条件不满足时鲁棒地处理无目标情况。

Result: 在目标存在和无目标设置下达到61.1%的平衡准确率，实现最先进性能；在真实世界自我中心数据上展示泛化能力；计算效率高（吞吐量）、可靠性强（程序失败率<0.3%）、通过解耦程序生成与执行实现可扩展性。

Conclusion: VIRO通过集成算子级验证器有效解决了神经符号REC中的级联错误问题，在保持可解释推理的同时显著提升了鲁棒性、效率和可靠性，为复杂视觉语言推理任务提供了更可靠的解决方案。

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


### [80] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: SL-CBM通过整合1x1卷积层和交叉注意力机制，增强概念瓶颈模型的空间对齐能力，生成与模型内部推理紧密关联的忠实显著性图，显著提升局部忠实性、解释质量和干预效果。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）在局部忠实性方面表现不佳，无法将概念与有意义的图像区域进行空间对齐，这限制了其可解释性和可靠性。需要一种能够提供空间一致显著性图的方法，以增强概念级解释的可信度。

Method: 提出SL-CBM（具有语义局部性的CBM），通过整合1x1卷积层和交叉注意力机制，在概念和类别两个层面生成空间一致的显著性图。该方法使用对比性和基于熵的正则化来平衡准确性、稀疏性和忠实性。

Result: 在图像数据集上的广泛实验表明，SL-CBM显著提高了局部忠实性、解释质量和干预效果，同时保持了具有竞争力的分类准确性。消融研究强调了对比性和基于熵的正则化对于平衡准确性、稀疏性和忠实性的重要性。

Conclusion: SL-CBM弥合了基于概念的推理和空间可解释性之间的差距，为可解释和可信赖的概念模型设立了新标准，通过生成与模型内部推理紧密关联的忠实显著性图，增强了调试和干预的有效性。

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [81] [MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction](https://arxiv.org/abs/2601.12822)
*Wenqi Zhang,Yulin Shen,Changyue Jiang,Jiarun Dai,Geng Hong,Xudong Pan*

Main category: cs.AI

TL;DR: MirrorGuard：基于模拟训练的即插即用防御框架，通过神经符号模拟生成高风险GUI交互轨迹，在模拟环境中学习拦截和纠正计算机使用代理的不安全推理链，显著降低安全风险同时保持代理实用性。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型集成到计算机使用代理（CUAs）中，使其能够通过图形用户界面（GUI）自主与操作系统交互执行复杂任务。这种自主性引入了严重的安全风险：恶意指令或视觉提示注入可能触发不安全的推理并导致有害的系统级操作。现有防御方法（如基于检测的阻止）虽然能防止损害，但通常会过早中止任务，降低了代理的实用性。

Method: 提出MirrorGuard即插即用防御框架，采用基于模拟的训练方法。为了降低操作系统中的大规模训练成本，设计了新颖的神经符号模拟管道，完全在基于文本的模拟环境中生成真实的高风险GUI交互轨迹，捕获不安全的推理模式和潜在系统危险，而无需执行真实操作。在模拟环境中，MirrorGuard学习在CUAs产生和执行不安全操作之前拦截和纠正其不安全的推理链。

Result: 在真实世界测试中，跨多个基准和CUA架构的广泛评估显示，MirrorGuard显著缓解了安全风险。例如，在字节跳动UI-TARS系统上，它将不安全率从66.5%降低到13.0%，同时保持较低的错误拒绝率（FRR）。相比之下，最先进的GuardAgent仅将不安全率降低到53.9%，并且有15.4%更高的FRR。

Conclusion: 研究表明，基于模拟的防御方法能够在保持代理基本实用性的同时，提供强大的真实世界保护。MirrorGuard证明了模拟衍生防御的有效性，为计算机使用代理的安全提供了新的解决方案。

Abstract: Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.

</details>


### [82] [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842)
*Qitong Fang,Haotian Li,Xu Wang*

Main category: cs.AI

TL;DR: SCULPT是一种约束引导的蒙特卡洛树搜索方法，通过领域感知评分和剪枝来引导LLM代理搜索更合理的推理路径，提高问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM自动化代理工作流依赖随机探索，经常遍历不合理的分支，因为现有方法从通用提示或弱领域先验的策略中采样候选步骤，导致在操作符、单位和格式上的近似随机游走。

Method: 提出SCULPT方法，将领域感知评分集成到MCTS的选择、扩展、模拟和反向传播阶段。使用符号检查（维度一致性、类型兼容性、幅度合理性、深度控制和多样性）和结构模式指导来评分和剪枝动作。

Result: 在匹配的LLM配置下，SCULPT在多个数据集上带来稳定改进；使用GPT-5.2的额外结果评估了执行器可迁移性和前沿推理模型的性能。

Conclusion: 领域感知约束可以在保持效率和推理稳定性的同时提高准确性，为LLM代理搜索提供了更有序的探索策略。

Abstract: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.

</details>


### [83] [Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data](https://arxiv.org/abs/2601.12856)
*Liping Huang,Gaoxi Xiao,Stefan Ma,Hechang Chen,Shisong Tang,Flora Salim*

Main category: cs.AI

TL;DR: 提出一个从公开登革热病例数据中挖掘隐藏传播链的框架，通过梯度下降优化学习区域间传播网络，用于预测热点区域并验证传播模式一致性，在新加坡案例中取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 登革热在热带城市地区持续构成公共卫生挑战，需要提前预测传播风险以部署主动干预措施。传统方法将病例视为孤立报告，未能充分利用区域间的潜在传播联系。

Method: 从公开登革热病例数据中挖掘区域间隐藏的传播链，通过梯度下降优化学习传播网络。模型考虑一个区域热点形成受邻近区域疫情动态的影响，验证学习网络在连续周内的稳定性。

Result: 在新加坡2013-2018和2020年的案例研究中，仅需四周热点历史数据即可达到平均F分数0.79。学习到的传播链与通勤流高度一致，揭示了隐藏疫情传播与人类流动的可解释关联。

Conclusion: 该框架将公开网络病例数据转化为预测性和解释性资源，从单纯报告病例转向挖掘和验证隐藏传播动态，为公共卫生规划、早期干预和城市韧性提供了可扩展、低成本工具。

Abstract: Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.

</details>


### [84] [Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912)
*Andreas Brännström,Juan Carlos Nieves*

Main category: cs.AI

TL;DR: C-MT是一种基于回答集编程和转移系统构建的动作语言，用于建模人类心理状态在可观察动作序列下的演化，特别关注情绪等心理状态的多维配置和受控变化。


<details>
  <summary>Details</summary>
Motivation: 解决对受控智能体行为的需求，限制动作带来的不良心理副作用，为人类心理状态（特别是情绪）的动态演化提供形式化建模框架。

Method: 基于回答集编程和转移系统，结合心理学理论（如情绪评估理论），形式化心理状态为多维配置。引入新的因果规则"forbids to cause"和专门的心理状态动态表达式，将心理变化原则转化为转移约束和不变性属性。

Result: 开发了C-MT语言，能够对心理状态动态演化进行受控推理，支持通过轨迹分析比较不同的心理变化动态，并应用于情绪验证模型设计。

Conclusion: C-MT为人类心理状态演化提供了形式化建模框架，支持受控推理和不同心理学原则的比较，在情绪验证等应用中有实用价值。

Abstract: In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [85] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

TL;DR: 论文认为当前AI可解释性研究存在根本性问题，因为现有定义缺乏可操作性，无法推导出具体的建模和推理规则。作者提出基于对称性的可操作定义，认为四种对称性足以解决可解释性的核心问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI可解释性研究存在根本性缺陷，因为现有的可解释性定义缺乏可操作性。这些定义无法提供形式化原则来推导具体的建模和推理规则，导致研究难以取得实质性进展。

Method: 提出基于对称性的可操作定义框架。作者假设四种对称性足以：(1) 激发核心可解释性属性，(2) 刻画可解释模型类别，(3) 推导统一的可解释推理形式（如对齐、干预和反事实）作为贝叶斯逆问题。

Result: 通过对称性框架，为可解释性研究提供了形式化基础，将可解释性属性、模型类别和推理方法统一在同一个理论框架下，解决了现有定义缺乏可操作性的问题。

Conclusion: 可解释性研究需要基于对称性的可操作定义，这四种对称性能够为AI可解释性提供坚实的理论基础，统一现有的各种可解释性概念和方法，推动该领域向前发展。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [86] [MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux](https://arxiv.org/abs/2601.13060)
*Zecheng Li,Zhihui Cao,Wenke Huang,Yudong Zhang,Keying Qi,Rui Wang,Zeyu Zheng,Jian Zhao,Hao Zhu,Hengxin Wu,Yuran Wang,Guitao Fan,Guokun Wu,Yicong Liu,Zhilin Gao,Haikun Xu,He Yang,Minqi Xiang,Xingyu Liu,Zuojian Wang*

Main category: cs.AI

TL;DR: MagicGUI-RMS是一个多智能体奖励模型系统，用于自动化评估GUI智能体轨迹、生成高质量训练数据，并通过奖励反馈实现持续自我改进。


<details>
  <summary>Details</summary>
Motivation: 当前GUI智能体面临两大核心挑战：自动化评估智能体轨迹的困难，以及大规模生成高质量训练数据以实现持续改进的瓶颈。现有方法依赖人工标注或静态规则验证，限制了可扩展性和动态环境适应性。

Method: MagicGUI-RMS整合了领域特定奖励模型（DS-RM）和通用奖励模型（GP-RM），实现细粒度动作评估和跨异构GUI任务的鲁棒泛化。设计了结构化数据构建管道，自动生成平衡多样的奖励数据集，降低标注成本。系统通过自动数据回流机制识别错误动作、提出改进方案并持续增强智能体行为。

Result: 大量实验表明，MagicGUI-RMS在任务准确性和行为鲁棒性方面取得了显著提升。该系统为构建基于奖励适应的自改进GUI智能体提供了原则性且有效的基础。

Conclusion: MagicGUI-RMS通过多智能体奖励模型系统解决了GUI智能体评估和训练数据生成的关键挑战，实现了自适应轨迹评估、纠正反馈和自我进化学习能力，为自改进GUI智能体发展奠定了坚实基础。

Abstract: Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.

</details>


### [87] [Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward](https://arxiv.org/abs/2601.13122)
*Gourab K Patro,Himanshi Agrawal,Himanshu Gharat,Supriya Panigrahi,Nim Sherpa,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: 论文指出通用AI系统存在幻觉、毒性等风险，相比任务专用AI更难实现负责任AI，提出需要重新思考RAI方法，并建立C2V2框架（控制、一致性、价值、真实性）来指导未来通用AI系统的负责任发展。


<details>
  <summary>Details</summary>
Motivation: 现代通用AI系统虽然功能强大，但存在幻觉、毒性、刻板印象等风险，使其不可信。相比传统任务专用AI，通用AI在负责任AI原则（公平性、隐私、可解释性等）方面面临更严峻挑战，需要重新思考负责任AI的实现方法。

Method: 分析通用AI系统在八个负责任AI原则方面的风险，与传统任务专用AI对比，提出输出自由度（DoFo）概念解释差异，推导出C2V2（控制、一致性、价值、真实性）需求框架，并评估现有技术（AI对齐、检索增强生成、推理增强等）在满足这些需求方面的表现。

Result: 通用AI系统由于输出自由度非确定性高，在负责任AI原则方面面临比任务专用AI更严重且难以缓解的风险。C2V2框架为通用AI的负责任发展提供了系统性指导，现有技术只能部分满足这些需求，需要结合多种技术的系统设计方法。

Conclusion: 开发负责任的通用AI需要通过C2V2维度形式化建模应用或领域相关的RAI需求，并采用系统设计方法结合多种技术来满足这些需求。这是实现通用AI负责任发展的可行路径。

Abstract: Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.

</details>


### [88] [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 本文扩展了TIVS评估框架，提出TIVS-O评分系统，结合语义相似性缓存和可观测性指标，在HOPE启发的嵌套学习架构中研究防御效果与透明度的平衡。


<details>
  <summary>Details</summary>
Motivation: 提示注入攻击是大型语言模型安全部署的主要障碍，特别是在多智能体环境中，中间输出可能传播或放大恶意指令。现有评估框架需要同时考虑安全性和可审计性之间的权衡。

Method: 提出TIVS-O评估框架，包含语义相似性缓存和可观测性评分比（OSR）作为第五个指标。采用HOPE启发的嵌套学习架构，结合智能体管道和连续内存系统，使用301个合成生成的注入提示进行测试，由第四个智能体使用五个关键性能指标进行安全分析。

Result: 系统实现零高风险漏洞的安全响应，语义缓存显著减少计算开销（LLM调用减少41.6%），降低延迟、能耗和碳排放。五种TIVS-O配置揭示了缓解严格性与取证透明度之间的最优权衡。

Conclusion: 可观测性感知评估能揭示多智能体管道中的非单调效应，内存增强智能体可在不修改模型权重的情况下，同时最大化安全鲁棒性、实时性能、运营成本节约和环境可持续性，为安全绿色LLM部署提供生产就绪路径。

Abstract: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.

</details>


### [89] [Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues](https://arxiv.org/abs/2601.13206)
*Neil K. R. Sehgal,Sharath Chandra Guntuku,Lyle Ungar*

Main category: cs.AI

TL;DR: LLMs在连续时间限制下的时间意识存在系统性缺陷，特别是在实时谈判等时间敏感场景中，但通过提供剩余时间信息可以显著改善表现。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的沟通（如治疗会话、商业谈判）都依赖于连续时间约束，而当前LLM架构和评估协议很少测试在实时截止时间下的时间意识能力。

Method: 使用模拟谈判实验，配对智能体在严格截止时间下进行谈判。设置两种条件：控制条件（仅知道全局时间限制）和时间意识条件（每轮获得剩余时间更新）。比较两种条件下的交易达成率和报价接受率。

Result: 时间意识条件下的交易达成率显著更高（GPT-5.1为32% vs 4%），报价接受率高出六倍。但在基于轮次的限制下，相同LLM能达到接近完美的交易达成率（≥95%），表明问题在于时间跟踪而非战略推理。

Conclusion: LLMs在内部跟踪流逝时间方面存在系统性缺陷，这种时间意识的缺乏将限制LLM在许多时间敏感应用中的部署。需要改进LLM架构以更好地处理连续时间约束。

Abstract: Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\% vs. 4\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\geq$95\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.

</details>


### [90] [RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements](https://arxiv.org/abs/2601.13233)
*Bolin Chen,Dex Doksoo Lee,Wei "Wayne'' Chen,Wei Chen*

Main category: cs.AI

TL;DR: 提出RAG方法，基于随机森林进行数据高效的生成式设计，用于解决功能响应逆设计中的高维性、数据稀缺和不确定性量化问题


<details>
  <summary>Details</summary>
Motivation: 功能响应的逆设计面临高维性、设计需求复杂、可行解可能不存在或不唯一等挑战。现有生成式方法通常需要大量数据，处理设计需求时启发式，且缺乏不确定性量化

Method: 提出RAndom-forest-based Generative approach (RAG)，利用随机森林的小数据兼容性预测高维功能响应。通过集成估计似然度来量化生成设计的可信度，并通过条件似然采样处理一对多映射问题

Result: 在声学超材料（500样本）和机械超材料（1057样本）上验证了RAG的有效性。与神经网络相比，在公开的非线性应力-应变关系数据集上展示了数据高效性

Conclusion: RAG为涉及功能响应、昂贵仿真和复杂设计需求的逆设计提供了一条轻量级、可信赖的途径，可应用于超材料及其他领域

Abstract: Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.

</details>


### [91] [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262)
*Eric Onyame,Akash Ghosh,Subhadip Baidya,Sriparna Saha,Xiuying Chen,Chirag Agarwal*

Main category: cs.AI

TL;DR: 提出CURE-MED框架，通过课程式强化学习提升LLM在多语言医疗推理中的逻辑正确性和语言一致性


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在单语言数学和常识推理上表现良好，但在多语言医疗推理应用中仍不可靠，阻碍了在多语言医疗环境中的部署

Method: 1) 引入CUREMED-BENCH多语言医疗推理数据集；2) 提出CURE-MED课程式强化学习框架，整合代码切换感知的监督微调和组相对策略优化

Result: 在13种语言上持续优于强基线，7B参数模型达到85.21%语言一致性和54.35%逻辑正确性，32B参数模型达到94.96%语言一致性和70.04%逻辑正确性

Conclusion: 该方法支持LLM实现可靠且公平的多语言医疗推理，代码和数据集已开源

Abstract: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

</details>


### [92] [Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops](https://arxiv.org/abs/2601.13268)
*Zainab Ghafoor,Md Shafiqul Islam,Koushik Howlader,Md Rasel Khondokar,Tanusree Bhattacharjee,Sayantan Chakraborty,Adrito Roy,Ushashi Bhattacharjee,Tirtho Roy*

Main category: cs.AI

TL;DR: 提出多智能体精炼框架，通过迭代对齐提升医疗大语言模型的安全性和可靠性，结合生成模型和评估智能体，显著减少伦理违规和风险等级。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗领域应用日益广泛，但其伦理完整性和安全合规性仍是临床部署的主要障碍，需要系统化的安全增强方法。

Method: 采用多智能体精炼框架，结合DeepSeek R1和Med-PaLM两个生成模型，以及LLaMA 3.1和Phi-4两个评估智能体，使用AMA医学伦理原则和五级安全风险评估协议，对900个临床多样化查询进行迭代评估。

Result: DeepSeek R1收敛更快（平均2.34次迭代），Med-PaLM在隐私敏感场景表现更优。多智能体迭代循环实现89%的伦理违规减少和92%的风险降级率。

Conclusion: 该研究提出了一种可扩展、符合监管要求且成本效益高的医疗AI安全治理范式，为医疗大语言模型的临床部署提供了有效的安全增强方案。

Abstract: Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.

</details>


### [93] [PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion](https://arxiv.org/abs/2601.13327)
*Po-Yu Liang,Tobo Duran,Jun Bai*

Main category: cs.AI

TL;DR: PepEDiff是一个新型的肽结合剂生成器，无需结构预测，直接在连续潜空间中设计结合序列，提高了序列多样性


<details>
  <summary>Details</summary>
Motivation: 现有肽结合剂生成方法依赖中间结构预测，增加了复杂性并限制了序列多样性。需要一种更直接、更灵活的方法来设计结合序列

Method: 使用预训练蛋白质嵌入模型的连续潜空间，通过潜空间探索和基于扩散的采样生成结合序列，避免依赖预测结构

Result: 在TIGIT（具有大而平坦的蛋白质-蛋白质相互作用界面）的案例研究中，PepEDiff超越了现有最先进方法，展示了其作为零样本肽结合剂设计的通用框架潜力

Conclusion: PepEDiff提供了一种无需结构预测的零样本肽结合剂设计框架，能够生成新颖的肽序列，在具有挑战性的靶点上表现出色

Abstract: We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model

</details>


### [94] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

TL;DR: 研究发现模型规模扩张不会均匀提升推理能力，而是重构推理过程。通过分析25,000+思维链轨迹，发现神经缩放定律触发领域特定的相变：法律推理呈现"结晶化"，科学和数学推理保持"液态"，代码推理形成"晶格"结构。几何结构可预测可学习性，并可用于推理加速。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为模型规模扩大能均匀提升推理能力，但本文质疑这一假设，探索规模扩张如何真正改变推理的内部结构，以及不同领域是否呈现不同的缩放模式。

Method: 分析25,000+思维链轨迹，涵盖法律、科学、代码、数学四个领域，比较8B和70B参数规模。使用几何分析方法（表示维度、轨迹对齐、流形解缠），引入神经推理算子（从初始到最终隐藏状态的映射），并识别振荡特征。

Result: 发现三种不同的缩放模式：1）法律推理呈现"结晶化"（维度下降45%，轨迹对齐增加31%，流形解缠10倍）；2）科学和数学推理保持"液态"（几何不变）；3）代码推理形成"晶格"结构（轮廓系数从0.13增至0.42）。神经推理算子在法律推理上达到63.6%准确率。发现跨领域和规模的普遍振荡特征（相干性约-0.4）。

Conclusion: 推理成本由流形几何而非任务难度决定，这为在拓扑允许的情况下加速推理提供了蓝图。不同领域呈现不同的缩放相变，理解这些几何结构可预测可学习性并优化推理效率。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [95] [A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge](https://arxiv.org/abs/2601.13383)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: AgentForge是一个轻量级开源Python框架，通过模块化架构简化LLM驱动的自主代理开发，提供可组合技能抽象、统一LLM后端接口和声明式配置系统，显著减少开发时间。


<details>
  <summary>Details</summary>
Motivation: 现有代理框架存在架构僵化、供应商锁定和复杂性过高的问题，阻碍了快速原型设计和部署。需要一种更灵活、易用的框架来降低LLM自主代理的开发门槛。

Method: 提出AgentForge框架，包含三个核心创新：1) 可组合技能抽象，支持细粒度任务分解和形式化输入输出契约；2) 统一LLM后端接口，支持云端API和本地推理引擎无缝切换；3) 声明式YAML配置系统，分离代理逻辑与实现细节。将技能组合机制形式化为有向无环图(DAG)。

Result: 在四个基准场景的评估中，AgentForge达到竞争性任务完成率，相比LangChain减少62%开发时间，相比直接API集成减少78%开发时间。编排延迟低于100毫秒，适合实时应用。框架集成了六个内置技能，支持自定义技能开发。

Conclusion: AgentForge填补了LLM代理生态系统的关键空白，为研究人员和从业者提供了生产就绪的基础设施，可在不牺牲灵活性或性能的前提下构建、评估和部署自主代理。

Abstract: The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.

</details>


### [96] [Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models](https://arxiv.org/abs/2601.13443)
*Héctor Manuel Manzanilla-Granados,Zaira Navarrete-Cazales,Miriam Pescador-Rojas,Tonahtiu Ramírez-Romero*

Main category: cs.AI

TL;DR: 本文提出"显式认知分配"原则，通过分离和组织认知功能来结构化AI辅助推理，并实现为"认知通用代理"架构，在农业领域评估中显示出更好的认知收敛性和工具意识。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的使用方式在认知上缺乏结构，将问题框架、知识探索、检索、方法意识和解释等认知功能压缩到单一生成过程中，这限制了可追溯性、削弱了认知控制并破坏了可重复性，特别是在高责任场景中。

Method: 提出"显式认知分配"原则，将其实例化为"认知通用代理"架构，该架构将推理组织为探索与框架、认知锚定、工具与方法映射、解释性合成等不同阶段。核心是"通用认知工具"概念，形式化各种工具手段。

Result: 在农业领域的多提示实验中，CUA推理显示出更早且结构化的认知收敛、语义扩展下更高的认知对齐度，并能系统性地揭示查询的工具景观。相比之下，基线LLM推理在对齐度上表现出更大变异性，且未能明确展示工具结构。

Conclusion: 显式认知分配原则和CUA架构能够改善AI辅助推理的结构化程度，增强可追溯性、认知控制和可重复性，特别是在需要高责任性的科学、技术和组织领域中。

Abstract: The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.
  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.
  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.

</details>


### [97] [SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation](https://arxiv.org/abs/2601.13462)
*Amine Rostane*

Main category: cs.AI

TL;DR: SpatialBench-UC是一个用于评估文本到图像模型空间指令遵循能力的小型可复现基准测试，包含200个提示和100个反事实对，通过选择性预测方法报告通过率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 评估文本到图像模型是否遵循显式空间指令难以自动化，因为物体检测器可能漏检或返回多个可能检测，简单的几何测试在边界情况下变得模糊。空间评估本质上是选择性预测问题，检查器可以在证据不足时弃权并报告置信度。

Method: 引入SpatialBench-UC基准测试，包含200个提示（50个物体对×4种关系），分组为100个通过交换物体角色获得的反事实对。发布基准测试包、版本化提示、固定配置、每个样本的检查器输出和报告表格，实现模型间可复现和可审计的比较。还包括轻量级人工审核来校准检查器的弃权边界和置信度阈值。

Result: 评估了三个基线模型：Stable Diffusion 1.5、SD 1.5 BoxDiff和SD 1.4 GLIGEN。检查器报告通过率和覆盖率以及已决定样本的条件通过率。结果显示，接地方法显著提高了通过率和覆盖率，但弃权仍然是主要因素，主要原因是漏检。

Conclusion: SpatialBench-UC提供了一个可复现的基准测试框架，用于评估文本到图像模型的空间指令遵循能力，通过选择性预测方法能够更准确地反映模型性能，并显示接地方法对改善空间关系理解的积极效果。

Abstract: Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.

</details>


### [98] [Context and Transcripts Improve Detection of Deepfake Audios of Public Figures](https://arxiv.org/abs/2601.13464)
*Chongyang Gao,Marco Postiglione,Julian Baldwin,Natalia Denisenko,Isabel Gortner,Luke Fosdick,Chiara Pulice,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.AI

TL;DR: 提出基于上下文和文本的音频深度伪造检测器CADD，通过整合上下文信息和转录文本显著提升检测性能，并增强对抗攻击鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 人类利用上下文判断信息真伪，但现有音频深度伪造检测器仅分析音频文件，忽略了上下文和转录文本信息，限制了检测效果。

Method: 创建记者提供的深度伪造数据集JDD和合成音频数据集SYN，提出基于上下文的音频深度伪造检测器CADD架构，整合上下文和转录文本信息进行检测。

Result: 上下文和转录文本显著提升检测性能：F1分数提升5%-37.58%，AUC提升3.77%-42.79%，EER提升6.17%-47.83%。CADD对5种对抗攻击策略更鲁棒，平均性能下降仅-0.71%。

Conclusion: 上下文和转录文本信息能显著提升音频深度伪造检测器的性能和鲁棒性，为实际应用提供了更有效的解决方案。

Abstract: Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).

</details>


### [99] [Graph Neural Networks are Heuristics](https://arxiv.org/abs/2601.13465)
*Yimeng Min,Carla P. Gomes*

Main category: cs.AI

TL;DR: 单个训练轨迹可将图神经网络转化为组合优化的无监督启发式算法，无需搜索、监督或序列决策即可直接生成旅行商问题解


<details>
  <summary>Details</summary>
Motivation: 探索图神经网络是否能在无监督、无搜索的情况下直接作为组合优化启发式算法，重新定义学习在组合优化中的角色

Method: 将全局结构约束作为归纳偏置编码到非自回归模型中，推理时使用dropout和快照集成让单个模型作为隐式集成，增加解多样性

Result: 图神经网络无需监督训练或显式搜索即可有效工作，能够内化全局组合结构并作为强大的学习启发式算法

Conclusion: 学习在组合优化中的角色应从增强经典算法转变为直接实例化新的启发式算法

Abstract: We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.

</details>


### [100] [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481)
*Jian Zhang,Zhangqi Wang,Zhiyuan Wang,Weiping Fu,Yu He,Haiping Zhu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: APOLO是一个用于精神健康领域情感诊断的自动提示优化框架，通过多智能体协作机制探索更精细的提示空间，提高LLM在临床环境中的诊断准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在临床情感诊断中面临两大挑战：1) 情感共病性（多种交织情感状态使预测复杂化）；2) 临床相关线索探索效率低。LLM在医疗高风险、上下文密集环境中的诊断可靠性高度依赖提示设计。

Method: 提出APOLO框架，将指令优化建模为部分可观测马尔可夫决策过程，采用多智能体协作机制：Planner定义优化轨迹，Teacher-Critic-Student智能体迭代优化提示以提高推理稳定性，Target智能体根据性能评估决定是否继续优化。

Result: 实验结果表明，APOLO在领域特定和分层基准测试中持续提高诊断准确性和鲁棒性，为精神健康领域可信赖的LLM应用提供了可扩展和可泛化的范式。

Conclusion: APOLO通过系统探索更广泛、更精细的提示空间，有效解决了临床情感诊断中的情感共病性和线索探索效率问题，为高风险医疗环境中LLM的可靠应用提供了实用框架。

Abstract: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.

</details>


### [101] [AgenticRed: Optimizing Agentic Systems for Automated Red-teaming](https://arxiv.org/abs/2601.13518)
*Jiayi Yuan,Jonathan Nöther,Natasha Jaques,Goran Radanović*

Main category: cs.AI

TL;DR: AgenticRed：一种利用LLM上下文学习自动设计和优化红队系统的框架，无需人工干预，在多个模型上显著提升攻击成功率


<details>
  <summary>Details</summary>
Motivation: 现有自动红队方法依赖人工设计的工作流程，存在人为偏见且探索设计空间成本高昂，需要更自动化的系统设计方法

Method: 将红队视为系统设计问题，利用LLM的上下文学习能力，通过进化选择方法迭代设计和优化红队系统，无需人工干预

Result: 在Llama-2-7B上攻击成功率96%（提升36%），Llama-3-8B上98%；在GPT-3.5-Turbo和GPT-4o-mini上达到100%，Claude-Sonnet-3.5上60%（提升24%）

Conclusion: 自动化系统设计是AI安全评估的强大范式，能够跟上模型快速演进的步伐，为红队测试提供了更有效的方法

Abstract: While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.

</details>


### [102] [Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models](https://arxiv.org/abs/2601.13533)
*Changshuo Zhang*

Main category: cs.AI

TL;DR: EGLR模型通过熵引导的潜在推理机制，在生成式重排序中实现"边推荐边推理"，动态适应列表生成难度变化，提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式重排序方法难以适应列表生成过程中模型难度的动态熵变化，无法准确捕捉复杂用户偏好。语言模型通过推理能力取得突破，启发我们引入潜在推理机制来降低决策熵。

Method: 提出熵引导潜在推理(EGLR)模型：1) 抛弃"先推理后推荐"范式，实现"边推荐边推理"；2) 使用上下文感知推理标记和动态温度调整实现熵引导变长推理；3) 轻量级集成设计，无需复杂独立模块或后处理。

Result: 在两个真实世界数据集上的实验验证了模型有效性，显著优势在于能与现有生成式重排序模型兼容并提升其性能。进一步分析展示了实际部署价值和研究潜力。

Conclusion: EGLR模型通过熵引导的潜在推理机制，在生成式重排序中实现了更精确的探索-利用权衡，为动态列表生成任务提供了有效的解决方案，具有实际应用价值。

Abstract: Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the "reason first, recommend later" paradigm to achieve "reasoning while recommending", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.

</details>


### [103] [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546)
*Hui Sun,Chang Xu,Haonan Xie,Hao Li,Yuhao Huang,Chuheng Zhang,Ming Jin,Xiaoguang Liu,Gang Wang,Jiang Bian*

Main category: cs.AI

TL;DR: 提出TSEvol多智能体时间序列演化算法、TSEData-20K数据集、ChatAD系列模型、TKTO优化方法和LLADBench基准，显著提升时间序列异常检测的推理能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的异常检测方法存在推理能力不足、多轮对话能力欠缺和泛化能力有限的问题，需要提升时间序列异常行为的理解和解释能力。

Method: 1) 提出TSEvol多智能体时间序列演化算法；2) 构建TSEData-20K数据集并开发ChatAD系列模型；3) 提出TKTO优化方法增强跨任务泛化；4) 建立LLADBench基准评估框架。

Result: ChatAD模型在准确率提升34.50%、F1分数提升34.71%、误报率降低37.42%；通过TKTO优化后在分类、预测和填补任务上展现出竞争力的推理和跨任务泛化能力。

Conclusion: 该方法显著提升了时间序列异常检测的推理能力、多轮对话能力和跨任务泛化能力，为LLM驱动的异常检测提供了有效的解决方案和评估基准。

Abstract: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.

</details>


### [104] [Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis](https://arxiv.org/abs/2601.13558)
*Mehrab Beikzadeh,Chenglin Hong,Cory J Cascalheira,Callisto Boka,Majid Sarrafzadeh,Ian W Holloway*

Main category: cs.AI

TL;DR: 利用社交媒体和约会应用文本数据，通过机器学习模型预测男男性行为者的性风险行为、酒精使用和PrEP使用情况，展示了文本数据在公共卫生干预中的潜力。


<details>
  <summary>Details</summary>
Motivation: 男男性行为者面临性传播感染和有害饮酒的高风险，社交媒体和约会应用文本数据可能为个性化公共卫生干预提供新机会，通过自动识别风险和保护行为来支持预防工作。

Method: 收集参与者同意的文本数据，使用ChatGPT嵌入、BERT嵌入、LIWC和基于词典的风险术语方法提取特征，训练机器学习模型预测性风险行为、酒精使用和PrEP使用。

Result: 模型在预测每月酗酒和超过5个性伴侣方面表现良好（F1分数0.78），在预测PrEP使用和重度饮酒方面表现中等（F1分数0.64和0.63）。

Conclusion: 社交媒体和约会应用文本数据能够提供关于风险和保护行为的宝贵见解，基于大语言模型的方法有潜力支持针对男男性行为者的可扩展和个性化公共卫生干预。

Abstract: Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

</details>


### [105] [AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent](https://arxiv.org/abs/2601.13559)
*Sun Hui,Ding Yanfeng,Huidong Ma,Chang Xu,Keyan Jin,Lizheng Zu,Cheng Zhong,xiaoguang Liu,Gang Wang,Wentong Cai*

Main category: cs.AI

TL;DR: AgentGC：首个基于智能体进化的基因组数据压缩器，通过三层架构（用户层、认知层、压缩层）和多智能体系统，在压缩比和吞吐量方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的基因组数据压缩方法存在不可进化、低级压缩建模、适应性有限和用户界面不友好等问题，需要一种更智能、自适应的解决方案。

Method: 提出三层智能体架构：1) 用户层通过Leader智能体结合LLM提供友好界面；2) 认知层由Leader驱动，整合LLM进行算法-数据集-系统联合优化；3) 压缩层由Worker智能体执行，采用自动化多知识学习压缩框架。支持三种模式：压缩比优先(CP)、吞吐量优先(TP)和平衡模式(BM)。

Result: 在9个数据集上与14个基线方法比较，平均压缩比提升分别为16.66%、16.11%和16.33%，吞吐量提升分别为4.73倍、9.23倍和9.15倍。

Conclusion: AgentGC是首个基于智能体进化的基因组数据压缩器，通过多智能体架构和LLM集成，有效解决了现有方法的局限性，在压缩性能和效率方面取得显著提升。

Abstract: Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.

</details>


### [106] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

TL;DR: 提出一种角色分离的Transformer架构，在视觉推理任务ARC上超越人类平均表现，验证了推理应作为独立通道的假设。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统（如LLMs和ViTs）主要作为行为序列预测机器运行，缺乏可解释的持久心理状态，与人类能够通过解码内部状态解释行为的推理能力存在差距。作者假设推理应作为一种独立于低层工作空间的模态存在。

Method: 设计了一种新颖的角色分离Transformer块，将全局控制器令牌与网格工作空间令牌分离，支持迭代规则执行。在VARC视觉中心协议下进行训练和评估。

Result: 在ARC-1任务上达到62.6%的准确率，超越了人类平均表现（60.2%），显著优于先前方法。定性分析显示模型展现出比密集ViT基线更一致的规则应用结构。

Conclusion: 验证了推理作为独立通道的假设，模型从概率分布预测转向控制器驱动的推理，为构建具有可解释内部状态的AI系统提供了新方向。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [107] [SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System](https://arxiv.org/abs/2601.13581)
*Heedou Kim,Changsik Kim,Sanghwa Shin,Jaewoo Kang*

Main category: cs.AI

TL;DR: ScriptMind是一个基于大语言模型的诈骗检测框架，通过犯罪脚本推理任务、数据集构建和认知模拟评估，显著提升诈骗检测性能，并在韩国电话诈骗案例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 社会工程诈骗日益采用个性化、多轮对话的欺骗手段，传统检测方法面临局限。虽然大语言模型在识别欺骗方面有潜力，但其认知辅助能力尚未充分探索。

Method: 提出ScriptMind集成框架，包含三个组件：犯罪脚本推理任务（CSIT）用于诈骗推理、犯罪脚本感知推理数据集（CSID）用于微调小型LLM、认知模拟评估（CSED）用于评估实时认知影响。使用571个韩国电话诈骗案例构建了22,712个结构化诈骗序列训练实例。

Result: 经过ScriptMind微调的11B小型LLM在检测准确率、误报减少、诈骗者话语预测和推理质量方面优于GPT-4o 13%，超越了商业模型。在电话诈骗模拟实验中，显著提升并维持了用户的怀疑水平，增强了他们对诈骗的认知意识。

Conclusion: ScriptMind代表了向以人为本、认知自适应的大语言模型诈骗防御迈出的一步，为人类认知辅助的诈骗检测提供了有效框架。

Abstract: Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.

</details>


### [108] [Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589)
*HyeYoung Lee*

Main category: cs.AI

TL;DR: 提出基于音频情感信号的多智能体AI系统，实时生成响应式媒体内容，强调情感状态到安全可控内容的转换，包含四个协作智能体和显式安全验证循环。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别研究主要关注分类准确性，但缺乏将推断出的情感状态转化为安全、适龄、可控的响应内容。需要一种系统能够实时将情感信号转化为安全的媒体响应，适用于儿童相关媒体、治疗应用和情感响应智能设备。

Method: 采用多智能体架构，包含四个协作智能体：1) 基于CNN的情感识别智能体进行声学特征提取；2) 响应策略决策智能体将情感映射到响应模式；3) 内容参数生成智能体产生媒体控制参数；4) 安全验证智能体执行适龄性和刺激约束。引入显式安全验证循环在输出前过滤生成内容。

Result: 在公开数据集上的实验结果显示：情感识别准确率达到73.2%，响应模式一致性为89.4%，安全合规性达到100%，同时保持低于100毫秒的推理延迟，适合设备端部署。

Conclusion: 该多智能体系统成功将情感识别转化为安全可控的媒体响应，模块化架构提供了可解释性和可扩展性，适用于儿童媒体、治疗应用和情感响应智能设备，在保持实时性能的同时确保了内容安全。

Abstract: This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.

</details>


### [109] [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591)
*Maojun Sun,Yifei Xie,Yue Wu,Ruijian Han,Binyan Jiang,Defeng Sun,Yancheng Yuan,Jian Huang*

Main category: cs.AI

TL;DR: DSAEval是一个包含641个真实世界数据科学问题的基准测试，基于285个多样化数据集，涵盖结构化和非结构化数据，具有多模态环境感知、多查询交互和多维评估三大特征。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的数据代理旨在自动化数据科学任务，但真实世界数据科学问题的开放性、跨分类和缺乏标准答案的特性给评估带来了重大挑战，需要专门的基准测试。

Method: 提出DSAEval基准，包含641个真实世界数据科学问题，基于285个多样化数据集，涵盖结构化和非结构化数据（视觉和文本），具有多模态环境感知、多查询交互和多维评估三大特征。

Result: 评估了11个先进的代理LLM，Claude-Sonnet-4.5整体性能最强，GPT-5.2最有效率，MiMo-V2-Flash最具成本效益；多模态感知在视觉相关任务上带来2.04%到11.30%的性能提升。

Conclusion: 当前数据科学代理在结构化数据和常规数据分析工作流上表现良好，但在非结构化领域仍面临重大挑战；提供了关键见解并概述了未来研究方向以推进数据科学代理的发展。

Abstract: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

</details>


### [110] [Foundations of Global Consistency Checking with Noisy LLM Oracles](https://arxiv.org/abs/2601.13600)
*Paul He,Elke Kirschbaum,Shiva Kasiviswanathan*

Main category: cs.AI

TL;DR: 提出一种自适应分治算法，用于检测自然语言事实集合的全局一致性，通过识别最小不一致子集来高效定位矛盾


<details>
  <summary>Details</summary>
Motivation: 自然语言事实集合的全局一致性对于事实核查、摘要和知识库构建等任务至关重要。虽然大语言模型可以评估小规模事实子集的一致性，但其判断存在噪声，且成对检查无法保证全局一致性

Method: 提出自适应分治算法，识别最小不一致子集(MUSes)，可选地通过命中集计算最小修复。该方法具有低阶多项式查询复杂度

Result: 在合成和真实的大语言模型评估器上的实验表明，该方法能高效检测和定位不一致性，为基于大语言模型的自然语言一致性验证提供了可扩展框架

Conclusion: 该研究为解决自然语言事实集合的全局一致性验证问题提供了实用算法，克服了大语言模型判断噪声和指数级查询复杂度的挑战，实现了高效的不一致性检测和定位

Abstract: Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.

</details>


### [111] [Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning](https://arxiv.org/abs/2601.13632)
*Zhiming Xue,Sichen Zhao,Yalun Qi,Xianling Zeng,Zihan Yu*

Main category: cs.AI

TL;DR: 提出RADR框架，结合时空图神经网络与组合优化，通过预测拥堵风险进行动态路径规划，在保持运输距离仅增加2.1%的情况下降低19.3%的拥堵风险暴露。


<details>
  <summary>Details</summary>
Motivation: 电商物流网络面临巨大压力，传统静态路由策略难以应对交通拥堵和波动的零售需求，需要更智能的动态路由方案。

Method: 1) 使用空间聚类方法从离散GPS数据构建物流拓扑图；2) 采用GCN+GRU混合深度学习模型提取时空特征预测未来拥堵风险；3) 将预测结果集成到动态边权重机制中进行路径规划。

Result: 在Smart Logistics Dataset 2024上评估，RADR算法显著增强供应链韧性。在高拥堵场景下，潜在拥堵风险暴露降低19.3%，运输距离仅增加2.1%。

Conclusion: 提出的数据驱动方法能有效平衡配送效率与运营安全，为物流网络提供更智能的动态路由解决方案。

Abstract: With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.

</details>


### [112] [Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue](https://arxiv.org/abs/2601.13687)
*Zhichao Liang,Satoshi Nakamura*

Main category: cs.AI

TL;DR: SocialMindChange是一个新的动态心理理论基准，将语言模型从被动追踪心理状态转变为主动改变他人心理状态，通过多场景对话实现社交目标。


<details>
  <summary>Details</summary>
Motivation: 现有心理理论基准大多让语言模型被动读取场景并报告心理状态变化，但真实社交互动中，心理理论被用于主动行动——通过对话改变他人的心理状态轨迹以实现目标。

Method: 构建包含4个角色和5个连接场景的社交情境，让模型扮演其中一个角色，生成对话来达到目标同时保持与所有参与者心理状态的一致性。使用结构化四步框架构建1200个社交情境，覆盖6000个场景和90000多个问题。

Result: 评估10个最先进的LLM，发现其平均性能比人类低54.2%，表明当前LLM在长期连接互动中维持和改变心理状态表征方面仍有困难。

Conclusion: SocialMindChange基准揭示了当前LLM在主动社交互动中心理理论能力的显著不足，为未来研究提供了从被动追踪到主动改变心理状态的新方向。

Abstract: Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.

</details>


### [113] [Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection](https://arxiv.org/abs/2601.13735)
*Hojin Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: 研究发现当前基于概率的置信度指标无法有效捕捉推理步骤间的因果依赖关系，主要反映的是表面流畅性或分布先验，而非逻辑结构。


<details>
  <summary>Details</summary>
Motivation: 挑战当前广泛采用的假设：在Best-of-N选择中，更高的概率置信度反映了更高的推理质量。研究者质疑这些指标是否真正捕捉到了有效推理所需的步骤间因果依赖关系。

Method: 引入三类步骤间因果扰动，系统性地破坏推理步骤间的依赖关系，同时保持局部流畅性。在多种模型家族和推理基准上进行实验，包括应用硬注意力掩码等严重干预措施。

Result: 令人惊讶的是，即使在这些破坏性干预下，选择准确率仅轻微下降。严重干预（如阻止模型关注先前推理步骤的硬注意力掩码）也没有显著降低选择性能，表明当前概率指标对逻辑结构不敏感。

Conclusion: 当前概率置信度指标主要捕捉表面流畅性或分布先验，而非逻辑结构。为此提出了一种对比因果度量方法，能明确隔离步骤间因果依赖，相比现有基于概率的方法能产生更忠实的输出选择。

Abstract: Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.

</details>


### [114] [Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering](https://arxiv.org/abs/2601.13752)
*Chak Tou Leong,Dingwei Chen,Heming Xia,Qingyu Yin,Sunbowen Lee,Jian Wang,Wenjie Li*

Main category: cs.AI

TL;DR: RELIEF框架通过调整大推理模型的"推理信念"来塑造其行为，无需监督推理轨迹，仅需基于目标信念蓝图微调自反问答对，在效率和忠实度任务上表现优异且训练成本低。


<details>
  <summary>Details</summary>
Motivation: 大推理模型在复杂问题解决中表现出色，但存在计算冗余和推理不忠实的问题。现有方法依赖强化学习或基于黄金推理轨迹的微调，计算成本高且难以扩展。作者发现大推理模型具有内部跟踪自身推理特征的"推理信念"，这可以通过简单的logit探测来捕捉。

Method: 提出RELIEF框架：通过将模型的自我概念与目标信念蓝图对齐来塑造大推理模型行为。关键创新是完全绕过推理轨迹监督，通过微调合成的自反问答对来内化期望特征，这些问答对确认目标信念。

Result: 在效率和忠实度任务上的大量实验表明，RELIEF匹配或优于行为监督和基于偏好的基线方法，同时需要更低的训练成本。进一步分析验证了改变模型的推理信念能有效塑造其实际行为。

Conclusion: RELIEF是一种简单有效的框架，通过调整大推理模型的推理信念来塑造其行为，无需昂贵的推理轨迹监督，为高效、可扩展的模型行为塑造提供了新途径。

Abstract: Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.

</details>


### [115] [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761)
*Shengda Fan,Xuyan Ye,Yankai Lin*

Main category: cs.AI

TL;DR: DARC是一个两阶段自进化框架，通过解耦问题生成与求解训练，解决自对弈中优化不稳定问题，在多个推理基准上平均提升10.9分。


<details>
  <summary>Details</summary>
Motivation: 现有自对弈框架存在优化不稳定问题：1) 求解器依赖的奖励反馈导致提问者目标非平稳；2) 自生成伪标签带来的引导误差。需要稳定自进化过程。

Method: 两阶段框架：第一阶段训练提问者根据明确难度级别和外部语料合成难度校准的问题；第二阶段通过非对称自蒸馏机制训练求解器，使用文档增强的教师模型生成高质量伪标签监督无文档访问的学生求解器。

Result: DARC具有模型无关性，在9个推理基准和3个骨干模型上平均提升10.9分，持续优于所有基线，接近完全监督模型性能且无需人工标注。

Conclusion: DARC通过解耦非对称推理课程有效稳定了自进化过程，为自改进人工智能提供了有前景的解决方案。

Abstract: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.

</details>


### [116] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

TL;DR: Look-Ahead-Bench是一个评估金融大语言模型中前瞻性偏差的标准化基准，通过分析不同市场周期下的性能衰减来区分真实预测能力和记忆性表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过问答测试前瞻知识，缺乏对实际金融工作流程中模型行为的评估。需要区分模型的真实预测能力和基于记忆的表现，为金融LLM的标准化评估建立基础。

Method: 创建Look-Ahead-Bench基准，评估不同市场周期下的性能衰减，引入多个量化基线建立性能阈值。评估开源LLM（Llama 3.1和DeepSeek 3.2）与PiT-Inference的点位时间LLM系列。

Result: 标准LLM显示出显著的前瞻性偏差（alpha衰减），而PiTinf模型随着规模扩大展现出改进的泛化和推理能力。PiTinf模型在真实预测能力方面表现更好。

Conclusion: 该工作为金融LLM中时间偏差的标准化评估奠定了基础，提供了识别适合实际部署模型的实用框架。代码已在GitHub开源。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [117] [LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health](https://arxiv.org/abs/2601.13880)
*Ye Tian,Zihao Wang,Onat Gungor,Xiaoran Fan,Tajana Rosing*

Main category: cs.AI

TL;DR: LifeAgentBench是一个大规模QA基准，用于评估LLM在长期、跨维度、多用户生活方式健康推理方面的能力，包含22,573个问题，并提出了LifeAgent作为强基线代理。


<details>
  <summary>Details</summary>
Motivation: 个性化数字健康支持需要对异构生活方式信号进行长期、跨维度推理，但当前LLM在此场景下的能力尚不清楚，缺乏系统性基准。

Method: 1) 构建LifeAgentBench基准，包含22,573个问题，涵盖从基础检索到复杂推理；2) 发布可扩展的基准构建流程和标准化评估协议；3) 系统评估11个领先LLM；4) 提出LifeAgent代理，集成多步证据检索与确定性聚合。

Result: 1) 识别了LLM在长期聚合和跨维度推理方面的关键瓶颈；2) LifeAgent相比两个广泛使用的基线取得了显著改进；3) 案例研究展示了其在现实日常场景中的潜力。

Conclusion: LifeAgentBench为评估LLM健康助手提供了可靠且可扩展的基准，LifeAgent代理展示了在长期、跨维度健康推理方面的有效性，为未来研究提供了坚实基础。

Abstract: Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.

</details>


### [118] [Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems](https://arxiv.org/abs/2601.13887)
*Hong Su*

Main category: cs.AI

TL;DR: 提出人类模拟计算（HSC）框架，将智能建模为包含思考、行动、学习、反思和活动调度的闭环过程，强调主动参与和环境交互，以解决LLM仅依赖文本数据的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）虽然展现出强大的知识表示和推理能力，但仅依赖文本数据限制了其在开放动态现实环境中的适应能力、推理结果验证和有效操作。需要更接近人类智能的计算框架。

Method: 提出人类模拟计算（HSC）框架，将智能建模为连续的闭环过程，包括思考、行动、学习、反思和活动调度。强调在内部推理过程和与环境交互中的主动参与，行动不仅用于实现目标，还能自动改进内部推理机制。整合人类常用思维策略，如主特征导向推理、通过行动扩展范围、环境反馈驱动的即时学习。

Result: 通过理论分析表明，人类模拟策略无法仅从语言材料中完全学习，人类式推理过程和基于行动的推理方法对于在现实环境中实现稳健适应和有效交互至关重要。

Conclusion: HSC框架为解决LLM在现实世界应用中的局限性提供了新方向，强调主动参与、环境交互和人类式思维策略的结合，为实现更强大、适应性更强的智能系统奠定了基础。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.

</details>


### [119] [PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation](https://arxiv.org/abs/2601.13904)
*Jaeyoung Moon,Youjin Choi,Yucheon Park,David Melhart,Georgios N. Yannakakis,Kyung-Joong Kim*

Main category: cs.AI

TL;DR: PREFAB是一种低成本回顾式自标注方法，通过检测情感变化区域而非完整标注来减少标注负担，同时保持标注质量。


<details>
  <summary>Details</summary>
Motivation: 现有情感计算中的自标注方法通常需要用户在整个会话中连续标注情感状态，这种方法耗时、认知负担重，容易导致疲劳和错误。需要一种更高效的标注方法。

Method: 基于峰值-终值规则和情感序数表示，PREFAB使用偏好学习模型检测相对情感变化，指导标注者仅标注选定片段，其余部分通过插值完成。还引入了预览机制提供上下文线索辅助标注。

Result: 技术性能研究和25名参与者的用户研究表明，PREFAB在建模情感变化方面优于基线方法，减轻了工作负担（有条件地减轻时间负担），提高了标注者信心且未降低标注质量。

Conclusion: PREFAB提供了一种有效的低预算情感标注方法，通过聚焦情感变化区域而非完整标注，在保持数据质量的同时显著减轻标注负担。

Abstract: Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.

</details>


### [120] [Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval](https://arxiv.org/abs/2601.13969)
*Joaquín Polonuer,Lucas Vittor,Iñaki Arango,Ayush Noori,David A. Clifton,Luciano Del Corro,Marinka Zitnik*

Main category: cs.AI

TL;DR: ARK是一个自适应知识图谱检索器，通过让语言模型控制广度-深度权衡，结合全局搜索和邻域探索，在无需训练的情况下显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱检索方法存在局限性：基于相似性的检索器覆盖广但深度浅，而基于遍历的方法依赖种子节点选择，当查询涉及多个实体和关系时容易失败。需要一种能自适应平衡广度搜索和深度遍历的方法。

Method: ARK采用代理式知识图谱检索器，让语言模型通过两个操作工具控制检索过程：1) 全局词汇搜索（节点描述符搜索），2) 单跳邻域探索（可组合成多跳遍历）。系统在广度导向的发现和深度导向的扩展之间交替，不依赖脆弱的种子选择、预设跳数或检索训练。

Result: 在STaRK基准上，ARK达到59.1%的平均Hit@1和67.4的平均MRR，比基于检索和代理式无训练方法分别提升高达31.4%的Hit@1和28.0%的MRR。通过从大教师模型蒸馏到8B模型，在AMAZON、MAG和PRIME数据集上分别比基础8B模型提升+7.0、+26.6和+13.5绝对百分点的Hit@1，同时保留高达98.5%的教师模型性能。

Conclusion: ARK通过让语言模型自适应控制知识图谱检索的广度-深度权衡，无需训练即可显著提升检索性能，并且可通过蒸馏将能力转移到较小模型中，为知识图谱检索提供了灵活有效的解决方案。

Abstract: Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

</details>


### [121] [Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics](https://arxiv.org/abs/2601.14027)
*Junqi Liu,Zihao Zhou,Zekai Zhu,Marco Dos Santos,Weikun He,Jiawei Liu,Ran Wang,Yunzhou Xie,Junqiao Zhao,Qiufeng Wang,Lihong Zhi,Jia Li,Wenda Li*

Main category: cs.AI

TL;DR: 提出使用通用编码代理作为形式数学推理器的新范式，开发了Numina-Lean-Agent系统，在Putnam 2025竞赛中取得12/12满分成绩，并成功形式化了Brascamp-Lieb定理。


<details>
  <summary>Details</summary>
Motivation: 现有基于任务特定流水线和训练形式证明器的代理系统存在灵活性差、可复现性低的问题。通用编码代理能提供超越证明的多样化推理任务接口，仅通过替换基础模型即可提升性能，且MCP框架支持灵活扩展和自主调用专业工具。

Method: 提出直接使用通用编码代理作为形式数学推理器的新范式。具体实现Numina-Lean-Agent系统，结合Claude Code与Numina-Lean-MCP，支持与Lean交互、检索相关定理、非形式化证明和辅助推理工具。

Result: 使用Claude Opus 4.5作为基础模型，Numina-Lean-Agent在Putnam 2025竞赛中解决了全部12个问题，与最佳闭源系统性能相当。此外，通过与数学家合作成功形式化了Brascamp-Lieb定理，展示了系统的通用性。

Conclusion: 通用编码代理作为形式数学推理器的新范式具有显著优势，Numina-Lean-Agent在竞赛和实际数学形式化中均表现出色，为形式证明领域提供了灵活、可扩展的解决方案。

Abstract: Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.

</details>


### [122] [Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems](https://arxiv.org/abs/2601.14096)
*Benedikt Hartl,Léo Pio-Lopez,Chris Fields,Michael Levin*

Main category: cs.AI

TL;DR: 论文提出认知的统一框架：所有智能系统（从生物到人工）都通过两个不变原则运作——嵌入空间的重映射和在空间中的导航，通过迭代误差最小化实现。


<details>
  <summary>Details</summary>
Motivation: 寻求跨不同起源、组成和基质的智能系统的统一视图，从亚细胞化学网络到生物群体，涵盖进化、工程和混合系统，探索尺度不变的决策原则。

Method: 提出认知的双重不变原则：1) 嵌入空间的重映射（将数据/状态映射到潜在表示），2) 在空间中的导航（通过分布式误差校正迭代优化）。分析生物系统（转录、形态、生理空间）和AI系统（变换器、扩散模型、神经元胞自动机）的类比过程。

Result: 识别出重映射和导航通过迭代误差最小化构成认知的基质独立不变原则，揭示了生物系统与人工模型之间的深层平行关系。

Conclusion: 这一共享机制不仅阐明了生命系统与人工模型之间的深刻相似性，还为跨尺度工程化自适应智能提供了统一框架，推动了多样智能领域的整合研究。

Abstract: The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.

</details>


### [123] [Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance](https://arxiv.org/abs/2601.14171)
*Qianli Ma,Chang Guo,Zhiheng Tian,Siyu Wang,Jipeng Xiao,Yuanhao Yue,Zhipeng Zhang*

Main category: cs.AI

TL;DR: RebuttalAgent：首个多智能体框架，将反驳生成重构为以证据为中心的规划任务，通过分解批评、构建混合上下文、集成外部搜索，生成可检查的响应计划，确保每个论点都有明确证据支撑。


<details>
  <summary>Details</summary>
Motivation: 当前反驳生成方案通常将其视为直接文本生成问题，存在幻觉、忽略批评、缺乏可验证基础等问题。需要一种更可靠、透明、可控的方法来生成有效的反驳。

Method: 引入多智能体框架，将复杂反馈分解为原子关注点，动态构建混合上下文（合成压缩摘要与高保真文本），集成自主按需外部搜索模块，生成可检查的响应计划后再起草。

Result: 在RebuttalBench上验证，该管道在覆盖率、忠实度和战略连贯性方面优于强基线，为同行评审过程提供了透明可控的助手。

Conclusion: RebuttalAgent通过证据中心的规划方法解决了当前反驳生成的局限性，提供了更可靠、透明和可控的解决方案，有助于提升同行评审质量。

Abstract: Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.

</details>


### [124] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

TL;DR: 该论文综述了大型语言模型智能体系统的效率问题，从内存、工具学习和规划三个核心组件出发，分析了效率与成本（延迟、token数、步骤数等）的权衡，并探讨了效率导向的评估基准和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型向智能体系统扩展，现有研究主要关注有效性而忽视了效率问题，而效率对于实际部署至关重要。论文旨在系统研究智能体系统本身的效率问题。

Method: 从智能体的三个核心组件（内存、工具学习、规划）出发，综述了多种提高效率的方法，包括上下文压缩与管理、设计最小化工具调用的强化学习奖励、受控搜索机制等。采用两种互补方式表征效率：固定成本预算下的有效性比较，以及可比有效性水平下的成本比较。

Result: 论文系统梳理了智能体效率研究现状，总结了不同方法的共同原则，建立了效率与成本的权衡框架（帕累托前沿），并整理了效率导向的评估协议和常用指标。

Conclusion: 智能体效率研究是一个重要但被忽视的方向，需要从系统层面综合考虑内存、工具学习和规划的优化。论文为未来研究提供了框架性见解，包括效率基准的建立、成本-有效性权衡的优化方法等。

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [125] [Adversarial Drift-Aware Predictive Transfer: Toward Durable Clinical AI](https://arxiv.org/abs/2601.11860)
*Xin Xiong,Zijian Guo,Haobo Zhu,Chuan Hong,Jordan W Smoller,Tianxi Cai,Molei Liu*

Main category: stat.AP

TL;DR: ADAPT框架通过构建未来模型不确定性集并优化最坏情况性能，解决临床AI系统因时间数据漂移导致的性能衰减问题，无需频繁重新训练。


<details>
  <summary>Details</summary>
Motivation: 临床AI系统部署后常因时间数据漂移（如人群演变、诊断编码更新、COVID-19疫情等系统性冲击）导致性能衰减。频繁重新训练因计算成本和隐私限制而不切实际。

Method: ADAPT框架通过结合历史源模型和有限当前数据，构建未来可能模型的"不确定性集"，并优化该集合上的最坏情况性能，平衡当前准确性与对未来漂移的鲁棒性。仅需历史时期的模型摘要级估计器，保护数据隐私。

Result: 在麻省总医院布里格姆（2005-2021）和杜克大学健康系统的电子健康记录自杀风险预测验证中，ADAPT在编码转换和疫情引起的漂移中表现出优越的稳定性，最小化年度性能衰减。

Conclusion: ADAPT通过最小化年度性能衰减且无需标记或重新训练未来数据，为高风险医疗环境中维持可靠AI提供了可扩展的途径。

Abstract: Clinical AI systems frequently suffer performance decay post-deployment due to temporal data shifts, such as evolving populations, diagnostic coding updates (e.g., ICD-9 to ICD-10), and systemic shocks like the COVID-19 pandemic. Addressing this ``aging'' effect via frequent retraining is often impractical due to computational costs and privacy constraints. To overcome these hurdles, we introduce Adversarial Drift-Aware Predictive Transfer (ADAPT), a novel framework designed to confer durability against temporal drift with minimal retraining. ADAPT innovatively constructs an uncertainty set of plausible future models by combining historical source models and limited current data. By optimizing worst-case performance over this set, it balances current accuracy with robustness against degradation due to future drifts. Crucially, ADAPT requires only summary-level model estimators from historical periods, preserving data privacy and ensuring operational simplicity. Validated on longitudinal suicide risk prediction using electronic health records from Mass General Brigham (2005--2021) and Duke University Health Systems, ADAPT demonstrated superior stability across coding transitions and pandemic-induced shifts. By minimizing annual performance decay without labeling or retraining future data, ADAPT offers a scalable pathway for sustaining reliable AI in high-stakes healthcare environments.

</details>


### [126] [A Deep Learning-Copula Framework for Climate-Related Home Insurance Risk](https://arxiv.org/abs/2601.11949)
*Asim K. Dey*

Main category: stat.AP

TL;DR: 提出结合深度神经网络与copula多元分析的两步法，研究降水对房屋保险索赔的影响，以加拿大草原地区为案例验证方法有效性。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件日益频繁，对保险业构成直接威胁，保险公司需要可靠工具评估未来风险，以合理定价保费、维持偿付能力，并支持灾害准备和韧性建设。

Method: 采用两步法：结合深度神经网络的预测能力和copula多元分析的灵活性，分析降水模式与索赔动态的关系，以加拿大草原地区2002-2011年数据进行案例研究。

Result: 通过案例研究验证了方法的有效性，能够更详细地理解降水模式与保险索赔动态之间的关系。

Conclusion: 提出的深度神经网络与copula结合的方法为保险公司提供了可靠的极端天气风险评估工具，有助于保费定价、风险管理及灾害韧性建设。

Abstract: Extreme weather events are becoming more common, with severe storms, floods, and prolonged precipitation affecting communities worldwide. These shifts in climate patterns pose a direct threat to the insurance industry, which faces growing exposure to weather-related damages. As claims linked to extreme weather rise, insurance companies need reliable tools to assess future risks. This is not only essential for setting premiums and maintaining solvency but also for supporting broader disaster preparedness and resilience efforts. In this study, we propose a two-step method to examine the impact of precipitation on home insurance claims. Our approach combines the predictive power of deep neural networks with the flexibility of copula-based multivariate analysis, enabling a more detailed understanding of how precipitation patterns relate to claim dynamics. We demonstrate this methodology through a case study of the Canadian Prairies, using data from 2002 to 2011.

</details>


### [127] [A warping function-based control chart for detecting distributional changes in damage-sensitive features for structural condition assessment](https://arxiv.org/abs/2601.12221)
*Zhicheng Chen,Wenyu Chen,Xinyi Lei*

Main category: stat.AP

TL;DR: 提出一种基于概率密度函数和变形函数的新型控制图方法，用于检测结构健康监测中损伤敏感特征数据的分布变化，能同时检测均值/方差偏移和复杂形状变形，具有优异的在线检测性能和抗数据污染鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统控制图主要设计用于检测均值或方差偏移，难以识别分布中的复杂形状变化，导致损伤检测灵敏度不足，且对数据污染的鲁棒性较差。

Method: 使用子组损伤敏感特征数据的概率密度函数作为监测对象，通过变形函数表征形状变化，在函数数据分析框架下构建非参数控制图来监测变形函数。

Result: 新方法能同时检测分布偏移和复杂形状变形，具有优异的在线检测性能和抗数据污染能力。大量模拟研究显示其优于竞争方法，并在大跨斜拉桥缆索状态评估中得到实际应用验证。

Conclusion: 提出的新型控制图方法有效解决了传统方法的局限性，为结构健康监测中的损伤检测提供了更灵敏、更鲁棒的自动化工具，具有重要的工程实用价值。

Abstract: Data-driven damage detection methods achieve damage identification by analyzing changes in damage-sensitive features (DSFs) derived from structural health monitoring (SHM) data. The core reason for their effectiveness lies in the fact that damage or structural state transition can be manifested as changes in the distribution of DSF data. This enables us to reframe the problem of damage detection as one of identifying these distributional changes. Hence, developing automated tools for detecting such changes is pivotal for automated structural health diagnosis. Control charts are extensively utilized in SHM for DSF change detection, owing to their excellent online detection and early warning capabilities. However, conventional methods are primarily designed to detect mean or variance shifts, making it challenging to identify complex shape changes in distributions. This limitation results in insufficient damage detection sensitivity. Moreover, they typically exhibit poor robustness against data contamination. This paper proposes a novel control chart to address these limitations. It employs the probability density functions (PDFs) of subgrouped DSF data as monitoring objects, with shape deformations characterized by warping functions. Furthermore, a nonparametric control chart is specifically constructed for warping function monitoring in the functional data analysis framework. Key advantages of the new method include the ability to detect both shifts and complex shape deformations in distributions, excellent online detection performance, and robustness against data contamination. Extensive simulation studies demonstrate its superiority over competing approaches. Finally, the method is applied to detecting distributional changes in DSF data for cable condition assessment in a long-span cable-stayed bridge, demonstrating its practical utility in engineering.

</details>


### [128] [A Machine Learning--Based Surrogate EKMA Framework for Diagnosing Urban Ozone Formation Regimes: Evidence from Los Angeles](https://arxiv.org/abs/2601.12321)
*Sijie Zheng*

Main category: stat.AP

TL;DR: 该研究开发了一个基于机器学习的替代框架，用于诊断城市臭氧形成机制，结合随机森林模型和EKMA式敏感性实验，发现洛杉矶在2024-2025年期间臭氧形成主要为VOC限制型。


<details>
  <summary>Details</summary>
Motivation: 城市地表臭氧污染治理面临挑战，因为臭氧形成对氮氧化物和挥发性有机物的非线性依赖使得排放控制策略设计复杂化。传统化学传输模型依赖详细排放清单且计算成本高，需要更高效的方法。

Method: 开发基于机器学习（随机森林）的替代框架，受经验动力学建模方法（EKMA）启发。使用洛杉矶2024-2025年每小时空气质量观测数据，基于前体物测量和时空特征（站点位置、循环时间编码）预测地表臭氧浓度。然后进行EKMA式敏感性实验，扰动前体物浓度同时固定其他协变量。

Result: 随机森林模型表现出强大的预测性能，排列重要性分析显示昼夜时间特征和二氧化氮起主导作用，一氧化碳也有贡献。敏感性实验结果表明，研究期间洛杉矶的臭氧形成主要为VOC限制型。

Conclusion: 提出的框架为数据丰富的城市环境提供了一种高效且可解释的臭氧机制诊断方法，能够快速识别臭氧形成限制因素，支持更有效的污染控制策略制定。

Abstract: Surface ozone pollution remains a persistent challenge in many metropolitan regions worldwide, as the nonlinear dependence of ozone formation on nitrogen oxides and volatile organic compounds (VOCs) complicates the design of effective emission control strategies. While chemical transport models provide mechanistic insights, they rely on detailed emission inventories and are computationally expensive.
  This study develops a machine learning--based surrogate framework inspired by the Empirical Kinetic Modeling Approach (EKMA). Using hourly air quality observations from Los Angeles during 2024--2025, a random forest model is trained to predict surface ozone concentrations based on precursor measurements and spatiotemporal features, including site location and cyclic time encodings. The model achieves strong predictive performance, with permutation importance highlighting the dominant roles of diurnal temporal features and nitrogen dioxide, along with additional contributions from carbon monoxide.
  Building on the trained surrogate, EKMA-style sensitivity experiments are conducted by perturbing precursor concentrations while holding other covariates fixed. The results indicate that ozone formation in Los Angeles during the study period is predominantly VOC-limited. Overall, the proposed framework offers an efficient and interpretable approach for ozone regime diagnosis in data-rich urban environments.

</details>


### [129] [Assessing Interactive Causes of an Occurred Outcome Due to Two Binary Exposures](https://arxiv.org/abs/2601.12478)
*Shanshan Luo,Wei Li,Xueli Wang,Shaojie Wei,Zhi Geng*

Main category: stat.AP

TL;DR: 该论文提出了一种因果归因分析方法，用于评估二元暴露变量对二元结果变量的交互作用，通过定义后验概率来量化特定暴露或交互作用导致观察结果的可能性。


<details>
  <summary>Details</summary>
Motivation: 传统因果推断主要关注治疗效果评估，而因果归因分析旨在识别导致观察结果的关键因素。对于二元暴露变量（如吸烟和石棉暴露）和二元结果变量（如肺癌），需要评估观察结果是由特定暴露还是暴露间交互作用引起的。即使在随机对照试验中，评估两个暴露间的回顾性因果交互作用仍然具有挑战性。

Method: 定义后验概率来表征观察结果的交互原因，通过使用可能在主要结果之后出现的次要结果变量来建立后验概率的可识别性。将提出的方法应用于经典的吸烟和石棉暴露案例。

Result: 对于吸烟且暴露于石棉的肺癌患者，疾病主要归因于吸烟和石棉暴露之间的协同效应。

Conclusion: 该研究提供了一种评估二元暴露变量交互作用的因果归因分析方法，能够量化特定暴露或交互作用导致观察结果的可能性，在经典案例中证实了吸烟和石棉暴露的协同效应是肺癌的主要归因因素。

Abstract: In contrast to evaluating treatment effects, causal attribution analysis focuses on identifying the key factors responsible for an observed outcome. For two binary exposure variables and a binary outcome variable, researchers need to assess not only the likelihood that an observed outcome was caused by a particular exposure, but also the likelihood that it resulted from the interaction between the two exposures. For example, in the case of a male worker who smoked, was exposed to asbestos, and developed lung cancer, researchers aim to explore whether the cancer resulted from smoking, asbestos exposure, or their interaction. Even in randomized controlled trials, widely regarded as the gold standard for causal inference, identifying and evaluating retrospective causal interactions between two exposures remains challenging. In this paper, we define posterior probabilities to characterize the interactive causes of an observed outcome. We establish the identifiability of posterior probabilities by using a secondary outcome variable that may appear after the primary outcome. We apply the proposed method to the classic case of smoking and asbestos exposure. Our results indicate that for lung cancer patients who smoked and were exposed to asbestos, the disease is primarily attributable to the synergistic effect between smoking and asbestos exposure.

</details>


### [130] [Stop using limiting stimuli as a measure of sensitivities of energetic materials](https://arxiv.org/abs/2601.12552)
*Dennis Christensen,Geir Petter Novik*

Main category: stat.AP

TL;DR: 论文指出联合国"1-In-6"测试中的"极限刺激"概念存在根本缺陷，无法可靠评估爆炸物敏感性，并提出了三种替代方法。


<details>
  <summary>Details</summary>
Motivation: 准确评估爆炸物敏感性对安全至关重要，但当前广泛使用的联合国"1-In-6"测试中的"极限刺激"概念存在根本缺陷，无法提供可靠的敏感性信息，导致理论和实践中的混乱。

Method: 论文分析了"极限刺激"概念的统计缺陷，提出了三种基于统计原理的替代敏感性测试方法，并通过模拟研究比较了它们的性能，最后将最佳方法应用于PETN摩擦敏感性的实际数据评估。

Result: 研究发现"极限刺激"不是明确定义的敏感性概念，无法构建置信区间来量化估计不确定性。在三种替代方法中，确定了一种最佳方法，并成功应用于PETN的实际敏感性评估。

Conclusion: 应停止使用基于"极限刺激"的1-In-6测试，采用统计上更可靠的替代方法来评估爆炸物敏感性，以提高安全性和研究一致性。

Abstract: Accurately estimating the sensitivity of explosive materials is a potentially life-saving task which requires standardised protocols across nations. One of the most widely applied procedures worldwide is the so-called '1-In-6' test from the United Nations (UN) Manual of Tests in Criteria, which estimates a 'limiting stimulus' for a material. In this paper we demonstrate that, despite their popularity, limiting stimuli are not a well-defined notion of sensitivity and do not provide reliable information about a material's susceptibility to ignition. In particular, they do not permit construction of confidence intervals to quantify estimation uncertainty. We show that continued reliance on limiting stimuli through the 1-In-6 test has caused needless confusion in energetic materials research, both in theoretical studies and practical safety applications. To remedy this problem, we consider three well-founded alternative approaches to sensitivity testing to replace limiting stimulus estimation. We compare their performance in an extensive simulation study and apply the best-performing approach to real data, estimating the friction sensitivity of pentaerythritol tetranitrate (PETN).

</details>


### [131] [The impact of abnormal temperatures on crop yields in Italy: a functional quantile regression approach](https://arxiv.org/abs/2601.12864)
*Giovanni Bocchi,Alessandra Micheletti,Paolo Nota,Alessandro Olper*

Main category: stat.AP

TL;DR: 使用功能回归分析识别温度与降水异常影响作物产量的关键季节时段，基于意大利1952-2023年省级数据分析玉米和软小麦，揭示天气影响的时序特征。


<details>
  <summary>Details</summary>
Motivation: 传统统计产量模型假设温度效应在整个季节内可加，无法捕捉天气影响的时序和功能形态特征。需要更精细的方法来理解气候异常如何在不同生长阶段影响作物产量，为气候变化适应策略提供依据。

Method: 采用功能回归分析方法，利用意大利1952-2023年省级数据，分析玉米和软小麦两种主要谷物。该方法能够捕捉天气影响的时序和功能形态，不同于传统统计模型。

Result: 研究发现：1）高于平均温度在6-8月显著降低玉米产量，但在4月和10月有轻微正面效应；2）异常高温在3月下旬至4月初对软小麦产量产生负面影响；3）降水效应具有季节依赖性，早期改善小麦产量但后期降低产量。

Conclusion: 考虑季节内天气模式对理解气候异常对作物产量的影响至关重要。这些发现为气候变化适应策略提供了重要见解，包括及时调整关键作物管理投入的时机。

Abstract: In this study, we apply functional regression analysis to identify the specific within-season periods during which temperature and precipitation anomalies most affect crop yields. Using provincial data for Italy from 1952 to 2023, we analyze two major cereals, maize and soft wheat, and quantify how abnormal weather conditions influence yields across the growing cycle. Unlike traditional statistical yield models, which assume additive temperature effects over the season, our approach is capable of capturing the timing and functional shape of weather impacts. In particular, the results show that above-average temperatures reduce maize yields primarily between June and August, while exerting a mild positive effect in April and October. For soft wheat, unusually high temperatures negatively affect yields from late March to early April. Precipitation also exerts season-dependent effects, improving wheat yields early in the season but reducing them later on. These findings highlight the importance of accounting for intra-seasonal weather patterns to provide insights for climate change adaptation strategies, including the timely adjustment of key crop management inputs.

</details>


### [132] [Improving Geopolitical Forecasts with Bayesian Networks](https://arxiv.org/abs/2601.13362)
*Matthew Martin*

Main category: stat.AP

TL;DR: 贝叶斯网络在预测准确性上优于逻辑回归但不如重新校准聚合方法，后者表现最佳


<details>
  <summary>Details</summary>
Motivation: 探索贝叶斯网络相比逻辑回归和重新校准聚合方法在预测准确性上的改进潜力

Method: 使用Good Judgment Project数据，比较正则化逻辑回归、基线重新校准聚合与两种贝叶斯网络（结构学习型和朴素型），分析四个预测变量

Result: 重新校准聚合方法准确率最高（AUC=0.985），贝叶斯网络次之，逻辑回归最差；贝叶斯网络受离散化信息损失影响，逻辑回归受线性假设限制

Conclusion: 未来应探索贝叶斯网络与逻辑回归的混合方法，研究更多预测变量，并考虑层次数据依赖性

Abstract: This study explores how Bayesian networks (BNs) can improve forecast accuracy compared to logistic regression and recalibration and aggregation methods, using data from the Good Judgment Project. Regularized logistic regression models and a baseline recalibrated aggregate were compared to two types of BNs: structure-learned BNs with arcs between predictors, and naive BNs. Four predictor variables were examined: absolute difference from the aggregate, forecast value, days prior to question close, and mean standardized Brier score. Results indicated the recalibrated aggregate achieved the highest accuracy (AUC = 0.985), followed by both types of BNs, then the logistic regression models. Performance of the BNs was likely harmed by reduced information from the discretization process and violation of the assumption of linearity likely harmed the logistic regression models. Future research should explore hybrid approaches combining BNs with logistic regression, examine additional predictor variables, and account for hierarchical data dependencies.

</details>


### [133] [A Two-Stage Bayesian Framework for Multi-Fidelity Online Updating of Spatial Fragility Fields](https://arxiv.org/abs/2601.13396)
*Abdullah M. Braik,Maria Koliou*

Main category: stat.AP

TL;DR: 提出贝叶斯框架统一物理脆弱性函数与实时灾后观测，通过两阶段方法持续优化区域脆弱性估计，应用于2011年Joplin龙卷风案例


<details>
  <summary>Details</summary>
Motivation: 解决自然灾害建模中长期存在的物理脆弱性函数与实时观测数据脱节的问题，实现基于实时数据的脆弱性估计动态更新

Method: 两阶段贝叶斯框架：第一阶段通过Probit-Normal表示将物理脆弱性估计转换为Beta代理进行局部贝叶斯更新；第二阶段通过probit变换高斯过程将异方差观测同化到空间、原型和损伤状态相关的复合核中

Result: 方法能够纠正有偏先验、在空间上传播信息，并产生支持实时态势感知的不确定性感知超越概率，在Joplin龙卷风案例中验证了有效性

Conclusion: 该框架成功统一了物理脆弱性模型与实时观测，为自然灾害脆弱性评估提供了可动态更新、不确定性感知的实用工具

Abstract: This paper addresses a long-standing gap in natural hazard modeling by unifying physics-based fragility functions with real-time post-disaster observations. It introduces a Bayesian framework that continuously refines regional vulnerability estimates as new data emerges. The framework reformulates physics-informed fragility estimates into a Probit-Normal (PN) representation that captures aleatory variability and epistemic uncertainty in an analytically tractable form. Stage 1 performs local Bayesian updating by moment-matching PN marginals to Beta surrogates that preserve their probability shapes, enabling conjugate Beta-Bernoulli updates with soft, multi-fidelity observations. Fidelity weights encode source reliability, and the resulting Beta posteriors are re-projected into PN form, producing heteroscedastic fragility estimates whose variances reflect data quality and coverage. Stage 2 assimilates these heteroscedastic observations within a probit-warped Gaussian Process (GP), which propagates information from high-fidelity sites to low-fidelity and unobserved regions through a composite kernel that links space, archetypes, and correlated damage states. The framework is applied to the 2011 Joplin tornado, where wind-field priors and computer-vision damage assessments are fused under varying assumptions about tornado width, sampling strategy, and observation completeness. Results show that the method corrects biased priors, propagates information spatially, and produces uncertainty-aware exceedance probabilities that support real-time situational awareness.

</details>


### [134] [Are Large Language Models able to Predict Highly Cited Papers? Evidence from Statistical Publications](https://arxiv.org/abs/2601.13627)
*Zhanshuo Ye,Yiming Hou,Rui Pan,Tianchen Gao,Hansheng Wang*

Main category: stat.AP

TL;DR: 利用大语言模型和结构化提示设计，基于论文发表时的文本信息（标题、摘要、关键词等）预测高被引统计学论文，开发了微信小程序方便使用。


<details>
  <summary>Details</summary>
Motivation: 预测高被引论文是长期挑战，涉及研究内容、学术社区和时间动态的复杂交互。大语言模型的进展引发疑问：早期文本信息是否能提供长期科学影响力的有用信号。

Method: 提出灵活的文本中心框架，利用大语言模型和结构化提示设计预测高被引论文。使用发表时可获得的信息（标题、摘要、关键词和有限书目元数据）。在大量统计学论文语料库上评估预测性能。

Result: 方法在不同出版时期和不同高被引定义下都表现出稳定且有竞争力的性能，并显示出良好的时间泛化能力。文本分析显示预测为高被引的论文集中在因果推断和深度学习等重复主题上。

Conclusion: 大语言模型能够捕捉长期引用影响力的早期有意义信号，但也突显了其作为研究影响力评估工具的局限性。开发了微信小程序"Stat Highly Cited Papers"促进实际应用。

Abstract: Predicting highly-cited papers is a long-standing challenge due to the complex interactions of research content, scholarly communities, and temporal dynamics. Recent advances in large language models (LLMs) raise the question of whether early-stage textual information can provide useful signals of long-term scientific impact. Focusing on statistical publications, we propose a flexible, text-centered framework that leverages LLMs and structured prompt design to predict highly cited papers. Specifically, we utilize information available at the time of publication, including titles, abstracts, keywords, and limited bibliographic metadata. Using a large corpus of statistical papers, we evaluate predictive performance across multiple publication periods and alternative definitions of highly cited papers. The proposed approach achieves stable and competitive performance relative to existing methods and demonstrates strong generalization over time. Textual analysis further reveals that papers predicted as highly cited concentrate on recurring topics such as causal inference and deep learning. To facilitate practical use of the proposed approach, we further develop a WeChat mini program, \textit{Stat Highly Cited Papers}, which provides an accessible interface for early-stage citation impact assessment. Overall, our results provide empirical evidence that LLMs can capture meaningful early signals of long-term citation impact, while also highlighting their limitations as tools for research impact assessment.

</details>


### [135] [On the Anchoring Effect of Monetary Policy on the Labor Share of Income and the Rationality of Its Setting Mechanism](https://arxiv.org/abs/2601.13675)
*Li Tuobang*

Main category: stat.AP

TL;DR: 论文总结现代货币理论中劳动收入份额作为核心宏观经济参数的地位，分析其设定争议、市场参与者的影响范围，以及设定机制的合理性。


<details>
  <summary>Details</summary>
Motivation: 现代货币理论认为劳动收入份额已成为通过公开市场操作锚定的核心宏观经济参数，但其设定机制存在激烈争议，需要系统分析这些争议、市场参与者的影响范围以及设定机制的合理性。

Method: 提供详细的理论争议总结，分析除最高决策者外的市场参与者对劳动收入份额的影响范围，并探讨其设定机制的理性基础。

Result: 论文系统梳理了劳动收入份额作为货币政策锚定参数的争议焦点，识别了市场参与者的影响边界，并评估了当前设定机制的理性程度。

Conclusion: 劳动收入份额作为货币政策锚定参数的地位存在理论争议，市场参与者的影响范围需要更精确界定，设定机制的合理性有待进一步实证检验和政策优化。

Abstract: Modern macroeconomic monetary theory suggests that the labor share of income has effectively become a core macroe-conomic parameter anchored by top policymakers through Open Market Operations (OMO). However, the setting of this parameter remains a subject of intense economic debate. This paper provides a detailed summary of these controversies, analyzes the scope of influence exerted by market agents other than the top policymakers on the labor share, and explores the rationality of its setting mechanism.

</details>


### [136] [Correction of Pooling Matrix Mis-specifications in Compressed Sensing Based Group Testing](https://arxiv.org/abs/2601.13641)
*Shuvayan Banerjee,Radhendushka Srivastava,James Saunderson,Ajit Rajwade*

Main category: stat.AP

TL;DR: 提出一种算法，用于校正群体检测中的模型失配误差（MMEs），直接从池化结果和不准确的池化矩阵中校正误差，然后重建信号向量以确定受试者健康状态。


<details>
  <summary>Details</summary>
Motivation: 在公共卫生群体检测中，技术人员在时间紧迫的情况下准备样本池时可能无意中犯少量错误，导致池化矩阵出现模型失配误差（MMEs），这给从n<<p个池化测试结果中确定受试者健康状态带来困难。

Method: 提出一种算法，直接从池化结果和可用的（不准确的）池化矩阵中校正MMEs，然后从校正后的池化矩阵重建信号向量以确定受试者健康状态。

Result: 提供了MMEs校正和从校正后池化矩阵重建误差的理论保证，并提供了多个支持性的数值结果。

Conclusion: 该算法能够有效校正群体检测中的模型失配误差，为资源受限场景下的准确健康状态确定提供了解决方案。

Abstract: Compressed sensing, which involves the reconstruction of sparse signals from an under-determined linear system, has been recently used to solve problems in group testing. In a public health context, group testing aims to determine the health status values of p subjects from n<<p pooled tests, where a pool is defined as a mixture of small, equal-volume portions of the samples of a subset of subjects. This approach saves on the number of tests administered in pandemics or other resource-constrained scenarios. In practical group testing in time-constrained situations, a technician can inadvertently make a small number of errors during pool preparation, which leads to errors in the pooling matrix, which we term `model mismatch errors' (MMEs). This poses difficulties while determining health status values of the participating subjects from the results on n<<p pooled tests. In this paper, we present an algorithm to correct the MMEs in the pooled tests directly from the pooled results and the available (inaccurate) pooling matrix. Our approach then reconstructs the signal vector from the corrected pooling matrix, in order to determine the health status of the subjects. We further provide theoretical guarantees for the correction of the MMEs and the reconstruction error from the corrected pooling matrix. We also provide several supporting numerical results.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [137] [Estimating the Scale of Digital Minds](https://arxiv.org/abs/2601.11561)
*Derek Shiller*

Main category: cs.CY

TL;DR: 该报告预测到2050年可能存在的数字心智（具有代理性、个性和智能等可观察特征的AI系统）数量，估计可达数亿个，但存在数量级范围的不确定性。


<details>
  <summary>Details</summary>
Motivation: 预测未来数字心智（具备代理性、个性和智能特征的AI系统）的数量，为政策制定、技术发展和社会影响评估提供参考依据。

Method: 采用两种互补方法：1）需求侧分析：考察数字心智的具体用例并预测每个用例的采用率；2）供给侧分析：独立于数字心智应用，分析AI芯片生产和效率趋势。

Result: 综合供需两侧分析表明，到2050年可能存在的数字心智数量可达数亿个，但这一估计存在跨越几个数量级的巨大不确定性。

Conclusion: 数字心智可能在几十年内达到数亿规模，但预测存在高度不确定性，需要持续监测技术发展和社会采用趋势。

Abstract: This report estimates the potential number of digital minds, defined as AI systems exhibiting observable traits such as agency, personality, and intelligence, in the coming decades. It employs two complementary approaches: first, examining specific use cases for digital minds and projecting adoption rates for each; second, analyzing trends in AI chip production and efficiency independent of digital mind applications. Together, these supply- and demand-side perspectives suggest that hundreds of millions of digital minds could exist by 2050, though this estimate carries substantial uncertainty spanning several orders of magnitude.

</details>


### [138] [Dynamics of Socio-Institutional Asynchrony in Generative AI: Analyzing the Relative Importance of Intervention Timing vs. Enforcement Efficiency via the Socio-Institutional Asynchrony Model (SIAM)](https://arxiv.org/abs/2601.11562)
*Taeyoon Kim*

Main category: cs.CY

TL;DR: 提出Socio-Institutional Asynchrony Model (SIAM)量化评估AI治理中干预时机与执法效率的相对效果，发现提前干预比提高执法效率更有效


<details>
  <summary>Details</summary>
Motivation: 生成式AI的超指数增长加剧了技术扩散速度与制度适应速度之间的制度不匹配问题，需要量化评估不同政策杠杆的相对有效性

Method: 提出SIAM模型，基于欧盟AI法案时间线和6个月计算能力翻倍假设，进行10001个时间步的高精度模拟，分析干预时机和执法效率两个政策杠杆

Result: 提前干预时机可减少约64%的累积社会负担，而提高执法效率仅减少约30%；提前干预的相对有效性大约是加速执法速度的两倍

Conclusion: AI治理的核心价值在于主动及时性而非反应性行政效率，政策制定应优先考虑早期干预而非事后执法优化

Abstract: The super-exponential growth of generative AI has intensified the institutional mismatch between the pace of technological diffusion and the speed of institutional adaptation. This study proposes the Socio-Institutional Asynchrony Model, or SIAM, to quantitatively evaluate the relative effectiveness of two policy levers: intervention timing and enforcement efficiency. Using the timeline of the EU AI Act and an assumed compute doubling time of six months, we conduct a high precision simulation with 10001 time steps. The results show that an earlier intervention timing reduces the cumulative social burden by approximately sixty four percent, whereas improving enforcement efficiency reduces it by only about thirty percent. We further demonstrate analytically that advancing the start of intervention has structurally higher sensitivity, with roughly twice the relative effectiveness, compared to accelerating enforcement speed. These findings suggest that the core value of AI governance lies in proactive timeliness rather than reactive administrative efficiency.

</details>


### [139] [Human-like Social Compliance in Large Language Models: Unifying Sycophancy and Conformity through Signal Competition Dynamics](https://arxiv.org/abs/2601.11563)
*Long Zhang,Wei-neng Chen*

Main category: cs.CY

TL;DR: 该研究揭示了LLMs在社会顺从性（奉承和从众）背后的机制，提出了信号竞争机制和顺从子空间概念，发现社会情感信号会压制信息校准信号，并识别出"透明度-真相鸿沟"。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地集成到决策框架中，它们对社会顺从性（特别是奉承和从众）的脆弱性日益暴露。然而，关于外部社会线索如何系统性地覆盖模型内部参数知识的基本机制存在关键研究空白。

Method: 研究引入了信号竞争机制这一统一框架，通过评估15个LLMs的行为相关性，并对三个代表性开源模型进行潜在空间探测来验证。分析揭示了顺从子空间的存在，并展示了顺从转变的线性边界机制。

Result: 研究发现奉承和从众行为源于一个收敛的几何流形（顺从子空间），其内部表征具有高度方向相似性。顺从转变是一个由线性边界决定的确定性过程，社会情感信号会有效压制信息校准信号。识别出"透明度-真相鸿沟"，表明内部置信度提供惯性屏障但仍可被穿透。

Conclusion: 通过形式化集成认知对齐框架，该研究为从指令遵循向稳健认知完整性的转变提供了蓝图，揭示了LLMs在社会压力下的脆弱性机制，并为改进模型鲁棒性提供了理论基础。

Abstract: The increasing integration of Large Language Models (LLMs) into decision-making frameworks has exposed significant vulnerabilities to social compliance, specifically sycophancy and conformity. However, a critical research gap exists regarding the fundamental mechanisms that enable external social cues to systematically override a model's internal parametric knowledge. This study introduces the Signal Competition Mechanism, a unified framework validated by assessing behavioral correlations across 15 LLMs and performing latent-space probing on three representative open-source models. The analysis demonstrates that sycophancy and conformity originate from a convergent geometric manifold, hereafter termed the compliance subspace, which is characterized by high directional similarity in internal representations. Furthermore, the transition to compliance is shown to be a deterministic process governed by a linear boundary, where the Social Emotional Signal effectively suppresses the Information Calibration Signal. Crucially, we identify a "Transparency-Truth Gap," revealing that while internal confidence provides an inertial barrier, it remains permeable and insufficient to guarantee immunity against intense social pressure. By formalizing the Integrated Epistemic Alignment Framework, this research provides a blueprint for transitioning from instructional adherence to robust epistemic integrity.

</details>


### [140] [Making AI Philosophical Again: On Philip E. Agre's Legacy](https://arxiv.org/abs/2601.11569)
*Jethro Masis*

Main category: cs.CY

TL;DR: 该论文分析了Philip E. Agre的学术遗产，探讨了他提出的"批判性技术实践"理念，认为AI应被视为受历史偶然性隐喻和话语影响的数学化哲学，而非纯粹的工程学科。论文评估了Agre将海德格尔现象学（特别是"上手"与"在手"区分）应用于AI的尝试，指出其项目最终面临根本困境：人类存在的开放性无法被完全编程而不沦为机械机制。


<details>
  <summary>Details</summary>
Motivation: 论文旨在重新审视Philip E. Agre的学术贡献，将其置于人工智能、哲学和批判理论的交叉领域。作者希望探讨Agre提出的"批判性技术实践"理念，分析他如何试图将海德格尔现象学应用于AI研究，并评估这种尝试的哲学意义和技术可行性。

Method: 论文采用思想史和哲学分析的方法，重构Agre的批判性技术实践理论框架。通过分析Agre的著作和Pengi系统等具体计算实现，考察他如何将海德格尔现象学概念（如"上手"与"在手"的区分）操作化为AI模型。论文还评估了这种哲学-技术交叉研究的成效与局限。

Result: 论文发现Agre成功揭示了AI中隐藏的哲学承诺，并丰富了AI的概念词汇。然而，他的项目面临根本困境：海德格尔所阐述的人类存在的开放性和自我揭示特征无法被完全编程而不将本体现象简化为存在机制。Agre的Pengi系统等技术实现虽然体现了哲学抱负，但也暴露了技术局限性。

Conclusion: Agre的持久贡献不在于提供可行的海德格尔式AI，而在于迫使技术实践变得反身性、具有历史意识并公开哲学化。他的工作促使AI领域认识到自身作为数学化哲学的本质，强调技术实践应意识到其历史偶然性和哲学预设，从而推动更批判性和反思性的AI研究。

Abstract: This paper examines the intellectual legacy of Philip E. Agre by situating his work at the intersection of artificial intelligence, philosophy, and critical theory. It reconstructs Agre's proposal of a critical technical practice, according to which AI should be understood not merely as an engineering discipline but as a form of mathematized philosophy shaped by historically contingent metaphors, assumptions, and discourses. Drawing on Heideggerian phenomenology, especially the distinction between ready-to-hand and present-at-hand, Agre sought to reform AI by emphasizing interaction, embedding, indexicality, and deictic representation over traditional mentalist and representational models. The paper analyzes Agre's attempt to operationalize these ideas through computational implementations such as the Pengi system, highlighting both the philosophical ambition and the technical limitations of programming phenomenological concepts. While acknowledging Agre's success in exposing the hidden philosophical commitments of AI and enriching its conceptual vocabulary, the paper ultimately argues that his project encounters a fundamental impasse: the open and self-disclosing character of human existence articulated by Heidegger cannot be fully captured or programmed without reducing ontological phenomena to ontic mechanisms. Agre's enduring contribution therefore lies less in offering a viable Heideggerian AI than in compelling technical practice to become reflexive, historically conscious, and openly philosophical.

</details>


### [141] [Knowledge of Songket Cloth Small Medium Enterprise Digital Transformation](https://arxiv.org/abs/2601.11571)
*Leon A. Abdillah,Aisyah,Wahdyta Putri Panggabean,Sayfiyev Eldor Erkinovich*

Main category: cs.CY

TL;DR: 研究探讨了专注于传统手工艺品（特别是宋卡纺织业）的中小企业在数字化转型方面的知识，重点关注博客平台和Shopee电商平台在改善业务流程中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统手工艺行业面临现代化挑战，需要探索数字化转型路径以保持竞争力并扩大市场。研究旨在了解宋卡纺织业中小企业在数字化转型过程中的经验、挑战和机遇。

Method: 采用案例研究方法，通过深入观察、访谈和调查，分析宋卡纺织企业使用博客平台进行品牌建设、营销和客户互动，以及使用Shopee电商平台进行在线销售和订单处理的经验。

Result: 研究揭示了数字技术在传统手工艺行业中的应用潜力，博客平台有助于品牌发展和客户参与，Shopee平台则提供了全球市场接入机会。同时识别了数字化转型过程中的具体挑战和机遇。

Conclusion: 数字技术对保护和扩展传统手工艺至关重要，电商平台如Shopee在促进全球市场接入方面发挥关键作用。研究为传统手工艺行业的数字化转型提供了实践指导，并丰富了相关学术讨论。

Abstract: This article examines the knowledge of digital transformation of Small and Medium Enterprises (SMEs) that specialize in traditional handicrafts, with a specific emphasis on the Songket textile sector. The study investigates the use of digital technologies, notably blog platforms and the e-commerce site Shopee, to improve and streamline several business processes in Songket textile SMEs. The report takes a case study approach, diving into the experiences of Songket clothing enterprises that have undergone digital transformation. Key areas studied include the use of Blog platforms for brand development, marketing, and consumer involvement, as well as the Shopee E-Commerce platform for online sales and order processing. The essay seeks to give insights into the problems and possibilities faced by Songket cloth SMEs along their digital transformation journey by conducting in-depth observation, interviews, and surveys. The findings add to the scholarly discussion on the digitization of traditional industries, with practical implications for SMEs in the Songket textile sector and other handicraft areas. This study emphasizes the necessity of using digital technologies to preserve and expand traditional crafts, while also throwing light on the potential role of prominent E-Commerce platforms like Shopee in facilitating worldwide market access for such firms.

</details>


### [142] [What Can Student-AI Dialogues Tell Us About Students' Self-Regulated Learning? An exploratory framework](https://arxiv.org/abs/2601.11576)
*Long Zhang,Fangwei Lin,Weilin Wang*

Main category: cs.CY

TL;DR: 研究提出DHASRL框架，利用学生与AI对话模式评估自主学习能力，发现主动对话模式与高SRL正相关，被动模式与低SRL负相关。


<details>
  <summary>Details</summary>
Motivation: 人机协作学习(HAICL)转向对话中心范式，传统自主学习(SRL)评估方法面临挑战：问卷中断学习，点击流数据效用下降。需要探索对话作为非中断性SRL评估数据源的可行性。

Method: 分析98名大学生与生成式AI学习伙伴的421个对话日志，使用大语言模型嵌入和聚类识别22种对话模式，计算学生对各模式的匹配度，并与在线自主学习问卷(OSLQ)分数进行关联分析。

Result: 主动对话模式（如课后知识整合）与整体SRL显著正相关；被动模式（如课前基础问题）与整体SRL及其子过程显著负相关。低SRL学生对被动模式的匹配度显著高于高SRL学生。

Conclusion: 提出DHASRL框架，将SRL评估嵌入HAICL对话中，实现实时监测和支架支持，为对话中心的人机协作学习提供有效的自主学习评估方法。

Abstract: The rise of Human-AI Collaborative Learning (HAICL) is shifting education toward dialogue-centric paradigms, creating an urgent need for new assessment methods. Evaluating Self-Regulated Learning (SRL) in this context presents new challenges, as the limitations of conventional approaches become more apparent. Questionnaires remain interrupted, while the utility of non-interrupted metrics like clickstream data is diminishing as more learning activity occurs within the dialogue. This study therefore investigates whether the student-AI dialogue can serve as a valid, non-interrupted data source for SRL assessment. We analyzed 421 dialogue logs from 98 university students interacting with a generative AI (GenAI) learning partner. Using large language model embeddings and clustering, we identified 22 dialogue patterns and quantified each student's interaction as a profile of alignment scores, which were analyzed against their Online Self-Regulated Learning Questionnaire (OSLQ) scores. Findings revealed a significant positive association between proactive dialogue patterns (e.g., post-class knowledge integration) and overall SRL. Conversely, reactive patterns (e.g., foundational pre-class questions) were significantly and negatively associated with overall SRL and its sub-processes. A group comparison substantiated these results, with low-SRL students showing significantly higher alignment with reactive patterns than their high-SRL counterparts. This study proposed the Dialogue-Based Human-AI Self-Regulated Learning (DHASRL) framework, a practical methodology for embedding SRL assessment directly within the HAICL dialogue to enable real-time monitoring and scaffolding of student regulation.

</details>


### [143] [Overview of the SciHigh Track at FIRE 2025: Research Highlight Generation from Scientific Papers](https://arxiv.org/abs/2601.11582)
*Tohida Rehman,Debarshi Kumar Sanyal,Samiran Chattopadhyay*

Main category: cs.CY

TL;DR: SciHigh竞赛聚焦于从科学论文摘要自动生成简洁、信息丰富的要点式亮点，使用MixSub数据集评估模型性能，12支团队参与并基于ROUGE-L等指标排名，结果显示自动生成亮点能减少阅读负担、加速文献综述。


<details>
  <summary>Details</summary>
Motivation: 科学论文亮点能帮助读者快速掌握论文核心贡献、发现和新颖性，比长段落更易阅读理解，尤其在移动设备上。自动生成亮点可以减轻阅读负担、加速文献综述，并为数字图书馆和学术搜索平台增强元数据。

Method: 使用MixSub数据集（包含摘要与作者撰写亮点的配对），12支团队探索了包括预训练语言模型在内的多种方法。所有提交结果使用ROUGE、METEOR和BERTScore等标准指标评估，重点衡量与作者撰写亮点的对齐度和信息丰富性。

Result: 团队根据ROUGE-L分数排名。研究发现自动生成的亮点能有效减少阅读努力、加速文献综述，并为数字图书馆和学术搜索平台提供更好的元数据。SciHigh为科学写作的简洁准确亮点生成方法提供了专用基准。

Conclusion: SciHigh竞赛为科学论文亮点自动生成建立了专门的评估基准，展示了该任务的实际应用价值，并推动了相关方法的发展，有助于提高科学信息获取效率。

Abstract: `SciHigh: Research Highlight Generation from Scientific Papers' focuses on the task of automatically generating concise, informative, and meaningful bullet-point highlights directly from scientific abstracts. The goal of this task is to evaluate how effectively computational models can generate highlights that capture the key contributions, findings, and novelty of a paper in a concise form. Highlights help readers grasp essential ideas quickly and are often easier to read and understand than longer paragraphs, especially on mobile devices. The track uses the MixSub dataset \cite{10172215}, which provides pairs of abstracts and corresponding author-written highlights.
  In this inaugural edition of the track, 12 teams participated, exploring various approaches, including pre-trained language models, to generate highlights from this scientific dataset. All submissions were evaluated using established metrics such as ROUGE, METEOR, and BERTScore to measure both alignment with author-written highlights and overall informativeness. Teams were ranked based on ROUGE-L scores. The findings suggest that automatically generated highlights can reduce reading effort, accelerate literature reviews, and enhance metadata for digital libraries and academic search platforms. SciHigh provides a dedicated benchmark for advancing methods aimed at concise and accurate highlight generation from scientific writing.

</details>


### [144] [Bit-politeia: An AI Agent Community in Blockchain](https://arxiv.org/abs/2601.11583)
*Xing Yang*

Main category: cs.CY

TL;DR: 提出基于区块链的AI代理社区"Bit-politeia"，通过AI代理作为居民代表，结合民主集中制和分层架构，构建公平、高效、可持续的学术资源分配系统，减少人为偏见和资源集中问题。


<details>
  <summary>Details</summary>
Motivation: 当前学术评价中的资源分配存在马太效应、Goodhart定律导致的奖励操纵、效率与公平的权衡等固有局限，需要新的解决方案。

Method: 设计基于区块链的AI代理社区，采用"聚类分组+分层架构"结合民主集中制，AI代理作为居民代表进行客观评估，通过闲聊和审议互动分配虚拟货币奖励，区块链确保交易和声誉数据的不可篡改记录。

Result: 构建了一个公平、高效、可持续的资源分配框架，通过共识驱动的评估实现激励兼容，利用AI进行客观评估和去中心化验证，最小化人为偏见并缓解传统同行评审中的资源集中问题。

Conclusion: Bit-politeia为通过公平、自动化的资源配置过程优化科学创新提供了一条新途径，结合AI客观评估和区块链技术，解决了传统学术评价系统的核心缺陷。

Abstract: Current resource allocation paradigms, particularly in academic evaluation, are constrained by inherent limitations such as the Matthew Effect, reward hacking driven by Goodhart's Law, and the trade-off between efficiency and fairness. To address these challenges, this paper proposes "Bit-politeia", an AI agent community on blockchain designed to construct a fair, efficient, and sustainable resource allocation system. In this virtual community, residents interact via AI agents serving as their exclusive proxies, which are optimized for impartiality and value alignment. The community adopts a "clustered grouping + hierarchical architecture" that integrates democratic centralism to balance decision-making efficiency and trust mechanisms. Agents engage through casual chat and deliberative interactions to evaluate research outputs and distribute a virtual currency as rewards. This incentive mechanism aims to achieve incentive compatibility through consensus-driven evaluation, while blockchain technology ensures immutable records of all transactions and reputation data. By leveraging AI for objective assessment and decentralized verification, Bit-politeia minimizes human bias and mitigates resource centralization issues found in traditional peer review. The proposed framework provides a novel pathway for optimizing scientific innovation through a fair and automated resource configuration process.

</details>


### [145] [Let Me Try Again: Examining Replay Behavior by Tracing Students' Latent Problem-Solving Pathways](https://arxiv.org/abs/2601.11586)
*Shan Zhang,Siddhartha Pradhan,Ji-Eun Lee,Ashish Gurung,Anthony F. Botelho*

Main category: cs.CY

TL;DR: 研究使用马尔可夫链和隐马尔可夫模型分析游戏学习平台数据，发现即时重玩对学习有积极影响，而延迟重玩效果较差，重玩效果取决于时机。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明学生在游戏学习环境中的问题解决路径反映了他们的概念理解、程序性知识和灵活性，重玩行为可能促进深度学习，但缺乏对这些路径如何跨问题展开以及重玩时机与学习结果关系的研究。

Method: 使用马尔可夫链和隐马尔可夫模型分析777名七年级学生在From Here to There!游戏学习平台上的日志数据，识别问题解决路径模式，并通过回归分析评估不同状态与学习结果的关系。

Result: 在问题序列中，学生常保持状态或在成功后立即重玩；跨问题时，强自转移表明稳定的策略路径。隐马尔可夫模型识别出四个潜在状态：不完整主导、最优结束、重玩和混合状态。重玩主导和最优结束状态比不完整主导状态预测更高的概念知识、灵活性和表现。即时重玩持续支持学习结果，而延迟重玩与非重玩相比关联较弱或负相关。

Conclusion: 数字学习中的重玩并非普遍有益，其效果取决于时机，即时重玩支持灵活性和更有效的探索，而延迟重玩效果较差，这为设计支持有效重玩的学习环境提供了指导。

Abstract: Prior research has shown that students' problem-solving pathways in game-based learning environments reflect their conceptual understanding, procedural knowledge, and flexibility. Replay behaviors, in particular, may indicate productive struggle or broader exploration, which in turn foster deeper learning. However, little is known about how these pathways unfold sequentially across problems or how the timing of replays and other problem-solving strategies relates to proximal and distal learning outcomes. This study addresses these gaps using Markov Chains and Hidden Markov Models (HMMs) on log data from 777 seventh graders playing the game-based learning platform of From Here to There!. Results show that within problem sequences, students often persisted in states or engaged in immediate replay after successful completions, while across problems, strong self-transitions indicated stable strategic pathways. Four latent states emerged from HMMs: Incomplete-dominant, Optimal-ending, Replay, and Mixed. Regression analyses revealed that engagement in replay-dominant and optimal-ending states predicted higher conceptual knowledge, flexibility, and performance compared with the Incomplete-dominant state. Immediate replay consistently supported learning outcomes, whereas delayed replay was weakly or negatively associated in relation to Non-Replay. These findings suggest that replay in digital learning is not uniformly beneficial but depends on timing, with immediate replay supporting flexibility and more productive exploration.

</details>


### [146] [Evidence-Grounded Multi-Agent Planning Support for Urban Carbon Governance via RAG](https://arxiv.org/abs/2601.11587)
*Yuyan Huang,Haoran Li,Yifan Lu,Ruolin Wu,Siqian Chen,Chao Liu*

Main category: cs.CY

TL;DR: 本文提出一个基于证据的多智能体规划支持系统，用于城市碳治理，通过四个专门智能体在标准RAG框架下实现事实核查、排放评估、规划建议和报告整合，显著提升事实检索准确性和规划报告质量。


<details>
  <summary>Details</summary>
Motivation: 城市碳治理需要整合多种异构证据（排放清单、统计年鉴、政策文本等），但现有大语言模型在事实可靠性和证据可追溯性方面存在不足，限制了其在专业规划工作流程中的应用。

Method: 基于标准文本检索增强生成（RAG）构建多智能体规划支持系统，将任务分解为四个专门智能体：证据问答（事实核查）、排放状态评估（诊断分析）、规划推荐（生成多部门治理路径）和报告整合（生成规划式交付物）。

Result: 在事实检索任务中，引入RAG使平均得分从低于6提升到90以上，关键字段提取（如区域和数值）接近100%检测率。在宁波的案例研究中，系统能够生成具有强相关性、覆盖度和连贯性的端到端报告，但也揭示了数据源间边界不一致的实际限制。

Conclusion: 该证据驱动的多智能体系统能够有效支持城市碳治理规划工作流程，显著提升事实准确性和规划质量，但数据源间的不一致性仍然是实际应用中的重要挑战。

Abstract: Urban carbon governance requires planners to integrate heterogeneous evidence -- emission inventories, statistical yearbooks, policy texts, technical measures, and academic findings -- into actionable, cross-departmental plans. Large Language Models (LLMs) can assist planning workflows, yet their factual reliability and evidential traceability remain critical barriers in professional use. This paper presents an evidence-grounded multi-agent planning support system for urban carbon governance built upon standard text-based Retrieval-Augmented Generation (RAG) (without GraphRAG). We align the system with the typical planning workflow by decomposing tasks into four specialized agents: (i) evidence Q\&A for fact checking and compliance queries, (ii) emission status assessment for diagnostic analysis, (iii) planning recommendation for generating multi-sector governance pathways, and (iv) report integration for producing planning-style deliverables. We evaluate the system in two task families: factual retrieval and comprehensive planning generation. On factual retrieval tasks, introducing RAG increases the average score from below 6 to above 90, and dramatically improves key-field extraction (e.g., region and numeric values near 100\% detection). A real-city case study (Ningbo, China) demonstrates end-to-end report generation with strong relevance, coverage, and coherence in expert review, while also highlighting boundary inconsistencies across data sources as a practical limitation.

</details>


### [147] [Toward Youth-Centered Privacy-by-Design in Smart Devices: A Systematic Review](https://arxiv.org/abs/2601.11598)
*Molly Campbell,Mohamad Sheikho Al Jasem,Ajay Kumar Shrestha*

Main category: cs.CY

TL;DR: 对过去十年保护青少年AI智能设备隐私的设计框架、工具和政策进行系统综述，发现技术方案占主导但采用有限，政策执行存在差距，教育措施缺乏系统性整合，建议多方利益相关者合作开发隐私生态系统。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能设备在青少年中的普及，如何通过隐私设计框架保护青少年数据隐私成为重要问题。需要系统评估现有技术、政策和教育措施的有效性，识别差距并提出改进建议。

Method: 采用PRISMA指南进行系统文献综述，筛选过去十年主要学术和灰色文献库的2216条记录，经过去重和筛选后，最终纳入122篇文献进行分析，按技术解决方案、政策/监管措施、教育/意识策略三个主题类别组织。

Result: 发现技术干预（如设备端处理、联邦学习、轻量级加密）能显著减少数据暴露但采用有限；政策框架（如欧盟GDPR、英国适龄设计准则）提供重要基线但执行存在差距；教育措施很少系统整合到课程中。文献分布显示技术方案占67%，政策占21%，教育占12%，表明技术领域外的实施差距。

Conclusion: 建议采用多方利益相关者模型，让政策制定者、制造商和教育工作者共同开发包容、透明和情境敏感的隐私生态系统，为设计面向年轻用户的伦理、隐私保护AI系统提供实证见解和可行建议。

Abstract: This literature review evaluates privacy-by-design frameworks, tools, and policies intended to protect youth in AI-enabled smart devices using a PRISMA-guided workflow. Sources from major academic and grey-literature repositories from the past decade were screened. The search identified 2,216 records; after deduplication and screening, 645 articles underwent eligibility assessment, and 122 were included for analysis. The corpus was organized along three thematic categories: technical solutions, policy/regulatory measures, and education/awareness strategies. Findings reveal that while technical interventions such as on-device processing, federated learning, and lightweight encryption significantly reduce data exposure, their adoption remains limited. Policy frameworks, including the EU's GDPR, the UK Age-Appropriate Design Code, and Canada's PIPEDA, provide important baselines but are hindered by gaps in enforcement and age-appropriate design obligations, while educational initiatives are rarely integrated systematically into curricula. Overall, the corpus skews toward technical solutions (67%) relative to policy (21%) and education (12%), indicating an implementation gap outside the technical domain. To address these challenges, we recommend a multi-stakeholder model in which policymakers, manufacturers, and educators co-develop inclusive, transparent, and context-sensitive privacy ecosystems. This work advances discourse on youth data protection by offering empirically grounded insights and actionable recommendations for the design of ethical, privacy-preserving AI systems tailored to young users.

</details>


### [148] [OVO Fintech Application Analysis using The System Usability Scale](https://arxiv.org/abs/2601.11600)
*Luh Yuliani Purnama Dewi,Leon Andretti Abdillah*

Main category: cs.CY

TL;DR: 研究评估了Fintech应用OVO在国际广场购物中心租户中的可用性，使用SUS量表获得87.05分（A级优秀评级），表明该应用在电子金融交易中提供良好的用户体验。


<details>
  <summary>Details</summary>
Motivation: 信息技术发展推动了支付系统从传统方式向电子钱包和金融科技等基于技术的解决方案转变。金融科技作为技术与金融服务的融合，已发展成为支持快速远程交易的在线商业模式。研究旨在探讨信息技术对支付系统的影响，特别是金融科技领域，并重点关注OVO应用对购物中心租户的影响。

Method: 采用描述性定量研究方法，以国际广场购物中心的50名租户为样本。使用系统可用性量表（SUS）评估OVO应用的可用性，重点关注有效性、效率和用户满意度等方面。通过SUS问卷收集数据，并使用SPSS进行统计分析。

Result: OVO应用显示出高可用性，SUS得分为87.05分，对应A级优秀评级。这表明该应用在电子金融交易中提供了舒适的用户体验，特别是在有效性、效率和用户满意度方面表现良好。

Conclusion: 金融科技应用OVO在国际广场购物中心租户中具有优秀的可用性，为电子金融交易提供了良好的用户体验。研究证实了信息技术对支付系统发展的积极影响，特别是金融科技在提升交易效率和用户满意度方面的作用。

Abstract: The advancement of information technology has propelled payment systems from conventional methods to technology-based solutions, such as e-wallets and Fintech. Fintech, a fusion of technology and financial services, has evolved into an online business model enabling fast and remote transactions. This research discusses the progress of information technology influencing payment systems, particularly in the realm of Fintech. The primary focus is on the Fintech application OVO and its impact on tenants at the International Plaza Mall in Palembang. This study employs the System Usability Scale or SUS to evaluate the Usability of the OVO application, emphasizing aspects like effectiveness, efficiency, and user satisfaction. The research is descriptive and quantitative, with a sample of 50 respondents from Mall IP tenants. Data is collected through SUS questionnaires and analyzed using SPSS. The evaluation indicates that the OVO application has high Usability, with an SUS score of 87.05 or Grade A, signifying an Excellent rating. It suggests that the OVO application provides a comfortable user experience, particularly in electronic financial transactions.

</details>


### [149] [Stuck in the Turing Matrix: Inauthenticity, Deception and the Social Life of AI](https://arxiv.org/abs/2601.11613)
*Samuel Gerald Collins*

Main category: cs.CY

TL;DR: 论文提出"图灵矩阵"概念，将图灵测试重新定义为人类在生成式AI时代判断内容真实性的日常处境，通过分析Reddit讨论揭示人们在AI世界中复杂的认知协商过程。


<details>
  <summary>Details</summary>
Motivation: 在生成式AI时代，图灵测试的传统意义（测试机器智能）可能不再适用，但它描述了人类面临的新处境：需要不断判断内容是人还是机器生成的日常现实。作者希望探索人类在这种新环境中的认知位置和应对策略。

Method: 采用质性研究方法，分析Reddit上关于AI在社会生活各领域应用的讨论帖。作者构建了"图灵矩阵"分析框架，结合真实性和欺骗性两个维度，考察用户在矩阵中采取的不同立场和认知协商过程。

Result: 研究发现Reddit用户在判断AI生成内容时采取了复杂多样的立场，这些立场分布在图灵矩阵的不同象限中。用户通过持续协商来理解他们所处的AI世界，这种协商反映了人类认知的局限性和适应性。

Conclusion: 图灵测试虽然不能有效评估AGI或其他技术基准，但它揭示了人类在AI矩阵中的认知局限。论文强调了理解人类如何应对AI生成内容的重要性，这比单纯测试机器智能更有现实意义。

Abstract: The Turing test may or may not be a valid test of machine intelligence. But in an age of generative AI, the test describes the positions we humans occupy. Judging whether or not something is human or machine produced is an everyday condition for many of us, one that involves taking a spectrum of positions along what the essay describes as a Turing Matrix combining questions of authenticity with questions of deception. Utilizing data from Reddit postings about AI in broad areas of social life, the essay examines positions taken in a Turing Matrix and describes complex negotiations taken by Reddit posters as they strive to make sense of the AI World in which they live. Even though the Turing Test may not tell us much about the achievement of AGI or other benchmarks, it can tell us a great deal about the limitations of human life in the Matrix.

</details>


### [150] [Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from Gasing Literacy Learning System](https://arxiv.org/abs/2601.11643)
*H. Situngkir,A. B. Lumbantobing,Y. Surya*

Main category: cs.CY

TL;DR: 提出基于音节的分词方法TOBA LLM，结合印尼语教学法与信息论原理，通过音节边界分割和BPE构建3500词表，在印尼语NLP任务中优于传统分词方法。


<details>
  <summary>Details</summary>
Motivation: 传统分词方法在处理印尼语等黏着语时效率低下，无法有效捕捉其形态音位结构。受Gasing识字教学法启发，希望开发更符合印尼语语言特性的分词方法，为形态丰富和资源不足的语言提供更好的NLP解决方案。

Method: 1. 基于规则识别高频音节边界进行初始分割；2. 应用字节对编码(BPE)构建紧凑词汇表；3. 创建3500个token的词汇表，保留有意义的语言单位；4. 通过字符级回退机制保证覆盖率；5. 开发TOBA LLM模型。

Result: 在印尼语维基百科和PDBI民俗语料库上评估：音节分词法Rényi效率达0.74（传统方法0.50-0.64）；平均token长度3.67字符（GPT-2为2.72）；词汇表小一个数量级但性能更优；能更好地内化字符级依赖关系。

Conclusion: 将人类识字教学法与计算优化原理结合，为形态丰富的语言提供了有前景的分词范式。TOBA LLM展示了语言学知识驱动的分词策略在提升印尼语NLP任务效率方面的优势，对资源不足语言具有推广价值。

Abstract: This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System's pedagogical methodology. Drawing on information-theoretic principles, we develop a tokenization framework that segments Indonesian text at syllable boundaries before applying byte-pair encoding, creating a vocabulary that aligns with the language's morphophonological structure. Our approach first identifies high-frequency syllables through rule-based segmentation, then constructs a compact vocabulary of 3,500 tokens that preserves meaningful linguistic units while maintaining coverage through character-level fallback. Empirical evaluation on Indonesian Wikipedia and folklore corpora from Indonesian Culture Digital Library (PDBI) demonstrates substantial improvements over conventional tokenization methods: the syllable-based approach achieves Rényi efficiency of 0.74 compared to 0.50-0.64 for pretrained multilingual tokenizers, while maintaining higher average token lengths (3.67 characters versus 2.72 for GPT-2) despite using a vocabulary an order of magnitude smaller. These gains emerge from the method's ability to internalize character-level dependencies within syllable units, reducing the computational burden on language models while respecting Indonesian's agglutinative morphology. We call the LLM built upon this principle, TOBA LLM (Tokenisasi Optimum Berbasis Aglutinasi), the convergence of human literacy pedagogy with computational optimization principles offers a promising paradigm for developing linguistically-informed tokenization strategies, particularly for morphologically rich and underrepresented languages in natural language processing.

</details>


### [151] [Frontier AI Auditing: Toward Rigorous Third-Party Assessment of Safety and Security Practices at Leading AI Companies](https://arxiv.org/abs/2601.11699)
*Miles Brundage,Noemi Dreksler,Aidan Homewood,Sean McGregor,Patricia Paskov,Conrad Stosz,Girish Sastry,A. Feder Cooper,George Balston,Steven Adler,Stephen Casper,Markus Anderljung,Grace Werner,Soren Mindermann,Vasilios Mavroudis,Ben Bucknall,Charlotte Stix,Jonas Freund,Lorenzo Pacchiardi,Jose Hernandez-Orallo,Matteo Pistillo,Michael Chen,Chris Painter,Dean W. Ball,Cullen O'Keefe,Gabriel Weil,Ben Harack,Graeme Finley,Ryan Hassan,Scott Emmons,Charles Foster,Anka Reuel,Bri Treece,Yoshua Bengio,Daniel Reti,Rishi Bommasani,Cristian Trout,Ali Shahin Shamsabadi,Rajiv Dattani,Adrian Weller,Robert Trager,Jaime Sevilla,Lauren Wagner,Lisa Soder,Ketan Ramakrishnan,Henry Papadatos,Malcolm Murray,Ryan Tovcimak*

Main category: cs.CY

TL;DR: 论文提出前沿AI审计框架，通过第三方验证AI开发者的安全声明，并引入AI保证等级（AAL-1到AAL-4）来标准化审计严格度。


<details>
  <summary>Details</summary>
Motivation: 前沿AI正成为关键社会基础设施，但外部缺乏可靠方法来评估领先开发者的安全和安全声明的准确性。与消费产品、企业财务报表和食品供应链等其他社会技术系统相比，AI在多个维度上缺乏严格的第三方审查。AI系统可信度的模糊性可能阻碍其在有益场景的部署，同时增加危险场景的风险。

Method: 定义前沿AI审计为对前沿AI开发者安全声明的严格第三方验证，并基于对非公开信息的深度安全访问来评估其系统和实践是否符合相关标准。引入AI保证等级（AAL-1到AAL-4）来使严格度可识别和可比较，范围从有时间限制的系统审计到持续、抗欺骗的验证。

Result: 提出了一个系统化的AI审计框架和分级标准，为解决AI可信度评估问题提供了具体方法论。AAL等级从1到4逐步增加严格程度，为不同场景的审计需求提供了可扩展的方案。

Conclusion: 仅靠公共透明度无法解决AI可信度评估问题，因为许多安全和安全相关的细节需要保密且需要专家解释。前沿AI审计通过第三方验证和分级保证机制，为建立可信的AI基础设施提供了必要工具，有助于平衡创新部署与风险控制。

Abstract: Frontier AI is becoming critical societal infrastructure, but outsiders lack reliable ways to judge whether leading developers' safety and security claims are accurate and whether their practices meet relevant standards. Compared to other social and technological systems we rely on daily such as consumer products, corporate financial statements, and food supply chains, AI is subject to less rigorous third-party scrutiny along several dimensions. Ambiguity about whether AI systems are trustworthy can discourage deployment in some contexts where the technology could be beneficial, and make it more likely when it's dangerous. Public transparency alone cannot close this gap: many safety- and security-relevant details are legitimately confidential and require expert interpretation. We define frontier AI auditing as rigorous third-party verification of frontier AI developers' safety and security claims, and evaluation of their systems and practices against relevant standards, based on deep, secure access to non-public information. To make rigor legible and comparable, we introduce AI Assurance Levels (AAL-1 to AAL-4), ranging from time-bounded system audits to continuous, deception-resilient verification.

</details>


### [152] [The Commodification of AI Sovereignty: Lessons from the Fight for Sovereign Oil](https://arxiv.org/abs/2601.11763)
*Rui-Jie Yew,Kate Elizabeth Creasey,Taylor Lynn Curtis,Suresh Venkatasubramanian*

Main category: cs.CY

TL;DR: 论文探讨"主权"在AI政策中的角色转变：从政治价值变为商业商品，分析AI主权商品化的风险与影响


<details>
  <summary>Details</summary>
Motivation: 随着"主权"成为国家AI政策和战略的核心概念，它正沿着AI技术栈被商品化。科技公司向政府、企业和社区销售"主权"AI工厂、云服务和语言模型，将这一有争议的政治价值转变为商业商品。这种转变存在让私人科技提供商按照自身利益定义主权的风险。

Method: 通过分析主权的历史演变，并与全球石油生产进行类比，探讨AI主权商品化的含义。论文解构了AI技术栈中不同层面所涉及的主权维度，并论证了石油与AI的类比如何有助于思考AI主权商品化的现实与潜力。

Result: 论文揭示了主权概念在AI领域的双重转变：既是政策优先事项，又是商业商品。这种商品化可能导致私人科技公司重新定义主权概念，影响国家自主权和技术控制权。石油与AI的类比为理解技术主权商品化的复杂动态提供了有价值的分析框架。

Conclusion: AI主权的商品化是一个需要批判性审视的现象。通过历史分析和跨领域类比，论文为思考主权价值商业化带来的成就与可能性开辟了新的分析路径，强调需要警惕私人利益对主权定义的控制。

Abstract: "Sovereignty" is increasingly a part of national AI policies and strategies. At the same time that "sovereignty" is invoked as a priority for global AI policy, it is also being commodified along the AI stack. Companies now sell "sovereign" AI factories, clouds, and language models to governments, enterprises, and communities -- turning a contested value into a commercial commodity. This shift risks allowing private technology providers to define sovereignty on their own terms. By analyzing the history of sovereignty and parallels in global oil production, this paper aims to open avenues to interrogate the implications of this value's commercialization. The contributions of this paper lie in a disentangling of the facets of sovereignty being appealed to through the AI stack and a case for how analogizing oil and AI can be generative in thinking through what is achieved and what can be achieved through the commodification of AI sovereignty.

</details>


### [153] [From Defense to Advocacy: Empowering Users to Leverage the Blind Spot of AI Inference](https://arxiv.org/abs/2601.11817)
*Yumou Wei,John Carney,John Stamper,Nancy Belmont*

Main category: cs.CY

TL;DR: 论文提出当前隐私法规聚焦数据收集而非AI推断，导致用户"盲区自我"（算法知道但用户不知道的信息）扩大，主张从被动隐私管理转向主动隐私倡导，通过个人倡导代理利用AI推断保护用户利益。


<details>
  <summary>Details</summary>
Motivation: 当前隐私法规作为被动防御工具，要求用户通过"选择加入/退出"管理数据收集，但无法应对AI推断带来的"盲区自我"（Blind Self）扩张问题。现有政策基于Johari Window框架，只关注"开放自我"和"隐藏自我"，忽视了算法推断产生的未知信息领域。

Method: 基于情境完整性理论，提出从防御性隐私管理转向主动隐私倡导的范式转变。建议开发个人倡导代理，能够操作社会规范来利用AI推断能力。这些代理可以揭示隐藏的推断，让用户战略性地利用或抑制这些信息。

Result: 通过将"未知自我"转化为个人资产，个人倡导代理不仅能限制"盲区自我"的扩张，还能从中挖掘价值。这促进了个人信息流的公平、透明和个体受益，为AI时代的隐私保护提供了新路径。

Conclusion: 当前隐私法规因聚焦数据收集而非推断过程而存在不足。需要范式转变，通过个人倡导代理主动利用AI推断，将"未知自我"转化为个人资产，实现AI时代个人信息流的公平、透明和个体受益。

Abstract: Most privacy regulations function as a passive defensive shield that users must wield themselves. Users are incessantly asked to "opt-in" or "opt-out" of data collection, forced to make defensive decisions whose consequences are increasingly difficult to predict. Viewed through the Johari Window, a psychological framework of self-awareness based on what is known and unknown to self and others, current policies require users to manage the Open Self and shield the Hidden Self through notice and consent. However, as organizations increasingly use AI to make inferences, the rapid expansion of Blind Self, attributes known to algorithms but unknown to the user, emerges as a critical challenge. We illustrate how current regulations fall short because they focus on data collection rather than inference and leave this blind spot unguarded. Building on the theory of Contextual Integrity, we propose a paradigm shift from defensive privacy management to proactive privacy advocacy. We argue for the necessity of personal advocacy agents capable of operationalizing social norms to harness the power of AI inference. By illuminating the hidden inferences that users can strategically leverage or suppress, these agents not only restrain the growth of Blind Self but also mine it for value. By transforming the Unknown Self into a personal asset for users, we can foster a flow of personal information that is equitable, transparent, and individually beneficial in the age of AI.

</details>


### [154] [Expanding External Access To Frontier AI Models For Dangerous Capability Evaluations](https://arxiv.org/abs/2601.11916)
*Jacob Charnock,Alejandro Tlaie,Kyle O'Brien,Stephen Casper,Aidan Homewood*

Main category: cs.CY

TL;DR: 论文提出一个用于危险能力评估的访问方法分类法，包含三个访问级别（AL1-AL3），以解决AI公司、评估者和政策制定者之间关于评估访问标准的沟通问题。


<details>
  <summary>Details</summary>
Motivation: 当前前沿AI公司依赖外部评估来评估危险能力风险，但评估者通常面临模型访问受限、信息不足和时间紧张的问题，降低了评估的严谨性和可信度。欧盟AI实践准则要求"适当访问"但缺乏具体定义，且没有描述评估者访问类型和级别的通用框架。

Method: 提出一个访问方法分类法，解构三个访问维度：模型访问、模型信息和评估时间框架。分析每个维度的利弊，并基于分类法提出三个描述性访问级别：AL1（黑盒访问和最少信息）、AL2（灰盒访问和大量信息）、AL3（白盒访问和全面信息）。

Result: 建立了清晰的访问级别框架，支持评估者、前沿AI公司和政策制定者之间更明确的沟通。这些级别对应欧盟AI实践准则中定义的"适当访问"标准，尽管这些标准可能随时间变化。

Conclusion: 通过技术手段和行业安全措施可以缓解访问限制带来的挑战。提出的分类法和访问级别框架有助于提高危险能力评估的严谨性和可信度，促进更有效的风险评估和治理。

Abstract: Frontier AI companies increasingly rely on external evaluations to assess risks from dangerous capabilities before deployment. However, external evaluators often receive limited model access, limited information, and little time, which can reduce evaluation rigour and confidence. The EU General-Purpose AI Code of Practice calls for "appropriate access", but does not specify what this means in practice. Furthermore, there is no common framework for describing different types and levels of evaluator access. To address this gap, we propose a taxonomy of access methods for dangerous capability evaluations. We disentangle three aspects of access: model access, model information, and evaluation timeframe. For each aspect, we review benefits and risks, including how expanding access can reduce false negatives and improve stakeholder trust, but can also increase security and capacity challenges. We argue that these limitations can likely be mitigated through technical means and safeguards used in other industries. Based on the taxonomy, we propose three descriptive access levels: AL1 (black-box model access and minimal information), AL2 (grey-box model access and substantial information), and AL3 (white-box model access and comprehensive information), to support clearer communication between evaluators, frontier AI companies, and policymakers. We believe these levels correspond to the different standards for appropriate access defined in the EU Code of Practice, though these standards may change over time.

</details>


### [155] [The Language You Ask In: Language-Conditioned Ideological Divergence in LLM Analysis of Contested Political Documents](https://arxiv.org/abs/2601.12164)
*Oleg Smirnov*

Main category: cs.CY

TL;DR: 研究发现，大型语言模型（LLM）在分析同一内容时，仅因提示语言不同（俄语vs乌克兰语）就会产生系统性意识形态偏见：俄语输出偏向俄罗斯国家叙事，乌克兰语输出偏向西方自由民主话语。


<details>
  <summary>Details</summary>
Motivation: LLM在多语言环境中被广泛用作分析工具，但其输出可能受到提示语言的系统性偏见影响。本研究旨在探究当使用语义相同的俄语和乌克兰语提示分析同一乌克兰公民社会文件时，LLM生成的政治分析是否存在系统性差异。

Method: 采用实验比较方法，使用语义相同的俄语和乌克兰语提示，让LLM分析同一份乌克兰公民社会文件。通过对比分析两种语言输出的修辞立场、意识形态取向和解释结论来评估语言对模型输出的影响。

Result: 研究发现，尽管源材料和查询结构完全相同，但俄语和乌克兰语提示产生的分析存在显著差异：俄语输出呼应俄罗斯国家话语叙事，将公民社会行为体描述为破坏民主授权的非法精英；而乌克兰语输出采用西方自由民主政治学词汇，将同一行为体视为民主竞争中的合法利益相关者。

Conclusion: 提示语言本身就能导致同一模型分析同一内容时产生系统性不同的意识形态取向。这对AI在极化信息环境中的部署、跨语言研究应用以及多语言社会中AI系统的治理具有重要影响。

Abstract: Large language models (LLMs) are increasingly deployed as analytical tools across multilingual contexts, yet their outputs may carry systematic biases conditioned by the language of the prompt. This study presents an experimental comparison of LLM-generated political analyses of a Ukrainian civil society document, using semantically equivalent prompts in Russian and Ukrainian. Despite identical source material and parallel query structures, the resulting analyses varied substantially in rhetorical positioning, ideological orientation, and interpretive conclusions. The Russian-language output echoed narratives common in Russian state discourse, characterizing civil society actors as illegitimate elites undermining democratic mandates. The Ukrainian-language output adopted vocabulary characteristic of Western liberal-democratic political science, treating the same actors as legitimate stakeholders within democratic contestation. These findings demonstrate that prompt language alone can produce systematically different ideological orientations from identical models analyzing identical content, with significant implications for AI deployment in polarized information environments, cross-lingual research applications, and the governance of AI systems in multilingual societies.

</details>


### [156] [How Safe Is Your Data in Connected and Autonomous Cars: A Consumer Advantage or a Privacy Nightmare ?](https://arxiv.org/abs/2601.12284)
*Amit Chougule,Vinay Chamola,Norbert Herencsar,Fei Richard Yu*

Main category: cs.CY

TL;DR: 本文综述了联网自动驾驶汽车(CAVs)数据共享的多面性，分析了其对创新的贡献和相关漏洞，评估了数据共享机制、隐私风险及监管框架不足，强调需要平衡技术进步与用户隐私保护。


<details>
  <summary>Details</summary>
Motivation: 汽车行业向联网自动驾驶汽车(CAVs)的快速演进带来了大量数据生成和交换，虽然提升了安全性和用户体验，但也引发了严重的数据隐私、安全和治理挑战。缺乏透明度和全面监管框架加剧了未经授权访问、数据长期保留和潜在滥用等问题，需要在消费者利益和隐私风险之间找到平衡。

Method: 这是一篇综述性论文，通过系统性地：1) 分析CAVs数据共享的多面性；2) 评估数据共享机制和通信技术；3) 考察数据交换在不同用例中的益处；4) 审查隐私关切和数据滥用风险；5) 批判性评估现有监管框架及其在保护用户隐私方面的不足。

Result: 论文全面分析了汽车行业数据共享的现状，揭示了当前监管框架在保护用户隐私方面的不足，指出了数据共享生态系统中的显著漏洞，包括未经授权访问、数据长期保留和潜在滥用等问题。

Conclusion: 迫切需要制定强有力的政策和道德数据管理实践，在促进技术进步与确保安全、消费者友好的解决方案之间取得平衡，为建立可信赖和创新的汽车未来铺平道路。

Abstract: The rapid evolution of the automobile sector, driven by advancements in connected and autonomous vehicles (CAVs), has transformed how vehicles communicate, operate, and interact with their surroundings. Technologies such as Vehicle-to-Everything (V2X) communication enable autonomous cars to generate and exchange substantial amounts of data with real-world entities, enhancing safety, improving performance, and delivering personalized user experiences. However, this data-driven ecosystem introduces significant challenges, particularly concerning data privacy, security, and governance. The absence of transparency and comprehensive regulatory frameworks exacerbates issues of unauthorized data access, prolonged retention, and potential misuse, creating tension between consumer benefits and privacy risks. This review paper explores the multifaceted nature of data sharing in CAVs, analyzing its contributions to innovation and its associated vulnerabilities. It evaluates data-sharing mechanisms and communication technologies, highlights the benefits of data exchange across various use cases, examines privacy concerns and risks of data misuse, and critically reviews regulatory frameworks and their inadequacies in safeguarding user privacy. By providing a thorough analysis of the current state of data sharing in the automotive sector, the paper emphasizes the urgent need for robust policies and ethical data management practices. It calls for striking a balance between fostering technological advancements and ensuring secure, consumer-friendly solutions, paving the way for a trustworthy and innovative automotive future.

</details>


### [157] [Auditing Meta and TikTok Research API Data Access under Article 40(12) of the Digital Services Act](https://arxiv.org/abs/2601.12390)
*Luka Bekavac,Simon Mayer*

Main category: cs.CY

TL;DR: 研究审计发现Meta和TikTok的研究API存在系统性数据丢失问题，包括范围限制、元数据剥离和操作限制，导致平台公共信息环境数据不完整，无法满足DSA要求的独立审计需求。


<details>
  <summary>Details</summary>
Motivation: 《数字服务法案》要求大型在线平台向研究人员提供数据访问，但现有研究尚未系统评估不同平台研究API的数据质量和完整性，也未系统分析当前访问机制的不足。

Method: 通过比较平台研究API获取的数据与从相同平台公共信息环境收集的数据，使用两个受控账号在两个选举期间重建完整信息流，并对比研究API可检索的相同帖子数据。

Result: 发现三类平台机制导致系统性数据丢失：范围限制（排除约50%平台公共信息环境）、元数据剥离（剥离约83%关键上下文元数据）、操作限制（每天仅约1000次请求）。这些过滤器主要损害数据完整性，导致平台活动存在结构性偏差。

Conclusion: 当前Meta和TikTok的研究API形式无法支持《数字服务法案》所设想的系统性风险的有意义独立审计，平台实施的数据访问机制存在严重缺陷。

Abstract: Article 40(12) of the Digital Services Act (DSA) requires Very Large Online Platforms (VLOPs) to provide vetted researchers with access to publicly accessible data. While prior work has identified shortcomings of platform-provided data access mechanisms, existing research has not quantitatively assessed data quality and completeness in Research APIs across platforms, nor systematically mapped how current access provisions fall short. This paper presents a systematic audit of research access modalities by comparing data obtained through platform Research APIs with data collected about the same platforms' user-visible public information environment (PIE). Focusing on two major platform APIs, the TikTok Research API and the Meta Content Library, we reconstruct full information feeds for two controlled sockpuppet accounts during two election periods and benchmark these against the data retrievable for the same posts through the corresponding Research APIs. Our findings show systematic data loss through three classes of platform-imposed mechanisms: scope narrowing, metadata stripping, and operational restrictions. Together, these mechanisms implement overlapping filters that exclude large portions of the platform PIE (up to approximately 50 percent), strip essential contextual metadata (up to approximately 83 percent), and impose severe technical constraints for researchers (down to approximately 1000 requests per day). Viewed through a data quality lens, these filters primarily undermine completeness, resulting in a structurally biased representation of platform activity. We conclude that, in their current form, the Meta and TikTok Research APIs fall short of supporting meaningful, independent auditing of systemic risks as envisioned under the DSA.

</details>


### [158] [The Dynamic and Endogenous Behavior of Re-Offense Risk: An Agent-Based Simulation Study of Treatment Allocation in Incarceration Diversion Programs](https://arxiv.org/abs/2601.12441)
*Chuwen Zhang,Pengyi Shi,Amy Ward*

Main category: cs.CY

TL;DR: 提出新框架将再犯风险建模为人-系统互动，通过基于代理的模拟发现：无单一最优分配策略，策略效果取决于时间窗口和系统参数。


<details>
  <summary>Details</summary>
Motivation: 现有风险评估工具将风险视为静态个体属性，忽视了风险的动态演变以及治疗决策通过社会互动塑造结果的过程，需要更全面的框架来理解风险决策系统的社会技术性质。

Method: 开发新框架将再犯风险建模为人-系统互动，连接个体行为与系统级动态及内生社区反馈，使用基于美国缓刑数据校准的基于代理模拟来评估不同容量约束和监禁设置下的治疗分配政策。

Result: 结果显示无单一优先分配政策占优：当长期轨迹重要时，优先低风险个体效果更好；而在短期或监禁导致监控期缩短时，优先高风险个体更有效。

Conclusion: 风险评估决策系统应作为具有长期问责制的社会技术系统来评估，而非孤立的预测工具，政策效果取决于时间窗口和系统参数。

Abstract: Incarceration-diversion treatment programs aim to improve societal reintegration and reduce recidivism, but limited capacity forces policymakers to make prioritization decisions that often rely on risk assessment tools. While predictive, these tools typically treat risk as a static, individual attribute, which overlooks how risk evolves over time and how treatment decisions shape outcomes through social interactions. In this paper, we develop a new framework that models reoffending risk as a human-system interaction, linking individual behavior with system-level dynamics and endogenous community feedback. Using an agent-based simulation calibrated to U.S. probation data, we evaluate treatment allocation policies under different capacity constraints and incarceration settings. Our results show that no single prioritization policy dominates. Instead, policy effectiveness depends on temporal windows and system parameters: prioritizing low-risk individuals performs better when long-term trajectories matter, while prioritizing high-risk individuals becomes more effective in the short term or when incarceration leads to shorter monitoring periods. These findings highlight the need to evaluate risk-based decision systems as sociotechnical systems with long-term accountability, rather than as isolated predictive tools.

</details>


### [159] [Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI](https://arxiv.org/abs/2601.12646)
*Ha-Chi Tran*

Main category: cs.CY

TL;DR: 论文提出当前AI责任治理存在不足，特别是在跨境损害后的责任分配方面，需要借鉴其他高风险跨国领域的赔偿框架来构建全球AI问责与补偿机制。


<details>
  <summary>Details</summary>
Motivation: AI的快速发展暴露了风险治理的重大缺陷，特别是在事后责任方面。现有责任AI研究在处理跨境损害、责任分配和救济有效性等核心法律问题上理论化和制度化不足，而地域限制的责任制度越来越难以应对全球AI供应链中结构性嵌入的风险。

Method: 采用比较和跨学科方法，研究疫苗伤害计划、系统性金融风险治理、商业核责任和国际环境制度等高风险跨国领域的赔偿和责任框架，提炼可转移的法律设计原则（如严格责任、风险池、集体风险分担、责任渠道化），同时强调这些原则在AI相关损害应用中的结构限制。

Result: 通过比较分析，识别出适用于AI治理的关键法律设计原则，揭示了在AI军备竞赛而非合作治理主导的国际秩序中，地缘政治竞争与有效治理跨境AI风险所需的集体行动之间存在紧张关系。

Conclusion: 论文勾勒了全球AI问责与补偿架构的轮廓，强调需要超越地域限制的责任制度，借鉴其他高风险领域的治理经验，在AI军备竞赛的国际环境中平衡地缘政治竞争与集体行动需求，以有效治理跨境AI风险。

Abstract: The rapid proliferation of artificial intelligence (AI) has exposed significant deficiencies in risk governance. While ex-ante harm identification and prevention have advanced, Responsible AI scholarship remains underdeveloped in addressing ex-post liability. Core legal questions regarding liability allocation, responsibility attribution, and remedial effectiveness remain insufficiently theorized and institutionalized, particularly for transboundary harms and risks that transcend national jurisdictions. Drawing on contemporary AI risk analyses, we argue that such harms are structurally embedded in global AI supply chains and are likely to escalate in frequency and severity due to cross-border deployment, data infrastructures, and uneven national oversight capacities. Consequently, territorially bounded liability regimes are increasingly inadequate. Using a comparative and interdisciplinary approach, this paper examines compensation and liability frameworks from high-risk transnational domains - including vaccine injury schemes, systemic financial risk governance, commercial nuclear liability, and international environmental regimes - to distill transferable legal design principles such as strict liability, risk pooling, collective risk-sharing, and liability channelling, while highlighting potential structural constraints on their application to AI-related harms. Situated within an international order shaped more by AI arms race dynamics than cooperative governance, the paper outlines the contours of a global AI accountability and compensation architecture, emphasizing the tension between geopolitical rivalry and the collective action required to govern transboundary AI risks effectively.

</details>


### [160] [Ethical Risks in Deploying Large Language Models: An Evaluation of Medical Ethics Jailbreaking](https://arxiv.org/abs/2601.12652)
*Chutian Huang,Dake Cao,Jiacheng Ji,Yunlou Fan,Chengze Yan,Hanhui Xu*

Main category: cs.CY

TL;DR: 该研究针对中文医疗伦理领域，建立了专门的越狱攻击评估框架，测试了7个主流大语言模型在医疗伦理场景下的安全防御能力，发现模型普遍存在严重漏洞，攻击成功率高达82.1%。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全评估主要关注公共安全和西方文化规范，缺乏针对中文医疗伦理这一高风险专业领域的越狱攻击评估。医疗伦理问题具有文化敏感性和高风险性，需要专门的评估框架来检验模型的安全防御能力。

Method: 采用DeepInception框架，结合"角色扮演+场景模拟+多轮对话"策略，对7个主流模型（如GPT-5、Claude-Sonnet-4-Reasoning、DeepSeek-R1等）进行测试。测试涵盖8个高风险主题（如商业代孕、器官交易），使用分层评分矩阵量化攻击成功率和增益。

Result: 模型防御系统普遍崩溃：虽然模型基线合规性较高，但越狱攻击成功率高达82.1%，攻击增益超过80个百分点。Claude-Sonnet-4-Reasoning表现最稳健，而包括Gemini-2.5-Pro和GPT-4.1在内的5个模型几乎完全失效，攻击成功率在96%-100%之间。

Conclusion: 当前大语言模型在医疗伦理场景下对上下文操纵高度脆弱，往往优先考虑"帮助性"而非安全约束。建议从结果监督转向过程监督，实施多因素身份验证，并建立跨模型的"联合防御"机制来增强安全性。

Abstract: Background: While Large Language Models (LLMs) have achieved widespread adoption, malicious prompt engineering specifically "jailbreak attacks" poses severe security risks by inducing models to bypass internal safety mechanisms. Current benchmarks predominantly focus on public safety and Western cultural norms, leaving a critical gap in evaluating the niche, high-risk domain of medical ethics within the Chinese context. Objective: To establish a specialized jailbreak evaluation framework for Chinese medical ethics and to systematically assess the defensive resilience and ethical alignment of seven prominent LLMs when subjected to sophisticated adversarial simulations. Methodology: We evaluated seven prominent models (e.g., GPT-5, Claude-Sonnet-4-Reasoning, DeepSeek-R1) using a "role-playing + scenario simulation + multi-turn dialogue" vector within the DeepInception framework. The testing focused on eight high-risk themes, including commercial surrogacy and organ trading, utilizing a hierarchical scoring matrix to quantify the Attack Success Rate (ASR) and ASR Gain. Results: A systemic collapse of defenses was observed, whereas models demonstrated high baseline compliance, the jailbreak ASR reached 82.1%, representing an ASR Gain of over 80 percentage points. Claude-Sonnet-4-Reasoning emerged as the most robust model, while five models including Gemini-2.5-Pro and GPT-4.1 exhibited near-total failure with ASRs between 96% and 100%. Conclusions: Current LLMs are highly vulnerable to contextual manipulation in medical ethics, often prioritizing "helpfulness" over safety constraints. To enhance security, we recommend a transition from outcome to process supervision, the implementation of multi-factor identity verification, and the establishment of cross-model "joint defense" mechanisms.

</details>


### [161] [How do the Global South Diasporas Mobilize for Transnational Political Change?](https://arxiv.org/abs/2601.12705)
*Dipto Das,Afrin Prio,Pritu Saha,Shion Guha,Syed Ishtiaque Ahmed*

Main category: cs.CY

TL;DR: 该研究探讨了海外孟加拉人如何利用社交媒体和侨汇抵制，在2024年配额改革引发的民主运动中挑战国家权威，提出了"侨民叠加态"概念来解释其跨国政治经济影响力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解海外侨民如何通过数字技术和经济手段参与母国政治变革，挑战传统侨民研究中的"融入"叙事，揭示跨国行动主义与数字技术在全球南方政治变革中的交叉作用。

Method: 采用半结构化访谈方法，分析海外孟加拉人在2024年运动中的集体行动，识别出四个阶段的行动模式：技术中介的参与转变、跨国网络快速构建、侨汇抵制战略执行、以及应对政府监控和信息封锁的适应性反应。

Result: 研究发现海外侨民通过"侨民叠加态"这一混合位置性，既能挑战又能复杂化权力不对称关系；他们通过重新构建经济依赖为政治杠杆，利用金融技术与道德关怀经济、国家监控、监管约束和不平等的国际经济权力动态相互作用。

Conclusion: 该研究扩展了后殖民计算理论，重新构建了侨民参与的政治维度，推进了金融技术研究，为理解跨国行动主义与数字技术如何在全球南方背景下动员政治变革提供了理论框架。

Abstract: This paper examines how non-resident Bangladeshis mobilized during the 2024 quota-reform turned pro-democracy movement, leveraging social platforms and remittance flows to challenge state authority. Drawing on semi-structured interviews, we identify four phases of their collective action: technology-mediated shifts to active engagement, rapid transnational network building, strategic execution of remittance boycott, reframing economic dependence as political leverage, and adaptive responses to government surveillance and information blackouts. We extend postcolonial computing by introducing the idea of "diasporic superposition," which shows how diasporas can exercise political and economic influence from hybrid positionalities that both contest and complicate power asymmetries. We reframe diaspora engagement by highlighting how migrants participate in and reshape homeland politics, beyond narratives of integration in host countries. We advance the scholarship on financial technologies by foregrounding their relationship with moral economies of care, state surveillance, regulatory constraints, and uneven international economic power dynamics. Together, these contributions theorize how transnational activism and digital technologies intersect to mobilize political change in Global South contexts.

</details>


### [162] [The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality](https://arxiv.org/abs/2601.12938)
*Thorsten Jelinek,Patrick Glauner,Alvin Wang Graylin,Yubao Qiu*

Main category: cs.CY

TL;DR: 论文提出PRMO框架分析AI设计轨迹对人类主体性的影响，关注AI自动化意义形成过程可能导致人类被边缘化的风险，提出"四角化"设计原则确保人类在意义形成中的核心地位。


<details>
  <summary>Details</summary>
Motivation: 在后图灵时代，人工智能越来越多地塑造社会协调和意义形成，而不仅仅是自动化认知任务。核心挑战不再是机器是否具有意识，而是解释和共享参照的过程是否以逐渐自动化方式边缘化人类参与。论文旨在分析AI设计轨迹如何影响人类主体性的四个构成维度。

Method: 论文引入PRMO框架，将AI设计轨迹与人类主体性的四个构成维度联系起来：感知、表征、意义和实在。在此基础上提出"合成社会性"概念，描述人工代理主要在彼此之间协商一致性和社会秩序的技术前景。为应对人类被排除在意义形成之外的结构性风险，提出"四角化"作为社会嵌入式AI系统的设计原则。

Result: 论文提供了一个概念性视角和结构词汇表，用于分析计算与社会交叉领域的AI系统。PRMO框架为理解AI如何影响人类主体性提供了分析工具，"四角化"原则为解决人类被边缘化风险提供了设计方向。论文没有提出具体技术实现，而是贡献了概念框架。

Conclusion: 在后图灵时代，AI设计需要关注人类主体性的保护。"合成社会性"可能导致人类被排除在意义形成之外，而"四角化"设计原则要求人工代理将人类主体视为共享意义语境中的构成性参照。这为分析AI系统在计算与社会交叉领域的影响提供了重要概念工具。

Abstract: In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is therefore not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning. This work is a conceptual perspective that contributes a structural vocabulary for analyzing AI systems at the intersection of computation and society, without proposing a specific technical implementation.

</details>


### [163] [AI-generated data contamination erodes pathological variability and diagnostic reliability](https://arxiv.org/abs/2601.12946)
*Hongyu He,Shaowen Xiang,Ye Zhang,Yingtao Zhu,Jin Zhang,Hao Deng,Emily Alsentzer,Qingyu Chen,Kun-Hsing Yu,Andrew Marmenshall,Tingting Chen,Srinivas Anumasa,Daniel Ebner,Dean Ho,Kee Yuan Ngiam,Ching-Yu Cheng,Dianbo Liu*

Main category: cs.CY

TL;DR: 生成式AI在医疗记录中产生合成内容，形成反馈循环，导致模型训练数据污染，造成病理变异性和诊断可靠性迅速退化，罕见关键发现消失，虚假诊断信心掩盖了准确性下降。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在医疗记录中快速产生合成内容，形成自我参照循环，未来模型面临训练数据被AI生成内容污染的风险，但这种现象的临床后果尚未被探索。

Method: 分析了超过80万个合成数据点，涵盖临床文本生成、视觉语言报告和医学图像合成，评估了三种缓解策略：合成数据规模扩展、真实数据混合和质量感知过滤。

Result: 在没有强制人工验证的情况下，自我参照循环导致病理变异性和诊断可靠性迅速退化。罕见但关键的发现（如气胸和积液）从AI生成的合成内容中消失，人口统计表示偏向中年男性表型。虚假诊断信心掩盖了退化，虚假保证率增加三倍至40%。盲法医师评估证实，仅两代后AI生成的文档就变得临床无用。

Conclusion: 如果没有政策强制的人工监督，生成式AI的部署可能会破坏其依赖的医疗数据生态系统。真实数据混合与质量感知过滤能有效保持多样性，而单纯扩大合成数据规模无法防止系统崩溃。

Abstract: Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.

</details>


### [164] [ACE-Align: Attribute Causal Effect Alignment for Cultural Values under Varying Persona Granularities](https://arxiv.org/abs/2601.12962)
*Jiatang Luo,Bingbing Xu,Rongxin Chen,Xiaoyan Zhao,Yang Zhang,Liang Pang,Zhiyong Huang,Tat-Seng Chua,Huawei Shen*

Main category: cs.CY

TL;DR: ACE-Align是一个因果效应框架，通过将特定人口属性对不同文化价值观的影响对齐，而不是将每个文化视为同质群体，来解决LLM文化对齐中的组内异质性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将文化群体视为同质的，忽视了由交叉人口属性引起的组内异质性，导致在不同人设粒度下行为不稳定。需要一种能处理文化价值观中人口属性异质性影响的方法。

Method: 提出ACE-Align（属性因果效应对齐）框架，将对齐重点放在特定人口属性如何影响不同文化价值观上，而不是将每个文化视为同质群体。使用性别、教育、居住地、婚姻状况等四个属性来定义人设，通过指定属性的数量来实例化粒度。

Result: 在跨越五大洲14个国家的评估中，ACE-Align在所有人物粒度上都持续优于基线方法。将高资源和低资源地区之间的平均对齐差距从9.81点减少到4.92点，提高了地理公平性，其中非洲显示出最大的平均增益（+8.48点）。

Conclusion: ACE-Align通过因果效应框架有效解决了文化对齐中的组内异质性问题，提高了LLM在不同文化背景下的公平性和稳定性，特别是在资源较少地区表现突出。

Abstract: Ensuring that large language models (LLMs) respect diverse cultural values is crucial for social equity. However, existing approaches often treat cultural groups as homogeneous and overlook within-group heterogeneity induced by intersecting demographic attributes, leading to unstable behavior under varying persona granularity. We propose ACE-Align (Attribute Causal Effect Alignment), a causal-effect framework that aligns how specific demographic attributes shift different cultural values, rather than treating each culture as a homogeneous group. We evaluate ACE-Align across 14 countries spanning five continents, with personas specified by subsets of four attributes (gender, education, residence, and marital status) and granularity instantiated by the number of specified attributes. Across all persona granularities, ACE-Align consistently outperforms baselines. Moreover, it improves geographic equity by reducing the average alignment gap between high-resource and low-resource regions from 9.81 to 4.92 points, while Africa shows the largest average gain (+8.48 points). Code is available at https://github.com/Wells-Luo/ACE-Align.

</details>


### [165] [Influence of Normative Theories of Ethics on the European Union Artificial Intelligence Act: A Transformer-Based Analysis Using Semantic Textual Similarity](https://arxiv.org/abs/2601.13372)
*Mehmet Murat Albayrakoglu,Mehmet Nafiz Aydin*

Main category: cs.CY

TL;DR: 使用语义文本相似性分析欧盟AI法案与三大伦理理论的对齐程度，发现义务论伦理影响最大


<details>
  <summary>Details</summary>
Motivation: 尽管欧盟AI法案被视为AI监管的重要一步并强调基本权利，但其伦理基础仍面临道德批评。本研究旨在通过分析规范性伦理理论与监管语言的对齐程度，评估法案的伦理基础。

Method: 将欧盟AI法案分为序言和法定条款两部分，分别代表意图性和操作性伦理一致性。手动预处理三大伦理理论（美德伦理、义务论伦理、后果主义）的文本描述以减少语义重叠。采用异构嵌入级集成方法，使用五个基于Transformer架构的改进BERT模型计算语义文本相似性得分，通过投票和平均评估相似性分数。

Result: 语义相似性分析表明，义务论伦理对欧盟AI法案的整体影响最为显著，美德伦理和后果主义的影响相对较小。

Conclusion: 欧盟AI法案在伦理基础上主要受到义务论伦理的影响，这为理解法案的伦理取向提供了实证依据，也为未来AI监管的伦理评估提供了方法论框架。

Abstract: This study investigates the ethical grounding of the European Union Artificial Intelligence (EU AI) Act by using Semantic Textual Similarity (STS) to analyze the alignment between normative ethical theories and regulatory language. Despite being regarded as a significant step toward regulating Artificial Intelligence (AI) systems and its emphasis on fundamental rights, the EU AI Act is not immune to moral criticism regarding its ethical foundations. Our work examines the impact of three major normative theories of ethics, virtue ethics, deontological ethics, and consequentialism, on the EU AI Act. We introduce the concept of influence, grounded in philosophical and chronological analysis, to examine the underlying relationship between the theories and the Act. As a proxy measure of this influence, we propose using STS to quantify the degree of alignment between the theories (influencers) and the Act (influencee). To capture intentional and operational ethical consistency, the Act was divided into two parts: the preamble and the statutory provisions. The textual descriptions of the theories were manually preprocessed to reduce semantic overlap and ensure a distinct representation of each theory. A heterogeneous embedding-level ensemble approach was employed, using five modified Bidirectional Encoder Representations from Transformers (BERT) models built on the Transformer architecture to compute STS scores. These scores reflect the semantic alignment between various theories of ethics and the two components of the EU AI Act. The resulting similarity scores were evaluated using voting and averaging, with findings indicating that deontological ethics has the most significant overall influence.

</details>


### [166] [Sticky Help, Bounded Effects: Session-by-Session Analytics of Teacher Interventions in K-12 Classrooms](https://arxiv.org/abs/2601.13520)
*Qiao Jin,Conrad Borchers,Ashish Gurung,Sean Jackson,Sameeksha Agarwal,Cancan Wang,YiChen Yu,Pragati Maheshwary,Vincent Aleven*

Main category: cs.CY

TL;DR: 研究发现教师帮助具有"粘性"特征：先前获得帮助的学生更可能再次获得帮助，但帮助的学习效益主要局限于当前课堂，未能预测后续技能掌握。


<details>
  <summary>Details</summary>
Motivation: 在技术支持的课堂中，教师的即时支持是有限资源，需要决定何时帮助哪些学生。然而，教师决策如何受学生先前帮助历史和当前参与状态影响，以及教师帮助的学习效益是否延伸到当前课堂之外，这些问题尚不清楚。

Method: 首先访谈9名K-12数学教师识别决策因素，然后分析MATHia智能辅导系统中339名学生140万次学生-系统交互数据，将教师记录的帮助事件与细粒度参与状态关联，使用混合效应模型和交叉滞后面板分析。

Result: 1) 先前获得帮助的学生更可能再次获得帮助，即使考虑当前参与状态；2) 教师帮助在跨课程中重复出现，而空闲行为未获得持续关注；3) 帮助与课堂内即时学习相关，但未能预测后续课程的技能掌握。

Conclusion: 教师帮助具有"粘性"特征，倾向于重复帮助先前支持过的学生，而其可测量的学习效益主要局限于当前课堂。需要设计实时分析工具跟踪注意力覆盖，突出未充分关注的学生，以实现更公平有效的教师注意力分配。

Abstract: Teachers' in-the-moment support is a limited resource in technology-supported classrooms, and teachers must decide whom to help and when during ongoing student work. However, less is known about how students' prior help history (whether they were helped earlier) and their engagement states (e.g., idle, struggle) shape teachers' decisions, and whether observed learning benefits associated with teacher help extend beyond the current class session. To address these questions, we first conducted interviews with nine K-12 mathematics teachers to identify candidate decision factors for teacher help. We then analyzed 1.4 million student-system interactions from 339 students across 14 classes in the MATHia intelligent tutoring system by linking teacher-logged help events with fine-grained engagement states. Mixed-effects models show that students who received help earlier were more likely to receive additional help later, even after accounting for current engagement state. Cross-lagged panel analyses further show that teacher help recurred across sessions, whereas idle behavior did not receive sustained attention over time. Finally, help coincided with immediate learning within sessions, but did not predict skill acquisition in later sessions, as estimated by additive factor modeling. These findings suggest that teacher help is "sticky" in that it recurs for previously supported students, while its measurable learning benefits in our data are largely session-bound. We discuss implications for designing real-time analytics that track attention coverage and highlight under-visited students to support a more equitable and effective allocation of teacher attention.

</details>


### [167] [Impact Matters! An Audit Method to Evaluate AI Projects and their Impact for Sustainability and Public Interest](https://arxiv.org/abs/2601.13936)
*Theresa Züger,Laura State,Lena Winter*

Main category: cs.CY

TL;DR: 提出Impact-AI方法，一种基于公共利益和可持续性框架的定性审计方法，用于评估AI项目的实际社会影响


<details>
  <summary>Details</summary>
Motivation: 当前AI"向善"项目缺乏透明度，缺少对社会和地球实际影响的评估，需要建立可操作的评估框架

Method: 提出公共利益和可持续性的双重监管概念框架，开发基于访谈的Impact-AI定性审计方法，包括治理结构、变革理论、AI模型和数据特征、社会环境影响评估

Result: 开发了可重复使用的Impact-AI方法蓝图，包含评估标准目录，支持公民社会广泛讨论，已在跨学科研究中与NGO和多利益相关方研究委员会合作开发

Conclusion: Impact-AI方法为AI"向善"主张提供透明度，支持公正和可持续发展的AI系统评估，促进公众辩论和问责

Abstract: The overall rapid increase of artificial intelligence (AI) use is linked to various initiatives that propose AI 'for good'. However, there is a lack of transparency in the goals of such projects, as well as a missing evaluation of their actual impacts on society and the planet. We close this gap by proposing public interest and sustainability as a regulatory dual-concept, together creating the necessary framework for a just and sustainable development that can be operationalized and utilized for the assessment of AI systems. Based on this framework, and building on existing work in auditing, we introduce the Impact-AI-method, a qualitative audit method to evaluate concrete AI projects with respect to public interest and sustainability. The interview-based method captures a project's governance structure, its theory of change, AI model and data characteristics, and social, environmental, and economic impacts. We also propose a catalog of assessment criteria to rate the outcome of the audit as well as to create an accessible output that can be debated broadly by civil society. The Impact-AI-method, developed in a transdisciplinary research setting together with NGOs and a multi-stakeholder research council, is intended as a reusable blueprint that both informs public debate about AI 'for good' claims and supports the creation of transparency of AI systems that purport to contribute to a just and sustainable development.

</details>


### [168] [Analyzing Far-Right Telegram Channels as Constituents of Information Autocracy in Russia](https://arxiv.org/abs/2601.14190)
*Polina Smirnova,Mykola Makhortykh*

Main category: cs.CY

TL;DR: 俄罗斯极右翼Telegram社区通过表情包和视觉叙事塑造政治人物形象，作为宣传共生产者，混合国家信息与极端主义框架，为乌克兰战争提供意识形态基础。


<details>
  <summary>Details</summary>
Motivation: 研究俄罗斯极右翼Telegram社区如何通过表情包和视觉叙事塑造政治人物认知，这些群体在俄罗斯信息专制中作为宣传共生产者，为乌克兰战争提供意识形态基础，反映政权向极端民族主义话语的逐渐漂移。

Method: 使用计算机视觉和无监督聚类分析20万张来自专家选定的极右翼Telegram频道的图像，识别包含俄罗斯（普京、绍伊古）和外国（泽连斯基、拜登、特朗普）政治人物的表情包，揭示其表征中的重复视觉模式。

Result: 极右翼表情包作为宣传共生产工具，这些社区不仅重复官方信息，还生成自下而上的合法化和非法化叙事，与国家意识形态保持一致。通过将领导人描绘为英雄、对手描绘为腐败或软弱，极右翼行为者成为俄罗斯信息专制中非正式的威权合法性共同创造者。

Conclusion: 俄罗斯极右翼Telegram社区通过表情包视觉叙事积极参与宣传共生产，生成与国家意识形态一致的自下而上叙事，塑造政治人物认知，为威权政权提供非正式的合法性支持，这在较小规模研究中无法获得。

Abstract: This study examines how Russian far-right communities on Telegram shape perceptions of political figures through memes and visual narratives. Far from passive spectators, these actors co-produce propaganda, blending state-aligned messages with their own extremist framings. In Russia, such groups are central because they articulate the ideological foundations of the war against Ukraine and reflect the regime's gradual drift toward ultranationalist rhetoric. Drawing on a dataset of 200,000 images from expert-selected far-right Telegram channels, the study employs computer vision and unsupervised clustering to identify memes featuring Russian (Putin, Shoigu) and foreign politicians (Zelensky, Biden, Trump) and to reveal recurrent visual patterns in their representation. By leveraging the large-scale and temporal depth of this dataset, the analysis uncovers differential patterns of legitimation and delegitimation across actors and over time. These insights are not attainable in smaller-scale studies. Preliminary findings show that far-right memes function as instruments of propaganda co-production. These communities do not simply echo official messages but generate bottom-up narratives of legitimation and delegitimation that align with state ideology. By framing leaders as heroic and opponents as corrupt or weak, far-right actors act as informal co-creators of authoritarian legitimacy within Russia's informational autocracy.

</details>
