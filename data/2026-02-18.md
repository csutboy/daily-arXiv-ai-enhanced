<div id=toc></div>

# Table of Contents

- [cs.SI](#cs.SI) [Total: 2]
- [stat.AP](#stat.AP) [Total: 4]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.ET](#cs.ET) [Total: 5]
- [econ.EM](#econ.EM) [Total: 2]
- [cs.CY](#cs.CY) [Total: 8]


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [1] [The geometry of online conversations and the causal antecedents of conflictual discourse](https://arxiv.org/abs/2602.15600)
*Carlo Santagiustina,Caterina Cruciani*

Main category: cs.SI

TL;DR: 研究在线气候讨论中冲突性语言的因果前因和互动几何，发现回复延迟、对话结构和分支特征影响话语冲突的三个维度（立场、语气、情感/事实框架）


<details>
  <summary>Details</summary>
Motivation: 研究在线线程对话中冲突性语言的形成机制，特别是时间延迟、对话结构和树状分支如何影响话语冲突的不同维度（立场、语气、情感框架）

Method: 使用LLM提示和平均推断三个注释维度（立场：同意/不同意；语气：攻击/尊重；情感/事实框架），分析在线论坛线程数据，考察时间、对话和树状结构特征的影响

Result: 1) 线程内连续帖子间延迟越长，回复越尊重；相对于父帖延迟越长，分歧略少但更情感化。2) 存在强烈的局部对话环境对齐效应，既向回复同一父帖的兄弟帖平均特征收敛，也向父帖本身收敛，父帖效应通常更强。3) 早期分支级响应调节对齐动态，分支起始时与根消息的立场影响父子立场对齐程度

Conclusion: 在线讨论中的话语冲突受时间延迟、对话结构和分支特征的系统性影响，不同冲突维度（文明相关vs情感框架）受这些因素影响的方式不同，为理解在线互动动态提供了新见解

Abstract: This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.

</details>


### [2] [SVD Incidence Centrality: A Unified Spectral Framework for Node and Edge Analysis in Directed Networks and Hypergraphs](https://arxiv.org/abs/2602.15736)
*Jorge Luiz Franco,Thomas Peron,Alcebiades Dal Col,Fabiano Petronetto,Filipe Alves Neto Verri,Eric K. Tokuda,Luiz Gustavo Nonato*

Main category: cs.SI

TL;DR: 提出基于奇异值分解的统一谱框架，用于有向网络的中心性分析，克服传统方法的方向信息丢失和稀疏排名问题。


<details>
  <summary>Details</summary>
Motivation: 现有中心性度量存在关键局限：要么通过对称化丢弃方向信息，要么产生稀疏、依赖实现的排名，从而模糊结构重要性。需要一种能自然保留方向信息并提供密集排名的统一方法。

Method: 基于关联矩阵的奇异值分解，通过Hodge拉普拉斯算子的伪逆推导顶点和边中心性，形成统一的谱框架。该方法自然扩展到超图，保持数学一致性。

Result: 该方法产生密集且分辨率良好的排名，克服了有向图中介中心性常见的稀疏性限制。在真实世界网络上的实验验证了该框架在不同领域的有效性。

Conclusion: 提出的谱框架为有向网络中心性分析提供了统一方法，自然保留方向信息，产生密集排名，克服了传统度量的局限性，并扩展到超图分析。

Abstract: Identifying influential nodes and edges in directed networks remains a fundamental challenge across domains from social influence to biological regulation. Most existing centrality measures face a critical limitation: they either discard directional information through symmetrization or produce sparse, implementation-dependent rankings that obscure structural importance. We introduce a unified spectral framework for centrality analysis in directed networks grounded in the Singular value decomposition of the incidence matrix. The proposed approach derives both vertex and edge centralities via the pseudoinverse of Hodge Laplacians, yielding dense and well-resolved rankings that overcome the sparsity limitations commonly observed in betweenness centrality for directed graphs. Unlike traditional measures that require graph symmetrization, our framework naturally preserves directional information, enabling principled hub/authority analysis while maintaining mathematical consistency through spectral graph theory. The method extends naturally to hypergraphs through the same mathematical foundation. Experimental validation on real-world networks demonstrates the framework's effectiveness across diverse domains where traditional centrality measures encounter limitations due to implementation dependencies and sparse outputs.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [3] [From Chain-Ladder to Individual Claims Reserving](https://arxiv.org/abs/2602.15385)
*Ronald Richman,Mario V. Wüthrich*

Main category: stat.AP

TL;DR: 提出一种新的链梯法准备金计算方法，通过直接估计多期因子将最新观测值投影至最终赔款，为机器学习技术在个体赔款准备金中的应用提供自然路径。


<details>
  <summary>Details</summary>
Motivation: 链梯法是财险中最广泛使用的准备金技术，但传统方法通过滚动累计赔款和估计链梯因子来计算准备金。本文旨在通过重构数据利用方式，为机器学习技术在个体赔款准备金中的应用创造机会。

Method: 提出新的链梯法计算方法：不通过估计链梯因子滚动累计赔款，而是估计多期因子，直接将最新观测值投影至最终赔款。这种替代视角为机器学习技术应用提供了自然路径，并以神经网络在个体赔款准备金中的小规模实际数据应用作为概念验证。

Result: 提出了基于多期因子直接投影的链梯法新计算方法，成功展示了神经网络在个体赔款准备金中的应用可行性，为机器学习技术在保险准备金领域的应用开辟了新途径。

Conclusion: 通过重构链梯法的数据利用方式，提出了一种新的准备金计算方法，不仅改进了传统链梯法，更重要的是为机器学习技术在个体赔款准备金中的应用提供了自然框架，具有重要的理论和实践意义。

Abstract: The chain-ladder (CL) method is the most widely used claims reserving technique in non-life insurance. This manuscript introduces a novel approach to computing the CL reserves based on a fundamental restructuring of the data utilization for the CL prediction procedure. Instead of rolling forward the cumulative claims with estimated CL factors, we estimate multi-period factors that project the latest observations directly to the ultimate claims. This alternative perspective on CL reserving creates a natural pathway for the application of machine learning techniques to individual claims reserving. As a proof of concept, we present a small-scale real data application employing neural networks for individual claims reserving.

</details>


### [4] [Deep description of static and dynamic network ties in Honduran villages](https://arxiv.org/abs/2602.15429)
*Marios Papamichalis,Nikolaos Nakis,Nicholas A. Christakis*

Main category: stat.AP

TL;DR: 研究通过2016和2019年两波数据，分析了洪都拉斯176个村庄中20,232人的多维度社会网络动态，发现性别和宗教在健康与财务网络中呈现显著的同质性，且教育、财务因素随时间对社交关系的影响增强。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解农村环境中个人属性和社区特征如何共同影响社会网络的形成与动态变化，特别是合作与冲突关系如何共同塑造社会结构，为理解农村社会经济发展提供实证基础。

Method: 使用两波纵向调查数据（2016、2019），涵盖友谊、健康建议、财务帮助和敌对关系等多维度网络。采用混合效应零膨胀负二项模型分析个体属性（性别、婚姻、教育、宗教、原住民身份）和村庄特征对网络动态的影响，辅以配对同质性和社区层面指标分析。

Result: 发现性别和宗教在健康与财务网络中呈现显著的同质性配对；性别和宗教在所有网络类型中表现出最一致的同质性混合；社区层面的同质性指标显示教育和财务因素随时间对社交关系的影响逐渐增强。

Conclusion: 个人属性和社区动态共同塑造农村社会网络的形成和社会经济关系，性别和宗教是网络同质性的关键因素，而教育和财务因素随时间的重要性增加，为理解农村社会结构演变提供了重要见解。

Abstract: We examine static and dynamic social network structure in 176 villages within the Copan Department of Honduras across two data waves (2016, 2019), using detailed data on multiplex networks for 20,232 individuals enrolled in a longitudinal survey. These networks capture friendship, health advice, financial help, and adversarial relationships, allowing us to show how cooperation and conflict jointly shape social structure. Using node-level network measures derived from near-census sociocentric village networks, we leverage mixed-effects zero-inflated negative binomial models to assess the influence of individual attributes, such as gender, marital status, education, religion, and indigenous status, and of village characteristics, on the dynamics of social networks over time. We complement these node-level models with dyadic assortativity (odds-ratio-based homophily) and community-level measures to describe how sorting by key attributes differs across network types and between waves. Our results demonstrate significant assortativity based on gender and religion, particularly within health and financial networks. Across networks, gender and religion exhibit the most consistent assortative mixing. Additionally, community-level assortativity metrics indicate that educational and financial factors increasingly influence social ties over time. Our findings provide insights into how personal attributes and community dynamics interact to shape network formation and socio-economic relationships in rural settings over time.

</details>


### [5] [Reproducibility and Statistical Methodology](https://arxiv.org/abs/2602.15697)
*Anthony Almudevar,Jacob Almudevar*

Main category: stat.AP

TL;DR: 对2015年OSC心理学可重复性研究的批判性分析，指出其方法存在偏差，并主张在科学研究中需要平衡假阳性和假阴性错误率


<details>
  <summary>Details</summary>
Motivation: OSC 2015年的研究声称心理学领域大量已发表结果不可重复，这一结论对心理学科学产生了深远影响。本文旨在重新审视这一主张，分析其方法学问题，并探讨科学研究中可重复性的更平衡观点。

Method: 1. 对OSC研究方法的扩展分析，揭示其方法学偏差；2. 文献综述，比较OSC研究与其他更乐观的可重复性估计；3. 理论讨论，分析假阳性和假阴性错误率在科学研究中的平衡。

Result: 1. OSC方法本身存在偏差，能够解释其与其他研究在可重复性估计上的差异；2. 科学研究的可重复性评估需要更全面的视角；3. 单纯关注假阳性率而忽视假阴性率是不科学的。

Conclusion: 科学研究需要平衡假阳性和假阴性错误率，而不是片面强调假阳性控制。OSC研究的方法学偏差使其结论需要谨慎对待，科学可重复性的讨论需要更全面的方法论和伦理考量。

Abstract: In 2015 the Open Science Collaboration (OSC) (Nosek et al 2015) published a highly influential paper which claimed that a large fraction of published results in the psychological sciences were not reproducible. In this article we review this claim from several points of view. We first offer an extended analysis of the methods used in that study. We show that the OSC methodology induces a bias that is able by itself to explain the discrepancy between the OSC estimates of reproducibility and other more optimistic estimates made by similar studies.
  The article also offers a more general literature review and discussion of reproducibility in experimental science. We argue, for both scientific and ethical reasons, that a considered balance of false positive and false negative rates is preferable to a single-minded concentration on false positive rates alone.

</details>


### [6] [Decision Quality Evaluation Framework at Pinterest](https://arxiv.org/abs/2602.15809)
*Yuqi Tian,Robert Paine,Attila Dobi,Kevin O'Sullivan,Aravindh Manickavasagam,Faisal Farooq*

Main category: stat.AP

TL;DR: Pinterest开发了一个决策质量评估框架，使用专家标注的黄金数据集和智能采样管道，用于评估内容安全系统的质量，支持LLM代理评估、提示优化、政策演进和指标验证。


<details>
  <summary>Details</summary>
Motivation: 在线平台需要在大规模执行内容安全政策时评估审核决策质量，但面临成本、规模和可信度之间的权衡挑战，以及政策演变的复杂性。

Method: 开发了以专家标注的黄金数据集为核心的决策质量评估框架，引入基于倾向得分的智能采样管道扩展数据集覆盖，支持LLM代理基准测试、数据驱动的提示优化、政策演进管理和指标验证。

Result: 该框架实现了从主观评估向数据驱动、量化实践的转变，能够有效评估各种LLM代理的成本性能权衡，优化提示策略，管理复杂政策演变，并验证政策内容流行度指标的完整性。

Conclusion: 提出的框架为内容安全系统管理提供了可靠的数据驱动评估方法，解决了大规模内容审核中的质量评估挑战，支持平台持续改进内容安全实践。

Abstract: Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed and deployed at Pinterest. The framework is centered on a high-trust Golden Set (GDS) curated by subject matter experts (SMEs), which serves as a ground truth benchmark. We introduce an automated intelligent sampling pipeline that uses propensity scores to efficiently expand dataset coverage. We demonstrate the framework's practical application in several key areas: benchmarking the cost-performance trade-offs of various LLM agents, establishing a rigorous methodology for data-driven prompt optimization, managing complex policy evolution, and ensuring the integrity of policy content prevalence metrics via continuous validation. The framework enables a shift from subjective assessments to a data-driven and quantitative practice for managing content safety systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis](https://arxiv.org/abs/2602.15067)
*Rut Pate,Snehal Rajput,Mehul S. Raval,Rupal A. Kapdi,Mohendra Roy*

Main category: cs.AI

TL;DR: 提出基于注意力门控循环残差U-Net的三平面(2.5D)模型，用于脑肿瘤分割和生存预测，在BraTS2021验证集上获得0.900的Dice分数


<details>
  <summary>Details</summary>
Motivation: 胶质瘤作为最常见的原发性脑肿瘤，具有侵袭性、预后和组织学特征差异大的特点，治疗挑战大，手术干预复杂耗时，需要更好的分割方法辅助治疗规划

Method: 提出注意力门控循环残差U-Net(R2U-Net)三平面(2.5D)模型，整合残差、循环和三平面架构增强特征表示；使用人工神经网络(ANN)将64个特征减少到28个进行生存天数预测

Result: 在BraTS2021验证集上，全肿瘤分割Dice相似性分数达到0.900；生存预测准确率45.71%，均方误差108,318.128，Spearman秩相关系数0.338

Conclusion: 该方法在保持计算效率的同时提高了特征表示和分割精度，性能与领先模型相当，有助于改善治疗规划

Abstract: Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, and triplanar architectures while maintaining computational efficiency, potentially aiding in better treatment planning. The proposed method achieves a Dice Similarity Score (DSC) of 0.900 for Whole Tumor (WT) segmentation on the BraTS2021 validation set, demonstrating performance comparable to leading models. Additionally, the triplanar network extracts 64 features per planar model for survival days prediction, which are reduced to 28 using an Artificial Neural Network (ANN). This approach achieves an accuracy of 45.71%, a Mean Squared Error (MSE) of 108,318.128, and a Spearman Rank Correlation Coefficient (SRC) of 0.338 on the test dataset.

</details>


### [8] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: ResearchGym是一个评估AI智能体端到端研究能力的基准测试环境，基于5篇顶会论文构建了39个子任务，发现前沿AI智能体存在能力-可靠性差距，偶尔能达到SOTA但表现不稳定。


<details>
  <summary>Details</summary>
Motivation: 需要系统评估AI智能体在完整研究流程中的能力，包括提出假设、运行实验、超越人类基线等，但目前缺乏这样的基准测试环境。

Method: 基于ICML、ICLR、ACL的5篇口头报告和焦点论文，保留数据集、评估框架和基线实现，但隐藏论文提出的方法，构建了5个容器化任务环境共39个子任务。

Result: GPT-5智能体仅在15次评估中的1次（6.7%）超越基线11.5%，平均只完成26.5%的子任务。发现长期失败模式包括缺乏耐心、资源管理差、对弱假设过度自信等。但在单次运行中成功超越了一个ICML 2025焦点任务的解决方案。

Conclusion: 前沿AI智能体偶尔能达到SOTA研究性能，但存在显著的能力-可靠性差距。ResearchGym为自主智能体的闭环研究提供了系统评估和分析的基础设施。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [9] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该论文研究如何通过修改教师模型的推理输出来防止未经授权的知识蒸馏，提出了既能降低训练效果又能嵌入可验证水印的方法。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏被广泛用于将大语言模型能力转移到更小的学生模型，但未经授权的蒸馏利用了他人的开发成果和成本，需要技术手段来防止这种不公平使用。

Method: 提出了动态重写教师模型推理输出的方法，包括基于LLM的重写方法和基于梯度的技术，在保持答案正确性和语义连贯性的同时实现反蒸馏和API水印嵌入。

Result: 简单的基于指令的重写方法能有效实现反蒸馏效果，同时保持甚至提升教师模型性能；重写方法还能实现高可靠的水印检测，几乎没有误报。

Conclusion: 通过重写推理输出可以有效防止未经授权的知识蒸馏，同时保持模型性能，为保护大语言模型知识产权提供了实用技术方案。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [10] [Panini: Continual Learning in Token Space via Structured Memory](https://arxiv.org/abs/2602.15156)
*Shreyas Rajesh,Pavan Holur,Mehmet Yigit Turali,Chenda Duan,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: Panini提出了一种非参数持续学习框架，将文档表示为生成语义工作空间（GSW）——一个实体和事件感知的问答对网络，通过推理链进行知识检索，相比传统RAG方法更高效准确。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）方法存在两个主要问题：1）测试时计算效率低下（LLM重复处理相同文档）；2）块检索可能引入不相关上下文，增加无依据生成。需要一种更高效、更可靠的持续学习框架来处理新文档和知识。

Method: 提出Panini框架，将文档表示为生成语义工作空间（GSW）——实体和事件感知的问答对网络。基础模型保持不变，学习通过将每个新经验整合到外部语义记忆状态中实现。给定查询时，仅遍历持续更新的GSW，检索最可能的推理链。

Result: 在六个QA基准测试中，Panini实现了最高的平均性能，比其他竞争基线高出5%-7%，同时使用2-30倍更少的答案上下文标记，支持完全开源管道，并在精心策划的不可回答查询上减少了无依据答案。

Conclusion: 在写入时高效准确地结构化经验（如GSW框架所实现的）在读取时既提高了效率又增强了可靠性。该方法展示了非参数持续学习的有效性，为处理动态知识提供了新思路。

Abstract: Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject irrelevant context that increases unsupported generation. We propose a human-like non-parametric continual learning framework, where the base model remains fixed, and learning occurs by integrating each new experience into an external semantic memory state that accumulates and consolidates itself continually. We present Panini, which realizes this by representing documents as Generative Semantic Workspaces (GSW) -- an entity- and event-aware network of question-answer (QA) pairs, sufficient for an LLM to reconstruct the experienced situations and mine latent knowledge via reasoning-grounded inference chains on the network. Given a query, Panini only traverses the continually-updated GSW (not the verbatim documents or chunks), and retrieves the most likely inference chains. Across six QA benchmarks, Panini achieves the highest average performance, 5%-7% higher than other competitive baselines, while using 2-30x fewer answer-context tokens, supports fully open-source pipelines, and reduces unsupported answers on curated unanswerable queries. The results show that efficient and accurate structuring of experiences at write time -- as achieved by the GSW framework -- yields both efficiency and reliability gains at read time. Code is available at https://github.com/roychowdhuryresearch/gsw-memory.

</details>


### [11] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 提出基于da Costa容忍原则和Tarski后承算子的da Costian-Tarskianism方法，使用扩展后承系统和扩展发展图处理本体异质性


<details>
  <summary>Details</summary>
Motivation: 解决本体异质性（ontological heterogeneity）问题，即不同本体系统之间的兼容性和互操作性问题

Method: 基于Carnapian-Goguenism，采用da Costa数学容忍原则和Tarski后承算子，构建扩展后承系统（添加本体公理）和扩展发展图（通过态射、纤维化、分裂等操作关联本体）

Result: 建立了da Costian-Tarskianism理论框架，定义了扩展后承系统和扩展发展图，为处理本体异质性提供了形式化工具

Conclusion: 该方法为应用本体论领域提供了新的理论框架，并指出了未来研究方向

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [12] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该研究比较了20个前沿和开源LLM在风险决策中的表现，发现LLM可分为推理模型和对话模型两类，前者更理性，后者更接近人类但理性程度较低，数学推理训练是区分两者的关键因素。


<details>
  <summary>Details</summary>
Motivation: LLM作为决策支持系统或智能体工作流正在快速改变数字生态系统，但人们对LLM在不确定性下的决策理解仍然有限。需要研究LLM的风险选择行为，并与人类决策进行比较。

Method: 从两个维度比较LLM风险选择：(1)前景表示（显式vs经验基础）和(2)决策理由（解释）。研究涉及20个前沿和开源LLM，并辅以匹配的人类受试者实验作为参考点，同时使用期望收益最大化的理性智能体模型作为另一个参考。

Result: LLM可分为两类：推理模型（RMs）倾向于理性行为，对前景顺序、得失框架和解释不敏感，在显式和经验历史前景下表现相似；对话模型（CMs）理性程度显著较低，更接近人类，对前景顺序、框架和解释敏感，存在较大的描述-历史差距。开源LLM的配对比较表明，区分RMs和CMs的关键因素是数学推理训练。

Conclusion: LLM在风险决策中存在明显差异，可分为理性导向的推理模型和更接近人类但理性程度较低的对话模型。数学推理训练是塑造LLM决策行为的关键因素，这对LLM作为决策支持系统的应用具有重要意义。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [13] [Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212)
*Yuanyan Song,Kezhi Wang,Xinmian Xu*

Main category: cs.AI

TL;DR: 提出安全的无线智能体AI网络，通过智能体协作和友好干扰保护隐私，优化资源分配以降低能耗


<details>
  <summary>Details</summary>
Motivation: 在为用户提供推理任务QoS保障的同时，保护私有知识和推理结果的机密性，并延长AI智能体的服务时间

Method: 构建包含一个监督AI智能体和多个其他AI智能体的网络，监督智能体动态分配协作推理任务，未选中的智能体作为友好干扰器。提出ASC和LAW两种资源分配方案，分别使用ADMM、SDR、SCA算法和LLM优化器解决联合优化问题

Result: 相比基准方案，提出的解决方案能降低网络能耗高达59.1%，并在基于Qwen的实际智能体AI系统中验证了满意的推理精度

Conclusion: 提出的安全无线智能体AI网络框架能有效保护隐私、降低能耗，并通过两种资源分配方案在实际系统中验证了可行性

Abstract: In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. To extend the service duration of AI agents, an energy minimization problem is formulated that jointly optimizes AI agent selection, base station (BS) beamforming, and AI agent transmission power, subject to latency and reasoning accuracy constraints. To address the formulated problem, we propose two resource allocation schemes, ASC and LAW, which first decompose it into three sub-problems. Specifically, ASC optimizes each sub-problem iteratively using the proposed alternating direction method of multipliers (ADMM)-based algorithm, semi-definite relaxation (SDR), and successive convex approximation (SCA), while LAW tackles each sub-problem using the proposed large language model (LLM) optimizer within an agentic workflow. The experimental results show that the proposed solutions can reduce network energy consumption by up to 59.1% compared to other benchmark schemes. Furthermore, the proposed schemes are validated using a practical agentic AI system based on Qwen, demonstrating satisfactory reasoning accuracy across various public benchmarks.

</details>


### [14] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 本章介绍了基于仿真的合成数据生成技术，用于解决AI训练中数据不足的问题，并提出了数字孪生AI仿真解决方案的参考框架。


<details>
  <summary>Details</summary>
Motivation: 数据量不足和质量不高是现代符号AI采用的主要障碍，因此对合成数据生成技术的需求很高。仿真提供了一种系统化的方法来生成多样化的合成数据。

Method: 提出了基于仿真的合成数据生成方法，并介绍了一个用于描述、设计和分析数字孪生AI仿真解决方案的参考框架。

Result: 本章介绍了仿真合成数据生成的关键概念、优势和挑战，为AI训练提供了系统化的数据生成方法。

Conclusion: 基于仿真的合成数据生成是解决AI训练数据不足的有效途径，数字孪生框架为设计AI仿真解决方案提供了系统化的参考。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


### [15] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 本文提出AI/机器学习框架补充确定性算法，预测供应链金融中的发票稀释风险，使用实时动态信用限额替代传统不可撤销支付承诺。


<details>
  <summary>Details</summary>
Motivation: 发票稀释（批准金额与实际收款差距）是供应链金融中重要的非信用风险和利润损失来源。传统依赖买方不可撤销支付承诺（IPU）的方法阻碍了供应链金融的采用，特别是对于次级投资级买方。需要更灵活的数据驱动方法来管理此风险。

Method: 提出AI/机器学习框架，补充确定性算法来预测发票稀释。使用实时动态信用限额方法，为每个买方-供应商对实时预测稀释风险。基于九个关键交易字段的广泛生产数据集进行评估。

Result: 论文评估了AI/机器学习框架在预测发票稀释方面的表现，但具体结果未在摘要中提供。该方法旨在提供比传统IPU方法更灵活的风险管理方案。

Conclusion: AI/机器学习框架可以补充确定性算法，为供应链金融中的发票稀释风险提供更灵活、数据驱动的预测方法，有助于克服传统IPU方法的局限性，促进供应链金融的采用。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [16] [Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models](https://arxiv.org/abs/2602.15270)
*Farbod Abbasi,Zachary Patterson,Bilal Farooq*

Main category: cs.AI

TL;DR: 提出一种基于WGAN-GP的多源数据集联合学习方法来生成合成人口数据，通过逆梯度惩罚正则化提高多样性和可行性，在相似性、多样性和可行性指标上均优于传统序列方法。


<details>
  <summary>Details</summary>
Motivation: 当前合成人口生成方法存在两大局限：1）依赖单一数据集或采用序列化数据融合生成过程，无法捕捉特征间的复杂相互作用；2）难以处理采样零值（有效但未观测到的属性组合）和结构零值（因逻辑约束不可行的组合），导致生成数据多样性和可行性不足。

Method: 提出一种新颖的联合学习方法，使用带梯度惩罚的Wasserstein生成对抗网络（WGAN-GP）同时集成和合成多源数据集。在生成器损失函数中定义正则化项（逆梯度惩罚）来提高多样性和可行性。

Result: 提出的联合方法在召回率上比序列基线提高7%，精确度提高15%。正则化项进一步提升了多样性和可行性，召回率增加10%，精确度增加1%。在相似性分布的五指标评分中，联合方法达到88.1分，优于序列方法的84.6分。

Conclusion: 这种多源生成方法通过联合学习提高了合成人口数据的多样性和可行性，作为基于智能体模型的关键输入，有望显著提升ABM的准确性和可靠性。

Abstract: Generating realistic synthetic populations is essential for agent-based models (ABM) in transportation and urban planning. Current methods face two major limitations. First, many rely on a single dataset or follow a sequential data fusion and generation process, which means they fail to capture the complex interplay between features. Second, these approaches struggle with sampling zeros (valid but unobserved attribute combinations) and structural zeros (infeasible combinations due to logical constraints), which reduce the diversity and feasibility of the generated data. This study proposes a novel method to simultaneously integrate and synthesize multi-source datasets using a Wasserstein Generative Adversarial Network (WGAN) with gradient penalty. This joint learning method improves both the diversity and feasibility of synthetic data by defining a regularization term (inverse gradient penalty) for the generator loss function. For the evaluation, we implement a unified evaluation metric for similarity, and place special emphasis on measuring diversity and feasibility through recall, precision, and the F1 score. Results show that the proposed joint approach outperforms the sequential baseline, with recall increasing by 7\% and precision by 15\%. Additionally, the regularization term further improves diversity and feasibility, reflected in a 10\% increase in recall and 1\% in precision. We assess similarity distributions using a five-metric score. The joint approach performs better overall, and reaches a score of 88.1 compared to 84.6 for the sequential method. Since synthetic populations serve as a key input for ABM, this multi-source generative approach has the potential to significantly enhance the accuracy and reliability of ABM.

</details>


### [17] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 研究不同记忆类型在动态不确定环境中如何辅助空间导航，发现结合多种策略的架构能有效处理探索、搜索和路径规划等不同子任务，使用非平稳概率学习更新记忆并基于记忆构建地图的智能体在任务难度增加时效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 在动态变化且感知受限的不确定环境中，智能体需要快速学习并构建稳健的导航策略。传统方法难以应对环境非平稳性、感知不确定性和学习速度要求等挑战，因此需要探索不同记忆策略如何帮助解决这些复杂导航问题。

Method: 研究从简单到复杂的多种策略，包括不同记忆使用和学习方式。重点考察利用非平稳概率学习技术更新情景记忆，并基于这些记忆动态构建不完美地图（有噪声且限于智能体经验）进行实时路径规划的架构。

Result: 当任务难度（如目标距离）增加时，使用非平稳概率学习更新记忆并基于记忆构建地图进行规划的智能体，相比简单（最小记忆）智能体效率显著提升。但当地理定位和环境变化带来的不确定性过大时，这种优势会减弱。

Conclusion: 需要能够整合多种策略的架构来处理不同性质的子任务（探索、搜索和路径规划）。在不确定性不过大的情况下，结合非平稳概率学习和记忆更新的智能体在复杂导航任务中表现出色，特别是在任务难度增加时。

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [18] [EAA: Automating materials characterization with vision language model agents](https://arxiv.org/abs/2602.15294)
*Ming Du,Yanqi Luo,Srutarshi Banerjee,Michael Wojcik,Jelena Popovic,Mathew J. Cherukara*

Main category: cs.AI

TL;DR: EAA是一个基于视觉语言模型的智能代理系统，用于自动化复杂的实验显微镜工作流程，通过多模态推理和工具增强操作，支持从全自动到交互式的工作流。


<details>
  <summary>Details</summary>
Motivation: 传统实验显微镜工作流程复杂且需要专业知识，EAA旨在通过智能代理系统提高光束线效率、减轻操作负担，并降低用户专业知识门槛。

Method: 基于灵活的任务管理器架构，集成多模态推理、工具增强操作和可选长期记忆，支持自主程序和交互式用户引导测量，提供与Model Context Protocol双向兼容的现代工具生态系统。

Result: 在先进光子源的成像光束线上成功演示了自动区域板聚焦、自然语言描述的特征搜索和交互式数据采集，展示了视觉智能代理如何增强光束线效率。

Conclusion: EAA系统展示了视觉智能代理在自动化复杂实验工作流程中的潜力，能够显著提高实验效率、降低操作负担，并为更广泛的用户群体提供便利。

Abstract: We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM queries. EAA further provides a modern tool ecosystem with two-way compatibility for Model Context Protocol (MCP), allowing instrument-control tools to be consumed or served across applications. We demonstrate EAA at an imaging beamline at the Advanced Photon Source, including automated zone plate focusing, natural language-described feature search, and interactive data acquisition. These results illustrate how vision-capable agents can enhance beamline efficiency, reduce operational burden, and lower the expertise barrier for users.

</details>


### [19] [X-MAP: eXplainable Misclassification Analysis and Profiling for Spam and Phishing Detection](https://arxiv.org/abs/2602.15298)
*Qi Zhang,Dian Chen,Lance M. Kaplan,Audun Jøsang,Dong Hyun Jeong,Feng Chen,Jin-Hee Cho*

Main category: cs.AI

TL;DR: X-MAP是一个可解释的误分类分析和分析框架，通过主题级语义模式揭示模型失败原因，结合SHAP特征归因和矩阵分解构建可解释主题配置文件，用于改进垃圾邮件和钓鱼检测。


<details>
  <summary>Details</summary>
Motivation: 垃圾邮件和钓鱼检测中的误分类危害很大：假阴性让用户暴露于攻击，假阳性降低信任。现有基于不确定性的检测器可能被欺骗且可解释性有限，需要更好的方法来分析和修复模型错误。

Method: X-MAP结合SHAP特征归因和非负矩阵分解，为正确分类的垃圾/钓鱼邮件和合法邮件构建可解释的主题配置文件，然后使用Jensen-Shannon散度测量每条消息与这些配置文件的偏差。

Result: 实验显示误分类消息的偏差至少是正确分类消息的两倍。作为检测器，X-MAP达到0.98 AUROC，在95% TRR时将误拒率降至0.089。作为修复层，它能恢复高达97%的错误拒绝的正确预测。

Conclusion: X-MAP在改进垃圾邮件和钓鱼检测方面具有有效性和可解释性，能够揭示模型失败的语义模式并修复误分类。

Abstract: Misclassifications in spam and phishing detection are very harmful, as false negatives expose users to attacks while false positives degrade trust. Existing uncertainty-based detectors can flag potential errors, but possibly be deceived and offer limited interpretability. This paper presents X-MAP, an eXplainable Misclassification Analysis and Profilling framework that reveals topic-level semantic patterns behind model failures. X-MAP combines SHAP-based feature attributions with non-negative matrix factorization to build interpretable topic profiles for reliably classified spam/phishing and legitimate messages, and measures each message's deviation from these profiles using Jensen-Shannon divergence. Experiments on SMS and phishing datasets show that misclassified messages exhibit at least two times larger divergence than correctly classified ones. As a detector, X-MAP achieves up to 0.98 AUROC and lowers the false-rejection rate at 95% TRR to 0.089 on positive predictions. When used as a repair layer on base detectors, it recovers up to 97% of falsely rejected correct predictions with moderate leakage. These results demonstrate X-MAP's effectiveness and interpretability for improving spam and phishing detection.

</details>


### [20] [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)
*Zhixing Zhang,Jesen Zhang,Hao Liu,Qinhan Lv,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.AI

TL;DR: 提出Agro-Reflective框架，通过LLM代理在农业数据环境中执行代码、观察结果、迭代优化的循环，解决现有农业基础模型缺乏语言推理能力的问题


<details>
  <summary>Details</summary>
Motivation: 现有农业基础模型虽然能处理大规模时空数据，但缺乏语言推理和交互能力；而大语言模型擅长文本处理，却无法直接处理高维异构农业数据。需要桥接这一鸿沟

Method: 构建AgriWorld Python执行环境，提供地理空间查询、遥感时间序列分析、作物生长模拟等工具；设计Agro-Reflective多轮LLM代理，通过执行-观察-优化的循环迭代分析

Result: 在AgroBench基准测试中，涵盖查找、预测、异常检测和反事实分析等任务，表现优于纯文本和直接工具使用基线，验证了执行驱动反思的可靠性

Conclusion: 提出的代理框架成功将LLM的语言推理能力与农业数据工具结合，通过迭代执行-观察-优化循环实现了可靠的农业科学分析

Abstract: Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual "what-if" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.

</details>


### [21] [World-Model-Augmented Web Agents with Action Correction](https://arxiv.org/abs/2602.15384)
*Zhouzhou Shen,Xueyu Hu,Xiyun Li,Tianqing Fang,Juncheng Li,Shengyu Zhang*

Main category: cs.AI

TL;DR: WAC是一个基于多模型协作的网页代理，通过世界模型模拟行动后果和法官模型评估风险，实现风险感知的网页任务自动化。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的网页代理存在两个主要问题：1) 难以预测环境变化，导致行动决策不合理；2) 缺乏对执行风险的全面认知，过早执行风险操作导致任务失败和损失。

Method: WAC采用模型协作、后果模拟和反馈驱动的行动优化。包括：1) 多智能体协作流程，行动模型咨询世界模型获取策略指导；2) 两阶段推理链，世界模型模拟行动结果，法官模型评估风险并触发行动修正反馈。

Result: 在VisualWebArena上实现1.8%的绝对提升，在Online-Mind2Web上实现1.3%的绝对提升。

Conclusion: WAC通过模型协作和风险感知机制，有效提升了网页代理的决策质量和任务执行韧性，解决了现有代理在环境预测和风险认知方面的局限性。

Abstract: Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.

</details>


### [22] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 提出自适应弃权系统，通过上下文感知的动态阈值调整和多维检测架构，在保证安全性的同时减少误报和延迟，优化LLM的安全-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制存在安全-效用权衡问题：严格过滤会误阻良性查询，宽松控制则产生不安全内容。传统基于静态规则或固定阈值的防护措施缺乏上下文敏感性且计算成本高，导致高延迟和用户体验下降。

Method: 引入自适应弃权系统，基于实时上下文信号（如领域和用户历史）动态调整安全阈值。采用多维检测架构，包含五个并行检测器，通过分层级联机制结合以优化速度和精度。级联设计通过渐进式过滤查询减少不必要计算。

Result: 在混合和特定领域工作负载上的广泛评估显示，显著减少了误报，特别是在医疗建议和创意写作等敏感领域。系统在严格操作模式下保持高安全精度和接近完美的召回率。与非级联模型和外部防护系统相比，实现了显著的延迟改进。

Conclusion: 上下文感知的弃权框架有效平衡了安全性和效用，同时保持性能，为可靠的LLM部署提供了可扩展的解决方案。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [23] [Common Belief Revisited](https://arxiv.org/abs/2602.15403)
*Thomas Ågotnes*

Main category: cs.AI

TL;DR: 本文解决了关于共同信念逻辑的开放问题，证明了在个体信念为KD45时，共同信念的逻辑不仅需要KD4加上shift-reflexivity公理，还需要一个额外的依赖于代理人数的公理。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为共同信念是KD4，但本文发现当个体信念为KD45时，共同信念会失去5属性而保留D和4属性，并具有shift-reflexivity属性。这引发了一个开放问题：KD4加上shift-reflexivity公理是否足以完全刻画共同信念？

Method: 通过逻辑分析证明，作者展示了仅靠KD4和shift-reflexivity公理不足以完全刻画共同信念，需要引入一个额外的依赖于代理人数的公理，从而为共同信念提供了完整的逻辑刻画。

Result: 证明了对第一个问题的回答是"否"：除了shift-reflexivity公理外，还需要一个额外的公理，且这个公理依赖于代理人数的多少。最终得到了共同信念的完整逻辑刻画，解决了这个开放问题。

Conclusion: 本文完全刻画了在个体信念为KD45时共同信念的逻辑特性，解决了长期存在的开放问题，表明共同信念的逻辑不仅包括KD4和shift-reflexivity，还需要一个依赖于代理人数的额外公理。

Abstract: Contrary to common belief, common belief is not KD4.
  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(Cφ\rightarrow φ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:
  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.

</details>


### [24] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: EduEVAL-DB是一个基于教师角色的数据集，用于评估和训练自动教学评估器和AI导师，包含854个解释，涵盖科学、语言和社会科学K-12年级问题，并提出了教学风险评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门用于评估自动教学评估器和AI导师教学解释质量的数据集，需要基于真实教育实践中的教学风格和缺陷来构建评估工具。

Method: 基于ScienceQA基准构建数据集，包含139个问题的854个解释（1个人类教师解释+6个LLM模拟教师角色解释）。提出包含五个维度的教学风险评估框架，通过半自动专家评审进行标注。

Result: 构建了EduEVAL-DB数据集，包含教学风险标注。初步验证实验表明，该数据集适用于教学风险评估，Gemini 2.5 Pro表现优于Llama 3.1 8B，监督微调能提升风险检测能力。

Conclusion: EduEVAL-DB为评估和训练自动教学评估器提供了有价值的资源，支持教学风险评估，并展示了在消费级硬件上部署模型的可行性。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [25] [Quantifying construct validity in large language model evaluations](https://arxiv.org/abs/2602.15532)
*Ryan Othniel Kearns*

Main category: cs.AI

TL;DR: 该论文提出了结构化能力模型，首次从大量LLM基准测试结果中提取可解释且可泛化的能力，解决了现有方法在构造效度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前LLM社区将基准测试结果等同于模型通用能力，但基准测试存在测试集污染、标注错误等问题。现有方法（潜在因子模型和缩放定律）都无法有效衡量基准测试的构造效度，无法可靠分离基准结果与实际能力。

Method: 提出了结构化能力模型，结合了缩放定律和潜在因子模型的优点：模型规模影响能力（如缩放定律），能力影响观测结果并考虑测量误差（如潜在因子模型）。在OpenLLM Leaderboard的大规模结果样本上拟合该模型。

Result: 结构化能力模型在简约拟合指标上优于潜在因子模型，在分布外基准预测上优于缩放定律。该模型能够更好地分离模型规模与能力，提供更好的解释和预测能力。

Conclusion: 结构化能力模型通过适当结合缩放定律和潜在因子模型的见解，为LLM评估中的构造效度量化提供了更好的解释和预测能力，是首个能从大量基准测试结果中提取可解释且可泛化能力的模型。

Abstract: The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.
  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.
  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.

</details>


### [26] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: Ruva提出首个"透明盒"架构，用于人类参与的AI记忆管理，将个人AI从向量匹配转向知识图谱推理，确保用户可检查和精确删除特定事实，实现"被遗忘权"。


<details>
  <summary>Details</summary>
Motivation: 当前个人AI主要采用"黑盒"检索增强生成，存在缺乏问责性的问题：当AI产生幻觉或检索敏感数据时，用户无法检查原因或纠正错误。向量数据库的"删除"操作在数学上不精确，会留下概率性"幽灵"，违反真正的隐私保护。

Method: Ruva采用"透明盒"架构，基于个人知识图谱构建个人AI，实现人类参与的记忆管理。通过从向量匹配转向图谱推理，让用户能够检查AI知道的内容，并对特定事实进行精确删除。

Result: Ruva成为首个支持人类参与记忆管理的"透明盒"架构，确保用户对个人AI知识的完全可见性和控制权，实现了真正的"被遗忘权"。

Conclusion: Ruva通过将个人AI从向量匹配转向知识图谱推理，赋予用户对自己生活的编辑权，解决了当前AI系统中的问责性和隐私保护问题，为个人AI提供了透明、可控的新范式。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.

</details>


### [27] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: 该研究使用部分信息分解(PID)分析多模态Transformer，发现视觉信息在早期层达到峰值后衰减，语言信息在后期层主导预测(约82%)，跨模态协同作用始终低于2%，揭示了"模态转导"模式。


<details>
  <summary>Details</summary>
Motivation: 研究多模态Transformer在回答视觉问题时，预测是由视觉证据、语言推理还是真正的跨模态计算驱动的，以及这种结构如何在不同层间演化。

Method: 提出PID Flow框架：结合降维、归一化流高斯化和闭式高斯PID估计，对LLaVA-1.5-7B和LLaVA-1.6-7B在六个GQA推理任务中进行层级分析，并通过注意力敲除实验建立因果关系。

Result: 发现一致的"模态转导"模式：视觉独特信息早期达到峰值后衰减，语言独特信息在后期层激增(占最终预测约82%)，跨模态协同作用始终低于2%。模型变体间高度稳定(层间相关性>0.96)，但任务依赖性很强。

Conclusion: 提供了多模态Transformer中视觉如何转化为语言的信息论因果解释，为识别模态特定信息丢失的架构瓶颈提供了定量指导。

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [28] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 提出一种预处理方法，通过推断额外的累积约束来捕捉调度问题中的多资源交互，无需搜索时探测，从而提高搜索性能并收紧目标界限


<details>
  <summary>Details</summary>
Motivation: 传统约束规划中累积约束的传播通常按单个约束进行，忽略了多资源之间的交互作用，导致在某些基准测试中出现严重的性能下降

Method: 将累积约束解释为占用向量上的线性不等式，通过三个步骤生成有效不等式：(1)发现覆盖集（不能并行运行的任务集合），(2)通过提升技术加强覆盖不等式，(3)将生成的约束注入调度问题实例

Result: 在标准RCPSP和RCPSP/max测试套件上的实验表明，推断的约束在有利实例上提高了搜索性能并收紧目标界限，在不利实例上仅有轻微性能下降。此外，发现了25个新的下界和5个新的最优解，其中8个下界直接来自推断的约束

Conclusion: 提出的预处理方法能够有效捕捉调度问题中的多资源交互，通过推断额外的累积约束显著改善约束规划在调度问题上的性能，特别是在资源受限项目调度问题上表现出色

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [29] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: 提出CARE Drive框架，用于评估自动驾驶中视觉语言模型决策是否真正基于人类相关理由，而非事后合理化。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶模型评估主要关注结果性能（如安全性、轨迹精度），但无法判断模型决策是否真正基于人类相关理由，这在安全关键领域可能导致虚假信心。

Method: 提出CARE Drive框架：1) 提示校准确保稳定输出；2) 系统化上下文扰动，测量决策对人类理由（安全距离、社会压力、效率约束等）的敏感性，通过比较基准模型和理由增强模型在受控上下文变化下的决策。

Result: 明确的人类理由显著影响模型决策，改善与专家推荐行为的一致性；但对不同类型理由的响应性存在差异，表明模型对不同类型理由的敏感性不均匀。

Conclusion: CARE Drive框架提供了无需修改模型参数即可系统评估基础模型理由响应性的实证证据，有助于确保自动驾驶中AI决策的真实合理性。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [30] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: PERSONA：无需训练的LLM人格控制框架，通过激活空间中的向量操作实现细粒度人格调控，性能接近监督微调


<details>
  <summary>Details</summary>
Motivation: 现有LLM人格控制方法依赖静态提示或昂贵的微调，无法捕捉人格特质的动态性和组合性，需要更灵活高效的解决方案

Method: 三阶段框架：1) Persona-Base通过对比激活分析提取正交人格向量；2) Persona-Algebra通过向量算术实现强度控制、组合和抑制；3) Persona-Flow在推理时动态组合向量实现上下文感知适应

Result: 在PersonalityBench上平均得分9.60（接近监督微调上限9.61），在Persona-Evolve动态人格适应基准上达到91%胜率，无需梯度更新

Conclusion: LLM人格特质在数学上是可处理的，为可解释和高效的行为控制开辟了新方向，证明了激活空间中人格向量的正交性和可操作性

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [31] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: RCE框架让预训练语言模型能在推理时动态修改内部表示空间，通过生成低秩概念子空间来构建新抽象，显著提升组合推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如思维链、自洽性、强化学习）仅扩展token级搜索，但保持模型的潜在表示空间固定。当所需抽象未编码在该空间中时，性能会崩溃。需要让模型能在推理时修改内部表示几何。

Method: 提出递归概念演化（RCE）框架：检测到表示不足时生成动态低秩概念子空间，通过最小描述长度准则选择子空间，在协同时合并子空间，通过约束优化进行整合以保持稳定性。

Result: 在Mistral-7B上集成RCE，在组合推理基准上取得显著提升：ARC-AGI-2提升12-18点，GPQA和BBH提升8-14点，MATH和HLE上深度诱导错误持续减少。

Conclusion: RCE使预训练语言模型能在推理时构建新抽象而非仅重组现有概念，显著提升组合推理能力，为语言模型表示演化开辟了新方向。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [32] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: GlobeDiff：一种基于扩散模型的多智能体全局状态推断算法，通过多模态扩散过程解决部分可观测性问题


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的部分可观测性是有效协调和决策的关键障碍。现有方法如信念状态估计和智能体间通信存在局限性：信念方法主要依赖过去经验而未能充分利用全局信息，通信方法则缺乏有效利用辅助信息的鲁棒模型。

Method: 提出Global State Diffusion Algorithm (GlobeDiff)，将状态推断过程建模为多模态扩散过程。该方法基于局部观测推断全局状态，克服状态估计中的模糊性，同时以高保真度推断全局状态。

Result: 理论证明GlobeDiff在单模态和多模态分布下的估计误差均有界。大量实验结果表明，GlobeDiff实现了优越的性能，能够准确推断全局状态。

Conclusion: GlobeDiff通过扩散模型有效解决了多智能体系统中的部分可观测性问题，在理论和实验上都表现出优越的全局状态推断能力。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [33] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 该论文分析了使用大语言模型作为合成参与者在社会科学实验中的有效性，对比了启发式方法和统计校准两种策略，并讨论了它们在不同研究阶段（探索性vs验证性）的适用性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地被用作社会科学实验中的合成参与者，但缺乏关于何时这种模拟能够有效推断人类行为的指导。需要明确不同方法在探索性和验证性研究中的适用条件。

Method: 论文对比了两种策略：1）启发式方法：通过提示工程、模型微调等技术减少LLM引起的误差，使模拟与观察的人类行为可互换；2）统计校准：结合辅助人类数据和统计调整，在明确假设下处理观察与模拟响应之间的差异。

Result: 启发式方法适用于探索性任务，但缺乏验证性研究所需的正式统计保证。统计校准在明确假设下保持有效性，并能以比仅依赖人类参与者的实验更低的成本提供更精确的因果效应估计。两种方法的潜力都取决于LLM对相关人群的近似程度。

Conclusion: 研究者需要根据研究目标选择合适的方法：探索性研究可用启发式方法，验证性研究需要统计校准。同时应避免狭隘地只关注用LLM替代人类参与者，而要考虑更广泛的研究机会。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [34] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 本研究提出使用LLM嵌入作为编码方法，替代传统的one-hot编码，以更好地捕捉建筑语义中对象类型和子类型之间的细微关系，在建筑信息模型分类任务中取得了优于基准的性能。


<details>
  <summary>Details</summary>
Motivation: 在AECO行业中，准确表示建筑语义（包括通用对象类型和特定子类型）对于AI模型训练至关重要。传统的编码方法（如one-hot编码）往往无法传达密切相关的子类型之间的细微关系，限制了AI的语义理解能力。

Method: 提出使用大型语言模型（LLM）嵌入（如OpenAI GPT和Meta LLaMA）作为编码方法，保留建筑语义的精细区别。评估方法包括训练GraphSAGE模型对5个高层住宅建筑信息模型中的42个建筑对象子类型进行分类，测试了不同嵌入维度，包括原始高维LLM嵌入（1,536、3,072或4,096维）和通过Matryoshka表示模型生成的1,024维压缩嵌入。

Result: 实验结果表明，LLM编码优于传统的one-hot基准，其中llama-3（压缩）嵌入实现了0.8766的加权平均F1分数，而one-hot编码为0.8475。LLM编码在捕捉建筑语义的细微差别方面表现出色。

Conclusion: LLM编码在增强AI解释复杂、领域特定的建筑语义方面具有显著潜力。随着LLM和降维技术的不断发展，这种方法在AECO行业的语义细化任务中具有广泛的应用前景。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [35] [Pairwise XOR and XNOR Gates in Squeezed Instantaneous Noise Based Logic](https://arxiv.org/abs/2602.15032)
*Nasir Kenarangui,Laszlo B. Kish,Arthur Powalka*

Main category: cs.ET

TL;DR: 本文在压缩INBL方案中实现了XOR和XNOR门操作，验证了其布尔行为正确性，并保持了瞬时评估特性，为更复杂的INBL算法提供了关键门集。


<details>
  <summary>Details</summary>
Motivation: 基于噪声的逻辑（INBL）是一种使用随机过程编码二进制信息的新型计算框架，能够构建指数级大的希尔伯特空间。之前的研究在对称INBL方案中引入了XOR和XNOR操作，但需要在压缩INBL方案中实现这些门操作，以构建更完整的门集，实现INBL的通用性目标。

Method: 将先前为对称INBL方案开发的XOR/XNOR门操作适配到压缩INBL方案中。这些操作可以在超空间向量及其叠加态上成对应用，同时保持与压缩参考系统的兼容性。通过验证操作在比特级和目标M比特字符串上的布尔行为正确性，并证明操作保持瞬时评估特性。

Result: 成功在压缩INBL方案中实现了XOR和XNOR门操作，验证了这些操作具有正确的布尔行为，并且保持了瞬时评估特性。结果表明，先前为对称INBL开发的XOR/XNOR工具包可以适配到压缩方案中。

Conclusion: 压缩方案中XOR/XNOR门操作的实现是构建更复杂INBL算法所需门集的关键部分，推进了INBL门通用性的目标。这进一步强化了INBL作为一个灵活经典计算框架的地位，能够模拟量子计算的某些结构优势。

Abstract: Instantaneous noise-based logic (INBL) is a novel computing approach that encodes binary information using stochastic processes. It uses 2M orthogonal stochastic reference noises for M noise-bits to construct an exponentially large Hilbert space (hyperspace) of dimension 2^M. INBL offers a classical alternative to quantum-style parallelism for specific problems with exponential speedup compared to classical algorithms. Building on recent work that introduced pairwise XOR and XNOR operations defined for a symmetric INBL scheme, this paper implements these gates for a squeezed INBL scheme. Hyperspace vectors are product strings corresponding to M-bit long binary numbers. The proposed operations can apply pairwise on hyperspace vectors and their superpositions, while remaining compatible with the squeezed reference system. We validate that the squeezed-scheme XOR/XNOR gate operations have correct Boolean behavior over both bitwise and targeted M-bit strings and demonstrate that the operations preserve instantaneous evaluation. The results show that the XOR/XNOR toolkit, previously developed for symmetric INBL, can be tailored for the squeezed scheme. This development is a key part of the gate set needed for more complex INBL algorithms in the squeezed INBL scheme and advances the objective of gate universality in INBL. It further strengthens the case for INBL as a flexible, classical computing framework that can emulate some structural advantages of quantum computation.

</details>


### [36] [High Convergence Rates of CMOS Invertible Logic Circuits Based on Many-Body Hamiltonians](https://arxiv.org/abs/2602.15033)
*Naoya Onizawa,Takahiro Hanyu*

Main category: cs.ET

TL;DR: 提出基于多体哈密顿量的CMOS可逆逻辑电路，通过三体自旋相互作用简化能量景观，提高收敛速度


<details>
  <summary>Details</summary>
Motivation: 传统二体哈密顿量能量景观复杂，难以达到全局最小能量，需要更简单的能量景观设计来提高计算效率

Method: 使用三体自旋相互作用构建哈密顿量，通过随机计算进行退火，实现函数的概率前向和后向操作

Result: 三体CIL电路相比传统二体CIL电路收敛速度提高数倍，FPGA上面积开销可忽略

Conclusion: 三体相互作用哈密顿量设计能有效简化能量景观，显著提高CMOS可逆逻辑电路的收敛性能

Abstract: This paper introduces CMOS invertible-logic (CIL) circuits based on many-body Hamiltonians. CIL can realize probabilistic forward and backward operations of a function by annealing a corresponding Hamiltonian using stochastic computing. We have created a Hamiltonian that includes three-body interaction of spins (probabilistic nodes). It provides some degrees of freedom to design a simpler landscape of Hamiltonian (energy) than that of the conventional two-body Hamiltonian. The simpler landscape makes it easier to reach the global minimum energy. The proposed three-body CIL circuits are designed and evaluated with the conventional two-body CIL circuits, resulting in few-times higher convergence rates with negligible area overhead on FPGA.

</details>


### [37] [Full-Field Damage Monitoring in Architected Lattices Using In situ Electrical Impedance Tomography](https://arxiv.org/abs/2602.15048)
*Akash Deep,Andrea Samore,Alistair McEwan,Andrew McBride,Shanmugam Kumar*

Main category: cs.ET

TL;DR: 首次在可调谐结构晶格材料框架中实现原位电阻抗断层扫描，实时监测3D打印多功能晶格复合材料损伤演化，包括早期预断裂事件


<details>
  <summary>Details</summary>
Motivation: 开发一种可扩展的全场传感方法，用于结构多功能材料，实现损伤演化的实时监测，为自主智能材料和数字孪生框架提供实验验证途径

Method: 采用Voronoi分支-主干-分支图案设计晶格，使用CNT增强光固化树脂3D打印，在晶格周边分布16个电极进行电阻抗断层扫描测量，采用相邻和跨接电流注入方案重建电导率图

Result: 成功重建了具有高时间分辨率的连续韧带断裂电导率图，局部电导率损失与断裂位置定量吻合，包括远离电极的区域；结构可调性可系统控制对早期损伤的成像灵敏度

Conclusion: 原位电阻抗断层扫描是一种可扩展的全场传感模式，适用于结构多功能材料，为自主智能材料、数据丰富的材料状态和数字孪生框架提供了实验验证途径

Abstract: Electrical impedance tomography (EIT) enables non-invasive, spatially continuous reconstruction of internal conductivity distributions, providing full field sensing beyond conventional point measurements. Here, we report the first in situ implementation of EIT within a tunable architected lattice materials framework, enabling systematic exploration across a broad lattice design space while achieving real time monitoring of damage evolution, including early stage, prefracture events, in 3D printed multifunctional lattice composites. Lattices are designed via Voronoi based branch trunk branch motifs inspired by 2D wallpaper symmetries and fabricated using CNT infused photocurable resins, with nanoscale filler dispersion confirmed by field emission scanning electron microscopy. Sixteen electrodes distributed along the lattice periphery enable EIT measurements during quasi static tensile loading. Conductivity maps reconstructed using adjacent and across current injection schemes resolve sequential ligament fracture with high temporal resolution, with localised conductivity loss quantitatively coinciding with fracture sites, including regions remote from electrodes. Architectural tunability allows systematic control of EIT imaging sensitivity to early stage damage, while pronounced resistance discontinuities at failure further corroborate spatial localisation; global end to end resistance measurements complement macroscopic stress strain responses. Collectively, these results establish in situ EIT as a scalable, full field sensing modality for architected multifunctional materials, providing an experimentally validated pathway toward autonomous, intelligent materials and data rich material states that can inform digital twin frameworks for structural, biomedical, and energy related applications.

</details>


### [38] [Quantum Optimization for Access Point Selection Under Budget Constraint](https://arxiv.org/abs/2602.15049)
*Mohamed Khalil Brik,Ahmed Shokry,Moustafa Youssef*

Main category: cs.ET

TL;DR: 提出量子AP选择算法，在预算约束下通过量子退火优化AP子集，显著减少基础设施需求，同时保持定位精度并大幅提升计算速度。


<details>
  <summary>Details</summary>
Motivation: 传统AP选择方法在大型3D室内环境中计算成本高，需要在定位精度和部署成本之间权衡，需要更高效的解决方案。

Method: 将AP选择问题建模为QUBO问题，利用量子退火求解器在预算约束下找到最优AP子集。

Result: AP数量减少96.1%的同时保持3D定位精度，计算速度提升61倍（0.20秒），定位误差降低10%，楼层定位准确率达73%。

Conclusion: 量子AP选择算法在减少基础设施需求、提高计算效率和定位精度方面优于传统方法，在大规模3D定位中具有应用前景。

Abstract: Optimal Access Point (AP) selection is crucial for accurate indoor localization, yet it is constrained by budget, creating a trade-off between localization accuracy and deployment cost. Classical approaches to AP selection are often computationally expensive, hindering their application in large-scale 3D indoor environments.
  In this paper, we introduce a quantum APs selection algorithm under a budget constraint. The proposed algorithm leverages quantum annealing to identify the most effective subset of APs allowed within a given budget. We formulate the APs selection problem as a quadratic unconstrained binary optimization (QUBO) problem, making it suitable for quantum annealing solvers. The proposed technique can drastically reduce infrastructure requirements with a negligible impact on performance.
  We implement the proposed quantum algorithm and deploy it in a realistic 3D testbed. Our results show that the proposed approach can reduce the number of required APs by 96.1% while maintaining a comparable 3D localization accuracy. Furthermore, the proposed quantum approach outperforms classical AP selection algorithms in both accuracy and computational speed. Specifically, our technique achieves a time of 0.20 seconds, representing a speedup of 61 times over its classical counterpart, while reducing the mean localization error by 10% compared to the classical counterpart. For floor localization, the quantum approach achieves 73% floor accuracy, outperforming both the classical AP selection (58.6%) and even using the complete set of APs (70.4%). This highlights the promise of the proposed quantum APs selection algorithm for large-scale 3D localization.

</details>


### [39] [Quantum Computing for Healthcare Digital Twin Systems](https://arxiv.org/abs/2602.15477)
*Asma Taheri Monfared,Andrea Bombarda,Angelo Gargantini,Majid Haghparast*

Main category: cs.ET

TL;DR: 本文全面回顾了医疗领域的量子数字孪生技术，重点分析了阻碍其实际应用的关键挑战，并提出了推进安全可靠、临床可行的量子数字孪生系统发展的研究方向。


<details>
  <summary>Details</summary>
Motivation: 医疗系统日益复杂，需要先进的计算模型进行实时监控、安全数据交换和智能决策。传统数字孪生框架在可扩展性、计算效率和安全性方面存在局限，而量子数字孪生虽能通过量子计算提升性能，但仍面临硬件限制、系统集成、可扩展性和临床信任等根本性挑战。

Method: 本文采用系统性文献回顾方法，对医疗领域的量子数字孪生技术进行全面综述，重点识别和分析阻碍其实际应用的关键挑战，并在此基础上提出未来的研究方向和发展策略。

Result: 识别出量子数字孪生在医疗领域应用的主要挑战包括：量子硬件限制、经典-量子混合系统集成、基于云的量子访问、可扩展性问题以及临床信任度不足。这些因素共同阻碍了量子数字孪生在现实医疗环境中的广泛采用。

Conclusion: 量子数字孪生技术具有革新医疗保健的潜力，但需要解决硬件、集成、可扩展性和临床信任等关键挑战。通过制定明确的研究方向和实施策略，可以推进安全、可靠、临床可行的量子数字孪生系统的发展，为下一代医疗应用奠定基础。

Abstract: The growing complexity of healthcare systems requires advanced computational models for real-time monitoring, secure data exchange, and intelligent decision-making. Digital Twins (DTs) provide virtual representations of physical healthcare entities, enabling continuous patient monitoring and personalized care. However, classical DT frameworks face limitations in scalability, computational efficiency, and security. Recent studies have introduced Quantum Digital Twins (QDTs) to enhance performance through quantum computing, addressing challenges such as quantum-resistant security and efficient task offloading in healthcare environments. Despite these advances, most existing QDT models remain constrained by fundamental challenges related to quantum hardware limitations, hybrid classical-quantum system integration, cloud-based quantum access, scalability, and clinical trust. This paper provides a comprehensive review of QDTs for healthcare, with a particular focus on identifying and analyzing the key challenges that currently hinder their real-world adoption. Furthermore, it outlines critical research directions and enabling strategies aimed at advancing the development of secure, reliable, and clinically viable quantum digital twin systems for next-generation healthcare applications.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [40] [A Projection Approach to Nonparametric Significance and Conditional Independence Testing](https://arxiv.org/abs/2602.15289)
*Xiaojun Song,Jichao Yuan*

Main category: econ.EM

TL;DR: 提出一种基于定制非参数型投影加权函数的新型非参数显著性检验方法，具有优良的理论和数值性质，可检测参数速率的局部备择，并构建计算便利的乘数自助法获取临界值。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理协变量密度时通常需要更强的紧支撑假设（来自随机分母），本文旨在克服这一限制，开发更灵活的非参数显著性检验方法。

Method: 基于定制的非参数型投影加权函数构建显著性检验，推导其渐近性质，使用非参数正交投影构造计算便利的乘数自助法获取临界值，并将定制投影程序扩展到条件独立性检验。

Result: 提出的检验方法能检测参数速率的局部备择，克服了现有方法对协变量密度紧支撑假设的需求，模拟实验显示在有限样本中测试显著性和条件独立性方面具有优势。

Conclusion: 开发的新型非参数显著性检验方法具有理论优势和实践价值，特别在放宽假设条件和计算便利性方面优于现有方法，适用于显著性检验和条件独立性检验。

Abstract: This paper develops a novel nonparametric significance test based on a tailored nonparametric-type projected weighting function that exhibits appealing theoretical and numerical properties. We derive the asymptotic properties of the proposed test and show that it can detect local alternatives at the parametric rate. Using the nonparametric orthogonal projection, we construct a computationally convenient multiplier bootstrap to obtain critical values from the case-dependent asymptotic null distribution. Compared with the existing literature, our approach overcomes the need for a stronger compact support assumption on the density of covariates arising from random denominators. We also extend the tailor-made projection procedure to test the conditional independence assumption. The simulation experiments further illustrate the advantages of our proposed method in testing significance and conditional independence in finite samples.

</details>


### [41] [Income Inequality and Economic Growth: A Meta-Analytic Approach](https://arxiv.org/abs/2602.15690)
*Lisa Cpretti,Lorenzo Tonni*

Main category: econ.EM

TL;DR: 收入不平等与经济增长关系的实证研究结果存在高度异质性，本文通过元分析发现不平等对增长有微小但显著的负面影响，异质性主要源于现实特征和研究设计差异。


<details>
  <summary>Details</summary>
Motivation: 现有关于收入不平等与经济增长关系的实证文献产生了高度异质且常常相互矛盾的结果，需要系统性地探究这些异质性的来源。

Method: 采用元分析方法，系统整合和分析1994-2025年间相关研究的证据，通过元回归解释观察到的异质性。

Result: 发现收入不平等对后续经济增长有经济上微小但统计上显著的负向平均效应，存在显著的异质性和基于统计显著性的选择性发表偏误，但无系统性方向偏误。税后转移支付后的不平等测量与更负的增长效应相关，不平等的负面影响在高收入经济体相对于发展中国家更弱甚至逆转。方法选择也影响结果：横截面研究倾向于报告更负的估计，而固定效应、工具变量和GMM估计在面板设置中与更正的估计相关。

Conclusion: 收入不平等与经济增长关系的异质性结果既源于现实世界的特征差异，也源于研究设计选择，特别是测量方法和估计技术对报告效应大小有重要影响。

Abstract: The empirical literature on the relationship between income inequality and economic growth has produced highly heterogeneous and often conflicting results. This paper investigates the sources of this heterogeneity using a meta-analytic approach that systematically combines and analyzes evidence from relevant studies published between 1994 and 2025. We find an economically small but statistically significant negative average effect of income inequality on subsequent economic growth, together with strong evidence of substantial heterogeneity and selective publication based on statistical significance, but no evidence of systematic directional bias. To explain the observed heterogeneity, we estimate a meta-regression. The results indicate that both real-world characteristics and research design choices shape reported effect sizes. In particular, inequality measured net of taxes and transfers is associated with more negative growth effects, and the adverse impact of inequality is weaker - or even reversed - in high-income economies relative to developing countries. Methodological choices also matter: cross-sectional studies tend to report more negative estimates, while fixed-effects, instrumental-variable, and GMM estimators are associated with more positive estimates in panel settings.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [42] [Algorithmic Approaches to Opinion Selection for Online Deliberation: A Comparative Study](https://arxiv.org/abs/2602.15439)
*Salim Hafid,Manon Berriche,Jean-Philippe Cointet*

Main category: cs.CY

TL;DR: 论文提出了一种基于社会选择理论的新型算法，用于在线审议平台的意见选择，旨在平衡比例代表性和多样性，相比现有方法在民主标准上表现更优。


<details>
  <summary>Details</summary>
Motivation: 在线审议平台使用算法自动选择代表性意见时，现有策略（如共识、多样性）对民主标准（如比例代表性）的影响不明确，且共识导向策略可能压制少数声音和减少内容多样性。

Method: 基于社会选择理论提出新算法，结合多样性和平衡的代表性概念；对多种算法方法进行基准测试比较。

Result: 实证发现没有单一策略在所有民主标准上占优，但提出的社会选择启发式选择规则在比例代表性和多样性之间实现了最强的权衡平衡。

Conclusion: 研究填补了算法选择策略对民主标准影响的空白，提出的新算法为在线审议平台提供了更好的意见选择方案，平衡了代表性和多样性需求。

Abstract: During deliberation processes, mediators and facilitators typically need to select a small and representative set of opinions later used to produce digestible reports for stakeholders. In online deliberation platforms, algorithmic selection is increasingly used to automate this process. However, such automation is not without consequences. For instance, enforcing consensus-seeking algorithmic strategies can imply ignoring or flattening conflicting preferences, which may lead to erasing minority voices and reducing content diversity. More generally, across the variety of existing selection strategies (e.g., consensus, diversity), it remains unclear how each approach influences desired democratic criteria such as proportional representation. To address this gap, we benchmark several algorithmic approaches in this context. We also build on social choice theory to propose a novel algorithm that incorporates both diversity and a balanced notion of representation in the selection strategy. We find empirically that while no single strategy dominates across all democratic desiderata, our social-choice-inspired selection rule achieves the strongest trade-off between proportional representation and diversity.

</details>


### [43] [Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight](https://arxiv.org/abs/2602.15259)
*Kirandeep Kaur,Xingda Lyu,Chirag Shah*

Main category: cs.CY

TL;DR: 论文主张生成式AI需要从被动响应转向主动干预，但必须基于认识论和行为学双重基础，以负责任地处理用户未知的未知问题。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI代理假设用户能清晰表达需求，但现实中用户常无法意识到自己不知道什么、面临什么风险或值得考虑什么。这种"认识论不完整性"要求AI具备主动性，而不仅仅是效率提升。

Method: 结合无知哲学和主动行为研究理论，提出生成式主动性需要双重基础：认识论基础（识别未知的未知）和行为学基础（建立干预原则和约束）。

Result: 提出了"行为基础"概念，即主动代理需要原则性约束来确定何时、如何以及在何种程度上进行干预，避免误导注意力、压倒用户或造成伤害。

Conclusion: 生成式主动性必须同时基于认识论和行为学基础，才能设计出负责任、能促进有意义伙伴关系的AI代理，有效应对认识论不完整性挑战。

Abstract: Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. Existing approaches to proactivity remain narrowly anticipatory, extrapolating from past behavior and presuming that goals are already well defined, thereby failing to support users meaningfully. However, surfacing possibilities beyond a user's current awareness is not inherently beneficial. Unconstrained proactive interventions can misdirect attention, overwhelm users, or introduce harm. Proactive agents, therefore, require behavioral grounding: principled constraints on when, how, and to what extent an agent should intervene. We advance the position that generative proactivity must be grounded both epistemically and behaviorally. Drawing on the philosophy of ignorance and research on proactive behavior, we argue that these theories offer critical guidance for designing agents that can engage responsibly and foster meaningful partnerships.

</details>


### [44] [FrameRef: A Framing Dataset and Simulation Testbed for Modeling Bounded Rational Information Health](https://arxiv.org/abs/2602.15273)
*Victor De Lima,Jiqun Liu,Grace Hui Yang*

Main category: cs.CY

TL;DR: FrameRef是一个大规模数据集和模拟框架，用于研究排名和推荐系统中信息框架对用户信息健康的长期影响


<details>
  <summary>Details</summary>
Motivation: 现代搜索和推荐系统中的排名和个性化政策会影响用户接触不良数字体验的方式，需要研究这种暴露对用户信息健康的长期影响

Method: 创建包含1,073,740个系统性重构主张的FrameRef数据集，提出基于模拟的框架来建模顺序信息暴露和强化动态，通过微调语言模型构建框架敏感的代理角色

Result: 研究表明，接受度和信心的小幅系统性偏移会随时间累积，导致信息健康轨迹显著分歧；人类评估证实FrameRef生成的框架可测量地影响人类判断

Conclusion: FrameRef数据集和框架为通过模拟进行系统性信息健康研究提供了基础，补充并指导了以人为中心的负责任研究

Abstract: Information ecosystems increasingly shape how people internalize exposure to adverse digital experiences, raising concerns about the long-term consequences for information health. In modern search and recommendation systems, ranking and personalization policies play a central role in shaping such exposure and its long-term effects on users. To study these effects in a controlled setting, we present FrameRef, a large-scale dataset of 1,073,740 systematically reframed claims across five framing dimensions: authoritative, consensus, emotional, prestige, and sensationalist, and propose a simulation-based framework for modeling sequential information exposure and reinforcement dynamics characteristic of ranking and recommendation systems. Within this framework, we construct framing-sensitive agent personas by fine-tuning language models with framing-conditioned loss attenuation, inducing targeted biases while preserving overall task competence. Using Monte Carlo trajectory sampling, we show that small, systematic shifts in acceptance and confidence can compound over time, producing substantial divergence in cumulative information health trajectories. Human evaluation further confirms that FrameRef's generated framings measurably affect human judgment. Together, our dataset and framework provide a foundation for systematic information health research through simulation, complementing and informing responsible human-centered research. We release FrameRef, code, documentation, human evaluation data, and persona adapter models at https://github.com/infosenselab/frameref.

</details>


### [45] [From PhysioNet to Foundation Models -- A history and potential futures](https://arxiv.org/abs/2602.15371)
*Gari D. Clifford*

Main category: cs.CY

TL;DR: 回顾医学数据共享35年演变，从磁带到互联网，聚焦心电生理信号数据库PhysioNet 25年发展，探讨AI时代大规模生理数据库、开源代码、公开竞赛的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 分析医学数据共享从传统方式到现代AI驱动的演变过程，特别是PhysioNet资源25年发展经验，探讨当前大规模生理数据库、开源模型和公开竞赛面临的新挑战与机遇。

Method: 基于作者25年参与PhysioNet资源开发的第一手经验，结合心电生理学领域案例，从历史视角分析医学数据共享演变，并探讨未来发展方向和解决方案。

Result: 识别出PhysioNet资源最有前景的未来方向，包括基础模型与AI碳足迹平衡、Tiny-ML与边缘计算潜力、竞赛激励模式、资金模型、科学可重复性等关键议题。

Conclusion: 医学数据共享面临AI时代新挑战，但通过PhysioNet挑战赛等开放获取模式，结合可持续的AI发展策略，能够解决大规模生理数据库应用中的关键问题，推动领域进步。

Abstract: Over the last 35 years, the sharing of medical data and models for research has evolved from sneakernet to the internet - from mailing magnetic tapes and compact discs of a handful of well-curated recordings, to the high-speed download of relatively comprehensive hospital databases. More recently, the fervor around the potential for modern machine learning and 'AI' to catapult us into the next industrial revolution has led to a seemingly insatiable desire to pump almost any source of data into large models. Although this has great potential, it also presents a whole set of new challenges. In this article I examine these trends over the last 30 years, drawing on examples from cardiology, one of the oldest data-intensive fields that is undergoing a renaissance via machine learning. From the early days of computerized cardiology, the Research Resource for Complex Physiologic Signals (PhysioNet) has been at the cutting edge of this field. This article, therefore, includes much of the Resource's history and the contributions drawn from 25 years of firsthand experience of co-developing elements of the Resource with its founders. I identify the most promising future directions for the PhysioNet Resource, and more generally, the growing issues and opportunities around dissemination and use of massive physiological databases, associated open access code, and public competitions, along with potential solutions to the key issues facing our field. Topics range from how we should approach foundation models in the context of the rapidly growing AI carbon footprint, to the potential of Tiny-ML and edge computing. I also cover issues around prizes and incentives, funding models, and scientific repeatability, as well as how we might address these issues by leveraging the PhysioNet Challenges, consistent with the philosophy of open-access from the early days of the PhysioNet Resource.

</details>


### [46] [What makes an Expert? Comparing Problem-solving Practices in Data Science Notebooks](https://arxiv.org/abs/2602.15428)
*Manuel Valle Torre,Marcus Specht,Catharine Oertel*

Main category: cs.CY

TL;DR: 专家与新手在数据科学问题解决过程中的差异：专家采用更短、更迭代的工作流程和高效的动作序列，而非遵循不同的阶段转换模式。


<details>
  <summary>Details</summary>
Motivation: 数据科学专业知识需要难以直接传授的隐性、过程导向技能。本研究旨在实证理解专家与新手在问题解决过程中的差异，为数据科学教育提供基于证据的指导。

Method: 对440个Jupyter笔记本进行多层次序列分析，将低级别编码动作映射到高级别问题解决实践，比较专家和新手的工作流程结构。

Result: 专家与新手在数据科学阶段转换（如数据导入、EDA、模型训练、可视化）上没有根本差异。差异主要体现在：1）整体工作流程结构 - 新手倾向于长线性过程，专家采用短迭代策略；2）单元格级别的精细动作模式 - 专家使用高效、上下文特定的动作序列。

Conclusion: 数据科学教育应关注培养灵活、迭代的思维方式，而不仅仅是最终产品。在AI工具日益重要的背景下，这种过程导向的教学方法尤为重要，为课程设计和评估提供了实证依据。

Abstract: The development of data science expertise requires tacit, process-oriented skills that are difficult to teach directly. This study addresses the resulting challenge of empirically understanding how the problem-solving processes of experts and novices differ. We apply a multi-level sequence analysis to 440 Jupyter notebooks from a public dataset, mapping low-level coding actions to higher-level problem-solving practices. Our findings reveal that experts do not follow fundamentally different transitions between data science phases than novices (e.g., Data Import, EDA, Model Training, Visualization). Instead, expertise is distinguished by the overall workflow structure from a problem-solving perspective and cell-level, fine-grained action patterns. Novices tend to follow long, linear processes, whereas experts employ shorter, more iterative strategies enacted through efficient, context-specific action sequences. These results provide data science educators with empirical insights for curriculum design and assessment, shifting the focus from final products toward the development of the flexible, iterative thinking that defines expertise-a priority in a field increasingly shaped by AI tools.

</details>


### [47] [From Earthquake Solidarity to Educational Equity: Conceptualizing a Sustainable, Volunteer-Driven P2P Learning Ecosystem at Scale](https://arxiv.org/abs/2602.15432)
*Öykü Kaplan,Adam Przybyłek,Michael Neumann,Netta Iivari*

Main category: cs.CY

TL;DR: 该研究分析了一个由志愿者驱动的P2P教育项目如何从2023年土耳其地震的紧急响应演变为可持续生态系统，运行两年多，服务300多名中学生和40多名志愿者导师。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在完全在线、非互惠的远同伴辅导环境中，社会技术动态如何支持长期韧性，理解从紧急响应到可持续生态系统的转变机制。

Method: 采用解释性案例研究方法，通过参与观察、焦点小组、问卷调查和协作愿景研讨会进行数据三角验证，分析社会技术动态。

Result: 研究发现：年龄相近促进信任但带来教学权威挑战；志愿者参与主要受内在动机驱动；学生报告信心、表达能力和理解力显著提升；学生将导师视为榜样并希望成为未来导师；双方都呼吁专用平台支持。

Conclusion: 研究综合这些发现提出了理论启示和五个设计原则，用于构建可持续的大规模P2P学习生态系统，强调代际互惠循环、安全空间和平台支持的重要性。

Abstract: This study examines the evolution of a grassroots, volunteer-driven peer-to-peer (P2P) educational initiative from an emergency response to the 2023 Türkiye earthquake into a sustainable ecosystem that operated for over two years and supported 300+ middle-school learners with 40+ volunteer tutors. Employing an interpretive case study approach, we triangulated data from participant observation, focus groups, questionnaires, and collaborative visioning workshops to investigate the socio-technical dynamics enabling long-term resilience in a fully online, nonreciprocal far-peer tutoring setting. Our findings reveal that while age proximity fosters trust and open communication, it also poses challenges for tutors who must balance peer rapport with instructional authority. Volunteer engagement is driven primarily by intrinsic motives - educational impact and community belonging - while optional micro-earning is envisioned as a practical enabler for long-term sustainability. Tutees report significant gains in confidence, self-expression, and accelerated comprehension, attributing these outcomes to personalized, interactive sessions within a "family-like" safe space that combines academic instruction with socio-emotional support. Notably, tutees view tutors as aspirational role models and express strong intentions to return as tutors themselves, envisioning a self-regenerating cycle of intergenerational reciprocity that carries knowledge and solidarity from generation to generation. Both cohorts call for a dedicated platform featuring integrated scheduling, personalization, feedback, and quality assurance mechanisms. We synthesize these insights into theory-informed implications and five design principles for sustainable P2P learning ecosystems at scale.

</details>


### [48] [How to Detect Information Voids Using Longitudinal Data from Social Media and Web Searches](https://arxiv.org/abs/2602.15476)
*Irene Scalco,Francesco Gesualdo,Roy Cerqueti,Matteo Cinelli*

Main category: cs.CY

TL;DR: 该研究利用注意力经济模型中的信息供需反馈循环，开发了一种检测和量化信息空白（即特定主题上可靠信息稀缺的时期）的方法，并通过COVID-19疫苗在欧洲六国推广的案例研究，发现信息空白与错误信息高发相关。


<details>
  <summary>Details</summary>
Motivation: 当前信息传播环境中存在信息空白（information voids）现象，即特定主题上可靠信息稀缺的时期。这些空白期可能成为错误信息滋生的温床，但缺乏系统性的检测和量化方法。研究旨在通过注意力经济模型来理解信息空白如何形成、持续，并验证其与错误信息传播的关联。

Method: 基于注意力经济模型，利用信息供给和需求之间的反馈循环开发信息空白检测方法。采用多平台数据（Facebook、Google、Twitter、Wikipedia、在线新闻媒体）进行案例研究，分析COVID-19疫苗在欧洲六国推广期间的信息传播模式。将信息空白概念化为特定的信息传播机制，并量化其对应概念——信息过剩。

Result: 研究发现信息空白确实存在，并且与高质量信息在线流通比例的下降相关。信息空白区域中错误信息的流行率更高，成为个体更容易被低质量在线内容误导的问题热点。研究还量化了信息过剩，这是当前信息流行病定义的核心组成部分。

Conclusion: 信息空白与错误信息的高发存在关联，为将信息空白纳入错误信息出现的机制性解释提供了实证支持。这些发现有助于更全面地理解信息流行病现象，并为监测和干预错误信息传播提供了新的视角。

Abstract: The model of the attention economy, where content producers compete for the attention of users, relies on two key forces: information supply and demand. This study leverages the feedback loop between these forces to develop a method for detecting and quantifying information voids, i.e., periods in which little or no reliable information is available on a given topic. Using a case study on COVID-19 vaccines rollout in six European countries, and drawing on data from multiple platforms including Facebook, Google, Twitter, Wikipedia, and online news outlets, we examine how information voids emerge, persist and correlate with a decline in the proportion of high-quality information circulating online. By conceptualising information voids as a specific regime of information spreading, we also quantify their counterpart, information overabundance, which constitute a central component of the current definition of infodemic. We show that information voids are associated with a higher prevalence of misinformation, thus representing problematic hotspots in which individuals are more likely to be misled by low-quality online content. Overall, our findings provide empirical support for the inclusion of information voids in mechanistic explanations of misinformation emergence.

</details>


### [49] [Who Is Doing the Thinking? AI as a Dynamic Cognitive Partner: A Learner-Informed Framework](https://arxiv.org/abs/2602.15638)
*C. K. Y Chan*

Main category: cs.CY

TL;DR: 本研究提出AI作为动态认知伙伴的框架，通过分析133名香港中学生的质性数据，识别出AI支持学生认知的九个维度，区分了促进理解的生产性支持与替代认知努力的非生产性依赖。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能在教育中的应用日益广泛，但学生如何概念化AI在他们思维和学习中的角色仍需要解释。当前缺乏一个框架来理解AI如何作为动态认知伙伴在不同学习情境中发挥作用。

Method: 采用质性分析方法，分析133名香港中学生在完成AI素养课程后的书面回答，识别学习者描述AI作为认知伙伴的维度。

Result: 识别出九个相互关联的维度：概念支架、反馈与错误检测、思维激发、认知组织、适应性辅导支持、元认知监控支持、任务与认知负荷调节、课堂边界外的学习连续性、以及通过表征灵活性进行解释重构。学生区分了促进理解的生产性支持和替代认知努力的非生产性依赖。

Conclusion: 基于社会文化理论、分布式认知、自我调节学习和认知负荷视角，该框架阐明了AI如何融入学习者的认知活动，同时揭示了认知扩展与替代之间的边界，表明学生具有情境意识，知道何时应该和不应该使用AI。

Abstract: Artificial intelligence is increasingly embedded in education, yet there remains a need to explain how students conceptualize AI's role in their thinking and learning. This study proposes a framework positioning AI as a dynamic cognitive partner whose function shifts across learning situations. Using qualitative analysis of written responses from 133 secondary students in Hong Kong following completion of an AI literacy course, we identified nine interrelated dimensions through which learners described AI as partnering with their cognition: conceptual scaffolding for difficult ideas; feedback and error detection; idea stimulation; cognitive organization; adaptive tutoring support; metacognitive monitoring support; task and cognitive load regulation; learning continuity beyond classroom boundaries; and explanation reframing through representational flexibility during moments of being stuck or overwhelmed. Across these dimensions, students distinguished between productive support that extends understanding and unproductive reliance that replaces cognitive effort, indicating situational awareness of when AI should and should not be used. Grounded in sociocultural theory, distributed cognition, self-regulated learning, and cognitive load perspectives, the framework clarifies how AI becomes integrated into learners' cognitive activity while illuminating the boundary between cognitive extension and substitution.

</details>
