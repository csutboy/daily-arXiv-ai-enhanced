<div id=toc></div>

# Table of Contents

- [cs.SI](#cs.SI) [Total: 9]
- [cs.CY](#cs.CY) [Total: 3]
- [eess.SY](#eess.SY) [Total: 19]
- [cs.RO](#cs.RO) [Total: 32]
- [econ.EM](#econ.EM) [Total: 2]
- [stat.AP](#stat.AP) [Total: 1]
- [econ.TH](#econ.TH) [Total: 1]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.AI](#cs.AI) [Total: 60]


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [1] [FTSCommDetector: Discovering Behavioral Communities through Temporal Synchronization](https://arxiv.org/abs/2510.00014)
*Tianyang Luo,Xikun Zhang,Dongjin Song*

Main category: cs.SI

TL;DR: 提出了FTSCommDetector方法，使用时间一致性架构(TCA)来发现连续多元时间序列中的相似和相异社区，解决了传统社区检测方法无法捕捉同步-去同步模式的问题。


<details>
  <summary>Details</summary>
Motivation: 传统社区检测方法无法解释像AAPL和MSFT这样相同行业分类的公司在市场动荡时出现不同响应模式的现象，因为它们无法捕捉实体在关键时刻对齐但在其他时间独立移动的同步-去同步模式。

Method: FTSCommDetector采用时间一致性架构(TCA)，通过双尺度编码和静态拓扑与动态注意力机制来保持时间一致性，不同于现有方法独立处理每个时间戳。还建立了信息论基础证明尺度分离如何最大化互补信息，并引入归一化时间剖面(NTP)进行尺度不变评估。

Result: 在四个不同的金融市场(SP100、SP500、SP1000、日经225)上，FTSCommDetector相比最强基线实现了3.5%到11.1%的性能提升。该方法表现出显著的鲁棒性，在60到120天的窗口大小范围内仅有2%的性能变化。

Conclusion: FTSCommDetector提供了一种有效的方法来发现时间序列中的同步-去同步社区模式，为投资组合构建和风险管理提供了实用见解，且无需针对特定数据集进行调优。

Abstract: Why do trillion-dollar tech giants AAPL and MSFT diverge into different
response patterns during market disruptions despite identical sector
classifications? This paradox reveals a fundamental limitation: traditional
community detection methods fail to capture synchronization-desynchronization
patterns where entities move independently yet align during critical moments.
To this end, we introduce FTSCommDetector, implementing our Temporal Coherence
Architecture (TCA) to discover similar and dissimilar communities in continuous
multivariate time series. Unlike existing methods that process each timestamp
independently, causing unstable community assignments and missing evolving
relationships, our approach maintains coherence through dual-scale encoding and
static topology with dynamic attention. Furthermore, we establish
information-theoretic foundations demonstrating how scale separation maximizes
complementary information and introduce Normalized Temporal Profiles (NTP) for
scale-invariant evaluation. As a result, FTSCommDetector achieves consistent
improvements across four diverse financial markets (SP100, SP500, SP1000,
Nikkei 225), with gains ranging from 3.5% to 11.1% over the strongest
baselines. The method demonstrates remarkable robustness with only 2%
performance variation across window sizes from 60 to 120 days, making
dataset-specific tuning unnecessary, providing practical insights for portfolio
construction and risk management.

</details>


### [2] [When Life Paths Cross: Extracting Human Interactions in Time and Space from Wikipedia](https://arxiv.org/abs/2510.00019)
*Zhongyang Liu,Ying Zhang,Xiangyi Xiao,Wenting Liu,Yuanting Zha,Haipeng Zhang*

Main category: cs.SI

TL;DR: 从维基百科传记中提取685,966条人物交互记录，开发集成注意力机制和多任务学习的模型，F1分数达86.51%，用于分析美国政治人物交互以研究政治极化。


<details>
  <summary>Details</summary>
Motivation: 人物交互分析在文化、经济、政治等领域具有重要意义，但受限于位置和时间信息的稀缺性，需要从大规模文本中提取结构化交互数据。

Method: 从维基百科数百万传记页面中提取交互四元组(人物1,人物2,时间,位置)，设计集成注意力机制、多任务学习和特征迁移的模型来处理文本异质性和松散关联问题。

Result: 模型F1分数达到86.51%，优于基线模型；提取了685,966条交互记录，并构建了包含4,507条标注四元组的WikiInteraction数据集；通过美国政治人物交互分析展示了数据价值。

Conclusion: 成功开发了从维基百科提取人物交互信息的高效方法，为研究社会网络动态提供了大规模数据集，并在政治极化分析中验证了其应用潜力。

Abstract: Interactions among notable individuals -- whether examined individually, in
groups, or as networks -- often convey significant messages across cultural,
economic, political, scientific, and historical perspectives. By analyzing the
times and locations of these interactions, we can observe how dynamics unfold
across regions over time. However, relevant studies are often constrained by
data scarcity, particularly concerning the availability of specific location
and time information. To address this issue, we mine millions of biography
pages from Wikipedia, extracting 685,966 interaction records in the form of
(Person1, Person2, Time, Location) interaction quadruplets. The key elements of
these interactions are often scattered throughout the heterogeneous
crowd-sourced text and may be loosely or indirectly associated. We overcome
this challenge by designing a model that integrates attention mechanisms,
multi-task learning, and feature transfer methods, achieving an F1 score of
86.51%, which outperforms baseline models. We further conduct an empirical
analysis of intra- and inter-party interactions among political figures to
examine political polarization in the US, showcasing the potential of the
extracted data from a perspective that may not be possible without this data.
We make our code, the extracted interaction data, and the WikiInteraction
dataset of 4,507 labeled interaction quadruplets publicly available.

</details>


### [3] [IA aplicada al análisis del conflicto Irán-Israel: Mapeo de discursos en YouTube](https://arxiv.org/abs/2510.00021)
*Alvaro Vallejo Ramírez*

Main category: cs.SI

TL;DR: 本研究基于YouTube上的12万条评论，分析了2025年6月伊朗-以色列冲突的数字表征，识别了相关参与者的论述立场，并探讨了媒体和算法偏见如何塑造数字对话。


<details>
  <summary>Details</summary>
Motivation: 分析数字空间中伊朗-以色列冲突的论述表征，识别媒体和算法偏见对数字对话的影响，揭示常被忽视的叙事不对称性。

Method: 采用混合方法设计：定量阶段使用NLP技术和机器学习模型（BERT和XLM-RoBERTa）将评论分为10类；定性阶段进行媒体背景和意识形态叙事的批判分析，辅以人工标注和监督训练。

Result: 研究发现亲巴勒斯坦和反美国/以色列论述明显过度代表，而亲美国和反巴勒斯坦立场边缘化。伊朗在冲突期间成为数字对话的中心角色，表明叙事从先前霸权框架的转变。算法偏见在放大某些论述同时限制其他论述的影响得到证实。

Conclusion: 本研究为数字争议研究提供了结合计算分析和哲学批判的方法论框架，是首个通过人工智能和批判分析在YouTube上映射国际冲突论述的西班牙语研究之一，揭示了常被忽视的不对称性和叙事争议。

Abstract: Purpose. This study analyzes the digital representation of the Iran-Israel
conflict that occurred in June 2025, based on 120,000 comments posted on
YouTube. It sought to identify discursive positions regarding the actors
involved and to examine how media and algorithmic biases shape digital
conversations. Methodology. A mixed-methods design with triangulation was
adopted. In the quantitative phase, natural language processing techniques and
machine learning models (BERT and XLM-RoBERTa) were used to classify comments
into ten categories. In the qualitative phase, a critical analysis of media
context and ideological narratives was conducted, complemented by manual
annotation and supervised training. This strategy enabled the integration of
statistical robustness with contextual understanding. Results and conclusions.
The findings reveal a clear overrepresentation of pro-Palestinian and
anti-United States/Israel discourses, while pro-United States and
anti-Palestinian positions were marginal. Iran, usually rendered invisible in
global media, emerged as a central actor in the digital conversation during the
conflict, suggesting a narrative shift away from previous hegemonic frameworks.
Likewise, the results confirm the influence of algorithmic biases in amplifying
certain discourses while limiting others. Original contributions. This work
combines computational analysis and philosophical critique for the study of
digital controversies, providing a methodological framework replicable in
geopolitical contexts. It is one of the first Spanish-language studies to map,
through artificial intelligence and critical analysis, discourses on an
international conflict on YouTube, highlighting asymmetries and narrative
disputes that are often overlooked.

</details>


### [4] [EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis](https://arxiv.org/abs/2510.00024)
*Mohammad Hossein Samaei,Faryad Darabi Sahneh,Lee W. Cohnstaedt,Caterina Scoglio*

Main category: cs.SI

TL;DR: EpidemIQs是一个多智能体LLM框架，用于自动化流行病建模研究，能够自主完成文献综述、分析推导、网络建模、随机模拟等任务，并以科学论文格式生成完整报告。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型自动化复杂的跨学科研究领域，特别是流行病建模这种涉及网络科学、动力系统、流行病学和随机模拟的复杂领域。

Method: 采用多智能体框架，包括科学家智能体（负责规划、协调和生成最终结果）和任务专家智能体（专注于特定任务），使用GPT 4.1和GPT 4.1 mini作为骨干模型。

Result: 框架能够100%成功生成完整科学报告，平均总token使用量为870K，每项研究成本约1.57美元，在五个不同场景中均表现优于单智能体方法。

Conclusion: EpidemIQs通过显著降低发现过程的成本和周转时间，并增强对先进建模工具的可访问性，推动了科学研究的加速发展。

Abstract: Large Language Models (LLMs) offer new opportunities to automate complex
interdisciplinary research domains. Epidemic modeling, characterized by its
complexity and reliance on network science, dynamical systems, epidemiology,
and stochastic simulations, represents a prime candidate for leveraging
LLM-driven automation. We introduce \textbf{EpidemIQs}, a novel multi-agent LLM
framework that integrates user inputs and autonomously conducts literature
review, analytical derivation, network modeling, mechanistic modeling,
stochastic simulations, data visualization and analysis, and finally
documentation of findings in a structured manuscript. We introduced two types
of agents: a scientist agent for planning, coordination, reflection, and
generation of final results, and a task-expert agent to focus exclusively on
one specific duty serving as a tool to the scientist agent. The framework
consistently generated complete reports in scientific article format.
Specifically, using GPT 4.1 and GPT 4.1 mini as backbone LLMs for scientist and
task-expert agents, respectively, the autonomous process completed with average
total token usage 870K at a cost of about \$1.57 per study, achieving a 100\%
completion success rate through our experiments. We evaluate EpidemIQs across
different epidemic scenarios, measuring computational cost, completion success
rate, and AI and human expert reviews of generated reports. We compare
EpidemIQs to the single-agent LLM, which has the same system prompts and tools,
iteratively planning, invoking tools, and revising outputs until task
completion. The comparison shows consistently higher performance of the
proposed framework across five different scenarios. EpidemIQs represents a step
forward in accelerating scientific research by significantly reducing costs and
turnaround time of discovery processes, and enhancing accessibility to advanced
modeling tools.

</details>


### [5] [Modeling Product Ecosystems](https://arxiv.org/abs/2510.00036)
*Tridib Banerjee*

Main category: cs.SI

TL;DR: 本文开发了一个动态系统框架来建模产品采用网络中的影响传播，使用Metzler交互矩阵和基于效用的衰减。推导了恒定、分段恒定和完全时变交互结构的精确解，建立了五个关键结果，包括正交互保证非负放大、感知效用饱和、引入频率主导质量改进等。


<details>
  <summary>Details</summary>
Motivation: 将流行病阈值理论和正系统分析扩展到网络化采用场景，为网络上的影响动态提供可校准的显式表达式。

Method: 使用Metzler交互矩阵和基于效用的衰减构建正线性系统，通过矩阵指数和Peano-Baker级数推导精确解。

Result: 建立了五个核心结果：正交互的非负放大特性、感知效用的韦伯-费希纳饱和、引入频率优于质量改进、强化交互的单调增益效应，以及SIS型动态下长期保持的谱半径上界。

Conclusion: 该框架将流行病阈值理论和正系统分析成功扩展到网络化采用场景，为影响动态提供了可校准的显式表达式，深化了对网络传播机制的理解。

Abstract: This paper develops a dynamical-systems framework for modeling influence
propagation in product adoption networks, formulated as a positive linear
system with Metzler interaction matrices and utility-based decay. Exact
solutions are derived for constant, piecewise-constant, and fully time-varying
interaction structures using matrix exponentials and the Peano--Baker series.
It establishes five results: (i) positive interactions guarantee nonnegative
amplification, (ii) perceived utility saturates after $\approx\!3$
complementary additions (Weber--Fechner), (iii) frequency of comparable
introductions dominates incremental quality improvements, (iv) reinforcing
interactions yields monotone gains while decay control gives ambiguous effects,
and (v) long-run retention under SIS-type dynamics is bounded by the inverse
spectral radius of the adoption graph. These results extend epidemic-threshold
theory and positive-systems analysis to networked adoption, yielding explicit,
calibratable expressions for influence dynamics on networks.

</details>


### [6] [SoREX: Towards Self-Explainable Social Recommendation with Relevant Ego-Path Extraction](https://arxiv.org/abs/2510.00080)
*Hanze Guo,Yijun Ma,Xiao Zhou*

Main category: cs.SI

TL;DR: SoREX是一个基于图神经网络的自解释社交推荐框架，通过两塔架构和好友推荐增强社交信号，提供基于自我路径提取的解释机制。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于GNN的社交推荐方法缺乏有意义的预测解释能力的问题，提升推荐系统的可解释性。

Method: 采用两塔框架独立建模社交关系和用户-物品交互，通过辅助任务强化社交信号；提出自我路径提取方法，将目标用户的自我网络转化为多跳自我路径集合，提取因子特定和候选物品感知的自我路径子集作为解释。

Result: 在四个广泛采用的基准数据集上的综合实验验证了SoREX在预测准确性方面的有效性；定性和定量分析确认了提取解释的有效性。

Conclusion: SoREX框架不仅提高了推荐准确性，还通过创新的自我路径提取和解释重聚合机制实现了内在的自解释能力，为社交推荐提供了有意义的解释。

Abstract: Social recommendation has been proven effective in addressing data sparsity
in user-item interaction modeling by leveraging social networks. The recent
integration of Graph Neural Networks (GNNs) has further enhanced prediction
accuracy in contemporary social recommendation algorithms. However, many
GNN-based approaches in social recommendation lack the ability to furnish
meaningful explanations for their predictions. In this study, we confront this
challenge by introducing SoREX, a self-explanatory GNN-based social
recommendation framework. SoREX adopts a two-tower framework enhanced by friend
recommendation, independently modeling social relations and user-item
interactions, while jointly optimizing an auxiliary task to reinforce social
signals. To offer explanations, we propose a novel ego-path extraction
approach. This method involves transforming the ego-net of a target user into a
collection of multi-hop ego-paths, from which we extract factor-specific and
candidate-aware ego-path subsets as explanations. This process facilitates the
summarization of detailed comparative explanations among different candidate
items through intricate substructure analysis. Furthermore, we conduct
explanation re-aggregation to explicitly correlate explanations with downstream
predictions, imbuing our framework with inherent self-explainability.
Comprehensive experiments conducted on four widely adopted benchmark datasets
validate the effectiveness of SoREX in predictive accuracy. Additionally,
qualitative and quantitative analyses confirm the efficacy of the extracted
explanations in SoREX. Our code and data are available at
https://github.com/antman9914/SoREX.

</details>


### [7] [Mobility Behavior Evolution During Extended Emergencies: Returners, Explorers, and the 15-Minute City](https://arxiv.org/abs/2510.00469)
*Omid Armantalab,Jason Hawkins,Wissam Kontar*

Main category: cs.SI

TL;DR: 研究使用YJMob100K数据集分析紧急情况下人类移动行为，重点关注返回者和探索者之间的转换模式，发现至少需要两周数据才能检测到有意义的行为变化，并揭示了空间可达性对城市韧性的重要性。


<details>
  <summary>Details</summary>
Motivation: 理解紧急情况下的人类移动行为对于增强城市韧性和指导应急管理至关重要，需要揭示在精细空间尺度下被掩盖的行为动态。

Method: 使用YJMob100K数据集，分析15天紧急期间在人口密集大都市区域的移动行为，重点关注返回者（重复访问有限地点）和探索者（跨更广目的地旅行）之间的转换，结合15分钟城市框架分析时空动态。

Result: 结果显示：至少需要两周数据才能检测到有意义的行为变化；长期紧急情况下，个体恢复访问非必要地点的速度较慢；探索者显著减少长距离旅行；周末和节假日呈现返回者式的短距离模式；低POI密度社区居民常前往POI丰富区域。

Conclusion: 加强本地可达性可能提高危机期间的城市韧性，空间差异在紧急情况下表现明显，精细空间数据对于理解城市移动行为动态至关重要。

Abstract: Understanding human mobility during emergencies is critical for strengthening
urban resilience and guiding emergency management. This study examines
transitions between returners, who repeatedly visit a limited set of locations,
and explorers, who travel across broader destinations, over a 15-day emergency
period in a densely populated metropolitan region using the YJMob100K dataset.
High-resolution spatial data reveal intra-urban behavioral dynamics often
masked at coarser scales. Beyond static comparisons, we analyze how mobility
evolves over time, with varying emergency durations, across weekdays and
weekends, and relative to neighborhood boundaries, linking the analysis to the
15-minute city framework.
  Results show that at least two weeks of data are required to detect
meaningful behavioral shifts. During prolonged emergencies, individuals resume
visits to non-essential locations more slowly than under normal conditions.
Explorers markedly reduce long distance travel, while weekends and holidays
consistently exhibit returner-like, short distance patterns. Residents of low
Points of Interest (POI) density neighborhoods often travel to POI rich areas,
highlighting spatial disparities. Strengthening local accessibility may improve
urban resilience during crises.
  Full reproducibility is supported through the project website:
https://github.com/wissamkontar

</details>


### [8] [Threats to the sustainability of Community Notes on X](https://arxiv.org/abs/2510.00650)
*Zahra Arjmandi-Lari,Alexios Mantzarlis,Tom Stafford*

Main category: cs.SI

TL;DR: 分析了X平台社区笔记系统的效果，发现发布笔记对作者未来创作有积极影响，但当前系统只有10%的笔记被认定为"有帮助"且比例在下降，存在风险。


<details>
  <summary>Details</summary>
Motivation: 理解社区笔记系统背后的用户动机，特别是除了党派对立之外的其他驱动因素，以及评估该系统的稳定性和潜在破坏性。

Method: 使用回归断点设计分析笔记发布的影响，这种方法比传统的观察数据方法能提供更强的因果推断。

Result: 研究发现发布笔记对作者未来的笔记创作有积极影响，但当前系统只有10%的笔记被认定为"有帮助"，且这一比例在下降。

Conclusion: 当前社区笔记系统存在风险，这对X平台社区笔记的未来发展以及该方法在其他平台的扩展具有重要意义。

Abstract: Community Notes are emerging as an important option for content moderation.
The Community Notes system pioneered by Twitter, now known as X, uses a
bridging algorithm to identify user-generated context with upvotes across
political divides, supposedly spinning consensual gold from partisan straw. It
is important to understand the nature of the community behind Community Notes,
especially as the feature has now been imitated by several billion-user
platforms. We look for signs of stability and disruption in the X Community
Notes community and interrogate the motivations other than partisan animus
(Allen, Martel, and Rand 2022) which may be driving users to contribute. We
conduct a novel analysis of the impact of having a note published, which
requires being considered "helpful" by the bridging algorithm, utilising a
regression discontinuity design. This allows stronger causal inference than
conventional methods used with observational data. Our analysis shows the
positive effect on future note authoring of having a note published. This
highlights the risk of the current system, where the proportion of notes
considered "helpful" (and therefore shown to users on X) is low, 10%, and
declining. This analysis has implications for the future of Community Notes on
X and the extension of this approach to other platforms.

</details>


### [9] [Discovering Communities in Continuous-Time Temporal Networks by Optimizing L-Modularity](https://arxiv.org/abs/2510.00741)
*Victor Brabant,Angela Bonifati,Rémy Cazabet*

Main category: cs.SI

TL;DR: LAGO是一种用于动态社区检测的新方法，通过贪婪优化纵向模块度来发现连续时间网络中的动态社区，能够精确捕捉节点进出社区的时间点。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的动态数据需要具有精确时间准确性的社区检测方法，而现有方法要么依赖时间离散化，要么假设社区演化模式过于刚性，无法捕捉节点进出社区的精确时刻。

Method: LAGO通过贪婪优化纵向模块度（Longitudinal Modularity）来发现动态社区，这是模块度在连续时间网络中的特定适应形式，能够精确追踪节点进入和退出社区的时间点。

Result: 在合成基准测试和真实世界数据集上的评估表明，LAGO能够高效地发现时间和拓扑上一致的社区。

Conclusion: LAGO提供了一种有效的方法来发现动态网络中的社区结构，能够精确捕捉社区演化的时间动态性，克服了现有方法在时间精度方面的局限性。

Abstract: Community detection is a fundamental problem in network analysis, with many
applications in various fields. Extending community detection to the temporal
setting with exact temporal accuracy, as required by real-world dynamic data,
necessitates methods specifically adapted to the temporal nature of
interactions. We introduce LAGO, a novel method for uncovering dynamic
communities by greedy optimization of Longitudinal Modularity, a specific
adaptation of Modularity for continuous-time networks. Unlike prior approaches
that rely on time discretization or assume rigid community evolution, LAGO
captures the precise moments when nodes enter and exit communities. We evaluate
LAGO on synthetic benchmarks and real-world datasets, demonstrating its ability
to efficiently uncover temporally and topologically coherent communities.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [10] [Simulating Student Success in the Age of GenAI: A Kantian-Axiomatic Perspective](https://arxiv.org/abs/2510.00091)
*Seyma Yaman Kayadibi*

Main category: cs.CY

TL;DR: 该研究通过康德公理视角重新解读学生对生成式AI感知成功的蒙特卡洛模拟，发现有限离散数据满足基本排序公理但无法满足无端点性和密度性，这反映了经验观察与理想连续统之间的认识论边界。


<details>
  <summary>Details</summary>
Motivation: 旨在探讨有限经验数据与理想数学结构（如无端点密集线性序）之间的关系，揭示模拟方法在捕捉学生感知结构时的局限性，并从康德哲学角度理解这种局限性。

Method: 使用先前工作的主题级调查统计数据，在[1,5]李克特量表上生成10,000个合成分数，然后评估这些模拟输出是否符合密集线性序的公理要求。

Result: 数据层面满足基本排序公理（A1-A3），但无法满足无端点性（A4-A5）和密度性（A6），这些失败被视为认识论边界的标志而非方法缺陷。

Conclusion: 有限量化观察无法实例化无界密集连续统的理想属性，这些属性属于构造性直觉而非有限抽样本身，研究为理解学生感知的先天结构提供了新的解释框架。

Abstract: This study reinterprets a Monte Carlo simulation of students' perceived
success with generative AI (GenAI) through a Kantian-axiomatic lens. Building
on prior work, theme-level survey statistics Ease of Use and Learnability,
System Efficiency and Learning Burden, and Perceived Complexity and Integration
from a representative dataset are used to generate 10,000 synthetic scores per
theme on the [1,5] Likert scale. The simulated outputs are evaluated against
the axioms of dense linear order without endpoints (DLO): irreflexivity,
transitivity, total comparability (connectedness), no endpoints (no greatest
and no least; A4-A5), and density (A6). At the data level, the basic ordering
axioms (A1-A3) are satisfied, whereas no-endpoints (A4-A5) and density (A6)
fail as expected. Likert clipping introduces minimum and maximum observed
values, and a finite, discretized sample need not contain a value strictly
between any two distinct scores. These patterns are read not as methodological
defects but as markers of an epistemological boundary. Following Kant and
Friedman, the findings suggest that what simulations capture finite, quantized
observations cannot instantiate the ideal properties of an unbounded, dense
continuum. Such properties belong to constructive intuition rather than to
finite sampling alone. A complementary visualization contrasts the empirical
histogram with a sine-curve proxy to clarify this divide. The contribution is
interpretive rather than data-expansive: it reframes an existing simulation as
a probe of the synthetic a priori structure underlying students' perceptions,
showing how formal order-theoretic coherence coexists with principled failures
of endpoint-freeness and density in finite empirical models.

</details>


### [11] [Digital Domination: A Case for Republican Liberty in Artificial Intelligence](https://arxiv.org/abs/2510.00312)
*Matthew David Hamilton*

Main category: cs.CY

TL;DR: 本文探讨人工智能如何威胁共和主义自由观，通过分析数字广告和社交媒体算法，揭示AI在个体和政治层面造成的新型不自由状态——数字支配。


<details>
  <summary>Details</summary>
Motivation: AI正以不可预测的方式改变社会政治生活，需要明确指导其发展和监管的原则。文章关注AI对共和主义自由（免于无问责权力的自由）构成的威胁。

Method: 通过分析数字广告和社交媒体算法，结合昆汀·斯金纳、菲利普·佩蒂特等共和主义理论家的著作，从个体和政治两个层面探讨AI的影响。

Result: 发现AI在个体层面能潜意识影响行为和思想，被影响者对这些算法控制有限；在政治层面，让科技公司高管和外国势力能影响国内政治进程，而现有国家制度难以有效问责这些行为者。

Conclusion: 必须建立机制让个人能够对算法及其开发者进行问责，才能真正实现自由。AI已经创造了一种新型的不自由状态——数字支配。

Abstract: Artificial intelligence is set to revolutionize social and political life in
unpredictable ways, raising questions about the principles that ought to guide
its development and regulation. By examining digital advertising and social
media algorithms, this article highlights how artificial intelligence already
poses a significant threat to the republican conception of liberty -- or
freedom from unaccountable power -- and thereby highlights the necessity of
protecting republican liberty when integrating artificial intelligence into
society. At an individual level, these algorithms can subconsciously influence
behavior and thought, and those subject to this influence have limited power
over the algorithms they engage. At the political level, these algorithms give
technology company executives and other foreign parties the power to influence
domestic political processes, such as elections; the multinational nature of
algorithm-based platforms and the speed with which technology companies
innovate make incumbent state institutions ineffective at holding these actors
accountable. At both levels, artificial intelligence has thus created a new
form of unfreedom: digital domination. By drawing on the works of Quentin
Skinner, Philip Pettit, and other republican theorists, this article asserts
that individuals must have mechanisms to hold algorithms (and those who develop
them) accountable in order to be truly free.

</details>


### [12] [Disc-Cover Complexity Trends in Music Illustrations from Sinatra to Swift](https://arxiv.org/abs/2510.00990)
*Nicolas Fracaro,Stefano Cecconello,Mauro Conti,Niccolò Di Marco,Alessandro Galeazzi*

Main category: cs.CY

TL;DR: 该研究分析了75年间11种流行音乐类型的专辑封面视觉复杂性，发现大多数流派呈现出向极简主义发展的趋势，但同时也存在例外和随时间增长的多样性。


<details>
  <summary>Details</summary>
Motivation: 专辑封面作为艺术与商业交汇的视觉艺术形式，能够反映文化、技术和商业动态的演变，但此前研究不足。该研究旨在通过计算分析方法系统研究专辑封面作为文化历史档案的价值。

Method: 使用多种计算度量方法，捕捉视觉复杂性的多个维度，分析跨越75年和11种流行音乐类型的专辑封面。

Result: 分析显示大多数流派呈现出向极简主义发展的广泛趋势，但存在显著例外，突显了审美趋势的异质性。同时观察到随时间增长的方差，许多封面继续表现出高度的抽象性和复杂性。

Conclusion: 专辑封面是丰富的、可量化的文化历史档案，计算分析方法在系统研究艺术方面具有重要价值，能够连接定量分析与审美文化探究。

Abstract: The study of art evolution has provided valuable insights into societal
change, often revealing long-term patterns of simplification and
transformation. Album covers represent a distinctive yet understudied form of
visual art that has both shaped and been shaped by cultural, technological, and
commercial dynamics over the past century. As highly visible artifacts at the
intersection of art and commerce, they offer a unique lens through which to
study cultural evolution. In this work, we examine the visual complexity of
album covers spanning 75 years and 11 popular musical genres. Using a diverse
set of computational measures that capture multiple dimensions of visual
complexity, our analysis reveals a broad shift toward minimalism across most
genres, with notable exceptions that highlight the heterogeneity of aesthetic
trends. At the same time, we observe growing variance over time, with many
covers continuing to display high levels of abstraction and intricacy.
Together, these findings position album covers as a rich, quantifiable archive
of cultural history and underscore the value of computational approaches in the
systematic study of the arts, bridging quantitative analysis with aesthetic and
cultural inquiry.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [13] [Robust Attitude Control of Nonlinear Multi-Rotor Dynamics with LFT Models and $\mathcal{H}_\infty$ Performance](https://arxiv.org/abs/2510.00208)
*Tanay Kumar,Raktim Bhattacharya*

Main category: eess.SY

TL;DR: 比较H∞和经典PID控制器在多旋翼无人机姿态调节中的性能，特别是在风扰动和陀螺仪噪声存在的情况下。


<details>
  <summary>Details</summary>
Motivation: 无人机在不确定环境中的姿态稳定面临非线性动力学、参数变化和传感器限制等挑战，需要研究更鲁棒的控制方法。

Method: 使用线性参数变化(LPV)框架建模飞行动力学，将非线性和参数变化表示为结构化不确定性，设计基于H∞公式的鲁棒控制器，仅使用陀螺仪测量。

Result: 非线性仿真结果表明，与经典PID控制相比，鲁棒控制器在严重风扰动下的姿态调节性能有显著改善。

Conclusion: H∞鲁棒控制器在不确定环境下比传统PID控制器具有更好的姿态稳定性能。

Abstract: Attitude stabilization of unmanned aerial vehicles in uncertain environments
presents significant challenges due to nonlinear dynamics, parameter
variations, and sensor limitations. This paper presents a comparative study of
$\mathcal{H}_\infty$ and classical PID controllers for multi-rotor attitude
regulation in the presence of wind disturbances and gyroscope noise. The flight
dynamics are modeled using a linear parameter-varying (LPV) framework, where
nonlinearities and parameter variations are systematically represented as
structured uncertainties within a linear fractional transformation formulation.
A robust controller based on $\mathcal{H}_\infty$ formulation is designed using
only gyroscope measurements to ensure guaranteed performance bounds. Nonlinear
simulation results demonstrate the effectiveness of the robust controllers
compared to classical PID control, showing significant improvement in attitude
regulation under severe wind disturbances.

</details>


### [14] [Combined Learning and Control: A New Paradigm for Optimal Control with Unknown Dynamics](https://arxiv.org/abs/2510.00308)
*Panagiotis Kounatidis,Andreas A. Malikopoulos*

Main category: eess.SY

TL;DR: 提出结合学习与控制（CLC）方法，通过统一基于模型的控制和数据驱动学习来解决未知动力学的最优控制问题。


<details>
  <summary>Details</summary>
Motivation: 解决具有未知动力学的最优控制问题，弥合经典最优控制与现代学习方法之间的差距。

Method: 设计控制器使其在代理目标上最优，同时惩罚与真实系统的失配，从而确保控制器在实际系统上也是最优的。

Result: 在线性二次调节器问题中展示了CLC框架，明确了惩罚权重的设置条件，并开发了直接从数据调整权重的轻量级学习循环。

Conclusion: CLC作为经典最优控制与现代学习方法之间实用且理论基础的桥梁，明确了先验知识何时足够以及何时需要学习。

Abstract: In this paper, we present the combined learning-and-control (CLC) approach,
which is a new way to solve optimal control problems with unknown dynamics by
unifying model-based control and data-driven learning. The key idea is simple:
we design a controller to be optimal for a proxy objective built on an
available model while penalizing mismatches with the real system, so that the
resulting controller is also optimal for the actual system. Building on the
original CLC formulation, we demonstrate the framework to the linear quadratic
regulator problem and make three advances: (i) we show that the CLC penalty is
a sequence of stage-specific weights rather than a single constant; (ii) we
identify when these weights can be set in advance and when they must depend on
the (unknown) dynamics; and (iii) we develop a lightweight learning loop that
tunes the weights directly from data without abandoning the benefits of a
model-based design. We provide a complete algorithm and an empirical study
against common baseline methods. The results clarify where prior knowledge
suffices and where learning is essential, and they position CLC as a practical,
theoretically grounded bridge between classical optimal control and modern
learning methods.

</details>


### [15] [MM-LMPC: Multi-Modal Learning Model Predictive Control via Bandit-Based Mode Selection](https://arxiv.org/abs/2510.00410)
*Wataru Hashimoto,Kazumune Hashimoto*

Main category: eess.SY

TL;DR: 提出了多模态学习模型预测控制（MM-LMPC），通过聚类历史轨迹到不同模式，使用多臂老虎机元控制器平衡探索与利用，解决传统LMPC容易陷入局部最优的问题。


<details>
  <summary>Details</summary>
Motivation: 传统LMPC依赖初始轨迹，容易陷入局部最优，可能错过全局更好的解决方案。例如在避障任务中，可能只优化初始选择的路径而忽略其他可能更优的路径。

Method: 将历史轨迹聚类到不同模式，维护模式特定的终端集和价值函数；使用基于置信下界（LCB）的多臂老虎机元控制器来平衡不同模式间的探索与利用。

Result: 建立了递归可行性、闭环稳定性、渐近收敛到最佳模式以及对数遗憾界；在避障任务仿真中验证了性能提升。

Conclusion: MM-LMPC能够逃离高成本局部最优解，发现全局更优解，在迭代任务中表现出比传统LMPC更好的性能。

Abstract: Learning Model Predictive Control (LMPC) improves performance on iterative
tasks by leveraging data from previous executions. At each iteration, LMPC
constructs a sampled safe set from past trajectories and uses it as a terminal
constraint, with a terminal cost given by the corresponding cost-to-go. While
effective, LMPC heavily depends on the initial trajectories: states with high
cost-to-go are rarely selected as terminal candidates in later iterations,
leaving parts of the state space unexplored and potentially missing better
solutions. For example, in a reach-avoid task with two possible routes, LMPC
may keep refining the initially shorter path while neglecting the alternative
path that could lead to a globally better solution. To overcome this
limitation, we propose Multi-Modal LMPC (MM-LMPC), which clusters past
trajectories into modes and maintains mode-specific terminal sets and value
functions. A bandit-based meta-controller with a Lower Confidence Bound (LCB)
policy balances exploration and exploitation across modes, enabling systematic
refinement of all modes. This allows MM-LMPC to escape high-cost local optima
and discover globally superior solutions. We establish recursive feasibility,
closed-loop stability, asymptotic convergence to the best mode, and a
logarithmic regret bound. Simulations on obstacle-avoidance tasks validate the
performance improvements of the proposed method.

</details>


### [16] [Modeling and Mixed-Integer Nonlinear MPC of Positive-Negative Pressure Pneumatic Systems](https://arxiv.org/abs/2510.00433)
*Yu Mei,Xinyu Zhou,Xiaobo Tan*

Main category: eess.SY

TL;DR: 提出了一种基于混合整数非线性模型预测控制(MI-NMPC)的软体机器人驱动器正负压调节框架，通过耦合物理基础的切换非线性模型和优化算法，实现精确的参考跟踪。


<details>
  <summary>Details</summary>
Motivation: 软体机器人驱动器中的正负压调节面临复杂非线性、振荡和方向相关的分段动力学等挑战，传统控制方法难以有效处理这些特性。

Method: 采用物理基础的切换非线性模型(充气/放气模式)与混合整数非线性模型预测控制器(MI-NMPC)相结合，使用组合积分近似方法处理离散模式决策，共同优化模式调度和PWM输入。

Result: 仿真验证表明，该方法在阶跃和正弦参考信号下均表现出色，在精度、控制努力和切换频率之间实现了有利的权衡，优于传统的PID和启发式模式选择的NMPC。

Conclusion: 所提出的MI-NMPC框架能够有效处理软体机器人驱动器正负压调节中的复杂动力学特性，为实现高性能控制提供了可行的解决方案。

Abstract: Positive-negative pressure regulation is critical to soft robotic actuators,
enabling large motion ranges and versatile actuation modes. However, it remains
challenging due to complex nonlinearities, oscillations, and
direction-dependent, piecewise dynamics introduced by affordable pneumatic
valves and the bidirectional architecture. We present a model-based control
framework that couples a physics-grounded switched nonlinear plant model
(inflation/deflation modes) with a mixed-integer nonlinear model predictive
controller (MI-NMPC). The controller co-optimizes mode scheduling and PWM
inputs to realize accurate reference tracking while enforcing input constraints
and penalizing energy consumption and excessive switching. To make discrete
mode decisions tractable, we employ a Combinatorial Integral Approximation that
relaxes binary mode variables to continuous surrogates within the
valve-scheduling layer. With parameters identified from the physical system,
simulations with step and sinusoidal references validate the proposed MI-NMPC,
showing a consistently favorable trade-off among accuracy, control effort, and
switching, and outperforming conventional PID and NMPC with heuristic mode
selection.

</details>


### [17] [Four-Port Probe Stations and SOLR Calibration Standard Design up to 125 GHz on 28 nm CMOS](https://arxiv.org/abs/2510.00435)
*Dipankar Shakya,Theodore S. Rappaport,Ethan Shieh,Michael E. Knox,Hamed Rahmani,Davood Shahrjerdi,Mingjun Ying,Kimberley Fan,Matt Lu,Andrej Rumiantsev,Vince Mallette,Gavin Fisher,Giancarlo De Chirico,Pratik Ghate,Shean McMahon*

Main category: eess.SY

TL;DR: 开发了两种创新的四端口探针台和高达125 GHz的四端口校准标准，用于未来多频段无线设备的精确射频表征


<details>
  <summary>Details</summary>
Motivation: 真正的四端口探测在毫米波及更高频率尚不存在，但未来多频段无线设备需要同时使用多个天线和射频链

Method: 设计基于UMC 28 nm CMOS工艺的片上SOLR校准标准，使用虚拟多线TRL校准提取S/O/L标准S参数，验证SOLR校准性能

Result: 成功开发了MPI和FFI的新型探针解决方案以及SOLR校准，为宽频率范围的精确射频表征提供了重要机会

Conclusion: 这些创新解决方案为未来无线设备的精确射频测量开辟了新的可能性

Abstract: This paper presents two innovative four-port probe stations developed by
FormFactor Incorporated (FFI) and MPI Corporation (MPI), and a four-port
calibration standard design up to 125 GHz for the probe stations. True
four-port probing at mmWave and beyond does not yet exist, but is anticipated
for future multi-band wireless devices using several antennas and RF chains.
The four-port probe stations are housed in the THz measurement facility at NYU
and allow simultaneous probing from East, West, North, and South orientations,
which presents challenges for calibration. An on-chip
Short-Open-Load-Reciprocal (SOLR) calibration (cal) standard is designed
leveraging UMC's 28 nm CMOS process. S/O/L standard S-parameters are extracted
using a virtual multiline Thru-Reflect-Line (mTRL) cal and used to validate
SOLR cal performance via simulations up to 125 GHz. The novel probing solutions
from MPI and FFI, along with the SOLR cal, open up considerable opportunities
for precise RF characterization across wide frequency ranges.

</details>


### [18] [An Interpolation-based Scheme for Rapid Frequency-Domain System Identification](https://arxiv.org/abs/2510.00525)
*Jared Jonas,Bassam Bamieh*

Main category: eess.SY

TL;DR: 提出基于重心插值和权重优化的频域系统辨识方案，特别适用于正弦响应测试成本高的系统，能减少测试次数


<details>
  <summary>Details</summary>
Motivation: 针对正弦响应测试时间长或成本高的系统，需要减少测试次数，同时保证辨识精度和系统稳定性

Method: 使用重心插值和权重优化，结合自适应频率点选择算法，利用瞬态数据优化权重，采用凸优化问题保证系统稳定性

Result: 在高阶、轻阻尼结构系统上的计算结果验证了该方案的有效性

Conclusion: 该方案能够有效减少正弦响应测试次数，同时保证辨识精度和系统稳定性，特别适用于测试成本高的系统

Abstract: We present a frequency-domain system identification scheme based on
barycentric interpolation and weight optimization. The scheme is related to the
Adaptive Antoulas-Anderson (AAA) algorithm for model reduction, but uses an
adaptive algorithm for selection of frequency points for interrogating the
system response, as would be required in identification versus model reduction.
The scheme is particularly suited for systems in which any one sinusoidal
response run is long or expensive, and thus there is an incentive to reduce the
total number of such runs. Two key features of our algorithm are the use of
transient data in sinusoidal runs to both optimize the barycentric weights, and
automated next-frequency selection on an adaptive grid. Both are done with
error criteria that are proxies for a system's $H^2$ and $H^\infty$ norms
respectively. Furthermore, the optimization problem we formulate is convex, and
can optionally guarantee stability of the identified system. Computational
results on a high-order, lightly damped structural system highlights the
efficacy of this scheme.

</details>


### [19] [Development and Field Validation of a Fully Customised Vehicle Scanning System on Two Full-Scale Bridges](https://arxiv.org/abs/2510.00560)
*A. Calderon Hurtado,J. Xu,R. Salleh,D. Dias-da-Costa,M. Makki Alamdari*

Main category: eess.SY

TL;DR: 本文介绍了首个专门为drive-by桥梁检测设计的电动检查车辆，该自主平台能够保持恒定低速并提供可定制操作参数，通过间接结构健康监测框架在真实桥梁上进行测试，展示了该方法的实际可行性。


<details>
  <summary>Details</summary>
Motivation: 确保桥梁结构完整性对基础设施安全和长期可持续性至关重要。间接结构健康监测通过drive-by桥梁检测提供了一种比传统方法更具成本效益和可扩展性的替代方案。

Method: 开发了专门设计的电动检查车辆，该自主平台能保持恒定低速和可定制操作参数，部署在ISHM框架中并在两个全尺寸桥梁上进行测试，使用两个无监督框架分析收集的数据以识别桥梁特性和结构状况的特征。

Result: 研究结果表明该方法具有实际可行性，ISHM有潜力成为高效桥梁监测的可行工具。

Conclusion: 这项研究展示了ISHM作为下一代结构健康监测系统开发工具的潜力，能够增强安全性、优化维护策略并支持关键基础设施的长期使用。

Abstract: Ensuring the structural integrity of bridges is essential for maintaining
infrastructure safety and promoting long-term sustainability. In this context,
Indirect Structural Health Monitoring (ISHM) through drive-by bridge inspection
emerges as a promising alternative to traditional inspection methods, offering
a cost-effective and scalable solution by using vehicle-mounted sensors to
assess the condition of bridges without requiring direct instrumentation. This
study introduces the first purpose-built electric inspection vehicle
specifically designed for drive-by bridge inspection. The autonomous platform
is capable of maintaining a constant low speed and offers customisable
operational parameters to maximise the accuracy and repeatability of indirect
sensing, capabilities not achieved in previous studies. The vehicle is deployed
within an ISHM framework and tested on two full-scale bridges to evaluate its
effectiveness in capturing structural dynamic responses. Two unsupervised
frameworks are then employed to analyse the collected data to identify features
indicative of bridge properties and structural condition. The promising
findings from this study demonstrate the practical feasibility of the approach.
The study also shows the potential of ISHM as a viable tool for efficient
bridge monitoring, contributing to the development of next-generation
structural health monitoring systems that can enhance safety, optimise
maintenance strategies, and support the longevity of critical infrastructure.

</details>


### [20] [Formation Control via Rotation Symmetry Constraints](https://arxiv.org/abs/2510.00676)
*Zamir Martinez,Daniel Zelazo*

Main category: eess.SY

TL;DR: 提出了一种基于旋转对称约束的多智能体分布式编队控制策略，使用势函数实现智能体间的旋转对称性，仅需(n-1)条边的最小连通性要求，并能实现编队的平移、旋转和缩放机动。


<details>
  <summary>Details</summary>
Motivation: 开发一种仅依赖旋转对称约束的分布式编队控制方法，降低通信和连接要求，同时增强编队的灵活性和机动能力。

Method: 设计了一个势函数来强制执行智能体间的旋转对称性，其梯度定义了控制律，驱动智能体达到期望的对称平面配置。通过增强设计来解决机动问题，使编队能够沿预定虚拟轨迹进行协调的平移、旋转和缩放。

Result: 数值仿真验证了所提方法的有效性和灵活性，证明仅需最小连通性(n-1条边)即可实现控制策略。

Conclusion: 该基于旋转对称约束的分布式编队控制策略具有最小连通性要求，能够实现灵活的编队机动，为多智能体系统提供了高效可靠的控制方案。

Abstract: We present a distributed formation control strategy for multi-agent systems
based only on rotation symmetry constraints. We propose a potential function
that enforces inter-agent \textbf{rotational} symmetries, with its gradient
defining the control law driving the agents toward a desired symmetric and
planar configuration. We show that only $(n-1)$ edges, the minimal connectivity
requirement, are sufficient to implement the control strategy, where $n$ is the
number of agents. We further augment the design to address the
\textbf{maneuvering problem}, enabling the formation to undergo coordinated
translations, rotations, and scalings along a predefined virtual trajectory.
Numerical simulations demonstrate the effectiveness and flexibility of the
proposed method.

</details>


### [21] [Uncertainty-Aware Flexibility of Buildings: From Quantification to Provision](https://arxiv.org/abs/2510.00858)
*Julie Rousseau,Hanmin Cai,Philipp Heer,Kristina Orehounig,Gabriela Hug*

Main category: eess.SY

TL;DR: 本文提出了一种考虑不确定性的建筑灵活性量化方法，使用机会约束公式和仿射反馈策略来提升灵活性评估的准确性，并在二级频率控制市场中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 建筑作为可再生能源整合的灵活性资源具有潜力，但预测的灵活性潜力受到不确定的天气预测和不准确的建筑热模型影响，需要更可靠的量化方法。

Method: 采用机会约束公式进行不确定性感知的灵活性量化，并引入仿射反馈策略来实时调整灵活性提供，考虑了日内交易和灵活性提供期后的回弹效应。

Result: 结果显示引入仿射反馈策略能增加灵活性和收益，考虑不确定性在灵活性量化中是必要的，特别是在没有日内交易的情况下。忽略不确定性的方法虽然看似有利可图，但会带来显著的热舒适度损失。

Conclusion: 建议采用保持舒适度的方法，将热不适真实反映在经济灵活性收益中，以获得更公平的比较，确保建筑灵活性资源的可持续利用。

Abstract: Buildings represent a promising flexibility source to support the integration
of renewable energy sources, as they may shift their heating energy consumption
over time without impacting users' comfort. However, a building's predicted
flexibility potential is based on uncertain ambient weather forecasts and a
typically inaccurate building thermal model. Hence, this paper presents an
uncertainty-aware flexibility quantifier using a chance-constrained
formulation. Because such a quantifier may be conservative, we additionally
model real-time feedback in the quantification, in the form of affine feedback
policies. Such adaptation can take the form of intra-day trades or rebound
around the flexibility provision period. To assess the flexibility
quantification formulations, we further assume that flexible buildings
participate in secondary frequency control markets. The results show some
increase in flexibility and revenues when introducing affine feedback policies.
Additionally, it is demonstrated that accounting for uncertainties in the
flexibility quantification is necessary, especially when intra-day trades are
not available. Even though an uncertainty-ignorant potential may seem
financially profitable in secondary frequency control markets, it comes at the
cost of significant thermal discomfort for inhabitants. Hence, we suggest a
comfort-preserving approach, aiming to truly reflect thermal discomfort on the
economic flexibility revenue, to obtain a fairer comparison.

</details>


### [22] [TubeDAgger: Reducing the Number of Expert Interventions with Stochastic Reach-Tubes](https://arxiv.org/abs/2510.00906)
*Julian Lemmel,Manuel Kranzl,Adam Lamine,Philipp Neubauer,Radu Grosu,Sophie A. Neubauer*

Main category: eess.SY

TL;DR: 提出使用随机可达管作为判断专家干预时机的新方法，减少交互模仿学习中的专家干预次数


<details>
  <summary>Details</summary>
Motivation: 现有的DAgger算法及其变体在判断何时让新手策略行动或交还控制给专家时存在差异，需要针对不同环境调整决策阈值

Method: 使用随机可达管（常用于动态系统验证）来估计专家干预的必要性，无需针对每个环境微调决策阈值

Result: 与使用怀疑分类模型的相关方法相比，有效减少了专家干预次数

Conclusion: 随机可达管方法在交互模仿学习中能有效减少专家干预，且无需环境特定的阈值调优

Abstract: Interactive Imitation Learning deals with training a novice policy from
expert demonstrations in an online fashion. The established DAgger algorithm
trains a robust novice policy by alternating between interacting with the
environment and retraining of the network. Many variants thereof exist, that
differ in the method of discerning whether to allow the novice to act or return
control to the expert. We propose the use of stochastic reachtubes - common in
verification of dynamical systems - as a novel method for estimating the
necessity of expert intervention. Our approach does not require fine-tuning of
decision thresholds per environment and effectively reduces the number of
expert interventions, especially when compared with related approaches that
make use of a doubt classification model.

</details>


### [23] [Accurate Small-Signal Modeling of Digitally Controlled Buck Converters with ADC-PWM Synchronization](https://arxiv.org/abs/2510.00943)
*Hang Zhou,Yuxin Yang,Branislav Hrezdak,John Edward Fletcher*

Main category: eess.SY

TL;DR: 提出了数字控制降压变换器在强制连续导通模式下的精确小信号模型，考虑了DPWM-ADC同步的影响，能够准确预测模拟和数字环路增益。


<details>
  <summary>Details</summary>
Motivation: 数字控制在功率电子变换器中日益普及，但DPWM与ADC同步的小信号影响尚未得到研究，需要建立精确模型来指导补偿器设计和稳定性评估。

Method: 使用采样数据框架，考虑非对称和对称载波调制，通过修正z变换推导数字环路增益的闭式表达式。

Result: 模型能够精确预测开关频率和采样频率以上的环路增益，模拟环路增益可直接从数字环路增益获得，无需复杂计算。

Conclusion: 提出的模型通过仿真和实验验证了有效性，为数字控制功率变换器的补偿器设计和稳定性分析提供了精确工具。

Abstract: Digital control has become increasingly widespread in modern power electronic
converters. When acquiring feedback signals such as the inductor current,
synchronizing the analog-to-digital converter (ADC) with the digital
pulse-width modulator (DPWM) is commonly employed to accurately track their
steady-state average. However, the small-signal implications of such
synchronization have not been investigated. This paper presents an exact
small-signal model for digitally controlled buck converters operating in forced
continuous-conduction mode (FCCM) under constant-frequency current-mode
control, explicitly accounting for DPWM-ADC synchronization. Using a
sampled-data framework, the proposed model captures all sideband effects
introduced by the sampling process, yielding precise predictions of both analog
and digital loop gains, even at frequencies beyond the switching and sampling
frequencies. Both asymmetrical and symmetrical carrier modulations are
considered. Furthermore, the digital loop gain is derived in closed form using
the modified z-transform, enabling low-complexity compensator design and
stability assessment. Within this framework, the analog loop gain can be
directly obtained from the digital loop gain, thereby eliminating the need for
computationally intensive infinite series evaluations. The validity of the
proposed model is confirmed through both simulation and experimental results.

</details>


### [24] [Structuring Automotive Data for Systems Engineering: A Taxonomy-Based Approach](https://arxiv.org/abs/2510.00963)
*Carl Philipp Hohl,Philipp Reis,Tobias Schürmann,Stefan Otten,Eric Sax*

Main category: eess.SY

TL;DR: 本文通过结构化文献回顾开发了汽车数据归纳分类法，解决汽车数据分散收集导致的数据孤岛、格式不一致和互操作性有限等问题，提高数据可访问性和利用率。


<details>
  <summary>Details</summary>
Motivation: 汽车数据在仿真、测试台架和实际驾驶中以分散方式收集，导致数据孤岛、存储结构不一致和互操作性有限，造成数据收集冗余、集成效率低下和应用次优。

Method: 进行结构化文献回顾并开发汽车数据归纳分类法，根据数据来源和应用对数据进行分类。

Result: 分析显示对实际驾驶和机器学习应用的关注日益增长，同时揭示了需求工程数据可用性方面的关键差距。

Conclusion: 通过提供结构化汽车数据的系统框架，本研究有助于更高效的数据管理和改进汽车行业的决策制定。

Abstract: Vehicle data is essential for advancing data-driven development throughout
the automotive lifecycle, including requirements engineering, design,
verification, and validation, and post-deployment optimization. Developers
currently collect data in a decentralized and fragmented manner across
simulations, test benches, and real-world driving, resulting in data silos,
inconsistent formats, and limited interoperability. This leads to redundant
efforts, inefficient integration, and suboptimal use of data. This
fragmentation results in data silos, inconsistent storage structures, and
limited interoperability, leading to redundant data collection, inefficient
integration, and suboptimal application. To address these challenges, this
article presents a structured literature review and develops an inductive
taxonomy for automotive data. This taxonomy categorizes data according to its
sources and applications, improving data accessibility and utilization. The
analysis reveals a growing emphasis on real-world driving and machine learning
applications while highlighting a critical gap in data availability for
requirements engineering. By providing a systematic framework for structuring
automotive data, this research contributes to more efficient data management
and improved decision-making in the automotive industry.

</details>


### [25] [Real-time Operation of Electric Autonomous Mobility-on-Demand System Considering Power System Regulation](https://arxiv.org/abs/2510.00984)
*Lyuzhu Pan,Hongcai Zhang*

Main category: eess.SY

TL;DR: 提出一个实时协调框架来解决电动自动驾驶按需出行系统在充电站集中充电时对电网的潜在负面影响，通过马尔可夫决策过程建模车队时空特性，结合模型预测控制实现系统协调。


<details>
  <summary>Details</summary>
Motivation: 电动自动驾驶按需出行系统的集中充电可能恶化电网运行，进而影响出行系统的最优运行，需要预防这种潜在风险。

Method: 基于马尔可夫决策过程建模车队时空特性，包括服务行程、重新定位和充电；建立充电站充电可及性模型；提出分段线性近似动态规划算法结合模型预测控制。

Result: 在曼哈顿和14节点配电网络中的数值实验验证了算法的有效性，并强调了系统协调的必要性。

Conclusion: 所提出的协调框架和算法能够有效解决EAMoD系统集中充电对电网的影响，确保两个系统的协调运行。

Abstract: Electric autonomous mobility-on-demand (EAMoD) systems are emerging all over
the world. However, their potential swarm charging in depots may deteriorate
operation of the power system, further in turn affecting EAMoD system's optimal
operation. To prevent this latent risk, we develop a real-time coordination
framework for the EAMoD system and the power system. First, the
temporal-spatial characteristics of EAMoD fleets are fully described based on a
Markov decision process model, including serving trips, repositioning, and
charging. Second, charger accessibility of EAMoD depot charging is well modeled
as real-world configuration, wherein fast and slow charge piles are both
included. Third, the power system regulation model provides real-time charging
regulation constraints for EAMoD systems to prevent potential overload and
undervoltage. To address the poor solution quality attributed to the complex
decision space of the EAMoD system, this paper proposes a piecewise
linear-based approximate dynamic programming algorithm combined with model
predictive control. Numerical experiments in the Manhattan and a 14-node power
distribution network validate the effectiveness of the proposed algorithm and
underscore the necessity of system coordination.

</details>


### [26] [Optimal Pricing of Electric Vehicle Charging on Coupled Power-Transportation Network based on Generalized Sensitivity Analysis](https://arxiv.org/abs/2510.00992)
*Lyuzhu Pan,Hongcai Zhang*

Main category: eess.SY

TL;DR: 提出一种基于广义灵敏度分析的电动汽车充电最优定价方法，通过梯度信息替代传统KKT条件，解决耦合电力-交通网络中的非凸定价问题。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车普及，充电服务提供商需要在考虑耦合电力-交通网络运行条件下优化充电价格以提高利润，但传统方法涉及用户均衡模型导致非凸且计算困难。

Method: 采用灵敏度分析捕捉充电需求对价格的最佳响应梯度，提出定制梯度下降算法，数学证明有效性且时间复杂度为多项式。

Result: 在不同规模网络上的数值实验验证了算法的计算效率，表明其在大规模耦合网络运行性能评估中的潜力。

Conclusion: 所提出的广义灵敏度分析方法能有效解决大规模耦合电力-交通网络中的电动汽车充电最优定价问题，具有计算效率和实用性优势。

Abstract: In the last decade, charging service providers are emerging along with the
prevalence of electric vehicles. These providers need to strategically optimize
their charging prices to improve the profits considering operation conditions
of the coupled power-transportation network. However, the optimal pricing
problem generally involves the user equilibrium model, which leads to a
mathematical program with equilibrium constraints. As a result, the pricing
problem is non-convex and computationally intractable especially for
large-scale network. To address this challenge, we propose a generalized
sensitivity analysis approach for optimal pricing of electric vehicle charging
on coupled power-transportation network. Specifically, we adopt a sensitivity
analysis to capture the best response of charging demand to charging price in
the gradient form. Consequently, charging service providers can make pricing
decisions based on the gradient information instead of the conventional KKT
conditions of the user equilibrium model. We then propose a tailored gradient
descent algorithm to solve the whole pricing problem. The mathematical proof of
validity is given and the time complexity of the proposed algorithm is
theoretically polynomial. Numerical experiments on different scales of networks
verify the computational efficiency of the proposed algorithm, indicating its
potential in evaluating the impact of the optimal pricing on the operational
performance of large-scale coupled power-transportation network.

</details>


### [27] [A Model-Based Extended State Observer for Discrete-Time Linear Multivariable Systems](https://arxiv.org/abs/2510.01007)
*Jinfeng Chen,Zhiqiang Gao,Qin Lin*

Main category: eess.SY

TL;DR: 提出了基于模型的扩展状态观测器及其变体，用于离散时间线性多变量系统，建立了存在性条件，并分析了误差特性。


<details>
  <summary>Details</summary>
Motivation: 针对多变量系统中多扰动估计问题，扩展传统ESO方法以处理非对角扰动增益矩阵的情况。

Method: 将多扰动定义为扩展状态向量，提出MB-ESO及其变体，利用与未知输入观测器的联系建立存在性条件，分析误差传递函数。

Result: 当观测器特征值置于原点且子系统解耦时，变体MB-ESO与UIO产生相同的扰动估计；扰动估计误差随观测器特征值和时间单调减小。

Conclusion: MB-ESO及其变体为多变量系统扰动估计提供了有效方法，建立了明确的存在性条件和误差特性分析。

Abstract: A model-based extended state observer (MB-ESO) and its variant are proposed
for discrete-time linear multivariable systems, where multiple disturbances are
defined as an extended state vector in the same manner as in the original
formulation of ESO. The variant MB-ESO extends the MB-ESO to address cases
where the disturbance gain matrix is non-diagonal. Leveraging the connection
between the variant MB-ESO and the well-known unknown input observer (UIO), the
condition for the existence of a MB-ESO and its variant in multivariable
systems is established, for the first time, i.e., no invariant zeros exist
between the disturbances and the plant outputs. It is shown that, with the
observer eigenvalues all placed at the origin and the subsystems decoupled, the
variant MB-ESO produces the identical disturbance estimation as that of UIO.
Moreover, the error characteristics of MB-ESO and its variant are analyzed and
the transfer functions associated with the disturbance estimation errors are
derived. It is demonstrated both mathematically and in simulations that the
disturbance estimation error of MB-ESO decreases monotonically with respect to
both the observer eigenvalues and time.

</details>


### [28] [Gain-Scheduled Passive Fault-Tolerant Control Design for Dual-System UAV Transition Flight](https://arxiv.org/abs/2510.01044)
*Junfeng Cai,Marco Lovera*

Main category: eess.SY

TL;DR: 提出一种用于双系统无人机过渡飞行的增益调度被动容错控制方法，将执行器故障引起的模型不确定性视为输入不确定性，显著减少设计点数量，简化控制综合过程。


<details>
  <summary>Details</summary>
Motivation: 双系统无人机作为安全关键系统，需要在发生故障后保持安全飞行，因此需要有效的容错控制方法。

Method: 采用增益调度结构化H无穷被动容错控制方法，将执行器故障引起的控制效能损失建模为模型输入不确定性，使用乘法不确定性描述。

Result: 在非线性六自由度模拟器上验证，相比LQR和结构化H无穷控制系统，提出的方法具有更优越的容错性能。

Conclusion: 该方法能显著简化双系统无人机过渡飞行容错控制系统设计过程，提高设计效率，并展示出优异的容错性能。

Abstract: Dual-system UAVs with vertical take-off and landing capabilities have become
increasingly popular in recent years. As a safety-critical system, it is
important that a dual-system UAV can maintain safe flight after faults/failures
occur. This paper proposes a gain-scheduled passive fault-tolerant control
(PFTC) method for the transition flight of dual-system UAVs. In this novel FTC
design method, the model uncertainties arising from the loss of control
effectiveness caused by actuator faults/failures, for the first time, are
treated as model input uncertainty, allowing us to use multiplicative
uncertainty descriptions to represent it. The advantages of the proposed method
consist in significantly reducing the number of design points, thereby
simplifying the control synthesis process and improving the efficiency of
designing the FTC system for dual-system UAV transition flight compared with
the existing FTC design methods. As a general method, it can be applied to the
design of FTC systems with multiple uncertain parameters and multiple channels.
The developed passive FTC system is validated on a nonlinear
six-degree-of-freedom simulator. The simulation results demonstrate that the
gain-scheduled structured H infinity (GS SHIF) PFTC system provides superior
fault tolerance performance compared with the LQR and structured H infinity
control systems, thereby showcasing the effectiveness and the advantages of the
proposed GS SHIF PFTC approach.

</details>


### [29] [Grid Frequency Stability Support Potential of Data Center: A Quantitative Assessment of Flexibility](https://arxiv.org/abs/2510.01050)
*Pengyu Ren,Wei Sun,Yifan Wang,Gareth Harrison*

Main category: eess.SY

TL;DR: 提出基于决策树的约束学习方法，将非线性频率约束嵌入混合整数线性规划，优化数据中心参与频率响应的发电调度。


<details>
  <summary>Details</summary>
Motivation: 数据中心快速增长改变了电力系统动态，在增加电力需求的同时提供了快速可控的灵活性，需要增强需求侧频率响应建模以确保可靠运行。

Method: 基于决策树约束学习的数据驱动线性化框架，将非线性最低频率约束嵌入混合整数线性规划问题。

Result: 增加灵活数据中心负载比例持续改善系统成本效率并支持可再生能源并网，但存在边际收益递减现象。

Conclusion: 随着数据中心在系统负荷中占比增大，其主动参与频率响应对维持经济安全的系统运行将愈发不可或缺。

Abstract: The rapid expansion of data center infrastructure is reshaping power system
dynamics by significantly increasing electricity demand while also offering
potential for fast and controllable flexibility. To ensure reliable operation
under such conditions, the frequency secured unit commitment problem must be
solved with enhanced modeling of demand side frequency response. In this work,
we propose a data-driven linearization framework based on decision tree based
constraint learning to embed nonlinear nadir frequency constraints into
mixed-integer linear programming. This approach enables tractable optimization
of generation schedules and fast frequency response from data centers. Through
case studies on both a benchmark system and a 2030 future scenario with higher
DC penetration, we demonstrate that increasing the proportion of flexible DC
load consistently improves system cost efficiency and supports renewable
integration. However, this benefit exhibits diminishing marginal returns,
motivating the introduction of the Marginal Flexibility Value metric to
quantify the economic value of additional flexibility. The results highlight
that as DCs become a larger share of system load, their active participation in
frequency response will be increasingly indispensable for maintaining both
economic and secure system operations.

</details>


### [30] [Predictive Control Barrier Functions for Discrete-Time Linear Systems with Unmodeled Delays](https://arxiv.org/abs/2510.01059)
*Juan Augusto Paredes Salazar,James Usevitch,Ankit Goel*

Main category: eess.SY

TL;DR: 提出预测控制屏障函数(PCBF)框架，用于处理具有未知相对度的离散时间系统的状态约束问题，解决输入延迟或未建模输入动态带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有离散时间CBF方法在相对度大于1时需要构建辅助屏障函数，这使实现复杂化且可能导致保守的安全集。

Method: 通过扩展预测时域构建相对度为1的关联系统的CBF，使PCBF的超水平集与安全集重合。

Result: 在具有输入延迟的离散时间双积分器和具有位置约束的双旋翼系统上验证了方法的有效性。

Conclusion: PCBF框架简化了约束执行，无需辅助函数，为处理未知相对度系统提供了有效解决方案。

Abstract: This paper introduces a predictive control barrier function (PCBF) framework
for enforcing state constraints in discrete-time systems with unknown relative
degree, which can be caused by input delays or unmodeled input dynamics.
Existing discrete-time CBF formulations typically require the construction of
auxiliary barrier functions when the relative degree is greater than one, which
complicates implementation and may yield conservative safe sets. The proposed
PCBF framework addresses this challenge by extending the prediction horizon to
construct a CBF for an associated system with relative degree one. As a result,
the superlevel set of the PCBF coincides with the safe set, simplifying
constraint enforcement and eliminating the need for auxiliary functions. The
effectiveness of the proposed method is demonstrated on a discrete-time double
integrator with input delay and a bicopter system with position constraints.

</details>


### [31] [Safety-Critical Control via Recurrent Tracking Functions](https://arxiv.org/abs/2510.01147)
*Jixian Liu,Enrique Mallada*

Main category: eess.SY

TL;DR: 该论文提出了一种用于高阶非线性系统的安全关键控制器合成方法，通过引入循环跟踪函数(RTFs)来放宽传统Lyapunov跟踪函数的单调衰减要求，构建循环控制屏障函数(RCBFs)来保证系统安全。


<details>
  <summary>Details</summary>
Motivation: 针对高阶非线性系统中构造有效控制屏障函数(CBFs)计算困难的问题，以及传统Lyapunov跟踪函数需要单调衰减且仅适用于全驱动系统的限制。

Method: 利用分层控制设计，在降阶模型中设计CBFs，同时调节全阶模型动态。引入循环跟踪函数(RTFs)替代单调衰减要求，通过有限时间循环条件允许跟踪误差的瞬时偏差。将降阶模型的CBFs与RTFs结合构建循环CBFs(RCBFs)。

Result: 建立了理论安全保证，并通过数值实验验证了RTFs的有效性和全阶模型的安全性。

Conclusion: 所提出的方法能够有效解决高阶非线性系统的安全控制问题，放宽了传统方法的严格限制，同时保证了系统的安全性。

Abstract: This paper addresses the challenge of synthesizing safety-critical
controllers for high-order nonlinear systems, where constructing valid Control
Barrier Functions (CBFs) remains computationally intractable. Leveraging
layered control, we design CBFs in reduced-order models (RoMs) while regulating
full-order models' (FoMs) dynamics at the same time. Traditional Lyapunov
tracking functions are required to decrease monotonically, but systematic
synthesis methods for such functions exist only for fully-actuated systems. To
overcome this limitation, we introduce Recurrent Tracking Functions (RTFs),
which replace the monotonic decay requirement with a weaker finite-time
recurrence condition. This relaxation permits transient deviations of tracking
errors while ensuring safety. By augmenting CBFs for RoMs with RTFs, we
construct recurrent CBFs (RCBFs) whose zero-superlevel set is control
$\tau$-recurrent, and guarantee safety for all initial states in such a set
when RTFs are satisfied. We establish theoretical safety guarantees and
validate the approach through numerical experiments, demonstrating RTFs'
effectiveness and the safety of FoMs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [32] [RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes](https://arxiv.org/abs/2510.00154)
*Xinyi Liu,Mohammadreza Fani Sani,Zewei Zhou,Julius Wirbel,Bahram Zarrin,Roberto Galeazzi*

Main category: cs.RO

TL;DR: RoboPilot是一个双思维闭环机器人操作框架，通过快速和慢速思维切换来平衡效率和准确性，在动态环境中实现复杂任务的适应性推理和执行。


<details>
  <summary>Details</summary>
Motivation: 当前自主机器人系统大多采用开环范式，缺乏推理和反馈机制，导致对环境变化的鲁棒性差和错误累积严重。

Method: 利用原始动作进行结构化任务规划和灵活动作生成，引入反馈机制支持动态变化和错误恢复，通过思维链推理增强高层任务规划和低层动作生成。

Result: 在RoboPilot-Bench基准测试中，任务成功率比最先进基线方法高出25.9%，工业机器人的实际部署进一步证明了其在真实环境中的鲁棒性。

Conclusion: RoboPilot框架通过双思维闭环设计和反馈机制，显著提升了机器人在复杂任务执行中的鲁棒性和适应性。

Abstract: Despite rapid progress in autonomous robotics, executing complex or
long-horizon tasks remains a fundamental challenge. Most current approaches
follow an open-loop paradigm with limited reasoning and no feedback, resulting
in poor robustness to environmental changes and severe error accumulation. We
present RoboPilot, a dual-thinking closed-loop framework for robotic
manipulation that supports adaptive reasoning for complex tasks in real-world
dynamic environments. RoboPilot leverages primitive actions for structured task
planning and flexible action generation, while introducing feedback to enable
replanning from dynamic changes and execution errors. Chain-of-Thought
reasoning further enhances high-level task planning and guides low-level action
generation. The system dynamically switches between fast and slow thinking to
balance efficiency and accuracy. To systematically evaluate the robustness of
RoboPilot in diverse robot manipulation scenarios, we introduce
RoboPilot-Bench, a benchmark spanning 21 tasks across 10 categories, including
infeasible-task recognition and failure recovery. Experiments show that
RoboPilot outperforms state-of-the-art baselines by 25.9\% in task success
rate, and the real-world deployment on an industrial robot further demonstrates
its robustness in real-world settings.

</details>


### [33] [A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream](https://arxiv.org/abs/2510.00182)
*Jorge Mendez-Mendez*

Main category: cs.RO

TL;DR: 本研究评估了使用Gemini 2.5 Flash大语言模型替代任务与运动规划(TAMP)关键组件的16种算法，在4,950个问题上的实验表明，基于LLM的规划器成功率较低、规划时间较长，且几何细节会增加任务规划错误。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在复杂机器人问题中的规划能力，特别是如何将LLM的语义知识与TAMP的形式推理相结合，以了解这些规划能力在机器人任务空间中的覆盖范围。

Method: 开发了16种使用Gemini 2.5 Flash替代TAMP关键组件的算法，在三个领域进行了4,950个问题的零样本实验，比较了不同LLM变体的性能。

Result: 基于Gemini的规划器比工程化对应物成功率更低、规划时间更长；提供几何细节比纯PDDL描述产生更多任务规划错误；在大多数情况下，非推理LLM变体（更快）优于推理变体（更慢）。

Conclusion: LLM在TAMP系统中的集成需要谨慎设计，非推理LLM变体由于TAMP系统可以指导其纠正错误而表现更好，表明LLM与TAMP的协同工作比完全依赖LLM推理更有效。

Abstract: Using large language models (LLMs) to solve complex robotics problems
requires understanding their planning capabilities. Yet while we know that LLMs
can plan on some problems, the extent to which these planning capabilities
cover the space of robotics tasks is unclear. One promising direction is to
integrate the semantic knowledge of LLMs with the formal reasoning of task and
motion planning (TAMP). However, the myriad of choices for how to integrate
LLMs within TAMP complicates the design of such systems. We develop 16
algorithms that use Gemini 2.5 Flash to substitute key TAMP components. Our
zero-shot experiments across 4,950 problems and three domains reveal that the
Gemini-based planners exhibit lower success rates and higher planning times
than their engineered counterparts. We show that providing geometric details
increases the number of task-planning errors compared to pure PDDL
descriptions, and that (faster) non-reasoning LLM variants outperform (slower)
reasoning variants in most cases, since the TAMP system can direct the LLM to
correct its mistakes.

</details>


### [34] [A Novel Robust Control Method Combining DNN-Based NMPC Approximation and PI Control: Application to Exoskeleton Squat Movements](https://arxiv.org/abs/2510.00188)
*Alireza Aliyari,Gholamreza Vossoughi*

Main category: cs.RO

TL;DR: 提出混合NMPC-DNN-PI控制器，将神经网络近似的非线性模型预测控制与PI控制器结合，应用于外骨骼机器人的下蹲运动控制，显著提高了在未见条件下的鲁棒性并大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统NMPC计算负载过重，而纯神经网络近似的NMPC-DNN在面对意外干扰或与训练数据不同的工况时缺乏鲁棒性，导致跟踪误差增大。

Method: 首次将NMPC-DNN输出与PI控制器结合形成混合控制器，应用于具有复杂动力学模型的外骨骼机器人三主动关节（踝、膝、髋）下蹲运动控制，使用530多万训练样本训练DNN。

Result: 在DNN未见条件下，混合控制器的跟踪误差显著低于纯NMPC-DNN；使用外骨骼后人体关节扭矩大幅降低（踝30.9%、膝41.8%、髋29.7%）；计算成本比NMPC降低99.93%。

Conclusion: 混合NMPC-DNN-PI控制器在保持NMPC精度的同时，显著提高了鲁棒性并大幅降低了计算成本，为复杂机器人系统的实时控制提供了有效解决方案。

Abstract: Nonlinear Model Predictive Control (NMPC) is a precise controller, but its
heavy computational load often prevents application in robotic systems. Some
studies have attempted to approximate NMPC using deep neural networks
(NMPC-DNN). However, in the presence of unexpected disturbances or when
operating conditions differ from training data, this approach lacks robustness,
leading to large tracking errors. To address this issue, for the first time,
the NMPC-DNN output is combined with a PI controller (Hybrid NMPC-DNN-PI). The
proposed controller is validated by applying it to an exoskeleton robot during
squat movement, which has a complex dynamic model and has received limited
attention regarding robust nonlinear control design. A human-robot dynamic
model with three active joints (ankle, knee, hip) is developed, and more than
5.3 million training samples are used to train the DNN. The results show that,
under unseen conditions for the DNN, the tracking error in Hybrid NMPC-DNN-PI
is significantly lower compared to NMPC-DNN. Moreover, human joint torques are
greatly reduced with the use of the exoskeleton, with RMS values for the
studied case reduced by 30.9%, 41.8%, and 29.7% at the ankle, knee, and hip,
respectively. In addition, the computational cost of Hybrid NMPC-DNN-PI is
99.93% lower than that of NMPC.

</details>


### [35] [TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks](https://arxiv.org/abs/2510.00225)
*Yue Meng,Fei Chen,Chuchu Fan*

Main category: cs.RO

TL;DR: TGPO提出了一种分层强化学习方法来解决信号时序逻辑（STL）任务，通过将STL分解为定时子目标和不变约束，使用高层时间分配和低层时间条件策略，显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习算法难以处理STL的非马尔可夫特性和稀疏奖励问题，现有方法只能处理有限的STL片段或使用稀疏终端奖励。

Method: TGPO将STL分解为定时子目标和不变约束，采用分层框架：高层组件提出具体时间分配，低层时间条件策略使用密集的阶段奖励学习实现序列子目标。在推理时采样多种时间分配，并使用Metropolis-Hastings采样引导高层时间搜索。

Result: 在五个环境中（从低维导航到操作、无人机和四足机器人运动）的实验表明，TGPO在广泛的STL任务中显著优于最先进的基线方法，平均任务成功率比最佳基线提高了31.6%。

Conclusion: TGPO为处理复杂、长时程的STL任务提供了一种有效的分层强化学习方法，特别在高维和长时程情况下表现优异。

Abstract: Learning control policies for complex, long-horizon tasks is a central
challenge in robotics and autonomous systems. Signal Temporal Logic (STL)
offers a powerful and expressive language for specifying such tasks, but its
non-Markovian nature and inherent sparse reward make it difficult to be solved
via standard Reinforcement Learning (RL) algorithms. Prior RL approaches focus
only on limited STL fragments or use STL robustness scores as sparse terminal
rewards. In this paper, we propose TGPO, Temporal Grounded Policy Optimization,
to solve general STL tasks. TGPO decomposes STL into timed subgoals and
invariant constraints and provides a hierarchical framework to tackle the
problem. The high-level component of TGPO proposes concrete time allocations
for these subgoals, and the low-level time-conditioned policy learns to achieve
the sequenced subgoals using a dense, stage-wise reward signal. During
inference, we sample various time allocations and select the most promising
assignment for the policy network to rollout the solution trajectory. To foster
efficient policy learning for complex STL with multiple subgoals, we leverage
the learned critic to guide the high-level temporal search via
Metropolis-Hastings sampling, focusing exploration on temporally feasible
solutions. We conduct experiments on five environments, ranging from
low-dimensional navigation to manipulation, drone, and quadrupedal locomotion.
Under a wide range of STL tasks, TGPO significantly outperforms
state-of-the-art baselines (especially for high-dimensional and long-horizon
cases), with an average of 31.6% improvement in task success rate compared to
the best baseline. The code will be available at
https://github.com/mengyuest/TGPO

</details>


### [36] [BC-MPPI: A Probabilistic Constraint Layer for Safe Model-Predictive Path-Integral Control](https://arxiv.org/abs/2510.00272)
*Odichimnma Ezeji,Michael Ziegltrum,Giulio Turrisi,Tommaso Belvedere,Valerio Modugno*

Main category: cs.RO

TL;DR: BC-MPPI是一种在MPPI控制中加入概率约束的安全层，通过概率代理评估轨迹可行性，自动降低可能违反约束的轨迹权重，无需手动调整惩罚成本。


<details>
  <summary>Details</summary>
Motivation: MPPI控制虽然快速且无需梯度，但缺乏硬性约束保证。需要一种轻量级的安全层来确保约束满足，同时保持计算效率。

Method: 为每个状态和输入约束附加概率代理，在每次重规划时评估候选轨迹的可行性概率，该概率用于缩放轨迹权重，推动采样分布朝向安全子集。

Result: 在四旋翼无人机模拟中，BC-MPPI在保持安全裕度的同时满足规定的违反概率要求，适用于100-1500个采样点范围。

Conclusion: BC-MPPI提供了一种可集成到认证自主系统验证流程中的轻量级安全解决方案，代理模型可作为独立、版本控制的组件。

Abstract: Model Predictive Path Integral (MPPI) control has recently emerged as a fast,
gradient-free alternative to model-predictive control in highly non-linear
robotic tasks, yet it offers no hard guarantees on constraint satisfaction. We
introduce Bayesian-Constraints MPPI (BC-MPPI), a lightweight safety layer that
attaches a probabilistic surrogate to every state and input constraint. At each
re-planning step the surrogate returns the probability that a candidate
trajectory is feasible; this joint probability scales the weight given to a
candidate, automatically down-weighting rollouts likely to collide or exceed
limits and pushing the sampling distribution toward the safe subset; no
hand-tuned penalty costs or explicit sample rejection required. We train the
surrogate from 1000 offline simulations and deploy the controller on a
quadrotor in MuJoCo with both static and moving obstacles. Across K in
[100,1500] rollouts BC-MPPI preserves safety margins while satisfying the
prescribed probability of violation. Because the surrogate is a stand-alone,
version-controlled artefact and the runtime safety score is a single scalar,
the approach integrates naturally with verification-and-validation pipelines
for certifiable autonomous systems.

</details>


### [37] [Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning](https://arxiv.org/abs/2510.00329)
*Sarmad Mehrdad,Maxime Sabbah,Vincent Bonnet,Ludovic Righetti*

Main category: cs.RO

TL;DR: 该论文应用最小观测逆强化学习（MO-IRL）建模和预测具有时变成本权重的人类手臂伸展运动，相比传统IRL方法显著减少了所需演示数据和收敛时间。


<details>
  <summary>Details</summary>
Motivation: 研究人类运动控制中动态成本结构的建模，传统IRL方法需要大量演示数据且收敛慢，需要更高效的方法来揭示生物运动的时变成本机制。

Method: 使用平面双连杆生物力学模型，将轨迹分割为多个阶段，学习阶段特定的七种候选成本函数组合，通过MO-IRL迭代优化成本权重。

Result: 训练10次试验后，六段和八段权重划分的平均关节角度RMSE分别为6.4度和5.6度，优于静态权重的10.4度。跨被试验证显示约8度RMSE，具有良好的泛化能力。

Conclusion: MO-IRL能有效揭示人类运动控制中动态、被试独立的成本结构，学习到的权重在运动起始和终止阶段强调关节加速度最小化，符合生物运动的平滑性原则，具有应用于人形机器人的潜力。

Abstract: This paper investigates the application of Minimal Observation Inverse
Reinforcement Learning (MO-IRL) to model and predict human arm-reaching
movements with time-varying cost weights. Using a planar two-link biomechanical
model and high-resolution motion-capture data from subjects performing a
pointing task, we segment each trajectory into multiple phases and learn
phase-specific combinations of seven candidate cost functions. MO-IRL
iteratively refines cost weights by scaling observed and generated trajectories
in the maximum entropy IRL formulation, greatly reducing the number of required
demonstrations and convergence time compared to classical IRL approaches.
Training on ten trials per posture yields average joint-angle Root Mean Squared
Errors (RMSE) of 6.4 deg and 5.6 deg for six- and eight-segment weight
divisions, respectively, versus 10.4 deg using a single static weight.
Cross-validation on remaining trials and, for the first time, inter-subject
validation on an unseen subject's 20 trials, demonstrates comparable predictive
accuracy, around 8 deg RMSE, indicating robust generalization. Learned weights
emphasize joint acceleration minimization during movement onset and
termination, aligning with smoothness principles observed in biological motion.
These results suggest that MO-IRL can efficiently uncover dynamic,
subject-independent cost structures underlying human motor control, with
potential applications for humanoid robots.

</details>


### [38] [DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts](https://arxiv.org/abs/2510.00358)
*Linjin He,Xinda Qi,Dong Chen,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 提出DiSA-IQL方法，通过惩罚不可靠的状态-动作对来缓解离线强化学习中的分布偏移问题，在软体蛇形机器人控制任务中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 软体蛇形机器人控制面临高度非线性动力学挑战，现有方法依赖简化假设限制了性能。在线强化学习成本高且危险，离线RL存在分布偏移问题影响泛化能力。

Method: 提出DiSA-IQL（分布偏移感知隐式Q学习），在IQL基础上通过鲁棒性调制惩罚不可靠的状态-动作对来缓解分布偏移。

Result: 在目标到达任务的分布内和分布外评估中，DiSA-IQL始终优于BC、CQL和原始IQL基线，获得更高的成功率、更平滑的轨迹和更好的鲁棒性。

Conclusion: DiSA-IQL有效解决了离线RL在软体机器人控制中的分布偏移问题，代码已开源以支持可复现性和进一步研究。

Abstract: Soft snake robots offer remarkable flexibility and adaptability in complex
environments, yet their control remains challenging due to highly nonlinear
dynamics. Existing model-based and bio-inspired controllers rely on simplified
assumptions that limit performance. Deep reinforcement learning (DRL) has
recently emerged as a promising alternative, but online training is often
impractical because of costly and potentially damaging real-world interactions.
Offline RL provides a safer option by leveraging pre-collected datasets, but it
suffers from distribution shift, which degrades generalization to unseen
scenarios. To overcome this challenge, we propose DiSA-IQL
(Distribution-Shift-Aware Implicit Q-Learning), an extension of IQL that
incorporates robustness modulation by penalizing unreliable state-action pairs
to mitigate distribution shift. We evaluate DiSA-IQL on goal-reaching tasks
across two settings: in-distribution and out-of-distribution evaluation.
Simulation results show that DiSA-IQL consistently outperforms baseline models,
including Behavior Cloning (BC), Conservative Q-Learning (CQL), and vanilla
IQL, achieving higher success rates, smoother trajectories, and improved
robustness. The codes are open-sourced to support reproducibility and to
facilitate further research in offline RL for soft robot control.

</details>


### [39] [Physics-Informed Neural Controlled Differential Equations for Scalable Long Horizon Multi-Agent Motion Forecasting](https://arxiv.org/abs/2510.00401)
*Shounak Sural,Charles Kekeh,Wenliang Liu,Federico Pecora,Mouhacine Benosman*

Main category: cs.RO

TL;DR: 提出PINCoDE模型，基于神经控制微分方程进行多机器人长时程运动预测，结合物理约束和深度学习，支持从10到100个机器人的扩展预测。


<details>
  <summary>Details</summary>
Motivation: 多自主机器人长时程运动预测面临非线性交互、预测误差累积和连续时间动态演化等挑战，需要开发高效的目标条件轨迹预测模型。

Method: 使用神经控制微分方程（CDEs）构建PINCoDE模型，在连续时间中结合物理约束，学习多机器人系统的微分方程参数，支持目标条件预测。

Result: 模型可扩展到100个机器人而无需额外参数，1分钟预测的平均ADE低于0.5米，4分钟预测的位姿误差比解析模型减少2.7倍。

Conclusion: PINCoDE通过结合物理约束和深度学习，有效解决了多机器人长时程运动预测问题，具有良好的可扩展性和预测精度。

Abstract: Long-horizon motion forecasting for multiple autonomous robots is challenging
due to non-linear agent interactions, compounding prediction errors, and
continuous-time evolution of dynamics. Learned dynamics of such a system can be
useful in various applications such as travel time prediction,
prediction-guided planning and generative simulation. In this work, we aim to
develop an efficient trajectory forecasting model conditioned on multi-agent
goals. Motivated by the recent success of physics-guided deep learning for
partially known dynamical systems, we develop a model based on neural
Controlled Differential Equations (CDEs) for long-horizon motion forecasting.
Unlike discrete-time methods such as RNNs and transformers, neural CDEs operate
in continuous time, allowing us to combine physics-informed constraints and
biases to jointly model multi-robot dynamics. Our approach, named PINCoDE
(Physics-Informed Neural Controlled Differential Equations), learns
differential equation parameters that can be used to predict the trajectories
of a multi-agent system starting from an initial condition. PINCoDE is
conditioned on future goals and enforces physics constraints for robot motion
over extended periods of time. We adopt a strategy that scales our model from
10 robots to 100 robots without the need for additional model parameters, while
producing predictions with an average ADE below 0.5 m for a 1-minute horizon.
Furthermore, progressive training with curriculum learning for our PINCoDE
model results in a 2.7X reduction of forecasted pose error over 4 minute
horizons compared to analytical models.

</details>


### [40] [VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators](https://arxiv.org/abs/2510.00406)
*Hengtao Li,Pengxiang Ding,Runze Suo,Yihao Wang,Zirui Ge,Dongyuan Zang,Kexian Yu,Mingyang Sun,Hongyin Zhang,Donglin Wang,Weihua Su*

Main category: cs.RO

TL;DR: VLA-RFT是一个基于世界模型的强化微调框架，通过数据驱动的可控模拟器来增强视觉-语言-动作模型的泛化性和鲁棒性，仅需不到400步微调即可超越监督基线。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型主要依赖模仿学习，容易产生累积误差且在分布偏移下鲁棒性差。强化学习可以缓解这些问题，但通常需要昂贵的真实世界交互或面临模拟到现实的差距。

Method: 使用从真实交互数据训练的数据驱动世界模型作为可控模拟器，该模拟器根据动作预测未来视觉观察，允许策略展开并使用从目标达成参考中获得的密集轨迹级奖励。

Result: 仅需不到400步微调，VLA-RFT就超越了强大的监督基线，比基于模拟器的强化学习更高效，在扰动条件下表现出强大的鲁棒性，保持稳定的任务执行。

Conclusion: 基于世界模型的强化微调是一种实用的后训练范式，可以有效增强视觉-语言-动作模型的泛化性和鲁棒性。

Abstract: Vision-Language-Action (VLA) models enable embodied decision-making but rely
heavily on imitation learning, leading to compounding errors and poor
robustness under distribution shift. Reinforcement learning (RL) can mitigate
these issues yet typically demands costly real-world interactions or suffers
from sim-to-real gaps. We introduce VLA-RFT, a reinforcement fine-tuning
framework that leverages a data-driven world model as a controllable simulator.
Trained from real interaction data, the simulator predicts future visual
observations conditioned on actions, allowing policy rollouts with dense,
trajectory-level rewards derived from goal-achieving references. This design
delivers an efficient and action-aligned learning signal, drastically lowering
sample requirements. With fewer than 400 fine-tuning steps, VLA-RFT surpasses
strong supervised baselines and achieves greater efficiency than
simulator-based RL. Moreover, it exhibits strong robustness under perturbed
conditions, sustaining stable task execution. Our results establish
world-model-based RFT as a practical post-training paradigm to enhance the
generalization and robustness of VLA models. For more details, please refer to
https://vla-rft.github.io/.

</details>


### [41] [Seeing through Uncertainty: Robust Task-Oriented Optimization in Visual Navigation](https://arxiv.org/abs/2510.00441)
*Yiyuan Pan,Yunzhe Xu,Zhe Liu,Hesheng Wang*

Main category: cs.RO

TL;DR: NeuRO是一个集成学习优化框架，将感知网络与下游任务级鲁棒优化紧密耦合，通过部分输入凸神经网络和保形校准将视觉预测转化为凸不确定性集合，解决了数据稀缺下的视觉导航泛化问题。


<details>
  <summary>Details</summary>
Motivation: 视觉导航是具身AI的基础问题，但实际部署需要长时程规划能力来处理多目标任务。主要瓶颈是数据稀缺：从有限数据学习的策略容易过拟合且无法泛化到分布外场景。现有神经网络代理通常增加架构复杂性，这在少样本场景中适得其反。

Method: NeuRO框架：(i)使用部分输入凸神经网络(PICNNs)和保形校准将噪声视觉预测转化为凸不确定性集合，直接参数化优化约束；(ii)将部分可观测性下的规划重新表述为鲁棒优化问题，实现跨环境转移的不确定性感知策略。

Result: 在无序和顺序多目标导航任务上的大量实验表明，NeuRO建立了最先进的性能，特别是在未见环境的泛化方面表现突出。

Conclusion: 这项工作为开发鲁棒、可泛化的自主代理提供了重要进展，NeuRO框架在数据稀缺条件下实现了优异的泛化能力。

Abstract: Visual navigation is a fundamental problem in embodied AI, yet practical
deployments demand long-horizon planning capabilities to address
multi-objective tasks. A major bottleneck is data scarcity: policies learned
from limited data often overfit and fail to generalize OOD. Existing neural
network-based agents typically increase architectural complexity that
paradoxically become counterproductive in the small-sample regime. This paper
introduce NeuRO, a integrated learning-to-optimize framework that tightly
couples perception networks with downstream task-level robust optimization.
Specifically, NeuRO addresses core difficulties in this integration: (i) it
transforms noisy visual predictions under data scarcity into convex uncertainty
sets using Partially Input Convex Neural Networks (PICNNs) with conformal
calibration, which directly parameterize the optimization constraints; and (ii)
it reformulates planning under partial observability as a robust optimization
problem, enabling uncertainty-aware policies that transfer across environments.
Extensive experiments on both unordered and sequential multi-object navigation
tasks demonstrate that NeuRO establishes SoTA performance, particularly in
generalization to unseen environments. Our work thus presents a significant
advancement for developing robust, generalizable autonomous agents.

</details>


### [42] [Integrating Offline Pre-Training with Online Fine-Tuning: A Reinforcement Learning Approach for Robot Social Navigation](https://arxiv.org/abs/2510.00466)
*Run Su,Hao Fu,Shuai Zhou,Yingao Fu*

Main category: cs.RO

TL;DR: 提出了一种用于机器人社交导航的离线到在线微调强化学习算法，通过将Return-to-Go预测集成到因果Transformer架构中，解决了离线训练与在线部署之间的分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在机器人社交导航中存在探索不足和分布偏移问题，需要一种能够有效结合离线训练知识和在线环境交互的方法。

Method: 设计了时空融合模型来实时估计RTG值，结合时间行人运动模式和空间人群动态编码，并构建了混合离线-在线经验采样机制来稳定策略更新。

Result: 在模拟社交导航环境中的广泛实验表明，该方法相比最先进的基线方法实现了更高的成功率和更低的碰撞率。

Conclusion: 该算法显著增强了导航策略的鲁棒性和适应性，为现实世界应用中更可靠和自适应的机器人导航系统铺平了道路。

Abstract: Offline reinforcement learning (RL) has emerged as a promising framework for
addressing robot social navigation challenges. However, inherent uncertainties
in pedestrian behavior and limited environmental interaction during training
often lead to suboptimal exploration and distributional shifts between offline
training and online deployment. To overcome these limitations, this paper
proposes a novel offline-to-online fine-tuning RL algorithm for robot social
navigation by integrating Return-to-Go (RTG) prediction into a causal
Transformer architecture. Our algorithm features a spatiotem-poral fusion model
designed to precisely estimate RTG values in real-time by jointly encoding
temporal pedestrian motion patterns and spatial crowd dynamics. This RTG
prediction framework mitigates distribution shift by aligning offline policy
training with online environmental interactions. Furthermore, a hybrid
offline-online experience sampling mechanism is built to stabilize policy
updates during fine-tuning, ensuring balanced integration of pre-trained
knowledge and real-time adaptation. Extensive experiments in simulated social
navigation environments demonstrate that our method achieves a higher success
rate and lower collision rate compared to state-of-the-art baselines. These
results underscore the efficacy of our algorithm in enhancing navigation policy
robustness and adaptability. This work paves the way for more reliable and
adaptive robotic navigation systems in real-world applications.

</details>


### [43] [From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment](https://arxiv.org/abs/2510.00491)
*Han Zhou,Jinjin Cao,Liyuan Ma,Xueji Fang,Guo-jun Qi*

Main category: cs.RO

TL;DR: Traj2Action是一个通过3D轨迹作为中间表示来弥合人类与机器人形态差距的框架，将人类操作知识转移到机器人动作中，在真实机器人实验中性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 解决机器人多样化操作技能学习依赖昂贵遥操作演示的问题，利用可扩展的人类视频数据，但需要克服人类与机器人形态差异带来的知识转移障碍。

Method: 使用操作端点的3D轨迹作为统一中间表示，先学习生成粗略轨迹作为高层运动规划，然后在协同去噪框架中合成精确的机器人特定动作。

Result: 在Franka机器人上的真实世界实验显示，相比基线在短时和长时任务上性能分别提升27%和22.25%，且随着人类数据规模增加，机器人策略学习效果显著提升。

Conclusion: Traj2Action通过轨迹中间表示有效弥合了人类与机器人的形态差距，实现了从人类视频到机器人操作技能的高效知识转移。

Abstract: Learning diverse manipulation skills for real-world robots is severely
bottlenecked by the reliance on costly and hard-to-scale teleoperated
demonstrations. While human videos offer a scalable alternative, effectively
transferring manipulation knowledge is fundamentally hindered by the
significant morphological gap between human and robotic embodiments. To address
this challenge and facilitate skill transfer from human to robot, we introduce
Traj2Action,a novel framework that bridges this embodiment gap by using the 3D
trajectory of the operational endpoint as a unified intermediate
representation, and then transfers the manipulation knowledge embedded in this
trajectory to the robot's actions. Our policy first learns to generate a coarse
trajectory, which forms an high-level motion plan by leveraging both human and
robot data. This plan then conditions the synthesis of precise, robot-specific
actions (e.g., orientation and gripper state) within a co-denoising framework.
Extensive real-world experiments on a Franka robot demonstrate that Traj2Action
boosts the performance by up to 27% and 22.25% over $\pi_0$ baseline on short-
and long-horizon real-world tasks, and achieves significant gains as human data
scales in robot policy learning. Our project website, featuring code and video
demonstrations, is available at
https://anonymous.4open.science/w/Traj2Action-4A45/.

</details>


### [44] [Two stage GNSS outlier detection for factor graph optimization based GNSS-RTK/INS/odometer fusion](https://arxiv.org/abs/2510.00524)
*Baoshan Song,Penggao Yan,Xiao Xia,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 提出了一种两阶段异常值检测方法，用于提升GNSS-RTK/INS/里程计紧耦合系统的定位性能，通过多普勒测量和预积分约束来检测和剔除伪距异常值。


<details>
  <summary>Details</summary>
Motivation: 复杂环境中GNSS定位面临非视距传播、多径效应和信号遮挡等挑战，这些因素会在伪距测量中引入大异常值，严重影响RTK定位和紧耦合集成导航系统的性能。

Method: 采用两阶段异常值检测：第一阶段使用多普勒测量进行GNSS-only异常检测；第二阶段利用预积分IMU和里程计约束生成预测双差伪距测量，进行精细化异常识别和剔除。基于因子图优化的紧耦合GNSS-RTK/INS/里程计集成框架。

Result: 实验结果表明，该两阶段检测框架显著降低了伪距异常值的影响，在深度城市峡谷测试中，将融合系统的RMSE从0.52米降低到0.30米，提升了42.3%的定位精度和一致性。

Conclusion: 提出的两阶段异常值检测方法有效提升了复杂环境下GNSS定位的鲁棒性，通过结合多普勒测量和惯性/里程计约束，能够有效应对大伪距误差和卫星测量质量下降问题。

Abstract: Reliable GNSS positioning in complex environments remains a critical
challenge due to non-line-of-sight (NLOS) propagation, multipath effects, and
frequent signal blockages. These effects can easily introduce large outliers
into the raw pseudo-range measurements, which significantly degrade the
performance of global navigation satellite system (GNSS) real-time kinematic
(RTK) positioning and limit the effectiveness of tightly coupled GNSS-based
integrated navigation system. To address this issue, we propose a two-stage
outlier detection method and apply the method in a tightly coupled GNSS-RTK,
inertial navigation system (INS), and odometer integration based on factor
graph optimization (FGO). In the first stage, Doppler measurements are employed
to detect pseudo-range outliers in a GNSS-only manner, since Doppler is less
sensitive to multipath and NLOS effects compared with pseudo-range, making it a
more stable reference for detecting sudden inconsistencies. In the second
stage, pre-integrated inertial measurement units (IMU) and odometer constraints
are used to generate predicted double-difference pseudo-range measurements,
which enable a more refined identification and rejection of remaining outliers.
By combining these two complementary stages, the system achieves improved
robustness against both gross pseudo-range errors and degraded satellite
measuring quality. The experimental results demonstrate that the two-stage
detection framework significantly reduces the impact of pseudo-range outliers,
and leads to improved positioning accuracy and consistency compared with
representative baseline approaches. In the deep urban canyon test, the outlier
mitigation method has limits the RMSE of GNSS-RTK/INS/odometer fusion from 0.52
m to 0.30 m, with 42.3% improvement.

</details>


### [45] [GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks](https://arxiv.org/abs/2510.00573)
*Yen-Ling Tai,Yi-Ru Yang,Kuan-Ting Yu,Yu-Wei Chao,Yi-Ting Chen*

Main category: cs.RO

TL;DR: 提出了GRITS框架，一种基于引导扩散策略的机器人舀取食物方法，通过预测溢出概率来指导动作生成，显著减少食物溢出。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习算法在处理多样化和动态变化的食物状态时表现不佳，容易导致食物溢出和可靠性降低。

Method: 设计了溢出预测器来估计给定观察和动作序列下的溢出概率，在模拟数据集上训练，并在推理时作为可微引导信号指导扩散采样过程。

Result: 在真实机器人平台上验证，在10个未见过的食物类别上达到82%的任务成功率和4%的溢出率，相比无引导基线减少40%以上的溢出。

Conclusion: GRITS框架通过引导扩散策略有效解决了食物舀取中的溢出问题，提高了机器人操作的可靠性。

Abstract: Robotic food scooping is a critical manipulation skill for food preparation
and service robots. However, existing robot learning algorithms, especially
learn-from-demonstration methods, still struggle to handle diverse and dynamic
food states, which often results in spillage and reduced reliability. In this
work, we introduce GRITS: A Spillage-Aware Guided Diffusion Policy for Robot
Food Scooping Tasks. This framework leverages guided diffusion policy to
minimize food spillage during scooping and to ensure reliable transfer of food
items from the initial to the target location. Specifically, we design a
spillage predictor that estimates the probability of spillage given current
observation and action rollout. The predictor is trained on a simulated dataset
with food spillage scenarios, constructed from four primitive shapes (spheres,
cubes, cones, and cylinders) with varied physical properties such as mass,
friction, and particle size. At inference time, the predictor serves as a
differentiable guidance signal, steering the diffusion sampling process toward
safer trajectories while preserving task success. We validate GRITS on a
real-world robotic food scooping platform. GRITS is trained on six food
categories and evaluated on ten unseen categories with different shapes and
quantities. GRITS achieves an 82% task success rate and a 4% spillage rate,
reducing spillage by over 40% compared to baselines without guidance, thereby
demonstrating its effectiveness.

</details>


### [46] [Hybrid Training for Vision-Language-Action Models](https://arxiv.org/abs/2510.00600)
*Pietro Mazzaglia,Cansu Sancaktar,Markus Peschl,Daniel Dijkman*

Main category: cs.RO

TL;DR: 提出Hybrid Training (HyT)框架，让视觉-语言-动作模型在训练时学习思维链，但在推理时可选择跳过思维生成，从而在保持性能的同时减少推理延迟。


<details>
  <summary>Details</summary>
Motivation: 思维链(CoT)方法虽然能提升性能，但会显著增加推理时间，这在需要实时动作的机器人任务中影响可用性。研究是否必须生成长思维链才能获得性能提升。

Method: HyT框架：在训练时让模型学习思维链，但在推理时可选择直接生成动作而跳过思维生成。支持条件化预测多种输出，提供推理时的灵活性。

Result: 在模拟基准测试和真实世界实验中验证了方法的有效性。

Conclusion: HyT框架使VLAs能够从思维链学习中获益，同时允许在推理时跳过思维生成，实现性能与效率的平衡，并支持灵活的推理模式。

Abstract: Using Large Language Models to produce intermediate thoughts, a.k.a.
Chain-of-thought (CoT), before providing an answer has been a successful recipe
for solving complex language tasks. In robotics, similar embodied CoT
strategies, generating thoughts before actions, have also been shown to lead to
improved performance when using Vision-Language-Action models (VLAs). As these
techniques increase the length of the model's generated outputs to include the
thoughts, the inference time is negatively affected. Delaying an agent's
actions in real-world executions, as in robotic manipulation settings, strongly
affects the usability of a method, as tasks require long sequences of actions.
However, is the generation of long chains-of-thought a strong prerequisite for
achieving performance improvements? In this work, we explore the idea of Hybrid
Training (HyT), a framework that enables VLAs to learn from thoughts and
benefit from the associated performance gains, while enabling the possibility
to leave out CoT generation during inference. Furthermore, by learning to
conditionally predict a diverse set of outputs, HyT supports flexibility at
inference time, enabling the model to either predict actions directly, generate
thoughts or follow instructions. We evaluate the proposed method in a series of
simulated benchmarks and real-world experiments.

</details>


### [47] [What Did I Learn? Operational Competence Assessment for AI-Based Trajectory Planners](https://arxiv.org/abs/2510.00619)
*Michiel Braat,Maren Buermann,Marijke van Weperen,Jan-Pieter Paardekooper*

Main category: cs.RO

TL;DR: 提出了一种基于知识图谱的方法来识别自动驾驶车辆未充分训练的场景，通过分析训练数据中的子场景覆盖情况来评估模型在特定驾驶场景中的能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶功能越来越依赖机器学习，但模型性能取决于训练数据与任务的匹配程度。为了确保可靠运行，需要了解数据集中包含的内容以评估训练模型的运行风险。

Method: 将驾驶数据建模为知识图谱，表示驾驶场景中的实体及其关系。通过查询特定的子场景配置来检查其在数据集中的出现情况，并根据训练集中子场景配置的覆盖率和复杂性来估计车辆在驾驶场景中的能力。

Result: 将该方法应用于NuPlan数据集，通过知识图谱建模并分析特定驾驶场景的覆盖情况。结果表明，更复杂的场景需要更大的覆盖范围才能获得高能力。

Conclusion: 这种方法有助于监控基于数据集训练的机器学习模型的能力，这对于在自动驾驶中部署可信AI至关重要，同时通过以人类可理解的水平描述数据集来提高可解释性。

Abstract: Automated driving functions increasingly rely on machine learning for tasks
like perception and trajectory planning, requiring large, relevant datasets.
The performance of these algorithms depends on how closely the training data
matches the task. To ensure reliable functioning, it is crucial to know what is
included in the dataset to assess the trained model's operational risk. We aim
to enhance the safe use of machine learning in automated driving by developing
a method to recognize situations that an automated vehicle has not been
sufficiently trained on. This method also improves explainability by describing
the dataset at a human-understandable level. We propose modeling driving data
as knowledge graphs, representing driving scenes with entities and their
relationships. These graphs are queried for specific sub-scene configurations
to check their occurrence in the dataset. We estimate a vehicle's competence in
a driving scene by considering the coverage and complexity of sub-scene
configurations in the training set. Higher complexity scenes require greater
coverage for high competence. We apply this method to the NuPlan dataset,
modeling it with knowledge graphs and analyzing the coverage of specific
driving scenes. This approach helps monitor the competence of machine learning
models trained on the dataset, which is essential for trustworthy AI to be
deployed in automated driving.

</details>


### [48] [Trajectory Based Observer Design: A Framework for Lightweight Sensor Fusion](https://arxiv.org/abs/2510.00630)
*Federico Oliva,Tom Shaked,Daniele Carnevale,Amir Degani*

Main category: cs.RO

TL;DR: 提出了一种基于优化的观测器设计方法TBOD，通过预记录的测量轨迹来调整观测器参数，适用于非线性系统和多传感器设置。


<details>
  <summary>Details</summary>
Motivation: 高效的观测器设计和精确的传感器融合在状态估计中至关重要，需要一种轻量级、通用的方法来简化观测器设计过程。

Method: 基于参数化观测器动力学，利用预记录的测量轨迹通过数值优化来调整观测器参数，结合经典观测器理论和移动水平估计器方法。

Result: 在陆地漫游车定位问题中测试，结合IMU和超宽带天线测距传感器，与扩展卡尔曼滤波器相比，位置估计精度相当，但方向估计显著改善。

Conclusion: TBOD方法提供了一种轻量级、通用的传感器融合方法，能够高效处理通用传感器并以模块化方式工作，最重要的是其简单的调谐过程。

Abstract: Efficient observer design and accurate sensor fusion are key in state
estimation. This work proposes an optimization-based methodology, termed
Trajectory Based Optimization Design (TBOD), allowing the user to easily design
observers for general nonlinear systems and multi-sensor setups. Starting from
parametrized observer dynamics, the proposed method considers a finite set of
pre-recorded measurement trajectories from the nominal plant and exploits them
to tune the observer parameters through numerical optimization. This research
hinges on the classic observer's theory and Moving Horizon Estimators
methodology. Optimization is exploited to ease the observer's design, providing
the user with a lightweight, general-purpose sensor fusion methodology. TBOD's
main characteristics are the capability to handle general sensors efficiently
and in a modular way and, most importantly, its straightforward tuning
procedure. The TBOD's performance is tested on a terrestrial rover localization
problem, combining IMU and ranging sensors provided by Ultra Wide Band
antennas, and validated through a motion-capture system. Comparison with an
Extended Kalman Filter is also provided, matching its position estimation
accuracy and significantly improving in the orientation.

</details>


### [49] [Enabling High-Frequency Cross-Modality Visual Positioning Service for Accurate Drone Landing](https://arxiv.org/abs/2510.00646)
*Haoyang Wang,Xinyu Luo,Wenhua Ding,Jingao Xu,Xuecheng Chen,Ruiyang Duan,Jialong Chen,Haitao Zhang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: EV-Pose是一个基于事件相机的无人机视觉定位系统，通过时空特征引导的位姿估计和运动感知的分层融合优化，实现了高精度、低延迟的6自由度位姿跟踪，显著提升了无人机着陆精度。


<details>
  <summary>Details</summary>
Motivation: 传统GPS在城市场景中因信号衰减和多径传播不可靠，现有视觉定位服务在无人机上的部署存在精度和效率限制。

Method: 设计了基于事件相机的无人机视觉定位系统，包括时空特征引导的位姿估计模块（提取时序距离场进行3D点云匹配）和运动感知的分层融合优化方案（在事件过滤早期和位姿优化后期利用无人机运动信息）。

Result: 实现了1.34度的旋转精度和6.9mm的平移精度，跟踪延迟为10.08ms，比基线方法提升超过50%。

Conclusion: EV-Pose系统能够实现精确的无人机着陆，为无人机物流提供了可靠的位姿跟踪解决方案。

Abstract: After years of growth, drone-based delivery is transforming logistics. At its
core, real-time 6-DoF drone pose tracking enables precise flight control and
accurate drone landing. With the widespread availability of urban 3D maps, the
Visual Positioning Service (VPS), a mobile pose estimation system, has been
adapted to enhance drone pose tracking during the landing phase, as
conventional systems like GPS are unreliable in urban environments due to
signal attenuation and multi-path propagation. However, deploying the current
VPS on drones faces limitations in both estimation accuracy and efficiency. In
this work, we redesign drone-oriented VPS with the event camera and introduce
EV-Pose to enable accurate, high-frequency 6-DoF pose tracking for accurate
drone landing. EV-Pose introduces a spatio-temporal feature-instructed pose
estimation module that extracts a temporal distance field to enable 3D point
map matching for pose estimation; and a motion-aware hierarchical fusion and
optimization scheme to enhance the above estimation in accuracy and efficiency,
by utilizing drone motion in the \textit{early stage} of event filtering and
the \textit{later stage} of pose optimization. Evaluation shows that EV-Pose
achieves a rotation accuracy of 1.34$\degree$ and a translation accuracy of
6.9$mm$ with a tracking latency of 10.08$ms$, outperforming baselines by
$>$50\%, \tmcrevise{thus enabling accurate drone landings.} Demo:
https://ev-pose.github.io/

</details>


### [50] [Shared Object Manipulation with a Team of Collaborative Quadrupeds](https://arxiv.org/abs/2510.00682)
*Shengzhi Wang,Niels Dehio,Xuanqi Zeng,Xian Yang,Lingwei Zhang,Yun-Hui Liu,K. W. Samuel Au*

Main category: cs.RO

TL;DR: 将经典混合运动-力控制器扩展到腿式机械臂系统团队，实现刚性物体的协作移动操作


<details>
  <summary>Details</summary>
Motivation: 多机器人团队处理笨重物体具有优势，但现有研究多关注多机械臂系统，受限于工作空间约束

Method: 扩展经典混合运动-力控制器到腿式机械臂系统团队，采用力闭合抓取方式

Result: 机器人能够灵活协调运动，实现高效稳定的物体协作操作和运输，通过仿真和真实实验验证

Conclusion: 该方法成功实现了腿式机器人团队的协作移动操作能力

Abstract: Utilizing teams of multiple robots is advantageous for handling bulky
objects. Many related works focus on multi-manipulator systems, which are
limited by workspace constraints. In this paper, we extend a classical hybrid
motion-force controller to a team of legged manipulator systems, enabling
collaborative loco-manipulation of rigid objects with a force-closed grasp. Our
novel approach allows the robots to flexibly coordinate their movements,
achieving efficient and stable object co-manipulation and transport, validated
through extensive simulations and real-world experiments.

</details>


### [51] [HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy](https://arxiv.org/abs/2510.00695)
*Myungkyu Koo,Daewon Choi,Taeyoung Kim,Kyungmin Lee,Changyeon Kim,Youngyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: HAMLET是一个可扩展框架，通过引入时刻令牌和轻量级记忆模块，将视觉-语言-动作模型（VLA）改造为能够利用历史上下文的历史感知策略，在需要历史上下文的长时程任务上表现显著提升。


<details>
  <summary>Details</summary>
Motivation: 机器人操作任务本质上是历史依赖的，但现有的VLA模型仅依赖当前观测而忽略历史上下文。为了解决这个问题，需要开发能够有效利用历史信息的框架。

Method: 提出时刻令牌来紧凑编码每个时间步的感知信息，通过时间对比学习初始化表示；使用轻量级记忆模块整合过去时间步的时刻令牌为记忆特征，用于动作预测。

Result: 在GR00T N1.5上，HAMLET在历史依赖的真实世界任务中达到76.4%的平均成功率，比基线提升47.2%；在RoboCasa Kitchen上从64.1%提升到66.4%，在LIBERO上从95.6%提升到97.7%。

Conclusion: HAMLET成功将最先进的VLA模型转变为历史感知策略，特别是在需要历史上下文的长时程任务上表现出显著改进，证明了其有效性。

Abstract: Inherently, robotic manipulation tasks are history-dependent: leveraging past
context could be beneficial. However, most existing Vision-Language-Action
models (VLAs) have been designed without considering this aspect, i.e., they
rely solely on the current observation, ignoring preceding context. In this
paper, we propose HAMLET, a scalable framework to adapt VLAs to attend to the
historical context during action prediction. Specifically, we introduce moment
tokens that compactly encode perceptual information at each timestep. Their
representations are initialized with time-contrastive learning, allowing them
to better capture temporally distinctive aspects. Next, we employ a lightweight
memory module that integrates the moment tokens across past timesteps into
memory features, which are then leveraged for action prediction. Through
empirical evaluation, we show that HAMLET successfully transforms a
state-of-the-art VLA into a history-aware policy, especially demonstrating
significant improvements on long-horizon tasks that require historical context.
In particular, on top of GR00T N1.5, HAMLET achieves an average success rate of
76.4% on history-dependent real-world tasks, surpassing the baseline
performance by 47.2%. Furthermore, HAMLET pushes prior art performance from
64.1% to 66.4% on RoboCasa Kitchen (100-demo setup) and from 95.6% to 97.7% on
LIBERO, highlighting its effectiveness even under generic robot-manipulation
benchmarks.

</details>


### [52] [MultiPhysio-HRC: Multimodal Physiological Signals Dataset for industrial Human-Robot Collaboration](https://arxiv.org/abs/2510.00703)
*Andrea Bussolan,Stefano Baraldo,Oliver Avram,Pablo Urcola,Luis Montesano,Luca Maria Gambardella,Anna Valente*

Main category: cs.RO

TL;DR: 提出了MultiPhysio-HRC多模态数据集，包含生理、音频和面部数据，用于研究人机协作中的心理状态感知。


<details>
  <summary>Details</summary>
Motivation: 工业5.0中人机协作需要感知人类的心理生理状态（如压力和认知负荷），以实现自适应和人类感知的机器人系统。

Method: 收集了EEG、ECG、EDA、RESP、EMG、语音记录和面部动作单元等多模态数据，结合受控认知任务、沉浸式虚拟现实体验和工业拆卸活动，并通过验证的心理自评问卷获得丰富的地面真实标注。

Result: 评估了压力和认知负荷分类的基线模型，展示了数据集在情感计算和人类感知机器人研究中的潜力。

Conclusion: MultiPhysio-HRC数据集公开可用，支持以人为中心的自动化、工作场所福祉和智能机器人系统的研究。

Abstract: Human-robot collaboration (HRC) is a key focus of Industry 5.0, aiming to
enhance worker productivity while ensuring well-being. The ability to perceive
human psycho-physical states, such as stress and cognitive load, is crucial for
adaptive and human-aware robotics. This paper introduces MultiPhysio-HRC, a
multimodal dataset containing physiological, audio, and facial data collected
during real-world HRC scenarios. The dataset includes electroencephalography
(EEG), electrocardiography (ECG), electrodermal activity (EDA), respiration
(RESP), electromyography (EMG), voice recordings, and facial action units. The
dataset integrates controlled cognitive tasks, immersive virtual reality
experiences, and industrial disassembly activities performed manually and with
robotic assistance, to capture a holistic view of the participants' mental
states. Rich ground truth annotations were obtained using validated
psychological self-assessment questionnaires. Baseline models were evaluated
for stress and cognitive load classification, demonstrating the dataset's
potential for affective computing and human-aware robotics research.
MultiPhysio-HRC is publicly available to support research in human-centered
automation, workplace well-being, and intelligent robotic systems.

</details>


### [53] [CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation](https://arxiv.org/abs/2510.00726)
*Giovanni Minelli,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 提出Cross-State Transition Attention Transformer，通过状态转移注意力机制和时序掩码训练，提升机器人操作策略对执行变化的适应性。


<details>
  <summary>Details</summary>
Motivation: 监督学习中的机器人操作策略在遇到训练未覆盖的执行变化时表现不佳，现有注意力机制未能充分利用演示中的时序结构模式。

Method: 使用状态转移注意力机制调制标准注意力权重，结合时序掩码训练随机移除近期视觉信息，强制模型从历史上下文进行时序推理。

Result: 在仿真评估中，STA方法在所有任务上均优于标准交叉注意力和TCN、LSTM等时序建模方法，在精度关键任务上比交叉注意力提升2倍以上。

Conclusion: 通过显式建模状态转移模式并结合时序掩码训练，能有效提升机器人操作策略对执行变化的鲁棒性。

Abstract: Learning robotic manipulation policies through supervised learning from
demonstrations remains challenging when policies encounter execution variations
not explicitly covered during training. While incorporating historical context
through attention mechanisms can improve robustness, standard approaches
process all past states in a sequence without explicitly modeling the temporal
structure that demonstrations may include, such as failure and recovery
patterns. We propose a Cross-State Transition Attention Transformer that
employs a novel State Transition Attention (STA) mechanism to modulate standard
attention weights based on learned state evolution patterns, enabling policies
to better adapt their behavior based on execution history. Our approach
combines this structured attention with temporal masking during training, where
visual information is randomly removed from recent timesteps to encourage
temporal reasoning from historical context. Evaluation in simulation shows that
STA consistently outperforms standard cross-attention and temporal modeling
approaches like TCN and LSTM networks across all tasks, achieving more than 2x
improvement over cross-attention on precision-critical tasks.

</details>


### [54] [Product-oriented Product-Process-Resource Asset Network and its Representation in AutomationML for Asset Administration Shell](https://arxiv.org/abs/2510.00933)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 提出了一种基于PPR建模范式的PoPAN模型，将产品生命周期末端阶段的影响纳入工程阶段，支持产品在整个生命周期中的维修、再制造和升级循环，并以电动汽车电池拆解为例进行验证。


<details>
  <summary>Details</summary>
Motivation: 当前工业标准主要关注生产阶段而非完整产品生命周期，且侧重于生产过程而非产品本身。需要将产品生命周期末端阶段（如报废处理）的影响纳入工程阶段考虑。

Method: 基于产品-过程-资源(PPR)建模范式，提出PoPAN模型作为产品的数字影子，封装在资产管理壳中，支持维修、再制造和升级循环，并使用AutomationML数据格式进行序列化。

Result: 开发了PoPAN模型框架，能够伴随产品整个生命周期，支持在信息物理生产系统中进行维修、再制造和升级操作，并通过电动汽车电池拆解用例验证了模型的有效性。

Conclusion: PoPAN模型成功将产品生命周期末端考虑纳入工程阶段，为支持循环经济提供了可行的建模方法，特别是在电动汽车电池再制造等应用中具有重要价值。

Abstract: Current products, especially in the automotive sector, pose complex technical
systems having a multi-disciplinary mechatronic nature. Industrial standards
supporting system engineering and production typically (i) address the
production phase only, but do not cover the complete product life cycle, and
(ii) focus on production processes and resources rather than the products
themselves. The presented approach is motivated by incorporating impacts of
end-of-life phase of the product life cycle into the engineering phase. This
paper proposes a modelling approach coming up from the Product-Process-Resource
(PPR) modeling paradigm. It combines requirements on (i) respecting the product
structure as a basis for the model, and (ii) it incorporates repairing,
remanufacturing, or upcycling within cyber-physical production systems. The
proposed model called PoPAN should accompany the product during the entire life
cycle as a digital shadow encapsulated within the Asset Administration Shell of
a product. To facilitate the adoption of the proposed paradigm, the paper also
proposes serialization of the model in the AutomationML data format. The model
is demonstrated on a use-case for disassembling electric vehicle batteries to
support their remanufacturing for stationary battery applications.

</details>


### [55] [Tele-rehabilitation with online skill transfer and adaptation in $\mathbb{R}^3 \times \mathit{S}^3$](https://arxiv.org/abs/2510.00770)
*Tianle Ni,Xiao Chen,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了一种用于机器人辅助远程康复的远程教学框架，通过双边遥操作连接治疗师和患者端的机器人，实现康复训练的远程演示和执行。


<details>
  <summary>Details</summary>
Motivation: 为机器人辅助远程康复领域开发一个能够实现治疗师远程指导、患者被动训练，并支持个性化调整的远程教学系统。

Method: 使用双边遥操作连接治疗师和患者端的机器人，采用6自由度动态运动基元在ℝ³×S³空间中联合编码平移和旋转运动，确保准确的轨迹再现。

Result: 在7自由度机械臂上的实验证明了该方法的可行性，系统能够实现治疗师引导和患者被动训练之间的平滑过渡，并支持运动的自适应调整。

Conclusion: 该框架展示了在个性化远程监督康复方面的潜力，为远程康复治疗提供了有效的技术解决方案。

Abstract: This paper proposes a tele-teaching framework for the domain of
robot-assisted tele-rehabilitation. The system connects two robotic
manipulators on therapist and patient side via bilateral teleoperation,
enabling a therapist to remotely demonstrate rehabilitation exercises that are
executed by the patient-side robot. A 6-DoF Dynamical Movement Primitives
formulation is employed to jointly encode translational and rotational motions
in $\mathbb{R}^3 \times \mathit{S}^3$ space, ensuring accurate trajectory
reproduction. The framework supports smooth transitions between therapist-led
guidance and patient passive training, while allowing adaptive adjustment of
motion. Experiments with 7-DoF manipulators demonstrate the feasibility of the
approach, highlighting its potential for personalized and remotely supervised
rehabilitation.

</details>


### [56] [Non-submodular Visual Attention for Robot Navigation](https://arxiv.org/abs/2510.00942)
*Reza Vafaee,Kian Behzad,Milad Siami,Luca Carlone,Ali Jadbabaie*

Main category: cs.RO

TL;DR: 提出了一个任务导向的计算框架，通过战略性地选择视觉特征来增强机器人视觉惯性导航，解决了时间和能量资源受限的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在视觉惯性导航中面临的时间和能量资源限制问题，提高导航效率。

Method: 使用基于均方误差的非子模目标函数和简化动态预测模型来选择视觉特征。提出了四种多项式时间近似算法：经典贪婪法、低秩贪婪变体、随机贪婪采样器和基于一阶泰勒展开的线性化选择器。

Result: 在标准化基准和自定义控制感知平台上的广泛实验验证了理论结果，这些方法实现了强大的近似保证，同时支持实时部署。

Conclusion: 该框架通过有效的特征选择和近似算法，在保持强近似保证的同时实现了实时部署，显著提升了视觉惯性导航的性能。

Abstract: This paper presents a task-oriented computational framework to enhance
Visual-Inertial Navigation (VIN) in robots, addressing challenges such as
limited time and energy resources. The framework strategically selects visual
features using a Mean Squared Error (MSE)-based, non-submodular objective
function and a simplified dynamic anticipation model. To address the
NP-hardness of this problem, we introduce four polynomial-time approximation
algorithms: a classic greedy method with constant-factor guarantees; a low-rank
greedy variant that significantly reduces computational complexity; a
randomized greedy sampler that balances efficiency and solution quality; and a
linearization-based selector based on a first-order Taylor expansion for
near-constant-time execution. We establish rigorous performance bounds by
leveraging submodularity ratios, curvature, and element-wise curvature
analyses. Extensive experiments on both standardized benchmarks and a custom
control-aware platform validate our theoretical results, demonstrating that
these methods achieve strong approximation guarantees while enabling real-time
deployment.

</details>


### [57] [Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions](https://arxiv.org/abs/2510.00783)
*Thanh Nguyen Canh,Haolan Zhang,Xiem HoangVan,Nak Young Chong*

Main category: cs.RO

TL;DR: 这是一篇关于语义SLAM的综述性研究论文，系统梳理了该领域的发展历程、现有技术和未来方向。


<details>
  <summary>Details</summary>
Motivation: 语义SLAM领域缺乏全面的综述文献来涵盖最新进展和持续挑战，因此本研究旨在填补这一空白。

Method: 提出了统一的问题表述和模块化解决方案框架，将问题分解为视觉定位、语义特征提取、建图、数据关联和闭环优化等阶段，并探讨了深度学习和大型语言模型等替代方法。

Result: 提供了对语义SLAM技术现状的全面检查，阐明了当前趋势和关键障碍，并回顾了相关SLAM数据集的研究。

Conclusion: 本研究为研究人员导航语义SLAM复杂领域提供了全面资源，并讨论了未来潜在的研究方向。

Abstract: Semantic Simultaneous Localization and Mapping (SLAM) is a critical area of
research within robotics and computer vision, focusing on the simultaneous
localization of robotic systems and associating semantic information to
construct the most accurate and complete comprehensive model of the surrounding
environment. Since the first foundational work in Semantic SLAM appeared more
than two decades ago, this field has received increasing attention across
various scientific communities. Despite its significance, the field lacks
comprehensive surveys encompassing recent advances and persistent challenges.
In response, this study provides a thorough examination of the state-of-the-art
of Semantic SLAM techniques, with the aim of illuminating current trends and
key obstacles. Beginning with an in-depth exploration of the evolution of
visual SLAM, this study outlines its strengths and unique characteristics,
while also critically assessing previous survey literature. Subsequently, a
unified problem formulation and evaluation of the modular solution framework is
proposed, which divides the problem into discrete stages, including visual
localization, semantic feature extraction, mapping, data association, and loop
closure optimization. Moreover, this study investigates alternative
methodologies such as deep learning and the utilization of large language
models, alongside a review of relevant research about contemporary SLAM
datasets. Concluding with a discussion on potential future research directions,
this study serves as a comprehensive resource for researchers seeking to
navigate the complex landscape of Semantic SLAM.

</details>


### [58] [RTFF: Random-to-Target Fabric Flattening Policy using Dual-Arm Manipulator](https://arxiv.org/abs/2510.00814)
*Kai Tang,Dipankar Bhattacharya,Hang Xu,Fuyuki Tokuda,Norman C. Tien,Kazuhiro Kosuge*

Main category: cs.RO

TL;DR: 提出了首个随机到目标织物平整策略，采用混合模仿学习-视觉伺服框架，通过基于模板的网格实现精确目标状态表示和一致的顶点对应，在真实双臂遥操作系统上验证了零样本对齐、高精度和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决织物生产中机器人操作面临的挑战，包括织物可变形性、无限自由度以及褶皱、折叠和机械臂遮挡等问题，实现可靠的织物平整和对齐。

Method: 采用混合模仿学习-视觉伺服框架，其中模仿学习使用显式织物模型进行粗略对齐，视觉伺服确保精细对齐；提出基于模板的网格表示和RTFF-Mesh Action Chunking Transformer策略。

Result: 在真实双臂遥操作系统上验证，展示了零样本对齐不同目标、高精度和跨织物与尺度的强泛化能力。

Conclusion: 提出的RTFF策略成功解决了织物平整和对齐的挑战，为机器人织物操作提供了有效的解决方案。

Abstract: Robotic fabric manipulation in garment production for sewing, cutting, and
ironing requires reliable flattening and alignment, yet remains challenging due
to fabric deformability, effectively infinite degrees of freedom, and frequent
occlusions from wrinkles, folds, and the manipulator's End-Effector (EE) and
arm. To address these issues, this paper proposes the first Random-to-Target
Fabric Flattening (RTFF) policy, which aligns a random wrinkled fabric state to
an arbitrary wrinkle-free target state. The proposed policy adopts a hybrid
Imitation Learning-Visual Servoing (IL-VS) framework, where IL learns with
explicit fabric models for coarse alignment of the wrinkled fabric toward a
wrinkle-free state near the target, and VS ensures fine alignment to the
target. Central to this framework is a template-based mesh that offers precise
target state representation, wrinkle-aware geometry prediction, and consistent
vertex correspondence across RTFF manipulation steps, enabling robust
manipulation and seamless IL-VS switching. Leveraging the power of mesh, a
novel IL solution for RTFF-Mesh Action Chunking Transformer (MACT)-is then
proposed by conditioning the mesh information into a Transformer-based policy.
The RTFF policy is validated on a real dual-arm tele-operation system, showing
zero-shot alignment to different targets, high accuracy, and strong
generalization across fabrics and scales. Project website:
https://kaitang98.github.io/RTFF_Policy/

</details>


### [59] [ROSflight 2.0: Lean ROS 2-Based Autopilot for Unmanned Aerial Vehicles](https://arxiv.org/abs/2510.00995)
*Jacob Moore,Phil Tokumaru,Ian Reid,Brandon Sutherland,Joseph Ritchie,Gabe Snow,Tim McLain*

Main category: cs.RO

TL;DR: ROSflight是一个轻量级的开源无人机自动驾驶生态系统，专为研究人员设计，旨在降低无人机研究门槛并加速从仿真到硬件实验的过渡。


<details>
  <summary>Details</summary>
Motivation: 降低无人机研究的入门门槛，通过维护精简、文档完善和模块化的代码库，加速从仿真到硬件实验的过渡过程。

Method: 从ROS 1过渡到ROS 2，改进架构的模块化和可用性，包括支持硬件、低级执行器混合和仿真环境。

Result: 硬件结果显示，ROSflight能够通过串行连接以400Hz的频率控制多旋翼无人机，同时将所有控制回路在配套计算机上闭合。

Conclusion: 这些改进提升了ROSflight的可用性，使其能够加速先进空中机动性等领域的研究。

Abstract: ROSflight is a lean, open-source autopilot ecosystem for unmanned aerial
vehicles (UAVs). Designed by researchers for researchers, it is built to lower
the barrier to entry to UAV research and accelerate the transition from
simulation to hardware experiments by maintaining a lean (not full-featured),
well-documented, and modular codebase. This publication builds on previous
treatments and describes significant additions to the architecture that improve
the modularity and usability of ROSflight, including the transition from ROS 1
to ROS 2, supported hardware, low-level actuator mixing, and the simulation
environment. We believe that these changes improve the usability of ROSflight
and enable ROSflight to accelerate research in areas like advanced-air
mobility. Hardware results are provided, showing that ROSflight is able to
control a multirotor over a serial connection at 400 Hz while closing all
control loops on the companion computer.

</details>


### [60] [ROSplane 2.0: A Fixed-Wing Autopilot for Research](https://arxiv.org/abs/2510.01041)
*Ian Reid,Joseph Ritchie,Jacob Moore,Brandon Sutherland,Gabe Snow,Phillip Tokumaru,Tim McLain*

Main category: cs.RO

TL;DR: ROSplane是一个开源固定翼无人机自主控制栈，旨在加速无人机研究，提供清晰的接口和易于修改的框架，支持快速集成控制、路径规划和估计算法。


<details>
  <summary>Details</summary>
Motivation: 无人机研究需要将前沿技术集成到现有自动驾驶框架中，这个过程通常需要大量资源、时间和系统知识。ROSplane旨在降低研究门槛，加速研究进程。

Method: 基于ROS 2构建，提供清晰定义的接口和易于修改的框架，支持快速集成各种算法。采用精简易懂的代码和详细文档，提高模块化程度，改进气动建模流程。

Result: ROSplane成功从ROS 1迁移到ROS 2，增强了估计和控制算法，提高了模块化程度，改进了气动建模流程，显著减少了从仿真到真实测试的转换工作量。

Conclusion: ROSplane架构显著减少了集成新研究工具和方法所需的工作量，加速了硬件实验进程，为无人机研究提供了高效的研究平台。

Abstract: Unmanned aerial vehicle (UAV) research requires the integration of
cutting-edge technology into existing autopilot frameworks. This process can be
arduous, requiring extensive resources, time, and detailed knowledge of the
existing system. ROSplane is a lean, open-source fixed-wing autonomy stack
built by researchers for researchers. It is designed to accelerate research by
providing clearly defined interfaces with an easily modifiable framework.
Powered by ROS 2, ROSplane allows for rapid integration of low or high-level
control, path planning, or estimation algorithms. A focus on lean, easily
understood code and extensive documentation lowers the barrier to entry for
researchers. Recent developments to ROSplane improve its capacity to accelerate
UAV research, including the transition from ROS 1 to ROS 2, enhanced estimation
and control algorithms, increased modularity, and an improved aerodynamic
modeling pipeline. This aerodynamic modeling pipeline significantly reduces the
effort of transitioning from simulation to real-world testing without requiring
expensive system identification or computational fluid dynamics tools.
ROSplane's architecture reduces the effort required to integrate new research
tools and methods, expediting hardware experimentation.

</details>


### [61] [Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning](https://arxiv.org/abs/2510.01023)
*S. Satsevich,A. Bazhenov,S. Egorov,A. Erkhov,M. Gromakov,A. Fedoseev,D. Tsetserukou*

Main category: cs.RO

TL;DR: 提出基于HTC Vive Tracker 2.0的新型力反馈遥操作系统，用于低成本大规模模仿学习数据收集


<details>
  <summary>Details</summary>
Motivation: 开发经济实惠的力反馈遥操作系统，以支持大规模模仿学习数据收集，同时保持低成本

Method: 集成消费级HTC Vive Tracker 2.0、定制控制器、UR3机械臂和配备定制手指的Robotiq夹爪，通过嵌入式力传感器实现均匀压力分布和实时力数据传输

Result: 实验结果显示系统提高了任务成功率，并为大规模模仿学习数据收集提供了低成本解决方案

Conclusion: 该系统成功实现了经济高效的力反馈遥操作，为模仿学习数据收集提供了可行方案

Abstract: This paper presents a novel teleoperation system with force feedback,
utilizing consumer-grade HTC Vive Trackers 2.0. The system integrates a
custom-built controller, a UR3 robotic arm, and a Robotiq gripper equipped with
custom-designed fingers to ensure uniform pressure distribution on an embedded
force sensor. Real-time compression force data is transmitted to the
controller, enabling operators to perceive the gripping force applied to
objects. Experimental results demonstrate that the system enhances task success
rates and provides a low-cost solution for large-scale imitation learning data
collection without compromising affordability.

</details>


### [62] [Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition](https://arxiv.org/abs/2510.01068)
*Jiahang Cao,Yize Huang,Hanzhong Guo,Rui Zhang,Mu Nan,Weijian Mai,Jiaxu Wang,Hao Cheng,Jingkai Sun,Gang Han,Wen Zhao,Qiang Zhang,Yijie Guo,Qihao Zheng,Chunfeng Song,Xiao Li,Ping Luo,Andrew F. Luo*

Main category: cs.RO

TL;DR: 提出了一种无需额外训练的策略组合方法GPC，通过组合多个预训练扩散模型的分布分数来提升机器人控制性能，在多个基准测试中表现优于单个策略。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人控制中表现出色，但大规模交互数据获取成本高昂。本文探索在不进行额外训练的情况下提升策略性能的新范式。

Method: 提出通用策略组合(GPC)方法，通过凸组合和测试时搜索来组合多个预训练策略的分布分数，支持异构策略的组合。

Result: 在Robomimic、PushT和RoboTwin基准测试及真实机器人评估中，GPC一致提升了性能和适应性，组合策略性能超过任一父策略。

Conclusion: GPC是一种简单有效的控制性能提升方法，通过利用现有策略实现性能增益，为策略组合提供了理论基础和实用框架。

Abstract: Diffusion-based models for robotic control, including vision-language-action
(VLA) and vision-action (VA) policies, have demonstrated significant
capabilities. Yet their advancement is constrained by the high cost of
acquiring large-scale interaction datasets. This work introduces an alternative
paradigm for enhancing policy performance without additional model training.
Perhaps surprisingly, we demonstrate that the composed policies can exceed the
performance of either parent policy. Our contribution is threefold. First, we
establish a theoretical foundation showing that the convex composition of
distributional scores from multiple diffusion models can yield a superior
one-step functional objective compared to any individual score. A
Gr\"onwall-type bound is then used to show that this single-step improvement
propagates through entire generation trajectories, leading to systemic
performance gains. Second, motivated by these results, we propose General
Policy Composition (GPC), a training-free method that enhances performance by
combining the distributional scores of multiple pre-trained policies via a
convex combination and test-time search. GPC is versatile, allowing for the
plug-and-play composition of heterogeneous policies, including VA and VLA
models, as well as those based on diffusion or flow-matching, irrespective of
their input visual modalities. Third, we provide extensive empirical
validation. Experiments on Robomimic, PushT, and RoboTwin benchmarks, alongside
real-world robotic evaluations, confirm that GPC consistently improves
performance and adaptability across a diverse set of tasks. Further analysis of
alternative composition operators and weighting strategies offers insights into
the mechanisms underlying the success of GPC. These results establish GPC as a
simple yet effective method for improving control performance by leveraging
existing policies.

</details>


### [63] [Real-Time Trajectory Generation and Hybrid Lyapunov-Based Control for Hopping Robots](https://arxiv.org/abs/2510.01138)
*Matthew Woodward*

Main category: cs.RO

TL;DR: 提出了一种实时、计算效率高的非线性阻力补偿轨迹生成方法和李雅普诺夫控制器，使跳跃机器人能够从起飞到触地执行复杂空中轨迹控制。


<details>
  <summary>Details</summary>
Motivation: 当前跳跃机器人无法直接控制空中轨迹或过渡到飞行状态，无法充分利用跳跃系统的效率优势。

Method: 开发了非线性阻力补偿的轨迹生成方法和基于李雅普诺夫稳定性的控制器，支持从起飞到触地的完整轨迹跟踪。

Result: 系统能够创建和跟踪复杂空中轨迹，在水平和垂直表面上实现精确触地控制，同时保持触地时的严格姿态控制。

Conclusion: 该计算高效的方法适用于各种尺寸的跳跃机器人，并具有对四旋翼无人机的通用适用性。

Abstract: The advent of rotor-based hopping robots has created very capable hopping
platforms with high agility and efficiency, and similar controllability, as
compared to their purely flying quadrotor counterparts. Advances in robot
performance have increased the hopping height to greater than 4 meters and
opened up the possibility for more complex aerial trajectories (i.e.,
behaviors). However, currently hopping robots do not directly control their
aerial trajectory or transition to flight, eliminating the efficiency benefits
of a hopping system. Here we show a real-time, computationally efficiency,
non-linear drag compensated, trajectory generation methodology and accompanying
Lyapunov-based controller. The combined system can create and follow complex
aerial trajectories from liftoff to touchdown on horizontal and vertical
surfaces, while maintaining strick control over the orientation at touchdown.
The computational efficiency provides broad applicability across all size
scales of hopping robots while maintaining applicability to quadrotors in
general.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [64] [A Unified Framework for Spatial and Temporal Treatment Effect Boundaries: Theory and Identification](https://arxiv.org/abs/2510.00754)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 提出了一个统一的理论框架，用于检测和估计处理效应在空间和时间维度上的边界，将处理效应边界形式化为结构参数，并基于信息传播的扩散模型建立识别条件和估计方法。


<details>
  <summary>Details</summary>
Motivation: 需要形式化处理效应边界的概念，以识别因果效应停止运作的制度转变点，为政策干预提供关键阈值检测工具。

Method: 基于信息传播的扩散模型，建立空间和时间边界共享共同动态的条件，推导识别结果并提出一致估计量，通过蒙特卡洛模拟验证方法性能。

Result: 蒙特卡洛模拟表明该方法在各种数据生成过程中表现良好，框架能够检测局部处理何时变为系统性，并识别政策干预的关键阈值。

Conclusion: 该统一框架为检测处理效应边界提供了理论工具，有助于理解制度转变和政策干预时机。

Abstract: This paper develops a unified theoretical framework for detecting and
estimating boundaries in treatment effects across both spatial and temporal
dimensions. We formalize the concept of treatment effect boundaries as
structural parameters characterizing regime transitions where causal effects
cease to operate. Building on diffusion-based models of information
propagation, we establish conditions under which spatial and temporal
boundaries share common dynamics, derive identification results, and propose
consistent estimators. Monte Carlo simulations demonstrate the performance of
our methods under various data-generating processes. The framework provides
tools for detecting when local treatments become systemic and identifying
critical thresholds for policy intervention.

</details>


### [65] [Generalized Bayes in Conditional Moment Restriction Models](https://arxiv.org/abs/2510.01036)
*Sid Kankanala*

Main category: econ.EM

TL;DR: 本文开发了一个广义（准）贝叶斯框架用于条件矩限制模型，其中参数是内生变量的非参数结构函数。建立了高斯过程先验的收缩率，并提供了准贝叶斯后验的Bernstein-von Mises定理成立的条件。


<details>
  <summary>Details</summary>
Motivation: 扩展经典参数GMM模型的结果，为非参数结构函数提供贝叶斯推断框架，使最优加权准贝叶斯可信集达到精确的渐近频率覆盖。

Method: 使用高斯过程先验的广义准贝叶斯方法，建立收缩率和Bernstein-von Mises定理的条件。

Result: 准贝叶斯可信集实现精确渐近频率覆盖，模拟显示广义贝叶斯估计器优于常见替代方法。

Conclusion: 广义准贝叶斯框架成功扩展了经典GMM结果，为非参数条件矩限制模型提供了有效的贝叶斯推断工具。

Abstract: This paper develops a generalized (quasi-) Bayes framework for conditional
moment restriction models, where the parameter of interest is a nonparametric
structural function of endogenous variables. We establish contraction rates for
a class of Gaussian process priors and provide conditions under which a
Bernstein-von Mises theorem holds for the quasi-Bayes posterior. Consequently,
we show that optimally weighted quasi-Bayes credible sets achieve exact
asymptotic frequentist coverage, extending classical results for parametric GMM
models. As an application, we estimate firm-level production functions using
Chilean plant-level data. Simulations illustrate the favorable performance of
generalized Bayes estimators relative to common alternatives.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [66] [Revealing the temporal dynamics of antibiotic anomalies in the infant gut microbiome with neural jump ODEs](https://arxiv.org/abs/2510.00087)
*Anja Adamov,Markus Chardonnet,Florian Krach,Jakob Heiss,Josef Teichmann,Nicholas A. Bokulich*

Main category: stat.AP

TL;DR: 提出基于神经跳跃常微分方程(NJODEs)的异常检测框架，用于不规则采样的多变量时间序列，能够准确识别各种偏差并在婴儿肠道微生物组数据中有效检测抗生素引起的异常。


<details>
  <summary>Details</summary>
Motivation: 解决不规则采样多变量时间序列中的异常检测挑战，特别是在数据稀缺的情况下，需要能够处理跳跃、漂移、扩散和噪声等多种异常类型的方法。

Method: 使用神经跳跃常微分方程(NJODEs)推断条件均值和方差轨迹，以完全路径依赖的方式计算异常分数，能够处理不均匀间隔的纵向观测并调整静态和动态协变量。

Result: 在合成数据中准确识别多种异常；在婴儿肠道微生物组数据中揭示了抗生素引起的异常程度和持续性，特别是在第二次抗生素疗程、延长治疗期间和第二年暴露时；异常分数在预测抗生素事件方面优于基于多样性的基线方法。

Conclusion: 该方法为推断由扰动引起的微生物异常提供了基础，为通过最小化微生物干扰来优化干预方案提供了转化机会。

Abstract: Detecting anomalies in irregularly sampled multi-variate time-series is
challenging, especially in data-scarce settings. Here we introduce an anomaly
detection framework for irregularly sampled time-series that leverages neural
jump ordinary differential equations (NJODEs). The method infers conditional
mean and variance trajectories in a fully path dependent way and computes
anomaly scores. On synthetic data containing jump, drift, diffusion, and noise
anomalies, the framework accurately identifies diverse deviations. Applied to
infant gut microbiome trajectories, it delineates the magnitude and persistence
of antibiotic-induced disruptions: revealing prolonged anomalies after second
antibiotic courses, extended duration treatments, and exposures during the
second year of life. We further demonstrate the predictive capabilities of the
inferred anomaly scores in accurately predicting antibiotic events and
outperforming diversity-based baselines. Our approach accommodates unevenly
spaced longitudinal observations, adjusts for static and dynamic covariates,
and provides a foundation for inferring microbial anomalies induced by
perturbations, offering a translational opportunity to optimize intervention
regimens by minimizing microbial disruptions.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [67] [Elicitability](https://arxiv.org/abs/2510.00879)
*Yaron Azrieli,Christopher Chambers,Paul Healy,Nicolas Lambert*

Main category: econ.TH

TL;DR: 该论文研究了在分析师可能操纵统计研究的情况下，如何通过适当的激励设计来获取真实信息。作者比较了不同实验在信息获取能力上的差异，发现用于估计的数据也适用于激励设计，但反之不成立。


<details>
  <summary>Details</summary>
Motivation: 分析师在不受监控的情况下可能操纵统计研究，而基于报告和可信数据的支付机制可以激励真实信息的披露。研究旨在理解如何通过激励设计来获取准确信息。

Method: 作者建立了一个理论框架，描述通过适当设计的激励可以获取的信息类型，并将该框架应用于常见的统计模型。通过比较不同实验在信息获取能力上的差异，分析了数据作为激励生成器与统计推断工具的异同。

Result: 研究发现，数据在激励设计和统计推断中的使用存在差异：适合估计的数据也适合激励设计，但反之不一定成立。这种排序与Blackwell排序相关但不同。

Conclusion: 研究揭示了将数据作为支付方案中的激励生成器与将数据用于统计推断之间的重要区别，为设计有效的激励机制提供了理论依据。

Abstract: An analyst is tasked with producing a statistical study. The analyst is not
monitored and is able to manipulate the study. He can receive payments
contingent on his report and trusted data collected from an independent source,
modeled as a statistical experiment. We describe the information that can be
elicited with appropriately shaped incentives, and apply our framework to a
variety of common statistical models. We then compare experiments based on the
information they enable us to elicit. This order is connected to, but different
from, the Blackwell order. Data preferred for estimation are also preferred for
elicitation, but not conversely. Our results shed light on how using data as
incentive generator in payment schemes differs from using data for statistical
inference.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [68] [Board Gender Diversity and Carbon Emissions Performance: Insights from Panel Regressions, Machine Learning and Explainable AI](https://arxiv.org/abs/2510.00244)
*Mohammad Hassan Shakil,Arne Johan Pollestad,Khine Kyaw,Ziaul Haque Munim*

Main category: q-fin.GN

TL;DR: 研究发现董事会性别多样性与企业碳排放绩效存在显著非线性关系，最佳比例为35%，最低门槛为22%。ESG争议不影响该关系，环境创新不是中介机制。


<details>
  <summary>Details</summary>
Motivation: 欧盟引入董事会性别配额政策背景下，研究董事会性别多样性对企业碳排放绩效的影响，检验该关系是否受ESG争议影响以及环境创新的中介作用。

Method: 使用面板回归和机器学习算法分析2016-2022年欧洲企业数据，采用结构方程模型检验中介效应。

Result: 发现35%为最优性别多样性比例，22%为最低有效门槛；ESG争议不影响该关系，环境创新不是中介变量。

Conclusion: 董事会性别多样性通过治理机制而非象征性行动改善碳排放绩效，研究结果对学术界、企业和监管机构具有重要启示。

Abstract: With the European Union introducing gender quotas on corporate boards, this
study investigates the impact of board gender diversity (BGD) on firms' carbon
emission performance (CEP). Using panel regressions and advanced machine
learning algorithms on data from European firms between 2016 and 2022, the
analyses reveal a significant non-linear relationship. Specifically, CEP
improves with BGD up to an optimal level of approximately 35 percent, beyond
which further increases in BGD yield no additional improvement in CEP. A
minimum threshold of 22 percent BGD is necessary for meaningful improvements in
CEP. To assess the legitimacy of CEP outcomes, this study examines whether ESG
controversies affect the relationship between BGD and CEP. The results show no
significant effect, suggesting that the effect of BGD is driven by governance
mechanisms rather than symbolic actions. Additionally, structural equation
modelling (SEM) indicates that while environmental innovation contributes to
CEP, it is not the mediating channel through which BGD promotes CEP. The
results have implications for academics, businesses, and regulators.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [69] [Two-Stage Asymmetric Tullock Contests with Cost Shifters and Endogenous Continuation Decision](https://arxiv.org/abs/2510.00349)
*Felix Reichel*

Main category: econ.GN

TL;DR: 提出了一个基于竞赛理论的三项全能简化模型，将其建模为顺序两阶段博弈，分析游泳跟骑对参赛者决策和努力水平的影响。


<details>
  <summary>Details</summary>
Motivation: 研究三项全能比赛中游泳跟骑策略如何影响运动员的参赛决策和后续比赛中的努力水平，探讨内生参与决策的形成机制。

Method: 构建顺序两阶段博弈模型：第一阶段（游泳后）决定是否继续参赛，第二阶段（自行车-跑步）采用Tullock竞赛形式，游泳跟骑作为二次努力成本的乘性转移因子。

Result: 推导出双人情况下的闭式均衡策略，证明非对称n人情况下均衡的存在性、唯一性和比较静态性质，发现游泳跟骑强度产生运动员特定的临界规则。

Conclusion: 游泳跟骑的收益、暴露程度和群体规模与异质有效成本参数和均衡努力水平相关，内生参与集形成了子博弈完美均衡。

Abstract: This paper introduces a contest-theoretic simplified model of triathlon as a
sequential two-stage game. In Stage 1 (post-swim), participants decide whether
to continue or withdraw from the contest, thereby generating an endogenous
participation decision. In Stage 2 (bike-run), competition is represented as a
Tullock contest in which swim drafting acts as a multiplicative shifter of
quadratic effort costs. Closed-form equilibrium strategies are derived in the
two-player case, and existence, uniqueness, and comparative statics are shown
in the asymmetric n-player case. The continuation decision yields
athlete-specific cutoff rules in swim drafting intensity and induces
subgame-perfect equilibria (SPEs) with endogenous participation sets. The
analysis relates swim drafting benefits, exposure, and group size to
heterogeneous effective cost parameters and equilibrium efforts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [70] [Learning to Lead Themselves: Agentic AI in MAS using MARL](https://arxiv.org/abs/2510.00022)
*Ansh Kamthan*

Main category: cs.AI

TL;DR: 该论文研究了自主智能体如何通过去中心化协作决策改进多智能体系统中的任务分配和协调，主要应用于无人机配送和仓库自动化。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统从原型转向实际部署，多个智能体进行去中心化协作决策的能力成为核心需求。

Method: 在合作多智能体强化学习框架下，采用集中训练、分散执行的轻量级多智能体近端策略优化（IPPO）方法，在PettingZoo环境中进行实验。

Result: 多个同质无人机或智能体能够在没有显式通信的情况下自组织覆盖不同目标。

Conclusion: 自主智能体人工智能能够有效提升多智能体系统的任务分配和协调能力。

Abstract: As autonomous systems move from prototypes to real deployments, the ability
of multiple agents to make decentralized, cooperative decisions becomes a core
requirement. This paper examines how agentic artificial intelligence, agents
that act independently, adaptively and proactively can improve task allocation
and coordination in multi-agent systems, with primary emphasis on drone
delivery and secondary relevance to warehouse automation. We formulate the
problem in a cooperative multi-agent reinforcement learning setting and
implement a lightweight multi-agent Proximal Policy Optimization, called IPPO,
approach in PyTorch under a centralized-training, decentralized-execution
paradigm. Experiments are conducted in PettingZoo environment, where multiple
homogeneous drones or agents must self-organize to cover distinct targets
without explicit communication.

</details>


### [71] [Exploring Network-Knowledge Graph Duality: A Case Study in Agentic Supply Chain Risk Analysis](https://arxiv.org/abs/2510.01115)
*Evan Heus,Rick Bookstaber,Dhruv Sharma*

Main category: cs.AI

TL;DR: 提出了一种基于LLM的智能体框架，利用网络与知识图谱的二元性进行供应链风险分析，通过图遍历和上下文模板实现实时、可解释的风险叙述生成。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法过度简化关系，专业模型成本高且静态，无法有效处理金融风险中的复杂多模态网络数据。

Method: 将供应链网络视为知识图谱，使用网络中心性评分指导图遍历提取关键风险路径，结合数值因子表和新闻流数据，采用上下文模板使定量数据对LLM可理解。

Result: 实现了轻量级方法，无需昂贵微调或专用图数据库，即可实时生成简洁、可解释、上下文丰富的风险叙述。

Conclusion: 该框架成功解决了LLM在金融风险分析中的局限性，提供了一种高效、可扩展的供应链风险评估方案。

Abstract: Large Language Models (LLMs) struggle with the complex, multi-modal, and
network-native data underlying financial risk. Standard Retrieval-Augmented
Generation (RAG) oversimplifies relationships, while specialist models are
costly and static. We address this gap with an LLM-centric agent framework for
supply chain risk analysis. Our core contribution is to exploit the inherent
duality between networks and knowledge graphs (KG). We treat the supply chain
network as a KG, allowing us to use structural network science principles for
retrieval. A graph traverser, guided by network centrality scores, efficiently
extracts the most economically salient risk paths. An agentic architecture
orchestrates this graph retrieval alongside data from numerical factor tables
and news streams. Crucially, it employs novel ``context shells'' -- descriptive
templates that embed raw figures in natural language -- to make quantitative
data fully intelligible to the LLM. This lightweight approach enables the model
to generate concise, explainable, and context-rich risk narratives in real-time
without costly fine-tuning or a dedicated graph database.

</details>


### [72] [ToolBrain: A Flexible Reinforcement Learning Framework for Agentic Tools](https://arxiv.org/abs/2510.00023)
*Quy Minh Le,Minh Sao Khue Luu,Khanh-Tung Tran,Duc-Hai Nguyen,Hoang-Quoc-Viet Pham,Quan Le,Hoang Thanh Lam,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: ToolBrain是一个轻量级框架，通过强化学习训练AI代理使用工具，解决了手动设计奖励、训练数据有限和多工具选择困难等问题。


<details>
  <summary>Details</summary>
Motivation: 当前训练AI代理使用工具面临手动设计奖励、训练数据有限、多工具选择困难等挑战，导致适应慢、计算资源浪费和性能不佳。

Method: 开发ToolBrain框架，支持GRPO、DPO等强化学习算法和监督学习，提供自定义奖励函数和自动LLM评判系统，包含知识蒸馏、任务生成、工具检索等功能。

Result: 在邮件搜索任务中训练CodeAct代理，工具使用技能提升高达30.0%，同时保持代码库简单且可扩展。

Conclusion: ToolBrain为研究人员和从业者提供了一个用户友好、高效的框架，能够快速提升AI代理的工具使用能力，推动Agentic AI发展。

Abstract: Effective tool use is essential for agentic AI, yet training agents to
utilize tools remains challenging due to manually designed rewards, limited
training data, and poor multi-tool selection, resulting in slow adaptation,
wasted computational resources, and suboptimal performance. We introduce
ToolBrain, a lightweight and user-friendly framework for coaching tool use in
agentic models with flexible reinforcement learning (RL), easing the barriers
for researchers and practitioners to adapt LLM-based agents to specific
domains. It supports a wide range of training strategies, including RL
algorithms such as GRPO and DPO, as well as supervised learning. ToolBrain
enables custom reward callables directly on an agent's execution traces or
simply utilizes an automated LLM-as-a-judge system for reward generation. It is
packed with useful capabilities, including knowledge distillation from large to
small models for efficient development, automatic task generation from tool
descriptions, seamless tool retrieval, efficient fine-tuning pipelines with
QLoRA through Unsloth, and quantized inference via bitsandbytes. We demonstrate
ToolBrain through diverse use cases, such as training a CodeAct agent to
autonomously execute email search tasks, showing fast, targeted improvements
(up to 30.0%) in tool-use skills while keeping the codebase simple and
extensible in Agentic AI. Our framework is publicly available at
https://toolbrain.org.

</details>


### [73] [ARS: Adaptive Reasoning Suppression for Efficient Large Reasoning Language Models](https://arxiv.org/abs/2510.00071)
*Dongqi Zheng*

Main category: cs.AI

TL;DR: 提出自适应推理抑制(ARS)方法，通过动态抑制冗余推理步骤来提升大型推理语言模型的效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理语言模型在复杂推理任务中表现出色，但存在计算效率低下的问题，现有方法难以平衡推理质量与推理成本。

Method: 采用训练免费的自适应推理抑制方法，通过多检查点确定性估计机制和渐进抑制阈值来动态抑制冗余推理步骤。

Result: 在数学推理基准测试中，ARS实现了最高53%的token减少、46.1%的延迟减少和57.9%的能耗减少，同时保持或提高了准确性。

Conclusion: ARS方法在多个模型架构上验证了其有效性，能够在显著提升推理效率的同时保持推理质量。

Abstract: Large Reasoning Language Models (LRLMs or LRMs) demonstrate remarkable
capabilities in complex reasoning tasks, but suffer from significant
computational inefficiencies due to overthinking phenomena. Existing efficient
reasoning methods face the challenge of balancing reasoning quality with
inference cost reduction. We propose \textbf{Adaptive Reasoning Suppression
(ARS)}, a novel training-free approach that dynamically suppresses redundant
reasoning steps while preserving accuracy through adaptive certainty
monitoring. ARS introduces a multi-checkpoint certainty estimation mechanism
with progressive suppression thresholds, achieving superior efficiency compared
to static suppression methods. Our extensive evaluation across mathematical
reasoning benchmarks using multiple model architectures demonstrates that ARS
achieves up to 53%, 46.1%, and 57.9% in token, latency and energy reduction,
while maintaining or improving accuracy.

</details>


### [74] [NeurIPS should lead scientific consensus on AI policy](https://arxiv.org/abs/2510.00075)
*Rishi Bommasani*

Main category: cs.AI

TL;DR: NeurIPS应该积极推动AI政策科学共识的形成，以制定更明智的AI政策。


<details>
  <summary>Details</summary>
Motivation: 当前AI政策制定缺乏科学共识形成机制，而NeurIPS作为AI领域的领导者，最适合承担这一角色。

Method: 建议NeurIPS借鉴IPCC在气候政策共识形成方面的经验，开展初步试点项目。

Result: 论文识别了AI政策共识形成的空白，并论证了NeurIPS作为最佳选择的原因。

Conclusion: NeurIPS应该在AI政策科学共识形成方面发挥领导作用，以制定更高质量的AI政策。

Abstract: Designing wise AI policy is a grand challenge for society. To design such
policy, policymakers should place a premium on rigorous evidence and scientific
consensus. While several mechanisms exist for evidence generation, and nascent
mechanisms tackle evidence synthesis, we identify a complete void on consensus
formation. In this position paper, we argue NeurIPS should actively catalyze
scientific consensus on AI policy. Beyond identifying the current deficit in
consensus formation mechanisms, we argue that NeurIPS is the best option due
its strengths and the paucity of compelling alternatives. To make progress, we
recommend initial pilots for NeurIPS by distilling lessons from the IPCC's
leadership to build scientific consensus on climate policy. We dispel
predictable counters that AI researchers disagree too much to achieve consensus
and that policy engagement is not the business of NeurIPS. NeurIPS leads AI on
many fronts, and it should champion scientific consensus to create higher
quality AI policy.

</details>


### [75] [Towards a Framework for Supporting the Ethical and Regulatory Certification of AI Systems](https://arxiv.org/abs/2510.00084)
*Fabian Kovac,Sebastian Neumaier,Timea Pahi,Torsten Priebe,Rafael Rodrigues,Dimitrios Christodoulou,Maxime Cordy,Sylvain Kubler,Ali Kordia,Georgios Pitsiladis,John Soldatos,Petros Zervoudakis*

Main category: cs.AI

TL;DR: CERTAIN项目开发了一个综合框架，将监管合规、伦理标准和透明度整合到AI系统中，通过语义MLOps、本体驱动的数据谱系追踪和RegOps工作流程来构建核心组件。


<details>
  <summary>Details</summary>
Motivation: AI在欧洲社会和经济中的快速普及带来了关键的伦理、法律和监管挑战，需要解决这些挑战以促进负责任的AI创新。

Method: 采用语义MLOps进行结构化AI生命周期管理，本体驱动的数据谱系追踪确保可追溯性和问责制，以及RegOps工作流程将合规要求操作化。

Result: 通过在不同试点中实施和验证解决方案，CERTAIN项目推进了监管合规，并促进了符合欧洲标准的负责任AI创新。

Conclusion: CERTAIN框架通过整合监管合规、伦理标准和透明度，为应对AI带来的伦理、法律和监管挑战提供了有效解决方案。

Abstract: Artificial Intelligence has rapidly become a cornerstone technology,
significantly influencing Europe's societal and economic landscapes. However,
the proliferation of AI also raises critical ethical, legal, and regulatory
challenges. The CERTAIN (Certification for Ethical and Regulatory Transparency
in Artificial Intelligence) project addresses these issues by developing a
comprehensive framework that integrates regulatory compliance, ethical
standards, and transparency into AI systems. In this position paper, we outline
the methodological steps for building the core components of this framework.
Specifically, we present: (i) semantic Machine Learning Operations (MLOps) for
structured AI lifecycle management, (ii) ontology-driven data lineage tracking
to ensure traceability and accountability, and (iii) regulatory operations
(RegOps) workflows to operationalize compliance requirements. By implementing
and validating its solutions across diverse pilots, CERTAIN aims to advance
regulatory compliance and to promote responsible AI innovation aligned with
European standards.

</details>


### [76] [Judging by Appearances? Auditing and Intervening Vision-Language Models for Bail Prediction](https://arxiv.org/abs/2510.00088)
*Sagnik Basu,Shubham Prakash,Ashish Maruti Barge,Siddharth D Jaiswal,Abhisek Dash,Saptarshi Ghosh,Animesh Mukherjee*

Main category: cs.AI

TL;DR: 该研究审计了视觉语言模型在保释决策预测中的表现，发现模型存在严重偏见，会高置信度错误拒绝应获保释者。通过RAG管道引入法律先例和微调干预，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型的兴起，法律判决预测系统开始利用罪犯图像和文本报告，但这种方式可能带来意外后果和恶意使用。需要评估VLMs在保释决策中的有效性。

Method: 首先审计独立VLMs在保释预测任务中的表现，然后设计干预算法：通过RAG管道引入法律先例，并使用创新方案对VLMs进行微调。

Result: 独立VLMs在多个交叉群体中表现不佳，会高置信度错误拒绝应获保释者。干预措施显著提高了保释预测性能。

Conclusion: 这项工作为未来在VLMs部署到真实世界法律判决预测之前设计更智能的干预措施铺平了道路。

Abstract: Large language models (LLMs) have been extensively used for legal judgment
prediction tasks based on case reports and crime history. However, with a surge
in the availability of large vision language models (VLMs), legal judgment
prediction systems can now be made to leverage the images of the criminals in
addition to the textual case reports/crime history. Applications built in this
way could lead to inadvertent consequences and be used with malicious intent.
In this work, we run an audit to investigate the efficiency of standalone VLMs
in the bail decision prediction task. We observe that the performance is poor
across multiple intersectional groups and models \textit{wrongly deny bail to
deserving individuals with very high confidence}. We design different
intervention algorithms by first including legal precedents through a RAG
pipeline and then fine-tuning the VLMs using innovative schemes. We demonstrate
that these interventions substantially improve the performance of bail
prediction. Our work paves the way for the design of smarter interventions on
VLMs in the future, before they can be deployed for real-world legal judgment
prediction.

</details>


### [77] [AuditAgent: Expert-Guided Multi-Agent Reasoning for Cross-Document Fraudulent Evidence Discovery](https://arxiv.org/abs/2510.00156)
*Songran Bai,Bingzhe Wu,Yiwei Zhang,Chengke Wu,Xiaolong Zheng,Yaze Yuan,Ke Wu,Jianqiang Li*

Main category: cs.AI

TL;DR: 提出了一种名为AuditAgent的多智能体推理框架，用于金融欺诈检测中的细粒度证据链定位，在召回率和可解释性方面显著优于通用智能体方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的金融欺诈检测面临重大挑战，因为证据在复杂、多年的财务披露中具有微妙性和分散性。

Method: 开发了多智能体推理框架AuditAgent，整合了审计领域专业知识、主体级风险先验、混合检索策略和专用智能体模块，用于识别和聚合跨报告证据。

Result: 在从中国证监会发布的执法文件和财务报告构建的专家标注数据集上的广泛实验表明，该方法在召回率和可解释性方面显著优于通用智能体范式。

Conclusion: 研究结果强调了领域特定推理和数据集构建在推进实际监管应用中稳健金融欺诈检测的价值。

Abstract: Financial fraud detection in real-world scenarios presents significant
challenges due to the subtlety and dispersion of evidence across complex,
multi-year financial disclosures. In this work, we introduce a novel
multi-agent reasoning framework AuditAgent, enhanced with auditing domain
expertise, for fine-grained evidence chain localization in financial fraud
cases. Leveraging an expert-annotated dataset constructed from enforcement
documents and financial reports released by the China Securities Regulatory
Commission, our approach integrates subject-level risk priors, a hybrid
retrieval strategy, and specialized agent modules to efficiently identify and
aggregate cross-report evidence. Extensive experiments demonstrate that our
method substantially outperforms General-Purpose Agent paradigm in both recall
and interpretability, establishing a new benchmark for automated, transparent
financial forensics. Our results highlight the value of domain-specific
reasoning and dataset construction for advancing robust financial fraud
detection in practical, real-world regulatory applications.

</details>


### [78] [AI in data science education: experiences from the classroom](https://arxiv.org/abs/2510.00793)
*J. A. Hageman,C. F. W. Peeters*

Main category: cs.AI

TL;DR: 该研究探讨了AI（特别是像ChatGPT这样的大语言模型）在教育环境中的整合，重点关注对教与学的影响。研究发现AI工具既能简化任务、增强学习，也存在学生过度依赖技术而阻碍基本认知和问题解决能力发展的风险。


<details>
  <summary>Details</summary>
Motivation: 探索AI在教育环境中的整合，了解其对教学和学习的影响，特别是识别AI带来的益处和挑战。

Method: 通过对瓦赫宁根大学数据科学课程的课程协调员进行访谈。

Result: 研究发现AI工具可以简化任务并增强学习，但也存在学生过度依赖这些技术的问题，可能阻碍基本认知和问题解决能力的发展。

Conclusion: AI可以成为教育中的宝贵资产，但需要负责任地使用，考虑伦理问题，并调整评估方法，确保教育成果的实现，使AI补充而非取代基本学习过程。

Abstract: This study explores the integration of AI, particularly large language models
(LLMs) like ChatGPT, into educational settings, focusing on the implications
for teaching and learning. Through interviews with course coordinators from
data science courses at Wageningen University, this research identifies both
the benefits and challenges associated with AI in the classroom. While AI tools
can streamline tasks and enhance learning, concerns arise regarding students'
overreliance on these technologies, potentially hindering the development of
essential cognitive and problem solving skills. The study highlights the
importance of responsible AI usage, ethical considerations, and the need for
adapting assessment methods to ensure educational outcomes are met. With
careful integration, AI can be a valuable asset in education, provided it is
used to complement rather than replace fundamental learning processes.

</details>


### [79] [Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI](https://arxiv.org/abs/2510.00167)
*Diego Ortiz Barbosa,Mohit Agrawal,Yash Malegaonkar,Luis Burbano,Axel Andersson,György Dán,Henrik Sandberg,Alvaro A. Cardenas*

Main category: cs.AI

TL;DR: 该论文提出使用具身AI和大型视觉语言模型来增强自主无人机在突发事件中的自适应决策能力，替代传统手工编码的安全规则方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖安全工程师手工编写大量恢复规则，无法应对现实世界中的各种意外情况，且容易变得不完整。需要一种能够实时评估上下文并生成适当动作的自适应决策系统。

Method: 使用具身AI和大型视觉语言模型，在Unreal Engine模拟的城市场景中，让无人机动态解释周围环境并决定紧急机动以实现安全着陆。

Result: 研究结果表明，具身AI能够实现一类以前无法手工设计的自适应恢复和决策流程，提高了自主空中系统的弹性和安全性。

Conclusion: 基于具身AI的方法为自主无人机系统提供了一种新的自适应恢复和决策能力，显著提升了系统在面对突发事件时的安全性和韧性。

Abstract: Autonomous drones must often respond to sudden events, such as alarms,
faults, or unexpected changes in their environment, that require immediate and
adaptive decision-making. Traditional approaches rely on safety engineers
hand-coding large sets of recovery rules, but this strategy cannot anticipate
the vast range of real-world contingencies and quickly becomes incomplete.
Recent advances in embodied AI, powered by large visual language models,
provide commonsense reasoning to assess context and generate appropriate
actions in real time. We demonstrate this capability in a simulated urban
benchmark in the Unreal Engine, where drones dynamically interpret their
surroundings and decide on sudden maneuvers for safe landings. Our results show
that embodied AI makes possible a new class of adaptive recovery and
decision-making pipelines that were previously infeasible to design by hand,
advancing resilience and safety in autonomous aerial systems.

</details>


### [80] [Object-Centric Case-Based Reasoning via Argumentation](https://arxiv.org/abs/2510.00185)
*Gabriel de Olim Gaul,Adam Gould,Avinash Kori,Francesca Toni*

Main category: cs.AI

TL;DR: SAA-CBR是一种新型的神经符号图像分类方法，结合了神经Slot Attention组件和符号推理的AA-CBR方法，在CLEVR-Hans数据集上表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 开发一个结合神经学习和符号推理的混合系统，以提升图像分类性能，特别是在需要对象级理解和推理的任务中。

Method: 使用Slot Attention进行对象中心学习，然后通过AA-CBR进行符号推理，包括特征组合策略、案例库缩减、基于计数的偏序、One-Vs-Rest多分类策略以及双极AA-CBR变体。

Result: 在CLEVR-Hans数据集上，SAA-CBR表现出与基线模型相竞争的性能。

Conclusion: SAA-CBR是一个有效的图像分类器，成功整合了神经和符号方法，为神经符号AI提供了有前景的方向。

Abstract: We introduce Slot Attention Argumentation for Case-Based Reasoning (SAA-CBR),
a novel neuro-symbolic pipeline for image classification that integrates
object-centric learning via a neural Slot Attention (SA) component with
symbolic reasoning conducted by Abstract Argumentation for Case-Based Reasoning
(AA-CBR). We explore novel integrations of AA-CBR with the neural component,
including feature combination strategies, casebase reduction via representative
samples, novel count-based partial orders, a One-Vs-Rest strategy for extending
AA-CBR to multi-class classification, and an application of Supported AA-CBR, a
bipolar variant of AA-CBR. We demonstrate that SAA-CBR is an effective
classifier on the CLEVR-Hans datasets, showing competitive performance against
baseline models.

</details>


### [81] [Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware Objective](https://arxiv.org/abs/2510.00186)
*Anni Li,Aria Attar,Paul Dong*

Main category: cs.AI

TL;DR: Thinkquel是一个经过微调的模型，用于生成可靠、可移植且经过执行验证的数据库查询。它集成了新颖的合成数据管道TS-SQL和专门设计的Token-Sequence GRPO强化学习目标，以弥合token级训练信号与序列级执行奖励之间的差距。


<details>
  <summary>Details</summary>
Motivation: 将自然语言请求转换为可靠、生产就绪的数据转换仍然具有挑战性：正确性依赖于精确的模式链接和仓库特定的SQL方言，而训练期间最强的监督——执行成功和结果匹配——仅在序列级别提供。同时，组装大规模、经过执行验证的语料库成本高昂，且token级目标与这些全局信号不一致，导致优化不稳定和可移植性有限。

Method: Thinkquel集成了一种新颖的合成数据管道TS-SQL，利用dbt作为可移植的中间表示，并结合span感知的强化学习目标Token-Sequence GRPO（TS-GRPO），专门设计用于在微调LLMs时弥合token级训练信号与序列级执行奖励之间的差距。

Result: 在500个示例的TS-SQL测试集上，Thinkquel（32B）通过两阶段SFT课程达到93.2%的执行成功率和61.8%的精确结果匹配，相比基础模型分别提高了67.2%（执行）和44.4%（匹配）。在Spider（14B）实验中，TS-GRPO提高了训练稳定性，并加速了执行匹配奖励相对于GRPO和GSPO的收敛。

Conclusion: Thinkquel通过集成TS-SQL合成数据管道和TS-GRPO强化学习目标，成功解决了自然语言到SQL转换中的挑战，显著提高了执行成功率和结果匹配精度，同时改善了训练稳定性和收敛速度。

Abstract: Transforming natural-language requests into reliable, production-ready data
transformations remains challenging: correctness depends on precise schema
linking and warehouse-specific SQL dialects, while the strongest supervision
available during training--execution success and result matching--are provided
only at the sequence level. At the same time, assembling large,
execution-validated corpora is costly, and token-level objectives misalign with
these global signals, yielding unstable optimization and limited portability.
We introduce Thinkquel, a fine-tuned model for producing robust, portable, and
execution-validated database queries. Methodologies in Thinkquel integrates a
novel synthetic data pipeline, TS-SQL, that leverages dbt as a portable
intermediate representation with a span-aware reinforcement learning objective,
and Token-Sequence GRPO (TS-GRPO), specifically designed to bridge the gap
between token-level training signals and sequence-level execution rewards when
finetuning LLMs. On the 500-example TS-SQL test set, Thinkquel (32B) reaches
93.2\% execution success and 61.8\% exact-result match with a two-stage SFT
curriculum, improving over the base model by 67.2\% (exec.) and 44.4\% (match).
In Spider (14B) experiments, TS-GRPO increases training stability and speeds
convergence of the execution-match reward relative to GRPO and GSPO.

</details>


### [82] [DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems](https://arxiv.org/abs/2510.00229)
*Rohan Kadekodi,Zhan Jin,Keisuke Kamahori,Yile Gu,Sean Khatiri,Noah H. Bayindirli,Sergey Gorbunov,Baris Kasikci*

Main category: cs.AI

TL;DR: 提出了解耦微调方法，将工具调用任务分解为工具选择和参数生成两个子任务，使用LoRA适配器分别优化，并通过DualTune推理框架实现高效本地代理编排。


<details>
  <summary>Details</summary>
Motivation: 本地LLM在工具调用场景中表现不佳，需要隐私保护且成本效益高的解决方案，因此需要提升本地模型的工具调用能力。

Method: 采用解耦微调方法，为工具选择和参数生成分别创建专用LoRA适配器，使用分离的损失掩码进行微调，并通过DualTune框架动态加载适配器进行推理。

Result: 在MCP-Bench基准测试中，Qwen-2.5-7B模型的工具调用准确率提升了46%，在大多数情况下优于2倍大小的模型。

Conclusion: 解耦微调和DualTune框架显著提升了本地LLM的工具调用能力，实现了高效且隐私保护的代理编排。

Abstract: The deployment of Large Language Models (LLMs) as agentic orchestrators has
revolutionized task automation, but the need for privacy-preserving,
cost-effective solutions demands on-device inference capabilities. However,
local LLMs consistently underperform compared to frontier models in tool
calling scenarios, struggling with both tool selection from large tool sets and
accurate argument generation for complex parameter structures. We introduce a
methodology that disaggregates a tool-calling task into two distinct subtasks:
tool selection and argument generation. We propose "decoupled fine-tuning", a
novel post-training approach that employs LoRA fine-tuning to create dedicated
LoRA adapters for tool selection and tool-specific argument generation using
separate loss masking for each of the subtasks. Furthermore, we present
DualTune, an inference framework that leverages the LoRA adapters created using
decoupled fine-tuning to perform efficient agent orchestration with the help of
local models on end-user devices. DualTune decomposes the tool-call generation
step into tool selection and argument generation, and dynamically loads the
corresponding LoRA adapters to generate tool calls. Additionally, DualTune
implements hierarchical orchestration to restrict the number of tools required
for tool selection. Our experiments on the MCP-Bench benchmark demonstrate that
the Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool
calling accuracy of the base model by 46%, and outperforms other local
reasoning, non-reasoning and fine-tuned models of similar size in all cases,
and models that are 2x larger, in most cases.

</details>


### [83] [MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning](https://arxiv.org/abs/2510.00274)
*Maisha Maliha,Dean Hougen*

Main category: cs.AI

TL;DR: 提出了MAGIC-MASK框架，将基于扰动的可解释性方法扩展到多智能体强化学习，通过智能体间协作共享掩码状态信息和经验，提高关键状态发现效率和解释保真度。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习智能体决策过程的可解释性挑战，特别是在安全关键和多智能体环境中。现有方法如StateMask存在计算成本高、探索覆盖不足、缺乏多智能体适应等问题。

Method: 集成近端策略优化、自适应epsilon-greedy探索和轻量级智能体间协作，进行显著性引导的掩码处理，共享基于奖励的见解。基于轨迹扰动、奖励保真度分析和KL散度正则化的统一数学形式化。

Result: 在单智能体和多智能体基准测试中验证，包括多智能体高速公路驾驶环境和Google Research Football，在保真度、学习效率和策略鲁棒性方面持续优于最先进基线方法。

Conclusion: MAGIC-MASK框架成功将可解释性从单智能体系统推广到多智能体系统，提供基于概率建模和多智能体马尔可夫决策过程的可解释、可迁移的解释。

Abstract: Understanding the decision-making process of Deep Reinforcement Learning
agents remains a key challenge for deploying these systems in safety-critical
and multi-agent environments. While prior explainability methods like
StateMask, have advanced the identification of critical states, they remain
limited by computational cost, exploration coverage, and lack of adaptation to
multi-agent settings. To overcome these limitations, we propose a
mathematically grounded framework, MAGIC-MASK (Multi-Agent Guided Inter-agent
Collaboration with Mask-Based Explainability for Reinforcement Learning), that
extends perturbation-based explanation to Multi-Agent Reinforcement Learning.
Our method integrates Proximal Policy Optimization, adaptive epsilon-greedy
exploration, and lightweight inter-agent collaboration to share masked state
information and peer experience. This collaboration enables each agent to
perform saliency-guided masking and share reward-based insights with peers,
reducing the time required for critical state discovery, improving explanation
fidelity, and leading to faster and more robust learning. The core novelty of
our approach lies in generalizing explainability from single-agent to
multi-agent systems through a unified mathematical formalism built on
trajectory perturbation, reward fidelity analysis, and Kullback-Leibler
divergence regularization. This framework yields localized, interpretable
explanations grounded in probabilistic modeling and multi-agent Markov decision
processes. We validate our framework on both single-agent and multi-agent
benchmarks, including a multi-agent highway driving environment and Google
Research Football, demonstrating that MAGIC-MASK consistently outperforms
state-of-the-art baselines in fidelity, learning efficiency, and policy
robustness while offering interpretable and transferable explanations.

</details>


### [84] [ICL Optimized Fragility](https://arxiv.org/abs/2510.00300)
*Serena Gomez Wannaz*

Main category: cs.AI

TL;DR: ICL指南在提升特定任务性能的同时，会显著影响跨领域推理能力，造成"优化脆弱性"现象——在简单任务上表现优异但在复杂推理问题上性能下降。


<details>
  <summary>Details</summary>
Motivation: 探索ICL指南对跨领域认知能力的影响，特别是对推理灵活性的系统性影响。

Method: 使用GPT-OSS:20b模型的6个变体（1个基线+5种ICL配置），在840个测试中评估通用知识、逻辑谜题和数学奥赛问题的表现，并进行ANOVA统计分析。

Result: ICL模型在通用知识任务上达到91%-99%准确率，但在逻辑谜题上准确率降至10-43%（基线为43%），数学奥赛问题无显著差异。

Conclusion: ICL指南在效率和推理灵活性之间存在系统性权衡，对LLM部署和AI安全具有重要影响。

Abstract: ICL guides are known to improve task-specific performance, but their impact
on cross-domain cognitive abilities remains unexplored. This study examines how
ICL guides affect reasoning across different knowledge domains using six
variants of the GPT-OSS:20b model: one baseline model and five ICL
configurations (simple, chain-of-thought, random, appended text, and symbolic
language). The models were subjected to 840 tests spanning general knowledge
questions, logic riddles, and a mathematical olympiad problem. Statistical
analysis (ANOVA) revealed significant behavioral modifications (p less than
0.001) across ICL variants, demonstrating a phenomenon termed "optimized
fragility." ICL models achieved 91%-99% accuracy on general knowledge tasks
while showing degraded performance on complex reasoning problems, with accuracy
dropping to 10-43% on riddles compared to 43% for the baseline model. Notably,
no significant differences emerged on the olympiad problem (p=0.2173),
suggesting that complex mathematical reasoning remains unaffected by ICL
optimization. These findings indicate that ICL guides create systematic
trade-offs between efficiency and reasoning flexibility, with important
implications for LLM deployment and AI safety.

</details>


### [85] [BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models](https://arxiv.org/abs/2510.00307)
*Thierry Blankenstein,Jialin Yu,Zixuan Li,Vassilis Plachouras,Sunando Sengupta,Philip Torr,Yarin Gal,Alasdair Paren,Adel Bibi*

Main category: cs.AI

TL;DR: 本文研究了LLM代理在工具选择中的偏见问题，提出了评估工具选择偏见的基准，发现模型存在固定选择单一提供商或偏好列表中靠前工具的不公平现象，并提出了轻量级缓解方法。


<details>
  <summary>Details</summary>
Motivation: LLM代理依赖外部工具市场，但工具选择如果存在系统性偏见会降低用户体验并扭曲竞争，需要研究工具选择偏见的评估和缓解方法。

Method: 构建包含多个功能等效工具的多样化工具类别基准，测试7个模型，通过控制实验研究工具特征、元数据和预训练暴露对偏见的影响，并提出基于相关工具子集过滤和均匀采样的缓解方法。

Result: 发现语义对齐是选择的最强预测因素，扰动描述会显著改变选择，重复预训练暴露会放大偏见，提出的缓解方法能减少偏见同时保持良好任务覆盖率。

Conclusion: 工具选择偏见是工具增强LLM公平部署的关键障碍，需要关注和解决。

Abstract: Agents backed by large language models (LLMs) often rely on external tools
drawn from marketplaces where multiple providers offer functionally equivalent
options. This raises a critical point concerning fairness: if selection is
systematically biased, it can degrade user experience and distort competition
by privileging some providers over others. We introduce a benchmark of diverse
tool categories, each containing multiple functionally equivalent tools, to
evaluate tool-selection bias. Using this benchmark, we test seven models and
show that unfairness exists with models either fixating on a single provider or
disproportionately preferring earlier-listed tools in context. To investigate
the origins of this bias, we conduct controlled experiments examining tool
features, metadata (name, description, parameters), and pre-training exposure.
We find that: (1) semantic alignment between queries and metadata is the
strongest predictor of choice; (2) perturbing descriptions significantly shifts
selections; and (3) repeated pre-training exposure to a single endpoint
amplifies bias. Finally, we propose a lightweight mitigation that first filters
the candidate tools to a relevant subset and then samples uniformly, reducing
bias while preserving good task coverage. Our findings highlight tool-selection
bias as a key obstacle for the fair deployment of tool-augmented LLMs.

</details>


### [86] [When Hallucination Costs Millions: Benchmarking AI Agents in High-Stakes Adversarial Financial Markets](https://arxiv.org/abs/2510.00332)
*Zeshi Dai,Zimo Peng,Zerui Cheng,Ryan Yihe Li*

Main category: cs.AI

TL;DR: CAIA基准测试揭示AI在对抗性高风险环境中的严重缺陷：即使最先进的模型也无法有效应对主动欺骗，在加密市场等真实场景中表现不佳，工具增强效果有限且存在系统性工具选择问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估主要关注受控环境下的任务完成能力，但真实世界部署需要AI具备对抗主动欺骗的韧性。加密市场2024年因漏洞损失300亿美元，是测试AI在对抗性环境中能力的理想场景。

Method: 使用加密市场作为测试平台，评估17个模型在178个时间锚定任务上的表现。这些任务要求AI区分真相与操纵、导航碎片化信息环境、在对抗压力下做出不可逆的金融决策。

Result: 无工具时前沿模型准确率仅28%，工具增强后提升至67.4%，但仍低于人类基准80%。模型存在系统性工具选择问题：偏好不可靠的网页搜索而非权威数据源，容易落入SEO优化的虚假信息和社交媒体操纵陷阱。

Conclusion: 当前模型尽管在推理得分上表现优异，但在需要对抗主动反对的环境中仍存在根本性不足。对抗性鲁棒性是可信AI自主性的必要条件，CAIA基准为此提供了持续更新的评估框架。

Abstract: We present CAIA, a benchmark exposing a critical blind spot in AI evaluation:
the inability of state-of-the-art models to operate in adversarial, high-stakes
environments where misinformation is weaponized and errors are irreversible.
While existing benchmarks measure task completion in controlled settings,
real-world deployment demands resilience against active deception. Using crypto
markets as a testbed where $30 billion was lost to exploits in 2024, we
evaluate 17 models on 178 time-anchored tasks requiring agents to distinguish
truth from manipulation, navigate fragmented information landscapes, and make
irreversible financial decisions under adversarial pressure.
  Our results reveal a fundamental capability gap: without tools, even frontier
models achieve only 28% accuracy on tasks junior analysts routinely handle.
Tool augmentation improves performance but plateaus at 67.4% versus 80% human
baseline, despite unlimited access to professional resources. Most critically,
we uncover a systematic tool selection catastrophe: models preferentially
choose unreliable web search over authoritative data, falling for SEO-optimized
misinformation and social media manipulation. This behavior persists even when
correct answers are directly accessible through specialized tools, suggesting
foundational limitations rather than knowledge gaps. We also find that Pass@k
metrics mask dangerous trial-and-error behavior for autonomous deployment.
  The implications extend beyond crypto to any domain with active adversaries,
e.g. cybersecurity, content moderation, etc. We release CAIA with contamination
controls and continuous updates, establishing adversarial robustness as a
necessary condition for trustworthy AI autonomy. The benchmark reveals that
current models, despite impressive reasoning scores, remain fundamentally
unprepared for environments where intelligence must survive active opposition.

</details>


### [87] [Hierarchical Reasoning Model: A Critical Supplementary Material](https://arxiv.org/abs/2510.00355)
*Renee Ge,Qianli Liao,Tomaso Poggio*

Main category: cs.AI

TL;DR: 对Transformer在逻辑推理任务中的局限性进行分析，提出基于潜在空间和循环推理的层次推理模型变体，在数独和迷宫任务上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: Transformer在序列自回归任务中表现优异，但在逻辑推理方面存在局限，这可能是由于缺乏对潜在空间和循环推理等创造性应用的探索

Method: 对层次推理模型进行批判性回顾，检查关键设计选择，并提出在Transformer潜在空间中实现循环推理的变体模型

Result: 在Sudoku-Extreme和Maze-Hard任务上取得了比先前报告显著更好的性能

Conclusion: 研究结果提出了令人惊讶的观察和进一步研究的引人入胜方向，表明这类模型仍处于早期阶段，需要深入探索

Abstract: Transformers have demonstrated remarkable performance in natural language
processing and related domains, as they largely focus on sequential,
autoregressive next-token prediction tasks. Yet, they struggle in logical
reasoning, not necessarily because of a fundamental limitation of these models,
but possibly due to the lack of exploration of more creative uses, such as
latent space and recurrent reasoning. An emerging exploration in this direction
is the Hierarchical Reasoning Model (Wang et al., 2025), which introduces a
novel type of recurrent reasoning in the latent space of transformers,
achieving remarkable performance on a wide range of 2D reasoning tasks. Despite
the promising results, this line of models is still at an early stage and calls
for in-depth investigation. In this work, we perform a critical review on this
class of models, examine key design choices and present intriguing variants
that achieve significantly better performance on the Sudoku-Extreme and
Maze-Hard tasks than previously reported. Our results also raise surprising
observations and intriguing directions for further research.

</details>


### [88] [Semantic-Driven AI Agent Communications: Challenges and Solutions](https://arxiv.org/abs/2510.00381)
*Kaiwen Yu,Mengying Sun,Zhijin Qin,Xiaodong Xu,Ping Yang,Yue Xiao,Gang Wu*

Main category: cs.AI

TL;DR: 提出语义驱动的AI智能体通信框架，包含语义自适应传输、语义轻量化传输和语义自进化控制三大技术，以解决动态环境和有限资源下的智能体通信挑战。


<details>
  <summary>Details</summary>
Motivation: 随着智能服务快速发展，通信目标从人类转向AI智能体，需要新范式实现实时感知、决策和协作。语义通信虽具前景，但受限于动态环境和资源约束。

Method: 1) 语义自适应传输：使用真实或生成样本进行微调，使模型适应变化环境；2) 语义轻量化传输：结合剪枝、量化和感知感知采样，降低模型复杂度；3) 语义自进化控制：采用分布式分层决策优化多维资源。

Result: 仿真结果显示，所提方案实现了更快的收敛速度和更强的鲁棒性，分布式分层优化方法显著优于传统决策方案。

Conclusion: 该框架在AI智能体通信网络中具有巨大潜力，能够有效支持动态环境下的多智能体协作。

Abstract: With the rapid growth of intelligent services, communication targets are
shifting from humans to artificial intelligent (AI) agents, which require new
paradigms to enable real-time perception, decision-making, and collaboration.
Semantic communication, which conveys task-relevant meaning rather than raw
data, offers a promising solution. However, its practical deployment remains
constrained by dynamic environments and limited resources. To address these
issues, this article proposes a semantic-driven AI agent communication
framework and develops three enabling techniques. First, semantic adaptation
transmission applies fine-tuning with real or generative samples to efficiently
adapt models to varying environments. Second, semantic lightweight transmission
incorporates pruning, quantization, and perception-aware sampling to reduce
model complexity and alleviate computational burden on edge agents. Third,
semantic self-evolution control employs distributed hierarchical
decision-making to optimize multi-dimensional resources, enabling robust
multi-agent collaboration in dynamic environments. Simulation results show that
the proposed solutions achieve faster convergence and stronger robustness,
while the proposed distributed hierarchical optimization method significantly
outperforms conventional decision-making schemes, highlighting its potential
for AI agent communication networks.

</details>


### [89] [Towards Self-Evolving Benchmarks: Synthesizing Agent Trajectories via Test-Time Exploration under Validate-by-Reproduce Paradigm](https://arxiv.org/abs/2510.00415)
*Dadi Guo,Tianyi Zhou,Dongrui Liu,Chen Qian,Qihan Ren,Shuai Shao,Zhiyuan Fan,Yi R. Fung,Kun Wang,Linfeng Zhang,Jing Shao*

Main category: cs.AI

TL;DR: 提出了TRACE框架，通过让智能体自由探索和演化现有基准任务，自动生成更高难度的新任务并记录可验证的执行轨迹，解决了现有智能体基准测试快速达到性能上限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准测试面临新开发的智能体快速达到性能上限的问题，无法满足评估智能体能力的需求，需要一种能够持续生成挑战性任务的动态评估系统。

Method: TRACE框架包含三个阶段：进化提案挖掘（通过初步探索和发散性思维提供任务进化提案）、问题形成与自由探索（将提案概念化为可行问题候选，记录执行轨迹）、多级验证（确保演化任务具有可验证和可复现的轨迹）。

Result: 在GAIA基准上的实验表明，TRACE框架能够持续提升任务复杂度，同时通过可验证的执行轨迹提高正确性的可靠性。

Conclusion: 这项工作标志着从静态手动策划的基准测试向动态自演化评估系统的范式转变，为智能体发展提供了可持续且具有挑战性的平台。

Abstract: Recent advances in large language models (LLMs) and agent system designs have
empowered agents with unprecedented levels of capability. However, existing
agent benchmarks are showing a trend of rapid ceiling-hitting by newly
developed agents, making it difficult to meet the demands for evaluating agent
abilities. To address this problem, we propose the Trajectory-based
Validated-by-Reproducing Agent-benchmark Complexity Evolution (TRACE)
framework. This framework takes an original task from an existing benchmark and
encourages agents to freely explore and evolve it into a new task with higher
difficulty while recording validatable agent trajectories. The framework
proceeds in three stages: (1) evolutionary proposal mining, which provides task
evolution proposals through preliminary exploration and divergent thinking; (2)
problem formation and free exploration, where proposals are conceptualized into
feasible problem candidates and the agents then explore them freely while
recording their execution trajectories; and (3) multi-level validation, which
ensures that the evolved tasks are accompanied by validatable and reproducible
trajectories. Experiments on the GAIA benchmark demonstrate that the TRACE
framework consistently enhances task complexity while improving the reliability
of correctness through validatable execution trajectories. This work marks a
paradigm shift from static, manually curated benchmarks to dynamic,
self-evolving evaluation systems, providing a sustainable and challenging
runway for agent development.

</details>


### [90] [Automated Evaluation can Distinguish the Good and Bad AI Responses to Patient Questions about Hospitalization](https://arxiv.org/abs/2510.00436)
*Sarvesh Soni,Dina Demner-Fushman*

Main category: cs.AI

TL;DR: 该研究探讨了自动化评估AI系统回答患者住院相关问题的方法，发现精心设计的自动化评估可以替代人工专家评审，实现AI系统的可扩展比较评估。


<details>
  <summary>Details</summary>
Motivation: 当前评估AI回答患者健康问题的黄金标准是人工专家评审，但这种方法劳动密集且缓慢，限制了可扩展性。自动化指标虽然前景广阔，但与人类判断的一致性不一且往往依赖上下文。

Method: 在100个患者案例中，收集了28个AI系统的2800个回答，从三个维度进行评估：是否回答问题、是否适当使用临床记录证据、是否使用一般医学知识。使用临床医生撰写的参考答案作为指标锚点。

Result: 自动化排名与专家评分高度匹配，表明精心设计的自动化评估可以准确反映AI系统的表现。

Conclusion: 研究表明，精心设计的自动化评估可以扩展AI系统的比较评估，支持患者与临床医生的沟通。

Abstract: Automated approaches to answer patient-posed health questions are rising, but
selecting among systems requires reliable evaluation. The current gold standard
for evaluating the free-text artificial intelligence (AI) responses--human
expert review--is labor-intensive and slow, limiting scalability. Automated
metrics are promising yet variably aligned with human judgments and often
context-dependent. To address the feasibility of automating the evaluation of
AI responses to hospitalization-related questions posed by patients, we
conducted a large systematic study of evaluation approaches. Across 100 patient
cases, we collected responses from 28 AI systems (2800 total) and assessed them
along three dimensions: whether a system response (1) answers the question, (2)
appropriately uses clinical note evidence, and (3) uses general medical
knowledge. Using clinician-authored reference answers to anchor metrics,
automated rankings closely matched expert ratings. Our findings suggest that
carefully designed automated evaluation can scale comparative assessment of AI
systems and support patient-clinician communication.

</details>


### [91] [Expandable Decision-Making States for Multi-Agent Deep Reinforcement Learning in Soccer Tactical Analysis](https://arxiv.org/abs/2510.00480)
*Kenjiro Ide,Taiga Someya,Kohei Kawaguchi,Keisuke Fujii*

Main category: cs.AI

TL;DR: 提出EDMS方法，通过语义增强的状态表示和动作掩码机制，在足球等团队运动中构建可解释的球员级智能体模型，实现战术分析和跨数据源的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统规则分析直观但有限，现代机器学习模型缺乏明确智能体表示。需要构建既能战术解释又能在异构数据源中鲁棒的球员级智能体模型。

Method: 使用Expandable Decision-Making States (EDMS)语义增强状态表示，结合动作掩码方案，为持球和无球球员提供不同的决策集，将学习到的价值函数和动作策略映射到人类可解释的战术概念。

Result: EDMS与动作掩码相比基线持续降低了动作预测损失和时序差分误差，定性案例研究和Q值可视化显示EDMS能突出高风险高回报的战术模式。

Conclusion: EDMS方法成功构建了可解释的球员级智能体模型，实现了战术概念的映射和跨数据源的兼容性，为定量战术分析提供了有效工具。

Abstract: Invasion team sports such as soccer produce a high-dimensional, strongly
coupled state space as many players continuously interact on a shared field,
challenging quantitative tactical analysis. Traditional rule-based analyses are
intuitive, while modern predictive machine learning models often perform
pattern-matching without explicit agent representations. The problem we address
is how to build player-level agent models from data, whose learned values and
policies are both tactically interpretable and robust across heterogeneous data
sources. Here, we propose Expandable Decision-Making States (EDMS), a
semantically enriched state representation that augments raw positions and
velocities with relational variables (e.g., scoring of space, pass, and score),
combined with an action-masking scheme that gives on-ball and off-ball agents
distinct decision sets. Compared to prior work, EDMS maps learned value
functions and action policies to human-interpretable tactical concepts (e.g.,
marking pressure, passing lanes, ball accessibility) instead of raw coordinate
features, and aligns agent choices with the rules of play. In the experiments,
EDMS with action masking consistently reduced both action-prediction loss and
temporal-difference (TD) error compared to the baseline. Qualitative case
studies and Q-value visualizations further indicate that EDMS highlights
high-risk, high-reward tactical patterns (e.g., fast counterattacks and
defensive breakthroughs). We also integrated our approach into an open-source
library and demonstrated compatibility with multiple commercial and open
datasets, enabling cross-provider evaluation and reproducible experiments.

</details>


### [92] [Rethinking Reward Models for Multi-Domain Test-Time Scaling](https://arxiv.org/abs/2510.00492)
*Dong Bok Lee,Seanie Lee,Sangwoo Park,Minki Kang,Jinheon Baek,Dongki Kim,Dominik Wagner,Jiongdao Jin,Heejun Lee,Tobias Bocklet,Jinyu Wang,Jingjing Fu,Sung Ju Hwang,Jiang Bia,Lei Song*

Main category: cs.AI

TL;DR: 本文挑战了传统观点，发现在14个多样化领域中，生成式结果奖励模型(GenORM)表现最稳健，而非传统认为的逐步奖励模型(PRM)更优。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为逐步奖励模型(PRM)优于结果奖励模型(ORM)，但这种观点主要基于数学相关领域的证据。本文旨在在多样化领域中统一评估不同奖励模型的性能。

Method: 在14个多样化领域中统一评估四种奖励模型变体：判别式ORM和PRM(DisORM, DisPRM)以及生成式ORM和PRM(GenORM, GenPRM)。

Result: 发现：(i) DisORM与DisPRM表现相当；(ii) GenPRM不具竞争力；(iii) GenORM是最稳健的模型，在所有测试领域都取得显著且一致的增益。

Conclusion: 逐步评分会继承LLM自动标注的标签噪声，难以评估长推理轨迹，包括涉及自我修正的推理。理论分析显示逐步聚合会随着推理长度增长而放大错误。这些发现挑战了细粒度监督总是更好的普遍假设。

Abstract: The reliability of large language models (LLMs) during test-time scaling is
often assessed with \emph{external verifiers} or \emph{reward models} that
distinguish correct reasoning from flawed logic. Prior work generally assumes
that process reward models (PRMs), which score every intermediate reasoning
step, outperform outcome reward models (ORMs) that assess only the final
answer. This view is based mainly on evidence from narrow, math-adjacent
domains. We present the first unified evaluation of four reward model variants,
discriminative ORM and PRM (\DisORM, \DisPRM) and generative ORM and PRM
(\GenORM, \GenPRM), across 14 diverse domains. Contrary to conventional wisdom,
we find that (i) \DisORM performs on par with \DisPRM, (ii) \GenPRM is not
competitive, and (iii) overall, \GenORM is the most robust, yielding
significant and consistent gains across every tested domain. We attribute this
to PRM-style stepwise scoring, which inherits label noise from LLM
auto-labeling and has difficulty evaluating long reasoning trajectories,
including those involving self-correcting reasoning. Our theoretical analysis
shows that step-wise aggregation compounds errors as reasoning length grows,
and our empirical observations confirm this effect. These findings challenge
the prevailing assumption that fine-grained supervision is always better and
support generative outcome verification for multi-domain deployment. We
publicly release our code, datasets, and checkpoints at
\href{https://github.com/db-Lee/Multi-RM}{\underline{\small\texttt{https://github.com/db-Lee/Multi-RM}}}
to facilitate future research in multi-domain settings.

</details>


### [93] [VIRTUE: Visual-Interactive Text-Image Universal Embedder](https://arxiv.org/abs/2510.00523)
*Wei-Yao Wang,Kazuya Tateishi,Qiyu Wu,Shusuke Takahashi,Yuki Mitsufuji*

Main category: cs.AI

TL;DR: 提出了VIRTUE模型，将分割模型和视觉语言模型的能力扩展到表示学习领域，支持视觉交互式提示来指定图像中的感兴趣区域，在36个通用MMEB任务和5个视觉交互SCaR任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入模型缺乏视觉交互能力来指定用户感兴趣区域，而生成模型已探索此类能力。为嵌入模型添加视觉交互不仅能解锁用户意图本地化应用，还能让模型学习图像中的实体级信息以补充全局表示。

Method: 提出VIRTUE模型，将分割模型处理视觉提示的能力与视觉语言模型结合，使嵌入器能处理复杂和模糊场景。分割模型可处理指向图像特定区域的视觉提示。

Result: 在包含100万样本的大规模SCaR基准测试中，VIRTUE在36个通用MMEB任务上提升3.1%-8.5%，在5个视觉交互SCaR任务上提升15.2%-20.3%，均达到最先进性能。

Conclusion: VIRTUE成功将分割模型和视觉语言模型的能力扩展到表示学习领域，通过视觉交互显著提升了嵌入模型的性能和应用范围。

Abstract: Multimodal representation learning models have demonstrated successful
operation across complex tasks, and the integration of vision-language models
(VLMs) has further enabled embedding models with instruction-following
capabilities. However, existing embedding models lack visual-interactive
capabilities to specify regions of interest from users (e.g., point, bounding
box, mask), which have been explored in generative models to broaden their
human-interactive applicability. Equipping embedding models with visual
interactions not only would unlock new applications with localized grounding of
user intent, which remains unexplored, but also enable the models to learn
entity-level information within images to complement their global
representations for conventional embedding tasks. In this paper, we propose a
novel Visual-InteRactive Text-Image Universal Embedder (VIRTUE) that extends
the capabilities of the segmentation model and the vision-language model to the
realm of representation learning. In VIRTUE, the segmentation model can process
visual prompts that pinpoint specific regions within an image, thereby enabling
the embedder to handle complex and ambiguous scenarios more precisely. To
evaluate the visual-interaction ability of VIRTUE, we introduce a large-scale
Segmentation-and-Scene Caption Retrieval (SCaR) benchmark comprising 1M samples
that aims to retrieve the text caption by jointly considering the entity with a
specific object and image scene. VIRTUE consistently achieves a
state-of-the-art performance with significant improvements across 36 universal
MMEB (3.1%-8.5%) and five visual-interactive SCaR (15.2%-20.3%) tasks.

</details>


### [94] [Data Quality Challenges in Retrieval-Augmented Generation](https://arxiv.org/abs/2510.00552)
*Leopold Müller,Joshua Holstein,Sarah Bause,Gerhard Satzger,Niklas Kühl*

Main category: cs.AI

TL;DR: 本研究开发了针对RAG系统的数据质量维度，通过访谈IT服务公司从业者，识别出15个跨四个处理阶段的DQ维度，揭示了传统DQ框架需要扩展以适应RAG系统的动态特性。


<details>
  <summary>Details</summary>
Motivation: 当前数据质量框架主要针对静态数据集，无法充分应对RAG系统的动态多阶段特性，需要开发专门针对这类AI系统的DQ维度。

Method: 对16家领先IT服务公司的从业者进行半结构化访谈，通过定性内容分析归纳推导出RAG系统的DQ维度。

Result: 识别出15个不同的DQ维度，分布在RAG系统的四个处理阶段：数据提取、数据转换、提示与搜索、生成。发现新维度主要集中在早期阶段，DQ问题会在管道中转化和传播。

Conclusion: 传统DQ框架需要添加新维度以覆盖RAG环境，需要采用前置式质量管理策略和动态的、阶段感知的质量管理方法。

Abstract: Organizations increasingly adopt Retrieval-Augmented Generation (RAG) to
enhance Large Language Models with enterprise-specific knowledge. However,
current data quality (DQ) frameworks have been primarily developed for static
datasets, and only inadequately address the dynamic, multi-stage nature of RAG
systems. This study aims to develop DQ dimensions for this new type of AI-based
systems. We conduct 16 semi-structured interviews with practitioners of leading
IT service companies. Through a qualitative content analysis, we inductively
derive 15 distinct DQ dimensions across the four processing stages of RAG
systems: data extraction, data transformation, prompt & search, and generation.
Our findings reveal that (1) new dimensions have to be added to traditional DQ
frameworks to also cover RAG contexts; (2) these new dimensions are
concentrated in early RAG steps, suggesting the need for front-loaded quality
management strategies, and (3) DQ issues transform and propagate through the
RAG pipeline, necessitating a dynamic, step-aware approach to quality
management.

</details>


### [95] [A Neuro-Fuzzy System for Interpretable Long-Term Stock Market Forecasting](https://arxiv.org/abs/2510.00960)
*Miha Ožbot,Igor Škrjanc,Vitomir Štruc*

Main category: cs.AI

TL;DR: 提出Fuzzformer模型，结合循环神经网络、多头自注意力和模糊推理系统，用于多变量股票市场数据分析和长期时间序列预测，在保持预测准确性的同时提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 在多变量时间序列预测中，同时实现准确性和可解释性是一个重大挑战。

Method: 使用LSTM网络和时间注意力将多变量数据压缩为适合模糊推理系统的可解释特征，结合多头自注意力和模糊推理系统构建Fuzzformer架构。

Result: 在S&P500股票市场指数上的初步结果显示，该模型与传统模型（如ARIMA和LSTM）具有相当的预测性能，同时提供网络内部有意义的信息流。

Conclusion: 该方法在可解释预测方面显示出潜力，虽然存在性能权衡，但在理解和预测股票市场行为方面具有实际应用价值。

Abstract: In the complex landscape of multivariate time series forecasting, achieving
both accuracy and interpretability remains a significant challenge. This paper
introduces the Fuzzy Transformer (Fuzzformer), a novel recurrent neural network
architecture combined with multi-head self-attention and fuzzy inference
systems to analyze multivariate stock market data and conduct long-term time
series forecasting. The method leverages LSTM networks and temporal attention
to condense multivariate data into interpretable features suitable for fuzzy
inference systems. The resulting architecture offers comparable forecasting
performance to conventional models such as ARIMA and LSTM while providing
meaningful information flow within the network. The method was examined on the
real world stock market index S\&P500. Initial results show potential for
interpretable forecasting and identify current performance tradeoffs,
suggesting practical application in understanding and forecasting stock market
behavior.

</details>


### [96] [Toward Safer Diffusion Language Models: Discovery and Mitigation of Priming Vulnerability](https://arxiv.org/abs/2510.00565)
*Shojiro Yamabe,Jun Sakuma*

Main category: cs.AI

TL;DR: 扩散语言模型(DLMs)存在安全漏洞，攻击者可通过在中间步骤注入肯定性令牌来绕过安全防护，本文提出了一种针对DLMs的安全对齐方法来缓解此漏洞。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型通过并行迭代去噪生成令牌，这种推理机制可能带来新的安全风险，特别是越狱攻击利用这种机制的安全漏洞尚未被充分理解。

Method: 研究发现如果有害查询的肯定性令牌出现在中间步骤，后续去噪过程可能被引导生成有害响应。基于此分析，提出了一种针对DLMs的安全对齐方法，训练模型从包含肯定性令牌的污染中间状态生成安全响应。

Result: 实验表明该方法显著缓解了漏洞，对任务性能影响最小，同时提高了对传统越狱攻击的鲁棒性。

Conclusion: 扩散语言模型存在特定的安全漏洞，需要针对性的安全研究，提出的安全对齐方法有效提升了DLMs的安全性。

Abstract: Diffusion language models (DLMs) generate tokens in parallel through
iterative denoising, which can reduce latency and enable bidirectional
conditioning. However, the safety risks posed by jailbreak attacks that exploit
this inference mechanism are not well understood. In this paper, we reveal that
DLMs have a critical vulnerability stemming from their iterative denoising
process and propose a countermeasure. Specifically, our investigation shows
that if an affirmative token for a harmful query appears at an intermediate
step, subsequent denoising can be steered toward a harmful response even in
aligned models. As a result, simply injecting such affirmative tokens can
readily bypass the safety guardrails. Furthermore, we demonstrate that the
vulnerability allows existing optimization-based jailbreak attacks to succeed
on DLMs. Building on this analysis, we propose a novel safety alignment method
tailored to DLMs that trains models to generate safe responses from
contaminated intermediate states that contain affirmative tokens. Our
experiments indicate that the proposed method significantly mitigates the
vulnerability with minimal impact on task performance. Furthermore, our method
improves robustness against conventional jailbreak attacks. Our work
underscores the need for DLM-specific safety research.

</details>


### [97] [ACON: Optimizing Context Compression for Long-horizon LLM Agents](https://arxiv.org/abs/2510.00615)
*Minki Kang,Wei-Ning Chen,Dongge Han,Huseyin A. Inan,Lukas Wutschitz,Yanzhi Chen,Robert Sim,Saravan Rajmohan*

Main category: cs.AI

TL;DR: ACON是一个统一的框架，通过优化自然语言压缩指南来压缩环境观察和交互历史，减少26-54%的内存使用，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在动态环境中作为代理部署，长上下文带来了成本和效率问题，而现有的上下文压缩方法主要关注单步任务或狭窄应用。

Method: ACON利用压缩指南优化：当完整上下文成功但压缩上下文失败时，LLM分析失败原因并相应更新压缩指南，然后将优化的LLM压缩器蒸馏到更小的模型中。

Result: 在AppWorld、OfficeBench和Multi-objective QA上的实验显示，ACON减少26-54%的内存使用（峰值token），同时基本保持任务性能，蒸馏到更小压缩器时保持95%以上准确率，并将较小LM作为长视野代理的性能提升达46%。

Conclusion: ACON有效解决了代理任务中的长上下文问题，通过优化的压缩框架在减少内存使用的同时保持性能，并能蒸馏到更小的模型中。

Abstract: Large language models (LLMs) are increasingly deployed as agents in dynamic,
real-world environments, where success requires both reasoning and effective
tool use. A central challenge for agentic tasks is the growing context length,
as agents must accumulate long histories of actions and observations. This
expansion raises costs and reduces efficiency in long-horizon tasks, yet prior
work on context compression has mostly focused on single-step tasks or narrow
applications. We introduce Agent Context Optimization (ACON), a unified
framework that optimally compresses both environment observations and
interaction histories into concise yet informative condensations. ACON
leverages compression guideline optimization in natural language space: given
paired trajectories where full context succeeds but compressed context fails,
capable LLMs analyze the causes of failure, and the compression guideline is
updated accordingly. Furthermore, we propose distilling the optimized LLM
compressor into smaller models to reduce the overhead of the additional module.
Experiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON
reduces memory usage by 26-54% (peak tokens) while largely preserving task
performance, preserves over 95% of accuracy when distilled into smaller
compressors, and enhances smaller LMs as long-horizon agents with up to 46%
performance improvement.

</details>


### [98] [HARPA: A Testability-Driven, Literature-Grounded Framework for Research Ideation](https://arxiv.org/abs/2510.00620)
*Rosni Vasu,Peter Jansen,Pao Siangliulue,Cristina Sarasua,Abraham Bernstein,Peter Clark,Bhavana Dalvi Mishra*

Main category: cs.AI

TL;DR: HARPA是一个AI驱动的科学发现系统，通过文献挖掘识别研究趋势，探索假设设计空间，并基于实验反馈学习奖励模型，生成可测试且基于文献的研究假设。


<details>
  <summary>Details</summary>
Motivation: 解决现有自动化科学发现工具难以生成既可测试又基于文献的假设，且无法适应先前实验结果的问题。

Method: 采用人类研究者的构思流程：文献挖掘识别新兴趋势→探索假设设计空间→通过定位研究差距和论证设计选择来收敛到精确可测试的假设，并学习基于先前实验结果的奖励模型。

Result: HARPA生成的研究提案在可行性(+0.78)和文献基础性(+0.85)上显著优于基线；与ASD代理测试时成功率更高(20 vs 11/40)，失败更少(16 vs 21/40)；奖励模型比未训练基线提升约28%。

Conclusion: HARPA代表了AI驱动科学发现领域的重要进展，能够生成更可行、更基于文献的研究假设，并能从实验反馈中学习改进。

Abstract: While there has been a surge of interest in automated scientific discovery
(ASD), especially with the emergence of LLMs, it remains challenging for tools
to generate hypotheses that are both testable and grounded in the scientific
literature. Additionally, existing ideation tools are not adaptive to prior
experimental outcomes. We developed HARPA to address these challenges by
incorporating the ideation workflow inspired by human researchers. HARPA first
identifies emerging research trends through literature mining, then explores
hypothesis design spaces, and finally converges on precise, testable hypotheses
by pinpointing research gaps and justifying design choices. Our evaluations
show that HARPA-generated hypothesis-driven research proposals perform
comparably to a strong baseline AI-researcher across most qualitative
dimensions (e.g., specificity, novelty, overall quality), but achieve
significant gains in feasibility(+0.78, p$<0.05$, bootstrap) and groundedness
(+0.85, p$<0.01$, bootstrap) on a 10-point Likert scale. When tested with the
ASD agent (CodeScientist), HARPA produced more successful executions (20 vs. 11
out of 40) and fewer failures (16 vs. 21 out of 40), showing that expert
feasibility judgments track with actual execution success. Furthermore, to
simulate how researchers continuously refine their understanding of what
hypotheses are both testable and potentially interesting from experience, HARPA
learns a reward model that scores new hypotheses based on prior experimental
outcomes, achieving approx. a 28\% absolute gain over HARPA's untrained
baseline scorer. Together, these methods represent a step forward in the field
of AI-driven scientific discovery.

</details>


### [99] [Is Model Editing Built on Sand? Revealing Its Illusory Success and Fragile Foundation](https://arxiv.org/abs/2510.00625)
*Wei Liu,Haomei Xu,Bingqing Liu,Zhiying Deng,Haozhao Wang,Jun Wang,Ruixuan Li,Yee Whye Teh,Wee Sun Lee*

Main category: cs.AI

TL;DR: 该论文揭示了当前模型编辑方法存在严重缺陷，其表面上的成功实际上是基于脆弱的捷径而非真实的语义理解，在否定查询等简单测试下就会崩溃。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型不可避免地编码过时或错误知识，更新、删除和遗忘这些知识对于对齐、安全等问题很重要。模型编辑被提出作为解决这一问题的有前景范式，但作者发现现有的编辑方法存在根本性问题。

Method: 作者系统性地开发了一套新的评估方法，特别设计了包含否定查询的负例测试，来揭示模型编辑方法是否真正基于语义理解而非利用隐藏的捷径。

Result: 研究发现，即使是最先进的模型编辑方法在简单的否定查询下也会崩溃，表明编辑很可能基于捷径而非完整的语义理解。

Conclusion: 模型编辑方法目前建立在脆弱的基础上，其成功可能是虚幻的，需要在进一步推进之前重新考虑其根本基础。

Abstract: Large language models (LLMs) inevitably encode outdated or incorrect
knowledge. Updating, deleting, and forgetting such knowledge is important for
alignment, safety, and other issues. To address this issue, model editing has
emerged as a promising paradigm: by precisely editing a small subset of
parameters such that a specific fact is updated while preserving other
knowledge. Despite its great success reported in previous papers, we find the
apparent reliability of editing rests on a fragile foundation and the current
literature is largely driven by illusory success. The fundamental goal of
steering the model's output toward a target with minimal modification would
encourage exploiting hidden shortcuts, rather than utilizing real semantics.
This problem directly challenges the feasibility of the current model editing
literature at its very foundation, as shortcuts are inherently at odds with
robust knowledge integration. Coincidentally, this issue has long been obscured
by evaluation frameworks that lack the design of negative examples. To uncover
it, we systematically develop a suite of new evaluation methods. Strikingly, we
find that state-of-the-art approaches collapse even under the simplest negation
queries. Our empirical evidence shows that editing is likely to be based on
shortcuts rather than full semantics, calling for an urgent reconsideration of
the very basis of model editing before further advancements can be meaningfully
pursued.

</details>


### [100] [Collaborative-Distilled Diffusion Models (CDDM) for Accelerated and Lightweight Trajectory Prediction](https://arxiv.org/abs/2510.00627)
*Bingzhang Wang,Kehua Chen,Yinhai Wang*

Main category: cs.AI

TL;DR: 提出CDDM方法，通过协作渐进蒸馏技术将大型扩散模型压缩为轻量级模型，在保持高性能的同时实现161倍压缩和31倍加速，适用于自动驾驶和智能交通系统的实时轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在概率轨迹预测中表现出色，但模型规模大、采样速度慢，难以在实际应用中部署。需要开发轻量高效的实时预测方法。

Method: 基于协作渐进蒸馏(CPD)，逐步将知识从大型教师扩散模型转移到轻量学生模型，同时减少采样步骤和模型规模。引入双信号正则化蒸馏损失，结合教师和真实数据的指导。

Result: 在ETH-UCY行人基准和nuScenes车辆基准上达到SOTA精度。压缩后模型仅需231K参数和2-4个采样步骤，保持96.2% ADE和95.5% FDE性能，延迟仅9ms。

Conclusion: CDDM成功将高性能生成模型与实际部署约束相结合，为自动驾驶和智能交通系统提供了资源高效的实时概率预测解决方案。

Abstract: Trajectory prediction is a fundamental task in Autonomous Vehicles (AVs) and
Intelligent Transportation Systems (ITS), supporting efficient motion planning
and real-time traffic safety management. Diffusion models have recently
demonstrated strong performance in probabilistic trajectory prediction, but
their large model size and slow sampling process hinder real-world deployment.
This paper proposes Collaborative-Distilled Diffusion Models (CDDM), a novel
method for real-time and lightweight trajectory prediction. Built upon
Collaborative Progressive Distillation (CPD), CDDM progressively transfers
knowledge from a high-capacity teacher diffusion model to a lightweight student
model, jointly reducing both the number of sampling steps and the model size
across distillation iterations. A dual-signal regularized distillation loss is
further introduced to incorporate guidance from both the teacher and
ground-truth data, mitigating potential overfitting and ensuring robust
performance. Extensive experiments on the ETH-UCY pedestrian benchmark and the
nuScenes vehicle benchmark demonstrate that CDDM achieves state-of-the-art
prediction accuracy. The well-distilled CDDM retains 96.2% and 95.5% of the
baseline model's ADE and FDE performance on pedestrian trajectories, while
requiring only 231K parameters and 4 or 2 sampling steps, corresponding to 161x
compression, 31x acceleration, and 9 ms latency. Qualitative results further
show that CDDM generates diverse and accurate trajectories under dynamic agent
behaviors and complex social interactions. By bridging high-performing
generative models with practical deployment constraints, CDDM enables
resource-efficient probabilistic prediction for AVs and ITS. Code is available
at https://github.com/bingzhangw/CDDM.

</details>


### [101] [Expected Attention: KV Cache Compression by Estimating Attention from Future Queries Distribution](https://arxiv.org/abs/2510.00636)
*Alessio Devoto,Maximilian Jeblick,Simon Jégou*

Main category: cs.AI

TL;DR: 提出了一种名为Expected Attention的训练无关KV缓存压缩方法，通过预测未来查询如何关注KV对来估计其重要性，解决了注意力分数不可用的问题。


<details>
  <summary>Details</summary>
Motivation: KV缓存的内存消耗是大型语言模型推理效率的主要瓶颈，而基于注意力分数的KV缓存剪枝方法面临实际限制：未来token的注意力分数在压缩时不可用，且现代实现如Flash Attention不生成完整注意力矩阵。

Method: 利用LLM激活的分布特性，以闭式形式计算每个KV对的期望注意力分数，基于这些分数进行原则性排序和剪枝，最小化对残差流的影响。

Result: 该方法在预填充和解码阶段都能无缝运行，在两个场景中都持续优于最先进的基线方法。

Conclusion: 开发了KVPress库，包含20多种技术，为研究人员实现和基准测试KV缓存压缩方法提供了全面支持。

Abstract: Memory consumption of the Key-Value (KV) cache represents a major bottleneck
for efficient large language model inference. While attention-score-based KV
cache pruning shows promise, it faces critical practical limitations: attention
scores from future tokens are unavailable during compression, and modern
implementations like Flash Attention do not materialize the full attention
matrix, making past scores inaccessible. To overcome these challenges, we
introduce $\textbf{Expected Attention, a training-free compression method}$
that estimates KV pairs importance by predicting how future queries will attend
to them. Our approach leverages the distributional properties of LLM
activations to compute expected attention scores in closed form for each KV
pair. These scores enable principled ranking and pruning of KV pairs with
minimal impact on the residual stream, achieving effective compression without
performance degradation. Importantly, our method operates seamlessly across
both prefilling and decoding phases, consistently outperforming
state-of-the-art baselines in both scenarios. Finally, $\textbf{we release
KVPress, a comprehensive library to enable researchers to implement and
benchmark KV cache compression methods, already including more than 20
techniques}$.

</details>


### [102] [Batch-CAM: Introduction to better reasoning in convolutional deep learning models](https://arxiv.org/abs/2510.00664)
*Giacomo Ignesti,Davide Moroni,Massimo Martinelli*

Main category: cs.AI

TL;DR: 提出Batch-CAM训练范式，融合批处理Grad-CAM算法和原型重建损失，提升模型在分类任务中的性能，同时改善准确性和图像重建质量。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险领域，深度学习模型的可解释性至关重要，准确解释与精确度同等重要。

Method: 结合批处理Grad-CAM算法和原型重建损失，引导模型关注显著图像特征。

Result: Batch-CAM在准确性和图像重建质量上同时提升，同时减少了训练和推理时间。

Conclusion: 该方法通过确保模型学习证据相关信息，为构建更透明、可解释和可信赖的AI系统做出贡献。

Abstract: Understanding the inner workings of deep learning models is crucial for
advancing artificial intelligence, particularly in high-stakes fields such as
healthcare, where accurate explanations are as vital as precision. This paper
introduces Batch-CAM, a novel training paradigm that fuses a batch
implementation of the Grad-CAM algorithm with a prototypical reconstruction
loss. This combination guides the model to focus on salient image features,
thereby enhancing its performance across classification tasks. Our results
demonstrate that Batch-CAM achieves a simultaneous improvement in accuracy and
image reconstruction quality while reducing training and inference times. By
ensuring models learn from evidence-relevant information,this approach makes a
relevant contribution to building more transparent, explainable, and
trustworthy AI systems.

</details>


### [103] [Relevance-Zone Reduction in Game Solving](https://arxiv.org/abs/2510.00689)
*Chi-Huang Lin,Ting Han Wei,Chun-Jui Wang,Hung Guei,Chung-Chin Shih,Yun-Jui Tsai,I-Chen Wu,Ti-Rong Wu*

Main category: cs.AI

TL;DR: 提出了一种迭代式RZ缩减方法，通过逐步限制搜索区域来减小相关性区域的大小，从而提高策略重用效率和剪枝效果。


<details>
  <summary>Details</summary>
Motivation: 由于游戏树的指数级增长，许多游戏尚未解决。相关性区域(RZ)技术虽然能减少搜索空间，但不同解决方案会产生不同大小的RZ，较小的RZ更有利于重用和剪枝效率。

Method: 设计迭代RZ缩减方法，重复求解相同位置并逐步限制参与区域；提出三种约束生成策略，并集成RZ模式表以充分利用过往解决方案。

Result: 在7x7 Killall-Go实验中，平均RZ大小减少到原始的85.95%。

Conclusion: 缩减后的RZ可以作为可重用知识永久存储，用于未来更大的棋盘或不同开局情况的求解任务。

Abstract: Game solving aims to find the optimal strategies for all players and
determine the theoretical outcome of a game. However, due to the exponential
growth of game trees, many games remain unsolved, even though methods like
AlphaZero have demonstrated super-human level in game playing. The
Relevance-Zone (RZ) is a local strategy reuse technique that restricts the
search to only the regions relevant to the outcome, significantly reducing the
search space. However, RZs are not unique. Different solutions may result in
RZs of varying sizes. Smaller RZs are generally more favorable, as they
increase the chance of reuse and improve pruning efficiency. To this end, we
propose an iterative RZ reduction method that repeatedly solves the same
position while gradually restricting the region involved, guiding the solver
toward smaller RZs. We design three constraint generation strategies and
integrate an RZ Pattern Table to fully leverage past solutions. In experiments
on 7x7 Killall-Go, our method reduces the average RZ size to 85.95% of the
original. Furthermore, the reduced RZs can be permanently stored as reusable
knowledge for future solving tasks, especially for larger board sizes or
different openings.

</details>


### [104] [ACPO: Adaptive Curriculum Policy Optimization for Aligning Vision-Language Models in Complex Reasoning](https://arxiv.org/abs/2510.00690)
*Yunhao Wang,Ziting Li,Shuai Chen,Tao Liu,Chao Song,Junjie Jiang,Jian Zhu,Peng Gao,Bin Qin*

Main category: cs.AI

TL;DR: 提出了自适应课程策略优化（ACPO）框架，通过动态课程和自适应裁剪机制改进视觉语言模型的强化学习对齐，在多项多模态推理基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有策略优化算法（如PPO）在训练大规模视觉语言模型进行复杂推理时存在局限性，包括静态训练计划和刚性裁剪机制，阻碍了模型的有效对齐。

Method: ACPO采用双组件自适应学习策略：1）动态课程，从稳定的近策略探索阶段逐步过渡到高效的离策略利用阶段；2）优势感知自适应裁剪（AAAC），用动态样本级边界替代固定裁剪超参数。

Result: 在MathVista、LogicVista和MMMU-Pro等挑战性多模态推理基准上的实验表明，ACPO持续优于DAPO和PAPO等强基线，实现了最先进性能、加速收敛和优越的训练稳定性。

Conclusion: ACPO通过自适应课程和裁剪机制有效解决了现有策略优化算法的局限性，为大规模视觉语言模型的复杂推理对齐提供了更高效和稳定的训练框架。

Abstract: Aligning large-scale vision-language models (VLMs) for complex reasoning via
reinforcement learning is often hampered by the limitations of existing policy
optimization algorithms, such as static training schedules and the rigid,
uniform clipping mechanism in Proximal Policy Optimization (PPO). In this work,
we introduce Adaptive Curriculum Policy Optimization (ACPO), a novel framework
that addresses these challenges through a dual-component adaptive learning
strategy. First, ACPO employs a dynamic curriculum that orchestrates a
principled transition from a stable, near on-policy exploration phase to an
efficient, off-policy exploitation phase by progressively increasing sample
reuse. Second, we propose an Advantage-Aware Adaptive Clipping (AAAC) mechanism
that replaces the fixed clipping hyperparameter with dynamic, sample-wise
bounds modulated by the normalized advantage of each token. This allows for
more granular and robust policy updates, enabling larger gradients for
high-potential samples while safeguarding against destructive ones. We conduct
extensive experiments on a suite of challenging multimodal reasoning
benchmarks, including MathVista, LogicVista, and MMMU-Pro. Results demonstrate
that ACPO consistently outperforms strong baselines such as DAPO and PAPO,
achieving state-of-the-art performance, accelerated convergence, and superior
training stability.

</details>


### [105] [AttentionDep: Domain-Aware Attention for Explainable Depression Severity Assessment](https://arxiv.org/abs/2510.00706)
*Yusif Ibrahimov,Tarique Anwar,Tommy Yuan,Turan Mutallimov,Elgun Hasanov*

Main category: cs.AI

TL;DR: 提出AttentionDep模型，通过融合上下文和领域知识进行可解释的抑郁症严重程度检测，在社交媒体数据上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用社交媒体平台作为了解个体心理状态的窗口，开发可信赖且透明的AI系统用于心理健康评估。

Method: 使用层次化编码（unigrams和bigrams）和注意力机制，结合心理健康知识图谱的领域知识，采用有序回归框架预测抑郁症严重程度。

Result: 在多个数据集上比现有最优方法提升超过5%的等级F1分数，同时提供可解释的预测洞察。

Conclusion: 该工作推动了基于社交媒体的心理健康评估中可信赖和透明AI系统的发展。

Abstract: In today's interconnected society, social media platforms provide a window
into individuals' thoughts, emotions, and mental states. This paper explores
the use of platforms like Facebook, X (formerly Twitter), and Reddit for
depression severity detection. We propose AttentionDep, a domain-aware
attention model that drives explainable depression severity estimation by
fusing contextual and domain knowledge. Posts are encoded hierarchically using
unigrams and bigrams, with attention mechanisms highlighting clinically
relevant tokens. Domain knowledge from a curated mental health knowledge graph
is incorporated through a cross-attention mechanism, enriching the contextual
features. Finally, depression severity is predicted using an ordinal regression
framework that respects the clinical-relevance and natural ordering of severity
levels. Our experiments demonstrate that AttentionDep outperforms
state-of-the-art baselines by over 5% in graded F1 score across datasets, while
providing interpretable insights into its predictions. This work advances the
development of trustworthy and transparent AI systems for mental health
assessment from social media.

</details>


### [106] [EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty](https://arxiv.org/abs/2510.00732)
*Yuchen Tian,Ruiyuan Huang,Xuanwu Wang,Jing Ma,Zengfeng Huang,Ziyang Luo,Hongzhan Lin,Da Zheng,Lun Du*

Main category: cs.AI

TL;DR: 提出了一种新颖的数据增强流水线，通过对称性和难度两个角度提升定理证明模型的鲁棒性，并训练出在多个基准测试中达到最先进水平的非推理定理证明器EvolProver。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在形式定理证明中表现出潜力，但普遍性不足且对问题表述的微小变换很脆弱，需要提升模型的鲁棒性。

Method: 提出三阶段数据增强方法：EvolAST（基于抽象语法树的句法对称性增强）、EvolDomain（跨数学领域的语义对称性增强）和EvolDifficulty（难度演化增强），然后使用增强数据训练7B参数的EvolProver模型。

Result: EvolProver在FormalMATH-Lite上达到53.8% pass@32的新SOTA，在MiniF2F-Test（69.8%）、Ineq-Comp-Seed（52.2%）和Ineq-Comp-Transformed（34.0%）上均为非推理模型的最佳表现，超越了同规模推理模型。

Conclusion: 提出的数据增强流水线能有效提升定理证明模型的鲁棒性和性能，消融研究证实了该方法在多个基准测试中的有效性。

Abstract: Large Language Models (LLMs) for formal theorem proving have shown
significant promise, yet they often lack generalizability and are fragile to
even minor transformations of problem statements. To address this limitation,
we introduce a novel data augmentation pipeline designed to enhance model
robustness from two perspectives: symmetry and difficulty. From the symmetry
perspective, we propose two complementary methods: EvolAST, an Abstract Syntax
Tree (AST) based approach that targets syntactic symmetry to generate
semantically equivalent problem variants, and EvolDomain, which leverages LLMs
to address semantic symmetry by translating theorems across mathematical
domains. From the difficulty perspective, we propose EvolDifficulty, which uses
carefully designed evolutionary instructions to guide LLMs in generating new
theorems with a wider range of difficulty. We then use the evolved data to
train EvolProver, a 7B-parameter non-reasoning theorem prover. EvolProver
establishes a new state-of-the-art (SOTA) on FormalMATH-Lite with a 53.8%
pass@32 rate, surpassing all models of comparable size, including
reasoning-based models. It also sets new SOTA records for non-reasoning models
on MiniF2F-Test (69.8% pass@32), Ineq-Comp-Seed (52.2% pass@32), and
Ineq-Comp-Transformed (34.0% pass@32). Ablation studies further confirm our
data augmentation pipeline's effectiveness across multiple benchmarks.

</details>


### [107] [DIA: The Adversarial Exposure of Deterministic Inversion in Diffusion Models](https://arxiv.org/abs/2510.00778)
*Seunghoo Hong,Geonho Son,Juhun Lee,Simon S. Woo*

Main category: cs.AI

TL;DR: 提出了DDIM反演攻击(DIA)方法，通过攻击DDIM反演轨迹路径来有效破坏恶意图像编辑，在防御性能上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: DDIM反演技术使恶意用户能够轻松合成虚假内容，现有防御方法在破坏扩散过程方面效果有限，需要更有效的防御机制。

Method: 开发了DDIM反演攻击(DIA)，直接攻击DDIM反演轨迹路径，与迭代去噪轨迹更好地对齐，提高破坏效果。

Result: DIA方法在破坏各种编辑方法方面表现优于之前的防御方法，提供了更有效的防御性能。

Conclusion: DIA框架为行业和研究社区提供了实用的防御方法，能够有效对抗AI的恶意使用。

Abstract: Diffusion models have shown to be strong representation learners, showcasing
state-of-the-art performance across multiple domains. Aside from accelerated
sampling, DDIM also enables the inversion of real images back to their latent
codes. A direct inheriting application of this inversion operation is real
image editing, where the inversion yields latent trajectories to be utilized
during the synthesis of the edited image. Unfortunately, this practical tool
has enabled malicious users to freely synthesize misinformative or deepfake
contents with greater ease, which promotes the spread of unethical and abusive,
as well as privacy-, and copyright-infringing contents. While defensive
algorithms such as AdvDM and Photoguard have been shown to disrupt the
diffusion process on these images, the misalignment between their objectives
and the iterative denoising trajectory at test time results in weak disruptive
performance.In this work, we present the DDIM Inversion Attack (DIA) that
attacks the integrated DDIM trajectory path. Our results support the effective
disruption, surpassing previous defensive methods across various editing
methods. We believe that our frameworks and results can provide practical
defense methods against the malicious use of AI for both the industry and the
research community. Our code is available here:
https://anonymous.4open.science/r/DIA-13419/.

</details>


### [108] [Benchmarking Agentic Systems in Automated Scientific Information Extraction with ChemX](https://arxiv.org/abs/2510.00795)
*Anastasia Vepreva,Julia Razlivina,Maria Eremeeva,Nina Gubina,Anastasia Orlova,Aleksei Dmitrenko,Ksenya Kapranova,Susan Jyakhwo,Nikita Vasilev,Arsen Sarkisyan,Ivan Yu. Chernyshov,Vladimir Vinogradov,Andrei Dmitrenko*

Main category: cs.AI

TL;DR: 提出了ChemX数据集，包含10个手工整理且经过领域专家验证的数据集，用于评估和改进化学信息提取方法。通过对比现有最先进的代理系统和现代基线模型，揭示了化学信息提取面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 化学信息提取因数据异质性而面临重大挑战，现有代理方法在该领域表现有限。需要专门的基准数据集来推动该领域的发展。

Method: 构建了10个手工整理的数据集，涵盖纳米材料和小分子。进行了广泛的基准测试，比较了ChatGPT代理、化学专用提取代理以及作者提出的单代理方法，还评估了GPT-5等现代基线模型。

Result: 实证发现化学信息提取存在持续挑战，特别是在处理领域特定术语、复杂表格和示意图表示以及上下文相关歧义方面。

Conclusion: ChemX基准是推进化学自动化信息提取的关键资源，挑战了现有方法的泛化能力，并为有效评估策略提供了宝贵见解。

Abstract: The emergence of agent-based systems represents a significant advancement in
artificial intelligence, with growing applications in automated data
extraction. However, chemical information extraction remains a formidable
challenge due to the inherent heterogeneity of chemical data. Current
agent-based approaches, both general-purpose and domain-specific, exhibit
limited performance in this domain. To address this gap, we present ChemX, a
comprehensive collection of 10 manually curated and domain-expert-validated
datasets focusing on nanomaterials and small molecules. These datasets are
designed to rigorously evaluate and enhance automated extraction methodologies
in chemistry. To demonstrate their utility, we conduct an extensive
benchmarking study comparing existing state-of-the-art agentic systems such as
ChatGPT Agent and chemical-specific data extraction agents. Additionally, we
introduce our own single-agent approach that enables precise control over
document preprocessing prior to extraction. We further evaluate the performance
of modern baselines, such as GPT-5 and GPT-5 Thinking, to compare their
capabilities with agentic approaches. Our empirical findings reveal persistent
challenges in chemical information extraction, particularly in processing
domain-specific terminology, complex tabular and schematic representations, and
context-dependent ambiguities. The ChemX benchmark serves as a critical
resource for advancing automated information extraction in chemistry,
challenging the generalization capabilities of existing methods, and providing
valuable insights into effective evaluation strategies.

</details>


### [109] [Semantic Bridges Between First Order c-Representations and Cost-Based Semantics: An Initial Perspective](https://arxiv.org/abs/2510.00817)
*Nicholas Leisegang,Giovanni Casini,Thomas Meyer*

Main category: cs.AI

TL;DR: 本文比较了加权知识库与c-表示两种处理不一致知识库的方法，证明在特定条件下它们能在语义层面产生相同的解释排序，并分析了两者在推理关系上的等价性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是比较加权知识库和c-表示这两种处理不一致知识库的形式化方法，探索它们在语义结构和推理关系上的联系与等价性。

Method: 通过语义层面的比较分析，研究加权知识库的成本语义和c-表示的惩罚机制如何产生解释排序，并探讨两者在特定条件下的等价关系。

Result: 结果表明，在特定条件下加权知识库和一组可废止条件可以生成相同的解释排序，两种形式化方法在语义结构上具有相对成本的等价性。

Conclusion: 两种方法在语义层面存在等价关系，这一发现有助于进一步推动成本语义和c-表示的研究发展。

Abstract: Weighted-knowledge bases and cost-based semantics represent a recent
formalism introduced by Bienvenu et al. for Ontology Mediated Data Querying in
the case where a given knowledge base is inconsistent. This is done by adding a
weight to each statement in the knowledge base (KB), and then giving each DL
interpretation a cost based on how often it breaks rules in the KB. In this
paper we compare this approach with c-representations, a form of non-monotonic
reasoning originally introduced by Kern-Isberner. c-Representations describe a
means to interpret defeasible concept inclusions in the first-order case. This
is done by assigning a numerical ranking to each interpretations via penalties
for each violated conditional. We compare these two approaches on a semantic
level. In particular, we show that under certain conditions a weighted
knowledge base and a set of defeasible conditionals can generate the same
ordering on interpretations, and therefore an equivalence of semantic
structures up to relative cost. Moreover, we compare entailment described in
both cases, where certain notions are equivalently expressible in both
formalisms. Our results have the potential to benefit further work on both
cost-based semantics and c-representations

</details>


### [110] [Logical Consistency Between Disagreeing Experts and Its Role in AI Safety](https://arxiv.org/abs/2510.00821)
*Andrés Corrada-Emmanuel*

Main category: cs.AI

TL;DR: 本文提出了一种无监督评估分类器的逻辑方法，通过分析分类器之间的一致性和分歧来推断其性能，无需真实标签。该方法使用线性规划在整数空间中计算与观察到的决策一致的可能正确或错误响应集合。


<details>
  <summary>Details</summary>
Motivation: 当专家在测试中出现分歧时，我们可以断定他们不可能都100%正确；但当他们完全一致时，无法排除任何可能的评估结果。这种一致性与分歧在效用上的不对称性激发了本文对无监督分类器评估逻辑的探索。

Method: 将分类器对齐决策的统计摘要作为输入，构建整数空间中可能正确或错误响应的线性规划问题。包含明显逻辑约束（如正确响应数不能超过观察响应数）作为不等式，以及适用于所有有限测试的普遍线性等式公理。

Result: 该方法具有实际和即时效用，通过构建无知识警报系统，能够检测当一个或多个LLM作为评判者违反用户指定的最低评分阈值时的情况。

Conclusion: 仅基于逻辑一致性的无监督评估方法为分类器性能评估提供了实用工具，特别适用于检测LLM评判者的违规行为，无需依赖真实标签知识。

Abstract: If two experts disagree on a test, we may conclude both cannot be 100 per
cent correct. But if they completely agree, no possible evaluation can be
excluded. This asymmetry in the utility of agreements versus disagreements is
explored here by formalizing a logic of unsupervised evaluation for
classifiers. Its core problem is computing the set of group evaluations that
are logically consistent with how we observe them agreeing and disagreeing in
their decisions. Statistical summaries of their aligned decisions are inputs
into a Linear Programming problem in the integer space of possible correct or
incorrect responses given true labels. Obvious logical constraints, such as,
the number of correct responses cannot exceed the number of observed responses,
are inequalities. But in addition, there are axioms, universally applicable
linear equalities that apply to all finite tests. The practical and immediate
utility of this approach to unsupervised evaluation using only logical
consistency is demonstrated by building no-knowledge alarms that can detect
when one or more LLMs-as-Judges are violating a minimum grading threshold
specified by the user.

</details>


### [111] [Benchmarking Machine Learning Models for Fault Classification and Localization in Power System Protection](https://arxiv.org/abs/2510.00831)
*Julian Oelhaf,Georg Kordowich,Changhun Kim,Paula Andrea Pérez-Toro,Christian Bergler,Andreas Maier,Johann Jäger,Siming Bayer*

Main category: cs.AI

TL;DR: 该论文对电力系统保护中的故障分类和故障定位进行了机器学习模型比较基准研究，基于EMT数据评估了经典ML模型在实时约束下的性能。


<details>
  <summary>Details</summary>
Motivation: 分布式能源资源（特别是可再生能源）的日益集成给电力系统保护带来了重大挑战，传统的基于固定阈值的保护方案在动态条件下无法可靠识别和定位短路故障。

Method: 使用电压和电流波形数据，将其分割为10毫秒到50毫秒的滑动窗口，在现实的实时约束下评估经典机器学习模型。

Result: 最佳故障分类模型的F1得分为0.992±0.001，最佳故障定位模型的R2为0.806±0.008，平均处理时间为0.563毫秒。

Conclusion: 机器学习为电力系统保护提供了有前景的替代方案，本研究首次提供了跨模型和设置的系统性基准比较。

Abstract: The increasing integration of distributed energy resources (DERs),
particularly renewables, poses significant challenges for power system
protection, with fault classification (FC) and fault localization (FL) being
among the most critical tasks. Conventional protection schemes, based on fixed
thresholds, cannot reliably identify and localize short circuits with the
increasing complexity of the grid under dynamic conditions. Machine learning
(ML) offers a promising alternative; however, systematic benchmarks across
models and settings remain limited. This work presents, for the first time, a
comparative benchmarking study of classical ML models for FC and FL in power
system protection based on EMT data. Using voltage and current waveforms
segmented into sliding windows of 10 ms to 50 ms, we evaluate models under
realistic real-time constraints. Performance is assessed in terms of accuracy,
robustness to window size, and runtime efficiency. The best-performing FC model
achieved an F1 score of 0.992$\pm$0.001, while the top FL model reached an R2
of 0.806$\pm$0.008 with a mean processing time of 0.563 ms.

</details>


### [112] [Improving Cryptocurrency Pump-and-Dump Detection through Ensemble-Based Models and Synthetic Oversampling Techniques](https://arxiv.org/abs/2510.00836)
*Jieun Yu,Minjung Park,Sangmi Chai*

Main category: cs.AI

TL;DR: 该研究使用SMOTE技术处理加密货币市场中泵与倾倒(P&D)操纵检测的类别不平衡问题，并评估集成学习模型。XGBoost和LightGBM表现最佳，实现了高召回率和快速计算性能。


<details>
  <summary>Details</summary>
Motivation: 加密货币市场中泵与倾倒操纵事件的稀缺性导致严重的类别不平衡，阻碍了准确的检测。

Method: 应用合成少数类过采样技术(SMOTE)处理类别不平衡，并评估先进的集成学习模型来区分操纵性交易行为和正常市场活动。

Result: 应用SMOTE显著提高了所有模型检测P&D事件的能力，XGBoost和LightGBM分别实现了94.87%和93.59%的高召回率，并表现出快速计算性能。

Conclusion: 将数据平衡技术与集成方法相结合，可显著提高操纵活动的早期检测能力，有助于建立更公平、透明和稳定的加密货币市场。

Abstract: This study aims to detect pump and dump (P&D) manipulation in cryptocurrency
markets, where the scarcity of such events causes severe class imbalance and
hinders accurate detection. To address this issue, the Synthetic Minority
Oversampling Technique (SMOTE) was applied, and advanced ensemble learning
models were evaluated to distinguish manipulative trading behavior from normal
market activity. The experimental results show that applying SMOTE greatly
enhanced the ability of all models to detect P&D events by increasing recall
and improving the overall balance between precision and recall. In particular,
XGBoost and LightGBM achieved high recall rates (94.87% and 93.59%,
respectively) with strong F1-scores and demonstrated fast computational
performance, making them suitable for near real time surveillance. These
findings indicate that integrating data balancing techniques with ensemble
methods significantly improves the early detection of manipulative activities,
contributing to a fairer, more transparent, and more stable cryptocurrency
market.

</details>


### [113] [Learning Compact Representations of LLM Abilities via Item Response Theory](https://arxiv.org/abs/2510.00844)
*Jianhao Chen,Chenxu Wang,Gengrui Zhang,Peng Ye,Lei Bai,Wei Hu,Yuzhong Qu,Shuyue Hu*

Main category: cs.AI

TL;DR: 该论文提出了一种基于项目反应理论(IRT)的方法来学习大语言模型(LLMs)的紧凑表示，通过建模模型能力、查询区分度和难度三个因素，使用混合专家网络(MoE)联合学习这些参数，在模型路由和基准准确率预测任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型数量的激增，如何高效管理和利用这些庞大资源成为一个重要挑战。需要学习LLM能力的紧凑表示来促进下游任务，如模型路由和新基准上的性能预测。

Method: 受心理测量学中项目反应理论(IRT)的启发，将模型正确回答查询的概率建模为三个关键因素的函数：模型的多技能能力向量、查询的区分度向量和查询的难度标量。使用混合专家网络(MoE)耦合模型级和查询级嵌入来联合学习这些参数。

Result: 大量实验表明，该方法在模型路由和基准准确率预测任务上实现了最先进的性能。分析验证了学习到的参数编码了关于模型能力和查询特征的有意义、可解释的信息。

Conclusion: 提出的基于IRT的方法能够有效学习LLM能力的紧凑表示，这些表示不仅在下游任务中表现出色，而且具有很好的可解释性，为大规模语言模型的管理和利用提供了有效解决方案。

Abstract: Recent years have witnessed a surge in the number of large language models
(LLMs), yet efficiently managing and utilizing these vast resources remains a
significant challenge. In this work, we explore how to learn compact
representations of LLM abilities that can facilitate downstream tasks, such as
model routing and performance prediction on new benchmarks. We frame this
problem as estimating the probability that a given model will correctly answer
a specific query. Inspired by the item response theory (IRT) in psychometrics,
we model this probability as a function of three key factors: (i) the model's
multi-skill ability vector, (2) the query's discrimination vector that
separates models of differing skills, and (3) the query's difficulty scalar. To
learn these parameters jointly, we introduce a Mixture-of-Experts (MoE) network
that couples model- and query-level embeddings. Extensive experiments
demonstrate that our approach leads to state-of-the-art performance in both
model routing and benchmark accuracy prediction. Moreover, analysis validates
that the learned parameters encode meaningful, interpretable information about
model capabilities and query characteristics.

</details>


### [114] [Unveiling Interesting Insights: Monte Carlo Tree Search for Knowledge Discovery](https://arxiv.org/abs/2510.00876)
*Pietro Totis,Alberto Pozanco,Daniel Borrajo*

Main category: cs.AI

TL;DR: 提出了一种基于蒙特卡洛树搜索的自动洞察和数据探索方法AIDE，用于解决从数据到可操作知识的转化难题。


<details>
  <summary>Details</summary>
Motivation: 组织收集了大量数据但难以转化为可操作知识，自动化知识发现面临数据导航、模型构建和主观目标等复杂问题。

Method: 使用蒙特卡洛树搜索框架构建AIDE系统，能够自动识别数据转换和模型来发现有趣的数据模式。

Result: 在真实世界和合成数据上的评估表明，AIDE能有效识别数据转换和模型，发现有趣的数据模式。

Conclusion: AIDE为自动化知识发现提供了可扩展的基础框架，未来可集成更多模式提取策略和领域知识。

Abstract: Organizations are increasingly focused on leveraging data from their
processes to gain insights and drive decision-making. However, converting this
data into actionable knowledge remains a difficult and time-consuming task.
There is often a gap between the volume of data collected and the ability to
process and understand it, which automated knowledge discovery aims to fill.
Automated knowledge discovery involves complex open problems, including
effectively navigating data, building models to extract implicit relationships,
and considering subjective goals and knowledge. In this paper, we introduce a
novel method for Automated Insights and Data Exploration (AIDE), that serves as
a robust foundation for tackling these challenges through the use of Monte
Carlo Tree Search (MCTS). We evaluate AIDE using both real-world and synthetic
data, demonstrating its effectiveness in identifying data transformations and
models that uncover interesting data patterns. Among its strengths, AIDE's
MCTS-based framework offers significant extensibility, allowing for future
integration of additional pattern extraction strategies and domain knowledge.
This makes AIDE a valuable step towards developing a comprehensive solution for
automated knowledge discovery.

</details>


### [115] [FusionAdapter for Few-Shot Relation Learning in Multimodal Knowledge Graphs](https://arxiv.org/abs/2510.00894)
*Ran Liu,Yuan Fang,Xiaoli Li*

Main category: cs.AI

TL;DR: 提出FusionAdapter方法用于多模态知识图谱中的少样本关系学习，通过适配器模块和融合策略有效整合多模态信息，在低资源场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MMKG方法主要将多模态对齐到共享空间，忽略了特定模态的独特贡献，在低资源设置下性能受限。

Method: 引入适配器模块使各模态能高效适应未见关系，并提出融合策略在整合多模态实体表示时保持模态特定特征。

Result: 在两个基准MMKG数据集上的广泛实验表明，FusionAdapter优于最先进方法。

Conclusion: 通过有效适应和融合多模态信息，FusionAdapter能以最小监督提高对新关系的泛化能力。

Abstract: Multimodal Knowledge Graphs (MMKGs) incorporate various modalities, including
text and images, to enhance entity and relation representations. Notably,
different modalities for the same entity often present complementary and
diverse information. However, existing MMKG methods primarily align modalities
into a shared space, which tends to overlook the distinct contributions of
specific modalities, limiting their performance particularly in low-resource
settings. To address this challenge, we propose FusionAdapter for the learning
of few-shot relationships (FSRL) in MMKG. FusionAdapter introduces (1) an
adapter module that enables efficient adaptation of each modality to unseen
relations and (2) a fusion strategy that integrates multimodal entity
representations while preserving diverse modality-specific characteristics. By
effectively adapting and fusing information from diverse modalities,
FusionAdapter improves generalization to novel relations with minimal
supervision. Extensive experiments on two benchmark MMKG datasets demonstrate
that FusionAdapter achieves superior performance over state-of-the-art methods.

</details>


### [116] [On Discovering Algorithms for Adversarial Imitation Learning](https://arxiv.org/abs/2510.00922)
*Shashank Reddy Chirra,Jayden Teoh,Praveen Paruchuri,Pradeep Varakantham*

Main category: cs.AI

TL;DR: 本文提出了一种数据驱动的奖励分配函数发现方法DAIL，通过LLM引导的进化框架自动探索奖励分配函数空间，在未见过的环境和策略优化算法中表现出色，超越了人工设计的基线方法。


<details>
  <summary>Details</summary>
Motivation: 对抗模仿学习(AIL)方法虽然有效但被认为不稳定。现有研究主要关注密度比估计，而奖励分配函数对训练动态和最终策略性能的影响被忽视，且通常依赖于人工设计。

Method: 采用LLM引导的进化框架来探索奖励分配函数空间，基于模仿策略的性能直接发现数据驱动的奖励分配函数，提出了首个元学习的AIL算法DAIL。

Result: DAIL在未见过的环境和策略优化算法中表现出良好的泛化能力，超越了当前最先进的人工设计基线方法，并带来更稳定的训练过程。

Conclusion: DAIL通过数据驱动方法发现了更有效的奖励分配函数，为AIL的稳定性提供了新的见解，证明了奖励分配函数在AIL稳定性中的重要作用。

Abstract: Adversarial Imitation Learning (AIL) methods, while effective in settings
with limited expert demonstrations, are often considered unstable. These
approaches typically decompose into two components: Density Ratio (DR)
estimation $\frac{\rho_E}{\rho_{\pi}}$, where a discriminator estimates the
relative occupancy of state-action pairs under the policy versus the expert;
and Reward Assignment (RA), where this ratio is transformed into a reward
signal used to train the policy. While significant research has focused on
improving density estimation, the role of reward assignment in influencing
training dynamics and final policy performance has been largely overlooked. RA
functions in AIL are typically derived from divergence minimization objectives,
relying heavily on human design and ingenuity. In this work, we take a
different approach: we investigate the discovery of data-driven RA functions,
i.e, based directly on the performance of the resulting imitation policy. To
this end, we leverage an LLM-guided evolutionary framework that efficiently
explores the space of RA functions, yielding \emph{Discovered Adversarial
Imitation Learning} (DAIL), the first meta-learnt AIL algorithm. Remarkably,
DAIL generalises across unseen environments and policy optimization algorithms,
outperforming the current state-of-the-art of \emph{human-designed} baselines.
Finally, we analyse why DAIL leads to more stable training, offering novel
insights into the role of RA functions in the stability of AIL. Code is
publicly available: https://github.com/shshnkreddy/DAIL.

</details>


### [117] [Test-Time Search in Neural Graph Coarsening Procedures for the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2510.00958)
*Yoonju Sim,Hyeonah Kim,Changhyun Kwon*

Main category: cs.AI

TL;DR: 提出了一种基于随机性的测试时搜索方法，通过在图粗化过程中引入随机边选择和GraphCHiP算法，提高了神经网络分离方法在CVRP问题中识别有效不等式的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的分离方法在识别有效不等式时生成的不等式数量不足，主要是因为模型对生成多样化子集的敏感性不够。

Method: 1. 在图粗化过程中引入随机边选择替代贪婪方法；2. 提出GraphCHiP算法，利用粗化历史识别RCIs和FCIs。

Result: 在随机生成的CVRP实例上，该方法相比现有神经分离方法能更有效地减少对偶间隙，并首次成功识别出有效的FCIs。

Conclusion: 通过测试时搜索增强训练模型性能，能够提高有效不等式的识别能力，特别是在识别具有挑战性的FCIs方面表现出色。

Abstract: The identification of valid inequalities, such as the rounded capacity
inequalities (RCIs), is a key component of cutting plane methods for the
Capacitated Vehicle Routing Problem (CVRP). While a deep learning-based
separation method can learn to find high-quality cuts, our analysis reveals
that the model produces fewer cuts than expected because it is insufficiently
sensitive to generate a diverse set of generated subsets. This paper proposes
an alternative: enhancing the performance of a trained model at inference time
through a new test-time search with stochasticity. First, we introduce
stochastic edge selection into the graph coarsening procedure, replacing the
previously proposed greedy approach. Second, we propose the Graph Coarsening
History-based Partitioning (GraphCHiP) algorithm, which leverages coarsening
history to identify not only RCIs but also, for the first time, the Framed
capacity inequalities (FCIs). Experiments on randomly generated CVRP instances
demonstrate the effectiveness of our approach in reducing the dual gap compared
to the existing neural separation method. Additionally, our method discovers
effective FCIs on a specific instance, despite the challenging nature of
identifying such cuts.

</details>


### [118] [QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL](https://arxiv.org/abs/2510.00967)
*Cong Yu,Valter Uotila,Shilong Deng,Qingyuan Wu,Tuo Shi,Songlin Jiang,Lei You,Bo Zhao*

Main category: cs.AI

TL;DR: QUASAR是一个基于工具增强大语言模型的强化学习框架，用于生成和优化量子电路，通过量子模拟器验证和分层奖励机制解决LLM生成量子电路的质量问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的量子电路生成方法存在两个主要问题：(i)参数化量子门需要精确数值优化，(ii)LLM缺乏量子领域知识导致生成低质量电路。

Method: 提出QUASAR框架，包含量子电路验证方法和分层奖励机制的强化学习训练，使用外部量子模拟器验证电路质量。

Result: 在4B参数LLM上，QUASAR在Pass@1达到99.31%有效性，Pass@10达到100%，优于GPT-4o、GPT-5、DeepSeek-V3等工业级LLM和多个基线方法。

Conclusion: QUASAR通过工具增强和强化学习显著提升了LLM生成量子电路的语法和语义性能，解决了量子领域知识缺乏的问题。

Abstract: Designing and optimizing task-specific quantum circuits are crucial to
leverage the advantage of quantum computing. Recent large language model
(LLM)-based quantum circuit generation has emerged as a promising automatic
solution. However, the fundamental challenges remain unaddressed: (i)
parameterized quantum gates require precise numerical values for optimal
performance, which also depend on multiple aspects, including the number of
quantum gates, their parameters, and the layout/depth of the circuits. (ii)
LLMs often generate low-quality or incorrect quantum circuits due to the lack
of quantum domain-specific knowledge. We propose QUASAR, an agentic
reinforcement learning (RL) framework for quantum circuits generation and
optimization based on tool-augmented LLMs. To align the LLM with
quantum-specific knowledge and improve the generated quantum circuits, QUASAR
designs (i) a quantum circuit verification approach with external quantum
simulators and (ii) a sophisticated hierarchical reward mechanism in RL
training. Extensive evaluation shows improvements in both syntax and semantic
performance of the generated quantum circuits. When augmenting a 4B LLM, QUASAR
has achieved the validity of 99.31% in Pass@1 and 100% in Pass@10,
outperforming industrial LLMs of GPT-4o, GPT-5 and DeepSeek-V3 and several
supervised-fine-tuning (SFT)-only and RL-only baselines.

</details>


### [119] [Adaptive Federated Few-Shot Rare-Disease Diagnosis with Energy-Aware Secure Aggregation](https://arxiv.org/abs/2510.00976)
*Aueaphum Aueawatthanaphisut*

Main category: cs.AI

TL;DR: 提出了AFFR框架，整合元学习、能量感知客户端调度和安全聚合，用于解决罕见病诊断中的数据稀缺、设备掉线和隐私保护问题。


<details>
  <summary>Details</summary>
Motivation: 罕见病诊断面临数据极度稀缺、隐私担忧和边缘设备资源有限等挑战，需要一种能在真实临床网络中部署的解决方案。

Method: 结合三个核心组件：基于元学习的少样本联邦优化、能量感知客户端调度以减少设备掉线、以及带校准差分隐私的安全聚合。

Result: 在模拟罕见病检测数据集上，相比基线联邦学习准确率提升10%，客户端掉线率降低50%以上，且隐私-效用权衡在临床可接受范围内。

Conclusion: AFFR为罕见病的公平可信联邦诊断提供了实用路径，统一解决了数据稀缺、设备稳定性和隐私保护等关键问题。

Abstract: Rare-disease diagnosis remains one of the most pressing challenges in digital
health, hindered by extreme data scarcity, privacy concerns, and the limited
resources of edge devices. This paper proposes the Adaptive Federated Few-Shot
Rare-Disease Diagnosis (AFFR) framework, which integrates three pillars: (i)
few-shot federated optimization with meta-learning to generalize from limited
patient samples, (ii) energy-aware client scheduling to mitigate device
dropouts and ensure balanced participation, and (iii) secure aggregation with
calibrated differential privacy to safeguard sensitive model updates. Unlike
prior work that addresses these aspects in isolation, AFFR unifies them into a
modular pipeline deployable on real-world clinical networks. Experimental
evaluation on simulated rare-disease detection datasets demonstrates up to 10%
improvement in accuracy compared with baseline FL, while reducing client
dropouts by over 50% without degrading convergence. Furthermore,
privacy-utility trade-offs remain within clinically acceptable bounds. These
findings highlight AFFR as a practical pathway for equitable and trustworthy
federated diagnosis of rare conditions.

</details>


### [120] [Integrating AI and Ensemble Forecasting: Explainable Materials Planning with Scorecards and Trend Insights for a Large-Scale Manufacturer](https://arxiv.org/abs/2510.01006)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 该论文提出了一个售后需求预测和监控的实用架构，结合了统计、机器学习和深度学习模型的集成方法，并包含面向角色的分析层，用于生成记分卡和趋势诊断。


<details>
  <summary>Details</summary>
Motivation: 为了解决售后需求预测中的复杂性和不确定性，特别是在考虑多种外部因素（如COVID-19、宏观经济指标等）的情况下，需要一个能够提供准确预测并支持决策的系统。

Method: 采用收入感知和聚类感知的模型集成方法，结合外生信号（如安装基数、定价、宏观指标等），并将COVID-19视为独立机制。通过帕累托感知分割对高收入项目单独预测，长尾项目通过聚类合并预测。

Result: 系统能够生成国家-部件级别的预测，并提供校准的置信区间。此外，性能记分卡提供了决策相关的洞察，如准确性阈值内的收入份额和数量、偏差分解、地理和产品家族热点等。

Conclusion: 该架构通过可复现的工作流程，将预测、监控和库存决策闭环，帮助规划者从“当前准确性如何”转向“准确性趋势及应采取的杠杆”，提升了决策效率。

Abstract: This paper presents a practical architecture for after-sales demand
forecasting and monitoring that unifies a revenue- and cluster-aware ensemble
of statistical, machine-learning, and deep-learning models with a role-driven
analytics layer for scorecards and trend diagnostics. The framework ingests
exogenous signals (installed base, pricing, macro indicators, life cycle,
seasonality) and treats COVID-19 as a distinct regime, producing country-part
forecasts with calibrated intervals. A Pareto-aware segmentation forecasts
high-revenue items individually and pools the long tail via clusters, while
horizon-aware ensembling aligns weights with business-relevant losses (e.g.,
WMAPE). Beyond forecasts, a performance scorecard delivers decision-focused
insights: accuracy within tolerance thresholds by revenue share and count, bias
decomposition (over- vs under-forecast), geographic and product-family
hotspots, and ranked root causes tied to high-impact part-country pairs. A
trend module tracks trajectories of MAPE/WMAPE and bias across recent months,
flags entities that are improving or deteriorating, detects change points
aligned with known regimes, and attributes movements to lifecycle and seasonal
factors. LLMs are embedded in the analytics layer to generate role-aware
narratives and enforce reporting contracts. They standardize business
definitions, automate quality checks and reconciliations, and translate
quantitative results into concise, explainable summaries for planners and
executives. The system exposes a reproducible workflow -- request
specification, model execution, database-backed artifacts, and AI-generated
narratives -- so planners can move from "How accurate are we now?" to "Where is
accuracy heading and which levers should we pull?", closing the loop between
forecasting, monitoring, and inventory decisions across more than 90 countries
and about 6,000 parts.

</details>


### [121] [Shape Happens: Automatic Feature Manifold Discovery in LLMs via Supervised Multi-Dimensional Scaling](https://arxiv.org/abs/2510.01025)
*Federico Tiblias,Irina Bigoulaeva,Jingcheng Niu,Simone Balloccu,Iryna Gurevych*

Main category: cs.AI

TL;DR: 提出了SMDS方法来自动发现语言模型中的特征流形，发现不同特征形成圆形、直线、聚类等几何结构，这些结构反映概念特性、跨模型稳定、支持推理并随上下文动态变化。


<details>
  <summary>Details</summary>
Motivation: 先前研究专注于发现特定特征的特定几何结构，缺乏泛化性。需要一种模型无关的方法来自动发现特征流形。

Method: 引入监督多维缩放(SMDS)方法，以时间推理为案例研究，自动发现特征流形。

Result: 发现不同特征形成各种几何结构，这些结构一致反映概念特性、跨模型家族和尺寸稳定、主动支持模型推理、并随上下文变化动态重塑。

Conclusion: 研究结果揭示了特征流形的功能作用，支持基于实体的推理模型，其中语言模型编码和转换结构化表示。

Abstract: The linear representation hypothesis states that language models (LMs) encode
concepts as directions in their latent space, forming organized,
multidimensional manifolds. Prior efforts focus on discovering specific
geometries for specific features, and thus lack generalization. We introduce
Supervised Multi-Dimensional Scaling (SMDS), a model-agnostic method to
automatically discover feature manifolds. We apply SMDS to temporal reasoning
as a case study, finding that different features form various geometric
structures such as circles, lines, and clusters. SMDS reveals many insights on
these structures: they consistently reflect the properties of the concepts they
represent; are stable across model families and sizes; actively support
reasoning in models; and dynamically reshape in response to context changes.
Together, our findings shed light on the functional role of feature manifolds,
supporting a model of entity-based reasoning in which LMs encode and transform
structured representations.

</details>


### [122] [Uncovering the Computational Ingredients of Human-Like Representations in LLMs](https://arxiv.org/abs/2510.01030)
*Zach Studdiford,Timothy T. Rogers,Kushin Mukherjee,Siddharth Suresh*

Main category: cs.AI

TL;DR: 本研究通过三重相似性任务评估了70多个不同架构的LLM，发现指令微调和注意力头维度是影响模型与人类概念表示对齐的关键因素，而多模态预训练和参数规模影响有限。现有基准测试无法完全捕捉人机对齐程度。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的快速发展带来了多样化的计算要素，但尚不清楚哪些要素对构建具有人类类似表示能力的模型最为关键。现有基准测试不适合衡量人机表示对齐，使得基准分数无法可靠评估LLM是否在成为有用认知模型方面取得进展。

Method: 使用认知科学中成熟的三重相似性任务方法，基于THINGS数据库中的概念，评估了70多个在计算要素上广泛变化的模型，比较人类和模型的表示对齐程度。

Result: 发现经过指令微调的模型和具有更大注意力头维度的模型与人类表示最为对齐，而多模态预训练和参数规模对对齐影响有限。现有基准测试中MMLU比其他基准更能捕捉表示对齐，但都无法完全解释对齐分数的方差。

Conclusion: 研究结果有助于识别推进LLM成为人类概念表示模型的最关键计算要素，并解决了LLM评估中的一个关键基准测试空白。

Abstract: The ability to translate diverse patterns of inputs into structured patterns
of behavior has been thought to rest on both humans' and machines' ability to
learn robust representations of relevant concepts. The rapid advancement of
transformer-based large language models (LLMs) has led to a diversity of
computational ingredients -- architectures, fine tuning methods, and training
datasets among others -- but it remains unclear which of these ingredients are
most crucial for building models that develop human-like representations.
Further, most current LLM benchmarks are not suited to measuring
representational alignment between humans and models, making benchmark scores
unreliable for assessing if current LLMs are making progress towards becoming
useful cognitive models. We address these limitations by first evaluating a set
of over 70 models that widely vary in their computational ingredients on a
triplet similarity task, a method well established in the cognitive sciences
for measuring human conceptual representations, using concepts from the THINGS
database. Comparing human and model representations, we find that models that
undergo instruction-finetuning and which have larger dimensionality of
attention heads are among the most human aligned, while multimodal pretraining
and parameter size have limited bearing on alignment. Correlations between
alignment scores and scores on existing benchmarks reveal that while some
benchmarks (e.g., MMLU) are better suited than others (e.g., MUSR) for
capturing representational alignment, no existing benchmark is capable of fully
accounting for the variance of alignment scores, demonstrating their
insufficiency in capturing human-AI alignment. Taken together, our findings
help highlight the computational ingredients most essential for advancing LLMs
towards models of human conceptual representation and address a key
benchmarking gap in LLM evaluation.

</details>


### [123] [Activation-Deactivation: A General Framework for Robust Post-hoc Explainable AI](https://arxiv.org/abs/2510.01038)
*Akchunya Chanchal,David A. Kelly,Hana Chockler*

Main category: cs.AI

TL;DR: 提出了一种新的前向传播范式Activation-Deactivation (AD)，通过关闭模型中与遮挡部分对应的组件来消除遮挡输入特征对模型决策的影响，解决了传统黑盒解释方法因遮挡导致分布外图像的问题。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒解释方法依赖遮挡输入部分生成突变体，导致分布外图像，影响解释质量，且选择合适遮挡值需要领域知识。

Method: 引入ConvAD机制，可轻松添加到任何训练好的CNN中，实现AD范式，无需额外训练或微调。

Result: 实验表明AD解释在鲁棒性方面相比遮挡方法提升高达62.5%，能提取更鲁棒的解释且无需领域知识。

Conclusion: ConvAD机制不改变网络决策过程，能提供更鲁棒的解释，解决了传统遮挡方法的局限性。

Abstract: Black-box explainability methods are popular tools for explaining the
decisions of image classifiers. A major drawback of these tools is their
reliance on mutants obtained by occluding parts of the input, leading to
out-of-distribution images. This raises doubts about the quality of the
explanations. Moreover, choosing an appropriate occlusion value often requires
domain knowledge. In this paper we introduce a novel forward-pass paradigm
Activation-Deactivation (AD), which removes the effects of occluded input
features from the model's decision-making by switching off the parts of the
model that correspond to the occlusions. We introduce ConvAD, a drop-in
mechanism that can be easily added to any trained Convolutional Neural Network
(CNN), and which implements the AD paradigm. This leads to more robust
explanations without any additional training or fine-tuning. We prove that the
ConvAD mechanism does not change the decision-making process of the network. We
provide experimental evaluation across several datasets and model
architectures. We compare the quality of AD-explanations with explanations
achieved using a set of masking values, using the proxies of robustness, size,
and confidence drop-off. We observe a consistent improvement in robustness of
AD explanations (up to 62.5%) compared to explanations obtained with
occlusions, demonstrating that ConvAD extracts more robust explanations without
the need for domain knowledge.

</details>


### [124] [Typed Chain-of-Thought: A Curry-Howard Framework for Verifying LLM Reasoning](https://arxiv.org/abs/2510.01069)
*Elija Perrier*

Main category: cs.AI

TL;DR: 提出基于Curry-Howard对应的理论框架，将CoT推理过程映射为形式化类型证明，以验证推理的忠实性。


<details>
  <summary>Details</summary>
Motivation: 解决CoT提示生成推理过程的忠实性问题，提升模型可解释性和可靠性。

Method: 利用Curry-Howard对应关系，将自然语言推理步骤转换为形式化类型证明结构。

Result: 成功将CoT推理轨迹转换为良类型证明，提供可验证的计算忠实性证书。

Conclusion: 该框架为构建更可靠可信的AI系统提供了从叙述性解释到形式化验证的路径。

Abstract: While Chain-of-Thought (CoT) prompting enhances the reasoning capabilities of
large language models, the faithfulness of the generated rationales remains an
open problem for model interpretability. We propose a novel theoretical lens
for this problem grounded in the Curry-Howard correspondence, which posits a
direct relationship between formal proofs and computer programs. Under this
paradigm, a faithful reasoning trace is analogous to a well-typed program,
where each intermediate step corresponds to a typed logical inference. We
operationalise this analogy, presenting methods to extract and map the
informal, natural language steps of CoT into a formal, typed proof structure.
Successfully converting a CoT trace into a well-typed proof serves as a strong,
verifiable certificate of its computational faithfulness, moving beyond
heuristic interpretability towards formal verification. Our framework provides
a methodology to transform plausible narrative explanations into formally
verifiable programs, offering a path towards building more reliable and
trustworthy AI systems.

</details>


### [125] [Safety Instincts: LLMs Learn to Trust Their Internal Compass for Self-Defense](https://arxiv.org/abs/2510.01088)
*Guobin Shen,Dongcheng Zhao,Haibo Tong,Jindong Li,Feifei Zhao,Yi Zeng*

Main category: cs.AI

TL;DR: SIRL方法利用LLM内部的安全信念，将拒绝有害请求时的高置信度转化为自生成奖励信号，无需外部验证器即可强化模型的安全本能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏通用安全标准和可靠的内容验证器，确保LLM安全性面临挑战。研究发现对齐模型已具备内部安全信念，但缺乏有效利用这些信念的方法。

Method: 提出Safety Instincts Reinforcement Learning (SIRL)，将模型拒绝有害请求时的高置信度（低熵）转化为自生成奖励信号，通过强化学习训练模型信任其安全本能。

Result: 在Llama和Qwen模型上评估，SIRL对20+种越狱方法保持89%+的防御成功率，仅使用15,000个无标签提示就超越资源密集的监督方法，同时保持数学、编程和对话基准性能。

Conclusion: 有效对齐可以从模型内部产生，为无需大量人工监督的自主、鲁棒AI安全机制开辟了道路。

Abstract: Ensuring Large Language Model (LLM) safety remains challenging due to the
absence of universal standards and reliable content validators, making it
difficult to obtain effective training signals. We discover that aligned models
already possess robust internal safety beliefs: they consistently produce
high-confidence refusals to harmful requests while exhibiting high entropy when
generating potentially dangerous content. This entropy gap reveals an untapped
signal--models intrinsically "know" when to refuse. We introduce Safety
Instincts Reinforcement Learning (SIRL), which transforms this internal
confidence into a self-generated reward signal, eliminating dependence on
external validators or human annotations. SIRL teaches models to trust their
safety instincts by reinforcing low-entropy refusal behaviors. Evaluated on
Llama and Qwen models, SIRL maintains 89%+ Defense Success Rates (DSRs) against
20+ jailbreak methods, from static prompts to adaptive attacks. Using only
15,000 unlabeled prompts, SIRL surpasses resource-intensive supervised methods
while preserving performance on mathematics, coding, and conversation
benchmarks. Our work demonstrates that effective alignment can emerge from
within, paving the way for more autonomous and robust AI safety mechanisms that
scale without extensive human oversight.

</details>


### [126] [Optimizing Fairness in Production Planning: A Human-Centric Approach to Machine and Workforce Allocation](https://arxiv.org/abs/2510.01094)
*Alexander Nasuta,Alessandro Cisi,Sylwia Olbrych,Gustavo Vieira,Rui Fernandes,Lucas Paletta,Marlene Mayr,Rishyank Chevuri,Robert Woitsch,Hans Aoyang Zhou,Anas Abdelrazeq,Robert H. Schmitt*

Main category: cs.AI

TL;DR: 提出一个双层人本生产计划框架，结合约束规划优化生产调度，使用马尔可夫决策过程优化工人分配，在保证效率的同时提升工人公平性。


<details>
  <summary>Details</summary>
Motivation: 工业制造中需要同时优化运营效率和劳动力公平性，传统方法往往忽视工人偏好、经验、适应能力和医疗约束等人本因素。

Method: 第一层使用约束规划(CP)解决订单-产线分配问题；第二层使用马尔可夫决策过程(MDP)解决工人-产线分配问题，并比较贪婪分配、MCTS和RL三种策略。

Result: CP调度产生紧凑可行的生产计划，MDP工人分配显著提升公平性和偏好匹配度。领域专家评估显示两个组件都有效，同时指出了改进方向。

Conclusion: 结合约束规划与学习型决策为人本生产计划提供了稳健方法，能够同时优化吞吐量和工人福祉，为公平高效的制造调度奠定实践基础。

Abstract: This work presents a two-layer, human-centric production planning framework
designed to optimize both operational efficiency and workforce fairness in
industrial manufacturing. The first layer formulates the Order-Line allocation
as a Constraint Programming (CP) problem, generating high-utilization
production schedules that respect machine capacities, processing times, and due
dates. The second layer models Worker-Line allocation as a Markov Decision
Process (MDP), integrating human factors such as worker preference, experience,
resilience, and medical constraints into the assignment process. Three solution
strategies, greedy allocation, MCTS, and RL, are implemented and compared
across multiple evaluation scenarios. The proposed system is validated through
16 test sessions with domain experts from the automotive industry, combining
quantitative key performance indicators (KPIs) with expert ratings. Results
indicate that the CP-based scheduling approach produces compact, feasible
production plans with low tardiness, while the MDP-based worker allocation
significantly improves fairness and preference alignment compared to baseline
approaches. Domain experts rated both the Order-Line and Worker-Line components
as effective and highlighted opportunities to further refine the objective
function to penalize excessive earliness and improve continuity in worker
assignments. Overall, the findings demonstrate that combining CP with
learning-based decision-making provides a robust approach for human-centric
production planning. The approach enables simultaneous optimization of
throughput and workforce well-being, offering a practical foundation for fair
and efficient manufacturing scheduling in industrial settings.

</details>


### [127] [PRISM-Consult: A Panel-of-Experts Architecture for Clinician-Aligned Diagnosis](https://arxiv.org/abs/2510.01114)
*Lionel Levine,John Santerre,Alexander S. Young,T. Barry Levine,Francis Campion,Majid Sarrafzadeh*

Main category: cs.AI

TL;DR: PRISM-Consult是一个临床医生对齐的专家小组架构，将紧凑的PRISM序列模型扩展为路由的领域专家家族，通过轻量级路由器将病例分配到不同专科模型，实现参数效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 开发一个安全、可审计且低延迟的临床咨询系统，通过领域专家模型提高诊断准确性和计算效率，避免常见事件主导结果。

Method: 使用结构化临床事件标记化，轻量级路由器读取前几个标记并分配到专科模型（心血管、肺、胃肠、肌肉骨骼、心因性），每个专科继承PRISM的小型transformer架构和标记模板。

Result: 在真实世界急诊科队列中，专科模型在各领域表现出平滑收敛和低开发困惑度，路由器在安全优先策略下实现高质量路由和大量计算节省。

Conclusion: 该框架为大规模安全、可审计和低延迟咨询提供了实用路径，并概述了外部/时间复制、非对称生命威胁阈值和多标签仲裁等验证步骤以满足临床部署标准。

Abstract: We present PRISM-Consult, a clinician-aligned panel-of-experts architecture
that extends the compact PRISM sequence model into a routed family of domain
specialists. Episodes are tokenized as structured clinical events; a
light-weight router reads the first few tokens and dispatches to specialist
models (Cardiac-Vascular, Pulmonary, Gastro-Oesophageal, Musculoskeletal,
Psychogenic). Each specialist inherits PRISM's small transformer backbone and
token template, enabling parameter efficiency and interpretability. On
real-world Emergency Department cohorts, specialists exhibit smooth convergence
with low development perplexities across domains, while the router achieves
high routing quality and large compute savings versus consult-all under a
safety-first policy. We detail the data methodology (initial vs. conclusive
ICD-9 families), routing thresholds and calibration, and report per-domain
results to avoid dominance by common events. The framework provides a practical
path to safe, auditable, and low-latency consult at scale, and we outline
validation steps-external/temporal replication, asymmetric life-threat
thresholds, and multi-label arbitration-to meet prospective clinical deployment
standards.

</details>


### [128] [Apriel-1.5-15b-Thinker](https://arxiv.org/abs/2510.01141)
*Shruthan Radhakrishna,Aman Tiwari,Aanjaneya Shukla,Masoud Hashemi,Rishabh Maheshwary,Shiva Krishna Reddy Malay,Jash Mehta,Pulkit Pattnaik,Saloni Mittal,Khalil Slimi,Kelechi Ogueji,Akintunde Oladipo,Soham Parikh,Oluwanifemi Bamgbose,Toby Liang,Ahmed Masry,Khyati Mahajan,Sai Rajeswar Mudumba,Vikas Yadav,Sathwik Tejaswi Madhusudhan,Torsten Scholak,Sagar Davasam,Srinivas Sunkara,Nicholas Chapados*

Main category: cs.AI

TL;DR: Apriel-1.5-15B-Thinker是一个150亿参数的多模态推理模型，通过渐进式三阶段训练方法实现前沿性能，无需大规模计算资源，在单GPU部署限制下达到与更大模型竞争的结果。


<details>
  <summary>Details</summary>
Motivation: 旨在证明通过精心设计的训练方法而非单纯扩大规模，可以在有限计算资源下实现前沿水平的多模态推理能力，使更多组织能够获得高性能模型。

Method: 采用三阶段渐进方法：1）深度扩展推理能力；2）分阶段持续预训练，包括基础文本视觉理解和通过合成数据增强视觉推理；3）高质量文本监督微调，涵盖数学、编程、科学和工具使用。

Result: 在Artificial Analysis Intelligence Index上获得52分，与DeepSeek-R1-0528相当；在十个图像基准测试中平均性能仅比Gemini-2.5-Flash和Claude Sonnet-3.7低5分。

Conclusion: 精心设计的中间训练方法可以在不依赖大规模计算的情况下显著缩小能力差距，使前沿多模态推理对基础设施有限的组织更加可及。

Abstract: We present Apriel-1.5-15B-Thinker, a 15-billion parameter open-weights
multimodal reasoning model that achieves frontier-level performance through
training design rather than sheer scale. Starting from Pixtral-12B, we apply a
progressive three-stage methodology: (1) depth upscaling to expand reasoning
capacity without pretraining from scratch, (2) staged continual pre-training
that first develops foundational text and vision understanding, then enhances
visual reasoning through targeted synthetic data generation addressing spatial
structure, compositional understanding, and fine-grained perception, and (3)
high-quality text-only supervised fine-tuning on curated instruction-response
pairs with explicit reasoning traces spanning mathematics, coding, science, and
tool use. Notably, our model achieves competitive results without reinforcement
learning or preference optimization, isolating the contribution of our
data-centric continual pre-training approach. On the Artificial Analysis
Intelligence Index, Apriel-1.5-15B-Thinker attains a score of 52, matching
DeepSeek-R1-0528 despite requiring significantly fewer computational resources.
Across ten image benchmarks, its performance is on average within five points
of Gemini-2.5-Flash and Claude Sonnet-3.7, a key achievement for a model
operating within single-GPU deployment constraints. Our results demonstrate
that thoughtful mid-training 2 design can close substantial capability gaps
without massive scale, making frontier-level multimodal reasoning accessible to
organizations with limited infrastructure. We release the model checkpoint, all
training recipes, and evaluation protocols under the MIT license to to advance
open-source research.

</details>


### [129] [Generalized Parallel Scaling with Interdependent Generations](https://arxiv.org/abs/2510.01143)
*Harry Dong,David Brandfonbrener,Eryk Helenowski,Yun He,Mrinal Kumar,Han Fang,Yuejie Chi,Karthik Abinav Sankararaman*

Main category: cs.AI

TL;DR: Bridge是一个并行LLM推理方法，通过让多个响应在生成过程中相互依赖，而不是独立生成，从而提高响应质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统的并行LLM推理中，多个响应独立生成，浪费了计算资源，且无法利用一个生成中的有用信息来帮助其他生成。

Method: 将批处理的LLM隐藏状态重新构想为整体张量而非独立切片，仅添加少量新参数（2.8%-5.1%），使响应在并行生成过程中相互依赖。

Result: Bridge将基于可验证奖励的强化学习的相对平均准确率提升高达50%，并提高了正确响应的一致性。一次训练即可扩展到任何生成宽度，性能优于独立生成。

Conclusion: Bridge解锁了一种更通用的并行扩展模式，有效利用序列间的信息，兼容任何后生成聚合技术。

Abstract: Parallel LLM inference scaling involves sampling a set of $N>1$ responses for
a single input prompt. However, these $N$ parallel responses tend to be
generated independently from each other, partitioning compute resources and
leaving potentially useful information in one generation untapped by others.
This is in contrast to response length scaling where past computation is used
in all future steps. For higher quality responses and response sets, we propose
Bridge to generate interdependent responses in parallel by rethinking batched
LLM hidden states as holistic tensors rather than independent slices. With only
a small amount (2.8%-5.1%) of new parameters, Bridge improves the relative mean
accuracy gains from reinforcement learning with verifiable rewards by up to 50%
and boosts consistency of correct responses. Trained once, Bridge scales to any
generation width, all with greater performance than independent generations,
unlocking a more general mode of parallel scaling that effectively leverages
information between sequences, compatible with any post-generation aggregation
technique.

</details>
