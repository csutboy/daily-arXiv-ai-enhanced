{"id": "2602.04060", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.04060", "abs": "https://arxiv.org/abs/2602.04060", "authors": ["M Hashem Pesaran", "Ron Smith"], "title": "The Output Convergence Debate Revisited: Lessons from recent developments in the analysis of panel data models", "comment": "47 pages and one figure", "summary": "This paper provides a critical examination of the empirical basis of the output convergence debate in the light of recent developments in the analysis of dynamic heterogeneous panels with interactive effects. It shows that popular tools such as Barro's cross-country regressions and two-way fixed effects (TWFE) estimators that assume parallel trends and homogeneous dynamics lead to substantial under-estimation of the speed of convergence and misleading inference. Instead, dynamic common correlated effects (DCCE) estimators due to Chudik and Pesaran (2015a) provide consistent estimates and valid inference that are robust to nonparallel trends and correlated heterogeneity and apply even if there are breaks, trends and/or unit roots in the latent technology factor. It also suggests a way to estimate the effect of slowly moving determinants of growth. The theoretical findings are augmented with empirical evidence using Penn World Tables data, finding little evidence of per capita output convergence across countries, very slow evidence of cross country growth convergence, and reasonably fast within country convergence. Capital accumulation is found to be the most important single determinant of cross-country differences in output while slow moving indicators such as potential for conflict and protection of property rights proved to be statistically significant determinants of the steady state levels of output per capita. We are also able to replicate a positive evidence of democratization on output, but we find that the statistical significance of this effect to fall as we allow for nonparallel trends and dynamic heterogeneity.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u6027\u68c0\u9a8c\u4e86\u4ea7\u51fa\u6536\u655b\u8fa9\u8bba\u7684\u5b9e\u8bc1\u57fa\u7840\uff0c\u4f7f\u7528\u52a8\u6001\u5f02\u8d28\u9762\u677f\u4ea4\u4e92\u6548\u5e94\u5206\u6790\u65b0\u65b9\u6cd5\uff0c\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\u4f4e\u4f30\u6536\u655b\u901f\u5ea6\u4e14\u63a8\u65ad\u8bef\u5bfc\uff0c\u800cDCCE\u65b9\u6cd5\u63d0\u4f9b\u7a33\u5065\u4f30\u8ba1\uff0c\u5b9e\u8bc1\u53d1\u73b0\u8de8\u56fd\u4eba\u5747\u4ea7\u51fa\u6536\u655b\u8bc1\u636e\u5fae\u5f31\uff0c\u8d44\u672c\u79ef\u7d2f\u662f\u8de8\u56fd\u4ea7\u51fa\u5dee\u5f02\u6700\u91cd\u8981\u51b3\u5b9a\u56e0\u7d20\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u4ea7\u51fa\u6536\u655b\u8fa9\u8bba\u7684\u5b9e\u8bc1\u57fa\u7840\uff0c\u6279\u5224\u4f20\u7edf\u65b9\u6cd5\uff08\u5982Barro\u8de8\u56fd\u56de\u5f52\u548c\u53cc\u5411\u56fa\u5b9a\u6548\u5e94\uff09\u5047\u8bbe\u5e73\u884c\u8d8b\u52bf\u548c\u540c\u8d28\u52a8\u6001\u7684\u5c40\u9650\u6027\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u80fd\u5bfc\u81f4\u6536\u655b\u901f\u5ea6\u4f4e\u4f30\u548c\u8bef\u5bfc\u6027\u63a8\u65ad\u3002", "method": "\u91c7\u7528Chudik\u548cPesaran(2015a)\u63d0\u51fa\u7684\u52a8\u6001\u5171\u540c\u76f8\u5173\u6548\u5e94(DCCE)\u4f30\u8ba1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u5904\u7406\u975e\u5e73\u884c\u8d8b\u52bf\u3001\u76f8\u5173\u5f02\u8d28\u6027\uff0c\u5373\u4f7f\u6f5c\u5728\u6280\u672f\u56e0\u5b50\u5b58\u5728\u65ad\u70b9\u3001\u8d8b\u52bf\u548c/\u6216\u5355\u4f4d\u6839\u4e5f\u9002\u7528\uff1b\u540c\u65f6\u63d0\u51fa\u4f30\u8ba1\u7f13\u6162\u79fb\u52a8\u589e\u957f\u51b3\u5b9a\u56e0\u7d20\u5f71\u54cd\u7684\u65b9\u6cd5\uff1b\u4f7f\u7528Penn World Tables\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "1) \u8de8\u56fd\u4eba\u5747\u4ea7\u51fa\u6536\u655b\u8bc1\u636e\u5fae\u5f31\uff1b2) \u8de8\u56fd\u589e\u957f\u6536\u655b\u975e\u5e38\u7f13\u6162\uff1b3) \u56fd\u5185\u6536\u655b\u76f8\u5bf9\u8f83\u5feb\uff1b4) \u8d44\u672c\u79ef\u7d2f\u662f\u8de8\u56fd\u4ea7\u51fa\u5dee\u5f02\u6700\u91cd\u8981\u51b3\u5b9a\u56e0\u7d20\uff1b5) \u51b2\u7a81\u6f5c\u529b\u548c\u4ea7\u6743\u4fdd\u62a4\u7b49\u7f13\u6162\u79fb\u52a8\u6307\u6807\u5bf9\u4eba\u5747\u4ea7\u51fa\u7a33\u6001\u6c34\u5e73\u6709\u7edf\u8ba1\u663e\u8457\u5f71\u54cd\uff1b6) \u6c11\u4e3b\u5316\u5bf9\u4ea7\u51fa\u7684\u6b63\u5411\u6548\u5e94\u5728\u8003\u8651\u975e\u5e73\u884c\u8d8b\u52bf\u548c\u52a8\u6001\u5f02\u8d28\u6027\u540e\u7edf\u8ba1\u663e\u8457\u6027\u4e0b\u964d\u3002", "conclusion": "\u4f20\u7edf\u6536\u655b\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0cDCCE\u65b9\u6cd5\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u4f30\u8ba1\u548c\u63a8\u65ad\uff1b\u5b9e\u8bc1\u8bc1\u636e\u4e0d\u652f\u6301\u5f3a\u8de8\u56fd\u6536\u655b\uff0c\u8d44\u672c\u79ef\u7d2f\u662f\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\uff1b\u65b9\u6cd5\u9009\u62e9\u5bf9\u653f\u7b56\u76f8\u5173\u7ed3\u8bba\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u7279\u522b\u662f\u6c11\u4e3b\u5316\u6548\u5e94\u7b49\u53d1\u73b0\u5bf9\u6a21\u578b\u8bbe\u5b9a\u654f\u611f\u3002"}}
{"id": "2602.04092", "categories": ["stat.AP", "econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04092", "abs": "https://arxiv.org/abs/2602.04092", "authors": ["Oana M. Enache", "Sherri Rose"], "title": "Time-to-Event Estimation with Unreliably Reported Events in Medicare Health Plan Payment", "comment": "36 pages, 9 figures", "summary": "Time-to-event estimation (i.e., survival analysis) is common in health research, most often using methods that assume proportional hazards and no competing risks. Because both assumptions are frequently invalid, estimators more aligned with real-world settings have been proposed. An effect can be estimated as the difference in areas below the cumulative incidence functions of two groups up to a pre-specified time point. This approach, restricted mean time lost (RMTL), can be used in settings with competing risks as well. We extend RMTL estimation for use in an understudied health policy application in Medicare. Medicare currently supports healthcare payment for over 69 million beneficiaries, most of whom are enrolled in Medicare Advantage plans and receive insurance from private insurers. These insurers are prospectively paid by the federal government for each of their beneficiaries' anticipated health needs using an ordinary least squares linear regression algorithm. As all coefficients are positive and predictor variables are largely insurer-submitted health conditions, insurers are incentivized to upcode, or report more diagnoses than may be accurate. Such gaming is projected to cost the federal government $40 billion in 2025 alone without clear benefit to beneficiaries. We propose several novel estimators of coding intensity and possible upcoding in Medicare Advantage, including accounting for unreliable reporting. We demonstrate estimator performance in simulated data leveraging the National Institutes of Health's All of Us study and also develop an open source R package to simulate realistic labeled upcoding data, which were not previously available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u751f\u5b58\u5206\u6790\u4e2d\u7684\u9650\u5236\u5e73\u5747\u65f6\u95f4\u635f\u5931\uff08RMTL\uff09\u65b9\u6cd5\u6269\u5c55\u5230Medicare Advantage\u8ba1\u5212\u4e2d\u7684\u7f16\u7801\u5f3a\u5ea6\u8bc4\u4f30\uff0c\u4ee5\u68c0\u6d4b\u4fdd\u9669\u516c\u53f8\u53ef\u80fd\u5b58\u5728\u7684\u8fc7\u5ea6\u7f16\u7801\uff08upcoding\uff09\u884c\u4e3a\uff0c\u5e76\u5f00\u53d1\u4e86\u76f8\u5e94\u7684\u4f30\u8ba1\u5668\u548c\u5f00\u6e90R\u5305\u7528\u4e8e\u6a21\u62df\u771f\u5b9e\u6570\u636e\u3002", "motivation": "Medicare Advantage\u8ba1\u5212\u4e2d\uff0c\u4fdd\u9669\u516c\u53f8\u56e0\u6309\u9884\u671f\u5065\u5eb7\u9700\u6c42\u83b7\u5f97\u524d\u77bb\u6027\u652f\u4ed8\uff0c\u4e14\u6240\u6709\u7cfb\u6570\u4e3a\u6b63\u3001\u9884\u6d4b\u53d8\u91cf\u4e3b\u8981\u4e3a\u4fdd\u9669\u516c\u53f8\u63d0\u4ea4\u7684\u5065\u5eb7\u72b6\u51b5\uff0c\u5b58\u5728\u8fc7\u5ea6\u7f16\u7801\uff08\u62a5\u544a\u66f4\u591a\u8bca\u65ad\uff09\u7684\u6fc0\u52b1\u3002\u8fd9\u79cd\u535a\u5f08\u884c\u4e3a\u9884\u8ba1\u57282025\u5e74\u5c06\u7ed9\u8054\u90a6\u653f\u5e9c\u9020\u6210400\u4ebf\u7f8e\u5143\u635f\u5931\uff0c\u4f46\u7f3a\u4e4f\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5c06\u751f\u5b58\u5206\u6790\u4e2d\u7684\u9650\u5236\u5e73\u5747\u65f6\u95f4\u635f\u5931\uff08RMTL\uff09\u65b9\u6cd5\u6269\u5c55\u5230Medicare Advantage\u7f16\u7801\u5f3a\u5ea6\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e86\u51e0\u79cd\u65b0\u7684\u7f16\u7801\u5f3a\u5ea6\u548c\u53ef\u80fd\u8fc7\u5ea6\u7f16\u7801\u7684\u4f30\u8ba1\u5668\uff0c\u5305\u62ec\u8003\u8651\u4e0d\u53ef\u9760\u62a5\u544a\u7684\u60c5\u51b5\u3002\u5229\u7528NIH\u7684All of Us\u7814\u7a76\u6570\u636e\u8fdb\u884c\u6a21\u62df\u9a8c\u8bc1\uff0c\u5e76\u5f00\u53d1\u4e86\u5f00\u6e90R\u5305\u6765\u6a21\u62df\u771f\u5b9e\u7684\u6807\u8bb0\u8fc7\u5ea6\u7f16\u7801\u6570\u636e\u3002", "result": "\u5f00\u53d1\u4e86\u65b0\u7684\u4f30\u8ba1\u5668\u6765\u8bc4\u4f30Medicare Advantage\u4e2d\u7684\u7f16\u7801\u5f3a\u5ea6\u548c\u53ef\u80fd\u8fc7\u5ea6\u7f16\u7801\uff0c\u901a\u8fc7\u6a21\u62df\u6570\u636e\u9a8c\u8bc1\u4e86\u4f30\u8ba1\u5668\u6027\u80fd\uff0c\u5e76\u521b\u5efa\u4e86\u5f00\u6e90R\u5305\u7528\u4e8e\u751f\u6210\u4ee5\u524d\u4e0d\u53ef\u7528\u7684\u771f\u5b9e\u6807\u8bb0\u8fc7\u5ea6\u7f16\u7801\u6570\u636e\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c06RMTL\u65b9\u6cd5\u5e94\u7528\u4e8eMedicare Advantage\u8ba1\u5212\u7684\u7f16\u7801\u5f3a\u5ea6\u8bc4\u4f30\uff0c\u4e3a\u89e3\u51b3\u4fdd\u9669\u516c\u53f8\u8fc7\u5ea6\u7f16\u7801\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177\u548c\u6570\u636e\u6a21\u62df\u80fd\u529b\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u68c0\u6d4b\u548c\u91cf\u5316\u8fd9\u4e00\u6210\u672c\u9ad8\u6602\u7684\u535a\u5f08\u884c\u4e3a\u3002"}}
{"id": "2602.03969", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03969", "abs": "https://arxiv.org/abs/2602.03969", "authors": ["Shama Magnur", "Mayank Kejriwal"], "title": "Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem", "comment": "16 pages, 5 Figures, 7 Tables", "summary": "The emergence of large language models (LLMs) represents a significant technological shift within the scientific ecosystem, particularly within the field of artificial intelligence (AI). This paper examines structural changes in the AI research landscape using a dataset of arXiv preprints (cs.AI) from 2021 through 2025. Given the rapid pace of AI development, the preprint ecosystem has become a critical barometer for real-time scientific shifts, often preceding formal peer-reviewed publication by months or years. By employing a multi-stage data collection and enrichment pipeline in conjunction with LLM-based institution classification, we analyze the evolution of publication volumes, author team sizes, and academic--industry collaboration patterns. Our results reveal an unprecedented surge in publication output following the introduction of ChatGPT, with academic institutions continuing to provide the largest volume of research. However, we observe that academic--industry collaboration is still suppressed, as measured by a Normalized Collaboration Index (NCI) that remains significantly below the random-mixing baseline across all major subfields. These findings highlight a continuing institutional divide and suggest that the capital-intensive nature of generative AI research may be reshaping the boundaries of scientific collaboration.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528arXiv\u9884\u5370\u672c\u6570\u636e\uff082021-2025\uff09\u5206\u6790AI\u7814\u7a76\u683c\u5c40\u7684\u7ed3\u6784\u53d8\u5316\uff0c\u53d1\u73b0ChatGPT\u63a8\u51fa\u540e\u8bba\u6587\u6570\u91cf\u6fc0\u589e\uff0c\u5b66\u672f\u673a\u6784\u4ecd\u662f\u4e3b\u8981\u8d21\u732e\u8005\uff0c\u4f46\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u5408\u4f5c\u4ecd\u4f4e\u4e8e\u968f\u673a\u6df7\u5408\u57fa\u51c6\uff0c\u8868\u660e\u751f\u6210\u5f0fAI\u7814\u7a76\u7684\u8d44\u672c\u5bc6\u96c6\u578b\u7279\u6027\u53ef\u80fd\u91cd\u5851\u79d1\u5b66\u5408\u4f5c\u8fb9\u754c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u51fa\u73b0\u4ee3\u8868\u4e86\u79d1\u5b66\u751f\u6001\u7cfb\u7edf\u7684\u91cd\u8981\u6280\u672f\u8f6c\u53d8\uff0c\u7279\u522b\u662f\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u3002arXiv\u9884\u5370\u672c\u751f\u6001\u7cfb\u7edf\u5df2\u6210\u4e3a\u5b9e\u65f6\u79d1\u5b66\u53d8\u5316\u7684\u5173\u952e\u6307\u6807\uff0c\u901a\u5e38\u6bd4\u6b63\u5f0f\u540c\u884c\u8bc4\u5ba1\u53d1\u8868\u63d0\u524d\u6570\u6708\u6216\u6570\u5e74\u3002\u7814\u7a76\u65e8\u5728\u5206\u6790AI\u7814\u7a76\u683c\u5c40\u7684\u7ed3\u6784\u53d8\u5316\uff0c\u5305\u62ec\u53d1\u8868\u91cf\u3001\u4f5c\u8005\u56e2\u961f\u89c4\u6a21\u548c\u5b66\u672f-\u4ea7\u4e1a\u5408\u4f5c\u6a21\u5f0f\u7684\u6f14\u53d8\u3002", "method": "\u4f7f\u75282021\u5e74\u81f32025\u5e74arXiv\u9884\u5370\u672c\uff08cs.AI\uff09\u6570\u636e\u96c6\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u6570\u636e\u6536\u96c6\u548c\u4e30\u5bcc\u5316\u6d41\u7a0b\uff0c\u7ed3\u5408\u57fa\u4e8eLLM\u7684\u673a\u6784\u5206\u7c7b\u65b9\u6cd5\uff0c\u5206\u6790\u53d1\u8868\u91cf\u3001\u4f5c\u8005\u56e2\u961f\u89c4\u6a21\u548c\u5b66\u672f-\u4ea7\u4e1a\u5408\u4f5c\u6a21\u5f0f\u7684\u6f14\u53d8\uff0c\u5e76\u4f7f\u7528\u5f52\u4e00\u5316\u5408\u4f5c\u6307\u6570\uff08NCI\uff09\u6765\u8861\u91cf\u5408\u4f5c\u6c34\u5e73\u3002", "result": "1. ChatGPT\u63a8\u51fa\u540e\u8bba\u6587\u53d1\u8868\u91cf\u51fa\u73b0\u524d\u6240\u672a\u6709\u7684\u6fc0\u589e\uff1b2. \u5b66\u672f\u673a\u6784\u7ee7\u7eed\u63d0\u4f9b\u6700\u5927\u91cf\u7684\u7814\u7a76\u4ea7\u51fa\uff1b3. \u5b66\u672f-\u4ea7\u4e1a\u5408\u4f5c\u4ecd\u7136\u53d7\u5230\u6291\u5236\uff0c\u6240\u6709\u4e3b\u8981\u5b50\u9886\u57df\u7684\u5f52\u4e00\u5316\u5408\u4f5c\u6307\u6570\uff08NCI\uff09\u90fd\u663e\u8457\u4f4e\u4e8e\u968f\u673a\u6df7\u5408\u57fa\u51c6\uff1b4. \u8fd9\u8868\u660e\u6301\u7eed\u5b58\u5728\u7684\u673a\u6784\u9e3f\u6c9f\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0AI\u7814\u7a76\u683c\u5c40\u5b58\u5728\u6301\u7eed\u7684\u673a\u6784\u9e3f\u6c9f\uff0c\u751f\u6210\u5f0fAI\u7814\u7a76\u7684\u8d44\u672c\u5bc6\u96c6\u578b\u7279\u6027\u53ef\u80fd\u6b63\u5728\u91cd\u5851\u79d1\u5b66\u5408\u4f5c\u7684\u8fb9\u754c\u3002\u5b66\u672f-\u4ea7\u4e1a\u5408\u4f5c\u4ecd\u7136\u4f4e\u4e8e\u9884\u671f\u6c34\u5e73\uff0c\u8fd9\u53cd\u6620\u4e86AI\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u7684\u7ed3\u6784\u6027\u53d8\u5316\u3002"}}
{"id": "2602.04546", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.04546", "abs": "https://arxiv.org/abs/2602.04546", "authors": ["Florian Kramer", "Henrich R. Greve", "Moritz von Zahn", "Hayagreeva Rao"], "title": "Unmasking Superspreaders: Data-Driven Approaches for Identifying and Comparing Key Influencers of Conspiracy Theories on X.com", "comment": null, "summary": "Conspiracy theories can threaten society by spreading misinformation, deepening polarization, and eroding trust in democratic institutions. Social media often fuels the spread of conspiracies, primarily driven by two key actors: Superspreaders -- influential individuals disseminating conspiracy content at disproportionately high rates, and Bots -- automated accounts designed to amplify conspiracies strategically. To counter the spread of conspiracy theories, it is critical to both identify these actors and to better understand their behavior. However, a systematic analysis of these actors as well as real-world-applicable identification methods are still lacking. In this study, we leverage over seven million tweets from the COVID-19 pandemic to analyze key differences between Human Superspreaders and Bots across dimensions such as linguistic complexity, toxicity, and hashtag usage. Our analysis reveals distinct communication strategies: Superspreaders tend to use more complex language and substantive content while relying less on structural elements like hashtags and emojis, likely to enhance credibility and authority. By contrast, Bots favor simpler language and strategic cross-usage of hashtags, likely to increase accessibility, facilitate infiltration into trending discussions, and amplify reach. To counter both Human Superspreaders and Bots, we propose and evaluate 27 novel metrics for quantifying the severity of conspiracy theory spread. Our findings highlight the effectiveness of an adapted H-Index for computationally feasible identification of Human Superspreaders. By identifying behavioral patterns unique to Human Superspreaders and Bots as well as providing suitable identification methods, this study provides a foundation for mitigation strategies, including platform moderation policies, temporary and permanent account suspensions, and public awareness campaigns.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e0a\u9634\u8c0b\u8bba\u4f20\u64ad\u7684\u4e24\u7c7b\u5173\u952e\u89d2\u8272\uff1a\u4eba\u7c7b\u8d85\u7ea7\u4f20\u64ad\u8005\u548c\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u5206\u6790700\u4e07\u6761COVID-19\u76f8\u5173\u63a8\u6587\u63ed\u793a\u5176\u884c\u4e3a\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa27\u4e2a\u91cf\u5316\u6307\u6807\u53ca\u57fa\u4e8eH\u6307\u6570\u7684\u8bc6\u522b\u65b9\u6cd5\u3002", "motivation": "\u9634\u8c0b\u8bba\u901a\u8fc7\u793e\u4ea4\u5a92\u4f53\u4f20\u64ad\u4f1a\u5a01\u80c1\u793e\u4f1a\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5173\u952e\u4f20\u64ad\u8005\uff08\u4eba\u7c7b\u8d85\u7ea7\u4f20\u64ad\u8005\u548c\u673a\u5668\u4eba\uff09\u7684\u7cfb\u7edf\u5206\u6790\u548c\u5b9e\u7528\u8bc6\u522b\u65b9\u6cd5\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5206\u6790700\u591a\u4e07\u6761COVID-19\u76f8\u5173\u63a8\u6587\uff0c\u4ece\u8bed\u8a00\u590d\u6742\u6027\u3001\u6bd2\u6027\u3001\u6807\u7b7e\u4f7f\u7528\u7b49\u7ef4\u5ea6\u6bd4\u8f83\u4eba\u7c7b\u8d85\u7ea7\u4f20\u64ad\u8005\u548c\u673a\u5668\u4eba\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u63d0\u51fa\u5e76\u8bc4\u4f3027\u4e2a\u91cf\u5316\u9634\u8c0b\u8bba\u4f20\u64ad\u4e25\u91cd\u6027\u7684\u65b0\u6307\u6807\u3002", "result": "\u53d1\u73b0\u4e24\u7c7b\u4f20\u64ad\u8005\u7684\u660e\u663e\u5dee\u5f02\uff1a\u4eba\u7c7b\u8d85\u7ea7\u4f20\u64ad\u8005\u4f7f\u7528\u66f4\u590d\u6742\u7684\u8bed\u8a00\u548c\u5b9e\u8d28\u6027\u5185\u5bb9\uff0c\u8f83\u5c11\u4f9d\u8d56\u6807\u7b7e\u548c\u8868\u60c5\u7b26\u53f7\u4ee5\u589e\u5f3a\u53ef\u4fe1\u5ea6\uff1b\u673a\u5668\u4eba\u5219\u4f7f\u7528\u66f4\u7b80\u5355\u7684\u8bed\u8a00\u548c\u7b56\u7565\u6027\u6807\u7b7e\u4ea4\u53c9\u4f7f\u7528\u4ee5\u63d0\u9ad8\u53ef\u8bbf\u95ee\u6027\u548c\u6e17\u900f\u6027\u3002\u6539\u8fdb\u7684H\u6307\u6570\u80fd\u6709\u6548\u8bc6\u522b\u4eba\u7c7b\u8d85\u7ea7\u4f20\u64ad\u8005\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u4eba\u7c7b\u8d85\u7ea7\u4f20\u64ad\u8005\u548c\u673a\u5668\u4eba\u7684\u72ec\u7279\u884c\u4e3a\u6a21\u5f0f\u5e76\u63d0\u4f9b\u5408\u9002\u7684\u8bc6\u522b\u65b9\u6cd5\uff0c\u4e3a\u5e73\u53f0\u5ba1\u6838\u653f\u7b56\u3001\u8d26\u6237\u5c01\u7981\u548c\u516c\u4f17\u610f\u8bc6\u8fd0\u52a8\u7b49\u7f13\u89e3\u7b56\u7565\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.04035", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.04035", "abs": "https://arxiv.org/abs/2602.04035", "authors": ["Thomas Neuner", "Henriette Padberg", "Lior Kornblum", "Eilam Yalon", "Pedram Khalili Amiri", "Shahar Kvatinsky"], "title": "A Comparative Study of Digital Memristor-Based Processing-In-Memory from a Device and Reliability Perspective", "comment": "23 pages, 12 figures, 3 tables, invited review paper, published in: https://advanced.onlinelibrary.wiley.com/doi/full/10.1002/aelm.202500348, T. Neuner and H. Padberg contributed equally to the work, S. Kvatinsky is the corresponding author", "summary": "As data-intensive applications increasingly strain conventional computing systems, processing-in-memory (PIM) has emerged as a promising paradigm to alleviate the memory wall by minimizing data transfer between memory and processing units. This review presents the recent advances in both stateful and non-stateful logic techniques for PIM, focusing on emerging nonvolatile memory technologies such as resistive random-access memory (RRAM), phase-change memory (PCM), and magnetoresistive random-access memory (MRAM). Both experimentally demonstrated and simulated logic designs are critically examined, highlighting key challenges in reliability and the role of device-level optimization in enabling scalable and commercial viable PIM systems. The review begins with an overview of relevant logic families, memristive device types, and associated reliability metrics. Each logic family is then explored in terms of how it capitalizes on distinct device properties to implement logic techniques. A comparative table of representative device stacks and performance parameters illustrates trade-offs and quality indicators. Through this comprehensive analysis, the development of optimized, robust memristive devices for next-generation PIM applications is supported.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u56de\u987e\u4e86\u5b58\u5185\u8ba1\u7b97\u4e2d\u57fa\u4e8e\u65b0\u5174\u975e\u6613\u5931\u6027\u5b58\u50a8\u5668\u7684\u72b6\u6001\u903b\u8f91\u548c\u975e\u72b6\u6001\u903b\u8f91\u6280\u672f\u8fdb\u5c55\uff0c\u91cd\u70b9\u5206\u6790RRAM\u3001PCM\u3001MRAM\u7b49\u5668\u4ef6\u7684\u903b\u8f91\u8bbe\u8ba1\u3001\u53ef\u9760\u6027\u6311\u6218\u53ca\u5668\u4ef6\u7ea7\u4f18\u5316\u5bf9\u5546\u4e1a\u5316\u5b58\u5185\u8ba1\u7b97\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u5bf9\u4f20\u7edf\u8ba1\u7b97\u7cfb\u7edf\u7684\u538b\u529b\u589e\u5927\uff0c\u5b58\u5185\u8ba1\u7b97\u6210\u4e3a\u7f13\u89e3\u5185\u5b58\u5899\u95ee\u9898\u7684\u91cd\u8981\u8303\u5f0f\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u65b0\u5174\u975e\u6613\u5931\u6027\u5b58\u50a8\u5668\u6280\u672f\u5728\u5b58\u5185\u8ba1\u7b97\u4e2d\u7684\u903b\u8f91\u5b9e\u73b0\u65b9\u6cd5\u3001\u53ef\u9760\u6027\u6311\u6218\u548c\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u63a8\u52a8\u53ef\u6269\u5c55\u7684\u5546\u4e1a\u5316\u5b58\u5185\u8ba1\u7b97\u7cfb\u7edf\u53d1\u5c55\u3002", "method": "\u7efc\u8ff0\u9996\u5148\u6982\u8ff0\u76f8\u5173\u903b\u8f91\u5bb6\u65cf\u3001\u5fc6\u963b\u5668\u4ef6\u7c7b\u578b\u548c\u53ef\u9760\u6027\u6307\u6807\uff0c\u7136\u540e\u5206\u6790\u5404\u903b\u8f91\u5bb6\u65cf\u5982\u4f55\u5229\u7528\u4e0d\u540c\u5668\u4ef6\u7279\u6027\u5b9e\u73b0\u903b\u8f91\u6280\u672f\uff0c\u901a\u8fc7\u4ee3\u8868\u6027\u5668\u4ef6\u5806\u6808\u548c\u6027\u80fd\u53c2\u6570\u7684\u5bf9\u6bd4\u8868\u5c55\u793a\u6743\u8861\u548c\u8d28\u91cf\u6307\u6807\uff0c\u5168\u9762\u8bc4\u4f30\u5b9e\u9a8c\u9a8c\u8bc1\u548c\u6a21\u62df\u7684\u903b\u8f91\u8bbe\u8ba1\u3002", "result": "\u7cfb\u7edf\u5206\u6790\u4e86RRAM\u3001PCM\u3001MRAM\u7b49\u65b0\u5174\u5b58\u50a8\u5668\u5728\u5b58\u5185\u8ba1\u7b97\u4e2d\u7684\u903b\u8f91\u6280\u672f\u5b9e\u73b0\uff0c\u8bc6\u522b\u4e86\u53ef\u9760\u6027\u65b9\u9762\u7684\u5173\u952e\u6311\u6218\uff0c\u5f3a\u8c03\u4e86\u5668\u4ef6\u7ea7\u4f18\u5316\u5bf9\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u5546\u4e1a\u5316\u5b58\u5185\u8ba1\u7b97\u7cfb\u7edf\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u5b58\u5185\u8ba1\u7b97\u5e94\u7528\u7684\u4f18\u5316\u3001\u9c81\u68d2\u5fc6\u963b\u5668\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "conclusion": "\u901a\u8fc7\u5168\u9762\u5206\u6790\u72b6\u6001\u548c\u975e\u72b6\u6001\u903b\u8f91\u6280\u672f\uff0c\u8be5\u7efc\u8ff0\u652f\u6301\u5f00\u53d1\u4f18\u5316\u7684\u9c81\u68d2\u5fc6\u963b\u5668\u4ef6\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u5b58\u5185\u8ba1\u7b97\u5e94\u7528\u5960\u5b9a\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u5668\u4ef6\u7279\u6027\u4e0e\u903b\u8f91\u8bbe\u8ba1\u7684\u534f\u540c\u4f18\u5316\u5bf9\u5b9e\u73b0\u5546\u4e1a\u53ef\u884c\u5b58\u5185\u8ba1\u7b97\u7cfb\u7edf\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2602.03943", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.03943", "abs": "https://arxiv.org/abs/2602.03943", "authors": ["Sangpil Youm", "Nari Yoo", "Sou Hyun Jang"], "title": "Predicting Depressive Symptoms through Emotion Pairs within Asian American Families", "comment": "Accepted to 10th International Conference on Computational Social Science IC2S2, July 17-20, 2024, Philadelphia, USA", "summary": "Studies on intergenerational relationships between parents and children in Asian American families highlight their impact on mental health and well-being. This study investigates the role of ambivalent emotions in online narratives shared by Asian and Asian American children on the subreddit, r/Asianparentstories. By employing a BERT-based model to detect emotion at the sentence level and depressive symptoms at the post level, we analyze mixed feelings to better understand how they predict depressive symptoms. First, among 28 detectable, eight (realization, approval, sadness, anger, curiosity, annoyance, disappointment, disapproval) comprise over 50%, exhibiting significant co-occurrence among themselves and with other emotions. Second, we find the co-occurrence of multiple emotions, indicating that emotions in a single post are not limited to consistently positive or negative feelings. Finally, our findings indicate that while negative emotion pairs (e.g., confusion-grief, anger-grief) are associated with depressive symptoms, positive emotion pairs (e.g., admiration-realization, amusement-joy) negatively correlate with depressive symptoms, and combinations of ambivalent emotions indicate varied results in predicting depressive symptoms. These findings highlight the importance of automated emotion classification and the need to consider emotional ambivalence, which holds practical and clinical implications for understanding the dynamics of parent-child relationships.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7BERT\u6a21\u578b\u5206\u6790\u4e9a\u88d4\u7f8e\u56fd\u5b50\u5973\u5728Reddit\u4e0a\u7684\u60c5\u611f\u8868\u8fbe\uff0c\u53d1\u73b0\u6df7\u5408\u60c5\u611f\u5bf9\u6291\u90c1\u75c7\u72b6\u7684\u9884\u6d4b\u4f5c\u7528\uff0c\u5f3a\u8c03\u60c5\u611f\u77db\u76fe\u6027\u5728\u4eb2\u5b50\u5173\u7cfb\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u4e9a\u88d4\u7f8e\u56fd\u5bb6\u5ead\u4eb2\u5b50\u5173\u7cfb\u5bf9\u5fc3\u7406\u5065\u5eb7\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u5728\u7ebf\u53d9\u4e8b\u4e2d\u77db\u76fe\u60c5\u611f\u7684\u4f5c\u7528\uff0c\u4ee5\u66f4\u597d\u7406\u89e3\u60c5\u611f\u8868\u8fbe\u4e0e\u6291\u90c1\u75c7\u72b6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u4f7f\u7528BERT\u6a21\u578b\u5206\u6790r/Asianparentstories\u5b50\u7248\u5757\u5185\u5bb9\uff0c\u5728\u53e5\u5b50\u5c42\u9762\u68c0\u6d4b\u60c5\u611f\uff0c\u5728\u5e16\u5b50\u5c42\u9762\u68c0\u6d4b\u6291\u90c1\u75c7\u72b6\uff0c\u7814\u7a76\u591a\u79cd\u60c5\u611f\u5171\u73b0\u6a21\u5f0f\u53ca\u5176\u4e0e\u6291\u90c1\u75c7\u72b6\u7684\u5173\u8054\u3002", "result": "\u53d1\u73b08\u79cd\u4e3b\u8981\u60c5\u611f\u5360\u4e3b\u5bfc\u4e14\u663e\u8457\u5171\u73b0\uff1b\u5e16\u5b50\u4e2d\u5e38\u5305\u542b\u591a\u79cd\u77db\u76fe\u60c5\u611f\uff1b\u8d1f\u9762\u60c5\u611f\u7ec4\u5408\u4e0e\u6291\u90c1\u75c7\u72b6\u6b63\u76f8\u5173\uff0c\u6b63\u9762\u60c5\u611f\u7ec4\u5408\u8d1f\u76f8\u5173\uff0c\u77db\u76fe\u60c5\u611f\u7ec4\u5408\u9884\u6d4b\u7ed3\u679c\u591a\u6837\u3002", "conclusion": "\u81ea\u52a8\u5316\u60c5\u611f\u5206\u7c7b\u5bf9\u7406\u89e3\u4eb2\u5b50\u5173\u7cfb\u52a8\u6001\u5f88\u91cd\u8981\uff0c\u60c5\u611f\u77db\u76fe\u6027\u5177\u6709\u5b9e\u8df5\u548c\u4e34\u5e8a\u610f\u4e49\uff0c\u9700\u8981\u66f4\u7ec6\u81f4\u5730\u8003\u8651\u6df7\u5408\u60c5\u611f\u5728\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2602.03900", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03900", "abs": "https://arxiv.org/abs/2602.03900", "authors": ["Erik Goh", "John Kos", "Ashok Goel"], "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks", "comment": null, "summary": "Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.", "AI": {"tldr": "TMK\u6846\u67b6\u63d0\u793a\u663e\u8457\u63d0\u5347LLM\u5728\u7b26\u53f7\u89c4\u5212\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4ece31.5%\u63d0\u5347\u81f397.3%\uff0c\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u4ece\u8bed\u8a00\u6a21\u5f0f\u8f6c\u5411\u5f62\u5f0f\u5316\u4ee3\u7801\u6267\u884c\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u6280\u672f\u5982CoT\u5728LLM\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6846\u67b6\u6765\u63d0\u5347LLM\u7684\u89c4\u5212\u548c\u63a8\u7406\u80fd\u529b\u3002TMK\u6846\u67b6\u56e0\u5176\u80fd\u6355\u6349\u56e0\u679c\u3001\u76ee\u7684\u8bba\u548c\u5c42\u6b21\u5316\u63a8\u7406\u7ed3\u6784\uff0c\u4ee5\u53ca\u660e\u786e\u7684\u4efb\u52a1\u5206\u89e3\u673a\u5236\uff0c\u6709\u671b\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u7f3a\u9677\u3002", "method": "\u91c7\u7528Task-Method-Knowledge (TMK)\u6846\u67b6\u8fdb\u884c\u7ed3\u6784\u5316\u63d0\u793a\uff0c\u5728PlanBench\u57fa\u51c6\u6d4b\u8bd5\u7684Blocksworld\u9886\u57df\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30TMK\u662f\u5426\u80fd\u5e2e\u52a9\u8bed\u8a00\u6a21\u578b\u5c06\u590d\u6742\u89c4\u5212\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u4efb\u52a1\u3002", "result": "TMK\u63d0\u793a\u4f7f\u63a8\u7406\u6a21\u578b\u5728\u4e0d\u900f\u660e\u7684\u7b26\u53f7\u4efb\u52a1\uff08PlanBench\u4e2dBlocksworld\u7684\u968f\u673a\u7248\u672c\uff09\u4e0a\u51c6\u786e\u7387\u4ece31.5%\u63d0\u5347\u81f397.3%\uff0c\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u53cd\u8f6c\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u4ece\u8bed\u8a00\u6a21\u5f0f\u8f6c\u5411\u5f62\u5f0f\u5316\u4ee3\u7801\u6267\u884c\u8def\u5f84\u7684\u673a\u5236\u3002", "conclusion": "TMK\u4e0d\u4ec5\u63d0\u4f9b\u4e0a\u4e0b\u6587\uff0c\u66f4\u91cd\u8981\u7684\u662f\u4f5c\u4e3a\u4e00\u79cd\u673a\u5236\uff0c\u5f15\u5bfc\u63a8\u7406\u6a21\u578b\u8fdc\u79bb\u9ed8\u8ba4\u7684\u8bed\u8a00\u6a21\u5f0f\uff0c\u5728\u5b9e\u9a8c\u4e2d\u6fc0\u6d3b\u5f62\u5f0f\u5316\u3001\u4ee3\u7801\u6267\u884c\u7684\u8def\u5f84\uff0c\u4ece\u800c\u5728\u7b26\u53f7\u64cd\u4f5c\u4efb\u52a1\u4e0a\u5b9e\u73b0\u7a81\u7834\u6027\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.04674", "categories": ["cs.SI", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.04674", "abs": "https://arxiv.org/abs/2602.04674", "authors": ["Eun Cheol Choi", "Lindsay E. Young", "Emilio Ferrara"], "title": "Overstating Attitudes, Ignoring Networks: LLM Biases in Simulating Misinformation Susceptibility", "comment": null, "summary": "Large language models (LLMs) are increasingly used as proxies for human judgment in computational social science, yet their ability to reproduce patterns of susceptibility to misinformation remains unclear. We test whether LLM-simulated survey respondents, prompted with participant profiles drawn from social survey data measuring network, demographic, attitudinal and behavioral features, can reproduce human patterns of misinformation belief and sharing. Using three online surveys as baselines, we evaluate whether LLM outputs match observed response distributions and recover feature-outcome associations present in the original survey data. LLM-generated responses capture broad distributional tendencies and show modest correlation with human responses, but consistently overstate the association between belief and sharing. Linear models fit to simulated responses exhibit substantially higher explained variance and place disproportionate weight on attitudinal and behavioral features, while largely ignoring personal network characteristics, relative to models fit to human responses. Analyses of model-generated reasoning and LLM training data suggest that these distortions reflect systematic biases in how misinformation-related concepts are represented. Our findings suggest that LLM-based survey simulations are better suited for diagnosing systematic divergences from human judgment than for substituting it.", "AI": {"tldr": "LLM\u6a21\u62df\u8c03\u67e5\u53d7\u8bbf\u8005\u80fd\u6355\u6349\u4eba\u7c7b\u9519\u8bef\u4fe1\u606f\u4fe1\u5ff5\u7684\u5206\u5e03\u8d8b\u52bf\uff0c\u4f46\u4f1a\u5938\u5927\u4fe1\u5ff5\u4e0e\u5206\u4eab\u7684\u5173\u8054\uff0c\u8fc7\u5ea6\u91cd\u89c6\u6001\u5ea6\u884c\u4e3a\u7279\u5f81\u800c\u5ffd\u7565\u793e\u4ea4\u7f51\u7edc\u7279\u5f81\uff0c\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\u3002", "motivation": "\u8bc4\u4f30LLM\u4f5c\u4e3a\u4eba\u7c7b\u5224\u65ad\u4ee3\u7406\u5728\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u80fd\u5426\u51c6\u786e\u518d\u73b0\u4eba\u7c7b\u5bf9\u9519\u8bef\u4fe1\u606f\u7684\u6613\u611f\u6027\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u5728\u7ebf\u8c03\u67e5\u4f5c\u4e3a\u57fa\u7ebf\uff0c\u8ba9LLM\u6a21\u62df\u53d7\u8bbf\u8005\uff08\u57fa\u4e8e\u793e\u4ea4\u7f51\u7edc\u3001\u4eba\u53e3\u7edf\u8ba1\u3001\u6001\u5ea6\u548c\u884c\u4e3a\u7279\u5f81\u7684\u4e2a\u4eba\u8d44\u6599\uff09\uff0c\u6bd4\u8f83LLM\u8f93\u51fa\u4e0e\u4eba\u7c7b\u54cd\u5e94\u7684\u5206\u5e03\u548c\u7279\u5f81-\u7ed3\u679c\u5173\u8054\u3002", "result": "LLM\u751f\u6210\u7684\u54cd\u5e94\u80fd\u6355\u6349\u5e7f\u6cdb\u7684\u5206\u5e03\u8d8b\u52bf\uff0c\u4e0e\u4eba\u7c7b\u54cd\u5e94\u6709\u9002\u5ea6\u76f8\u5173\u6027\uff0c\u4f46\u6301\u7eed\u5938\u5927\u4fe1\u5ff5\u4e0e\u5206\u4eab\u7684\u5173\u8054\u3002\u6a21\u62df\u54cd\u5e94\u7684\u7ebf\u6027\u6a21\u578b\u89e3\u91ca\u65b9\u5dee\u66f4\u9ad8\uff0c\u8fc7\u5ea6\u91cd\u89c6\u6001\u5ea6\u884c\u4e3a\u7279\u5f81\u800c\u5ffd\u7565\u4e2a\u4eba\u7f51\u7edc\u7279\u5f81\u3002", "conclusion": "LLM\u57fa\u4e8e\u8c03\u67e5\u6a21\u62df\u66f4\u9002\u5408\u8bca\u65ad\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u5224\u65ad\uff0c\u56e0\u4e3a\u5b58\u5728\u9519\u8bef\u4fe1\u606f\u76f8\u5173\u6982\u5ff5\u7684\u8868\u5f81\u504f\u5dee\u3002"}}
{"id": "2602.04164", "categories": ["cs.ET", "stat.AP", "stat.CO", "stat.OT"], "pdf": "https://arxiv.org/pdf/2602.04164", "abs": "https://arxiv.org/abs/2602.04164", "authors": ["Yuan Cai", "Mustafa Demir", "Farzan Sasangohar", "Mohsen Zare"], "title": "The Dynamics of Attention across Automated and Manual Driving Modes: A Driving Simulation Study", "comment": null, "summary": "This study aims to explore the dynamics of driver attention to various zones, including the road, the central mirror, the embedded Human-Machine Interface (HMI), and the speedometer, across different driving modes in AVs. The integration of autonomous vehicles (AVs) into transportation systems has introduced critical safety concerns, particularly regarding driver re-engagement during mode transitions. Past accidents underscore the risks of overreliance on automation and highlight the need to understand dynamic attention allocation to support safety in autonomous driving. A high-fidelity driving simulation was conducted. Eye-tracking technology was used to measure fixation duration, fixation count, and time to first fixation across distinct driving modes (automated, manual, and transition), which were then used to assess how drivers allocated attention to various areas of interest (AOIs). Findings show that drivers' attention varies significantly across driving modes. In manual mode, attention consistently focuses on the road, while in automated mode, prolonged fixation on the embedded HMI was observed. During the handover and takeover phases, attention shifts dynamically between environmental and technological elements. The study reveals that driver attention allocation is mode-dependent. These findings inform the design of adaptive HMIs in AVs that align with drivers' attention patterns. By presenting relevant information according to the driving context, such systems can enhance driver-vehicle interaction, support effective transitions, and improve overall safety. Systematic analysis of visual attention dynamics across driving modes is gaining prominence, as it informs adaptive HMI designs and driver readiness interventions. The GLMM findings can be directly applied to the design of adaptive HMIs or driver training programs to enhance attention and improve safety.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u81ea\u52a8\u9a7e\u9a76\u4e2d\u9a7e\u9a76\u5458\u5728\u4e0d\u540c\u9a7e\u9a76\u6a21\u5f0f\uff08\u81ea\u52a8\u3001\u624b\u52a8\u3001\u8fc7\u6e21\uff09\u4e0b\u5bf9\u9053\u8def\u3001\u4e2d\u592e\u540e\u89c6\u955c\u3001\u5d4c\u5165\u5f0fHMI\u548c\u901f\u5ea6\u8868\u7b49\u533a\u57df\u7684\u6ce8\u610f\u529b\u52a8\u6001\u5206\u914d\uff0c\u53d1\u73b0\u6ce8\u610f\u529b\u6a21\u5f0f\u968f\u9a7e\u9a76\u6a21\u5f0f\u53d8\u5316\u663e\u8457\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u96c6\u6210\u5230\u4ea4\u901a\u7cfb\u7edf\u5f15\u53d1\u4e86\u5b89\u5168\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u6a21\u5f0f\u8f6c\u6362\u671f\u95f4\u7684\u9a7e\u9a76\u5458\u91cd\u65b0\u53c2\u4e0e\u3002\u8fc7\u53bb\u7684\u4e8b\u6545\u51f8\u663e\u4e86\u5bf9\u81ea\u52a8\u5316\u7684\u8fc7\u5ea6\u4f9d\u8d56\u98ce\u9669\uff0c\u9700\u8981\u7406\u89e3\u52a8\u6001\u6ce8\u610f\u529b\u5206\u914d\u4ee5\u652f\u6301\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u3002", "method": "\u91c7\u7528\u9ad8\u4fdd\u771f\u9a7e\u9a76\u6a21\u62df\uff0c\u4f7f\u7528\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u6d4b\u91cf\u4e0d\u540c\u9a7e\u9a76\u6a21\u5f0f\uff08\u81ea\u52a8\u3001\u624b\u52a8\u548c\u8fc7\u6e21\uff09\u4e0b\u7684\u6ce8\u89c6\u6301\u7eed\u65f6\u95f4\u3001\u6ce8\u89c6\u6b21\u6570\u548c\u9996\u6b21\u6ce8\u89c6\u65f6\u95f4\uff0c\u8bc4\u4f30\u9a7e\u9a76\u5458\u5bf9\u4e0d\u540c\u5174\u8da3\u533a\u57df\u7684\u6ce8\u610f\u529b\u5206\u914d\u3002", "result": "\u9a7e\u9a76\u5458\u6ce8\u610f\u529b\u5728\u4e0d\u540c\u9a7e\u9a76\u6a21\u5f0f\u4e0b\u5dee\u5f02\u663e\u8457\uff1a\u624b\u52a8\u6a21\u5f0f\u4e0b\u6ce8\u610f\u529b\u6301\u7eed\u96c6\u4e2d\u5728\u9053\u8def\u4e0a\uff1b\u81ea\u52a8\u6a21\u5f0f\u4e0b\u89c2\u5bdf\u5230\u5bf9\u5d4c\u5165\u5f0fHMI\u7684\u957f\u65f6\u95f4\u6ce8\u89c6\uff1b\u5728\u4ea4\u63a5\u548c\u63a5\u7ba1\u9636\u6bb5\uff0c\u6ce8\u610f\u529b\u5728\u73af\u5883\u548c\u6280\u672f\u5143\u7d20\u4e4b\u95f4\u52a8\u6001\u8f6c\u79fb\u3002", "conclusion": "\u9a7e\u9a76\u5458\u6ce8\u610f\u529b\u5206\u914d\u662f\u6a21\u5f0f\u4f9d\u8d56\u7684\uff0c\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u8bbe\u8ba1\u7b26\u5408\u9a7e\u9a76\u5458\u6ce8\u610f\u529b\u6a21\u5f0f\u7684\u81ea\u9002\u5e94HMI\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002\u901a\u8fc7\u6839\u636e\u9a7e\u9a76\u60c5\u5883\u5448\u73b0\u76f8\u5173\u4fe1\u606f\uff0c\u6b64\u7c7b\u7cfb\u7edf\u53ef\u4ee5\u589e\u5f3a\u9a7e\u9a76\u5458-\u8f66\u8f86\u4ea4\u4e92\uff0c\u652f\u6301\u6709\u6548\u8fc7\u6e21\u5e76\u63d0\u9ad8\u6574\u4f53\u5b89\u5168\u3002"}}
{"id": "2602.04554", "categories": ["stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.04554", "abs": "https://arxiv.org/abs/2602.04554", "authors": ["Zhexuan Yang", "Duchwan Ryu", "Feng Luan"], "title": "mmcmcBayes:An R Package Implementing a Multistage MCMC Framework for Detecting the Differentially Methylated Regions", "comment": "27 pages, 3 figures", "summary": "Identifying differentially methylated regions is an important task in epigenome-wide association studies, where differential signals often arise across groups of neighboring CpG sites. Many existing methods detect differentially methylated regions by aggregating CpG-level test results, which may limit their ability to capture complex regional methylation patterns. In this paper, we introduce the R package mmcmcBayes, which implements a multistage Markov chain Monte Carlo procedure for region-level detection of differentially methylated regions. The method models sample-wise regional methylation summaries using the alpha-skew generalized normal distribution and evaluates evidence for differential methylation between groups through Bayes factors. We use a multistage region-splitting strategy to refine candidate regions based on statistical evidence. We describe the underlying methodology and software implementation, and illustrate its performance through simulation studies and applications to Illumina 450K methylation data. The mmcmcBayes package provides a practical region-level alternative to existing CpG-based differentially methylated regions detection methods and includes supporting functions for summarizing, comparing, and visualizing detected regions.", "AI": {"tldr": "mmcmcBayes\u662f\u4e00\u4e2aR\u5305\uff0c\u4f7f\u7528\u591a\u9636\u6bb5MCMC\u65b9\u6cd5\u68c0\u6d4b\u5dee\u5f02\u7532\u57fa\u5316\u533a\u57df\uff0c\u901a\u8fc7\u533a\u57df\u7ea7\u5efa\u6a21\u548c\u8d1d\u53f6\u65af\u56e0\u5b50\u8bc4\u4f30\u7ec4\u95f4\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u805a\u5408CpG\u4f4d\u70b9\u6d4b\u8bd5\u7ed3\u679c\u6765\u68c0\u6d4b\u5dee\u5f02\u7532\u57fa\u5316\u533a\u57df\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u5176\u6355\u6349\u590d\u6742\u533a\u57df\u7532\u57fa\u5316\u6a21\u5f0f\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u533a\u57df\u7ea7\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u7a0b\u5e8f\uff0c\u4f7f\u7528alpha-skew\u5e7f\u4e49\u6b63\u6001\u5206\u5e03\u5efa\u6a21\u6837\u672c\u533a\u57df\u7532\u57fa\u5316\u6458\u8981\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u56e0\u5b50\u8bc4\u4f30\u7ec4\u95f4\u5dee\u5f02\u7532\u57fa\u5316\u8bc1\u636e\uff0c\u5e76\u4f7f\u7528\u591a\u9636\u6bb5\u533a\u57df\u5206\u5272\u7b56\u7565\u57fa\u4e8e\u7edf\u8ba1\u8bc1\u636e\u7ec6\u5316\u5019\u9009\u533a\u57df\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548cIllumina 450K\u7532\u57fa\u5316\u6570\u636e\u5e94\u7528\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6027\u80fd\u3002mmcmcBayes\u5305\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u533a\u57df\u7ea7\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u5305\u542b\u7528\u4e8e\u603b\u7ed3\u3001\u6bd4\u8f83\u548c\u53ef\u89c6\u5316\u68c0\u6d4b\u533a\u57df\u7684\u8f85\u52a9\u51fd\u6570\u3002", "conclusion": "mmcmcBayes\u5305\u4e3a\u73b0\u6709\u57fa\u4e8eCpG\u7684\u5dee\u5f02\u7532\u57fa\u5316\u533a\u57df\u68c0\u6d4b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u533a\u57df\u7ea7\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u590d\u6742\u533a\u57df\u7532\u57fa\u5316\u6a21\u5f0f\u3002"}}
{"id": "2602.04064", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.04064", "abs": "https://arxiv.org/abs/2602.04064", "authors": ["Neil Majithia", "Rajat Shinde", "Zo Chapman", "Prajun Trital", "Jordan Decker", "Manil Maskey", "Elena Simperl", "Nigel Shadbolt"], "title": "The CitizenQuery Benchmark: A Novel Dataset and Evaluation Pipeline for Measuring LLM Performance in Citizen Query Tasks", "comment": null, "summary": "\"Citizen queries\" are questions asked by an individual about government policies, guidance, and services that are relevant to their circumstances, encompassing a range of topics including benefits, taxes, immigration, employment, public health, and more. This represents a compelling use case for Large Language Models (LLMs) that respond to citizen queries with information that is adapted to a user's context and communicated according to their needs. However, in this use case, any misinformation could have severe, negative, likely invisible ramifications for an individual placing their trust in a model's response.\n  To this effect, we introduce CitizenQuery-UK, a benchmark dataset of 22 thousand pairs of citizen queries and responses that have been synthetically generated from the swathes of public information on $gov.uk$ about government in the UK. We present the curation methodology behind CitizenQuery-UK and an overview of its contents. We also introduce a methodology for the benchmarking of LLMs with the dataset, using an adaptation of FActScore to benchmark 11 models for factuality, abstention frequency, and verbosity. We document these results, and interpret them in the context of the public sector, finding that: (i) there are distinct performance profiles across model families, but each is competitive; (ii) high variance undermines utility; (iii) abstention is low and verbosity is high, with implications on reliability; and (iv) more trustworthy AI requires acknowledged \"fallibility\" in the way it interacts with users.\n  The contribution of our research lies in assessing the trustworthiness of LLMs in citizen query tasks; as we see a world of increasing AI integration into day-to-day life, our benchmark, built entirely on open data, lays the foundations for better evidenced decision-making regarding AI and the public sector.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CitizenQuery-UK\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u56de\u7b54\u516c\u6c11\u653f\u5e9c\u76f8\u5173\u67e5\u8be2\u65f6\u7684\u53ef\u4fe1\u5ea6\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e8b\u5b9e\u6027\u3001\u5f03\u6743\u9891\u7387\u548c\u5197\u957f\u5ea6\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u9700\u8981\u627f\u8ba4AI\u7684\"\u6613\u9519\u6027\"\u3002", "motivation": "\u516c\u6c11\u67e5\u8be2\u662f\u4e2a\u4eba\u5411\u653f\u5e9c\u8be2\u95ee\u653f\u7b56\u3001\u6307\u5bfc\u548c\u670d\u52a1\u7684\u95ee\u9898\uff0c\u6d89\u53ca\u798f\u5229\u3001\u7a0e\u6536\u3001\u79fb\u6c11\u7b49\u591a\u4e2a\u91cd\u8981\u9886\u57df\u3002\u867d\u7136LLMs\u6709\u6f5c\u529b\u6839\u636e\u7528\u6237\u80cc\u666f\u63d0\u4f9b\u4e2a\u6027\u5316\u56de\u7b54\uff0c\u4f46\u4efb\u4f55\u9519\u8bef\u4fe1\u606f\u90fd\u53ef\u80fd\u5bf9\u4fe1\u4efb\u6a21\u578b\u7684\u4e2a\u4eba\u4ea7\u751f\u4e25\u91cd\u4e14\u96be\u4ee5\u5bdf\u89c9\u7684\u8d1f\u9762\u5f71\u54cd\u3002\u56e0\u6b64\u9700\u8981\u8bc4\u4f30LLMs\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "1) \u521b\u5efaCitizenQuery-UK\u57fa\u51c6\u6570\u636e\u96c6\uff1a\u4ece\u82f1\u56fd\u653f\u5e9c\u7f51\u7ad9gov.uk\u7684\u516c\u5f00\u4fe1\u606f\u4e2d\u5408\u6210\u751f\u6210\u4e8622,000\u5bf9\u516c\u6c11\u67e5\u8be2\u548c\u56de\u7b54\uff1b2) \u63d0\u51fa\u57fa\u4e8eFActScore\u7684\u8bc4\u4f30\u65b9\u6cd5\uff1a\u5bf911\u4e2aLLMs\u8fdb\u884c\u4e8b\u5b9e\u6027\u3001\u5f03\u6743\u9891\u7387\u548c\u5197\u957f\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(i) \u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u6709\u72ec\u7279\u7684\u6027\u80fd\u7279\u5f81\uff0c\u4f46\u90fd\u5177\u5907\u7ade\u4e89\u529b\uff1b(ii) \u9ad8\u65b9\u5dee\u524a\u5f31\u4e86\u6a21\u578b\u7684\u5b9e\u7528\u6027\uff1b(iii) \u5f03\u6743\u7387\u4f4e\u800c\u5197\u957f\u5ea6\u9ad8\uff0c\u5f71\u54cd\u53ef\u9760\u6027\uff1b(iv) \u66f4\u53ef\u4fe1\u7684AI\u9700\u8981\u5728\u4e0e\u7528\u6237\u4e92\u52a8\u65f6\u627f\u8ba4\u5176\"\u6613\u9519\u6027\"\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b8c\u5168\u57fa\u4e8e\u5f00\u653e\u6570\u636e\u6784\u5efa\u7684\u57fa\u51c6\uff0c\u4e3aAI\u5728\u516c\u5171\u90e8\u95e8\u5e94\u7528\u7684\u51b3\u7b56\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8bc1\u636e\u57fa\u7840\u3002\u968f\u7740AI\u65e5\u76ca\u878d\u5165\u65e5\u5e38\u751f\u6d3b\uff0c\u8bc4\u4f30LLMs\u5728\u516c\u6c11\u67e5\u8be2\u4efb\u52a1\u4e2d\u7684\u53ef\u4fe1\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5efa\u7acb\u627f\u8ba4AI\u5c40\u9650\u6027\u7684\u4ea4\u4e92\u65b9\u5f0f\u3002"}}
{"id": "2602.03950", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03950", "abs": "https://arxiv.org/abs/2602.03950", "authors": ["Aditya Basarkar", "Benyamin Tabarsi", "Tiffany Barnes", "Dongkuan", "Xu"], "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation", "comment": "9 pages, 7 figures, submitted to ACL ARR 2026", "summary": "Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.", "AI": {"tldr": "IIPC\u662f\u4e00\u79cd\u8fed\u4ee3\u6539\u8fdb\u7684\u7a0b\u5e8f\u6784\u9020\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6267\u884c\u53cd\u9988\u548c\u94fe\u5f0f\u601d\u7ef4\u6765\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u4ecd\u7f3a\u4e4f\u53ef\u9760\u53ef\u4fee\u6b63\u7684\u63a8\u7406\u8fc7\u7a0b\u8868\u793a\uff0c\u8981\u4e48\u91c7\u7528\u50f5\u5316\u7684\u987a\u5e8f\u6d41\u7a0b\u65e0\u6cd5\u4fee\u6b63\u65e9\u671f\u9519\u8bef\uff0c\u8981\u4e48\u4f9d\u8d56\u53ef\u80fd\u5931\u6548\u7684\u542f\u53d1\u5f0f\u81ea\u8bc4\u4f30\u3002\u6b64\u5916\uff0c\u7a0b\u5e8f\u5316\u4e0a\u4e0b\u6587\u53ef\u80fd\u5206\u6563\u8bed\u8a00\u6a21\u578b\u7684\u6ce8\u610f\u529b\u5e76\u964d\u4f4e\u51c6\u786e\u6027\u3002", "method": "IIPC\uff08\u8fed\u4ee3\u6539\u8fdb\u7684\u7a0b\u5e8f\u6784\u9020\uff09\u65b9\u6cd5\u8fed\u4ee3\u5730\u7cbe\u70bc\u7a0b\u5e8f\u5316\u63a8\u7406\u94fe\uff0c\u5c06\u6267\u884c\u53cd\u9988\u4e0e\u57fa\u7840LLM\u7684\u539f\u751f\u94fe\u5f0f\u601d\u7ef4\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u4ee5\u4fdd\u6301\u9ad8\u5c42\u6b21\u4e0a\u4e0b\u6587\u805a\u7126\u3002", "result": "IIPC\u5728\u591a\u4e2a\u57fa\u7840LLM\u4e0a\u7684\u5927\u591a\u6570\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u7ade\u4e89\u65b9\u6cd5\u3002", "conclusion": "IIPC\u901a\u8fc7\u8fed\u4ee3\u7cbe\u70bc\u7a0b\u5e8f\u5316\u63a8\u7406\u94fe\u548c\u7ed3\u5408\u6267\u884c\u53cd\u9988\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\uff0c\u76f8\u5173\u4ee3\u7801\u5df2\u5f00\u6e90\u53d1\u5e03\u3002"}}
{"id": "2602.04694", "categories": ["cs.SI", "cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.04694", "abs": "https://arxiv.org/abs/2602.04694", "authors": ["Maya Le", "Pawe\u0142 Pra\u0142at", "Aaron Smith", "Fran\u00e7ois Th\u00e9berge"], "title": "The Needle is a Thread: Finding Planted Paths in Noisy Process Trees", "comment": "15 pages, 9 figures", "summary": "Motivated by applications in cybersecurity such as finding meaningful sequences of malware-related events buried inside large amounts of computer log data, we introduce the \"planted path\" problem and propose an algorithm to find fuzzy matchings between two trees. This algorithm can be used as a \"building block\" for more complicated workflows. We demonstrate usefulness of a few of such workflows in mining synthetically generated data as well as real-world ACME cybersecurity datasets.", "AI": {"tldr": "\u63d0\u51fa\"\u690d\u5165\u8def\u5f84\"\u95ee\u9898\uff0c\u5f00\u53d1\u7528\u4e8e\u5728\u6811\u7ed3\u6784\u4e2d\u5bfb\u627e\u6a21\u7cca\u5339\u914d\u7684\u7b97\u6cd5\uff0c\u4f5c\u4e3a\u7f51\u7edc\u5b89\u5168\u4e2d\u6076\u610f\u8f6f\u4ef6\u4e8b\u4ef6\u5e8f\u5217\u68c0\u6d4b\u7684\u57fa\u7840\u6a21\u5757", "motivation": "\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u9700\u6c42\uff0c\u7279\u522b\u662f\u4ece\u5927\u91cf\u8ba1\u7b97\u673a\u65e5\u5fd7\u6570\u636e\u4e2d\u68c0\u6d4b\u6076\u610f\u8f6f\u4ef6\u76f8\u5173\u4e8b\u4ef6\u5e8f\u5217", "method": "\u5f15\u5165\"\u690d\u5165\u8def\u5f84\"\u95ee\u9898\uff0c\u63d0\u51fa\u5728\u6811\u7ed3\u6784\u4e2d\u5bfb\u627e\u6a21\u7cca\u5339\u914d\u7684\u7b97\u6cd5\uff0c\u4f5c\u4e3a\u590d\u6742\u5de5\u4f5c\u6d41\u7a0b\u7684\u57fa\u7840\u6a21\u5757", "result": "\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9eACME\u7f51\u7edc\u5b89\u5168\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5de5\u4f5c\u6d41\u7a0b\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u7b97\u6cd5\u53ef\u4f5c\u4e3a\u7f51\u7edc\u5b89\u5168\u4e2d\u6076\u610f\u8f6f\u4ef6\u4e8b\u4ef6\u5e8f\u5217\u68c0\u6d4b\u7684\u57fa\u7840\u6784\u5efa\u6a21\u5757\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2602.04411", "categories": ["cs.ET", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.04411", "abs": "https://arxiv.org/abs/2602.04411", "authors": ["Tongtong Feng", "Xin Wang", "Wenwu Zhu"], "title": "Self-evolving Embodied AI", "comment": null, "summary": "Embodied Artificial Intelligence (AI) is an intelligent system formed by agents and their environment through active perception, embodied cognition, and action interaction. Existing embodied AI remains confined to human-crafted setting, in which agents are trained on given memory and construct models for given tasks, enabling fixed embodiments to interact with relatively static environments. Such methods fail in in-the-wild setting characterized by variable embodiments and dynamic open environments. This paper introduces self-evolving embodied AI, a new paradigm in which agents operate based on their changing state and environment with memory self-updating, task self-switching, environment self-prediction, embodiment self-adaptation, and model self-evolution, aiming to achieve continually adaptive intelligence with autonomous evolution. Specifically, we present the definition, framework, components, and mechanisms of self-evolving embodied AI, systematically review state-of-the-art works for realized components, discuss practical applications, and point out future research directions. We believe that self-evolving embodied AI enables agents to autonomously learn and interact with environments in a human-like manner and provide a new perspective toward general artificial intelligence.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u6f14\u5316\u5177\u8eabAI\u65b0\u8303\u5f0f\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u5728\u52a8\u6001\u5f00\u653e\u73af\u5883\u4e2d\u901a\u8fc7\u8bb0\u5fc6\u81ea\u66f4\u65b0\u3001\u4efb\u52a1\u81ea\u5207\u6362\u3001\u73af\u5883\u81ea\u9884\u6d4b\u3001\u5177\u8eab\u81ea\u9002\u5e94\u548c\u6a21\u578b\u81ea\u6f14\u5316\u5b9e\u73b0\u6301\u7eed\u81ea\u9002\u5e94\u667a\u80fd\u3002", "motivation": "\u73b0\u6709\u5177\u8eabAI\u5c40\u9650\u4e8e\u4eba\u5de5\u8bbe\u5b9a\u73af\u5883\uff0c\u667a\u80fd\u4f53\u5728\u7ed9\u5b9a\u8bb0\u5fc6\u548c\u4efb\u52a1\u4e0a\u8bad\u7ec3\uff0c\u65e0\u6cd5\u9002\u5e94\u91ce\u5916\u73af\u5883\u4e2d\u53ef\u53d8\u7684\u5177\u8eab\u5f62\u6001\u548c\u52a8\u6001\u5f00\u653e\u73af\u5883\u3002", "method": "\u63d0\u51fa\u81ea\u6f14\u5316\u5177\u8eabAI\u6846\u67b6\uff0c\u5305\u62ec\u5b9a\u4e49\u3001\u6846\u67b6\u3001\u7ec4\u4ef6\u548c\u673a\u5236\uff0c\u7cfb\u7edf\u56de\u987e\u73b0\u6709\u7ec4\u4ef6\u5b9e\u73b0\uff0c\u8ba8\u8bba\u5b9e\u9645\u5e94\u7528\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u7684\u7814\u7a76\u8303\u5f0f\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u57fa\u4e8e\u81ea\u8eab\u72b6\u6001\u548c\u73af\u5883\u53d8\u5316\u81ea\u4e3b\u64cd\u4f5c\uff0c\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u7684\u81ea\u4e3b\u5b66\u4e60\u548c\u73af\u5883\u4ea4\u4e92\u80fd\u529b\u3002", "conclusion": "\u81ea\u6f14\u5316\u5177\u8eabAI\u4e3a\u5b9e\u73b0\u901a\u7528\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u4ee5\u4eba\u7c7b\u65b9\u5f0f\u81ea\u4e3b\u5b66\u4e60\u548c\u4e0e\u73af\u5883\u4ea4\u4e92\u3002"}}
{"id": "2602.04638", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.04638", "abs": "https://arxiv.org/abs/2602.04638", "authors": ["Irene Garc\u00eda Mu\u00f1oz", "Ian Hall", "Thomas House"], "title": "Inference for Within- and Between-Partnership Transmission Rates for HIV Infection", "comment": "14 pages, 3 figures, 3 tables", "summary": "HIV transmission within serodiscordant couples remains a significant public health challenge, particularly in sub-Saharan Africa. Estimating the rate of such infection, alongside the rates of introduction of infection from outside the partnership, is a special case of the more general epidemiological challenge of inferring intensities of within- and between-group intensities of transmission. This study presents a stochastic susceptible-infected (SI) pair model for estimating key epidemiological parameters governing HIV transmission within and between couples, which we further extend to account for gender-specific differences in infection dynamics. Using a likelihood-based inference approach, we estimate transmission parameters and associated uncertainty from observed data. These values can be used to inform infection prevention strategies for HIV, and the methodology proposed can be generalised to other epidemiological settings.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u968f\u673aSI\u914d\u5bf9\u6a21\u578b\u6765\u4f30\u8ba1HIV\u5728\u8840\u6e05\u4e0d\u4e00\u81f4\u4f34\u4fa3\u4e2d\u7684\u4f20\u64ad\u7387\uff0c\u8003\u8651\u4e86\u6027\u522b\u5dee\u5f02\uff0c\u4f7f\u7528\u57fa\u4e8e\u4f3c\u7136\u7684\u63a8\u65ad\u65b9\u6cd5\u4f30\u8ba1\u53c2\u6570\uff0c\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6d41\u884c\u75c5\u5b66\u573a\u666f\u3002", "motivation": "HIV\u5728\u8840\u6e05\u4e0d\u4e00\u81f4\u4f34\u4fa3\u4e2d\u7684\u4f20\u64ad\u662f\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u7684\u91cd\u8981\u516c\u5171\u536b\u751f\u6311\u6218\uff0c\u9700\u8981\u51c6\u786e\u4f30\u8ba1\u4f34\u4fa3\u5185\u548c\u4f34\u4fa3\u5916\u7684\u611f\u67d3\u7387\uff0c\u4ee5\u5236\u5b9a\u6709\u6548\u7684\u9884\u9632\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u968f\u673a\u6613\u611f-\u611f\u67d3(SI)\u914d\u5bf9\u6a21\u578b\u6765\u4f30\u8ba1HIV\u4f20\u64ad\u7684\u5173\u952e\u6d41\u884c\u75c5\u5b66\u53c2\u6570\uff0c\u6269\u5c55\u6a21\u578b\u4ee5\u8003\u8651\u6027\u522b\u7279\u5f02\u6027\u5dee\u5f02\uff0c\u91c7\u7528\u57fa\u4e8e\u4f3c\u7136\u7684\u63a8\u65ad\u65b9\u6cd5\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u4f30\u8ba1\u53c2\u6570\u548c\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u80fd\u591f\u4f30\u8ba1HIV\u5728\u4f34\u4fa3\u5185\u548c\u4f34\u4fa3\u95f4\u4f20\u64ad\u53c2\u6570\u7684\u6a21\u578b\uff0c\u8fd9\u4e9b\u53c2\u6570\u503c\u53ef\u7528\u4e8e\u6307\u5bfcHIV\u611f\u67d3\u9884\u9632\u7b56\u7565\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3aHIV\u4f20\u64ad\u53c2\u6570\u4f30\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6d41\u884c\u75c5\u5b66\u8bbe\u7f6e\uff0c\u6709\u52a9\u4e8e\u5236\u5b9a\u9488\u5bf9\u6027\u7684\u611f\u67d3\u9884\u9632\u7b56\u7565\u3002"}}
{"id": "2602.04087", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.04087", "abs": "https://arxiv.org/abs/2602.04087", "authors": ["Ibrahim Denis Fofanah"], "title": "Quantifying Algorithmic Friction in Automated Resume Screening Systems", "comment": "Measurement extension of prior work on algorithmic friction in automated recruitment systems", "summary": "Automated resume screening systems are now a central part of hiring at scale, yet there is growing evidence that rigid screening logic can exclude qualified candidates before human review. In prior work, we introduced the concept of Artificial Frictional Unemployment to describe labor market inefficiencies arising from automated recruitment systems. This paper extends that framework by focusing on measurement. We present a method for quantifying algorithmic friction in resume screening pipelines by modeling screening as a classification task and defining friction as excess false negative rejection caused by semantic misinterpretation. Using controlled simulations, we compare deterministic keyword-based screening with vector-space semantic matching under identical qualification conditions. The results show that keyword-based screening exhibits high levels of algorithmic friction, while semantic representations substantially reduce false negative rejection without compromising precision. By treating algorithmic friction as a system-level property, this study provides an empirical basis for evaluating how recruitment system design affects matching efficiency in modern labor markets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u7b80\u5386\u81ea\u52a8\u7b5b\u9009\u7cfb\u7edf\u4e2d\"\u7b97\u6cd5\u6469\u64e6\"\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u6bd4\u8f83\u5173\u952e\u8bcd\u7b5b\u9009\u548c\u8bed\u4e49\u5339\u914d\uff0c\u53d1\u73b0\u8bed\u4e49\u5339\u914d\u80fd\u663e\u8457\u51cf\u5c11\u8bef\u62d2\u7387\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u5316\u7b80\u5386\u7b5b\u9009\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u62db\u8058\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u50f5\u5316\u7684\u7b5b\u9009\u903b\u8f91\u53ef\u80fd\u5728\u4eba\u5de5\u5ba1\u6838\u524d\u5c31\u6392\u9664\u4e86\u5408\u683c\u5019\u9009\u4eba\u3002\u5148\u524d\u7814\u7a76\u63d0\u51fa\u4e86\"\u4eba\u5de5\u6469\u64e6\u6027\u5931\u4e1a\"\u6982\u5ff5\u6765\u63cf\u8ff0\u81ea\u52a8\u5316\u62db\u8058\u7cfb\u7edf\u5bfc\u81f4\u7684\u52b3\u52a8\u529b\u5e02\u573a\u4f4e\u6548\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u6269\u5c55\u8be5\u6846\u67b6\u5e76\u805a\u7126\u4e8e\u6d4b\u91cf\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u91cf\u5316\u7b80\u5386\u7b5b\u9009\u7ba1\u9053\u4e2d\u7b97\u6cd5\u6469\u64e6\u7684\u65b9\u6cd5\uff1a\u5c06\u7b5b\u9009\u5efa\u6a21\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u5b9a\u4e49\u6469\u64e6\u4e3a\u8bed\u4e49\u8bef\u89e3\u5bfc\u81f4\u7684\u8fc7\u5ea6\u5047\u9634\u6027\u62d2\u7edd\u3002\u901a\u8fc7\u53d7\u63a7\u6a21\u62df\uff0c\u5728\u76f8\u540c\u8d44\u683c\u6761\u4ef6\u4e0b\u6bd4\u8f83\u786e\u5b9a\u6027\u5173\u952e\u8bcd\u7b5b\u9009\u548c\u5411\u91cf\u7a7a\u95f4\u8bed\u4e49\u5339\u914d\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u7b5b\u9009\u8868\u73b0\u51fa\u9ad8\u6c34\u5e73\u7684\u7b97\u6cd5\u6469\u64e6\uff0c\u800c\u8bed\u4e49\u8868\u793a\u80fd\u663e\u8457\u51cf\u5c11\u5047\u9634\u6027\u62d2\u7edd\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u7b5b\u9009\u7cbe\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7b97\u6cd5\u6469\u64e6\u89c6\u4e3a\u7cfb\u7edf\u7ea7\u5c5e\u6027\uff0c\u672c\u7814\u7a76\u4e3a\u8bc4\u4f30\u62db\u8058\u7cfb\u7edf\u8bbe\u8ba1\u5982\u4f55\u5f71\u54cd\u73b0\u4ee3\u52b3\u52a8\u529b\u5e02\u573a\u5339\u914d\u6548\u7387\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u8868\u660e\u8bed\u4e49\u5339\u914d\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u81ea\u52a8\u5316\u7b5b\u9009\u4e2d\u7684\u6469\u64e6\u6027\u5931\u4e1a\u3002"}}
{"id": "2602.03955", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03955", "abs": "https://arxiv.org/abs/2602.03955", "authors": ["Yinyi Luo", "Yiqiao Jin", "Weichen Yu", "Mengqi Zhang", "Srijan Kumar", "Xiaoxiao Li", "Weijie Xu", "Xin Chen", "Jindong Wang"], "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent", "comment": null, "summary": "While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.", "AI": {"tldr": "AgentArk\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u4f5c\u63a8\u7406\u80fd\u529b\u538b\u7f29\u5230\u5355\u4e2a\u6a21\u578b\u4e2d\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "motivation": "\u5f53\u524dLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u867d\u7136\u901a\u8fc7\u8fed\u4ee3\u8fa9\u8bba\u83b7\u5f97\u4e86\u4f18\u8d8a\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u53d7\u5230\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u9519\u8bef\u4f20\u64ad\u7684\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51faAgentArk\u6846\u67b6\uff0c\u91c7\u7528\u4e09\u79cd\u5206\u5c42\u84b8\u998f\u7b56\u7565\uff1a\u63a8\u7406\u589e\u5f3a\u5fae\u8c03\u3001\u57fa\u4e8e\u8f68\u8ff9\u7684\u6570\u636e\u589e\u5f3a\u3001\u8fc7\u7a0b\u611f\u77e5\u84b8\u998f\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u52a8\u6001\u538b\u7f29\u5230\u5355\u4e2a\u6a21\u578b\u7684\u6743\u91cd\u4e2d", "result": "\u84b8\u998f\u540e\u7684\u6a21\u578b\u5728\u4fdd\u6301\u5355\u667a\u80fd\u4f53\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u5c55\u73b0\u51fa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5f3a\u63a8\u7406\u548c\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\uff0c\u5e76\u5728\u591a\u6837\u5316\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b", "conclusion": "\u901a\u8fc7\u5c06\u8ba1\u7b97\u8d1f\u62c5\u4ece\u63a8\u7406\u8f6c\u79fb\u5230\u8bad\u7ec3\uff0cAgentArk\u4e3a\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u6709\u671b\u63a8\u52a8\u672a\u6765\u7814\u7a76"}}
{"id": "2602.04495", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.04495", "abs": "https://arxiv.org/abs/2602.04495", "authors": ["Maher Harb", "Nader Foroughi", "Matt Stehman", "Bob Lutz", "Nati Erez", "Erik Garcell"], "title": "Quantum-Based Resilient Routing in Networks: Minimizing Latency Under Dual-Link Failures", "comment": "15 pages, 4 figures", "summary": "Network optimization problems represent large combinatorial search spaces that grow exponentially with network size, making them computationally intensive to solve. This paper addresses the latency-resilient Layer 3 routing optimization problem in telecommunications networks with predefined Layer 1 optical links. We formulate this problem as a graph-based optimization problem with the objective of minimizing latency, creating vertex-disjoint paths from each site to the internet backbone, and maximizing overall resiliency by limiting the impact of dual-link failures. By framing the problem as finding two disjoint shortest paths, coupled together with a resiliency component to the objective function, we establish a single formulation to produce optimal path design. The mathematical formulation was adapted to solve the problem using quantum approximate optimization algorithm (QAOA) executed over both quantum simulator and quantum hardware. QAOA was tested on a toy graph topology with 5 vertices and 7 edges and considering two limiting scenarios respectively representing independent (uncorrelated) link failures and highly correlated failure for one pair of edges. Both explored scenarios produced the optimal network design-corresponding to the valid solution with highest frequency of occurrence and minimum energy state, hence, validating the proposed formulation for optimizing Layer 3 routing on quantum systems of the future.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff08QAOA\uff09\u89e3\u51b3\u7535\u4fe1\u7f51\u7edc\u4e2d\u5ef6\u8fdf\u5f39\u6027\u7684Layer 3\u8def\u7531\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u5bfb\u627e\u4e24\u6761\u4e0d\u76f8\u4ea4\u7684\u6700\u77ed\u8def\u5f84\u6765\u6700\u5c0f\u5316\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u7f51\u7edc\u5f39\u6027\u3002", "motivation": "\u7f51\u7edc\u4f18\u5316\u95ee\u9898\u968f\u7740\u7f51\u7edc\u89c4\u6a21\u589e\u957f\u800c\u5448\u6307\u6570\u7ea7\u590d\u6742\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u7535\u4fe1\u7f51\u7edc\u9700\u8981\u89e3\u51b3\u5ef6\u8fdf\u5f39\u6027\u7684Layer 3\u8def\u7531\u4f18\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9884\u5b9a\u4e49Layer 1\u5149\u94fe\u8def\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u627e\u5230\u65e2\u80fd\u6700\u5c0f\u5316\u5ef6\u8fdf\u53c8\u80fd\u63d0\u9ad8\u7f51\u7edc\u5f39\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u56fe\u4f18\u5316\u95ee\u9898\uff0c\u76ee\u6807\u662f\u6700\u5c0f\u5316\u5ef6\u8fdf\u3001\u521b\u5efa\u4ece\u6bcf\u4e2a\u7ad9\u70b9\u5230\u4e92\u8054\u7f51\u9aa8\u5e72\u7f51\u7684\u9876\u70b9\u4e0d\u76f8\u4ea4\u8def\u5f84\uff0c\u5e76\u901a\u8fc7\u9650\u5236\u53cc\u94fe\u8def\u6545\u969c\u7684\u5f71\u54cd\u6765\u6700\u5927\u5316\u6574\u4f53\u5f39\u6027\u3002\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u5bfb\u627e\u4e24\u6761\u4e0d\u76f8\u4ea4\u7684\u6700\u77ed\u8def\u5f84\uff0c\u5e76\u5728\u76ee\u6807\u51fd\u6570\u4e2d\u52a0\u5165\u5f39\u6027\u7ec4\u4ef6\u3002\u4f7f\u7528\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff08QAOA\uff09\u5728\u91cf\u5b50\u6a21\u62df\u5668\u548c\u91cf\u5b50\u786c\u4ef6\u4e0a\u6c42\u89e3\u3002", "result": "\u5728\u5305\u542b5\u4e2a\u9876\u70b9\u548c7\u6761\u8fb9\u7684\u73a9\u5177\u56fe\u62d3\u6251\u4e0a\u6d4b\u8bd5QAOA\uff0c\u8003\u8651\u4e24\u79cd\u9650\u5236\u573a\u666f\uff1a\u72ec\u7acb\uff08\u4e0d\u76f8\u5173\uff09\u94fe\u8def\u6545\u969c\u548c\u4e00\u5bf9\u8fb9\u7684\u9ad8\u5ea6\u76f8\u5173\u6545\u969c\u3002\u4e24\u79cd\u573a\u666f\u90fd\u4ea7\u751f\u4e86\u6700\u4f18\u7f51\u7edc\u8bbe\u8ba1\uff0c\u5bf9\u5e94\u6700\u9ad8\u51fa\u73b0\u9891\u7387\u7684\u6709\u6548\u89e3\u548c\u6700\u5c0f\u80fd\u91cf\u72b6\u6001\u3002", "conclusion": "\u63d0\u51fa\u7684\u516c\u5f0f\u80fd\u591f\u4ea7\u751f\u6700\u4f18\u8def\u5f84\u8bbe\u8ba1\uff0c\u9a8c\u8bc1\u4e86\u5728\u672a\u6765\u7684\u91cf\u5b50\u7cfb\u7edf\u4e0a\u4f18\u5316Layer 3\u8def\u7531\u7684\u53ef\u884c\u6027\u3002\u91cf\u5b50\u8ba1\u7b97\u65b9\u6cd5\u4e3a\u89e3\u51b3\u590d\u6742\u7684\u7f51\u7edc\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2602.04332", "categories": ["cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04332", "abs": "https://arxiv.org/abs/2602.04332", "authors": ["Vasudha Malhotra", "Rhea D'silva", "Rashina Hoda"], "title": "They Call Her 'Miss' and Him 'Professor': Lived Experiences of Women Teaching Support Staff in IT/SE Education", "comment": null, "summary": "Despite their critical role in shaping student learning in computing education, the contributions of women teaching-support staff (TSS) often go unrecognised and undervalued. In this experience report, we synthesise lived experiences of 15 women TSS in IT/SE higher education to illuminate how authority is earned, resisted, and maintained in everyday teaching. Participants shared both their positive and negative lived experiences associated with finding and losing voice with teaching team colleagues on the one hand, and rewarding connections and gendered friction with students on the other. We map these dynamics onto an intersectional \"wheel of privilege and power\" tailored to TSS roles. The farther a TSS profile sits from the wheel's center (e.g., non-native English, non-white, younger-seeming, non-permanent, early-career), the more relational, emotional, and disciplinary labour is needed to reach parity. We provide actionable insights and recommendations for creating more inclusive education environments in technology dominant fields that are particularly timely as universities worldwide grapple with post-pandemic teaching models and seek to build more inclusive and resilient academic communities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc715\u4f4d\u5973\u6027\u6559\u5b66\u652f\u6301\u4eba\u5458\u7684\u7ecf\u9a8c\uff0c\u63ed\u793a\u4e86\u5728IT/SE\u9ad8\u7b49\u6559\u80b2\u4e2d\uff0c\u5973\u6027\u6559\u5b66\u652f\u6301\u4eba\u5458\u5982\u4f55\u83b7\u5f97\u3001\u62b5\u6297\u548c\u7ef4\u62a4\u6743\u5a01\uff0c\u5e76\u63d0\u51fa\u4e86\u521b\u5efa\u66f4\u5177\u5305\u5bb9\u6027\u6559\u80b2\u73af\u5883\u7684\u5efa\u8bae\u3002", "motivation": "\u5973\u6027\u6559\u5b66\u652f\u6301\u4eba\u5458\u5728\u8ba1\u7b97\u6559\u80b2\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u4f46\u5979\u4eec\u7684\u8d21\u732e\u5e38\u5e38\u88ab\u5ffd\u89c6\u548c\u4f4e\u4f30\u3002\u7814\u7a76\u65e8\u5728\u63ed\u793a\u5979\u4eec\u5728\u65e5\u5e38\u6559\u5b66\u4e2d\u7684\u6743\u5a01\u52a8\u6001\uff0c\u7279\u522b\u662f\u5728\u6280\u672f\u4e3b\u5bfc\u9886\u57df\u4e2d\u521b\u5efa\u66f4\u5177\u5305\u5bb9\u6027\u6559\u80b2\u73af\u5883\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u7ecf\u9a8c\u62a5\u544a\u65b9\u6cd5\uff0c\u7efc\u5408\u5206\u6790\u4e8615\u4f4dIT/SE\u9ad8\u7b49\u6559\u80b2\u4e2d\u5973\u6027\u6559\u5b66\u652f\u6301\u4eba\u5458\u7684\u751f\u6d3b\u7ecf\u9a8c\uff0c\u901a\u8fc7\u8bbf\u8c08\u6536\u96c6\u5979\u4eec\u4e0e\u6559\u5b66\u56e2\u961f\u540c\u4e8b\u548c\u5b66\u751f\u4e92\u52a8\u7684\u6b63\u9762\u548c\u8d1f\u9762\u7ecf\u5386\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5973\u6027\u6559\u5b66\u652f\u6301\u4eba\u5458\u9700\u8981\u6839\u636e\u81ea\u8eab\u7279\u5f81\uff08\u5982\u975e\u82f1\u8bed\u6bcd\u8bed\u3001\u975e\u767d\u4eba\u3001\u5e74\u8f7b\u5916\u8868\u3001\u975e\u6c38\u4e45\u804c\u4f4d\u3001\u65e9\u671f\u804c\u4e1a\uff09\u8fdb\u884c\u4e0d\u540c\u7a0b\u5ea6\u7684\u5173\u7cfb\u3001\u60c5\u611f\u548c\u5b66\u79d1\u52b3\u52a8\u6765\u8fbe\u5230\u5e73\u7b49\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u9488\u5bf9\u6559\u5b66\u652f\u6301\u4eba\u5458\u89d2\u8272\u7684\u4ea4\u53c9\u6027\"\u7279\u6743\u4e0e\u6743\u529b\u8f6e\"\u6846\u67b6\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u521b\u5efa\u66f4\u5177\u5305\u5bb9\u6027\u6280\u672f\u6559\u80b2\u73af\u5883\u7684\u53ef\u884c\u5efa\u8bae\uff0c\u7279\u522b\u662f\u5728\u5168\u7403\u5927\u5b66\u5e94\u5bf9\u540e\u75ab\u60c5\u6559\u5b66\u6a21\u5f0f\u5e76\u5bfb\u6c42\u5efa\u7acb\u66f4\u5177\u5305\u5bb9\u6027\u548c\u97e7\u6027\u7684\u5b66\u672f\u793e\u533a\u7684\u5173\u952e\u65f6\u671f\u3002"}}
{"id": "2602.03974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03974", "abs": "https://arxiv.org/abs/2602.03974", "authors": ["Shuhui Qu"], "title": "Active Epistemic Control for Query-Efficient Verified Planning", "comment": null, "summary": "Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \\textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management with categorical feasibility checks. AEC maintains a strict separation between a \\emph{grounded fact store} used for commitment and a \\emph{belief store} used only for pruning candidate plans. At each step, it either queries the environment to ground an unresolved predicate when uncertainty is high or predictions are ambiguous, or simulates the predicate to filter hypotheses when confidence is sufficient. Final commitment is gated by grounded precondition coverage and an SQ-BCP pullback-style compatibility check, so simulated beliefs affect efficiency but cannot directly certify feasibility. Experiments on ALFWorld and ScienceWorld show that AEC achieves competitive success with fewer replanning rounds than strong LLM-agent baselines.", "AI": {"tldr": "AEC\u662f\u4e00\u79cd\u4e3b\u52a8\u8ba4\u77e5\u63a7\u5236\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u79bb\u4e8b\u5b9e\u5b58\u50a8\u4e0e\u4fe1\u5ff5\u5b58\u50a8\uff0c\u7ed3\u5408\u73af\u5883\u67e5\u8be2\u4e0e\u6a21\u62df\u9884\u6d4b\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u89c4\u5212\u3002", "motivation": "\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u4ea4\u4e92\u73af\u5883\u4e2d\uff0c\u4efb\u52a1\u5173\u952e\u524d\u63d0\u6761\u4ef6\uff08\u5982\u7269\u4f53\u4f4d\u7f6e\u6216\u5bb9\u5668\u72b6\u6001\uff09\u5728\u51b3\u7b56\u65f6\u53ef\u80fd\u672a\u77e5\uff0c\u800c\u901a\u8fc7\u4ea4\u4e92\u83b7\u53d6\u8fd9\u4e9b\u4fe1\u606f\u6210\u672c\u9ad8\u6602\u3002\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u53ef\u4ee5\u5ec9\u4ef7\u9884\u6d4b\u7f3a\u5931\u4e8b\u5b9e\uff0c\u4f46\u9884\u6d4b\u9519\u8bef\u53ef\u80fd\u65e0\u58f0\u5730\u5bfc\u81f4\u4e0d\u53ef\u884c\u7684\u627f\u8bfa\u3002", "method": "\u63d0\u51fa\u4e3b\u52a8\u8ba4\u77e5\u63a7\u5236(AEC)\uff0c\u8fd9\u662f\u4e00\u79cd\u8ba4\u77e5-\u5206\u7c7b\u89c4\u5212\u5c42\uff0c\u5c06\u57fa\u4e8e\u6a21\u578b\u7684\u4fe1\u5ff5\u7ba1\u7406\u4e0e\u5206\u7c7b\u53ef\u884c\u6027\u68c0\u67e5\u76f8\u7ed3\u5408\u3002AEC\u4e25\u683c\u5206\u79bb\u7528\u4e8e\u627f\u8bfa\u7684\u63a5\u5730\u4e8b\u5b9e\u5b58\u50a8\u548c\u4ec5\u7528\u4e8e\u526a\u679d\u5019\u9009\u8ba1\u5212\u7684\u4fe1\u5ff5\u5b58\u50a8\u3002\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\uff0c\u5f53\u4e0d\u786e\u5b9a\u6027\u9ad8\u6216\u9884\u6d4b\u6a21\u7cca\u65f6\u67e5\u8be2\u73af\u5883\u4ee5\u63a5\u5730\u672a\u89e3\u6790\u8c13\u8bcd\uff0c\u6216\u5728\u7f6e\u4fe1\u5ea6\u8db3\u591f\u65f6\u6a21\u62df\u8c13\u8bcd\u4ee5\u8fc7\u6ee4\u5047\u8bbe\u3002\u6700\u7ec8\u627f\u8bfa\u901a\u8fc7\u63a5\u5730\u524d\u63d0\u6761\u4ef6\u8986\u76d6\u548cSQ-BCP\u62c9\u56de\u5f0f\u517c\u5bb9\u6027\u68c0\u67e5\u6765\u628a\u5173\u3002", "result": "\u5728ALFWorld\u548cScienceWorld\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAEC\u5728\u6bd4\u5f3a\u5927\u7684LLM\u667a\u80fd\u4f53\u57fa\u7ebf\u66f4\u5c11\u7684\u91cd\u65b0\u89c4\u5212\u8f6e\u6b21\u4e2d\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u6210\u529f\u7387\u3002", "conclusion": "AEC\u901a\u8fc7\u5728\u89c4\u5212\u4e2d\u4e25\u683c\u5206\u79bb\u4e8b\u5b9e\u4e0e\u4fe1\u5ff5\uff0c\u7ed3\u5408\u4e3b\u52a8\u73af\u5883\u67e5\u8be2\u4e0e\u6a21\u62df\u9884\u6d4b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u7684\u89c4\u5212\u95ee\u9898\uff0c\u51cf\u5c11\u4e86\u91cd\u65b0\u89c4\u5212\u9700\u6c42\uff0c\u63d0\u9ad8\u4e86\u89c4\u5212\u6548\u7387\u3002"}}
{"id": "2602.04456", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.04456", "abs": "https://arxiv.org/abs/2602.04456", "authors": ["Zhiyi Chen", "Eun Cheol Choi", "Yingjia Luo", "Xinyi Wang", "Yulei Xiao", "Aizi Yang", "Luca Luceri"], "title": "Growth First, Care Second? Tracing the Landscape of LLM Value Preferences in Everyday Dilemmas", "comment": "dataset available at https://github.com/Renesmeeczy/Value-Trade-off-in-Reddit-Dilemmas", "summary": "People increasingly seek advice online from both human peers and large language model (LLM)-based chatbots. Such advice rarely involves identifying a single correct answer; instead, it typically requires navigating trade-offs among competing values. We aim to characterize how LLMs navigate value trade-offs across different advice-seeking contexts. First, we examine the value trade-off structure underlying advice seeking using a curated dataset from four advice-oriented subreddits. Using a bottom-up approach, we inductively construct a hierarchical value framework by aggregating fine-grained values extracted from individual advice options into higher-level value categories. We construct value co-occurrence networks to characterize how values co-occur within dilemmas and find substantial heterogeneity in value trade-off structures across advice-seeking contexts: a women-focused subreddit exhibits the highest network density, indicating more complex value conflicts; women's, men's, and friendship-related subreddits exhibit highly correlated value-conflict patterns centered on security-related tensions (security vs. respect/connection/commitment); by contrast, career advice forms a distinct structure where security frequently clashes with self-actualization and growth. We then evaluate LLM value preferences against these dilemmas and find that, across models and contexts, LLMs consistently prioritize values related to Exploration & Growth over Benevolence & Connection. This systemically skewed value orientation highlights a potential risk of value homogenization in AI-mediated advice, raising concerns about how such systems may shape decision-making and normative outcomes at scale.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86LLM\u5728\u5728\u7ebf\u5efa\u8bae\u573a\u666f\u4e2d\u7684\u4ef7\u503c\u6743\u8861\u504f\u597d\uff0c\u53d1\u73b0LLM\u7cfb\u7edf\u6027\u5730\u504f\u5411\u63a2\u7d22\u4e0e\u6210\u957f\u4ef7\u503c\uff0c\u800c\u975e\u4ec1\u6148\u4e0e\u8fde\u63a5\u4ef7\u503c\uff0c\u5b58\u5728\u4ef7\u503c\u540c\u8d28\u5316\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u4eba\u4eec\u8d8a\u6765\u8d8a\u591a\u5730\u4ece\u4eba\u7c7b\u540c\u4f34\u548cLLM\u804a\u5929\u673a\u5668\u4eba\u5bfb\u6c42\u5728\u7ebf\u5efa\u8bae\uff0c\u8fd9\u4e9b\u5efa\u8bae\u901a\u5e38\u6d89\u53ca\u5728\u7ade\u4e89\u6027\u4ef7\u503c\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002\u7814\u7a76\u65e8\u5728\u8868\u5f81LLM\u5728\u4e0d\u540c\u5efa\u8bae\u5bfb\u6c42\u60c5\u5883\u4e2d\u5982\u4f55\u5bfc\u822a\u4ef7\u503c\u6743\u8861\uff0c\u4ee5\u7406\u89e3AI\u4e2d\u4ecb\u5efa\u8bae\u53ef\u80fd\u5e26\u6765\u7684\u4ef7\u503c\u540c\u8d28\u5316\u98ce\u9669\u3002", "method": "1. \u4f7f\u7528\u56db\u4e2a\u5efa\u8bae\u5bfc\u5411\u7684subreddit\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\u6784\u5efa\u5206\u5c42\u4ef7\u503c\u6846\u67b6\uff1b2. \u6784\u5efa\u4ef7\u503c\u5171\u73b0\u7f51\u7edc\u6765\u8868\u5f81\u4ef7\u503c\u5728\u56f0\u5883\u4e2d\u7684\u5171\u73b0\u6a21\u5f0f\uff1b3. \u8bc4\u4f30LLM\u5728\u8fd9\u4e9b\u56f0\u5883\u4e2d\u7684\u4ef7\u503c\u504f\u597d\uff0c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u548c\u60c5\u5883\u4e0b\u7684\u4ef7\u503c\u53d6\u5411\u3002", "result": "1. \u4e0d\u540c\u5efa\u8bae\u60c5\u5883\u7684\u4ef7\u503c\u6743\u8861\u7ed3\u6784\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\uff1a\u5973\u6027subreddit\u7f51\u7edc\u5bc6\u5ea6\u6700\u9ad8\uff0c\u8868\u660e\u66f4\u590d\u6742\u7684\u4ef7\u503c\u51b2\u7a81\uff1b\u5973\u6027\u3001\u7537\u6027\u548c\u53cb\u8c0a\u76f8\u5173subreddit\u56f4\u7ed5\u5b89\u5168\u76f8\u5173\u7d27\u5f20\u5173\u7cfb\u5f62\u6210\u9ad8\u5ea6\u76f8\u5173\u7684\u4ef7\u503c\u51b2\u7a81\u6a21\u5f0f\uff1b\u804c\u4e1a\u5efa\u8bae\u5219\u5f62\u6210\u72ec\u7279\u7ed3\u6784\uff0c\u5b89\u5168\u5e38\u4e0e\u81ea\u6211\u5b9e\u73b0\u548c\u6210\u957f\u51b2\u7a81\u30022. LLM\u5728\u6240\u6709\u6a21\u578b\u548c\u60c5\u5883\u4e2d\u4e00\u81f4\u4f18\u5148\u8003\u8651\u63a2\u7d22\u4e0e\u6210\u957f\u4ef7\u503c\uff0c\u800c\u975e\u4ec1\u6148\u4e0e\u8fde\u63a5\u4ef7\u503c\u3002", "conclusion": "LLM\u5728\u4ef7\u503c\u6743\u8861\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u7684\u504f\u5411\u6027\u4ef7\u503c\u53d6\u5411\uff0c\u8fd9\u79cd\u4ef7\u503c\u540c\u8d28\u5316\u98ce\u9669\u53ef\u80fd\u5728\u5927\u89c4\u6a21\u4e0a\u5851\u9020\u51b3\u7b56\u548c\u89c4\u8303\u7ed3\u679c\uff0c\u5bf9AI\u4e2d\u4ecb\u5efa\u8bae\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u51fa\u4e86\u91cd\u8981\u5173\u5207\u3002"}}
{"id": "2602.03975", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03975", "abs": "https://arxiv.org/abs/2602.03975", "authors": ["Shuhui Qu"], "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure", "comment": null, "summary": "Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \\emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a state-level selective verification framework that combines (i) deterministic feasibility gating over a structured move interface, (ii) pre-verification ranking using a hybrid of learned state-distance and residual scoring, and (iii) adaptive allocation of verifier calls based on local uncertainty. Unlike solution-level best-of-$N$ or uniform intermediate verification, our method distributes verification where it is most informative. On the \\textsc{MATH} benchmark, our approach achieves higher accuracy than best-of-$N$, majority voting, and beam search while using 44\\% fewer verifier calls.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u72b6\u6001\u7ea7\u9009\u62e9\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u60c5\u51b5\u4e0b\u4f18\u5316\u9a8c\u8bc1\u8d44\u6e90\u5206\u914d\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728MATH\u57fa\u51c6\u4e0a\u51cf\u5c1144%\u9a8c\u8bc1\u8c03\u7528\u540c\u65f6\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u8d8a\u6765\u8d8a\u53d7\u6602\u8d35\u9a8c\u8bc1\u7684\u74f6\u9888\u9650\u5236\uff0c\u8bb8\u591a\u63a8\u7406\u7cfb\u7edf\u5c06\u5927\u91cf\u9a8c\u8bc1\u8c03\u7528\u6d6a\u8d39\u5728\u5197\u4f59\u6216\u65e0\u524d\u666f\u7684\u4e2d\u95f4\u5047\u8bbe\u4e0a\uff0c\u9700\u8981\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u60c5\u51b5\u4e0b\u7814\u7a76\u5982\u4f55\u4f18\u5316\u9a8c\u8bc1\u8d44\u6e90\u5206\u914d", "method": "\u63d0\u51fa\u72b6\u6001\u7ea7\u9009\u62e9\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1) \u7ed3\u6784\u5316\u79fb\u52a8\u63a5\u53e3\u4e0a\u7684\u786e\u5b9a\u6027\u53ef\u884c\u6027\u95e8\u63a7\uff1b2) \u7ed3\u5408\u5b66\u4e60\u72b6\u6001\u8ddd\u79bb\u548c\u6b8b\u5dee\u5f97\u5206\u7684\u9884\u9a8c\u8bc1\u6392\u5e8f\uff1b3) \u57fa\u4e8e\u5c40\u90e8\u4e0d\u786e\u5b9a\u6027\u7684\u9a8c\u8bc1\u8c03\u7528\u81ea\u9002\u5e94\u5206\u914d", "result": "\u5728MATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4best-of-N\u3001\u591a\u6570\u6295\u7968\u548c\u675f\u641c\u7d22\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\uff0c\u540c\u65f6\u51cf\u5c1144%\u7684\u9a8c\u8bc1\u8c03\u7528", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u667a\u80fd\u5206\u914d\u9a8c\u8bc1\u8d44\u6e90\u5230\u6700\u4fe1\u606f\u4e30\u5bcc\u7684\u4e2d\u95f4\u72b6\u6001\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u9a8c\u8bc1\u7b56\u7565"}}
{"id": "2602.04503", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.04503", "abs": "https://arxiv.org/abs/2602.04503", "authors": ["Zhaoyang Liu", "Xiaocong Du", "Yixi Zhou", "Ye Shi", "Haipeng Zhang"], "title": "Fine-grained Classification of A Million Life Trajectories from Wikipedia", "comment": null, "summary": "Life trajectories of notable people convey essential messages for human dynamics research. These trajectories consist of (\\textit{person, time, location, activity type}) tuples recording when and where a person was born, went to school, started a job, or fought in a war. However, current studies only cover limited activity types such as births and deaths, lacking large-scale fine-grained trajectories. Using a tool that extracts (\\textit{person, time, location}) triples from Wikipedia, we formulate the problem of classifying these triples into 24 carefully-defined types using textual context as complementary information. The challenge is that triple entities are often scattered in noisy contexts. We use syntactic graphs to bring triple entities and relevant information closer, fusing them with text embeddings to classify life trajectory activities. Since Wikipedia text quality varies, we use LLMs to refine the text for more standardized syntactic graphs. Our framework achieves 84.5\\% accuracy, surpassing baselines. We construct the largest fine-grained life trajectory dataset with 3.8 million labeled activities for 589,193 individuals spanning 3 centuries. In the end, we showcase how these trajectories can support grand narratives of human dynamics across time and space. Code/data are publicly available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u4ece\u7ef4\u57fa\u767e\u79d1\u63d0\u53d6\u7ec6\u7c92\u5ea6\u4eba\u751f\u8f68\u8ff9\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u53e5\u6cd5\u56fe\u548c\u6587\u672c\u5d4c\u5165\u5bf9\u6d3b\u52a8\u7c7b\u578b\u8fdb\u884c\u5206\u7c7b\uff0c\u6784\u5efa\u4e86\u5305\u542b380\u4e07\u6807\u6ce8\u6d3b\u52a8\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6", "motivation": "\u5f53\u524d\u7814\u7a76\u4ec5\u8986\u76d6\u6709\u9650\u6d3b\u52a8\u7c7b\u578b\uff08\u5982\u51fa\u751f\u548c\u6b7b\u4ea1\uff09\uff0c\u7f3a\u4e4f\u5927\u89c4\u6a21\u7ec6\u7c92\u5ea6\u7684\u4eba\u751f\u8f68\u8ff9\u6570\u636e\u3002\u4eba\u751f\u8f68\u8ff9\u5bf9\u4eba\u7c7b\u52a8\u529b\u5b66\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6570\u636e\u4e0d\u591f\u5168\u9762", "method": "1. \u4ece\u7ef4\u57fa\u767e\u79d1\u63d0\u53d6\uff08\u4eba\u7269\u3001\u65f6\u95f4\u3001\u5730\u70b9\uff09\u4e09\u5143\u7ec4\uff1b2. \u4f7f\u7528\u53e5\u6cd5\u56fe\u5c06\u5206\u6563\u7684\u4e09\u5143\u7ec4\u5b9e\u4f53\u548c\u76f8\u5173\u4fe1\u606f\u805a\u5408\uff1b3. \u7ed3\u5408\u6587\u672c\u5d4c\u5165\u5bf924\u79cd\u6d3b\u52a8\u7c7b\u578b\u8fdb\u884c\u5206\u7c7b\uff1b4. \u5229\u7528LLM\u4f18\u5316\u6587\u672c\u8d28\u91cf\u4ee5\u751f\u6210\u6807\u51c6\u5316\u53e5\u6cd5\u56fe", "result": "1. \u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523084.5%\uff0c\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\uff1b2. \u6784\u5efa\u4e86\u6700\u5927\u7ec6\u7c92\u5ea6\u4eba\u751f\u8f68\u8ff9\u6570\u636e\u96c6\uff1a\u5305\u542b380\u4e07\u6807\u6ce8\u6d3b\u52a8\uff0c\u6d89\u53ca589,193\u4eba\uff0c\u65f6\u95f4\u8de8\u5ea63\u4e2a\u4e16\u7eaa\uff1b3. \u4ee3\u7801\u548c\u6570\u636e\u5df2\u516c\u5f00", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u7ec6\u7c92\u5ea6\u4eba\u751f\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u80fd\u591f\u652f\u6301\u8de8\u65f6\u7a7a\u7684\u4eba\u7c7b\u52a8\u529b\u5b66\u5b8f\u5927\u53d9\u4e8b\u7814\u7a76\uff0c\u4e3a\u7406\u89e3\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\u63d0\u4f9b\u4e86\u91cd\u8981\u6570\u636e\u57fa\u7840"}}
{"id": "2602.03978", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03978", "abs": "https://arxiv.org/abs/2602.03978", "authors": ["Zidi Xiong", "Shan Chen", "Himabindu Lakkaraju"], "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning", "comment": null, "summary": "As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a \"free gift\" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model families and training domains. Our results show that this effect is not universal: monitorability improvements are strongly data-dependent. In particular, we demonstrate the critical role of data diversity and instruction-following data during RLVR training. We further show that monitorability is orthogonal to capability--improvements in reasoning performance do not imply increased transparency. Through mechanistic analysis, we attribute monitorability gains primarily to response distribution sharpening (entropy reduction) and increased attention to the prompt, rather than stronger causal reliance on reasoning traces. We also reveal how monitorability dynamics vary with controlled training and evaluation difficulty. Together, these findings provide a holistic view of how monitorability emerges under RLVR, clarifying when gains are likely to occur and when they are not.", "AI": {"tldr": "RLVR\u8bad\u7ec3\u65e9\u671f\u76d1\u63a7\u6027\u770b\u4f3c\"\u514d\u8d39\u793c\u7269\"\uff0c\u4f46\u5b9e\u9645\u5f3a\u70c8\u4f9d\u8d56\u6570\u636e\u591a\u6837\u6027\u548c\u6307\u4ee4\u8ddf\u968f\u6570\u636e\uff0c\u4e0e\u80fd\u529b\u63d0\u5347\u6b63\u4ea4\uff0c\u4e3b\u8981\u6e90\u4e8e\u54cd\u5e94\u5206\u5e03\u9510\u5316\u548c\u5bf9\u63d0\u793a\u7684\u5173\u6ce8\u589e\u5f3a\u3002", "motivation": "\u968f\u7740\u5927\u578b\u63a8\u7406\u6a21\u578b\u90e8\u7f72\u589e\u52a0\uff0c\u5ba1\u8ba1\u5176\u601d\u7ef4\u94fe\u7684\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u53d1\u73b0RLVR\u65e9\u671f\u9636\u6bb5\u76d1\u63a7\u6027\uff08\u601d\u7ef4\u94fe\u5fe0\u5b9e\u53cd\u6620\u5185\u90e8\u8ba1\u7b97\u7684\u7a0b\u5ea6\uff09\u770b\u4f3c\"\u514d\u8d39\u83b7\u5f97\"\uff0c\u4f46\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u666e\u904d\u6027\u548c\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u8de8\u6a21\u578b\u5bb6\u65cf\u548c\u8bad\u7ec3\u9886\u57df\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5206\u6790\u6570\u636e\u591a\u6837\u6027\u3001\u6307\u4ee4\u8ddf\u968f\u6570\u636e\u7684\u4f5c\u7528\uff0c\u8fdb\u884c\u673a\u5236\u5206\u6790\uff08\u54cd\u5e94\u5206\u5e03\u9510\u5316\u3001\u6ce8\u610f\u529b\u53d8\u5316\uff09\uff0c\u5e76\u63a7\u5236\u8bad\u7ec3\u548c\u8bc4\u4f30\u96be\u5ea6\u7814\u7a76\u76d1\u63a7\u6027\u52a8\u6001\u3002", "result": "\u76d1\u63a7\u6027\u6539\u8fdb\u5e76\u975e\u666e\u904d\u73b0\u8c61\uff0c\u5f3a\u70c8\u4f9d\u8d56\u6570\u636e\u591a\u6837\u6027\uff1b\u76d1\u63a7\u6027\u4e0e\u80fd\u529b\u63d0\u5347\u6b63\u4ea4\uff1b\u673a\u5236\u4e0a\u4e3b\u8981\u6e90\u4e8e\u54cd\u5e94\u5206\u5e03\u71b5\u51cf\u5c11\u548c\u5bf9\u63d0\u793a\u7684\u5173\u6ce8\u589e\u5f3a\uff0c\u800c\u975e\u5bf9\u63a8\u7406\u94fe\u7684\u56e0\u679c\u4f9d\u8d56\uff1b\u76d1\u63a7\u6027\u52a8\u6001\u968f\u8bad\u7ec3\u548c\u8bc4\u4f30\u96be\u5ea6\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86RLVR\u4e0b\u76d1\u63a7\u6027\u51fa\u73b0\u7684\u6574\u4f53\u89c6\u56fe\uff0c\u660e\u786e\u4e86\u76d1\u63a7\u6027\u589e\u76ca\u4f55\u65f6\u53ef\u80fd\u53d1\u751f\u3001\u4f55\u65f6\u4e0d\u4f1a\u53d1\u751f\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u8d28\u91cf\u548c\u7c7b\u578b\u7684\u5173\u952e\u4f5c\u7528\uff0c\u6f84\u6e05\u4e86\u76d1\u63a7\u6027\u4e0e\u80fd\u529b\u63d0\u5347\u7684\u72ec\u7acb\u6027\u3002"}}
{"id": "2602.04518", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04518", "abs": "https://arxiv.org/abs/2602.04518", "authors": ["Andr\u00e9s Holgado-S\u00e1nchez", "Holger Billhardt", "Alberto Fern\u00e1ndez", "Sascha Ossowski"], "title": "Learning the Value Systems of Agents with Preference-based and Inverse Reinforcement Learning", "comment": "42 pages, 5 figures. Published in Journal of Autonomous Agents and Multi-Agent Systems", "summary": "Agreement Technologies refer to open computer systems in which autonomous software agents interact with one another, typically on behalf of humans, in order to come to mutually acceptable agreements. With the advance of AI systems in recent years, it has become apparent that such agreements, in order to be acceptable to the involved parties, must remain aligned with ethical principles and moral values. However, this is notoriously difficult to ensure, especially as different human users (and their software agents) may hold different value systems, i.e. they may differently weigh the importance of individual moral values. Furthermore, it is often hard to specify the precise meaning of a value in a particular context in a computational manner. Methods to estimate value systems based on human-engineered specifications, e.g. based on value surveys, are limited in scale due to the need for intense human moderation. In this article, we propose a novel method to automatically \\emph{learn} value systems from observations and human demonstrations. In particular, we propose a formal model of the \\emph{value system learning} problem, its instantiation to sequential decision-making domains based on multi-objective Markov decision processes, as well as tailored preference-based and inverse reinforcement learning algorithms to infer value grounding functions and value systems. The approach is illustrated and evaluated by two simulated use cases.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ece\u89c2\u5bdf\u548c\u4eba\u7c7b\u6f14\u793a\u4e2d\u81ea\u52a8\u5b66\u4e60\u4ef7\u503c\u7cfb\u7edf\u7684\u65b0\u65b9\u6cd5\uff0c\u57fa\u4e8e\u591a\u76ee\u6807\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u504f\u597d\u5b66\u4e60\u548c\u9006\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6765\u63a8\u65ad\u4ef7\u503c\u57fa\u7840\u51fd\u6570\u548c\u4ef7\u503c\u7cfb\u7edf\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u53d1\u5c55\uff0c\u534f\u8bae\u6280\u672f\u9700\u8981\u4e0e\u4f26\u7406\u539f\u5219\u548c\u9053\u5fb7\u4ef7\u503c\u4fdd\u6301\u4e00\u81f4\uff0c\u4f46\u4e0d\u540c\u7528\u6237\u53ef\u80fd\u6301\u6709\u4e0d\u540c\u7684\u4ef7\u503c\u7cfb\u7edf\uff0c\u4e14\u96be\u4ee5\u5728\u8ba1\u7b97\u5c42\u9762\u5177\u4f53\u5316\u4ef7\u503c\u542b\u4e49\u3002\u73b0\u6709\u57fa\u4e8e\u4eba\u5de5\u89c4\u8303\u7684\u65b9\u6cd5\uff08\u5982\u4ef7\u503c\u8c03\u67e5\uff09\u53d7\u9650\u4e8e\u4eba\u5de5\u8c03\u5236\u7684\u89c4\u6a21\u3002", "method": "\u63d0\u51fa\u4ef7\u503c\u7cfb\u7edf\u5b66\u4e60\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u57fa\u4e8e\u591a\u76ee\u6807\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5c06\u5176\u5b9e\u4f8b\u5316\u5230\u5e8f\u5217\u51b3\u7b56\u9886\u57df\uff0c\u4f7f\u7528\u504f\u597d\u5b66\u4e60\u548c\u9006\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6765\u63a8\u65ad\u4ef7\u503c\u57fa\u7840\u51fd\u6570\u548c\u4ef7\u503c\u7cfb\u7edf\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u6a21\u62df\u7528\u4f8b\u8fdb\u884c\u8bf4\u660e\u548c\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u89c2\u5bdf\u548c\u6f14\u793a\u4e2d\u81ea\u52a8\u5b66\u4e60\u4ef7\u503c\u7cfb\u7edf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5b66\u4e60\u4ef7\u503c\u7cfb\u7edf\u7684\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u89c4\u8303\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u534f\u8bae\u6280\u672f\u4e2d\u7684\u4ef7\u503c\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04003", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04003", "abs": "https://arxiv.org/abs/2602.04003", "authors": ["Shutong Fan", "Lan Zhang", "Xiaoyong Yuan"], "title": "When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making", "comment": null, "summary": "Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent natural-language explanations that shape how users perceive and trust AI outputs, revealing a new attack surface at the cognitive layer: the communication channel between AI and its users. We introduce adversarial explanation attacks (AEAs), where an attacker manipulates the framing of LLM-generated explanations to modulate human trust in incorrect outputs. We formalize this behavioral threat through the trust miscalibration gap, a metric that captures the difference in human trust between correct and incorrect outputs under adversarial explanations. By incorporating this gap, AEAs explore the daunting threats in which persuasive explanations reinforce users' trust in incorrect predictions. To characterize this threat, we conducted a controlled experiment (n = 205), systematically varying four dimensions of explanation framing: reasoning mode, evidence type, communication style, and presentation format. Our findings show that users report nearly identical trust for adversarial and benign explanations, with adversarial explanations preserving the vast majority of benign trust despite being incorrect. The most vulnerable cases arise when AEAs closely resemble expert communication, combining authoritative evidence, neutral tone, and domain-appropriate reasoning. Vulnerability is highest on hard tasks, in fact-driven domains, and among participants who are less formally educated, younger, or highly trusting of AI. This is the first systematic security study that treats explanations as an adversarial cognitive channel and quantifies their impact on human trust in AI-assisted decision making.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5bf9\u6297\u6027\u89e3\u91ca\u653b\u51fb(AEAs)\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u64cd\u7eb5LLM\u751f\u6210\u89e3\u91ca\u7684\u6846\u67b6\u6765\u8c03\u8282\u4eba\u7c7b\u5bf9\u9519\u8bef\u8f93\u51fa\u7684\u4fe1\u4efb\uff0c\u63ed\u793a\u4e86AI\u4e0e\u7528\u6237\u4e4b\u95f4\u8ba4\u77e5\u5c42\u9762\u7684\u65b0\u653b\u51fb\u9762\u3002", "motivation": "\u73b0\u4ee3AI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u5728\u4eba\u7c7b\u51b3\u7b56\u5faa\u73af\u4e2d\u8fd0\u884c\uff0c\u7528\u6237\u4f9d\u8d56\u6a21\u578b\u63a8\u8350\u505a\u51fa\u51b3\u7b56\u3002LLM\u751f\u6210\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u4f1a\u5f71\u54cd\u7528\u6237\u5bf9AI\u8f93\u51fa\u7684\u611f\u77e5\u548c\u4fe1\u4efb\uff0c\u8fd9\u63ed\u793a\u4e86AI\u4e0e\u7528\u6237\u4e4b\u95f4\u8ba4\u77e5\u5c42\u9762\u7684\u65b0\u653b\u51fb\u9762\u3002\u76ee\u524d\u5927\u591a\u6570\u5bf9\u6297\u6027\u5a01\u80c1\u9488\u5bf9\u6a21\u578b\u7684\u8ba1\u7b97\u884c\u4e3a\uff0c\u800c\u975e\u4f9d\u8d56\u6a21\u578b\u7684\u4eba\u7c7b\u7528\u6237\u3002", "method": "\u5f15\u5165\u5bf9\u6297\u6027\u89e3\u91ca\u653b\u51fb(AEAs)\uff0c\u901a\u8fc7\u4fe1\u4efb\u6821\u51c6\u5dee\u8ddd\u6765\u5f62\u5f0f\u5316\u884c\u4e3a\u5a01\u80c1\u3002\u8fdb\u884c\u63a7\u5236\u5b9e\u9a8c(n=205)\uff0c\u7cfb\u7edf\u53d8\u5316\u89e3\u91ca\u6846\u67b6\u7684\u56db\u4e2a\u7ef4\u5ea6\uff1a\u63a8\u7406\u6a21\u5f0f\u3001\u8bc1\u636e\u7c7b\u578b\u3001\u6c9f\u901a\u98ce\u683c\u548c\u5448\u73b0\u683c\u5f0f\u3002\u91cf\u5316\u5bf9\u6297\u6027\u89e3\u91ca\u5bf9\u4eba\u7c7b\u4fe1\u4efb\u7684\u5f71\u54cd\u3002", "result": "\u7528\u6237\u5bf9\u5bf9\u6297\u6027\u548c\u826f\u6027\u89e3\u91ca\u62a5\u544a\u7684\u4fe1\u4efb\u5ea6\u51e0\u4e4e\u76f8\u540c\uff0c\u5bf9\u6297\u6027\u89e3\u91ca\u5c3d\u7ba1\u9519\u8bef\u4f46\u4ecd\u4fdd\u7559\u4e86\u5927\u90e8\u5206\u826f\u6027\u4fe1\u4efb\u3002\u6700\u8106\u5f31\u7684\u6848\u4f8b\u51fa\u73b0\u5728AEA\u6a21\u4eff\u4e13\u5bb6\u6c9f\u901a\u65f6\uff0c\u7ed3\u5408\u6743\u5a01\u8bc1\u636e\u3001\u4e2d\u6027\u8bed\u6c14\u548c\u9886\u57df\u9002\u5f53\u7684\u63a8\u7406\u3002\u5728\u56f0\u96be\u4efb\u52a1\u3001\u4e8b\u5b9e\u9a71\u52a8\u9886\u57df\u4ee5\u53ca\u6559\u80b2\u7a0b\u5ea6\u8f83\u4f4e\u3001\u8f83\u5e74\u8f7b\u6216\u9ad8\u5ea6\u4fe1\u4efbAI\u7684\u53c2\u4e0e\u8005\u4e2d\u8106\u5f31\u6027\u6700\u9ad8\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5c06\u89e3\u91ca\u89c6\u4e3a\u5bf9\u6297\u6027\u8ba4\u77e5\u901a\u9053\u5e76\u91cf\u5316\u5176\u5bf9AI\u8f85\u52a9\u51b3\u7b56\u4e2d\u4eba\u7c7b\u4fe1\u4efb\u5f71\u54cd\u7684\u7cfb\u7edf\u6027\u5b89\u5168\u7814\u7a76\u3002\u63ed\u793a\u4e86LLM\u89e3\u91ca\u53ef\u80fd\u88ab\u64cd\u7eb5\u6765\u7ef4\u6301\u7528\u6237\u5bf9\u9519\u8bef\u8f93\u51fa\u7684\u4fe1\u4efb\uff0c\u63d0\u51fa\u4e86AI\u5b89\u5168\u4e2d\u8ba4\u77e5\u5c42\u9762\u7684\u65b0\u5a01\u80c1\u3002"}}
{"id": "2602.04742", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.04742", "abs": "https://arxiv.org/abs/2602.04742", "authors": ["Molly Apsel", "Michael N. Jones"], "title": "Inference-Time Reasoning Selectively Reduces Implicit Social Bias in Large Language Models", "comment": null, "summary": "Drawing on constructs from psychology, prior work has identified a distinction between explicit and implicit bias in large language models (LLMs). While many LLMs undergo post-training alignment and safety procedures to avoid expressions of explicit social bias, they still exhibit significant implicit biases on indirect tasks resembling the Implicit Association Test (IAT). Recent work has further shown that inference-time reasoning can impair LLM performance on tasks that rely on implicit statistical learning. Motivated by a theoretical link between implicit associations and statistical learning in human cognition, we examine how reasoning-enabled inference affects implicit bias in LLMs. We find that enabling reasoning significantly reduces measured implicit bias on an IAT-style evaluation for some model classes across fifteen stereotype topics. This effect appears specific to social bias domains, as we observe no corresponding reduction for non-social implicit associations. As reasoning is increasingly enabled by default in deployed LLMs, these findings suggest that it can meaningfully alter fairness evaluation outcomes in some systems, while also raising questions about how alignment procedures interact with inference-time reasoning to drive variation in bias reduction across model types. More broadly, this work highlights how theory from cognitive science and psychology can complement AI evaluation research by providing methodological and interpretive frameworks that reveal new insights into model behavior.", "AI": {"tldr": "\u63a8\u7406\u80fd\u529b\u80fd\u663e\u8457\u964d\u4f4e\u67d0\u4e9bLLM\u5728IAT\u5f0f\u8bc4\u4f30\u4e2d\u7684\u9690\u6027\u504f\u89c1\uff0c\u4f46\u4ec5\u9650\u793e\u4f1a\u504f\u89c1\u9886\u57df\uff0c\u5bf9\u975e\u793e\u4f1a\u9690\u6027\u5173\u8054\u65e0\u6548", "motivation": "\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\uff0c\u7814\u7a76\u63a8\u7406\u80fd\u529b\u5982\u4f55\u5f71\u54cdLLM\u7684\u9690\u6027\u504f\u89c1\uff0c\u63a2\u7d22\u63a8\u7406\u4e0e\u5bf9\u9f50\u7a0b\u5e8f\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u5bfc\u81f4\u4e0d\u540c\u6a21\u578b\u7c7b\u578b\u7684\u504f\u89c1\u5dee\u5f02", "method": "\u4f7f\u7528IAT\u5f0f\u8bc4\u4f30\u65b9\u6cd5\uff0c\u572815\u4e2a\u523b\u677f\u5370\u8c61\u4e3b\u9898\u4e0a\u6d4b\u8bd5\u4e0d\u540c\u6a21\u578b\u7c7b\u522b\uff0c\u6bd4\u8f83\u542f\u7528\u63a8\u7406\u524d\u540e\u7684\u9690\u6027\u504f\u89c1\u53d8\u5316\uff0c\u5e76\u533a\u5206\u793e\u4f1a\u4e0e\u975e\u793e\u4f1a\u9886\u57df", "result": "\u542f\u7528\u63a8\u7406\u663e\u8457\u964d\u4f4e\u4e86\u67d0\u4e9b\u6a21\u578b\u7c7b\u522b\u5728IAT\u5f0f\u8bc4\u4f30\u4e2d\u7684\u9690\u6027\u504f\u89c1\u6d4b\u91cf\u503c\uff0c\u4f46\u8fd9\u79cd\u6548\u679c\u4ec5\u9650\u4e8e\u793e\u4f1a\u504f\u89c1\u9886\u57df\uff0c\u5bf9\u975e\u793e\u4f1a\u9690\u6027\u5173\u8054\u6ca1\u6709\u76f8\u5e94\u51cf\u5c11", "conclusion": "\u63a8\u7406\u80fd\u529b\u80fd\u6539\u53d8LLM\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u7ed3\u679c\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u5bf9\u9f50\u7a0b\u5e8f\u4e0e\u63a8\u7406\u65f6\u95f4\u63a8\u7406\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u7684\u95ee\u9898\uff0c\u8ba4\u77e5\u79d1\u5b66\u7406\u8bba\u80fd\u4e3aAI\u8bc4\u4f30\u63d0\u4f9b\u65b9\u6cd5\u8bba\u548c\u89e3\u91ca\u6846\u67b6"}}
{"id": "2602.04028", "categories": ["cs.AI", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04028", "abs": "https://arxiv.org/abs/2602.04028", "authors": ["Leila Amgoud", "Martin Cooper"], "title": "Axiomatic Foundations of Counterfactual Explanations", "comment": null, "summary": "Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process.\n  This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within this taxonomy, formally characterizes their behavior, and analyzes the computational complexity of generating such explanations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8e\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5668\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\uff0c\u8bc6\u522b\u4e86\u4e94\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e76\u5c06\u73b0\u6709\u89e3\u91ca\u5668\u7eb3\u5165\u5206\u7c7b\u4f53\u7cfb\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5668\u53ea\u5173\u6ce8\u5355\u4e00\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u548c\u5c40\u90e8\u89e3\u91ca\uff0c\u7f3a\u4e4f\u5bf9\u66ff\u4ee3\u53cd\u4e8b\u5b9e\u7c7b\u578b\u7684\u7cfb\u7edf\u7814\u7a76\uff0c\u4e5f\u6ca1\u6709\u7814\u7a76\u80fd\u591f\u63ed\u793a\u7cfb\u7edf\u6574\u4f53\u63a8\u7406\u8fc7\u7a0b\u7684\u5168\u5c40\u53cd\u4e8b\u5b9e\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4e00\u7ec4\u7406\u60f3\u5c5e\u6027\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u8bc1\u660e\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\uff0c\u5efa\u7acb\u8868\u793a\u5b9a\u7406\uff0c\u8bc6\u522b\u4e94\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e76\u5c06\u73b0\u6709\u89e3\u91ca\u5668\u7eb3\u5165\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86\u6ca1\u6709\u5355\u4e00\u89e3\u91ca\u5668\u80fd\u540c\u65f6\u6ee1\u8db3\u67d0\u4e9b\u516c\u7406\u7ec4\u5408\uff0c\u5efa\u7acb\u4e86\u516c\u7406\u5b50\u96c6\u4e0e\u89e3\u91ca\u5668\u5bb6\u65cf\u4e4b\u95f4\u7684\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff0c\u8bc6\u522b\u4e86\u4e94\u79cd\u6839\u672c\u4e0d\u540c\u7684\u53cd\u4e8b\u5b9e\u7c7b\u578b\uff0c\u5305\u62ec\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53cd\u4e8b\u5b9e\u89e3\u91ca\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u591a\u6837\u6027\uff0c\u4e3a\u7406\u89e3\u548c\u8bbe\u8ba1\u66f4\u5168\u9762\u7684\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2602.04759", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04759", "abs": "https://arxiv.org/abs/2602.04759", "authors": ["Michelle L. Ding", "Harini Suresh", "Suresh Venkatasubramanian"], "title": "How to Stop Playing Whack-a-Mole: Mapping the Ecosystem of Technologies Facilitating AI-Generated Non-Consensual Intimate Images", "comment": null, "summary": "The last decade has witnessed a rapid advancement of generative AI technology that significantly scaled the accessibility of AI-generated non-consensual intimate images (AIG-NCII), a form of image-based sexual abuse that disproportionately harms women and girls. There is a patchwork of commendable efforts across industry, policy, academia, and civil society to address AIG-NCII. However, these efforts lack a shared, consistent mental model that situates the technologies they target within the context of a large, interconnected, and ever-evolving technological ecosystem. As a result, interventions remain siloed and are difficult to evaluate and compare, leading to a reactive cycle of whack-a-mole. We contribute the first comprehensive AIG-NCII technological ecosystem that maps and taxonomizes 11 categories of technologies facilitating the creation, distribution, proliferation and discovery, infrastructural support, and monetization of AIG-NCII. First, we build and visualize the ecosystem through a synthesis of over a hundred primary sources from researchers, journalists, advocates, policymakers, and technologists. Next, we demonstrate how stakeholders can use the ecosystem as a tool to 1) understand new incidents of harm via a case study of Grok and 2) evaluate existing interventions via three more case studies. We conclude with three actionable recommendations, namely that stakeholders should 1) use the ecosystem to map out state, federal, and international laws to produce a clearer policy landscape, 2) collectively develop a database that dynamically tracks the 11 technologies in the ecosystem to better evaluate interventions, and 3) adopt a relational approach to researching AIG-NCII to better understand how the ecosystem technologies interact.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5168\u9762\u7684AIG-NCII\uff08AI\u751f\u6210\u975e\u81ea\u613f\u4eb2\u5bc6\u56fe\u50cf\uff09\u6280\u672f\u751f\u6001\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06\u76f8\u5173\u6280\u672f\u5206\u4e3a11\u4e2a\u7c7b\u522b\uff0c\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u7406\u89e3\u5371\u5bb3\u4e8b\u4ef6\u5e76\u8bc4\u4f30\u5e72\u9884\u63aa\u65bd\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4AIG-NCII\uff08\u4e3b\u8981\u4f24\u5bb3\u5987\u5973\u548c\u5973\u7ae5\u7684\u56fe\u50cf\u6027\u8650\u5f85\u5f62\u5f0f\uff09\u53ef\u53ca\u6027\u5927\u5e45\u63d0\u5347\u3002\u73b0\u6709\u5e94\u5bf9\u63aa\u65bd\u5206\u6563\u4e14\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\uff0c\u5bfc\u81f4\u5e72\u9884\u63aa\u65bd\u5b64\u7acb\u3001\u96be\u4ee5\u8bc4\u4f30\u548c\u6bd4\u8f83\uff0c\u5f62\u6210\"\u6253\u5730\u9f20\"\u5f0f\u7684\u88ab\u52a8\u5e94\u5bf9\u5faa\u73af\u3002", "method": "1. \u901a\u8fc7\u7efc\u5408\u7814\u7a76\u4eba\u5458\u3001\u8bb0\u8005\u3001\u5021\u5bfc\u8005\u3001\u653f\u7b56\u5236\u5b9a\u8005\u548c\u6280\u672f\u4e13\u5bb6\u7684100\u591a\u4e2a\u4e3b\u8981\u6765\u6e90\uff0c\u6784\u5efa\u5e76\u53ef\u89c6\u5316AIG-NCII\u6280\u672f\u751f\u6001\u7cfb\u7edf\n2. \u5c06\u6280\u672f\u5206\u4e3a11\u4e2a\u7c7b\u522b\uff1a\u521b\u4f5c\u3001\u5206\u53d1\u3001\u4f20\u64ad\u4e0e\u53d1\u73b0\u3001\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u548c\u8d27\u5e01\u5316\u7b49\n3. \u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff08\u5305\u62ecGrok\u6848\u4f8b\uff09\u5c55\u793a\u751f\u6001\u7cfb\u7edf\u5982\u4f55\u5e2e\u52a9\u7406\u89e3\u65b0\u7684\u5371\u5bb3\u4e8b\u4ef6\n4. \u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5982\u4f55\u8bc4\u4f30\u73b0\u6709\u5e72\u9884\u63aa\u65bd", "result": "\u5f00\u53d1\u4e86\u9996\u4e2a\u5168\u9762\u7684AIG-NCII\u6280\u672f\u751f\u6001\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06\u76f8\u5173\u6280\u672f\u7cfb\u7edf\u6027\u5730\u5206\u4e3a11\u4e2a\u7c7b\u522b\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u8be5\u6846\u67b6\u80fd\u6709\u6548\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\uff1a1\uff09\u7406\u89e3\u65b0\u7684\u5371\u5bb3\u4e8b\u4ef6\uff08\u5982Grok\u6848\u4f8b\uff09\uff1b2\uff09\u8bc4\u4f30\u73b0\u6709\u5e72\u9884\u63aa\u65bd\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e09\u9879\u53ef\u64cd\u4f5c\u5efa\u8bae\uff1a1\uff09\u5229\u7528\u751f\u6001\u7cfb\u7edf\u6846\u67b6\u68b3\u7406\u5dde\u3001\u8054\u90a6\u548c\u56fd\u9645\u6cd5\u5f8b\uff0c\u5f62\u6210\u66f4\u6e05\u6670\u7684\u653f\u7b56\u683c\u5c40\uff1b2\uff09\u5171\u540c\u5f00\u53d1\u52a8\u6001\u8ddf\u8e2a\u751f\u6001\u7cfb\u7edf\u4e2d11\u7c7b\u6280\u672f\u7684\u6570\u636e\u5e93\uff0c\u4ee5\u66f4\u597d\u8bc4\u4f30\u5e72\u9884\u63aa\u65bd\uff1b3\uff09\u91c7\u7528\u5173\u7cfb\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u66f4\u597d\u5730\u7406\u89e3\u751f\u6001\u7cfb\u7edf\u6280\u672f\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2602.04089", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04089", "abs": "https://arxiv.org/abs/2602.04089", "authors": ["Xiaofeng Lin", "Sirou Zhu", "Yilei Chen", "Mingyu Chen", "Hejian Sang", "Ioannis Paschalidis", "Zhipeng Wang", "Aldo Pacchiano", "Xuezhou Zhang"], "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL", "comment": null, "summary": "Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.", "AI": {"tldr": "ORBIT\u6846\u67b6\u901a\u8fc7\u5143\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLMs\u5728\u4e0a\u4e0b\u6587\u4e2d\u4ece\u4ea4\u4e92\u4e2d\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u672a\u89c1\u73af\u5883\u4e2d\u7684\u5728\u7ebf\u5b66\u4e60\u80fd\u529b", "motivation": "\u73b0\u6709LLMs\u5728\u9700\u8981\u5728\u7ebf\u4ea4\u4e92\u7684\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u53ef\u9760\u5229\u7528\u4e0a\u4e0b\u6587\u4ea4\u4e92\u7ecf\u9a8c\uff0c\u9700\u8981\u5e73\u8861\u4fe1\u606f\u6536\u96c6\u548c\u5229\u7528", "method": "\u63d0\u51faORBIT\u6846\u67b6\uff1a\u591a\u4efb\u52a1\u3001\u591a\u56de\u5408\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3LLMs\u5728\u4e0a\u4e0b\u6587\u4e2d\u4ece\u4ea4\u4e92\u4e2d\u5b66\u4e60", "result": "\u7ecf\u8fc7\u5143\u8bad\u7ec3\u540e\uff0c\u76f8\u5bf9\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b(Qwen3-14B)\u5728\u5168\u65b0\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u7684\u5728\u7ebf\u5b66\u4e60\u80fd\u529b\uff0c\u5339\u914dGPT-5.2\u6027\u80fd\uff0c\u5927\u5e45\u4f18\u4e8e\u6807\u51c6RL\u5fae\u8c03", "conclusion": "\u901a\u8fc7\u8bad\u7ec3\u53ef\u4ee5\u89e3\u51b3LLMs\u5728\u7ebf\u5b66\u4e60\u80fd\u529b\u7684\u9650\u5236\uff0c\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u5b9e\u9a8c\u663e\u793a\u6301\u7eed\u589e\u76ca\uff0c\u8868\u660e\u5b66\u4e60\u578b\u63a8\u7406\u65f6\u51b3\u7b56\u4ee3\u7406\u6709\u5de8\u5927\u6f5c\u529b"}}
{"id": "2602.04101", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04101", "abs": "https://arxiv.org/abs/2602.04101", "authors": ["Harsha Vardhan Khurdula", "Vineet Agarwal", "Yoeven D Khemlani"], "title": "Interfaze: The Future of AI is built on Task-Specific Small Models", "comment": "8 pages, 1 figure", "summary": "We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external sources (web pages, code, PDFs) into compact structured state, and (iii) an action layer that can browse, retrieve, execute code in a sandbox, and drive a headless browser for dynamic web pages. A thin controller sits on top of this stack and exposes a single, OpenAI-style endpoint: it decides which small models and actions to run and always forwards the distilled context to a user-selected LLM that produces the final response.\n  On this architecture, Interfaze-Beta achieves 83.6% on MMLU-Pro, 91.4% on MMLU, 81.3% on GPQA-Diamond, 57.8% on LiveCodeBench v5, and 90.0% on AIME-2025, along with strong multimodal scores on MMMU (val) (77.3%), AI2D (91.5%), ChartQA (90.9%), and Common Voice v16 (90.8%). We show that most queries are handled primarily by the small-model and tool stack, with the large LLM operating only on distilled context, yielding competitive accuracy while shifting the bulk of computation away from the most expensive and monolithic models.", "AI": {"tldr": "Interfaze\u662f\u4e00\u4e2a\u5c06LLM\u5e94\u7528\u89c6\u4e3a\u4e0a\u4e0b\u6587\u6784\u5efa\u4e0e\u6267\u884c\u95ee\u9898\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f02\u6784DNN\u5806\u6808\u3001\u4e0a\u4e0b\u6587\u6784\u5efa\u5c42\u548c\u884c\u52a8\u5c42\uff0c\u7ed3\u5408\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\uff0c\u5c06\u5927\u90e8\u5206\u8ba1\u7b97\u4ece\u6602\u8d35\u7684\u5927\u578b\u6a21\u578b\u4e2d\u8f6c\u79fb\u51fa\u6765\u3002", "motivation": "\u73b0\u4ee3LLM\u5e94\u7528\u4e0d\u5e94\u4ec5\u4f9d\u8d56\u5355\u4e00\u5927\u578b\u6a21\u578b\uff0c\u800c\u5e94\u89c6\u4e3a\u4e0a\u4e0b\u6587\u6784\u5efa\u4e0e\u6267\u884c\u95ee\u9898\u3002\u9700\u8981\u5c06\u590d\u6742\u4efb\u52a1\u5206\u89e3\u4e3a\u611f\u77e5\u3001\u4e0a\u4e0b\u6587\u6784\u5efa\u548c\u884c\u52a8\u6267\u884c\uff0c\u4ee5\u964d\u4f4e\u5bf9\u6602\u8d35\u5927\u578b\u6a21\u578b\u7684\u4f9d\u8d56\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) \u5f02\u6784DNN\u5806\u6808\u914d\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u611f\u77e5\u6a21\u5757\uff0c\u5904\u7406\u590d\u6742PDF\u3001\u56fe\u8868\u3001\u591a\u8bed\u8a00ASR\u7b49\uff1b(2) \u4e0a\u4e0b\u6587\u6784\u5efa\u5c42\u722c\u53d6\u3001\u7d22\u5f15\u3001\u89e3\u6790\u5916\u90e8\u8d44\u6e90\u4e3a\u7ed3\u6784\u5316\u72b6\u6001\uff1b(3) \u884c\u52a8\u5c42\u652f\u6301\u6d4f\u89c8\u3001\u68c0\u7d22\u3001\u6c99\u7bb1\u4ee3\u7801\u6267\u884c\u3001\u65e0\u5934\u6d4f\u89c8\u5668\u9a71\u52a8\u3002\u9876\u5c42\u63a7\u5236\u5668\u51b3\u5b9a\u4f7f\u7528\u54ea\u4e9b\u5c0f\u578b\u6a21\u578b\u548c\u884c\u52a8\uff0c\u5e76\u5c06\u63d0\u70bc\u7684\u4e0a\u4e0b\u6587\u8f6c\u53d1\u7ed9\u7528\u6237\u9009\u62e9\u7684LLM\u751f\u6210\u6700\u7ec8\u54cd\u5e94\u3002", "result": "Interfaze-Beta\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1aMMLU-Pro 83.6%\u3001MMLU 91.4%\u3001GPQA-Diamond 81.3%\u3001LiveCodeBench v5 57.8%\u3001AIME-2025 90.0%\uff0c\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u4e5f\u6709\u5f3a\u52b2\u8868\u73b0\u3002\u5927\u591a\u6570\u67e5\u8be2\u4e3b\u8981\u7531\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u5806\u6808\u5904\u7406\uff0c\u5927\u578bLLM\u4ec5\u64cd\u4f5c\u63d0\u70bc\u540e\u7684\u4e0a\u4e0b\u6587\uff0c\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u51c6\u786e\u5ea6\u540c\u65f6\u5c06\u5927\u90e8\u5206\u8ba1\u7b97\u4ece\u6602\u8d35\u7684\u5927\u578b\u6a21\u578b\u4e2d\u8f6c\u79fb\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u5e94\u7528\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e0a\u4e0b\u6587\u6784\u5efa\u4e0e\u6267\u884c\u95ee\u9898\uff0c\u7ed3\u5408\u5f02\u6784\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u5806\u6808\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5bf9\u6602\u8d35\u5927\u578b\u6a21\u578b\u7684\u4f9d\u8d56\uff0c\u4e3a\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684AI\u7cfb\u7edf\u67b6\u6784\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.04813", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.04813", "abs": "https://arxiv.org/abs/2602.04813", "authors": ["Shubham Vatsal", "Harsh Dubey", "Aditi Singh"], "title": "Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents", "comment": null, "summary": "Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e03\u7ef4\u5206\u7c7b\u6cd5\u6765\u7cfb\u7edf\u8bc4\u4f30\u533b\u7597\u9886\u57dfLLM\u667a\u80fd\u4f53\u7684\u80fd\u529b\u73b0\u72b6\uff0c\u901a\u8fc7\u5bf949\u9879\u7814\u7a76\u7684\u5206\u6790\u63ed\u793a\u4e86\u80fd\u529b\u5b9e\u73b0\u7684\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u73b0\u6709\u533b\u7597LLM\u667a\u80fd\u4f53\u7814\u7a76\u591a\u4e3a\u6982\u8ff0\u6027\u8c03\u67e5\u6216\u5355\u4e00\u80fd\u529b\u63a2\u8ba8\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u533b\u7597\u9886\u57df\u667a\u80fd\u4f53\u7814\u7a76\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "\u5f00\u53d1\u4e03\u7ef4\u5206\u7c7b\u6cd5\uff08\u8ba4\u77e5\u80fd\u529b\u3001\u77e5\u8bc6\u7ba1\u7406\u3001\u4ea4\u4e92\u6a21\u5f0f\u3001\u9002\u5e94\u4e0e\u5b66\u4e60\u3001\u5b89\u5168\u4e0e\u4f26\u7406\u3001\u6846\u67b6\u7c7b\u578b\u5b66\u3001\u6838\u5fc3\u4efb\u52a1\u4e0e\u5b50\u4efb\u52a1\uff09\uff0c\u5305\u542b29\u4e2a\u64cd\u4f5c\u5b50\u7ef4\u5ea6\u3002\u4f7f\u7528\u660e\u786e\u7eb3\u5165\u6392\u9664\u6807\u51c6\u548c\u6807\u7b7e\u89c4\u5219\uff08\u5b8c\u5168\u5b9e\u73b0\u3001\u90e8\u5206\u5b9e\u73b0\u3001\u672a\u5b9e\u73b0\uff09\uff0c\u5bf949\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6620\u5c04\u548c\u5b9a\u91cf\u5206\u6790\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u660e\u663e\u7684\u80fd\u529b\u4e0d\u5bf9\u79f0\uff1a\u5916\u90e8\u77e5\u8bc6\u6574\u5408\u666e\u904d\u5b9e\u73b0\uff0876%\u5b8c\u5168\u5b9e\u73b0\uff09\uff0c\u800c\u4e8b\u4ef6\u89e6\u53d1\u6fc0\u6d3b\uff0892%\u672a\u5b9e\u73b0\uff09\u548c\u6f02\u79fb\u68c0\u6d4b\u4e0e\u7f13\u89e3\uff0898%\u672a\u5b9e\u73b0\uff09\u4e25\u91cd\u7f3a\u5931\u3002\u67b6\u6784\u4e0a\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u5360\u4e3b\u5bfc\uff0882%\u5b8c\u5168\u5b9e\u73b0\uff09\uff0c\u4f46\u7f16\u6392\u5c42\u5927\u591a\u4e0d\u5b8c\u6574\u3002\u6838\u5fc3\u4efb\u52a1\u4e2d\u4fe1\u606f\u4e2d\u5fc3\u80fd\u529b\u9886\u5148\uff0c\u800c\u6cbb\u7597\u89c4\u5212\u7b49\u884c\u52a8\u5bfc\u5411\u9886\u57df\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\uff0859%\u672a\u5b9e\u73b0\uff09\u3002", "conclusion": "\u533b\u7597LLM\u667a\u80fd\u4f53\u7814\u7a76\u5728\u77e5\u8bc6\u6574\u5408\u548c\u591a\u667a\u80fd\u4f53\u67b6\u6784\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u81ea\u9002\u5e94\u5b66\u4e60\u3001\u4e8b\u4ef6\u9a71\u52a8\u4ea4\u4e92\u548c\u884c\u52a8\u5bfc\u5411\u4efb\u52a1\u65b9\u9762\u5b58\u5728\u660e\u663e\u77ed\u677f\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.04144", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04144", "abs": "https://arxiv.org/abs/2602.04144", "authors": ["Ruiting Dai", "Zheyu Wang", "Haoyu Yang", "Yihan Liu", "Chengzhi Wang", "Zekun Zhang", "Zishan Huang", "Jiaman Cen", "Lisi Mo"], "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows", "comment": null, "summary": "Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retrieval rigidity. Critically, these end-to-end architectures are fundamentally constrained by Semantic-Detail Entanglement -- a structural conflict between logical reasoning and signal synthesis that compromises fidelity. In this paper, we present \\textbf{\\underline{O}}mni-\\textbf{\\underline{M}}odality \\textbf{\\underline{G}}eneration Agent (\\textbf{OMG-Agent}), a novel framework that shifts the paradigm from static mapping to a dynamic coarse-to-fine Agentic Workflow. By mimicking a \\textit{deliberate-then-act} cognitive process, OMG-Agent explicitly decouples the task into three synergistic stages: (1) an MLLM-driven Semantic Planner that resolves input ambiguity via Progressive Contextual Reasoning, creating a deterministic structured semantic plan; (2) a non-parametric Evidence Retriever that grounds abstract semantics in external knowledge; and (3) a Retrieval-Injected Executor that utilizes retrieved evidence as flexible feature prompts to overcome rigidity and synthesize high-fidelity details. Extensive experiments on multiple benchmarks demonstrate that OMG-Agent consistently surpasses state-of-the-art methods, maintaining robustness under extreme missingness, e.g., a $2.6$-point gain on CMU-MOSI at $70$\\% missing rates.", "AI": {"tldr": "OMG-Agent\uff1a\u4e00\u79cd\u65b0\u578b\u591a\u6a21\u6001\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u8bed\u4e49\u89c4\u5212\u3001\u8bc1\u636e\u68c0\u7d22\u548c\u6267\u884c\u5408\u6210\u4e09\u9636\u6bb5\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u8bed\u4e49-\u7ec6\u8282\u7ea0\u7f20\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6570\u636e\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u7684\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u7cfb\u7edf\u5728\u6570\u636e\u4e0d\u5b8c\u6574\u65f6\u53ef\u9760\u6027\u5dee\uff1a\u4f20\u7edf\u53c2\u6570/\u751f\u6210\u6a21\u578b\u56e0\u8fc7\u5ea6\u4f9d\u8d56\u5185\u90e8\u8bb0\u5fc6\u800c\u4ea7\u751f\u5e7b\u89c9\uff0c\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\u5219\u53d7\u9650\u4e8e\u68c0\u7d22\u521a\u6027\u3002\u8fd9\u4e9b\u7aef\u5230\u7aef\u67b6\u6784\u5b58\u5728\u8bed\u4e49-\u7ec6\u8282\u7ea0\u7f20\u7684\u7ed3\u6784\u6027\u51b2\u7a81\uff0c\u635f\u5bb3\u4e86\u751f\u6210\u4fdd\u771f\u5ea6\u3002", "method": "\u63d0\u51faOMG-Agent\u6846\u67b6\uff0c\u91c7\u7528\u52a8\u6001\u7c97\u5230\u7ec6\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff1a1) MLLM\u9a71\u52a8\u7684\u8bed\u4e49\u89c4\u5212\u5668\u901a\u8fc7\u6e10\u8fdb\u4e0a\u4e0b\u6587\u63a8\u7406\u89e3\u51b3\u8f93\u5165\u6b67\u4e49\uff1b2) \u975e\u53c2\u6570\u8bc1\u636e\u68c0\u7d22\u5668\u5c06\u62bd\u8c61\u8bed\u4e49\u951a\u5b9a\u5230\u5916\u90e8\u77e5\u8bc6\uff1b3) \u68c0\u7d22\u6ce8\u5165\u6267\u884c\u5668\u5229\u7528\u68c0\u7d22\u8bc1\u636e\u4f5c\u4e3a\u7075\u6d3b\u7279\u5f81\u63d0\u793a\u5408\u6210\u9ad8\u4fdd\u771f\u7ec6\u8282\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOMG-Agent\u59cb\u7ec8\u8d85\u8d8a\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u6781\u7aef\u7f3a\u5931\u60c5\u51b5\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u4f8b\u5982\u5728CMU-MOSI\u6570\u636e\u96c6\u4e0a70%\u7f3a\u5931\u7387\u65f6\u83b7\u5f972.6\u5206\u7684\u63d0\u5347\u3002", "conclusion": "OMG-Agent\u901a\u8fc7\u89e3\u8026\u8bed\u4e49\u89c4\u5212\u548c\u7ec6\u8282\u5408\u6210\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u751f\u6210\u4e2d\u7684\u8bed\u4e49-\u7ec6\u8282\u7ea0\u7f20\u95ee\u9898\uff0c\u4e3a\u6570\u636e\u4e0d\u5b8c\u6574\u573a\u666f\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04210", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04210", "abs": "https://arxiv.org/abs/2602.04210", "authors": ["Enyu Zhou", "Zhiheng Xi", "Long Ma", "Zhihao Zhang", "Shihan Dou", "Zhikai Lei", "Guoteng Wang", "Rui Zheng", "Hang Yan", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Steering LLMs via Scalable Interactive Oversight", "comment": null, "summary": "As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\\% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faScalable Interactive Oversight\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u590d\u6742\u610f\u56fe\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u51b3\u7b56\u6811\uff0c\u8ba9\u975e\u4e13\u5bb6\u7528\u6237\u4e5f\u80fd\u6709\u6548\u76d1\u7763AI\u5b8c\u6210\u8d85\u51fa\u81ea\u8eab\u80fd\u529b\u8303\u56f4\u7684\u590d\u6742\u4efb\u52a1\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u81ea\u52a8\u5316\u5b8c\u6210\u590d\u6742\u957f\u671f\u4efb\u52a1\uff0c\u51fa\u73b0\u4e86\u76d1\u7763\u7f3a\u53e3\uff1a\u7528\u6237\u56e0\u7f3a\u4e4f\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3001\u96be\u4ee5\u7cbe\u786e\u8868\u8fbe\u610f\u56fe\u3001\u65e0\u6cd5\u53ef\u9760\u9a8c\u8bc1\u590d\u6742\u8f93\u51fa\uff0c\u96be\u4ee5\u6709\u6548\u6307\u5bfcAI\u7cfb\u7edf\u3002\u8fd9\u63d0\u51fa\u4e86\u53ef\u6269\u5c55\u76d1\u7763\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51faScalable Interactive Oversight\u6846\u67b6\uff0c\u5c06\u590d\u6742\u610f\u56fe\u9012\u5f52\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u51b3\u7b56\u6811\uff0c\u5728\u8282\u70b9\u5904\u6536\u96c6\u4f4e\u8d1f\u62c5\u7684\u4eba\u7c7b\u53cd\u9988\uff0c\u9012\u5f52\u805a\u5408\u4e3a\u7cbe\u786e\u7684\u5168\u5c40\u6307\u5bfc\uff0c\u800c\u975e\u4f9d\u8d56\u5f00\u653e\u5f0f\u63d0\u793a\u3002", "result": "\u5728\u7f51\u9875\u5f00\u53d1\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u4f7f\u975e\u4e13\u5bb6\u80fd\u751f\u6210\u4e13\u5bb6\u7ea7\u4ea7\u54c1\u9700\u6c42\u6587\u6863\uff0c\u5bf9\u9f50\u5ea6\u63d0\u534754%\u3002\u6846\u67b6\u53ef\u901a\u8fc7\u4ec5\u4f7f\u7528\u5728\u7ebf\u7528\u6237\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4f18\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u89e3\u51b3AI\u6269\u5c55\u4e2d\u7684\u4eba\u7c7b\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u4f7f\u4eba\u7c7b\u80fd\u5728\u8d85\u8d8a\u81ea\u8eab\u80fd\u529b\u7684\u4efb\u52a1\u4e0a\u8d1f\u8d23\u4efb\u5730\u6307\u5bfcAI\u7cfb\u7edf\u3002"}}
{"id": "2602.04213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04213", "abs": "https://arxiv.org/abs/2602.04213", "authors": ["Feiyu Gavin Zhu", "Jean Oh", "Reid Simmons"], "title": "InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons", "comment": "Proceedings of the 21st ACM/IEEE International Conference on Human-Robot Interaction", "summary": "Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent new skills. To lower the barrier of teaching AI agents, we propose Interactive Policy Restructuring and Training (InterPReT), which takes user instructions to continually update the policy structure and optimize its parameters to fit user demonstrations. This enables end-users to interactively give instructions and demonstrations, monitor the agent's performance, and review the agent's decision-making strategies. A user study (N=34) on teaching an AI agent to drive in a racing game confirms that our approach yields more robust policies without impairing system usability, compared to a generic imitation learning baseline, when a layperson is responsible for both giving demonstrations and determining when to stop. This shows that our method is more suitable for end-users without much technical background in machine learning to train a dependable policy", "AI": {"tldr": "InterPReT\uff1a\u4e00\u79cd\u4ea4\u4e92\u5f0f\u7b56\u7565\u91cd\u6784\u4e0e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u8ba9\u975e\u4e13\u4e1a\u7528\u6237\u80fd\u591f\u901a\u8fc7\u6307\u4ee4\u548c\u6f14\u793a\u6765\u8bad\u7ec3AI\u4ee3\u7406\uff0c\u964d\u4f4eAI\u6559\u5b66\u95e8\u69db", "motivation": "\u73b0\u6709\u6a21\u4eff\u5b66\u4e60\u9700\u8981\u4e13\u4e1a\u4eba\u5458\u7684\u6f14\u793a\u548c\u8bad\u7ec3\u76d1\u63a7\uff0c\u8fd9\u5bf9\u666e\u901a\u7528\u6237\u6765\u8bf4\u95e8\u69db\u592a\u9ad8\u3002\u9700\u8981\u964d\u4f4e\u975e\u4e13\u4e1a\u7528\u6237\u6559\u5b66AI\u4ee3\u7406\u7684\u95e8\u69db\uff0c\u8ba9\u666e\u901a\u7528\u6237\u80fd\u591f\u4ea4\u4e92\u5f0f\u5730\u6559\u5bfcAI\u4ee3\u7406\u65b0\u6280\u80fd", "method": "\u63d0\u51faInteractive Policy Restructuring and Training (InterPReT)\uff0c\u901a\u8fc7\u7528\u6237\u6307\u4ee4\u6301\u7eed\u66f4\u65b0\u7b56\u7565\u7ed3\u6784\u5e76\u4f18\u5316\u53c2\u6570\u4ee5\u9002\u5e94\u6f14\u793a\uff0c\u652f\u6301\u7528\u6237\u4ea4\u4e92\u5f0f\u63d0\u4f9b\u6307\u4ee4\u548c\u6f14\u793a\u3001\u76d1\u63a7\u4ee3\u7406\u6027\u80fd\u3001\u5ba1\u67e5\u51b3\u7b56\u7b56\u7565", "result": "\u5728\u8d5b\u8f66\u6e38\u620f\u6559\u5b66\u7684\u7528\u6237\u7814\u7a76\uff08N=34\uff09\u4e2d\uff0c\u76f8\u6bd4\u901a\u7528\u6a21\u4eff\u5b66\u4e60\u57fa\u7ebf\uff0cInterPReT\u5728\u666e\u901a\u7528\u6237\u8d1f\u8d23\u6f14\u793a\u548c\u51b3\u5b9a\u505c\u6b62\u65f6\u673a\u65f6\uff0c\u80fd\u4ea7\u751f\u66f4\u9c81\u68d2\u7684\u7b56\u7565\u4e14\u4e0d\u5f71\u54cd\u7cfb\u7edf\u53ef\u7528\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u66f4\u9002\u5408\u6ca1\u6709\u673a\u5668\u5b66\u4e60\u6280\u672f\u80cc\u666f\u7684\u7ec8\u7aef\u7528\u6237\u8bad\u7ec3\u53ef\u9760\u7684\u7b56\u7565\uff0c\u964d\u4f4e\u4e86AI\u6559\u5b66\u7684\u95e8\u69db"}}
{"id": "2602.04248", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.04248", "abs": "https://arxiv.org/abs/2602.04248", "authors": ["Hao Lu", "Haoyuan Huang", "Yulin Zhou", "Chen Li", "Ningxin Zhu"], "title": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "comment": "9 pages, 5 figures", "summary": "Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. These results underscore the critical necessity of coupling structured search with empirical accumulation for mastering complex, open-ended reasoning tasks.", "AI": {"tldr": "Empirical-MCTS\uff1a\u4e00\u79cd\u5c06\u65e0\u72b6\u6001MCTS\u8f6c\u53d8\u4e3a\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u7684\u53cc\u5faa\u73af\u6846\u67b6\uff0c\u901a\u8fc7\u5c40\u90e8\u63a2\u7d22\u4e0e\u5168\u5c40\u8bb0\u5fc6\u4f18\u5316\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b", "motivation": "\u5f53\u524d\u63a8\u7406\u65f6\u6269\u5c55\u7b56\u7565\uff08\u5982MCTS\uff09\u4e3b\u8981\u662f\u65e0\u72b6\u6001\u7684\uff0c\u6bcf\u6b21\u89e3\u51b3\u95ee\u9898\u540e\u4e22\u5f03\u6210\u529f\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u65e0\u6cd5\u6a21\u4eff\u4eba\u7c7b\u7ecf\u9a8c\u79ef\u7d2f\u7684\u667a\u6167\u7279\u5f81\u3002\u9700\u8981\u5c06\u7ed3\u6784\u5316\u641c\u7d22\u4e0e\u7ecf\u9a8c\u79ef\u7d2f\u76f8\u7ed3\u5408\u6765\u638c\u63e1\u590d\u6742\u7684\u5f00\u653e\u5f0f\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u63d0\u51faEmpirical-MCTS\u53cc\u5faa\u73af\u6846\u67b6\uff1a1) PE-EMP\uff08\u6210\u5bf9\u7ecf\u9a8c\u8fdb\u5316\u5143\u63d0\u793a\uff09\u4f5c\u4e3a\u5c40\u90e8\u641c\u7d22\u7684\u53cd\u5c04\u4f18\u5316\u5668\uff0c\u4f7f\u7528\u6210\u5bf9\u53cd\u9988\u52a8\u6001\u5408\u6210\u81ea\u9002\u5e94\u6807\u51c6\u5e76\u5b9e\u65f6\u6f14\u5316\u5143\u63d0\u793a\uff1b2) \u8bb0\u5fc6\u4f18\u5316\u4ee3\u7406\u7ba1\u7406\u5168\u5c40\u5b58\u50a8\u5e93\u4f5c\u4e3a\u52a8\u6001\u7b56\u7565\u5148\u9a8c\uff0c\u4f7f\u7528\u539f\u5b50\u64cd\u4f5c\u8de8\u95ee\u9898\u63d0\u70bc\u9ad8\u8d28\u91cf\u89c1\u89e3\u3002", "result": "\u5728\u590d\u6742\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08AIME25\u3001ARC-AGI-2\u3001MathArena Apex\uff09\u4e0a\uff0cEmpirical-MCTS\u663e\u8457\u4f18\u4e8e\u65e0\u72b6\u6001MCTS\u7b56\u7565\u548c\u72ec\u7acb\u7ecf\u9a8c\u9a71\u52a8\u4ee3\u7406\uff0c\u8bc1\u660e\u4e86\u7ed3\u6784\u5316\u641c\u7d22\u4e0e\u7ecf\u9a8c\u79ef\u7d2f\u7ed3\u5408\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u5c06\u7ed3\u6784\u5316\u641c\u7d22\u4e0e\u7ecf\u9a8c\u79ef\u7d2f\u76f8\u7ed3\u5408\u5bf9\u4e8e\u638c\u63e1\u590d\u6742\u5f00\u653e\u5f0f\u63a8\u7406\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0cEmpirical-MCTS\u6846\u67b6\u6210\u529f\u5730\u5c06\u65e0\u72b6\u6001\u641c\u7d22\u8f6c\u53d8\u4e3a\u6301\u7eed\u7684\u975e\u53c2\u6570\u5b66\u4e60\u8fc7\u7a0b\u3002"}}
{"id": "2602.04284", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04284", "abs": "https://arxiv.org/abs/2602.04284", "authors": ["Yansong Ning", "Jun Fang", "Naiqiang Tan", "Hao Liu"], "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning", "comment": "Under Review", "summary": "Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.", "AI": {"tldr": "Agent-Omit\uff1a\u4e00\u4e2a\u7edf\u4e00\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u8ba9LLM\u4ee3\u7406\u80fd\u81ea\u9002\u5e94\u5730\u7701\u7565\u5197\u4f59\u7684\u601d\u8003\u548c\u89c2\u5bdf\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06\u6574\u4e2a\u4ea4\u4e92\u8f68\u8ff9\u540c\u7b49\u5bf9\u5f85\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u8f6e\u6b21\u4e2d\u601d\u8003\u5fc5\u8981\u6027\u548c\u89c2\u5bdf\u6548\u7528\u7684\u5dee\u5f02\uff0c\u5bfc\u81f4\u4ee3\u7406\u6548\u7387\u4f4e\u4e0b", "method": "1) \u5408\u6210\u5c11\u91cf\u51b7\u542f\u52a8\u6570\u636e\uff08\u5355\u8f6e\u548c\u591a\u8f6e\u7701\u7565\u573a\u666f\uff09\u5fae\u8c03\u4ee3\u7406\uff1b2) \u63d0\u51fa\u7701\u7565\u611f\u77e5\u7684\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u542b\u53cc\u91cd\u91c7\u6837\u673a\u5236\u548c\u5b9a\u5236\u7684\u7701\u7565\u5956\u52b1\uff1b3) \u7406\u8bba\u4e0a\u8bc1\u660e\u7701\u7565\u7b56\u7565\u7684\u504f\u5dee\u53d7KL\u6563\u5ea6\u4e0a\u754c\u7ea6\u675f", "result": "\u5728\u4e94\u4e2a\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgent-Omit-8B\u6027\u80fd\u53ef\u4e0e\u524d\u6cbfLLM\u4ee3\u7406\u76f8\u5ab2\u7f8e\uff0c\u5e76\u5728\u6548\u7387-\u6548\u679c\u6743\u8861\u4e0a\u4f18\u4e8e\u4e03\u79cd\u9ad8\u6548LLM\u4ee3\u7406\u65b9\u6cd5", "conclusion": "Agent-Omit\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7406\u6548\u7387\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7701\u7565\u5197\u4f59\u601d\u8003\u548c\u89c2\u5bdf\u5b9e\u73b0\u66f4\u597d\u7684\u6548\u679c-\u6548\u7387\u5e73\u8861\uff0c\u4e3a\u9ad8\u6548\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2602.04326", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.04326", "abs": "https://arxiv.org/abs/2602.04326", "authors": ["SeungWon Seo", "SooBin Lim", "SeongRae Noh", "Haneul Kim", "HyeongYeop Kang"], "title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents", "comment": "31 pages, 10 figures, Accepted ICLR 2026", "summary": "Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.", "AI": {"tldr": "PCE\u6846\u67b6\u5c06LLM\u63a8\u7406\u4e2d\u7684\u9690\u542b\u5047\u8bbe\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u901a\u8fc7\u573a\u666f\u53ef\u80fd\u6027\u3001\u76ee\u6807\u6536\u76ca\u548c\u6267\u884c\u6210\u672c\u8bc4\u5206\u6765\u6307\u5bfc\u884c\u52a8\u9009\u62e9\uff0c\u51cf\u5c11\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u901a\u4fe1\u5f00\u9500", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u3001\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\uff0c\u667a\u80fd\u4f53\u9700\u8981\u5904\u7406\u9690\u85cf\u5bf9\u8c61\u548c\u534f\u4f5c\u4f19\u4f34\u610f\u56fe\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u73b0\u6709LLM\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u9891\u7e41\u901a\u4fe1\u6765\u7f13\u89e3\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u8fd9\u4f1a\u4ea7\u751f\u9ad8\u6602\u7684token\u548c\u65f6\u95f4\u6210\u672c\uff0c\u5e76\u53ef\u80fd\u7834\u574f\u5de5\u4f5c\u6d41\u7a0b", "method": "\u63d0\u51faPlanner-Composer-Evaluator\uff08PCE\uff09\u6846\u67b6\uff1a\u5c06LLM\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u9690\u542b\u5047\u8bbe\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u5185\u90e8\u8282\u70b9\u7f16\u7801\u73af\u5883\u5047\u8bbe\uff0c\u53f6\u5b50\u8282\u70b9\u6620\u5c04\u5230\u884c\u52a8\uff0c\u6bcf\u6761\u8def\u5f84\u901a\u8fc7\u573a\u666f\u53ef\u80fd\u6027\u3001\u76ee\u6807\u5bfc\u5411\u6536\u76ca\u548c\u6267\u884c\u6210\u672c\u8fdb\u884c\u8bc4\u5206", "result": "\u5728\u4e24\u4e2a\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\uff08C-WAH\u548cTDW-MAT\uff09\u548c\u4e09\u4e2a\u4e0d\u540cLLM\u9aa8\u5e72\u4e0a\uff0cPCE\u5728\u6210\u529f\u7387\u548c\u4efb\u52a1\u6548\u7387\u4e0a\u6301\u7eed\u4f18\u4e8e\u901a\u4fe1\u5bc6\u96c6\u578b\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684token\u4f7f\u7528\u91cf\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660ePCE\u7684\u6027\u80fd\u63d0\u5347\u4e0e\u6a21\u578b\u80fd\u529b\u548c\u63a8\u7406\u6df1\u5ea6\u7684\u6269\u5c55\u76f8\u4e92\u8865\u5145", "conclusion": "PCE\u4e3a\u5c06LLM\u9690\u542b\u5047\u8bbe\u8f6c\u5316\u4e3a\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u89c4\u5212\u7b56\u7565\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u9014\u5f84\uff0c\u4ea7\u751f\u66f4\u9ad8\u6548\u548c\u53ef\u4fe1\u7684\u901a\u4fe1\u6a21\u5f0f\uff0c\u51cf\u5c11\u5bf9\u9891\u7e41\u901a\u4fe1\u7684\u4f9d\u8d56"}}
{"id": "2602.04385", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04385", "abs": "https://arxiv.org/abs/2602.04385", "authors": ["Marco Picone", "Fabio Turazza", "Matteo Martinelli", "Marco Mamei"], "title": "Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications", "comment": "Author-accepted manuscript of a paper published in the 2025 IEEE International Conference on Systems, Man and Cybernetics (IEEE SMC), October 2025, doi: 10.1109/SMC58881.2025.11343418", "summary": "The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level intelligent functionalities. Recently, Digital Twin (DT) technology has emerged as a promising solution, offering structured, interoperable and semantically rich digital representations of physical assets. Current approaches are often siloed and tightly coupled, limiting scalability and reuse of AI functionalities. This work proposes a modular and interoperable solution that enables seamless AI pipeline integration into CPS by minimizing configuration and decoupling the roles of DTs and AI components. We introduce the concept of Zero Configuration (ZeroConf) AI pipelines, where DTs orchestrate data management and intelligent augmentation. The approach is demonstrated in a MicroFactory scenario, showing support for concurrent ML models and dynamic data processing, effectively accelerating the deployment of intelligent services in complex industrial settings.", "AI": {"tldr": "\u63d0\u51fa\u96f6\u914d\u7f6eAI\u7ba1\u9053\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u7f16\u6392\u6570\u636e\u7ba1\u7406\u548c\u667a\u80fd\u589e\u5f3a\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u7684AI\u4e0eCPS\u96c6\u6210\u65b9\u6848", "motivation": "CPS\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u7269\u8054\u7f51\u548c\u5de5\u4e1a\u7269\u8054\u7f51\u6280\u672f\u788e\u7247\u5316\uff08\u4e0d\u540c\u901a\u4fe1\u534f\u8bae\u3001\u6570\u636e\u683c\u5f0f\u548c\u8bbe\u5907\u80fd\u529b\uff09\u5bfc\u81f4\u7269\u7406\u5c42\u4e0e\u9ad8\u5c42\u667a\u80fd\u529f\u80fd\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u9e3f\u6c9f\u3002\u73b0\u6709\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\u901a\u5e38\u5b64\u7acb\u4e14\u7d27\u8026\u5408\uff0c\u9650\u5236\u4e86AI\u529f\u80fd\u7684\u53ef\u6269\u5c55\u6027\u548c\u91cd\u7528\u6027\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u914d\u7f6e\u548c\u89e3\u8026\u6570\u5b57\u5b6a\u751f\u4e0eAI\u7ec4\u4ef6\u89d2\u8272\uff0c\u5b9e\u73b0AI\u7ba1\u9053\u4e0eCPS\u7684\u65e0\u7f1d\u96c6\u6210\u3002\u5f15\u5165\u96f6\u914d\u7f6eAI\u7ba1\u9053\u6982\u5ff5\uff0c\u5176\u4e2d\u6570\u5b57\u5b6a\u751f\u8d1f\u8d23\u7f16\u6392\u6570\u636e\u7ba1\u7406\u548c\u667a\u80fd\u589e\u5f3a\u3002", "result": "\u5728\u5fae\u5de5\u5382\u573a\u666f\u4e2d\u6f14\u793a\u4e86\u8be5\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5bf9\u5e76\u53d1ML\u6a21\u578b\u548c\u52a8\u6001\u6570\u636e\u5904\u7406\u7684\u652f\u6301\uff0c\u6709\u6548\u52a0\u901f\u4e86\u590d\u6742\u5de5\u4e1a\u73af\u5883\u4e2d\u667a\u80fd\u670d\u52a1\u7684\u90e8\u7f72\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u7684\u96f6\u914d\u7f6eAI\u7ba1\u9053\u65b9\u6cd5\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u6280\u672f\uff0c\u89e3\u51b3\u4e86CPS\u4e2dAI/ML\u96c6\u6210\u7684\u788e\u7247\u5316\u548c\u7d27\u8026\u5408\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u5de5\u4e1a\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u91cd\u7528\u7684\u667a\u80fd\u670d\u52a1\u90e8\u7f72\u65b9\u6848\u3002"}}
{"id": "2602.04496", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04496", "abs": "https://arxiv.org/abs/2602.04496", "authors": ["Zhentao Tang", "Yuqi Cui", "Shixiong Kai", "Wenqian Zhao", "Ke Ye", "Xing Li", "Anxin Tian", "Zehua Pei", "Hui-Ling Zhen", "Shoubo Hu", "Xiaoguang Li", "Yunhe Wang", "Mingxuan Yuan"], "title": "ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control", "comment": null, "summary": "Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.", "AI": {"tldr": "ReThinker\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7Solver-Critic-Selector\u67b6\u6784\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u5728\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\uff08\u5982Humanity's Last Exam\uff09\u4e0a\u5b58\u5728\u6311\u6218\uff0c\u4f20\u7edf\u5de5\u5177\u6d41\u6c34\u7ebf\u50f5\u5316\u3001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u8106\u5f31\u3001\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u7387\u4f4e\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347", "method": "\u63d0\u51faReThinker\u6846\u67b6\uff0c\u91c7\u7528Solver-Critic-Selector\u4e09\u9636\u6bb5\u67b6\u6784\uff0c\u57fa\u4e8e\u6a21\u578b\u7f6e\u4fe1\u5ea6\u52a8\u6001\u5206\u914d\u8ba1\u7b97\uff0c\u652f\u6301\u81ea\u9002\u5e94\u5de5\u5177\u8c03\u7528\u3001\u591a\u7ef4\u5ea6\u53cd\u601d\u548c\u7f6e\u4fe1\u5ea6\u52a0\u6743\u9009\u62e9\u3002\u540c\u65f6\u63d0\u51fa\u53cd\u5411\u6570\u636e\u5408\u6210\u6d41\u6c34\u7ebf\u548c\u81ea\u9002\u5e94\u8f68\u8ff9\u56de\u6536\u7b56\u7565\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u8fdb\u884c\u53ef\u6269\u5c55\u8bad\u7ec3", "result": "\u5728HLE\u3001GAIA\u548cXBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReThinker\u6301\u7eed\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u57fa\u7840\u6a21\u578b\u548c\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\uff0c\u5728\u4e13\u5bb6\u7ea7\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u7ed3\u679c", "conclusion": "ReThinker\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u548c\u521b\u65b0\u7684\u65e0\u76d1\u7763\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.04572", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.04572", "abs": "https://arxiv.org/abs/2602.04572", "authors": ["Niv Fono", "Yftah Ziser", "Omer Ben-Porat"], "title": "From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums", "comment": null, "summary": "While Generative AI (GenAI) systems draw users away from (Q&A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\u6765\u89e3\u51b3\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4e0e\u95ee\u7b54\u8bba\u575b\u4e4b\u95f4\u7684\u6096\u8bba\u5173\u7cfb\uff1aAI\u4f9d\u8d56\u8bba\u575b\u6570\u636e\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u540c\u65f6\u53c8\u5206\u6d41\u7528\u6237\u3002\u901a\u8fc7\u987a\u5e8f\u4ea4\u4e92\u6846\u67b6\u548c\u771f\u5b9e\u6570\u636e\u6a21\u62df\uff0c\u8bc1\u660e\u4e86\u6fc0\u52b1\u9519\u914d\u95ee\u9898\uff0c\u4f46\u5c55\u793a\u4e86\u53ef\u6301\u7eed\u534f\u4f5c\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7cfb\u7edf\u9762\u4e34\u4e00\u4e2a\u6096\u8bba\uff1a\u5b83\u4eec\u4f9d\u8d56\u95ee\u7b54\u8bba\u575b\u4ea7\u751f\u7684\u6570\u636e\u6765\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u540c\u65f6\u53c8\u5c06\u7528\u6237\u4ece\u8fd9\u4e9b\u8bba\u575b\u5206\u6d41\u8d70\u3002\u8fd9\u5bfc\u81f4\u4e86AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u4e4b\u95f4\u7684\u7d27\u5f20\u5173\u7cfb\uff0c\u9700\u8981\u63a2\u7d22\u53ef\u6301\u7eed\u7684\u534f\u4f5c\u673a\u5236\u3002", "method": "\u63d0\u51fa\u987a\u5e8f\u4ea4\u4e92\u6846\u67b6\uff0c\u8ba9\u751f\u6210\u5f0fAI\u7cfb\u7edf\u5411\u8bba\u575b\u63d0\u51fa\u95ee\u9898\uff0c\u8bba\u575b\u53ef\u4ee5\u9009\u62e9\u53d1\u5e03\u90e8\u5206\u95ee\u9898\u3002\u8be5\u6846\u67b6\u8003\u8651\u4e86\u975e\u8d27\u5e01\u4ea4\u6362\u3001\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u6fc0\u52b1\u9519\u914d\u7b49\u590d\u6742\u56e0\u7d20\u3002\u4f7f\u7528\u771f\u5b9e\u7684Stack Exchange\u6570\u636e\u548c\u5e38\u7528LLM\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u7684\u5168\u9762\u6a21\u62df\u3002", "result": "\u5b9e\u8bc1\u8bc1\u660e\u4e86\u6fc0\u52b1\u9519\u914d\u95ee\u9898\u7684\u5b58\u5728\uff0c\u4f46\u540c\u65f6\u4e5f\u8868\u660e\u53c2\u4e0e\u8005\u80fd\u591f\u8fbe\u5230\u7406\u60f3\u5168\u4fe1\u606f\u573a\u666f\u4e0b\u7ea6\u4e00\u534a\u7684\u6548\u7528\u3002\u7ed3\u679c\u7a81\u51fa\u4e86AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u4e4b\u95f4\u53ef\u6301\u7eed\u534f\u4f5c\u7684\u6f5c\u529b\u3002", "conclusion": "\u5c3d\u7ba1\u5b58\u5728\u6fc0\u52b1\u9519\u914d\uff0c\u4f46\u901a\u8fc7\u9002\u5f53\u7684\u6846\u67b6\u8bbe\u8ba1\uff0c\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u53ef\u4ee5\u5b9e\u73b0\u53ef\u6301\u7eed\u534f\u4f5c\uff0c\u4fdd\u6301\u6709\u6548\u7684\u77e5\u8bc6\u5171\u4eab\u3002\u8fd9\u79cd\u534f\u4f5c\u5bf9\u4e8eAI\u7cfb\u7edf\u7684\u6301\u7eed\u6539\u8fdb\u548c\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u7684\u751f\u5b58\u90fd\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.04575", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04575", "abs": "https://arxiv.org/abs/2602.04575", "authors": ["Jiaheng Liu", "Yuanxing Zhang", "Shihao Li", "Xinping Lei"], "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration", "comment": null, "summary": "For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \\textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.\n  Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVibe AIGC\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7f16\u6392\u89e3\u51b3\u5f53\u524d\u751f\u6210\u5f0fAI\u7684\u610f\u56fe-\u6267\u884c\u5dee\u8ddd\u95ee\u9898\uff0c\u5c06\u7528\u6237\u4ece\u63d0\u793a\u5de5\u7a0b\u5e08\u8f6c\u53d8\u4e3a\u63d0\u4f9b\"\u6c1b\u56f4\"\u7684\u6307\u6325\u5b98\uff0c\u7531\u5143\u89c4\u5212\u5668\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0fAI\u5b58\u5728\"\u610f\u56fe-\u6267\u884c\u5dee\u8ddd\"\u95ee\u9898\uff0c\u5373\u7528\u6237\u7684\u9ad8\u5c42\u610f\u56fe\u4e0e\u968f\u673a\u9ed1\u76d2\u6a21\u578b\u8f93\u51fa\u4e4b\u95f4\u7684\u6839\u672c\u6027\u8131\u8282\u3002\u5c3d\u7ba1\u6a21\u578b\u89c4\u6a21\u4e0d\u65ad\u6269\u5927\uff0c\u89c6\u89c9\u4fdd\u771f\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u4f46\u9047\u5230\u4e86\"\u53ef\u7528\u6027\u5929\u82b1\u677f\"\uff0c\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u6570\u5b57\u8d44\u4ea7\u521b\u4f5c\u9700\u6c42\u3002", "method": "\u63d0\u51faVibe AIGC\u8303\u5f0f\uff0c\u53d7Vibe Coding\u542f\u53d1\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7f16\u6392\u5b9e\u73b0\u5185\u5bb9\u751f\u6210\u3002\u7528\u6237\u4f5c\u4e3a\u6307\u6325\u5b98\u63d0\u4f9b\"\u6c1b\u56f4\"\uff08\u5305\u542b\u7f8e\u5b66\u504f\u597d\u3001\u529f\u80fd\u903b\u8f91\u7b49\u9ad8\u5c42\u8868\u793a\uff09\uff0c\u4e2d\u592e\u5143\u89c4\u5212\u5668\u4f5c\u4e3a\u7cfb\u7edf\u67b6\u6784\u5e08\uff0c\u5c06\u6c1b\u56f4\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u3001\u53ef\u9a8c\u8bc1\u3001\u81ea\u9002\u5e94\u7684\u667a\u80fd\u4f53\u7ba1\u9053\uff0c\u4ece\u968f\u673a\u63a8\u7406\u8f6c\u5411\u903b\u8f91\u7f16\u6392\u3002", "result": "Vibe AIGC\u80fd\u591f\u5f25\u5408\u4eba\u7c7b\u60f3\u8c61\u529b\u4e0e\u673a\u5668\u6267\u884c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5c06AI\u4ece\u8106\u5f31\u7684\u63a8\u7406\u5f15\u64ce\u8f6c\u53d8\u4e3a\u7a33\u5065\u7684\u7cfb\u7edf\u7ea7\u5de5\u7a0b\u5408\u4f5c\u4f19\u4f34\uff0c\u91cd\u65b0\u5b9a\u4e49\u4eba\u673a\u534f\u4f5c\u7ecf\u6d4e\u3002", "conclusion": "\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u5c06\u6c11\u4e3b\u5316\u590d\u6742\u3001\u957f\u65f6\u7a0b\u6570\u5b57\u8d44\u4ea7\u7684\u521b\u4f5c\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u81ea\u4e3b\u5408\u6210\uff0c\u5b9e\u73b0\u4ece\u6a21\u578b\u4e2d\u5fc3\u5230\u7cfb\u7edf\u4e2d\u5fc3\u7684\u8f6c\u53d8\uff0c\u89e3\u51b3\u5f53\u524d\u751f\u6210\u5f0fAI\u7684\u6839\u672c\u5c40\u9650\u6027\u3002"}}
{"id": "2602.04634", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.04634", "abs": "https://arxiv.org/abs/2602.04634", "authors": ["Zelai Xu", "Zhexuan Xu", "Ruize Zhang", "Chunyang Zhu", "Shi Yu", "Weilin Liu", "Quanlu Zhang", "Wenbo Ding", "Chao Yu", "Yu Wang"], "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.", "AI": {"tldr": "WideSeek-R1\uff1a\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u9886\u5bfc-\u5b50\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5b9e\u73b0\u5bbd\u5ea6\u6269\u5c55\u4ee5\u89e3\u51b3\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\uff0c4B\u53c2\u6570\u6a21\u578b\u6027\u80fd\u5ab2\u7f8e671B\u53c2\u6570\u7684\u5355\u667a\u80fd\u4f53\u6a21\u578b\u3002", "motivation": "\u5f53\u524dLLM\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6df1\u5ea6\u6269\u5c55\uff08\u5355\u4e2a\u667a\u80fd\u4f53\u89e3\u51b3\u957f\u65f6\u7a0b\u95ee\u9898\uff09\uff0c\u4f46\u968f\u7740\u4efb\u52a1\u8303\u56f4\u53d8\u5e7f\uff0c\u74f6\u9888\u4ece\u4e2a\u4f53\u80fd\u529b\u8f6c\u5411\u7ec4\u7ec7\u80fd\u529b\u3002\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u624b\u5de5\u5de5\u4f5c\u6d41\u548c\u8f6e\u8f6c\u4ea4\u4e92\uff0c\u65e0\u6cd5\u6709\u6548\u5e76\u884c\u5316\u5de5\u4f5c\u3002", "method": "\u63d0\u51faWideSeek-R1\u6846\u67b6\uff1a\u9886\u5bfc\u667a\u80fd\u4f53-\u5b50\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u4f7f\u7528\u5171\u4eabLLM\u4f46\u9694\u79bb\u4e0a\u4e0b\u6587\u548c\u4e13\u7528\u5de5\u5177\uff0c\u57282\u4e07\u4e2a\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u6570\u636e\u96c6\u4e0a\u8054\u5408\u4f18\u5316\u9886\u5bfc\u667a\u80fd\u4f53\u548c\u5e76\u884c\u5b50\u667a\u80fd\u4f53\u3002", "result": "WideSeek-R1-4B\u5728WideSearch\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523040.0%\u7684item F1\u5206\u6570\uff0c\u6027\u80fd\u4e0e\u5355\u667a\u80fd\u4f53DeepSeek-R1-671B\u76f8\u5f53\u3002\u968f\u7740\u5e76\u884c\u5b50\u667a\u80fd\u4f53\u6570\u91cf\u589e\u52a0\uff0c\u6027\u80fd\u6301\u7eed\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u5bbd\u5ea6\u6269\u5c55\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5bbd\u5ea6\u6269\u5c55\u662f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u91cd\u8981\u7ef4\u5ea6\uff0cWideSeek-R1\u901a\u8fc7MARL\u8bad\u7ec3\u7684\u9886\u5bfc-\u5b50\u667a\u80fd\u4f53\u6846\u67b6\u80fd\u591f\u6709\u6548\u534f\u8c03\u5e76\u884c\u6267\u884c\uff0c\u5728\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u4e0a\u5b9e\u73b0\u9ad8\u6548\u6269\u5c55\u3002"}}
{"id": "2602.04836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04836", "abs": "https://arxiv.org/abs/2602.04836", "authors": ["Haosen Ge", "Hamsa Bastani", "Osbert Bastani"], "title": "Are AI Capabilities Increasing Exponentially? A Competing Hypothesis", "comment": null, "summary": "Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53cd\u9a73\u4e86METR\u62a5\u544a\u4e2dAI\u80fd\u529b\u5448\u6307\u6570\u589e\u957f\u7684\u89c2\u70b9\uff0c\u901a\u8fc7\u62df\u5408S\u578b\u66f2\u7ebf\u53d1\u73b0\u62d0\u70b9\u5df2\u8fc7\uff0c\u5e76\u63d0\u51fa\u66f4\u590d\u6742\u6a21\u578b\u5206\u89e3\u57fa\u7840\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u8d28\u7591\u73b0\u6709\u6307\u6570\u589e\u957f\u9884\u6d4b\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u53cd\u9a73METR\u62a5\u544a\u4e2d\u5173\u4e8eAI\u80fd\u529b\u81ea2019\u5e74\u4ee5\u6765\u5448\u6307\u6570\u589e\u957f\u7684\u7ed3\u8bba\uff0c\u6307\u51fa\u6570\u636e\u4e0d\u652f\u6301\u8fd9\u79cd\u589e\u957f\u6a21\u5f0f\uff0c\u65e8\u5728\u63ed\u793a\u73b0\u6709\u6307\u6570\u589e\u957f\u9884\u6d4b\u7684\u8106\u5f31\u6027\u3002", "method": "1) \u5bf9METR\u73b0\u6709\u6570\u636e\u62df\u5408S\u578b/\u903b\u8f91\u66f2\u7ebf\uff0c\u53d1\u73b0\u62d0\u70b9\u5df2\u8fc7\uff1b2) \u63d0\u51fa\u66f4\u590d\u6742\u6a21\u578b\uff0c\u5c06AI\u80fd\u529b\u5206\u89e3\u4e3a\u57fa\u7840\u80fd\u529b\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5404\u81ea\u6709\u4e0d\u540c\u7684\u6539\u8fdb\u901f\u7387\u3002", "result": "1) \u62df\u5408S\u578b\u66f2\u7ebf\u663e\u793a\u62d0\u70b9\u5df2\u7ecf\u8fc7\u53bb\uff0c\u800c\u975eMETR\u9884\u6d4b\u7684\u9065\u8fdc\u672a\u6765\uff1b2) \u590d\u6742\u6a21\u578b\u652f\u6301AI\u80fd\u529b\u5c06\u5728\u8fd1\u671f\u51fa\u73b0\u62d0\u70b9\u7684\u5047\u8bbe\uff1b3) \u6210\u529f\u8d28\u7591\u4e86\u73b0\u6709\u6307\u6570\u589e\u957f\u9884\u6d4b\u7684\u53ef\u9760\u6027\u3002", "conclusion": "AI\u80fd\u529b\u589e\u957f\u5e76\u975e\u6307\u6570\u578b\uff0c\u73b0\u6709\u6307\u6570\u589e\u957f\u9884\u6d4b\u7f3a\u4e4f\u7a33\u5065\u6027\uff0c\u9700\u8981\u66f4\u7ec6\u81f4\u7684\u6a21\u578b\u6765\u7406\u89e3AI\u80fd\u529b\u53d1\u5c55\u7684\u4e0d\u540c\u7ef4\u5ea6\u53ca\u5176\u6539\u8fdb\u901f\u7387\u3002"}}
{"id": "2602.04837", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04837", "abs": "https://arxiv.org/abs/2602.04837", "authors": ["Zhaotian Weng", "Antonis Antoniades", "Deepak Nathani", "Zhen Zhang", "Xiao Pu", "Xin Eric Wang"], "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing", "comment": "18 pages", "summary": "Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.", "AI": {"tldr": "GEA\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f00\u653e\u81ea\u6539\u8fdb\u4ee3\u7406\u8303\u5f0f\uff0c\u5c06\u4ee3\u7406\u7fa4\u4f53\u4f5c\u4e3a\u57fa\u672c\u8fdb\u5316\u5355\u5143\uff0c\u901a\u8fc7\u7fa4\u4f53\u5185\u663e\u5f0f\u7ecf\u9a8c\u5171\u4eab\u548c\u91cd\u7528\uff0c\u663e\u8457\u63d0\u5347\u7f16\u7801\u4efb\u52a1\u6027\u80fd\uff0c\u8d85\u8d8a\u73b0\u6709\u81ea\u8fdb\u5316\u65b9\u6cd5\u548c\u4eba\u7c7b\u8bbe\u8ba1\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u81ea\u8fdb\u5316\u8303\u5f0f\u91c7\u7528\u6811\u72b6\u7ed3\u6784\u8fdb\u5316\uff0c\u5bfc\u81f4\u63a2\u7d22\u591a\u6837\u6027\u5229\u7528\u6548\u7387\u4f4e\u4e0b\uff0c\u5404\u8fdb\u5316\u5206\u652f\u5b64\u7acb\uff0c\u65e0\u6cd5\u6709\u6548\u5171\u4eab\u7ecf\u9a8c\u3002\u9700\u8981\u4e00\u79cd\u80fd\u66f4\u597d\u5229\u7528\u63a2\u7d22\u591a\u6837\u6027\u3001\u5b9e\u73b0\u6301\u7eed\u957f\u671f\u8fdb\u6b65\u7684\u81ea\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7fa4\u4f53\u8fdb\u5316\u4ee3\u7406(GEA)\u8303\u5f0f\uff0c\u5c06\u4ee3\u7406\u7fa4\u4f53\u4f5c\u4e3a\u57fa\u672c\u8fdb\u5316\u5355\u5143\uff0c\u5728\u8fdb\u5316\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u7fa4\u4f53\u5185\u663e\u5f0f\u7ecf\u9a8c\u5171\u4eab\u548c\u91cd\u7528\uff0c\u514b\u670d\u6811\u72b6\u7ed3\u6784\u8fdb\u5316\u4e2d\u5b64\u7acb\u5206\u652f\u5bfc\u81f4\u7684\u63a2\u7d22\u591a\u6837\u6027\u5229\u7528\u4e0d\u8db3\u95ee\u9898\u3002", "result": "\u5728\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u81ea\u8fdb\u5316\u65b9\u6cd5(SWE-bench Verified: 71.0% vs 56.7%\uff0cPolyglot: 88.3% vs 68.3%)\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u9876\u7ea7\u4eba\u7c7b\u8bbe\u8ba1\u4ee3\u7406\u6846\u67b6\u3002\u80fd\u66f4\u6709\u6548\u5c06\u65e9\u671f\u63a2\u7d22\u591a\u6837\u6027\u8f6c\u5316\u4e3a\u6301\u7eed\u957f\u671f\u8fdb\u6b65\uff0c\u4fee\u590d\u6846\u67b6\u7ea7bug\u5e73\u5747\u53ea\u97001.4\u6b21\u8fed\u4ee3(\u81ea\u8fdb\u5316\u65b9\u6cd5\u97005\u6b21)\u3002", "conclusion": "GEA\u901a\u8fc7\u7fa4\u4f53\u4f5c\u4e3a\u8fdb\u5316\u5355\u5143\u548c\u663e\u5f0f\u7ecf\u9a8c\u5171\u4eab\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u81ea\u6539\u8fdb\uff0c\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3001\u8de8\u6a21\u578b\u53ef\u8fc1\u79fb\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5f00\u653e\u81ea\u6539\u8fdb\u4ee3\u7406\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.04843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04843", "abs": "https://arxiv.org/abs/2602.04843", "authors": ["Dmitrii Kharlapenko", "Alessandro Stolfo", "Arthur Conmy", "Mrinmaya Sachan", "Zhijing Jin"], "title": "Fluid Representations in Reasoning Models", "comment": null, "summary": "Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u673a\u5236\u5206\u6790\u53d1\u73b0QwQ-32B\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4f1a\u52a8\u6001\u4f18\u5316\u5176\u5185\u90e8\u8868\u5f81\uff0c\u8fd9\u79cd\"\u6d41\u4f53\u63a8\u7406\u8868\u5f81\"\u662f\u63a8\u7406\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u56e0\u7d20\u4e4b\u4e00", "motivation": "\u867d\u7136\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u5728\u62bd\u8c61\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u63ed\u793aQwQ-32B\u6a21\u578b\u5982\u4f55\u5904\u7406\u62bd\u8c61\u7ed3\u6784\u4fe1\u606f\uff0c\u7406\u89e3\u63a8\u7406\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u5185\u90e8\u673a\u5236", "method": "\u4f7f\u7528Mystery Blocksworld\uff08\u8bed\u4e49\u6df7\u6dc6\u7684\u89c4\u5212\u9886\u57df\uff09\u8fdb\u884c\u673a\u5236\u5206\u6790\uff0c\u901a\u8fc7\u8f6c\u5411\u5b9e\u9a8c\u5efa\u7acb\u56e0\u679c\u8bc1\u636e\uff0c\u7814\u7a76\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5982\u4f55\u6539\u8fdb\u52a8\u4f5c\u548c\u6982\u5ff5\u7684\u8868\u5f81", "result": "\u53d1\u73b0QwQ-32B\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9010\u6b65\u6539\u8fdb\u5185\u90e8\u8868\u5f81\uff0c\u53d1\u5c55\u51fa\u5173\u6ce8\u7ed3\u6784\u800c\u975e\u5177\u4f53\u52a8\u4f5c\u540d\u79f0\u7684\u62bd\u8c61\u7f16\u7801\uff1b\u6210\u529f\u8f68\u8ff9\u4e2d\u7684\u7cbe\u70bc\u8868\u5f81\u6ce8\u5165\u80fd\u63d0\u5347\u51c6\u786e\u7387\uff0c\u7b26\u53f7\u8868\u5f81\u53ef\u66ff\u4ee3\u6df7\u6dc6\u7f16\u7801\u4e14\u6027\u80fd\u635f\u5931\u6700\u5c0f", "conclusion": "\u63a8\u7406\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u56e0\u7d20\u4e4b\u4e00\u662f\u4e0a\u4e0b\u6587\u4e2d\u7684\u8868\u5f81\u7cbe\u70bc\uff0c\u5373\"\u6d41\u4f53\u63a8\u7406\u8868\u5f81\"\u2014\u2014\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u4f18\u5316\u5176\u5185\u90e8\u8868\u5f81\u7684\u80fd\u529b"}}
