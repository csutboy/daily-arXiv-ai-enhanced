<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 3]
- [cs.CY](#cs.CY) [Total: 6]
- [econ.TH](#econ.TH) [Total: 3]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.AI](#cs.AI) [Total: 16]
- [econ.EM](#econ.EM) [Total: 8]
- [eess.SY](#eess.SY) [Total: 17]
- [econ.GN](#econ.GN) [Total: 6]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.ET](#cs.ET) [Total: 3]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [Modeling Headway in Heterogeneous and Mixed Traffic Flow: A Statistical Distribution Based on a General Exponential Function](https://arxiv.org/abs/2511.03154)
*Natchaphon Leungbootnak,Zihao Li,Zihang Wei,Dominique Lord,Yunlong Zhang*

Main category: stat.AP

TL;DR: 提出了一种基于实数基的新型车头时距分布模型，在异质交通和混合交通条件下优于现有六种分布，特别是在高速公路场景中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有车头时距分布模型在异质交通（不同类型车辆）和混合交通（人工驾驶与自动驾驶车辆）中拟合效果不佳，无法准确反映多样化的驾驶行为和特征。

Method: 修改指数函数，使用实数基替代欧拉数e，增加建模灵活性；将非概率函数归一化处理，推导出封闭形式方程；使用五个公开数据集（highD、exiD、NGSIM、Waymo、Lyft）进行综合实验验证。

Result: 提出的分布不仅能捕捉车头时距分布的基本特征，还提供了具有物理意义的参数来描述观测车头时距的分布形状；在高速公路异质交通流中表现最优，在城市道路条件下（包括异质和混合交通）也取得良好结果。

Conclusion: 基于实数基的新型车头时距分布模型在异质和混合交通条件下具有优越性能，特别是在不间断交通流场景中显著优于现有分布模型。

Abstract: The ability of existing headway distributions to accurately reflect the
diverse behaviors and characteristics in heterogeneous traffic (different types
of vehicles) and mixed traffic (human-driven vehicles with autonomous vehicles)
is limited, leading to unsatisfactory goodness of fit. To address these issues,
we modified the exponential function to obtain a novel headway distribution.
Rather than employing Euler's number (e) as the base of the exponential
function, we utilized a real number base to provide greater flexibility in
modeling the observed headway. However, the proposed is not a probability
function. We normalize it to calculate the probability and derive the
closed-form equation. In this study, we utilized a comprehensive experiment
with five open datasets: highD, exiD, NGSIM, Waymo, and Lyft to evaluate the
performance of the proposed distribution and compared its performance with six
existing distributions under mixed and heterogeneous traffic flow. The results
revealed that the proposed distribution not only captures the fundamental
characteristics of headway distribution but also provides physically meaningful
parameters that describe the distribution shape of observed headways. Under
heterogeneous flow on highways (i.e., uninterrupted traffic flow), the proposed
distribution outperforms other candidate distributions. Under urban road
conditions (i.e., interrupted traffic flow), including heterogeneous and mixed
traffic, the proposed distribution still achieves decent results.

</details>


### [2] [Post-2024 U.S. Presidential Election Analysis of Election and Poll Data: Real-life Validation of Prediction via Small Area Estimation and Uncertainty Quantification](https://arxiv.org/abs/2511.03555)
*Zheshi Zheng,Yuanyuan Li,Peter X. K. Song,Jiming Jiang*

Main category: stat.AP

TL;DR: 使用小区域估计方法构建的预测模型，基于选前一周的民调数据，能够完美预测2024年美国总统选举的选举人团结果，并引入错误预测概率来量化预测不确定性。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够准确预测美国总统选举结果并可靠量化预测不确定性的方法，同时分析民调偏差对选举预测的影响。

Method: 采用小区域估计方法构建预测模型，使用选前一周的民调数据，并引入符合推理方法来可靠估计错误预测概率，替代标准自助法。

Result: 模型在44个有民调数据的州中完美预测了选举人团结果，敏感性分析显示摇摆州特别容易受到民调偏差的影响。

Conclusion: 小区域估计方法结合符合推理能够提供准确的选举预测和可靠的不确定性量化，摇摆州的民调偏差是预测准确性的关键风险因素。

Abstract: We carry out a post-election analysis of the 2024 U.S. Presidential Election
(USPE) using a prediction model derived from the Small Area Estimation (SAE)
methodology. With pollster data obtained one week prior to the election day,
retrospectively, our SAE-based prediction model can perfectly predict the
Electoral College election results in all 44 states where polling data were
available. In addition to such desirable prediction accuracy, we introduce the
probability of incorrect prediction (PoIP) to rigorously analyze prediction
uncertainty. Since the standard bootstrap method appears inadequate for
estimating PoIP, we propose a conformal inference method that yields reliable
uncertainty quantification. We further investigate potential pollster biases by
the means of sensitivity analyses and conclude that swing states are
particularly vulnerable to polling bias in the prediction of the 2024 USPE.

</details>


### [3] [Adjusting for Heavy Censoring and Double-Dipping to Compare Risk Stratification Abilities of Existing Models for Time to Diagnosis of Huntington Disease](https://arxiv.org/abs/2511.03596)
*Kyle F. Grosser,Abigail G. Foes,Stellen Li,Vraj Parikh,Tanya P. Garcia,Sarah C. Lotspeich*

Main category: stat.AP

TL;DR: 本文系统比较了四种亨廷顿病诊断时间预测模型，在ENROLL-HD数据上进行外部验证，发现MRS模型表现最佳，但CAP和PIN模型在简化实施方面具有优势，同时指出先前研究存在方法学缺陷。


<details>
  <summary>Details</summary>
Motivation: 亨廷顿病诊断时间准确建模对临床试验设计至关重要，但现有模型在方法、假设和准确性上存在差异且缺乏系统比较，先前研究存在训练测试数据重叠和未考虑高右删失率的问题。

Method: 讨论四种常见模型的理论基础，使用ENROLL-HD研究数据进行外部验证，采用调整删失率的性能指标评估模型风险分层能力。

Result: MRS模型（包含最多协变量）表现最佳，但较简单的CAP和PIN模型表现接近且实施更简便；同时发现先前研究低估了临床试验所需样本量。

Conclusion: MRS模型是HD临床试验设计的最佳选择，但CAP和PIN模型在简化实施方面具有实用价值；研究为模型选择提供了指导，并强调需要重新评估临床试验样本量估算。

Abstract: Huntington disease (HD) is a genetically inherited neurodegenerative disease
with progressively worsening symptoms. Accurately modeling time to HD diagnosis
is essential for clinical trial design and treatment planning. Langbehn's
model, the CAG-Age Product (CAP) model, the Prognostic Index Normed (PIN)
model, and the Multivariate Risk Score (MRS) model have all been proposed for
this task. However, differing in methodology, assumptions, and accuracy, these
models may yield conflicting predictions. Few studies have systematically
compared these models' performance, and those that have could be misleading due
to (i) testing the models on the same data used to train them and (ii) failing
to account for high rates of right censoring (80%+) in performance metrics. We
discuss the theoretical foundations of the four most common models of time to
HD diagnosis, offering intuitive comparisons about their practical feasibility.
Further, we externally validate their risk stratification abilities using data
from the ENROLL-HD study and performance metrics that adjust for censoring. Our
findings guide the selection of a model for HD clinical trial design. The MRS
model, which incorporates the most covariates, performed the best. However, the
simpler CAP and PIN models were not far behind and may be logistically simpler
to adopt. We also show how these models can be used to estimate sample sizes
for an HD clinical trial, emphasizing that previous estimates would lead to
underpowered trials.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [4] [Teaching Quantum Computing through Lab-Integrated Learning: Bridging Conceptual and Computational Understanding](https://arxiv.org/abs/2511.02844)
*Umar Farooq,Krishna Upadhyay*

Main category: cs.CY

TL;DR: 该论文介绍了一种在量子计算教育中采用实验室集成学习模式的教学方法，通过结合讲座和编程实验帮助学生克服经典编程直觉，发展基于概率、测量和干涉的量子推理技能。


<details>
  <summary>Details</summary>
Motivation: 量子计算教育需要学生超越经典编程的直觉（如状态、确定性和调试），发展基于概率、测量和干涉的推理技能。现有的教学方法需要改进以支持概念转变和渐进式理解。

Method: 采用实验室集成学习模型，将讲座与每周编程实验配对。课程从Quantum Without Linear Algebra (QWLA)开始，通过直观的字典表示引入叠加和纠缠等核心概念，然后过渡到IBM Qiskit进行电路设计、噪声模拟和算法实现。

Result: 学生作业和反馈分析表明，动手实验提高了学生的信心、概念清晰度和跨表示流利度，但也揭示了在调试、测量推理和理解概率结果方面的持续挑战。

Conclusion: 实验室集成学习为计算机科学教育中的量子计算教学提供了一种有效且易于实施的方法，能够支持概念转变和渐进式理解。

Abstract: Quantum computing education requires students to move beyond classical
programming intuitions related to state, determinism, and debugging, and to
develop reasoning skills grounded in probability, measurement, and
interference. This paper reports on the design and delivery of a combined
undergraduate and graduate course at Louisiana State University that employed a
lab-integrated learning model to support conceptual change and progressive
understanding. The course paired lectures with weekly programming labs that
served as environments for experimentation and reflection. These labs enabled
students to confront misconceptions and refine their mental models through
direct observation and evidence-based reasoning. Instruction began with Quantum
Without Linear Algebra (QWLA), which introduced core concepts such as
superposition and entanglement through intuitive, dictionary representations.
The course then transitioned to IBM Qiskit, which provided a professional
framework for circuit design, noise simulation, and algorithm implementation.
Analysis of student work and feedback indicated that hands-on experimentation
improved confidence, conceptual clarity, and fluency across representations. At
the same time, it revealed persistent challenges in debugging, reasoning about
measurement, and understanding probabilistic outcomes. This paper presents the
course structure, instructional strategies, and lessons learned, and argues
that lab-integrated learning offers an effective and accessible approach to
teaching quantum computing in computer science education.

</details>


### [5] [Academics and Generative AI: Empirical and Epistemic Indicators of Policy-Practice Voids](https://arxiv.org/abs/2511.02875)
*R. Yamamoto Ravenor*

Main category: cs.CY

TL;DR: 开发了一个十项间接引出的工具，用于识别机构规则与学术实践中AI使用之间的差距，通过三个过滤指标来评估这种差距。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在学术界普及，政策与实践之间的分歧变得重要，需要可审计的对齐指标来识别这种差距。

Method: 使用嵌入结构化解释框架的十项间接引出工具，从学者中提取经验和认识论信号，通过三个过滤指标来识别政策与实践的差距。

Result: 开发了三个过滤指标：(1)AI整合评估能力，(2)部门级必要性，(3)本体论立场，用于映射采购声明与证据类别。

Conclusion: 该工具能够有效识别机构规则与学术AI实践之间的差距，为政策制定提供可审计的对齐指标。

Abstract: As generative AI diffuses through academia, policy-practice divergence
becomes consequential, creating demand for auditable indicators of alignment.
This study prototypes a ten-item, indirect-elicitation instrument embedded in a
structured interpretive framework to surface voids between institutional rules
and practitioner AI use. The framework extracts empirical and epistemic signals
from academics, yielding three filtered indicators of such voids: (1)
AI-integrated assessment capacity (proxy) - within a three-signal screen (AI
skill, perceived teaching benefit, detection confidence), the share who would
fully allow AI in exams; (2) sector-level necessity (proxy) - among high output
control users who still credit AI with high contribution, the proportion who
judge AI capable of challenging established disciplines; and (3) ontological
stance - among respondents who judge AI different in kind from prior tools,
report practice change, and pass a metacognition gate, the split between
material and immaterial views as an ontological map aligning procurement claims
with evidence classes.

</details>


### [6] [A Criminology of Machines](https://arxiv.org/abs/2511.02895)
*Gian Maria Campedelli*

Main category: cs.CY

TL;DR: 本文主张犯罪学需要应对自主AI代理兴起带来的犯罪和社会控制影响，提出将AI视为具有计算、社会和法律维度的实体，并分析了多AI代理系统风险及四个关键研究问题。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理在各行业部署和机器间交互日益普遍，犯罪学必须开始应对这种转变对犯罪和社会控制的影响，超越将AI仅视为工具的传统观念。

Method: 基于行动者网络理论和Woolgar的机器社会学框架，借鉴AI安全文献，提出双重分类法来表征AI代理间交互产生异常、违法或犯罪结果的渠道。

Result: 提出了四个关键研究问题：机器是否会简单模仿人类、人类犯罪理论是否适用于AI代理、哪些犯罪类型会首先受影响、以及这种社会转变如何影响警务。

Conclusion: 犯罪学家迫切需要从理论和实证角度参与多AI代理系统对犯罪研究的影响，并在AI安全和治理辩论中发挥更积极作用。

Abstract: While the possibility of reaching human-like Artificial Intelligence (AI)
remains controversial, the likelihood that the future will be characterized by
a society with a growing presence of autonomous machines is high. Autonomous AI
agents are already deployed and active across several industries and digital
environments and alongside human-human and human-machine interactions,
machine-machine interactions are poised to become increasingly prevalent. Given
these developments, I argue that criminology must begin to address the
implications of this transition for crime and social control. Drawing on
Actor-Network Theory and Woolgar's decades-old call for a sociology of machines
-- frameworks that acquire renewed relevance with the rise of generative AI
agents -- I contend that criminologists should move beyond conceiving AI solely
as a tool. Instead, AI agents should be recognized as entities with agency
encompassing computational, social, and legal dimensions. Building on the
literature on AI safety, I thus examine the risks associated with the rise of
multi-agent AI systems, proposing a dual taxonomy to characterize the channels
through which interactions among AI agents may generate deviant, unlawful, or
criminal outcomes. I then advance and discuss four key questions that warrant
theoretical and empirical attention: (1) Can we assume that machines will
simply mimic humans? (2) Will crime theories developed for humans suffice to
explain deviant or criminal behaviors emerging from interactions between
autonomous AI agents? (3) What types of criminal behaviors will be affected
first? (4) How might this unprecedented societal shift impact policing? These
questions underscore the urgent need for criminologists to theoretically and
empirically engage with the implications of multi-agent AI systems for the
study of crime and play a more active role in debates on AI safety and
governance.

</details>


### [7] [Google's Hidden Empire](https://arxiv.org/abs/2511.02931)
*Aline Blankertz,Brianna Rock,Nicholas Shaxson*

Main category: cs.CY

TL;DR: 本文揭示谷歌通过收购、支持和投资超过6000家公司建立了庞大的数字帝国，其市场控制力远超预期，并分析了反垄断监管失败的原因。


<details>
  <summary>Details</summary>
Motivation: 研究谷歌在全球数字市场中的实际控制规模，揭示传统反垄断监管的局限性，特别是新古典经济学方法在评估垂直和混合并购时的不足。

Method: 通过分析谷歌的并购活动数据，特别是对Google/DoubleClick和Google/Fitbit并购案的案例研究，评估监管机构的执法失败。

Result: 发现谷歌已构建包含6000多家公司的庞大网络，其市场控制力远超公开认知，传统反垄断方法未能有效识别和阻止这种市场力量的集中。

Conclusion: 需要改革反垄断监管方法，特别在评估大型科技公司并购时，应超越传统经济学框架，以应对谷歌拟以320亿美元收购Wiz等重大交易。

Abstract: This paper presents striking new data about the scale of Google's involvement
in the global digital and corporate landscape, head and shoulders above the
other big tech firms. While public attention and some antitrust scrutiny has
focused on these firms' mergers and acquisitions (M&A) activities, Google has
also been amassing an empire of more than 6,000 companies which it has
acquired, supported or invested in, across the digital economy and beyond. The
power of Google over the digital markets infrastructure and dynamics is likely
greater than previously documented. We also trace the antitrust failures that
have led to this state of affairs. In particular, we explore the role of
neoclassical economics practiced both inside the regulatory authorities and by
consultants on the outside. Their unduly narrow approach has obscured harms
from vertical and conglomerate concentrations of market power and erected ever
higher hurdles for enforcement action, as we demonstrate using examples of the
failure to intervene in the Google/DoubleClick and Google/Fitbit mergers. Our
lessons from the past failures can inform the current approach towards one of
the biggest ever big tech M&A deals: Google's $32 billion acquisition of the
Israeli cloud cybersecurity firm Wiz.

</details>


### [8] [Ownership and Flow Primitives for Scalable Consent Management in Digital Public Infrastructures](https://arxiv.org/abs/2511.02950)
*Rohith Vaidyanathan,Srinath Srinivasa,Praseeda,Dev Shinde*

Main category: cs.CY

TL;DR: 本文提出了一套基础抽象概念来表示数字公共基础设施中数字资产的拥有模式及其对同意数据流的影响，旨在解决大规模人口中的复杂同意管理问题。


<details>
  <summary>Details</summary>
Motivation: 数字公共基础设施中的同意管理面临复杂挑战，需要在个人自主权与公共福祉、国家主权之间取得平衡，同时确保符合数据共享法规要求。

Method: 提出一套基础抽象概念来表示数字资产的拥有模式及其对同意数据流的影响，构建透明、安全、以用户为中心的同意管理架构。

Result: 通过形式化的数据拥有模型，实现了同意端到端的可追溯性、细粒度的数据共享控制，并与不断发展的法律和监管框架保持一致。

Conclusion: 所提出的架构能够有效解决数字公共基础设施中复杂的同意管理问题，为大规模人口的数据共享提供了透明、安全且合规的解决方案。

Abstract: Digital public infrastructures (DPIs) represent networks of open technology
standards, applications, services, and digital assets made available for the
public good. One of the key challenges in DPI design is to resolve complex
issues of consent, scaled over large populations. While the primary objective
of consent management is to empower the data owner, ownership itself can come
with variegated morphological forms with different implications over consent.
Questions of ownership in a public space also have several nuances where
individual autonomy needs to be balanced with public well-being and national
sovereignty. This requires consent management to be compliant with applicable
regulations for data sharing. This paper addresses the question of representing
modes of ownership of digital assets and their corresponding implications for
consensual data flows in a DPI. It proposes a set of foundational abstractions
to represent them. Our proposed architecture responds to the growing need for
transparent, secure, and user-centric consent management within Digital Public
Infrastructure (DPI). Incorporating a formalised data ownership model enables
end-to-end traceability of consent, fine-grained control over data sharing, and
alignment with evolving legal and regulatory frameworks.

</details>


### [9] [Retrofitters, pragmatists and activists: Public interest litigation for accountable automated decision-making](https://arxiv.org/abs/2511.03211)
*Henry Fraser,Zahra Stardust*

Main category: cs.CY

TL;DR: 本文探讨了在澳大利亚通过公益诉讼促进AI和自动化决策问责的作用，分析了在监管面临地缘政治阻力时，如何通过执行现有法律来实现有效治理。


<details>
  <summary>Details</summary>
Motivation: 由于ADM监管面临地缘政治阻力，有效治理必须至少部分依赖现有法律的执行，因此需要探索公益诉讼在促进AI问责中的作用。

Method: 通过对澳大利亚公益诉讼律师、技术政策活动家和技术法学学者的访谈，将公益诉讼定位为ADM透明度、问责和正义生态系统的一部分。

Result: 研究发现公益诉讼是法律改造的实践，即调整旧法律以适应新情况，并汇总了有效的公益诉讼策略和战术。

Conclusion: 公益诉讼是促进ADM问责的重要工具，但存在法律系统限制，需要克服这些限制的机构安排才能实现有效诉讼和问责。

Abstract: This paper examines the role of public interest litigation in promoting
accountability for AI and automated decision-making (ADM) in Australia. Since
ADM regulatio faces geopolitical headwinds, effective governance will have to
rely at least in part on the enforcement of existing laws. Drawing on
interviews with Australian public interest litigators, technology policy
activists, and technology law scholars, the paper positions public interest
litigation as part of a larger ecosystem for transparency, accountability and
justice with respect to ADM. It builds on one participants's characterisation
of litigation about ADM as an exercise in legal retrofitting: adapting old laws
to new circumstances. The paper's primary contribution is to aggregate,
organise and present original insights on pragmatic strategies and tactics for
effective public interest litigation about ADM. Naturally, it also contends
with the limits of these strategies, and of the legal system. Where limits are,
however, capable of being overcome, the paper presents findings on urgent
needs: the enabling institutional arrangements without which effective
litigation and accountability will falter. The paper is relevant to law and
technology scholars; individuals and groups harmed by ADM; public interest
litigators and technology lawyers; civil society and advocacy organisations;
and policymakers.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [10] [A Theory of Saving under Risk Preference Dynamics](https://arxiv.org/abs/2511.03142)
*Qingyin Ma,Xinxi Song,Alexis Akira Toda*

Main category: econ.TH

TL;DR: 本文提出一个包含偏好冲击的最优储蓄通用理论，证明当存在未来风险厌恶程度降低的可能性时，富裕家庭会出现零边际消费倾向和100%储蓄率，这比现有理论条件更宽松且更符合实证观察。


<details>
  <summary>Details</summary>
Motivation: 实证显示富裕家庭储蓄率显著更高、边际消费倾向更低，但现有理论只能在严格假设下解释这一现象。本文旨在构建更通用的理论框架来解释富裕家庭的储蓄行为。

Method: 开发包含偏好冲击的最优储蓄通用理论，允许风险厌恶程度随状态和时间变化，分析渐进消费和储蓄动态。

Result: 证明当存在未来风险厌恶程度降低的正概率时，会出现零渐进边际消费倾向和100%储蓄率，这一结果比现有理论条件更弱。

Conclusion: 消失的边际消费倾向是最优储蓄模型的普遍特征而非特殊情况，为富裕家庭储蓄行为提供了更稳健的理论解释和实证一致性。

Abstract: Empirical evidence shows that wealthy households have substantially higher
saving rates and markedly lower marginal propensity to consume (MPC) than other
groups. Existing theory can account for this pattern only under restrictive
assumptions on returns, discounting, and preferences. This paper develops a
general theory of optimal savings with preference shocks, allowing risk
aversion to vary across states and over time. We show that incorporating such
heterogeneity in risk attitudes fundamentally alters the asymptotic dynamics of
consumption and saving. In particular, we provide an analytical
characterization of the asymptotic MPCs and show that zero asymptotic MPCs,
corresponding to a 100\% asymptotic saving rate, arise under markedly weaker
conditions than in existing theory. Strikingly, such outcomes occur whenever
there is a positive probability that agents become less risk averse in the
future. As a result, the vanishing MPC emerges as a generic feature rather than
a knife-edge result of the optimal savings model, offering a more theoretically
robust and empirically consistent account of the saving behavior of wealthy
households.

</details>


### [11] [Balanced contributions, consistency, and value for games with externalities](https://arxiv.org/abs/2511.03145)
*André Casajus,Yukihiko Funaki,Frank Huettner*

Main category: econ.TH

TL;DR: 本文研究了具有外部性的博弈中Shapley值的公平一致扩展，基于Casajus等人的限制条件，定义了平衡贡献、Sobolev一致性和Hart-Mas-Colell一致性，并证明这些性质可以刻画Macho-Stadler等人提出的Shapley值推广。


<details>
  <summary>Details</summary>
Motivation: 研究具有外部性的博弈中如何公平一致地扩展经典的Shapley值，填补现有理论空白。

Method: 基于Casajus等人识别的限制条件，定义适用于外部性博弈的平衡贡献、Sobolev一致性和Hart-Mas-Colell一致性等公理性质。

Result: 证明了这些性质能够刻画Macho-Stadler等人提出的Shapley值推广，平行于经典Shapley值的重要特征化结果。

Conclusion: 成功建立了具有外部性的博弈中Shapley值推广的公理化特征，为这类博弈的公平分配提供了理论基础。

Abstract: We consider fair and consistent extensions of the Shapley value for games
with externalities. Based on the restriction identified by Casajus et al.
(2024, Games Econ. Behavior 147, 88-146), we define balanced contributions,
Sobolev's consistency, and Hart and Mas-Colell's consistency for games with
externalities, and we show that these properties lead to characterizations of
the generalization of the Shapley value introduced by Macho-Stadler et al.
(2007, J. Econ. Theory 135, 339-356), that parallel important characterizations
of the Shapley value.

</details>


### [12] [Explicit Consumption Functions with Borrowing Constraints: a Continuous Time Approach](https://arxiv.org/abs/2511.03452)
*Jordan Roulleau-Pasdeloup*

Main category: econ.TH

TL;DR: 该论文推导了收入波动问题的显式全局闭式解，包括r=0时的精确解和r>0时的近似解，并分析了边际消费倾向的性质。


<details>
  <summary>Details</summary>
Motivation: 标准的收入波动问题在借贷约束和恒定利率下没有已知的显式全局闭式解，作者旨在填补这一空白。

Method: 使用连续时间公式，在r=0时利用Lambert W函数推导精确解，在r>0时推导适用于r接近0的近似解。

Result: 成功推导出显式全局闭式解，获得了资产和永久收入的边际消费倾向的显式表达式，并证明消费函数是超模的。

Conclusion: 该研究为收入波动问题提供了新的解析解，揭示了消费函数的超模性质，对理解消费行为有重要意义。

Abstract: There is no known explicit global closed form solution for the standard
income fluctuation problem with a borrowing constraint and where wealth
accumulates with a constant interest rate $r$. Using a continuous time
formulation, I derive an explicit global closed form solution for the case
$r=0$ using the Lambert W function. For the case $r>0$, I derive an explicit
global closed form approximation that is valid for $r\sim 0$. I then use these
to derive explicit expressions for the marginal propensity to consume out of
assets and permanent income. I show that the cross-derivative between the two
is strictly positive: the consumption consumption is supermodular.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [13] [Toward an Agricultural Operational Design Domain: A Framework](https://arxiv.org/abs/2511.02937)
*Mirco Felske,Jannik Redenius,Georg Happich,Julius Schöning*

Main category: cs.RO

TL;DR: 本文提出了农业运营设计域（Ag-ODD）框架，用于描述和验证自主农业系统的运营边界，解决现有ODD概念无法应对农业应用独特挑战的问题。


<details>
  <summary>Details</summary>
Motivation: 农业自动化系统在复杂多变环境中运行，需要整合驾驶和工作流程，现有运营设计域概念无法满足农业应用的独特需求，需要结构化的环境描述方法。

Method: Ag-ODD框架包含三个核心元素：1）基于ASAM Open ODD和CityGML的结构化描述概念；2）扩展自PEGASUS 6层模型的7层模型，增加了过程层；3）迭代验证流程确保完整性和一致性。

Result: 该框架提供了创建明确且可验证的Ag-ODD的一致方法，演示用例表明其能够支持自主农业系统环境描述的标准化和可扩展性。

Conclusion: Ag-ODD框架为自主农业系统提供了结构化的环境描述和验证方法，有助于解决农业自动化中的复杂性和一致性挑战。

Abstract: The agricultural sector increasingly relies on autonomous systems that
operate in complex and variable environments. Unlike on-road applications,
agricultural automation integrates driving and working processes, each of which
imposes distinct operational constraints. Handling this complexity and ensuring
consistency throughout the development and validation processes requires a
structured, transparent, and verified description of the environment. However,
existing Operational Design Domain (ODD) concepts do not yet address the unique
challenges of agricultural applications.
  Therefore, this work introduces the Agricultural ODD (Ag-ODD) Framework,
which can be used to describe and verify the operational boundaries of
autonomous agricultural systems. The Ag-ODD Framework consists of three core
elements. First, the Ag-ODD description concept, which provides a structured
method for unambiguously defining environmental and operational parameters
using concepts from ASAM Open ODD and CityGML. Second, the 7-Layer Model
derived from the PEGASUS 6-Layer Model, has been extended to include a process
layer to capture dynamic agricultural operations. Third, the iterative
verification process verifies the Ag-ODD against its corresponding logical
scenarios, derived from the 7-Layer Model, to ensure the Ag-ODD's completeness
and consistency.
  Together, these elements provide a consistent approach for creating
unambiguous and verifiable Ag-ODD. Demonstrative use cases show how the Ag-ODD
Framework can support the standardization and scalability of environmental
descriptions for autonomous agricultural systems.

</details>


### [14] [Comprehensive Assessment of LiDAR Evaluation Metrics: A Comparative Study Using Simulated and Real Data](https://arxiv.org/abs/2511.02994)
*Syed Mostaquim Ali,Taufiq Rahman,Ghazal Farhani,Mohamed H. Zaki,Benoit Anctil,Dominique Charlebois*

Main category: cs.RO

TL;DR: 本文探索了用于比较真实世界和模拟LiDAR扫描的评估指标，发现密度感知Chamfer距离(DCD)在所有情况下表现最佳，并验证了虚拟测试环境在自动驾驶系统开发中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于成本和安全性考虑，传统物理测试不切实际，需要虚拟测试环境(VTE)作为替代方案。比较VTE生成的传感器输出与真实世界对应物可以验证VTE的准确性。

Method: 采用综合实验方法测试不同评估指标的敏感性和准确性，包括噪声、密度、失真、传感器方向和通道设置。使用真实LiDAR扫描数据生成虚拟测试环境，并在相同姿态下生成模拟LiDAR扫描进行比较。

Result: 模拟和真实LiDAR扫描在语义分割输出上相似，mIoU为21%（校正强度后），平均DCD为0.63。密度感知Chamfer距离在感知方法中最具相关性。

Conclusion: 密度感知Chamfer距离是评估模拟和真实LiDAR扫描相似度的最佳指标，虚拟测试环境可以有效地用于自动驾驶系统开发，尽管模拟和真实扫描在几何特性和模型输出上存在差异。

Abstract: For developing safe Autonomous Driving Systems (ADS), rigorous testing is
required before they are deemed safe for road deployments. Since comprehensive
conventional physical testing is impractical due to cost and safety concerns,
Virtual Testing Environments (VTE) can be adopted as an alternative. Comparing
VTE-generated sensor outputs against their real-world analogues can be a strong
indication that the VTE accurately represents reality. Correspondingly, this
work explores a comprehensive experimental approach to finding evaluation
metrics suitable for comparing real-world and simulated LiDAR scans. The
metrics were tested in terms of sensitivity and accuracy with different noise,
density, distortion, sensor orientation, and channel settings. From comparing
the metrics, we found that Density Aware Chamfer Distance (DCD) works best
across all cases. In the second step of the research, a Virtual Testing
Environment was generated using real LiDAR scan data. The data was collected in
a controlled environment with only static objects using an instrumented vehicle
equipped with LiDAR, IMU and cameras. Simulated LiDAR scans were generated from
the VTEs using the same pose as real LiDAR scans. The simulated and LiDAR scans
were compared in terms of model perception and geometric similarity. Actual and
simulated LiDAR scans have a similar semantic segmentation output with a mIoU
of 21\% with corrected intensity and an average density aware chamfer distance
(DCD) of 0.63. This indicates a slight difference in the geometric properties
of simulated and real LiDAR scans and a significant difference between model
outputs. During the comparison, density-aware chamfer distance was found to be
the most correlated among the metrics with perception methods.

</details>


### [15] [A Collaborative Reasoning Framework for Anomaly Diagnostics in Underwater Robotics](https://arxiv.org/abs/2511.03075)
*Markus Buchholz,Ignacio Carlucho,Yvan R. Petillot*

Main category: cs.RO

TL;DR: AURA是一个用于机器人异常和故障诊断的协作框架，结合了大型语言模型、高保真数字孪生和人机交互，通过双代理架构实时检测和响应异常行为。


<details>
  <summary>Details</summary>
Motivation: 在安全关键环境中安全部署自主系统需要将人类专业知识与AI驱动分析相结合，特别是在处理不可预见的异常时。

Method: 采用双代理架构：低级状态异常特征化代理监控遥测数据并转换为结构化问题描述；高级诊断推理代理与操作员进行知识驱动对话以识别根本原因。人类验证的诊断结果转化为训练样本，不断优化感知模型。

Result: 建立了一个可信赖、持续改进的人机团队模式，将专家知识逐步提炼到AI中，使其从静态工具转变为自适应合作伙伴。

Conclusion: AURA框架为构建可信赖且持续改进的人机协作系统提供了具体实现模式，通过反馈循环将专家知识逐步注入AI系统。

Abstract: The safe deployment of autonomous systems in safety-critical settings
requires a paradigm that combines human expertise with AI-driven analysis,
especially when anomalies are unforeseen. We introduce AURA (Autonomous
Resilience Agent), a collaborative framework for anomaly and fault diagnostics
in robotics. AURA integrates large language models (LLMs), a high-fidelity
digital twin (DT), and human-in-the-loop interaction to detect and respond to
anomalous behavior in real time. The architecture uses two agents with clear
roles: (i) a low-level State Anomaly Characterization Agent that monitors
telemetry and converts signals into a structured natural-language problem
description, and (ii) a high-level Diagnostic Reasoning Agent that conducts a
knowledge-grounded dialogue with an operator to identify root causes, drawing
on external sources. Human-validated diagnoses are then converted into new
training examples that refine the low-level perceptual model. This feedback
loop progressively distills expert knowledge into the AI, transforming it from
a static tool into an adaptive partner. We describe the framework's operating
principles and provide a concrete implementation, establishing a pattern for
trustworthy, continually improving human-robot teams.

</details>


### [16] [WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models](https://arxiv.org/abs/2511.03077)
*R. Khorrambakht,Joaquim Ortiz-Haro,Joseph Amigo,Omar Mostafa,Daniel Dugas,Franziska Meier,Ludovic Righetti*

Main category: cs.RO

TL;DR: 提出了一种基于世界模型的机器人规划方法，使用非结构化的游戏数据学习视觉世界模型、扩散动作采样器和奖励模型，结合MCTS规划器优化动作序列，在真实机器人任务中显著优于行为克隆基线。


<details>
  <summary>Details</summary>
Motivation: 行为克隆方法需要特定任务的演示数据且难以迁移到新任务，而基于策略的方法需要频繁的环境重置。本文采用基于模型的方法，使用易于收集的非结构化数据来学习环境模型。

Method: 收集非结构化游戏数据学习动作条件视觉世界模型、扩散动作采样器和奖励模型，使用MCTS规划器优化长序列动作，通过零阶模型预测控制器执行计划。

Result: 在3个真实机器人任务中验证了方法的有效性，动作采样器缓解了世界模型在规划过程中的幻觉问题，相比行为克隆基线有显著改进。

Conclusion: 基于世界模型的规划方法比行为克隆更有效，扩散动作采样器能有效缓解模型幻觉，MCTS规划器能够优化长序列动作决策。

Abstract: Robots must understand their environment from raw sensory inputs and reason
about the consequences of their actions in it to solve complex tasks. Behavior
Cloning (BC) leverages task-specific human demonstrations to learn this
knowledge as end-to-end policies. However, these policies are difficult to
transfer to new tasks, and generating training data is challenging because it
requires careful demonstrations and frequent environment resets. In contrast to
such policy-based view, in this paper we take a model-based approach where we
collect a few hours of unstructured easy-to-collect play data to learn an
action-conditioned visual world model, a diffusion-based action sampler, and
optionally a reward model. The world model -- in combination with the action
sampler and a reward model -- is then used to optimize long sequences of
actions with a Monte Carlo Tree Search (MCTS) planner. The resulting plans are
executed on the robot via a zeroth-order Model Predictive Controller (MPC). We
show that the action sampler mitigates hallucinations of the world model during
planning and validate our approach on 3 real-world robotic tasks with varying
levels of planning and modeling complexity. Our experiments support the
hypothesis that planning leads to a significant improvement over BC baselines
on a standard manipulation test environment.

</details>


### [17] [3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors](https://arxiv.org/abs/2511.03078)
*Rohan Kota,Kaival Shah,J. Edward Colgate,Gregory Reardon*

Main category: cs.RO

TL;DR: 开发了一个开源库，将低成本3D打印机转换为自动探测设备，用于生成大量标记训练数据以校准触觉传感器。


<details>
  <summary>Details</summary>
Motivation: 触觉传感对于实现灵巧可靠的机器人操作至关重要，但校准过程通常需要大量人工工作且缺乏标准化方法。

Method: 使用3D打印机作为自动探测设备收集数据，然后使用定制卷积神经网络重建高质量深度图。

Result: 成功校准了两种商用触觉传感器（DIGIT和GelSight Mini），并通过数据消融研究确定了所需数据量。

Conclusion: 该自动化方法可以加速触觉传感研究，简化传感器部署，促进触觉传感在机器人平台中的实际应用。

Abstract: Tactile sensing plays a key role in enabling dexterous and reliable robotic
manipulation, but realizing this capability requires substantial calibration to
convert raw sensor readings into physically meaningful quantities. Despite its
near-universal necessity, the calibration process remains ad hoc and
labor-intensive. Here, we introduce \libname{}, an open-source library that
transforms a low-cost 3D printer into an automated probing device capable of
generating large volumes of labeled training data for tactile sensor
calibration. We demonstrate the utility of \libname{} by calibrating two
commercially available vision-based tactile sensors, DIGIT and GelSight Mini,
to reconstruct high-quality depth maps using the collected data and a custom
convolutional neural network. In addition, we perform a data ablation study to
determine how much data is needed for accurate calibration, providing practical
guidelines for researchers working with these specific sensors, and we
benchmark the trained models on previously unseen objects to evaluate
calibration accuracy and generalization performance. By automating tactile
sensor calibration, \libname{} can accelerate tactile sensing research,
simplify sensor deployment, and promote the practical integration of tactile
sensing in robotic platforms.

</details>


### [18] [SENT Map -- Semantically Enhanced Topological Maps with Foundation Models](https://arxiv.org/abs/2511.03165)
*Raj Surya Rajendran Kathirvel,Zach A Chavis,Stephen J. Guy,Karthik Desingh*

Main category: cs.RO

TL;DR: SENT-Map是一种语义增强的拓扑地图，通过JSON文本格式表示室内环境，利用基础模型支持自主导航和操作，采用两阶段方法：先用视觉基础模型与操作员共同建图，然后用自然语言查询进行规划。


<details>
  <summary>Details</summary>
Motivation: 为了支持自主导航和操作，需要一种既能被人类理解又能被基础模型处理的语义地图表示方法，避免部署时出现不可行状态。

Method: 采用两阶段方法：第一阶段使用视觉基础模型与操作员共同建图；第二阶段使用SENT-Map表示和自然语言查询在基础模型中进行规划。

Result: 实验结果表明，语义增强使得即使是小型本地可部署的基础模型也能成功在室内环境中进行规划。

Conclusion: SENT-Map框架通过语义增强的拓扑地图表示，有效支持了基础模型在室内环境中的自主导航和操作规划。

Abstract: We introduce SENT-Map, a semantically enhanced topological map for
representing indoor environments, designed to support autonomous navigation and
manipulation by leveraging advancements in foundational models (FMs). Through
representing the environment in a JSON text format, we enable semantic
information to be added and edited in a format that both humans and FMs
understand, while grounding the robot to existing nodes during planning to
avoid infeasible states during deployment. Our proposed framework employs a two
stage approach, first mapping the environment alongside an operator with a
Vision-FM, then using the SENT-Map representation alongside a natural-language
query within an FM for planning. Our experimental results show that
semantic-enhancement enables even small locally-deployable FMs to successfully
plan over indoor environments.

</details>


### [19] [Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning](https://arxiv.org/abs/2511.03167)
*Xin Liu,Jinze Wu,Yinghui Li,Chenkun Qi,Yufei Xue,Feng Gao*

Main category: cs.RO

TL;DR: 提出了一种基于运动先验的方法，成功将深度强化学习应用于真实六足机器人，使其在复杂地形中生成自然步态并展现出色鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多足机器人虽然能通过多条腿与环境交互来增强复杂地形的导航稳定性，但在更大的动作探索空间中如何有效协调多条腿以生成自然且鲁棒的运动是一个关键问题。

Method: 生成优化的运动先验数据集，基于这些先验训练对抗判别器来引导六足机器人学习自然步态，然后将学习到的策略成功迁移到真实六足机器人上。

Result: 学习到的策略成功迁移到真实六足机器人，在复杂地形中无需视觉信息即可展示自然步态模式和显著鲁棒性。这是首次使用强化学习控制器在真实六足机器人上实现复杂地形行走。

Conclusion: 该方法成功解决了多足机器人步态协调问题，为真实环境中的六足机器人运动控制提供了有效的强化学习解决方案。

Abstract: Multi-legged robots offer enhanced stability to navigate complex terrains
with their multiple legs interacting with the environment. However, how to
effectively coordinate the multiple legs in a larger action exploration space
to generate natural and robust movements is a key issue. In this paper, we
introduce a motion prior-based approach, successfully applying deep
reinforcement learning algorithms to a real hexapod robot. We generate a
dataset of optimized motion priors, and train an adversarial discriminator
based on the priors to guide the hexapod robot to learn natural gaits. The
learned policy is then successfully transferred to a real hexapod robot, and
demonstrate natural gait patterns and remarkable robustness without visual
information in complex terrains. This is the first time that a reinforcement
learning controller has been used to achieve complex terrain walking on a real
hexapod robot.

</details>


### [20] [Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control](https://arxiv.org/abs/2511.03181)
*Rewida Ali,Cristian C. Beltran-Hernandez,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出了一个基于学习的框架，将LLM驱动的高级任务规划器与混合模仿学习和强化学习的低级策略相结合，用于机器人礼品包装任务，实现了97%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中可变形物体操作的挑战，特别是礼品包装这类涉及精确折叠、控制折痕和安全固定的长时程操作问题。

Method: 使用Sub-task Aware Robotic Transformer (START)从人类演示中学习统一策略，通过子任务ID提供显式时间基础，捕获整个包装序列的长期时间依赖关系。

Result: 在真实世界包装任务中达到97%的成功率，统一变换器策略减少了对专用模型的需求，支持可控的人类监督。

Conclusion: 该框架有效连接了高级意图与可变形物体操作所需的精细力控制，展示了在复杂人机协作任务中的鲁棒性能。

Abstract: Human-robot cooperation is essential in environments such as warehouses and
retail stores, where workers frequently handle deformable objects like paper,
bags, and fabrics. Coordinating robotic actions with human assistance remains
difficult due to the unpredictable dynamics of deformable materials and the
need for adaptive force control. To explore this challenge, we focus on the
task of gift wrapping, which exemplifies a long-horizon manipulation problem
involving precise folding, controlled creasing, and secure fixation of paper.
Success is achieved when the robot completes the sequence to produce a neatly
wrapped package with clean folds and no tears.
  We propose a learning-based framework that integrates a high-level task
planner powered by a large language model (LLM) with a low-level hybrid
imitation learning (IL) and reinforcement learning (RL) policy. At its core is
a Sub-task Aware Robotic Transformer (START) that learns a unified policy from
human demonstrations. The key novelty lies in capturing long-range temporal
dependencies across the full wrapping sequence within a single model. Unlike
vanilla Action Chunking with Transformer (ACT), typically applied to short
tasks, our method introduces sub-task IDs that provide explicit temporal
grounding. This enables robust performance across the entire wrapping process
and supports flexible execution, as the policy learns sub-goals rather than
merely replicating motion sequences.
  Our framework achieves a 97% success rate on real-world wrapping tasks. We
show that the unified transformer-based policy reduces the need for specialized
models, allows controlled human supervision, and effectively bridges high-level
intent with the fine-grained force control required for deformable object
manipulation.

</details>


### [21] [Collaborative Assembly Policy Learning of a Sightless Robot](https://arxiv.org/abs/2511.03189)
*Zeqing Zhang,Weifeng Lu,Lei Yang,Wei Jing,Bowei Tang,Jia Pan*

Main category: cs.RO

TL;DR: 提出一种结合导纳控制和强化学习的新方法，用于盲机器人-人类协作的板插入任务，相比传统导纳控制提高了成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 传统导纳控制在物理人机协作中难以准确测量人力/力矩来估计人类意图，而纯强化学习方法因安全约束和稀疏奖励不适合板插入任务。

Method: 使用人类设计的导纳控制器来促进更主动的机器人行为，结合强化学习方法减少人类操作者的努力。

Result: 仿真和真实实验表明，该方法在成功率和任务完成时间上优于导纳控制，且测量到的力/力矩显著减少。

Conclusion: 提出的方法能有效解决盲机器人-人类协作任务中的挑战，提高协作效率和安全性。

Abstract: This paper explores a physical human-robot collaboration (pHRC) task
involving the joint insertion of a board into a frame by a sightless robot and
a human operator. While admittance control is commonly used in pHRC tasks, it
can be challenging to measure the force/torque applied by the human for
accurate human intent estimation, limiting the robot's ability to assist in the
collaborative task. Other methods that attempt to solve pHRC tasks using
reinforcement learning (RL) are also unsuitable for the board-insertion task
due to its safety constraints and sparse rewards. Therefore, we propose a novel
RL approach that utilizes a human-designed admittance controller to facilitate
more active robot behavior and reduce human effort. Through simulation and
real-world experiments, we demonstrate that our approach outperforms admittance
control in terms of success rate and task completion time. Additionally, we
observed a significant reduction in measured force/torque when using our
proposed approach compared to admittance control. The video of the experiments
is available at https://youtu.be/va07Gw6YIog.

</details>


### [22] [GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement](https://arxiv.org/abs/2511.03400)
*Minquan Gao,Xinyi Li,Qing Yan,Xiaojian Sun,Xiaopan Zhang,Chien-Ming Huang,Jiachen Li*

Main category: cs.RO

TL;DR: GUIDES是一个轻量级框架，通过将基础模型的语义指导注入预训练机器人策略的潜在空间，无需架构重新设计即可增强策略的语义意识。


<details>
  <summary>Details</summary>
Motivation: 预训练机器人策略缺乏基础模型的语义意识，但完全替换成本高昂且会丢失积累的知识，需要一种升级而非替换的解决方案。

Method: 使用微调的视觉语言模型生成上下文指令，通过辅助模块编码为指导嵌入，注入策略潜在空间，并通过大语言模型反射器在推理时监控置信度并进行推理循环。

Result: 在RoboCasa仿真环境中验证显示任务成功率显著提升，UR5机器人实际部署证明提高了关键子任务（如抓取）的运动精度。

Conclusion: GUIDES提供了一种实用且资源高效的途径来升级已验证的机器人策略，而非替换它们。

Abstract: Pre-trained robot policies serve as the foundation of many validated robotic
systems, which encapsulate extensive embodied knowledge. However, they often
lack the semantic awareness characteristic of foundation models, and replacing
them entirely is impractical in many situations due to high costs and the loss
of accumulated knowledge. To address this gap, we introduce GUIDES, a
lightweight framework that augments pre-trained policies with semantic guidance
from foundation models without requiring architectural redesign. GUIDES employs
a fine-tuned vision-language model (Instructor) to generate contextual
instructions, which are encoded by an auxiliary module into guidance
embeddings. These embeddings are injected into the policy's latent space,
allowing the legacy model to adapt to this new semantic input through brief,
targeted fine-tuning. For inference-time robustness, a large language
model-based Reflector monitors the Instructor's confidence and, when confidence
is low, initiates a reasoning loop that analyzes execution history, retrieves
relevant examples, and augments the VLM's context to refine subsequent actions.
Extensive validation in the RoboCasa simulation environment across diverse
policy architectures shows consistent and substantial improvements in task
success rates. Real-world deployment on a UR5 robot further demonstrates that
GUIDES enhances motion precision for critical sub-tasks such as grasping.
Overall, GUIDES offers a practical and resource-efficient pathway to upgrade,
rather than replace, validated robot policies.

</details>


### [23] [Value Elicitation for a Socially Assistive Robot Addressing Social Anxiety: A Participatory Design Approach](https://arxiv.org/abs/2511.03444)
*Vesna Poprcova,Iulia Lefter,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 通过参与式设计工作坊，研究心理健康学术研究人员对社交焦虑辅助机器人设计的核心价值观，包括适应性、接受度和有效性。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是普遍的心理健康问题，但支持治疗不足。社交机器人技术为补充传统心理健康干预提供了新机会，需要了解用户价值观来设计有意义的解决方案。

Method: 采用参与式设计工作坊，通过创造性、反思性和展望性活动，让心理健康学术研究人员探索场景和设计可能性，系统获取价值观、期望、需求和偏好。

Result: 研究发现社交焦虑支持机器人设计的核心价值包括适应性、接受度和有效性，强调用户中心和情境感知的设计考虑。

Conclusion: 研究强调了研究导向的价值获取方法的重要性，为开发社交辅助机器人提供了用户中心和情境感知的设计指导。

Abstract: Social anxiety is a prevalent mental health condition that can significantly
impact overall well-being and quality of life. Despite its widespread effects,
adequate support or treatment for social anxiety is often insufficient.
Advances in technology, particularly in social robotics, offer promising
opportunities to complement traditional mental health. As an initial step
toward developing effective solutions, it is essential to understand the values
that shape what is considered meaningful, acceptable, and helpful. In this
study, a participatory design workshop was conducted with mental health
academic researchers to elicit the underlying values that should inform the
design of socially assistive robots for social anxiety support. Through
creative, reflective, and envisioning activities, participants explored
scenarios and design possibilities, allowing for systematic elicitation of
values, expectations, needs, and preferences related to robot-supported
interventions. The findings reveal rich insights into design-relevant
values-including adaptivity, acceptance, and efficacy-that are core to support
for individuals with social anxiety. This study highlights the significance of
a research-led approach to value elicitation, emphasising user-centred and
context-aware design considerations in the development of socially assistive
robots.

</details>


### [24] [Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control](https://arxiv.org/abs/2511.03481)
*Jianbo Yuan,Haohua Zhu,Jing Dai,Sheng Yi*

Main category: cs.RO

TL;DR: Dex-Hand 021是一款高性能的五指机器人手，具有12个主动和7个被动自由度，重量仅1kg。采用基于本体感觉力传感的导纳控制方法，在抓取能力和精度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 人类手在日常生活中和工业应用中发挥着重要作用，但复制其多功能能力（包括运动、感知和协调操作）对机器人系统仍然是一个巨大挑战。需要平衡类人敏捷性与工程约束（如复杂性、尺寸重量比、耐用性和力传感性能）。

Method: 开发了电缆驱动的五指机器人手，提出基于本体感觉力传感的导纳控制方法，增强操作能力。

Result: 单指负载能力超过10N，指尖重复性低于0.001m，力估计误差低于0.2N。与PID控制相比，多物体抓取中的关节扭矩减少了31.19%，显著提高了力传感能力并防止碰撞过载。成功执行了33种GRASP分类运动和复杂操作任务。

Conclusion: 这项工作推进了轻量级工业级灵巧手的设计，增强了本体感觉控制，为机器人操作和智能制造做出了贡献。

Abstract: The human hand plays a vital role in daily life and industrial applications,
yet replicating its multifunctional capabilities-including motion, sensing, and
coordinated manipulation-with robotic systems remains a formidable challenge.
Developing a dexterous robotic hand requires balancing human-like agility with
engineering constraints such as complexity, size-to-weight ratio, durability,
and force-sensing performance. This letter presents Dex-Hand 021, a
high-performance, cable-driven five-finger robotic hand with 12 active and 7
passive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight
1 kg design. We propose a proprioceptive force-sensing-based admittance control
method to enhance manipulation. Experimental results demonstrate its superior
performance: a single-finger load capacity exceeding 10 N, fingertip
repeatability under 0.001 m, and force estimation errors below 0.2 N. Compared
to PID control, joint torques in multi-object grasping are reduced by 31.19%,
significantly improves force-sensing capability while preventing overload
during collisions. The hand excels in both power and precision grasps,
successfully executing 33 GRASP taxonomy motions and complex manipulation
tasks. This work advances the design of lightweight, industrial-grade dexterous
hands and enhances proprioceptive control, contributing to robotic manipulation
and intelligent manufacturing.

</details>


### [25] [ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications](https://arxiv.org/abs/2511.03497)
*Lei Fu,Sahar Salimpour,Leonardo Militano,Harry Edelman,Jorge Peña Queralta,Giovanni Toffetti*

Main category: cs.RO

TL;DR: 本文提出了一个用于分析ROS和ROS 2数据包的MCP服务器，通过自然语言处理机器人数据，并评估了8种不同LLM/VLM模型在工具调用能力上的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然Agentic AI和Physical AI是两个重要的AI研究领域，但它们在机器人领域的交叉研究仍然稀缺。本文旨在填补这一空白，通过MCP协议实现机器人数据的自然语言分析。

Method: 开发了一个MCP服务器，专门用于分析ROS/ROS 2数据包，内置了机器人领域知识的工具，支持轨迹分析、激光扫描数据、变换和时间序列数据等。同时提供了一个轻量级UI用于在不同LLM上测试工具性能。

Result: 实验评估了8种最先进的LLM/VLM模型，发现Kimi K2和Claude Sonnet 4在工具调用能力上表现最佳。工具描述模式、参数数量、可用工具数量等因素都会影响成功率。

Conclusion: MCP服务器为机器人数据的自然语言分析提供了有效解决方案，但不同LLM在工具调用能力上存在显著差异，需要进一步优化工具设计和模型选择。

Abstract: Agentic AI systems and Physical or Embodied AI systems have been two key
research verticals at the forefront of Artificial Intelligence and Robotics,
with Model Context Protocol (MCP) increasingly becoming a key component and
enabler of agentic applications. However, the literature at the intersection of
these verticals, i.e., Agentic Embodied AI, remains scarce. This paper
introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for
analyzing, visualizing and processing robot data with natural language through
LLMs and VLMs. We describe specific tooling built with robotics domain
knowledge, with our initial release focused on mobile robotics and supporting
natively the analysis of trajectories, laser scan data, transforms, or time
series data. This is in addition to providing an interface to standard ROS 2
CLI tools ("ros2 bag list" or "ros2 bag info"), as well as the ability to
filter bags with a subset of topics or trimmed in time. Coupled with the MCP
server, we provide a lightweight UI that allows the benchmarking of the tooling
with different LLMs, both proprietary (Anthropic, OpenAI) and open-source
(through Groq). Our experimental results include the analysis of tool calling
capabilities of eight different state-of-the-art LLM/VLM models, both
proprietary and open-source, large and small. Our experiments indicate that
there is a large divide in tool calling capabilities, with Kimi K2 and Claude
Sonnet 4 demonstrating clearly superior performance. We also conclude that
there are multiple factors affecting the success rates, from the tool
description schema to the number of arguments, as well as the number of tools
available to the models. The code is available with a permissive license at
https://github.com/binabik-ai/mcp-rosbags.

</details>


### [26] [Indicating Robot Vision Capabilities with Augmented Reality](https://arxiv.org/abs/2511.03550)
*Hong Wang,Ridhima Phatak,James Ocampo,Zhao Han*

Main category: cs.RO

TL;DR: 研究提出四种AR视野指示器来改善人类对机器人视野能力的心理模型，通过实验评估发现任务空间的分配中心指示器准确率最高，而自我中心的深眼窝设计也能提高准确性。


<details>
  <summary>Details</summary>
Motivation: 人类常错误假设机器人与人类有相同的视野范围，这种不准确的心理模型会导致人机协作失败，特别是当机器人无法扫描场景更新世界模型时。

Method: 提出了四种AR视野指示器，从自我中心（机器人眼睛和头部空间）到分配中心（任务空间），并通过用户实验（N=41）评估其准确性、信心、任务效率和认知负荷。

Result: 分配中心的任务空间方块指示器准确率最高，但解读机器人视野有延迟；自我中心的深眼窝设计也能提高准确性；所有指示器下参与者信心高且认知负荷低。

Conclusion: 贡献了六条实践指南，帮助应用AR指示器或物理改造来使人类心理模型与机器人视觉能力对齐。

Abstract: Research indicates that humans can mistakenly assume that robots and humans
have the same field of view (FoV), possessing an inaccurate mental model of
robots. This misperception may lead to failures during human-robot
collaboration tasks where robots might be asked to complete impossible tasks
about out-of-view objects. The issue is more severe when robots do not have a
chance to scan the scene to update their world model while focusing on assigned
tasks. To help align humans' mental models of robots' vision capabilities, we
propose four FoV indicators in augmented reality (AR) and conducted a user
human-subjects experiment (N=41) to evaluate them in terms of accuracy,
confidence, task efficiency, and workload. These indicators span a spectrum
from egocentric (robot's eye and head space) to allocentric (task space).
Results showed that the allocentric blocks at the task space had the highest
accuracy with a delay in interpreting the robot's FoV. The egocentric indicator
of deeper eye sockets, possible for physical alteration, also increased
accuracy. In all indicators, participants' confidence was high while cognitive
load remained low. Finally, we contribute six guidelines for practitioners to
apply our AR indicators or physical alterations to align humans' mental models
with robots' vision capabilities.

</details>


### [27] [OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera](https://arxiv.org/abs/2511.03571)
*Hao Shi,Ze Wang,Shangwei Guo,Mengfei Duan,Song Wang,Teng Chen,Kailun Yang,Lin Wang,Kaiwei Wang*

Main category: cs.RO

TL;DR: OneOcc是一个专为腿式/人形机器人设计的全景语义场景补全框架，通过双投影融合、双网格体素化、轻量级解码器和步态位移补偿等创新方法，在360度全景语义占用感知方面实现了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语义场景补全系统主要针对轮式机器人设计，无法满足腿式/人形机器人因步态引起的身体抖动和360度连续感知需求。

Method: 结合双投影融合(DP-ER)利用环形全景和等距柱面展开，双网格体素化(BGV)在笛卡尔和柱极坐标系中推理，轻量级解码器实现动态多尺度融合，以及无需额外传感器的步态位移补偿(GDC)。

Result: 在QuadOcc数据集上超越了强大的视觉基线和流行的LiDAR方法；在Human360Occ数据集上分别获得了+3.83 mIoU(同城)和+8.08(跨城)的性能提升。

Conclusion: OneOcc为腿式/人形机器人提供了可部署的全方位感知能力，模块轻量化，在两个新发布的全景占用基准上均实现了最先进性能。

Abstract: Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet most
semantic scene completion (SSC) systems target wheeled platforms with
forward-facing sensors. We present OneOcc, a vision-only panoramic SSC
framework designed for gait-introduced body jitter and 360{\deg} continuity.
OneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annular
panorama and its equirectangular unfolding, preserving 360{\deg} continuity and
grid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian and
cylindrical-polar spaces, reducing discretization bias and sharpening
free/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3D
for dynamic multi-scale fusion and better long-range/occlusion reasoning; and
(iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-level
motion correction without extra sensors. We also release two panoramic
occupancy benchmarks: QuadOcc (real quadruped, first-person 360{\deg}) and
Human360Occ (H3O) (CARLA human-ego 360{\deg} with RGB, Depth, semantic
occupancy; standardized within-/cross-city splits). OneOcc sets new
state-of-the-art (SOTA): on QuadOcc it beats strong vision baselines and
popular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08
(cross-city). Modules are lightweight, enabling deployable full-surround
perception for legged/humanoid robots. Datasets and code will be publicly
available at https://github.com/MasterHow/OneOcc.

</details>


### [28] [Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution](https://arxiv.org/abs/2511.03576)
*Aniol Civit,Antonio Andriella,Carles Sierra,Guillem Alenyà*

Main category: cs.RO

TL;DR: 提出了MUP-QBAF框架，基于定量双极论证框架解决多用户个性化中的偏好冲突问题，特别适用于机器人交互场景。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互个性化方法主要关注单用户适应，忽略了多利益相关者之间可能存在的偏好冲突场景。

Method: 使用定量双极论证框架(QBAFs)，将用户偏好表示为论证，结合机器人对环境动态观察，迭代重新计算论证强度。

Result: 通过辅助机器人在衰弱评估任务中调解护理人员和被护理者冲突偏好的案例研究验证了框架的有效性，并进行了论证基础分数的敏感性分析。

Conclusion: 该工作为多用户人机交互领域提供了透明、结构化且上下文敏感的竞争用户偏好解决方法，是数据驱动方法的原理性替代方案。

Abstract: While personalisation in Human-Robot Interaction (HRI) has advanced
significantly, most existing approaches focus on single-user adaptation,
overlooking scenarios involving multiple stakeholders with potentially
conflicting preferences. To address this, we propose the Multi-User Preferences
Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user
personalisation framework based on Quantitative Bipolar Argumentation
Frameworks (QBAFs) that explicitly models and resolves multi-user preference
conflicts. Unlike prior work in Argumentation Frameworks, which typically
assumes static inputs, our approach is tailored to robotics: it incorporates
both users' arguments and the robot's dynamic observations of the environment,
allowing the system to adapt over time and respond to changing contexts.
Preferences, both positive and negative, are represented as arguments whose
strength is recalculated iteratively based on new information. The framework's
properties and capabilities are presented and validated through a realistic
case study, where an assistive robot mediates between the conflicting
preferences of a caregiver and a care recipient during a frailty assessment
task. This evaluation further includes a sensitivity analysis of argument base
scores, demonstrating how preference outcomes can be shaped by user input and
contextual observations. By offering a transparent, structured, and
context-sensitive approach to resolving competing user preferences, this work
advances the field of multi-user HRI. It provides a principled alternative to
data-driven methods, enabling robots to navigate conflicts in real-world
environments.

</details>


### [29] [Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning](https://arxiv.org/abs/2511.03591)
*Qingyi Chen,Ruiqi Ni,Jun Kim,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了一种流形约束的Hamilton-Jacobi可达性学习框架，用于解决多智能体运动规划中的任务诱导约束问题，使机器人能够在动态环境中生成既安全又满足任务可行性的运动规划。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器人需要在动态环境中导航，同时遵守任务施加的流形约束（如服务机器人必须端平杯子），但现有的去中心化多智能体运动规划方法难以有效整合流形约束。

Method: 通过求解流形约束下的Hamilton-Jacobi可达性问题来捕捉任务感知的安全条件，然后将这些条件集成到去中心化轨迹优化规划器中。

Result: 该方法能够泛化到多种流形约束任务，有效扩展到高维多智能体操作问题，在实验中优于现有约束运动规划器，且运行速度适合实际应用。

Conclusion: 所提出的框架为多智能体运动规划中的流形约束问题提供了有效解决方案，无需对其他智能体的策略做出假设，实现了安全且任务可行的运动规划。

Abstract: Safe multi-agent motion planning (MAMP) under task-induced constraints is a
critical challenge in robotics. Many real-world scenarios require robots to
navigate dynamic environments while adhering to manifold constraints imposed by
tasks. For example, service robots must carry cups upright while avoiding
collisions with humans or other robots. Despite recent advances in
decentralized MAMP for high-dimensional systems, incorporating manifold
constraints remains difficult. To address this, we propose a
manifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for
decentralized MAMP. Our method solves HJR problems under manifold constraints
to capture task-aware safety conditions, which are then integrated into a
decentralized trajectory optimization planner. This enables robots to generate
motion plans that are both safe and task-feasible without requiring assumptions
about other agents' policies. Our approach generalizes across diverse
manifold-constrained tasks and scales effectively to high-dimensional
multi-agent manipulation problems. Experiments show that our method outperforms
existing constrained motion planners and operates at speeds suitable for
real-world applications. Video demonstrations are available at
https://youtu.be/RYcEHMnPTH8 .

</details>


### [30] [Multi-robot searching with limited sensing range for static and mobile intruders](https://arxiv.org/abs/2511.03622)
*Swadhin Agrawal,Sujoy Bhore,Joseph S. B. Mitchell,P. B. Sujit,Aayush Gohil*

Main category: cs.RO

TL;DR: 本文研究了在多机器人系统中搜索几何域内入侵者的问题，针对静态和移动入侵者，证明了该问题是NP难的，并提出了基于空间填充曲线、随机搜索和协作随机搜索的高效鲁棒算法。


<details>
  <summary>Details</summary>
Motivation: 研究多机器人系统在几何域中搜索入侵者的问题，旨在解决传统搜索方法的局限性，提高搜索效率和鲁棒性。

Method: 提出了三种算法：基于空间填充曲线的搜索、随机搜索和协作随机搜索，并分析了机器人数量与搜索时间之间的权衡关系。

Result: 证明了搜索入侵者问题是NP难的，即使对于静态入侵者也是如此；开发的算法在效率和鲁棒性方面表现良好。

Conclusion: 通过多机器人协作和智能搜索策略，可以有效解决几何域中的入侵者搜索问题，但需要在机器人数量和搜索时间之间进行权衡。

Abstract: We consider the problem of searching for an intruder in a geometric domain by
utilizing multiple search robots. The domain is a simply connected orthogonal
polygon with edges parallel to the cartesian coordinate axes. Each robot has a
limited sensing capability. We study the problem for both static and mobile
intruders. It turns out that the problem of finding an intruder is NP-hard,
even for a stationary intruder. Given this intractability, we turn our
attention towards developing efficient and robust algorithms, namely methods
based on space-filling curves, random search, and cooperative random search.
Moreover, for each proposed algorithm, we evaluate the trade-off between the
number of search robots and the time required for the robots to complete the
search process while considering the geometric properties of the connected
orthogonal search area.

</details>


### [31] [Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural](https://arxiv.org/abs/2511.03651)
*Andrei A. Korigodskii,Oleg D. Kalachev,Artem E. Vasiunik,Matvei V. Urvantsev,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 开发了用于绘制世界最大无人机壁画的自主无人机系统，结合红外运动捕捉和LiDAR技术实现精确定位，采用独特控制架构实现精确轨迹跟踪，并设计了防喷漆损坏的喷涂机制。


<details>
  <summary>Details</summary>
Motivation: 解决在恶劣室外条件下（如风、阳光直射）保持艺术精度和操作可靠性的双重挑战，扩展机器人在创意领域的应用。

Method: 结合红外运动捕捉相机和LiDAR的新型导航系统；采用切向和法向不同调节的独特控制架构；轨迹规划和路径优化算法；定制设计的防喷漆损坏的喷涂机制。

Result: 实验结果表明系统在各种条件下都具有鲁棒性和精确性，成功展示了自主大规模艺术创作的潜力。

Conclusion: 该系统为自主大规模艺术创作开辟了新途径，扩展了机器人在创意领域的应用范围，展示了在恶劣室外条件下保持高精度的能力。

Abstract: This paper presents the innovative design and successful deployment of a
pioneering autonomous unmanned aerial system developed for executing the
world's largest mural painted by a drone. Addressing the dual challenges of
maintaining artistic precision and operational reliability under adverse
outdoor conditions such as wind and direct sunlight, our work introduces a
robust system capable of navigating and painting outdoors with unprecedented
accuracy. Key to our approach is a novel navigation system that combines an
infrared (IR) motion capture camera and LiDAR technology, enabling precise
location tracking tailored specifically for largescale artistic applications.
We employ a unique control architecture that uses different regulation in
tangential and normal directions relative to the planned path, enabling precise
trajectory tracking and stable line rendering. We also present algorithms for
trajectory planning and path optimization, allowing for complex curve drawing
and area filling. The system includes a custom-designed paint spraying
mechanism, specifically engineered to function effectively amidst the turbulent
airflow generated by the drone's propellers, which also protects the drone's
critical components from paint-related damage, ensuring longevity and
consistent performance. Experimental results demonstrate the system's
robustness and precision in varied conditions, showcasing its potential for
autonomous large-scale art creation and expanding the functional applications
of robotics in creative fields.

</details>


### [32] [Motion Planning Under Temporal Logic Specifications In Semantically Unknown Environments](https://arxiv.org/abs/2511.03652)
*Azizollah Taheri,Derya Aksaray*

Main category: cs.RO

TL;DR: 提出了一种在不确定环境中处理时空逻辑任务的运动规划方法，使用基于自动机的价值迭代进行在线重规划


<details>
  <summary>Details</summary>
Motivation: 解决在环境语义标签不确定的情况下（如区域位置只有概率信念）实现时空逻辑任务的问题

Method: 构建特殊乘积自动机来捕捉语义标签的不确定性，为自动机边设计奖励函数，使用价值迭代进行在线重规划

Result: 展示了理论结果和仿真实验，证明了所提方法的有效性

Conclusion: 所提出的自动机理论方法能够有效处理不确定环境中的时空逻辑任务规划问题

Abstract: This paper addresses a motion planning problem to achieve
spatio-temporal-logical tasks, expressed by syntactically co-safe linear
temporal logic specifications (scLTL\next), in uncertain environments. Here,
the uncertainty is modeled as some probabilistic knowledge on the semantic
labels of the environment. For example, the task is "first go to region 1, then
go to region 2"; however, the exact locations of regions 1 and 2 are not known
a priori, instead a probabilistic belief is available. We propose a novel
automata-theoretic approach, where a special product automaton is constructed
to capture the uncertainty related to semantic labels, and a reward function is
designed for each edge of this product automaton. The proposed algorithm
utilizes value iteration for online replanning. We show some theoretical
results and present some simulations/experiments to demonstrate the efficacy of
the proposed approach.

</details>


### [33] [Unconscious and Intentional Human Motion Cues for Expressive Robot-Arm Motion Design](https://arxiv.org/abs/2511.03676)
*Taito Tashiro,Tomoko Yonezawa,Hirotake Yamazoe*

Main category: cs.RO

TL;DR: 基于人类动作时序设计机器人手臂表达性运动的研究，发现撤回阶段的运动时机对印象形成很重要，物理实体能增强运动线索的可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用人类运动线索来设计具有表达性的机器人手臂运动，通过分析人类在游戏中的自然和有意动作来指导机器人运动设计。

Method: 使用不完全信息游戏Geister分析人类两种类型的棋子移动动作：自然游戏（无意识倾向）和指令表达（有意线索），基于发现创建阶段特定的机器人运动，通过改变运动速度和停止持续时间，并在物理机器人和录制视频两种呈现方式下评估观察者印象。

Result: 结果表明，晚期运动时机（特别是撤回阶段）在印象形成中起重要作用，物理实体增强了运动线索的可解释性。

Conclusion: 这些发现为基于人类时序行为设计表达性机器人运动提供了见解。

Abstract: This study investigates how human motion cues can be used to design
expressive robot-arm movements. Using the imperfect-information game Geister,
we analyzed two types of human piece-moving motions: natural gameplay
(unconscious tendencies) and instructed expressions (intentional cues). Based
on these findings, we created phase-specific robot motions by varying movement
speed and stop duration, and evaluated observer impressions under two
presentation modalities: a physical robot and a recorded video. Results
indicate that late-phase motion timing, particularly during withdrawal, plays
an important role in impression formation and that physical embodiment enhances
the interpretability of motion cues. These findings provide insights for
designing expressive robot motions based on human timing behavior.

</details>


### [34] [Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping](https://arxiv.org/abs/2511.03691)
*Zhihang Qin,Yueheng Zhang,Wan Su,Linxin Hou,Shenghao Zhou,Zhijun Chen,Yu Jun Tan,Cecilia Laschi*

Main category: cs.RO

TL;DR: 提出了一种自包含的软体夹爪，通过内部液体在三联双稳态腔室间的重分布实现无外部能源的稳定抓取，具有尺寸选择性和刚度适应性。


<details>
  <summary>Details</summary>
Motivation: 传统流体驱动软体夹爪依赖外部能源，限制了便携性和长期自主性。需要开发自包含、无需持续能量输入的软体抓取解决方案。

Method: 设计三个相互连接的双稳态突跳腔室，当顶部传感腔室接触物体变形时，位移液体触发抓取腔室的突跳扩张，实现稳定抓取。内部液压反馈使抓取压力能被动适应物体刚度。

Result: 实现了无需外部能源的稳定尺寸选择性抓取，抓取压力能自适应物体刚度，设计紧凑且自包含。

Conclusion: 这种无源紧凑设计为软体机器人中的轻量化、刚度自适应流体驱动操作开辟了新可能，特别适用于水下和野外环境中的目标尺寸特定采样和操作。

Abstract: Conventional fluid-driven soft grippers typically depend on external sources,
which limit portability and long-term autonomy. This work introduces a
self-contained soft gripper with fixed size that operates solely through
internal liquid redistribution among three interconnected bistable snap-through
chambers. When the top sensing chamber deforms upon contact, the displaced
liquid triggers snap-through expansion of the grasping chambers, enabling
stable and size-selective grasping without continuous energy input. The
internal hydraulic feedback further allows passive adaptation of gripping
pressure to object stiffness. This source-free and compact design opens new
possibilities for lightweight, stiffness-adaptive fluid-driven manipulation in
soft robotics, providing a feasible approach for targeted size-specific
sampling and operation in underwater and field environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [35] [Evaluating Control Protocols for Untrusted AI Agents](https://arxiv.org/abs/2511.02997)
*Jon Kutasov,Chloe Loughridge,Yuqi Sun,Henry Sleight,Buck Shlegeris,Tyler Tracy,Joe Benton*

Main category: cs.AI

TL;DR: 本文系统评估了AI控制协议在SHADE-Arena环境中的安全性，发现关键行动延迟策略在对抗自适应攻击时表现最稳健，而重采样策略在攻击者了解协议内部信息时安全性会大幅下降。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统作为智能体被广泛部署，确保其安全运行变得至关重要。AI控制通过监控AI代理行为并在必要时干预或审计来降低风险，需要评估这些协议在当前攻击下的有效性及其对自适应对手的鲁棒性。

Method: 在SHADE-Arena多样化智能体环境中系统评估控制协议，包括可信模型延迟、重采样和关键行动延迟等蓝队协议，然后针对这些协议迭代开发红队攻击策略。

Result: 重采样和关键行动延迟协议可将安全性从50%提升到96%；但当攻击策略具备额外能力（如知道重采样发生时间或能模拟监控器）时，重采样策略的安全性降至17%；关键行动延迟策略即使面对最强红队策略也保持高度稳健。

Conclusion: 关键行动延迟是高度稳健的控制策略，而重采样策略在攻击者了解协议内部信息时容易受到攻击，表明拒绝攻击策略访问协议内部信息的重要性。

Abstract: As AI systems become more capable and widely deployed as agents, ensuring
their safe operation becomes critical. AI control offers one approach to
mitigating the risk from untrusted AI agents by monitoring their actions and
intervening or auditing when necessary. Evaluating the safety of these
protocols requires understanding both their effectiveness against current
attacks and their robustness to adaptive adversaries. In this work, we
systematically evaluate a range of control protocols in SHADE-Arena, a dataset
of diverse agentic environments. First, we evaluate blue team protocols,
including deferral to trusted models, resampling, and deferring on critical
actions, against a default attack policy. We find that resampling for
incrimination and deferring on critical actions perform best, increasing safety
from 50% to 96%. We then iterate on red team strategies against these protocols
and find that attack policies with additional affordances, such as knowledge of
when resampling occurs or the ability to simulate monitors, can substantially
improve attack success rates against our resampling strategy, decreasing safety
to 17%. However, deferring on critical actions is highly robust to even our
strongest red team strategies, demonstrating the importance of denying attack
policies access to protocol internals.

</details>


### [36] [PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework](https://arxiv.org/abs/2511.03023)
*Sina Montazeri,Yunhe Feng,Kewei Sha*

Main category: cs.AI

TL;DR: PublicAgent是一个多智能体框架，通过将端到端数据分析工作流分解为专门的智能体（意图澄清、数据集发现、分析和报告），解决了LLM在复杂分析任务中的注意力稀释、推理模式干扰和错误传播问题。


<details>
  <summary>Details</summary>
Motivation: 开放数据仓库对非专家难以访问，需要数据集发现、模式映射和统计分析的专业知识。现有LLM在端到端分析工作流中存在注意力稀释、推理模式干扰和错误传播等根本限制。

Method: 采用多智能体框架，将分析流程分解为专门的智能体：意图澄清、数据集发现、分析和报告。这种架构在智能体上下文中保持专注注意力，并在每个阶段实现验证。

Result: 评估5个模型和50个查询得出5个设计原则：1)专业化独立于模型强度提供价值；2)智能体分为通用型（发现、分析）和条件型（报告、意图）；3)智能体缓解不同故障模式；4)架构优势在任务复杂度中持续存在；5)智能体有效性在模型间差异大。

Conclusion: 这些原则指导了何时以及为什么在复杂分析工作流中需要专业化，同时通过自然语言接口实现更广泛的公共数据访问。

Abstract: Open data repositories hold potential for evidence-based decision-making, yet
are inaccessible to non-experts lacking expertise in dataset discovery, schema
mapping, and statistical analysis. Large language models show promise for
individual tasks, but end-to-end analytical workflows expose fundamental
limitations: attention dilutes across growing contexts, specialized reasoning
patterns interfere, and errors propagate undetected. We present PublicAgent, a
multi-agent framework that addresses these limitations through decomposition
into specialized agents for intent clarification, dataset discovery, analysis,
and reporting. This architecture maintains focused attention within agent
contexts and enables validation at each stage. Evaluation across five models
and 50 queries derives five design principles for multi-agent LLM systems.
First, specialization provides value independent of model strength--even the
strongest model shows 97.5% agent win rates, with benefits orthogonal to model
scale. Second, agents divide into universal (discovery, analysis) and
conditional (report, intent) categories. Universal agents show consistent
effectiveness (std dev 12.4%) while conditional agents vary by model (std dev
20.5%). Third, agents mitigate distinct failure modes--removing discovery or
analysis causes catastrophic failures (243-280 instances), while removing
report or intent causes quality degradation. Fourth, architectural benefits
persist across task complexity with stable win rates (86-92% analysis, 84-94%
discovery), indicating workflow management value rather than reasoning
enhancement. Fifth, wide variance in agent effectiveness across models (42-96%
for analysis) requires model-aware architecture design. These principles guide
when and why specialization is necessary for complex analytical workflows while
enabling broader access to public data through natural language interfaces.

</details>


### [37] [No-Human in the Loop: Agentic Evaluation at Scale for Recommendation](https://arxiv.org/abs/2511.03051)
*Tao Zhang,Kehui Yao,Luyi Ma,Jiao Chen,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: ScalingEval是一个大规模基准测试研究，系统比较了36个LLM作为评估者的性能，发现Gemini 1.5 Pro在跨类别表现最佳，GPT-4o在延迟-准确性-成本权衡最优，Claude 3.5 Sonnet决策置信度最高。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型作为评估者对于构建可扩展和可信赖的评估流程越来越重要，需要系统性的基准测试来比较不同LLM的性能。

Method: 使用多智能体框架，通过可扩展的多数投票将模式审计和问题代码聚合成真实标签，无需人工标注即可实现LLM评估者的可重复比较。

Result: 在互补商品推荐任务中，Claude 3.5 Sonnet决策置信度最高；Gemini 1.5 Pro跨类别表现最佳；GPT-4o在延迟-准确性-成本权衡最优；GPT-OSS 20B在开源模型中领先。结构化领域（电子、体育）共识强，生活方式类别（服装、食品）存在持续分歧。

Conclusion: ScalingEval为LLM作为评估者建立了可重复的基准和评估协议，提供了关于扩展性、可靠性和模型系列权衡的可操作指导。

Abstract: Evaluating large language models (LLMs) as judges is increasingly critical
for building scalable and trustworthy evaluation pipelines. We present
ScalingEval, a large-scale benchmarking study that systematically compares 36
LLMs, including GPT, Gemini, Claude, and Llama, across multiple product
categories using a consensus-driven evaluation protocol. Our multi-agent
framework aggregates pattern audits and issue codes into ground-truth labels
via scalable majority voting, enabling reproducible comparison of LLM
evaluators without human annotation. Applied to large-scale complementary-item
recommendation, the benchmark reports four key findings: (i) Anthropic Claude
3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers
the best overall performance across categories; (iii) GPT-4o provides the most
favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among
open-source models. Category-level analysis shows strong consensus in
structured domains (Electronics, Sports) but persistent disagreement in
lifestyle categories (Clothing, Food). These results establish ScalingEval as a
reproducible benchmark and evaluation protocol for LLMs as judges, with
actionable guidance on scaling, reliability, and model family tradeoffs.

</details>


### [38] [Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge](https://arxiv.org/abs/2511.03070)
*Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim*

Main category: cs.AI

TL;DR: 构建首个基准测试来评估LLMs是否内化了现实世界概率分布知识，结果显示LLMs在理解现实世界统计分布方面表现不佳，且缺乏因果层次中的观测分布知识。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然取得显著进展，但在实现更通用智能方面仍需提升能力。关键区别在于事实性知识和概率性知识，LLMs被宣传为现实世界分布的强大通用逼近器，但统计学中的维度灾难理论对高维分布学习提出了根本性挑战。

Method: 开发首个基准测试，直接验证LLMs是否能够获取描述现实世界人口的经验分布，涵盖经济、健康、教育和社会行为等多个领域。

Result: LLMs整体表现不佳，似乎无法自然地内化现实世界统计数据。在Pearl因果层次框架下，语言模型缺乏观测分布知识。

Conclusion: LLMs在获取现实世界概率分布知识方面存在根本性限制，根据因果层次定理，这意味着它们在干预性和反事实性知识方面也受到限制。

Abstract: Artificial intelligence (AI) systems hold great promise for advancing various
scientific disciplines, and are increasingly used in real-world applications.
Despite their remarkable progress, further capabilities are expected in order
to achieve more general types of intelligence. A critical distinction in this
context is between factual knowledge, which can be evaluated against true or
false answers (e.g., "what is the capital of England?"), and probabilistic
knowledge, reflecting probabilistic properties of the real world (e.g., "what
is the sex of a computer science graduate in the US?"). In this paper, our goal
is to build a benchmark for understanding the capabilities of LLMs in terms of
knowledge of probability distributions describing the real world. Given that
LLMs are trained on vast amounts of text, it may be plausible that they
internalize aspects of these distributions. Indeed, LLMs are touted as powerful
universal approximators of real-world distributions. At the same time,
classical results in statistics, known as curse of dimensionality, highlight
fundamental challenges in learning distributions in high dimensions,
challenging the notion of universal distributional learning. In this work, we
develop the first benchmark to directly test this hypothesis, evaluating
whether LLMs have access to empirical distributions describing real-world
populations across domains such as economics, health, education, and social
behavior. Our results demonstrate that LLMs perform poorly overall, and do not
seem to internalize real-world statistics naturally. When interpreted in the
context of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that
language models do not contain knowledge on observational distributions (Layer
1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional
(Layer 2) and counterfactual (Layer 3) knowledge of these models is also
limited.

</details>


### [39] [SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators](https://arxiv.org/abs/2511.03092)
*Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar*

Main category: cs.AI

TL;DR: SnapStream是一种KV缓存压缩方法，可在保持模型精度的同时减少4倍片上内存使用，并已在生产环境中部署验证。


<details>
  <summary>Details</summary>
Motivation: 随着100B+参数大语言模型和100k+上下文长度的普及，对片上内存的需求激增。现有KV缓存压缩技术难以在工业部署框架中应用，且对现代指令跟随和推理模型的精度影响不明确。

Method: 开发SnapStream KV缓存压缩方法，在Llama-3.1-8B-Instruct和DeepSeek-R1上探索精度影响，并在16路张量并行部署的DeepSeek-671B上进行验证。

Result: 在128k上下文长度下实现每秒1832个token的处理速度，片上内存使用减少4倍，在LongBench-v2、AIME24和LiveCodeBench上精度损失最小。

Conclusion: SnapStream是首个在具有静态图和连续批处理的生产推理系统中部署的稀疏KV注意力技术，实现了高效的内存使用和可接受的精度损失。

Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+
context length support have resulted in increasing demands for on-chip memory
to support large KV caches. Techniques such as StreamingLLM and SnapKV
demonstrate how to control KV cache size while maintaining model accuracy. Yet,
these techniques are not commonly used within industrial deployments using
frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static
graphs and continuous batching methodology employed by these frameworks make it
difficult to admit modifications to the standard multi-head attention
algorithm, while on the other hand, the accuracy implications of such
techniques on modern instruction-following and reasoning models are not well
understood, obfuscating the need for implementing these techniques. In this
paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and
DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be
deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way
tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators
running at 128k context length and up to 1832 tokens per second in a real
production setting. SnapStream enables $4\times$ improved on-chip memory usage
and introduces minimal accuracy degradation on LongBench-v2, AIME24 and
LiveCodeBench. To the best of our knowledge, this is the first implementation
of sparse KV attention techniques deployed in a production inference system
with static graphs and continuous batching.

</details>


### [40] [Large language models require a new form of oversight: capability-based monitoring](https://arxiv.org/abs/2511.03106)
*Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman*

Main category: cs.AI

TL;DR: 提出基于能力的监控方法，替代传统的基于任务的监控，用于医疗领域大语言模型的监督。


<details>
  <summary>Details</summary>
Motivation: 传统基于任务的监控方法不适用于大语言模型，因为LLMs不是为特定任务或人群训练的，无法假设性能退化源于数据集漂移。

Method: 基于能力的监控围绕共享模型能力（如摘要、推理、翻译、安全护栏）组织监控，实现跨任务检测系统性弱点、长尾错误和涌现行为。

Result: 该方法为医疗领域LLMs提供可扩展的监控基础，能够检测任务监控可能遗漏的问题。

Conclusion: 基于能力的监控为医疗领域LLMs和未来通用AI模型提供安全、自适应和协作监控的可扩展基础。

Abstract: The rapid adoption of large language models (LLMs) in healthcare has been
accompanied by scrutiny of their oversight. Existing monitoring approaches,
inherited from traditional machine learning (ML), are task-based and founded on
assumed performance degradation arising from dataset drift. In contrast, with
LLMs, inevitable model degradation due to changes in populations compared to
the training dataset cannot be assumed, because LLMs were not trained for any
specific task in any given population. We therefore propose a new organizing
principle guiding generalist LLM monitoring that is scalable and grounded in
how these models are developed and used in practice: capability-based
monitoring. Capability-based monitoring is motivated by the fact that LLMs are
generalist systems whose overlapping internal capabilities are reused across
numerous downstream tasks. Instead of evaluating each downstream task
independently, this approach organizes monitoring around shared model
capabilities, such as summarization, reasoning, translation, or safety
guardrails, in order to enable cross-task detection of systemic weaknesses,
long-tail errors, and emergent behaviors that task-based monitoring may miss.
We describe considerations for developers, organizational leaders, and
professional societies for implementing a capability-based monitoring approach.
Ultimately, capability-based monitoring will provide a scalable foundation for
safe, adaptive, and collaborative monitoring of LLMs and future generalist
artificial intelligence models in healthcare.

</details>


### [41] [miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward](https://arxiv.org/abs/2511.03108)
*Azim Ospanov,Farzan Farnia,Roozbeh Yousefzadeh*

Main category: cs.AI

TL;DR: 该论文分析了miniF2F基准测试中形式化与非形式化陈述之间的差异，发现超过一半的问题存在不一致性。通过修正这些错误，创建了miniF2F-v2数据集，将完整定理证明流程的准确率从40%提升到70%。


<details>
  <summary>Details</summary>
Motivation: 评估AI系统在数学奥林匹克竞赛环境中的表现，特别是从自然语言理解到形式化证明的完整流程，发现现有基准测试存在严重的形式化与非形式化陈述不一致问题。

Method: 对miniF2F基准进行全面分析，识别形式化与非形式化陈述之间的差异，修正所有错误和简化，创建miniF2F-v2数据集，并在修正后的数据集上重新评估完整的定理证明流程。

Result: 在原始miniF2F上，完整定理证明流程的最佳准确率约为36%，远低于文献中报告的自动形式化(97%)和定理证明(69%)的单独准确率。在修正后的miniF2F-v2上，准确率提升至70%。

Conclusion: 高质量的基准测试对于评估形式推理领域的进展至关重要，能够更好地诊断自动形式化和定理证明模型的失败与成功模式。miniF2F-v2数据集为社区提供了更可靠的评估工具。

Abstract: We perform a thorough analysis of the formal and informal statements in the
miniF2F benchmark from the perspective of an AI system that is tasked to
participate in a math Olympiad consisting of the problems in miniF2F. In such
setting, the model has to read and comprehend the problems in natural language,
formalize them in Lean language, then proceed with proving the problems, and it
will get credit for each problem if the formal proof corresponds to the
original informal statement presented to the model. Our evaluation results
reveal that the best accuracy of such pipeline can be about 36% using the SoTA
models in the literature, considerably lower than the individual SoTA
accuracies, 97% and 69% reported in the autoformalization and theorem proving
literature. Analyzing the failure modes, we trace back a considerable portion
of this drop to discrepancies between the formal and informal statements for
more than half of the problems in miniF2F. We proceed with correcting all the
errors, discrepancies and simplifications in formal and informal statements,
and present the miniF2F-v2 with fully verified formal and informal statements
and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to
the best accuracy of 70%, a significant improvement from the 40% on the
original miniF2F, yet indicating considerable misalignment between the
autoformalization models and theorem provers. Our deep analysis suggests that a
higher quality benchmark can help the community better evaluate progress in the
field of formal reasoning and also better diagnose the failure and success
modes of autoformalization and theorem proving models. Our dataset is available
at https://github.com/roozbeh-yz/miniF2F_v2.

</details>


### [42] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 提出了一种利用多模态大语言模型辅助设计烟花算法的新框架，通过引入关键部分概念扩展FWA到复杂高维任务，在TSP和EDA问题上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在处理非凸、高维、黑盒等复杂优化问题时效率低下，而大语言模型在语言理解和代码生成方面的进步为优化算法设计提供了新思路。

Method: 以烟花算法为基础优化器，结合多模态大语言模型，提出关键部分概念来扩展FWA处理复杂高维任务，并利用大语言模型的多模态特性充分利用优化过程中的信息。

Result: 在旅行商问题和电子设计自动化问题上的实验结果表明，新框架下生成的烟花算法在许多问题实例上达到或超越了当前最优结果。

Conclusion: 将大语言模型与优化算法结合是解决复杂优化问题的有效途径，证明了多模态大语言模型在辅助优化算法设计方面的潜力。

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [43] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的LLM安全响应框架，通过输入级安全分类和输出级RAG增强，实现99.3%的风险召回率和100%的高风险场景安全得分。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，其安全问题日益突出，严重制约了在关键领域的可信部署，需要系统化的安全保障方案。

Method: 输入级采用监督微调的四级分类模型（安全、不安全、条件安全、聚焦注意），输出级结合RAG和微调的解释模型，确保响应基于可信知识库。

Result: 在公共安全评估基准上显著优于基线模型TinyR1-Safety-8B，在专有高风险测试集上组件获得100%安全得分，风险召回率达到99.3%。

Conclusion: 该研究为构建高安全性、高可信度的LLM应用提供了有效的工程路径，验证了框架在复杂风险场景下的卓越保护能力。

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [44] [Uncovering Bugs in Formal Explainers: A Case Study with PyXAI](https://arxiv.org/abs/2511.03169)
*Xuanxiang Huang,Yacine Izza,Alexey Ignatiev,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了一种验证形式化可解释AI工具的新方法，并在PyXAI工具上发现了计算错误解释的问题。


<details>
  <summary>Details</summary>
Motivation: 形式化可解释AI相比非形式化方法具有理论严谨性保证，但实际实现验证研究不足，需要开发验证方法来确保工具可靠性。

Method: 开发了一种新颖的验证形式化解释器的方法论，并对公开可用的PyXAI解释器进行了评估。

Result: 实验发现在大多数分析的数据集上，PyXAI计算出的解释存在错误，证实了验证方法的重要性。

Conclusion: 形式化解释器的实际实现需要严格验证，提出的验证方法对确保可解释AI工具的可靠性至关重要。

Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical
guarantees of rigor when compared to other non-formal methods of
explainability. However, little attention has been given to the validation of
practical implementations of formal explainers. This paper develops a novel
methodology for validating formal explainers and reports on the assessment of
the publicly available formal explainer PyXAI. The paper documents the
existence of incorrect explanations computed by PyXAI on most of the datasets
analyzed in the experiments, thereby confirming the importance of the proposed
novel methodology for the validation of formal explainers.

</details>


### [45] [Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework](https://arxiv.org/abs/2511.03179)
*Varun Kumar,George Em Karniadakis*

Main category: cs.AI

TL;DR: 提出了一个多智能体AI框架来形式化工程设计过程，通过专业智能体协作生成和优化设计，并以NACA翼型气动优化为例验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统工程设计方法需要多领域专业知识，存在资源密集和效率低下的问题，需要更高效的协作设计框架。

Method: 构建包含三个AI智能体的框架：图本体学家（构建领域知识图谱）、系统工程师（制定技术需求）、设计工程师（生成候选设计），通过迭代反馈循环优化设计。

Result: 成功应用于4位数NACA翼型的气动优化，最终设计通过最大化升阻比等性能指标验证了框架的有效性。

Conclusion: 配备结构化知识表示的协作AI智能体能够显著提高工程设计过程的效率、一致性和质量。

Abstract: The engineering design process often demands expertise from multiple domains,
leading to complex collaborations and iterative refinements. Traditional
methods can be resource-intensive and prone to inefficiencies. To address this,
we formalize the engineering design process through a multi-agent AI framework
that integrates structured design and review loops. The framework introduces
specialized knowledge-driven agents that collaborate to generate and refine
design candidates. As an exemplar, we demonstrate its application to the
aerodynamic optimization of 4-digit NACA airfoils. The framework consists of
three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems
Engineer. The Graph Ontologist employs a Large Language Model (LLM) to
construct two domain-specific knowledge graphs from airfoil design literature.
The Systems Engineer, informed by a human manager, formulates technical
requirements that guide design generation and evaluation. The Design Engineer
leverages the design knowledge graph and computational tools to propose
candidate airfoils meeting these requirements. The Systems Engineer reviews and
provides feedback both qualitative and quantitative using its own knowledge
graph, forming an iterative feedback loop until a design is validated by the
manager. The final design is then optimized to maximize performance metrics
such as the lift-to-drag ratio. Overall, this work demonstrates how
collaborative AI agents equipped with structured knowledge representations can
enhance efficiency, consistency, and quality in the engineering design process.

</details>


### [46] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: 本文介绍了Summit Concierge，一个为Adobe Summit开发的领域特定AI助手，采用人在环路的开发工作流，结合提示工程、检索基础和轻量级人工验证来解决数据稀疏、质量保证和快速部署等现实约束。


<details>
  <summary>Details</summary>
Motivation: 生成式AI助手在企业环境中具有提升生产力、简化信息访问和改善用户体验的潜力，但面临数据稀疏、质量保证和快速部署等现实约束。

Method: 采用人在环路的开发工作流，结合提示工程、检索基础和轻量级人工验证，构建了系统架构和开发流程。

Result: 成功开发并部署了Summit Concierge助手，能够处理广泛的活动相关查询，在冷启动场景下实现了可扩展和可靠的AI助手。

Conclusion: 敏捷、反馈驱动的开发方法能够在冷启动场景下实现可扩展和可靠的AI助手。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


### [47] [From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers](https://arxiv.org/abs/2511.03235)
*Yi-Fei Liu,Yi-Long Lu,Di He,Hang Zhang*

Main category: cs.AI

TL;DR: 大型语言模型能够仅从大五人格量表数据中准确预测人类心理特质的相关结构，通过两阶段推理过程实现零样本性能，接近机器学习算法的准确度。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能够从最小定量输入中建模人类心理特质的关联结构，探索其推理能力和心理模拟潜力。

Method: 使用816名人类的大五人格量表数据提示各种LLMs，让它们模拟在其他9个心理量表上的反应，分析推理轨迹和两阶段处理过程。

Result: LLMs生成的反应与人类数据的量表间相关模式高度一致（R² > 0.89），性能远超基于语义相似性的预测，接近直接训练算法的准确度。

Conclusion: LLMs通过抽象和推理过程能够精确预测个体心理特质，为心理模拟提供了强大工具，并揭示了其涌现的推理能力。

Abstract: Psychological constructs within individuals are widely believed to be
interconnected. We investigated whether and how Large Language Models (LLMs)
can model the correlational structure of human psychological traits from
minimal quantitative inputs. We prompted various LLMs with Big Five Personality
Scale responses from 816 human individuals to role-play their responses on nine
other psychological scales. LLMs demonstrated remarkable accuracy in capturing
human psychological structure, with the inter-scale correlation patterns from
LLM-generated responses strongly aligning with those from human data $(R^2 >
0.89)$. This zero-shot performance substantially exceeded predictions based on
semantic similarity and approached the accuracy of machine learning algorithms
trained directly on the dataset. Analysis of reasoning traces revealed that
LLMs use a systematic two-stage process: First, they transform raw Big Five
responses into natural language personality summaries through information
selection and compression, analogous to generating sufficient statistics.
Second, they generate target scale responses based on reasoning from these
summaries. For information selection, LLMs identify the same key personality
factors as trained algorithms, though they fail to differentiate item
importance within factors. The resulting compressed summaries are not merely
redundant representations but capture synergistic information--adding them to
original scores enhances prediction alignment, suggesting they encode emergent,
second-order patterns of trait interplay. Our findings demonstrate that LLMs
can precisely predict individual participants' psychological traits from
minimal data through a process of abstraction and reasoning, offering both a
powerful tool for psychological simulation and valuable insights into their
emergent reasoning capabilities.

</details>


### [48] [Towards Scalable Web Accessibility Audit with MLLMs as Copilots](https://arxiv.org/abs/2511.03471)
*Ming Gu,Ziwei Wang,Sicen Lai,Zirui Gao,Sheng Zhou,Jiajun Bu*

Main category: cs.AI

TL;DR: 提出了一个名为AAA的自动化Web可访问性审计框架，通过人机协作模式实现WCAG-EM标准的大规模执行，包含GRASP采样方法和MaC智能助手两个核心创新。


<details>
  <summary>Details</summary>
Motivation: 当前网站可访问性审计方法资源密集且难以规模化，大多数网站界面不符合标准，阻碍了数字空间的社会福利、正义和平等发展。

Method: AAA框架包含：GRASP基于图的多模态采样方法，通过学习视觉、文本和关系线索的嵌入确保代表性页面覆盖；MaC多模态大语言模型助手，通过跨模态推理为审计员提供智能辅助。

Result: 实验证明该方法有效，提供了四个新的基准数据集，并发现小规模语言模型经过微调后也能成为专家系统。

Conclusion: 该框架实现了可扩展的端到端Web可访问性审计，通过AI增强辅助为现实世界影响赋能。

Abstract: Ensuring web accessibility is crucial for advancing social welfare, justice,
and equality in digital spaces, yet the vast majority of website user
interfaces remain non-compliant, due in part to the resource-intensive and
unscalable nature of current auditing practices. While WCAG-EM offers a
structured methodology for site-wise conformance evaluation, it involves great
human efforts and lacks practical support for execution at scale. In this work,
we present an auditing framework, AAA, which operationalizes WCAG-EM through a
human-AI partnership model. AAA is anchored by two key innovations: GRASP, a
graph-based multimodal sampling method that ensures representative page
coverage via learned embeddings of visual, textual, and relational cues; and
MaC, a multimodal large language model-based copilot that supports auditors
through cross-modal reasoning and intelligent assistance in high-effort tasks.
Together, these components enable scalable, end-to-end web accessibility
auditing, empowering human auditors with AI-enhanced assistance for real-world
impact. We further contribute four novel datasets designed for benchmarking
core stages of the audit pipeline. Extensive experiments demonstrate the
effectiveness of our methods, providing insights that small-scale language
models can serve as capable experts when fine-tuned.

</details>


### [49] [Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)](https://arxiv.org/abs/2511.03545)
*Sebastian Ordyniak,Giacomo Paesani,Mateusz Rychlicki,Stefan Szeider*

Main category: cs.AI

TL;DR: 对多种机器学习模型的解释问题进行参数化复杂度分析，包括决策树、决策集、决策列表、布尔电路等，涵盖溯因和对比两种解释类型。


<details>
  <summary>Details</summary>
Motivation: 填补可解释AI领域的理论空白，为透明机器学习模型的解释问题提供复杂性理论基础，促进AI系统的透明度和问责制。

Method: 采用参数化复杂度理论框架，分析不同ML模型的解释问题，包括本地和全局的溯因与对比解释。

Result: 建立了各种ML模型解释问题的复杂性理论框架，揭示了不同模型解释任务的复杂度特征。

Conclusion: 为可解释AI提供了重要的理论基础，有助于指导未来XAI研究，强调透明AI系统的必要性。

Abstract: This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,
each offering unique explanatory challenges. This research fills a significant
gap in explainable AI (XAI) by providing a foundational understanding of the
complexities of generating explanations for these models. This work provides
insights vital for further research in the domain of XAI, contributing to the
broader discourse on the necessity of transparency and accountability in AI
systems.

</details>


### [50] [Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning](https://arxiv.org/abs/2511.03724)
*Richard Dewey,Janos Botyanszki,Ciamac C. Moallemi,Andrew T. Zheng*

Main category: cs.AI

TL;DR: Solly是首个在简化版Liar's Poker中达到精英人类水平的AI智能体，通过自对弈和深度强化学习训练，在多人和单挑模式下均表现优异，胜率超过50%，并超越了大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 虽然AI在德州扑克等游戏中已取得突破，但这些游戏的多玩家动态较弱。Liar's Poker具有更丰富的多玩家互动，是测试AI在不确定性和不完美信息下推理能力的更好测试平台。

Method: 使用无模型、演员-评论家深度强化学习算法进行自对弈训练。

Result: Solly在单挑和多玩家Liar's Poker中均达到精英人类水平，胜率超过50%，在资金收益上表现优异，超越了具有推理能力的大型语言模型。

Conclusion: Solly证明了深度强化学习可以在复杂的多玩家不完全信息游戏中达到精英人类水平，并开发了新颖的投标策略和有效的随机化玩法。

Abstract: AI researchers have long focused on poker-like games as a testbed for
environments characterized by multi-player dynamics, imperfect information, and
reasoning under uncertainty. While recent breakthroughs have matched elite
human play at no-limit Texas hold'em, the multi-player dynamics are subdued:
most hands converge quickly with only two players engaged through multiple
rounds of bidding. In this paper, we present Solly, the first AI agent to
achieve elite human play in reduced-format Liar's Poker, a game characterized
by extensive multi-player engagement. We trained Solly using self-play with a
model-free, actor-critic, deep reinforcement learning algorithm. Solly played
at an elite human level as measured by win rate (won over 50% of hands) and
equity (money won) in heads-up and multi-player Liar's Poker. Solly also
outperformed large language models (LLMs), including those with reasoning
abilities, on the same metrics. Solly developed novel bidding strategies,
randomized play effectively, and was not easily exploitable by world-class
human players.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [51] [Inferential Theory for Pricing Errors with Latent Factors and Firm Characteristics](https://arxiv.org/abs/2511.03076)
*Jungjun Choi,Ming Yuan*

Main category: econ.EM

TL;DR: 提出一个新的因子模型框架，将潜在因子与公司特征结合，将错误定价分解为内部alpha和外部alpha两个独立成分，解决了正交性、基依赖和单位敏感性等问题。


<details>
  <summary>Details</summary>
Motivation: 统一统计方法和基于特征的因子建模方法，解决现有模型在正交性、基依赖和单位敏感性方面的限制，提供更完善的错误定价分析框架。

Method: 基于低秩方法的估计器，采用显式去偏技术，提供闭式解和严格的推断理论，支持特征数量增长并放宽样本维度标准假设。

Result: 使用2000-2019年美国股票收益数据，发现内部alpha和外部alpha均存在显著证据，内部alpha呈现行业层面的共同运动，外部alpha反映超越公司基本面的异质性冲击。

Conclusion: 该框架统一了统计和基于特征的方法，在因子建模方面提供理论进展，并对错误定价结构提供新的见解。

Abstract: We study factor models that combine latent factors with firm characteristics
and propose a new framework for modeling, estimating, and inferring pricing
errors. Following Zhang (2024), our approach decomposes mispricing into two
distinct components: inside alpha, explained by firm characteristics but
orthogonal to factor exposures, and outside alpha, orthogonal to both factors
and characteristics. Our model generalizes those developed recently such as
Kelly et al. (2019) and Zhang (2024), resolving issues of orthogonality, basis
dependence, and unit sensitivity. Methodologically, we develop estimators
grounded in low-rank methods with explicit debiasing, providing closed-form
solutions and a rigorous inferential theory that accommodates a growing number
of characteristics and relaxes standard assumptions on sample dimensions.
Empirically, using U.S. stock returns from 2000-2019, we document strong
evidence of both inside and outside alphas, with the former showing
industry-level co-movements and the latter reflecting idiosyncratic shocks
beyond firm fundamentals. Our framework thus unifies statistical and
characteristic-based approaches to factor modeling, offering both theoretical
advances and new insights into the structure of pricing errors.

</details>


### [52] [The Economics of Spatial Coordination in Critical Infrastructure Investment](https://arxiv.org/abs/2511.03091)
*L Kaili Diamond,Benjamin Gilbert*

Main category: econ.EM

TL;DR: 开发了一种混合方法，结合嵌套固定点动态规划和模拟矩估计法，用于估计结构动态离散选择模型中的空间协调机制，并在Titan超级计算机的GPU替换数据中识别出两种协调机制。


<details>
  <summary>Details</summary>
Motivation: 解决在空间环境中估计结构动态离散选择模型时的计算难题，同时保持结构解释能力，以理解基础设施管理中的空间协调行为。

Method: 结合嵌套固定点(NFXP)动态规划和模拟矩估计法(MSM)的混合方法，应用于12,915个设备位置的GPU替换数据。

Result: 识别出两种空间协调机制：顺序替换级联(γ_lag = -0.793)和同时故障批处理(γ_fail = -0.265)，顺序协调强度约为故障批处理的3倍，空间相互依赖性解释了独立决策模型未解释的5.3%变异。

Conclusion: 空间协调在基础设施管理中具有显著重要性，忽略空间协调的政策会系统性地错误安排干预时机并丧失可用的协调收益。

Abstract: We develop a hybrid approach to estimate spatial coordination mechanisms in
structural dynamic discrete choice models by combining nested fixed-point
(NFXP) dynamic programming with method of simulated moments (MSM), achieving
computational tractability in spatial settings while preserving structural
interpretation. Applying this framework to GPU replacement data from 12,915
equipment locations in Oak Ridge National Laboratory's Titan supercomputer, we
identify two distinct coordination mechanisms: sequential replacement cascades
(gamma_lag = -0.793) and contemporaneous failure batching (gamma_fail =
-0.265). Sequential coordination dominates - approximately three times stronger
than failure batching - indicating that operators engage in deliberate
strategic behavior rather than purely reactive responses. Spatial
interdependencies account for 5.3% of variation unexplained by
independent-decision models, with coordination concentrated in high-risk
thermal environments exhibiting effects more than 10 times stronger than cool
zones. Formal tests decisively reject spatial independence (chi-squared(2) =
685.38, p < 0.001), demonstrating that infrastructure policies ignoring spatial
coordination will systematically mistime interventions and forgo available
coordination gains.

</details>


### [53] [Large Bayesian Tensor Autoregressions](https://arxiv.org/abs/2511.03097)
*Yaling Qi*

Main category: econ.EM

TL;DR: 提出了一个贝叶斯张量自回归框架，用于分析多维时间序列数据，特别关注国际贸易中的国家间和部门间动态，并引入了随机波动性来捕捉时变波动。


<details>
  <summary>Details</summary>
Motivation: 随着多维经济数据集的增长，特别是包含进口国、出口国和商品三个维度的双边贸易数据，需要新的方法来分析这种高阶张量时间序列的动态特性。

Method: 开发了基于低秩Tucker分解和分层收缩先验的高效采样方法，将灵活随机波动性纳入张量自回归模型，以解决计算挑战和过拟合问题。

Result: 模型能够捕捉COVID-19大流行和近期战争爆发导致的时变波动性，并通过Tucker分解将高维贸易流投影到全球因子上。

Conclusion: 提出的贝叶斯张量自回归框架为分析大型多维时间序列提供了一种有效方法，特别适用于国际贸易数据的动态建模和波动性分析。

Abstract: The availability of multidimensional economic datasets has grown
significantly in recent years. An example is bilateral trade values across
goods among countries, comprising three dimensions -- importing countries,
exporting countries, and goods -- forming a third-order tensor time series.
This paper introduces a general Bayesian tensor autoregressive framework to
analyze the dynamics of large, multidimensional time series with a particular
focus on international trade across different countries and sectors. Departing
from the standard homoscedastic assumption in this literature, we incorporate
flexible stochastic volatility into the tensor autoregressive models. The
proposed models can capture time-varying volatility due to the COVID-19
pandemic and recent outbreaks of war. To address computational challenges and
mitigate overfitting, we develop an efficient sampling method based on low-rank
Tucker decomposition and hierarchical shrinkage priors. Additionally, we
provide a factor interpretation of the model showing how the Tucker
decomposition projects large-dimensional disaggregated trade flows onto global
factors.

</details>


### [54] [Unbiased Regression-Adjusted Estimation of Average Treatment Effects in Randomized Controlled Trials](https://arxiv.org/abs/2511.03236)
*Alberto Abadie,Mehrdad Ghadiri,Ali Jadbabaie,Mahyar JafariNodeh*

Main category: econ.EM

TL;DR: 提出LOORA方法消除传统回归调整的有限样本偏差，提供精确方差表达式，通过岭正则化提高小样本稳定性，在大样本中保持无偏性并达到渐近效率


<details>
  <summary>Details</summary>
Motivation: 传统回归调整方法在随机对照试验中存在有限样本偏差，需要开发无偏且高效的估计方法

Method: 使用留一法回归调整估计器(LOORA)，结合岭正则化限制高杠杆观测值的影响，构建置信区间时采用两阶段程序考虑回归调整和随机分配

Result: LOORA消除了显著偏差，在真实联合分布数据中实现了接近名义水平的置信区间覆盖

Conclusion: LOORA方法在保持无偏性的同时提高了估计精度，为随机对照试验中的平均处理效应估计提供了可靠工具

Abstract: This article introduces a leave-one-out regression adjustment estimator
(LOORA) for estimating average treatment effects in randomized controlled
trials. The method removes the finite-sample bias of conventional regression
adjustment and provides exact variance expressions for LOORA versions of the
Horvitz-Thompson and difference-in-means estimators under simple and complete
random assignment. Ridge regularization limits the influence of high-leverage
observations, improving stability and precision in small samples. In large
samples, LOORA attains the asymptotic efficiency of regression-adjusted
estimator as characterized by Lin (2013, Annals of Applied Statistics), while
remaining exactly unbiased. To construct confidence intervals, we rely on
asymptotic variance estimates that treat the estimator as a two-step procedure,
accounting for both the regression adjustment and the random assignment stages.
Two within-subject experimental applications that provide realistic joint
distributions of potential outcomes as ground truth show that LOORA eliminates
substantial biases and achieves close-to-nominal confidence interval coverage.

</details>


### [55] [Using spatial modeling to address covariate measurement error](https://arxiv.org/abs/2511.03306)
*Susanne M. Schennach,Vincent Starck*

Main category: econ.EM

TL;DR: 提出一种利用空间数据解决协变量测量误差的新估计方法，该方法使用邻近观测作为重复测量，通过控制观测间的随机距离来建立识别条件


<details>
  <summary>Details</summary>
Motivation: 解决协变量测量误差问题，特别是在非线性模型和非经典误差情况下，不依赖变量分布的先验假设

Method: 结合筛半参数最大似然估计、第一步核估计和模拟方法，利用邻近观测作为重复测量，通过算子对角化方法建立识别条件

Result: 通过受控模拟和应用案例验证了方法的有效性，应用于评估前殖民时期政治结构对非洲当前经济发展的影响

Conclusion: 该方法为处理协变量测量误差提供了一种有效的空间数据利用途径，适用于一般非线性模型和非经典误差情况

Abstract: We propose a new estimation methodology to address the presence of covariate
measurement error by exploiting the availability of spatial data. The approach
uses neighboring observations as repeated measurements, after suitably
controlling for the random distance between the observations in a way that
allows the use of operator diagonalization methods to establish identification.
The method is applicable to general nonlinear models with potentially
nonclassical errors and does not rely on a priori distributional assumptions
regarding any of the variables. The method's implementation combines a sieve
semiparametric maximum likelihood with a first-step kernel estimator and
simulation methods. The method's effectiveness is illustrated through both
controlled simulations and an application to the assessment of the effect of
pre-colonial political structure on current economic development in Africa.

</details>


### [56] [Multivariate Ordered Discrete Response Models with Lattice Structures](https://arxiv.org/abs/2511.03418)
*Tatiana Komarova,William Matcham*

Main category: econ.EM

TL;DR: 本文分析了具有格结构的多元有序离散响应模型，研究跨多个维度进行窄框架选择的决策者行为，在参数化和半参数化框架下推导识别条件并开发估计方法。


<details>
  <summary>Details</summary>
Motivation: 研究决策者在多个维度上采用窄框架选择策略的行为模式，这类模型能够更好地描述现实世界中复杂的多维度离散选择问题。

Method: 使用格结构建模多元有序离散响应，将潜在连续过程通过功能独立的决策阈值映射为离散响应。在半参数框架下建模为协变量指数和未观测误差的和，推导参数、阈值和误差联合分布的识别条件。

Result: 推导了参数化和半参数化模型的识别条件，对于二元probit情况分别识别回归参数、阈值和相关参数，后者需要额外的协变量条件。开发了相应的估计方法并通过模拟验证了估计器的性能。

Conclusion: 提出的格结构模型能够有效分析多维度窄框架选择行为，识别条件和估计方法为实证研究提供了理论基础和实用工具。

Abstract: We analyze multivariate ordered discrete response models with a lattice
structure, modeling decision makers who narrowly bracket choices across
multiple dimensions. These models map latent continuous processes into discrete
responses using functionally independent decision thresholds. In a
semiparametric framework, we model latent processes as sums of covariate
indices and unobserved errors, deriving conditions for identifying parameters,
thresholds, and the joint cumulative distribution function of errors. For the
parametric bivariate probit case, we separately derive identification of
regression parameters and thresholds, and the correlation parameter, with the
latter requiring additional covariate conditions. We outline estimation
approaches for semiparametric and parametric models and present simulations
illustrating the performance of estimators for lattice models.

</details>


### [57] [The moment is here: a generalised class of estimators for fuzzy regression discontinuity designs](https://arxiv.org/abs/2511.03424)
*Stuart Lane*

Main category: econ.EM

TL;DR: 标准模糊断点回归(FRD)估计量存在有限样本下无任何阶矩的问题，作者提出了一类广义FRD估计量，具有有限样本下的所有阶矩，能显著改善估计精度和推断准确性。


<details>
  <summary>Details</summary>
Motivation: 标准FRD估计量在有限样本下没有有限矩，导致估计不精确、抽样分布重尾，在小样本或处理概率断点较小时推断不准确。

Method: 提出一类广义FRD估计量，包含一个连续统的估计量，通过单一调优参数索引，包含标准FRD和锐断点(SRD)估计量作为特例。

Result: 新估计量在有限样本下具有所有阶矩，显著改善中位数偏差、中位数绝对偏差和均方根误差，在小样本或处理概率断点较小时保持稳定。

Conclusion: 新提出的FRD估计量和置信区间在小样本下具有更好的稳定性和性能，通过蒙特卡洛模拟和实际教育数据验证了改进效果。

Abstract: The standard fuzzy regression discontinuity (FRD) estimator is a ratio of
differences of local polynomial estimators. I show that this estimator does not
have finite moments of any order in finite samples, regardless of the choice of
kernel function, bandwidth, or order of polynomial. This leads to an imprecise
estimator with a heavy-tailed sampling distribution, and inaccurate inference
with small sample sizes or when the discontinuity in the probability of
treatment assignment at the cutoff is small. I present a generalised class of
computationally simple FRD estimators, which contains a continuum of estimators
with finite moments of all orders in finite samples, and nests both the
standard FRD and sharp (SRD) estimators. The class is indexed by a single
tuning parameter, and I provide simple values that lead to substantial
improvements in median bias, median absolute deviation and root mean squared
error. These new estimators remain very stable in small samples, or when the
discontinuity in the probability of treatment assignment at the cutoff is
small. Simple confidence intervals that have strong coverage and length
properties in small samples are also developed. The improvements are seen
across a wide range of models and using common bandwidth selection algorithms
in extensive Monte Carlo simulations. The improved stability and performance of
the estimators and confidence intervals is also demonstrated using data on
class size effects on educational attainment.

</details>


### [58] [Leniency Designs: An Operator's Manual](https://arxiv.org/abs/2511.03572)
*Paul Goldsmith-Pinkham,Peter Hull,Michal Kolesár*

Main category: econ.EM

TL;DR: 本文提供了一个关于宽恕（法官或审查员工具）设计的逐步指南，基于近期计量经济学文献。提出了无偏折刀工具变量估计器（UJIVE），专门用于利用外生宽恕变化，避免在多决策者或控制变量情况下的微妙偏差。


<details>
  <summary>Details</summary>
Motivation: 开发一个系统性的方法来设计和评估宽恕工具，解决现有方法中存在的潜在偏差问题，特别是在多决策者环境下的工具变量估计。

Method: 使用无偏折刀工具变量估计器（UJIVE），该方法专门设计用于处理外生宽恕变化，能够评估关键假设（如准随机分配和平均第一阶段单调性），并检验处理效应估计的外部有效性。

Result: 通过对Farre-Mensa等人（2020）研究的重新分析，展示了该方法在估计初创企业专利价值方面的应用，验证了所提检查清单的有效性。

Conclusion: UJIVE为宽恕设计提供了一个强大的工具，能够避免传统方法的偏差，同时提供对关键假设的检验和统计推断的改进方法。

Abstract: We develop a step-by-step guide to leniency (a.k.a. judge or examiner
instrument) designs, drawing on recent econometric literatures. The unbiased
jackknife instrumental variables estimator (UJIVE) is purpose-built for
leveraging exogenous leniency variation, avoiding subtle biases even in the
presence of many decision-makers or controls. We show how UJIVE can also be
used to assess key assumptions underlying leniency designs, including
quasi-random assignment and average first-stage monotonicity, and to probe the
external validity of treatment effect estimates. We further discuss statistical
inference, arguing that non-clustered standard errors are often appropriate. A
reanalysis of Farre-Mensa et al. (2020), using quasi-random examiner assignment
to estimate the value of patents to startups, illustrates our checklist.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [59] [Robust reduced-order model predictive control using peak-to-peak analysis of filtered signals](https://arxiv.org/abs/2511.03002)
*Johannes Köhler,Carlo Scholz,Melanie Zeilinger*

Main category: eess.SY

TL;DR: 提出一种基于降阶模型的模型预测控制方法，通过预测误差边界系统来保证全阶系统的约束满足和鲁棒性能，在100维质量-弹簧-阻尼系统中相比现有方法减少了四个数量级的保守性。


<details>
  <summary>Details</summary>
Motivation: 针对大规模线性系统的模型预测控制计算复杂度高的问题，需要开发基于降阶模型的MPC方法，但现有方法存在保守性过大的缺陷。

Method: 使用降阶模型结合鲁棒控制工具，通过预测标量误差边界系统来获得全阶系统输出的保证边界，并基于此制定鲁棒MPC。具体步骤包括误差分析、峰值增益边界确定和滤波信号使用。

Result: 在100维质量-弹簧-阻尼系统上的实验表明，该方法相比现有方法减少了超过四个数量级的保守性，同时保证了约束满足和鲁棒性能。

Conclusion: 所提出的基于降阶模型的鲁棒MPC方法能够有效处理大规模线性系统，显著降低计算复杂度同时保证控制性能，为解决高维系统控制问题提供了有效途径。

Abstract: We address the design of a model predictive control (MPC) scheme for
large-scale linear systems using reduced-order models (ROMs). Our approach uses
a ROM, leverages tools from robust control, and integrates them into an MPC
framework to achieve computational tractability with robust constraint
satisfaction. Our key contribution is a method to obtain guaranteed bounds on
the predicted outputs of the full-order system by predicting a (scalar)
error-bounding system alongside the ROM. This bound is then used to formulate a
robust ROM-based MPC that guarantees constraint satisfaction and robust
performance. Our method is developed step-by-step by (i) analysing the error,
(ii) bounding the peak-to-peak gain, an (iii) using filtered signals. We
demonstrate our method on a 100-dimensional mass-spring-damper system,
achieving over four orders of magnitude reduction in conservatism relative to
existing approaches.

</details>


### [60] [Oscillation Analysis and Damping Control for a Proposed North American AC-DC Macrogrid](https://arxiv.org/abs/2511.03017)
*Kaustav Chatterjee,Sameer Nekkalapu,Antos Varghese,Marcelo Elizondo,Quan Nguyen,Xiaoyuan Fan*

Main category: eess.SY

TL;DR: 本文评估了通过多端直流电网连接北美东西部电网的小信号稳定性风险，识别了阻尼不足的区间振荡模式，并设计了基于广域反馈的阻尼控制器来抑制不稳定振荡。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注东西部电网互联的容量共享和频率支持优势，但对其可能引发的小信号稳定性挑战缺乏深入分析，需要填补这一研究空白。

Method: 开发了定制化的多端直流系统动态模型，并与行业级的东西部电网模型集成；采用基于模型的振荡分析识别阻尼不足的区间模式；利用频率扫描方法进行数据驱动的模型线性化和控制器综合。

Result: 识别了多端直流集成后东西部电网区间模式的潜在变化，发现了阻尼不足的振荡模式；设计的广域反馈阻尼控制器在正常运行和选定故障场景下均表现出良好的阻尼性能。

Conclusion: 东西部电网通过多端直流互联会引入小信号稳定性风险，但通过精心设计的阻尼控制器可以有效缓解这些风险，确保系统的稳定运行。

Abstract: In recent years, several studies conducted by both industry and U.S.
Department of Energy (DOE)-funded initiatives have proposed linking North
America's Eastern and Western Interconnections (EI and WI) through a
multiterminal DC (MTDC) macrogrid. These studies have explored the advantages
and opportunities of the proposed configuration from the perspectives of
capacity sharing and frequency support. However, the potential challenges of
small-signal stability arising from this interconnection have not been
thoroughly examined. To address this gap, detailed model-based simulation
studies are performed in this paper to assess the risks of poorly damped
inter-area oscillations in the proposed macrogrid. A custom-built dynamic model
of the MTDC system is developed and integrated with industry-grade models of
the EI and WI, incorporating high levels of inverter-based energy resources.
Through model-based oscillation analysis, potential shifts in inter-area modes
for both EI and WI, resulting from the MTDC integration are characterized, and
modes with inadequate damping are identified. Furthermore, to mitigate the
risks of unstable oscillations, supplementary damping controllers are designed
for the MTDC system, leveraging wide-area feedback to modulate active power set
points at selected converter stations. A frequency scanning approach is
employed for data-driven model linearization and controller synthesis. The
damping performance is evaluated under the designed operating conditions and
selected contingency scenarios.

</details>


### [61] [Quantifying Power Systems Resilience Using Statistical Analysis and Bayesian Learning](https://arxiv.org/abs/2511.03043)
*Apsara Adhikari,Charlotte Wertz,Anamika Dubey,Arslan Ahmad,Ian Dobson*

Main category: eess.SY

TL;DR: 开发了一个使用统计和贝叶斯学习方法的框架，定量建模天气参数与电力系统韧性指标之间的关系，识别出风速、温度和降水是关键影响因素。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件日益频繁和强烈，严重影响电网，导致大规模停电，但缺乏系统性建模天气参数对韧性影响的研究。

Method: 利用真实世界的公开停电和天气数据，采用统计和贝叶斯学习方法，识别影响特定区域韧性指标的关键天气变量。

Result: 对伊利诺伊州库克县和佛罗里达州迈阿密-戴德县的案例研究发现，风速、温度和降水是韧性分析和风险评估的关键因素，且这些变量联合研究时具有组合效应。

Conclusion: 该框架为理解天气事件如何影响配电系统性能提供了宝贵见解，支持决策者制定更有效的风险缓解、资源分配和适应气候变化策略。

Abstract: The increasing frequency and intensity of extreme weather events is
significantly affecting the power grid, causing large-scale outages and
impacting power system resilience. Yet limited work has been done on
systematically modeling the impacts of weather parameters to quantify
resilience. This study presents a framework using statistical and Bayesian
learning approaches to quantitatively model the relationship between weather
parameters and power system resilience metrics. By leveraging real-world
publicly available outage and weather data, we identify key weather variables
of wind speed, temperature, and precipitation influencing a particular region's
resilience metrics. A case study of Cook County, Illinois, and Miami-Dade
County, Florida, reveals that these weather parameters are critical factors in
resiliency analysis and risk assessment. Additionally, we find that these
weather variables have combined effects when studied jointly compared to their
effects in isolation. This framework provides valuable insights for
understanding how weather events affect power distribution system performance,
supporting decision-makers in developing more effective strategies for risk
mitigation, resource allocation, and adaptation to changing climatic
conditions.

</details>


### [62] [Microgrids optimal radial reconfiguration via FORWARD algorithm](https://arxiv.org/abs/2511.03059)
*Joan Vendrell Gallart,Russell Bent,Solmaz Kia*

Main category: eess.SY

TL;DR: 本文提出了一种基于排列的迭代搜索方法，结合FORWARD方法来解决微电网资源分配和径向配置设计问题，为MINLP求解器提供预热启动策略。


<details>
  <summary>Details</summary>
Motivation: 微电网的分散性和动态运行带来了复杂的能源管理挑战，包括供需平衡、系统稳定性和运营成本最小化，这些通常需要解决计算上难以处理的NP-hard MINLP问题。

Method: 提出了一种基于排列的迭代搜索方法，结合FORWARD方法来高效识别可行且接近最优的径向网络结构，同时固有地尊重物理约束。

Result: 该方法能够有效识别可行的近最优径向网络结构，并为基准MINLP求解器提供可扩展的预热启动解决方案。

Conclusion: 所提出的方法为解决微电网设计中的复杂MINLP问题提供了可扩展的解决方案，通过预热启动策略提高了求解器的效率。

Abstract: Microgrids offer a promising paradigm for integrating distributed energy
resources, bolstering energy resilience, and reducing the impact of blackouts.
However, their inherent decentralization and dynamic operation present
substantial energy management complexities. These complexities, including
balancing supply and demand, ensuring system stability, and minimizing
operational costs, often necessitate solving computationally intractable
NP-hard Mixed-Integer Non-Linear Programming (MINLP) problems. Traditional
MINLP solvers struggle with the scalability and feasibility guarantees required
for these challenges. To address this, this paper tackles the problem of
resource allocation and radial configuration design for microgrid power
distribution and proposes and abstracted problem which is solved by introducing
a permutation-based iterative search method over the recently introduced
FORWARD method to efficiently identify feasible, near-optimal radial network
structures while inherently respecting physical constraints. Furthermore, this
paper investigates the integration of the proposed method as a warm-start
strategy for benchmark MINLP solvers offering a scalable solution for
comprehensive microgrid design.

</details>


### [63] [Active Noise Control Method Using Time Domain Neural Networks for Path Decoupling](https://arxiv.org/abs/2511.03162)
*Yijing Chu,Qinxuan Xiang,Sipei Zhao,Ming Wu,Y. Zhao,Guangzheng Yu*

Main category: eess.SY

TL;DR: 提出了一种结合固定值神经网络和自适应策略的混合方法，用于高效的去中心化主动噪声控制，解决了多通道系统中的串扰和预滤波误差问题。


<details>
  <summary>Details</summary>
Motivation: 在去中心化主动噪声控制系统中，多通道次级源和误差麦克风之间的串扰会显著降低控制精度，而Fx类算法中的参考信号预滤波可能进一步引入建模误差。

Method: 采用混合方法：自适应滤波器使用LMS算法在线建模自身通道的主路径，神经网络(DecNet)用于次级路径反演和解耦，在时域实现以保证因果性并避免延迟。

Result: 使用实测声学路径的仿真结果表明，该方法在不同声学条件下优于现有的使用传统自适应滤波器或基于神经网络的固定系数方法的ANC算法。

Conclusion: 所提出的混合DecNet-LMS算法能有效解决去中心化ANC系统中的串扰和预滤波问题，提高控制性能。

Abstract: In decentralized active noise control (ANC) systems, crosstalk between
multichannel secondary sources and error microphones significantly degrades
control accuracy. Moreover, prefiltering reference signals in filtered-x (Fx)
type algorithms may further introduce modeling errors. A theoretical analysis
of the Fx-based decentralized control algorithm was performed, which reveals
how prefiltering and crosstalk affect the control performance. Then, a hybrid
method combining fixed-value neural networks and adaptive strategies was
proposed for efficient decentralized ANC. The adaptive filter models the
primary path of its own channel online using the least mean square (LMS)
algorithm while the neural network (named DecNet) is used for secondary paths
inverting and decoupling. The hybrid DecNet-LMS algorithm was implemented in
the time domain to guarantee causality and avoid latency. Simulation results
with measured acoustic paths show that the proposed method outperforms the
existing ANC algorithms using either traditional adaptive filters or neural
network-based fixed-coefficient methods under different acoustic conditions.

</details>


### [64] [MHE in Output Feedback Control of Uncertain Nonlinear Systems via IQCs](https://arxiv.org/abs/2511.03221)
*Yang Guo,Stefan Streif*

Main category: eess.SY

TL;DR: 提出一种用于非线性约束系统的移动视界估计方案，该系统具有参数或静态非线性不确定性，并假设在无估计误差时存在鲁棒稳定的状态反馈控制器。


<details>
  <summary>Details</summary>
Motivation: 针对具有不确定性的非线性约束系统，开发能够在存在估计误差时保证闭环系统稳定性的估计方法。

Method: 利用积分二次约束引入新的可检测性概念，并基于此设计移动视界估计方案。

Result: 当不确定系统满足所提出的可检测性条件时，所设计的MHE方案能够保证由不确定系统、控制器和MHE组成的闭环系统对外部扰动具有输入到状态稳定性。

Conclusion: 所提出的MHE方案为具有不确定性的非线性约束系统提供了有效的状态估计方法，并能保证闭环系统的鲁棒稳定性。

Abstract: We propose a moving horizon estimation (MHE) scheme for general nonlinear
constrained systems with parametric or static nonlinear uncertainties and a
predetermined state feedback controller that is assumed to robustly stabilize
the system in the absence of estimation errors. Leveraging integral quadratic
constraints (IQCs), we introduce a new notion of detectability that is robust
to possibly non-parametric uncertainties and verifiable in practice. Assuming
that the uncertain system driven by the controller satisfies this notion of
detectability, we provide an MHE formulation such that the closed-loop system
formed of the uncertain system, the controller and MHE is input-to-state stable
w.r.t. exogenous disturbances.

</details>


### [65] [Theoretical and Experimental Limitations of RoCoF Estimation](https://arxiv.org/abs/2511.03249)
*Gutierrez-Florensa,F. Sanniti,D. Tedeschi,L. Sigrist,A. Ortega,F. Milano*

Main category: eess.SY

TL;DR: 提出了一种基于微分几何和流体力学概念的数值鲁棒方法，用于精确估计频率变化率(RoCoF)，并应用于RoCoF基的欠频减载控制方案。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统具有低惯性和基于变流器的发电特性，增加了暂态严重性，使得频率和RoCoF估计更加复杂和不精确，这影响了保护系统的可靠性。

Method: 采用从微分几何和流体力学继承的概念，开发数值鲁棒方法，并使用高采样率实验测量进行测试，应用于RoCoF基的欠频减载控制方案。

Result: 该方法提供了关于事故性质的信息，可用于改进保护系统的响应，并开发了更快的控制逻辑。

Conclusion: 所提出的数值鲁棒方法能够提高RoCoF估计的精度，为保护系统提供更准确的事故信息，从而改善电力系统的安全运行。

Abstract: A precise estimation of the Rate of Change of Frequency (RoCoF) is crucial
for secure power system operation. In fact, RoCoF is strictly related to the
amount of the available physical and/or virtual inertia of the system and the
severity of the active power unbalance following a disturbance. For this
reason, it is widely exploited in different protection systems, e.g.,
Anti-Islanding, Under Frequency Load Shedding (UFLS) and wide-area protection
systems. The new paradigm of modern power systems, with a low-inertia and
converter-based generation assets, is increasing the transient severity, making
the frequency and the RoCoF estimation more complex and less precise for the
actual devices. This work addresses this issue by proposing a numerically
robust approach based on concepts inherited from differential geometry and
fluid mechanics. The proposed approach is then tested with high-sampling real
experimental measurements and used to develop a faster control logic for a
RoCoF-based UFLS control scheme. The proposed approach provides information to
protections regarding the nature of the contingency which can be used to
improve its response.

</details>


### [66] [Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games -- Part II: Stability](https://arxiv.org/abs/2511.03297)
*Leonardo Pedroso,Andrea Agazzi,W. P. M. H. Heemels,Mauro Salazar*

Main category: eess.SY

TL;DR: 本文研究大型群体动态博弈中混合稳态纳什均衡(MSNE)的演化稳定性，给出了确保局部和全局稳定性的条件，分析了MSNE在战略偏离下的鲁棒性和长期生存能力。


<details>
  <summary>Details</summary>
Motivation: 研究大型群体动态博弈中MSNE的演化稳定性，以理解该均衡解在战略偏离下的鲁棒性和长期生存能力。

Method: 通过分析博弈的支付映射结构和MSNE的结构特性，推导确保局部和全局稳定性的条件，研究演化动态下的稳定性行为。

Result: 得出了MSNE在演化动态下局部和全局稳定性的充分条件，这些条件同时依赖于MSNE的结构特性和博弈的支付映射特性。

Conclusion: MSNE的演化稳定性不仅取决于均衡本身的结构，还取决于博弈的支付映射特性，这为理解大型群体动态博弈中均衡的长期生存能力提供了理论依据。

Abstract: We study a dynamic game with a large population of players who choose actions
from a finite set in continuous time. Each player has a state in a finite state
space that evolves stochastically with their actions. A player's reward depends
not only on their own state and action but also on the distribution of states
and actions across the population, capturing effects such as congestion in
traffic networks. In Part I, we introduced an evolutionary model and a new
solution concept - the mixed stationary Nash Equilibrium (MSNE) - which
coincides with the rest points of the mean field evolutionary model under
meaningful families of revision protocols. In this second part, we investigate
the evolutionary stability of MSNE. We derive conditions on both the structure
of the MSNE and the game's payoff map that ensure local and global stability
under evolutionary dynamics. These results characterize when MSNE can robustly
emerge and persist against strategic deviations, thereby providing insight into
its long-term viability in large population dynamic games.

</details>


### [67] [Lightwave Power Transfer-Enabled Underwater Optical ISAC Systems under Ship Attitude Variation](https://arxiv.org/abs/2511.03366)
*Kapila W. S. Palitharathna,Constantinos Psomas,Ioannis Krikidis*

Main category: eess.SY

TL;DR: 提出了一种基于光波能量传输的水下光学集成感知与通信系统，该系统通过海面船只上的接入点向海底传感器和感知目标传输光信号，同时实现能量收集、上行通信和目标定位功能。


<details>
  <summary>Details</summary>
Motivation: 解决水下环境中集成感知与通信系统的实际部署问题，特别是在考虑船舶姿态变化等现实条件下的系统性能优化。

Method: 建立包含船舶滚转、俯仰和偏航角高斯分布的系统模型，推导目标定位均方误差和上行数据速率的闭式近似表达式，分析最优相机布局和能量收集使用比例。

Result: 理论与仿真结果高度一致，验证了所提模型的有效性，在10度姿态变化下实现10^{-2} m^2的最小定位误差，最优能量收集使用比例为0.55。

Conclusion: 揭示了O-ISAC系统中通信与感知之间的基本权衡关系，为实际系统设计提供了有价值的指导，包括最优相机布局和能量管理策略。

Abstract: In this paper, we propose a lightwave power transfer-enabled underwater
optical integrated sensing and communication (O-ISAC) system, where an access
point (AP) mounted on a seasurface ship transmits lightwave signals to two
nodes, namely ($i$) a seabed sensor that harvests energy and transmits uplink
information to the AP, and ($ii$) a sensing target whose position is estimated
by the AP using an array of pinhole cameras. To capture practical deployment
conditions, the ship attitude variation is modeled through its roll, pitch, and
yaw angles, each following a Gaussian distribution under low-to-moderate sea
states. Closed-form approximations are derived for the mean squared error (MSE)
of target localization and the achievable uplink data rate. Analytical and
simulation results demonstrate excellent agreement, validating the proposed
models and derived expressions, while revealing the fundamental
communication-sensing tradeoff in the O-ISAC system. The results further
provide valuable design insights, including the optimal camera placement on the
ship to minimize localization error, achieving a minimum MSE of $10^{-2}$
$\text{m}^2$ with multiple cameras under roll, pitch, and yaw angle variation
of $10^{\circ}$, and the optimal harvest-use ratio of $0.55$ for the considered
setup.

</details>


### [68] [A Digital Twin of Evaporative Thermo-Fluidic Process in Fixation Unit of DoD Inkjet Printers](https://arxiv.org/abs/2511.03379)
*Samarth Toolhally,Joeri Roelofs,Siep Weiland,Amritam Das*

Main category: eess.SY

TL;DR: 本文提出了喷墨打印机定影单元的模块化数字孪生模型，通过无限维状态估计器从有限传感器数据推断定影状态，并开发了H∞最优Luenberger状态估计器来实时监测纸张的时空热效应。


<details>
  <summary>Details</summary>
Motivation: 喷墨打印中纸张的最佳湿度对打印质量至关重要，需要通过热风冲击在定影单元中实现。现有方法需要更精确的时空性能监测和鲁棒的状态估计。

Method: 采用图论模型构建模块化数字孪生，每个节点代表定影单元不同部分的热流体动力学。蒸发建模为非线性边界效应，通过线性分式表示与节点动力学耦合。使用偏积分方程框架进行稳定性、输入输出分析、仿真和快速原型验证。

Result: 开发了统一的数字孪生方法，能够从商业打印机的操作数据中验证模型，并合成H∞最优状态估计器来估计热状态。

Conclusion: 该方法实现了定影单元的实时时空性能监测，为喷墨打印过程提供了鲁棒的状态估计和性能监控能力。

Abstract: In inkjet printing, optimal paper moisture is crucial for print quality,
achieved through hot-air impingement in the fixation unit. This paper presents
a modular digital twin of the fixation unit, modeling the thermo-fluidic drying
process and monitoring its spatio-temporal performance. The novel approach
formulates the digital twin as an infinite-dimensional state estimator that
infers fixation states from limited sensor data, while remaining robust to
disturbances. Modularity is achieved through a graph-theoretic model, where
each node represents thermo-fluidic dynamics in different sections of the
fixation unit. Evaporation is modeled as a nonlinear boundary effect coupled
with node dynamics via Linear Fractional Representation. Using the Partial
Integral Equation (PIE) framework, we develop a unified approach for stability,
input-output analysis, simulation, and rapid prototyping, validated with
operational data from a commercial printer. An $\mathcal{H}_{\infty}$-optimal
Luenberger state estimator is then synthesized to estimate thermal states from
available sensor data, enabling real-time monitoring of spatio-temporal thermal
effects on paper sheets.

</details>


### [69] [Maximum Likelihood Estimation of Dynamic Sub-Networks with Missing Data](https://arxiv.org/abs/2511.03391)
*João Victor Galvão da Mata,Anders Hansson,Martin S. Andersen*

Main category: eess.SY

TL;DR: 提出一种最大似然估计方法，能够在复杂互连系统中识别子网络参数，无需估计整个网络，显著降低计算复杂度并增强隐私保护。


<details>
  <summary>Details</summary>
Motivation: 传统最大似然估计在大规模网络识别中计算成本过高，且需要共享敏感内部数据，存在隐私和效率问题。

Method: 基于特定拓扑条件，仅使用目标子网络和直接连接的分离器子网络中的局部测量信号来估计子网络参数。

Result: 建立了网络可分离性的理论条件，推导了子网络的概率密度函数，并通过数值示例验证了方法的有效性。

Conclusion: 该方法能够显著降低计算复杂度，同时通过避免跨组织边界共享敏感数据来增强隐私保护，为大规模网络识别提供了可行方案。

Abstract: Maximum likelihood estimation is effective for identifying dynamical systems,
but applying it to large networks becomes computationally prohibitive. This
paper introduces a maximum likelihood estimation method that enables
identification of sub-networks within complex interconnected systems without
estimating the entire network. The key insight is that under specific
topological conditions, a sub-network's parameters can be estimated using only
local measurements: signals within the target sub-network and those in the
directly connected to the so-called separator sub-network. This approach
significantly reduces computational complexity while enhancing privacy by
eliminating the need to share sensitive internal data across organizational
boundaries. We establish theoretical conditions for network separability,
derive the probability density function for the sub-network, and demonstrate
the method's effectiveness through numerical examples.

</details>


### [70] [An Alternative Derivation and Optimal Design Method of the Generalized Bilinear Transformation for Discretizing Analog Systems](https://arxiv.org/abs/2511.03403)
*Shen Chen,Yanlong Li,Jiamin Cui,Wei Yao,Jisong Wang,Yixin Tian,Chaohou Liu,Yang Yang,Jiaxi Ying,Zeng Liu,Jinjun Liu*

Main category: eess.SY

TL;DR: 本文提出了广义双线性变换(GBT)中参数α的物理意义解释和最优设计方法，通过六边形近似误差函数面积来推导GBT，将α定义为形状因子，并基于归一化幅度或相位误差开发了形状因子的最优设计方法。


<details>
  <summary>Details</summary>
Motivation: 传统欧拉或图斯汀变换是GBT的特例，但GBT中的设计参数α的物理意义和最优设计方法研究不足，需要揭示其物理含义并开发系统化的设计方法。

Method: 采用新的六边形形状来近似误差函数的包围面积，从而推导GBT，将参数α定义为形状因子，并通过域映射分析其稳定范围[0.5,1]，基于归一化幅度或相位误差建立目标函数来优化形状因子。

Result: 揭示了形状因子α的物理意义为后向矩形比的百分比，发现了幅度和相位两种失真模式，开发了形状因子的最优设计方法，并通过低通滤波器设计验证了方法的有效性。

Conclusion: 提出的方法成功揭示了GBT参数α的物理意义，建立了系统化的最优设计框架，为数字系统设计提供了更精确和可控的变换方法。

Abstract: A popular method for designing digital systems is transforming the transfer
function of the corresponding analog systems from the continuous-time domain
(s-domain) into the discrete-time domain (z-domain) using the Euler or Tustin
method. We demonstrate that these transformations are two specific forms of the
Generalized Bilinear Transformation (GBT) with a design parameter, $\alpha$.
However, the physical meaning and optimal design method for this parameter are
not sufficiently studied. In this paper, we propose an alternative derivation
of the GBT derived by employing a new hexagonal shape to approximate the
enclosed area of the error function, and we define the parameter $\alpha$ as
the shape factor. The physical meaning of the shape factor is firstly revealed,
which equals to the percentage of the backward rectangular ratio of the
proposed hexagonal shape. We demonstrate that the stable range of the shape
factor is [0.5, 1] through domain mapping. Depending on the operating
frequencies and the shape factor, we observe two distinct distortion modes,
i.e., the magnitude and phase distortion. We proceed to develop an optimal
design method for the shape factor based on an objective function in form of
the normalized magnitude or phase error. Finally, a low-pass filter (LPF) is
designed and tested to verify the effectiveness of the proposed method by
comparing the theoretical calculations with the experimental results.

</details>


### [71] [System Identification of a Moored ASV with Recessed Moon Pool via Deterministic and Bayesian Hankel-DMDc](https://arxiv.org/abs/2511.03482)
*Giorgio Palma,Ivan Santic,Andrea Serani,Lorenzo Minno,Matteo Diez*

Main category: eess.SY

TL;DR: 该研究使用HDMDc及其贝叶斯扩展BHDMDc对系泊状态下的小型自主水面船进行系统辨识，在规则和不规则迎浪条件下验证了模型预测能力，首次展示了在不同海况下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决带有月池的小型自主水面船在系泊状态下的系统辨识问题，月池引起的晃荡非线性响应增加了建模挑战，需要开发准确的数据驱动降阶模型。

Method: 使用Hankel动态模态分解控制(HDMDc)及其贝叶斯扩展(BHDMDc)构建数据驱动降阶模型，基于船舶运动和系泊载荷测量数据，在拖曳水池中进行规则和不规则迎浪实验。

Result: HDMDc提供了准确的确定性动力学预测，贝叶斯公式通过考虑超参数选择的变异性实现了不确定性感知的模型响应表征，验证显示两种方法都能预测未见过的规则和不规则波浪激励下的船舶响应。

Conclusion: HDMDc基降阶模型是系统辨识的可行数据驱动替代方案，首次展示了其在不同于训练集的海况下的泛化能力，在重现船舶动力学方面达到高精度。

Abstract: This study addresses the system identification of a small autonomous surface
vehicle (ASV) under moored conditions using Hankel dynamic mode decomposition
with control (HDMDc) and its Bayesian extension (BHDMDc). Experiments were
carried out on a Codevintec CK-14e ASV in the towing tank of CNR-INM, under
both irregular and regular head-sea wave conditions. The ASV under
investigation features a recessed moon pool, which induces nonlinear responses
due to sloshing, thereby increasing the modelling challenge. Data-driven
reduced-order models were built from measurements of vessel motions and mooring
loads. The HDMDc framework provided accurate deterministic predictions of
vessel dynamics, while the Bayesian formulation enabled uncertainty-aware
characterization of the model response by accounting for variability in
hyperparameter selection. Validation against experimental data demonstrated
that both HDMDc and BHDMDc can predict the vessel's response to unseen regular
and irregular wave excitations. In conclusion, the study shows that HDMDc-based
ROMs are a viable data-driven alternative for system identification,
demonstrating for the first time their generalization capability for a sea
condition different from the training set, achieving high accuracy in
reproducing vessel dynamics.

</details>


### [72] [Data-driven Modeling of Grid-following Control in Grid-connected Converters](https://arxiv.org/abs/2511.03494)
*Amir Bahador Javadi,Philip Pong*

Main category: eess.SY

TL;DR: 评估稀疏识别非线性动力学和深度符号回归方法在捕捉现代电网复杂动态方面的有效性，使用基于转换器的资源替代传统发电机的系统生成合成数据。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源集成和智能电网技术发展，需要灵活可扩展的建模方法来准确捕捉现代电网的复杂动态。

Method: 使用基于转换器的资源替代传统发电机，在连接到无限母线的无损输电线路系统中生成合成数据，评估稀疏识别非线性动力学和深度符号回归方法。

Result: 通过系统设置生成了用于评估的合成数据，为比较两种方法的有效性提供了基础。

Conclusion: 该研究为评估数据驱动方法在捕捉电网动态方面的性能提供了实验框架，有助于开发更准确的电网建模方法。

Abstract: As power systems evolve with the integration of renewable energy sources and
the implementation of smart grid technologies, there is an increasing need for
flexible and scalable modeling approaches capable of accurately capturing the
complex dynamics of modern grids. To meet this need, various methods, such as
the sparse identification of nonlinear dynamics and deep symbolic regression,
have been developed to identify dynamical systems directly from data. In this
study, we examine the application of a converter-based resource as a
replacement for a traditional generator within a lossless transmission line
linked to an infinite bus system. This setup is used to generate synthetic data
in grid-following control mode, enabling the evaluation of these methods in
effectively capturing system dynamics.

</details>


### [73] [Powered Descent Trajectory Optimization of Chandrayaan-3 using Radau Collocation and Controllable Sets](https://arxiv.org/abs/2511.03594)
*Suraj Kumar,Aditya Rallapalli,Ashok Kumar Kakula,Bharat Kumar GVP*

Main category: eess.SY

TL;DR: 本文介绍了印度月船3号任务的动力下降轨迹设计，采用伪谱Radau配点优化框架和基于可控性的航点优化方法，量化了燃料消耗与鲁棒性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 印度成为第四个实现月球软着陆的国家，需要设计可靠的动力下降轨迹以确保任务成功。

Method: 使用伪谱Radau配点优化框架进行轨迹设计，并采用基于可控性的航点优化方法来增强轨迹对状态和控制扰动的鲁棒性。

Result: 成功设计了月船3号的动力下降轨迹，并量化了燃料消耗与鲁棒性之间的权衡关系。

Conclusion: 该方法为任务规划提供了实用的考虑因素，确保了月船3号任务的软着陆成功。

Abstract: India achieved a significant milestone on August $23^{\text{rd}}$ 2023,
becoming the fourth country to accomplish a soft landing on the Moon. This
paper presents the powered descent trajectory design for the Chandrayaan-3
mission. The optimization framework is based on pseudospectral Radau
collocation, and controllability-based waypoint refinement is employed to
further enhance the robustness of the trajectory against state and control
perturbations. Furthermore, the trade-off between fuel consumption and
robustness is explicitly quantified, providing insights into the practical
considerations of mission planning.

</details>


### [74] [Artificial-reference tracking MPC with probabilistically validated performance on industrial embedded systems](https://arxiv.org/abs/2511.03603)
*Victor Gracia,Pablo Krupa,Filiberto Fele,Teodoro Alamo*

Main category: eess.SY

TL;DR: 该论文提出了一种针对嵌入式系统的高效MPC跟踪控制实现，采用结构利用的一阶方法，结合了无偏移方案、约束收紧和软约束等实用功能，并在PLC上通过硬件在环实验验证了性能。


<details>
  <summary>Details</summary>
Motivation: 工业嵌入式系统计算资源有限，通常只能执行简单控制算法。虽然近年来MPC在嵌入式系统上的实现有所探索，但现有简化方案往往缺乏实际应用所需的关键特性。

Method: 采用带人工参考的MPC跟踪控制，通过结构利用的一阶方法求解，整合了无偏移方案、回退参数实现约束收紧、软约束保持可行性等实用功能，并建立了概率性能验证框架。

Result: 在PLC上成功实现，通过硬件在环控制非线性连续搅拌釜反应器，对闭环系统的约束违反和MPC优化算法每次迭代次数进行了概率验证。

Conclusion: 提出的方法在嵌入式系统上高效实现了具有实用功能的MPC控制，并通过概率验证框架确保了长期运行的可靠性。

Abstract: Industrial embedded systems are typically used to execute simple control
algorithms due to their low computational resources. Despite these limitations,
the implementation of advanced control techniques such as Model Predictive
Control (MPC) has been explored by the control community in recent years,
typically considering simple linear formulations or explicit ones to facilitate
the online computation of the control input. These simplifications often lack
features and properties that are desirable in real-world environments. In this
article, we present an efficient implementation for embedded systems of MPC for
tracking with artificial reference, solved via a recently developed
structure-exploiting first-order method. This formulation is tailored to a wide
range of applications by incorporating essential practical features at a small
computational cost, including integration with an offset-free scheme, back-off
parameters that enable constraint tightening, and soft constraints that
preserve feasibility under disturbances or plant-model mismatch. We accompany
this with a framework for probabilistic performance validation of the
closed-loop system over long-term operation. We illustrate the applicability of
the approach on a Programmable Logic Controller (PLC), incorporated in a
hardware-in-the-loop setup to control a nonlinear continuous stirred-tank
reactor. The behavior of the closed-loop system is probabilistically validated
with respect to constraint violations and the number of iterations required at
each time step by the MPC optimization algorithm.

</details>


### [75] [A Constant-Gain Equation-Error Framework for Airliner Aerodynamic Monitoring Using QAR Data](https://arxiv.org/abs/2511.03678)
*Ruiying Wen,Yuntao Dai,Hongyong Wang*

Main category: eess.SY

TL;DR: 提出了一种恒定增益方程误差方法（CG-EEM），用于解决使用QAR数据监测飞机气动性能时传统方法失效的问题，特别适用于低激励巡航数据。


<details>
  <summary>Details</summary>
Motivation: 使用操作QAR数据监测飞机气动性能对运行效率和安全性至关重要，但传统状态传播滤波器因缺少关键参数（如飞机转动惯量）而失效，标准递归估计器在低激励巡航数据中也表现不佳。

Method: 提出恒定增益方程误差方法（CG-EEM），采用具有恒定卡尔曼类增益的自定义估计器，专门针对巡航飞行的平稳、低信噪比特性设计。

Result: 在包含200多个航班的多机队数据集上验证，CG-EEM产生高度一致、物理上合理的气动参数，并能正确识别不同机型间的已知性能差异。

Conclusion: CG-EEM提供了一个稳健、可扩展且计算高效的工具，用于机队范围的性能监控和性能退化的早期检测。

Abstract: Monitoring the in-service aerodynamic performance of airliners is critical
for operational efficiency and safety, but using operational Quick Access
Recorder (QAR) data for this purpose presents significant challenges. This
paper first establishes that the absence of key parameters, particularly
aircraft moments of inertia, makes conventional state-propagation filters
fundamentally unsuitable for this application. This limitation necessitates a
decoupled, Equation-Error Method (EEM). However, we then demonstrate through a
comparative analysis that standard recursive estimators with time-varying
gains, such as Recursive Least Squares (RLS), also fail within an EEM
framework, exhibiting premature convergence or instability when applied to
low-excitation cruise data. To overcome these dual challenges, we propose and
validate the Constant-Gain Equation-Error Method (CG-EEM). This framework
employs a custom estimator with a constant, Kalman-like gain, which is
perfectly suited to the stationary, low-signal-to-noise characteristics of
cruise flight. The CG-EEM is extensively validated on a large, multi-fleet
dataset of over 200 flights, where it produces highly consistent, physically
plausible aerodynamic parameters and correctly identifies known performance
differences between aircraft types. The result is a robust, scalable, and
computationally efficient tool for fleet-wide performance monitoring and the
early detection of performance degradation.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [76] [Extreme events and public debt dynamics: Lessons from Croatia's experience](https://arxiv.org/abs/2511.02973)
*Luka Draganić,Leonarda Srdelić,Marwil J. Davila-Fernandez*

Main category: econ.GN

TL;DR: 本文使用克罗地亚数据和IMF的自然灾害债务动态工具，评估了小型开放经济体中公共债务如何应对极端事件。研究发现，在无灾害情况下，债务占GDP比率将逐步下降至55%以下，但重大地震灾害会导致债务短期急剧上升并持续走高至75%。


<details>
  <summary>Details</summary>
Motivation: 评估克罗地亚这一新加入欧盟国家在灾害后的恢复能力，为小型开放经济体如何应对极端事件提供参考。

Method: 使用IMF的自然灾害债务动态工具，比较基准情景和压力情景下的债务路径，后者模拟2025年发生重大地震。采用确定性和随机性模拟评估潜在结果的分布。

Result: 基准情景下债务可持续下降，但灾害情景会导致债务短期急剧上升并持续走高，债务占GDP比率从55%升至75%。

Conclusion: 自然灾害可能逆转债务下降趋势并使其多年保持高位，凸显财政缓冲对吸收冲击的重要性。该研究创新地将自然灾害压力测试整合到公共债务分析中，对财政风险管理和政策规划具有广泛意义。

Abstract: Using Croatian data and the IMF's Natural Disaster Debt Dynamic Tool, this
paper assesses how public debt adjusts to extreme events in a small open
economy. We compare debt paths under baseline and stress scenarios, the latter
simulating a major earthquake in 2025. Croatia provides a unique setting for
evaluating post-disaster recovery in countries recently incorporated into the
European Union. Our benchmark projections, which assume moderate economic
growth and a broadly neutral fiscal stance, suggest the debt-to-GDP ratio will
gradually decline to below 55% by 2040. In contrast, in the disaster scenario,
we document a sharp short-term increase and a persistent upward shift in the
debt trajectory, reaching 75% of GDP. Deterministic and stochastic simulations
allow us to assess the distribution of potential outcomes. It is shown that, in
the absence of shocks, public debt is on a sustainable downward path, but a
severe natural disaster could reverse this trend and keep it elevated for
years. Our findings highlight the importance of fiscal buffers that are
critical for creating space to absorb shocks. The paper innovates by
integrating natural disaster stress-testing into public debt analysis, with
implications for fiscal risk management and policy planning. While we focus on
Croatia, the mechanisms we uncover have broader implications for small open
economies exposed to extreme events.

</details>


### [77] [A Computer Vision Based Proxy for Political Polarization in Religious Countries: A Turkiye Case Study](https://arxiv.org/abs/2511.03088)
*Liangze Ke*

Main category: econ.GN

TL;DR: 使用计算机视觉分析YouTube视频中的群体间距离作为政治极化的新代理指标，发现在土耳其宗教与非宗教群体间距离与选举极化高度相关，而群体内多样性有助于稳定极化。


<details>
  <summary>Details</summary>
Motivation: 传统经济指标难以全面衡量政治极化，需要开发可扩展的计算方法来量化社会文化分裂。

Method: 分析1400多个YouTube视频，使用先进的目标检测技术量化土耳其的群体间距离，并与基于熵的投票指标进行相关性分析。

Result: 宗教与非宗教群体间距离与选举熵呈强正相关，而非宗教群体内部多样性有助于降低极化程度。

Conclusion: 物理距离可作为政治极化的有效代理指标，为计算社会科学提供了新的测量工具，补充传统经济指标。

Abstract: This paper examines a novel proxy for political polarization, initially
proposed by Caliskan et al., which estimates intergroup distances using
computer vision. Analyzing 1,400+ YouTube videos with advanced object
detection, their study quantifies demographic and religious divides in Turkiye,
a deeply polarized nation. Our findings reveal strong correlations between
intergroup distances and electoral polarization, measured via entropy-based
voting metrics weighted by religiosity and political inclination. Two key
insights emerge: (1) Greater distances between religious and nonreligious
individuals (NRP vs RP) heighten electoral entropy, underscoring sociocultural
fragmentation. (2) Intragroup diversity among nonreligious individuals (NRP vs
NRP) stabilizes polarization, aligning with Axelrod's cultural dissemination
model. This research advances computational social science and economics by
showing that physical distancing serves as a scalable proxy for polarization,
complementing traditional economic indicators.

</details>


### [78] [Gender gap in the desired wages: Evidence from large administrative data](https://arxiv.org/abs/2511.03252)
*Taiyo Fukai,Keisuke Kawata,Mizuki Komura,Takahiro Toriyabe*

Main category: econ.GN

TL;DR: 使用公共就业推荐的大规模行政数据分析性别工资期望差距，发现职业期望是造成差异的最重要因素，但残差项占比最大。


<details>
  <summary>Details</summary>
Motivation: 研究性别在期望工资方面的差距，利用更广泛的工资分布数据来深入分析这一现象。

Method: 使用公共就业推荐的大规模行政数据，基于年龄、期望工作地区和期望职业进行分解分析，并进行异质性和敏感性分析。

Result: 三个因素中，期望职业对期望工资差异的影响最大，但残差项（未解释部分）的占比最大。

Conclusion: 期望职业是解释性别期望工资差距的关键因素，但仍有大量未解释的差异需要进一步研究。

Abstract: This study analyzes the gender gap in desired wages using large
administrative data of public job referrals, which allows us to look at the
desired salaries of individuals from a wider wage distribution. We conduct a
decomposition analysis using available information on age, desired work region,
and desired occupation. We find that of the three factors, desired occupation
is the most important in generating differences in desired wages; however, the
residuals are the largest outside of the three factors. To further probe the
unexplained residuals, we also conduct heterogeneity and sensitivity analyses
using the available data.

</details>


### [79] [Duration Dependence and Job Search over the Spell: Evidence from Job Seeker Activity Reports](https://arxiv.org/abs/2511.03377)
*Jonas Cederlöf,Sara Roman*

Main category: econ.GN

TL;DR: 研究发现失业期间求职行为的变化主要源于动态选择效应，而非真正的持续时间依赖性。搜索努力在失业期内保持平稳，但在再就业前急剧下降，且失业救济金耗尽会导致搜索努力下降约10%。


<details>
  <summary>Details</summary>
Motivation: 研究失业期间求职行为如何演变，以及求职者在面试机会方面是否经历持续时间依赖性，区分内在变化与动态选择效应。

Method: 利用240万份月度活动报告数据，采用时间和失业期固定效应设计，分离失业期内的变化与动态选择。

Result: 原始搜索努力随失业持续时间增加，但这反映了动态选择：失业期内的搜索努力保持平稳，在再就业前几个月急剧下降。面试机会每月下降6%，但只有10-14%反映真正的持续时间依赖性。

Conclusion: 失业期间的求职行为变化主要由动态选择驱动，而非真正的持续时间依赖性，且存在显著的异质性，特别是年龄和劳动力市场状况的影响。

Abstract: We study how job search behavior evolves over the unemployment spell and the
extent to which job seekers experience duration dependence in callbacks.
Leveraging data on 2.4 million monthly activity reports containing detailed
information on job applications, interviews, and other search activities, we
separate within-spell changes from dynamic selection with a time-and-spell
fixed effects design. We find that raw search effort increases with
unemployment duration, but this pattern reflects dynamic selection:
within-spell search effort remains flat and declines sharply in the months
preceding re-employment. Around unemployment insurance (UI) exhaustion, search
effort drops by approximately 10%, likely due to participation in labor market
programs crowding out job search. Reported interviews indicate that callbacks
decline by 6% per month, but only 10--14% of this decline reflects ``true''
duration dependence. Finally, we document substantial heterogeneity: search
effort and duration dependence vary strongly by age, and job seekers in tight
labor markets experience about 50% more duration dependence.

</details>


### [80] [Defining the payback period for nonconventional cash flows: an axiomatic approach](https://arxiv.org/abs/2511.03568)
*Mikhail V. Sokolov*

Main category: econ.GN

TL;DR: 本文证明了对于非常规投资项目，项目余额的最后一个盈亏平衡点是唯一符合经济学意义公理组的投资回收期定义。


<details>
  <summary>Details</summary>
Motivation: 非常规投资项目的投资回收期定义存在挑战，因为其累计现金流可能有多个盈亏平衡点。学术界和实践者提出了几种相互矛盾的定义方法。

Method: 通过建立一组经济学意义的公理，分析不同投资回收期定义的合理性。

Result: 发现项目余额的最后一个盈亏平衡点是唯一符合所有公理的投资回收期定义。类似结果也适用于贴现投资回收期。

Conclusion: 项目余额的最后一个盈亏平衡点应作为非常规投资项目投资回收期的标准定义，因为它具有经济学一致性。

Abstract: The payback period is unambiguously defined for conventional investment
projects, projects in which a series of cash outflows is followed by a series
of cash inflows. Its definition for nonconventional projects is more
challenging, since their balances (cumulative cash flow streams) may have
multiple break-even points. Academics and practitioners offer a few
contradictory recipes to manage this issue, suggesting to use the first
break-even point of the balance, the last break-even point of the balance, or
the break-even point of the modified cumulative cash flow stream, representing
the moment of time in which the cumulative cash inflow exceeds the total cash
outflow. In this note, we show that the last break-even point of the project
balance is the only definition of the payback period consistent with a set of
economically meaningful axioms. An analogous result is established for the
discounted payback period.

</details>


### [81] [Supply Chain Disruptions, the Structure of Production Networks, and the Impact of Globalization](https://arxiv.org/abs/2511.03660)
*Matthew L. Elliott,Matthew O. Jackson*

Main category: econ.GN

TL;DR: 本文构建了一个简约的多部门国际生产模型，研究生产中断如何通过生产网络传播，以及短期和长期影响的差异。


<details>
  <summary>Details</summary>
Motivation: 研究生产中断如何通过复杂的供应链网络影响其他商品和消费者，以及这种影响如何依赖于商品在生产网络中的位置和整体结构。

Method: 构建了一个简约的多部门国际生产模型，分析生产网络中的中断传播机制，比较短期和长期影响，并考察供应链复杂性和运输成本变化的影响。

Result: 短期中断影响远大于长期影响；供应链复杂性增加会提高中断概率和预期规模；运输成本降低导致生产专业化，降低中断概率但增加中断时的冲击。

Conclusion: 生产网络的结构特征对经济冲击的传播具有重要影响，政策制定需要考虑供应链的复杂性和专业化程度对经济韧性的双重影响。

Abstract: We introduce a parsimonious multi-sector model of international production
and use it to study the impact of a disruption in the production of some goods
propagates to other goods and consumers, and how that impact depends on the
goods' positions in, and overall structure of, the production network. We show
that the short-run impact of a disruption can be dramatically larger than the
long-run impact. The short-run disruption depends on the value of all of the
final goods whose supply chains involve a disrupted good, while by contrast the
long-run disruption depends only on the cost of the disrupted goods. We use the
model to show how increased complexity of supply chains leads to increased
fragility in terms of the probability and expected short-run size of a
disruption. We also show how decreased transportation costs can lead to
increased specialization in production, lowering the chances for disruption but
increasing the impact conditional upon disruption. We use the model to
characterize the power that a country has over others via diversions of its
production as well as quotas on imports and exports.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [82] [Establishing Trust in Crowdsourced Data](https://arxiv.org/abs/2511.03016)
*Iffat Gheyas,Muhammad Rizwan Asghar,Steve Schneider,Alan Woodward*

Main category: cs.SI

TL;DR: 该研究系统分析了众包数据平台的信任管理实践，识别了现有优势与局限性，并提出了包含AI工具、透明声誉指标、去中心化审核等解决方案，以提升数据可靠性。


<details>
  <summary>Details</summary>
Motivation: 众包数据支持实时决策但面临错误信息、数据错误和贡献者权力集中等挑战，需要系统研究信任管理实践来改善数据质量。

Method: 系统考察了志愿地理信息、维基生态系统、社交媒体、移动众感以及专业评论和环境众包等五类平台的信任管理实践。

Result: 识别出自动审核和社区验证等优势，但也发现数据快速涌入、小众监督缺口、不透明信任指标和精英主导等局限性。

Conclusion: 提出结合先进AI工具、透明声誉指标、去中心化审核、结构化社区参与和"软实力"策略的综合解决方案，旨在公平分配决策权并增强数据可靠性。

Abstract: Crowdsourced data supports real-time decision-making but faces challenges
like misinformation, errors, and contributor power concentration. This study
systematically examines trust management practices across platforms categorised
as Volunteered Geographic Information, Wiki Ecosystems, Social Media, Mobile
Crowdsensing, and Specialised Review and Environmental Crowdsourcing.
Identified strengths include automated moderation and community validation,
while limitations involve rapid data influx, niche oversight gaps, opaque trust
metrics, and elite dominance. Proposed solutions incorporate advanced AI tools,
transparent reputation metrics, decentralised moderation, structured community
engagement, and a ``soft power'' strategy, aiming to equitably distribute
decision-making authority and enhance overall data reliability.

</details>


### [83] [Beyond Citations: Measuring Idea-level Knowledge Diffusion from Research to Journalism and Policy-making](https://arxiv.org/abs/2511.03378)
*Yangliu Fan,Kilian Buehling,Volker Stocker*

Main category: cs.SI

TL;DR: 本文提出了一种基于文本的方法来测量社会科学知识在研究、新闻和政策制定领域之间的思想层面扩散，超越了传统的直接引用测量。


<details>
  <summary>Details</summary>
Motivation: 社会科学知识对不同利益相关者很重要，但测量其在不同领域间的扩散仍然具有挑战性，需要超越直接引用测量的方法。

Method: 使用72,703份文件（2000-2019年），通过计算思想提及次数、估计领域特定语境、使用嵌入回归方法比较跨领域语境化含义，追踪媒体效应理论在不同领域间的扩散。

Result: 扩散模式和动态在不同思想间差异显著；研究与政策间的语义距离通常大于研究与新闻间的距离；思想在不同领域扮演不同角色；实践导向的思想随时间呈现语义趋同。

Conclusion: 研究揭示了社会科学知识在思想层面的跨领域扩散模式和动态，为超越引用的知识扩散测量提供了新视角和方法。

Abstract: Despite the importance of social science knowledge for various stakeholders,
measuring its diffusion into different domains remains a challenge. This study
uses a novel text-based approach to measure the idea-level diffusion of social
science knowledge from the research domain to the journalism and policy-making
domains. By doing so, we expand the detection of knowledge diffusion beyond the
measurements of direct references. Our study focuses on media effects theories
as key research ideas in the field of communication science. Using 72,703
documents (2000-2019) from three domains (i.e., research, journalism, and
policy-making) that mention these ideas, we count the mentions of these ideas
in each domain, estimate their domain-specific contexts, and track and compare
differences across domains and over time. Overall, we find that diffusion
patterns and dynamics vary considerably between ideas, with some ideas
diffusing between other domains, while others do not. Based on the embedding
regression approach, we compare contextualized meanings across domains and find
that the distances between research and policy are typically larger than
between research and journalism. We also find that ideas largely shift roles
across domains - from being the theories themselves in research to sense-making
in news to applied, administrative use in policy. Over time, we observe
semantic convergence mainly for ideas that are practically oriented. Our
results characterize the cross-domain diffusion patterns and dynamics of social
science knowledge at the idea level, and we discuss the implications for
measuring knowledge diffusion beyond citations.

</details>


### [84] [A local eigenvector centrality](https://arxiv.org/abs/2511.03608)
*Ruaridh A. Clark,Francesca Arrigo,Agathe Bouis,Malcolm Macdonald*

Main category: cs.SI

TL;DR: 提出了一种局部特征向量中心性度量，结合局部和全局连通性，通过参考显著特征间隙并组合相关特征谱来检测反映突出社区结构影响的中心性。


<details>
  <summary>Details</summary>
Motivation: 传统特征向量中心性主要衡量全局连通性，但缺乏对局部社区结构的考虑。需要一种能够同时捕捉局部和全局连通性重要性的中心性度量。

Method: 引入局部特征向量中心性，参考显著特征间隙并通过欧几里得范数组合相关特征谱，以检测反映突出社区结构影响的中心性。

Result: 在具有明确定义社区结构的接触网络中，局部特征向量中心性识别出与孤立应用于每个社区的特征向量中心性和PageRank相似但不同的分布。在网络无明确定义社区的情况下，能识别局部突出和全局连接的枢纽。

Conclusion: 局部特征向量中心性能够有效识别反映社区结构影响的节点重要性，并能检测不符合其定义局部结构的节点和社区，同时通过参考PageRank可以缓解特征向量基度量的局部化效应。

Abstract: Eigenvector centrality is an established measure of global connectivity, from
which the importance and influence of nodes can be inferred. We introduce a
local eigenvector centrality that incorporates both local and global
connectivity. This new measure references prominent eigengaps and combines
their associated eigenspectrum, via the Euclidean norm, to detect centrality
that reflects the influence of prominent community structures. In contact
networks, with clearly defined community structures, local eigenvector
centrality is shown to identify similar but distinct distributions to
eigenvector centrality applied on each community in isolation and PageRank.
Discrepancies between the two eigenvector measures highlight nodes and
communities that do not conform to their defined local structures, e.g. nodes
with more connections outside of their defined community than within it. While
reference to PageRank's centrality assessment enables a mitigation strategy for
localisation effects inherent in eigenvector-based measures. In networks
without clearly defined communities, such as city road networks, local
eigenvector centrality is shown to identify both locally prominent and globally
connected hubs.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [85] [NF-SecRIS: RIS-Assisted Near-Field Physical Layer Security via Secure Location Modulation](https://arxiv.org/abs/2511.02949)
*Zhendong Wang,Chenyang Meng,Jun Yang,Jiayuan Wang,Yin Li,Linshan Jiang,Jin Zhang*

Main category: cs.ET

TL;DR: 提出了NF-SecRIS系统，这是首个基于超大规模可重构智能表面的近场通信系统，实现了距离-角度二维物理层安全。


<details>
  <summary>Details</summary>
Motivation: 6G无线网络对物理层安全通信提出极高要求，现有方案通常只能在角度维度实现一维物理层安全，无法在距离维度实现安全。

Method: 提出安全位置调制方案，以极低复杂度合成RIS的近场时空编码模式，确保只有合法用户能接收原始星座图，而其他距离或角度的窃听者只能接收混淆星座图。

Result: 实验结果显示合法用户的误码率低于10^{-4}，而其他距离或角度的窃听者误码率超过40%。

Conclusion: 验证了近场通信中二维物理层安全的实现。

Abstract: The 6G wireless networks impose extremely high requirements on physical layer
secure communication. However, the existing solutions usually can only achieve
one-dimensional physical layer security (PLS) in the angle dimension, and
cannot achieve PLS in the range dimension. In this paper, we propose the
NF-SecRIS system, the first range-angle-dependent (2D) PLS near-field
communication system based on ultra-large-scale reconfigurable intelligent
surface (RIS). We propose the secure location modulation scheme to synthesize
the near-field spatial-temporal coding pattern of RIS with extremely low
complexity. It ensures that only legitimate user can receive the raw
constellations, while potential eavesdroppers at other ranges or angles can
only receive the obfuscated constellations. NF-SecRIS operates without
requiring synchronization with either transmitter or receiver. We implement a
prototype of NF-SecRIS and conduct comprehensive experiments with multiple
modulation schemes. The results show that the bit error rate (BER) of
legitimate user is below 10^{-4}, while eavesdroppers at other ranges or angles
suffer from BER exceeding 40%. It validates the implementation of 2D PLS in
near-field communications.

</details>


### [86] [QAGT-MLP: An Attention-Based Graph Transformer for Small and Large-Scale Quantum Error Mitigation](https://arxiv.org/abs/2511.03119)
*Seyed Mohamad Ali Tousi,G. N. DeSouza*

Main category: cs.ET

TL;DR: 提出QAGT-MLP：一种基于注意力机制的图变换器，用于量子误差缓解，通过融合全局结构和局部光锥邻域特征来预测噪声缓解后的量子电路输出值。


<details>
  <summary>Details</summary>
Motivation: 现有量子误差缓解方法存在执行或校准开销大、难以扩展到大规模深度电路的问题，需要一种既准确又简单高效的误差缓解技术。

Method: 将量子电路编码为图结构，使用双路径注意力模块提取测量量子比特的全局结构上下文和局部光锥上下文特征，结合电路级描述符特征和噪声期望值，通过轻量级MLP预测噪声缓解值。

Result: 在100量子比特的TFIM电路上，QAGT-MLP在平均误差和误差变异性方面优于现有学习方法，在相同测量预算下展现了强大的有效性和实际应用价值。

Conclusion: QAGT-MLP通过注意力机制融合全局和局部特征，在不增加噪声缩放或资源需求的情况下实现高质量误差缓解，为现代和未来量子工作负载提供了可扩展且实用的误差缓解路径。

Abstract: Noisy quantum devices demand error-mitigation techniques to be accurate yet
simple and efficient in terms of number of shots and processing time. Many
established approaches (e.g., extrapolation and quasi-probability cancellation)
impose substantial execution or calibration overheads, while existing
learning-based methods have difficulty scaling to large and deep circuits. In
this research, we introduce QAGT-MLP: an attention-based graph transformer
tailored for small- and large-scale quantum error mitigation (QEM). QAGT-MLP
encodes each quantum circuit as a graph whose nodes represent gate instances
and whose edges capture qubit connectivity and causal adjacency. A dual-path
attention module extracts features around measured qubits at two scales or
contexts: 1) graph-wide global structural context; and 2) fine-grained local
lightcone context. These learned representations are concatenated with
circuit-level descriptor features and the circuit noisy expected values, then
they are passed to a lightweight MLP to predict the noise-mitigated values. On
large-scale 100-qubit Trotterized 1D Transverse-Field Ising Models -- TFIM
circuits -- the proposed QAGT-MLP outperformed state-of-the-art learning
baselines in terms of mean error and error variability, demonstrating strong
validity and applicability in real-world QEM scenarios under matched shot
budgets. By using attention to fuse global structures with local lightcone
neighborhoods, QAGT-MLP achieves high mitigation quality without the increasing
noise scaling or resource demand required by classical QEM pipelines, while
still offering a scalable and practical path to QEM in modern and future
quantum workloads.

</details>


### [87] [LLM-enhanced Air Quality Monitoring Interface via Model Context Protocol](https://arxiv.org/abs/2511.03706)
*Yu-Erh Pan,Ayesha Siddika Nipu*

Main category: cs.ET

TL;DR: 提出了一种基于大语言模型(LLM)增强的空气监测界面(AMI)，通过模型上下文协议(MCP)集成实时传感器数据和对话界面，在降低幻觉风险的同时提供准确的环境监测服务。


<details>
  <summary>Details</summary>
Motivation: 传统空气质量监测系统存在可视化复杂、交互性有限、部署成本高等问题，而LLM虽然提供了新的可访问性机会，但在安全关键领域存在幻觉风险。

Method: 结合Django后端、响应式用户仪表板和安全的MCP服务器，将系统功能作为可发现工具暴露给LLM，使其成为主动操作者而非被动响应者。

Result: 专家评估显示高事实准确性(4.78)、完整性(4.82)和最小化幻觉(4.84)，评分基于5分制，并得到评分者间可靠性分析支持。

Conclusion: 将LLM与标准化工具协议结合，可为实时环境监测创建可靠、安全且用户友好的界面。

Abstract: Air quality monitoring is central to environmental sustainability and public
health, yet traditional systems remain difficult for non-expert users to
interpret due to complex visualizations, limited interactivity, and high
deployment costs. Recent advances in Large Language Models (LLMs) offer new
opportunities to make sensor data more accessible, but their tendency to
produce hallucinations limits reliability in safety-critical domains. To
address these challenges, we present an LLM-enhanced Air Monitoring Interface
(AMI) that integrates real-time sensor data with a conversational interface via
the Model Context Protocol (MCP). Our system grounds LLM outputs in live
environmental data, enabling accurate, context-aware responses while reducing
hallucination risk. The architecture combines a Django-based backend, a
responsive user dashboard, and a secure MCP server that exposes system
functions as discoverable tools, allowing the LLM to act as an active operator
rather than a passive responder. Expert evaluation demonstrated high factual
accuracy (4.78), completeness (4.82), and minimal hallucinations (4.84), on a
scale of 5, supported by inter-rater reliability analysis. These results
highlight the potential of combining LLMs with standardized tool protocols to
create reliable, secure, and user-friendly interfaces for real-time
environmental monitoring.

</details>
